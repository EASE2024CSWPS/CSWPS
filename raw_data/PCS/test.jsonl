{"id": 1072, "code": "\tpublic SpringApplicationBuilder environmentPrefix(String environmentPrefix) {\n\t\tthis.application.setEnvironmentPrefix(environmentPrefix);\n\t\treturn this;\n\t}", "summary_tokens": ["prefix", "that", "should", "be", "applied", "when", "obtaining", "configuration", "properties", "from", "the", "system", "environment"], "project": "spring-boot"}
{"id": 456, "code": "\tpublic T getObject() {\n\t\treturn this.object;\n\t}", "summary_tokens": ["return", "the", "actual", "object", "content"], "project": "spring-boot"}
{"id": 181, "code": "\tpublic String getMessage() {\n\t\treturn this.message.isEmpty() ? null : this.message.toString();\n\t}", "summary_tokens": ["return", "an", "outcome", "message", "or", "null"], "project": "spring-boot"}
{"id": 20, "code": "\tprivate String getEntityManagerFactoryName(String beanName) {\n\t\tif (beanName.length() > ENTITY_MANAGER_FACTORY_SUFFIX.length()\n\t\t\t\t&& StringUtils.endsWithIgnoreCase(beanName, ENTITY_MANAGER_FACTORY_SUFFIX)) {\n\t\t\treturn beanName.substring(0, beanName.length() - ENTITY_MANAGER_FACTORY_SUFFIX.length());\n\t\t}\n\t\treturn beanName;\n\t}", "summary_tokens": ["get", "the", "name", "of", "an", "entity", "manager", "factory", "based", "on", "its", "bean", "name"], "project": "spring-boot"}
{"id": 207, "code": "\tpublic void setJndiName(String jndiName) {\n\t\tthis.jndiName = jndiName;\n\t}", "summary_tokens": ["allows", "the", "data", "source", "to", "be", "managed", "by", "the", "container", "and", "obtained", "via", "jndi"], "project": "spring-boot"}
{"id": 1357, "code": "\tpublic <T extends ThreadPoolTaskExecutor> T build(Class<T> taskExecutorClass) {\n\t\treturn configure(BeanUtils.instantiateClass(taskExecutorClass));\n\t}", "summary_tokens": ["build", "a", "new", "thread", "pool", "task", "executor", "instance", "of", "the", "specified", "type", "and", "configure", "it", "using", "this", "builder"], "project": "spring-boot"}
{"id": 223, "code": "\tvoid setReplyTemplate(KafkaTemplate<Object, Object> replyTemplate) {\n\t\tthis.replyTemplate = replyTemplate;\n\t}", "summary_tokens": ["set", "the", "kafka", "template", "to", "use", "to", "send", "replies"], "project": "spring-boot"}
{"id": 622, "code": "\tpublic String getDomain() {\n\t\treturn this.domain;\n\t}", "summary_tokens": ["return", "the", "domain", "for", "this", "image", "name"], "project": "spring-boot"}
{"id": 55, "code": "\tdefault boolean hasParameters() {\n\t\treturn getParameterCount() > 0;\n\t}", "summary_tokens": ["return", "true", "if", "there", "is", "at", "least", "one", "parameter"], "project": "spring-boot"}
{"id": 226, "code": "\tpublic void setCommonErrorHandler(CommonErrorHandler commonErrorHandler) {\n\t\tthis.commonErrorHandler = commonErrorHandler;\n\t}", "summary_tokens": ["set", "the", "common", "error", "handler", "to", "use"], "project": "spring-boot"}
{"id": 741, "code": "\tpublic String optString(String name, String fallback) {\n\t\tObject object = opt(name);\n\t\tString result = JSON.toString(object);\n\t\treturn result != null ? result : fallback;\n\t}", "summary_tokens": ["returns", "the", "value", "mapped", "by", "name", "if", "it", "exists", "coercing", "it", "if", "necessary"], "project": "spring-boot"}
{"id": 842, "code": "\tpublic List<String> getTags() {\n\t\treturn this.tags.getOrNull();\n\t}", "summary_tokens": ["returns", "the", "tags", "that", "will", "be", "created", "for", "the", "built", "image"], "project": "spring-boot"}
{"id": 1355, "code": "\tpublic TaskExecutorBuilder customizers(Iterable<TaskExecutorCustomizer> customizers) {\n\t\tAssert.notNull(customizers, \"Customizers must not be null\");\n\t\treturn new TaskExecutorBuilder(this.queueCapacity, this.corePoolSize, this.maxPoolSize,\n\t\t\t\tthis.allowCoreThreadTimeOut, this.keepAlive, this.awaitTermination, this.awaitTerminationPeriod,\n\t\t\t\tthis.threadNamePrefix, this.taskDecorator, append(null, customizers));\n\t}", "summary_tokens": ["set", "the", "task", "executor", "customizer", "task", "executor", "customizers", "that", "should", "be", "applied", "to", "the", "thread", "pool", "task", "executor"], "project": "spring-boot"}
{"id": 332, "code": "\tpublic void applyDependencies(DependencyCustomizer dependencies) throws CompilationFailedException {\n\t}", "summary_tokens": ["apply", "any", "dependency", "customizations"], "project": "spring-boot"}
{"id": 1564, "code": "\tpublic MimeMappings getMimeMappings() {\n\t\treturn this.mimeMappings;\n\t}", "summary_tokens": ["returns", "the", "mime", "type", "mappings"], "project": "spring-boot"}
{"id": 1238, "code": "\tdefault ConfigurationPropertySource filter(Predicate<ConfigurationPropertyName> filter) {\n\t\treturn new FilteredConfigurationPropertiesSource(this, filter);\n\t}", "summary_tokens": ["return", "a", "filtered", "variant", "of", "this", "source", "containing", "only", "names", "that", "match", "the", "given", "predicate"], "project": "spring-boot"}
{"id": 412, "code": "\tpublic <T> T persistAndGetId(Object entity, Class<T> idType) {\n\t\tpersist(entity);\n\t\treturn getId(entity, idType);\n\t}", "summary_tokens": ["make", "an", "instance", "managed", "and", "persistent", "then", "return", "its", "id"], "project": "spring-boot"}
{"id": 1097, "code": "\tStream<ConfigDataEnvironmentContributor> stream() {\n\t\treturn StreamSupport.stream(spliterator(), false);\n\t}", "summary_tokens": ["returns", "a", "stream", "that", "traverses", "this", "contributor", "and", "all", "its", "children", "in", "priority", "order"], "project": "spring-boot"}
{"id": 538, "code": "\tString getVersion() {\n\t\treturn this.version;\n\t}", "summary_tokens": ["return", "the", "buildpack", "version"], "project": "spring-boot"}
{"id": 1074, "code": "\tpublic SpringApplicationBuilder initializers(ApplicationContextInitializer<?>... initializers) {\n\t\tthis.application.addInitializers(initializers);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "some", "initializers", "to", "the", "application", "applied", "to", "the", "application", "context", "before", "any", "bean", "definitions", "are", "loaded"], "project": "spring-boot"}
{"id": 78, "code": "\tpublic Collection<Resource> createEndpointResources(EndpointMapping endpointMapping,\n\t\t\tCollection<ExposableWebEndpoint> endpoints, EndpointMediaTypes endpointMediaTypes,\n\t\t\tEndpointLinksResolver linksResolver, boolean shouldRegisterLinks) {\n\t\tList<Resource> resources = new ArrayList<>();\n\t\tendpoints.stream().flatMap((endpoint) -> endpoint.getOperations().stream())\n\t\t\t\t.map((operation) -> createResource(endpointMapping, operation)).forEach(resources::add);\n\t\tif (shouldRegisterLinks) {\n\t\t\tResource resource = createEndpointLinksResource(endpointMapping.getPath(), endpointMediaTypes,\n\t\t\t\t\tlinksResolver);\n\t\t\tresources.add(resource);\n\t\t}\n\t\treturn resources;\n\t}", "summary_tokens": ["creates", "resource", "resources", "for", "the", "operations", "of", "the", "given", "web", "endpoints"], "project": "spring-boot"}
{"id": 1437, "code": "\tpublic boolean isIncluded(Include include) {\n\t\treturn this.includes.contains(include);\n\t}", "summary_tokens": ["get", "the", "option", "for", "including", "the", "specified", "attribute", "in", "the", "error", "response"], "project": "spring-boot"}
{"id": 646, "code": "\tpublic static int umaskForPath(Path path) throws IOException {\n\t\tAssert.notNull(path, \"Path must not be null\");\n\t\tPosixFileAttributeView attributeView = Files.getFileAttributeView(path, PosixFileAttributeView.class);\n\t\tAssert.state(attributeView != null, \"Unsupported file type for retrieving Posix attributes\");\n\t\treturn posixPermissionsToUmask(attributeView.readAttributes().permissions());\n\t}", "summary_tokens": ["return", "the", "integer", "representation", "of", "the", "file", "permissions", "for", "a", "path", "where", "the", "integer", "value", "conforms", "to", "the", "a", "href", "https", "en"], "project": "spring-boot"}
{"id": 852, "code": "\tpublic DockerSpec getDocker() {\n\t\treturn this.docker;\n\t}", "summary_tokens": ["returns", "the", "docker", "configuration", "the", "builder", "will", "use"], "project": "spring-boot"}
{"id": 1150, "code": "\tpublic String getProfile() {\n\t\treturn this.reference.getProfile();\n\t}", "summary_tokens": ["return", "the", "profile", "or", "null", "if", "the", "resource", "is", "not", "profile", "specific"], "project": "spring-boot"}
{"id": 1453, "code": "\tpublic void setCharset(String charset) {\n\t\tthis.charset = charset;\n\t}", "summary_tokens": ["set", "the", "charset", "used", "for", "reading", "mustache", "template", "files"], "project": "spring-boot"}
{"id": 1449, "code": "\tpublic WebServer getWebServer() {\n\t\tWebServerManager serverManager = this.serverManager;\n\t\treturn (serverManager != null) ? serverManager.getWebServer() : null;\n\t}", "summary_tokens": ["returns", "the", "web", "server", "that", "was", "created", "by", "the", "context", "or", "null", "if", "the", "server", "has", "not", "yet", "been", "created"], "project": "spring-boot"}
{"id": 1225, "code": "\tpublic String getElement(int elementIndex, Form form) {\n\t\tCharSequence element = this.elements.get(elementIndex);\n\t\tElementType type = this.elements.getType(elementIndex);\n\t\tif (type.isIndexed()) {\n\t\t\treturn element.toString();\n\t\t}\n\t\tif (form == Form.ORIGINAL) {\n\t\t\tif (type != ElementType.NON_UNIFORM) {\n\t\t\t\treturn element.toString();\n\t\t\t}\n\t\t\treturn convertToOriginalForm(element).toString();\n\t\t}\n\t\tif (form == Form.DASHED) {\n\t\t\tif (type == ElementType.UNIFORM || type == ElementType.DASHED) {\n\t\t\t\treturn element.toString();\n\t\t\t}\n\t\t\treturn convertToDashedElement(element).toString();\n\t\t}\n\t\tCharSequence uniformElement = this.uniformElements[elementIndex];\n\t\tif (uniformElement == null) {\n\t\t\tuniformElement = (type != ElementType.UNIFORM) ? convertToUniformElement(element) : element;\n\t\t\tthis.uniformElements[elementIndex] = uniformElement.toString();\n\t\t}\n\t\treturn uniformElement.toString();\n\t}", "summary_tokens": ["return", "an", "element", "in", "the", "name", "in", "the", "given", "form"], "project": "spring-boot"}
{"id": 1056, "code": "\tpublic SpringApplicationBuilder contextFactory(ApplicationContextFactory factory) {\n\t\tthis.application.setApplicationContextFactory(factory);\n\t\treturn this;\n\t}", "summary_tokens": ["explicitly", "set", "the", "factory", "used", "to", "create", "the", "application", "context"], "project": "spring-boot"}
{"id": 1280, "code": "\tpublic static DataSourceBuilder<?> derivedFrom(DataSource dataSource) {\n\t\tif (dataSource instanceof EmbeddedDatabase) {\n\t\t\ttry {\n\t\t\t\tdataSource = dataSource.unwrap(DataSource.class);\n\t\t\t}\n\t\t\tcatch (SQLException ex) {\n\t\t\t\tthrow new IllegalStateException(\"Unable to unwrap embedded database\", ex);\n\t\t\t}\n\t\t}\n\t\treturn new DataSourceBuilder<>(unwrap(dataSource));\n\t}", "summary_tokens": ["create", "a", "new", "data", "source", "builder", "instance", "derived", "from", "the", "specified", "data", "source"], "project": "spring-boot"}
{"id": 253, "code": "\tpublic Duration determineTimeout(Supplier<Duration> fallbackTimeout) {\n\t\treturn (this.timeout != null) ? this.timeout : fallbackTimeout.get();\n\t}", "summary_tokens": ["determine", "the", "session", "timeout"], "project": "spring-boot"}
{"id": 1561, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "for", "this", "filter"], "project": "spring-boot"}
{"id": 855, "code": "\tpublic void layered(Action<LayeredSpec> action) {\n\t\taction.execute(this.layered);\n\t}", "summary_tokens": ["configures", "the", "jar", "s", "layering", "using", "the", "given", "action"], "project": "spring-boot"}
{"id": 822, "code": "\tpublic void setRunImage(String runImage) {\n\t\tthis.runImage = runImage;\n\t}", "summary_tokens": ["sets", "the", "run", "image", "that", "will", "be", "included", "in", "the", "built", "image"], "project": "spring-boot"}
{"id": 670, "code": "\tpublic String getShortDescription() {\n\t\treturn this.shortDescription;\n\t}", "summary_tokens": ["a", "single", "line", "single", "sentence", "description", "of", "this", "property", "if", "any"], "project": "spring-boot"}
{"id": 1569, "code": "\tprotected final File getValidDocumentRoot() {\n\t\treturn this.documentRoot.getValidDirectory();\n\t}", "summary_tokens": ["returns", "the", "absolute", "document", "root", "when", "it", "points", "to", "a", "valid", "directory", "logging", "a", "warning", "and", "returning", "null", "otherwise"], "project": "spring-boot"}
{"id": 1104, "code": "\tstatic ConfigDataEnvironmentContributor ofExisting(PropertySource<?> propertySource) {\n\t\treturn new ConfigDataEnvironmentContributor(Kind.EXISTING, null, null, false, propertySource,\n\t\t\t\tConfigurationPropertySource.from(propertySource), null, null, null);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "contributor", "that", "wraps", "an", "kind", "existing", "existing", "property", "source"], "project": "spring-boot"}
{"id": 853, "code": "\tpublic void docker(Action<DockerSpec> action) {\n\t\taction.execute(this.docker);\n\t}", "summary_tokens": ["configures", "the", "docker", "connection", "using", "the", "given", "action"], "project": "spring-boot"}
{"id": 1274, "code": "\tpublic DataSourceBuilder<T> url(String url) {\n\t\tset(DataSourceProperty.URL, url);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "url", "that", "should", "be", "used", "when", "building", "the", "datasource"], "project": "spring-boot"}
{"id": 643, "code": "\tpublic static <S> VolumeName basedOn(S source, Function<S, String> nameExtractor, String prefix, String suffix,\n\t\t\tint digestLength) {\n\t\tAssert.notNull(source, \"Source must not be null\");\n\t\tAssert.notNull(nameExtractor, \"NameExtractor must not be null\");\n\t\tAssert.notNull(prefix, \"Prefix must not be null\");\n\t\tAssert.notNull(suffix, \"Suffix must not be null\");\n\t\treturn of(prefix + getDigest(nameExtractor.apply(source), digestLength) + suffix);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "new", "volume", "name", "based", "on", "an", "object"], "project": "spring-boot"}
{"id": 1474, "code": "\tpublic ClientAuth getClientAuth() {\n\t\treturn this.clientAuth;\n\t}", "summary_tokens": ["return", "whether", "client", "authentication", "is", "not", "wanted", "none", "wanted", "want", "or", "needed", "need"], "project": "spring-boot"}
{"id": 285, "code": "\tdefault RequestMappingHandlerAdapter getRequestMappingHandlerAdapter() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "custom", "request", "mapping", "handler", "adapter", "that", "should", "be", "used", "and", "processed", "by", "the", "mvc", "configuration"], "project": "spring-boot"}
{"id": 1334, "code": "\tpublic void setSchemaLocations(List<String> schemaLocations) {\n\t\tthis.schemaLocations = schemaLocations;\n\t}", "summary_tokens": ["sets", "the", "locations", "of", "schema", "ddl", "scripts", "to", "apply", "to", "the", "database"], "project": "spring-boot"}
{"id": 1378, "code": "\tpublic RestTemplateBuilder additionalMessageConverters(\n\t\t\tCollection<? extends HttpMessageConverter<?>> messageConverters) {\n\t\tAssert.notNull(messageConverters, \"MessageConverters must not be null\");\n\t\treturn new RestTemplateBuilder(this.requestFactoryCustomizer, this.detectRequestFactory, this.rootUri,\n\t\t\t\tappend(this.messageConverters, messageConverters), this.interceptors, this.requestFactory,\n\t\t\t\tthis.uriTemplateHandler, this.errorHandler, this.basicAuthentication, this.defaultHeaders,\n\t\t\t\tthis.customizers, this.requestCustomizers);\n\t}", "summary_tokens": ["add", "additional", "http", "message", "converter", "http", "message", "converters", "that", "should", "be", "used", "with", "the", "rest", "template"], "project": "spring-boot"}
{"id": 1300, "code": "\tpublic void initialize(LoggingInitializationContext initializationContext, String configLocation, LogFile logFile) {\n\t}", "summary_tokens": ["fully", "initialize", "the", "logging", "system"], "project": "spring-boot"}
{"id": 1556, "code": "\tpublic final void load(Class<?> relativeClass, String... resourceNames) {\n\t\tResource[] resources = new Resource[resourceNames.length];\n\t\tfor (int i = 0; i < resourceNames.length; i++) {\n\t\t\tresources[i] = new ClassPathResource(resourceNames[i], relativeClass);\n\t\t}\n\t\tthis.reader.loadBeanDefinitions(resources);\n\t}", "summary_tokens": ["load", "bean", "definitions", "from", "the", "given", "xml", "resources"], "project": "spring-boot"}
{"id": 368, "code": "\tint checkedRead(byte[] buffer, int offset, int length) throws IOException {\n\t\tint amountRead = read(buffer, offset, length);\n\t\tif (amountRead == -1) {\n\t\t\tthrow new IOException(\"End of stream\");\n\t\t}\n\t\treturn amountRead;\n\t}", "summary_tokens": ["read", "a", "number", "of", "bytes", "from", "the", "stream", "checking", "that", "the", "end", "of", "the", "stream", "hasn", "t", "been", "reached"], "project": "spring-boot"}
{"id": 756, "code": "\tpublic JSONStringer endObject() throws JSONException {\n\t\treturn close(Scope.EMPTY_OBJECT, Scope.NONEMPTY_OBJECT, \"}\");", "summary_tokens": ["ends", "encoding", "the", "current", "object"], "project": "spring-boot"}
{"id": 69, "code": "\tstatic String getRootPath(List<PathMapper> pathMappers, EndpointId endpointId) {\n\t\tAssert.notNull(endpointId, \"EndpointId must not be null\");\n\t\tif (pathMappers != null) {\n\t\t\tfor (PathMapper mapper : pathMappers) {\n\t\t\t\tString path = mapper.getRootPath(endpointId);\n\t\t\t\tif (StringUtils.hasText(path)) {\n\t\t\t\t\treturn path;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn endpointId.toString();\n\t}", "summary_tokens": ["resolve", "the", "root", "path", "for", "the", "specified", "endpoint", "id", "from", "the", "given", "path", "mappers"], "project": "spring-boot"}
{"id": 1258, "code": "\tstatic EnvironmentPostProcessorsFactory fromSpringFactories(ClassLoader classLoader) {\n\t\treturn new SpringFactoriesEnvironmentPostProcessorsFactory(\n\t\t\t\tSpringFactoriesLoader.forDefaultResourceLocation(classLoader));\n\t}", "summary_tokens": ["return", "a", "environment", "post", "processors", "factory", "backed", "by", "spring"], "project": "spring-boot"}
{"id": 917, "code": "\tpublic static String sha1Hash(File file) throws IOException {\n\t\treturn Digest.sha1(InputStreamSupplier.forFile(file));\n\t}", "summary_tokens": ["generate", "a", "sha", "0", "hash", "for", "a", "given", "file"], "project": "spring-boot"}
{"id": 552, "code": "\tOwner getBuildOwner() {\n\t\treturn this.buildOwner;\n\t}", "summary_tokens": ["return", "the", "build", "owner", "that", "should", "be", "used", "for", "written", "content"], "project": "spring-boot"}
{"id": 1537, "code": "\tpublic void setEnvironment(ConfigurableEnvironment environment) {\n\t\tsuper.setEnvironment(environment);\n\t\tthis.reader.setEnvironment(environment);\n\t\tthis.scanner.setEnvironment(environment);\n\t}", "summary_tokens": ["p", "delegates", "given", "environment", "to", "underlying", "annotated", "bean", "definition", "reader", "and", "class", "path", "bean", "definition", "scanner", "members"], "project": "spring-boot"}
{"id": 835, "code": "\tpublic void setBuildpacks(List<String> buildpacks) {\n\t\tthis.buildpacks.set(buildpacks);\n\t}", "summary_tokens": ["sets", "the", "buildpacks", "that", "will", "be", "used", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 410, "code": "\tvoid add(String name, List<PropertyMigration> properties) {\n\t\tthis.content.put(name, new LegacyProperties(properties));\n\t}", "summary_tokens": ["register", "a", "new", "property", "source"], "project": "spring-boot"}
{"id": 408, "code": "\tString getWarningReport() {\n\t\tMap<String, List<PropertyMigration>> content = getContent(LegacyProperties::getRenamed);\n\t\tif (content.isEmpty()) {\n\t\t\treturn null;\n\t\t}\n\t\tStringBuilder report = new StringBuilder();\n\t\treport.append(String\n\t\t\t\t.format(\"%nThe use of configuration keys that have been renamed was found in the environment:%n%n\"));\n\t\tappend(report, content);\n\t\treport.append(String.format(\"%n\"));\n\t\treport.append(\"Each configuration key has been temporarily mapped to its \"\n\t\t\t\t+ \"replacement for your convenience. To silence this warning, please \"\n\t\t\t\t+ \"update your configuration to use the new keys.\");\n\t\treport.append(String.format(\"%n\"));\n\t\treturn report.toString();\n\t}", "summary_tokens": ["return", "a", "report", "for", "all", "the", "properties", "that", "were", "automatically", "renamed"], "project": "spring-boot"}
{"id": 476, "code": "\tpublic void setProperty(String property) {\n\t\tthis.property = property;\n\t}", "summary_tokens": ["set", "the", "ant", "property", "to", "set", "if", "left", "unset", "result", "will", "be", "printed", "to", "the", "log"], "project": "spring-boot"}
{"id": 455, "code": "\tpublic static void initFields(Object testInstance, ObjectFactory<Jsonb> jsonb) {\n\t\tnew JsonbTester.JsonbFieldInitializer().initFields(testInstance, jsonb);\n\t}", "summary_tokens": ["utility", "method", "to", "initialize", "jsonb", "tester", "fields"], "project": "spring-boot"}
{"id": 667, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["the", "name", "of", "the", "property", "in", "lowercase", "dashed", "form", "e"], "project": "spring-boot"}
{"id": 727, "code": "\tpublic Object remove(String name) {\n\t\treturn this.nameValuePairs.remove(name);\n\t}", "summary_tokens": ["removes", "the", "named", "mapping", "if", "it", "exists", "does", "nothing", "otherwise"], "project": "spring-boot"}
{"id": 1572, "code": "\tdefault CookieSameSiteSupplier when(Predicate<Cookie> predicate) {\n\t\tAssert.notNull(predicate, \"Predicate must not be null\");\n\t\treturn (cookie) -> predicate.test(cookie) ? getSameSite(cookie) : null;\n\t}", "summary_tokens": ["limit", "this", "supplier", "so", "that", "it", "s", "only", "called", "if", "the", "predicate", "accepts", "the", "cookie"], "project": "spring-boot"}
{"id": 721, "code": "\tpublic String join(String separator) throws JSONException {\n\t\tJSONStringer stringer = new JSONStringer();\n\t\tstringer.open(JSONStringer.Scope.NULL, \"\");\n\t\tfor (int i = 0, size = this.values.size(); i < size; i++) {\n\t\t\tif (i > 0) {\n\t\t\t\tstringer.out.append(separator);\n\t\t\t}\n\t\t\tstringer.value(this.values.get(i));\n\t\t}\n\t\tstringer.close(JSONStringer.Scope.NULL, JSONStringer.Scope.NULL, \"\");\n\t\treturn stringer.out.toString();\n\t}", "summary_tokens": ["returns", "a", "new", "string", "by", "alternating", "this", "array", "s", "values", "with", "separator"], "project": "spring-boot"}
{"id": 1019, "code": "\tpublic static boolean hasMatchingName(PropertySource<?> propertySource) {\n\t\treturn (propertySource != null) && propertySource.getName().equals(NAME);\n\t}", "summary_tokens": ["return", "true", "if", "the", "given", "source", "is", "named", "default", "properties"], "project": "spring-boot"}
{"id": 1113, "code": "\tdefault boolean isLoadable(ConfigDataLoaderContext context, R resource) {\n\t\treturn true;\n\t}", "summary_tokens": ["returns", "if", "the", "specified", "resource", "can", "be", "loaded", "by", "this", "instance"], "project": "spring-boot"}
{"id": 1568, "code": "\tprotected boolean shouldRegisterJspServlet() {\n\t\treturn this.jsp != null && this.jsp.getRegistered()\n\t\t\t\t&& ClassUtils.isPresent(this.jsp.getClassName(), getClass().getClassLoader());\n\t}", "summary_tokens": ["returns", "whether", "the", "jsp", "servlet", "should", "be", "registered", "with", "the", "web", "server"], "project": "spring-boot"}
{"id": 968, "code": "\tprotected Artifact getSourceArtifact(String classifier) {\n\t\tArtifact sourceArtifact = getArtifact(classifier);\n\t\treturn (sourceArtifact != null) ? sourceArtifact : this.project.getArtifact();\n\t}", "summary_tokens": ["return", "the", "source", "artifact", "to", "repackage"], "project": "spring-boot"}
{"id": 525, "code": "\tvoid attachTo(ImageConfig.Update update) {\n\t\ttry {\n\t\t\tString json = SharedObjectMapper.get().writeValueAsString(getNode());\n\t\t\tupdate.withLabel(LABEL_NAME, json);\n\t\t}\n\t\tcatch (JsonProcessingException ex) {\n\t\t\tthrow new IllegalStateException(ex);\n\t\t}\n\t}", "summary_tokens": ["attach", "this", "metadata", "to", "the", "given", "update", "callback"], "project": "spring-boot"}
{"id": 1326, "code": "\tpublic void setLifecycleTimeout(Duration lifecycleTimeout) {\n\t\tthis.lifecycleTimeout = lifecycleTimeout;\n\t}", "summary_tokens": ["set", "the", "maximum", "amount", "of", "time", "that", "should", "be", "waited", "when", "starting", "or", "stopping", "the", "server"], "project": "spring-boot"}
{"id": 1585, "code": "\tpublic HttpWebServiceMessageSenderBuilder setConnectTimeout(Duration connectTimeout) {\n\t\tthis.connectTimeout = connectTimeout;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "connection", "timeout"], "project": "spring-boot"}
{"id": 840, "code": "\tpublic void binding(String binding) {\n\t\tthis.bindings.add(binding);\n\t}", "summary_tokens": ["add", "an", "entry", "to", "the", "volume", "bindings", "that", "will", "be", "mounted", "to", "the", "container", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 1349, "code": "\tpublic TaskExecutorBuilder allowCoreThreadTimeOut(boolean allowCoreThreadTimeOut) {\n\t\treturn new TaskExecutorBuilder(this.queueCapacity, this.corePoolSize, this.maxPoolSize, allowCoreThreadTimeOut,\n\t\t\t\tthis.keepAlive, this.awaitTermination, this.awaitTerminationPeriod, this.threadNamePrefix,\n\t\t\t\tthis.taskDecorator, this.customizers);\n\t}", "summary_tokens": ["set", "whether", "core", "threads", "are", "allowed", "to", "time", "out"], "project": "spring-boot"}
{"id": 1062, "code": "\tpublic SpringApplicationBuilder registerShutdownHook(boolean registerShutdownHook) {\n\t\tthis.registerShutdownHookApplied = true;\n\t\tthis.application.setRegisterShutdownHook(registerShutdownHook);\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "if", "the", "created", "application", "context", "should", "have", "a", "shutdown", "hook", "registered"], "project": "spring-boot"}
{"id": 1105, "code": "\tstatic ConfigDataEnvironmentContributor ofUnboundImport(ConfigDataLocation location, ConfigDataResource resource,\n\t\t\tboolean profileSpecific, ConfigData configData, int propertySourceIndex) {\n\t\tPropertySource<?> propertySource = configData.getPropertySources().get(propertySourceIndex);\n\t\tConfigData.Options options = configData.getOptions(propertySource);\n\t\tConfigurationPropertySource configurationPropertySource = ConfigurationPropertySource.from(propertySource);\n\t\treturn new ConfigDataEnvironmentContributor(Kind.UNBOUND_IMPORT, location, resource, profileSpecific,\n\t\t\t\tpropertySource, configurationPropertySource, null, options, null);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "an", "kind", "unbound", "import", "unbound", "import", "contributor"], "project": "spring-boot"}
{"id": 617, "code": "\tpublic ImageReference getTag() {\n\t\treturn this.tag;\n\t}", "summary_tokens": ["return", "the", "tag", "of", "the", "archive"], "project": "spring-boot"}
{"id": 1191, "code": "\tpublic T get() throws NoSuchElementException {\n\t\tif (this.value == null) {\n\t\t\tthrow new NoSuchElementException(\"No value bound\");\n\t\t}\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "object", "that", "was", "bound", "or", "throw", "a", "no", "such", "element", "exception", "if", "no", "value", "was", "bound"], "project": "spring-boot"}
{"id": 773, "code": "\tprivate JSONArray readArray() throws JSONException {\n\t\tJSONArray result = new JSONArray();\n\n\t\t\n\t\tboolean hasTrailingSeparator = false;\n\n\t\twhile (true) {\n\t\t\tswitch (nextCleanInternal()) {\n\t\t\t\tcase -1:\n\t\t\t\t\tthrow syntaxError(\"Unterminated array\");\n\t\t\t\tcase ']':\n\t\t\t\t\tif (hasTrailingSeparator) {\n\t\t\t\t\t\tresult.put(null);\n\t\t\t\t\t}\n\t\t\t\t\treturn result;\n\t\t\t\tcase ',':\n\t\t\t\tcase ';':\n\t\t\t\t\t\n\t\t\t\t\tresult.put(null);\n\t\t\t\t\thasTrailingSeparator = true;\n\t\t\t\t\tcontinue;\n\t\t\t\tdefault:\n\t\t\t\t\tthis.pos--;\n\t\t\t}\n\n\t\t\tresult.put(nextValue());\n\n\t\t\tswitch (nextCleanInternal()) {\n\t\t\t\tcase ']':\n\t\t\t\t\treturn result;\n\t\t\t\tcase ',':\n\t\t\t\tcase ';':\n\t\t\t\t\thasTrailingSeparator = true;\n\t\t\t\t\tcontinue;\n\t\t\t\tdefault:\n\t\t\t\t\tthrow syntaxError(\"Unterminated array\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["reads", "a", "sequence", "of", "values", "and", "the", "trailing", "closing", "brace", "of", "an", "array"], "project": "spring-boot"}
{"id": 163, "code": "\tpublic void setRetryTemplateCustomizers(List<RabbitRetryTemplateCustomizer> retryTemplateCustomizers) {\n\t\tthis.retryTemplateCustomizers = retryTemplateCustomizers;\n\t}", "summary_tokens": ["set", "the", "rabbit", "retry", "template", "customizer", "instances", "to", "use"], "project": "spring-boot"}
{"id": 1018, "code": "\tpublic void close(ConfigurableApplicationContext applicationContext) {\n\t\tthis.events.multicastEvent(new BootstrapContextClosedEvent(this, applicationContext));\n\t}", "summary_tokens": ["method", "to", "be", "called", "when", "bootstrap", "context", "is", "closed", "and", "the", "application", "context", "is", "prepared"], "project": "spring-boot"}
{"id": 42, "code": "\tpublic Map<String, Object> getArguments() {\n\t\treturn this.arguments;\n\t}", "summary_tokens": ["return", "the", "invocation", "arguments"], "project": "spring-boot"}
{"id": 1286, "code": "\tdefault Integer getIdle() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "number", "of", "established", "but", "idle", "connections"], "project": "spring-boot"}
{"id": 239, "code": "\tprotected final boolean isJta() {\n\t\treturn (this.jtaTransactionManager != null);\n\t}", "summary_tokens": ["returns", "if", "a", "jta", "platform", "transaction", "manager", "is", "being", "used"], "project": "spring-boot"}
{"id": 371, "code": "\tpublic int getPort() {\n\t\treturn this.port;\n\t}", "summary_tokens": ["return", "the", "port", "that", "the", "server", "is", "listening", "on"], "project": "spring-boot"}
{"id": 1404, "code": "\tpublic ThreadPool getThreadPool() {\n\t\treturn this.threadPool;\n\t}", "summary_tokens": ["returns", "a", "jetty", "thread", "pool", "that", "should", "be", "used", "by", "the", "server"], "project": "spring-boot"}
{"id": 136, "code": "\tprotected void postProcessRequestHeaders(Map<String, List<String>> headers) {\n\n\t}", "summary_tokens": ["post", "process", "the", "given", "mutable", "map", "of", "request", "headers"], "project": "spring-boot"}
{"id": 1265, "code": "\tpublic String getBranch() {\n\t\treturn get(\"branch\");\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "branch", "or", "null"], "project": "spring-boot"}
{"id": 286, "code": "\tdefault ExceptionHandlerExceptionResolver getExceptionHandlerExceptionResolver() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "custom", "exception", "handler", "exception", "resolver", "that", "should", "be", "used", "and", "processed", "by", "the", "mvc", "configuration"], "project": "spring-boot"}
{"id": 562, "code": "\tvoid withDaemonAccess() {\n\t\tthis.daemonAccess = true;\n\t}", "summary_tokens": ["update", "this", "phase", "with", "docker", "daemon", "access"], "project": "spring-boot"}
{"id": 709, "code": "\tpublic double optDouble(int index, double fallback) {\n\t\tObject object = opt(index);\n\t\tDouble result = JSON.toDouble(object);\n\t\treturn result != null ? result : fallback;\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index", "if", "it", "exists", "and", "is", "a", "double", "or", "can", "be", "coerced", "to", "a", "double"], "project": "spring-boot"}
{"id": 1444, "code": "\tpublic void setBeanNameGenerator(BeanNameGenerator beanNameGenerator) {\n\t\tthis.reader.setBeanNameGenerator(beanNameGenerator);\n\t\tthis.scanner.setBeanNameGenerator(beanNameGenerator);\n\t\tgetBeanFactory().registerSingleton(AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, beanNameGenerator);\n\t}", "summary_tokens": ["provide", "a", "custom", "bean", "name", "generator", "for", "use", "with", "annotated", "bean", "definition", "reader", "and", "or", "class", "path", "bean", "definition", "scanner", "if", "any"], "project": "spring-boot"}
{"id": 48, "code": "\tpublic String getKey() {\n\t\treturn this.key;\n\t}", "summary_tokens": ["return", "the", "key", "of", "the", "data"], "project": "spring-boot"}
{"id": 252, "code": "\tstatic DatabaseInitializationSettings getSettings(DataSource dataSource, JdbcSessionProperties properties) {\n\t\tDatabaseInitializationSettings settings = new DatabaseInitializationSettings();\n\t\tsettings.setSchemaLocations(resolveSchemaLocations(dataSource, properties));\n\t\tsettings.setMode(properties.getInitializeSchema());\n\t\tsettings.setContinueOnError(true);\n\t\treturn settings;\n\t}", "summary_tokens": ["adapts", "jdbc", "session", "properties", "spring", "session", "jdbc", "properties", "to", "database", "initialization", "settings", "replacing", "any", "placeholders"], "project": "spring-boot"}
{"id": 1382, "code": "\tpublic RestTemplateBuilder requestFactory(Supplier<ClientHttpRequestFactory> requestFactory) {\n\t\tAssert.notNull(requestFactory, \"RequestFactory Supplier must not be null\");\n\t\treturn new RestTemplateBuilder(this.requestFactoryCustomizer, this.detectRequestFactory, this.rootUri,\n\t\t\t\tthis.messageConverters, this.interceptors, requestFactory, this.uriTemplateHandler, this.errorHandler,\n\t\t\t\tthis.basicAuthentication, this.defaultHeaders, this.customizers, this.requestCustomizers);\n\t}", "summary_tokens": ["set", "the", "supplier", "of", "client", "http", "request", "factory", "that", "should", "be", "called", "each", "time", "we", "build", "a", "new", "rest", "template", "instance"], "project": "spring-boot"}
{"id": 1156, "code": "\tpublic ConfigurableApplicationContext getApplicationContext() {\n\t\treturn this.context;\n\t}", "summary_tokens": ["return", "the", "application", "context"], "project": "spring-boot"}
{"id": 11, "code": "\tAccessLevel getAccessLevel(String token, String applicationId) throws CloudFoundryAuthorizationException {\n\t\ttry {\n\t\t\tURI uri = getPermissionsUri(applicationId);\n\t\t\tRequestEntity<?> request = RequestEntity.get(uri).header(\"Authorization\", \"bearer \" + token).build();\n\t\t\tMap<?, ?> body = this.restTemplate.exchange(request, Map.class).getBody();\n\t\t\tif (Boolean.TRUE.equals(body.get(\"read_sensitive_data\"))) {\n\t\t\t\treturn AccessLevel.FULL;\n\t\t\t}\n\t\t\treturn AccessLevel.RESTRICTED;\n\t\t}\n\t\tcatch (HttpClientErrorException ex) {\n\t\t\tif (ex.getStatusCode().equals(HttpStatus.FORBIDDEN)) {\n\t\t\t\tthrow new CloudFoundryAuthorizationException(Reason.ACCESS_DENIED, \"Access denied\");\n\t\t\t}\n\t\t\tthrow new CloudFoundryAuthorizationException(Reason.INVALID_TOKEN, \"Invalid token\", ex);\n\t\t}\n\t\tcatch (HttpServerErrorException ex) {\n\t\t\tthrow new CloudFoundryAuthorizationException(Reason.SERVICE_UNAVAILABLE, \"Cloud controller not reachable\");\n\t\t}\n\t}", "summary_tokens": ["return", "the", "access", "level", "that", "should", "be", "granted", "to", "the", "given", "token"], "project": "spring-boot"}
{"id": 570, "code": "\tvoid apply(ContainerConfig.Update update) {\n\t\tif (this.daemonAccess) {\n\t\t\tupdate.withUser(\"root\");\n\t\t}\n\t\tupdate.withCommand(\"/cnb/lifecycle/\" + this.name, StringUtils.toStringArray(this.args));\n\t\tupdate.withLabel(\"author\", \"spring-boot\");\n\t\tthis.bindings.forEach(update::withBinding);\n\t\tthis.env.forEach(update::withEnv);\n\t\tif (this.networkMode != null) {\n\t\t\tupdate.withNetworkMode(this.networkMode);\n\t\t}\n\t\tthis.securityOptions.forEach(update::withSecurityOption);\n\t}", "summary_tokens": ["apply", "this", "phase", "settings", "to", "a", "container", "config", "update"], "project": "spring-boot"}
{"id": 520, "code": "\tpublic String getOperation() {\n\t\treturn this.operation;\n\t}", "summary_tokens": ["return", "the", "builder", "operation", "that", "failed"], "project": "spring-boot"}
{"id": 627, "code": "\tpublic String getTag() {\n\t\treturn this.tag;\n\t}", "summary_tokens": ["return", "the", "tag", "from", "the", "reference", "or", "null"], "project": "spring-boot"}
{"id": 803, "code": "\tpublic String getGroup() {\n\t\treturn this.group.getOrNull();\n\t}", "summary_tokens": ["returns", "the", "value", "used", "for", "the", "build"], "project": "spring-boot"}
{"id": 1004, "code": "\tpublic File getTestResourcesLocation() {\n\t\tFile testClassesLocation = getTestClassesLocation();\n\t\tif (testClassesLocation.getPath().endsWith(path(\"bin\", \"test\"))\n\t\t\t\t|| testClassesLocation.getPath().endsWith(path(\"bin\", \"intTest\"))) {\n\t\t\treturn testClassesLocation;\n\t\t}\n\t\tif (testClassesLocation.getPath().endsWith(path(\"build\", \"classes\", \"java\", \"test\"))) {\n\t\t\treturn new File(testClassesLocation.getParentFile().getParentFile().getParentFile(), \"resources/test\");\n\t\t}\n\t\tif (testClassesLocation.getPath().endsWith(path(\"build\", \"classes\", \"java\", \"intTest\"))) {\n\t\t\treturn new File(testClassesLocation.getParentFile().getParentFile().getParentFile(), \"resources/intTest\");\n\t\t}\n\t\tthrow new IllegalStateException(\n\t\t\t\t\"Cannot determine test resources location from classes location '\" + testClassesLocation + \"'\");\n\t}", "summary_tokens": ["returns", "the", "location", "into", "which", "test", "resources", "have", "been", "built"], "project": "spring-boot"}
{"id": 1027, "code": "\tstatic void withHook(Hook hook, Runnable action) {\n\t\thooks.get().add(hook);\n\t\ttry {\n\t\t\taction.run();\n\t\t}\n\t\tfinally {\n\t\t\thooks.get().remove(hook);\n\t\t}\n\t}", "summary_tokens": ["runs", "the", "given", "action", "with", "the", "given", "hook", "attached"], "project": "spring-boot"}
{"id": 271, "code": "\tprotected boolean isTraceEnabled(ServerRequest request) {\n\t\treturn getBooleanParameter(request, \"trace\");\n\t}", "summary_tokens": ["check", "whether", "the", "trace", "attribute", "has", "been", "set", "on", "the", "given", "request"], "project": "spring-boot"}
{"id": 361, "code": "\tpublic void setTriggerFilter(FileFilter triggerFilter) {\n\t\tsynchronized (this.monitor) {\n\t\t\tthis.triggerFilter = triggerFilter;\n\t\t}\n\t}", "summary_tokens": ["set", "an", "optional", "file", "filter", "used", "to", "limit", "the", "files", "that", "trigger", "a", "change"], "project": "spring-boot"}
{"id": 1482, "code": "\tpublic String getKeyStoreProvider() {\n\t\treturn this.keyStoreProvider;\n\t}", "summary_tokens": ["return", "the", "provider", "for", "the", "key", "store"], "project": "spring-boot"}
{"id": 542, "code": "\tstatic BuildpackMetadata fromJson(JsonNode node) {\n\t\treturn new BuildpackMetadata(node);\n\t}", "summary_tokens": ["factory", "method", "create", "buildpack", "metadata", "from", "json"], "project": "spring-boot"}
{"id": 1267, "code": "\tpublic String getShortCommitId() {\n\t\tString shortId = get(\"commit.id.abbrev\");\n\t\tif (shortId != null) {\n\t\t\treturn shortId;\n\t\t}\n\t\tString id = getCommitId();\n\t\tif (id == null) {\n\t\t\treturn null;\n\t\t}\n\t\treturn (id.length() > 7) ? id.substring(0, 7) : id;\n\t}", "summary_tokens": ["return", "the", "abbreviated", "id", "of", "the", "commit", "or", "null"], "project": "spring-boot"}
{"id": 700, "code": "\tpublic int length() {\n\t\treturn this.values.size();\n\t}", "summary_tokens": ["returns", "the", "number", "of", "values", "in", "this", "array"], "project": "spring-boot"}
{"id": 1450, "code": "\tdefault Map<String, Object> getErrorAttributes(ServerRequest request, ErrorAttributeOptions options) {\n\t\treturn Collections.emptyMap();\n\t}", "summary_tokens": ["return", "a", "map", "of", "the", "error", "attributes"], "project": "spring-boot"}
{"id": 1347, "code": "\tpublic TaskExecutorBuilder corePoolSize(int corePoolSize) {\n\t\treturn new TaskExecutorBuilder(this.queueCapacity, corePoolSize, this.maxPoolSize, this.allowCoreThreadTimeOut,\n\t\t\t\tthis.keepAlive, this.awaitTermination, this.awaitTerminationPeriod, this.threadNamePrefix,\n\t\t\t\tthis.taskDecorator, this.customizers);\n\t}", "summary_tokens": ["set", "the", "core", "number", "of", "threads"], "project": "spring-boot"}
{"id": 664, "code": "\tString getSourceType() {\n\t\treturn this.sourceType;\n\t}", "summary_tokens": ["the", "class", "name", "of", "the", "source", "that", "contributed", "this", "property"], "project": "spring-boot"}
{"id": 107, "code": "\tprotected Map<String, Object> getNestedMap(Map<String, Object> map, String key) {\n\t\tObject value = map.get(key);\n\t\tif (value == null) {\n\t\t\treturn Collections.emptyMap();\n\t\t}\n\t\treturn (Map<String, Object>) value;\n\t}", "summary_tokens": ["return", "the", "nested", "map", "with", "the", "specified", "key", "or", "empty", "map", "if", "the", "specified", "map", "contains", "no", "mapping", "for", "the", "key"], "project": "spring-boot"}
{"id": 1247, "code": "\tpublic void putAll(Map<?, ?> map) {\n\t\tAssert.notNull(map, \"Map must not be null\");\n\t\tassertNotReadOnlySystemAttributesMap(map);\n\t\tmap.forEach(this::put);\n\t}", "summary_tokens": ["add", "all", "entries", "from", "the", "specified", "map"], "project": "spring-boot"}
{"id": 559, "code": "\tint getMinor() {\n\t\treturn this.minor;\n\t}", "summary_tokens": ["return", "the", "minor", "version", "number"], "project": "spring-boot"}
{"id": 1234, "code": "\tstatic ConfigurationPropertyName of(CharSequence name, boolean returnNullIfInvalid) {\n\t\tElements elements = elementsOf(name, returnNullIfInvalid);\n\t\treturn (elements != null) ? new ConfigurationPropertyName(elements) : null;\n\t}", "summary_tokens": ["return", "a", "configuration", "property", "name", "for", "the", "specified", "string"], "project": "spring-boot"}
{"id": 18, "code": "\tprivate ConditionOutcome getDefaultOutcome(ConditionContext context) {\n\t\tboolean match = Boolean.parseBoolean(context.getEnvironment().getProperty(DEFAULT_PROPERTY_NAME, \"true\"));\n\t\treturn new ConditionOutcome(match, ConditionMessage.forCondition(ConditionalOnEnabledMetricsExport.class)\n\t\t\t\t.because(DEFAULT_PROPERTY_NAME + \" is considered \" + match));\n\t}", "summary_tokens": ["return", "the", "default", "outcome", "that", "should", "be", "used", "if", "property", "is", "not", "set"], "project": "spring-boot"}
{"id": 1168, "code": "\tpublic static BoundConfigurationProperties get(ApplicationContext context) {\n\t\tif (!context.containsBeanDefinition(BEAN_NAME)) {\n\t\t\treturn null;\n\t\t}\n\t\treturn context.getBean(BEAN_NAME, BoundConfigurationProperties.class);\n\t}", "summary_tokens": ["return", "the", "bound", "configuration", "properties", "from", "the", "given", "application", "context", "if", "it", "is", "available"], "project": "spring-boot"}
{"id": 1419, "code": "\tpublic void setTomcatConnectorCustomizers(\n\t\t\tCollection<? extends TomcatConnectorCustomizer> tomcatConnectorCustomizers) {\n\t\tAssert.notNull(tomcatConnectorCustomizers, \"TomcatConnectorCustomizers must not be null\");\n\t\tthis.tomcatConnectorCustomizers = new LinkedHashSet<>(tomcatConnectorCustomizers);\n\t}", "summary_tokens": ["set", "tomcat", "connector", "customizer", "s", "that", "should", "be", "applied", "to", "the", "tomcat", "connector"], "project": "spring-boot"}
{"id": 1595, "code": "\tpublic WebServiceTemplateBuilder setCheckConnectionForFault(boolean checkConnectionForFault) {\n\t\treturn new WebServiceTemplateBuilder(this.detectHttpMessageSender, this.interceptors,\n\t\t\t\tappend(this.internalCustomizers, new CheckConnectionFaultCustomizer(checkConnectionForFault)),\n\t\t\t\tthis.customizers, this.messageSenders, this.marshaller, this.unmarshaller, this.destinationProvider,\n\t\t\t\tthis.transformerFactoryClass, this.messageFactory);\n\t}", "summary_tokens": ["indicates", "whether", "the", "connection", "should", "be", "checked", "for", "fault", "indicators", "true", "or", "whether", "we", "should", "rely", "on", "the", "message", "only", "false"], "project": "spring-boot"}
{"id": 157, "code": "\tpublic String determineVirtualHost() {\n\t\tif (CollectionUtils.isEmpty(this.parsedAddresses)) {\n\t\t\treturn getVirtualHost();\n\t\t}\n\t\tAddress address = this.parsedAddresses.get(0);\n\t\treturn (address.virtualHost != null) ? address.virtualHost : getVirtualHost();\n\t}", "summary_tokens": ["if", "addresses", "have", "been", "set", "and", "the", "first", "address", "has", "a", "virtual", "host", "it", "is", "returned"], "project": "spring-boot"}
{"id": 203, "code": "\tpublic String getUsername() {\n\t\treturn this.username;\n\t}", "summary_tokens": ["return", "the", "configured", "username", "or", "null", "if", "none", "was", "configured"], "project": "spring-boot"}
{"id": 961, "code": "\tURL getUrl() throws MalformedURLException {\n\t\treturn new URL(this.jarFile.getUrl(), getName());\n\t}", "summary_tokens": ["return", "a", "url", "for", "this", "jar", "entry"], "project": "spring-boot"}
{"id": 101, "code": "\tprotected Map<String, Object> generateContent() {\n\t\tMap<String, Object> content = extractContent(toPropertySource());\n\t\tpostProcessContent(content);\n\t\treturn content;\n\t}", "summary_tokens": ["extract", "the", "content", "to", "contribute", "to", "the", "info", "endpoint"], "project": "spring-boot"}
{"id": 939, "code": "\tpublic void setBackupSource(boolean backupSource) {\n\t\tthis.backupSource = backupSource;\n\t}", "summary_tokens": ["sets", "if", "source", "files", "should", "be", "backed", "up", "when", "they", "would", "be", "overwritten"], "project": "spring-boot"}
{"id": 1565, "code": "\tpublic File getDocumentRoot() {\n\t\treturn this.documentRoot.getDirectory();\n\t}", "summary_tokens": ["returns", "the", "document", "root", "which", "will", "be", "used", "by", "the", "web", "context", "to", "serve", "static", "files"], "project": "spring-boot"}
{"id": 618, "code": "\tpublic static ImageArchive from(Image image, IOConsumer<Update> update) throws IOException {\n\t\treturn new Update(image).applyTo(update);\n\t}", "summary_tokens": ["create", "a", "new", "image", "archive", "based", "on", "an", "existing", "image"], "project": "spring-boot"}
{"id": 572, "code": "\tprivate static StackId fromImageConfig(ImageConfig imageConfig) {\n\t\tString value = imageConfig.getLabels().get(LABEL_NAME);\n\t\tAssert.state(StringUtils.hasText(value), () -> \"Missing '\" + LABEL_NAME + \"' stack label\");\n\t\treturn new StackId(value);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "stack", "id", "from", "an", "image", "config"], "project": "spring-boot"}
{"id": 748, "code": "\tpublic JSONArray names() {\n\t\treturn this.nameValuePairs.isEmpty() ? null : new JSONArray(new ArrayList<>(this.nameValuePairs.keySet()));\n\t}", "summary_tokens": ["returns", "an", "array", "containing", "the", "string", "names", "in", "this", "object"], "project": "spring-boot"}
{"id": 901, "code": "\tfinal void run(Deque<String> args) {\n\t\tList<String> parameters = new ArrayList<>();\n\t\tMap<Option, String> options = new HashMap<>();\n\t\twhile (!args.isEmpty()) {\n\t\t\tString arg = args.removeFirst();\n\t\t\tOption option = this.options.find(arg);\n\t\t\tif (option != null) {\n\t\t\t\toptions.put(option, option.claimArg(args));\n\t\t\t}\n\t\t\telse {\n\t\t\t\tparameters.add(arg);\n\t\t\t}\n\t\t}\n\t\trun(options, parameters);\n\t}", "summary_tokens": ["run", "the", "command", "by", "processing", "the", "remaining", "arguments"], "project": "spring-boot"}
{"id": 351, "code": "\tpublic static List<String> getUrls(String path, ClassLoader classLoader) {\n\t\tif (classLoader == null) {\n\t\t\tclassLoader = ClassUtils.getDefaultClassLoader();\n\t\t}\n\t\tpath = StringUtils.cleanPath(path);\n\t\ttry {\n\t\t\treturn getUrlsFromWildcardPath(path, classLoader);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthrow new IllegalArgumentException(\"Cannot create URL from path [\" + path + \"]\", ex);\n\t\t}\n\t}", "summary_tokens": ["return", "urls", "from", "a", "given", "source", "path"], "project": "spring-boot"}
{"id": 1264, "code": "\tpublic Instant getTime() {\n\t\treturn getInstant(\"time\");\n\t}", "summary_tokens": ["return", "the", "timestamp", "of", "the", "build", "or", "null"], "project": "spring-boot"}
{"id": 488, "code": "\tpublic BuildRequest withRunImage(ImageReference runImageName) {\n\t\treturn new BuildRequest(this.name, this.applicationContent, this.builder, runImageName.inTaggedOrDigestForm(),\n\t\t\t\tthis.creator, this.env, this.cleanCache, this.verboseLogging, this.pullPolicy, this.publish,\n\t\t\t\tthis.buildpacks, this.bindings, this.network, this.tags, this.buildCache, this.launchCache);\n\t}", "summary_tokens": ["return", "a", "new", "build", "request", "with", "an", "updated", "run", "image"], "project": "spring-boot"}
{"id": 1432, "code": "\tpublic void addContextLifecycleListeners(LifecycleListener... contextLifecycleListeners) {\n\t\tAssert.notNull(contextLifecycleListeners, \"ContextLifecycleListeners must not be null\");\n\t\tthis.contextLifecycleListeners.addAll(Arrays.asList(contextLifecycleListeners));\n\t}", "summary_tokens": ["add", "lifecycle", "listener", "s", "that", "should", "be", "added", "to", "the", "tomcat", "context"], "project": "spring-boot"}
{"id": 284, "code": "\tdefault RequestMappingHandlerMapping getRequestMappingHandlerMapping() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "custom", "request", "mapping", "handler", "mapping", "that", "should", "be", "used", "and", "processed", "by", "the", "mvc", "configuration"], "project": "spring-boot"}
{"id": 541, "code": "\tstatic BuildpackMetadata fromImageConfig(ImageConfig imageConfig) throws IOException {\n\t\tAssert.notNull(imageConfig, \"ImageConfig must not be null\");\n\t\tString json = imageConfig.getLabels().get(LABEL_NAME);\n\t\tAssert.notNull(json, () -> \"No '\" + LABEL_NAME + \"' label found in image config labels '\"\n\t\t\t\t+ StringUtils.collectionToCommaDelimitedString(imageConfig.getLabels().keySet()) + \"'\");\n\t\treturn fromJson(json);\n\t}", "summary_tokens": ["factory", "method", "to", "extract", "buildpack", "metadata", "from", "image", "config"], "project": "spring-boot"}
{"id": 1596, "code": "\tpublic WebServiceTemplateBuilder setCheckConnectionForError(boolean checkConnectionForError) {\n\t\treturn new WebServiceTemplateBuilder(this.detectHttpMessageSender, this.interceptors,\n\t\t\t\tappend(this.internalCustomizers, new CheckConnectionForErrorCustomizer(checkConnectionForError)),\n\t\t\t\tthis.customizers, this.messageSenders, this.marshaller, this.unmarshaller, this.destinationProvider,\n\t\t\t\tthis.transformerFactoryClass, this.messageFactory);\n\t}", "summary_tokens": ["indicates", "whether", "the", "connection", "should", "be", "checked", "for", "error", "indicators", "true", "or", "whether", "these", "should", "be", "ignored", "false"], "project": "spring-boot"}
{"id": 553, "code": "\tBuilderMetadata getBuilderMetadata() {\n\t\treturn this.builderMetadata;\n\t}", "summary_tokens": ["return", "the", "builder", "meta", "data", "that", "was", "used", "to", "create", "this", "ephemeral", "builder"], "project": "spring-boot"}
{"id": 1573, "code": "\tstatic CookieSameSiteSupplier ofNone() {\n\t\treturn of(SameSite.NONE);\n\t}", "summary_tokens": ["return", "a", "new", "cookie", "same", "site", "supplier", "that", "always", "returns", "same", "site", "none"], "project": "spring-boot"}
{"id": 1406, "code": "\tprotected void configureSsl(SslContextFactory.Server factory, Ssl ssl, SslStoreProvider sslStoreProvider) {\n\t\tfactory.setProtocol(ssl.getProtocol());\n\t\tconfigureSslClientAuth(factory, ssl);\n\t\tconfigureSslPasswords(factory, ssl);\n\t\tfactory.setCertAlias(ssl.getKeyAlias());\n\t\tif (!ObjectUtils.isEmpty(ssl.getCiphers())) {\n\t\t\tfactory.setIncludeCipherSuites(ssl.getCiphers());\n\t\t\tfactory.setExcludeCipherSuites();\n\t\t}\n\t\tif (ssl.getEnabledProtocols() != null) {\n\t\t\tfactory.setIncludeProtocols(ssl.getEnabledProtocols());\n\t\t}\n\t\tif (sslStoreProvider != null) {\n\t\t\ttry {\n\t\t\t\tString keyPassword = sslStoreProvider.getKeyPassword();\n\t\t\t\tif (keyPassword != null) {\n\t\t\t\t\tfactory.setKeyManagerPassword(keyPassword);\n\t\t\t\t}\n\t\t\t\tfactory.setKeyStore(sslStoreProvider.getKeyStore());\n\t\t\t\tfactory.setTrustStore(sslStoreProvider.getTrustStore());\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tthrow new IllegalStateException(\"Unable to set SSL store\", ex);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tconfigureSslKeyStore(factory, ssl);\n\t\t\tconfigureSslTrustStore(factory, ssl);\n\t\t}\n\t}", "summary_tokens": ["configure", "the", "ssl", "connection"], "project": "spring-boot"}
{"id": 950, "code": "\tprotected MainMethodRunner createMainMethodRunner(String mainClass, String[] args, ClassLoader classLoader) {\n\t\treturn new MainMethodRunner(mainClass, args);\n\t}", "summary_tokens": ["create", "the", "main", "method", "runner", "used", "to", "launch", "the", "application"], "project": "spring-boot"}
{"id": 1196, "code": "\tpublic T orElseGet(Supplier<? extends T> other) {\n\t\treturn (this.value != null) ? this.value : other.get();\n\t}", "summary_tokens": ["return", "the", "object", "that", "was", "bound", "or", "the", "result", "of", "invoking", "other", "if", "no", "value", "has", "been", "bound"], "project": "spring-boot"}
{"id": 1555, "code": "\tpublic void setEnvironment(ConfigurableEnvironment environment) {\n\t\tsuper.setEnvironment(environment);\n\t\tthis.reader.setEnvironment(getEnvironment());\n\t}", "summary_tokens": ["p", "delegates", "the", "given", "environment", "to", "underlying", "xml", "bean", "definition", "reader"], "project": "spring-boot"}
{"id": 1526, "code": "\tpublic static boolean isSupportedType(EventListener listener) {\n\t\tfor (Class<?> type : SUPPORTED_TYPES) {\n\t\t\tif (ClassUtils.isAssignableValue(type, listener)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["returns", "true", "if", "the", "specified", "listener", "is", "one", "of", "the", "supported", "types"], "project": "spring-boot"}
{"id": 816, "code": "\tpublic Property<JavaVersion> getTargetJavaVersion() {\n\t\treturn this.targetJavaVersion;\n\t}", "summary_tokens": ["returns", "the", "target", "java", "version", "of", "the", "project", "e"], "project": "spring-boot"}
{"id": 329, "code": "\tpublic boolean isHangup() {\n\t\treturn this.hangup;\n\t}", "summary_tokens": ["flag", "to", "signal", "that", "the", "caller", "can", "or", "should", "hangup"], "project": "spring-boot"}
{"id": 1193, "code": "\tpublic void ifBound(Consumer<? super T> consumer) {\n\t\tAssert.notNull(consumer, \"Consumer must not be null\");\n\t\tif (this.value != null) {\n\t\t\tconsumer.accept(this.value);\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "specified", "consumer", "with", "the", "bound", "value", "or", "do", "nothing", "if", "no", "value", "has", "been", "bound"], "project": "spring-boot"}
{"id": 420, "code": "\tpublic <E> E refresh(E entity) {\n\t\tgetEntityManager().refresh(entity);\n\t\treturn entity;\n\t}", "summary_tokens": ["refresh", "the", "state", "of", "the", "instance", "from", "the", "database", "overwriting", "changes", "made", "to", "the", "entity", "if", "any"], "project": "spring-boot"}
{"id": 83, "code": "\tpublic WebServerNamespace getNamespace() {\n\t\treturn this.namespace;\n\t}", "summary_tokens": ["returns", "the", "web", "server", "namespace", "associated", "with", "this", "path"], "project": "spring-boot"}
{"id": 1033, "code": "\tdefault void ready(ConfigurableApplicationContext context, Duration timeTaken) {\n\t}", "summary_tokens": ["called", "immediately", "before", "the", "run", "method", "finishes", "when", "the", "application", "context", "has", "been", "refreshed", "and", "all", "command", "line", "runner", "command", "line", "runners", "and", "application", "runner", "application", "runners", "have", "been", "called"], "project": "spring-boot"}
{"id": 1093, "code": "\tboolean hasConfigDataOption(ConfigData.Option option) {\n\t\treturn this.configDataOptions.contains(option);\n\t}", "summary_tokens": ["return", "if", "the", "contributor", "has", "a", "specific", "config", "data", "option"], "project": "spring-boot"}
{"id": 517, "code": "\tpublic static BuildRequest forJarFile(ImageReference name, File jarFile) {\n\t\tassertJarFile(jarFile);\n\t\treturn new BuildRequest(name, (owner) -> TarArchive.fromZip(jarFile, owner));\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "new", "build", "request", "from", "a", "jar", "file"], "project": "spring-boot"}
{"id": 509, "code": "\tpublic boolean isPublish() {\n\t\treturn this.publish;\n\t}", "summary_tokens": ["return", "if", "the", "built", "image", "should", "be", "pushed", "to", "a", "registry"], "project": "spring-boot"}
{"id": 946, "code": "\tprotected void postProcessClassPathArchives(List<Archive> archives) throws Exception {\n\t}", "summary_tokens": ["called", "to", "post", "process", "archive", "entries", "before", "they", "are", "used"], "project": "spring-boot"}
{"id": 1529, "code": "\tpublic T getServlet() {\n\t\treturn this.servlet;\n\t}", "summary_tokens": ["return", "the", "servlet", "being", "registered"], "project": "spring-boot"}
{"id": 886, "code": "\tpublic void setApplication(ApplicationSpec spec) {\n\t\tthis.application = spec;\n\t}", "summary_tokens": ["sets", "the", "application", "spec", "that", "controls", "the", "layers", "to", "which", "application", "classes", "are", "resources", "belong"], "project": "spring-boot"}
{"id": 53, "code": "\tprotected boolean isEndpointTypeExposed(Class<?> beanType) {\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "if", "an", "endpoint", "bean", "should", "be", "exposed"], "project": "spring-boot"}
{"id": 1576, "code": "\tstatic CookieSameSiteSupplier of(SameSite sameSite) {\n\t\tAssert.notNull(sameSite, \"SameSite must not be null\");\n\t\treturn (cookie) -> sameSite;\n\t}", "summary_tokens": ["return", "a", "new", "cookie", "same", "site", "supplier", "that", "always", "returns", "the", "given", "same", "site", "value"], "project": "spring-boot"}
{"id": 139, "code": "\tpublic Collection<String> getServletNameMappings() {\n\t\treturn getRegistration().getServletNameMappings();\n\t}", "summary_tokens": ["returns", "the", "servlet", "name", "mappings", "for", "the", "registered", "filter"], "project": "spring-boot"}
{"id": 1592, "code": "\tpublic WebServiceTemplateBuilder additionalInterceptors(Collection<? extends ClientInterceptor> interceptors) {\n\t\tAssert.notNull(interceptors, \"Interceptors must not be null\");\n\t\treturn new WebServiceTemplateBuilder(this.detectHttpMessageSender, append(this.interceptors, interceptors),\n\t\t\t\tthis.internalCustomizers, this.customizers, this.messageSenders, this.marshaller, this.unmarshaller,\n\t\t\t\tthis.destinationProvider, this.transformerFactoryClass, this.messageFactory);\n\t}", "summary_tokens": ["add", "additional", "client", "interceptor", "client", "interceptors", "that", "should", "be", "used", "with", "the", "web", "service", "template"], "project": "spring-boot"}
{"id": 1602, "code": "\tpublic WebServiceTemplateBuilder setDefaultUri(String defaultUri) {\n\t\tAssert.hasText(defaultUri, \"DefaultUri must not be empty\");\n\t\treturn setDestinationProvider(() -> URI.create(defaultUri));\n\t}", "summary_tokens": ["set", "the", "default", "uri", "to", "be", "used", "on", "operations", "that", "do", "not", "have", "a", "uri", "parameter"], "project": "spring-boot"}
{"id": 505, "code": "\tpublic Creator getCreator() {\n\t\treturn this.creator;\n\t}", "summary_tokens": ["return", "the", "creator", "the", "builder", "should", "use"], "project": "spring-boot"}
{"id": 1601, "code": "\tpublic WebServiceTemplateBuilder setTransformerFactoryClass(\n\t\t\tClass<? extends TransformerFactory> transformerFactoryClass) {\n\t\treturn new WebServiceTemplateBuilder(this.detectHttpMessageSender, this.interceptors, this.internalCustomizers,\n\t\t\t\tthis.customizers, this.messageSenders, this.marshaller, this.unmarshaller, this.destinationProvider,\n\t\t\t\ttransformerFactoryClass, this.messageFactory);\n\t}", "summary_tokens": ["set", "the", "transformer", "factory", "implementation", "to", "use"], "project": "spring-boot"}
{"id": 829, "code": "\tpublic void setVerboseLogging(boolean verboseLogging) {\n\t\tthis.verboseLogging = verboseLogging;\n\t}", "summary_tokens": ["sets", "whether", "verbose", "logging", "should", "be", "enabled", "while", "building", "the", "image"], "project": "spring-boot"}
{"id": 1492, "code": "\tdefault String getKeyPassword() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "password", "of", "the", "private", "key", "in", "the", "key", "store"], "project": "spring-boot"}
{"id": 1545, "code": "\tpublic final void register(Class<?>... annotatedClasses) {\n\t\tAssert.notEmpty(annotatedClasses, \"At least one annotated class must be specified\");\n\t\tthis.annotatedClasses.addAll(Arrays.asList(annotatedClasses));\n\t}", "summary_tokens": ["register", "one", "or", "more", "annotated", "classes", "to", "be", "processed"], "project": "spring-boot"}
{"id": 624, "code": "\tpublic static ImageName of(String value) {\n\t\tAssert.hasText(value, \"Value must not be empty\");\n\t\tString domain = parseDomain(value);\n\t\tString path = (domain != null) ? value.substring(domain.length() + 1) : value;\n\t\tAssert.isTrue(Regex.PATH.matcher(path).matches(),\n\t\t\t\t() -> \"Unable to parse name \\\"\" + value + \"\\\". \"\n\t\t\t\t\t\t+ \"Image name must be in the form '[domainHost:port/][path/]name', \"\n\t\t\t\t\t\t+ \"with 'path' and 'name' containing only [a-z0-9][.][_][-]\");\n\t\treturn new ImageName(domain, path);\n\t}", "summary_tokens": ["create", "a", "new", "image", "name", "from", "the", "given", "value"], "project": "spring-boot"}
{"id": 703, "code": "\tpublic Object get(int index) throws JSONException {\n\t\ttry {\n\t\t\tObject value = this.values.get(index);\n\t\t\tif (value == null) {\n\t\t\t\tthrow new JSONException(\"Value at \" + index + \" is null.\");\n\t\t\t}\n\t\t\treturn value;\n\t\t}\n\t\tcatch (IndexOutOfBoundsException e) {\n\t\t\tthrow new JSONException(\"Index \" + index + \" out of range [0..\" + this.values.size() + \")\");\n\t\t}\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index"], "project": "spring-boot"}
{"id": 1420, "code": "\tpublic void addConnectorCustomizers(TomcatConnectorCustomizer... tomcatConnectorCustomizers) {\n\t\tAssert.notNull(tomcatConnectorCustomizers, \"TomcatConnectorCustomizers must not be null\");\n\t\tthis.tomcatConnectorCustomizers.addAll(Arrays.asList(tomcatConnectorCustomizers));\n\t}", "summary_tokens": ["add", "tomcat", "connector", "customizer", "s", "that", "should", "be", "added", "to", "the", "tomcat", "connector"], "project": "spring-boot"}
{"id": 1434, "code": "\tpublic void setProtocol(String protocol) {\n\t\tAssert.hasLength(protocol, \"Protocol must not be empty\");\n\t\tthis.protocol = protocol;\n\t}", "summary_tokens": ["the", "tomcat", "protocol", "to", "use", "when", "create", "the", "connector"], "project": "spring-boot"}
{"id": 155, "code": "\tpublic String determineUsername() {\n\t\tif (CollectionUtils.isEmpty(this.parsedAddresses)) {\n\t\t\treturn this.username;\n\t\t}\n\t\tAddress address = this.parsedAddresses.get(0);\n\t\treturn (address.username != null) ? address.username : this.username;\n\t}", "summary_tokens": ["if", "addresses", "have", "been", "set", "and", "the", "first", "address", "has", "a", "username", "it", "is", "returned"], "project": "spring-boot"}
{"id": 443, "code": "\tprotected JsonContent<T> getJsonContent(String json) {\n\t\treturn new JsonContent<>(getResourceLoadClass(), getType(), json);\n\t}", "summary_tokens": ["factory", "method", "used", "to", "get", "a", "json", "content", "instance", "from", "a", "source", "json", "string"], "project": "spring-boot"}
{"id": 1124, "code": "\tprotected List<String> getFileNames(ClassLoader classLoader) {\n\t\treturn Arrays.asList(StandardConfigDataLocationResolver.DEFAULT_CONFIG_NAMES);\n\t}", "summary_tokens": ["get", "the", "application", "file", "names", "to", "consider"], "project": "spring-boot"}
{"id": 1187, "code": "\tdefault Object onSuccess(ConfigurationPropertyName name, Bindable<?> target, BindContext context, Object result) {\n\t\treturn result;\n\t}", "summary_tokens": ["called", "when", "binding", "of", "an", "element", "ends", "with", "a", "successful", "result"], "project": "spring-boot"}
{"id": 1198, "code": "\tpublic ResolvableType getType() {\n\t\treturn this.type;\n\t}", "summary_tokens": ["return", "the", "type", "of", "the", "item", "to", "bind"], "project": "spring-boot"}
{"id": 837, "code": "\tpublic void buildpacks(List<String> buildpacks) {\n\t\tthis.buildpacks.addAll(buildpacks);\n\t}", "summary_tokens": ["adds", "entries", "to", "the", "buildpacks", "that", "will", "be", "used", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 873, "code": "\tpublic void builderRegistry(Action<DockerRegistrySpec> action) {\n\t\taction.execute(this.builderRegistry);\n\t}", "summary_tokens": ["customizes", "the", "docker", "registry", "spec", "that", "configures", "authentication", "to", "the", "builder", "registry"], "project": "spring-boot"}
{"id": 788, "code": "\tpublic void revert(Class<?> type) throws IOException {\n\t\tAssert.isTrue(getSourceFile(type).exists(), \"Source file for type '\" + type + \"' does not exist\");\n\t\tcopySources(type);\n\t}", "summary_tokens": ["restore", "source", "code", "of", "given", "class", "to", "its", "original", "contents"], "project": "spring-boot"}
{"id": 1441, "code": "\tpublic static ErrorAttributeOptions defaults() {\n\t\treturn of();\n\t}", "summary_tokens": ["create", "an", "error", "attribute", "options", "with", "defaults"], "project": "spring-boot"}
{"id": 595, "code": "\tpublic Stream<Error> stream() {\n\t\treturn this.errors.stream();\n\t}", "summary_tokens": ["returns", "a", "sequential", "stream", "of", "the", "errors"], "project": "spring-boot"}
{"id": 398, "code": "\tpublic static HttpTunnelPayload get(HttpInputMessage message) throws IOException {\n\t\tlong length = message.getHeaders().getContentLength();\n\t\tif (length <= 0) {\n\t\t\treturn null;\n\t\t}\n\t\tString seqHeader = message.getHeaders().getFirst(SEQ_HEADER);\n\t\tAssert.state(StringUtils.hasLength(seqHeader), \"Missing sequence header\");\n\t\ttry (ReadableByteChannel body = Channels.newChannel(message.getBody())) {\n\t\t\tByteBuffer payload = ByteBuffer.allocate((int) length);\n\t\t\twhile (payload.hasRemaining()) {\n\t\t\t\tbody.read(payload);\n\t\t\t}\n\t\t\tpayload.flip();\n\t\t\treturn new HttpTunnelPayload(Long.parseLong(seqHeader), payload);\n\t\t}\n\t}", "summary_tokens": ["return", "the", "http", "tunnel", "payload", "for", "the", "given", "message", "or", "null", "if", "there", "is", "no", "payload"], "project": "spring-boot"}
{"id": 324, "code": "\tpublic void pushPrompt(String prompt) {\n\t\tthis.prompts.push(prompt);\n\t}", "summary_tokens": ["push", "a", "new", "prompt", "to", "be", "used", "by", "the", "shell"], "project": "spring-boot"}
{"id": 899, "code": "\tOptions getOptions() {\n\t\treturn this.options;\n\t}", "summary_tokens": ["return", "options", "that", "this", "command", "accepts"], "project": "spring-boot"}
{"id": 686, "code": "\tpublic String getReason() {\n\t\treturn this.reason;\n\t}", "summary_tokens": ["a", "reason", "why", "the", "related", "property", "is", "deprecated", "if", "any"], "project": "spring-boot"}
{"id": 140, "code": "\tpublic Collection<String> getUrlPatternMappings() {\n\t\treturn getRegistration().getUrlPatternMappings();\n\t}", "summary_tokens": ["returns", "the", "url", "pattern", "mappings", "for", "the", "registered", "filter"], "project": "spring-boot"}
{"id": 547, "code": "\tpublic String getName() {\n\t\treturn \"Spring Boot\";\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "builder", "creator"], "project": "spring-boot"}
{"id": 369, "code": "\tpublic int start() throws IOException {\n\t\tsynchronized (this.monitor) {\n\t\t\tAssert.state(!isStarted(), \"Server already started\");\n\t\t\tlogger.debug(LogMessage.format(\"Starting live reload server on port %s\", this.port));\n\t\t\tthis.serverSocket = new ServerSocket(this.port);\n\t\t\tint localPort = this.serverSocket.getLocalPort();\n\t\t\tthis.listenThread = this.threadFactory.newThread(this::acceptConnections);\n\t\t\tthis.listenThread.setDaemon(true);\n\t\t\tthis.listenThread.setName(\"Live Reload Server\");\n\t\t\tthis.listenThread.start();\n\t\t\treturn localPort;\n\t\t}\n\t}", "summary_tokens": ["start", "the", "livereload", "server", "and", "accept", "incoming", "connections"], "project": "spring-boot"}
{"id": 786, "code": "\tpublic void addSourceCode(Class<?> target, InputStream snippetStream) throws Exception {\n\t\tFile targetFile = getSourceFile(target);\n\t\tString contents = getContents(targetFile);\n\t\tint insertAt = contents.lastIndexOf('}');\n\t\tString additionalSource = FileCopyUtils.copyToString(new InputStreamReader(snippetStream));\n\t\tcontents = contents.substring(0, insertAt) + additionalSource + contents.substring(insertAt);\n\t\tputContents(targetFile, contents);", "summary_tokens": ["add", "source", "code", "at", "the", "end", "of", "file", "just", "before", "last", "target", "the", "target", "snippet", "stream", "the", "snippet", "stream", "exception", "if", "the", "source", "cannot", "be", "added"], "project": "spring-boot"}
{"id": 1087, "code": "\tKind getKind() {\n\t\treturn this.kind;\n\t}", "summary_tokens": ["return", "the", "contributor", "kind"], "project": "spring-boot"}
{"id": 1132, "code": "\tpublic ConfigDataLocation getLocation() {\n\t\treturn this.location;\n\t}", "summary_tokens": ["return", "the", "original", "location", "that", "was", "resolved", "to", "determine", "the", "resource"], "project": "spring-boot"}
{"id": 1094, "code": "\tList<ConfigDataLocation> getImports() {\n\t\treturn (this.properties != null) ? this.properties.getImports() : Collections.emptyList();\n\t}", "summary_tokens": ["return", "any", "imports", "requested", "by", "this", "contributor"], "project": "spring-boot"}
{"id": 1318, "code": "\tpublic void setBootstrapExecutor(AsyncTaskExecutor bootstrapExecutor) {\n\t\tthis.bootstrapExecutor = bootstrapExecutor;\n\t}", "summary_tokens": ["configure", "the", "bootstrap", "executor", "to", "be", "used", "by", "the", "local", "container", "entity", "manager", "factory", "bean"], "project": "spring-boot"}
{"id": 1327, "code": "\tprotected boolean ignoreApplicationContext(ApplicationContext applicationContext) {\n\t\treturn false;\n\t}", "summary_tokens": ["returns", "if", "the", "application", "context", "should", "be", "ignored", "and", "not", "used", "for", "matching"], "project": "spring-boot"}
{"id": 1363, "code": "\tpublic TaskSchedulerBuilder customizers(Iterable<TaskSchedulerCustomizer> customizers) {\n\t\tAssert.notNull(customizers, \"Customizers must not be null\");\n\t\treturn new TaskSchedulerBuilder(this.poolSize, this.awaitTermination, this.awaitTerminationPeriod,\n\t\t\t\tthis.threadNamePrefix, append(null, customizers));\n\t}", "summary_tokens": ["set", "the", "task", "scheduler", "customizer", "task", "scheduler", "customizers", "that", "should", "be", "applied", "to", "the", "thread", "pool", "task", "scheduler"], "project": "spring-boot"}
{"id": 262, "code": "\tpublic DateTimeFormatters timeFormat(String pattern) {\n\t\tthis.timeFormatter = isIso(pattern) ? DateTimeFormatter.ISO_LOCAL_TIME\n\t\t\t\t: (isIsoOffset(pattern) ? DateTimeFormatter.ISO_OFFSET_TIME : formatter(pattern));\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "the", "time", "format", "using", "the", "given", "pattern"], "project": "spring-boot"}
{"id": 1158, "code": "\tpublic Duration getTimeTaken() {\n\t\treturn this.timeTaken;\n\t}", "summary_tokens": ["return", "the", "time", "taken", "for", "the", "application", "to", "be", "ready", "to", "service", "requests", "or", "null", "if", "unknown"], "project": "spring-boot"}
{"id": 1002, "code": "\tpublic <T> T execute(long wait, int maxAttempts, Callable<T> callback) throws Exception {\n\t\tgetLog().debug(\"Waiting for spring application to start...\");\n\t\tfor (int i = 0; i < maxAttempts; i++) {\n\t\t\tT result = callback.call();\n\t\t\tif (result != null) {\n\t\t\t\treturn result;\n\t\t\t}\n\t\t\tString message = \"Spring application is not ready yet, waiting \" + wait + \"ms (attempt \" + (i + 1) + \")\";\n\t\t\tgetLog().debug(message);\n\t\t\tsynchronized (this.lock) {\n\t\t\t\ttry {\n\t\t\t\t\tthis.lock.wait(wait);\n\t\t\t\t}\n\t\t\t\tcatch (InterruptedException ex) {\n\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t\tthrow new IllegalStateException(\"Interrupted while waiting for Spring Boot app to start.\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tthrow new MojoExecutionException(\n\t\t\t\t\"Spring application did not start before the configured timeout (\" + (wait * maxAttempts) + \"ms\");\n\t}", "summary_tokens": ["execute", "a", "task", "retrying", "it", "on", "failure"], "project": "spring-boot"}
{"id": 986, "code": "\tpublic String getBuilder() {\n\t\treturn this.builder;\n\t}", "summary_tokens": ["the", "name", "of", "the", "builder", "image", "to", "use", "to", "create", "the", "image"], "project": "spring-boot"}
{"id": 663, "code": "\tpublic Map<String, ConfigurationMetadataProperty> getProperties() {\n\t\treturn this.properties;\n\t}", "summary_tokens": ["return", "the", "configuration", "metadata", "property", "properties", "defined", "in", "this", "group"], "project": "spring-boot"}
{"id": 1001, "code": "\tstatic JMXConnector connect(int port) throws IOException {\n\t\tString url = \"service:jmx:rmi:///jndi/rmi://127.0.0.1:\" + port + \"/jmxrmi\";\n\t\tJMXServiceURL serviceUrl = new JMXServiceURL(url);\n\t\treturn JMXConnectorFactory.connect(serviceUrl, null);\n\t}", "summary_tokens": ["create", "a", "connector", "for", "an", "javax"], "project": "spring-boot"}
{"id": 1459, "code": "\tprotected final File createTempDir(String prefix) {\n\t\ttry {\n\t\t\tFile tempDir = Files.createTempDirectory(prefix + \".\" + getPort() + \".\").toFile();\n\t\t\ttempDir.deleteOnExit();\n\t\t\treturn tempDir;\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new WebServerException(\n\t\t\t\t\t\"Unable to create tempDir. java.io.tmpdir is set to \" + System.getProperty(\"java.io.tmpdir\"), ex);\n\t\t}\n\t}", "summary_tokens": ["return", "the", "absolute", "temp", "dir", "for", "given", "web", "server"], "project": "spring-boot"}
{"id": 983, "code": "\tvoid setPublishRegistry(DockerRegistry builderRegistry) {\n\t\tthis.publishRegistry = builderRegistry;\n\t}", "summary_tokens": ["sets", "the", "docker", "registry", "that", "configures", "authentication", "to", "the", "publishing", "registry"], "project": "spring-boot"}
{"id": 356, "code": "\tpublic String overview() {\n\t\tint added = 0;\n\t\tint deleted = 0;\n\t\tint modified = 0;\n\t\tfor (ChangedFiles changedFiles : this.changeSet) {\n\t\t\tfor (ChangedFile changedFile : changedFiles) {\n\t\t\t\tType type = changedFile.getType();\n\t\t\t\tif (type == Type.ADD) {\n\t\t\t\t\tadded++;\n\t\t\t\t}\n\t\t\t\telse if (type == Type.DELETE) {\n\t\t\t\t\tdeleted++;\n\t\t\t\t}\n\t\t\t\telse if (type == Type.MODIFY) {\n\t\t\t\t\tmodified++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tint size = added + deleted + modified;\n\t\treturn String.format(\"%s (%s, %s, %s)\", quantityOfUnit(size, \"class path change\"),\n\t\t\t\tquantityOfUnit(added, \"addition\"), quantityOfUnit(deleted, \"deletion\"),\n\t\t\t\tquantityOfUnit(modified, \"modification\"));\n\t}", "summary_tokens": ["return", "an", "overview", "of", "the", "changes", "that", "triggered", "this", "event"], "project": "spring-boot"}
{"id": 1426, "code": "\tpublic List<Connector> getAdditionalTomcatConnectors() {\n\t\treturn this.additionalTomcatConnectors;\n\t}", "summary_tokens": ["returns", "a", "mutable", "collection", "of", "the", "connector", "s", "that", "will", "be", "added", "to", "the", "tomcat"], "project": "spring-boot"}
{"id": 1403, "code": "\tpublic Collection<JettyServerCustomizer> getServerCustomizers() {\n\t\treturn this.jettyServerCustomizers;\n\t}", "summary_tokens": ["returns", "a", "mutable", "collection", "of", "jetty", "jetty", "server", "customizer", "s", "that", "will", "be", "applied", "to", "the", "server", "before", "it", "is", "created"], "project": "spring-boot"}
{"id": 484, "code": "\tstatic BuildLog to(PrintStream out) {\n\t\treturn new PrintStreamBuildLog(out);\n\t}", "summary_tokens": ["factory", "method", "that", "returns", "a", "build", "log", "the", "outputs", "to", "a", "given", "print", "stream"], "project": "spring-boot"}
{"id": 1507, "code": "\tpublic void setAsyncSupported(boolean asyncSupported) {\n\t\tthis.asyncSupported = asyncSupported;\n\t}", "summary_tokens": ["sets", "if", "asynchronous", "operations", "are", "supported", "for", "this", "registration"], "project": "spring-boot"}
{"id": 241, "code": "\tprotected final DataSource getDataSource() {\n\t\treturn this.dataSource;\n\t}", "summary_tokens": ["return", "the", "data", "source"], "project": "spring-boot"}
{"id": 91, "code": "\tdefault Set<HealthEndpointGroup> getAllWithAdditionalPath(WebServerNamespace namespace) {\n\t\tAssert.notNull(namespace, \"Namespace must not be null\");\n\t\tSet<HealthEndpointGroup> filteredGroups = new LinkedHashSet<>();\n\t\tgetNames().stream().map(this::get).filter(\n\t\t\t\t(group) -> group.getAdditionalPath() != null && group.getAdditionalPath().hasNamespace(namespace))\n\t\t\t\t.forEach(filteredGroups::add);\n\t\treturn filteredGroups;\n\t}", "summary_tokens": ["return", "all", "the", "groups", "with", "an", "additional", "path", "on", "the", "specified", "web", "server", "namespace"], "project": "spring-boot"}
{"id": 930, "code": "\tpublic LibraryCoordinates getCoordinates() {\n\t\treturn this.coordinates;\n\t}", "summary_tokens": ["return", "the", "library", "coordinates", "coordinates", "of", "the", "library"], "project": "spring-boot"}
{"id": 881, "code": "\tpublic boolean isIncludeLayerTools() {\n\t\treturn this.includeLayerTools;\n\t}", "summary_tokens": ["returns", "whether", "the", "layer", "tools", "should", "be", "included", "as", "a", "dependency", "in", "the", "layered", "archive"], "project": "spring-boot"}
{"id": 76, "code": "\tpublic Collection<String> getConsumes() {\n\t\treturn Collections.unmodifiableCollection(this.consumes);\n\t}", "summary_tokens": ["returns", "the", "media", "types", "that", "the", "operation", "consumes"], "project": "spring-boot"}
{"id": 150, "code": "\tprotected void setRetryTemplateCustomizers(List<RabbitRetryTemplateCustomizer> retryTemplateCustomizers) {\n\t\tthis.retryTemplateCustomizers = retryTemplateCustomizers;\n\t}", "summary_tokens": ["set", "the", "rabbit", "retry", "template", "customizer", "instances", "to", "use"], "project": "spring-boot"}
{"id": 122, "code": "\tpublic static Tag outcome(ClientResponse response) {\n\t\tOutcome outcome = (response != null) ? Outcome.forStatus(response.statusCode().value()) : Outcome.UNKNOWN;\n\t\treturn outcome.asTag();\n\t}", "summary_tokens": ["creates", "an", "outcome", "tag", "derived", "from", "the", "client", "response", "status", "code", "status", "of", "the", "given", "response"], "project": "spring-boot"}
{"id": 1226, "code": "\tpublic int getNumberOfElements() {\n\t\treturn this.elements.getSize();\n\t}", "summary_tokens": ["return", "the", "total", "number", "of", "elements", "in", "the", "name"], "project": "spring-boot"}
{"id": 925, "code": "\tpublic static Layout forFile(File file) {\n\t\tif (file == null) {\n\t\t\tthrow new IllegalArgumentException(\"File must not be null\");\n\t\t}\n\t\tString lowerCaseFileName = file.getName().toLowerCase(Locale.ENGLISH);\n\t\tif (lowerCaseFileName.endsWith(\".jar\")) {\n\t\t\treturn new Jar();\n\t\t}\n\t\tif (lowerCaseFileName.endsWith(\".war\")) {\n\t\t\treturn new War();\n\t\t}\n\t\tif (file.isDirectory() || lowerCaseFileName.endsWith(\".zip\")) {\n\t\t\treturn new Expanded();\n\t\t}\n\t\tthrow new IllegalStateException(\"Unable to deduce layout for '\" + file + \"'\");\n\t}", "summary_tokens": ["return", "a", "layout", "for", "the", "given", "source", "file"], "project": "spring-boot"}
{"id": 1315, "code": "\tpublic PropertySource<?> getPropertySource() {\n\t\treturn this.propertySource;\n\t}", "summary_tokens": ["return", "the", "origin", "property", "source"], "project": "spring-boot"}
{"id": 166, "code": "\tpublic JobExecution getJobExecution() {\n\t\treturn this.execution;\n\t}", "summary_tokens": ["return", "the", "job", "execution"], "project": "spring-boot"}
{"id": 1176, "code": "\tpublic PropertyMapper alwaysApplyingWhenNonNull() {\n\t\treturn alwaysApplying(this::whenNonNull);\n\t}", "summary_tokens": ["return", "a", "new", "property", "mapper", "instance", "that", "applies", "source", "when", "non", "null", "when", "non", "null", "to", "every", "source"], "project": "spring-boot"}
{"id": 1586, "code": "\tpublic HttpWebServiceMessageSenderBuilder setReadTimeout(Duration readTimeout) {\n\t\tthis.readTimeout = readTimeout;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "read", "timeout"], "project": "spring-boot"}
{"id": 1204, "code": "\tpublic Bindable<T> withAnnotations(Annotation... annotations) {\n\t\treturn new Bindable<>(this.type, this.boxedType, this.value,\n\t\t\t\t(annotations != null) ? annotations : NO_ANNOTATIONS, NO_BIND_RESTRICTIONS);\n\t}", "summary_tokens": ["create", "an", "updated", "bindable", "instance", "with", "the", "specified", "annotations"], "project": "spring-boot"}
{"id": 341, "code": "\tprotected boolean canAdd() {\n\t\treturn true;\n\t}", "summary_tokens": ["strategy", "called", "to", "test", "if", "dependencies", "can", "be", "added"], "project": "spring-boot"}
{"id": 1045, "code": "\tdefault ReadinessState getReadinessState() {\n\t\treturn getState(ReadinessState.class, ReadinessState.REFUSING_TRAFFIC);\n\t}", "summary_tokens": ["return", "the", "readiness", "state", "of", "the", "application"], "project": "spring-boot"}
{"id": 933, "code": "\tpublic boolean isIncluded() {\n\t\treturn this.included;\n\t}", "summary_tokens": ["return", "if", "the", "library", "is", "included", "in", "the", "fat", "jar"], "project": "spring-boot"}
{"id": 311, "code": "\tString getJavaVersion() {\n\t\treturn this.javaVersion;\n\t}", "summary_tokens": ["the", "java", "version", "to", "use", "or", "null", "if", "it", "should", "not", "be", "customized"], "project": "spring-boot"}
{"id": 1233, "code": "\tpublic static boolean isValid(CharSequence name) {\n\t\treturn of(name, true) != null;\n\t}", "summary_tokens": ["returns", "if", "the", "given", "name", "is", "valid"], "project": "spring-boot"}
{"id": 391, "code": "\tpublic void handle(ServerHttpRequest request, ServerHttpResponse response) throws IOException {\n\t\ttry {\n\t\t\tAssert.state(request.getHeaders().getContentLength() > 0, \"No content\");\n\t\t\tObjectInputStream objectInputStream = new ObjectInputStream(request.getBody());\n\t\t\tClassLoaderFiles files = (ClassLoaderFiles) objectInputStream.readObject();\n\t\t\tobjectInputStream.close();\n\t\t\tthis.server.updateAndRestart(files);\n\t\t\tresponse.setStatusCode(HttpStatus.OK);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tlogger.warn(\"Unable to handler restart server HTTP request\", ex);\n\t\t\tresponse.setStatusCode(HttpStatus.INTERNAL_SERVER_ERROR);\n\t\t}\n\t}", "summary_tokens": ["handle", "a", "server", "request"], "project": "spring-boot"}
{"id": 1590, "code": "\tpublic WebServiceTemplateBuilder additionalMessageSenders(\n\t\t\tCollection<? extends WebServiceMessageSender> messageSenders) {\n\t\tAssert.notNull(messageSenders, \"MessageSenders must not be null\");\n\t\treturn new WebServiceTemplateBuilder(this.detectHttpMessageSender, this.interceptors, this.internalCustomizers,\n\t\t\t\tthis.customizers, this.messageSenders.add(messageSenders), this.marshaller, this.unmarshaller,\n\t\t\t\tthis.destinationProvider, this.transformerFactoryClass, this.messageFactory);\n\t}", "summary_tokens": ["add", "additional", "web", "service", "message", "sender", "web", "service", "message", "senders", "that", "should", "be", "used", "with", "the", "web", "service", "template"], "project": "spring-boot"}
{"id": 900, "code": "\tParameters getParameters() {\n\t\treturn this.parameters;\n\t}", "summary_tokens": ["return", "parameters", "that", "this", "command", "accepts"], "project": "spring-boot"}
{"id": 2, "code": "\tprivate List<String> readAutoConfigurationsFile() throws IOException {\n\t\tFile file = findAutoConfigurationImportsFile();\n\t\tif (file == null) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t\ttry (BufferedReader reader = new BufferedReader(new FileReader(file))) {\n\t\t\treturn reader.lines().map(this::stripComment).filter((line) -> !line.isEmpty())\n\t\t\t\t\t.collect(Collectors.toList());\n\t\t}\n\t}", "summary_tokens": ["reads", "auto", "configurations", "from", "meta", "inf", "spring", "org"], "project": "spring-boot"}
{"id": 72, "code": "\tpublic int getStatus() {\n\t\treturn this.status;\n\t}", "summary_tokens": ["returns", "the", "status", "for", "the", "response"], "project": "spring-boot"}
{"id": 957, "code": "\tRandomAccessData getCentralDirectory(RandomAccessData data) {\n\t\tif (this.zip64End != null) {\n\t\t\treturn this.zip64End.getCentralDirectory(data);\n\t\t}\n\t\tlong offset = Bytes.littleEndianValue(this.block, this.offset + 16, 4);\n\t\tlong length = Bytes.littleEndianValue(this.block, this.offset + 12, 4);\n\t\treturn data.getSubsection(offset, length);\n\t}", "summary_tokens": ["return", "the", "bytes", "of", "the", "central", "directory", "based", "on", "the", "offset", "indicated", "in", "this", "record"], "project": "spring-boot"}
{"id": 491, "code": "\tpublic BuildRequest withCleanCache(boolean cleanCache) {\n\t\treturn new BuildRequest(this.name, this.applicationContent, this.builder, this.runImage, this.creator, this.env,\n\t\t\t\tcleanCache, this.verboseLogging, this.pullPolicy, this.publish, this.buildpacks, this.bindings,\n\t\t\t\tthis.network, this.tags, this.buildCache, this.launchCache);\n\t}", "summary_tokens": ["return", "a", "new", "build", "request", "with", "an", "updated", "clean", "cache", "setting"], "project": "spring-boot"}
{"id": 208, "code": "\tvoid setDestinationResolver(DestinationResolver destinationResolver) {\n\t\tthis.destinationResolver = destinationResolver;\n\t}", "summary_tokens": ["set", "the", "destination", "resolver", "to", "use", "or", "null", "if", "no", "destination", "resolver", "should", "be", "associated", "with", "the", "factory", "by", "default"], "project": "spring-boot"}
{"id": 1251, "code": "\tpublic static void throwIfMultipleNonNullValuesIn(Consumer<Map<String, Object>> entries) {\n\t\tMap<String, Object> map = new LinkedHashMap<>();\n\t\tentries.accept(map);\n\t\tSet<String> configuredNames = map.entrySet().stream().filter((entry) -> entry.getValue() != null)\n\t\t\t\t.map(Map.Entry::getKey).collect(Collectors.toCollection(LinkedHashSet::new));\n\t\tif (configuredNames.size() > 1) {\n\t\t\tthrow new MutuallyExclusiveConfigurationPropertiesException(configuredNames, map.keySet());\n\t\t}\n\t}", "summary_tokens": ["throw", "a", "new", "mutually", "exclusive", "configuration", "properties", "exception", "if", "multiple", "non", "null", "values", "are", "defined", "in", "a", "set", "of", "entries"], "project": "spring-boot"}
{"id": 678, "code": "\tpublic String getGroupId() {\n\t\treturn this.groupId;\n\t}", "summary_tokens": ["the", "identifier", "of", "the", "group", "to", "which", "this", "source", "is", "associated"], "project": "spring-boot"}
{"id": 994, "code": "\tpublic boolean isIncludeLayerTools() {\n\t\treturn this.includeLayerTools;\n\t}", "summary_tokens": ["whether", "to", "include", "the", "layer", "tools", "jar"], "project": "spring-boot"}
{"id": 124, "code": "\tpublic static Tag status(ServerWebExchange exchange) {\n\t\tHttpStatusCode status = exchange.getResponse().getStatusCode();\n\t\tif (status == null) {\n\t\t\tstatus = HttpStatus.OK;\n\t\t}\n\t\treturn Tag.of(\"status\", String.valueOf(status.value()));\n\t}", "summary_tokens": ["creates", "a", "status", "tag", "based", "on", "the", "response", "status", "of", "the", "given", "exchange"], "project": "spring-boot"}
{"id": 766, "code": "\tpublic Object nextValue() throws JSONException {\n\t\tint c = nextCleanInternal();\n\t\tswitch (c) {\n\t\t\tcase -1:\n\t\t\t\tthrow syntaxError(\"End of input\");\n\n\t\t\tcase '{':\n\t\t\t\treturn readObject();\n\n\t\t\tcase '[':\n\t\t\t\treturn readArray();\n\n\t\t\tcase '\\'':\n\t\t\tcase '\"':\n\t\t\t\treturn nextString((char) c);\n\n\t\t\tdefault:\n\t\t\t\tthis.pos--;\n\t\t\t\treturn readLiteral();\n\t\t}\n\t}\n\n\tprivate int nextCleanInternal() throws JSONException {\n\t\twhile (this.pos < this.in.length()) {\n\t\t\tint c = this.in.charAt(this.pos++);\n\t\t\tswitch (c) {\n\t\t\t\tcase '\\t':\n\t\t\t\tcase ' ':\n\t\t\t\tcase '\\n':\n\t\t\t\tcase '\\r':\n\t\t\t\t\tcontinue;\n\n\t\t\t\tcase '/':\n\t\t\t\t\tif (this.pos == this.in.length()) {\n\t\t\t\t\t\treturn c;\n\t\t\t\t\t}\n\n\t\t\t\t\tchar peek = this.in.charAt(this.pos);\n\t\t\t\t\tswitch (peek) {\n\t\t\t\t\t\tcase '*':\n\t\t\t\t\t\t\t// skip a /* c-style comment */\n\t\t\t\t\t\t\tthis.pos++;\n\t\t\t\t\t\t\tint commentEnd = this.in.indexOf(\"*/\", this.pos);\n\t\t\t\t\t\t\tif (commentEnd == -1) {\n\t\t\t\t\t\t\t\tthrow syntaxError(\"Unterminated comment\");\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tthis.pos = commentEnd + 2;\n\t\t\t\t\t\t\tcontinue;\n\n\t\t\t\t\t\tcase '/':\n\t\t\t\t\t\t\t// skip a // end-of-line comment\n\t\t\t\t\t\t\tthis.pos++;\n\t\t\t\t\t\t\tskipToEndOfLine();\n\t\t\t\t\t\t\tcontinue;\n\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treturn c;\n\t\t\t\t\t}\n\n\t\t\t\tcase '#':\n\t\t\t\t\t/*\n\t\t\t\t\t * Skip a # hash end-of-line comment. The JSON RFC doesn't specify\n\t\t\t\t\t * this behavior, but it's required to parse existing documents. See\n\t\t\t\t\t * https://b/2571423.\n\t\t\t\t\t */\n\t\t\t\t\tskipToEndOfLine();\n\t\t\t\t\tcontinue;\n\n\t\t\t\tdefault:\n\t\t\t\t\treturn c;\n\t\t\t}\n\t\t}\n\n\t\treturn -1;\n\t}\n\n\t/**\n\t * Advances the position until after the next newline character. If the line is\n\t * terminated by \"\\r\\n\", the '\\n' must be consumed as whitespace by the caller.\n\t */\n\tprivate void skipToEndOfLine() {\n\t\tfor (; this.pos < this.in.length(); this.pos++) {\n\t\t\tchar c = this.in.charAt(this.pos);\n\t\t\tif (c == '\\r' || c == '\\n') {\n\t\t\t\tthis.pos++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Returns the string up to but not including {@code quote}, unescaping any character\n\t * escape sequences encountered along the way. The opening quote should have already\n\t * been read. This consumes the closing quote, but does not include it in the returned\n\t * string.\n\t * @param quote either ' or \".\n\t * @return the string up to but not including {@code quote}\n\t * @throws NumberFormatException if any unicode escape sequences are malformed.\n\t * @throws JSONException if processing of json failed\n\t */\n\tpublic String nextString(char quote) throws JSONException {\n\t\t\n\t\tStringBuilder builder = null;\n\n\t\t\n\t\tint start = this.pos;\n\n\t\twhile (this.pos < this.in.length()) {\n\t\t\tint c = this.in.charAt(this.pos++);\n\t\t\tif (c == quote) {\n\t\t\t\tif (builder == null) {\n\t\t\t\t\t\n\t\t\t\t\treturn new String(this.in.substring(start, this.pos - 1));\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbuilder.append(this.in, start, this.pos - 1);\n\t\t\t\t\treturn builder.toString();\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (c == '\\\\') {\n\t\t\t\tif (this.pos == this.in.length()) {\n\t\t\t\t\tthrow syntaxError(\"Unterminated escape sequence\");\n\t\t\t\t}\n\t\t\t\tif (builder == null) {\n\t\t\t\t\tbuilder = new StringBuilder();\n\t\t\t\t}\n\t\t\t\tbuilder.append(this.in, start, this.pos - 1);\n\t\t\t\tbuilder.append(readEscapeCharacter());\n\t\t\t\tstart = this.pos;\n\t\t\t}\n\t\t}\n\n\t\tthrow syntaxError(\"Unterminated string\");\n\t}\n\n\t\n\tprivate char readEscapeCharacter() throws JSONException {\n\t\tchar escaped = this.in.charAt(this.pos++);\n\t\tswitch (escaped) {\n\t\t\tcase 'u':\n\t\t\t\tif (this.pos + 4 > this.in.length()) {\n\t\t\t\t\tthrow syntaxError(\"Unterminated escape sequence\");\n\t\t\t\t}\n\t\t\t\tString hex = this.in.substring(this.pos, this.pos + 4);\n\t\t\t\tthis.pos += 4;\n\t\t\t\treturn (char) Integer.parseInt(hex, 16);\n\n\t\t\tcase 't':\n\t\t\t\treturn '\\t';\n\n\t\t\tcase 'b':\n\t\t\t\treturn '\\b';\n\n\t\t\tcase 'n':\n\t\t\t\treturn '\\n';\n\n\t\t\tcase 'r':\n\t\t\t\treturn '\\r';\n\n\t\t\tcase 'f':\n\t\t\t\treturn '\\f';\n\n\t\t\tcase '\\'':\n\t\t\tcase '\"':\n\t\t\tcase '\\\\':\n\t\t\tdefault:\n\t\t\t\treturn escaped;\n\t\t}\n\t}\n\n\t/**\n\t * Reads a null, boolean, numeric or unquoted string literal value. Numeric values\n\t * will be returned as an Integer, Long, or Double, in that order of preference.\n\t * @return a literal value\n\t * @throws JSONException if processing of json failed\n\t */\n\tprivate Object readLiteral() throws JSONException {\n\t\tString literal = nextToInternal(\"{}[]/\\\\:,=;# \\t\\f\");\n\n\t\tif (literal.isEmpty()) {\n\t\t\tthrow syntaxError(\"Expected literal value\");\n\t\t}\n\t\telse if (\"null\".equalsIgnoreCase(literal)) {\n\t\t\treturn JSONObject.NULL;\n\t\t}\n\t\telse if (\"true\".equalsIgnoreCase(literal)) {\n\t\t\treturn Boolean.TRUE;\n\t\t}\n\t\telse if (\"false\".equalsIgnoreCase(literal)) {\n\t\t\treturn Boolean.FALSE;\n\t\t}\n\n\t\t/* try to parse as an integral type... */\n\t\tif (literal.indexOf('.') == -1) {\n\t\t\tint base = 10;\n\t\t\tString number = literal;\n\t\t\tif (number.startsWith(\"0x\") || number.startsWith(\"0X\")) {\n\t\t\t\tnumber = number.substring(2);\n\t\t\t\tbase = 16;\n\t\t\t}\n\t\t\telse if (number.startsWith(\"0\") && number.length() > 1) {\n\t\t\t\tnumber = number.substring(1);\n\t\t\t\tbase = 8;\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tlong longValue = Long.parseLong(number, base);\n\t\t\t\tif (longValue <= Integer.MAX_VALUE && longValue >= Integer.MIN_VALUE) {\n\t\t\t\t\treturn (int) longValue;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn longValue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (NumberFormatException e) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\n\t\t\n\t\ttry {\n\t\t\treturn Double.valueOf(literal);\n\t\t}\n\t\tcatch (NumberFormatException ignored) {\n\t\t}\n\n\t\t\n\t\treturn new String(literal); \n\t}\n\n\t\n\tprivate String nextToInternal(String excluded) {\n\t\tint start = this.pos;\n\t\tfor (; this.pos < this.in.length(); this.pos++) {\n\t\t\tchar c = this.in.charAt(this.pos);\n\t\t\tif (c == '\\r' || c == '\\n' || excluded.indexOf(c) != -1) {\n\t\t\t\treturn this.in.substring(start, this.pos);\n\t\t\t}\n\t\t}\n\t\treturn this.in.substring(start);\n\t}\n\n\t/**\n\t * Reads a sequence of key/value pairs and the trailing closing brace '}' of an", "summary_tokens": ["returns", "the", "next", "value", "from", "the", "input"], "project": "spring-boot"}
{"id": 388, "code": "\tprotected final SourceDirectory getOrCreateSourceDirectory(String name) {\n\t\tSourceDirectory sourceDirectory = this.sourceDirectories.get(name);\n\t\tif (sourceDirectory == null) {\n\t\t\tsourceDirectory = new SourceDirectory(name);\n\t\t\tthis.sourceDirectories.put(name, sourceDirectory);\n\t\t}\n\t\treturn sourceDirectory;\n\t}", "summary_tokens": ["get", "or", "create", "a", "source", "directory", "with", "the", "given", "name"], "project": "spring-boot"}
{"id": 969, "code": "\tprotected RunArguments resolveApplicationArguments() {\n\t\tRunArguments runArguments = (this.arguments != null) ? new RunArguments(this.arguments)\n\t\t\t\t: new RunArguments(this.commandlineArguments);\n\t\taddActiveProfileArgument(runArguments);\n\t\treturn runArguments;\n\t}", "summary_tokens": ["resolve", "the", "application", "arguments", "to", "use"], "project": "spring-boot"}
{"id": 22, "code": "\tpublic String getApiTokenOrThrow() {\n\t\tif (this.apiToken == null && !usesProxy()) {\n\t\t\tthrow new InvalidConfigurationPropertyValueException(\"management.wavefront.api-token\", null,\n\t\t\t\t\t\"This property is mandatory whenever publishing directly to the Wavefront API\");\n\t\t}\n\t\treturn this.apiToken;\n\t}", "summary_tokens": ["returns", "the", "api", "token", "or", "throws", "an", "exception", "if", "the", "api", "token", "is", "mandatory"], "project": "spring-boot"}
{"id": 567, "code": "\tvoid withNetworkMode(String networkMode) {\n\t\tthis.networkMode = networkMode;\n\t}", "summary_tokens": ["update", "this", "phase", "with", "the", "network", "the", "build", "container", "will", "connect", "to"], "project": "spring-boot"}
{"id": 16, "code": "\tpublic static ServiceLevelObjectiveBoundary valueOf(String value) {\n\t\treturn new ServiceLevelObjectiveBoundary(MeterValue.valueOf(value));\n\t}", "summary_tokens": ["return", "a", "new", "service", "level", "objective", "boundary", "instance", "for", "the", "given", "string", "value"], "project": "spring-boot"}
{"id": 1546, "code": "\tpublic final void scan(String... basePackages) {\n\t\tAssert.notEmpty(basePackages, \"At least one base package must be specified\");\n\t\tthis.basePackages = basePackages;\n\t}", "summary_tokens": ["perform", "a", "scan", "within", "the", "specified", "base", "packages"], "project": "spring-boot"}
{"id": 266, "code": "\tpublic void setMessageWriters(List<HttpMessageWriter<?>> messageWriters) {\n\t\tAssert.notNull(messageWriters, \"'messageWriters' must not be null\");\n\t\tthis.messageWriters = messageWriters;\n\t}", "summary_tokens": ["configure", "http", "message", "writers", "to", "serialize", "the", "response", "body", "with"], "project": "spring-boot"}
{"id": 321, "code": "\tprotected ExitStatus run(OptionSet options) throws Exception {\n\t\treturn ExitStatus.OK;\n\t}", "summary_tokens": ["run", "the", "command", "using", "the", "specified", "parsed", "option", "set"], "project": "spring-boot"}
{"id": 345, "code": "\tpublic String getArtifactId() {\n\t\treturn this.artifactId;\n\t}", "summary_tokens": ["return", "the", "dependency", "artifact", "id"], "project": "spring-boot"}
{"id": 1142, "code": "\tpublic ConfigurationPropertyName getReplacement() {\n\t\treturn this.replacement;\n\t}", "summary_tokens": ["return", "the", "replacement", "property", "that", "should", "be", "used", "instead", "or", "null", "if", "not", "replacement", "is", "available"], "project": "spring-boot"}
{"id": 870, "code": "\tprivate static <T> Callable<T> callTo(Callable<T> callable) {\n\t\treturn callable;\n\t}", "summary_tokens": ["syntactic", "sugar", "that", "makes", "copy", "spec", "from", "calls", "a", "little", "easier", "to", "read"], "project": "spring-boot"}
{"id": 468, "code": "\tpublic <T> TestPropertyValues and(Stream<T> stream, Function<T, Pair> mapper) {\n\t\tif (stream == null) {\n\t\t\treturn this;\n\t\t}\n\t\tMap<String, Object> properties = new LinkedHashMap<>(this.properties);\n\t\tstream.map(mapper).filter(Objects::nonNull).forEach((pair) -> pair.addTo(properties));\n\t\treturn new TestPropertyValues(properties);\n\t}", "summary_tokens": ["return", "a", "new", "test", "property", "values", "instance", "with", "additional", "entries"], "project": "spring-boot"}
{"id": 224, "code": "\tvoid setTransactionManager(KafkaAwareTransactionManager<Object, Object> transactionManager) {\n\t\tthis.transactionManager = transactionManager;\n\t}", "summary_tokens": ["set", "the", "kafka", "aware", "transaction", "manager", "to", "use"], "project": "spring-boot"}
{"id": 240, "code": "\tprotected final JpaProperties getProperties() {\n\t\treturn this.properties;\n\t}", "summary_tokens": ["return", "the", "jpa", "properties"], "project": "spring-boot"}
{"id": 496, "code": "\tpublic BuildRequest withBindings(List<Binding> bindings) {\n\t\tAssert.notNull(bindings, \"Bindings must not be null\");\n\t\treturn new BuildRequest(this.name, this.applicationContent, this.builder, this.runImage, this.creator, this.env,\n\t\t\t\tthis.cleanCache, this.verboseLogging, this.pullPolicy, this.publish, this.buildpacks, bindings,\n\t\t\t\tthis.network, this.tags, this.buildCache, this.launchCache);\n\t}", "summary_tokens": ["return", "a", "new", "build", "request", "with", "updated", "bindings"], "project": "spring-boot"}
{"id": 389, "code": "\tpublic Collection<SourceDirectory> getSourceDirectories() {\n\t\treturn Collections.unmodifiableCollection(this.sourceDirectories.values());\n\t}", "summary_tokens": ["return", "all", "source", "directory", "source", "directories", "that", "have", "been", "added", "to", "the", "collection"], "project": "spring-boot"}
{"id": 897, "code": "\tString getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "this", "command"], "project": "spring-boot"}
{"id": 33, "code": "\tprotected AvailabilityState getState(ApplicationAvailability applicationAvailability) {\n\t\treturn applicationAvailability.getState(this.stateType);\n\t}", "summary_tokens": ["return", "the", "current", "availability", "state"], "project": "spring-boot"}
{"id": 504, "code": "\tpublic ImageReference getRunImage() {\n\t\treturn this.runImage;\n\t}", "summary_tokens": ["return", "the", "run", "image", "that", "should", "be", "used", "if", "provided"], "project": "spring-boot"}
{"id": 35, "code": "\tpublic CacheEntry cache(@Selector String cache, @Nullable String cacheManager) {\n\t\treturn extractUniqueCacheEntry(cache, getCacheEntries((name) -> name.equals(cache), isNameMatch(cacheManager)));\n\t}", "summary_tokens": ["return", "a", "cache", "descriptor", "for", "the", "specified", "cache"], "project": "spring-boot"}
{"id": 734, "code": "\tpublic double getDouble(String name) throws JSONException {\n\t\tObject object = get(name);\n\t\tDouble result = JSON.toDouble(object);\n\t\tif (result == null) {\n\t\t\tthrow JSON.typeMismatch(name, object, \"double\");\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["returns", "the", "value", "mapped", "by", "name", "if", "it", "exists", "and", "is", "a", "double", "or", "can", "be", "coerced", "to", "a", "double"], "project": "spring-boot"}
{"id": 683, "code": "\tpublic String getSourceMethod() {\n\t\treturn this.sourceMethod;\n\t}", "summary_tokens": ["the", "method", "name", "that", "defines", "this", "source", "if", "any"], "project": "spring-boot"}
{"id": 406, "code": "\tpublic void setLongPollTimeout(int longPollTimeout) {\n\t\tAssert.isTrue(longPollTimeout > 0, \"LongPollTimeout must be a positive value\");\n\t\tthis.longPollTimeout = longPollTimeout;\n\t}", "summary_tokens": ["set", "the", "long", "poll", "timeout", "for", "the", "server"], "project": "spring-boot"}
{"id": 41, "code": "\tpublic String getReason() {\n\t\treturn this.reason;\n\t}", "summary_tokens": ["return", "the", "reason", "explaining", "why", "the", "request", "is", "invalid", "potentially", "null"], "project": "spring-boot"}
{"id": 821, "code": "\tpublic String getRunImage() {\n\t\treturn this.runImage;\n\t}", "summary_tokens": ["returns", "the", "run", "image", "that", "will", "be", "included", "in", "the", "built", "image"], "project": "spring-boot"}
{"id": 907, "code": "\tpublic void writeIndexFile(String location, Collection<String> lines) throws IOException {\n\t\tif (location != null) {\n\t\t\tJarArchiveEntry entry = new JarArchiveEntry(location);\n\t\t\twriteEntry(entry, (outputStream) -> {\n\t\t\t\tBufferedWriter writer = new BufferedWriter(\n\t\t\t\t\t\tnew OutputStreamWriter(outputStream, StandardCharsets.UTF_8));\n\t\t\t\tfor (String line : lines) {\n\t\t\t\t\twriter.write(line);\n\t\t\t\t\twriter.write(\"\\n\");\n\t\t\t\t}\n\t\t\t\twriter.flush();\n\t\t\t});\n\t\t}\n\t}", "summary_tokens": ["write", "a", "simple", "index", "file", "containing", "the", "specified", "utf", "0", "lines"], "project": "spring-boot"}
{"id": 1549, "code": "\tprivate org.springframework.boot.web.servlet.ServletContextInitializer getSelfInitializer() {\n\t\treturn this::selfInitialize;\n\t}", "summary_tokens": ["returns", "the", "servlet", "context", "initializer", "that", "will", "be", "used", "to", "complete", "the", "setup", "of", "this", "web", "application", "context"], "project": "spring-boot"}
{"id": 1567, "code": "\tprotected final ServletContextInitializer[] mergeInitializers(ServletContextInitializer... initializers) {\n\t\tList<ServletContextInitializer> mergedInitializers = new ArrayList<>();\n\t\tmergedInitializers.add((servletContext) -> this.initParameters.forEach(servletContext::setInitParameter));\n\t\tmergedInitializers.add(new SessionConfiguringInitializer(this.session));\n\t\tmergedInitializers.addAll(Arrays.asList(initializers));\n\t\tmergedInitializers.addAll(this.initializers);\n\t\treturn mergedInitializers.toArray(new ServletContextInitializer[0]);\n\t}", "summary_tokens": ["utility", "method", "that", "can", "be", "used", "by", "subclasses", "wishing", "to", "combine", "the", "specified", "servlet", "context", "initializer", "parameters", "with", "those", "defined", "in", "this", "instance"], "project": "spring-boot"}
{"id": 958, "code": "\tint getNumberOfRecords() {\n\t\tif (this.zip64End != null) {\n\t\t\treturn this.zip64End.getNumberOfRecords();\n\t\t}\n\t\tlong numberOfRecords = Bytes.littleEndianValue(this.block, this.offset + 10, 2);\n\t\treturn (int) numberOfRecords;\n\t}", "summary_tokens": ["return", "the", "number", "of", "zip", "entries", "in", "the", "file"], "project": "spring-boot"}
{"id": 1098, "code": "\tpublic Iterator<ConfigDataEnvironmentContributor> iterator() {\n\t\treturn new ContributorIterator();\n\t}", "summary_tokens": ["returns", "an", "iterator", "that", "traverses", "this", "contributor", "and", "all", "its", "children", "in", "priority", "order"], "project": "spring-boot"}
{"id": 38, "code": "\tpublic String toLowerCaseString() {\n\t\treturn this.lowerCaseValue;\n\t}", "summary_tokens": ["return", "a", "lower", "case", "version", "of", "the", "endpoint", "id"], "project": "spring-boot"}
{"id": 342, "code": "\tpublic DependencyResolutionContext getDependencyResolutionContext() {\n\t\treturn this.dependencyResolutionContext;\n\t}", "summary_tokens": ["returns", "the", "dependency", "resolution", "context"], "project": "spring-boot"}
{"id": 151, "code": "\tpublic void configure(RabbitConnectionFactoryBean factory) {\n\t\tAssert.notNull(factory, \"RabbitConnectionFactoryBean must not be null\");\n\t\tfactory.setResourceLoader(this.resourceLoader);\n\t\tPropertyMapper map = PropertyMapper.get();\n\t\tmap.from(this.rabbitProperties::determineHost).whenNonNull().to(factory::setHost);\n\t\tmap.from(this.rabbitProperties::determinePort).to(factory::setPort);\n\t\tmap.from(this.rabbitProperties::determineUsername).whenNonNull().to(factory::setUsername);\n\t\tmap.from(this.rabbitProperties::determinePassword).whenNonNull().to(factory::setPassword);\n\t\tmap.from(this.rabbitProperties::determineVirtualHost).whenNonNull().to(factory::setVirtualHost);\n\t\tmap.from(this.rabbitProperties::getRequestedHeartbeat).whenNonNull().asInt(Duration::getSeconds)\n\t\t\t\t.to(factory::setRequestedHeartbeat);\n\t\tmap.from(this.rabbitProperties::getRequestedChannelMax).to(factory::setRequestedChannelMax);\n\t\tRabbitProperties.Ssl ssl = this.rabbitProperties.getSsl();\n\t\tif (ssl.determineEnabled()) {\n\t\t\tfactory.setUseSSL(true);\n\t\t\tmap.from(ssl::getAlgorithm).whenNonNull().to(factory::setSslAlgorithm);\n\t\t\tmap.from(ssl::getKeyStoreType).to(factory::setKeyStoreType);\n\t\t\tmap.from(ssl::getKeyStore).to(factory::setKeyStore);\n\t\t\tmap.from(ssl::getKeyStorePassword).to(factory::setKeyStorePassphrase);\n\t\t\tmap.from(ssl::getKeyStoreAlgorithm).whenNonNull().to(factory::setKeyStoreAlgorithm);\n\t\t\tmap.from(ssl::getTrustStoreType).to(factory::setTrustStoreType);\n\t\t\tmap.from(ssl::getTrustStore).to(factory::setTrustStore);\n\t\t\tmap.from(ssl::getTrustStorePassword).to(factory::setTrustStorePassphrase);\n\t\t\tmap.from(ssl::getTrustStoreAlgorithm).whenNonNull().to(factory::setTrustStoreAlgorithm);\n\t\t\tmap.from(ssl::isValidateServerCertificate)\n\t\t\t\t\t.to((validate) -> factory.setSkipServerCertificateValidation(!validate));\n\t\t\tmap.from(ssl::getVerifyHostname).to(factory::setEnableHostnameVerification);\n\t\t}\n\t\tmap.from(this.rabbitProperties::getConnectionTimeout).whenNonNull().asInt(Duration::toMillis)\n\t\t\t\t.to(factory::setConnectionTimeout);\n\t\tmap.from(this.rabbitProperties::getChannelRpcTimeout).whenNonNull().asInt(Duration::toMillis)\n\t\t\t\t.to(factory::setChannelRpcTimeout);\n\t\tmap.from(this.credentialsProvider).whenNonNull().to(factory::setCredentialsProvider);\n\t\tmap.from(this.credentialsRefreshService).whenNonNull().to(factory::setCredentialsRefreshService);\n\t}", "summary_tokens": ["configure", "the", "specified", "rabbit", "connection", "factory", "bean"], "project": "spring-boot"}
{"id": 357, "code": "\tpublic void setStopWatcherOnRestart(boolean stopWatcherOnRestart) {\n\t\tthis.stopWatcherOnRestart = stopWatcherOnRestart;\n\t}", "summary_tokens": ["set", "if", "the", "file", "system", "watcher", "should", "be", "stopped", "when", "a", "full", "restart", "occurs"], "project": "spring-boot"}
{"id": 1044, "code": "\tdefault LivenessState getLivenessState() {\n\t\treturn getState(LivenessState.class, LivenessState.BROKEN);\n\t}", "summary_tokens": ["return", "the", "liveness", "state", "of", "the", "application"], "project": "spring-boot"}
{"id": 1174, "code": "\tprivate boolean isNestedType(String propertyName, Class<?> propertyType) {\n\t\tif (this.type.equals(propertyType.getDeclaringClass())) {\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\tField field = ReflectionUtils.findField(this.type, propertyName);\n\t\t\treturn field != null && MergedAnnotations.from(field).isPresent(NestedConfigurationProperty.class);\n\t\t}\n\t}", "summary_tokens": ["specify", "whether", "the", "specified", "property", "refer", "to", "a", "nested", "type"], "project": "spring-boot"}
{"id": 628, "code": "\tpublic String getDigest() {\n\t\treturn this.digest;\n\t}", "summary_tokens": ["return", "the", "digest", "from", "the", "reference", "or", "null"], "project": "spring-boot"}
{"id": 1484, "code": "\tpublic String getTrustStorePassword() {\n\t\treturn this.trustStorePassword;\n\t}", "summary_tokens": ["return", "the", "password", "used", "to", "access", "the", "trust", "store"], "project": "spring-boot"}
{"id": 1205, "code": "\tpublic Bindable<T> withExistingValue(T existingValue) {\n\t\tAssert.isTrue(\n\t\t\t\texistingValue == null || this.type.isArray() || this.boxedType.resolve().isInstance(existingValue),\n\t\t\t\t() -> \"ExistingValue must be an instance of \" + this.type);\n\t\tSupplier<T> value = (existingValue != null) ? () -> existingValue : null;\n\t\treturn new Bindable<>(this.type, this.boxedType, value, this.annotations, this.bindRestrictions);\n\t}", "summary_tokens": ["create", "an", "updated", "bindable", "instance", "with", "an", "existing", "value"], "project": "spring-boot"}
{"id": 1501, "code": "\tpublic Collection<String> getUrlPatterns() {\n\t\treturn this.urlPatterns;\n\t}", "summary_tokens": ["return", "a", "mutable", "collection", "of", "url", "patterns", "as", "defined", "in", "the", "servlet", "specification", "that", "the", "filter", "will", "be", "registered", "against"], "project": "spring-boot"}
{"id": 135, "code": "\tpublic final void sendingResponse(HttpTrace trace, TraceableResponse response, Supplier<Principal> principal,\n\t\t\tSupplier<String> sessionId) {\n\t\tsetIfIncluded(Include.TIME_TAKEN, () -> calculateTimeTaken(trace), trace::setTimeTaken);\n\t\tsetIfIncluded(Include.SESSION_ID, sessionId, trace::setSessionId);\n\t\tsetIfIncluded(Include.PRINCIPAL, principal, trace::setPrincipal);\n\t\ttrace.setResponse(new HttpTrace.Response(new FilteredTraceableResponse(response)));\n\t}", "summary_tokens": ["ends", "the", "tracing", "of", "the", "exchange", "that", "is", "being", "concluded", "by", "sending", "the", "given", "response"], "project": "spring-boot"}
{"id": 596, "code": "\tpublic boolean isEmpty() {\n\t\treturn this.errors.isEmpty();\n\t}", "summary_tokens": ["return", "if", "there", "are", "any", "contained", "errors"], "project": "spring-boot"}
{"id": 479, "code": "\tvoid assertSupports(ApiVersion other) {\n\t\tif (!supports(other)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Detected platform API version '\" + other + \"' does not match supported version '\" + this + \"'\");\n\t\t}\n\t}", "summary_tokens": ["assert", "that", "this", "api", "version", "supports", "the", "specified", "version"], "project": "spring-boot"}
{"id": 1297, "code": "\tpublic static LogFile get(PropertyResolver propertyResolver) {\n\t\tString file = propertyResolver.getProperty(FILE_NAME_PROPERTY);\n\t\tString path = propertyResolver.getProperty(FILE_PATH_PROPERTY);\n\t\tif (StringUtils.hasLength(file) || StringUtils.hasLength(path)) {\n\t\t\treturn new LogFile(file, path);\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["get", "a", "log", "file", "from", "the", "given", "spring", "environment"], "project": "spring-boot"}
{"id": 1059, "code": "\tpublic SpringApplicationBuilder logStartupInfo(boolean logStartupInfo) {\n\t\tthis.application.setLogStartupInfo(logStartupInfo);\n\t\treturn this;\n\t}", "summary_tokens": ["flag", "to", "indicate", "the", "startup", "information", "should", "be", "logged"], "project": "spring-boot"}
{"id": 919, "code": "\tstatic InputStreamSupplier forFile(File file) {\n\t\treturn () -> new FileInputStream(file);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "an", "input", "stream", "supplier", "for", "the", "given", "file"], "project": "spring-boot"}
{"id": 1341, "code": "\tpublic Charset getEncoding() {\n\t\treturn this.encoding;\n\t}", "summary_tokens": ["returns", "the", "encoding", "to", "use", "when", "reading", "the", "schema", "and", "data", "scripts"], "project": "spring-boot"}
{"id": 1554, "code": "\tpublic void setValidating(boolean validating) {\n\t\tthis.reader.setValidating(validating);\n\t}", "summary_tokens": ["set", "whether", "to", "use", "xml", "validation"], "project": "spring-boot"}
{"id": 154, "code": "\tpublic String determineAddresses() {\n\t\tif (CollectionUtils.isEmpty(this.parsedAddresses)) {\n\t\t\treturn this.host + \":\" + determinePort();\n\t\t}\n\t\tList<String> addressStrings = new ArrayList<>();\n\t\tfor (Address parsedAddress : this.parsedAddresses) {\n\t\t\taddressStrings.add(parsedAddress.host + \":\" + parsedAddress.port);\n\t\t}\n\t\treturn StringUtils.collectionToCommaDelimitedString(addressStrings);\n\t}", "summary_tokens": ["returns", "the", "comma", "separated", "addresses", "or", "a", "single", "address", "host", "port", "created", "from", "the", "configured", "host", "and", "port", "if", "no", "addresses", "have", "been", "set"], "project": "spring-boot"}
{"id": 660, "code": "\tpublic static NamedPipeSocket get(String path) throws IOException {\n\t\treturn new NamedPipeSocket(path);\n\t}", "summary_tokens": ["return", "a", "new", "named", "pipe", "socket", "for", "the", "given", "path"], "project": "spring-boot"}
{"id": 447, "code": "\tpublic ObjectContent<T> read(Reader reader) throws IOException {\n\t\tverify();\n\t\tAssert.notNull(reader, \"Reader must not be null\");\n\t\tT object = readObject(reader, this.type);\n\t\tcloseQuietly(reader);\n\t\treturn new ObjectContent<>(this.type, object);\n\t}", "summary_tokens": ["return", "object", "content", "from", "reading", "from", "the", "specified", "reader"], "project": "spring-boot"}
{"id": 836, "code": "\tpublic void buildpack(String buildpack) {\n\t\tthis.buildpacks.add(buildpack);\n\t}", "summary_tokens": ["add", "an", "entry", "to", "the", "buildpacks", "that", "will", "be", "used", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 1116, "code": "\tpublic String getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "location", "always", "excluding", "any", "user", "specified", "optional", "prefix"], "project": "spring-boot"}
{"id": 698, "code": "\tpublic String getShortDescription() {\n\t\treturn this.shortDescription;\n\t}", "summary_tokens": ["a", "single", "line", "single", "sentence", "description", "of", "this", "hint", "if", "any"], "project": "spring-boot"}
{"id": 916, "code": "\tpublic static void removeDuplicatesFromOutputDirectory(File outputDirectory, File originDirectory) {\n\t\tif (originDirectory.isDirectory()) {\n\t\t\tfor (String name : originDirectory.list()) {\n\t\t\t\tFile targetFile = new File(outputDirectory, name);\n\t\t\t\tif (targetFile.exists() && targetFile.canWrite()) {\n\t\t\t\t\tif (!targetFile.isDirectory()) {\n\t\t\t\t\t\ttargetFile.delete();\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tFileUtils.removeDuplicatesFromOutputDirectory(targetFile, new File(originDirectory, name));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["utility", "to", "remove", "duplicate", "files", "from", "an", "output", "directory", "if", "they", "already", "exist", "in", "an", "origin"], "project": "spring-boot"}
{"id": 1052, "code": "\tpublic SpringApplication build(String... args) {\n\t\tconfigureAsChildIfNecessary(args);\n\t\tthis.application.addPrimarySources(this.sources);\n\t\treturn this.application;\n\t}", "summary_tokens": ["returns", "a", "fully", "configured", "spring", "application", "that", "is", "ready", "to", "run"], "project": "spring-boot"}
{"id": 82, "code": "\tpublic Collection<ExposableWebEndpoint> getEndpoints() {\n\t\treturn this.endpoints;\n\t}", "summary_tokens": ["return", "the", "web", "endpoints", "being", "mapped"], "project": "spring-boot"}
{"id": 1143, "code": "\tstatic void throwIfPropertyFound(ConfigDataEnvironmentContributor contributor) {\n\t\tConfigurationPropertySource propertySource = contributor.getConfigurationPropertySource();\n\t\tif (propertySource != null) {\n\t\t\tERRORS.forEach((name, replacement) -> {\n\t\t\t\tConfigurationProperty property = propertySource.getConfigurationProperty(name);\n\t\t\t\tif (property != null) {\n\t\t\t\t\tthrow new InvalidConfigDataPropertyException(property, false, replacement,\n\t\t\t\t\t\t\tcontributor.getResource());\n\t\t\t\t}\n\t\t\t});\n\t\t\tif (contributor.isFromProfileSpecificImport()\n\t\t\t\t\t&& !contributor.hasConfigDataOption(ConfigData.Option.IGNORE_PROFILES)) {\n\t\t\t\tPROFILE_SPECIFIC_ERRORS.forEach((name) -> {\n\t\t\t\t\tConfigurationProperty property = propertySource.getConfigurationProperty(name);\n\t\t\t\t\tif (property != null) {\n\t\t\t\t\t\tthrow new InvalidConfigDataPropertyException(property, true, null, contributor.getResource());\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["throw", "an", "invalid", "config", "data", "property", "exception", "if", "the", "given", "config", "data", "environment", "contributor", "contains", "any", "invalid", "property"], "project": "spring-boot"}
{"id": 806, "code": "\tpublic void setArtifact(String artifact) {\n\t\tthis.artifact.set(artifact);\n\t}", "summary_tokens": ["sets", "the", "value", "used", "for", "the", "build"], "project": "spring-boot"}
{"id": 927, "code": "\tpublic File getFile() {\n\t\treturn this.file;\n\t}", "summary_tokens": ["return", "the", "library", "file"], "project": "spring-boot"}
{"id": 92, "code": "\tstatic HealthEndpointGroups of(HealthEndpointGroup primary, Map<String, HealthEndpointGroup> additional) {\n\t\tAssert.notNull(primary, \"Primary must not be null\");\n\t\tAssert.notNull(additional, \"Additional must not be null\");\n\t\treturn new HealthEndpointGroups() {\n\n\t\t\t@Override\n\t\t\tpublic HealthEndpointGroup getPrimary() {\n\t\t\t\treturn primary;\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic Set<String> getNames() {\n\t\t\t\treturn additional.keySet();\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic HealthEndpointGroup get(String name) {\n\t\t\t\treturn additional.get(name);\n\t\t\t}\n\n\t\t};\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "health", "endpoint", "groups", "instance"], "project": "spring-boot"}
{"id": 938, "code": "\tstatic <T> T doWithMainClasses(JarFile jarFile, String classesLocation, MainClassCallback<T> callback)\n\t\t\tthrows IOException {\n\t\tList<JarEntry> classEntries = getClassEntries(jarFile, classesLocation);\n\t\tclassEntries.sort(new ClassEntryComparator());\n\t\tfor (JarEntry entry : classEntries) {\n\t\t\ttry (InputStream inputStream = new BufferedInputStream(jarFile.getInputStream(entry))) {\n\t\t\t\tClassDescriptor classDescriptor = createClassDescriptor(inputStream);\n\t\t\t\tif (classDescriptor != null && classDescriptor.isMainMethodFound()) {\n\t\t\t\t\tString className = convertToClassName(entry.getName(), classesLocation);\n\t\t\t\t\tT result = callback.doWith(new MainClass(className, classDescriptor.getAnnotationNames()));\n\t\t\t\t\tif (result != null) {\n\t\t\t\t\t\treturn result;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["perform", "the", "given", "callback", "operation", "on", "all", "main", "classes", "from", "the", "given", "jar"], "project": "spring-boot"}
{"id": 1229, "code": "\tpublic ConfigurationPropertyName chop(int size) {\n\t\tif (size >= getNumberOfElements()) {\n\t\t\treturn this;\n\t\t}\n\t\treturn new ConfigurationPropertyName(this.elements.chop(size));\n\t}", "summary_tokens": ["return", "a", "new", "configuration", "property", "name", "by", "chopping", "this", "name", "to", "the", "given", "size"], "project": "spring-boot"}
{"id": 1190, "code": "\tdefault void onFinish(ConfigurationPropertyName name, Bindable<?> target, BindContext context, Object result)", "summary_tokens": ["called", "when", "binding", "finishes", "with", "either", "bound", "or", "unbound", "result"], "project": "spring-boot"}
{"id": 689, "code": "\tpublic List<ValueHint> getKeyHints() {\n\t\treturn this.keyHints;\n\t}", "summary_tokens": ["the", "list", "of", "well", "defined", "keys", "if", "any"], "project": "spring-boot"}
{"id": 1128, "code": "\tboolean isActive(ConfigDataActivationContext activationContext) {\n\t\treturn this.activate == null || this.activate.isActive(activationContext);\n\t}", "summary_tokens": ["return", "true", "if", "the", "properties", "indicate", "that", "the", "config", "data", "property", "source", "is", "active", "for", "the", "given", "activation", "context"], "project": "spring-boot"}
{"id": 1254, "code": "\tprotected Class<? extends T> getCauseType() {\n\t\treturn (Class<? extends T>) ResolvableType.forClass(AbstractFailureAnalyzer.class, getClass()).resolveGeneric();\n\t}", "summary_tokens": ["return", "the", "cause", "type", "being", "handled", "by", "the", "analyzer"], "project": "spring-boot"}
{"id": 175, "code": "\tpublic ConditionEvaluationReport getParent() {\n\t\treturn this.parent;\n\t}", "summary_tokens": ["the", "parent", "report", "from", "a", "parent", "bean", "factory", "if", "there", "is", "one"], "project": "spring-boot"}
{"id": 647, "code": "\tpublic static int posixPermissionsToUmask(Collection<PosixFilePermission> permissions) {\n\t\tAssert.notNull(permissions, \"Permissions must not be null\");\n\t\tint owner = permissionToUmask(permissions, PosixFilePermission.OWNER_EXECUTE, PosixFilePermission.OWNER_WRITE,\n\t\t\t\tPosixFilePermission.OWNER_READ);\n\t\tint group = permissionToUmask(permissions, PosixFilePermission.GROUP_EXECUTE, PosixFilePermission.GROUP_WRITE,\n\t\t\t\tPosixFilePermission.GROUP_READ);\n\t\tint other = permissionToUmask(permissions, PosixFilePermission.OTHERS_EXECUTE, PosixFilePermission.OTHERS_WRITE,\n\t\t\t\tPosixFilePermission.OTHERS_READ);\n\t\treturn Integer.parseInt(\"\" + owner + group + other, 8);\n\t}", "summary_tokens": ["return", "the", "integer", "representation", "of", "a", "set", "of", "posix", "file", "permissions", "where", "the", "integer", "value", "conforms", "to", "the", "a", "href", "https", "en"], "project": "spring-boot"}
{"id": 963, "code": "\tprivate FilterArtifacts getFilters(ArtifactsFilter... additionalFilters) {\n\t\tFilterArtifacts filters = new FilterArtifacts();\n\t\tfor (ArtifactsFilter additionalFilter : additionalFilters) {\n\t\t\tfilters.addFilter(additionalFilter);\n\t\t}\n\t\tfilters.addFilter(new MatchingGroupIdFilter(cleanFilterConfig(this.excludeGroupIds)));\n\t\tif (this.includes != null && !this.includes.isEmpty()) {\n\t\t\tfilters.addFilter(new IncludeFilter(this.includes));\n\t\t}\n\t\tif (this.excludes != null && !this.excludes.isEmpty()) {\n\t\t\tfilters.addFilter(new ExcludeFilter(this.excludes));\n\t\t}\n\t\tfilters.addFilter(new JarTypeFilter());\n\t\treturn filters;\n\t}", "summary_tokens": ["return", "artifact", "filters", "configured", "for", "this", "mojo"], "project": "spring-boot"}
{"id": 1606, "code": "\tpublic static String getVersion() {\n\t\treturn \"${springBootVersion}\";\n\t}", "summary_tokens": ["return", "the", "full", "version", "string", "of", "the", "present", "spring", "boot", "codebase"], "project": "spring-boot"}
{"id": 582, "code": "\tpublic ErrorDetail getErrorDetail() {\n\t\treturn this.errorDetail;\n\t}", "summary_tokens": ["returns", "the", "details", "of", "any", "error", "encountered", "during", "processing"], "project": "spring-boot"}
{"id": 300, "code": "\tString getGroupId() {\n\t\treturn this.groupId;\n\t}", "summary_tokens": ["the", "group", "id", "to", "use", "or", "null", "if", "it", "should", "not", "be", "customized"], "project": "spring-boot"}
{"id": 419, "code": "\tpublic void flush() {\n\t\tgetEntityManager().flush();\n\t}", "summary_tokens": ["synchronize", "the", "persistence", "context", "to", "the", "underlying", "database"], "project": "spring-boot"}
{"id": 1330, "code": "\tprotected void initialized(Supplier<C> context) {\n\t}", "summary_tokens": ["method", "that", "can", "be", "implemented", "by", "subclasses", "that", "wish", "to", "initialize", "items", "the", "first", "time", "that", "the", "matcher", "is", "called"], "project": "spring-boot"}
{"id": 339, "code": "\tpublic DependencyCustomizer ifAnyResourcesPresent(String... paths) {\n\t\treturn new DependencyCustomizer(this) {\n\t\t\t@Override\n\t\t\tprotected boolean canAdd() {\n\t\t\t\tfor (String path : paths) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn DependencyCustomizer.this.loader.getResource(path) != null;\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn DependencyCustomizer.this.canAdd();\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["create", "a", "nested", "dependency", "customizer", "that", "only", "applies", "at", "least", "one", "of", "the", "specified", "paths", "is", "on", "the", "class", "path"], "project": "spring-boot"}
{"id": 1164, "code": "\tpublic StartupTimeline getBufferedTimeline() {\n\t\treturn new StartupTimeline(this.startTime, new ArrayList<>(this.events));\n\t}", "summary_tokens": ["return", "the", "startup", "timeline", "timeline", "as", "a", "snapshot", "of", "currently", "buffered", "steps"], "project": "spring-boot"}
{"id": 1224, "code": "\tpublic String getLastElement(Form form) {\n\t\tint size = getNumberOfElements();\n\t\treturn (size != 0) ? getElement(size - 1, form) : EMPTY_STRING;\n\t}", "summary_tokens": ["return", "the", "last", "element", "in", "the", "name", "in", "the", "given", "form"], "project": "spring-boot"}
{"id": 913, "code": "\tpublic String toString() {\n\t\treturn LibraryCoordinates.toStandardNotationString(this);\n\t}", "summary_tokens": ["return", "the", "coordinates", "in", "the", "form", "group", "id", "artifact", "id", "version"], "project": "spring-boot"}
{"id": 1180, "code": "\tfinal Object bind(ConfigurationPropertyName name, Bindable<?> target, AggregateElementBinder elementBinder) {\n\t\tObject result = bindAggregate(name, target, elementBinder);\n\t\tSupplier<?> value = target.getValue();\n\t\tif (result == null || value == null) {\n\t\t\treturn result;\n\t\t}\n\t\treturn merge((Supplier<T>) value, (T) result);\n\t}", "summary_tokens": ["perform", "binding", "for", "the", "aggregate"], "project": "spring-boot"}
{"id": 1487, "code": "\tpublic String getCertificate() {\n\t\treturn this.certificate;\n\t}", "summary_tokens": ["return", "the", "location", "of", "the", "certificate", "in", "pem", "format"], "project": "spring-boot"}
{"id": 229, "code": "\tpublic void configure(ConcurrentKafkaListenerContainerFactory<Object, Object> listenerFactory,\n\t\t\tConsumerFactory<Object, Object> consumerFactory) {\n\t\tlistenerFactory.setConsumerFactory(consumerFactory);\n\t\tconfigureListenerFactory(listenerFactory);\n\t\tconfigureContainer(listenerFactory.getContainerProperties());\n\t}", "summary_tokens": ["configure", "the", "specified", "kafka", "listener", "container", "factory"], "project": "spring-boot"}
{"id": 1605, "code": "\tpublic <T extends WebServiceTemplate> T configure(T webServiceTemplate) {\n\t\tAssert.notNull(webServiceTemplate, \"WebServiceTemplate must not be null\");\n\t\tconfigureMessageSenders(webServiceTemplate);\n\t\tPropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull();\n\t\tapplyCustomizers(webServiceTemplate, this.internalCustomizers);\n\t\tmap.from(this.marshaller).to(webServiceTemplate::setMarshaller);\n\t\tmap.from(this.unmarshaller).to(webServiceTemplate::setUnmarshaller);\n\t\tmap.from(this.destinationProvider).to(webServiceTemplate::setDestinationProvider);\n\t\tmap.from(this.transformerFactoryClass).to(webServiceTemplate::setTransformerFactoryClass);\n\t\tmap.from(this.messageFactory).to(webServiceTemplate::setMessageFactory);\n\t\tif (!CollectionUtils.isEmpty(this.interceptors)) {\n\t\t\tSet<ClientInterceptor> merged = new LinkedHashSet<>(this.interceptors);\n\t\t\tif (webServiceTemplate.getInterceptors() != null) {\n\t\t\t\tmerged.addAll(Arrays.asList(webServiceTemplate.getInterceptors()));\n\t\t\t}\n\t\t\twebServiceTemplate.setInterceptors(merged.toArray(new ClientInterceptor[0]));\n\t\t}\n\t\tapplyCustomizers(webServiceTemplate, this.customizers);\n\t\treturn webServiceTemplate;\n\t}", "summary_tokens": ["configure", "the", "provided", "web", "service", "template", "instance", "using", "this", "builder"], "project": "spring-boot"}
{"id": 536, "code": "\tstatic BuildpackLayersMetadata fromJson(JsonNode node) {\n\t\treturn new BuildpackLayersMetadata(node);\n\t}", "summary_tokens": ["create", "a", "buildpack", "layers", "metadata", "from", "json"], "project": "spring-boot"}
{"id": 895, "code": "\tpublic void setOptimizedLaunch(boolean optimizedLaunch) {\n\t\tthis.optimizedLaunch = optimizedLaunch;\n\t}", "summary_tokens": ["sets", "whether", "the", "jvm", "s", "launch", "should", "be", "optimized"], "project": "spring-boot"}
{"id": 1743, "code": "static ImmutableList<URL> parseJavaClassPath() {\n  ImmutableList.Builder<URL> urls = ImmutableList.builder();\n  for (String entry : Splitter.on(PATH_SEPARATOR.value()).split(JAVA_CLASS_PATH.value())) {\n    try {\n      try {\n        urls.add(new File(entry).toURI().toURL());\n      } catch (SecurityException e) { \n        urls.add(new URL(\"file\", null, new File(entry).getAbsolutePath()));\n      }\n    } catch (MalformedURLException e) {\n      logger.log(WARNING, \"malformed classpath entry: \" + entry, e);\n    }\n  }\n  return urls.build();\n}", "summary_tokens": ["returns", "the", "urls", "in", "the", "class", "path", "specified", "by", "the", "java"], "project": "guava"}
{"id": 1040, "code": "public String toString() {\n  return \"isDirected: \"\n      + isDirected()\n      + \", allowsSelfLoops: \"\n      + allowsSelfLoops()\n      + \", nodes: \"\n      + nodes()\n      + \", edges: \"\n      + edgeValueMap(this);\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "this", "graph"], "project": "guava"}
{"id": 1844, "code": "public long incrementAndGet(K key) {\n  return addAndGet(key, 1);\n}", "summary_tokens": ["increments", "by", "one", "the", "value", "currently", "associated", "with", "key", "and", "returns", "the", "new", "value"], "project": "guava"}
{"id": 477, "code": "public void testLongValue() {\n  AtomicDouble at = new AtomicDouble();\n  assertEquals(0L, at.longValue());\n  for (double x : VALUES) {\n    at.set(x);\n    assertEquals((long) x, at.longValue());\n  }\n}", "summary_tokens": ["long", "value", "returns", "current", "value"], "project": "guava"}
{"id": 564, "code": "public void callAndAssertThrows(\n    Class<? extends Throwable> expected, String methodName, Object... arguments)\n    throws Exception {\n  checkNotNull(expected);\n  checkNotNull(methodName);\n  checkNotNull(arguments);\n  sendRequest(methodName, arguments);\n  assertEquals(expected, getResponse(methodName).getThrowable().getClass());\n}", "summary_tokens": ["causes", "this", "thread", "to", "call", "the", "named", "method", "and", "asserts", "that", "the", "call", "throws", "the", "expected", "type", "of", "throwable"], "project": "guava"}
{"id": 422, "code": "public void testBadArguments_plusforspace() {\n  try {\n    new PercentEscaper(\" \", false);\n  } catch (IllegalArgumentException e) {\n    fail(\"Space can be a 'safe' character if plusForSpace is false\");\n  }\n  String msg = \"plusForSpace cannot be specified when space is a 'safe' character\";\n  try {\n    new PercentEscaper(\" \", true);\n    fail(msg);\n  } catch (IllegalArgumentException expected) {\n    assertThat(expected).hasMessageThat().isEqualTo(msg);\n  }\n}", "summary_tokens": ["tests", "that", "if", "space", "is", "a", "safe", "character", "you", "cannot", "also", "specify", "plus", "for", "space", "throws", "illegal", "argument", "exception"], "project": "guava"}
{"id": 881, "code": "public static <K, V> ImmutableSetMultimap<K, V> of(\n    K k1, V v1, K k2, V v2, K k3, V v3, K k4, V v4, K k5, V v5) {\n  ImmutableSetMultimap.Builder<K, V> builder = ImmutableSetMultimap.builder();\n  builder.put(k1, v1);\n  builder.put(k2, v2);\n  builder.put(k3, v3);\n  builder.put(k4, v4);\n  builder.put(k5, v5);\n  return builder.build();\n}", "summary_tokens": ["returns", "an", "immutable", "multimap", "containing", "the", "given", "entries", "in", "order"], "project": "guava"}
{"id": 1558, "code": "public int length() {\n  return end - start;\n}", "summary_tokens": ["returns", "the", "number", "of", "values", "in", "this", "array"], "project": "guava"}
{"id": 132, "code": "public static RuntimeException create(Collection<? extends Throwable> exceptions) {\n  if (exceptions.size() == 0) {\n    throw new IllegalArgumentException(\"Can't create an ExceptionCollection with no exceptions\");\n  }\n  if (exceptions.size() == 1) {\n    Throwable temp = exceptions.iterator().next();\n    if (temp instanceof RuntimeException) {\n      return (RuntimeException) temp;\n    } else {\n      return new RuntimeException(temp);\n    }\n  }\n  return new ClusterException(exceptions);\n}", "summary_tokens": ["given", "a", "collection", "of", "exceptions", "returns", "a", "runtime", "exception", "with", "the", "following", "rules"], "project": "guava"}
{"id": 769, "code": "public float floatValue() {\n  return (float) sum();\n}", "summary_tokens": ["returns", "the", "sum", "as", "a", "float", "after", "a", "widening", "primitive", "conversion"], "project": "guava"}
{"id": 1783, "code": "final TypeToken<? super T> getGenericSuperclass() {\n  if (runtimeType instanceof TypeVariable) {\n      \n    return boundAsSuperclass(((TypeVariable<?>) runtimeType).getBounds()[0]);\n  }\n  if (runtimeType instanceof WildcardType) {\n      \n    return boundAsSuperclass(((WildcardType) runtimeType).getUpperBounds()[0]);\n  }\n  Type superclass = getRawType().getGenericSuperclass();\n  if (superclass == null) {\n    return null;\n  }\n  @SuppressWarnings(\"unchecked\") \n  TypeToken<? super T> superToken = (TypeToken<? super T>) resolveSupertype(superclass);\n  return superToken;\n}", "summary_tokens": ["returns", "the", "generic", "superclass", "of", "this", "type", "or", "null", "if", "the", "type", "represents", "object", "or", "an", "interface"], "project": "guava"}
{"id": 1210, "code": "public void writeChars(String s) throws IOException {\n  for (int i = 0; i < s.length(); i++) {\n    writeChar(s.charAt(i));\n  }\n}", "summary_tokens": ["writes", "a", "string", "as", "specified", "by", "data", "output", "stream", "write", "chars", "string", "except", "each", "character", "is", "written", "using", "little", "endian", "byte", "order"], "project": "guava"}
{"id": 735, "code": "public double hitRate() {\n  long requestCount = requestCount();\n  return (requestCount == 0) ? 1.0 : (double) hitCount / requestCount;\n}", "summary_tokens": ["returns", "the", "ratio", "of", "cache", "requests", "which", "were", "hits"], "project": "guava"}
{"id": 1861, "code": "long putIfAbsent(K key, long newValue) {\n  AtomicBoolean noValue = new AtomicBoolean(false);\n  Long result =\n      map.compute(\n          key,\n          (k, oldValue) -> {\n            if (oldValue == null || oldValue == 0) {\n              noValue.set(true);\n              return newValue;\n            } else {\n              return oldValue;\n            }\n          });\n  return noValue.get() ? 0L : result.longValue();\n}", "summary_tokens": ["if", "key", "is", "not", "already", "associated", "with", "a", "value", "or", "if", "key", "is", "associated", "with", "zero", "associate", "it", "with", "new", "value"], "project": "guava"}
{"id": 574, "code": "public static char toUpperCase(char c) {\n  return isLowerCase(c) ? (char) (c ^ CASE_MASK) : c;\n}", "summary_tokens": ["if", "the", "argument", "is", "a", "is", "lower", "case", "char", "lowercase", "ascii", "character", "returns", "the", "uppercase", "equivalent"], "project": "guava"}
{"id": 767, "code": "public String toString() {\n  return Long.toString(sum());\n}", "summary_tokens": ["returns", "the", "string", "representation", "of", "the", "sum"], "project": "guava"}
{"id": 1013, "code": "static Dispatcher immediate() {\n  return ImmediateDispatcher.INSTANCE;\n}", "summary_tokens": ["returns", "a", "dispatcher", "that", "dispatches", "events", "to", "subscribers", "immediately", "as", "they", "re", "posted", "without", "using", "an", "intermediate", "queue", "to", "change", "the", "dispatch", "order"], "project": "guava"}
{"id": 1037, "code": "public String toString() {\n  return \"isDirected: \"\n      + isDirected()\n      + \", allowsSelfLoops: \"\n      + allowsSelfLoops()\n      + \", nodes: \"\n      + nodes()\n      + \", edges: \"\n      + edges();\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "this", "graph"], "project": "guava"}
{"id": 1907, "code": "public static Runnable doNothing() {\n  return EMPTY_RUNNABLE;\n}", "summary_tokens": ["returns", "a", "runnable", "instance", "that", "does", "nothing", "when", "run"], "project": "guava"}
{"id": 1605, "code": "public static void sortDescending(int[] array, int fromIndex, int toIndex) {\n  checkNotNull(array);\n  checkPositionIndexes(fromIndex, toIndex, array.length);\n  Arrays.sort(array, fromIndex, toIndex);\n  reverse(array, fromIndex, toIndex);\n}", "summary_tokens": ["sorts", "the", "elements", "of", "array", "between", "from", "index", "inclusive", "and", "to", "index", "exclusive", "in", "descending", "order"], "project": "guava"}
{"id": 1452, "code": "protected char[] escape(int cp) {\n    \n    \n  if (cp < safeOctets.length && safeOctets[cp]) {\n    return null;\n  } else if (cp == ' ' && plusForSpace) {\n    return PLUS_SIGN;\n  } else if (cp <= 0x7F) {\n      \n      \n    char[] dest = new char[3];\n    dest[0] = '%';\n    dest[2] = UPPER_HEX_DIGITS[cp & 0xF];\n    dest[1] = UPPER_HEX_DIGITS[cp >>> 4];\n    return dest;\n  } else if (cp <= 0x7ff) {\n      \n      \n    char[] dest = new char[6];\n    dest[0] = '%';\n    dest[3] = '%';\n    dest[5] = UPPER_HEX_DIGITS[cp & 0xF];\n    cp >>>= 4;\n    dest[4] = UPPER_HEX_DIGITS[0x8 | (cp & 0x3)];\n    cp >>>= 2;\n    dest[2] = UPPER_HEX_DIGITS[cp & 0xF];\n    cp >>>= 4;\n    dest[1] = UPPER_HEX_DIGITS[0xC | cp];\n    return dest;\n  } else if (cp <= 0xffff) {\n      \n      \n    char[] dest = new char[9];\n    dest[0] = '%';\n    dest[1] = 'E';\n    dest[3] = '%';\n    dest[6] = '%';\n    dest[8] = UPPER_HEX_DIGITS[cp & 0xF];\n    cp >>>= 4;\n    dest[7] = UPPER_HEX_DIGITS[0x8 | (cp & 0x3)];\n    cp >>>= 2;\n    dest[5] = UPPER_HEX_DIGITS[cp & 0xF];\n    cp >>>= 4;\n    dest[4] = UPPER_HEX_DIGITS[0x8 | (cp & 0x3)];\n    cp >>>= 2;\n    dest[2] = UPPER_HEX_DIGITS[cp];\n    return dest;\n  } else if (cp <= 0x10ffff) {\n    char[] dest = new char[12];\n      \n      \n    dest[0] = '%';\n    dest[1] = 'F';\n    dest[3] = '%';\n    dest[6] = '%';\n    dest[9] = '%';\n    dest[11] = UPPER_HEX_DIGITS[cp & 0xF];\n    cp >>>= 4;\n    dest[10] = UPPER_HEX_DIGITS[0x8 | (cp & 0x3)];\n    cp >>>= 2;\n    dest[8] = UPPER_HEX_DIGITS[cp & 0xF];\n    cp >>>= 4;\n    dest[7] = UPPER_HEX_DIGITS[0x8 | (cp & 0x3)];\n    cp >>>= 2;\n    dest[5] = UPPER_HEX_DIGITS[cp & 0xF];\n    cp >>>= 4;\n    dest[4] = UPPER_HEX_DIGITS[0x8 | (cp & 0x3)];\n    cp >>>= 2;\n    dest[2] = UPPER_HEX_DIGITS[cp & 0x7];\n    return dest;\n  } else {\n      \n    throw new IllegalArgumentException(\"Invalid unicode character value \" + cp);\n  }\n}", "summary_tokens": ["escapes", "the", "given", "unicode", "code", "point", "in", "utf", "0"], "project": "guava"}
{"id": 1909, "code": "public void addListener(Listener listener, Executor executor) {\n  state.addListener(listener, executor);\n}", "summary_tokens": ["registers", "a", "listener", "to", "be", "executor", "execute", "executed", "on", "the", "given", "executor"], "project": "guava"}
{"id": 781, "code": "public static <C extends Comparable> ContiguousSet<C> create(\n    Range<C> range, DiscreteDomain<C> domain) {\n  checkNotNull(range);\n  checkNotNull(domain);\n  Range<C> effectiveRange = range;\n  try {\n    if (!range.hasLowerBound()) {\n      effectiveRange = effectiveRange.intersection(Range.atLeast(domain.minValue()));\n    }\n    if (!range.hasUpperBound()) {\n      effectiveRange = effectiveRange.intersection(Range.atMost(domain.maxValue()));\n    }\n  } catch (NoSuchElementException e) {\n    throw new IllegalArgumentException(e);\n  }\n\n  boolean empty;\n  if (effectiveRange.isEmpty()) {\n    empty = true;\n  } else {\n      \n    C afterLower = requireNonNull(range.lowerBound.leastValueAbove(domain));\n    C beforeUpper = requireNonNull(range.upperBound.greatestValueBelow(domain));\n      \n    empty = Range.compareOrThrow(afterLower, beforeUpper) > 0;\n  }\n\n  return empty\n      ? new EmptyContiguousSet<C>(domain)\n      : new RegularContiguousSet<C>(effectiveRange, domain);\n}", "summary_tokens": ["returns", "a", "contiguous", "set", "containing", "the", "same", "values", "in", "the", "given", "domain", "range", "contains", "contained", "by", "the", "range"], "project": "guava"}
{"id": 1318, "code": "public static Scale percentiles() {\n  return scale(100);\n}", "summary_tokens": ["specifies", "the", "computation", "of", "percentiles", "i"], "project": "guava"}
{"id": 1778, "code": "public static TypeToken<?> of(Type type) {\n  return new SimpleTypeToken<>(type);\n}", "summary_tokens": ["returns", "an", "instance", "of", "type", "token", "that", "wraps", "type"], "project": "guava"}
{"id": 408, "code": "static void assertDiagonalLinearTransformation(\n    LinearTransformation transformation, double x1, double y1, double xDelta, double yDelta) {\n  checkArgument(xDelta != 0.0);\n  checkArgument(yDelta != 0.0);\n  assertThat(transformation.isHorizontal()).isFalse();\n  assertThat(transformation.isVertical()).isFalse();\n  assertThat(transformation.inverse().isHorizontal()).isFalse();\n  assertThat(transformation.inverse().isVertical()).isFalse();\n  assertThat(transformation.transform(x1)).isWithin(ALLOWED_ERROR).of(y1);\n  assertThat(transformation.transform(x1 + xDelta)).isWithin(ALLOWED_ERROR).of(y1 + yDelta);\n  assertThat(transformation.inverse().transform(y1)).isWithin(ALLOWED_ERROR).of(x1);\n  assertThat(transformation.inverse().transform(y1 + yDelta))\n      .isWithin(ALLOWED_ERROR)\n      .of(x1 + xDelta);\n  assertThat(transformation.slope()).isWithin(ALLOWED_ERROR).of(yDelta / xDelta);\n  assertThat(transformation.inverse().slope()).isWithin(ALLOWED_ERROR).of(xDelta / yDelta);\n  assertThat(transformation.inverse()).isSameInstanceAs(transformation.inverse());\n  assertThat(transformation.inverse().inverse()).isSameInstanceAs(transformation);\n}", "summary_tokens": ["asserts", "that", "transformation", "is", "diagonal", "i"], "project": "guava"}
{"id": 343, "code": "public void testDegenerateComparator() throws Exception {\n  TreeMultiset<String> ms = TreeMultiset.create(DEGENERATE_COMPARATOR);\n\n  ms.add(\"foo\");\n  ms.add(\"a\");\n  ms.add(\"bar\");\n  ms.add(\"b\");\n  ms.add(\"c\");\n\n  assertEquals(2, ms.count(\"bar\"));\n  assertEquals(3, ms.count(\"b\"));\n\n  Multiset<String> ms2 = TreeMultiset.create(DEGENERATE_COMPARATOR);\n\n  ms2.add(\"cat\", 2);\n  ms2.add(\"x\", 3);\n\n  assertEquals(ms, ms2);\n  assertEquals(ms2, ms);\n\n  SortedSet<String> elementSet = ms.elementSet();\n  assertEquals(\"a\", elementSet.first());\n  assertEquals(\"foo\", elementSet.last());\n  assertEquals(DEGENERATE_COMPARATOR, elementSet.comparator());\n}", "summary_tokens": ["test", "a", "tree", "multiset", "with", "a", "comparator", "that", "can", "return", "0", "when", "comparing", "unequal", "values"], "project": "guava"}
{"id": 1681, "code": "public UnsignedInteger minus(UnsignedInteger val) {\n  return fromIntBits(value - checkNotNull(val).value);\n}", "summary_tokens": ["returns", "the", "result", "of", "subtracting", "this", "and", "val"], "project": "guava"}
{"id": 1008, "code": "private static char[] growBuffer(char[] dest, int index, int size) {\n  if (size < 0) { \n    throw new AssertionError(\"Cannot increase internal buffer any further\");\n  }\n  char[] copy = new char[size];\n  if (index > 0) {\n    System.arraycopy(dest, 0, copy, 0, index);\n  }\n  return copy;\n}", "summary_tokens": ["helper", "method", "to", "grow", "the", "character", "buffer", "as", "needed", "this", "only", "happens", "once", "in", "a", "while", "so", "it", "s", "ok", "if", "it", "s", "in", "a", "method", "call"], "project": "guava"}
{"id": 1469, "code": "public static int countTrue(boolean... values) {\n  int count = 0;\n  for (boolean value : values) {\n    if (value) {\n      count++;\n    }\n  }\n  return count;\n}", "summary_tokens": ["returns", "the", "number", "of", "values", "that", "are", "true"], "project": "guava"}
{"id": 1432, "code": "public String type() {\n  return type;\n}", "summary_tokens": ["returns", "the", "top", "level", "media", "type"], "project": "guava"}
{"id": 1919, "code": "public ThreadFactoryBuilder setDaemon(boolean daemon) {\n  this.daemon = daemon;\n  return this;\n}", "summary_tokens": ["sets", "daemon", "or", "not", "for", "new", "threads", "created", "with", "this", "thread", "factory"], "project": "guava"}
{"id": 109, "code": "public static Method[] getHashCodeMethods() {\n  return new Method[] {\n    Helpers.getMethod(SetHashCodeTester.class, \"testHashCode\"),\n    Helpers.getMethod(SetHashCodeTester.class, \"testHashCode_containingNull\")\n  };\n}", "summary_tokens": ["returns", "the", "method", "instances", "for", "the", "test", "methods", "in", "this", "class", "which", "call", "hash", "code", "on", "the", "set", "values", "so", "that", "set", "tests", "on", "unhashable", "objects", "can", "suppress", "it", "with", "feature", "specific", "test", "suite", "builder"], "project": "guava"}
{"id": 1829, "code": "private void readObject(java.io.ObjectInputStream s)\n    throws java.io.IOException, ClassNotFoundException {\n  s.defaultReadObject();\n\n  set(s.readDouble());\n}", "summary_tokens": ["reconstitutes", "the", "instance", "from", "a", "stream", "that", "is", "deserializes", "it"], "project": "guava"}
{"id": 400, "code": "private static void assertMean(long x, long y) {\n  long expectedMean = computeMeanSafely(x, y);\n  assertEquals(expectedMean, LongMath.mean(x, y));\n  assertEquals(\n      \"The mean of x and y should equal the mean of y and x\", expectedMean, LongMath.mean(y, x));\n}", "summary_tokens": ["helper", "method", "that", "asserts", "the", "arithmetic", "mean", "of", "x", "and", "y", "is", "equal", "to", "the", "result", "of", "compute", "mean", "safely"], "project": "guava"}
{"id": 567, "code": "public void assertPriorCallReturns(boolean expected, @Nullable String methodName)\n    throws Exception {\n  assertEquals(expected, getResponse(methodName).getResult());\n}", "summary_tokens": ["asserts", "that", "a", "prior", "call", "that", "had", "caused", "this", "thread", "to", "block", "or", "wait", "has", "since", "returned", "the", "expected", "boolean", "value"], "project": "guava"}
{"id": 600, "code": "public CharMatcher or(CharMatcher other) {\n  return new Or(this, other);\n}", "summary_tokens": ["returns", "a", "matcher", "that", "matches", "any", "character", "matched", "by", "either", "this", "matcher", "or", "other"], "project": "guava"}
{"id": 558, "code": "public void testTransitionRace() throws TimeoutException {\n  for (int k = 0; k < 1000; k++) {\n    List<Service> services = Lists.newArrayList();\n    for (int i = 0; i < 5; i++) {\n      services.add(new SnappyShutdownService(i));\n    }\n    ServiceManager manager = new ServiceManager(services);\n    manager.startAsync().awaitHealthy();\n    manager.stopAsync().awaitStopped(10, TimeUnit.SECONDS);\n  }\n}", "summary_tokens": ["this", "test", "is", "for", "a", "case", "where", "two", "service"], "project": "guava"}
{"id": 1589, "code": "public static int saturatedCast(long value) {\n  if (value > Integer.MAX_VALUE) {\n    return Integer.MAX_VALUE;\n  }\n  if (value < Integer.MIN_VALUE) {\n    return Integer.MIN_VALUE;\n  }\n  return (int) value;\n}", "summary_tokens": ["returns", "the", "int", "nearest", "in", "value", "to", "value"], "project": "guava"}
{"id": 1884, "code": "public boolean waitForUninterruptibly(Guard guard, long time, TimeUnit unit) {\n  final long timeoutNanos = toSafeNanos(time, unit);\n  if (!((guard.monitor == this) && lock.isHeldByCurrentThread())) {\n    throw new IllegalMonitorStateException();\n  }\n  if (guard.isSatisfied()) {\n    return true;\n  }\n  boolean signalBeforeWaiting = true;\n  final long startTime = initNanoTime(timeoutNanos);\n  boolean interrupted = Thread.interrupted();\n  try {\n    for (long remainingNanos = timeoutNanos; ; ) {\n      try {\n        return awaitNanos(guard, remainingNanos, signalBeforeWaiting);\n      } catch (InterruptedException interrupt) {\n        interrupted = true;\n        if (guard.isSatisfied()) {\n          return true;\n        }\n        signalBeforeWaiting = false;\n        remainingNanos = remainingNanos(startTime, timeoutNanos);\n      }\n    }\n  } finally {\n    if (interrupted) {\n      Thread.currentThread().interrupt();\n    }\n  }\n}", "summary_tokens": ["waits", "for", "the", "guard", "to", "be", "satisfied"], "project": "guava"}
{"id": 1345, "code": "public Stats snapshot() {\n  return new Stats(count, mean, sumOfSquaresOfDeltas, min, max);\n}", "summary_tokens": ["returns", "an", "immutable", "snapshot", "of", "the", "current", "statistics"], "project": "guava"}
{"id": 745, "code": "public CacheStats minus(CacheStats other) {\n  return new CacheStats(\n      Math.max(0, saturatedSubtract(hitCount, other.hitCount)),\n      Math.max(0, saturatedSubtract(missCount, other.missCount)),\n      Math.max(0, saturatedSubtract(loadSuccessCount, other.loadSuccessCount)),\n      Math.max(0, saturatedSubtract(loadExceptionCount, other.loadExceptionCount)),\n      Math.max(0, saturatedSubtract(totalLoadTime, other.totalLoadTime)),\n      Math.max(0, saturatedSubtract(evictionCount, other.evictionCount)));\n}", "summary_tokens": ["returns", "a", "new", "cache", "stats", "representing", "the", "difference", "between", "this", "cache", "stats", "and", "other"], "project": "guava"}
{"id": 1582, "code": "public List<Long> asList() {\n    \n  return new AsList(this);\n}", "summary_tokens": ["returns", "an", "immutable", "i", "view", "i", "of", "this", "array", "s", "values", "as", "a", "list", "note", "that", "long", "values", "are", "boxed", "into", "long", "instances", "on", "demand", "which", "can", "be", "very", "expensive"], "project": "guava"}
{"id": 672, "code": "public static boolean isNullOrEmpty(@CheckForNull String string) {\n  return Platform.stringIsNullOrEmpty(string);\n}", "summary_tokens": ["returns", "true", "if", "the", "given", "string", "is", "null", "or", "is", "the", "empty", "string"], "project": "guava"}
{"id": 507, "code": "private static boolean isTimed(Method method) {\n  return isLongTimeUnitBased(method) || isDurationBased(method);\n}", "summary_tokens": ["determines", "whether", "the", "given", "method", "is", "time", "based"], "project": "guava"}
{"id": 488, "code": "public void testTransformExceptionRemainsMemoized() throws Throwable {\n    \n    \n    \n    \n  SettableFuture<Integer> exceptionInput = SettableFuture.create();\n  ListenableFuture<Integer> exceptionComposedFuture =\n      transform(exceptionInput, newOneTimeExceptionThrower(), directExecutor());\n  exceptionInput.set(0);\n  runGetIdempotencyTest(exceptionComposedFuture, MyRuntimeException.class);\n\n  SettableFuture<Integer> errorInput = SettableFuture.create();\n  ListenableFuture<Integer> errorComposedFuture =\n      transform(errorInput, newOneTimeErrorThrower(), directExecutor());\n  errorInput.set(0);\n\n  runGetIdempotencyTest(errorComposedFuture, MyError.class);\n\n    \n  exceptionComposedFuture =\n      transform(exceptionInput, newOneTimeExceptionThrower(), directExecutor());\n  runGetIdempotencyTest(exceptionComposedFuture, MyRuntimeException.class);\n\n  runGetIdempotencyTest(\n      transform(errorInput, newOneTimeErrorThrower(), directExecutor()), MyError.class);\n  runGetIdempotencyTest(errorComposedFuture, MyError.class);\n}", "summary_tokens": ["test", "that", "the", "function", "is", "invoked", "only", "once", "even", "if", "it", "throws", "an", "exception"], "project": "guava"}
{"id": 1567, "code": "public boolean equals(@CheckForNull Object object) {\n  if (object == this) {\n    return true;\n  }\n  if (!(object instanceof ImmutableIntArray)) {\n    return false;\n  }\n  ImmutableIntArray that = (ImmutableIntArray) object;\n  if (this.length() != that.length()) {\n    return false;\n  }\n  for (int i = 0; i < length(); i++) {\n    if (this.get(i) != that.get(i)) {\n      return false;\n    }\n  }\n  return true;\n}", "summary_tokens": ["returns", "true", "if", "object", "is", "an", "immutable", "int", "array", "containing", "the", "same", "values", "as", "this", "one", "in", "the", "same", "order"], "project": "guava"}
{"id": 1632, "code": "public static Set<Class<?>> allWrapperTypes() {\n  return WRAPPER_TO_PRIMITIVE_TYPE.keySet();\n}", "summary_tokens": ["returns", "an", "immutable", "set", "of", "all", "nine", "primitive", "wrapper", "types", "including", "void"], "project": "guava"}
{"id": 1995, "code": "public static void deleteDirectoryContents(Path path, RecursiveDeleteOption... options)\n    throws IOException {\n  Collection<IOException> exceptions = null; \n  try (DirectoryStream<Path> stream = Files.newDirectoryStream(path)) {\n    if (stream instanceof SecureDirectoryStream) {\n      SecureDirectoryStream<Path> sds = (SecureDirectoryStream<Path>) stream;\n      exceptions = deleteDirectoryContentsSecure(sds);\n    } else {\n      checkAllowsInsecure(path, options);\n      exceptions = deleteDirectoryContentsInsecure(stream);\n    }\n  } catch (IOException e) {\n    if (exceptions == null) {\n      throw e;\n    } else {\n      exceptions.add(e);\n    }\n  }\n\n  if (exceptions != null) {\n    throwDeleteFailed(path, exceptions);\n  }\n}", "summary_tokens": ["deletes", "all", "files", "within", "the", "directory", "at", "the", "given", "path", "delete", "recursively", "recursively"], "project": "guava"}
{"id": 1955, "code": "public void testAccumulateAndGetWithMax() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(SIZE);\n  for (int i : new int[] {0, SIZE - 1}) {\n    for (double x : VALUES) {\n      for (double y : VALUES) {\n        aa.set(i, x);\n        double z = aa.accumulateAndGet(i, y, Double::max);\n        double expectedMax = max(x, y);\n        assertBitEquals(expectedMax, z);\n        assertBitEquals(expectedMax, aa.get(i));\n      }\n    }\n  }\n}", "summary_tokens": ["accumulate", "and", "get", "with", "max", "stores", "max", "of", "given", "value", "to", "current", "and", "returns", "current", "value"], "project": "guava"}
{"id": 88, "code": "public static Method getCreateWithNullUnsupportedMethod() {\n  return Helpers.getMethod(CollectionCreationTester.class, \"testCreateWithNull_unsupported\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "create", "with", "null", "unsupported", "so", "that", "tests", "can", "suppress", "it", "with", "feature", "specific", "test", "suite", "builder"], "project": "guava"}
{"id": 702, "code": "private Method getFinalizeReferentMethod() {\n  Class<?> finalizableReferenceClass = finalizableReferenceClassReference.get();\n  if (finalizableReferenceClass == null) {\n      \n    return null;\n  }\n  try {\n    return finalizableReferenceClass.getMethod(\"finalizeReferent\");\n  } catch (NoSuchMethodException e) {\n    throw new AssertionError(e);\n  }\n}", "summary_tokens": ["looks", "up", "finalizable", "reference"], "project": "guava"}
{"id": 1263, "code": "public static int saturatedPow(int b, int k) {\n  checkNonNegative(\"exponent\", k);\n  switch (b) {\n    case 0:\n      return (k == 0) ? 1 : 0;\n    case 1:\n      return 1;\n    case (-1):\n      return ((k & 1) == 0) ? 1 : -1;\n    case 2:\n      if (k >= Integer.SIZE - 1) {\n        return Integer.MAX_VALUE;\n      }\n      return 1 << k;\n    case (-2):\n      if (k >= Integer.SIZE) {\n        return Integer.MAX_VALUE + (k & 1);\n      }\n      return ((k & 1) == 0) ? 1 << k : -1 << k;\n    default:\n        \n  }\n  int accum = 1;\n    \n  int limit = Integer.MAX_VALUE + ((b >>> Integer.SIZE - 1) & (k & 1));\n  while (true) {\n    switch (k) {\n      case 0:\n        return accum;\n      case 1:\n        return saturatedMultiply(accum, b);\n      default:\n        if ((k & 1) != 0) {\n          accum = saturatedMultiply(accum, b);\n        }\n        k >>= 1;\n        if (k > 0) {\n          if (-FLOOR_SQRT_MAX_INT > b | b > FLOOR_SQRT_MAX_INT) {\n            return limit;\n          }\n          b *= b;\n        }\n    }\n  }\n}", "summary_tokens": ["returns", "the", "b", "to", "the", "k", "th", "power", "unless", "it", "would", "overflow", "or", "underflow", "in", "which", "case", "integer"], "project": "guava"}
{"id": 245, "code": "public void testIsWellFormed_1Byte() {\n  testBytes(1, EXPECTED_ONE_BYTE_ROUNDTRIPPABLE_COUNT);\n}", "summary_tokens": ["tests", "that", "round", "tripping", "of", "all", "two", "byte", "permutations", "work"], "project": "guava"}
{"id": 208, "code": "public boolean add(E e) {\n  return super.add(e);\n}", "summary_tokens": ["inserts", "the", "specified", "element", "at", "the", "tail", "of", "this", "queue", "if", "it", "is", "possible", "to", "do", "so", "immediately", "without", "exceeding", "the", "queue", "s", "capacity", "returning", "true", "upon", "success", "and", "throwing", "an", "illegal", "state", "exception", "if", "this", "queue", "is", "full"], "project": "guava"}
{"id": 480, "code": "public void testDistinctZeros() {\n  AtomicDouble at = new AtomicDouble(+0.0);\n  assertFalse(at.compareAndSet(-0.0, 7.0));\n  assertFalse(at.weakCompareAndSet(-0.0, 7.0));\n  assertBitEquals(+0.0, at.get());\n  assertTrue(at.compareAndSet(+0.0, -0.0));\n  assertBitEquals(-0.0, at.get());\n  assertFalse(at.compareAndSet(+0.0, 7.0));\n  assertFalse(at.weakCompareAndSet(+0.0, 7.0));\n  assertBitEquals(-0.0, at.get());\n}", "summary_tokens": ["compare", "and", "set", "treats", "0"], "project": "guava"}
{"id": 1403, "code": "public static InetAddress decrement(InetAddress address) {\n  byte[] addr = address.getAddress();\n  int i = addr.length - 1;\n  while (i >= 0 && addr[i] == (byte) 0x00) {\n    addr[i] = (byte) 0xff;\n    i--;\n  }\n\n  checkArgument(i >= 0, \"Decrementing %s would wrap.\", address);\n\n  addr[i]--;\n  return bytesToInetAddress(addr);\n}", "summary_tokens": ["returns", "a", "new", "inet", "address", "that", "is", "one", "less", "than", "the", "passed", "in", "address"], "project": "guava"}
{"id": 1847, "code": "public long getAndIncrement(K key) {\n  return getAndAdd(key, 1);\n}", "summary_tokens": ["increments", "by", "one", "the", "value", "currently", "associated", "with", "key", "and", "returns", "the", "old", "value"], "project": "guava"}
{"id": 855, "code": "public final int remove(@CheckForNull Object element, int occurrences) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "collection", "unmodified"], "project": "guava"}
{"id": 1433, "code": "public String subtype() {\n  return subtype;\n}", "summary_tokens": ["returns", "the", "media", "subtype"], "project": "guava"}
{"id": 2016, "code": "public final double getAndAccumulate(int i, double x, DoubleBinaryOperator accumulatorFunction) {\n  checkNotNull(accumulatorFunction);\n  return getAndUpdate(i, oldValue -> accumulatorFunction.applyAsDouble(oldValue, x));\n}", "summary_tokens": ["atomically", "updates", "the", "element", "at", "index", "i", "with", "the", "results", "of", "applying", "the", "given", "function", "to", "the", "curernt", "and", "given", "values"], "project": "guava"}
{"id": 239, "code": "private Object[] getParametersForSignature(Object firstParam, ImmutableList<Class<?>> sig) {\n  Object[] params = new Object[sig.size()];\n  params[0] = firstParam;\n  if (params.length > 1) {\n    params[1] = \"\";\n    if (params.length > 2) {\n        \n      for (int i = 2; i < params.length; i++) {\n        params[i] = ArbitraryInstances.get(sig.get(i));\n      }\n    }\n  }\n  return params;\n}", "summary_tokens": ["returns", "an", "array", "containing", "parameters", "for", "invoking", "a", "check", "argument", "check", "not", "null", "or", "check", "state", "method", "reflectively"], "project": "guava"}
{"id": 953, "code": "public static <C extends Comparable<?>> Range<C> atLeast(C endpoint) {\n  return create(Cut.belowValue(endpoint), Cut.<C>aboveAll());\n}", "summary_tokens": ["returns", "a", "range", "that", "contains", "all", "values", "greater", "than", "or", "equal", "to", "endpoint"], "project": "guava"}
{"id": 253, "code": "public void testEviction_maxWeight_zero() {\n  CountingRemovalListener<Integer, Integer> removalListener = countingRemovalListener();\n  IdentityLoader<Integer> loader = identityLoader();\n\n    \n  Weigher<Integer, Integer> evensOnly =\n      new Weigher<Integer, Integer>() {\n        @Override\n        public int weigh(Integer k, Integer v) {\n          return k % 2;\n        }\n      };\n\n  LoadingCache<Integer, Integer> cache =\n      CacheBuilder.newBuilder()\n          .concurrencyLevel(1)\n          .maximumWeight(0)\n          .weigher(evensOnly)\n          .removalListener(removalListener)\n          .build(loader);\n\n    \n  assertThat(cache.getUnchecked(1)).isEqualTo(1);\n  assertThat(cache.asMap().keySet()).isEmpty();\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(1);\n\n    \n  assertThat(cache.getUnchecked(2)).isEqualTo(2);\n  assertThat(cache.asMap().keySet()).containsExactly(2);\n\n  CacheTesting.processPendingNotifications(cache);\n  CacheTesting.checkValidState(cache);\n  assertThat(removalListener.getCount()).isEqualTo(1);\n\n    \n  assertThat(cache.getUnchecked(4)).isEqualTo(4);\n  assertThat(cache.asMap().keySet()).containsExactly(2, 4);\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(1);\n\n    \n  assertThat(cache.getUnchecked(5)).isEqualTo(5);\n  assertThat(cache.asMap().keySet()).containsExactly(2, 4);\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(2);\n\n    \n  CacheTesting.checkValidState(cache);\n}", "summary_tokens": ["with", "an", "unlimited", "size", "cache", "with", "max", "weight", "of", "0", "entries", "weighing", "0", "should", "still", "be", "cached"], "project": "guava"}
{"id": 555, "code": "public void testEmptyServiceManager() {\n  Logger logger = Logger.getLogger(ServiceManager.class.getName());\n  logger.setLevel(Level.FINEST);\n  TestLogHandler logHandler = new TestLogHandler();\n  logger.addHandler(logHandler);\n  ServiceManager manager = new ServiceManager(Arrays.<Service>asList());\n  RecordingListener listener = new RecordingListener();\n  manager.addListener(listener, directExecutor());\n  manager.startAsync().awaitHealthy();\n  assertTrue(manager.isHealthy());\n  assertTrue(listener.healthyCalled);\n  assertFalse(listener.stoppedCalled);\n  assertTrue(listener.failedServices.isEmpty());\n  manager.stopAsync().awaitStopped();\n  assertFalse(manager.isHealthy());\n  assertTrue(listener.stoppedCalled);\n  assertTrue(listener.failedServices.isEmpty());\n    \n    \n  assertEquals(\"ServiceManager{services=[]}\", manager.toString());\n  assertTrue(manager.servicesByState().isEmpty());\n  assertTrue(manager.startupTimes().isEmpty());\n  Formatter logFormatter =\n      new Formatter() {\n        @Override\n        public String format(LogRecord record) {\n          return formatMessage(record);\n        }\n      };\n  for (LogRecord record : logHandler.getStoredLogRecords()) {\n    assertThat(logFormatter.format(record)).doesNotContain(\"NoOpService\");\n  }\n}", "summary_tokens": ["this", "is", "for", "covering", "a", "case", "where", "the", "service", "manager", "would", "behave", "strangely", "if", "constructed", "with", "no", "service", "under", "management"], "project": "guava"}
{"id": 1329, "code": "public long count() {\n  return count;\n}", "summary_tokens": ["returns", "the", "number", "of", "values"], "project": "guava"}
{"id": 738, "code": "public long loadCount() {\n  return saturatedAdd(loadSuccessCount, loadExceptionCount);\n}", "summary_tokens": ["returns", "the", "total", "number", "of", "times", "that", "cache", "lookup", "methods", "attempted", "to", "load", "new", "values"], "project": "guava"}
{"id": 163, "code": "public void testConstructorParameter(Constructor<?> ctor, int paramIndex) {\n  ctor.setAccessible(true);\n  testParameter(null, Invokable.from(ctor), paramIndex, ctor.getDeclaringClass());\n}", "summary_tokens": ["verifies", "that", "ctor", "produces", "a", "null", "pointer", "exception", "or", "unsupported", "operation", "exception", "when", "the", "parameter", "in", "position", "param", "index", "is", "null"], "project": "guava"}
{"id": 436, "code": "private static void radixEncodeParseAndAssertEquals(Long value, int radix) {\n  assertEquals(\"Radix: \" + radix, value, Longs.tryParse(Long.toString(value, radix), radix));\n}", "summary_tokens": ["encodes", "the", "long", "as", "a", "string", "with", "given", "radix", "then", "uses", "longs", "try", "parse", "string", "int", "to", "parse", "the", "result"], "project": "guava"}
{"id": 1163, "code": "public int intValue() {\n  return (int) sum();\n}", "summary_tokens": ["returns", "the", "sum", "as", "an", "int", "after", "a", "narrowing", "primitive", "conversion"], "project": "guava"}
{"id": 1304, "code": "public byte[] toByteArray() {\n  ByteBuffer buffer = ByteBuffer.allocate(BYTES).order(ByteOrder.LITTLE_ENDIAN);\n  xStats.writeTo(buffer);\n  yStats.writeTo(buffer);\n  buffer.putDouble(sumOfProductsOfDeltas);\n  return buffer.array();\n}", "summary_tokens": ["gets", "a", "byte", "array", "representation", "of", "this", "instance"], "project": "guava"}
{"id": 2013, "code": "public final double accumulateAndGet(double x, DoubleBinaryOperator accumulatorFunction) {\n  checkNotNull(accumulatorFunction);\n  return updateAndGet(oldValue -> accumulatorFunction.applyAsDouble(oldValue, x));\n}", "summary_tokens": ["atomically", "updates", "the", "current", "value", "with", "the", "results", "of", "applying", "the", "given", "function", "to", "the", "current", "and", "given", "values"], "project": "guava"}
{"id": 570, "code": "public void testRegularFutureInterrupted() throws ExecutionException {\n\n    \n  InterruptionUtil.requestInterruptIn(200, TimeUnit.MILLISECONDS);\n\n  assertFalse(Thread.interrupted());\n  try {\n    delayedFuture.get(20000, TimeUnit.MILLISECONDS);\n    fail(\"expected to be interrupted\");\n  } catch (InterruptedException expected) {\n  } catch (TimeoutException e) {\n    throw new RuntimeException(e);\n  }\n\n    \n  assertFalse(Thread.interrupted());\n\n  assertFalse(sleeper.completed);\n  try {\n    assertTrue(delayedFuture.get());\n  } catch (InterruptedException e) {\n    throw new RuntimeException(e);\n  }\n  assertTrue(sleeper.completed);\n}", "summary_tokens": ["this", "first", "test", "doesn", "t", "test", "anything", "in", "uninterruptibles", "just", "demonstrates", "some", "normal", "behavior", "of", "futures", "so", "that", "you", "can", "contrast", "the", "next", "test", "with", "it"], "project": "guava"}
{"id": 1957, "code": "public void testGetAndUpdateWithSubtract() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(SIZE);\n  for (int i : new int[] {0, SIZE - 1}) {\n    for (double x : VALUES) {\n      for (double y : VALUES) {\n        aa.set(i, x);\n        double z = aa.getAndUpdate(i, value -> value - y);\n        assertBitEquals(x, z);\n        assertBitEquals(x - y, aa.get(i));\n      }\n    }\n  }\n}", "summary_tokens": ["get", "and", "update", "subtracts", "given", "value", "to", "current", "and", "returns", "previous", "value"], "project": "guava"}
{"id": 1090, "code": "private GraphConnections<N, V> addNodeInternal(N node) {\n  GraphConnections<N, V> connections = newConnections();\n  checkState(nodeConnections.put(node, connections) == null);\n  return connections;\n}", "summary_tokens": ["adds", "node", "to", "the", "graph", "and", "returns", "the", "associated", "graph", "connections"], "project": "guava"}
{"id": 1779, "code": "public final Class<? super T> getRawType() {\n    \n  Class<?> rawType = getRawTypes().iterator().next();\n  @SuppressWarnings(\"unchecked\") \n  Class<? super T> result = (Class<? super T>) rawType;\n  return result;\n}", "summary_tokens": ["returns", "the", "raw", "type", "of", "t"], "project": "guava"}
{"id": 362, "code": "private static void assertApproximateElementCountGuess(BloomFilter<?> bf, int sizeGuess) {\n  assertThat(bf.approximateElementCount()).isAtLeast((long) (sizeGuess * 0.99));\n  assertThat(bf.approximateElementCount()).isAtMost((long) (sizeGuess * 1.01));\n}", "summary_tokens": ["asserts", "that", "bloom", "filter", "approximate", "element", "count", "is", "within", "0", "percent", "of", "the", "expected", "value"], "project": "guava"}
{"id": 974, "code": "public boolean equals(@CheckForNull Object object) {\n  if (object instanceof Range) {\n    Range<?> other = (Range<?>) object;\n    return lowerBound.equals(other.lowerBound) && upperBound.equals(other.upperBound);\n  }\n  return false;\n}", "summary_tokens": ["returns", "true", "if", "object", "is", "a", "range", "having", "the", "same", "endpoints", "and", "bound", "types", "as", "this", "range"], "project": "guava"}
{"id": 966, "code": "public boolean apply(C input) {\n  return contains(input);\n}", "summary_tokens": ["provided", "only", "to", "satisfy", "the", "predicate", "interface", "use", "contains", "instead"], "project": "guava"}
{"id": 1838, "code": "public double addAndGet(int i, double delta) {\n  return accumulateAndGet(i, delta, Double::sum);\n}", "summary_tokens": ["atomically", "adds", "the", "given", "value", "to", "the", "element", "at", "index", "i"], "project": "guava"}
{"id": 594, "code": "public static CharMatcher anyOf(final CharSequence sequence) {\n  switch (sequence.length()) {\n    case 0:\n      return none();\n    case 1:\n      return is(sequence.charAt(0));\n    case 2:\n      return isEither(sequence.charAt(0), sequence.charAt(1));\n    default:\n        \n        \n      return new AnyOf(sequence);\n  }\n}", "summary_tokens": ["returns", "a", "char", "matcher", "that", "matches", "any", "bmp", "character", "present", "in", "the", "given", "character", "sequence"], "project": "guava"}
{"id": 839, "code": "public static <K, V> ImmutableMultimap<K, V> copyOf(\n    Iterable<? extends Entry<? extends K, ? extends V>> entries) {\n  return ImmutableListMultimap.copyOf(entries);\n}", "summary_tokens": ["returns", "an", "immutable", "multimap", "containing", "the", "specified", "entries"], "project": "guava"}
{"id": 724, "code": "public static CacheBuilderSpec disableCaching() {\n    \n  return CacheBuilderSpec.parse(\"maximumSize=0\");\n}", "summary_tokens": ["returns", "a", "cache", "builder", "spec", "that", "will", "prevent", "caching"], "project": "guava"}
{"id": 1005, "code": "protected int nextEscapeIndex(CharSequence csq, int start, int end) {\n  int index = start;\n  while (index < end) {\n    int cp = codePointAt(csq, index, end);\n    if (cp < 0 || escape(cp) != null) {\n      break;\n    }\n    index += Character.isSupplementaryCodePoint(cp) ? 2 : 1;\n  }\n  return index;\n}", "summary_tokens": ["scans", "a", "sub", "sequence", "of", "characters", "from", "a", "given", "char", "sequence", "returning", "the", "index", "of", "the", "next", "character", "that", "requires", "escaping"], "project": "guava"}
{"id": 1578, "code": "public int lastIndexOf(long target) {\n  for (int i = end - 1; i >= start; i--) {\n    if (array[i] == target) {\n      return i - start;\n    }\n  }\n  return -1;\n}", "summary_tokens": ["returns", "the", "largest", "index", "for", "which", "get", "returns", "target", "or", "0", "if", "no", "such", "index", "exists"], "project": "guava"}
{"id": 949, "code": "public static <C extends Comparable<?>> Range<C> lessThan(C endpoint) {\n  return create(Cut.<C>belowAll(), Cut.belowValue(endpoint));\n}", "summary_tokens": ["returns", "a", "range", "that", "contains", "all", "values", "strictly", "less", "than", "endpoint"], "project": "guava"}
{"id": 181, "code": "public void testAddNullReference() {\n  try {\n    equalsTester.addEqualityGroup((Object) null);\n    fail(\"Should fail on null reference\");\n  } catch (NullPointerException e) {\n  }\n}", "summary_tokens": ["test", "null", "reference", "yields", "error"], "project": "guava"}
{"id": 1475, "code": "public static byte[] concat(byte[]... arrays) {\n  int length = 0;\n  for (byte[] array : arrays) {\n    length += array.length;\n  }\n  byte[] result = new byte[length];\n  int pos = 0;\n  for (byte[] array : arrays) {\n    System.arraycopy(array, 0, result, pos, array.length);\n    pos += array.length;\n  }\n  return result;\n}", "summary_tokens": ["returns", "the", "values", "from", "each", "provided", "array", "combined", "into", "a", "single", "array"], "project": "guava"}
{"id": 1798, "code": "protected Object writeReplace() {\n    \n    \n  return of(new TypeResolver().resolveType(runtimeType));\n}", "summary_tokens": ["implemented", "to", "support", "serialization", "of", "subclasses"], "project": "guava"}
{"id": 620, "code": "public String toString() {\n  return super.toString();\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "this", "char", "matcher", "such", "as", "char", "matcher"], "project": "guava"}
{"id": 298, "code": "public void testAdd_withFailures() {\n  AtomicInteger existing = new AtomicInteger(12);\n  AtomicInteger existingZero = new AtomicInteger(0);\n\n    \n  when(backingMap.get(KEY)).thenReturn(null);\n    \n  when(backingMap.putIfAbsent(eq(KEY), isA(AtomicInteger.class))).thenReturn(existingZero);\n    \n  when(backingMap.replace(eq(KEY), eq(existingZero), isA(AtomicInteger.class))).thenReturn(false);\n    \n  when(backingMap.putIfAbsent(eq(KEY), isA(AtomicInteger.class))).thenReturn(existing);\n\n    \n  when(backingMap.get(KEY)).thenReturn(existingZero);\n    \n  when(backingMap.replace(eq(KEY), eq(existingZero), isA(AtomicInteger.class))).thenReturn(false);\n  when(backingMap.putIfAbsent(eq(KEY), isA(AtomicInteger.class))).thenReturn(existing);\n\n    \n  when(backingMap.get(KEY)).thenReturn(existing);\n    \n\n  assertEquals(12, multiset.add(KEY, 3));\n  assertEquals(15, existing.get());\n}", "summary_tokens": ["simulate", "some", "of", "the", "races", "that", "can", "happen", "on", "add"], "project": "guava"}
{"id": 199, "code": "int stringBuilderIsEmpty(int reps) {\n  int dummy = 0;\n  for (int i = 0; i < reps; i++) {\n    StringBuilder sb = new StringBuilder();\n    for (String comp : components) {\n      if (sb.length() > 0) {\n        sb.append(DELIMITER_STRING);\n      }\n      sb.append(comp);\n    }\n    dummy ^= sb.toString().length();\n  }\n  return dummy;\n}", "summary_tokens": ["only", "appends", "delimiter", "if", "the", "accumulated", "string", "is", "non", "empty"], "project": "guava"}
{"id": 1732, "code": "public static String toString(long x, int radix) {\n  checkArgument(\n      radix >= Character.MIN_RADIX && radix <= Character.MAX_RADIX,\n      \"radix (%s) must be between Character.MIN_RADIX and Character.MAX_RADIX\",\n      radix);\n  if (x == 0) {\n      \n    return \"0\";\n  } else if (x > 0) {\n    return Long.toString(x, radix);\n  } else {\n    char[] buf = new char[64];\n    int i = buf.length;\n    if ((radix & (radix - 1)) == 0) {\n        \n      int shift = Integer.numberOfTrailingZeros(radix);\n      int mask = radix - 1;\n      do {\n        buf[--i] = Character.forDigit(((int) x) & mask, radix);\n        x >>>= shift;\n      } while (x != 0);\n    } else {\n        \n        \n      long quotient;\n      if ((radix & 1) == 0) {\n          \n        quotient = (x >>> 1) / (radix >>> 1);\n      } else {\n        quotient = divide(x, radix);\n      }\n      long rem = x - quotient * radix;\n      buf[--i] = Character.forDigit((int) rem, radix);\n      x = quotient;\n        \n      while (x > 0) {\n        buf[--i] = Character.forDigit((int) (x % radix), radix);\n        x /= radix;\n      }\n    }\n      \n    return new String(buf, i, buf.length - i);\n  }\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "x", "for", "the", "given", "radix", "where", "x", "is", "treated", "as", "unsigned"], "project": "guava"}
{"id": 57, "code": "public static <T> Set<T> intersection(Set<? extends T> set1, Set<? extends T> set2) {\n  Set<T> result = Helpers.<T>copyToSet(set1);\n  result.retainAll(set2);\n  return result;\n}", "summary_tokens": ["construct", "a", "new", "java"], "project": "guava"}
{"id": 1796, "code": "public final Invokable<T, T> constructor(Constructor<?> constructor) {\n  checkArgument(\n      constructor.getDeclaringClass() == getRawType(),\n      \"%s not declared by %s\",\n      constructor,\n      getRawType());\n  return new Invokable.ConstructorInvokable<T>(constructor) {\n    @Override\n    Type getGenericReturnType() {\n      return getCovariantTypeResolver().resolveType(super.getGenericReturnType());\n    }\n\n    @Override\n    Type[] getGenericParameterTypes() {\n      return getInvariantTypeResolver().resolveTypesInPlace(super.getGenericParameterTypes());\n    }\n\n    @Override\n    Type[] getGenericExceptionTypes() {\n      return getCovariantTypeResolver().resolveTypesInPlace(super.getGenericExceptionTypes());\n    }\n\n    @Override\n    public TypeToken<T> getOwnerType() {\n      return TypeToken.this;\n    }\n\n    @Override\n    public String toString() {\n      return getOwnerType() + \"(\" + Joiner.on(\", \").join(getGenericParameterTypes()) + \")\";\n    }\n  };\n}", "summary_tokens": ["returns", "the", "invokable", "for", "constructor", "which", "must", "be", "a", "member", "of", "t"], "project": "guava"}
{"id": 707, "code": "public CacheBuilder<K, V> initialCapacity(int initialCapacity) {\n  checkState(\n      this.initialCapacity == UNSET_INT,\n      \"initial capacity was already set to %s\",\n      this.initialCapacity);\n  checkArgument(initialCapacity >= 0);\n  this.initialCapacity = initialCapacity;\n  return this;\n}", "summary_tokens": ["sets", "the", "minimum", "total", "size", "for", "the", "internal", "hash", "tables"], "project": "guava"}
{"id": 1091, "code": "public static <N> Traverser<N> forGraph(SuccessorsFunction<N> graph) {\n  return new Traverser<N>(graph) {\n    @Override\n    Traversal<N> newTraversal() {\n      return Traversal.inGraph(graph);\n    }\n  };\n}", "summary_tokens": ["creates", "a", "new", "traverser", "for", "the", "given", "general", "graph"], "project": "guava"}
{"id": 1393, "code": "public static Inet4Address getEmbeddedIPv4ClientAddress(Inet6Address ip) {\n  if (isCompatIPv4Address(ip)) {\n    return getCompatIPv4Address(ip);\n  }\n\n  if (is6to4Address(ip)) {\n    return get6to4IPv4Address(ip);\n  }\n\n  if (isTeredoAddress(ip)) {\n    return getTeredoInfo(ip).getClient();\n  }\n\n  throw formatIllegalArgumentException(\"'%s' has no embedded IPv4 address.\", toAddrString(ip));\n}", "summary_tokens": ["examines", "the", "inet", "0", "address", "to", "extract", "the", "embedded", "ipv", "0", "client", "address", "if", "the", "inet", "address", "is", "an", "ipv", "0", "address", "of", "one", "of", "the", "specified", "address", "types", "that", "contain", "an", "embedded", "ipv", "0", "address"], "project": "guava"}
{"id": 518, "code": "protected void setDelays() {\n  SHORT_DELAY_MS = getShortDelay();\n  SMALL_DELAY_MS = SHORT_DELAY_MS * 5;\n  MEDIUM_DELAY_MS = SHORT_DELAY_MS * 10;\n  LONG_DELAY_MS = SHORT_DELAY_MS * 200;\n}", "summary_tokens": ["sets", "delays", "as", "multiples", "of", "short", "delay"], "project": "guava"}
{"id": 1136, "code": "public static HashFunction adler32() {\n  return ChecksumType.ADLER_32.hashFunction;\n}", "summary_tokens": ["returns", "a", "hash", "function", "implementing", "the", "adler", "0", "checksum", "algorithm", "0", "hash", "bits"], "project": "guava"}
{"id": 1904, "code": "final long reserve(int permits) {\n  checkPermits(permits);\n  synchronized (mutex()) {\n    return reserveAndGetWaitLength(permits, stopwatch.readMicros());\n  }\n}", "summary_tokens": ["reserves", "the", "given", "number", "of", "permits", "from", "this", "rate", "limiter", "for", "future", "use", "returning", "the", "number", "of", "microseconds", "until", "the", "reservation", "can", "be", "consumed"], "project": "guava"}
{"id": 1042, "code": "public static <S> ElementOrder<S> stable() {\n  return new ElementOrder<>(Type.STABLE, null);\n}", "summary_tokens": ["returns", "an", "instance", "which", "specifies", "that", "ordering", "is", "guaranteed", "to", "be", "always", "be", "the", "same", "across", "iterations", "and", "across", "releases"], "project": "guava"}
{"id": 2011, "code": "public LongStream stream() {\n  return Arrays.stream(array, start, end);\n}", "summary_tokens": ["returns", "a", "stream", "over", "the", "values", "in", "this", "array", "in", "order"], "project": "guava"}
{"id": 471, "code": "public void testGetAndSet() {\n  double prev = Math.E;\n  AtomicDouble at = new AtomicDouble(prev);\n  for (double x : VALUES) {\n    assertBitEquals(prev, at.getAndSet(x));\n    prev = x;\n  }\n}", "summary_tokens": ["get", "and", "set", "returns", "previous", "value", "and", "sets", "to", "given", "value"], "project": "guava"}
{"id": 1660, "code": "public static int compare(byte a, byte b) {\n  return a - b; \n}", "summary_tokens": ["compares", "the", "two", "specified", "byte", "values"], "project": "guava"}
{"id": 1195, "code": "protected void add(char[] cbuf, int off, int len) throws IOException {\n  int pos = off;\n  if (sawReturn && len > 0) {\n      \n    if (finishLine(cbuf[pos] == '\\n')) {\n      pos++;\n    }\n  }\n\n  int start = pos;\n  for (int end = off + len; pos < end; pos++) {\n    switch (cbuf[pos]) {\n      case '\\r':\n        line.append(cbuf, start, pos - start);\n        sawReturn = true;\n        if (pos + 1 < end) {\n          if (finishLine(cbuf[pos + 1] == '\\n')) {\n            pos++;\n          }\n        }\n        start = pos + 1;\n        break;\n\n      case '\\n':\n        line.append(cbuf, start, pos - start);\n        finishLine(true);\n        start = pos + 1;\n        break;\n\n      default:\n          \n    }\n  }\n  line.append(cbuf, start, off + len - start);\n}", "summary_tokens": ["process", "additional", "characters", "from", "the", "stream"], "project": "guava"}
{"id": 1316, "code": "public static ScaleAndIndex median() {\n  return scale(2).index(1);\n}", "summary_tokens": ["specifies", "the", "computation", "of", "a", "median", "i"], "project": "guava"}
{"id": 1505, "code": "public static int indexOf(double[] array, double[] target) {\n  checkNotNull(array, \"array\");\n  checkNotNull(target, \"target\");\n  if (target.length == 0) {\n    return 0;\n  }\n\n  outer:\n  for (int i = 0; i < array.length - target.length + 1; i++) {\n    for (int j = 0; j < target.length; j++) {\n      if (array[i + j] != target[j]) {\n        continue outer;\n      }\n    }\n    return i;\n  }\n  return -1;\n}", "summary_tokens": ["returns", "the", "start", "position", "of", "the", "first", "occurrence", "of", "the", "specified", "target", "within", "array", "or", "0", "if", "there", "is", "no", "such", "occurrence"], "project": "guava"}
{"id": 2000, "code": "private static Path getParentPath(Path path) {\n  Path parent = path.getParent();\n\n    \n  if (parent != null) {\n      \n      \n      \n      \n      \n    return parent;\n  }\n\n    \n  if (path.getNameCount() == 0) {\n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n      \n    return null;\n  } else {\n      \n    return path.getFileSystem().getPath(\".\");\n  }\n}", "summary_tokens": ["returns", "a", "path", "to", "the", "parent", "directory", "of", "the", "given", "path"], "project": "guava"}
{"id": 882, "code": "public static <K, V> Builder<K, V> builder() {\n  return new Builder<>();\n}", "summary_tokens": ["returns", "a", "new", "builder"], "project": "guava"}
{"id": 559, "code": "public void testStateOrdering() {\n    \n  assertLessThan(NEW, STARTING);\n  assertLessThan(NEW, TERMINATED);\n\n  assertLessThan(STARTING, RUNNING);\n  assertLessThan(STARTING, STOPPING);\n  assertLessThan(STARTING, FAILED);\n\n  assertLessThan(RUNNING, STOPPING);\n  assertLessThan(RUNNING, FAILED);\n\n  assertLessThan(STOPPING, FAILED);\n  assertLessThan(STOPPING, TERMINATED);\n}", "summary_tokens": ["assert", "on", "the", "comparison", "ordering", "of", "the", "state", "enum", "since", "we", "guarantee", "it"], "project": "guava"}
{"id": 260, "code": "private static <K> List<Object> doConcurrentGet(\n    final LoadingCache<K, ?> cache,\n    final K key,\n    int nThreads,\n    final CountDownLatch gettersStartedSignal)\n    throws InterruptedException {\n\n  final AtomicReferenceArray<Object> result = new AtomicReferenceArray<>(nThreads);\n  final CountDownLatch gettersComplete = new CountDownLatch(nThreads);\n  for (int i = 0; i < nThreads; i++) {\n    final int index = i;\n    Thread thread =\n        new Thread(\n            new Runnable() {\n              @Override\n              public void run() {\n                gettersStartedSignal.countDown();\n                Object value = null;\n                try {\n                  int mod = index % 3;\n                  if (mod == 0) {\n                    value = cache.get(key);\n                  } else if (mod == 1) {\n                    value = cache.getUnchecked(key);\n                  } else {\n                    cache.refresh(key);\n                    value = cache.get(key);\n                  }\n                  result.set(index, value);\n                } catch (Throwable t) {\n                  result.set(index, t);\n                }\n                gettersComplete.countDown();\n              }\n            });\n    thread.start();\n      \n      \n    while (thread.isAlive() && thread.getState() != Thread.State.WAITING) {\n      Thread.yield();\n    }\n  }\n  gettersStartedSignal.countDown();\n  gettersComplete.await();\n\n  List<Object> resultList = Lists.newArrayListWithExpectedSize(nThreads);\n  for (int i = 0; i < nThreads; i++) {\n    resultList.add(result.get(i));\n  }\n  return resultList;\n}", "summary_tokens": ["test", "helper", "method", "that", "performs", "n", "threads", "concurrent", "calls", "to", "cache"], "project": "guava"}
{"id": 1655, "code": "public static void reverse(short[] array, int fromIndex, int toIndex) {\n  checkNotNull(array);\n  checkPositionIndexes(fromIndex, toIndex, array.length);\n  for (int i = fromIndex, j = toIndex - 1; i < j; i++, j--) {\n    short tmp = array[i];\n    array[i] = array[j];\n    array[j] = tmp;\n  }\n}", "summary_tokens": ["reverses", "the", "elements", "of", "array", "between", "from", "index", "inclusive", "and", "to", "index", "exclusive"], "project": "guava"}
{"id": 1308, "code": "public PairedStats snapshot() {\n  return new PairedStats(xStats.snapshot(), yStats.snapshot(), sumOfProductsOfDeltas);\n}", "summary_tokens": ["returns", "an", "immutable", "snapshot", "of", "the", "current", "statistics"], "project": "guava"}
{"id": 121, "code": "List<Class<?>> findClassesToTest(\n    Iterable<? extends Class<?>> classes, Iterable<String> explicitTestNames) {\n    \n  TreeMap<String, Class<?>> classMap = Maps.newTreeMap();\n  for (Class<?> cls : classes) {\n    classMap.put(cls.getName(), cls);\n  }\n    \n  Multimap<Class<?>, Class<?>> testClasses = HashMultimap.create();\n  LinkedHashSet<Class<?>> candidateClasses = Sets.newLinkedHashSet();\n  for (Class<?> cls : classes) {\n    Optional<String> testedClassName = TEST_SUFFIX.chop(cls.getName());\n    if (testedClassName.isPresent()) {\n      Class<?> testedClass = classMap.get(testedClassName.get());\n      if (testedClass != null) {\n        testClasses.put(testedClass, cls);\n      }\n    } else {\n      candidateClasses.add(cls);\n    }\n  }\n  List<Class<?>> result = Lists.newArrayList();\n  NEXT_CANDIDATE:\n  for (Class<?> candidate : Iterables.filter(candidateClasses, classFilter)) {\n    for (Class<?> testClass : testClasses.get(candidate)) {\n      if (hasTest(testClass, explicitTestNames)) {\n          \n        continue NEXT_CANDIDATE;\n      }\n    }\n    result.add(candidate);\n  }\n  return result;\n}", "summary_tokens": ["finds", "the", "classes", "not", "ending", "with", "a", "test", "suffix", "and", "not", "covered", "by", "an", "explicit", "test", "whose", "name", "is", "explicit", "test", "name"], "project": "guava"}
{"id": 952, "code": "public static <C extends Comparable<?>> Range<C> greaterThan(C endpoint) {\n  return create(Cut.aboveValue(endpoint), Cut.<C>aboveAll());\n}", "summary_tokens": ["returns", "a", "range", "that", "contains", "all", "values", "strictly", "greater", "than", "endpoint"], "project": "guava"}
{"id": 1708, "code": "public static UnsignedLong valueOf(String string, int radix) {\n  return fromLongBits(UnsignedLongs.parseUnsignedLong(string, radix));\n}", "summary_tokens": ["returns", "an", "unsigned", "long", "holding", "the", "value", "of", "the", "specified", "string", "parsed", "as", "an", "unsigned", "long", "value", "in", "the", "specified", "radix"], "project": "guava"}
{"id": 770, "code": "public double doubleValue() {\n  return (double) sum();\n}", "summary_tokens": ["returns", "the", "sum", "as", "a", "double", "after", "a", "widening", "primitive", "conversion"], "project": "guava"}
{"id": 1539, "code": "public static ImmutableDoubleArray of(double first, double... rest) {\n  checkArgument(\n      rest.length <= Integer.MAX_VALUE - 1, \"the total number of elements must fit in an int\");\n  double[] array = new double[rest.length + 1];\n  array[0] = first;\n  System.arraycopy(rest, 0, array, 1, rest.length);\n  return new ImmutableDoubleArray(array);\n}", "summary_tokens": ["returns", "an", "immutable", "array", "containing", "the", "given", "values", "in", "order"], "project": "guava"}
{"id": 1905, "code": "public boolean tryAcquire(int permits, long timeout, TimeUnit unit) {\n  long timeoutMicros = max(unit.toMicros(timeout), 0);\n  checkPermits(permits);\n  long microsToWait;\n  synchronized (mutex()) {\n    long nowMicros = stopwatch.readMicros();\n    if (!canAcquire(nowMicros, timeoutMicros)) {\n      return false;\n    } else {\n      microsToWait = reserveAndGetWaitLength(permits, nowMicros);\n    }\n  }\n  stopwatch.sleepMicrosUninterruptibly(microsToWait);\n  return true;\n}", "summary_tokens": ["acquires", "the", "given", "number", "of", "permits", "from", "this", "rate", "limiter", "if", "it", "can", "be", "obtained", "without", "exceeding", "the", "specified", "timeout", "or", "returns", "false", "immediately", "without", "waiting", "if", "the", "permits", "would", "not", "have", "been", "granted", "before", "the", "timeout", "expired"], "project": "guava"}
{"id": 1068, "code": "private static <N> boolean subgraphHasCycle(\n    Graph<N> graph,\n    Map<Object, NodeVisitState> visitedNodes,\n    N node,\n    @CheckForNull N previousNode) {\n  NodeVisitState state = visitedNodes.get(node);\n  if (state == NodeVisitState.COMPLETE) {\n    return false;\n  }\n  if (state == NodeVisitState.PENDING) {\n    return true;\n  }\n\n  visitedNodes.put(node, NodeVisitState.PENDING);\n  for (N nextNode : graph.successors(node)) {\n    if (canTraverseWithoutReusingEdge(graph, nextNode, previousNode)\n        && subgraphHasCycle(graph, visitedNodes, nextNode, node)) {\n      return true;\n    }\n  }\n  visitedNodes.put(node, NodeVisitState.COMPLETE);\n  return false;\n}", "summary_tokens": ["performs", "a", "traversal", "of", "the", "nodes", "reachable", "from", "node"], "project": "guava"}
{"id": 130, "code": "private List<Object> generateEqualFactoryArguments(\n    Invokable<?, ?> factory, List<Parameter> params, List<Object> args)\n    throws ParameterNotInstantiableException, FactoryMethodReturnsNullException,\n        InvocationTargetException, IllegalAccessException {\n  List<Object> equalArgs = Lists.newArrayList(args);\n  for (int i = 0; i < args.size(); i++) {\n    Parameter param = params.get(i);\n    Object arg = args.get(i);\n      \n      \n    Object shouldBeEqualArg = generateDummyArg(param, newFreshValueGenerator());\n    if (arg != shouldBeEqualArg\n        && Objects.equal(arg, shouldBeEqualArg)\n        && hashCodeInsensitiveToArgReference(factory, args, i, shouldBeEqualArg)\n        && hashCodeInsensitiveToArgReference(\n            factory, args, i, generateDummyArg(param, newFreshValueGenerator()))) {\n        \n        \n        \n      equalArgs.set(i, shouldBeEqualArg);\n    }\n  }\n  return equalArgs;\n}", "summary_tokens": ["returns", "dummy", "factory", "arguments", "that", "are", "equal", "to", "args", "but", "may", "be", "different", "instances", "to", "be", "used", "to", "construct", "a", "second", "instance", "of", "the", "same", "equality", "group"], "project": "guava"}
{"id": 1320, "code": "private static boolean containsNaN(double... dataset) {\n  for (double value : dataset) {\n    if (Double.isNaN(value)) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "whether", "any", "of", "the", "values", "in", "dataset", "are", "na", "n"], "project": "guava"}
{"id": 1560, "code": "public int get(int index) {\n  Preconditions.checkElementIndex(index, length());\n  return array[start + index];\n}", "summary_tokens": ["returns", "the", "int", "value", "present", "at", "the", "given", "index"], "project": "guava"}
{"id": 741, "code": "public double loadExceptionRate() {\n  long totalLoadCount = saturatedAdd(loadSuccessCount, loadExceptionCount);\n  return (totalLoadCount == 0) ? 0.0 : (double) loadExceptionCount / totalLoadCount;\n}", "summary_tokens": ["returns", "the", "ratio", "of", "cache", "loading", "attempts", "which", "threw", "exceptions"], "project": "guava"}
{"id": 1541, "code": "public static Builder builder() {\n  return new Builder(10);\n}", "summary_tokens": ["returns", "a", "new", "empty", "builder", "for", "immutable", "double", "array", "instances", "with", "a", "default", "initial", "capacity"], "project": "guava"}
{"id": 1108, "code": "static long hash128to64(long high, long low) {\n  long a = (low ^ high) * K3;\n  a ^= (a >>> 47);\n  long b = (high ^ a) * K3;\n  b ^= (b >>> 47);\n  b *= K3;\n  return b;\n}", "summary_tokens": ["implementation", "of", "hash", "0", "to", "0", "from", "util", "hash", "hash", "0", "to", "0"], "project": "guava"}
{"id": 1511, "code": "public static Converter<String, Double> stringConverter() {\n  return DoubleConverter.INSTANCE;\n}", "summary_tokens": ["returns", "a", "serializable", "converter", "object", "that", "converts", "between", "strings", "and", "doubles", "using", "double", "value", "of", "and", "double", "to", "string"], "project": "guava"}
{"id": 1832, "code": "public final void set(int i, double newValue) {\n  long next = doubleToRawLongBits(newValue);\n  longs.set(i, next);\n}", "summary_tokens": ["atomically", "sets", "the", "element", "at", "position", "i", "to", "the", "given", "value"], "project": "guava"}
{"id": 203, "code": "void setUp() {\n  final long seed = 99;\n  final Random rnd = new Random(seed);\n  strings = new String[SAMPLES];\n  for (int i = 0; i < SAMPLES; i++) {\n    StringBuilder sb = new StringBuilder();\n    for (int j = 0; j < charCount; j++) {\n      int codePoint;\n        \n      do {\n        codePoint = rnd.nextInt(maxCodePoint.value);\n      } while (Character.isSurrogate((char) codePoint));\n      sb.appendCodePoint(codePoint);\n    }\n    strings[i] = sb.toString();\n  }\n}", "summary_tokens": ["compute", "arrays", "of", "valid", "unicode", "text", "and", "store", "it", "in", "0", "forms", "byte", "arrays", "strings", "and", "string", "builders", "in", "a", "char", "sequence", "to", "make", "it", "a", "little", "harder", "for", "the", "jvm"], "project": "guava"}
{"id": 48, "code": "public List<String> order(List<String> insertionOrder) {\n  return insertionOrder;\n}", "summary_tokens": ["returns", "the", "original", "element", "list", "unchanged"], "project": "guava"}
{"id": 963, "code": "public BoundType upperBoundType() {\n  return upperBound.typeAsUpperBound();\n}", "summary_tokens": ["returns", "the", "type", "of", "this", "range", "s", "upper", "bound", "bound", "type", "closed", "if", "the", "range", "includes", "its", "upper", "endpoint", "bound", "type", "open", "if", "it", "does", "not"], "project": "guava"}
{"id": 1777, "code": "public Type resolveType(Type type) {\n  checkNotNull(type);\n  if (type instanceof TypeVariable) {\n    return typeTable.resolve((TypeVariable<?>) type);\n  } else if (type instanceof ParameterizedType) {\n    return resolveParameterizedType((ParameterizedType) type);\n  } else if (type instanceof GenericArrayType) {\n    return resolveGenericArrayType((GenericArrayType) type);\n  } else if (type instanceof WildcardType) {\n    return resolveWildcardType((WildcardType) type);\n  } else {\n      \n    return type;\n  }\n}", "summary_tokens": ["resolves", "all", "type", "variables", "in", "type", "and", "all", "downstream", "types", "and", "returns", "a", "corresponding", "type", "with", "type", "variables", "resolved"], "project": "guava"}
{"id": 1059, "code": "public static GraphBuilder<Object> undirected() {\n  return new GraphBuilder<>(false);\n}", "summary_tokens": ["returns", "a", "graph", "builder", "for", "building", "undirected", "graphs"], "project": "guava"}
{"id": 112, "code": "public static void assertUnescaped(UnicodeEscaper escaper, int cp) {\n  Assert.assertNull(computeReplacement(escaper, cp));\n}", "summary_tokens": ["asserts", "that", "a", "unicode", "escaper", "does", "not", "escape", "the", "given", "character"], "project": "guava"}
{"id": 258, "code": "private static void testConcurrentLoadingUncheckedException(CacheBuilder<Object, Object> builder)\n    throws InterruptedException {\n\n  int count = 10;\n  final AtomicInteger callCount = new AtomicInteger();\n  final CountDownLatch startSignal = new CountDownLatch(count + 1);\n  final RuntimeException e = new RuntimeException();\n\n  LoadingCache<String, String> cache =\n      builder.build(\n          new CacheLoader<String, String>() {\n            @Override\n            public String load(String key) throws InterruptedException {\n              callCount.incrementAndGet();\n              startSignal.await();\n              throw e;\n            }\n          });\n\n  List<Object> result = doConcurrentGet(cache, \"bar\", count, startSignal);\n\n  assertEquals(1, callCount.get());\n  for (int i = 0; i < count; i++) {\n      \n      \n    assertThat(result.get(i)).isInstanceOf(UncheckedExecutionException.class);\n    assertThat(((UncheckedExecutionException) result.get(i))).hasCauseThat().isSameInstanceAs(e);\n  }\n\n    \n  try {\n    cache.getUnchecked(\"bar\");\n    fail();\n  } catch (UncheckedExecutionException expected) {\n  }\n  assertEquals(2, callCount.get());\n}", "summary_tokens": ["on", "a", "concurrent", "computation", "that", "throws", "an", "unchecked", "exception", "all", "threads", "should", "get", "the", "wrapped", "exception", "with", "the", "loader", "called", "only", "once"], "project": "guava"}
{"id": 954, "code": "public static <C extends Comparable<?>> Range<C> downTo(C endpoint, BoundType boundType) {\n  switch (boundType) {\n    case OPEN:\n      return greaterThan(endpoint);\n    case CLOSED:\n      return atLeast(endpoint);\n    default:\n      throw new AssertionError();\n  }\n}", "summary_tokens": ["returns", "a", "range", "from", "the", "given", "endpoint", "which", "may", "be", "either", "inclusive", "closed", "or", "exclusive", "open", "with", "no", "upper", "bound"], "project": "guava"}
{"id": 56, "code": "private static TesterRequirements incorporateRequirements(\n    TesterRequirements requirements, TesterRequirements moreRequirements, Object source)\n    throws ConflictingRequirementsException {\n  Set<Feature<?>> presentFeatures = requirements.getPresentFeatures();\n  Set<Feature<?>> absentFeatures = requirements.getAbsentFeatures();\n  Set<Feature<?>> morePresentFeatures = moreRequirements.getPresentFeatures();\n  Set<Feature<?>> moreAbsentFeatures = moreRequirements.getAbsentFeatures();\n  checkConflict(\"absent\", absentFeatures, \"present\", morePresentFeatures, source);\n  checkConflict(\"present\", presentFeatures, \"absent\", moreAbsentFeatures, source);\n  presentFeatures.addAll(morePresentFeatures);\n  absentFeatures.addAll(moreAbsentFeatures);\n  return requirements;\n}", "summary_tokens": ["incorporate", "additional", "requirements", "into", "an", "existing", "requirements", "object"], "project": "guava"}
{"id": 653, "code": "public static void checkPositionIndexes(int start, int end, int size) {\n    \n  if (start < 0 || end < start || end > size) {\n    throw new IndexOutOfBoundsException(badPositionIndexes(start, end, size));\n  }\n}", "summary_tokens": ["ensures", "that", "start", "and", "end", "specify", "valid", "i", "positions", "i", "in", "an", "array", "list", "or", "string", "of", "size", "size", "and", "are", "in", "order"], "project": "guava"}
{"id": 38, "code": "SortedSetTestSuiteBuilder<E> newBuilderUsing(\n    TestSortedSetGenerator<E> delegate, Bound to, Bound from) {\n  return using(new SortedSetSubsetTestSetGenerator<E>(delegate, to, from));\n}", "summary_tokens": ["like", "using", "but", "overrideable", "by", "navigable", "set", "test", "suite", "builder"], "project": "guava"}
{"id": 1066, "code": "public <N1 extends N> MutableGraph<N1> build() {\n  return new StandardMutableGraph<>(this);\n}", "summary_tokens": ["returns", "an", "empty", "mutable", "graph", "with", "the", "properties", "of", "this", "graph", "builder"], "project": "guava"}
{"id": 1815, "code": "public final double get() {\n  return longBitsToDouble(value);\n}", "summary_tokens": ["gets", "the", "current", "value"], "project": "guava"}
{"id": 673, "code": "public static String padStart(String string, int minLength, char padChar) {\n  checkNotNull(string); \n  if (string.length() >= minLength) {\n    return string;\n  }\n  StringBuilder sb = new StringBuilder(minLength);\n  for (int i = string.length(); i < minLength; i++) {\n    sb.append(padChar);\n  }\n  sb.append(string);\n  return sb.toString();\n}", "summary_tokens": ["returns", "a", "string", "of", "length", "at", "least", "min", "length", "consisting", "of", "string", "prepended", "with", "as", "many", "copies", "of", "pad", "char", "as", "are", "necessary", "to", "reach", "that", "length"], "project": "guava"}
{"id": 744, "code": "public long evictionCount() {\n  return evictionCount;\n}", "summary_tokens": ["returns", "the", "number", "of", "times", "an", "entry", "has", "been", "evicted"], "project": "guava"}
{"id": 417, "code": "public void testPlusForSpace() {\n  UnicodeEscaper basicEscaper = new PercentEscaper(\"\", false);\n  UnicodeEscaper plusForSpaceEscaper = new PercentEscaper(\"\", true);\n  UnicodeEscaper spaceEscaper = new PercentEscaper(\" \", false);\n\n  assertEquals(\"string%20with%20spaces\", basicEscaper.escape(\"string with spaces\"));\n  assertEquals(\"string+with+spaces\", plusForSpaceEscaper.escape(\"string with spaces\"));\n  assertEquals(\"string with spaces\", spaceEscaper.escape(\"string with spaces\"));\n}", "summary_tokens": ["tests", "the", "various", "ways", "that", "the", "space", "character", "can", "be", "handled"], "project": "guava"}
{"id": 482, "code": "static URL[] getClassPathUrls() {\n  return ClassPathUtil.class.getClassLoader() instanceof URLClassLoader\n      ? ((URLClassLoader) ClassPathUtil.class.getClassLoader()).getURLs()\n      : parseJavaClassPath();\n}", "summary_tokens": ["returns", "the", "urls", "in", "the", "class", "path"], "project": "guava"}
{"id": 441, "code": "public void testToString_delayedTimeout() throws Exception {\n  TimedWaiterThread thread =\n      new TimedWaiterThread(new AbstractFuture<Object>() {}, 2, TimeUnit.SECONDS);\n  thread.start();\n  thread.awaitWaiting();\n  thread.suspend();\n    \n  long toWaitMillis = 3500 - TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - thread.startTime);\n  Thread.sleep(toWaitMillis);\n  thread.setPriority(Thread.MAX_PRIORITY);\n  thread.resume();\n  thread.join();\n    \n    \n    \n    \n    \n  boolean longWait = TimeUnit.NANOSECONDS.toSeconds(thread.timeSpentBlocked) >= 5;\n    \n    \n  char overWaitNanosFirstDigit =\n      Long.toString(\n              thread.timeSpentBlocked - TimeUnit.MILLISECONDS.toNanos(longWait ? 5000 : 3000))\n          .charAt(0);\n  if (overWaitNanosFirstDigit < '4') {\n    overWaitNanosFirstDigit = '9';\n  }\n  String nanosRegex = \"[4-\" + overWaitNanosFirstDigit + \"][0-9]+\";\n  assertWithMessage(\n          \"Spent \" + thread.timeSpentBlocked + \" ns blocked; slept for \" + toWaitMillis + \" ms\")\n      .that(thread.exception)\n      .hasMessageThat()\n      .matches(\n          \"Waited 2 seconds \\\\(plus \"\n              + (longWait ? \"3\" : \"1\")\n              + \" seconds, \"\n              + nanosRegex\n              + \" nanoseconds delay\\\\).*\");\n}", "summary_tokens": ["this", "test", "attempts", "to", "cause", "a", "future", "to", "wait", "for", "longer", "than", "it", "was", "requested", "to", "from", "a", "timed", "get", "call"], "project": "guava"}
{"id": 1839, "code": "public String toString() {\n  int iMax = length() - 1;\n  if (iMax == -1) {\n    return \"[]\";\n  }\n\n    \n  StringBuilder b = new StringBuilder((17 + 2) * (iMax + 1));\n  b.append('[');\n  for (int i = 0; ; i++) {\n    b.append(longBitsToDouble(longs.get(i)));\n    if (i == iMax) {\n      return b.append(']').toString();\n    }\n    b.append(',').append(' ');\n  }\n}", "summary_tokens": ["returns", "the", "string", "representation", "of", "the", "current", "values", "of", "array"], "project": "guava"}
{"id": 351, "code": "public void putEdge_nodesNotInGraph() {\n  assume().that(graphIsMutable()).isTrue();\n\n  graphAsMutableGraph.addNode(N1);\n  assertTrue(graphAsMutableGraph.putEdge(N1, N5));\n  assertTrue(graphAsMutableGraph.putEdge(N4, N1));\n  assertTrue(graphAsMutableGraph.putEdge(N2, N3));\n  assertThat(graph.nodes()).containsExactly(N1, N5, N4, N2, N3).inOrder();\n  assertThat(graph.adjacentNodes(N1)).containsExactly(N4, N5);\n  assertThat(graph.adjacentNodes(N2)).containsExactly(N3);\n  assertThat(graph.adjacentNodes(N3)).containsExactly(N2);\n  assertThat(graph.adjacentNodes(N4)).containsExactly(N1);\n  assertThat(graph.adjacentNodes(N5)).containsExactly(N1);\n}", "summary_tokens": ["tests", "that", "the", "method", "put", "edge", "will", "silently", "add", "the", "missing", "nodes", "to", "the", "graph", "then", "add", "the", "edge", "connecting", "them"], "project": "guava"}
{"id": 1932, "code": "protected Entry<E> standardPollFirstEntry() {\n  Iterator<Entry<E>> entryIterator = entrySet().iterator();\n  if (!entryIterator.hasNext()) {\n    return null;\n  }\n  Entry<E> entry = entryIterator.next();\n  entry = Multisets.immutableEntry(entry.getElement(), entry.getCount());\n  entryIterator.remove();\n  return entry;\n}", "summary_tokens": ["a", "sensible", "definition", "of", "poll", "first", "entry", "in", "terms", "of", "entry", "set"], "project": "guava"}
{"id": 911, "code": "public MapMaker concurrencyLevel(int concurrencyLevel) {\n  checkState(\n      this.concurrencyLevel == UNSET_INT,\n      \"concurrency level was already set to %s\",\n      this.concurrencyLevel);\n  checkArgument(concurrencyLevel > 0);\n  this.concurrencyLevel = concurrencyLevel;\n  return this;\n}", "summary_tokens": ["guides", "the", "allowed", "concurrency", "among", "update", "operations"], "project": "guava"}
{"id": 1095, "code": "public final Iterable<N> depthFirstPostOrder(Iterable<? extends N> startNodes) {\n  ImmutableSet<N> validated = validate(startNodes);\n  return new Iterable<N>() {\n    @Override\n    public Iterator<N> iterator() {\n      return newTraversal().postOrder(validated.iterator());\n    }\n  };\n}", "summary_tokens": ["returns", "an", "unmodifiable", "iterable", "over", "the", "nodes", "reachable", "from", "any", "of", "the", "start", "nodes", "in", "the", "order", "of", "a", "depth", "first", "post", "order", "traversal"], "project": "guava"}
{"id": 1472, "code": "public static boolean contains(byte[] array, byte target) {\n  for (byte value : array) {\n    if (value == target) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "true", "if", "target", "is", "present", "as", "an", "element", "anywhere", "in", "array"], "project": "guava"}
{"id": 1845, "code": "public long decrementAndGet(K key) {\n  return addAndGet(key, -1);\n}", "summary_tokens": ["decrements", "by", "one", "the", "value", "currently", "associated", "with", "key", "and", "returns", "the", "new", "value"], "project": "guava"}
{"id": 1756, "code": "public final boolean isFinal() {\n  return Modifier.isFinal(getModifiers());\n}", "summary_tokens": ["returns", "true", "if", "this", "method", "is", "final", "per", "modifier"], "project": "guava"}
{"id": 333, "code": "public void testPowerSetHashCode_inputHashCodeTimesTooFarValueIsZero() {\n  Set<Object> sumToEighthMaxIntElements =\n      newHashSet(objectWithHashCode(1 << 29), objectWithHashCode(0));\n  assertPowerSetHashCode(1 << 30, sumToEighthMaxIntElements);\n\n  Set<Object> sumToQuarterMaxIntElements =\n      newHashSet(objectWithHashCode(1 << 30), objectWithHashCode(0));\n  assertPowerSetHashCode(1 << 31, sumToQuarterMaxIntElements);\n}", "summary_tokens": ["test", "that", "a", "hash", "code", "miscomputed", "by", "input"], "project": "guava"}
{"id": 1718, "code": "public BigInteger bigIntegerValue() {\n  BigInteger bigInt = BigInteger.valueOf(value & UNSIGNED_MASK);\n  if (value < 0) {\n    bigInt = bigInt.setBit(Long.SIZE - 1);\n  }\n  return bigInt;\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "unsigned", "long", "as", "a", "big", "integer"], "project": "guava"}
{"id": 1484, "code": "public static boolean contains(char[] array, char target) {\n  for (char value : array) {\n    if (value == target) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "true", "if", "target", "is", "present", "as", "an", "element", "anywhere", "in", "array"], "project": "guava"}
{"id": 73, "code": "public List<String> order(List<String> insertionOrder) {\n  return insertionOrder;\n}", "summary_tokens": ["returns", "the", "original", "element", "list", "unchanged"], "project": "guava"}
{"id": 1841, "code": "private void readObject(java.io.ObjectInputStream s)\n    throws java.io.IOException, ClassNotFoundException {\n  s.defaultReadObject();\n\n  int length = s.readInt();\n  ImmutableLongArray.Builder builder = ImmutableLongArray.builder();\n  for (int i = 0; i < length; i++) {\n    builder.add(doubleToRawLongBits(s.readDouble()));\n  }\n  this.longs = new AtomicLongArray(builder.build().toArray());\n}", "summary_tokens": ["reconstitutes", "the", "instance", "from", "a", "stream", "that", "is", "deserializes", "it"], "project": "guava"}
{"id": 1754, "code": "public final boolean isPrivate() {\n  return Modifier.isPrivate(getModifiers());\n}", "summary_tokens": ["returns", "true", "if", "the", "element", "is", "private"], "project": "guava"}
{"id": 531, "code": "void joinPool(ExecutorService exec) {\n  try {\n    exec.shutdown();\n    assertTrue(\n        \"ExecutorService did not terminate in a timely manner\",\n        exec.awaitTermination(2 * LONG_DELAY_MS, MILLISECONDS));\n  } catch (SecurityException ok) {\n      \n  } catch (InterruptedException ie) {\n    fail(\"Unexpected InterruptedException\");\n  }\n}", "summary_tokens": ["waits", "out", "termination", "of", "a", "thread", "pool", "or", "fails", "doing", "so"], "project": "guava"}
{"id": 979, "code": "final void checkNoDuplicate(R rowKey, C columnKey, @CheckForNull V existingValue, V newValue) {\n  checkArgument(\n      existingValue == null,\n      \"Duplicate key: (row=%s, column=%s), values: [%s, %s].\",\n      rowKey,\n      columnKey,\n      newValue,\n      existingValue);\n}", "summary_tokens": ["illegal", "argument", "exception", "if", "existing", "value", "is", "not", "null"], "project": "guava"}
{"id": 1800, "code": "private Type getOwnerTypeIfPresent() {\n  if (runtimeType instanceof ParameterizedType) {\n    return ((ParameterizedType) runtimeType).getOwnerType();\n  } else if (runtimeType instanceof Class<?>) {\n    return ((Class<?>) runtimeType).getEnclosingClass();\n  } else {\n    return null;\n  }\n}", "summary_tokens": ["returns", "the", "owner", "type", "of", "a", "parameterized", "type", "or", "enclosing", "class", "of", "a", "class", "or", "null", "otherwise"], "project": "guava"}
{"id": 474, "code": "public void testSerialization() throws Exception {\n  AtomicDouble a = new AtomicDouble();\n  AtomicDouble b = serialClone(a);\n  assertNotSame(a, b);\n  a.set(-22.0);\n  AtomicDouble c = serialClone(a);\n  assertNotSame(b, c);\n  assertBitEquals(-22.0, a.get());\n  assertBitEquals(0.0, b.get());\n  assertBitEquals(-22.0, c.get());\n  for (double x : VALUES) {\n    AtomicDouble d = new AtomicDouble(x);\n    assertBitEquals(serialClone(d).get(), d.get());\n  }\n}", "summary_tokens": ["a", "deserialized", "serialized", "atomic", "holds", "same", "value"], "project": "guava"}
{"id": 1524, "code": "public static int indexOf(float[] array, float[] target) {\n  checkNotNull(array, \"array\");\n  checkNotNull(target, \"target\");\n  if (target.length == 0) {\n    return 0;\n  }\n\n  outer:\n  for (int i = 0; i < array.length - target.length + 1; i++) {\n    for (int j = 0; j < target.length; j++) {\n      if (array[i + j] != target[j]) {\n        continue outer;\n      }\n    }\n    return i;\n  }\n  return -1;\n}", "summary_tokens": ["returns", "the", "start", "position", "of", "the", "first", "occurrence", "of", "the", "specified", "target", "within", "array", "or", "0", "if", "there", "is", "no", "such", "occurrence"], "project": "guava"}
{"id": 540, "code": "long millisElapsedSince(long startNanoTime) {\n  return NANOSECONDS.toMillis(System.nanoTime() - startNanoTime);\n}", "summary_tokens": ["returns", "the", "number", "of", "milliseconds", "since", "time", "given", "by", "start", "nano", "time", "which", "must", "have", "been", "previously", "returned", "from", "a", "call", "to", "system", "nano", "time"], "project": "guava"}
{"id": 1368, "code": "private static boolean isValidPort(int port) {\n  return port >= 0 && port <= 65535;\n}", "summary_tokens": ["return", "true", "for", "valid", "port", "numbers"], "project": "guava"}
{"id": 415, "code": "private static void checkBigIntegerConversion(String ip, BigInteger bigIntegerIp) {\n  InetAddress address = InetAddresses.forString(ip);\n  boolean isIpv6 = address instanceof Inet6Address;\n  assertEquals(bigIntegerIp, InetAddresses.toBigInteger(address));\n  assertEquals(\n      address,\n      isIpv6\n          ? InetAddresses.fromIPv6BigInteger(bigIntegerIp)\n          : InetAddresses.fromIPv4BigInteger(bigIntegerIp));\n}", "summary_tokens": ["checks", "that", "the", "ip", "converts", "to", "the", "big", "integer", "and", "the", "big", "integer", "converts", "to", "the", "ip"], "project": "guava"}
{"id": 178, "code": "public static ListeningScheduledExecutorService noOpScheduledExecutor() {\n  return new NoOpScheduledExecutorService();\n}", "summary_tokens": ["returns", "a", "scheduled", "executor", "service", "that", "never", "executes", "anything"], "project": "guava"}
{"id": 1901, "code": "public final void setRate(double permitsPerSecond) {\n  checkArgument(\n      permitsPerSecond > 0.0 && !Double.isNaN(permitsPerSecond), \"rate must be positive\");\n  synchronized (mutex()) {\n    doSetRate(permitsPerSecond, stopwatch.readMicros());\n  }\n}", "summary_tokens": ["updates", "the", "stable", "rate", "of", "this", "rate", "limiter", "that", "is", "the", "permits", "per", "second", "argument", "provided", "in", "the", "factory", "method", "that", "constructed", "the", "rate", "limiter"], "project": "guava"}
{"id": 950, "code": "public static <C extends Comparable<?>> Range<C> atMost(C endpoint) {\n  return create(Cut.<C>belowAll(), Cut.aboveValue(endpoint));\n}", "summary_tokens": ["returns", "a", "range", "that", "contains", "all", "values", "less", "than", "or", "equal", "to", "endpoint"], "project": "guava"}
{"id": 1555, "code": "public static ImmutableIntArray of(int first, int... rest) {\n  checkArgument(\n      rest.length <= Integer.MAX_VALUE - 1, \"the total number of elements must fit in an int\");\n  int[] array = new int[rest.length + 1];\n  array[0] = first;\n  System.arraycopy(rest, 0, array, 1, rest.length);\n  return new ImmutableIntArray(array);\n}", "summary_tokens": ["returns", "an", "immutable", "array", "containing", "the", "given", "values", "in", "order"], "project": "guava"}
{"id": 1307, "code": "public void addAll(PairedStats values) {\n  if (values.count() == 0) {\n    return;\n  }\n\n  xStats.addAll(values.xStats());\n  if (yStats.count() == 0) {\n    sumOfProductsOfDeltas = values.sumOfProductsOfDeltas();\n  } else {\n      \n      \n      \n    sumOfProductsOfDeltas +=\n        values.sumOfProductsOfDeltas()\n            + (values.xStats().mean() - xStats.mean())\n                * (values.yStats().mean() - yStats.mean())\n                * values.count();\n  }\n  yStats.addAll(values.yStats());\n}", "summary_tokens": ["adds", "the", "given", "statistics", "to", "the", "dataset", "as", "if", "the", "individual", "values", "used", "to", "compute", "the", "statistics", "had", "been", "added", "directly"], "project": "guava"}
{"id": 222, "code": "public Comparator<? super E> comparator() {\n  return q.comparator();\n}", "summary_tokens": ["returns", "the", "comparator", "used", "to", "order", "the", "elements", "in", "this", "queue", "or", "null", "if", "this", "queue", "uses", "the", "comparable", "natural", "ordering", "of", "its", "elements"], "project": "guava"}
{"id": 13, "code": "protected void expectNullKeyMissingWhenNullKeysUnsupported(String message) {\n  try {\n    assertFalse(message, getMap().containsKey(null));\n  } catch (NullPointerException tolerated) {\n      \n  }\n}", "summary_tokens": ["equivalent", "to", "expect", "missing", "keys", "object", "expect", "missing", "keys", "null", "except", "that", "the", "call", "to", "contains", "null", "is", "permitted", "to", "throw", "a", "null", "pointer", "exception"], "project": "guava"}
{"id": 797, "code": "private void readObject(ObjectInputStream stream) throws IOException, ClassNotFoundException {\n  stream.defaultReadObject();\n  @SuppressWarnings(\"unchecked\") \n  Class<E> localType = (Class<E>) stream.readObject();\n  type = localType;\n  enumConstants = type.getEnumConstants();\n  counts = new int[enumConstants.length];\n  Serialization.populateMultiset(this, stream);\n}", "summary_tokens": ["the", "class", "e", "for", "the", "enum", "type", "the", "number", "of", "distinct", "elements", "the", "first", "element", "its", "count", "the", "second", "element", "its", "count", "and", "so", "on"], "project": "guava"}
{"id": 41, "code": "public Iterable<Entry<AnEnum, String>> order(List<Entry<AnEnum, String>> insertionOrder) {\n  return orderEntriesByKey(insertionOrder);\n}", "summary_tokens": ["returns", "the", "elements", "sorted", "in", "natural", "order"], "project": "guava"}
{"id": 1967, "code": "public void testUpdateAndGetWithSubtract() {\n  for (double x : VALUES) {\n    for (double y : VALUES) {\n      AtomicDouble a = new AtomicDouble(x);\n      double z = a.updateAndGet(value -> value - y);\n      assertBitEquals(x - y, z);\n      assertBitEquals(x - y, a.get());\n    }\n  }\n}", "summary_tokens": ["update", "and", "get", "with", "subtract", "stores", "subtraction", "of", "value", "from", "current", "and", "returns", "current", "value"], "project": "guava"}
{"id": 1225, "code": "public static BigInteger floorPowerOfTwo(BigInteger x) {\n  return BigInteger.ZERO.setBit(log2(x, FLOOR));\n}", "summary_tokens": ["returns", "the", "largest", "power", "of", "two", "less", "than", "or", "equal", "to", "x"], "project": "guava"}
{"id": 1827, "code": "public double doubleValue() {\n  return get();\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "atomic", "double", "as", "a", "double"], "project": "guava"}
{"id": 1846, "code": "public long addAndGet(K key, long delta) {\n  return accumulateAndGet(key, delta, Long::sum);\n}", "summary_tokens": ["adds", "delta", "to", "the", "value", "currently", "associated", "with", "key", "and", "returns", "the", "new", "value"], "project": "guava"}
{"id": 1077, "code": "public static <N, V> ImmutableValueGraph<N, V> copyOf(ImmutableValueGraph<N, V> graph) {\n  return checkNotNull(graph);\n}", "summary_tokens": ["simply", "returns", "its", "argument"], "project": "guava"}
{"id": 836, "code": "private void writeObject(ObjectOutputStream stream) throws IOException {\n  stream.defaultWriteObject();\n  Serialization.writeMultimap(this, stream);\n}", "summary_tokens": ["number", "of", "distinct", "keys", "and", "then", "for", "each", "distinct", "key", "the", "key", "the", "number", "of", "values", "for", "that", "key", "and", "the", "key", "s", "values"], "project": "guava"}
{"id": 723, "code": "public static CacheBuilderSpec parse(String cacheBuilderSpecification) {\n  CacheBuilderSpec spec = new CacheBuilderSpec(cacheBuilderSpecification);\n  if (!cacheBuilderSpecification.isEmpty()) {\n    for (String keyValuePair : KEYS_SPLITTER.split(cacheBuilderSpecification)) {\n      List<String> keyAndValue = ImmutableList.copyOf(KEY_VALUE_SPLITTER.split(keyValuePair));\n      checkArgument(!keyAndValue.isEmpty(), \"blank key-value pair\");\n      checkArgument(\n          keyAndValue.size() <= 2,\n          \"key-value pair %s with more than one equals sign\",\n          keyValuePair);\n\n        \n      String key = keyAndValue.get(0);\n      ValueParser valueParser = VALUE_PARSERS.get(key);\n      checkArgument(valueParser != null, \"unknown key %s\", key);\n\n      String value = keyAndValue.size() == 1 ? null : keyAndValue.get(1);\n      valueParser.parse(spec, key, value);\n    }\n  }\n\n  return spec;\n}", "summary_tokens": ["creates", "a", "cache", "builder", "spec", "from", "a", "string"], "project": "guava"}
{"id": 923, "code": "E getEntry(@Nullable Object key) {\n  if (key == null) {\n    return null;\n  }\n  int hash = hash(key);\n  return segmentFor(hash).getEntry(key, hash);\n}", "summary_tokens": ["returns", "the", "internal", "entry", "for", "the", "specified", "key"], "project": "guava"}
{"id": 136, "code": "public EquivalenceTester<T> addEquivalenceGroup(T first, T... rest) {\n  addEquivalenceGroup(Lists.asList(first, rest));\n  return this;\n}", "summary_tokens": ["adds", "a", "group", "of", "objects", "that", "are", "supposed", "to", "be", "equivalent", "to", "each", "other", "and", "not", "equivalent", "to", "objects", "in", "any", "other", "equivalence", "group", "added", "to", "this", "tester"], "project": "guava"}
{"id": 1749, "code": "public void putAll(Map<? extends TypeToken<? extends B>, ? extends B> map) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "map", "unmodified"], "project": "guava"}
{"id": 914, "code": "public <K, V> ConcurrentMap<K, V> makeMap() {\n  if (!useCustomMap) {\n    return new ConcurrentHashMap<>(getInitialCapacity(), 0.75f, getConcurrencyLevel());\n  }\n  return MapMakerInternalMap.create(this);\n}", "summary_tokens": ["builds", "a", "thread", "safe", "map"], "project": "guava"}
{"id": 378, "code": "public void testConsistentHash_linearCongruentialGeneratorCompatibility() {\n  int[] golden100 = {\n    0, 55, 62, 8, 45, 59, 86, 97, 82, 59,\n    73, 37, 17, 56, 86, 21, 90, 37, 38, 83\n  };\n  for (int i = 0; i < golden100.length; i++) {\n    assertEquals(golden100[i], Hashing.consistentHash(i, 100));\n  }\n  assertEquals(6, Hashing.consistentHash(10863919174838991L, 11));\n  assertEquals(3, Hashing.consistentHash(2016238256797177309L, 11));\n  assertEquals(5, Hashing.consistentHash(1673758223894951030L, 11));\n  assertEquals(80343, Hashing.consistentHash(2, 100001));\n  assertEquals(22152, Hashing.consistentHash(2201, 100001));\n  assertEquals(15018, Hashing.consistentHash(2202, 100001));\n}", "summary_tokens": ["check", "a", "few", "golden", "values", "to", "see", "that", "implementations", "across", "languages", "are", "equivalent"], "project": "guava"}
{"id": 1960, "code": "public void testGetAndAccumulateWithSum() {\n  for (double x : VALUES) {\n    for (double y : VALUES) {\n      AtomicDouble a = new AtomicDouble(x);\n      double z = a.getAndAccumulate(y, Double::sum);\n      assertBitEquals(x, z);\n      assertBitEquals(x + y, a.get());\n    }\n  }\n}", "summary_tokens": ["get", "and", "accumulate", "with", "sum", "adds", "given", "value", "to", "current", "and", "returns", "previous", "value"], "project": "guava"}
{"id": 1915, "code": "public ImmutableSetMultimap<State, Service> servicesByState() {\n  return state.servicesByState();\n}", "summary_tokens": ["provides", "a", "snapshot", "of", "the", "current", "state", "of", "all", "the", "services", "under", "management"], "project": "guava"}
{"id": 1189, "code": "synchronized File getFile() {\n  return file;\n}", "summary_tokens": ["returns", "the", "file", "holding", "the", "data", "possibly", "null"], "project": "guava"}
{"id": 268, "code": "static void checkEviction(Cache<?, ?> cache) {\n  if (hasLocalCache(cache)) {\n    checkEviction(toLocalCache(cache));\n  }\n}", "summary_tokens": ["peeks", "into", "the", "cache", "s", "internals", "to", "verify", "that", "its", "eviction", "queue", "is", "consistent"], "project": "guava"}
{"id": 306, "code": "public void testReplaceValuesRandomAccess() {\n  Multimap<String, Integer> multimap = create();\n  multimap.put(\"foo\", 1);\n  multimap.put(\"foo\", 3);\n  assertTrue(multimap.replaceValues(\"foo\", Arrays.asList(2, 4)) instanceof RandomAccess);\n  assertTrue(multimap.replaceValues(\"bar\", Arrays.asList(2, 4)) instanceof RandomAccess);\n}", "summary_tokens": ["confirm", "that", "replace", "values", "returns", "a", "list", "that", "implements", "random", "access", "even", "though", "get", "doesn", "t"], "project": "guava"}
{"id": 1598, "code": "public static byte[] toByteArray(int value) {\n  return new byte[] {\n    (byte) (value >> 24), (byte) (value >> 16), (byte) (value >> 8), (byte) value\n  };\n}", "summary_tokens": ["returns", "a", "big", "endian", "representation", "of", "value", "in", "a", "0", "element", "byte", "array", "equivalent", "to", "byte", "buffer"], "project": "guava"}
{"id": 547, "code": "public void testInvokeAnyImpl_nullElement() throws Exception {\n  ListeningExecutorService e = newDirectExecutorService();\n  List<Callable<Integer>> l = new ArrayList<>();\n  l.add(\n      new Callable<Integer>() {\n        @Override\n        public Integer call() {\n          throw new ArithmeticException(\"/ by zero\");\n        }\n      });\n  l.add(null);\n  try {\n    invokeAnyImpl(e, l, false, 0, TimeUnit.NANOSECONDS);\n    fail();\n  } catch (NullPointerException success) {\n  } finally {\n    joinPool(e);\n  }\n}", "summary_tokens": ["invoke", "any", "c", "throws", "npe", "if", "c", "has", "null", "elements"], "project": "guava"}
{"id": 1971, "code": "public java.util.Optional<T> toJavaUtil() {\n  return java.util.Optional.ofNullable(orNull());\n}", "summary_tokens": ["returns", "the", "equivalent", "java"], "project": "guava"}
{"id": 654, "code": "static int chooseTableSize(int setSize) {\n  if (setSize == 1) {\n    return 2;\n  }\n    \n    \n  int tableSize = Integer.highestOneBit(setSize - 1) << 1;\n  while (tableSize * DESIRED_LOAD_FACTOR < setSize) {\n    tableSize <<= 1;\n  }\n  return tableSize;\n}", "summary_tokens": ["returns", "an", "array", "size", "suitable", "for", "the", "backing", "array", "of", "a", "hash", "table", "that", "uses", "open", "addressing", "with", "linear", "probing", "in", "its", "implementation"], "project": "guava"}
{"id": 1315, "code": "public final LinearTransformation leastSquaresFit() {\n  checkState(count() > 1);\n  if (isNaN(sumOfProductsOfDeltas)) {\n    return LinearTransformation.forNaN();\n  }\n  double xSumOfSquaresOfDeltas = xStats.sumOfSquaresOfDeltas();\n  if (xSumOfSquaresOfDeltas > 0.0) {\n    if (yStats.sumOfSquaresOfDeltas() > 0.0) {\n      return LinearTransformation.mapping(xStats.mean(), yStats.mean())\n          .withSlope(sumOfProductsOfDeltas / xSumOfSquaresOfDeltas);\n    } else {\n      return LinearTransformation.horizontal(yStats.mean());\n    }\n  } else {\n    checkState(yStats.sumOfSquaresOfDeltas() > 0.0);\n    return LinearTransformation.vertical(xStats.mean());\n  }\n}", "summary_tokens": ["returns", "a", "linear", "transformation", "giving", "the", "best", "fit", "to", "the", "data", "according", "to", "a", "href", "http", "mathworld"], "project": "guava"}
{"id": 1273, "code": "public static long floorPowerOfTwo(long x) {\n  checkPositive(\"x\", x);\n\n    \n    \n  return 1L << ((Long.SIZE - 1) - Long.numberOfLeadingZeros(x));\n}", "summary_tokens": ["returns", "the", "largest", "power", "of", "two", "less", "than", "or", "equal", "to", "x"], "project": "guava"}
{"id": 345, "code": "public void testRegistrationWithBridgeMethod() {\n  final AtomicInteger calls = new AtomicInteger();\n  bus.register(\n      new Callback<String>() {\n        @Subscribe\n        @Override\n        public void call(String s) {\n          calls.incrementAndGet();\n        }\n      });\n\n  bus.post(\"hello\");\n\n  assertEquals(1, calls.get());\n}", "summary_tokens": ["tests", "that", "bridge", "methods", "are", "not", "subscribed", "to", "events"], "project": "guava"}
{"id": 1683, "code": "public UnsignedInteger dividedBy(UnsignedInteger val) {\n  return fromIntBits(UnsignedInts.divide(value, checkNotNull(val).value));\n}", "summary_tokens": ["returns", "the", "result", "of", "dividing", "this", "by", "val"], "project": "guava"}
{"id": 354, "code": "public void immutableValueGraphBuilder_copiesGraphBuilder() {\n  ValueGraphBuilder<String, Object> graphBuilder =\n      ValueGraphBuilder.directed()\n          .allowsSelfLoops(true)\n          .<String>nodeOrder(ElementOrder.<String>natural());\n  ImmutableValueGraph.Builder<String, Integer> immutableValueGraphBuilder =\n      graphBuilder.<String, Integer>immutable();\n\n    \n  graphBuilder.allowsSelfLoops(false).nodeOrder(ElementOrder.<String>unordered());\n\n  ImmutableValueGraph<String, Integer> emptyGraph = immutableValueGraphBuilder.build();\n\n  assertThat(emptyGraph.isDirected()).isTrue();\n  assertThat(emptyGraph.allowsSelfLoops()).isTrue();\n  assertThat(emptyGraph.nodeOrder()).isEqualTo(ElementOrder.<String>natural());\n}", "summary_tokens": ["tests", "that", "the", "immutable", "value", "graph"], "project": "guava"}
{"id": 131, "code": "private static <T> ImmutableList<Invokable<?, ? extends T>> getFactories(TypeToken<T> type) {\n  List<Invokable<?, ? extends T>> factories = Lists.newArrayList();\n  for (Method method : type.getRawType().getDeclaredMethods()) {\n    Invokable<?, ?> invokable = type.method(method);\n    if (!invokable.isPrivate()\n        && !invokable.isSynthetic()\n        && invokable.isStatic()\n        && type.isSupertypeOf(invokable.getReturnType())) {\n      @SuppressWarnings(\"unchecked\") \n      Invokable<?, ? extends T> factory = (Invokable<?, ? extends T>) invokable;\n      factories.add(factory);\n    }\n  }\n  if (!Modifier.isAbstract(type.getRawType().getModifiers())) {\n    for (Constructor<?> constructor : type.getRawType().getDeclaredConstructors()) {\n      Invokable<T, T> invokable = type.constructor(constructor);\n      if (!invokable.isPrivate() && !invokable.isSynthetic()) {\n        factories.add(invokable);\n      }\n    }\n  }\n  for (Invokable<?, ?> factory : factories) {\n    factory.setAccessible(true);\n  }\n    \n    \n    \n  return BY_NUMBER_OF_PARAMETERS\n      .compound(BY_METHOD_NAME)\n      .compound(BY_PARAMETERS)\n      .immutableSortedCopy(factories);\n}", "summary_tokens": ["factories", "with", "the", "least", "number", "of", "parameters", "are", "listed", "first"], "project": "guava"}
{"id": 1333, "code": "public double populationStandardDeviation() {\n  return Math.sqrt(populationVariance());\n}", "summary_tokens": ["returns", "the", "a", "href", "http", "en"], "project": "guava"}
{"id": 113, "code": "public static void assertUnicodeEscaping(\n    UnicodeEscaper escaper, String expected, char hi, char lo) {\n\n  int cp = Character.toCodePoint(hi, lo);\n  String escaped = computeReplacement(escaper, cp);\n  Assert.assertNotNull(escaped);\n  Assert.assertEquals(expected, escaped);\n}", "summary_tokens": ["asserts", "that", "a", "unicode", "escaper", "escapes", "the", "given", "hi", "lo", "surrogate", "pair", "into", "the", "expected", "string"], "project": "guava"}
{"id": 871, "code": "public void remove(Range<C> range) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "range", "set", "unmodified"], "project": "guava"}
{"id": 780, "code": "static int maskCombine(int prefix, int suffix, int mask) {\n  return (prefix & ~mask) | (suffix & mask);\n}", "summary_tokens": ["returns", "a", "new", "value", "combining", "the", "prefix", "and", "suffix", "using", "the", "given", "mask"], "project": "guava"}
{"id": 1052, "code": "public final N nodeU() {\n  return nodeU;\n}", "summary_tokens": ["if", "this", "endpoint", "pair", "is", "ordered", "returns", "the", "source", "otherwise", "returns", "an", "arbitrary", "but", "consistent", "endpoint", "of", "the", "origin", "edge"], "project": "guava"}
{"id": 1984, "code": "public static CharSink asCharSink(Path path, Charset charset, OpenOption... options) {\n  return asByteSink(path, options).asCharSink(charset);\n}", "summary_tokens": ["returns", "a", "view", "of", "the", "given", "path", "as", "a", "char", "sink", "using", "the", "given", "charset"], "project": "guava"}
{"id": 1218, "code": "private static CharBuffer grow(CharBuffer buf) {\n  char[] copy = Arrays.copyOf(buf.array(), buf.capacity() * 2);\n  CharBuffer bigger = CharBuffer.wrap(copy);\n  Java8Compatibility.position(bigger, buf.position());\n  Java8Compatibility.limit(bigger, buf.limit());\n  return bigger;\n}", "summary_tokens": ["returns", "a", "new", "char", "buffer", "identical", "to", "buf", "except", "twice", "the", "capacity"], "project": "guava"}
{"id": 782, "code": "public static ContiguousSet<Long> closed(long lower, long upper) {\n  return create(Range.closed(lower, upper), DiscreteDomain.longs());\n}", "summary_tokens": ["returns", "a", "nonempty", "contiguous", "set", "containing", "all", "long", "values", "from", "lower", "inclusive", "to", "upper", "inclusive"], "project": "guava"}
{"id": 811, "code": "public static <B> Builder<B> builder() {\n  return new Builder<>();\n}", "summary_tokens": ["returns", "a", "new", "builder"], "project": "guava"}
{"id": 1321, "code": "private static double interpolate(double lower, double upper, double remainder, double scale) {\n  if (lower == NEGATIVE_INFINITY) {\n    if (upper == POSITIVE_INFINITY) {\n        \n      return NaN;\n    }\n      \n    return NEGATIVE_INFINITY;\n  }\n  if (upper == POSITIVE_INFINITY) {\n      \n    return POSITIVE_INFINITY;\n  }\n  return lower + (upper - lower) * remainder / scale;\n}", "summary_tokens": ["returns", "a", "value", "a", "fraction", "remainder", "scale", "of", "the", "way", "between", "lower", "and", "upper"], "project": "guava"}
{"id": 51, "code": "public static Set<Feature<?>> impliedFeatures(Set<Feature<?>> features) {\n  Set<Feature<?>> impliedSet = new LinkedHashSet<>();\n  Queue<Feature<?>> queue = new ArrayDeque<>(features);\n  while (!queue.isEmpty()) {\n    Feature<?> feature = queue.remove();\n    for (Feature<?> implied : feature.getImpliedFeatures()) {\n      if (!features.contains(implied) && impliedSet.add(implied)) {\n        queue.add(implied);\n      }\n    }\n  }\n  return impliedSet;\n}", "summary_tokens": ["given", "a", "set", "of", "features", "return", "a", "new", "set", "of", "all", "features", "directly", "or", "indirectly", "implied", "by", "any", "of", "them"], "project": "guava"}
{"id": 1404, "code": "public static InetAddress increment(InetAddress address) {\n  byte[] addr = address.getAddress();\n  int i = addr.length - 1;\n  while (i >= 0 && addr[i] == (byte) 0xff) {\n    addr[i] = 0;\n    i--;\n  }\n\n  checkArgument(i >= 0, \"Incrementing %s would wrap.\", address);\n\n  addr[i]++;\n  return bytesToInetAddress(addr);\n}", "summary_tokens": ["returns", "a", "new", "inet", "address", "that", "is", "one", "more", "than", "the", "passed", "in", "address"], "project": "guava"}
{"id": 446, "code": "public void testConstructor2NPE() {\n  double[] a = null;\n  try {\n    new AtomicDoubleArray(a);\n    fail();\n  } catch (NullPointerException success) {\n  }\n}", "summary_tokens": ["constructor", "with", "null", "array", "throws", "npe"], "project": "guava"}
{"id": 1880, "code": "public boolean enterIf(Guard guard, long time, TimeUnit unit) {\n  if (guard.monitor != this) {\n    throw new IllegalMonitorStateException();\n  }\n  if (!enter(time, unit)) {\n    return false;\n  }\n\n  boolean satisfied = false;\n  try {\n    return satisfied = guard.isSatisfied();\n  } finally {\n    if (!satisfied) {\n      lock.unlock();\n    }\n  }\n}", "summary_tokens": ["enters", "this", "monitor", "if", "the", "guard", "is", "satisfied"], "project": "guava"}
{"id": 565, "code": "public void callAndAssertBlocks(String methodName, Object... arguments) throws Exception {\n  checkNotNull(methodName);\n  checkNotNull(arguments);\n  assertEquals(false, invokeMethod(\"hasQueuedThread\", this));\n  sendRequest(methodName, arguments);\n  Thread.sleep(DUE_DILIGENCE_MILLIS);\n  assertEquals(true, invokeMethod(\"hasQueuedThread\", this));\n  assertNull(responseQueue.poll());\n}", "summary_tokens": ["causes", "this", "thread", "to", "call", "the", "named", "method", "and", "asserts", "that", "this", "thread", "becomes", "blocked", "on", "the", "lock", "like", "object"], "project": "guava"}
{"id": 937, "code": "MoveDesc<E> removeAt(int index) {\n  checkPositionIndex(index, size);\n  modCount++;\n  size--;\n  if (size == index) {\n    queue[size] = null;\n    return null;\n  }\n  E actualLastElement = elementData(size);\n  int lastElementAt = heapForIndex(size).swapWithConceptuallyLastElement(actualLastElement);\n  if (lastElementAt == index) {\n      \n      \n      \n    queue[size] = null;\n    return null;\n  }\n  E toTrickle = elementData(size);\n  queue[size] = null;\n  MoveDesc<E> changes = fillHole(index, toTrickle);\n  if (lastElementAt < index) {\n      \n    if (changes == null) {\n        \n      return new MoveDesc<>(actualLastElement, toTrickle);\n    } else {\n        \n        \n      return new MoveDesc<>(actualLastElement, changes.replaced);\n    }\n  }\n    \n  return changes;\n}", "summary_tokens": ["removes", "the", "element", "at", "position", "index"], "project": "guava"}
{"id": 1990, "code": "public static void touch(Path path) throws IOException {\n  checkNotNull(path);\n\n  try {\n    Files.setLastModifiedTime(path, FileTime.fromMillis(System.currentTimeMillis()));\n  } catch (NoSuchFileException e) {\n    try {\n      Files.createFile(path);\n    } catch (FileAlreadyExistsException ignore) {\n        \n        \n        \n        \n        \n        \n    }\n  }\n}", "summary_tokens": ["like", "the", "unix", "command", "of", "the", "same", "name", "creates", "an", "empty", "file", "or", "updates", "the", "last", "modified", "timestamp", "of", "the", "existing", "file", "at", "the", "given", "path", "to", "the", "current", "system", "time"], "project": "guava"}
{"id": 726, "code": "public String toParsableString() {\n  return specification;\n}", "summary_tokens": ["returns", "a", "string", "that", "can", "be", "used", "to", "parse", "an", "equivalent", "cache", "builder", "spec"], "project": "guava"}
{"id": 66, "code": "static <T> SortedMultiset<T> cast(Multiset<T> iterable) {\n  return (SortedMultiset<T>) iterable;\n}", "summary_tokens": ["used", "to", "avoid", "http", "bugs"], "project": "guava"}
{"id": 1676, "code": "public static void sort(byte[] array, int fromIndex, int toIndex) {\n  checkNotNull(array);\n  checkPositionIndexes(fromIndex, toIndex, array.length);\n  for (int i = fromIndex; i < toIndex; i++) {\n    array[i] = flip(array[i]);\n  }\n  Arrays.sort(array, fromIndex, toIndex);\n  for (int i = fromIndex; i < toIndex; i++) {\n    array[i] = flip(array[i]);\n  }\n}", "summary_tokens": ["sorts", "the", "array", "between", "from", "index", "inclusive", "and", "to", "index", "exclusive", "treating", "its", "elements", "as", "unsigned", "bytes"], "project": "guava"}
{"id": 1046, "code": "public Type type() {\n  return type;\n}", "summary_tokens": ["returns", "the", "type", "of", "ordering", "used"], "project": "guava"}
{"id": 1481, "code": "public static char checkedCast(long value) {\n  char result = (char) value;\n  checkArgument(result == value, \"Out of range: %s\", value);\n  return result;\n}", "summary_tokens": ["returns", "the", "char", "value", "that", "is", "equal", "to", "value", "if", "possible"], "project": "guava"}
{"id": 1337, "code": "public double max() {\n  checkState(count != 0);\n  return max;\n}", "summary_tokens": ["returns", "the", "highest", "value", "in", "the", "dataset"], "project": "guava"}
{"id": 1868, "code": "private static String getLockName(Enum<?> rank) {\n  return rank.getDeclaringClass().getSimpleName() + \".\" + rank.name();\n}", "summary_tokens": ["for", "the", "given", "enum", "value", "rank", "returns", "the", "value", "s", "enum", "class"], "project": "guava"}
{"id": 111, "code": "public static void assertEscaping(UnicodeEscaper escaper, String expected, int cp) {\n\n  String escaped = computeReplacement(escaper, cp);\n  Assert.assertNotNull(escaped);\n  Assert.assertEquals(expected, escaped);\n}", "summary_tokens": ["asserts", "that", "a", "unicode", "escaper", "escapes", "the", "given", "code", "point", "into", "the", "expected", "string"], "project": "guava"}
{"id": 1353, "code": "public double min() {\n  checkState(count != 0);\n  return min;\n}", "summary_tokens": ["returns", "the", "lowest", "value", "in", "the", "dataset"], "project": "guava"}
{"id": 1985, "code": "public static ImmutableList<Path> listFiles(Path dir) throws IOException {\n  try (DirectoryStream<Path> stream = Files.newDirectoryStream(dir)) {\n    return ImmutableList.copyOf(stream);\n  } catch (DirectoryIteratorException e) {\n    throw e.getCause();\n  }\n}", "summary_tokens": ["returns", "an", "immutable", "list", "of", "paths", "to", "the", "files", "contained", "in", "the", "given", "directory"], "project": "guava"}
{"id": 1585, "code": "public String toString() {\n  if (isEmpty()) {\n    return \"[]\";\n  }\n  StringBuilder builder = new StringBuilder(length() * 5); \n  builder.append('[').append(array[start]);\n\n  for (int i = start + 1; i < end; i++) {\n    builder.append(\", \").append(array[i]);\n  }\n  builder.append(']');\n  return builder.toString();\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "this", "array", "in", "the", "same", "form", "as", "arrays", "to", "string", "long", "for", "example", "0", "0", "0"], "project": "guava"}
{"id": 95, "code": "public static Method getListIteratorUnmodifiableMethod() {\n  return Helpers.getMethod(ListListIteratorTester.class, \"testListIterator_unmodifiable\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "list", "iterator", "unmodifiable", "so", "that", "it", "can", "be", "suppressed", "in", "gwt", "tests"], "project": "guava"}
{"id": 463, "code": "static boolean bitEquals(double x, double y) {\n  return Double.doubleToRawLongBits(x) == Double.doubleToRawLongBits(y);\n}", "summary_tokens": ["the", "notion", "of", "equality", "used", "by", "atomic", "double"], "project": "guava"}
{"id": 1157, "code": "public void increment() {\n  add(1L);\n}", "summary_tokens": ["equivalent", "to", "add", "0"], "project": "guava"}
{"id": 1931, "code": "protected Entry<E> standardLastEntry() {\n  Iterator<Entry<E>> entryIterator = descendingMultiset().entrySet().iterator();\n  if (!entryIterator.hasNext()) {\n    return null;\n  }\n  Entry<E> entry = entryIterator.next();\n  return Multisets.immutableEntry(entry.getElement(), entry.getCount());\n}", "summary_tokens": ["a", "sensible", "definition", "of", "last", "entry", "in", "terms", "of", "descending", "multiset"], "project": "guava"}
{"id": 866, "code": "static <C extends Comparable> ImmutableRangeSet<C> all() {\n  return (ImmutableRangeSet<C>) ALL;\n}", "summary_tokens": ["returns", "an", "immutable", "range", "set", "containing", "the", "single", "range", "range", "all"], "project": "guava"}
{"id": 1224, "code": "public static BigInteger ceilingPowerOfTwo(BigInteger x) {\n  return BigInteger.ZERO.setBit(log2(x, CEILING));\n}", "summary_tokens": ["returns", "the", "smallest", "power", "of", "two", "greater", "than", "or", "equal", "to", "x"], "project": "guava"}
{"id": 1392, "code": "public static boolean hasEmbeddedIPv4ClientAddress(Inet6Address ip) {\n  return isCompatIPv4Address(ip) || is6to4Address(ip) || isTeredoAddress(ip);\n}", "summary_tokens": ["examines", "the", "inet", "0", "address", "to", "determine", "if", "it", "is", "an", "ipv", "0", "address", "of", "one", "of", "the", "specified", "address", "types", "that", "contain", "an", "embedded", "ipv", "0", "address"], "project": "guava"}
{"id": 179, "code": "public static SameThreadScheduledExecutorService sameThreadScheduledExecutor() {\n  return new SameThreadScheduledExecutorService();\n}", "summary_tokens": ["creates", "a", "scheduled", "executor", "service", "that", "runs", "each", "task", "in", "the", "thread", "that", "invokes", "execute", "submit", "schedule", "as", "in", "caller", "runs", "policy"], "project": "guava"}
{"id": 891, "code": "public static <E extends Comparable<? super E>> ImmutableSortedMultiset<E> of(\n    E e1, E e2, E e3, E e4, E e5, E e6, E... remaining) {\n  int size = remaining.length + 6;\n  List<E> all = Lists.newArrayListWithCapacity(size);\n  Collections.addAll(all, e1, e2, e3, e4, e5, e6);\n  Collections.addAll(all, remaining);\n  return copyOf(Ordering.natural(), all);\n}", "summary_tokens": ["returns", "an", "immutable", "sorted", "multiset", "containing", "the", "given", "elements", "sorted", "by", "their", "natural", "ordering"], "project": "guava"}
{"id": 820, "code": "ImmutableList<E> subListUnchecked(int fromIndex, int toIndex) {\n  return new SubList(fromIndex, toIndex - fromIndex);\n}", "summary_tokens": ["called", "by", "the", "default", "implementation", "of", "sub", "list", "when", "to", "index", "from", "index", "0", "after", "index", "validation", "has", "already", "been", "performed"], "project": "guava"}
{"id": 1267, "code": "public static boolean isPrime(int n) {\n  return LongMath.isPrime(n);\n}", "summary_tokens": ["returns", "true", "if", "n", "is", "a", "a", "href", "http", "mathworld"], "project": "guava"}
{"id": 1279, "code": "public static long sqrt(long x, RoundingMode mode) {\n  checkNonNegative(\"x\", x);\n  if (fitsInInt(x)) {\n    return IntMath.sqrt((int) x, mode);\n  }\n    \n  long guess = (long) Math.sqrt(x);\n    \n  long guessSquared = guess * guess;\n    \n    \n  switch (mode) {\n    case UNNECESSARY:\n      checkRoundingUnnecessary(guessSquared == x);\n      return guess;\n    case FLOOR:\n    case DOWN:\n      if (x < guessSquared) {\n        return guess - 1;\n      }\n      return guess;\n    case CEILING:\n    case UP:\n      if (x > guessSquared) {\n        return guess + 1;\n      }\n      return guess;\n    case HALF_DOWN:\n    case HALF_UP:\n    case HALF_EVEN:\n      long sqrtFloor = guess - ((x < guessSquared) ? 1 : 0);\n      long halfSquare = sqrtFloor * sqrtFloor + sqrtFloor;\n        \n      return sqrtFloor + lessThanBranchFree(halfSquare, x);\n    default:\n      throw new AssertionError();\n  }\n}", "summary_tokens": ["returns", "the", "square", "root", "of", "x", "rounded", "with", "the", "specified", "rounding", "mode"], "project": "guava"}
{"id": 1471, "code": "public static int hashCode(byte value) {\n  return value;\n}", "summary_tokens": ["returns", "a", "hash", "code", "for", "value", "equal", "to", "the", "result", "of", "invoking", "byte", "value"], "project": "guava"}
{"id": 484, "code": "void waitUntilClosed(ClosingFuture<?> closingFuture) {\n  assertTrue(awaitUninterruptibly(closingFuture.whenClosedCountDown(), 1, SECONDS));\n}", "summary_tokens": ["waits", "for", "the", "given", "step", "s", "closeables", "to", "be", "closed"], "project": "guava"}
{"id": 65, "code": "public static List<Method> getIteratorDuplicateInitializingMethods() {\n  return Arrays.asList(\n      Helpers.getMethod(MultisetIteratorTester.class, \"testIteratorKnownOrder\"),\n      Helpers.getMethod(MultisetIteratorTester.class, \"testIteratorUnknownOrder\"),\n      Helpers.getMethod(MultisetIteratorTester.class, \"testRemovingIteratorKnownOrder\"),\n      Helpers.getMethod(MultisetIteratorTester.class, \"testRemovingIteratorUnknownOrder\"));\n}", "summary_tokens": ["returns", "method", "instances", "for", "the", "tests", "that", "assume", "multisets", "support", "duplicates", "so", "that", "the", "test", "of", "multisets"], "project": "guava"}
{"id": 265, "code": "static boolean hasLocalCache(Cache<?, ?> cache) {\n  return (checkNotNull(cache) instanceof LocalLoadingCache);\n}", "summary_tokens": ["determines", "whether", "the", "given", "cache", "can", "be", "converted", "to", "a", "local", "cache", "by", "to", "local", "cache", "without", "throwing", "an", "exception"], "project": "guava"}
{"id": 369, "code": "public void testMultipleLengths() {\n  int iterations = 800;\n  byte[] buf = new byte[iterations * 4];\n  int bufLen = 0;\n  long h = 0;\n  for (int i = 0; i < iterations; ++i) {\n    h ^= fingerprint(buf, i);\n    h = remix(h);\n    buf[bufLen++] = getChar(h);\n\n    h ^= fingerprint(buf, i * i % bufLen);\n    h = remix(h);\n    buf[bufLen++] = getChar(h);\n\n    h ^= fingerprint(buf, i * i * i % bufLen);\n    h = remix(h);\n    buf[bufLen++] = getChar(h);\n\n    h ^= fingerprint(buf, bufLen);\n    h = remix(h);\n    buf[bufLen++] = getChar(h);\n\n    int x0 = buf[bufLen - 1] & 0xff;\n    int x1 = buf[bufLen - 2] & 0xff;\n    int x2 = buf[bufLen - 3] & 0xff;\n    int x3 = buf[bufLen / 2] & 0xff;\n    buf[((x0 << 16) + (x1 << 8) + x2) % bufLen] ^= x3;\n    buf[((x1 << 16) + (x2 << 8) + x3) % bufLen] ^= i % 256;\n  }\n  assertEquals(0x7a1d67c50ec7e167L, h);\n}", "summary_tokens": ["tests", "that", "the", "java", "port", "of", "farm", "hash", "fingerprint", "0", "provides", "the", "same", "results", "on", "buffers", "up", "to", "0", "bytes", "long", "as", "the", "c", "reference", "implementation"], "project": "guava"}
{"id": 1459, "code": "public static int compare(boolean a, boolean b) {\n  return (a == b) ? 0 : (a ? 1 : -1);\n}", "summary_tokens": ["compares", "the", "two", "specified", "boolean", "values", "in", "the", "standard", "way", "false", "is", "considered", "less", "than", "true"], "project": "guava"}
{"id": 277, "code": "private Iterable<LoadingCache<Object, Object>> caches() {\n    \n  CacheBuilderFactory factory = cacheFactory();\n  return Iterables.transform(\n      factory.buildAllPermutations(),\n      new Function<CacheBuilder<Object, Object>, LoadingCache<Object, Object>>() {\n        @Override\n        public LoadingCache<Object, Object> apply(CacheBuilder<Object, Object> builder) {\n          return builder.recordStats().build(identityLoader());\n        }\n      });\n}", "summary_tokens": ["most", "of", "the", "tests", "in", "this", "class", "run", "against", "every", "one", "of", "these", "caches"], "project": "guava"}
{"id": 1188, "code": "public long getCount() {\n  return count;\n}", "summary_tokens": ["returns", "the", "number", "of", "bytes", "written"], "project": "guava"}
{"id": 80, "code": "public static <K, V> void assertMultimapIsUnmodifiable(\n    Multimap<K, V> multimap, K sampleKey, V sampleValue) {\n  List<Entry<K, V>> originalEntries =\n      Collections.unmodifiableList(Lists.newArrayList(multimap.entries()));\n\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n  Collection<V> sampleValueAsCollection = Collections.singleton(sampleValue);\n\n    \n  try {\n    multimap.clear();\n    fail(\"clear succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  assertSetIsUnmodifiable(\n      multimap.asMap().entrySet(), Maps.immutableEntry(sampleKey, sampleValueAsCollection));\n\n    \n\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n  if (!multimap.isEmpty()) {\n    Collection<V> values = multimap.asMap().entrySet().iterator().next().getValue();\n\n    assertCollectionIsUnmodifiable(values, sampleValue);\n  }\n\n    \n  assertCollectionIsUnmodifiable(multimap.entries(), Maps.immutableEntry(sampleKey, sampleValue));\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  for (Entry<K, V> entry : multimap.entries()) {\n    assertMapEntryIsUnmodifiable(entry);\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  assertMultisetIsUnmodifiable(multimap.keys(), sampleKey);\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  assertSetIsUnmodifiable(multimap.keySet(), sampleKey);\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  if (!multimap.isEmpty()) {\n    K key = multimap.keySet().iterator().next();\n    assertCollectionIsUnmodifiable(multimap.get(key), sampleValue);\n    assertMultimapRemainsUnmodified(multimap, originalEntries);\n  }\n\n    \n  try {\n    multimap.put(sampleKey, sampleValue);\n    fail(\"put succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  try {\n    multimap.putAll(sampleKey, sampleValueAsCollection);\n    fail(\"putAll(K, Iterable) succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  Multimap<K, V> multimap2 = ArrayListMultimap.create();\n  multimap2.put(sampleKey, sampleValue);\n  try {\n    multimap.putAll(multimap2);\n    fail(\"putAll(Multimap<K, V>) succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  try {\n    multimap.remove(sampleKey, sampleValue);\n    fail(\"remove succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  try {\n    multimap.removeAll(sampleKey);\n    fail(\"removeAll succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  try {\n    multimap.replaceValues(sampleKey, sampleValueAsCollection);\n    fail(\"replaceValues succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    \n  try {\n    multimap.asMap().remove(sampleKey);\n    fail(\"asMap().remove() succeeded on unmodifiable multimap\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n  if (!multimap.isEmpty()) {\n    K presentKey = multimap.keySet().iterator().next();\n    try {\n      multimap.asMap().get(presentKey).remove(sampleValue);\n      fail(\"asMap().get().remove() succeeded on unmodifiable multimap\");\n    } catch (UnsupportedOperationException expected) {\n    }\n    assertMultimapRemainsUnmodified(multimap, originalEntries);\n\n    try {\n      multimap.asMap().values().iterator().next().remove(sampleValue);\n      fail(\"asMap().values().iterator().next().remove() succeeded on unmodifiable multimap\");\n    } catch (UnsupportedOperationException expected) {\n    }\n\n    try {\n      ((Collection<?>) multimap.asMap().values().toArray()[0]).clear();\n      fail(\"asMap().values().toArray()[0].clear() succeeded on unmodifiable multimap\");\n    } catch (UnsupportedOperationException expected) {\n    }\n  }\n\n  assertCollectionIsUnmodifiable(multimap.values(), sampleValue);\n  assertMultimapRemainsUnmodified(multimap, originalEntries);\n}", "summary_tokens": ["verifies", "that", "a", "multimap", "is", "immutable"], "project": "guava"}
{"id": 1283, "code": "public static long checkedAdd(long a, long b) {\n  long result = a + b;\n  checkNoOverflow((a ^ b) < 0 | (a ^ result) >= 0, \"checkedAdd\", a, b);\n  return result;\n}", "summary_tokens": ["returns", "the", "sum", "of", "a", "and", "b", "provided", "it", "does", "not", "overflow"], "project": "guava"}
{"id": 638, "code": "public static ToStringHelper toStringHelper(String className) {\n  return new ToStringHelper(className);\n}", "summary_tokens": ["creates", "an", "instance", "of", "to", "string", "helper", "in", "the", "same", "manner", "as", "to", "string", "helper", "object", "but", "using", "class", "name", "instead", "of", "using", "an", "instance", "s", "object", "get", "class"], "project": "guava"}
{"id": 1331, "code": "public double sum() {\n  return mean * count;\n}", "summary_tokens": ["returns", "the", "sum", "of", "the", "values"], "project": "guava"}
{"id": 1446, "code": "static MediaType createImageType(String subtype) {\n  return create(IMAGE_TYPE, subtype);\n}", "summary_tokens": ["creates", "a", "media", "type", "with", "the", "image", "type", "and", "the", "given", "subtype"], "project": "guava"}
{"id": 1998, "code": "private static Collection<IOException> deleteRecursivelyInsecure(Path path) {\n  Collection<IOException> exceptions = null;\n  try {\n    if (Files.isDirectory(path, NOFOLLOW_LINKS)) {\n      try (DirectoryStream<Path> stream = Files.newDirectoryStream(path)) {\n        exceptions = deleteDirectoryContentsInsecure(stream);\n      }\n    }\n\n      \n      \n    if (exceptions == null) {\n      Files.delete(path);\n    }\n\n    return exceptions;\n  } catch (IOException e) {\n    return addException(exceptions, e);\n  }\n}", "summary_tokens": ["insecure", "recursive", "delete", "for", "file", "systems", "that", "don", "t", "support", "secure", "directory", "stream"], "project": "guava"}
{"id": 1642, "code": "public static int lastIndexOf(short[] array, short target) {\n  return lastIndexOf(array, target, 0, array.length);\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "last", "appearance", "of", "the", "value", "target", "in", "array"], "project": "guava"}
{"id": 538, "code": "void sleep(long millis) {\n  try {\n    delay(millis);\n  } catch (InterruptedException ie) {\n    AssertionFailedError afe = new AssertionFailedError(\"Unexpected InterruptedException\");\n    afe.initCause(ie);\n    throw afe;\n  }\n}", "summary_tokens": ["sleeps", "until", "the", "given", "time", "has", "elapsed"], "project": "guava"}
{"id": 830, "code": "public static <K, V> Builder<K, V> builder() {\n  return new Builder<>();\n}", "summary_tokens": ["returns", "a", "new", "builder"], "project": "guava"}
{"id": 1707, "code": "public static UnsignedLong fromLongBits(long bits) {\n    \n  return new UnsignedLong(bits);\n}", "summary_tokens": ["returns", "an", "unsigned", "long", "corresponding", "to", "a", "given", "bit", "representation"], "project": "guava"}
{"id": 1639, "code": "public static int compare(short a, short b) {\n  return a - b; \n}", "summary_tokens": ["compares", "the", "two", "specified", "short", "values"], "project": "guava"}
{"id": 434, "code": "private static void radixEncodeParseAndAssertEquals(Integer value, int radix) {\n  assertEquals(\"Radix: \" + radix, value, Ints.tryParse(Integer.toString(value, radix), radix));\n}", "summary_tokens": ["encodes", "the", "an", "integer", "as", "a", "string", "with", "given", "radix", "then", "uses", "ints", "try", "parse", "string", "int", "to", "parse", "the", "result"], "project": "guava"}
{"id": 410, "code": "static void assertVerticalLinearTransformation(LinearTransformation transformation, double x) {\n  assertThat(transformation.isHorizontal()).isFalse();\n  assertThat(transformation.isVertical()).isTrue();\n  assertThat(transformation.inverse().isHorizontal()).isTrue();\n  assertThat(transformation.inverse().isVertical()).isFalse();\n  try {\n    transformation.transform(0.0);\n    fail(\"Expected IllegalStateException\");\n  } catch (IllegalStateException expected) {\n  }\n  assertThat(transformation.inverse().transform(-1.0)).isWithin(ALLOWED_ERROR).of(x);\n  assertThat(transformation.inverse().transform(1.0)).isWithin(ALLOWED_ERROR).of(x);\n  try {\n    transformation.slope();\n    fail(\"Expected IllegalStateException\");\n  } catch (IllegalStateException expected) {\n  }\n  assertThat(transformation.inverse().slope()).isWithin(ALLOWED_ERROR).of(0.0);\n  assertThat(transformation.inverse()).isSameInstanceAs(transformation.inverse());\n  assertThat(transformation.inverse().inverse()).isSameInstanceAs(transformation);\n}", "summary_tokens": ["asserts", "that", "transformation", "is", "vertical", "with", "the", "given", "value", "of", "x"], "project": "guava"}
{"id": 1817, "code": "public final void lazySet(double newValue) {\n  long next = doubleToRawLongBits(newValue);\n  updater.lazySet(this, next);\n}", "summary_tokens": ["eventually", "sets", "to", "the", "given", "value"], "project": "guava"}
{"id": 1114, "code": "public static HashCode fromBytes(byte[] bytes) {\n  checkArgument(bytes.length >= 1, \"A HashCode must contain at least 1 byte.\");\n  return fromBytesNoCopy(bytes.clone());\n}", "summary_tokens": ["creates", "a", "hash", "code", "from", "a", "byte", "array"], "project": "guava"}
{"id": 1399, "code": "public static Inet4Address fromIPv4BigInteger(BigInteger address) {\n  return (Inet4Address) fromBigInteger(address, false);\n}", "summary_tokens": ["returns", "the", "inet", "0", "address", "corresponding", "to", "a", "given", "big", "integer"], "project": "guava"}
{"id": 1562, "code": "public int lastIndexOf(int target) {\n  for (int i = end - 1; i >= start; i--) {\n    if (array[i] == target) {\n      return i - start;\n    }\n  }\n  return -1;\n}", "summary_tokens": ["returns", "the", "largest", "index", "for", "which", "get", "returns", "target", "or", "0", "if", "no", "such", "index", "exists"], "project": "guava"}
{"id": 384, "code": "private static void assertReadsCorrectly(CharSequence charSequence) throws IOException {\n  String expected = charSequence.toString();\n\n    \n  CharSequenceReader reader = new CharSequenceReader(charSequence);\n  for (int i = 0; i < expected.length(); i++) {\n    assertEquals(expected.charAt(i), reader.read());\n  }\n  assertFullyRead(reader);\n\n    \n  reader = new CharSequenceReader(charSequence);\n  char[] buf = new char[expected.length()];\n  assertEquals(expected.length() == 0 ? -1 : expected.length(), reader.read(buf));\n  assertEquals(expected, new String(buf));\n  assertFullyRead(reader);\n\n    \n  reader = new CharSequenceReader(charSequence);\n  buf = new char[5];\n  StringBuilder builder = new StringBuilder();\n  int read;\n  while ((read = reader.read(buf, 0, buf.length)) != -1) {\n    builder.append(buf, 0, read);\n  }\n  assertEquals(expected, builder.toString());\n  assertFullyRead(reader);\n\n    \n  reader = new CharSequenceReader(charSequence);\n  CharBuffer buf2 = CharBuffer.allocate(expected.length());\n  assertEquals(expected.length() == 0 ? -1 : expected.length(), reader.read(buf2));\n  Java8Compatibility.flip(buf2);\n  assertEquals(expected, buf2.toString());\n  assertFullyRead(reader);\n\n    \n  reader = new CharSequenceReader(charSequence);\n  buf2 = CharBuffer.allocate(5);\n  builder = new StringBuilder();\n  while (reader.read(buf2) != -1) {\n    Java8Compatibility.flip(buf2);\n    builder.append(buf2);\n    Java8Compatibility.clear(buf2);\n  }\n  assertEquals(expected, builder.toString());\n  assertFullyRead(reader);\n\n    \n  reader = new CharSequenceReader(charSequence);\n  assertEquals(expected.length(), reader.skip(Long.MAX_VALUE));\n  assertFullyRead(reader);\n\n    \n  if (expected.length() > 5) {\n    reader = new CharSequenceReader(charSequence);\n    assertEquals(5, reader.skip(5));\n\n    buf = new char[expected.length() - 5];\n    assertEquals(buf.length, reader.read(buf, 0, buf.length));\n    assertEquals(expected.substring(5), new String(buf));\n    assertFullyRead(reader);\n  }\n}", "summary_tokens": ["creates", "a", "char", "sequence", "reader", "wrapping", "the", "given", "char", "sequence", "and", "tests", "that", "the", "reader", "produces", "the", "same", "sequence", "when", "read", "using", "each", "type", "of", "read", "method", "it", "provides"], "project": "guava"}
{"id": 2007, "code": "public DoubleStream stream() {\n  return Arrays.stream(array, start, end);\n}", "summary_tokens": ["returns", "a", "stream", "over", "the", "values", "in", "this", "array", "in", "order"], "project": "guava"}
{"id": 561, "code": "public void testBasicInvariants() {\n  for (Striped<?> striped : allImplementations()) {\n    assertBasicInvariants(striped);\n  }\n}", "summary_tokens": ["checks", "idempotency", "and", "that", "we", "observe", "the", "promised", "number", "of", "stripes"], "project": "guava"}
{"id": 917, "code": "static <K>\n    MapMakerInternalMap<K, Dummy, ? extends InternalEntry<K, Dummy, ?>, ?> createWithDummyValues(\n        MapMaker builder) {\n  if (builder.getKeyStrength() == Strength.STRONG\n      && builder.getValueStrength() == Strength.STRONG) {\n    return new MapMakerInternalMap<>(builder, StrongKeyDummyValueEntry.Helper.<K>instance());\n  }\n  if (builder.getKeyStrength() == Strength.WEAK\n      && builder.getValueStrength() == Strength.STRONG) {\n    return new MapMakerInternalMap<>(builder, WeakKeyDummyValueEntry.Helper.<K>instance());\n  }\n  if (builder.getValueStrength() == Strength.WEAK) {\n    throw new IllegalArgumentException(\"Map cannot have both weak and dummy values\");\n  }\n  throw new AssertionError();\n}", "summary_tokens": ["returns", "a", "fresh", "map", "maker", "internal", "map", "with", "map", "maker"], "project": "guava"}
{"id": 1057, "code": "protected long edgeCount() {\n  return delegate().edges().size();\n}", "summary_tokens": ["defer", "to", "abstract", "value", "graph", "edges", "based", "on", "successors", "object", "for", "full", "edges", "implementation"], "project": "guava"}
{"id": 107, "code": "static int collectionIteratorTesterNumIterations() {\n  return 5;\n}", "summary_tokens": ["see", "collection", "iterator", "tester"], "project": "guava"}
{"id": 1663, "code": "public static String join(String separator, byte... array) {\n  checkNotNull(separator);\n  if (array.length == 0) {\n    return \"\";\n  }\n\n    \n  StringBuilder builder = new StringBuilder(array.length * 5);\n  builder.append(array[0]);\n  for (int i = 1; i < array.length; i++) {\n    builder.append(separator).append(array[i]);\n  }\n  return builder.toString();\n}", "summary_tokens": ["returns", "a", "string", "containing", "the", "supplied", "byte", "values", "separated", "by", "separator"], "project": "guava"}
{"id": 1491, "code": "public static byte[] toByteArray(char value) {\n  return new byte[] {(byte) (value >> 8), (byte) value};\n}", "summary_tokens": ["returns", "a", "big", "endian", "representation", "of", "value", "in", "a", "0", "element", "byte", "array", "equivalent", "to", "byte", "buffer"], "project": "guava"}
{"id": 1664, "code": "public static Comparator<byte[]> lexicographicalComparator() {\n  return LexicographicalComparator.INSTANCE;\n}", "summary_tokens": ["returns", "a", "comparator", "that", "compares", "two", "byte", "arrays", "a", "href", "http", "en"], "project": "guava"}
{"id": 1848, "code": "public long getAndDecrement(K key) {\n  return getAndAdd(key, -1);\n}", "summary_tokens": ["decrements", "by", "one", "the", "value", "currently", "associated", "with", "key", "and", "returns", "the", "old", "value"], "project": "guava"}
{"id": 1656, "code": "public static short[] toArray(Collection<? extends Number> collection) {\n  if (collection instanceof ShortArrayAsList) {\n    return ((ShortArrayAsList) collection).toShortArray();\n  }\n\n  Object[] boxedArray = collection.toArray();\n  int len = boxedArray.length;\n  short[] array = new short[len];\n  for (int i = 0; i < len; i++) {\n      \n    array[i] = ((Number) checkNotNull(boxedArray[i])).shortValue();\n  }\n  return array;\n}", "summary_tokens": ["returns", "an", "array", "containing", "each", "value", "of", "collection", "converted", "to", "a", "short", "value", "in", "the", "manner", "of", "number", "short", "value"], "project": "guava"}
{"id": 920, "code": "boolean isLiveForTesting(InternalEntry<K, V, ?> entry) {\n  return segmentFor(entry.getHash()).getLiveValueForTesting(entry) != null;\n}", "summary_tokens": ["this", "method", "is", "a", "convenience", "for", "testing"], "project": "guava"}
{"id": 1863, "code": "public static CycleDetectingLockFactory newInstance(Policy policy) {\n  return new CycleDetectingLockFactory(policy);\n}", "summary_tokens": ["creates", "a", "new", "factory", "with", "the", "specified", "policy"], "project": "guava"}
{"id": 303, "code": "public void testConcatContainingNull() {\n  @SuppressWarnings(\"unchecked\")\n  Iterator<Iterator<Integer>> input = asList(iterateOver(1, 2), null, iterateOver(3)).iterator();\n  Iterator<Integer> result = Iterators.concat(input);\n  assertEquals(1, (int) result.next());\n  assertEquals(2, (int) result.next());\n  try {\n    result.hasNext();\n    fail(\"no exception thrown\");\n  } catch (NullPointerException e) {\n  }\n  try {\n    result.next();\n    fail(\"no exception thrown\");\n  } catch (NullPointerException e) {\n  }\n    \n}", "summary_tokens": ["illustrates", "the", "somewhat", "bizarre", "behavior", "when", "a", "null", "is", "passed", "in"], "project": "guava"}
{"id": 391, "code": "private static File root() {\n  return File.listRoots()[0];\n}", "summary_tokens": ["returns", "a", "root", "path", "for", "the", "file", "system"], "project": "guava"}
{"id": 1138, "code": "public static HashFunction fingerprint2011() {\n  return Fingerprint2011.FINGERPRINT_2011;\n}", "summary_tokens": ["returns", "a", "hash", "function", "implementing", "the", "fingerprint", "0", "hashing", "function", "0", "hash", "bits"], "project": "guava"}
{"id": 616, "code": "public String trimTrailingFrom(CharSequence sequence) {\n  int len = sequence.length();\n  for (int last = len - 1; last >= 0; last--) {\n    if (!matches(sequence.charAt(last))) {\n      return sequence.subSequence(0, last + 1).toString();\n    }\n  }\n  return \"\";\n}", "summary_tokens": ["returns", "a", "substring", "of", "the", "input", "character", "sequence", "that", "omits", "all", "matching", "bmp", "characters", "from", "the", "end", "of", "the", "string"], "project": "guava"}
{"id": 719, "code": "public <K1 extends K, V1 extends V> CacheBuilder<K1, V1> removalListener(\n    RemovalListener<? super K1, ? super V1> listener) {\n  checkState(this.removalListener == null);\n\n    \n  @SuppressWarnings(\"unchecked\")\n  CacheBuilder<K1, V1> me = (CacheBuilder<K1, V1>) this;\n  me.removalListener = checkNotNull(listener);\n  return me;\n}", "summary_tokens": ["specifies", "a", "listener", "instance", "that", "caches", "should", "notify", "each", "time", "an", "entry", "is", "removed", "for", "any", "removal", "cause", "reason"], "project": "guava"}
{"id": 1773, "code": "final Type capture() {\n  Type superclass = getClass().getGenericSuperclass();\n  checkArgument(superclass instanceof ParameterizedType, \"%s isn't parameterized\", superclass);\n  return ((ParameterizedType) superclass).getActualTypeArguments()[0];\n}", "summary_tokens": ["returns", "the", "captured", "type"], "project": "guava"}
{"id": 1509, "code": "public static double constrainToRange(double value, double min, double max) {\n    \n    \n  if (min <= max) {\n    return Math.min(Math.max(value, min), max);\n  }\n  throw new IllegalArgumentException(\n      lenientFormat(\"min (%s) must be less than or equal to max (%s)\", min, max));\n}", "summary_tokens": ["returns", "the", "value", "nearest", "to", "value", "which", "is", "within", "the", "closed", "range", "min"], "project": "guava"}
{"id": 591, "code": "public static CharMatcher singleWidth() {\n  return SingleWidth.INSTANCE;\n}", "summary_tokens": ["determines", "whether", "a", "character", "is", "single", "width", "not", "double", "width"], "project": "guava"}
{"id": 101, "code": "public static Method getPutNullKeyUnsupportedMethod() {\n  return Helpers.getMethod(MapPutTester.class, \"testPut_nullKeyUnsupported\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "put", "null", "key", "unsupported", "so", "that", "tests", "of", "java"], "project": "guava"}
{"id": 1571, "code": "public static ImmutableLongArray of(long first, long... rest) {\n  checkArgument(\n      rest.length <= Integer.MAX_VALUE - 1, \"the total number of elements must fit in an int\");\n  long[] array = new long[rest.length + 1];\n  array[0] = first;\n  System.arraycopy(rest, 0, array, 1, rest.length);\n  return new ImmutableLongArray(array);\n}", "summary_tokens": ["returns", "an", "immutable", "array", "containing", "the", "given", "values", "in", "order"], "project": "guava"}
{"id": 2017, "code": "public final double accumulateAndGet(int i, double x, DoubleBinaryOperator accumulatorFunction) {\n  checkNotNull(accumulatorFunction);\n  return updateAndGet(i, oldValue -> accumulatorFunction.applyAsDouble(oldValue, x));\n}", "summary_tokens": ["atomically", "updates", "the", "element", "at", "index", "i", "with", "the", "results", "of", "applying", "the", "given", "function", "to", "the", "curernt", "and", "given", "values"], "project": "guava"}
{"id": 501, "code": "public void testSuccessfulAsList_logging_error() throws Exception {\n  assertEquals(\n      newArrayList((Object) null),\n      getDone(successfulAsList(immediateFailedFuture(new MyError()))));\n  List<LogRecord> logged = aggregateFutureLogHandler.getStoredLogRecords();\n  assertThat(logged).hasSize(1); \n  assertThat(logged.get(0).getThrown()).isInstanceOf(MyError.class);\n}", "summary_tokens": ["ensure", "that", "errors", "are", "always", "logged"], "project": "guava"}
{"id": 865, "code": "public static <C extends Comparable> ImmutableRangeSet<C> of(Range<C> range) {\n  checkNotNull(range);\n  if (range.isEmpty()) {\n    return of();\n  } else if (range.equals(Range.all())) {\n    return all();\n  } else {\n    return new ImmutableRangeSet<C>(ImmutableList.of(range));\n  }\n}", "summary_tokens": ["returns", "an", "immutable", "range", "set", "containing", "the", "specified", "single", "range"], "project": "guava"}
{"id": 23, "code": "public static <T> Collection<T> misleadingSizeCollection(int delta) {\n    \n    \n    \n  return new ArrayList<T>() {\n    @Override\n    public int size() {\n      return Math.max(0, super.size() + delta);\n    }\n  };\n}", "summary_tokens": ["returns", "a", "collection", "that", "simulates", "concurrent", "modification", "by", "having", "its", "size", "method", "return", "incorrect", "values"], "project": "guava"}
{"id": 1989, "code": "public static boolean equal(Path path1, Path path2) throws IOException {\n  checkNotNull(path1);\n  checkNotNull(path2);\n  if (Files.isSameFile(path1, path2)) {\n    return true;\n  }\n\n    \n  ByteSource source1 = asByteSource(path1);\n  ByteSource source2 = asByteSource(path2);\n  long len1 = source1.sizeIfKnown().or(0L);\n  long len2 = source2.sizeIfKnown().or(0L);\n  if (len1 != 0 && len2 != 0 && len1 != len2) {\n    return false;\n  }\n  return source1.contentEquals(source2);\n}", "summary_tokens": ["returns", "true", "if", "the", "files", "located", "by", "the", "given", "paths", "exist", "are", "not", "directories", "and", "contain", "the", "same", "bytes"], "project": "guava"}
{"id": 317, "code": "public void testIteratorRegressionChildlessUncle() {\n  final ArrayList<Integer> initial = Lists.newArrayList(1, 15, 13, 8, 9, 10, 11, 14);\n  MinMaxPriorityQueue<Integer> q = MinMaxPriorityQueue.create(initial);\n  assertIntact(q);\n  q.remove(9);\n  q.remove(11);\n  q.remove(10);\n    \n    \n  List<Integer> result = Lists.newArrayListWithCapacity(initial.size());\n  for (Iterator<Integer> iter = q.iterator(); iter.hasNext(); ) {\n    Integer value = iter.next();\n    result.add(value);\n    if (value == 8) {\n      iter.remove();\n    }\n  }\n  assertIntact(q);\n  assertThat(result).containsExactly(1, 15, 13, 8, 14);\n}", "summary_tokens": ["tests", "a", "failure", "caused", "by", "fix", "to", "childless", "uncle", "issue"], "project": "guava"}
{"id": 381, "code": "public void testSlice_appendingAfterSlicing() throws IOException {\n    \n  AppendableByteSource source = new AppendableByteSource(newPreFilledByteArray(5));\n\n    \n  ByteSource slice = source.slice(10, 5);\n\n    \n  InputStream in = slice.openStream();\n\n    \n  source.append(newPreFilledByteArray(5, 10));\n\n    \n    \n    \n    \n  assertEquals(-1, in.read());\n}", "summary_tokens": ["tests", "that", "the", "default", "slice", "behavior", "is", "correct", "when", "the", "source", "is", "sliced", "starting", "at", "an", "offset", "that", "is", "greater", "than", "the", "current", "length", "of", "the", "source", "a", "stream", "is", "then", "opened", "to", "that", "source", "and", "finally", "additional", "bytes", "are", "appended", "to", "the", "source", "before", "the", "stream", "is", "read"], "project": "guava"}
{"id": 17, "code": "public B withFeatures(Feature<?>... features) {\n  return withFeatures(Arrays.asList(features));\n}", "summary_tokens": ["configures", "this", "builder", "to", "produce", "tests", "appropriate", "for", "the", "given", "features"], "project": "guava"}
{"id": 285, "code": "static <K, V> NullRemovalListener<K, V> nullRemovalListener() {\n  return new NullRemovalListener<>();\n}", "summary_tokens": ["returns", "a", "new", "no", "op", "removal", "listener"], "project": "guava"}
{"id": 1024, "code": "private static boolean isDeclaredThreadSafe(Method method) {\n  return method.getAnnotation(AllowConcurrentEvents.class) != null;\n}", "summary_tokens": ["checks", "whether", "method", "is", "thread", "safe", "as", "indicated", "by", "the", "presence", "of", "the", "allow", "concurrent", "events", "annotation"], "project": "guava"}
{"id": 1765, "code": "public final ImmutableList<TypeToken<? extends Throwable>> getExceptionTypes() {\n  ImmutableList.Builder<TypeToken<? extends Throwable>> builder = ImmutableList.builder();\n  for (Type type : getGenericExceptionTypes()) {\n      \n    @SuppressWarnings(\"unchecked\")\n    TypeToken<? extends Throwable> exceptionType =\n        (TypeToken<? extends Throwable>) TypeToken.of(type);\n    builder.add(exceptionType);\n  }\n  return builder.build();\n}", "summary_tokens": ["returns", "all", "declared", "exception", "types", "of", "this", "invokable"], "project": "guava"}
{"id": 468, "code": "public void testCompareAndSet() {\n  double prev = Math.E;\n  double unused = Math.E + Math.PI;\n  AtomicDouble at = new AtomicDouble(prev);\n  for (double x : VALUES) {\n    assertBitEquals(prev, at.get());\n    assertFalse(at.compareAndSet(unused, x));\n    assertBitEquals(prev, at.get());\n    assertTrue(at.compareAndSet(prev, x));\n    assertBitEquals(x, at.get());\n    prev = x;\n  }\n}", "summary_tokens": ["compare", "and", "set", "succeeds", "in", "changing", "value", "if", "equal", "to", "expected", "else", "fails"], "project": "guava"}
{"id": 1216, "code": "private void advance() throws IOException {\n  close();\n  if (it.hasNext()) {\n    in = it.next().openStream();\n  }\n}", "summary_tokens": ["closes", "the", "current", "input", "stream", "and", "opens", "the", "next", "one", "if", "any"], "project": "guava"}
{"id": 1516, "code": "public static void reverse(double[] array, int fromIndex, int toIndex) {\n  checkNotNull(array);\n  checkPositionIndexes(fromIndex, toIndex, array.length);\n  for (int i = fromIndex, j = toIndex - 1; i < j; i++, j--) {\n    double tmp = array[i];\n    array[i] = array[j];\n    array[j] = tmp;\n  }\n}", "summary_tokens": ["reverses", "the", "elements", "of", "array", "between", "from", "index", "inclusive", "and", "to", "index", "exclusive"], "project": "guava"}
{"id": 1771, "code": "public static void initialize(Class<?>... classes) {\n  for (Class<?> clazz : classes) {\n    try {\n      Class.forName(clazz.getName(), true, clazz.getClassLoader());\n    } catch (ClassNotFoundException e) {\n      throw new AssertionError(e);\n    }\n  }\n}", "summary_tokens": ["ensures", "that", "the", "given", "classes", "are", "initialized", "as", "described", "in", "a", "href", "http", "java"], "project": "guava"}
{"id": 1869, "code": "private void aboutToAcquire(CycleDetectingLock lock) {\n  if (!lock.isAcquiredByCurrentThread()) {\n    ArrayList<LockGraphNode> acquiredLockList = acquiredLocks.get();\n    LockGraphNode node = lock.getLockGraphNode();\n    node.checkAcquiredLocks(policy, acquiredLockList);\n    acquiredLockList.add(node);\n  }\n}", "summary_tokens": ["cycle", "detecting", "lock", "implementations", "must", "call", "this", "method", "before", "attempting", "to", "acquire", "the", "lock"], "project": "guava"}
{"id": 1366, "code": "public HostAndPort requireBracketsForIPv6() {\n  checkArgument(!hasBracketlessColons, \"Possible bracketless IPv6 literal: %s\", host);\n  return this;\n}", "summary_tokens": ["generate", "an", "error", "if", "the", "host", "might", "be", "a", "non", "bracketed", "ipv", "0", "literal"], "project": "guava"}
{"id": 1890, "code": "public boolean hasQueuedThreads() {\n  return lock.hasQueuedThreads();\n}", "summary_tokens": ["returns", "whether", "any", "threads", "are", "waiting", "to", "enter", "this", "monitor"], "project": "guava"}
{"id": 1993, "code": "public static String getNameWithoutExtension(Path path) {\n  Path name = path.getFileName();\n\n    \n  if (name == null) {\n    return \"\";\n  }\n\n  String fileName = name.toString();\n  int dotIndex = fileName.lastIndexOf('.');\n  return dotIndex == -1 ? fileName : fileName.substring(0, dotIndex);\n}", "summary_tokens": ["returns", "the", "file", "name", "without", "its", "a", "href", "http", "en"], "project": "guava"}
{"id": 826, "code": "public ImmutableList<E> reverse() {\n  return (size() <= 1) ? this : new ReverseImmutableList<E>(this);\n}", "summary_tokens": ["returns", "a", "view", "of", "this", "immutable", "list", "in", "reverse", "order"], "project": "guava"}
{"id": 1870, "code": "private static void lockStateChanged(CycleDetectingLock lock) {\n  if (!lock.isAcquiredByCurrentThread()) {\n    ArrayList<LockGraphNode> acquiredLockList = acquiredLocks.get();\n    LockGraphNode node = lock.getLockGraphNode();\n      \n      \n    for (int i = acquiredLockList.size() - 1; i >= 0; i--) {\n      if (acquiredLockList.get(i) == node) {\n        acquiredLockList.remove(i);\n        break;\n      }\n    }\n  }\n}", "summary_tokens": ["cycle", "detecting", "lock", "implementations", "must", "call", "this", "method", "in", "a", "finally", "clause", "after", "any", "attempt", "to", "change", "the", "lock", "state", "including", "both", "lock", "and", "unlock", "attempts"], "project": "guava"}
{"id": 1241, "code": "public static boolean fuzzyEquals(double a, double b, double tolerance) {\n  MathPreconditions.checkNonNegative(\"tolerance\", tolerance);\n  return Math.copySign(a - b, 1.0) <= tolerance\n        \n      || (a == b) \n      || (Double.isNaN(a) && Double.isNaN(b));\n}", "summary_tokens": ["returns", "true", "if", "a", "and", "b", "are", "within", "tolerance", "of", "each", "other"], "project": "guava"}
{"id": 637, "code": "public static <T> T firstNonNull(@CheckForNull T first, T second) {\n  if (first != null) {\n    return first;\n  }\n  if (second != null) {\n    return second;\n  }\n  throw new NullPointerException(\"Both parameters are null\");\n}", "summary_tokens": ["returns", "the", "first", "of", "two", "given", "parameters", "that", "is", "not", "null", "if", "either", "is", "or", "otherwise", "throws", "a", "null", "pointer", "exception"], "project": "guava"}
{"id": 1023, "code": "private SubscriberExceptionContext context(Object event) {\n  return new SubscriberExceptionContext(bus, event, target, method);\n}", "summary_tokens": ["gets", "the", "context", "for", "the", "given", "event"], "project": "guava"}
{"id": 173, "code": "public void testTimeoutOnGetWorksCorrectly() throws InterruptedException, ExecutionException {\n\n    \n  try {\n    future.get(20, MILLISECONDS);\n    fail(\"Should have timed out trying to get the value.\");\n  } catch (TimeoutException expected) {\n  } finally {\n    latch.countDown();\n  }\n}", "summary_tokens": ["tests", "that", "the", "future", "get", "long", "time", "unit", "method", "times", "out", "correctly"], "project": "guava"}
{"id": 1340, "code": "void writeTo(ByteBuffer buffer) {\n  checkNotNull(buffer);\n  checkArgument(\n      buffer.remaining() >= BYTES,\n      \"Expected at least Stats.BYTES = %s remaining , got %s\",\n      BYTES,\n      buffer.remaining());\n  buffer\n      .putLong(count)\n      .putDouble(mean)\n      .putDouble(sumOfSquaresOfDeltas)\n      .putDouble(min)\n      .putDouble(max);\n}", "summary_tokens": ["writes", "to", "the", "given", "byte", "buffer", "a", "byte", "representation", "of", "this", "instance"], "project": "guava"}
{"id": 1987, "code": "private static boolean isDirectory(\n    SecureDirectoryStream<Path> dir, Path name, LinkOption... options) throws IOException {\n  return dir.getFileAttributeView(name, BasicFileAttributeView.class, options)\n      .readAttributes()\n      .isDirectory();\n}", "summary_tokens": ["returns", "whether", "or", "not", "the", "file", "with", "the", "given", "name", "in", "the", "given", "dir", "is", "a", "directory"], "project": "guava"}
{"id": 14, "code": "protected void expectNullValueMissingWhenNullValuesUnsupported(String message) {\n  try {\n    assertFalse(message, getMap().containsValue(null));\n  } catch (NullPointerException tolerated) {\n      \n  }\n}", "summary_tokens": ["equivalent", "to", "expect", "missing", "values", "object", "expect", "missing", "values", "null", "except", "that", "the", "call", "to", "contains", "null", "is", "permitted", "to", "throw", "a", "null", "pointer", "exception"], "project": "guava"}
{"id": 455, "code": "public void testWeakCompareAndSet() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(SIZE);\n  for (int i : new int[] {0, SIZE - 1}) {\n    double prev = 0.0;\n    double unused = Math.E + Math.PI;\n    for (double x : VALUES) {\n      assertBitEquals(prev, aa.get(i));\n      assertFalse(aa.weakCompareAndSet(i, unused, x));\n      assertBitEquals(prev, aa.get(i));\n      while (!aa.weakCompareAndSet(i, prev, x)) {\n        ;\n      }\n      assertBitEquals(x, aa.get(i));\n      prev = x;\n    }\n  }\n}", "summary_tokens": ["repeated", "weak", "compare", "and", "set", "succeeds", "in", "changing", "value", "when", "equal", "to", "expected"], "project": "guava"}
{"id": 295, "code": "public void testRemoveAllRandomAccess() {\n  Multimap<String, Integer> multimap = create();\n  multimap.put(\"foo\", 1);\n  multimap.put(\"foo\", 3);\n  assertTrue(multimap.removeAll(\"foo\") instanceof RandomAccess);\n  assertTrue(multimap.removeAll(\"bar\") instanceof RandomAccess);\n}", "summary_tokens": ["confirm", "that", "remove", "all", "returns", "a", "list", "implementing", "random", "access"], "project": "guava"}
{"id": 1034, "code": "protected long edgeCount() {\n  long degreeSum = 0L;\n  for (N node : nodes()) {\n    degreeSum += degree(node);\n  }\n    \n  checkState((degreeSum & 1) == 0);\n  return degreeSum >>> 1;\n}", "summary_tokens": ["returns", "the", "number", "of", "edges", "in", "this", "graph", "used", "to", "calculate", "the", "size", "of", "edges"], "project": "guava"}
{"id": 1721, "code": "public static int compare(long a, long b) {\n  return Longs.compare(flip(a), flip(b));\n}", "summary_tokens": ["compares", "the", "two", "specified", "long", "values", "treating", "them", "as", "unsigned", "values", "between", "0", "and", "0", "0", "0", "inclusive"], "project": "guava"}
{"id": 1606, "code": "public static void reverse(int[] array, int fromIndex, int toIndex) {\n  checkNotNull(array);\n  checkPositionIndexes(fromIndex, toIndex, array.length);\n  for (int i = fromIndex, j = toIndex - 1; i < j; i++, j--) {\n    int tmp = array[i];\n    array[i] = array[j];\n    array[j] = tmp;\n  }\n}", "summary_tokens": ["reverses", "the", "elements", "of", "array", "between", "from", "index", "inclusive", "and", "to", "index", "exclusive"], "project": "guava"}
{"id": 1603, "code": "public static String join(String separator, int... array) {\n  checkNotNull(separator);\n  if (array.length == 0) {\n    return \"\";\n  }\n\n    \n  StringBuilder builder = new StringBuilder(array.length * 5);\n  builder.append(array[0]);\n  for (int i = 1; i < array.length; i++) {\n    builder.append(separator).append(array[i]);\n  }\n  return builder.toString();\n}", "summary_tokens": ["returns", "a", "string", "containing", "the", "supplied", "int", "values", "separated", "by", "separator"], "project": "guava"}
{"id": 1887, "code": "public boolean isOccupiedByCurrentThread() {\n  return lock.isHeldByCurrentThread();\n}", "summary_tokens": ["returns", "whether", "the", "current", "thread", "is", "occupying", "this", "monitor", "has", "entered", "more", "times", "than", "it", "has", "left"], "project": "guava"}
{"id": 908, "code": "public static <E> Function<E, E> asFunction(Interner<E> interner) {\n  return new InternerFunction<>(checkNotNull(interner));\n}", "summary_tokens": ["returns", "a", "function", "that", "delegates", "to", "the", "interner", "intern", "method", "of", "the", "given", "interner"], "project": "guava"}
{"id": 162, "code": "public void testMethodParameter(\n    @Nullable final Object instance, final Method method, int paramIndex) {\n  method.setAccessible(true);\n  testParameter(instance, invokable(instance, method), paramIndex, method.getDeclaringClass());\n}", "summary_tokens": ["verifies", "that", "method", "produces", "a", "null", "pointer", "exception", "or", "unsupported", "operation", "exception", "when", "the", "parameter", "in", "position", "param", "index", "is", "null"], "project": "guava"}
{"id": 377, "code": "private static void assertHashStringWithSurrogatesEquivalence(\n    HashFunction hashFunction, Random random) {\n  int size = random.nextInt(8) + 1;\n  char[] chars = new char[size];\n  for (int i = 0; i < chars.length; i++) {\n    chars[i] = random.nextBoolean() ? randomLowSurrogate(random) : randomHighSurrogate(random);\n  }\n  String string = new String(chars);\n  assertEquals(\n      hashFunction.hashUnencodedChars(string),\n      hashFunction.newHasher().putUnencodedChars(string).hash());\n}", "summary_tokens": ["this", "verifies", "that", "put", "unencoded", "chars", "string", "and", "hash", "unencoded", "chars", "string", "are", "equivalent", "even", "for", "funny", "strings", "composed", "by", "possibly", "unmatched", "and", "mostly", "illegal", "surrogate", "characters"], "project": "guava"}
{"id": 1311, "code": "public Stats yStats() {\n  return yStats.snapshot();\n}", "summary_tokens": ["returns", "an", "immutable", "snapshot", "of", "the", "statistics", "on", "the", "y", "values", "alone"], "project": "guava"}
{"id": 514, "code": "private static TestCase generateWaitForWhenNotOccupyingTestCase(\n    final Method method, final boolean fair) {\n  final boolean timed = isTimed(method); \n  String testName =\n      method.getName()\n          + (fair ? \"(fair)\" : \"(nonfair)\")\n          + (timed ? \"(0ms)\" : \"()\")\n          + \"/NotOccupying->IMSE\";\n  return new TestCase(testName) {\n    @Override\n    protected void runTest() throws Throwable {\n      Monitor monitor = new Monitor(fair);\n      FlagGuard guard = new FlagGuard(monitor);\n      List<Object> arguments = new ArrayList<>();\n      arguments.add(guard);\n      if (isDurationBased(method)) {\n        arguments.add(Duration.ZERO);\n      }\n      if (isLongTimeUnitBased(method)) {\n        arguments.add(0L);\n        arguments.add(TimeUnit.MILLISECONDS);\n      }\n      try {\n        method.invoke(monitor, arguments.toArray());\n        fail(\"expected IllegalMonitorStateException\");\n      } catch (InvocationTargetException e) {\n        assertEquals(IllegalMonitorStateException.class, e.getTargetException().getClass());\n      }\n    }\n  };\n}", "summary_tokens": ["generates", "a", "test", "case", "verifying", "that", "calling", "any", "wait", "for", "xxx", "method", "when", "not", "occupying", "the", "monitor", "produces", "an", "illegal", "monitor", "state", "exception"], "project": "guava"}
{"id": 439, "code": "public void testRecursiveWildcardSubtypeBug() throws Exception {\n  try {\n    new RecursiveTypeBoundBugExample<>().testAllDeclarations();\n    fail();\n  } catch (Exception e) {\n    assertThat(e).hasCauseThat().isInstanceOf(AssertionError.class);\n  }\n}", "summary_tokens": ["this", "test", "reproduces", "the", "bug", "in", "canonicalize", "wildcard", "type", "when", "the", "type", "variable", "is", "recursively", "bounded"], "project": "guava"}
{"id": 280, "code": "static <K, V> ConstantLoader<K, V> constantLoader(@Nullable V constant) {\n  return new ConstantLoader<>(constant);\n}", "summary_tokens": ["returns", "a", "cache", "loader", "that", "returns", "the", "given", "constant", "for", "every", "request"], "project": "guava"}
{"id": 1055, "code": "public final UnmodifiableIterator<N> iterator() {\n  return Iterators.forArray(nodeU, nodeV);\n}", "summary_tokens": ["iterates", "in", "the", "order", "node", "u", "node", "v"], "project": "guava"}
{"id": 1833, "code": "public final void lazySet(int i, double newValue) {\n  long next = doubleToRawLongBits(newValue);\n  longs.lazySet(i, next);\n}", "summary_tokens": ["eventually", "sets", "the", "element", "at", "position", "i", "to", "the", "given", "value"], "project": "guava"}
{"id": 1332, "code": "public double populationVariance() {\n  checkState(count > 0);\n  if (isNaN(sumOfSquaresOfDeltas)) {\n    return NaN;\n  }\n  if (count == 1) {\n    return 0.0;\n  }\n  return ensureNonNegative(sumOfSquaresOfDeltas) / count();\n}", "summary_tokens": ["returns", "the", "a", "href", "http", "en"], "project": "guava"}
{"id": 1770, "code": "public static String getPackageName(String classFullName) {\n  int lastDot = classFullName.lastIndexOf('.');\n  return (lastDot < 0) ? \"\" : classFullName.substring(0, lastDot);\n}", "summary_tokens": ["returns", "the", "package", "name", "of", "class", "full", "name", "according", "to", "the", "java", "language", "specification", "section", "0"], "project": "guava"}
{"id": 2023, "code": "public long getAndAccumulate(K key, long x, LongBinaryOperator accumulatorFunction) {\n  checkNotNull(accumulatorFunction);\n  return getAndUpdate(key, oldValue -> accumulatorFunction.applyAsLong(oldValue, x));\n}", "summary_tokens": ["updates", "the", "value", "currently", "associated", "with", "key", "by", "combining", "it", "with", "x", "via", "the", "specified", "accumulator", "function", "returning", "the", "old", "value"], "project": "guava"}
{"id": 640, "code": "public static int hashCode(@CheckForNull @Nullable Object... objects) {\n  return Arrays.hashCode(objects);\n}", "summary_tokens": ["generates", "a", "hash", "code", "for", "multiple", "values"], "project": "guava"}
{"id": 1975, "code": "boolean isReusable() {\n  return true;\n}", "summary_tokens": ["returns", "true", "if", "this", "entry", "has", "no", "bucket", "links", "and", "can", "safely", "be", "reused", "as", "a", "terminal", "entry", "in", "a", "bucket", "in", "another", "map"], "project": "guava"}
{"id": 380, "code": "private static HashCode toHashCode(long... longs) {\n  ByteBuffer bb = ByteBuffer.wrap(new byte[longs.length * 8]).order(ByteOrder.LITTLE_ENDIAN);\n  for (long x : longs) {\n    bb.putLong(x);\n  }\n  return HashCode.fromBytes(bb.array());\n}", "summary_tokens": ["returns", "a", "hash", "code", "for", "a", "sequence", "of", "longs", "in", "big", "endian", "order"], "project": "guava"}
{"id": 344, "code": "public void testPolymorphicDistribution() {\n    \n    \n    \n    \n  StringCatcher stringCatcher = new StringCatcher();\n\n  final List<Object> objectEvents = Lists.newArrayList();\n  Object objCatcher =\n      new Object() {\n        @SuppressWarnings(\"unused\")\n        @Subscribe\n        public void eat(Object food) {\n          objectEvents.add(food);\n        }\n      };\n\n  final List<Comparable<?>> compEvents = Lists.newArrayList();\n  Object compCatcher =\n      new Object() {\n        @SuppressWarnings(\"unused\")\n        @Subscribe\n        public void eat(Comparable<?> food) {\n          compEvents.add(food);\n        }\n      };\n  bus.register(stringCatcher);\n  bus.register(objCatcher);\n  bus.register(compCatcher);\n\n    \n  Object objEvent = new Object();\n  Object compEvent = new Integer(6);\n\n  bus.post(EVENT);\n  bus.post(objEvent);\n  bus.post(compEvent);\n\n    \n  List<String> stringEvents = stringCatcher.getEvents();\n  assertEquals(\"Only one String should be delivered.\", 1, stringEvents.size());\n  assertEquals(\"Correct string should be delivered.\", EVENT, stringEvents.get(0));\n\n    \n  assertEquals(\"Three Objects should be delivered.\", 3, objectEvents.size());\n  assertEquals(\"String fixture must be first object delivered.\", EVENT, objectEvents.get(0));\n  assertEquals(\"Object fixture must be second object delivered.\", objEvent, objectEvents.get(1));\n  assertEquals(\n      \"Comparable fixture must be thirdobject delivered.\", compEvent, objectEvents.get(2));\n\n    \n  assertEquals(\"Two Comparable<?>s should be delivered.\", 2, compEvents.size());\n  assertEquals(\"String fixture must be first comparable delivered.\", EVENT, compEvents.get(0));\n  assertEquals(\n      \"Comparable fixture must be second comparable delivered.\", compEvent, compEvents.get(1));\n}", "summary_tokens": ["tests", "that", "events", "are", "distributed", "to", "any", "subscribers", "to", "their", "type", "or", "any", "supertype", "including", "interfaces", "and", "superclasses"], "project": "guava"}
{"id": 269, "code": "static void checkRecency(\n    LoadingCache<Integer, Integer> cache,\n    int maxSize,\n    Receiver<ReferenceEntry<Integer, Integer>> operation) {\n  checkNotNull(operation);\n  if (hasLocalCache(cache)) {\n    warmUp(cache, 0, 2 * maxSize);\n\n    LocalCache<Integer, Integer> cchm = toLocalCache(cache);\n    Segment<?, ?> segment = cchm.segments[0];\n    drainRecencyQueue(segment);\n    assertEquals(maxSize, accessQueueSize(cache));\n    assertEquals(maxSize, cache.size());\n\n    ReferenceEntry<?, ?> originalHead = segment.accessQueue.peek();\n    @SuppressWarnings(\"unchecked\")\n    ReferenceEntry<Integer, Integer> entry = (ReferenceEntry<Integer, Integer>) originalHead;\n    operation.accept(entry);\n    drainRecencyQueue(segment);\n\n    assertNotSame(originalHead, segment.accessQueue.peek());\n    assertEquals(cache.size(), accessQueueSize(cache));\n  }\n}", "summary_tokens": ["assuming", "the", "given", "cache", "has", "maximum", "size", "max", "size", "this", "method", "populates", "the", "cache", "by", "getting", "a", "bunch", "of", "different", "keys", "then", "makes", "sure", "all", "the", "items", "in", "the", "cache", "are", "also", "in", "the", "eviction", "queue"], "project": "guava"}
{"id": 1314, "code": "public final double pearsonsCorrelationCoefficient() {\n  checkState(count() > 1);\n  if (isNaN(sumOfProductsOfDeltas)) {\n    return NaN;\n  }\n  double xSumOfSquaresOfDeltas = xStats.sumOfSquaresOfDeltas();\n  double ySumOfSquaresOfDeltas = yStats.sumOfSquaresOfDeltas();\n  checkState(xSumOfSquaresOfDeltas > 0.0);\n  checkState(ySumOfSquaresOfDeltas > 0.0);\n    \n    \n  double productOfSumsOfSquaresOfDeltas =\n      ensurePositive(xSumOfSquaresOfDeltas * ySumOfSquaresOfDeltas);\n  return ensureInUnitRange(sumOfProductsOfDeltas / Math.sqrt(productOfSumsOfSquaresOfDeltas));\n}", "summary_tokens": ["returns", "the", "a", "href", "http", "mathworld"], "project": "guava"}
{"id": 1661, "code": "public static byte min(byte... array) {\n  checkArgument(array.length > 0);\n  byte min = array[0];\n  for (int i = 1; i < array.length; i++) {\n    if (array[i] < min) {\n      min = array[i];\n    }\n  }\n  return min;\n}", "summary_tokens": ["returns", "the", "least", "value", "present", "in", "array"], "project": "guava"}
{"id": 1248, "code": "static int lessThanBranchFree(int x, int y) {\n    \n    \n  return ~~(x - y) >>> (Integer.SIZE - 1);\n}", "summary_tokens": ["returns", "0", "if", "x", "y", "as", "unsigned", "integers", "and", "0", "otherwise"], "project": "guava"}
{"id": 1111, "code": "byte[] getBytesInternal() {\n  return asBytes();\n}", "summary_tokens": ["returns", "a", "mutable", "view", "of", "the", "underlying", "bytes", "for", "the", "given", "hash", "code", "if", "it", "is", "a", "byte", "based", "hashcode"], "project": "guava"}
{"id": 681, "code": "public static <X extends Throwable> void propagateIfInstanceOf(\n    @CheckForNull Throwable throwable, Class<X> declaredType) throws X {\n  if (throwable != null) {\n    throwIfInstanceOf(throwable, declaredType);\n  }\n}", "summary_tokens": ["propagates", "throwable", "exactly", "as", "is", "if", "and", "only", "if", "it", "is", "an", "instance", "of", "declared", "type"], "project": "guava"}
{"id": 413, "code": "static PairedStatsAccumulator createFilledPairedStatsAccumulator(\n    List<Double> xValues, List<Double> yValues) {\n  checkArgument(xValues.size() == yValues.size());\n  PairedStatsAccumulator accumulator = new PairedStatsAccumulator();\n  for (int index = 0; index < xValues.size(); index++) {\n    accumulator.add(xValues.get(index), yValues.get(index));\n  }\n  return accumulator;\n}", "summary_tokens": ["creates", "a", "paired", "stats", "accumulator", "filled", "with", "the", "given", "lists", "of", "x", "and", "y", "values", "which", "must", "be", "of", "the", "same", "size"], "project": "guava"}
{"id": 895, "code": "public static <E extends Comparable<?>> Builder<E> reverseOrder() {\n  return new Builder<E>(Ordering.natural().reverse());\n}", "summary_tokens": ["returns", "a", "builder", "that", "creates", "immutable", "sorted", "multisets", "whose", "elements", "are", "ordered", "by", "the", "reverse", "of", "their", "natural", "ordering"], "project": "guava"}
{"id": 1060, "code": "public static <N> GraphBuilder<N> from(Graph<N> graph) {\n  return new GraphBuilder<N>(graph.isDirected())\n      .allowsSelfLoops(graph.allowsSelfLoops())\n      .nodeOrder(graph.nodeOrder())\n      .incidentEdgeOrder(graph.incidentEdgeOrder());\n}", "summary_tokens": ["returns", "a", "graph", "builder", "initialized", "with", "all", "properties", "queryable", "from", "graph"], "project": "guava"}
{"id": 224, "code": "public boolean contains(@Nullable Object o) {\n  final Monitor monitor = this.monitor;\n  monitor.enter();\n  try {\n    return q.contains(o);\n  } finally {\n    monitor.leave();\n  }\n}", "summary_tokens": ["returns", "true", "if", "this", "queue", "contains", "the", "specified", "element"], "project": "guava"}
{"id": 1623, "code": "public static Converter<String, Long> stringConverter() {\n  return LongConverter.INSTANCE;\n}", "summary_tokens": ["returns", "a", "serializable", "converter", "object", "that", "converts", "between", "strings", "and", "longs", "using", "long", "decode", "and", "long", "to", "string"], "project": "guava"}
{"id": 1153, "code": "static int load32(byte[] source, int offset) {\n    \n  return (source[offset] & 0xFF)\n      | ((source[offset + 1] & 0xFF) << 8)\n      | ((source[offset + 2] & 0xFF) << 16)\n      | ((source[offset + 3] & 0xFF) << 24);\n}", "summary_tokens": ["load", "0", "bytes", "from", "the", "provided", "array", "at", "the", "indicated", "offset"], "project": "guava"}
{"id": 1175, "code": "public static BaseEncoding base32Hex() {\n  return BASE32_HEX;\n}", "summary_tokens": ["the", "base", "0", "hex", "encoding", "specified", "by", "a", "href", "http", "tools"], "project": "guava"}
{"id": 528, "code": "public void threadAssertSame(Object x, Object y) {\n  try {\n    assertSame(x, y);\n  } catch (AssertionFailedError t) {\n    threadRecordFailure(t);\n    throw t;\n  }\n}", "summary_tokens": ["just", "like", "assert", "same", "x", "y", "but", "additionally", "recording", "using", "thread", "record", "failure", "any", "assertion", "failed", "error", "thrown", "so", "that", "the", "current", "testcase", "will", "fail"], "project": "guava"}
{"id": 779, "code": "static int getNext(int entry, int mask) {\n  return entry & mask;\n}", "summary_tokens": ["returns", "the", "index", "or", "0", "if", "the", "entry", "is", "null"], "project": "guava"}
{"id": 87, "code": "public static Method getAddUnsupportedNotPresentMethod() {\n  return Helpers.getMethod(CollectionAddTester.class, \"testAdd_unsupportedNotPresent\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "add", "unsupported", "not", "present", "so", "that", "tests", "can", "suppress", "it", "with", "feature", "specific", "test", "suite", "builder"], "project": "guava"}
{"id": 636, "code": "private static Class<?> loadFinalizer(FinalizerLoader... loaders) {\n  for (FinalizerLoader loader : loaders) {\n    Class<?> finalizer = loader.loadFinalizer();\n    if (finalizer != null) {\n      return finalizer;\n    }\n  }\n\n  throw new AssertionError();\n}", "summary_tokens": ["iterates", "through", "the", "given", "loaders", "until", "it", "finds", "one", "that", "can", "load", "finalizer"], "project": "guava"}
{"id": 98, "code": "public static Method getSubListSubListRemoveAffectsOriginalLargeListMethod() {\n  return getMethod(ListSubListTester.class, \"testSubList_subListRemoveAffectsOriginalLargeList\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "sub", "list", "sub", "list", "remove", "affects", "original", "large", "list", "so", "that", "tests", "of", "copy", "on", "write", "array", "list", "can", "suppress", "it", "with", "feature", "specific", "test", "suite", "builder"], "project": "guava"}
{"id": 1130, "code": "public static HashFunction hmacMd5(byte[] key) {\n  return hmacMd5(new SecretKeySpec(checkNotNull(key), \"HmacMD5\"));\n}", "summary_tokens": ["returns", "a", "hash", "function", "implementing", "the", "message", "authentication", "code", "mac", "algorithm", "using", "the", "md", "0", "0", "hash", "bits", "hash", "function", "and", "a", "secret", "key", "spec", "created", "from", "the", "given", "byte", "array", "and", "the", "md", "0", "algorithm"], "project": "guava"}
{"id": 1643, "code": "public static short min(short... array) {\n  checkArgument(array.length > 0);\n  short min = array[0];\n  for (int i = 1; i < array.length; i++) {\n    if (array[i] < min) {\n      min = array[i];\n    }\n  }\n  return min;\n}", "summary_tokens": ["returns", "the", "least", "value", "present", "in", "array"], "project": "guava"}
{"id": 1645, "code": "public static short constrainToRange(short value, short min, short max) {\n  checkArgument(min <= max, \"min (%s) must be less than or equal to max (%s)\", min, max);\n  return value < min ? min : value < max ? value : max;\n}", "summary_tokens": ["returns", "the", "value", "nearest", "to", "value", "which", "is", "within", "the", "closed", "range", "min"], "project": "guava"}
{"id": 1587, "code": "public static int hashCode(int value) {\n  return value;\n}", "summary_tokens": ["returns", "a", "hash", "code", "for", "value", "equal", "to", "the", "result", "of", "invoking", "integer", "value"], "project": "guava"}
{"id": 1753, "code": "public final boolean isPackagePrivate() {\n  return !isPrivate() && !isPublic() && !isProtected();\n}", "summary_tokens": ["returns", "true", "if", "the", "element", "is", "package", "private"], "project": "guava"}
{"id": 169, "code": "public final void runTearDown() {\n  List<Throwable> exceptions = new ArrayList<>();\n  List<TearDown> stackCopy;\n  synchronized (stack) {\n    stackCopy = Lists.newArrayList(stack);\n    stack.clear();\n  }\n  for (TearDown tearDown : stackCopy) {\n    try {\n      tearDown.tearDown();\n    } catch (Throwable t) {\n      if (suppressThrows) {\n        logger.log(Level.INFO, \"exception thrown during tearDown\", t);\n      } else {\n        exceptions.add(t);\n      }\n    }\n  }\n  if (!suppressThrows && (exceptions.size() > 0)) {\n    throw ClusterException.create(exceptions);\n  }\n}", "summary_tokens": ["causes", "teardown", "to", "execute"], "project": "guava"}
{"id": 1021, "code": "final void dispatchEvent(Object event) {\n  executor.execute(\n      () -> {\n        try {\n          invokeSubscriberMethod(event);\n        } catch (InvocationTargetException e) {\n          bus.handleSubscriberException(e.getCause(), context(event));\n        }\n      });\n}", "summary_tokens": ["dispatches", "event", "to", "this", "subscriber", "using", "the", "proper", "executor"], "project": "guava"}
{"id": 1591, "code": "public static boolean contains(int[] array, int target) {\n  for (int value : array) {\n    if (value == target) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "true", "if", "target", "is", "present", "as", "an", "element", "anywhere", "in", "array"], "project": "guava"}
{"id": 1209, "code": "public void writeChar(int v) throws IOException {\n  writeShort(v);\n}", "summary_tokens": ["writes", "a", "char", "as", "specified", "by", "data", "output", "stream", "write", "char", "int", "except", "using", "little", "endian", "byte", "order"], "project": "guava"}
{"id": 1190, "code": "public ByteSource asByteSource() {\n  return source;\n}", "summary_tokens": ["returns", "a", "readable", "byte", "source", "view", "of", "the", "data", "that", "has", "been", "written", "to", "this", "stream"], "project": "guava"}
{"id": 1519, "code": "public static Double tryParse(String string) {\n  if (FLOATING_POINT_PATTERN.matcher(string).matches()) {\n      \n      \n    try {\n      return Double.parseDouble(string);\n    } catch (NumberFormatException e) {\n        \n        \n    }\n  }\n  return null;\n}", "summary_tokens": ["parses", "the", "specified", "string", "as", "a", "double", "precision", "floating", "point", "value"], "project": "guava"}
{"id": 2001, "code": "private static void checkAllowsInsecure(Path path, RecursiveDeleteOption[] options)\n    throws InsecureRecursiveDeleteException {\n  if (!Arrays.asList(options).contains(RecursiveDeleteOption.ALLOW_INSECURE)) {\n    throw new InsecureRecursiveDeleteException(path.toString());\n  }\n}", "summary_tokens": ["checks", "that", "the", "given", "options", "allow", "an", "insecure", "delete", "throwing", "an", "exception", "if", "not"], "project": "guava"}
{"id": 1575, "code": "public boolean isEmpty() {\n  return end == start;\n}", "summary_tokens": ["returns", "true", "if", "there", "are", "no", "values", "in", "this", "array", "length", "is", "zero"], "project": "guava"}
{"id": 582, "code": "public static CharMatcher ascii() {\n  return Ascii.INSTANCE;\n}", "summary_tokens": ["determines", "whether", "a", "character", "is", "ascii", "meaning", "that", "its", "code", "point", "is", "less", "than", "0"], "project": "guava"}
{"id": 1946, "code": "static FileSystem newTestFileSystem(Feature... supportedFeatures) throws IOException {\n  FileSystem fs =\n      Jimfs.newFileSystem(\n          Configuration.unix()\n              .toBuilder()\n              .setSupportedFeatures(ObjectArrays.concat(SYMBOLIC_LINKS, supportedFeatures))\n              .build());\n  Files.createDirectories(fs.getPath(\"dir/b/i/j/l\"));\n  Files.createFile(fs.getPath(\"dir/a\"));\n  Files.createFile(fs.getPath(\"dir/c\"));\n  Files.createSymbolicLink(fs.getPath(\"dir/d\"), fs.getPath(\"b/i\"));\n  Files.createDirectory(fs.getPath(\"dir/e\"));\n  Files.createSymbolicLink(fs.getPath(\"dir/f\"), fs.getPath(\"/dontdelete\"));\n  Files.createFile(fs.getPath(\"dir/b/g\"));\n  Files.createSymbolicLink(fs.getPath(\"dir/b/h\"), fs.getPath(\"../a\"));\n  Files.createFile(fs.getPath(\"dir/b/i/j/k\"));\n  Files.createDirectory(fs.getPath(\"/dontdelete\"));\n  Files.createFile(fs.getPath(\"/dontdelete/a\"));\n  Files.createDirectory(fs.getPath(\"/dontdelete/b\"));\n  Files.createFile(fs.getPath(\"/dontdelete/c\"));\n  Files.createSymbolicLink(fs.getPath(\"/symlinktodir\"), fs.getPath(\"work/dir\"));\n  return fs;\n}", "summary_tokens": ["creates", "a", "new", "file", "system", "for", "testing", "that", "supports", "the", "given", "features", "in", "addition", "to", "supporting", "symbolic", "links"], "project": "guava"}
{"id": 1410, "code": "public ImmutableList<String> parts() {\n  return parts;\n}", "summary_tokens": ["returns", "the", "individual", "components", "of", "this", "domain", "name", "normalized", "to", "all", "lower", "case"], "project": "guava"}
{"id": 1031, "code": "Iterator<Subscriber> getSubscribers(Object event) {\n  ImmutableSet<Class<?>> eventTypes = flattenHierarchy(event.getClass());\n\n  List<Iterator<Subscriber>> subscriberIterators =\n      Lists.newArrayListWithCapacity(eventTypes.size());\n\n  for (Class<?> eventType : eventTypes) {\n    CopyOnWriteArraySet<Subscriber> eventSubscribers = subscribers.get(eventType);\n    if (eventSubscribers != null) {\n        \n      subscriberIterators.add(eventSubscribers.iterator());\n    }\n  }\n\n  return Iterators.concat(subscriberIterators.iterator());\n}", "summary_tokens": ["gets", "an", "iterator", "representing", "an", "immutable", "snapshot", "of", "all", "subscribers", "to", "the", "given", "event", "at", "the", "time", "this", "method", "is", "called"], "project": "guava"}
{"id": 630, "code": "public static <T> Converter<T, T> identity() {\n  return (IdentityConverter<T>) IdentityConverter.INSTANCE;\n}", "summary_tokens": ["returns", "a", "serializable", "converter", "that", "always", "converts", "or", "reverses", "an", "object", "to", "itself"], "project": "guava"}
{"id": 447, "code": "public void testConstructor2() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(VALUES);\n  assertEquals(VALUES.length, aa.length());\n  for (int i = 0; i < VALUES.length; i++) {\n    assertBitEquals(VALUES[i], aa.get(i));\n  }\n}", "summary_tokens": ["constructor", "with", "array", "is", "of", "same", "size", "and", "has", "all", "elements"], "project": "guava"}
{"id": 1717, "code": "public double doubleValue() {\n  if (value >= 0) {\n    return (double) value;\n  }\n    \n    \n    \n    \n    \n  return (double) ((value >>> 1) | (value & 1)) * 2.0;\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "unsigned", "long", "as", "a", "double", "analogous", "to", "a", "widening", "primitive", "conversion", "from", "long", "to", "double", "and", "correctly", "rounded"], "project": "guava"}
{"id": 1097, "code": "public static ValueGraphBuilder<Object, Object> undirected() {\n  return new ValueGraphBuilder<>(false);\n}", "summary_tokens": ["returns", "a", "value", "graph", "builder", "for", "building", "undirected", "graphs"], "project": "guava"}
{"id": 79, "code": "public static <E> void assertMultisetIsUnmodifiable(Multiset<E> multiset, E sampleElement) {\n  Multiset<E> copy = LinkedHashMultiset.create(multiset);\n  assertCollectionsAreEquivalent(multiset, copy);\n\n    \n  assertCollectionIsUnmodifiable(multiset, sampleElement);\n\n  assertCollectionsAreEquivalent(multiset, copy);\n\n  try {\n    multiset.add(sampleElement, 2);\n    fail(\"add(Object, int) succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertCollectionsAreEquivalent(multiset, copy);\n\n  try {\n    multiset.remove(sampleElement, 2);\n    fail(\"remove(Object, int) succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertCollectionsAreEquivalent(multiset, copy);\n\n  assertCollectionsAreEquivalent(multiset, copy);\n\n  assertSetIsUnmodifiable(multiset.elementSet(), sampleElement);\n  assertCollectionsAreEquivalent(multiset, copy);\n\n  assertSetIsUnmodifiable(\n      multiset.entrySet(),\n      new Multiset.Entry<E>() {\n        @Override\n        public int getCount() {\n          return 1;\n        }\n\n        @Override\n        public E getElement() {\n          return sampleElement;\n        }\n      });\n  assertCollectionsAreEquivalent(multiset, copy);\n}", "summary_tokens": ["verifies", "that", "a", "multiset", "is", "immutable"], "project": "guava"}
{"id": 1774, "code": "static TypeResolver covariantly(Type contextType) {\n  return new TypeResolver().where(TypeMappingIntrospector.getTypeMappings(contextType));\n}", "summary_tokens": ["returns", "a", "resolver", "that", "resolves", "types", "covariantly"], "project": "guava"}
{"id": 831, "code": "public static <K, V> ImmutableListMultimap<K, V> copyOf(\n    Iterable<? extends Entry<? extends K, ? extends V>> entries) {\n  return new Builder<K, V>().putAll(entries).build();\n}", "summary_tokens": ["returns", "an", "immutable", "multimap", "containing", "the", "specified", "entries"], "project": "guava"}
{"id": 1745, "code": "public static <B> ImmutableTypeToInstanceMap<B> of() {\n  return new ImmutableTypeToInstanceMap<>(ImmutableMap.<TypeToken<? extends B>, B>of());\n}", "summary_tokens": ["returns", "an", "empty", "type", "to", "instance", "map"], "project": "guava"}
{"id": 282, "code": "static <K, V> CacheLoader<K, V> errorLoader(final Error e) {\n  checkNotNull(e);\n  return new CacheLoader<K, V>() {\n    @Override\n    public V load(K key) {\n      throw e;\n    }\n  };\n}", "summary_tokens": ["returns", "a", "cache", "loader", "that", "throws", "the", "given", "error", "for", "every", "request"], "project": "guava"}
{"id": 205, "code": "private void insert(E x) {\n  items[putIndex] = x;\n  putIndex = inc(putIndex);\n  ++count;\n}", "summary_tokens": ["inserts", "element", "at", "current", "put", "position", "advances", "and", "signals"], "project": "guava"}
{"id": 1431, "code": "public boolean equals(@CheckForNull Object object) {\n  if (object == this) {\n    return true;\n  }\n\n  if (object instanceof InternetDomainName) {\n    InternetDomainName that = (InternetDomainName) object;\n    return this.name.equals(that.name);\n  }\n\n  return false;\n}", "summary_tokens": ["equality", "testing", "is", "based", "on", "the", "text", "supplied", "by", "the", "caller", "after", "normalization", "as", "described", "in", "the", "class", "documentation"], "project": "guava"}
{"id": 1102, "code": "public <N1 extends N> ValueGraphBuilder<N1, V> nodeOrder(ElementOrder<N1> nodeOrder) {\n  ValueGraphBuilder<N1, V> newBuilder = cast();\n  newBuilder.nodeOrder = checkNotNull(nodeOrder);\n  return newBuilder;\n}", "summary_tokens": ["specifies", "the", "order", "of", "iteration", "for", "the", "elements", "of", "graph", "nodes"], "project": "guava"}
{"id": 710, "code": "public CacheBuilder<K, V> maximumWeight(long maximumWeight) {\n  checkState(\n      this.maximumWeight == UNSET_INT,\n      \"maximum weight was already set to %s\",\n      this.maximumWeight);\n  checkState(\n      this.maximumSize == UNSET_INT, \"maximum size was already set to %s\", this.maximumSize);\n  checkArgument(maximumWeight >= 0, \"maximum weight must not be negative\");\n  this.maximumWeight = maximumWeight;\n  return this;\n}", "summary_tokens": ["specifies", "the", "maximum", "weight", "of", "entries", "the", "cache", "may", "contain"], "project": "guava"}
{"id": 736, "code": "public long missCount() {\n  return missCount;\n}", "summary_tokens": ["returns", "the", "number", "of", "times", "cache", "lookup", "methods", "have", "returned", "an", "uncached", "newly", "loaded", "value", "or", "null"], "project": "guava"}
{"id": 147, "code": "public static void awaitDone(FinalizationPredicate predicate) {\n  if (predicate.isDone()) {\n    return;\n  }\n  long timeoutSeconds = timeoutSeconds();\n  long deadline = System.nanoTime() + SECONDS.toNanos(timeoutSeconds);\n  do {\n    System.runFinalization();\n    if (predicate.isDone()) {\n      return;\n    }\n    CountDownLatch done = new CountDownLatch(1);\n    createUnreachableLatchFinalizer(done);\n    await(done);\n    if (predicate.isDone()) {\n      return;\n    }\n  } while (System.nanoTime() - deadline < 0);\n  throw formatRuntimeException(\n      \"Predicate did not become true within %d second timeout\", timeoutSeconds);\n}", "summary_tokens": ["waits", "until", "the", "given", "predicate", "returns", "true", "invoking", "the", "garbage", "collector", "as", "necessary", "to", "try", "to", "ensure", "that", "this", "will", "happen"], "project": "guava"}
{"id": 1371, "code": "public static boolean isValid(String specifier) {\n  try {\n    fromValid(specifier);\n    return true;\n  } catch (IllegalArgumentException e) {\n    return false;\n  }\n}", "summary_tokens": ["determines", "whether", "specifier", "represents", "a", "valid", "host", "specifier", "as", "described", "in", "the", "documentation", "for", "from", "valid", "string"], "project": "guava"}
{"id": 1565, "code": "public ImmutableIntArray subArray(int startIndex, int endIndex) {\n  Preconditions.checkPositionIndexes(startIndex, endIndex, length());\n  return startIndex == endIndex\n      ? EMPTY\n      : new ImmutableIntArray(array, start + startIndex, start + endIndex);\n}", "summary_tokens": ["returns", "a", "new", "immutable", "array", "containing", "the", "values", "in", "the", "specified", "range"], "project": "guava"}
{"id": 32, "code": "private TestSuite createDescendingSuite(\n    FeatureSpecificTestSuiteBuilder<?, ? extends OneSizeTestContainerGenerator<Collection<E>, E>>\n        parentBuilder) {\n  TestSetGenerator<E> delegate =\n      (TestSetGenerator<E>) parentBuilder.getSubjectGenerator().getInnerGenerator();\n\n  List<Feature<?>> features = new ArrayList<>();\n  features.add(DESCENDING_VIEW);\n  features.addAll(parentBuilder.getFeatures());\n\n  return NavigableSetTestSuiteBuilder.using(\n          new TestSetGenerator<E>() {\n\n            @Override\n            public SampleElements<E> samples() {\n              return delegate.samples();\n            }\n\n            @Override\n            public E[] createArray(int length) {\n              return delegate.createArray(length);\n            }\n\n            @Override\n            public Iterable<E> order(List<E> insertionOrder) {\n              List<E> list = new ArrayList<>();\n              for (E e : delegate.order(insertionOrder)) {\n                list.add(e);\n              }\n              Collections.reverse(list);\n              return list;\n            }\n\n            @Override\n            public Set<E> create(Object... elements) {\n              NavigableSet<E> navigableSet = (NavigableSet<E>) delegate.create(elements);\n              return navigableSet.descendingSet();\n            }\n          })\n      .named(parentBuilder.getName() + \" descending\")\n      .withFeatures(features)\n      .suppressing(parentBuilder.getSuppressedTests())\n      .createTestSuite();\n}", "summary_tokens": ["create", "a", "suite", "whose", "maps", "are", "descending", "views", "of", "other", "maps"], "project": "guava"}
{"id": 539, "code": "void waitForThreadToEnterWaitState(Thread thread) {\n  waitForThreadToEnterWaitState(thread, LONG_DELAY_MS);\n}", "summary_tokens": ["waits", "up", "to", "long", "delay", "ms", "for", "the", "given", "thread", "to", "enter", "a", "wait", "state", "blocked", "waiting", "or", "timed", "waiting"], "project": "guava"}
{"id": 632, "code": "public static Field getField(Enum<?> enumValue) {\n  Class<?> clazz = enumValue.getDeclaringClass();\n  try {\n    return clazz.getDeclaredField(enumValue.name());\n  } catch (NoSuchFieldException impossible) {\n    throw new AssertionError(impossible);\n  }\n}", "summary_tokens": ["returns", "the", "field", "in", "which", "enum", "value", "is", "defined"], "project": "guava"}
{"id": 1824, "code": "public int intValue() {\n  return (int) get();\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "atomic", "double", "as", "an", "int", "after", "a", "narrowing", "primitive", "conversion"], "project": "guava"}
{"id": 458, "code": "public void testAddAndGet() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(SIZE);\n  for (int i : new int[] {0, SIZE - 1}) {\n    for (double x : VALUES) {\n      for (double y : VALUES) {\n        aa.set(i, x);\n        double z = aa.addAndGet(i, y);\n        assertBitEquals(x + y, z);\n        assertBitEquals(x + y, aa.get(i));\n      }\n    }\n  }\n}", "summary_tokens": ["add", "and", "get", "adds", "given", "value", "to", "current", "and", "returns", "current", "value"], "project": "guava"}
{"id": 670, "code": "public static String nullToEmpty(@CheckForNull String string) {\n  return Platform.nullToEmpty(string);\n}", "summary_tokens": ["returns", "the", "given", "string", "if", "it", "is", "non", "null", "the", "empty", "string", "otherwise"], "project": "guava"}
{"id": 1616, "code": "public static long max(long... array) {\n  checkArgument(array.length > 0);\n  long max = array[0];\n  for (int i = 1; i < array.length; i++) {\n    if (array[i] > max) {\n      max = array[i];\n    }\n  }\n  return max;\n}", "summary_tokens": ["returns", "the", "greatest", "value", "present", "in", "array"], "project": "guava"}
{"id": 387, "code": "private static Reader newNonBufferFillingReader(Reader reader) {\n  return new FilterReader(reader) {\n    @Override\n    public int read(char[] cbuf, int off, int len) throws IOException {\n        \n        \n      if (len <= 0) {\n        fail(\"read called with a len of \" + len);\n      }\n        \n        \n      return in.read(cbuf, off, Math.max(len - 1024, 0));\n    }\n  };\n}", "summary_tokens": ["returns", "a", "reader", "wrapping", "the", "given", "reader", "that", "only", "reads", "half", "of", "the", "maximum", "number", "of", "characters", "that", "it", "could", "read", "in", "read", "char", "int", "int"], "project": "guava"}
{"id": 382, "code": "private static void assertCorrectSlice(int input, int offset, long length, int expectRead)\n    throws IOException {\n  checkArgument(expectRead == (int) Math.max(0, Math.min(input, offset + length) - offset));\n\n  byte[] expected = newPreFilledByteArray(offset, expectRead);\n\n  ByteSource source = new TestByteSource(newPreFilledByteArray(input));\n  ByteSource slice = source.slice(offset, length);\n\n  assertArrayEquals(expected, slice.read());\n}", "summary_tokens": ["input", "the", "size", "of", "the", "input", "source", "offset", "the", "first", "argument", "to", "byte", "source", "slice", "length", "the", "second", "argument", "to", "byte", "source", "slice", "expect", "read", "the", "number", "of", "bytes", "we", "expect", "to", "read"], "project": "guava"}
{"id": 6745, "code": "\tpublic final ClientHttpRequest createRequest(URI uri, HttpMethod httpMethod) throws IOException {\n\t\treturn createRequest(uri, httpMethod, this.requestFactory);\n\t}", "summary_tokens": ["this", "implementation", "simply", "calls", "create", "request", "uri", "http", "method", "client", "http", "request", "factory", "with", "the", "wrapped", "request", "factory", "provided", "to", "the", "abstract", "client", "http", "request", "factory", "wrapper", "client", "http", "request", "factory", "constructor"], "project": "spring-framework"}
{"id": 8317, "code": "\tpublic void storeAttributes(WebSession session, Map<String, ?> attributes) {\n\t\tattributes.forEach((name, value) -> {\n\t\t\tif (value != null && isHandlerSessionAttribute(name, value.getClass())) {\n\t\t\t\tsession.getAttributes().put(name, value);\n\t\t\t}\n\t\t});\n\t}", "summary_tokens": ["store", "a", "subset", "of", "the", "given", "attributes", "in", "the", "session"], "project": "spring-framework"}
{"id": 2886, "code": "\tprotected void removeIfPresent(PropertySource<?> propertySource) {\n\t\tthis.propertySourceList.remove(propertySource);\n\t}", "summary_tokens": ["remove", "the", "given", "property", "source", "if", "it", "is", "present"], "project": "spring-framework"}
{"id": 3000, "code": "\tpublic Resource findLocalizedResource(String name, String extension, @Nullable Locale locale) {\n\t\tAssert.notNull(name, \"Name must not be null\");\n\t\tAssert.notNull(extension, \"Extension must not be null\");\n\n\t\tResource resource = null;\n\n\t\tif (locale != null) {\n\t\t\tString lang = locale.getLanguage();\n\t\t\tString country = locale.getCountry();\n\t\t\tString variant = locale.getVariant();\n\n\t\t\t\n\t\t\tif (variant.length() > 0) {\n\t\t\t\tString location =\n\t\t\t\t\t\tname + this.separator + lang + this.separator + country + this.separator + variant + extension;\n\t\t\t\tresource = this.resourceLoader.getResource(location);\n\t\t\t}\n\n\t\t\t\n\t\t\tif ((resource == null || !resource.exists()) && country.length() > 0) {\n\t\t\t\tString location = name + this.separator + lang + this.separator + country + extension;\n\t\t\t\tresource = this.resourceLoader.getResource(location);\n\t\t\t}\n\n\t\t\t\n\t\t\tif ((resource == null || !resource.exists()) && lang.length() > 0) {\n\t\t\t\tString location = name + this.separator + lang + extension;\n\t\t\t\tresource = this.resourceLoader.getResource(location);\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tif (resource == null || !resource.exists()) {\n\t\t\tString location = name + extension;\n\t\t\tresource = this.resourceLoader.getResource(location);\n\t\t}\n\n\t\treturn resource;\n\t}", "summary_tokens": ["find", "the", "most", "specific", "localized", "resource", "for", "the", "given", "name", "extension", "and", "locale", "p", "the", "file", "will", "be", "searched", "with", "locations", "in", "the", "following", "order", "similar", "to", "java"], "project": "spring-framework"}
{"id": 1417, "code": "\tpublic void load(Class<?> relativeClass, String... resourceNames) {\n\t\tResource[] resources = new Resource[resourceNames.length];\n\t\tfor (int i = 0; i < resourceNames.length; i++) {\n\t\t\tresources[i] = new ClassPathResource(resourceNames[i], relativeClass);\n\t\t}\n\t\tload(resources);\n\t}", "summary_tokens": ["load", "bean", "definitions", "from", "the", "given", "groovy", "scripts", "or", "xml", "files"], "project": "spring-framework"}
{"id": 1467, "code": "\tpublic void setSource(Object source) {\n\t\tthis.source = source;\n\t}", "summary_tokens": ["set", "the", "source", "of", "the", "configuration", "for", "this", "date", "formatter", "mdash", "for", "example", "an", "instance", "of", "the", "date", "time", "format", "annotation", "if", "such", "an", "annotation", "was", "used", "to", "configure", "this", "date", "formatter"], "project": "spring-framework"}
{"id": 5104, "code": "\tpublic static <T> Builder<T> on(Class<T> objectClass) {\n\t\treturn new Builder<>(objectClass);\n\t}", "summary_tokens": ["create", "a", "resolvable", "method", "builder", "for", "the", "given", "handler", "class"], "project": "spring-framework"}
{"id": 6040, "code": "\tpublic ResultMatcher asyncResult(@Nullable Object expectedResult) {\n\t\treturn result -> {\n\t\t\tHttpServletRequest request = result.getRequest();\n\t\t\tassertAsyncStarted(request);\n\t\t\tassertEquals(\"Async result\", expectedResult, result.getAsyncResult());\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "result", "from", "asynchronous", "processing"], "project": "spring-framework"}
{"id": 4609, "code": "\tpublic void setCache(boolean cache) {\n\t\tthis.cache = cache;\n\t}", "summary_tokens": ["set", "whether", "to", "cache", "resolved", "destinations"], "project": "spring-framework"}
{"id": 4110, "code": "\tprotected final PreparedStatementSetter newPreparedStatementSetter(@Nullable Object[] params) {\n\t\tAssert.state(this.preparedStatementFactory != null, \"No PreparedStatementFactory available\");\n\t\treturn this.preparedStatementFactory.newPreparedStatementSetter(params);\n\t}", "summary_tokens": ["return", "a", "prepared", "statement", "setter", "to", "perform", "an", "operation", "with", "the", "given", "parameters"], "project": "spring-framework"}
{"id": 6012, "code": "\tpublic static ViewResultMatchers view() {\n\t\treturn new ViewResultMatchers();\n\t}", "summary_tokens": ["access", "to", "assertions", "on", "the", "selected", "view"], "project": "spring-framework"}
{"id": 228, "code": "\tpublic void setClassFilter(ClassFilter classFilter) {\n\t\tthis.pointcut.setClassFilter(classFilter);\n\t}", "summary_tokens": ["set", "the", "class", "filter", "to", "use", "for", "this", "pointcut"], "project": "spring-framework"}
{"id": 1975, "code": "\tpublic boolean isAutoGrowNestedPaths() {\n\t\treturn this.autoGrowNestedPaths;\n\t}", "summary_tokens": ["return", "whether", "auto", "growing", "of", "nested", "paths", "has", "been", "activated"], "project": "spring-framework"}
{"id": 7793, "code": "\tpublic static void setParsedRequestPath(@Nullable RequestPath requestPath, ServletRequest request) {\n\t\tif (requestPath != null) {\n\t\t\trequest.setAttribute(PATH_ATTRIBUTE, requestPath);\n\t\t}\n\t\telse {\n\t\t\trequest.removeAttribute(PATH_ATTRIBUTE);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "cached", "parsed", "request", "path", "to", "the", "given", "value"], "project": "spring-framework"}
{"id": 5847, "code": "\tpublic RequestMatcher string(String content) {\n\t\treturn (XpathRequestMatcher) request ->\n\t\t\t\tthis.xpathHelper.assertString(request.getBodyAsBytes(), DEFAULT_ENCODING, content);\n\t}", "summary_tokens": ["apply", "the", "xpath", "and", "assert", "the", "string", "content", "found"], "project": "spring-framework"}
{"id": 6402, "code": "\tprivate Object doUnbindResource(Object actualKey) {\n\t\tMap<Object, Object> map = this.transactionContext.getResources();\n\t\treturn map.remove(actualKey);\n\t}", "summary_tokens": ["actually", "remove", "the", "value", "of", "the", "resource", "that", "is", "bound", "for", "the", "given", "key"], "project": "spring-framework"}
{"id": 7292, "code": "\tpublic void onError(Consumer<Throwable> callback) {\n\t\tthis.errorCallback = callback;\n\t}", "summary_tokens": ["register", "code", "to", "invoke", "when", "an", "error", "occurred", "during", "the", "async", "request"], "project": "spring-framework"}
{"id": 1411, "code": "\tpublic final DefaultListableBeanFactory getDefaultListableBeanFactory() {\n\t\treturn this.beanFactory;\n\t}", "summary_tokens": ["return", "the", "underlying", "bean", "factory", "of", "this", "context", "available", "for", "registering", "bean", "definitions"], "project": "spring-framework"}
{"id": 3278, "code": "\tpublic boolean isRunning() {\n\t\treturn (this.currentTaskName != null);\n\t}", "summary_tokens": ["determine", "whether", "this", "stop", "watch", "is", "currently", "running"], "project": "spring-framework"}
{"id": 2176, "code": "\tpublic static void removeListener(RecordedInvocationsListener listener) {\n\t\tLISTENERS.remove(listener);\n\t}", "summary_tokens": ["deregister", "the", "given", "invocations", "listener"], "project": "spring-framework"}
{"id": 2344, "code": "private int readMethod(\n    final ClassVisitor classVisitor, final Context context, final int methodInfoOffset) {\n  char[] charBuffer = context.charBuffer;\n\n    \n  int currentOffset = methodInfoOffset;\n  context.currentMethodAccessFlags = readUnsignedShort(currentOffset);\n  context.currentMethodName = readUTF8(currentOffset + 2, charBuffer);\n  context.currentMethodDescriptor = readUTF8(currentOffset + 4, charBuffer);\n  currentOffset += 6;\n\n    \n    \n    \n  int codeOffset = 0;\n    \n  int exceptionsOffset = 0;\n    \n  String[] exceptions = null;\n    \n  boolean synthetic = false;\n    \n  int signatureIndex = 0;\n    \n  int runtimeVisibleAnnotationsOffset = 0;\n    \n  int runtimeInvisibleAnnotationsOffset = 0;\n    \n  int runtimeVisibleParameterAnnotationsOffset = 0;\n    \n  int runtimeInvisibleParameterAnnotationsOffset = 0;\n    \n  int runtimeVisibleTypeAnnotationsOffset = 0;\n    \n  int runtimeInvisibleTypeAnnotationsOffset = 0;\n    \n  int annotationDefaultOffset = 0;\n    \n  int methodParametersOffset = 0;\n    \n    \n  Attribute attributes = null;\n\n  int attributesCount = readUnsignedShort(currentOffset);\n  currentOffset += 2;\n  while (attributesCount-- > 0) {\n      \n    String attributeName = readUTF8(currentOffset, charBuffer);\n    int attributeLength = readInt(currentOffset + 2);\n    currentOffset += 6;\n      \n      \n    if (Constants.CODE.equals(attributeName)) {\n      if ((context.parsingOptions & SKIP_CODE) == 0) {\n        codeOffset = currentOffset;\n      }\n    } else if (Constants.EXCEPTIONS.equals(attributeName)) {\n      exceptionsOffset = currentOffset;\n      exceptions = new String[readUnsignedShort(exceptionsOffset)];\n      int currentExceptionOffset = exceptionsOffset + 2;\n      for (int i = 0; i < exceptions.length; ++i) {\n        exceptions[i] = readClass(currentExceptionOffset, charBuffer);\n        currentExceptionOffset += 2;\n      }\n    } else if (Constants.SIGNATURE.equals(attributeName)) {\n      signatureIndex = readUnsignedShort(currentOffset);\n    } else if (Constants.DEPRECATED.equals(attributeName)) {\n      context.currentMethodAccessFlags |= Opcodes.ACC_DEPRECATED;\n    } else if (Constants.RUNTIME_VISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleTypeAnnotationsOffset = currentOffset;\n    } else if (Constants.ANNOTATION_DEFAULT.equals(attributeName)) {\n      annotationDefaultOffset = currentOffset;\n    } else if (Constants.SYNTHETIC.equals(attributeName)) {\n      synthetic = true;\n      context.currentMethodAccessFlags |= Opcodes.ACC_SYNTHETIC;\n    } else if (Constants.RUNTIME_INVISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleTypeAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_VISIBLE_PARAMETER_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleParameterAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_INVISIBLE_PARAMETER_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleParameterAnnotationsOffset = currentOffset;\n    } else if (Constants.METHOD_PARAMETERS.equals(attributeName)) {\n      methodParametersOffset = currentOffset;\n    } else {\n      Attribute attribute =\n          readAttribute(\n              context.attributePrototypes,\n              attributeName,\n              currentOffset,\n              attributeLength,\n              charBuffer,\n              -1,\n              null);\n      attribute.nextAttribute = attributes;\n      attributes = attribute;\n    }\n    currentOffset += attributeLength;\n  }\n\n    \n  MethodVisitor methodVisitor =\n      classVisitor.visitMethod(\n          context.currentMethodAccessFlags,\n          context.currentMethodName,\n          context.currentMethodDescriptor,\n          signatureIndex == 0 ? null : readUtf(signatureIndex, charBuffer),\n          exceptions);\n  if (methodVisitor == null) {\n    return currentOffset;\n  }\n\n    \n    \n    \n    \n  if (methodVisitor instanceof MethodWriter) {\n    MethodWriter methodWriter = (MethodWriter) methodVisitor;\n    if (methodWriter.canCopyMethodAttributes(\n        this,\n        synthetic,\n        (context.currentMethodAccessFlags & Opcodes.ACC_DEPRECATED) != 0,\n        readUnsignedShort(methodInfoOffset + 4),\n        signatureIndex,\n        exceptionsOffset)) {\n      methodWriter.setMethodAttributesSource(methodInfoOffset, currentOffset - methodInfoOffset);\n      return currentOffset;\n    }\n  }\n\n    \n  if (methodParametersOffset != 0 && (context.parsingOptions & SKIP_DEBUG) == 0) {\n    int parametersCount = readByte(methodParametersOffset);\n    int currentParameterOffset = methodParametersOffset + 1;\n    while (parametersCount-- > 0) {\n        \n      methodVisitor.visitParameter(\n          readUTF8(currentParameterOffset, charBuffer),\n          readUnsignedShort(currentParameterOffset + 2));\n      currentParameterOffset += 4;\n    }\n  }\n\n    \n  if (annotationDefaultOffset != 0) {\n    AnnotationVisitor annotationVisitor = methodVisitor.visitAnnotationDefault();\n    readElementValue(annotationVisitor, annotationDefaultOffset, null, charBuffer);\n    if (annotationVisitor != null) {\n      annotationVisitor.visitEnd();\n    }\n  }\n\n    \n  if (runtimeVisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              methodVisitor.visitAnnotation(annotationDescriptor,  true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              methodVisitor.visitAnnotation(annotationDescriptor,  false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeVisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              methodVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              methodVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeVisibleParameterAnnotationsOffset != 0) {\n    readParameterAnnotations(\n        methodVisitor, context, runtimeVisibleParameterAnnotationsOffset,  true);\n  }\n\n    \n  if (runtimeInvisibleParameterAnnotationsOffset != 0) {\n    readParameterAnnotations(\n        methodVisitor,\n        context,\n        runtimeInvisibleParameterAnnotationsOffset,\n         false);\n  }\n\n    \n  while (attributes != null) {\n      \n    Attribute nextAttribute = attributes.nextAttribute;\n    attributes.nextAttribute = null;\n    methodVisitor.visitAttribute(attributes);\n    attributes = nextAttribute;\n  }\n\n    \n  if (codeOffset != 0) {\n    methodVisitor.visitCode();\n    readCode(methodVisitor, context, codeOffset);\n  }\n\n    \n  methodVisitor.visitEnd();\n  return currentOffset;\n}", "summary_tokens": ["reads", "a", "jvms", "method", "info", "structure", "and", "makes", "the", "given", "visitor", "visit", "it"], "project": "spring-framework"}
{"id": 8788, "code": "\tpublic void setDetectHandlerFunctionsInAncestorContexts(boolean detectHandlerFunctionsInAncestorContexts) {\n\t\tthis.detectHandlerFunctionsInAncestorContexts = detectHandlerFunctionsInAncestorContexts;\n\t}", "summary_tokens": ["set", "whether", "to", "detect", "handler", "functions", "in", "ancestor", "application", "contexts"], "project": "spring-framework"}
{"id": 2199, "code": "\tpublic ResourceFileAssert assertThat() {\n\t\treturn new ResourceFileAssert(this);\n\t}", "summary_tokens": ["assert", "j", "assert", "that", "support"], "project": "spring-framework"}
{"id": 6076, "code": "\tpublic ResultMatcher isPaymentRequired() {\n\t\treturn matcher(HttpStatus.PAYMENT_REQUIRED);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 5217, "code": "\tdefault void postProcessEntityManagerFactory(EntityManagerFactory emf) {\n\t}", "summary_tokens": ["optional", "callback", "for", "post", "processing", "the", "native", "entity", "manager", "factory", "before", "active", "use"], "project": "spring-framework"}
{"id": 9677, "code": "\tprotected ObjectWrapper getObjectWrapper() {\n\t\tObjectWrapper ow = obtainConfiguration().getObjectWrapper();\n\t\treturn (ow != null ? ow :\n\t\t\t\tnew DefaultObjectWrapperBuilder(Configuration.DEFAULT_INCOMPATIBLE_IMPROVEMENTS).build());\n\t}", "summary_tokens": ["return", "the", "configured", "free", "marker", "object", "wrapper", "or", "the", "object", "wrapper", "default", "wrapper", "default", "wrapper", "if", "none", "specified"], "project": "spring-framework"}
{"id": 4816, "code": "\tpublic void registerDestructionCallback(String name, Runnable callback) {\n\t\tsynchronized (getSessionMutex()) {\n\t\t\tif (isSessionCompleted()) {\n\t\t\t\tthrow new IllegalStateException(\"Session id=\" + getSessionId() + \" already completed\");\n\t\t\t}\n\t\t\tthis.attributes.put(DESTRUCTION_CALLBACK_NAME_PREFIX + name, callback);\n\t\t}\n\t}", "summary_tokens": ["register", "a", "callback", "to", "execute", "on", "destruction", "of", "the", "specified", "attribute"], "project": "spring-framework"}
{"id": 1015, "code": "\tprotected final FileTypeMap getFileTypeMap() {\n\t\tif (this.fileTypeMap == null) {\n\t\t\ttry {\n\t\t\t\tthis.fileTypeMap = createFileTypeMap(this.mappingLocation, this.mappings);\n\t\t\t}\n\t\t\tcatch (IOException ex) {\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\"Could not load specified MIME type mapping file: \" + this.mappingLocation, ex);\n\t\t\t}\n\t\t}\n\t\treturn this.fileTypeMap;\n\t}", "summary_tokens": ["return", "the", "delegate", "file", "type", "map", "compiled", "from", "the", "mappings", "in", "the", "mapping", "file", "and", "the", "entries", "in", "the", "mappings", "property"], "project": "spring-framework"}
{"id": 3300, "code": "\tpublic static boolean hasLength(@Nullable String str) {\n\t\treturn (str != null && !str.isEmpty());\n\t}", "summary_tokens": ["check", "that", "the", "given", "string", "is", "neither", "null", "nor", "of", "length", "0"], "project": "spring-framework"}
{"id": 5926, "code": "\tstatic ResultMatcher matchAll(ResultMatcher... matchers) {\n\t\treturn result -> {\n\t\t\tfor (ResultMatcher matcher : matchers) {\n\t\t\t\tmatcher.match(result);\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["static", "method", "for", "matching", "with", "an", "array", "of", "result", "matchers"], "project": "spring-framework"}
{"id": 6510, "code": "\tpublic void setRollbackOnly() {\n\t\tthis.rollbackOnly = true;\n\t}", "summary_tokens": ["mark", "the", "resource", "transaction", "as", "rollback", "only"], "project": "spring-framework"}
{"id": 7883, "code": "\tpublic int getScore() {\n\t\treturn 0;\n\t}", "summary_tokens": ["return", "the", "score", "for", "this", "path", "element", "combined", "score", "is", "used", "to", "compare", "parsed", "patterns"], "project": "spring-framework"}
{"id": 9929, "code": "\tpublic String getAcceptedProtocol() {\n\t\treturn this.acceptedProtocol;\n\t}", "summary_tokens": ["return", "the", "selected", "sub", "protocol", "to", "use"], "project": "spring-framework"}
{"id": 911, "code": "\tvoid copyPropertiesHonorsGenericTypeMatchesFromWildcardToWildcard() {\n\t\tList<?> list = Arrays.asList(\"foo\", 42);\n\t\tWildcardListHolder1 wildcardListHolder1 = new WildcardListHolder1();\n\t\twildcardListHolder1.setList(list);\n\t\tWildcardListHolder2 wildcardListHolder2 = new WildcardListHolder2();\n\t\tassertThat(wildcardListHolder2.getList()).isEmpty();\n\n\t\tBeanUtils.copyProperties(wildcardListHolder1, wildcardListHolder2);\n\t\tassertThat(wildcardListHolder1.getList()).isEqualTo(list);\n\t\tassertThat(wildcardListHolder2.getList()).isEqualTo(list);\n\t}", "summary_tokens": ["list", "can", "be", "copied", "to", "list"], "project": "spring-framework"}
{"id": 5179, "code": "\tpublic void setCurrentTenantIdentifierResolver(CurrentTenantIdentifierResolver currentTenantIdentifierResolver) {\n\t\tgetProperties().put(AvailableSettings.MULTI_TENANT_IDENTIFIER_RESOLVER, currentTenantIdentifierResolver);\n\t\tsuper.setCurrentTenantIdentifierResolver(currentTenantIdentifierResolver);\n\t}", "summary_tokens": ["overridden", "to", "reliably", "pass", "a", "current", "tenant", "identifier", "resolver", "to", "the", "session", "factory"], "project": "spring-framework"}
{"id": 6122, "code": "\tpublic ResultMatcher nodeList(Matcher<? super NodeList> matcher) {\n\t\treturn result -> {\n\t\t\tMockHttpServletResponse response = result.getResponse();\n\t\t\tthis.xpathHelper.assertNodeList(response.getContentAsByteArray(), getDefinedEncoding(response), matcher);\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "xpath", "and", "assert", "the", "node", "list", "content", "found", "with", "the", "given", "hamcrest", "matcher"], "project": "spring-framework"}
{"id": 4366, "code": "\tpublic void setPhase(int phase) {\n\t\tthis.phase = phase;\n\t}", "summary_tokens": ["specify", "the", "phase", "in", "which", "this", "container", "should", "be", "started", "and", "stopped"], "project": "spring-framework"}
{"id": 7281, "code": "\tdefault <T> void beforeConcurrentHandling(NativeWebRequest request, Callable<T> task) throws Exception {\n\t}", "summary_tokens": ["invoked", "em", "before", "em", "the", "start", "of", "concurrent", "handling", "in", "the", "original", "thread", "in", "which", "the", "callable", "is", "submitted", "for", "concurrent", "handling"], "project": "spring-framework"}
{"id": 8670, "code": "\tprotected void configurePathMatch(PathMatchConfigurer configurer) {\n\t}", "summary_tokens": ["override", "this", "method", "to", "configure", "path", "matching", "options"], "project": "spring-framework"}
{"id": 8218, "code": "\tpublic Set<MediaTypeExpression> getExpressions() {\n\t\treturn new LinkedHashSet<>(this.expressions);\n\t}", "summary_tokens": ["return", "the", "contained", "media", "type", "expressions"], "project": "spring-framework"}
{"id": 4877, "code": "\tpublic TaskScheduler getTaskScheduler() {\n\t\treturn this.taskScheduler;\n\t}", "summary_tokens": ["return", "the", "configured", "task", "scheduler"], "project": "spring-framework"}
{"id": 8401, "code": "\tpublic void setConfiguration(Configuration configuration) {\n\t\tthis.configuration = configuration;\n\t}", "summary_tokens": ["set", "a", "pre", "configured", "configuration", "to", "use", "for", "the", "free", "marker", "web", "config", "e"], "project": "spring-framework"}
{"id": 3260, "code": "\tpublic static boolean isUrl(@Nullable String resourceLocation) {\n\t\tif (resourceLocation == null) {\n\t\t\treturn false;\n\t\t}\n\t\tif (resourceLocation.startsWith(CLASSPATH_URL_PREFIX)) {\n\t\t\treturn true;\n\t\t}\n\t\ttry {\n\t\t\tnew URL(resourceLocation);\n\t\t\treturn true;\n\t\t}\n\t\tcatch (MalformedURLException ex) {\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["return", "whether", "the", "given", "resource", "location", "is", "a", "url", "either", "a", "special", "classpath", "pseudo", "url", "or", "a", "standard", "url"], "project": "spring-framework"}
{"id": 2496, "code": "public void visitEnd() {\n  if (mv != null) {\n    mv.visitEnd();\n  }\n}", "summary_tokens": ["visits", "the", "end", "of", "the", "method"], "project": "spring-framework"}
{"id": 6304, "code": "\tpublic void setTransactionManager(@Nullable TransactionManager transactionManager) {\n\t\tthis.transactionManager = transactionManager;\n\t}", "summary_tokens": ["set", "the", "jta", "transaction", "manager", "to", "use", "as", "direct", "reference"], "project": "spring-framework"}
{"id": 5588, "code": "\tpublic void beforeTestExecution(ExtensionContext context) throws Exception {\n\t\tObject testInstance = context.getRequiredTestInstance();\n\t\tMethod testMethod = context.getRequiredTestMethod();\n\t\tgetTestContextManager(context).beforeTestExecution(testInstance, testMethod);\n\t}", "summary_tokens": ["delegates", "to", "test", "context", "manager", "before", "test", "execution"], "project": "spring-framework"}
{"id": 1711, "code": "\tpublic void setConnectOnStartup(boolean connectOnStartup) {\n\t\tthis.connectOnStartup = connectOnStartup;\n\t}", "summary_tokens": ["set", "whether", "to", "connect", "to", "the", "server", "on", "startup"], "project": "spring-framework"}
{"id": 4040, "code": "\tpublic void setBlockCommentEndDelimiter(String blockCommentEndDelimiter) {\n\t\tAssert.hasText(blockCommentEndDelimiter, \"'blockCommentEndDelimiter' must not be null or empty\");\n\t\tthis.blockCommentEndDelimiter = blockCommentEndDelimiter;\n\t}", "summary_tokens": ["set", "the", "end", "delimiter", "that", "identifies", "block", "comments", "within", "the", "sql", "scripts"], "project": "spring-framework"}
{"id": 8216, "code": "\tpublic CompositeRequestCondition getMatchingCondition(ServerWebExchange exchange) {\n\t\tif (isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\tRequestConditionHolder[] matchingConditions = new RequestConditionHolder[getLength()];\n\t\tfor (int i = 0; i < getLength(); i++) {\n\t\t\tmatchingConditions[i] = this.requestConditions[i].getMatchingCondition(exchange);\n\t\t\tif (matchingConditions[i] == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\treturn new CompositeRequestCondition(matchingConditions);\n\t}", "summary_tokens": ["delegate", "to", "em", "all", "em", "contained", "conditions", "to", "match", "the", "request", "and", "return", "the", "resulting", "matching", "condition", "instances"], "project": "spring-framework"}
{"id": 1020, "code": "\tpublic synchronized void setSession(Session session) {\n\t\tAssert.notNull(session, \"Session must not be null\");\n\t\tthis.session = session;\n\t}", "summary_tokens": ["set", "the", "java", "mail", "session", "possibly", "pulled", "from", "jndi"], "project": "spring-framework"}
{"id": 4977, "code": "\tpublic void setHeaderInitializer(@Nullable MessageHeaderInitializer headerInitializer) {\n\t\tthis.headerInitializer = headerInitializer;\n\t}", "summary_tokens": ["configure", "a", "message", "header", "initializer", "to", "apply", "to", "the", "headers", "of", "message", "messages", "from", "decoded", "stomp", "frames"], "project": "spring-framework"}
{"id": 9211, "code": "\tpublic void setArgumentSeparator(String argumentSeparator) {\n\t\tthis.argumentSeparator = argumentSeparator;\n\t}", "summary_tokens": ["set", "the", "separator", "to", "use", "for", "splitting", "an", "arguments", "string"], "project": "spring-framework"}
{"id": 6617, "code": "\tprivate String toHeaderValue() {\n\t\tStringBuilder headerValue = new StringBuilder();\n\t\tif (this.maxAge != null) {\n\t\t\tappendDirective(headerValue, \"max-age=\" + this.maxAge.getSeconds());\n\t\t}\n\t\tif (this.noCache) {\n\t\t\tappendDirective(headerValue, \"no-cache\");\n\t\t}\n\t\tif (this.noStore) {\n\t\t\tappendDirective(headerValue, \"no-store\");\n\t\t}\n\t\tif (this.mustRevalidate) {\n\t\t\tappendDirective(headerValue, \"must-revalidate\");\n\t\t}\n\t\tif (this.noTransform) {\n\t\t\tappendDirective(headerValue, \"no-transform\");\n\t\t}\n\t\tif (this.cachePublic) {\n\t\t\tappendDirective(headerValue, \"public\");\n\t\t}\n\t\tif (this.cachePrivate) {\n\t\t\tappendDirective(headerValue, \"private\");\n\t\t}\n\t\tif (this.proxyRevalidate) {\n\t\t\tappendDirective(headerValue, \"proxy-revalidate\");\n\t\t}\n\t\tif (this.sMaxAge != null) {\n\t\t\tappendDirective(headerValue, \"s-maxage=\" + this.sMaxAge.getSeconds());\n\t\t}\n\t\tif (this.staleIfError != null) {\n\t\t\tappendDirective(headerValue, \"stale-if-error=\" + this.staleIfError.getSeconds());\n\t\t}\n\t\tif (this.staleWhileRevalidate != null) {\n\t\t\tappendDirective(headerValue, \"stale-while-revalidate=\" + this.staleWhileRevalidate.getSeconds());\n\t\t}\n\t\treturn headerValue.toString();\n\t}", "summary_tokens": ["return", "the", "cache", "control", "header", "value"], "project": "spring-framework"}
{"id": 5648, "code": "\tpublic void processContextConfiguration(ContextConfigurationAttributes configAttributes) {\n\t\tString[] processedLocations =\n\t\t\t\tprocessLocationsInternal(configAttributes.getDeclaringClass(), configAttributes.getLocations());\n\t\tconfigAttributes.setLocations(processedLocations);\n\t}", "summary_tokens": ["the", "default", "implementation", "processes", "locations", "analogous", "to", "process", "locations", "class", "string"], "project": "spring-framework"}
{"id": 3445, "code": "\tvoid synthesizeNonPublicWithAttributeAliasesFromDifferentPackage() throws Exception {\n\t\tClass<?> type = ClassUtils.forName(\n\t\t\t\t\"org.springframework.core.annotation.subpackage.NonPublicAliasedAnnotatedClass\",\n\t\t\t\tnull);\n\t\tClass<? extends Annotation> annotationType = (Class<? extends Annotation>) ClassUtils.forName(\n\t\t\t\t\"org.springframework.core.annotation.subpackage.NonPublicAliasedAnnotation\",\n\t\t\t\tnull);\n\t\tAnnotation annotation = type.getAnnotation(annotationType);\n\t\tassertThat(annotation).isNotNull();\n\t\tMergedAnnotation<Annotation> mergedAnnotation = MergedAnnotation.from(annotation);\n\t\tAnnotation synthesizedAnnotation = mergedAnnotation.synthesize();\n\t\tassertSynthesized(synthesizedAnnotation);\n\t\tassertThat(mergedAnnotation.getString(\"name\")).isEqualTo(\"test\");\n\t\tassertThat(mergedAnnotation.getString(\"path\")).isEqualTo(\"/test\");\n\t\tassertThat(mergedAnnotation.getString(\"value\")).isEqualTo(\"/test\");\n\t}", "summary_tokens": ["fully", "reflection", "based", "test", "that", "verifies", "support", "for", "synthesizing", "annotations", "across", "packages", "with", "non", "public", "visibility", "of", "user", "types", "e"], "project": "spring-framework"}
{"id": 3194, "code": "\tpublic int getConcurrencyLimit() {\n\t\treturn this.concurrencyLimit;\n\t}", "summary_tokens": ["return", "the", "maximum", "number", "of", "concurrent", "access", "attempts", "allowed"], "project": "spring-framework"}
{"id": 2001, "code": "\tpublic void setValidator(@Nullable Validator validator) {\n\t\tassertValidators(validator);\n\t\tthis.validators.clear();\n\t\tif (validator != null) {\n\t\t\tthis.validators.add(validator);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "validator", "to", "apply", "after", "each", "binding", "step"], "project": "spring-framework"}
{"id": 4584, "code": "\tprotected String fromHeaderName(String headerName) {\n\t\tif (MessageHeaders.CONTENT_TYPE.equals(headerName)) {\n\t\t\treturn CONTENT_TYPE_PROPERTY;\n\t\t}\n\t\treturn super.fromHeaderName(headerName);\n\t}", "summary_tokens": ["add", "the", "outbound", "prefix", "if", "necessary"], "project": "spring-framework"}
{"id": 4614, "code": "\tprotected void testFullConfiguration(ApplicationContext context) {\n\t\tJmsListenerContainerTestFactory simpleFactory =\n\t\t\t\tcontext.getBean(\"simpleFactory\", JmsListenerContainerTestFactory.class);\n\t\tassertThat(simpleFactory.getListenerContainers().size()).isEqualTo(1);\n\t\tMethodJmsListenerEndpoint endpoint = (MethodJmsListenerEndpoint)\n\t\t\t\tsimpleFactory.getListenerContainers().get(0).getEndpoint();\n\t\tassertThat(endpoint.getId()).isEqualTo(\"listener1\");\n\t\tassertThat(endpoint.getDestination()).isEqualTo(\"queueIn\");\n\t\tassertThat(endpoint.getSelector()).isEqualTo(\"mySelector\");\n\t\tassertThat(endpoint.getSubscription()).isEqualTo(\"mySubscription\");\n\t\tassertThat(endpoint.getConcurrency()).isEqualTo(\"1-10\");\n\n\t\tMethod m = ReflectionUtils.findMethod(endpoint.getClass(), \"getDefaultResponseDestination\");\n\t\tReflectionUtils.makeAccessible(m);\n\t\tObject destination = ReflectionUtils.invokeMethod(m, endpoint);\n\t\tassertThat(destination).isEqualTo(\"queueOut\");\n\t}", "summary_tokens": ["test", "for", "full", "bean", "discovery"], "project": "spring-framework"}
{"id": 323, "code": "\tpublic String getPropertyName() {\n\t\treturn this.propertyName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "offending", "property"], "project": "spring-framework"}
{"id": 6884, "code": "\tpublic void setCharset(Charset charset) {\n\t\tAssert.notNull(charset, \"Charset must not be null\");\n\t\tthis.charset = charset;\n\t}", "summary_tokens": ["set", "the", "character", "set", "to", "use", "for", "part", "headers", "such", "as", "content", "disposition", "and", "its", "filename", "parameter"], "project": "spring-framework"}
{"id": 6530, "code": "\tprotected void releaseResource(H resourceHolder, K resourceKey) {\n\t}", "summary_tokens": ["release", "the", "given", "resource", "after", "it", "has", "been", "unbound", "from", "the", "thread"], "project": "spring-framework"}
{"id": 7185, "code": "\tpublic void setFieldMarkerPrefix(@Nullable String fieldMarkerPrefix) {\n\t\tthis.fieldMarkerPrefix = fieldMarkerPrefix;\n\t}", "summary_tokens": ["specify", "a", "prefix", "that", "can", "be", "used", "for", "parameters", "that", "mark", "potentially", "empty", "fields", "having", "prefix", "field", "as", "name"], "project": "spring-framework"}
{"id": 4298, "code": "\tprotected Connection doCreateConnection() throws JMSException {\n\t\tConnectionFactory cf = getTargetConnectionFactory();\n\t\tif (Boolean.FALSE.equals(this.pubSubMode) && cf instanceof QueueConnectionFactory) {\n\t\t\treturn ((QueueConnectionFactory) cf).createQueueConnection();\n\t\t}\n\t\telse if (Boolean.TRUE.equals(this.pubSubMode) && cf instanceof TopicConnectionFactory) {\n\t\t\treturn ((TopicConnectionFactory) cf).createTopicConnection();\n\t\t}\n\t\telse {\n\t\t\treturn obtainTargetConnectionFactory().createConnection();\n\t\t}\n\t}", "summary_tokens": ["create", "a", "jms", "connection", "via", "this", "template", "s", "connection", "factory"], "project": "spring-framework"}
{"id": 3291, "code": "\tpublic String toString() {\n\t\tStringBuilder sb = new StringBuilder(shortSummary());\n\t\tif (this.keepTaskList) {\n\t\t\tfor (TaskInfo task : getTaskInfo()) {\n\t\t\t\tsb.append(\"; [\").append(task.getTaskName()).append(\"] took \").append(task.getTimeNanos()).append(\" ns\");\n\t\t\t\tlong percent = Math.round(100.0 * task.getTimeNanos() / getTotalTimeNanos());\n\t\t\t\tsb.append(\" = \").append(percent).append('%');\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tsb.append(\"; no task info kept\");\n\t\t}\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["generate", "an", "informative", "string", "describing", "all", "tasks", "performed", "p", "for", "custom", "reporting", "call", "get", "task", "info", "and", "use", "the", "task", "info", "directly"], "project": "spring-framework"}
{"id": 8462, "code": "\tpublic XnioWorker getXnioWorker() {\n\t\treturn this.worker;\n\t}", "summary_tokens": ["return", "the", "configured", "xnio", "worker"], "project": "spring-framework"}
{"id": 4312, "code": "\tpublic JmsTemplate getJmsTemplate() {\n\t\treturn this.jmsTemplate;\n\t}", "summary_tokens": ["return", "the", "configured", "jms", "template"], "project": "spring-framework"}
{"id": 1880, "code": "\tpublic Trigger getTrigger() {\n\t\treturn this.trigger;\n\t}", "summary_tokens": ["return", "the", "associated", "trigger"], "project": "spring-framework"}
{"id": 7317, "code": "\tpublic void registerDeferredResultInterceptors(DeferredResultProcessingInterceptor... interceptors) {\n\t\tAssert.notNull(interceptors, \"A DeferredResultProcessingInterceptor is required\");\n\t\tfor (DeferredResultProcessingInterceptor interceptor : interceptors) {\n\t\t\tString key = interceptor.getClass().getName() + \":\" + interceptor.hashCode();\n\t\t\tthis.deferredResultInterceptors.put(key, interceptor);\n\t\t}\n\t}", "summary_tokens": ["register", "one", "or", "more", "deferred", "result", "processing", "interceptor", "deferred", "result", "processing", "interceptors", "without", "a", "specified", "key"], "project": "spring-framework"}
{"id": 8933, "code": "\tpublic final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler)\n\t\t\tthrows Exception {\n\n\t\treturn handleInternal(request, response, (HandlerMethod) handler);\n\t}", "summary_tokens": ["this", "implementation", "expects", "the", "handler", "to", "be", "an", "handler", "method"], "project": "spring-framework"}
{"id": 9576, "code": "\tpublic void setExpandUriTemplateVariables(boolean expandUriTemplateVariables) {\n\t\tthis.expandUriTemplateVariables = expandUriTemplateVariables;\n\t}", "summary_tokens": ["whether", "to", "treat", "the", "redirect", "url", "as", "a", "uri", "template"], "project": "spring-framework"}
{"id": 6125, "code": "\tpublic ResultMatcher doesNotExist() {\n\t\treturn result -> {\n\t\t\tMockHttpServletResponse response = result.getResponse();\n\t\t\tthis.xpathHelper.doesNotExist(response.getContentAsByteArray(), getDefinedEncoding(response));\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "xpath", "and", "assert", "that", "content", "doesn", "t", "exist"], "project": "spring-framework"}
{"id": 7274, "code": "\tpublic final HttpServletRequest getRequest() {\n\t\treturn this.request;\n\t}", "summary_tokens": ["exposes", "the", "native", "http", "servlet", "request", "that", "we", "re", "wrapping"], "project": "spring-framework"}
{"id": 5130, "code": "\tpublic void setQueryCacheRegion(@Nullable String queryCacheRegion) {\n\t\tthis.queryCacheRegion = queryCacheRegion;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "cache", "region", "for", "queries", "executed", "by", "this", "template"], "project": "spring-framework"}
{"id": 737, "code": "\tpublic boolean isGeneratedBeanName() {\n\t\treturn this.generatedBeanName;\n\t}", "summary_tokens": ["return", "if", "the", "bean", "name", "is", "generated"], "project": "spring-framework"}
{"id": 8829, "code": "\tpublic void setMappings(Properties mappings) {\n\t\tCollectionUtils.mergePropertiesIntoMap(mappings, this.urlMap);\n\t}", "summary_tokens": ["map", "url", "paths", "to", "handler", "bean", "names"], "project": "spring-framework"}
{"id": 2113, "code": "\tvoid orderingIsLifo() {\n\t\t{\n\t\t\tAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();\n\t\t\tctx.register(ConfigWithImplicitName.class, P2Config.class);\n\t\t\tctx.refresh();\n\t\t\t\n\t\t\tassertThat(ctx.getBean(TestBean.class).getName()).isEqualTo(\"p2TestBean\");\n\t\t\tctx.close();\n\t\t}\n\n\t\t{\n\t\t\tAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();\n\t\t\tctx.register(P2Config.class, ConfigWithImplicitName.class);\n\t\t\tctx.refresh();\n\t\t\t\n\t\t\tassertThat(ctx.getBean(TestBean.class).getName()).isEqualTo(\"p1TestBean\");\n\t\t\tctx.close();\n\t\t}\n\t}", "summary_tokens": ["tests", "the", "lifo", "behavior", "of", "annotations"], "project": "spring-framework"}
{"id": 4672, "code": "\tprivate NamedValueInfo getNamedValueInfo(MethodParameter parameter) {\n\t\tNamedValueInfo namedValueInfo = this.namedValueInfoCache.get(parameter);\n\t\tif (namedValueInfo == null) {\n\t\t\tnamedValueInfo = createNamedValueInfo(parameter);\n\t\t\tnamedValueInfo = updateNamedValueInfo(parameter, namedValueInfo);\n\t\t\tthis.namedValueInfoCache.put(parameter, namedValueInfo);\n\t\t}\n\t\treturn namedValueInfo;\n\t}", "summary_tokens": ["obtain", "the", "named", "value", "for", "the", "given", "method", "parameter"], "project": "spring-framework"}
{"id": 8658, "code": "\tpublic UrlBasedViewResolverRegistration scriptTemplate() {\n\t\tif (!checkBeanOfType(ScriptTemplateConfigurer.class)) {\n\t\t\tthrow new BeanInitializationException(\"In addition to a script template view resolver \" +\n\t\t\t\t\t\"there must also be a single ScriptTemplateConfig bean in this web application context \" +\n\t\t\t\t\t\"(or its parent): ScriptTemplateConfigurer is the usual implementation. \" +\n\t\t\t\t\t\"This bean may be given any name.\");\n\t\t}\n\t\tScriptRegistration registration = new ScriptRegistration();\n\t\tthis.viewResolvers.add(registration.getViewResolver());\n\t\treturn registration;\n\t}", "summary_tokens": ["register", "a", "script", "template", "view", "resolver", "with", "an", "empty", "default", "view", "name", "prefix", "and", "suffix"], "project": "spring-framework"}
{"id": 6346, "code": "\tprivate void prepareSynchronization(TransactionSynchronizationManager synchronizationManager,\n\t\t\tGenericReactiveTransaction status, TransactionDefinition definition) {\n\n\t\tif (status.isNewSynchronization()) {\n\t\t\tsynchronizationManager.setActualTransactionActive(status.hasTransaction());\n\t\t\tsynchronizationManager.setCurrentTransactionIsolationLevel(\n\t\t\t\t\tdefinition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT ?\n\t\t\t\t\t\t\tdefinition.getIsolationLevel() : null);\n\t\t\tsynchronizationManager.setCurrentTransactionReadOnly(definition.isReadOnly());\n\t\t\tsynchronizationManager.setCurrentTransactionName(definition.getName());\n\t\t\tsynchronizationManager.initSynchronization();\n\t\t}\n\t}", "summary_tokens": ["initialize", "transaction", "synchronization", "as", "appropriate"], "project": "spring-framework"}
{"id": 2494, "code": "public void visitLineNumber(final int line, final Label start) {\n  if (mv != null) {\n    mv.visitLineNumber(line, start);\n  }\n}", "summary_tokens": ["visits", "a", "line", "number", "declaration"], "project": "spring-framework"}
{"id": 634, "code": "\tpublic BeanDefinitionBuilder addPropertyValue(String name, @Nullable Object value) {\n\t\tthis.beanDefinition.getPropertyValues().add(name, value);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "supplied", "property", "value", "under", "the", "given", "property", "name"], "project": "spring-framework"}
{"id": 4761, "code": "\tpublic List<HandlerMethodArgumentResolver> getResolvers() {\n\t\treturn Collections.unmodifiableList(this.argumentResolvers);\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "with", "the", "contained", "resolvers", "or", "an", "empty", "list"], "project": "spring-framework"}
{"id": 1708, "code": "\tpublic void setServiceUrl(String url) throws MalformedURLException {\n\t\tthis.serviceUrl = new JMXServiceURL(url);\n\t}", "summary_tokens": ["set", "the", "service", "url", "of", "the", "remote", "mbean", "server"], "project": "spring-framework"}
{"id": 7608, "code": "\tpublic void setViewName(@Nullable String viewName) {\n\t\tthis.view = viewName;\n\t}", "summary_tokens": ["set", "a", "view", "name", "to", "be", "resolved", "by", "the", "dispatcher", "servlet", "via", "a", "view", "resolver"], "project": "spring-framework"}
{"id": 7119, "code": "\tpublic void setParameterName(String parameterName) {\n\t\tAssert.notNull(parameterName, \"parameterName is required\");\n\t\tthis.parameterName = parameterName;\n\t}", "summary_tokens": ["set", "the", "query", "parameter", "name", "to", "use", "when", "set", "favor", "parameter", "is", "on"], "project": "spring-framework"}
{"id": 1550, "code": "\tprotected ObjectName getObjectName(Object bean, @Nullable String beanKey) throws MalformedObjectNameException {\n\t\tif (bean instanceof SelfNaming) {\n\t\t\treturn ((SelfNaming) bean).getObjectName();\n\t\t}\n\t\telse {\n\t\t\treturn this.namingStrategy.getObjectName(bean, beanKey);\n\t\t}\n\t}", "summary_tokens": ["retrieve", "the", "object", "name", "for", "a", "bean"], "project": "spring-framework"}
{"id": 1910, "code": "\tprotected GroovyClassLoader buildGroovyClassLoader(@Nullable ClassLoader classLoader) {\n\t\treturn (this.compilerConfiguration != null ?\n\t\t\t\tnew GroovyClassLoader(classLoader, this.compilerConfiguration) : new GroovyClassLoader(classLoader));\n\t}", "summary_tokens": ["build", "a", "groovy", "class", "loader", "for", "the", "given", "class", "loader"], "project": "spring-framework"}
{"id": 4300, "code": "\tprotected Session getSession(Connection con, Integer mode) throws JMSException {\n\t\treturn null;\n\t}", "summary_tokens": ["template", "method", "for", "obtaining", "a", "potentially", "cached", "session"], "project": "spring-framework"}
{"id": 9470, "code": "\tprotected int writeTagContent(TagWriter tagWriter) throws JspException {\n\t\ttagWriter.startTag(\"select\");\n\t\twriteDefaultAttributes(tagWriter);\n\t\tif (isMultiple()) {\n\t\t\ttagWriter.writeAttribute(\"multiple\", \"multiple\");\n\t\t}\n\t\ttagWriter.writeOptionalAttributeValue(\"size\", getDisplayString(evaluate(\"size\", getSize())));\n\n\t\tObject items = getItems();\n\t\tif (items != null) {\n\t\t\t\n\t\t\tif (items != EMPTY) {\n\t\t\t\tObject itemsObject = evaluate(\"items\", items);\n\t\t\t\tif (itemsObject != null) {\n\t\t\t\t\tfinal String selectName = getName();\n\t\t\t\t\tString valueProperty = (getItemValue() != null ?\n\t\t\t\t\t\t\tObjectUtils.getDisplayString(evaluate(\"itemValue\", getItemValue())) : null);\n\t\t\t\t\tString labelProperty = (getItemLabel() != null ?\n\t\t\t\t\t\t\tObjectUtils.getDisplayString(evaluate(\"itemLabel\", getItemLabel())) : null);\n\t\t\t\t\tOptionWriter optionWriter =\n\t\t\t\t\t\t\tnew OptionWriter(itemsObject, getBindStatus(), valueProperty, labelProperty, isHtmlEscape()) {\n\t\t\t\t\t\t\t\t@Override\n\t\t\t\t\t\t\t\tprotected String processOptionValue(String resolvedValue) {\n\t\t\t\t\t\t\t\t\treturn processFieldValue(selectName, resolvedValue, \"option\");\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t};\n\t\t\t\t\toptionWriter.writeOptions(tagWriter);\n\t\t\t\t}\n\t\t\t}\n\t\t\ttagWriter.endTag(true);\n\t\t\twriteHiddenTagIfNecessary(tagWriter);\n\t\t\treturn SKIP_BODY;\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\ttagWriter.forceBlock();\n\t\t\tthis.tagWriter = tagWriter;\n\t\t\tthis.pageContext.setAttribute(LIST_VALUE_PAGE_ATTRIBUTE, getBindStatus());\n\t\t\treturn EVAL_BODY_INCLUDE;\n\t\t}\n\t}", "summary_tokens": ["renders", "the", "html", "select", "tag", "to", "the", "supplied", "tag", "writer"], "project": "spring-framework"}
{"id": 60, "code": "\tprivate Class<?> getAdviceClass(Element adviceElement, ParserContext parserContext) {\n\t\tString elementName = parserContext.getDelegate().getLocalName(adviceElement);\n\t\tif (BEFORE.equals(elementName)) {\n\t\t\treturn AspectJMethodBeforeAdvice.class;\n\t\t}\n\t\telse if (AFTER.equals(elementName)) {\n\t\t\treturn AspectJAfterAdvice.class;\n\t\t}\n\t\telse if (AFTER_RETURNING_ELEMENT.equals(elementName)) {\n\t\t\treturn AspectJAfterReturningAdvice.class;\n\t\t}\n\t\telse if (AFTER_THROWING_ELEMENT.equals(elementName)) {\n\t\t\treturn AspectJAfterThrowingAdvice.class;\n\t\t}\n\t\telse if (AROUND.equals(elementName)) {\n\t\t\treturn AspectJAroundAdvice.class;\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"Unknown advice kind [\" + elementName + \"].\");\n\t\t}\n\t}", "summary_tokens": ["gets", "the", "advice", "implementation", "class", "corresponding", "to", "the", "supplied", "element"], "project": "spring-framework"}
{"id": 1768, "code": "\tdefault Clock getClock() {\n\t\treturn Clock.systemDefaultZone();\n\t}", "summary_tokens": ["return", "the", "clock", "to", "use", "for", "scheduling", "purposes"], "project": "spring-framework"}
{"id": 5440, "code": "\tpublic final ClientHttpResponse execute() throws IOException {\n\t\tthis.executed = true;\n\t\treturn executeInternal();\n\t}", "summary_tokens": ["set", "the", "is", "executed", "executed", "flag", "to", "true", "and", "return", "the", "configured", "set", "response", "client", "http", "response", "response"], "project": "spring-framework"}
{"id": 8374, "code": "\tpublic void setPrefix(@Nullable String prefix) {\n\t\tthis.prefix = (prefix != null ? prefix : \"\");\n\t}", "summary_tokens": ["set", "the", "prefix", "that", "gets", "prepended", "to", "view", "names", "when", "building", "a", "url"], "project": "spring-framework"}
{"id": 8168, "code": "\tstatic BodyBuilder temporaryRedirect(URI location) {\n\t\tBodyBuilder builder = status(HttpStatus.TEMPORARY_REDIRECT);\n\t\treturn builder.location(location);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "a", "http", "status", "temporary", "redirect", "0", "temporary", "redirect", "status", "and", "a", "location", "header", "set", "to", "the", "given", "uri"], "project": "spring-framework"}
{"id": 2029, "code": "\tpublic final Map<?, ?> getTargetMap() {\n\t\treturn this.target;\n\t}", "summary_tokens": ["return", "the", "target", "map", "to", "bind", "onto"], "project": "spring-framework"}
{"id": 9464, "code": "\tpublic void setItemLabel(String itemLabel) {\n\t\tthis.itemLabel = itemLabel;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "property", "mapped", "to", "the", "label", "inner", "text", "of", "the", "option", "tag"], "project": "spring-framework"}
{"id": 5297, "code": "\tpublic void setGenerateDdl(boolean generateDdl) {\n\t\tthis.generateDdl = generateDdl;\n\t}", "summary_tokens": ["set", "whether", "to", "generate", "ddl", "after", "the", "entity", "manager", "factory", "has", "been", "initialized", "creating", "updating", "all", "relevant", "tables"], "project": "spring-framework"}
{"id": 4453, "code": "\tpublic void setBackOff(BackOff backOff) {\n\t\tthis.backOff = backOff;\n\t}", "summary_tokens": ["specify", "the", "back", "off", "instance", "to", "use", "to", "compute", "the", "interval", "between", "recovery", "attempts"], "project": "spring-framework"}
{"id": 1678, "code": "\tpublic ObjectName getObjectName(Object managedBean, @Nullable String beanKey) throws MalformedObjectNameException {\n\t\tAssert.state(this.attributeSource != null, \"No JmxAttributeSource set\");\n\t\tClass<?> managedClass = AopUtils.getTargetClass(managedBean);\n\t\tManagedResource mr = this.attributeSource.getManagedResource(managedClass);\n\n\t\t\n\t\tif (mr != null && StringUtils.hasText(mr.getObjectName())) {\n\t\t\treturn ObjectNameManager.getInstance(mr.getObjectName());\n\t\t}\n\t\telse {\n\t\t\tAssert.state(beanKey != null, \"No ManagedResource attribute and no bean key specified\");\n\t\t\ttry {\n\t\t\t\treturn ObjectNameManager.getInstance(beanKey);\n\t\t\t}\n\t\t\tcatch (MalformedObjectNameException ex) {\n\t\t\t\tString domain = this.defaultDomain;\n\t\t\t\tif (domain == null) {\n\t\t\t\t\tdomain = ClassUtils.getPackageName(managedClass);\n\t\t\t\t}\n\t\t\t\tHashtable<String, String> properties = new Hashtable<>();\n\t\t\t\tproperties.put(\"type\", ClassUtils.getShortName(managedClass));\n\t\t\t\tproperties.put(\"name\", beanKey);\n\t\t\t\treturn ObjectNameManager.getInstance(domain, properties);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["reads", "the", "object", "name", "from", "the", "source", "level", "metadata", "associated", "with", "the", "managed", "resource", "s", "class"], "project": "spring-framework"}
{"id": 6051, "code": "\tpublic ResultMatcher isContinue() {\n\t\treturn matcher(HttpStatus.CONTINUE);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 1881, "code": "\tpublic static CronField zeroNanos() {\n\t\treturn BitsCronField.zeroNanos();\n\t}", "summary_tokens": ["return", "a", "cron", "field", "enabled", "for", "0", "nanoseconds"], "project": "spring-framework"}
{"id": 7994, "code": "\tpublic PathMatchConfigurer setUseTrailingSlashMatch(Boolean trailingSlashMatch) {\n\t\tthis.trailingSlashMatch = trailingSlashMatch;\n\t\treturn this;\n\t}", "summary_tokens": ["whether", "to", "match", "to", "urls", "irrespective", "of", "the", "presence", "of", "a", "trailing", "slash"], "project": "spring-framework"}
{"id": 979, "code": "\tprotected ExceptionTypeFilter createExceptionTypeFilter(\n\t\t\tClass<? extends Throwable>[] includes, Class<? extends Throwable>[] excludes) {\n\n\t\treturn new ExceptionTypeFilter(Arrays.asList(includes), Arrays.asList(excludes), true);\n\t}", "summary_tokens": ["convenience", "method", "for", "subclasses", "to", "create", "a", "specific", "exception", "type", "filter"], "project": "spring-framework"}
{"id": 7511, "code": "\tprotected boolean shouldNotFilterAsyncDispatch() {\n\t\treturn false;\n\t}", "summary_tokens": ["returns", "false", "so", "that", "the", "filter", "may", "set", "up", "the", "request", "context", "in", "each", "asynchronously", "dispatched", "thread"], "project": "spring-framework"}
{"id": 234, "code": "\tpublic static boolean matches(Pointcut pointcut, Method method, Class<?> targetClass, Object... args) {\n\t\tAssert.notNull(pointcut, \"Pointcut must not be null\");\n\t\tif (pointcut == Pointcut.TRUE) {\n\t\t\treturn true;\n\t\t}\n\t\tif (pointcut.getClassFilter().matches(targetClass)) {\n\t\t\t\n\t\t\tMethodMatcher mm = pointcut.getMethodMatcher();\n\t\t\tif (mm.matches(method, targetClass)) {\n\t\t\t\t\n\t\t\t\treturn (!mm.isRuntime() || mm.matches(method, targetClass, args));\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["perform", "the", "least", "expensive", "check", "for", "a", "pointcut", "match"], "project": "spring-framework"}
{"id": 8379, "code": "\tprotected String[] getViewNames() {\n\t\treturn this.viewNames;\n\t}", "summary_tokens": ["return", "the", "view", "names", "or", "name", "patterns", "that", "can", "be", "handled", "by", "this", "view", "resolver"], "project": "spring-framework"}
{"id": 666, "code": "\tpublic static String uniqueBeanName(String beanName, BeanDefinitionRegistry registry) {\n\t\tString id = beanName;\n\t\tint counter = -1;\n\n\t\t\n\t\tString prefix = beanName + GENERATED_BEAN_NAME_SEPARATOR;\n\t\twhile (counter == -1 || registry.containsBeanDefinition(id)) {\n\t\t\tcounter++;\n\t\t\tid = prefix + counter;\n\t\t}\n\t\treturn id;\n\t}", "summary_tokens": ["turn", "the", "given", "bean", "name", "into", "a", "unique", "bean", "name", "for", "the", "given", "bean", "factory", "appending", "a", "unique", "counter", "as", "suffix", "if", "necessary"], "project": "spring-framework"}
{"id": 1281, "code": "\tprotected BeanDefinitionRegistry getRegistry() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "bean", "definition", "registry", "used", "by", "this", "scanner", "if", "any"], "project": "spring-framework"}
{"id": 621, "code": "\tdefault Object getLazyResolutionProxyIfNecessary(DependencyDescriptor descriptor, @Nullable String beanName) {\n\t\treturn null;\n\t}", "summary_tokens": ["build", "a", "proxy", "for", "lazy", "resolution", "of", "the", "actual", "dependency", "target", "if", "demanded", "by", "the", "injection", "point"], "project": "spring-framework"}
{"id": 1988, "code": "\tpublic void setIgnoreUnknownFields(boolean ignoreUnknownFields) {\n\t\tthis.ignoreUnknownFields = ignoreUnknownFields;\n\t}", "summary_tokens": ["set", "whether", "to", "ignore", "unknown", "fields", "that", "is", "whether", "to", "ignore", "bind", "parameters", "that", "do", "not", "have", "corresponding", "fields", "in", "the", "target", "object"], "project": "spring-framework"}
{"id": 1837, "code": "\tpublic Runnable getRunnable() {\n\t\tAssert.state(this.runnable != null, \"No Runnable set\");\n\t\treturn this.runnable;\n\t}", "summary_tokens": ["return", "the", "runnable", "to", "schedule", "as", "executor", "task"], "project": "spring-framework"}
{"id": 4926, "code": "\tdefault org.springframework.util.concurrent.ListenableFuture<StompSession> getSessionFuture() {\n\t\treturn new org.springframework.util.concurrent.CompletableToListenableFutureAdapter<>(\n\t\t\t\tgetSession());\n\t}", "summary_tokens": ["return", "a", "future", "that", "will", "complete", "when", "the", "session", "is", "ready", "for", "use"], "project": "spring-framework"}
{"id": 5816, "code": "\tpublic RequestMatcher multipartDataContains(Map<String, ?> expectedMap) {\n\t\tMultiValueMap<String, Object> map = new LinkedMultiValueMap<>(expectedMap.size());\n\t\texpectedMap.forEach(map::add);\n\t\treturn multipartData(map, false);\n\t}", "summary_tokens": ["variant", "of", "multipart", "data", "multi", "value", "map", "that", "does", "the", "same", "but", "only", "for", "a", "subset", "of", "the", "actual", "values"], "project": "spring-framework"}
{"id": 2332, "code": "final ByteVector encodeUtf8(final String stringValue, final int offset, final int maxByteLength) {\n  int charLength = stringValue.length();\n  int byteLength = offset;\n  for (int i = offset; i < charLength; ++i) {\n    char charValue = stringValue.charAt(i);\n    if (charValue >= 0x0001 && charValue <= 0x007F) {\n      byteLength++;\n    } else if (charValue <= 0x07FF) {\n      byteLength += 2;\n    } else {\n      byteLength += 3;\n    }\n  }\n  if (byteLength > maxByteLength) {\n    throw new IllegalArgumentException(\"UTF8 string too large\");\n  }\n    \n  int byteLengthOffset = length - offset - 2;\n  if (byteLengthOffset >= 0) {\n    data[byteLengthOffset] = (byte) (byteLength >>> 8);\n    data[byteLengthOffset + 1] = (byte) byteLength;\n  }\n  if (length + byteLength - offset > data.length) {\n    enlarge(byteLength - offset);\n  }\n  int currentLength = length;\n  for (int i = offset; i < charLength; ++i) {\n    char charValue = stringValue.charAt(i);\n    if (charValue >= 0x0001 && charValue <= 0x007F) {\n      data[currentLength++] = (byte) charValue;\n    } else if (charValue <= 0x07FF) {\n      data[currentLength++] = (byte) (0xC0 | charValue >> 6 & 0x1F);\n      data[currentLength++] = (byte) (0x80 | charValue & 0x3F);\n    } else {\n      data[currentLength++] = (byte) (0xE0 | charValue >> 12 & 0xF);\n      data[currentLength++] = (byte) (0x80 | charValue >> 6 & 0x3F);\n      data[currentLength++] = (byte) (0x80 | charValue & 0x3F);\n    }\n  }\n  length = currentLength;\n  return this;\n}", "summary_tokens": ["puts", "an", "utf", "0", "string", "into", "this", "byte", "vector"], "project": "spring-framework"}
{"id": 445, "code": "\tpublic CodeBlock generateNewBeanDefinitionCode(GenerationContext generationContext,\n\t\t\tResolvableType beanType, BeanRegistrationCode beanRegistrationCode) {\n\n\t\treturn this.codeFragments.generateNewBeanDefinitionCode(generationContext,\n\t\t\t\tbeanType, beanRegistrationCode);\n\n\t}", "summary_tokens": ["generate", "the", "code", "that", "defines", "the", "new", "bean", "definition", "instance"], "project": "spring-framework"}
{"id": 236, "code": "\tpublic void setPatterns(String... patterns) {\n\t\tthis.patterns = patterns;\n\t}", "summary_tokens": ["set", "the", "regular", "expressions", "defining", "methods", "to", "match"], "project": "spring-framework"}
{"id": 8756, "code": "\tpublic static <T extends ServerResponse> RouterFunction<T> nest(\n\t\t\tRequestPredicate predicate, RouterFunction<T> routerFunction) {\n\n\t\treturn new DefaultNestedRouterFunction<>(predicate, routerFunction);\n\t}", "summary_tokens": ["route", "to", "the", "given", "router", "function", "if", "the", "given", "request", "predicate", "applies"], "project": "spring-framework"}
{"id": 4097, "code": "\tpublic void setSqlReadyForUse(boolean sqlReadyForUse) {\n\t\tthis.sqlReadyForUse = sqlReadyForUse;\n\t}", "summary_tokens": ["set", "whether", "the", "sql", "can", "be", "used", "as", "is"], "project": "spring-framework"}
{"id": 3416, "code": "\tpublic void clear() {\n\t\tthis.prefixToNamespaceUri.clear();\n\t\tthis.namespaceUriToPrefixes.clear();\n\t}", "summary_tokens": ["remove", "all", "declared", "prefixes"], "project": "spring-framework"}
{"id": 2868, "code": "\tpublic boolean containsOption(String optionName) {\n\t\treturn this.optionArgs.containsKey(optionName);\n\t}", "summary_tokens": ["return", "whether", "the", "option", "with", "the", "given", "name", "was", "present", "on", "the", "command", "line"], "project": "spring-framework"}
{"id": 5161, "code": "\tpublic Properties getHibernateProperties() {\n\t\tif (this.hibernateProperties == null) {\n\t\t\tthis.hibernateProperties = new Properties();\n\t\t}\n\t\treturn this.hibernateProperties;\n\t}", "summary_tokens": ["return", "the", "hibernate", "properties", "if", "any"], "project": "spring-framework"}
{"id": 390, "code": "\tpublic <A extends Annotation> A getAnnotation(Class<A> annotationType) {\n\t\treturn (this.field != null ? this.field.getAnnotation(annotationType) :\n\t\t\t\tobtainMethodParameter().getParameterAnnotation(annotationType));\n\t}", "summary_tokens": ["retrieve", "a", "field", "parameter", "annotation", "of", "the", "given", "type", "if", "any"], "project": "spring-framework"}
{"id": 7920, "code": "\tpublic Flux<DataBuffer> getBody() {\n\t\treturn this.body;\n\t}", "summary_tokens": ["return", "the", "response", "body", "or", "an", "error", "stream", "if", "the", "body", "was", "not", "set"], "project": "spring-framework"}
{"id": 8022, "code": "\tprotected void configureContentTypeResolver(RequestedContentTypeResolverBuilder builder) {\n\t}", "summary_tokens": ["override", "to", "configure", "how", "the", "requested", "content", "type", "is", "resolved"], "project": "spring-framework"}
{"id": 3652, "code": "\tpublic int getActualCount() {\n\t\treturn this.actualCount;\n\t}", "summary_tokens": ["return", "the", "actual", "column", "count"], "project": "spring-framework"}
{"id": 7702, "code": "\tprotected String formatRequest(ServerHttpRequest request) {\n\t\tString rawQuery = request.getURI().getRawQuery();\n\t\tString query = StringUtils.hasText(rawQuery) ? \"?\" + rawQuery : \"\";\n\t\treturn \"HTTP \" + request.getMethod() + \" \\\"\" + request.getPath() + query + \"\\\"\";\n\t}", "summary_tokens": ["format", "the", "request", "for", "logging", "purposes", "including", "http", "method", "and", "url"], "project": "spring-framework"}
{"id": 7873, "code": "\tpublic PathPattern parse(String pathPattern) throws PatternParseException {\n\t\tAssert.notNull(pathPattern, \"Path pattern must not be null\");\n\n\t\tthis.pathPatternData = pathPattern.toCharArray();\n\t\tthis.pathPatternLength = this.pathPatternData.length;\n\t\tthis.headPE = null;\n\t\tthis.currentPE = null;\n\t\tthis.capturedVariableNames = null;\n\t\tthis.pathElementStart = -1;\n\t\tthis.pos = 0;\n\t\tresetPathElementState();\n\n\t\twhile (this.pos < this.pathPatternLength) {\n\t\t\tchar ch = this.pathPatternData[this.pos];\n\t\t\tchar separator = this.parser.getPathOptions().separator();\n\t\t\tif (ch == separator) {\n\t\t\t\tif (this.pathElementStart != -1) {\n\t\t\t\t\tpushPathElement(createPathElement());\n\t\t\t\t}\n\t\t\t\tif (peekDoubleWildcard()) {\n\t\t\t\t\tpushPathElement(new WildcardTheRestPathElement(this.pos, separator));\n\t\t\t\t\tthis.pos += 2;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tpushPathElement(new SeparatorPathElement(this.pos, separator));\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (this.pathElementStart == -1) {\n\t\t\t\t\tthis.pathElementStart = this.pos;\n\t\t\t\t}\n\t\t\t\tif (ch == '?') {\n\t\t\t\t\tthis.singleCharWildcardCount++;\n\t\t\t\t}\n\t\t\t\telse if (ch == '{') {\n\t\t\t\t\tif (this.insideVariableCapture) {\n\t\t\t\t\t\tthrow new PatternParseException(this.pos, this.pathPatternData,\n\t\t\t\t\t\t\t\tPatternMessage.ILLEGAL_NESTED_CAPTURE);\n\t\t\t\t\t}\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tthis.insideVariableCapture = true;\n\t\t\t\t\tthis.variableCaptureStart = this.pos;\n\t\t\t\t}\n\t\t\t\telse if (ch == '}') {\n\t\t\t\t\tif (!this.insideVariableCapture) {\n\t\t\t\t\t\tthrow new PatternParseException(this.pos, this.pathPatternData,\n\t\t\t\t\t\t\t\tPatternMessage.MISSING_OPEN_CAPTURE);\n\t\t\t\t\t}\n\t\t\t\t\tthis.insideVariableCapture = false;\n\t\t\t\t\tif (this.isCaptureTheRestVariable && (this.pos + 1) < this.pathPatternLength) {\n\t\t\t\t\t\tthrow new PatternParseException(this.pos + 1, this.pathPatternData,\n\t\t\t\t\t\t\t\tPatternMessage.NO_MORE_DATA_EXPECTED_AFTER_CAPTURE_THE_REST);\n\t\t\t\t\t}\n\t\t\t\t\tthis.variableCaptureCount++;\n\t\t\t\t}\n\t\t\t\telse if (ch == ':') {\n\t\t\t\t\tif (this.insideVariableCapture && !this.isCaptureTheRestVariable) {\n\t\t\t\t\t\tskipCaptureRegex();\n\t\t\t\t\t\tthis.insideVariableCapture = false;\n\t\t\t\t\t\tthis.variableCaptureCount++;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (ch == '*') {\n\t\t\t\t\tif (this.insideVariableCapture && this.variableCaptureStart == this.pos - 1) {\n\t\t\t\t\t\tthis.isCaptureTheRestVariable = true;\n\t\t\t\t\t}\n\t\t\t\t\tthis.wildcard = true;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (this.insideVariableCapture) {\n\t\t\t\t\tif ((this.variableCaptureStart + 1 + (this.isCaptureTheRestVariable ? 1 : 0)) == this.pos &&\n\t\t\t\t\t\t\t!Character.isJavaIdentifierStart(ch)) {\n\t\t\t\t\t\tthrow new PatternParseException(this.pos, this.pathPatternData,\n\t\t\t\t\t\t\t\tPatternMessage.ILLEGAL_CHARACTER_AT_START_OF_CAPTURE_DESCRIPTOR,\n\t\t\t\t\t\t\t\tCharacter.toString(ch));\n\n\t\t\t\t\t}\n\t\t\t\t\telse if ((this.pos > (this.variableCaptureStart + 1 + (this.isCaptureTheRestVariable ? 1 : 0)) &&\n\t\t\t\t\t\t\t!Character.isJavaIdentifierPart(ch) && ch != '-')) {\n\t\t\t\t\t\tthrow new PatternParseException(this.pos, this.pathPatternData,\n\t\t\t\t\t\t\t\tPatternMessage.ILLEGAL_CHARACTER_IN_CAPTURE_DESCRIPTOR,\n\t\t\t\t\t\t\t\tCharacter.toString(ch));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis.pos++;\n\t\t}\n\t\tif (this.pathElementStart != -1) {\n\t\t\tpushPathElement(createPathElement());\n\t\t}\n\t\treturn new PathPattern(pathPattern, this.parser, this.headPE);", "summary_tokens": ["package", "private", "delegate", "for", "path", "pattern", "parser", "parse", "string"], "project": "spring-framework"}
{"id": 7548, "code": "\tprotected void handleResolvedValue(@Nullable Object arg, String name, MethodParameter parameter,\n\t\t\t@Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest) {\n\t}", "summary_tokens": ["invoked", "after", "a", "value", "is", "resolved"], "project": "spring-framework"}
{"id": 9860, "code": "\tpublic void setInboundMessageSizeLimit(int inboundMessageSizeLimit) {\n\t\tthis.inboundMessageSizeLimit = inboundMessageSizeLimit;\n\t}", "summary_tokens": ["configure", "the", "maximum", "size", "allowed", "for", "inbound", "stomp", "message"], "project": "spring-framework"}
{"id": 4066, "code": "\tpublic void setJdbcTemplate(JdbcTemplate jdbcTemplate) {\n\t\tthis.jdbcTemplate = jdbcTemplate;\n\t}", "summary_tokens": ["an", "alternative", "to", "the", "more", "commonly", "used", "set", "data", "source", "when", "you", "want", "to", "use", "the", "same", "jdbc", "template", "in", "multiple", "rdbms", "operations"], "project": "spring-framework"}
{"id": 3621, "code": "\tpublic void testConversionsAvailable() throws Exception {\n\t\tTypeConvertorUsingConversionService tcs = new TypeConvertorUsingConversionService();\n\n\t\t\n\t\tClass<?> clazz = typeDescriptorForListOfString.getElementTypeDescriptor().getType();\n\t\tassertThat(clazz).isEqualTo(String.class);\n\t\tList<?> l = (List<?>) tcs.convertValue(listOfInteger, TypeDescriptor.forObject(listOfInteger), typeDescriptorForListOfString);\n\t\tassertThat(l).isNotNull();\n\n\t\t\n\t\tclazz = typeDescriptorForListOfInteger.getElementTypeDescriptor().getType();\n\t\tassertThat(clazz).isEqualTo(Integer.class);\n\n\t\tl = (List<?>) tcs.convertValue(listOfString, TypeDescriptor.forObject(listOfString), typeDescriptorForListOfString);\n\t\tassertThat(l).isNotNull();\n\t}", "summary_tokens": ["test", "the", "service", "can", "convert", "what", "we", "are", "about", "to", "use", "in", "the", "expression", "evaluation", "tests"], "project": "spring-framework"}
{"id": 8485, "code": "\tdefault void afterConcurrentHandlingStarted(HttpServletRequest request, HttpServletResponse response,\n\t\t\tObject handler) throws Exception {\n\t}", "summary_tokens": ["called", "instead", "of", "post", "handle", "and", "after", "completion", "when", "the", "handler", "is", "being", "executed", "concurrently"], "project": "spring-framework"}
{"id": 6387, "code": "\tpublic static Mono<TransactionContext> currentContext() throws NoTransactionException {\n\t\treturn Mono.deferContextual(ctx -> {\n\t\t\tif (ctx.hasKey(TransactionContext.class)) {\n\t\t\t\treturn Mono.just(ctx.get(TransactionContext.class));\n\t\t\t}\n\t\t\tif (ctx.hasKey(TransactionContextHolder.class)) {\n\t\t\t\tTransactionContextHolder holder = ctx.get(TransactionContextHolder.class);\n\t\t\t\tif (holder.hasContext()) {\n\t\t\t\t\treturn Mono.just(holder.currentContext());\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn Mono.error(new NoTransactionInContextException());\n\t\t});\n\t}", "summary_tokens": ["obtain", "the", "current", "transaction", "context", "from", "the", "subscriber", "context", "or", "the", "transactional", "context", "holder"], "project": "spring-framework"}
{"id": 9442, "code": "\tprivate void renderOption(TagWriter tagWriter, Object item, @Nullable Object value, @Nullable Object label)\n\t\t\tthrows JspException {\n\n\t\ttagWriter.startTag(\"option\");\n\t\twriteCommonAttributes(tagWriter);\n\n\t\tString valueDisplayString = getDisplayString(value);\n\t\tString labelDisplayString = getDisplayString(label);\n\n\t\tvalueDisplayString = processOptionValue(valueDisplayString);\n\n\t\t\n\t\ttagWriter.writeAttribute(\"value\", valueDisplayString);\n\n\t\tif (isOptionSelected(value) || (value != item && isOptionSelected(item))) {\n\t\t\ttagWriter.writeAttribute(\"selected\", \"selected\");\n\t\t}\n\t\tif (isOptionDisabled()) {\n\t\t\ttagWriter.writeAttribute(\"disabled\", \"disabled\");\n\t\t}\n\t\ttagWriter.appendValue(labelDisplayString);\n\t\ttagWriter.endTag();\n\t}", "summary_tokens": ["render", "an", "html", "option", "with", "the", "supplied", "value", "and", "label"], "project": "spring-framework"}
{"id": 2851, "code": "\tprotected Set<String> getReservedDefaultProfiles() {\n\t\treturn Collections.singleton(RESERVED_DEFAULT_PROFILE_NAME);\n\t}", "summary_tokens": ["return", "the", "set", "of", "reserved", "default", "profile", "names"], "project": "spring-framework"}
{"id": 3105, "code": "\tpublic static void notEmpty(@Nullable Map<?, ?> map) {\n\t\tnotEmpty(map, \"[Assertion failed] - this map must not be empty; it must contain at least one entry\");\n\t}", "summary_tokens": ["assert", "that", "a", "map", "contains", "entries", "that", "is", "it", "must", "not", "be", "null", "and", "must", "contain", "at", "least", "one", "entry"], "project": "spring-framework"}
{"id": 5195, "code": "\tprotected boolean shouldNotFilterErrorDispatch() {\n\t\treturn false;\n\t}", "summary_tokens": ["returns", "false", "so", "that", "the", "filter", "may", "provide", "a", "hibernate", "session", "to", "each", "error", "dispatches"], "project": "spring-framework"}
{"id": 5844, "code": "\tpublic RequestMatcher exists() {\n\t\treturn (XpathRequestMatcher) request ->\n\t\t\t\tthis.xpathHelper.exists(request.getBodyAsBytes(), DEFAULT_ENCODING);\n\t}", "summary_tokens": ["assert", "that", "content", "exists", "at", "the", "given", "xpath"], "project": "spring-framework"}
{"id": 8372, "code": "\tpublic void setViewClass(@Nullable Class<?> viewClass) {\n\t\tif (viewClass != null && !requiredViewClass().isAssignableFrom(viewClass)) {\n\t\t\tString name = viewClass.getName();\n\t\t\tthrow new IllegalArgumentException(\"Given view class [\" + name + \"] \" +\n\t\t\t\t\t\"is not of type [\" + requiredViewClass().getName() + \"]\");\n\t\t}\n\t\tthis.viewClass = viewClass;\n\t}", "summary_tokens": ["set", "the", "view", "class", "that", "should", "be", "used", "to", "create", "views"], "project": "spring-framework"}
{"id": 7022, "code": "\tpublic Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "pojo", "that", "needs", "to", "be", "serialized"], "project": "spring-framework"}
{"id": 6586, "code": "\tpublic void cannotCreateTransaction() throws Exception {\n\t\tTransactionAttribute txatt = new DefaultTransactionAttribute();\n\n\t\tMethod m = getNameMethod;\n\t\tMapTransactionAttributeSource tas = new MapTransactionAttributeSource();\n\t\ttas.register(m, txatt);\n\n\t\tReactiveTransactionManager rtm = mock(ReactiveTransactionManager.class);\n\t\t\n\t\tCannotCreateTransactionException ex = new CannotCreateTransactionException(\"foobar\", null);\n\t\tgiven(rtm.getReactiveTransaction(txatt)).willThrow(ex);\n\n\t\tDefaultTestBean tb = new DefaultTestBean() {\n\t\t\t@Override\n\t\t\tpublic Mono<String> getName() {\n\t\t\t\tthrow new UnsupportedOperationException(\n\t\t\t\t\t\t\"Shouldn't have invoked target method when couldn't create transaction for transactional method\");\n\t\t\t}\n\t\t};\n\t\tTestBean itb = (TestBean) advised(tb, rtm, tas);\n\n\t\titb.getName()\n\t\t\t\t.as(StepVerifier::create)\n\t\t\t\t.expectError(CannotCreateTransactionException.class)\n\t\t\t\t.verify();\n\t}", "summary_tokens": ["simulate", "a", "transaction", "infrastructure", "failure"], "project": "spring-framework"}
{"id": 6378, "code": "\tprotected boolean shouldUnbindAtCompletion() {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "this", "holder", "should", "be", "unbound", "at", "completion", "or", "should", "rather", "be", "left", "bound", "to", "the", "thread", "after", "the", "transaction"], "project": "spring-framework"}
{"id": 5770, "code": "\tpublic void assertNode(String content, Matcher<? super Node> matcher) throws Exception {\n\t\tDocument document = parseXmlString(content);\n\t\tassertThat(\"Body content\", document, matcher);\n\t}", "summary_tokens": ["parse", "the", "content", "as", "node", "and", "apply", "a", "matcher"], "project": "spring-framework"}
{"id": 1730, "code": "\tpublic static boolean isDefaultJndiEnvironmentAvailable() {\n\t\tif (shouldIgnoreDefaultJndiEnvironment) {\n\t\t\treturn false;\n\t\t}\n\t\ttry {\n\t\t\tnew InitialContext().getEnvironment();\n\t\t\treturn true;\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["check", "whether", "a", "default", "jndi", "environment", "as", "in", "a", "jakarta", "ee", "environment", "is", "available", "on", "this", "jvm"], "project": "spring-framework"}
{"id": 4451, "code": "\tprotected Session getSession(JmsResourceHolder holder) {\n\t\treturn holder.getSession();\n\t}", "summary_tokens": ["fetch", "an", "appropriate", "session", "from", "the", "given", "jms", "resource", "holder"], "project": "spring-framework"}
{"id": 758, "code": "\tpublic void registerExternallyManagedConfigMember(Member configMember) {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\tif (this.externallyManagedConfigMembers == null) {\n\t\t\t\tthis.externallyManagedConfigMembers = new LinkedHashSet<>(1);\n\t\t\t}\n\t\t\tthis.externallyManagedConfigMembers.add(configMember);\n\t\t}\n\t}", "summary_tokens": ["register", "an", "externally", "managed", "configuration", "method", "or", "field"], "project": "spring-framework"}
{"id": 1312, "code": "\tpublic boolean condition(String conditionExpression, ApplicationEvent event, Method targetMethod,\n\t\t\tAnnotatedElementKey methodKey, Object[] args, @Nullable BeanFactory beanFactory) {\n\n\t\tEventExpressionRootObject root = new EventExpressionRootObject(event, args);\n\t\tMethodBasedEvaluationContext evaluationContext = new MethodBasedEvaluationContext(\n\t\t\t\troot, targetMethod, args, getParameterNameDiscoverer());\n\t\tif (beanFactory != null) {\n\t\t\tevaluationContext.setBeanResolver(new BeanFactoryResolver(beanFactory));\n\t\t}\n\n\t\treturn (Boolean.TRUE.equals(getExpression(this.conditionCache, methodKey, conditionExpression).getValue(\n\t\t\t\tevaluationContext, Boolean.class)));\n\t}", "summary_tokens": ["determine", "if", "the", "condition", "defined", "by", "the", "specified", "expression", "evaluates", "to", "true"], "project": "spring-framework"}
{"id": 6375, "code": "\tpublic Object getSuspendedResources() {\n\t\treturn this.suspendedResources;\n\t}", "summary_tokens": ["return", "the", "holder", "for", "resources", "that", "have", "been", "suspended", "for", "this", "transaction", "if", "any"], "project": "spring-framework"}
{"id": 4291, "code": "\tprotected boolean isReconnectOnException() {\n\t\treturn this.reconnectOnException;\n\t}", "summary_tokens": ["return", "whether", "the", "single", "connection", "should", "be", "renewed", "when", "a", "jmsexception", "is", "reported", "by", "the", "underlying", "connection"], "project": "spring-framework"}
{"id": 6729, "code": "\tprotected String initToStringContent() {\n\t\treturn \"type='\" + this.type + \"'\" +\n\t\t\t\t\", title='\" + getTitle() + \"'\" +\n\t\t\t\t\", status=\" + getStatus() +\n\t\t\t\t\", detail='\" + getDetail() + \"'\" +\n\t\t\t\t\", instance='\" + getInstance() + \"'\" +\n\t\t\t\t\", properties='\" + getProperties() + \"'\";\n\t}", "summary_tokens": ["return", "a", "string", "representation", "of", "the", "problem", "detail", "fields"], "project": "spring-framework"}
{"id": 6779, "code": "\tpublic void setExecutor(@Nullable Executor executor) {\n\t\tthis.executor = executor;\n\t}", "summary_tokens": ["configure", "the", "executor", "to", "use"], "project": "spring-framework"}
{"id": 9094, "code": "\tprotected boolean isFlashMapForRequest(FlashMap flashMap, HttpServletRequest request) {\n\t\tString expectedPath = flashMap.getTargetRequestPath();\n\t\tif (expectedPath != null) {\n\t\t\tString requestUri = getUrlPathHelper().getOriginatingRequestUri(request);\n\t\t\tif (!requestUri.equals(expectedPath) && !requestUri.equals(expectedPath + \"/\")) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\tMultiValueMap<String, String> actualParams = getOriginatingRequestParams(request);\n\t\tMultiValueMap<String, String> expectedParams = flashMap.getTargetRequestParams();\n\t\tfor (Map.Entry<String, List<String>> entry : expectedParams.entrySet()) {\n\t\t\tList<String> actualValues = actualParams.get(entry.getKey());\n\t\t\tif (actualValues == null) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tfor (String expectedValue : entry.getValue()) {\n\t\t\t\tif (!actualValues.contains(expectedValue)) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["whether", "the", "given", "flash", "map", "matches", "the", "current", "request"], "project": "spring-framework"}
{"id": 3362, "code": "\tpublic static <T> Comparator<T> nullsLow(Comparator<T> comparator) {\n\t\treturn new NullSafeComparator<>(comparator, true);\n\t}", "summary_tokens": ["return", "a", "decorator", "for", "the", "given", "comparator", "which", "accepts", "null", "values", "and", "sorts", "them", "lower", "than", "non", "null", "values"], "project": "spring-framework"}
{"id": 3338, "code": "\tpublic static String[] split(@Nullable String toSplit, @Nullable String delimiter) {\n\t\tif (!hasLength(toSplit) || !hasLength(delimiter)) {\n\t\t\treturn null;\n\t\t}\n\t\tint offset = toSplit.indexOf(delimiter);\n\t\tif (offset < 0) {\n\t\t\treturn null;\n\t\t}\n\n\t\tString beforeDelimiter = toSplit.substring(0, offset);\n\t\tString afterDelimiter = toSplit.substring(offset + delimiter.length());\n\t\treturn new String[] {beforeDelimiter, afterDelimiter};\n\t}", "summary_tokens": ["split", "a", "string", "at", "the", "first", "occurrence", "of", "the", "delimiter"], "project": "spring-framework"}
{"id": 1935, "code": "\tpublic static ScriptEngine retrieveEngineByName(ScriptEngineManager scriptEngineManager, String engineName) {\n\t\tScriptEngine engine = scriptEngineManager.getEngineByName(engineName);\n\t\tif (engine == null) {\n\t\t\tSet<String> engineNames = new LinkedHashSet<>();\n\t\t\tfor (ScriptEngineFactory engineFactory : scriptEngineManager.getEngineFactories()) {\n\t\t\t\tList<String> factoryNames = engineFactory.getNames();\n\t\t\t\tif (factoryNames.contains(engineName)) {\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\ttry {\n\t\t\t\t\t\tengine = engineFactory.getScriptEngine();\n\t\t\t\t\t\tengine.setBindings(scriptEngineManager.getBindings(), ScriptContext.GLOBAL_SCOPE);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Throwable ex) {\n\t\t\t\t\t\tthrow new IllegalStateException(\"Script engine with name '\" + engineName +\n\t\t\t\t\t\t\t\t\"' failed to initialize\", ex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tengineNames.addAll(factoryNames);\n\t\t\t}\n\t\t\tthrow new IllegalArgumentException(\"Script engine with name '\" + engineName +\n\t\t\t\t\t\"' not found; registered engine names: \" + engineNames);\n\t\t}\n\t\treturn engine;\n\t}", "summary_tokens": ["retrieve", "a", "script", "engine", "from", "the", "given", "script", "engine", "manager", "by", "name", "delegating", "to", "script", "engine", "manager", "get", "engine", "by", "name", "but", "throwing", "a", "descriptive", "exception", "if", "not", "found", "or", "if", "initialization", "failed"], "project": "spring-framework"}
{"id": 281, "code": "\tpublic void setRefreshCheckDelay(long refreshCheckDelay) {\n\t\tthis.refreshCheckDelay = refreshCheckDelay;\n\t}", "summary_tokens": ["set", "the", "delay", "between", "refresh", "checks", "in", "milliseconds"], "project": "spring-framework"}
{"id": 5177, "code": "\tpublic LocalSessionFactoryBuilder setCacheRegionFactory(RegionFactory cacheRegionFactory) {\n\t\tgetProperties().put(AvailableSettings.CACHE_REGION_FACTORY, cacheRegionFactory);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "hibernate", "region", "factory", "to", "use", "for", "the", "session", "factory"], "project": "spring-framework"}
{"id": 4692, "code": "\tpublic void setBeanFactory(BeanFactory beanFactory) {\n\t\tthis.beanFactory = beanFactory;\n\t}", "summary_tokens": ["a", "bean", "factory", "only", "needs", "to", "be", "available", "for", "placeholder", "resolution", "in", "handler", "method", "arguments", "it", "s", "optional", "otherwise"], "project": "spring-framework"}
{"id": 3540, "code": "\tpublic boolean isAutoGrowNullReferences() {\n\t\treturn this.autoGrowNullReferences;\n\t}", "summary_tokens": ["return", "true", "if", "null", "references", "should", "be", "automatically", "grown"], "project": "spring-framework"}
{"id": 5535, "code": "\tdefault void beforeTestMethod(TestContext testContext) throws Exception {\n\t}", "summary_tokens": ["pre", "processes", "a", "test", "em", "before", "em", "execution", "of", "em", "before", "em", "lifecycle", "callbacks", "of", "the", "underlying", "test", "framework", "mdash", "for", "example", "by", "setting", "up", "test", "fixtures"], "project": "spring-framework"}
{"id": 9665, "code": "\tprotected Channel newFeed() {\n\t\treturn new Channel(\"rss_2.0\");\n\t}", "summary_tokens": ["create", "a", "new", "channel", "instance", "to", "hold", "the", "entries"], "project": "spring-framework"}
{"id": 5022, "code": "\tpublic String getFirst(String headerName) {\n\t\tList<String> headerValues = this.headers.get(headerName);\n\t\treturn headerValues != null ? headerValues.get(0) : null;\n\t}", "summary_tokens": ["return", "the", "first", "header", "value", "for", "the", "given", "header", "name", "if", "any"], "project": "spring-framework"}
{"id": 5236, "code": "\tpublic void setPersistenceXmlLocations(String... persistenceXmlLocations) {\n\t\tthis.persistenceXmlLocations = persistenceXmlLocations;\n\t}", "summary_tokens": ["specify", "multiple", "locations", "of", "persistence"], "project": "spring-framework"}
{"id": 160, "code": "\tprotected DefaultListableBeanFactory getInternalBeanFactoryForBean(String beanName) {\n\t\tsynchronized (this.internalBeanFactories) {\n\t\t\treturn this.internalBeanFactories.computeIfAbsent(beanName,\n\t\t\t\t\tname -> buildInternalBeanFactory(this.beanFactory));\n\t\t}\n\t}", "summary_tokens": ["return", "the", "internal", "bean", "factory", "to", "be", "used", "for", "the", "specified", "bean"], "project": "spring-framework"}
{"id": 8967, "code": "\tpublic void setContentNegotiationManager(ContentNegotiationManager contentNegotiationManager) {\n\t\tthis.contentNegotiationManager = contentNegotiationManager;\n\t}", "summary_tokens": ["set", "the", "content", "negotiation", "manager", "to", "use", "to", "determine", "requested", "media", "types"], "project": "spring-framework"}
{"id": 5491, "code": "\tstatic BootstrapContext createBootstrapContext(Class<?> testClass) {\n\t\tCacheAwareContextLoaderDelegate cacheAwareContextLoaderDelegate = createCacheAwareContextLoaderDelegate();\n\t\tClass<? extends BootstrapContext> clazz = null;\n\t\ttry {\n\t\t\tclazz = (Class<? extends BootstrapContext>) ClassUtils.forName(\n\t\t\t\t\tDEFAULT_BOOTSTRAP_CONTEXT_CLASS_NAME, BootstrapUtils.class.getClassLoader());\n\t\t\tConstructor<? extends BootstrapContext> constructor = clazz.getConstructor(\n\t\t\t\t\tClass.class, CacheAwareContextLoaderDelegate.class);\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(String.format(\"Instantiating BootstrapContext using constructor [%s]\", constructor));\n\t\t\t}\n\t\t\treturn BeanUtils.instantiateClass(constructor, testClass, cacheAwareContextLoaderDelegate);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tthrow new IllegalStateException(\"Could not load BootstrapContext [\" + clazz + \"]\", ex);\n\t\t}\n\t}", "summary_tokens": ["create", "the", "bootstrap", "context", "for", "the", "specified", "class", "test", "class"], "project": "spring-framework"}
{"id": 9695, "code": "\tpublic void setJsonPrefix(String jsonPrefix) {\n\t\tthis.jsonPrefix = jsonPrefix;\n\t}", "summary_tokens": ["specify", "a", "custom", "prefix", "to", "use", "for", "this", "view", "s", "json", "output"], "project": "spring-framework"}
{"id": 2442, "code": "public int getTag() {\n  return tag;\n}", "summary_tokens": ["returns", "the", "kind", "of", "field", "or", "method", "designated", "by", "this", "handle"], "project": "spring-framework"}
{"id": 7948, "code": "\tprotected PrintWriter getTargetWriter() throws IOException {\n\t\tif (this.targetWriter == null) {\n\t\t\tthis.targetWriter = this.response.getWriter();\n\t\t}\n\t\treturn this.targetWriter;\n\t}", "summary_tokens": ["lazily", "initialize", "the", "target", "writer"], "project": "spring-framework"}
{"id": 2898, "code": "\tpublic CommandLineArgs parse(String... args) {\n\t\tCommandLineArgs commandLineArgs = new CommandLineArgs();\n\t\tfor (String arg : args) {\n\t\t\tif (arg.startsWith(\"--\")) {\n\t\t\t\tString optionText = arg.substring(2);\n\t\t\t\tString optionName;\n\t\t\t\tString optionValue = null;\n\t\t\t\tint indexOfEqualsSign = optionText.indexOf('=');\n\t\t\t\tif (indexOfEqualsSign > -1) {\n\t\t\t\t\toptionName = optionText.substring(0, indexOfEqualsSign);\n\t\t\t\t\toptionValue = optionText.substring(indexOfEqualsSign + 1);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\toptionName = optionText;\n\t\t\t\t}\n\t\t\t\tif (optionName.isEmpty()) {\n\t\t\t\t\tthrow new IllegalArgumentException(\"Invalid argument syntax: \" + arg);\n\t\t\t\t}\n\t\t\t\tcommandLineArgs.addOptionArg(optionName, optionValue);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcommandLineArgs.addNonOptionArg(arg);\n\t\t\t}\n\t\t}\n\t\treturn commandLineArgs;\n\t}", "summary_tokens": ["parse", "the", "given", "string", "array", "based", "on", "the", "rules", "described", "simple", "command", "line", "args", "parser", "above", "returning", "a", "fully", "populated", "command", "line", "args", "object"], "project": "spring-framework"}
{"id": 2359, "code": "private int[] readBootstrapMethodsAttribute(final int maxStringLength) {\n  char[] charBuffer = new char[maxStringLength];\n  int currentAttributeOffset = getFirstAttributeOffset();\n  for (int i = readUnsignedShort(currentAttributeOffset - 2); i > 0; --i) {\n      \n    String attributeName = readUTF8(currentAttributeOffset, charBuffer);\n    int attributeLength = readInt(currentAttributeOffset + 2);\n    currentAttributeOffset += 6;\n    if (Constants.BOOTSTRAP_METHODS.equals(attributeName)) {\n        \n      int[] result = new int[readUnsignedShort(currentAttributeOffset)];\n        \n      int currentBootstrapMethodOffset = currentAttributeOffset + 2;\n      for (int j = 0; j < result.length; ++j) {\n        result[j] = currentBootstrapMethodOffset;\n          \n          \n        currentBootstrapMethodOffset +=\n            4 + readUnsignedShort(currentBootstrapMethodOffset + 2) * 2;\n      }\n      return result;\n    }\n    currentAttributeOffset += attributeLength;\n  }\n  throw new IllegalArgumentException();\n}", "summary_tokens": ["reads", "the", "bootstrap", "methods", "attribute", "to", "compute", "the", "offset", "of", "each", "bootstrap", "method"], "project": "spring-framework"}
{"id": 5688, "code": "\tpublic void beforeTestMethod(TestContext testContext) throws Exception {\n\t\tbeforeOrAfterTestMethod(testContext, BEFORE_METHOD, BEFORE_EACH_TEST_METHOD);\n\t}", "summary_tokens": ["if", "the", "current", "test", "method", "of", "the", "supplied", "test", "context", "test", "context", "is", "annotated", "with", "and", "the", "dirties", "context", "method", "mode", "method", "mode", "is", "set", "to", "method", "mode", "before", "method", "before", "method", "or", "if", "the", "test", "class", "is", "annotated", "with", "and", "the", "dirties", "context", "class", "mode", "class", "mode", "is", "set", "to", "class", "mode", "before", "each", "test", "method", "before", "each", "test", "method", "the", "application", "context", "application", "context", "of", "the", "test", "context", "will", "be", "test", "context", "mark", "application", "context", "dirty", "marked", "as", "dirty", "and", "the", "dependency", "injection", "test", "execution", "listener", "reinject", "dependencies", "attribute", "reinject", "dependencies", "attribute", "in", "the", "test", "context", "will", "be", "set", "to", "true"], "project": "spring-framework"}
{"id": 4668, "code": "\tpublic void setThrowExceptionOnLateReply(boolean throwExceptionOnLateReply) {\n\t\tthis.throwExceptionOnLateReply = throwExceptionOnLateReply;\n\t}", "summary_tokens": ["whether", "the", "thread", "sending", "a", "reply", "should", "have", "an", "exception", "raised", "if", "the", "receiving", "thread", "isn", "t", "going", "to", "receive", "the", "reply", "either", "because", "it", "timed", "out", "or", "because", "it", "already", "received", "a", "reply", "or", "because", "it", "got", "an", "exception", "while", "sending", "the", "request", "message"], "project": "spring-framework"}
{"id": 2412, "code": "public String getName() {\n  return name;\n}", "summary_tokens": ["returns", "the", "name", "of", "this", "constant"], "project": "spring-framework"}
{"id": 9673, "code": "\tpublic void setConfiguration(@Nullable Configuration configuration) {\n\t\tthis.configuration = configuration;\n\t}", "summary_tokens": ["set", "the", "free", "marker", "configuration", "to", "be", "used", "by", "this", "view"], "project": "spring-framework"}
{"id": 7218, "code": "\tpublic final BindingResult getBindingResult() {\n\t\treturn this.bindingResult;\n\t}", "summary_tokens": ["return", "the", "binding", "result", "that", "this", "bind", "exception", "wraps"], "project": "spring-framework"}
{"id": 6522, "code": "\tpublic boolean isOpen() {\n\t\treturn (this.referenceCount > 0);\n\t}", "summary_tokens": ["return", "whether", "there", "are", "still", "open", "references", "to", "this", "holder"], "project": "spring-framework"}
{"id": 8183, "code": "\tpublic void setCorsConfigurationSource(CorsConfigurationSource corsConfigurationSource) {\n\t\tAssert.notNull(corsConfigurationSource, \"corsConfigurationSource must not be null\");\n\t\tthis.corsConfigurationSource = corsConfigurationSource;\n\t}", "summary_tokens": ["set", "the", "global", "cors", "configuration", "source"], "project": "spring-framework"}
{"id": 4903, "code": "\tpublic StompBrokerRelayRegistration setRelayHost(String relayHost) {\n\t\tAssert.hasText(relayHost, \"relayHost must not be empty\");\n\t\tthis.relayHost = relayHost;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "stomp", "message", "broker", "host"], "project": "spring-framework"}
{"id": 6989, "code": "\tpublic void setFactory(JsonFactory factory) {\n\t\tthis.builder.factory(factory);\n\t}", "summary_tokens": ["define", "the", "json", "factory", "to", "be", "used", "to", "create", "the", "object", "mapper", "instance"], "project": "spring-framework"}
{"id": 8859, "code": "\tpublic void setServletClass(Class<? extends Servlet> servletClass) {\n\t\tthis.servletClass = servletClass;\n\t}", "summary_tokens": ["set", "the", "class", "of", "the", "servlet", "to", "wrap"], "project": "spring-framework"}
{"id": 3737, "code": "\tpublic boolean isNamedBinding() {\n\t\treturn this.namedBinding;\n\t}", "summary_tokens": ["check", "whether", "parameters", "should", "be", "bound", "by", "name"], "project": "spring-framework"}
{"id": 510, "code": "\tpublic void setPlaceholderSuffix(String placeholderSuffix) {\n\t\tthis.placeholderSuffix = placeholderSuffix;\n\t}", "summary_tokens": ["set", "the", "suffix", "that", "a", "placeholder", "string", "ends", "with"], "project": "spring-framework"}
{"id": 1465, "code": "\tpublic void addMessages(Map<String, String> messages, Locale locale) {\n\t\tAssert.notNull(messages, \"Messages Map must not be null\");\n\t\tmessages.forEach((code, msg) -> addMessage(code, locale, msg));\n\t}", "summary_tokens": ["associate", "the", "given", "message", "values", "with", "the", "given", "keys", "as", "codes"], "project": "spring-framework"}
{"id": 1152, "code": "\tpublic void setPreferFileSystemAccess(boolean preferFileSystemAccess) {\n\t\tthis.preferFileSystemAccess = preferFileSystemAccess;\n\t}", "summary_tokens": ["set", "whether", "to", "prefer", "file", "system", "access", "for", "template", "loading"], "project": "spring-framework"}
{"id": 5666, "code": "\tprotected void loadBeanDefinitions(GenericApplicationContext context, MergedContextConfiguration mergedConfig) {\n\t\tcreateBeanDefinitionReader(context).loadBeanDefinitions(mergedConfig.getLocations());\n\t}", "summary_tokens": ["load", "bean", "definitions", "into", "the", "supplied", "generic", "application", "context", "context", "from", "the", "locations", "or", "classes", "in", "the", "supplied", "merged", "context", "configuration"], "project": "spring-framework"}
{"id": 708, "code": "\tprivate Object doGetObjectFromFactoryBean(FactoryBean<?> factory, String beanName) throws BeanCreationException {\n\t\tObject object;\n\t\ttry {\n\t\t\tobject = factory.getObject();\n\t\t}\n\t\tcatch (FactoryBeanNotInitializedException ex) {\n\t\t\tthrow new BeanCurrentlyInCreationException(beanName, ex.toString());\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tthrow new BeanCreationException(beanName, \"FactoryBean threw exception on object creation\", ex);\n\t\t}\n\n\t\t\n\t\t\n\t\tif (object == null) {\n\t\t\tif (isSingletonCurrentlyInCreation(beanName)) {\n\t\t\t\tthrow new BeanCurrentlyInCreationException(\n\t\t\t\t\t\tbeanName, \"FactoryBean which is currently in creation returned null from getObject\");\n\t\t\t}\n\t\t\tobject = new NullBean();\n\t\t}\n\t\treturn object;\n\t}", "summary_tokens": ["obtain", "an", "object", "to", "expose", "from", "the", "given", "factory", "bean"], "project": "spring-framework"}
{"id": 6969, "code": "\tpublic Jackson2ObjectMapperBuilder indentOutput(boolean indentOutput) {\n\t\tthis.features.put(SerializationFeature.INDENT_OUTPUT, indentOutput);\n\t\treturn this;\n\t}", "summary_tokens": ["shortcut", "for", "serialization", "feature", "indent", "output", "option"], "project": "spring-framework"}
{"id": 1577, "code": "\tprotected String getClassName(Object managedBean, String beanKey) throws JMException {\n\t\treturn getTargetClass(managedBean).getName();\n\t}", "summary_tokens": ["get", "the", "class", "name", "of", "the", "mbean", "resource"], "project": "spring-framework"}
{"id": 9682, "code": "\tprotected SimpleHash buildTemplateModel(Map<String, Object> model, HttpServletRequest request,\n\t\t\tHttpServletResponse response) {\n\n\t\tSimpleHash fmModel = new SimpleHash(getObjectWrapper());\n\t\tfmModel.putAll(model);\n\t\treturn fmModel;\n\t}", "summary_tokens": ["build", "a", "free", "marker", "template", "model", "for", "the", "given", "model", "map"], "project": "spring-framework"}
{"id": 2961, "code": "\tpublic int hashCode() {\n\t\treturn this.inputStream.hashCode();\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "hash", "code", "of", "the", "underlying", "input", "stream"], "project": "spring-framework"}
{"id": 8250, "code": "\tprivate void assertEqualConditionTypes(RequestCondition<?> cond1, RequestCondition<?> cond2) {\n\t\tClass<?> clazz = cond1.getClass();\n\t\tClass<?> otherClazz = cond2.getClass();\n\t\tif (!clazz.equals(otherClazz)) {\n\t\t\tthrow new ClassCastException(\"Incompatible request conditions: \" + clazz + \" vs \" + otherClazz);\n\t\t}\n\t}", "summary_tokens": ["ensure", "the", "held", "request", "conditions", "are", "of", "the", "same", "type"], "project": "spring-framework"}
{"id": 2814, "code": "\tpublic Log getLogger() {\n\t\treturn logger;\n\t}", "summary_tokens": ["return", "the", "currently", "configured", "logger"], "project": "spring-framework"}
{"id": 8590, "code": "\tpublic CorsRegistration allowedMethods(String... methods) {\n\t\tthis.config.setAllowedMethods(Arrays.asList(methods));\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "http", "methods", "to", "allow", "e"], "project": "spring-framework"}
{"id": 4367, "code": "\tpublic int getPhase() {\n\t\treturn this.phase;\n\t}", "summary_tokens": ["return", "the", "phase", "in", "which", "this", "container", "will", "be", "started", "and", "stopped"], "project": "spring-framework"}
{"id": 8380, "code": "\tpublic void setRedirectViewProvider(Function<String, RedirectView> redirectViewProvider) {\n\t\tthis.redirectViewProvider = redirectViewProvider;\n\t}", "summary_tokens": ["url", "based", "redirect", "view", "provider", "which", "can", "be", "used", "to", "provide", "for", "example", "redirect", "views", "with", "a", "custom", "default", "status", "code"], "project": "spring-framework"}
{"id": 3983, "code": "\tpublic Connection getConnection(String username, String password) throws SQLException {\n\t\tif (ObjectUtils.nullSafeEquals(username, getUsername()) &&\n\t\t\t\tObjectUtils.nullSafeEquals(password, getPassword())) {\n\t\t\treturn getConnection();\n\t\t}\n\t\telse {\n\t\t\tthrow new SQLException(\"SingleConnectionDataSource does not support custom username and password\");\n\t\t}\n\t}", "summary_tokens": ["specifying", "a", "custom", "username", "and", "password", "doesn", "t", "make", "sense", "with", "a", "single", "connection"], "project": "spring-framework"}
{"id": 2572, "code": "static int getReturnTypeOffset(final String methodDescriptor) {\n    \n  int currentOffset = 1;\n    \n  while (methodDescriptor.charAt(currentOffset) != ')') {\n    while (methodDescriptor.charAt(currentOffset) == '[') {\n      currentOffset++;\n    }\n    if (methodDescriptor.charAt(currentOffset++) == 'L') {\n        \n      int semiColumnOffset = methodDescriptor.indexOf(';', currentOffset);\n      currentOffset = Math.max(currentOffset, semiColumnOffset + 1);\n    }\n  }\n  return currentOffset + 1;\n}", "summary_tokens": ["returns", "the", "start", "index", "of", "the", "return", "type", "of", "the", "given", "method", "descriptor"], "project": "spring-framework"}
{"id": 8642, "code": "\tpublic UrlBasedViewResolverRegistration viewNames(String... viewNames) {\n\t\tthis.viewResolver.setViewNames(viewNames);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "view", "names", "or", "name", "patterns", "that", "can", "be", "handled", "by", "this", "view", "resolver"], "project": "spring-framework"}
{"id": 1619, "code": "\tprivate boolean hasManagedOperation(Method method) {\n\t\treturn (obtainAttributeSource().getManagedOperation(method) != null);\n\t}", "summary_tokens": ["checks", "to", "see", "if", "the", "given", "method", "has", "the", "managed", "operation", "attribute"], "project": "spring-framework"}
{"id": 3038, "code": "\tpublic static Log getHiddenLog(String category) {\n\t\treturn LogFactory.getLog(\"_\" + category);\n\t}", "summary_tokens": ["create", "a", "hidden", "logger", "with", "a", "category", "name", "prefixed", "with", "thus", "precluding", "it", "from", "being", "enabled", "together", "with", "other", "log", "categories", "from", "the", "same", "package"], "project": "spring-framework"}
{"id": 336, "code": "\tpublic static String canonicalPropertyName(@Nullable String propertyName) {\n\t\tif (propertyName == null) {\n\t\t\treturn \"\";\n\t\t}\n\n\t\tStringBuilder sb = new StringBuilder(propertyName);\n\t\tint searchIndex = 0;\n\t\twhile (searchIndex != -1) {\n\t\t\tint keyStart = sb.indexOf(PropertyAccessor.PROPERTY_KEY_PREFIX, searchIndex);\n\t\t\tsearchIndex = -1;\n\t\t\tif (keyStart != -1) {\n\t\t\t\tint keyEnd = sb.indexOf(\n\t\t\t\t\t\tPropertyAccessor.PROPERTY_KEY_SUFFIX, keyStart + PropertyAccessor.PROPERTY_KEY_PREFIX.length());\n\t\t\t\tif (keyEnd != -1) {\n\t\t\t\t\tString key = sb.substring(keyStart + PropertyAccessor.PROPERTY_KEY_PREFIX.length(), keyEnd);\n\t\t\t\t\tif ((key.startsWith(\"'\") && key.endsWith(\"'\")) || (key.startsWith(\"\\\"\") && key.endsWith(\"\\\"\"))) {\n\t\t\t\t\t\tsb.delete(keyStart + 1, keyStart + 2);\n\t\t\t\t\t\tsb.delete(keyEnd - 2, keyEnd - 1);\n\t\t\t\t\t\tkeyEnd = keyEnd - 2;\n\t\t\t\t\t}\n\t\t\t\t\tsearchIndex = keyEnd + PropertyAccessor.PROPERTY_KEY_SUFFIX.length();\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["determine", "the", "canonical", "name", "for", "the", "given", "property", "path"], "project": "spring-framework"}
{"id": 3542, "code": "\tpublic int getMaximumAutoGrowSize() {\n\t\treturn this.maximumAutoGrowSize;\n\t}", "summary_tokens": ["return", "the", "maximum", "size", "that", "a", "collection", "can", "auto", "grow"], "project": "spring-framework"}
{"id": 5801, "code": "\tpublic static ExpectedCount max(int max) {\n\t\tAssert.isTrue(max >= 1, \"'max' must be >= 1\");\n\t\treturn new ExpectedCount(1, max);\n\t}", "summary_tokens": ["at", "most", "max", "number", "of", "times"], "project": "spring-framework"}
{"id": 6601, "code": "\tvoid conflictingRulesToDetermineExactContract() {\n\t\tList<RollbackRuleAttribute> list = new ArrayList<>();\n\t\tlist.add(new NoRollbackRuleAttribute(MyBusinessWarningException.class));\n\t\tlist.add(new RollbackRuleAttribute(MyBusinessException.class));\n\t\tRuleBasedTransactionAttribute rta = new RuleBasedTransactionAttribute(TransactionDefinition.PROPAGATION_REQUIRED, list);\n\n\t\tassertThat(rta.rollbackOn(new MyBusinessException())).isTrue();\n\t\tassertThat(rta.rollbackOn(new MyBusinessWarningException())).isFalse();\n\t}", "summary_tokens": ["see", "a", "href", "https", "forum"], "project": "spring-framework"}
{"id": 1945, "code": "\tpublic Object getAttribute(String attributeName) {\n\t\treturn get(attributeName);\n\t}", "summary_tokens": ["return", "the", "attribute", "value", "for", "the", "given", "name", "if", "any"], "project": "spring-framework"}
{"id": 6490, "code": "\tpublic final void setIsolationLevel(int isolationLevel) {\n\t\tif (!constants.getValues(PREFIX_ISOLATION).contains(isolationLevel)) {\n\t\t\tthrow new IllegalArgumentException(\"Only values of isolation constants allowed\");\n\t\t}\n\t\tthis.isolationLevel = isolationLevel;\n\t}", "summary_tokens": ["set", "the", "isolation", "level"], "project": "spring-framework"}
{"id": 6538, "code": "\tdefault void afterCommit() {\n\t}", "summary_tokens": ["invoked", "after", "transaction", "commit"], "project": "spring-framework"}
{"id": 7574, "code": "\tpublic void initModel(NativeWebRequest request, ModelAndViewContainer container, HandlerMethod handlerMethod)\n\t\t\tthrows Exception {\n\n\t\tMap<String, ?> sessionAttributes = this.sessionAttributesHandler.retrieveAttributes(request);\n\t\tcontainer.mergeAttributes(sessionAttributes);\n\t\tinvokeModelAttributeMethods(request, container);\n\n\t\tfor (String name : findSessionAttributeArguments(handlerMethod)) {\n\t\t\tif (!container.containsAttribute(name)) {\n\t\t\t\tObject value = this.sessionAttributesHandler.retrieveAttribute(request, name);\n\t\t\t\tif (value == null) {\n\t\t\t\t\tthrow new HttpSessionRequiredException(\"Expected session attribute '\" + name + \"'\", name);\n\t\t\t\t}\n\t\t\t\tcontainer.addAttribute(name, value);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["populate", "the", "model", "in", "the", "following", "order", "ol", "li", "retrieve", "known", "session", "attributes", "listed", "as"], "project": "spring-framework"}
{"id": 8177, "code": "\tpublic void setMessageWriters(List<HttpMessageWriter<?>> configurer) {\n\t\tthis.messageWriters = configurer;\n\t}", "summary_tokens": ["configure", "http", "message", "writers", "to", "serialize", "the", "request", "body", "with"], "project": "spring-framework"}
{"id": 3766, "code": "\tprivate void locateTableAndProcessMetaData(DatabaseMetaData databaseMetaData,\n\t\t\t@Nullable String catalogName, @Nullable String schemaName, @Nullable String tableName) {\n\n\t\tMap<String, TableMetaData> tableMeta = new HashMap<>();\n\t\tResultSet tables = null;\n\t\ttry {\n\t\t\ttables = databaseMetaData.getTables(\n\t\t\t\t\tcatalogNameToUse(catalogName), schemaNameToUse(schemaName), tableNameToUse(tableName), null);\n\t\t\twhile (tables != null && tables.next()) {\n\t\t\t\tTableMetaData tmd = new TableMetaData();\n\t\t\t\ttmd.setCatalogName(tables.getString(\"TABLE_CAT\"));\n\t\t\t\ttmd.setSchemaName(tables.getString(\"TABLE_SCHEM\"));\n\t\t\t\ttmd.setTableName(tables.getString(\"TABLE_NAME\"));\n\t\t\t\tif (tmd.getSchemaName() == null) {\n\t\t\t\t\ttableMeta.put(this.userName != null ? this.userName.toUpperCase() : \"\", tmd);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\ttableMeta.put(tmd.getSchemaName().toUpperCase(), tmd);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcatch (SQLException ex) {\n\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\tlogger.warn(\"Error while accessing table meta-data results: \" + ex.getMessage());\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tJdbcUtils.closeResultSet(tables);\n\t\t}\n\n\t\tif (tableMeta.isEmpty()) {\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Unable to locate table meta-data for '\" + tableName + \"': column names must be provided\");\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tprocessTableColumns(databaseMetaData, findTableMetaData(schemaName, tableName, tableMeta));\n\t\t}\n\t}", "summary_tokens": ["method", "supporting", "the", "meta", "data", "processing", "for", "a", "table"], "project": "spring-framework"}
{"id": 5067, "code": "\tdefault void afterMessageHandled(Message<?> message, MessageChannel channel, MessageHandler handler,\n\t\t\t@Nullable Exception ex) {\n\t}", "summary_tokens": ["invoked", "inside", "the", "runnable", "submitted", "to", "the", "executor", "after", "calling", "the", "target", "message", "handler", "regardless", "of", "the", "outcome", "i"], "project": "spring-framework"}
{"id": 5199, "code": "\tpublic SessionFactory getSessionFactory() {\n\t\treturn this.sessionFactory;\n\t}", "summary_tokens": ["return", "the", "hibernate", "session", "factory", "that", "should", "be", "used", "to", "create", "hibernate", "sessions"], "project": "spring-framework"}
{"id": 6120, "code": "\tpublic ResultMatcher name(String expectedViewName) {\n\t\treturn result -> {\n\t\t\tModelAndView mav = result.getModelAndView();\n\t\t\tif (mav == null) {\n\t\t\t\tfail(\"No ModelAndView found\");\n\t\t\t}\n\t\t\tassertEquals(\"View name\", expectedViewName, mav.getViewName());\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "selected", "view", "name"], "project": "spring-framework"}
{"id": 9446, "code": "\tprotected boolean isOptionDisabled() throws JspException {\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "whether", "the", "option", "fields", "should", "be", "disabled"], "project": "spring-framework"}
{"id": 6574, "code": "\tpublic void tearDown() {\n\t\tassertThat(TransactionSynchronizationManager.getResourceMap().isEmpty()).isTrue();\n\t\tassertThat(TransactionSynchronizationManager.isSynchronizationActive()).isFalse();\n\t\tassertThat(TransactionSynchronizationManager.getCurrentTransactionName()).isNull();\n\t\tassertThat(TransactionSynchronizationManager.isCurrentTransactionReadOnly()).isFalse();\n\t\tassertThat(TransactionSynchronizationManager.isActualTransactionActive()).isFalse();\n\t}", "summary_tokens": ["prevent", "any", "side", "effects", "due", "to", "this", "test", "modifying", "thread", "locals", "that", "might", "affect", "subsequent", "tests", "when", "all", "tests", "are", "run", "in", "the", "same", "jvm", "as", "with", "eclipse"], "project": "spring-framework"}
{"id": 4496, "code": "\tpublic void setConnectLazily(boolean connectLazily) {\n\t\tthis.connectLazily = connectLazily;\n\t}", "summary_tokens": ["specify", "whether", "to", "connect", "lazily", "i"], "project": "spring-framework"}
{"id": 7046, "code": "\tstatic RequestPath parse(String rawPath, @Nullable String contextPath) {\n\t\treturn new DefaultRequestPath(rawPath, contextPath);\n\t}", "summary_tokens": ["variant", "of", "parse", "uri", "string", "with", "the", "encoded", "uri", "get", "raw", "path", "raw", "path"], "project": "spring-framework"}
{"id": 6118, "code": "\tpublic ResultMatcher isNetworkAuthenticationRequired() {\n\t\treturn matcher(HttpStatus.valueOf(511));\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 1533, "code": "\tpublic void setAssembler(MBeanInfoAssembler assembler) {\n\t\tthis.assembler = assembler;\n\t}", "summary_tokens": ["set", "the", "implementation", "of", "the", "mbean", "info", "assembler", "interface", "to", "use", "for", "this", "exporter"], "project": "spring-framework"}
{"id": 8587, "code": "\tprotected ContentNegotiationManager buildContentNegotiationManager() {\n\t\tthis.factory.addMediaTypes(this.mediaTypes);\n\t\treturn this.factory.build();\n\t}", "summary_tokens": ["build", "a", "content", "negotiation", "manager", "based", "on", "this", "configurer", "s", "settings"], "project": "spring-framework"}
{"id": 7777, "code": "\tpublic EncodingMode getEncodingMode() {\n\t\treturn this.encodingMode;\n\t}", "summary_tokens": ["return", "the", "configured", "encoding", "mode"], "project": "spring-framework"}
{"id": 314, "code": "\tpublic static void acceptClassLoader(@Nullable ClassLoader classLoader) {\n\t\tif (classLoader != null) {\n\t\t\tacceptedClassLoaders.add(classLoader);\n\t\t}\n\t}", "summary_tokens": ["accept", "the", "given", "class", "loader", "as", "cache", "safe", "even", "if", "its", "classes", "would", "not", "qualify", "as", "cache", "safe", "in", "this", "cached", "introspection", "results", "class"], "project": "spring-framework"}
{"id": 8816, "code": "\tpublic void setStatusCodes(Properties statusCodes) {\n\t\tfor (Enumeration<?> enumeration = statusCodes.propertyNames(); enumeration.hasMoreElements();) {\n\t\t\tString viewName = (String) enumeration.nextElement();\n\t\t\tInteger statusCode = Integer.valueOf(statusCodes.getProperty(viewName));\n\t\t\tthis.statusCodes.put(viewName, statusCode);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "http", "status", "code", "that", "this", "exception", "resolver", "will", "apply", "for", "a", "given", "resolved", "error", "view"], "project": "spring-framework"}
{"id": 7844, "code": "\tpublic void setAlwaysUseFullPath(boolean alwaysUseFullPath) {\n\t\tcheckReadOnly();\n\t\tthis.alwaysUseFullPath = alwaysUseFullPath;\n\t}", "summary_tokens": ["whether", "url", "lookups", "should", "always", "use", "the", "full", "path", "within", "the", "current", "web", "application", "context", "i"], "project": "spring-framework"}
{"id": 3809, "code": "\tprotected ParsedSql getParsedSql(String sql) {\n\t\treturn this.parsedSqlCache.get(sql);\n\t}", "summary_tokens": ["obtain", "a", "parsed", "representation", "of", "the", "given", "sql", "statement"], "project": "spring-framework"}
{"id": 948, "code": "\tpublic Object getObject() throws BeansException {\n\t\tif (isSingleton()) {\n\t\t\treturn this.testBean;\n\t\t}\n\t\telse {\n\t\t\tTestBean prototype = new TestBean(\"prototype created at \" + System.currentTimeMillis(), 11);\n\t\t\tif (this.beanFactory != null) {\n\t\t\t\tthis.beanFactory.applyBeanPostProcessorsBeforeInitialization(prototype, this.beanName);\n\t\t\t}\n\t\t\tprototypeCreated = true;\n\t\t\treturn prototype;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "managed", "object", "supporting", "both", "singleton", "and", "prototype", "mode"], "project": "spring-framework"}
{"id": 2370, "code": "private String readUtf(final int utfOffset, final int utfLength, final char[] charBuffer) {\n  int currentOffset = utfOffset;\n  int endOffset = currentOffset + utfLength;\n  int strLength = 0;\n  byte[] classBuffer = classFileBuffer;\n  while (currentOffset < endOffset) {\n    int currentByte = classBuffer[currentOffset++];\n    if ((currentByte & 0x80) == 0) {\n      charBuffer[strLength++] = (char) (currentByte & 0x7F);\n    } else if ((currentByte & 0xE0) == 0xC0) {\n      charBuffer[strLength++] =\n          (char) (((currentByte & 0x1F) << 6) + (classBuffer[currentOffset++] & 0x3F));\n    } else {\n      charBuffer[strLength++] =\n          (char)\n              (((currentByte & 0xF) << 12)\n                  + ((classBuffer[currentOffset++] & 0x3F) << 6)\n                  + (classBuffer[currentOffset++] & 0x3F));\n    }\n  }\n  return new String(charBuffer, 0, strLength);\n}", "summary_tokens": ["reads", "an", "utf", "0", "string", "in", "class", "file", "buffer"], "project": "spring-framework"}
{"id": 6368, "code": "\tprotected Mono<Void> registerAfterCompletionWithExistingTransaction(TransactionSynchronizationManager synchronizationManager,\n\t\t\tObject transaction, List<TransactionSynchronization> synchronizations) throws TransactionException {\n\n\t\tlogger.debug(\"Cannot register Spring after-completion synchronization with existing transaction - \" +\n\t\t\t\t\"processing Spring after-completion callbacks immediately, with outcome status 'unknown'\");\n\t\treturn invokeAfterCompletion(synchronizationManager, synchronizations, TransactionSynchronization.STATUS_UNKNOWN);\n\t}", "summary_tokens": ["register", "the", "given", "list", "of", "transaction", "synchronizations", "with", "the", "existing", "transaction"], "project": "spring-framework"}
{"id": 988, "code": "\tpublic boolean isEarlyRemove() {\n\t\treturn !getCacheAnnotation().afterInvocation();\n\t}", "summary_tokens": ["specify", "if", "the", "cache", "entry", "should", "be", "removed", "before", "invoking", "the", "method"], "project": "spring-framework"}
{"id": 6404, "code": "\tpublic void initSynchronization() throws IllegalStateException {\n\t\tif (isSynchronizationActive()) {\n\t\t\tthrow new IllegalStateException(\"Cannot activate transaction synchronization - already active\");\n\t\t}\n\t\tthis.transactionContext.setSynchronizations(new LinkedHashSet<>());\n\t}", "summary_tokens": ["activate", "transaction", "synchronization", "for", "the", "current", "context"], "project": "spring-framework"}
{"id": 5014, "code": "\tpublic void setAck(@Nullable String ack) {\n\t\tset(ACK, ack);\n\t}", "summary_tokens": ["set", "the", "ack", "header", "to", "one", "of", "auto", "client", "or", "client", "individual"], "project": "spring-framework"}
{"id": 2352, "code": "private void readParameterAnnotations(\n    final MethodVisitor methodVisitor,\n    final Context context,\n    final int runtimeParameterAnnotationsOffset,\n    final boolean visible) {\n  int currentOffset = runtimeParameterAnnotationsOffset;\n  int numParameters = classFileBuffer[currentOffset++] & 0xFF;\n  methodVisitor.visitAnnotableParameterCount(numParameters, visible);\n  char[] charBuffer = context.charBuffer;\n  for (int i = 0; i < numParameters; ++i) {\n    int numAnnotations = readUnsignedShort(currentOffset);\n    currentOffset += 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentOffset, charBuffer);\n      currentOffset += 2;\n        \n      currentOffset =\n          readElementValues(\n              methodVisitor.visitParameterAnnotation(i, annotationDescriptor, visible),\n              currentOffset,\n               true,\n              charBuffer);\n    }\n  }\n}", "summary_tokens": ["reads", "a", "runtime", "in", "visible", "parameter", "annotations", "attribute", "and", "makes", "the", "given", "visitor", "visit", "it"], "project": "spring-framework"}
{"id": 6712, "code": "\tpublic static Log forLogName(Class<?> primaryLoggerClass) {\n\t\tLog primaryLogger = LogFactory.getLog(primaryLoggerClass);\n\t\treturn forLog(primaryLogger);\n\t}", "summary_tokens": ["create", "a", "primary", "logger", "for", "the", "given", "class", "and", "wrap", "it", "with", "a", "composite", "that", "delegates", "to", "it", "or", "to", "the", "fallback", "logger", "org"], "project": "spring-framework"}
{"id": 629, "code": "\tpublic BeanDefinitionBuilder setParentName(String parentName) {\n\t\tthis.beanDefinition.setParentName(parentName);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "parent", "definition", "of", "this", "bean", "definition"], "project": "spring-framework"}
{"id": 1816, "code": "\tpublic void afterPropertiesSet() {\n\t\tinitialize();\n\t}", "summary_tokens": ["calls", "initialize", "after", "the", "container", "applied", "all", "property", "values"], "project": "spring-framework"}
{"id": 3787, "code": "\tpublic boolean isGeneratedKeysColumnNameArraySupported() {\n\t\treturn obtainMetaDataProvider().isGeneratedKeysColumnNameArraySupported();\n\t}", "summary_tokens": ["is", "a", "column", "name", "string", "array", "for", "retrieving", "generated", "keys", "supported", "java"], "project": "spring-framework"}
{"id": 6581, "code": "\tpublic void proxyTypeAspectJCausesRegistrationOfAnnotationTransactionAspect() {\n\t\t\n\t\t\n\t\tassertThatException()\n\t\t\t.isThrownBy(() -> new AnnotationConfigApplicationContext(EnableAspectjTxConfig.class, TxManagerConfig.class))\n\t\t\t.withMessageContaining(\"AspectJJtaTransactionManagementConfiguration\");\n\t}", "summary_tokens": ["a", "cheap", "test", "just", "to", "prove", "that", "in", "aspectj", "mode", "the", "annotation", "transaction", "aspect", "does", "indeed", "get", "loaded", "or", "in", "this", "case", "attempted", "to", "be", "loaded", "at", "which", "point", "the", "test", "fails"], "project": "spring-framework"}
{"id": 4248, "code": "\tpublic void setMostSpecificMethod(@Nullable Method mostSpecificMethod) {\n\t\tthis.mostSpecificMethod = mostSpecificMethod;\n\t}", "summary_tokens": ["set", "the", "most", "specific", "method", "known", "for", "this", "endpoint", "s", "declaration"], "project": "spring-framework"}
{"id": 616, "code": "\tpublic String getTypeName() {\n\t\treturn this.typeName;\n\t}", "summary_tokens": ["retrieve", "the", "type", "name"], "project": "spring-framework"}
{"id": 8976, "code": "\tpublic void setRedirectPatterns(@Nullable String... redirectPatterns) {\n\t\tthis.redirectPatterns = redirectPatterns;\n\t}", "summary_tokens": ["configure", "one", "more", "simple", "patterns", "as", "described", "in", "pattern", "match", "utils", "simple", "match", "to", "use", "in", "order", "to", "recognize", "custom", "redirect", "prefixes", "in", "addition", "to", "redirect"], "project": "spring-framework"}
{"id": 9463, "code": "\tprotected String getItemValue() {\n\t\treturn this.itemValue;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "item", "value", "attribute"], "project": "spring-framework"}
{"id": 1599, "code": "\tprotected void populateOperationDescriptor(Descriptor desc, Method method, String beanKey) {\n\t\tapplyDefaultCurrencyTimeLimit(desc);\n\t}", "summary_tokens": ["allows", "subclasses", "to", "add", "extra", "fields", "to", "the", "descriptor", "for", "a", "particular", "operation"], "project": "spring-framework"}
{"id": 6872, "code": "\tdefault String filename() {\n\t\tString filename = this.headers().getContentDisposition().getFilename();\n\t\tAssert.state(filename != null, \"No filename found\");\n\t\treturn filename;\n\t}", "summary_tokens": ["return", "the", "original", "filename", "in", "the", "client", "s", "filesystem"], "project": "spring-framework"}
{"id": 2581, "code": "public int getDimensions() {\n  int numDimensions = 1;\n  while (valueBuffer.charAt(valueBegin + numDimensions) == '[') {\n    numDimensions++;\n  }\n  return numDimensions;\n}", "summary_tokens": ["returns", "the", "number", "of", "dimensions", "of", "this", "array", "type"], "project": "spring-framework"}
{"id": 9104, "code": "\tpublic String[] getErrorCodes() {\n\t\treturn this.errorCodes;\n\t}", "summary_tokens": ["return", "the", "error", "codes", "for", "the", "field", "or", "object", "if", "any"], "project": "spring-framework"}
{"id": 6942, "code": "\tpublic void setPrettyPrinting(boolean prettyPrinting) {\n\t\tthis.prettyPrinting = prettyPrinting;\n\t}", "summary_tokens": ["whether", "to", "use", "the", "gson", "builder", "set", "pretty", "printing", "when", "writing", "json"], "project": "spring-framework"}
{"id": 6813, "code": "\tstatic ClientCodecConfigurer create() {\n\t\treturn CodecConfigurerFactory.create(ClientCodecConfigurer.class);\n\t}", "summary_tokens": ["static", "factory", "method", "for", "a", "client", "codec", "configurer"], "project": "spring-framework"}
{"id": 2662, "code": "public void add(Class clazz) {\n    Method[] methods = clazz.getMethods();\n    for (int i = 0; i < methods.length; i++) {\n        Method m = methods[i];\n        if (!m.getDeclaringClass().getName().equals(\"java.lang.Object\")) {\n            add(m);\n        }\n    }\n}", "summary_tokens": ["add", "all", "the", "public", "methods", "in", "the", "specified", "class"], "project": "spring-framework"}
{"id": 6445, "code": "\tprotected DefaultTransactionStatus newTransactionStatus(\n\t\t\tTransactionDefinition definition, @Nullable Object transaction, boolean newTransaction,\n\t\t\tboolean newSynchronization, boolean debug, @Nullable Object suspendedResources) {\n\n\t\tboolean actualNewSynchronization = newSynchronization &&\n\t\t\t\t!TransactionSynchronizationManager.isSynchronizationActive();\n\t\treturn new DefaultTransactionStatus(\n\t\t\t\ttransaction, newTransaction, actualNewSynchronization,\n\t\t\t\tdefinition.isReadOnly(), debug, suspendedResources);\n\t}", "summary_tokens": ["create", "a", "transaction", "status", "instance", "for", "the", "given", "arguments"], "project": "spring-framework"}
{"id": 7308, "code": "\tpublic boolean isConcurrentHandlingStarted() {\n\t\treturn (this.asyncWebRequest != null && this.asyncWebRequest.isAsyncStarted());\n\t}", "summary_tokens": ["whether", "the", "selected", "handler", "for", "the", "current", "request", "chose", "to", "handle", "the", "request", "asynchronously"], "project": "spring-framework"}
{"id": 715, "code": "\tpublic void setSource(@Nullable Object source) {\n\t\tthis.source = source;\n\t}", "summary_tokens": ["set", "the", "configuration", "source", "object", "for", "this", "metadata", "element"], "project": "spring-framework"}
{"id": 54, "code": "\tprivate void parseAdvisor(Element advisorElement, ParserContext parserContext) {\n\t\tAbstractBeanDefinition advisorDef = createAdvisorBeanDefinition(advisorElement, parserContext);\n\t\tString id = advisorElement.getAttribute(ID);\n\n\t\ttry {\n\t\t\tthis.parseState.push(new AdvisorEntry(id));\n\t\t\tString advisorBeanName = id;\n\t\t\tif (StringUtils.hasText(advisorBeanName)) {\n\t\t\t\tparserContext.getRegistry().registerBeanDefinition(advisorBeanName, advisorDef);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tadvisorBeanName = parserContext.getReaderContext().registerWithGeneratedName(advisorDef);\n\t\t\t}\n\n\t\t\tObject pointcut = parsePointcutProperty(advisorElement, parserContext);\n\t\t\tif (pointcut instanceof BeanDefinition) {\n\t\t\t\tadvisorDef.getPropertyValues().add(POINTCUT, pointcut);\n\t\t\t\tparserContext.registerComponent(\n\t\t\t\t\t\tnew AdvisorComponentDefinition(advisorBeanName, advisorDef, (BeanDefinition) pointcut));\n\t\t\t}\n\t\t\telse if (pointcut instanceof String) {\n\t\t\t\tadvisorDef.getPropertyValues().add(POINTCUT, new RuntimeBeanReference((String) pointcut));\n\t\t\t\tparserContext.registerComponent(\n\t\t\t\t\t\tnew AdvisorComponentDefinition(advisorBeanName, advisorDef));\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tthis.parseState.pop();\n\t\t}\n\t}", "summary_tokens": ["parses", "the", "supplied", "advisor", "element", "and", "registers", "the", "resulting", "org"], "project": "spring-framework"}
{"id": 3389, "code": "\tpublic static DataSize ofGigabytes(long gigabytes) {\n\t\treturn new DataSize(Math.multiplyExact(gigabytes, BYTES_PER_GB));\n\t}", "summary_tokens": ["obtain", "a", "data", "size", "representing", "the", "specified", "number", "of", "gigabytes"], "project": "spring-framework"}
{"id": 9758, "code": "\tpublic void setAutoStartup(boolean autoStartup) {\n\t\tthis.autoStartup = autoStartup;\n\t}", "summary_tokens": ["set", "whether", "to", "auto", "connect", "to", "the", "remote", "endpoint", "after", "this", "connection", "manager", "has", "been", "initialized", "and", "the", "spring", "context", "has", "been", "refreshed"], "project": "spring-framework"}
{"id": 4311, "code": "\tpublic void setJmsTemplate(@Nullable JmsTemplate jmsTemplate) {\n\t\tthis.jmsTemplate = jmsTemplate;\n\t}", "summary_tokens": ["set", "the", "jms", "template", "to", "use"], "project": "spring-framework"}
{"id": 2483, "code": "public void visitJumpInsn(final int opcode, final Label label) {\n  if (mv != null) {\n    mv.visitJumpInsn(opcode, label);\n  }\n}", "summary_tokens": ["visits", "a", "jump", "instruction"], "project": "spring-framework"}
{"id": 8734, "code": "\tstatic <T> Builder<T> fromObject(T t, ParameterizedTypeReference<T> entityType) {\n\t\treturn DefaultEntityResponseBuilder.fromObject(t, entityType);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "the", "given", "object", "and", "type", "reference"], "project": "spring-framework"}
{"id": 4576, "code": "\tpublic static void closeMessageProducer(@Nullable MessageProducer producer) {\n\t\tif (producer != null) {\n\t\t\ttry {\n\t\t\t\tproducer.close();\n\t\t\t}\n\t\t\tcatch (JMSException ex) {\n\t\t\t\tlogger.trace(\"Could not close JMS MessageProducer\", ex);\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\t\n\t\t\t\tlogger.trace(\"Unexpected exception on closing JMS MessageProducer\", ex);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["close", "the", "given", "jms", "message", "producer", "and", "ignore", "any", "thrown", "exception"], "project": "spring-framework"}
{"id": 6193, "code": "\tpublic Class<?> getEndpointClass() {\n\t\treturn null;\n\t}", "summary_tokens": ["implementation", "of", "the", "jca", "0"], "project": "spring-framework"}
{"id": 6737, "code": "\tpublic static HeadersBuilder<?> head(String uriTemplate, Object... uriVariables) {\n\t\treturn method(HttpMethod.HEAD, uriTemplate, uriVariables);\n\t}", "summary_tokens": ["create", "an", "http", "head", "builder", "with", "the", "given", "string", "base", "uri", "template"], "project": "spring-framework"}
{"id": 2595, "code": "public static TypeReference newTypeParameterReference(final int sort, final int paramIndex) {\n  return new TypeReference((sort << 24) | (paramIndex << 16));\n}", "summary_tokens": ["returns", "a", "reference", "to", "a", "type", "parameter", "of", "a", "generic", "class", "or", "method"], "project": "spring-framework"}
{"id": 1650, "code": "\tpublic int getPersistPeriod() {\n\t\treturn this.persistPeriod;\n\t}", "summary_tokens": ["the", "persist", "period", "for", "this", "metric"], "project": "spring-framework"}
{"id": 7716, "code": "\tpublic boolean hasForwardedHeaderTransformer() {\n\t\treturn (this.forwardedHeaderTransformer != null);\n\t}", "summary_tokens": ["whether", "a", "forwarded", "header", "transformer", "is", "configured", "or", "not", "either", "detected", "from", "an", "application", "context", "or", "explicitly", "configured", "via", "forwarded", "header", "transformer", "forwarded", "header", "transformer"], "project": "spring-framework"}
{"id": 5248, "code": "\tpublic DataSource getDefaultDataSource() {\n\t\treturn this.defaultDataSource;\n\t}", "summary_tokens": ["return", "the", "jdbc", "data", "source", "that", "the", "jpa", "persistence", "provider", "is", "supposed", "to", "use", "for", "accessing", "the", "database", "if", "none", "has", "been", "specified", "in", "persistence"], "project": "spring-framework"}
{"id": 155, "code": "\tpublic String getAdvisorBeanNamePrefix() {\n\t\treturn this.advisorBeanNamePrefix;\n\t}", "summary_tokens": ["return", "the", "prefix", "for", "bean", "names", "that", "will", "cause", "them", "to", "be", "included", "for", "auto", "proxying", "by", "this", "object"], "project": "spring-framework"}
{"id": 4302, "code": "\tprotected void closeConnection(Connection con) {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Closing shared JMS Connection: \" + con);\n\t\t}\n\t\ttry {\n\t\t\ttry {\n\t\t\t\tif (this.startedCount > 0) {\n\t\t\t\t\tcon.stop();\n\t\t\t\t}\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tcon.close();\n\t\t\t}\n\t\t}\n\t\tcatch (jakarta.jms.IllegalStateException ex) {\n\t\t\tlogger.debug(\"Ignoring Connection state exception - assuming already closed: \" + ex);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tlogger.warn(\"Could not close shared JMS Connection\", ex);\n\t\t}\n\t}", "summary_tokens": ["close", "the", "given", "connection"], "project": "spring-framework"}
{"id": 642, "code": "\tpublic BeanDefinitionBuilder setAutowireMode(int autowireMode) {\n\t\tthis.beanDefinition.setAutowireMode(autowireMode);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "autowire", "mode", "for", "this", "definition"], "project": "spring-framework"}
{"id": 3225, "code": "\tpublic static void copyRecursively(Path src, Path dest) throws IOException {\n\t\tAssert.notNull(src, \"Source Path must not be null\");\n\t\tAssert.notNull(dest, \"Destination Path must not be null\");\n\t\tBasicFileAttributes srcAttr = Files.readAttributes(src, BasicFileAttributes.class);\n\n\t\tif (srcAttr.isDirectory()) {\n\t\t\tFiles.walkFileTree(src, EnumSet.of(FOLLOW_LINKS), Integer.MAX_VALUE, new SimpleFileVisitor<Path>() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException {\n\t\t\t\t\tFiles.createDirectories(dest.resolve(src.relativize(dir)));\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {\n\t\t\t\t\tFiles.copy(file, dest.resolve(src.relativize(file)), StandardCopyOption.REPLACE_EXISTING);\n\t\t\t\t\treturn FileVisitResult.CONTINUE;\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse if (srcAttr.isRegularFile()) {\n\t\t\tFiles.copy(src, dest);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"Source File must denote a directory or file\");\n\t\t}\n\t}", "summary_tokens": ["recursively", "copy", "the", "contents", "of", "the", "src", "file", "directory", "to", "the", "dest", "file", "directory"], "project": "spring-framework"}
{"id": 8135, "code": "\tpublic static RequestPredicate pathExtension(Predicate<String> extensionPredicate) {\n\t\treturn new PathExtensionPredicate(extensionPredicate);\n\t}", "summary_tokens": ["return", "a", "request", "predicate", "that", "matches", "if", "the", "request", "s", "path", "matches", "the", "given", "predicate"], "project": "spring-framework"}
{"id": 7210, "code": "\tpublic final void setPropertyEditorRegistrars(@Nullable PropertyEditorRegistrar[] propertyEditorRegistrars) {\n\t\tthis.propertyEditorRegistrars = propertyEditorRegistrars;\n\t}", "summary_tokens": ["specify", "multiple", "property", "editor", "registrars", "to", "be", "applied", "to", "every", "data", "binder"], "project": "spring-framework"}
{"id": 7524, "code": "\tpublic void handleNavigation(FacesContext facesContext, String fromAction, String outcome) {\n\t\tNavigationHandler handler = getDelegate(facesContext);\n\t\tif (handler instanceof DecoratingNavigationHandler) {\n\t\t\t((DecoratingNavigationHandler) handler).handleNavigation(\n\t\t\t\t\tfacesContext, fromAction, outcome, this.originalNavigationHandler);\n\t\t}\n\t\telse {\n\t\t\thandler.handleNavigation(facesContext, fromAction, outcome);\n\t\t}\n\t}", "summary_tokens": ["handle", "the", "navigation", "request", "implied", "by", "the", "specified", "parameters", "through", "delegating", "to", "the", "target", "bean", "in", "the", "spring", "application", "context"], "project": "spring-framework"}
{"id": 1699, "code": "\tpublic void setServer(@Nullable MBeanServer server) {\n\t\tthis.server = server;\n\t}", "summary_tokens": ["specify", "the", "mbean", "server", "instance", "with", "which", "all", "beans", "should", "be", "registered"], "project": "spring-framework"}
{"id": 8108, "code": "\tstatic HandlerFilterFunction<?, ?> ofRequestProcessor(\n\t\t\tFunction<ServerRequest, Mono<ServerRequest>> requestProcessor) {\n\n\t\tAssert.notNull(requestProcessor, \"Function must not be null\");\n\t\treturn (request, next) -> requestProcessor.apply(request).flatMap(next::handle);\n\t}", "summary_tokens": ["adapt", "the", "given", "request", "processor", "function", "to", "a", "filter", "function", "that", "only", "operates", "on", "the", "server", "request"], "project": "spring-framework"}
{"id": 6408, "code": "\tpublic void setCurrentTransactionName(@Nullable String name) {\n\t\tthis.transactionContext.setCurrentTransactionName(name);\n\t}", "summary_tokens": ["expose", "the", "name", "of", "the", "current", "transaction", "if", "any"], "project": "spring-framework"}
{"id": 9291, "code": "\tprotected String getTitle() {\n\t\treturn this.title;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "title", "attribute"], "project": "spring-framework"}
{"id": 5139, "code": "\tprotected void enableFilters(Session session) {\n\t\tString[] filterNames = getFilterNames();\n\t\tif (filterNames != null) {\n\t\t\tfor (String filterName : filterNames) {\n\t\t\t\tsession.enableFilter(filterName);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["enable", "the", "specified", "filters", "on", "the", "given", "session"], "project": "spring-framework"}
{"id": 6356, "code": "\tprivate Mono<Void> doRollbackOnCommitException(TransactionSynchronizationManager synchronizationManager,\n\t\t\tGenericReactiveTransaction status, Throwable ex) throws TransactionException {\n\n\t\treturn Mono.defer(() -> {\n\t\t\tif (status.isNewTransaction()) {\n\t\t\t\tif (status.isDebug()) {\n\t\t\t\t\tlogger.debug(\"Initiating transaction rollback after commit exception\", ex);\n\t\t\t\t}\n\t\t\t\treturn doRollback(synchronizationManager, status);\n\t\t\t}\n\t\t\telse if (status.hasTransaction()) {\n\t\t\t\tif (status.isDebug()) {\n\t\t\t\t\tlogger.debug(\"Marking existing transaction as rollback-only after commit exception\", ex);\n\t\t\t\t}\n\t\t\t\treturn doSetRollbackOnly(synchronizationManager, status);\n\t\t\t}\n\t\t\treturn Mono.empty();\n\t\t}).onErrorResume(ErrorPredicates.RUNTIME_OR_ERROR, rbex -> {\n\t\t\tlogger.error(\"Commit exception overridden by rollback exception\", ex);\n\t\t\treturn triggerAfterCompletion(synchronizationManager, status, TransactionSynchronization.STATUS_UNKNOWN)\n\t\t\t\t.then(Mono.error(rbex));\n\t\t}).then(triggerAfterCompletion(synchronizationManager, status, TransactionSynchronization.STATUS_ROLLED_BACK));\n\t}", "summary_tokens": ["invoke", "do", "rollback", "handling", "rollback", "exceptions", "properly"], "project": "spring-framework"}
{"id": 8995, "code": "\tpublic HttpInputMessage beforeBodyRead(HttpInputMessage inputMessage, MethodParameter parameter,\n\t\t\tType targetType, Class<? extends HttpMessageConverter<?>> converterType) throws IOException {\n\n\t\treturn inputMessage;\n\t}", "summary_tokens": ["the", "default", "implementation", "returns", "the", "input", "message", "that", "was", "passed", "in"], "project": "spring-framework"}
{"id": 4656, "code": "\tprotected Message<?> doConvert(Object payload, @Nullable Map<String, Object> headers,\n\t\t\t@Nullable MessagePostProcessor postProcessor) {\n\n\t\tMessageHeaders messageHeaders = null;\n\t\tObject conversionHint = (headers != null ? headers.get(CONVERSION_HINT_HEADER) : null);\n\n\t\tMap<String, Object> headersToUse = processHeadersToSend(headers);\n\t\tif (headersToUse != null) {\n\t\t\tif (headersToUse instanceof MessageHeaders) {\n\t\t\t\tmessageHeaders = (MessageHeaders) headersToUse;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tmessageHeaders = new MessageHeaders(headersToUse);\n\t\t\t}\n\t\t}\n\n\t\tMessageConverter converter = getMessageConverter();\n\t\tMessage<?> message = (converter instanceof SmartMessageConverter ?\n\t\t\t\t((SmartMessageConverter) converter).toMessage(payload, messageHeaders, conversionHint) :\n\t\t\t\tconverter.toMessage(payload, messageHeaders));\n\t\tif (message == null) {\n\t\t\tString payloadType = payload.getClass().getName();\n\t\t\tObject contentType = (messageHeaders != null ? messageHeaders.get(MessageHeaders.CONTENT_TYPE) : null);\n\t\t\tthrow new MessageConversionException(\"Unable to convert payload with type='\" + payloadType +\n\t\t\t\t\t\"', contentType='\" + contentType + \"', converter=[\" + getMessageConverter() + \"]\");\n\t\t}\n\t\tif (postProcessor != null) {\n\t\t\tmessage = postProcessor.postProcessMessage(message);\n\t\t}\n\t\treturn message;\n\t}", "summary_tokens": ["convert", "the", "given", "object", "to", "serialized", "form", "possibly", "using", "a", "message", "converter", "wrap", "it", "as", "a", "message", "with", "the", "given", "headers", "and", "apply", "the", "given", "post", "processor"], "project": "spring-framework"}
{"id": 9775, "code": "\tpublic AsyncTaskExecutor getTaskExecutor() {\n\t\treturn this.taskExecutor;\n\t}", "summary_tokens": ["return", "the", "configured", "async", "task", "executor"], "project": "spring-framework"}
{"id": 4431, "code": "\tprotected MessageConsumer createConsumer(Session session, Destination destination) throws JMSException {\n\t\tif (isPubSubDomain() && destination instanceof Topic) {\n\t\t\tif (isSubscriptionShared()) {\n\t\t\t\treturn (isSubscriptionDurable() ?\n\t\t\t\t\t\tsession.createSharedDurableConsumer((Topic) destination, getSubscriptionName(), getMessageSelector()) :\n\t\t\t\t\t\tsession.createSharedConsumer((Topic) destination, getSubscriptionName(), getMessageSelector()));\n\t\t\t}\n\t\t\telse if (isSubscriptionDurable()) {\n\t\t\t\treturn session.createDurableSubscriber(\n\t\t\t\t\t\t(Topic) destination, getSubscriptionName(), getMessageSelector(), isPubSubNoLocal());\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\treturn session.createConsumer(destination, getMessageSelector(), isPubSubNoLocal());\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\treturn session.createConsumer(destination, getMessageSelector());\n\t\t}\n\t}", "summary_tokens": ["create", "a", "jms", "message", "consumer", "for", "the", "given", "session", "and", "destination"], "project": "spring-framework"}
{"id": 3045, "code": "\tpublic void serialize(Object object, OutputStream outputStream) throws IOException {\n\t\tif (!(object instanceof Serializable)) {\n\t\t\tthrow new IllegalArgumentException(getClass().getSimpleName() + \" requires a Serializable payload \" +\n\t\t\t\t\t\"but received an object of type [\" + object.getClass().getName() + \"]\");\n\t\t}\n\t\tObjectOutputStream objectOutputStream = new ObjectOutputStream(outputStream);\n\t\tobjectOutputStream.writeObject(object);\n\t\tobjectOutputStream.flush();\n\t}", "summary_tokens": ["writes", "the", "source", "object", "to", "an", "output", "stream", "using", "java", "serialization"], "project": "spring-framework"}
{"id": 8178, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "for", "this", "result", "handler", "relative", "to", "others"], "project": "spring-framework"}
{"id": 1519, "code": "\tpublic void setProxyInterface(Class<?> proxyInterface) {\n\t\tthis.proxyInterface = proxyInterface;\n\t}", "summary_tokens": ["set", "the", "interface", "that", "the", "generated", "proxy", "will", "implement"], "project": "spring-framework"}
{"id": 767, "code": "\tpublic boolean isExternallyManagedDestroyMethod(String destroyMethod) {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\treturn (this.externallyManagedDestroyMethods != null &&\n\t\t\t\t\tthis.externallyManagedDestroyMethods.contains(destroyMethod));\n\t\t}\n\t}", "summary_tokens": ["determine", "if", "the", "given", "method", "name", "indicates", "an", "externally", "managed", "destruction", "method"], "project": "spring-framework"}
{"id": 2451, "code": "static void putExceptionTable(final Handler firstHandler, final ByteVector output) {\n  output.putShort(getExceptionTableLength(firstHandler));\n  Handler handler = firstHandler;\n  while (handler != null) {\n    output\n        .putShort(handler.startPc.bytecodeOffset)\n        .putShort(handler.endPc.bytecodeOffset)\n        .putShort(handler.handlerPc.bytecodeOffset)\n        .putShort(handler.catchType);\n    handler = handler.nextHandler;\n  }\n}", "summary_tokens": ["puts", "the", "jvms", "exception", "table", "corresponding", "to", "the", "handler", "list", "that", "begins", "with", "the", "given", "element"], "project": "spring-framework"}
{"id": 8620, "code": "\tprotected UrlPathHelper getUrlPathHelperOrDefault() {\n\t\tif (this.urlPathHelper != null) {\n\t\t\treturn this.urlPathHelper;\n\t\t}\n\t\tif (this.defaultUrlPathHelper == null) {\n\t\t\tthis.defaultUrlPathHelper = new UrlPathHelper();\n\t\t}\n\t\treturn this.defaultUrlPathHelper;\n\t}", "summary_tokens": ["return", "the", "configured", "url", "path", "helper", "or", "a", "default", "shared", "instance", "otherwise"], "project": "spring-framework"}
{"id": 64, "code": "\tpublic void setTargetBeanName(String targetBeanName) {\n\t\tthis.targetBeanName = targetBeanName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "bean", "to", "locate", "the", "method", "on"], "project": "spring-framework"}
{"id": 8115, "code": "\tdefault RequestPredicate and(RequestPredicate other) {\n\t\treturn new RequestPredicates.AndRequestPredicate(this, other);\n\t}", "summary_tokens": ["return", "a", "composed", "request", "predicate", "that", "tests", "against", "both", "this", "predicate", "and", "the", "other", "predicate"], "project": "spring-framework"}
{"id": 3550, "code": "\tpublic static Literal getIntLiteral(String numberToken, int startPos, int endPos, int radix) {\n\t\ttry {\n\t\t\tint value = Integer.parseInt(numberToken, radix);\n\t\t\treturn new IntLiteral(numberToken, startPos, endPos, value);\n\t\t}\n\t\tcatch (NumberFormatException ex) {\n\t\t\tthrow new InternalParseException(new SpelParseException(startPos, ex, SpelMessage.NOT_AN_INTEGER, numberToken));\n\t\t}\n\t}", "summary_tokens": ["process", "the", "string", "form", "of", "a", "number", "using", "the", "specified", "base", "if", "supplied", "and", "return", "an", "appropriate", "literal", "to", "hold", "it"], "project": "spring-framework"}
{"id": 6599, "code": "\tvoid ruleForRollbackOnChecked() {\n\t\tList<RollbackRuleAttribute> list = new ArrayList<>();\n\t\tlist.add(new RollbackRuleAttribute(IOException.class.getName()));\n\t\tRuleBasedTransactionAttribute rta = new RuleBasedTransactionAttribute(TransactionDefinition.PROPAGATION_REQUIRED, list);\n\n\t\tassertThat(rta.rollbackOn(new RuntimeException())).isTrue();\n\t\tassertThat(rta.rollbackOn(new MyRuntimeException())).isTrue();\n\t\tassertThat(rta.rollbackOn(new Exception())).isFalse();\n\t\t\n\t\tassertThat(rta.rollbackOn(new IOException())).isTrue();\n\t}", "summary_tokens": ["test", "one", "checked", "exception", "that", "should", "roll", "back"], "project": "spring-framework"}
{"id": 6173, "code": "\tpublic final PersistenceExceptionTranslator[] getDelegates() {\n\t\treturn this.delegates.toArray(new PersistenceExceptionTranslator[0]);\n\t}", "summary_tokens": ["return", "all", "registered", "persistence", "exception", "translator", "delegates", "as", "array"], "project": "spring-framework"}
{"id": 2482, "code": "public void visitInvokeDynamicInsn(\n    final String name,\n    final String descriptor,\n    final Handle bootstrapMethodHandle,\n    final Object... bootstrapMethodArguments) {\n  if (api < Opcodes.ASM5) {\n    throw new UnsupportedOperationException(REQUIRES_ASM5);\n  }\n  if (mv != null) {\n    mv.visitInvokeDynamicInsn(name, descriptor, bootstrapMethodHandle, bootstrapMethodArguments);\n  }\n}", "summary_tokens": ["visits", "an", "invokedynamic", "instruction"], "project": "spring-framework"}
{"id": 704, "code": "\tprivate static List<DestructionAwareBeanPostProcessor> filterPostProcessors(\n\t\t\tList<DestructionAwareBeanPostProcessor> processors, Object bean) {\n\n\t\tList<DestructionAwareBeanPostProcessor> filteredPostProcessors = null;\n\t\tif (!CollectionUtils.isEmpty(processors)) {\n\t\t\tfilteredPostProcessors = new ArrayList<>(processors.size());\n\t\t\tfor (DestructionAwareBeanPostProcessor processor : processors) {\n\t\t\t\tif (processor.requiresDestruction(bean)) {\n\t\t\t\t\tfilteredPostProcessors.add(processor);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn filteredPostProcessors;\n\t}", "summary_tokens": ["search", "for", "all", "destruction", "aware", "bean", "post", "processors", "in", "the", "list"], "project": "spring-framework"}
{"id": 412, "code": "\tpublic static boolean isAutowirable(Parameter parameter, int parameterIndex) {\n\t\tAssert.notNull(parameter, \"Parameter must not be null\");\n\t\tAnnotatedElement annotatedParameter = getEffectiveAnnotatedParameter(parameter, parameterIndex);\n\t\treturn (AnnotatedElementUtils.hasAnnotation(annotatedParameter, Autowired.class) ||\n\t\t\t\tAnnotatedElementUtils.hasAnnotation(annotatedParameter, Qualifier.class) ||\n\t\t\t\tAnnotatedElementUtils.hasAnnotation(annotatedParameter, Value.class));\n\t}", "summary_tokens": ["determine", "if", "the", "supplied", "parameter", "can", "em", "potentially", "em", "be", "autowired", "from", "an", "autowire", "capable", "bean", "factory"], "project": "spring-framework"}
{"id": 5235, "code": "\tpublic void setPersistenceXmlLocation(String persistenceXmlLocation) {\n\t\tthis.persistenceXmlLocations = new String[] {persistenceXmlLocation};\n\t}", "summary_tokens": ["specify", "the", "location", "of", "the", "persistence"], "project": "spring-framework"}
{"id": 4394, "code": "\tprotected String getDestinationDescription() {\n\t\tObject destination = this.destination;\n\t\treturn (destination != null ? destination.toString() : \"\");\n\t}", "summary_tokens": ["return", "a", "descriptive", "string", "for", "this", "container", "s", "jms", "destination", "never", "null"], "project": "spring-framework"}
{"id": 9070, "code": "\tpublic List<String> getContentCodings() {\n\t\treturn Collections.unmodifiableList(this.contentCodings);\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "with", "the", "supported", "content", "codings"], "project": "spring-framework"}
{"id": 8280, "code": "\tpublic List<HttpMessageWriter<?>> getMessageWriters() {\n\t\treturn this.messageWriters;\n\t}", "summary_tokens": ["return", "the", "configured", "message", "converters"], "project": "spring-framework"}
{"id": 2481, "code": "public void visitMethodInsn(\n    final int opcode,\n    final String owner,\n    final String name,\n    final String descriptor,\n    final boolean isInterface) {\n  if (api < Opcodes.ASM5 && (opcode & Opcodes.SOURCE_DEPRECATED) == 0) {\n    if (isInterface != (opcode == Opcodes.INVOKEINTERFACE)) {\n      throw new UnsupportedOperationException(\"INVOKESPECIAL/STATIC on interfaces requires ASM5\");\n    }\n    visitMethodInsn(opcode, owner, name, descriptor);\n    return;\n  }\n  if (mv != null) {\n    mv.visitMethodInsn(opcode & ~Opcodes.SOURCE_MASK, owner, name, descriptor, isInterface);\n  }\n}", "summary_tokens": ["visits", "a", "method", "instruction"], "project": "spring-framework"}
{"id": 4671, "code": "\tpublic int compareTo(DestinationPatternsMessageCondition other, Message<?> message) {\n\t\tObject destination = message.getHeaders().get(LOOKUP_DESTINATION_HEADER);\n\t\tif (destination == null) {\n\t\t\treturn 0;\n\t\t}\n\n\t\tComparator<String> patternComparator = getPatternComparator(destination);\n\t\tIterator<String> iterator = this.patterns.iterator();\n\t\tIterator<String> iteratorOther = other.patterns.iterator();\n\t\twhile (iterator.hasNext() && iteratorOther.hasNext()) {\n\t\t\tint result = patternComparator.compare(iterator.next(), iteratorOther.next());\n\t\t\tif (result != 0) {\n\t\t\t\treturn result;\n\t\t\t}\n\t\t}\n\n\t\tif (iterator.hasNext()) {\n\t\t\treturn -1;\n\t\t}\n\t\telse if (iteratorOther.hasNext()) {\n\t\t\treturn 1;\n\t\t}\n\t\telse {\n\t\t\treturn 0;\n\t\t}\n\t}", "summary_tokens": ["compare", "the", "two", "conditions", "based", "on", "the", "destination", "patterns", "they", "contain"], "project": "spring-framework"}
{"id": 5661, "code": "\tpublic final GenericApplicationContext loadContextForAotRuntime(MergedContextConfiguration mergedConfig,\n\t\t\tApplicationContextInitializer<ConfigurableApplicationContext> initializer) throws Exception {\n\n\t\tAssert.notNull(mergedConfig, \"MergedContextConfiguration must not be null\");\n\t\tAssert.notNull(initializer, \"ApplicationContextInitializer must not be null\");\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Loading ApplicationContext for AOT runtime for merged context configuration \" + mergedConfig);\n\t\t}\n\n\t\tvalidateMergedContextConfiguration(mergedConfig);\n\n\t\tGenericApplicationContext context = createContext();\n\t\tprepareContext(context);\n\t\tprepareContext(context, mergedConfig);\n\t\tinitializer.initialize(context);\n\t\tcustomizeContext(context);\n\t\tcustomizeContext(context, mergedConfig);\n\t\tcontext.refresh();\n\t\treturn context;\n\t}", "summary_tokens": ["load", "a", "generic", "application", "context", "for", "aot", "run", "time", "execution", "based", "on", "the", "supplied", "merged", "context", "configuration", "and", "application", "context", "initializer"], "project": "spring-framework"}
{"id": 8639, "code": "\tpublic UrlBasedViewResolverRegistration prefix(String prefix) {\n\t\tthis.viewResolver.setPrefix(prefix);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "prefix", "that", "gets", "prepended", "to", "view", "names", "when", "building", "a", "url"], "project": "spring-framework"}
{"id": 2586, "code": "public int hashCode() {\n  int hashCode = 13 * (sort == INTERNAL ? OBJECT : sort);\n  if (sort >= ARRAY) {\n    for (int i = valueBegin, end = valueEnd; i < end; i++) {\n      hashCode = 17 * (hashCode + valueBuffer.charAt(i));\n    }\n  }\n  return hashCode;\n}", "summary_tokens": ["returns", "a", "hash", "code", "value", "for", "this", "type"], "project": "spring-framework"}
{"id": 9556, "code": "\tpublic void setStripTrailingSlash(boolean stripTrailingSlash) {\n\t\tthis.stripTrailingSlash = stripTrailingSlash;\n\t}", "summary_tokens": ["set", "whether", "trailing", "slashes", "should", "be", "stripped", "from", "the", "uri", "when", "generating", "the", "view", "name"], "project": "spring-framework"}
{"id": 778, "code": "\tpublic void destroy() {\n\t\tthis.beanFactory = null;\n\t\tthis.beanWiringInfoResolver = null;\n\t}", "summary_tokens": ["release", "references", "to", "the", "bean", "factory", "and", "bean", "wiring", "info", "resolver", "when", "the", "container", "is", "destroyed"], "project": "spring-framework"}
{"id": 6154, "code": "\tvoid buildContextHierarchyMapForTestClassHierarchyWithMultiLevelContextHierarchiesAndOverriddenInitializers() {\n\t\tMap<String, List<ContextConfigurationAttributes>> map = buildContextHierarchyMap(TestClass2WithMultiLevelContextHierarchyWithOverriddenInitializers.class);\n\n\t\tassertThat(map).hasSize(2).containsKeys(\"alpha\", \"beta\");\n\n\t\tList<ContextConfigurationAttributes> alphaConfig = map.get(\"alpha\");\n\t\tassertThat(alphaConfig).hasSize(2);\n\t\tassertThat(alphaConfig.get(0).getLocations().length).isEqualTo(1);\n\t\tassertThat(alphaConfig.get(0).getLocations()[0]).isEqualTo(\"1-A.xml\");\n\t\tassertThat(alphaConfig.get(0).getInitializers().length).isEqualTo(0);\n\t\tassertThat(alphaConfig.get(1).getLocations().length).isEqualTo(0);\n\t\tassertThat(alphaConfig.get(1).getInitializers().length).isEqualTo(1);\n\t\tassertThat(alphaConfig.get(1).getInitializers()[0]).isEqualTo(DummyApplicationContextInitializer.class);\n\n\t\tList<ContextConfigurationAttributes> betaConfig = map.get(\"beta\");\n\t\tassertThat(betaConfig).hasSize(2);\n\t\tassertThat(betaConfig.get(0).getLocations().length).isEqualTo(1);\n\t\tassertThat(betaConfig.get(0).getLocations()[0]).isEqualTo(\"1-B.xml\");\n\t\tassertThat(betaConfig.get(0).getInitializers().length).isEqualTo(0);\n\t\tassertThat(betaConfig.get(1).getLocations().length).isEqualTo(0);\n\t\tassertThat(betaConfig.get(1).getInitializers().length).isEqualTo(1);\n\t\tassertThat(betaConfig.get(1).getInitializers()[0]).isEqualTo(DummyApplicationContextInitializer.class);\n\t}", "summary_tokens": ["used", "to", "reproduce", "bug", "reported", "in", "https", "jira"], "project": "spring-framework"}
{"id": 1716, "code": "\tpublic void setLocateExistingServerIfPossible(boolean locateExistingServerIfPossible) {\n\t\tthis.locateExistingServerIfPossible = locateExistingServerIfPossible;\n\t}", "summary_tokens": ["set", "whether", "the", "mbean", "server", "factory", "bean", "should", "attempt", "to", "locate", "a", "running", "mbean", "server", "before", "creating", "one"], "project": "spring-framework"}
{"id": 2917, "code": "\tpublic boolean equals(@Nullable Object other) {\n\t\treturn (this == other || (other instanceof Resource &&\n\t\t\t\t((Resource) other).getDescription().equals(getDescription())));\n\t}", "summary_tokens": ["this", "implementation", "compares", "description", "strings"], "project": "spring-framework"}
{"id": 3669, "code": "\tprotected void suppressProperty(String propertyName) {\n\t\tif (this.mappedFields != null) {\n\t\t\tthis.mappedFields.remove(lowerCaseName(propertyName));\n\t\t\tthis.mappedFields.remove(underscoreName(propertyName));\n\t\t}\n\t}", "summary_tokens": ["remove", "the", "specified", "property", "from", "the", "mapped", "fields"], "project": "spring-framework"}
{"id": 3337, "code": "\tpublic static String[] removeDuplicateStrings(String[] array) {\n\t\tif (ObjectUtils.isEmpty(array)) {\n\t\t\treturn array;\n\t\t}\n\n\t\tSet<String> set = new LinkedHashSet<>(Arrays.asList(array));\n\t\treturn toStringArray(set);\n\t}", "summary_tokens": ["remove", "duplicate", "strings", "from", "the", "given", "array"], "project": "spring-framework"}
{"id": 9067, "code": "\tpublic void setDefaultServletName(String defaultServletName) {\n\t\tthis.defaultServletName = defaultServletName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "default", "servlet", "to", "be", "forwarded", "to", "for", "static", "resource", "requests"], "project": "spring-framework"}
{"id": 6756, "code": "\tprotected RequestConfig mergeRequestConfig(RequestConfig clientConfig) {\n\t\tif (this.requestConfig == null) {  \n\t\t\treturn clientConfig;\n\t\t}\n\n\t\tRequestConfig.Builder builder = RequestConfig.copy(clientConfig);\n\t\tint connectTimeout = this.requestConfig.getConnectTimeout();\n\t\tif (connectTimeout >= 0) {\n\t\t\tbuilder.setConnectTimeout(connectTimeout);\n\t\t}\n\t\tint connectionRequestTimeout = this.requestConfig.getConnectionRequestTimeout();\n\t\tif (connectionRequestTimeout >= 0) {\n\t\t\tbuilder.setConnectionRequestTimeout(connectionRequestTimeout);\n\t\t}\n\t\tint socketTimeout = this.requestConfig.getSocketTimeout();\n\t\tif (socketTimeout >= 0) {\n\t\t\tbuilder.setSocketTimeout(socketTimeout);\n\t\t}\n\t\treturn builder.build();\n\t}", "summary_tokens": ["merge", "the", "given", "http", "client", "level", "request", "config", "with", "the", "factory", "level", "request", "config", "if", "necessary"], "project": "spring-framework"}
{"id": 4044, "code": "\tpublic static String buildErrorMessage(String stmt, int stmtNumber, EncodedResource encodedResource) {\n\t\treturn String.format(\"Failed to execute SQL script statement #%s of %s: %s\", stmtNumber, encodedResource, stmt);\n\t}", "summary_tokens": ["build", "an", "error", "message", "for", "an", "sql", "script", "execution", "failure", "based", "on", "the", "supplied", "arguments"], "project": "spring-framework"}
{"id": 2324, "code": "final ByteVector put11(final int byteValue1, final int byteValue2) {\n  int currentLength = length;\n  if (currentLength + 2 > data.length) {\n    enlarge(2);\n  }\n  byte[] currentData = data;\n  currentData[currentLength++] = (byte) byteValue1;\n  currentData[currentLength++] = (byte) byteValue2;\n  length = currentLength;\n  return this;\n}", "summary_tokens": ["puts", "two", "bytes", "into", "this", "byte", "vector"], "project": "spring-framework"}
{"id": 2229, "code": "\tpublic GeneratedClass addForFeature(String featureName, Consumer<TypeSpec.Builder> type) {\n\t\tAssert.hasLength(featureName, \"'featureName' must not be empty\");\n\t\tAssert.notNull(type, \"'type' must not be null\");\n\t\treturn createAndAddGeneratedClass(featureName, null, type);\n\t}", "summary_tokens": ["add", "a", "new", "generated", "class", "for", "the", "specified", "feature", "name", "and", "no", "particular", "component"], "project": "spring-framework"}
{"id": 8803, "code": "\tprotected void prepareResponse(Exception ex, HttpServletResponse response) {\n\t\tif (this.preventResponseCaching) {\n\t\t\tpreventCaching(response);\n\t\t}\n\t}", "summary_tokens": ["prepare", "the", "response", "for", "the", "exceptional", "case"], "project": "spring-framework"}
{"id": 6156, "code": "\tpublic void test3IncrementCount2() {\n\t\tint count = dao.getCount(TEST_NAME);\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tassertThat(count).as(\"Expected count=0 after test2IncrementCount1().\").isEqualTo(0);\n\n\t\tcount = dao.incrementCount(TEST_NAME);\n\t\tassertThat(count).as(\"Expected count=1 now.\").isEqualTo(1);\n\t}", "summary_tokens": ["overrides", "parent", "implementation", "in", "order", "to", "change", "expectations", "to", "align", "with", "behavior", "associated", "with", "required", "transactions", "on", "repositories", "daos", "and", "default", "rollback", "semantics", "for", "transactions", "managed", "by", "the", "test", "context", "framework"], "project": "spring-framework"}
{"id": 2059, "code": "\tprotected Class<?>[] determineValidationGroups(MethodInvocation invocation) {\n\t\tValidated validatedAnn = AnnotationUtils.findAnnotation(invocation.getMethod(), Validated.class);\n\t\tif (validatedAnn == null) {\n\t\t\tObject target = invocation.getThis();\n\t\t\tAssert.state(target != null, \"Target must not be null\");\n\t\t\tvalidatedAnn = AnnotationUtils.findAnnotation(target.getClass(), Validated.class);\n\t\t}\n\t\treturn (validatedAnn != null ? validatedAnn.value() : new Class<?>[0]);\n\t}", "summary_tokens": ["determine", "the", "validation", "groups", "to", "validate", "against", "for", "the", "given", "method", "invocation"], "project": "spring-framework"}
{"id": 8732, "code": "\tdefault MessageCodesResolver getMessageCodesResolver() {\n\t\treturn null;\n\t}", "summary_tokens": ["provide", "a", "custom", "message", "codes", "resolver", "for", "building", "message", "codes", "from", "data", "binding", "and", "validation", "error", "codes"], "project": "spring-framework"}
{"id": 7492, "code": "\tpublic void setRelativeRedirects(boolean relativeRedirects) {\n\t\tthis.relativeRedirects = relativeRedirects;\n\t}", "summary_tokens": ["use", "this", "property", "to", "enable", "relative", "redirects", "as", "explained", "in", "relative", "redirect", "filter", "and", "also", "using", "the", "same", "response", "wrapper", "as", "that", "filter", "does", "or", "if", "both", "are", "configured", "only", "one", "will", "wrap"], "project": "spring-framework"}
{"id": 2674, "code": "public void mergeSort(int index, int lo, int hi, Comparator cmp) {\n    chooseComparer(index, cmp);\n    super.mergeSort(lo, hi - 1);\n}", "summary_tokens": ["sort", "the", "arrays", "using", "an", "in", "place", "merge", "sort"], "project": "spring-framework"}
{"id": 9199, "code": "\tpublic void setVar(String var) {\n\t\tthis.var = var;\n\t}", "summary_tokens": ["set", "the", "variable", "name", "to", "expose", "the", "evaluation", "result", "under"], "project": "spring-framework"}
{"id": 6396, "code": "\tpublic boolean hasResource(Object key) {\n\t\tObject actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key);\n\t\tObject value = doGetResource(actualKey);\n\t\treturn (value != null);\n\t}", "summary_tokens": ["check", "if", "there", "is", "a", "resource", "for", "the", "given", "key", "bound", "to", "the", "current", "thread"], "project": "spring-framework"}
{"id": 6961, "code": "\tpublic Jackson2ObjectMapperBuilder serializersByType(Map<Class<?>, JsonSerializer<?>> serializers) {\n\t\tthis.serializers.putAll(serializers);\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "custom", "serializers", "for", "the", "given", "types"], "project": "spring-framework"}
{"id": 6373, "code": "\tpublic boolean isReadOnly() {\n\t\treturn this.readOnly;\n\t}", "summary_tokens": ["return", "if", "this", "transaction", "is", "defined", "as", "read", "only", "transaction"], "project": "spring-framework"}
{"id": 8200, "code": "\tpublic void setExtensions(Map<String, String> extensions) {\n\t\textensions.forEach(this::registerExtension);\n\t}", "summary_tokens": ["configure", "mappings", "from", "content", "codings", "to", "file", "extensions"], "project": "spring-framework"}
{"id": 6717, "code": "\tpublic void setType(URI type) {\n\t\tAssert.notNull(type, \"'type' is required\");\n\t\tthis.type = type;\n\t}", "summary_tokens": ["setter", "for", "the", "get", "type", "problem", "type"], "project": "spring-framework"}
{"id": 1511, "code": "\tprivate boolean shouldShadow(String className) {\n\t\treturn (!className.equals(getClass().getName()) && !className.endsWith(\"ShadowingClassLoader\") &&\n\t\t\t\tisEligibleForShadowing(className));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "class", "should", "be", "excluded", "from", "shadowing"], "project": "spring-framework"}
{"id": 5348, "code": "\tprotected void setConnection(@Nullable Connection connection) {\n\t\tthis.currentConnection = connection;\n\t}", "summary_tokens": ["override", "the", "existing", "connection", "with", "the", "given", "connection"], "project": "spring-framework"}
{"id": 4389, "code": "\tprotected void logRejectedTask(Object task, RuntimeException ex) {\n\t\tif (logger.isWarnEnabled()) {\n\t\t\tlogger.warn(\"Listener container task [\" + task + \"] has been rejected and paused: \" + ex);\n\t\t}\n\t}", "summary_tokens": ["log", "a", "task", "that", "has", "been", "rejected", "by", "do", "reschedule", "task"], "project": "spring-framework"}
{"id": 2762, "code": "\tpublic static void setFlag(String key) {\n\t\tlocalProperties.put(key, Boolean.TRUE.toString());\n\t}", "summary_tokens": ["programmatically", "set", "a", "local", "flag", "to", "true", "overriding", "an", "entry", "in", "the", "spring"], "project": "spring-framework"}
{"id": 7155, "code": "\tpublic void bind(ServletRequest request) {\n\t\tMutablePropertyValues mpvs = new ServletRequestParameterPropertyValues(request);\n\t\tMultipartRequest multipartRequest = WebUtils.getNativeRequest(request, MultipartRequest.class);\n\t\tif (multipartRequest != null) {\n\t\t\tbindMultipart(multipartRequest.getMultiFileMap(), mpvs);\n\t\t}\n\t\telse if (StringUtils.startsWithIgnoreCase(request.getContentType(), MediaType.MULTIPART_FORM_DATA_VALUE)) {\n\t\t\tHttpServletRequest httpServletRequest = WebUtils.getNativeRequest(request, HttpServletRequest.class);\n\t\t\tif (httpServletRequest != null && HttpMethod.POST.matches(httpServletRequest.getMethod())) {\n\t\t\t\tStandardServletPartUtils.bindParts(httpServletRequest, mpvs, isBindEmptyMultipartFiles());\n\t\t\t}\n\t\t}\n\t\taddBindValues(mpvs, request);\n\t\tdoBind(mpvs);\n\t}", "summary_tokens": ["bind", "the", "parameters", "of", "the", "given", "request", "to", "this", "binder", "s", "target", "also", "binding", "multipart", "files", "in", "case", "of", "a", "multipart", "request"], "project": "spring-framework"}
{"id": 5684, "code": "\tpublic String[] resolve(Class<?> testClass) {\n\t\tAssert.notNull(testClass, \"Class must not be null\");\n\t\tAnnotationDescriptor<ActiveProfiles> descriptor = findAnnotationDescriptor(testClass, ActiveProfiles.class);\n\n\t\tif (descriptor == null) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(String.format(\n\t\t\t\t\t\"Could not find an 'annotation declaring class' for annotation type [%s] and class [%s]\",\n\t\t\t\t\tActiveProfiles.class.getName(), testClass.getName()));\n\t\t\t}\n\t\t\treturn EMPTY_STRING_ARRAY;\n\t\t}\n\t\telse {\n\t\t\tActiveProfiles annotation = descriptor.getAnnotation();\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(String.format(\"Retrieved @ActiveProfiles [%s] for declaring class [%s].\", annotation,\n\t\t\t\t\tdescriptor.getDeclaringClass().getName()));\n\t\t\t}\n\t\t\treturn annotation.profiles();\n\t\t}\n\t}", "summary_tokens": ["resolve", "the", "em", "bean", "definition", "profiles", "em", "for", "the", "given", "class", "test", "class", "based", "on", "profiles", "configured", "declaratively", "via", "active", "profiles", "profiles", "or", "active", "profiles", "value"], "project": "spring-framework"}
{"id": 9771, "code": "\tpublic TaskExecutor getTaskExecutor() {\n\t\treturn this.taskExecutor;\n\t}", "summary_tokens": ["return", "the", "configured", "task", "executor"], "project": "spring-framework"}
{"id": 1171, "code": "\tdefault KeyGenerator keyGenerator() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "key", "generator", "bean", "to", "use", "for", "annotation", "driven", "cache", "management"], "project": "spring-framework"}
{"id": 5577, "code": "\tprivate Set<Sql> getSqlAnnotationsFor(Method method) {\n\t\treturn AnnotatedElementUtils.getMergedRepeatableAnnotations(method, Sql.class, SqlGroup.class);\n\t}", "summary_tokens": ["get", "the", "annotations", "declared", "on", "the", "supplied", "method"], "project": "spring-framework"}
{"id": 212, "code": "\tprotected Object doProceed(MethodInvocation mi) throws Throwable {\n\t\t\n\t\treturn mi.proceed();\n\t}", "summary_tokens": ["proceed", "with", "the", "supplied", "org"], "project": "spring-framework"}
{"id": 3395, "code": "\tpublic long toKilobytes() {\n\t\treturn this.bytes / BYTES_PER_KB;\n\t}", "summary_tokens": ["return", "the", "number", "of", "kilobytes", "in", "this", "instance"], "project": "spring-framework"}
{"id": 3109, "code": "\tpublic E get(int index) {\n\t\tint backingListSize = this.backingList.size();\n\t\tE element = null;\n\t\tif (index < backingListSize) {\n\t\t\telement = this.backingList.get(index);\n\t\t\tif (element == null) {\n\t\t\t\telement = this.elementFactory.createElement(index);\n\t\t\t\tthis.backingList.set(index, element);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tfor (int x = backingListSize; x < index; x++) {\n\t\t\t\tthis.backingList.add(null);\n\t\t\t}\n\t\t\telement = this.elementFactory.createElement(index);\n\t\t\tthis.backingList.add(element);\n\t\t}\n\t\treturn element;\n\t}", "summary_tokens": ["get", "the", "element", "at", "the", "supplied", "index", "creating", "it", "if", "there", "is", "no", "element", "at", "that", "index"], "project": "spring-framework"}
{"id": 3111, "code": "\tpublic static byte[] decode(byte[] src) {\n\t\tif (src.length == 0) {\n\t\t\treturn src;\n\t\t}\n\t\treturn Base64.getDecoder().decode(src);\n\t}", "summary_tokens": ["base", "0", "decode", "the", "given", "byte", "array"], "project": "spring-framework"}
{"id": 4846, "code": "\tpublic String getDefaultDestinationPrefix() {\n\t\treturn this.defaultDestinationPrefix;\n\t}", "summary_tokens": ["return", "the", "configured", "default", "destination", "prefix"], "project": "spring-framework"}
{"id": 4960, "code": "\tpublic void setHeaderInitializer(@Nullable MessageHeaderInitializer headerInitializer) {\n\t\tthis.headerInitializer = headerInitializer;\n\t}", "summary_tokens": ["configure", "a", "message", "header", "initializer", "to", "apply", "to", "the", "headers", "of", "all", "messages", "created", "through", "the", "stomp", "broker", "relay", "message", "handler", "that", "are", "sent", "to", "the", "client", "outbound", "message", "channel"], "project": "spring-framework"}
{"id": 1098, "code": "\tpublic static DataSource getConfigTimeDataSource() {\n\t\treturn configTimeDataSourceHolder.get();\n\t}", "summary_tokens": ["return", "the", "data", "source", "for", "the", "currently", "configured", "quartz", "scheduler", "to", "be", "used", "by", "local", "data", "source", "job", "store"], "project": "spring-framework"}
{"id": 820, "code": "\tprivate BeanDefinitionParser findParserForElement(Element element, ParserContext parserContext) {\n\t\tString localName = parserContext.getDelegate().getLocalName(element);\n\t\tBeanDefinitionParser parser = this.parsers.get(localName);\n\t\tif (parser == null) {\n\t\t\tparserContext.getReaderContext().fatal(\n\t\t\t\t\t\"Cannot locate BeanDefinitionParser for element [\" + localName + \"]\", element);\n\t\t}\n\t\treturn parser;\n\t}", "summary_tokens": ["locates", "the", "bean", "definition", "parser", "from", "the", "register", "implementations", "using", "the", "local", "name", "of", "the", "supplied", "element"], "project": "spring-framework"}
{"id": 3286, "code": "\tpublic double getTotalTimeSeconds() {\n\t\treturn nanosToSeconds(this.totalTimeNanos);\n\t}", "summary_tokens": ["get", "the", "total", "time", "in", "seconds", "for", "all", "tasks"], "project": "spring-framework"}
{"id": 8646, "code": "\tpublic ViewControllerRegistration setStatusCode(HttpStatusCode statusCode) {\n\t\tthis.controller.setStatusCode(statusCode);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "status", "code", "to", "set", "on", "the", "response"], "project": "spring-framework"}
{"id": 4930, "code": "\tpublic void setTaskScheduler(@Nullable TaskScheduler taskScheduler) {\n\t\tthis.taskScheduler = taskScheduler;\n\t}", "summary_tokens": ["configure", "the", "task", "scheduler", "to", "use", "for", "receipt", "tracking"], "project": "spring-framework"}
{"id": 1813, "code": "\tpublic void setWaitForTasksToCompleteOnShutdown(boolean waitForJobsToCompleteOnShutdown) {\n\t\tthis.waitForTasksToCompleteOnShutdown = waitForJobsToCompleteOnShutdown;\n\t}", "summary_tokens": ["set", "whether", "to", "wait", "for", "scheduled", "tasks", "to", "complete", "on", "shutdown", "not", "interrupting", "running", "tasks", "and", "executing", "all", "tasks", "in", "the", "queue"], "project": "spring-framework"}
{"id": 8634, "code": "\tprotected ResourceHttpRequestHandler getRequestHandler() {\n\t\tResourceHttpRequestHandler handler = new ResourceHttpRequestHandler();\n\t\tif (this.resourceChainRegistration != null) {\n\t\t\thandler.setResourceResolvers(this.resourceChainRegistration.getResourceResolvers());\n\t\t\thandler.setResourceTransformers(this.resourceChainRegistration.getResourceTransformers());\n\t\t}\n\t\thandler.setLocationValues(this.locationValues);\n\t\thandler.setLocations(this.locationsResources);\n\t\tif (this.cacheControl != null) {\n\t\t\thandler.setCacheControl(this.cacheControl);\n\t\t}\n\t\telse if (this.cachePeriod != null) {\n\t\t\thandler.setCacheSeconds(this.cachePeriod);\n\t\t}\n\t\thandler.setUseLastModified(this.useLastModified);\n\t\thandler.setOptimizeLocations(this.optimizeLocations);\n\t\treturn handler;\n\t}", "summary_tokens": ["return", "a", "resource", "http", "request", "handler", "instance"], "project": "spring-framework"}
{"id": 3016, "code": "\tpublic Resource getResource() {\n\t\treturn this.resource;\n\t}", "summary_tokens": ["return", "the", "underlying", "resource", "for", "this", "resource", "region"], "project": "spring-framework"}
{"id": 8796, "code": "\tpublic void setWarnLogCategory(String loggerName) {\n\t\tthis.warnLogger = (StringUtils.hasLength(loggerName) ? LogFactory.getLog(loggerName) : null);\n\t}", "summary_tokens": ["set", "the", "log", "category", "for", "warn", "logging"], "project": "spring-framework"}
{"id": 6058, "code": "\tpublic ResultMatcher isNonAuthoritativeInformation() {\n\t\treturn matcher(HttpStatus.NON_AUTHORITATIVE_INFORMATION);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 1003, "code": "\tpublic JCacheOperationSource getCacheOperationSource() {\n\t\tAssert.state(this.cacheOperationSource != null, \"The 'cacheOperationSource' property is required: \" +\n\t\t\t\t\"If there are no cacheable methods, then don't use a cache aspect.\");\n\t\treturn this.cacheOperationSource;\n\t}", "summary_tokens": ["return", "the", "cache", "operation", "source", "for", "this", "cache", "aspect"], "project": "spring-framework"}
{"id": 8876, "code": "\tprotected ModelAndView applyStatusAndReason(int statusCode, @Nullable String reason, HttpServletResponse response)\n\t\t\tthrows IOException {\n\n\t\tif (!StringUtils.hasLength(reason)) {\n\t\t\tresponse.sendError(statusCode);\n\t\t}\n\t\telse {\n\t\t\tString resolvedReason = (this.messageSource != null ?\n\t\t\t\t\tthis.messageSource.getMessage(reason, null, reason, LocaleContextHolder.getLocale()) :\n\t\t\t\t\treason);\n\t\t\tresponse.sendError(statusCode, resolvedReason);\n\t\t}\n\t\treturn new ModelAndView();\n\t}", "summary_tokens": ["apply", "the", "resolved", "status", "code", "and", "reason", "to", "the", "response"], "project": "spring-framework"}
{"id": 5520, "code": "\tprivate static EnclosingConfiguration getEnclosingConfiguration(Class<?> clazz) {\n\t\treturn cachedEnclosingConfigurationModes.get(clazz);\n\t}", "summary_tokens": ["get", "the", "enclosing", "configuration", "mode", "for", "the", "supplied", "class"], "project": "spring-framework"}
{"id": 4329, "code": "\tpublic boolean isPubSubNoLocal() {\n\t\treturn this.pubSubNoLocal;\n\t}", "summary_tokens": ["return", "whether", "to", "inhibit", "the", "delivery", "of", "messages", "published", "by", "its", "own", "connection"], "project": "spring-framework"}
{"id": 306, "code": "\tpublic void afterThrowing(Method m, Exception ex) throws Throwable {\n\t\tthrow new UnsupportedOperationException(\"Shouldn't be called\");\n\t}", "summary_tokens": ["not", "valid", "wrong", "number", "of", "arguments"], "project": "spring-framework"}
{"id": 9931, "code": "\tpublic void handleInitialRequest(ServerHttpRequest request, ServerHttpResponse response,\n\t\t\tSockJsFrameFormat frameFormat) throws SockJsException {\n\n\t\tthis.uri = request.getURI();\n\t\tthis.handshakeHeaders = request.getHeaders();\n\t\tthis.principal = request.getPrincipal();\n\t\ttry {\n\t\t\tthis.localAddress = request.getLocalAddress();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\n\t\t}\n\t\ttry {\n\t\t\tthis.remoteAddress = request.getRemoteAddress();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\n\t\t}\n\n\t\tsynchronized (this.responseLock) {\n\t\t\ttry {\n\t\t\t\tthis.response = response;\n\t\t\t\tthis.frameFormat = frameFormat;\n\t\t\t\tServerHttpAsyncRequestControl control = request.getAsyncRequestControl(response);\n\t\t\t\tthis.asyncRequestControl = control;\n\t\t\t\tcontrol.start(-1);\n\t\t\t\tdisableShallowEtagHeaderFilter(request);\n\t\t\t\t\n\t\t\t\tdelegateConnectionEstablished();\n\t\t\t\thandleRequestInternal(request, response, true);\n\t\t\t\t\n\t\t\t\tthis.readyToSend = isActive();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\ttryCloseWithSockJsTransportError(ex, CloseStatus.SERVER_ERROR);\n\t\t\t\tthrow new SockJsTransportFailureException(\"Failed to open session\", getId(), ex);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["handle", "the", "first", "request", "for", "receiving", "messages", "on", "a", "sock", "js", "http", "transport", "based", "session"], "project": "spring-framework"}
{"id": 7013, "code": "\tpublic void setHandlerInstantiator(HandlerInstantiator handlerInstantiator) {\n\t\tthis.builder.handlerInstantiator(handlerInstantiator);\n\t}", "summary_tokens": ["customize", "the", "construction", "of", "jackson", "handlers", "json", "serializer", "json", "deserializer", "key", "deserializer", "type", "resolver", "builder", "and", "type", "id", "resolver"], "project": "spring-framework"}
{"id": 3116, "code": "\tpublic static String encodeToUrlSafeString(byte[] src) {\n\t\treturn new String(encodeUrlSafe(src), DEFAULT_CHARSET);\n\t}", "summary_tokens": ["base", "0", "encode", "the", "given", "byte", "array", "to", "a", "string", "using", "the", "rfc", "0", "url", "and", "filename", "safe", "alphabet"], "project": "spring-framework"}
{"id": 2425, "code": "final void copyFrom(final Frame frame) {\n  inputLocals = frame.inputLocals;\n  inputStack = frame.inputStack;\n  outputStackStart = 0;\n  outputLocals = frame.outputLocals;\n  outputStack = frame.outputStack;\n  outputStackTop = frame.outputStackTop;\n  initializationCount = frame.initializationCount;\n  initializations = frame.initializations;\n}", "summary_tokens": ["sets", "this", "frame", "to", "the", "value", "of", "the", "given", "frame"], "project": "spring-framework"}
{"id": 389, "code": "\tpublic Annotation[] getAnnotations() {\n\t\tif (this.field != null) {\n\t\t\tAnnotation[] fieldAnnotations = this.fieldAnnotations;\n\t\t\tif (fieldAnnotations == null) {\n\t\t\t\tfieldAnnotations = this.field.getAnnotations();\n\t\t\t\tthis.fieldAnnotations = fieldAnnotations;\n\t\t\t}\n\t\t\treturn fieldAnnotations;\n\t\t}\n\t\telse {\n\t\t\treturn obtainMethodParameter().getParameterAnnotations();\n\t\t}\n\t}", "summary_tokens": ["obtain", "the", "annotations", "associated", "with", "the", "wrapped", "field", "or", "method", "constructor", "parameter"], "project": "spring-framework"}
{"id": 2182, "code": "\tpublic ClassLoader getClassLoader() {\n\t\treturn this.classLoader;\n\t}", "summary_tokens": ["return", "the", "classloader", "containing", "the", "compiled", "content", "and", "access", "to", "the", "resources"], "project": "spring-framework"}
{"id": 889, "code": "\tpublic boolean isFirstPage() {\n\t\treturn getPage() == 0;\n\t}", "summary_tokens": ["return", "if", "the", "current", "page", "is", "the", "first", "one"], "project": "spring-framework"}
{"id": 495, "code": "\tdefault boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException {\n\t\treturn true;\n\t}", "summary_tokens": ["perform", "operations", "after", "the", "bean", "has", "been", "instantiated", "via", "a", "constructor", "or", "factory", "method", "but", "before", "spring", "property", "population", "from", "explicit", "properties", "or", "autowiring", "occurs"], "project": "spring-framework"}
{"id": 8186, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["specify", "the", "order", "value", "for", "this", "handler", "mapping", "bean"], "project": "spring-framework"}
{"id": 7130, "code": "\tpublic void setDefaultContentTypeStrategy(ContentNegotiationStrategy strategy) {\n\t\tthis.defaultNegotiationStrategy = strategy;\n\t}", "summary_tokens": ["set", "a", "custom", "content", "negotiation", "strategy", "to", "use", "to", "determine", "the", "content", "type", "to", "use", "when", "no", "content", "type", "is", "requested"], "project": "spring-framework"}
{"id": 1330, "code": "\tpublic void setExpressionPrefix(String expressionPrefix) {\n\t\tAssert.hasText(expressionPrefix, \"Expression prefix must not be empty\");\n\t\tthis.expressionPrefix = expressionPrefix;\n\t}", "summary_tokens": ["set", "the", "prefix", "that", "an", "expression", "string", "starts", "with"], "project": "spring-framework"}
{"id": 6786, "code": "\tpublic void setUseGlobalResources(boolean useGlobalResources) {\n\t\tthis.useGlobalResources = useGlobalResources;\n\t}", "summary_tokens": ["whether", "to", "use", "global", "reactor", "netty", "resources", "via", "http", "resources"], "project": "spring-framework"}
{"id": 3850, "code": "\tpublic boolean isCompiled() {\n\t\treturn this.compiled;\n\t}", "summary_tokens": ["is", "this", "operation", "compiled", "whether", "this", "operation", "is", "compiled", "and", "ready", "to", "use"], "project": "spring-framework"}
{"id": 6388, "code": "\tpublic static Function<Context, Context> createTransactionContext() {\n\t\treturn context -> context.put(TransactionContext.class, new TransactionContext());\n\t}", "summary_tokens": ["create", "a", "transaction", "context", "and", "register", "it", "in", "the", "subscriber", "context"], "project": "spring-framework"}
{"id": 5949, "code": "\tpublic WebClient getWebClient() {\n\t\treturn super.getWebClient();\n\t}", "summary_tokens": ["return", "the", "current", "web", "client", "in", "a", "public", "fashion"], "project": "spring-framework"}
{"id": 5288, "code": "\tprotected boolean shouldNotFilterAsyncDispatch() {\n\t\treturn false;\n\t}", "summary_tokens": ["returns", "false", "so", "that", "the", "filter", "may", "re", "bind", "the", "opened", "entity", "manager", "to", "each", "asynchronously", "dispatched", "thread", "and", "postpone", "closing", "it", "until", "the", "very", "last", "asynchronous", "dispatch"], "project": "spring-framework"}
{"id": 5738, "code": "\tprotected void runAfterTransactionMethods(TestContext testContext) throws Exception {\n\t\tThrowable afterTransactionException = null;\n\n\t\tList<Method> methods = getAnnotatedMethods(testContext.getTestClass(), AfterTransaction.class);\n\t\tfor (Method method : methods) {\n\t\t\ttry {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Executing @AfterTransaction method [\" + method + \"] for test context \" + testContext);\n\t\t\t\t}\n\t\t\t\tReflectionUtils.makeAccessible(method);\n\t\t\t\tmethod.invoke(testContext.getTestInstance());\n\t\t\t}\n\t\t\tcatch (InvocationTargetException ex) {\n\t\t\t\tThrowable targetException = ex.getTargetException();\n\t\t\t\tif (afterTransactionException == null) {\n\t\t\t\t\tafterTransactionException = targetException;\n\t\t\t\t}\n\t\t\t\tlogger.error(\"Exception encountered while executing @AfterTransaction method [\" + method +\n\t\t\t\t\t\t\"] for test context \" + testContext, targetException);\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tif (afterTransactionException == null) {\n\t\t\t\t\tafterTransactionException = ex;\n\t\t\t\t}\n\t\t\t\tlogger.error(\"Exception encountered while executing @AfterTransaction method [\" + method +\n\t\t\t\t\t\t\"] for test context \" + testContext, ex);\n\t\t\t}\n\t\t}\n\n\t\tif (afterTransactionException != null) {\n\t\t\tReflectionUtils.rethrowException(afterTransactionException);\n\t\t}\n\t}", "summary_tokens": ["run", "all", "after", "transaction", "methods", "for", "the", "specified", "test", "context", "test", "context"], "project": "spring-framework"}
{"id": 5790, "code": "\tpublic static void assertViewName(ModelAndView mav, String expectedName) {\n\t\tassertTrue(\"View name is not equal to '\" + expectedName + \"' but was '\" + mav.getViewName() + \"'\",\n\t\t\t\tObjectUtils.nullSafeEquals(expectedName, mav.getViewName()));\n\t}", "summary_tokens": ["check", "to", "see", "if", "the", "view", "name", "in", "the", "model", "and", "view", "matches", "the", "given", "expected", "name"], "project": "spring-framework"}
{"id": 9841, "code": "\tpublic void addProtocolHandler(SubProtocolHandler handler) {\n\t\tList<String> protocols = handler.getSupportedProtocols();\n\t\tif (CollectionUtils.isEmpty(protocols)) {\n\t\t\tif (logger.isErrorEnabled()) {\n\t\t\t\tlogger.error(\"No sub-protocols for \" + handler);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tfor (String protocol : protocols) {\n\t\t\tSubProtocolHandler replaced = this.protocolHandlerLookup.put(protocol, handler);\n\t\t\tif (replaced != null && replaced != handler) {\n\t\t\t\tthrow new IllegalStateException(\"Cannot map \" + handler +\n\t\t\t\t\t\t\" to protocol '\" + protocol + \"': already mapped to \" + replaced + \".\");\n\t\t\t}\n\t\t}\n\t\tthis.protocolHandlers.add(handler);\n\t}", "summary_tokens": ["register", "a", "sub", "protocol", "handler"], "project": "spring-framework"}
{"id": 8296, "code": "\tpublic SessionStatus getSessionStatus() {\n\t\treturn this.sessionStatus;\n\t}", "summary_tokens": ["return", "the", "session", "status", "instance", "to", "use", "that", "can", "be", "used", "to", "signal", "that", "session", "processing", "is", "complete"], "project": "spring-framework"}
{"id": 7791, "code": "\tpublic static RequestPath parseAndCache(HttpServletRequest request) {\n\t\tRequestPath requestPath = ServletRequestPath.parse(request);\n\t\trequest.setAttribute(PATH_ATTRIBUTE, requestPath);\n\t\treturn requestPath;\n\t}", "summary_tokens": ["parse", "the", "http", "servlet", "request", "get", "request", "uri", "request", "uri", "to", "a", "request", "path", "and", "save", "it", "in", "the", "request", "attribute", "path", "attribute", "for", "subsequent", "use", "with", "org"], "project": "spring-framework"}
{"id": 1859, "code": "\tpublic void setKeepAliveSeconds(int keepAliveSeconds) {\n\t\tsynchronized (this.poolSizeMonitor) {\n\t\t\tif (this.threadPoolExecutor != null) {\n\t\t\t\tthis.threadPoolExecutor.setKeepAliveTime(keepAliveSeconds, TimeUnit.SECONDS);\n\t\t\t}\n\t\t\tthis.keepAliveSeconds = keepAliveSeconds;\n\t\t}\n\t}", "summary_tokens": ["set", "the", "thread", "pool", "executor", "s", "keep", "alive", "seconds"], "project": "spring-framework"}
{"id": 3065, "code": "\tdefault MultiValueMap<String, Object> getAllAnnotationAttributes(\n\t\t\tString annotationName, boolean classValuesAsString) {\n\n\t\tAdapt[] adaptations = Adapt.values(classValuesAsString, true);\n\t\treturn getAnnotations().stream(annotationName)\n\t\t\t\t.filter(MergedAnnotationPredicates.unique(MergedAnnotation::getMetaTypes))\n\t\t\t\t.map(MergedAnnotation::withNonMergedAttributes)\n\t\t\t\t.collect(MergedAnnotationCollectors.toMultiValueMap(map ->\n\t\t\t\t\t\tmap.isEmpty() ? null : map, adaptations));\n\t}", "summary_tokens": ["retrieve", "all", "attributes", "of", "all", "annotations", "of", "the", "given", "type", "if", "any", "i"], "project": "spring-framework"}
{"id": 7244, "code": "\tpublic <E> E getResponseBodyAs(ParameterizedTypeReference<E> targetType) {\n\t\treturn getResponseBodyAs(ResolvableType.forType(targetType.getType()));\n\t}", "summary_tokens": ["variant", "of", "get", "response", "body", "as", "class", "with", "parameterized", "type", "reference"], "project": "spring-framework"}
{"id": 628, "code": "\tpublic AbstractBeanDefinition getBeanDefinition() {\n\t\tthis.beanDefinition.validate();\n\t\treturn this.beanDefinition;\n\t}", "summary_tokens": ["validate", "and", "return", "the", "created", "bean", "definition", "object"], "project": "spring-framework"}
{"id": 6312, "code": "\tpublic void setAllowCustomIsolationLevels(boolean allowCustomIsolationLevels) {\n\t\tthis.allowCustomIsolationLevels = allowCustomIsolationLevels;\n\t}", "summary_tokens": ["set", "whether", "to", "allow", "custom", "isolation", "levels", "to", "be", "specified"], "project": "spring-framework"}
{"id": 7465, "code": "\tpublic void setBeforeMessagePrefix(String beforeMessagePrefix) {\n\t\tthis.beforeMessagePrefix = beforeMessagePrefix;\n\t}", "summary_tokens": ["set", "the", "value", "that", "should", "be", "prepended", "to", "the", "log", "message", "written", "i", "before", "i", "a", "request", "is", "processed"], "project": "spring-framework"}
{"id": 4370, "code": "\tprotected void validateConfiguration() {\n\t}", "summary_tokens": ["validate", "the", "configuration", "of", "this", "container"], "project": "spring-framework"}
{"id": 1036, "code": "\tpublic MimeMessage createMimeMessage() {\n\t\treturn new SmartMimeMessage(getSession(), getDefaultEncoding(), getDefaultFileTypeMap());\n\t}", "summary_tokens": ["this", "implementation", "creates", "a", "smart", "mime", "message", "holding", "the", "specified", "default", "encoding", "and", "default", "file", "type", "map"], "project": "spring-framework"}
{"id": 3730, "code": "\tpublic void setFunction(boolean function) {\n\t\tthis.function = function;\n\t}", "summary_tokens": ["specify", "whether", "this", "call", "is", "a", "function", "call"], "project": "spring-framework"}
{"id": 9284, "code": "\tpublic void setCssErrorClass(String cssErrorClass) {\n\t\tthis.cssErrorClass = cssErrorClass;\n\t}", "summary_tokens": ["the", "css", "class", "to", "use", "when", "the", "field", "bound", "to", "a", "particular", "tag", "has", "errors"], "project": "spring-framework"}
{"id": 4791, "code": "\tstatic RSocketRequester wrap(\n\t\t\tRSocket rsocket, MimeType dataMimeType, MimeType metadataMimeType,\n\t\t\tRSocketStrategies strategies) {\n\n\t\treturn new DefaultRSocketRequester(null, rsocket, dataMimeType, metadataMimeType, strategies);\n\t}", "summary_tokens": ["wrap", "an", "existing", "rsocket"], "project": "spring-framework"}
{"id": 4013, "code": "\tpublic EmbeddedDatabaseBuilder setCommentPrefix(String commentPrefix) {\n\t\tthis.databasePopulator.setCommentPrefix(commentPrefix);\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "the", "single", "line", "comment", "prefix", "used", "in", "all", "sql", "scripts"], "project": "spring-framework"}
{"id": 4643, "code": "\tprivate KSerializer<Object> serializer(Type type) {\n\t\tKSerializer<Object> serializer = serializerCache.get(type);\n\t\tif (serializer == null) {\n\t\t\tserializer = SerializersKt.serializer(type);\n\t\t\tserializerCache.put(type, serializer);\n\t\t}\n\t\treturn serializer;\n\t}", "summary_tokens": ["tries", "to", "find", "a", "serializer", "that", "can", "marshall", "or", "unmarshall", "instances", "of", "the", "given", "type", "using", "kotlinx"], "project": "spring-framework"}
{"id": 9550, "code": "\tprotected void setResponseContentType(HttpServletRequest request, HttpServletResponse response) {\n\t\tMediaType mediaType = (MediaType) request.getAttribute(View.SELECTED_CONTENT_TYPE);\n\t\tif (mediaType != null && mediaType.isConcrete()) {\n\t\t\tresponse.setContentType(mediaType.toString());\n\t\t}\n\t\telse {\n\t\t\tresponse.setContentType(getContentType());\n\t\t}\n\t}", "summary_tokens": ["set", "the", "content", "type", "of", "the", "response", "to", "the", "configured", "set", "content", "type", "string", "content", "type", "unless", "the", "view", "selected", "content", "type", "request", "attribute", "is", "present", "and", "set", "to", "a", "concrete", "media", "type"], "project": "spring-framework"}
{"id": 7398, "code": "\tprotected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws IOException {\n\t\tString[] configLocations = getConfigLocations();\n\t\tif (configLocations != null) {\n\t\t\tfor (String configLocation : configLocations) {\n\t\t\t\treader.loadBeanDefinitions(configLocation);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["load", "the", "bean", "definitions", "with", "the", "given", "xml", "bean", "definition", "reader"], "project": "spring-framework"}
{"id": 3721, "code": "\tpublic Set<String> getLimitedInParameterNames() {\n\t\treturn this.limitedInParameterNames;\n\t}", "summary_tokens": ["get", "a", "limited", "set", "of", "in", "parameters", "to", "be", "used"], "project": "spring-framework"}
{"id": 6167, "code": "\tpublic void rootWacServletContainerAttributeNotPreviouslySetWithContextHierarchy() {\n\t\tStaticApplicationContext ear = new StaticApplicationContext();\n\t\tStaticWebApplicationContext root = new StaticWebApplicationContext();\n\t\troot.setParent(ear);\n\t\troot.setServletContext(this.servletContext);\n\t\tStaticWebApplicationContext dispatcher = new StaticWebApplicationContext();\n\t\tdispatcher.setParent(root);\n\t\tdispatcher.setServletContext(this.servletContext);\n\n\t\tDefaultMockMvcBuilder builder = webAppContextSetup(dispatcher);\n\t\tWebApplicationContext wac = builder.initWebAppContext();\n\n\t\tassertThat(wac).isSameAs(dispatcher);\n\t\tassertThat(wac.getParent()).isSameAs(root);\n\t\tassertThat(wac.getParent().getParent()).isSameAs(ear);\n\t\tassertThat(WebApplicationContextUtils.getRequiredWebApplicationContext(this.servletContext)).isSameAs(root);\n\t}", "summary_tokens": ["see", "spr", "0", "and", "spr", "0"], "project": "spring-framework"}
{"id": 875, "code": "\tprotected Method findMatchingMethod() {\n\t\tMethod matchingMethod = super.findMatchingMethod();\n\t\t\n\t\tif (matchingMethod == null) {\n\t\t\t\n\t\t\tmatchingMethod = doFindMatchingMethod(getArguments());\n\t\t}\n\t\tif (matchingMethod == null) {\n\t\t\t\n\t\t\tmatchingMethod = doFindMatchingMethod(new Object[] {getArguments()});\n\t\t}\n\t\treturn matchingMethod;\n\t}", "summary_tokens": ["this", "implementation", "looks", "for", "a", "method", "with", "matching", "parameter", "types"], "project": "spring-framework"}
{"id": 6708, "code": "\tpublic static HttpHeaders readOnlyHttpHeaders(HttpHeaders headers) {\n\t\tAssert.notNull(headers, \"HttpHeaders must not be null\");\n\t\treturn (headers instanceof ReadOnlyHttpHeaders ? headers : new ReadOnlyHttpHeaders(headers.headers));\n\t}", "summary_tokens": ["apply", "a", "read", "only", "http", "headers", "wrapper", "around", "the", "given", "headers", "if", "necessary"], "project": "spring-framework"}
{"id": 6847, "code": "\tprotected Flux<DataBuffer> processInput(Publisher<DataBuffer> input, ResolvableType elementType,\n\t\t\t\t@Nullable MimeType mimeType, @Nullable Map<String, Object> hints) {\n\n\t\treturn Flux.from(input);\n\t}", "summary_tokens": ["process", "the", "input", "publisher", "into", "a", "flux"], "project": "spring-framework"}
{"id": 1692, "code": "\tpublic static String[] getMethodSignature(Method method) {\n\t\tClass<?>[] types = method.getParameterTypes();\n\t\tString[] signature = new String[types.length];\n\t\tfor (int x = 0; x < types.length; x++) {\n\t\t\tsignature[x] = types[x].getName();\n\t\t}\n\t\treturn signature;\n\t}", "summary_tokens": ["create", "a", "string", "representing", "the", "argument", "signature", "of", "a", "method"], "project": "spring-framework"}
{"id": 4305, "code": "\tprotected ConnectionFactory getTargetConnectionFactory() {\n\t\tConnectionFactory target = this.targetConnectionFactory;\n\t\tAssert.state(target != null, \"'targetConnectionFactory' is required\");\n\t\treturn target;\n\t}", "summary_tokens": ["return", "the", "target", "connection", "factory", "that", "this", "connection", "factory", "should", "delegate", "to"], "project": "spring-framework"}
{"id": 3144, "code": "\tpublic static Class<?> determineCommonAncestor(@Nullable Class<?> clazz1, @Nullable Class<?> clazz2) {\n\t\tif (clazz1 == null) {\n\t\t\treturn clazz2;\n\t\t}\n\t\tif (clazz2 == null) {\n\t\t\treturn clazz1;\n\t\t}\n\t\tif (clazz1.isAssignableFrom(clazz2)) {\n\t\t\treturn clazz1;\n\t\t}\n\t\tif (clazz2.isAssignableFrom(clazz1)) {\n\t\t\treturn clazz2;\n\t\t}\n\t\tClass<?> ancestor = clazz1;\n\t\tdo {\n\t\t\tancestor = ancestor.getSuperclass();\n\t\t\tif (ancestor == null || Object.class == ancestor) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\twhile (!ancestor.isAssignableFrom(clazz2));\n\t\treturn ancestor;\n\t}", "summary_tokens": ["determine", "the", "common", "ancestor", "of", "the", "given", "classes", "if", "any"], "project": "spring-framework"}
{"id": 9282, "code": "\tpublic void setCssClass(String cssClass) {\n\t\tthis.cssClass = cssClass;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "class", "attribute"], "project": "spring-framework"}
{"id": 5964, "code": "\tpublic ResultMatcher encoding(String characterEncoding) {\n\t\treturn result -> {\n\t\t\tString actual = result.getResponse().getCharacterEncoding();\n\t\t\tassertEquals(\"Character encoding\", characterEncoding, actual);\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "character", "encoding", "in", "the", "servlet", "response"], "project": "spring-framework"}
{"id": 1635, "code": "\tpublic void setMethodMappings(Properties mappings) {\n\t\tthis.methodMappings = new HashMap<>();\n\t\tfor (Enumeration<?> en = mappings.keys(); en.hasMoreElements();) {\n\t\t\tString beanKey = (String) en.nextElement();\n\t\t\tString[] methodNames = StringUtils.commaDelimitedListToStringArray(mappings.getProperty(beanKey));\n\t\t\tthis.methodMappings.put(beanKey, Set.of(methodNames));\n\t\t}\n\t}", "summary_tokens": ["set", "the", "mappings", "of", "bean", "keys", "to", "a", "comma", "separated", "list", "of", "method", "names"], "project": "spring-framework"}
{"id": 2788, "code": "\tvoid validate(Annotation annotation) {\n\t\tassertAnnotation(annotation);\n\t\tfor (int i = 0; i < size(); i++) {\n\t\t\tif (canThrowTypeNotPresentException(i)) {\n\t\t\t\ttry {\n\t\t\t\t\tget(i).invoke(annotation);\n\t\t\t\t}\n\t\t\t\tcatch (Throwable ex) {\n\t\t\t\t\tthrow new IllegalStateException(\"Could not obtain annotation attribute value for \" +\n\t\t\t\t\t\t\tget(i).getName() + \" declared on \" + annotation.annotationType(), ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["check", "if", "values", "from", "the", "given", "annotation", "can", "be", "safely", "accessed", "without", "causing", "any", "type", "not", "present", "exception", "type", "not", "present", "exceptions"], "project": "spring-framework"}
{"id": 4540, "code": "\tpublic void setDestinationResolver(DestinationResolver destinationResolver) {\n\t\tDefaultJmsActivationSpecFactory factory = new DefaultJmsActivationSpecFactory();\n\t\tfactory.setDestinationResolver(destinationResolver);\n\t\tthis.activationSpecFactory = factory;\n\t}", "summary_tokens": ["set", "the", "destination", "resolver", "to", "use", "for", "resolving", "destination", "names", "into", "the", "jca", "0"], "project": "spring-framework"}
{"id": 8979, "code": "\tpublic static MvcUriComponentsBuilder relativeTo(UriComponentsBuilder baseUrl) {\n\t\treturn new MvcUriComponentsBuilder(baseUrl);\n\t}", "summary_tokens": ["create", "an", "instance", "of", "this", "class", "with", "a", "base", "url"], "project": "spring-framework"}
{"id": 9479, "code": "\tpublic void writeOptionalAttributeValue(String attributeName, @Nullable String attributeValue) throws JspException {\n\t\tif (StringUtils.hasText(attributeValue)) {\n\t\t\twriteAttribute(attributeName, attributeValue);\n\t\t}\n\t}", "summary_tokens": ["write", "an", "html", "attribute", "if", "the", "supplied", "value", "is", "not", "null", "or", "zero", "length"], "project": "spring-framework"}
{"id": 9528, "code": "\tpublic String getRequestContextAttribute() {\n\t\treturn this.requestContextAttribute;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "request", "context", "attribute", "if", "any"], "project": "spring-framework"}
{"id": 8969, "code": "\tpublic void setResponseBodyAdvice(@Nullable List<ResponseBodyAdvice<?>> responseBodyAdvice) {\n\t\tif (responseBodyAdvice != null) {\n\t\t\tthis.responseBodyAdvice.addAll(responseBodyAdvice);\n\t\t}\n\t}", "summary_tokens": ["add", "one", "or", "more", "components", "to", "be", "invoked", "after", "the", "execution", "of", "a", "controller", "method", "annotated", "with", "or", "returning", "response", "entity", "but", "before", "the", "body", "is", "written", "to", "the", "response", "with", "the", "selected", "http", "message", "converter"], "project": "spring-framework"}
{"id": 4599, "code": "\tprotected Serializable extractSerializableFromMessage(ObjectMessage message) throws JMSException {\n\t\treturn message.getObject();\n\t}", "summary_tokens": ["extract", "a", "serializable", "object", "from", "the", "given", "object", "message"], "project": "spring-framework"}
{"id": 4184, "code": "\tprotected long getNextKey() throws DataAccessException {\n\t\tConnection con = DataSourceUtils.getConnection(getDataSource());\n\t\tStatement stmt = null;\n\t\tResultSet rs = null;\n\t\ttry {\n\t\t\tstmt = con.createStatement();\n\t\t\tDataSourceUtils.applyTransactionTimeout(stmt, getDataSource());\n\t\t\trs = stmt.executeQuery(getSequenceQuery());\n\t\t\tif (rs.next()) {\n\t\t\t\treturn rs.getLong(1);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new DataAccessResourceFailureException(\"Sequence query did not return a result\");\n\t\t\t}\n\t\t}\n\t\tcatch (SQLException ex) {\n\t\t\tthrow new DataAccessResourceFailureException(\"Could not obtain sequence value\", ex);\n\t\t}\n\t\tfinally {\n\t\t\tJdbcUtils.closeResultSet(rs);\n\t\t\tJdbcUtils.closeStatement(stmt);\n\t\t\tDataSourceUtils.releaseConnection(con, getDataSource());\n\t\t}\n\t}", "summary_tokens": ["executes", "the", "sql", "as", "specified", "by", "get", "sequence", "query"], "project": "spring-framework"}
{"id": 2206, "code": "\tpublic ResourceFile getSingle() throws IllegalStateException {\n\t\treturn this.files.getSingle();\n\t}", "summary_tokens": ["return", "the", "single", "source", "file", "contained", "in", "the", "collection"], "project": "spring-framework"}
{"id": 7622, "code": "\tpublic void setBinding(String attributeName, boolean enabled) {\n\t\tif (!enabled) {\n\t\t\tthis.noBinding.add(attributeName);\n\t\t}\n\t\telse {\n\t\t\tthis.noBinding.remove(attributeName);\n\t\t}\n\t}", "summary_tokens": ["register", "whether", "data", "binding", "should", "occur", "for", "a", "corresponding", "model", "attribute", "corresponding", "to", "an", "binding", "true", "false", "declaration"], "project": "spring-framework"}
{"id": 2725, "code": "\tpublic void addDiscoverer(ParameterNameDiscoverer pnd) {\n\t\tthis.parameterNameDiscoverers.add(pnd);\n\t}", "summary_tokens": ["add", "a", "further", "parameter", "name", "discoverer", "delegate", "to", "the", "list", "of", "discoverers", "that", "this", "prioritized", "parameter", "name", "discoverer", "checks"], "project": "spring-framework"}
{"id": 3973, "code": "\tprotected Integer defaultTransactionIsolation() {\n\t\treturn this.defaultTransactionIsolation;\n\t}", "summary_tokens": ["expose", "the", "default", "transaction", "isolation", "value"], "project": "spring-framework"}
{"id": 8944, "code": "\tprotected void validateIfApplicable(WebDataBinder binder, MethodParameter parameter) {\n\t\tAnnotation[] annotations = parameter.getParameterAnnotations();\n\t\tfor (Annotation ann : annotations) {\n\t\t\tObject[] validationHints = ValidationAnnotationUtils.determineValidationHints(ann);\n\t\t\tif (validationHints != null) {\n\t\t\t\tbinder.validate(validationHints);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["validate", "the", "binding", "target", "if", "applicable"], "project": "spring-framework"}
{"id": 8008, "code": "\tpublic boolean hasMappingForPattern(String pathPattern) {\n\t\tfor (ResourceHandlerRegistration registration : this.registrations) {\n\t\t\tif (Arrays.asList(registration.getPathPatterns()).contains(pathPattern)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["whether", "a", "resource", "handler", "has", "already", "been", "registered", "for", "the", "given", "path", "pattern"], "project": "spring-framework"}
{"id": 2685, "code": "\tpublic static boolean isVisibilityBridgeMethodPair(Method bridgeMethod, Method bridgedMethod) {\n\t\tif (bridgeMethod == bridgedMethod) {\n\t\t\treturn true;\n\t\t}\n\t\treturn (bridgeMethod.getReturnType().equals(bridgedMethod.getReturnType()) &&\n\t\t\t\tbridgeMethod.getParameterCount() == bridgedMethod.getParameterCount() &&\n\t\t\t\tArrays.equals(bridgeMethod.getParameterTypes(), bridgedMethod.getParameterTypes()));\n\t}", "summary_tokens": ["compare", "the", "signatures", "of", "the", "bridge", "method", "and", "the", "method", "which", "it", "bridges"], "project": "spring-framework"}
{"id": 4829, "code": "\tpublic String getSessionId() {\n\t\treturn (String) getHeader(SESSION_ID_HEADER);\n\t}", "summary_tokens": ["return", "the", "id", "of", "the", "current", "session"], "project": "spring-framework"}
{"id": 1504, "code": "\tpublic static boolean isInstrumentationAvailable() {\n\t\treturn (getInstrumentation() != null);\n\t}", "summary_tokens": ["check", "whether", "an", "instrumentation", "instance", "is", "available", "for", "the", "current", "vm"], "project": "spring-framework"}
{"id": 1368, "code": "\tpublic void setBasename(String basename) {\n\t\tsetBasenames(basename);\n\t}", "summary_tokens": ["set", "a", "single", "basename", "following", "the", "basic", "resource", "bundle", "convention", "of", "not", "specifying", "file", "extension", "or", "language", "codes"], "project": "spring-framework"}
{"id": 1035, "code": "\tpublic FileTypeMap getDefaultFileTypeMap() {\n\t\treturn this.defaultFileTypeMap;\n\t}", "summary_tokens": ["return", "the", "default", "java", "activation", "file", "type", "map", "for", "mime", "message", "mime", "messages", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 5669, "code": "\tpublic void beforeTestClass(TestContext testContext) throws Exception {\n\t\t\n\t}", "summary_tokens": ["the", "default", "implementation", "is", "em", "empty", "em"], "project": "spring-framework"}
{"id": 2459, "code": "final void markSubroutine(final short subroutineId) {\n    \n    \n    \n    \n  Label listOfBlocksToProcess = this;\n  listOfBlocksToProcess.nextListElement = EMPTY_LIST;\n  while (listOfBlocksToProcess != EMPTY_LIST) {\n      \n    Label basicBlock = listOfBlocksToProcess;\n    listOfBlocksToProcess = listOfBlocksToProcess.nextListElement;\n    basicBlock.nextListElement = null;\n\n      \n      \n    if (basicBlock.subroutineId == 0) {\n      basicBlock.subroutineId = subroutineId;\n      listOfBlocksToProcess = basicBlock.pushSuccessors(listOfBlocksToProcess);\n    }\n  }\n}", "summary_tokens": ["finds", "the", "basic", "blocks", "that", "belong", "to", "the", "subroutine", "starting", "with", "the", "basic", "block", "corresponding", "to", "this", "label", "and", "marks", "these", "blocks", "as", "belonging", "to", "this", "subroutine"], "project": "spring-framework"}
{"id": 2703, "code": "\tpublic String propertyToConstantNamePrefix(String propertyName) {\n\t\tStringBuilder parsedPrefix = new StringBuilder();\n\t\tfor (int i = 0; i < propertyName.length(); i++) {\n\t\t\tchar c = propertyName.charAt(i);\n\t\t\tif (Character.isUpperCase(c)) {\n\t\t\t\tparsedPrefix.append('_');\n\t\t\t\tparsedPrefix.append(c);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tparsedPrefix.append(Character.toUpperCase(c));\n\t\t\t}\n\t\t}\n\t\treturn parsedPrefix.toString();\n\t}", "summary_tokens": ["convert", "the", "given", "bean", "property", "name", "to", "a", "constant", "name", "prefix"], "project": "spring-framework"}
{"id": 2422, "code": "public void visitAttribute(final Attribute attribute) {\n  if (fv != null) {\n    fv.visitAttribute(attribute);\n  }\n}", "summary_tokens": ["visits", "a", "non", "standard", "attribute", "of", "the", "field"], "project": "spring-framework"}
{"id": 2086, "code": "\tprivate Object testPrototypeInstancesAreIndependent(String beanName) {\n\t\t\n\t\tint INITIAL_COUNT = 10;\n\n\t\tDefaultListableBeanFactory bf = new DefaultListableBeanFactory();\n\t\tnew XmlBeanDefinitionReader(bf).loadBeanDefinitions(new ClassPathResource(PROTOTYPE_CONTEXT, CLASS));\n\n\t\t\n\t\tSideEffectBean raw = (SideEffectBean) bf.getBean(\"prototypeTarget\");\n\t\tassertThat(raw.getCount()).isEqualTo(INITIAL_COUNT);\n\t\traw.doWork();\n\t\tassertThat(raw.getCount()).isEqualTo(INITIAL_COUNT+1);\n\t\traw = (SideEffectBean) bf.getBean(\"prototypeTarget\");\n\t\tassertThat(raw.getCount()).isEqualTo(INITIAL_COUNT);\n\n\t\t\n\t\tSideEffectBean prototype2FirstInstance = (SideEffectBean) bf.getBean(beanName);\n\t\tassertThat(prototype2FirstInstance.getCount()).isEqualTo(INITIAL_COUNT);\n\t\tprototype2FirstInstance.doWork();\n\t\tassertThat(prototype2FirstInstance.getCount()).isEqualTo(INITIAL_COUNT + 1);\n\n\t\tSideEffectBean prototype2SecondInstance = (SideEffectBean) bf.getBean(beanName);\n\t\tassertThat(prototype2FirstInstance == prototype2SecondInstance).as(\"Prototypes are not ==\").isFalse();\n\t\tassertThat(prototype2SecondInstance.getCount()).isEqualTo(INITIAL_COUNT);\n\t\tassertThat(prototype2FirstInstance.getCount()).isEqualTo(INITIAL_COUNT + 1);\n\n\t\treturn prototype2FirstInstance;\n\t}", "summary_tokens": ["uses", "its", "own", "bean", "factory", "xml", "for", "clarity", "bean", "name", "name", "of", "the", "proxy", "factory", "bean", "definition", "that", "should", "be", "a", "prototype"], "project": "spring-framework"}
{"id": 2763, "code": "\tpublic static boolean getFlag(String key) {\n\t\treturn Boolean.parseBoolean(getProperty(key));\n\t}", "summary_tokens": ["retrieve", "the", "flag", "for", "the", "given", "property", "key"], "project": "spring-framework"}
{"id": 6310, "code": "\tpublic void setTransactionSynchronizationRegistryName(String transactionSynchronizationRegistryName) {\n\t\tthis.transactionSynchronizationRegistryName = transactionSynchronizationRegistryName;\n\t}", "summary_tokens": ["set", "the", "jndi", "name", "of", "the", "jta", "0"], "project": "spring-framework"}
{"id": 2377, "code": "public String getClassName() {\n  return className;\n}", "summary_tokens": ["returns", "the", "internal", "name", "of", "the", "class"], "project": "spring-framework"}
{"id": 3735, "code": "\tpublic boolean isAccessCallParameterMetaData() {\n\t\treturn this.accessCallParameterMetaData;\n\t}", "summary_tokens": ["check", "whether", "call", "parameter", "meta", "data", "should", "be", "accessed"], "project": "spring-framework"}
{"id": 5856, "code": "\tpublic static DefaultResponseCreator withNoContent() {\n\t\treturn new DefaultResponseCreator(HttpStatus.NO_CONTENT);\n\t}", "summary_tokens": ["response", "creator", "for", "a", "0", "response", "no", "content"], "project": "spring-framework"}
{"id": 9894, "code": "\tpublic RestOperations getRestTemplate() {\n\t\treturn this.restTemplate;\n\t}", "summary_tokens": ["return", "the", "configured", "rest", "template"], "project": "spring-framework"}
{"id": 671, "code": "\tpublic int hashCode() {\n\t\treturn this.beanDefinition.hashCode();\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "hash", "code", "of", "the", "underlying", "bean", "definition"], "project": "spring-framework"}
{"id": 5050, "code": "\tpublic void setInboundPrefix(@Nullable String inboundPrefix) {\n\t\tthis.inboundPrefix = (inboundPrefix != null ? inboundPrefix : \"\");\n\t}", "summary_tokens": ["specify", "a", "prefix", "to", "be", "appended", "to", "the", "message", "header", "name", "for", "any", "user", "defined", "property", "that", "is", "being", "mapped", "into", "the", "message", "headers"], "project": "spring-framework"}
{"id": 3128, "code": "\tpublic static boolean isPrimitiveOrWrapper(Class<?> clazz) {\n\t\tAssert.notNull(clazz, \"Class must not be null\");\n\t\treturn (clazz.isPrimitive() || isPrimitiveWrapper(clazz));\n\t}", "summary_tokens": ["check", "if", "the", "given", "class", "represents", "a", "primitive", "i"], "project": "spring-framework"}
{"id": 2102, "code": "\tvoid initializingBeanAndInitMethod() {\n\t\tInitAndIB.constructed = false;\n\t\tDefaultListableBeanFactory xbf = new DefaultListableBeanFactory();\n\t\tnew XmlBeanDefinitionReader(xbf).loadBeanDefinitions(INITIALIZERS_CONTEXT);\n\t\tassertThat(InitAndIB.constructed).isFalse();\n\t\txbf.preInstantiateSingletons();\n\t\tassertThat(InitAndIB.constructed).isFalse();\n\t\tInitAndIB iib = (InitAndIB) xbf.getBean(\"init-and-ib\");\n\t\tassertThat(InitAndIB.constructed).isTrue();\n\t\tassertThat(iib.afterPropertiesSetInvoked && iib.initMethodInvoked).isTrue();\n\t\tassertThat(!iib.destroyed && !iib.customDestroyed).isTrue();\n\t\txbf.destroySingletons();\n\t\tassertThat(iib.destroyed && iib.customDestroyed).isTrue();\n\t\txbf.destroySingletons();\n\t\tassertThat(iib.destroyed && iib.customDestroyed).isTrue();\n\t}", "summary_tokens": ["check", "that", "initializing", "bean", "method", "is", "called", "first"], "project": "spring-framework"}
{"id": 7827, "code": "\tpublic boolean matches(@Nullable String uri) {\n\t\tif (uri == null) {\n\t\t\treturn false;\n\t\t}\n\t\tMatcher matcher = this.matchPattern.matcher(uri);\n\t\treturn matcher.matches();\n\t}", "summary_tokens": ["indicate", "whether", "the", "given", "uri", "matches", "this", "template"], "project": "spring-framework"}
{"id": 6816, "code": "\tprotected Map<String, Object> getReadHints(ResolvableType actualType,\n\t\t\tResolvableType elementType, ServerHttpRequest request, ServerHttpResponse response) {\n\n\t\tif (this.decoder instanceof HttpMessageDecoder) {\n\t\t\tHttpMessageDecoder<?> decoder = (HttpMessageDecoder<?>) this.decoder;\n\t\t\treturn decoder.getDecodeHints(actualType, elementType, request, response);\n\t\t}\n\t\treturn Hints.none();\n\t}", "summary_tokens": ["get", "additional", "hints", "for", "decoding", "for", "example", "based", "on", "the", "server", "request", "or", "annotations", "from", "controller", "method", "parameters"], "project": "spring-framework"}
{"id": 5302, "code": "\tpublic void testDoesNotTranslateUnfamiliarException() {\n\t\tUnsupportedOperationException userRuntimeException = new UnsupportedOperationException();\n\t\tassertThat(EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(userRuntimeException)).as(\"Exception should not be wrapped\").isNull();\n\t}", "summary_tokens": ["we", "do", "not", "convert", "unknown", "exceptions"], "project": "spring-framework"}
{"id": 3276, "code": "\tpublic void start(String taskName) throws IllegalStateException {\n\t\tif (this.currentTaskName != null) {\n\t\t\tthrow new IllegalStateException(\"Can't start StopWatch: it's already running\");\n\t\t}\n\t\tthis.currentTaskName = taskName;\n\t\tthis.startTimeNanos = System.nanoTime();\n\t}", "summary_tokens": ["start", "a", "named", "task"], "project": "spring-framework"}
{"id": 8197, "code": "\tpublic Cache getCache() {\n\t\treturn this.cache;\n\t}", "summary_tokens": ["return", "the", "configured", "cache"], "project": "spring-framework"}
{"id": 9802, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "for", "the", "resulting", "org"], "project": "spring-framework"}
{"id": 3284, "code": "\tpublic long getTotalTimeNanos() {\n\t\treturn this.totalTimeNanos;\n\t}", "summary_tokens": ["get", "the", "total", "time", "in", "nanoseconds", "for", "all", "tasks"], "project": "spring-framework"}
{"id": 2620, "code": "\tpublic void setStrategy(GeneratorStrategy strategy) {\n\t\tif (strategy == null)\n\t\t\tstrategy = DefaultGeneratorStrategy.INSTANCE;\n\t\tthis.strategy = strategy;\n\t}", "summary_tokens": ["set", "the", "strategy", "to", "use", "to", "create", "the", "bytecode", "from", "this", "generator"], "project": "spring-framework"}
{"id": 2672, "code": "public static ParallelSorter create(Object[] arrays) {\n    Generator gen = new Generator();\n    gen.setArrays(arrays);\n    return gen.create();\n}", "summary_tokens": ["create", "a", "new", "parallel", "sorter", "object", "for", "a", "set", "of", "arrays"], "project": "spring-framework"}
{"id": 8867, "code": "\tpublic void setSuffix(@Nullable String suffix) {\n\t\tthis.suffix = (suffix != null ? suffix : \"\");\n\t}", "summary_tokens": ["set", "the", "suffix", "to", "append", "to", "the", "request", "url", "filename", "to", "build", "a", "view", "name"], "project": "spring-framework"}
{"id": 4412, "code": "\tpublic boolean isReplyPubSubDomain() {\n\t\tif (this.replyPubSubDomain != null) {\n\t\t\treturn this.replyPubSubDomain;\n\t\t}\n\t\telse {\n\t\t\treturn isPubSubDomain();\n\t\t}\n\t}", "summary_tokens": ["return", "whether", "the", "publish", "subscribe", "domain", "jakarta"], "project": "spring-framework"}
{"id": 594, "code": "\tpublic String getMessage() {\n\t\treturn this.message;\n\t}", "summary_tokens": ["get", "the", "message", "detailing", "the", "problem"], "project": "spring-framework"}
{"id": 6316, "code": "\tprotected void initTransactionSynchronizationRegistry() {\n\t\tif (this.transactionSynchronizationRegistry == null) {\n\t\t\t\n\t\t\tif (StringUtils.hasLength(this.transactionSynchronizationRegistryName)) {\n\t\t\t\tthis.transactionSynchronizationRegistry =\n\t\t\t\t\t\tlookupTransactionSynchronizationRegistry(this.transactionSynchronizationRegistryName);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.transactionSynchronizationRegistry = retrieveTransactionSynchronizationRegistry();\n\t\t\t\tif (this.transactionSynchronizationRegistry == null && this.autodetectTransactionSynchronizationRegistry) {\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tthis.transactionSynchronizationRegistry =\n\t\t\t\t\t\t\tfindTransactionSynchronizationRegistry(this.userTransaction, this.transactionManager);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (this.transactionSynchronizationRegistry != null) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Using JTA TransactionSynchronizationRegistry: \" + this.transactionSynchronizationRegistry);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "jta", "0"], "project": "spring-framework"}
{"id": 1585, "code": "\tprotected boolean isUseStrictCasing() {\n\t\treturn this.useStrictCasing;\n\t}", "summary_tokens": ["return", "whether", "strict", "casing", "for", "attributes", "is", "enabled"], "project": "spring-framework"}
{"id": 6238, "code": "\tdefault String getListenerId() {\n\t\treturn \"\";\n\t}", "summary_tokens": ["return", "an", "identifier", "for", "the", "listener", "to", "be", "able", "to", "refer", "to", "it", "individually"], "project": "spring-framework"}
{"id": 5165, "code": "\tpublic void setPackagesToScan(String... packagesToScan) {\n\t\tthis.packagesToScan = packagesToScan;\n\t}", "summary_tokens": ["specify", "packages", "to", "search", "for", "autodetection", "of", "your", "entity", "classes", "in", "the", "classpath"], "project": "spring-framework"}
{"id": 3642, "code": "\tprivate void checkMatch2(Class<?>[] inputTypes, Class<?>[] expectedTypes, StandardTypeConverter typeConverter, ArgumentsMatchKind expectedMatchKind) {\n\t\tReflectionHelper.ArgumentsMatchInfo matchInfo = ReflectionHelper.compareArgumentsVarargs(getTypeDescriptors(expectedTypes), getTypeDescriptors(inputTypes), typeConverter);\n\t\tif (expectedMatchKind == null) {\n\t\t\tassertThat(matchInfo).as(\"Did not expect them to match in any way: \" + matchInfo).isNull();\n\t\t}\n\t\telse {\n\t\t\tassertThat(matchInfo).as(\"Should not be a null match\").isNotNull();\n\t\t}\n\n\t\tif (expectedMatchKind == ArgumentsMatchKind.EXACT) {\n\t\t\tassertThat(matchInfo.isExactMatch()).isTrue();\n\t\t}\n\t\telse if (expectedMatchKind == ArgumentsMatchKind.CLOSE) {\n\t\t\tassertThat(matchInfo.isCloseMatch()).isTrue();\n\t\t}\n\t\telse if (expectedMatchKind == ArgumentsMatchKind.REQUIRES_CONVERSION) {\n\t\t\tassertThat(matchInfo.isMatchRequiringConversion()).as(\"expected to be a match requiring conversion, but was \" + matchInfo).isTrue();\n\t\t}\n\t}", "summary_tokens": ["used", "to", "validate", "the", "match", "returned", "from", "a", "compare", "arguments", "call"], "project": "spring-framework"}
{"id": 8156, "code": "\tdefault Optional<String> queryParam(String name) {\n\t\tList<String> queryParamValues = queryParams().get(name);\n\t\tif (CollectionUtils.isEmpty(queryParamValues)) {\n\t\t\treturn Optional.empty();\n\t\t}\n\t\telse {\n\t\t\tString value = queryParamValues.get(0);\n\t\t\tif (value == null) {\n\t\t\t\tvalue = \"\";\n\t\t\t}\n\t\t\treturn Optional.of(value);\n\t\t}\n\t}", "summary_tokens": ["get", "the", "first", "query", "parameter", "with", "the", "given", "name", "if", "present"], "project": "spring-framework"}
{"id": 2419, "code": "void execute(\n    final int opcode, final int arg, final Symbol symbolArg, final SymbolTable symbolTable) {\n  super.execute(opcode, arg, symbolArg, symbolTable);\n  Frame successor = new Frame(null);\n  merge(symbolTable, successor, 0);\n  copyFrom(successor);\n}", "summary_tokens": ["sets", "this", "current", "frame", "to", "the", "input", "stack", "map", "frame", "of", "the", "next", "current", "instruction", "i"], "project": "spring-framework"}
{"id": 9597, "code": "\tpublic void setBasenames(String... basenames) {\n\t\tthis.basenames = basenames;\n\t}", "summary_tokens": ["set", "an", "array", "of", "basenames", "each", "following", "java"], "project": "spring-framework"}
{"id": 2860, "code": "\tpublic void setPlaceholderPrefix(String placeholderPrefix) {\n\t\tAssert.notNull(placeholderPrefix, \"'placeholderPrefix' must not be null\");\n\t\tthis.placeholderPrefix = placeholderPrefix;\n\t}", "summary_tokens": ["set", "the", "prefix", "that", "placeholders", "replaced", "by", "this", "resolver", "must", "begin", "with"], "project": "spring-framework"}
{"id": 766, "code": "\tpublic void registerExternallyManagedDestroyMethod(String destroyMethod) {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\tif (this.externallyManagedDestroyMethods == null) {\n\t\t\t\tthis.externallyManagedDestroyMethods = new LinkedHashSet<>(1);\n\t\t\t}\n\t\t\tthis.externallyManagedDestroyMethods.add(destroyMethod);\n\t\t}\n\t}", "summary_tokens": ["register", "an", "externally", "managed", "configuration", "destruction", "method", "mdash", "for", "example", "a", "method", "annotated", "with", "jsr", "0", "s", "jakarta"], "project": "spring-framework"}
{"id": 3041, "code": "\tpublic String toString() {\n\t\tif (this.result == null) {\n\t\t\tthis.result = buildString();\n\t\t}\n\t\treturn this.result;\n\t}", "summary_tokens": ["this", "will", "be", "called", "by", "the", "logging", "provider", "potentially", "once", "per", "log", "target", "therefore", "locally", "caching", "the", "result", "here"], "project": "spring-framework"}
{"id": 5433, "code": "\tprotected String getInsertIntoLegosetStatement() {\n\t\treturn \"INSERT INTO legoset (id, name, manual) VALUES(:id, :name, :manual)\";\n\t}", "summary_tokens": ["get", "a", "parameterized", "insert", "into", "legoset", "statement", "setting", "id", "name", "and", "manual", "values"], "project": "spring-framework"}
{"id": 247, "code": "\tpublic synchronized Class<?> getTargetClass() {\n\t\treturn (this.lazyTarget != null ? this.lazyTarget.getClass() : null);\n\t}", "summary_tokens": ["this", "default", "implementation", "returns", "null", "if", "the", "target", "is", "null", "it", "is", "hasn", "t", "yet", "been", "initialized", "or", "the", "target", "class", "if", "the", "target", "has", "already", "been", "initialized"], "project": "spring-framework"}
{"id": 2901, "code": "\tpublic boolean containsProperty(String name) {\n\t\treturn (getProperty(name) != null);\n\t}", "summary_tokens": ["return", "true", "if", "a", "property", "with", "the", "given", "name", "or", "any", "underscore", "uppercase", "variant", "thereof", "exists", "in", "this", "property", "source"], "project": "spring-framework"}
{"id": 4505, "code": "\tpublic void onException(JMSException ex) {\n\t\t\n\t\tinvokeExceptionListener(ex);\n\n\t\t\n\t\tif (this.recoverOnException) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Trying to recover from JMS Connection exception: \" + ex);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tsynchronized (this.consumersMonitor) {\n\t\t\t\t\tthis.sessions = null;\n\t\t\t\t\tthis.consumers = null;\n\t\t\t\t}\n\t\t\t\trefreshSharedConnection();\n\t\t\t\tinitializeConsumers();\n\t\t\t\tlogger.debug(\"Successfully refreshed JMS Connection\");\n\t\t\t}\n\t\t\tcatch (JMSException recoverEx) {\n\t\t\t\tlogger.debug(\"Failed to recover JMS Connection\", recoverEx);\n\t\t\t\tlogger.error(\"Encountered non-recoverable JMSException\", ex);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["jms", "exception", "listener", "implementation", "invoked", "by", "the", "jms", "provider", "in", "case", "of", "connection", "failures"], "project": "spring-framework"}
{"id": 6254, "code": "\tpublic void setQualifier(@Nullable String qualifier) {\n\t\tthis.qualifier = qualifier;\n\t}", "summary_tokens": ["associate", "a", "qualifier", "value", "with", "this", "transaction", "attribute"], "project": "spring-framework"}
{"id": 5137, "code": "\tprotected <T> T doExecute(HibernateCallback<T> action, boolean enforceNativeSession) throws DataAccessException {\n\t\tAssert.notNull(action, \"Callback object must not be null\");\n\n\t\tSession session = null;\n\t\tboolean isNew = false;\n\t\ttry {\n\t\t\tsession = obtainSessionFactory().getCurrentSession();\n\t\t}\n\t\tcatch (HibernateException ex) {\n\t\t\tlogger.debug(\"Could not retrieve pre-bound Hibernate session\", ex);\n\t\t}\n\t\tif (session == null) {\n\t\t\tsession = obtainSessionFactory().openSession();\n\t\t\tsession.setHibernateFlushMode(FlushMode.MANUAL);\n\t\t\tisNew = true;\n\t\t}\n\n\t\ttry {\n\t\t\tenableFilters(session);\n\t\t\tSession sessionToExpose =\n\t\t\t\t\t(enforceNativeSession || isExposeNativeSession() ? session : createSessionProxy(session));\n\t\t\treturn action.doInHibernate(sessionToExpose);\n\t\t}\n\t\tcatch (HibernateException ex) {\n\t\t\tthrow SessionFactoryUtils.convertHibernateAccessException(ex);\n\t\t}\n\t\tcatch (PersistenceException ex) {\n\t\t\tif (ex.getCause() instanceof HibernateException) {\n\t\t\t\tthrow SessionFactoryUtils.convertHibernateAccessException((HibernateException) ex.getCause());\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t\tcatch (RuntimeException ex) {\n\t\t\t\n\t\t\tthrow ex;\n\t\t}\n\t\tfinally {\n\t\t\tif (isNew) {\n\t\t\t\tSessionFactoryUtils.closeSession(session);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tdisableFilters(session);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["execute", "the", "action", "specified", "by", "the", "given", "action", "object", "within", "a", "session"], "project": "spring-framework"}
{"id": 7139, "code": "\tpublic void setUseJaf(boolean useJaf) {\n\t\tsetUseRegisteredExtensionsOnly(!useJaf);\n\t}", "summary_tokens": ["indicate", "whether", "to", "use", "the", "java", "activation", "framework", "as", "a", "fallback", "option", "to", "map", "from", "file", "extensions", "to", "media", "types"], "project": "spring-framework"}
{"id": 8918, "code": "\tpublic int compareTo(ProducesRequestCondition other, HttpServletRequest request) {\n\t\ttry {\n\t\t\tList<MediaType> acceptedMediaTypes = getAcceptedMediaTypes(request);\n\t\t\tfor (MediaType acceptedMediaType : acceptedMediaTypes) {\n\t\t\t\tint thisIndex = this.indexOfEqualMediaType(acceptedMediaType);\n\t\t\t\tint otherIndex = other.indexOfEqualMediaType(acceptedMediaType);\n\t\t\t\tint result = compareMatchingMediaTypes(this, thisIndex, other, otherIndex);\n\t\t\t\tif (result != 0) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t\tthisIndex = this.indexOfIncludedMediaType(acceptedMediaType);\n\t\t\t\totherIndex = other.indexOfIncludedMediaType(acceptedMediaType);\n\t\t\t\tresult = compareMatchingMediaTypes(this, thisIndex, other, otherIndex);\n\t\t\t\tif (result != 0) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t\tcatch (HttpMediaTypeNotAcceptableException ex) {\n\t\t\t\n\t\t\tthrow new IllegalStateException(\"Cannot compare without having any requested media types\", ex);\n\t\t}\n\t}", "summary_tokens": ["compares", "this", "and", "another", "produces", "condition", "as", "follows", "ol", "li", "sort", "accept", "header", "media", "types", "by", "quality", "value", "via", "org"], "project": "spring-framework"}
{"id": 3264, "code": "\tpublic static boolean isJarURL(URL url) {\n\t\tString protocol = url.getProtocol();\n\t\treturn (URL_PROTOCOL_JAR.equals(protocol) || URL_PROTOCOL_WAR.equals(protocol) ||\n\t\t\t\tURL_PROTOCOL_ZIP.equals(protocol) || URL_PROTOCOL_VFSZIP.equals(protocol) ||\n\t\t\t\tURL_PROTOCOL_WSJAR.equals(protocol));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "url", "points", "to", "a", "resource", "in", "a", "jar", "file"], "project": "spring-framework"}
{"id": 4343, "code": "\tpublic long getTimeToLive() {\n\t\treturn this.timeToLive;\n\t}", "summary_tokens": ["return", "the", "time", "to", "live", "of", "the", "message", "when", "sending"], "project": "spring-framework"}
{"id": 6694, "code": "\tpublic List<String> getVary() {\n\t\treturn getValuesAsList(VARY);\n\t}", "summary_tokens": ["return", "the", "request", "header", "names", "subject", "to", "content", "negotiation"], "project": "spring-framework"}
{"id": 801, "code": "\tpublic Document loadDocument(InputSource inputSource, EntityResolver entityResolver,\n\t\t\tErrorHandler errorHandler, int validationMode, boolean namespaceAware) throws Exception {\n\n\t\tDocumentBuilderFactory factory = createDocumentBuilderFactory(validationMode, namespaceAware);\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"Using JAXP provider [\" + factory.getClass().getName() + \"]\");\n\t\t}\n\t\tDocumentBuilder builder = createDocumentBuilder(factory, entityResolver, errorHandler);\n\t\treturn builder.parse(inputSource);\n\t}", "summary_tokens": ["load", "the", "document", "at", "the", "supplied", "input", "source", "using", "the", "standard", "jaxp", "configured", "xml", "parser"], "project": "spring-framework"}
{"id": 9191, "code": "\tpublic boolean isIgnoreNestedPath() {\n\t\treturn this.ignoreNestedPath;\n\t}", "summary_tokens": ["return", "whether", "to", "ignore", "a", "nested", "path", "if", "any"], "project": "spring-framework"}
{"id": 7696, "code": "\tpublic LocaleContextResolver getLocaleContextResolver() {\n\t\treturn this.localeContextResolver;\n\t}", "summary_tokens": ["return", "the", "configured", "locale", "context", "resolver"], "project": "spring-framework"}
{"id": 2963, "code": "\tpublic boolean exists() {\n\t\treturn Files.exists(this.path);\n\t}", "summary_tokens": ["this", "implementation", "returns", "whether", "the", "underlying", "file", "exists"], "project": "spring-framework"}
{"id": 1601, "code": "\tprotected void applyCurrencyTimeLimit(Descriptor desc, int currencyTimeLimit) {\n\t\tif (currencyTimeLimit > 0) {\n\t\t\t\n\t\t\tdesc.setField(FIELD_CURRENCY_TIME_LIMIT, Integer.toString(currencyTimeLimit));\n\t\t}\n\t\telse if (currencyTimeLimit == 0) {\n\t\t\t\n\t\t\tdesc.setField(FIELD_CURRENCY_TIME_LIMIT, Integer.toString(Integer.MAX_VALUE));\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tapplyDefaultCurrencyTimeLimit(desc);\n\t\t}\n\t}", "summary_tokens": ["apply", "the", "given", "jmx", "currency", "time", "limit", "value", "to", "the", "given", "descriptor"], "project": "spring-framework"}
{"id": 5333, "code": "\tpublic String getSql() {\n\t\treturn this.sql;\n\t}", "summary_tokens": ["return", "the", "sql", "that", "led", "to", "the", "problem", "if", "known"], "project": "spring-framework"}
{"id": 6769, "code": "\tpublic void setReadTimeout(int readTimeout) {\n\t\tthis.readTimeout = readTimeout;\n\t}", "summary_tokens": ["set", "the", "underlying", "urlconnection", "s", "read", "timeout", "in", "milliseconds"], "project": "spring-framework"}
{"id": 6645, "code": "\tpublic HttpMethod getAccessControlRequestMethod() {\n\t\tString requestMethod = getFirst(ACCESS_CONTROL_REQUEST_METHOD);\n\t\tif (requestMethod != null) {\n\t\t\treturn HttpMethod.valueOf(requestMethod);\n\t\t}\n\t\telse {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "access", "control", "request", "method", "request", "header"], "project": "spring-framework"}
{"id": 5611, "code": "\tprotected void runChild(FrameworkMethod frameworkMethod, RunNotifier notifier) {\n\t\tDescription description = describeChild(frameworkMethod);\n\t\tif (isTestMethodIgnored(frameworkMethod)) {\n\t\t\tnotifier.fireTestIgnored(description);\n\t\t}\n\t\telse {\n\t\t\tStatement statement;\n\t\t\ttry {\n\t\t\t\tstatement = methodBlock(frameworkMethod);\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tstatement = new Fail(ex);\n\t\t\t}\n\t\t\trunLeaf(statement, description, notifier);\n\t\t}\n\t}", "summary_tokens": ["perform", "the", "same", "logic", "as", "block", "junit", "0", "class", "runner", "run", "child", "framework", "method", "run", "notifier", "except", "that", "tests", "are", "determined", "to", "be", "em", "ignored", "em", "by", "is", "test", "method", "ignored", "framework", "method"], "project": "spring-framework"}
{"id": 2145, "code": "\tpublic static CacheManager createSimpleCacheManager(String... cacheNames) {\n\t\tSimpleCacheManager result = new SimpleCacheManager();\n\t\tList<Cache> caches = new ArrayList<>();\n\t\tfor (String cacheName : cacheNames) {\n\t\t\tcaches.add(new ConcurrentMapCache(cacheName));\n\t\t}\n\t\tresult.setCaches(caches);\n\t\tresult.afterPropertiesSet();\n\t\treturn result;\n\t}", "summary_tokens": ["create", "a", "simple", "cache", "manager", "with", "the", "specified", "cache", "s"], "project": "spring-framework"}
{"id": 6342, "code": "\tpublic final Mono<ReactiveTransaction> getReactiveTransaction(@Nullable TransactionDefinition definition)\n\t\t\tthrows TransactionException {\n\n\t\t\n\t\tTransactionDefinition def = (definition != null ? definition : TransactionDefinition.withDefaults());\n\n\t\treturn TransactionSynchronizationManager.forCurrentTransaction()\n\t\t\t\t.flatMap(synchronizationManager -> {\n\n\t\t\tObject transaction = doGetTransaction(synchronizationManager);\n\n\t\t\t\n\t\t\tboolean debugEnabled = logger.isDebugEnabled();\n\n\t\t\tif (isExistingTransaction(transaction)) {\n\t\t\t\t\n\t\t\t\treturn handleExistingTransaction(synchronizationManager, def, transaction, debugEnabled);\n\t\t\t}\n\n\t\t\t\n\t\t\tif (def.getTimeout() < TransactionDefinition.TIMEOUT_DEFAULT) {\n\t\t\t\treturn Mono.error(new InvalidTimeoutException(\"Invalid transaction timeout\", def.getTimeout()));\n\t\t\t}\n\n\t\t\t\n\t\t\tif (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_MANDATORY) {\n\t\t\t\treturn Mono.error(new IllegalTransactionStateException(\n\t\t\t\t\t\t\"No existing transaction found for transaction marked with propagation 'mandatory'\"));\n\t\t\t}\n\t\t\telse if (def.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRED ||\n\t\t\t\t\tdef.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW ||\n\t\t\t\t\tdef.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) {\n\n\t\t\t\treturn TransactionContextManager.currentContext()\n\t\t\t\t\t\t.map(TransactionSynchronizationManager::new)\n\t\t\t\t\t\t.flatMap(nestedSynchronizationManager ->\n\t\t\t\t\t\t\t\tsuspend(nestedSynchronizationManager, null)\n\t\t\t\t\t\t\t\t.map(Optional::of)\n\t\t\t\t\t\t\t\t.defaultIfEmpty(Optional.empty())\n\t\t\t\t\t\t\t\t.flatMap(suspendedResources -> {\n\t\t\t\t\t\t\tif (debugEnabled) {\n\t\t\t\t\t\t\t\tlogger.debug(\"Creating new transaction with name [\" + def.getName() + \"]: \" + def);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\treturn Mono.defer(() -> {\n\t\t\t\t\t\t\t\tGenericReactiveTransaction status = newReactiveTransaction(\n\t\t\t\t\t\t\t\t\t\tnestedSynchronizationManager, def, transaction, true,\n\t\t\t\t\t\t\t\t\t\tdebugEnabled, suspendedResources.orElse(null));\n\t\t\t\t\t\t\t\treturn doBegin(nestedSynchronizationManager, transaction, def)\n\t\t\t\t\t\t\t\t\t\t.doOnSuccess(ignore -> prepareSynchronization(nestedSynchronizationManager, status, def))\n\t\t\t\t\t\t\t\t\t\t.thenReturn(status);\n\t\t\t\t\t\t\t}).onErrorResume(ErrorPredicates.RUNTIME_OR_ERROR,\n\t\t\t\t\t\t\t\t\tex -> resume(nestedSynchronizationManager, null, suspendedResources.orElse(null))\n\t\t\t\t\t\t\t\t\t.then(Mono.error(ex)));\n\t\t\t\t\t\t}));\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\tif (def.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT && logger.isWarnEnabled()) {\n\t\t\t\t\tlogger.warn(\"Custom isolation level specified but no actual transaction initiated; \" +\n\t\t\t\t\t\t\t\"isolation level will effectively be ignored: \" + def);\n\t\t\t\t}\n\t\t\t\treturn Mono.just(prepareReactiveTransaction(synchronizationManager, def, null, true, debugEnabled, null));\n\t\t\t}\n\t\t});\n\t}", "summary_tokens": ["this", "implementation", "handles", "propagation", "behavior"], "project": "spring-framework"}
{"id": 6731, "code": "\tpublic static ProblemDetail forStatusAndDetail(HttpStatusCode status, String detail) {\n\t\tAssert.notNull(status, \"HttpStatusCode is required\");\n\t\tProblemDetail problemDetail = forStatus(status.value());\n\t\tproblemDetail.setDetail(detail);\n\t\treturn problemDetail;\n\t}", "summary_tokens": ["create", "a", "problem", "detail", "instance", "with", "the", "given", "status", "and", "detail"], "project": "spring-framework"}
{"id": 1795, "code": "\tpublic Set<ScheduledTask> getScheduledTasks() {\n\t\tSet<ScheduledTask> result = new LinkedHashSet<>();\n\t\tsynchronized (this.scheduledTasks) {\n\t\t\tCollection<Set<ScheduledTask>> allTasks = this.scheduledTasks.values();\n\t\t\tfor (Set<ScheduledTask> tasks : allTasks) {\n\t\t\t\tresult.addAll(tasks);\n\t\t\t}\n\t\t}\n\t\tresult.addAll(this.registrar.getScheduledTasks());\n\t\treturn result;\n\t}", "summary_tokens": ["return", "all", "currently", "scheduled", "tasks", "from", "scheduled", "methods", "as", "well", "as", "from", "programmatic", "scheduling", "configurer", "interaction"], "project": "spring-framework"}
{"id": 2466, "code": "public int getCodeSize() {\n  return codeSize;\n}", "summary_tokens": ["returns", "the", "size", "of", "the", "method", "s", "code", "attribute", "in", "bytes"], "project": "spring-framework"}
{"id": 1316, "code": "\tpublic void setTaskExecutor(@Nullable Executor taskExecutor) {\n\t\tthis.taskExecutor = taskExecutor;\n\t}", "summary_tokens": ["set", "a", "custom", "executor", "typically", "a", "org"], "project": "spring-framework"}
{"id": 4549, "code": "\tprotected void populateActivationSpecProperties(BeanWrapper bw, JmsActivationSpecConfig config) {\n\t\tString destinationName = config.getDestinationName();\n\t\tif (destinationName != null) {\n\t\t\tboolean pubSubDomain = config.isPubSubDomain();\n\t\t\tObject destination = destinationName;\n\t\t\tif (this.destinationResolver != null) {\n\t\t\t\ttry {\n\t\t\t\t\tdestination = this.destinationResolver.resolveDestinationName(null, destinationName, pubSubDomain);\n\t\t\t\t}\n\t\t\t\tcatch (JMSException ex) {\n\t\t\t\t\tthrow new DestinationResolutionException(\n\t\t\t\t\t\t\t\"Cannot resolve destination name [\" + destinationName + \"]\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbw.setPropertyValue(\"destination\", destination);\n\t\t\tbw.setPropertyValue(\"destinationType\", pubSubDomain ? Topic.class.getName() : Queue.class.getName());\n\t\t}\n\n\t\tif (bw.isWritableProperty(\"subscriptionDurability\")) {\n\t\t\tbw.setPropertyValue(\"subscriptionDurability\", config.isSubscriptionDurable() ? \"Durable\" : \"NonDurable\");\n\t\t}\n\t\telse if (config.isSubscriptionDurable()) {\n\t\t\t\n\t\t\tthrow new IllegalArgumentException(\"Durable subscriptions not supported by underlying provider\");\n\t\t}\n\t\tif (config.isSubscriptionShared()) {\n\t\t\tthrow new IllegalArgumentException(\"Shared subscriptions not supported for JCA-driven endpoints\");\n\t\t}\n\n\t\tif (config.getSubscriptionName() != null) {\n\t\t\tbw.setPropertyValue(\"subscriptionName\", config.getSubscriptionName());\n\t\t}\n\t\tif (config.getClientId() != null) {\n\t\t\tbw.setPropertyValue(\"clientId\", config.getClientId());\n\t\t}\n\t\tif (config.getMessageSelector() != null) {\n\t\t\tbw.setPropertyValue(\"messageSelector\", config.getMessageSelector());\n\t\t}\n\t\tapplyAcknowledgeMode(bw, config.getAcknowledgeMode());\n\t}", "summary_tokens": ["populate", "the", "given", "application", "spec", "object", "with", "the", "settings", "defined", "in", "the", "given", "configuration", "object"], "project": "spring-framework"}
{"id": 1329, "code": "\tprotected void lazyLoadArguments() {\n\t\t\n\t\tif (ObjectUtils.isEmpty(this.arguments)) {\n\t\t\treturn;\n\t\t}\n\n\t\t\n\t\tString[] paramNames = this.parameterNameDiscoverer.getParameterNames(this.method);\n\t\tint paramCount = (paramNames != null ? paramNames.length : this.method.getParameterCount());\n\t\tint argsCount = this.arguments.length;\n\n\t\tfor (int i = 0; i < paramCount; i++) {\n\t\t\tObject value = null;\n\t\t\tif (argsCount > paramCount && i == paramCount - 1) {\n\t\t\t\t\n\t\t\t\tvalue = Arrays.copyOfRange(this.arguments, i, argsCount);\n\t\t\t}\n\t\t\telse if (argsCount > i) {\n\t\t\t\t\n\t\t\t\tvalue = this.arguments[i];\n\t\t\t}\n\t\t\tsetVariable(\"a\" + i, value);\n\t\t\tsetVariable(\"p\" + i, value);\n\t\t\tif (paramNames != null && paramNames[i] != null) {\n\t\t\t\tsetVariable(paramNames[i], value);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["load", "the", "param", "information", "only", "when", "needed"], "project": "spring-framework"}
{"id": 9570, "code": "\tprotected void exposeHelpers(HttpServletRequest request) throws Exception {\n\t\tif (this.messageSource != null) {\n\t\t\tJstlUtils.exposeLocalizationContext(request, this.messageSource);\n\t\t}\n\t\telse {\n\t\t\tJstlUtils.exposeLocalizationContext(new RequestContext(request, getServletContext()));\n\t\t}\n\t}", "summary_tokens": ["exposes", "a", "jstl", "localization", "context", "for", "spring", "s", "locale", "and", "message", "source"], "project": "spring-framework"}
{"id": 8449, "code": "\tvoid handleMessage(Type type, WebSocketMessage message) {\n\t\tthis.receivePublisher.handleMessage(message);\n\t}", "summary_tokens": ["handle", "a", "message", "callback", "from", "the", "web", "socket", "handler", "adapter"], "project": "spring-framework"}
{"id": 9649, "code": "\tprotected PdfReader readPdfResource() throws IOException {\n\t\tString url = getUrl();\n\t\tAssert.state(url != null, \"'url' not set\");\n\t\treturn new PdfReader(obtainApplicationContext().getResource(url).getInputStream());\n\t}", "summary_tokens": ["read", "the", "raw", "pdf", "resource", "into", "an", "i", "text", "pdf", "reader"], "project": "spring-framework"}
{"id": 7451, "code": "\tpublic void setCorsConfigurations(@Nullable Map<String, CorsConfiguration> configMap) {\n\t\tthis.corsConfigurations.clear();\n\t\tif (configMap != null) {\n\t\t\tconfigMap.forEach(this::registerCorsConfiguration);\n\t\t}\n\t}", "summary_tokens": ["set", "cors", "configuration", "based", "on", "url", "patterns"], "project": "spring-framework"}
{"id": 4077, "code": "\tpublic boolean isReturnGeneratedKeys() {\n\t\treturn this.returnGeneratedKeys;\n\t}", "summary_tokens": ["return", "whether", "statements", "should", "be", "capable", "of", "returning", "auto", "generated", "keys"], "project": "spring-framework"}
{"id": 6367, "code": "\tprotected Mono<Void> doSetRollbackOnly(TransactionSynchronizationManager synchronizationManager,\n\t\t\tGenericReactiveTransaction status) throws TransactionException {\n\n\t\tthrow new IllegalTransactionStateException(\n\t\t\t\t\"Participating in existing transactions is not supported - when 'isExistingTransaction' \" +\n\t\t\t\t\"returns true, appropriate 'doSetRollbackOnly' behavior must be provided\");\n\t}", "summary_tokens": ["set", "the", "given", "transaction", "rollback", "only"], "project": "spring-framework"}
{"id": 1944, "code": "\tpublic boolean containsAttribute(String attributeName) {\n\t\treturn containsKey(attributeName);\n\t}", "summary_tokens": ["does", "this", "model", "contain", "an", "attribute", "of", "the", "given", "name", "attribute", "name", "the", "name", "of", "the", "model", "attribute", "never", "null", "whether", "this", "model", "contains", "a", "corresponding", "attribute"], "project": "spring-framework"}
{"id": 417, "code": "\tpublic boolean isAutowireCandidate(BeanDefinitionHolder bdHolder, DependencyDescriptor descriptor) {\n\t\tboolean match = super.isAutowireCandidate(bdHolder, descriptor);\n\t\tif (match) {\n\t\t\tmatch = checkQualifiers(bdHolder, descriptor.getAnnotations());\n\t\t\tif (match) {\n\t\t\t\tMethodParameter methodParam = descriptor.getMethodParameter();\n\t\t\t\tif (methodParam != null) {\n\t\t\t\t\tMethod method = methodParam.getMethod();\n\t\t\t\t\tif (method == null || void.class == method.getReturnType()) {\n\t\t\t\t\t\tmatch = checkQualifiers(bdHolder, methodParam.getMethodAnnotations());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn match;\n\t}", "summary_tokens": ["determine", "whether", "the", "provided", "bean", "definition", "is", "an", "autowire", "candidate"], "project": "spring-framework"}
{"id": 8815, "code": "\tpublic void setDefaultErrorView(String defaultErrorView) {\n\t\tthis.defaultErrorView = defaultErrorView;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "default", "error", "view"], "project": "spring-framework"}
{"id": 7335, "code": "\tprotected void initPropertySources() {\n\t\tConfigurableEnvironment env = getEnvironment();\n\t\tif (env instanceof ConfigurableWebEnvironment) {\n\t\t\t((ConfigurableWebEnvironment) env).initPropertySources(this.servletContext, this.servletConfig);\n\t\t}\n\t}", "summary_tokens": ["p", "replace", "servlet", "related", "property", "sources"], "project": "spring-framework"}
{"id": 387, "code": "\tpublic Field getField() {\n\t\treturn this.field;\n\t}", "summary_tokens": ["return", "the", "wrapped", "field", "if", "any"], "project": "spring-framework"}
{"id": 7669, "code": "\tpublic HttpHeaders getResponseHeaders() {\n\t\treturn HttpHeaders.EMPTY;\n\t}", "summary_tokens": ["return", "headers", "associated", "with", "the", "exception", "that", "should", "be", "added", "to", "the", "error", "response", "e"], "project": "spring-framework"}
{"id": 6987, "code": "\tpublic void setObjectMapper(ObjectMapper objectMapper) {\n\t\tthis.objectMapper = objectMapper;\n\t}", "summary_tokens": ["set", "the", "object", "mapper", "instance", "to", "use"], "project": "spring-framework"}
{"id": 505, "code": "\tpublic Class<?> getObjectType() {\n\t\tif (!isPrepared()) {\n\t\t\t\n\t\t\treturn null;\n\t\t}\n\t\treturn getPreparedMethod().getReturnType();\n\t}", "summary_tokens": ["return", "the", "type", "of", "object", "that", "this", "factory", "bean", "creates", "or", "null", "if", "not", "known", "in", "advance"], "project": "spring-framework"}
{"id": 7642, "code": "\tprotected final void setMultipartParameters(Map<String, String[]> multipartParameters) {\n\t\tthis.multipartParameters = multipartParameters;\n\t}", "summary_tokens": ["set", "a", "map", "with", "parameter", "names", "as", "keys", "and", "string", "array", "objects", "as", "values"], "project": "spring-framework"}
{"id": 5608, "code": "\tprotected Statement withBeforeClasses(Statement statement) {\n\t\tStatement junitBeforeClasses = super.withBeforeClasses(statement);\n\t\treturn new RunBeforeTestClassCallbacks(junitBeforeClasses, getTestContextManager());\n\t}", "summary_tokens": ["wrap", "the", "statement", "returned", "by", "the", "parent", "implementation", "with", "a", "run", "before", "test", "class", "callbacks", "statement", "thus", "preserving", "the", "default", "junit", "functionality", "while", "adding", "support", "for", "the", "spring", "test", "context", "framework"], "project": "spring-framework"}
{"id": 6213, "code": "\tpublic boolean isRunning() {\n\t\treturn this.running;\n\t}", "summary_tokens": ["return", "whether", "the", "configured", "message", "endpoint", "is", "currently", "active"], "project": "spring-framework"}
{"id": 3831, "code": "\tpublic void setInParameterNames(Set<String> inParameterNames) {\n\t\tthis.callMetaDataContext.setLimitedInParameterNames(inParameterNames);\n\t}", "summary_tokens": ["set", "the", "names", "of", "in", "parameters", "to", "be", "used"], "project": "spring-framework"}
{"id": 1744, "code": "\tprotected Class<?> createCompositeInterface(Class<?>[] interfaces) {\n\t\treturn ClassUtils.createCompositeInterface(interfaces, this.beanClassLoader);\n\t}", "summary_tokens": ["create", "a", "composite", "interface", "class", "for", "the", "given", "interfaces", "implementing", "the", "given", "interfaces", "in", "one", "single", "class"], "project": "spring-framework"}
{"id": 8370, "code": "\tstatic Builder<?> view(String name) {\n\t\treturn new DefaultRenderingBuilder(name);\n\t}", "summary_tokens": ["create", "a", "new", "builder", "for", "response", "rendering", "based", "on", "the", "given", "view", "name"], "project": "spring-framework"}
{"id": 5864, "code": "\tpublic WebTestClient.ResponseSpec value(String name, Consumer<String> consumer) {\n\t\tString value = getCookie(name).getValue();\n\t\tthis.exchangeResult.assertWithDiagnostics(() -> consumer.accept(value));\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["consume", "the", "value", "of", "the", "response", "cookie"], "project": "spring-framework"}
{"id": 2719, "code": "\tprotected boolean isEligibleForOverriding(String className) {\n\t\treturn !isExcluded(className);\n\t}", "summary_tokens": ["determine", "whether", "the", "specified", "class", "is", "eligible", "for", "overriding", "by", "this", "class", "loader"], "project": "spring-framework"}
{"id": 6214, "code": "\tpublic void destroy() {\n\t\tstop();\n\t}", "summary_tokens": ["deactivates", "the", "message", "endpoint", "preparing", "it", "for", "shutdown"], "project": "spring-framework"}
{"id": 7503, "code": "\tprotected void initFilterBean() throws ServletException {\n\t}", "summary_tokens": ["subclasses", "may", "override", "this", "to", "perform", "custom", "initialization"], "project": "spring-framework"}
{"id": 8061, "code": "\tpublic static <T> BodyInserter<T, ReactiveHttpOutputMessage> empty() {\n\t\treturn (BodyInserter<T, ReactiveHttpOutputMessage>) EMPTY_INSERTER;\n\t}", "summary_tokens": ["inserter", "that", "does", "not", "write"], "project": "spring-framework"}
{"id": 1044, "code": "\tpublic final FileTypeMap getDefaultFileTypeMap() {\n\t\treturn this.defaultFileTypeMap;\n\t}", "summary_tokens": ["return", "the", "default", "file", "type", "map", "of", "this", "message", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 9540, "code": "\tpublic String getBeanName() {\n\t\treturn this.beanName;\n\t}", "summary_tokens": ["return", "the", "view", "s", "name"], "project": "spring-framework"}
{"id": 795, "code": "\tprotected void postProcess(BeanDefinitionBuilder beanDefinition, Element element) {\n\t}", "summary_tokens": ["hook", "method", "that", "derived", "classes", "can", "implement", "to", "inspect", "change", "a", "bean", "definition", "after", "parsing", "is", "complete"], "project": "spring-framework"}
{"id": 9632, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["specify", "the", "order", "value", "for", "this", "view", "resolver", "bean"], "project": "spring-framework"}
{"id": 9921, "code": "\tpublic Collection<String> getAllowedOrigins() {\n\t\treturn this.corsConfiguration.getAllowedOrigins();\n\t}", "summary_tokens": ["return", "the", "set", "allowed", "origins", "collection", "configured", "allowed", "origins"], "project": "spring-framework"}
{"id": 311, "code": "\tpublic void addMetadataAttribute(BeanMetadataAttribute attribute) {\n\t\tsuper.setAttribute(attribute.getName(), attribute);\n\t}", "summary_tokens": ["add", "the", "given", "bean", "metadata", "attribute", "to", "this", "accessor", "s", "set", "of", "attributes"], "project": "spring-framework"}
{"id": 4135, "code": "\tpublic static CustomSQLExceptionTranslatorRegistry getInstance() {\n\t\treturn instance;\n\t}", "summary_tokens": ["return", "the", "singleton", "instance"], "project": "spring-framework"}
{"id": 9793, "code": "\tpublic SockJsServiceRegistration setHeartbeatTime(long heartbeatTime) {\n\t\tthis.heartbeatTime = heartbeatTime;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "amount", "of", "time", "in", "milliseconds", "when", "the", "server", "has", "not", "sent", "any", "messages", "and", "after", "which", "the", "server", "should", "send", "a", "heartbeat", "frame", "to", "the", "client", "in", "order", "to", "keep", "the", "connection", "from", "breaking"], "project": "spring-framework"}
{"id": 4093, "code": "\tprotected boolean supportsLobParameters() {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "blob", "clob", "parameters", "are", "supported", "for", "this", "kind", "of", "operation"], "project": "spring-framework"}
{"id": 3605, "code": "\tpublic static Builder forReadWriteDataBinding() {\n\t\treturn new Builder(DataBindingPropertyAccessor.forReadWriteAccess());\n\t}", "summary_tokens": ["create", "a", "simple", "evaluation", "context", "for", "read", "write", "access", "to", "public", "properties", "via", "data", "binding", "property", "accessor"], "project": "spring-framework"}
{"id": 78, "code": "\tstatic Object setCurrentProxy(@Nullable Object proxy) {\n\t\tObject old = currentProxy.get();\n\t\tif (proxy != null) {\n\t\t\tcurrentProxy.set(proxy);\n\t\t}\n\t\telse {\n\t\t\tcurrentProxy.remove();\n\t\t}\n\t\treturn old;\n\t}", "summary_tokens": ["make", "the", "given", "proxy", "available", "via", "the", "current", "proxy", "method"], "project": "spring-framework"}
{"id": 9216, "code": "\tpublic int doEndTag() throws JspException {\n\t\ttry {\n\t\t\t\n\t\t\tString msg = resolveMessage();\n\n\t\t\t\n\t\t\tmsg = htmlEscape(msg);\n\t\t\tmsg = this.javaScriptEscape ? JavaScriptUtils.javaScriptEscape(msg) : msg;\n\n\t\t\t\n\t\t\tif (this.var != null) {\n\t\t\t\tthis.pageContext.setAttribute(this.var, msg, TagUtils.getScope(this.scope));\n\t\t\t}\n\t\t\telse {\n\t\t\t\twriteMessage(msg);\n\t\t\t}\n\n\t\t\treturn EVAL_PAGE;\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new JspTagException(ex.getMessage(), ex);\n\t\t}\n\t\tcatch (NoSuchMessageException ex) {\n\t\t\tthrow new JspTagException(getNoSuchMessageExceptionDescription(ex));\n\t\t}\n\t}", "summary_tokens": ["resolves", "the", "message", "escapes", "it", "if", "demanded", "and", "writes", "it", "to", "the", "page", "or", "exposes", "it", "as", "variable"], "project": "spring-framework"}
{"id": 168, "code": "\tpublic void setLogTargetClassInvocation(boolean logTargetClassInvocation) {\n\t\tthis.logTargetClassInvocation = logTargetClassInvocation;\n\t}", "summary_tokens": ["set", "whether", "to", "log", "the", "invocation", "on", "the", "target", "class", "if", "applicable", "i"], "project": "spring-framework"}
{"id": 6050, "code": "\tpublic ResultMatcher reason(String reason) {\n\t\treturn result -> assertEquals(\"Response status reason\", reason, result.getResponse().getErrorMessage());\n\t}", "summary_tokens": ["assert", "the", "servlet", "response", "error", "message"], "project": "spring-framework"}
{"id": 7235, "code": "\tpublic boolean hasMessageBody() throws IOException {\n\t\tHttpStatusCode statusCode = getStatusCode();\n\t\tif (statusCode.is1xxInformational() || statusCode == HttpStatus.NO_CONTENT ||\n\t\t\t\tstatusCode == HttpStatus.NOT_MODIFIED) {\n\t\t\treturn false;\n\t\t}\n\t\tif (getHeaders().getContentLength() == 0) {\n\t\t\treturn false;\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["indicates", "whether", "the", "response", "has", "a", "message", "body"], "project": "spring-framework"}
{"id": 3126, "code": "\tpublic static Class<?> resolvePrimitiveClassName(@Nullable String name) {\n\t\tClass<?> result = null;\n\t\t\n\t\t\n\t\tif (name != null && name.length() <= 7) {\n\t\t\t\n\t\t\tresult = primitiveTypeNameMap.get(name);\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["resolve", "the", "given", "class", "name", "as", "primitive", "class", "if", "appropriate", "according", "to", "the", "jvm", "s", "naming", "rules", "for", "primitive", "classes"], "project": "spring-framework"}
{"id": 7710, "code": "\tpublic boolean hasSessionManager() {\n\t\treturn (this.sessionManager != null);\n\t}", "summary_tokens": ["whether", "a", "web", "session", "manager", "is", "configured", "or", "not", "either", "detected", "from", "an", "application", "context", "or", "explicitly", "configured", "via", "session", "manager"], "project": "spring-framework"}
{"id": 137, "code": "\tprotected boolean advisorsPreFiltered() {\n\t\treturn false;\n\t}", "summary_tokens": ["return", "whether", "the", "advisors", "returned", "by", "the", "subclass", "are", "pre", "filtered", "to", "match", "the", "bean", "s", "target", "class", "already", "allowing", "the", "class", "filter", "check", "to", "be", "skipped", "when", "building", "advisors", "chains", "for", "aop", "invocations"], "project": "spring-framework"}
{"id": 3055, "code": "\tpublic final ThreadFactory getThreadFactory() {\n\t\treturn this.threadFactory;\n\t}", "summary_tokens": ["return", "the", "external", "factory", "to", "use", "for", "creating", "new", "threads", "if", "any"], "project": "spring-framework"}
{"id": 5567, "code": "\tString getBlockCommentEndDelimiter() {\n\t\treturn this.blockCommentEndDelimiter;\n\t}", "summary_tokens": ["get", "the", "end", "delimiter", "that", "identifies", "block", "comments", "within", "the", "sql", "scripts"], "project": "spring-framework"}
{"id": 3489, "code": "\tpublic static long toLong(TypeConverter typeConverter, TypedValue typedValue) {\n\t\treturn convertValue(typeConverter, typedValue, Long.class);\n\t}", "summary_tokens": ["attempt", "to", "convert", "a", "typed", "value", "to", "a", "long", "using", "the", "supplied", "type", "converter"], "project": "spring-framework"}
{"id": 2020, "code": "\tpublic void setMessageCodeFormatter(@Nullable MessageCodeFormatter formatter) {\n\t\tthis.formatter = (formatter != null ? formatter : DEFAULT_FORMATTER);\n\t}", "summary_tokens": ["specify", "the", "format", "for", "message", "codes", "built", "by", "this", "resolver"], "project": "spring-framework"}
{"id": 5007, "code": "\tpublic String getSession() {\n\t\treturn getFirst(SESSION);\n\t}", "summary_tokens": ["get", "the", "session", "header"], "project": "spring-framework"}
{"id": 5030, "code": "\tpublic void handleTransportError(StompSession session, Throwable exception) {\n\t}", "summary_tokens": ["this", "implementation", "is", "empty"], "project": "spring-framework"}
{"id": 9853, "code": "\tpublic Stats getStats() {\n\t\treturn this.stats;\n\t}", "summary_tokens": ["return", "a", "structured", "object", "with", "various", "session", "counters"], "project": "spring-framework"}
{"id": 7116, "code": "\tpublic Map<String, MediaType> getMediaTypeMappings() {\n\t\tMap<String, MediaType> result = null;\n\t\tfor (MediaTypeFileExtensionResolver resolver : this.resolvers) {\n\t\t\tif (resolver instanceof MappingMediaTypeFileExtensionResolver) {\n\t\t\t\tMap<String, MediaType> map = ((MappingMediaTypeFileExtensionResolver) resolver).getMediaTypes();\n\t\t\t\tif (CollectionUtils.isEmpty(map)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tresult = (result != null ? result : new HashMap<>(4));\n\t\t\t\tresult.putAll(map);\n\t\t\t}\n\t\t}\n\t\treturn (result != null ? result : Collections.emptyMap());\n\t}", "summary_tokens": ["return", "all", "registered", "lookup", "key", "to", "media", "type", "mappings", "by", "iterating", "media", "type", "file", "extension", "resolver", "s"], "project": "spring-framework"}
{"id": 4441, "code": "\tprotected MessageConsumer createListenerConsumer(Session session) throws JMSException {\n\t\tDestination destination = getDestination();\n\t\tif (destination == null) {\n\t\t\tString destinationName = getDestinationName();\n\t\t\tAssert.state(destinationName != null, \"No destination set\");\n\t\t\tdestination = resolveDestinationName(session, destinationName);\n\t\t}\n\t\treturn createConsumer(session, destination);\n\t}", "summary_tokens": ["create", "a", "message", "consumer", "for", "the", "given", "jms", "session", "registering", "a", "message", "listener", "for", "the", "specified", "listener"], "project": "spring-framework"}
{"id": 3177, "code": "\tpublic static <E> void mergeArrayIntoCollection(@Nullable Object array, Collection<E> collection) {\n\t\tObject[] arr = ObjectUtils.toObjectArray(array);\n\t\tCollections.addAll(collection, (E[])arr);\n\t}", "summary_tokens": ["merge", "the", "given", "array", "into", "the", "given", "collection"], "project": "spring-framework"}
{"id": 3575, "code": "\tprivate void pushCharToken(TokenKind kind) {\n\t\tthis.tokens.add(new Token(kind, this.pos, this.pos + 1));\n\t\tthis.pos++;\n\t}", "summary_tokens": ["push", "a", "token", "of", "just", "one", "character", "in", "length"], "project": "spring-framework"}
{"id": 9292, "code": "\tpublic void setDir(String dir) {\n\t\tthis.dir = dir;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "dir", "attribute"], "project": "spring-framework"}
{"id": 3838, "code": "\tpublic boolean isFunction() {\n\t\treturn this.callMetaDataContext.isFunction();\n\t}", "summary_tokens": ["is", "this", "call", "a", "function", "call"], "project": "spring-framework"}
{"id": 8502, "code": "\tprivate void initFlashMapManager(ApplicationContext context) {\n\t\ttry {\n\t\t\tthis.flashMapManager = context.getBean(FLASH_MAP_MANAGER_BEAN_NAME, FlashMapManager.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Detected \" + this.flashMapManager.getClass().getSimpleName());\n\t\t\t}\n\t\t\telse if (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Detected \" + this.flashMapManager);\n\t\t\t}\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\n\t\t\tthis.flashMapManager = getDefaultStrategy(context, FlashMapManager.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"No FlashMapManager '\" + FLASH_MAP_MANAGER_BEAN_NAME +\n\t\t\t\t\t\t\"': using default [\" + this.flashMapManager.getClass().getSimpleName() + \"]\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "flash", "map", "manager", "used", "by", "this", "servlet", "instance"], "project": "spring-framework"}
{"id": 2452, "code": "public int getOffset() {\n  if ((flags & FLAG_RESOLVED) == 0) {\n    throw new IllegalStateException(\"Label offset position has not been resolved yet\");\n  }\n  return bytecodeOffset;\n}", "summary_tokens": ["returns", "the", "bytecode", "offset", "corresponding", "to", "this", "label"], "project": "spring-framework"}
{"id": 5954, "code": "\tpublic static MockHttpServletRequestBuilder put(URI uri) {\n\t\treturn new MockHttpServletRequestBuilder(HttpMethod.PUT, uri);\n\t}", "summary_tokens": ["create", "a", "mock", "http", "servlet", "request", "builder", "for", "a", "put", "request"], "project": "spring-framework"}
{"id": 9772, "code": "\tpublic void setUserProperties(@Nullable Map<String, Object> userProperties) {\n\t\tif (userProperties != null) {\n\t\t\tthis.userProperties.putAll(userProperties);\n\t\t}\n\t}", "summary_tokens": ["the", "standard", "java", "web", "socket", "api", "allows", "passing", "user", "properties", "to", "the", "server", "via", "client", "endpoint", "config", "get", "user", "properties", "user", "properties"], "project": "spring-framework"}
{"id": 1191, "code": "\tprotected void doClear(Cache cache, boolean immediate) {\n\t\ttry {\n\t\t\tif (immediate) {\n\t\t\t\tcache.invalidate();\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcache.clear();\n\t\t\t}\n\t\t}\n\t\tcatch (RuntimeException ex) {\n\t\t\tgetErrorHandler().handleCacheClearError(ex, cache);\n\t\t}\n\t}", "summary_tokens": ["execute", "cache", "clear", "on", "the", "specified", "cache", "and", "invoke", "the", "error", "handler", "if", "an", "exception", "occurs"], "project": "spring-framework"}
{"id": 156, "code": "\tprotected boolean isEligibleAdvisorBean(String beanName) {\n\t\tif (!isUsePrefix()) {\n\t\t\treturn true;\n\t\t}\n\t\tString prefix = getAdvisorBeanNamePrefix();\n\t\treturn (prefix != null && beanName.startsWith(prefix));\n\t}", "summary_tokens": ["consider", "advisor", "beans", "with", "the", "specified", "prefix", "as", "eligible", "if", "activated"], "project": "spring-framework"}
{"id": 6916, "code": "\tfinal List<HttpMessageWriter<?>> getBaseObjectWriters() {\n\t\tList<HttpMessageWriter<?>> writers = new ArrayList<>();\n\t\tif (kotlinSerializationJsonPresent) {\n\t\t\taddCodec(writers, new EncoderHttpMessageWriter<>(getKotlinSerializationJsonEncoder()));\n\t\t}\n\t\tif (jackson2Present) {\n\t\t\taddCodec(writers, new EncoderHttpMessageWriter<>(getJackson2JsonEncoder()));\n\t\t}\n\t\tif (jackson2SmilePresent) {\n\t\t\taddCodec(writers, new EncoderHttpMessageWriter<>(this.jackson2SmileEncoder != null ?\n\t\t\t\t\t(Jackson2SmileEncoder) this.jackson2SmileEncoder : new Jackson2SmileEncoder()));\n\t\t}\n\t\tif (jaxb2Present && !shouldIgnoreXml) {\n\t\t\taddCodec(writers, new EncoderHttpMessageWriter<>(this.jaxb2Encoder != null ?\n\t\t\t\t\t(Jaxb2XmlEncoder) this.jaxb2Encoder : new Jaxb2XmlEncoder()));\n\t\t}\n\t\treturn writers;\n\t}", "summary_tokens": ["return", "base", "object", "writers", "only", "i"], "project": "spring-framework"}
{"id": 1993, "code": "\tpublic String[] getAllowedFields() {\n\t\treturn this.allowedFields;\n\t}", "summary_tokens": ["return", "the", "field", "patterns", "that", "should", "be", "allowed", "for", "binding"], "project": "spring-framework"}
{"id": 170, "code": "\tpublic void setUseDynamicLogger(boolean useDynamicLogger) {\n\t\t\n\t\tthis.defaultLogger = (useDynamicLogger ? null : LogFactory.getLog(getClass()));\n\t}", "summary_tokens": ["set", "whether", "to", "use", "a", "dynamic", "logger", "or", "a", "static", "logger"], "project": "spring-framework"}
{"id": 9043, "code": "\tprotected ModelAndView handleMissingPathVariable(MissingPathVariableException ex,\n\t\t\tHttpServletRequest request, HttpServletResponse response, @Nullable Object handler) throws IOException {\n\n\t\treturn null;\n\t}", "summary_tokens": ["handle", "the", "case", "when", "a", "declared", "path", "variable", "does", "not", "match", "any", "extracted", "uri", "variable"], "project": "spring-framework"}
{"id": 255, "code": "\tpublic void setMaxIdle(int maxIdle) {\n\t\tthis.maxIdle = maxIdle;\n\t}", "summary_tokens": ["set", "the", "maximum", "number", "of", "idle", "objects", "in", "the", "pool"], "project": "spring-framework"}
{"id": 7533, "code": "\tpublic static WebApplicationContext getRequiredWebApplicationContext(FacesContext fc) throws IllegalStateException {\n\t\tWebApplicationContext wac = getWebApplicationContext(fc);\n\t\tif (wac == null) {\n\t\t\tthrow new IllegalStateException(\"No WebApplicationContext found: no ContextLoaderListener registered?\");\n\t\t}\n\t\treturn wac;\n\t}", "summary_tokens": ["find", "the", "root", "web", "application", "context", "for", "this", "web", "app", "typically", "loaded", "via", "org"], "project": "spring-framework"}
{"id": 3835, "code": "\tpublic void setSchemaName(@Nullable String schemaName) {\n\t\tthis.callMetaDataContext.setSchemaName(schemaName);\n\t}", "summary_tokens": ["set", "the", "schema", "name", "to", "use"], "project": "spring-framework"}
{"id": 4004, "code": "\tpublic EmbeddedDatabaseBuilder generateUniqueName(boolean flag) {\n\t\tthis.databaseFactory.setGenerateUniqueDatabaseName(flag);\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "whether", "a", "unique", "id", "should", "be", "generated", "and", "used", "as", "the", "database", "name"], "project": "spring-framework"}
{"id": 1237, "code": "\tdefault String getDefaultMessage() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "default", "message", "to", "be", "used", "to", "resolve", "this", "message"], "project": "spring-framework"}
{"id": 5747, "code": "\tpublic int hashCode() {\n\t\treturn (31 * super.hashCode() + this.resourceBasePath.hashCode());\n\t}", "summary_tokens": ["generate", "a", "unique", "hash", "code", "for", "all", "properties", "of", "this", "web", "merged", "context", "configuration", "excluding", "the", "get", "test", "class", "test", "class"], "project": "spring-framework"}
{"id": 6132, "code": "\tpublic static DefaultMockMvcBuilder webAppContextSetup(WebApplicationContext context) {\n\t\treturn new DefaultMockMvcBuilder(context);\n\t}", "summary_tokens": ["build", "a", "mock", "mvc", "instance", "using", "the", "given", "fully", "initialized", "i"], "project": "spring-framework"}
{"id": 2592, "code": "public String toString() {\n  int length = getLength();\n  StringBuilder result = new StringBuilder(length * 2);\n  for (int i = 0; i < length; ++i) {\n    switch (getStep(i)) {\n      case ARRAY_ELEMENT:\n        result.append('[');\n        break;\n      case INNER_TYPE:\n        result.append('.');\n        break;\n      case WILDCARD_BOUND:\n        result.append('*');\n        break;\n      case TYPE_ARGUMENT:\n        result.append(getStepArgument(i)).append(';');\n        break;\n      default:\n        throw new AssertionError();\n    }\n  }\n  return result.toString();\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "this", "type", "path"], "project": "spring-framework"}
{"id": 3563, "code": "\tpublic static boolean compile(Expression expression) {\n\t\treturn (expression instanceof SpelExpression && ((SpelExpression) expression).compileExpression());\n\t}", "summary_tokens": ["request", "that", "an", "attempt", "is", "made", "to", "compile", "the", "specified", "expression"], "project": "spring-framework"}
{"id": 1272, "code": "\tprotected boolean checkCandidate(String beanName, BeanDefinition beanDefinition) throws IllegalStateException {\n\t\tif (!this.registry.containsBeanDefinition(beanName)) {\n\t\t\treturn true;\n\t\t}\n\t\tBeanDefinition existingDef = this.registry.getBeanDefinition(beanName);\n\t\tBeanDefinition originatingDef = existingDef.getOriginatingBeanDefinition();\n\t\tif (originatingDef != null) {\n\t\t\texistingDef = originatingDef;\n\t\t}\n\t\tif (isCompatible(beanDefinition, existingDef)) {\n\t\t\treturn false;\n\t\t}\n\t\tthrow new ConflictingBeanDefinitionException(\"Annotation-specified bean name '\" + beanName +\n\t\t\t\t\"' for bean class [\" + beanDefinition.getBeanClassName() + \"] conflicts with existing, \" +\n\t\t\t\t\"non-compatible bean definition of same name and class [\" + existingDef.getBeanClassName() + \"]\");\n\t}", "summary_tokens": ["check", "the", "given", "candidate", "s", "bean", "name", "determining", "whether", "the", "corresponding", "bean", "definition", "needs", "to", "be", "registered", "or", "conflicts", "with", "an", "existing", "definition"], "project": "spring-framework"}
{"id": 4330, "code": "\tpublic void setReceiveTimeout(long receiveTimeout) {\n\t\tthis.receiveTimeout = receiveTimeout;\n\t}", "summary_tokens": ["set", "the", "timeout", "to", "use", "for", "receive", "calls", "in", "milliseconds"], "project": "spring-framework"}
{"id": 9154, "code": "\tpublic static ServletUriComponentsBuilder fromCurrentRequest() {\n\t\treturn fromRequest(getCurrentRequest());\n\t}", "summary_tokens": ["same", "as", "from", "request", "http", "servlet", "request", "except", "the", "request", "is", "obtained", "through", "request", "context", "holder"], "project": "spring-framework"}
{"id": 8637, "code": "\tpublic ResourceHandlerRegistry setOrder(int order) {\n\t\tthis.order = order;\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "the", "order", "to", "use", "for", "resource", "handling", "relative", "to", "other", "handler", "mapping", "handler", "mappings", "configured", "in", "the", "spring", "mvc", "application", "context"], "project": "spring-framework"}
{"id": 6513, "code": "\tpublic void setTimeoutInSeconds(int seconds) {\n\t\tsetTimeoutInMillis(seconds * 1000L);\n\t}", "summary_tokens": ["set", "the", "timeout", "for", "this", "object", "in", "seconds"], "project": "spring-framework"}
{"id": 7857, "code": "\tpublic String getPathWithinApplication(HttpServletRequest request) {\n\t\tString contextPath = getContextPath(request);\n\t\tString requestUri = getRequestUri(request);\n\t\tString path = getRemainingPath(requestUri, contextPath, true);\n\t\tif (path != null) {\n\t\t\t\n\t\t\treturn (StringUtils.hasText(path) ? path : \"/\");\n\t\t}\n\t\telse {\n\t\t\treturn requestUri;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "path", "within", "the", "web", "application", "for", "the", "given", "request"], "project": "spring-framework"}
{"id": 5285, "code": "\tprotected String getEntityManagerFactoryBeanName() {\n\t\treturn this.entityManagerFactoryBeanName;\n\t}", "summary_tokens": ["return", "the", "bean", "name", "of", "the", "entity", "manager", "factory", "to", "fetch", "from", "spring", "s", "root", "application", "context"], "project": "spring-framework"}
{"id": 8359, "code": "\tpublic boolean isContextRelative() {\n\t\treturn this.contextRelative;\n\t}", "summary_tokens": ["whether", "to", "interpret", "urls", "as", "relative", "to", "the", "current", "context", "path"], "project": "spring-framework"}
{"id": 2337, "code": "public String getClassName() {\n    \n  return readClass(header + 2, new char[maxStringLength]);\n}", "summary_tokens": ["returns", "the", "internal", "name", "of", "the", "class", "see", "type", "get", "internal", "name"], "project": "spring-framework"}
{"id": 4261, "code": "\tpublic static Session getTransactionalSession(final ConnectionFactory cf,\n\t\t\t@Nullable final Connection existingCon, final boolean synchedLocalTransactionAllowed)\n\t\t\tthrows JMSException {\n\n\t\treturn doGetTransactionalSession(cf, new ResourceFactory() {\n\t\t\t@Override\n\t\t\t@Nullable\n\t\t\tpublic Session getSession(JmsResourceHolder holder) {\n\t\t\t\treturn holder.getSession(Session.class, existingCon);\n\t\t\t}\n\t\t\t@Override\n\t\t\t@Nullable\n\t\t\tpublic Connection getConnection(JmsResourceHolder holder) {\n\t\t\t\treturn (existingCon != null ? existingCon : holder.getConnection());\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic Connection createConnection() throws JMSException {\n\t\t\t\treturn cf.createConnection();\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic Session createSession(Connection con) throws JMSException {\n\t\t\t\treturn con.createSession(synchedLocalTransactionAllowed, Session.AUTO_ACKNOWLEDGE);\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic boolean isSynchedLocalTransactionAllowed() {\n\t\t\t\treturn synchedLocalTransactionAllowed;\n\t\t\t}\n\t\t}, true);\n\t}", "summary_tokens": ["obtain", "a", "jms", "session", "that", "is", "synchronized", "with", "the", "current", "transaction", "if", "any"], "project": "spring-framework"}
{"id": 6799, "code": "\tpublic void setClientHttpRequestInitializers(\n\t\t\tList<ClientHttpRequestInitializer> clientHttpRequestInitializers) {\n\n\t\tif (this.clientHttpRequestInitializers != clientHttpRequestInitializers) {\n\t\t\tthis.clientHttpRequestInitializers.clear();\n\t\t\tthis.clientHttpRequestInitializers.addAll(clientHttpRequestInitializers);\n\t\t\tAnnotationAwareOrderComparator.sort(this.clientHttpRequestInitializers);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "request", "initializers", "that", "this", "accessor", "should", "use"], "project": "spring-framework"}
{"id": 1341, "code": "\tpublic static void setDefaultTimeZone(@Nullable TimeZone timeZone) {\n\t\tdefaultTimeZone = timeZone;\n\t}", "summary_tokens": ["set", "a", "shared", "default", "time", "zone", "at", "the", "framework", "level", "as", "an", "alternative", "to", "the", "jvm", "wide", "default", "time", "zone"], "project": "spring-framework"}
{"id": 8905, "code": "\tpublic PathPatternsRequestCondition getMatchingCondition(HttpServletRequest request) {\n\t\tPathContainer path = ServletRequestPathUtils.getParsedRequestPath(request).pathWithinApplication();\n\t\tSortedSet<PathPattern> matches = getMatchingPatterns(path);\n\t\treturn (matches != null ? new PathPatternsRequestCondition(matches) : null);\n\t}", "summary_tokens": ["checks", "if", "any", "of", "the", "patterns", "match", "the", "given", "request", "and", "returns", "an", "instance", "that", "is", "guaranteed", "to", "contain", "matching", "patterns", "sorted"], "project": "spring-framework"}
{"id": 2309, "code": "static AnnotationWriter create(\n    final SymbolTable symbolTable,\n    final int typeRef,\n    final TypePath typePath,\n    final String descriptor,\n    final AnnotationWriter previousAnnotation) {\n    \n    \n  ByteVector typeAnnotation = new ByteVector();\n    \n  TypeReference.putTarget(typeRef, typeAnnotation);\n  TypePath.put(typePath, typeAnnotation);\n    \n  typeAnnotation.putShort(symbolTable.addConstantUtf8(descriptor)).putShort(0);\n  return new AnnotationWriter(\n      symbolTable,  true, typeAnnotation, previousAnnotation);\n}", "summary_tokens": ["creates", "a", "new", "annotation", "writer", "using", "named", "values"], "project": "spring-framework"}
{"id": 9916, "code": "\tpublic void setWebSocketEnabled(boolean webSocketEnabled) {\n\t\tthis.webSocketEnabled = webSocketEnabled;\n\t}", "summary_tokens": ["some", "load", "balancers", "do", "not", "support", "web", "socket"], "project": "spring-framework"}
{"id": 9586, "code": "\tprotected void appendCurrentQueryParams(StringBuilder targetUrl, HttpServletRequest request) {\n\t\tString query = request.getQueryString();\n\t\tif (StringUtils.hasText(query)) {\n\t\t\t\n\t\t\tString fragment = null;\n\t\t\tint anchorIndex = targetUrl.indexOf(\"#\");\n\t\t\tif (anchorIndex > -1) {\n\t\t\t\tfragment = targetUrl.substring(anchorIndex);\n\t\t\t\ttargetUrl.delete(anchorIndex, targetUrl.length());\n\t\t\t}\n\n\t\t\tif (targetUrl.toString().indexOf('?') < 0) {\n\t\t\t\ttargetUrl.append('?').append(query);\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttargetUrl.append('&').append(query);\n\t\t\t}\n\t\t\t\n\t\t\tif (fragment != null) {\n\t\t\t\ttargetUrl.append(fragment);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["append", "the", "query", "string", "of", "the", "current", "request", "to", "the", "target", "redirect", "url"], "project": "spring-framework"}
{"id": 8446, "code": "\tpublic String getLogPrefix() {\n\t\treturn this.logPrefix;\n\t}", "summary_tokens": ["a", "log", "prefix", "used", "in", "the", "handshake", "to", "correlate", "log", "messages", "if", "any"], "project": "spring-framework"}
{"id": 2836, "code": "\tpublic TypeDescriptor getTargetType() {\n\t\treturn this.targetType;\n\t}", "summary_tokens": ["return", "the", "target", "type", "we", "tried", "to", "convert", "the", "value", "to"], "project": "spring-framework"}
{"id": 1176, "code": "\tpublic void setStore(ConcurrentMap<Object, Object> store) {\n\t\tthis.store = store;\n\t}", "summary_tokens": ["specify", "the", "concurrent", "map", "to", "use", "as", "an", "internal", "store", "possibly", "pre", "populated"], "project": "spring-framework"}
{"id": 3771, "code": "\tpublic String getCatalogName() {\n\t\treturn this.catalogName;\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "catalog", "for", "this", "context"], "project": "spring-framework"}
{"id": 256, "code": "\tpublic int getMaxIdle() {\n\t\treturn this.maxIdle;\n\t}", "summary_tokens": ["return", "the", "maximum", "number", "of", "idle", "objects", "in", "the", "pool"], "project": "spring-framework"}
{"id": 9429, "code": "\tprotected Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["get", "the", "value", "attribute", "of", "the", "rendered", "html", "option", "tag"], "project": "spring-framework"}
{"id": 5191, "code": "\tprotected final Session currentSession() throws DataAccessResourceFailureException {\n\t\tSessionFactory sessionFactory = getSessionFactory();\n\t\tAssert.state(sessionFactory != null, \"No SessionFactory set\");\n\t\treturn sessionFactory.getCurrentSession();\n\t}", "summary_tokens": ["conveniently", "obtain", "the", "current", "hibernate", "session"], "project": "spring-framework"}
{"id": 6318, "code": "\tprotected UserTransaction lookupUserTransaction(String userTransactionName)\n\t\t\tthrows TransactionSystemException {\n\t\ttry {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Retrieving JTA UserTransaction from JNDI location [\" + userTransactionName + \"]\");\n\t\t\t}\n\t\t\treturn getJndiTemplate().lookup(userTransactionName, UserTransaction.class);\n\t\t}\n\t\tcatch (NamingException ex) {\n\t\t\tthrow new TransactionSystemException(\n\t\t\t\t\t\"JTA UserTransaction is not available at JNDI location [\" + userTransactionName + \"]\", ex);\n\t\t}\n\t}", "summary_tokens": ["look", "up", "the", "jta", "user", "transaction", "in", "jndi", "via", "the", "configured", "name"], "project": "spring-framework"}
{"id": 7754, "code": "\tpublic ParameterizedTypeReference<?> getBodyElementType() {\n\t\treturn this.bodyElementType;\n\t}", "summary_tokens": ["return", "the", "element", "type", "for", "a", "get", "body", "publisher", "body"], "project": "spring-framework"}
{"id": 8453, "code": "\tpublic ChannelId getChannelId() {\n\t\treturn this.channelId;\n\t}", "summary_tokens": ["return", "the", "id", "of", "the", "underlying", "netty", "channel"], "project": "spring-framework"}
{"id": 4189, "code": "\tpublic void setStreamAsLob(boolean streamAsLob) {\n\t\tthis.streamAsLob = streamAsLob;\n\t}", "summary_tokens": ["specify", "whether", "to", "submit", "a", "binary", "stream", "character", "stream", "to", "the", "jdbc", "driver", "as", "explicit", "lob", "content", "using", "the", "jdbc", "0"], "project": "spring-framework"}
{"id": 5799, "code": "\tpublic static ExpectedCount manyTimes() {\n\t\treturn new ExpectedCount(1, Integer.MAX_VALUE);\n\t}", "summary_tokens": ["many", "times", "range", "of", "0"], "project": "spring-framework"}
{"id": 9150, "code": "\tprivate static ServletUriComponentsBuilder initFromRequest(HttpServletRequest request) {\n\t\tString scheme = request.getScheme();\n\t\tString host = request.getServerName();\n\t\tint port = request.getServerPort();\n\n\t\tServletUriComponentsBuilder builder = new ServletUriComponentsBuilder();\n\t\tbuilder.scheme(scheme);\n\t\tbuilder.host(host);\n\t\tif ((\"http\".equals(scheme) && port != 80) || (\"https\".equals(scheme) && port != 443)) {\n\t\t\tbuilder.port(port);\n\t\t}\n\t\treturn builder;\n\t}", "summary_tokens": ["initialize", "a", "builder", "with", "a", "scheme", "host", "and", "port", "but", "not", "path", "and", "query"], "project": "spring-framework"}
{"id": 4273, "code": "\tSession getOriginalSession() {\n\t\treturn this.sessions.peek();\n\t}", "summary_tokens": ["return", "an", "existing", "original", "session", "if", "any"], "project": "spring-framework"}
{"id": 762, "code": "\tpublic boolean isExternallyManagedInitMethod(String initMethod) {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\treturn (this.externallyManagedInitMethods != null &&\n\t\t\t\t\tthis.externallyManagedInitMethods.contains(initMethod));\n\t\t}\n\t}", "summary_tokens": ["determine", "if", "the", "given", "method", "name", "indicates", "an", "externally", "managed", "initialization", "method"], "project": "spring-framework"}
{"id": 6714, "code": "\tpublic String getMediaType() {\n\t\treturn this.mediaType;\n\t}", "summary_tokens": ["return", "the", "offending", "media", "type"], "project": "spring-framework"}
{"id": 7011, "code": "\tpublic final void setModulesToInstall(Class<? extends Module>... modules) {\n\t\tthis.builder.modulesToInstall(modules);\n\t}", "summary_tokens": ["specify", "one", "or", "more", "modules", "by", "class", "or", "class", "name", "in", "xml", "to", "be", "registered", "with", "the", "object", "mapper"], "project": "spring-framework"}
{"id": 2078, "code": "\tpublic void testIntroductionThrowsUncheckedException() throws Throwable {\n\t\tTestBean target = new TestBean();\n\t\ttarget.setAge(21);\n\t\tProxyFactory pc = new ProxyFactory(target);\n\n\t\t@SuppressWarnings(\"serial\")\n\t\tclass MyDi extends DelegatingIntroductionInterceptor implements TimeStamped {\n\t\t\t\n\t\t\t@Override\n\t\t\tpublic long getTimeStamp() {\n\t\t\t\tthrow new UnsupportedOperationException();\n\t\t\t}\n\t\t}\n\t\tpc.addAdvisor(new DefaultIntroductionAdvisor(new MyDi()));\n\n\t\tTimeStamped ts = (TimeStamped) createProxy(pc);\n\t\tassertThatExceptionOfType(UnsupportedOperationException.class).isThrownBy(ts::getTimeStamp);\n\t}", "summary_tokens": ["note", "that", "an", "introduction", "can", "t", "throw", "an", "unexpected", "checked", "exception", "as", "it", "s", "constrained", "by", "the", "interface"], "project": "spring-framework"}
{"id": 8116, "code": "\tdefault RequestPredicate negate() {\n\t\treturn new RequestPredicates.NegateRequestPredicate(this);\n\t}", "summary_tokens": ["return", "a", "predicate", "that", "represents", "the", "logical", "negation", "of", "this", "predicate"], "project": "spring-framework"}
{"id": 8567, "code": "\tprivate static void registerFlashMapManager(ParserContext context, @Nullable Object source) {\n\t\tif (!containsBeanInHierarchy(context, DispatcherServlet.FLASH_MAP_MANAGER_BEAN_NAME)) {\n\t\t\tRootBeanDefinition beanDef = new RootBeanDefinition(SessionFlashMapManager.class);\n\t\t\tbeanDef.setSource(source);\n\t\t\tbeanDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\t\tcontext.getRegistry().registerBeanDefinition(DispatcherServlet.FLASH_MAP_MANAGER_BEAN_NAME, beanDef);\n\t\t\tcontext.registerComponent(new BeanComponentDefinition(beanDef, DispatcherServlet.FLASH_MAP_MANAGER_BEAN_NAME));\n\t\t}\n\t}", "summary_tokens": ["registers", "an", "session", "flash", "map", "manager", "under", "a", "well", "known", "name", "unless", "already", "registered"], "project": "spring-framework"}
{"id": 3852, "code": "\tprotected Map<String, Object> doExecute(Map<String, ?> args) {\n\t\tcheckCompiled();\n\t\tMap<String, ?> params = matchInParameterValuesWithCallParameters(args);\n\t\treturn executeCallInternal(params);\n\t}", "summary_tokens": ["delegate", "method", "that", "executes", "the", "call", "using", "the", "passed", "in", "map", "of", "parameters"], "project": "spring-framework"}
{"id": 9719, "code": "\tprotected boolean isEligibleForMarshalling(String modelKey, Object value) {\n\t\tAssert.state(this.marshaller != null, \"No Marshaller set\");\n\t\tClass<?> classToCheck = value.getClass();\n\t\tif (value instanceof JAXBElement) {\n\t\t\tclassToCheck = ((JAXBElement<?>) value).getDeclaredType();\n\t\t}\n\t\treturn this.marshaller.supports(classToCheck);\n\t}", "summary_tokens": ["check", "whether", "the", "given", "value", "from", "the", "current", "view", "s", "model", "is", "eligible", "for", "marshalling", "through", "the", "configured", "marshaller"], "project": "spring-framework"}
{"id": 734, "code": "\tpublic static RegisteredBean of(ConfigurableListableBeanFactory beanFactory,\n\t\t\tString beanName) {\n\n\t\tAssert.notNull(beanFactory, \"'beanFactory' must not be null\");\n\t\tAssert.hasLength(beanName, \"'beanName' must not be empty\");\n\t\treturn new RegisteredBean(beanFactory, () -> beanName, false,\n\t\t\t\t() -> (RootBeanDefinition) beanFactory.getMergedBeanDefinition(beanName),\n\t\t\t\tnull);\n\t}", "summary_tokens": ["create", "a", "new", "registered", "bean", "instance", "for", "a", "regular", "bean"], "project": "spring-framework"}
{"id": 1266, "code": "\tpublic void setScopedProxyMode(ScopedProxyMode scopedProxyMode) {\n\t\tthis.scopeMetadataResolver = new AnnotationScopeMetadataResolver(scopedProxyMode);\n\t}", "summary_tokens": ["specify", "the", "proxy", "behavior", "for", "non", "singleton", "scoped", "beans"], "project": "spring-framework"}
{"id": 9907, "code": "\tpublic int getStreamBytesLimit() {\n\t\treturn this.streamBytesLimit;\n\t}", "summary_tokens": ["return", "the", "minimum", "number", "of", "bytes", "that", "can", "be", "sent", "over", "a", "single", "http", "streaming", "request", "before", "it", "will", "be", "closed"], "project": "spring-framework"}
{"id": 582, "code": "\tpublic void error(Problem problem) {\n\t\tthrow new BeanDefinitionParsingException(problem);\n\t}", "summary_tokens": ["throws", "a", "bean", "definition", "parsing", "exception", "detailing", "the", "error", "that", "has", "occurred"], "project": "spring-framework"}
{"id": 951, "code": "\tpublic void getCountForFactoryClass() {\n\t\tassertThat(getListableBeanFactory().getBeanNamesForType(FactoryBean.class).length == 2).as(\"Should have 2 factories, not \" +\n\t\t\t\tgetListableBeanFactory().getBeanNamesForType(FactoryBean.class).length).isTrue();\n\n\t\tassertThat(getListableBeanFactory().getBeanNamesForType(FactoryBean.class).length == 2).as(\"Should have 2 factories, not \" +\n\t\t\t\tgetListableBeanFactory().getBeanNamesForType(FactoryBean.class).length).isTrue();\n\t}", "summary_tokens": ["check", "that", "count", "refers", "to", "factory", "class", "not", "bean", "class"], "project": "spring-framework"}
{"id": 8678, "code": "\tpublic BeanNameUrlHandlerMapping beanNameHandlerMapping(\n\t\t\t@Qualifier(\"mvcConversionService\") FormattingConversionService conversionService,\n\t\t\t@Qualifier(\"mvcResourceUrlProvider\") ResourceUrlProvider resourceUrlProvider) {\n\n\t\tBeanNameUrlHandlerMapping mapping = new BeanNameUrlHandlerMapping();\n\t\tmapping.setOrder(2);\n\t\tinitHandlerMapping(mapping, conversionService, resourceUrlProvider);\n\t\treturn mapping;\n\t}", "summary_tokens": ["return", "a", "bean", "name", "url", "handler", "mapping", "ordered", "at", "0", "to", "map", "url", "paths", "to", "controller", "bean", "names"], "project": "spring-framework"}
{"id": 7987, "code": "\tpublic CorsRegistration exposedHeaders(String... headers) {\n\t\tthis.config.setExposedHeaders(Arrays.asList(headers));\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "list", "of", "response", "headers", "other", "than", "simple", "headers", "i"], "project": "spring-framework"}
{"id": 992, "code": "\tpublic CacheResolver getExceptionCacheResolver() {\n\t\treturn this.exceptionCacheResolver;\n\t}", "summary_tokens": ["return", "the", "cache", "resolver", "instance", "to", "use", "to", "resolve", "the", "cache", "to", "use", "for", "matching", "exceptions", "thrown", "by", "this", "operation"], "project": "spring-framework"}
{"id": 3877, "code": "\tprotected void checkCompiled() {\n\t\tif (!isCompiled()) {\n\t\t\tlogger.debug(\"JdbcInsert not compiled before execution - invoking compile\");\n\t\t\tcompile();\n\t\t}\n\t}", "summary_tokens": ["check", "whether", "this", "operation", "has", "been", "compiled", "already", "lazily", "compile", "it", "if", "not", "already", "compiled"], "project": "spring-framework"}
{"id": 2616, "code": "\tpublic void setClassLoader(ClassLoader classLoader) {\n\t\tthis.classLoader = classLoader;\n\t}", "summary_tokens": ["set", "the", "code", "class", "loader", "code", "in", "which", "the", "class", "will", "be", "generated"], "project": "spring-framework"}
{"id": 6844, "code": "\tpublic Encoder<?> getEncoder() {\n\t\treturn this.encoder;\n\t}", "summary_tokens": ["return", "the", "configured", "encoder", "if", "any"], "project": "spring-framework"}
{"id": 1522, "code": "\tpublic void setEnvironment(@Nullable Map<String, ?> environment) {\n\t\tthis.environment = environment;\n\t}", "summary_tokens": ["specify", "the", "environment", "for", "the", "jmx", "connector"], "project": "spring-framework"}
{"id": 903, "code": "\tprivate Object getPropertyValue(Object obj) {\n\t\t\n\t\t\n\t\t\n\t\ttry {\n\t\t\tBeanWrapperImpl beanWrapper = new BeanWrapperImpl(false);\n\t\t\tbeanWrapper.setWrappedInstance(obj);\n\t\t\treturn beanWrapper.getPropertyValue(this.sortDefinition.getProperty());\n\t\t}\n\t\tcatch (BeansException ex) {\n\t\t\tlogger.debug(\"PropertyComparator could not access property - treating as null for sorting\", ex);\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["get", "the", "sort", "definition", "s", "property", "value", "for", "the", "given", "object"], "project": "spring-framework"}
{"id": 1338, "code": "\tpublic static void setDefaultLocale(@Nullable Locale locale) {\n\t\tLocaleContextHolder.defaultLocale = locale;\n\t}", "summary_tokens": ["set", "a", "shared", "default", "locale", "at", "the", "framework", "level", "as", "an", "alternative", "to", "the", "jvm", "wide", "default", "locale"], "project": "spring-framework"}
{"id": 5109, "code": "public int getBlah() {\n  return blah_;\n}", "summary_tokens": ["code", "optional", "int", "0", "blah", "0", "code"], "project": "spring-framework"}
{"id": 1340, "code": "\tpublic static void setTimeZone(@Nullable TimeZone timeZone, boolean inheritable) {\n\t\tLocaleContext localeContext = getLocaleContext();\n\t\tLocale locale = (localeContext != null ? localeContext.getLocale() : null);\n\t\tif (timeZone != null) {\n\t\t\tlocaleContext = new SimpleTimeZoneAwareLocaleContext(locale, timeZone);\n\t\t}\n\t\telse if (locale != null) {\n\t\t\tlocaleContext = new SimpleLocaleContext(locale);\n\t\t}\n\t\telse {\n\t\t\tlocaleContext = null;\n\t\t}\n\t\tsetLocaleContext(localeContext, inheritable);\n\t}", "summary_tokens": ["associate", "the", "given", "time", "zone", "with", "the", "current", "thread", "preserving", "any", "locale", "that", "may", "have", "been", "set", "already"], "project": "spring-framework"}
{"id": 377, "code": "\tpublic String getResourceDescription() {\n\t\treturn this.resourceDescription;\n\t}", "summary_tokens": ["return", "the", "description", "of", "the", "resource", "that", "the", "bean", "definition", "came", "from", "if", "available"], "project": "spring-framework"}
{"id": 5896, "code": "\tpublic WebTestClient.BodyContentSpec isNotEmpty() {\n\t\tthis.pathHelper.assertValueIsNotEmpty(this.content);\n\t\treturn this.bodySpec;\n\t}", "summary_tokens": ["applies", "json", "path", "expectations", "helper", "assert", "value", "is", "not", "empty", "string"], "project": "spring-framework"}
{"id": 9779, "code": "\tpublic String getStompSubProtocolStatsInfo() {\n\t\treturn (this.stompSubProtocolHandler != null ? this.stompSubProtocolHandler.getStatsInfo() : \"null\");\n\t}", "summary_tokens": ["get", "stats", "about", "stomp", "related", "web", "socket", "message", "processing"], "project": "spring-framework"}
{"id": 9315, "code": "\tprotected String getOnkeydown() {\n\t\treturn this.onkeydown;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onkeydown", "attribute"], "project": "spring-framework"}
{"id": 7825, "code": "\tpublic List<String> getVariableNames() {\n\t\treturn this.variableNames;\n\t}", "summary_tokens": ["return", "the", "names", "of", "the", "variables", "in", "the", "template", "in", "order"], "project": "spring-framework"}
{"id": 2920, "code": "\tpublic final byte[] getByteArray() {\n\t\treturn this.byteArray;\n\t}", "summary_tokens": ["return", "the", "underlying", "byte", "array"], "project": "spring-framework"}
{"id": 7751, "code": "\tpublic Map<String, Object> getAttributes() {\n\t\treturn this.attributes;\n\t}", "summary_tokens": ["return", "the", "attributes", "associated", "with", "the", "request", "or", "an", "empty", "map"], "project": "spring-framework"}
{"id": 4492, "code": "\tprotected void refreshConnectionUntilSuccessful() {\n\t\tBackOffExecution execution = this.backOff.start();\n\t\twhile (isRunning()) {\n\t\t\ttry {\n\t\t\t\tif (sharedConnectionEnabled()) {\n\t\t\t\t\trefreshSharedConnection();\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tConnection con = createConnection();\n\t\t\t\t\tJmsUtils.closeConnection(con);\n\t\t\t\t}\n\t\t\t\tlogger.debug(\"Successfully refreshed JMS Connection\");\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tif (ex instanceof JMSException) {\n\t\t\t\t\tinvokeExceptionListener((JMSException) ex);\n\t\t\t\t}\n\t\t\t\tStringBuilder msg = new StringBuilder();\n\t\t\t\tmsg.append(\"Could not refresh JMS Connection for destination '\");\n\t\t\t\tmsg.append(getDestinationDescription()).append(\"' - retrying using \");\n\t\t\t\tmsg.append(execution).append(\". Cause: \");\n\t\t\t\tmsg.append(ex instanceof JMSException ? JmsUtils.buildExceptionMessage((JMSException) ex) : ex.getMessage());\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.error(msg, ex);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tlogger.error(msg);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!applyBackOffTime(execution)) {\n\t\t\t\tlogger.error(\"Stopping container for destination '\" + getDestinationDescription() +\n\t\t\t\t\t\t\"': back-off policy does not allow for further attempts.\");\n\t\t\t\tstop();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["refresh", "the", "underlying", "connection", "not", "returning", "before", "an", "attempt", "has", "been", "successful"], "project": "spring-framework"}
{"id": 2026, "code": "\tpublic String getField() {\n\t\treturn this.field;\n\t}", "summary_tokens": ["return", "the", "affected", "field", "of", "the", "object"], "project": "spring-framework"}
{"id": 1362, "code": "\tpublic void setConfigLocations(@Nullable String... locations) {\n\t\tif (locations != null) {\n\t\t\tAssert.noNullElements(locations, \"Config locations must not be null\");\n\t\t\tthis.configLocations = new String[locations.length];\n\t\t\tfor (int i = 0; i < locations.length; i++) {\n\t\t\t\tthis.configLocations[i] = resolvePath(locations[i]).trim();\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthis.configLocations = null;\n\t\t}\n\t}", "summary_tokens": ["set", "the", "config", "locations", "for", "this", "application", "context"], "project": "spring-framework"}
{"id": 7271, "code": "\tpublic static RequestAttributes getRequestAttributes() {\n\t\tRequestAttributes attributes = requestAttributesHolder.get();\n\t\tif (attributes == null) {\n\t\t\tattributes = inheritableRequestAttributesHolder.get();\n\t\t}\n\t\treturn attributes;\n\t}", "summary_tokens": ["return", "the", "request", "attributes", "currently", "bound", "to", "the", "thread"], "project": "spring-framework"}
{"id": 2951, "code": "\tpublic String getFilename() {\n\t\treturn (this.file != null ? this.file.getName() : this.filePath.getFileName().toString());\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "name", "of", "the", "file"], "project": "spring-framework"}
{"id": 3588, "code": "\tpublic final Method getMethod() {\n\t\treturn this.originalMethod;\n\t}", "summary_tokens": ["return", "the", "original", "method", "that", "this", "executor", "has", "been", "configured", "for"], "project": "spring-framework"}
{"id": 3087, "code": "\tpublic void setCaseSensitive(boolean caseSensitive) {\n\t\tthis.caseSensitive = caseSensitive;\n\t}", "summary_tokens": ["specify", "whether", "to", "perform", "pattern", "matching", "in", "a", "case", "sensitive", "fashion"], "project": "spring-framework"}
{"id": 3844, "code": "\tpublic String getCallString() {\n\t\treturn this.callString;\n\t}", "summary_tokens": ["get", "the", "call", "string", "that", "should", "be", "used", "based", "on", "parameters", "and", "meta", "data"], "project": "spring-framework"}
{"id": 8268, "code": "\tprotected Comparator<RequestMappingInfo> getMappingComparator(final ServerWebExchange exchange) {\n\t\treturn (info1, info2) -> info1.compareTo(info2, exchange);\n\t}", "summary_tokens": ["provide", "a", "comparator", "to", "sort", "request", "mapping", "infos", "matched", "to", "a", "request"], "project": "spring-framework"}
{"id": 6189, "code": "\tpublic void setTransactionName(String transactionName) {\n\t\tthis.transactionName = transactionName;\n\t}", "summary_tokens": ["specify", "the", "name", "of", "the", "transaction", "if", "any"], "project": "spring-framework"}
{"id": 4103, "code": "\tpublic void setResultType(Class<T> resultType) {\n\t\tthis.rowMapper.setRequiredType(resultType);\n\t}", "summary_tokens": ["specify", "the", "type", "that", "the", "result", "object", "is", "required", "to", "match"], "project": "spring-framework"}
{"id": 6906, "code": "\tfinal List<HttpMessageReader<?>> getObjectReaders() {\n\t\treturn this.objectReaders;\n\t}", "summary_tokens": ["return", "object", "readers", "json", "xml", "sse"], "project": "spring-framework"}
{"id": 4979, "code": "\tpublic List<Message<byte[]>> decode(ByteBuffer byteBuffer,\n\t\t\t@Nullable MultiValueMap<String, String> partialMessageHeaders) {\n\n\t\tList<Message<byte[]>> messages = new ArrayList<>();\n\t\twhile (byteBuffer.hasRemaining()) {\n\t\t\tMessage<byte[]> message = decodeMessage(byteBuffer, partialMessageHeaders);\n\t\t\tif (message != null) {\n\t\t\t\tmessages.add(message);\n\t\t\t\tskipEol(byteBuffer);\n\t\t\t\tif (!byteBuffer.hasRemaining()) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\treturn messages;\n\t}", "summary_tokens": ["decodes", "one", "or", "more", "stomp", "frames", "from", "the", "given", "buffer", "and", "returns", "a", "list", "of", "message", "messages"], "project": "spring-framework"}
{"id": 6753, "code": "\tpublic void setHttpContextFactory(BiFunction<HttpMethod, URI, HttpContext> httpContextFactory) {\n\t\tthis.httpContextFactory = httpContextFactory;\n\t}", "summary_tokens": ["configure", "a", "factory", "to", "pre", "create", "the", "http", "context", "for", "each", "request"], "project": "spring-framework"}
{"id": 771, "code": "\tpublic static Method getCurrentlyInvokedFactoryMethod() {\n\t\treturn currentlyInvokedFactoryMethod.get();\n\t}", "summary_tokens": ["return", "the", "factory", "method", "currently", "being", "invoked", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 9918, "code": "\tpublic void setSuppressCors(boolean suppressCors) {\n\t\tthis.suppressCors = suppressCors;\n\t}", "summary_tokens": ["this", "option", "can", "be", "used", "to", "disable", "automatic", "addition", "of", "cors", "headers", "for", "sock", "js", "requests"], "project": "spring-framework"}
{"id": 4868, "code": "\tpublic boolean isPreservePublishOrder() {\n\t\treturn this.preservePublishOrder;\n\t}", "summary_tokens": ["whether", "to", "ensure", "messages", "are", "received", "in", "the", "order", "of", "publication"], "project": "spring-framework"}
{"id": 6966, "code": "\tpublic Jackson2ObjectMapperBuilder defaultViewInclusion(boolean defaultViewInclusion) {\n\t\tthis.features.put(MapperFeature.DEFAULT_VIEW_INCLUSION, defaultViewInclusion);\n\t\treturn this;\n\t}", "summary_tokens": ["shortcut", "for", "mapper", "feature", "default", "view", "inclusion", "option"], "project": "spring-framework"}
{"id": 6742, "code": "\tpublic static HeadersBuilder<?> options(String uriTemplate, Object... uriVariables) {\n\t\treturn method(HttpMethod.OPTIONS, uriTemplate, uriVariables);\n\t}", "summary_tokens": ["creates", "an", "http", "options", "builder", "with", "the", "given", "string", "base", "uri", "template"], "project": "spring-framework"}
{"id": 5102, "code": "\tpublic final ArgResolver annot(Predicate<MethodParameter>... filter) {\n\t\treturn new ArgResolver(filter);\n\t}", "summary_tokens": ["filter", "on", "method", "arguments", "with", "annotation"], "project": "spring-framework"}
{"id": 9131, "code": "\tpublic boolean isResponseEncodedHtmlEscape() {\n\t\treturn (this.responseEncodedHtmlEscape == null || this.responseEncodedHtmlEscape.booleanValue());\n\t}", "summary_tokens": ["is", "html", "escaping", "using", "the", "response", "encoding", "by", "default", "if", "enabled", "only", "xml", "markup", "significant", "characters", "will", "be", "escaped", "with", "utf", "encodings"], "project": "spring-framework"}
{"id": 6262, "code": "\tpublic boolean rollbackOn(Throwable ex) {\n\t\tRollbackRuleAttribute winner = null;\n\t\tint deepest = Integer.MAX_VALUE;\n\n\t\tif (this.rollbackRules != null) {\n\t\t\tfor (RollbackRuleAttribute rule : this.rollbackRules) {\n\t\t\t\tint depth = rule.getDepth(ex);\n\t\t\t\tif (depth >= 0 && depth < deepest) {\n\t\t\t\t\tdeepest = depth;\n\t\t\t\t\twinner = rule;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tif (winner == null) {\n\t\t\treturn super.rollbackOn(ex);\n\t\t}\n\n\t\treturn !(winner instanceof NoRollbackRuleAttribute);\n\t}", "summary_tokens": ["winning", "rule", "is", "the", "shallowest", "rule", "that", "is", "the", "closest", "in", "the", "inheritance", "hierarchy", "to", "the", "exception"], "project": "spring-framework"}
{"id": 6450, "code": "\tprivate void resumeAfterBeginException(\n\t\t\tObject transaction, @Nullable SuspendedResourcesHolder suspendedResources, Throwable beginEx) {\n\n\t\ttry {\n\t\t\tresume(transaction, suspendedResources);\n\t\t}\n\t\tcatch (RuntimeException | Error resumeEx) {\n\t\t\tString exMessage = \"Inner transaction begin exception overridden by outer transaction resume exception\";\n\t\t\tlogger.error(exMessage, beginEx);\n\t\t\tthrow resumeEx;\n\t\t}\n\t}", "summary_tokens": ["resume", "outer", "transaction", "after", "inner", "transaction", "begin", "failed"], "project": "spring-framework"}
{"id": 6948, "code": "\tpublic Jackson2ObjectMapperBuilder createXmlMapper(boolean createXmlMapper) {\n\t\tthis.createXmlMapper = createXmlMapper;\n\t\treturn this;\n\t}", "summary_tokens": ["if", "set", "to", "true", "an", "xml", "mapper", "will", "be", "created", "using", "its", "default", "constructor"], "project": "spring-framework"}
{"id": 556, "code": "\tdefault Object getEarlyBeanReference(Object bean, String beanName) throws BeansException {\n\t\treturn bean;\n\t}", "summary_tokens": ["obtain", "a", "reference", "for", "early", "access", "to", "the", "specified", "bean", "typically", "for", "the", "purpose", "of", "resolving", "a", "circular", "reference"], "project": "spring-framework"}
{"id": 7830, "code": "\tpublic static String encodeAuthority(String authority, Charset charset) {\n\t\treturn encode(authority, charset, HierarchicalUriComponents.Type.AUTHORITY);\n\t}", "summary_tokens": ["encode", "the", "given", "uri", "authority", "with", "the", "given", "encoding"], "project": "spring-framework"}
{"id": 5658, "code": "\tprotected void beforeOrAfterTestClass(TestContext testContext, ClassMode requiredClassMode) throws Exception {\n\t\tAssert.notNull(testContext, \"TestContext must not be null\");\n\t\tAssert.notNull(requiredClassMode, \"requiredClassMode must not be null\");\n\n\t\tClass<?> testClass = testContext.getTestClass();\n\t\tAssert.notNull(testClass, \"The test class of the supplied TestContext must not be null\");\n\n\t\tDirtiesContext dirtiesContext = TestContextAnnotationUtils.findMergedAnnotation(testClass, DirtiesContext.class);\n\t\tboolean classAnnotated = (dirtiesContext != null);\n\t\tClassMode classMode = (classAnnotated ? dirtiesContext.classMode() : null);\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tString phase = (requiredClassMode.name().startsWith(\"BEFORE\") ? \"Before\" : \"After\");\n\t\t\tlogger.debug(String.format(\n\t\t\t\t\"%s test class: context %s, class annotated with @DirtiesContext [%s] with mode [%s].\", phase,\n\t\t\t\ttestContext, classAnnotated, classMode));\n\t\t}\n\n\t\tif (classMode == requiredClassMode) {\n\t\t\tdirtyContext(testContext, dirtiesContext.hierarchyMode());\n\t\t}\n\t}", "summary_tokens": ["perform", "the", "actual", "work", "for", "before", "test", "class", "and", "after", "test", "class", "by", "dirtying", "the", "context", "if", "appropriate", "i"], "project": "spring-framework"}
{"id": 722, "code": "\tpublic String getKeyTypeName() {\n\t\treturn this.keyTypeName;\n\t}", "summary_tokens": ["return", "the", "default", "key", "type", "name", "class", "name", "to", "be", "used", "for", "this", "map"], "project": "spring-framework"}
{"id": 6230, "code": "\tstatic TransactionDefinition withDefaults() {\n\t\treturn StaticTransactionDefinition.INSTANCE;\n\t}", "summary_tokens": ["return", "an", "unmodifiable", "transaction", "definition", "with", "defaults"], "project": "spring-framework"}
{"id": 837, "code": "\tpublic void setEntityResolver(@Nullable EntityResolver entityResolver) {\n\t\tthis.entityResolver = entityResolver;\n\t}", "summary_tokens": ["set", "a", "sax", "entity", "resolver", "to", "be", "used", "for", "parsing"], "project": "spring-framework"}
{"id": 6461, "code": "\tprivate void triggerAfterCompletion(DefaultTransactionStatus status, int completionStatus) {\n\t\tif (status.isNewSynchronization()) {\n\t\t\tList<TransactionSynchronization> synchronizations = TransactionSynchronizationManager.getSynchronizations();\n\t\t\tTransactionSynchronizationManager.clearSynchronization();\n\t\t\tif (!status.hasTransaction() || status.isNewTransaction()) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tinvokeAfterCompletion(synchronizations, completionStatus);\n\t\t\t}\n\t\t\telse if (!synchronizations.isEmpty()) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tregisterAfterCompletionWithExistingTransaction(status.getTransaction(), synchronizations);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["trigger", "after", "completion", "callbacks"], "project": "spring-framework"}
{"id": 9198, "code": "\tpublic void setExpression(String expression) {\n\t\tthis.expression = this.expressionParser.parseExpression(expression);\n\t}", "summary_tokens": ["set", "the", "expression", "to", "evaluate"], "project": "spring-framework"}
{"id": 998, "code": "\tpublic void setExceptionCacheResolver(@Nullable CacheResolver exceptionCacheResolver) {\n\t\tthis.exceptionCacheResolver = SingletonSupplier.ofNullable(exceptionCacheResolver);\n\t}", "summary_tokens": ["set", "the", "cache", "resolver", "to", "resolve", "exception", "caches"], "project": "spring-framework"}
{"id": 5903, "code": "\tpublic <T> WebTestClient.BodyContentSpec value(Consumer<T> consumer, Class<T> targetType) {\n\t\tObject value = this.pathHelper.evaluateJsonPath(this.content, targetType);\n\t\tconsumer.accept((T) value);\n\t\treturn this.bodySpec;\n\t}", "summary_tokens": ["consume", "the", "result", "of", "the", "jsonpath", "evaluation", "and", "provide", "a", "target", "class"], "project": "spring-framework"}
{"id": 7141, "code": "\tprotected MediaType handleNoMatch(NativeWebRequest webRequest, String extension)\n\t\t\tthrows HttpMediaTypeNotAcceptableException {\n\n\t\tMediaType mediaType = null;\n\t\tString mimeType = this.servletContext.getMimeType(\"file.\" + extension);\n\t\tif (StringUtils.hasText(mimeType)) {\n\t\t\tmediaType = MediaType.parseMediaType(mimeType);\n\t\t}\n\t\tif (mediaType == null || MediaType.APPLICATION_OCTET_STREAM.equals(mediaType)) {\n\t\t\tMediaType superMediaType = super.handleNoMatch(webRequest, extension);\n\t\t\tif (superMediaType != null) {\n\t\t\t\tmediaType = superMediaType;\n\t\t\t}\n\t\t}\n\t\treturn mediaType;\n\t}", "summary_tokens": ["resolve", "file", "extension", "via", "servlet", "context", "get", "mime", "type", "string", "and", "also", "delegate", "to", "base", "class", "for", "a", "potential", "org"], "project": "spring-framework"}
{"id": 9343, "code": "\tprotected int writeTagContent(TagWriter tagWriter) throws JspException {\n\t\tObject items = getItems();\n\t\tObject itemsObject = (items instanceof String ? evaluate(\"items\", items) : items);\n\n\t\tString itemValue = getItemValue();\n\t\tString itemLabel = getItemLabel();\n\t\tString valueProperty =\n\t\t\t\t(itemValue != null ? ObjectUtils.getDisplayString(evaluate(\"itemValue\", itemValue)) : null);\n\t\tString labelProperty =\n\t\t\t\t(itemLabel != null ? ObjectUtils.getDisplayString(evaluate(\"itemLabel\", itemLabel)) : null);\n\n\t\tClass<?> boundType = getBindStatus().getValueType();\n\t\tif (itemsObject == null && boundType != null && boundType.isEnum()) {\n\t\t\titemsObject = boundType.getEnumConstants();\n\t\t}\n\n\t\tif (itemsObject == null) {\n\t\t\tthrow new IllegalArgumentException(\"Attribute 'items' is required and must be a Collection, an Array or a Map\");\n\t\t}\n\n\t\tif (itemsObject.getClass().isArray()) {\n\t\t\tObject[] itemsArray = (Object[]) itemsObject;\n\t\t\tfor (int i = 0; i < itemsArray.length; i++) {\n\t\t\t\tObject item = itemsArray[i];\n\t\t\t\twriteObjectEntry(tagWriter, valueProperty, labelProperty, item, i);\n\t\t\t}\n\t\t}\n\t\telse if (itemsObject instanceof Collection) {\n\t\t\tfinal Collection<?> optionCollection = (Collection<?>) itemsObject;\n\t\t\tint itemIndex = 0;\n\t\t\tfor (Iterator<?> it = optionCollection.iterator(); it.hasNext(); itemIndex++) {\n\t\t\t\tObject item = it.next();\n\t\t\t\twriteObjectEntry(tagWriter, valueProperty, labelProperty, item, itemIndex);\n\t\t\t}\n\t\t}\n\t\telse if (itemsObject instanceof Map) {\n\t\t\tfinal Map<?, ?> optionMap = (Map<?, ?>) itemsObject;\n\t\t\tint itemIndex = 0;\n\t\t\tfor (Iterator it = optionMap.entrySet().iterator(); it.hasNext(); itemIndex++) {\n\t\t\t\tMap.Entry entry = (Map.Entry) it.next();\n\t\t\t\twriteMapEntry(tagWriter, valueProperty, labelProperty, entry, itemIndex);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"Attribute 'items' must be an array, a Collection or a Map\");\n\t\t}\n\n\t\treturn SKIP_BODY;\n\t}", "summary_tokens": ["renders", "the", "input", "type", "radio", "element", "with", "the", "configured", "set", "items", "object", "values"], "project": "spring-framework"}
{"id": 2066, "code": "\tprivate String qName(String fileSuffix) {\n\t\treturn String.format(\"%s-%s\", getClass().getSimpleName(), fileSuffix);\n\t}", "summary_tokens": ["returns", "the", "relatively", "qualified", "name", "for", "var", "file", "suffix", "var"], "project": "spring-framework"}
{"id": 5968, "code": "\tpublic ResultMatcher node(Matcher<? super Node> matcher) {\n\t\treturn result -> {\n\t\t\tString content = result.getResponse().getContentAsString();\n\t\t\tthis.xmlHelper.assertNode(content, matcher);\n\t\t};\n\t}", "summary_tokens": ["parse", "the", "response", "content", "as", "node", "and", "apply", "the", "given", "hamcrest", "matcher"], "project": "spring-framework"}
{"id": 6389, "code": "\tpublic static Function<Context, Context> getOrCreateContext() {\n\t\treturn context -> {\n\t\t\tTransactionContextHolder holder = context.get(TransactionContextHolder.class);\n\t\t\tif (holder.hasContext()) {\n\t\t\t\treturn context.put(TransactionContext.class, holder.currentContext());\n\t\t\t}\n\t\t\treturn context.put(TransactionContext.class, holder.createContext());\n\t\t};\n\t}", "summary_tokens": ["return", "a", "function", "to", "create", "or", "associate", "a", "new", "transaction", "context"], "project": "spring-framework"}
{"id": 7999, "code": "\tpublic ResourceHandlerRegistration setCacheControl(CacheControl cacheControl) {\n\t\tthis.cacheControl = cacheControl;\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "the", "cache", "control", "which", "should", "be", "used", "by", "the", "resource", "handler"], "project": "spring-framework"}
{"id": 9557, "code": "\tpublic void setStripExtension(boolean stripExtension) {\n\t\tthis.stripExtension = stripExtension;\n\t}", "summary_tokens": ["set", "whether", "file", "extensions", "should", "be", "stripped", "from", "the", "uri", "when", "generating", "the", "view", "name"], "project": "spring-framework"}
{"id": 2251, "code": "\tpublic boolean isAllowWrite() {\n\t\treturn this.mode == FieldMode.WRITE;\n\t}", "summary_tokens": ["return", "whether", "setting", "the", "value", "of", "the", "field", "should", "be", "allowed"], "project": "spring-framework"}
{"id": 2935, "code": "\tpublic int hashCode() {\n\t\treturn this.description.hashCode();\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "hash", "code", "of", "the", "underlying", "description", "string"], "project": "spring-framework"}
{"id": 2571, "code": "public static Type getReturnType(final Method method) {\n  return getType(method.getReturnType());\n}", "summary_tokens": ["returns", "the", "type", "corresponding", "to", "the", "return", "type", "of", "the", "given", "method"], "project": "spring-framework"}
{"id": 6749, "code": "\tpublic void setConnectTimeout(int timeout) {\n\t\tAssert.isTrue(timeout >= 0, \"Timeout must be a non-negative value\");\n\t\tthis.requestConfig = requestConfigBuilder().setConnectTimeout(timeout).build();\n\t}", "summary_tokens": ["set", "the", "connection", "timeout", "for", "the", "underlying", "request", "config"], "project": "spring-framework"}
{"id": 5629, "code": "\tprivate Statement withTestContextManagerCacheEviction(Statement next, Class<?> testClass) {\n\t\treturn new TestContextManagerCacheEvictor(next, testClass);\n\t}", "summary_tokens": ["wrap", "the", "supplied", "statement", "with", "a", "test", "context", "manager", "cache", "evictor", "statement"], "project": "spring-framework"}
{"id": 1676, "code": "\tpublic void setAttributeSource(JmxAttributeSource attributeSource) {\n\t\tAssert.notNull(attributeSource, \"JmxAttributeSource must not be null\");\n\t\tthis.attributeSource = attributeSource;\n\t}", "summary_tokens": ["set", "the", "implementation", "of", "the", "jmx", "attribute", "source", "interface", "to", "use", "when", "reading", "the", "source", "level", "metadata"], "project": "spring-framework"}
{"id": 3422, "code": "\tXMLEventReader getXMLEventReader() {\n\t\treturn this.eventReader;\n\t}", "summary_tokens": ["return", "the", "xmlevent", "reader", "used", "by", "this", "stax", "source"], "project": "spring-framework"}
{"id": 9046, "code": "\tprotected ModelAndView handleServletRequestBindingException(ServletRequestBindingException ex,\n\t\t\tHttpServletRequest request, HttpServletResponse response, @Nullable Object handler) throws IOException {\n\n\t\treturn null;\n\t}", "summary_tokens": ["handle", "the", "case", "when", "an", "unrecoverable", "binding", "exception", "occurs", "e"], "project": "spring-framework"}
{"id": 687, "code": "\tprotected void afterSingletonCreation(String beanName) {\n\t\tif (!this.inCreationCheckExclusions.contains(beanName) && !this.singletonsCurrentlyInCreation.remove(beanName)) {\n\t\t\tthrow new IllegalStateException(\"Singleton '\" + beanName + \"' isn't currently in creation\");\n\t\t}\n\t}", "summary_tokens": ["callback", "after", "singleton", "creation"], "project": "spring-framework"}
{"id": 3938, "code": "\tpublic void setDataSource(@Nullable DataSource dataSource) {\n\t\tif (dataSource instanceof TransactionAwareDataSourceProxy) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tthis.dataSource = ((TransactionAwareDataSourceProxy) dataSource).getTargetDataSource();\n\t\t}\n\t\telse {\n\t\t\tthis.dataSource = dataSource;\n\t\t}\n\t}", "summary_tokens": ["set", "the", "jdbc", "data", "source", "that", "this", "instance", "should", "manage", "transactions", "for"], "project": "spring-framework"}
{"id": 5534, "code": "\tdefault void prepareTestInstance(TestContext testContext) throws Exception {\n\t}", "summary_tokens": ["prepares", "the", "object", "test", "instance", "of", "the", "supplied", "test", "context", "test", "context", "mdash", "for", "example", "to", "inject", "dependencies"], "project": "spring-framework"}
{"id": 5250, "code": "\tpublic DataSource getDefaultJtaDataSource() {\n\t\treturn this.defaultJtaDataSource;\n\t}", "summary_tokens": ["return", "the", "jta", "aware", "data", "source", "that", "the", "jpa", "persistence", "provider", "is", "supposed", "to", "use", "for", "accessing", "the", "database", "if", "none", "has", "been", "specified", "in", "persistence"], "project": "spring-framework"}
{"id": 204, "code": "\tpublic static ClassFilter union(ClassFilter[] classFilters) {\n\t\tAssert.notEmpty(classFilters, \"ClassFilter array must not be empty\");\n\t\treturn new UnionClassFilter(classFilters);\n\t}", "summary_tokens": ["match", "all", "classes", "that", "i", "either", "i", "or", "all", "of", "the", "given", "class", "filters", "matches"], "project": "spring-framework"}
{"id": 7383, "code": "\tprotected ConfigurableEnvironment createEnvironment() {\n\t\treturn new StandardServletEnvironment();\n\t}", "summary_tokens": ["create", "and", "return", "a", "new", "standard", "servlet", "environment"], "project": "spring-framework"}
{"id": 9166, "code": "\tpublic final int getCacheSeconds() {\n\t\treturn this.cacheSeconds;\n\t}", "summary_tokens": ["return", "the", "number", "of", "seconds", "that", "content", "is", "cached"], "project": "spring-framework"}
{"id": 6728, "code": "\tpublic Map<String, Object> getProperties() {\n\t\treturn this.properties;\n\t}", "summary_tokens": ["return", "a", "generic", "map", "of", "properties", "that", "are", "not", "known", "ahead", "of", "time", "possibly", "null", "if", "no", "properties", "have", "been", "added"], "project": "spring-framework"}
{"id": 8394, "code": "\tpublic List<View> getDefaultViews() {\n\t\treturn this.defaultViews;\n\t}", "summary_tokens": ["return", "the", "configured", "default", "view", "s"], "project": "spring-framework"}
{"id": 6669, "code": "\tpublic void setExpires(long expires) {\n\t\tsetDate(EXPIRES, expires);\n\t}", "summary_tokens": ["set", "the", "date", "and", "time", "at", "which", "the", "message", "is", "no", "longer", "valid", "as", "specified", "by", "the", "expires", "header"], "project": "spring-framework"}
{"id": 5343, "code": "\tpublic static Connection getTargetConnection(Connection con) {\n\t\tConnection conToUse = con;\n\t\twhile (conToUse instanceof Wrapped<?>) {\n\t\t\tconToUse = ((Wrapped<Connection>) conToUse).unwrap();\n\t\t}\n\t\treturn conToUse;\n\t}", "summary_tokens": ["return", "the", "innermost", "target", "connection", "of", "the", "given", "connection"], "project": "spring-framework"}
{"id": 8879, "code": "\tpublic List<RequestCondition<?>> getConditions() {\n\t\treturn unwrap();\n\t}", "summary_tokens": ["return", "the", "underlying", "conditions", "possibly", "empty", "but", "never", "null"], "project": "spring-framework"}
{"id": 3482, "code": "\tpublic String getMessage() {\n\t\treturn toDetailedString();\n\t}", "summary_tokens": ["return", "the", "exception", "message"], "project": "spring-framework"}
{"id": 8297, "code": "\tpublic void setSessionContext(SessionAttributesHandler attributesHandler, WebSession session) {\n\t\tthis.saveModelOperation = () -> {\n\t\t\tif (getSessionStatus().isComplete()) {\n\t\t\t\tattributesHandler.cleanupAttributes(session);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tattributesHandler.storeAttributes(session, getModel().asMap());\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["provide", "the", "context", "required", "to", "apply", "save", "model", "after", "the", "controller", "method", "has", "been", "invoked"], "project": "spring-framework"}
{"id": 2070, "code": "\tpublic void testValuesStick() {\n\t\tint age1 = 33;\n\t\tint age2 = 37;\n\t\tString name = \"tony\";\n\n\t\tTestBean target1 = new TestBean();\n\t\ttarget1.setAge(age1);\n\t\tProxyFactory pf1 = new ProxyFactory(target1);\n\t\tpf1.addAdvisor(new DefaultPointcutAdvisor(new NopInterceptor()));\n\t\tpf1.addAdvisor(new DefaultPointcutAdvisor(new TimestampIntroductionInterceptor()));\n\t\tITestBean tb = (ITestBean) pf1.getProxy();\n\n\t\tassertThat(tb.getAge()).isEqualTo(age1);\n\t\ttb.setAge(age2);\n\t\tassertThat(tb.getAge()).isEqualTo(age2);\n\t\tassertThat(tb.getName()).isNull();\n\t\ttb.setName(name);\n\t\tassertThat(tb.getName()).isEqualTo(name);\n\t}", "summary_tokens": ["simple", "test", "that", "if", "we", "set", "values", "we", "can", "get", "them", "out", "again"], "project": "spring-framework"}
{"id": 2810, "code": "\tpublic void setMaxInMemorySize(int byteCount) {\n\t\tthis.maxInMemorySize = byteCount;\n\t}", "summary_tokens": ["configure", "a", "limit", "on", "the", "number", "of", "bytes", "that", "can", "be", "buffered", "whenever", "the", "input", "stream", "needs", "to", "be", "aggregated"], "project": "spring-framework"}
{"id": 1220, "code": "\tprivate void updateCacheNames(String name) {\n\t\tSet<String> cacheNames = new LinkedHashSet<>(this.cacheNames);\n\t\tcacheNames.add(name);\n\t\tthis.cacheNames = Collections.unmodifiableSet(cacheNames);\n\t}", "summary_tokens": ["update", "the", "exposed", "cache", "names", "set", "with", "the", "given", "name"], "project": "spring-framework"}
{"id": 6853, "code": "\tprotected void logWarningIfNecessary(Type type, @Nullable Throwable cause) {\n\t\tif (cause == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tString msg = \"Failed to evaluate Jackson \" + (type instanceof JavaType ? \"de\" : \"\") +\n\t\t\t\t\t\"serialization for type [\" + type + \"]\";\n\t\t\tlogger.debug(msg, cause);\n\t\t}\n\t}", "summary_tokens": ["determine", "whether", "to", "log", "the", "given", "exception", "coming", "from", "a", "object", "mapper", "can", "deserialize", "object", "mapper", "can", "serialize", "check"], "project": "spring-framework"}
{"id": 3986, "code": "\tpublic void initConnection() throws SQLException {\n\t\tif (getUrl() == null) {\n\t\t\tthrow new IllegalStateException(\"'url' property is required for lazily initializing a Connection\");\n\t\t}\n\t\tsynchronized (this.connectionMonitor) {\n\t\t\tcloseConnection();\n\t\t\tthis.target = getConnectionFromDriver(getUsername(), getPassword());\n\t\t\tprepareConnection(this.target);\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Established shared JDBC Connection: \" + this.target);\n\t\t\t}\n\t\t\tthis.connection = (isSuppressClose() ? getCloseSuppressingConnectionProxy(this.target) : this.target);\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "underlying", "connection", "via", "the", "driver", "manager"], "project": "spring-framework"}
{"id": 8628, "code": "\tpublic ResourceHandlerRegistration addResourceLocations(Resource... locations) {\n\t\tthis.locationsResources.addAll(Arrays.asList(locations));\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "locations", "to", "serve", "static", "resources", "from", "based", "on", "pre", "resolved", "resource", "references"], "project": "spring-framework"}
{"id": 7850, "code": "\tprotected String getDefaultEncoding() {\n\t\treturn this.defaultEncoding;\n\t}", "summary_tokens": ["return", "the", "default", "character", "encoding", "to", "use", "for", "url", "decoding"], "project": "spring-framework"}
{"id": 4725, "code": "\tpublic Object resolveArgument(MethodParameter parameter, Message<?> message) throws Exception {\n\t\tHandlerMethodArgumentResolver resolver = getArgumentResolver(parameter);\n\t\tif (resolver == null) {\n\t\t\tthrow new IllegalArgumentException(\"Unsupported parameter type [\" +\n\t\t\t\t\tparameter.getParameterType().getName() + \"]. supportsParameter should be called first.\");\n\t\t}\n\t\treturn resolver.resolveArgument(parameter, message);\n\t}", "summary_tokens": ["iterate", "over", "registered", "handler", "method", "argument", "resolver", "handler", "method", "argument", "resolvers", "and", "invoke", "the", "one", "that", "supports", "it"], "project": "spring-framework"}
{"id": 6103, "code": "\tpublic ResultMatcher isPreconditionRequired() {\n\t\treturn matcher(HttpStatus.valueOf(428));\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2218, "code": "\tpublic void add(String factoryType, String... factoryImplementations) {\n\t\tList<String> implementations = this.factories.computeIfAbsent(factoryType, key -> new ArrayList<>());\n\t\tfor (String factoryImplementation : factoryImplementations) {\n\t\t\timplementations.add(factoryImplementation);\n\t\t}\n\t}", "summary_tokens": ["add", "factory", "implementations", "to", "this", "instance"], "project": "spring-framework"}
{"id": 6662, "code": "\tpublic long getContentLength() {\n\t\tString value = getFirst(CONTENT_LENGTH);\n\t\treturn (value != null ? Long.parseLong(value) : -1);\n\t}", "summary_tokens": ["return", "the", "length", "of", "the", "body", "in", "bytes", "as", "specified", "by", "the", "content", "length", "header"], "project": "spring-framework"}
{"id": 2312, "code": "static int computeParameterAnnotationsSize(\n    final String attributeName,\n    final AnnotationWriter[] annotationWriters,\n    final int annotableParameterCount) {\n    \n    \n    \n    \n    \n  int attributeSize = 7 + 2 * annotableParameterCount;\n  for (int i = 0; i < annotableParameterCount; ++i) {\n    AnnotationWriter annotationWriter = annotationWriters[i];\n    attributeSize +=\n        annotationWriter == null ? 0 : annotationWriter.computeAnnotationsSize(attributeName) - 8;\n  }\n  return attributeSize;\n}", "summary_tokens": ["returns", "the", "size", "of", "a", "runtime", "in", "visible", "parameter", "annotations", "attribute", "containing", "all", "the", "annotation", "lists", "from", "the", "given", "annotation", "writer", "sub", "array"], "project": "spring-framework"}
{"id": 6952, "code": "\tpublic Jackson2ObjectMapperBuilder locale(String localeString) {\n\t\tthis.locale = StringUtils.parseLocale(localeString);\n\t\treturn this;\n\t}", "summary_tokens": ["override", "the", "default", "locale", "to", "use", "for", "formatting"], "project": "spring-framework"}
{"id": 4319, "code": "\tpublic Destination getDefaultDestination() {\n\t\treturn (this.defaultDestination instanceof Destination ? (Destination) this.defaultDestination : null);\n\t}", "summary_tokens": ["return", "the", "destination", "to", "be", "used", "on", "send", "receive", "operations", "that", "do", "not", "have", "a", "destination", "parameter"], "project": "spring-framework"}
{"id": 6874, "code": "\tpublic static FileStorage fromPath(Path path) throws IOException {\n\t\tif (!Files.exists(path)) {\n\t\t\tFiles.createDirectory(path);\n\t\t}\n\t\treturn new PathFileStorage(path);\n\t}", "summary_tokens": ["create", "a", "new", "file", "storage", "from", "a", "user", "specified", "path"], "project": "spring-framework"}
{"id": 6576, "code": "\tpublic void transactionAttributeDeclaredOnClassMethod() throws Exception {\n\t\tMethod classMethod = ITestBean1.class.getMethod(\"getAge\");\n\n\t\tAnnotationTransactionAttributeSource atas = new AnnotationTransactionAttributeSource();\n\t\tTransactionAttribute actual = atas.getTransactionAttribute(classMethod, TestBean1.class);\n\n\t\tRuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute();\n\t\trbta.getRollbackRules().add(new RollbackRuleAttribute(Exception.class));\n\t\tassertThat(((RuleBasedTransactionAttribute) actual).getRollbackRules()).isEqualTo(rbta.getRollbackRules());\n\t}", "summary_tokens": ["test", "the", "important", "case", "where", "the", "invocation", "is", "on", "a", "proxied", "interface", "method", "but", "the", "attribute", "is", "defined", "on", "the", "target", "class"], "project": "spring-framework"}
{"id": 2099, "code": "\tvoid bogusParentageFromParentFactory() {\n\t\tDefaultListableBeanFactory parent = new DefaultListableBeanFactory();\n\t\tnew XmlBeanDefinitionReader(parent).loadBeanDefinitions(PARENT_CONTEXT);\n\t\tDefaultListableBeanFactory child = new DefaultListableBeanFactory(parent);\n\t\tnew XmlBeanDefinitionReader(child).loadBeanDefinitions(CHILD_CONTEXT);\n\t\tassertThatExceptionOfType(BeanDefinitionStoreException.class).isThrownBy(() ->\n\t\t\t\tchild.getBean(\"bogusParent\", TestBean.class))\n\t\t\t.withMessageContaining(\"bogusParent\")\n\t\t\t.withCauseInstanceOf(NoSuchBeanDefinitionException.class);\n\t}", "summary_tokens": ["check", "that", "a", "prototype", "can", "t", "inherit", "from", "a", "bogus", "parent"], "project": "spring-framework"}
{"id": 6794, "code": "\tpublic LoopResources getLoopResources() {\n\t\tAssert.state(this.loopResources != null, \"LoopResources not initialized yet\");\n\t\treturn this.loopResources;\n\t}", "summary_tokens": ["return", "the", "configured", "loop", "resources"], "project": "spring-framework"}
{"id": 4820, "code": "\tpublic void sessionCompleted() {\n\t\tsynchronized (getSessionMutex()) {\n\t\t\tif (!isSessionCompleted()) {\n\t\t\t\texecuteDestructionCallbacks();\n\t\t\t\tthis.attributes.put(SESSION_COMPLETED_NAME, Boolean.TRUE);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["invoked", "when", "the", "session", "is", "completed"], "project": "spring-framework"}
{"id": 9472, "code": "\tprivate boolean forceMultiple() throws JspException {\n\t\tBindStatus bindStatus = getBindStatus();\n\t\tClass<?> valueType = bindStatus.getValueType();\n\t\tif (valueType != null && typeRequiresMultiple(valueType)) {\n\t\t\treturn true;\n\t\t}\n\t\telse if (bindStatus.getEditor() != null) {\n\t\t\tObject editorValue = bindStatus.getEditor().getValue();\n\t\t\tif (editorValue != null && typeRequiresMultiple(editorValue.getClass())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["returns", "true", "if", "the", "bound", "value", "requires", "the", "resultant", "select", "tag", "to", "be", "multi", "select"], "project": "spring-framework"}
{"id": 4862, "code": "\tprotected String[] resolveEmbeddedValuesInDestinations(String[] destinations) {\n\t\tif (this.valueResolver == null) {\n\t\t\treturn destinations;\n\t\t}\n\t\tString[] result = new String[destinations.length];\n\t\tfor (int i = 0; i < destinations.length; i++) {\n\t\t\tresult[i] = this.valueResolver.resolveStringValue(destinations[i]);\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["resolve", "placeholder", "values", "in", "the", "given", "array", "of", "destinations"], "project": "spring-framework"}
{"id": 4027, "code": "\tpublic void setDatabaseCleaner(DatabasePopulator databaseCleaner) {\n\t\tthis.databaseCleaner = databaseCleaner;\n\t}", "summary_tokens": ["set", "the", "database", "populator", "to", "execute", "during", "the", "bean", "destruction", "phase", "cleaning", "up", "the", "database", "and", "leaving", "it", "in", "a", "known", "state", "for", "others"], "project": "spring-framework"}
{"id": 2032, "code": "\tpublic <T> T unwrap(Class<T> sourceType) {\n\t\tif (sourceType.isInstance(this.source)) {\n\t\t\treturn sourceType.cast(this.source);\n\t\t}\n\t\telse if (this.source instanceof Throwable) {\n\t\t\tThrowable cause = ((Throwable) this.source).getCause();\n\t\t\tif (sourceType.isInstance(cause)) {\n\t\t\t\treturn sourceType.cast(cause);\n\t\t\t}\n\t\t}\n\t\tthrow new IllegalArgumentException(\"No source object of the given type available: \" + sourceType);\n\t}", "summary_tokens": ["unwrap", "the", "source", "behind", "this", "error", "possibly", "an", "exception", "typically", "org"], "project": "spring-framework"}
{"id": 8578, "code": "\tpublic ContentNegotiationConfigurer mediaType(String extension, MediaType mediaType) {\n\t\tthis.mediaTypes.put(extension, mediaType);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "mapping", "from", "a", "key", "extracted", "from", "a", "path", "extension", "or", "a", "query", "parameter", "to", "a", "media", "type"], "project": "spring-framework"}
{"id": 7021, "code": "\tpublic void setValue(Object value) {\n\t\tthis.value = value;\n\t}", "summary_tokens": ["modify", "the", "pojo", "to", "serialize"], "project": "spring-framework"}
{"id": 3490, "code": "\tpublic static char toChar(TypeConverter typeConverter, TypedValue typedValue) {\n\t\treturn convertValue(typeConverter, typedValue, Character.class);\n\t}", "summary_tokens": ["attempt", "to", "convert", "a", "typed", "value", "to", "a", "char", "using", "the", "supplied", "type", "converter"], "project": "spring-framework"}
{"id": 2390, "code": "public RecordComponentVisitor visitRecordComponent(\n    final String name, final String descriptor, final String signature) {\n  if (api < Opcodes.ASM8) {\n    throw new UnsupportedOperationException(\"Record requires ASM8\");\n  }\n  if (cv != null) {\n    return cv.visitRecordComponent(name, descriptor, signature);\n  }\n  return null;\n}", "summary_tokens": ["visits", "a", "record", "component", "of", "the", "class"], "project": "spring-framework"}
{"id": 3267, "code": "\tpublic static URL extractArchiveURL(URL jarUrl) throws MalformedURLException {\n\t\tString urlFile = jarUrl.getFile();\n\n\t\tint endIndex = urlFile.indexOf(WAR_URL_SEPARATOR);\n\t\tif (endIndex != -1) {\n\t\t\t\n\t\t\tString warFile = urlFile.substring(0, endIndex);\n\t\t\tif (URL_PROTOCOL_WAR.equals(jarUrl.getProtocol())) {\n\t\t\t\treturn new URL(warFile);\n\t\t\t}\n\t\t\tint startIndex = warFile.indexOf(WAR_URL_PREFIX);\n\t\t\tif (startIndex != -1) {\n\t\t\t\treturn new URL(warFile.substring(startIndex + WAR_URL_PREFIX.length()));\n\t\t\t}\n\t\t}\n\n\t\t\n\t\treturn extractJarFileURL(jarUrl);\n\t}", "summary_tokens": ["extract", "the", "url", "for", "the", "outermost", "archive", "from", "the", "given", "jar", "war", "url", "which", "may", "point", "to", "a", "resource", "in", "a", "jar", "file", "or", "to", "a", "jar", "file", "itself"], "project": "spring-framework"}
{"id": 4727, "code": "\tpublic void setLogger(Log logger) {\n\t\tthis.logger = logger;\n\t}", "summary_tokens": ["set", "an", "alternative", "logger", "to", "use", "than", "the", "one", "based", "on", "the", "class", "name"], "project": "spring-framework"}
{"id": 4843, "code": "\tpublic void send(Message<?> message) {\n\t\tAssert.notNull(message, \"Message is required\");\n\t\tString destination = SimpMessageHeaderAccessor.getDestination(message.getHeaders());\n\t\tif (destination != null) {\n\t\t\tsendInternal(message);\n\t\t\treturn;\n\t\t}\n\t\tdoSend(getRequiredDefaultDestination(), message);\n\t}", "summary_tokens": ["if", "the", "headers", "of", "the", "given", "message", "already", "contain", "a", "org"], "project": "spring-framework"}
{"id": 2635, "code": "public static void hash_code(CodeEmitter e, Type type, int multiplier, final Customizer customizer) {\n    hash_code(e, type, multiplier, CustomizerRegistry.singleton(customizer));\n}", "summary_tokens": ["use", "hash", "code", "code", "emitter", "type", "int", "customizer", "registry", "instead"], "project": "spring-framework"}
{"id": 7752, "code": "\tpublic Object getBodyValue() {\n\t\treturn this.bodyValue;\n\t}", "summary_tokens": ["return", "the", "request", "body", "as", "a", "value", "to", "be", "serialized", "if", "set"], "project": "spring-framework"}
{"id": 4708, "code": "\tpublic void setReturnValueHandlers(@Nullable List<HandlerMethodReturnValueHandler> returnValueHandlers) {\n\t\tif (returnValueHandlers == null) {\n\t\t\tthis.returnValueHandlers.clear();\n\t\t\treturn;\n\t\t}\n\t\tthis.returnValueHandlers.addHandlers(returnValueHandlers);\n\t}", "summary_tokens": ["configure", "the", "complete", "list", "of", "supported", "return", "value", "types", "effectively", "overriding", "the", "ones", "configured", "by", "default"], "project": "spring-framework"}
{"id": 7755, "code": "\tpublic byte[] getContentAsByteArray() {\n\t\treturn this.cachedContent.toByteArray();\n\t}", "summary_tokens": ["return", "the", "cached", "request", "content", "as", "a", "byte", "array"], "project": "spring-framework"}
{"id": 7685, "code": "\tdefault <T> T getRequiredAttribute(String name) {\n\t\tT value = getAttribute(name);\n\t\tAssert.notNull(value, () -> \"Required attribute '\" + name + \"' is missing.\");\n\t\treturn value;\n\t}", "summary_tokens": ["return", "the", "session", "attribute", "value", "or", "if", "not", "present", "raise", "an", "illegal", "argument", "exception"], "project": "spring-framework"}
{"id": 2079, "code": "\tpublic void testCannotAddIntroductionAdviceToIntroduceClass() throws Throwable {\n\t\tTestBean target = new TestBean();\n\t\ttarget.setAge(21);\n\t\tProxyFactory pc = new ProxyFactory(target);\n\t\tassertThatIllegalArgumentException().as(\"Shouldn't be able to add introduction advice that introduces a class, rather than an interface\").isThrownBy(() ->\n\t\t\t\tpc.addAdvisor(0, new DefaultIntroductionAdvisor(new TimestampIntroductionInterceptor(), TestBean.class)))\n\t\t\t.withMessageContaining(\"interface\");\n\t\t\n\t\tITestBean proxied = (ITestBean) createProxy(pc);\n\t\tassertThat(proxied.getAge()).isEqualTo(target.getAge());\n\t}", "summary_tokens": ["should", "only", "be", "able", "to", "introduce", "interfaces", "not", "classes"], "project": "spring-framework"}
{"id": 9766, "code": "\tpublic AsyncTaskExecutor getTaskExecutor() {\n\t\treturn this.taskExecutor;\n\t}", "summary_tokens": ["return", "the", "configured", "async", "task", "executor"], "project": "spring-framework"}
{"id": 6481, "code": "\tpublic void releaseHeldSavepoint() throws TransactionException {\n\t\tObject savepoint = getSavepoint();\n\t\tif (savepoint == null) {\n\t\t\tthrow new TransactionUsageException(\n\t\t\t\t\t\"Cannot release savepoint - no savepoint associated with current transaction\");\n\t\t}\n\t\tgetSavepointManager().releaseSavepoint(savepoint);\n\t\tsetSavepoint(null);\n\t}", "summary_tokens": ["release", "the", "savepoint", "that", "is", "held", "for", "the", "transaction"], "project": "spring-framework"}
{"id": 1490, "code": "\tpublic void setRoundingMode(RoundingMode roundingMode) {\n\t\tthis.roundingMode = roundingMode;\n\t}", "summary_tokens": ["specify", "the", "rounding", "mode", "to", "use", "for", "decimal", "parsing"], "project": "spring-framework"}
{"id": 8489, "code": "\tpublic void setDetectAllViewResolvers(boolean detectAllViewResolvers) {\n\t\tthis.detectAllViewResolvers = detectAllViewResolvers;\n\t}", "summary_tokens": ["set", "whether", "to", "detect", "all", "view", "resolver", "beans", "in", "this", "servlet", "s", "context"], "project": "spring-framework"}
{"id": 6919, "code": "\tvoid setPartWritersSupplier(Supplier<List<HttpMessageWriter<?>>> supplier) {\n\t\tthis.partWritersSupplier = supplier;\n\t\tinitTypedWriters();\n\t}", "summary_tokens": ["set", "a", "supplier", "for", "part", "writers", "to", "use", "when", "multipart", "codecs", "are", "not", "explicitly", "configured"], "project": "spring-framework"}
{"id": 9598, "code": "\tpublic void setBundleClassLoader(ClassLoader classLoader) {\n\t\tthis.bundleClassLoader = classLoader;\n\t}", "summary_tokens": ["set", "the", "class", "loader", "to", "load", "resource", "bundles", "with"], "project": "spring-framework"}
{"id": 15, "code": "\tprivate void maybeBindAnnotationsFromPointcutExpression() {\n\t\tList<String> varNames = new ArrayList<>();\n\t\tString[] tokens = StringUtils.tokenizeToStringArray(this.pointcutExpression, \" \");\n\t\tfor (int i = 0; i < tokens.length; i++) {\n\t\t\tString toMatch = tokens[i];\n\t\t\tint firstParenIndex = toMatch.indexOf('(');\n\t\t\tif (firstParenIndex != -1) {\n\t\t\t\ttoMatch = toMatch.substring(0, firstParenIndex);\n\t\t\t}\n\t\t\tif (singleValuedAnnotationPcds.contains(toMatch)) {\n\t\t\t\tPointcutBody body = getPointcutBody(tokens, i);\n\t\t\t\ti += body.numTokensConsumed;\n\t\t\t\tString varName = maybeExtractVariableName(body.text);\n\t\t\t\tif (varName != null) {\n\t\t\t\t\tvarNames.add(varName);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (tokens[i].startsWith(\"@args(\") || tokens[i].equals(\"@args\")) {\n\t\t\t\tPointcutBody body = getPointcutBody(tokens, i);\n\t\t\t\ti += body.numTokensConsumed;\n\t\t\t\tmaybeExtractVariableNamesFromArgs(body.text, varNames);\n\t\t\t}\n\t\t}\n\n\t\tbindAnnotationsFromVarNames(varNames);\n\t}", "summary_tokens": ["parse", "the", "string", "pointcut", "expression", "looking", "for", "0", "this", "0", "target", "0", "args", "0", "within", "0", "withincode", "0", "annotation"], "project": "spring-framework"}
{"id": 9200, "code": "\tpublic void setScope(String scope) {\n\t\tthis.scope = TagUtils.getScope(scope);\n\t}", "summary_tokens": ["set", "the", "scope", "to", "export", "the", "evaluation", "result", "to"], "project": "spring-framework"}
{"id": 1081, "code": "\tpublic final void execute(JobExecutionContext context) throws JobExecutionException {\n\t\ttry {\n\t\t\tBeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this);\n\t\t\tMutablePropertyValues pvs = new MutablePropertyValues();\n\t\t\tpvs.addPropertyValues(context.getScheduler().getContext());\n\t\t\tpvs.addPropertyValues(context.getMergedJobDataMap());\n\t\t\tbw.setPropertyValues(pvs, true);\n\t\t}\n\t\tcatch (SchedulerException ex) {\n\t\t\tthrow new JobExecutionException(ex);\n\t\t}\n\t\texecuteInternal(context);\n\t}", "summary_tokens": ["this", "implementation", "applies", "the", "passed", "in", "job", "data", "map", "as", "bean", "property", "values", "and", "delegates", "to", "execute", "internal", "afterwards"], "project": "spring-framework"}
{"id": 2708, "code": "\tpublic static boolean isKotlinPresent() {\n\t\treturn kotlinPresent;\n\t}", "summary_tokens": ["determine", "whether", "kotlin", "is", "present", "in", "general"], "project": "spring-framework"}
{"id": 8479, "code": "\tpublic void setMaxBinaryMessageBufferSize(Integer bufferSize) {\n\t\tthis.maxBinaryMessageBufferSize = bufferSize;\n\t}", "summary_tokens": ["exposes", "the", "underlying", "config", "option", "on", "jakarta"], "project": "spring-framework"}
{"id": 1324, "code": "\tprotected void onApplicationEventInternal(ApplicationEvent event) {\n\t\tif (this.delegate == null) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Must specify a delegate object or override the onApplicationEventInternal method\");\n\t\t}\n\t\tthis.delegate.onApplicationEvent(event);\n\t}", "summary_tokens": ["actually", "process", "the", "event", "after", "having", "filtered", "according", "to", "the", "desired", "event", "source", "already"], "project": "spring-framework"}
{"id": 7442, "code": "\tpublic Map<String, CorsConfiguration> getCorsConfigurations() {\n\t\tMap<String, CorsConfiguration> result = CollectionUtils.newHashMap(this.corsConfigurations.size());\n\t\tthis.corsConfigurations.forEach((pattern, config) -> result.put(pattern.getPatternString(), config));\n\t\treturn Collections.unmodifiableMap(result);\n\t}", "summary_tokens": ["return", "all", "configured", "cors", "mappings"], "project": "spring-framework"}
{"id": 2895, "code": "\tpublic String toString() {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\treturn getClass().getSimpleName() + \"@\" + System.identityHashCode(this) +\n\t\t\t\t\t\" {name='\" + getName() + \"', properties=\" + getSource() + \"}\";\n\t\t}\n\t\telse {\n\t\t\treturn getClass().getSimpleName() + \" {name='\" + getName() + \"'}\";\n\t\t}\n\t}", "summary_tokens": ["produce", "concise", "output", "type", "and", "name", "if", "the", "current", "log", "level", "does", "not", "include", "debug"], "project": "spring-framework"}
{"id": 9160, "code": "\tpublic final void setSupportedMethods(@Nullable String... methods) {\n\t\tif (!ObjectUtils.isEmpty(methods)) {\n\t\t\tthis.supportedMethods = new LinkedHashSet<>(Arrays.asList(methods));\n\t\t}\n\t\telse {\n\t\t\tthis.supportedMethods = null;\n\t\t}\n\t\tinitAllowHeader();\n\t}", "summary_tokens": ["set", "the", "http", "methods", "that", "this", "content", "generator", "should", "support"], "project": "spring-framework"}
{"id": 540, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "value", "of", "this", "object", "for", "sorting", "purposes"], "project": "spring-framework"}
{"id": 3744, "code": "\tpublic Map<String, ?> matchInParameterValuesWithCallParameters(Map<String, ?> inParameters) {\n\t\tCallMetaDataProvider provider = obtainMetaDataProvider();\n\t\tif (!provider.isProcedureColumnMetaDataUsed()) {\n\t\t\treturn inParameters;\n\t\t}\n\n\t\tMap<String, String> callParameterNames = CollectionUtils.newHashMap(this.callParameters.size());\n\t\tfor (SqlParameter parameter : this.callParameters) {\n\t\t\tif (parameter.isInputValueProvided()) {\n\t\t\t\tString parameterName =  parameter.getName();\n\t\t\t\tString parameterNameToMatch = provider.parameterNameToUse(parameterName);\n\t\t\t\tif (parameterNameToMatch != null) {\n\t\t\t\t\tcallParameterNames.put(parameterNameToMatch.toLowerCase(), parameterName);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tMap<String, Object> matchedParameters = CollectionUtils.newHashMap(inParameters.size());\n\t\tinParameters.forEach((parameterName, parameterValue) -> {\n\t\t\tString parameterNameToMatch = provider.parameterNameToUse(parameterName);\n\t\t\tString callParameterName = callParameterNames.get(lowerCase(parameterNameToMatch));\n\t\t\tif (callParameterName == null) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tObject value = parameterValue;\n\t\t\t\t\tif (value instanceof SqlParameterValue) {\n\t\t\t\t\t\tvalue = ((SqlParameterValue) value).getValue();\n\t\t\t\t\t}\n\t\t\t\t\tif (value != null) {\n\t\t\t\t\t\tlogger.debug(\"Unable to locate the corresponding IN or IN-OUT parameter for \\\"\" +\n\t\t\t\t\t\t\t\tparameterName + \"\\\" in the parameters used: \" + callParameterNames.keySet());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tmatchedParameters.put(callParameterName, parameterValue);\n\t\t\t}\n\t\t});\n\n\t\tif (matchedParameters.size() < callParameterNames.size()) {\n\t\t\tfor (String parameterName : callParameterNames.keySet()) {\n\t\t\t\tString parameterNameToMatch = provider.parameterNameToUse(parameterName);\n\t\t\t\tString callParameterName = callParameterNames.get(lowerCase(parameterNameToMatch));\n\t\t\t\tif (!matchedParameters.containsKey(callParameterName) && logger.isInfoEnabled()) {\n\t\t\t\t\tlogger.info(\"Unable to locate the corresponding parameter value for '\" + parameterName +\n\t\t\t\t\t\t\t\"' within the parameter values provided: \" + inParameters.keySet());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Matching \" + inParameters.keySet() + \" with \" + callParameterNames.values());\n\t\t\tlogger.debug(\"Found match for \" + matchedParameters.keySet());\n\t\t}\n\t\treturn matchedParameters;\n\t}", "summary_tokens": ["match", "input", "parameter", "values", "with", "the", "parameters", "declared", "to", "be", "used", "in", "the", "call"], "project": "spring-framework"}
{"id": 1491, "code": "\tpublic void setCurrency(Currency currency) {\n\t\tthis.currency = currency;\n\t}", "summary_tokens": ["specify", "the", "currency", "if", "known"], "project": "spring-framework"}
{"id": 8371, "code": "\tstatic RedirectBuilder redirectTo(String url) {\n\t\treturn new DefaultRenderingBuilder(new RedirectView(url));\n\t}", "summary_tokens": ["create", "a", "new", "builder", "for", "a", "redirect", "through", "a", "redirect", "view"], "project": "spring-framework"}
{"id": 4690, "code": "\tpublic void setCustomArgumentResolvers(List<HandlerMethodArgumentResolver> customArgumentResolvers) {\n\t\tthis.customArgumentResolvers = customArgumentResolvers;\n\t}", "summary_tokens": ["set", "the", "list", "of", "custom", "handler", "method", "argument", "resolver", "s", "that", "will", "be", "used", "after", "resolvers", "for", "supported", "argument", "type"], "project": "spring-framework"}
{"id": 9643, "code": "\tpublic void setLocation(Resource location) {\n\t\tthis.location = location;\n\t}", "summary_tokens": ["set", "the", "location", "of", "the", "xml", "file", "that", "defines", "the", "view", "beans"], "project": "spring-framework"}
{"id": 1251, "code": "\tprivate static Environment getOrCreateEnvironment(BeanDefinitionRegistry registry) {\n\t\tAssert.notNull(registry, \"BeanDefinitionRegistry must not be null\");\n\t\tif (registry instanceof EnvironmentCapable) {\n\t\t\treturn ((EnvironmentCapable) registry).getEnvironment();\n\t\t}\n\t\treturn new StandardEnvironment();\n\t}", "summary_tokens": ["get", "the", "environment", "from", "the", "given", "registry", "if", "possible", "otherwise", "return", "a", "new", "standard", "environment"], "project": "spring-framework"}
{"id": 5882, "code": "\tpublic WebTestClient.ResponseSpec exists(String name) {\n\t\tif (!getHeaders().containsKey(name)) {\n\t\t\tString message = getMessage(name) + \" does not exist\";\n\t\t\tthis.exchangeResult.assertWithDiagnostics(() -> AssertionErrors.fail(message));\n\t\t}\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["expect", "that", "the", "header", "with", "the", "given", "name", "is", "present"], "project": "spring-framework"}
{"id": 4981, "code": "\tprotected void skipEol(ByteBuffer byteBuffer) {\n\t\twhile (true) {\n\t\t\tif (!tryConsumeEndOfLine(byteBuffer)) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["skip", "one", "ore", "more", "eol", "characters", "at", "the", "start", "of", "the", "given", "byte", "buffer"], "project": "spring-framework"}
{"id": 5833, "code": "\tpublic static RequestMatcher anything() {\n\t\treturn request -> {};\n\t}", "summary_tokens": ["match", "to", "any", "request"], "project": "spring-framework"}
{"id": 6037, "code": "\tpublic ResultMatcher size(int size) {\n\t\treturn result -> {\n\t\t\tModelAndView mav = getModelAndView(result);\n\t\t\tint actual = 0;\n\t\t\tfor (String key : mav.getModel().keySet()) {\n\t\t\t\tif (!key.startsWith(BindingResult.MODEL_KEY_PREFIX)) {\n\t\t\t\t\tactual++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tassertEquals(\"Model size\", size, actual);\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "number", "of", "model", "attributes"], "project": "spring-framework"}
{"id": 4393, "code": "\tpublic String getDestinationName() {\n\t\treturn (this.destination instanceof String ? (String) this.destination : null);\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "destination", "to", "receive", "messages", "from"], "project": "spring-framework"}
{"id": 5196, "code": "\tprotected SessionFactory lookupSessionFactory() {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Using SessionFactory '\" + getSessionFactoryBeanName() + \"' for OpenSessionInViewFilter\");\n\t\t}\n\t\tWebApplicationContext wac = WebApplicationContextUtils.getRequiredWebApplicationContext(getServletContext());\n\t\treturn wac.getBean(getSessionFactoryBeanName(), SessionFactory.class);\n\t}", "summary_tokens": ["look", "up", "the", "session", "factory", "that", "this", "filter", "should", "use"], "project": "spring-framework"}
{"id": 4878, "code": "\tpublic void setHeartbeatValue(@Nullable long[] heartbeat) {\n\t\tif (heartbeat != null && (heartbeat.length != 2 || heartbeat[0] < 0 || heartbeat[1] < 0)) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid heart-beat: \" + Arrays.toString(heartbeat));\n\t\t}\n\t\tthis.heartbeatValue = heartbeat;\n\t}", "summary_tokens": ["configure", "the", "value", "for", "the", "heart", "beat", "settings"], "project": "spring-framework"}
{"id": 4563, "code": "\tpublic String getCorrelationId() {\n\t\treturn (String) getHeader(JmsHeaders.CORRELATION_ID);\n\t}", "summary_tokens": ["return", "the", "jms", "headers", "correlation", "id", "correlation", "id"], "project": "spring-framework"}
{"id": 7736, "code": "\tpublic WebSessionStore getSessionStore() {\n\t\treturn this.sessionStore;\n\t}", "summary_tokens": ["return", "the", "configured", "web", "session", "store"], "project": "spring-framework"}
{"id": 684, "code": "\tprotected void removeSingleton(String beanName) {\n\t\tsynchronized (this.singletonObjects) {\n\t\t\tthis.singletonObjects.remove(beanName);\n\t\t\tthis.singletonFactories.remove(beanName);\n\t\t\tthis.earlySingletonObjects.remove(beanName);\n\t\t\tthis.registeredSingletons.remove(beanName);\n\t\t}\n\t}", "summary_tokens": ["remove", "the", "bean", "with", "the", "given", "name", "from", "the", "singleton", "cache", "of", "this", "factory", "to", "be", "able", "to", "clean", "up", "eager", "registration", "of", "a", "singleton", "if", "creation", "failed"], "project": "spring-framework"}
{"id": 9258, "code": "\tprotected String getName() throws JspException {\n\t\treturn getPropertyPath();\n\t}", "summary_tokens": ["get", "the", "value", "for", "the", "html", "name", "attribute"], "project": "spring-framework"}
{"id": 8596, "code": "\tpublic CorsRegistration addMapping(String pathPattern) {\n\t\tCorsRegistration registration = new CorsRegistration(pathPattern);\n\t\tthis.registrations.add(registration);\n\t\treturn registration;\n\t}", "summary_tokens": ["enable", "cross", "origin", "request", "handling", "for", "the", "specified", "path", "pattern"], "project": "spring-framework"}
{"id": 1642, "code": "\tpublic Object getDefaultValue() {\n\t\treturn this.defaultValue;\n\t}", "summary_tokens": ["return", "the", "default", "value", "of", "this", "attribute"], "project": "spring-framework"}
{"id": 2735, "code": "\tpublic ReactiveAdapter getAdapter(@Nullable Class<?> reactiveType, @Nullable Object source) {\n\t\tif (this.adapters.isEmpty()) {\n\t\t\treturn null;\n\t\t}\n\n\t\tObject sourceToUse = (source instanceof Optional ? ((Optional<?>) source).orElse(null) : source);\n\t\tClass<?> clazz = (sourceToUse != null ? sourceToUse.getClass() : reactiveType);\n\t\tif (clazz == null) {\n\t\t\treturn null;\n\t\t}\n\t\tfor (ReactiveAdapter adapter : this.adapters) {\n\t\t\tif (adapter.getReactiveType() == clazz) {\n\t\t\t\treturn adapter;\n\t\t\t}\n\t\t}\n\t\tfor (ReactiveAdapter adapter : this.adapters) {\n\t\t\tif (adapter.getReactiveType().isAssignableFrom(clazz)) {\n\t\t\t\treturn adapter;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["get", "the", "adapter", "for", "the", "given", "reactive", "type"], "project": "spring-framework"}
{"id": 6067, "code": "\tpublic ResultMatcher isFound() {\n\t\treturn matcher(HttpStatus.FOUND);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 3656, "code": "\tpublic int getActualRowsAffected() {\n\t\treturn this.actual;\n\t}", "summary_tokens": ["return", "the", "number", "of", "rows", "that", "have", "actually", "been", "affected"], "project": "spring-framework"}
{"id": 9675, "code": "\tprotected Configuration obtainConfiguration() {\n\t\tConfiguration configuration = getConfiguration();\n\t\tAssert.state(configuration != null, \"No Configuration set\");\n\t\treturn configuration;\n\t}", "summary_tokens": ["obtain", "the", "free", "marker", "configuration", "for", "actual", "use"], "project": "spring-framework"}
{"id": 1615, "code": "\tprotected boolean includeWriteAttribute(Method method, String beanKey) {\n\t\treturn hasManagedAttribute(method);\n\t}", "summary_tokens": ["votes", "on", "the", "inclusion", "of", "an", "attribute", "mutator"], "project": "spring-framework"}
{"id": 7231, "code": "\tpublic void setMessageConverters(List<HttpMessageConverter<?>> messageConverters) {\n\t\tthis.messageConverters = messageConverters;\n\t}", "summary_tokens": ["set", "the", "message", "converters", "to", "use", "by", "this", "extractor"], "project": "spring-framework"}
{"id": 2770, "code": "\tpublic static <A extends Annotation> A getMergedAnnotation(AnnotatedElement element, Class<A> annotationType) {\n\t\t\n\t\tif (AnnotationFilter.PLAIN.matches(annotationType) ||\n\t\t\t\tAnnotationsScanner.hasPlainJavaAnnotationsOnly(element)) {\n\t\t\treturn element.getDeclaredAnnotation(annotationType);\n\t\t}\n\t\t\n\t\treturn getAnnotations(element)\n\t\t\t\t.get(annotationType, null, MergedAnnotationSelectors.firstDirectlyDeclared())\n\t\t\t\t.synthesize(MergedAnnotation::isPresent).orElse(null);\n\t}", "summary_tokens": ["get", "the", "first", "annotation", "of", "the", "specified", "annotation", "type", "within", "the", "annotation", "hierarchy", "em", "above", "em", "the", "supplied", "element", "merge", "that", "annotation", "s", "attributes", "with", "em", "matching", "em", "attributes", "from", "annotations", "in", "lower", "levels", "of", "the", "annotation", "hierarchy", "and", "synthesize", "the", "result", "back", "into", "an", "annotation", "of", "the", "specified", "annotation", "type"], "project": "spring-framework"}
{"id": 3370, "code": "\tpublic T obtain() {\n\t\tT instance = get();\n\t\tAssert.state(instance != null, \"No instance from Supplier\");\n\t\treturn instance;\n\t}", "summary_tokens": ["obtain", "the", "shared", "singleton", "instance", "for", "this", "supplier"], "project": "spring-framework"}
{"id": 7512, "code": "\tprotected boolean shouldNotFilterErrorDispatch() {\n\t\treturn false;\n\t}", "summary_tokens": ["returns", "false", "so", "that", "the", "filter", "may", "set", "up", "the", "request", "context", "in", "an", "error", "dispatch"], "project": "spring-framework"}
{"id": 9332, "code": "\tprotected boolean isReadonly() {\n\t\treturn this.readonly;\n\t}", "summary_tokens": ["gets", "the", "value", "of", "the", "readonly", "attribute"], "project": "spring-framework"}
{"id": 867, "code": "\tpublic void setAsText(@Nullable String text) throws IllegalArgumentException {\n\t\tProperties props = new Properties();\n\t\tif (text != null) {\n\t\t\ttry {\n\t\t\t\t\n\t\t\t\tprops.load(new ByteArrayInputStream(text.getBytes(StandardCharsets.ISO_8859_1)));\n\t\t\t}\n\t\t\tcatch (IOException ex) {\n\t\t\t\t\n\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\"Failed to parse [\" + text + \"] into Properties\", ex);\n\t\t\t}\n\t\t}\n\t\tsetValue(props);\n\t}", "summary_tokens": ["convert", "string", "into", "properties", "considering", "it", "as", "properties", "content"], "project": "spring-framework"}
{"id": 8951, "code": "\tprotected Class<?> getReturnValueType(@Nullable Object value, MethodParameter returnType) {\n\t\treturn (value != null ? value.getClass() : returnType.getParameterType());\n\t}", "summary_tokens": ["return", "the", "type", "of", "the", "value", "to", "be", "written", "to", "the", "response"], "project": "spring-framework"}
{"id": 6258, "code": "\tpublic void resolveAttributeStrings(@Nullable StringValueResolver resolver) {\n\t\tString timeoutString = this.timeoutString;\n\t\tif (StringUtils.hasText(timeoutString)) {\n\t\t\tif (resolver != null) {\n\t\t\t\ttimeoutString = resolver.resolveStringValue(timeoutString);\n\t\t\t}\n\t\t\tif (StringUtils.hasLength(timeoutString)) {\n\t\t\t\ttry {\n\t\t\t\t\tsetTimeout(Integer.parseInt(timeoutString));\n\t\t\t\t}\n\t\t\t\tcatch (RuntimeException ex) {\n\t\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\t\"Invalid timeoutString value \\\"\" + timeoutString + \"\\\" - cannot parse into int\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (resolver != null) {\n\t\t\tif (this.qualifier != null) {\n\t\t\t\tthis.qualifier = resolver.resolveStringValue(this.qualifier);\n\t\t\t}\n\t\t\tSet<String> resolvedLabels = new LinkedHashSet<>(this.labels.size());\n\t\t\tfor (String label : this.labels) {\n\t\t\t\tresolvedLabels.add(resolver.resolveStringValue(label));\n\t\t\t}\n\t\t\tthis.labels = resolvedLabels;\n\t\t}\n\t}", "summary_tokens": ["resolve", "attribute", "values", "that", "are", "defined", "as", "resolvable", "strings", "set", "timeout", "string", "set", "qualifier", "set", "labels"], "project": "spring-framework"}
{"id": 312, "code": "\tpublic BeanMetadataAttribute getMetadataAttribute(String name) {\n\t\treturn (BeanMetadataAttribute) super.getAttribute(name);\n\t}", "summary_tokens": ["look", "up", "the", "given", "bean", "metadata", "attribute", "in", "this", "accessor", "s", "set", "of", "attributes"], "project": "spring-framework"}
{"id": 6738, "code": "\tpublic static BodyBuilder post(String uriTemplate, Object... uriVariables) {\n\t\treturn method(HttpMethod.POST, uriTemplate, uriVariables);\n\t}", "summary_tokens": ["create", "an", "http", "post", "builder", "with", "the", "given", "string", "base", "uri", "template"], "project": "spring-framework"}
{"id": 274, "code": "\tpublic boolean equals(Object other) {\n\t\treturn (this == other || (other instanceof HotSwappableTargetSource &&\n\t\t\t\tthis.target.equals(((HotSwappableTargetSource) other).target)));\n\t}", "summary_tokens": ["two", "hot", "swappable", "target", "sources", "are", "equal", "if", "the", "current", "target", "objects", "are", "equal"], "project": "spring-framework"}
{"id": 276, "code": "\tpublic Object getTarget() throws BeansException {\n\t\treturn newPrototypeInstance();\n\t}", "summary_tokens": ["obtain", "a", "new", "prototype", "instance", "for", "every", "call"], "project": "spring-framework"}
{"id": 9707, "code": "\tpublic void setEngineName(@Nullable String engineName) {\n\t\tthis.engineName = engineName;\n\t}", "summary_tokens": ["set", "the", "engine", "name", "that", "will", "be", "used", "to", "instantiate", "the", "script", "engine"], "project": "spring-framework"}
{"id": 2348, "code": "private void createDebugLabel(final int bytecodeOffset, final Label[] labels) {\n  if (labels[bytecodeOffset] == null) {\n    readLabel(bytecodeOffset, labels).flags |= Label.FLAG_DEBUG_ONLY;\n  }\n}", "summary_tokens": ["creates", "a", "label", "with", "the", "label", "flag", "debug", "only", "flag", "set", "if", "there", "is", "no", "already", "existing", "label", "for", "the", "given", "bytecode", "offset", "otherwise", "does", "nothing"], "project": "spring-framework"}
{"id": 8417, "code": "\tprotected Class<?> requiredViewClass() {\n\t\treturn FreeMarkerView.class;\n\t}", "summary_tokens": ["requires", "free", "marker", "view"], "project": "spring-framework"}
{"id": 1304, "code": "\tstatic <T> T instantiateClass(Class<?> clazz, Class<T> assignableTo, Environment environment,\n\t\t\tResourceLoader resourceLoader, BeanDefinitionRegistry registry) {\n\n\t\tAssert.notNull(clazz, \"Class must not be null\");\n\t\tAssert.isAssignable(assignableTo, clazz);\n\t\tif (clazz.isInterface()) {\n\t\t\tthrow new BeanInstantiationException(clazz, \"Specified class is an interface\");\n\t\t}\n\t\tClassLoader classLoader = (registry instanceof ConfigurableBeanFactory ?\n\t\t\t\t((ConfigurableBeanFactory) registry).getBeanClassLoader() : resourceLoader.getClassLoader());\n\t\tT instance = (T) createInstance(clazz, environment, resourceLoader, registry, classLoader);\n\t\tParserStrategyUtils.invokeAwareMethods(instance, environment, resourceLoader, registry, classLoader);\n\t\treturn instance;\n\t}", "summary_tokens": ["instantiate", "a", "class", "using", "an", "appropriate", "constructor", "and", "return", "the", "new", "instance", "as", "the", "specified", "assignable", "type"], "project": "spring-framework"}
{"id": 5123, "code": "\tpublic String[] getFilterNames() {\n\t\treturn this.filterNames;\n\t}", "summary_tokens": ["return", "the", "names", "of", "hibernate", "filters", "to", "be", "activated", "if", "any"], "project": "spring-framework"}
{"id": 773, "code": "\tpublic void addBean(String name, Object bean) {\n\t\tthis.beans.put(name, bean);\n\t}", "summary_tokens": ["add", "a", "new", "singleton", "bean"], "project": "spring-framework"}
{"id": 9606, "code": "\tpublic void destroy() throws BeansException {\n\t\tfor (ConfigurableApplicationContext factory : this.bundleCache.values()) {\n\t\t\tfactory.close();\n\t\t}\n\t\tthis.localeCache.clear();\n\t\tthis.bundleCache.clear();\n\t}", "summary_tokens": ["close", "the", "bundle", "view", "factories", "on", "context", "shutdown"], "project": "spring-framework"}
{"id": 9724, "code": "\tpublic void setOutputProperties(Properties outputProperties) {\n\t\tthis.outputProperties = outputProperties;\n\t}", "summary_tokens": ["set", "arbitrary", "transformer", "output", "properties", "to", "be", "applied", "to", "the", "stylesheet"], "project": "spring-framework"}
{"id": 9912, "code": "\tpublic void setDisconnectDelay(long disconnectDelay) {\n\t\tthis.disconnectDelay = disconnectDelay;\n\t}", "summary_tokens": ["the", "amount", "of", "time", "in", "milliseconds", "before", "a", "client", "is", "considered", "disconnected", "after", "not", "having", "a", "receiving", "connection", "i"], "project": "spring-framework"}
{"id": 459, "code": "\tprotected void destroyInstance(@Nullable T instance) throws Exception {\n\t}", "summary_tokens": ["callback", "for", "destroying", "a", "singleton", "instance"], "project": "spring-framework"}
{"id": 6202, "code": "\tpublic void setMessageEndpointFactory(@Nullable MessageEndpointFactory messageEndpointFactory) {\n\t\tthis.messageEndpointFactory = messageEndpointFactory;\n\t}", "summary_tokens": ["set", "the", "jca", "message", "endpoint", "factory", "to", "activate", "pointing", "to", "a", "message", "listener", "object", "that", "the", "endpoints", "will", "delegate", "to"], "project": "spring-framework"}
{"id": 2058, "code": "\tprotected void postProcessConfiguration(Configuration<?> configuration) {\n\t}", "summary_tokens": ["post", "process", "the", "given", "bean", "validation", "configuration", "adding", "to", "or", "overriding", "any", "of", "its", "settings"], "project": "spring-framework"}
{"id": 5431, "code": "\tpublic BindMarker bind(Object value) {\n\t\tAssert.notNull(value, \"Value must not be null\");\n\t\tBindMarker marker = nextMarker();\n\t\tgetBindings().put(marker, new ValueBinding(marker, value));\n\t\treturn marker;\n\t}", "summary_tokens": ["bind", "a", "value", "and", "return", "the", "related", "bind", "marker"], "project": "spring-framework"}
{"id": 1110, "code": "\tpublic void setJobFactory(JobFactory jobFactory) {\n\t\tthis.jobFactory = jobFactory;\n\t\tthis.jobFactorySet = true;\n\t}", "summary_tokens": ["set", "the", "quartz", "job", "factory", "to", "use", "for", "this", "scheduler"], "project": "spring-framework"}
{"id": 3898, "code": "\tpublic void loadBeanDefinitions(String sql) {\n\t\tAssert.notNull(this.jdbcTemplate, \"Not fully configured - specify DataSource or JdbcTemplate\");\n\t\tfinal Properties props = new Properties();\n\t\tthis.jdbcTemplate.query(sql, rs -> {\n\t\t\tString beanName = rs.getString(1);\n\t\t\tString property = rs.getString(2);\n\t\t\tString value = rs.getString(3);\n\t\t\t\n\t\t\tprops.setProperty(beanName + '.' + property, value);\n\t\t});\n\t\tthis.propReader.registerBeanDefinitions(props);\n\t}", "summary_tokens": ["load", "bean", "definitions", "from", "the", "database", "via", "the", "given", "sql", "string"], "project": "spring-framework"}
{"id": 5514, "code": "\tpublic static boolean hasAnnotation(Class<?> clazz, Class<? extends Annotation> annotationType) {\n\t\treturn MergedAnnotations.search(SearchStrategy.TYPE_HIERARCHY)\n\t\t\t\t.withEnclosingClasses(TestContextAnnotationUtils::searchEnclosingClass)\n\t\t\t\t.from(clazz)\n\t\t\t\t.isPresent(annotationType);\n\t}", "summary_tokens": ["determine", "if", "an", "annotation", "of", "the", "specified", "annotation", "type", "is", "present", "or", "meta", "present", "on", "the", "supplied", "class", "according", "to", "the", "search", "algorithm", "used", "in", "find", "merged", "annotation", "class", "class"], "project": "spring-framework"}
{"id": 7851, "code": "\tprivate void setReadOnly() {\n\t\tthis.readOnly = true;\n\t}", "summary_tokens": ["switch", "to", "read", "only", "mode", "where", "further", "configuration", "changes", "are", "not", "allowed"], "project": "spring-framework"}
{"id": 4148, "code": "\tpublic SQLExceptionTranslator getExceptionTranslator() {\n\t\tSQLExceptionTranslator exceptionTranslator = this.exceptionTranslator;\n\t\tif (exceptionTranslator != null) {\n\t\t\treturn exceptionTranslator;\n\t\t}\n\t\tsynchronized (this) {\n\t\t\texceptionTranslator = this.exceptionTranslator;\n\t\t\tif (exceptionTranslator == null) {\n\t\t\t\tif (SQLErrorCodeSQLExceptionTranslator.hasUserProvidedErrorCodesFile()) {\n\t\t\t\t\texceptionTranslator = new SQLErrorCodeSQLExceptionTranslator(obtainDataSource());\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\texceptionTranslator = new SQLExceptionSubclassTranslator();\n\t\t\t\t}\n\t\t\t\tthis.exceptionTranslator = exceptionTranslator;\n\t\t\t}\n\t\t\treturn exceptionTranslator;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "exception", "translator", "for", "this", "instance"], "project": "spring-framework"}
{"id": 5244, "code": "\tpublic void setDataSources(Map<String, DataSource> dataSources) {\n\t\tthis.dataSourceLookup = new MapDataSourceLookup(dataSources);\n\t}", "summary_tokens": ["specify", "the", "jdbc", "data", "sources", "that", "the", "jpa", "persistence", "provider", "is", "supposed", "to", "use", "for", "accessing", "the", "database", "resolving", "data", "source", "names", "in", "persistence"], "project": "spring-framework"}
{"id": 3531, "code": "\tpublic static void insertNumericUnboxOrPrimitiveTypeCoercion(\n\t\t\tMethodVisitor mv, @Nullable String stackDescriptor, char targetDescriptor) {\n\n\t\tif (!CodeFlow.isPrimitive(stackDescriptor)) {\n\t\t\tCodeFlow.insertUnboxNumberInsns(mv, targetDescriptor, stackDescriptor);\n\t\t}\n\t\telse {\n\t\t\tCodeFlow.insertAnyNecessaryTypeConversionBytecodes(mv, targetDescriptor, stackDescriptor);\n\t\t}\n\t}", "summary_tokens": ["for", "use", "in", "mathematical", "operators", "handles", "converting", "from", "a", "possibly", "boxed", "number", "on", "the", "stack", "to", "a", "primitive", "numeric", "type"], "project": "spring-framework"}
{"id": 9227, "code": "\tpublic void setValue(@Nullable String value) {\n\t\tthis.value = value;\n\t}", "summary_tokens": ["set", "the", "raw", "value", "of", "the", "parameter"], "project": "spring-framework"}
{"id": 4382, "code": "\tprotected void startSharedConnection() throws JMSException {\n\t\tsynchronized (this.sharedConnectionMonitor) {\n\t\t\tthis.sharedConnectionStarted = true;\n\t\t\tif (this.sharedConnection != null) {\n\t\t\t\ttry {\n\t\t\t\t\tthis.sharedConnection.start();\n\t\t\t\t}\n\t\t\t\tcatch (jakarta.jms.IllegalStateException ex) {\n\t\t\t\t\tlogger.debug(\"Ignoring Connection start exception - assuming already started: \" + ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["start", "the", "shared", "connection"], "project": "spring-framework"}
{"id": 5858, "code": "\tpublic static DefaultResponseCreator withUnauthorizedRequest() {\n\t\treturn new DefaultResponseCreator(HttpStatus.UNAUTHORIZED);\n\t}", "summary_tokens": ["response", "creator", "for", "a", "0", "response", "unauthorized"], "project": "spring-framework"}
{"id": 7266, "code": "\tprotected final FacesContext getFacesContext() {\n\t\treturn this.facesContext;\n\t}", "summary_tokens": ["return", "the", "jsf", "faces", "context", "that", "this", "adapter", "operates", "on"], "project": "spring-framework"}
{"id": 3368, "code": "\tprotected void interruptTask() {\n\t}", "summary_tokens": ["subclasses", "can", "override", "this", "method", "to", "implement", "interruption", "of", "the", "future", "s", "computation"], "project": "spring-framework"}
{"id": 4173, "code": "\tpublic void setCacheSize(int cacheSize) {\n\t\tthis.cacheSize = cacheSize;\n\t}", "summary_tokens": ["set", "the", "number", "of", "buffered", "keys"], "project": "spring-framework"}
{"id": 4186, "code": "\tpublic String getDummyName() {\n\t\treturn this.dummyName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "dummy", "column"], "project": "spring-framework"}
{"id": 3984, "code": "\tpublic boolean shouldClose(Connection con) {\n\t\tsynchronized (this.connectionMonitor) {\n\t\t\treturn (con != this.connection && con != this.target);\n\t\t}\n\t}", "summary_tokens": ["this", "is", "a", "single", "connection", "do", "not", "close", "it", "when", "returning", "to", "the", "pool"], "project": "spring-framework"}
{"id": 6474, "code": "\tpublic boolean isLocalRollbackOnly() {\n\t\treturn this.rollbackOnly;\n\t}", "summary_tokens": ["determine", "the", "rollback", "only", "flag", "via", "checking", "this", "transaction", "status"], "project": "spring-framework"}
{"id": 6706, "code": "\tpublic void add(String headerName, @Nullable String headerValue) {\n\t\tthis.headers.add(headerName, headerValue);\n\t}", "summary_tokens": ["add", "the", "given", "single", "header", "value", "under", "the", "given", "name"], "project": "spring-framework"}
{"id": 9208, "code": "\tpublic void setMessage(MessageSourceResolvable message) {\n\t\tthis.message = message;\n\t}", "summary_tokens": ["set", "the", "message", "source", "resolvable", "for", "this", "tag"], "project": "spring-framework"}
{"id": 9324, "code": "\tprotected String getOnblur() {\n\t\treturn this.onblur;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onblur", "attribute"], "project": "spring-framework"}
{"id": 9437, "code": "\tprivate void renderFromArray(TagWriter tagWriter) throws JspException {\n\t\tdoRenderFromCollection(CollectionUtils.arrayToList(this.optionSource), tagWriter);\n\t}", "summary_tokens": ["render", "the", "inner", "option", "tags", "using", "the", "option", "source"], "project": "spring-framework"}
{"id": 8283, "code": "\tprivate NamedValueInfo updateNamedValueInfo(MethodParameter parameter, NamedValueInfo info) {\n\t\tString name = info.name;\n\t\tif (info.name.isEmpty()) {\n\t\t\tname = parameter.getParameterName();\n\t\t\tif (name == null) {\n\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\"Name for argument of type [\" + parameter.getNestedParameterType().getName() +\n\t\t\t\t\t\t\"] not specified, and parameter name information not found in class file either.\");\n\t\t\t}\n\t\t}\n\t\tString defaultValue = (ValueConstants.DEFAULT_NONE.equals(info.defaultValue) ? null : info.defaultValue);\n\t\treturn new NamedValueInfo(name, info.required, defaultValue);\n\t}", "summary_tokens": ["create", "a", "new", "named", "value", "info", "based", "on", "the", "given", "named", "value", "info", "with", "sanitized", "values"], "project": "spring-framework"}
{"id": 656, "code": "\tpublic void setInitMethodName(@Nullable String initMethodName) {\n\t\tthis.initMethodName = (StringUtils.hasText(initMethodName) ? initMethodName : null);\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "default", "initializer", "method"], "project": "spring-framework"}
{"id": 5904, "code": "\tdefault void beforeServerCreated(WebHttpHandlerBuilder builder) {\n\t}", "summary_tokens": ["invoked", "just", "before", "the", "mock", "server", "is", "built"], "project": "spring-framework"}
{"id": 8531, "code": "\tprotected ConfigurableEnvironment createEnvironment() {\n\t\treturn new StandardServletEnvironment();\n\t}", "summary_tokens": ["create", "and", "return", "a", "new", "standard", "servlet", "environment"], "project": "spring-framework"}
{"id": 9899, "code": "\tprivate String escapeSockJsSpecialChars(char[] characters) {\n\t\tStringBuilder result = new StringBuilder();\n\t\tfor (char c : characters) {\n\t\t\tif (isSockJsSpecialChar(c)) {\n\t\t\t\tresult.append('\\\\').append('u');\n\t\t\t\tString hex = Integer.toHexString(c).toLowerCase();\n\t\t\t\tfor (int i = 0; i < (4 - hex.length()); i++) {\n\t\t\t\t\tresult.append('0');\n\t\t\t\t}\n\t\t\t\tresult.append(hex);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tresult.append(c);\n\t\t\t}\n\t\t}\n\t\treturn result.toString();\n\t}", "summary_tokens": ["see", "json", "unicode", "encoding", "section", "of", "sock", "js", "protocol"], "project": "spring-framework"}
{"id": 9542, "code": "\tprotected Map<String, Object> createMergedOutputModel(@Nullable Map<String, ?> model,\n\t\t\tHttpServletRequest request, HttpServletResponse response) {\n\n\t\t@SuppressWarnings(\"unchecked\")\n\t\tMap<String, Object> pathVars = (this.exposePathVariables ?\n\t\t\t\t(Map<String, Object>) request.getAttribute(View.PATH_VARIABLES) : null);\n\n\t\t\n\t\tint size = this.staticAttributes.size();\n\t\tsize += (model != null ? model.size() : 0);\n\t\tsize += (pathVars != null ? pathVars.size() : 0);\n\n\t\tMap<String, Object> mergedModel = CollectionUtils.newLinkedHashMap(size);\n\t\tmergedModel.putAll(this.staticAttributes);\n\t\tif (pathVars != null) {\n\t\t\tmergedModel.putAll(pathVars);\n\t\t}\n\t\tif (model != null) {\n\t\t\tmergedModel.putAll(model);\n\t\t}\n\n\t\t\n\t\tif (this.requestContextAttribute != null) {\n\t\t\tmergedModel.put(this.requestContextAttribute, createRequestContext(request, response, mergedModel));\n\t\t}\n\n\t\treturn mergedModel;\n\t}", "summary_tokens": ["creates", "a", "combined", "output", "map", "never", "null", "that", "includes", "dynamic", "values", "and", "static", "attributes"], "project": "spring-framework"}
{"id": 12, "code": "\tprivate boolean maybeBindThisJoinPoint() {\n\t\tif ((this.argumentTypes[0] == JoinPoint.class) || (this.argumentTypes[0] == ProceedingJoinPoint.class)) {\n\t\t\tbindParameterName(0, THIS_JOIN_POINT);\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["if", "the", "first", "parameter", "is", "of", "type", "join", "point", "or", "proceeding", "join", "point", "bind", "this", "join", "point", "as", "parameter", "name", "and", "return", "true", "else", "return", "false"], "project": "spring-framework"}
{"id": 5266, "code": "\tpublic void addTransformer(ClassTransformer classTransformer) {\n\t\tthrow new UnsupportedOperationException(\"addTransformer not supported\");\n\t}", "summary_tokens": ["this", "implementation", "throws", "an", "unsupported", "operation", "exception"], "project": "spring-framework"}
{"id": 1363, "code": "\tprotected String[] getConfigLocations() {\n\t\treturn (this.configLocations != null ? this.configLocations : getDefaultConfigLocations());\n\t}", "summary_tokens": ["return", "an", "array", "of", "resource", "locations", "referring", "to", "the", "xml", "bean", "definition", "files", "that", "this", "context", "should", "be", "built", "with"], "project": "spring-framework"}
{"id": 8854, "code": "\tpublic void setUrlPathHelper(UrlPathHelper urlPathHelper) {\n\t\tAssert.notNull(urlPathHelper, \"UrlPathHelper must not be null\");\n\t\tthis.urlPathHelper = urlPathHelper;\n\t}", "summary_tokens": ["set", "the", "url", "path", "helper", "to", "use", "for", "the", "resolution", "of", "lookup", "paths"], "project": "spring-framework"}
{"id": 3632, "code": "\tvoid indexingAsAPropertyAccess_SPR6968_5() {\n\t\tGoo g = Goo.instance;\n\t\tStandardEvaluationContext context = new StandardEvaluationContext(g);\n\t\tExpression expr = null;\n\t\texpr = new SpelExpressionParser().parseRaw(\"instance[bar]='world'\");\n\t\texpr.getValue(context, String.class);\n\t\tassertThat(g.value).isEqualTo(\"world\");\n\t\texpr.getValue(context, String.class); \n\t\tassertThat(g.value).isEqualTo(\"world\");\n\t}", "summary_tokens": ["should", "be", "accessing", "goo"], "project": "spring-framework"}
{"id": 6169, "code": "\tpublic int getActualSize() {\n\t\treturn this.actualSize;\n\t}", "summary_tokens": ["return", "the", "actual", "result", "size", "or", "0", "if", "unknown"], "project": "spring-framework"}
{"id": 1473, "code": "\tpublic void setTimeZone(TimeZone timeZone) {\n\t\tthis.timeZone = timeZone;\n\t}", "summary_tokens": ["set", "the", "time", "zone", "to", "normalize", "the", "date", "values", "into", "if", "any"], "project": "spring-framework"}
{"id": 8685, "code": "\tpublic RequestMappingHandlerAdapter requestMappingHandlerAdapter(\n\t\t\t@Qualifier(\"mvcContentNegotiationManager\") ContentNegotiationManager contentNegotiationManager,\n\t\t\t@Qualifier(\"mvcConversionService\") FormattingConversionService conversionService,\n\t\t\t@Qualifier(\"mvcValidator\") Validator validator) {\n\n\t\tRequestMappingHandlerAdapter adapter = createRequestMappingHandlerAdapter();\n\t\tadapter.setContentNegotiationManager(contentNegotiationManager);\n\t\tadapter.setMessageConverters(getMessageConverters());\n\t\tadapter.setWebBindingInitializer(getConfigurableWebBindingInitializer(conversionService, validator));\n\t\tadapter.setCustomArgumentResolvers(getArgumentResolvers());\n\t\tadapter.setCustomReturnValueHandlers(getReturnValueHandlers());\n\n\t\tif (jackson2Present) {\n\t\t\tadapter.setRequestBodyAdvice(Collections.singletonList(new JsonViewRequestBodyAdvice()));\n\t\t\tadapter.setResponseBodyAdvice(Collections.singletonList(new JsonViewResponseBodyAdvice()));\n\t\t}\n\n\t\tAsyncSupportConfigurer configurer = getAsyncSupportConfigurer();\n\t\tif (configurer.getTaskExecutor() != null) {\n\t\t\tadapter.setTaskExecutor(configurer.getTaskExecutor());\n\t\t}\n\t\tif (configurer.getTimeout() != null) {\n\t\t\tadapter.setAsyncRequestTimeout(configurer.getTimeout());\n\t\t}\n\t\tadapter.setCallableInterceptors(configurer.getCallableInterceptors());\n\t\tadapter.setDeferredResultInterceptors(configurer.getDeferredResultInterceptors());\n\n\t\treturn adapter;\n\t}", "summary_tokens": ["returns", "a", "request", "mapping", "handler", "adapter", "for", "processing", "requests", "through", "annotated", "controller", "methods"], "project": "spring-framework"}
{"id": 5459, "code": "\tpublic ServletResponse getResponse() {\n\t\treturn this.response;\n\t}", "summary_tokens": ["return", "the", "response", "that", "do", "filter", "has", "been", "called", "with"], "project": "spring-framework"}
{"id": 9501, "code": "\tpublic boolean isCache() {\n\t\treturn (this.cacheLimit > 0);\n\t}", "summary_tokens": ["return", "if", "caching", "is", "enabled"], "project": "spring-framework"}
{"id": 1957, "code": "\tprotected String canonicalFieldName(String field) {\n\t\treturn PropertyAccessorUtils.canonicalPropertyName(field);\n\t}", "summary_tokens": ["returns", "the", "canonical", "property", "name"], "project": "spring-framework"}
{"id": 8712, "code": "\tpublic ViewResolver mvcViewResolver(\n\t\t\t@Qualifier(\"mvcContentNegotiationManager\") ContentNegotiationManager contentNegotiationManager) {\n\t\tViewResolverRegistry registry =\n\t\t\t\tnew ViewResolverRegistry(contentNegotiationManager, this.applicationContext);\n\t\tconfigureViewResolvers(registry);\n\n\t\tif (registry.getViewResolvers().isEmpty() && this.applicationContext != null) {\n\t\t\tString[] names = BeanFactoryUtils.beanNamesForTypeIncludingAncestors(\n\t\t\t\t\tthis.applicationContext, ViewResolver.class, true, false);\n\t\t\tif (names.length == 1) {\n\t\t\t\tregistry.getViewResolvers().add(new InternalResourceViewResolver());\n\t\t\t}\n\t\t}\n\n\t\tViewResolverComposite composite = new ViewResolverComposite();\n\t\tcomposite.setOrder(registry.getOrder());\n\t\tcomposite.setViewResolvers(registry.getViewResolvers());\n\t\tif (this.applicationContext != null) {\n\t\t\tcomposite.setApplicationContext(this.applicationContext);\n\t\t}\n\t\tif (this.servletContext != null) {\n\t\t\tcomposite.setServletContext(this.servletContext);\n\t\t}\n\t\treturn composite;\n\t}", "summary_tokens": ["register", "a", "view", "resolver", "composite", "that", "contains", "a", "chain", "of", "view", "resolvers", "to", "use", "for", "view", "resolution"], "project": "spring-framework"}
{"id": 4316, "code": "\tpublic String getDefaultDestinationName() {\n\t\treturn this.defaultDestinationName;\n\t}", "summary_tokens": ["return", "the", "configured", "default", "destination", "name"], "project": "spring-framework"}
{"id": 8351, "code": "\tpublic PropertyEditor findEditor(Class<?> valueClass) {\n\t\treturn (this.bindingResult != null ?\n\t\t\t\tthis.bindingResult.findEditor(this.expression, valueClass) : null);\n\t}", "summary_tokens": ["find", "a", "property", "editor", "for", "the", "given", "value", "class", "associated", "with", "the", "property", "that", "this", "bound", "status", "is", "currently", "bound", "to"], "project": "spring-framework"}
{"id": 5572, "code": "\tpublic void afterTestMethod(TestContext testContext) {\n\t\texecuteSqlScripts(testContext, ExecutionPhase.AFTER_TEST_METHOD);\n\t}", "summary_tokens": ["execute", "sql", "scripts", "configured", "via", "sql", "for", "the", "supplied", "test", "context", "em", "after", "em", "the", "current", "test", "method"], "project": "spring-framework"}
{"id": 7760, "code": "\tprotected void copyBodyToResponse(boolean complete) throws IOException {\n\t\tif (this.content.size() > 0) {\n\t\t\tHttpServletResponse rawResponse = (HttpServletResponse) getResponse();\n\t\t\tif ((complete || this.contentLength != null) && !rawResponse.isCommitted()) {\n\t\t\t\tif (rawResponse.getHeader(HttpHeaders.TRANSFER_ENCODING) == null) {\n\t\t\t\t\trawResponse.setContentLength(complete ? this.content.size() : this.contentLength);\n\t\t\t\t}\n\t\t\t\tthis.contentLength = null;\n\t\t\t}\n\t\t\tthis.content.writeTo(rawResponse.getOutputStream());\n\t\t\tthis.content.reset();\n\t\t\tif (complete) {\n\t\t\t\tsuper.flushBuffer();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["copy", "the", "cached", "body", "content", "to", "the", "response"], "project": "spring-framework"}
{"id": 3356, "code": "\tpublic long getMaxElapsedTime() {\n\t\treturn this.maxElapsedTime;\n\t}", "summary_tokens": ["return", "the", "maximum", "elapsed", "time", "in", "milliseconds", "after", "which", "a", "call", "to", "back", "off", "execution", "next", "back", "off", "returns", "back", "off", "execution", "stop"], "project": "spring-framework"}
{"id": 1953, "code": "\tprotected String fixedField(@Nullable String field) {\n\t\tif (StringUtils.hasLength(field)) {\n\t\t\treturn getNestedPath() + canonicalFieldName(field);\n\t\t}\n\t\telse {\n\t\t\tString path = getNestedPath();\n\t\t\treturn (path.endsWith(Errors.NESTED_PATH_SEPARATOR) ?\n\t\t\t\t\tpath.substring(0, path.length() - NESTED_PATH_SEPARATOR.length()) : path);\n\t\t}\n\t}", "summary_tokens": ["transform", "the", "given", "field", "into", "its", "full", "path", "regarding", "the", "nested", "path", "of", "this", "instance"], "project": "spring-framework"}
{"id": 1072, "code": "\tpublic void setDescription(String description) {\n\t\tthis.description = description;\n\t}", "summary_tokens": ["set", "a", "textual", "description", "for", "this", "job"], "project": "spring-framework"}
{"id": 6013, "code": "\tpublic static FlashAttributeResultMatchers flash() {\n\t\treturn new FlashAttributeResultMatchers();\n\t}", "summary_tokens": ["access", "to", "flash", "attribute", "assertions"], "project": "spring-framework"}
{"id": 5338, "code": "\tpublic static Mono<Void> doReleaseConnection(Connection connection, ConnectionFactory connectionFactory) {\n\t\treturn TransactionSynchronizationManager.forCurrentTransaction()\n\t\t\t\t.flatMap(synchronizationManager -> {\n\t\t\tConnectionHolder conHolder = (ConnectionHolder) synchronizationManager.getResource(connectionFactory);\n\t\t\tif (conHolder != null && connectionEquals(conHolder, connection)) {\n\t\t\t\t\n\t\t\t\tconHolder.released();\n\t\t\t}\n\t\t\treturn Mono.from(connection.close());\n\t\t}).onErrorResume(NoTransactionException.class, e -> Mono.from(connection.close()));\n\t}", "summary_tokens": ["actually", "close", "the", "given", "connection", "obtained", "from", "the", "given", "connection", "factory"], "project": "spring-framework"}
{"id": 6600, "code": "\tvoid ruleForCommitOnSubclassOfChecked() {\n\t\tList<RollbackRuleAttribute> list = new ArrayList<>();\n\t\t\n\t\t\n\t\tlist.add(new RollbackRuleAttribute(\"java.lang.Exception\"));\n\t\tlist.add(new NoRollbackRuleAttribute(\"IOException\"));\n\t\tRuleBasedTransactionAttribute rta = new RuleBasedTransactionAttribute(TransactionDefinition.PROPAGATION_REQUIRED, list);\n\n\t\tassertThat(rta.rollbackOn(new RuntimeException())).isTrue();\n\t\tassertThat(rta.rollbackOn(new Exception())).isTrue();\n\t\t\n\t\tassertThat(rta.rollbackOn(new IOException())).isFalse();\n\t}", "summary_tokens": ["check", "that", "a", "rule", "can", "cause", "commit", "on", "a", "ioexception", "when", "exception", "prompts", "a", "rollback"], "project": "spring-framework"}
{"id": 3500, "code": "\tpublic void enterCompilationScope() {\n\t\tthis.compilationScopes.push(new ArrayList<>());\n\t}", "summary_tokens": ["enter", "a", "new", "compilation", "scope", "usually", "due", "to", "nested", "expression", "evaluation"], "project": "spring-framework"}
{"id": 9823, "code": "\tpublic Principal getUser() {\n\t\treturn this.user;\n\t}", "summary_tokens": ["return", "the", "user", "for", "the", "session", "associated", "with", "the", "event"], "project": "spring-framework"}
{"id": 1397, "code": "\tprivate void doStop(Map<String, ? extends Lifecycle> lifecycleBeans, final String beanName,\n\t\t\tfinal CountDownLatch latch, final Set<String> countDownBeanNames) {\n\n\t\tLifecycle bean = lifecycleBeans.remove(beanName);\n\t\tif (bean != null) {\n\t\t\tString[] dependentBeans = getBeanFactory().getDependentBeans(beanName);\n\t\t\tfor (String dependentBean : dependentBeans) {\n\t\t\t\tdoStop(lifecycleBeans, dependentBean, latch, countDownBeanNames);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tif (bean.isRunning()) {\n\t\t\t\t\tif (bean instanceof SmartLifecycle) {\n\t\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\t\tlogger.trace(\"Asking bean '\" + beanName + \"' of type [\" +\n\t\t\t\t\t\t\t\t\tbean.getClass().getName() + \"] to stop\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcountDownBeanNames.add(beanName);\n\t\t\t\t\t\t((SmartLifecycle) bean).stop(() -> {\n\t\t\t\t\t\t\tlatch.countDown();\n\t\t\t\t\t\t\tcountDownBeanNames.remove(beanName);\n\t\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\t\tlogger.debug(\"Bean '\" + beanName + \"' completed its stop procedure\");\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\t\tlogger.trace(\"Stopping bean '\" + beanName + \"' of type [\" +\n\t\t\t\t\t\t\t\t\tbean.getClass().getName() + \"]\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbean.stop();\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"Successfully stopped bean '\" + beanName + \"'\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (bean instanceof SmartLifecycle) {\n\t\t\t\t\t\n\t\t\t\t\tlatch.countDown();\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\t\tlogger.warn(\"Failed to stop bean '\" + beanName + \"'\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["stop", "the", "specified", "bean", "as", "part", "of", "the", "given", "set", "of", "lifecycle", "beans", "making", "sure", "that", "any", "beans", "that", "depends", "on", "it", "are", "stopped", "first"], "project": "spring-framework"}
{"id": 4158, "code": "\tprotected RuntimeException translateException(String task, SQLException ex) {\n\t\tDataAccessException dae = getExceptionTranslator().translate(task, null, ex);\n\t\tif (dae != null) {\n\t\t\treturn dae;\n\t\t}\n\t\treturn super.translateException(task, ex);\n\t}", "summary_tokens": ["this", "implementation", "attempts", "to", "use", "the", "sqlexception", "translator", "falling", "back", "to", "a", "org"], "project": "spring-framework"}
{"id": 9182, "code": "\tprotected final void cacheForSeconds(HttpServletResponse response, int seconds, boolean mustRevalidate) {\n\t\tif (this.useExpiresHeader) {\n\t\t\t\n\t\t\tresponse.setDateHeader(HEADER_EXPIRES, System.currentTimeMillis() + seconds * 1000L);\n\t\t}\n\t\telse if (response.containsHeader(HEADER_EXPIRES)) {\n\t\t\t\n\t\t\tresponse.setHeader(HEADER_EXPIRES, \"\");\n\t\t}\n\n\t\tif (this.useCacheControlHeader) {\n\t\t\t\n\t\t\tString headerValue = \"max-age=\" + seconds;\n\t\t\tif (mustRevalidate || this.alwaysMustRevalidate) {\n\t\t\t\theaderValue += \", must-revalidate\";\n\t\t\t}\n\t\t\tresponse.setHeader(HEADER_CACHE_CONTROL, headerValue);\n\t\t}\n\n\t\tif (response.containsHeader(HEADER_PRAGMA)) {\n\t\t\t\n\t\t\tresponse.setHeader(HEADER_PRAGMA, \"\");\n\t\t}\n\t}", "summary_tokens": ["set", "http", "headers", "to", "allow", "caching", "for", "the", "given", "number", "of", "seconds"], "project": "spring-framework"}
{"id": 3690, "code": "\tpublic boolean isInputValueProvided() {\n\t\treturn false;\n\t}", "summary_tokens": ["this", "implementation", "always", "returns", "false"], "project": "spring-framework"}
{"id": 7358, "code": "\tpublic boolean wasFailure() {\n\t\treturn (this.failureCause != null);\n\t}", "summary_tokens": ["return", "whether", "the", "request", "failed"], "project": "spring-framework"}
{"id": 7058, "code": "\tprotected void flushingFailed(Throwable t) {\n\t\tcancel();\n\t\tonError(t);\n\t}", "summary_tokens": ["invoked", "when", "an", "error", "happens", "while", "flushing"], "project": "spring-framework"}
{"id": 4078, "code": "\tpublic void setGeneratedKeysColumnNames(@Nullable String... names) {\n\t\tif (isCompiled()) {\n\t\t\tthrow new InvalidDataAccessApiUsageException(\n\t\t\t\t\t\"The column names for the generated keys must be set before the operation is compiled\");\n\t\t}\n\t\tthis.generatedKeysColumnNames = names;\n\t}", "summary_tokens": ["set", "the", "column", "names", "of", "the", "auto", "generated", "keys"], "project": "spring-framework"}
{"id": 7657, "code": "\tpublic HttpHeaders getHeaders() {\n\t\tif (CollectionUtils.isEmpty(this.httpMethods)) {\n\t\t\treturn HttpHeaders.EMPTY;\n\t\t}\n\t\tHttpHeaders headers = new HttpHeaders();\n\t\theaders.setAllow(this.httpMethods);\n\t\treturn headers;\n\t}", "summary_tokens": ["return", "http", "headers", "with", "an", "allow", "header", "that", "documents", "the", "allowed", "http", "methods", "for", "this", "url", "if", "available", "or", "an", "empty", "instance", "otherwise"], "project": "spring-framework"}
{"id": 9555, "code": "\tpublic void setStripLeadingSlash(boolean stripLeadingSlash) {\n\t\tthis.stripLeadingSlash = stripLeadingSlash;\n\t}", "summary_tokens": ["set", "whether", "leading", "slashes", "should", "be", "stripped", "from", "the", "uri", "when", "generating", "the", "view", "name"], "project": "spring-framework"}
{"id": 6217, "code": "\tpublic void setResourceAdapterClass(Class<? extends ResourceAdapter> resourceAdapterClass) {\n\t\tthis.resourceAdapter = BeanUtils.instantiateClass(resourceAdapterClass);\n\t}", "summary_tokens": ["specify", "the", "target", "jca", "resource", "adapter", "as", "class", "to", "be", "instantiated", "with", "its", "default", "configuration"], "project": "spring-framework"}
{"id": 5434, "code": "\tprivate MockResult mockSingleColumnResult(@Nullable MockRow.Builder row) {\n\t\tMockResult.Builder resultBuilder = MockResult.builder();\n\t\tif (row != null) {\n\t\t\tMockRowMetadata metadata = MockRowMetadata.builder().columnMetadata(\n\t\t\t\t\tMockColumnMetadata.builder().name(\"name\").javaType(String.class).build()).build();\n\t\t\tresultBuilder = resultBuilder.row(row.metadata(metadata).build());\n\t\t}\n\t\treturn resultBuilder.build();\n\t}", "summary_tokens": ["mocks", "a", "result", "with", "a", "single", "column", "name", "and", "a", "single", "row", "if", "a", "non", "null", "row", "is", "provided"], "project": "spring-framework"}
{"id": 8167, "code": "\tstatic BodyBuilder seeOther(URI location) {\n\t\tBodyBuilder builder = status(HttpStatus.SEE_OTHER);\n\t\treturn builder.location(location);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "a", "http", "status", "see", "other", "0", "see", "other", "status", "and", "a", "location", "header", "set", "to", "the", "given", "uri"], "project": "spring-framework"}
{"id": 3178, "code": "\tpublic static <K, V> void mergePropertiesIntoMap(@Nullable Properties props, Map<K, V> map) {\n\t\tif (props != null) {\n\t\t\tfor (Enumeration<?> en = props.propertyNames(); en.hasMoreElements();) {\n\t\t\t\tString key = (String) en.nextElement();\n\t\t\t\tObject value = props.get(key);\n\t\t\t\tif (value == null) {\n\t\t\t\t\t\n\t\t\t\t\tvalue = props.getProperty(key);\n\t\t\t\t}\n\t\t\t\tmap.put((K) key, (V) value);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["merge", "the", "given", "properties", "instance", "into", "the", "given", "map", "copying", "all", "properties", "key", "value", "pairs", "over"], "project": "spring-framework"}
{"id": 9264, "code": "\tpublic final PropertyEditor getEditor() throws JspException {\n\t\treturn getPropertyEditor();\n\t}", "summary_tokens": ["exposes", "the", "property", "editor", "for", "editor", "aware", "tag"], "project": "spring-framework"}
{"id": 3840, "code": "\tpublic boolean isReturnValueRequired() {\n\t\treturn this.callMetaDataContext.isReturnValueRequired();\n\t}", "summary_tokens": ["does", "the", "call", "require", "a", "return", "value"], "project": "spring-framework"}
{"id": 6469, "code": "\tprotected void prepareForCommit(DefaultTransactionStatus status) {\n\t}", "summary_tokens": ["make", "preparations", "for", "commit", "to", "be", "performed", "before", "the", "before", "commit", "synchronization", "callbacks", "occur"], "project": "spring-framework"}
{"id": 9812, "code": "\tpublic WebSocketTransportRegistration setMessageSizeLimit(int messageSizeLimit) {\n\t\tthis.messageSizeLimit = messageSizeLimit;\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "the", "maximum", "size", "of", "an", "inbound", "sub", "protocol", "message", "such", "as", "a", "stomp", "frame", "which", "may", "be", "aggregated", "from", "multiple", "web", "socket", "messages"], "project": "spring-framework"}
{"id": 5488, "code": "\tpublic String get(String key) {\n\t\tAssert.hasText(key, \"'key' must not be empty\");\n\t\treturn System.getProperty(key);\n\t}", "summary_tokens": ["get", "the", "em", "profile", "value", "em", "indicated", "by", "the", "specified", "key", "from", "the", "system", "properties"], "project": "spring-framework"}
{"id": 3598, "code": "\tpublic BeanResolver getBeanResolver() {\n\t\treturn null;\n\t}", "summary_tokens": ["simple", "evaluation", "context", "does", "not", "support", "the", "use", "of", "bean", "references"], "project": "spring-framework"}
{"id": 7033, "code": "\tprotected void customizeUnmarshaller(Unmarshaller unmarshaller) {\n\t}", "summary_tokens": ["customize", "the", "unmarshaller", "created", "by", "this", "message", "converter", "before", "using", "it", "to", "read", "the", "object", "from", "the", "input"], "project": "spring-framework"}
{"id": 7002, "code": "\tpublic void setAutoDetectGettersSetters(boolean autoDetectGettersSetters) {\n\t\tthis.builder.autoDetectGettersSetters(autoDetectGettersSetters);\n\t}", "summary_tokens": ["shortcut", "for", "mapper", "feature", "auto", "detect", "setters", "mapper", "feature", "auto", "detect", "getters", "mapper", "feature", "auto", "detect", "is", "getters", "options"], "project": "spring-framework"}
{"id": 7640, "code": "\tprotected MultiValueMap<String, MultipartFile> getMultipartFiles() {\n\t\tif (this.multipartFiles == null) {\n\t\t\tinitializeMultipart();\n\t\t}\n\t\treturn this.multipartFiles;\n\t}", "summary_tokens": ["obtain", "the", "multipart", "file", "map", "for", "retrieval", "lazily", "initializing", "it", "if", "necessary"], "project": "spring-framework"}
{"id": 5604, "code": "\tprotected TestContextManager createTestContextManager(Class<?> clazz) {\n\t\treturn new TestContextManager(clazz);\n\t}", "summary_tokens": ["create", "a", "new", "test", "context", "manager", "for", "the", "supplied", "test", "class"], "project": "spring-framework"}
{"id": 57, "code": "\tprivate AbstractBeanDefinition parseDeclareParents(Element declareParentsElement, ParserContext parserContext) {\n\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.rootBeanDefinition(DeclareParentsAdvisor.class);\n\t\tbuilder.addConstructorArgValue(declareParentsElement.getAttribute(IMPLEMENT_INTERFACE));\n\t\tbuilder.addConstructorArgValue(declareParentsElement.getAttribute(TYPE_PATTERN));\n\n\t\tString defaultImpl = declareParentsElement.getAttribute(DEFAULT_IMPL);\n\t\tString delegateRef = declareParentsElement.getAttribute(DELEGATE_REF);\n\n\t\tif (StringUtils.hasText(defaultImpl) && !StringUtils.hasText(delegateRef)) {\n\t\t\tbuilder.addConstructorArgValue(defaultImpl);\n\t\t}\n\t\telse if (StringUtils.hasText(delegateRef) && !StringUtils.hasText(defaultImpl)) {\n\t\t\tbuilder.addConstructorArgReference(delegateRef);\n\t\t}\n\t\telse {\n\t\t\tparserContext.getReaderContext().error(\n\t\t\t\t\t\"Exactly one of the \" + DEFAULT_IMPL + \" or \" + DELEGATE_REF + \" attributes must be specified\",\n\t\t\t\t\tdeclareParentsElement, this.parseState.snapshot());\n\t\t}\n\n\t\tAbstractBeanDefinition definition = builder.getBeanDefinition();\n\t\tdefinition.setSource(parserContext.extractSource(declareParentsElement));\n\t\tparserContext.getReaderContext().registerWithGeneratedName(definition);\n\t\treturn definition;\n\t}", "summary_tokens": ["parse", "a", "declare", "parents", "element", "and", "register", "the", "appropriate", "declare", "parents", "advisor", "with", "the", "bean", "definition", "registry", "encapsulated", "in", "the", "supplied", "parser", "context"], "project": "spring-framework"}
{"id": 1668, "code": "\tpublic void setObjectName(@Nullable String objectName) {\n\t\tthis.objectName = objectName;\n\t}", "summary_tokens": ["set", "the", "jmx", "object", "name", "of", "this", "managed", "resource"], "project": "spring-framework"}
{"id": 5184, "code": "\tprivate boolean matchesEntityTypeFilter(MetadataReader reader, MetadataReaderFactory readerFactory) throws IOException {\n\t\tif (this.entityTypeFilters != null) {\n\t\t\tfor (TypeFilter filter : this.entityTypeFilters) {\n\t\t\t\tif (filter.match(reader, readerFactory)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["check", "whether", "any", "of", "the", "configured", "entity", "type", "filters", "matches", "the", "current", "class", "descriptor", "contained", "in", "the", "metadata", "reader"], "project": "spring-framework"}
{"id": 4689, "code": "\tpublic void setValidator(Validator validator) {\n\t\tthis.validator = validator;\n\t}", "summary_tokens": ["set", "the", "validator", "instance", "used", "for", "validating", "arguments"], "project": "spring-framework"}
{"id": 8740, "code": "\tstatic Builder from(RenderingResponse other) {\n\t\treturn new DefaultRenderingResponseBuilder(other);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "the", "template", "name", "status", "code", "headers", "and", "model", "of", "the", "given", "response"], "project": "spring-framework"}
{"id": 6267, "code": "\tpublic void setTransactionManager(@Nullable TransactionManager transactionManager) {\n\t\tthis.transactionManager = transactionManager;\n\t}", "summary_tokens": ["specify", "the", "em", "default", "em", "transaction", "manager", "to", "use", "to", "drive", "transactions"], "project": "spring-framework"}
{"id": 402, "code": "\tdefault T getIfUnique(Supplier<T> defaultSupplier) throws BeansException {\n\t\tT dependency = getIfUnique();\n\t\treturn (dependency != null ? dependency : defaultSupplier.get());\n\t}", "summary_tokens": ["return", "an", "instance", "possibly", "shared", "or", "independent", "of", "the", "object", "managed", "by", "this", "factory"], "project": "spring-framework"}
{"id": 8843, "code": "\tpublic String getParamName() {\n\t\treturn this.paramName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "parameter", "that", "contains", "a", "locale", "specification", "in", "a", "locale", "change", "request"], "project": "spring-framework"}
{"id": 2775, "code": "\tpublic static AnnotationAttributes findMergedAnnotationAttributes(AnnotatedElement element,\n\t\t\tString annotationName, boolean classValuesAsString, boolean nestedAnnotationsAsMap) {\n\n\t\tMergedAnnotation<?> mergedAnnotation = findAnnotations(element)\n\t\t\t\t.get(annotationName, null, MergedAnnotationSelectors.firstDirectlyDeclared());\n\t\treturn getAnnotationAttributes(mergedAnnotation, classValuesAsString, nestedAnnotationsAsMap);\n\t}", "summary_tokens": ["find", "the", "first", "annotation", "of", "the", "specified", "annotation", "name", "within", "the", "annotation", "hierarchy", "em", "above", "em", "the", "supplied", "element", "and", "merge", "that", "annotation", "s", "attributes", "with", "em", "matching", "em", "attributes", "from", "annotations", "in", "lower", "levels", "of", "the", "annotation", "hierarchy"], "project": "spring-framework"}
{"id": 2296, "code": "\tpublic static ResourceHintsPredicates resource() {\n\t\treturn resource;\n\t}", "summary_tokens": ["return", "a", "predicate", "generator", "for", "resource", "hints", "resource", "hints"], "project": "spring-framework"}
{"id": 8221, "code": "\tpublic void setBodyRequired(boolean bodyRequired) {\n\t\tthis.bodyRequired = bodyRequired;\n\t}", "summary_tokens": ["whether", "this", "condition", "should", "expect", "requests", "to", "have", "a", "body"], "project": "spring-framework"}
{"id": 511, "code": "\tpublic void setValueSeparator(@Nullable String valueSeparator) {\n\t\tthis.valueSeparator = valueSeparator;\n\t}", "summary_tokens": ["specify", "the", "separating", "character", "between", "the", "placeholder", "variable", "and", "the", "associated", "default", "value", "or", "null", "if", "no", "such", "special", "character", "should", "be", "processed", "as", "a", "value", "separator"], "project": "spring-framework"}
{"id": 7411, "code": "\tpublic List<String> getAllowedHeaders() {\n\t\treturn this.allowedHeaders;\n\t}", "summary_tokens": ["return", "the", "allowed", "actual", "request", "headers", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 8820, "code": "\tpublic void setExceptionAttribute(@Nullable String exceptionAttribute) {\n\t\tthis.exceptionAttribute = exceptionAttribute;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "model", "attribute", "as", "which", "the", "exception", "should", "be", "exposed"], "project": "spring-framework"}
{"id": 7714, "code": "\tpublic boolean hasLocaleContextResolver() {\n\t\treturn (this.localeContextResolver != null);\n\t}", "summary_tokens": ["whether", "a", "locale", "context", "resolver", "is", "configured", "or", "not", "either", "detected", "from", "an", "application", "context", "or", "explicitly", "configured", "via", "locale", "context", "resolver"], "project": "spring-framework"}
{"id": 9325, "code": "\tpublic void setOnchange(String onchange) {\n\t\tthis.onchange = onchange;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "onchange", "attribute"], "project": "spring-framework"}
{"id": 833, "code": "\tpublic void setEventListener(@Nullable ReaderEventListener eventListener) {\n\t\tthis.eventListener = (eventListener != null ? eventListener : new EmptyReaderEventListener());\n\t}", "summary_tokens": ["specify", "which", "reader", "event", "listener", "to", "use"], "project": "spring-framework"}
{"id": 332, "code": "\tpublic static int getFirstNestedPropertySeparatorIndex(String propertyPath) {\n\t\treturn getNestedPropertySeparatorIndex(propertyPath, false);\n\t}", "summary_tokens": ["determine", "the", "first", "nested", "property", "separator", "in", "the", "given", "property", "path", "ignoring", "dots", "in", "keys", "like", "map", "my"], "project": "spring-framework"}
{"id": 836, "code": "\tpublic void setDocumentLoader(@Nullable DocumentLoader documentLoader) {\n\t\tthis.documentLoader = (documentLoader != null ? documentLoader : new DefaultDocumentLoader());\n\t}", "summary_tokens": ["specify", "the", "document", "loader", "to", "use"], "project": "spring-framework"}
{"id": 6976, "code": "\tpublic Jackson2ObjectMapperBuilder findModulesViaServiceLoader(boolean findModules) {\n\t\tthis.findModulesViaServiceLoader = findModules;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "whether", "to", "let", "jackson", "find", "available", "modules", "via", "the", "jdk", "service", "loader", "based", "on", "meta", "inf", "metadata", "in", "the", "classpath"], "project": "spring-framework"}
{"id": 9056, "code": "\tprotected void sendServerError(Exception ex, HttpServletRequest request, HttpServletResponse response)\n\t\t\tthrows IOException {\n\n\t\trequest.setAttribute(WebUtils.ERROR_EXCEPTION_ATTRIBUTE, ex);\n\t\tresponse.sendError(HttpServletResponse.SC_INTERNAL_SERVER_ERROR);\n\t}", "summary_tokens": ["invoked", "to", "send", "a", "server", "error"], "project": "spring-framework"}
{"id": 1977, "code": "\tpublic int getAutoGrowCollectionLimit() {\n\t\treturn this.autoGrowCollectionLimit;\n\t}", "summary_tokens": ["return", "the", "current", "limit", "for", "array", "and", "collection", "auto", "growing"], "project": "spring-framework"}
{"id": 4147, "code": "\tpublic void setExceptionTranslator(SQLExceptionTranslator exceptionTranslator) {\n\t\tthis.exceptionTranslator = exceptionTranslator;\n\t}", "summary_tokens": ["set", "the", "exception", "translator", "for", "this", "instance"], "project": "spring-framework"}
{"id": 4715, "code": "\tprotected void registerExceptionHandlerAdvice(\n\t\t\tMessagingAdviceBean bean, AbstractExceptionHandlerMethodResolver resolver) {\n\n\t\tthis.exceptionHandlerAdviceCache.put(bean, resolver);\n\t}", "summary_tokens": ["subclasses", "can", "invoke", "this", "method", "to", "populate", "the", "messaging", "advice", "bean", "cache", "e"], "project": "spring-framework"}
{"id": 9132, "code": "\tpublic Boolean getResponseEncodedHtmlEscape() {\n\t\treturn this.responseEncodedHtmlEscape;\n\t}", "summary_tokens": ["return", "the", "default", "setting", "about", "use", "of", "response", "encoding", "for", "html", "escape", "setting", "differentiating", "between", "no", "default", "specified", "and", "an", "explicit", "value"], "project": "spring-framework"}
{"id": 9172, "code": "\tpublic final boolean isUseCacheControlHeader() {\n\t\treturn this.useCacheControlHeader;\n\t}", "summary_tokens": ["return", "whether", "the", "http", "0"], "project": "spring-framework"}
{"id": 8731, "code": "\tdefault Validator getValidator() {\n\t\treturn null;\n\t}", "summary_tokens": ["provide", "a", "custom", "validator", "instead", "of", "the", "one", "created", "by", "default"], "project": "spring-framework"}
{"id": 2127, "code": "\tpublic static void zeroOutFactoryCount() throws Exception {\n\t\tgetSerializableFactoryMap().clear();\n\t}", "summary_tokens": ["defensively", "zero", "out", "static", "factory", "count", "other", "tests", "may", "have", "misbehaved", "before", "us"], "project": "spring-framework"}
{"id": 7402, "code": "\tpublic List<String> getAllowedOrigins() {\n\t\treturn this.allowedOrigins;\n\t}", "summary_tokens": ["return", "the", "configured", "origins", "to", "allow", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 4818, "code": "\tpublic Object getSessionMutex() {\n\t\tObject mutex = this.attributes.get(SESSION_MUTEX_NAME);\n\t\tif (mutex == null) {\n\t\t\tmutex = this.attributes;\n\t\t}\n\t\treturn mutex;\n\t}", "summary_tokens": ["expose", "the", "object", "to", "synchronize", "on", "for", "the", "underlying", "session"], "project": "spring-framework"}
{"id": 8171, "code": "\tstatic HeadersBuilder<?> notFound() {\n\t\treturn status(HttpStatus.NOT_FOUND);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "a", "http", "status", "not", "found", "0", "not", "found", "status"], "project": "spring-framework"}
{"id": 4720, "code": "\tpublic HandlerMethodArgumentResolverComposite addResolver(HandlerMethodArgumentResolver resolver) {\n\t\tthis.argumentResolvers.add(resolver);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "given", "handler", "method", "argument", "resolver"], "project": "spring-framework"}
{"id": 8779, "code": "\tstatic HeadersBuilder<?> notFound() {\n\t\treturn status(HttpStatus.NOT_FOUND);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "a", "http", "status", "not", "found", "0", "not", "found", "status"], "project": "spring-framework"}
{"id": 6604, "code": "\tpublic static CacheControl empty() {\n\t\treturn new CacheControl();\n\t}", "summary_tokens": ["return", "an", "empty", "directive"], "project": "spring-framework"}
{"id": 2280, "code": "\tpublic SerializationHints registerType(Class<? extends Serializable> type) {\n\t\treturn registerType(type, null);\n\t}", "summary_tokens": ["register", "that", "the", "specified", "type", "need", "to", "be", "serialized", "using", "java", "serialization"], "project": "spring-framework"}
{"id": 147, "code": "\tpublic void setBeanNames(String... beanNames) {\n\t\tAssert.notEmpty(beanNames, \"'beanNames' must not be empty\");\n\t\tthis.beanNames = new ArrayList<>(beanNames.length);\n\t\tfor (String mappedName : beanNames) {\n\t\t\tthis.beanNames.add(mappedName.strip());\n\t\t}\n\t}", "summary_tokens": ["set", "the", "names", "of", "the", "beans", "that", "should", "automatically", "get", "wrapped", "with", "proxies"], "project": "spring-framework"}
{"id": 7720, "code": "\tpublic WebHttpHandlerBuilder clone() {\n\t\treturn new WebHttpHandlerBuilder(this);\n\t}", "summary_tokens": ["clone", "this", "web", "http", "handler", "builder"], "project": "spring-framework"}
{"id": 3461, "code": "\tprotected void testDecodeToMonoCancel(Publisher<DataBuffer> input, ResolvableType outputType,\n\t\t\t@Nullable MimeType mimeType, @Nullable Map<String, Object> hints) {\n\n\t\tMono<?> result = this.decoder.decodeToMono(input, outputType, mimeType, hints);\n\t\tStepVerifier.create(result).thenCancel().verify();\n\t}", "summary_tokens": ["test", "a", "decoder", "decode", "to", "mono", "decode", "scenario", "where", "the", "input", "stream", "is", "canceled"], "project": "spring-framework"}
{"id": 8497, "code": "\tprivate void initHandlerMappings(ApplicationContext context) {\n\t\tthis.handlerMappings = null;\n\n\t\tif (this.detectAllHandlerMappings) {\n\t\t\t\n\t\t\tMap<String, HandlerMapping> matchingBeans =\n\t\t\t\t\tBeanFactoryUtils.beansOfTypeIncludingAncestors(context, HandlerMapping.class, true, false);\n\t\t\tif (!matchingBeans.isEmpty()) {\n\t\t\t\tthis.handlerMappings = new ArrayList<>(matchingBeans.values());\n\t\t\t\t\n\t\t\t\tAnnotationAwareOrderComparator.sort(this.handlerMappings);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\tHandlerMapping hm = context.getBean(HANDLER_MAPPING_BEAN_NAME, HandlerMapping.class);\n\t\t\t\tthis.handlerMappings = Collections.singletonList(hm);\n\t\t\t}\n\t\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\n\t\t\n\t\t\n\t\tif (this.handlerMappings == null) {\n\t\t\tthis.handlerMappings = getDefaultStrategies(context, HandlerMapping.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"No HandlerMappings declared for servlet '\" + getServletName() +\n\t\t\t\t\t\t\"': using default strategies from DispatcherServlet.properties\");\n\t\t\t}\n\t\t}\n\n\t\tfor (HandlerMapping mapping : this.handlerMappings) {\n\t\t\tif (mapping.usesPathPatterns()) {\n\t\t\t\tthis.parseRequestPath = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "handler", "mappings", "used", "by", "this", "class"], "project": "spring-framework"}
{"id": 7914, "code": "\tpublic void setWriteHandler(Function<Flux<DataBuffer>, Mono<Void>> writeHandler) {\n\t\tAssert.notNull(writeHandler, \"'writeHandler' is required\");\n\t\tthis.writeHandler = writeHandler;\n\t}", "summary_tokens": ["configure", "a", "custom", "handler", "for", "writing", "the", "request", "body"], "project": "spring-framework"}
{"id": 9524, "code": "\tpublic boolean checkResource(Locale locale) throws Exception {\n\t\treturn true;\n\t}", "summary_tokens": ["check", "whether", "the", "underlying", "resource", "that", "the", "configured", "url", "points", "to", "actually", "exists"], "project": "spring-framework"}
{"id": 2729, "code": "\tpublic boolean isNoValue() {\n\t\treturn getDescriptor().isNoValue();\n\t}", "summary_tokens": ["shortcut", "for", "get", "descriptor"], "project": "spring-framework"}
{"id": 3039, "code": "\tpublic static String formatValue(\n\t\t\t@Nullable Object value, int maxLength, boolean replaceNewlinesAndControlCharacters) {\n\n\t\tif (value == null) {\n\t\t\treturn \"\";\n\t\t}\n\t\tString result;\n\t\ttry {\n\t\t\tresult = ObjectUtils.nullSafeToString(value);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tresult = ObjectUtils.nullSafeToString(ex);\n\t\t}\n\t\tif (maxLength != -1) {\n\t\t\tresult = (result.length() > maxLength ? result.substring(0, maxLength) + \" (truncated)...\" : result);\n\t\t}\n\t\tif (replaceNewlinesAndControlCharacters) {\n\t\t\tresult = NEWLINE_PATTERN.matcher(result).replaceAll(\"<EOL>\");\n\t\t\tresult = CONTROL_CHARACTER_PATTERN.matcher(result).replaceAll(\"?\");\n\t\t}\n\t\tif (value instanceof CharSequence) {\n\t\t\tresult = \"\\\"\" + result + \"\\\"\";\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["format", "the", "given", "value", "via", "to", "string", "quoting", "it", "if", "it", "is", "a", "char", "sequence", "truncating", "at", "the", "specified", "max", "length", "and", "compacting", "it", "into", "a", "single", "line", "when", "replace", "new", "lines", "is", "set"], "project": "spring-framework"}
{"id": 3691, "code": "\tprotected void processRow(ResultSet rs, int rowNum) throws SQLException {\n\t}", "summary_tokens": ["subclasses", "may", "override", "this", "to", "perform", "custom", "extraction", "or", "processing"], "project": "spring-framework"}
{"id": 2686, "code": "\tprotected Class<?> resolveFallbackIfPossible(String className, ClassNotFoundException ex)\n\t\t\tthrows IOException, ClassNotFoundException{\n\n\t\tthrow ex;\n\t}", "summary_tokens": ["resolve", "the", "given", "class", "name", "against", "a", "fallback", "class", "loader"], "project": "spring-framework"}
{"id": 7609, "code": "\tpublic String getViewName() {\n\t\treturn (this.view instanceof String ? (String) this.view : null);\n\t}", "summary_tokens": ["return", "the", "view", "name", "to", "be", "resolved", "by", "the", "dispatcher", "servlet", "via", "a", "view", "resolver", "or", "null", "if", "a", "view", "object", "is", "set"], "project": "spring-framework"}
{"id": 8313, "code": "\tprotected String[] resolveEmbeddedValuesInPatterns(String[] patterns) {\n\t\tif (this.embeddedValueResolver == null) {\n\t\t\treturn patterns;\n\t\t}\n\t\telse {\n\t\t\tString[] resolvedPatterns = new String[patterns.length];\n\t\t\tfor (int i = 0; i < patterns.length; i++) {\n\t\t\t\tresolvedPatterns[i] = this.embeddedValueResolver.resolveStringValue(patterns[i]);\n\t\t\t}\n\t\t\treturn resolvedPatterns;\n\t\t}\n\t}", "summary_tokens": ["resolve", "placeholder", "values", "in", "the", "given", "array", "of", "patterns"], "project": "spring-framework"}
{"id": 3293, "code": "\tpublic static String copyToString(ByteArrayOutputStream baos, Charset charset) {\n\t\tAssert.notNull(baos, \"No ByteArrayOutputStream specified\");\n\t\tAssert.notNull(charset, \"No Charset specified\");\n\n\t\treturn baos.toString(charset);\n\t}", "summary_tokens": ["copy", "the", "contents", "of", "the", "given", "byte", "array", "output", "stream", "into", "a", "string"], "project": "spring-framework"}
{"id": 3783, "code": "\tpublic int[] createInsertTypes() {\n\t\tint[] types = new int[getTableColumns().size()];\n\t\tList<TableParameterMetaData> parameters = obtainMetaDataProvider().getTableParameterMetaData();\n\t\tMap<String, TableParameterMetaData> parameterMap = CollectionUtils.newLinkedHashMap(parameters.size());\n\t\tfor (TableParameterMetaData tpmd : parameters) {\n\t\t\tparameterMap.put(tpmd.getParameterName().toUpperCase(), tpmd);\n\t\t}\n\t\tint typeIndx = 0;\n\t\tfor (String column : getTableColumns()) {\n\t\t\tif (column == null) {\n\t\t\t\ttypes[typeIndx] = SqlTypeValue.TYPE_UNKNOWN;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tTableParameterMetaData tpmd = parameterMap.get(column.toUpperCase());\n\t\t\t\tif (tpmd != null) {\n\t\t\t\t\ttypes[typeIndx] = tpmd.getSqlType();\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\ttypes[typeIndx] = SqlTypeValue.TYPE_UNKNOWN;\n\t\t\t\t}\n\t\t\t}\n\t\t\ttypeIndx++;\n\t\t}\n\t\treturn types;\n\t}", "summary_tokens": ["build", "the", "array", "of", "java"], "project": "spring-framework"}
{"id": 2705, "code": "\tpublic void excludeClass(String className) {\n\t\tAssert.notNull(className, \"Class name must not be null\");\n\t\tthis.excludedClasses.add(className);\n\t}", "summary_tokens": ["add", "a", "class", "name", "to", "exclude", "from", "decoration", "e"], "project": "spring-framework"}
{"id": 5272, "code": "\tprotected Document buildDocument(ErrorHandler handler, InputStream stream)\n\t\t\tthrows ParserConfigurationException, SAXException, IOException {\n\n\t\tDocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();\n\t\tdbf.setNamespaceAware(true);\n\t\tDocumentBuilder parser = dbf.newDocumentBuilder();\n\t\tparser.setErrorHandler(handler);\n\t\treturn parser.parse(stream);\n\t}", "summary_tokens": ["validate", "the", "given", "stream", "and", "return", "a", "valid", "dom", "document", "for", "parsing"], "project": "spring-framework"}
{"id": 5282, "code": "\tpublic void addTransformer(ClassTransformer classTransformer) {\n\t\tif (this.loadTimeWeaver == null) {\n\t\t\tthrow new IllegalStateException(\"Cannot apply class transformer without LoadTimeWeaver specified\");\n\t\t}\n\t\tthis.loadTimeWeaver.addTransformer(new ClassFileTransformerAdapter(classTransformer));\n\t}", "summary_tokens": ["this", "implementation", "delegates", "to", "the", "load", "time", "weaver", "if", "specified"], "project": "spring-framework"}
{"id": 2778, "code": "\tpublic static <A extends Annotation> Set<A> findMergedRepeatableAnnotations(AnnotatedElement element,\n\t\t\tClass<A> annotationType, @Nullable Class<? extends Annotation> containerType) {\n\n\t\treturn findRepeatableAnnotations(element, containerType, annotationType)\n\t\t\t\t.stream(annotationType)\n\t\t\t\t.sorted(highAggregateIndexesFirst())\n\t\t\t\t.collect(MergedAnnotationCollectors.toAnnotationSet());\n\t}", "summary_tokens": ["find", "all", "em", "repeatable", "annotations", "em", "of", "the", "specified", "annotation", "type", "within", "the", "annotation", "hierarchy", "em", "above", "em", "the", "supplied", "element", "and", "for", "each", "annotation", "found", "merge", "that", "annotation", "s", "attributes", "with", "em", "matching", "em", "attributes", "from", "annotations", "in", "lower", "levels", "of", "the", "annotation", "hierarchy", "and", "synthesize", "the", "results", "back", "into", "an", "annotation", "of", "the", "specified", "annotation", "type"], "project": "spring-framework"}
{"id": 3152, "code": "\tpublic static Class<?> getUserClass(Class<?> clazz) {\n\t\tif (clazz.getName().contains(CGLIB_CLASS_SEPARATOR)) {\n\t\t\tClass<?> superclass = clazz.getSuperclass();\n\t\t\tif (superclass != null && superclass != Object.class) {\n\t\t\t\treturn superclass;\n\t\t\t}\n\t\t}\n\t\treturn clazz;\n\t}", "summary_tokens": ["return", "the", "user", "defined", "class", "for", "the", "given", "class", "usually", "simply", "the", "given", "class", "but", "the", "original", "class", "in", "case", "of", "a", "cglib", "generated", "subclass"], "project": "spring-framework"}
{"id": 7351, "code": "\tprotected void initPropertySources() {\n\t\tConfigurableEnvironment env = getEnvironment();\n\t\tif (env instanceof ConfigurableWebEnvironment) {\n\t\t\t((ConfigurableWebEnvironment) env).initPropertySources(this.servletContext, null);\n\t\t}\n\t}", "summary_tokens": ["p", "replace", "servlet", "related", "property", "sources"], "project": "spring-framework"}
{"id": 4898, "code": "\tpublic MessageBrokerRegistry setPathMatcher(PathMatcher pathMatcher) {\n\t\tthis.pathMatcher = pathMatcher;\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "the", "path", "matcher", "to", "use", "to", "match", "the", "destinations", "of", "incoming", "messages", "to", "and", "methods"], "project": "spring-framework"}
{"id": 8442, "code": "\tpublic Mono<Principal> getPrincipal() {\n\t\treturn this.principalMono;\n\t}", "summary_tokens": ["return", "the", "principal", "associated", "with", "the", "handshake", "request", "if", "any"], "project": "spring-framework"}
{"id": 1280, "code": "\tpublic void setEnvironment(Environment environment) {\n\t\tAssert.notNull(environment, \"Environment must not be null\");\n\t\tthis.environment = environment;\n\t\tthis.conditionEvaluator = null;\n\t}", "summary_tokens": ["set", "the", "environment", "to", "use", "when", "resolving", "placeholders", "and", "evaluating", "conditional", "annotated", "component", "classes"], "project": "spring-framework"}
{"id": 6234, "code": "\tdefault boolean isCandidateClass(Class<?> targetClass) {\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "class", "is", "a", "candidate", "for", "transaction", "attributes", "in", "the", "annotation", "format", "of", "this", "transaction", "annotation", "parser"], "project": "spring-framework"}
{"id": 8070, "code": "\tpublic static <T, P extends Publisher<T>> MultipartInserter fromMultipartAsyncData(\n\t\t\tString name, P publisher, ParameterizedTypeReference<T> typeReference) {\n\n\t\treturn new DefaultMultipartInserter().withPublisher(name, publisher, typeReference);\n\t}", "summary_tokens": ["variant", "of", "from", "multipart", "async", "data", "string", "publisher", "class", "that", "accepts", "a", "parameterized", "type", "reference", "for", "the", "element", "type", "which", "allows", "specifying", "generic", "type", "information"], "project": "spring-framework"}
{"id": 2630, "code": "public void create_arg_array() {\n        \n\n    push(state.argumentTypes.length);\n    newarray();\n    for (int i = 0; i < state.argumentTypes.length; i++) {\n        dup();\n        push(i);\n        load_arg(i);\n        box(state.argumentTypes[i]);\n        aastore();\n    }\n}", "summary_tokens": ["allocates", "and", "fills", "an", "object", "array", "with", "the", "arguments", "to", "the", "current", "method"], "project": "spring-framework"}
{"id": 7230, "code": "\tprotected Charset getCharset(ClientHttpResponse response) {\n\t\tHttpHeaders headers = response.getHeaders();\n\t\tMediaType contentType = headers.getContentType();\n\t\treturn (contentType != null ? contentType.getCharset() : null);\n\t}", "summary_tokens": ["determine", "the", "charset", "of", "the", "response", "for", "inclusion", "in", "a", "status", "exception"], "project": "spring-framework"}
{"id": 4208, "code": "\tpublic void malformedSqlStateCodes() {\n\t\tSQLException sex = new SQLException(\"Message\", null, 1);\n\t\tassertThat(this.trans.translate(\"task\", sql, sex)).isNull();\n\n\t\tsex = new SQLException(\"Message\", \"\", 1);\n\t\tassertThat(this.trans.translate(\"task\", sql, sex)).isNull();\n\n\t\t\n\t\tsex = new SQLException(\"Message\", \"I\", 1);\n\t\tassertThat(this.trans.translate(\"task\", sql, sex)).isNull();\n\t}", "summary_tokens": ["postgre", "sql", "can", "return", "null"], "project": "spring-framework"}
{"id": 5990, "code": "\tpublic ResultMatcher exists(String name) {\n\t\treturn result -> assertTrue(\"Response should contain header '\" + name + \"'\",\n\t\t\t\tresult.getResponse().containsHeader(name));\n\t}", "summary_tokens": ["assert", "that", "the", "named", "response", "header", "exists"], "project": "spring-framework"}
{"id": 1997, "code": "\tpublic String[] getRequiredFields() {\n\t\treturn this.requiredFields;\n\t}", "summary_tokens": ["return", "the", "fields", "that", "are", "required", "for", "each", "binding", "process"], "project": "spring-framework"}
{"id": 6792, "code": "\tpublic void setLoopResourcesSupplier(Supplier<LoopResources> supplier) {\n\t\tthis.loopResourcesSupplier = supplier;\n\t}", "summary_tokens": ["use", "this", "when", "you", "don", "t", "want", "to", "participate", "in", "global", "resources", "and", "you", "want", "to", "customize", "the", "creation", "of", "the", "managed", "loop", "resources"], "project": "spring-framework"}
{"id": 4130, "code": "\tpublic void setErrorCodes(String... errorCodes) {\n\t\tthis.errorCodes = StringUtils.sortStringArray(errorCodes);\n\t}", "summary_tokens": ["set", "the", "sql", "error", "codes", "to", "match"], "project": "spring-framework"}
{"id": 554, "code": "\tdefault Class<?> determineBeanType(Class<?> beanClass, String beanName) throws BeansException {\n\t\treturn beanClass;\n\t}", "summary_tokens": ["determine", "the", "type", "of", "the", "bean", "to", "be", "eventually", "returned", "from", "this", "processor", "s", "post", "process", "before", "instantiation", "callback"], "project": "spring-framework"}
{"id": 8064, "code": "\tpublic static <T> BodyInserter<T, ReactiveHttpOutputMessage> fromProducer(\n\t\t\tT producer, ParameterizedTypeReference<?> elementTypeRef) {\n\n\t\tAssert.notNull(producer, \"'producer' must not be null\");\n\t\tAssert.notNull(elementTypeRef, \"'elementTypeRef' must not be null\");\n\t\tReactiveAdapter adapter = ReactiveAdapterRegistry.getSharedInstance().getAdapter(producer.getClass());\n\t\tAssert.notNull(adapter, \"'producer' type is unknown to ReactiveAdapterRegistry\");\n\t\treturn (message, context) ->\n\t\t\t\twriteWithMessageWriters(message, context, producer, ResolvableType.forType(elementTypeRef), adapter);\n\t}", "summary_tokens": ["inserter", "to", "write", "the", "given", "producer", "of", "value", "s", "which", "must", "be", "a", "publisher", "or", "another", "producer", "adaptable", "to", "a", "publisher", "via", "reactive", "adapter", "registry"], "project": "spring-framework"}
{"id": 4058, "code": "\tpublic int getQueueCount() {\n\t\treturn this.parameterQueue.size();\n\t}", "summary_tokens": ["return", "the", "current", "number", "of", "statements", "or", "statement", "parameters", "in", "the", "queue"], "project": "spring-framework"}
{"id": 3127, "code": "\tpublic static boolean isPrimitiveWrapper(Class<?> clazz) {\n\t\tAssert.notNull(clazz, \"Class must not be null\");\n\t\treturn primitiveWrapperTypeMap.containsKey(clazz);\n\t}", "summary_tokens": ["check", "if", "the", "given", "class", "represents", "a", "primitive", "wrapper", "i"], "project": "spring-framework"}
{"id": 4269, "code": "\tpublic final void addConnection(Connection connection) {\n\t\tAssert.isTrue(!this.frozen, \"Cannot add Connection because JmsResourceHolder is frozen\");\n\t\tAssert.notNull(connection, \"Connection must not be null\");\n\t\tif (!this.connections.contains(connection)) {\n\t\t\tthis.connections.add(connection);\n\t\t}\n\t}", "summary_tokens": ["add", "the", "given", "connection", "to", "this", "resource", "holder"], "project": "spring-framework"}
{"id": 9197, "code": "\tprotected void writeBodyContent(String content) throws IOException {\n\t\tAssert.state(this.bodyContent != null, \"No BodyContent set\");\n\t\tthis.bodyContent.getEnclosingWriter().print(content);\n\t}", "summary_tokens": ["write", "the", "escaped", "body", "content", "to", "the", "page"], "project": "spring-framework"}
{"id": 4337, "code": "\tpublic void setDeliveryPersistent(boolean deliveryPersistent) {\n\t\tthis.deliveryMode = (deliveryPersistent ? DeliveryMode.PERSISTENT : DeliveryMode.NON_PERSISTENT);\n\t}", "summary_tokens": ["set", "whether", "message", "delivery", "should", "be", "persistent", "or", "non", "persistent", "specified", "as", "boolean", "value", "true", "or", "false"], "project": "spring-framework"}
{"id": 339, "code": "\tpublic final PropertyAccessException[] getPropertyAccessExceptions() {\n\t\treturn this.propertyAccessExceptions;\n\t}", "summary_tokens": ["return", "an", "array", "of", "the", "property", "access", "exceptions", "stored", "in", "this", "object"], "project": "spring-framework"}
{"id": 1567, "code": "\tpublic Object invoke(String opName, Object[] opArgs, String[] sig)\n\t\t\tthrows MBeanException, ReflectionException {\n\n\t\tClassLoader currentClassLoader = Thread.currentThread().getContextClassLoader();\n\t\ttry {\n\t\t\tThread.currentThread().setContextClassLoader(this.managedResourceClassLoader);\n\t\t\treturn super.invoke(opName, opArgs, sig);\n\t\t}\n\t\tfinally {\n\t\t\tThread.currentThread().setContextClassLoader(currentClassLoader);\n\t\t}\n\t}", "summary_tokens": ["switches", "the", "thread", "get", "context", "class", "loader", "context", "class", "loader", "for", "the", "managed", "resources", "class", "loader", "before", "allowing", "the", "invocation", "to", "occur"], "project": "spring-framework"}
{"id": 2042, "code": "\tprotected void doValidate(Object bean) {\n\t\tAssert.state(this.validator != null, \"No Validator set\");\n\t\tObject objectToValidate = AopProxyUtils.getSingletonTarget(bean);\n\t\tif (objectToValidate == null) {\n\t\t\tobjectToValidate = bean;\n\t\t}\n\t\tSet<ConstraintViolation<Object>> result = this.validator.validate(objectToValidate);\n\n\t\tif (!result.isEmpty()) {\n\t\t\tStringBuilder sb = new StringBuilder(\"Bean state is invalid: \");\n\t\t\tfor (Iterator<ConstraintViolation<Object>> it = result.iterator(); it.hasNext();) {\n\t\t\t\tConstraintViolation<Object> violation = it.next();\n\t\t\t\tsb.append(violation.getPropertyPath()).append(\" - \").append(violation.getMessage());\n\t\t\t\tif (it.hasNext()) {\n\t\t\t\t\tsb.append(\"; \");\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow new BeanInitializationException(sb.toString());\n\t\t}\n\t}", "summary_tokens": ["perform", "validation", "of", "the", "given", "bean"], "project": "spring-framework"}
{"id": 7635, "code": "\tpublic boolean isOpen() {\n\t\treturn true;\n\t}", "summary_tokens": ["this", "implementation", "always", "returns", "true"], "project": "spring-framework"}
{"id": 8172, "code": "\tstatic BodyBuilder unprocessableEntity() {\n\t\treturn status(HttpStatus.UNPROCESSABLE_ENTITY);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "an", "http", "status", "unprocessable", "entity", "0", "unprocessable", "entity", "status"], "project": "spring-framework"}
{"id": 1973, "code": "\tpublic String getObjectName() {\n\t\treturn this.objectName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "bound", "object"], "project": "spring-framework"}
{"id": 6324, "code": "\tprotected UserTransaction findUserTransaction() {\n\t\tString jndiName = DEFAULT_USER_TRANSACTION_NAME;\n\t\ttry {\n\t\t\tUserTransaction ut = getJndiTemplate().lookup(jndiName, UserTransaction.class);\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"JTA UserTransaction found at default JNDI location [\" + jndiName + \"]\");\n\t\t\t}\n\t\t\tthis.userTransactionObtainedFromJndi = true;\n\t\t\treturn ut;\n\t\t}\n\t\tcatch (NamingException ex) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"No JTA UserTransaction found at default JNDI location [\" + jndiName + \"]\", ex);\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["find", "the", "jta", "user", "transaction", "through", "a", "default", "jndi", "lookup", "java", "comp", "user", "transaction"], "project": "spring-framework"}
{"id": 5174, "code": "\tpublic final Configuration getConfiguration() {\n\t\tif (this.configuration == null) {\n\t\t\tthrow new IllegalStateException(\"Configuration not initialized yet\");\n\t\t}\n\t\treturn this.configuration;\n\t}", "summary_tokens": ["return", "the", "hibernate", "configuration", "object", "used", "to", "build", "the", "session", "factory"], "project": "spring-framework"}
{"id": 9064, "code": "\tpublic void setContentCodings(List<String> codings) {\n\t\tAssert.notEmpty(codings, \"At least one content coding expected\");\n\t\tthis.contentCodings.clear();\n\t\tthis.contentCodings.addAll(codings);\n\t}", "summary_tokens": ["configure", "the", "supported", "content", "codings", "from", "the", "accept", "encoding", "header", "for", "which", "to", "cache", "resource", "variations"], "project": "spring-framework"}
{"id": 6168, "code": "\tpublic int getExpectedSize() {\n\t\treturn this.expectedSize;\n\t}", "summary_tokens": ["return", "the", "expected", "result", "size"], "project": "spring-framework"}
{"id": 6734, "code": "\tpublic Type getType() {\n\t\tif (this.type == null) {\n\t\t\tT body = getBody();\n\t\t\tif (body != null) {\n\t\t\t\treturn body.getClass();\n\t\t\t}\n\t\t}\n\t\treturn this.type;\n\t}", "summary_tokens": ["return", "the", "type", "of", "the", "request", "s", "body"], "project": "spring-framework"}
{"id": 8129, "code": "\tpublic static RequestPredicate HEAD(String pattern) {\n\t\treturn method(HttpMethod.HEAD).and(path(pattern));\n\t}", "summary_tokens": ["return", "a", "request", "predicate", "that", "matches", "if", "request", "s", "http", "method", "is", "head", "and", "the", "given", "pattern", "matches", "against", "the", "request", "path"], "project": "spring-framework"}
{"id": 7001, "code": "\tpublic void setAutoDetectFields(boolean autoDetectFields) {\n\t\tthis.builder.autoDetectFields(autoDetectFields);\n\t}", "summary_tokens": ["shortcut", "for", "mapper", "feature", "auto", "detect", "fields", "option"], "project": "spring-framework"}
{"id": 8504, "code": "\tpublic final MultipartResolver getMultipartResolver() {\n\t\treturn this.multipartResolver;\n\t}", "summary_tokens": ["obtain", "this", "servlet", "s", "multipart", "resolver", "if", "any"], "project": "spring-framework"}
{"id": 1598, "code": "\tprotected void populateAttributeDescriptor(\n\t\t\tDescriptor desc, @Nullable Method getter, @Nullable Method setter, String beanKey) {\n\n\t\tapplyDefaultCurrencyTimeLimit(desc);\n\t}", "summary_tokens": ["allows", "subclasses", "to", "add", "extra", "fields", "to", "the", "descriptor", "for", "a", "particular", "attribute"], "project": "spring-framework"}
{"id": 1311, "code": "\tpublic final ApplicationContext getApplicationContext() {\n\t\treturn (ApplicationContext) getSource();\n\t}", "summary_tokens": ["get", "the", "application", "context", "that", "the", "event", "was", "raised", "for"], "project": "spring-framework"}
{"id": 9135, "code": "\tpublic RequestDataValueProcessor getRequestDataValueProcessor() {\n\t\treturn this.requestDataValueProcessor;\n\t}", "summary_tokens": ["return", "the", "request", "data", "value", "processor", "instance", "to", "use", "obtained", "from", "the", "web", "application", "context", "under", "the", "name", "request", "data", "value", "processor"], "project": "spring-framework"}
{"id": 9274, "code": "\tpublic int doEndTag() throws JspException {\n\t\tif (shouldRender()) {\n\t\t\tAssert.state(this.tagWriter != null, \"No TagWriter set\");\n\t\t\tif (this.bodyContent != null && StringUtils.hasText(this.bodyContent.getString())) {\n\t\t\t\trenderFromBodyContent(this.bodyContent, this.tagWriter);\n\t\t\t}\n\t\t\telse {\n\t\t\t\trenderDefaultContent(this.tagWriter);\n\t\t\t}\n\t\t}\n\t\treturn EVAL_PAGE;\n\t}", "summary_tokens": ["if", "should", "render", "rendering", "flush", "any", "buffered", "body", "content", "or", "if", "no", "body", "content", "is", "supplied", "render", "default", "content", "render", "the", "default", "content"], "project": "spring-framework"}
{"id": 748, "code": "\tpublic void setTargetType(@Nullable Class<?> targetType) {\n\t\tthis.targetType = (targetType != null ? ResolvableType.forClass(targetType) : null);\n\t}", "summary_tokens": ["specify", "the", "target", "type", "of", "this", "bean", "definition", "if", "known", "in", "advance"], "project": "spring-framework"}
{"id": 3510, "code": "\tpublic static String createSignatureDescriptor(Constructor<?> ctor) {\n\t\tClass<?>[] params = ctor.getParameterTypes();\n\t\tStringBuilder sb = new StringBuilder();\n\t\tsb.append('(');\n\t\tfor (Class<?> param : params) {\n\t\t\tsb.append(toJvmDescriptor(param));\n\t\t}\n\t\tsb.append(\")V\");\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["create", "the", "jvm", "signature", "descriptor", "for", "a", "constructor"], "project": "spring-framework"}
{"id": 1737, "code": "\tpublic void setLookupOnStartup(boolean lookupOnStartup) {\n\t\tthis.lookupOnStartup = lookupOnStartup;\n\t}", "summary_tokens": ["set", "whether", "to", "look", "up", "the", "jndi", "object", "on", "startup"], "project": "spring-framework"}
{"id": 5884, "code": "\tpublic WebTestClient.ResponseSpec cacheControl(CacheControl cacheControl) {\n\t\treturn assertHeader(\"Cache-Control\", cacheControl.getHeaderValue(), getHeaders().getCacheControl());\n\t}", "summary_tokens": ["expect", "a", "cache", "control", "header", "with", "the", "given", "value"], "project": "spring-framework"}
{"id": 2444, "code": "public String getName() {\n  return name;\n}", "summary_tokens": ["returns", "the", "name", "of", "the", "field", "or", "method", "designated", "by", "this", "handle"], "project": "spring-framework"}
{"id": 9007, "code": "\tpublic boolean useTrailingSlashMatch() {\n\t\treturn this.useTrailingSlashMatch;\n\t}", "summary_tokens": ["whether", "to", "match", "to", "urls", "irrespective", "of", "the", "presence", "of", "a", "trailing", "slash"], "project": "spring-framework"}
{"id": 326, "code": "\tpublic String getPropertyName() {\n\t\treturn (this.propertyChangeEvent != null ? this.propertyChangeEvent.getPropertyName() : null);\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "affected", "property", "if", "available"], "project": "spring-framework"}
{"id": 1045, "code": "\tprotected Object createJobInstance(TriggerFiredBundle bundle) throws Exception {\n\t\tClass<?> jobClass = bundle.getJobDetail().getJobClass();\n\t\treturn ReflectionUtils.accessibleConstructor(jobClass).newInstance();\n\t}", "summary_tokens": ["create", "an", "instance", "of", "the", "specified", "job", "class"], "project": "spring-framework"}
{"id": 482, "code": "\tprotected void logDeprecatedBean(String beanName, Class<?> beanType, BeanDefinition beanDefinition) {\n\t\tStringBuilder builder = new StringBuilder();\n\t\tbuilder.append(beanType);\n\t\tbuilder.append(\" ['\");\n\t\tbuilder.append(beanName);\n\t\tbuilder.append('\\'');\n\t\tString resourceDescription = beanDefinition.getResourceDescription();\n\t\tif (StringUtils.hasLength(resourceDescription)) {\n\t\t\tbuilder.append(\" in \");\n\t\t\tbuilder.append(resourceDescription);\n\t\t}\n\t\tbuilder.append(\"] has been deprecated\");\n\t\twriteToLog(builder.toString());\n\t}", "summary_tokens": ["logs", "a", "warning", "for", "a", "bean", "annotated", "with", "deprecated"], "project": "spring-framework"}
{"id": 5591, "code": "\tpublic boolean supportsParameter(ParameterContext parameterContext, ExtensionContext extensionContext) {\n\t\tParameter parameter = parameterContext.getParameter();\n\t\tExecutable executable = parameter.getDeclaringExecutable();\n\t\tClass<?> testClass = extensionContext.getRequiredTestClass();\n\t\tPropertyProvider junitPropertyProvider = propertyName ->\n\t\t\t\textensionContext.getConfigurationParameter(propertyName).orElse(null);\n\t\treturn (TestConstructorUtils.isAutowirableConstructor(executable, testClass, junitPropertyProvider) ||\n\t\t\t\tApplicationContext.class.isAssignableFrom(parameter.getType()) ||\n\t\t\t\tsupportsApplicationEvents(parameterContext) ||\n\t\t\t\tParameterResolutionDelegate.isAutowirable(parameter, parameterContext.getIndex()));\n\t}", "summary_tokens": ["determine", "if", "the", "value", "for", "the", "parameter", "in", "the", "supplied", "parameter", "context", "should", "be", "autowired", "from", "the", "test", "s", "application", "context"], "project": "spring-framework"}
{"id": 4275, "code": "\tpublic void commitAll() throws JMSException {\n\t\tfor (Session session : this.sessions) {\n\t\t\ttry {\n\t\t\t\tsession.commit();\n\t\t\t}\n\t\t\tcatch (TransactionInProgressException ex) {\n\t\t\t\t\n\t\t\t}\n\t\t\tcatch (jakarta.jms.IllegalStateException ex) {\n\t\t\t\tif (this.connectionFactory != null) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tMethod getDataSourceMethod = this.connectionFactory.getClass().getMethod(\"getDataSource\");\n\t\t\t\t\t\tObject ds = ReflectionUtils.invokeMethod(getDataSourceMethod, this.connectionFactory);\n\t\t\t\t\t\twhile (ds != null) {\n\t\t\t\t\t\t\tif (TransactionSynchronizationManager.hasResource(ds)) {\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tMethod getTargetDataSourceMethod = ds.getClass().getMethod(\"getTargetDataSource\");\n\t\t\t\t\t\t\t\tds = ReflectionUtils.invokeMethod(getTargetDataSourceMethod, ds);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tcatch (NoSuchMethodException nsme) {\n\t\t\t\t\t\t\t\tds = null;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Throwable ex2) {\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"No working getDataSource method found on ConnectionFactory: \" + ex2);\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["commit", "all", "of", "this", "resource", "holder", "s", "sessions"], "project": "spring-framework"}
{"id": 366, "code": "\tprivate PropertyEditor findDefaultEditor(@Nullable Class<?> requiredType) {\n\t\tPropertyEditor editor = null;\n\t\tif (requiredType != null) {\n\t\t\t\n\t\t\teditor = this.propertyEditorRegistry.getDefaultEditor(requiredType);\n\t\t\tif (editor == null && String.class != requiredType) {\n\t\t\t\t\n\t\t\t\teditor = BeanUtils.findEditorByConvention(requiredType);\n\t\t\t}\n\t\t}\n\t\treturn editor;\n\t}", "summary_tokens": ["find", "a", "default", "editor", "for", "the", "given", "type"], "project": "spring-framework"}
{"id": 6971, "code": "\tpublic Jackson2ObjectMapperBuilder visibility(PropertyAccessor accessor, JsonAutoDetect.Visibility visibility) {\n\t\tthis.visibilities.put(accessor, visibility);\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "visibility", "to", "limit", "what", "kind", "of", "properties", "are", "auto", "detected"], "project": "spring-framework"}
{"id": 9107, "code": "\tpublic String getErrorMessage() {\n\t\tString[] errorMessages = initErrorMessages();\n\t\treturn (errorMessages.length > 0 ? errorMessages[0] : \"\");\n\t}", "summary_tokens": ["return", "the", "first", "error", "message", "for", "the", "field", "or", "object", "if", "any"], "project": "spring-framework"}
{"id": 7273, "code": "\tpublic String getConversationId() {\n\t\treturn null;\n\t}", "summary_tokens": ["there", "is", "no", "conversation", "id", "concept", "for", "a", "request", "so", "this", "method", "returns", "null"], "project": "spring-framework"}
{"id": 9865, "code": "\tpublic int getPhase() {\n\t\treturn this.phase;\n\t}", "summary_tokens": ["return", "the", "configured", "phase"], "project": "spring-framework"}
{"id": 1249, "code": "\tpublic <T> void registerBean(Class<T> beanClass, @Nullable String name, @Nullable Supplier<T> supplier,\n\t\t\tBeanDefinitionCustomizer... customizers) {\n\n\t\tdoRegisterBean(beanClass, name, null, supplier, customizers);\n\t}", "summary_tokens": ["register", "a", "bean", "from", "the", "given", "bean", "class", "deriving", "its", "metadata", "from", "class", "declared", "annotations"], "project": "spring-framework"}
{"id": 3668, "code": "\tprotected void initialize(Class<T> mappedClass) {\n\t\tthis.mappedClass = mappedClass;\n\t\tthis.mappedFields = new HashMap<>();\n\t\tthis.mappedProperties = new HashSet<>();\n\n\t\tfor (PropertyDescriptor pd : BeanUtils.getPropertyDescriptors(mappedClass)) {\n\t\t\tif (pd.getWriteMethod() != null) {\n\t\t\t\tString lowerCaseName = lowerCaseName(pd.getName());\n\t\t\t\tthis.mappedFields.put(lowerCaseName, pd);\n\t\t\t\tString underscoreName = underscoreName(pd.getName());\n\t\t\t\tif (!lowerCaseName.equals(underscoreName)) {\n\t\t\t\t\tthis.mappedFields.put(underscoreName, pd);\n\t\t\t\t}\n\t\t\t\tthis.mappedProperties.add(pd.getName());\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "mapping", "meta", "data", "for", "the", "given", "class"], "project": "spring-framework"}
{"id": 2164, "code": "\tpublic HintType getHintType() {\n\t\treturn this.instrumentedMethod.getHintType();\n\t}", "summary_tokens": ["return", "the", "category", "of", "runtime", "hints", "this", "invocation", "relates", "to"], "project": "spring-framework"}
{"id": 4773, "code": "\tpublic void setReactiveAdapterRegistry(ReactiveAdapterRegistry registry) {\n\t\tAssert.notNull(registry, \"ReactiveAdapterRegistry is required\");\n\t\tthis.reactiveAdapterRegistry = registry;\n\t}", "summary_tokens": ["configure", "the", "registry", "for", "adapting", "various", "reactive", "types"], "project": "spring-framework"}
{"id": 9261, "code": "\tprotected String getPropertyPath() throws JspException {\n\t\tString expression = getBindStatus().getExpression();\n\t\treturn (expression != null ? expression : \"\");\n\t}", "summary_tokens": ["build", "the", "property", "path", "for", "this", "tag", "including", "the", "nested", "path", "but", "i", "not", "i", "prefixed", "with", "the", "name", "of", "the", "form", "attribute"], "project": "spring-framework"}
{"id": 8444, "code": "\tpublic InetSocketAddress getRemoteAddress() {\n\t\treturn this.remoteAddress;\n\t}", "summary_tokens": ["for", "a", "server", "session", "this", "is", "the", "remote", "address", "where", "the", "handshake", "request", "came", "from"], "project": "spring-framework"}
{"id": 2908, "code": "\tpublic URL getURL() throws IOException {\n\t\tthrow new FileNotFoundException(getDescription() + \" cannot be resolved to URL\");\n\t}", "summary_tokens": ["this", "implementation", "throws", "a", "file", "not", "found", "exception", "assuming", "that", "the", "resource", "cannot", "be", "resolved", "to", "a", "url"], "project": "spring-framework"}
{"id": 2052, "code": "\tpublic void setParameterNameDiscoverer(ParameterNameDiscoverer parameterNameDiscoverer) {\n\t\tthis.parameterNameDiscoverer = parameterNameDiscoverer;\n\t}", "summary_tokens": ["set", "the", "parameter", "name", "discoverer", "to", "use", "for", "resolving", "method", "and", "constructor", "parameter", "names", "if", "needed", "for", "message", "interpolation"], "project": "spring-framework"}
{"id": 4143, "code": "\tpublic void setDataSource(@Nullable DataSource dataSource) {\n\t\tthis.dataSource = dataSource;\n\t}", "summary_tokens": ["set", "the", "jdbc", "data", "source", "to", "obtain", "connections", "from"], "project": "spring-framework"}
{"id": 1061, "code": "\tpublic void setDescription(String description) {\n\t\tthis.description = description;\n\t}", "summary_tokens": ["associate", "a", "textual", "description", "with", "this", "trigger"], "project": "spring-framework"}
{"id": 9269, "code": "\tprotected final void writeOptionalAttribute(TagWriter tagWriter, String attributeName, @Nullable String value)\n\t\t\tthrows JspException {\n\n\t\tif (value != null) {\n\t\t\ttagWriter.writeOptionalAttributeValue(attributeName, getDisplayString(evaluate(attributeName, value)));\n\t\t}\n\t}", "summary_tokens": ["optionally", "writes", "the", "supplied", "value", "under", "the", "supplied", "attribute", "name", "into", "the", "supplied", "tag", "writer"], "project": "spring-framework"}
{"id": 2004, "code": "\tpublic Validator getValidator() {\n\t\treturn (!this.validators.isEmpty() ? this.validators.get(0) : null);\n\t}", "summary_tokens": ["return", "the", "primary", "validator", "to", "apply", "after", "each", "binding", "step", "if", "any"], "project": "spring-framework"}
{"id": 2627, "code": "public void not() {\n    push(1);\n    math(XOR, Type.INT_TYPE);\n}", "summary_tokens": ["toggles", "the", "integer", "on", "the", "top", "of", "the", "stack", "from", "0", "to", "0", "or", "vice", "versa"], "project": "spring-framework"}
{"id": 1658, "code": "\tpublic void setName(@Nullable String name) {\n\t\tthis.name = name;\n\t}", "summary_tokens": ["set", "the", "name", "of", "this", "notification"], "project": "spring-framework"}
{"id": 8746, "code": "\tdefault void accept(RequestPredicates.Visitor visitor) {\n\t\tvisitor.unknown(this);\n\t}", "summary_tokens": ["accept", "the", "given", "visitor"], "project": "spring-framework"}
{"id": 439, "code": "\tpublic void resolveAndInvoke(RegisteredBean registeredBean, Object instance) {\n\t\tAssert.notNull(registeredBean, \"'registeredBean' must not be null\");\n\t\tAssert.notNull(instance, \"'instance' must not be null\");\n\t\tMethod method = getMethod(registeredBean);\n\t\tAutowiredArguments resolved = resolveArguments(registeredBean, method);\n\t\tif (resolved != null) {\n\t\t\tReflectionUtils.makeAccessible(method);\n\t\t\tReflectionUtils.invokeMethod(method, instance, resolved.toArray());\n\t\t}\n\t}", "summary_tokens": ["resolve", "the", "method", "arguments", "for", "the", "specified", "registered", "bean", "and", "invoke", "the", "method", "using", "reflection"], "project": "spring-framework"}
{"id": 6091, "code": "\tpublic ResultMatcher isUnsupportedMediaType() {\n\t\treturn matcher(HttpStatus.UNSUPPORTED_MEDIA_TYPE);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 8336, "code": "\tpublic String getPath() {\n\t\treturn this.path;\n\t}", "summary_tokens": ["return", "the", "bean", "and", "property", "path", "for", "which", "values", "and", "errors", "will", "be", "resolved", "e"], "project": "spring-framework"}
{"id": 8435, "code": "\tpublic void setScripts(String... scripts) {\n\t\tthis.scripts = scripts;\n\t}", "summary_tokens": ["see", "script", "template", "configurer", "set", "scripts", "string"], "project": "spring-framework"}
{"id": 4704, "code": "\tpublic void setCustomReturnValueHandlers(@Nullable List<HandlerMethodReturnValueHandler> customReturnValueHandlers) {\n\t\tthis.customReturnValueHandlers.clear();\n\t\tif (customReturnValueHandlers != null) {\n\t\t\tthis.customReturnValueHandlers.addAll(customReturnValueHandlers);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "list", "of", "custom", "handler", "method", "return", "value", "handler", "s", "that", "will", "be", "used", "after", "return", "value", "handlers", "for", "known", "types"], "project": "spring-framework"}
{"id": 4946, "code": "\tpublic void setSystemLogin(String systemLogin) {\n\t\tAssert.hasText(systemLogin, \"systemLogin must not be empty\");\n\t\tthis.systemLogin = systemLogin;\n\t}", "summary_tokens": ["set", "the", "login", "for", "the", "shared", "system", "connection", "used", "to", "send", "messages", "to", "the", "stomp", "broker", "from", "within", "the", "application", "i"], "project": "spring-framework"}
{"id": 2342, "code": "private int readRecordComponent(\n    final ClassVisitor classVisitor, final Context context, final int recordComponentOffset) {\n  char[] charBuffer = context.charBuffer;\n\n  int currentOffset = recordComponentOffset;\n  String name = readUTF8(currentOffset, charBuffer);\n  String descriptor = readUTF8(currentOffset + 2, charBuffer);\n  currentOffset += 4;\n\n    \n    \n\n    \n    \n  String signature = null;\n    \n  int runtimeVisibleAnnotationsOffset = 0;\n    \n  int runtimeInvisibleAnnotationsOffset = 0;\n    \n  int runtimeVisibleTypeAnnotationsOffset = 0;\n    \n  int runtimeInvisibleTypeAnnotationsOffset = 0;\n    \n    \n  Attribute attributes = null;\n\n  int attributesCount = readUnsignedShort(currentOffset);\n  currentOffset += 2;\n  while (attributesCount-- > 0) {\n      \n    String attributeName = readUTF8(currentOffset, charBuffer);\n    int attributeLength = readInt(currentOffset + 2);\n    currentOffset += 6;\n      \n      \n    if (Constants.SIGNATURE.equals(attributeName)) {\n      signature = readUTF8(currentOffset, charBuffer);\n    } else if (Constants.RUNTIME_VISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleTypeAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_INVISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleTypeAnnotationsOffset = currentOffset;\n    } else {\n      Attribute attribute =\n          readAttribute(\n              context.attributePrototypes,\n              attributeName,\n              currentOffset,\n              attributeLength,\n              charBuffer,\n              -1,\n              null);\n      attribute.nextAttribute = attributes;\n      attributes = attribute;\n    }\n    currentOffset += attributeLength;\n  }\n\n  RecordComponentVisitor recordComponentVisitor =\n      classVisitor.visitRecordComponent(name, descriptor, signature);\n  if (recordComponentVisitor == null) {\n    return currentOffset;\n  }\n\n    \n  if (runtimeVisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              recordComponentVisitor.visitAnnotation(annotationDescriptor,  true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              recordComponentVisitor.visitAnnotation(annotationDescriptor,  false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeVisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              recordComponentVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              recordComponentVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  while (attributes != null) {\n      \n    Attribute nextAttribute = attributes.nextAttribute;\n    attributes.nextAttribute = null;\n    recordComponentVisitor.visitAttribute(attributes);\n    attributes = nextAttribute;\n  }\n\n    \n  recordComponentVisitor.visitEnd();\n  return currentOffset;\n}", "summary_tokens": ["reads", "a", "record", "component", "and", "visit", "it"], "project": "spring-framework"}
{"id": 7977, "code": "\tpublic void setParameterName(String parameterName) {\n\t\tAssert.notNull(parameterName, \"'parameterName' is required\");\n\t\tthis.parameterName = parameterName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "parameter", "to", "use", "to", "determine", "requested", "media", "types"], "project": "spring-framework"}
{"id": 2768, "code": "\tpublic static boolean isAnnotated(AnnotatedElement element, String annotationName) {\n\t\treturn getAnnotations(element).isPresent(annotationName);\n\t}", "summary_tokens": ["determine", "if", "an", "annotation", "of", "the", "specified", "annotation", "name", "is", "em", "present", "em", "on", "the", "supplied", "annotated", "element", "or", "within", "the", "annotation", "hierarchy", "em", "above", "em", "the", "specified", "element"], "project": "spring-framework"}
{"id": 4813, "code": "\tpublic void setAttribute(String name, Object value) {\n\t\tthis.attributes.put(name, value);\n\t}", "summary_tokens": ["set", "the", "value", "with", "the", "given", "name", "replacing", "an", "existing", "value", "if", "any"], "project": "spring-framework"}
{"id": 3712, "code": "\tpublic Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "value", "object", "that", "this", "parameter", "value", "holds"], "project": "spring-framework"}
{"id": 3247, "code": "\tpublic static List<MimeType> parseMimeTypes(String mimeTypes) {\n\t\tif (!StringUtils.hasLength(mimeTypes)) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t\treturn tokenize(mimeTypes).stream()\n\t\t\t\t.filter(StringUtils::hasText)\n\t\t\t\t.map(MimeTypeUtils::parseMimeType)\n\t\t\t\t.collect(Collectors.toList());\n\t}", "summary_tokens": ["parse", "the", "comma", "separated", "string", "into", "a", "list", "of", "mime", "type", "objects"], "project": "spring-framework"}
{"id": 4951, "code": "\tpublic long getSystemHeartbeatSendInterval() {\n\t\treturn this.systemHeartbeatSendInterval;\n\t}", "summary_tokens": ["return", "the", "interval", "in", "milliseconds", "at", "which", "the", "system", "connection", "will", "send", "heartbeats", "to", "the", "stomp", "broker"], "project": "spring-framework"}
{"id": 6773, "code": "\tprotected HttpHeaders initReadOnlyHeaders() {\n\t\treturn HttpHeaders.readOnlyHttpHeaders(this.headers);\n\t}", "summary_tokens": ["initialize", "the", "read", "only", "headers", "after", "the", "request", "is", "committed"], "project": "spring-framework"}
{"id": 5499, "code": "\tpublic boolean hasResources() {\n\t\treturn (hasLocations() || hasClasses());\n\t}", "summary_tokens": ["determine", "if", "this", "merged", "context", "configuration", "instance", "has", "either", "path", "based", "context", "resource", "locations", "or", "class", "based", "resources"], "project": "spring-framework"}
{"id": 8412, "code": "\tpublic boolean checkResourceExists(Locale locale) throws Exception {\n\t\ttry {\n\t\t\t\n\t\t\tgetTemplate(locale);\n\t\t\treturn true;\n\t\t}\n\t\tcatch (FileNotFoundException ex) {\n\t\t\t\n\t\t\treturn false;\n\t\t}\n\t\tcatch (ParseException ex) {\n\t\t\tthrow new ApplicationContextException(\n\t\t\t\t\t\"Failed to parse FreeMarker template for URL [\" +  getUrl() + \"]\", ex);\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new ApplicationContextException(\n\t\t\t\t\t\"Could not load FreeMarker template for URL [\" + getUrl() + \"]\", ex);\n\t\t}\n\t}", "summary_tokens": ["check", "that", "the", "free", "marker", "template", "used", "for", "this", "view", "exists", "and", "is", "valid"], "project": "spring-framework"}
{"id": 4809, "code": "\tpublic void setDefaultMetadataMimeType(MimeType mimeType) {\n\t\tAssert.notNull(mimeType, \"'metadataMimeType' is required\");\n\t\tthis.defaultMetadataMimeType = mimeType;\n\t}", "summary_tokens": ["configure", "the", "default", "mime", "type", "for", "payload", "data", "if", "the", "setup", "frame", "did", "not", "specify", "one"], "project": "spring-framework"}
{"id": 2477, "code": "public void visitIntInsn(final int opcode, final int operand) {\n  if (mv != null) {\n    mv.visitIntInsn(opcode, operand);\n  }\n}", "summary_tokens": ["visits", "an", "instruction", "with", "a", "single", "int", "operand"], "project": "spring-framework"}
{"id": 9375, "code": "\tprotected String getServletRelativeAction() {\n\t\treturn this.servletRelativeAction;\n\t}", "summary_tokens": ["get", "the", "servlet", "relative", "value", "of", "the", "action", "attribute"], "project": "spring-framework"}
{"id": 1587, "code": "\tprotected boolean isExposeClassDescriptor() {\n\t\treturn this.exposeClassDescriptor;\n\t}", "summary_tokens": ["return", "whether", "to", "expose", "the", "jmx", "descriptor", "field", "class", "for", "managed", "operations"], "project": "spring-framework"}
{"id": 7480, "code": "\tpublic boolean isForceRequestEncoding() {\n\t\treturn this.forceRequestEncoding;\n\t}", "summary_tokens": ["return", "whether", "the", "encoding", "should", "be", "forced", "on", "requests"], "project": "spring-framework"}
{"id": 3931, "code": "\tprotected void setTransactionActive(boolean transactionActive) {\n\t\tthis.transactionActive = transactionActive;\n\t}", "summary_tokens": ["set", "whether", "this", "holder", "represents", "an", "active", "jdbc", "managed", "transaction"], "project": "spring-framework"}
{"id": 5322, "code": "\tprotected Object unmarshalSaxSource(SAXSource saxSource) throws XmlMappingException, IOException {\n\t\tif (saxSource.getXMLReader() == null) {\n\t\t\ttry {\n\t\t\t\tsaxSource.setXMLReader(createXmlReader());\n\t\t\t}\n\t\t\tcatch (SAXException | ParserConfigurationException ex) {\n\t\t\t\tthrow new UnmarshallingFailureException(\"Could not create XMLReader for SAXSource\", ex);\n\t\t\t}\n\t\t}\n\t\tif (saxSource.getInputSource() == null) {\n\t\t\tsaxSource.setInputSource(new InputSource());\n\t\t}\n\t\ttry {\n\t\t\treturn unmarshalSaxReader(saxSource.getXMLReader(), saxSource.getInputSource());\n\t\t}\n\t\tcatch (NullPointerException ex) {\n\t\t\tif (!isSupportDtd()) {\n\t\t\t\tthrow new UnmarshallingFailureException(\"NPE while unmarshalling. \" +\n\t\t\t\t\t\t\"This can happen on JDK 1.6 due to the presence of DTD \" +\n\t\t\t\t\t\t\"declarations, which are disabled.\");\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t}", "summary_tokens": ["template", "method", "for", "handling", "saxsource", "s"], "project": "spring-framework"}
{"id": 1695, "code": "\tpublic static Class<?> getClassToExpose(Class<?> clazz) {\n\t\treturn ClassUtils.getUserClass(clazz);\n\t}", "summary_tokens": ["return", "the", "class", "or", "interface", "to", "expose", "for", "the", "given", "bean", "class"], "project": "spring-framework"}
{"id": 1386, "code": "\tprotected Class<?> requiredContextClass() {\n\t\treturn ApplicationContext.class;\n\t}", "summary_tokens": ["determine", "the", "context", "class", "that", "any", "context", "passed", "to", "set", "application", "context", "must", "be", "an", "instance", "of"], "project": "spring-framework"}
{"id": 5432, "code": "\tpublic BindMarker bindNull(Class<?> valueType) {\n\t\tAssert.notNull(valueType, \"Value type must not be null\");\n\t\tBindMarker marker = nextMarker();\n\t\tgetBindings().put(marker, new NullBinding(marker, valueType));\n\t\treturn marker;\n\t}", "summary_tokens": ["bind", "a", "null", "value", "and", "return", "the", "related", "bind", "marker"], "project": "spring-framework"}
{"id": 2129, "code": "\tpublic void getMessageWithNoDefaultPassedInAndFoundInMsgCatalog() {\n\t\tObject[] arguments = {\n\t\t\t7, new Date(System.currentTimeMillis()),\n\t\t\t\"a disturbance in the Force\"\n\t\t};\n\n\t\t\n\t\tassertThat(sac.getMessage(\"message.format.example1\", arguments, Locale.US).\n\t\t\t\t\t\tcontains(\"there was \\\"a disturbance in the Force\\\" on planet 7.\")).as(\"msg from staticMsgSource for Locale.US substituting args for placeholders is as expected\").isTrue();\n\n\t\t\n\t\tassertThat(sac.getMessage(\"message.format.example1\", arguments, Locale.UK).\n\t\t\t\t\t\tcontains(\"there was \\\"a disturbance in the Force\\\" on station number 7.\")).as(\"msg from staticMsgSource for Locale.UK substituting args for placeholders is as expected\").isTrue();\n\n\t\t\n\t\tassertThat(sac.getMessage(\"message.format.example2\", null, Locale.US)\n\t\t\t\t.equals(\"This is a test message in the message catalog with no args.\")).as(\"msg from staticMsgSource for Locale.US that requires no args is as expected\").isTrue();\n\t}", "summary_tokens": ["example", "taken", "from", "the", "javadocs", "for", "the", "java"], "project": "spring-framework"}
{"id": 4945, "code": "\tpublic String getClientPasscode() {\n\t\treturn this.clientPasscode;\n\t}", "summary_tokens": ["return", "the", "configured", "passcode", "to", "use", "for", "connections", "to", "the", "stomp", "broker", "on", "behalf", "of", "connected", "clients"], "project": "spring-framework"}
{"id": 7045, "code": "\tstatic PathContainer parsePath(String path, Options options) {\n\t\treturn DefaultPathContainer.createFromUrlPath(path, options);\n\t}", "summary_tokens": ["parse", "the", "path", "value", "into", "a", "sequence", "of", "separator", "separator", "and", "path", "segment", "path", "segment", "elements"], "project": "spring-framework"}
{"id": 1239, "code": "\tdefault boolean isAutoStartup() {\n\t\treturn true;\n\t}", "summary_tokens": ["returns", "true", "if", "this", "lifecycle", "component", "should", "get", "started", "automatically", "by", "the", "container", "at", "the", "time", "that", "the", "containing", "application", "context", "gets", "refreshed"], "project": "spring-framework"}
{"id": 3653, "code": "\tpublic SQLException getSQLException() {\n\t\treturn (SQLException) getCause();\n\t}", "summary_tokens": ["return", "the", "wrapped", "sqlexception"], "project": "spring-framework"}
{"id": 2411, "code": "protected ClassLoader getClassLoader() {\n    \n  ClassLoader classLoader = null;\n  try {\n    classLoader = Thread.currentThread().getContextClassLoader();\n  } catch (Throwable ex) {\n      \n  }\n  return (classLoader != null ? classLoader : getClass().getClassLoader());\n}", "summary_tokens": ["returns", "the", "class", "loader", "to", "be", "used", "by", "the", "default", "implementation", "of", "get", "common", "super", "class", "string", "string", "that", "of", "this", "class", "writer", "s", "runtime", "type", "by", "default"], "project": "spring-framework"}
{"id": 2647, "code": "\tpublic void setCallbacks(Callback[] callbacks) {\n\t\tif (callbacks != null && callbacks.length == 0) {\n\t\t\tthrow new IllegalArgumentException(\"Array cannot be empty\");\n\t\t}\n\t\tthis.callbacks = callbacks;\n\t}", "summary_tokens": ["set", "the", "array", "of", "callbacks", "to", "use"], "project": "spring-framework"}
{"id": 1787, "code": "\tdefault AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {\n\t\treturn null;\n\t}", "summary_tokens": ["the", "async", "uncaught", "exception", "handler", "instance", "to", "be", "used", "when", "an", "exception", "is", "thrown", "during", "an", "asynchronous", "method", "execution", "with", "void", "return", "type"], "project": "spring-framework"}
{"id": 4986, "code": "\tpublic static StompHeaderAccessor create(StompCommand command, Map<String, List<String>> headers) {\n\t\treturn new StompHeaderAccessor(command, headers);\n\t}", "summary_tokens": ["create", "an", "instance", "for", "the", "given", "stomp", "command", "and", "headers"], "project": "spring-framework"}
{"id": 6722, "code": "\tpublic void setProperty(String name, Object value) {\n\t\tthis.properties = (this.properties != null ? this.properties : new LinkedHashMap<>());\n\t\tthis.properties.put(name, value);\n\t}", "summary_tokens": ["set", "a", "dynamic", "property", "to", "be", "added", "to", "a", "generic", "get", "properties", "properties", "map"], "project": "spring-framework"}
{"id": 619, "code": "\tdefault boolean hasQualifier(DependencyDescriptor descriptor) {\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "descriptor", "declares", "a", "qualifier", "beyond", "the", "type", "typically", "but", "not", "necessarily", "a", "specific", "kind", "of", "annotation"], "project": "spring-framework"}
{"id": 5092, "code": "\tpublic List<String> removeNativeHeader(String headerName) {\n\t\tAssert.state(isMutable(), \"Already immutable\");\n\t\tMap<String, List<String>> nativeHeaders = getNativeHeaders();\n\t\tif (CollectionUtils.isEmpty(nativeHeaders)) {\n\t\t\treturn null;\n\t\t}\n\t\treturn nativeHeaders.remove(headerName);\n\t}", "summary_tokens": ["remove", "the", "specified", "native", "header", "value", "replacing", "existing", "values"], "project": "spring-framework"}
{"id": 5211, "code": "\tpublic DataAccessException translateExceptionIfPossible(RuntimeException ex) {\n\t\treturn EntityManagerFactoryUtils.convertJpaAccessExceptionIfPossible(ex);\n\t}", "summary_tokens": ["this", "implementation", "delegates", "to", "entity", "manager", "factory", "utils"], "project": "spring-framework"}
{"id": 2758, "code": "\tpublic Set<Object> keySet() {\n\t\tSet<Object> sortedKeys = new TreeSet<>(keyComparator);\n\t\tsortedKeys.addAll(super.keySet());\n\t\treturn Collections.synchronizedSet(sortedKeys);\n\t}", "summary_tokens": ["return", "a", "sorted", "set", "of", "the", "keys", "in", "this", "properties", "object"], "project": "spring-framework"}
{"id": 169, "code": "\tprotected String createInvocationTraceName(MethodInvocation invocation) {\n\t\tMethod method = invocation.getMethod();\n\t\tClass<?> clazz = method.getDeclaringClass();\n\t\tif (this.logTargetClassInvocation && clazz.isInstance(invocation.getThis())) {\n\t\t\tclazz = invocation.getThis().getClass();\n\t\t}\n\t\tString className = clazz.getName();\n\t\treturn getPrefix() + className + '.' + method.getName() + getSuffix();\n\t}", "summary_tokens": ["create", "a", "string", "name", "for", "the", "given", "method", "invocation", "that", "can", "be", "used", "for", "trace", "logging", "purposes"], "project": "spring-framework"}
{"id": 800, "code": "\tprotected void doParse(Element element, BeanDefinitionBuilder builder) {\n\t}", "summary_tokens": ["parse", "the", "supplied", "element", "and", "populate", "the", "supplied", "bean", "definition", "builder", "as", "required"], "project": "spring-framework"}
{"id": 9840, "code": "\tpublic void setProtocolHandlers(List<SubProtocolHandler> protocolHandlers) {\n\t\tthis.protocolHandlerLookup.clear();\n\t\tthis.protocolHandlers.clear();\n\t\tfor (SubProtocolHandler handler : protocolHandlers) {\n\t\t\taddProtocolHandler(handler);\n\t\t}\n\t}", "summary_tokens": ["configure", "one", "or", "more", "handlers", "to", "use", "depending", "on", "the", "sub", "protocol", "requested", "by", "the", "client", "in", "the", "web", "socket", "handshake", "request"], "project": "spring-framework"}
{"id": 4226, "code": "\tpublic void setSelector(@Nullable String selector) {\n\t\tthis.selector = selector;\n\t}", "summary_tokens": ["set", "the", "jms", "message", "selector", "expression"], "project": "spring-framework"}
{"id": 46, "code": "\tprivate Object getSingletonAspectInstance(Class<?> aspectClass) {\n\t\treturn aspectCache.computeIfAbsent(aspectClass,\n\t\t\t\tclazz -> new SimpleAspectInstanceFactory(clazz).getAspectInstance());\n\t}", "summary_tokens": ["get", "the", "singleton", "aspect", "instance", "for", "the", "supplied", "aspect", "type"], "project": "spring-framework"}
{"id": 7546, "code": "\tprotected void handleMissingValueAfterConversion(String name, MethodParameter parameter, NativeWebRequest request)\n\t\t\tthrows Exception {\n\n\t\thandleMissingValue(name, parameter, request);\n\t}", "summary_tokens": ["invoked", "when", "a", "named", "value", "is", "present", "but", "becomes", "null", "after", "conversion"], "project": "spring-framework"}
{"id": 5569, "code": "\tpublic String toString() {\n\t\treturn new ToStringCreator(this)\n\t\t\t\t.append(\"dataSource\", this.dataSource)\n\t\t\t\t.append(\"transactionManager\", this.transactionManager)\n\t\t\t\t.append(\"transactionMode\", this.transactionMode)\n\t\t\t\t.append(\"encoding\", this.encoding)\n\t\t\t\t.append(\"separator\", this.separator)\n\t\t\t\t.append(\"commentPrefixes\", this.commentPrefixes)\n\t\t\t\t.append(\"blockCommentStartDelimiter\", this.blockCommentStartDelimiter)\n\t\t\t\t.append(\"blockCommentEndDelimiter\", this.blockCommentEndDelimiter)\n\t\t\t\t.append(\"errorMode\", this.errorMode)\n\t\t\t\t.toString();\n\t}", "summary_tokens": ["provide", "a", "string", "representation", "of", "the", "merged", "sql", "script", "configuration"], "project": "spring-framework"}
{"id": 6185, "code": "\tpublic void setAlwaysTranslate(boolean alwaysTranslate) {\n\t\tthis.alwaysTranslate = alwaysTranslate;\n\t}", "summary_tokens": ["specify", "whether", "to", "always", "translate", "the", "exception", "true", "or", "whether", "throw", "the", "raw", "exception", "when", "declared", "i"], "project": "spring-framework"}
{"id": 6019, "code": "\tpublic static ResultMatcher redirectedUrlPattern(String urlPattern) {\n\t\treturn result -> {\n\t\t\tassertTrue(\"'\" + urlPattern + \"' is not an Ant-style path pattern\",\n\t\t\t\t\tpathMatcher.isPattern(urlPattern));\n\t\t\tString url = result.getResponse().getRedirectedUrl();\n\t\t\tassertTrue(\"Redirected URL '\" + url + \"' does not match the expected URL pattern '\" + urlPattern + \"'\",\n\t\t\t\t\t(url != null && pathMatcher.match(urlPattern, url)));\n\t\t};\n\t}", "summary_tokens": ["asserts", "the", "request", "was", "redirected", "to", "the", "given", "url"], "project": "spring-framework"}
{"id": 8539, "code": "\tpublic String getViewName() {\n\t\treturn (this.view instanceof String ? (String) this.view : null);\n\t}", "summary_tokens": ["return", "the", "view", "name", "to", "be", "resolved", "by", "the", "dispatcher", "servlet", "via", "a", "view", "resolver", "or", "null", "if", "we", "are", "using", "a", "view", "object"], "project": "spring-framework"}
{"id": 254, "code": "\tprotected Object writeReplace() throws ObjectStreamException {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Disconnecting TargetSource [\" + this + \"]\");\n\t\t}\n\t\ttry {\n\t\t\t\n\t\t\tObject target = getTarget();\n\t\t\treturn (target != null ? new SingletonTargetSource(target) :\n\t\t\t\t\tEmptyTargetSource.forClass(getTargetClass()));\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tString msg = \"Cannot get target for disconnecting TargetSource [\" + this + \"]\";\n\t\t\tlogger.error(msg, ex);\n\t\t\tthrow new NotSerializableException(msg + \": \" + ex);\n\t\t}\n\t}", "summary_tokens": ["replaces", "this", "object", "with", "a", "singleton", "target", "source", "on", "serialization"], "project": "spring-framework"}
{"id": 8544, "code": "\tprotected Map<String, Object> getModelInternal() {\n\t\treturn this.model;\n\t}", "summary_tokens": ["return", "the", "model", "map"], "project": "spring-framework"}
{"id": 9712, "code": "\tpublic void setContentType(@Nullable String contentType) {\n\t\tthis.contentType = contentType;\n\t}", "summary_tokens": ["set", "the", "content", "type", "to", "use", "for", "the", "response"], "project": "spring-framework"}
{"id": 1285, "code": "\tpublic final MetadataReaderFactory getMetadataReaderFactory() {\n\t\tif (this.metadataReaderFactory == null) {\n\t\t\tthis.metadataReaderFactory = new CachingMetadataReaderFactory();\n\t\t}\n\t\treturn this.metadataReaderFactory;\n\t}", "summary_tokens": ["return", "the", "metadata", "reader", "factory", "used", "by", "this", "component", "provider"], "project": "spring-framework"}
{"id": 8776, "code": "\tstatic BodyBuilder temporaryRedirect(URI location) {\n\t\tBodyBuilder builder = status(HttpStatus.TEMPORARY_REDIRECT);\n\t\treturn builder.location(location);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "a", "http", "status", "temporary", "redirect", "0", "temporary", "redirect", "status", "and", "a", "location", "header", "set", "to", "the", "given", "uri"], "project": "spring-framework"}
{"id": 9065, "code": "\tpublic List<String> getContentCodings() {\n\t\treturn Collections.unmodifiableList(this.contentCodings);\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "with", "the", "supported", "content", "codings"], "project": "spring-framework"}
{"id": 7954, "code": "\tpublic void registerNamedDispatcher(String name, RequestDispatcher requestDispatcher) {\n\t\tAssert.notNull(name, \"RequestDispatcher name must not be null\");\n\t\tAssert.notNull(requestDispatcher, \"RequestDispatcher must not be null\");\n\t\tthis.namedRequestDispatchers.put(name, requestDispatcher);\n\t}", "summary_tokens": ["register", "a", "request", "dispatcher", "typically", "a", "mock", "request", "dispatcher", "that", "acts", "as", "a", "wrapper", "for", "the", "named", "servlet"], "project": "spring-framework"}
{"id": 9822, "code": "\tpublic Message<byte[]> getMessage() {\n\t\treturn this.message;\n\t}", "summary_tokens": ["return", "the", "message", "associated", "with", "the", "event"], "project": "spring-framework"}
{"id": 9161, "code": "\tpublic final String[] getSupportedMethods() {\n\t\treturn (this.supportedMethods != null ? StringUtils.toStringArray(this.supportedMethods) : null);\n\t}", "summary_tokens": ["return", "the", "http", "methods", "that", "this", "content", "generator", "supports"], "project": "spring-framework"}
{"id": 191, "code": "\tpublic long getCount() {\n\t\treturn this.count;\n\t}", "summary_tokens": ["return", "the", "number", "of", "times", "this", "interceptor", "has", "been", "invoked"], "project": "spring-framework"}
{"id": 5366, "code": "\tpublic void setDatabaseCleaner(DatabasePopulator databaseCleaner) {\n\t\tthis.databaseCleaner = databaseCleaner;\n\t}", "summary_tokens": ["set", "the", "database", "populator", "to", "execute", "during", "the", "bean", "destruction", "phase", "cleaning", "up", "the", "database", "and", "leaving", "it", "in", "a", "known", "state", "for", "others"], "project": "spring-framework"}
{"id": 3576, "code": "\tprivate void pushPairToken(TokenKind kind) {\n\t\tthis.tokens.add(new Token(kind, this.pos, this.pos + 2));\n\t\tthis.pos += 2;\n\t}", "summary_tokens": ["push", "a", "token", "of", "two", "characters", "in", "length"], "project": "spring-framework"}
{"id": 4589, "code": "\tprotected jakarta.jms.Message createMessageForPayload(\n\t\t\tObject payload, Session session, @Nullable Object conversionHint) throws JMSException {\n\n\t\treturn this.payloadConverter.toMessage(payload, session);\n\t}", "summary_tokens": ["create", "a", "jms", "message", "for", "the", "specified", "payload", "and", "conversion", "hint"], "project": "spring-framework"}
{"id": 8543, "code": "\tpublic boolean isReference() {\n\t\treturn (this.view instanceof String);\n\t}", "summary_tokens": ["return", "whether", "we", "use", "a", "view", "reference", "i"], "project": "spring-framework"}
{"id": 5111, "code": "\tpublic String getPersistentClassName() {\n\t\tif (this.persistentClass instanceof Class) {\n\t\t\treturn ((Class<?>) this.persistentClass).getName();\n\t\t}\n\t\treturn (this.persistentClass != null ? this.persistentClass.toString() : null);\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "persistent", "class", "of", "the", "object", "for", "which", "the", "locking", "failed"], "project": "spring-framework"}
{"id": 6649, "code": "\tpublic Set<HttpMethod> getAllow() {\n\t\tString value = getFirst(ALLOW);\n\t\tif (StringUtils.hasLength(value)) {\n\t\t\tString[] tokens = StringUtils.tokenizeToStringArray(value, \",\");\n\t\t\tSet<HttpMethod> result = new LinkedHashSet<>(tokens.length);\n\t\t\tfor (String token : tokens) {\n\t\t\t\tHttpMethod method = HttpMethod.valueOf(token);\n\t\t\t\tresult.add(method);\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\telse {\n\t\t\treturn Collections.emptySet();\n\t\t}\n\t}", "summary_tokens": ["return", "the", "set", "of", "allowed", "http", "method", "http", "methods", "as", "specified", "by", "the", "allow", "header"], "project": "spring-framework"}
{"id": 1594, "code": "\tprotected String getAttributeDescription(PropertyDescriptor propertyDescriptor, String beanKey) {\n\t\treturn propertyDescriptor.getDisplayName();\n\t}", "summary_tokens": ["get", "the", "description", "for", "a", "particular", "attribute"], "project": "spring-framework"}
{"id": 9187, "code": "\tpublic final Errors getErrors() {\n\t\treturn this.errors;\n\t}", "summary_tokens": ["retrieve", "the", "errors", "instance", "that", "this", "tag", "is", "currently", "bound", "to"], "project": "spring-framework"}
{"id": 7216, "code": "\tprotected String getAttributeNameInSession(WebRequest request, String attributeName) {\n\t\treturn this.attributeNamePrefix + attributeName;\n\t}", "summary_tokens": ["calculate", "the", "attribute", "name", "in", "the", "backend", "session"], "project": "spring-framework"}
{"id": 5642, "code": "\tpublic void evaluate() throws Throwable {\n\t\tthis.testContextManager.beforeTestClass();\n\t\tthis.next.evaluate();\n\t}", "summary_tokens": ["invoke", "test", "context", "manager", "before", "test", "class", "and", "then", "evaluate", "the", "next", "statement", "in", "the", "execution", "chain", "typically", "an", "instance", "of", "org"], "project": "spring-framework"}
{"id": 4875, "code": "\tpublic void setCacheLimit(@Nullable Integer cacheLimit) {\n\t\tthis.cacheLimit = cacheLimit;\n\t\tinitCacheLimitToUse();\n\t}", "summary_tokens": ["when", "configured", "the", "specified", "cache", "limit", "is", "passed", "down", "to", "the", "underlying", "subscription", "registry", "overriding", "any", "default", "there"], "project": "spring-framework"}
{"id": 6836, "code": "\tpublic String event() {\n\t\treturn this.event;\n\t}", "summary_tokens": ["return", "the", "event", "field", "of", "this", "event", "if", "available"], "project": "spring-framework"}
{"id": 503, "code": "\tpublic void setSingleton(boolean singleton) {\n\t\tthis.singleton = singleton;\n\t}", "summary_tokens": ["set", "if", "a", "singleton", "should", "be", "created", "or", "a", "new", "object", "on", "each", "get", "object", "request", "otherwise"], "project": "spring-framework"}
{"id": 4251, "code": "\tpublic void setBeanFactory(@Nullable BeanFactory beanFactory) {\n\t\tif (this.embeddedValueResolver == null && beanFactory instanceof ConfigurableBeanFactory) {\n\t\t\tthis.embeddedValueResolver = new EmbeddedValueResolver((ConfigurableBeanFactory) beanFactory);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "bean", "factory", "to", "use", "to", "resolve", "expressions", "may", "be", "null"], "project": "spring-framework"}
{"id": 1537, "code": "\tpublic void addExcludedBean(String excludedBean) {\n\t\tAssert.notNull(excludedBean, \"ExcludedBean must not be null\");\n\t\tthis.excludedBeans.add(excludedBean);\n\t}", "summary_tokens": ["add", "the", "name", "of", "bean", "that", "should", "be", "excluded", "from", "autodetection"], "project": "spring-framework"}
{"id": 3400, "code": "\tprotected boolean hasNamespacesFeature() {\n\t\treturn this.namespacesFeature;\n\t}", "summary_tokens": ["indicates", "whether", "the", "sax", "feature", "http", "xml"], "project": "spring-framework"}
{"id": 8901, "code": "\tpublic boolean isEmptyPathMapping() {\n\t\treturn this.patterns == EMPTY_PATH_PATTERN;\n\t}", "summary_tokens": ["whether", "the", "condition", "is", "the", "empty", "path", "mapping"], "project": "spring-framework"}
{"id": 2569, "code": "public static Type getMethodType(final Type returnType, final Type... argumentTypes) {\n  return getType(getMethodDescriptor(returnType, argumentTypes));\n}", "summary_tokens": ["returns", "the", "method", "type", "corresponding", "to", "the", "given", "argument", "and", "return", "types"], "project": "spring-framework"}
{"id": 5792, "code": "\tprotected List<ClientHttpRequest> getRequests() {\n\t\treturn Collections.unmodifiableList(this.requests);\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "of", "requests", "executed", "so", "far"], "project": "spring-framework"}
{"id": 8315, "code": "\tpublic boolean isHandlerSessionAttribute(String attributeName, Class<?> attributeType) {\n\t\tAssert.notNull(attributeName, \"Attribute name must not be null\");\n\t\tif (this.attributeNames.contains(attributeName) || this.attributeTypes.contains(attributeType)) {\n\t\t\tthis.knownAttributeNames.add(attributeName);\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["whether", "the", "attribute", "name", "or", "type", "match", "the", "names", "and", "types", "specified", "via", "on", "the", "underlying", "controller"], "project": "spring-framework"}
{"id": 1202, "code": "\tpublic int hashCode() {\n\t\treturn toString().hashCode();\n\t}", "summary_tokens": ["this", "implementation", "returns", "to", "string", "s", "hash", "code"], "project": "spring-framework"}
{"id": 6850, "code": "\tpublic void registerObjectMappersForType(Class<?> clazz, Consumer<Map<MimeType, ObjectMapper>> registrar) {\n\t\tif (this.objectMapperRegistrations == null) {\n\t\t\tthis.objectMapperRegistrations = new LinkedHashMap<>();\n\t\t}\n\t\tMap<MimeType, ObjectMapper> registrations =\n\t\t\t\tthis.objectMapperRegistrations.computeIfAbsent(clazz, c -> new LinkedHashMap<>());\n\t\tregistrar.accept(registrations);\n\t}", "summary_tokens": ["configure", "the", "object", "mapper", "instances", "to", "use", "for", "the", "given", "class"], "project": "spring-framework"}
{"id": 9805, "code": "\tDefaultSockJsSchedulerContainer defaultSockJsSchedulerContainer() {\n\t\treturn (initHandlerRegistry().requiresTaskScheduler() ?\n\t\t\t\tnew DefaultSockJsSchedulerContainer(initDefaultSockJsScheduler()) :\n\t\t\t\tnew DefaultSockJsSchedulerContainer(null));\n\t}", "summary_tokens": ["a", "container", "of", "the", "default", "task", "scheduler", "to", "use", "if", "none", "was", "registered", "explicitly", "via", "sock", "js", "service", "registration", "set", "task", "scheduler", "as", "follows", "pre", "class", "code", "0", "configuration", "0", "enable", "web", "socket", "public", "class", "web", "socket", "config", "implements", "web", "socket", "configurer"], "project": "spring-framework"}
{"id": 1552, "code": "\tprotected DynamicMBean adaptMBeanIfPossible(Object bean) throws JMException {\n\t\tClass<?> targetClass = AopUtils.getTargetClass(bean);\n\t\tif (targetClass != bean.getClass()) {\n\t\t\tClass<?> ifc = JmxUtils.getMXBeanInterface(targetClass);\n\t\t\tif (ifc != null) {\n\t\t\t\tif (!ifc.isInstance(bean)) {\n\t\t\t\t\tthrow new NotCompliantMBeanException(\"Managed bean [\" + bean +\n\t\t\t\t\t\t\t\"] has a target class with an MXBean interface but does not expose it in the proxy\");\n\t\t\t\t}\n\t\t\t\treturn new StandardMBean(bean, ((Class<Object>) ifc), true);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tifc = JmxUtils.getMBeanInterface(targetClass);\n\t\t\t\tif (ifc != null) {\n\t\t\t\t\tif (!ifc.isInstance(bean)) {\n\t\t\t\t\t\tthrow new NotCompliantMBeanException(\"Managed bean [\" + bean +\n\t\t\t\t\t\t\t\t\"] has a target class with an MBean interface but does not expose it in the proxy\");\n\t\t\t\t\t}\n\t\t\t\t\treturn new StandardMBean(bean, ((Class<Object>) ifc));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["build", "an", "adapted", "mbean", "for", "the", "given", "bean", "instance", "if", "possible"], "project": "spring-framework"}
{"id": 6365, "code": "\tprotected Mono<Void> doResume(TransactionSynchronizationManager synchronizationManager,\n\t\t\t@Nullable Object transaction, Object suspendedResources) throws TransactionException {\n\n\t\tthrow new TransactionSuspensionNotSupportedException(\n\t\t\t\t\"Transaction manager [\" + getClass().getName() + \"] does not support transaction suspension\");\n\t}", "summary_tokens": ["resume", "the", "resources", "of", "the", "current", "transaction"], "project": "spring-framework"}
{"id": 587, "code": "\tpublic Object extractSource(Object sourceCandidate, @Nullable Resource definitionResource) {\n\t\treturn null;\n\t}", "summary_tokens": ["this", "implementation", "simply", "returns", "null", "for", "any", "input"], "project": "spring-framework"}
{"id": 272, "code": "\tpublic synchronized Class<?> getTargetClass() {\n\t\treturn this.target.getClass();\n\t}", "summary_tokens": ["return", "the", "type", "of", "the", "current", "target", "object"], "project": "spring-framework"}
{"id": 655, "code": "\tpublic int getDependencyCheck() {\n\t\treturn this.dependencyCheck;\n\t}", "summary_tokens": ["return", "the", "default", "dependency", "check", "code"], "project": "spring-framework"}
{"id": 5679, "code": "\tstatic Set<Class<? extends ApplicationContextInitializer<?>>> resolveInitializerClasses(\n\t\t\tList<ContextConfigurationAttributes> configAttributesList) {\n\n\t\tAssert.notEmpty(configAttributesList, \"ContextConfigurationAttributes List must not be empty\");\n\t\tSet<Class<? extends ApplicationContextInitializer<?>>> initializerClasses = new LinkedHashSet<>();\n\n\t\tfor (ContextConfigurationAttributes configAttributes : configAttributesList) {\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Processing context initializers for configuration attributes \" + configAttributes);\n\t\t\t}\n\t\t\tCollections.addAll(initializerClasses, configAttributes.getInitializers());\n\t\t\tif (!configAttributes.isInheritInitializers()) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\treturn initializerClasses;\n\t}", "summary_tokens": ["resolve", "the", "set", "of", "merged", "application", "context", "initializer", "classes", "for", "the", "supplied", "list", "of", "context", "configuration", "attributes"], "project": "spring-framework"}
{"id": 3860, "code": "\tpublic void setSchemaName(@Nullable String schemaName) {\n\t\tcheckIfConfigurationModificationIsAllowed();\n\t\tthis.tableMetaDataContext.setSchemaName(schemaName);\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "schema", "for", "this", "insert"], "project": "spring-framework"}
{"id": 7489, "code": "\tpublic void setFormConverter(FormHttpMessageConverter converter) {\n\t\tAssert.notNull(converter, \"FormHttpMessageConverter is required\");\n\t\tthis.formConverter = converter;\n\t}", "summary_tokens": ["set", "the", "converter", "to", "use", "for", "parsing", "form", "content"], "project": "spring-framework"}
{"id": 6962, "code": "\tpublic Jackson2ObjectMapperBuilder deserializerByType(Class<?> type, JsonDeserializer<?> deserializer) {\n\t\tthis.deserializers.put(type, deserializer);\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "a", "custom", "deserializer", "for", "the", "given", "type"], "project": "spring-framework"}
{"id": 4939, "code": "\tpublic String getRelayHost() {\n\t\treturn this.relayHost;\n\t}", "summary_tokens": ["return", "the", "stomp", "message", "broker", "host"], "project": "spring-framework"}
{"id": 8618, "code": "\tpublic Boolean isUseRegisteredSuffixPatternMatch() {\n\t\treturn this.registeredSuffixPatternMatch;\n\t}", "summary_tokens": ["whether", "to", "use", "registered", "suffixes", "for", "pattern", "matching"], "project": "spring-framework"}
{"id": 5485, "code": "\tpublic static ProfileValueSource retrieveProfileValueSource(Class<?> testClass) {\n\t\tAssert.notNull(testClass, \"testClass must not be null\");\n\n\t\tClass<ProfileValueSourceConfiguration> annotationType = ProfileValueSourceConfiguration.class;\n\t\tProfileValueSourceConfiguration config = AnnotatedElementUtils.findMergedAnnotation(testClass, annotationType);\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Retrieved @ProfileValueSourceConfiguration [\" + config + \"] for test class [\" +\n\t\t\t\t\ttestClass.getName() + \"]\");\n\t\t}\n\n\t\tClass<? extends ProfileValueSource> profileValueSourceType;\n\t\tif (config != null) {\n\t\t\tprofileValueSourceType = config.value();\n\t\t}\n\t\telse {\n\t\t\tprofileValueSourceType = (Class<? extends ProfileValueSource>) AnnotationUtils.getDefaultValue(annotationType);\n\t\t\tAssert.state(profileValueSourceType != null, \"No default ProfileValueSource class\");\n\t\t}\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Retrieved ProfileValueSource type [\" + profileValueSourceType + \"] for class [\" +\n\t\t\t\t\ttestClass.getName() + \"]\");\n\t\t}\n\n\t\tProfileValueSource profileValueSource;\n\t\tif (SystemProfileValueSource.class == profileValueSourceType) {\n\t\t\tprofileValueSource = SystemProfileValueSource.getInstance();\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\tprofileValueSource = ReflectionUtils.accessibleConstructor(profileValueSourceType).newInstance();\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\t\tlogger.warn(\"Could not instantiate a ProfileValueSource of type [\" + profileValueSourceType +\n\t\t\t\t\t\t\t\"] for class [\" + testClass.getName() + \"]: using default.\", ex);\n\t\t\t\t}\n\t\t\t\tprofileValueSource = SystemProfileValueSource.getInstance();\n\t\t\t}\n\t\t}\n\n\t\treturn profileValueSource;\n\t}", "summary_tokens": ["retrieves", "the", "profile", "value", "source", "type", "for", "the", "specified", "class", "test", "class", "as", "configured", "via", "the", "profile", "value", "source", "configuration", "0", "profile", "value", "source", "configuration", "annotation", "and", "instantiates", "a", "new", "instance", "of", "that", "type"], "project": "spring-framework"}
{"id": 4233, "code": "\tpublic JmsListenerEndpointRegistry getEndpointRegistry() {\n\t\treturn this.endpointRegistry;\n\t}", "summary_tokens": ["return", "the", "jms", "listener", "endpoint", "registry", "instance", "for", "this", "registrar", "may", "be", "null"], "project": "spring-framework"}
{"id": 1195, "code": "\tprotected Object getCacheKey(Method method, @Nullable Class<?> targetClass) {\n\t\treturn new MethodClassKey(method, targetClass);\n\t}", "summary_tokens": ["determine", "a", "cache", "key", "for", "the", "given", "method", "and", "target", "class"], "project": "spring-framework"}
{"id": 2659, "code": "\tpublic static void registerStaticCallbacks(Class generatedClass, Callback[] callbacks) {\n\t\tsetCallbacksHelper(generatedClass, callbacks, SET_STATIC_CALLBACKS_NAME);\n\t}", "summary_tokens": ["similar", "to", "register", "callbacks", "but", "suitable", "for", "use", "when", "multiple", "threads", "will", "be", "creating", "instances", "of", "the", "generated", "class"], "project": "spring-framework"}
{"id": 5524, "code": "\tprivate List<TestExecutionListener> getReversedTestExecutionListeners() {\n\t\tList<TestExecutionListener> listenersReversed = new ArrayList<>(getTestExecutionListeners());\n\t\tCollections.reverse(listenersReversed);\n\t\treturn listenersReversed;\n\t}", "summary_tokens": ["get", "a", "copy", "of", "the", "test", "execution", "listener", "test", "execution", "listeners", "registered", "for", "this", "test", "context", "manager", "in", "reverse", "order"], "project": "spring-framework"}
{"id": 5457, "code": "\tpublic static MockCookie parse(String setCookieHeader) {\n\t\tAssert.notNull(setCookieHeader, \"Set-Cookie header must not be null\");\n\t\tString[] cookieParts = setCookieHeader.split(\"\\\\s*=\\\\s*\", 2);\n\t\tAssert.isTrue(cookieParts.length == 2, () -> \"Invalid Set-Cookie header '\" + setCookieHeader + \"'\");\n\n\t\tString name = cookieParts[0];\n\t\tString[] valueAndAttributes = cookieParts[1].split(\"\\\\s*;\\\\s*\", 2);\n\t\tString value = valueAndAttributes[0];\n\t\tString[] attributes =\n\t\t\t\t(valueAndAttributes.length > 1 ? valueAndAttributes[1].split(\"\\\\s*;\\\\s*\") : new String[0]);\n\n\t\tMockCookie cookie = new MockCookie(name, value);\n\t\tfor (String attribute : attributes) {\n\t\t\tif (StringUtils.startsWithIgnoreCase(attribute, \"Domain\")) {\n\t\t\t\tcookie.setDomain(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Max-Age\")) {\n\t\t\t\tcookie.setMaxAge(Integer.parseInt(extractAttributeValue(attribute, setCookieHeader)));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Expires\")) {\n\t\t\t\ttry {\n\t\t\t\t\tcookie.setExpires(ZonedDateTime.parse(extractAttributeValue(attribute, setCookieHeader),\n\t\t\t\t\t\t\tDateTimeFormatter.RFC_1123_DATE_TIME));\n\t\t\t\t}\n\t\t\t\tcatch (DateTimeException ex) {\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Path\")) {\n\t\t\t\tcookie.setPath(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Secure\")) {\n\t\t\t\tcookie.setSecure(true);\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"HttpOnly\")) {\n\t\t\t\tcookie.setHttpOnly(true);\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"SameSite\")) {\n\t\t\t\tcookie.setSameSite(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Comment\")) {\n\t\t\t\tcookie.setComment(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t}\n\t\treturn cookie;\n\t}", "summary_tokens": ["factory", "method", "that", "parses", "the", "value", "of", "the", "supplied", "set", "cookie", "header"], "project": "spring-framework"}
{"id": 2219, "code": "\tpublic <T> void addInstance(String factoryType, T... factoryInstance) {\n\t\tList<String> implementations = this.factories.computeIfAbsent(factoryType, key -> new ArrayList<>());\n\t\tfor (T factoryImplementation : factoryInstance) {\n\t\t\tString reference = \"!\" + factoryType + \":\" + factoryImplementation.getClass().getName()\n\t\t\t\t\t+ this.sequence.getAndIncrement();\n\t\t\timplementations.add(reference);\n\t\t\tthis.implementations.put(reference, factoryImplementation);\n\t\t}\n\t}", "summary_tokens": ["add", "factory", "instances", "to", "this", "instance"], "project": "spring-framework"}
{"id": 1572, "code": "\tpublic void setDefaultDomain(String defaultDomain) {\n\t\tthis.metadataNamingStrategy.setDefaultDomain(defaultDomain);\n\t}", "summary_tokens": ["specify", "the", "default", "domain", "to", "be", "used", "for", "generating", "object", "names", "when", "no", "source", "level", "metadata", "has", "been", "specified"], "project": "spring-framework"}
{"id": 5449, "code": "\tpublic Mono<String> getBodyAsString() {\n\n\t\tCharset charset = Optional.ofNullable(getHeaders().getContentType()).map(MimeType::getCharset)\n\t\t\t\t.orElse(StandardCharsets.UTF_8);\n\n\t\treturn DataBufferUtils.join(getBody())\n\t\t\t\t.map(buffer -> {\n\t\t\t\t\tString s = buffer.toString(charset);\n\t\t\t\t\tDataBufferUtils.release(buffer);\n\t\t\t\t\treturn s;\n\t\t\t\t})\n\t\t\t\t.defaultIfEmpty(\"\");\n\t}", "summary_tokens": ["aggregate", "response", "data", "and", "convert", "to", "a", "string", "using", "the", "content", "type", "charset", "or", "utf", "0", "by", "default"], "project": "spring-framework"}
{"id": 357, "code": "\tpublic static PropertyMatches forField(String propertyName, Class<?> beanClass, int maxDistance) {\n\t\treturn new FieldPropertyMatches(propertyName, beanClass, maxDistance);\n\t}", "summary_tokens": ["create", "property", "matches", "for", "the", "given", "field", "property"], "project": "spring-framework"}
{"id": 6336, "code": "\tprotected void doRegisterAfterCompletionWithJtaTransaction(\n\t\t\tJtaTransactionObject txObject, List<TransactionSynchronization> synchronizations)\n\t\t\tthrows RollbackException, SystemException {\n\n\t\tint jtaStatus = txObject.getUserTransaction().getStatus();\n\t\tif (jtaStatus == Status.STATUS_NO_TRANSACTION) {\n\t\t\tthrow new RollbackException(\"JTA transaction already completed - probably rolled back\");\n\t\t}\n\t\tif (jtaStatus == Status.STATUS_ROLLEDBACK) {\n\t\t\tthrow new RollbackException(\"JTA transaction already rolled back (probably due to a timeout)\");\n\t\t}\n\n\t\tif (this.transactionSynchronizationRegistry != null) {\n\t\t\t\n\t\t\tthis.transactionSynchronizationRegistry.registerInterposedSynchronization(\n\t\t\t\t\tnew JtaAfterCompletionSynchronization(synchronizations));\n\t\t}\n\n\t\telse if (getTransactionManager() != null) {\n\t\t\t\n\t\t\tTransaction transaction = getTransactionManager().getTransaction();\n\t\t\tif (transaction == null) {\n\t\t\t\tthrow new IllegalStateException(\"No JTA Transaction available\");\n\t\t\t}\n\t\t\ttransaction.registerSynchronization(new JtaAfterCompletionSynchronization(synchronizations));\n\t\t}\n\n\t\telse {\n\t\t\t\n\t\t\tlogger.warn(\"Participating in existing JTA transaction, but no JTA TransactionManager available: \" +\n\t\t\t\t\t\"cannot register Spring after-completion callbacks with outer JTA transaction - \" +\n\t\t\t\t\t\"processing Spring after-completion callbacks with outcome status 'unknown'\");\n\t\t\tinvokeAfterCompletion(synchronizations, TransactionSynchronization.STATUS_UNKNOWN);\n\t\t}\n\t}", "summary_tokens": ["register", "a", "jta", "synchronization", "on", "the", "jta", "transaction", "manager", "for", "calling", "after", "completion", "on", "the", "given", "spring", "transaction", "synchronizations"], "project": "spring-framework"}
{"id": 1969, "code": "\tdefault String[] getSuppressedFields() {\n\t\treturn new String[0];\n\t}", "summary_tokens": ["return", "the", "list", "of", "fields", "that", "were", "suppressed", "during", "the", "bind", "process"], "project": "spring-framework"}
{"id": 6934, "code": "\tpublic void setWriteAcceptCharset(boolean writeAcceptCharset) {\n\t\tthis.writeAcceptCharset = writeAcceptCharset;\n\t}", "summary_tokens": ["whether", "the", "accept", "charset", "header", "should", "be", "written", "to", "any", "outgoing", "request", "sourced", "from", "the", "value", "of", "charset", "available", "charsets"], "project": "spring-framework"}
{"id": 286, "code": "\tprivate void testThisOrTarget(String which) throws SecurityException, NoSuchMethodException {\n\t\tString matchesTestBean = which + \"(org.springframework.beans.testfixture.beans.TestBean)\";\n\t\tString matchesIOther = which + \"(org.springframework.beans.testfixture.beans.IOther)\";\n\t\tAspectJExpressionPointcut testBeanPc = new AspectJExpressionPointcut();\n\t\ttestBeanPc.setExpression(matchesTestBean);\n\n\t\tAspectJExpressionPointcut iOtherPc = new AspectJExpressionPointcut();\n\t\tiOtherPc.setExpression(matchesIOther);\n\n\t\tassertThat(testBeanPc.matches(TestBean.class)).isTrue();\n\t\tassertThat(testBeanPc.matches(getAge, TestBean.class)).isTrue();\n\t\tassertThat(iOtherPc.matches(OtherIOther.class.getMethod(\"absquatulate\"), OtherIOther.class)).isTrue();\n\t\tassertThat(testBeanPc.matches(OtherIOther.class.getMethod(\"absquatulate\"), OtherIOther.class)).isFalse();\n\t}", "summary_tokens": ["this", "and", "target", "are", "equivalent"], "project": "spring-framework"}
{"id": 5000, "code": "\tpublic String getLogin() {\n\t\treturn getFirst(LOGIN);\n\t}", "summary_tokens": ["get", "the", "login", "header"], "project": "spring-framework"}
{"id": 2202, "code": "\tpublic ResourceFiles and(ResourceFiles ResourceFiles) {\n\t\treturn new ResourceFiles(this.files.and(ResourceFiles.files));\n\t}", "summary_tokens": ["return", "a", "new", "resource", "files", "instance", "that", "merges", "files", "from", "another", "resource", "files", "instance"], "project": "spring-framework"}
{"id": 1087, "code": "\tpublic void setTriggers(Trigger... triggers) {\n\t\tthis.triggers = Arrays.asList(triggers);\n\t}", "summary_tokens": ["register", "a", "list", "of", "trigger", "objects", "with", "the", "scheduler", "that", "this", "factory", "bean", "creates"], "project": "spring-framework"}
{"id": 5941, "code": "\tprotected final WebConnection createConnection(WebClient webClient) {\n\t\tAssert.notNull(webClient, \"WebClient must not be null\");\n\t\treturn createConnection(webClient, webClient.getWebConnection());\n\t}", "summary_tokens": ["create", "a", "new", "web", "connection", "that", "will", "use", "a", "mock", "mvc", "instance", "if", "one", "of", "the", "specified", "web", "request", "matcher", "instances", "matches"], "project": "spring-framework"}
{"id": 5292, "code": "\tprotected String getParticipateAttributeName() {\n\t\treturn obtainEntityManagerFactory().toString() + PARTICIPATE_SUFFIX;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "request", "attribute", "that", "identifies", "that", "a", "request", "is", "already", "filtered"], "project": "spring-framework"}
{"id": 2100, "code": "\tvoid singletonInheritsFromParentFactoryPrototype() {\n\t\tDefaultListableBeanFactory parent = new DefaultListableBeanFactory();\n\t\tnew XmlBeanDefinitionReader(parent).loadBeanDefinitions(PARENT_CONTEXT);\n\t\tDefaultListableBeanFactory child = new DefaultListableBeanFactory(parent);\n\t\tnew XmlBeanDefinitionReader(child).loadBeanDefinitions(CHILD_CONTEXT);\n\t\tTestBean inherits = (TestBean) child.getBean(\"singletonInheritsFromParentFactoryPrototype\");\n\t\t\n\t\tassertThat(inherits.getName().equals(\"prototype-override\")).isTrue();\n\t\t\n\t\tassertThat(inherits.getAge() == 2).isTrue();\n\t\tTestBean inherits2 = (TestBean) child.getBean(\"singletonInheritsFromParentFactoryPrototype\");\n\t\tassertThat(inherits2 == inherits).isTrue();\n\t}", "summary_tokens": ["note", "that", "prototype", "singleton", "distinction", "is", "b", "not", "b", "inherited"], "project": "spring-framework"}
{"id": 2340, "code": "public void accept(\n    final ClassVisitor classVisitor,\n    final Attribute[] attributePrototypes,\n    final int parsingOptions) {\n  Context context = new Context();\n  context.attributePrototypes = attributePrototypes;\n  context.parsingOptions = parsingOptions;\n  context.charBuffer = new char[maxStringLength];\n\n    \n  char[] charBuffer = context.charBuffer;\n  int currentOffset = header;\n  int accessFlags = readUnsignedShort(currentOffset);\n  String thisClass = readClass(currentOffset + 2, charBuffer);\n  String superClass = readClass(currentOffset + 4, charBuffer);\n  String[] interfaces = new String[readUnsignedShort(currentOffset + 6)];\n  currentOffset += 8;\n  for (int i = 0; i < interfaces.length; ++i) {\n    interfaces[i] = readClass(currentOffset, charBuffer);\n    currentOffset += 2;\n  }\n\n    \n    \n    \n  int innerClassesOffset = 0;\n    \n  int enclosingMethodOffset = 0;\n    \n  String signature = null;\n    \n  String sourceFile = null;\n    \n  String sourceDebugExtension = null;\n    \n  int runtimeVisibleAnnotationsOffset = 0;\n    \n  int runtimeInvisibleAnnotationsOffset = 0;\n    \n  int runtimeVisibleTypeAnnotationsOffset = 0;\n    \n  int runtimeInvisibleTypeAnnotationsOffset = 0;\n    \n  int moduleOffset = 0;\n    \n  int modulePackagesOffset = 0;\n    \n  String moduleMainClass = null;\n    \n  String nestHostClass = null;\n    \n  int nestMembersOffset = 0;\n    \n  int permittedSubclassesOffset = 0;\n    \n  int recordOffset = 0;\n    \n    \n  Attribute attributes = null;\n\n  int currentAttributeOffset = getFirstAttributeOffset();\n  for (int i = readUnsignedShort(currentAttributeOffset - 2); i > 0; --i) {\n      \n    String attributeName = readUTF8(currentAttributeOffset, charBuffer);\n    int attributeLength = readInt(currentAttributeOffset + 2);\n    currentAttributeOffset += 6;\n      \n      \n    if (Constants.SOURCE_FILE.equals(attributeName)) {\n      sourceFile = readUTF8(currentAttributeOffset, charBuffer);\n    } else if (Constants.INNER_CLASSES.equals(attributeName)) {\n      innerClassesOffset = currentAttributeOffset;\n    } else if (Constants.ENCLOSING_METHOD.equals(attributeName)) {\n      enclosingMethodOffset = currentAttributeOffset;\n    } else if (Constants.NEST_HOST.equals(attributeName)) {\n      nestHostClass = readClass(currentAttributeOffset, charBuffer);\n    } else if (Constants.NEST_MEMBERS.equals(attributeName)) {\n      nestMembersOffset = currentAttributeOffset;\n    } else if (Constants.PERMITTED_SUBCLASSES.equals(attributeName)) {\n      permittedSubclassesOffset = currentAttributeOffset;\n    } else if (Constants.SIGNATURE.equals(attributeName)) {\n      signature = readUTF8(currentAttributeOffset, charBuffer);\n    } else if (Constants.RUNTIME_VISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleAnnotationsOffset = currentAttributeOffset;\n    } else if (Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleTypeAnnotationsOffset = currentAttributeOffset;\n    } else if (Constants.DEPRECATED.equals(attributeName)) {\n      accessFlags |= Opcodes.ACC_DEPRECATED;\n    } else if (Constants.SYNTHETIC.equals(attributeName)) {\n      accessFlags |= Opcodes.ACC_SYNTHETIC;\n    } else if (Constants.SOURCE_DEBUG_EXTENSION.equals(attributeName)) {\n      if (attributeLength > classFileBuffer.length - currentAttributeOffset) {\n        throw new IllegalArgumentException();\n      }\n      sourceDebugExtension =\n          readUtf(currentAttributeOffset, attributeLength, new char[attributeLength]);\n    } else if (Constants.RUNTIME_INVISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleAnnotationsOffset = currentAttributeOffset;\n    } else if (Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleTypeAnnotationsOffset = currentAttributeOffset;\n    } else if (Constants.RECORD.equals(attributeName)) {\n      recordOffset = currentAttributeOffset;\n      accessFlags |= Opcodes.ACC_RECORD;\n    } else if (Constants.MODULE.equals(attributeName)) {\n      moduleOffset = currentAttributeOffset;\n    } else if (Constants.MODULE_MAIN_CLASS.equals(attributeName)) {\n      moduleMainClass = readClass(currentAttributeOffset, charBuffer);\n    } else if (Constants.MODULE_PACKAGES.equals(attributeName)) {\n      modulePackagesOffset = currentAttributeOffset;\n    } else if (!Constants.BOOTSTRAP_METHODS.equals(attributeName)) {\n        \n      Attribute attribute =\n          readAttribute(\n              attributePrototypes,\n              attributeName,\n              currentAttributeOffset,\n              attributeLength,\n              charBuffer,\n              -1,\n              null);\n      attribute.nextAttribute = attributes;\n      attributes = attribute;\n    }\n    currentAttributeOffset += attributeLength;\n  }\n\n    \n    \n  classVisitor.visit(\n      readInt(cpInfoOffsets[1] - 7), accessFlags, thisClass, signature, superClass, interfaces);\n\n    \n  if ((parsingOptions & SKIP_DEBUG) == 0\n      && (sourceFile != null || sourceDebugExtension != null)) {\n    classVisitor.visitSource(sourceFile, sourceDebugExtension);\n  }\n\n    \n  if (moduleOffset != 0) {\n    readModuleAttributes(\n        classVisitor, context, moduleOffset, modulePackagesOffset, moduleMainClass);\n  }\n\n    \n  if (nestHostClass != null) {\n    classVisitor.visitNestHost(nestHostClass);\n  }\n\n    \n  if (enclosingMethodOffset != 0) {\n    String className = readClass(enclosingMethodOffset, charBuffer);\n    int methodIndex = readUnsignedShort(enclosingMethodOffset + 2);\n    String name = methodIndex == 0 ? null : readUTF8(cpInfoOffsets[methodIndex], charBuffer);\n    String type = methodIndex == 0 ? null : readUTF8(cpInfoOffsets[methodIndex] + 2, charBuffer);\n    classVisitor.visitOuterClass(className, name, type);\n  }\n\n    \n  if (runtimeVisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              classVisitor.visitAnnotation(annotationDescriptor,  true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              classVisitor.visitAnnotation(annotationDescriptor,  false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeVisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              classVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              classVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  while (attributes != null) {\n      \n    Attribute nextAttribute = attributes.nextAttribute;\n    attributes.nextAttribute = null;\n    classVisitor.visitAttribute(attributes);\n    attributes = nextAttribute;\n  }\n\n    \n  if (nestMembersOffset != 0) {\n    int numberOfNestMembers = readUnsignedShort(nestMembersOffset);\n    int currentNestMemberOffset = nestMembersOffset + 2;\n    while (numberOfNestMembers-- > 0) {\n      classVisitor.visitNestMember(readClass(currentNestMemberOffset, charBuffer));\n      currentNestMemberOffset += 2;\n    }\n  }\n\n    \n  if (permittedSubclassesOffset != 0) {\n    int numberOfPermittedSubclasses = readUnsignedShort(permittedSubclassesOffset);\n    int currentPermittedSubclassesOffset = permittedSubclassesOffset + 2;\n    while (numberOfPermittedSubclasses-- > 0) {\n      classVisitor.visitPermittedSubclass(\n          readClass(currentPermittedSubclassesOffset, charBuffer));\n      currentPermittedSubclassesOffset += 2;\n    }\n  }\n\n    \n  if (innerClassesOffset != 0) {\n    int numberOfClasses = readUnsignedShort(innerClassesOffset);\n    int currentClassesOffset = innerClassesOffset + 2;\n    while (numberOfClasses-- > 0) {\n      classVisitor.visitInnerClass(\n          readClass(currentClassesOffset, charBuffer),\n          readClass(currentClassesOffset + 2, charBuffer),\n          readUTF8(currentClassesOffset + 4, charBuffer),\n          readUnsignedShort(currentClassesOffset + 6));\n      currentClassesOffset += 8;\n    }\n  }\n\n    \n  if (recordOffset != 0) {\n    int recordComponentsCount = readUnsignedShort(recordOffset);\n    recordOffset += 2;\n    while (recordComponentsCount-- > 0) {\n      recordOffset = readRecordComponent(classVisitor, context, recordOffset);\n    }\n  }\n\n    \n  int fieldsCount = readUnsignedShort(currentOffset);\n  currentOffset += 2;\n  while (fieldsCount-- > 0) {\n    currentOffset = readField(classVisitor, context, currentOffset);\n  }\n  int methodsCount = readUnsignedShort(currentOffset);\n  currentOffset += 2;\n  while (methodsCount-- > 0) {\n    currentOffset = readMethod(classVisitor, context, currentOffset);\n  }\n\n    \n  classVisitor.visitEnd();\n}", "summary_tokens": ["makes", "the", "given", "visitor", "visit", "the", "jvms", "class", "file", "structure", "passed", "to", "the", "constructor", "of", "this", "class", "reader"], "project": "spring-framework"}
{"id": 6340, "code": "\tpublic final TransactionManager getTransactionManager() {\n\t\treturn this.transactionManager;\n\t}", "summary_tokens": ["return", "the", "jta", "transaction", "manager", "that", "this", "adapter", "delegates", "to"], "project": "spring-framework"}
{"id": 3415, "code": "\tpublic void removeBinding(@Nullable String prefix) {\n\t\tif (XMLConstants.DEFAULT_NS_PREFIX.equals(prefix)) {\n\t\t\tthis.defaultNamespaceUri = \"\";\n\t\t}\n\t\telse if (prefix != null) {\n\t\t\tString namespaceUri = this.prefixToNamespaceUri.remove(prefix);\n\t\t\tif (namespaceUri != null) {\n\t\t\t\tSet<String> prefixes = this.namespaceUriToPrefixes.get(namespaceUri);\n\t\t\t\tif (prefixes != null) {\n\t\t\t\t\tprefixes.remove(prefix);\n\t\t\t\t\tif (prefixes.isEmpty()) {\n\t\t\t\t\t\tthis.namespaceUriToPrefixes.remove(namespaceUri);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["remove", "the", "given", "prefix", "from", "this", "context"], "project": "spring-framework"}
{"id": 1461, "code": "\tpublic void registerSingleton(String name, Class<?> clazz, MutablePropertyValues pvs) throws BeansException {\n\t\tGenericBeanDefinition bd = new GenericBeanDefinition();\n\t\tbd.setBeanClass(clazz);\n\t\tbd.setPropertyValues(pvs);\n\t\tgetDefaultListableBeanFactory().registerBeanDefinition(name, bd);\n\t}", "summary_tokens": ["register", "a", "singleton", "bean", "with", "the", "underlying", "bean", "factory"], "project": "spring-framework"}
{"id": 2493, "code": "public AnnotationVisitor visitLocalVariableAnnotation(\n    final int typeRef,\n    final TypePath typePath,\n    final Label[] start,\n    final Label[] end,\n    final int[] index,\n    final String descriptor,\n    final boolean visible) {\n  if (api < Opcodes.ASM5) {\n    throw new UnsupportedOperationException(REQUIRES_ASM5);\n  }\n  if (mv != null) {\n    return mv.visitLocalVariableAnnotation(\n        typeRef, typePath, start, end, index, descriptor, visible);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "annotation", "on", "a", "local", "variable", "type"], "project": "spring-framework"}
{"id": 9073, "code": "\tpublic void registerExtension(String coding, String extension) {\n\t\tthis.extensions.put(coding, (extension.startsWith(\".\") ? extension : \".\" + extension));\n\t}", "summary_tokens": ["java", "config", "friendly", "alternative", "to", "set", "extensions", "map"], "project": "spring-framework"}
{"id": 9881, "code": "\tpublic Collection<String> getAllowedOrigins() {\n\t\tList<String> allowedOrigins = this.corsConfiguration.getAllowedOrigins();\n\t\treturn (CollectionUtils.isEmpty(allowedOrigins) ? Collections.emptySet() :\n\t\t\t\tCollections.unmodifiableSet(new LinkedHashSet<>(allowedOrigins)));\n\t}", "summary_tokens": ["return", "the", "set", "allowed", "origin", "patterns", "collection", "configured", "allowed", "origins"], "project": "spring-framework"}
{"id": 8866, "code": "\tprotected String getPrefix() {\n\t\treturn this.prefix;\n\t}", "summary_tokens": ["return", "the", "prefix", "to", "prepend", "to", "the", "request", "url", "filename"], "project": "spring-framework"}
{"id": 5480, "code": "\tpublic FilterRegistration getFilterRegistration(String filterName) {\n\t\treturn null;\n\t}", "summary_tokens": ["this", "method", "always", "returns", "null"], "project": "spring-framework"}
{"id": 7973, "code": "\tpublic HandlerResult setExceptionHandler(Function<Throwable, Mono<HandlerResult>> function) {\n\t\tthis.exceptionHandler = function;\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "an", "exception", "handler", "that", "may", "be", "used", "to", "produce", "an", "alternative", "result", "when", "result", "handling", "fails"], "project": "spring-framework"}
{"id": 9219, "code": "\tprotected void writeMessage(String msg) throws IOException {\n\t\tthis.pageContext.getOut().write(msg);\n\t}", "summary_tokens": ["write", "the", "message", "to", "the", "page"], "project": "spring-framework"}
{"id": 8997, "code": "\tpublic Object handleEmptyBody(@Nullable Object body, HttpInputMessage inputMessage, MethodParameter parameter,\n\t\t\tType targetType, Class<? extends HttpMessageConverter<?>> converterType) {\n\n\t\treturn body;\n\t}", "summary_tokens": ["the", "default", "implementation", "returns", "the", "body", "that", "was", "passed", "in"], "project": "spring-framework"}
{"id": 2942, "code": "\tpublic URL getURL() throws IOException {\n\t\treturn (this.file != null ? this.file.toURI().toURL() : this.filePath.toUri().toURL());\n\t}", "summary_tokens": ["this", "implementation", "returns", "a", "url", "for", "the", "underlying", "file"], "project": "spring-framework"}
{"id": 8787, "code": "\tpublic void setMessageConverters(List<HttpMessageConverter<?>> messageConverters) {\n\t\tthis.messageConverters = messageConverters;\n\t}", "summary_tokens": ["set", "the", "message", "body", "converters", "to", "use"], "project": "spring-framework"}
{"id": 3975, "code": "\tpublic Connection getConnection() {\n\t\treturn this.connection;\n\t}", "summary_tokens": ["return", "the", "specified", "connection", "as", "is"], "project": "spring-framework"}
{"id": 4481, "code": "\tprotected void doRescheduleTask(Object task) {\n\t\tAssert.state(this.taskExecutor != null, \"No TaskExecutor available\");\n\t\tthis.taskExecutor.execute((Runnable) task);\n\t}", "summary_tokens": ["re", "executes", "the", "given", "task", "via", "this", "listener", "container", "s", "task", "executor"], "project": "spring-framework"}
{"id": 6203, "code": "\tpublic MessageEndpointFactory getMessageEndpointFactory() {\n\t\treturn this.messageEndpointFactory;\n\t}", "summary_tokens": ["return", "the", "jca", "message", "endpoint", "factory", "to", "activate"], "project": "spring-framework"}
{"id": 3077, "code": "\tpublic final ResourceLoader getResourceLoader() {\n\t\treturn this.resourceLoader;\n\t}", "summary_tokens": ["return", "the", "resource", "loader", "that", "this", "metadata", "reader", "factory", "has", "been", "constructed", "with"], "project": "spring-framework"}
{"id": 9824, "code": "\tpublic String getSessionId() {\n\t\treturn this.sessionId;\n\t}", "summary_tokens": ["return", "the", "session", "id"], "project": "spring-framework"}
{"id": 8288, "code": "\tprivate Object handleNullValue(String name, @Nullable Object value, Class<?> paramType) {\n\t\tif (value == null) {\n\t\t\tif (Boolean.TYPE.equals(paramType)) {\n\t\t\t\treturn Boolean.FALSE;\n\t\t\t}\n\t\t\telse if (paramType.isPrimitive()) {\n\t\t\t\tthrow new IllegalStateException(\"Optional \" + paramType.getSimpleName() +\n\t\t\t\t\t\t\" parameter '\" + name + \"' is present but cannot be translated into a\" +\n\t\t\t\t\t\t\" null value due to being declared as a primitive type. \" +\n\t\t\t\t\t\t\"Consider declaring it as object wrapper for the corresponding primitive type.\");\n\t\t\t}\n\t\t}\n\t\treturn value;\n\t}", "summary_tokens": ["a", "null", "results", "in", "a", "false", "value", "for", "boolean", "s", "or", "an", "exception", "for", "other", "primitives"], "project": "spring-framework"}
{"id": 7638, "code": "\tpublic boolean isResolved() {\n\t\treturn (this.multipartFiles != null);\n\t}", "summary_tokens": ["determine", "whether", "the", "underlying", "multipart", "request", "has", "been", "resolved"], "project": "spring-framework"}
{"id": 779, "code": "\tpublic void configureBean(Object beanInstance) {\n\t\tif (this.beanFactory == null) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"BeanFactory has not been set on \" + ClassUtils.getShortName(getClass()) + \": \" +\n\t\t\t\t\t\t\"Make sure this configurer runs in a Spring container. Unable to configure bean of type [\" +\n\t\t\t\t\t\tClassUtils.getDescriptiveType(beanInstance) + \"]. Proceeding without injection.\");\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\n\t\tBeanWiringInfoResolver bwiResolver = this.beanWiringInfoResolver;\n\t\tAssert.state(bwiResolver != null, \"No BeanWiringInfoResolver available\");\n\t\tBeanWiringInfo bwi = bwiResolver.resolveWiringInfo(beanInstance);\n\t\tif (bwi == null) {\n\t\t\t\n\t\t\treturn;\n\t\t}\n\n\n\t\tConfigurableListableBeanFactory beanFactory = this.beanFactory;\n\t\tAssert.state(beanFactory != null, \"No BeanFactory available\");\n\t\ttry {\n\t\t\tString beanName = bwi.getBeanName();\n\t\t\tif (bwi.indicatesAutowiring() || (bwi.isDefaultBeanName() && beanName != null &&\n\t\t\t\t\t!beanFactory.containsBean(beanName))) {\n\t\t\t\t\n\t\t\t\tbeanFactory.autowireBeanProperties(beanInstance, bwi.getAutowireMode(), bwi.getDependencyCheck());\n\t\t\t\tbeanFactory.initializeBean(beanInstance, (beanName != null ? beanName : \"\"));\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\tbeanFactory.configureBean(beanInstance, (beanName != null ? beanName : \"\"));\n\t\t\t}\n\t\t}\n\t\tcatch (BeanCreationException ex) {\n\t\t\tThrowable rootCause = ex.getMostSpecificCause();\n\t\t\tif (rootCause instanceof BeanCurrentlyInCreationException) {\n\t\t\t\tBeanCreationException bce = (BeanCreationException) rootCause;\n\t\t\t\tString bceBeanName = bce.getBeanName();\n\t\t\t\tif (bceBeanName != null && beanFactory.isCurrentlyInCreation(bceBeanName)) {\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Failed to create target bean '\" + bce.getBeanName() +\n\t\t\t\t\t\t\t\t\"' while configuring object of type [\" + beanInstance.getClass().getName() +\n\t\t\t\t\t\t\t\t\"] - probably due to a circular reference. This is a common startup situation \" +\n\t\t\t\t\t\t\t\t\"and usually not fatal. Proceeding without injection. Original exception: \" + ex);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t}", "summary_tokens": ["configure", "the", "bean", "instance"], "project": "spring-framework"}
{"id": 7481, "code": "\tpublic void setForceResponseEncoding(boolean forceResponseEncoding) {\n\t\tthis.forceResponseEncoding = forceResponseEncoding;\n\t}", "summary_tokens": ["set", "whether", "the", "configured", "set", "encoding", "encoding", "of", "this", "filter", "is", "supposed", "to", "override", "existing", "response", "encodings"], "project": "spring-framework"}
{"id": 7113, "code": "\tpublic <T extends ContentNegotiationStrategy> T getStrategy(Class<T> strategyType) {\n\t\tfor (ContentNegotiationStrategy strategy : getStrategies()) {\n\t\t\tif (strategyType.isInstance(strategy)) {\n\t\t\t\treturn (T) strategy;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["find", "a", "content", "negotiation", "strategy", "of", "the", "given", "type"], "project": "spring-framework"}
{"id": 241, "code": "\tpublic String getTargetBeanName() {\n\t\treturn this.targetBeanName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "target", "bean", "in", "the", "factory"], "project": "spring-framework"}
{"id": 3257, "code": "\tpublic synchronized void resize(int targetCapacity) {\n\t\tAssert.isTrue(targetCapacity >= this.count, \"New capacity must not be smaller than current size\");\n\t\tbyte[] resizedBuffer = new byte[targetCapacity];\n\t\tSystem.arraycopy(this.buf, 0, resizedBuffer, 0, this.count);\n\t\tthis.buf = resizedBuffer;\n\t}", "summary_tokens": ["resize", "the", "internal", "buffer", "size", "to", "a", "specified", "capacity"], "project": "spring-framework"}
{"id": 3534, "code": "\tpublic SpelMessage getMessageCode() {\n\t\treturn this.message;\n\t}", "summary_tokens": ["return", "the", "message", "code"], "project": "spring-framework"}
{"id": 976, "code": "\tprotected boolean allowPublicMethodsOnly() {\n\t\treturn false;\n\t}", "summary_tokens": ["should", "only", "public", "methods", "be", "allowed", "to", "have", "caching", "semantics", "p", "the", "default", "implementation", "returns", "false"], "project": "spring-framework"}
{"id": 9895, "code": "\tpublic void setTaskExecutor(TaskExecutor taskExecutor) {\n\t\tAssert.notNull(taskExecutor, \"TaskExecutor must not be null\");\n\t\tthis.taskExecutor = taskExecutor;\n\t}", "summary_tokens": ["configure", "the", "task", "executor", "to", "use", "to", "execute", "xhr", "receive", "requests"], "project": "spring-framework"}
{"id": 6680, "code": "\tpublic long getIfUnmodifiedSince() {\n\t\treturn getFirstDate(IF_UNMODIFIED_SINCE, false);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "if", "unmodified", "since", "header"], "project": "spring-framework"}
{"id": 9902, "code": "\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}", "summary_tokens": ["set", "a", "unique", "name", "for", "this", "service", "mainly", "for", "logging", "purposes"], "project": "spring-framework"}
{"id": 6797, "code": "\tpublic void setRequestFactory(ClientHttpRequestFactory requestFactory) {\n\t\tAssert.notNull(requestFactory, \"ClientHttpRequestFactory must not be null\");\n\t\tthis.requestFactory = requestFactory;\n\t}", "summary_tokens": ["set", "the", "request", "factory", "that", "this", "accessor", "uses", "for", "obtaining", "client", "request", "handles"], "project": "spring-framework"}
{"id": 2812, "code": "\tprotected T decodeDataBuffer(DataBuffer buffer, ResolvableType elementType,\n\t\t\t@Nullable MimeType mimeType, @Nullable Map<String, Object> hints) {\n\n\t\treturn decode(buffer, elementType, mimeType, hints);\n\t}", "summary_tokens": ["how", "to", "decode", "a", "data", "buffer", "to", "the", "target", "element", "type"], "project": "spring-framework"}
{"id": 9461, "code": "\tprotected Object getItems() {\n\t\treturn this.items;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "items", "attribute"], "project": "spring-framework"}
{"id": 6083, "code": "\tpublic ResultMatcher isConflict() {\n\t\treturn matcher(HttpStatus.CONFLICT);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 5779, "code": "\tpublic void assertString(byte[] content, @Nullable String encoding, String expectedValue) throws Exception {\n\t\tString actual = evaluateXpath(content, encoding, String.class);\n\t\tAssertionErrors.assertEquals(\"XPath \" + this.expression, expectedValue, actual);\n\t}", "summary_tokens": ["apply", "the", "xpath", "expression", "and", "assert", "the", "resulting", "content", "as", "a", "string"], "project": "spring-framework"}
{"id": 6465, "code": "\tprotected boolean useSavepointForNestedTransaction() {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "to", "use", "a", "savepoint", "for", "a", "nested", "transaction"], "project": "spring-framework"}
{"id": 5198, "code": "\tpublic void setSessionFactory(@Nullable SessionFactory sessionFactory) {\n\t\tthis.sessionFactory = sessionFactory;\n\t}", "summary_tokens": ["set", "the", "hibernate", "session", "factory", "that", "should", "be", "used", "to", "create", "hibernate", "sessions"], "project": "spring-framework"}
{"id": 8990, "code": "\tpublic MethodArgumentBuilder withMappingName(String mappingName) {\n\t\treturn fromMappingName(this.baseUrl, mappingName);\n\t}", "summary_tokens": ["an", "alternative", "to", "from", "mapping", "name", "string", "for", "use", "with", "an", "instance", "of", "this", "class", "created", "via", "relative", "to"], "project": "spring-framework"}
{"id": 3174, "code": "\tpublic static <K, V> HashMap<K, V> newHashMap(int expectedSize) {\n\t\treturn new HashMap<>((int) (expectedSize / DEFAULT_LOAD_FACTOR), DEFAULT_LOAD_FACTOR);\n\t}", "summary_tokens": ["instantiate", "a", "new", "hash", "map", "with", "an", "initial", "capacity", "that", "can", "accommodate", "the", "specified", "number", "of", "elements", "without", "any", "immediate", "resize", "rehash", "operations", "to", "be", "expected"], "project": "spring-framework"}
{"id": 5908, "code": "\tstatic MockServerSpec<?> bindToWebHandler(WebHandler webHandler) {\n\t\treturn new DefaultMockServerSpec(webHandler);\n\t}", "summary_tokens": ["integration", "testing", "with", "a", "mock", "server", "targeting", "the", "given", "web", "handler"], "project": "spring-framework"}
{"id": 5553, "code": "\tpublic void beforeTestMethod(TestContext testContext) {\n\t\ttestContext.publishEvent(BeforeTestMethodEvent::new);\n\t}", "summary_tokens": ["publish", "a", "before", "test", "method", "event", "to", "the", "application", "context", "for", "the", "supplied", "test", "context"], "project": "spring-framework"}
{"id": 5019, "code": "\tpublic String getMessageId() {\n\t\treturn getFirst(MESSAGE_ID);\n\t}", "summary_tokens": ["get", "the", "message", "id", "header"], "project": "spring-framework"}
{"id": 2604, "code": "public int getTypeParameterBoundIndex() {\n  return (targetTypeAndInfo & 0x0000FF00) >> 8;\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "type", "parameter", "bound", "within", "the", "type", "parameter", "get", "type", "parameter", "index", "referenced", "by", "this", "type", "reference"], "project": "spring-framework"}
{"id": 8710, "code": "\tprotected final void addDefaultHandlerExceptionResolvers(List<HandlerExceptionResolver> exceptionResolvers,\n\t\t\tContentNegotiationManager mvcContentNegotiationManager) {\n\n\t\tExceptionHandlerExceptionResolver exceptionHandlerResolver = createExceptionHandlerExceptionResolver();\n\t\texceptionHandlerResolver.setContentNegotiationManager(mvcContentNegotiationManager);\n\t\texceptionHandlerResolver.setMessageConverters(getMessageConverters());\n\t\texceptionHandlerResolver.setCustomArgumentResolvers(getArgumentResolvers());\n\t\texceptionHandlerResolver.setCustomReturnValueHandlers(getReturnValueHandlers());\n\t\tif (jackson2Present) {\n\t\t\texceptionHandlerResolver.setResponseBodyAdvice(\n\t\t\t\t\tCollections.singletonList(new JsonViewResponseBodyAdvice()));\n\t\t}\n\t\tif (this.applicationContext != null) {\n\t\t\texceptionHandlerResolver.setApplicationContext(this.applicationContext);\n\t\t}\n\t\texceptionHandlerResolver.afterPropertiesSet();\n\t\texceptionResolvers.add(exceptionHandlerResolver);\n\n\t\tResponseStatusExceptionResolver responseStatusResolver = new ResponseStatusExceptionResolver();\n\t\tresponseStatusResolver.setMessageSource(this.applicationContext);\n\t\texceptionResolvers.add(responseStatusResolver);\n\n\t\texceptionResolvers.add(new DefaultHandlerExceptionResolver());\n\t}", "summary_tokens": ["a", "method", "available", "to", "subclasses", "for", "adding", "default", "handler", "exception", "resolver", "handler", "exception", "resolvers"], "project": "spring-framework"}
{"id": 9134, "code": "\tpublic UrlPathHelper getUrlPathHelper() {\n\t\treturn this.urlPathHelper;\n\t}", "summary_tokens": ["return", "the", "url", "path", "helper", "used", "for", "context", "path", "and", "request", "uri", "decoding"], "project": "spring-framework"}
{"id": 7660, "code": "\tpublic Set<HttpMethod> getSupportedMethods() {\n\t\treturn this.httpMethods;\n\t}", "summary_tokens": ["return", "the", "list", "of", "supported", "http", "methods"], "project": "spring-framework"}
{"id": 4317, "code": "\tprotected void initDefaultStrategies() {\n\t\tsetMessageConverter(new SimpleMessageConverter());\n\t}", "summary_tokens": ["initialize", "the", "default", "implementations", "for", "the", "template", "s", "strategies", "dynamic", "destination", "resolver", "and", "simple", "message", "converter"], "project": "spring-framework"}
{"id": 9349, "code": "\tpublic void setName(String name) {\n\t\tthis.name = name;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "name", "attribute"], "project": "spring-framework"}
{"id": 6947, "code": "\tpublic Gson getGson() {\n\t\treturn this.gson;\n\t}", "summary_tokens": ["return", "the", "configured", "gson", "instance", "for", "this", "converter"], "project": "spring-framework"}
{"id": 385, "code": "\tdefault boolean isSingleton() {\n\t\treturn true;\n\t}", "summary_tokens": ["is", "the", "object", "managed", "by", "this", "factory", "a", "singleton", "that", "is", "will", "get", "object", "always", "return", "the", "same", "object", "a", "reference", "that", "can", "be", "cached", "p", "b", "note", "b", "if", "a", "factory", "bean", "indicates", "to", "hold", "a", "singleton", "object", "the", "object", "returned", "from", "get", "object", "might", "get", "cached", "by", "the", "owning", "bean", "factory"], "project": "spring-framework"}
{"id": 3982, "code": "\tprotected Boolean getAutoCommitValue() {\n\t\treturn this.autoCommit;\n\t}", "summary_tokens": ["return", "whether", "the", "returned", "connection", "s", "auto", "commit", "setting", "should", "be", "overridden"], "project": "spring-framework"}
{"id": 8808, "code": "\tpublic ModelAndView resolveException(\n\t\t\tHttpServletRequest request, HttpServletResponse response, @Nullable Object handler, Exception ex) {\n\n\t\tif (this.resolvers != null) {\n\t\t\tfor (HandlerExceptionResolver handlerExceptionResolver : this.resolvers) {\n\t\t\t\tModelAndView mav = handlerExceptionResolver.resolveException(request, response, handler, ex);\n\t\t\t\tif (mav != null) {\n\t\t\t\t\treturn mav;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["resolve", "the", "exception", "by", "iterating", "over", "the", "list", "of", "configured", "exception", "resolvers"], "project": "spring-framework"}
{"id": 2890, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "this", "property", "source"], "project": "spring-framework"}
{"id": 4845, "code": "\tpublic void setDefaultDestinationPrefix(String defaultDestinationPrefix) {\n\t\tthis.defaultDestinationPrefix = defaultDestinationPrefix;\n\t}", "summary_tokens": ["configure", "a", "default", "prefix", "to", "add", "to", "message", "destinations", "in", "cases", "where", "a", "method", "is", "not", "annotated", "with", "send", "to", "or", "does", "not", "specify", "any", "destinations", "through", "the", "annotation", "s", "value", "attribute"], "project": "spring-framework"}
{"id": 8742, "code": "\tdefault RequestPredicate and(RequestPredicate other) {\n\t\treturn new RequestPredicates.AndRequestPredicate(this, other);\n\t}", "summary_tokens": ["return", "a", "composed", "request", "predicate", "that", "tests", "against", "both", "this", "predicate", "and", "the", "other", "predicate"], "project": "spring-framework"}
{"id": 4072, "code": "\tpublic void setResultSetType(int resultSetType) {\n\t\tthis.resultSetType = resultSetType;\n\t}", "summary_tokens": ["set", "whether", "to", "use", "statements", "that", "return", "a", "specific", "type", "of", "result", "set"], "project": "spring-framework"}
{"id": 1325, "code": "\tpublic boolean canRead(EvaluationContext context, @Nullable Object target, String name) throws AccessException {\n\t\treturn true;\n\t}", "summary_tokens": ["can", "read", "any", "environment", "thus", "always", "returns", "true"], "project": "spring-framework"}
{"id": 6898, "code": "\tprotected void initReaders() {\n\t\tinitTypedReaders();\n\t\tinitObjectReaders();\n\t}", "summary_tokens": ["reset", "and", "initialize", "typed", "readers", "and", "object", "readers"], "project": "spring-framework"}
{"id": 5935, "code": "\tpublic WebClient build() {\n\t\treturn (this.webClient != null ? this.webClient : withDelegate(new WebClient()).build());\n\t}", "summary_tokens": ["build", "the", "web", "client", "configured", "via", "this", "builder"], "project": "spring-framework"}
{"id": 5614, "code": "\tprotected boolean isTestMethodIgnored(FrameworkMethod frameworkMethod) {\n\t\tMethod method = frameworkMethod.getMethod();\n\t\treturn (method.isAnnotationPresent(Ignore.class) ||\n\t\t\t\t!ProfileValueUtils.isTestEnabledInThisEnvironment(method, getTestClass().getJavaClass()));\n\t}", "summary_tokens": ["return", "true", "if", "ignore", "is", "present", "for", "the", "supplied", "framework", "method", "test", "method", "or", "if", "the", "test", "method", "is", "disabled", "via"], "project": "spring-framework"}
{"id": 362, "code": "\tdefault Spliterator<PropertyValue> spliterator() {\n\t\treturn Spliterators.spliterator(getPropertyValues(), 0);\n\t}", "summary_tokens": ["return", "a", "spliterator", "over", "the", "property", "values"], "project": "spring-framework"}
{"id": 1019, "code": "\tpublic Properties getJavaMailProperties() {\n\t\treturn this.javaMailProperties;\n\t}", "summary_tokens": ["allow", "code", "map", "access", "to", "the", "java", "mail", "properties", "of", "this", "sender", "with", "the", "option", "to", "add", "or", "override", "specific", "entries"], "project": "spring-framework"}
{"id": 7371, "code": "\tpublic String getMethod() {\n\t\treturn this.method;\n\t}", "summary_tokens": ["return", "the", "http", "method", "of", "the", "request", "usually", "get", "or", "post"], "project": "spring-framework"}
{"id": 4854, "code": "\tpublic void setConversionService(ConversionService conversionService) {\n\t\tthis.conversionService = conversionService;\n\t}", "summary_tokens": ["configure", "a", "conversion", "service", "to", "use", "when", "resolving", "method", "arguments", "for", "example", "message", "header", "values"], "project": "spring-framework"}
{"id": 3807, "code": "\tpublic int getCacheLimit() {\n\t\treturn this.parsedSqlCache.capacity();\n\t}", "summary_tokens": ["return", "the", "maximum", "number", "of", "entries", "for", "this", "template", "s", "sql", "cache"], "project": "spring-framework"}
{"id": 4969, "code": "\tpublic TaskScheduler getTaskScheduler() {\n\t\treturn this.taskScheduler;\n\t}", "summary_tokens": ["the", "configured", "task", "scheduler"], "project": "spring-framework"}
{"id": 5771, "code": "\tpublic void assertSource(String content, Matcher<? super Source> matcher) throws Exception {\n\t\tDocument document = parseXmlString(content);\n\t\tassertThat(\"Body content\", new DOMSource(document), matcher);\n\t}", "summary_tokens": ["parse", "the", "content", "as", "domsource", "and", "apply", "a", "matcher"], "project": "spring-framework"}
{"id": 5512, "code": "\tdefault boolean hasApplicationContext() {\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "if", "the", "application", "context", "application", "context", "for", "this", "test", "context", "is", "known", "to", "be", "available"], "project": "spring-framework"}
{"id": 2346, "code": "protected Label readLabel(final int bytecodeOffset, final Label[] labels) {\n    \n  if (bytecodeOffset >= labels.length) {\n    return new Label();\n  }\n    \n  if (labels[bytecodeOffset] == null) {\n    labels[bytecodeOffset] = new Label();\n  }\n  return labels[bytecodeOffset];\n}", "summary_tokens": ["returns", "the", "label", "corresponding", "to", "the", "given", "bytecode", "offset"], "project": "spring-framework"}
{"id": 9195, "code": "\tpublic void setJavaScriptEscape(boolean javaScriptEscape) throws JspException {\n\t\tthis.javaScriptEscape = javaScriptEscape;\n\t}", "summary_tokens": ["set", "java", "script", "escaping", "for", "this", "tag", "as", "boolean", "value"], "project": "spring-framework"}
{"id": 5245, "code": "\tpublic void setDataSourceLookup(@Nullable DataSourceLookup dataSourceLookup) {\n\t\tthis.dataSourceLookup = (dataSourceLookup != null ? dataSourceLookup : new JndiDataSourceLookup());\n\t}", "summary_tokens": ["specify", "the", "jdbc", "data", "source", "lookup", "that", "provides", "data", "sources", "for", "the", "persistence", "provider", "resolving", "data", "source", "names", "in", "persistence"], "project": "spring-framework"}
{"id": 154, "code": "\tpublic void setAdvisorBeanNamePrefix(@Nullable String advisorBeanNamePrefix) {\n\t\tthis.advisorBeanNamePrefix = advisorBeanNamePrefix;\n\t}", "summary_tokens": ["set", "the", "prefix", "for", "bean", "names", "that", "will", "cause", "them", "to", "be", "included", "for", "auto", "proxying", "by", "this", "object"], "project": "spring-framework"}
{"id": 5936, "code": "\tstatic void validateContextPath(@Nullable String contextPath) {\n\t\tif (contextPath == null || contextPath.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\t\tAssert.isTrue(contextPath.startsWith(\"/\"), () -> \"contextPath '\" + contextPath + \"' must start with '/'.\");\n\t\tAssert.isTrue(!contextPath.endsWith(\"/\"), () -> \"contextPath '\" + contextPath + \"' must not end with '/'.\");\n\t}", "summary_tokens": ["validate", "the", "supplied", "context", "path"], "project": "spring-framework"}
{"id": 2269, "code": "\tpublic String getBaseName() {\n\t\treturn this.baseName;\n\t}", "summary_tokens": ["return", "the", "base", "name", "of", "the", "resource", "bundle"], "project": "spring-framework"}
{"id": 1052, "code": "\tpublic void setJobDataAsMap(Map<String, ?> jobDataAsMap) {\n\t\tthis.jobDataMap.putAll(jobDataAsMap);\n\t}", "summary_tokens": ["register", "objects", "in", "the", "job", "data", "map", "via", "a", "given", "map"], "project": "spring-framework"}
{"id": 1242, "code": "\tprotected String getAdviceModeAttributeName() {\n\t\treturn DEFAULT_ADVICE_MODE_ATTRIBUTE_NAME;\n\t}", "summary_tokens": ["the", "name", "of", "the", "advice", "mode", "attribute", "for", "the", "annotation", "specified", "by", "the", "generic", "type", "a"], "project": "spring-framework"}
{"id": 3302, "code": "\tpublic static boolean containsWhitespace(@Nullable String str) {\n\t\treturn containsWhitespace((CharSequence) str);\n\t}", "summary_tokens": ["check", "whether", "the", "given", "string", "contains", "any", "whitespace", "characters"], "project": "spring-framework"}
{"id": 9250, "code": "\tprotected boolean isValidDynamicAttribute(String localName, Object value) {\n\t\treturn !\"type\".equals(localName);\n\t}", "summary_tokens": ["flags", "type", "as", "an", "illegal", "dynamic", "attribute"], "project": "spring-framework"}
{"id": 2660, "code": "\tpublic static boolean isEnhanced(Class type) {\n\t\ttry {\n\t\t\tgetCallbacksSetter(type, SET_THREAD_CALLBACKS_NAME);\n\t\t\treturn true;\n\t\t}\n\t\tcatch (NoSuchMethodException e) {\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["determine", "if", "a", "class", "was", "generated", "using", "code", "enhancer", "code"], "project": "spring-framework"}
{"id": 6138, "code": "\tpublic static final void assertContextCacheStatistics(ContextCache contextCache, String usageScenario,\n\t\t\tint expectedSize, int expectedHitCount, int expectedMissCount) {\n\n\t\tassertThat(contextCache.size()).as(\"Verifying number of contexts in cache (\" + usageScenario + \").\").isEqualTo(expectedSize);\n\t\tassertThat(contextCache.getHitCount()).as(\"Verifying number of cache hits (\" + usageScenario + \").\").isEqualTo(expectedHitCount);\n\t\tassertThat(contextCache.getMissCount()).as(\"Verifying number of cache misses (\" + usageScenario + \").\").isEqualTo(expectedMissCount);\n\t}", "summary_tokens": ["assert", "the", "statistics", "of", "the", "supplied", "context", "cache"], "project": "spring-framework"}
{"id": 2513, "code": "public void visitExport(final String packaze, final int access, final String... modules) {\n  if (mv != null) {\n    mv.visitExport(packaze, access, modules);\n  }\n}", "summary_tokens": ["visit", "an", "exported", "package", "of", "the", "current", "module"], "project": "spring-framework"}
{"id": 2345, "code": "private void readCode(\n    final MethodVisitor methodVisitor, final Context context, final int codeOffset) {\n  int currentOffset = codeOffset;\n\n    \n  final byte[] classBuffer = classFileBuffer;\n  final char[] charBuffer = context.charBuffer;\n  final int maxStack = readUnsignedShort(currentOffset);\n  final int maxLocals = readUnsignedShort(currentOffset + 2);\n  final int codeLength = readInt(currentOffset + 4);\n  currentOffset += 8;\n  if (codeLength > classFileBuffer.length - currentOffset) {\n    throw new IllegalArgumentException();\n  }\n\n    \n  final int bytecodeStartOffset = currentOffset;\n  final int bytecodeEndOffset = currentOffset + codeLength;\n  final Label[] labels = context.currentMethodLabels = new Label[codeLength + 1];\n  while (currentOffset < bytecodeEndOffset) {\n    final int bytecodeOffset = currentOffset - bytecodeStartOffset;\n    final int opcode = classBuffer[currentOffset] & 0xFF;\n    switch (opcode) {\n      case Opcodes.NOP:\n      case Opcodes.ACONST_NULL:\n      case Opcodes.ICONST_M1:\n      case Opcodes.ICONST_0:\n      case Opcodes.ICONST_1:\n      case Opcodes.ICONST_2:\n      case Opcodes.ICONST_3:\n      case Opcodes.ICONST_4:\n      case Opcodes.ICONST_5:\n      case Opcodes.LCONST_0:\n      case Opcodes.LCONST_1:\n      case Opcodes.FCONST_0:\n      case Opcodes.FCONST_1:\n      case Opcodes.FCONST_2:\n      case Opcodes.DCONST_0:\n      case Opcodes.DCONST_1:\n      case Opcodes.IALOAD:\n      case Opcodes.LALOAD:\n      case Opcodes.FALOAD:\n      case Opcodes.DALOAD:\n      case Opcodes.AALOAD:\n      case Opcodes.BALOAD:\n      case Opcodes.CALOAD:\n      case Opcodes.SALOAD:\n      case Opcodes.IASTORE:\n      case Opcodes.LASTORE:\n      case Opcodes.FASTORE:\n      case Opcodes.DASTORE:\n      case Opcodes.AASTORE:\n      case Opcodes.BASTORE:\n      case Opcodes.CASTORE:\n      case Opcodes.SASTORE:\n      case Opcodes.POP:\n      case Opcodes.POP2:\n      case Opcodes.DUP:\n      case Opcodes.DUP_X1:\n      case Opcodes.DUP_X2:\n      case Opcodes.DUP2:\n      case Opcodes.DUP2_X1:\n      case Opcodes.DUP2_X2:\n      case Opcodes.SWAP:\n      case Opcodes.IADD:\n      case Opcodes.LADD:\n      case Opcodes.FADD:\n      case Opcodes.DADD:\n      case Opcodes.ISUB:\n      case Opcodes.LSUB:\n      case Opcodes.FSUB:\n      case Opcodes.DSUB:\n      case Opcodes.IMUL:\n      case Opcodes.LMUL:\n      case Opcodes.FMUL:\n      case Opcodes.DMUL:\n      case Opcodes.IDIV:\n      case Opcodes.LDIV:\n      case Opcodes.FDIV:\n      case Opcodes.DDIV:\n      case Opcodes.IREM:\n      case Opcodes.LREM:\n      case Opcodes.FREM:\n      case Opcodes.DREM:\n      case Opcodes.INEG:\n      case Opcodes.LNEG:\n      case Opcodes.FNEG:\n      case Opcodes.DNEG:\n      case Opcodes.ISHL:\n      case Opcodes.LSHL:\n      case Opcodes.ISHR:\n      case Opcodes.LSHR:\n      case Opcodes.IUSHR:\n      case Opcodes.LUSHR:\n      case Opcodes.IAND:\n      case Opcodes.LAND:\n      case Opcodes.IOR:\n      case Opcodes.LOR:\n      case Opcodes.IXOR:\n      case Opcodes.LXOR:\n      case Opcodes.I2L:\n      case Opcodes.I2F:\n      case Opcodes.I2D:\n      case Opcodes.L2I:\n      case Opcodes.L2F:\n      case Opcodes.L2D:\n      case Opcodes.F2I:\n      case Opcodes.F2L:\n      case Opcodes.F2D:\n      case Opcodes.D2I:\n      case Opcodes.D2L:\n      case Opcodes.D2F:\n      case Opcodes.I2B:\n      case Opcodes.I2C:\n      case Opcodes.I2S:\n      case Opcodes.LCMP:\n      case Opcodes.FCMPL:\n      case Opcodes.FCMPG:\n      case Opcodes.DCMPL:\n      case Opcodes.DCMPG:\n      case Opcodes.IRETURN:\n      case Opcodes.LRETURN:\n      case Opcodes.FRETURN:\n      case Opcodes.DRETURN:\n      case Opcodes.ARETURN:\n      case Opcodes.RETURN:\n      case Opcodes.ARRAYLENGTH:\n      case Opcodes.ATHROW:\n      case Opcodes.MONITORENTER:\n      case Opcodes.MONITOREXIT:\n      case Constants.ILOAD_0:\n      case Constants.ILOAD_1:\n      case Constants.ILOAD_2:\n      case Constants.ILOAD_3:\n      case Constants.LLOAD_0:\n      case Constants.LLOAD_1:\n      case Constants.LLOAD_2:\n      case Constants.LLOAD_3:\n      case Constants.FLOAD_0:\n      case Constants.FLOAD_1:\n      case Constants.FLOAD_2:\n      case Constants.FLOAD_3:\n      case Constants.DLOAD_0:\n      case Constants.DLOAD_1:\n      case Constants.DLOAD_2:\n      case Constants.DLOAD_3:\n      case Constants.ALOAD_0:\n      case Constants.ALOAD_1:\n      case Constants.ALOAD_2:\n      case Constants.ALOAD_3:\n      case Constants.ISTORE_0:\n      case Constants.ISTORE_1:\n      case Constants.ISTORE_2:\n      case Constants.ISTORE_3:\n      case Constants.LSTORE_0:\n      case Constants.LSTORE_1:\n      case Constants.LSTORE_2:\n      case Constants.LSTORE_3:\n      case Constants.FSTORE_0:\n      case Constants.FSTORE_1:\n      case Constants.FSTORE_2:\n      case Constants.FSTORE_3:\n      case Constants.DSTORE_0:\n      case Constants.DSTORE_1:\n      case Constants.DSTORE_2:\n      case Constants.DSTORE_3:\n      case Constants.ASTORE_0:\n      case Constants.ASTORE_1:\n      case Constants.ASTORE_2:\n      case Constants.ASTORE_3:\n        currentOffset += 1;\n        break;\n      case Opcodes.IFEQ:\n      case Opcodes.IFNE:\n      case Opcodes.IFLT:\n      case Opcodes.IFGE:\n      case Opcodes.IFGT:\n      case Opcodes.IFLE:\n      case Opcodes.IF_ICMPEQ:\n      case Opcodes.IF_ICMPNE:\n      case Opcodes.IF_ICMPLT:\n      case Opcodes.IF_ICMPGE:\n      case Opcodes.IF_ICMPGT:\n      case Opcodes.IF_ICMPLE:\n      case Opcodes.IF_ACMPEQ:\n      case Opcodes.IF_ACMPNE:\n      case Opcodes.GOTO:\n      case Opcodes.JSR:\n      case Opcodes.IFNULL:\n      case Opcodes.IFNONNULL:\n        createLabel(bytecodeOffset + readShort(currentOffset + 1), labels);\n        currentOffset += 3;\n        break;\n      case Constants.ASM_IFEQ:\n      case Constants.ASM_IFNE:\n      case Constants.ASM_IFLT:\n      case Constants.ASM_IFGE:\n      case Constants.ASM_IFGT:\n      case Constants.ASM_IFLE:\n      case Constants.ASM_IF_ICMPEQ:\n      case Constants.ASM_IF_ICMPNE:\n      case Constants.ASM_IF_ICMPLT:\n      case Constants.ASM_IF_ICMPGE:\n      case Constants.ASM_IF_ICMPGT:\n      case Constants.ASM_IF_ICMPLE:\n      case Constants.ASM_IF_ACMPEQ:\n      case Constants.ASM_IF_ACMPNE:\n      case Constants.ASM_GOTO:\n      case Constants.ASM_JSR:\n      case Constants.ASM_IFNULL:\n      case Constants.ASM_IFNONNULL:\n        createLabel(bytecodeOffset + readUnsignedShort(currentOffset + 1), labels);\n        currentOffset += 3;\n        break;\n      case Constants.GOTO_W:\n      case Constants.JSR_W:\n      case Constants.ASM_GOTO_W:\n        createLabel(bytecodeOffset + readInt(currentOffset + 1), labels);\n        currentOffset += 5;\n        break;\n      case Constants.WIDE:\n        switch (classBuffer[currentOffset + 1] & 0xFF) {\n          case Opcodes.ILOAD:\n          case Opcodes.FLOAD:\n          case Opcodes.ALOAD:\n          case Opcodes.LLOAD:\n          case Opcodes.DLOAD:\n          case Opcodes.ISTORE:\n          case Opcodes.FSTORE:\n          case Opcodes.ASTORE:\n          case Opcodes.LSTORE:\n          case Opcodes.DSTORE:\n          case Opcodes.RET:\n            currentOffset += 4;\n            break;\n          case Opcodes.IINC:\n            currentOffset += 6;\n            break;\n          default:\n            throw new IllegalArgumentException();\n        }\n        break;\n      case Opcodes.TABLESWITCH:\n          \n        currentOffset += 4 - (bytecodeOffset & 3);\n          \n        createLabel(bytecodeOffset + readInt(currentOffset), labels);\n        int numTableEntries = readInt(currentOffset + 8) - readInt(currentOffset + 4) + 1;\n        currentOffset += 12;\n          \n        while (numTableEntries-- > 0) {\n          createLabel(bytecodeOffset + readInt(currentOffset), labels);\n          currentOffset += 4;\n        }\n        break;\n      case Opcodes.LOOKUPSWITCH:\n          \n        currentOffset += 4 - (bytecodeOffset & 3);\n          \n        createLabel(bytecodeOffset + readInt(currentOffset), labels);\n        int numSwitchCases = readInt(currentOffset + 4);\n        currentOffset += 8;\n          \n        while (numSwitchCases-- > 0) {\n          createLabel(bytecodeOffset + readInt(currentOffset + 4), labels);\n          currentOffset += 8;\n        }\n        break;\n      case Opcodes.ILOAD:\n      case Opcodes.LLOAD:\n      case Opcodes.FLOAD:\n      case Opcodes.DLOAD:\n      case Opcodes.ALOAD:\n      case Opcodes.ISTORE:\n      case Opcodes.LSTORE:\n      case Opcodes.FSTORE:\n      case Opcodes.DSTORE:\n      case Opcodes.ASTORE:\n      case Opcodes.RET:\n      case Opcodes.BIPUSH:\n      case Opcodes.NEWARRAY:\n      case Opcodes.LDC:\n        currentOffset += 2;\n        break;\n      case Opcodes.SIPUSH:\n      case Constants.LDC_W:\n      case Constants.LDC2_W:\n      case Opcodes.GETSTATIC:\n      case Opcodes.PUTSTATIC:\n      case Opcodes.GETFIELD:\n      case Opcodes.PUTFIELD:\n      case Opcodes.INVOKEVIRTUAL:\n      case Opcodes.INVOKESPECIAL:\n      case Opcodes.INVOKESTATIC:\n      case Opcodes.NEW:\n      case Opcodes.ANEWARRAY:\n      case Opcodes.CHECKCAST:\n      case Opcodes.INSTANCEOF:\n      case Opcodes.IINC:\n        currentOffset += 3;\n        break;\n      case Opcodes.INVOKEINTERFACE:\n      case Opcodes.INVOKEDYNAMIC:\n        currentOffset += 5;\n        break;\n      case Opcodes.MULTIANEWARRAY:\n        currentOffset += 4;\n        break;\n      default:\n        throw new IllegalArgumentException();\n    }\n  }\n\n    \n    \n  int exceptionTableLength = readUnsignedShort(currentOffset);\n  currentOffset += 2;\n  while (exceptionTableLength-- > 0) {\n    Label start = createLabel(readUnsignedShort(currentOffset), labels);\n    Label end = createLabel(readUnsignedShort(currentOffset + 2), labels);\n    Label handler = createLabel(readUnsignedShort(currentOffset + 4), labels);\n    String catchType = readUTF8(cpInfoOffsets[readUnsignedShort(currentOffset + 6)], charBuffer);\n    currentOffset += 8;\n    methodVisitor.visitTryCatchBlock(start, end, handler, catchType);\n  }\n\n    \n    \n    \n    \n    \n    \n  int stackMapFrameOffset = 0;\n    \n  int stackMapTableEndOffset = 0;\n    \n  boolean compressedFrames = true;\n    \n  int localVariableTableOffset = 0;\n    \n  int localVariableTypeTableOffset = 0;\n    \n    \n  int[] visibleTypeAnnotationOffsets = null;\n    \n    \n  int[] invisibleTypeAnnotationOffsets = null;\n    \n    \n  Attribute attributes = null;\n\n  int attributesCount = readUnsignedShort(currentOffset);\n  currentOffset += 2;\n  while (attributesCount-- > 0) {\n      \n    String attributeName = readUTF8(currentOffset, charBuffer);\n    int attributeLength = readInt(currentOffset + 2);\n    currentOffset += 6;\n    if (Constants.LOCAL_VARIABLE_TABLE.equals(attributeName)) {\n      if ((context.parsingOptions & SKIP_DEBUG) == 0) {\n        localVariableTableOffset = currentOffset;\n          \n        int currentLocalVariableTableOffset = currentOffset;\n        int localVariableTableLength = readUnsignedShort(currentLocalVariableTableOffset);\n        currentLocalVariableTableOffset += 2;\n        while (localVariableTableLength-- > 0) {\n          int startPc = readUnsignedShort(currentLocalVariableTableOffset);\n          createDebugLabel(startPc, labels);\n          int length = readUnsignedShort(currentLocalVariableTableOffset + 2);\n          createDebugLabel(startPc + length, labels);\n            \n          currentLocalVariableTableOffset += 10;\n        }\n      }\n    } else if (Constants.LOCAL_VARIABLE_TYPE_TABLE.equals(attributeName)) {\n      localVariableTypeTableOffset = currentOffset;\n        \n        \n    } else if (Constants.LINE_NUMBER_TABLE.equals(attributeName)) {\n      if ((context.parsingOptions & SKIP_DEBUG) == 0) {\n          \n        int currentLineNumberTableOffset = currentOffset;\n        int lineNumberTableLength = readUnsignedShort(currentLineNumberTableOffset);\n        currentLineNumberTableOffset += 2;\n        while (lineNumberTableLength-- > 0) {\n          int startPc = readUnsignedShort(currentLineNumberTableOffset);\n          int lineNumber = readUnsignedShort(currentLineNumberTableOffset + 2);\n          currentLineNumberTableOffset += 4;\n          createDebugLabel(startPc, labels);\n          labels[startPc].addLineNumber(lineNumber);\n        }\n      }\n    } else if (Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      visibleTypeAnnotationOffsets =\n          readTypeAnnotations(methodVisitor, context, currentOffset,  true);\n        \n        \n        \n        \n        \n        \n    } else if (Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      invisibleTypeAnnotationOffsets =\n          readTypeAnnotations(methodVisitor, context, currentOffset,  false);\n        \n    } else if (Constants.STACK_MAP_TABLE.equals(attributeName)) {\n      if ((context.parsingOptions & SKIP_FRAMES) == 0) {\n        stackMapFrameOffset = currentOffset + 2;\n        stackMapTableEndOffset = currentOffset + attributeLength;\n      }\n        \n        \n        \n        \n        \n        \n        \n        \n        \n    } else if (\"StackMap\".equals(attributeName)) {\n      if ((context.parsingOptions & SKIP_FRAMES) == 0) {\n        stackMapFrameOffset = currentOffset + 2;\n        stackMapTableEndOffset = currentOffset + attributeLength;\n        compressedFrames = false;\n      }\n        \n        \n        \n        \n    } else {\n      Attribute attribute =\n          readAttribute(\n              context.attributePrototypes,\n              attributeName,\n              currentOffset,\n              attributeLength,\n              charBuffer,\n              codeOffset,\n              labels);\n      attribute.nextAttribute = attributes;\n      attributes = attribute;\n    }\n    currentOffset += attributeLength;\n  }\n\n    \n    \n  final boolean expandFrames = (context.parsingOptions & EXPAND_FRAMES) != 0;\n  if (stackMapFrameOffset != 0) {\n      \n      \n      \n    context.currentFrameOffset = -1;\n    context.currentFrameType = 0;\n    context.currentFrameLocalCount = 0;\n    context.currentFrameLocalCountDelta = 0;\n    context.currentFrameLocalTypes = new Object[maxLocals];\n    context.currentFrameStackCount = 0;\n    context.currentFrameStackTypes = new Object[maxStack];\n    if (expandFrames) {\n      computeImplicitFrame(context);\n    }\n      \n      \n      \n      \n      \n      \n      \n    for (int offset = stackMapFrameOffset; offset < stackMapTableEndOffset - 2; ++offset) {\n      if (classBuffer[offset] == Frame.ITEM_UNINITIALIZED) {\n        int potentialBytecodeOffset = readUnsignedShort(offset + 1);\n        if (potentialBytecodeOffset >= 0\n            && potentialBytecodeOffset < codeLength\n            && (classBuffer[bytecodeStartOffset + potentialBytecodeOffset] & 0xFF)\n                == Opcodes.NEW) {\n          createLabel(potentialBytecodeOffset, labels);\n        }\n      }\n    }\n  }\n  if (expandFrames && (context.parsingOptions & EXPAND_ASM_INSNS) != 0) {\n      \n      \n      \n      \n      \n      \n    methodVisitor.visitFrame(Opcodes.F_NEW, maxLocals, null, 0, null);\n  }\n\n    \n    \n\n    \n    \n  int currentVisibleTypeAnnotationIndex = 0;\n    \n  int currentVisibleTypeAnnotationBytecodeOffset =\n      getTypeAnnotationBytecodeOffset(visibleTypeAnnotationOffsets, 0);\n    \n    \n  int currentInvisibleTypeAnnotationIndex = 0;\n    \n  int currentInvisibleTypeAnnotationBytecodeOffset =\n      getTypeAnnotationBytecodeOffset(invisibleTypeAnnotationOffsets, 0);\n\n    \n  boolean insertFrame = false;\n\n    \n    \n    \n  final int wideJumpOpcodeDelta =\n      (context.parsingOptions & EXPAND_ASM_INSNS) == 0 ? Constants.WIDE_JUMP_OPCODE_DELTA : 0;\n\n  currentOffset = bytecodeStartOffset;\n  while (currentOffset < bytecodeEndOffset) {\n    final int currentBytecodeOffset = currentOffset - bytecodeStartOffset;\n\n      \n    Label currentLabel = labels[currentBytecodeOffset];\n    if (currentLabel != null) {\n      currentLabel.accept(methodVisitor, (context.parsingOptions & SKIP_DEBUG) == 0);\n    }\n\n      \n    while (stackMapFrameOffset != 0\n        && (context.currentFrameOffset == currentBytecodeOffset\n            || context.currentFrameOffset == -1)) {\n        \n        \n      if (context.currentFrameOffset != -1) {\n        if (!compressedFrames || expandFrames) {\n          methodVisitor.visitFrame(\n              Opcodes.F_NEW,\n              context.currentFrameLocalCount,\n              context.currentFrameLocalTypes,\n              context.currentFrameStackCount,\n              context.currentFrameStackTypes);\n        } else {\n          methodVisitor.visitFrame(\n              context.currentFrameType,\n              context.currentFrameLocalCountDelta,\n              context.currentFrameLocalTypes,\n              context.currentFrameStackCount,\n              context.currentFrameStackTypes);\n        }\n          \n          \n        insertFrame = false;\n      }\n      if (stackMapFrameOffset < stackMapTableEndOffset) {\n        stackMapFrameOffset =\n            readStackMapFrame(stackMapFrameOffset, compressedFrames, expandFrames, context);\n      } else {\n        stackMapFrameOffset = 0;\n      }\n    }\n\n      \n      \n    if (insertFrame) {\n      if ((context.parsingOptions & EXPAND_FRAMES) != 0) {\n        methodVisitor.visitFrame(Constants.F_INSERT, 0, null, 0, null);\n      }\n      insertFrame = false;\n    }\n\n      \n    int opcode = classBuffer[currentOffset] & 0xFF;\n    switch (opcode) {\n      case Opcodes.NOP:\n      case Opcodes.ACONST_NULL:\n      case Opcodes.ICONST_M1:\n      case Opcodes.ICONST_0:\n      case Opcodes.ICONST_1:\n      case Opcodes.ICONST_2:\n      case Opcodes.ICONST_3:\n      case Opcodes.ICONST_4:\n      case Opcodes.ICONST_5:\n      case Opcodes.LCONST_0:\n      case Opcodes.LCONST_1:\n      case Opcodes.FCONST_0:\n      case Opcodes.FCONST_1:\n      case Opcodes.FCONST_2:\n      case Opcodes.DCONST_0:\n      case Opcodes.DCONST_1:\n      case Opcodes.IALOAD:\n      case Opcodes.LALOAD:\n      case Opcodes.FALOAD:\n      case Opcodes.DALOAD:\n      case Opcodes.AALOAD:\n      case Opcodes.BALOAD:\n      case Opcodes.CALOAD:\n      case Opcodes.SALOAD:\n      case Opcodes.IASTORE:\n      case Opcodes.LASTORE:\n      case Opcodes.FASTORE:\n      case Opcodes.DASTORE:\n      case Opcodes.AASTORE:\n      case Opcodes.BASTORE:\n      case Opcodes.CASTORE:\n      case Opcodes.SASTORE:\n      case Opcodes.POP:\n      case Opcodes.POP2:\n      case Opcodes.DUP:\n      case Opcodes.DUP_X1:\n      case Opcodes.DUP_X2:\n      case Opcodes.DUP2:\n      case Opcodes.DUP2_X1:\n      case Opcodes.DUP2_X2:\n      case Opcodes.SWAP:\n      case Opcodes.IADD:\n      case Opcodes.LADD:\n      case Opcodes.FADD:\n      case Opcodes.DADD:\n      case Opcodes.ISUB:\n      case Opcodes.LSUB:\n      case Opcodes.FSUB:\n      case Opcodes.DSUB:\n      case Opcodes.IMUL:\n      case Opcodes.LMUL:\n      case Opcodes.FMUL:\n      case Opcodes.DMUL:\n      case Opcodes.IDIV:\n      case Opcodes.LDIV:\n      case Opcodes.FDIV:\n      case Opcodes.DDIV:\n      case Opcodes.IREM:\n      case Opcodes.LREM:\n      case Opcodes.FREM:\n      case Opcodes.DREM:\n      case Opcodes.INEG:\n      case Opcodes.LNEG:\n      case Opcodes.FNEG:\n      case Opcodes.DNEG:\n      case Opcodes.ISHL:\n      case Opcodes.LSHL:\n      case Opcodes.ISHR:\n      case Opcodes.LSHR:\n      case Opcodes.IUSHR:\n      case Opcodes.LUSHR:\n      case Opcodes.IAND:\n      case Opcodes.LAND:\n      case Opcodes.IOR:\n      case Opcodes.LOR:\n      case Opcodes.IXOR:\n      case Opcodes.LXOR:\n      case Opcodes.I2L:\n      case Opcodes.I2F:\n      case Opcodes.I2D:\n      case Opcodes.L2I:\n      case Opcodes.L2F:\n      case Opcodes.L2D:\n      case Opcodes.F2I:\n      case Opcodes.F2L:\n      case Opcodes.F2D:\n      case Opcodes.D2I:\n      case Opcodes.D2L:\n      case Opcodes.D2F:\n      case Opcodes.I2B:\n      case Opcodes.I2C:\n      case Opcodes.I2S:\n      case Opcodes.LCMP:\n      case Opcodes.FCMPL:\n      case Opcodes.FCMPG:\n      case Opcodes.DCMPL:\n      case Opcodes.DCMPG:\n      case Opcodes.IRETURN:\n      case Opcodes.LRETURN:\n      case Opcodes.FRETURN:\n      case Opcodes.DRETURN:\n      case Opcodes.ARETURN:\n      case Opcodes.RETURN:\n      case Opcodes.ARRAYLENGTH:\n      case Opcodes.ATHROW:\n      case Opcodes.MONITORENTER:\n      case Opcodes.MONITOREXIT:\n        methodVisitor.visitInsn(opcode);\n        currentOffset += 1;\n        break;\n      case Constants.ILOAD_0:\n      case Constants.ILOAD_1:\n      case Constants.ILOAD_2:\n      case Constants.ILOAD_3:\n      case Constants.LLOAD_0:\n      case Constants.LLOAD_1:\n      case Constants.LLOAD_2:\n      case Constants.LLOAD_3:\n      case Constants.FLOAD_0:\n      case Constants.FLOAD_1:\n      case Constants.FLOAD_2:\n      case Constants.FLOAD_3:\n      case Constants.DLOAD_0:\n      case Constants.DLOAD_1:\n      case Constants.DLOAD_2:\n      case Constants.DLOAD_3:\n      case Constants.ALOAD_0:\n      case Constants.ALOAD_1:\n      case Constants.ALOAD_2:\n      case Constants.ALOAD_3:\n        opcode -= Constants.ILOAD_0;\n        methodVisitor.visitVarInsn(Opcodes.ILOAD + (opcode >> 2), opcode & 0x3);\n        currentOffset += 1;\n        break;\n      case Constants.ISTORE_0:\n      case Constants.ISTORE_1:\n      case Constants.ISTORE_2:\n      case Constants.ISTORE_3:\n      case Constants.LSTORE_0:\n      case Constants.LSTORE_1:\n      case Constants.LSTORE_2:\n      case Constants.LSTORE_3:\n      case Constants.FSTORE_0:\n      case Constants.FSTORE_1:\n      case Constants.FSTORE_2:\n      case Constants.FSTORE_3:\n      case Constants.DSTORE_0:\n      case Constants.DSTORE_1:\n      case Constants.DSTORE_2:\n      case Constants.DSTORE_3:\n      case Constants.ASTORE_0:\n      case Constants.ASTORE_1:\n      case Constants.ASTORE_2:\n      case Constants.ASTORE_3:\n        opcode -= Constants.ISTORE_0;\n        methodVisitor.visitVarInsn(Opcodes.ISTORE + (opcode >> 2), opcode & 0x3);\n        currentOffset += 1;\n        break;\n      case Opcodes.IFEQ:\n      case Opcodes.IFNE:\n      case Opcodes.IFLT:\n      case Opcodes.IFGE:\n      case Opcodes.IFGT:\n      case Opcodes.IFLE:\n      case Opcodes.IF_ICMPEQ:\n      case Opcodes.IF_ICMPNE:\n      case Opcodes.IF_ICMPLT:\n      case Opcodes.IF_ICMPGE:\n      case Opcodes.IF_ICMPGT:\n      case Opcodes.IF_ICMPLE:\n      case Opcodes.IF_ACMPEQ:\n      case Opcodes.IF_ACMPNE:\n      case Opcodes.GOTO:\n      case Opcodes.JSR:\n      case Opcodes.IFNULL:\n      case Opcodes.IFNONNULL:\n        methodVisitor.visitJumpInsn(\n            opcode, labels[currentBytecodeOffset + readShort(currentOffset + 1)]);\n        currentOffset += 3;\n        break;\n      case Constants.GOTO_W:\n      case Constants.JSR_W:\n        methodVisitor.visitJumpInsn(\n            opcode - wideJumpOpcodeDelta,\n            labels[currentBytecodeOffset + readInt(currentOffset + 1)]);\n        currentOffset += 5;\n        break;\n      case Constants.ASM_IFEQ:\n      case Constants.ASM_IFNE:\n      case Constants.ASM_IFLT:\n      case Constants.ASM_IFGE:\n      case Constants.ASM_IFGT:\n      case Constants.ASM_IFLE:\n      case Constants.ASM_IF_ICMPEQ:\n      case Constants.ASM_IF_ICMPNE:\n      case Constants.ASM_IF_ICMPLT:\n      case Constants.ASM_IF_ICMPGE:\n      case Constants.ASM_IF_ICMPGT:\n      case Constants.ASM_IF_ICMPLE:\n      case Constants.ASM_IF_ACMPEQ:\n      case Constants.ASM_IF_ACMPNE:\n      case Constants.ASM_GOTO:\n      case Constants.ASM_JSR:\n      case Constants.ASM_IFNULL:\n      case Constants.ASM_IFNONNULL:\n        {\n            \n            \n            \n            \n            \n            \n          opcode =\n              opcode < Constants.ASM_IFNULL\n                  ? opcode - Constants.ASM_OPCODE_DELTA\n                  : opcode - Constants.ASM_IFNULL_OPCODE_DELTA;\n          Label target = labels[currentBytecodeOffset + readUnsignedShort(currentOffset + 1)];\n          if (opcode == Opcodes.GOTO || opcode == Opcodes.JSR) {\n              \n            methodVisitor.visitJumpInsn(opcode + Constants.WIDE_JUMP_OPCODE_DELTA, target);\n          } else {\n              \n              \n              \n            opcode = opcode < Opcodes.GOTO ? ((opcode + 1) ^ 1) - 1 : opcode ^ 1;\n            Label endif = createLabel(currentBytecodeOffset + 3, labels);\n            methodVisitor.visitJumpInsn(opcode, endif);\n            methodVisitor.visitJumpInsn(Constants.GOTO_W, target);\n              \n              \n            insertFrame = true;\n          }\n          currentOffset += 3;\n          break;\n        }\n      case Constants.ASM_GOTO_W:\n          \n        methodVisitor.visitJumpInsn(\n            Constants.GOTO_W, labels[currentBytecodeOffset + readInt(currentOffset + 1)]);\n          \n          \n          \n        insertFrame = true;\n        currentOffset += 5;\n        break;\n      case Constants.WIDE:\n        opcode = classBuffer[currentOffset + 1] & 0xFF;\n        if (opcode == Opcodes.IINC) {\n          methodVisitor.visitIincInsn(\n              readUnsignedShort(currentOffset + 2), readShort(currentOffset + 4));\n          currentOffset += 6;\n        } else {\n          methodVisitor.visitVarInsn(opcode, readUnsignedShort(currentOffset + 2));\n          currentOffset += 4;\n        }\n        break;\n      case Opcodes.TABLESWITCH:\n        {\n            \n          currentOffset += 4 - (currentBytecodeOffset & 3);\n            \n          Label defaultLabel = labels[currentBytecodeOffset + readInt(currentOffset)];\n          int low = readInt(currentOffset + 4);\n          int high = readInt(currentOffset + 8);\n          currentOffset += 12;\n          Label[] table = new Label[high - low + 1];\n          for (int i = 0; i < table.length; ++i) {\n            table[i] = labels[currentBytecodeOffset + readInt(currentOffset)];\n            currentOffset += 4;\n          }\n          methodVisitor.visitTableSwitchInsn(low, high, defaultLabel, table);\n          break;\n        }\n      case Opcodes.LOOKUPSWITCH:\n        {\n            \n          currentOffset += 4 - (currentBytecodeOffset & 3);\n            \n          Label defaultLabel = labels[currentBytecodeOffset + readInt(currentOffset)];\n          int numPairs = readInt(currentOffset + 4);\n          currentOffset += 8;\n          int[] keys = new int[numPairs];\n          Label[] values = new Label[numPairs];\n          for (int i = 0; i < numPairs; ++i) {\n            keys[i] = readInt(currentOffset);\n            values[i] = labels[currentBytecodeOffset + readInt(currentOffset + 4)];\n            currentOffset += 8;\n          }\n          methodVisitor.visitLookupSwitchInsn(defaultLabel, keys, values);\n          break;\n        }\n      case Opcodes.ILOAD:\n      case Opcodes.LLOAD:\n      case Opcodes.FLOAD:\n      case Opcodes.DLOAD:\n      case Opcodes.ALOAD:\n      case Opcodes.ISTORE:\n      case Opcodes.LSTORE:\n      case Opcodes.FSTORE:\n      case Opcodes.DSTORE:\n      case Opcodes.ASTORE:\n      case Opcodes.RET:\n        methodVisitor.visitVarInsn(opcode, classBuffer[currentOffset + 1] & 0xFF);\n        currentOffset += 2;\n        break;\n      case Opcodes.BIPUSH:\n      case Opcodes.NEWARRAY:\n        methodVisitor.visitIntInsn(opcode, classBuffer[currentOffset + 1]);\n        currentOffset += 2;\n        break;\n      case Opcodes.SIPUSH:\n        methodVisitor.visitIntInsn(opcode, readShort(currentOffset + 1));\n        currentOffset += 3;\n        break;\n      case Opcodes.LDC:\n        methodVisitor.visitLdcInsn(readConst(classBuffer[currentOffset + 1] & 0xFF, charBuffer));\n        currentOffset += 2;\n        break;\n      case Constants.LDC_W:\n      case Constants.LDC2_W:\n        methodVisitor.visitLdcInsn(readConst(readUnsignedShort(currentOffset + 1), charBuffer));\n        currentOffset += 3;\n        break;\n      case Opcodes.GETSTATIC:\n      case Opcodes.PUTSTATIC:\n      case Opcodes.GETFIELD:\n      case Opcodes.PUTFIELD:\n      case Opcodes.INVOKEVIRTUAL:\n      case Opcodes.INVOKESPECIAL:\n      case Opcodes.INVOKESTATIC:\n      case Opcodes.INVOKEINTERFACE:\n        {\n          int cpInfoOffset = cpInfoOffsets[readUnsignedShort(currentOffset + 1)];\n          int nameAndTypeCpInfoOffset = cpInfoOffsets[readUnsignedShort(cpInfoOffset + 2)];\n          String owner = readClass(cpInfoOffset, charBuffer);\n          String name = readUTF8(nameAndTypeCpInfoOffset, charBuffer);\n          String descriptor = readUTF8(nameAndTypeCpInfoOffset + 2, charBuffer);\n          if (opcode < Opcodes.INVOKEVIRTUAL) {\n            methodVisitor.visitFieldInsn(opcode, owner, name, descriptor);\n          } else {\n            boolean isInterface =\n                classBuffer[cpInfoOffset - 1] == Symbol.CONSTANT_INTERFACE_METHODREF_TAG;\n            methodVisitor.visitMethodInsn(opcode, owner, name, descriptor, isInterface);\n          }\n          if (opcode == Opcodes.INVOKEINTERFACE) {\n            currentOffset += 5;\n          } else {\n            currentOffset += 3;\n          }\n          break;\n        }\n      case Opcodes.INVOKEDYNAMIC:\n        {\n          int cpInfoOffset = cpInfoOffsets[readUnsignedShort(currentOffset + 1)];\n          int nameAndTypeCpInfoOffset = cpInfoOffsets[readUnsignedShort(cpInfoOffset + 2)];\n          String name = readUTF8(nameAndTypeCpInfoOffset, charBuffer);\n          String descriptor = readUTF8(nameAndTypeCpInfoOffset + 2, charBuffer);\n          int bootstrapMethodOffset = bootstrapMethodOffsets[readUnsignedShort(cpInfoOffset)];\n          Handle handle =\n              (Handle) readConst(readUnsignedShort(bootstrapMethodOffset), charBuffer);\n          Object[] bootstrapMethodArguments =\n              new Object[readUnsignedShort(bootstrapMethodOffset + 2)];\n          bootstrapMethodOffset += 4;\n          for (int i = 0; i < bootstrapMethodArguments.length; i++) {\n            bootstrapMethodArguments[i] =\n                readConst(readUnsignedShort(bootstrapMethodOffset), charBuffer);\n            bootstrapMethodOffset += 2;\n          }\n          methodVisitor.visitInvokeDynamicInsn(\n              name, descriptor, handle, bootstrapMethodArguments);\n          currentOffset += 5;\n          break;\n        }\n      case Opcodes.NEW:\n      case Opcodes.ANEWARRAY:\n      case Opcodes.CHECKCAST:\n      case Opcodes.INSTANCEOF:\n        methodVisitor.visitTypeInsn(opcode, readClass(currentOffset + 1, charBuffer));\n        currentOffset += 3;\n        break;\n      case Opcodes.IINC:\n        methodVisitor.visitIincInsn(\n            classBuffer[currentOffset + 1] & 0xFF, classBuffer[currentOffset + 2]);\n        currentOffset += 3;\n        break;\n      case Opcodes.MULTIANEWARRAY:\n        methodVisitor.visitMultiANewArrayInsn(\n            readClass(currentOffset + 1, charBuffer), classBuffer[currentOffset + 3] & 0xFF);\n        currentOffset += 4;\n        break;\n      default:\n        throw new AssertionError();\n    }\n\n      \n    while (visibleTypeAnnotationOffsets != null\n        && currentVisibleTypeAnnotationIndex < visibleTypeAnnotationOffsets.length\n        && currentVisibleTypeAnnotationBytecodeOffset <= currentBytecodeOffset) {\n      if (currentVisibleTypeAnnotationBytecodeOffset == currentBytecodeOffset) {\n          \n        int currentAnnotationOffset =\n            readTypeAnnotationTarget(\n                context, visibleTypeAnnotationOffsets[currentVisibleTypeAnnotationIndex]);\n          \n        String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n        currentAnnotationOffset += 2;\n          \n        readElementValues(\n            methodVisitor.visitInsnAnnotation(\n                context.currentTypeAnnotationTarget,\n                context.currentTypeAnnotationTargetPath,\n                annotationDescriptor,\n                 true),\n            currentAnnotationOffset,\n             true,\n            charBuffer);\n      }\n      currentVisibleTypeAnnotationBytecodeOffset =\n          getTypeAnnotationBytecodeOffset(\n              visibleTypeAnnotationOffsets, ++currentVisibleTypeAnnotationIndex);\n    }\n\n      \n    while (invisibleTypeAnnotationOffsets != null\n        && currentInvisibleTypeAnnotationIndex < invisibleTypeAnnotationOffsets.length\n        && currentInvisibleTypeAnnotationBytecodeOffset <= currentBytecodeOffset) {\n      if (currentInvisibleTypeAnnotationBytecodeOffset == currentBytecodeOffset) {\n          \n        int currentAnnotationOffset =\n            readTypeAnnotationTarget(\n                context, invisibleTypeAnnotationOffsets[currentInvisibleTypeAnnotationIndex]);\n          \n        String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n        currentAnnotationOffset += 2;\n          \n        readElementValues(\n            methodVisitor.visitInsnAnnotation(\n                context.currentTypeAnnotationTarget,\n                context.currentTypeAnnotationTargetPath,\n                annotationDescriptor,\n                 false),\n            currentAnnotationOffset,\n             true,\n            charBuffer);\n      }\n      currentInvisibleTypeAnnotationBytecodeOffset =\n          getTypeAnnotationBytecodeOffset(\n              invisibleTypeAnnotationOffsets, ++currentInvisibleTypeAnnotationIndex);\n    }\n  }\n  if (labels[codeLength] != null) {\n    methodVisitor.visitLabel(labels[codeLength]);\n  }\n\n    \n  if (localVariableTableOffset != 0 && (context.parsingOptions & SKIP_DEBUG) == 0) {\n      \n    int[] typeTable = null;\n    if (localVariableTypeTableOffset != 0) {\n      typeTable = new int[readUnsignedShort(localVariableTypeTableOffset) * 3];\n      currentOffset = localVariableTypeTableOffset + 2;\n      int typeTableIndex = typeTable.length;\n      while (typeTableIndex > 0) {\n          \n        typeTable[--typeTableIndex] = currentOffset + 6;\n        typeTable[--typeTableIndex] = readUnsignedShort(currentOffset + 8);\n        typeTable[--typeTableIndex] = readUnsignedShort(currentOffset);\n        currentOffset += 10;\n      }\n    }\n    int localVariableTableLength = readUnsignedShort(localVariableTableOffset);\n    currentOffset = localVariableTableOffset + 2;\n    while (localVariableTableLength-- > 0) {\n      int startPc = readUnsignedShort(currentOffset);\n      int length = readUnsignedShort(currentOffset + 2);\n      String name = readUTF8(currentOffset + 4, charBuffer);\n      String descriptor = readUTF8(currentOffset + 6, charBuffer);\n      int index = readUnsignedShort(currentOffset + 8);\n      currentOffset += 10;\n      String signature = null;\n      if (typeTable != null) {\n        for (int i = 0; i < typeTable.length; i += 3) {\n          if (typeTable[i] == startPc && typeTable[i + 1] == index) {\n            signature = readUTF8(typeTable[i + 2], charBuffer);\n            break;\n          }\n        }\n      }\n      methodVisitor.visitLocalVariable(\n          name, descriptor, signature, labels[startPc], labels[startPc + length], index);\n    }\n  }\n\n    \n  if (visibleTypeAnnotationOffsets != null) {\n    for (int typeAnnotationOffset : visibleTypeAnnotationOffsets) {\n      int targetType = readByte(typeAnnotationOffset);\n      if (targetType == TypeReference.LOCAL_VARIABLE\n          || targetType == TypeReference.RESOURCE_VARIABLE) {\n          \n        currentOffset = readTypeAnnotationTarget(context, typeAnnotationOffset);\n          \n        String annotationDescriptor = readUTF8(currentOffset, charBuffer);\n        currentOffset += 2;\n          \n        readElementValues(\n            methodVisitor.visitLocalVariableAnnotation(\n                context.currentTypeAnnotationTarget,\n                context.currentTypeAnnotationTargetPath,\n                context.currentLocalVariableAnnotationRangeStarts,\n                context.currentLocalVariableAnnotationRangeEnds,\n                context.currentLocalVariableAnnotationRangeIndices,\n                annotationDescriptor,\n                 true),\n            currentOffset,\n             true,\n            charBuffer);\n      }\n    }\n  }\n\n    \n  if (invisibleTypeAnnotationOffsets != null) {\n    for (int typeAnnotationOffset : invisibleTypeAnnotationOffsets) {\n      int targetType = readByte(typeAnnotationOffset);\n      if (targetType == TypeReference.LOCAL_VARIABLE\n          || targetType == TypeReference.RESOURCE_VARIABLE) {\n          \n        currentOffset = readTypeAnnotationTarget(context, typeAnnotationOffset);\n          \n        String annotationDescriptor = readUTF8(currentOffset, charBuffer);\n        currentOffset += 2;\n          \n        readElementValues(\n            methodVisitor.visitLocalVariableAnnotation(\n                context.currentTypeAnnotationTarget,\n                context.currentTypeAnnotationTargetPath,\n                context.currentLocalVariableAnnotationRangeStarts,\n                context.currentLocalVariableAnnotationRangeEnds,\n                context.currentLocalVariableAnnotationRangeIndices,\n                annotationDescriptor,\n                 false),\n            currentOffset,\n             true,\n            charBuffer);\n      }\n    }\n  }\n\n    \n  while (attributes != null) {\n      \n    Attribute nextAttribute = attributes.nextAttribute;\n    attributes.nextAttribute = null;\n    methodVisitor.visitAttribute(attributes);\n    attributes = nextAttribute;\n  }\n\n    \n  methodVisitor.visitMaxs(maxStack, maxLocals);\n}", "summary_tokens": ["reads", "a", "jvms", "code", "attribute", "and", "makes", "the", "given", "visitor", "visit", "it"], "project": "spring-framework"}
{"id": 6618, "code": "\tpublic HttpHeaders getHeaders() {\n\t\treturn this.headers;\n\t}", "summary_tokens": ["returns", "the", "headers", "of", "this", "entity"], "project": "spring-framework"}
{"id": 1721, "code": "\tprotected MBeanServer locateMBeanServer(@Nullable String agentId) throws MBeanServerNotFoundException {\n\t\treturn JmxUtils.locateMBeanServer(agentId);\n\t}", "summary_tokens": ["attempt", "to", "locate", "an", "existing", "mbean", "server"], "project": "spring-framework"}
{"id": 493, "code": "\tpublic void setBeanName(String beanName) {\n\t\tthis.beanName = StringUtils.trimAllWhitespace(BeanFactoryUtils.originalBeanName(beanName));\n\t}", "summary_tokens": ["the", "bean", "name", "of", "this", "field", "retrieving", "factory", "bean", "will", "be", "interpreted", "as", "static", "field", "pattern", "if", "neither", "target", "class", "nor", "target", "object", "nor", "target", "field", "have", "been", "specified"], "project": "spring-framework"}
{"id": 8541, "code": "\tpublic View getView() {\n\t\treturn (this.view instanceof View ? (View) this.view : null);\n\t}", "summary_tokens": ["return", "the", "view", "object", "or", "null", "if", "we", "are", "using", "a", "view", "name", "to", "be", "resolved", "by", "the", "dispatcher", "servlet", "via", "a", "view", "resolver"], "project": "spring-framework"}
{"id": 5934, "code": "\tpublic MockMvcWebClientBuilder withDelegate(WebClient webClient) {\n\t\tAssert.notNull(webClient, \"WebClient must not be null\");\n\t\twebClient.setWebConnection(createConnection(webClient));\n\t\tthis.webClient = webClient;\n\t\treturn this;\n\t}", "summary_tokens": ["supply", "the", "web", "client", "that", "the", "client", "build", "built", "by", "this", "builder", "should", "delegate", "to", "when", "processing", "non", "web", "request", "matcher", "matching", "requests"], "project": "spring-framework"}
{"id": 5049, "code": "\tpublic long getRegistryExpirationPeriod() {\n\t\treturn this.registryExpirationPeriod;\n\t}", "summary_tokens": ["return", "the", "configured", "registry", "expiration", "period"], "project": "spring-framework"}
{"id": 4971, "code": "\tpublic long[] getDefaultHeartbeat() {\n\t\treturn this.defaultHeartbeat;\n\t}", "summary_tokens": ["return", "the", "configured", "default", "heart", "beat", "value", "never", "null"], "project": "spring-framework"}
{"id": 9782, "code": "\tpublic String getClientOutboundExecutorStatsInfo() {\n\t\treturn getExecutorStatsInfo(this.outboundChannelExecutor);\n\t}", "summary_tokens": ["get", "stats", "about", "the", "executor", "processing", "outgoing", "messages", "to", "web", "socket", "clients"], "project": "spring-framework"}
{"id": 124, "code": "\tpublic void setAdvisorAdapterRegistry(AdvisorAdapterRegistry advisorAdapterRegistry) {\n\t\tthis.advisorAdapterRegistry = advisorAdapterRegistry;\n\t}", "summary_tokens": ["specify", "the", "advisor", "adapter", "registry", "to", "use"], "project": "spring-framework"}
{"id": 5973, "code": "\tpublic ResultMatcher doesNotExist(String name) {\n\t\treturn result -> {\n\t\t\tCookie cookie = result.getResponse().getCookie(name);\n\t\t\tassertNull(\"Unexpected cookie with name '\" + name + \"'\", cookie);\n\t\t};\n\t}", "summary_tokens": ["assert", "a", "cookie", "does", "not", "exist"], "project": "spring-framework"}
{"id": 9655, "code": "\tprotected final void renderMergedOutputModel(\n\t\t\tMap<String, Object> model, HttpServletRequest request, HttpServletResponse response) throws Exception {\n\n\t\t\n\t\tWorkbook workbook = createWorkbook(model, request);\n\n\t\t\n\t\tbuildExcelDocument(model, workbook, request, response);\n\n\t\t\n\t\tresponse.setContentType(getContentType());\n\n\t\t\n\t\trenderWorkbook(workbook, response);\n\t}", "summary_tokens": ["renders", "the", "excel", "view", "given", "the", "specified", "model"], "project": "spring-framework"}
{"id": 809, "code": "\tpublic String getMerge() {\n\t\treturn this.merge;\n\t}", "summary_tokens": ["return", "the", "default", "merge", "setting", "for", "the", "document", "that", "s", "currently", "parsed"], "project": "spring-framework"}
{"id": 5178, "code": "\tpublic LocalSessionFactoryBuilder setMultiTenantConnectionProvider(MultiTenantConnectionProvider multiTenantConnectionProvider) {\n\t\tgetProperties().put(AvailableSettings.MULTI_TENANT_CONNECTION_PROVIDER, multiTenantConnectionProvider);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "a", "multi", "tenant", "connection", "provider", "to", "be", "passed", "on", "to", "the", "session", "factory"], "project": "spring-framework"}
{"id": 3155, "code": "\tpublic static String getShortName(Class<?> clazz) {\n\t\treturn getShortName(getQualifiedName(clazz));\n\t}", "summary_tokens": ["get", "the", "class", "name", "without", "the", "qualified", "package", "name"], "project": "spring-framework"}
{"id": 9681, "code": "\tprotected void doRender(Map<String, Object> model, HttpServletRequest request,\n\t\t\tHttpServletResponse response) throws Exception {\n\n\t\t\n\t\texposeModelAsRequestAttributes(model, request);\n\t\t\n\t\tSimpleHash fmModel = buildTemplateModel(model, request, response);\n\n\t\t\n\t\tLocale locale = RequestContextUtils.getLocale(request);\n\t\tprocessTemplate(getTemplate(locale), fmModel, response);\n\t}", "summary_tokens": ["render", "the", "free", "marker", "view", "to", "the", "given", "response", "using", "the", "given", "model", "map", "which", "contains", "the", "complete", "template", "model", "to", "use"], "project": "spring-framework"}
{"id": 3732, "code": "\tpublic void setReturnValueRequired(boolean returnValueRequired) {\n\t\tthis.returnValueRequired = returnValueRequired;\n\t}", "summary_tokens": ["specify", "whether", "a", "return", "value", "is", "required"], "project": "spring-framework"}
{"id": 3226, "code": "\tprotected boolean match(T instance, Collection<? extends T> candidates) {\n\t\tfor (T candidate : candidates) {\n\t\t\tif (match(instance, candidate)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "if", "the", "specified", "instance", "matches", "one", "of", "the", "candidates"], "project": "spring-framework"}
{"id": 8948, "code": "\tvoid closeStreamIfNecessary(InputStream body) {\n\t\t\n\t\t\n\t}", "summary_tokens": ["allow", "for", "closing", "the", "body", "stream", "if", "necessary", "e"], "project": "spring-framework"}
{"id": 8367, "code": "\tprotected StringBuilder appendCurrentRequestQuery(String targetUrl, ServerHttpRequest request) {\n\t\tString query = request.getURI().getRawQuery();\n\t\tif (!StringUtils.hasText(query)) {\n\t\t\treturn new StringBuilder(targetUrl);\n\t\t}\n\n\t\tint index = targetUrl.indexOf('#');\n\t\tString fragment = (index > -1 ? targetUrl.substring(index) : null);\n\n\t\tStringBuilder result = new StringBuilder();\n\t\tresult.append(index != -1 ? targetUrl.substring(0, index) : targetUrl);\n\t\tresult.append(targetUrl.indexOf('?') < 0 ? '?' : '&').append(query);\n\n\t\tif (fragment != null) {\n\t\t\tresult.append(fragment);\n\t\t}\n\n\t\treturn result;\n\t}", "summary_tokens": ["append", "the", "query", "of", "the", "current", "request", "to", "the", "target", "redirect", "url"], "project": "spring-framework"}
{"id": 4446, "code": "\tprivate void rollbackOnException(PlatformTransactionManager manager, TransactionStatus status, Throwable ex) {\n\t\tlogger.debug(\"Initiating transaction rollback on listener exception\", ex);\n\t\ttry {\n\t\t\tmanager.rollback(status);\n\t\t}\n\t\tcatch (RuntimeException ex2) {\n\t\t\tlogger.error(\"Listener exception overridden by rollback exception\", ex);\n\t\t\tthrow ex2;\n\t\t}\n\t\tcatch (Error err) {\n\t\t\tlogger.error(\"Listener exception overridden by rollback error\", ex);\n\t\t\tthrow err;\n\t\t}\n\t}", "summary_tokens": ["perform", "a", "rollback", "handling", "rollback", "exceptions", "properly"], "project": "spring-framework"}
{"id": 9699, "code": "\tpublic void setExtractValueFromSingleKeyModel(boolean extractValueFromSingleKeyModel) {\n\t\tthis.extractValueFromSingleKeyModel = extractValueFromSingleKeyModel;\n\t}", "summary_tokens": ["set", "whether", "to", "serialize", "models", "containing", "a", "single", "attribute", "as", "a", "map", "or", "whether", "to", "extract", "the", "single", "value", "from", "the", "model", "and", "serialize", "it", "directly"], "project": "spring-framework"}
{"id": 1704, "code": "\tprotected void doUnregister(ObjectName objectName) {\n\t\tAssert.state(this.server != null, \"No MBeanServer set\");\n\t\tboolean actuallyUnregistered = false;\n\n\t\tsynchronized (this.registeredBeans) {\n\t\t\tif (this.registeredBeans.remove(objectName)) {\n\t\t\t\ttry {\n\t\t\t\t\t\n\t\t\t\t\tif (this.server.isRegistered(objectName)) {\n\t\t\t\t\t\tthis.server.unregisterMBean(objectName);\n\t\t\t\t\t\tactuallyUnregistered = true;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\t\t\t\tlogger.info(\"Could not unregister MBean [\" + objectName + \"] as said MBean \" +\n\t\t\t\t\t\t\t\t\t\"is not registered (perhaps already unregistered by an external process)\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcatch (JMException ex) {\n\t\t\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\t\t\tlogger.info(\"Could not unregister MBean [\" + objectName + \"]\", ex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (actuallyUnregistered) {\n\t\t\tonUnregister(objectName);\n\t\t}\n\t}", "summary_tokens": ["actually", "unregister", "the", "specified", "mbean", "from", "the", "server"], "project": "spring-framework"}
{"id": 7356, "code": "\tpublic String getSessionId() {\n\t\treturn this.sessionId;\n\t}", "summary_tokens": ["return", "the", "id", "of", "the", "http", "session", "if", "any"], "project": "spring-framework"}
{"id": 8966, "code": "\tpublic List<HttpMessageConverter<?>> getMessageConverters() {\n\t\treturn this.messageConverters;\n\t}", "summary_tokens": ["return", "the", "configured", "message", "body", "converters"], "project": "spring-framework"}
{"id": 8996, "code": "\tpublic Object afterBodyRead(Object body, HttpInputMessage inputMessage, MethodParameter parameter,\n\t\t\tType targetType, Class<? extends HttpMessageConverter<?>> converterType) {\n\n\t\treturn body;\n\t}", "summary_tokens": ["the", "default", "implementation", "returns", "the", "body", "that", "was", "passed", "in"], "project": "spring-framework"}
{"id": 6209, "code": "\tpublic int getPhase() {\n\t\treturn this.phase;\n\t}", "summary_tokens": ["return", "the", "phase", "in", "which", "this", "endpoint", "manager", "will", "be", "started", "and", "stopped"], "project": "spring-framework"}
{"id": 3004, "code": "\tpublic void setLocations(Resource... locations) {\n\t\tthis.locations = locations;\n\t}", "summary_tokens": ["set", "locations", "of", "properties", "files", "to", "be", "loaded"], "project": "spring-framework"}
{"id": 7222, "code": "\tpublic static Mono<Map<String, Object>> extractValuesToBind(ServerWebExchange exchange) {\n\t\tMultiValueMap<String, String> queryParams = exchange.getRequest().getQueryParams();\n\t\tMono<MultiValueMap<String, String>> formData = exchange.getFormData();\n\t\tMono<MultiValueMap<String, Part>> multipartData = exchange.getMultipartData();\n\n\t\treturn Mono.zip(Mono.just(queryParams), formData, multipartData)\n\t\t\t\t.map(tuple -> {\n\t\t\t\t\tMap<String, Object> result = new TreeMap<>();\n\t\t\t\t\ttuple.getT1().forEach((key, values) -> addBindValue(result, key, values));\n\t\t\t\t\ttuple.getT2().forEach((key, values) -> addBindValue(result, key, values));\n\t\t\t\t\ttuple.getT3().forEach((key, values) -> addBindValue(result, key, values));\n\t\t\t\t\treturn result;\n\t\t\t\t});\n\t}", "summary_tokens": ["combine", "query", "params", "and", "form", "data", "for", "multipart", "form", "data", "from", "the", "body", "of", "the", "request", "into", "a", "map", "string", "object", "of", "values", "to", "use", "for", "data", "binding", "purposes"], "project": "spring-framework"}
{"id": 2216, "code": "\tpublic SourceFile getSingle(String pattern) throws IllegalStateException {\n\t\treturn getSingle(Pattern.compile(pattern));\n\t}", "summary_tokens": ["return", "the", "single", "matching", "source", "file", "contained", "in", "the", "collection"], "project": "spring-framework"}
{"id": 576, "code": "\tpublic String toString() {\n\t\treturn getDescription();\n\t}", "summary_tokens": ["this", "implementation", "returns", "this", "component", "definition", "s", "description"], "project": "spring-framework"}
{"id": 3096, "code": "\tpublic String combine(String pattern1, String pattern2) {\n\t\tif (!StringUtils.hasText(pattern1) && !StringUtils.hasText(pattern2)) {\n\t\t\treturn \"\";\n\t\t}\n\t\tif (!StringUtils.hasText(pattern1)) {\n\t\t\treturn pattern2;\n\t\t}\n\t\tif (!StringUtils.hasText(pattern2)) {\n\t\t\treturn pattern1;\n\t\t}\n\n\t\tboolean pattern1ContainsUriVar = (pattern1.indexOf('{') != -1);\n\t\tif (!pattern1.equals(pattern2) && !pattern1ContainsUriVar && match(pattern1, pattern2)) {\n\t\t\t\n\t\t\t\n\t\t\treturn pattern2;\n\t\t}\n\n\t\t\n\t\t\n\t\tif (pattern1.endsWith(this.pathSeparatorPatternCache.getEndsOnWildCard())) {\n\t\t\treturn concat(pattern1.substring(0, pattern1.length() - 2), pattern2);\n\t\t}\n\n\t\t\n\t\t\n\t\tif (pattern1.endsWith(this.pathSeparatorPatternCache.getEndsOnDoubleWildCard())) {\n\t\t\treturn concat(pattern1, pattern2);\n\t\t}\n\n\t\tint starDotPos1 = pattern1.indexOf(\"*.\");\n\t\tif (pattern1ContainsUriVar || starDotPos1 == -1 || this.pathSeparator.equals(\".\")) {\n\t\t\t\n\t\t\treturn concat(pattern1, pattern2);\n\t\t}\n\n\t\tString ext1 = pattern1.substring(starDotPos1 + 1);\n\t\tint dotPos2 = pattern2.indexOf('.');\n\t\tString file2 = (dotPos2 == -1 ? pattern2 : pattern2.substring(0, dotPos2));\n\t\tString ext2 = (dotPos2 == -1 ? \"\" : pattern2.substring(dotPos2));\n\t\tboolean ext1All = (ext1.equals(\".*\") || ext1.isEmpty());\n\t\tboolean ext2All = (ext2.equals(\".*\") || ext2.isEmpty());\n\t\tif (!ext1All && !ext2All) {\n\t\t\tthrow new IllegalArgumentException(\"Cannot combine patterns: \" + pattern1 + \" vs \" + pattern2);\n\t\t}\n\t\tString ext = (ext1All ? ext2 : ext1);\n\t\treturn file2 + ext;\n\t}\n\n\tprivate String concat(String path1, String path2) {\n\t\tboolean path1EndsWithSeparator = path1.endsWith(this.pathSeparator);\n\t\tboolean path2StartsWithSeparator = path2.startsWith(this.pathSeparator);\n\n\t\tif (path1EndsWithSeparator && path2StartsWithSeparator) {\n\t\t\treturn path1 + path2.substring(1);\n\t\t}\n\t\telse if (path1EndsWithSeparator || path2StartsWithSeparator) {\n\t\t\treturn path1 + path2;\n\t\t}\n\t\telse {\n\t\t\treturn path1 + this.pathSeparator + path2;\n\t\t}\n\t}\n\n\t\n\t@Override\n\tpublic Comparator<String> getPatternComparator(String path) {\n\t\treturn new AntPatternComparator(path);\n\t}\n\n\n\t\n\tprotected static class AntPathStringMatcher {\n\n\t\tprivate static final Pattern GLOB_PATTERN = Pattern.compile(\"\\\\?|\\\\*|\\\\{((?:\\\\{[^/]+?\\\\}|[^/{}]|\\\\\\\\[{}])+?)\\\\}\");\n\n\t\tprivate static final String DEFAULT_VARIABLE_PATTERN = \"((?s).*)\";\n\n\t\tprivate final String rawPattern;\n\n\t\tprivate final boolean caseSensitive;\n\n\t\tprivate final boolean exactMatch;\n\n\t\t@Nullable\n\t\tprivate final Pattern pattern;\n\n\t\tprivate final List<String> variableNames = new ArrayList<>();\n\n\t\tpublic AntPathStringMatcher(String pattern) {\n\t\t\tthis(pattern, true);\n\t\t}\n\n\t\tpublic AntPathStringMatcher(String pattern, boolean caseSensitive) {\n\t\t\tthis.rawPattern = pattern;\n\t\t\tthis.caseSensitive = caseSensitive;\n\t\t\tStringBuilder patternBuilder = new StringBuilder();\n\t\t\tMatcher matcher = GLOB_PATTERN.matcher(pattern);\n\t\t\tint end = 0;\n\t\t\twhile (matcher.find()) {\n\t\t\t\tpatternBuilder.append(quote(pattern, end, matcher.start()));\n\t\t\t\tString match = matcher.group();\n\t\t\t\tif (\"?\".equals(match)) {\n\t\t\t\t\tpatternBuilder.append('.');\n\t\t\t\t}\n\t\t\t\telse if (\"*\".equals(match)) {\n\t\t\t\t\tpatternBuilder.append(\".*\");\n\t\t\t\t}\n\t\t\t\telse if (match.startsWith(\"{\") && match.endsWith(\"}\")) {\n\t\t\t\t\tint colonIdx = match.indexOf(':');\n\t\t\t\t\tif (colonIdx == -1) {\n\t\t\t\t\t\tpatternBuilder.append(DEFAULT_VARIABLE_PATTERN);\n\t\t\t\t\t\tthis.variableNames.add(matcher.group(1));\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tString variablePattern = match.substring(colonIdx + 1, match.length() - 1);\n\t\t\t\t\t\tpatternBuilder.append('(');\n\t\t\t\t\t\tpatternBuilder.append(variablePattern);\n\t\t\t\t\t\tpatternBuilder.append(')');\n\t\t\t\t\t\tString variableName = match.substring(1, colonIdx);\n\t\t\t\t\t\tthis.variableNames.add(variableName);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tend = matcher.end();\n\t\t\t}\n\t\t\t\n\t\t\tif (end == 0) {\n\t\t\t\tthis.exactMatch = true;\n\t\t\t\tthis.pattern = null;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.exactMatch = false;\n\t\t\t\tpatternBuilder.append(quote(pattern, end, pattern.length()));\n\t\t\t\tthis.pattern = Pattern.compile(patternBuilder.toString(),\n\t\t\t\t\t\tPattern.DOTALL | (this.caseSensitive ? 0 : Pattern.CASE_INSENSITIVE));\n\t\t\t}\n\t\t}\n\n\t\tprivate String quote(String s, int start, int end) {\n\t\t\tif (start == end) {\n\t\t\t\treturn \"\";\n\t\t\t}\n\t\t\treturn Pattern.quote(s.substring(start, end));\n\t\t}\n\n\t\t\n\t\tpublic boolean matchStrings(String str, @Nullable Map<String, String> uriTemplateVariables) {\n\t\t\tif (this.exactMatch) {\n\t\t\t\treturn this.caseSensitive ? this.rawPattern.equals(str) : this.rawPattern.equalsIgnoreCase(str);\n\t\t\t}\n\t\t\telse if (this.pattern != null) {\n\t\t\t\tMatcher matcher = this.pattern.matcher(str);\n\t\t\t\tif (matcher.matches()) {\n\t\t\t\t\tif (uriTemplateVariables != null) {\n\t\t\t\t\t\tif (this.variableNames.size() != matcher.groupCount()) {\n\t\t\t\t\t\t\tthrow new IllegalArgumentException(\"The number of capturing groups in the pattern segment \" +\n\t\t\t\t\t\t\t\t\tthis.pattern + \" does not match the number of URI template variables it defines, \" +\n\t\t\t\t\t\t\t\t\t\"which can occur if capturing groups are used in a URI template regex. \" +\n\t\t\t\t\t\t\t\t\t\"Use non-capturing groups instead.\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tfor (int i = 1; i <= matcher.groupCount(); i++) {\n\t\t\t\t\t\t\tString name = this.variableNames.get(i - 1);\n\t\t\t\t\t\t\tif (name.startsWith(\"*\")) {\n\t\t\t\t\t\t\t\tthrow new IllegalArgumentException(\"Capturing patterns (\" + name + \") are not \" +\n\t\t\t\t\t\t\t\t\t\t\"supported by the AntPathMatcher. Use the PathPatternParser instead.\");\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tString value = matcher.group(i);\n\t\t\t\t\t\t\turiTemplateVariables.put(name, value);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\n\t}\n\n\n\t\n\tprotected static class AntPatternComparator implements Comparator<String> {\n\n\t\tprivate final String path;\n\n\t\tpublic AntPatternComparator(String path) {\n\t\t\tthis.path = path;\n\t\t}\n\n\t\t\n\t\t@Override\n\t\tpublic int compare(String pattern1, String pattern2) {\n\t\t\tPatternInfo info1 = new PatternInfo(pattern1);\n\t\t\tPatternInfo info2 = new PatternInfo(pattern2);\n\n\t\t\tif (info1.isLeastSpecific() && info2.isLeastSpecific()) {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\telse if (info1.isLeastSpecific()) {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\telse if (info2.isLeastSpecific()) {\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tboolean pattern1EqualsPath = pattern1.equals(this.path);\n\t\t\tboolean pattern2EqualsPath = pattern2.equals(this.path);\n\t\t\tif (pattern1EqualsPath && pattern2EqualsPath) {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\telse if (pattern1EqualsPath) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\telse if (pattern2EqualsPath) {\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tif (info1.isPrefixPattern() && info2.isPrefixPattern()) {\n\t\t\t\treturn info2.getLength() - info1.getLength();\n\t\t\t}\n\t\t\telse if (info1.isPrefixPattern() && info2.getDoubleWildcards() == 0) {\n\t\t\t\treturn 1;\n\t\t\t}\n\t\t\telse if (info2.isPrefixPattern() && info1.getDoubleWildcards() == 0) {\n\t\t\t\treturn -1;\n\t\t\t}\n\n\t\t\tif (info1.getTotalCount() != info2.getTotalCount()) {\n\t\t\t\treturn info1.getTotalCount() - info2.getTotalCount();\n\t\t\t}\n\n\t\t\tif (info1.getLength() != info2.getLength()) {\n\t\t\t\treturn info2.getLength() - info1.getLength();\n\t\t\t}\n\n\t\t\tif (info1.getSingleWildcards() < info2.getSingleWildcards()) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\telse if (info2.getSingleWildcards() < info1.getSingleWildcards()) {\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\tif (info1.getUriVars() < info2.getUriVars()) {\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t\telse if (info2.getUriVars() < info1.getUriVars()) {\n\t\t\t\treturn 1;\n\t\t\t}\n\n\t\t\treturn 0;\n\t\t}\n\n\n\t\t\n\t\tprivate static class PatternInfo {\n\n\t\t\t@Nullable\n\t\t\tprivate final String pattern;\n\n\t\t\tprivate int uriVars;\n\n\t\t\tprivate int singleWildcards;\n\n\t\t\tprivate int doubleWildcards;\n\n\t\t\tprivate boolean catchAllPattern;\n\n\t\t\tprivate boolean prefixPattern;\n\n\t\t\t@Nullable\n\t\t\tprivate Integer length;\n\n\t\t\tpublic PatternInfo(@Nullable String pattern) {\n\t\t\t\tthis.pattern = pattern;\n\t\t\t\tif (this.pattern != null) {\n\t\t\t\t\tinitCounters();\n\t\t\t\t\tthis.catchAllPattern = this.pattern.equals(\"/**\");\n\t\t\t\t\tthis.prefixPattern = !this.catchAllPattern && this.pattern.endsWith(\"/**\");\n\t\t\t\t}\n\t\t\t\tif (this.uriVars == 0) {\n\t\t\t\t\tthis.length = (this.pattern != null ? this.pattern.length() : 0);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tprotected void initCounters() {\n\t\t\t\tint pos = 0;\n\t\t\t\tif (this.pattern != null) {\n\t\t\t\t\twhile (pos < this.pattern.length()) {\n\t\t\t\t\t\tif (this.pattern.charAt(pos) == '{') {\n\t\t\t\t\t\t\tthis.uriVars++;\n\t\t\t\t\t\t\tpos++;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (this.pattern.charAt(pos) == '*') {\n\t\t\t\t\t\t\tif (pos + 1 < this.pattern.length() && this.pattern.charAt(pos + 1) == '*') {\n\t\t\t\t\t\t\t\tthis.doubleWildcards++;\n\t\t\t\t\t\t\t\tpos += 2;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse if (pos > 0 && !this.pattern.substring(pos - 1).equals(\".*\")) {\n\t\t\t\t\t\t\t\tthis.singleWildcards++;\n\t\t\t\t\t\t\t\tpos++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\tpos++;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tpos++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tpublic int getUriVars() {\n\t\t\t\treturn this.uriVars;\n\t\t\t}\n\n\t\t\tpublic int getSingleWildcards() {\n\t\t\t\treturn this.singleWildcards;\n\t\t\t}\n\n\t\t\tpublic int getDoubleWildcards() {\n\t\t\t\treturn this.doubleWildcards;\n\t\t\t}\n\n\t\t\tpublic boolean isLeastSpecific() {\n\t\t\t\treturn (this.pattern == null || this.catchAllPattern);\n\t\t\t}\n\n\t\t\tpublic boolean isPrefixPattern() {\n\t\t\t\treturn this.prefixPattern;\n\t\t\t}\n\n\t\t\tpublic int getTotalCount() {\n\t\t\t\treturn this.uriVars + this.singleWildcards + (2 * this.doubleWildcards);\n\t\t\t}\n\n\t\t\t\n\t\t\tpublic int getLength() {\n\t\t\t\tif (this.length == null) {\n\t\t\t\t\tthis.length = (this.pattern != null ?\n\t\t\t\t\t\t\tVARIABLE_PATTERN.matcher(this.pattern).replaceAll(\"#\").length() : 0);\n\t\t\t\t}\n\t\t\t\treturn this.length;\n\t\t\t}\n\t\t}\n\t}\n\n\n\t\n\tprivate static class PathSeparatorPatternCache {\n\n\t\tprivate final String endsOnWildCard;\n\n\t\tprivate final String endsOnDoubleWildCard;\n\n\t\tpublic PathSeparatorPatternCache(String pathSeparator) {\n\t\t\tthis.endsOnWildCard = pathSeparator + \"*\";\n\t\t\tthis.endsOnDoubleWildCard = pathSeparator + \"**\";\n\t\t}\n\n\t\tpublic String getEndsOnWildCard() {\n\t\t\treturn this.endsOnWildCard;\n\t\t}\n\n\t\tpublic String getEndsOnDoubleWildCard() {\n\t\t\treturn this.endsOnDoubleWildCard;\n\t\t}\n\t}\n\n}\n", "summary_tokens": ["combine", "two", "patterns", "into", "a", "new", "pattern"], "project": "spring-framework"}
{"id": 8916, "code": "\tpublic ProducesRequestCondition combine(ProducesRequestCondition other) {\n\t\treturn (!other.expressions.isEmpty() ? other : this);\n\t}", "summary_tokens": ["returns", "the", "other", "instance", "if", "it", "has", "any", "expressions", "returns", "this", "instance", "otherwise"], "project": "spring-framework"}
{"id": 4277, "code": "\tpublic void setConnectionFactory(@Nullable ConnectionFactory cf) {\n\t\tif (cf instanceof TransactionAwareConnectionFactoryProxy) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tthis.connectionFactory = ((TransactionAwareConnectionFactoryProxy) cf).getTargetConnectionFactory();\n\t\t}\n\t\telse {\n\t\t\tthis.connectionFactory = cf;\n\t\t}\n\t}", "summary_tokens": ["set", "the", "jms", "connection", "factory", "that", "this", "instance", "should", "manage", "transactions", "for"], "project": "spring-framework"}
{"id": 299, "code": "\tprotected void close() {\n\t\tthis.beanFactory.destroySingletons();\n\t}", "summary_tokens": ["we", "must", "simulate", "container", "shutdown", "which", "should", "clear", "threads"], "project": "spring-framework"}
{"id": 3517, "code": "\tpublic static boolean isPrimitiveOrUnboxableSupportedNumberOrBoolean(@Nullable String descriptor) {\n\t\tif (descriptor == null) {\n\t\t\treturn false;\n\t\t}\n\t\tif (isPrimitiveOrUnboxableSupportedNumber(descriptor)) {\n\t\t\treturn true;\n\t\t}\n\t\treturn (\"Z\".equals(descriptor) || descriptor.equals(\"Ljava/lang/Boolean\"));\n\t}", "summary_tokens": ["determine", "if", "the", "supplied", "descriptor", "is", "for", "a", "supported", "number", "type", "or", "boolean"], "project": "spring-framework"}
{"id": 1929, "code": "\tprotected Object createRefreshableProxy(TargetSource ts, @Nullable Class<?>[] interfaces, boolean proxyTargetClass) {\n\t\tProxyFactory proxyFactory = new ProxyFactory();\n\t\tproxyFactory.setTargetSource(ts);\n\t\tClassLoader classLoader = this.beanClassLoader;\n\n\t\tif (interfaces != null) {\n\t\t\tproxyFactory.setInterfaces(interfaces);\n\t\t}\n\t\telse {\n\t\t\tClass<?> targetClass = ts.getTargetClass();\n\t\t\tif (targetClass != null) {\n\t\t\t\tproxyFactory.setInterfaces(ClassUtils.getAllInterfacesForClass(targetClass, this.beanClassLoader));\n\t\t\t}\n\t\t}\n\n\t\tif (proxyTargetClass) {\n\t\t\tclassLoader = null;  \n\t\t\tproxyFactory.setProxyTargetClass(true);\n\t\t}\n\n\t\tDelegatingIntroductionInterceptor introduction = new DelegatingIntroductionInterceptor(ts);\n\t\tintroduction.suppressInterface(TargetSource.class);\n\t\tproxyFactory.addAdvice(introduction);\n\n\t\treturn proxyFactory.getProxy(classLoader);\n\t}", "summary_tokens": ["create", "a", "refreshable", "proxy", "for", "the", "given", "aop", "target", "source"], "project": "spring-framework"}
{"id": 2986, "code": "\tdefault WritableByteChannel writableChannel() throws IOException {\n\t\treturn Channels.newChannel(getOutputStream());\n\t}", "summary_tokens": ["return", "a", "writable", "byte", "channel"], "project": "spring-framework"}
{"id": 2138, "code": "\tpublic MockEnvironment withProperty(String key, String value) {\n\t\tthis.setProperty(key, value);\n\t\treturn this;\n\t}", "summary_tokens": ["convenient", "synonym", "for", "set", "property", "that", "returns", "the", "current", "instance"], "project": "spring-framework"}
{"id": 9023, "code": "\tpublic synchronized void onTimeout(Runnable callback) {\n\t\tthis.timeoutCallback.setDelegate(callback);\n\t}", "summary_tokens": ["register", "code", "to", "invoke", "when", "the", "async", "request", "times", "out"], "project": "spring-framework"}
{"id": 3417, "code": "\tpublic Iterator<String> getBoundPrefixes() {\n\t\treturn this.prefixToNamespaceUri.keySet().iterator();\n\t}", "summary_tokens": ["return", "all", "declared", "prefixes"], "project": "spring-framework"}
{"id": 1257, "code": "\tpublic static Set<BeanDefinitionHolder> registerAnnotationConfigProcessors(\n\t\t\tBeanDefinitionRegistry registry, @Nullable Object source) {\n\n\t\tDefaultListableBeanFactory beanFactory = unwrapDefaultListableBeanFactory(registry);\n\t\tif (beanFactory != null) {\n\t\t\tif (!(beanFactory.getDependencyComparator() instanceof AnnotationAwareOrderComparator)) {\n\t\t\t\tbeanFactory.setDependencyComparator(AnnotationAwareOrderComparator.INSTANCE);\n\t\t\t}\n\t\t\tif (!(beanFactory.getAutowireCandidateResolver() instanceof ContextAnnotationAutowireCandidateResolver)) {\n\t\t\t\tbeanFactory.setAutowireCandidateResolver(new ContextAnnotationAutowireCandidateResolver());\n\t\t\t}\n\t\t}\n\n\t\tSet<BeanDefinitionHolder> beanDefs = new LinkedHashSet<>(8);\n\n\t\tif (!registry.containsBeanDefinition(CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME)) {\n\t\t\tRootBeanDefinition def = new RootBeanDefinition(ConfigurationClassPostProcessor.class);\n\t\t\tdef.setSource(source);\n\t\t\tbeanDefs.add(registerPostProcessor(registry, def, CONFIGURATION_ANNOTATION_PROCESSOR_BEAN_NAME));\n\t\t}\n\n\t\tif (!registry.containsBeanDefinition(AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME)) {\n\t\t\tRootBeanDefinition def = new RootBeanDefinition(AutowiredAnnotationBeanPostProcessor.class);\n\t\t\tdef.setSource(source);\n\t\t\tbeanDefs.add(registerPostProcessor(registry, def, AUTOWIRED_ANNOTATION_PROCESSOR_BEAN_NAME));\n\t\t}\n\n\t\t\n\t\tif (jakartaAnnotationsPresent && !registry.containsBeanDefinition(COMMON_ANNOTATION_PROCESSOR_BEAN_NAME)) {\n\t\t\tRootBeanDefinition def = new RootBeanDefinition(CommonAnnotationBeanPostProcessor.class);\n\t\t\tdef.setSource(source);\n\t\t\tbeanDefs.add(registerPostProcessor(registry, def, COMMON_ANNOTATION_PROCESSOR_BEAN_NAME));\n\t\t}\n\n\t\t\n\t\t\n\t\tif (jsr250Present && !registry.containsBeanDefinition(JSR250_ANNOTATION_PROCESSOR_BEAN_NAME)) {\n\t\t\ttry {\n\t\t\t\tRootBeanDefinition def = new RootBeanDefinition(InitDestroyAnnotationBeanPostProcessor.class);\n\t\t\t\tdef.getPropertyValues().add(\"initAnnotationType\", classLoader.loadClass(\"javax.annotation.PostConstruct\"));\n\t\t\t\tdef.getPropertyValues().add(\"destroyAnnotationType\", classLoader.loadClass(\"javax.annotation.PreDestroy\"));\n\t\t\t\tdef.setSource(source);\n\t\t\t\tbeanDefs.add(registerPostProcessor(registry, def, JSR250_ANNOTATION_PROCESSOR_BEAN_NAME));\n\t\t\t}\n\t\t\tcatch (ClassNotFoundException ex) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tif (jpaPresent && !registry.containsBeanDefinition(PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME)) {\n\t\t\tRootBeanDefinition def = new RootBeanDefinition();\n\t\t\ttry {\n\t\t\t\tdef.setBeanClass(ClassUtils.forName(PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME,\n\t\t\t\t\t\tAnnotationConfigUtils.class.getClassLoader()));\n\t\t\t}\n\t\t\tcatch (ClassNotFoundException ex) {\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\"Cannot load optional framework class: \" + PERSISTENCE_ANNOTATION_PROCESSOR_CLASS_NAME, ex);\n\t\t\t}\n\t\t\tdef.setSource(source);\n\t\t\tbeanDefs.add(registerPostProcessor(registry, def, PERSISTENCE_ANNOTATION_PROCESSOR_BEAN_NAME));\n\t\t}\n\n\t\tif (!registry.containsBeanDefinition(EVENT_LISTENER_PROCESSOR_BEAN_NAME)) {\n\t\t\tRootBeanDefinition def = new RootBeanDefinition(EventListenerMethodProcessor.class);\n\t\t\tdef.setSource(source);\n\t\t\tbeanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_PROCESSOR_BEAN_NAME));\n\t\t}\n\n\t\tif (!registry.containsBeanDefinition(EVENT_LISTENER_FACTORY_BEAN_NAME)) {\n\t\t\tRootBeanDefinition def = new RootBeanDefinition(DefaultEventListenerFactory.class);\n\t\t\tdef.setSource(source);\n\t\t\tbeanDefs.add(registerPostProcessor(registry, def, EVENT_LISTENER_FACTORY_BEAN_NAME));\n\t\t}\n\n\t\treturn beanDefs;\n\t}", "summary_tokens": ["register", "all", "relevant", "annotation", "post", "processors", "in", "the", "given", "registry"], "project": "spring-framework"}
{"id": 3493, "code": "\tpublic static byte toByte(TypeConverter typeConverter, TypedValue typedValue) {\n\t\treturn convertValue(typeConverter, typedValue, Byte.class);\n\t}", "summary_tokens": ["attempt", "to", "convert", "a", "typed", "value", "to", "a", "byte", "using", "the", "supplied", "type", "converter"], "project": "spring-framework"}
{"id": 6216, "code": "\tpublic void setConnectionManager(ConnectionManager connectionManager) {\n\t\tthis.connectionManager = connectionManager;\n\t}", "summary_tokens": ["set", "the", "jca", "connection", "manager", "that", "should", "be", "used", "to", "create", "the", "desired", "connection", "factory"], "project": "spring-framework"}
{"id": 6155, "code": "\tpublic void test3IncrementCount2() {\n\t\tint count = dao.getCount(TEST_NAME);\n\t\tassertThat(count).as(\"Expected count=1 after test2IncrementCount1().\").isEqualTo(1);\n\n\t\tcount = dao.incrementCount(TEST_NAME);\n\t\tassertThat(count).as(\"Expected count=2 now.\").isEqualTo(2);\n\t}", "summary_tokens": ["the", "default", "implementation", "of", "this", "method", "assumes", "that", "the", "transaction", "for", "test", "0", "increment", "count", "0", "was", "committed"], "project": "spring-framework"}
{"id": 2557, "code": "Symbol addConstantModule(final String moduleName) {\n  return addConstantUtf8Reference(Symbol.CONSTANT_MODULE_TAG, moduleName);\n}", "summary_tokens": ["adds", "a", "constant", "module", "info", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 2696, "code": "\tpublic Set<String> getNamesForSuffix(@Nullable String nameSuffix) {\n\t\tString suffixToUse = (nameSuffix != null ? nameSuffix.trim().toUpperCase(Locale.ENGLISH) : \"\");\n\t\tSet<String> names = new HashSet<>();\n\t\tfor (String code : this.fieldCache.keySet()) {\n\t\t\tif (code.endsWith(suffixToUse)) {\n\t\t\t\tnames.add(code);\n\t\t\t}\n\t\t}\n\t\treturn names;\n\t}", "summary_tokens": ["return", "all", "names", "of", "the", "given", "group", "of", "constants"], "project": "spring-framework"}
{"id": 6899, "code": "\tprotected void initWriters() {\n\t\tinitTypedWriters();\n\t\tinitObjectWriters();\n\t}", "summary_tokens": ["reset", "and", "initialize", "typed", "writers", "and", "object", "writers"], "project": "spring-framework"}
{"id": 302, "code": "\tpublic void testRefreshCheckWithNonRefresh() throws Exception {\n\t\tCountingRefreshableTargetSource ts = new CountingRefreshableTargetSource();\n\t\tts.setRefreshCheckDelay(0);\n\n\t\tObject a = ts.getTarget();\n\t\tThread.sleep(1);\n\t\tObject b = ts.getTarget();\n\n\t\tassertThat(ts.getCallCount()).as(\"Should be one call to freshTarget to get initial target\").isEqualTo(1);\n\t\tassertThat(b).as(\"Returned objects should be the same - no refresh should occur\").isSameAs(a);\n\t}", "summary_tokens": ["test", "what", "happens", "when", "checking", "for", "refresh", "but", "not", "refreshing", "object"], "project": "spring-framework"}
{"id": 2420, "code": "public AnnotationVisitor visitAnnotation(final String descriptor, final boolean visible) {\n  if (fv != null) {\n    return fv.visitAnnotation(descriptor, visible);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "annotation", "of", "the", "field"], "project": "spring-framework"}
{"id": 8078, "code": "\tstatic Builder create(HttpMethod method, URI url) {\n\t\treturn new DefaultClientRequestBuilder(method, url);\n\t}", "summary_tokens": ["create", "a", "request", "builder", "with", "the", "given", "http", "method", "and", "url"], "project": "spring-framework"}
{"id": 9616, "code": "\tprotected boolean isRedirectContextRelative() {\n\t\treturn this.redirectContextRelative;\n\t}", "summary_tokens": ["return", "whether", "to", "interpret", "a", "given", "redirect", "url", "that", "starts", "with", "a", "slash", "as", "relative", "to", "the", "current", "servlet", "context", "i"], "project": "spring-framework"}
{"id": 4502, "code": "\tprotected void doInitialize() throws JMSException {\n\t\tif (!this.connectLazily) {\n\t\t\ttry {\n\t\t\t\testablishSharedConnection();\n\t\t\t}\n\t\t\tcatch (JMSException ex) {\n\t\t\t\tlogger.debug(\"Could not connect on initialization - registering message consumers lazily\", ex);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tinitializeConsumers();\n\t\t}\n\t}", "summary_tokens": ["creates", "the", "specified", "number", "of", "concurrent", "consumers", "in", "the", "form", "of", "a", "jms", "session", "plus", "associated", "message", "consumer"], "project": "spring-framework"}
{"id": 825, "code": "\tprotected final void registerBeanDefinitionDecoratorForAttribute(String attrName, BeanDefinitionDecorator dec) {\n\t\tthis.attributeDecorators.put(attrName, dec);\n\t}", "summary_tokens": ["subclasses", "can", "call", "this", "to", "register", "the", "supplied", "bean", "definition", "decorator", "to", "handle", "the", "specified", "attribute"], "project": "spring-framework"}
{"id": 5791, "code": "\tprotected List<RequestExpectation> getExpectations() {\n\t\treturn Collections.unmodifiableList(this.expectations);\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "of", "the", "expectations"], "project": "spring-framework"}
{"id": 1632, "code": "\tpublic void setIgnoredMethodMappings(Properties mappings) {\n\t\tthis.ignoredMethodMappings = new HashMap<>();\n\t\tfor (Enumeration<?> en = mappings.keys(); en.hasMoreElements();) {\n\t\t\tString beanKey = (String) en.nextElement();\n\t\t\tString[] methodNames = StringUtils.commaDelimitedListToStringArray(mappings.getProperty(beanKey));\n\t\t\tthis.ignoredMethodMappings.put(beanKey, Set.of(methodNames));\n\t\t}\n\t}", "summary_tokens": ["set", "the", "mappings", "of", "bean", "keys", "to", "a", "comma", "separated", "list", "of", "method", "names"], "project": "spring-framework"}
{"id": 9381, "code": "\tprotected String getEnctype() {\n\t\treturn this.enctype;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "enctype", "attribute"], "project": "spring-framework"}
{"id": 7787, "code": "\tpublic static String htmlEscapeDecimal(String input, String encoding) {\n\t\tAssert.notNull(input, \"Input is required\");\n\t\tAssert.notNull(encoding, \"Encoding is required\");\n\t\tStringBuilder escaped = new StringBuilder(input.length() * 2);\n\t\tfor (int i = 0; i < input.length(); i++) {\n\t\t\tchar character = input.charAt(i);\n\t\t\tif (characterEntityReferences.isMappedToReference(character, encoding)) {\n\t\t\t\tescaped.append(HtmlCharacterEntityReferences.DECIMAL_REFERENCE_START);\n\t\t\t\tescaped.append((int) character);\n\t\t\t\tescaped.append(HtmlCharacterEntityReferences.REFERENCE_END);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tescaped.append(character);\n\t\t\t}\n\t\t}\n\t\treturn escaped.toString();\n\t}", "summary_tokens": ["turn", "special", "characters", "into", "html", "character", "references"], "project": "spring-framework"}
{"id": 9368, "code": "\tpublic void setModelAttribute(String modelAttribute) {\n\t\tthis.modelAttribute = modelAttribute;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "form", "attribute", "in", "the", "model"], "project": "spring-framework"}
{"id": 6589, "code": "\tpublic void transactionShouldSucceedWithCallbackPreference() throws Exception {\n\t\tTransactionAttribute txatt = new DefaultTransactionAttribute();\n\n\t\tMapTransactionAttributeSource tas = new MapTransactionAttributeSource();\n\t\ttas.register(getNameMethod, txatt);\n\n\t\tMockCallbackPreferringTransactionManager ptm = new MockCallbackPreferringTransactionManager();\n\n\t\tTestBean tb = new TestBean();\n\t\tITestBean itb = (ITestBean) advised(tb, ptm, tas);\n\n\t\tcheckTransactionStatus(false);\n\t\titb.getName();\n\t\tcheckTransactionStatus(false);\n\n\t\tassertThat(ptm.getDefinition()).isSameAs(txatt);\n\t\tassertThat(ptm.getStatus().isRollbackOnly()).isFalse();\n\t}", "summary_tokens": ["check", "that", "a", "transaction", "is", "created", "and", "committed", "using", "callback", "preferring", "platform", "transaction", "manager"], "project": "spring-framework"}
{"id": 7522, "code": "\tpublic Mono<Void> filter(ServerWebExchange exchange, WebFilterChain chain) {\n\n\t\tif (exchange.getRequest().getMethod() != HttpMethod.POST) {\n\t\t\treturn chain.filter(exchange);\n\t\t}\n\n\t\treturn exchange.getFormData()\n\t\t\t\t.map(formData -> {\n\t\t\t\t\tString method = formData.getFirst(this.methodParamName);\n\t\t\t\t\treturn StringUtils.hasLength(method) ? mapExchange(exchange, method) : exchange;\n\t\t\t\t})\n\t\t\t\t.flatMap(chain::filter);\n\t}", "summary_tokens": ["transform", "an", "http", "post", "into", "another", "method", "based", "on", "method", "param", "name"], "project": "spring-framework"}
{"id": 4699, "code": "", "summary_tokens": ["for", "the", "no", "matching", "exception", "handler", "method", "constant"], "project": "spring-framework"}
{"id": 7982, "code": "\tpublic RequestedContentTypeResolver build() {\n\t\tList<RequestedContentTypeResolver> resolvers = (!this.candidates.isEmpty() ?\n\t\t\t\tthis.candidates.stream().map(Supplier::get).collect(Collectors.toList()) :\n\t\t\t\tCollections.singletonList(new HeaderContentTypeResolver()));\n\n\t\treturn exchange -> {\n\t\t\tfor (RequestedContentTypeResolver resolver : resolvers) {\n\t\t\t\tList<MediaType> mediaTypes = resolver.resolveMediaTypes(exchange);\n\t\t\t\tif (mediaTypes.equals(RequestedContentTypeResolver.MEDIA_TYPE_ALL_LIST)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\treturn mediaTypes;\n\t\t\t}\n\t\t\treturn RequestedContentTypeResolver.MEDIA_TYPE_ALL_LIST;\n\t\t};\n\t}", "summary_tokens": ["build", "a", "requested", "content", "type", "resolver", "that", "delegates", "to", "the", "list", "of", "resolvers", "configured", "through", "this", "builder"], "project": "spring-framework"}
{"id": 6691, "code": "\tpublic void setUpgrade(@Nullable String upgrade) {\n\t\tsetOrRemove(UPGRADE, upgrade);\n\t}", "summary_tokens": ["set", "the", "new", "value", "of", "the", "upgrade", "header"], "project": "spring-framework"}
{"id": 6633, "code": "\tpublic List<String> getAccessControlAllowHeaders() {\n\t\treturn getValuesAsList(ACCESS_CONTROL_ALLOW_HEADERS);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "access", "control", "allow", "headers", "response", "header"], "project": "spring-framework"}
{"id": 3832, "code": "\tpublic Set<String> getInParameterNames() {\n\t\treturn this.callMetaDataContext.getLimitedInParameterNames();\n\t}", "summary_tokens": ["get", "the", "names", "of", "in", "parameters", "to", "be", "used"], "project": "spring-framework"}
{"id": 1323, "code": "\tdefault String getListenerId() {\n\t\treturn \"\";\n\t}", "summary_tokens": ["return", "an", "optional", "identifier", "for", "the", "listener"], "project": "spring-framework"}
{"id": 7189, "code": "\tpublic void setBindEmptyMultipartFiles(boolean bindEmptyMultipartFiles) {\n\t\tthis.bindEmptyMultipartFiles = bindEmptyMultipartFiles;\n\t}", "summary_tokens": ["set", "whether", "to", "bind", "empty", "multipart", "file", "parameters"], "project": "spring-framework"}
{"id": 4853, "code": "\tpublic MessageConverter getMessageConverter() {\n\t\treturn this.messageConverter;\n\t}", "summary_tokens": ["return", "the", "configured", "message", "converter"], "project": "spring-framework"}
{"id": 2870, "code": "\tpublic void addNonOptionArg(String value) {\n\t\tthis.nonOptionArgs.add(value);\n\t}", "summary_tokens": ["add", "the", "given", "value", "to", "the", "list", "of", "non", "option", "arguments"], "project": "spring-framework"}
{"id": 7759, "code": "\tpublic int getContentSize() {\n\t\treturn this.content.size();\n\t}", "summary_tokens": ["return", "the", "current", "size", "of", "the", "cached", "content"], "project": "spring-framework"}
{"id": 1677, "code": "\tpublic void setDefaultDomain(String defaultDomain) {\n\t\tthis.defaultDomain = defaultDomain;\n\t}", "summary_tokens": ["specify", "the", "default", "domain", "to", "be", "used", "for", "generating", "object", "names", "when", "no", "source", "level", "metadata", "has", "been", "specified"], "project": "spring-framework"}
{"id": 4526, "code": "\tpublic void setConcurrency(String concurrency) {\n\t\ttry {\n\t\t\tint separatorIndex = concurrency.indexOf('-');\n\t\t\tif (separatorIndex != -1) {\n\t\t\t\tsetMaxConcurrency(Integer.parseInt(concurrency, separatorIndex + 1, concurrency.length(), 10));\n\t\t\t}\n\t\t\telse {\n\t\t\t\tsetMaxConcurrency(Integer.parseInt(concurrency));\n\t\t\t}\n\t\t}\n\t\tcatch (NumberFormatException ex) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid concurrency value [\" + concurrency + \"]: only \" +\n\t\t\t\t\t\"single maximum integer (e.g. \\\"5\\\") and minimum-maximum combo (e.g. \\\"3-5\\\") supported. \" +\n\t\t\t\t\t\"Note that JmsActivationSpecConfig will effectively ignore the minimum value and \" +\n\t\t\t\t\t\"scale from zero up to the number of consumers according to the maximum value.\");\n\t\t}\n\t}", "summary_tokens": ["specify", "concurrency", "limits", "via", "a", "lower", "upper", "string", "e"], "project": "spring-framework"}
{"id": 7070, "code": "\tprotected MultiValueMap<String, String> initQueryParams() {\n\t\tMultiValueMap<String, String> queryParams = new LinkedMultiValueMap<>();\n\t\tString query = getURI().getRawQuery();\n\t\tif (query != null) {\n\t\t\tMatcher matcher = QUERY_PATTERN.matcher(query);\n\t\t\twhile (matcher.find()) {\n\t\t\t\tString name = decodeQueryParam(matcher.group(1));\n\t\t\t\tString eq = matcher.group(2);\n\t\t\t\tString value = matcher.group(3);\n\t\t\t\tvalue = (value != null ? decodeQueryParam(value) : (StringUtils.hasLength(eq) ? \"\" : null));\n\t\t\t\tqueryParams.add(name, value);\n\t\t\t}\n\t\t}\n\t\treturn queryParams;\n\t}", "summary_tokens": ["a", "method", "for", "parsing", "of", "the", "query", "into", "name", "value", "pairs"], "project": "spring-framework"}
{"id": 523, "code": "\tpublic void setBeanNameSeparator(String beanNameSeparator) {\n\t\tthis.beanNameSeparator = beanNameSeparator;\n\t}", "summary_tokens": ["set", "the", "separator", "to", "expect", "between", "bean", "name", "and", "property", "path"], "project": "spring-framework"}
{"id": 7668, "code": "\tpublic HttpHeaders getHeaders() {\n\t\treturn getResponseHeaders();\n\t}", "summary_tokens": ["return", "headers", "to", "add", "to", "the", "error", "response", "e"], "project": "spring-framework"}
{"id": 6179, "code": "\tpublic static <T> T requiredUniqueResult(@Nullable Collection<T> results) throws IncorrectResultSizeDataAccessException {\n\t\tif (CollectionUtils.isEmpty(results)) {\n\t\t\tthrow new EmptyResultDataAccessException(1);\n\t\t}\n\t\tif (!CollectionUtils.hasUniqueObject(results)) {\n\t\t\tthrow new IncorrectResultSizeDataAccessException(1, results.size());\n\t\t}\n\t\treturn results.iterator().next();\n\t}", "summary_tokens": ["return", "a", "unique", "result", "object", "from", "the", "given", "collection"], "project": "spring-framework"}
{"id": 7468, "code": "\tpublic void setAfterMessageSuffix(String afterMessageSuffix) {\n\t\tthis.afterMessageSuffix = afterMessageSuffix;\n\t}", "summary_tokens": ["set", "the", "value", "that", "should", "be", "appended", "to", "the", "log", "message", "written", "i", "after", "i", "a", "request", "is", "processed"], "project": "spring-framework"}
{"id": 7712, "code": "\tpublic boolean hasCodecConfigurer() {\n\t\treturn (this.codecConfigurer != null);\n\t}", "summary_tokens": ["whether", "a", "server", "codec", "configurer", "is", "configured", "or", "not", "either", "detected", "from", "an", "application", "context", "or", "explicitly", "configured", "via", "codec", "configurer"], "project": "spring-framework"}
{"id": 3488, "code": "\tpublic static double toDouble(TypeConverter typeConverter, TypedValue typedValue) {\n\t\treturn convertValue(typeConverter, typedValue, Double.class);\n\t}", "summary_tokens": ["attempt", "to", "convert", "a", "typed", "value", "to", "a", "double", "using", "the", "supplied", "type", "converter"], "project": "spring-framework"}
{"id": 3035, "code": "\tpublic void debug(Throwable cause, Supplier<? extends CharSequence> messageSupplier) {\n\t\tif (this.log.isDebugEnabled()) {\n\t\t\tthis.log.debug(LogMessage.of(messageSupplier), cause);\n\t\t}\n\t}", "summary_tokens": ["log", "an", "error", "with", "debug", "log", "level"], "project": "spring-framework"}
{"id": 6552, "code": "\tpublic static void clearSynchronization() throws IllegalStateException {\n\t\tif (!isSynchronizationActive()) {\n\t\t\tthrow new IllegalStateException(\"Cannot deactivate transaction synchronization - not active\");\n\t\t}\n\t\tsynchronizations.remove();\n\t}", "summary_tokens": ["deactivate", "transaction", "synchronization", "for", "the", "current", "thread"], "project": "spring-framework"}
{"id": 453, "code": "\tpublic void afterPropertiesSet() throws Exception {\n\t\tif (isSingleton()) {\n\t\t\tthis.initialized = true;\n\t\t\tthis.singletonInstance = createInstance();\n\t\t\tthis.earlySingletonInstance = null;\n\t\t}\n\t}", "summary_tokens": ["eagerly", "create", "the", "singleton", "instance", "if", "necessary"], "project": "spring-framework"}
{"id": 5047, "code": "\tpublic String getBroadcastDestination() {\n\t\treturn this.broadcastDestination;\n\t}", "summary_tokens": ["return", "the", "configured", "destination", "for", "broadcasting", "user", "registry", "information"], "project": "spring-framework"}
{"id": 6851, "code": "\tpublic Map<MimeType, ObjectMapper> getObjectMappersForType(Class<?> clazz) {\n\t\tfor (Map.Entry<Class<?>, Map<MimeType, ObjectMapper>> entry : getObjectMapperRegistrations().entrySet()) {\n\t\t\tif (entry.getKey().isAssignableFrom(clazz)) {\n\t\t\t\treturn entry.getValue();\n\t\t\t}\n\t\t}\n\t\treturn Collections.emptyMap();\n\t}", "summary_tokens": ["return", "object", "mapper", "registrations", "for", "the", "given", "class", "if", "any"], "project": "spring-framework"}
{"id": 6646, "code": "\tpublic void setAcceptCharset(List<Charset> acceptableCharsets) {\n\t\tStringJoiner joiner = new StringJoiner(\", \");\n\t\tfor (Charset charset : acceptableCharsets) {\n\t\t\tjoiner.add(charset.name().toLowerCase(Locale.ENGLISH));\n\t\t}\n\t\tset(ACCEPT_CHARSET, joiner.toString());\n\t}", "summary_tokens": ["set", "the", "list", "of", "acceptable", "charset", "charsets", "as", "specified", "by", "the", "accept", "charset", "header"], "project": "spring-framework"}
{"id": 9721, "code": "\tpublic void setUriResolver(URIResolver uriResolver) {\n\t\tthis.uriResolver = uriResolver;\n\t}", "summary_tokens": ["set", "the", "uriresolver", "used", "in", "the", "transform"], "project": "spring-framework"}
{"id": 6658, "code": "\tpublic ContentDisposition getContentDisposition() {\n\t\tString contentDisposition = getFirst(CONTENT_DISPOSITION);\n\t\tif (StringUtils.hasText(contentDisposition)) {\n\t\t\treturn ContentDisposition.parse(contentDisposition);\n\t\t}\n\t\treturn ContentDisposition.empty();\n\t}", "summary_tokens": ["return", "a", "parsed", "representation", "of", "the", "content", "disposition", "header"], "project": "spring-framework"}
{"id": 900, "code": "\tprotected SortDefinition copySortDefinition(SortDefinition sort) {\n\t\treturn new MutableSortDefinition(sort);\n\t}", "summary_tokens": ["create", "a", "deep", "copy", "of", "the", "given", "sort", "definition", "for", "use", "as", "state", "holder", "to", "compare", "a", "modified", "sort", "definition", "against"], "project": "spring-framework"}
{"id": 2275, "code": "\tpublic ResourceHints resources() {\n\t\treturn this.resources;\n\t}", "summary_tokens": ["provide", "access", "to", "resource", "based", "hints"], "project": "spring-framework"}
{"id": 2866, "code": "\tpublic void addOptionArg(String optionName, @Nullable String optionValue) {\n\t\tif (!this.optionArgs.containsKey(optionName)) {\n\t\t\tthis.optionArgs.put(optionName, new ArrayList<>());\n\t\t}\n\t\tif (optionValue != null) {\n\t\t\tthis.optionArgs.get(optionName).add(optionValue);\n\t\t}\n\t}", "summary_tokens": ["add", "an", "option", "argument", "for", "the", "given", "option", "name", "and", "add", "the", "given", "value", "to", "the", "list", "of", "values", "associated", "with", "this", "option", "of", "which", "there", "may", "be", "zero", "or", "more"], "project": "spring-framework"}
{"id": 2741, "code": "\tpublic Object getEmptyValue() {\n\t\tAssert.state(this.emptyValueSupplier != null, \"Empty values not supported\");\n\t\treturn this.emptyValueSupplier.get();\n\t}", "summary_tokens": ["return", "an", "empty", "value", "instance", "for", "the", "underlying", "reactive", "or", "async", "type"], "project": "spring-framework"}
{"id": 6148, "code": "\tpublic void afterTransaction() {\n\t\tassertThat(deletePerson(YODA)).as(\"Deleting yoda\").isEqualTo(1);\n\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tassertNumRowsInPersonTable(2, \"after a transactional test method\");\n\t}", "summary_tokens": ["overrides", "after", "transaction", "in", "order", "to", "assert", "a", "different", "result"], "project": "spring-framework"}
{"id": 2304, "code": "public void visit(final String name, final Object value) {\n  if (av != null) {\n    av.visit(name, value);\n  }\n}", "summary_tokens": ["visits", "a", "primitive", "value", "of", "the", "annotation"], "project": "spring-framework"}
{"id": 1693, "code": "\tpublic static String getAttributeName(PropertyDescriptor property, boolean useStrictCasing) {\n\t\tif (useStrictCasing) {\n\t\t\treturn StringUtils.capitalize(property.getName());\n\t\t}\n\t\telse {\n\t\t\treturn property.getName();\n\t\t}\n\t}", "summary_tokens": ["return", "the", "jmx", "attribute", "name", "to", "use", "for", "the", "given", "java", "beans", "property"], "project": "spring-framework"}
{"id": 6448, "code": "\tprotected final SuspendedResourcesHolder suspend(@Nullable Object transaction) throws TransactionException {\n\t\tif (TransactionSynchronizationManager.isSynchronizationActive()) {\n\t\t\tList<TransactionSynchronization> suspendedSynchronizations = doSuspendSynchronization();\n\t\t\ttry {\n\t\t\t\tObject suspendedResources = null;\n\t\t\t\tif (transaction != null) {\n\t\t\t\t\tsuspendedResources = doSuspend(transaction);\n\t\t\t\t}\n\t\t\t\tString name = TransactionSynchronizationManager.getCurrentTransactionName();\n\t\t\t\tTransactionSynchronizationManager.setCurrentTransactionName(null);\n\t\t\t\tboolean readOnly = TransactionSynchronizationManager.isCurrentTransactionReadOnly();\n\t\t\t\tTransactionSynchronizationManager.setCurrentTransactionReadOnly(false);\n\t\t\t\tInteger isolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel();\n\t\t\t\tTransactionSynchronizationManager.setCurrentTransactionIsolationLevel(null);\n\t\t\t\tboolean wasActive = TransactionSynchronizationManager.isActualTransactionActive();\n\t\t\t\tTransactionSynchronizationManager.setActualTransactionActive(false);\n\t\t\t\treturn new SuspendedResourcesHolder(\n\t\t\t\t\t\tsuspendedResources, suspendedSynchronizations, name, readOnly, isolationLevel, wasActive);\n\t\t\t}\n\t\t\tcatch (RuntimeException | Error ex) {\n\t\t\t\t\n\t\t\t\tdoResumeSynchronization(suspendedSynchronizations);\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t}\n\t\telse if (transaction != null) {\n\t\t\t\n\t\t\tObject suspendedResources = doSuspend(transaction);\n\t\t\treturn new SuspendedResourcesHolder(suspendedResources);\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["suspend", "the", "given", "transaction"], "project": "spring-framework"}
{"id": 6840, "code": "\tpublic static <T> Builder<T> builder(T data) {\n\t\treturn new BuilderImpl<>(data);\n\t}", "summary_tokens": ["return", "a", "builder", "for", "a", "sse", "event", "populated", "with", "the", "given", "data", "data"], "project": "spring-framework"}
{"id": 7594, "code": "\tpublic Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n\t\t\tNativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception {\n\n\t\tHandlerMethodArgumentResolver resolver = getArgumentResolver(parameter);\n\t\tif (resolver == null) {\n\t\t\tthrow new IllegalArgumentException(\"Unsupported parameter type [\" +\n\t\t\t\t\tparameter.getParameterType().getName() + \"]. supportsParameter should be called first.\");\n\t\t}\n\t\treturn resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory);\n\t}", "summary_tokens": ["iterate", "over", "registered", "handler", "method", "argument", "resolver", "handler", "method", "argument", "resolvers", "and", "invoke", "the", "one", "that", "supports", "it"], "project": "spring-framework"}
{"id": 5408, "code": "\tvoid addNamedParameter(String parameterName, int startIndex, int endIndex) {\n\t\tthis.parameterNames.add(parameterName);\n\t\tthis.parameterIndexes.add(new int[] {startIndex, endIndex});\n\t}", "summary_tokens": ["add", "a", "named", "parameter", "parsed", "from", "this", "sql", "statement"], "project": "spring-framework"}
{"id": 8831, "code": "\tpublic Map<String, ?> getUrlMap() {\n\t\treturn this.urlMap;\n\t}", "summary_tokens": ["allow", "map", "access", "to", "the", "url", "path", "mappings", "with", "the", "option", "to", "add", "or", "override", "specific", "entries"], "project": "spring-framework"}
{"id": 8179, "code": "\tpublic void setUseCaseSensitiveMatch(boolean caseSensitiveMatch) {\n\t\tthis.patternParser.setCaseSensitive(caseSensitiveMatch);\n\t}", "summary_tokens": ["shortcut", "method", "for", "setting", "the", "same", "property", "on", "the", "underlying", "pattern", "parser", "in", "use"], "project": "spring-framework"}
{"id": 1883, "code": "\tpublic static CronField parseMinutes(String value) {\n\t\treturn BitsCronField.parseMinutes(value);\n\t}", "summary_tokens": ["parse", "the", "given", "value", "into", "a", "minutes", "cron", "field", "the", "second", "entry", "of", "a", "cron", "expression"], "project": "spring-framework"}
{"id": 8331, "code": "\tprotected Mono<Map<String, Object>> getModelAttributes(\n\t\t\t@Nullable Map<String, ?> model, ServerWebExchange exchange) {\n\n\t\tMap<String, Object> attributes;\n\t\tif (model != null) {\n\t\t\tattributes = new ConcurrentHashMap<>(model.size());\n\t\t\tfor (Map.Entry<String, ?> entry : model.entrySet()) {\n\t\t\t\tif (entry.getValue() != null) {\n\t\t\t\t\tattributes.put(entry.getKey(), entry.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tattributes = new ConcurrentHashMap<>(0);\n\t\t}\n\n\t\treturn resolveAsyncAttributes(attributes, exchange)\n\t\t\t\t.doOnTerminate(() -> exchange.getAttributes().remove(BINDING_CONTEXT_ATTRIBUTE))\n\t\t\t\t.thenReturn(attributes);\n\t}", "summary_tokens": ["prepare", "the", "model", "to", "use", "for", "rendering"], "project": "spring-framework"}
{"id": 4468, "code": "\tpublic final int getIdleTaskExecutionLimit() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\treturn this.idleTaskExecutionLimit;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "limit", "for", "idle", "executions", "of", "a", "consumer", "task"], "project": "spring-framework"}
{"id": 3731, "code": "\tpublic boolean isFunction() {\n\t\treturn this.function;\n\t}", "summary_tokens": ["check", "whether", "this", "call", "is", "a", "function", "call"], "project": "spring-framework"}
{"id": 9783, "code": "\tpublic String getSockJsTaskSchedulerStatsInfo() {\n\t\tif (this.sockJsTaskScheduler == null) {\n\t\t\treturn \"null\";\n\t\t}\n\t\tif (this.sockJsTaskScheduler instanceof ThreadPoolTaskScheduler) {\n\t\t\treturn getExecutorStatsInfo(((ThreadPoolTaskScheduler) this.sockJsTaskScheduler)\n\t\t\t\t\t.getScheduledThreadPoolExecutor());\n\t\t}\n\t\treturn \"unknown\";\n\t}", "summary_tokens": ["get", "stats", "about", "the", "sock", "js", "task", "scheduler"], "project": "spring-framework"}
{"id": 123, "code": "\tpublic void setFrozen(boolean frozen) {\n\t\tthis.freezeProxy = frozen;\n\t}", "summary_tokens": ["set", "whether", "the", "proxy", "should", "be", "frozen", "preventing", "advice", "from", "being", "added", "to", "it", "once", "it", "is", "created"], "project": "spring-framework"}
{"id": 3391, "code": "\tpublic static DataSize of(long amount, DataUnit unit) {\n\t\tAssert.notNull(unit, \"Unit must not be null\");\n\t\treturn new DataSize(Math.multiplyExact(amount, unit.size().toBytes()));\n\t}", "summary_tokens": ["obtain", "a", "data", "size", "representing", "an", "amount", "in", "the", "specified", "data", "unit"], "project": "spring-framework"}
{"id": 9509, "code": "\tprotected View createView(String viewName, Locale locale) throws Exception {\n\t\treturn loadView(viewName, locale);\n\t}", "summary_tokens": ["create", "the", "actual", "view", "object"], "project": "spring-framework"}
{"id": 9693, "code": "\tprotected Template getTemplate(String viewUrl) throws Exception {\n\t\tAssert.state(this.engine != null, \"No MarkupTemplateEngine set\");\n\t\ttry {\n\t\t\treturn this.engine.createTemplateByPath(viewUrl);\n\t\t}\n\t\tcatch (ClassNotFoundException ex) {\n\t\t\tThrowable cause = (ex.getCause() != null ? ex.getCause() : ex);\n\t\t\tthrow new ServletException(\n\t\t\t\t\t\"Could not find class while rendering Groovy Markup view with name '\" +\n\t\t\t\t\tgetUrl() + \"': \" + ex.getMessage() + \"'\", cause);\n\t\t}\n\t}", "summary_tokens": ["return", "a", "template", "compiled", "by", "the", "configured", "groovy", "markup", "template", "engine", "for", "the", "given", "view", "url"], "project": "spring-framework"}
{"id": 8205, "code": "\tprotected Mono<String> resolveUrlPath(String resourcePath, ServerWebExchange exchange,\n\t\t\tResource resource, ResourceTransformerChain transformerChain) {\n\n\t\tif (resourcePath.startsWith(\"/\")) {\n\t\t\t\n\t\t\tResourceUrlProvider urlProvider = getResourceUrlProvider();\n\t\t\treturn (urlProvider != null ? urlProvider.getForUriString(resourcePath, exchange) : Mono.empty());\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\treturn transformerChain.getResolverChain()\n\t\t\t\t\t.resolveUrlPath(resourcePath, Collections.singletonList(resource));\n\t\t}\n\t}", "summary_tokens": ["a", "transformer", "can", "use", "this", "method", "when", "a", "resource", "being", "transformed", "contains", "links", "to", "other", "resources"], "project": "spring-framework"}
{"id": 11, "code": "\tpublic String[] getParameterNames(Constructor<?> ctor) {\n\t\tif (this.raiseExceptions) {\n\t\t\tthrow new UnsupportedOperationException(\"An advice method can never be a constructor\");\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\t\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["an", "advice", "method", "can", "never", "be", "a", "constructor", "in", "spring"], "project": "spring-framework"}
{"id": 398, "code": "\tpublic int getNumberOfBeansFound() {\n\t\treturn this.numberOfBeansFound;\n\t}", "summary_tokens": ["return", "the", "number", "of", "beans", "found", "when", "only", "one", "matching", "bean", "was", "expected"], "project": "spring-framework"}
{"id": 927, "code": "\tpublic void testBeanAutowiredWithFactoryBean() {\n\t\tbf.registerBeanDefinition(\"factoryBeanDependentBean\", new RootBeanDefinition(FactoryBeanDependentBean.class));\n\t\tbf.registerSingleton(\"stringFactoryBean\", new StringFactoryBean());\n\n\t\tfinal StringFactoryBean factoryBean = (StringFactoryBean) bf.getBean(\"&stringFactoryBean\");\n\t\tfinal FactoryBeanDependentBean bean = (FactoryBeanDependentBean) bf.getBean(\"factoryBeanDependentBean\");\n\n\t\tassertThat(factoryBean).as(\"The singleton StringFactoryBean should have been registered.\").isNotNull();\n\t\tassertThat(bean).as(\"The factoryBeanDependentBean should have been registered.\").isNotNull();\n\t\tassertThat(bean.getFactoryBean()).as(\"The FactoryBeanDependentBean should have been autowired 'by type' with the StringFactoryBean.\").isEqualTo(factoryBean);\n\t}", "summary_tokens": ["verifies", "that", "a", "dependency", "on", "a", "factory", "bean", "can", "be", "autowired", "via", "autowired", "specifically", "addressing", "the", "jira", "issue", "raised", "in", "a", "href", "https", "opensource"], "project": "spring-framework"}
{"id": 4691, "code": "\tpublic void setArgumentResolvers(@Nullable List<HandlerMethodArgumentResolver> argumentResolvers) {\n\t\tif (argumentResolvers == null) {\n\t\t\tthis.argumentResolvers.clear();\n\t\t\treturn;\n\t\t}\n\t\tthis.argumentResolvers.addResolvers(argumentResolvers);\n\t}", "summary_tokens": ["configure", "the", "complete", "list", "of", "supported", "argument", "types", "effectively", "overriding", "the", "ones", "configured", "by", "default"], "project": "spring-framework"}
{"id": 6463, "code": "\tprivate void cleanupAfterCompletion(DefaultTransactionStatus status) {\n\t\tstatus.setCompleted();\n\t\tif (status.isNewSynchronization()) {\n\t\t\tTransactionSynchronizationManager.clear();\n\t\t}\n\t\tif (status.isNewTransaction()) {\n\t\t\tdoCleanupAfterCompletion(status.getTransaction());\n\t\t}\n\t\tif (status.getSuspendedResources() != null) {\n\t\t\tif (status.isDebug()) {\n\t\t\t\tlogger.debug(\"Resuming suspended transaction after completion of inner transaction\");\n\t\t\t}\n\t\t\tObject transaction = (status.hasTransaction() ? status.getTransaction() : null);\n\t\t\tresume(transaction, (SuspendedResourcesHolder) status.getSuspendedResources());\n\t\t}\n\t}", "summary_tokens": ["clean", "up", "after", "completion", "clearing", "synchronization", "if", "necessary", "and", "invoking", "do", "cleanup", "after", "completion"], "project": "spring-framework"}
{"id": 1662, "code": "\tpublic void setIndex(int index) {\n\t\tthis.index = index;\n\t}", "summary_tokens": ["set", "the", "index", "of", "this", "parameter", "in", "the", "operation", "signature"], "project": "spring-framework"}
{"id": 1456, "code": "\tprotected MessageFormat getMessageFormat(ResourceBundle bundle, String code, Locale locale)\n\t\t\tthrows MissingResourceException {\n\n\t\tMap<String, Map<Locale, MessageFormat>> codeMap = this.cachedBundleMessageFormats.get(bundle);\n\t\tMap<Locale, MessageFormat> localeMap = null;\n\t\tif (codeMap != null) {\n\t\t\tlocaleMap = codeMap.get(code);\n\t\t\tif (localeMap != null) {\n\t\t\t\tMessageFormat result = localeMap.get(locale);\n\t\t\t\tif (result != null) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tString msg = getStringOrNull(bundle, code);\n\t\tif (msg != null) {\n\t\t\tif (codeMap == null) {\n\t\t\t\tcodeMap = this.cachedBundleMessageFormats.computeIfAbsent(bundle, b -> new ConcurrentHashMap<>());\n\t\t\t}\n\t\t\tif (localeMap == null) {\n\t\t\t\tlocaleMap = codeMap.computeIfAbsent(code, c -> new ConcurrentHashMap<>());\n\t\t\t}\n\t\t\tMessageFormat result = createMessageFormat(msg, locale);\n\t\t\tlocaleMap.put(locale, result);\n\t\t\treturn result;\n\t\t}\n\n\t\treturn null;\n\t}", "summary_tokens": ["return", "a", "message", "format", "for", "the", "given", "bundle", "and", "code", "fetching", "already", "generated", "message", "formats", "from", "the", "cache"], "project": "spring-framework"}
{"id": 4500, "code": "\tpublic void setTaskExecutor(Executor taskExecutor) {\n\t\tthis.taskExecutor = taskExecutor;\n\t}", "summary_tokens": ["set", "the", "spring", "task", "executor", "to", "use", "for", "executing", "the", "listener", "once", "a", "message", "has", "been", "received", "by", "the", "provider"], "project": "spring-framework"}
{"id": 2243, "code": "\tstatic MethodName of(String... parts) {\n\t\tAssert.notNull(parts, \"'parts' must not be null\");\n\t\treturn new MethodName(join(parts));\n\t}", "summary_tokens": ["create", "a", "new", "method", "name", "from", "the", "specific", "parts"], "project": "spring-framework"}
{"id": 2594, "code": "public static TypeReference newTypeReference(final int sort) {\n  return new TypeReference(sort << 24);\n}", "summary_tokens": ["returns", "a", "type", "reference", "of", "the", "given", "sort"], "project": "spring-framework"}
{"id": 5507, "code": "\tpublic ApplicationContext getParentApplicationContext() {\n\t\tif (this.parent == null) {\n\t\t\treturn null;\n\t\t}\n\t\tAssert.state(this.cacheAwareContextLoaderDelegate != null,\n\t\t\t\t\"Cannot retrieve a parent application context without access to the CacheAwareContextLoaderDelegate\");\n\t\treturn this.cacheAwareContextLoaderDelegate.loadContext(this.parent);\n\t}", "summary_tokens": ["get", "the", "parent", "application", "context", "for", "the", "context", "defined", "by", "this", "merged", "context", "configuration", "from", "the", "context", "cache"], "project": "spring-framework"}
{"id": 1485, "code": "\tpublic static DateTimeFormatter getFormatter(DateTimeFormatter formatter, @Nullable Locale locale) {\n\t\tDateTimeFormatter formatterToUse = (locale != null ? formatter.withLocale(locale) : formatter);\n\t\tDateTimeContext context = getDateTimeContext();\n\t\treturn (context != null ? context.getFormatter(formatterToUse) : formatterToUse);\n\t}", "summary_tokens": ["obtain", "a", "date", "time", "formatter", "with", "user", "specific", "settings", "applied", "to", "the", "given", "base", "formatter"], "project": "spring-framework"}
{"id": 5379, "code": "\tpublic void setBlockCommentEndDelimiter(String blockCommentEndDelimiter) {\n\t\tAssert.hasText(blockCommentEndDelimiter, \"'blockCommentEndDelimiter' must not be null or empty\");\n\t\tthis.blockCommentEndDelimiter = blockCommentEndDelimiter;\n\t}", "summary_tokens": ["set", "the", "end", "delimiter", "that", "identifies", "block", "comments", "within", "the", "sql", "scripts"], "project": "spring-framework"}
{"id": 7570, "code": "\tprotected void validateValueIfApplicable(WebDataBinder binder, MethodParameter parameter,\n\t\t\tClass<?> targetType, String fieldName, @Nullable Object value) {\n\n\t\tfor (Annotation ann : parameter.getParameterAnnotations()) {\n\t\t\tObject[] validationHints = ValidationAnnotationUtils.determineValidationHints(ann);\n\t\t\tif (validationHints != null) {\n\t\t\t\tfor (Validator validator : binder.getValidators()) {\n\t\t\t\t\tif (validator instanceof SmartValidator) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t((SmartValidator) validator).validateValue(targetType, fieldName, value,\n\t\t\t\t\t\t\t\t\tbinder.getBindingResult(), validationHints);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcatch (IllegalArgumentException ex) {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["validate", "the", "specified", "candidate", "value", "if", "applicable"], "project": "spring-framework"}
{"id": 8936, "code": "\tprotected RequestMappingInfo getMatchingMapping(RequestMappingInfo info, HttpServletRequest request) {\n\t\treturn info.getMatchingCondition(request);\n\t}", "summary_tokens": ["check", "if", "the", "given", "request", "mapping", "info", "matches", "the", "current", "request", "and", "return", "a", "potentially", "new", "instance", "with", "conditions", "that", "match", "the", "current", "request", "for", "example", "with", "a", "subset", "of", "url", "patterns"], "project": "spring-framework"}
{"id": 4678, "code": "\tpublic ReactiveAdapterRegistry getAdapterRegistry() {\n\t\treturn this.adapterRegistry;\n\t}", "summary_tokens": ["return", "the", "configured", "reactive", "adapter", "registry"], "project": "spring-framework"}
{"id": 3134, "code": "\tpublic static String convertResourcePathToClassName(String resourcePath) {\n\t\tAssert.notNull(resourcePath, \"Resource path must not be null\");\n\t\treturn resourcePath.replace(PATH_SEPARATOR, PACKAGE_SEPARATOR);\n\t}", "summary_tokens": ["convert", "a", "based", "resource", "path", "to", "a"], "project": "spring-framework"}
{"id": 6546, "code": "\tpublic static Object unbindResourceIfPossible(Object key) {\n\t\tObject actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key);\n\t\treturn doUnbindResource(actualKey);\n\t}", "summary_tokens": ["unbind", "a", "resource", "for", "the", "given", "key", "from", "the", "current", "thread"], "project": "spring-framework"}
{"id": 2633, "code": "public static void process_array(CodeEmitter e, Type type, ProcessArrayCallback callback) {\n    Type componentType = TypeUtils.getComponentType(type);\n    Local array = e.make_local();\n    Local loopvar = e.make_local(Type.INT_TYPE);\n    Label loopbody = e.make_label();\n    Label checkloop = e.make_label();\n    e.store_local(array);\n    e.push(0);\n    e.store_local(loopvar);\n    e.goTo(checkloop);\n\n    e.mark(loopbody);\n    e.load_local(array);\n    e.load_local(loopvar);\n    e.array_load(componentType);\n    callback.processElement(componentType);\n    e.iinc(loopvar, 1);\n\n    e.mark(checkloop);\n    e.load_local(loopvar);\n    e.load_local(array);\n    e.arraylength();\n    e.if_icmp(CodeEmitter.LT, loopbody);\n}", "summary_tokens": ["process", "an", "array", "on", "the", "stack"], "project": "spring-framework"}
{"id": 9089, "code": "\tpublic int getFlashMapTimeout() {\n\t\treturn this.flashMapTimeout;\n\t}", "summary_tokens": ["return", "the", "amount", "of", "time", "in", "seconds", "before", "a", "flash", "map", "expires"], "project": "spring-framework"}
{"id": 315, "code": "\tpublic static void clearClassLoader(@Nullable ClassLoader classLoader) {\n\t\tacceptedClassLoaders.removeIf(registeredLoader ->\n\t\t\t\tisUnderneathClassLoader(registeredLoader, classLoader));\n\t\tstrongClassCache.keySet().removeIf(beanClass ->\n\t\t\t\tisUnderneathClassLoader(beanClass.getClassLoader(), classLoader));\n\t\tsoftClassCache.keySet().removeIf(beanClass ->\n\t\t\t\tisUnderneathClassLoader(beanClass.getClassLoader(), classLoader));\n\t}", "summary_tokens": ["clear", "the", "introspection", "cache", "for", "the", "given", "class", "loader", "removing", "the", "introspection", "results", "for", "all", "classes", "underneath", "that", "class", "loader", "and", "removing", "the", "class", "loader", "and", "its", "children", "from", "the", "acceptance", "list"], "project": "spring-framework"}
{"id": 5775, "code": "\tpublic void assertNodeList(byte[] content, @Nullable String encoding, Matcher<? super NodeList> matcher)\n\t\t\tthrows Exception {\n\n\t\tDocument document = parseXmlByteArray(content, encoding);\n\t\tNodeList nodeList = evaluateXpath(document, XPathConstants.NODESET, NodeList.class);\n\t\tMatcherAssert.assertThat(\"XPath \" + this.getXpathExpression(), nodeList, matcher);\n\t}", "summary_tokens": ["parse", "the", "content", "evaluate", "the", "xpath", "expression", "as", "a", "node", "list", "and", "assert", "it", "with", "the", "given", "matcher", "node", "list"], "project": "spring-framework"}
{"id": 2813, "code": "\tpublic void setLogger(Log logger) {\n\t\tthis.logger = logger;\n\t}", "summary_tokens": ["set", "an", "alternative", "logger", "to", "use", "than", "the", "one", "based", "on", "the", "class", "name"], "project": "spring-framework"}
{"id": 8102, "code": "\tpublic static WebClientAdapter forClient(WebClient webClient) {\n\t\treturn new WebClientAdapter(webClient);\n\t}", "summary_tokens": ["create", "a", "web", "client", "adapter", "for", "the", "given", "web", "client", "instance"], "project": "spring-framework"}
{"id": 2544, "code": "Symbol addConstantInteger(final int value) {\n  return addConstantIntegerOrFloat(Symbol.CONSTANT_INTEGER_TAG, value);\n}", "summary_tokens": ["adds", "a", "constant", "integer", "info", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 4221, "code": "\tpublic String getId() {\n\t\treturn this.id;\n\t}", "summary_tokens": ["return", "the", "id", "of", "this", "endpoint", "possibly", "generated"], "project": "spring-framework"}
{"id": 7626, "code": "\tpublic ModelAndViewContainer addAttribute(Object value) {\n\t\tgetModel().addAttribute(value);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "supplied", "attribute", "to", "the", "underlying", "model"], "project": "spring-framework"}
{"id": 6305, "code": "\tpublic TransactionManager getTransactionManager() {\n\t\treturn this.transactionManager;\n\t}", "summary_tokens": ["return", "the", "jta", "transaction", "manager", "that", "this", "transaction", "manager", "uses", "if", "any"], "project": "spring-framework"}
{"id": 3834, "code": "\tpublic String getCatalogName() {\n\t\treturn this.callMetaDataContext.getCatalogName();\n\t}", "summary_tokens": ["get", "the", "catalog", "name", "used"], "project": "spring-framework"}
{"id": 5176, "code": "\tpublic LocalSessionFactoryBuilder setBeanContainer(ConfigurableListableBeanFactory beanFactory) {\n\t\tgetProperties().put(AvailableSettings.BEAN_CONTAINER, new SpringBeanContainer(beanFactory));\n\t\treturn this;\n\t}", "summary_tokens": ["set", "a", "hibernate", "org"], "project": "spring-framework"}
{"id": 2391, "code": "public FieldVisitor visitField(\n    final int access,\n    final String name,\n    final String descriptor,\n    final String signature,\n    final Object value) {\n  if (cv != null) {\n    return cv.visitField(access, name, descriptor, signature, value);\n  }\n  return null;\n}", "summary_tokens": ["visits", "a", "field", "of", "the", "class"], "project": "spring-framework"}
{"id": 3133, "code": "\tpublic static boolean isAssignableValue(Class<?> type, @Nullable Object value) {\n\t\tAssert.notNull(type, \"Type must not be null\");\n\t\treturn (value != null ? isAssignable(type, value.getClass()) : !type.isPrimitive());\n\t}", "summary_tokens": ["determine", "if", "the", "given", "type", "is", "assignable", "from", "the", "given", "value", "assuming", "setting", "by", "reflection"], "project": "spring-framework"}
{"id": 9770, "code": "\tpublic void setTaskExecutor(TaskExecutor taskExecutor) {\n\t\tAssert.notNull(taskExecutor, \"TaskExecutor must not be null\");\n\t\tthis.taskExecutor = taskExecutor;\n\t}", "summary_tokens": ["set", "a", "task", "executor", "to", "use", "to", "open", "connections"], "project": "spring-framework"}
{"id": 544, "code": "\tprotected String convertPropertyValue(String originalValue) {\n\t\treturn originalValue;\n\t}", "summary_tokens": ["convert", "the", "given", "property", "value", "from", "the", "properties", "source", "to", "the", "value", "which", "should", "be", "applied"], "project": "spring-framework"}
{"id": 7531, "code": "\tprotected WebApplicationContext getWebApplicationContext(FacesContext facesContext) {\n\t\treturn FacesContextUtils.getRequiredWebApplicationContext(facesContext);\n\t}", "summary_tokens": ["retrieve", "the", "web", "application", "context", "to", "delegate", "bean", "name", "resolution", "to"], "project": "spring-framework"}
{"id": 158, "code": "\tstatic void setCurrentProxiedBeanName(@Nullable String beanName) {\n\t\tif (beanName != null) {\n\t\t\tcurrentProxiedBeanName.set(beanName);\n\t\t}\n\t\telse {\n\t\t\tcurrentProxiedBeanName.remove();\n\t\t}\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "currently", "proxied", "bean", "instance"], "project": "spring-framework"}
{"id": 3250, "code": "\tpublic static <T extends MimeType> void sortBySpecificity(List<T> mimeTypes) {\n\t\tAssert.notNull(mimeTypes, \"'mimeTypes' must not be null\");\n\t\tAssert.isTrue(mimeTypes.size() <= 50, \"Too many elements\");\n\n\t\tbubbleSort(mimeTypes, MimeType::isLessSpecific);\n\t}", "summary_tokens": ["sorts", "the", "given", "list", "of", "mime", "type", "objects", "by", "mime", "type", "is", "more", "specific", "mime", "type", "specificity"], "project": "spring-framework"}
{"id": 5381, "code": "\tpublic void setIgnoreFailedDrops(boolean ignoreFailedDrops) {\n\t\tthis.ignoreFailedDrops = ignoreFailedDrops;\n\t}", "summary_tokens": ["flag", "to", "indicate", "that", "a", "failed", "sql", "drop", "statement", "can", "be", "ignored"], "project": "spring-framework"}
{"id": 3211, "code": "\tpublic int size() {\n\t\treturn (this.alreadyBufferedSize + this.index);\n\t}", "summary_tokens": ["return", "the", "number", "of", "bytes", "stored", "in", "this", "code", "fast", "byte", "array", "output", "stream", "code"], "project": "spring-framework"}
{"id": 5079, "code": "\tpublic MessageBuilder<T> copyHeadersIfAbsent(@Nullable Map<String, ?> headersToCopy) {\n\t\tthis.headerAccessor.copyHeadersIfAbsent(headersToCopy);\n\t\treturn this;\n\t}", "summary_tokens": ["copy", "the", "name", "value", "pairs", "from", "the", "provided", "map"], "project": "spring-framework"}
{"id": 386, "code": "\tpublic MethodParameter getMethodParameter() {\n\t\treturn this.methodParameter;\n\t}", "summary_tokens": ["return", "the", "wrapped", "method", "parameter", "if", "any"], "project": "spring-framework"}
{"id": 6885, "code": "\tprotected byte[] generateMultipartBoundary() {\n\t\treturn MimeTypeUtils.generateMultipartBoundary();\n\t}", "summary_tokens": ["generate", "a", "multipart", "boundary"], "project": "spring-framework"}
{"id": 6420, "code": "\tpublic static Mono<Void> invokeAfterCommit(Collection<TransactionSynchronization> synchronizations) {\n\t\treturn Flux.fromIterable(synchronizations)\n\t\t\t\t.concatMap(TransactionSynchronization::afterCommit)\n\t\t\t\t.then();\n\t}", "summary_tokens": ["actually", "invoke", "the", "after", "commit", "methods", "of", "the", "given", "spring", "transaction", "synchronization", "objects"], "project": "spring-framework"}
{"id": 916, "code": "\tvoid copyPropertiesDoesNotHonorGenericTypeMismatchesFromSubTypeToSuperType() {\n\t\tIntegerListHolder1 integerListHolder = new IntegerListHolder1();\n\t\tintegerListHolder.getList().add(42);\n\t\tNumberListHolder numberListHolder = new NumberListHolder();\n\n\t\tBeanUtils.copyProperties(integerListHolder, numberListHolder);\n\t\tassertThat(integerListHolder.getList()).containsOnly(42);\n\t\tassertThat(numberListHolder.getList()).isEmpty();\n\t}", "summary_tokens": ["list", "integer", "can", "not", "be", "copied", "to", "list", "number"], "project": "spring-framework"}
{"id": 4992, "code": "\tpublic long getContentLength() {\n\t\tString value = getFirst(CONTENT_LENGTH);\n\t\treturn (value != null ? Long.parseLong(value) : -1);\n\t}", "summary_tokens": ["return", "the", "content", "length", "header", "or", "0", "if", "unknown"], "project": "spring-framework"}
{"id": 259, "code": "\tpublic void setMaxWait(long maxWait) {\n\t\tthis.maxWait = maxWait;\n\t}", "summary_tokens": ["set", "the", "maximum", "waiting", "time", "for", "fetching", "an", "object", "from", "the", "pool"], "project": "spring-framework"}
{"id": 8041, "code": "\tprotected MessageCodesResolver getMessageCodesResolver() {\n\t\treturn null;\n\t}", "summary_tokens": ["override", "this", "method", "to", "provide", "a", "custom", "message", "codes", "resolver"], "project": "spring-framework"}
{"id": 9156, "code": "\tpublic String removePathExtension() {\n\t\tString extension = null;\n\t\tif (this.originalPath != null) {\n\t\t\textension = UriUtils.extractFileExtension(this.originalPath);\n\t\t\tif (StringUtils.hasLength(extension)) {\n\t\t\t\tint end = this.originalPath.length() - (extension.length() + 1);\n\t\t\t\treplacePath(this.originalPath.substring(0, end));\n\t\t\t}\n\t\t\tthis.originalPath = null;\n\t\t}\n\t\treturn extension;\n\t}", "summary_tokens": ["remove", "any", "path", "extension", "from", "the", "http", "servlet", "request", "get", "request", "uri", "request", "uri"], "project": "spring-framework"}
{"id": 2973, "code": "\tpublic WritableByteChannel writableChannel() throws IOException {\n\t\treturn Files.newByteChannel(this.path, StandardOpenOption.WRITE);\n\t}", "summary_tokens": ["this", "implementation", "opens", "a", "channel", "for", "the", "underlying", "file"], "project": "spring-framework"}
{"id": 3942, "code": "\tpublic boolean isEnforceReadOnly() {\n\t\treturn this.enforceReadOnly;\n\t}", "summary_tokens": ["return", "whether", "to", "enforce", "the", "read", "only", "nature", "of", "a", "transaction", "through", "an", "explicit", "statement", "on", "the", "transactional", "connection"], "project": "spring-framework"}
{"id": 8086, "code": "\tdefault ExchangeFunction filter(ExchangeFilterFunction filter) {\n\t\treturn filter.apply(this);\n\t}", "summary_tokens": ["filter", "the", "exchange", "function", "with", "the", "given", "exchange", "filter", "function", "resulting", "in", "a", "filtered", "exchange", "function"], "project": "spring-framework"}
{"id": 6300, "code": "\tpublic UserTransaction getUserTransaction() {\n\t\treturn this.userTransaction;\n\t}", "summary_tokens": ["return", "the", "jta", "user", "transaction", "that", "this", "transaction", "manager", "uses"], "project": "spring-framework"}
{"id": 408, "code": "\tdefault boolean isEagerInit() {\n\t\treturn false;\n\t}", "summary_tokens": ["does", "this", "factory", "bean", "expect", "eager", "initialization", "that", "is", "eagerly", "initialize", "itself", "as", "well", "as", "expect", "eager", "initialization", "of", "its", "singleton", "object", "if", "any", "p", "a", "standard", "factory", "bean", "is", "not", "expected", "to", "initialize", "eagerly", "its", "get", "object", "will", "only", "be", "called", "for", "actual", "access", "even", "in", "case", "of", "a", "singleton", "object"], "project": "spring-framework"}
{"id": 6914, "code": "\tfinal List<HttpMessageWriter<?>> getObjectWriters() {\n\t\treturn this.objectWriters;\n\t}", "summary_tokens": ["return", "object", "writers", "json", "xml", "sse"], "project": "spring-framework"}
{"id": 6399, "code": "\tpublic void bindResource(Object key, Object value) throws IllegalStateException {\n\t\tObject actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key);\n\t\tAssert.notNull(value, \"Value must not be null\");\n\t\tMap<Object, Object> map = this.transactionContext.getResources();\n\t\tObject oldValue = map.put(actualKey, value);\n\t\tif (oldValue != null) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Already value [\" + oldValue + \"] for key [\" + actualKey + \"] bound to context\");\n\t\t}\n\t}", "summary_tokens": ["bind", "the", "given", "resource", "for", "the", "given", "key", "to", "the", "current", "context"], "project": "spring-framework"}
{"id": 9458, "code": "\tprotected String getType() {\n\t\treturn \"password\";\n\t}", "summary_tokens": ["return", "password", "causing", "the", "rendered", "html", "input", "element", "to", "have", "a", "type", "of", "password"], "project": "spring-framework"}
{"id": 3893, "code": "\tpublic final T extractData(ResultSet rs) throws SQLException, DataAccessException {\n\t\tif (!rs.next()) {\n\t\t\thandleNoRowFound();\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\tstreamData(rs);\n\t\t\t\tif (rs.next()) {\n\t\t\t\t\thandleMultipleRowsFound();\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (IOException ex) {\n\t\t\t\tthrow new LobRetrievalFailureException(\"Could not stream LOB content\", ex);\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["delegates", "to", "handle", "no", "row", "found", "handle", "multiple", "rows", "found", "and", "stream", "data", "according", "to", "the", "result", "set", "state"], "project": "spring-framework"}
{"id": 4276, "code": "\tpublic void closeAll() {\n\t\tfor (Session session : this.sessions) {\n\t\t\ttry {\n\t\t\t\tsession.close();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tlogger.debug(\"Could not close synchronized JMS Session after transaction\", ex);\n\t\t\t}\n\t\t}\n\t\tfor (Connection con : this.connections) {\n\t\t\tConnectionFactoryUtils.releaseConnection(con, this.connectionFactory, true);\n\t\t}\n\t\tthis.connections.clear();\n\t\tthis.sessions.clear();\n\t\tthis.sessionsPerConnection.clear();\n\t}", "summary_tokens": ["close", "all", "of", "this", "resource", "holder", "s", "sessions", "and", "clear", "its", "state"], "project": "spring-framework"}
{"id": 9387, "code": "\tprotected String getOnreset() {\n\t\treturn this.onreset;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onreset", "attribute"], "project": "spring-framework"}
{"id": 7065, "code": "\tprotected void dataReceived(T data) {\n\t\tT prev = this.currentData;\n\t\tif (prev != null) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tdiscardData(data);\n\t\t\tcancel();\n\t\t\tonError(new IllegalStateException(\"Received new data while current not processed yet.\"));\n\t\t}\n\t\tthis.currentData = data;\n\t}", "summary_tokens": ["template", "method", "invoked", "after", "a", "data", "item", "to", "write", "is", "received", "via", "subscriber", "on", "next", "object"], "project": "spring-framework"}
{"id": 4383, "code": "\tprotected void stopSharedConnection() throws JMSException {\n\t\tsynchronized (this.sharedConnectionMonitor) {\n\t\t\tthis.sharedConnectionStarted = false;\n\t\t\tif (this.sharedConnection != null) {\n\t\t\t\ttry {\n\t\t\t\t\tthis.sharedConnection.stop();\n\t\t\t\t}\n\t\t\t\tcatch (jakarta.jms.IllegalStateException ex) {\n\t\t\t\t\tlogger.debug(\"Ignoring Connection stop exception - assuming already stopped: \" + ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["stop", "the", "shared", "connection"], "project": "spring-framework"}
{"id": 6489, "code": "\tpublic final void setIsolationLevelName(String constantName) throws IllegalArgumentException {\n\t\tif (!constantName.startsWith(PREFIX_ISOLATION)) {\n\t\t\tthrow new IllegalArgumentException(\"Only isolation constants allowed\");\n\t\t}\n\t\tsetIsolationLevel(constants.asNumber(constantName).intValue());\n\t}", "summary_tokens": ["set", "the", "isolation", "level", "by", "the", "name", "of", "the", "corresponding", "constant", "in", "transaction", "definition", "e"], "project": "spring-framework"}
{"id": 5774, "code": "\tpublic void assertNode(byte[] content, @Nullable String encoding, Matcher<? super Node> matcher)\n\t\t\tthrows Exception {\n\n\t\tNode node = evaluateXpath(content, encoding, Node.class);\n\t\tMatcherAssert.assertThat(\"XPath \" + this.expression, node, matcher);\n\t}", "summary_tokens": ["parse", "the", "content", "evaluate", "the", "xpath", "expression", "as", "a", "node", "and", "assert", "it", "with", "the", "given", "matcher", "node"], "project": "spring-framework"}
{"id": 9922, "code": "\tpublic void setAllowedOriginPatterns(Collection<String> allowedOriginPatterns) {\n\t\tAssert.notNull(allowedOriginPatterns, \"Allowed origin patterns Collection must not be null\");\n\t\tthis.corsConfiguration.setAllowedOriginPatterns(new ArrayList<>(allowedOriginPatterns));\n\t}", "summary_tokens": ["alternative", "to", "set", "allowed", "origins", "collection", "that", "supports", "more", "flexible", "patterns", "for", "specifying", "the", "origins", "for", "which", "cross", "origin", "requests", "are", "allowed", "from", "a", "browser"], "project": "spring-framework"}
{"id": 2084, "code": "\tpublic void testDoubleTargetSourcesAreRejected() {\n\t\ttestDoubleTargetSourceIsRejected(\"doubleTarget\");\n\t\t\n\t\ttestDoubleTargetSourceIsRejected(\"arbitraryTarget\");\n\t}", "summary_tokens": ["test", "that", "it", "s", "forbidden", "to", "specify", "target", "source", "in", "both", "interceptor", "chain", "and", "target", "source", "property"], "project": "spring-framework"}
{"id": 3321, "code": "\tpublic static String uncapitalize(String str) {\n\t\treturn changeFirstCharacterCase(str, false);\n\t}", "summary_tokens": ["uncapitalize", "a", "string", "changing", "the", "first", "letter", "to", "lower", "case", "as", "per", "character", "to", "lower", "case", "char"], "project": "spring-framework"}
{"id": 923, "code": "\tpublic void testHierarchicalCountBeansWithOverride() {\n\t\t\n\t\tassertThat(this.listableBeanFactory.getBeanDefinitionCount() == 1).isTrue();\n\t\t\n\t\tassertThat(BeanFactoryUtils.countBeansIncludingAncestors(this.listableBeanFactory) == 8).as(\"Should count 8 beans, not \" + BeanFactoryUtils.countBeansIncludingAncestors(this.listableBeanFactory)).isTrue();\n\t}", "summary_tokens": ["check", "that", "override", "doesn", "t", "count", "as", "two", "separate", "beans"], "project": "spring-framework"}
{"id": 7713, "code": "\tpublic WebHttpHandlerBuilder localeContextResolver(LocaleContextResolver localeContextResolver) {\n\t\tthis.localeContextResolver = localeContextResolver;\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "the", "locale", "context", "resolver", "to", "set", "on", "the", "server", "web", "exchange", "web", "server", "exchange"], "project": "spring-framework"}
{"id": 8515, "code": "\tprotected void cleanupMultipart(HttpServletRequest request) {\n\t\tif (this.multipartResolver != null) {\n\t\t\tMultipartHttpServletRequest multipartRequest =\n\t\t\t\t\tWebUtils.getNativeRequest(request, MultipartHttpServletRequest.class);\n\t\t\tif (multipartRequest != null) {\n\t\t\t\tthis.multipartResolver.cleanupMultipart(multipartRequest);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["clean", "up", "any", "resources", "used", "by", "the", "given", "multipart", "request", "if", "any"], "project": "spring-framework"}
{"id": 1403, "code": "\tpublic void setAllowBeanDefinitionOverriding(boolean allowBeanDefinitionOverriding) {\n\t\tthis.beanFactory.setAllowBeanDefinitionOverriding(allowBeanDefinitionOverriding);\n\t}", "summary_tokens": ["set", "whether", "it", "should", "be", "allowed", "to", "override", "bean", "definitions", "by", "registering", "a", "different", "definition", "with", "the", "same", "name", "automatically", "replacing", "the", "former"], "project": "spring-framework"}
{"id": 1840, "code": "\tpublic void setPeriod(long period) {\n\t\tthis.period = period;\n\t}", "summary_tokens": ["set", "the", "period", "between", "repeated", "task", "executions", "in", "milliseconds"], "project": "spring-framework"}
{"id": 6114, "code": "\tpublic ResultMatcher isInsufficientStorage() {\n\t\treturn matcher(HttpStatus.INSUFFICIENT_STORAGE);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 8418, "code": "\tpublic ApplicationContext getApplicationContext() {\n\t\treturn this.applicationContext;\n\t}", "summary_tokens": ["return", "the", "application", "context"], "project": "spring-framework"}
{"id": 9091, "code": "\tpublic UrlPathHelper getUrlPathHelper() {\n\t\treturn this.urlPathHelper;\n\t}", "summary_tokens": ["return", "the", "url", "path", "helper", "implementation", "to", "use"], "project": "spring-framework"}
{"id": 9816, "code": "\tpublic WebSocketTransportRegistration setSendBufferSizeLimit(int sendBufferSizeLimit) {\n\t\tthis.sendBufferSizeLimit = sendBufferSizeLimit;\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "the", "maximum", "amount", "of", "data", "to", "buffer", "when", "sending", "messages", "to", "a", "web", "socket", "session", "or", "an", "http", "response", "when", "sock", "js", "fallback", "option", "are", "in", "use"], "project": "spring-framework"}
{"id": 7861, "code": "\tpublic String getContextPath(HttpServletRequest request) {\n\t\tString contextPath = (String) request.getAttribute(WebUtils.INCLUDE_CONTEXT_PATH_ATTRIBUTE);\n\t\tif (contextPath == null) {\n\t\t\tcontextPath = request.getContextPath();\n\t\t}\n\t\tif (StringUtils.matchesCharacter(contextPath, '/')) {\n\t\t\t\n\t\t\tcontextPath = \"\";\n\t\t}\n\t\treturn decodeRequestString(request, contextPath);\n\t}", "summary_tokens": ["return", "the", "context", "path", "for", "the", "given", "request", "detecting", "an", "include", "request", "url", "if", "called", "within", "a", "request", "dispatcher", "include"], "project": "spring-framework"}
{"id": 3335, "code": "\tpublic static String[] sortStringArray(String[] array) {\n\t\tif (ObjectUtils.isEmpty(array)) {\n\t\t\treturn array;\n\t\t}\n\n\t\tArrays.sort(array);\n\t\treturn array;\n\t}", "summary_tokens": ["sort", "the", "given", "string", "array", "if", "necessary"], "project": "spring-framework"}
{"id": 3242, "code": "\tpublic Method getPreparedMethod() throws IllegalStateException {\n\t\tif (this.methodObject == null) {\n\t\t\tthrow new IllegalStateException(\"prepare() must be called prior to invoke() on MethodInvoker\");\n\t\t}\n\t\treturn this.methodObject;\n\t}", "summary_tokens": ["return", "the", "prepared", "method", "object", "that", "will", "be", "invoked"], "project": "spring-framework"}
{"id": 1987, "code": "\tpublic BindingResult getBindingResult() {\n\t\treturn getInternalBindingResult();\n\t}", "summary_tokens": ["return", "the", "binding", "result", "instance", "created", "by", "this", "data", "binder"], "project": "spring-framework"}
{"id": 8278, "code": "\tprotected Mono<Object> readBody(MethodParameter bodyParam, @Nullable MethodParameter actualParam,\n\t\t\tboolean isBodyRequired, BindingContext bindingContext, ServerWebExchange exchange) {\n\n\t\tResolvableType bodyType = ResolvableType.forMethodParameter(bodyParam);\n\t\tResolvableType actualType = (actualParam != null ? ResolvableType.forMethodParameter(actualParam) : bodyType);\n\t\tClass<?> resolvedType = bodyType.resolve();\n\t\tReactiveAdapter adapter = (resolvedType != null ? getAdapterRegistry().getAdapter(resolvedType) : null);\n\t\tResolvableType elementType = (adapter != null ? bodyType.getGeneric() : bodyType);\n\t\tisBodyRequired = isBodyRequired || (adapter != null && !adapter.supportsEmpty());\n\n\t\tServerHttpRequest request = exchange.getRequest();\n\t\tServerHttpResponse response = exchange.getResponse();\n\n\t\tMediaType contentType = request.getHeaders().getContentType();\n\t\tMediaType mediaType = (contentType != null ? contentType : MediaType.APPLICATION_OCTET_STREAM);\n\t\tObject[] hints = extractValidationHints(bodyParam);\n\n\t\tif (mediaType.isCompatibleWith(MediaType.APPLICATION_FORM_URLENCODED)) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Form data is accessed via ServerWebExchange.getFormData() in WebFlux.\");\n\t\t\t}\n\t\t\treturn Mono.error(new ResponseStatusException(HttpStatus.UNSUPPORTED_MEDIA_TYPE));\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(exchange.getLogPrefix() + (contentType != null ?\n\t\t\t\t\t\"Content-Type:\" + contentType :\n\t\t\t\t\t\"No Content-Type, using \" + MediaType.APPLICATION_OCTET_STREAM));\n\t\t}\n\n\t\tfor (HttpMessageReader<?> reader : getMessageReaders()) {\n\t\t\tif (reader.canRead(elementType, mediaType)) {\n\t\t\t\tMap<String, Object> readHints = Hints.from(Hints.LOG_PREFIX_HINT, exchange.getLogPrefix());\n\t\t\t\tif (adapter != null && adapter.isMultiValue()) {\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(exchange.getLogPrefix() + \"0..N [\" + elementType + \"]\");\n\t\t\t\t\t}\n\t\t\t\t\tFlux<?> flux = reader.read(actualType, elementType, request, response, readHints);\n\t\t\t\t\tflux = flux.onErrorResume(ex -> Flux.error(handleReadError(bodyParam, ex)));\n\t\t\t\t\tif (isBodyRequired) {\n\t\t\t\t\t\tflux = flux.switchIfEmpty(Flux.error(() -> handleMissingBody(bodyParam)));\n\t\t\t\t\t}\n\t\t\t\t\tif (hints != null) {\n\t\t\t\t\t\tflux = flux.doOnNext(target ->\n\t\t\t\t\t\t\t\tvalidate(target, hints, bodyParam, bindingContext, exchange));\n\t\t\t\t\t}\n\t\t\t\t\treturn Mono.just(adapter.fromPublisher(flux));\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\t\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(exchange.getLogPrefix() + \"0..1 [\" + elementType + \"]\");\n\t\t\t\t\t}\n\t\t\t\t\tMono<?> mono = reader.readMono(actualType, elementType, request, response, readHints);\n\t\t\t\t\tmono = mono.onErrorResume(ex -> Mono.error(handleReadError(bodyParam, ex)));\n\t\t\t\t\tif (isBodyRequired) {\n\t\t\t\t\t\tmono = mono.switchIfEmpty(Mono.error(() -> handleMissingBody(bodyParam)));\n\t\t\t\t\t}\n\t\t\t\t\tif (hints != null) {\n\t\t\t\t\t\tmono = mono.doOnNext(target ->\n\t\t\t\t\t\t\t\tvalidate(target, hints, bodyParam, bindingContext, exchange));\n\t\t\t\t\t}\n\t\t\t\t\treturn (adapter != null ? Mono.just(adapter.fromPublisher(mono)) : Mono.from(mono));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t\n\n\t\tHttpMethod method = request.getMethod();\n\t\tif (contentType == null && SUPPORTED_METHODS.contains(method)) {\n\t\t\tFlux<DataBuffer> body = request.getBody().doOnNext(buffer -> {\n\t\t\t\tDataBufferUtils.release(buffer);\n\t\t\t\t\n\t\t\t\tthrow new UnsupportedMediaTypeStatusException(\n\t\t\t\t\t\tmediaType, getSupportedMediaTypes(elementType), elementType);\n\t\t\t});\n\t\t\tif (isBodyRequired) {\n\t\t\t\tbody = body.switchIfEmpty(Mono.error(() -> handleMissingBody(bodyParam)));\n\t\t\t}\n\t\t\treturn (adapter != null ? Mono.just(adapter.fromPublisher(body)) : Mono.from(body));\n\t\t}\n\n\t\treturn Mono.error(new UnsupportedMediaTypeStatusException(\n\t\t\t\tmediaType, getSupportedMediaTypes(elementType), elementType));\n\t}", "summary_tokens": ["read", "the", "body", "from", "a", "method", "argument", "with", "http", "message", "reader"], "project": "spring-framework"}
{"id": 6278, "code": "\tprotected TransactionManager determineTransactionManager(@Nullable TransactionAttribute txAttr) {\n\t\t\n\t\tif (txAttr == null || this.beanFactory == null) {\n\t\t\treturn getTransactionManager();\n\t\t}\n\n\t\tString qualifier = txAttr.getQualifier();\n\t\tif (StringUtils.hasText(qualifier)) {\n\t\t\treturn determineQualifiedTransactionManager(this.beanFactory, qualifier);\n\t\t}\n\t\telse if (StringUtils.hasText(this.transactionManagerBeanName)) {\n\t\t\treturn determineQualifiedTransactionManager(this.beanFactory, this.transactionManagerBeanName);\n\t\t}\n\t\telse {\n\t\t\tTransactionManager defaultTransactionManager = getTransactionManager();\n\t\t\tif (defaultTransactionManager == null) {\n\t\t\t\tdefaultTransactionManager = this.transactionManagerCache.get(DEFAULT_TRANSACTION_MANAGER_KEY);\n\t\t\t\tif (defaultTransactionManager == null) {\n\t\t\t\t\tdefaultTransactionManager = this.beanFactory.getBean(TransactionManager.class);\n\t\t\t\t\tthis.transactionManagerCache.putIfAbsent(\n\t\t\t\t\t\t\tDEFAULT_TRANSACTION_MANAGER_KEY, defaultTransactionManager);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn defaultTransactionManager;\n\t\t}\n\t}", "summary_tokens": ["determine", "the", "specific", "transaction", "manager", "to", "use", "for", "the", "given", "transaction"], "project": "spring-framework"}
{"id": 6585, "code": "\tprotected void doTestRollbackOnException(\n\t\t\tfinal Exception ex, final boolean shouldRollback, boolean rollbackException) throws Exception {\n\n\t\tTransactionAttribute txatt = new DefaultTransactionAttribute() {\n\t\t\t@Override\n\t\t\tpublic boolean rollbackOn(Throwable t) {\n\t\t\t\tassertThat(t).isSameAs(ex);\n\t\t\t\treturn shouldRollback;\n\t\t\t}\n\t\t};\n\n\t\tMethod m = exceptionalMethod;\n\t\tMapTransactionAttributeSource tas = new MapTransactionAttributeSource();\n\t\ttas.register(m, txatt);\n\n\t\tReactiveTransaction status = mock(ReactiveTransaction.class);\n\t\tReactiveTransactionManager rtm = mock(ReactiveTransactionManager.class);\n\t\t\n\n\t\tgiven(rtm.getReactiveTransaction(txatt)).willReturn(Mono.just(status));\n\n\t\tTransactionSystemException tex = new TransactionSystemException(\"system exception\");\n\t\tif (rollbackException) {\n\t\t\tif (shouldRollback) {\n\t\t\t\tgiven(rtm.rollback(status)).willReturn(Mono.error(tex));\n\t\t\t}\n\t\t\telse {\n\t\t\t\tgiven(rtm.commit(status)).willReturn(Mono.error(tex));\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tgiven(rtm.commit(status)).willReturn(Mono.empty());\n\t\t\tgiven(rtm.rollback(status)).willReturn(Mono.empty());\n\t\t}\n\n\t\tDefaultTestBean tb = new DefaultTestBean();\n\t\tTestBean itb = (TestBean) advised(tb, rtm, tas);\n\n\t\titb.exceptional(ex)\n\t\t\t\t.as(StepVerifier::create)\n\t\t\t\t.expectErrorSatisfies(actual -> {\n\t\t\t\t\tif (rollbackException) {\n\t\t\t\t\t\tassertThat(actual).isEqualTo(tex);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tassertThat(actual).isEqualTo(ex);\n\t\t\t\t\t}\n\t\t\t\t}).verify();\n\n\t\tif (!rollbackException) {\n\t\t\tif (shouldRollback) {\n\t\t\t\tverify(rtm).rollback(status);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tverify(rtm).commit(status);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["check", "that", "the", "when", "exception", "thrown", "by", "the", "target", "can", "produce", "the", "desired", "behavior", "with", "the", "appropriate", "transaction", "attribute"], "project": "spring-framework"}
{"id": 7425, "code": "\tpublic List<String> checkHeaders(@Nullable List<String> requestHeaders) {\n\t\tif (requestHeaders == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (requestHeaders.isEmpty()) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t\tif (ObjectUtils.isEmpty(this.allowedHeaders)) {\n\t\t\treturn null;\n\t\t}\n\n\t\tboolean allowAnyHeader = this.allowedHeaders.contains(ALL);\n\t\tList<String> result = new ArrayList<>(requestHeaders.size());\n\t\tfor (String requestHeader : requestHeaders) {\n\t\t\tif (StringUtils.hasText(requestHeader)) {\n\t\t\t\trequestHeader = requestHeader.trim();\n\t\t\t\tif (allowAnyHeader) {\n\t\t\t\t\tresult.add(requestHeader);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tfor (String allowedHeader : this.allowedHeaders) {\n\t\t\t\t\t\tif (requestHeader.equalsIgnoreCase(allowedHeader)) {\n\t\t\t\t\t\t\tresult.add(requestHeader);\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn (result.isEmpty() ? null : result);\n\t}", "summary_tokens": ["check", "the", "supplied", "request", "headers", "or", "the", "headers", "listed", "in", "the", "access", "control", "request", "headers", "of", "a", "pre", "flight", "request", "against", "the", "configured", "allowed", "headers"], "project": "spring-framework"}
{"id": 6896, "code": "\tprivate static Message.Builder getMessageBuilder(Class<?> clazz) throws Exception {\n\t\tMethod method = methodCache.get(clazz);\n\t\tif (method == null) {\n\t\t\tmethod = clazz.getMethod(\"newBuilder\");\n\t\t\tmethodCache.put(clazz, method);\n\t\t}\n\t\treturn (Message.Builder) method.invoke(clazz);\n\t}", "summary_tokens": ["create", "a", "new", "message"], "project": "spring-framework"}
{"id": 5700, "code": "\tvoid mergeWith(TestPropertySourceAttributes attributes) {\n\t\tAssert.state(attributes.declaringClass == this.declaringClass,\n\t\t\t\t() -> \"Detected @TestPropertySource declarations within an aggregate index \"\n\t\t\t\t\t\t+ \"with different sources: \" + this.declaringClass.getName() + \" and \"\n\t\t\t\t\t\t+ attributes.declaringClass.getName());\n\t\tlogger.trace(LogMessage.format(\"Retrieved %s for declaring class [%s].\",\n\t\t\t\tattributes, this.declaringClass.getName()));\n\t\tassertSameBooleanAttribute(this.inheritLocations, attributes.inheritLocations,\n\t\t\t\t\"inheritLocations\", attributes);\n\t\tassertSameBooleanAttribute(this.inheritProperties, attributes.inheritProperties,\n\t\t\t\t\"inheritProperties\", attributes);\n\t\tmergePropertiesAndLocationsFrom(attributes);\n\t}", "summary_tokens": ["merge", "this", "test", "property", "source", "attributes", "instance", "with", "the", "supplied", "test", "property", "source", "attributes", "asserting", "that", "the", "two", "sets", "of", "test", "property", "source", "attributes", "have", "identical", "values", "for", "the", "test", "property", "source", "inherit", "locations", "and", "test", "property", "source", "inherit", "properties", "flags", "and", "that", "the", "two", "underlying", "annotations", "were", "declared", "on", "the", "same", "class"], "project": "spring-framework"}
{"id": 7704, "code": "\tpublic static WebHttpHandlerBuilder applicationContext(ApplicationContext context) {\n\n\t\tWebHttpHandlerBuilder builder = new WebHttpHandlerBuilder(\n\t\t\t\tcontext.getBean(WEB_HANDLER_BEAN_NAME, WebHandler.class), context);\n\n\t\tList<WebFilter> webFilters = context\n\t\t\t\t.getBeanProvider(WebFilter.class)\n\t\t\t\t.orderedStream()\n\t\t\t\t.collect(Collectors.toList());\n\t\tbuilder.filters(filters -> filters.addAll(webFilters));\n\n\t\tList<WebExceptionHandler> exceptionHandlers = context\n\t\t\t\t.getBeanProvider(WebExceptionHandler.class)\n\t\t\t\t.orderedStream()\n\t\t\t\t.collect(Collectors.toList());\n\t\tbuilder.exceptionHandlers(handlers -> handlers.addAll(exceptionHandlers));\n\n\t\tcontext.getBeanProvider(HttpHandlerDecoratorFactory.class)\n\t\t\t\t.orderedStream()\n\t\t\t\t.forEach(builder::httpHandlerDecorator);\n\n\t\ttry {\n\t\t\tbuilder.sessionManager(\n\t\t\t\t\tcontext.getBean(WEB_SESSION_MANAGER_BEAN_NAME, WebSessionManager.class));\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\n\t\t}\n\n\t\ttry {\n\t\t\tbuilder.codecConfigurer(\n\t\t\t\t\tcontext.getBean(SERVER_CODEC_CONFIGURER_BEAN_NAME, ServerCodecConfigurer.class));\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\n\t\t}\n\n\t\ttry {\n\t\t\tbuilder.localeContextResolver(\n\t\t\t\t\tcontext.getBean(LOCALE_CONTEXT_RESOLVER_BEAN_NAME, LocaleContextResolver.class));\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\n\t\t}\n\n\t\ttry {\n\t\t\tbuilder.forwardedHeaderTransformer(\n\t\t\t\t\tcontext.getBean(FORWARDED_HEADER_TRANSFORMER_BEAN_NAME, ForwardedHeaderTransformer.class));\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\n\t\t}\n\n\t\treturn builder;\n\t}", "summary_tokens": ["static", "factory", "method", "to", "create", "a", "new", "builder", "instance", "by", "detecting", "beans", "in", "an", "application", "context"], "project": "spring-framework"}
{"id": 1610, "code": "\tprivate boolean isDeclaredInInterface(Method method, String beanKey) {\n\t\tClass<?>[] ifaces = null;\n\n\t\tif (this.resolvedInterfaceMappings != null) {\n\t\t\tifaces = this.resolvedInterfaceMappings.get(beanKey);\n\t\t}\n\n\t\tif (ifaces == null) {\n\t\t\tifaces = this.managedInterfaces;\n\t\t\tif (ifaces == null) {\n\t\t\t\tifaces = ClassUtils.getAllInterfacesForClass(method.getDeclaringClass());\n\t\t\t}\n\t\t}\n\n\t\tfor (Class<?> ifc : ifaces) {\n\t\t\tfor (Method ifcMethod : ifc.getMethods()) {\n\t\t\t\tif (ifcMethod.getName().equals(method.getName()) &&\n\t\t\t\t\t\tifcMethod.getParameterCount() == method.getParameterCount() &&\n\t\t\t\t\t\tArrays.equals(ifcMethod.getParameterTypes(), method.getParameterTypes())) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}", "summary_tokens": ["checks", "to", "see", "if", "the", "given", "method", "is", "declared", "in", "a", "managed", "interface", "for", "the", "given", "bean"], "project": "spring-framework"}
{"id": 8124, "code": "\tpublic static Function<String, RequestPredicate> pathPredicates(PathPatternParser patternParser) {\n\t\tAssert.notNull(patternParser, \"PathPatternParser must not be null\");\n\t\treturn pattern -> new PathPatternPredicate(patternParser.parse(pattern));\n\t}", "summary_tokens": ["return", "a", "function", "that", "creates", "new", "path", "matching", "request", "predicates", "from", "pattern", "strings", "using", "the", "given", "path", "pattern", "parser"], "project": "spring-framework"}
{"id": 1033, "code": "\tpublic String getDefaultEncoding() {\n\t\treturn this.defaultEncoding;\n\t}", "summary_tokens": ["return", "the", "default", "encoding", "for", "mime", "message", "mime", "messages", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 7901, "code": "public boolean hasBlah() {\n  return ((bitField0_ & 0x00000001) == 0x00000001);\n}", "summary_tokens": ["code", "optional", "int", "0", "blah", "0", "code"], "project": "spring-framework"}
{"id": 3645, "code": "\tpublic static Instrumentation getInstrumentation() {\n\t\treturn instrumentation;\n\t}", "summary_tokens": ["return", "the", "instrumentation", "interface", "exposed", "by", "the", "jvm"], "project": "spring-framework"}
{"id": 987, "code": "\tpublic boolean isEarlyRemove() {\n\t\treturn !getCacheAnnotation().afterInvocation();\n\t}", "summary_tokens": ["specify", "if", "the", "cache", "should", "be", "cleared", "before", "invoking", "the", "method"], "project": "spring-framework"}
{"id": 2753, "code": "\tpublic String canonicalName(String name) {\n\t\tString canonicalName = name;\n\t\t\n\t\tString resolvedName;\n\t\tdo {\n\t\t\tresolvedName = this.aliasMap.get(canonicalName);\n\t\t\tif (resolvedName != null) {\n\t\t\t\tcanonicalName = resolvedName;\n\t\t\t}\n\t\t}\n\t\twhile (resolvedName != null);\n\t\treturn canonicalName;\n\t}", "summary_tokens": ["determine", "the", "raw", "name", "resolving", "aliases", "to", "canonical", "names"], "project": "spring-framework"}
{"id": 8420, "code": "\tpublic Function<String, String> getTemplateLoader() {\n\t\treturn this.templateLoader;\n\t}", "summary_tokens": ["return", "a", "function", "that", "takes", "a", "template", "path", "as", "input", "and", "returns", "the", "template", "content", "as", "a", "string"], "project": "spring-framework"}
{"id": 2933, "code": "\tprotected Resource getResourceByPath(String path) {\n\t\treturn new ClassPathContextResource(path, getClassLoader());\n\t}", "summary_tokens": ["return", "a", "resource", "handle", "for", "the", "resource", "at", "the", "given", "path"], "project": "spring-framework"}
{"id": 7902, "code": "public int getBlah() {\n  return blah_;\n}", "summary_tokens": ["code", "optional", "int", "0", "blah", "0", "code"], "project": "spring-framework"}
{"id": 2274, "code": "\tpublic ReflectionHints reflection() {\n\t\treturn this.reflection;\n\t}", "summary_tokens": ["provide", "access", "to", "reflection", "based", "hints"], "project": "spring-framework"}
{"id": 9512, "code": "\tpublic void setExposeSessionAttributes(boolean exposeSessionAttributes) {\n\t\tthis.exposeSessionAttributes = exposeSessionAttributes;\n\t}", "summary_tokens": ["set", "whether", "all", "http", "session", "attributes", "should", "be", "added", "to", "the", "model", "prior", "to", "merging", "with", "the", "template"], "project": "spring-framework"}
{"id": 5909, "code": "\tstatic Builder bindToServer(ClientHttpConnector connector) {\n\t\treturn new DefaultWebTestClientBuilder(connector);\n\t}", "summary_tokens": ["a", "variant", "of", "bind", "to", "server", "with", "a", "pre", "configured", "connector"], "project": "spring-framework"}
{"id": 4860, "code": "\tpublic void setHeaderInitializer(@Nullable MessageHeaderInitializer headerInitializer) {\n\t\tthis.headerInitializer = headerInitializer;\n\t}", "summary_tokens": ["configure", "a", "message", "header", "initializer", "to", "pass", "on", "to", "handler", "method", "return", "value", "handler", "handler", "method", "return", "value", "handlers", "that", "send", "messages", "from", "controller", "return", "values"], "project": "spring-framework"}
{"id": 1096, "code": "\tpublic static ResourceLoader getConfigTimeResourceLoader() {\n\t\treturn configTimeResourceLoaderHolder.get();\n\t}", "summary_tokens": ["return", "the", "resource", "loader", "for", "the", "currently", "configured", "quartz", "scheduler", "to", "be", "used", "by", "resource", "loader", "class", "load", "helper"], "project": "spring-framework"}
{"id": 8447, "code": "\tdefault List<String> getSubProtocols() {\n\t\treturn Collections.emptyList();\n\t}", "summary_tokens": ["return", "the", "list", "of", "sub", "protocols", "supported", "by", "this", "handler"], "project": "spring-framework"}
{"id": 5852, "code": "\tpublic DefaultResponseCreator location(URI location) {\n\t\tthis.headers.setLocation(location);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "location", "header"], "project": "spring-framework"}
{"id": 519, "code": "\tpublic void afterPropertiesSet() {\n\t\tif (this.systemTreePath != null) {\n\t\t\tthis.systemPrefs = this.systemPrefs.node(this.systemTreePath);\n\t\t}\n\t\tif (this.userTreePath != null) {\n\t\t\tthis.userPrefs = this.userPrefs.node(this.userTreePath);\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "eagerly", "fetches", "the", "preferences", "instances", "for", "the", "required", "system", "and", "user", "tree", "nodes"], "project": "spring-framework"}
{"id": 3, "code": "\tvoid testNoProxy() throws Exception {\n\t\tBeanFactory bf = getBeanFactory();\n\t\tObject o = bf.getBean(\"noSetters\");\n\t\tassertThat(AopUtils.isAopProxy(o)).isFalse();\n\t}", "summary_tokens": ["if", "no", "pointcuts", "match", "no", "attrs", "there", "should", "be", "proxying"], "project": "spring-framework"}
{"id": 1702, "code": "\tprotected void doRegister(Object mbean, ObjectName objectName) throws JMException {\n\t\tAssert.state(this.server != null, \"No MBeanServer set\");\n\t\tObjectName actualObjectName;\n\n\t\tsynchronized (this.registeredBeans) {\n\t\t\tObjectInstance registeredBean = null;\n\t\t\ttry {\n\t\t\t\tregisteredBean = this.server.registerMBean(mbean, objectName);\n\t\t\t}\n\t\t\tcatch (InstanceAlreadyExistsException ex) {\n\t\t\t\tif (this.registrationPolicy == RegistrationPolicy.IGNORE_EXISTING) {\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Ignoring existing MBean at [\" + objectName + \"]\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (this.registrationPolicy == RegistrationPolicy.REPLACE_EXISTING) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"Replacing existing MBean at [\" + objectName + \"]\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthis.server.unregisterMBean(objectName);\n\t\t\t\t\t\tregisteredBean = this.server.registerMBean(mbean, objectName);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (InstanceNotFoundException ex2) {\n\t\t\t\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\t\t\t\tlogger.info(\"Unable to replace existing MBean at [\" + objectName + \"]\", ex2);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tthrow ex;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t\n\t\t\tactualObjectName = (registeredBean != null ? registeredBean.getObjectName() : null);\n\t\t\tif (actualObjectName == null) {\n\t\t\t\tactualObjectName = objectName;\n\t\t\t}\n\t\t\tthis.registeredBeans.add(actualObjectName);\n\t\t}\n\n\t\tonRegister(actualObjectName, mbean);\n\t}", "summary_tokens": ["actually", "register", "the", "mbean", "with", "the", "server"], "project": "spring-framework"}
{"id": 4254, "code": "\tpublic void setMessageListener(@Nullable MessageListener messageListener) {\n\t\tthis.messageListener = messageListener;\n\t}", "summary_tokens": ["set", "the", "message", "listener", "to", "invoke", "when", "a", "message", "matching", "the", "endpoint", "is", "received"], "project": "spring-framework"}
{"id": 2119, "code": "\tvoid repro() {\n\t\tAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();\n\t\tctx.scan(getClass().getPackage().getName());\n\t\tctx.refresh();\n\t\tassertThat(ctx.containsBean(\"withNestedAnnotation\")).isTrue();\n\t\tctx.close();\n\t}", "summary_tokens": ["prior", "to", "the", "fix", "for", "spr", "0", "this", "test", "threw", "because", "the", "nested", "my", "component", "annotation", "was", "being", "falsely", "considered", "as", "a", "lite", "configuration", "class", "candidate"], "project": "spring-framework"}
{"id": 1190, "code": "\tprotected void doEvict(Cache cache, Object key, boolean immediate) {\n\t\ttry {\n\t\t\tif (immediate) {\n\t\t\t\tcache.evictIfPresent(key);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcache.evict(key);\n\t\t\t}\n\t\t}\n\t\tcatch (RuntimeException ex) {\n\t\t\tgetErrorHandler().handleCacheEvictError(ex, cache, key);\n\t\t}\n\t}", "summary_tokens": ["execute", "cache", "evict", "object", "cache", "evict", "if", "present", "object", "on", "the", "specified", "cache", "and", "invoke", "the", "error", "handler", "if", "an", "exception", "occurs"], "project": "spring-framework"}
{"id": 1655, "code": "\tpublic void setNotificationType(String notificationType) {\n\t\tthis.notificationTypes = StringUtils.commaDelimitedListToStringArray(notificationType);\n\t}", "summary_tokens": ["set", "a", "single", "notification", "type", "or", "a", "list", "of", "notification", "types", "as", "comma", "delimited", "string"], "project": "spring-framework"}
{"id": 637, "code": "\tpublic BeanDefinitionBuilder setInitMethodName(@Nullable String methodName) {\n\t\tthis.beanDefinition.setInitMethodName(methodName);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "init", "method", "for", "this", "definition"], "project": "spring-framework"}
{"id": 6648, "code": "\tpublic void setAllow(Set<HttpMethod> allowedMethods) {\n\t\tset(ALLOW, StringUtils.collectionToCommaDelimitedString(allowedMethods));\n\t}", "summary_tokens": ["set", "the", "set", "of", "allowed", "http", "method", "http", "methods", "as", "specified", "by", "the", "allow", "header"], "project": "spring-framework"}
{"id": 3561, "code": "\tprivate void consumeArguments(List<SpelNodeImpl> accumulatedArguments) {\n\t\tToken t = peekToken();\n\t\tAssert.state(t != null, \"Expected token\");\n\t\tint pos = t.startPos;\n\t\tToken next;\n\t\tdo {\n\t\t\tnextToken();  \n\t\t\tt = peekToken();\n\t\t\tif (t == null) {\n\t\t\t\tthrow internalException(pos, SpelMessage.RUN_OUT_OF_ARGUMENTS);\n\t\t\t}\n\t\t\tif (t.kind != TokenKind.RPAREN) {\n\t\t\t\taccumulatedArguments.add(eatExpression());\n\t\t\t}\n\t\t\tnext = peekToken();\n\t\t}\n\t\twhile (next != null && next.kind == TokenKind.COMMA);\n\n\t\tif (next == null) {\n\t\t\tthrow internalException(pos, SpelMessage.RUN_OUT_OF_ARGUMENTS);\n\t\t}\n\t}", "summary_tokens": ["used", "for", "consuming", "arguments", "for", "either", "a", "method", "or", "a", "constructor", "call"], "project": "spring-framework"}
{"id": 7482, "code": "\tpublic boolean isForceResponseEncoding() {\n\t\treturn this.forceResponseEncoding;\n\t}", "summary_tokens": ["return", "whether", "the", "encoding", "should", "be", "forced", "on", "responses"], "project": "spring-framework"}
{"id": 8299, "code": "\tprivate boolean bindingDisabled(MethodParameter parameter) {\n\t\tModelAttribute modelAttribute = parameter.getParameterAnnotation(ModelAttribute.class);\n\t\treturn (modelAttribute != null && !modelAttribute.binding());\n\t}", "summary_tokens": ["determine", "if", "binding", "should", "be", "disabled", "for", "the", "supplied", "method", "parameter", "based", "on", "the", "model", "attribute", "binding", "annotation", "attribute"], "project": "spring-framework"}
{"id": 2253, "code": "\tpublic boolean isAllowUnsafeAccess() {\n\t\treturn this.allowUnsafeAccess;\n\t}", "summary_tokens": ["return", "whether", "using", "unsafe", "on", "the", "field", "should", "be", "allowed"], "project": "spring-framework"}
{"id": 5069, "code": "\tpublic IdGenerator getIdGenerator() {\n\t\treturn this.idGenerator;\n\t}", "summary_tokens": ["return", "the", "configured", "id", "generator", "if", "any"], "project": "spring-framework"}
{"id": 226, "code": "\tpublic NameMatchMethodPointcut addMethodName(String name) {\n\t\tthis.mappedNames.add(name);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "another", "eligible", "method", "name", "in", "addition", "to", "those", "already", "named"], "project": "spring-framework"}
{"id": 5714, "code": "\tprotected void springTestContextBeforeTestMethod(Method testMethod) throws Exception {\n\t\tthis.testContextManager.beforeTestMethod(this, testMethod);\n\t}", "summary_tokens": ["delegates", "to", "the", "configured", "test", "context", "manager", "to", "test", "context", "manager", "before", "test", "method", "object", "method", "pre", "process", "the", "test", "method", "before", "the", "actual", "test", "is", "executed"], "project": "spring-framework"}
{"id": 5056, "code": "\tpublic Log getLogger() {\n\t\treturn logger;\n\t}", "summary_tokens": ["return", "the", "currently", "configured", "logger"], "project": "spring-framework"}
{"id": 542, "code": "\tprotected void convertProperties(Properties props) {\n\t\tEnumeration<?> propertyNames = props.propertyNames();\n\t\twhile (propertyNames.hasMoreElements()) {\n\t\t\tString propertyName = (String) propertyNames.nextElement();\n\t\t\tString propertyValue = props.getProperty(propertyName);\n\t\t\tString convertedValue = convertProperty(propertyName, propertyValue);\n\t\t\tif (!ObjectUtils.nullSafeEquals(propertyValue, convertedValue)) {\n\t\t\t\tprops.setProperty(propertyName, convertedValue);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["convert", "the", "given", "merged", "properties", "converting", "property", "values", "if", "necessary"], "project": "spring-framework"}
{"id": 8123, "code": "\tpublic static RequestPredicate path(String pattern) {\n\t\tAssert.notNull(pattern, \"'pattern' must not be null\");\n\t\tif (!pattern.isEmpty() && !pattern.startsWith(\"/\")) {\n\t\t\tpattern = \"/\" + pattern;\n\t\t}\n\t\treturn pathPredicates(PathPatternParser.defaultInstance).apply(pattern);\n\t}", "summary_tokens": ["return", "a", "request", "predicate", "that", "tests", "the", "request", "path", "against", "the", "given", "path", "pattern"], "project": "spring-framework"}
{"id": 8377, "code": "\tprotected String getSuffix() {\n\t\treturn this.suffix;\n\t}", "summary_tokens": ["return", "the", "suffix", "that", "gets", "appended", "to", "view", "names", "when", "building", "a", "url"], "project": "spring-framework"}
{"id": 2995, "code": "\tpublic DefaultDataBuffer join(List<? extends DataBuffer> dataBuffers) {\n\t\tAssert.notEmpty(dataBuffers, \"DataBuffer List must not be empty\");\n\t\tint capacity = dataBuffers.stream().mapToInt(DataBuffer::readableByteCount).sum();\n\t\tDefaultDataBuffer result = allocateBuffer(capacity);\n\t\tdataBuffers.forEach(result::write);\n\t\tdataBuffers.forEach(DataBufferUtils::release);\n\t\treturn result;\n\t}", "summary_tokens": ["p", "this", "implementation", "creates", "a", "single", "default", "data", "buffer", "to", "contain", "the", "data", "in", "data", "buffers"], "project": "spring-framework"}
{"id": 651, "code": "\tpublic Boolean getLazyInit() {\n\t\treturn this.lazyInit;\n\t}", "summary_tokens": ["return", "whether", "beans", "should", "be", "lazily", "initialized", "by", "default", "i"], "project": "spring-framework"}
{"id": 4523, "code": "\tpublic void setAcknowledgeModeName(String constantName) {\n\t\tsetAcknowledgeMode(sessionConstants.asNumber(constantName).intValue());\n\t}", "summary_tokens": ["set", "the", "jms", "acknowledgement", "mode", "by", "the", "name", "of", "the", "corresponding", "constant", "in", "the", "jms", "session", "interface", "e"], "project": "spring-framework"}
{"id": 4065, "code": "\tprotected RowMapper<T> newRowMapper(@Nullable Object[] parameters, @Nullable Map<?, ?> context) {\n\t\treturn new RowMapperImpl(parameters, context);\n\t}", "summary_tokens": ["implementation", "of", "protected", "abstract", "method"], "project": "spring-framework"}
{"id": 6166, "code": "\tpublic void rootWacServletContainerAttributeNotPreviouslySet() {\n\t\tStubWebApplicationContext root = new StubWebApplicationContext(this.servletContext);\n\t\tDefaultMockMvcBuilder builder = webAppContextSetup(root);\n\t\tWebApplicationContext wac = builder.initWebAppContext();\n\t\tassertThat(wac).isSameAs(root);\n\t\tassertThat(WebApplicationContextUtils.getRequiredWebApplicationContext(this.servletContext)).isSameAs(root);\n\t}", "summary_tokens": ["see", "spr", "0", "and", "spr", "0"], "project": "spring-framework"}
{"id": 8635, "code": "\tpublic ResourceHandlerRegistration addResourceHandler(String... pathPatterns) {\n\t\tResourceHandlerRegistration registration = new ResourceHandlerRegistration(pathPatterns);\n\t\tthis.registrations.add(registration);\n\t\treturn registration;\n\t}", "summary_tokens": ["add", "a", "resource", "handler", "to", "serve", "static", "resources"], "project": "spring-framework"}
{"id": 1478, "code": "\tpublic Chronology getChronology() {\n\t\treturn this.chronology;\n\t}", "summary_tokens": ["return", "the", "user", "s", "chronology", "calendar", "system", "if", "any"], "project": "spring-framework"}
{"id": 2369, "code": "public String readUTF8(final int offset, final char[] charBuffer) {\n  int constantPoolEntryIndex = readUnsignedShort(offset);\n  if (offset == 0 || constantPoolEntryIndex == 0) {\n    return null;\n  }\n  return readUtf(constantPoolEntryIndex, charBuffer);\n}", "summary_tokens": ["reads", "a", "constant", "utf", "0", "constant", "pool", "entry", "in", "this", "class", "reader"], "project": "spring-framework"}
{"id": 3658, "code": "\tpublic SQLException getSQLException() {\n\t\treturn (SQLException) getCause();\n\t}", "summary_tokens": ["return", "the", "underlying", "sqlexception"], "project": "spring-framework"}
{"id": 2017, "code": "\tprotected Object[] getArgumentsForBindError(String objectName, String field) {\n\t\tString[] codes = new String[] {objectName + Errors.NESTED_PATH_SEPARATOR + field, field};\n\t\treturn new Object[] {new DefaultMessageSourceResolvable(codes, field)};\n\t}", "summary_tokens": ["return", "field", "error", "arguments", "for", "a", "binding", "error", "on", "the", "given", "field"], "project": "spring-framework"}
{"id": 131, "code": "\tprotected Object wrapIfNecessary(Object bean, String beanName, Object cacheKey) {\n\t\tif (StringUtils.hasLength(beanName) && this.targetSourcedBeans.contains(beanName)) {\n\t\t\treturn bean;\n\t\t}\n\t\tif (Boolean.FALSE.equals(this.advisedBeans.get(cacheKey))) {\n\t\t\treturn bean;\n\t\t}\n\t\tif (isInfrastructureClass(bean.getClass()) || shouldSkip(bean.getClass(), beanName)) {\n\t\t\tthis.advisedBeans.put(cacheKey, Boolean.FALSE);\n\t\t\treturn bean;\n\t\t}\n\n\t\t\n\t\tObject[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);\n\t\tif (specificInterceptors != DO_NOT_PROXY) {\n\t\t\tthis.advisedBeans.put(cacheKey, Boolean.TRUE);\n\t\t\tObject proxy = createProxy(\n\t\t\t\t\tbean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));\n\t\t\tthis.proxyTypes.put(cacheKey, proxy.getClass());\n\t\t\treturn proxy;\n\t\t}\n\n\t\tthis.advisedBeans.put(cacheKey, Boolean.FALSE);\n\t\treturn bean;\n\t}", "summary_tokens": ["wrap", "the", "given", "bean", "if", "necessary", "i"], "project": "spring-framework"}
{"id": 6403, "code": "\tpublic boolean isSynchronizationActive() {\n\t\treturn (this.transactionContext.getSynchronizations() != null);\n\t}", "summary_tokens": ["return", "if", "transaction", "synchronization", "is", "active", "for", "the", "current", "context"], "project": "spring-framework"}
{"id": 8213, "code": "\tpublic boolean isEmpty() {\n\t\treturn ObjectUtils.isEmpty(this.requestConditions);\n\t}", "summary_tokens": ["whether", "this", "instance", "contains", "0", "conditions", "or", "not"], "project": "spring-framework"}
{"id": 1938, "code": "\tpublic ConcurrentModel addAllAttributes(@Nullable Map<String, ?> attributes) {\n\t\tif (attributes != null) {\n\t\t\tputAll(attributes);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["copy", "all", "attributes", "in", "the", "supplied", "map", "into", "this", "map"], "project": "spring-framework"}
{"id": 1163, "code": "\tprivate UnsupportedOperationException methodInCallStack(String keyItem) {\n\t\ttry {\n\t\t\tservice.cacheWithException(keyItem, true);\n\t\t\tthrow new IllegalStateException(\"Should have thrown an exception\");\n\t\t}\n\t\tcatch (UnsupportedOperationException e) {\n\t\t\treturn e;\n\t\t}\n\t}", "summary_tokens": ["the", "only", "purpose", "of", "this", "method", "is", "to", "invoke", "a", "particular", "method", "on", "the", "service", "so", "that", "the", "call", "stack", "is", "different"], "project": "spring-framework"}
{"id": 2690, "code": "\tprotected final Map<String, Object> getFieldCache() {\n\t\treturn this.fieldCache;\n\t}", "summary_tokens": ["exposes", "the", "field", "cache", "to", "subclasses", "a", "map", "from", "string", "field", "name", "to", "object", "value"], "project": "spring-framework"}
{"id": 8227, "code": "\tpublic HeadersRequestCondition combine(HeadersRequestCondition other) {\n\t\tif (isEmpty() && other.isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\telse if (other.isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\telse if (isEmpty()) {\n\t\t\treturn other;\n\t\t}\n\t\tSet<HeaderExpression> set = new LinkedHashSet<>(this.expressions);\n\t\tset.addAll(other.expressions);\n\t\treturn new HeadersRequestCondition(set);\n\t}", "summary_tokens": ["returns", "a", "new", "instance", "with", "the", "union", "of", "the", "header", "expressions", "from", "this", "and", "the", "other", "instance"], "project": "spring-framework"}
{"id": 7051, "code": "\tpublic final void onError(Throwable ex) {\n\t\tState state = this.state.get();\n\t\tif (rsReadLogger.isTraceEnabled()) {\n\t\t\trsReadLogger.trace(getLogPrefix() + \"onError: \" + ex + \" [\" + state + \"]\");\n\t\t}\n\t\tstate.onError(this, ex);\n\t}", "summary_tokens": ["subclasses", "can", "call", "this", "to", "delegate", "container", "error", "notifications"], "project": "spring-framework"}
{"id": 8872, "code": "\tprotected String extractViewNameFromUrlPath(String uri) {\n\t\tint start = (uri.charAt(0) == '/' ? 1 : 0);\n\t\tint lastIndex = uri.lastIndexOf('.');\n\t\tint end = (lastIndex < 0 ? uri.length() : lastIndex);\n\t\treturn uri.substring(start, end);\n\t}", "summary_tokens": ["extract", "the", "url", "filename", "from", "the", "given", "request", "uri"], "project": "spring-framework"}
{"id": 4770, "code": "\tpublic void addArgumentResolvers(List<? extends HandlerMethodArgumentResolver> resolvers) {\n\t\tthis.argumentResolvers.addResolvers(resolvers);\n\t}", "summary_tokens": ["add", "the", "arguments", "resolvers", "to", "use", "for", "message", "handling", "and", "exception", "handling", "methods"], "project": "spring-framework"}
{"id": 8981, "code": "\tpublic static UriComponentsBuilder fromMethodName(UriComponentsBuilder builder,\n\t\t\tClass<?> controllerType, String methodName, Object... args) {\n\n\t\tMethod method = getMethod(controllerType, methodName, args);\n\t\treturn fromMethodInternal(builder, controllerType, method, args);\n\t}", "summary_tokens": ["an", "alternative", "to", "from", "method", "name", "class", "string", "object"], "project": "spring-framework"}
{"id": 7157, "code": "\tpublic void closeNoCatch() throws ServletRequestBindingException {\n\t\tif (getBindingResult().hasErrors()) {\n\t\t\tthrow new ServletRequestBindingException(\n\t\t\t\t\t\"Errors binding onto object '\" + getBindingResult().getObjectName() + \"'\",\n\t\t\t\t\tnew BindException(getBindingResult()));\n\t\t}\n\t}", "summary_tokens": ["treats", "errors", "as", "fatal"], "project": "spring-framework"}
{"id": 695, "code": "\tprotected void clearSingletonCache() {\n\t\tsynchronized (this.singletonObjects) {\n\t\t\tthis.singletonObjects.clear();\n\t\t\tthis.singletonFactories.clear();\n\t\t\tthis.earlySingletonObjects.clear();\n\t\t\tthis.registeredSingletons.clear();\n\t\t\tthis.singletonsCurrentlyInDestruction = false;\n\t\t}\n\t}", "summary_tokens": ["clear", "all", "cached", "singleton", "instances", "in", "this", "registry"], "project": "spring-framework"}
{"id": 9334, "code": "\tpublic void setItemValue(String itemValue) {\n\t\tAssert.hasText(itemValue, \"'itemValue' must not be empty\");\n\t\tthis.itemValue = itemValue;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "property", "mapped", "to", "the", "value", "attribute", "of", "the", "input", "type", "checkbox", "radio", "tag"], "project": "spring-framework"}
{"id": 4290, "code": "\tpublic void setReconnectOnException(boolean reconnectOnException) {\n\t\tthis.reconnectOnException = reconnectOnException;\n\t}", "summary_tokens": ["specify", "whether", "the", "single", "connection", "should", "be", "reset", "to", "be", "subsequently", "renewed", "when", "a", "jmsexception", "is", "reported", "by", "the", "underlying", "connection"], "project": "spring-framework"}
{"id": 8842, "code": "\tpublic void setParamName(String paramName) {\n\t\tthis.paramName = paramName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "parameter", "that", "contains", "a", "locale", "specification", "in", "a", "locale", "change", "request"], "project": "spring-framework"}
{"id": 2894, "code": "\tpublic int hashCode() {\n\t\treturn ObjectUtils.nullSafeHashCode(getName());\n\t}", "summary_tokens": ["return", "a", "hash", "code", "derived", "from", "the", "name", "property", "of", "this", "property", "source", "object"], "project": "spring-framework"}
{"id": 5819, "code": "\tpublic RequestMatcher source(Matcher<? super Source> matcher) {\n\t\treturn new AbstractXmlRequestMatcher() {\n\t\t\t@Override\n\t\t\tprotected void matchInternal(MockClientHttpRequest request) throws Exception {\n\t\t\t\txmlHelper.assertSource(request.getBodyAsString(), matcher);\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["parse", "the", "request", "content", "as", "domsource", "and", "apply", "the", "given", "matcher"], "project": "spring-framework"}
{"id": 3030, "code": "\tpublic boolean isTraceEnabled() {\n\t\treturn this.log.isTraceEnabled();\n\t}", "summary_tokens": ["is", "trace", "logging", "currently", "enabled"], "project": "spring-framework"}
{"id": 465, "code": "\tpublic void setCustomEditors(Map<Class<?>, Class<? extends PropertyEditor>> customEditors) {\n\t\tthis.customEditors = customEditors;\n\t}", "summary_tokens": ["specify", "the", "custom", "editors", "to", "register", "via", "a", "map", "using", "the", "class", "name", "of", "the", "required", "type", "as", "the", "key", "and", "the", "class", "name", "of", "the", "associated", "property", "editor", "as", "value"], "project": "spring-framework"}
{"id": 3518, "code": "\tpublic static boolean isPrimitiveOrUnboxableSupportedNumber(@Nullable String descriptor) {\n\t\tif (descriptor == null) {\n\t\t\treturn false;\n\t\t}\n\t\tif (descriptor.length() == 1) {\n\t\t\treturn \"DFIJ\".contains(descriptor);\n\t\t}\n\t\tif (descriptor.startsWith(\"Ljava/lang/\")) {\n\t\t\tString name = descriptor.substring(\"Ljava/lang/\".length());\n\t\t\tif (name.equals(\"Double\") || name.equals(\"Float\") || name.equals(\"Integer\") || name.equals(\"Long\")) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "if", "the", "supplied", "descriptor", "is", "for", "a", "supported", "number"], "project": "spring-framework"}
{"id": 2617, "code": "\tpublic void setNamingPolicy(NamingPolicy namingPolicy) {\n\t\tif (namingPolicy == null)\n\t\t\tnamingPolicy = DefaultNamingPolicy.INSTANCE;\n\t\tthis.namingPolicy = namingPolicy;\n\t}", "summary_tokens": ["override", "the", "default", "naming", "policy"], "project": "spring-framework"}
{"id": 9672, "code": "\tprotected String getEncoding() {\n\t\treturn this.encoding;\n\t}", "summary_tokens": ["return", "the", "encoding", "for", "the", "free", "marker", "template"], "project": "spring-framework"}
{"id": 4424, "code": "\tprotected void doExecuteListener(Session session, Message message) throws JMSException {\n\t\tif (!isAcceptMessagesWhileStopping() && !isRunning()) {\n\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\tlogger.warn(\"Rejecting received message because of the listener container \" +\n\t\t\t\t\t\t\"having been stopped in the meantime: \" + message);\n\t\t\t}\n\t\t\trollbackIfNecessary(session);\n\t\t\tthrow new MessageRejectedWhileStoppingException();\n\t\t}\n\n\t\ttry {\n\t\t\tinvokeListener(session, message);\n\t\t}\n\t\tcatch (JMSException | RuntimeException | Error ex) {\n\t\t\trollbackOnExceptionIfNecessary(session, ex);\n\t\t\tthrow ex;\n\t\t}\n\t\tcommitIfNecessary(session, message);\n\t}", "summary_tokens": ["execute", "the", "specified", "listener", "committing", "or", "rolling", "back", "the", "transaction", "afterwards", "if", "necessary"], "project": "spring-framework"}
{"id": 9254, "code": "\tpublic String getId() {\n\t\treturn this.id;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "id", "attribute"], "project": "spring-framework"}
{"id": 7443, "code": "\tpublic static boolean isCorsRequest(ServerHttpRequest request) {\n\t\treturn request.getHeaders().containsKey(HttpHeaders.ORIGIN) && !isSameOrigin(request);\n\t}", "summary_tokens": ["returns", "true", "if", "the", "request", "is", "a", "valid", "cors", "one", "by", "checking", "origin", "header", "presence", "and", "ensuring", "that", "origins", "are", "different", "via", "is", "same", "origin"], "project": "spring-framework"}
{"id": 9591, "code": "\tprotected String urlEncode(String input, String encodingScheme) throws UnsupportedEncodingException {\n\t\treturn URLEncoder.encode(input, encodingScheme);\n\t}", "summary_tokens": ["url", "encode", "the", "given", "input", "string", "with", "the", "given", "encoding", "scheme"], "project": "spring-framework"}
{"id": 7792, "code": "\tpublic static RequestPath getParsedRequestPath(ServletRequest request) {\n\t\tRequestPath path = (RequestPath) request.getAttribute(PATH_ATTRIBUTE);\n\t\tAssert.notNull(path, () -> \"Expected parsed RequestPath in request attribute \\\"\" + PATH_ATTRIBUTE + \"\\\".\");\n\t\treturn path;\n\t}", "summary_tokens": ["return", "a", "parse", "and", "cache", "previously", "parsed", "and", "cached", "request", "path"], "project": "spring-framework"}
{"id": 1244, "code": "\tpublic final BeanDefinitionRegistry getRegistry() {\n\t\treturn this.registry;\n\t}", "summary_tokens": ["get", "the", "bean", "definition", "registry", "that", "this", "reader", "operates", "on"], "project": "spring-framework"}
{"id": 5528, "code": "\tpublic void beforeTestExecution(Object testInstance, Method testMethod) throws Exception {\n\t\tString callbackName = \"beforeTestExecution\";\n\t\tprepareForBeforeCallback(callbackName, testInstance, testMethod);\n\n\t\tfor (TestExecutionListener testExecutionListener : getTestExecutionListeners()) {\n\t\t\ttry {\n\t\t\t\ttestExecutionListener.beforeTestExecution(getTestContext());\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\thandleBeforeException(ex, callbackName, testExecutionListener, testInstance, testMethod);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["hook", "for", "pre", "processing", "a", "test", "em", "immediately", "before", "em", "execution", "of", "the", "java"], "project": "spring-framework"}
{"id": 2030, "code": "\tpublic String getObjectName() {\n\t\treturn this.objectName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "affected", "object"], "project": "spring-framework"}
{"id": 5925, "code": "\tdefault ResultActions andExpectAll(ResultMatcher... matchers) throws Exception {\n\t\tExceptionCollector exceptionCollector = new ExceptionCollector();\n\t\tfor (ResultMatcher matcher : matchers) {\n\t\t\texceptionCollector.execute(() -> this.andExpect(matcher));\n\t\t}\n\t\texceptionCollector.assertEmpty();\n\t\treturn this;\n\t}", "summary_tokens": ["perform", "multiple", "expectations", "with", "the", "guarantee", "that", "all", "expectations", "will", "be", "asserted", "even", "if", "one", "or", "more", "expectations", "fail", "with", "an", "exception"], "project": "spring-framework"}
{"id": 292, "code": "\tpublic void setup() {\n\t\tProxyFactory pf = new ProxyFactory(new SerializablePerson());\n\t\tnop = new SerializableNopInterceptor();\n\t\tpc = new NameMatchMethodPointcut();\n\t\tpf.addAdvisor(new DefaultPointcutAdvisor(pc, nop));\n\t\tproxied = (Person) pf.getProxy();\n\t}", "summary_tokens": ["create", "an", "empty", "pointcut", "populating", "instance", "variables"], "project": "spring-framework"}
{"id": 5810, "code": "\tpublic RequestMatcher contentTypeCompatibleWith(MediaType contentType) {\n\t\treturn request -> {\n\t\t\tMediaType actualContentType = request.getHeaders().getContentType();\n\t\t\tassertTrue(\"Content type not set\", actualContentType != null);\n\t\t\tif (actualContentType != null) {\n\t\t\t\tassertTrue(\"Content type [\" + actualContentType + \"] is not compatible with [\" + contentType + \"]\",\n\t\t\t\t\t\tactualContentType.isCompatibleWith(contentType));\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "request", "content", "type", "is", "compatible", "with", "the", "given", "content", "type", "as", "defined", "by", "media", "type", "is", "compatible", "with", "media", "type"], "project": "spring-framework"}
{"id": 7152, "code": "\tpublic boolean isMissingAfterConversion() {\n\t\treturn this.missingAfterConversion;\n\t}", "summary_tokens": ["whether", "the", "request", "value", "was", "present", "but", "converted", "to", "null", "e"], "project": "spring-framework"}
{"id": 2268, "code": "\tpublic ReflectionHints registerMethod(Method method, Consumer<ExecutableHint.Builder> methodHint) {\n\t\treturn registerType(TypeReference.of(method.getDeclaringClass()),\n\t\t\t\ttypeHint -> typeHint.withMethod(method.getName(), mapParameters(method), methodHint));\n\t}", "summary_tokens": ["register", "the", "need", "for", "reflection", "on", "the", "specified", "method"], "project": "spring-framework"}
{"id": 9146, "code": "\tpublic static ServletUriComponentsBuilder fromContextPath(HttpServletRequest request) {\n\t\tServletUriComponentsBuilder builder = initFromRequest(request);\n\t\tbuilder.replacePath(request.getContextPath());\n\t\treturn builder;\n\t}", "summary_tokens": ["prepare", "a", "builder", "from", "the", "host", "port", "scheme", "and", "context", "path", "of", "the", "given", "http", "servlet", "request"], "project": "spring-framework"}
{"id": 8136, "code": "\tpublic static RequestPredicate queryParam(String name, Predicate<String> predicate) {\n\t\treturn new QueryParamPredicate(name, predicate);\n\t}", "summary_tokens": ["return", "a", "request", "predicate", "that", "tests", "the", "request", "s", "query", "parameter", "of", "the", "given", "name", "against", "the", "given", "predicate"], "project": "spring-framework"}
{"id": 6834, "code": "\tstatic ServerCodecConfigurer create() {\n\t\treturn CodecConfigurerFactory.create(ServerCodecConfigurer.class);\n\t}", "summary_tokens": ["static", "factory", "method", "for", "a", "server", "codec", "configurer"], "project": "spring-framework"}
{"id": 7043, "code": "\tpublic ServerHttpResponse getDelegate() {\n\t\treturn this.delegate;\n\t}", "summary_tokens": ["returns", "the", "target", "response", "that", "this", "response", "delegates", "to"], "project": "spring-framework"}
{"id": 5416, "code": "\tint getTotalParameterCount() {\n\t\treturn this.totalParameterCount;\n\t}", "summary_tokens": ["return", "the", "total", "count", "of", "all", "the", "parameters", "in", "the", "sql", "statement"], "project": "spring-framework"}
{"id": 9224, "code": "\tpublic int doEndTag() {\n\t\tif (this.previousNestedPath != null) {\n\t\t\t\n\t\t\tthis.pageContext.setAttribute(NESTED_PATH_VARIABLE_NAME, this.previousNestedPath, PageContext.REQUEST_SCOPE);\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tthis.pageContext.removeAttribute(NESTED_PATH_VARIABLE_NAME, PageContext.REQUEST_SCOPE);\n\t\t}\n\n\t\treturn EVAL_PAGE;\n\t}", "summary_tokens": ["reset", "any", "previous", "nested", "path", "value"], "project": "spring-framework"}
{"id": 1886, "code": "\tpublic static CronField parseMonth(String value) {\n\t\tvalue = replaceOrdinals(value, MONTHS);\n\t\treturn BitsCronField.parseMonth(value);\n\t}", "summary_tokens": ["parse", "the", "given", "value", "into", "a", "month", "cron", "field", "the", "fifth", "entry", "of", "a", "cron", "expression"], "project": "spring-framework"}
{"id": 2343, "code": "private int readField(\n    final ClassVisitor classVisitor, final Context context, final int fieldInfoOffset) {\n  char[] charBuffer = context.charBuffer;\n\n    \n  int currentOffset = fieldInfoOffset;\n  int accessFlags = readUnsignedShort(currentOffset);\n  String name = readUTF8(currentOffset + 2, charBuffer);\n  String descriptor = readUTF8(currentOffset + 4, charBuffer);\n  currentOffset += 6;\n\n    \n    \n    \n  Object constantValue = null;\n    \n  String signature = null;\n    \n  int runtimeVisibleAnnotationsOffset = 0;\n    \n  int runtimeInvisibleAnnotationsOffset = 0;\n    \n  int runtimeVisibleTypeAnnotationsOffset = 0;\n    \n  int runtimeInvisibleTypeAnnotationsOffset = 0;\n    \n    \n  Attribute attributes = null;\n\n  int attributesCount = readUnsignedShort(currentOffset);\n  currentOffset += 2;\n  while (attributesCount-- > 0) {\n      \n    String attributeName = readUTF8(currentOffset, charBuffer);\n    int attributeLength = readInt(currentOffset + 2);\n    currentOffset += 6;\n      \n      \n    if (Constants.CONSTANT_VALUE.equals(attributeName)) {\n      int constantvalueIndex = readUnsignedShort(currentOffset);\n      constantValue = constantvalueIndex == 0 ? null : readConst(constantvalueIndex, charBuffer);\n    } else if (Constants.SIGNATURE.equals(attributeName)) {\n      signature = readUTF8(currentOffset, charBuffer);\n    } else if (Constants.DEPRECATED.equals(attributeName)) {\n      accessFlags |= Opcodes.ACC_DEPRECATED;\n    } else if (Constants.SYNTHETIC.equals(attributeName)) {\n      accessFlags |= Opcodes.ACC_SYNTHETIC;\n    } else if (Constants.RUNTIME_VISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeVisibleTypeAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_INVISIBLE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleAnnotationsOffset = currentOffset;\n    } else if (Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS.equals(attributeName)) {\n      runtimeInvisibleTypeAnnotationsOffset = currentOffset;\n    } else {\n      Attribute attribute =\n          readAttribute(\n              context.attributePrototypes,\n              attributeName,\n              currentOffset,\n              attributeLength,\n              charBuffer,\n              -1,\n              null);\n      attribute.nextAttribute = attributes;\n      attributes = attribute;\n    }\n    currentOffset += attributeLength;\n  }\n\n    \n  FieldVisitor fieldVisitor =\n      classVisitor.visitField(accessFlags, name, descriptor, signature, constantValue);\n  if (fieldVisitor == null) {\n    return currentOffset;\n  }\n\n    \n  if (runtimeVisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              fieldVisitor.visitAnnotation(annotationDescriptor,  true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              fieldVisitor.visitAnnotation(annotationDescriptor,  false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeVisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeVisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeVisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              fieldVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   true),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  if (runtimeInvisibleTypeAnnotationsOffset != 0) {\n    int numAnnotations = readUnsignedShort(runtimeInvisibleTypeAnnotationsOffset);\n    int currentAnnotationOffset = runtimeInvisibleTypeAnnotationsOffset + 2;\n    while (numAnnotations-- > 0) {\n        \n      currentAnnotationOffset = readTypeAnnotationTarget(context, currentAnnotationOffset);\n        \n      String annotationDescriptor = readUTF8(currentAnnotationOffset, charBuffer);\n      currentAnnotationOffset += 2;\n        \n      currentAnnotationOffset =\n          readElementValues(\n              fieldVisitor.visitTypeAnnotation(\n                  context.currentTypeAnnotationTarget,\n                  context.currentTypeAnnotationTargetPath,\n                  annotationDescriptor,\n                   false),\n              currentAnnotationOffset,\n               true,\n              charBuffer);\n    }\n  }\n\n    \n  while (attributes != null) {\n      \n    Attribute nextAttribute = attributes.nextAttribute;\n    attributes.nextAttribute = null;\n    fieldVisitor.visitAttribute(attributes);\n    attributes = nextAttribute;\n  }\n\n    \n  fieldVisitor.visitEnd();\n  return currentOffset;\n}", "summary_tokens": ["reads", "a", "jvms", "field", "info", "structure", "and", "makes", "the", "given", "visitor", "visit", "it"], "project": "spring-framework"}
{"id": 6930, "code": "\tdefault List<MediaType> getSupportedMediaTypes(Class<?> clazz) {\n\t\treturn (canRead(clazz, null) || canWrite(clazz, null) ?\n\t\t\t\tgetSupportedMediaTypes() : Collections.emptyList());\n\t}", "summary_tokens": ["return", "the", "list", "of", "media", "types", "supported", "by", "this", "converter", "for", "the", "given", "class"], "project": "spring-framework"}
{"id": 9642, "code": "\tpublic List<ViewResolver> getViewResolvers() {\n\t\treturn Collections.unmodifiableList(this.viewResolvers);\n\t}", "summary_tokens": ["return", "the", "list", "of", "view", "view", "resolvers", "to", "delegate", "to"], "project": "spring-framework"}
{"id": 8127, "code": "\tpublic static RequestPredicate accept(MediaType... mediaTypes) {\n\t\tAssert.notEmpty(mediaTypes, \"'mediaTypes' must not be empty\");\n\t\treturn new AcceptPredicate(mediaTypes);\n\t}", "summary_tokens": ["return", "a", "request", "predicate", "that", "tests", "if", "the", "request", "s", "server", "request"], "project": "spring-framework"}
{"id": 5691, "code": "\tprotected void loadBeanDefinitions(GenericApplicationContext context, MergedContextConfiguration mergedConfig) {\n\t\tnew GroovyBeanDefinitionReader(context).loadBeanDefinitions(mergedConfig.getLocations());\n\t}", "summary_tokens": ["load", "bean", "definitions", "into", "the", "supplied", "generic", "application", "context", "context", "from", "the", "locations", "in", "the", "supplied", "merged", "context", "configuration", "using", "a", "groovy", "bean", "definition", "reader"], "project": "spring-framework"}
{"id": 1528, "code": "\tpublic void setBeans(Map<String, Object> beans) {\n\t\tthis.beans = beans;\n\t}", "summary_tokens": ["supply", "a", "map", "of", "beans", "to", "be", "registered", "with", "the", "jmx", "mbean", "server"], "project": "spring-framework"}
{"id": 7148, "code": "\tpublic final String getCookieName() {\n\t\treturn this.cookieName;\n\t}", "summary_tokens": ["return", "the", "expected", "name", "of", "the", "request", "cookie"], "project": "spring-framework"}
{"id": 5461, "code": "\tpublic void reset() {\n\t\tthis.request = null;\n\t\tthis.response = null;\n\t\tthis.iterator = null;\n\t}", "summary_tokens": ["reset", "this", "mock", "filter", "chain", "allowing", "it", "to", "be", "invoked", "again"], "project": "spring-framework"}
{"id": 9621, "code": "\tpublic void setRequestContextAttribute(@Nullable String requestContextAttribute) {\n\t\tthis.requestContextAttribute = requestContextAttribute;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "request", "context", "attribute", "for", "all", "views"], "project": "spring-framework"}
{"id": 8706, "code": "\tpublic SimpleControllerHandlerAdapter simpleControllerHandlerAdapter() {\n\t\treturn new SimpleControllerHandlerAdapter();\n\t}", "summary_tokens": ["returns", "a", "simple", "controller", "handler", "adapter", "for", "processing", "requests", "with", "interface", "based", "controllers"], "project": "spring-framework"}
{"id": 6905, "code": "\tprotected void extendTypedReaders(List<HttpMessageReader<?>> typedReaders) {\n\t}", "summary_tokens": ["hook", "for", "client", "or", "server", "specific", "typed", "readers"], "project": "spring-framework"}
{"id": 8684, "code": "\tprotected void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) {\n\t}", "summary_tokens": ["override", "this", "method", "to", "configure", "default", "servlet", "handling"], "project": "spring-framework"}
{"id": 8049, "code": "\tdefault void configureHttpMessageCodecs(ServerCodecConfigurer configurer) {\n\t}", "summary_tokens": ["configure", "the", "http", "message", "readers", "and", "writers", "for", "reading", "from", "the", "request", "body", "and", "for", "writing", "to", "the", "response", "body", "in", "annotated", "controllers", "and", "functional", "endpoints"], "project": "spring-framework"}
{"id": 8219, "code": "\tpublic Set<MediaType> getConsumableMediaTypes() {\n\t\tSet<MediaType> result = new LinkedHashSet<>();\n\t\tfor (ConsumeMediaTypeExpression expression : this.expressions) {\n\t\t\tif (!expression.isNegated()) {\n\t\t\t\tresult.add(expression.getMediaType());\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["returns", "the", "media", "types", "for", "this", "condition", "excluding", "negated", "expressions"], "project": "spring-framework"}
{"id": 787, "code": "\tprotected boolean shouldGenerateId() {\n\t\treturn false;\n\t}", "summary_tokens": ["should", "an", "id", "be", "generated", "instead", "of", "read", "from", "the", "passed", "in", "element", "p", "disabled", "by", "default", "subclasses", "can", "override", "this", "to", "enable", "id", "generation"], "project": "spring-framework"}
{"id": 5901, "code": "\tpublic WebTestClient.BodyContentSpec isArray() {\n\t\tthis.pathHelper.assertValueIsArray(this.content);\n\t\treturn this.bodySpec;\n\t}", "summary_tokens": ["applies", "json", "path", "expectations", "helper", "assert", "value", "is", "array", "string"], "project": "spring-framework"}
{"id": 104, "code": "\tpublic Class<?> getProxyClass(@Nullable ClassLoader classLoader) {\n\t\treturn createAopProxy().getProxyClass(classLoader);\n\t}", "summary_tokens": ["determine", "the", "proxy", "class", "according", "to", "the", "settings", "in", "this", "factory"], "project": "spring-framework"}
{"id": 190, "code": "\tprivate void checkForInvalidPlaceholders(String message) throws IllegalArgumentException {\n\t\tMatcher matcher = PATTERN.matcher(message);\n\t\twhile (matcher.find()) {\n\t\t\tString match = matcher.group();\n\t\t\tif (!ALLOWED_PLACEHOLDERS.contains(match)) {\n\t\t\t\tthrow new IllegalArgumentException(\"Placeholder [\" + match + \"] is not valid\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["checks", "to", "see", "if", "the", "supplied", "string", "has", "any", "placeholders", "that", "are", "not", "specified", "as", "constants", "on", "this", "class", "and", "throws", "an", "illegal", "argument", "exception", "if", "so"], "project": "spring-framework"}
{"id": 729, "code": "\tpublic void setSource(@Nullable Object source) {\n\t\tthis.source = source;\n\t}", "summary_tokens": ["set", "the", "configuration", "source", "object", "for", "this", "metadata", "element"], "project": "spring-framework"}
{"id": 4760, "code": "\tpublic HandlerMethodArgumentResolverComposite addResolvers(\n\t\t\t@Nullable List<? extends HandlerMethodArgumentResolver> resolvers) {\n\n\t\tif (resolvers != null) {\n\t\t\tthis.argumentResolvers.addAll(resolvers);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "given", "handler", "method", "argument", "resolver", "handler", "method", "argument", "resolvers"], "project": "spring-framework"}
{"id": 6741, "code": "\tpublic static HeadersBuilder<?> delete(String uriTemplate, Object... uriVariables) {\n\t\treturn method(HttpMethod.DELETE, uriTemplate, uriVariables);\n\t}", "summary_tokens": ["create", "an", "http", "delete", "builder", "with", "the", "given", "string", "base", "uri", "template"], "project": "spring-framework"}
{"id": 8161, "code": "\tstatic BodyBuilder from(ServerResponse other) {\n\t\treturn new DefaultServerResponseBuilder(other);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "the", "status", "code", "and", "headers", "of", "the", "given", "response"], "project": "spring-framework"}
{"id": 2668, "code": "\tpublic Object invoke(Object obj, Object[] args) throws Throwable {\n\t\ttry {\n\t\t\tinit();\n\t\t\tFastClassInfo fci = fastClassInfo;\n\t\t\treturn fci.f1.invoke(fci.i1, obj, args);\n\t\t}\n\t\tcatch (InvocationTargetException ex) {\n\t\t\tthrow ex.getTargetException();\n\t\t}\n\t\tcatch (IllegalArgumentException ex) {\n\t\t\tif (fastClassInfo.i1 < 0)\n\t\t\t\tthrow new IllegalArgumentException(\"Protected method: \" + sig1);\n\t\t\tthrow ex;\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "original", "method", "on", "a", "different", "object", "of", "the", "same", "type"], "project": "spring-framework"}
{"id": 2962, "code": "\tpublic final String getPath() {\n\t\treturn this.path.toString();\n\t}", "summary_tokens": ["return", "the", "file", "path", "for", "this", "resource"], "project": "spring-framework"}
{"id": 8414, "code": "\tprotected SimpleHash getTemplateModel(Map<String, Object> model, ServerWebExchange exchange) {\n\t\tSimpleHash fmModel = new SimpleHash(getObjectWrapper());\n\t\tfmModel.putAll(model);\n\t\treturn fmModel;\n\t}", "summary_tokens": ["build", "a", "free", "marker", "template", "model", "for", "the", "given", "model", "map"], "project": "spring-framework"}
{"id": 9503, "code": "\tpublic boolean isCacheUnresolved() {\n\t\treturn this.cacheUnresolved;\n\t}", "summary_tokens": ["return", "if", "caching", "of", "unresolved", "views", "is", "enabled"], "project": "spring-framework"}
{"id": 5386, "code": "\tstatic boolean containsStatementSeparator(EncodedResource resource, String script,\n\t\t\tString separator, String[] commentPrefixes, String blockCommentStartDelimiter,\n\t\t\tString blockCommentEndDelimiter) throws ScriptException {\n\n\t\tboolean inSingleQuote = false;\n\t\tboolean inDoubleQuote = false;\n\t\tboolean inEscape = false;\n\n\t\tfor (int i = 0; i < script.length(); i++) {\n\t\t\tchar c = script.charAt(i);\n\t\t\tif (inEscape) {\n\t\t\t\tinEscape = false;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t\n\t\t\tif (c == '\\\\') {\n\t\t\t\tinEscape = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!inDoubleQuote && (c == '\\'')) {\n\t\t\t\tinSingleQuote = !inSingleQuote;\n\t\t\t}\n\t\t\telse if (!inSingleQuote && (c == '\"')) {\n\t\t\t\tinDoubleQuote = !inDoubleQuote;\n\t\t\t}\n\t\t\tif (!inSingleQuote && !inDoubleQuote) {\n\t\t\t\tif (script.startsWith(separator, i)) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\telse if (startsWithAny(script, commentPrefixes, i)) {\n\t\t\t\t\t// Skip over any content from the start of the comment to the EOL\n\t\t\t\t\tint indexOfNextNewline = script.indexOf('\\n', i);\n\t\t\t\t\tif (indexOfNextNewline > i) {\n\t\t\t\t\t\ti = indexOfNextNewline;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\t// If there's no EOL, we must be at the end of the script, so stop here.\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (script.startsWith(blockCommentStartDelimiter, i)) {\n\t\t\t\t\t// Skip over any block comments\n\t\t\t\t\tint indexOfCommentEnd = script.indexOf(blockCommentEndDelimiter, i);\n\t\t\t\t\tif (indexOfCommentEnd > i) {\n\t\t\t\t\t\ti = indexOfCommentEnd + blockCommentEndDelimiter.length() - 1;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tthrow new ScriptParseException(\n\t\t\t\t\t\t\t\t\"Missing block comment end delimiter: \" + blockCommentEndDelimiter, resource);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "if", "the", "provided", "sql", "script", "contains", "the", "specified", "statement", "separator"], "project": "spring-framework"}
{"id": 246, "code": "\tpublic synchronized boolean isInitialized() {\n\t\treturn (this.lazyTarget != null);\n\t}", "summary_tokens": ["return", "whether", "the", "lazy", "target", "object", "of", "this", "target", "source", "has", "already", "been", "fetched"], "project": "spring-framework"}
{"id": 8773, "code": "\tstatic BodyBuilder accepted() {\n\t\treturn status(HttpStatus.ACCEPTED);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "a", "http", "status", "accepted", "0", "accepted", "status"], "project": "spring-framework"}
{"id": 8570, "code": "\tpublic AsyncSupportConfigurer setTaskExecutor(AsyncTaskExecutor taskExecutor) {\n\t\tthis.taskExecutor = taskExecutor;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "provided", "task", "executor", "is", "used", "to", "ol", "li", "handle", "callable", "controller", "method", "return", "values"], "project": "spring-framework"}
{"id": 34, "code": "\tpublic int getOrder() {\n\t\tif (this.aspectInstance instanceof Ordered) {\n\t\t\treturn ((Ordered) this.aspectInstance).getOrder();\n\t\t}\n\t\treturn getOrderForAspectClass(this.aspectInstance.getClass());\n\t}", "summary_tokens": ["determine", "the", "order", "for", "this", "factory", "s", "aspect", "instance", "either", "an", "instance", "specific", "order", "expressed", "through", "implementing", "the", "org"], "project": "spring-framework"}
{"id": 1293, "code": "\tpublic void clearCache() {\n\t\tif (this.metadataReaderFactory instanceof CachingMetadataReaderFactory) {\n\t\t\t\n\t\t\t\n\t\t\t((CachingMetadataReaderFactory) this.metadataReaderFactory).clearCache();\n\t\t}\n\t}", "summary_tokens": ["clear", "the", "local", "metadata", "cache", "if", "any", "removing", "all", "cached", "class", "metadata"], "project": "spring-framework"}
{"id": 7532, "code": "\tpublic static WebApplicationContext getWebApplicationContext(FacesContext fc) {\n\t\tAssert.notNull(fc, \"FacesContext must not be null\");\n\t\tObject attr = fc.getExternalContext().getApplicationMap().get(\n\t\t\t\tWebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE);\n\t\tif (attr == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (attr instanceof RuntimeException) {\n\t\t\tthrow (RuntimeException) attr;\n\t\t}\n\t\tif (attr instanceof Error) {\n\t\t\tthrow (Error) attr;\n\t\t}\n\t\tif (!(attr instanceof WebApplicationContext)) {\n\t\t\tthrow new IllegalStateException(\"Root context attribute is not of type WebApplicationContext: \" + attr);\n\t\t}\n\t\treturn (WebApplicationContext) attr;\n\t}", "summary_tokens": ["find", "the", "root", "web", "application", "context", "for", "this", "web", "app", "typically", "loaded", "via", "org"], "project": "spring-framework"}
{"id": 614, "code": "\tpublic void setBeanNameGenerator(@Nullable BeanNameGenerator beanNameGenerator) {\n\t\tthis.beanNameGenerator = (beanNameGenerator != null ? beanNameGenerator : DefaultBeanNameGenerator.INSTANCE);\n\t}", "summary_tokens": ["set", "the", "bean", "name", "generator", "to", "use", "for", "anonymous", "beans", "without", "explicit", "bean", "name", "specified"], "project": "spring-framework"}
{"id": 6566, "code": "\tpublic static void triggerBeforeCompletion() {\n\t\tfor (TransactionSynchronization synchronization : TransactionSynchronizationManager.getSynchronizations()) {\n\t\t\ttry {\n\t\t\t\tsynchronization.beforeCompletion();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tlogger.debug(\"TransactionSynchronization.beforeCompletion threw exception\", ex);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["trigger", "before", "completion", "callbacks", "on", "all", "currently", "registered", "synchronizations"], "project": "spring-framework"}
{"id": 9869, "code": "\tpublic void setServerContainer(@Nullable ServerContainer serverContainer) {\n\t\tthis.serverContainer = serverContainer;\n\t}", "summary_tokens": ["set", "the", "jsr", "0", "server", "container", "to", "use", "for", "endpoint", "registration"], "project": "spring-framework"}
{"id": 3140, "code": "\tpublic static Class<?>[] getAllInterfacesForClass(Class<?> clazz, @Nullable ClassLoader classLoader) {\n\t\treturn toClassArray(getAllInterfacesForClassAsSet(clazz, classLoader));\n\t}", "summary_tokens": ["return", "all", "interfaces", "that", "the", "given", "class", "implements", "as", "an", "array", "including", "ones", "implemented", "by", "superclasses"], "project": "spring-framework"}
{"id": 5739, "code": "\tprotected PlatformTransactionManager getTransactionManager(TestContext testContext) {\n\t\treturn TestContextTransactionUtils.retrieveTransactionManager(testContext, null);\n\t}", "summary_tokens": ["get", "the", "platform", "transaction", "manager", "transaction", "manager", "to", "use", "for", "the", "supplied", "test", "context", "test", "context"], "project": "spring-framework"}
{"id": 3223, "code": "\tprivate static void close(Closeable closeable) {\n\t\ttry {\n\t\t\tcloseable.close();\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\t\n\t\t}\n\t}", "summary_tokens": ["attempt", "to", "close", "the", "supplied", "closeable", "silently", "swallowing", "any", "exceptions"], "project": "spring-framework"}
{"id": 2517, "code": "public void visitEnd() {\n  if (mv != null) {\n    mv.visitEnd();\n  }\n}", "summary_tokens": ["visits", "the", "end", "of", "the", "module"], "project": "spring-framework"}
{"id": 6932, "code": "\tpublic void setWriteAcceptCharset(boolean writeAcceptCharset) {\n\t\tthis.stringHttpMessageConverter.setWriteAcceptCharset(writeAcceptCharset);\n\t}", "summary_tokens": ["delegates", "to", "string", "http", "message", "converter", "set", "write", "accept", "charset", "boolean"], "project": "spring-framework"}
{"id": 6142, "code": "\tvoid autowiredAndNonAutowiredTestMethods() {\n\t\ttestEventsFor(AutowiredAndNonAutowiredTestMethods.class)\n\t\t\t.assertStatistics(stats -> stats.started(2).succeeded(0).failed(2))\n\t\t\t.assertThatEvents()\n\t\t\t\t.haveExactly(1,\n\t\t\t\t\tevent(testWithDisplayName(\"autowired(TestInfo)\"),\n\t\t\t\t\tfinishedWithFailure(\n\t\t\t\t\t\tinstanceOf(IllegalStateException.class),\n\t\t\t\t\t\tmessage(msg -> msg.matches(\".+must not be annotated with @Autowired.+\")))))\n\t\t\t\t.haveExactly(1,\n\t\t\t\t\tevent(testWithDisplayName(\"nonAutowired(TestInfo)\"),\n\t\t\t\t\tfinishedWithFailure(\n\t\t\t\t\t\tinstanceOf(IllegalStateException.class),\n\t\t\t\t\t\tmessage(msg -> msg.matches(\".+must not be annotated with @Autowired.+\")))));\n\t}", "summary_tokens": ["a", "non", "autowired", "test", "method", "should", "fail", "the", "same", "as", "an", "autowired", "test", "method", "in", "the", "same", "class", "since", "spring", "still", "should", "not", "autowire", "the", "autowired", "test", "method", "as", "a", "configuration", "method", "when", "junit", "attempts", "to", "execute", "the", "non", "autowired", "test", "method"], "project": "spring-framework"}
{"id": 2776, "code": "\tpublic static <A extends Annotation> A findMergedAnnotation(AnnotatedElement element, Class<A> annotationType) {\n\t\t\n\t\tif (AnnotationFilter.PLAIN.matches(annotationType) ||\n\t\t\t\tAnnotationsScanner.hasPlainJavaAnnotationsOnly(element)) {\n\t\t\treturn element.getDeclaredAnnotation(annotationType);\n\t\t}\n\t\t\n\t\treturn findAnnotations(element)\n\t\t\t\t.get(annotationType, null, MergedAnnotationSelectors.firstDirectlyDeclared())\n\t\t\t\t.synthesize(MergedAnnotation::isPresent).orElse(null);\n\t}", "summary_tokens": ["find", "the", "first", "annotation", "of", "the", "specified", "annotation", "type", "within", "the", "annotation", "hierarchy", "em", "above", "em", "the", "supplied", "element", "merge", "that", "annotation", "s", "attributes", "with", "em", "matching", "em", "attributes", "from", "annotations", "in", "lower", "levels", "of", "the", "annotation", "hierarchy", "and", "synthesize", "the", "result", "back", "into", "an", "annotation", "of", "the", "specified", "annotation", "type"], "project": "spring-framework"}
{"id": 2782, "code": "\tAnnotationTypeMapping get(int index) {\n\t\treturn this.mappings.get(index);\n\t}", "summary_tokens": ["get", "an", "individual", "mapping", "from", "this", "instance"], "project": "spring-framework"}
{"id": 4340, "code": "\tpublic void setPriority(int priority) {\n\t\tthis.priority = priority;\n\t}", "summary_tokens": ["set", "the", "priority", "of", "a", "message", "when", "sending"], "project": "spring-framework"}
{"id": 1466, "code": "\tpublic static void enableAspectJWeaving(\n\t\t\t@Nullable LoadTimeWeaver weaverToUse, @Nullable ClassLoader beanClassLoader) {\n\n\t\tif (weaverToUse == null) {\n\t\t\tif (InstrumentationLoadTimeWeaver.isInstrumentationAvailable()) {\n\t\t\t\tweaverToUse = new InstrumentationLoadTimeWeaver(beanClassLoader);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalStateException(\"No LoadTimeWeaver available\");\n\t\t\t}\n\t\t}\n\t\tweaverToUse.addTransformer(\n\t\t\t\tnew AspectJClassBypassingClassFileTransformer(new ClassPreProcessorAgentAdapter()));\n\t}", "summary_tokens": ["enable", "aspect", "j", "weaving", "with", "the", "given", "load", "time", "weaver"], "project": "spring-framework"}
{"id": 4929, "code": "\tpublic MessageConverter getMessageConverter() {\n\t\treturn this.converter;\n\t}", "summary_tokens": ["return", "the", "configured", "message", "converter"], "project": "spring-framework"}
{"id": 2374, "code": "public String readPackage(final int offset, final char[] charBuffer) {\n  return readStringish(offset, charBuffer);\n}", "summary_tokens": ["reads", "a", "constant", "package", "constant", "pool", "entry", "in", "this", "class", "reader"], "project": "spring-framework"}
{"id": 9021, "code": "\tpublic synchronized void complete() {\n\t\t\n\t\tif (this.sendFailed) {\n\t\t\treturn;\n\t\t}\n\t\tthis.complete = true;\n\t\tif (this.handler != null) {\n\t\t\tthis.handler.complete();\n\t\t}\n\t}", "summary_tokens": ["complete", "request", "processing", "by", "performing", "a", "dispatch", "into", "the", "servlet", "container", "where", "spring", "mvc", "is", "invoked", "once", "more", "and", "completes", "the", "request", "processing", "lifecycle"], "project": "spring-framework"}
{"id": 1544, "code": "\tprotected void registerBeans() {\n\t\t\n\t\tif (this.beans == null) {\n\t\t\tthis.beans = new HashMap<>();\n\t\t\t\n\t\t\tif (this.autodetectMode == null) {\n\t\t\t\tthis.autodetectMode = AUTODETECT_ALL;\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tint mode = (this.autodetectMode != null ? this.autodetectMode : AUTODETECT_NONE);\n\t\tif (mode != AUTODETECT_NONE) {\n\t\t\tif (this.beanFactory == null) {\n\t\t\t\tthrow new MBeanExportException(\"Cannot autodetect MBeans if not running in a BeanFactory\");\n\t\t\t}\n\t\t\tif (mode == AUTODETECT_MBEAN || mode == AUTODETECT_ALL) {\n\t\t\t\t\n\t\t\t\tlogger.debug(\"Autodetecting user-defined JMX MBeans\");\n\t\t\t\tautodetect(this.beans, (beanClass, beanName) -> isMBean(beanClass));\n\t\t\t}\n\t\t\t\n\t\t\tif ((mode == AUTODETECT_ASSEMBLER || mode == AUTODETECT_ALL) &&\n\t\t\t\t\tthis.assembler instanceof AutodetectCapableMBeanInfoAssembler) {\n\t\t\t\tautodetect(this.beans, ((AutodetectCapableMBeanInfoAssembler) this.assembler)::includeBean);\n\t\t\t}\n\t\t}\n\n\t\tif (!this.beans.isEmpty()) {\n\t\t\tthis.beans.forEach((beanName, instance) -> registerBeanNameOrInstance(instance, beanName));\n\t\t}\n\t}", "summary_tokens": ["register", "the", "defined", "beans", "with", "the", "mbean", "server"], "project": "spring-framework"}
{"id": 8165, "code": "\tstatic BodyBuilder accepted() {\n\t\treturn status(HttpStatus.ACCEPTED);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "an", "http", "status", "accepted", "0", "accepted", "status"], "project": "spring-framework"}
{"id": 504, "code": "\tpublic Object getObject() throws Exception {\n\t\tif (this.singleton) {\n\t\t\tif (!this.initialized) {\n\t\t\t\tthrow new FactoryBeanNotInitializedException();\n\t\t\t}\n\t\t\t\n\t\t\treturn this.singletonObject;\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\treturn invokeWithTargetException();\n\t\t}\n\t}", "summary_tokens": ["returns", "the", "same", "value", "each", "time", "if", "the", "singleton", "property", "is", "set", "to", "true", "otherwise", "returns", "the", "value", "returned", "from", "invoking", "the", "specified", "method", "on", "the", "fly"], "project": "spring-framework"}
{"id": 4980, "code": "\tprivate Message<byte[]> decodeMessage(ByteBuffer byteBuffer, @Nullable MultiValueMap<String, String> headers) {\n\t\tMessage<byte[]> decodedMessage = null;\n\t\tskipEol(byteBuffer);\n\t\tbyteBuffer.mark();\n\n\t\tString command = readCommand(byteBuffer);\n\t\tif (command.length() > 0) {\n\t\t\tStompHeaderAccessor headerAccessor = null;\n\t\t\tbyte[] payload = null;\n\t\t\tif (byteBuffer.remaining() > 0) {\n\t\t\t\tStompCommand stompCommand = StompCommand.valueOf(command);\n\t\t\t\theaderAccessor = StompHeaderAccessor.create(stompCommand);\n\t\t\t\tinitHeaders(headerAccessor);\n\t\t\t\treadHeaders(byteBuffer, headerAccessor, stompCommand);\n\t\t\t\tpayload = readPayload(byteBuffer, headerAccessor);\n\t\t\t}\n\t\t\tif (payload != null) {\n\t\t\t\tif (payload.length > 0) {\n\t\t\t\t\tStompCommand stompCommand = headerAccessor.getCommand();\n\t\t\t\t\tif (stompCommand != null && !stompCommand.isBodyAllowed()) {\n\t\t\t\t\t\tthrow new StompConversionException(stompCommand +\n\t\t\t\t\t\t\t\t\" shouldn't have a payload: length=\" + payload.length + \", headers=\" + headers);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\theaderAccessor.updateSimpMessageHeadersFromStompHeaders();\n\t\t\t\theaderAccessor.setLeaveMutable(true);\n\t\t\t\tdecodedMessage = MessageBuilder.createMessage(payload, headerAccessor.getMessageHeaders());\n\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\tlogger.trace(\"Decoded \" + headerAccessor.getDetailedLogMessage(payload));\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tlogger.trace(\"Incomplete frame, resetting input buffer...\");\n\t\t\t\tif (headers != null && headerAccessor != null) {\n\t\t\t\t\tString name = NativeMessageHeaderAccessor.NATIVE_HEADERS;\n\t\t\t\t\t@SuppressWarnings(\"unchecked\")\n\t\t\t\t\tMultiValueMap<String, String> map = (MultiValueMap<String, String>) headerAccessor.getHeader(name);\n\t\t\t\t\tif (map != null) {\n\t\t\t\t\t\theaders.putAll(map);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tbyteBuffer.reset();\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tStompHeaderAccessor headerAccessor = StompHeaderAccessor.createForHeartbeat();\n\t\t\tinitHeaders(headerAccessor);\n\t\t\theaderAccessor.setLeaveMutable(true);\n\t\t\tdecodedMessage = MessageBuilder.createMessage(HEARTBEAT_PAYLOAD, headerAccessor.getMessageHeaders());\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Decoded \" + headerAccessor.getDetailedLogMessage(null));\n\t\t\t}\n\t\t}\n\n\t\treturn decodedMessage;\n\t}", "summary_tokens": ["decode", "a", "single", "stomp", "frame", "from", "the", "given", "buffer", "into", "a", "message"], "project": "spring-framework"}
{"id": 9000, "code": "\tpublic void setUseTrailingSlashMatch(boolean useTrailingSlashMatch) {\n\t\tthis.useTrailingSlashMatch = useTrailingSlashMatch;\n\t\tif (getPatternParser() != null) {\n\t\t\tgetPatternParser().setMatchOptionalTrailingSeparator(useTrailingSlashMatch);\n\t\t}\n\t}", "summary_tokens": ["whether", "to", "match", "to", "urls", "irrespective", "of", "the", "presence", "of", "a", "trailing", "slash"], "project": "spring-framework"}
{"id": 6661, "code": "\tpublic void setContentLength(long contentLength) {\n\t\tset(CONTENT_LENGTH, Long.toString(contentLength));\n\t}", "summary_tokens": ["set", "the", "length", "of", "the", "body", "in", "bytes", "as", "specified", "by", "the", "content", "length", "header"], "project": "spring-framework"}
{"id": 5017, "code": "\tpublic String getSubscription() {\n\t\treturn getFirst(SUBSCRIPTION);\n\t}", "summary_tokens": ["get", "the", "subscription", "header"], "project": "spring-framework"}
{"id": 7153, "code": "\tpublic final String getParameterName() {\n\t\treturn this.parameterName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "offending", "parameter"], "project": "spring-framework"}
{"id": 9763, "code": "\tpublic boolean isRunning() {\n\t\treturn this.running;\n\t}", "summary_tokens": ["return", "whether", "this", "connection", "manager", "has", "been", "started"], "project": "spring-framework"}
{"id": 8368, "code": "\tprotected Mono<Void> sendRedirect(String targetUrl, ServerWebExchange exchange) {\n\t\tString transformedUrl = (isRemoteHost(targetUrl) ? targetUrl : exchange.transformUrl(targetUrl));\n\t\tServerHttpResponse response = exchange.getResponse();\n\t\tresponse.getHeaders().setLocation(URI.create(transformedUrl));\n\t\tresponse.setStatusCode(getStatusCode());\n\t\treturn Mono.empty();\n\t}", "summary_tokens": ["send", "a", "redirect", "back", "to", "the", "http", "client"], "project": "spring-framework"}
{"id": 9078, "code": "\tprotected WebApplicationContext createRootApplicationContext() {\n\t\tClass<?>[] configClasses = getRootConfigClasses();\n\t\tif (!ObjectUtils.isEmpty(configClasses)) {\n\t\t\tAnnotationConfigWebApplicationContext context = new AnnotationConfigWebApplicationContext();\n\t\t\tcontext.register(configClasses);\n\t\t\treturn context;\n\t\t}\n\t\telse {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["p", "this", "implementation", "creates", "an", "annotation", "config", "web", "application", "context", "providing", "it", "the", "annotated", "classes", "returned", "by", "get", "root", "config", "classes"], "project": "spring-framework"}
{"id": 8762, "code": "\tdefault RequestPath requestPath() {\n\t\treturn ServletRequestPathUtils.getParsedRequestPath(servletRequest());\n\t}", "summary_tokens": ["get", "the", "request", "path", "as", "a", "path", "container"], "project": "spring-framework"}
{"id": 7201, "code": "\tpublic final void setMessageCodesResolver(@Nullable MessageCodesResolver messageCodesResolver) {\n\t\tthis.messageCodesResolver = messageCodesResolver;\n\t}", "summary_tokens": ["set", "the", "strategy", "to", "use", "for", "resolving", "errors", "into", "message", "codes"], "project": "spring-framework"}
{"id": 2465, "code": "public String getDescriptor() {\n  return descriptor;\n}", "summary_tokens": ["returns", "the", "descriptor", "of", "the", "method"], "project": "spring-framework"}
{"id": 1194, "code": "\tpublic Collection<CacheOperation> getCacheOperations(Method method, @Nullable Class<?> targetClass) {\n\t\tif (method.getDeclaringClass() == Object.class) {\n\t\t\treturn null;\n\t\t}\n\n\t\tObject cacheKey = getCacheKey(method, targetClass);\n\t\tCollection<CacheOperation> cached = this.attributeCache.get(cacheKey);\n\n\t\tif (cached != null) {\n\t\t\treturn (cached != NULL_CACHING_ATTRIBUTE ? cached : null);\n\t\t}\n\t\telse {\n\t\t\tCollection<CacheOperation> cacheOps = computeCacheOperations(method, targetClass);\n\t\t\tif (cacheOps != null) {\n\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\tlogger.trace(\"Adding cacheable method '\" + method.getName() + \"' with attribute: \" + cacheOps);\n\t\t\t\t}\n\t\t\t\tthis.attributeCache.put(cacheKey, cacheOps);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.attributeCache.put(cacheKey, NULL_CACHING_ATTRIBUTE);\n\t\t\t}\n\t\t\treturn cacheOps;\n\t\t}\n\t}", "summary_tokens": ["determine", "the", "caching", "attribute", "for", "this", "method", "invocation"], "project": "spring-framework"}
{"id": 5715, "code": "\tpublic void run(IHookCallBack callBack, ITestResult testResult) {\n\t\tMethod testMethod = testResult.getMethod().getConstructorOrMethod().getMethod();\n\t\tboolean beforeCallbacksExecuted = false;\n\n\t\ttry {\n\t\t\tthis.testContextManager.beforeTestExecution(this, testMethod);\n\t\t\tbeforeCallbacksExecuted = true;\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tthis.testException = ex;\n\t\t}\n\n\t\tif (beforeCallbacksExecuted) {\n\t\t\tcallBack.runTestMethod(testResult);\n\t\t\tthis.testException = getTestResultException(testResult);\n\t\t}\n\n\t\ttry {\n\t\t\tthis.testContextManager.afterTestExecution(this, testMethod, this.testException);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tif (this.testException == null) {\n\t\t\t\tthis.testException = ex;\n\t\t\t}\n\t\t}\n\n\t\tif (this.testException != null) {\n\t\t\tthrowAsUncheckedException(this.testException);\n\t\t}\n\t}", "summary_tokens": ["delegates", "to", "the", "ihook", "call", "back", "run", "test", "method", "itest", "result", "test", "method", "in", "the", "supplied", "callback", "to", "execute", "the", "actual", "test", "and", "then", "tracks", "the", "exception", "thrown", "during", "test", "execution", "if", "any"], "project": "spring-framework"}
{"id": 4124, "code": "\tpublic Map<String, Object> execute(ParameterMapper inParamMapper) throws DataAccessException {\n\t\tcheckCompiled();\n\t\treturn getJdbcTemplate().call(newCallableStatementCreator(inParamMapper), getDeclaredParameters());\n\t}", "summary_tokens": ["execute", "the", "stored", "procedure"], "project": "spring-framework"}
{"id": 3020, "code": "\tpublic static <T> List<T> loadFactories(Class<T> factoryType, @Nullable ClassLoader classLoader) {\n\t\treturn forDefaultResourceLocation(classLoader).load(factoryType);\n\t}", "summary_tokens": ["load", "and", "instantiate", "the", "factory", "implementations", "of", "the", "given", "type", "from", "factories", "resource", "location", "using", "the", "given", "class", "loader"], "project": "spring-framework"}
{"id": 2902, "code": "\tpublic Object getProperty(String name) {\n\t\tString actualName = resolvePropertyName(name);\n\t\tif (logger.isDebugEnabled() && !name.equals(actualName)) {\n\t\t\tlogger.debug(\"PropertySource '\" + getName() + \"' does not contain property '\" + name +\n\t\t\t\t\t\"', but found equivalent '\" + actualName + \"'\");\n\t\t}\n\t\treturn super.getProperty(actualName);\n\t}", "summary_tokens": ["this", "implementation", "returns", "true", "if", "a", "property", "with", "the", "given", "name", "or", "any", "underscore", "uppercase", "variant", "thereof", "exists", "in", "this", "property", "source"], "project": "spring-framework"}
{"id": 5890, "code": "\tpublic WebTestClient.ResponseSpec lastModified(long lastModified) {\n\t\treturn assertHeader(\"Last-Modified\", lastModified, getHeaders().getLastModified());\n\t}", "summary_tokens": ["expect", "a", "last", "modified", "header", "with", "the", "given", "value"], "project": "spring-framework"}
{"id": 1432, "code": "\tprotected MessageFormat createMessageFormat(String msg, Locale locale) {\n\t\treturn new MessageFormat(msg, locale);\n\t}", "summary_tokens": ["create", "a", "message", "format", "for", "the", "given", "message", "and", "locale"], "project": "spring-framework"}
{"id": 5314, "code": "\tpublic final void marshal(Object graph, Result result) throws IOException, XmlMappingException {\n\t\tif (result instanceof DOMResult) {\n\t\t\tmarshalDomResult(graph, (DOMResult) result);\n\t\t}\n\t\telse if (StaxUtils.isStaxResult(result)) {\n\t\t\tmarshalStaxResult(graph, result);\n\t\t}\n\t\telse if (result instanceof SAXResult) {\n\t\t\tmarshalSaxResult(graph, (SAXResult) result);\n\t\t}\n\t\telse if (result instanceof StreamResult) {\n\t\t\tmarshalStreamResult(graph, (StreamResult) result);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"Unknown Result type: \" + result.getClass());\n\t\t}\n\t}", "summary_tokens": ["marshals", "the", "object", "graph", "with", "the", "given", "root", "into", "the", "provided", "javax"], "project": "spring-framework"}
{"id": 480, "code": "\tpublic Class<?> getDependencyType() {\n\t\tif (this.field != null) {\n\t\t\tif (this.nestingLevel > 1) {\n\t\t\t\tClass<?> clazz = getResolvableType().getRawClass();\n\t\t\t\treturn (clazz != null ? clazz : Object.class);\n\t\t\t}\n\t\t\telse {\n\t\t\t\treturn this.field.getType();\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\treturn obtainMethodParameter().getNestedParameterType();\n\t\t}\n\t}", "summary_tokens": ["determine", "the", "declared", "non", "generic", "type", "of", "the", "wrapped", "parameter", "field"], "project": "spring-framework"}
{"id": 6344, "code": "\tprivate GenericReactiveTransaction prepareReactiveTransaction(\n\t\t\tTransactionSynchronizationManager synchronizationManager, TransactionDefinition definition,\n\t\t\t@Nullable Object transaction, boolean newTransaction, boolean debug, @Nullable Object suspendedResources) {\n\n\t\tGenericReactiveTransaction status = newReactiveTransaction(synchronizationManager,\n\t\t\t\tdefinition, transaction, newTransaction, debug, suspendedResources);\n\t\tprepareSynchronization(synchronizationManager, status, definition);\n\t\treturn status;\n\t}", "summary_tokens": ["create", "a", "new", "reactive", "transaction", "for", "the", "given", "arguments", "also", "initializing", "transaction", "synchronization", "as", "appropriate"], "project": "spring-framework"}
{"id": 5410, "code": "\tint[] getParameterIndexes(int parameterPosition) {\n\t\treturn this.parameterIndexes.get(parameterPosition);\n\t}", "summary_tokens": ["return", "the", "parameter", "indexes", "for", "the", "specified", "parameter"], "project": "spring-framework"}
{"id": 4234, "code": "\tpublic void setMessageHandlerMethodFactory(@Nullable MessageHandlerMethodFactory messageHandlerMethodFactory) {\n\t\tthis.messageHandlerMethodFactory = messageHandlerMethodFactory;\n\t}", "summary_tokens": ["set", "the", "message", "handler", "method", "factory", "to", "use", "to", "configure", "the", "message", "listener", "responsible", "to", "serve", "an", "endpoint", "detected", "by", "this", "processor"], "project": "spring-framework"}
{"id": 5182, "code": "\tpublic LocalSessionFactoryBuilder addPackages(String... annotatedPackages) {\n\t\tfor (String annotatedPackage : annotatedPackages) {\n\t\t\taddPackage(annotatedPackage);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "given", "annotated", "packages", "in", "a", "batch"], "project": "spring-framework"}
{"id": 607, "code": "\tpublic Object extractSource(Object sourceCandidate) {\n\t\treturn this.sourceExtractor.extractSource(sourceCandidate, this.resource);\n\t}", "summary_tokens": ["call", "the", "source", "extractor", "for", "the", "given", "source", "object"], "project": "spring-framework"}
{"id": 3641, "code": "\tprivate void checkMatch(Class<?>[] inputTypes, Class<?>[] expectedTypes, StandardTypeConverter typeConverter, ArgumentsMatchKind expectedMatchKind) {\n\t\tReflectionHelper.ArgumentsMatchInfo matchInfo = ReflectionHelper.compareArguments(getTypeDescriptors(expectedTypes), getTypeDescriptors(inputTypes), typeConverter);\n\t\tif (expectedMatchKind == null) {\n\t\t\tassertThat(matchInfo).as(\"Did not expect them to match in any way\").isNull();\n\t\t}\n\t\telse {\n\t\t\tassertThat(matchInfo).as(\"Should not be a null match\").isNotNull();\n\t\t}\n\n\t\tif (expectedMatchKind == ArgumentsMatchKind.EXACT) {\n\t\t\tassertThat(matchInfo.isExactMatch()).isTrue();\n\t\t}\n\t\telse if (expectedMatchKind == ArgumentsMatchKind.CLOSE) {\n\t\t\tassertThat(matchInfo.isCloseMatch()).isTrue();\n\t\t}\n\t\telse if (expectedMatchKind == ArgumentsMatchKind.REQUIRES_CONVERSION) {\n\t\t\tassertThat(matchInfo.isMatchRequiringConversion()).as(\"expected to be a match requiring conversion, but was \" + matchInfo).isTrue();\n\t\t}\n\t}", "summary_tokens": ["used", "to", "validate", "the", "match", "returned", "from", "a", "compare", "arguments", "call"], "project": "spring-framework"}
{"id": 1696, "code": "\tpublic static boolean isMBean(@Nullable Class<?> clazz) {\n\t\treturn (clazz != null &&\n\t\t\t\t(DynamicMBean.class.isAssignableFrom(clazz) ||\n\t\t\t\t\t\t(getMBeanInterface(clazz) != null || getMXBeanInterface(clazz) != null)));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "bean", "class", "qualifies", "as", "an", "mbean", "as", "is"], "project": "spring-framework"}
{"id": 4463, "code": "\tpublic void setMaxMessagesPerTask(int maxMessagesPerTask) {\n\t\tAssert.isTrue(maxMessagesPerTask != 0, \"'maxMessagesPerTask' must not be 0\");\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tthis.maxMessagesPerTask = maxMessagesPerTask;\n\t\t}\n\t}", "summary_tokens": ["specify", "the", "maximum", "number", "of", "messages", "to", "process", "in", "one", "task"], "project": "spring-framework"}
{"id": 4673, "code": "\tprivate NamedValueInfo updateNamedValueInfo(MethodParameter parameter, NamedValueInfo info) {\n\t\tString name = info.name;\n\t\tif (info.name.isEmpty()) {\n\t\t\tname = parameter.getParameterName();\n\t\t\tif (name == null) {\n\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\"Name for argument of type [\" + parameter.getNestedParameterType().getName() +\n\t\t\t\t\t\t\"] not specified, and parameter name information not found in class file either.\");\n\t\t\t}\n\t\t}\n\t\treturn new NamedValueInfo(name, info.required,\n\t\t\t\tValueConstants.DEFAULT_NONE.equals(info.defaultValue) ? null : info.defaultValue);\n\t}", "summary_tokens": ["fall", "back", "on", "the", "parameter", "name", "from", "the", "class", "file", "if", "necessary", "and", "replace", "value", "constants", "default", "none", "with", "null"], "project": "spring-framework"}
{"id": 6733, "code": "\tpublic URI getUrl() {\n\t\tif (this.url == null) {\n\t\t\tthrow new UnsupportedOperationException();\n\t\t}\n\t\treturn this.url;\n\t}", "summary_tokens": ["return", "the", "url", "of", "the", "request"], "project": "spring-framework"}
{"id": 82, "code": "\tpublic boolean equals(@Nullable Object other) {\n\t\tif (other == this) {\n\t\t\treturn true;\n\t\t}\n\t\tif (other == null) {\n\t\t\treturn false;\n\t\t}\n\n\t\tJdkDynamicAopProxy otherProxy;\n\t\tif (other instanceof JdkDynamicAopProxy) {\n\t\t\totherProxy = (JdkDynamicAopProxy) other;\n\t\t}\n\t\telse if (Proxy.isProxyClass(other.getClass())) {\n\t\t\tInvocationHandler ih = Proxy.getInvocationHandler(other);\n\t\t\tif (!(ih instanceof JdkDynamicAopProxy)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\totherProxy = (JdkDynamicAopProxy) ih;\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\treturn false;\n\t\t}\n\n\t\t\n\t\treturn AopProxyUtils.equalsInProxy(this.advised, otherProxy.advised);\n\t}", "summary_tokens": ["equality", "means", "interfaces", "advisors", "and", "target", "source", "are", "equal"], "project": "spring-framework"}
{"id": 7117, "code": "\tpublic void setStrategies(@Nullable List<ContentNegotiationStrategy> strategies) {\n\t\tthis.strategies = (strategies != null ? new ArrayList<>(strategies) : null);\n\t}", "summary_tokens": ["set", "the", "exact", "list", "of", "strategies", "to", "use"], "project": "spring-framework"}
{"id": 1660, "code": "\tpublic void setDescription(@Nullable String description) {\n\t\tthis.description = description;\n\t}", "summary_tokens": ["set", "a", "description", "for", "this", "notification"], "project": "spring-framework"}
{"id": 8043, "code": "\tprotected void configureViewResolvers(ViewResolverRegistry registry) {\n\t}", "summary_tokens": ["configure", "view", "resolution", "for", "supporting", "template", "engines"], "project": "spring-framework"}
{"id": 4891, "code": "\tpublic ChannelRegistration interceptors(ChannelInterceptor... interceptors) {\n\t\tthis.interceptors.addAll(Arrays.asList(interceptors));\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "the", "given", "interceptors", "for", "this", "message", "channel", "adding", "them", "to", "the", "channel", "s", "current", "list", "of", "interceptors"], "project": "spring-framework"}
{"id": 8729, "code": "\tdefault void extendMessageConverters(List<HttpMessageConverter<?>> converters) {\n\t}", "summary_tokens": ["extend", "or", "modify", "the", "list", "of", "converters", "after", "it", "has", "been", "either", "configure", "message", "converters", "list", "configured", "or", "initialized", "with", "a", "default", "list"], "project": "spring-framework"}
{"id": 4957, "code": "\tpublic String getVirtualHost() {\n\t\treturn this.virtualHost;\n\t}", "summary_tokens": ["return", "the", "configured", "virtual", "host", "value"], "project": "spring-framework"}
{"id": 3387, "code": "\tpublic static DataSize ofKilobytes(long kilobytes) {\n\t\treturn new DataSize(Math.multiplyExact(kilobytes, BYTES_PER_KB));\n\t}", "summary_tokens": ["obtain", "a", "data", "size", "representing", "the", "specified", "number", "of", "kilobytes"], "project": "spring-framework"}
{"id": 7879, "code": "\tprivate void resetPathElementState() {\n\t\tthis.pathElementStart = -1;\n\t\tthis.singleCharWildcardCount = 0;\n\t\tthis.insideVariableCapture = false;\n\t\tthis.variableCaptureCount = 0;\n\t\tthis.wildcard = false;\n\t\tthis.isCaptureTheRestVariable = false;\n\t\tthis.variableCaptureStart = -1;\n\t}", "summary_tokens": ["reset", "all", "the", "flags", "and", "position", "markers", "computed", "during", "path", "element", "processing"], "project": "spring-framework"}
{"id": 8339, "code": "\tpublic Class<?> getValueType() {\n\t\treturn this.valueType;\n\t}", "summary_tokens": ["get", "the", "class", "type", "of", "the", "field"], "project": "spring-framework"}
{"id": 2575, "code": "public static String getInternalName(final Class<?> clazz) {\n  return clazz.getName().replace('.', '/');\n}", "summary_tokens": ["returns", "the", "internal", "name", "of", "the", "given", "class"], "project": "spring-framework"}
{"id": 7995, "code": "\tpublic PathMatchConfigurer addPathPrefix(String prefix, Predicate<Class<?>> predicate) {\n\t\tif (this.pathPrefixes == null) {\n\t\t\tthis.pathPrefixes = new LinkedHashMap<>();\n\t\t}\n\t\tthis.pathPrefixes.put(prefix, predicate);\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "a", "path", "prefix", "to", "apply", "to", "matching", "controller", "methods"], "project": "spring-framework"}
{"id": 4098, "code": "\tpublic boolean isSqlReadyForUse() {\n\t\treturn this.sqlReadyForUse;\n\t}", "summary_tokens": ["return", "whether", "the", "sql", "can", "be", "used", "as", "is"], "project": "spring-framework"}
{"id": 4064, "code": "\tprotected final T mapRow(ResultSet rs, int rowNum, @Nullable Object[] parameters, @Nullable Map<?, ?> context)\n\t\t\tthrows SQLException {\n\n\t\treturn mapRow(rs, rowNum);\n\t}", "summary_tokens": ["this", "method", "is", "implemented", "to", "invoke", "the", "simpler", "map", "row", "template", "method", "ignoring", "parameters"], "project": "spring-framework"}
{"id": 5861, "code": "\tpublic static DefaultResponseCreator withRawStatus(int status) {\n\t\treturn new DefaultResponseCreator(status);\n\t}", "summary_tokens": ["variant", "of", "with", "status", "http", "status", "code", "with", "an", "integer"], "project": "spring-framework"}
{"id": 3694, "code": "\tpublic final int getRowCount() {\n\t\treturn this.rowCount;\n\t}", "summary_tokens": ["return", "the", "row", "count", "of", "this", "result", "set"], "project": "spring-framework"}
{"id": 4482, "code": "\tprotected void messageReceived(Object invoker, Session session) {\n\t\t((AsyncMessageListenerInvoker) invoker).setIdle(false);\n\t\tscheduleNewInvokerIfAppropriate();\n\t}", "summary_tokens": ["tries", "scheduling", "a", "new", "invoker", "since", "we", "know", "messages", "are", "coming", "in"], "project": "spring-framework"}
{"id": 4688, "code": "\tpublic void setMessageConverter(MessageConverter messageConverter) {\n\t\tthis.messageConverter = messageConverter;\n\t}", "summary_tokens": ["set", "the", "message", "converter", "to", "use"], "project": "spring-framework"}
{"id": 6411, "code": "\tpublic boolean isCurrentTransactionReadOnly() {\n\t\treturn this.transactionContext.isCurrentTransactionReadOnly();\n\t}", "summary_tokens": ["return", "whether", "the", "current", "transaction", "is", "marked", "as", "read", "only"], "project": "spring-framework"}
{"id": 121, "code": "\tprotected void extendAdvisors(List<Advisor> candidateAdvisors) {\n\t}", "summary_tokens": ["extension", "hook", "that", "subclasses", "can", "override", "to", "register", "additional", "advisors", "given", "the", "sorted", "advisors", "obtained", "to", "date"], "project": "spring-framework"}
{"id": 4016, "code": "\tpublic EmbeddedDatabaseBuilder setBlockCommentEndDelimiter(String blockCommentEndDelimiter) {\n\t\tthis.databasePopulator.setBlockCommentEndDelimiter(blockCommentEndDelimiter);\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "the", "end", "delimiter", "for", "block", "comments", "in", "all", "sql", "scripts"], "project": "spring-framework"}
{"id": 3819, "code": "\tvoid setTotalParameterCount(int totalParameterCount) {\n\t\tthis.totalParameterCount = totalParameterCount;\n\t}", "summary_tokens": ["set", "the", "total", "count", "of", "all", "the", "parameters", "in", "the", "sql", "statement"], "project": "spring-framework"}
{"id": 2473, "code": "public void visitAttribute(final Attribute attribute) {\n  if (mv != null) {\n    mv.visitAttribute(attribute);\n  }\n}", "summary_tokens": ["visits", "a", "non", "standard", "attribute", "of", "this", "method"], "project": "spring-framework"}
{"id": 3268, "code": "\tpublic static URI toURI(String location) throws URISyntaxException {\n\t\treturn new URI(StringUtils.replace(location, \" \", \"%20\"));\n\t}", "summary_tokens": ["create", "a", "uri", "instance", "for", "the", "given", "location", "string", "replacing", "spaces", "with", "0", "uri", "encoding", "first"], "project": "spring-framework"}
{"id": 2609, "code": "public int getTypeArgumentIndex() {\n  return targetTypeAndInfo & 0xFF;\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "type", "argument", "referenced", "by", "this", "type", "reference"], "project": "spring-framework"}
{"id": 8516, "code": "\tprotected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception {\n\t\tif (this.handlerMappings != null) {\n\t\t\tfor (HandlerMapping mapping : this.handlerMappings) {\n\t\t\t\tHandlerExecutionChain handler = mapping.getHandler(request);\n\t\t\t\tif (handler != null) {\n\t\t\t\t\treturn handler;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "handler", "execution", "chain", "for", "this", "request"], "project": "spring-framework"}
{"id": 3246, "code": "\tpublic static MimeType parseMimeType(String mimeType) {\n\t\tif (!StringUtils.hasLength(mimeType)) {\n\t\t\tthrow new InvalidMimeTypeException(mimeType, \"'mimeType' must not be empty\");\n\t\t}\n\t\t\n\t\tif (mimeType.startsWith(\"multipart\")) {\n\t\t\treturn parseMimeTypeInternal(mimeType);\n\t\t}\n\t\treturn cachedMimeTypes.get(mimeType);\n\t}", "summary_tokens": ["parse", "the", "given", "string", "into", "a", "single", "mime", "type"], "project": "spring-framework"}
{"id": 1863, "code": "\tpublic void setAllowCoreThreadTimeOut(boolean allowCoreThreadTimeOut) {\n\t\tthis.allowCoreThreadTimeOut = allowCoreThreadTimeOut;\n\t}", "summary_tokens": ["specify", "whether", "to", "allow", "core", "threads", "to", "time", "out"], "project": "spring-framework"}
{"id": 7412, "code": "\tpublic void addAllowedHeader(String allowedHeader) {\n\t\tif (this.allowedHeaders == null) {\n\t\t\tthis.allowedHeaders = new ArrayList<>(4);\n\t\t}\n\t\telse if (this.allowedHeaders == DEFAULT_PERMIT_ALL) {\n\t\t\tsetAllowedHeaders(DEFAULT_PERMIT_ALL);\n\t\t}\n\t\tthis.allowedHeaders.add(allowedHeader);\n\t}", "summary_tokens": ["add", "an", "actual", "request", "header", "to", "allow"], "project": "spring-framework"}
{"id": 5465, "code": "\tprivate void assertIsValid() {\n\t\tAssert.state(!isInvalid(), \"The session has already been invalidated\");\n\t}", "summary_tokens": ["convenience", "method", "for", "asserting", "that", "this", "session", "has", "not", "been", "invalidate", "invalidated"], "project": "spring-framework"}
{"id": 4410, "code": "\tpublic boolean isPubSubNoLocal() {\n\t\treturn this.pubSubNoLocal;\n\t}", "summary_tokens": ["return", "whether", "to", "inhibit", "the", "delivery", "of", "messages", "published", "by", "its", "own", "connection"], "project": "spring-framework"}
{"id": 5023, "code": "\tpublic void add(String headerName, @Nullable String headerValue) {\n\t\tList<String> headerValues = this.headers.computeIfAbsent(headerName, k -> new ArrayList<>(1));\n\t\theaderValues.add(headerValue);\n\t}", "summary_tokens": ["add", "the", "given", "single", "header", "value", "under", "the", "given", "name"], "project": "spring-framework"}
{"id": 1822, "code": "\tpublic void setCommonPool(boolean commonPool) {\n\t\tthis.commonPool = commonPool;\n\t}", "summary_tokens": ["set", "whether", "to", "expose", "jdk", "0", "s", "common", "fork", "join", "pool"], "project": "spring-framework"}
{"id": 3584, "code": "\tstatic boolean convertArguments(TypeConverter converter, Object[] arguments, Executable executable,\n\t\t\t@Nullable Integer varargsPosition) throws EvaluationException {\n\n\t\tboolean conversionOccurred = false;\n\t\tif (varargsPosition == null) {\n\t\t\tfor (int i = 0; i < arguments.length; i++) {\n\t\t\t\tTypeDescriptor targetType = new TypeDescriptor(MethodParameter.forExecutable(executable, i));\n\t\t\t\tObject argument = arguments[i];\n\t\t\t\targuments[i] = converter.convertValue(argument, TypeDescriptor.forObject(argument), targetType);\n\t\t\t\tconversionOccurred |= (argument != arguments[i]);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tfor (int i = 0; i < varargsPosition; i++) {\n\t\t\t\tTypeDescriptor targetType = new TypeDescriptor(MethodParameter.forExecutable(executable, i));\n\t\t\t\tObject argument = arguments[i];\n\t\t\t\targuments[i] = converter.convertValue(argument, TypeDescriptor.forObject(argument), targetType);\n\t\t\t\tconversionOccurred |= (argument != arguments[i]);\n\t\t\t}\n\n\t\t\tMethodParameter methodParam = MethodParameter.forExecutable(executable, varargsPosition);\n\n\t\t\t\n\t\t\tif (varargsPosition == arguments.length - 1) {\n\t\t\t\tObject argument = arguments[varargsPosition];\n\t\t\t\tTypeDescriptor targetType = new TypeDescriptor(methodParam);\n\t\t\t\tTypeDescriptor sourceType = TypeDescriptor.forObject(argument);\n\t\t\t\tif (argument == null) {\n\t\t\t\t\t\n\t\t\t\t\tif (targetType.getElementTypeDescriptor().getObjectType() == Optional.class) {\n\t\t\t\t\t\targuments[varargsPosition] = Optional.empty();\n\t\t\t\t\t\tconversionOccurred = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\telse if (!sourceType.equals(targetType.getElementTypeDescriptor())) {\n\t\t\t\t\targuments[varargsPosition] = converter.convertValue(argument, sourceType, targetType);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tif (argument != arguments[varargsPosition] &&\n\t\t\t\t\t\t!isFirstEntryInArray(argument, arguments[varargsPosition])) {\n\t\t\t\t\tconversionOccurred = true; \n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\telse {\n\t\t\t\tTypeDescriptor targetType = new TypeDescriptor(methodParam).getElementTypeDescriptor();\n\t\t\t\tAssert.state(targetType != null, \"No element type\");\n\t\t\t\tfor (int i = varargsPosition; i < arguments.length; i++) {\n\t\t\t\t\tObject argument = arguments[i];\n\t\t\t\t\targuments[i] = converter.convertValue(argument, TypeDescriptor.forObject(argument), targetType);\n\t\t\t\t\tconversionOccurred |= (argument != arguments[i]);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn conversionOccurred;\n\t}", "summary_tokens": ["takes", "an", "input", "set", "of", "argument", "values", "and", "converts", "them", "to", "the", "types", "specified", "as", "the", "required", "parameter", "types"], "project": "spring-framework"}
{"id": 598, "code": "\tpublic Throwable getRootCause() {\n\t\treturn this.rootCause;\n\t}", "summary_tokens": ["get", "the", "underlying", "exception", "that", "caused", "the", "error", "may", "be", "null"], "project": "spring-framework"}
{"id": 9448, "code": "\tpublic void setItemValue(String itemValue) {\n\t\tAssert.hasText(itemValue, \"'itemValue' must not be empty\");\n\t\tthis.itemValue = itemValue;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "property", "mapped", "to", "the", "value", "attribute", "of", "the", "option", "tag"], "project": "spring-framework"}
{"id": 1117, "code": "\tpublic void setWaitForJobsToCompleteOnShutdown(boolean waitForJobsToCompleteOnShutdown) {\n\t\tthis.waitForJobsToCompleteOnShutdown = waitForJobsToCompleteOnShutdown;\n\t}", "summary_tokens": ["set", "whether", "to", "wait", "for", "running", "jobs", "to", "complete", "on", "shutdown"], "project": "spring-framework"}
{"id": 9139, "code": "\tpublic String getRequestUri() {\n\t\treturn this.urlPathHelper.getOriginatingRequestUri(this.request);\n\t}", "summary_tokens": ["return", "the", "request", "uri", "of", "the", "original", "request", "that", "is", "the", "invoked", "url", "without", "parameters"], "project": "spring-framework"}
{"id": 3720, "code": "\tpublic void setLimitedInParameterNames(Set<String> limitedInParameterNames) {\n\t\tthis.limitedInParameterNames = limitedInParameterNames;\n\t}", "summary_tokens": ["specify", "a", "limited", "set", "of", "in", "parameters", "to", "be", "used"], "project": "spring-framework"}
{"id": 6274, "code": "\tprotected final BeanFactory getBeanFactory() {\n\t\treturn this.beanFactory;\n\t}", "summary_tokens": ["return", "the", "bean", "factory", "to", "use", "for", "retrieving", "transaction", "manager", "beans"], "project": "spring-framework"}
{"id": 2946, "code": "\tpublic ReadableByteChannel readableChannel() throws IOException {\n\t\ttry {\n\t\t\treturn FileChannel.open(this.filePath, StandardOpenOption.READ);\n\t\t}\n\t\tcatch (NoSuchFileException ex) {\n\t\t\tthrow new FileNotFoundException(ex.getMessage());\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "opens", "a", "file", "channel", "for", "the", "underlying", "file"], "project": "spring-framework"}
{"id": 2535, "code": "private Entry get(final int hashCode) {\n  return entries[hashCode % entries.length];\n}", "summary_tokens": ["returns", "the", "list", "of", "entries", "which", "can", "potentially", "have", "the", "given", "hash", "code"], "project": "spring-framework"}
{"id": 9126, "code": "\tprotected Theme getFallbackTheme() {\n\t\tThemeSource themeSource = RequestContextUtils.getThemeSource(getRequest());\n\t\tif (themeSource == null) {\n\t\t\tthemeSource = new ResourceBundleThemeSource();\n\t\t}\n\t\tTheme theme = themeSource.getTheme(DEFAULT_THEME_NAME);\n\t\tif (theme == null) {\n\t\t\tthrow new IllegalStateException(\"No theme defined and no fallback theme found\");\n\t\t}\n\t\treturn theme;\n\t}", "summary_tokens": ["determine", "the", "fallback", "theme", "for", "this", "context"], "project": "spring-framework"}
{"id": 3329, "code": "\tpublic static Locale parseLocale(String localeValue) {\n\t\tString[] tokens = tokenizeLocaleSource(localeValue);\n\t\tif (tokens.length == 1) {\n\t\t\tvalidateLocalePart(localeValue);\n\t\t\tLocale resolved = Locale.forLanguageTag(localeValue);\n\t\t\tif (resolved.getLanguage().length() > 0) {\n\t\t\t\treturn resolved;\n\t\t\t}\n\t\t}\n\t\treturn parseLocaleTokens(localeValue, tokens);\n\t}", "summary_tokens": ["parse", "the", "given", "string", "value", "into", "a", "locale", "accepting", "the", "locale", "to", "string", "format", "as", "well", "as", "bcp", "0", "language", "tags", "as", "specified", "by", "locale", "for", "language", "tag"], "project": "spring-framework"}
{"id": 9868, "code": "\tpublic void setAnnotatedEndpointClasses(Class<?>... annotatedEndpointClasses) {\n\t\tthis.annotatedEndpointClasses = Arrays.asList(annotatedEndpointClasses);\n\t}", "summary_tokens": ["explicitly", "list", "annotated", "endpoint", "types", "that", "should", "be", "registered", "on", "startup"], "project": "spring-framework"}
{"id": 1484, "code": "\tpublic static DateTimeContext getDateTimeContext() {\n\t\treturn dateTimeContextHolder.get();\n\t}", "summary_tokens": ["return", "the", "date", "time", "context", "associated", "with", "the", "current", "thread", "if", "any"], "project": "spring-framework"}
{"id": 2492, "code": "public void visitLocalVariable(\n    final String name,\n    final String descriptor,\n    final String signature,\n    final Label start,\n    final Label end,\n    final int index) {\n  if (mv != null) {\n    mv.visitLocalVariable(name, descriptor, signature, start, end, index);\n  }\n}", "summary_tokens": ["visits", "a", "local", "variable", "declaration"], "project": "spring-framework"}
{"id": 2228, "code": "\tpublic GeneratedClass getOrAddForFeatureComponent(String featureName,\n\t\t\tClass<?> targetComponent, Consumer<TypeSpec.Builder> type) {\n\n\t\tAssert.hasLength(featureName, \"'featureName' must not be empty\");\n\t\tAssert.notNull(targetComponent, \"'targetComponent' must not be null\");\n\t\tAssert.notNull(type, \"'type' must not be null\");\n\t\tOwner owner = new Owner(this.classNameGenerator.getFeatureNamePrefix(), featureName, targetComponent);\n\t\tGeneratedClass generatedClass = this.classesByOwner.computeIfAbsent(owner, key ->\n\t\t\t\tcreateAndAddGeneratedClass(featureName, targetComponent, type));\n\t\tgeneratedClass.assertSameType(type);\n\t\treturn generatedClass;\n\t}", "summary_tokens": ["get", "or", "add", "a", "generated", "class", "for", "the", "specified", "feature", "name", "targeting", "the", "specified", "component"], "project": "spring-framework"}
{"id": 8023, "code": "\tprotected final Map<String, CorsConfiguration> getCorsConfigurations() {\n\t\tif (this.corsConfigurations == null) {\n\t\t\tCorsRegistry registry = new CorsRegistry();\n\t\t\taddCorsMappings(registry);\n\t\t\tthis.corsConfigurations = registry.getCorsConfigurations();\n\t\t}\n\t\treturn this.corsConfigurations;\n\t}", "summary_tokens": ["callback", "for", "building", "the", "global", "cors", "configuration"], "project": "spring-framework"}
{"id": 6841, "code": "\tpublic Decoder<?> getDecoder() {\n\t\treturn this.decoder;\n\t}", "summary_tokens": ["return", "the", "configured", "decoder"], "project": "spring-framework"}
{"id": 6164, "code": "\tpublic void rootWacServletContainerAttributePreviouslySet() {\n\t\tStubWebApplicationContext child = new StubWebApplicationContext(this.servletContext);\n\t\tthis.servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, child);\n\n\t\tDefaultMockMvcBuilder builder = webAppContextSetup(child);\n\t\tassertThat(WebApplicationContextUtils.getRequiredWebApplicationContext(this.servletContext)).isSameAs(builder.initWebAppContext());\n\t}", "summary_tokens": ["see", "spr", "0", "and", "spr", "0"], "project": "spring-framework"}
{"id": 5948, "code": "\tprotected WebClient modifyWebClientInternal(WebClient webClient) {\n\t\treturn webClient;\n\t}", "summary_tokens": ["modify", "the", "supplied", "web", "client"], "project": "spring-framework"}
{"id": 1637, "code": "\tpublic String getDescription() {\n\t\treturn this.description;\n\t}", "summary_tokens": ["return", "a", "description", "for", "this", "attribute"], "project": "spring-framework"}
{"id": 1278, "code": "\tpublic void resetFilters(boolean useDefaultFilters) {\n\t\tthis.includeFilters.clear();\n\t\tthis.excludeFilters.clear();\n\t\tif (useDefaultFilters) {\n\t\t\tregisterDefaultFilters();\n\t\t}\n\t}", "summary_tokens": ["reset", "the", "configured", "type", "filters"], "project": "spring-framework"}
{"id": 5711, "code": "\tpublic final void setApplicationContext(ApplicationContext applicationContext) {\n\t\tthis.applicationContext = applicationContext;\n\t}", "summary_tokens": ["set", "the", "application", "context", "to", "be", "used", "by", "this", "test", "instance", "provided", "via", "application", "context", "aware", "semantics"], "project": "spring-framework"}
{"id": 2807, "code": "\tpublic static RepeatableContainers standardRepeatables() {\n\t\treturn StandardRepeatableContainers.INSTANCE;\n\t}", "summary_tokens": ["create", "a", "repeatable", "containers", "instance", "that", "searches", "using", "java", "s", "repeatable", "annotation"], "project": "spring-framework"}
{"id": 3511, "code": "\tpublic static String toJvmDescriptor(Class<?> clazz) {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tif (clazz.isArray()) {\n\t\t\twhile (clazz.isArray()) {\n\t\t\t\tsb.append('[');\n\t\t\t\tclazz = clazz.getComponentType();\n\t\t\t}\n\t\t}\n\t\tif (clazz.isPrimitive()) {\n\t\t\tif (clazz == Boolean.TYPE) {\n\t\t\t\tsb.append('Z');\n\t\t\t}\n\t\t\telse if (clazz == Byte.TYPE) {\n\t\t\t\tsb.append('B');\n\t\t\t}\n\t\t\telse if (clazz == Character.TYPE) {\n\t\t\t\tsb.append('C');\n\t\t\t}\n\t\t\telse if (clazz == Double.TYPE) {\n\t\t\t\tsb.append('D');\n\t\t\t}\n\t\t\telse if (clazz == Float.TYPE) {\n\t\t\t\tsb.append('F');\n\t\t\t}\n\t\t\telse if (clazz == Integer.TYPE) {\n\t\t\t\tsb.append('I');\n\t\t\t}\n\t\t\telse if (clazz == Long.TYPE) {\n\t\t\t\tsb.append('J');\n\t\t\t}\n\t\t\telse if (clazz == Short.TYPE) {\n\t\t\t\tsb.append('S');\n\t\t\t}\n\t\t\telse if (clazz == Void.TYPE) {\n\t\t\t\tsb.append('V');\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tsb.append('L');\n\t\t\tsb.append(clazz.getName().replace('.', '/'));\n\t\t\tsb.append(';');\n\t\t}\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["determine", "the", "jvm", "descriptor", "for", "a", "specified", "class"], "project": "spring-framework"}
{"id": 5998, "code": "\tpublic ResultMatcher isEmpty() {\n\t\treturn result -> this.jsonPathHelper.assertValueIsEmpty(getContent(result));\n\t}", "summary_tokens": ["evaluate", "the", "json", "path", "expression", "against", "the", "response", "content", "and", "assert", "that", "an", "empty", "value", "exists", "at", "the", "given", "path"], "project": "spring-framework"}
{"id": 9807, "code": "\tdefault void configureWebSocketTransport(WebSocketTransportRegistration registry) {\n\t}", "summary_tokens": ["configure", "options", "related", "to", "the", "processing", "of", "messages", "received", "from", "and", "sent", "to", "web", "socket", "clients"], "project": "spring-framework"}
{"id": 9486, "code": "\tprotected String getRows() {\n\t\treturn this.rows;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "rows", "attribute"], "project": "spring-framework"}
{"id": 9908, "code": "\tpublic void setSessionCookieNeeded(boolean sessionCookieNeeded) {\n\t\tthis.sessionCookieNeeded = sessionCookieNeeded;\n\t}", "summary_tokens": ["the", "sock", "js", "protocol", "requires", "a", "server", "to", "respond", "to", "an", "initial", "info", "request", "from", "clients", "with", "a", "cookie", "needed", "boolean", "property", "that", "indicates", "whether", "the", "use", "of", "a", "jsessionid", "cookie", "is", "required", "for", "the", "application", "to", "function", "correctly", "e"], "project": "spring-framework"}
{"id": 4867, "code": "\tpublic void setPreservePublishOrder(boolean preservePublishOrder) {\n\t\tOrderedMessageChannelDecorator.configureInterceptor(this.clientOutboundChannel, preservePublishOrder);\n\t\tthis.preservePublishOrder = preservePublishOrder;\n\t}", "summary_tokens": ["whether", "the", "client", "must", "receive", "messages", "in", "the", "order", "of", "publication"], "project": "spring-framework"}
{"id": 6485, "code": "\tprotected SavepointManager getSavepointManager() {\n\t\tthrow new NestedTransactionNotSupportedException(\"This transaction does not support savepoints\");\n\t}", "summary_tokens": ["return", "a", "savepoint", "manager", "for", "the", "underlying", "transaction", "if", "possible"], "project": "spring-framework"}
{"id": 4648, "code": "\tprivate Message.Builder getMessageBuilder(Class<?> clazz) {\n\t\ttry {\n\t\t\tMethod method = methodCache.get(clazz);\n\t\t\tif (method == null) {\n\t\t\t\tmethod = clazz.getMethod(\"newBuilder\");\n\t\t\t\tmethodCache.put(clazz, method);\n\t\t\t}\n\t\t\treturn (Message.Builder) method.invoke(clazz);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthrow new MessageConversionException(\n\t\t\t\t\t\"Invalid Protobuf Message type: no invocable newBuilder() method on \" + clazz, ex);\n\t\t}\n\t}", "summary_tokens": ["create", "a", "new", "message"], "project": "spring-framework"}
{"id": 6697, "code": "\tprivate long getFirstDate(String headerName, boolean rejectInvalid) {\n\t\tZonedDateTime zonedDateTime = getFirstZonedDateTime(headerName, rejectInvalid);\n\t\treturn (zonedDateTime != null ? zonedDateTime.toInstant().toEpochMilli() : -1);\n\t}", "summary_tokens": ["parse", "the", "first", "header", "value", "for", "the", "given", "header", "name", "as", "a", "date", "return", "0", "if", "there", "is", "no", "value", "or", "also", "in", "case", "of", "an", "invalid", "value", "if", "reject", "invalid", "false", "or", "raise", "illegal", "argument", "exception", "if", "the", "value", "cannot", "be", "parsed", "as", "a", "date"], "project": "spring-framework"}
{"id": 7678, "code": "\tpublic MultiValueMap<String, String> getRequestParams() {\n\t\treturn this.requestParams;\n\t}", "summary_tokens": ["return", "the", "actual", "request", "parameters"], "project": "spring-framework"}
{"id": 7730, "code": "\tpublic void setCookieMaxAge(Duration maxAge) {\n\t\tthis.cookieMaxAge = maxAge;\n\t}", "summary_tokens": ["set", "the", "value", "for", "the", "max", "age", "attribute", "of", "the", "cookie", "that", "holds", "the", "session", "id"], "project": "spring-framework"}
{"id": 2843, "code": "\tpublic static ConversionService getSharedInstance() {\n\t\tDefaultConversionService cs = sharedInstance;\n\t\tif (cs == null) {\n\t\t\tsynchronized (DefaultConversionService.class) {\n\t\t\t\tcs = sharedInstance;\n\t\t\t\tif (cs == null) {\n\t\t\t\t\tcs = new DefaultConversionService();\n\t\t\t\t\tsharedInstance = cs;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn cs;\n\t}", "summary_tokens": ["return", "a", "shared", "default", "conversion", "service", "instance", "lazily", "building", "it", "once", "needed"], "project": "spring-framework"}
{"id": 2188, "code": "\tpublic <T> T getInstance(Class<T> type, String className) {\n\t\tClass<?> loaded = loadClass(className);\n\t\treturn newInstance(loaded);\n\t}", "summary_tokens": ["return", "an", "instance", "of", "a", "compiled", "class", "identified", "by", "its", "class", "name"], "project": "spring-framework"}
{"id": 2578, "code": "public static String getMethodDescriptor(final Method method) {\n  StringBuilder stringBuilder = new StringBuilder();\n  stringBuilder.append('(');\n  Class<?>[] parameters = method.getParameterTypes();\n  for (Class<?> parameter : parameters) {\n    appendDescriptor(parameter, stringBuilder);\n  }\n  stringBuilder.append(')');\n  appendDescriptor(method.getReturnType(), stringBuilder);\n  return stringBuilder.toString();\n}", "summary_tokens": ["returns", "the", "descriptor", "corresponding", "to", "the", "given", "method"], "project": "spring-framework"}
{"id": 6370, "code": "\tpublic Object getTransaction() {\n\t\tAssert.state(this.transaction != null, \"No transaction active\");\n\t\treturn this.transaction;\n\t}", "summary_tokens": ["return", "the", "underlying", "transaction", "object"], "project": "spring-framework"}
{"id": 162, "code": "\tpublic void destroy() {\n\t\tsynchronized (this.internalBeanFactories) {\n\t\t\tfor (DefaultListableBeanFactory bf : this.internalBeanFactories.values()) {\n\t\t\t\tbf.destroySingletons();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["destroys", "the", "internal", "bean", "factory", "on", "shutdown", "of", "the", "target", "source", "creator"], "project": "spring-framework"}
{"id": 5627, "code": "\tprivate Statement withAfterTestClassCallbacks(Statement next, TestContextManager testContextManager) {\n\t\treturn new RunAfterTestClassCallbacks(next, testContextManager);\n\t}", "summary_tokens": ["wrap", "the", "supplied", "statement", "with", "a", "run", "after", "test", "class", "callbacks", "statement"], "project": "spring-framework"}
{"id": 264, "code": "\tpublic long getMinEvictableIdleTimeMillis() {\n\t\treturn this.minEvictableIdleTimeMillis;\n\t}", "summary_tokens": ["return", "the", "minimum", "time", "that", "an", "idle", "object", "can", "sit", "in", "the", "pool"], "project": "spring-framework"}
{"id": 1926, "code": "\tprotected Class<?> createConfigInterface(BeanDefinition bd, @Nullable Class<?>[] interfaces) {\n\t\tInterfaceMaker maker = new InterfaceMaker();\n\t\tPropertyValue[] pvs = bd.getPropertyValues().getPropertyValues();\n\t\tfor (PropertyValue pv : pvs) {\n\t\t\tString propertyName = pv.getName();\n\t\t\tClass<?> propertyType = BeanUtils.findPropertyType(propertyName, interfaces);\n\t\t\tString setterName = \"set\" + StringUtils.capitalize(propertyName);\n\t\t\tSignature signature = new Signature(setterName, Type.VOID_TYPE, new Type[] {Type.getType(propertyType)});\n\t\t\tmaker.add(signature, new Type[0]);\n\t\t}\n\t\tif (StringUtils.hasText(bd.getInitMethodName())) {\n\t\t\tSignature signature = new Signature(bd.getInitMethodName(), Type.VOID_TYPE, new Type[0]);\n\t\t\tmaker.add(signature, new Type[0]);\n\t\t}\n\t\tif (StringUtils.hasText(bd.getDestroyMethodName())) {\n\t\t\tSignature signature = new Signature(bd.getDestroyMethodName(), Type.VOID_TYPE, new Type[0]);\n\t\t\tmaker.add(signature, new Type[0]);\n\t\t}\n\t\treturn maker.create();\n\t}", "summary_tokens": ["create", "a", "config", "interface", "for", "the", "given", "bean", "definition", "defining", "setter", "methods", "for", "the", "defined", "property", "values", "as", "well", "as", "an", "init", "method", "and", "a", "destroy", "method", "if", "defined"], "project": "spring-framework"}
{"id": 4567, "code": "\tpublic String getMessageId() {\n\t\treturn (String) getHeader(JmsHeaders.MESSAGE_ID);\n\t}", "summary_tokens": ["return", "the", "jms", "headers", "message", "id", "message", "id"], "project": "spring-framework"}
{"id": 1258, "code": "\tpublic void registerBeanDefinitions(\n\t\t\tAnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {\n\n\t\tAopConfigUtils.registerAspectJAnnotationAutoProxyCreatorIfNecessary(registry);\n\n\t\tAnnotationAttributes enableAspectJAutoProxy =\n\t\t\t\tAnnotationConfigUtils.attributesFor(importingClassMetadata, EnableAspectJAutoProxy.class);\n\t\tif (enableAspectJAutoProxy != null) {\n\t\t\tif (enableAspectJAutoProxy.getBoolean(\"proxyTargetClass\")) {\n\t\t\t\tAopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);\n\t\t\t}\n\t\t\tif (enableAspectJAutoProxy.getBoolean(\"exposeProxy\")) {\n\t\t\t\tAopConfigUtils.forceAutoProxyCreatorToExposeProxy(registry);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["register", "escalate", "and", "configure", "the", "aspect", "j", "auto", "proxy", "creator", "based", "on", "the", "value", "of", "the", "enable", "aspect", "jauto", "proxy", "proxy", "target", "class", "attribute", "on", "the", "importing", "class"], "project": "spring-framework"}
{"id": 5035, "code": "\tpublic boolean isRemoveLeadingSlash() {\n\t\treturn this.removeLeadingSlash;\n\t}", "summary_tokens": ["whether", "to", "remove", "the", "leading", "slash", "from", "target", "destinations"], "project": "spring-framework"}
{"id": 5395, "code": "\tpublic void setConnectionFactories(Map<String, ConnectionFactory> connectionFactories) {\n\t\tAssert.notNull(connectionFactories, \"ConnectionFactories must not be null\");\n\t\tthis.connectionFactories.putAll(connectionFactories);\n\t}", "summary_tokens": ["set", "the", "map", "of", "connection", "factory", "connection", "factories"], "project": "spring-framework"}
{"id": 7470, "code": "\tprotected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain)\n\t\t\tthrows ServletException, IOException {\n\n\t\tboolean isFirstRequest = !isAsyncDispatch(request);\n\t\tHttpServletRequest requestToUse = request;\n\n\t\tif (isIncludePayload() && isFirstRequest && !(request instanceof ContentCachingRequestWrapper)) {\n\t\t\trequestToUse = new ContentCachingRequestWrapper(request, getMaxPayloadLength());\n\t\t}\n\n\t\tboolean shouldLog = shouldLog(requestToUse);\n\t\tif (shouldLog && isFirstRequest) {\n\t\t\tbeforeRequest(requestToUse, getBeforeMessage(requestToUse));\n\t\t}\n\t\ttry {\n\t\t\tfilterChain.doFilter(requestToUse, response);\n\t\t}\n\t\tfinally {\n\t\t\tif (shouldLog && !isAsyncStarted(requestToUse)) {\n\t\t\t\tafterRequest(requestToUse, getAfterMessage(requestToUse));\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["forwards", "the", "request", "to", "the", "next", "filter", "in", "the", "chain", "and", "delegates", "down", "to", "the", "subclasses", "to", "perform", "the", "actual", "request", "logging", "both", "before", "and", "after", "the", "request", "is", "processed"], "project": "spring-framework"}
{"id": 9780, "code": "\tpublic String getStompBrokerRelayStatsInfo() {\n\t\treturn (this.stompBrokerRelay != null ? this.stompBrokerRelay.getStatsInfo() : \"null\");\n\t}", "summary_tokens": ["get", "stats", "about", "stomp", "broker", "relay", "when", "using", "a", "full", "featured", "stomp", "broker"], "project": "spring-framework"}
{"id": 7961, "code": "\tpublic Map<String, ? extends FilterRegistration> getFilterRegistrations() {\n\t\treturn Collections.emptyMap();\n\t}", "summary_tokens": ["this", "method", "always", "returns", "an", "collections", "empty", "map", "empty", "map"], "project": "spring-framework"}
{"id": 8623, "code": "\tpublic RedirectViewControllerRegistration setStatusCode(HttpStatusCode statusCode) {\n\t\tAssert.isTrue(statusCode.is3xxRedirection(), \"Not a redirect status code\");\n\t\tthis.redirectView.setStatusCode(statusCode);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "specific", "redirect", "0", "xx", "status", "code", "to", "use"], "project": "spring-framework"}
{"id": 3170, "code": "\tpublic static boolean isUserLevelMethod(Method method) {\n\t\tAssert.notNull(method, \"Method must not be null\");\n\t\treturn (method.isBridge() || (!method.isSynthetic() && !isGroovyObjectMethod(method)));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "method", "is", "declared", "by", "the", "user", "or", "at", "least", "pointing", "to", "a", "user", "declared", "method"], "project": "spring-framework"}
{"id": 1644, "code": "\tpublic String getCategory() {\n\t\treturn this.category;\n\t}", "summary_tokens": ["the", "category", "of", "this", "metric", "ex"], "project": "spring-framework"}
{"id": 1336, "code": "\tpublic static LocaleContext getLocaleContext() {\n\t\tLocaleContext localeContext = localeContextHolder.get();\n\t\tif (localeContext == null) {\n\t\t\tlocaleContext = inheritableLocaleContextHolder.get();\n\t\t}\n\t\treturn localeContext;\n\t}", "summary_tokens": ["return", "the", "locale", "context", "associated", "with", "the", "current", "thread", "if", "any"], "project": "spring-framework"}
{"id": 4861, "code": "\tpublic MessageHeaderInitializer getHeaderInitializer() {\n\t\treturn this.headerInitializer;\n\t}", "summary_tokens": ["return", "the", "configured", "header", "initializer"], "project": "spring-framework"}
{"id": 4096, "code": "\tpublic boolean isFunction() {\n\t\treturn this.function;\n\t}", "summary_tokens": ["return", "whether", "this", "call", "is", "for", "a", "function"], "project": "spring-framework"}
{"id": 835, "code": "\tpublic void setNamespaceHandlerResolver(@Nullable NamespaceHandlerResolver namespaceHandlerResolver) {\n\t\tthis.namespaceHandlerResolver = namespaceHandlerResolver;\n\t}", "summary_tokens": ["specify", "the", "namespace", "handler", "resolver", "to", "use"], "project": "spring-framework"}
{"id": 6670, "code": "\tpublic long getExpires() {\n\t\treturn getFirstDate(EXPIRES, false);\n\t}", "summary_tokens": ["return", "the", "date", "and", "time", "at", "which", "the", "message", "is", "no", "longer", "valid", "as", "specified", "by", "the", "expires", "header"], "project": "spring-framework"}
{"id": 2675, "code": "public static StringSwitcher create(String[] strings, int[] ints, boolean fixedInput) {\n    Generator gen = new Generator();\n    gen.setStrings(strings);\n    gen.setInts(ints);\n    gen.setFixedInput(fixedInput);\n    return gen.create();\n}", "summary_tokens": ["helper", "method", "to", "create", "a", "string", "switcher"], "project": "spring-framework"}
{"id": 9265, "code": "\tprotected String convertToDisplayString(@Nullable Object value) throws JspException {\n\t\tPropertyEditor editor = (value != null ? getBindStatus().findEditor(value.getClass()) : null);\n\t\treturn getDisplayString(value, editor);\n\t}", "summary_tokens": ["get", "a", "display", "string", "for", "the", "given", "value", "converted", "by", "a", "property", "editor", "that", "the", "bind", "status", "may", "have", "registered", "for", "the", "value", "s", "class"], "project": "spring-framework"}
{"id": 1187, "code": "\tpublic CacheErrorHandler getErrorHandler() {\n\t\treturn this.errorHandler.obtain();\n\t}", "summary_tokens": ["return", "the", "cache", "error", "handler", "to", "use"], "project": "spring-framework"}
{"id": 1861, "code": "\tpublic void setQueueCapacity(int queueCapacity) {\n\t\tthis.queueCapacity = queueCapacity;\n\t}", "summary_tokens": ["set", "the", "capacity", "for", "the", "thread", "pool", "executor", "s", "blocking", "queue"], "project": "spring-framework"}
{"id": 2821, "code": "\tdefault DataBuffer encodeValue(T value, DataBufferFactory bufferFactory,\n\t\t\tResolvableType valueType, @Nullable MimeType mimeType, @Nullable Map<String, Object> hints) {\n\n\t\t\n\t\tthrow new UnsupportedOperationException();\n\t}", "summary_tokens": ["encode", "an", "object", "of", "type", "t", "to", "a", "data", "buffer"], "project": "spring-framework"}
{"id": 9436, "code": "\tpublic void writeOptions(TagWriter tagWriter) throws JspException {\n\t\tif (this.optionSource.getClass().isArray()) {\n\t\t\trenderFromArray(tagWriter);\n\t\t}\n\t\telse if (this.optionSource instanceof Collection) {\n\t\t\trenderFromCollection(tagWriter);\n\t\t}\n\t\telse if (this.optionSource instanceof Map) {\n\t\t\trenderFromMap(tagWriter);\n\t\t}\n\t\telse if (this.optionSource instanceof Class && ((Class<?>) this.optionSource).isEnum()) {\n\t\t\trenderFromEnum(tagWriter);\n\t\t}\n\t\telse {\n\t\t\tthrow new JspException(\n\t\t\t\t\t\"Type [\" + this.optionSource.getClass().getName() + \"] is not valid for option items\");\n\t\t}\n\t}", "summary_tokens": ["write", "the", "option", "tags", "for", "the", "configured", "option", "source", "to", "the", "supplied", "tag", "writer"], "project": "spring-framework"}
{"id": 9688, "code": "\tpublic void setLocale(Locale locale) {\n\t\tsuper.setLocale(locale);\n\t}", "summary_tokens": ["this", "method", "should", "not", "be", "used", "since", "the", "considered", "locale", "for", "resolving", "templates", "is", "the", "locale", "for", "the", "current", "http", "request"], "project": "spring-framework"}
{"id": 9578, "code": "\tpublic boolean isPropagateQueryProperties() {\n\t\treturn this.propagateQueryParams;\n\t}", "summary_tokens": ["whether", "to", "propagate", "the", "query", "params", "of", "the", "current", "url"], "project": "spring-framework"}
{"id": 2400, "code": "public int newClass(final String value) {\n  return symbolTable.addConstantClass(value).index;\n}", "summary_tokens": ["adds", "a", "class", "reference", "to", "the", "constant", "pool", "of", "the", "class", "being", "build"], "project": "spring-framework"}
{"id": 5805, "code": "\tpublic void verify(Duration timeout) {\n\t\tthis.expectationManager.verify(timeout);\n\t}", "summary_tokens": ["variant", "of", "verify", "that", "waits", "for", "up", "to", "the", "specified", "time", "for", "all", "expectations", "to", "be", "fulfilled"], "project": "spring-framework"}
{"id": 6296, "code": "\tpublic JndiTemplate getJndiTemplate() {\n\t\treturn this.jndiTemplate;\n\t}", "summary_tokens": ["return", "the", "jndi", "template", "used", "for", "jndi", "lookups"], "project": "spring-framework"}
{"id": 6117, "code": "\tpublic ResultMatcher isNotExtended() {\n\t\treturn matcher(HttpStatus.NOT_EXTENDED);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2455, "code": "final void accept(final MethodVisitor methodVisitor, final boolean visitLineNumbers) {\n  methodVisitor.visitLabel(this);\n  if (visitLineNumbers && lineNumber != 0) {\n    methodVisitor.visitLineNumber(lineNumber & 0xFFFF, this);\n    if (otherLineNumbers != null) {\n      for (int i = 1; i <= otherLineNumbers[0]; ++i) {\n        methodVisitor.visitLineNumber(otherLineNumbers[i], this);\n      }\n    }\n  }\n}", "summary_tokens": ["makes", "the", "given", "visitor", "visit", "this", "label", "and", "its", "source", "line", "numbers", "if", "applicable"], "project": "spring-framework"}
{"id": 9099, "code": "\tpublic Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "current", "value", "of", "the", "field", "i"], "project": "spring-framework"}
{"id": 3654, "code": "\tpublic String getSql() {\n\t\treturn this.sql;\n\t}", "summary_tokens": ["return", "the", "sql", "that", "caused", "the", "problem"], "project": "spring-framework"}
{"id": 9319, "code": "\tprotected void writeOptionalAttributes(TagWriter tagWriter) throws JspException {\n\t\ttagWriter.writeOptionalAttributeValue(CLASS_ATTRIBUTE, resolveCssClass());\n\t\ttagWriter.writeOptionalAttributeValue(STYLE_ATTRIBUTE,\n\t\t\t\tObjectUtils.getDisplayString(evaluate(\"cssStyle\", getCssStyle())));\n\t\twriteOptionalAttribute(tagWriter, LANG_ATTRIBUTE, getLang());\n\t\twriteOptionalAttribute(tagWriter, TITLE_ATTRIBUTE, getTitle());\n\t\twriteOptionalAttribute(tagWriter, DIR_ATTRIBUTE, getDir());\n\t\twriteOptionalAttribute(tagWriter, TABINDEX_ATTRIBUTE, getTabindex());\n\t\twriteOptionalAttribute(tagWriter, ONCLICK_ATTRIBUTE, getOnclick());\n\t\twriteOptionalAttribute(tagWriter, ONDBLCLICK_ATTRIBUTE, getOndblclick());\n\t\twriteOptionalAttribute(tagWriter, ONMOUSEDOWN_ATTRIBUTE, getOnmousedown());\n\t\twriteOptionalAttribute(tagWriter, ONMOUSEUP_ATTRIBUTE, getOnmouseup());\n\t\twriteOptionalAttribute(tagWriter, ONMOUSEOVER_ATTRIBUTE, getOnmouseover());\n\t\twriteOptionalAttribute(tagWriter, ONMOUSEMOVE_ATTRIBUTE, getOnmousemove());\n\t\twriteOptionalAttribute(tagWriter, ONMOUSEOUT_ATTRIBUTE, getOnmouseout());\n\t\twriteOptionalAttribute(tagWriter, ONKEYPRESS_ATTRIBUTE, getOnkeypress());\n\t\twriteOptionalAttribute(tagWriter, ONKEYUP_ATTRIBUTE, getOnkeyup());\n\t\twriteOptionalAttribute(tagWriter, ONKEYDOWN_ATTRIBUTE, getOnkeydown());\n\n\t\tif (!CollectionUtils.isEmpty(this.dynamicAttributes)) {\n\t\t\tfor (Map.Entry<String, Object> entry : this.dynamicAttributes.entrySet()) {\n\t\t\t\ttagWriter.writeOptionalAttributeValue(entry.getKey(), getDisplayString(entry.getValue()));\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["writes", "the", "optional", "attributes", "configured", "via", "this", "base", "class", "to", "the", "supplied", "tag", "writer"], "project": "spring-framework"}
{"id": 3711, "code": "\tpublic static List<SqlParameter> sqlTypesToAnonymousParameterList(@Nullable int... types) {\n\t\tif (types == null) {\n\t\t\treturn new ArrayList<>();\n\t\t}\n\t\tList<SqlParameter> result = new ArrayList<>(types.length);\n\t\tfor (int type : types) {\n\t\t\tresult.add(new SqlParameter(type));\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["convert", "a", "list", "of", "jdbc", "types", "as", "defined", "in", "java"], "project": "spring-framework"}
{"id": 7261, "code": "\tpublic void requestCompleted() {\n\t\texecuteRequestDestructionCallbacks();\n\t\tupdateAccessedSessionAttributes();\n\t\tthis.requestActive = false;\n\t}", "summary_tokens": ["signal", "that", "the", "request", "has", "been", "completed"], "project": "spring-framework"}
{"id": 1499, "code": "\tpublic void setFormatterRegistrars(Set<FormatterRegistrar> formatterRegistrars) {\n\t\tthis.formatterRegistrars = formatterRegistrars;\n\t}", "summary_tokens": ["p", "configure", "the", "set", "of", "formatter", "registrars", "to", "invoke", "to", "register", "converters", "and", "formatters", "in", "addition", "to", "those", "added", "declaratively", "via", "set", "converters", "set", "and", "set", "formatters", "set"], "project": "spring-framework"}
{"id": 4776, "code": "\tpublic InvocableHandlerMethod initMessageMappingMethod(HandlerMethod handlerMethod) {\n\t\tInvocableHandlerMethod invocable = new InvocableHandlerMethod(handlerMethod);\n\t\tinvocable.setArgumentResolvers(this.argumentResolvers.getResolvers());\n\t\treturn invocable;\n\t}", "summary_tokens": ["create", "invocable", "handler", "method", "with", "the", "configured", "arg", "resolvers"], "project": "spring-framework"}
{"id": 516, "code": "\tpublic void setBeanFactory(BeanFactory beanFactory) {\n\t\tthis.beanFactory = beanFactory;\n\t}", "summary_tokens": ["only", "necessary", "to", "check", "that", "we", "re", "not", "parsing", "our", "own", "bean", "definition", "to", "avoid", "failing", "on", "unresolvable", "placeholders", "in", "properties", "file", "locations"], "project": "spring-framework"}
{"id": 2784, "code": "\tdefault R doWithAggregate(C context, int aggregateIndex) {\n\t\treturn null;\n\t}", "summary_tokens": ["called", "when", "an", "aggregate", "is", "about", "to", "be", "processed"], "project": "spring-framework"}
{"id": 9750, "code": "\tprotected ConversionService getConversionService() {\n\t\tApplicationContext applicationContext = getApplicationContext();\n\t\tAssert.state(applicationContext != null, \"Unable to locate the Spring ApplicationContext\");\n\t\ttry {\n\t\t\treturn applicationContext.getBean(CONVERSION_SERVICE_BEAN_NAME, ConversionService.class);\n\t\t}\n\t\tcatch (BeansException ex) {\n\t\t\tthrow new IllegalStateException(\"Unable to find ConversionService: please configure a '\" +\n\t\t\t\t\tCONVERSION_SERVICE_BEAN_NAME + \"' or override the getConversionService() method\", ex);\n\t\t}\n\t}", "summary_tokens": ["strategy", "method", "used", "to", "obtain", "the", "conversion", "service"], "project": "spring-framework"}
{"id": 1006, "code": "\tpublic void setTransactionAware(boolean transactionAware) {\n\t\tthis.transactionAware = transactionAware;\n\t}", "summary_tokens": ["set", "whether", "this", "cache", "manager", "should", "expose", "transaction", "aware", "cache", "objects"], "project": "spring-framework"}
{"id": 1710, "code": "\tpublic void setEnvironmentMap(@Nullable Map<String, ?> environment) {\n\t\tif (environment != null) {\n\t\t\tthis.environment.putAll(environment);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "environment", "properties", "used", "to", "construct", "the", "jmxconnector", "as", "a", "map", "of", "string", "keys", "and", "arbitrary", "object", "values"], "project": "spring-framework"}
{"id": 4604, "code": "\tpublic DestinationResolver getDestinationResolver() {\n\t\treturn this.destinationResolver;\n\t}", "summary_tokens": ["return", "the", "destination", "resolver", "for", "this", "accessor", "never", "null"], "project": "spring-framework"}
{"id": 9735, "code": "\tpublic void readOnlyAttributeRenderingWhenReadonlyIsTrue() throws Exception {\n\t\tthis.tag.setPath(\"name\");\n\t\tthis.tag.setReadonly(true);\n\n\t\tassertThat(this.tag.doStartTag()).isEqualTo(Tag.SKIP_BODY);\n\n\t\tString output = getOutput();\n\t\tassertTagOpened(output);\n\t\tassertTagClosed(output);\n\n\t\tassertContainsAttribute(output, \"type\", getType());\n\t\tassertContainsAttribute(output, \"readonly\", \"readonly\");\n\t\tassertValueAttribute(output, \"Rob\");\n\t}", "summary_tokens": ["see", "spr", "0", "https", "opensource"], "project": "spring-framework"}
{"id": 2230, "code": "\tpublic GeneratedClass addForFeatureComponent(String featureName,\n\t\t\tClass<?> targetComponent, Consumer<TypeSpec.Builder> type) {\n\n\t\tAssert.hasLength(featureName, \"'featureName' must not be empty\");\n\t\tAssert.notNull(targetComponent, \"'targetComponent' must not be null\");\n\t\tAssert.notNull(type, \"'type' must not be null\");\n\t\treturn createAndAddGeneratedClass(featureName, targetComponent, type);\n\t}", "summary_tokens": ["add", "a", "new", "generated", "class", "for", "the", "specified", "feature", "name", "targeting", "the", "specified", "component"], "project": "spring-framework"}
{"id": 477, "code": "\tpublic DependencyDescriptor forFallbackMatch() {\n\t\treturn new DependencyDescriptor(this) {\n\t\t\t@Override\n\t\t\tpublic boolean fallbackMatchAllowed() {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["return", "a", "variant", "of", "this", "descriptor", "that", "is", "intended", "for", "a", "fallback", "match"], "project": "spring-framework"}
{"id": 6199, "code": "\tprotected AbstractMessageEndpoint createEndpointInternal() throws UnavailableException {\n\t\treturn new GenericMessageEndpoint();\n\t}", "summary_tokens": ["creates", "a", "concrete", "generic", "message", "endpoint", "internal", "to", "this", "factory"], "project": "spring-framework"}
{"id": 3954, "code": "\tprotected Integer getCurrentIsolationLevel() {\n\t\tInteger isolationLevelToUse = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel();\n\t\tif (isolationLevelToUse == null) {\n\t\t\tisolationLevelToUse = getIsolationLevel();\n\t\t}\n\t\treturn isolationLevelToUse;\n\t}", "summary_tokens": ["determine", "the", "current", "isolation", "level", "either", "the", "transaction", "s", "isolation", "level", "or", "a", "statically", "defined", "isolation", "level"], "project": "spring-framework"}
{"id": 3043, "code": "\tpublic static LogMessage format(String format, Object... args) {\n\t\treturn new FormatMessageX(format, args);\n\t}", "summary_tokens": ["build", "a", "lazily", "formatted", "message", "from", "the", "given", "format", "string", "and", "varargs"], "project": "spring-framework"}
{"id": 4483, "code": "\tprotected void noMessageReceived(Object invoker, Session session) {\n\t\t((AsyncMessageListenerInvoker) invoker).setIdle(true);\n\t}", "summary_tokens": ["marks", "the", "affected", "invoker", "as", "idle"], "project": "spring-framework"}
{"id": 4615, "code": "\tprotected void testCustomConfiguration(ApplicationContext context) {\n\t\tJmsListenerContainerTestFactory defaultFactory =\n\t\t\t\tcontext.getBean(\"jmsListenerContainerFactory\", JmsListenerContainerTestFactory.class);\n\t\tJmsListenerContainerTestFactory customFactory =\n\t\t\t\tcontext.getBean(\"customFactory\", JmsListenerContainerTestFactory.class);\n\t\tassertThat(defaultFactory.getListenerContainers().size()).isEqualTo(1);\n\t\tassertThat(customFactory.getListenerContainers().size()).isEqualTo(1);\n\t\tJmsListenerEndpoint endpoint = defaultFactory.getListenerContainers().get(0).getEndpoint();\n\t\tassertThat(endpoint.getClass()).as(\"Wrong endpoint type\").isEqualTo(SimpleJmsListenerEndpoint.class);\n\t\tassertThat(((SimpleJmsListenerEndpoint) endpoint).getMessageListener()).as(\"Wrong listener set in custom endpoint\").isEqualTo(context.getBean(\"simpleMessageListener\"));\n\n\t\tJmsListenerEndpointRegistry customRegistry =\n\t\t\t\tcontext.getBean(\"customRegistry\", JmsListenerEndpointRegistry.class);\n\t\tassertThat(customRegistry.getListenerContainerIds().size()).as(\"Wrong number of containers in the registry\").isEqualTo(2);\n\t\tassertThat(customRegistry.getListenerContainers().size()).as(\"Wrong number of containers in the registry\").isEqualTo(2);\n\t\tassertThat(customRegistry.getListenerContainer(\"listenerId\")).as(\"Container with custom id on the annotation should be found\").isNotNull();\n\t\tassertThat(customRegistry.getListenerContainer(\"myCustomEndpointId\")).as(\"Container created with custom id should be found\").isNotNull();\n\t}", "summary_tokens": ["test", "for", "custom", "bean", "and", "an", "endpoint", "manually", "registered", "with", "my", "custom", "endpoint", "id"], "project": "spring-framework"}
{"id": 9826, "code": "\tpublic void setErrorHandler(StompSubProtocolErrorHandler errorHandler) {\n\t\tthis.errorHandler = errorHandler;\n\t}", "summary_tokens": ["configure", "a", "handler", "for", "error", "messages", "sent", "to", "clients", "which", "allows", "customizing", "the", "error", "messages", "or", "preventing", "them", "from", "being", "sent"], "project": "spring-framework"}
{"id": 3740, "code": "\tpublic String getScalarOutParameterName() {\n\t\tif (isFunction()) {\n\t\t\treturn getFunctionReturnName();\n\t\t}\n\t\telse {\n\t\t\tif (this.outParameterNames.size() > 1) {\n\t\t\t\tlogger.info(\"Accessing single output value when procedure has more than one output parameter\");\n\t\t\t}\n\t\t\treturn (!this.outParameterNames.isEmpty() ? this.outParameterNames.get(0) : null);\n\t\t}\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "single", "out", "parameter", "for", "this", "call"], "project": "spring-framework"}
{"id": 7718, "code": "\tpublic boolean hasHttpHandlerDecorator() {\n\t\treturn (this.httpHandlerDecorator != null);\n\t}", "summary_tokens": ["whether", "a", "decorator", "for", "http", "handler", "is", "configured", "or", "not", "via", "http", "handler", "decorator", "function"], "project": "spring-framework"}
{"id": 6181, "code": "\tpublic static int intResult(@Nullable Collection<?> results)\n\t\t\tthrows IncorrectResultSizeDataAccessException, TypeMismatchDataAccessException {\n\n\t\treturn objectResult(results, Number.class).intValue();\n\t}", "summary_tokens": ["return", "a", "unique", "int", "result", "from", "the", "given", "collection"], "project": "spring-framework"}
{"id": 5321, "code": "\tprotected Object unmarshalStaxSource(Source staxSource) throws XmlMappingException {\n\t\tXMLStreamReader streamReader = StaxUtils.getXMLStreamReader(staxSource);\n\t\tif (streamReader != null) {\n\t\t\treturn unmarshalXmlStreamReader(streamReader);\n\t\t}\n\t\telse {\n\t\t\tXMLEventReader eventReader = StaxUtils.getXMLEventReader(staxSource);\n\t\t\tif (eventReader != null) {\n\t\t\t\treturn unmarshalXmlEventReader(eventReader);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\"StaxSource contains neither XMLStreamReader nor XMLEventReader\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["template", "method", "for", "handling", "stax", "source", "s"], "project": "spring-framework"}
{"id": 8715, "code": "\tprotected void addCorsMappings(CorsRegistry registry) {\n\t}", "summary_tokens": ["override", "this", "method", "to", "configure", "cross", "origin", "requests", "processing"], "project": "spring-framework"}
{"id": 309, "code": "\tpublic Method getConstructingMethod() {\n\t\treturn this.constructingMethod;\n\t}", "summary_tokens": ["return", "the", "delegate", "for", "bean", "construction", "purposes", "if", "known"], "project": "spring-framework"}
{"id": 1994, "code": "\tpublic void setDisallowedFields(@Nullable String... disallowedFields) {\n\t\tif (disallowedFields == null) {\n\t\t\tthis.disallowedFields = null;\n\t\t}\n\t\telse {\n\t\t\tString[] fieldPatterns = new String[disallowedFields.length];\n\t\t\tfor (int i = 0; i < fieldPatterns.length; i++) {\n\t\t\t\tfieldPatterns[i] = PropertyAccessorUtils.canonicalPropertyName(disallowedFields[i]).toLowerCase();\n\t\t\t}\n\t\t\tthis.disallowedFields = fieldPatterns;\n\t\t}\n\t}", "summary_tokens": ["register", "field", "patterns", "that", "should", "i", "not", "i", "be", "allowed", "for", "binding"], "project": "spring-framework"}
{"id": 8393, "code": "\tpublic void setDefaultViews(@Nullable List<View> defaultViews) {\n\t\tthis.defaultViews.clear();\n\t\tif (defaultViews != null) {\n\t\t\tthis.defaultViews.addAll(defaultViews);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "default", "views", "to", "consider", "always", "when", "resolving", "view", "names", "and", "trying", "to", "satisfy", "the", "best", "matching", "content", "type"], "project": "spring-framework"}
{"id": 9862, "code": "\tpublic void setAutoStartup(boolean autoStartup) {\n\t\tthis.autoStartup = autoStartup;\n\t}", "summary_tokens": ["set", "whether", "to", "auto", "start", "the", "contained", "web", "socket", "client", "when", "the", "spring", "context", "has", "been", "refreshed"], "project": "spring-framework"}
{"id": 9287, "code": "\tprotected String getCssStyle() {\n\t\treturn this.cssStyle;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "style", "attribute"], "project": "spring-framework"}
{"id": 5420, "code": "\tdefault boolean identifiablePlaceholders() {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "the", "bind", "markers", "factory", "uses", "identifiable", "placeholders", "false", "if", "multiple", "placeholders", "cannot", "be", "distinguished", "by", "just", "the", "bind", "marker", "get", "placeholder", "placeholder", "identifier"], "project": "spring-framework"}
{"id": 3175, "code": "\tpublic static <K, V> LinkedHashMap<K, V> newLinkedHashMap(int expectedSize) {\n\t\treturn new LinkedHashMap<>((int) (expectedSize / DEFAULT_LOAD_FACTOR), DEFAULT_LOAD_FACTOR);\n\t}", "summary_tokens": ["instantiate", "a", "new", "linked", "hash", "map", "with", "an", "initial", "capacity", "that", "can", "accommodate", "the", "specified", "number", "of", "elements", "without", "any", "immediate", "resize", "rehash", "operations", "to", "be", "expected"], "project": "spring-framework"}
{"id": 3263, "code": "\tpublic static boolean isFileURL(URL url) {\n\t\tString protocol = url.getProtocol();\n\t\treturn (URL_PROTOCOL_FILE.equals(protocol) || URL_PROTOCOL_VFSFILE.equals(protocol) ||\n\t\t\t\tURL_PROTOCOL_VFS.equals(protocol));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "url", "points", "to", "a", "resource", "in", "the", "file", "system", "i"], "project": "spring-framework"}
{"id": 2783, "code": "\tstatic AnnotationTypeMappings forAnnotationType(Class<? extends Annotation> annotationType,\n\t\t\tRepeatableContainers repeatableContainers, AnnotationFilter annotationFilter) {\n\n\t\tif (repeatableContainers == RepeatableContainers.standardRepeatables()) {\n\t\t\treturn standardRepeatablesCache.computeIfAbsent(annotationFilter,\n\t\t\t\t\tkey -> new Cache(repeatableContainers, key)).get(annotationType);\n\t\t}\n\t\tif (repeatableContainers == RepeatableContainers.none()) {\n\t\t\treturn noRepeatablesCache.computeIfAbsent(annotationFilter,\n\t\t\t\t\tkey -> new Cache(repeatableContainers, key)).get(annotationType);\n\t\t}\n\t\treturn new AnnotationTypeMappings(repeatableContainers, annotationFilter, annotationType);\n\t}", "summary_tokens": ["create", "annotation", "type", "mappings", "for", "the", "specified", "annotation", "type"], "project": "spring-framework"}
{"id": 9716, "code": "\tpublic void setMarshaller(Marshaller marshaller) {\n\t\tthis.marshaller = marshaller;\n\t}", "summary_tokens": ["set", "the", "marshaller", "to", "be", "used", "by", "this", "view"], "project": "spring-framework"}
{"id": 3999, "code": "\tpublic void setCredentialsForCurrentThread(String username, String password) {\n\t\tthis.threadBoundCredentials.set(new JdbcUserCredentials(username, password));\n\t}", "summary_tokens": ["set", "user", "credentials", "for", "this", "proxy", "and", "the", "current", "thread"], "project": "spring-framework"}
{"id": 9346, "code": "\tpublic void setLabel(Object label) {\n\t\tthis.label = label;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "label", "attribute"], "project": "spring-framework"}
{"id": 914, "code": "\tvoid copyPropertiesDoesNotCopyFromSuperTypeToSubType() {\n\t\tNumberHolder numberHolder = new NumberHolder();\n\t\tnumberHolder.setNumber(Integer.valueOf(42));\n\t\tIntegerHolder integerHolder = new IntegerHolder();\n\n\t\tBeanUtils.copyProperties(numberHolder, integerHolder);\n\t\tassertThat(numberHolder.getNumber()).isEqualTo(42);\n\t\tassertThat(integerHolder.getNumber()).isNull();\n\t}", "summary_tokens": ["number", "can", "not", "be", "copied", "to", "integer"], "project": "spring-framework"}
{"id": 8222, "code": "\tpublic boolean isBodyRequired() {\n\t\treturn this.bodyRequired;\n\t}", "summary_tokens": ["return", "the", "setting", "for", "set", "body", "required", "boolean"], "project": "spring-framework"}
{"id": 4283, "code": "\tprotected Session createSession(Connection con) throws JMSException {\n\t\treturn con.createSession(true, Session.AUTO_ACKNOWLEDGE);\n\t}", "summary_tokens": ["create", "a", "jms", "session", "for", "the", "given", "connection"], "project": "spring-framework"}
{"id": 4379, "code": "\tprotected final void refreshSharedConnection() throws JMSException {\n\t\tsynchronized (this.sharedConnectionMonitor) {\n\t\t\tConnectionFactoryUtils.releaseConnection(\n\t\t\t\t\tthis.sharedConnection, getConnectionFactory(), this.sharedConnectionStarted);\n\t\t\tthis.sharedConnection = null;\n\t\t\tthis.sharedConnection = createSharedConnection();\n\t\t\tif (this.sharedConnectionStarted) {\n\t\t\t\tthis.sharedConnection.start();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["refresh", "the", "shared", "connection", "that", "this", "container", "holds"], "project": "spring-framework"}
{"id": 9767, "code": "\tprotected Principal getUser() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "user", "to", "make", "available", "through", "web", "socket", "session", "get", "principal"], "project": "spring-framework"}
{"id": 9543, "code": "\tprotected RequestContext createRequestContext(\n\t\t\tHttpServletRequest request, HttpServletResponse response, Map<String, Object> model) {\n\n\t\treturn new RequestContext(request, response, getServletContext(), model);\n\t}", "summary_tokens": ["create", "a", "request", "context", "to", "expose", "under", "the", "specified", "attribute", "name"], "project": "spring-framework"}
{"id": 6936, "code": "\tpublic void setObjectMapper(ObjectMapper objectMapper) {\n\t\tAssert.isInstanceOf(CBORFactory.class, objectMapper.getFactory(), \"CBORFactory required\");\n\t\tsuper.setObjectMapper(objectMapper);\n\t}", "summary_tokens": ["the", "object", "mapper", "must", "be", "configured", "with", "a", "cborfactory", "instance"], "project": "spring-framework"}
{"id": 6134, "code": "\tdefault void afterConfigurerAdded(ConfigurableMockMvcBuilder<?> builder) {\n\t}", "summary_tokens": ["invoked", "immediately", "when", "this", "mock", "mvc", "configurer", "is", "added", "via", "configurable", "mock", "mvc", "builder", "apply"], "project": "spring-framework"}
{"id": 7688, "code": "\tpublic boolean isRemoveOnly() {\n\t\treturn this.removeOnly;\n\t}", "summary_tokens": ["whether", "the", "remove", "only", "mode", "is", "on"], "project": "spring-framework"}
{"id": 1709, "code": "\tpublic void setEnvironment(Properties environment) {\n\t\tCollectionUtils.mergePropertiesIntoMap(environment, this.environment);\n\t}", "summary_tokens": ["set", "the", "environment", "properties", "used", "to", "construct", "the", "jmxconnector", "as", "java"], "project": "spring-framework"}
{"id": 2497, "code": "private void computeAllFrames() {\n    \n  Handler handler = firstHandler;\n  while (handler != null) {\n    String catchTypeDescriptor =\n        handler.catchTypeDescriptor == null ? \"java/lang/Throwable\" : handler.catchTypeDescriptor;\n    int catchType = Frame.getAbstractTypeFromInternalName(symbolTable, catchTypeDescriptor);\n      \n    Label handlerBlock = handler.handlerPc.getCanonicalInstance();\n    handlerBlock.flags |= Label.FLAG_JUMP_TARGET;\n      \n    Label handlerRangeBlock = handler.startPc.getCanonicalInstance();\n    Label handlerRangeEnd = handler.endPc.getCanonicalInstance();\n    while (handlerRangeBlock != handlerRangeEnd) {\n      handlerRangeBlock.outgoingEdges =\n          new Edge(catchType, handlerBlock, handlerRangeBlock.outgoingEdges);\n      handlerRangeBlock = handlerRangeBlock.nextBasicBlock;\n    }\n    handler = handler.nextHandler;\n  }\n\n    \n  Frame firstFrame = firstBasicBlock.frame;\n  firstFrame.setInputFrameFromDescriptor(symbolTable, accessFlags, descriptor, this.maxLocals);\n  firstFrame.accept(this);\n\n    \n    \n    \n    \n    \n    \n  Label listOfBlocksToProcess = firstBasicBlock;\n  listOfBlocksToProcess.nextListElement = Label.EMPTY_LIST;\n  int maxStackSize = 0;\n  while (listOfBlocksToProcess != Label.EMPTY_LIST) {\n      \n    Label basicBlock = listOfBlocksToProcess;\n    listOfBlocksToProcess = listOfBlocksToProcess.nextListElement;\n    basicBlock.nextListElement = null;\n      \n    basicBlock.flags |= Label.FLAG_REACHABLE;\n      \n    int maxBlockStackSize = basicBlock.frame.getInputStackSize() + basicBlock.outputStackMax;\n    if (maxBlockStackSize > maxStackSize) {\n      maxStackSize = maxBlockStackSize;\n    }\n      \n    Edge outgoingEdge = basicBlock.outgoingEdges;\n    while (outgoingEdge != null) {\n      Label successorBlock = outgoingEdge.successor.getCanonicalInstance();\n      boolean successorBlockChanged =\n          basicBlock.frame.merge(symbolTable, successorBlock.frame, outgoingEdge.info);\n      if (successorBlockChanged && successorBlock.nextListElement == null) {\n          \n          \n        successorBlock.nextListElement = listOfBlocksToProcess;\n        listOfBlocksToProcess = successorBlock;\n      }\n      outgoingEdge = outgoingEdge.nextEdge;\n    }\n  }\n\n    \n    \n    \n  Label basicBlock = firstBasicBlock;\n  while (basicBlock != null) {\n    if ((basicBlock.flags & (Label.FLAG_JUMP_TARGET | Label.FLAG_REACHABLE))\n        == (Label.FLAG_JUMP_TARGET | Label.FLAG_REACHABLE)) {\n      basicBlock.frame.accept(this);\n    }\n    if ((basicBlock.flags & Label.FLAG_REACHABLE) == 0) {\n        \n      Label nextBasicBlock = basicBlock.nextBasicBlock;\n      int startOffset = basicBlock.bytecodeOffset;\n      int endOffset = (nextBasicBlock == null ? code.length : nextBasicBlock.bytecodeOffset) - 1;\n      if (endOffset >= startOffset) {\n          \n        for (int i = startOffset; i < endOffset; ++i) {\n          code.data[i] = Opcodes.NOP;\n        }\n        code.data[endOffset] = (byte) Opcodes.ATHROW;\n          \n          \n        int frameIndex = visitFrameStart(startOffset,  0,  1);\n        currentFrame[frameIndex] =\n            Frame.getAbstractTypeFromInternalName(symbolTable, \"java/lang/Throwable\");\n        visitFrameEnd();\n          \n        firstHandler = Handler.removeRange(firstHandler, basicBlock, nextBasicBlock);\n          \n        maxStackSize = Math.max(maxStackSize, 1);\n      }\n    }\n    basicBlock = basicBlock.nextBasicBlock;\n  }\n\n  this.maxStack = maxStackSize;\n}", "summary_tokens": ["computes", "all", "the", "stack", "map", "frames", "of", "the", "method", "from", "scratch"], "project": "spring-framework"}
{"id": 7186, "code": "\tpublic String getFieldMarkerPrefix() {\n\t\treturn this.fieldMarkerPrefix;\n\t}", "summary_tokens": ["return", "the", "prefix", "for", "parameters", "that", "mark", "potentially", "empty", "fields"], "project": "spring-framework"}
{"id": 7960, "code": "\tpublic FilterRegistration getFilterRegistration(String filterName) {\n\t\treturn null;\n\t}", "summary_tokens": ["this", "method", "always", "returns", "null"], "project": "spring-framework"}
{"id": 5284, "code": "\tpublic void setEntityManagerFactoryBeanName(@Nullable String entityManagerFactoryBeanName) {\n\t\tthis.entityManagerFactoryBeanName = entityManagerFactoryBeanName;\n\t}", "summary_tokens": ["set", "the", "bean", "name", "of", "the", "entity", "manager", "factory", "to", "fetch", "from", "spring", "s", "root", "application", "context"], "project": "spring-framework"}
{"id": 3579, "code": "\tpublic static DataBindingPropertyAccessor forReadWriteAccess() {\n\t\treturn new DataBindingPropertyAccessor(true);\n\t}", "summary_tokens": ["create", "a", "new", "data", "binding", "property", "accessor", "for", "read", "write", "operations"], "project": "spring-framework"}
{"id": 4294, "code": "\tpublic void initConnection() throws JMSException {\n\t\tif (getTargetConnectionFactory() == null) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"'targetConnectionFactory' is required for lazily initializing a Connection\");\n\t\t}\n\t\tsynchronized (this.connectionMonitor) {\n\t\t\tif (this.connection != null) {\n\t\t\t\tcloseConnection(this.connection);\n\t\t\t}\n\t\t\tthis.connection = doCreateConnection();\n\t\t\tprepareConnection(this.connection);\n\t\t\tif (this.startedCount > 0) {\n\t\t\t\tthis.connection.start();\n\t\t\t}\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Established shared JMS Connection: \" + this.connection);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "underlying", "shared", "connection"], "project": "spring-framework"}
{"id": 8298, "code": "\tpublic void saveModel() {\n\t\tif (this.saveModelOperation != null) {\n\t\t\tthis.saveModelOperation.run();\n\t\t}\n\t}", "summary_tokens": ["save", "model", "attributes", "in", "the", "session", "based", "on", "a", "type", "level", "declarations", "in", "an", "annotation"], "project": "spring-framework"}
{"id": 7845, "code": "\tpublic void setUrlDecode(boolean urlDecode) {\n\t\tcheckReadOnly();\n\t\tthis.urlDecode = urlDecode;\n\t}", "summary_tokens": ["whether", "the", "context", "path", "and", "request", "uri", "should", "be", "decoded", "both", "of", "which", "are", "returned", "i", "undecoded", "i", "by", "the", "servlet", "api", "in", "contrast", "to", "the", "servlet", "path"], "project": "spring-framework"}
{"id": 9119, "code": "\tpublic final Map<String, Object> getModel() {\n\t\treturn this.model;\n\t}", "summary_tokens": ["return", "the", "model", "map", "that", "this", "request", "context", "encapsulates", "if", "any"], "project": "spring-framework"}
{"id": 1090, "code": "\tpublic void setGlobalTriggerListeners(TriggerListener... globalTriggerListeners) {\n\t\tthis.globalTriggerListeners = globalTriggerListeners;\n\t}", "summary_tokens": ["specify", "global", "quartz", "trigger", "listeners", "to", "be", "registered", "with", "the", "scheduler"], "project": "spring-framework"}
{"id": 5702, "code": "\tClass<?> getDeclaringClass() {\n\t\treturn this.declaringClass;\n\t}", "summary_tokens": ["get", "the", "class", "class", "that", "declared"], "project": "spring-framework"}
{"id": 2285, "code": "\tpublic Stream<ExecutableHint> methods() {\n\t\treturn this.methods.stream();\n\t}", "summary_tokens": ["return", "the", "methods", "that", "require", "reflection"], "project": "spring-framework"}
{"id": 5357, "code": "\tpublic Mono<Void> resetConnection() {\n\t\tConnection connection = this.target.get();\n\t\tif (connection == null) {\n\t\t\treturn Mono.empty();\n\t\t}\n\t\treturn Mono.defer(() -> {\n\t\t\tif (this.target.compareAndSet(connection, null)) {\n\t\t\t\tthis.connection = null;\n\t\t\t\treturn Mono.from(connection.close());\n\t\t\t}\n\t\t\treturn Mono.empty();\n\t\t});\n\t}", "summary_tokens": ["reset", "the", "underlying", "shared", "connection", "to", "be", "reinitialized", "on", "next", "access"], "project": "spring-framework"}
{"id": 3630, "code": "\tvoid indexingAsAPropertyAccess_SPR6968_3() {\n\t\tStandardEvaluationContext context = new StandardEvaluationContext(new Goo());\n\t\tcontext.setVariable(\"bar\", \"wibble\");\n\t\tString name = null;\n\t\tExpression expr = null;\n\t\texpr = new SpelExpressionParser().parseRaw(\"instance[#bar]\");\n\t\t\n\t\tname = expr.getValue(context, String.class);\n\t\tassertThat(name).isEqualTo(\"wobble\");\n\t\tname = expr.getValue(context, String.class); \n\t\tassertThat(name).isEqualTo(\"wobble\");\n\t}", "summary_tokens": ["should", "be", "accessing", "goo"], "project": "spring-framework"}
{"id": 1489, "code": "\tpublic void setFractionDigits(int fractionDigits) {\n\t\tthis.fractionDigits = fractionDigits;\n\t}", "summary_tokens": ["specify", "the", "desired", "number", "of", "fraction", "digits"], "project": "spring-framework"}
{"id": 4556, "code": "\tpublic void setSessionAcknowledgeModeName(String constantName) {\n\t\tsetSessionAcknowledgeMode(sessionConstants.asNumber(constantName).intValue());\n\t}", "summary_tokens": ["set", "the", "jms", "acknowledgement", "mode", "by", "the", "name", "of", "the", "corresponding", "constant", "in", "the", "jms", "session", "interface", "e"], "project": "spring-framework"}
{"id": 1979, "code": "\tprotected AbstractPropertyBindingResult createBeanPropertyBindingResult() {\n\t\tBeanPropertyBindingResult result = new BeanPropertyBindingResult(getTarget(),\n\t\t\t\tgetObjectName(), isAutoGrowNestedPaths(), getAutoGrowCollectionLimit());\n\n\t\tif (this.conversionService != null) {\n\t\t\tresult.initConversion(this.conversionService);\n\t\t}\n\t\tif (this.messageCodesResolver != null) {\n\t\t\tresult.setMessageCodesResolver(this.messageCodesResolver);\n\t\t}\n\n\t\treturn result;\n\t}", "summary_tokens": ["create", "the", "abstract", "property", "binding", "result", "instance", "using", "standard", "java", "bean", "property", "access"], "project": "spring-framework"}
{"id": 2583, "code": "public static int getArgumentsAndReturnSizes(final String methodDescriptor) {\n  int argumentsSize = 1;\n    \n  int currentOffset = 1;\n  int currentChar = methodDescriptor.charAt(currentOffset);\n    \n  while (currentChar != ')') {\n    if (currentChar == 'J' || currentChar == 'D') {\n      currentOffset++;\n      argumentsSize += 2;\n    } else {\n      while (methodDescriptor.charAt(currentOffset) == '[') {\n        currentOffset++;\n      }\n      if (methodDescriptor.charAt(currentOffset++) == 'L') {\n          \n        int semiColumnOffset = methodDescriptor.indexOf(';', currentOffset);\n        currentOffset = Math.max(currentOffset, semiColumnOffset + 1);\n      }\n      argumentsSize += 1;\n    }\n    currentChar = methodDescriptor.charAt(currentOffset);\n  }\n  currentChar = methodDescriptor.charAt(currentOffset + 1);\n  if (currentChar == 'V') {\n    return argumentsSize << 2;\n  } else {\n    int returnSize = (currentChar == 'J' || currentChar == 'D') ? 2 : 1;\n    return argumentsSize << 2 | returnSize;\n  }\n}", "summary_tokens": ["computes", "the", "size", "of", "the", "arguments", "and", "of", "the", "return", "value", "of", "a", "method"], "project": "spring-framework"}
{"id": 7726, "code": "\tpublic void setDefaultLocale(@Nullable Locale defaultLocale) {\n\t\tthis.defaultLocale = defaultLocale;\n\t}", "summary_tokens": ["configure", "a", "fixed", "default", "locale", "to", "fall", "back", "on", "if", "the", "request", "does", "not", "have", "an", "accept", "language", "header", "not", "set", "by", "default"], "project": "spring-framework"}
{"id": 4810, "code": "\tpublic MimeType getDefaultMetadataMimeType() {\n\t\treturn this.defaultMetadataMimeType;\n\t}", "summary_tokens": ["return", "the", "configured", "set", "default", "metadata", "mime", "type", "default", "metadata", "mime", "type"], "project": "spring-framework"}
{"id": 859, "code": "\tpublic String registerWithGeneratedName(BeanDefinition beanDefinition) {\n\t\tString generatedName = generateBeanName(beanDefinition);\n\t\tgetRegistry().registerBeanDefinition(generatedName, beanDefinition);\n\t\treturn generatedName;\n\t}", "summary_tokens": ["call", "the", "bean", "name", "generator", "for", "the", "given", "bean", "definition", "and", "register", "the", "bean", "definition", "under", "the", "generated", "name"], "project": "spring-framework"}
{"id": 127, "code": "\tpublic void setApplyCommonInterceptorsFirst(boolean applyCommonInterceptorsFirst) {\n\t\tthis.applyCommonInterceptorsFirst = applyCommonInterceptorsFirst;\n\t}", "summary_tokens": ["set", "whether", "the", "common", "interceptors", "should", "be", "applied", "before", "bean", "specific", "ones"], "project": "spring-framework"}
{"id": 1697, "code": "\tpublic static Class<?> getMBeanInterface(@Nullable Class<?> clazz) {\n\t\tif (clazz == null || clazz.getSuperclass() == null) {\n\t\t\treturn null;\n\t\t}\n\t\tString mbeanInterfaceName = clazz.getName() + MBEAN_SUFFIX;\n\t\tClass<?>[] implementedInterfaces = clazz.getInterfaces();\n\t\tfor (Class<?> iface : implementedInterfaces) {\n\t\t\tif (iface.getName().equals(mbeanInterfaceName)) {\n\t\t\t\treturn iface;\n\t\t\t}\n\t\t}\n\t\treturn getMBeanInterface(clazz.getSuperclass());\n\t}", "summary_tokens": ["return", "the", "standard", "mbean", "interface", "for", "the", "given", "class", "if", "any", "that", "is", "an", "interface", "whose", "name", "matches", "the", "class", "name", "of", "the", "given", "class", "but", "with", "suffix", "mbean"], "project": "spring-framework"}
{"id": 8610, "code": "\tpublic PathMatchConfigurer setUseTrailingSlashMatch(Boolean trailingSlashMatch) {\n\t\tthis.trailingSlashMatch = trailingSlashMatch;\n\t\treturn this;\n\t}", "summary_tokens": ["whether", "to", "match", "to", "urls", "irrespective", "of", "the", "presence", "of", "a", "trailing", "slash"], "project": "spring-framework"}
{"id": 6323, "code": "\tprotected TransactionSynchronizationRegistry retrieveTransactionSynchronizationRegistry() throws TransactionSystemException {\n\t\treturn null;\n\t}", "summary_tokens": ["allows", "subclasses", "to", "retrieve", "the", "jta", "0"], "project": "spring-framework"}
{"id": 1452, "code": "\tprotected MessageFormat resolveCode(String code, Locale locale) {\n\t\tSet<String> basenames = getBasenameSet();\n\t\tfor (String basename : basenames) {\n\t\t\tResourceBundle bundle = getResourceBundle(basename, locale);\n\t\t\tif (bundle != null) {\n\t\t\t\tMessageFormat messageFormat = getMessageFormat(bundle, code, locale);\n\t\t\t\tif (messageFormat != null) {\n\t\t\t\t\treturn messageFormat;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["resolves", "the", "given", "message", "code", "as", "key", "in", "the", "registered", "resource", "bundles", "using", "a", "cached", "message", "format", "instance", "per", "message", "code"], "project": "spring-framework"}
{"id": 1345, "code": "\tpublic void setCommonMessages(@Nullable Properties commonMessages) {\n\t\tthis.commonMessages = commonMessages;\n\t}", "summary_tokens": ["specify", "locale", "independent", "common", "messages", "with", "the", "message", "code", "as", "key", "and", "the", "full", "message", "string", "may", "contain", "argument", "placeholders", "as", "value"], "project": "spring-framework"}
{"id": 367, "code": "\tprivate Object doConvertValue(@Nullable Object oldValue, @Nullable Object newValue,\n\t\t\t@Nullable Class<?> requiredType, @Nullable PropertyEditor editor) {\n\n\t\tObject convertedValue = newValue;\n\n\t\tif (editor != null && !(convertedValue instanceof String)) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\ttry {\n\t\t\t\teditor.setValue(convertedValue);\n\t\t\t\tObject newConvertedValue = editor.getValue();\n\t\t\t\tif (newConvertedValue != convertedValue) {\n\t\t\t\t\tconvertedValue = newConvertedValue;\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\teditor = null;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"PropertyEditor [\" + editor.getClass().getName() + \"] does not support setValue call\", ex);\n\t\t\t\t}\n\t\t\t\t\n\t\t\t}\n\t\t}\n\n\t\tObject returnValue = convertedValue;\n\n\t\tif (requiredType != null && !requiredType.isArray() && convertedValue instanceof String[]) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Converting String array to comma-delimited String [\" + convertedValue + \"]\");\n\t\t\t}\n\t\t\tconvertedValue = StringUtils.arrayToCommaDelimitedString((String[]) convertedValue);\n\t\t}\n\n\t\tif (convertedValue instanceof String) {\n\t\t\tif (editor != null) {\n\t\t\t\t\n\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\tlogger.trace(\"Converting String to [\" + requiredType + \"] using property editor [\" + editor + \"]\");\n\t\t\t\t}\n\t\t\t\tString newTextValue = (String) convertedValue;\n\t\t\t\treturn doConvertTextValue(oldValue, newTextValue, editor);\n\t\t\t}\n\t\t\telse if (String.class == requiredType) {\n\t\t\t\treturnValue = convertedValue;\n\t\t\t}\n\t\t}\n\n\t\treturn returnValue;\n\t}", "summary_tokens": ["convert", "the", "value", "to", "the", "required", "type", "if", "necessary", "from", "a", "string", "using", "the", "given", "property", "editor"], "project": "spring-framework"}
{"id": 438, "code": "\tpublic AutowiredArguments resolve(RegisteredBean registeredBean) {\n\t\tAssert.notNull(registeredBean, \"'registeredBean' must not be null\");\n\t\treturn resolveArguments(registeredBean, getMethod(registeredBean));\n\t}", "summary_tokens": ["resolve", "the", "method", "arguments", "for", "the", "specified", "registered", "bean"], "project": "spring-framework"}
{"id": 4349, "code": "\tprivate <T> T executeLocal(SessionCallback<T> action, boolean startConnection) throws JmsException {\n\t\tAssert.notNull(action, \"Callback object must not be null\");\n\t\tConnection con = null;\n\t\tSession session = null;\n\t\ttry {\n\t\t\tcon = createConnection();\n\t\t\tsession = con.createSession(false, Session.AUTO_ACKNOWLEDGE);\n\t\t\tif (startConnection) {\n\t\t\t\tcon.start();\n\t\t\t}\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Executing callback on JMS Session: \" + session);\n\t\t\t}\n\t\t\treturn action.doInJms(session);\n\t\t}\n\t\tcatch (JMSException ex) {\n\t\t\tthrow convertJmsAccessException(ex);\n\t\t}\n\t\tfinally {\n\t\t\tJmsUtils.closeSession(session);\n\t\t\tConnectionFactoryUtils.releaseConnection(con, getConnectionFactory(), startConnection);\n\t\t}\n\t}", "summary_tokens": ["a", "variant", "of", "execute", "session", "callback", "boolean", "that", "explicitly", "creates", "a", "non", "transactional", "session"], "project": "spring-framework"}
{"id": 9045, "code": "\tprotected ModelAndView handleMissingServletRequestPartException(MissingServletRequestPartException ex,\n\t\t\tHttpServletRequest request, HttpServletResponse response, @Nullable Object handler) throws IOException {\n\n\t\treturn null;\n\t}", "summary_tokens": ["handle", "the", "case", "where", "an", "request", "part", "a", "multipart", "file", "or", "a", "jakarta"], "project": "spring-framework"}
{"id": 2327, "code": "final ByteVector put112(final int byteValue1, final int byteValue2, final int shortValue) {\n  int currentLength = length;\n  if (currentLength + 4 > data.length) {\n    enlarge(4);\n  }\n  byte[] currentData = data;\n  currentData[currentLength++] = (byte) byteValue1;\n  currentData[currentLength++] = (byte) byteValue2;\n  currentData[currentLength++] = (byte) (shortValue >>> 8);\n  currentData[currentLength++] = (byte) shortValue;\n  length = currentLength;\n  return this;\n}", "summary_tokens": ["puts", "two", "bytes", "and", "a", "short", "into", "this", "byte", "vector"], "project": "spring-framework"}
{"id": 8195, "code": "\tpublic void setContentCodings(List<String> codings) {\n\t\tAssert.notEmpty(codings, \"At least one content coding expected\");\n\t\tthis.contentCodings.clear();\n\t\tthis.contentCodings.addAll(codings);\n\t}", "summary_tokens": ["configure", "the", "supported", "content", "codings", "from", "the", "accept", "encoding", "header", "for", "which", "to", "cache", "resource", "variations"], "project": "spring-framework"}
{"id": 4024, "code": "\tpublic void addPopulators(DatabasePopulator... populators) {\n\t\tAssert.notNull(populators, \"DatabasePopulators must not be null\");\n\t\tthis.populators.addAll(Arrays.asList(populators));\n\t}", "summary_tokens": ["add", "one", "or", "more", "populators", "to", "the", "list", "of", "delegates"], "project": "spring-framework"}
{"id": 7842, "code": "\tpublic static String decode(String source, Charset charset) {\n\t\treturn StringUtils.uriDecode(source, charset);\n\t}", "summary_tokens": ["decode", "the", "given", "encoded", "uri", "component"], "project": "spring-framework"}
{"id": 3961, "code": "\tpublic void setReadOnly(boolean readOnly) {\n\t\tthis.readOnly = readOnly;\n\t}", "summary_tokens": ["set", "the", "read", "only", "status", "of", "this", "transaction"], "project": "spring-framework"}
{"id": 9171, "code": "\tpublic final void setUseCacheControlHeader(boolean useCacheControlHeader) {\n\t\tthis.useCacheControlHeader = useCacheControlHeader;\n\t}", "summary_tokens": ["set", "whether", "to", "use", "the", "http", "0"], "project": "spring-framework"}
{"id": 7237, "code": "\tdefault void handleError(URI url, HttpMethod method, ClientHttpResponse response) throws IOException {\n\t\thandleError(response);\n\t}", "summary_tokens": ["alternative", "to", "handle", "error", "client", "http", "response", "with", "extra", "information", "providing", "access", "to", "the", "request", "url", "and", "http", "method"], "project": "spring-framework"}
{"id": 9245, "code": "\tprotected String replaceUriTemplateParams(String uri, List<Param> params, Set<String> usedParams)\n\t\t\tthrows JspException {\n\n\t\tString encoding = this.pageContext.getResponse().getCharacterEncoding();\n\t\tfor (Param param : params) {\n\t\t\tString template = URL_TEMPLATE_DELIMITER_PREFIX + param.getName() + URL_TEMPLATE_DELIMITER_SUFFIX;\n\t\t\tif (uri.contains(template)) {\n\t\t\t\tusedParams.add(param.getName());\n\t\t\t\tString value = param.getValue();\n\t\t\t\ttry {\n\t\t\t\t\turi = StringUtils.replace(uri, template,\n\t\t\t\t\t\t\t(value != null ? UriUtils.encodePath(value, encoding) : \"\"));\n\t\t\t\t}\n\t\t\t\tcatch (UnsupportedCharsetException ex) {\n\t\t\t\t\tthrow new JspException(ex);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttemplate = URL_TEMPLATE_DELIMITER_PREFIX + '/' + param.getName() + URL_TEMPLATE_DELIMITER_SUFFIX;\n\t\t\t\tif (uri.contains(template)) {\n\t\t\t\t\tusedParams.add(param.getName());\n\t\t\t\t\tString value = param.getValue();\n\t\t\t\t\ttry {\n\t\t\t\t\t\turi = StringUtils.replace(uri, template,\n\t\t\t\t\t\t\t\t(value != null ? UriUtils.encodePathSegment(value, encoding) : \"\"));\n\t\t\t\t\t}\n\t\t\t\t\tcatch (UnsupportedCharsetException ex) {\n\t\t\t\t\t\tthrow new JspException(ex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn uri;\n\t}", "summary_tokens": ["replace", "template", "markers", "in", "the", "url", "matching", "available", "parameters"], "project": "spring-framework"}
{"id": 7217, "code": "\tprotected WebApplicationContext getWebApplicationContext() {\n\t\tWebApplicationContext wac = ContextLoader.getCurrentWebApplicationContext();\n\t\tif (wac == null) {\n\t\t\tthrow new IllegalStateException(\"No WebApplicationContext registered for current thread - \" +\n\t\t\t\t\t\"consider overriding SpringWebConstraintValidatorFactory.getWebApplicationContext()\");\n\t\t}\n\t\treturn wac;\n\t}", "summary_tokens": ["retrieve", "the", "spring", "web", "application", "context", "to", "use"], "project": "spring-framework"}
{"id": 2819, "code": "\tdefault T decode(DataBuffer buffer, ResolvableType targetType,\n\t\t\t@Nullable MimeType mimeType, @Nullable Map<String, Object> hints) throws DecodingException {\n\n\t\tCompletableFuture<T> future = decodeToMono(Mono.just(buffer), targetType, mimeType, hints).toFuture();\n\t\tAssert.state(future.isDone(), \"DataBuffer decoding should have completed.\");\n\n\t\tThrowable failure;\n\t\ttry {\n\t\t\treturn future.get();\n\t\t}\n\t\tcatch (ExecutionException ex) {\n\t\t\tfailure = ex.getCause();\n\t\t}\n\t\tcatch (InterruptedException ex) {\n\t\t\tfailure = ex;\n\t\t}\n\t\tthrow (failure instanceof CodecException ? (CodecException) failure :\n\t\t\t\tnew DecodingException(\"Failed to decode: \" + failure.getMessage(), failure));\n\t}", "summary_tokens": ["decode", "a", "data", "buffer", "to", "an", "object", "of", "type", "t"], "project": "spring-framework"}
{"id": 8828, "code": "\tpublic void setUseSharedServletConfig(boolean useSharedServletConfig) {\n\t\tthis.useSharedServletConfig = useSharedServletConfig;\n\t}", "summary_tokens": ["set", "whether", "to", "use", "the", "shared", "servlet", "config", "object", "passed", "in", "through", "set", "servlet", "config", "if", "available"], "project": "spring-framework"}
{"id": 845, "code": "\tprotected int detectValidationMode(Resource resource) {\n\t\tif (resource.isOpen()) {\n\t\t\tthrow new BeanDefinitionStoreException(\n\t\t\t\t\t\"Passed-in Resource [\" + resource + \"] contains an open stream: \" +\n\t\t\t\t\t\"cannot determine validation mode automatically. Either pass in a Resource \" +\n\t\t\t\t\t\"that is able to create fresh streams, or explicitly specify the validationMode \" +\n\t\t\t\t\t\"on your XmlBeanDefinitionReader instance.\");\n\t\t}\n\n\t\tInputStream inputStream;\n\t\ttry {\n\t\t\tinputStream = resource.getInputStream();\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new BeanDefinitionStoreException(\n\t\t\t\t\t\"Unable to determine validation mode for [\" + resource + \"]: cannot open InputStream. \" +\n\t\t\t\t\t\"Did you attempt to load directly from a SAX InputSource without specifying the \" +\n\t\t\t\t\t\"validationMode on your XmlBeanDefinitionReader instance?\", ex);\n\t\t}\n\n\t\ttry {\n\t\t\treturn this.validationModeDetector.detectValidationMode(inputStream);\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new BeanDefinitionStoreException(\"Unable to determine validation mode for [\" +\n\t\t\t\t\tresource + \"]: an error occurred whilst reading from the InputStream.\", ex);\n\t\t}\n\t}", "summary_tokens": ["detect", "which", "kind", "of", "validation", "to", "perform", "on", "the", "xml", "file", "identified", "by", "the", "supplied", "resource"], "project": "spring-framework"}
{"id": 4109, "code": "\tprotected ParsedSql getParsedSql() {\n\t\tsynchronized (this.parsedSqlMonitor) {\n\t\t\tif (this.cachedSql == null) {\n\t\t\t\tthis.cachedSql = NamedParameterUtils.parseSqlStatement(resolveSql());\n\t\t\t}\n\t\t\treturn this.cachedSql;\n\t\t}\n\t}", "summary_tokens": ["obtain", "a", "parsed", "representation", "of", "this", "operation", "s", "sql", "statement"], "project": "spring-framework"}
{"id": 6443, "code": "\tprivate TransactionStatus handleExistingTransaction(\n\t\t\tTransactionDefinition definition, Object transaction, boolean debugEnabled)\n\t\t\tthrows TransactionException {\n\n\t\tif (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) {\n\t\t\tthrow new IllegalTransactionStateException(\n\t\t\t\t\t\"Existing transaction found for transaction marked with propagation 'never'\");\n\t\t}\n\n\t\tif (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED) {\n\t\t\tif (debugEnabled) {\n\t\t\t\tlogger.debug(\"Suspending current transaction\");\n\t\t\t}\n\t\t\tObject suspendedResources = suspend(transaction);\n\t\t\tboolean newSynchronization = (getTransactionSynchronization() == SYNCHRONIZATION_ALWAYS);\n\t\t\treturn prepareTransactionStatus(\n\t\t\t\t\tdefinition, null, false, newSynchronization, debugEnabled, suspendedResources);\n\t\t}\n\n\t\tif (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_REQUIRES_NEW) {\n\t\t\tif (debugEnabled) {\n\t\t\t\tlogger.debug(\"Suspending current transaction, creating new transaction with name [\" +\n\t\t\t\t\t\tdefinition.getName() + \"]\");\n\t\t\t}\n\t\t\tSuspendedResourcesHolder suspendedResources = suspend(transaction);\n\t\t\ttry {\n\t\t\t\treturn startTransaction(definition, transaction, debugEnabled, suspendedResources);\n\t\t\t}\n\t\t\tcatch (RuntimeException | Error beginEx) {\n\t\t\t\tresumeAfterBeginException(transaction, suspendedResources, beginEx);\n\t\t\t\tthrow beginEx;\n\t\t\t}\n\t\t}\n\n\t\tif (definition.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NESTED) {\n\t\t\tif (!isNestedTransactionAllowed()) {\n\t\t\t\tthrow new NestedTransactionNotSupportedException(\n\t\t\t\t\t\t\"Transaction manager does not allow nested transactions by default - \" +\n\t\t\t\t\t\t\"specify 'nestedTransactionAllowed' property with value 'true'\");\n\t\t\t}\n\t\t\tif (debugEnabled) {\n\t\t\t\tlogger.debug(\"Creating nested transaction with name [\" + definition.getName() + \"]\");\n\t\t\t}\n\t\t\tif (useSavepointForNestedTransaction()) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tDefaultTransactionStatus status =\n\t\t\t\t\t\tprepareTransactionStatus(definition, transaction, false, false, debugEnabled, null);\n\t\t\t\tstatus.createAndHoldSavepoint();\n\t\t\t\treturn status;\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\treturn startTransaction(definition, transaction, debugEnabled, null);\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tif (debugEnabled) {\n\t\t\tlogger.debug(\"Participating in existing transaction\");\n\t\t}\n\t\tif (isValidateExistingTransaction()) {\n\t\t\tif (definition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT) {\n\t\t\t\tInteger currentIsolationLevel = TransactionSynchronizationManager.getCurrentTransactionIsolationLevel();\n\t\t\t\tif (currentIsolationLevel == null || currentIsolationLevel != definition.getIsolationLevel()) {\n\t\t\t\t\tConstants isoConstants = DefaultTransactionDefinition.constants;\n\t\t\t\t\tthrow new IllegalTransactionStateException(\"Participating transaction with definition [\" +\n\t\t\t\t\t\t\tdefinition + \"] specifies isolation level which is incompatible with existing transaction: \" +\n\t\t\t\t\t\t\t(currentIsolationLevel != null ?\n\t\t\t\t\t\t\t\t\tisoConstants.toCode(currentIsolationLevel, DefaultTransactionDefinition.PREFIX_ISOLATION) :\n\t\t\t\t\t\t\t\t\t\"(unknown)\"));\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!definition.isReadOnly()) {\n\t\t\t\tif (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {\n\t\t\t\t\tthrow new IllegalTransactionStateException(\"Participating transaction with definition [\" +\n\t\t\t\t\t\t\tdefinition + \"] is not marked as read-only but existing transaction is\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tboolean newSynchronization = (getTransactionSynchronization() != SYNCHRONIZATION_NEVER);\n\t\treturn prepareTransactionStatus(definition, transaction, false, newSynchronization, debugEnabled, null);\n\t}", "summary_tokens": ["create", "a", "transaction", "status", "for", "an", "existing", "transaction"], "project": "spring-framework"}
{"id": 3933, "code": "\tprotected void setConnection(@Nullable Connection connection) {\n\t\tif (this.currentConnection != null) {\n\t\t\tif (this.connectionHandle != null) {\n\t\t\t\tthis.connectionHandle.releaseConnection(this.currentConnection);\n\t\t\t}\n\t\t\tthis.currentConnection = null;\n\t\t}\n\t\tif (connection != null) {\n\t\t\tthis.connectionHandle = new SimpleConnectionHandle(connection);\n\t\t}\n\t\telse {\n\t\t\tthis.connectionHandle = null;\n\t\t}\n\t}", "summary_tokens": ["override", "the", "existing", "connection", "handle", "with", "the", "given", "connection"], "project": "spring-framework"}
{"id": 3665, "code": "\tpublic boolean isPrimitivesDefaultedForNullValue() {\n\t\treturn this.primitivesDefaultedForNullValue;\n\t}", "summary_tokens": ["return", "whether", "we", "re", "defaulting", "java", "primitives", "in", "the", "case", "of", "mapping", "a", "null", "value", "from", "corresponding", "database", "fields"], "project": "spring-framework"}
{"id": 7005, "code": "\tpublic void setFailOnEmptyBeans(boolean failOnEmptyBeans) {\n\t\tthis.builder.failOnEmptyBeans(failOnEmptyBeans);\n\t}", "summary_tokens": ["shortcut", "for", "serialization", "feature", "fail", "on", "empty", "beans", "option"], "project": "spring-framework"}
{"id": 2470, "code": "public AnnotationVisitor visitTypeAnnotation(\n    final int typeRef, final TypePath typePath, final String descriptor, final boolean visible) {\n  if (api < Opcodes.ASM5) {\n    throw new UnsupportedOperationException(REQUIRES_ASM5);\n  }\n  if (mv != null) {\n    return mv.visitTypeAnnotation(typeRef, typePath, descriptor, visible);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "annotation", "on", "a", "type", "in", "the", "method", "signature"], "project": "spring-framework"}
{"id": 8204, "code": "\tpublic ResourceUrlProvider getResourceUrlProvider() {\n\t\treturn this.resourceUrlProvider;\n\t}", "summary_tokens": ["return", "the", "configured", "resource", "url", "provider"], "project": "spring-framework"}
{"id": 5101, "code": "\tpublic MethodParameter arg(ResolvableType type) {\n\t\treturn new ArgResolver().arg(type);\n\t}", "summary_tokens": ["find", "a", "unique", "argument", "matching", "the", "given", "type"], "project": "spring-framework"}
{"id": 7869, "code": "\tprotected String determineEncoding(HttpServletRequest request) {\n\t\tString enc = request.getCharacterEncoding();\n\t\tif (enc == null) {\n\t\t\tenc = getDefaultEncoding();\n\t\t}\n\t\treturn enc;\n\t}", "summary_tokens": ["determine", "the", "encoding", "for", "the", "given", "request"], "project": "spring-framework"}
{"id": 696, "code": "\tpublic void destroySingleton(String beanName) {\n\t\t\n\t\tremoveSingleton(beanName);\n\n\t\t\n\t\tDisposableBean disposableBean;\n\t\tsynchronized (this.disposableBeans) {\n\t\t\tdisposableBean = (DisposableBean) this.disposableBeans.remove(beanName);\n\t\t}\n\t\tdestroyBean(beanName, disposableBean);\n\t}", "summary_tokens": ["destroy", "the", "given", "bean"], "project": "spring-framework"}
{"id": 3238, "code": "\tpublic Object[] getArguments() {\n\t\treturn (this.arguments != null ? this.arguments : EMPTY_ARGUMENTS);\n\t}", "summary_tokens": ["return", "the", "arguments", "for", "the", "method", "invocation"], "project": "spring-framework"}
{"id": 3958, "code": "\tpublic boolean hasConnectionHolder() {\n\t\treturn (this.connectionHolder != null);\n\t}", "summary_tokens": ["check", "whether", "this", "transaction", "object", "has", "a", "connection", "holder"], "project": "spring-framework"}
{"id": 5969, "code": "\tpublic ResultMatcher source(Matcher<? super Source> matcher) {\n\t\treturn result -> {\n\t\t\tString content = result.getResponse().getContentAsString();\n\t\t\tthis.xmlHelper.assertSource(content, matcher);\n\t\t};\n\t}", "summary_tokens": ["parse", "the", "response", "content", "as", "domsource", "and", "apply", "the", "given", "hamcrest", "matcher"], "project": "spring-framework"}
{"id": 4318, "code": "\tpublic void setDefaultDestination(@Nullable Destination destination) {\n\t\tthis.defaultDestination = destination;\n\t}", "summary_tokens": ["set", "the", "destination", "to", "be", "used", "on", "send", "receive", "operations", "that", "do", "not", "have", "a", "destination", "parameter"], "project": "spring-framework"}
{"id": 814, "code": "\tpublic void setInitMethod(@Nullable String initMethod) {\n\t\tthis.initMethod = initMethod;\n\t}", "summary_tokens": ["set", "the", "default", "init", "method", "setting", "for", "the", "document", "that", "s", "currently", "parsed"], "project": "spring-framework"}
{"id": 9629, "code": "\tpublic void setExposedContextBeanNames(@Nullable String... exposedContextBeanNames) {\n\t\tthis.exposedContextBeanNames = exposedContextBeanNames;\n\t}", "summary_tokens": ["specify", "the", "names", "of", "beans", "in", "the", "context", "which", "are", "supposed", "to", "be", "exposed"], "project": "spring-framework"}
{"id": 7774, "code": "\tpublic void removeCookie(HttpServletResponse response) {\n\t\tAssert.notNull(response, \"HttpServletResponse must not be null\");\n\t\tCookie cookie = createCookie(\"\");\n\t\tcookie.setMaxAge(0);\n\t\tif (isCookieSecure()) {\n\t\t\tcookie.setSecure(true);\n\t\t}\n\t\tif (isCookieHttpOnly()) {\n\t\t\tcookie.setHttpOnly(true);\n\t\t}\n\t\tresponse.addCookie(cookie);\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"Removed cookie '\" + getCookieName() + \"'\");\n\t\t}\n\t}", "summary_tokens": ["remove", "the", "cookie", "that", "this", "generator", "describes", "from", "the", "response"], "project": "spring-framework"}
{"id": 4607, "code": "\tprotected Destination resolveDestinationName(Session session, String destinationName) throws JMSException {\n\t\treturn getDestinationResolver().resolveDestinationName(session, destinationName, isPubSubDomain());\n\t}", "summary_tokens": ["resolve", "the", "given", "destination", "name", "into", "a", "jms", "destination", "via", "this", "accessor", "s", "destination", "resolver"], "project": "spring-framework"}
{"id": 249, "code": "\tpublic void setMaxSize(int maxSize) {\n\t\tthis.maxSize = maxSize;\n\t}", "summary_tokens": ["set", "the", "maximum", "size", "of", "the", "pool"], "project": "spring-framework"}
{"id": 6244, "code": "\tpublic TransactionPhase getTransactionPhase() {\n\t\treturn this.transactionPhase;\n\t}", "summary_tokens": ["return", "the", "transaction", "phase", "to", "invoke", "the", "listener", "in"], "project": "spring-framework"}
{"id": 7975, "code": "\tpublic Mono<HandlerResult> applyExceptionHandler(Throwable failure) {\n\t\treturn (this.exceptionHandler != null ? this.exceptionHandler.apply(failure) : Mono.error(failure));\n\t}", "summary_tokens": ["apply", "the", "exception", "handler", "and", "return", "the", "alternative", "result"], "project": "spring-framework"}
{"id": 9210, "code": "\tpublic void setArguments(Object arguments) {\n\t\tthis.arguments = arguments;\n\t}", "summary_tokens": ["set", "optional", "message", "arguments", "for", "this", "tag", "as", "a", "comma", "delimited", "string", "each", "string", "argument", "can", "contain", "jsp", "el", "an", "object", "array", "used", "as", "argument", "array", "or", "a", "single", "object", "used", "as", "single", "argument"], "project": "spring-framework"}
{"id": 7895, "code": "\tpublic boolean matches(int pathIndex, MatchingContext matchingContext) {\n\t\tString segmentData = null;\n\t\t\n\t\tif (pathIndex < matchingContext.pathLength) {\n\t\t\tElement element = matchingContext.pathElements.get(pathIndex);\n\t\t\tif (!(element instanceof PathContainer.PathSegment)) {\n\t\t\t\t\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tsegmentData = ((PathContainer.PathSegment)element).valueToMatch();\n\t\t\tpathIndex++;\n\t\t}\n\n\t\tif (isNoMorePattern()) {\n\t\t\tif (matchingContext.determineRemainingPath) {\n\t\t\t\tmatchingContext.remainingPathIndex = pathIndex;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (pathIndex == matchingContext.pathLength) {\n\t\t\t\t\t\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn (matchingContext.isMatchOptionalTrailingSeparator() &&  \n\t\t\t\t\t\t\tsegmentData != null && segmentData.length() > 0 &&  \n\t\t\t\t\t\t\t(pathIndex + 1) == matchingContext.pathLength &&   \n\t\t\t\t\t\t\tmatchingContext.isSeparator(pathIndex));  \n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tif (segmentData == null || segmentData.length() == 0) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn (this.next != null && this.next.matches(pathIndex, matchingContext));\n\t\t}\n\t}", "summary_tokens": ["matching", "on", "a", "wildcard", "path", "element", "is", "quite", "straight", "forward"], "project": "spring-framework"}
{"id": 1309, "code": "\tpublic ClassName processAheadOfTime(GenericApplicationContext applicationContext,\n\t\t\tGenerationContext generationContext) {\n\t\treturn withGeneratedClassHandler(new GeneratedClassHandler(generationContext), () -> {\n\t\t\tapplicationContext.refreshForAotProcessing(generationContext.getRuntimeHints());\n\t\t\tDefaultListableBeanFactory beanFactory = applicationContext.getDefaultListableBeanFactory();\n\t\t\tApplicationContextInitializationCodeGenerator codeGenerator =\n\t\t\t\t\tnew ApplicationContextInitializationCodeGenerator(generationContext);\n\t\t\tnew BeanFactoryInitializationAotContributions(beanFactory).applyTo(generationContext, codeGenerator);\n\t\t\treturn codeGenerator.getGeneratedClass().getName();\n\t\t});\n\t}", "summary_tokens": ["process", "the", "specified", "generic", "application", "context", "ahead", "of", "time", "using", "the", "specified", "generation", "context"], "project": "spring-framework"}
{"id": 2056, "code": "\tpublic Map<String, String> getValidationPropertyMap() {\n\t\treturn this.validationPropertyMap;\n\t}", "summary_tokens": ["allow", "map", "access", "to", "the", "bean", "validation", "properties", "to", "be", "passed", "to", "the", "validation", "provider", "with", "the", "option", "to", "add", "or", "override", "specific", "entries"], "project": "spring-framework"}
{"id": 6941, "code": "\tpublic void setSerializeNulls(boolean serializeNulls) {\n\t\tthis.serializeNulls = serializeNulls;\n\t}", "summary_tokens": ["whether", "to", "use", "the", "gson", "builder", "serialize", "nulls", "option", "when", "writing", "json"], "project": "spring-framework"}
{"id": 7992, "code": "\tprotected Map<String, CorsConfiguration> getCorsConfigurations() {\n\t\tMap<String, CorsConfiguration> configs = CollectionUtils.newLinkedHashMap(this.registrations.size());\n\t\tfor (CorsRegistration registration : this.registrations) {\n\t\t\tconfigs.put(registration.getPathPattern(), registration.getCorsConfiguration());\n\t\t}\n\t\treturn configs;\n\t}", "summary_tokens": ["return", "the", "registered", "cors", "configuration", "objects", "keyed", "by", "path", "pattern"], "project": "spring-framework"}
{"id": 1503, "code": "\tpublic void removeTransformers() {\n\t\tsynchronized (this.transformers) {\n\t\t\tif (this.instrumentation != null && !this.transformers.isEmpty()) {\n\t\t\t\tfor (int i = this.transformers.size() - 1; i >= 0; i--) {\n\t\t\t\t\tthis.instrumentation.removeTransformer(this.transformers.get(i));\n\t\t\t\t}\n\t\t\t\tthis.transformers.clear();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["remove", "all", "registered", "transformers", "in", "inverse", "order", "of", "registration"], "project": "spring-framework"}
{"id": 6014, "code": "\tpublic static ResultMatcher forwardedUrl(@Nullable String expectedUrl) {\n\t\treturn result -> assertEquals(\"Forwarded URL\", expectedUrl, result.getResponse().getForwardedUrl());\n\t}", "summary_tokens": ["asserts", "the", "request", "was", "forwarded", "to", "the", "given", "url"], "project": "spring-framework"}
{"id": 2082, "code": "\tpublic void testCloneInvocationToProceedThreeTimes() throws Throwable {\n\t\tTestBean tb = new TestBean();\n\t\tProxyFactory pc = new ProxyFactory(tb);\n\t\tpc.addInterface(ITestBean.class);\n\n\t\tMethodInterceptor twoBirthdayInterceptor = mi -> {\n\t\t\t\n\t\t\t\n\t\t\tMethodInvocation clone1 = ((ReflectiveMethodInvocation) mi).invocableClone();\n\t\t\tMethodInvocation clone2 = ((ReflectiveMethodInvocation) mi).invocableClone();\n\t\t\tclone1.proceed();\n\t\t\tclone2.proceed();\n\t\t\treturn mi.proceed();\n\t\t};\n\t\t@SuppressWarnings(\"serial\")\n\t\tStaticMethodMatcherPointcutAdvisor advisor = new StaticMethodMatcherPointcutAdvisor(twoBirthdayInterceptor) {\n\t\t\t@Override\n\t\t\tpublic boolean matches(Method m, @Nullable Class<?> targetClass) {\n\t\t\t\treturn \"haveBirthday\".equals(m.getName());\n\t\t\t}\n\t\t};\n\t\tpc.addAdvisor(advisor);\n\t\tITestBean it = (ITestBean) createProxy(pc);\n\n\t\tfinal int age = 20;\n\t\tit.setAge(age);\n\t\tassertThat(it.getAge()).isEqualTo(age);\n\t\t\n\t\tassertThat(it.haveBirthday()).isEqualTo((age + 2));\n\t\t\n\t\tassertThat(it.getAge()).isEqualTo((age + 3));\n\t}", "summary_tokens": ["there", "are", "times", "when", "we", "want", "to", "call", "proceed", "twice"], "project": "spring-framework"}
{"id": 5892, "code": "\tpublic WebTestClient.BodyContentSpec isEqualTo(Object expectedValue) {\n\t\tthis.pathHelper.assertValue(this.content, expectedValue);\n\t\treturn this.bodySpec;\n\t}", "summary_tokens": ["applies", "json", "path", "expectations", "helper", "assert", "value", "string", "object"], "project": "spring-framework"}
{"id": 7008, "code": "\tpublic void setFeaturesToEnable(Object... featuresToEnable) {\n\t\tthis.builder.featuresToEnable(featuresToEnable);\n\t}", "summary_tokens": ["specify", "features", "to", "enable"], "project": "spring-framework"}
{"id": 3047, "code": "\tdefault byte[] serializeToByteArray(T object) throws IOException {\n\t\tByteArrayOutputStream out = new ByteArrayOutputStream(1024);\n\t\tserialize(object, out);\n\t\treturn out.toByteArray();\n\t}", "summary_tokens": ["turn", "an", "object", "of", "type", "t", "into", "a", "serialized", "byte", "array"], "project": "spring-framework"}
{"id": 1247, "code": "\tpublic void setScopeMetadataResolver(@Nullable ScopeMetadataResolver scopeMetadataResolver) {\n\t\tthis.scopeMetadataResolver =\n\t\t\t\t(scopeMetadataResolver != null ? scopeMetadataResolver : new AnnotationScopeMetadataResolver());\n\t}", "summary_tokens": ["set", "the", "scope", "metadata", "resolver", "to", "use", "for", "registered", "component", "classes"], "project": "spring-framework"}
{"id": 5190, "code": "\tpublic final HibernateTemplate getHibernateTemplate() {\n\t\treturn this.hibernateTemplate;\n\t}", "summary_tokens": ["return", "the", "hibernate", "template", "for", "this", "dao", "pre", "initialized", "with", "the", "session", "factory", "or", "set", "explicitly"], "project": "spring-framework"}
{"id": 8984, "code": "\tpublic static <T> T on(Class<T> controllerType) {\n\t\treturn controller(controllerType);\n\t}", "summary_tokens": ["return", "a", "mock", "controller", "instance"], "project": "spring-framework"}
{"id": 7682, "code": "\tpublic HttpHeaders getHeaders() {\n\t\tif (CollectionUtils.isEmpty(this.supportedMediaTypes) ) {\n\t\t\treturn HttpHeaders.EMPTY;\n\t\t}\n\t\tHttpHeaders headers = new HttpHeaders();\n\t\theaders.setAccept(this.supportedMediaTypes);\n\t\tif (this.method == HttpMethod.PATCH) {\n\t\t\theaders.setAcceptPatch(this.supportedMediaTypes);\n\t\t}\n\t\treturn headers;\n\t}", "summary_tokens": ["return", "http", "headers", "with", "an", "accept", "header", "that", "documents", "the", "supported", "media", "types", "if", "available", "or", "an", "empty", "instance", "otherwise"], "project": "spring-framework"}
{"id": 5316, "code": "\tprotected void marshalStaxResult(Object graph, Result staxResult) throws XmlMappingException {\n\t\tXMLStreamWriter streamWriter = StaxUtils.getXMLStreamWriter(staxResult);\n\t\tif (streamWriter != null) {\n\t\t\tmarshalXmlStreamWriter(graph, streamWriter);\n\t\t}\n\t\telse {\n\t\t\tXMLEventWriter eventWriter = StaxUtils.getXMLEventWriter(staxResult);\n\t\t\tif (eventWriter != null) {\n\t\t\t\tmarshalXmlEventWriter(graph, eventWriter);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\"StaxResult contains neither XMLStreamWriter nor XMLEventConsumer\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["template", "method", "for", "handling", "stax", "result", "s"], "project": "spring-framework"}
{"id": 8119, "code": "\tdefault void accept(RequestPredicates.Visitor visitor) {\n\t\tvisitor.unknown(this);\n\t}", "summary_tokens": ["accept", "the", "given", "visitor"], "project": "spring-framework"}
{"id": 8972, "code": "\tprotected List<HandlerMethodReturnValueHandler> getDefaultReturnValueHandlers() {\n\t\tList<HandlerMethodReturnValueHandler> handlers = new ArrayList<>();\n\n\t\t\n\t\thandlers.add(new ModelAndViewMethodReturnValueHandler());\n\t\thandlers.add(new ModelMethodProcessor());\n\t\thandlers.add(new ViewMethodReturnValueHandler());\n\t\thandlers.add(new HttpEntityMethodProcessor(\n\t\t\t\tgetMessageConverters(), this.contentNegotiationManager, this.responseBodyAdvice));\n\n\t\t\n\t\thandlers.add(new ServletModelAttributeMethodProcessor(false));\n\t\thandlers.add(new RequestResponseBodyMethodProcessor(\n\t\t\t\tgetMessageConverters(), this.contentNegotiationManager, this.responseBodyAdvice));\n\n\t\t\n\t\thandlers.add(new ViewNameMethodReturnValueHandler());\n\t\thandlers.add(new MapMethodProcessor());\n\n\t\t\n\t\tif (getCustomReturnValueHandlers() != null) {\n\t\t\thandlers.addAll(getCustomReturnValueHandlers());\n\t\t}\n\n\t\t\n\t\thandlers.add(new ServletModelAttributeMethodProcessor(true));\n\n\t\treturn handlers;\n\t}", "summary_tokens": ["return", "the", "list", "of", "return", "value", "handlers", "to", "use", "including", "built", "in", "and", "custom", "handlers", "provided", "via", "set", "return", "value", "handlers"], "project": "spring-framework"}
{"id": 957, "code": "\tpublic void setCaffeineSpec(CaffeineSpec caffeineSpec) {\n\t\tdoSetCaffeine(Caffeine.from(caffeineSpec));\n\t}", "summary_tokens": ["set", "the", "caffeine", "spec", "to", "use", "for", "building", "each", "individual", "caffeine", "cache", "instance"], "project": "spring-framework"}
{"id": 4281, "code": "\tpublic void afterPropertiesSet() {\n\t\tif (getConnectionFactory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"Property 'connectionFactory' is required\");\n\t\t}\n\t}", "summary_tokens": ["make", "sure", "the", "connection", "factory", "has", "been", "set"], "project": "spring-framework"}
{"id": 2538, "code": "Symbol addConstant(final Object value) {\n  if (value instanceof Integer) {\n    return addConstantInteger(((Integer) value).intValue());\n  } else if (value instanceof Byte) {\n    return addConstantInteger(((Byte) value).intValue());\n  } else if (value instanceof Character) {\n    return addConstantInteger(((Character) value).charValue());\n  } else if (value instanceof Short) {\n    return addConstantInteger(((Short) value).intValue());\n  } else if (value instanceof Boolean) {\n    return addConstantInteger(((Boolean) value).booleanValue() ? 1 : 0);\n  } else if (value instanceof Float) {\n    return addConstantFloat(((Float) value).floatValue());\n  } else if (value instanceof Long) {\n    return addConstantLong(((Long) value).longValue());\n  } else if (value instanceof Double) {\n    return addConstantDouble(((Double) value).doubleValue());\n  } else if (value instanceof String) {\n    return addConstantString((String) value);\n  } else if (value instanceof Type) {\n    Type type = (Type) value;\n    int typeSort = type.getSort();\n    if (typeSort == Type.OBJECT) {\n      return addConstantClass(type.getInternalName());\n    } else if (typeSort == Type.METHOD) {\n      return addConstantMethodType(type.getDescriptor());\n    } else { \n      return addConstantClass(type.getDescriptor());\n    }\n  } else if (value instanceof Handle) {\n    Handle handle = (Handle) value;\n    return addConstantMethodHandle(\n        handle.getTag(),\n        handle.getOwner(),\n        handle.getName(),\n        handle.getDesc(),\n        handle.isInterface());\n  } else if (value instanceof ConstantDynamic) {\n    ConstantDynamic constantDynamic = (ConstantDynamic) value;\n    return addConstantDynamic(\n        constantDynamic.getName(),\n        constantDynamic.getDescriptor(),\n        constantDynamic.getBootstrapMethod(),\n        constantDynamic.getBootstrapMethodArgumentsUnsafe());\n  } else {\n    throw new IllegalArgumentException(\"value \" + value);\n  }\n}", "summary_tokens": ["adds", "a", "number", "or", "string", "constant", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 7379, "code": "\tpublic void setConfigLocations(String... configLocations) {\n\t\tthrow new UnsupportedOperationException(\"StaticWebApplicationContext does not support config locations\");\n\t}", "summary_tokens": ["the", "static", "web", "application", "context", "class", "does", "not", "support", "this", "method"], "project": "spring-framework"}
{"id": 592, "code": "\tpublic String toString() {\n\t\tStringBuilder sb = new StringBuilder(64);\n\t\tint i = 0;\n\t\tfor (ParseState.Entry entry : this.state) {\n\t\t\tif (i > 0) {\n\t\t\t\tsb.append('\\n');\n\t\t\t\tfor (int j = 0; j < i; j++) {\n\t\t\t\t\tsb.append('\\t');\n\t\t\t\t}\n\t\t\t\tsb.append(\"-> \");\n\t\t\t}\n\t\t\tsb.append(entry);\n\t\t\ti++;\n\t\t}\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["returns", "a", "tree", "style", "representation", "of", "the", "current", "parse", "state"], "project": "spring-framework"}
{"id": 3090, "code": "\tprotected boolean doMatch(String pattern, @Nullable String path, boolean fullMatch,\n\t\t\t@Nullable Map<String, String> uriTemplateVariables) {\n\n\t\tif (path == null || path.startsWith(this.pathSeparator) != pattern.startsWith(this.pathSeparator)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tString[] pattDirs = tokenizePattern(pattern);\n\t\tif (fullMatch && this.caseSensitive && !isPotentialMatch(path, pattDirs)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tString[] pathDirs = tokenizePath(path);\n\t\tint pattIdxStart = 0;\n\t\tint pattIdxEnd = pattDirs.length - 1;\n\t\tint pathIdxStart = 0;\n\t\tint pathIdxEnd = pathDirs.length - 1;\n\n\t\t\n\t\twhile (pattIdxStart <= pattIdxEnd && pathIdxStart <= pathIdxEnd) {\n\t\t\tString pattDir = pattDirs[pattIdxStart];\n\t\t\tif (\"**\".equals(pattDir)) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!matchStrings(pattDir, pathDirs[pathIdxStart], uriTemplateVariables)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tpattIdxStart++;\n\t\t\tpathIdxStart++;\n\t\t}\n\n\t\tif (pathIdxStart > pathIdxEnd) {\n\t\t\t\n\t\t\tif (pattIdxStart > pattIdxEnd) {\n\t\t\t\treturn (pattern.endsWith(this.pathSeparator) == path.endsWith(this.pathSeparator));\n\t\t\t}\n\t\t\tif (!fullMatch) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tif (pattIdxStart == pattIdxEnd && pattDirs[pattIdxStart].equals(\"*\") && path.endsWith(this.pathSeparator)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tfor (int i = pattIdxStart; i <= pattIdxEnd; i++) {\n\t\t\t\tif (!pattDirs[i].equals(\"**\")) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t\telse if (pattIdxStart > pattIdxEnd) {\n\t\t\t\n\t\t\treturn false;\n\t\t}\n\t\telse if (!fullMatch && \"**\".equals(pattDirs[pattIdxStart])) {\n\t\t\t\n\t\t\treturn true;\n\t\t}\n\n\t\t\n\t\twhile (pattIdxStart <= pattIdxEnd && pathIdxStart <= pathIdxEnd) {\n\t\t\tString pattDir = pattDirs[pattIdxEnd];\n\t\t\tif (pattDir.equals(\"**\")) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (!matchStrings(pattDir, pathDirs[pathIdxEnd], uriTemplateVariables)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (pattIdxEnd == (pattDirs.length - 1)\n\t\t\t\t\t&& pattern.endsWith(this.pathSeparator) != path.endsWith(this.pathSeparator)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tpattIdxEnd--;\n\t\t\tpathIdxEnd--;\n\t\t}\n\t\tif (pathIdxStart > pathIdxEnd) {\n\t\t\t\n\t\t\tfor (int i = pattIdxStart; i <= pattIdxEnd; i++) {\n\t\t\t\tif (!pattDirs[i].equals(\"**\")) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\n\t\twhile (pattIdxStart != pattIdxEnd && pathIdxStart <= pathIdxEnd) {\n\t\t\tint patIdxTmp = -1;\n\t\t\tfor (int i = pattIdxStart + 1; i <= pattIdxEnd; i++) {\n\t\t\t\tif (pattDirs[i].equals(\"**\")) {\n\t\t\t\t\tpatIdxTmp = i;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (patIdxTmp == pattIdxStart + 1) {\n\t\t\t\t\n\t\t\t\tpattIdxStart++;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t\n\t\t\t\n\t\t\tint patLength = (patIdxTmp - pattIdxStart - 1);\n\t\t\tint strLength = (pathIdxEnd - pathIdxStart + 1);\n\t\t\tint foundIdx = -1;\n\n\t\t\tstrLoop:\n\t\t\tfor (int i = 0; i <= strLength - patLength; i++) {\n\t\t\t\tfor (int j = 0; j < patLength; j++) {\n\t\t\t\t\tString subPat = pattDirs[pattIdxStart + j + 1];\n\t\t\t\t\tString subStr = pathDirs[pathIdxStart + i + j];\n\t\t\t\t\tif (!matchStrings(subPat, subStr, uriTemplateVariables)) {\n\t\t\t\t\t\tcontinue strLoop;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfoundIdx = pathIdxStart + i;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (foundIdx == -1) {\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\tpattIdxStart = patIdxTmp;\n\t\t\tpathIdxStart = foundIdx + patLength;\n\t\t}\n\n\t\tfor (int i = pattIdxStart; i <= pattIdxEnd; i++) {\n\t\t\tif (!pattDirs[i].equals(\"**\")) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\treturn true;\n\t}", "summary_tokens": ["actually", "match", "the", "given", "path", "against", "the", "given", "pattern"], "project": "spring-framework"}
{"id": 7741, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"Clock is required\");\n\t\tthis.clock = clock;\n\t\tremoveExpiredSessions();\n\t}", "summary_tokens": ["configure", "the", "clock", "to", "use", "to", "set", "last", "access", "time", "on", "every", "created", "session", "and", "to", "calculate", "if", "it", "is", "expired"], "project": "spring-framework"}
{"id": 6888, "code": "\tdefault String name() {\n\t\tString name = headers().getContentDisposition().getName();\n\t\tAssert.state(name != null, \"No name available\");\n\t\treturn name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "event", "as", "provided", "through", "the", "content", "disposition", "name", "parameter"], "project": "spring-framework"}
{"id": 2440, "code": "final void accept(final MethodWriter methodWriter) {\n    \n    \n  int[] localTypes = inputLocals;\n  int numLocal = 0;\n  int numTrailingTop = 0;\n  int i = 0;\n  while (i < localTypes.length) {\n    int localType = localTypes[i];\n    i += (localType == LONG || localType == DOUBLE) ? 2 : 1;\n    if (localType == TOP) {\n      numTrailingTop++;\n    } else {\n      numLocal += numTrailingTop + 1;\n      numTrailingTop = 0;\n    }\n  }\n    \n  int[] stackTypes = inputStack;\n  int numStack = 0;\n  i = 0;\n  while (i < stackTypes.length) {\n    int stackType = stackTypes[i];\n    i += (stackType == LONG || stackType == DOUBLE) ? 2 : 1;\n    numStack++;\n  }\n    \n  int frameIndex = methodWriter.visitFrameStart(owner.bytecodeOffset, numLocal, numStack);\n  i = 0;\n  while (numLocal-- > 0) {\n    int localType = localTypes[i];\n    i += (localType == LONG || localType == DOUBLE) ? 2 : 1;\n    methodWriter.visitAbstractType(frameIndex++, localType);\n  }\n  i = 0;\n  while (numStack-- > 0) {\n    int stackType = stackTypes[i];\n    i += (stackType == LONG || stackType == DOUBLE) ? 2 : 1;\n    methodWriter.visitAbstractType(frameIndex++, stackType);\n  }\n  methodWriter.visitFrameEnd();\n}", "summary_tokens": ["makes", "the", "given", "method", "writer", "visit", "the", "input", "frame", "of", "this", "frame"], "project": "spring-framework"}
{"id": 980, "code": "\tprotected StringBuilder getOperationDescription() {\n\t\tStringBuilder result = new StringBuilder();\n\t\tresult.append(getClass().getSimpleName());\n\t\tresult.append('[');\n\t\tresult.append(this.methodDetails);\n\t\treturn result;\n\t}", "summary_tokens": ["return", "an", "identifying", "description", "for", "this", "caching", "operation"], "project": "spring-framework"}
{"id": 6721, "code": "\tpublic void setInstance(@Nullable URI instance) {\n\t\tthis.instance = instance;\n\t}", "summary_tokens": ["setter", "for", "the", "get", "instance", "problem", "instance"], "project": "spring-framework"}
{"id": 6727, "code": "\tpublic URI getInstance() {\n\t\treturn this.instance;\n\t}", "summary_tokens": ["return", "the", "configured", "set", "instance", "uri", "problem", "instance"], "project": "spring-framework"}
{"id": 1002, "code": "\tpublic void setCacheOperationSource(JCacheOperationSource cacheOperationSource) {\n\t\tAssert.notNull(cacheOperationSource, \"JCacheOperationSource must not be null\");\n\t\tthis.cacheOperationSource = cacheOperationSource;\n\t}", "summary_tokens": ["set", "the", "cache", "operation", "source", "for", "this", "cache", "aspect"], "project": "spring-framework"}
{"id": 4338, "code": "\tpublic void setDeliveryMode(int deliveryMode) {\n\t\tthis.deliveryMode = deliveryMode;\n\t}", "summary_tokens": ["set", "the", "delivery", "mode", "to", "use", "when", "sending", "a", "message"], "project": "spring-framework"}
{"id": 8308, "code": "\tprotected boolean isHandler(Class<?> beanType) {\n\t\treturn AnnotatedElementUtils.hasAnnotation(beanType, Controller.class);\n\t}", "summary_tokens": ["expects", "a", "handler", "to", "have", "a", "type", "level", "controller", "annotation"], "project": "spring-framework"}
{"id": 233, "code": "\tpublic static Pointcut intersection(Pointcut pc1, Pointcut pc2) {\n\t\treturn new ComposablePointcut(pc1).intersection(pc2);\n\t}", "summary_tokens": ["match", "all", "methods", "that", "b", "both", "b", "the", "given", "pointcuts", "match"], "project": "spring-framework"}
{"id": 8764, "code": "\tdefault Optional<String> param(String name) {\n\t\tList<String> paramValues = params().get(name);\n\t\tif (CollectionUtils.isEmpty(paramValues)) {\n\t\t\treturn Optional.empty();\n\t\t}\n\t\telse {\n\t\t\tString value = paramValues.get(0);\n\t\t\tif (value == null) {\n\t\t\t\tvalue = \"\";\n\t\t\t}\n\t\t\treturn Optional.of(value);\n\t\t}\n\t}", "summary_tokens": ["get", "the", "first", "parameter", "with", "the", "given", "name", "if", "present"], "project": "spring-framework"}
{"id": 9689, "code": "\tprotected ClassLoader createTemplateClassLoader() throws IOException {\n\t\tString[] paths = StringUtils.commaDelimitedListToStringArray(getResourceLoaderPath());\n\t\tList<URL> urls = new ArrayList<>();\n\t\tfor (String path : paths) {\n\t\t\tResource[] resources = getApplicationContext().getResources(path);\n\t\t\tif (resources.length > 0) {\n\t\t\t\tfor (Resource resource : resources) {\n\t\t\t\t\tif (resource.exists()) {\n\t\t\t\t\t\turls.add(resource.getURL());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tClassLoader classLoader = getApplicationContext().getClassLoader();\n\t\tAssert.state(classLoader != null, \"No ClassLoader\");\n\t\treturn (!urls.isEmpty() ? new URLClassLoader(urls.toArray(new URL[0]), classLoader) : classLoader);\n\t}", "summary_tokens": ["create", "a", "parent", "class", "loader", "for", "groovy", "to", "use", "as", "parent", "class", "loader", "when", "loading", "and", "compiling", "templates"], "project": "spring-framework"}
{"id": 5328, "code": "\tpublic static InputSource createInputSource(Resource resource) throws IOException {\n\t\tInputSource inputSource = new InputSource(resource.getInputStream());\n\t\tinputSource.setSystemId(getSystemId(resource));\n\t\treturn inputSource;\n\t}", "summary_tokens": ["create", "a", "sax", "input", "source", "from", "the", "given", "resource"], "project": "spring-framework"}
{"id": 9842, "code": "\tpublic Map<String, SubProtocolHandler> getProtocolHandlerMap() {\n\t\treturn this.protocolHandlerLookup;\n\t}", "summary_tokens": ["return", "the", "sub", "protocols", "keyed", "by", "protocol", "name"], "project": "spring-framework"}
{"id": 8983, "code": "\tpublic static UriComponentsBuilder fromMethodCall(UriComponentsBuilder builder, Object info) {\n\t\tAssert.isInstanceOf(MethodInvocationInfo.class, info, \"MethodInvocationInfo required\");\n\t\tMethodInvocationInfo invocationInfo = (MethodInvocationInfo) info;\n\t\tClass<?> controllerType = invocationInfo.getControllerType();\n\t\tMethod method = invocationInfo.getControllerMethod();\n\t\tObject[] arguments = invocationInfo.getArgumentValues();\n\t\treturn fromMethodInternal(builder, controllerType, method, arguments);\n\t}", "summary_tokens": ["an", "alternative", "to", "from", "method", "call", "object", "that", "accepts", "a", "uri", "components", "builder", "representing", "the", "base", "url"], "project": "spring-framework"}
{"id": 2720, "code": "\tprotected Class<?> loadClassForOverriding(String name) throws ClassNotFoundException {\n\t\tClass<?> result = findLoadedClass(name);\n\t\tif (result == null) {\n\t\t\tbyte[] bytes = loadBytesForClass(name);\n\t\t\tif (bytes != null) {\n\t\t\t\tresult = defineClass(name, bytes, 0, bytes.length);\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["load", "the", "specified", "class", "for", "overriding", "purposes", "in", "this", "class", "loader"], "project": "spring-framework"}
{"id": 120, "code": "\tprotected List<Advisor> sortAdvisors(List<Advisor> advisors) {\n\t\tAnnotationAwareOrderComparator.sort(advisors);\n\t\treturn advisors;\n\t}", "summary_tokens": ["sort", "advisors", "based", "on", "ordering"], "project": "spring-framework"}
{"id": 6220, "code": "\tpublic void setWorkManager(WorkManager workManager) {\n\t\tthis.workManager = workManager;\n\t}", "summary_tokens": ["specify", "the", "jca", "work", "manager", "to", "use", "for", "bootstrapping", "the", "resource", "adapter"], "project": "spring-framework"}
{"id": 8784, "code": "\tpublic void setAsyncRequestTimeout(long timeout) {\n\t\tthis.asyncRequestTimeout = timeout;\n\t}", "summary_tokens": ["specify", "the", "amount", "of", "time", "in", "milliseconds", "before", "concurrent", "handling", "should", "time", "out"], "project": "spring-framework"}
{"id": 770, "code": "\tpublic AutowireCandidateResolver cloneIfNecessary() {\n\t\treturn this;\n\t}", "summary_tokens": ["this", "implementation", "returns", "this", "as", "is"], "project": "spring-framework"}
{"id": 6616, "code": "\tpublic String getHeaderValue() {\n\t\tString headerValue = toHeaderValue();\n\t\treturn (StringUtils.hasText(headerValue) ? headerValue : null);\n\t}", "summary_tokens": ["return", "the", "cache", "control", "header", "value", "if", "any"], "project": "spring-framework"}
{"id": 3397, "code": "\tpublic long toGigabytes() {\n\t\treturn this.bytes / BYTES_PER_GB;\n\t}", "summary_tokens": ["return", "the", "number", "of", "gigabytes", "in", "this", "instance"], "project": "spring-framework"}
{"id": 9451, "code": "\tprotected String getItemLabel() {\n\t\treturn this.itemLabel;\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "property", "mapped", "to", "the", "label", "inner", "text", "of", "the", "option", "tag"], "project": "spring-framework"}
{"id": 2503, "code": "void visitFrameEnd() {\n  if (previousFrame != null) {\n    if (stackMapTableEntries == null) {\n      stackMapTableEntries = new ByteVector();\n    }\n    putFrame();\n    ++stackMapTableNumberOfEntries;\n  }\n  previousFrame = currentFrame;\n  currentFrame = null;\n}", "summary_tokens": ["ends", "the", "visit", "of", "current", "frame", "by", "writing", "it", "in", "the", "stack", "map", "table", "entries", "and", "by", "updating", "the", "stack", "map", "table", "number", "of", "entries", "except", "if", "the", "current", "frame", "is", "the", "first", "one", "which", "is", "implicit", "in", "stack", "map", "table"], "project": "spring-framework"}
{"id": 5345, "code": "\tprotected boolean hasConnection() {\n\t\treturn (this.currentConnection != null);\n\t}", "summary_tokens": ["return", "whether", "this", "holder", "currently", "has", "a", "connection"], "project": "spring-framework"}
{"id": 1205, "code": "\tdefault boolean isCandidateClass(Class<?> targetClass) {\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "class", "is", "a", "candidate", "for", "cache", "operations", "in", "the", "metadata", "format", "of", "this", "cache", "operation", "source"], "project": "spring-framework"}
{"id": 8329, "code": "\tprotected final ApplicationContext obtainApplicationContext() {\n\t\tApplicationContext applicationContext = getApplicationContext();\n\t\tAssert.state(applicationContext != null, \"No ApplicationContext\");\n\t\treturn applicationContext;\n\t}", "summary_tokens": ["obtain", "the", "application", "context", "for", "actual", "use"], "project": "spring-framework"}
{"id": 2926, "code": "\tpublic int hashCode() {\n\t\treturn Arrays.hashCode(this.byteArray);\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "hash", "code", "based", "on", "the", "underlying", "byte", "array"], "project": "spring-framework"}
{"id": 9109, "code": "\tprivate String[] initErrorMessages() throws NoSuchMessageException {\n\t\tif (this.errorMessages == null) {\n\t\t\tif (this.objectErrors != null) {\n\t\t\t\tthis.errorMessages = new String[this.objectErrors.size()];\n\t\t\t\tfor (int i = 0; i < this.objectErrors.size(); i++) {\n\t\t\t\t\tObjectError error = this.objectErrors.get(i);\n\t\t\t\t\tthis.errorMessages[i] = this.requestContext.getMessage(error, this.htmlEscape);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.errorMessages = new String[0];\n\t\t\t}\n\t\t}\n\t\treturn this.errorMessages;\n\t}", "summary_tokens": ["extract", "the", "error", "messages", "from", "the", "object", "error", "list"], "project": "spring-framework"}
{"id": 449, "code": "\tpublic CodeBlock generateReturnCode(\n\t\t\tGenerationContext generationContext, BeanRegistrationCode beanRegistrationCode) {\n\n\t\treturn this.codeFragments.generateReturnCode(generationContext, beanRegistrationCode);\n\t}", "summary_tokens": ["generate", "the", "return", "statement"], "project": "spring-framework"}
{"id": 5163, "code": "\tpublic void setAnnotatedClasses(Class<?>... annotatedClasses) {\n\t\tthis.annotatedClasses = annotatedClasses;\n\t}", "summary_tokens": ["specify", "annotated", "entity", "classes", "to", "register", "with", "this", "hibernate", "session", "factory"], "project": "spring-framework"}
{"id": 2242, "code": "\tpublic InputStreamSource getGeneratedFile(Kind kind, String path) {\n\t\tAssert.notNull(kind, \"'kind' must not be null\");\n\t\tAssert.hasLength(path, \"'path' must not be empty\");\n\t\tMap<String, InputStreamSource> paths = this.files.get(kind);\n\t\treturn (paths != null) ? paths.get(path) : null;\n\t}", "summary_tokens": ["return", "the", "input", "stream", "source", "of", "specified", "file"], "project": "spring-framework"}
{"id": 7190, "code": "\tpublic boolean isBindEmptyMultipartFiles() {\n\t\treturn this.bindEmptyMultipartFiles;\n\t}", "summary_tokens": ["return", "whether", "to", "bind", "empty", "multipart", "file", "parameters"], "project": "spring-framework"}
{"id": 659, "code": "\tpublic String getDestroyMethodName() {\n\t\treturn this.destroyMethodName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "default", "destroy", "method"], "project": "spring-framework"}
{"id": 596, "code": "\tpublic String getResourceDescription() {\n\t\treturn getLocation().getResource().getDescription();\n\t}", "summary_tokens": ["get", "the", "description", "of", "the", "bean", "configuration", "source", "that", "triggered", "the", "error", "as", "contained", "within", "this", "problem", "s", "location", "object"], "project": "spring-framework"}
{"id": 7267, "code": "\tprotected final ExternalContext getExternalContext() {\n\t\treturn getFacesContext().getExternalContext();\n\t}", "summary_tokens": ["return", "the", "jsf", "external", "context", "that", "this", "adapter", "operates", "on"], "project": "spring-framework"}
{"id": 804, "code": "\tpublic NamespaceHandler resolve(String namespaceUri) {\n\t\tMap<String, Object> handlerMappings = getHandlerMappings();\n\t\tObject handlerOrClassName = handlerMappings.get(namespaceUri);\n\t\tif (handlerOrClassName == null) {\n\t\t\treturn null;\n\t\t}\n\t\telse if (handlerOrClassName instanceof NamespaceHandler) {\n\t\t\treturn (NamespaceHandler) handlerOrClassName;\n\t\t}\n\t\telse {\n\t\t\tString className = (String) handlerOrClassName;\n\t\t\ttry {\n\t\t\t\tClass<?> handlerClass = ClassUtils.forName(className, this.classLoader);\n\t\t\t\tif (!NamespaceHandler.class.isAssignableFrom(handlerClass)) {\n\t\t\t\t\tthrow new FatalBeanException(\"Class [\" + className + \"] for namespace [\" + namespaceUri +\n\t\t\t\t\t\t\t\"] does not implement the [\" + NamespaceHandler.class.getName() + \"] interface\");\n\t\t\t\t}\n\t\t\t\tNamespaceHandler namespaceHandler = (NamespaceHandler) BeanUtils.instantiateClass(handlerClass);\n\t\t\t\tnamespaceHandler.init();\n\t\t\t\thandlerMappings.put(namespaceUri, namespaceHandler);\n\t\t\t\treturn namespaceHandler;\n\t\t\t}\n\t\t\tcatch (ClassNotFoundException ex) {\n\t\t\t\tthrow new FatalBeanException(\"Could not find NamespaceHandler class [\" + className +\n\t\t\t\t\t\t\"] for namespace [\" + namespaceUri + \"]\", ex);\n\t\t\t}\n\t\t\tcatch (LinkageError err) {\n\t\t\t\tthrow new FatalBeanException(\"Unresolvable class definition for NamespaceHandler class [\" +\n\t\t\t\t\t\tclassName + \"] for namespace [\" + namespaceUri + \"]\", err);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["locate", "the", "namespace", "handler", "for", "the", "supplied", "namespace", "uri", "from", "the", "configured", "mappings"], "project": "spring-framework"}
{"id": 9088, "code": "\tpublic void setFlashMapTimeout(int flashMapTimeout) {\n\t\tthis.flashMapTimeout = flashMapTimeout;\n\t}", "summary_tokens": ["set", "the", "amount", "of", "time", "in", "seconds", "after", "a", "flash", "map", "is", "saved", "at", "request", "completion", "and", "before", "it", "expires"], "project": "spring-framework"}
{"id": 7970, "code": "\tpublic MethodParameter getReturnTypeSource() {\n\t\treturn (MethodParameter) this.returnType.getSource();\n\t}", "summary_tokens": ["return", "the", "method", "parameter", "from", "which", "get", "return", "type", "return", "type", "was", "created"], "project": "spring-framework"}
{"id": 1364, "code": "\tprotected String[] getDefaultConfigLocations() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "default", "config", "locations", "to", "use", "for", "the", "case", "where", "no", "explicit", "config", "locations", "have", "been", "specified"], "project": "spring-framework"}
{"id": 2608, "code": "public int getTryCatchBlockIndex() {\n  return (targetTypeAndInfo & 0x00FFFF00) >> 8;\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "try", "catch", "block", "using", "the", "order", "in", "which", "they", "are", "visited", "with", "visit", "try", "catch", "block", "whose", "catch", "type", "is", "referenced", "by", "this", "type", "reference"], "project": "spring-framework"}
{"id": 5360, "code": "\tpublic Mono<Connection> create() {\n\t\treturn getTransactionAwareConnectionProxy(getTargetConnectionFactory());\n\t}", "summary_tokens": ["delegates", "to", "connection", "factory", "utils", "for", "automatically", "participating", "in", "spring", "managed", "transactions"], "project": "spring-framework"}
{"id": 9411, "code": "\tprotected String getAlt() {\n\t\treturn this.alt;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "alt", "attribute"], "project": "spring-framework"}
{"id": 3469, "code": "\tprotected final Consumer<DataBuffer> expectBytes(byte[] expected) {\n\t\treturn dataBuffer -> {\n\t\t\tbyte[] resultBytes = new byte[dataBuffer.readableByteCount()];\n\t\t\tdataBuffer.read(resultBytes);\n\t\t\trelease(dataBuffer);\n\t\t\tassertThat(resultBytes).isEqualTo(expected);\n\t\t};\n\t}", "summary_tokens": ["create", "a", "result", "consumer", "that", "expects", "the", "given", "bytes"], "project": "spring-framework"}
{"id": 4762, "code": "\tpublic void clear() {\n\t\tthis.argumentResolvers.clear();\n\t\tthis.argumentResolverCache.clear();\n\t}", "summary_tokens": ["clear", "the", "list", "of", "configured", "resolvers", "and", "the", "resolver", "cache"], "project": "spring-framework"}
{"id": 4710, "code": "\tprotected final void detectHandlerMethods(final Object handler) {\n\t\tClass<?> handlerType;\n\t\tif (handler instanceof String) {\n\t\t\tApplicationContext context = getApplicationContext();\n\t\t\tAssert.state(context != null, \"ApplicationContext is required for resolving handler bean names\");\n\t\t\thandlerType = context.getType((String) handler);\n\t\t}\n\t\telse {\n\t\t\thandlerType = handler.getClass();\n\t\t}\n\n\t\tif (handlerType != null) {\n\t\t\tfinal Class<?> userType = ClassUtils.getUserClass(handlerType);\n\t\t\tMap<Method, T> methods = MethodIntrospector.selectMethods(userType,\n\t\t\t\t\t(MethodIntrospector.MetadataLookup<T>) method -> getMappingForMethod(method, userType));\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(formatMappings(userType, methods));\n\t\t\t}\n\t\t\tmethods.forEach((key, value) -> registerHandlerMethod(handler, key, value));\n\t\t}\n\t}", "summary_tokens": ["detect", "if", "the", "given", "handler", "has", "any", "methods", "that", "can", "handle", "messages", "and", "if", "so", "register", "it", "with", "the", "extracted", "mapping", "information"], "project": "spring-framework"}
{"id": 6979, "code": "\tpublic Jackson2ObjectMapperBuilder applicationContext(ApplicationContext applicationContext) {\n\t\tthis.applicationContext = applicationContext;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "spring", "application", "context", "in", "order", "to", "autowire", "jackson", "handlers", "json", "serializer", "json", "deserializer", "key", "deserializer", "type", "resolver", "builder", "and", "type", "id", "resolver"], "project": "spring-framework"}
{"id": 6613, "code": "\tpublic CacheControl sMaxAge(Duration sMaxAge) {\n\t\tthis.sMaxAge = sMaxAge;\n\t\treturn this;\n\t}", "summary_tokens": ["add", "an", "s", "maxage", "directive"], "project": "spring-framework"}
{"id": 5367, "code": "\tpublic void setEnabled(boolean enabled) {\n\t\tthis.enabled = enabled;\n\t}", "summary_tokens": ["flag", "to", "explicitly", "enable", "or", "disable", "the", "set", "database", "populator", "database", "populator", "and", "set", "database", "cleaner", "database", "cleaner"], "project": "spring-framework"}
{"id": 8586, "code": "\tpublic ContentNegotiationConfigurer defaultContentTypeStrategy(ContentNegotiationStrategy defaultStrategy) {\n\t\tthis.factory.setDefaultContentTypeStrategy(defaultStrategy);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "a", "custom", "content", "negotiation", "strategy", "to", "use", "to", "determine", "the", "content", "type", "to", "use", "when", "no", "content", "type", "is", "requested"], "project": "spring-framework"}
{"id": 9901, "code": "\tpublic TaskScheduler getTaskScheduler() {\n\t\treturn this.taskScheduler;\n\t}", "summary_tokens": ["a", "scheduler", "instance", "to", "use", "for", "scheduling", "heart", "beat", "messages"], "project": "spring-framework"}
{"id": 5306, "code": "\tpublic boolean isSupportDtd() {\n\t\treturn this.supportDtd;\n\t}", "summary_tokens": ["return", "whether", "dtd", "parsing", "is", "supported"], "project": "spring-framework"}
{"id": 1156, "code": "\tprotected TemplateLoader getTemplateLoaderForPath(String templateLoaderPath) {\n\t\tif (isPreferFileSystemAccess()) {\n\t\t\t\n\t\t\t\n\t\t\ttry {\n\t\t\t\tResource path = getResourceLoader().getResource(templateLoaderPath);\n\t\t\t\tFile file = path.getFile();  \n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\n\t\t\t\t\t\t\t\"Template loader path [\" + path + \"] resolved to file path [\" + file.getAbsolutePath() + \"]\");\n\t\t\t\t}\n\t\t\t\treturn new FileTemplateLoader(file);\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Cannot resolve template loader path [\" + templateLoaderPath +\n\t\t\t\t\t\t\t\"] to [java.io.File]: using SpringTemplateLoader as fallback\", ex);\n\t\t\t\t}\n\t\t\t\treturn new SpringTemplateLoader(getResourceLoader(), templateLoaderPath);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tlogger.debug(\"File system access not preferred: using SpringTemplateLoader\");\n\t\t\treturn new SpringTemplateLoader(getResourceLoader(), templateLoaderPath);\n\t\t}\n\t}", "summary_tokens": ["determine", "a", "free", "marker", "template", "loader", "for", "the", "given", "path"], "project": "spring-framework"}
{"id": 5874, "code": "\tpublic Flux<T> getResponseBody() {\n\t\treturn this.body;\n\t}", "summary_tokens": ["return", "the", "response", "body", "as", "a", "flux", "t", "of", "decoded", "elements"], "project": "spring-framework"}
{"id": 6439, "code": "\tpublic final void setRollbackOnCommitFailure(boolean rollbackOnCommitFailure) {\n\t\tthis.rollbackOnCommitFailure = rollbackOnCommitFailure;\n\t}", "summary_tokens": ["set", "whether", "do", "rollback", "should", "be", "performed", "on", "failure", "of", "the", "do", "commit", "call"], "project": "spring-framework"}
{"id": 9791, "code": "\tpublic SockJsServiceRegistration setStreamBytesLimit(int streamBytesLimit) {\n\t\tthis.streamBytesLimit = streamBytesLimit;\n\t\treturn this;\n\t}", "summary_tokens": ["streaming", "transports", "save", "responses", "on", "the", "client", "side", "and", "don", "t", "free", "memory", "used", "by", "delivered", "messages"], "project": "spring-framework"}
{"id": 8986, "code": "\tpublic static MethodArgumentBuilder fromMappingName(@Nullable UriComponentsBuilder builder, String name) {\n\t\tWebApplicationContext wac = getWebApplicationContext();\n\t\tAssert.notNull(wac, \"No WebApplicationContext. \");\n\t\tMap<String, RequestMappingInfoHandlerMapping> map = wac.getBeansOfType(RequestMappingInfoHandlerMapping.class);\n\t\tList<HandlerMethod> handlerMethods = null;\n\t\tfor (RequestMappingInfoHandlerMapping mapping : map.values()) {\n\t\t\thandlerMethods = mapping.getHandlerMethodsForMappingName(name);\n\t\t\tif (handlerMethods != null) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (handlerMethods == null) {\n\t\t\tthrow new IllegalArgumentException(\"Mapping not found: \" + name);\n\t\t}\n\t\telse if (handlerMethods.size() != 1) {\n\t\t\tthrow new IllegalArgumentException(\"No unique match for mapping \" + name + \": \" + handlerMethods);\n\t\t}\n\t\telse {\n\t\t\tHandlerMethod handlerMethod = handlerMethods.get(0);\n\t\t\tClass<?> controllerType = handlerMethod.getBeanType();\n\t\t\tMethod method = handlerMethod.getMethod();\n\t\t\treturn new MethodArgumentBuilder(builder, controllerType, method);\n\t\t}\n\t}", "summary_tokens": ["an", "alternative", "to", "from", "mapping", "name", "string", "that", "accepts", "a", "uri", "components", "builder", "representing", "the", "base", "url"], "project": "spring-framework"}
{"id": 4049, "code": "\tpublic static void splitSqlScript(@Nullable EncodedResource resource, String script,\n\t\t\tString separator, String[] commentPrefixes, String blockCommentStartDelimiter,\n\t\t\tString blockCommentEndDelimiter, List<String> statements) throws ScriptException {\n\n\t\tAssert.hasText(script, \"'script' must not be null or empty\");\n\t\tAssert.notNull(separator, \"'separator' must not be null\");\n\t\tAssert.notEmpty(commentPrefixes, \"'commentPrefixes' must not be null or empty\");\n\t\tfor (String commentPrefix : commentPrefixes) {\n\t\t\tAssert.hasText(commentPrefix, \"'commentPrefixes' must not contain null or empty elements\");\n\t\t}\n\t\tAssert.hasText(blockCommentStartDelimiter, \"'blockCommentStartDelimiter' must not be null or empty\");\n\t\tAssert.hasText(blockCommentEndDelimiter, \"'blockCommentEndDelimiter' must not be null or empty\");\n\n\t\tStringBuilder sb = new StringBuilder();\n\t\tboolean inSingleQuote = false;\n\t\tboolean inDoubleQuote = false;\n\t\tboolean inEscape = false;\n\n\t\tfor (int i = 0; i < script.length(); i++) {\n\t\t\tchar c = script.charAt(i);\n\t\t\tif (inEscape) {\n\t\t\t\tinEscape = false;\n\t\t\t\tsb.append(c);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t\n\t\t\tif (c == '\\\\') {\n\t\t\t\tinEscape = true;\n\t\t\t\tsb.append(c);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!inDoubleQuote && (c == '\\'')) {\n\t\t\t\tinSingleQuote = !inSingleQuote;\n\t\t\t}\n\t\t\telse if (!inSingleQuote && (c == '\"')) {\n\t\t\t\tinDoubleQuote = !inDoubleQuote;\n\t\t\t}\n\t\t\tif (!inSingleQuote && !inDoubleQuote) {\n\t\t\t\tif (script.startsWith(separator, i)) {\n\t\t\t\t\t// We've reached the end of the current statement\n\t\t\t\t\tif (sb.length() > 0) {\n\t\t\t\t\t\tstatements.add(sb.toString());\n\t\t\t\t\t\tsb = new StringBuilder();\n\t\t\t\t\t}\n\t\t\t\t\ti += separator.length() - 1;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\telse if (startsWithAny(script, commentPrefixes, i)) {\n\t\t\t\t\t// Skip over any content from the start of the comment to the EOL\n\t\t\t\t\tint indexOfNextNewline = script.indexOf('\\n', i);\n\t\t\t\t\tif (indexOfNextNewline > i) {\n\t\t\t\t\t\ti = indexOfNextNewline;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\t// If there's no EOL, we must be at the end of the script, so stop here.\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (script.startsWith(blockCommentStartDelimiter, i)) {\n\t\t\t\t\t// Skip over any block comments\n\t\t\t\t\tint indexOfCommentEnd = script.indexOf(blockCommentEndDelimiter, i);\n\t\t\t\t\tif (indexOfCommentEnd > i) {\n\t\t\t\t\t\ti = indexOfCommentEnd + blockCommentEndDelimiter.length() - 1;\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tthrow new ScriptParseException(\n\t\t\t\t\t\t\t\t\"Missing block comment end delimiter: \" + blockCommentEndDelimiter, resource);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (c == ' ' || c == '\\r' || c == '\\n' || c == '\\t') {\n\t\t\t\t\t\n\t\t\t\t\tif (sb.length() > 0 && sb.charAt(sb.length() - 1) != ' ') {\n\t\t\t\t\t\tc = ' ';\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tsb.append(c);\n\t\t}\n\n\t\tif (StringUtils.hasText(sb)) {\n\t\t\tstatements.add(sb.toString());\n\t\t}\n\t}", "summary_tokens": ["split", "an", "sql", "script", "into", "separate", "statements", "delimited", "by", "the", "provided", "separator", "string"], "project": "spring-framework"}
{"id": 8405, "code": "\tpublic void setConfiguration(@Nullable Configuration configuration) {\n\t\tthis.configuration = configuration;\n\t}", "summary_tokens": ["set", "the", "free", "marker", "configuration", "to", "be", "used", "by", "this", "view"], "project": "spring-framework"}
{"id": 8173, "code": "\tpublic RouterFunction<?> getRouterFunction() {\n\t\treturn this.routerFunction;\n\t}", "summary_tokens": ["return", "the", "configured", "router", "function"], "project": "spring-framework"}
{"id": 1617, "code": "\tprivate boolean hasManagedAttribute(Method method) {\n\t\treturn (obtainAttributeSource().getManagedAttribute(method) != null);\n\t}", "summary_tokens": ["checks", "to", "see", "if", "the", "given", "method", "has", "the", "managed", "attribute", "attribute"], "project": "spring-framework"}
{"id": 3512, "code": "\tpublic static String toDescriptorFromObject(@Nullable Object value) {\n\t\tif (value == null) {\n\t\t\treturn \"Ljava/lang/Object\";\n\t\t}\n\t\telse {\n\t\t\treturn toDescriptor(value.getClass());\n\t\t}\n\t}", "summary_tokens": ["determine", "the", "descriptor", "for", "an", "object", "instance", "or", "null"], "project": "spring-framework"}
{"id": 2184, "code": "\tpublic SourceFile getSourceFileFromPackage(String packageName) {\n\t\treturn this.sourceFiles.getSingleFromPackage(packageName);\n\t}", "summary_tokens": ["return", "the", "single", "source", "file", "that", "was", "compiled", "in", "the", "given", "package"], "project": "spring-framework"}
{"id": 2101, "code": "\tvoid initMethodThrowsException() {\n\t\tDefaultListableBeanFactory xbf = new DefaultListableBeanFactory();\n\t\tnew XmlBeanDefinitionReader(xbf).loadBeanDefinitions(INITIALIZERS_CONTEXT);\n\t\tassertThatExceptionOfType(BeanCreationException.class).isThrownBy(() ->\n\t\t\t\txbf.getBean(\"init-method2\"))\n\t\t\t.withCauseInstanceOf(IOException.class)\n\t\t\t.satisfies(ex -> {\n\t\t\t\tassertThat(ex.getResourceDescription()).contains(\"initializers.xml\");\n\t\t\t\tassertThat(ex.getBeanName()).isEqualTo(\"init-method2\");\n\t\t\t});\n\t}", "summary_tokens": ["test", "that", "if", "a", "custom", "initializer", "throws", "an", "exception", "it", "s", "handled", "correctly"], "project": "spring-framework"}
{"id": 6699, "code": "\tpublic List<String> getValuesAsList(String headerName) {\n\t\tList<String> values = get(headerName);\n\t\tif (values != null) {\n\t\t\tList<String> result = new ArrayList<>();\n\t\t\tfor (String value : values) {\n\t\t\t\tif (value != null) {\n\t\t\t\t\tCollections.addAll(result, StringUtils.tokenizeToStringArray(value, \",\"));\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\treturn Collections.emptyList();\n\t}", "summary_tokens": ["return", "all", "values", "of", "a", "given", "header", "name", "even", "if", "this", "header", "is", "set", "multiple", "times"], "project": "spring-framework"}
{"id": 3311, "code": "\tpublic static boolean endsWithIgnoreCase(@Nullable String str, @Nullable String suffix) {\n\t\treturn (str != null && suffix != null && str.length() >= suffix.length() &&\n\t\t\t\tstr.regionMatches(true, str.length() - suffix.length(), suffix, 0, suffix.length()));\n\t}", "summary_tokens": ["test", "if", "the", "given", "string", "ends", "with", "the", "specified", "suffix", "ignoring", "upper", "lower", "case"], "project": "spring-framework"}
{"id": 9874, "code": "\tpublic String[] getSupportedProtocols() {\n\t\treturn StringUtils.toStringArray(this.supportedProtocols);\n\t}", "summary_tokens": ["return", "the", "list", "of", "supported", "sub", "protocols"], "project": "spring-framework"}
{"id": 6639, "code": "\tpublic List<String> getAccessControlExposeHeaders() {\n\t\treturn getValuesAsList(ACCESS_CONTROL_EXPOSE_HEADERS);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "access", "control", "expose", "headers", "response", "header"], "project": "spring-framework"}
{"id": 3562, "code": "\tprivate SpelNodeImpl eatPossiblyQualifiedId() {\n\t\tDeque<SpelNodeImpl> qualifiedIdPieces = new ArrayDeque<>();\n\t\tToken node = peekToken();\n\t\twhile (isValidQualifiedId(node)) {\n\t\t\tnextToken();\n\t\t\tif (node.kind != TokenKind.DOT) {\n\t\t\t\tqualifiedIdPieces.add(new Identifier(node.stringValue(), node.startPos, node.endPos));\n\t\t\t}\n\t\t\tnode = peekToken();\n\t\t}\n\t\tif (qualifiedIdPieces.isEmpty()) {\n\t\t\tif (node == null) {\n\t\t\t\tthrow internalException( this.expressionString.length(), SpelMessage.OOD);\n\t\t\t}\n\t\t\tthrow internalException(node.startPos, SpelMessage.NOT_EXPECTED_TOKEN,\n\t\t\t\t\t\"qualified ID\", node.getKind().toString().toLowerCase());\n\t\t}\n\t\treturn new QualifiedIdentifier(qualifiedIdPieces.getFirst().getStartPosition(),\n\t\t\t\tqualifiedIdPieces.getLast().getEndPosition(), qualifiedIdPieces.toArray(new SpelNodeImpl[0]));\n\t}", "summary_tokens": ["eat", "an", "identifier", "possibly", "qualified", "meaning", "that", "it", "is", "dotted"], "project": "spring-framework"}
{"id": 152, "code": "\tpublic void setUsePrefix(boolean usePrefix) {\n\t\tthis.usePrefix = usePrefix;\n\t}", "summary_tokens": ["set", "whether", "to", "only", "include", "advisors", "with", "a", "certain", "prefix", "in", "the", "bean", "name"], "project": "spring-framework"}
{"id": 8698, "code": "\tprotected final List<HttpMessageConverter<?>> getMessageConverters() {\n\t\tif (this.messageConverters == null) {\n\t\t\tthis.messageConverters = new ArrayList<>();\n\t\t\tconfigureMessageConverters(this.messageConverters);\n\t\t\tif (this.messageConverters.isEmpty()) {\n\t\t\t\taddDefaultHttpMessageConverters(this.messageConverters);\n\t\t\t}\n\t\t\textendMessageConverters(this.messageConverters);\n\t\t}\n\t\treturn this.messageConverters;\n\t}", "summary_tokens": ["provides", "access", "to", "the", "shared", "http", "message", "converter", "http", "message", "converters", "used", "by", "the", "request", "mapping", "handler", "adapter", "and", "the", "exception", "handler", "exception", "resolver"], "project": "spring-framework"}
{"id": 588, "code": "\tpublic void push(Entry entry) {\n\t\tthis.state.push(entry);\n\t}", "summary_tokens": ["add", "a", "new", "entry", "to", "the", "array", "deque"], "project": "spring-framework"}
{"id": 1643, "code": "\tpublic void setCategory(@Nullable String category) {\n\t\tthis.category = category;\n\t}", "summary_tokens": ["the", "category", "of", "this", "metric", "ex"], "project": "spring-framework"}
{"id": 4963, "code": "\tpublic Stats getStats() {\n\t\treturn this.stats;\n\t}", "summary_tokens": ["return", "a", "structured", "object", "with", "internal", "state", "and", "counters"], "project": "spring-framework"}
{"id": 946, "code": "\tpublic void setSingleton(boolean singleton) {\n\t\tthis.singleton = singleton;\n\t}", "summary_tokens": ["set", "if", "the", "bean", "managed", "by", "this", "factory", "is", "a", "singleton"], "project": "spring-framework"}
{"id": 5247, "code": "\tpublic void setDefaultDataSource(@Nullable DataSource defaultDataSource) {\n\t\tthis.defaultDataSource = defaultDataSource;\n\t}", "summary_tokens": ["specify", "the", "jdbc", "data", "source", "that", "the", "jpa", "persistence", "provider", "is", "supposed", "to", "use", "for", "accessing", "the", "database", "if", "none", "has", "been", "specified", "in", "persistence"], "project": "spring-framework"}
{"id": 263, "code": "\tpublic void setMinEvictableIdleTimeMillis(long minEvictableIdleTimeMillis) {\n\t\tthis.minEvictableIdleTimeMillis = minEvictableIdleTimeMillis;\n\t}", "summary_tokens": ["set", "the", "minimum", "time", "that", "an", "idle", "object", "can", "sit", "in", "the", "pool", "before", "it", "becomes", "subject", "to", "eviction"], "project": "spring-framework"}
{"id": 7093, "code": "\tpublic void publishError(Throwable t) {\n\t\tState state = this.state.get();\n\t\tif (rsWriteResultLogger.isTraceEnabled()) {\n\t\t\trsWriteResultLogger.trace(this.logPrefix + \"failed: \" + t + \" [\" + state + \"]\");\n\t\t}\n\t\tstate.publishError(this, t);\n\t}", "summary_tokens": ["invoke", "this", "to", "delegate", "an", "error", "signal", "to", "the", "subscriber"], "project": "spring-framework"}
{"id": 5651, "code": "\tpublic final String[] processLocations(Class<?> clazz, String... locations) {\n\t\treturn processLocationsInternal(clazz, locations);\n\t}", "summary_tokens": ["if", "the", "supplied", "locations", "are", "null", "or", "em", "empty", "em", "and", "is", "generate", "default", "locations", "returns", "true", "default", "locations", "will", "be", "generate", "default", "locations", "class", "generated", "i"], "project": "spring-framework"}
{"id": 5064, "code": "\tdefault void afterReceiveCompletion(@Nullable Message<?> message, MessageChannel channel,\n\t\t\t@Nullable Exception ex) {\n\t}", "summary_tokens": ["invoked", "after", "the", "completion", "of", "a", "receive", "regardless", "of", "any", "exception", "that", "have", "been", "raised", "thus", "allowing", "for", "proper", "resource", "cleanup"], "project": "spring-framework"}
{"id": 929, "code": "\tpublic void twoPlaceholderConfigurers_withConflictingSettings() {\n\t\tString P2 = \"p2\";\n\t\tString P2_LOCAL_PROPS_VAL = \"p2LocalPropsVal\";\n\t\tString P2_SYSTEM_PROPS_VAL = \"p2SystemPropsVal\";\n\n\t\tAbstractBeanDefinition p2BeanDef = rootBeanDefinition(TestBean.class)\n\t\t\t\t.addPropertyValue(\"name\", \"${\" + P1 + \"}\")\n\t\t\t\t.addPropertyValue(\"country\", \"${\" + P2 + \"}\")\n\t\t\t\t.getBeanDefinition();\n\n\t\tbf.registerBeanDefinition(\"p1Bean\", p1BeanDef);\n\t\tbf.registerBeanDefinition(\"p2Bean\", p2BeanDef);\n\n\t\tppc.setIgnoreUnresolvablePlaceholders(true);\n\t\tppc.postProcessBeanFactory(bf);\n\n\t\tSystem.setProperty(P2, P2_SYSTEM_PROPS_VAL);\n\t\tProperties ppc2Properties = new Properties();\n\t\tppc2Properties.put(P2, P2_LOCAL_PROPS_VAL);\n\n\t\tPropertyPlaceholderConfigurer ppc2 = new PropertyPlaceholderConfigurer();\n\t\tppc2.setSystemPropertiesMode(PropertyPlaceholderConfigurer.SYSTEM_PROPERTIES_MODE_OVERRIDE);\n\t\tppc2.setProperties(ppc2Properties);\n\n\t\tppc2Properties = new Properties();\n\t\tppc2Properties.setProperty(P2, P2_LOCAL_PROPS_VAL);\n\t\tppc2.postProcessBeanFactory(bf);\n\n\t\tTestBean p1Bean = bf.getBean(\"p1Bean\", TestBean.class);\n\t\tassertThat(p1Bean.getName()).isEqualTo(P1_LOCAL_PROPS_VAL);\n\n\t\tTestBean p2Bean = bf.getBean(\"p2Bean\", TestBean.class);\n\t\tassertThat(p2Bean.getName()).isEqualTo(P1_LOCAL_PROPS_VAL);\n\t\tassertThat(p2Bean.getCountry()).isEqualTo(P2_SYSTEM_PROPS_VAL);\n\n\t\tSystem.clearProperty(P2);\n\t}", "summary_tokens": ["creates", "a", "scenario", "in", "which", "two", "ppcs", "are", "configured", "each", "with", "different", "settings", "regarding", "resolving", "properties", "from", "the", "environment"], "project": "spring-framework"}
{"id": 8793, "code": "\tprotected void detectHandlers() throws BeansException {\n\t\tApplicationContext applicationContext = obtainApplicationContext();\n\t\tString[] beanNames = (this.detectHandlersInAncestorContexts ?\n\t\t\t\tBeanFactoryUtils.beanNamesForTypeIncludingAncestors(applicationContext, Object.class) :\n\t\t\t\tapplicationContext.getBeanNamesForType(Object.class));\n\n\t\t\n\t\tfor (String beanName : beanNames) {\n\t\t\tString[] urls = determineUrlsForHandler(beanName);\n\t\t\tif (!ObjectUtils.isEmpty(urls)) {\n\t\t\t\t\n\t\t\t\tregisterHandler(urls, beanName);\n\t\t\t}\n\t\t}\n\n\t\tif (mappingsLogger.isDebugEnabled()) {\n\t\t\tmappingsLogger.debug(formatMappingName() + \" \" + getHandlerMap());\n\t\t}\n\t\telse if ((logger.isDebugEnabled() && !getHandlerMap().isEmpty()) || logger.isTraceEnabled()) {\n\t\t\tlogger.debug(\"Detected \" + getHandlerMap().size() + \" mappings in \" + formatMappingName());\n\t\t}\n\t}", "summary_tokens": ["register", "all", "handlers", "found", "in", "the", "current", "application", "context"], "project": "spring-framework"}
{"id": 1076, "code": "\tpublic void setConcurrent(boolean concurrent) {\n\t\tthis.concurrent = concurrent;\n\t}", "summary_tokens": ["specify", "whether", "multiple", "jobs", "should", "be", "run", "in", "a", "concurrent", "fashion"], "project": "spring-framework"}
{"id": 6908, "code": "\tprotected void extendObjectReaders(List<HttpMessageReader<?>> objectReaders) {\n\t}", "summary_tokens": ["hook", "for", "client", "or", "server", "specific", "object", "readers"], "project": "spring-framework"}
{"id": 8488, "code": "\tpublic void setDetectAllHandlerExceptionResolvers(boolean detectAllHandlerExceptionResolvers) {\n\t\tthis.detectAllHandlerExceptionResolvers = detectAllHandlerExceptionResolvers;\n\t}", "summary_tokens": ["set", "whether", "to", "detect", "all", "handler", "exception", "resolver", "beans", "in", "this", "servlet", "s", "context"], "project": "spring-framework"}
{"id": 3061, "code": "\tprotected void doExecute(Runnable task) {\n\t\tThread thread = (this.threadFactory != null ? this.threadFactory.newThread(task) : createThread(task));\n\t\tthread.start();\n\t}", "summary_tokens": ["template", "method", "for", "the", "actual", "execution", "of", "a", "task"], "project": "spring-framework"}
{"id": 7194, "code": "\tprotected void adaptEmptyArrayIndices(MutablePropertyValues mpvs) {\n\t\tfor (PropertyValue pv : mpvs.getPropertyValues()) {\n\t\t\tString name = pv.getName();\n\t\t\tif (name.endsWith(\"[]\")) {\n\t\t\t\tString field = name.substring(0, name.length() - 2);\n\t\t\t\tif (getPropertyAccessor().isWritableProperty(field) && !mpvs.contains(field)) {\n\t\t\t\t\tmpvs.add(field, pv.getValue());\n\t\t\t\t}\n\t\t\t\tmpvs.removePropertyValue(pv);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["check", "for", "property", "values", "with", "names", "that", "end", "on"], "project": "spring-framework"}
{"id": 8346, "code": "\tpublic String getErrorMessage() {\n\t\tString[] errorMessages = initErrorMessages();\n\t\treturn (errorMessages.length > 0 ? errorMessages[0] : \"\");\n\t}", "summary_tokens": ["return", "the", "first", "error", "message", "for", "the", "field", "or", "object", "if", "any"], "project": "spring-framework"}
{"id": 4990, "code": "\tpublic MimeType getContentType() {\n\t\tString value = getFirst(CONTENT_TYPE);\n\t\treturn (StringUtils.hasLength(value) ? MimeTypeUtils.parseMimeType(value) : null);\n\t}", "summary_tokens": ["return", "the", "content", "type", "header", "value"], "project": "spring-framework"}
{"id": 934, "code": "\tpublic void businessMethod() {\n\t\tif (!this.inited || (this.initMethodDeclared && !this.initedViaDeclaredInitMethod) ||\n\t\t\t\t!this.postProcessedAfterInit) {\n\t\t\tthrow new RuntimeException(\"Factory didn't initialize lifecycle object correctly\");\n\t\t}\n\t}", "summary_tokens": ["dummy", "business", "method", "that", "will", "fail", "unless", "the", "factory", "managed", "the", "bean", "s", "lifecycle", "correctly"], "project": "spring-framework"}
{"id": 5407, "code": "\tString getOriginalSql() {\n\t\treturn this.originalSql;\n\t}", "summary_tokens": ["return", "the", "sql", "statement", "that", "is", "being", "parsed"], "project": "spring-framework"}
{"id": 3379, "code": "\tstatic <T> ThrowingConsumer<T> of(ThrowingConsumer<T> consumer,\n\t\t\tBiFunction<String, Exception, RuntimeException> exceptionWrapper) {\n\n\t\treturn consumer.throwing(exceptionWrapper);\n\t}", "summary_tokens": ["lambda", "friendly", "convenience", "method", "that", "can", "be", "used", "to", "create", "a", "throwing", "consumer", "where", "the", "accept", "object", "method", "wraps", "any", "thrown", "checked", "exceptions", "using", "the", "given", "exception", "wrapper"], "project": "spring-framework"}
{"id": 5074, "code": "\tpublic MessageBuilder<T> setHeader(String headerName, @Nullable Object headerValue) {\n\t\tthis.headerAccessor.setHeader(headerName, headerValue);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "value", "for", "the", "given", "header", "name"], "project": "spring-framework"}
{"id": 8353, "code": "\tpublic List<MediaType> getSupportedMediaTypes() {\n\t\treturn this.writer.getWritableMediaTypes();\n\t}", "summary_tokens": ["p", "the", "implementation", "of", "this", "method", "for", "http", "message", "writer", "view", "delegates", "to", "http", "message", "writer", "get", "writable", "media", "types"], "project": "spring-framework"}
{"id": 6625, "code": "\tpublic List<Locale.LanguageRange> getAcceptLanguage() {\n\t\tString value = getFirst(ACCEPT_LANGUAGE);\n\t\treturn (StringUtils.hasText(value) ? Locale.LanguageRange.parse(value) : Collections.emptyList());\n\t}", "summary_tokens": ["return", "the", "language", "ranges", "from", "the", "accept", "language", "header"], "project": "spring-framework"}
{"id": 9083, "code": "\tprotected ApplicationContextInitializer<?>[] getServletApplicationContextInitializers() {\n\t\treturn null;\n\t}", "summary_tokens": ["specify", "application", "context", "initializers", "to", "be", "applied", "to", "the", "servlet", "specific", "application", "context", "that", "the", "dispatcher", "servlet", "is", "being", "created", "with"], "project": "spring-framework"}
{"id": 3523, "code": "\tpublic static String toDescriptor(Class<?> type) {\n\t\tString name = type.getName();\n\t\tif (type.isPrimitive()) {\n\t\t\tswitch (name.length()) {\n\t\t\t\tcase 3:\n\t\t\t\t\treturn \"I\";\n\t\t\t\tcase 4:\n\t\t\t\t\tif (name.equals(\"byte\")) {\n\t\t\t\t\t\treturn \"B\";\n\t\t\t\t\t}\n\t\t\t\t\telse if (name.equals(\"char\")) {\n\t\t\t\t\t\treturn \"C\";\n\t\t\t\t\t}\n\t\t\t\t\telse if (name.equals(\"long\")) {\n\t\t\t\t\t\treturn \"J\";\n\t\t\t\t\t}\n\t\t\t\t\telse if (name.equals(\"void\")) {\n\t\t\t\t\t\treturn \"V\";\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase 5:\n\t\t\t\t\tif (name.equals(\"float\")) {\n\t\t\t\t\t\treturn \"F\";\n\t\t\t\t\t}\n\t\t\t\t\telse if (name.equals(\"short\")) {\n\t\t\t\t\t\treturn \"S\";\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase 6:\n\t\t\t\t\tif (name.equals(\"double\")) {\n\t\t\t\t\t\treturn \"D\";\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase 7:\n\t\t\t\t\tif (name.equals(\"boolean\")) {\n\t\t\t\t\t\treturn \"Z\";\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tif (name.charAt(0) != '[') {\n\t\t\t\treturn \"L\" + type.getName().replace('.', '/');\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (name.endsWith(\";\")) {\n\t\t\t\t\treturn name.substring(0, name.length() - 1).replace('.', '/');\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn name;  \n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn \"\";\n\t}", "summary_tokens": ["deduce", "the", "descriptor", "for", "a", "type"], "project": "spring-framework"}
{"id": 6760, "code": "\tpublic void destroy() throws Exception {\n\t\tHttpClient httpClient = getHttpClient();\n\t\tif (httpClient instanceof Closeable) {\n\t\t\t((Closeable) httpClient).close();\n\t\t}\n\t}", "summary_tokens": ["shutdown", "hook", "that", "closes", "the", "underlying", "org"], "project": "spring-framework"}
{"id": 5946, "code": "\tpublic HtmlUnitDriver build() {\n\t\treturn (this.driver != null ? this.driver :\n\t\t\t\twithDelegate(new WebConnectionHtmlUnitDriver(BrowserVersion.CHROME)).build());\n\t}", "summary_tokens": ["build", "the", "html", "unit", "driver", "configured", "via", "this", "builder"], "project": "spring-framework"}
{"id": 2267, "code": "\tpublic ReflectionHints registerConstructor(Constructor<?> constructor, Consumer<ExecutableHint.Builder> constructorHint) {\n\t\treturn registerType(TypeReference.of(constructor.getDeclaringClass()),\n\t\t\t\ttypeHint -> typeHint.withConstructor(mapParameters(constructor), constructorHint));\n\t}", "summary_tokens": ["register", "the", "need", "for", "reflection", "on", "the", "specified", "constructor"], "project": "spring-framework"}
{"id": 3258, "code": "\tpublic synchronized void grow(int additionalCapacity) {\n\t\tAssert.isTrue(additionalCapacity >= 0, \"Additional capacity must be 0 or higher\");\n\t\tif (this.count + additionalCapacity > this.buf.length) {\n\t\t\tint newCapacity = Math.max(this.buf.length * 2, this.count + additionalCapacity);\n\t\t\tresize(newCapacity);\n\t\t}\n\t}", "summary_tokens": ["grow", "the", "internal", "buffer", "size"], "project": "spring-framework"}
{"id": 139, "code": "\tprivate Advisor[] resolveInterceptorNames() {\n\t\tBeanFactory bf = this.beanFactory;\n\t\tConfigurableBeanFactory cbf = (bf instanceof ConfigurableBeanFactory ? (ConfigurableBeanFactory) bf : null);\n\t\tList<Advisor> advisors = new ArrayList<>();\n\t\tfor (String beanName : this.interceptorNames) {\n\t\t\tif (cbf == null || !cbf.isCurrentlyInCreation(beanName)) {\n\t\t\t\tAssert.state(bf != null, \"BeanFactory required for resolving interceptor names\");\n\t\t\t\tObject next = bf.getBean(beanName);\n\t\t\t\tadvisors.add(this.advisorAdapterRegistry.wrap(next));\n\t\t\t}\n\t\t}\n\t\treturn advisors.toArray(new Advisor[0]);\n\t}", "summary_tokens": ["resolves", "the", "specified", "interceptor", "names", "to", "advisor", "objects"], "project": "spring-framework"}
{"id": 1483, "code": "\tpublic static void setDateTimeContext(@Nullable DateTimeContext dateTimeContext) {\n\t\tif (dateTimeContext == null) {\n\t\t\tresetDateTimeContext();\n\t\t}\n\t\telse {\n\t\t\tdateTimeContextHolder.set(dateTimeContext);\n\t\t}\n\t}", "summary_tokens": ["associate", "the", "given", "date", "time", "context", "with", "the", "current", "thread"], "project": "spring-framework"}
{"id": 4292, "code": "\tpublic void afterPropertiesSet() {\n\t\tif (this.connection == null && getTargetConnectionFactory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"Target Connection or ConnectionFactory is required\");\n\t\t}\n\t}", "summary_tokens": ["make", "sure", "a", "connection", "or", "connection", "factory", "has", "been", "set"], "project": "spring-framework"}
{"id": 8754, "code": "\tdefault RouterFunction<T> withAttributes(Consumer<Map<String, Object>> attributesConsumer) {\n\t\tAssert.notNull(attributesConsumer, \"AttributesConsumer must not be null\");\n\n\t\tMap<String, Object> attributes = new LinkedHashMap<>();\n\t\tattributesConsumer.accept(attributes);\n\t\treturn new RouterFunctions.AttributesRouterFunction<>(this, attributes);\n\t}", "summary_tokens": ["return", "a", "new", "routing", "function", "with", "attributes", "manipulated", "with", "the", "given", "consumer"], "project": "spring-framework"}
{"id": 7439, "code": "\tpublic void setPathMatcher(PathMatcher pathMatcher) {\n\t\tthis.pathMatcher = pathMatcher;\n\t}", "summary_tokens": ["configure", "a", "path", "matcher", "to", "use", "for", "pattern", "matching"], "project": "spring-framework"}
{"id": 5736, "code": "\tpublic void afterTestMethod(TestContext testContext) throws Exception {\n\t\tMethod testMethod = testContext.getTestMethod();\n\t\tAssert.notNull(testMethod, \"The test method of the supplied TestContext must not be null\");\n\n\t\tTransactionContext txContext = TransactionContextHolder.removeCurrentTransactionContext();\n\t\t\n\t\tif (txContext != null) {\n\t\t\tTransactionStatus transactionStatus = txContext.getTransactionStatus();\n\t\t\ttry {\n\t\t\t\t\n\t\t\t\tif (transactionStatus != null && !transactionStatus.isCompleted()) {\n\t\t\t\t\ttxContext.endTransaction();\n\t\t\t\t}\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\trunAfterTransactionMethods(testContext);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["if", "a", "transaction", "is", "currently", "active", "for", "the", "supplied", "test", "context", "test", "context", "this", "method", "will", "end", "the", "transaction", "and", "run", "after", "transaction", "methods"], "project": "spring-framework"}
{"id": 1727, "code": "\tpublic void setJndiEnvironment(@Nullable Properties jndiEnvironment) {\n\t\tthis.jndiTemplate = new JndiTemplate(jndiEnvironment);\n\t}", "summary_tokens": ["set", "the", "jndi", "environment", "to", "use", "for", "jndi", "lookups"], "project": "spring-framework"}
{"id": 9646, "code": "\tprotected Object getCacheKey(String viewName, Locale locale) {\n\t\treturn viewName;\n\t}", "summary_tokens": ["this", "implementation", "returns", "just", "the", "view", "name", "as", "xml", "view", "resolver", "doesn", "t", "support", "localized", "resolution"], "project": "spring-framework"}
{"id": 1663, "code": "\tpublic int getIndex() {\n\t\treturn this.index;\n\t}", "summary_tokens": ["return", "the", "index", "of", "this", "parameter", "in", "the", "operation", "signature"], "project": "spring-framework"}
{"id": 9372, "code": "\tpublic void setAction(@Nullable String action) {\n\t\tthis.action = (action != null ? action : \"\");\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "action", "attribute"], "project": "spring-framework"}
{"id": 6957, "code": "\tpublic Jackson2ObjectMapperBuilder filters(FilterProvider filters) {\n\t\tthis.filters = filters;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "global", "filters", "to", "use", "in", "order", "to", "support", "json", "filter", "annotated", "pojo"], "project": "spring-framework"}
{"id": 2413, "code": "public String getDescriptor() {\n  return descriptor;\n}", "summary_tokens": ["returns", "the", "type", "of", "this", "constant"], "project": "spring-framework"}
{"id": 5831, "code": "\tpublic RequestMatcher isArray() {\n\t\treturn new AbstractJsonPathRequestMatcher() {\n\t\t\t@Override\n\t\t\tprotected void matchInternal(MockClientHttpRequest request) throws IOException, ParseException {\n\t\t\t\tJsonPathRequestMatchers.this.jsonPathHelper.assertValueIsArray(request.getBodyAsString());\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "json", "path", "expression", "against", "the", "request", "content", "and", "assert", "that", "the", "result", "is", "an", "array"], "project": "spring-framework"}
{"id": 7983, "code": "\tpublic CorsRegistration allowedOrigins(String... origins) {\n\t\tthis.config.setAllowedOrigins(Arrays.asList(origins));\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "origins", "for", "which", "cross", "origin", "requests", "are", "allowed", "from", "a", "browser"], "project": "spring-framework"}
{"id": 7543, "code": "\tprivate NamedValueInfo updateNamedValueInfo(MethodParameter parameter, NamedValueInfo info) {\n\t\tString name = info.name;\n\t\tif (info.name.isEmpty()) {\n\t\t\tname = parameter.getParameterName();\n\t\t\tif (name == null) {\n\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\"Name for argument of type [\" + parameter.getNestedParameterType().getName() +\n\t\t\t\t\t\t\"] not specified, and parameter name information not found in class file either.\");\n\t\t\t}\n\t\t}\n\t\tString defaultValue = (ValueConstants.DEFAULT_NONE.equals(info.defaultValue) ? null : info.defaultValue);\n\t\treturn new NamedValueInfo(name, info.required, defaultValue);\n\t}", "summary_tokens": ["create", "a", "new", "named", "value", "info", "based", "on", "the", "given", "named", "value", "info", "with", "sanitized", "values"], "project": "spring-framework"}
{"id": 8819, "code": "\tpublic void setDefaultStatusCode(int defaultStatusCode) {\n\t\tthis.defaultStatusCode = defaultStatusCode;\n\t}", "summary_tokens": ["set", "the", "default", "http", "status", "code", "that", "this", "exception", "resolver", "will", "apply", "if", "it", "resolves", "an", "error", "view", "and", "if", "there", "is", "no", "status", "code", "mapping", "defined"], "project": "spring-framework"}
{"id": 7884, "code": "\tprotected final boolean isNoMorePattern() {\n\t\treturn this.next == null;\n\t}", "summary_tokens": ["return", "if", "the", "there", "are", "no", "more", "path", "elements", "in", "the", "pattern"], "project": "spring-framework"}
{"id": 9328, "code": "\tprotected String getAccesskey() {\n\t\treturn this.accesskey;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "accesskey", "attribute"], "project": "spring-framework"}
{"id": 7187, "code": "\tpublic void setFieldDefaultPrefix(@Nullable String fieldDefaultPrefix) {\n\t\tthis.fieldDefaultPrefix = fieldDefaultPrefix;\n\t}", "summary_tokens": ["specify", "a", "prefix", "that", "can", "be", "used", "for", "parameters", "that", "indicate", "default", "value", "fields", "having", "prefix", "field", "as", "name"], "project": "spring-framework"}
{"id": 6245, "code": "\tpublic void setListenerId(String listenerId) {\n\t\tthis.listenerId = listenerId;\n\t}", "summary_tokens": ["specify", "an", "id", "to", "identify", "the", "listener", "with"], "project": "spring-framework"}
{"id": 2210, "code": "\tpublic static SourceFiles none() {\n\t\treturn NONE;\n\t}", "summary_tokens": ["return", "a", "source", "files", "instance", "with", "no", "items"], "project": "spring-framework"}
{"id": 4448, "code": "\tprotected void messageReceived(Object invoker, Session session) {\n\t}", "summary_tokens": ["template", "method", "that", "gets", "called", "right", "when", "a", "new", "message", "has", "been", "received", "before", "attempting", "to", "process", "it"], "project": "spring-framework"}
{"id": 1505, "code": "\tprivate static Instrumentation getInstrumentation() {\n\t\tif (AGENT_CLASS_PRESENT) {\n\t\t\treturn InstrumentationAccessor.getInstrumentation();\n\t\t}\n\t\telse {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["obtain", "the", "instrumentation", "instance", "for", "the", "current", "vm", "if", "available"], "project": "spring-framework"}
{"id": 6555, "code": "\tpublic static void setCurrentTransactionReadOnly(boolean readOnly) {\n\t\tcurrentTransactionReadOnly.set(readOnly ? Boolean.TRUE : null);\n\t}", "summary_tokens": ["expose", "a", "read", "only", "flag", "for", "the", "current", "transaction"], "project": "spring-framework"}
{"id": 3289, "code": "\tpublic String shortSummary() {\n\t\treturn \"StopWatch '\" + getId() + \"': running time = \" + getTotalTimeNanos() + \" ns\";\n\t}", "summary_tokens": ["get", "a", "short", "description", "of", "the", "total", "running", "time"], "project": "spring-framework"}
{"id": 9388, "code": "\tpublic void setAutocomplete(String autocomplete) {\n\t\tthis.autocomplete = autocomplete;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "autocomplete", "attribute"], "project": "spring-framework"}
{"id": 1681, "code": "\tpublic void setServiceUrl(String serviceUrl) {\n\t\tthis.serviceUrl = serviceUrl;\n\t}", "summary_tokens": ["set", "the", "service", "url", "for", "the", "jmxconnector", "server"], "project": "spring-framework"}
{"id": 3141, "code": "\tpublic static Set<Class<?>> getAllInterfacesAsSet(Object instance) {\n\t\tAssert.notNull(instance, \"Instance must not be null\");\n\t\treturn getAllInterfacesForClassAsSet(instance.getClass());\n\t}", "summary_tokens": ["return", "all", "interfaces", "that", "the", "given", "instance", "implements", "as", "a", "set", "including", "ones", "implemented", "by", "superclasses"], "project": "spring-framework"}
{"id": 5777, "code": "\tpublic void doesNotExist(byte[] content, @Nullable String encoding) throws Exception {\n\t\tNode node = evaluateXpath(content, encoding, Node.class);\n\t\tAssertionErrors.assertNull(\"XPath \" + this.expression + \" exists\", node);\n\t}", "summary_tokens": ["apply", "the", "xpath", "expression", "and", "assert", "the", "resulting", "content", "does", "not", "exist"], "project": "spring-framework"}
{"id": 8209, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "for", "this", "result", "handler", "relative", "to", "others"], "project": "spring-framework"}
{"id": 4696, "code": "\tpublic Method resolveMethod(Throwable exception) {\n\t\tMethod method = resolveMethodByExceptionType(exception.getClass());\n\t\tif (method == null) {\n\t\t\tThrowable cause = exception.getCause();\n\t\t\tif (cause != null) {\n\t\t\t\tmethod = resolveMethodByExceptionType(cause.getClass());\n\t\t\t}\n\t\t}\n\t\treturn method;\n\t}", "summary_tokens": ["find", "a", "method", "to", "handle", "the", "given", "exception"], "project": "spring-framework"}
{"id": 6364, "code": "\tprotected Mono<Object> doSuspend(TransactionSynchronizationManager synchronizationManager,\n\t\t\tObject transaction) throws TransactionException {\n\n\t\tthrow new TransactionSuspensionNotSupportedException(\n\t\t\t\t\"Transaction manager [\" + getClass().getName() + \"] does not support transaction suspension\");\n\t}", "summary_tokens": ["suspend", "the", "resources", "of", "the", "current", "transaction"], "project": "spring-framework"}
{"id": 7195, "code": "\tpublic Object getEmptyValue(Class<?> fieldType) {\n\t\ttry {\n\t\t\tif (boolean.class == fieldType || Boolean.class == fieldType) {\n\t\t\t\t\n\t\t\t\treturn Boolean.FALSE;\n\t\t\t}\n\t\t\telse if (fieldType.isArray()) {\n\t\t\t\t\n\t\t\t\treturn Array.newInstance(fieldType.getComponentType(), 0);\n\t\t\t}\n\t\t\telse if (Collection.class.isAssignableFrom(fieldType)) {\n\t\t\t\treturn CollectionFactory.createCollection(fieldType, 0);\n\t\t\t}\n\t\t\telse if (Map.class.isAssignableFrom(fieldType)) {\n\t\t\t\treturn CollectionFactory.createMap(fieldType, 0);\n\t\t\t}\n\t\t}\n\t\tcatch (IllegalArgumentException ex) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Failed to create default value - falling back to null: \" + ex.getMessage());\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn null;\n\t}", "summary_tokens": ["determine", "an", "empty", "value", "for", "the", "specified", "field"], "project": "spring-framework"}
{"id": 2049, "code": "\tpublic void setValidationMessageSource(MessageSource messageSource) {\n\t\tthis.messageInterpolator = HibernateValidatorDelegate.buildMessageInterpolator(messageSource);\n\t}", "summary_tokens": ["specify", "a", "custom", "spring", "message", "source", "for", "resolving", "validation", "messages", "instead", "of", "relying", "on", "jsr", "0", "s", "default", "validation", "messages"], "project": "spring-framework"}
{"id": 1392, "code": "\tprotected GenericConversionService createConversionService() {\n\t\treturn new DefaultConversionService();\n\t}", "summary_tokens": ["create", "the", "conversion", "service", "instance", "returned", "by", "this", "factory", "bean"], "project": "spring-framework"}
{"id": 8840, "code": "\tpublic void setSupportedLocales(List<Locale> locales) {\n\t\tthis.supportedLocales.clear();\n\t\tthis.supportedLocales.addAll(locales);\n\t}", "summary_tokens": ["configure", "supported", "locales", "to", "check", "against", "the", "requested", "locales", "determined", "via", "http", "servlet", "request", "get", "locales"], "project": "spring-framework"}
{"id": 8805, "code": "\tprotected String[] determineUrlsForHandler(String beanName) {\n\t\tList<String> urls = new ArrayList<>();\n\t\tif (beanName.startsWith(\"/\")) {\n\t\t\turls.add(beanName);\n\t\t}\n\t\tString[] aliases = obtainApplicationContext().getAliases(beanName);\n\t\tfor (String alias : aliases) {\n\t\t\tif (alias.startsWith(\"/\")) {\n\t\t\t\turls.add(alias);\n\t\t\t}\n\t\t}\n\t\treturn StringUtils.toStringArray(urls);\n\t}", "summary_tokens": ["checks", "name", "and", "aliases", "of", "the", "given", "bean", "for", "urls", "starting", "with"], "project": "spring-framework"}
{"id": 2605, "code": "public int getSuperTypeIndex() {\n  return (short) ((targetTypeAndInfo & 0x00FFFF00) >> 8);\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "super", "type", "of", "a", "class", "that", "is", "referenced", "by", "this", "type", "reference"], "project": "spring-framework"}
{"id": 9857, "code": "\tprivate void checkSessions() {\n\t\tlong currentTime = System.currentTimeMillis();\n\t\tif (!isRunning() || (currentTime - this.lastSessionCheckTime < getTimeToFirstMessage())) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (this.sessionCheckLock.tryLock()) {\n\t\t\ttry {\n\t\t\t\tfor (WebSocketSessionHolder holder : this.sessions.values()) {\n\t\t\t\t\tif (holder.hasHandledMessages()) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tlong timeSinceCreated = currentTime - holder.getCreateTime();\n\t\t\t\t\tif (timeSinceCreated < getTimeToFirstMessage()) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tWebSocketSession session = holder.getSession();\n\t\t\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\t\t\tlogger.info(\"No messages received after \" + timeSinceCreated + \" ms. \" +\n\t\t\t\t\t\t\t\t\"Closing \" + holder.getSession() + \".\");\n\t\t\t\t\t}\n\t\t\t\t\ttry {\n\t\t\t\t\t\tthis.stats.incrementNoMessagesReceivedCount();\n\t\t\t\t\t\tsession.close(CloseStatus.SESSION_NOT_RELIABLE);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Throwable ex) {\n\t\t\t\t\t\tif (logger.isWarnEnabled()) {\n\t\t\t\t\t\t\tlogger.warn(\"Failed to close unreliable \" + session, ex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tthis.lastSessionCheckTime = currentTime;\n\t\t\t\tthis.sessionCheckLock.unlock();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["when", "a", "session", "is", "connected", "through", "a", "higher", "level", "protocol", "it", "has", "a", "chance", "to", "use", "heartbeat", "management", "to", "shut", "down", "sessions", "that", "are", "too", "slow", "to", "send", "or", "receive", "messages"], "project": "spring-framework"}
{"id": 7896, "code": "\tvoid keySetRemovalChecks() {\n\t\t\n\t\theaders.add(\"Alpha\", \"apple\");\n\t\theaders.add(\"Bravo\", \"banana\");\n\t\tassertThat(headers).containsOnlyKeys(\"Alpha\", \"Bravo\");\n\n\t\t\n\t\tboolean removed = headers.keySet().remove(\"Alpha\");\n\n\t\t\n\n\t\t\n\t\t\n\t\t\n\t\t\n\n\t\tassertThat(removed).isTrue();\n\t\tassertThat(headers.keySet().remove(\"Alpha\")).isFalse();\n\t\tassertThat(headers.size()).isEqualTo(1);\n\t\tassertThat(headers.containsKey(\"Alpha\")).as(\"Alpha should have been removed\").isFalse();\n\t\tassertThat(headers.containsKey(\"Bravo\")).as(\"Bravo should be present\").isTrue();\n\t\tassertThat(headers.keySet()).containsOnly(\"Bravo\");\n\t\tassertThat(headers.entrySet()).containsOnly(entry(\"Bravo\", Arrays.asList(\"banana\")));\n\t}", "summary_tokens": ["this", "method", "intentionally", "checks", "a", "wider", "different", "range", "of", "functionality", "than", "removal", "from", "key", "set", "removes", "entry", "from", "underlying", "map"], "project": "spring-framework"}
{"id": 7623, "code": "\tpublic SessionStatus getSessionStatus() {\n\t\treturn this.sessionStatus;\n\t}", "summary_tokens": ["return", "the", "session", "status", "instance", "to", "use", "that", "can", "be", "used", "to", "signal", "that", "session", "processing", "is", "complete"], "project": "spring-framework"}
{"id": 8389, "code": "\tprotected View applyLifecycleMethods(String viewName, AbstractUrlBasedView view) {\n\t\tApplicationContext context = getApplicationContext();\n\t\tif (context != null) {\n\t\t\tObject initialized = context.getAutowireCapableBeanFactory().initializeBean(view, viewName);\n\t\t\tif (initialized instanceof View) {\n\t\t\t\treturn (View) initialized;\n\t\t\t}\n\t\t}\n\t\treturn view;\n\t}", "summary_tokens": ["apply", "the", "containing", "application", "context", "s", "lifecycle", "methods", "to", "the", "given", "view", "instance", "if", "such", "a", "context", "is", "available"], "project": "spring-framework"}
{"id": 2156, "code": "\tpublic void activate() throws IllegalStateException, NamingException {\n\t\tlogger.info(\"Activating simple JNDI environment\");\n\t\tsynchronized (initializationLock) {\n\t\t\tif (!initialized) {\n\t\t\t\tAssert.state(!NamingManager.hasInitialContextFactoryBuilder(),\n\t\t\t\t\t\t\t\"Cannot activate SimpleNamingContextBuilder: there is already a JNDI provider registered. \" +\n\t\t\t\t\t\t\t\"Note that JNDI is a JVM-wide service, shared at the JVM system class loader level, \" +\n\t\t\t\t\t\t\t\"with no reset option. As a consequence, a JNDI provider must only be registered once per JVM.\");\n\t\t\t\tNamingManager.setInitialContextFactoryBuilder(this);\n\t\t\t\tinitialized = true;\n\t\t\t}\n\t\t}\n\t\tactivated = this;\n\t}", "summary_tokens": ["register", "the", "context", "builder", "by", "registering", "it", "with", "the", "jndi", "naming", "manager"], "project": "spring-framework"}
{"id": 6211, "code": "\tpublic void start() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tif (!this.running) {\n\t\t\t\tResourceAdapter resourceAdapter = getResourceAdapter();\n\t\t\t\tAssert.state(resourceAdapter != null, \"No ResourceAdapter set\");\n\t\t\t\ttry {\n\t\t\t\t\tresourceAdapter.endpointActivation(getMessageEndpointFactory(), getActivationSpec());\n\t\t\t\t}\n\t\t\t\tcatch (ResourceException ex) {\n\t\t\t\t\tthrow new IllegalStateException(\"Could not activate message endpoint\", ex);\n\t\t\t\t}\n\t\t\t\tthis.running = true;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["activates", "the", "configured", "message", "endpoint"], "project": "spring-framework"}
{"id": 5732, "code": "\tboolean isFlaggedForRollback() {\n\t\treturn this.flaggedForRollback;\n\t}", "summary_tokens": ["has", "the", "current", "transaction", "been", "flagged", "for", "rollback", "p", "in", "other", "words", "should", "we", "roll", "back", "or", "commit", "the", "current", "transaction", "upon", "completion", "of", "the", "current", "test"], "project": "spring-framework"}
{"id": 6982, "code": "\tpublic void configure(ObjectMapper objectMapper) {\n\t\tAssert.notNull(objectMapper, \"ObjectMapper must not be null\");\n\n\t\tMultiValueMap<Object, Module> modulesToRegister = new LinkedMultiValueMap<>();\n\t\tif (this.findModulesViaServiceLoader) {\n\t\t\tObjectMapper.findModules(this.moduleClassLoader).forEach(module -> registerModule(module, modulesToRegister));\n\t\t}\n\t\telse if (this.findWellKnownModules) {\n\t\t\tregisterWellKnownModulesIfAvailable(modulesToRegister);\n\t\t}\n\n\t\tif (this.modules != null) {\n\t\t\tthis.modules.forEach(module -> registerModule(module, modulesToRegister));\n\t\t}\n\t\tif (this.moduleClasses != null) {\n\t\t\tfor (Class<? extends Module> moduleClass : this.moduleClasses) {\n\t\t\t\tregisterModule(BeanUtils.instantiateClass(moduleClass), modulesToRegister);\n\t\t\t}\n\t\t}\n\t\tList<Module> modules = new ArrayList<>();\n\t\tfor (List<Module> nestedModules : modulesToRegister.values()) {\n\t\t\tmodules.addAll(nestedModules);\n\t\t}\n\t\tobjectMapper.registerModules(modules);\n\n\t\tif (this.dateFormat != null) {\n\t\t\tobjectMapper.setDateFormat(this.dateFormat);\n\t\t}\n\t\tif (this.locale != null) {\n\t\t\tobjectMapper.setLocale(this.locale);\n\t\t}\n\t\tif (this.timeZone != null) {\n\t\t\tobjectMapper.setTimeZone(this.timeZone);\n\t\t}\n\n\t\tif (this.annotationIntrospector != null) {\n\t\t\tobjectMapper.setAnnotationIntrospector(this.annotationIntrospector);\n\t\t}\n\t\tif (this.propertyNamingStrategy != null) {\n\t\t\tobjectMapper.setPropertyNamingStrategy(this.propertyNamingStrategy);\n\t\t}\n\t\tif (this.defaultTyping != null) {\n\t\t\tobjectMapper.setDefaultTyping(this.defaultTyping);\n\t\t}\n\t\tif (this.serializationInclusion != null) {\n\t\t\tobjectMapper.setDefaultPropertyInclusion(this.serializationInclusion);\n\t\t}\n\n\t\tif (this.filters != null) {\n\t\t\tobjectMapper.setFilterProvider(this.filters);\n\t\t}\n\n\t\tobjectMapper.addMixIn(ProblemDetail.class, ProblemDetailJacksonMixin.class);\n\t\tthis.mixIns.forEach(objectMapper::addMixIn);\n\n\t\tif (!this.serializers.isEmpty() || !this.deserializers.isEmpty()) {\n\t\t\tSimpleModule module = new SimpleModule();\n\t\t\taddSerializers(module);\n\t\t\taddDeserializers(module);\n\t\t\tobjectMapper.registerModule(module);\n\t\t}\n\n\t\tthis.visibilities.forEach(objectMapper::setVisibility);\n\n\t\tcustomizeDefaultFeatures(objectMapper);\n\t\tthis.features.forEach((feature, enabled) -> configureFeature(objectMapper, feature, enabled));\n\n\t\tif (this.handlerInstantiator != null) {\n\t\t\tobjectMapper.setHandlerInstantiator(this.handlerInstantiator);\n\t\t}\n\t\telse if (this.applicationContext != null) {\n\t\t\tobjectMapper.setHandlerInstantiator(\n\t\t\t\t\tnew SpringHandlerInstantiator(this.applicationContext.getAutowireCapableBeanFactory()));\n\t\t}\n\n\t\tif (this.configurer != null) {\n\t\t\tthis.configurer.accept(objectMapper);\n\t\t}\n\t}", "summary_tokens": ["configure", "an", "existing", "object", "mapper", "instance", "with", "this", "builder", "s", "settings"], "project": "spring-framework"}
{"id": 2157, "code": "\tpublic void deactivate() {\n\t\tlogger.info(\"Deactivating simple JNDI environment\");\n\t\tactivated = null;\n\t}", "summary_tokens": ["temporarily", "deactivate", "this", "context", "builder"], "project": "spring-framework"}
{"id": 1788, "code": "\tpublic static <V> ListenableFuture<V> forValue(V value) {\n\t\treturn new AsyncResult<>(value, null);\n\t}", "summary_tokens": ["create", "a", "new", "async", "result", "which", "exposes", "the", "given", "value", "from", "future", "get"], "project": "spring-framework"}
{"id": 4484, "code": "\tprotected void scheduleNewInvokerIfAppropriate() {\n\t\tif (isRunning()) {\n\t\t\tresumePausedTasks();\n\t\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\t\tif (this.scheduledInvokers.size() < this.maxConcurrentConsumers &&\n\t\t\t\t\t\tgetIdleInvokerCount() < this.idleConsumerLimit) {\n\t\t\t\t\tscheduleNewInvoker();\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Raised scheduled invoker count: \" + this.scheduledInvokers.size());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["schedule", "a", "new", "invoker", "increasing", "the", "total", "number", "of", "scheduled", "invokers", "for", "this", "listener", "container", "but", "only", "if", "the", "specified", "max", "concurrent", "consumers", "limit", "has", "not", "been", "reached", "yet", "and", "only", "if", "the", "specified", "idle", "consumer", "limit", "has", "not", "been", "reached", "either"], "project": "spring-framework"}
{"id": 756, "code": "\tpublic Method getResolvedFactoryMethod() {\n\t\treturn this.factoryMethodToIntrospect;\n\t}", "summary_tokens": ["return", "the", "resolved", "factory", "method", "as", "a", "java", "method", "object", "if", "available"], "project": "spring-framework"}
{"id": 2791, "code": "\tint indexOf(Method attribute) {\n\t\tfor (int i = 0; i < this.attributeMethods.length; i++) {\n\t\t\tif (this.attributeMethods[i].equals(attribute)) {\n\t\t\t\treturn i;\n\t\t\t}\n\t\t}\n\t\treturn -1;\n\t}", "summary_tokens": ["get", "the", "index", "of", "the", "specified", "attribute", "or", "0", "if", "the", "attribute", "is", "not", "in", "this", "collection"], "project": "spring-framework"}
{"id": 5331, "code": "\tpublic String getSql() {\n\t\treturn this.sql;\n\t}", "summary_tokens": ["return", "the", "sql", "that", "caused", "the", "problem"], "project": "spring-framework"}
{"id": 6637, "code": "\tpublic String getAccessControlAllowOrigin() {\n\t\treturn getFieldValues(ACCESS_CONTROL_ALLOW_ORIGIN);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "access", "control", "allow", "origin", "response", "header"], "project": "spring-framework"}
{"id": 5598, "code": "\tprotected int countRowsInTable(String tableName) {\n\t\treturn JdbcTestUtils.countRowsInTable(this.jdbcTemplate, tableName);\n\t}", "summary_tokens": ["convenience", "method", "for", "counting", "the", "rows", "in", "the", "given", "table"], "project": "spring-framework"}
{"id": 9362, "code": "\tpublic String getDelimiter() {\n\t\treturn this.delimiter;\n\t}", "summary_tokens": ["return", "the", "delimiter", "to", "be", "used", "between", "error", "messages"], "project": "spring-framework"}
{"id": 3725, "code": "\tpublic String getProcedureName() {\n\t\treturn this.procedureName;\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "procedure"], "project": "spring-framework"}
{"id": 4258, "code": "\tpublic static void releaseConnection(@Nullable Connection con, @Nullable ConnectionFactory cf, boolean started) {\n\t\tif (con == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (started && cf instanceof SmartConnectionFactory && ((SmartConnectionFactory) cf).shouldStop(con)) {\n\t\t\ttry {\n\t\t\t\tcon.stop();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tlogger.debug(\"Could not stop JMS Connection before closing it\", ex);\n\t\t\t}\n\t\t}\n\t\ttry {\n\t\t\tcon.close();\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tlogger.debug(\"Could not close JMS Connection\", ex);\n\t\t}\n\t}", "summary_tokens": ["release", "the", "given", "connection", "stopping", "it", "if", "necessary", "and", "eventually", "closing", "it"], "project": "spring-framework"}
{"id": 6747, "code": "\tpublic void setHttpClient(HttpClient httpClient) {\n\t\tAssert.notNull(httpClient, \"HttpClient must not be null\");\n\t\tthis.httpClient = httpClient;\n\t}", "summary_tokens": ["set", "the", "http", "client", "used", "for", "create", "request", "uri", "http", "method", "synchronous", "execution"], "project": "spring-framework"}
{"id": 1371, "code": "\tpublic Set<String> getBasenameSet() {\n\t\treturn this.basenameSet;\n\t}", "summary_tokens": ["return", "this", "message", "source", "s", "basename", "set", "containing", "entries", "in", "the", "order", "of", "registration"], "project": "spring-framework"}
{"id": 5708, "code": "\tpublic static void addPropertiesFilesToEnvironment(ConfigurableEnvironment environment,\n\t\t\tResourceLoader resourceLoader, String... locations) {\n\n\t\tAssert.notNull(environment, \"'environment' must not be null\");\n\t\tAssert.notNull(resourceLoader, \"'resourceLoader' must not be null\");\n\t\tAssert.notNull(locations, \"'locations' must not be null\");\n\t\ttry {\n\t\t\tfor (String location : locations) {\n\t\t\t\tString resolvedLocation = environment.resolveRequiredPlaceholders(location);\n\t\t\t\tResource resource = resourceLoader.getResource(resolvedLocation);\n\t\t\t\tenvironment.getPropertySources().addFirst(new ResourcePropertySource(resource));\n\t\t\t}\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new IllegalStateException(\"Failed to add PropertySource to Environment\", ex);\n\t\t}\n\t}", "summary_tokens": ["add", "the", "properties", "files", "from", "the", "given", "resource", "locations", "to", "the", "supplied", "configurable", "environment", "environment"], "project": "spring-framework"}
{"id": 2636, "code": "public static void not_equals(final CodeEmitter e, Type type, final Label notEquals, final CustomizerRegistry registry) {\n    (new ProcessArrayCallback() {\n        @Override\n        public void processElement(Type type) {\n            not_equals_helper(e, type, notEquals, registry, this);\n        }\n    }).processElement(type);\n}", "summary_tokens": ["branches", "to", "the", "specified", "label", "if", "the", "top", "two", "items", "on", "the", "stack", "are", "not", "equal"], "project": "spring-framework"}
{"id": 8056, "code": "\tpublic static <T> BodyExtractor<Flux<T>, ReactiveHttpInputMessage> toFlux(ParameterizedTypeReference<T> typeRef) {\n\t\treturn toFlux(ResolvableType.forType(typeRef.getType()));\n\t}", "summary_tokens": ["variant", "of", "to", "flux", "class", "for", "type", "information", "with", "generics"], "project": "spring-framework"}
{"id": 7483, "code": "\tprotected void beforeRequest(HttpServletRequest request, String message) {\n\t\tlogger.debug(message);\n\t}", "summary_tokens": ["writes", "a", "log", "message", "before", "the", "request", "is", "processed"], "project": "spring-framework"}
{"id": 379, "code": "\tpublic String getBeanName() {\n\t\treturn this.beanName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "instance", "that", "was", "of", "the", "wrong", "type"], "project": "spring-framework"}
{"id": 9875, "code": "\tprotected boolean isValidOrigin(ServerHttpRequest request) {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "the", "request", "origin", "header", "value", "is", "valid", "or", "not"], "project": "spring-framework"}
{"id": 2139, "code": "\tpublic void aspectModeAspectJAttemptsToRegisterAsyncAspect() {\n\t\t@SuppressWarnings(\"resource\")\n\t\tAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();\n\t\tctx.register(AspectJAsyncAnnotationConfig.class);\n\t\tassertThatExceptionOfType(BeanDefinitionStoreException.class).isThrownBy(\n\t\t\t\tctx::refresh);\n\t}", "summary_tokens": ["fails", "with", "classpath", "errors", "on", "trying", "to", "classload", "annotation", "async", "execution", "aspect"], "project": "spring-framework"}
{"id": 9058, "code": "\tpublic RedirectAttributesModelMap addAttribute(Object attributeValue) {\n\t\tsuper.addAttribute(attributeValue);\n\t\treturn this;\n\t}", "summary_tokens": ["p", "formats", "the", "attribute", "value", "as", "a", "string", "before", "adding", "it"], "project": "spring-framework"}
{"id": 728, "code": "\tpublic static <E> ManagedSet<E> of(E... elements) {\n\t\tManagedSet<E> set = new ManagedSet<>();\n\t\tCollections.addAll(set, elements);\n\t\treturn set;\n\t}", "summary_tokens": ["create", "a", "new", "instance", "containing", "an", "arbitrary", "number", "of", "elements"], "project": "spring-framework"}
{"id": 9690, "code": "\tprotected URL resolveTemplate(ClassLoader classLoader, String templatePath) throws IOException {\n\t\tMarkupTemplateEngine.TemplateResource resource = MarkupTemplateEngine.TemplateResource.parse(templatePath);\n\t\tLocale locale = LocaleContextHolder.getLocale();\n\t\tURL url = classLoader.getResource(resource.withLocale(StringUtils.replace(locale.toString(), \"-\", \"_\")).toString());\n\t\tif (url == null) {\n\t\t\turl = classLoader.getResource(resource.withLocale(locale.getLanguage()).toString());\n\t\t}\n\t\tif (url == null) {\n\t\t\turl = classLoader.getResource(resource.withLocale(null).toString());\n\t\t}\n\t\tif (url == null) {\n\t\t\tthrow new IOException(\"Unable to load template:\" + templatePath);\n\t\t}\n\t\treturn url;\n\t}", "summary_tokens": ["resolve", "a", "template", "from", "the", "given", "template", "path"], "project": "spring-framework"}
{"id": 4664, "code": "\tpublic void setSendTimeoutHeader(String sendTimeoutHeader) {\n\t\tAssert.notNull(sendTimeoutHeader, \"'sendTimeoutHeader' cannot be null\");\n\t\tthis.sendTimeoutHeader = sendTimeoutHeader;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "header", "used", "to", "determine", "the", "send", "timeout", "if", "present"], "project": "spring-framework"}
{"id": 3718, "code": "\tpublic void setFunctionReturnName(String functionReturnName) {\n\t\tthis.actualFunctionReturnName = functionReturnName;\n\t}", "summary_tokens": ["specify", "the", "name", "used", "for", "the", "return", "value", "of", "the", "function"], "project": "spring-framework"}
{"id": 7624, "code": "\tpublic void setRequestHandled(boolean requestHandled) {\n\t\tthis.requestHandled = requestHandled;\n\t}", "summary_tokens": ["whether", "the", "request", "has", "been", "handled", "fully", "within", "the", "handler", "e"], "project": "spring-framework"}
{"id": 799, "code": "\tprotected String getBeanClassName(Element element) {\n\t\treturn null;\n\t}", "summary_tokens": ["determine", "the", "bean", "class", "name", "corresponding", "to", "the", "supplied", "element"], "project": "spring-framework"}
{"id": 1228, "code": "\tpublic void setFallbackToNoOpCache(boolean fallbackToNoOpCache) {\n\t\tthis.fallbackToNoOpCache = fallbackToNoOpCache;\n\t}", "summary_tokens": ["indicate", "whether", "a", "no", "op", "cache", "manager", "should", "be", "added", "at", "the", "end", "of", "the", "delegate", "list"], "project": "spring-framework"}
{"id": 6150, "code": "\tvoid resolveActiveProfilesWithDefaultActiveProfilesResolver() {\n\t\tassertResolvedProfiles(DefaultActiveProfilesResolverTestCase.class, \"default\");\n\t}", "summary_tokens": ["this", "test", "verifies", "that", "default", "active", "profiles", "resolver", "can", "be", "declared", "explicitly"], "project": "spring-framework"}
{"id": 8240, "code": "\tpublic boolean isEmpty() {\n\t\treturn this.expressions.isEmpty();\n\t}", "summary_tokens": ["whether", "the", "condition", "has", "any", "media", "type", "expressions"], "project": "spring-framework"}
{"id": 5269, "code": "\tpublic PersistenceManagedTypes scan(String... packagesToScan) {\n\t\tScanResult scanResult = new ScanResult();\n\t\tfor (String pkg : packagesToScan) {\n\t\t\tscanPackage(pkg, scanResult);\n\t\t}\n\t\treturn scanResult.toJpaManagedTypes();\n\t}", "summary_tokens": ["scan", "the", "specified", "packages", "and", "return", "a", "persistence", "managed", "types", "that", "represents", "the", "result", "of", "the", "scanning"], "project": "spring-framework"}
{"id": 4167, "code": "\tpublic SQLErrorCodes unregisterDatabase(DataSource dataSource) {\n\t\treturn this.dataSourceCache.remove(dataSource);\n\t}", "summary_tokens": ["clear", "the", "cache", "for", "the", "specified", "data", "source", "if", "registered"], "project": "spring-framework"}
{"id": 5171, "code": "\tpublic ResourceLoader getResourceLoader() {\n\t\tif (this.resourcePatternResolver == null) {\n\t\t\tthis.resourcePatternResolver = new PathMatchingResourcePatternResolver();\n\t\t}\n\t\treturn this.resourcePatternResolver;\n\t}", "summary_tokens": ["determine", "the", "spring", "resource", "loader", "to", "use", "for", "hibernate", "metadata"], "project": "spring-framework"}
{"id": 2237, "code": "\tMethodSpec getMethodSpec() {\n\t\treturn this.methodSpec;\n\t}", "summary_tokens": ["return", "the", "method", "spec", "for", "this", "generated", "method"], "project": "spring-framework"}
{"id": 9575, "code": "\tpublic void setStatusCode(HttpStatusCode statusCode) {\n\t\tthis.statusCode = statusCode;\n\t}", "summary_tokens": ["set", "the", "status", "code", "for", "this", "view"], "project": "spring-framework"}
{"id": 3374, "code": "\tdefault R apply(T t, U u, BiFunction<String, Exception, RuntimeException> exceptionWrapper) {\n\t\ttry {\n\t\t\treturn applyWithException(t, u);\n\t\t}\n\t\tcatch (RuntimeException ex) {\n\t\t\tthrow ex;\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthrow exceptionWrapper.apply(ex.getMessage(), ex);\n\t\t}\n\t}", "summary_tokens": ["applies", "this", "function", "to", "the", "given", "argument", "wrapping", "any", "thrown", "checked", "exceptions", "using", "the", "given", "exception", "wrapper"], "project": "spring-framework"}
{"id": 7074, "code": "\tprotected void touchDataBuffer(DataBuffer buffer) {\n\t}", "summary_tokens": ["allow", "subclasses", "to", "associate", "a", "hint", "with", "the", "data", "buffer", "if", "it", "is", "a", "pooled", "buffer", "and", "supports", "leak", "tracking"], "project": "spring-framework"}
{"id": 2900, "code": "\tprotected void customizePropertySources(MutablePropertySources propertySources) {\n\t\tpropertySources.addLast(\n\t\t\t\tnew PropertiesPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME, getSystemProperties()));\n\t\tpropertySources.addLast(\n\t\t\t\tnew SystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, getSystemEnvironment()));\n\t}", "summary_tokens": ["customize", "the", "set", "of", "property", "sources", "with", "those", "appropriate", "for", "any", "standard", "java", "environment", "ul", "li", "system", "properties", "property", "source", "name", "li", "system", "environment", "property", "source", "name", "ul", "p", "properties", "present", "in", "system", "properties", "property", "source", "name", "will", "take", "precedence", "over", "those", "in", "system", "environment", "property", "source", "name"], "project": "spring-framework"}
{"id": 1735, "code": "\tpublic void setProxyInterface(Class<?> proxyInterface) {\n\t\tthis.proxyInterfaces = new Class<?>[] {proxyInterface};\n\t}", "summary_tokens": ["specify", "the", "proxy", "interface", "to", "use", "for", "the", "jndi", "object"], "project": "spring-framework"}
{"id": 5817, "code": "\tpublic RequestMatcher xml(String expectedXmlContent) {\n\t\treturn new AbstractXmlRequestMatcher() {\n\t\t\t@Override\n\t\t\tprotected void matchInternal(MockClientHttpRequest request) throws Exception {\n\t\t\t\txmlHelper.assertXmlEqual(expectedXmlContent, request.getBodyAsString());\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["parse", "the", "request", "body", "and", "the", "given", "string", "as", "xml", "and", "assert", "that", "the", "two", "are", "similar", "i"], "project": "spring-framework"}
{"id": 9541, "code": "\tpublic void render(@Nullable Map<String, ?> model, HttpServletRequest request,\n\t\t\tHttpServletResponse response) throws Exception {\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"View \" + formatViewName() +\n\t\t\t\t\t\", model \" + (model != null ? model : Collections.emptyMap()) +\n\t\t\t\t\t(this.staticAttributes.isEmpty() ? \"\" : \", static attributes \" + this.staticAttributes));\n\t\t}\n\n\t\tMap<String, Object> mergedModel = createMergedOutputModel(model, request, response);\n\t\tprepareResponse(request, response);\n\t\trenderMergedOutputModel(mergedModel, getRequestToExpose(request), response);\n\t}", "summary_tokens": ["prepares", "the", "view", "given", "the", "specified", "model", "merging", "it", "with", "static", "attributes", "and", "a", "request", "context", "attribute", "if", "necessary"], "project": "spring-framework"}
{"id": 9666, "code": "\tprotected final void buildFeedEntries(Map<String, Object> model, Channel channel,\n\t\t\tHttpServletRequest request, HttpServletResponse response) throws Exception {\n\n\t\tList<Item> items = buildFeedItems(model, request, response);\n\t\tchannel.setItems(items);\n\t}", "summary_tokens": ["invokes", "build", "feed", "items", "map", "http", "servlet", "request", "http", "servlet", "response", "to", "get", "a", "list", "of", "feed", "items"], "project": "spring-framework"}
{"id": 4268, "code": "\tpublic final boolean isFrozen() {\n\t\treturn this.frozen;\n\t}", "summary_tokens": ["return", "whether", "this", "resource", "holder", "is", "frozen", "i"], "project": "spring-framework"}
{"id": 7613, "code": "\tpublic ModelMap getModel() {\n\t\tif (useDefaultModel()) {\n\t\t\treturn this.defaultModel;\n\t\t}\n\t\telse {\n\t\t\tif (this.redirectModel == null) {\n\t\t\t\tthis.redirectModel = new ModelMap();\n\t\t\t}\n\t\t\treturn this.redirectModel;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "model", "to", "use", "either", "the", "default", "or", "the", "redirect", "model"], "project": "spring-framework"}
{"id": 1078, "code": "\tprotected void postProcessJobDetail(JobDetail jobDetail) {\n\t}", "summary_tokens": ["callback", "for", "post", "processing", "the", "job", "detail", "to", "be", "exposed", "by", "this", "factory", "bean"], "project": "spring-framework"}
{"id": 2, "code": "public static String rawMembersKey(TypeMirror type) {\n  return \"members/\" + rawTypeToString(type, '$');\n}", "summary_tokens": ["returns", "the", "members", "injector", "key", "for", "the", "raw", "type", "of", "type"], "project": "dagger"}
{"id": 59, "code": "private static boolean substringStartsWith(String string, int offset, String substring) {\n  return string.regionMatches(offset, substring, 0, substring.length());\n}", "summary_tokens": ["returns", "true", "if", "string"], "project": "dagger"}
{"id": 58, "code": "private static String extractKey(String key, int start, String delegatePrefix, String prefix) {\n  return delegatePrefix + key.substring(start + prefix.length(), key.length() - 1);\n}", "summary_tokens": ["returns", "an", "unwrapped", "key", "the", "key", "for", "t", "from", "a", "provider", "t", "for", "example", "removing", "all", "wrapping", "key", "information", "but", "preserving", "annotations", "or", "known", "prefixes"], "project": "dagger"}
{"id": 61, "code": "public static String getClassName(String key) {\n  int start = 0;\n  if (key.startsWith(\"@\") || key.startsWith(\"members/\")) {\n    start = key.lastIndexOf('/') + 1;\n  }\n  return (key.indexOf('<', start) == -1 && key.indexOf('[', start) == -1)\n      ? key.substring(start)\n      : null;\n}", "summary_tokens": ["returns", "the", "class", "name", "for", "key", "if", "key", "was", "created", "with", "a", "class", "instance"], "project": "dagger"}
{"id": 25, "code": "private boolean isProvidesMethodParameter(\n    Element parameter, Map<Element, Element> parametersToTheirMethods) {\n  return parametersToTheirMethods.get(parameter).getAnnotation(Provides.class) != null;\n}", "summary_tokens": ["parameter", "an", "element", "whose", "kind", "is", "parameter"], "project": "dagger"}
{"id": 84, "code": "public void inject(Object object) {\n  activityGraph.inject(object);\n}", "summary_tokens": ["inject", "the", "supplied", "object", "using", "the", "activity", "specific", "graph"], "project": "dagger"}
{"id": 83, "code": "protected List<Object> getModules() {\n  return Arrays.<Object>asList(new ActivityModule(this));\n}", "summary_tokens": ["a", "list", "of", "modules", "to", "use", "for", "the", "individual", "activity", "graph"], "project": "dagger"}
{"id": 41, "code": "public boolean isEmpty() {\n    return head == tail;\n}", "summary_tokens": ["returns", "tt", "true", "tt", "if", "this", "queue", "contains", "no", "elements"], "project": "dagger"}
{"id": 31, "code": "private void allocateElements(int numElements) {\n    int initialCapacity = MIN_INITIAL_CAPACITY;\n        \n        \n    if (numElements >= initialCapacity) {\n        initialCapacity = numElements;\n        initialCapacity |= (initialCapacity >>>  1);\n        initialCapacity |= (initialCapacity >>>  2);\n        initialCapacity |= (initialCapacity >>>  4);\n        initialCapacity |= (initialCapacity >>>  8);\n        initialCapacity |= (initialCapacity >>> 16);\n        initialCapacity++;\n\n        if (initialCapacity < 0)   \n            initialCapacity >>>= 1; \n    }\n    elements = new Object[initialCapacity];\n}", "summary_tokens": ["allocate", "empty", "array", "to", "hold", "the", "given", "number", "of", "elements"], "project": "dagger"}
{"id": 7, "code": "private static int nextDollar(String className, CharSequence current, int searchStart) {\n  while (true) {\n    int index = className.indexOf('$', searchStart);\n    if (index == -1) {\n      return -1;\n    }\n      \n      \n    if (index == 0 || index == className.length() - 1\n        || current.charAt(index - 1) == '.' || current.charAt(index + 1) == '.') {\n      searchStart = index + 1;\n      continue;\n    }\n    return index;\n  }\n}", "summary_tokens": ["finds", "the", "next", "in", "a", "class", "name", "which", "can", "be", "changed", "to", "a"], "project": "dagger"}
{"id": 12, "code": "private void generateStaticInjection(TypeElement type, List<Element> fields) throws IOException {\n  ClassName typeName = ClassName.get(type);\n  ClassName adapterClassName = adapterName(ClassName.get(type), STATIC_INJECTION_SUFFIX);\n\n  TypeSpec.Builder result = TypeSpec.classBuilder(adapterClassName.simpleName())\n      .addOriginatingElement(type)\n      .addJavadoc(AdapterJavadocs.STATIC_INJECTION_TYPE, type)\n      .addModifiers(PUBLIC, FINAL)\n      .superclass(StaticInjection.class);\n  for (Element field : fields) {\n    result.addField(memberBindingField(false, field));\n  }\n  result.addMethod(attachMethod(null, fields, false, typeName, null, true));\n  result.addMethod(staticInjectMethod(fields, typeName));\n\n  String packageName = getPackage(type).getQualifiedName().toString();\n  JavaFile javaFile = JavaFile.builder(packageName, result.build())\n      .addFileComment(AdapterJavadocs.GENERATED_BY_DAGGER)\n      .build();\n  javaFile.writeTo(processingEnv.getFiler());\n}", "summary_tokens": ["write", "a", "companion", "class", "for", "type", "that", "extends", "static", "injection"], "project": "dagger"}
{"id": 11, "code": "private void generateInjectAdapter(TypeElement type, ExecutableElement constructor,\n    List<Element> fields) throws IOException {\n  String packageName = getPackage(type).getQualifiedName().toString();\n  TypeMirror supertype = getApplicationSupertype(type);\n  if (supertype != null) {\n    supertype = processingEnv.getTypeUtils().erasure(supertype);\n  }\n  ClassName injectedClassName = ClassName.get(type);\n  ClassName adapterClassName = adapterName(injectedClassName, INJECT_ADAPTER_SUFFIX);\n\n  boolean isAbstract = type.getModifiers().contains(ABSTRACT);\n  boolean injectMembers = !fields.isEmpty() || supertype != null;\n  boolean disambiguateFields = !fields.isEmpty()\n      && (constructor != null)\n      && !constructor.getParameters().isEmpty();\n  boolean dependent = injectMembers\n      || ((constructor != null) && !constructor.getParameters().isEmpty());\n\n  TypeSpec.Builder result = TypeSpec.classBuilder(adapterClassName.simpleName())\n      .addOriginatingElement(type)\n      .addModifiers(PUBLIC, FINAL)\n      .superclass(ParameterizedTypeName.get(ClassName.get(Binding.class), injectedClassName))\n      .addJavadoc(\"$L\", bindingTypeDocs(injectableType(type.asType()), isAbstract,\n          injectMembers, dependent).toString());\n\n  for (Element field : fields) {\n    result.addField(memberBindingField(disambiguateFields, field));\n  }\n  if (constructor != null) {\n    for (VariableElement parameter : constructor.getParameters()) {\n      result.addField(parameterBindingField(disambiguateFields, parameter));\n    }\n  }\n  if (supertype != null) {\n    result.addField(supertypeBindingField(supertype));\n  }\n\n  result.addMethod(writeInjectAdapterConstructor(constructor, type, injectedClassName));\n  if (dependent) {\n    result.addMethod(attachMethod(\n        constructor, fields, disambiguateFields, injectedClassName, supertype, true));\n    result.addMethod(getDependenciesMethod(\n        constructor, fields, disambiguateFields, supertype, true));\n  }\n  if (constructor != null) {\n    result.addMethod(\n        getMethod(constructor, disambiguateFields, injectMembers, injectedClassName));\n  }\n  if (injectMembers) {\n    result.addMethod(\n        membersInjectMethod(fields, disambiguateFields, injectedClassName, supertype));\n  }\n\n  JavaFile javaFile = JavaFile.builder(packageName, result.build())\n      .addFileComment(AdapterJavadocs.GENERATED_BY_DAGGER)\n      .build();\n  javaFile.writeTo(processingEnv.getFiler());\n}", "summary_tokens": ["write", "a", "companion", "class", "for", "type", "that", "extends", "binding"], "project": "dagger"}
{"id": 6, "code": "private static TypeElement resolveType(Elements elements, String className, StringBuilder sb,\n    final int index) {\n\n    \n  sb.setCharAt(index, '.');\n  int nextIndex = nextDollar(className, sb, index + 1);\n  TypeElement type = nextIndex == -1\n      ? getTypeElement(elements, sb)\n      : resolveType(elements, className, sb, nextIndex);\n  if (type != null) {\n    return type;\n  }\n\n    \n  sb.setCharAt(index, '$');\n  nextIndex = nextDollar(className, sb, index + 1);\n  return nextIndex == -1\n      ? getTypeElement(elements, sb)\n      : resolveType(elements, className, sb, nextIndex);\n}", "summary_tokens": ["recursively", "explores", "the", "space", "of", "possible", "canonical", "names", "for", "a", "given", "binary", "class", "name"], "project": "dagger"}
{"id": 69, "code": "public Binding<?> requestBinding(String key, Object requiredBy, ClassLoader classLoader,\n    boolean mustHaveInjections, boolean library) {\n  assertLockHeld();\n\n  Binding<?> binding = null;\n  for (Linker linker = this; linker != null; linker = linker.base) {\n    binding = linker.bindings.get(key);\n    if (binding != null) {\n      if (linker != this && !binding.isLinked()) throw new AssertionError();\n      break;\n    }\n  }\n\n  if (binding == null) {\n      \n    Binding<?> deferredBinding =\n        new DeferredBinding(key, classLoader, requiredBy, mustHaveInjections);\n    deferredBinding.setLibrary(library);\n    deferredBinding.setDependedOn(true);\n    toLink.add(deferredBinding);\n    attachSuccess = false;\n    return null;\n  }\n\n  if (!binding.isLinked()) {\n    toLink.add(binding); \n  }\n\n  binding.setLibrary(library);\n  binding.setDependedOn(true);\n  return binding;\n}", "summary_tokens": ["returns", "the", "binding", "if", "it", "exists", "immediately"], "project": "dagger"}
{"id": 49, "code": "@Override public <T> ModuleAdapter<T> getModuleAdapter(Class<T> type) {\n  return (ModuleAdapter<T>) loadedAdapters.get(type);\n}", "summary_tokens": ["obtains", "a", "module", "adapter", "for", "module", "from", "the", "first", "responding", "resolver"], "project": "dagger"}
{"id": 38, "code": "public E peek() {\n    @SuppressWarnings(\"unchecked\") E result = (E) elements[head];\n        \n    return result;\n}", "summary_tokens": ["retrieves", "but", "does", "not", "remove", "the", "head", "of", "the", "queue", "represented", "by", "this", "queue", "or", "returns", "tt", "null", "tt", "if", "this", "queue", "is", "empty"], "project": "dagger"}
{"id": 63, "code": "public void installBindings(BindingsGroup toInstall) {\n  if (linkedBindings != null) {\n    throw new IllegalStateException(\"Cannot install further bindings after calling linkAll().\");\n  }\n  for (Map.Entry<String, ? extends Binding<?>> entry : toInstall.entrySet()) {\n    bindings.put(entry.getKey(), scope(entry.getValue()));\n  }\n}", "summary_tokens": ["adds", "all", "bindings", "in", "to", "install"], "project": "dagger"}
{"id": 457, "code": "\tpublic ServerHttpSecurity requestCache(Customizer<RequestCacheSpec> requestCacheCustomizer) {\n\t\trequestCacheCustomizer.customize(this.requestCache);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "the", "request", "cache", "which", "is", "used", "when", "a", "flow", "is", "interrupted", "i"], "project": "spring-security"}
{"id": 1404, "code": "\tdefault <A> List<A> getAttribute(String name) {\n\t\treturn (List<A>) getAttributes().get(name);\n\t}", "summary_tokens": ["get", "the", "saml", "0", "token", "attribute", "by", "name", "name", "the", "name", "of", "the", "attribute", "a", "the", "type", "of", "the", "attribute", "the", "attribute", "or", "null", "otherwise", "0"], "project": "spring-security"}
{"id": 15, "code": "\tprivate Map<ObjectIdentity, Acl> lookupObjectIdentities(final Collection<ObjectIdentity> objectIdentities,\n\t\t\tList<Sid> sids) {\n\t\tAssert.notEmpty(objectIdentities, \"Must provide identities to lookup\");\n\n\t\t\n\t\tMap<Serializable, Acl> acls = new HashMap<>();\n\n\t\t\n\t\t\n\t\tString sql = computeRepeatingSql(this.lookupObjectIdentitiesWhereClause, objectIdentities.size());\n\n\t\tSet<Long> parentsToLookup = this.jdbcTemplate.query(sql,\n\t\t\t\t(ps) -> setupLookupObjectIdentitiesStatement(ps, objectIdentities), new ProcessResultSet(acls, sids));\n\n\t\t\n\t\t\n\t\tif (parentsToLookup.size() > 0) {\n\t\t\tlookupPrimaryKeys(acls, parentsToLookup, sids);\n\t\t}\n\n\t\t\n\t\tMap<ObjectIdentity, Acl> resultMap = new HashMap<>();\n\t\tfor (Acl inputAcl : acls.values()) {\n\t\t\tAssert.isInstanceOf(AclImpl.class, inputAcl, \"Map should have contained an AclImpl\");\n\t\t\tAssert.isInstanceOf(Long.class, ((AclImpl) inputAcl).getId(), \"Acl.getId() must be Long\");\n\t\t\tAcl result = convert(acls, (Long) ((AclImpl) inputAcl).getId());\n\t\t\tresultMap.put(result.getObjectIdentity(), result);\n\t\t}\n\n\t\treturn resultMap;\n\t}", "summary_tokens": ["looks", "up", "a", "batch", "of", "code", "object", "identity", "code", "s", "directly", "from", "the", "database"], "project": "spring-security"}
{"id": 175, "code": "\tpublic WebInvocationPrivilegeEvaluator getPrivilegeEvaluator() {\n\t\treturn this.privilegeEvaluator;\n\t}", "summary_tokens": ["gets", "the", "web", "invocation", "privilege", "evaluator", "to", "be", "used"], "project": "spring-security"}
{"id": 2036, "code": "\tfinal Class<? extends Throwable>[] getRegisteredTypes() {\n\t\tSet<Class<? extends Throwable>> typeList = this.extractorMap.keySet();\n\t\treturn typeList.toArray(new Class[0]);\n\t}", "summary_tokens": ["returns", "an", "array", "containing", "the", "classes", "for", "which", "extractors", "are", "registered"], "project": "spring-security"}
{"id": 953, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock cannot be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["sets", "the", "clock", "used", "in", "instant", "now", "clock", "when", "checking", "the", "access", "token", "expiry"], "project": "spring-security"}
{"id": 1351, "code": "\tpublic void setAuthorityPrefix(String authorityPrefix) {\n\t\tAssert.notNull(authorityPrefix, \"authorityPrefix cannot be null\");\n\t\tthis.authorityPrefix = authorityPrefix;\n\t}", "summary_tokens": ["sets", "the", "prefix", "to", "use", "for", "granted", "authority", "authorities", "mapped", "by", "this", "converter"], "project": "spring-security"}
{"id": 392, "code": "\tpublic String getRolePrefix() {\n\t\treturn this.rolePrefix;\n\t}", "summary_tokens": ["the", "default", "prefix", "used", "with", "role", "based", "authorization"], "project": "spring-security"}
{"id": 1726, "code": "\tpublic void setApplicationEventPublisher(ApplicationEventPublisher applicationEventPublisher) {\n\t\tAssert.notNull(applicationEventPublisher, \"applicationEventPublisher cannot be null\");\n\t\tthis.applicationEventPublisher = applicationEventPublisher;\n\t}", "summary_tokens": ["sets", "the", "application", "event", "publisher", "to", "use", "for", "submitting", "session", "fixation", "protection", "event"], "project": "spring-security"}
{"id": 104, "code": "\tpublic JdbcUserDetailsManagerConfigurer<B> groupAuthoritiesByUsername(String query) {\n\t\tJdbcUserDetailsManager userDetailsService = getUserDetailsService();\n\t\tuserDetailsService.setEnableGroups(true);\n\t\tuserDetailsService.setGroupAuthoritiesByUsernameQuery(query);\n\t\treturn this;\n\t}", "summary_tokens": ["an", "sql", "statement", "to", "query", "user", "s", "group", "authorities", "given", "a", "username"], "project": "spring-security"}
{"id": 1252, "code": "\tdefault String getSubject() {\n\t\treturn this.getClaimAsString(IdTokenClaimNames.SUB);\n\t}", "summary_tokens": ["returns", "the", "subject", "identifier", "sub"], "project": "spring-security"}
{"id": 1109, "code": "\tpublic String getClientName() {\n\t\treturn this.clientName;\n\t}", "summary_tokens": ["returns", "the", "logical", "name", "of", "the", "client", "or", "registration"], "project": "spring-security"}
{"id": 2056, "code": "\tpublic void doFilterDefaultRequireCsrfProtectionMatcherAllowedMethodsCaseSensitive() throws Exception {\n\t\tthis.filter = new CsrfFilter(this.tokenRepository);\n\t\tthis.filter.setAccessDeniedHandler(this.deniedHandler);\n\t\tfor (String method : Arrays.asList(\"get\", \"TrAcE\", \"oPTIOnS\", \"hEaD\")) {\n\t\t\tresetRequestResponse();\n\t\t\tgiven(this.tokenRepository.loadToken(this.request)).willReturn(this.token);\n\t\t\tthis.request.setMethod(method);\n\t\t\tthis.filter.doFilter(this.request, this.response, this.filterChain);\n\t\t\tverify(this.deniedHandler).handle(eq(this.request), eq(this.response),\n\t\t\t\t\tany(InvalidCsrfTokenException.class));\n\t\t\tverifyNoMoreInteractions(this.filterChain);\n\t\t}\n\t}", "summary_tokens": ["sec", "0", "should", "not", "allow", "other", "cases", "through", "since", "spec", "states", "http", "method", "is", "case", "sensitive", "https", "www"], "project": "spring-security"}
{"id": 1774, "code": "\tprotected final void appendFilters(ServletContext servletContext, Filter... filters) {\n\t\tregisterFilters(servletContext, false, filters);\n\t}", "summary_tokens": ["inserts", "the", "provided", "filter", "s", "after", "existing", "filter", "s", "using", "default", "generated", "names", "get", "security", "dispatcher", "types", "and", "is", "async", "security", "supported"], "project": "spring-security"}
{"id": 1523, "code": "\tpublic static MockServerConfigurer springSecurity() {\n\t\treturn new MockServerConfigurer() {\n\n\t\t\t@Override\n\t\t\tpublic void beforeServerCreated(WebHttpHandlerBuilder builder) {\n\t\t\t\tbuilder.filters((filters) -> filters.add(0, new MutatorFilter()));\n\t\t\t}\n\n\t\t};\n\t}", "summary_tokens": ["sets", "up", "spring", "security", "s", "web", "test", "client", "test", "support", "the", "mock", "server", "configurer", "to", "use"], "project": "spring-security"}
{"id": 698, "code": "\tprivate String generatePseudoRandomNumber() {\n\t\tbyte[] randomBytes = new byte[this.pseudoRandomNumberBytes];\n\t\tthis.secureRandom.nextBytes(randomBytes);\n\t\treturn new String(Hex.encode(randomBytes));\n\t}", "summary_tokens": ["a", "pseduo", "random", "number", "hex", "encoded"], "project": "spring-security"}
{"id": 680, "code": "\tpublic static Context withAuthentication(Authentication authentication) {\n\t\treturn withSecurityContext(Mono.just(new SecurityContextImpl(authentication)));\n\t}", "summary_tokens": ["a", "shortcut", "for", "with", "security", "context", "mono", "authentication", "the", "authentication", "to", "be", "used", "a", "reactor", "context", "that", "contains", "the", "mono", "security", "context"], "project": "spring-security"}
{"id": 57, "code": "\tpublic <C extends SecurityConfigurer<O, B>> C getConfigurer(Class<C> clazz) {\n\t\tList<SecurityConfigurer<O, B>> configs = this.configurers.get(clazz);\n\t\tif (configs == null) {\n\t\t\treturn null;\n\t\t}\n\t\tAssert.state(configs.size() == 1,\n\t\t\t\t() -> \"Only one configurer expected for type \" + clazz + \", but got \" + configs);\n\t\treturn (C) configs.get(0);\n\t}", "summary_tokens": ["gets", "the", "security", "configurer", "by", "its", "class", "name", "or", "code", "null", "code", "if", "not", "found"], "project": "spring-security"}
{"id": 246, "code": "\tprivate String getUsernameParameter() {\n\t\treturn getAuthenticationFilter().getUsernameParameter();\n\t}", "summary_tokens": ["gets", "the", "http", "parameter", "that", "is", "used", "to", "submit", "the", "username"], "project": "spring-security"}
{"id": 586, "code": "\tpublic void setTrustResolver(AuthenticationTrustResolver trustResolver) {\n\t\tthis.authorizationStrategy.setTrustResolver(trustResolver);\n\t}", "summary_tokens": ["sets", "the", "authentication", "trust", "resolver", "to", "be", "used"], "project": "spring-security"}
{"id": 1686, "code": "\tpublic void setMappableRolesRetriever(MappableAttributesRetriever aJ2eeMappableRolesRetriever) {\n\t\tthis.j2eeMappableRoles = Collections.unmodifiableSet(aJ2eeMappableRolesRetriever.getMappableAttributes());\n\t}", "summary_tokens": ["a", "j", "0", "ee", "mappable", "roles", "retriever", "the", "mappable", "attributes", "retriever", "to", "use"], "project": "spring-security"}
{"id": 1962, "code": "\tpublic void setCookiePath(String cookiePath) {\n\t\tthis.cookiePath = cookiePath;\n\t}", "summary_tokens": ["sets", "the", "cookie", "path", "cookie", "path", "the", "cookie", "path"], "project": "spring-security"}
{"id": 1567, "code": "\tpublic void setRequestRejectedHandler(RequestRejectedHandler requestRejectedHandler) {\n\t\tAssert.notNull(requestRejectedHandler, \"requestRejectedHandler may not be null\");\n\t\tthis.requestRejectedHandler = requestRejectedHandler;\n\t}", "summary_tokens": ["sets", "the", "request", "rejected", "handler", "to", "be", "used", "for", "requests", "rejected", "by", "the", "firewall"], "project": "spring-security"}
{"id": 465, "code": "\tpublic void logoutWhenUsingSuccessHandlerRefThenMatchesNamespace() throws Exception {\n\t\tthis.spring.register(SuccessHandlerRefHttpLogoutConfig.class).autowire();\n\t\t\n\t\tthis.mvc.perform(post(\"/logout\").with(csrf()))\n\t\t\t\t.andExpect(authenticated(false))\n\t\t\t\t.andExpect(redirectedUrl(\"/SuccessHandlerRefHttpLogoutConfig\"))\n\t\t\t\t.andExpect(noCookies())\n\t\t\t\t.andExpect(session(Objects::isNull));\n\t\t\n\t}", "summary_tokens": ["http", "logout", "handler", "ref"], "project": "spring-security"}
{"id": 1657, "code": "\tprotected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response,\n\t\t\tAuthenticationException failed) throws IOException, ServletException {\n\t\tthis.securityContextHolderStrategy.clearContext();\n\t\tthis.logger.debug(\"Cleared security context due to exception\", failed);\n\t\trequest.setAttribute(WebAttributes.AUTHENTICATION_EXCEPTION, failed);\n\t\tif (this.authenticationFailureHandler != null) {\n\t\t\tthis.authenticationFailureHandler.onAuthenticationFailure(request, response, failed);\n\t\t}\n\t}", "summary_tokens": ["ensures", "the", "authentication", "object", "in", "the", "secure", "context", "is", "set", "to", "null", "when", "authentication", "fails"], "project": "spring-security"}
{"id": 1766, "code": "\tstatic String[] split(String toSplit, String delimiter) {\n\t\tAssert.hasLength(toSplit, \"Cannot split a null or empty string\");\n\t\tAssert.hasLength(delimiter, \"Cannot use a null or empty delimiter to split a string\");\n\t\tAssert.isTrue(delimiter.length() == 1, \"Delimiter can only be one character in length\");\n\t\tint offset = toSplit.indexOf(delimiter);\n\t\tif (offset < 0) {\n\t\t\treturn null;\n\t\t}\n\t\tString beforeDelimiter = toSplit.substring(0, offset);\n\t\tString afterDelimiter = toSplit.substring(offset + 1);\n\t\treturn new String[] { beforeDelimiter, afterDelimiter };\n\t}", "summary_tokens": ["splits", "a", "code", "string", "code", "at", "the", "first", "instance", "of", "the", "delimiter"], "project": "spring-security"}
{"id": 295, "code": "\tprivate PortMapper getPortMapper() {\n\t\tif (this.portMapper == null) {\n\t\t\tPortMapperImpl portMapper = new PortMapperImpl();\n\t\t\tportMapper.setPortMappings(this.httpsPortMappings);\n\t\t\tthis.portMapper = portMapper;\n\t\t}\n\t\treturn this.portMapper;\n\t}", "summary_tokens": ["gets", "the", "port", "mapper", "to", "use"], "project": "spring-security"}
{"id": 296, "code": "\tpublic RememberMeConfigurer<H> useSecureCookie(boolean useSecureCookie) {\n\t\tthis.useSecureCookie = useSecureCookie;\n\t\treturn this;\n\t}", "summary_tokens": ["whether", "the", "cookie", "should", "be", "flagged", "as", "secure", "or", "not"], "project": "spring-security"}
{"id": 579, "code": "\tpublic boolean commit() {\n\t\tif (this.authen == null) {\n\t\t\treturn false;\n\t\t}\n\t\tthis.subject.getPrincipals().add(this.authen);\n\t\treturn true;\n\t}", "summary_tokens": ["authenticate", "the", "code", "subject", "code", "phase", "two", "by", "adding", "the", "spring", "security", "code", "authentication", "code", "to", "the", "code", "subject", "code", "s", "principals"], "project": "spring-security"}
{"id": 382, "code": "\tpublic Constraint simpSubscribeDestMatchers(String... patterns) {\n\t\treturn simpDestMatchers(SimpMessageType.SUBSCRIBE, patterns);\n\t}", "summary_tokens": ["maps", "a", "list", "of", "simp", "destination", "message", "matcher", "instances", "that", "match", "on", "simp", "message", "type"], "project": "spring-security"}
{"id": 739, "code": "\tpublic static MethodInvocation create(Object object, String methodName, Object... args) {\n\t\tAssert.notNull(object, \"Object required\");\n\t\tClass<?>[] classArgs = null;\n\t\tif (args != null) {\n\t\t\tclassArgs = new Class<?>[args.length];\n\t\t\tfor (int i = 0; i < args.length; i++) {\n\t\t\t\tclassArgs[i] = args[i].getClass();\n\t\t\t}\n\t\t}\n\t\t\n\t\t\n\t\tClass<?> target = AopUtils.getTargetClass(object);\n\t\tif (object instanceof Advised) {\n\t\t\tAdvised a = (Advised) object;\n\t\t\tif (!a.isProxyTargetClass()) {\n\t\t\t\tClass<?>[] possibleInterfaces = a.getProxiedInterfaces();\n\t\t\t\tfor (Class<?> possibleInterface : possibleInterfaces) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tpossibleInterface.getMethod(methodName, classArgs);\n\t\t\t\t\t\t\n\t\t\t\t\t\ttarget = possibleInterface;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn createFromClass(object, target, methodName, classArgs, args);\n\t}", "summary_tokens": ["generates", "a", "code", "method", "invocation", "code", "for", "specified", "code", "method", "name", "code", "on", "the", "passed", "object", "using", "the", "code", "args", "code", "to", "locate", "the", "method"], "project": "spring-security"}
{"id": 93, "code": "\tpublic LdapAuthenticationProviderConfigurer<B> groupRoleAttribute(String groupRoleAttribute) {\n\t\tthis.groupRoleAttribute = groupRoleAttribute;\n\t\treturn this;\n\t}", "summary_tokens": ["specifies", "the", "attribute", "name", "which", "contains", "the", "role", "name"], "project": "spring-security"}
{"id": 1315, "code": "\tpublic JwsHeader getJwsHeader() {\n\t\treturn this.jwsHeader;\n\t}", "summary_tokens": ["returns", "the", "jws", "header", "jws", "headers"], "project": "spring-security"}
{"id": 1936, "code": "\tprotected Mono<Authentication> switchUser(WebFilterExchange webFilterExchange) {\n\t\treturn this.switchUserMatcher.matches(webFilterExchange.getExchange())\n\t\t\t\t.filter(ServerWebExchangeMatcher.MatchResult::isMatch)\n\t\t\t\t.flatMap((matchResult) -> ReactiveSecurityContextHolder.getContext())\n\t\t\t\t.map(SecurityContext::getAuthentication).flatMap((currentAuthentication) -> {\n\t\t\t\t\tString username = getUsername(webFilterExchange.getExchange());\n\t\t\t\t\treturn attemptSwitchUser(currentAuthentication, username);\n\t\t\t\t}).onErrorResume(AuthenticationException.class, (ex) -> onAuthenticationFailure(ex, webFilterExchange)\n\t\t\t\t\t\t.then(Mono.error(new SwitchUserAuthenticationException(ex))));\n\t}", "summary_tokens": ["attempt", "to", "switch", "to", "another", "user"], "project": "spring-security"}
{"id": 1349, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["the", "principal", "name", "which", "is", "by", "default", "the", "jwt", "s", "subject"], "project": "spring-security"}
{"id": 298, "code": "\tpublic RememberMeConfigurer<H> tokenRepository(PersistentTokenRepository tokenRepository) {\n\t\tthis.tokenRepository = tokenRepository;\n\t\treturn this;\n\t}", "summary_tokens": ["specifies", "the", "persistent", "token", "repository", "to", "use"], "project": "spring-security"}
{"id": 1721, "code": "\tpublic void setMatchingAlgorithm(RememberMeTokenAlgorithm matchingAlgorithm) {\n\t\tAssert.notNull(matchingAlgorithm, \"matchingAlgorithm cannot be null\");\n\t\tthis.matchingAlgorithm = matchingAlgorithm;\n\t}", "summary_tokens": ["sets", "the", "algorithm", "to", "be", "used", "to", "match", "the", "token", "signature", "matching", "algorithm", "the", "matching", "algorithm", "0"], "project": "spring-security"}
{"id": 1901, "code": "\tpublic boolean hasMoreElements() {\n\t\treturn (this.iterator.hasNext());\n\t}", "summary_tokens": ["tests", "if", "this", "enumeration", "contains", "more", "elements"], "project": "spring-security"}
{"id": 1108, "code": "\tpublic ProviderDetails getProviderDetails() {\n\t\treturn this.providerDetails;\n\t}", "summary_tokens": ["returns", "the", "details", "of", "the", "provider"], "project": "spring-security"}
{"id": 864, "code": "\tpublic boolean hasError() {\n\t\treturn this.errorStatus != null;\n\t}", "summary_tokens": ["checks", "whether", "an", "error", "is", "present"], "project": "spring-security"}
{"id": 732, "code": "\tpublic UsernamePasswordAuthenticationToken deserialize(JsonParser jp, DeserializationContext ctxt)\n\t\t\tthrows IOException, JsonProcessingException {\n\t\tObjectMapper mapper = (ObjectMapper) jp.getCodec();\n\t\tJsonNode jsonNode = mapper.readTree(jp);\n\t\tBoolean authenticated = readJsonNode(jsonNode, \"authenticated\").asBoolean();\n\t\tJsonNode principalNode = readJsonNode(jsonNode, \"principal\");\n\t\tObject principal = getPrincipal(mapper, principalNode);\n\t\tJsonNode credentialsNode = readJsonNode(jsonNode, \"credentials\");\n\t\tObject credentials = getCredentials(credentialsNode);\n\t\tList<GrantedAuthority> authorities = mapper.readValue(readJsonNode(jsonNode, \"authorities\").traverse(mapper),\n\t\t\t\tGRANTED_AUTHORITY_LIST);\n\t\tUsernamePasswordAuthenticationToken token = (!authenticated)\n\t\t\t\t? UsernamePasswordAuthenticationToken.unauthenticated(principal, credentials)\n\t\t\t\t: UsernamePasswordAuthenticationToken.authenticated(principal, credentials, authorities);\n\t\tJsonNode detailsNode = readJsonNode(jsonNode, \"details\");\n\t\tif (detailsNode.isNull() || detailsNode.isMissingNode()) {\n\t\t\ttoken.setDetails(null);\n\t\t}\n\t\telse {\n\t\t\tObject details = mapper.readValue(detailsNode.toString(), OBJECT);\n\t\t\ttoken.setDetails(details);\n\t\t}\n\t\treturn token;\n\t}", "summary_tokens": ["this", "method", "construct", "username", "password", "authentication", "token", "object", "from", "serialized", "json"], "project": "spring-security"}
{"id": 118, "code": "\tprotected AccessDecisionManager accessDecisionManager() {\n\t\tList<AccessDecisionVoter<?>> decisionVoters = new ArrayList<>();\n\t\tif (prePostEnabled()) {\n\t\t\tExpressionBasedPreInvocationAdvice expressionAdvice = new ExpressionBasedPreInvocationAdvice();\n\t\t\texpressionAdvice.setExpressionHandler(getExpressionHandler());\n\t\t\tdecisionVoters.add(new PreInvocationAuthorizationAdviceVoter(expressionAdvice));\n\t\t}\n\t\tif (jsr250Enabled()) {\n\t\t\tdecisionVoters.add(new Jsr250Voter());\n\t\t}\n\t\tRoleVoter roleVoter = new RoleVoter();\n\t\tGrantedAuthorityDefaults grantedAuthorityDefaults = getSingleBeanOrNull(GrantedAuthorityDefaults.class);\n\t\tif (grantedAuthorityDefaults != null) {\n\t\t\troleVoter.setRolePrefix(grantedAuthorityDefaults.getRolePrefix());\n\t\t}\n\t\tdecisionVoters.add(roleVoter);\n\t\tdecisionVoters.add(new AuthenticatedVoter());\n\t\treturn new AffirmativeBased(decisionVoters);\n\t}", "summary_tokens": ["allows", "subclasses", "to", "provide", "a", "custom", "access", "decision", "manager"], "project": "spring-security"}
{"id": 1681, "code": "\tprotected Object getPreAuthenticatedCredentials(HttpServletRequest request) {\n\t\tif (this.credentialsRequestHeader != null) {\n\t\t\treturn request.getHeader(this.credentialsRequestHeader);\n\t\t}\n\t\treturn \"N/A\";\n\t}", "summary_tokens": ["credentials", "aren", "t", "usually", "applicable", "but", "if", "a", "credentials", "request", "header", "is", "set", "this", "will", "be", "read", "and", "used", "as", "the", "credentials", "value"], "project": "spring-security"}
{"id": 1972, "code": "\tpublic void setPolicyDirectives(String policyDirectives) {\n\t\tAssert.hasLength(policyDirectives, \"policyDirectives must not be null or empty\");\n\t\tthis.policyDirectives = policyDirectives;\n\t\tthis.delegate = createDelegate();\n\t}", "summary_tokens": ["set", "the", "policy", "directive", "s", "to", "be", "used", "in", "the", "response", "header"], "project": "spring-security"}
{"id": 762, "code": "\tpublic static String hashpw(byte passwordb[], String salt) {\n\t\treturn hashpw(passwordb, salt, false);\n\t}", "summary_tokens": ["hash", "a", "password", "using", "the", "open", "bsd", "bcrypt", "scheme", "passwordb", "the", "password", "to", "hash", "as", "a", "byte", "array", "salt", "the", "salt", "to", "hash", "with", "perhaps", "generated", "using", "bcrypt"], "project": "spring-security"}
{"id": 186, "code": "\tprotected UserDetailsService userDetailsService() {\n\t\tAuthenticationManagerBuilder globalAuthBuilder = this.context.getBean(AuthenticationManagerBuilder.class);\n\t\treturn new UserDetailsServiceDelegator(Arrays.asList(this.localConfigureAuthenticationBldr, globalAuthBuilder));\n\t}", "summary_tokens": ["allows", "modifying", "and", "accessing", "the", "user", "details", "service", "from", "user", "details", "service", "bean", "without", "interacting", "with", "the", "application", "context"], "project": "spring-security"}
{"id": 1790, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy strategy) {\n\t\tthis.securityContextHolderStrategy = strategy;\n\t\tthis.contextObject = this.securityContextHolderStrategy.createEmptyContext();\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 274, "code": "\tprivate J2eePreAuthenticatedProcessingFilter getFilter(AuthenticationManager authenticationManager, H http) {\n\t\tif (this.j2eePreAuthenticatedProcessingFilter == null) {\n\t\t\tthis.j2eePreAuthenticatedProcessingFilter = new J2eePreAuthenticatedProcessingFilter();\n\t\t\tthis.j2eePreAuthenticatedProcessingFilter.setAuthenticationManager(authenticationManager);\n\t\t\tthis.j2eePreAuthenticatedProcessingFilter\n\t\t\t\t\t.setAuthenticationDetailsSource(createWebAuthenticationDetailsSource());\n\t\t\tthis.j2eePreAuthenticatedProcessingFilter\n\t\t\t\t\t.setSecurityContextHolderStrategy(getSecurityContextHolderStrategy());\n\t\t\tthis.j2eePreAuthenticatedProcessingFilter = postProcess(this.j2eePreAuthenticatedProcessingFilter);\n\t\t}\n\n\t\treturn this.j2eePreAuthenticatedProcessingFilter;\n\t}", "summary_tokens": ["gets", "the", "j", "0", "ee", "pre", "authenticated", "processing", "filter", "or", "creates", "a", "default", "instance", "using", "the", "properties", "provided"], "project": "spring-security"}
{"id": 1016, "code": "\tpublic Mono<OAuth2AuthorizedClient> authorize(OAuth2AuthorizationContext context) {\n\t\tAssert.notNull(context, \"context cannot be null\");\n\t\tOAuth2AuthorizedClient authorizedClient = context.getAuthorizedClient();\n\t\tif (authorizedClient == null || authorizedClient.getRefreshToken() == null\n\t\t\t\t|| !hasTokenExpired(authorizedClient.getAccessToken())) {\n\t\t\treturn Mono.empty();\n\t\t}\n\t\tObject requestScope = context.getAttribute(OAuth2AuthorizationContext.REQUEST_SCOPE_ATTRIBUTE_NAME);\n\t\tSet<String> scopes = Collections.emptySet();\n\t\tif (requestScope != null) {\n\t\t\tAssert.isInstanceOf(String[].class, requestScope, \"The context attribute must be of type String[] '\"\n\t\t\t\t\t+ OAuth2AuthorizationContext.REQUEST_SCOPE_ATTRIBUTE_NAME + \"'\");\n\t\t\tscopes = new HashSet<>(Arrays.asList((String[]) requestScope));\n\t\t}\n\t\tClientRegistration clientRegistration = context.getClientRegistration();\n\t\tOAuth2RefreshTokenGrantRequest refreshTokenGrantRequest = new OAuth2RefreshTokenGrantRequest(clientRegistration,\n\t\t\t\tauthorizedClient.getAccessToken(), authorizedClient.getRefreshToken(), scopes);\n\t\treturn Mono.just(refreshTokenGrantRequest).flatMap(this.accessTokenResponseClient::getTokenResponse)\n\t\t\t\t.onErrorMap(OAuth2AuthorizationException.class,\n\t\t\t\t\t\t(e) -> new ClientAuthorizationException(e.getError(), clientRegistration.getRegistrationId(),\n\t\t\t\t\t\t\t\te))\n\t\t\t\t.map((tokenResponse) -> new OAuth2AuthorizedClient(clientRegistration, context.getPrincipal().getName(),\n\t\t\t\t\t\ttokenResponse.getAccessToken(), tokenResponse.getRefreshToken()));\n\t}", "summary_tokens": ["attempt", "to", "re", "authorize", "the", "oauth", "0", "authorization", "context", "get", "client", "registration", "client", "in", "the", "provided", "context"], "project": "spring-security"}
{"id": 299, "code": "\tpublic RememberMeConfigurer<H> key(String key) {\n\t\tthis.key = key;\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "key", "to", "identify", "tokens", "created", "for", "remember", "me", "authentication"], "project": "spring-security"}
{"id": 540, "code": "\tpublic void setScheduler(Scheduler scheduler) {\n\t\tAssert.notNull(scheduler, \"scheduler cannot be null\");\n\t\tthis.scheduler = scheduler;\n\t}", "summary_tokens": ["sets", "the", "scheduler", "used", "by", "the", "user", "details", "repository", "reactive", "authentication", "manager"], "project": "spring-security"}
{"id": 695, "code": "\tprivate <T extends AccessibleObject> String[] lookupParameterNames(ParameterNameFactory<T> parameterNameFactory,\n\t\t\tT t) {\n\t\tAnnotation[][] parameterAnnotations = parameterNameFactory.findParameterAnnotations(t);\n\t\tint parameterCount = parameterAnnotations.length;\n\t\tString[] paramNames = new String[parameterCount];\n\t\tboolean found = false;\n\t\tfor (int i = 0; i < parameterCount; i++) {\n\t\t\tAnnotation[] annotations = parameterAnnotations[i];\n\t\t\tString parameterName = findParameterName(annotations);\n\t\t\tif (parameterName != null) {\n\t\t\t\tfound = true;\n\t\t\t\tparamNames[i] = parameterName;\n\t\t\t}\n\t\t}\n\t\treturn found ? paramNames : null;\n\t}", "summary_tokens": ["gets", "the", "parameter", "names", "or", "null", "if", "not", "found"], "project": "spring-security"}
{"id": 523, "code": "\tpublic Object invoke(JoinPoint jp, AspectJCallback advisorProceed) {\n\t\tInterceptorStatusToken token = super.beforeInvocation(new MethodInvocationAdapter(jp));\n\t\tObject result;\n\t\ttry {\n\t\t\tresult = advisorProceed.proceedWithObject();\n\t\t}\n\t\tfinally {\n\t\t\tsuper.finallyInvocation(token);\n\t\t}\n\t\treturn super.afterInvocation(token, result);\n\t}", "summary_tokens": ["method", "that", "is", "suitable", "for", "user", "with", "traditional", "aspect", "j", "code", "aspects"], "project": "spring-security"}
{"id": 1939, "code": "\tprivate Optional<Authentication> extractSourceAuthentication(Authentication currentAuthentication) {\n\t\t\n\t\tfor (GrantedAuthority authority : currentAuthentication.getAuthorities()) {\n\t\t\tif (authority instanceof SwitchUserGrantedAuthority) {\n\t\t\t\tSwitchUserGrantedAuthority switchAuthority = (SwitchUserGrantedAuthority) authority;\n\t\t\t\treturn Optional.of(switchAuthority.getSource());\n\t\t\t}\n\t\t}\n\t\treturn Optional.empty();\n\t}", "summary_tokens": ["find", "the", "original", "code", "authentication", "code", "object", "from", "the", "current", "user", "s", "granted", "authorities"], "project": "spring-security"}
{"id": 128, "code": "\tpublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {\n\t\tBeanDefinitionBuilder advisor = BeanDefinitionBuilder\n\t\t\t\t.rootBeanDefinition(MethodSecurityMetadataSourceAdvisor.class);\n\t\tadvisor.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\tadvisor.addConstructorArgValue(\"methodSecurityInterceptor\");\n\t\tadvisor.addConstructorArgReference(\"methodSecurityMetadataSource\");\n\t\tadvisor.addConstructorArgValue(\"methodSecurityMetadataSource\");\n\t\tMultiValueMap<String, Object> attributes = importingClassMetadata\n\t\t\t\t.getAllAnnotationAttributes(EnableGlobalMethodSecurity.class.getName());\n\t\tInteger order = (Integer) attributes.getFirst(\"order\");\n\t\tif (order != null) {\n\t\t\tadvisor.addPropertyValue(\"order\", order);\n\t\t}\n\t\tregistry.registerBeanDefinition(\"metaDataSourceAdvisor\", advisor.getBeanDefinition());\n\t}", "summary_tokens": ["register", "escalate", "and", "configure", "the", "aspect", "j", "auto", "proxy", "creator", "based", "on", "the", "value", "of", "the", "enable", "global", "method", "security", "proxy", "target", "class", "attribute", "on", "the", "importing", "class"], "project": "spring-security"}
{"id": 1164, "code": "\tpublic final void setAuthorizationRequestCustomizer(\n\t\t\tConsumer<OAuth2AuthorizationRequest.Builder> authorizationRequestCustomizer) {\n\t\tAssert.notNull(authorizationRequestCustomizer, \"authorizationRequestCustomizer cannot be null\");\n\t\tthis.authorizationRequestCustomizer = authorizationRequestCustomizer;\n\t}", "summary_tokens": ["sets", "the", "consumer", "to", "be", "provided", "the", "oauth", "0", "authorization", "request"], "project": "spring-security"}
{"id": 998, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock cannot be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["sets", "the", "clock", "used", "in", "instant", "now", "clock", "when", "checking", "the", "access", "token", "expiry"], "project": "spring-security"}
{"id": 415, "code": "\tprotected final BaseLdapPathContextSource getContextSource() {\n\t\treturn this.contextSource;\n\t}", "summary_tokens": ["gets", "the", "base", "ldap", "path", "context", "source", "used", "to", "perform", "ldap", "authentication"], "project": "spring-security"}
{"id": 999, "code": "\tpublic Mono<OAuth2AuthorizedClient> authorize(OAuth2AuthorizationContext context) {\n\t\tAssert.notNull(context, \"context cannot be null\");\n\t\tClientRegistration clientRegistration = context.getClientRegistration();\n\t\tOAuth2AuthorizedClient authorizedClient = context.getAuthorizedClient();\n\t\tif (!AuthorizationGrantType.PASSWORD.equals(clientRegistration.getAuthorizationGrantType())) {\n\t\t\treturn Mono.empty();\n\t\t}\n\t\tString username = context.getAttribute(OAuth2AuthorizationContext.USERNAME_ATTRIBUTE_NAME);\n\t\tString password = context.getAttribute(OAuth2AuthorizationContext.PASSWORD_ATTRIBUTE_NAME);\n\t\tif (!StringUtils.hasText(username) || !StringUtils.hasText(password)) {\n\t\t\treturn Mono.empty();\n\t\t}\n\t\tif (authorizedClient != null && !hasTokenExpired(authorizedClient.getAccessToken())) {\n\t\t\t\n\t\t\t\n\t\t\treturn Mono.empty();\n\t\t}\n\t\tif (authorizedClient != null && hasTokenExpired(authorizedClient.getAccessToken())\n\t\t\t\t&& authorizedClient.getRefreshToken() != null) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\treturn Mono.empty();\n\t\t}\n\t\tOAuth2PasswordGrantRequest passwordGrantRequest = new OAuth2PasswordGrantRequest(clientRegistration, username,\n\t\t\t\tpassword);\n\t\treturn Mono.just(passwordGrantRequest).flatMap(this.accessTokenResponseClient::getTokenResponse)\n\t\t\t\t.onErrorMap(OAuth2AuthorizationException.class,\n\t\t\t\t\t\t(e) -> new ClientAuthorizationException(e.getError(), clientRegistration.getRegistrationId(),\n\t\t\t\t\t\t\t\te))\n\t\t\t\t.map((tokenResponse) -> new OAuth2AuthorizedClient(clientRegistration, context.getPrincipal().getName(),\n\t\t\t\t\t\ttokenResponse.getAccessToken(), tokenResponse.getRefreshToken()));\n\t}", "summary_tokens": ["attempt", "to", "authorize", "or", "re", "authorize", "the", "oauth", "0", "authorization", "context", "get", "client", "registration", "client", "in", "the", "provided", "context"], "project": "spring-security"}
{"id": 932, "code": "\tpublic Method method() {\n\t\treturn this.method;\n\t}", "summary_tokens": ["return", "the", "resolved", "method"], "project": "spring-security"}
{"id": 2000, "code": "\tvoid setLogoutHandlers(List<LogoutHandler> logoutHandlers) {\n\t\tthis.logoutHandlers = logoutHandlers;\n\t}", "summary_tokens": ["p", "sets", "the", "logout", "handler", "s", "used", "when", "integrating", "with", "http", "servlet", "request", "with", "servlet", "0", "apis"], "project": "spring-security"}
{"id": 1301, "code": "\tpublic Map<String, Object> getClaims() {\n\t\treturn this.claims;\n\t}", "summary_tokens": ["returns", "the", "jwt", "claims", "set"], "project": "spring-security"}
{"id": 1636, "code": "\tprotected String obtainUsername(HttpServletRequest request) {\n\t\treturn request.getParameter(this.usernameParameter);\n\t}", "summary_tokens": ["enables", "subclasses", "to", "override", "the", "composition", "of", "the", "username", "such", "as", "by", "including", "additional", "values", "and", "a", "separator"], "project": "spring-security"}
{"id": 1165, "code": "\tprivate static String expandRedirectUri(ServerHttpRequest request, ClientRegistration clientRegistration) {\n\t\tMap<String, String> uriVariables = new HashMap<>();\n\t\turiVariables.put(\"registrationId\", clientRegistration.getRegistrationId());\n\t\t\n\t\tUriComponents uriComponents = UriComponentsBuilder.fromUri(request.getURI())\n\t\t\t\t.replacePath(request.getPath().contextPath().value())\n\t\t\t\t.replaceQuery(null)\n\t\t\t\t.fragment(null)\n\t\t\t\t.build();\n\t\t\n\t\tString scheme = uriComponents.getScheme();\n\t\turiVariables.put(\"baseScheme\", (scheme != null) ? scheme : \"\");\n\t\tString host = uriComponents.getHost();\n\t\turiVariables.put(\"baseHost\", (host != null) ? host : \"\");\n\t\t\n\t\tint port = uriComponents.getPort();\n\t\turiVariables.put(\"basePort\", (port == -1) ? \"\" : \":\" + port);\n\t\tString path = uriComponents.getPath();\n\t\tif (StringUtils.hasLength(path)) {\n\t\t\tif (path.charAt(0) != PATH_DELIMITER) {\n\t\t\t\tpath = PATH_DELIMITER + path;\n\t\t\t}\n\t\t}\n\t\turiVariables.put(\"basePath\", (path != null) ? path : \"\");\n\t\turiVariables.put(\"baseUrl\", uriComponents.toUriString());\n\t\tString action = \"\";\n\t\tif (AuthorizationGrantType.AUTHORIZATION_CODE.equals(clientRegistration.getAuthorizationGrantType())) {\n\t\t\taction = \"login\";\n\t\t}\n\t\turiVariables.put(\"action\", action);\n\t\t\n\t\treturn UriComponentsBuilder.fromUriString(clientRegistration.getRedirectUri())\n\t\t\t\t.buildAndExpand(uriVariables)\n\t\t\t\t.toUriString();\n\t\t\n\t}", "summary_tokens": ["expands", "the", "client", "registration", "get", "redirect", "uri", "with", "following", "provided", "variables", "br", "base", "url", "e"], "project": "spring-security"}
{"id": 396, "code": "\tpublic static ReactiveUserDetailsServiceResourceFactoryBean fromResource(Resource propertiesResource) {\n\t\tReactiveUserDetailsServiceResourceFactoryBean result = new ReactiveUserDetailsServiceResourceFactoryBean();\n\t\tresult.setResource(propertiesResource);\n\t\treturn result;\n\t}", "summary_tokens": ["create", "a", "reactive", "user", "details", "service", "resource", "factory", "bean", "with", "a", "resource", "that", "is", "a", "properties", "file", "in", "the", "format", "defined", "in", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 618, "code": "\tpublic Object invoke(MethodInvocation mi) throws Throwable {\n\t\tattemptAuthorization(mi);\n\t\treturn mi.proceed();\n\t}", "summary_tokens": ["determine", "if", "an", "authentication", "has", "access", "to", "the", "method", "invocation", "using", "the", "configured", "authorization", "manager"], "project": "spring-security"}
{"id": 812, "code": "\tpublic void testInternationalChars() {\n\t\tprint(\"BCrypt.hashpw w/ international chars: \");\n\t\tString pw1 = \"\u03c0\u03c0\u03c0\u03c0\u03c0\u03c0\u03c0\u03c0\";\n\t\tString pw2 = \"????????\";\n\t\tString h1 = BCrypt.hashpw(pw1, BCrypt.gensalt());\n\t\tassertThat(BCrypt.checkpw(pw2, h1)).isFalse();\n\t\tprint(\".\");\n\t\tString h2 = BCrypt.hashpw(pw2, BCrypt.gensalt());\n\t\tassertThat(BCrypt.checkpw(pw1, h2)).isFalse();\n\t\tprint(\".\");\n\t\tprintln(\"\");\n\t}", "summary_tokens": ["test", "for", "correct", "hashing", "of", "non", "us", "ascii", "passwords"], "project": "spring-security"}
{"id": 902, "code": "\tpublic void setPasswordAttributeName(String passwordAttributeName) {\n\t\tthis.passwordAttributeName = passwordAttributeName;\n\t}", "summary_tokens": ["the", "name", "of", "the", "attribute", "which", "contains", "the", "user", "s", "password"], "project": "spring-security"}
{"id": 722, "code": "\tpublic void setUsernameBasedPrimaryKey(boolean usernameBasedPrimaryKey) {\n\t\tthis.usernameBasedPrimaryKey = usernameBasedPrimaryKey;\n\t}", "summary_tokens": ["if", "code", "true", "code", "the", "default", "indicates", "the", "get", "users", "by", "username", "query", "returns", "a", "username", "in", "response", "to", "a", "query"], "project": "spring-security"}
{"id": 414, "code": "\tpublic void setContextSource(BaseLdapPathContextSource contextSource) {\n\t\tthis.contextSource = contextSource;\n\t}", "summary_tokens": ["sets", "the", "base", "ldap", "path", "context", "source", "used", "to", "perform", "ldap", "authentication"], "project": "spring-security"}
{"id": 1272, "code": "\tdefault String getProfile() {\n\t\treturn this.getClaimAsString(StandardClaimNames.PROFILE);\n\t}", "summary_tokens": ["returns", "the", "url", "of", "the", "user", "s", "profile", "page", "profile"], "project": "spring-security"}
{"id": 1283, "code": "\tdefault AddressStandardClaim getAddress() {\n\t\tMap<String, Object> addressFields = this.getClaimAsMap(StandardClaimNames.ADDRESS);\n\t\treturn (!CollectionUtils.isEmpty(addressFields) ? new DefaultAddressStandardClaim.Builder(addressFields).build()\n\t\t\t\t: new DefaultAddressStandardClaim.Builder().build());\n\t}", "summary_tokens": ["returns", "the", "user", "s", "preferred", "postal", "address", "address"], "project": "spring-security"}
{"id": 1946, "code": "\tpublic void setLogoutSuccessHandler(ServerLogoutSuccessHandler logoutSuccessHandler) {\n\t\tAssert.notNull(logoutSuccessHandler, \"logoutSuccessHandler cannot be null\");\n\t\tthis.logoutSuccessHandler = logoutSuccessHandler;\n\t}", "summary_tokens": ["sets", "the", "server", "logout", "success", "handler"], "project": "spring-security"}
{"id": 1213, "code": "\tdefault String getId() {\n\t\treturn getClaimAsString(OAuth2TokenIntrospectionClaimNames.JTI);\n\t}", "summary_tokens": ["returns", "the", "identifier", "jti", "for", "the", "token", "the", "identifier", "for", "the", "token"], "project": "spring-security"}
{"id": 1558, "code": "\tpublic void applySpringSecurityWhenAddFilterSecondThenSecurityFirst() throws Exception {\n\t\tMockMvc mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).apply(springSecurity())\n\t\t\t\t.addFilters(this.noOpFilter).build();\n\t\tmockMvc.perform(get(\"/\")).andExpect(status().is4xxClientError());\n\t}", "summary_tokens": ["since", "no", "op", "filter", "is", "second", "security", "will", "be", "invoked", "and", "the", "status", "will", "be", "not", "ok"], "project": "spring-security"}
{"id": 329, "code": "\tpublic SessionManagementConfigurer<H> sessionConcurrency(\n\t\t\tCustomizer<ConcurrencyControlConfigurer> sessionConcurrencyCustomizer) {\n\t\tsessionConcurrencyCustomizer.customize(new ConcurrencyControlConfigurer());\n\t\treturn this;\n\t}", "summary_tokens": ["controls", "the", "maximum", "number", "of", "sessions", "for", "a", "user"], "project": "spring-security"}
{"id": 1900, "code": "\tpublic String getRedirectUrl() {\n\t\tString queryString = createQueryString(this.queryString, this.matchingRequestParameterName);\n\t\treturn UrlUtils.buildFullRequestUrl(this.scheme, this.serverName, this.serverPort, this.requestURI,\n\t\t\t\tqueryString);\n\t}", "summary_tokens": ["indicates", "the", "url", "that", "the", "user", "agent", "used", "for", "this", "request"], "project": "spring-security"}
{"id": 432, "code": "\tprivate String registerAccessManager(ParserContext pc, boolean jsr250Enabled, BeanDefinition expressionVoter) {\n\t\tBeanDefinitionBuilder accessMgrBuilder = BeanDefinitionBuilder.rootBeanDefinition(AffirmativeBased.class);\n\t\tManagedList voters = new ManagedList(4);\n\t\tif (expressionVoter != null) {\n\t\t\tvoters.add(expressionVoter);\n\t\t}\n\t\tvoters.add(new RootBeanDefinition(RoleVoter.class));\n\t\tvoters.add(new RootBeanDefinition(AuthenticatedVoter.class));\n\t\tif (jsr250Enabled) {\n\t\t\tvoters.add(new RootBeanDefinition(Jsr250Voter.class));\n\t\t}\n\t\taccessMgrBuilder.addConstructorArgValue(voters);\n\t\tBeanDefinition accessManager = accessMgrBuilder.getBeanDefinition();\n\t\tString id = pc.getReaderContext().generateBeanName(accessManager);\n\t\tpc.registerBeanComponent(new BeanComponentDefinition(accessManager, id));\n\t\treturn id;\n\t}", "summary_tokens": ["register", "the", "default", "access", "decision", "manager"], "project": "spring-security"}
{"id": 1549, "code": "\tpublic static ResultMatcher unauthenticated() {\n\t\treturn new UnAuthenticatedMatcher();\n\t}", "summary_tokens": ["result", "matcher", "that", "verifies", "that", "no", "user", "is", "authenticated"], "project": "spring-security"}
{"id": 963, "code": "\tpublic void setClockSkew(Duration clockSkew) {\n\t\tAssert.notNull(clockSkew, \"clockSkew cannot be null\");\n\t\tAssert.isTrue(clockSkew.getSeconds() >= 0, \"clockSkew must be >= 0\");\n\t\tthis.clockSkew = clockSkew;\n\t}", "summary_tokens": ["sets", "the", "maximum", "acceptable", "clock", "skew", "which", "is", "used", "when", "checking", "the", "oauth", "0", "authorized", "client", "get", "access", "token", "access", "token", "expiry"], "project": "spring-security"}
{"id": 1375, "code": "\tpublic final void setRealmName(String realmName) {\n\t\tthis.realmName = realmName;\n\t}", "summary_tokens": ["set", "the", "default", "realm", "name", "to", "use", "in", "the", "bearer", "token", "error", "response", "realm", "name"], "project": "spring-security"}
{"id": 109, "code": "\tpublic final UserDetailsBuilder withUser(String username) {\n\t\tUserDetailsBuilder userBuilder = new UserDetailsBuilder((C) this);\n\t\tuserBuilder.username(username);\n\t\tthis.userBuilders.add(userBuilder);\n\t\treturn userBuilder;\n\t}", "summary_tokens": ["allows", "adding", "a", "user", "to", "the", "user", "details", "manager", "that", "is", "being", "created"], "project": "spring-security"}
{"id": 896, "code": "\tpublic void setGroupMemberAttributeName(String groupMemberAttributeName) {\n\t\tAssert.hasText(groupMemberAttributeName, \"groupMemberAttributeName should have text\");\n\t\tthis.groupMemberAttributeName = groupMemberAttributeName;\n\t\tthis.groupSearchFilter = \"(\" + groupMemberAttributeName + \"={0})\";\n\t}", "summary_tokens": ["sets", "the", "name", "of", "the", "multi", "valued", "attribute", "which", "holds", "the", "dns", "of", "users", "who", "are", "members", "of", "a", "group"], "project": "spring-security"}
{"id": 181, "code": "\tprotected void configure(HttpSecurity http) throws Exception {\n\t\tthis.logger.debug(\"Using default configure(HttpSecurity). \"\n\t\t\t\t+ \"If subclassed this will potentially override subclass configure(HttpSecurity).\");\n\t\thttp.authorizeRequests((requests) -> requests.anyRequest().authenticated());\n\t\thttp.formLogin();\n\t\thttp.httpBasic();\n\t}", "summary_tokens": ["override", "this", "method", "to", "configure", "the", "http", "security"], "project": "spring-security"}
{"id": 484, "code": "\tstatic void validateContextPath(@Nullable String contextPath) {\n\t\tif (contextPath == null || \"\".equals(contextPath)) {\n\t\t\treturn;\n\t\t}\n\t\tAssert.isTrue(contextPath.startsWith(\"/\"), () -> \"contextPath '\" + contextPath + \"' must start with '/'.\");\n\t\tAssert.isTrue(!contextPath.endsWith(\"/\"), () -> \"contextPath '\" + contextPath + \"' must not end with '/'.\");\n\t}", "summary_tokens": ["validate", "the", "supplied", "context", "path"], "project": "spring-security"}
{"id": 161, "code": "\tpublic HttpSecurity addFilterAt(Filter filter, Class<? extends Filter> atFilter) {\n\t\treturn addFilterAtOffsetOf(filter, 0, atFilter);\n\t}", "summary_tokens": ["adds", "the", "filter", "at", "the", "location", "of", "the", "specified", "filter", "class"], "project": "spring-security"}
{"id": 2018, "code": "\tpublic void sessionDestroyed(HttpSessionEvent event) {\n\t\textracted(event.getSession(), new HttpSessionDestroyedEvent(event.getSession()));\n\t}", "summary_tokens": ["handles", "the", "http", "session", "event", "by", "publishing", "a", "http", "session", "destroyed", "event", "to", "the", "application", "app", "context"], "project": "spring-security"}
{"id": 1194, "code": "\tdefault <A> A getAttribute(String name) {\n\t\treturn (A) getAttributes().get(name);\n\t}", "summary_tokens": ["get", "the", "oauth", "0"], "project": "spring-security"}
{"id": 408, "code": "\tpublic BeanDefinition parse(Element element, ParserContext pc) {\n\t\tCompositeComponentDefinition compositeDef = new CompositeComponentDefinition(element.getTagName(),\n\t\t\t\tpc.extractSource(element));\n\t\tpc.pushContainingComponent(compositeDef);\n\t\tregisterFilterChainProxyIfNecessary(pc, pc.extractSource(element));\n\t\t\n\t\tBeanDefinition listFactoryBean = pc.getRegistry().getBeanDefinition(BeanIds.FILTER_CHAINS);\n\t\tList<BeanReference> filterChains = (List<BeanReference>) listFactoryBean.getPropertyValues()\n\t\t\t\t.getPropertyValue(\"sourceList\").getValue();\n\t\tfilterChains.add(createFilterChain(element, pc));\n\t\tpc.popAndRegisterContainingComponent();\n\t\treturn null;\n\t}", "summary_tokens": ["the", "aim", "of", "this", "method", "is", "to", "build", "the", "list", "of", "filters", "which", "have", "been", "defined", "by", "the", "namespace", "elements", "and", "attributes", "within", "the", "lt", "http", "gt", "configuration", "along", "with", "any", "custom", "filter", "s", "linked", "to", "user", "defined", "filter", "beans"], "project": "spring-security"}
{"id": 333, "code": "\tprivate boolean isAllowSessionCreation() {\n\t\tSessionCreationPolicy sessionPolicy = getSessionCreationPolicy();\n\t\treturn SessionCreationPolicy.ALWAYS == sessionPolicy || SessionCreationPolicy.IF_REQUIRED == sessionPolicy;\n\t}", "summary_tokens": ["returns", "true", "if", "the", "session", "creation", "policy", "allows", "session", "creation", "else", "false", "true", "if", "the", "session", "creation", "policy", "allows", "session", "creation"], "project": "spring-security"}
{"id": 1292, "code": "\tpublic Map<String, Object> getJwk() {\n\t\treturn getHeader(JoseHeaderNames.JWK);\n\t}", "summary_tokens": ["returns", "the", "json", "web", "key", "which", "is", "the", "public", "key", "that", "corresponds", "to", "the", "key", "used", "to", "digitally", "sign", "the", "jws", "or", "encrypt", "the", "jwe"], "project": "spring-security"}
{"id": 1507, "code": "\tpublic boolean authorizeUsingAccessExpression() throws IOException {\n\t\tif (getContext().getAuthentication() == null) {\n\t\t\treturn false;\n\t\t}\n\t\tSecurityExpressionHandler<FilterInvocation> handler = getExpressionHandler();\n\t\tExpression accessExpression;\n\t\ttry {\n\t\t\taccessExpression = handler.getExpressionParser().parseExpression(getAccess());\n\t\t}\n\t\tcatch (ParseException ex) {\n\t\t\tthrow new IOException(ex);\n\t\t}\n\t\treturn ExpressionUtils.evaluateAsBoolean(accessExpression, createExpressionEvaluationContext(handler));\n\t}", "summary_tokens": ["make", "an", "authorization", "decision", "based", "on", "a", "spring", "el", "expression"], "project": "spring-security"}
{"id": 597, "code": "\tpublic static <T> AuthorityAuthorizationManager<T> hasAnyRole(String rolePrefix, String[] roles) {\n\t\tAssert.notNull(rolePrefix, \"rolePrefix cannot be null\");\n\t\tAssert.notEmpty(roles, \"roles cannot be empty\");\n\t\tAssert.noNullElements(roles, \"roles cannot contain null values\");\n\t\treturn hasAnyAuthority(toNamedRolesArray(rolePrefix, roles));\n\t}", "summary_tokens": ["creates", "an", "instance", "of", "authority", "authorization", "manager", "with", "the", "provided", "authorities"], "project": "spring-security"}
{"id": 1730, "code": "\tpublic void setExceptionIfMaximumExceeded(boolean exceptionIfMaximumExceeded) {\n\t\tthis.exceptionIfMaximumExceeded = exceptionIfMaximumExceeded;\n\t}", "summary_tokens": ["sets", "the", "tt", "exception", "if", "maximum", "exceeded", "tt", "property", "which", "determines", "whether", "the", "user", "should", "be", "prevented", "from", "opening", "more", "sessions", "than", "allowed"], "project": "spring-security"}
{"id": 1337, "code": "\tprivate Mono<JWKSet> getJWKSet() {\n\t\t\n\t\treturn this.webClient.get()\n\t\t\t\t.uri(this.jwkSetURL)\n\t\t\t\t.retrieve()\n\t\t\t\t.bodyToMono(String.class)\n\t\t\t\t.map(this::parse)\n\t\t\t\t.doOnNext((jwkSet) -> this.cachedJWKSet\n\t\t\t\t\t\t.set(Mono.just(jwkSet))\n\t\t\t\t)\n\t\t\t\t.cache();\n\t\t\n\t}", "summary_tokens": ["updates", "the", "cached", "jwk", "set", "from", "the", "configured", "url"], "project": "spring-security"}
{"id": 2012, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 557, "code": "\tpublic Authentication getAuthentication() {\n\t\treturn (Authentication) super.getSource();\n\t}", "summary_tokens": ["getters", "for", "the", "code", "authentication", "code", "request", "that", "caused", "the", "event"], "project": "spring-security"}
{"id": 1494, "code": "\tpublic static Converter<ResponseToken, Saml2ResponseValidatorResult> createDefaultResponseValidator() {\n\t\treturn (responseToken) -> {\n\t\t\tResponse response = responseToken.getResponse();\n\t\t\tSaml2AuthenticationToken token = responseToken.getToken();\n\t\t\tSaml2ResponseValidatorResult result = Saml2ResponseValidatorResult.success();\n\t\t\tString statusCode = getStatusCode(response);\n\t\t\tif (!StatusCode.SUCCESS.equals(statusCode)) {\n\t\t\t\tString message = String.format(\"Invalid status [%s] for SAML response [%s]\", statusCode,\n\t\t\t\t\t\tresponse.getID());\n\t\t\t\tresult = result.concat(new Saml2Error(Saml2ErrorCodes.INVALID_RESPONSE, message));\n\t\t\t}\n\n\t\t\tString inResponseTo = response.getInResponseTo();\n\t\t\tresult = result.concat(validateInResponseTo(token.getAuthenticationRequest(), inResponseTo));\n\n\t\t\tString issuer = response.getIssuer().getValue();\n\t\t\tString destination = response.getDestination();\n\t\t\tString location = token.getRelyingPartyRegistration().getAssertionConsumerServiceLocation();\n\t\t\tif (StringUtils.hasText(destination) && !destination.equals(location)) {\n\t\t\t\tString message = \"Invalid destination [\" + destination + \"] for SAML response [\" + response.getID()\n\t\t\t\t\t\t+ \"]\";\n\t\t\t\tresult = result.concat(new Saml2Error(Saml2ErrorCodes.INVALID_DESTINATION, message));\n\t\t\t}\n\t\t\tString assertingPartyEntityId = token.getRelyingPartyRegistration().getAssertingPartyDetails()\n\t\t\t\t\t.getEntityId();\n\t\t\tif (!StringUtils.hasText(issuer) || !issuer.equals(assertingPartyEntityId)) {\n\t\t\t\tString message = String.format(\"Invalid issuer [%s] for SAML response [%s]\", issuer, response.getID());\n\t\t\t\tresult = result.concat(new Saml2Error(Saml2ErrorCodes.INVALID_ISSUER, message));\n\t\t\t}\n\t\t\tif (response.getAssertions().isEmpty()) {\n\t\t\t\tresult = result.concat(\n\t\t\t\t\t\tnew Saml2Error(Saml2ErrorCodes.MALFORMED_RESPONSE_DATA, \"No assertions found in response.\"));\n\t\t\t}\n\t\t\treturn result;\n\t\t};\n\t}", "summary_tokens": ["construct", "a", "default", "strategy", "for", "validating", "the", "saml", "0"], "project": "spring-security"}
{"id": 1458, "code": "\tpublic static Builder withRegistrationId(String registrationId) {\n\t\tAssert.hasText(registrationId, \"registrationId cannot be empty\");\n\t\treturn new Builder(registrationId);\n\t}", "summary_tokens": ["creates", "a", "relying", "party", "registration", "builder", "with", "a", "known", "registration", "id", "registration", "id", "a", "string", "identifier", "for", "the", "relying", "party", "registration", "builder", "to", "create", "a", "relying", "party", "registration", "object"], "project": "spring-security"}
{"id": 1924, "code": "\tpublic void setServerAuthenticationConverter(ServerAuthenticationConverter authenticationConverter) {\n\t\tAssert.notNull(authenticationConverter, \"authenticationConverter cannot be null\");\n\t\tthis.authenticationConverter = authenticationConverter;\n\t}", "summary_tokens": ["sets", "the", "strategy", "used", "for", "converting", "from", "a", "server", "web", "exchange", "to", "an", "authentication", "used", "for", "authenticating", "with", "the", "provided", "reactive", "authentication", "manager"], "project": "spring-security"}
{"id": 2008, "code": "\tprivate Authentication getAuthentication() {\n\t\tAuthentication auth = this.securityContextHolderStrategy.getContext().getAuthentication();\n\t\treturn (!this.trustResolver.isAnonymous(auth)) ? auth : null;\n\t}", "summary_tokens": ["obtain", "the", "current", "active", "code", "authentication", "code", "the", "authentication", "object", "or", "code", "null", "code"], "project": "spring-security"}
{"id": 2002, "code": "\tpublic void setSecurityContextRepository(SecurityContextRepository securityContextRepository) {\n\t\tAssert.notNull(securityContextRepository, \"securityContextRepository cannot be null\");\n\t\tthis.securityContextRepository = securityContextRepository;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "repository", "to", "use"], "project": "spring-security"}
{"id": 21, "code": "\tpublic final void setLookupObjectIdentitiesWhereClause(String lookupObjectIdentitiesWhereClause) {\n\t\tthis.lookupObjectIdentitiesWhereClause = lookupObjectIdentitiesWhereClause;\n\t}", "summary_tokens": ["the", "sql", "for", "the", "where", "clause", "used", "in", "the", "tt", "lookup", "object", "identities", "tt", "method"], "project": "spring-security"}
{"id": 958, "code": "\tpublic final void setAuthorizedClientRowMapper(RowMapper<OAuth2AuthorizedClient> authorizedClientRowMapper) {\n\t\tAssert.notNull(authorizedClientRowMapper, \"authorizedClientRowMapper cannot be null\");\n\t\tthis.authorizedClientRowMapper = authorizedClientRowMapper;\n\t}", "summary_tokens": ["sets", "the", "row", "mapper", "used", "for", "mapping", "the", "current", "row", "in", "java"], "project": "spring-security"}
{"id": 1244, "code": "\tpublic static Builder success(String code) {\n\t\tAssert.hasText(code, \"code cannot be empty\");\n\t\treturn new Builder().code(code);\n\t}", "summary_tokens": ["returns", "a", "new", "builder", "initialized", "with", "the", "authorization", "code"], "project": "spring-security"}
{"id": 1299, "code": "\tpublic static Builder from(JwsHeader headers) {\n\t\treturn new Builder(headers);\n\t}", "summary_tokens": ["returns", "a", "new", "builder", "initialized", "with", "the", "provided", "headers"], "project": "spring-security"}
{"id": 564, "code": "\tAuthorityGranter[] getAuthorityGranters() {\n\t\treturn this.authorityGranters;\n\t}", "summary_tokens": ["returns", "the", "authority", "grannter", "array", "that", "was", "passed", "to", "the", "set", "authority", "granters", "authority", "granter", "method", "or", "null", "if", "it", "none", "were", "ever", "set"], "project": "spring-security"}
{"id": 489, "code": "\tpublic final EvaluationContext createEvaluationContext(Authentication authentication, T invocation) {\n\t\tSecurityExpressionOperations root = createSecurityExpressionRoot(authentication, invocation);\n\t\tStandardEvaluationContext ctx = createEvaluationContextInternal(authentication, invocation);\n\t\tctx.setBeanResolver(this.beanResolver);\n\t\tctx.setRootObject(root);\n\t\treturn ctx;\n\t}", "summary_tokens": ["invokes", "the", "internal", "template", "methods", "to", "create", "standard", "evaluation", "context", "and", "security", "expression", "root", "objects"], "project": "spring-security"}
{"id": 1322, "code": "\tpublic void setJwtValidator(OAuth2TokenValidator<Jwt> jwtValidator) {\n\t\tAssert.notNull(jwtValidator, \"jwtValidator cannot be null\");\n\t\tthis.jwtValidator = jwtValidator;\n\t}", "summary_tokens": ["use", "this", "jwt", "validator", "jwt", "validator", "the", "jwt", "validator", "to", "use"], "project": "spring-security"}
{"id": 2004, "code": "\tpublic void setAuthenticationEntryPoint(AuthenticationEntryPoint authenticationEntryPoint) {\n\t\tthis.authenticationEntryPoint = authenticationEntryPoint;\n\t}", "summary_tokens": ["p", "sets", "the", "authentication", "entry", "point", "used", "when", "integrating", "http", "servlet", "request", "with", "servlet", "0", "apis"], "project": "spring-security"}
{"id": 568, "code": "\tpublic void setLoginContextName(String loginContextName) {\n\t\tthis.loginContextName = loginContextName;\n\t}", "summary_tokens": ["set", "the", "login", "context", "name", "this", "name", "is", "used", "as", "the", "index", "to", "the", "configuration", "specified", "in", "the", "login", "config", "property"], "project": "spring-security"}
{"id": 893, "code": "\tpublic void changePassword(final String oldPassword, final String newPassword) {\n\t\tAuthentication authentication = this.securityContextHolderStrategy.getContext().getAuthentication();\n\t\tAssert.notNull(authentication,\n\t\t\t\t\"No authentication object found in security context. Can't change current user's password!\");\n\t\tString username = authentication.getName();\n\t\tthis.logger.debug(LogMessage.format(\"Changing password for user '%s'\", username));\n\t\tDistinguishedName userDn = this.usernameMapper.buildDn(username);\n\t\tif (this.usePasswordModifyExtensionOperation) {\n\t\t\tchangePasswordUsingExtensionOperation(userDn, oldPassword, newPassword);\n\t\t}\n\t\telse {\n\t\t\tchangePasswordUsingAttributeModification(userDn, oldPassword, newPassword);\n\t\t}\n\t}", "summary_tokens": ["changes", "the", "password", "for", "the", "current", "user"], "project": "spring-security"}
{"id": 380, "code": "\tprivate Constraint simpDestMatchers(SimpMessageType type, String... patterns) {\n\t\tList<MatcherBuilder> matchers = new ArrayList<>(patterns.length);\n\t\tfor (String pattern : patterns) {\n\t\t\tmatchers.add(new PathMatcherMessageMatcherBuilder(pattern, type));\n\t\t}\n\t\treturn new Constraint(matchers);\n\t}", "summary_tokens": ["maps", "a", "list", "of", "simp", "destination", "message", "matcher", "instances"], "project": "spring-security"}
{"id": 1929, "code": "\tpublic void setRedirectStrategy(ServerRedirectStrategy redirectStrategy) {\n\t\tAssert.notNull(redirectStrategy, \"redirectStrategy cannot be null\");\n\t\tthis.redirectStrategy = redirectStrategy;\n\t}", "summary_tokens": ["sets", "the", "redirect", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1018, "code": "\tpublic void setClockSkew(Duration clockSkew) {\n\t\tAssert.notNull(clockSkew, \"clockSkew cannot be null\");\n\t\tAssert.isTrue(clockSkew.getSeconds() >= 0, \"clockSkew must be >= 0\");\n\t\tthis.clockSkew = clockSkew;\n\t}", "summary_tokens": ["sets", "the", "maximum", "acceptable", "clock", "skew", "which", "is", "used", "when", "checking", "the", "oauth", "0", "authorized", "client", "get", "access", "token", "access", "token", "expiry"], "project": "spring-security"}
{"id": 1844, "code": "\tpublic void setAllowUrlEncodedLineSeparator(boolean allowUrlEncodedLineSeparator) {\n\t\tif (allowUrlEncodedLineSeparator) {\n\t\t\tthis.decodedUrlBlocklist.removeAll(FORBIDDEN_LINE_SEPARATOR);\n\t\t}\n\t\telse {\n\t\t\tthis.decodedUrlBlocklist.addAll(FORBIDDEN_LINE_SEPARATOR);\n\t\t}\n\t}", "summary_tokens": ["determines", "if", "a", "url", "encoded", "line", "separator", "is", "allowed", "in", "the", "path", "or", "not"], "project": "spring-security"}
{"id": 218, "code": "\tpublic AnonymousConfigurer<H> authenticationFilter(AnonymousAuthenticationFilter authenticationFilter) {\n\t\tthis.authenticationFilter = authenticationFilter;\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "anonymous", "authentication", "filter", "used", "to", "populate", "an", "anonymous", "user"], "project": "spring-security"}
{"id": 964, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock cannot be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["sets", "the", "clock", "used", "in", "instant", "now", "clock", "when", "checking", "the", "access", "token", "expiry"], "project": "spring-security"}
{"id": 719, "code": "\tpublic void setAuthoritiesByUsernameQuery(String queryString) {\n\t\tthis.authoritiesByUsernameQuery = queryString;\n\t}", "summary_tokens": ["allows", "the", "default", "query", "string", "used", "to", "retrieve", "authorities", "based", "on", "username", "to", "be", "overridden", "if", "default", "table", "or", "column", "names", "need", "to", "be", "changed"], "project": "spring-security"}
{"id": 300, "code": "\tpublic RememberMeConfigurer<H> rememberMeParameter(String rememberMeParameter) {\n\t\tthis.rememberMeParameter = rememberMeParameter;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "http", "parameter", "used", "to", "indicate", "to", "remember", "the", "user", "at", "time", "of", "login"], "project": "spring-security"}
{"id": 616, "code": "\tpublic static AuthorizationManagerBeforeMethodInterceptor secured(\n\t\t\tSecuredAuthorizationManager authorizationManager) {\n\t\tAuthorizationManagerBeforeMethodInterceptor interceptor = new AuthorizationManagerBeforeMethodInterceptor(\n\t\t\t\tAuthorizationMethodPointcuts.forAnnotations(Secured.class), authorizationManager);\n\t\tinterceptor.setOrder(AuthorizationInterceptorsOrder.SECURED.getOrder());\n\t\treturn interceptor;\n\t}", "summary_tokens": ["creates", "an", "interceptor", "for", "the", "secured", "annotation", "authorization", "manager", "the", "secured", "authorization", "manager", "to", "use", "the", "interceptor"], "project": "spring-security"}
{"id": 60, "code": "\tprotected <P> P postProcess(P object) {\n\t\treturn this.objectPostProcessor.postProcess(object);\n\t}", "summary_tokens": ["performs", "post", "processing", "of", "an", "object"], "project": "spring-security"}
{"id": 1814, "code": "\tpublic void setRequestAttributeHandler(CsrfTokenRequestAttributeHandler requestAttributeHandler) {\n\t\tAssert.notNull(requestAttributeHandler, \"requestAttributeHandler cannot be null\");\n\t\tthis.requestAttributeHandler = requestAttributeHandler;\n\t}", "summary_tokens": ["specify", "a", "csrf", "token", "request", "attribute", "handler", "to", "use", "for", "making", "the", "csrf", "token", "available", "as", "a", "request", "attribute"], "project": "spring-security"}
{"id": 1145, "code": "\tpublic static Consumer<Map<String, Object>> oauth2AuthorizedClient(OAuth2AuthorizedClient authorizedClient) {\n\t\treturn (attributes) -> attributes.put(OAUTH2_AUTHORIZED_CLIENT_ATTR_NAME, authorizedClient);\n\t}", "summary_tokens": ["modifies", "the", "client", "request", "attributes", "to", "include", "the", "oauth", "0", "authorized", "client", "to", "be", "used", "for", "providing", "the", "bearer", "token"], "project": "spring-security"}
{"id": 1950, "code": "\tpublic void setAccessDeniedHandler(ServerAccessDeniedHandler accessDeniedHandler) {\n\t\tAssert.notNull(accessDeniedHandler, \"accessDeniedHandler cannot be null\");\n\t\tthis.accessDeniedHandler = accessDeniedHandler;\n\t}", "summary_tokens": ["sets", "the", "access", "denied", "handler"], "project": "spring-security"}
{"id": 1311, "code": "\tpublic static <T extends JwtDecoder> T fromOidcIssuerLocation(String oidcIssuerLocation) {\n\t\tAssert.hasText(oidcIssuerLocation, \"oidcIssuerLocation cannot be empty\");\n\t\tMap<String, Object> configuration = JwtDecoderProviderConfigurationUtils\n\t\t\t\t.getConfigurationForOidcIssuerLocation(oidcIssuerLocation);\n\t\treturn (T) withProviderConfiguration(configuration, oidcIssuerLocation);\n\t}", "summary_tokens": ["creates", "a", "jwt", "decoder", "using", "the", "provided", "a", "href", "https", "openid"], "project": "spring-security"}
{"id": 1305, "code": "\tdefault Instant getExpiresAt() {\n\t\treturn this.getClaimAsInstant(JwtClaimNames.EXP);\n\t}", "summary_tokens": ["returns", "the", "expiration", "time", "exp", "claim", "which", "identifies", "the", "expiration", "time", "on", "or", "after", "which", "the", "jwt", "must", "not", "be", "accepted", "for", "processing"], "project": "spring-security"}
{"id": 430, "code": "\tpublic void setPasswordAttribute(String passwordAttribute) {\n\t\tthis.passwordAttribute = passwordAttribute;\n\t}", "summary_tokens": ["the", "attribute", "in", "the", "directory", "which", "contains", "the", "user", "password"], "project": "spring-security"}
{"id": 1177, "code": "\tpublic String getTokenValue() {\n\t\treturn this.tokenValue;\n\t}", "summary_tokens": ["returns", "the", "token", "value"], "project": "spring-security"}
{"id": 390, "code": "\tprotected boolean sameOriginDisabled() {\n\t\treturn false;\n\t}", "summary_tokens": ["p", "determines", "if", "a", "csrf", "token", "is", "required", "for", "connecting"], "project": "spring-security"}
{"id": 574, "code": "\tpublic void setLoginConfig(Resource loginConfig) {\n\t\tthis.loginConfig = loginConfig;\n\t}", "summary_tokens": ["set", "the", "jaas", "login", "configuration", "file"], "project": "spring-security"}
{"id": 1660, "code": "\tpublic void setAuthenticationDetailsSource(\n\t\t\tAuthenticationDetailsSource<HttpServletRequest, ?> authenticationDetailsSource) {\n\t\tAssert.notNull(authenticationDetailsSource, \"AuthenticationDetailsSource required\");\n\t\tthis.authenticationDetailsSource = authenticationDetailsSource;\n\t}", "summary_tokens": ["authentication", "details", "source", "the", "authentication", "details", "source", "to", "use"], "project": "spring-security"}
{"id": 1045, "code": "\tBodyInserters.FormInserter<String> populateTokenRequestBody(T grantRequest,\n\t\t\tBodyInserters.FormInserter<String> body) {\n\t\tClientRegistration clientRegistration = clientRegistration(grantRequest);\n\t\tif (!ClientAuthenticationMethod.CLIENT_SECRET_BASIC\n\t\t\t\t.equals(clientRegistration.getClientAuthenticationMethod())) {\n\t\t\tbody.with(OAuth2ParameterNames.CLIENT_ID, clientRegistration.getClientId());\n\t\t}\n\t\tif (ClientAuthenticationMethod.CLIENT_SECRET_POST.equals(clientRegistration.getClientAuthenticationMethod())) {\n\t\t\tbody.with(OAuth2ParameterNames.CLIENT_SECRET, clientRegistration.getClientSecret());\n\t\t}\n\t\tSet<String> scopes = scopes(grantRequest);\n\t\tif (!CollectionUtils.isEmpty(scopes)) {\n\t\t\tbody.with(OAuth2ParameterNames.SCOPE, StringUtils.collectionToDelimitedString(scopes, \" \"));\n\t\t}\n\t\treturn body;\n\t}", "summary_tokens": ["populates", "the", "body", "of", "the", "token", "request"], "project": "spring-security"}
{"id": 606, "code": "\tfinal AuthorizationManager<MethodInvocation> getManager(MethodInvocation methodInvocation) {\n\t\tMethod method = methodInvocation.getMethod();\n\t\tObject target = methodInvocation.getThis();\n\t\tClass<?> targetClass = (target != null) ? target.getClass() : null;\n\t\tMethodClassKey cacheKey = new MethodClassKey(method, targetClass);\n\t\treturn this.cachedManagers.computeIfAbsent(cacheKey, (k) -> resolveManager(method, targetClass));\n\t}", "summary_tokens": ["returns", "an", "authorization", "manager", "for", "the", "method", "invocation"], "project": "spring-security"}
{"id": 1512, "code": "\tprotected boolean isHtmlEscape() {\n\t\treturn this.htmlEscape;\n\t}", "summary_tokens": ["return", "the", "html", "escaping", "setting", "for", "this", "tag", "or", "the", "default", "setting", "if", "not", "overridden"], "project": "spring-security"}
{"id": 538, "code": "\tpublic void eraseCredentials() {\n\t\teraseSecret(getCredentials());\n\t\teraseSecret(getPrincipal());\n\t\teraseSecret(this.details);\n\t}", "summary_tokens": ["checks", "the", "credentials", "principal", "and", "details", "objects", "invoking", "the", "erase", "credentials", "method", "on", "any", "which", "implement", "credentials", "container"], "project": "spring-security"}
{"id": 1059, "code": "\tpublic void setRequestEntityConverter(\n\t\t\tConverter<OAuth2ClientCredentialsGrantRequest, RequestEntity<?>> requestEntityConverter) {\n\t\tAssert.notNull(requestEntityConverter, \"requestEntityConverter cannot be null\");\n\t\tthis.requestEntityConverter = requestEntityConverter;\n\t}", "summary_tokens": ["sets", "the", "converter", "used", "for", "converting", "the", "oauth", "0", "client", "credentials", "grant", "request", "to", "a", "request", "entity", "representation", "of", "the", "oauth", "0"], "project": "spring-security"}
{"id": 436, "code": "\tpublic static UserDetailsManagerResourceFactoryBean fromResource(Resource resource) {\n\t\tUserDetailsManagerResourceFactoryBean result = new UserDetailsManagerResourceFactoryBean();\n\t\tresult.setResource(resource);\n\t\treturn result;\n\t}", "summary_tokens": ["create", "a", "user", "details", "manager", "resource", "factory", "bean", "with", "a", "resource", "that", "is", "a", "properties", "file", "in", "the", "format", "defined", "in", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 1205, "code": "\tdefault List<String> getScopes() {\n\t\treturn getClaimAsStringList(OAuth2TokenIntrospectionClaimNames.SCOPE);\n\t}", "summary_tokens": ["returns", "the", "scopes", "scope", "associated", "with", "the", "token", "the", "scopes", "associated", "with", "the", "token"], "project": "spring-security"}
{"id": 1089, "code": "\tpublic void setClaimTypeConverterFactory(\n\t\t\tFunction<ClientRegistration, Converter<Map<String, Object>, Map<String, Object>>> claimTypeConverterFactory) {\n\t\tAssert.notNull(claimTypeConverterFactory, \"claimTypeConverterFactory cannot be null\");\n\t\tthis.claimTypeConverterFactory = claimTypeConverterFactory;\n\t}", "summary_tokens": ["sets", "the", "factory", "that", "provides", "a", "converter", "used", "for", "type", "conversion", "of", "claim", "values", "for", "an", "oidc", "id", "token"], "project": "spring-security"}
{"id": 2014, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1233, "code": "\tpublic Map<String, Object> getAdditionalParameters() {\n\t\treturn this.additionalParameters;\n\t}", "summary_tokens": ["returns", "the", "additional", "parameter", "s", "used", "in", "the", "request"], "project": "spring-security"}
{"id": 1281, "code": "\tdefault String getPhoneNumber() {\n\t\treturn this.getClaimAsString(StandardClaimNames.PHONE_NUMBER);\n\t}", "summary_tokens": ["returns", "the", "user", "s", "preferred", "phone", "number", "phone", "number"], "project": "spring-security"}
{"id": 1903, "code": "\tpublic static String formatDate(long value, DateFormat threadLocalformat) {\n\t\tString cachedDate = null;\n\t\tLong longValue = value;\n\t\ttry {\n\t\t\tcachedDate = formatCache.get(longValue);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t}\n\t\tif (cachedDate != null) {\n\t\t\treturn cachedDate;\n\t\t}\n\t\tString newDate;\n\t\tDate dateValue = new Date(value);\n\t\tif (threadLocalformat != null) {\n\t\t\tnewDate = threadLocalformat.format(dateValue);\n\t\t\tsynchronized (formatCache) {\n\t\t\t\tupdateCache(formatCache, longValue, newDate);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tsynchronized (formatCache) {\n\t\t\t\tnewDate = format.format(dateValue);\n\t\t\t\tupdateCache(formatCache, longValue, newDate);\n\t\t\t}\n\t\t}\n\t\treturn newDate;\n\t}", "summary_tokens": ["formats", "a", "specified", "date", "to", "http", "format"], "project": "spring-security"}
{"id": 409, "code": "\tprivate BeanReference createFilterChain(Element element, ParserContext pc) {\n\t\tboolean secured = !OPT_SECURITY_NONE.equals(element.getAttribute(ATT_SECURED));\n\t\tif (!secured) {\n\t\t\tvalidateSecuredFilterChainElement(element, pc);\n\t\t\tfor (int i = 0; i < element.getChildNodes().getLength(); i++) {\n\t\t\t\tif (element.getChildNodes().item(i) instanceof Element) {\n\t\t\t\t\tpc.getReaderContext().error(\"If you are using <http> to define an unsecured pattern, \"\n\t\t\t\t\t\t\t+ \"it cannot contain child elements.\", pc.extractSource(element));\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn createSecurityFilterChainBean(element, pc, Collections.emptyList());\n\t\t}\n\t\tBeanReference portMapper = createPortMapper(element, pc);\n\t\tBeanReference portResolver = createPortResolver(portMapper, pc);\n\t\tManagedList<BeanReference> authenticationProviders = new ManagedList<>();\n\t\tBeanReference authenticationManager = createAuthenticationManager(element, pc, authenticationProviders);\n\t\tboolean forceAutoConfig = isDefaultHttpConfig(element);\n\t\tHttpConfigurationBuilder httpBldr = new HttpConfigurationBuilder(element, forceAutoConfig, pc, portMapper,\n\t\t\t\tportResolver, authenticationManager);\n\t\thttpBldr.getSecurityContextRepositoryForAuthenticationFilters();\n\t\tAuthenticationConfigBuilder authBldr = new AuthenticationConfigBuilder(element, forceAutoConfig, pc,\n\t\t\t\thttpBldr.getSessionCreationPolicy(), httpBldr.getRequestCache(), authenticationManager,\n\t\t\t\thttpBldr.getSecurityContextHolderStrategyForAuthenticationFilters(),\n\t\t\t\thttpBldr.getSecurityContextRepositoryForAuthenticationFilters(), httpBldr.getSessionStrategy(),\n\t\t\t\tportMapper, portResolver, httpBldr.getCsrfLogoutHandler());\n\t\thttpBldr.setLogoutHandlers(authBldr.getLogoutHandlers());\n\t\thttpBldr.setEntryPoint(authBldr.getEntryPointBean());\n\t\thttpBldr.setAccessDeniedHandler(authBldr.getAccessDeniedHandlerBean());\n\t\thttpBldr.setCsrfIgnoreRequestMatchers(authBldr.getCsrfIgnoreRequestMatchers());\n\t\tauthenticationProviders.addAll(authBldr.getProviders());\n\t\tList<OrderDecorator> unorderedFilterChain = new ArrayList<>();\n\t\tunorderedFilterChain.addAll(httpBldr.getFilters());\n\t\tunorderedFilterChain.addAll(authBldr.getFilters());\n\t\tunorderedFilterChain.addAll(buildCustomFilterList(element, pc));\n\t\tunorderedFilterChain.sort(new OrderComparator());\n\t\tcheckFilterChainOrder(unorderedFilterChain, pc, pc.extractSource(element));\n\t\t\n\t\tList<BeanMetadataElement> filterChain = new ManagedList<>();\n\t\tfor (OrderDecorator od : unorderedFilterChain) {\n\t\t\tfilterChain.add(od.bean);\n\t\t}\n\t\treturn createSecurityFilterChainBean(element, pc, filterChain);\n\t}", "summary_tokens": ["creates", "the", "security", "filter", "chain", "bean", "from", "an", "lt", "http", "gt", "element"], "project": "spring-security"}
{"id": 1838, "code": "\tpublic void setAllowBackSlash(boolean allowBackSlash) {\n\t\tif (allowBackSlash) {\n\t\t\turlBlocklistsRemoveAll(FORBIDDEN_BACKSLASH);\n\t\t}\n\t\telse {\n\t\t\turlBlocklistsAddAll(FORBIDDEN_BACKSLASH);\n\t\t}\n\t}", "summary_tokens": ["p", "determines", "if", "a", "backslash", "or", "a", "url", "encoded", "backslash", "0", "c", "should", "be", "allowed", "in", "the", "path", "or", "not"], "project": "spring-security"}
{"id": 800, "code": "\tpublic void setAlgorithm(SecretKeyFactoryAlgorithm secretKeyFactoryAlgorithm) {\n\t\tif (secretKeyFactoryAlgorithm == null) {\n\t\t\tthrow new IllegalArgumentException(\"secretKeyFactoryAlgorithm cannot be null\");\n\t\t}\n\t\tString algorithmName = secretKeyFactoryAlgorithm.name();\n\t\ttry {\n\t\t\tSecretKeyFactory.getInstance(algorithmName);\n\t\t\tthis.algorithm = algorithmName;\n\t\t}\n\t\tcatch (NoSuchAlgorithmException ex) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid algorithm '\" + algorithmName + \"'.\", ex);\n\t\t}\n\t}", "summary_tokens": ["sets", "the", "algorithm", "to", "use"], "project": "spring-security"}
{"id": 1890, "code": "\tpublic void setBeanResolver(BeanResolver beanResolver) {\n\t\tAssert.notNull(beanResolver, \"beanResolver cannot be null\");\n\t\tthis.beanResolver = beanResolver;\n\t}", "summary_tokens": ["set", "the", "bean", "resolver", "to", "be", "used", "on", "the", "expressions", "bean", "resolver", "the", "bean", "resolver", "to", "use"], "project": "spring-security"}
{"id": 828, "code": "\tpublic static DistinguishedName getFullDn(DistinguishedName dn, Context baseCtx) throws NamingException {\n\t\tDistinguishedName baseDn = new DistinguishedName(baseCtx.getNameInNamespace());\n\t\tif (dn.contains(baseDn)) {\n\t\t\treturn dn;\n\t\t}\n\t\tbaseDn.append(dn);\n\t\treturn baseDn;\n\t}", "summary_tokens": ["gets", "the", "full", "dn", "of", "a", "name", "by", "prepending", "the", "name", "of", "the", "context", "it", "is", "relative", "to"], "project": "spring-security"}
{"id": 1490, "code": "\tpublic void setResponseValidator(Converter<ResponseToken, Saml2ResponseValidatorResult> responseValidator) {\n\t\tAssert.notNull(responseValidator, \"responseValidator cannot be null\");\n\t\tthis.responseValidator = responseValidator;\n\t}", "summary_tokens": ["set", "the", "converter", "to", "use", "for", "validating", "the", "saml", "0"], "project": "spring-security"}
{"id": 1454, "code": "\tpublic String getNameIdFormat() {\n\t\treturn this.nameIdFormat;\n\t}", "summary_tokens": ["get", "the", "name", "id", "format"], "project": "spring-security"}
{"id": 1425, "code": "\tpublic String getParameter(String name) {\n\t\treturn this.parameters.get(name);\n\t}", "summary_tokens": ["get", "the", "name", "parameters", "a", "short", "hand", "for", "code", "get", "parameters"], "project": "spring-security"}
{"id": 22, "code": "\tpublic final void setOrderByClause(String orderByClause) {\n\t\tthis.orderByClause = orderByClause;\n\t}", "summary_tokens": ["the", "sql", "for", "the", "order", "by", "clause", "used", "in", "both", "queries"], "project": "spring-security"}
{"id": 589, "code": "\tpublic static <T> AuthenticatedAuthorizationManager<T> rememberMe() {\n\t\treturn new AuthenticatedAuthorizationManager<>(new RememberMeAuthorizationStrategy());\n\t}", "summary_tokens": ["creates", "an", "instance", "of", "authenticated", "authorization", "manager", "that", "determines", "if", "the", "authentication", "is", "authenticated", "using", "remember", "me"], "project": "spring-security"}
{"id": 1763, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 794, "code": "\tpublic String encode(CharSequence rawPassword) {\n\t\tString salt = PREFIX + this.saltGenerator.generateKey() + SUFFIX;\n\t\treturn digest(salt, rawPassword);\n\t}", "summary_tokens": ["encodes", "the", "raw", "pass", "using", "a", "message", "digest"], "project": "spring-security"}
{"id": 555, "code": "\tpublic void setPreAuthenticationChecks(UserDetailsChecker preAuthenticationChecks) {\n\t\tthis.preAuthenticationChecks = preAuthenticationChecks;\n\t}", "summary_tokens": ["sets", "the", "policy", "will", "be", "used", "to", "verify", "the", "status", "of", "the", "loaded", "tt", "user", "details", "tt", "em", "before", "em", "validation", "of", "the", "credentials", "takes", "place"], "project": "spring-security"}
{"id": 1525, "code": "\tpublic static UserExchangeMutator mockUser(String username) {\n\t\treturn new UserExchangeMutator(username);\n\t}", "summary_tokens": ["updates", "the", "server", "web", "exchange", "to", "use", "a", "user", "details", "to", "create", "a", "username", "password", "authentication", "token", "as", "the", "principal"], "project": "spring-security"}
{"id": 585, "code": "", "summary_tokens": ["does", "nothing", "but", "required", "for", "jdk", "0"], "project": "spring-security"}
{"id": 26, "code": "\tprotected Long createOrRetrieveClassPrimaryKey(String type, boolean allowCreate, Class idType) {\n\t\tList<Long> classIds = this.jdbcOperations.queryForList(this.selectClassPrimaryKey, new Object[] { type },\n\t\t\t\tLong.class);\n\n\t\tif (!classIds.isEmpty()) {\n\t\t\treturn classIds.get(0);\n\t\t}\n\n\t\tif (allowCreate) {\n\t\t\tif (!isAclClassIdSupported()) {\n\t\t\t\tthis.jdbcOperations.update(this.insertClass, type);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.jdbcOperations.update(this.insertClass, type, idType.getCanonicalName());\n\t\t\t}\n\t\t\tAssert.isTrue(TransactionSynchronizationManager.isSynchronizationActive(), \"Transaction must be running\");\n\t\t\treturn this.jdbcOperations.queryForObject(this.classIdentityQuery, Long.class);\n\t\t}\n\n\t\treturn null;\n\t}", "summary_tokens": ["retrieves", "the", "primary", "key", "from", "acl", "class", "creating", "a", "new", "row", "if", "needed", "and", "the", "allow", "create", "property", "is", "true"], "project": "spring-security"}
{"id": 1069, "code": "\tpublic OAuth2AuthorizationExchange getAuthorizationExchange() {\n\t\treturn this.authorizationExchange;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "authorization", "exchange", "authorization", "exchange"], "project": "spring-security"}
{"id": 1966, "code": "\tpublic Mono<Void> logout(WebFilterExchange exchange, Authentication authentication) {\n\t\treturn this.csrfTokenRepository.saveToken(exchange.getExchange(), null);\n\t}", "summary_tokens": ["clears", "the", "csrf", "token", "exchange", "the", "exchange", "authentication", "the", "authentication", "a", "completion", "notification", "success", "or", "error"], "project": "spring-security"}
{"id": 1501, "code": "\tpublic void setRelayStateResolver(Converter<HttpServletRequest, String> relayStateResolver) {\n\t\tAssert.notNull(relayStateResolver, \"relayStateResolver cannot be null\");\n\t\tthis.authnRequestResolver.setRelayStateResolver(relayStateResolver);\n\t}", "summary_tokens": ["use", "this", "converter", "to", "compute", "the", "relay", "state", "relay", "state", "resolver", "the", "converter", "to", "use", "0"], "project": "spring-security"}
{"id": 1028, "code": "\tpublic final void setAuthoritiesMapper(GrantedAuthoritiesMapper authoritiesMapper) {\n\t\tAssert.notNull(authoritiesMapper, \"authoritiesMapper cannot be null\");\n\t\tthis.authoritiesMapper = authoritiesMapper;\n\t}", "summary_tokens": ["sets", "the", "granted", "authorities", "mapper", "used", "for", "mapping", "oauth", "0", "user", "get", "authorities", "to", "a", "new", "set", "of", "authorities", "which", "will", "be", "associated", "to", "the", "oauth", "0", "login", "authentication", "token"], "project": "spring-security"}
{"id": 766, "code": "\tprivate static byte[] getDecodabet(int options) {\n\t\tif ((options & URL_SAFE) == URL_SAFE) {\n\t\t\treturn _URL_SAFE_DECODABET;\n\t\t}\n\t\telse if ((options & ORDERED) == ORDERED) {\n\t\t\treturn _ORDERED_DECODABET;\n\t\t}\n\t\telse {\n\t\t\treturn _STANDARD_DECODABET;\n\t\t}\n\t}", "summary_tokens": ["returns", "one", "of", "the", "something", "decodabet", "byte", "arrays", "depending", "on", "the", "options", "specified"], "project": "spring-security"}
{"id": 119, "code": "\tprotected MethodSecurityExpressionHandler createExpressionHandler() {\n\t\treturn this.defaultMethodExpressionHandler;\n\t}", "summary_tokens": ["provide", "a", "method", "security", "expression", "handler", "that", "is", "registered", "with", "the", "expression", "based", "pre", "invocation", "advice"], "project": "spring-security"}
{"id": 1677, "code": "\tprotected Object getPreAuthenticatedPrincipal(HttpServletRequest request) {\n\t\tString principal = (String) request.getAttribute(this.principalEnvironmentVariable);\n\t\tif (principal == null && this.exceptionIfVariableMissing) {\n\t\t\tthrow new PreAuthenticatedCredentialsNotFoundException(\n\t\t\t\t\tthis.principalEnvironmentVariable + \" variable not found in request.\");\n\t\t}\n\t\treturn principal;\n\t}", "summary_tokens": ["read", "and", "returns", "the", "variable", "named", "by", "principal", "environment", "variable", "from", "the", "request"], "project": "spring-security"}
{"id": 1958, "code": "\tpublic void setCookieHttpOnly(boolean cookieHttpOnly) {\n\t\tthis.cookieHttpOnly = cookieHttpOnly;\n\t}", "summary_tokens": ["sets", "the", "http", "only", "attribute", "on", "the", "cookie", "containing", "the", "csrf", "token", "cookie", "http", "only", "true", "to", "mark", "the", "cookie", "as", "http", "only"], "project": "spring-security"}
{"id": 214, "code": "\tprivate FilterSecurityInterceptor createFilterSecurityInterceptor(H http,\n\t\t\tFilterInvocationSecurityMetadataSource metadataSource, AuthenticationManager authenticationManager)\n\t\t\tthrows Exception {\n\t\tFilterSecurityInterceptor securityInterceptor = new FilterSecurityInterceptor();\n\t\tsecurityInterceptor.setSecurityMetadataSource(metadataSource);\n\t\tsecurityInterceptor.setAccessDecisionManager(getAccessDecisionManager(http));\n\t\tsecurityInterceptor.setAuthenticationManager(authenticationManager);\n\t\tsecurityInterceptor.setSecurityContextHolderStrategy(getSecurityContextHolderStrategy());\n\t\tsecurityInterceptor.afterPropertiesSet();\n\t\treturn securityInterceptor;\n\t}", "summary_tokens": ["creates", "the", "filter", "security", "interceptor", "http", "the", "builder", "to", "use", "metadata", "source", "the", "filter", "invocation", "security", "metadata", "source", "to", "use", "authentication", "manager", "the", "authentication", "manager", "to", "use", "the", "filter", "security", "interceptor", "exception"], "project": "spring-security"}
{"id": 386, "code": "\tpublic MessageSecurityMetadataSourceRegistry expressionHandler(\n\t\t\tSecurityExpressionHandler<Message<Object>> expressionHandler) {\n\t\tAssert.notNull(expressionHandler, \"expressionHandler cannot be null\");\n\t\tthis.expressionHandler = expressionHandler;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "security", "expression", "handler", "to", "be", "used"], "project": "spring-security"}
{"id": 140, "code": "\tpublic HttpSecurity headers(Customizer<HeadersConfigurer<HttpSecurity>> headersCustomizer) throws Exception {\n\t\theadersCustomizer.customize(getOrApply(new HeadersConfigurer<>()));\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["adds", "the", "security", "headers", "to", "the", "response"], "project": "spring-security"}
{"id": 1980, "code": "\tpublic void setIncludeSubDomains(boolean includeSubDomains) {\n\t\tthis.subdomain = includeSubDomains ? \" ; includeSubDomains\" : \"\";\n\t\tupdateDelegate();\n\t}", "summary_tokens": ["sets", "if", "subdomains", "should", "be", "included"], "project": "spring-security"}
{"id": 2031, "code": "\tpublic void flushBuffer() throws IOException {\n\t\tdoOnResponseCommitted();\n\t\tsuper.flushBuffer();\n\t}", "summary_tokens": ["makes", "sure", "on", "committed", "response", "wrapper", "on", "response", "committed", "is", "invoked", "before", "calling", "the", "superclass", "code", "flush", "buffer", "code"], "project": "spring-security"}
{"id": 132, "code": "\tprotected final ApplicationContext getApplicationContext() {\n\t\treturn this.context;\n\t}", "summary_tokens": ["gets", "the", "application", "context", "the", "application", "context"], "project": "spring-security"}
{"id": 978, "code": "\tpublic OAuth2AuthorizedClient getAuthorizedClient() {\n\t\treturn this.authorizedClient;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "authorized", "client", "authorized", "client", "or", "null", "if", "it", "was", "not", "provided"], "project": "spring-security"}
{"id": 1433, "code": "\tpublic String getSamlResponse() {\n\t\treturn this.parameters.get(Saml2ParameterNames.SAML_RESPONSE);\n\t}", "summary_tokens": ["get", "the", "signed", "and", "serialized", "lt", "saml", "0", "logout", "response", "gt", "payload", "the", "signed", "and", "serialized", "lt", "saml", "0", "logout", "response", "gt", "payload"], "project": "spring-security"}
{"id": 906, "code": "\tprivate Set<String> getAttributeNames() {\n\t\treturn this.attributeNames;\n\t}", "summary_tokens": ["returns", "the", "attribute", "names", "that", "this", "populator", "has", "been", "configured", "to", "retrieve", "value", "can", "be", "null", "represents", "fetch", "all", "attributes", "the", "attribute", "names", "or", "null", "for", "all"], "project": "spring-security"}
{"id": 1487, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock must not be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["use", "this", "clock", "for", "generating", "the", "issued", "date", "time", "clock", "the", "clock", "to", "use"], "project": "spring-security"}
{"id": 1859, "code": "\tpublic void setReportOnly(boolean reportOnly) {\n\t\tthis.reportOnly = reportOnly;\n\t}", "summary_tokens": ["if", "true", "includes", "the", "content", "security", "policy", "report", "only", "header", "in", "the", "response", "otherwise", "defaults", "to", "the", "content", "security", "policy", "header"], "project": "spring-security"}
{"id": 1577, "code": "\tpublic void setTrustResolver(AuthenticationTrustResolver trustResolver) {\n\t\tAssert.notNull(trustResolver, \"trustResolver cannot be null\");\n\t\tthis.trustResolver = trustResolver;\n\t}", "summary_tokens": ["sets", "the", "authentication", "trust", "resolver", "to", "be", "used"], "project": "spring-security"}
{"id": 1006, "code": "\tpublic ReactiveOAuth2AuthorizedClientProviderBuilder provider(ReactiveOAuth2AuthorizedClientProvider provider) {\n\t\tAssert.notNull(provider, \"provider cannot be null\");\n\t\tthis.builders.computeIfAbsent(provider.getClass(), (k) -> () -> provider);\n\t\treturn ReactiveOAuth2AuthorizedClientProviderBuilder.this;\n\t}", "summary_tokens": ["configures", "a", "reactive", "oauth", "0", "authorized", "client", "provider", "to", "be", "composed", "with", "the", "delegating", "reactive", "oauth", "0", "authorized", "client", "provider"], "project": "spring-security"}
{"id": 1271, "code": "\tdefault String getPreferredUsername() {\n\t\treturn this.getClaimAsString(StandardClaimNames.PREFERRED_USERNAME);\n\t}", "summary_tokens": ["returns", "the", "preferred", "username", "preferred", "username", "that", "the", "user", "wishes", "to", "be", "referred", "to"], "project": "spring-security"}
{"id": 781, "code": "\tpublic static TextEncryptor text(CharSequence password, CharSequence salt) {\n\t\treturn new HexEncodingTextEncryptor(standard(password, salt));\n\t}", "summary_tokens": ["creates", "a", "text", "encryptor", "that", "uses", "standard", "password", "based", "encryption"], "project": "spring-security"}
{"id": 1077, "code": "\tpublic final void setAuthoritiesMapper(GrantedAuthoritiesMapper authoritiesMapper) {\n\t\tAssert.notNull(authoritiesMapper, \"authoritiesMapper cannot be null\");\n\t\tthis.authoritiesMapper = authoritiesMapper;\n\t}", "summary_tokens": ["sets", "the", "granted", "authorities", "mapper", "used", "for", "mapping", "oidc", "user", "get", "authorities", "to", "a", "new", "set", "of", "authorities", "which", "will", "be", "associated", "to", "the", "oauth", "0", "login", "authentication", "token"], "project": "spring-security"}
{"id": 823, "code": "\tpublic DistinguishedName buildDn(String username) {\n\t\tDistinguishedName dn = new DistinguishedName(this.userDnBase);\n\t\tdn.add(this.usernameAttribute, username);\n\t\treturn dn;\n\t}", "summary_tokens": ["assembles", "the", "distinguished", "name", "that", "should", "be", "used", "the", "given", "username"], "project": "spring-security"}
{"id": 2039, "code": "\tpublic final Throwable getFirstThrowableOfType(Class<? extends Throwable> throwableType, Throwable[] chain) {\n\t\tif (chain != null) {\n\t\t\tfor (Throwable t : chain) {\n\t\t\t\tif ((t != null) && throwableType.isInstance(t)) {\n\t\t\t\t\treturn t;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["returns", "the", "first", "throwable", "from", "the", "passed", "in", "array", "that", "is", "assignable", "to", "the", "provided", "type"], "project": "spring-security"}
{"id": 1044, "code": "\tprivate BodyInserters.FormInserter<String> createTokenRequestBody(T grantRequest) {\n\t\tMultiValueMap<String, String> parameters = getParametersConverter().convert(grantRequest);\n\t\treturn populateTokenRequestBody(grantRequest, BodyInserters.fromFormData(parameters));\n\t}", "summary_tokens": ["combine", "the", "results", "of", "parameters", "converter", "and", "populate", "token", "request", "body"], "project": "spring-security"}
{"id": 1592, "code": "\tpublic HttpServletRequest getRequest() {\n\t\treturn this.request;\n\t}", "summary_tokens": ["returns", "the", "http", "servlet", "request"], "project": "spring-security"}
{"id": 1219, "code": "\tpublic static void addConverters(ConverterRegistry converterRegistry) {\n\t\tconverterRegistry.addConverter(new ObjectToStringConverter());\n\t\tconverterRegistry.addConverter(new ObjectToBooleanConverter());\n\t\tconverterRegistry.addConverter(new ObjectToInstantConverter());\n\t\tconverterRegistry.addConverter(new ObjectToURLConverter());\n\t\tconverterRegistry.addConverter(new ObjectToListStringConverter());\n\t\tconverterRegistry.addConverter(new ObjectToMapStringObjectConverter());\n\t}", "summary_tokens": ["adds", "the", "converters", "that", "provide", "type", "conversion", "for", "claim", "values", "to", "the", "provided", "converter", "registry"], "project": "spring-security"}
{"id": 1091, "code": "\tpublic final void setClaimTypeConverterFactory(\n\t\t\tFunction<ClientRegistration, Converter<Map<String, Object>, Map<String, Object>>> claimTypeConverterFactory) {\n\t\tAssert.notNull(claimTypeConverterFactory, \"claimTypeConverterFactory cannot be null\");\n\t\tthis.claimTypeConverterFactory = claimTypeConverterFactory;\n\t}", "summary_tokens": ["sets", "the", "factory", "that", "provides", "a", "converter", "used", "for", "type", "conversion", "of", "claim", "values", "for", "an", "oidc", "user", "info"], "project": "spring-security"}
{"id": 500, "code": "\tpublic void setParameterNameDiscoverer(ParameterNameDiscoverer parameterNameDiscoverer) {\n\t\tthis.parameterNameDiscoverer = parameterNameDiscoverer;\n\t}", "summary_tokens": ["sets", "the", "parameter", "name", "discoverer", "to", "use"], "project": "spring-security"}
{"id": 1857, "code": "\tpublic void setShouldWriteHeadersEagerly(boolean shouldWriteHeadersEagerly) {\n\t\tthis.shouldWriteHeadersEagerly = shouldWriteHeadersEagerly;\n\t}", "summary_tokens": ["allow", "writing", "headers", "at", "the", "beginning", "of", "the", "request"], "project": "spring-security"}
{"id": 1928, "code": "\tpublic void setRequestCache(ServerRequestCache requestCache) {\n\t\tAssert.notNull(requestCache, \"requestCache cannot be null\");\n\t\tthis.requestCache = requestCache;\n\t}", "summary_tokens": ["the", "request", "cache", "to", "use", "to", "save", "the", "request", "before", "sending", "a", "redirect"], "project": "spring-security"}
{"id": 261, "code": "\tpublic FeaturePolicyConfig featurePolicy(String policyDirectives) {\n\t\tthis.featurePolicy.writer = new FeaturePolicyHeaderWriter(policyDirectives);\n\t\treturn this.featurePolicy;\n\t}", "summary_tokens": ["allows", "configuration", "for", "a", "href", "https", "wicg"], "project": "spring-security"}
{"id": 1639, "code": "\tpublic void setPasswordParameter(String passwordParameter) {\n\t\tAssert.hasText(passwordParameter, \"Password parameter must not be empty or null\");\n\t\tthis.passwordParameter = passwordParameter;\n\t}", "summary_tokens": ["sets", "the", "parameter", "name", "which", "will", "be", "used", "to", "obtain", "the", "password", "from", "the", "login", "request"], "project": "spring-security"}
{"id": 1420, "code": "\tpublic String getId() {\n\t\treturn this.id;\n\t}", "summary_tokens": ["the", "unique", "identifier", "for", "this", "logout", "request", "the", "logout", "request", "identifier"], "project": "spring-security"}
{"id": 1679, "code": "\tpublic void setExceptionIfVariableMissing(boolean exceptionIfVariableMissing) {\n\t\tthis.exceptionIfVariableMissing = exceptionIfVariableMissing;\n\t}", "summary_tokens": ["defines", "whether", "an", "exception", "should", "be", "raised", "if", "the", "principal", "variable", "is", "missing"], "project": "spring-security"}
{"id": 1548, "code": "\tpublic static AuthenticatedMatcher authenticated() {\n\t\treturn new AuthenticatedMatcher();\n\t}", "summary_tokens": ["result", "matcher", "that", "verifies", "that", "a", "specified", "user", "is", "authenticated"], "project": "spring-security"}
{"id": 243, "code": "\tpublic FormLoginConfigurer<H> passwordParameter(String passwordParameter) {\n\t\tgetAuthenticationFilter().setPasswordParameter(passwordParameter);\n\t\treturn this;\n\t}", "summary_tokens": ["the", "http", "parameter", "to", "look", "for", "the", "password", "when", "performing", "authentication"], "project": "spring-security"}
{"id": 996, "code": "\tpublic void setAccessTokenResponseClient(\n\t\t\tOAuth2AccessTokenResponseClient<OAuth2PasswordGrantRequest> accessTokenResponseClient) {\n\t\tAssert.notNull(accessTokenResponseClient, \"accessTokenResponseClient cannot be null\");\n\t\tthis.accessTokenResponseClient = accessTokenResponseClient;\n\t}", "summary_tokens": ["sets", "the", "client", "used", "when", "requesting", "an", "access", "token", "credential", "at", "the", "token", "endpoint", "for", "the", "password", "grant"], "project": "spring-security"}
{"id": 520, "code": "\tpublic void setRolePrefix(String rolePrefix) {\n\t\tthis.rolePrefix = rolePrefix;\n\t}", "summary_tokens": ["allows", "the", "default", "role", "prefix", "of", "code", "role", "code", "to", "be", "overridden"], "project": "spring-security"}
{"id": 1911, "code": "\tpublic void setMatchingRequestParameterName(String matchingRequestParameterName) {\n\t\tthis.matchingRequestParameterName = matchingRequestParameterName;\n\t}", "summary_tokens": ["specify", "the", "name", "of", "a", "query", "parameter", "that", "is", "added", "to", "the", "url", "that", "specifies", "the", "request", "cache", "should", "be", "checked", "in", "get", "matching", "request", "http", "servlet", "request", "http", "servlet", "response", "matching", "request", "parameter", "name", "the", "parameter", "name", "that", "must", "be", "in", "the", "request", "for", "get", "matching", "request", "http", "servlet", "request", "http", "servlet", "response", "to", "check", "the", "session"], "project": "spring-security"}
{"id": 1770, "code": "\tprivate <T extends Annotation> T findMethodAnnotation(Class<T> annotationClass, MethodParameter parameter) {\n\t\tT annotation = parameter.getParameterAnnotation(annotationClass);\n\t\tif (annotation != null) {\n\t\t\treturn annotation;\n\t\t}\n\t\tAnnotation[] annotationsToSearch = parameter.getParameterAnnotations();\n\t\tfor (Annotation toSearch : annotationsToSearch) {\n\t\t\tannotation = AnnotationUtils.findAnnotation(toSearch.annotationType(), annotationClass);\n\t\t\tif (annotation != null) {\n\t\t\t\treturn annotation;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["obtains", "the", "specified", "annotation", "on", "the", "specified", "method", "parameter"], "project": "spring-security"}
{"id": 253, "code": "\tpublic HeadersConfigurer<H> httpStrictTransportSecurity(Customizer<HstsConfig> hstsCustomizer) {\n\t\thstsCustomizer.customize(this.hsts.enable());\n\t\treturn HeadersConfigurer.this;\n\t}", "summary_tokens": ["allows", "customizing", "the", "hsts", "header", "writer", "which", "provides", "support", "for", "a", "href", "https", "tools"], "project": "spring-security"}
{"id": 1908, "code": "\tpublic void setRequestMatcher(RequestMatcher requestMatcher) {\n\t\tthis.requestMatcher = requestMatcher;\n\t}", "summary_tokens": ["allows", "selective", "use", "of", "saved", "requests", "for", "a", "subset", "of", "requests"], "project": "spring-security"}
{"id": 962, "code": "\tpublic void setJwtAssertionResolver(Function<OAuth2AuthorizationContext, Jwt> jwtAssertionResolver) {\n\t\tAssert.notNull(jwtAssertionResolver, \"jwtAssertionResolver cannot be null\");\n\t\tthis.jwtAssertionResolver = jwtAssertionResolver;\n\t}", "summary_tokens": ["sets", "the", "resolver", "used", "for", "resolving", "the", "jwt", "assertion"], "project": "spring-security"}
{"id": 1019, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock cannot be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["sets", "the", "clock", "used", "in", "instant", "now", "clock", "when", "checking", "the", "access", "token", "expiry"], "project": "spring-security"}
{"id": 201, "code": "\tprotected final AuthenticationEntryPoint getAuthenticationEntryPoint() {\n\t\treturn this.authenticationEntryPoint;\n\t}", "summary_tokens": ["gets", "the", "authentication", "entry", "point", "the", "authentication", "entry", "point"], "project": "spring-security"}
{"id": 892, "code": "\tpublic boolean equals(Object obj) {\n\t\tif (this == obj) {\n\t\t\treturn true;\n\t\t}\n\t\tif (!(obj instanceof LdapAuthority)) {\n\t\t\treturn false;\n\t\t}\n\t\tLdapAuthority other = (LdapAuthority) obj;\n\t\tif (!this.dn.equals(other.dn)) {\n\t\t\treturn false;\n\t\t}\n\t\treturn this.role.equals(other.role);\n\t}", "summary_tokens": ["compares", "the", "ldap", "authority", "based", "on", "get", "authority", "and", "get", "dn", "values"], "project": "spring-security"}
{"id": 1708, "code": "\tpublic void setParameter(String parameter) {\n\t\tAssert.hasText(parameter, \"Parameter name cannot be empty or null\");\n\t\tthis.parameter = parameter;\n\t}", "summary_tokens": ["sets", "the", "name", "of", "the", "parameter", "which", "should", "be", "checked", "for", "to", "see", "if", "a", "remember", "me", "has", "been", "requested", "during", "a", "login", "request"], "project": "spring-security"}
{"id": 362, "code": "\tpublic OAuth2LoginConfigurer<B> userInfoEndpoint(Customizer<UserInfoEndpointConfig> userInfoEndpointCustomizer) {\n\t\tuserInfoEndpointCustomizer.customize(this.userInfoEndpointConfig);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "the", "authorization", "server", "s", "user", "info", "endpoint"], "project": "spring-security"}
{"id": 195, "code": "\tpublic final T failureHandler(AuthenticationFailureHandler authenticationFailureHandler) {\n\t\tthis.failureUrl = null;\n\t\tthis.failureHandler = authenticationFailureHandler;\n\t\treturn getSelf();\n\t}", "summary_tokens": ["specifies", "the", "authentication", "failure", "handler", "to", "use", "when", "authentication", "fails"], "project": "spring-security"}
{"id": 718, "code": "\tprotected UserDetails createUserDetails(String username, UserDetails userFromUserQuery,\n\t\t\tList<GrantedAuthority> combinedAuthorities) {\n\t\tString returnUsername = userFromUserQuery.getUsername();\n\t\tif (!this.usernameBasedPrimaryKey) {\n\t\t\treturnUsername = username;\n\t\t}\n\t\treturn new User(returnUsername, userFromUserQuery.getPassword(), userFromUserQuery.isEnabled(),\n\t\t\t\tuserFromUserQuery.isAccountNonExpired(), userFromUserQuery.isCredentialsNonExpired(),\n\t\t\t\tuserFromUserQuery.isAccountNonLocked(), combinedAuthorities);\n\t}", "summary_tokens": ["can", "be", "overridden", "to", "customize", "the", "creation", "of", "the", "final", "user", "details", "object", "which", "is", "returned", "by", "the", "tt", "load", "user", "by", "username", "tt", "method"], "project": "spring-security"}
{"id": 1230, "code": "\tpublic String getClientId() {\n\t\treturn this.clientId;\n\t}", "summary_tokens": ["returns", "the", "client", "identifier"], "project": "spring-security"}
{"id": 838, "code": "\tpublic static DirContextOperations searchForSingleEntryInternal(DirContext ctx, SearchControls searchControls,\n\t\t\tString base, String filter, Object[] params) throws NamingException {\n\t\tfinal DistinguishedName ctxBaseDn = new DistinguishedName(ctx.getNameInNamespace());\n\t\tfinal DistinguishedName searchBaseDn = new DistinguishedName(base);\n\t\tfinal NamingEnumeration<SearchResult> resultsEnum = ctx.search(searchBaseDn, filter, params,\n\t\t\t\tbuildControls(searchControls));\n\t\tlogger.trace(LogMessage.format(\"Searching for entry under DN '%s', base = '%s', filter = '%s'\", ctxBaseDn,\n\t\t\t\tsearchBaseDn, filter));\n\t\tSet<DirContextOperations> results = new HashSet<>();\n\t\ttry {\n\t\t\twhile (resultsEnum.hasMore()) {\n\t\t\t\tSearchResult searchResult = resultsEnum.next();\n\t\t\t\tDirContextAdapter dca = (DirContextAdapter) searchResult.getObject();\n\t\t\t\tAssert.notNull(dca, \"No object returned by search, DirContext is not correctly configured\");\n\t\t\t\tlogger.debug(LogMessage.format(\"Found DN: %s\", dca.getDn()));\n\t\t\t\tresults.add(dca);\n\t\t\t}\n\t\t}\n\t\tcatch (PartialResultException ex) {\n\t\t\tLdapUtils.closeEnumeration(resultsEnum);\n\t\t\tlogger.trace(\"Ignoring PartialResultException\");\n\t\t}\n\t\tif (results.size() != 1) {\n\t\t\tthrow new IncorrectResultSizeDataAccessException(1, results.size());\n\t\t}\n\t\treturn results.iterator().next();\n\t}", "summary_tokens": ["internal", "method", "extracted", "to", "avoid", "code", "duplication", "in", "ad", "search"], "project": "spring-security"}
{"id": 1171, "code": "\tpublic void setRequestCache(ServerRequestCache requestCache) {\n\t\tAssert.notNull(requestCache, \"requestCache cannot be null\");\n\t\tthis.requestCache = requestCache;\n\t}", "summary_tokens": ["the", "request", "cache", "to", "use", "to", "save", "the", "request", "before", "sending", "a", "redirect"], "project": "spring-security"}
{"id": 1492, "code": "\tpublic void setAssertionElementsDecrypter(Consumer<AssertionToken> assertionDecrypter) {\n\t\tAssert.notNull(assertionDecrypter, \"assertionDecrypter cannot be null\");\n\t\tthis.assertionElementsDecrypter = assertionDecrypter;\n\t}", "summary_tokens": ["set", "the", "consumer", "strategy", "to", "use", "for", "decrypting", "elements", "of", "a", "validated", "assertion"], "project": "spring-security"}
{"id": 1356, "code": "\tpublic Authentication authenticate(Authentication authentication) throws AuthenticationException {\n\t\tif (!(authentication instanceof BearerTokenAuthenticationToken)) {\n\t\t\treturn null;\n\t\t}\n\t\tBearerTokenAuthenticationToken bearer = (BearerTokenAuthenticationToken) authentication;\n\t\tOAuth2AuthenticatedPrincipal principal = getOAuth2AuthenticatedPrincipal(bearer);\n\t\tAbstractAuthenticationToken result = convert(principal, bearer.getToken());\n\t\tresult.setDetails(bearer.getDetails());\n\t\tthis.logger.debug(\"Authenticated token\");\n\t\treturn result;\n\t}", "summary_tokens": ["introspect", "and", "validate", "the", "opaque", "a", "href", "https", "tools"], "project": "spring-security"}
{"id": 1889, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1682, "code": "\tpublic void setExceptionIfHeaderMissing(boolean exceptionIfHeaderMissing) {\n\t\tthis.exceptionIfHeaderMissing = exceptionIfHeaderMissing;\n\t}", "summary_tokens": ["defines", "whether", "an", "exception", "should", "be", "raised", "if", "the", "principal", "header", "is", "missing"], "project": "spring-security"}
{"id": 584, "code": "\tpublic Authentication getAuthentication() {\n\t\treturn (Authentication) this.source;\n\t}", "summary_tokens": ["pre", "casted", "method", "that", "returns", "the", "source", "of", "the", "event"], "project": "spring-security"}
{"id": 1493, "code": "\tpublic void setResponseAuthenticationConverter(\n\t\t\tConverter<ResponseToken, ? extends AbstractAuthenticationToken> responseAuthenticationConverter) {\n\t\tAssert.notNull(responseAuthenticationConverter, \"responseAuthenticationConverter cannot be null\");\n\t\tthis.responseAuthenticationConverter = responseAuthenticationConverter;\n\t}", "summary_tokens": ["set", "the", "converter", "to", "use", "for", "converting", "a", "validated", "response", "into", "an", "abstract", "authentication", "token"], "project": "spring-security"}
{"id": 1368, "code": "\tpublic void setAuthenticationFailureHandler(final AuthenticationFailureHandler authenticationFailureHandler) {\n\t\tAssert.notNull(authenticationFailureHandler, \"authenticationFailureHandler cannot be null\");\n\t\tthis.authenticationFailureHandler = authenticationFailureHandler;\n\t}", "summary_tokens": ["set", "the", "authentication", "failure", "handler", "to", "use"], "project": "spring-security"}
{"id": 388, "code": "\tprotected boolean containsMapping() {\n\t\treturn !this.matcherToExpression.isEmpty();\n\t}", "summary_tokens": ["allows", "determining", "if", "a", "mapping", "was", "added"], "project": "spring-security"}
{"id": 1779, "code": "\tprotected String getDispatcherWebApplicationContextSuffix() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "lt", "servlet", "name", "gt", "to", "use", "the", "dispatcher", "servlet", "s", "web", "application", "context", "to", "find", "the", "delegating", "filter", "proxy", "or", "null", "to", "use", "the", "parent", "application", "context"], "project": "spring-security"}
{"id": 239, "code": "\tprivate RequestCache getRequestCache(H http) {\n\t\tRequestCache result = http.getSharedObject(RequestCache.class);\n\t\tif (result != null) {\n\t\t\treturn result;\n\t\t}\n\t\treturn new HttpSessionRequestCache();\n\t}", "summary_tokens": ["gets", "the", "request", "cache", "to", "use"], "project": "spring-security"}
{"id": 809, "code": "\tpublic void testCheckpwByteArray_success() {\n\t\tfor (TestObject<byte[]> test : testObjectsByteArray) {\n\t\t\tassertThat(BCrypt.checkpw(test.password, test.expected)).isTrue();\n\t\t}\n\t}", "summary_tokens": ["test", "method", "for", "bcrypt"], "project": "spring-security"}
{"id": 115, "code": "\tpublic MethodInterceptor methodSecurityInterceptor(MethodSecurityMetadataSource methodSecurityMetadataSource) {\n\t\tthis.methodSecurityInterceptor = isAspectJ() ? new AspectJMethodSecurityInterceptor()\n\t\t\t\t: new MethodSecurityInterceptor();\n\t\tthis.methodSecurityInterceptor.setAccessDecisionManager(accessDecisionManager());\n\t\tthis.methodSecurityInterceptor.setAfterInvocationManager(afterInvocationManager());\n\t\tthis.methodSecurityInterceptor.setSecurityMetadataSource(methodSecurityMetadataSource);\n\t\tthis.methodSecurityInterceptor.setSecurityContextHolderStrategy(this.securityContextHolderStrategy);\n\t\tRunAsManager runAsManager = runAsManager();\n\t\tif (runAsManager != null) {\n\t\t\tthis.methodSecurityInterceptor.setRunAsManager(runAsManager);\n\t\t}\n\t\treturn this.methodSecurityInterceptor;\n\t}", "summary_tokens": ["creates", "the", "default", "method", "interceptor", "which", "is", "a", "method", "security", "interceptor", "using", "the", "following", "methods", "to", "construct", "it"], "project": "spring-security"}
{"id": 448, "code": "\tpublic ServerHttpSecurity csrf(Customizer<CsrfSpec> csrfCustomizer) {\n\t\tif (this.csrf == null) {\n\t\t\tthis.csrf = new CsrfSpec();\n\t\t}\n\t\tcsrfCustomizer.customize(this.csrf);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "a", "href", "https", "www"], "project": "spring-security"}
{"id": 1449, "code": "\tpublic Saml2MessageBinding getAssertionConsumerServiceBinding() {\n\t\treturn this.assertionConsumerServiceBinding;\n\t}", "summary_tokens": ["get", "the", "assertion", "consumer", "service", "binding"], "project": "spring-security"}
{"id": 1294, "code": "\tpublic String getType() {\n\t\treturn getHeader(JoseHeaderNames.TYP);\n\t}", "summary_tokens": ["returns", "the", "type", "header", "that", "declares", "the", "media", "type", "of", "the", "jws", "jwe"], "project": "spring-security"}
{"id": 155, "code": "\tpublic HttpSecurity saml2Login(Customizer<Saml2LoginConfigurer<HttpSecurity>> saml2LoginCustomizer)\n\t\t\tthrows Exception {\n\t\tsaml2LoginCustomizer.customize(getOrApply(new Saml2LoginConfigurer<>()));\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["configures", "authentication", "support", "using", "an", "saml", "0"], "project": "spring-security"}
{"id": 1648, "code": "\tpublic void logout(HttpServletRequest request, HttpServletResponse response, Authentication authentication) {\n\t\tAssert.notNull(request, \"HttpServletRequest required\");\n\t\tif (this.invalidateHttpSession) {\n\t\t\tHttpSession session = request.getSession(false);\n\t\t\tif (session != null) {\n\t\t\t\tsession.invalidate();\n\t\t\t\tif (this.logger.isDebugEnabled()) {\n\t\t\t\t\tthis.logger.debug(LogMessage.format(\"Invalidated session %s\", session.getId()));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tSecurityContext context = this.securityContextHolderStrategy.getContext();\n\t\tthis.securityContextHolderStrategy.clearContext();\n\t\tif (this.clearAuthentication) {\n\t\t\tcontext.setAuthentication(null);\n\t\t}\n\t}", "summary_tokens": ["requires", "the", "request", "to", "be", "passed", "in"], "project": "spring-security"}
{"id": 247, "code": "\tprivate String getPasswordParameter() {\n\t\treturn getAuthenticationFilter().getPasswordParameter();\n\t}", "summary_tokens": ["gets", "the", "http", "parameter", "that", "is", "used", "to", "submit", "the", "password"], "project": "spring-security"}
{"id": 69, "code": "\tpublic void addObjectPostProcessor(ObjectPostProcessor<?> objectPostProcessor) {\n\t\tthis.objectPostProcessor.addObjectPostProcessor(objectPostProcessor);\n\t}", "summary_tokens": ["adds", "an", "object", "post", "processor", "to", "be", "used", "for", "this", "security", "configurer", "adapter"], "project": "spring-security"}
{"id": 1831, "code": "\tprivate String strip(String path) {\n\t\tif (path == null) {\n\t\t\treturn null;\n\t\t}\n\t\tint semicolonIndex = path.indexOf(';');\n\t\tif (semicolonIndex < 0) {\n\t\t\tint doubleSlashIndex = path.indexOf(\"//\");\n\t\t\tif (doubleSlashIndex < 0) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\treturn path;\n\t\t\t}\n\t\t}\n\t\tStringTokenizer tokenizer = new StringTokenizer(path, \"/\");\n\t\tStringBuilder stripped = new StringBuilder(path.length());\n\t\tif (path.charAt(0) == '/') {\n\t\t\tstripped.append('/');\n\t\t}\n\t\twhile (tokenizer.hasMoreTokens()) {\n\t\t\tString segment = tokenizer.nextToken();\n\t\t\tsemicolonIndex = segment.indexOf(';');\n\t\t\tif (semicolonIndex >= 0) {\n\t\t\t\tsegment = segment.substring(0, semicolonIndex);\n\t\t\t}\n\t\t\tstripped.append(segment).append('/');\n\t\t}\n\t\t\n\t\tif (path.charAt(path.length() - 1) != '/') {\n\t\t\tstripped.deleteCharAt(stripped.length() - 1);\n\t\t}\n\t\treturn stripped.toString();\n\t}", "summary_tokens": ["removes", "path", "parameters", "from", "each", "path", "segment", "in", "the", "supplied", "path", "and", "truncates", "sequences", "of", "multiple", "characters", "to", "a", "single"], "project": "spring-security"}
{"id": 974, "code": "\tpublic <T> T getAttribute(String name) {\n\t\treturn (T) this.getAttributes().get(name);\n\t}", "summary_tokens": ["returns", "the", "value", "of", "an", "attribute", "associated", "to", "the", "context", "or", "null", "if", "not", "available"], "project": "spring-security"}
{"id": 1658, "code": "\tpublic void setApplicationEventPublisher(ApplicationEventPublisher anApplicationEventPublisher) {\n\t\tthis.eventPublisher = anApplicationEventPublisher;\n\t}", "summary_tokens": ["an", "application", "event", "publisher", "the", "application", "event", "publisher", "to", "use"], "project": "spring-security"}
{"id": 1296, "code": "\tpublic Set<String> getCritical() {\n\t\treturn getHeader(JoseHeaderNames.CRIT);\n\t}", "summary_tokens": ["returns", "the", "critical", "headers", "that", "indicates", "which", "extensions", "to", "the", "jws", "jwe", "jwa", "specifications", "are", "being", "used", "that", "must", "be", "understood", "and", "processed"], "project": "spring-security"}
{"id": 1852, "code": "\tpublic Set<String> getDecodedUrlBlocklist() {\n\t\treturn this.decodedUrlBlocklist;\n\t}", "summary_tokens": ["provides", "the", "existing", "decoded", "url", "blocklist", "which", "can", "add", "remove", "entries", "from", "the", "existing", "decoded", "url", "blocklist", "never", "null"], "project": "spring-security"}
{"id": 1754, "code": "\tpublic void setSwitchUserAuthorityChanger(SwitchUserAuthorityChanger switchUserAuthorityChanger) {\n\t\tthis.switchUserAuthorityChanger = switchUserAuthorityChanger;\n\t}", "summary_tokens": ["switch", "user", "authority", "changer", "to", "use", "to", "fine", "tune", "the", "authorities", "granted", "to", "subclasses", "may", "be", "null", "if", "switch", "user", "filter", "should", "not", "fine", "tune", "the", "authorities"], "project": "spring-security"}
{"id": 1180, "code": "\tpublic String getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["returns", "the", "value", "of", "the", "authentication", "method", "type"], "project": "spring-security"}
{"id": 1817, "code": "\tpublic void setRequestAttributeHandler(CsrfTokenRequestAttributeHandler requestAttributeHandler) {\n\t\tAssert.notNull(requestAttributeHandler, \"requestAttributeHandler cannot be null\");\n\t\tthis.requestAttributeHandler = requestAttributeHandler;\n\t}", "summary_tokens": ["specifies", "a", "csrf", "token", "request", "attribute", "handler", "that", "is", "used", "to", "make", "the", "csrf", "token", "available", "as", "a", "request", "attribute"], "project": "spring-security"}
{"id": 556, "code": "\tpublic void setPasswordEncoder(PasswordEncoder passwordEncoder) {\n\t\tAssert.notNull(passwordEncoder, \"passwordEncoder cannot be null\");\n\t\tthis.passwordEncoder = passwordEncoder;\n\t\tthis.userNotFoundEncodedPassword = null;\n\t}", "summary_tokens": ["sets", "the", "password", "encoder", "instance", "to", "be", "used", "to", "encode", "and", "validate", "passwords"], "project": "spring-security"}
{"id": 1256, "code": "\tdefault Instant getAuthenticatedAt() {\n\t\treturn this.getClaimAsInstant(IdTokenClaimNames.AUTH_TIME);\n\t}", "summary_tokens": ["returns", "the", "time", "when", "the", "end", "user", "authentication", "occurred", "auth", "time"], "project": "spring-security"}
{"id": 224, "code": "\tpublic CsrfConfigurer<H> ignoringAntMatchers(String... antPatterns) {\n\t\treturn new IgnoreCsrfProtectionRegistry(this.context).antMatchers(antPatterns).and();\n\t}", "summary_tokens": ["p", "allows", "specifying", "http", "servlet", "request", "that", "should", "not", "use", "csrf", "protection", "even", "if", "they", "match", "the", "require", "csrf", "protection", "matcher", "request", "matcher"], "project": "spring-security"}
{"id": 1591, "code": "\tpublic boolean isObserveOncePerRequest() {\n\t\treturn this.observeOncePerRequest;\n\t}", "summary_tokens": ["indicates", "whether", "once", "per", "request", "handling", "will", "be", "observed"], "project": "spring-security"}
{"id": 1529, "code": "\tpublic static OidcLoginMutator mockOidcLogin() {\n\t\tOAuth2AccessToken accessToken = new OAuth2AccessToken(OAuth2AccessToken.TokenType.BEARER, \"access-token\", null,\n\t\t\t\tnull, Collections.singleton(\"read\"));\n\t\treturn new OidcLoginMutator(accessToken);\n\t}", "summary_tokens": ["updates", "the", "server", "web", "exchange", "to", "establish", "a", "security", "context", "that", "has", "a", "oauth", "0", "authentication", "token", "for", "the", "authentication"], "project": "spring-security"}
{"id": 58, "code": "\tpublic <C extends SecurityConfigurer<O, B>> C removeConfigurer(Class<C> clazz) {\n\t\tList<SecurityConfigurer<O, B>> configs = this.configurers.remove(clazz);\n\t\tif (configs == null) {\n\t\t\treturn null;\n\t\t}\n\t\tAssert.state(configs.size() == 1,\n\t\t\t\t() -> \"Only one configurer expected for type \" + clazz + \", but got \" + configs);\n\t\treturn (C) configs.get(0);\n\t}", "summary_tokens": ["removes", "and", "returns", "the", "security", "configurer", "by", "its", "class", "name", "or", "code", "null", "code", "if", "not", "found"], "project": "spring-security"}
{"id": 630, "code": "\tpublic AuthorizationDecision check(Supplier<Authentication> authentication, MethodInvocationResult mi) {\n\t\tExpressionAttribute attribute = this.registry.getAttribute(mi.getMethodInvocation());\n\t\tif (attribute == ExpressionAttribute.NULL_ATTRIBUTE) {\n\t\t\treturn null;\n\t\t}\n\t\tMethodSecurityExpressionHandler expressionHandler = this.registry.getExpressionHandler();\n\t\tEvaluationContext ctx = expressionHandler.createEvaluationContext(authentication, mi.getMethodInvocation());\n\t\texpressionHandler.setReturnObject(mi.getResult(), ctx);\n\t\tboolean granted = ExpressionUtils.evaluateAsBoolean(attribute.getExpression(), ctx);\n\t\treturn new ExpressionAuthorizationDecision(granted, attribute.getExpression());\n\t}", "summary_tokens": ["determine", "if", "an", "authentication", "has", "access", "to", "the", "returned", "object", "by", "evaluating", "the", "post", "authorize", "annotation", "that", "the", "method", "invocation", "specifies"], "project": "spring-security"}
{"id": 1090, "code": "\tpublic static Map<String, Converter<Object, ?>> createDefaultClaimTypeConverters() {\n\t\tConverter<Object, ?> booleanConverter = getConverter(TypeDescriptor.valueOf(Boolean.class));\n\t\tConverter<Object, ?> instantConverter = getConverter(TypeDescriptor.valueOf(Instant.class));\n\t\tMap<String, Converter<Object, ?>> claimTypeConverters = new HashMap<>();\n\t\tclaimTypeConverters.put(StandardClaimNames.EMAIL_VERIFIED, booleanConverter);\n\t\tclaimTypeConverters.put(StandardClaimNames.PHONE_NUMBER_VERIFIED, booleanConverter);\n\t\tclaimTypeConverters.put(StandardClaimNames.UPDATED_AT, instantConverter);\n\t\treturn claimTypeConverters;\n\t}", "summary_tokens": ["returns", "the", "default", "converter", "s", "used", "for", "type", "conversion", "of", "claim", "values", "for", "an", "oidc", "user", "info"], "project": "spring-security"}
{"id": 1417, "code": "\tpublic String getSignature() {\n\t\treturn this.signature;\n\t}", "summary_tokens": ["returns", "the", "signature", "value", "for", "saml", "0", "message", "binding", "redirect", "requests", "the", "signature", "value"], "project": "spring-security"}
{"id": 675, "code": "\tpublic void setConvertToLowerCase(boolean convertToLowerCase) {\n\t\tthis.convertToLowerCase = convertToLowerCase;\n\t}", "summary_tokens": ["whether", "to", "convert", "the", "authority", "value", "to", "lower", "case", "in", "the", "mapping"], "project": "spring-security"}
{"id": 655, "code": "\tprivate static void performVersionChecks(String minSpringVersion) {\n\t\tif (minSpringVersion == null) {\n\t\t\treturn;\n\t\t}\n\t\t\n\t\tString springVersion = SpringVersion.getVersion();\n\t\tString version = getVersion();\n\t\tif (disableChecks(springVersion, version)) {\n\t\t\treturn;\n\t\t}\n\t\tlogger.info(\"You are running with Spring Security Core \" + version);\n\t\tif (new ComparableVersion(springVersion).compareTo(new ComparableVersion(minSpringVersion)) < 0) {\n\t\t\tlogger.warn(\"**** You are advised to use Spring \" + minSpringVersion\n\t\t\t\t\t+ \" or later with this version. You are running: \" + springVersion);\n\t\t}\n\t}", "summary_tokens": ["perform", "version", "checks", "with", "specific", "min", "spring", "version", "min", "spring", "version"], "project": "spring-security"}
{"id": 1994, "code": "\tpublic static ServerWebExchangeMatcher matchers(ServerWebExchangeMatcher... matchers) {\n\t\treturn new OrServerWebExchangeMatcher(matchers);\n\t}", "summary_tokens": ["creates", "a", "matcher", "that", "will", "match", "on", "any", "of", "the", "provided", "matchers", "matchers", "the", "matchers", "to", "match", "on", "the", "matcher", "to", "use"], "project": "spring-security"}
{"id": 776, "code": "\tstatic void initCipher(Cipher cipher, int mode, SecretKey secretKey, AlgorithmParameterSpec parameterSpec) {\n\t\ttry {\n\t\t\tif (parameterSpec != null) {\n\t\t\t\tcipher.init(mode, secretKey, parameterSpec);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcipher.init(mode, secretKey);\n\t\t\t}\n\t\t}\n\t\tcatch (InvalidKeyException ex) {\n\t\t\tthrow new IllegalArgumentException(\"Unable to initialize due to invalid secret key\", ex);\n\t\t}\n\t\tcatch (InvalidAlgorithmParameterException ex) {\n\t\t\tthrow new IllegalStateException(\"Unable to initialize due to invalid decryption parameter spec\", ex);\n\t\t}\n\t}", "summary_tokens": ["initializes", "the", "cipher", "for", "use"], "project": "spring-security"}
{"id": 464, "code": "\tpublic void basicAuthenticationWhenUsingEntryPointRefThenMatchesNamespace() throws Exception {\n\t\tthis.spring.register(EntryPointRefHttpBasicConfig.class, UserConfig.class).autowire();\n\t\tthis.mvc.perform(get(\"/\")).andExpect(status().is(999));\n\t\tthis.mvc.perform(get(\"/\").with(httpBasic(\"user\", \"invalid\"))).andExpect(status().is(999));\n\t\tthis.mvc.perform(get(\"/\").with(httpBasic(\"user\", \"password\"))).andExpect(status().isNotFound());\n\t}", "summary_tokens": ["http", "http", "basic", "point", "ref"], "project": "spring-security"}
{"id": 1847, "code": "\tpublic void setAllowedParameterNames(Predicate<String> allowedParameterNames) {\n\t\tAssert.notNull(allowedParameterNames, \"allowedParameterNames cannot be null\");\n\t\tthis.allowedParameterNames = allowedParameterNames;\n\t}", "summary_tokens": ["determines", "which", "parameter", "names", "should", "be", "allowed"], "project": "spring-security"}
{"id": 193, "code": "\tpublic final T permitAll(boolean permitAll) {\n\t\tthis.permitAll = permitAll;\n\t\treturn getSelf();\n\t}", "summary_tokens": ["ensures", "the", "urls", "for", "failure", "url", "string", "as", "well", "as", "for", "the", "http", "security", "builder", "the", "get", "login", "page", "and", "get", "login", "processing", "url", "are", "granted", "access", "to", "any", "user"], "project": "spring-security"}
{"id": 377, "code": "\tpublic Constraint anyMessage() {\n\t\treturn matchers(MessageMatcher.ANY_MESSAGE);\n\t}", "summary_tokens": ["maps", "any", "message", "to", "a", "security", "expression"], "project": "spring-security"}
{"id": 1071, "code": "\tpublic String getPassword() {\n\t\treturn this.password;\n\t}", "summary_tokens": ["returns", "the", "resource", "owner", "s", "password"], "project": "spring-security"}
{"id": 310, "code": "\tprivate AbstractRememberMeServices createRememberMeServices(H http, String key) {\n\t\treturn (this.tokenRepository != null) ? createPersistentRememberMeServices(http, key)\n\t\t\t\t: createTokenBasedRememberMeServices(http, key);\n\t}", "summary_tokens": ["creates", "the", "remember", "me", "services", "to", "use", "when", "none", "is", "provided"], "project": "spring-security"}
{"id": 363, "code": "\tpublic OAuth2ResourceServerConfigurer<H> jwt(Customizer<JwtConfigurer> jwtCustomizer) {\n\t\tif (this.jwtConfigurer == null) {\n\t\t\tthis.jwtConfigurer = new JwtConfigurer(this.context);\n\t\t}\n\t\tjwtCustomizer.customize(this.jwtConfigurer);\n\t\treturn this;\n\t}", "summary_tokens": ["enables", "jwt", "encoded", "bearer", "token", "support"], "project": "spring-security"}
{"id": 1603, "code": "\tpublic void setAuthenticationSuccessHandler(AuthenticationSuccessHandler successHandler) {\n\t\tAssert.notNull(successHandler, \"successHandler cannot be null\");\n\t\tthis.successHandler = successHandler;\n\t}", "summary_tokens": ["sets", "the", "strategy", "used", "to", "handle", "a", "successful", "authentication"], "project": "spring-security"}
{"id": 413, "code": "\tstatic void validateHttpRedirect(String url, ParserContext pc, Object source) {\n\t\tif (!StringUtils.hasText(url) || UrlUtils.isValidRedirectUrl(url) || url.startsWith(\"$\")\n\t\t\t\t|| url.startsWith(\"#\")) {\n\t\t\treturn;\n\t\t}\n\t\tpc.getReaderContext().warning(url + \" is not a valid redirect URL (must start with '/' or http(s))\", source);\n\t}", "summary_tokens": ["checks", "the", "value", "of", "an", "xml", "attribute", "which", "represents", "a", "redirect", "url"], "project": "spring-security"}
{"id": 888, "code": "\tpublic Map<String, List<String>> getAttributes() {\n\t\treturn this.attributes;\n\t}", "summary_tokens": ["returns", "the", "ldap", "attributes", "the", "ldap", "attributes", "map", "can", "be", "null"], "project": "spring-security"}
{"id": 2032, "code": "\tprivate void checkContentLength(long contentLengthToWrite) {\n\t\tthis.contentWritten += contentLengthToWrite;\n\t\tboolean isBodyFullyWritten = this.contentLength > 0 && this.contentWritten >= this.contentLength;\n\t\tint bufferSize = getBufferSize();\n\t\tboolean requiresFlush = bufferSize > 0 && this.contentWritten >= bufferSize;\n\t\tif (isBodyFullyWritten || requiresFlush) {\n\t\t\tdoOnResponseCommitted();\n\t\t}\n\t}", "summary_tokens": ["adds", "the", "content", "length", "to", "write", "to", "the", "total", "content", "written", "size", "and", "checks", "to", "see", "if", "the", "response", "should", "be", "written"], "project": "spring-security"}
{"id": 1750, "code": "\tpublic void setTargetUrl(String targetUrl) {\n\t\tthis.targetUrl = targetUrl;\n\t}", "summary_tokens": ["sets", "the", "url", "to", "go", "to", "after", "a", "successful", "switch", "exit", "user", "request"], "project": "spring-security"}
{"id": 1479, "code": "\tpublic void setAuthoritiesMapper(GrantedAuthoritiesMapper authoritiesMapper) {\n\t\tAssert.notNull(authoritiesMapper, \"authoritiesMapper cannot be null\");\n\t\tthis.authoritiesMapper = authoritiesMapper;\n\t}", "summary_tokens": ["sets", "the", "granted", "authorities", "mapper", "used", "for", "mapping", "assertion", "attributes", "to", "a", "new", "set", "of", "authorities", "which", "will", "be", "associated", "to", "the", "saml", "0", "authentication"], "project": "spring-security"}
{"id": 611, "code": "\tpublic void setAuthorizationEventPublisher(AuthorizationEventPublisher eventPublisher) {\n\t\tAssert.notNull(eventPublisher, \"eventPublisher cannot be null\");\n\t\tthis.eventPublisher = eventPublisher;\n\t}", "summary_tokens": ["use", "this", "authorization", "event", "publisher", "to", "publish", "the", "authorization", "manager", "result"], "project": "spring-security"}
{"id": 1240, "code": "\tpublic String getCode() {\n\t\treturn this.code;\n\t}", "summary_tokens": ["returns", "the", "authorization", "code"], "project": "spring-security"}
{"id": 1112, "code": "\tpublic static ClientRegistration.Builder fromOidcIssuerLocation(String issuer) {\n\t\tAssert.hasText(issuer, \"issuer cannot be empty\");\n\t\treturn getBuilder(issuer, oidc(URI.create(issuer)));\n\t}", "summary_tokens": ["creates", "a", "client", "registration"], "project": "spring-security"}
{"id": 245, "code": "\tpublic FormLoginConfigurer<H> successForwardUrl(String forwardUrl) {\n\t\tsuccessHandler(new ForwardAuthenticationSuccessHandler(forwardUrl));\n\t\treturn this;\n\t}", "summary_tokens": ["forward", "authentication", "success", "handler", "forward", "url", "the", "target", "url", "in", "case", "of", "success", "the", "form", "login", "configurer", "for", "additional", "customization"], "project": "spring-security"}
{"id": 531, "code": "\tpublic void decide(Authentication authentication, Object object, Collection<ConfigAttribute> configAttributes)\n\t\t\tthrows AccessDeniedException {\n\t\tint deny = 0;\n\t\tfor (AccessDecisionVoter voter : getDecisionVoters()) {\n\t\t\tint result = voter.vote(authentication, object, configAttributes);\n\t\t\tswitch (result) {\n\t\t\tcase AccessDecisionVoter.ACCESS_GRANTED:\n\t\t\t\treturn;\n\t\t\tcase AccessDecisionVoter.ACCESS_DENIED:\n\t\t\t\tdeny++;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (deny > 0) {\n\t\t\tthrow new AccessDeniedException(\n\t\t\t\t\tthis.messages.getMessage(\"AbstractAccessDecisionManager.accessDenied\", \"Access is denied\"));\n\t\t}\n\t\t\n\t\tcheckAllowIfAllAbstainDecisions();\n\t}", "summary_tokens": ["this", "concrete", "implementation", "simply", "polls", "all", "configured", "access", "decision", "voter", "s", "and", "grants", "access", "if", "any", "code", "access", "decision", "voter", "code", "voted", "affirmatively"], "project": "spring-security"}
{"id": 1895, "code": "\tprivate Object resolveSecurityContext(MethodParameter parameter, SecurityContext securityContext) {\n\t\tCurrentSecurityContext annotation = findMethodAnnotation(CurrentSecurityContext.class, parameter);\n\t\tObject securityContextResult = securityContext;\n\t\tString expressionToParse = annotation.expression();\n\t\tif (StringUtils.hasLength(expressionToParse)) {\n\t\t\tStandardEvaluationContext context = new StandardEvaluationContext();\n\t\t\tcontext.setRootObject(securityContext);\n\t\t\tcontext.setVariable(\"this\", securityContext);\n\t\t\tcontext.setBeanResolver(this.beanResolver);\n\t\t\tExpression expression = this.parser.parseExpression(expressionToParse);\n\t\t\tsecurityContextResult = expression.getValue(context);\n\t\t}\n\t\tif (isInvalidType(parameter, securityContextResult)) {\n\t\t\tif (annotation.errorOnInvalidType()) {\n\t\t\t\tthrow new ClassCastException(\n\t\t\t\t\t\tsecurityContextResult + \" is not assignable to \" + parameter.getParameterType());\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t\treturn securityContextResult;\n\t}", "summary_tokens": ["resolve", "the", "expression", "from", "current", "security", "context", "annotation", "to", "get", "the", "value"], "project": "spring-security"}
{"id": 1910, "code": "\tpublic void setSessionAttrName(String sessionAttrName) {\n\t\tthis.sessionAttrName = sessionAttrName;\n\t}", "summary_tokens": ["if", "the", "session", "attr", "name", "property", "is", "set", "the", "request", "is", "stored", "in", "the", "session", "using", "this", "attribute", "name"], "project": "spring-security"}
{"id": 1377, "code": "\tpublic void setBearerTokenHeaderName(String bearerTokenHeaderName) {\n\t\tthis.bearerTokenHeaderName = bearerTokenHeaderName;\n\t}", "summary_tokens": ["set", "this", "value", "to", "configure", "what", "header", "is", "checked", "when", "resolving", "a", "bearer", "token"], "project": "spring-security"}
{"id": 845, "code": "\tprotected UserDetailsContextMapper getUserDetailsContextMapper() {\n\t\treturn this.userDetailsContextMapper;\n\t}", "summary_tokens": ["provides", "access", "to", "the", "injected", "user", "details", "context", "mapper", "strategy", "for", "use", "by", "subclasses"], "project": "spring-security"}
{"id": 368, "code": "\tpublic Saml2LoginConfigurer<B> authenticationRequestResolver(\n\t\t\tSaml2AuthenticationRequestResolver authenticationRequestResolver) {\n\t\tAssert.notNull(authenticationRequestResolver, \"authenticationRequestResolver cannot be null\");\n\t\tthis.authenticationRequestResolver = authenticationRequestResolver;\n\t\treturn this;\n\t}", "summary_tokens": ["use", "this", "saml", "0", "authentication", "request", "resolver", "for", "generating", "saml", "0"], "project": "spring-security"}
{"id": 727, "code": "\tpublic void setAuthoritiesAsString(List<String> authoritiesAsStrings) {\n\t\tsetAuthorities(new ArrayList<>(authoritiesAsStrings.size()));\n\t\tfor (String authority : authoritiesAsStrings) {\n\t\t\taddAuthority(new SimpleGrantedAuthority(authority));\n\t\t}\n\t}", "summary_tokens": ["set", "all", "authorities", "for", "this", "user", "from", "string", "values"], "project": "spring-security"}
{"id": 410, "code": "\tprivate BeanReference createAuthenticationManager(Element element, ParserContext pc,\n\t\t\tManagedList<BeanReference> authenticationProviders) {\n\t\tString parentMgrRef = element.getAttribute(ATT_AUTHENTICATION_MANAGER_REF);\n\t\tBeanDefinitionBuilder authManager = BeanDefinitionBuilder.rootBeanDefinition(ProviderManager.class);\n\t\tauthManager.addConstructorArgValue(authenticationProviders);\n\t\tif (StringUtils.hasText(parentMgrRef)) {\n\t\t\tRuntimeBeanReference parentAuthManager = new RuntimeBeanReference(parentMgrRef);\n\t\t\tauthManager.addConstructorArgValue(parentAuthManager);\n\t\t\tRootBeanDefinition clearCredentials = new RootBeanDefinition(\n\t\t\t\t\tClearCredentialsMethodInvokingFactoryBean.class);\n\t\t\tclearCredentials.getPropertyValues().addPropertyValue(\"targetObject\", parentAuthManager);\n\t\t\tclearCredentials.getPropertyValues().addPropertyValue(\"targetMethod\",\n\t\t\t\t\t\"isEraseCredentialsAfterAuthentication\");\n\t\t\tauthManager.addPropertyValue(\"eraseCredentialsAfterAuthentication\", clearCredentials);\n\t\t}\n\t\telse {\n\t\t\tRootBeanDefinition amfb = new RootBeanDefinition(AuthenticationManagerFactoryBean.class);\n\t\t\tamfb.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\t\tString amfbId = pc.getReaderContext().generateBeanName(amfb);\n\t\t\tpc.registerBeanComponent(new BeanComponentDefinition(amfb, amfbId));\n\t\t\tRootBeanDefinition clearCredentials = new RootBeanDefinition(MethodInvokingFactoryBean.class);\n\t\t\tclearCredentials.getPropertyValues().addPropertyValue(\"targetObject\", new RuntimeBeanReference(amfbId));\n\t\t\tclearCredentials.getPropertyValues().addPropertyValue(\"targetMethod\",\n\t\t\t\t\t\"isEraseCredentialsAfterAuthentication\");\n\t\t\tauthManager.addConstructorArgValue(new RuntimeBeanReference(amfbId));\n\t\t\tauthManager.addPropertyValue(\"eraseCredentialsAfterAuthentication\", clearCredentials);\n\t\t}\n\t\t\n\t\tauthManager.addPropertyValue(\"authenticationEventPublisher\",\n\t\t\t\tnew RootBeanDefinition(DefaultAuthenticationEventPublisher.class));\n\t\tauthManager.getRawBeanDefinition().setSource(pc.extractSource(element));\n\t\tBeanDefinition authMgrBean = authManager.getBeanDefinition();\n\t\tString id = pc.getReaderContext().generateBeanName(authMgrBean);\n\t\tpc.registerBeanComponent(new BeanComponentDefinition(authMgrBean, id));\n\t\treturn new RuntimeBeanReference(id);\n\t}", "summary_tokens": ["creates", "the", "internal", "authentication", "manager", "bean", "which", "uses", "either", "the", "externally", "registered", "global", "one", "as", "a", "parent", "or", "the", "bean", "specified", "by", "authentication", "manager", "ref"], "project": "spring-security"}
{"id": 1312, "code": "\tpublic static <T extends JwtDecoder> T fromIssuerLocation(String issuer) {\n\t\tAssert.hasText(issuer, \"issuer cannot be empty\");\n\t\tMap<String, Object> configuration = JwtDecoderProviderConfigurationUtils\n\t\t\t\t.getConfigurationForIssuerLocation(issuer);\n\t\treturn (T) withProviderConfiguration(configuration, issuer);\n\t}", "summary_tokens": ["creates", "a", "jwt", "decoder", "using", "the", "provided", "a", "href", "https", "openid"], "project": "spring-security"}
{"id": 710, "code": "\tpublic static UserBuilder withDefaultPasswordEncoder() {\n\t\tlogger.warn(\"User.withDefaultPasswordEncoder() is considered unsafe for production \"\n\t\t\t\t+ \"and is only intended for sample applications.\");\n\t\tPasswordEncoder encoder = PasswordEncoderFactories.createDelegatingPasswordEncoder();\n\t\treturn builder().passwordEncoder(encoder::encode);\n\t}", "summary_tokens": ["p", "b", "warning", "b", "this", "method", "is", "considered", "unsafe", "for", "production", "and", "is", "only", "intended", "for", "sample", "applications"], "project": "spring-security"}
{"id": 455, "code": "\tpublic ServerHttpSecurity headers(Customizer<HeaderSpec> headerCustomizer) {\n\t\tif (this.headers == null) {\n\t\t\tthis.headers = new HeaderSpec();\n\t\t}\n\t\theaderCustomizer.customize(this.headers);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "http", "response", "headers"], "project": "spring-security"}
{"id": 1323, "code": "\tpublic void setClaimSetConverter(Converter<Map<String, Object>, Map<String, Object>> claimSetConverter) {\n\t\tAssert.notNull(claimSetConverter, \"claimSetConverter cannot be null\");\n\t\tthis.claimSetConverter = claimSetConverter;\n\t}", "summary_tokens": ["use", "the", "following", "converter", "for", "manipulating", "the", "jwt", "s", "claim", "set", "claim", "set", "converter", "the", "converter", "to", "use"], "project": "spring-security"}
{"id": 1168, "code": "\tpublic final void setRequestCache(ServerRequestCache requestCache) {\n\t\tAssert.notNull(requestCache, \"requestCache cannot be null\");\n\t\tthis.requestCache = requestCache;\n\t\tupdateDefaultAuthenticationSuccessHandler();\n\t}", "summary_tokens": ["sets", "the", "server", "request", "cache", "used", "for", "loading", "a", "previously", "saved", "request", "if", "available", "and", "replaying", "it", "after", "completing", "the", "processing", "of", "the", "oauth", "0"], "project": "spring-security"}
{"id": 446, "code": "\tpublic ServerHttpSecurity securityContextRepository(ServerSecurityContextRepository securityContextRepository) {\n\t\tAssert.notNull(securityContextRepository, \"securityContextRepository cannot be null\");\n\t\tthis.securityContextRepository = securityContextRepository;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "strategy", "used", "with", "reactor", "context", "web", "filter"], "project": "spring-security"}
{"id": 688, "code": "\tpublic static void setDeferredContext(Supplier<SecurityContext> deferredContext) {\n\t\tstrategy.setDeferredContext(deferredContext);\n\t}", "summary_tokens": ["sets", "a", "supplier", "that", "will", "return", "the", "current", "context"], "project": "spring-security"}
{"id": 1563, "code": "\tpublic List<SecurityFilterChain> getFilterChains() {\n\t\treturn Collections.unmodifiableList(this.filterChains);\n\t}", "summary_tokens": ["the", "list", "of", "security", "filter", "chain", "s", "which", "will", "be", "matched", "against", "and", "applied", "to", "incoming", "requests"], "project": "spring-security"}
{"id": 411, "code": "\tpublic BeanDefinition parse(Element oauth2ResourceServer, ParserContext pc) {\n\t\tElement jwt = DomUtils.getChildElementByTagName(oauth2ResourceServer, Elements.JWT);\n\t\tElement opaqueToken = DomUtils.getChildElementByTagName(oauth2ResourceServer, Elements.OPAQUE_TOKEN);\n\t\tvalidateConfiguration(oauth2ResourceServer, jwt, opaqueToken, pc);\n\t\tif (jwt != null) {\n\t\t\tBeanDefinition jwtAuthenticationProvider = new JwtBeanDefinitionParser().parse(jwt, pc);\n\t\t\tthis.authenticationProviders.add(new RuntimeBeanReference(\n\t\t\t\t\tpc.getReaderContext().registerWithGeneratedName(jwtAuthenticationProvider)));\n\t\t}\n\t\tif (opaqueToken != null) {\n\t\t\tBeanDefinition opaqueTokenAuthenticationProvider = new OpaqueTokenBeanDefinitionParser().parse(opaqueToken,\n\t\t\t\t\tpc);\n\t\t\tthis.authenticationProviders.add(new RuntimeBeanReference(\n\t\t\t\t\tpc.getReaderContext().registerWithGeneratedName(opaqueTokenAuthenticationProvider)));\n\t\t}\n\t\tBeanMetadataElement bearerTokenResolver = getBearerTokenResolver(oauth2ResourceServer);\n\t\tBeanDefinitionBuilder requestMatcherBuilder = BeanDefinitionBuilder\n\t\t\t\t.rootBeanDefinition(BearerTokenRequestMatcher.class);\n\t\trequestMatcherBuilder.addConstructorArgValue(bearerTokenResolver);\n\t\tBeanDefinition requestMatcher = requestMatcherBuilder.getBeanDefinition();\n\t\tBeanMetadataElement authenticationEntryPoint = getEntryPoint(oauth2ResourceServer);\n\t\tthis.entryPoints.put(requestMatcher, authenticationEntryPoint);\n\t\tthis.deniedHandlers.put(requestMatcher, this.accessDeniedHandler);\n\t\tthis.ignoreCsrfRequestMatchers.add(requestMatcher);\n\t\tBeanDefinitionBuilder filterBuilder = BeanDefinitionBuilder\n\t\t\t\t.rootBeanDefinition(BearerTokenAuthenticationFilter.class);\n\t\tBeanMetadataElement authenticationManagerResolver = getAuthenticationManagerResolver(oauth2ResourceServer);\n\t\tfilterBuilder.addConstructorArgValue(authenticationManagerResolver);\n\t\tfilterBuilder.addPropertyValue(BEARER_TOKEN_RESOLVER, bearerTokenResolver);\n\t\tfilterBuilder.addPropertyValue(AUTHENTICATION_ENTRY_POINT, authenticationEntryPoint);\n\t\treturn filterBuilder.getBeanDefinition();\n\t}", "summary_tokens": ["parse", "a", "lt", "oauth", "0", "resource", "server", "gt", "element", "and", "return", "the", "corresponding", "bearer", "token", "authentication", "filter", "oauth", "0", "resource", "server", "the", "lt", "oauth", "0", "resource", "server", "gt", "element"], "project": "spring-security"}
{"id": 1064, "code": "\tpublic void setRestOperations(RestOperations restOperations) {\n\t\tAssert.notNull(restOperations, \"restOperations cannot be null\");\n\t\tthis.restOperations = restOperations;\n\t}", "summary_tokens": ["sets", "the", "rest", "operations", "used", "when", "requesting", "the", "oauth", "0"], "project": "spring-security"}
{"id": 986, "code": "\tpublic OAuth2AccessToken getAccessToken() {\n\t\treturn this.accessToken;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "access", "token", "access", "token", "credential", "granted"], "project": "spring-security"}
{"id": 290, "code": "\tpublic List<LogoutHandler> getLogoutHandlers() {\n\t\treturn this.logoutHandlers;\n\t}", "summary_tokens": ["gets", "the", "logout", "handler", "instances", "that", "will", "be", "used"], "project": "spring-security"}
{"id": 1744, "code": "\tprotected boolean requiresSwitchUser(HttpServletRequest request) {\n\t\treturn this.switchUserMatcher.matches(request);\n\t}", "summary_tokens": ["checks", "the", "request", "uri", "for", "the", "presence", "of", "tt", "switch", "user", "url", "tt"], "project": "spring-security"}
{"id": 1183, "code": "\tdefault boolean hasClaim(String claim) {\n\t\tAssert.notNull(claim, \"claim cannot be null\");\n\t\treturn getClaims().containsKey(claim);\n\t}", "summary_tokens": ["returns", "true", "if", "the", "claim", "exists", "in", "get", "claims", "otherwise", "false"], "project": "spring-security"}
{"id": 1990, "code": "\tpublic void setRequiresHttpsRedirectMatcher(ServerWebExchangeMatcher requiresHttpsRedirectMatcher) {\n\t\tAssert.notNull(requiresHttpsRedirectMatcher, \"requiresHttpsRedirectMatcher cannot be null\");\n\t\tthis.requiresHttpsRedirectMatcher = requiresHttpsRedirectMatcher;\n\t}", "summary_tokens": ["use", "this", "server", "web", "exchange", "matcher", "to", "narrow", "which", "requests", "are", "redirected", "to", "https"], "project": "spring-security"}
{"id": 225, "code": "\tpublic CsrfConfigurer<H> ignoringRequestMatchers(RequestMatcher... requestMatchers) {\n\t\treturn new IgnoreCsrfProtectionRegistry(this.context).requestMatchers(requestMatchers).and();\n\t}", "summary_tokens": ["p", "allows", "specifying", "http", "servlet", "request", "s", "that", "should", "not", "use", "csrf", "protection", "even", "if", "they", "match", "the", "require", "csrf", "protection", "matcher", "request", "matcher"], "project": "spring-security"}
{"id": 1833, "code": "\tpublic void setAllowedHttpMethods(Collection<String> allowedHttpMethods) {\n\t\tAssert.notNull(allowedHttpMethods, \"allowedHttpMethods cannot be null\");\n\t\tthis.allowedHttpMethods = (allowedHttpMethods != ALLOW_ANY_HTTP_METHOD) ? new HashSet<>(allowedHttpMethods)\n\t\t\t\t: ALLOW_ANY_HTTP_METHOD;\n\t}", "summary_tokens": ["p", "determines", "which", "http", "methods", "should", "be", "allowed"], "project": "spring-security"}
{"id": 1394, "code": "\tpublic boolean isDecryptionCredential() {\n\t\treturn getCredentialTypes().contains(Saml2X509CredentialType.DECRYPTION);\n\t}", "summary_tokens": ["indicate", "whether", "this", "credential", "can", "be", "used", "for", "decryption", "true", "if", "the", "credential", "has", "a", "saml", "0", "x", "0", "credential", "type", "decryption", "type"], "project": "spring-security"}
{"id": 404, "code": "\tprivate BeanMetadataElement createAccessDeniedHandler(BeanDefinition invalidSessionStrategy,\n\t\t\tBeanMetadataElement defaultDeniedHandler) {\n\t\tif (invalidSessionStrategy == null) {\n\t\t\treturn defaultDeniedHandler;\n\t\t}\n\t\tManagedMap<Class<? extends AccessDeniedException>, BeanDefinition> handlers = new ManagedMap<>();\n\t\tBeanDefinitionBuilder invalidSessionHandlerBldr = BeanDefinitionBuilder\n\t\t\t\t.rootBeanDefinition(InvalidSessionAccessDeniedHandler.class);\n\t\tinvalidSessionHandlerBldr.addConstructorArgValue(invalidSessionStrategy);\n\t\thandlers.put(MissingCsrfTokenException.class, invalidSessionHandlerBldr.getBeanDefinition());\n\t\tBeanDefinitionBuilder deniedBldr = BeanDefinitionBuilder\n\t\t\t\t.rootBeanDefinition(DelegatingAccessDeniedHandler.class);\n\t\tdeniedBldr.addConstructorArgValue(handlers);\n\t\tdeniedBldr.addConstructorArgValue(defaultDeniedHandler);\n\t\treturn deniedBldr.getBeanDefinition();\n\t}", "summary_tokens": ["creates", "the", "access", "denied", "handler", "from", "the", "result", "of", "get", "default", "access", "denied", "handler", "http", "security", "builder", "and", "get", "invalid", "session", "strategy", "http", "security", "builder"], "project": "spring-security"}
{"id": 4, "code": "\tprotected Sid createCurrentUser(Authentication authentication) {\n\t\treturn new PrincipalSid(authentication);\n\t}", "summary_tokens": ["creates", "a", "principal", "like", "sid", "from", "the", "authentication", "information"], "project": "spring-security"}
{"id": 668, "code": "\tpublic void setStringSeparator(String stringSeparator) {\n\t\tthis.stringSeparator = stringSeparator;\n\t}", "summary_tokens": ["string", "separator", "the", "string", "separator", "to", "set"], "project": "spring-security"}
{"id": 661, "code": "\tpublic List<GrantedAuthority> getGrantedAuthorities(Collection<String> attributes) {\n\t\tArrayList<GrantedAuthority> result = new ArrayList<>();\n\t\tfor (String attribute : attributes) {\n\t\t\tCollection<GrantedAuthority> granted = this.attributes2grantedAuthoritiesMap.get(attribute);\n\t\t\tif (granted != null) {\n\t\t\t\tresult.addAll(granted);\n\t\t\t}\n\t\t}\n\t\tresult.trimToSize();\n\t\treturn result;\n\t}", "summary_tokens": ["map", "the", "given", "array", "of", "attributes", "to", "spring", "security", "granted", "authorities"], "project": "spring-security"}
{"id": 1656, "code": "\tprotected void successfulAuthentication(HttpServletRequest request, HttpServletResponse response,\n\t\t\tAuthentication authResult) throws IOException, ServletException {\n\t\tthis.logger.debug(LogMessage.format(\"Authentication success: %s\", authResult));\n\t\tSecurityContext context = this.securityContextHolderStrategy.createEmptyContext();\n\t\tcontext.setAuthentication(authResult);\n\t\tthis.securityContextHolderStrategy.setContext(context);\n\t\tthis.securityContextRepository.saveContext(context, request, response);\n\t\tif (this.eventPublisher != null) {\n\t\t\tthis.eventPublisher.publishEvent(new InteractiveAuthenticationSuccessEvent(authResult, this.getClass()));\n\t\t}\n\t\tif (this.authenticationSuccessHandler != null) {\n\t\t\tthis.authenticationSuccessHandler.onAuthenticationSuccess(request, response, authResult);\n\t\t}\n\t}", "summary_tokens": ["puts", "the", "code", "authentication", "code", "instance", "returned", "by", "the", "authentication", "manager", "into", "the", "secure", "context"], "project": "spring-security"}
{"id": 1672, "code": "\tpublic void setPreAuthenticatedUserDetailsService(\n\t\t\tAuthenticationUserDetailsService<PreAuthenticatedAuthenticationToken> uds) {\n\t\tthis.preAuthenticatedUserDetailsService = uds;\n\t}", "summary_tokens": ["set", "the", "authenticated", "user", "details", "service", "to", "be", "used", "to", "load", "the", "user", "details", "for", "the", "authenticated", "user"], "project": "spring-security"}
{"id": 1359, "code": "\tpublic Map<String, Object> getAttributes() {\n\t\treturn this.delegate.getAttributes();\n\t}", "summary_tokens": ["gets", "the", "attributes", "of", "the", "oauth", "0"], "project": "spring-security"}
{"id": 1198, "code": "\tpublic final String getDescription() {\n\t\treturn this.description;\n\t}", "summary_tokens": ["returns", "the", "error", "description"], "project": "spring-security"}
{"id": 1506, "code": "\tpublic boolean authorize() throws IOException {\n\t\tif (StringUtils.hasText(getAccess())) {\n\t\t\treturn authorizeUsingAccessExpression();\n\t\t}\n\t\tif (StringUtils.hasText(getUrl())) {\n\t\t\treturn authorizeUsingUrlCheck();\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["make", "an", "authorization", "decision", "by", "considering", "all", "lt", "authorize", "gt", "tag", "attributes"], "project": "spring-security"}
{"id": 1020, "code": "\tprivate boolean hasRemovalErrorCode(OAuth2AuthorizationException authorizationException) {\n\t\treturn this.removeAuthorizedClientErrorCodes.contains(authorizationException.getError().getErrorCode());\n\t}", "summary_tokens": ["returns", "true", "if", "the", "given", "exception", "has", "an", "error", "code", "that", "indicates", "that", "the", "authorized", "client", "should", "be", "removed"], "project": "spring-security"}
{"id": 1853, "code": "\tpublic Set<String> getEncodedUrlBlacklist() {\n\t\treturn getEncodedUrlBlocklist();\n\t}", "summary_tokens": ["provides", "the", "existing", "encoded", "url", "blocklist", "which", "can", "add", "remove", "entries", "from", "the", "existing", "encoded", "url", "blocklist", "never", "null", "use", "get", "encoded", "url", "blocklist", "instead"], "project": "spring-security"}
{"id": 1832, "code": "\tpublic void setUnsafeAllowAnyHttpMethod(boolean unsafeAllowAnyHttpMethod) {\n\t\tthis.allowedHttpMethods = unsafeAllowAnyHttpMethod ? ALLOW_ANY_HTTP_METHOD : createDefaultAllowedHttpMethods();\n\t}", "summary_tokens": ["sets", "if", "any", "http", "method", "is", "allowed"], "project": "spring-security"}
{"id": 939, "code": "\tpublic Mono<OAuth2AuthorizedClient> authorize(OAuth2AuthorizationContext context) {\n\t\tAssert.notNull(context, \"context cannot be null\");\n\t\tif (AuthorizationGrantType.AUTHORIZATION_CODE.equals(\n\t\t\t\tcontext.getClientRegistration().getAuthorizationGrantType()) && context.getAuthorizedClient() == null) {\n\t\t\t\n\t\t\t\n\t\t\treturn Mono.error(() -> new ClientAuthorizationRequiredException(\n\t\t\t\t\tcontext.getClientRegistration().getRegistrationId()));\n\t\t}\n\t\treturn Mono.empty();\n\t}", "summary_tokens": ["attempt", "to", "authorize", "the", "oauth", "0", "authorization", "context", "get", "client", "registration", "client", "in", "the", "provided", "context"], "project": "spring-security"}
{"id": 143, "code": "\tpublic HttpSecurity portMapper(Customizer<PortMapperConfigurer<HttpSecurity>> portMapperCustomizer)\n\t\t\tthrows Exception {\n\t\tportMapperCustomizer.customize(getOrApply(new PortMapperConfigurer<>()));\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["allows", "configuring", "a", "port", "mapper", "that", "is", "available", "from", "http", "security", "get", "shared", "object", "class"], "project": "spring-security"}
{"id": 1791, "code": "\tpublic void setTrustResolver(AuthenticationTrustResolver trustResolver) {\n\t\tAssert.notNull(trustResolver, \"trustResolver cannot be null\");\n\t\tthis.trustResolver = trustResolver;\n\t}", "summary_tokens": ["sets", "the", "authentication", "trust", "resolver", "to", "be", "used"], "project": "spring-security"}
{"id": 640, "code": "\tpublic void setExpressionHandler(MethodSecurityExpressionHandler expressionHandler) {\n\t\tthis.registry = new PreFilterExpressionAttributeRegistry(expressionHandler);\n\t}", "summary_tokens": ["use", "this", "method", "security", "expression", "handler", "expression", "handler", "the", "method", "security", "expression", "handler", "to", "use"], "project": "spring-security"}
{"id": 519, "code": "\tpublic boolean supports(Class<?> clazz) {\n\t\tfor (AfterInvocationProvider provider : this.providers) {\n\t\t\tif (!provider.supports(clazz)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["iterates", "through", "all", "code", "after", "invocation", "provider", "code", "s", "and", "ensures", "each", "can", "support", "the", "presented", "class"], "project": "spring-security"}
{"id": 1792, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy strategy) {\n\t\tAssert.notNull(this.securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = strategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1947, "code": "\tpublic void setLogoutHandler(ServerLogoutHandler logoutHandler) {\n\t\tAssert.notNull(logoutHandler, \"logoutHandler must not be null\");\n\t\tthis.logoutHandler = logoutHandler;\n\t}", "summary_tokens": ["sets", "the", "server", "logout", "handler"], "project": "spring-security"}
{"id": 1574, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1509, "code": "\tpublic boolean authorizeUsingUrlCheck() throws IOException {\n\t\tString contextPath = ((HttpServletRequest) getRequest()).getContextPath();\n\t\tAuthentication currentUser = getContext().getAuthentication();\n\t\treturn getPrivilegeEvaluator().isAllowed(contextPath, getUrl(), getMethod(), currentUser);\n\t}", "summary_tokens": ["make", "an", "authorization", "decision", "based", "on", "the", "url", "and", "http", "method", "attributes"], "project": "spring-security"}
{"id": 733, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1861, "code": "\tpublic void setPolicy(CrossOriginOpenerPolicy openerPolicy) {\n\t\tAssert.notNull(openerPolicy, \"openerPolicy cannot be null\");\n\t\tthis.policy = openerPolicy;\n\t}", "summary_tokens": ["sets", "the", "cross", "origin", "opener", "policy", "value", "to", "be", "used", "in", "the", "cross", "origin", "opener", "policy", "header", "opener", "policy", "the", "cross", "origin", "opener", "policy", "to", "use"], "project": "spring-security"}
{"id": 1316, "code": "\tpublic JwtClaimsSet getClaims() {\n\t\treturn this.claims;\n\t}", "summary_tokens": ["returns", "the", "jwt", "claims", "set", "claims"], "project": "spring-security"}
{"id": 1801, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 95, "code": "\tpublic LdapAuthenticationProviderConfigurer<B> groupSearchSubtree(boolean groupSearchSubtree) {\n\t\tthis.groupSearchSubtree = groupSearchSubtree;\n\t\treturn this;\n\t}", "summary_tokens": ["if", "set", "to", "true", "a", "subtree", "scope", "search", "will", "be", "performed", "for", "group", "membership"], "project": "spring-security"}
{"id": 142, "code": "\tpublic HttpSecurity sessionManagement(\n\t\t\tCustomizer<SessionManagementConfigurer<HttpSecurity>> sessionManagementCustomizer) throws Exception {\n\t\tsessionManagementCustomizer.customize(getOrApply(new SessionManagementConfigurer<>()));\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["allows", "configuring", "of", "session", "management"], "project": "spring-security"}
{"id": 804, "code": "\tpublic void testHashpw() {\n\t\tprint(\"BCrypt.hashpw(): \");\n\t\tfor (TestObject<String> test : testObjectsString) {\n\t\t\tString hashed = BCrypt.hashpw(test.password, test.salt);\n\t\t\tassertThat(hashed).isEqualTo(test.expected);\n\t\t\tprint(\".\");\n\t\t}\n\t\tprintln(\"\");\n\t}", "summary_tokens": ["test", "method", "for", "bcrypt"], "project": "spring-security"}
{"id": 1718, "code": "\tpublic void setSecurityContextRepository(SecurityContextRepository securityContextRepository) {\n\t\tAssert.notNull(securityContextRepository, \"securityContextRepository cannot be null\");\n\t\tthis.securityContextRepository = securityContextRepository;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "repository", "to", "save", "the", "security", "context", "on", "authentication", "success"], "project": "spring-security"}
{"id": 1876, "code": "\tpublic void setEnabled(boolean enabled) {\n\t\tif (!enabled) {\n\t\t\tsetBlock(false);\n\t\t}\n\t\tthis.enabled = enabled;\n\t\tupdateHeaderValue();\n\t}", "summary_tokens": ["if", "true", "will", "contain", "a", "value", "of", "0"], "project": "spring-security"}
{"id": 1238, "code": "\tpublic static Builder from(OAuth2AuthorizationRequest authorizationRequest) {\n\t\tAssert.notNull(authorizationRequest, \"authorizationRequest cannot be null\");\n\t\t\n\t\treturn new Builder(authorizationRequest.getGrantType())\n\t\t\t\t.authorizationUri(authorizationRequest.getAuthorizationUri())\n\t\t\t\t.clientId(authorizationRequest.getClientId())\n\t\t\t\t.redirectUri(authorizationRequest.getRedirectUri())\n\t\t\t\t.scopes(authorizationRequest.getScopes())\n\t\t\t\t.state(authorizationRequest.getState())\n\t\t\t\t.additionalParameters(authorizationRequest.getAdditionalParameters())\n\t\t\t\t.attributes(authorizationRequest.getAttributes());\n\t\t\n\t}", "summary_tokens": ["returns", "a", "new", "builder", "initialized", "with", "the", "values", "from", "the", "provided", "authorization", "request"], "project": "spring-security"}
{"id": 575, "code": "\tpublic void setRefreshConfigurationOnStartup(boolean refresh) {\n\t\tthis.refreshConfigurationOnStartup = refresh;\n\t}", "summary_tokens": ["if", "set", "a", "call", "to", "configuration", "refresh", "will", "be", "made", "by", "configure", "jaas", "resource", "method"], "project": "spring-security"}
{"id": 1560, "code": "\tpublic void setContextRelative(boolean useRelativeContext) {\n\t\tthis.contextRelative = useRelativeContext;\n\t}", "summary_tokens": ["if", "tt", "true", "tt", "causes", "any", "redirection", "urls", "to", "be", "calculated", "minus", "the", "protocol", "and", "context", "path", "defaults", "to", "tt", "false", "tt"], "project": "spring-security"}
{"id": 532, "code": "\tpublic boolean supports(Class<?> clazz) {\n\t\treturn true;\n\t}", "summary_tokens": ["this", "implementation", "supports", "any", "type", "of", "class", "because", "it", "does", "not", "query", "the", "presented", "secure", "object"], "project": "spring-security"}
{"id": 1173, "code": "\tprivate String getStateParameter(ServerWebExchange exchange) {\n\t\tAssert.notNull(exchange, \"exchange cannot be null\");\n\t\treturn exchange.getRequest().getQueryParams().getFirst(OAuth2ParameterNames.STATE);\n\t}", "summary_tokens": ["gets", "the", "state", "parameter", "from", "the", "server", "http", "request", "exchange", "the", "exchange", "to", "use", "the", "state", "parameter", "or", "null", "if", "not", "found"], "project": "spring-security"}
{"id": 72, "code": "\tpublic AuthenticationManagerBuilder authenticationEventPublisher(AuthenticationEventPublisher eventPublisher) {\n\t\tAssert.notNull(eventPublisher, \"AuthenticationEventPublisher cannot be null\");\n\t\tthis.eventPublisher = eventPublisher;\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "authentication", "event", "publisher", "event", "publisher", "the", "authentication", "event", "publisher", "to", "use", "the", "authentication", "manager", "builder", "for", "further", "customizations"], "project": "spring-security"}
{"id": 318, "code": "\tpublic SessionManagementConfigurer<H> invalidSessionUrl(String invalidSessionUrl) {\n\t\tthis.invalidSessionUrl = invalidSessionUrl;\n\t\treturn this;\n\t}", "summary_tokens": ["setting", "this", "attribute", "will", "inject", "the", "session", "management", "filter", "with", "a", "simple", "redirect", "invalid", "session", "strategy", "configured", "with", "the", "attribute", "value"], "project": "spring-security"}
{"id": 1335, "code": "\tpublic static ReactiveJwtDecoder fromIssuerLocation(String issuer) {\n\t\tAssert.hasText(issuer, \"issuer cannot be empty\");\n\t\tMap<String, Object> configuration = JwtDecoderProviderConfigurationUtils\n\t\t\t\t.getConfigurationForIssuerLocation(issuer);\n\t\treturn withProviderConfiguration(configuration, issuer);\n\t}", "summary_tokens": ["creates", "a", "reactive", "jwt", "decoder", "using", "the", "provided", "a", "href", "https", "openid"], "project": "spring-security"}
{"id": 237, "code": "\tAuthenticationEntryPoint getAuthenticationEntryPoint(H http) {\n\t\tAuthenticationEntryPoint entryPoint = this.authenticationEntryPoint;\n\t\tif (entryPoint == null) {\n\t\t\tentryPoint = createDefaultEntryPoint(http);\n\t\t}\n\t\treturn entryPoint;\n\t}", "summary_tokens": ["gets", "the", "authentication", "entry", "point", "according", "to", "the", "rules", "specified", "by", "authentication", "entry", "point", "authentication", "entry", "point", "http", "the", "http", "security", "used", "to", "look", "up", "shared", "authentication", "entry", "point", "the", "authentication", "entry", "point", "to", "use"], "project": "spring-security"}
{"id": 1575, "code": "\tpublic boolean isAllowed(String contextPath, String uri, String method, Authentication authentication) {\n\t\tList<WebInvocationPrivilegeEvaluator> privilegeEvaluators = getDelegate(contextPath, uri, method);\n\t\tif (privilegeEvaluators.isEmpty()) {\n\t\t\treturn true;\n\t\t}\n\t\tfor (WebInvocationPrivilegeEvaluator evaluator : privilegeEvaluators) {\n\t\t\tboolean isAllowed = evaluator.isAllowed(contextPath, uri, method, authentication);\n\t\t\tif (!isAllowed) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["determines", "whether", "the", "user", "represented", "by", "the", "supplied", "tt", "authentication", "tt", "object", "is", "allowed", "to", "invoke", "the", "supplied", "uri"], "project": "spring-security"}
{"id": 1106, "code": "\tpublic String getRedirectUri() {\n\t\treturn this.redirectUri;\n\t}", "summary_tokens": ["returns", "the", "uri", "or", "uri", "template", "for", "the", "redirection", "endpoint"], "project": "spring-security"}
{"id": 1553, "code": "\tpublic static CsrfTokenRepository getCsrfTokenRepository(HttpServletRequest request) {\n\t\tCsrfFilter filter = findFilter(request, CsrfFilter.class);\n\t\tif (filter == null) {\n\t\t\treturn DEFAULT_TOKEN_REPO;\n\t\t}\n\t\treturn (CsrfTokenRepository) ReflectionTestUtils.getField(filter, \"tokenRepository\");\n\t}", "summary_tokens": ["gets", "the", "csrf", "token", "repository", "for", "the", "specified", "http", "servlet", "request"], "project": "spring-security"}
{"id": 632, "code": "\tpublic void setExpressionHandler(MethodSecurityExpressionHandler expressionHandler) {\n\t\tthis.registry = new PostFilterExpressionAttributeRegistry(expressionHandler);\n\t}", "summary_tokens": ["use", "this", "method", "security", "expression", "handler"], "project": "spring-security"}
{"id": 344, "code": "\tprivate static String[] hasAnyRole(String... roles) {\n\t\tfor (int i = 0; i < roles.length; i++) {\n\t\t\troles[i] = \"ROLE_\" + roles[i];\n\t\t}\n\t\treturn roles;\n\t}", "summary_tokens": ["creates", "a", "string", "for", "specifying", "that", "a", "user", "requires", "one", "of", "many", "roles"], "project": "spring-security"}
{"id": 745, "code": "\tpublic void interfacesNeverContributeAnnotationsMethodLevel() throws Exception {\n\t\tParent target = new Parent();\n\t\tMockMethodInvocation mi = new MockMethodInvocation(target, target.getClass(), \"interfaceMethod\");\n\t\tCollection<ConfigAttribute> accessAttributes = this.mds.getAttributes(mi);\n\t\tassertThat(accessAttributes).isEmpty();\n\t}", "summary_tokens": ["the", "interfaces", "implemented", "by", "a", "class", "never", "contribute", "annotations", "to", "the", "class", "itself", "or", "any", "of", "its", "members"], "project": "spring-security"}
{"id": 2038, "code": "\tprivate Throwable extractCause(Throwable throwable) {\n\t\tfor (Map.Entry<Class<? extends Throwable>, ThrowableCauseExtractor> entry : this.extractorMap.entrySet()) {\n\t\t\tClass<? extends Throwable> throwableType = entry.getKey();\n\t\t\tif (throwableType.isInstance(throwable)) {\n\t\t\t\tThrowableCauseExtractor extractor = entry.getValue();\n\t\t\t\treturn extractor.extractCause(throwable);\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["extracts", "the", "cause", "of", "the", "given", "throwable", "using", "an", "appropriate", "extractor"], "project": "spring-security"}
{"id": 1999, "code": "\tvoid setAuthenticationManager(AuthenticationManager authenticationManager) {\n\t\tthis.authenticationManager = authenticationManager;\n\t}", "summary_tokens": ["p", "sets", "the", "authentication", "manager", "used", "when", "integrating", "http", "servlet", "request", "with", "servlet", "0", "apis"], "project": "spring-security"}
{"id": 428, "code": "\tpublic void setManagerPassword(String managerPassword) {\n\t\tthis.managerPassword = managerPassword;\n\t}", "summary_tokens": ["the", "password", "for", "the", "manager", "dn"], "project": "spring-security"}
{"id": 1072, "code": "\tpublic OAuth2AccessToken getAccessToken() {\n\t\treturn this.accessToken;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "access", "token", "access", "token", "credential", "granted"], "project": "spring-security"}
{"id": 1050, "code": "\tfinal Converter<T, HttpHeaders> getHeadersConverter() {\n\t\treturn this.headersConverter;\n\t}", "summary_tokens": ["returns", "the", "converter", "used", "for", "converting", "the", "abstract", "oauth", "0", "authorization", "grant", "request", "instance", "to", "a", "http", "headers", "used", "in", "the", "oauth", "0"], "project": "spring-security"}
{"id": 841, "code": "\tprotected Authentication createSuccessfulAuthentication(UsernamePasswordAuthenticationToken authentication,\n\t\t\tUserDetails user) {\n\t\tObject password = this.useAuthenticationRequestCredentials ? authentication.getCredentials()\n\t\t\t\t: user.getPassword();\n\t\tUsernamePasswordAuthenticationToken result = UsernamePasswordAuthenticationToken.authenticated(user, password,\n\t\t\t\tthis.authoritiesMapper.mapAuthorities(user.getAuthorities()));\n\t\tresult.setDetails(authentication.getDetails());\n\t\tthis.logger.debug(\"Authenticated user\");\n\t\treturn result;\n\t}", "summary_tokens": ["creates", "the", "final", "authentication", "object", "which", "will", "be", "returned", "from", "the", "authenticate", "method"], "project": "spring-security"}
{"id": 1769, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 270, "code": "\tpublic JeeConfigurer<H> mappableRoles(String... mappableRoles) {\n\t\tthis.mappableRoles.clear();\n\t\tfor (String role : mappableRoles) {\n\t\t\tthis.mappableRoles.add(\"ROLE_\" + role);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["specifies", "roles", "to", "use", "map", "from", "the", "http", "servlet", "request", "to", "the", "user", "details", "and", "automatically", "prefixes", "it", "with", "role"], "project": "spring-security"}
{"id": 83, "code": "\tpublic LdapAuthenticationProviderConfigurer<B> withObjectPostProcessor(ObjectPostProcessor<?> objectPostProcessor) {\n\t\taddObjectPostProcessor(objectPostProcessor);\n\t\treturn this;\n\t}", "summary_tokens": ["adds", "an", "object", "post", "processor", "for", "this", "class"], "project": "spring-security"}
{"id": 1841, "code": "\tpublic void setAllowUrlEncodedCarriageReturn(boolean allowUrlEncodedCarriageReturn) {\n\t\tif (allowUrlEncodedCarriageReturn) {\n\t\t\turlBlocklistsRemoveAll(FORBIDDEN_CR);\n\t\t}\n\t\telse {\n\t\t\turlBlocklistsAddAll(FORBIDDEN_CR);\n\t\t}\n\t}", "summary_tokens": ["determines", "if", "a", "url", "encoded", "carriage", "return", "is", "allowed", "in", "the", "path", "or", "not"], "project": "spring-security"}
{"id": 1544, "code": "\tpublic static OAuth2LoginRequestPostProcessor oauth2Login() {\n\t\tOAuth2AccessToken accessToken = new OAuth2AccessToken(OAuth2AccessToken.TokenType.BEARER, \"access-token\", null,\n\t\t\t\tnull, Collections.singleton(\"read\"));\n\t\treturn new OAuth2LoginRequestPostProcessor(accessToken);\n\t}", "summary_tokens": ["establish", "a", "security", "context", "that", "has", "a", "oauth", "0", "authentication", "token", "for", "the", "authentication", "a", "oauth", "0", "user", "as", "the", "principal", "and", "a", "oauth", "0", "authorized", "client", "in", "the", "session"], "project": "spring-security"}
{"id": 160, "code": "\tpublic HttpSecurity authenticationManager(AuthenticationManager authenticationManager) {\n\t\tAssert.notNull(authenticationManager, \"authenticationManager cannot be null\");\n\t\tthis.authenticationManager = authenticationManager;\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["configure", "the", "default", "authentication", "manager"], "project": "spring-security"}
{"id": 637, "code": "\tpublic AuthorizationDecision check(Supplier<Authentication> authentication, MethodInvocation mi) {\n\t\tExpressionAttribute attribute = this.registry.getAttribute(mi);\n\t\tif (attribute == ExpressionAttribute.NULL_ATTRIBUTE) {\n\t\t\treturn null;\n\t\t}\n\t\tEvaluationContext ctx = this.registry.getExpressionHandler().createEvaluationContext(authentication, mi);\n\t\tboolean granted = ExpressionUtils.evaluateAsBoolean(attribute.getExpression(), ctx);\n\t\treturn new ExpressionAuthorizationDecision(granted, attribute.getExpression());\n\t}", "summary_tokens": ["determine", "if", "an", "authentication", "has", "access", "to", "a", "method", "by", "evaluating", "an", "expression", "from", "the", "pre", "authorize", "annotation", "that", "the", "method", "invocation", "specifies"], "project": "spring-security"}
{"id": 1557, "code": "\tpublic void applySpringSecurityWhenAddFilterFirstThenFilterFirst() throws Exception {\n\t\tMockMvc mockMvc = MockMvcBuilders.webAppContextSetup(this.wac).addFilters(this.noOpFilter)\n\t\t\t\t.apply(springSecurity()).build();\n\t\tmockMvc.perform(get(\"/\")).andExpect(status().isOk());\n\t}", "summary_tokens": ["since", "no", "op", "filter", "is", "first", "does", "not", "continue", "the", "chain", "security", "will", "not", "be", "invoked", "and", "the", "status", "should", "be", "ok", "exception"], "project": "spring-security"}
{"id": 1129, "code": "\tpublic void setAuthorizationSuccessHandler(OAuth2AuthorizationSuccessHandler authorizationSuccessHandler) {\n\t\tAssert.notNull(authorizationSuccessHandler, \"authorizationSuccessHandler cannot be null\");\n\t\tthis.authorizationSuccessHandler = authorizationSuccessHandler;\n\t}", "summary_tokens": ["sets", "the", "oauth", "0", "authorization", "success", "handler", "that", "handles", "successful", "authorizations"], "project": "spring-security"}
{"id": 1572, "code": "\tpublic void setErrorPage(String errorPage) {\n\t\tAssert.isTrue(errorPage == null || errorPage.startsWith(\"/\"), \"errorPage must begin with '/'\");\n\t\tthis.errorPage = errorPage;\n\t}", "summary_tokens": ["the", "error", "page", "to", "use"], "project": "spring-security"}
{"id": 1207, "code": "\tdefault Instant getExpiresAt() {\n\t\treturn getClaimAsInstant(OAuth2TokenIntrospectionClaimNames.EXP);\n\t}", "summary_tokens": ["returns", "a", "timestamp", "exp", "indicating", "when", "the", "token", "expires", "a", "timestamp", "indicating", "when", "the", "token", "expires"], "project": "spring-security"}
{"id": 397, "code": "\tpublic static ReactiveUserDetailsServiceResourceFactoryBean fromString(String users) {\n\t\tReactiveUserDetailsServiceResourceFactoryBean result = new ReactiveUserDetailsServiceResourceFactoryBean();\n\t\tresult.setResource(new InMemoryResource(users));\n\t\treturn result;\n\t}", "summary_tokens": ["create", "a", "reactive", "user", "details", "service", "resource", "factory", "bean", "with", "a", "string", "that", "is", "in", "the", "format", "defined", "in", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 88, "code": "\tprivate PasswordComparisonAuthenticator createPasswordCompareAuthenticator(\n\t\t\tBaseLdapPathContextSource contextSource) {\n\t\tPasswordComparisonAuthenticator ldapAuthenticator = new PasswordComparisonAuthenticator(contextSource);\n\t\tif (this.passwordAttribute != null) {\n\t\t\tldapAuthenticator.setPasswordAttributeName(this.passwordAttribute);\n\t\t}\n\t\tldapAuthenticator.setPasswordEncoder(this.passwordEncoder);\n\t\treturn ldapAuthenticator;\n\t}", "summary_tokens": ["creates", "password", "comparison", "authenticator", "context", "source", "the", "base", "ldap", "path", "context", "source", "to", "use"], "project": "spring-security"}
{"id": 1647, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 32, "code": "\tprotected void updateObjectIdentity(MutableAcl acl) {\n\t\tLong parentId = null;\n\t\tif (acl.getParentAcl() != null) {\n\t\t\tAssert.isInstanceOf(ObjectIdentityImpl.class, acl.getParentAcl().getObjectIdentity(),\n\t\t\t\t\t\"Implementation only supports ObjectIdentityImpl\");\n\t\t\tObjectIdentityImpl oii = (ObjectIdentityImpl) acl.getParentAcl().getObjectIdentity();\n\t\t\tparentId = retrieveObjectIdentityPrimaryKey(oii);\n\t\t}\n\t\tAssert.notNull(acl.getOwner(), \"Owner is required in this implementation\");\n\t\tLong ownerSid = createOrRetrieveSidPrimaryKey(acl.getOwner(), true);\n\t\tint count = this.jdbcOperations.update(this.updateObjectIdentity, parentId, ownerSid, acl.isEntriesInheriting(),\n\t\t\t\tacl.getId());\n\t\tif (count != 1) {\n\t\t\tthrow new NotFoundException(\"Unable to locate ACL to update\");\n\t\t}\n\t}", "summary_tokens": ["updates", "an", "existing", "acl", "object", "identity", "row", "with", "new", "information", "presented", "in", "the", "passed", "mutable", "acl", "object"], "project": "spring-security"}
{"id": 354, "code": "\tpublic OAuth2ClientConfigurer<B> authorizedClientService(OAuth2AuthorizedClientService authorizedClientService) {\n\t\tAssert.notNull(authorizedClientService, \"authorizedClientService cannot be null\");\n\t\tthis.authorizedClientRepository(\n\t\t\t\tnew AuthenticatedPrincipalOAuth2AuthorizedClientRepository(authorizedClientService));\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "service", "for", "authorized", "client", "s"], "project": "spring-security"}
{"id": 817, "code": "\tpublic void setRoleHierarchy(RoleHierarchy roleHierarchy) {\n\t\tAssert.notNull(roleHierarchy, \"roleHierarchy cannot be null\");\n\t\tthis.roleHierarchy = roleHierarchy;\n\t}", "summary_tokens": ["sets", "the", "role", "hierarchy", "to", "be", "used"], "project": "spring-security"}
{"id": 1049, "code": "\tpublic void setWebClient(WebClient webClient) {\n\t\tAssert.notNull(webClient, \"webClient cannot be null\");\n\t\tthis.webClient = webClient;\n\t}", "summary_tokens": ["sets", "the", "web", "client", "used", "when", "requesting", "the", "oauth", "0"], "project": "spring-security"}
{"id": 2016, "code": "\tpublic void setRedirectStrategy(RedirectStrategy redirectStrategy) {\n\t\tthis.redirectStrategy = redirectStrategy;\n\t}", "summary_tokens": ["sets", "the", "redirect", "strategy", "used", "with", "concurrent", "session", "filter", "session", "registry", "string", "redirect", "strategy", "the", "redirect", "strategy", "to", "use", "use", "concurrent", "session", "filter", "session", "registry", "session", "information", "expired", "strategy", "instead"], "project": "spring-security"}
{"id": 783, "code": "\tpublic static PasswordEncoder createDelegatingPasswordEncoder() {\n\t\tString encodingId = \"bcrypt\";\n\t\tMap<String, PasswordEncoder> encoders = new HashMap<>();\n\t\tencoders.put(encodingId, new BCryptPasswordEncoder());\n\t\tencoders.put(\"ldap\", new org.springframework.security.crypto.password.LdapShaPasswordEncoder());\n\t\tencoders.put(\"MD4\", new org.springframework.security.crypto.password.Md4PasswordEncoder());\n\t\tencoders.put(\"MD5\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"MD5\"));\n\t\tencoders.put(\"noop\", org.springframework.security.crypto.password.NoOpPasswordEncoder.getInstance());\n\t\tencoders.put(\"pbkdf2\", new Pbkdf2PasswordEncoder());\n\t\tencoders.put(\"scrypt\", new SCryptPasswordEncoder());\n\t\tencoders.put(\"SHA-1\", new org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"SHA-1\"));\n\t\tencoders.put(\"SHA-256\",\n\t\t\t\tnew org.springframework.security.crypto.password.MessageDigestPasswordEncoder(\"SHA-256\"));\n\t\tencoders.put(\"sha256\", new org.springframework.security.crypto.password.StandardPasswordEncoder());\n\t\tencoders.put(\"argon2\", new Argon2PasswordEncoder());\n\t\treturn new DelegatingPasswordEncoder(encodingId, encoders);\n\t}", "summary_tokens": ["creates", "a", "delegating", "password", "encoder", "with", "default", "mappings"], "project": "spring-security"}
{"id": 1497, "code": "\tpublic Authentication authenticate(Authentication authentication) throws AuthenticationException {\n\t\ttry {\n\t\t\tSaml2AuthenticationToken token = (Saml2AuthenticationToken) authentication;\n\t\t\tString serializedResponse = token.getSaml2Response();\n\t\t\tResponse response = parseResponse(serializedResponse);\n\t\t\tprocess(token, response);\n\t\t\tAbstractAuthenticationToken authenticationResponse = this.responseAuthenticationConverter\n\t\t\t\t\t.convert(new ResponseToken(response, token));\n\t\t\tif (authenticationResponse != null) {\n\t\t\t\tauthenticationResponse.setDetails(authentication.getDetails());\n\t\t\t}\n\t\t\treturn authenticationResponse;\n\t\t}\n\t\tcatch (Saml2AuthenticationException ex) {\n\t\t\tthrow ex;\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthrow createAuthenticationException(Saml2ErrorCodes.INTERNAL_VALIDATION_ERROR, ex.getMessage(), ex);\n\t\t}\n\t}", "summary_tokens": ["authentication", "the", "authentication", "request", "object", "must", "be", "of", "type", "saml", "0", "authentication", "token", "saml", "0", "authentication", "if", "the", "assertion", "is", "valid", "authentication", "exception", "if", "a", "validation", "exception", "occurs"], "project": "spring-security"}
{"id": 1930, "code": "\tpublic void setRedirectStrategy(ServerRedirectStrategy redirectStrategy) {\n\t\tAssert.notNull(redirectStrategy, \"redirectStrategy cannot be null\");\n\t\tthis.redirectStrategy = redirectStrategy;\n\t}", "summary_tokens": ["sets", "the", "redirect", "strategy", "to", "use"], "project": "spring-security"}
{"id": 853, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1520, "code": "\tpublic void beforeTestMethod(TestContext testContext) {\n\t\tTestSecurityContext testSecurityContext = createTestSecurityContext(testContext.getTestMethod(), testContext);\n\t\tif (testSecurityContext == null) {\n\t\t\ttestSecurityContext = createTestSecurityContext(testContext.getTestClass(), testContext);\n\t\t}\n\t\tif (testSecurityContext == null) {\n\t\t\treturn;\n\t\t}\n\t\tSupplier<SecurityContext> supplier = testSecurityContext.getSecurityContextSupplier();\n\t\tif (testSecurityContext.getTestExecutionEvent() == TestExecutionEvent.TEST_METHOD) {\n\t\t\tthis.securityContextHolderStrategyConverter.convert(testContext).setContext(supplier.get());\n\t\t}\n\t\telse {\n\t\t\ttestContext.setAttribute(SECURITY_CONTEXT_ATTR_NAME, supplier);\n\t\t}\n\t}", "summary_tokens": ["sets", "up", "the", "security", "context", "for", "each", "test", "method"], "project": "spring-security"}
{"id": 1809, "code": "\tpublic void setCookiePath(String path) {\n\t\tthis.cookiePath = path;\n\t}", "summary_tokens": ["set", "the", "path", "that", "the", "cookie", "will", "be", "created", "with"], "project": "spring-security"}
{"id": 1224, "code": "\tpublic static Builder withResponse(OAuth2AccessTokenResponse response) {\n\t\treturn new Builder(response);\n\t}", "summary_tokens": ["returns", "a", "new", "builder", "initialized", "with", "the", "provided", "response"], "project": "spring-security"}
{"id": 426, "code": "\tpublic void setRoot(String root) {\n\t\tthis.root = root;\n\t}", "summary_tokens": ["optional", "root", "suffix", "for", "the", "embedded", "ldap", "server"], "project": "spring-security"}
{"id": 53, "code": "\tpublic Map<Class<?>, Object> getSharedObjects() {\n\t\treturn Collections.unmodifiableMap(this.sharedObjects);\n\t}", "summary_tokens": ["gets", "the", "shared", "objects", "the", "shared", "objects"], "project": "spring-security"}
{"id": 350, "code": "\tpublic X509Configurer<H> authenticationUserDetailsService(\n\t\t\tAuthenticationUserDetailsService<PreAuthenticatedAuthenticationToken> authenticationUserDetailsService) {\n\t\tthis.authenticationUserDetailsService = authenticationUserDetailsService;\n\t\treturn this;\n\t}", "summary_tokens": ["specifies", "the", "authentication", "user", "details", "service", "to", "use"], "project": "spring-security"}
{"id": 908, "code": "\tprivate int getMaxSearchDepth() {\n\t\treturn this.maxSearchDepth;\n\t}", "summary_tokens": ["how", "far", "should", "a", "nested", "search", "go"], "project": "spring-security"}
{"id": 1383, "code": "\tpublic boolean hasErrors() {\n\t\treturn !this.errors.isEmpty();\n\t}", "summary_tokens": ["say", "whether", "this", "result", "indicates", "success", "whether", "this", "result", "has", "errors"], "project": "spring-security"}
{"id": 8, "code": "\tprotected void registerPublicPermissions(Class<? extends Permission> clazz) {\n\t\tAssert.notNull(clazz, \"Class required\");\n\t\tField[] fields = clazz.getFields();\n\t\tfor (Field field : fields) {\n\t\t\ttry {\n\t\t\t\tObject fieldValue = field.get(null);\n\t\t\t\tif (Permission.class.isAssignableFrom(fieldValue.getClass())) {\n\t\t\t\t\t\n\t\t\t\t\tPermission perm = (Permission) fieldValue;\n\t\t\t\t\tString permissionName = field.getName();\n\t\t\t\t\tregisterPermission(perm, permissionName);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["registers", "the", "public", "static", "fields", "of", "type", "permission", "for", "a", "give", "class"], "project": "spring-security"}
{"id": 374, "code": "\tpublic Saml2LogoutConfigurer<H> relyingPartyRegistrationRepository(RelyingPartyRegistrationRepository repo) {\n\t\tthis.relyingPartyRegistrationRepository = repo;\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "relying", "party", "registration", "repository", "of", "relying", "parties", "each", "party", "representing", "a", "service", "provider", "sp", "and", "this", "host", "and", "identity", "provider", "idp", "pair", "that", "communicate", "with", "each", "other"], "project": "spring-security"}
{"id": 1868, "code": "\tpublic void setReportOnly(boolean reportOnly) {\n\t\tthis.reportOnly = reportOnly;\n\t}", "summary_tokens": ["p", "to", "get", "a", "public", "key", "pins", "header", "you", "should", "set", "this", "to", "false", "otherwise", "the", "header", "will", "be", "public", "key", "pins", "report", "only"], "project": "spring-security"}
{"id": 1823, "code": "\tpublic void setHeaderName(String headerName) {\n\t\tAssert.hasLength(headerName, \"headerName cannot be null or empty\");\n\t\tthis.headerName = headerName;\n\t}", "summary_tokens": ["sets", "the", "header", "name", "that", "the", "csrf", "token", "is", "expected", "to", "appear", "on", "and", "the", "header", "that", "the", "response", "will", "contain", "the", "csrf", "token"], "project": "spring-security"}
{"id": 1095, "code": "\tpublic final void setOauth2UserService(OAuth2UserService<OAuth2UserRequest, OAuth2User> oauth2UserService) {\n\t\tAssert.notNull(oauth2UserService, \"oauth2UserService cannot be null\");\n\t\tthis.oauth2UserService = oauth2UserService;\n\t}", "summary_tokens": ["sets", "the", "oauth", "0", "user", "service", "used", "when", "requesting", "the", "user", "info", "resource"], "project": "spring-security"}
{"id": 768, "code": "\tprivate static byte[] encodeBytesToBytes(byte[] source, int off, int len, int options) {\n\n\t\tif (source == null) {\n\t\t\tthrow new NullPointerException(\"Cannot serialize a null array.\");\n\t\t} \n\n\t\tif (off < 0) {\n\t\t\tthrow new IllegalArgumentException(\"Cannot have negative offset: \" + off);\n\t\t} \n\n\t\tif (len < 0) {\n\t\t\tthrow new IllegalArgumentException(\"Cannot have length offset: \" + len);\n\t\t} \n\n\t\tif (off + len > source.length) {\n\t\t\tthrow new IllegalArgumentException(String.format(\n\t\t\t\t\t\"Cannot have offset of %d and length of %d with array of length %d\", off, len, source.length));\n\t\t} \n\n\t\tboolean breakLines = (options & DO_BREAK_LINES) > 0;\n\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\n\t\t\n\t\tint encLen = (len / 3) * 4 + ((len % 3 > 0) ? 4 : 0);\n\n\t\tif (breakLines) {\n\t\t\tencLen += encLen / MAX_LINE_LENGTH; \n\t\t}\n\t\tbyte[] outBuff = new byte[encLen];\n\n\t\tint d = 0;\n\t\tint e = 0;\n\t\tint len2 = len - 2;\n\t\tint lineLength = 0;\n\t\tfor (; d < len2; d += 3, e += 4) {\n\t\t\tencode3to4(source, d + off, 3, outBuff, e, options);\n\n\t\t\tlineLength += 4;\n\t\t\tif (breakLines && lineLength >= MAX_LINE_LENGTH) {\n\t\t\t\toutBuff[e + 4] = NEW_LINE;\n\t\t\t\te++;\n\t\t\t\tlineLength = 0;\n\t\t\t} \n\t\t} \n\n\t\tif (d < len) {\n\t\t\tencode3to4(source, d + off, len - d, outBuff, e, options);\n\t\t\te += 4;\n\t\t} \n\n\t\t\n\t\tif (e <= outBuff.length - 1) {\n\t\t\tbyte[] finalOut = new byte[e];\n\t\t\tSystem.arraycopy(outBuff, 0, finalOut, 0, e);\n\t\t\t\n\t\t\t\n\t\t\treturn finalOut;\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\treturn outBuff;\n\t\t}\n\t}", "summary_tokens": ["source", "the", "data", "to", "convert", "off", "offset", "in", "array", "where", "conversion", "should", "begin", "len", "length", "of", "data", "to", "convert", "options", "specified", "options", "the", "base", "0", "encoded", "data", "as", "a", "string", "java"], "project": "spring-security"}
{"id": 149, "code": "\tpublic HttpSecurity requestCache(Customizer<RequestCacheConfigurer<HttpSecurity>> requestCacheCustomizer)\n\t\t\tthrows Exception {\n\t\trequestCacheCustomizer.customize(getOrApply(new RequestCacheConfigurer<>()));\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["allows", "configuring", "the", "request", "cache"], "project": "spring-security"}
{"id": 1997, "code": "\tpublic void setServletPath(String servletPath) {\n\t\tthis.servletPath = servletPath;\n\t}", "summary_tokens": ["the", "servlet", "path", "to", "match", "on"], "project": "spring-security"}
{"id": 398, "code": "\tpublic void setResourceLocation(String resourceLocation) {\n\t\tthis.resourceLocation = resourceLocation;\n\t}", "summary_tokens": ["sets", "the", "location", "of", "a", "resource", "that", "is", "a", "properties", "file", "in", "the", "format", "defined", "in", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 1031, "code": "\tpublic OAuth2AccessToken getAccessToken() {\n\t\treturn this.accessToken;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "access", "token", "access", "token"], "project": "spring-security"}
{"id": 691, "code": "\tpublic static SecurityContextHolderStrategy getContextHolderStrategy() {\n\t\treturn strategy;\n\t}", "summary_tokens": ["allows", "retrieval", "of", "the", "context", "strategy"], "project": "spring-security"}
{"id": 1782, "code": "\tprotected EnumSet<DispatcherType> getSecurityDispatcherTypes() {\n\t\treturn EnumSet.of(DispatcherType.REQUEST, DispatcherType.ERROR, DispatcherType.ASYNC);\n\t}", "summary_tokens": ["get", "the", "dispatcher", "type", "for", "the", "spring", "security", "filter", "chain"], "project": "spring-security"}
{"id": 471, "code": "\tprivate Collection<Attribute> attrgrp(XmlNode e) {\n\t\tCollection<Attribute> attrs = attrs(e);\n\t\tattrs.addAll(attrgrps(e));\n\t\treturn attrs;\n\t}", "summary_tokens": ["processes", "an", "individual", "attribute", "group", "by", "obtaining", "all", "the", "attributes", "and", "then", "looking", "for", "more", "attribute", "group", "elements", "and", "prcessing", "them"], "project": "spring-security"}
{"id": 1694, "code": "\tprotected Object getPreAuthenticatedPrincipal(HttpServletRequest httpRequest) {\n\t\tObject principal = this.wasHelper.getCurrentUserName();\n\t\tthis.logger.debug(LogMessage.format(\"PreAuthenticated WebSphere principal: %s\", principal));\n\t\treturn principal;\n\t}", "summary_tokens": ["return", "the", "web", "sphere", "user", "name"], "project": "spring-security"}
{"id": 692, "code": "\tpublic static SecurityContext createEmptyContext() {\n\t\treturn strategy.createEmptyContext();\n\t}", "summary_tokens": ["delegates", "the", "creation", "of", "a", "new", "empty", "context", "to", "the", "configured", "strategy"], "project": "spring-security"}
{"id": 1727, "code": "\tpublic void onAuthentication(Authentication authentication, HttpServletRequest request,\n\t\t\tHttpServletResponse response) {\n\t\tint allowedSessions = getMaximumSessionsForThisUser(authentication);\n\t\tif (allowedSessions == -1) {\n\t\t\t\n\t\t\treturn;\n\t\t}\n\t\tList<SessionInformation> sessions = this.sessionRegistry.getAllSessions(authentication.getPrincipal(), false);\n\t\tint sessionCount = sessions.size();\n\t\tif (sessionCount < allowedSessions) {\n\t\t\t\n\t\t\treturn;\n\t\t}\n\t\tif (sessionCount == allowedSessions) {\n\t\t\tHttpSession session = request.getSession(false);\n\t\t\tif (session != null) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tfor (SessionInformation si : sessions) {\n\t\t\t\t\tif (si.getSessionId().equals(session.getId())) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\t\n\t\t\t\n\t\t}\n\t\tallowableSessionsExceeded(sessions, allowedSessions, this.sessionRegistry);\n\t}", "summary_tokens": ["in", "addition", "to", "the", "steps", "from", "the", "superclass", "the", "session", "registry", "will", "be", "updated", "with", "the", "new", "session", "information"], "project": "spring-security"}
{"id": 818, "code": "\tpublic void setPermissionEvaluator(PermissionEvaluator permissionEvaluator) {\n\t\tAssert.notNull(permissionEvaluator, \"permissionEvaluator cannot be null\");\n\t\tthis.permissionEvaluator = permissionEvaluator;\n\t}", "summary_tokens": ["sets", "the", "permission", "evaluator", "to", "be", "used"], "project": "spring-security"}
{"id": 1481, "code": "\tpublic static Converter<AssertionToken, Saml2ResponseValidatorResult> createDefaultAssertionValidator(\n\t\t\tConverter<AssertionToken, ValidationContext> contextConverter) {\n\n\t\treturn createAssertionValidator(Saml2ErrorCodes.INVALID_ASSERTION,\n\t\t\t\t(assertionToken) -> SAML20AssertionValidators.attributeValidator, contextConverter);\n\t}", "summary_tokens": ["construct", "a", "default", "strategy", "for", "validating", "each", "saml", "0"], "project": "spring-security"}
{"id": 729, "code": "\tprivate static void addToModulesList(ClassLoader loader, List<Module> modules, String className) {\n\t\tModule module = loadAndGetInstance(className, loader);\n\t\tif (module != null) {\n\t\t\tmodules.add(module);\n\t\t}\n\t}", "summary_tokens": ["loader", "the", "class", "loader", "to", "use", "modules", "list", "of", "the", "modules", "to", "add", "class", "name", "name", "of", "the", "class", "to", "instantiate"], "project": "spring-security"}
{"id": 761, "code": "\tprivate byte[] crypt_raw(byte password[], byte salt[], int log_rounds, boolean sign_ext_bug, int safety,\n\t\t\tboolean for_check) {\n\t\tint cdata[] = bf_crypt_ciphertext.clone();\n\t\tint clen = cdata.length;\n\n\t\tlong rounds;\n\t\tif (log_rounds < 4 || log_rounds > 31) {\n\t\t\tif (!for_check) {\n\t\t\t\tthrow new IllegalArgumentException(\"Bad number of rounds\");\n\t\t\t}\n\t\t\tif (log_rounds != 0) {\n\t\t\t\tthrow new IllegalArgumentException(\"Bad number of rounds\");\n\t\t\t}\n\t\t\trounds = 0;\n\t\t}\n\t\telse {\n\t\t\trounds = roundsForLogRounds(log_rounds);\n\t\t\tif (rounds < 16 || rounds > 2147483648L) {\n\t\t\t\tthrow new IllegalArgumentException(\"Bad number of rounds\");\n\t\t\t}\n\t\t}\n\n\t\tif (salt.length != BCRYPT_SALT_LEN) {\n\t\t\tthrow new IllegalArgumentException(\"Bad salt length\");\n\t\t}\n\n\t\tinit_key();\n\t\tekskey(salt, password, sign_ext_bug, safety);\n\t\tfor (int i = 0; i < rounds; i++) {\n\t\t\tkey(password, sign_ext_bug, safety);\n\t\t\tkey(salt, false, safety);\n\t\t}\n\n\t\tfor (int i = 0; i < 64; i++) {\n\t\t\tfor (int j = 0; j < (clen >> 1); j++) {\n\t\t\t\tencipher(cdata, j << 1);\n\t\t\t}\n\t\t}\n\n\t\tbyte[] ret = new byte[clen * 4];\n\t\tfor (int i = 0, j = 0; i < clen; i++) {\n\t\t\tret[j++] = (byte) ((cdata[i] >> 24) & 0xff);\n\t\t\tret[j++] = (byte) ((cdata[i] >> 16) & 0xff);\n\t\t\tret[j++] = (byte) ((cdata[i] >> 8) & 0xff);\n\t\t\tret[j++] = (byte) (cdata[i] & 0xff);\n\t\t}\n\t\treturn ret;\n\t}", "summary_tokens": ["perform", "the", "central", "password", "hashing", "step", "in", "the", "bcrypt", "scheme", "password", "the", "password", "to", "hash", "salt", "the", "binary", "salt", "to", "hash", "with", "the", "password", "log", "rounds", "the", "binary", "logarithm", "of", "the", "number", "of", "rounds", "of", "hashing", "to", "apply", "sign", "ext", "bug", "true", "to", "implement", "the", "0", "x", "bug", "safety", "bit", "0", "is", "set", "when", "the", "safety", "measure", "is", "requested", "an", "array", "containing", "the", "binary", "hashed", "password"], "project": "spring-security"}
{"id": 821, "code": "\tpublic void testConcurrencyOfReadAndRemoveIsSafe() {\n\t\tObject principal = \"Joe Principal\";\n\t\tSessionRegistryImpl sessionregistry = new SessionRegistryImpl();\n\t\tSet sessions = Collections.synchronizedSet(new HashSet());\n\t\t\n\t\tfor (int i = 0; i < 50; i++) {\n\t\t\tString sessionId = Integer.toString(i);\n\t\t\tsessions.add(sessionId);\n\t\t\tsessionregistry.registerNewSession(sessionId, principal);\n\t\t}\n\n\t\t\n\t\tfor (int i=0; i < 10; i++) {\n\t\t\tThread reader = new Thread(new SessionRegistryReader(principal, sessionregistry));\n\t\t\treader.start();\n\t\t}\n\n\t\tThread remover = new Thread(new SessionRemover(\"remover\", sessionregistry, sessions));\n\n\t\tremover.start();\n\n\t\twhile(remover.isAlive()) {\n\t\t\tpause(250);\n\t\t}\n\n\t\tassertThat(errorOccurred).as(\"Thread errors detected; review log output for details\").isFalse();\n\t}", "summary_tokens": ["reproduces", "the", "npe", "mentioned", "in", "sec", "0", "where", "a", "session", "id", "is", "removed", "from", "the", "set", "of", "sessions", "before", "it", "is", "removed", "from", "the", "list", "of", "sessions", "for", "a", "principal"], "project": "spring-security"}
{"id": 927, "code": "\tpublic void setAdapterRegistry(ReactiveAdapterRegistry adapterRegistry) {\n\t\tAssert.notNull(adapterRegistry, \"adapterRegistry cannot be null\");\n\t\tthis.adapterRegistry = adapterRegistry;\n\t}", "summary_tokens": ["sets", "the", "reactive", "adapter", "registry", "to", "be", "used"], "project": "spring-security"}
{"id": 1386, "code": "\tpublic static Saml2ResponseValidatorResult success() {\n\t\treturn NO_ERRORS;\n\t}", "summary_tokens": ["construct", "a", "successful", "saml", "0", "response", "validator", "result", "an", "saml", "0", "response", "validator", "result", "with", "no", "errors"], "project": "spring-security"}
{"id": 1568, "code": "\tpublic String getFullRequestUrl() {\n\t\treturn UrlUtils.buildFullRequestUrl(this.request);\n\t}", "summary_tokens": ["indicates", "the", "url", "that", "the", "user", "agent", "used", "for", "this", "request"], "project": "spring-security"}
{"id": 1422, "code": "\tpublic Saml2MessageBinding getBinding() {\n\t\treturn this.binding;\n\t}", "summary_tokens": ["get", "the", "binding", "for", "the", "asserting", "party", "s", "a", "href", "https", "docs"], "project": "spring-security"}
{"id": 325, "code": "\tpublic SessionManagementConfigurer<H> sessionAuthenticationStrategy(\n\t\t\tSessionAuthenticationStrategy sessionAuthenticationStrategy) {\n\t\tthis.providedSessionAuthenticationStrategy = sessionAuthenticationStrategy;\n\t\treturn this;\n\t}", "summary_tokens": ["allows", "explicitly", "specifying", "the", "session", "authentication", "strategy"], "project": "spring-security"}
{"id": 1865, "code": "\tpublic void addSha256Pins(String... pins) {\n\t\tfor (String pin : pins) {\n\t\t\tAssert.notNull(pin, \"pin cannot be null\");\n\t\t\tthis.pins.put(pin, \"sha256\");\n\t\t}\n\t\tupdateHpkpHeaderValue();\n\t}", "summary_tokens": ["p", "adds", "a", "list", "of", "sha", "0", "hashed", "pins", "for", "the", "pin", "directive", "of", "the", "public", "key", "pins", "header"], "project": "spring-security"}
{"id": 1413, "code": "\tpublic AbstractSaml2AuthenticationRequest getAuthenticationRequest() {\n\t\treturn this.authenticationRequest;\n\t}", "summary_tokens": ["returns", "the", "authentication", "request", "sent", "to", "the", "assertion", "party", "or", "null", "if", "no", "authentication", "request", "is", "present", "the", "authentication", "request", "sent", "to", "the", "assertion", "party", "0"], "project": "spring-security"}
{"id": 1743, "code": "\tprotected boolean requiresExitUser(HttpServletRequest request) {\n\t\treturn this.exitUserMatcher.matches(request);\n\t}", "summary_tokens": ["checks", "the", "request", "uri", "for", "the", "presence", "of", "tt", "exit", "user", "url", "tt"], "project": "spring-security"}
{"id": 1216, "code": "\tpublic static OAuth2TokenValidatorResult success() {\n\t\treturn NO_ERRORS;\n\t}", "summary_tokens": ["construct", "a", "successful", "oauth", "0", "token", "validator", "result", "an", "oauth", "0", "token", "validator", "result", "with", "no", "errors"], "project": "spring-security"}
{"id": 1336, "code": "\tprivate static ReactiveJwtDecoder withProviderConfiguration(Map<String, Object> configuration, String issuer) {\n\t\tJwtDecoderProviderConfigurationUtils.validateIssuer(configuration, issuer);\n\t\tOAuth2TokenValidator<Jwt> jwtValidator = JwtValidators.createDefaultWithIssuer(issuer);\n\t\tString jwkSetUri = configuration.get(\"jwks_uri\").toString();\n\t\tNimbusReactiveJwtDecoder jwtDecoder = NimbusReactiveJwtDecoder.withJwkSetUri(jwkSetUri)\n\t\t\t\t.jwtProcessorCustomizer(ReactiveJwtDecoderProviderConfigurationUtils::addJWSAlgorithms).build();\n\t\tjwtDecoder.setJwtValidator(jwtValidator);\n\t\treturn jwtDecoder;\n\t}", "summary_tokens": ["build", "reactive", "jwt", "decoder", "from", "a", "href", "https", "openid"], "project": "spring-security"}
{"id": 452, "code": "\tpublic ServerHttpSecurity x509(Customizer<X509Spec> x509Customizer) {\n\t\tif (this.x509 == null) {\n\t\t\tthis.x509 = new X509Spec();\n\t\t}\n\t\tx509Customizer.customize(this.x509);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "x", "0", "authentication", "using", "a", "certificate", "provided", "by", "a", "client"], "project": "spring-security"}
{"id": 2353, "code": "public static Bitmap createArgb8888BitmapFromCurrentGlFramebuffer(int width, int height) {\n  ByteBuffer rgba8888Buffer = ByteBuffer.allocateDirect(width * height * 4);\n  GLES20.glReadPixels(\n      0, 0, width, height, GLES20.GL_RGBA, GLES20.GL_UNSIGNED_BYTE, rgba8888Buffer);\n  GlUtil.checkGlError();\n  Bitmap bitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888);\n    \n    \n    \n  bitmap.copyPixelsFromBuffer(rgba8888Buffer);\n    \n  return flipBitmapVertically(bitmap);\n}", "summary_tokens": ["creates", "a", "bitmap", "with", "the", "values", "of", "the", "current", "open", "gl", "framebuffer"], "project": "ExoPlayer"}
{"id": 2026, "code": "public void reset() {\n  revision = 0;\n  type = 0;\n  granulePosition = 0;\n  streamSerialNumber = 0;\n  pageSequenceNumber = 0;\n  pageChecksum = 0;\n  pageSegmentCount = 0;\n  headerSize = 0;\n  bodySize = 0;\n}", "summary_tokens": ["resets", "all", "primitive", "member", "fields", "to", "zero"], "project": "ExoPlayer"}
{"id": 1475, "code": "protected void skipOutputBuffer(VideoDecoderOutputBuffer outputBuffer) {\n  decoderCounters.skippedOutputBufferCount++;\n  outputBuffer.release();\n}", "summary_tokens": ["skips", "the", "specified", "output", "buffer", "and", "releases", "it"], "project": "ExoPlayer"}
{"id": 1370, "code": "public static long getStreamPositionUs(\n    long positionUs, MediaPeriodId mediaPeriodId, AdPlaybackState adPlaybackState) {\n  return mediaPeriodId.isAd()\n      ? getStreamPositionUsForAd(\n          positionUs, mediaPeriodId.adGroupIndex, mediaPeriodId.adIndexInAdGroup, adPlaybackState)\n      : getStreamPositionUsForContent(\n          positionUs, mediaPeriodId.nextAdGroupIndex, adPlaybackState);\n}", "summary_tokens": ["returns", "the", "position", "in", "the", "underlying", "server", "side", "inserted", "ads", "stream", "for", "a", "position", "in", "a", "media", "period"], "project": "ExoPlayer"}
{"id": 153, "code": "public SessionCallbackBuilder setRatingCallback(@Nullable RatingCallback ratingCallback) {\n  this.ratingCallback = ratingCallback;\n  return this;\n}", "summary_tokens": ["sets", "the", "rating", "callback", "to", "handle", "user", "ratings"], "project": "ExoPlayer"}
{"id": 51, "code": "private boolean updateTimeline() {\n  CastTimeline oldTimeline = currentTimeline;\n  MediaStatus status = getMediaStatus();\n  currentTimeline =\n      status != null\n          ? timelineTracker.getCastTimeline(remoteMediaClient)\n          : CastTimeline.EMPTY_CAST_TIMELINE;\n  boolean timelineChanged = !oldTimeline.equals(currentTimeline);\n  if (timelineChanged) {\n    currentWindowIndex = fetchCurrentWindowIndex(remoteMediaClient, currentTimeline);\n  }\n  return timelineChanged;\n}", "summary_tokens": ["updates", "the", "current", "timeline"], "project": "ExoPlayer"}
{"id": 295, "code": "public boolean hasNextWindow() {\n  return player.hasNextWindow();\n}", "summary_tokens": ["calls", "player", "has", "next", "window", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 52, "code": "private boolean updateTracksAndSelectionsAndNotifyIfChanged() {\n  if (remoteMediaClient == null) {\n      \n    return false;\n  }\n\n  @Nullable MediaStatus mediaStatus = getMediaStatus();\n  @Nullable MediaInfo mediaInfo = mediaStatus != null ? mediaStatus.getMediaInfo() : null;\n  @Nullable\n  List<MediaTrack> castMediaTracks = mediaInfo != null ? mediaInfo.getMediaTracks() : null;\n  if (castMediaTracks == null || castMediaTracks.isEmpty()) {\n    boolean hasChanged = !Tracks.EMPTY.equals(currentTracks);\n    currentTracks = Tracks.EMPTY;\n    return hasChanged;\n  }\n  @Nullable long[] activeTrackIds = mediaStatus.getActiveTrackIds();\n  if (activeTrackIds == null) {\n    activeTrackIds = EMPTY_TRACK_ID_ARRAY;\n  }\n\n  Tracks.Group[] trackGroups = new Tracks.Group[castMediaTracks.size()];\n  for (int i = 0; i < castMediaTracks.size(); i++) {\n    MediaTrack mediaTrack = castMediaTracks.get(i);\n    TrackGroup trackGroup =\n        new TrackGroup( Integer.toString(i), CastUtils.mediaTrackToFormat(mediaTrack));\n    @C.FormatSupport int[] trackSupport = new int[] {C.FORMAT_HANDLED};\n    boolean[] trackSelected = new boolean[] {isTrackActive(mediaTrack.getId(), activeTrackIds)};\n    trackGroups[i] =\n        new Tracks.Group(trackGroup,  false, trackSupport, trackSelected);\n  }\n  Tracks newTracks = new Tracks(ImmutableList.copyOf(trackGroups));\n  if (!newTracks.equals(currentTracks)) {\n    currentTracks = newTracks;\n    return true;\n  }\n  return false;\n}", "summary_tokens": ["updates", "the", "internal", "tracks", "and", "selection", "and", "returns", "whether", "they", "have", "changed"], "project": "ExoPlayer"}
{"id": 1204, "code": "public @Requirements.RequirementFlags int getNotMetRequirements() {\n  return notMetRequirements;\n}", "summary_tokens": ["returns", "the", "requirements", "needed", "for", "downloads", "to", "progress", "that", "are", "not", "currently", "met"], "project": "ExoPlayer"}
{"id": 2643, "code": "public void setCues(@Nullable List<Cue> cues) {\n  this.cues = (cues != null ? cues : Collections.emptyList());\n  updateOutput();\n}", "summary_tokens": ["sets", "the", "cues", "to", "be", "displayed", "by", "the", "view"], "project": "ExoPlayer"}
{"id": 822, "code": "public boolean isMuted() {\n  return muted;\n}", "summary_tokens": ["gets", "whether", "the", "current", "audio", "stream", "is", "muted", "or", "not"], "project": "ExoPlayer"}
{"id": 2081, "code": "public long getDurationUs() {\n  return durationUs;\n}", "summary_tokens": ["returns", "the", "duration", "last", "read", "from", "read", "duration", "extractor", "input", "position", "holder"], "project": "ExoPlayer"}
{"id": 1782, "code": "public static void delete(File cacheDir, @Nullable DatabaseProvider databaseProvider) {\n  if (!cacheDir.exists()) {\n    return;\n  }\n\n  File[] files = cacheDir.listFiles();\n  if (files == null) {\n    cacheDir.delete();\n    return;\n  }\n\n  if (databaseProvider != null) {\n      \n      \n    long uid = loadUid(files);\n    if (uid != UID_UNSET) {\n      try {\n        CacheFileMetadataIndex.delete(databaseProvider, uid);\n      } catch (DatabaseIOException e) {\n        Log.w(TAG, \"Failed to delete file metadata: \" + uid);\n      }\n      try {\n        CachedContentIndex.delete(databaseProvider, uid);\n      } catch (DatabaseIOException e) {\n        Log.w(TAG, \"Failed to delete file metadata: \" + uid);\n      }\n    }\n  }\n\n  Util.recursiveDelete(cacheDir);\n}", "summary_tokens": ["deletes", "all", "content", "belonging", "to", "a", "cache", "instance"], "project": "ExoPlayer"}
{"id": 1171, "code": "public static MediaCodecInfo getDecoderInfo(String mimeType, boolean secure, boolean tunneling)\n    throws DecoderQueryException {\n  List<MediaCodecInfo> decoderInfos = getDecoderInfos(mimeType, secure, tunneling);\n  return decoderInfos.isEmpty() ? null : decoderInfos.get(0);\n}", "summary_tokens": ["returns", "information", "about", "the", "preferred", "decoder", "for", "a", "given", "mime", "type"], "project": "ExoPlayer"}
{"id": 2769, "code": "public void releaseSource() {\n  runOnPlaybackThread(() -> mediaSource.releaseSource(mediaSourceListener));\n}", "summary_tokens": ["calls", "media", "source", "release", "source", "media", "source", "caller", "on", "the", "playback", "thread"], "project": "ExoPlayer"}
{"id": 2399, "code": "public int getPendingFrameCount() {\n  return pendingFrameCount.get();\n}", "summary_tokens": ["returns", "the", "number", "of", "input", "frames", "that", "have", "been", "register", "input", "frame", "registered", "but", "not", "completely", "processed", "yet"], "project": "ExoPlayer"}
{"id": 80, "code": "public static boolean supportsFormat(String mimeType) {\n  if (!isAvailable()) {\n    return false;\n  }\n  @Nullable String codecName = getCodecName(mimeType);\n  if (codecName == null) {\n    return false;\n  }\n  if (!ffmpegHasDecoder(codecName)) {\n    Log.w(TAG, \"No \" + codecName + \" decoder available. Check the FFmpeg build configuration.\");\n    return false;\n  }\n  return true;\n}", "summary_tokens": ["returns", "whether", "the", "underlying", "library", "supports", "the", "specified", "mime", "type"], "project": "ExoPlayer"}
{"id": 1074, "code": "public void setKeyRequestProperty(String name, String value) {\n  Assertions.checkNotNull(name);\n  Assertions.checkNotNull(value);\n  synchronized (keyRequestProperties) {\n    keyRequestProperties.put(name, value);\n  }\n}", "summary_tokens": ["sets", "a", "header", "for", "key", "requests", "made", "by", "the", "callback"], "project": "ExoPlayer"}
{"id": 112, "code": "private int getLoadingAdGroupIndex() {\n  if (player == null) {\n    return C.INDEX_UNSET;\n  }\n  long playerPositionUs = Util.msToUs(getContentPeriodPositionMs(player, timeline, period));\n  int adGroupIndex =\n      adPlaybackState.getAdGroupIndexForPositionUs(\n          playerPositionUs, Util.msToUs(contentDurationMs));\n  if (adGroupIndex == C.INDEX_UNSET) {\n    adGroupIndex =\n        adPlaybackState.getAdGroupIndexAfterPositionUs(\n            playerPositionUs, Util.msToUs(contentDurationMs));\n  }\n  return adGroupIndex;\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "ad", "group", "that", "will", "preload", "next", "or", "c", "index", "unset", "if", "there", "is", "no", "such", "ad", "group"], "project": "ExoPlayer"}
{"id": 1290, "code": "public void createPeriod(MediaPeriodId id) {\n  long preparePositionUs = getPreparePositionWithOverride(this.preparePositionUs);\n  mediaPeriod = checkNotNull(mediaSource).createPeriod(id, allocator, preparePositionUs);\n  if (callback != null) {\n    mediaPeriod.prepare( this, preparePositionUs);\n  }\n}", "summary_tokens": ["calls", "media", "source", "create", "period", "media", "period", "id", "allocator", "long", "on", "the", "wrapped", "source", "then", "prepares", "it", "if", "prepare", "callback", "long", "has", "been", "called"], "project": "ExoPlayer"}
{"id": 414, "code": "public static void addOrReplaceSpan(\n    Spannable spannable, Object span, int start, int end, int spanFlags) {\n  Object[] existingSpans = spannable.getSpans(start, end, span.getClass());\n  for (Object existingSpan : existingSpans) {\n    if (spannable.getSpanStart(existingSpan) == start\n        && spannable.getSpanEnd(existingSpan) == end\n        && spannable.getSpanFlags(existingSpan) == spanFlags) {\n      spannable.removeSpan(existingSpan);\n    }\n  }\n  spannable.setSpan(span, start, end, spanFlags);\n}", "summary_tokens": ["adds", "span", "to", "spannable", "between", "start", "and", "end", "removing", "any", "existing", "spans", "of", "the", "same", "type", "and", "with", "the", "same", "indices", "and", "flags"], "project": "ExoPlayer"}
{"id": 1088, "code": "public void flush() {\n  synchronized (lock) {\n    ++pendingFlushCount;\n    Util.castNonNull(handler).post(this::onFlushCompleted);\n  }\n}", "summary_tokens": ["initiates", "a", "flush", "asynchronously", "which", "will", "be", "completed", "on", "the", "callback", "thread"], "project": "ExoPlayer"}
{"id": 1660, "code": "public int getPriorityCountAfterExclusion(List<BaseUrl> baseUrls) {\n  Set<Integer> priorities = new HashSet<>();\n  List<BaseUrl> includedBaseUrls = applyExclusions(baseUrls);\n  for (int i = 0; i < includedBaseUrls.size(); i++) {\n    priorities.add(includedBaseUrls.get(i).priority);\n  }\n  return priorities.size();\n}", "summary_tokens": ["returns", "the", "number", "of", "priority", "levels", "for", "the", "given", "list", "of", "base", "urls", "after", "exclusion"], "project": "ExoPlayer"}
{"id": 1350, "code": "private synchronized boolean attemptSplice(long timeUs) {\n  if (length == 0) {\n    return timeUs > largestDiscardedTimestampUs;\n  }\n  if (getLargestReadTimestampUs() >= timeUs) {\n    return false;\n  }\n  int retainCount = countUnreadSamplesBefore(timeUs);\n  discardUpstreamSampleMetadata(absoluteFirstIndex + retainCount);\n  return true;\n}", "summary_tokens": ["attempts", "to", "discard", "samples", "from", "the", "end", "of", "the", "queue", "to", "allow", "samples", "starting", "from", "the", "specified", "timestamp", "to", "be", "spliced", "in"], "project": "ExoPlayer"}
{"id": 1343, "code": "public final void discardToRead() {\n  sampleDataQueue.discardDownstreamTo(discardSampleMetadataToRead());\n}", "summary_tokens": ["discards", "up", "to", "but", "not", "including", "the", "read", "position"], "project": "ExoPlayer"}
{"id": 2575, "code": "public boolean getShowShuffleButton() {\n  return controlViewLayoutManager.getShowButton(shuffleButton);\n}", "summary_tokens": ["returns", "whether", "the", "shuffle", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 2064, "code": "private void parseHeader() {\n  byte[] frameData = headerScratchBytes.getData();\n  if (format == null) {\n    format = DtsUtil.parseDtsFormat(frameData, formatId, language, null);\n    output.format(format);\n  }\n  sampleSize = DtsUtil.getDtsFrameSize(frameData);\n    \n    \n  sampleDurationUs =\n      (int)\n          (C.MICROS_PER_SECOND * DtsUtil.parseDtsAudioSampleCount(frameData) / format.sampleRate);\n}", "summary_tokens": ["parses", "the", "sample", "header"], "project": "ExoPlayer"}
{"id": 2611, "code": "public void hideController() {\n  if (controller != null) {\n    controller.hide();\n  }\n}", "summary_tokens": ["hides", "the", "playback", "controls"], "project": "ExoPlayer"}
{"id": 2812, "code": "public static File createTestFile(File file, long length) throws IOException {\n  FileOutputStream output = new FileOutputStream(file);\n  for (long i = 0; i < length; i++) {\n    output.write((int) i);\n  }\n  output.close();\n  return file;\n}", "summary_tokens": ["writes", "test", "data", "with", "the", "specified", "length", "to", "the", "file", "and", "returns", "it"], "project": "ExoPlayer"}
{"id": 2078, "code": "private boolean continueRead(\n    ParsableByteArray source, @Nullable byte[] target, int targetLength) {\n  int bytesToRead = min(source.bytesLeft(), targetLength - bytesRead);\n  if (bytesToRead <= 0) {\n    return true;\n  } else if (target == null) {\n    source.skipBytes(bytesToRead);\n  } else {\n    source.readBytes(target, bytesRead, bytesToRead);\n  }\n  bytesRead += bytesToRead;\n  return bytesRead == targetLength;\n}", "summary_tokens": ["continues", "a", "read", "from", "the", "provided", "source", "into", "a", "given", "target"], "project": "ExoPlayer"}
{"id": 2580, "code": "public void setShowVrButton(boolean showVrButton) {\n  controlViewLayoutManager.setShowButton(vrButton, showVrButton);\n}", "summary_tokens": ["sets", "whether", "the", "vr", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 2479, "code": "public @RepeatModeUtil.RepeatToggleModes int getRepeatToggleModes() {\n  return repeatToggleModes;\n}", "summary_tokens": ["returns", "which", "repeat", "toggle", "modes", "are", "enabled"], "project": "ExoPlayer"}
{"id": 1812, "code": "protected final boolean getFlag(@C.BufferFlags int flag) {\n  return (flags & flag) == flag;\n}", "summary_tokens": ["returns", "whether", "the", "specified", "flag", "has", "been", "set", "on", "this", "buffer"], "project": "ExoPlayer"}
{"id": 2256, "code": "public static int getPreviousSequenceNumber(int sequenceNumber) {\n  return IntMath.mod(sequenceNumber - 1, MAX_SEQUENCE_NUMBER + 1);\n}", "summary_tokens": ["returns", "the", "previous", "sequence", "number", "from", "the", "sequence", "number"], "project": "ExoPlayer"}
{"id": 1522, "code": "private void updateSurfacePlaybackFrameRate(boolean forceUpdate) {\n  if (Util.SDK_INT < 30\n      || surface == null\n      || changeFrameRateStrategy == C.VIDEO_CHANGE_FRAME_RATE_STRATEGY_OFF) {\n    return;\n  }\n\n  float surfacePlaybackFrameRate = 0;\n  if (started && surfaceMediaFrameRate != Format.NO_VALUE) {\n    surfacePlaybackFrameRate = surfaceMediaFrameRate * playbackSpeed;\n  }\n    \n    \n  if (!forceUpdate && this.surfacePlaybackFrameRate == surfacePlaybackFrameRate) {\n    return;\n  }\n  this.surfacePlaybackFrameRate = surfacePlaybackFrameRate;\n  Api30.setSurfaceFrameRate(surface, surfacePlaybackFrameRate);\n}", "summary_tokens": ["updates", "the", "playback", "frame", "rate", "of", "the", "current", "surface", "based", "on", "the", "playback", "speed", "frame", "rate", "of", "the", "content", "and", "whether", "the", "renderer", "is", "started"], "project": "ExoPlayer"}
{"id": 251, "code": "public Looper getApplicationLooper() {\n  return player.getApplicationLooper();\n}", "summary_tokens": ["calls", "player", "get", "application", "looper", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 377, "code": "public float getStarRating() {\n  return starRating;\n}", "summary_tokens": ["returns", "the", "fractional", "number", "of", "stars", "of", "this", "rating"], "project": "ExoPlayer"}
{"id": 2534, "code": "public int getControllerShowTimeoutMs() {\n  return controllerShowTimeoutMs;\n}", "summary_tokens": ["returns", "the", "playback", "controls", "timeout"], "project": "ExoPlayer"}
{"id": 24, "code": "public MediaQueueItem getItem(int periodId) {\n  MediaStatus mediaStatus = getMediaStatus();\n  return mediaStatus != null && currentTimeline.getIndexOfPeriod(periodId) != C.INDEX_UNSET\n      ? mediaStatus.getItemById(periodId)\n      : null;\n}", "summary_tokens": ["returns", "the", "item", "that", "corresponds", "to", "the", "period", "with", "the", "given", "id", "or", "null", "if", "no", "media", "queue", "or", "period", "with", "id", "period", "id", "exist"], "project": "ExoPlayer"}
{"id": 23, "code": "public static boolean isAvailable() {\n  return LOADER.isAvailable();\n}", "summary_tokens": ["returns", "whether", "the", "underlying", "library", "is", "available", "loading", "it", "if", "necessary"], "project": "ExoPlayer"}
{"id": 694, "code": " ExoPlaybackException copyWithMediaPeriodId(@Nullable MediaPeriodId mediaPeriodId) {\n  return new ExoPlaybackException(\n      Util.castNonNull(getMessage()),\n      getCause(),\n      errorCode,\n      type,\n      rendererName,\n      rendererIndex,\n      rendererFormat,\n      rendererFormatSupport,\n      mediaPeriodId,\n      timestampMs,\n      isRecoverable);\n}", "summary_tokens": ["returns", "a", "copy", "of", "this", "exception", "with", "the", "provided", "media", "period", "id"], "project": "ExoPlayer"}
{"id": 237, "code": "public Format copyWithMaxInputSize(int maxInputSize) {\n  return buildUpon().setMaxInputSize(maxInputSize).build();\n}", "summary_tokens": ["use", "build", "upon", "and", "builder", "set", "max", "input", "size", "int"], "project": "ExoPlayer"}
{"id": 2217, "code": "private static boolean isFmp4Variant(Format format) {\n  Metadata metadata = format.metadata;\n  if (metadata == null) {\n    return false;\n  }\n  for (int i = 0; i < metadata.length(); i++) {\n    Metadata.Entry entry = metadata.get(i);\n    if (entry instanceof HlsTrackMetadataEntry) {\n      return !((HlsTrackMetadataEntry) entry).variantInfos.isEmpty();\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "true", "if", "this", "format", "represents", "a", "variant", "track", "i"], "project": "ExoPlayer"}
{"id": 1678, "code": "private static boolean isPlayerEmsgEvent(String schemeIdUri, String value) {\n  return \"urn:mpeg:dash:event:2012\".equals(schemeIdUri)\n      && (\"1\".equals(value) || \"2\".equals(value) || \"3\".equals(value));\n}", "summary_tokens": ["returns", "whether", "an", "event", "with", "given", "scheme", "id", "uri", "and", "value", "is", "a", "dash", "emsg", "event", "targeting", "the", "player"], "project": "ExoPlayer"}
{"id": 1209, "code": "public void setMinRetryCount(int minRetryCount) {\n  Assertions.checkArgument(minRetryCount >= 0);\n  if (this.minRetryCount == minRetryCount) {\n    return;\n  }\n  this.minRetryCount = minRetryCount;\n  pendingMessages++;\n  internalHandler\n      .obtainMessage(MSG_SET_MIN_RETRY_COUNT, minRetryCount,  0)\n      .sendToTarget();\n}", "summary_tokens": ["sets", "the", "minimum", "number", "of", "times", "that", "a", "download", "will", "be", "retried"], "project": "ExoPlayer"}
{"id": 2753, "code": "public void reset() {\n  sampleQueue.reset();\n  sampleStreamItemsWritePosition = 0;\n  loadingFinished = false;\n}", "summary_tokens": ["resets", "the", "sample", "queue"], "project": "ExoPlayer"}
{"id": 1798, "code": "private void readTestData(\n    byte[] testData,\n    int dataOffset,\n    int dataLength,\n    int outputBufferLength,\n    int writeOffset,\n    int maxReadLength,\n    boolean expectFailOnOpen) {\n  int expectedFinalBytesRead = testData.length - dataOffset;\n  if (dataLength != C.LENGTH_UNSET) {\n    expectedFinalBytesRead = min(expectedFinalBytesRead, dataLength);\n  }\n  ByteArrayDataSource dataSource = new ByteArrayDataSource(testData);\n  boolean opened = false;\n  try {\n      \n    long length = dataSource.open(new DataSpec(Uri.EMPTY, dataOffset, dataLength));\n    opened = true;\n    assertThat(expectFailOnOpen).isFalse();\n\n      \n    assertThat(length)\n        .isEqualTo(dataLength != C.LENGTH_UNSET ? dataLength : expectedFinalBytesRead);\n\n    byte[] outputBuffer = new byte[outputBufferLength];\n    int accumulatedBytesRead = 0;\n    while (true) {\n        \n        \n      int requestedReadLength = min(maxReadLength, outputBufferLength - writeOffset);\n      assertThat(requestedReadLength).isGreaterThan(0);\n\n      int bytesRead = dataSource.read(outputBuffer, writeOffset, requestedReadLength);\n      if (bytesRead != C.RESULT_END_OF_INPUT) {\n        assertThat(bytesRead).isGreaterThan(0);\n        assertThat(bytesRead).isAtMost(requestedReadLength);\n          \n        for (int i = 0; i < bytesRead; i++) {\n          assertThat(outputBuffer[writeOffset + i])\n              .isEqualTo(testData[dataOffset + accumulatedBytesRead + i]);\n        }\n          \n        accumulatedBytesRead += bytesRead;\n        assertThat(accumulatedBytesRead).isAtMost(expectedFinalBytesRead);\n          \n        assertThat(\n                accumulatedBytesRead == expectedFinalBytesRead\n                    || bytesRead == requestedReadLength)\n            .isTrue();\n      } else {\n          \n        assertThat(accumulatedBytesRead).isEqualTo(expectedFinalBytesRead);\n        return;\n      }\n    }\n  } catch (IOException e) {\n    if (expectFailOnOpen && !opened) {\n        \n      return;\n    }\n      \n    fail();\n  }\n}", "summary_tokens": ["tests", "reading", "from", "a", "byte", "array", "data", "source", "with", "various", "parameters"], "project": "ExoPlayer"}
{"id": 1889, "code": "public static int readFrameBlockSizeSamplesFromKey(ParsableByteArray data, int blockSizeKey) {\n  switch (blockSizeKey) {\n    case 1:\n      return 192;\n    case 2:\n    case 3:\n    case 4:\n    case 5:\n      return 576 << (blockSizeKey - 2);\n    case 6:\n      return data.readUnsignedByte() + 1;\n    case 7:\n      return data.readUnsignedShort() + 1;\n    case 8:\n    case 9:\n    case 10:\n    case 11:\n    case 12:\n    case 13:\n    case 14:\n    case 15:\n      return 256 << (blockSizeKey - 8);\n    default:\n      return -1;\n  }\n}", "summary_tokens": ["reads", "the", "given", "block", "size"], "project": "ExoPlayer"}
{"id": 2636, "code": "public void onResume() {\n  if (surfaceView instanceof GLSurfaceView) {\n    ((GLSurfaceView) surfaceView).onResume();\n  }\n}", "summary_tokens": ["should", "be", "called", "when", "the", "player", "is", "visible", "to", "the", "user", "if", "the", "surface", "type", "extends", "glsurface", "view"], "project": "ExoPlayer"}
{"id": 1178, "code": "private static String getCodecMimeType(\n    android.media.MediaCodecInfo info, String name, String mimeType) {\n  String[] supportedTypes = info.getSupportedTypes();\n  for (String supportedType : supportedTypes) {\n    if (supportedType.equalsIgnoreCase(mimeType)) {\n      return supportedType;\n    }\n  }\n\n  if (mimeType.equals(MimeTypes.VIDEO_DOLBY_VISION)) {\n      \n      \n    if (\"OMX.MS.HEVCDV.Decoder\".equals(name)) {\n      return \"video/hevcdv\";\n    } else if (\"OMX.RTK.video.decoder\".equals(name)\n        || \"OMX.realtek.video.decoder.tunneled\".equals(name)) {\n      return \"video/dv_hevc\";\n    }\n  } else if (mimeType.equals(MimeTypes.AUDIO_ALAC) && \"OMX.lge.alac.decoder\".equals(name)) {\n    return \"audio/x-lg-alac\";\n  } else if (mimeType.equals(MimeTypes.AUDIO_FLAC) && \"OMX.lge.flac.decoder\".equals(name)) {\n    return \"audio/x-lg-flac\";\n  } else if (mimeType.equals(MimeTypes.AUDIO_AC3) && \"OMX.lge.ac3.decoder\".equals(name)) {\n    return \"audio/lg-ac3\";\n  }\n\n  return null;\n}", "summary_tokens": ["returns", "the", "codec", "s", "supported", "mime", "type", "for", "media", "of", "type", "mime", "type", "or", "null", "if", "the", "codec", "can", "t", "be", "used"], "project": "ExoPlayer"}
{"id": 1434, "code": "public FallbackSelection getFallbackSelectionFor(\n    FallbackOptions fallbackOptions, LoadErrorInfo loadErrorInfo) {\n  if (!isEligibleForFallback(loadErrorInfo.exception)) {\n    return null;\n  }\n    \n  if (fallbackOptions.isFallbackAvailable(FALLBACK_TYPE_LOCATION)) {\n    return new FallbackSelection(FALLBACK_TYPE_LOCATION, DEFAULT_LOCATION_EXCLUSION_MS);\n  } else if (fallbackOptions.isFallbackAvailable(FALLBACK_TYPE_TRACK)) {\n    return new FallbackSelection(FALLBACK_TYPE_TRACK, DEFAULT_TRACK_EXCLUSION_MS);\n  }\n  return null;\n}", "summary_tokens": ["returns", "whether", "a", "loader", "should", "fall", "back", "to", "using", "another", "resource", "on", "encountering", "an", "error", "and", "if", "so", "the", "duration", "for", "which", "the", "failing", "resource", "should", "be", "excluded"], "project": "ExoPlayer"}
{"id": 1392, "code": "private int primarySampleIndexToMediaChunkIndex(int primarySampleIndex, int minChunkIndex) {\n  for (int i = minChunkIndex + 1; i < mediaChunks.size(); i++) {\n    if (mediaChunks.get(i).getFirstSampleIndex(0) > primarySampleIndex) {\n      return i - 1;\n    }\n  }\n  return mediaChunks.size() - 1;\n}", "summary_tokens": ["returns", "the", "media", "chunk", "index", "corresponding", "to", "a", "given", "primary", "sample", "index"], "project": "ExoPlayer"}
{"id": 31, "code": "public float getVolume() {\n  return 1;\n}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "returns", "0"], "project": "ExoPlayer"}
{"id": 2084, "code": "public boolean isDurationReadFinished() {\n  return isDurationRead;\n}", "summary_tokens": ["returns", "true", "if", "a", "ts", "duration", "has", "been", "read"], "project": "ExoPlayer"}
{"id": 524, "code": "public static boolean isImage(@Nullable String mimeType) {\n  return BASE_TYPE_IMAGE.equals(getTopLevelType(mimeType));\n}", "summary_tokens": ["returns", "whether", "the", "given", "string", "is", "an", "image", "mime", "type"], "project": "ExoPlayer"}
{"id": 1102, "code": "public void add(int value) {\n  if (size == data.length) {\n    doubleArraySize();\n  }\n\n  tailIndex = (tailIndex + 1) & wrapAroundMask;\n  data[tailIndex] = value;\n  size++;\n}", "summary_tokens": ["add", "a", "new", "item", "to", "the", "queue"], "project": "ExoPlayer"}
{"id": 2145, "code": " static void endParagraph(SpannableStringBuilder builder) {\n  int position = builder.length() - 1;\n  while (position >= 0 && builder.charAt(position) == ' ') {\n    position--;\n  }\n  if (position >= 0 && builder.charAt(position) != '\\n') {\n    builder.append('\\n');\n  }\n}", "summary_tokens": ["called", "when", "the", "end", "of", "a", "paragraph", "is", "encountered"], "project": "ExoPlayer"}
{"id": 1346, "code": "public final void setUpstreamFormatChangeListener(\n    @Nullable UpstreamFormatChangedListener listener) {\n  upstreamFormatChangeListener = listener;\n}", "summary_tokens": ["sets", "a", "listener", "to", "be", "notified", "of", "changes", "to", "the", "upstream", "format"], "project": "ExoPlayer"}
{"id": 991, "code": "public boolean hasPendingData(long writtenFrames) {\n  return writtenFrames > getPlaybackHeadPosition() || forceHasPendingData();\n}", "summary_tokens": ["returns", "whether", "the", "audio", "track", "has", "any", "pending", "data", "to", "play", "out", "at", "its", "current", "position"], "project": "ExoPlayer"}
{"id": 2594, "code": "public void setPlayer(@Nullable Player player) {\n  Assertions.checkState(Looper.myLooper() == Looper.getMainLooper());\n  Assertions.checkArgument(\n      player == null || player.getApplicationLooper() == Looper.getMainLooper());\n  if (this.player == player) {\n    return;\n  }\n  @Nullable Player oldPlayer = this.player;\n  if (oldPlayer != null) {\n    oldPlayer.removeListener(componentListener);\n    if (surfaceView instanceof TextureView) {\n      oldPlayer.clearVideoTextureView((TextureView) surfaceView);\n    } else if (surfaceView instanceof SurfaceView) {\n      oldPlayer.clearVideoSurfaceView((SurfaceView) surfaceView);\n    }\n  }\n  if (subtitleView != null) {\n    subtitleView.setCues(null);\n  }\n  this.player = player;\n  if (useController()) {\n    controller.setPlayer(player);\n  }\n  updateBuffering();\n  updateErrorMessage();\n  updateForCurrentTrackSelections( true);\n  if (player != null) {\n    if (player.isCommandAvailable(COMMAND_SET_VIDEO_SURFACE)) {\n      if (surfaceView instanceof TextureView) {\n        player.setVideoTextureView((TextureView) surfaceView);\n      } else if (surfaceView instanceof SurfaceView) {\n        player.setVideoSurfaceView((SurfaceView) surfaceView);\n      }\n      updateAspectRatio();\n    }\n    if (subtitleView != null && player.isCommandAvailable(COMMAND_GET_TEXT)) {\n      subtitleView.setCues(player.getCurrentCues().cues);\n    }\n    player.addListener(componentListener);\n    maybeShowController(false);\n  } else {\n    hideController();\n  }\n}", "summary_tokens": ["sets", "the", "player", "to", "use"], "project": "ExoPlayer"}
{"id": 1778, "code": "public DefaultContentMetadata copyWithMutationsApplied(ContentMetadataMutations mutations) {\n  Map<String, byte[]> mutatedMetadata = applyMutations(metadata, mutations);\n  if (isMetadataEqual(metadata, mutatedMetadata)) {\n    return this;\n  }\n  return new DefaultContentMetadata(mutatedMetadata);\n}", "summary_tokens": ["returns", "a", "copy", "default", "content", "metadata", "with", "mutations", "applied"], "project": "ExoPlayer"}
{"id": 528, "code": "public static String getCodecsCorrespondingToMimeType(\n    @Nullable String codecs, @Nullable String mimeType) {\n  if (codecs == null || mimeType == null) {\n    return null;\n  }\n  String[] codecList = Util.splitCodecs(codecs);\n  StringBuilder builder = new StringBuilder();\n  for (String codec : codecList) {\n    if (mimeType.equals(getMediaMimeType(codec))) {\n      if (builder.length() > 0) {\n        builder.append(\",\");\n      }\n      builder.append(codec);\n    }\n  }\n  return builder.length() > 0 ? builder.toString() : null;\n}", "summary_tokens": ["returns", "a", "subsequence", "of", "codecs", "containing", "the", "codec", "strings", "that", "correspond", "to", "the", "given", "mime", "type"], "project": "ExoPlayer"}
{"id": 1517, "code": "public void onFormatChanged(float formatFrameRate) {\n  this.formatFrameRate = formatFrameRate;\n  frameRateEstimator.reset();\n  updateSurfaceMediaFrameRate();\n}", "summary_tokens": ["called", "when", "the", "renderer", "s", "output", "format", "changes"], "project": "ExoPlayer"}
{"id": 110, "code": "private AdsRenderingSettings setupAdsRendering(long contentPositionMs, long contentDurationMs) {\n  AdsRenderingSettings adsRenderingSettings = imaFactory.createAdsRenderingSettings();\n  adsRenderingSettings.setEnablePreloading(true);\n  adsRenderingSettings.setMimeTypes(\n      configuration.adMediaMimeTypes != null\n          ? configuration.adMediaMimeTypes\n          : supportedMimeTypes);\n  if (configuration.mediaLoadTimeoutMs != TIMEOUT_UNSET) {\n    adsRenderingSettings.setLoadVideoTimeout(configuration.mediaLoadTimeoutMs);\n  }\n  if (configuration.mediaBitrate != BITRATE_UNSET) {\n    adsRenderingSettings.setBitrateKbps(configuration.mediaBitrate / 1000);\n  }\n  adsRenderingSettings.setFocusSkipButtonWhenAvailable(\n      configuration.focusSkipButtonWhenAvailable);\n  if (configuration.adUiElements != null) {\n    adsRenderingSettings.setUiElements(configuration.adUiElements);\n  }\n\n    \n  int adGroupForPositionIndex =\n      adPlaybackState.getAdGroupIndexForPositionUs(\n          Util.msToUs(contentPositionMs), Util.msToUs(contentDurationMs));\n  if (adGroupForPositionIndex != C.INDEX_UNSET) {\n    boolean playAdWhenStartingPlayback =\n        adPlaybackState.getAdGroup(adGroupForPositionIndex).timeUs\n                == Util.msToUs(contentPositionMs)\n            || configuration.playAdBeforeStartPosition;\n    if (!playAdWhenStartingPlayback) {\n      adGroupForPositionIndex++;\n    } else if (hasMidrollAdGroups(adPlaybackState)) {\n        \n        \n        \n      pendingContentPositionMs = contentPositionMs;\n    }\n    if (adGroupForPositionIndex > 0) {\n      for (int i = 0; i < adGroupForPositionIndex; i++) {\n        adPlaybackState = adPlaybackState.withSkippedAdGroup(i);\n      }\n      if (adGroupForPositionIndex == adPlaybackState.adGroupCount) {\n          \n          \n        return null;\n      }\n      long adGroupForPositionTimeUs = adPlaybackState.getAdGroup(adGroupForPositionIndex).timeUs;\n      long adGroupBeforePositionTimeUs =\n          adPlaybackState.getAdGroup(adGroupForPositionIndex - 1).timeUs;\n      if (adGroupForPositionTimeUs == C.TIME_END_OF_SOURCE) {\n          \n        adsRenderingSettings.setPlayAdsAfterTime(\n            (double) adGroupBeforePositionTimeUs / C.MICROS_PER_SECOND + 1d);\n      } else {\n          \n          \n        double midpointTimeUs = (adGroupForPositionTimeUs + adGroupBeforePositionTimeUs) / 2d;\n        adsRenderingSettings.setPlayAdsAfterTime(midpointTimeUs / C.MICROS_PER_SECOND);\n      }\n    }\n  }\n  return adsRenderingSettings;\n}", "summary_tokens": ["configures", "ads", "rendering", "for", "starting", "playback", "returning", "the", "settings", "for", "the", "ima", "sdk", "or", "null", "if", "no", "ads", "should", "play"], "project": "ExoPlayer"}
{"id": 980, "code": "public void acceptTimestamp() {\n  if (state == STATE_ERROR) {\n    reset();\n  }\n}", "summary_tokens": ["accepts", "the", "timestamp", "last", "polled", "in", "maybe", "poll", "timestamp", "long"], "project": "ExoPlayer"}
{"id": 1052, "code": "public void setMode(@Mode int mode, @Nullable byte[] offlineLicenseKeySetId) {\n  checkState(sessions.isEmpty());\n  if (mode == MODE_QUERY || mode == MODE_RELEASE) {\n    checkNotNull(offlineLicenseKeySetId);\n  }\n  this.mode = mode;\n  this.offlineLicenseKeySetId = offlineLicenseKeySetId;\n}", "summary_tokens": ["sets", "the", "mode", "which", "determines", "the", "role", "of", "sessions", "acquired", "from", "the", "instance"], "project": "ExoPlayer"}
{"id": 460, "code": "public static @FileTypes.Type int inferFileTypeFromResponseHeaders(\n    Map<String, List<String>> responseHeaders) {\n  @Nullable List<String> contentTypes = responseHeaders.get(HEADER_CONTENT_TYPE);\n  @Nullable\n  String mimeType = contentTypes == null || contentTypes.isEmpty() ? null : contentTypes.get(0);\n  return inferFileTypeFromMimeType(mimeType);\n}", "summary_tokens": ["returns", "the", "type", "corresponding", "to", "the", "response", "headers", "provided"], "project": "ExoPlayer"}
{"id": 666, "code": "public void stop() {\n  standaloneClockIsStarted = false;\n  standaloneClock.stop();\n}", "summary_tokens": ["stops", "the", "standalone", "fallback", "clock"], "project": "ExoPlayer"}
{"id": 972, "code": "default void onAudioDecoderReleased(String decoderName) {}", "summary_tokens": ["called", "when", "a", "decoder", "is", "released"], "project": "ExoPlayer"}
{"id": 1689, "code": "public String buildUri(String representationId, long segmentNumber, int bandwidth, long time) {\n  StringBuilder builder = new StringBuilder();\n  for (int i = 0; i < identifierCount; i++) {\n    builder.append(urlPieces[i]);\n    if (identifiers[i] == REPRESENTATION_ID) {\n      builder.append(representationId);\n    } else if (identifiers[i] == NUMBER_ID) {\n      builder.append(String.format(Locale.US, identifierFormatTags[i], segmentNumber));\n    } else if (identifiers[i] == BANDWIDTH_ID) {\n      builder.append(String.format(Locale.US, identifierFormatTags[i], bandwidth));\n    } else if (identifiers[i] == TIME_ID) {\n      builder.append(String.format(Locale.US, identifierFormatTags[i], time));\n    }\n  }\n  builder.append(urlPieces[identifierCount]);\n  return builder.toString();\n}", "summary_tokens": ["constructs", "a", "uri", "from", "the", "template", "substituting", "in", "the", "provided", "arguments"], "project": "ExoPlayer"}
{"id": 1530, "code": "default void onRenderedFirstFrame(Object output, long renderTimeMs) {}", "summary_tokens": ["called", "when", "a", "frame", "is", "rendered", "for", "the", "first", "time", "since", "setting", "the", "output", "or", "since", "the", "renderer", "was", "reset", "or", "since", "the", "stream", "being", "rendered", "was", "changed"], "project": "ExoPlayer"}
{"id": 2239, "code": "public long getEndTimeUs() {\n  return startTimeUs + durationUs;\n}", "summary_tokens": ["returns", "the", "result", "of", "adding", "the", "duration", "of", "the", "playlist", "to", "its", "start", "time"], "project": "ExoPlayer"}
{"id": 2540, "code": "public void setControllerHideDuringAds(boolean controllerHideDuringAds) {\n  this.controllerHideDuringAds = controllerHideDuringAds;\n}", "summary_tokens": ["sets", "whether", "the", "playback", "controls", "are", "hidden", "when", "ads", "are", "playing"], "project": "ExoPlayer"}
{"id": 2680, "code": "public static ConditionVariable createRobolectricConditionVariable() {\n  return new ConditionVariable(\n      new SystemClock() {\n        @Override\n        public long elapsedRealtime() {\n            \n            \n            \n            \n          return Clock.DEFAULT.currentTimeMillis();\n        }\n      });\n}", "summary_tokens": ["creates", "a", "condition", "variable", "whose", "condition", "variable", "block", "long", "method", "times", "out", "according", "to", "wallclock", "time", "when", "used", "in", "robolectric", "tests"], "project": "ExoPlayer"}
{"id": 2124, "code": "private static ObjectData parseObjectData(ParsableBitArray data) {\n  int objectId = data.readBits(16);\n  data.skipBits(4); \n  int objectCodingMethod = data.readBits(2);\n  boolean nonModifyingColorFlag = data.readBit();\n  data.skipBits(1); \n\n  byte[] topFieldData = Util.EMPTY_BYTE_ARRAY;\n  byte[] bottomFieldData = Util.EMPTY_BYTE_ARRAY;\n\n  if (objectCodingMethod == OBJECT_CODING_STRING) {\n    int numberOfCodes = data.readBits(8);\n      \n    data.skipBits(numberOfCodes * 16); \n  } else if (objectCodingMethod == OBJECT_CODING_PIXELS) {\n    int topFieldDataLength = data.readBits(16);\n    int bottomFieldDataLength = data.readBits(16);\n    if (topFieldDataLength > 0) {\n      topFieldData = new byte[topFieldDataLength];\n      data.readBytes(topFieldData, 0, topFieldDataLength);\n    }\n    if (bottomFieldDataLength > 0) {\n      bottomFieldData = new byte[bottomFieldDataLength];\n      data.readBytes(bottomFieldData, 0, bottomFieldDataLength);\n    } else {\n      bottomFieldData = topFieldData;\n    }\n  }\n\n  return new ObjectData(objectId, nonModifyingColorFlag, topFieldData, bottomFieldData);\n}", "summary_tokens": ["parses", "an", "object", "data", "segment", "as", "defined", "by", "etsi", "en", "0", "0", "0"], "project": "ExoPlayer"}
{"id": 1758, "code": "public boolean applyMetadataMutations(ContentMetadataMutations mutations) {\n  DefaultContentMetadata oldMetadata = metadata;\n  metadata = metadata.copyWithMutationsApplied(mutations);\n  return !metadata.equals(oldMetadata);\n}", "summary_tokens": ["applies", "mutations", "to", "the", "metadata"], "project": "ExoPlayer"}
{"id": 1542, "code": "public static boolean isSupported(Projection projection) {\n  Projection.Mesh leftMesh = projection.leftMesh;\n  Projection.Mesh rightMesh = projection.rightMesh;\n  return leftMesh.getSubMeshCount() == 1\n      && leftMesh.getSubMesh(0).textureId == Projection.SubMesh.VIDEO_TEXTURE_ID\n      && rightMesh.getSubMeshCount() == 1\n      && rightMesh.getSubMesh(0).textureId == Projection.SubMesh.VIDEO_TEXTURE_ID;\n}", "summary_tokens": ["returns", "whether", "projection", "is", "supported"], "project": "ExoPlayer"}
{"id": 10, "code": "private void setCurrentItem(int itemIndex) {\n  maybeSetCurrentItemAndNotify(itemIndex);\n  if (currentPlayer.getCurrentTimeline().getWindowCount() != mediaQueue.size()) {\n      \n      \n    currentPlayer.setMediaItems(mediaQueue, itemIndex, C.TIME_UNSET);\n  } else {\n    currentPlayer.seekTo(itemIndex, C.TIME_UNSET);\n  }\n  currentPlayer.setPlayWhenReady(true);\n}", "summary_tokens": ["starts", "playback", "of", "the", "item", "at", "the", "given", "index"], "project": "ExoPlayer"}
{"id": 326, "code": "public long getBufferedPosition() {\n  return player.getBufferedPosition();\n}", "summary_tokens": ["calls", "player", "get", "buffered", "position", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 593, "code": "public String readDelimiterTerminatedString(char delimiter) {\n  if (bytesLeft() == 0) {\n    return null;\n  }\n  int stringLimit = position;\n  while (stringLimit < limit && data[stringLimit] != delimiter) {\n    stringLimit++;\n  }\n  String string = Util.fromUtf8Bytes(data, position, stringLimit - position);\n  position = stringLimit;\n  if (position < limit) {\n    position++;\n  }\n  return string;\n}", "summary_tokens": ["reads", "up", "to", "the", "next", "delimiter", "byte", "or", "the", "limit", "as", "utf", "0", "characters"], "project": "ExoPlayer"}
{"id": 178, "code": "public void setCustomErrorMessage(\n    @Nullable CharSequence message, int code, @Nullable Bundle extras) {\n  customError = (message == null) ? null : new Pair<>(code, message);\n  customErrorExtras = (message == null) ? null : extras;\n  invalidateMediaSessionPlaybackState();\n}", "summary_tokens": ["sets", "a", "custom", "error", "on", "the", "session"], "project": "ExoPlayer"}
{"id": 2662, "code": "public TrackSelectionDialogBuilder setAllowMultipleOverrides(boolean allowMultipleOverrides) {\n  this.allowMultipleOverrides = allowMultipleOverrides;\n  return this;\n}", "summary_tokens": ["sets", "whether", "multiple", "overrides", "can", "be", "set", "and", "selected", "i"], "project": "ExoPlayer"}
{"id": 2016, "code": "public int getIndexOfEarlierOrEqualSynchronizationSample(long timeUs) {\n    \n    \n  int startIndex = Util.binarySearchFloor(timestampsUs, timeUs, true, false);\n  for (int i = startIndex; i >= 0; i--) {\n    if ((flags[i] & C.BUFFER_FLAG_KEY_FRAME) != 0) {\n      return i;\n    }\n  }\n  return C.INDEX_UNSET;\n}", "summary_tokens": ["returns", "the", "sample", "index", "of", "the", "closest", "synchronization", "sample", "at", "or", "before", "the", "given", "timestamp", "if", "one", "is", "available"], "project": "ExoPlayer"}
{"id": 1748, "code": "private void openNextSource(DataSpec requestDataSpec, boolean checkCache) throws IOException {\n  @Nullable CacheSpan nextSpan;\n  String key = castNonNull(requestDataSpec.key);\n  if (currentRequestIgnoresCache) {\n    nextSpan = null;\n  } else if (blockOnCache) {\n    try {\n      nextSpan = cache.startReadWrite(key, readPosition, bytesRemaining);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      throw new InterruptedIOException();\n    }\n  } else {\n    nextSpan = cache.startReadWriteNonBlocking(key, readPosition, bytesRemaining);\n  }\n\n  DataSpec nextDataSpec;\n  DataSource nextDataSource;\n  if (nextSpan == null) {\n      \n      \n    nextDataSource = upstreamDataSource;\n    nextDataSpec =\n        requestDataSpec.buildUpon().setPosition(readPosition).setLength(bytesRemaining).build();\n  } else if (nextSpan.isCached) {\n      \n    Uri fileUri = Uri.fromFile(castNonNull(nextSpan.file));\n    long filePositionOffset = nextSpan.position;\n    long positionInFile = readPosition - filePositionOffset;\n    long length = nextSpan.length - positionInFile;\n    if (bytesRemaining != C.LENGTH_UNSET) {\n      length = min(length, bytesRemaining);\n    }\n    nextDataSpec =\n        requestDataSpec\n            .buildUpon()\n            .setUri(fileUri)\n            .setUriPositionOffset(filePositionOffset)\n            .setPosition(positionInFile)\n            .setLength(length)\n            .build();\n    nextDataSource = cacheReadDataSource;\n  } else {\n      \n    long length;\n    if (nextSpan.isOpenEnded()) {\n      length = bytesRemaining;\n    } else {\n      length = nextSpan.length;\n      if (bytesRemaining != C.LENGTH_UNSET) {\n        length = min(length, bytesRemaining);\n      }\n    }\n    nextDataSpec =\n        requestDataSpec.buildUpon().setPosition(readPosition).setLength(length).build();\n    if (cacheWriteDataSource != null) {\n      nextDataSource = cacheWriteDataSource;\n    } else {\n      nextDataSource = upstreamDataSource;\n      cache.releaseHoleSpan(nextSpan);\n      nextSpan = null;\n    }\n  }\n\n  checkCachePosition =\n      !currentRequestIgnoresCache && nextDataSource == upstreamDataSource\n          ? readPosition + MIN_READ_BEFORE_CHECKING_CACHE\n          : Long.MAX_VALUE;\n  if (checkCache) {\n    Assertions.checkState(isBypassingCache());\n    if (nextDataSource == upstreamDataSource) {\n        \n      return;\n    }\n      \n    try {\n      closeCurrentSource();\n    } catch (Throwable e) {\n      if (castNonNull(nextSpan).isHoleSpan()) {\n          \n        cache.releaseHoleSpan(nextSpan);\n      }\n      throw e;\n    }\n  }\n\n  if (nextSpan != null && nextSpan.isHoleSpan()) {\n    currentHoleSpan = nextSpan;\n  }\n  currentDataSource = nextDataSource;\n  currentDataSpec = nextDataSpec;\n  currentDataSourceBytesRead = 0;\n  long resolvedLength = nextDataSource.open(nextDataSpec);\n\n    \n  ContentMetadataMutations mutations = new ContentMetadataMutations();\n  if (nextDataSpec.length == C.LENGTH_UNSET && resolvedLength != C.LENGTH_UNSET) {\n    bytesRemaining = resolvedLength;\n    ContentMetadataMutations.setContentLength(mutations, readPosition + bytesRemaining);\n  }\n  if (isReadingFromUpstream()) {\n    actualUri = nextDataSource.getUri();\n    boolean isRedirected = !requestDataSpec.uri.equals(actualUri);\n    ContentMetadataMutations.setRedirectedUri(mutations, isRedirected ? actualUri : null);\n  }\n  if (isWritingToCache()) {\n    cache.applyContentMetadataMutations(key, mutations);\n  }\n}", "summary_tokens": ["opens", "the", "next", "source"], "project": "ExoPlayer"}
{"id": 2092, "code": "public static boolean checkFileType(ExtractorInput input) throws IOException {\n  ParsableByteArray scratch = new ParsableByteArray(ChunkHeader.SIZE_IN_BYTES);\n  ChunkHeader chunkHeader = ChunkHeader.peek(input, scratch);\n  if (chunkHeader.id != WavUtil.RIFF_FOURCC && chunkHeader.id != WavUtil.RF64_FOURCC) {\n    return false;\n  }\n\n  input.peekFully(scratch.getData(), 0, 4);\n  scratch.setPosition(0);\n  int formType = scratch.readInt();\n  if (formType != WavUtil.WAVE_FOURCC) {\n    Log.e(TAG, \"Unsupported form type: \" + formType);\n    return false;\n  }\n\n  return true;\n}", "summary_tokens": ["returns", "whether", "the", "given", "input", "starts", "with", "a", "riff", "or", "rf", "0", "chunk", "header", "followed", "by", "a", "wave", "tag"], "project": "ExoPlayer"}
{"id": 334, "code": "public boolean isCurrentWindowSeekable() {\n  return player.isCurrentWindowSeekable();\n}", "summary_tokens": ["calls", "player", "is", "current", "window", "seekable", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2512, "code": "protected int[] getActionIndicesForCompactView(List<String> actionNames, Player player) {\n  int pauseActionIndex = actionNames.indexOf(ACTION_PAUSE);\n  int playActionIndex = actionNames.indexOf(ACTION_PLAY);\n  int leftSideActionIndex =\n      usePreviousActionInCompactView\n          ? actionNames.indexOf(ACTION_PREVIOUS)\n          : (useRewindActionInCompactView ? actionNames.indexOf(ACTION_REWIND) : -1);\n  int rightSideActionIndex =\n      useNextActionInCompactView\n          ? actionNames.indexOf(ACTION_NEXT)\n          : (useFastForwardActionInCompactView ? actionNames.indexOf(ACTION_FAST_FORWARD) : -1);\n\n  int[] actionIndices = new int[3];\n  int actionCounter = 0;\n  if (leftSideActionIndex != -1) {\n    actionIndices[actionCounter++] = leftSideActionIndex;\n  }\n  boolean shouldShowPauseButton = shouldShowPauseButton(player);\n  if (pauseActionIndex != -1 && shouldShowPauseButton) {\n    actionIndices[actionCounter++] = pauseActionIndex;\n  } else if (playActionIndex != -1 && !shouldShowPauseButton) {\n    actionIndices[actionCounter++] = playActionIndex;\n  }\n  if (rightSideActionIndex != -1) {\n    actionIndices[actionCounter++] = rightSideActionIndex;\n  }\n  return Arrays.copyOf(actionIndices, actionCounter);\n}", "summary_tokens": ["gets", "an", "array", "with", "the", "indices", "of", "the", "buttons", "to", "be", "shown", "in", "compact", "mode"], "project": "ExoPlayer"}
{"id": 141, "code": "public static AdPlaybackState expandAdGroupPlaceholder(\n    int adGroupIndex,\n    long adGroupDurationUs,\n    int adIndexInAdGroup,\n    long adDurationUs,\n    int adsInAdGroupCount,\n    AdPlaybackState adPlaybackState) {\n  checkArgument(adIndexInAdGroup < adsInAdGroupCount);\n  long[] adDurationsUs =\n      updateAdDurationAndPropagate(\n          new long[adsInAdGroupCount], adIndexInAdGroup, adDurationUs, adGroupDurationUs);\n  return adPlaybackState\n      .withAdCount(adGroupIndex, adDurationsUs.length)\n      .withAdDurationsUs(adGroupIndex, adDurationsUs);\n}", "summary_tokens": ["expands", "a", "placeholder", "ad", "group", "with", "a", "single", "ad", "to", "the", "requested", "number", "of", "ads", "and", "sets", "the", "duration", "of", "the", "inserted", "ad"], "project": "ExoPlayer"}
{"id": 1835, "code": "public static int parseAc3SyncframeSize(byte[] data) {\n  if (data.length < 6) {\n    return C.LENGTH_UNSET;\n  }\n    \n  boolean isEac3 = ((data[5] & 0xF8) >> 3) > 10;\n  if (isEac3) {\n    int frmsiz = (data[2] & 0x07) << 8; \n    frmsiz |= data[3] & 0xFF; \n    return (frmsiz + 1) * 2; \n  } else {\n    int fscod = (data[4] & 0xC0) >> 6;\n    int frmsizecod = data[4] & 0x3F;\n    return getAc3SyncframeSize(fscod, frmsizecod);\n  }\n}", "summary_tokens": ["returns", "the", "size", "in", "bytes", "of", "the", "given", "e", "ac", "0", "syncframe"], "project": "ExoPlayer"}
{"id": 1219, "code": "public DownloadRequest copyWithMergedRequest(DownloadRequest newRequest) {\n  Assertions.checkArgument(id.equals(newRequest.id));\n  List<StreamKey> mergedKeys;\n  if (streamKeys.isEmpty() || newRequest.streamKeys.isEmpty()) {\n      \n    mergedKeys = Collections.emptyList();\n  } else {\n    mergedKeys = new ArrayList<>(streamKeys);\n    for (int i = 0; i < newRequest.streamKeys.size(); i++) {\n      StreamKey newKey = newRequest.streamKeys.get(i);\n      if (!mergedKeys.contains(newKey)) {\n        mergedKeys.add(newKey);\n      }\n    }\n  }\n  return new DownloadRequest(\n      id,\n      newRequest.uri,\n      newRequest.mimeType,\n      mergedKeys,\n      newRequest.keySetId,\n      newRequest.customCacheKey,\n      newRequest.data);\n}", "summary_tokens": ["returns", "the", "result", "of", "merging", "new", "request", "into", "this", "request"], "project": "ExoPlayer"}
{"id": 2090, "code": "public static long readPcrFromPacket(\n    ParsableByteArray packetBuffer, int startOfPacket, int pcrPid) {\n  packetBuffer.setPosition(startOfPacket);\n  if (packetBuffer.bytesLeft() < 5) {\n      \n    return C.TIME_UNSET;\n  }\n    \n  int tsPacketHeader = packetBuffer.readInt();\n  if ((tsPacketHeader & 0x800000) != 0) {\n      \n    return C.TIME_UNSET;\n  }\n  int pid = (tsPacketHeader & 0x1FFF00) >> 8;\n  if (pid != pcrPid) {\n    return C.TIME_UNSET;\n  }\n  boolean adaptationFieldExists = (tsPacketHeader & 0x20) != 0;\n  if (!adaptationFieldExists) {\n    return C.TIME_UNSET;\n  }\n\n  int adaptationFieldLength = packetBuffer.readUnsignedByte();\n  if (adaptationFieldLength >= 7 && packetBuffer.bytesLeft() >= 7) {\n    int flags = packetBuffer.readUnsignedByte();\n    boolean pcrFlagSet = (flags & 0x10) == 0x10;\n    if (pcrFlagSet) {\n      byte[] pcrBytes = new byte[6];\n      packetBuffer.readBytes(pcrBytes,  0, pcrBytes.length);\n      return readPcrValueFromPcrBytes(pcrBytes);\n    }\n  }\n  return C.TIME_UNSET;\n}", "summary_tokens": ["returns", "the", "pcr", "value", "read", "from", "a", "given", "ts", "packet"], "project": "ExoPlayer"}
{"id": 2831, "code": "public static void assertEmpty(Timeline timeline) {\n  assertWindowTags(timeline);\n  assertPeriodCounts(timeline);\n  for (boolean shuffled : new boolean[] {false, true}) {\n    assertThat(timeline.getFirstWindowIndex(shuffled)).isEqualTo(C.INDEX_UNSET);\n    assertThat(timeline.getLastWindowIndex(shuffled)).isEqualTo(C.INDEX_UNSET);\n  }\n}", "summary_tokens": ["assert", "that", "timeline", "is", "empty", "i"], "project": "ExoPlayer"}
{"id": 1411, "code": "public @NullableType TrackSelection[] getAll() {\n  return trackSelections.clone();\n}", "summary_tokens": ["returns", "the", "selections", "in", "a", "newly", "allocated", "array"], "project": "ExoPlayer"}
{"id": 1076, "code": "public void clearAllKeyRequestProperties() {\n  synchronized (keyRequestProperties) {\n    keyRequestProperties.clear();\n  }\n}", "summary_tokens": ["clears", "all", "headers", "for", "key", "requests", "made", "by", "the", "callback"], "project": "ExoPlayer"}
{"id": 1690, "code": "private static int parseTemplate(\n    String template, String[] urlPieces, int[] identifiers, String[] identifierFormatTags) {\n  urlPieces[0] = \"\";\n  int templateIndex = 0;\n  int identifierCount = 0;\n  while (templateIndex < template.length()) {\n    int dollarIndex = template.indexOf(\"$\", templateIndex);\n    if (dollarIndex == -1) {\n      urlPieces[identifierCount] += template.substring(templateIndex);\n      templateIndex = template.length();\n    } else if (dollarIndex != templateIndex) {\n      urlPieces[identifierCount] += template.substring(templateIndex, dollarIndex);\n      templateIndex = dollarIndex;\n    } else if (template.startsWith(ESCAPED_DOLLAR, templateIndex)) {\n      urlPieces[identifierCount] += \"$\";\n      templateIndex += 2;\n    } else {\n      int secondIndex = template.indexOf(\"$\", templateIndex + 1);\n      String identifier = template.substring(templateIndex + 1, secondIndex);\n      if (identifier.equals(REPRESENTATION)) {\n        identifiers[identifierCount] = REPRESENTATION_ID;\n      } else {\n        int formatTagIndex = identifier.indexOf(\"%0\");\n        String formatTag = DEFAULT_FORMAT_TAG;\n        if (formatTagIndex != -1) {\n          formatTag = identifier.substring(formatTagIndex);\n            \n            \n            \n          if (!formatTag.endsWith(\"d\") && !formatTag.endsWith(\"x\") && !formatTag.endsWith(\"X\")) {\n            formatTag += \"d\";\n          }\n          identifier = identifier.substring(0, formatTagIndex);\n        }\n        switch (identifier) {\n          case NUMBER:\n            identifiers[identifierCount] = NUMBER_ID;\n            break;\n          case BANDWIDTH:\n            identifiers[identifierCount] = BANDWIDTH_ID;\n            break;\n          case TIME:\n            identifiers[identifierCount] = TIME_ID;\n            break;\n          default:\n            throw new IllegalArgumentException(\"Invalid template: \" + template);\n        }\n        identifierFormatTags[identifierCount] = formatTag;\n      }\n      identifierCount++;\n      urlPieces[identifierCount] = \"\";\n      templateIndex = secondIndex + 1;\n    }\n  }\n  return identifierCount;\n}", "summary_tokens": ["parses", "template", "placing", "the", "decomposed", "components", "into", "the", "provided", "arrays"], "project": "ExoPlayer"}
{"id": 1789, "code": "private void removeStaleSpans() {\n  ArrayList<CacheSpan> spansToBeRemoved = new ArrayList<>();\n  for (CachedContent cachedContent : contentIndex.getAll()) {\n    for (CacheSpan span : cachedContent.getSpans()) {\n      if (span.file.length() != span.length) {\n        spansToBeRemoved.add(span);\n      }\n    }\n  }\n  for (int i = 0; i < spansToBeRemoved.size(); i++) {\n    removeSpanInternal(spansToBeRemoved.get(i));\n  }\n}", "summary_tokens": ["scans", "all", "of", "the", "cached", "spans", "in", "the", "in", "memory", "representation", "removing", "any", "for", "which", "the", "underlying", "file", "lengths", "no", "longer", "match"], "project": "ExoPlayer"}
{"id": 869, "code": "default void onAudioEnabled(EventTime eventTime, DecoderCounters decoderCounters) {}", "summary_tokens": ["called", "when", "an", "audio", "renderer", "is", "enabled"], "project": "ExoPlayer"}
{"id": 2144, "code": "private static long parseTimeExpression(String time, FrameAndTickRate frameAndTickRate)\n    throws SubtitleDecoderException {\n  Matcher matcher = CLOCK_TIME.matcher(time);\n  if (matcher.matches()) {\n    String hours = Assertions.checkNotNull(matcher.group(1));\n    double durationSeconds = Long.parseLong(hours) * 3600;\n    String minutes = Assertions.checkNotNull(matcher.group(2));\n    durationSeconds += Long.parseLong(minutes) * 60;\n    String seconds = Assertions.checkNotNull(matcher.group(3));\n    durationSeconds += Long.parseLong(seconds);\n    @Nullable String fraction = matcher.group(4);\n    durationSeconds += (fraction != null) ? Double.parseDouble(fraction) : 0;\n    @Nullable String frames = matcher.group(5);\n    durationSeconds +=\n        (frames != null) ? Long.parseLong(frames) / frameAndTickRate.effectiveFrameRate : 0;\n    @Nullable String subframes = matcher.group(6);\n    durationSeconds +=\n        (subframes != null)\n            ? ((double) Long.parseLong(subframes))\n                / frameAndTickRate.subFrameRate\n                / frameAndTickRate.effectiveFrameRate\n            : 0;\n    return (long) (durationSeconds * C.MICROS_PER_SECOND);\n  }\n  matcher = OFFSET_TIME.matcher(time);\n  if (matcher.matches()) {\n    String timeValue = Assertions.checkNotNull(matcher.group(1));\n    double offsetSeconds = Double.parseDouble(timeValue);\n    String unit = Assertions.checkNotNull(matcher.group(2));\n    switch (unit) {\n      case \"h\":\n        offsetSeconds *= 3600;\n        break;\n      case \"m\":\n        offsetSeconds *= 60;\n        break;\n      case \"s\":\n          \n        break;\n      case \"ms\":\n        offsetSeconds /= 1000;\n        break;\n      case \"f\":\n        offsetSeconds /= frameAndTickRate.effectiveFrameRate;\n        break;\n      case \"t\":\n        offsetSeconds /= frameAndTickRate.tickRate;\n        break;\n    }\n    return (long) (offsetSeconds * C.MICROS_PER_SECOND);\n  }\n  throw new SubtitleDecoderException(\"Malformed time expression: \" + time);\n}", "summary_tokens": ["parses", "a", "time", "expression", "returning", "the", "parsed", "timestamp"], "project": "ExoPlayer"}
{"id": 2789, "code": "public TestExoPlayerBuilder setLoadControl(LoadControl loadControl) {\n  this.loadControl = loadControl;\n  return this;\n}", "summary_tokens": ["sets", "a", "load", "control", "to", "be", "used", "by", "the", "player"], "project": "ExoPlayer"}
{"id": 985, "code": "public void setAudioTrack(\n    AudioTrack audioTrack,\n    boolean isPassthrough,\n    @C.Encoding int outputEncoding,\n    int outputPcmFrameSize,\n    int bufferSize) {\n  this.audioTrack = audioTrack;\n  this.outputPcmFrameSize = outputPcmFrameSize;\n  this.bufferSize = bufferSize;\n  audioTimestampPoller = new AudioTimestampPoller(audioTrack);\n  outputSampleRate = audioTrack.getSampleRate();\n  needsPassthroughWorkarounds = isPassthrough && needsPassthroughWorkarounds(outputEncoding);\n  isOutputPcm = Util.isEncodingLinearPcm(outputEncoding);\n  bufferSizeUs = isOutputPcm ? framesToDurationUs(bufferSize / outputPcmFrameSize) : C.TIME_UNSET;\n  lastRawPlaybackHeadPosition = 0;\n  rawPlaybackHeadWrapCount = 0;\n  passthroughWorkaroundPauseOffset = 0;\n  hasData = false;\n  stopTimestampUs = C.TIME_UNSET;\n  forceResetWorkaroundTimeMs = C.TIME_UNSET;\n  lastLatencySampleTimeUs = 0;\n  latencyUs = 0;\n  audioTrackPlaybackSpeed = 1f;\n}", "summary_tokens": ["sets", "the", "audio", "track", "to", "wrap"], "project": "ExoPlayer"}
{"id": 91, "code": "public long getLastFrameTimestamp() {\n  return flacGetLastFrameTimestamp(nativeDecoderContext);\n}", "summary_tokens": ["returns", "the", "timestamp", "for", "the", "first", "sample", "in", "the", "last", "decoded", "frame"], "project": "ExoPlayer"}
{"id": 1708, "code": "public void open_withSpecifiedRequestParameters_usesCorrectParameters() throws Exception {\n  MockWebServer mockWebServer = new MockWebServer();\n  mockWebServer.enqueue(new MockResponse());\n\n  String propertyFromFactory = \"fromFactory\";\n  Map<String, String> defaultRequestProperties = new HashMap<>();\n  defaultRequestProperties.put(\"0\", propertyFromFactory);\n  defaultRequestProperties.put(\"1\", propertyFromFactory);\n  defaultRequestProperties.put(\"2\", propertyFromFactory);\n  defaultRequestProperties.put(\"4\", propertyFromFactory);\n  DefaultHttpDataSource dataSource =\n      new DefaultHttpDataSource.Factory()\n          .setConnectTimeoutMs(1000)\n          .setReadTimeoutMs(1000)\n          .setDefaultRequestProperties(defaultRequestProperties)\n          .createDataSource();\n\n  String propertyFromSetter = \"fromSetter\";\n  dataSource.setRequestProperty(\"1\", propertyFromSetter);\n  dataSource.setRequestProperty(\"2\", propertyFromSetter);\n  dataSource.setRequestProperty(\"3\", propertyFromSetter);\n  dataSource.setRequestProperty(\"5\", propertyFromSetter);\n\n  String propertyFromDataSpec = \"fromDataSpec\";\n  Map<String, String> dataSpecRequestProperties = new HashMap<>();\n  dataSpecRequestProperties.put(\"2\", propertyFromDataSpec);\n  dataSpecRequestProperties.put(\"3\", propertyFromDataSpec);\n  dataSpecRequestProperties.put(\"4\", propertyFromDataSpec);\n  dataSpecRequestProperties.put(\"6\", propertyFromDataSpec);\n  DataSpec dataSpec =\n      new DataSpec.Builder()\n          .setUri(mockWebServer.url(\"/test-path\").toString())\n          .setHttpRequestHeaders(dataSpecRequestProperties)\n          .build();\n\n  dataSource.open(dataSpec);\n\n  Headers headers = mockWebServer.takeRequest(10, SECONDS).getHeaders();\n  assertThat(headers.get(\"0\")).isEqualTo(propertyFromFactory);\n  assertThat(headers.get(\"1\")).isEqualTo(propertyFromSetter);\n  assertThat(headers.get(\"2\")).isEqualTo(propertyFromDataSpec);\n  assertThat(headers.get(\"3\")).isEqualTo(propertyFromDataSpec);\n  assertThat(headers.get(\"4\")).isEqualTo(propertyFromDataSpec);\n  assertThat(headers.get(\"5\")).isEqualTo(propertyFromSetter);\n  assertThat(headers.get(\"6\")).isEqualTo(propertyFromDataSpec);\n}", "summary_tokens": ["this", "test", "will", "set", "http", "default", "request", "parameters", "0", "in", "the", "default", "http", "data", "source", "0", "via", "default", "http", "data", "source"], "project": "ExoPlayer"}
{"id": 1872, "code": "public synchronized DefaultExtractorsFactory setFlacExtractorFlags(\n    @FlacExtractor.Flags int flags) {\n  this.flacFlags = flags;\n  return this;\n}", "summary_tokens": ["sets", "flags", "for", "flac", "extractor", "instances", "created", "by", "the", "factory"], "project": "ExoPlayer"}
{"id": 1516, "code": "public void onPlaybackSpeed(float playbackSpeed) {\n  this.playbackSpeed = playbackSpeed;\n  resetAdjustment();\n  updateSurfacePlaybackFrameRate( false);\n}", "summary_tokens": ["called", "when", "the", "renderer", "s", "playback", "speed", "changes"], "project": "ExoPlayer"}
{"id": 1321, "code": "public final void setStartTimeUs(long startTimeUs) {\n  this.startTimeUs = startTimeUs;\n}", "summary_tokens": ["sets", "the", "start", "time", "for", "the", "queue"], "project": "ExoPlayer"}
{"id": 127, "code": "public ImaServerSideAdInsertionUriBuilder setManifestSuffix(@Nullable String manifestSuffix) {\n  this.manifestSuffix = manifestSuffix;\n  return this;\n}", "summary_tokens": ["sets", "the", "optional", "stream", "manifest", "s", "suffix", "which", "will", "be", "appended", "to", "the", "stream", "manifest", "s", "url"], "project": "ExoPlayer"}
{"id": 1734, "code": "private int readInternal(byte[] buffer, int offset, int readLength) throws IOException {\n  if (readLength == 0) {\n    return 0;\n  }\n  if (bytesToRead != C.LENGTH_UNSET) {\n    long bytesRemaining = bytesToRead - bytesRead;\n    if (bytesRemaining == 0) {\n      return C.RESULT_END_OF_INPUT;\n    }\n    readLength = (int) min(readLength, bytesRemaining);\n  }\n\n  int read = castNonNull(inputStream).read(buffer, offset, readLength);\n  if (read == -1) {\n    return C.RESULT_END_OF_INPUT;\n  }\n\n  bytesRead += read;\n  bytesTransferred(read);\n  return read;\n}", "summary_tokens": ["reads", "up", "to", "length", "bytes", "of", "data", "and", "stores", "them", "into", "buffer", "starting", "at", "index", "offset"], "project": "ExoPlayer"}
{"id": 746, "code": "private boolean areDurationsCompatible(long previousDurationUs, long newDurationUs) {\n  return previousDurationUs == C.TIME_UNSET || previousDurationUs == newDurationUs;\n}", "summary_tokens": ["returns", "whether", "a", "duration", "change", "of", "a", "period", "is", "compatible", "with", "keeping", "the", "following", "periods"], "project": "ExoPlayer"}
{"id": 961, "code": "public int getMaxChannelCount() {\n  return maxChannelCount;\n}", "summary_tokens": ["returns", "the", "maximum", "number", "of", "channels", "the", "device", "can", "play", "at", "the", "same", "time"], "project": "ExoPlayer"}
{"id": 1308, "code": "public void peekToBuffer(DecoderInputBuffer buffer, SampleExtrasHolder extrasHolder) {\n  readSampleData(readAllocationNode, buffer, extrasHolder, scratch);\n}", "summary_tokens": ["peeks", "data", "from", "the", "rolling", "buffer", "to", "populate", "a", "decoder", "input", "buffer", "without", "advancing", "the", "read", "position"], "project": "ExoPlayer"}
{"id": 1884, "code": "public static boolean peekFullyQuietly(\n    ExtractorInput input, byte[] output, int offset, int length, boolean allowEndOfInput)\n    throws IOException {\n  try {\n    return input.peekFully(output, offset, length,  allowEndOfInput);\n  } catch (EOFException e) {\n    if (allowEndOfInput) {\n      return false;\n    } else {\n      throw e;\n    }\n  }\n}", "summary_tokens": ["peeks", "data", "from", "input", "respecting", "allow", "end", "of", "input"], "project": "ExoPlayer"}
{"id": 706, "code": "public void setRendererOffset(long rendererPositionOffsetUs) {\n  this.rendererPositionOffsetUs = rendererPositionOffsetUs;\n}", "summary_tokens": ["sets", "the", "renderer", "time", "of", "the", "start", "of", "the", "period", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 2348, "code": " static File createExternalCacheFile(Context context, String fileName)\n    throws IOException {\n  File file = new File(context.getExternalCacheDir(), fileName);\n  checkState(!file.exists() || file.delete(), \"Could not delete file: \" + file.getAbsolutePath());\n  checkState(file.createNewFile(), \"Could not create file: \" + file.getAbsolutePath());\n  return file;\n}", "summary_tokens": ["creates", "a", "file", "of", "the", "file", "name", "in", "the", "application", "cache", "directory"], "project": "ExoPlayer"}
{"id": 1447, "code": "public long bytesLoaded() {\n  return dataSource.getBytesRead();\n}", "summary_tokens": ["returns", "the", "number", "of", "bytes", "loaded"], "project": "ExoPlayer"}
{"id": 1546, "code": "public void setDefaultStereoMode(@C.StereoMode int stereoMode) {\n  defaultStereoMode = stereoMode;\n}", "summary_tokens": ["sets", "the", "default", "stereo", "mode"], "project": "ExoPlayer"}
{"id": 1235, "code": "public static void start(Context context, Class<? extends DownloadService> clazz) {\n  context.startService(getIntent(context, clazz, ACTION_INIT));\n}", "summary_tokens": ["starts", "a", "download", "service", "to", "resume", "any", "ongoing", "downloads"], "project": "ExoPlayer"}
{"id": 953, "code": "public float getNonFatalErrorRate() {\n  long playTimeMs = getTotalPlayTimeMs();\n  return playTimeMs == 0 ? 0f : 1000f * nonFatalErrorCount / playTimeMs;\n}", "summary_tokens": ["returns", "the", "rate", "of", "non", "fatal", "errors", "in", "errors", "per", "play", "time", "second", "or", "0"], "project": "ExoPlayer"}
{"id": 841, "code": "default void onPlaybackParametersChanged(\n    EventTime eventTime, PlaybackParameters playbackParameters) {}", "summary_tokens": ["called", "when", "the", "playback", "parameters", "changed"], "project": "ExoPlayer"}
{"id": 1763, "code": "public void addSpan(SimpleCacheSpan span) {\n  cachedSpans.add(span);\n}", "summary_tokens": ["adds", "the", "given", "simple", "cache", "span", "which", "contains", "a", "part", "of", "the", "content"], "project": "ExoPlayer"}
{"id": 2524, "code": "public void setUseController(boolean useController) {\n  Assertions.checkState(!useController || controller != null);\n  setClickable(useController || hasOnClickListeners());\n  if (this.useController == useController) {\n    return;\n  }\n  this.useController = useController;\n  if (useController()) {\n    controller.setPlayer(player);\n  } else if (controller != null) {\n    controller.hide();\n    controller.setPlayer( null);\n  }\n  updateContentDescription();\n}", "summary_tokens": ["sets", "whether", "the", "playback", "controls", "can", "be", "shown"], "project": "ExoPlayer"}
{"id": 2773, "code": "public void assertPrepareAndReleaseAllPeriods() throws InterruptedException {\n  Timeline.Period period = new Timeline.Period();\n  for (int i = 0; i < timeline.getPeriodCount(); i++) {\n    timeline.getPeriod(i, period,  true);\n    assertPrepareAndReleasePeriod(new MediaPeriodId(period.uid, period.windowIndex));\n    for (int adGroupIndex = 0; adGroupIndex < period.getAdGroupCount(); adGroupIndex++) {\n      for (int adIndex = 0; adIndex < period.getAdCountInAdGroup(adGroupIndex); adIndex++) {\n        assertPrepareAndReleasePeriod(\n            new MediaPeriodId(period.uid, adGroupIndex, adIndex, period.windowIndex));\n      }\n    }\n  }\n}", "summary_tokens": ["creates", "and", "releases", "all", "periods", "including", "ad", "periods", "defined", "in", "the", "last", "timeline", "to", "be", "returned", "from", "prepare", "source", "assert", "timeline", "change", "or", "assert", "timeline", "change", "blocking"], "project": "ExoPlayer"}
{"id": 1430, "code": "public synchronized int getRegionEndTimeMs(long byteOffset) {\n  lookupRegion.startOffset = byteOffset;\n  @Nullable Region floorRegion = regions.floor(lookupRegion);\n  if (floorRegion == null\n      || byteOffset > floorRegion.endOffset\n      || floorRegion.endOffsetIndex == -1) {\n    return NOT_CACHED;\n  }\n  int index = floorRegion.endOffsetIndex;\n  if (index == chunkIndex.length - 1\n      && floorRegion.endOffset == (chunkIndex.offsets[index] + chunkIndex.sizes[index])) {\n    return CACHED_TO_END;\n  }\n  long segmentFractionUs =\n      (chunkIndex.durationsUs[index] * (floorRegion.endOffset - chunkIndex.offsets[index]))\n          / chunkIndex.sizes[index];\n  return (int) ((chunkIndex.timesUs[index] + segmentFractionUs) / 1000);\n}", "summary_tokens": ["when", "provided", "with", "a", "byte", "offset", "this", "method", "locates", "the", "cached", "region", "within", "which", "the", "offset", "falls", "and", "returns", "the", "approximate", "end", "position", "in", "milliseconds", "of", "that", "region"], "project": "ExoPlayer"}
{"id": 510, "code": "public long get(int index) {\n  if (index < 0 || index >= size) {\n    throw new IndexOutOfBoundsException(\"Invalid index \" + index + \", size is \" + size);\n  }\n  return values[index];\n}", "summary_tokens": ["returns", "the", "value", "at", "a", "specified", "index"], "project": "ExoPlayer"}
{"id": 2379, "code": "public static Size getSupportedResolution(\n    MediaCodecInfo encoderInfo, String mimeType, int width, int height) {\n  MediaCodecInfo.VideoCapabilities videoEncoderCapabilities =\n      encoderInfo.getCapabilitiesForType(mimeType).getVideoCapabilities();\n  int widthAlignment = videoEncoderCapabilities.getWidthAlignment();\n  int heightAlignment = videoEncoderCapabilities.getHeightAlignment();\n\n    \n  width = alignResolution(width, widthAlignment);\n  height = alignResolution(height, heightAlignment);\n  if (isSizeSupported(encoderInfo, mimeType, width, height)) {\n    return new Size(width, height);\n  }\n\n    \n  int newWidth = alignResolution(width * 3 / 4, widthAlignment);\n  int newHeight = alignResolution(height * 3 / 4, heightAlignment);\n  if (isSizeSupported(encoderInfo, mimeType, newWidth, newHeight)) {\n    return new Size(newWidth, newHeight);\n  }\n\n    \n  newWidth = alignResolution(width * 2 / 3, widthAlignment);\n  newHeight = alignResolution(height * 2 / 3, heightAlignment);\n  if (isSizeSupported(encoderInfo, mimeType, width, height)) {\n    return new Size(newWidth, newHeight);\n  }\n\n    \n  newWidth = alignResolution(width / 2, widthAlignment);\n  newHeight = alignResolution(height / 2, heightAlignment);\n  if (isSizeSupported(encoderInfo, mimeType, newWidth, newHeight)) {\n    return new Size(newWidth, newHeight);\n  }\n\n    \n  newWidth = alignResolution(width / 3, widthAlignment);\n  newHeight = alignResolution(height / 3, heightAlignment);\n  if (isSizeSupported(encoderInfo, mimeType, newWidth, newHeight)) {\n    return new Size(newWidth, newHeight);\n  }\n\n    \n  width = videoEncoderCapabilities.getSupportedWidths().clamp(width);\n  int adjustedHeight = videoEncoderCapabilities.getSupportedHeightsFor(width).clamp(height);\n  if (adjustedHeight != height) {\n    width =\n        alignResolution((int) round((double) width * adjustedHeight / height), widthAlignment);\n    height = alignResolution(adjustedHeight, heightAlignment);\n  }\n\n  return isSizeSupported(encoderInfo, mimeType, width, height) ? new Size(width, height) : null;\n}", "summary_tokens": ["finds", "an", "media", "codec", "info", "encoder", "s", "supported", "resolution", "from", "a", "given", "resolution"], "project": "ExoPlayer"}
{"id": 526, "code": "public static String getVideoMediaMimeType(@Nullable String codecs) {\n  if (codecs == null) {\n    return null;\n  }\n  String[] codecList = Util.splitCodecs(codecs);\n  for (String codec : codecList) {\n    @Nullable String mimeType = getMediaMimeType(codec);\n    if (mimeType != null && isVideo(mimeType)) {\n      return mimeType;\n    }\n  }\n  return null;\n}", "summary_tokens": ["returns", "the", "first", "video", "mime", "type", "derived", "from", "an", "rfc", "0", "codecs", "string"], "project": "ExoPlayer"}
{"id": 462, "code": "public static @FileTypes.Type int inferFileTypeFromUri(Uri uri) {\n  @Nullable String filename = uri.getLastPathSegment();\n  if (filename == null) {\n    return FileTypes.UNKNOWN;\n  } else if (filename.endsWith(EXTENSION_AC3) || filename.endsWith(EXTENSION_EC3)) {\n    return FileTypes.AC3;\n  } else if (filename.endsWith(EXTENSION_AC4)) {\n    return FileTypes.AC4;\n  } else if (filename.endsWith(EXTENSION_ADTS) || filename.endsWith(EXTENSION_AAC)) {\n    return FileTypes.ADTS;\n  } else if (filename.endsWith(EXTENSION_AMR)) {\n    return FileTypes.AMR;\n  } else if (filename.endsWith(EXTENSION_FLAC)) {\n    return FileTypes.FLAC;\n  } else if (filename.endsWith(EXTENSION_FLV)) {\n    return FileTypes.FLV;\n  } else if (filename.endsWith(EXTENSION_MID)\n      || filename.endsWith(EXTENSION_MIDI)\n      || filename.endsWith(EXTENSION_SMF)) {\n    return FileTypes.MIDI;\n  } else if (filename.startsWith(\n          EXTENSION_PREFIX_MK,\n           filename.length() - (EXTENSION_PREFIX_MK.length() + 1))\n      || filename.endsWith(EXTENSION_WEBM)) {\n    return FileTypes.MATROSKA;\n  } else if (filename.endsWith(EXTENSION_MP3)) {\n    return FileTypes.MP3;\n  } else if (filename.endsWith(EXTENSION_MP4)\n      || filename.startsWith(\n          EXTENSION_PREFIX_M4,\n           filename.length() - (EXTENSION_PREFIX_M4.length() + 1))\n      || filename.startsWith(\n          EXTENSION_PREFIX_MP4,\n           filename.length() - (EXTENSION_PREFIX_MP4.length() + 1))\n      || filename.startsWith(\n          EXTENSION_PREFIX_CMF,\n           filename.length() - (EXTENSION_PREFIX_CMF.length() + 1))) {\n    return FileTypes.MP4;\n  } else if (filename.startsWith(\n          EXTENSION_PREFIX_OG,\n           filename.length() - (EXTENSION_PREFIX_OG.length() + 1))\n      || filename.endsWith(EXTENSION_OPUS)) {\n    return FileTypes.OGG;\n  } else if (filename.endsWith(EXTENSION_PS)\n      || filename.endsWith(EXTENSION_MPEG)\n      || filename.endsWith(EXTENSION_MPG)\n      || filename.endsWith(EXTENSION_M2P)) {\n    return FileTypes.PS;\n  } else if (filename.endsWith(EXTENSION_TS)\n      || filename.startsWith(\n          EXTENSION_PREFIX_TS,\n           filename.length() - (EXTENSION_PREFIX_TS.length() + 1))) {\n    return FileTypes.TS;\n  } else if (filename.endsWith(EXTENSION_WAV) || filename.endsWith(EXTENSION_WAVE)) {\n    return FileTypes.WAV;\n  } else if (filename.endsWith(EXTENSION_VTT) || filename.endsWith(EXTENSION_WEBVTT)) {\n    return FileTypes.WEBVTT;\n  } else if (filename.endsWith(EXTENSION_JPG) || filename.endsWith(EXTENSION_JPEG)) {\n    return FileTypes.JPEG;\n  } else if (filename.endsWith(EXTENSION_AVI)) {\n    return FileTypes.AVI;\n  } else {\n    return FileTypes.UNKNOWN;\n  }\n}", "summary_tokens": ["returns", "the", "type", "corresponding", "to", "the", "uri", "provided"], "project": "ExoPlayer"}
{"id": 2726, "code": "public final boolean isOpened() {\n  return sourceOpened;\n}", "summary_tokens": ["returns", "whether", "the", "data", "source", "is", "currently", "opened"], "project": "ExoPlayer"}
{"id": 758, "code": "public MediaPeriod createPeriod(\n    MediaSource.MediaPeriodId id, Allocator allocator, long startPositionUs) {\n  Object mediaSourceHolderUid = getMediaSourceHolderUid(id.periodUid);\n  MediaSource.MediaPeriodId childMediaPeriodId =\n      id.copyWithPeriodUid(getChildPeriodUid(id.periodUid));\n  MediaSourceHolder holder = Assertions.checkNotNull(mediaSourceByUid.get(mediaSourceHolderUid));\n  enableMediaSource(holder);\n  holder.activeMediaPeriodIds.add(childMediaPeriodId);\n  MediaPeriod mediaPeriod =\n      holder.mediaSource.createPeriod(childMediaPeriodId, allocator, startPositionUs);\n  mediaSourceByMediaPeriod.put(mediaPeriod, holder);\n  disableUnusedMediaSources();\n  return mediaPeriod;\n}", "summary_tokens": ["returns", "a", "new", "media", "period", "identified", "by", "period", "id"], "project": "ExoPlayer"}
{"id": 2282, "code": "private boolean seekInsideBufferUs(long positionUs) {\n  for (int i = 0; i < rtspLoaderWrappers.size(); i++) {\n    SampleQueue sampleQueue = rtspLoaderWrappers.get(i).sampleQueue;\n    if (!sampleQueue.seekTo(positionUs,  false)) {\n      return false;\n    }\n  }\n  return true;\n}", "summary_tokens": ["attempts", "to", "seek", "to", "the", "specified", "position", "within", "the", "sample", "queues"], "project": "ExoPlayer"}
{"id": 1920, "code": "public void reset() {\n  byteOffset = 0;\n  bitOffset = 0;\n}", "summary_tokens": ["resets", "the", "reading", "position", "to", "zero"], "project": "ExoPlayer"}
{"id": 467, "code": "private int getAttributeLocation(String attributeName) {\n  return getAttributeLocation(programId, attributeName);\n}", "summary_tokens": ["returns", "the", "location", "of", "an", "attribute"], "project": "ExoPlayer"}
{"id": 1823, "code": "private void maybeNotifyDecodeLoop() {\n  if (canDecodeBuffer()) {\n    lock.notify();\n  }\n}", "summary_tokens": ["notifies", "the", "decode", "loop", "if", "there", "exists", "a", "queued", "input", "buffer", "and", "an", "available", "output", "buffer", "to", "decode", "into"], "project": "ExoPlayer"}
{"id": 430, "code": "public static <T extends Bundleable> ImmutableList<Bundle> toBundleList(List<T> bundleableList) {\n  ImmutableList.Builder<Bundle> builder = ImmutableList.builder();\n  for (int i = 0; i < bundleableList.size(); i++) {\n    Bundleable bundleable = bundleableList.get(i);\n    builder.add(bundleable.toBundle());\n  }\n  return builder.build();\n}", "summary_tokens": ["converts", "a", "list", "of", "bundleable", "to", "a", "list", "bundle"], "project": "ExoPlayer"}
{"id": 1866, "code": "private int readFromUpstream(\n    byte[] target, int offset, int length, int bytesAlreadyRead, boolean allowEndOfInput)\n    throws IOException {\n  if (Thread.interrupted()) {\n    throw new InterruptedIOException();\n  }\n  int bytesRead = dataReader.read(target, offset + bytesAlreadyRead, length - bytesAlreadyRead);\n  if (bytesRead == C.RESULT_END_OF_INPUT) {\n    if (bytesAlreadyRead == 0 && allowEndOfInput) {\n      return C.RESULT_END_OF_INPUT;\n    }\n    throw new EOFException();\n  }\n  return bytesAlreadyRead + bytesRead;\n}", "summary_tokens": ["starts", "or", "continues", "a", "read", "from", "the", "data", "reader"], "project": "ExoPlayer"}
{"id": 1883, "code": "public static boolean skipFullyQuietly(ExtractorInput input, int length) throws IOException {\n  try {\n    input.skipFully(length);\n  } catch (EOFException e) {\n    return false;\n  }\n  return true;\n}", "summary_tokens": ["equivalent", "to", "extractor", "input", "skip", "fully", "int", "except", "that", "it", "returns", "false", "instead", "of", "throwing", "an", "eofexception", "if", "the", "end", "of", "input", "is", "encountered", "without", "having", "fully", "satisfied", "the", "skip"], "project": "ExoPlayer"}
{"id": 2186, "code": "public boolean readBit() {\n  boolean returnValue = (data[byteOffset] & (0x80 >> bitOffset)) != 0;\n  skipBit();\n  return returnValue;\n}", "summary_tokens": ["reads", "a", "single", "bit"], "project": "ExoPlayer"}
{"id": 1463, "code": "public static String getNtpHost() {\n  synchronized (valueLock) {\n    return ntpHost;\n  }\n}", "summary_tokens": ["returns", "the", "ntp", "host", "address", "used", "to", "retrieve", "get", "elapsed", "realtime", "offset", "ms"], "project": "ExoPlayer"}
{"id": 867, "code": "default void onDecoderInputFormatChanged(EventTime eventTime, int trackType, Format format) {}", "summary_tokens": ["use", "on", "audio", "input", "format", "changed", "event", "time", "format", "decoder", "reuse", "evaluation", "and", "on", "video", "input", "format", "changed", "event", "time", "format", "decoder", "reuse", "evaluation"], "project": "ExoPlayer"}
{"id": 2049, "code": "private void setReadingSampleState(\n    TrackOutput outputToUse, long currentSampleDuration, int priorReadBytes, int sampleSize) {\n  state = STATE_READING_SAMPLE;\n  bytesRead = priorReadBytes;\n  this.currentOutput = outputToUse;\n  this.currentSampleDuration = currentSampleDuration;\n  this.sampleSize = sampleSize;\n}", "summary_tokens": ["sets", "the", "state", "to", "state", "reading", "sample"], "project": "ExoPlayer"}
{"id": 2533, "code": "public void hideController() {\n  if (controller != null) {\n    controller.hide();\n  }\n}", "summary_tokens": ["hides", "the", "playback", "controls"], "project": "ExoPlayer"}
{"id": 1036, "code": "public void flush() {\n  inputFrameCount = 0;\n  outputFrameCount = 0;\n  pitchFrameCount = 0;\n  oldRatePosition = 0;\n  newRatePosition = 0;\n  remainingInputToCopyFrameCount = 0;\n  prevPeriod = 0;\n  prevMinDiff = 0;\n  minDiff = 0;\n  maxDiff = 0;\n}", "summary_tokens": ["clears", "state", "in", "preparation", "for", "receiving", "a", "new", "stream", "of", "input", "buffers"], "project": "ExoPlayer"}
{"id": 868, "code": "default void onDecoderDisabled(\n    EventTime eventTime, int trackType, DecoderCounters decoderCounters) {}", "summary_tokens": ["use", "on", "audio", "disabled", "and", "on", "video", "disabled", "instead"], "project": "ExoPlayer"}
{"id": 2029, "code": "private long getPacketDurationUs(byte[] packet) {\n  int toc = packet[0] & 0xFF;\n  int frames;\n  switch (toc & 0x3) {\n    case 0:\n      frames = 1;\n      break;\n    case 1:\n    case 2:\n      frames = 2;\n      break;\n    default:\n      frames = packet[1] & 0x3F;\n      break;\n  }\n\n  int config = toc >> 3;\n  int length = config & 0x3;\n  if (config >= 16) {\n    length = 2500 << length;\n  } else if (config >= 12) {\n    length = 10000 << (length & 0x1);\n  } else if (length == 3) {\n    length = 60000;\n  } else {\n    length = 10000 << length;\n  }\n  return (long) frames * length;\n}", "summary_tokens": ["returns", "the", "duration", "of", "the", "given", "audio", "packet"], "project": "ExoPlayer"}
{"id": 294, "code": "public boolean hasNext() {\n  return player.hasNext();\n}", "summary_tokens": ["calls", "player", "has", "next", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 1322, "code": "public final void sourceId(int sourceId) {\n  upstreamSourceId = sourceId;\n}", "summary_tokens": ["sets", "a", "source", "identifier", "for", "subsequent", "samples"], "project": "ExoPlayer"}
{"id": 245, "code": "public Format copyWithBitrate(int bitrate) {\n  return buildUpon().setAverageBitrate(bitrate).setPeakBitrate(bitrate).build();\n}", "summary_tokens": ["use", "build", "upon", "and", "builder", "set", "average", "bitrate", "int", "and", "builder", "set", "peak", "bitrate", "int"], "project": "ExoPlayer"}
{"id": 1603, "code": "public void selectTracksWithNullOverride() throws ExoPlaybackException {\n  trackSelector.setParameters(\n      trackSelector\n          .buildUponParameters()\n          .setSelectionOverride(0, new TrackGroupArray(VIDEO_TRACK_GROUP), null));\n  TrackSelectorResult result =\n      trackSelector.selectTracks(RENDERER_CAPABILITIES, TRACK_GROUPS, periodId, TIMELINE);\n  assertSelections(result, new TrackSelection[] {null, TRACK_SELECTIONS[1]});\n  assertThat(result.rendererConfigurations)\n      .isEqualTo(new RendererConfiguration[] {null, DEFAULT});\n}", "summary_tokens": ["tests", "that", "a", "null", "override", "clears", "a", "track", "selection"], "project": "ExoPlayer"}
{"id": 516, "code": "public static void maybeSetInteger(MediaFormat format, String key, int value) {\n  if (value != Format.NO_VALUE) {\n    format.setInteger(key, value);\n  }\n}", "summary_tokens": ["sets", "a", "media", "format", "integer", "value"], "project": "ExoPlayer"}
{"id": 1452, "code": "public float getPercentile(float percentile) {\n  ensureSortedByValue();\n  float desiredWeight = percentile * totalWeight;\n  int accumulatedWeight = 0;\n  for (int i = 0; i < samples.size(); i++) {\n    Sample currentSample = samples.get(i);\n    accumulatedWeight += currentSample.weight;\n    if (accumulatedWeight >= desiredWeight) {\n      return currentSample.value;\n    }\n  }\n    \n  return samples.isEmpty() ? Float.NaN : samples.get(samples.size() - 1).value;\n}", "summary_tokens": ["computes", "a", "percentile", "by", "integration"], "project": "ExoPlayer"}
{"id": 2695, "code": "public static int getTotalBufferCount(DecoderCounters counters) {\n  counters.ensureUpdated();\n  return counters.skippedInputBufferCount\n      + counters.skippedOutputBufferCount\n      + counters.droppedBufferCount\n      + counters.renderedOutputBufferCount;\n}", "summary_tokens": ["returns", "the", "sum", "of", "the", "skipped", "dropped", "and", "rendered", "buffers"], "project": "ExoPlayer"}
{"id": 2303, "code": "public static RtspSessionHeader parseSessionHeader(String headerValue) throws ParserException {\n  Matcher matcher = SESSION_HEADER_PATTERN.matcher(headerValue);\n  if (!matcher.matches()) {\n    throw ParserException.createForMalformedManifest(headerValue,  null);\n  }\n\n  String sessionId = checkNotNull(matcher.group(1));\n    \n  long timeoutMs = DEFAULT_RTSP_TIMEOUT_MS;\n  @Nullable String timeoutString;\n  if ((timeoutString = matcher.group(2)) != null) {\n    try {\n      timeoutMs = Integer.parseInt(timeoutString) * C.MILLIS_PER_SECOND;\n    } catch (NumberFormatException e) {\n      throw ParserException.createForMalformedManifest(headerValue, e);\n    }\n  }\n\n  return new RtspSessionHeader(sessionId, timeoutMs);\n}", "summary_tokens": ["parses", "a", "session", "header", "in", "an", "rtsp", "message", "to", "rtsp", "session", "header"], "project": "ExoPlayer"}
{"id": 2535, "code": "public void setControllerShowTimeoutMs(int controllerShowTimeoutMs) {\n  Assertions.checkStateNotNull(controller);\n  this.controllerShowTimeoutMs = controllerShowTimeoutMs;\n  if (controller.isVisible()) {\n      \n    showController();\n  }\n}", "summary_tokens": ["sets", "the", "playback", "controls", "timeout"], "project": "ExoPlayer"}
{"id": 742, "code": "private static MediaPeriodId resolveMediaPeriodIdForAds(\n    Timeline timeline,\n    Object periodUid,\n    long positionUs,\n    long windowSequenceNumber,\n    Timeline.Window window,\n    Timeline.Period period) {\n  timeline.getPeriodByUid(periodUid, period);\n  timeline.getWindow(period.windowIndex, window);\n  int periodIndex = timeline.getIndexOfPeriod(periodUid);\n    \n  while ((period.durationUs == 0\n          && period.getAdGroupCount() > 0\n          && period.isServerSideInsertedAdGroup(period.getRemovedAdGroupCount())\n          && period.getAdGroupIndexForPositionUs(0) == C.INDEX_UNSET)\n      && periodIndex++ < window.lastPeriodIndex) {\n    timeline.getPeriod(periodIndex, period,  true);\n    periodUid = checkNotNull(period.uid);\n  }\n  timeline.getPeriodByUid(periodUid, period);\n  int adGroupIndex = period.getAdGroupIndexForPositionUs(positionUs);\n  if (adGroupIndex == C.INDEX_UNSET) {\n    int nextAdGroupIndex = period.getAdGroupIndexAfterPositionUs(positionUs);\n    return new MediaPeriodId(periodUid, windowSequenceNumber, nextAdGroupIndex);\n  } else {\n    int adIndexInAdGroup = period.getFirstAdIndexToPlay(adGroupIndex);\n    return new MediaPeriodId(periodUid, adGroupIndex, adIndexInAdGroup, windowSequenceNumber);\n  }\n}", "summary_tokens": ["resolves", "the", "specified", "timeline", "period", "and", "position", "to", "a", "media", "period", "id", "that", "should", "be", "played", "returning", "an", "identifier", "for", "an", "ad", "group", "if", "one", "needs", "to", "be", "played", "before", "the", "specified", "position", "or", "an", "identifier", "for", "a", "content", "media", "period", "if", "not"], "project": "ExoPlayer"}
{"id": 2102, "code": "public int getSubFrameCount() {\n  return subFrames.length;\n}", "summary_tokens": ["returns", "the", "number", "of", "sub", "frames"], "project": "ExoPlayer"}
{"id": 2106, "code": "private static int removeUnsynchronization(ParsableByteArray data, int length) {\n  byte[] bytes = data.getData();\n  int startPosition = data.getPosition();\n  for (int i = startPosition; i + 1 < startPosition + length; i++) {\n    if ((bytes[i] & 0xFF) == 0xFF && bytes[i + 1] == 0x00) {\n      int relativePosition = i - startPosition;\n      System.arraycopy(bytes, i + 2, bytes, i + 1, length - relativePosition - 2);\n      length--;\n    }\n  }\n  return length;\n}", "summary_tokens": ["performs", "in", "place", "removal", "of", "unsynchronization", "for", "length", "bytes", "starting", "from", "parsable", "byte", "array", "get", "position"], "project": "ExoPlayer"}
{"id": 865, "code": "default void onDecoderEnabled(\n    EventTime eventTime, int trackType, DecoderCounters decoderCounters) {}", "summary_tokens": ["use", "on", "audio", "enabled", "and", "on", "video", "enabled", "instead"], "project": "ExoPlayer"}
{"id": 725, "code": "public MediaPeriodInfo copyWithStartPositionUs(long startPositionUs) {\n  return startPositionUs == this.startPositionUs\n      ? this\n      : new MediaPeriodInfo(\n          id,\n          startPositionUs,\n          requestedContentPositionUs,\n          endPositionUs,\n          durationUs,\n          isFollowedByTransitionToSameStream,\n          isLastInTimelinePeriod,\n          isLastInTimelineWindow,\n          isFinal);\n}", "summary_tokens": ["returns", "a", "copy", "of", "this", "instance", "with", "the", "start", "position", "set", "to", "the", "specified", "value"], "project": "ExoPlayer"}
{"id": 1130, "code": "protected void resetCodecStateForRelease() {\n  resetCodecStateForFlush();\n\n  pendingPlaybackException = null;\n  c2Mp3TimestampTracker = null;\n  availableCodecInfos = null;\n  codecInfo = null;\n  codecInputFormat = null;\n  codecOutputMediaFormat = null;\n  codecOutputMediaFormatChanged = false;\n  codecHasOutputMediaFormat = false;\n  codecOperatingRate = CODEC_OPERATING_RATE_UNSET;\n  codecAdaptationWorkaroundMode = ADAPTATION_WORKAROUND_MODE_NEVER;\n  codecNeedsDiscardToSpsWorkaround = false;\n  codecNeedsFlushWorkaround = false;\n  codecNeedsSosFlushWorkaround = false;\n  codecNeedsEosFlushWorkaround = false;\n  codecNeedsEosOutputExceptionWorkaround = false;\n  codecNeedsEosBufferTimestampWorkaround = false;\n  codecNeedsMonoChannelCountWorkaround = false;\n  codecNeedsEosPropagation = false;\n  codecReconfigured = false;\n  codecReconfigurationState = RECONFIGURATION_STATE_NONE;\n  mediaCryptoRequiresSecureDecoder = false;\n}", "summary_tokens": ["resets", "the", "renderer", "internal", "state", "after", "a", "codec", "release"], "project": "ExoPlayer"}
{"id": 941, "code": "public int getMeanInitialVideoFormatBitrate() {\n  return initialVideoFormatBitrateCount == 0\n      ? C.LENGTH_UNSET\n      : (int) (totalInitialVideoFormatBitrate / initialVideoFormatBitrateCount);\n}", "summary_tokens": ["returns", "the", "mean", "initial", "video", "format", "bitrate", "in", "bits", "per", "second", "or", "c", "length", "unset", "if", "no", "video", "format", "data", "is", "available"], "project": "ExoPlayer"}
{"id": 1813, "code": "public android.media.MediaCodec.CryptoInfo getFrameworkCryptoInfo() {\n  return frameworkCryptoInfo;\n}", "summary_tokens": ["returns", "an", "equivalent", "android"], "project": "ExoPlayer"}
{"id": 2117, "code": "public void setContent(long timeUs, Subtitle subtitle, long subsampleOffsetUs) {\n  this.timeUs = timeUs;\n  this.subtitle = subtitle;\n  this.subsampleOffsetUs =\n      subsampleOffsetUs == Format.OFFSET_SAMPLE_RELATIVE ? this.timeUs : subsampleOffsetUs;\n}", "summary_tokens": ["sets", "the", "content", "of", "the", "output", "buffer", "consisting", "of", "a", "subtitle", "and", "associated", "metadata"], "project": "ExoPlayer"}
{"id": 2245, "code": "public ImmutableMap<String, String> getFmtpParametersAsMap() {\n  @Nullable String fmtpAttributeValue = attributes.get(ATTR_FMTP);\n  if (fmtpAttributeValue == null) {\n    return ImmutableMap.of();\n  }\n\n    \n  String[] fmtpComponents = Util.splitAtFirst(fmtpAttributeValue, \" \");\n  checkArgument(fmtpComponents.length == 2, fmtpAttributeValue);\n\n    \n    \n    \n  String[] parameters = fmtpComponents[1].split(\";\\\\s?\",  0);\n  ImmutableMap.Builder<String, String> formatParametersBuilder = new ImmutableMap.Builder<>();\n  for (String parameter : parameters) {\n      \n    String[] parameterPair = Util.splitAtFirst(parameter, \"=\");\n    formatParametersBuilder.put(parameterPair[0], parameterPair[1]);\n  }\n  return formatParametersBuilder.buildOrThrow();\n}", "summary_tokens": ["returns", "the", "fmtp", "attribute", "as", "a", "map", "of", "fmtp", "parameter", "names", "to", "values", "or", "an", "empty", "map", "if", "the", "media", "description", "does", "not", "contain", "any", "fmtp", "attribute"], "project": "ExoPlayer"}
{"id": 1979, "code": "private long getTimeUsForTableIndex(int tableIndex) {\n  return (durationUs * tableIndex) / 100;\n}", "summary_tokens": ["returns", "the", "time", "in", "microseconds", "for", "a", "given", "table", "index"], "project": "ExoPlayer"}
{"id": 784, "code": "public Target getTarget() {\n  return target;\n}", "summary_tokens": ["returns", "the", "target", "the", "message", "is", "sent", "to"], "project": "ExoPlayer"}
{"id": 597, "code": "public void proceed(int priority) throws InterruptedException {\n  synchronized (lock) {\n    while (highestPriority != priority) {\n      lock.wait();\n    }\n  }\n}", "summary_tokens": ["blocks", "until", "the", "task", "is", "allowed", "to", "proceed"], "project": "ExoPlayer"}
{"id": 1990, "code": "private static long parseTfdt(ParsableByteArray tfdt) {\n  tfdt.setPosition(Atom.HEADER_SIZE);\n  int fullAtom = tfdt.readInt();\n  int version = Atom.parseFullAtomVersion(fullAtom);\n  return version == 1 ? tfdt.readUnsignedLongToLong() : tfdt.readUnsignedInt();\n}", "summary_tokens": ["parses", "a", "tfdt", "atom", "defined", "in", "0", "0"], "project": "ExoPlayer"}
{"id": 935, "code": "public float getJoinTimeRatio() {\n  long playAndWaitTimeMs = getTotalPlayAndWaitTimeMs();\n  return playAndWaitTimeMs == 0 ? 0f : (float) getTotalJoinTimeMs() / playAndWaitTimeMs;\n}", "summary_tokens": ["returns", "the", "ratio", "of", "foreground", "join", "time", "to", "the", "total", "time", "spent", "playing", "and", "waiting", "or", "0"], "project": "ExoPlayer"}
{"id": 1938, "code": "private static void alignInputToEvenPosition(ExtractorInput input) throws IOException {\n  if ((input.getPosition() & 1) == 1) {\n    input.skipFully(1);\n  }\n}", "summary_tokens": ["skips", "one", "byte", "from", "the", "given", "input", "if", "the", "current", "position", "is", "odd"], "project": "ExoPlayer"}
{"id": 814, "code": "public void stop(boolean reset) {\n  blockUntilConstructorFinished();\n  player.stop(reset);\n}", "summary_tokens": ["use", "stop", "and", "clear", "media", "items", "if", "reset", "is", "true", "or", "just", "stop", "if", "reset", "is", "false"], "project": "ExoPlayer"}
{"id": 780, "code": "public PlaybackInfo copyWithPlayWhenReady(\n    boolean playWhenReady, @PlaybackSuppressionReason int playbackSuppressionReason) {\n  return new PlaybackInfo(\n      timeline,\n      periodId,\n      requestedContentPositionUs,\n      discontinuityStartPositionUs,\n      playbackState,\n      playbackError,\n      isLoading,\n      trackGroups,\n      trackSelectorResult,\n      staticMetadata,\n      loadingMediaPeriodId,\n      playWhenReady,\n      playbackSuppressionReason,\n      playbackParameters,\n      bufferedPositionUs,\n      totalBufferedDurationUs,\n      positionUs,\n      sleepingForOffload);\n}", "summary_tokens": ["copies", "playback", "info", "with", "new", "information", "about", "whether", "playback", "should", "proceed", "when", "ready"], "project": "ExoPlayer"}
{"id": 1225, "code": "public static Intent buildPauseDownloadsIntent(\n    Context context, Class<? extends DownloadService> clazz, boolean foreground) {\n  return getIntent(context, clazz, ACTION_PAUSE_DOWNLOADS, foreground);\n}", "summary_tokens": ["builds", "an", "intent", "to", "pause", "all", "downloads"], "project": "ExoPlayer"}
{"id": 744, "code": "private long resolvePeriodIndexToWindowSequenceNumber(Timeline timeline, Object periodUid) {\n  int windowIndex = timeline.getPeriodByUid(periodUid, period).windowIndex;\n  if (oldFrontPeriodUid != null) {\n    int oldFrontPeriodIndex = timeline.getIndexOfPeriod(oldFrontPeriodUid);\n    if (oldFrontPeriodIndex != C.INDEX_UNSET) {\n      int oldFrontWindowIndex = timeline.getPeriod(oldFrontPeriodIndex, period).windowIndex;\n      if (oldFrontWindowIndex == windowIndex) {\n          \n        return oldFrontPeriodWindowSequenceNumber;\n      }\n    }\n  }\n  MediaPeriodHolder mediaPeriodHolder = playing;\n  while (mediaPeriodHolder != null) {\n    if (mediaPeriodHolder.uid.equals(periodUid)) {\n        \n      return mediaPeriodHolder.info.id.windowSequenceNumber;\n    }\n    mediaPeriodHolder = mediaPeriodHolder.getNext();\n  }\n  mediaPeriodHolder = playing;\n  while (mediaPeriodHolder != null) {\n    int indexOfHolderInTimeline = timeline.getIndexOfPeriod(mediaPeriodHolder.uid);\n    if (indexOfHolderInTimeline != C.INDEX_UNSET) {\n      int holderWindowIndex = timeline.getPeriod(indexOfHolderInTimeline, period).windowIndex;\n      if (holderWindowIndex == windowIndex) {\n          \n        return mediaPeriodHolder.info.id.windowSequenceNumber;\n      }\n    }\n    mediaPeriodHolder = mediaPeriodHolder.getNext();\n  }\n    \n  long windowSequenceNumber = nextWindowSequenceNumber++;\n  if (playing == null) {\n      \n    oldFrontPeriodUid = periodUid;\n    oldFrontPeriodWindowSequenceNumber = windowSequenceNumber;\n  }\n  return windowSequenceNumber;\n}", "summary_tokens": ["resolves", "the", "specified", "period", "uid", "to", "a", "corresponding", "window", "sequence", "number"], "project": "ExoPlayer"}
{"id": 806, "code": "static @HardwareAccelerationSupport int getHardwareAccelerationSupport(\n    @Capabilities int supportFlags) {\n  return supportFlags & HARDWARE_ACCELERATION_SUPPORT_MASK;\n}", "summary_tokens": ["returns", "the", "hardware", "acceleration", "support", "from", "the", "combined", "capabilities"], "project": "ExoPlayer"}
{"id": 1467, "code": "public static void initialize(\n    @Nullable Loader loader, @Nullable InitializationCallback callback) {\n  if (isInitialized()) {\n    if (callback != null) {\n      callback.onInitialized();\n    }\n    return;\n  }\n  if (loader == null) {\n    loader = new Loader(\"SntpClient\");\n  }\n  loader.startLoading(\n      new NtpTimeLoadable(), new NtpTimeCallback(callback),  1);\n}", "summary_tokens": ["starts", "loading", "the", "device", "time", "offset"], "project": "ExoPlayer"}
{"id": 711, "code": "public void reevaluateBuffer(long rendererPositionUs) {\n  Assertions.checkState(isLoadingMediaPeriod());\n  if (prepared) {\n    mediaPeriod.reevaluateBuffer(toPeriodTime(rendererPositionUs));\n  }\n}", "summary_tokens": ["reevaluates", "the", "buffer", "of", "the", "media", "period", "at", "the", "given", "renderer", "position"], "project": "ExoPlayer"}
{"id": 808, "code": "public long resolveSeekPositionUs(long positionUs, long firstSyncUs, long secondSyncUs) {\n  if (toleranceBeforeUs == 0 && toleranceAfterUs == 0) {\n    return positionUs;\n  }\n  long minPositionUs =\n      Util.subtractWithOverflowDefault(positionUs, toleranceBeforeUs, Long.MIN_VALUE);\n  long maxPositionUs = Util.addWithOverflowDefault(positionUs, toleranceAfterUs, Long.MAX_VALUE);\n  boolean firstSyncPositionValid = minPositionUs <= firstSyncUs && firstSyncUs <= maxPositionUs;\n  boolean secondSyncPositionValid =\n      minPositionUs <= secondSyncUs && secondSyncUs <= maxPositionUs;\n  if (firstSyncPositionValid && secondSyncPositionValid) {\n    if (Math.abs(firstSyncUs - positionUs) <= Math.abs(secondSyncUs - positionUs)) {\n      return firstSyncUs;\n    } else {\n      return secondSyncUs;\n    }\n  } else if (firstSyncPositionValid) {\n    return firstSyncUs;\n  } else if (secondSyncPositionValid) {\n    return secondSyncUs;\n  } else {\n    return minPositionUs;\n  }\n}", "summary_tokens": ["resolves", "a", "seek", "based", "on", "the", "parameters", "given", "the", "requested", "seek", "position", "and", "two", "candidate", "sync", "points"], "project": "ExoPlayer"}
{"id": 1136, "code": "protected void onCodecError(Exception codecError) {\n    \n}", "summary_tokens": ["called", "when", "a", "codec", "error", "has", "occurred"], "project": "ExoPlayer"}
{"id": 721, "code": "private void disassociateNoSampleRenderersWithEmptySampleStream(\n    @NullableType SampleStream[] sampleStreams) {\n  for (int i = 0; i < rendererCapabilities.length; i++) {\n    if (rendererCapabilities[i].getTrackType() == C.TRACK_TYPE_NONE) {\n      sampleStreams[i] = null;\n    }\n  }\n}", "summary_tokens": ["for", "each", "renderer", "of", "type", "c", "track", "type", "none", "we", "will", "remove", "the", "empty", "sample", "stream", "that", "was", "associated", "with", "it"], "project": "ExoPlayer"}
{"id": 2578, "code": "public void setShowSubtitleButton(boolean showSubtitleButton) {\n  controlViewLayoutManager.setShowButton(subtitleButton, showSubtitleButton);\n}", "summary_tokens": ["sets", "whether", "the", "subtitle", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 486, "code": "private static EGLSurface createPbufferSurface(EGLDisplay eglDisplay, int width, int height) {\n  int[] pbufferAttributes =\n      new int[] {\n        EGL14.EGL_WIDTH, width,\n        EGL14.EGL_HEIGHT, height,\n        EGL14.EGL_NONE\n      };\n  return Api17.createEglPbufferSurface(\n      eglDisplay, EGL_CONFIG_ATTRIBUTES_RGBA_8888, pbufferAttributes);\n}", "summary_tokens": ["creates", "a", "new", "eglsurface", "wrapping", "a", "pixel", "buffer"], "project": "ExoPlayer"}
{"id": 682, "code": "protected void buildMetadataRenderers(\n    Context context,\n    MetadataOutput output,\n    Looper outputLooper,\n    @ExtensionRendererMode int extensionRendererMode,\n    ArrayList<Renderer> out) {\n  out.add(new MetadataRenderer(output, outputLooper));\n}", "summary_tokens": ["builds", "metadata", "renderers", "for", "use", "by", "the", "player"], "project": "ExoPlayer"}
{"id": 2384, "code": "public static boolean isBitrateModeSupported(\n    MediaCodecInfo encoderInfo, String mimeType, int bitrateMode) {\n  return encoderInfo\n      .getCapabilitiesForType(mimeType)\n      .getEncoderCapabilities()\n      .isBitrateModeSupported(bitrateMode);\n}", "summary_tokens": ["returns", "whether", "the", "bitrate", "mode", "is", "supported", "by", "the", "encoder"], "project": "ExoPlayer"}
{"id": 607, "code": "public synchronized long getLastAdjustedTimestampUs() {\n  return lastUnadjustedTimestampUs != C.TIME_UNSET\n      ? lastUnadjustedTimestampUs + timestampOffsetUs\n      : getFirstSampleTimestampUs();\n}", "summary_tokens": ["returns", "the", "last", "adjusted", "timestamp", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 2306, "code": "public static int parseInt(String intString) throws ParserException {\n  try {\n    return Integer.parseInt(intString);\n  } catch (NumberFormatException e) {\n    throw ParserException.createForMalformedManifest(intString, e);\n  }\n}", "summary_tokens": ["parses", "the", "string", "argument", "as", "an", "integer", "wraps", "the", "potential", "number", "format", "exception", "in", "parser", "exception"], "project": "ExoPlayer"}
{"id": 947, "code": "public float getDroppedFramesRate() {\n  long playTimeMs = getTotalPlayTimeMs();\n  return playTimeMs == 0 ? 0f : 1000f * totalDroppedFrames / playTimeMs;\n}", "summary_tokens": ["returns", "the", "mean", "rate", "at", "which", "video", "frames", "are", "dropped", "in", "dropped", "frames", "per", "play", "time", "second", "or", "0"], "project": "ExoPlayer"}
{"id": 1345, "code": "public final void setSampleOffsetUs(long sampleOffsetUs) {\n  if (this.sampleOffsetUs != sampleOffsetUs) {\n    this.sampleOffsetUs = sampleOffsetUs;\n    invalidateUpstreamFormatAdjustment();\n  }\n}", "summary_tokens": ["sets", "an", "offset", "that", "will", "be", "added", "to", "the", "timestamps", "and", "sub", "sample", "timestamps", "of", "samples", "that", "are", "subsequently", "queued"], "project": "ExoPlayer"}
{"id": 1330, "code": "public final int getReadIndex() {\n  return absoluteFirstIndex + readPosition;\n}", "summary_tokens": ["returns", "the", "current", "absolute", "read", "index"], "project": "ExoPlayer"}
{"id": 309, "code": "public MediaMetadata getMediaMetadata() {\n  return player.getMediaMetadata();\n}", "summary_tokens": ["calls", "player", "get", "media", "metadata", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 984, "code": "public long getTimestampPositionFrames() {\n  return audioTimestamp != null ? audioTimestamp.getTimestampPositionFrames() : C.POSITION_UNSET;\n}", "summary_tokens": ["if", "maybe", "poll", "timestamp", "long", "or", "has", "timestamp", "returned", "true", "returns", "the", "latest", "timestamp", "s", "position", "in", "frames"], "project": "ExoPlayer"}
{"id": 60, "code": "public static Format mediaTrackToFormat(MediaTrack mediaTrack) {\n  return new Format.Builder()\n      .setId(mediaTrack.getContentId())\n      .setContainerMimeType(mediaTrack.getContentType())\n      .setLanguage(mediaTrack.getLanguage())\n      .build();\n}", "summary_tokens": ["creates", "a", "format", "instance", "containing", "all", "information", "contained", "in", "the", "given", "media", "track", "object"], "project": "ExoPlayer"}
{"id": 2632, "code": "public void setAspectRatioListener(\n    @Nullable AspectRatioFrameLayout.AspectRatioListener listener) {\n  Assertions.checkStateNotNull(contentFrame);\n  contentFrame.setAspectRatioListener(listener);\n}", "summary_tokens": ["sets", "the", "aspect", "ratio", "frame", "layout"], "project": "ExoPlayer"}
{"id": 1834, "code": "public static SyncFrameInfo parseAc3SyncframeInfo(ParsableBitArray data) {\n  int initialPosition = data.getPosition();\n  data.skipBits(40);\n    \n  boolean isEac3 = data.readBits(5) > 10;\n  data.setPosition(initialPosition);\n  @Nullable String mimeType;\n  @StreamType int streamType = SyncFrameInfo.STREAM_TYPE_UNDEFINED;\n  int sampleRate;\n  int acmod;\n  int frameSize;\n  int sampleCount;\n  boolean lfeon;\n  int channelCount;\n  if (isEac3) {\n      \n    data.skipBits(16); \n    switch (data.readBits(2)) { \n      case 0:\n        streamType = SyncFrameInfo.STREAM_TYPE_TYPE0;\n        break;\n      case 1:\n        streamType = SyncFrameInfo.STREAM_TYPE_TYPE1;\n        break;\n      case 2:\n        streamType = SyncFrameInfo.STREAM_TYPE_TYPE2;\n        break;\n      default:\n        streamType = SyncFrameInfo.STREAM_TYPE_UNDEFINED;\n        break;\n    }\n    data.skipBits(3); \n    frameSize = (data.readBits(11) + 1) * 2; \n    int fscod = data.readBits(2);\n    int audioBlocks;\n    int numblkscod;\n    if (fscod == 3) {\n      numblkscod = 3;\n      sampleRate = SAMPLE_RATE_BY_FSCOD2[data.readBits(2)];\n      audioBlocks = 6;\n    } else {\n      numblkscod = data.readBits(2);\n      audioBlocks = BLOCKS_PER_SYNCFRAME_BY_NUMBLKSCOD[numblkscod];\n      sampleRate = SAMPLE_RATE_BY_FSCOD[fscod];\n    }\n    sampleCount = AUDIO_SAMPLES_PER_AUDIO_BLOCK * audioBlocks;\n    acmod = data.readBits(3);\n    lfeon = data.readBit();\n    channelCount = CHANNEL_COUNT_BY_ACMOD[acmod] + (lfeon ? 1 : 0);\n    data.skipBits(5 + 5); \n    if (data.readBit()) { \n      data.skipBits(8); \n    }\n    if (acmod == 0) {\n      data.skipBits(5); \n      if (data.readBit()) { \n        data.skipBits(8); \n      }\n    }\n    if (streamType == SyncFrameInfo.STREAM_TYPE_TYPE1 && data.readBit()) { \n      data.skipBits(16); \n    }\n    if (data.readBit()) { \n      if (acmod > 2) {\n        data.skipBits(2); \n      }\n      if ((acmod & 0x01) != 0 && acmod > 2) {\n        data.skipBits(3 + 3); \n      }\n      if ((acmod & 0x04) != 0) {\n        data.skipBits(6); \n      }\n      if (lfeon && data.readBit()) { \n        data.skipBits(5); \n      }\n      if (streamType == SyncFrameInfo.STREAM_TYPE_TYPE0) {\n        if (data.readBit()) { \n          data.skipBits(6); \n        }\n        if (acmod == 0 && data.readBit()) { \n          data.skipBits(6); \n        }\n        if (data.readBit()) { \n          data.skipBits(6); \n        }\n        int mixdef = data.readBits(2);\n        if (mixdef == 1) {\n          data.skipBits(1 + 1 + 3); \n        } else if (mixdef == 2) {\n          data.skipBits(12); \n        } else if (mixdef == 3) {\n          int mixdeflen = data.readBits(5);\n          if (data.readBit()) { \n            data.skipBits(1 + 1 + 3); \n            if (data.readBit()) { \n              data.skipBits(4); \n            }\n            if (data.readBit()) { \n              data.skipBits(4); \n            }\n            if (data.readBit()) { \n              data.skipBits(4); \n            }\n            if (data.readBit()) { \n              data.skipBits(4); \n            }\n            if (data.readBit()) { \n              data.skipBits(4); \n            }\n            if (data.readBit()) { \n              data.skipBits(4); \n            }\n            if (data.readBit()) { \n              data.skipBits(4); \n            }\n            if (data.readBit()) { \n              if (data.readBit()) { \n                data.skipBits(4); \n              }\n              if (data.readBit()) { \n                data.skipBits(4); \n              }\n            }\n          }\n          if (data.readBit()) { \n            data.skipBits(5); \n            if (data.readBit()) { \n              data.skipBits(5 + 2); \n              if (data.readBit()) { \n                data.skipBits(5 + 3); \n              }\n            }\n          }\n          data.skipBits(8 * (mixdeflen + 2)); \n          data.byteAlign(); \n        }\n        if (acmod < 2) {\n          if (data.readBit()) { \n            data.skipBits(8 + 6); \n          }\n          if (acmod == 0) {\n            if (data.readBit()) { \n              data.skipBits(8 + 6); \n            }\n          }\n        }\n        if (data.readBit()) { \n          if (numblkscod == 0) {\n            data.skipBits(5); \n          } else {\n            for (int blk = 0; blk < audioBlocks; blk++) {\n              if (data.readBit()) { \n                data.skipBits(5); \n              }\n            }\n          }\n        }\n      }\n    }\n    if (data.readBit()) { \n      data.skipBits(3 + 1 + 1); \n      if (acmod == 2) {\n        data.skipBits(2 + 2); \n      }\n      if (acmod >= 6) {\n        data.skipBits(2); \n      }\n      if (data.readBit()) { \n        data.skipBits(5 + 2 + 1); \n      }\n      if (acmod == 0 && data.readBit()) { \n        data.skipBits(5 + 2 + 1); \n      }\n      if (fscod < 3) {\n        data.skipBit(); \n      }\n    }\n    if (streamType == SyncFrameInfo.STREAM_TYPE_TYPE0 && numblkscod != 3) {\n      data.skipBit(); \n    }\n    if (streamType == SyncFrameInfo.STREAM_TYPE_TYPE2\n        && (numblkscod == 3 || data.readBit())) { \n      data.skipBits(6); \n    }\n    mimeType = MimeTypes.AUDIO_E_AC3;\n    if (data.readBit()) { \n      int addbsil = data.readBits(6);\n      if (addbsil == 1 && data.readBits(8) == 1) { \n        mimeType = MimeTypes.AUDIO_E_AC3_JOC;\n      }\n    }\n  } else  {\n    mimeType = MimeTypes.AUDIO_AC3;\n    data.skipBits(16 + 16); \n    int fscod = data.readBits(2);\n    if (fscod == 3) {\n        \n        \n      mimeType = null;\n    }\n    int frmsizecod = data.readBits(6);\n    frameSize = getAc3SyncframeSize(fscod, frmsizecod);\n    data.skipBits(5 + 3); \n    acmod = data.readBits(3);\n    if ((acmod & 0x01) != 0 && acmod != 1) {\n      data.skipBits(2); \n    }\n    if ((acmod & 0x04) != 0) {\n      data.skipBits(2); \n    }\n    if (acmod == 2) {\n      data.skipBits(2); \n    }\n    sampleRate =\n        fscod < SAMPLE_RATE_BY_FSCOD.length ? SAMPLE_RATE_BY_FSCOD[fscod] : Format.NO_VALUE;\n    sampleCount = AC3_SYNCFRAME_AUDIO_SAMPLE_COUNT;\n    lfeon = data.readBit();\n    channelCount = CHANNEL_COUNT_BY_ACMOD[acmod] + (lfeon ? 1 : 0);\n  }\n  return new SyncFrameInfo(\n      mimeType, streamType, channelCount, sampleRate, frameSize, sampleCount);\n}", "summary_tokens": ["returns", "e", "ac", "0", "format", "information", "given", "data", "containing", "a", "syncframe"], "project": "ExoPlayer"}
{"id": 1745, "code": "public int getLocalPort() {\n  if (socket == null) {\n    return UDP_PORT_UNSET;\n  }\n  return socket.getLocalPort();\n}", "summary_tokens": ["returns", "the", "local", "port", "number", "opened", "for", "the", "udp", "connection", "or", "udp", "port", "unset", "if", "no", "connection", "is", "open"], "project": "ExoPlayer"}
{"id": 434, "code": "public static <T extends Bundleable> SparseArray<Bundle> toBundleSparseArray(\n    SparseArray<T> bundleableSparseArray) {\n  SparseArray<Bundle> sparseArray = new SparseArray<>(bundleableSparseArray.size());\n  for (int i = 0; i < bundleableSparseArray.size(); i++) {\n    sparseArray.put(bundleableSparseArray.keyAt(i), bundleableSparseArray.valueAt(i).toBundle());\n  }\n  return sparseArray;\n}", "summary_tokens": ["converts", "a", "sparse", "array", "of", "bundleable", "to", "an", "sparse", "array", "of", "bundle", "so", "that", "the", "returned", "sparse", "array", "can", "be", "put", "to", "bundle", "using", "bundle", "put", "sparse", "parcelable", "array", "conveniently"], "project": "ExoPlayer"}
{"id": 1459, "code": "protected String getVideoString() {\n  Format format = player.getVideoFormat();\n  DecoderCounters decoderCounters = player.getVideoDecoderCounters();\n  if (format == null || decoderCounters == null) {\n    return \"\";\n  }\n  return \"\\n\"\n      + format.sampleMimeType\n      + \"(id:\"\n      + format.id\n      + \" r:\"\n      + format.width\n      + \"x\"\n      + format.height\n      + getPixelAspectRatioString(format.pixelWidthHeightRatio)\n      + getDecoderCountersBufferCountString(decoderCounters)\n      + \" vfpo: \"\n      + getVideoFrameProcessingOffsetAverageString(\n          decoderCounters.totalVideoFrameProcessingOffsetUs,\n          decoderCounters.videoFrameProcessingOffsetCount)\n      + \")\";\n}", "summary_tokens": ["returns", "a", "string", "containing", "video", "debugging", "information"], "project": "ExoPlayer"}
{"id": 130, "code": "public Uri build() {\n  checkState(\n      (TextUtils.isEmpty(assetKey)\n              && !TextUtils.isEmpty(contentSourceId)\n              && !TextUtils.isEmpty(videoId))\n          || (!TextUtils.isEmpty(assetKey)\n              && TextUtils.isEmpty(contentSourceId)\n              && TextUtils.isEmpty(videoId)));\n  checkState(format != C.CONTENT_TYPE_OTHER);\n  @Nullable String adsId = this.adsId;\n  if (adsId == null) {\n    adsId = assetKey != null ? assetKey : checkNotNull(videoId);\n  }\n  Uri.Builder dataUriBuilder = new Uri.Builder();\n  dataUriBuilder.scheme(C.SSAI_SCHEME);\n  dataUriBuilder.authority(IMA_AUTHORITY);\n  dataUriBuilder.appendQueryParameter(ADS_ID, adsId);\n  if (loadVideoTimeoutMs != DEFAULT_LOAD_VIDEO_TIMEOUT_MS) {\n    dataUriBuilder.appendQueryParameter(\n        LOAD_VIDEO_TIMEOUT_MS, String.valueOf(loadVideoTimeoutMs));\n  }\n  if (assetKey != null) {\n    dataUriBuilder.appendQueryParameter(ASSET_KEY, assetKey);\n  }\n  if (apiKey != null) {\n    dataUriBuilder.appendQueryParameter(API_KEY, apiKey);\n  }\n  if (contentSourceId != null) {\n    dataUriBuilder.appendQueryParameter(CONTENT_SOURCE_ID, contentSourceId);\n  }\n  if (videoId != null) {\n    dataUriBuilder.appendQueryParameter(VIDEO_ID, videoId);\n  }\n  if (manifestSuffix != null) {\n    dataUriBuilder.appendQueryParameter(MANIFEST_SUFFIX, manifestSuffix);\n  }\n  if (contentUrl != null) {\n    dataUriBuilder.appendQueryParameter(CONTENT_URL, contentUrl);\n  }\n  if (authToken != null) {\n    dataUriBuilder.appendQueryParameter(AUTH_TOKEN, authToken);\n  }\n  if (streamActivityMonitorId != null) {\n    dataUriBuilder.appendQueryParameter(STREAM_ACTIVITY_MONITOR_ID, streamActivityMonitorId);\n  }\n  if (!adTagParameters.isEmpty()) {\n    Uri.Builder adTagParametersUriBuilder = new Uri.Builder();\n    for (Map.Entry<String, String> entry : adTagParameters.entrySet()) {\n      adTagParametersUriBuilder.appendQueryParameter(entry.getKey(), entry.getValue());\n    }\n    dataUriBuilder.appendQueryParameter(\n        AD_TAG_PARAMETERS, adTagParametersUriBuilder.build().toString());\n  }\n  dataUriBuilder.appendQueryParameter(FORMAT, String.valueOf(format));\n  return dataUriBuilder.build();\n}", "summary_tokens": ["builds", "a", "uri", "with", "the", "builder", "s", "current", "values"], "project": "ExoPlayer"}
{"id": 1859, "code": "private static int readNon255TerminatedValue(ParsableByteArray buffer) {\n  int b;\n  int value = 0;\n  do {\n    if (buffer.bytesLeft() == 0) {\n      return -1;\n    }\n    b = buffer.readUnsignedByte();\n    value += b;\n  } while (b == 0xFF);\n  return value;\n}", "summary_tokens": ["reads", "a", "value", "from", "the", "provided", "buffer", "consisting", "of", "zero", "or", "more", "0", "x", "ff", "bytes", "followed", "by", "a", "terminating", "byte", "not", "equal", "to", "0", "x", "ff"], "project": "ExoPlayer"}
{"id": 1287, "code": "public void overridePreparePositionUs(long preparePositionUs) {\n  preparePositionOverrideUs = preparePositionUs;\n}", "summary_tokens": ["overrides", "the", "default", "prepare", "position", "at", "which", "to", "prepare", "the", "media", "period"], "project": "ExoPlayer"}
{"id": 792, "code": "public long getPositionMs() {\n  return positionMs;\n}", "summary_tokens": ["returns", "position", "in", "the", "media", "item", "at", "get", "media", "item", "index", "at", "which", "the", "message", "will", "be", "delivered", "in", "milliseconds"], "project": "ExoPlayer"}
{"id": 2289, "code": "public static ImmutableList<String> serializeRequest(RtspRequest request) {\n  checkArgument(request.headers.get(RtspHeaders.CSEQ) != null);\n\n  ImmutableList.Builder<String> builder = new ImmutableList.Builder<>();\n    \n  builder.add(\n      Util.formatInvariant(\n          \"%s %s %s\", toMethodString(request.method), request.uri, RTSP_VERSION));\n\n  ImmutableListMultimap<String, String> headers = request.headers.asMultiMap();\n  for (String headerName : headers.keySet()) {\n    ImmutableList<String> headerValuesForName = headers.get(headerName);\n    for (int i = 0; i < headerValuesForName.size(); i++) {\n      builder.add(Util.formatInvariant(\"%s: %s\", headerName, headerValuesForName.get(i)));\n    }\n  }\n    \n  builder.add(\"\");\n  builder.add(request.messageBody);\n  return builder.build();\n}", "summary_tokens": ["serializes", "an", "rtsp", "request", "to", "an", "immutable", "list", "of", "strings"], "project": "ExoPlayer"}
{"id": 1852, "code": "public static int getTypeForPcmEncoding(@C.PcmEncoding int pcmEncoding) {\n  switch (pcmEncoding) {\n    case C.ENCODING_PCM_8BIT:\n    case C.ENCODING_PCM_16BIT:\n    case C.ENCODING_PCM_24BIT:\n    case C.ENCODING_PCM_32BIT:\n      return TYPE_PCM;\n    case C.ENCODING_PCM_FLOAT:\n      return TYPE_FLOAT;\n    case C.ENCODING_PCM_16BIT_BIG_ENDIAN: \n    case C.ENCODING_INVALID:\n    case Format.NO_VALUE:\n    default:\n      throw new IllegalArgumentException();\n  }\n}", "summary_tokens": ["returns", "the", "wave", "format", "type", "value", "for", "the", "given", "c"], "project": "ExoPlayer"}
{"id": 2621, "code": "public void setControllerOnFullScreenModeChangedListener(\n    @Nullable StyledPlayerControlView.OnFullScreenModeChangedListener listener) {\n  Assertions.checkStateNotNull(controller);\n  this.fullscreenButtonClickListener = null;\n  controller.setOnFullScreenModeChangedListener(listener);\n}", "summary_tokens": ["sets", "the", "styled", "player", "control", "view"], "project": "ExoPlayer"}
{"id": 1451, "code": "public void addSample(int weight, float value) {\n  ensureSortedByIndex();\n\n  Sample newSample =\n      recycledSampleCount > 0 ? recycledSamples[--recycledSampleCount] : new Sample();\n  newSample.index = nextSampleIndex++;\n  newSample.weight = weight;\n  newSample.value = value;\n  samples.add(newSample);\n  totalWeight += weight;\n\n  while (totalWeight > maxWeight) {\n    int excessWeight = totalWeight - maxWeight;\n    Sample oldestSample = samples.get(0);\n    if (oldestSample.weight <= excessWeight) {\n      totalWeight -= oldestSample.weight;\n      samples.remove(0);\n      if (recycledSampleCount < MAX_RECYCLED_SAMPLES) {\n        recycledSamples[recycledSampleCount++] = oldestSample;\n      }\n    } else {\n      oldestSample.weight -= excessWeight;\n      totalWeight -= excessWeight;\n    }\n  }\n}", "summary_tokens": ["adds", "a", "new", "weighted", "value"], "project": "ExoPlayer"}
{"id": 880, "code": "default void onAudioCodecError(EventTime eventTime, Exception audioCodecError) {}", "summary_tokens": ["called", "when", "an", "audio", "decoder", "encounters", "an", "error"], "project": "ExoPlayer"}
{"id": 1001, "code": "protected void onFlush() {\n    \n}", "summary_tokens": ["called", "when", "the", "processor", "is", "flushed", "directly", "or", "as", "part", "of", "resetting"], "project": "ExoPlayer"}
{"id": 439, "code": "public static Pair<Integer, Integer> getVideoResolutionFromMpeg4VideoConfig(\n    byte[] videoSpecificConfig) {\n  int offset = 0;\n  boolean foundVOL = false;\n  ParsableByteArray scratchBytes = new ParsableByteArray(videoSpecificConfig);\n  while (offset + 3 < videoSpecificConfig.length) {\n    if (scratchBytes.readUnsignedInt24() != VISUAL_OBJECT_LAYER\n        || (videoSpecificConfig[offset + 3] & 0xF0) != VISUAL_OBJECT_LAYER_START) {\n      scratchBytes.setPosition(scratchBytes.getPosition() - 2);\n      offset++;\n      continue;\n    }\n    foundVOL = true;\n    break;\n  }\n\n  checkArgument(foundVOL, \"Invalid input: VOL not found.\");\n\n  ParsableBitArray scratchBits = new ParsableBitArray(videoSpecificConfig);\n    \n  scratchBits.skipBits((offset + 4) * 8);\n  scratchBits.skipBits(1); \n  scratchBits.skipBits(8); \n\n  if (scratchBits.readBit()) { \n    scratchBits.skipBits(4); \n    scratchBits.skipBits(3); \n  }\n\n  int aspectRatioInfo = scratchBits.readBits(4);\n  if (aspectRatioInfo == EXTENDED_PAR) {\n    scratchBits.skipBits(8); \n    scratchBits.skipBits(8); \n  }\n\n  if (scratchBits.readBit()) { \n    scratchBits.skipBits(2); \n    scratchBits.skipBits(1); \n    if (scratchBits.readBit()) { \n      scratchBits.skipBits(79);\n    }\n  }\n\n  int videoObjectLayerShape = scratchBits.readBits(2);\n  checkArgument(\n      videoObjectLayerShape == RECTANGULAR,\n      \"Only supports rectangular video object layer shape.\");\n\n  checkArgument(scratchBits.readBit()); \n  int vopTimeIncrementResolution = scratchBits.readBits(16);\n  checkArgument(scratchBits.readBit()); \n\n  if (scratchBits.readBit()) { \n    checkArgument(vopTimeIncrementResolution > 0);\n    vopTimeIncrementResolution--;\n    int numBitsToSkip = 0;\n    while (vopTimeIncrementResolution > 0) {\n      numBitsToSkip++;\n      vopTimeIncrementResolution >>= 1;\n    }\n    scratchBits.skipBits(numBitsToSkip); \n  }\n\n  checkArgument(scratchBits.readBit()); \n  int videoObjectLayerWidth = scratchBits.readBits(13);\n  checkArgument(scratchBits.readBit()); \n  int videoObjectLayerHeight = scratchBits.readBits(13);\n  checkArgument(scratchBits.readBit()); \n\n  scratchBits.skipBits(1); \n\n  return Pair.create(videoObjectLayerWidth, videoObjectLayerHeight);\n}", "summary_tokens": ["parses", "an", "mpeg", "0", "visual", "configuration", "information", "as", "defined", "in", "iso", "iec", "0", "0"], "project": "ExoPlayer"}
{"id": 2195, "code": "public void mp4SampleWithMdatTooLong() throws Exception {\n  ExtractorAsserts.assertBehavior(\n      Mp4Extractor::new, \"media/mp4/sample_mdat_too_long.mp4\", simulationConfig);\n}", "summary_tokens": ["test", "case", "for", "https", "github"], "project": "ExoPlayer"}
{"id": 866, "code": "default void onDecoderInitialized(\n    EventTime eventTime, int trackType, String decoderName, long initializationDurationMs) {}", "summary_tokens": ["use", "on", "audio", "decoder", "initialized", "and", "on", "video", "decoder", "initialized", "instead"], "project": "ExoPlayer"}
{"id": 1455, "code": "public final void start() {\n  if (started) {\n    return;\n  }\n  started = true;\n  player.addListener(updater);\n  updateAndPost();\n}", "summary_tokens": ["starts", "periodic", "updates", "of", "the", "text", "view"], "project": "ExoPlayer"}
{"id": 2447, "code": "private static Format createSefSlowMotionFormat(\n    int captureFrameRate, int inputMaxLayer, List<SlowMotionData.Segment> segments) {\n  SmtaMetadataEntry smtaMetadataEntry =\n      new SmtaMetadataEntry(captureFrameRate,  inputMaxLayer + 1);\n  SlowMotionData slowMotionData = new SlowMotionData(segments);\n  Metadata metadata = new Metadata(smtaMetadataEntry, slowMotionData);\n  return new Format.Builder()\n      .setSampleMimeType(MimeTypes.VIDEO_H264)\n      .setMetadata(metadata)\n      .build();\n}", "summary_tokens": ["creates", "a", "format", "for", "an", "sef", "slow", "motion", "video", "track"], "project": "ExoPlayer"}
{"id": 2750, "code": "public void append(List<FakeSampleStreamItem> items) {\n  sampleStreamItems.addAll(items);\n}", "summary_tokens": ["appends", "fake", "sample", "stream", "item", "fake", "sample", "stream", "items", "to", "the", "list", "of", "items", "that", "should", "be", "written", "to", "the", "queue"], "project": "ExoPlayer"}
{"id": 117, "code": "public void focusSkipButton() {\n  if (currentAdTagLoader != null) {\n    currentAdTagLoader.focusSkipButton();\n  }\n}", "summary_tokens": ["moves", "ui", "focus", "to", "the", "skip", "button", "or", "other", "interactive", "elements", "if", "currently", "shown"], "project": "ExoPlayer"}
{"id": 2470, "code": "public void addVisibilityListener(VisibilityListener listener) {\n  Assertions.checkNotNull(listener);\n  visibilityListeners.add(listener);\n}", "summary_tokens": ["adds", "a", "visibility", "listener"], "project": "ExoPlayer"}
{"id": 1249, "code": "public boolean isIdleRequired() {\n  return (requirements & DEVICE_IDLE) != 0;\n}", "summary_tokens": ["returns", "whether", "the", "device", "is", "required", "to", "be", "idle"], "project": "ExoPlayer"}
{"id": 847, "code": "default void onIsLoadingChanged(EventTime eventTime, boolean isLoading) {}", "summary_tokens": ["called", "when", "the", "player", "starts", "or", "stops", "loading", "data", "from", "a", "source"], "project": "ExoPlayer"}
{"id": 38, "code": "public void setVideoTextureView(@Nullable TextureView textureView) {}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "does", "nothing"], "project": "ExoPlayer"}
{"id": 827, "code": "public void setEnabled(boolean enabled) {\n  if (enabled) {\n    if (wakeLock == null) {\n      if (powerManager == null) {\n        Log.w(TAG, \"PowerManager is null, therefore not creating the WakeLock.\");\n        return;\n      }\n      wakeLock = powerManager.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, WAKE_LOCK_TAG);\n      wakeLock.setReferenceCounted(false);\n    }\n  }\n\n  this.enabled = enabled;\n  updateWakeLock();\n}", "summary_tokens": ["sets", "whether", "to", "enable", "the", "acquiring", "and", "releasing", "of", "the", "wake", "lock"], "project": "ExoPlayer"}
{"id": 937, "code": "public float getSeekTimeRatio() {\n  long playAndWaitTimeMs = getTotalPlayAndWaitTimeMs();\n  return playAndWaitTimeMs == 0 ? 0f : (float) getTotalSeekTimeMs() / playAndWaitTimeMs;\n}", "summary_tokens": ["returns", "the", "ratio", "of", "seek", "time", "to", "the", "total", "time", "spent", "playing", "and", "waiting", "or", "0"], "project": "ExoPlayer"}
{"id": 1329, "code": "public final int getFirstIndex() {\n  return absoluteFirstIndex;\n}", "summary_tokens": ["returns", "the", "current", "absolute", "start", "index"], "project": "ExoPlayer"}
{"id": 2757, "code": "public void release() {\n  sampleQueue.release();\n}", "summary_tokens": ["release", "the", "stream", "and", "its", "underlying", "sample", "queue"], "project": "ExoPlayer"}
{"id": 1572, "code": "private static byte[] encodeTxxxId3Frame(String description, String value) {\n  byte[] id3FrameData =\n      Bytes.concat(\n          \"TXXX\".getBytes(ISO_8859_1), \n          TestUtil.createByteArray(0, 0, 0, 0), \n          TestUtil.createByteArray(0, 0), \n          TestUtil.createByteArray(0), \n          description.getBytes(ISO_8859_1),\n          TestUtil.createByteArray(0), \n          value.getBytes(ISO_8859_1),\n          TestUtil.createByteArray(0)); \n  int frameSizeIndex = 7;\n  int frameSize = id3FrameData.length - 10;\n  Assertions.checkArgument(\n      frameSize < 128, \"frameSize must fit in 7 bits to avoid synch-safe encoding: \" + frameSize);\n  id3FrameData[frameSizeIndex] = (byte) frameSize;\n\n  byte[] id3Bytes =\n      Bytes.concat(\n          \"ID3\".getBytes(ISO_8859_1), \n          TestUtil.createByteArray(0x04, 0x00), \n          TestUtil.createByteArray(0), \n          TestUtil.createByteArray(0, 0, 0, 0), \n          id3FrameData);\n  int tagSizeIndex = 9;\n  int tagSize = id3Bytes.length - 10;\n  Assertions.checkArgument(\n      tagSize < 128, \"tagSize must fit in 7 bits to avoid synch-safe encoding: \" + tagSize);\n  id3Bytes[tagSizeIndex] = (byte) tagSize;\n  return id3Bytes;\n}", "summary_tokens": ["builds", "an", "id", "0", "v", "0", "tag", "containing", "a", "single", "user", "defined", "text", "information", "frame", "id", "txxx", "with", "description", "and", "value"], "project": "ExoPlayer"}
{"id": 845, "code": "default void onRepeatModeChanged(EventTime eventTime, @Player.RepeatMode int repeatMode) {}", "summary_tokens": ["called", "when", "the", "repeat", "mode", "changed"], "project": "ExoPlayer"}
{"id": 1821, "code": "protected void releaseOutputBuffer(O outputBuffer) {\n  synchronized (lock) {\n    releaseOutputBufferInternal(outputBuffer);\n    maybeNotifyDecodeLoop();\n  }\n}", "summary_tokens": ["releases", "an", "output", "buffer", "back", "to", "the", "decoder"], "project": "ExoPlayer"}
{"id": 1117, "code": "private static CodecProfileLevel[] estimateLegacyVp9ProfileLevels(\n    @Nullable CodecCapabilities capabilities) {\n  int maxBitrate = 0;\n  if (capabilities != null) {\n    @Nullable VideoCapabilities videoCapabilities = capabilities.getVideoCapabilities();\n    if (videoCapabilities != null) {\n      maxBitrate = videoCapabilities.getBitrateRange().getUpper();\n    }\n  }\n\n    \n  int level;\n  if (maxBitrate >= 180_000_000) {\n    level = CodecProfileLevel.VP9Level52;\n  } else if (maxBitrate >= 120_000_000) {\n    level = CodecProfileLevel.VP9Level51;\n  } else if (maxBitrate >= 60_000_000) {\n    level = CodecProfileLevel.VP9Level5;\n  } else if (maxBitrate >= 30_000_000) {\n    level = CodecProfileLevel.VP9Level41;\n  } else if (maxBitrate >= 18_000_000) {\n    level = CodecProfileLevel.VP9Level4;\n  } else if (maxBitrate >= 12_000_000) {\n    level = CodecProfileLevel.VP9Level31;\n  } else if (maxBitrate >= 7_200_000) {\n    level = CodecProfileLevel.VP9Level3;\n  } else if (maxBitrate >= 3_600_000) {\n    level = CodecProfileLevel.VP9Level21;\n  } else if (maxBitrate >= 1_800_000) {\n    level = CodecProfileLevel.VP9Level2;\n  } else if (maxBitrate >= 800_000) {\n    level = CodecProfileLevel.VP9Level11;\n  } else { \n    level = CodecProfileLevel.VP9Level1;\n  }\n\n  CodecProfileLevel profileLevel = new CodecProfileLevel();\n    \n  profileLevel.profile = CodecProfileLevel.VP9Profile0;\n  profileLevel.level = level;\n\n  return new CodecProfileLevel[] {profileLevel};\n}", "summary_tokens": ["called", "on", "devices", "with", "util", "sdk", "int", "0", "and", "below", "for", "vp", "0", "decoders", "whose", "codec", "capabilities", "do", "not", "correctly", "report", "profile", "levels"], "project": "ExoPlayer"}
{"id": 496, "code": "public static FloatBuffer createBuffer(int capacity) {\n  ByteBuffer byteBuffer = ByteBuffer.allocateDirect(capacity * C.BYTES_PER_FLOAT);\n  return byteBuffer.order(ByteOrder.nativeOrder()).asFloatBuffer();\n}", "summary_tokens": ["allocates", "a", "float", "buffer"], "project": "ExoPlayer"}
{"id": 1742, "code": "public long getBytesRead() {\n  return bytesRead;\n}", "summary_tokens": ["returns", "the", "total", "number", "of", "bytes", "that", "have", "been", "read", "from", "the", "data", "source"], "project": "ExoPlayer"}
{"id": 475, "code": "private static int getCStringLength(byte[] cString) {\n  for (int i = 0; i < cString.length; ++i) {\n    if (cString[i] == '\\0') {\n      return i;\n    }\n  }\n  return cString.length;\n}", "summary_tokens": ["returns", "the", "length", "of", "the", "null", "terminated", "c", "string", "in", "c", "string"], "project": "ExoPlayer"}
{"id": 205, "code": "public static String getVersion() {\n  return isAvailable() ? opusGetVersion() : null;\n}", "summary_tokens": ["returns", "the", "version", "of", "the", "underlying", "library", "if", "available", "or", "null", "otherwise"], "project": "ExoPlayer"}
{"id": 1961, "code": "private long readUint(ExtractorInput input) throws IOException {\n  input.peekFully(scratch.getData(), 0, 1);\n  int value = scratch.getData()[0] & 0xFF;\n  if (value == 0) {\n    return Long.MIN_VALUE;\n  }\n  int mask = 0x80;\n  int length = 0;\n  while ((value & mask) == 0) {\n    mask >>= 1;\n    length++;\n  }\n  value &= ~mask;\n  input.peekFully(scratch.getData(), 1, length);\n  for (int i = 0; i < length; i++) {\n    value <<= 8;\n    value += scratch.getData()[i + 1] & 0xFF;\n  }\n  peekLength += length + 1;\n  return value;\n}", "summary_tokens": ["peeks", "a", "variable", "length", "unsigned", "ebml", "integer", "from", "the", "input"], "project": "ExoPlayer"}
{"id": 2477, "code": "public int getShowTimeoutMs() {\n  return showTimeoutMs;\n}", "summary_tokens": ["returns", "the", "playback", "controls", "timeout"], "project": "ExoPlayer"}
{"id": 619, "code": "public static Uri removeQueryParameter(Uri uri, String queryParameterName) {\n  Uri.Builder builder = uri.buildUpon();\n  builder.clearQuery();\n  for (String key : uri.getQueryParameterNames()) {\n    if (!key.equals(queryParameterName)) {\n      for (String value : uri.getQueryParameters(key)) {\n        builder.appendQueryParameter(key, value);\n      }\n    }\n  }\n  return builder.build();\n}", "summary_tokens": ["removes", "query", "parameter", "from", "a", "uri", "if", "present"], "project": "ExoPlayer"}
{"id": 149, "code": "public void setPlayingContentPosition(int periodIndex, long positionMs) {\n  boolean notify = isPlayingAd;\n  PositionInfo oldPosition =\n      new PositionInfo(\n          windowUid,\n           0,\n          mediaItem,\n          periodUid,\n           0,\n          this.positionMs,\n          this.contentPositionMs,\n          this.adGroupIndex,\n          this.adIndexInAdGroup);\n  isPlayingAd = false;\n  adGroupIndex = C.INDEX_UNSET;\n  adIndexInAdGroup = C.INDEX_UNSET;\n  this.periodIndex = periodIndex;\n  this.positionMs = positionMs;\n  contentPositionMs = positionMs;\n  if (notify) {\n    PositionInfo newPosition =\n        new PositionInfo(\n            windowUid,\n             0,\n            mediaItem,\n            periodUid,\n             0,\n            positionMs,\n            this.contentPositionMs,\n            this.adGroupIndex,\n            this.adIndexInAdGroup);\n    listeners.sendEvent(\n        Player.EVENT_POSITION_DISCONTINUITY,\n        listener ->\n            listener.onPositionDiscontinuity(\n                oldPosition, newPosition, DISCONTINUITY_REASON_AUTO_TRANSITION));\n  }\n}", "summary_tokens": ["sets", "the", "state", "of", "this", "player", "as", "if", "it", "were", "playing", "content", "at", "the", "given", "position"], "project": "ExoPlayer"}
{"id": 1259, "code": "protected final MediaSourceEventListener.EventDispatcher createEventDispatcher(\n    int windowIndex, @Nullable MediaPeriodId mediaPeriodId, long mediaTimeOffsetMs) {\n  return eventDispatcher.withParameters(windowIndex, mediaPeriodId, mediaTimeOffsetMs);\n}", "summary_tokens": ["returns", "a", "media", "source", "event", "listener"], "project": "ExoPlayer"}
{"id": 1904, "code": "public int getDecodedBitrate() {\n  return bitsPerSample * sampleRate * channels;\n}", "summary_tokens": ["returns", "the", "bitrate", "of", "the", "stream", "after", "it", "s", "decoded", "into", "pcm"], "project": "ExoPlayer"}
{"id": 2842, "code": "public static void assertWindowEqualsExceptUidAndManifest(\n    Window expectedWindow, Window actualWindow) {\n  Object uid = expectedWindow.uid;\n  @Nullable Object manifest = expectedWindow.manifest;\n  try {\n    expectedWindow.uid = actualWindow.uid;\n    expectedWindow.manifest = actualWindow.manifest;\n    assertThat(actualWindow).isEqualTo(expectedWindow);\n  } finally {\n    expectedWindow.uid = uid;\n    expectedWindow.manifest = manifest;\n  }\n}", "summary_tokens": ["asserts", "that", "window", "windows", "are", "equal", "except", "window", "uid", "and", "window", "manifest"], "project": "ExoPlayer"}
{"id": 2396, "code": "public void setOutputSurface(\n    Surface outputSurface,\n    int outputWidth,\n    int outputHeight,\n    @Nullable SurfaceView debugSurfaceView) {\n    \n    \n    \n  this.outputSurface = outputSurface;\n  this.outputWidth = outputWidth;\n  this.outputHeight = outputHeight;\n\n  if (debugSurfaceView != null) {\n    debugSurfaceViewWrapper = new SurfaceViewWrapper(debugSurfaceView);\n  }\n\n  inputSurfaceTexture.setOnFrameAvailableListener(\n      surfaceTexture -> {\n        if (stopProcessing.get()) {\n            \n            \n          return;\n        }\n        try {\n          futures.add(singleThreadExecutorService.submit(this::processFrame));\n        } catch (RejectedExecutionException e) {\n          if (!stopProcessing.get()) {\n            throw e;\n          }\n        }\n      });\n}", "summary_tokens": ["sets", "the", "output", "surface"], "project": "ExoPlayer"}
{"id": 989, "code": "public boolean isStalled(long writtenFrames) {\n  return forceResetWorkaroundTimeMs != C.TIME_UNSET\n      && writtenFrames > 0\n      && SystemClock.elapsedRealtime() - forceResetWorkaroundTimeMs\n          >= FORCE_RESET_WORKAROUND_TIMEOUT_MS;\n}", "summary_tokens": ["returns", "whether", "the", "track", "is", "in", "an", "invalid", "state", "and", "must", "be", "recreated"], "project": "ExoPlayer"}
{"id": 2627, "code": "public void setShowShuffleButton(boolean showShuffleButton) {\n  Assertions.checkStateNotNull(controller);\n  controller.setShowShuffleButton(showShuffleButton);\n}", "summary_tokens": ["sets", "whether", "the", "shuffle", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 959, "code": " static Uri getExternalSurroundSoundGlobalSettingUri() {\n  return deviceMaySetExternalSurroundSoundGlobalSetting()\n      ? Global.getUriFor(EXTERNAL_SURROUND_SOUND_KEY)\n      : null;\n}", "summary_tokens": ["returns", "the", "global", "settings", "uri", "used", "by", "the", "device", "to", "specify", "external", "surround", "sound", "or", "null", "if", "the", "device", "does", "not", "support", "this", "functionality"], "project": "ExoPlayer"}
{"id": 2205, "code": "private static byte[] createByteArray(int... bytes) {\n  byte[] byteArray = new byte[bytes.length];\n  for (int i = 0; i < byteArray.length; i++) {\n    Assertions.checkState(0x00 <= bytes[i] && bytes[i] <= 0xFF);\n    byteArray[i] = (byte) bytes[i];\n  }\n  return byteArray;\n}", "summary_tokens": ["converts", "an", "array", "of", "integers", "in", "the", "range", "0", "0", "into", "an", "equivalent", "byte", "array"], "project": "ExoPlayer"}
{"id": 2405, "code": "default Size configure(int inputWidth, int inputHeight) {\n  return new Size(inputWidth, inputHeight);\n}", "summary_tokens": ["configures", "the", "input", "and", "output", "dimensions"], "project": "ExoPlayer"}
{"id": 1066, "code": "default DrmSessionReference preacquireSession(\n    @Nullable DrmSessionEventListener.EventDispatcher eventDispatcher, Format format) {\n  return DrmSessionReference.EMPTY;\n}", "summary_tokens": ["pre", "acquires", "a", "drm", "session", "for", "the", "specified", "format"], "project": "ExoPlayer"}
{"id": 2582, "code": "public void setAnimationEnabled(boolean animationEnabled) {\n  controlViewLayoutManager.setAnimationEnabled(animationEnabled);\n}", "summary_tokens": ["sets", "whether", "an", "animation", "is", "used", "to", "show", "and", "hide", "the", "playback", "controls"], "project": "ExoPlayer"}
{"id": 2272, "code": "public void retryWithRtpTcp() {\n  try {\n    close();\n    messageChannel = new RtspMessageChannel(new MessageListener());\n    messageChannel.open(getSocket(uri));\n    sessionId = null;\n    receivedAuthorizationRequest = false;\n    rtspAuthenticationInfo = null;\n  } catch (IOException e) {\n    playbackEventListener.onPlaybackError(new RtspPlaybackException(e));\n  }\n}", "summary_tokens": ["sets", "up", "a", "new", "playback", "session", "using", "tcp", "as", "rtp", "lower", "transport"], "project": "ExoPlayer"}
{"id": 2656, "code": "public static void removeEmbeddedFontSizes(Cue.Builder cue) {\n  cue.setTextSize(Cue.DIMEN_UNSET, Cue.TYPE_UNSET);\n  if (cue.getText() instanceof Spanned) {\n    if (!(cue.getText() instanceof Spannable)) {\n      cue.setText(SpannableString.valueOf(cue.getText()));\n    }\n    removeSpansIf(\n        (Spannable) checkNotNull(cue.getText()),\n        span -> span instanceof AbsoluteSizeSpan || span instanceof RelativeSizeSpan);\n  }\n}", "summary_tokens": ["removes", "all", "font", "size", "information", "from", "cue"], "project": "ExoPlayer"}
{"id": 1437, "code": "protected boolean isEligibleForFallback(IOException exception) {\n  if (!(exception instanceof InvalidResponseCodeException)) {\n    return false;\n  }\n  InvalidResponseCodeException invalidResponseCodeException =\n      (InvalidResponseCodeException) exception;\n  return invalidResponseCodeException.responseCode == 403 \n      || invalidResponseCodeException.responseCode == 404 \n      || invalidResponseCodeException.responseCode == 410 \n      || invalidResponseCodeException.responseCode == 416 \n      || invalidResponseCodeException.responseCode == 500 \n      || invalidResponseCodeException.responseCode == 503; \n}", "summary_tokens": ["returns", "whether", "an", "error", "should", "trigger", "a", "fallback", "if", "possible"], "project": "ExoPlayer"}
{"id": 1021, "code": "private static boolean codecNeedsDiscardChannelsWorkaround(String codecName) {\n    \n  return Util.SDK_INT < 24\n      && \"OMX.SEC.aac.dec\".equals(codecName)\n      && \"samsung\".equals(Util.MANUFACTURER)\n      && (Util.DEVICE.startsWith(\"zeroflte\")\n          || Util.DEVICE.startsWith(\"herolte\")\n          || Util.DEVICE.startsWith(\"heroqlte\"));\n}", "summary_tokens": ["returns", "whether", "the", "decoder", "is", "known", "to", "output", "six", "audio", "channels", "when", "provided", "with", "input", "with", "fewer", "than", "six", "channels"], "project": "ExoPlayer"}
{"id": 366, "code": "public static ParserException createForMalformedContainer(\n    @Nullable String message, @Nullable Throwable cause) {\n  return new ParserException(message, cause,  true, C.DATA_TYPE_MEDIA);\n}", "summary_tokens": ["creates", "a", "new", "instance", "for", "which", "content", "is", "malformed", "is", "true", "and", "data", "type", "is", "c", "data", "type", "media"], "project": "ExoPlayer"}
{"id": 640, "code": "public static Object getConcatenatedUid(Object childTimelineUid, Object childPeriodOrWindowUid) {\n  return Pair.create(childTimelineUid, childPeriodOrWindowUid);\n}", "summary_tokens": ["returns", "a", "concatenated", "uid", "for", "a", "period", "or", "window", "in", "a", "child", "timeline"], "project": "ExoPlayer"}
{"id": 1634, "code": "public void\n    selectTracks_audioChannelCountConstraintsDisabled_preferHigherNumChannelBeforeSampleRate()\n        throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format higherChannelLowerSampleRateFormat =\n      formatBuilder.setChannelCount(6).setSampleRate(22050).build();\n  Format lowerChannelHigherSampleRateFormat =\n      formatBuilder.setChannelCount(2).setSampleRate(44100).build();\n  TrackGroupArray trackGroups =\n      wrapFormats(higherChannelLowerSampleRateFormat, lowerChannelHigherSampleRateFormat);\n  trackSelector.setParameters(\n      trackSelector\n          .buildUponParameters()\n          .setConstrainAudioChannelCountToDeviceCapabilities(false)\n          .build());\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_SUPPORTED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, higherChannelLowerSampleRateFormat);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "prefer", "audio", "tracks", "with", "higher", "channel", "count", "over", "tracks", "with", "higher", "sample", "rate", "when", "audio", "channel", "count", "constraints", "are", "disabled", "other", "factors", "are", "the", "same", "and", "tracks", "are", "within", "renderer", "s", "capabilities"], "project": "ExoPlayer"}
{"id": 2119, "code": "private static void parseSubtitlingSegment(ParsableBitArray data, SubtitleService service) {\n  int segmentType = data.readBits(8);\n  int pageId = data.readBits(16);\n  int dataFieldLength = data.readBits(16);\n  int dataFieldLimit = data.getBytePosition() + dataFieldLength;\n\n  if ((dataFieldLength * 8) > data.bitsLeft()) {\n    Log.w(TAG, \"Data field length exceeds limit\");\n      \n    data.skipBits(data.bitsLeft());\n    return;\n  }\n\n  switch (segmentType) {\n    case SEGMENT_TYPE_DISPLAY_DEFINITION:\n      if (pageId == service.subtitlePageId) {\n        service.displayDefinition = parseDisplayDefinition(data);\n      }\n      break;\n    case SEGMENT_TYPE_PAGE_COMPOSITION:\n      if (pageId == service.subtitlePageId) {\n        @Nullable PageComposition current = service.pageComposition;\n        PageComposition pageComposition = parsePageComposition(data, dataFieldLength);\n        if (pageComposition.state != PAGE_STATE_NORMAL) {\n          service.pageComposition = pageComposition;\n          service.regions.clear();\n          service.cluts.clear();\n          service.objects.clear();\n        } else if (current != null && current.version != pageComposition.version) {\n          service.pageComposition = pageComposition;\n        }\n      }\n      break;\n    case SEGMENT_TYPE_REGION_COMPOSITION:\n      @Nullable PageComposition pageComposition = service.pageComposition;\n      if (pageId == service.subtitlePageId && pageComposition != null) {\n        RegionComposition regionComposition = parseRegionComposition(data, dataFieldLength);\n        if (pageComposition.state == PAGE_STATE_NORMAL) {\n          @Nullable\n          RegionComposition existingRegionComposition = service.regions.get(regionComposition.id);\n          if (existingRegionComposition != null) {\n            regionComposition.mergeFrom(existingRegionComposition);\n          }\n        }\n        service.regions.put(regionComposition.id, regionComposition);\n      }\n      break;\n    case SEGMENT_TYPE_CLUT_DEFINITION:\n      if (pageId == service.subtitlePageId) {\n        ClutDefinition clutDefinition = parseClutDefinition(data, dataFieldLength);\n        service.cluts.put(clutDefinition.id, clutDefinition);\n      } else if (pageId == service.ancillaryPageId) {\n        ClutDefinition clutDefinition = parseClutDefinition(data, dataFieldLength);\n        service.ancillaryCluts.put(clutDefinition.id, clutDefinition);\n      }\n      break;\n    case SEGMENT_TYPE_OBJECT_DATA:\n      if (pageId == service.subtitlePageId) {\n        ObjectData objectData = parseObjectData(data);\n        service.objects.put(objectData.id, objectData);\n      } else if (pageId == service.ancillaryPageId) {\n        ObjectData objectData = parseObjectData(data);\n        service.ancillaryObjects.put(objectData.id, objectData);\n      }\n      break;\n    default:\n        \n      break;\n  }\n\n    \n  data.skipBytes(dataFieldLimit - data.getBytePosition());\n}", "summary_tokens": ["parses", "a", "subtitling", "segment", "as", "defined", "by", "etsi", "en", "0", "0", "0"], "project": "ExoPlayer"}
{"id": 537, "code": " static Mp4aObjectType getObjectTypeFromMp4aRFC6381CodecString(String codec) {\n  Matcher matcher = MP4A_RFC_6381_CODEC_PATTERN.matcher(codec);\n  if (!matcher.matches()) {\n    return null;\n  }\n  String objectTypeIndicationHex = Assertions.checkNotNull(matcher.group(1));\n  @Nullable String audioObjectTypeIndicationDec = matcher.group(2);\n  int objectTypeIndication;\n  int audioObjectTypeIndication = 0;\n  try {\n    objectTypeIndication = Integer.parseInt(objectTypeIndicationHex, 16);\n    if (audioObjectTypeIndicationDec != null) {\n      audioObjectTypeIndication = Integer.parseInt(audioObjectTypeIndicationDec);\n    }\n  } catch (NumberFormatException e) {\n    return null;\n  }\n  return new Mp4aObjectType(objectTypeIndication, audioObjectTypeIndication);\n}", "summary_tokens": ["returns", "the", "mp", "0", "a", "object", "type", "of", "an", "rfc", "0", "mp", "0", "audio", "codec", "string"], "project": "ExoPlayer"}
{"id": 220, "code": "public final boolean hasNextWindow() {\n  return hasNextMediaItem();\n}", "summary_tokens": ["use", "has", "next", "media", "item", "instead"], "project": "ExoPlayer"}
{"id": 733, "code": "public MediaPeriodHolder enqueueNextMediaPeriodHolder(\n    RendererCapabilities[] rendererCapabilities,\n    TrackSelector trackSelector,\n    Allocator allocator,\n    MediaSourceList mediaSourceList,\n    MediaPeriodInfo info,\n    TrackSelectorResult emptyTrackSelectorResult) {\n  long rendererPositionOffsetUs =\n      loading == null\n          ? INITIAL_RENDERER_POSITION_OFFSET_US\n          : (loading.getRendererOffset() + loading.info.durationUs - info.startPositionUs);\n  MediaPeriodHolder newPeriodHolder =\n      new MediaPeriodHolder(\n          rendererCapabilities,\n          rendererPositionOffsetUs,\n          trackSelector,\n          allocator,\n          mediaSourceList,\n          info,\n          emptyTrackSelectorResult);\n  if (loading != null) {\n    loading.setNext(newPeriodHolder);\n  } else {\n    playing = newPeriodHolder;\n    reading = newPeriodHolder;\n  }\n  oldFrontPeriodUid = null;\n  loading = newPeriodHolder;\n  length++;\n  notifyQueueUpdate();\n  return newPeriodHolder;\n}", "summary_tokens": ["enqueues", "a", "new", "media", "period", "holder", "based", "on", "the", "specified", "information", "as", "the", "new", "loading", "media", "period", "and", "returns", "it"], "project": "ExoPlayer"}
{"id": 2641, "code": "public void draw(\n    Cue cue,\n    CaptionStyleCompat style,\n    float defaultTextSizePx,\n    float cueTextSizePx,\n    float bottomPaddingFraction,\n    Canvas canvas,\n    int cueBoxLeft,\n    int cueBoxTop,\n    int cueBoxRight,\n    int cueBoxBottom) {\n  boolean isTextCue = cue.bitmap == null;\n  int windowColor = Color.BLACK;\n  if (isTextCue) {\n    if (TextUtils.isEmpty(cue.text)) {\n        \n      return;\n    }\n    windowColor = cue.windowColorSet ? cue.windowColor : style.windowColor;\n  }\n  if (areCharSequencesEqual(this.cueText, cue.text)\n      && Util.areEqual(this.cueTextAlignment, cue.textAlignment)\n      && this.cueBitmap == cue.bitmap\n      && this.cueLine == cue.line\n      && this.cueLineType == cue.lineType\n      && Util.areEqual(this.cueLineAnchor, cue.lineAnchor)\n      && this.cuePosition == cue.position\n      && Util.areEqual(this.cuePositionAnchor, cue.positionAnchor)\n      && this.cueSize == cue.size\n      && this.cueBitmapHeight == cue.bitmapHeight\n      && this.foregroundColor == style.foregroundColor\n      && this.backgroundColor == style.backgroundColor\n      && this.windowColor == windowColor\n      && this.edgeType == style.edgeType\n      && this.edgeColor == style.edgeColor\n      && Util.areEqual(this.textPaint.getTypeface(), style.typeface)\n      && this.defaultTextSizePx == defaultTextSizePx\n      && this.cueTextSizePx == cueTextSizePx\n      && this.bottomPaddingFraction == bottomPaddingFraction\n      && this.parentLeft == cueBoxLeft\n      && this.parentTop == cueBoxTop\n      && this.parentRight == cueBoxRight\n      && this.parentBottom == cueBoxBottom) {\n      \n    drawLayout(canvas, isTextCue);\n    return;\n  }\n\n  this.cueText = cue.text;\n  this.cueTextAlignment = cue.textAlignment;\n  this.cueBitmap = cue.bitmap;\n  this.cueLine = cue.line;\n  this.cueLineType = cue.lineType;\n  this.cueLineAnchor = cue.lineAnchor;\n  this.cuePosition = cue.position;\n  this.cuePositionAnchor = cue.positionAnchor;\n  this.cueSize = cue.size;\n  this.cueBitmapHeight = cue.bitmapHeight;\n  this.foregroundColor = style.foregroundColor;\n  this.backgroundColor = style.backgroundColor;\n  this.windowColor = windowColor;\n  this.edgeType = style.edgeType;\n  this.edgeColor = style.edgeColor;\n  this.textPaint.setTypeface(style.typeface);\n  this.defaultTextSizePx = defaultTextSizePx;\n  this.cueTextSizePx = cueTextSizePx;\n  this.bottomPaddingFraction = bottomPaddingFraction;\n  this.parentLeft = cueBoxLeft;\n  this.parentTop = cueBoxTop;\n  this.parentRight = cueBoxRight;\n  this.parentBottom = cueBoxBottom;\n\n  if (isTextCue) {\n    Assertions.checkNotNull(cueText);\n    setupTextLayout();\n  } else {\n    Assertions.checkNotNull(cueBitmap);\n    setupBitmapLayout();\n  }\n  drawLayout(canvas, isTextCue);\n}", "summary_tokens": ["draws", "the", "provided", "cue", "into", "a", "canvas", "with", "the", "specified", "styling"], "project": "ExoPlayer"}
{"id": 1488, "code": "public long getFrameDurationNs() {\n  return isSynced() ? currentMatcher.getFrameDurationNs() : C.TIME_UNSET;\n}", "summary_tokens": ["the", "currently", "detected", "fixed", "frame", "duration", "estimate", "in", "nanoseconds", "or", "c", "time", "unset", "if", "is", "synced", "is", "false"], "project": "ExoPlayer"}
{"id": 1464, "code": "public static void setNtpHost(String ntpHost) {\n  synchronized (valueLock) {\n    if (!SntpClient.ntpHost.equals(ntpHost)) {\n      SntpClient.ntpHost = ntpHost;\n      isInitialized = false;\n    }\n  }\n}", "summary_tokens": ["sets", "the", "ntp", "host", "address", "used", "to", "retrieve", "get", "elapsed", "realtime", "offset", "ms"], "project": "ExoPlayer"}
{"id": 1135, "code": "protected void onCodecReleased(String name) {\n    \n}", "summary_tokens": ["called", "when", "a", "media", "codec", "has", "been", "released"], "project": "ExoPlayer"}
{"id": 2307, "code": "public static RtspSessionTiming parseTiming(String sdpRangeAttribute) throws ParserException {\n  long startTimeMs;\n  long stopTimeMs;\n  Matcher matcher = NPT_RANGE_PATTERN.matcher(sdpRangeAttribute);\n  checkManifestExpression(matcher.matches(),  sdpRangeAttribute);\n\n  @Nullable String startTimeString = matcher.group(1);\n  checkManifestExpression(startTimeString != null,  sdpRangeAttribute);\n  if (castNonNull(startTimeString).equals(\"now\")) {\n    startTimeMs = LIVE_START_TIME;\n  } else {\n    startTimeMs = (long) (Float.parseFloat(startTimeString) * C.MILLIS_PER_SECOND);\n  }\n\n  @Nullable String stopTimeString = matcher.group(2);\n  if (stopTimeString != null) {\n    try {\n      stopTimeMs = (long) (Float.parseFloat(stopTimeString) * C.MILLIS_PER_SECOND);\n    } catch (NumberFormatException e) {\n      throw ParserException.createForMalformedManifest(stopTimeString, e);\n    }\n    checkManifestExpression(stopTimeMs >= startTimeMs,  sdpRangeAttribute);\n  } else {\n    stopTimeMs = C.TIME_UNSET;\n  }\n\n  return new RtspSessionTiming(startTimeMs, stopTimeMs);\n}", "summary_tokens": ["parses", "an", "sdp", "range", "attribute", "rfc", "0", "section", "0"], "project": "ExoPlayer"}
{"id": 714, "code": "public long applyTrackSelection(\n    TrackSelectorResult newTrackSelectorResult,\n    long positionUs,\n    boolean forceRecreateStreams,\n    boolean[] streamResetFlags) {\n  for (int i = 0; i < newTrackSelectorResult.length; i++) {\n    mayRetainStreamFlags[i] =\n        !forceRecreateStreams && newTrackSelectorResult.isEquivalent(trackSelectorResult, i);\n  }\n\n    \n    \n  disassociateNoSampleRenderersWithEmptySampleStream(sampleStreams);\n  disableTrackSelectionsInResult();\n  trackSelectorResult = newTrackSelectorResult;\n  enableTrackSelectionsInResult();\n    \n  positionUs =\n      mediaPeriod.selectTracks(\n          newTrackSelectorResult.selections,\n          mayRetainStreamFlags,\n          sampleStreams,\n          streamResetFlags,\n          positionUs);\n  associateNoSampleRenderersWithEmptySampleStream(sampleStreams);\n\n    \n  hasEnabledTracks = false;\n  for (int i = 0; i < sampleStreams.length; i++) {\n    if (sampleStreams[i] != null) {\n      Assertions.checkState(newTrackSelectorResult.isRendererEnabled(i));\n        \n      if (rendererCapabilities[i].getTrackType() != C.TRACK_TYPE_NONE) {\n        hasEnabledTracks = true;\n      }\n    } else {\n      Assertions.checkState(newTrackSelectorResult.selections[i] == null);\n    }\n  }\n  return positionUs;\n}", "summary_tokens": ["applies", "a", "track", "selector", "result", "to", "the", "period"], "project": "ExoPlayer"}
{"id": 1785, "code": "private void loadDirectory(\n    File directory,\n    boolean isRoot,\n    @Nullable File[] files,\n    @Nullable Map<String, CacheFileMetadata> fileMetadata) {\n  if (files == null || files.length == 0) {\n      \n    if (!isRoot) {\n        \n        \n      directory.delete();\n    }\n    return;\n  }\n  for (File file : files) {\n    String fileName = file.getName();\n    if (isRoot && fileName.indexOf('.') == -1) {\n      loadDirectory(file,  false, file.listFiles(), fileMetadata);\n    } else {\n      if (isRoot\n          && (CachedContentIndex.isIndexFile(fileName) || fileName.endsWith(UID_FILE_SUFFIX))) {\n          \n        continue;\n      }\n      long length = C.LENGTH_UNSET;\n      long lastTouchTimestamp = C.TIME_UNSET;\n      @Nullable\n      CacheFileMetadata metadata = fileMetadata != null ? fileMetadata.remove(fileName) : null;\n      if (metadata != null) {\n        length = metadata.length;\n        lastTouchTimestamp = metadata.lastTouchTimestamp;\n      }\n      @Nullable\n      SimpleCacheSpan span =\n          SimpleCacheSpan.createCacheEntry(file, length, lastTouchTimestamp, contentIndex);\n      if (span != null) {\n        addSpan(span);\n      } else {\n        file.delete();\n      }\n    }\n  }\n}", "summary_tokens": ["loads", "a", "cache", "directory"], "project": "ExoPlayer"}
{"id": 2001, "code": "public static byte[] buildPsshAtom(\n    UUID systemId, @Nullable UUID[] keyIds, @Nullable byte[] data) {\n  int dataLength = data != null ? data.length : 0;\n  int psshBoxLength = Atom.FULL_HEADER_SIZE + 16  + 4  + dataLength;\n  if (keyIds != null) {\n    psshBoxLength += 4  + (keyIds.length * 16) ;\n  }\n  ByteBuffer psshBox = ByteBuffer.allocate(psshBoxLength);\n  psshBox.putInt(psshBoxLength);\n  psshBox.putInt(Atom.TYPE_pssh);\n  psshBox.putInt(keyIds != null ? 0x01000000 : 0 );\n  psshBox.putLong(systemId.getMostSignificantBits());\n  psshBox.putLong(systemId.getLeastSignificantBits());\n  if (keyIds != null) {\n    psshBox.putInt(keyIds.length);\n    for (UUID keyId : keyIds) {\n      psshBox.putLong(keyId.getMostSignificantBits());\n      psshBox.putLong(keyId.getLeastSignificantBits());\n    }\n  }\n  if (data != null && data.length != 0) {\n    psshBox.putInt(data.length);\n    psshBox.put(data);\n  } \n  return psshBox.array();\n}", "summary_tokens": ["builds", "a", "pssh", "atom", "for", "the", "given", "system", "id", "containing", "the", "given", "key", "ids", "and", "data"], "project": "ExoPlayer"}
{"id": 2058, "code": "private void readSample(ParsableByteArray data) {\n  int bytesToRead = min(data.bytesLeft(), sampleSize - bytesRead);\n  currentOutput.sampleData(data, bytesToRead);\n  bytesRead += bytesToRead;\n  if (bytesRead == sampleSize) {\n    if (timeUs != C.TIME_UNSET) {\n      currentOutput.sampleMetadata(timeUs, C.BUFFER_FLAG_KEY_FRAME, sampleSize, 0, null);\n      timeUs += currentSampleDuration;\n    }\n    setFindingSampleState();\n  }\n}", "summary_tokens": ["reads", "the", "rest", "of", "the", "sample"], "project": "ExoPlayer"}
{"id": 884, "code": "default void onVideoEnabled(EventTime eventTime, DecoderCounters decoderCounters) {}", "summary_tokens": ["called", "when", "a", "video", "renderer", "is", "enabled"], "project": "ExoPlayer"}
{"id": 2702, "code": "public ExoPlayerTestRunner start(boolean doPrepare) {\n  handler.post(\n      () -> {\n        try {\n          player = playerBuilder.setLooper(Looper.myLooper()).build();\n          if (surface != null) {\n            player.setVideoSurface(surface);\n          }\n          if (pauseAtEndOfMediaItems) {\n            player.setPauseAtEndOfMediaItems(true);\n          }\n          player.addListener(ExoPlayerTestRunner.this);\n          if (playerListener != null) {\n            player.addListener(playerListener);\n          }\n          if (analyticsListener != null) {\n            player.addAnalyticsListener(analyticsListener);\n          }\n          player.play();\n          if (actionSchedule != null) {\n            actionSchedule.start(\n                player,\n                playerBuilder.getTrackSelector(),\n                surface,\n                handler,\n                 ExoPlayerTestRunner.this);\n          }\n          if (initialMediaItemIndex != C.INDEX_UNSET) {\n            player.seekTo(initialMediaItemIndex, initialPositionMs);\n          }\n          if (!skipSettingMediaSources) {\n            player.setMediaSources(mediaSources,  false);\n          }\n          if (doPrepare) {\n            player.prepare();\n          }\n        } catch (Exception e) {\n          handleException(e);\n        }\n      });\n  return this;\n}", "summary_tokens": ["starts", "the", "test", "runner", "on", "its", "own", "thread"], "project": "ExoPlayer"}
{"id": 481, "code": "public static EGLDisplay createEglDisplay() {\n  return Api17.createEglDisplay();\n}", "summary_tokens": ["returns", "an", "initialized", "default", "egldisplay"], "project": "ExoPlayer"}
{"id": 740, "code": "public boolean updateQueuedPeriods(\n    Timeline timeline, long rendererPositionUs, long maxRendererReadPositionUs) {\n    \n    \n    \n  MediaPeriodHolder previousPeriodHolder = null;\n  MediaPeriodHolder periodHolder = playing;\n  while (periodHolder != null) {\n    MediaPeriodInfo oldPeriodInfo = periodHolder.info;\n\n      \n    MediaPeriodInfo newPeriodInfo;\n    if (previousPeriodHolder == null) {\n        \n        \n        \n      newPeriodInfo = getUpdatedMediaPeriodInfo(timeline, oldPeriodInfo);\n    } else {\n      newPeriodInfo =\n          getFollowingMediaPeriodInfo(timeline, previousPeriodHolder, rendererPositionUs);\n      if (newPeriodInfo == null) {\n          \n        return !removeAfter(previousPeriodHolder);\n      }\n      if (!canKeepMediaPeriodHolder(oldPeriodInfo, newPeriodInfo)) {\n          \n        return !removeAfter(previousPeriodHolder);\n      }\n    }\n\n      \n      \n    periodHolder.info =\n        newPeriodInfo.copyWithRequestedContentPositionUs(\n            oldPeriodInfo.requestedContentPositionUs);\n\n    if (!areDurationsCompatible(oldPeriodInfo.durationUs, newPeriodInfo.durationUs)) {\n        \n        \n      periodHolder.updateClipping();\n      long newDurationInRendererTime =\n          newPeriodInfo.durationUs == C.TIME_UNSET\n              ? Long.MAX_VALUE\n              : periodHolder.toRendererTime(newPeriodInfo.durationUs);\n      boolean isReadingAndReadBeyondNewDuration =\n          periodHolder == reading\n              && !periodHolder.info.isFollowedByTransitionToSameStream\n              && (maxRendererReadPositionUs == C.TIME_END_OF_SOURCE\n                  || maxRendererReadPositionUs >= newDurationInRendererTime);\n      boolean readingPeriodRemoved = removeAfter(periodHolder);\n      return !readingPeriodRemoved && !isReadingAndReadBeyondNewDuration;\n    }\n\n    previousPeriodHolder = periodHolder;\n    periodHolder = periodHolder.getNext();\n  }\n  return true;\n}", "summary_tokens": ["updates", "media", "periods", "in", "the", "queue", "to", "take", "into", "account", "the", "latest", "timeline", "and", "returns", "whether", "the", "timeline", "change", "has", "been", "fully", "handled"], "project": "ExoPlayer"}
{"id": 165, "code": "public static boolean getExoPlayerShuffleMode(int shuffleMode) {\n  switch (shuffleMode) {\n    case SessionPlayer.SHUFFLE_MODE_ALL:\n    case SessionPlayer.SHUFFLE_MODE_GROUP:\n      return true;\n    case SessionPlayer.SHUFFLE_MODE_NONE:\n      return false;\n    default:\n      throw new IllegalArgumentException();\n  }\n}", "summary_tokens": ["returns", "the", "simple", "exo", "player", "s", "shuffle", "mode", "for", "the", "given", "shuffle", "mode"], "project": "ExoPlayer"}
{"id": 695, "code": "private MediaMetadata buildUpdatedMediaMetadata() {\n  Timeline timeline = getCurrentTimeline();\n  if (timeline.isEmpty()) {\n    return staticAndDynamicMediaMetadata;\n  }\n  MediaItem mediaItem = timeline.getWindow(getCurrentMediaItemIndex(), window).mediaItem;\n    \n  return staticAndDynamicMediaMetadata.buildUpon().populate(mediaItem.mediaMetadata).build();\n}", "summary_tokens": ["builds", "a", "media", "metadata", "from", "the", "main", "sources"], "project": "ExoPlayer"}
{"id": 1951, "code": "private static HashMap<String, Object> readAmfEcmaArray(ParsableByteArray data) {\n  int count = data.readUnsignedIntToInt();\n  HashMap<String, Object> array = new HashMap<>(count);\n  for (int i = 0; i < count; i++) {\n    String key = readAmfString(data);\n    int type = readAmfType(data);\n    Object value = readAmfData(data, type);\n    if (value != null) {\n      array.put(key, value);\n    }\n  }\n  return array;\n}", "summary_tokens": ["read", "an", "ecma", "array", "from", "an", "amf", "encoded", "buffer"], "project": "ExoPlayer"}
{"id": 887, "code": "default void onDroppedVideoFrames(EventTime eventTime, int droppedFrames, long elapsedMs) {}", "summary_tokens": ["called", "after", "video", "frames", "have", "been", "dropped"], "project": "ExoPlayer"}
{"id": 753, "code": "public Timeline moveMediaSource(int currentIndex, int newIndex, ShuffleOrder shuffleOrder) {\n  return moveMediaSourceRange(currentIndex, currentIndex + 1, newIndex, shuffleOrder);\n}", "summary_tokens": ["moves", "an", "existing", "media", "source", "within", "the", "playlist"], "project": "ExoPlayer"}
{"id": 1733, "code": "private void skipFully(long bytesToSkip, DataSpec dataSpec) throws IOException {\n  if (bytesToSkip == 0) {\n    return;\n  }\n  byte[] skipBuffer = new byte[4096];\n  while (bytesToSkip > 0) {\n    int readLength = (int) min(bytesToSkip, skipBuffer.length);\n    int read = castNonNull(inputStream).read(skipBuffer, 0, readLength);\n    if (Thread.currentThread().isInterrupted()) {\n      throw new HttpDataSourceException(\n          new InterruptedIOException(),\n          dataSpec,\n          PlaybackException.ERROR_CODE_IO_UNSPECIFIED,\n          HttpDataSourceException.TYPE_OPEN);\n    }\n    if (read == -1) {\n      throw new HttpDataSourceException(\n          dataSpec,\n          PlaybackException.ERROR_CODE_IO_READ_POSITION_OUT_OF_RANGE,\n          HttpDataSourceException.TYPE_OPEN);\n    }\n    bytesToSkip -= read;\n    bytesTransferred(read);\n  }\n}", "summary_tokens": ["attempts", "to", "skip", "the", "specified", "number", "of", "bytes", "in", "full"], "project": "ExoPlayer"}
{"id": 1597, "code": "private void assertReadFormat(boolean formatRequired, Format format) {\n  clearFormatHolderAndInputBuffer();\n  int result =\n      sampleQueue.read(\n          formatHolder,\n          inputBuffer,\n          formatRequired ? SampleStream.FLAG_REQUIRE_FORMAT : 0,\n           false);\n  assertThat(result).isEqualTo(RESULT_FORMAT_READ);\n    \n  assertThat(formatHolder.format).isEqualTo(format);\n    \n  assertInputBufferContainsNoSampleData();\n  assertInputBufferHasNoDefaultFlagsSet();\n}", "summary_tokens": ["asserts", "sample", "queue", "read", "returns", "c", "result", "format", "read", "and", "that", "the", "format", "holder", "is", "filled", "with", "a", "format", "that", "equals", "format"], "project": "ExoPlayer"}
{"id": 1132, "code": "private void initBypass(Format format) {\n  disableBypass(); \n\n  String mimeType = format.sampleMimeType;\n  if (!MimeTypes.AUDIO_AAC.equals(mimeType)\n      && !MimeTypes.AUDIO_MPEG.equals(mimeType)\n      && !MimeTypes.AUDIO_OPUS.equals(mimeType)) {\n      \n    bypassBatchBuffer.setMaxSampleCount(1);\n  } else {\n    bypassBatchBuffer.setMaxSampleCount(BatchBuffer.DEFAULT_MAX_SAMPLE_COUNT);\n  }\n  bypassEnabled = true;\n}", "summary_tokens": ["configures", "rendering", "where", "no", "codec", "is", "used"], "project": "ExoPlayer"}
{"id": 89, "code": "public void decodeSample(ByteBuffer output) throws IOException, FlacFrameDecodeException {\n  output.clear();\n  int frameSize =\n      output.isDirect()\n          ? flacDecodeToBuffer(nativeDecoderContext, output)\n          : flacDecodeToArray(nativeDecoderContext, output.array());\n  if (frameSize < 0) {\n    if (!isDecoderAtEndOfInput()) {\n      throw new FlacFrameDecodeException(\"Cannot decode FLAC frame\", frameSize);\n    }\n      \n    output.limit(0);\n  } else {\n    output.limit(frameSize);\n  }\n}", "summary_tokens": ["decodes", "and", "consumes", "the", "next", "sample", "from", "the", "flac", "stream", "into", "the", "given", "byte", "buffer"], "project": "ExoPlayer"}
{"id": 2665, "code": "public TrackSelectionDialogBuilder setTrackNameProvider(\n    @Nullable TrackNameProvider trackNameProvider) {\n  this.trackNameProvider = trackNameProvider;\n  return this;\n}", "summary_tokens": ["sets", "the", "track", "name", "provider", "used", "to", "generate", "the", "user", "visible", "name", "of", "each", "track", "and", "updates", "the", "view", "with", "track", "names", "queried", "from", "the", "specified", "provider"], "project": "ExoPlayer"}
{"id": 891, "code": "default void onVideoCodecError(EventTime eventTime, Exception videoCodecError) {}", "summary_tokens": ["called", "when", "a", "video", "decoder", "encounters", "an", "error"], "project": "ExoPlayer"}
{"id": 782, "code": "public PlaybackInfo copyWithSleepingForOffload(boolean sleepingForOffload) {\n  return new PlaybackInfo(\n      timeline,\n      periodId,\n      requestedContentPositionUs,\n      discontinuityStartPositionUs,\n      playbackState,\n      playbackError,\n      isLoading,\n      trackGroups,\n      trackSelectorResult,\n      staticMetadata,\n      loadingMediaPeriodId,\n      playWhenReady,\n      playbackSuppressionReason,\n      playbackParameters,\n      bufferedPositionUs,\n      totalBufferedDurationUs,\n      positionUs,\n      sleepingForOffload);\n}", "summary_tokens": ["copies", "playback", "info", "with", "new", "sleeping", "for", "offload"], "project": "ExoPlayer"}
{"id": 1144, "code": "protected float getPlaybackSpeed() {\n  return currentPlaybackSpeed;\n}", "summary_tokens": ["returns", "the", "current", "playback", "speed", "as", "set", "by", "set", "playback", "speed"], "project": "ExoPlayer"}
{"id": 1260, "code": "protected final DrmSessionEventListener.EventDispatcher createDrmEventDispatcher(\n    int windowIndex, @Nullable MediaPeriodId mediaPeriodId) {\n  return drmEventDispatcher.withParameters(windowIndex, mediaPeriodId);\n}", "summary_tokens": ["returns", "a", "drm", "session", "event", "listener"], "project": "ExoPlayer"}
{"id": 1140, "code": "protected void onQueueInputBuffer(DecoderInputBuffer buffer) throws ExoPlaybackException {\n    \n}", "summary_tokens": ["called", "immediately", "before", "an", "input", "buffer", "is", "queued", "into", "the", "codec"], "project": "ExoPlayer"}
{"id": 1302, "code": "private boolean configureRetry(ExtractingLoadable loadable, int currentExtractedSampleCount) {\n  if (isLengthKnown || (seekMap != null && seekMap.getDurationUs() != C.TIME_UNSET)) {\n      \n      \n    extractedSamplesCountAtStartOfLoad = currentExtractedSampleCount;\n    return true;\n  } else if (prepared && !suppressRead()) {\n      \n      \n      \n      \n      \n      \n      \n      \n      \n    pendingDeferredRetry = true;\n    return false;\n  } else {\n      \n      \n      \n      \n    notifyDiscontinuity = prepared;\n    lastSeekPositionUs = 0;\n    extractedSamplesCountAtStartOfLoad = 0;\n    for (SampleQueue sampleQueue : sampleQueues) {\n      sampleQueue.reset();\n    }\n    loadable.setLoadPosition(0, 0);\n    return true;\n  }\n}", "summary_tokens": ["called", "to", "configure", "a", "retry", "when", "a", "load", "error", "occurs"], "project": "ExoPlayer"}
{"id": 1429, "code": "default long getTimeToFirstByteEstimateUs() {\n  return C.TIME_UNSET;\n}", "summary_tokens": ["returns", "the", "estimated", "time", "to", "first", "byte", "in", "microseconds", "or", "c", "time", "unset", "if", "no", "estimate", "is", "available"], "project": "ExoPlayer"}
{"id": 1131, "code": "private boolean readSourceOmittingSampleData(@SampleStream.ReadFlags int readFlags)\n    throws ExoPlaybackException {\n  FormatHolder formatHolder = getFormatHolder();\n  noDataBuffer.clear();\n  @ReadDataResult\n  int result = readSource(formatHolder, noDataBuffer, readFlags | FLAG_OMIT_SAMPLE_DATA);\n  if (result == C.RESULT_FORMAT_READ) {\n    onInputFormatChanged(formatHolder);\n    return true;\n  } else if (result == C.RESULT_BUFFER_READ && noDataBuffer.isEndOfStream()) {\n    inputStreamEnded = true;\n    processEndOfStream();\n  }\n  return false;\n}", "summary_tokens": ["reads", "from", "the", "source", "when", "sample", "data", "is", "not", "required"], "project": "ExoPlayer"}
{"id": 2436, "code": "public final @Capabilities int supportsFormat(Format format) {\n  return RendererCapabilities.create(\n      MimeTypes.getTrackType(format.sampleMimeType) == getTrackType()\n          ? C.FORMAT_HANDLED\n          : C.FORMAT_UNSUPPORTED_TYPE);\n}", "summary_tokens": ["returns", "whether", "the", "renderer", "supports", "the", "track", "type", "of", "the", "given", "format"], "project": "ExoPlayer"}
{"id": 520, "code": "public static void registerCustomMimeType(\n    String mimeType, String codecPrefix, @C.TrackType int trackType) {\n  CustomMimeType customMimeType = new CustomMimeType(mimeType, codecPrefix, trackType);\n  int customMimeTypeCount = customMimeTypes.size();\n  for (int i = 0; i < customMimeTypeCount; i++) {\n    if (mimeType.equals(customMimeTypes.get(i).mimeType)) {\n      customMimeTypes.remove(i);\n      break;\n    }\n  }\n  customMimeTypes.add(customMimeType);\n}", "summary_tokens": ["registers", "a", "custom", "mime", "type"], "project": "ExoPlayer"}
{"id": 2624, "code": "public void setShowPreviousButton(boolean showPreviousButton) {\n  Assertions.checkStateNotNull(controller);\n  controller.setShowPreviousButton(showPreviousButton);\n}", "summary_tokens": ["sets", "whether", "the", "previous", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 1710, "code": "protected final void transferStarted(DataSpec dataSpec) {\n  this.dataSpec = dataSpec;\n  for (int i = 0; i < listenerCount; i++) {\n    listeners.get(i).onTransferStart( this, dataSpec, isNetwork);\n  }\n}", "summary_tokens": ["notifies", "listeners", "that", "data", "transfer", "for", "the", "specified", "data", "spec", "started"], "project": "ExoPlayer"}
{"id": 286, "code": "public boolean hasPrevious() {\n  return player.hasPrevious();\n}", "summary_tokens": ["calls", "player", "has", "previous", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2530, "code": "public boolean dispatchMediaKeyEvent(KeyEvent event) {\n  return useController() && controller.dispatchMediaKeyEvent(event);\n}", "summary_tokens": ["called", "to", "process", "media", "key", "events"], "project": "ExoPlayer"}
{"id": 703, "code": "public long toRendererTime(long periodTimeUs) {\n  return periodTimeUs + getRendererOffset();\n}", "summary_tokens": ["converts", "time", "relative", "to", "the", "start", "of", "the", "period", "to", "the", "respective", "renderer", "time", "using", "get", "renderer", "offset", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 1095, "code": "public boolean append(DecoderInputBuffer buffer) {\n  checkArgument(!buffer.isEncrypted());\n  checkArgument(!buffer.hasSupplementalData());\n  checkArgument(!buffer.isEndOfStream());\n  if (!canAppendSampleBuffer(buffer)) {\n    return false;\n  }\n  if (sampleCount++ == 0) {\n    timeUs = buffer.timeUs;\n    if (buffer.isKeyFrame()) {\n      setFlags(C.BUFFER_FLAG_KEY_FRAME);\n    }\n  }\n  if (buffer.isDecodeOnly()) {\n    setFlags(C.BUFFER_FLAG_DECODE_ONLY);\n  }\n  @Nullable ByteBuffer bufferData = buffer.data;\n  if (bufferData != null) {\n    ensureSpaceForWrite(bufferData.remaining());\n    data.put(bufferData);\n  }\n  lastSampleTimeUs = buffer.timeUs;\n  return true;\n}", "summary_tokens": ["attempts", "to", "append", "the", "provided", "buffer"], "project": "ExoPlayer"}
{"id": 1664, "code": "private static int identifyEmbeddedTracks(\n    int primaryGroupCount,\n    List<AdaptationSet> adaptationSets,\n    int[][] groupedAdaptationSetIndices,\n    boolean[] primaryGroupHasEventMessageTrackFlags,\n    Format[][] primaryGroupClosedCaptionTrackFormats) {\n  int numEmbeddedTrackGroups = 0;\n  for (int i = 0; i < primaryGroupCount; i++) {\n    if (hasEventMessageTrack(adaptationSets, groupedAdaptationSetIndices[i])) {\n      primaryGroupHasEventMessageTrackFlags[i] = true;\n      numEmbeddedTrackGroups++;\n    }\n    primaryGroupClosedCaptionTrackFormats[i] =\n        getClosedCaptionTrackFormats(adaptationSets, groupedAdaptationSetIndices[i]);\n    if (primaryGroupClosedCaptionTrackFormats[i].length != 0) {\n      numEmbeddedTrackGroups++;\n    }\n  }\n  return numEmbeddedTrackGroups;\n}", "summary_tokens": ["iterates", "through", "list", "of", "primary", "track", "groups", "and", "identifies", "embedded", "tracks"], "project": "ExoPlayer"}
{"id": 907, "code": "public long getPlaybackStateDurationMs(@PlaybackState int playbackState) {\n  return playbackStateDurationsMs[playbackState];\n}", "summary_tokens": ["returns", "the", "total", "time", "spent", "in", "a", "given", "playback", "state", "in", "milliseconds"], "project": "ExoPlayer"}
{"id": 578, "code": "public long readUnsignedInt() {\n  return (data[position++] & 0xFFL) << 24\n      | (data[position++] & 0xFFL) << 16\n      | (data[position++] & 0xFFL) << 8\n      | (data[position++] & 0xFFL);\n}", "summary_tokens": ["reads", "the", "next", "four", "bytes", "as", "an", "unsigned", "value"], "project": "ExoPlayer"}
{"id": 1514, "code": "public void onSurfaceChanged(@Nullable Surface surface) {\n  if (surface instanceof PlaceholderSurface) {\n      \n    surface = null;\n  }\n  if (this.surface == surface) {\n    return;\n  }\n  clearSurfaceFrameRate();\n  this.surface = surface;\n  updateSurfacePlaybackFrameRate( true);\n}", "summary_tokens": ["called", "when", "the", "renderer", "changes", "which", "surface", "it", "s", "rendering", "to", "renders", "to"], "project": "ExoPlayer"}
{"id": 908, "code": "public @PlaybackState int getPlaybackStateAtTime(long realtimeMs) {\n  @PlaybackState int state = PLAYBACK_STATE_NOT_STARTED;\n  for (EventTimeAndPlaybackState timeAndState : playbackStateHistory) {\n    if (timeAndState.eventTime.realtimeMs > realtimeMs) {\n      break;\n    }\n    state = timeAndState.playbackState;\n  }\n  return state;\n}", "summary_tokens": ["returns", "the", "playback", "state", "at", "the", "given", "time"], "project": "ExoPlayer"}
{"id": 184, "code": "public void setMetadataDeduplicationEnabled(boolean metadataDeduplicationEnabled) {\n  this.metadataDeduplicationEnabled = metadataDeduplicationEnabled;\n}", "summary_tokens": ["sets", "whether", "media", "metadata", "provider", "same", "as", "media", "metadata", "compat", "media", "metadata", "compat", "should", "be", "consulted", "before", "calling", "media", "session", "compat", "set", "metadata", "media", "metadata", "compat"], "project": "ExoPlayer"}
{"id": 173, "code": "public void setErrorMessageProvider(\n    @Nullable ErrorMessageProvider<? super PlaybackException> errorMessageProvider) {\n  if (this.errorMessageProvider != errorMessageProvider) {\n    this.errorMessageProvider = errorMessageProvider;\n    invalidateMediaSessionPlaybackState();\n  }\n}", "summary_tokens": ["sets", "the", "optional", "error", "message", "provider"], "project": "ExoPlayer"}
{"id": 2050, "code": "private void setReadingAdtsHeaderState() {\n  state = STATE_READING_ADTS_HEADER;\n  bytesRead = 0;\n}", "summary_tokens": ["sets", "the", "state", "to", "state", "reading", "adts", "header"], "project": "ExoPlayer"}
{"id": 2244, "code": "private static Timeline prepareAndWaitForTimeline(HlsMediaSource mediaSource)\n    throws TimeoutException {\n  AtomicReference<Timeline> receivedTimeline = new AtomicReference<>();\n  mediaSource.prepareSource(\n      (source, timeline) -> receivedTimeline.set(timeline),\n       null,\n      PlayerId.UNSET);\n  runMainLooperUntil(() -> receivedTimeline.get() != null);\n  return receivedTimeline.get();\n}", "summary_tokens": ["prepares", "the", "media", "source", "and", "waits", "until", "the", "timeline", "is", "updated"], "project": "ExoPlayer"}
{"id": 1008, "code": "private boolean shouldApplyAudioProcessorPlaybackParameters() {\n    \n    \n    \n    \n    \n    \n    \n  return !tunneling\n      && MimeTypes.AUDIO_RAW.equals(configuration.inputFormat.sampleMimeType)\n      && !shouldUseFloatOutput(configuration.inputFormat.pcmEncoding);\n}", "summary_tokens": ["returns", "whether", "audio", "processor", "playback", "parameters", "should", "be", "applied", "in", "the", "current", "configuration"], "project": "ExoPlayer"}
{"id": 2673, "code": "public Map<TrackGroup, TrackSelectionOverride> getOverrides() {\n  return overrides;\n}", "summary_tokens": ["returns", "the", "selected", "track", "overrides"], "project": "ExoPlayer"}
{"id": 20, "code": "public static GlMatrixTransformation createSpin3dEffect() {\n  return MatrixTransformationFactory::calculate3dSpinMatrix;\n}", "summary_tokens": ["returns", "a", "gl", "matrix", "transformation", "that", "rotates", "a", "frame", "in", "0", "d", "around", "the", "y", "axis", "and", "applies", "perspective", "projection", "to", "0", "d"], "project": "ExoPlayer"}
{"id": 1735, "code": "private static void maybeTerminateInputStream(\n    @Nullable HttpURLConnection connection, long bytesRemaining) {\n  if (connection == null || Util.SDK_INT < 19 || Util.SDK_INT > 20) {\n    return;\n  }\n\n  try {\n    InputStream inputStream = connection.getInputStream();\n    if (bytesRemaining == C.LENGTH_UNSET) {\n        \n      if (inputStream.read() == -1) {\n        return;\n      }\n    } else if (bytesRemaining <= MAX_BYTES_TO_DRAIN) {\n        \n        \n      return;\n    }\n    String className = inputStream.getClass().getName();\n    if (\"com.android.okhttp.internal.http.HttpTransport$ChunkedInputStream\".equals(className)\n        || \"com.android.okhttp.internal.http.HttpTransport$FixedLengthInputStream\"\n            .equals(className)) {\n      Class<?> superclass = inputStream.getClass().getSuperclass();\n      Method unexpectedEndOfInput =\n          checkNotNull(superclass).getDeclaredMethod(\"unexpectedEndOfInput\");\n      unexpectedEndOfInput.setAccessible(true);\n      unexpectedEndOfInput.invoke(inputStream);\n    }\n  } catch (Exception e) {\n      \n      \n      \n  }\n}", "summary_tokens": ["on", "platform", "api", "levels", "0", "and", "0", "okhttp", "s", "implementation", "of", "input", "stream", "close", "can", "block", "for", "a", "long", "time", "if", "the", "stream", "has", "a", "lot", "of", "data", "remaining"], "project": "ExoPlayer"}
{"id": 137, "code": "public static AdsRequest getAdsRequestForAdTagDataSpec(\n    ImaFactory imaFactory, DataSpec adTagDataSpec) throws IOException {\n  AdsRequest request = imaFactory.createAdsRequest();\n  if (DataSchemeDataSource.SCHEME_DATA.equals(adTagDataSpec.uri.getScheme())) {\n    DataSchemeDataSource dataSchemeDataSource = new DataSchemeDataSource();\n    try {\n      dataSchemeDataSource.open(adTagDataSpec);\n      request.setAdsResponse(Util.fromUtf8Bytes(DataSourceUtil.readToEnd(dataSchemeDataSource)));\n    } finally {\n      dataSchemeDataSource.close();\n    }\n  } else {\n    request.setAdTagUrl(adTagDataSpec.uri.toString());\n  }\n  return request;\n}", "summary_tokens": ["returns", "an", "ads", "request", "based", "on", "the", "specified", "ad", "tag", "data", "spec"], "project": "ExoPlayer"}
{"id": 655, "code": "protected final FormatHolder getFormatHolder() {\n  formatHolder.clear();\n  return formatHolder;\n}", "summary_tokens": ["returns", "a", "clear", "format", "holder"], "project": "ExoPlayer"}
{"id": 500, "code": "private static int generateTexture() {\n  checkEglException(\n      !Util.areEqual(EGL14.eglGetCurrentContext(), EGL14.EGL_NO_CONTEXT), \"No current context\");\n\n  int[] texId = new int[1];\n  GLES20.glGenTextures( 1, texId,  0);\n  checkGlError();\n  return texId[0];\n}", "summary_tokens": ["returns", "a", "new", "gl", "texture", "identifier"], "project": "ExoPlayer"}
{"id": 2840, "code": "public static void assertAdGroupCounts(Timeline timeline, int... expectedAdGroupCounts) {\n  Period period = new Period();\n  for (int i = 0; i < timeline.getPeriodCount(); i++) {\n    timeline.getPeriod(i, period);\n    assertThat(period.getAdGroupCount()).isEqualTo(expectedAdGroupCounts[i]);\n  }\n}", "summary_tokens": ["asserts", "that", "periods", "period", "get", "ad", "group", "count", "are", "set", "correctly"], "project": "ExoPlayer"}
{"id": 390, "code": "public final Period getPeriod(int periodIndex, Period period) {\n  return getPeriod(periodIndex, period, false);\n}", "summary_tokens": ["populates", "a", "period", "with", "data", "for", "the", "period", "at", "the", "specified", "index"], "project": "ExoPlayer"}
{"id": 1441, "code": "public void clearFatalError() {\n  fatalError = null;\n}", "summary_tokens": ["clears", "any", "stored", "fatal", "error"], "project": "ExoPlayer"}
{"id": 1014, "code": "protected int getOffloadBufferSizeInBytes(@C.Encoding int encoding) {\n  int maxByteRate = getMaximumEncodedRateBytesPerSecond(encoding);\n  return checkedCast((long) offloadBufferDurationUs * maxByteRate / C.MICROS_PER_SECOND);\n}", "summary_tokens": ["returns", "the", "buffer", "size", "for", "offload", "playback"], "project": "ExoPlayer"}
{"id": 386, "code": "public final boolean isLastPeriod(\n    int periodIndex,\n    Period period,\n    Window window,\n    @Player.RepeatMode int repeatMode,\n    boolean shuffleModeEnabled) {\n  return getNextPeriodIndex(periodIndex, period, window, repeatMode, shuffleModeEnabled)\n      == C.INDEX_UNSET;\n}", "summary_tokens": ["returns", "whether", "the", "given", "period", "is", "the", "last", "period", "of", "the", "timeline", "depending", "on", "the", "repeat", "mode", "and", "whether", "shuffling", "is", "enabled"], "project": "ExoPlayer"}
{"id": 437, "code": "public static List<byte[]> buildCea708InitializationData(boolean isWideAspectRatio) {\n  return Collections.singletonList(isWideAspectRatio ? new byte[] {1} : new byte[] {0});\n}", "summary_tokens": ["returns", "initialization", "data", "for", "formats", "with", "mime", "type", "mime", "types", "application", "cea", "0"], "project": "ExoPlayer"}
{"id": 261, "code": "public void removeMediaItems(int fromIndex, int toIndex) {\n  player.removeMediaItems(fromIndex, toIndex);\n}", "summary_tokens": ["calls", "player", "remove", "media", "items", "int", "int", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1377, "code": "protected final void checkInBounds() {\n  if (currentIndex < fromIndex || currentIndex > toIndex) {\n    throw new NoSuchElementException();\n  }\n}", "summary_tokens": ["verifies", "that", "the", "iterator", "points", "to", "a", "valid", "element"], "project": "ExoPlayer"}
{"id": 271, "code": "public void play() {\n  player.play();\n}", "summary_tokens": ["calls", "player", "play", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 752, "code": "public Timeline removeMediaSourceRange(int fromIndex, int toIndex, ShuffleOrder shuffleOrder) {\n  Assertions.checkArgument(fromIndex >= 0 && fromIndex <= toIndex && toIndex <= getSize());\n  this.shuffleOrder = shuffleOrder;\n  removeMediaSourcesInternal(fromIndex, toIndex);\n  return createTimeline();\n}", "summary_tokens": ["removes", "a", "range", "of", "media", "source", "holder", "s", "from", "the", "playlist", "by", "specifying", "an", "initial", "index", "included", "and", "a", "final", "index", "excluded"], "project": "ExoPlayer"}
{"id": 831, "code": "default void onPlayerStateChanged(\n    EventTime eventTime, boolean playWhenReady, @Player.State int playbackState) {}", "summary_tokens": ["use", "on", "playback", "state", "changed", "event", "time", "int", "and", "on", "play", "when", "ready", "changed", "event", "time", "boolean", "int", "instead"], "project": "ExoPlayer"}
{"id": 300, "code": "public void seekToNext() {\n  player.seekToNext();\n}", "summary_tokens": ["calls", "player", "seek", "to", "next", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 616, "code": "public static Uri resolveToUri(@Nullable String baseUri, @Nullable String referenceUri) {\n  return Uri.parse(resolve(baseUri, referenceUri));\n}", "summary_tokens": ["like", "resolve", "string", "string", "but", "returns", "a", "uri", "instead", "of", "a", "string"], "project": "ExoPlayer"}
{"id": 2240, "code": "public HlsMediaPlaylist copyWith(long startTimeUs, int discontinuitySequence) {\n  return new HlsMediaPlaylist(\n      playlistType,\n      baseUri,\n      tags,\n      startOffsetUs,\n      preciseStart,\n      startTimeUs,\n       true,\n      discontinuitySequence,\n      mediaSequence,\n      version,\n      targetDurationUs,\n      partTargetDurationUs,\n      hasIndependentSegments,\n      hasEndTag,\n      hasProgramDateTime,\n      protectionSchemes,\n      segments,\n      trailingParts,\n      serverControl,\n      renditionReports);\n}", "summary_tokens": ["returns", "a", "playlist", "identical", "to", "this", "one", "except", "for", "the", "start", "time", "the", "discontinuity", "sequence", "and", "has", "discontinuity", "sequence", "values"], "project": "ExoPlayer"}
{"id": 575, "code": "public int readInt24() {\n  return ((data[position++] & 0xFF) << 24) >> 8\n      | (data[position++] & 0xFF) << 8\n      | (data[position++] & 0xFF);\n}", "summary_tokens": ["reads", "the", "next", "three", "bytes", "as", "a", "signed", "value"], "project": "ExoPlayer"}
{"id": 431, "code": "public static <T extends Bundleable> ImmutableList<T> fromBundleList(\n    Bundleable.Creator<T> creator, List<Bundle> bundleList) {\n  ImmutableList.Builder<T> builder = ImmutableList.builder();\n  for (int i = 0; i < bundleList.size(); i++) {\n    Bundle bundle = checkNotNull(bundleList.get(i)); \n    T bundleable = creator.fromBundle(bundle);\n    builder.add(bundleable);\n  }\n  return builder.build();\n}", "summary_tokens": ["converts", "a", "list", "of", "bundle", "to", "a", "list", "of", "bundleable"], "project": "ExoPlayer"}
{"id": 649, "code": "protected void onPositionReset(long positionUs, boolean joining) throws ExoPlaybackException {\n    \n}", "summary_tokens": ["called", "when", "the", "position", "is", "reset"], "project": "ExoPlayer"}
{"id": 1433, "code": "private static int[] getInitialBitrateCountryGroupAssignment(String country) {\n  switch (country) {\n    case \"AE\":\n      return new int[] {1, 4, 4, 4, 4, 0};\n    case \"AG\":\n      return new int[] {2, 4, 1, 2, 2, 2};\n    case \"AI\":\n      return new int[] {0, 2, 0, 3, 2, 2};\n    case \"AM\":\n      return new int[] {2, 3, 2, 3, 2, 2};\n    case \"AO\":\n      return new int[] {4, 4, 3, 2, 2, 2};\n    case \"AS\":\n      return new int[] {2, 2, 3, 3, 2, 2};\n    case \"AT\":\n      return new int[] {1, 0, 1, 1, 0, 0};\n    case \"AU\":\n      return new int[] {0, 1, 1, 1, 2, 0};\n    case \"AW\":\n      return new int[] {1, 3, 4, 4, 2, 2};\n    case \"BA\":\n      return new int[] {1, 2, 1, 1, 2, 2};\n    case \"BD\":\n      return new int[] {2, 1, 3, 3, 2, 2};\n    case \"BE\":\n      return new int[] {0, 1, 4, 4, 3, 2};\n    case \"BF\":\n      return new int[] {4, 3, 4, 3, 2, 2};\n    case \"BH\":\n      return new int[] {1, 2, 1, 3, 4, 2};\n    case \"BJ\":\n      return new int[] {4, 4, 3, 3, 2, 2};\n    case \"BO\":\n      return new int[] {1, 2, 3, 2, 2, 2};\n    case \"BS\":\n      return new int[] {4, 4, 2, 2, 2, 2};\n    case \"BT\":\n      return new int[] {3, 1, 3, 2, 2, 2};\n    case \"BW\":\n      return new int[] {3, 2, 1, 0, 2, 2};\n    case \"BY\":\n      return new int[] {0, 1, 2, 3, 2, 2};\n    case \"BZ\":\n      return new int[] {2, 4, 2, 1, 2, 2};\n    case \"CA\":\n      return new int[] {0, 2, 2, 2, 3, 2};\n    case \"CD\":\n      return new int[] {4, 2, 3, 2, 2, 2};\n    case \"CH\":\n      return new int[] {0, 0, 0, 1, 0, 2};\n    case \"CM\":\n      return new int[] {3, 3, 3, 3, 2, 2};\n    case \"CN\":\n      return new int[] {2, 0, 1, 1, 3, 2};\n    case \"CO\":\n      return new int[] {2, 3, 4, 3, 2, 2};\n    case \"CR\":\n      return new int[] {2, 3, 4, 4, 2, 2};\n    case \"CV\":\n      return new int[] {2, 1, 0, 0, 2, 2};\n    case \"BN\":\n    case \"CW\":\n      return new int[] {2, 2, 0, 0, 2, 2};\n    case \"DE\":\n      return new int[] {0, 1, 2, 2, 2, 3};\n    case \"DK\":\n      return new int[] {0, 0, 3, 2, 0, 2};\n    case \"DO\":\n      return new int[] {3, 4, 4, 4, 4, 2};\n    case \"EC\":\n      return new int[] {2, 3, 2, 1, 2, 2};\n    case \"ET\":\n      return new int[] {4, 3, 3, 1, 2, 2};\n    case \"FI\":\n      return new int[] {0, 0, 0, 3, 0, 2};\n    case \"FJ\":\n      return new int[] {3, 1, 2, 2, 2, 2};\n    case \"FM\":\n      return new int[] {4, 2, 4, 1, 2, 2};\n    case \"FR\":\n      return new int[] {1, 2, 3, 1, 0, 2};\n    case \"GB\":\n      return new int[] {0, 0, 1, 1, 1, 1};\n    case \"GE\":\n      return new int[] {1, 1, 1, 2, 2, 2};\n    case \"BB\":\n    case \"DM\":\n    case \"FO\":\n    case \"GI\":\n      return new int[] {0, 2, 0, 0, 2, 2};\n    case \"AF\":\n    case \"GM\":\n      return new int[] {4, 3, 3, 4, 2, 2};\n    case \"GN\":\n      return new int[] {4, 3, 4, 2, 2, 2};\n    case \"GQ\":\n      return new int[] {4, 2, 1, 4, 2, 2};\n    case \"GT\":\n      return new int[] {2, 3, 2, 2, 2, 2};\n    case \"CG\":\n    case \"EG\":\n    case \"GW\":\n      return new int[] {3, 4, 3, 3, 2, 2};\n    case \"GY\":\n      return new int[] {3, 2, 2, 1, 2, 2};\n    case \"HK\":\n      return new int[] {0, 1, 2, 3, 2, 0};\n    case \"HU\":\n      return new int[] {0, 0, 0, 1, 3, 2};\n    case \"ID\":\n      return new int[] {3, 1, 2, 2, 3, 2};\n    case \"ES\":\n    case \"IE\":\n      return new int[] {0, 1, 1, 1, 2, 2};\n    case \"CL\":\n    case \"IL\":\n      return new int[] {1, 2, 2, 2, 3, 2};\n    case \"IN\":\n      return new int[] {1, 1, 3, 2, 3, 3};\n    case \"IQ\":\n      return new int[] {3, 2, 2, 3, 2, 2};\n    case \"IR\":\n      return new int[] {3, 0, 1, 1, 4, 1};\n    case \"IT\":\n      return new int[] {0, 0, 0, 1, 1, 2};\n    case \"JM\":\n      return new int[] {2, 4, 3, 2, 2, 2};\n    case \"JO\":\n      return new int[] {2, 1, 1, 2, 2, 2};\n    case \"JP\":\n      return new int[] {0, 1, 1, 2, 2, 4};\n    case \"KH\":\n      return new int[] {2, 1, 4, 2, 2, 2};\n    case \"CF\":\n    case \"KI\":\n      return new int[] {4, 2, 4, 2, 2, 2};\n    case \"FK\":\n    case \"KE\":\n    case \"KP\":\n      return new int[] {3, 2, 2, 2, 2, 2};\n    case \"KR\":\n      return new int[] {0, 1, 1, 3, 4, 4};\n    case \"CY\":\n    case \"KW\":\n      return new int[] {1, 0, 0, 0, 0, 2};\n    case \"KZ\":\n      return new int[] {2, 1, 2, 2, 2, 2};\n    case \"LA\":\n      return new int[] {1, 2, 1, 3, 2, 2};\n    case \"LB\":\n      return new int[] {3, 3, 2, 4, 2, 2};\n    case \"LK\":\n      return new int[] {3, 1, 3, 3, 4, 2};\n    case \"CI\":\n    case \"DZ\":\n    case \"LR\":\n      return new int[] {3, 4, 4, 4, 2, 2};\n    case \"LS\":\n      return new int[] {3, 3, 2, 2, 2, 2};\n    case \"LT\":\n      return new int[] {0, 0, 0, 0, 2, 2};\n    case \"LU\":\n      return new int[] {1, 0, 3, 2, 1, 4};\n    case \"MA\":\n      return new int[] {3, 3, 1, 1, 2, 2};\n    case \"MC\":\n      return new int[] {0, 2, 2, 0, 2, 2};\n    case \"ME\":\n      return new int[] {2, 0, 0, 1, 2, 2};\n    case \"MK\":\n      return new int[] {1, 0, 0, 1, 3, 2};\n    case \"MM\":\n      return new int[] {2, 4, 2, 3, 2, 2};\n    case \"MN\":\n      return new int[] {2, 0, 1, 2, 2, 2};\n    case \"MO\":\n    case \"MP\":\n      return new int[] {0, 2, 4, 4, 2, 2};\n    case \"GP\":\n    case \"MQ\":\n      return new int[] {2, 1, 2, 3, 2, 2};\n    case \"MU\":\n      return new int[] {3, 1, 1, 2, 2, 2};\n    case \"MV\":\n      return new int[] {3, 4, 1, 4, 2, 2};\n    case \"MW\":\n      return new int[] {4, 2, 3, 3, 2, 2};\n    case \"MX\":\n      return new int[] {2, 4, 3, 4, 2, 2};\n    case \"MY\":\n      return new int[] {1, 0, 3, 1, 3, 2};\n    case \"MZ\":\n      return new int[] {3, 1, 2, 1, 2, 2};\n    case \"NC\":\n      return new int[] {3, 3, 4, 4, 2, 2};\n    case \"NG\":\n      return new int[] {3, 4, 2, 1, 2, 2};\n    case \"NL\":\n      return new int[] {0, 2, 2, 3, 0, 3};\n    case \"CZ\":\n    case \"NO\":\n      return new int[] {0, 0, 2, 0, 1, 2};\n    case \"NP\":\n      return new int[] {2, 2, 4, 3, 2, 2};\n    case \"NR\":\n    case \"NU\":\n      return new int[] {4, 2, 2, 1, 2, 2};\n    case \"OM\":\n      return new int[] {2, 3, 1, 3, 4, 2};\n    case \"GU\":\n    case \"PE\":\n      return new int[] {1, 2, 4, 4, 4, 2};\n    case \"CK\":\n    case \"PF\":\n      return new int[] {2, 2, 2, 1, 2, 2};\n    case \"ML\":\n    case \"PG\":\n      return new int[] {4, 3, 3, 2, 2, 2};\n    case \"PH\":\n      return new int[] {2, 1, 3, 3, 3, 0};\n    case \"NZ\":\n    case \"PL\":\n      return new int[] {1, 1, 2, 2, 4, 2};\n    case \"PR\":\n      return new int[] {2, 0, 2, 1, 2, 1};\n    case \"PS\":\n      return new int[] {3, 4, 1, 2, 2, 2};\n    case \"PW\":\n      return new int[] {2, 2, 4, 1, 2, 2};\n    case \"QA\":\n      return new int[] {2, 4, 4, 4, 4, 2};\n    case \"MF\":\n    case \"RE\":\n      return new int[] {1, 2, 1, 2, 2, 2};\n    case \"RO\":\n      return new int[] {0, 0, 1, 2, 1, 2};\n    case \"MD\":\n    case \"RS\":\n      return new int[] {1, 0, 0, 0, 2, 2};\n    case \"RU\":\n      return new int[] {1, 0, 0, 0, 4, 3};\n    case \"RW\":\n      return new int[] {3, 4, 2, 0, 2, 2};\n    case \"SA\":\n      return new int[] {3, 1, 1, 1, 2, 2};\n    case \"SB\":\n      return new int[] {4, 2, 4, 3, 2, 2};\n    case \"SG\":\n      return new int[] {1, 1, 2, 2, 2, 1};\n    case \"AQ\":\n    case \"ER\":\n    case \"SH\":\n      return new int[] {4, 2, 2, 2, 2, 2};\n    case \"GR\":\n    case \"HR\":\n    case \"SI\":\n      return new int[] {1, 0, 0, 0, 1, 2};\n    case \"BG\":\n    case \"MT\":\n    case \"SK\":\n      return new int[] {0, 0, 0, 0, 1, 2};\n    case \"AX\":\n    case \"LI\":\n    case \"MS\":\n    case \"PM\":\n    case \"SM\":\n      return new int[] {0, 2, 2, 2, 2, 2};\n    case \"SN\":\n      return new int[] {4, 4, 4, 3, 2, 2};\n    case \"SR\":\n      return new int[] {2, 4, 3, 0, 2, 2};\n    case \"SS\":\n      return new int[] {4, 3, 2, 3, 2, 2};\n    case \"ST\":\n      return new int[] {2, 2, 1, 2, 2, 2};\n    case \"NI\":\n    case \"PA\":\n    case \"SV\":\n      return new int[] {2, 3, 3, 3, 2, 2};\n    case \"SZ\":\n      return new int[] {3, 3, 3, 4, 2, 2};\n    case \"SX\":\n    case \"TC\":\n      return new int[] {1, 2, 1, 0, 2, 2};\n    case \"GA\":\n    case \"TG\":\n      return new int[] {3, 4, 1, 0, 2, 2};\n    case \"TH\":\n      return new int[] {0, 2, 2, 3, 3, 4};\n    case \"TK\":\n      return new int[] {2, 2, 2, 4, 2, 2};\n    case \"CU\":\n    case \"DJ\":\n    case \"SY\":\n    case \"TJ\":\n    case \"TL\":\n      return new int[] {4, 3, 4, 4, 2, 2};\n    case \"SC\":\n    case \"TM\":\n      return new int[] {4, 2, 1, 1, 2, 2};\n    case \"AZ\":\n    case \"GF\":\n    case \"LY\":\n    case \"PK\":\n    case \"SO\":\n    case \"TO\":\n      return new int[] {3, 2, 3, 3, 2, 2};\n    case \"TR\":\n      return new int[] {1, 1, 0, 0, 2, 2};\n    case \"TT\":\n      return new int[] {1, 4, 1, 3, 2, 2};\n    case \"EE\":\n    case \"IS\":\n    case \"LV\":\n    case \"PT\":\n    case \"SE\":\n    case \"TW\":\n      return new int[] {0, 0, 0, 0, 0, 2};\n    case \"TZ\":\n      return new int[] {3, 4, 3, 2, 2, 2};\n    case \"IM\":\n    case \"UA\":\n      return new int[] {0, 2, 1, 1, 2, 2};\n    case \"SL\":\n    case \"UG\":\n      return new int[] {3, 3, 4, 3, 2, 2};\n    case \"US\":\n      return new int[] {1, 0, 2, 2, 3, 1};\n    case \"AR\":\n    case \"KG\":\n    case \"TN\":\n    case \"UY\":\n      return new int[] {2, 1, 1, 1, 2, 2};\n    case \"UZ\":\n      return new int[] {2, 2, 3, 4, 2, 2};\n    case \"BL\":\n    case \"CX\":\n    case \"VA\":\n      return new int[] {1, 2, 2, 2, 2, 2};\n    case \"AD\":\n    case \"BM\":\n    case \"BQ\":\n    case \"GD\":\n    case \"GL\":\n    case \"KN\":\n    case \"KY\":\n    case \"LC\":\n    case \"VC\":\n      return new int[] {1, 2, 0, 0, 2, 2};\n    case \"VG\":\n      return new int[] {2, 2, 1, 1, 2, 2};\n    case \"GG\":\n    case \"VI\":\n      return new int[] {0, 2, 0, 1, 2, 2};\n    case \"VN\":\n      return new int[] {0, 3, 3, 4, 2, 2};\n    case \"GH\":\n    case \"NA\":\n    case \"VU\":\n      return new int[] {3, 3, 3, 2, 2, 2};\n    case \"IO\":\n    case \"MH\":\n    case \"TV\":\n    case \"WF\":\n      return new int[] {4, 2, 2, 4, 2, 2};\n    case \"WS\":\n      return new int[] {3, 1, 3, 1, 2, 2};\n    case \"AL\":\n    case \"XK\":\n      return new int[] {1, 1, 1, 1, 2, 2};\n    case \"BI\":\n    case \"HT\":\n    case \"KM\":\n    case \"MG\":\n    case \"NE\":\n    case \"SD\":\n    case \"TD\":\n    case \"VE\":\n    case \"YE\":\n      return new int[] {4, 4, 4, 4, 2, 2};\n    case \"JE\":\n    case \"YT\":\n      return new int[] {4, 2, 2, 3, 2, 2};\n    case \"ZA\":\n      return new int[] {3, 2, 2, 1, 1, 2};\n    case \"ZM\":\n      return new int[] {3, 3, 4, 2, 2, 2};\n    case \"MR\":\n    case \"ZW\":\n      return new int[] {4, 2, 4, 4, 2, 2};\n    default:\n      return new int[] {2, 2, 2, 2, 2, 2};\n  }\n}", "summary_tokens": ["returns", "initial", "bitrate", "group", "assignments", "for", "a", "country"], "project": "ExoPlayer"}
{"id": 2291, "code": "public static byte[] convertMessageToByteArray(List<String> message) {\n  return Joiner.on(CRLF).join(message).getBytes(RtspMessageChannel.CHARSET);\n}", "summary_tokens": ["converts", "an", "rtsp", "message", "to", "a", "byte", "array"], "project": "ExoPlayer"}
{"id": 552, "code": "public long readBitsToLong(int numBits) {\n  if (numBits <= 32) {\n    return Util.toUnsignedLong(readBits(numBits));\n  }\n  return Util.toLong(readBits(numBits - 32), readBits(32));\n}", "summary_tokens": ["reads", "up", "to", "0", "bits"], "project": "ExoPlayer"}
{"id": 2372, "code": "private static int getSuggestedBitrate(int width, int height, float frameRate) {\n    \n    \n    \n  return (int) (width * height * frameRate * 0.07 * 2);\n}", "summary_tokens": ["computes", "the", "video", "bit", "rate", "using", "the", "kush", "gauge"], "project": "ExoPlayer"}
{"id": 1505, "code": "protected MediaFormat getMediaFormat(\n    Format format,\n    String codecMimeType,\n    CodecMaxValues codecMaxValues,\n    float codecOperatingRate,\n    boolean deviceNeedsNoPostProcessWorkaround,\n    int tunnelingAudioSessionId) {\n  MediaFormat mediaFormat = new MediaFormat();\n    \n  mediaFormat.setString(MediaFormat.KEY_MIME, codecMimeType);\n  mediaFormat.setInteger(MediaFormat.KEY_WIDTH, format.width);\n  mediaFormat.setInteger(MediaFormat.KEY_HEIGHT, format.height);\n  MediaFormatUtil.setCsdBuffers(mediaFormat, format.initializationData);\n    \n  MediaFormatUtil.maybeSetFloat(mediaFormat, MediaFormat.KEY_FRAME_RATE, format.frameRate);\n  MediaFormatUtil.maybeSetInteger(mediaFormat, MediaFormat.KEY_ROTATION, format.rotationDegrees);\n  MediaFormatUtil.maybeSetColorInfo(mediaFormat, format.colorInfo);\n  if (MimeTypes.VIDEO_DOLBY_VISION.equals(format.sampleMimeType)) {\n      \n      \n    Pair<Integer, Integer> codecProfileAndLevel = MediaCodecUtil.getCodecProfileAndLevel(format);\n    if (codecProfileAndLevel != null) {\n      MediaFormatUtil.maybeSetInteger(\n          mediaFormat, MediaFormat.KEY_PROFILE, codecProfileAndLevel.first);\n    }\n  }\n    \n  mediaFormat.setInteger(MediaFormat.KEY_MAX_WIDTH, codecMaxValues.width);\n  mediaFormat.setInteger(MediaFormat.KEY_MAX_HEIGHT, codecMaxValues.height);\n  MediaFormatUtil.maybeSetInteger(\n      mediaFormat, MediaFormat.KEY_MAX_INPUT_SIZE, codecMaxValues.inputSize);\n    \n  if (Util.SDK_INT >= 23) {\n    mediaFormat.setInteger(MediaFormat.KEY_PRIORITY, 0 );\n    if (codecOperatingRate != CODEC_OPERATING_RATE_UNSET) {\n      mediaFormat.setFloat(MediaFormat.KEY_OPERATING_RATE, codecOperatingRate);\n    }\n  }\n  if (deviceNeedsNoPostProcessWorkaround) {\n    mediaFormat.setInteger(\"no-post-process\", 1);\n    mediaFormat.setInteger(\"auto-frc\", 0);\n  }\n  if (tunnelingAudioSessionId != C.AUDIO_SESSION_ID_UNSET) {\n    configureTunnelingV21(mediaFormat, tunnelingAudioSessionId);\n  }\n  return mediaFormat;\n}", "summary_tokens": ["returns", "the", "framework", "media", "format", "that", "should", "be", "used", "to", "configure", "the", "decoder"], "project": "ExoPlayer"}
{"id": 1354, "code": "private int countUnreadSamplesBefore(long timeUs) {\n  int count = length;\n  int relativeSampleIndex = getRelativeIndex(length - 1);\n  while (count > readPosition && timesUs[relativeSampleIndex] >= timeUs) {\n    count--;\n    relativeSampleIndex--;\n    if (relativeSampleIndex == -1) {\n      relativeSampleIndex = capacity - 1;\n    }\n  }\n  return count;\n}", "summary_tokens": ["counts", "the", "number", "of", "samples", "that", "haven", "t", "been", "read", "that", "have", "a", "timestamp", "smaller", "than", "time", "us"], "project": "ExoPlayer"}
{"id": 2551, "code": "public View getVideoSurfaceView() {\n  return surfaceView;\n}", "summary_tokens": ["gets", "the", "view", "onto", "which", "video", "is", "rendered"], "project": "ExoPlayer"}
{"id": 180, "code": "public void setMediaMetadataProvider(@Nullable MediaMetadataProvider mediaMetadataProvider) {\n  if (this.mediaMetadataProvider != mediaMetadataProvider) {\n    this.mediaMetadataProvider = mediaMetadataProvider;\n    invalidateMediaSessionMetadata();\n  }\n}", "summary_tokens": ["sets", "a", "provider", "of", "metadata", "to", "be", "published", "to", "the", "media", "session"], "project": "ExoPlayer"}
{"id": 495, "code": "public static void destroyEglContext(\n    @Nullable EGLDisplay eglDisplay, @Nullable EGLContext eglContext) {\n  Api17.destroyEglContext(eglDisplay, eglContext);\n}", "summary_tokens": ["destroys", "the", "eglcontext", "identified", "by", "the", "provided", "egldisplay", "and", "eglcontext"], "project": "ExoPlayer"}
{"id": 2364, "code": "private boolean maybeDequeueOutputBuffer(boolean setOutputBuffer) throws TransformationException {\n  if (outputBufferIndex >= 0) {\n    return true;\n  }\n  if (outputStreamEnded) {\n    return false;\n  }\n\n  try {\n    outputBufferIndex = mediaCodec.dequeueOutputBuffer(outputBufferInfo,  0);\n  } catch (RuntimeException e) {\n    throw createTransformationException(e);\n  }\n  if (outputBufferIndex < 0) {\n    if (outputBufferIndex == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) {\n      outputFormat = getFormat(mediaCodec.getOutputFormat());\n    }\n    return false;\n  }\n  if ((outputBufferInfo.flags & MediaCodec.BUFFER_FLAG_END_OF_STREAM) != 0) {\n    outputStreamEnded = true;\n    if (outputBufferInfo.size == 0) {\n      releaseOutputBuffer( false);\n      return false;\n    }\n  }\n  if ((outputBufferInfo.flags & MediaCodec.BUFFER_FLAG_CODEC_CONFIG) != 0) {\n      \n    releaseOutputBuffer( false);\n    return false;\n  }\n\n  if (setOutputBuffer) {\n    try {\n      outputBuffer = checkNotNull(mediaCodec.getOutputBuffer(outputBufferIndex));\n    } catch (RuntimeException e) {\n      throw createTransformationException(e);\n    }\n    outputBuffer.position(outputBufferInfo.offset);\n    outputBuffer.limit(outputBufferInfo.offset + outputBufferInfo.size);\n  }\n  return true;\n}", "summary_tokens": ["attempts", "to", "dequeue", "an", "output", "buffer", "if", "there", "is", "no", "output", "buffer", "pending"], "project": "ExoPlayer"}
{"id": 2419, "code": "public void endTrack(@C.TrackType int trackType) {\n  trackTypeToIndex.delete(trackType);\n}", "summary_tokens": ["notifies", "the", "muxer", "that", "all", "the", "samples", "have", "been", "write", "sample", "int", "byte", "buffer", "boolean", "long", "written", "for", "a", "given", "track"], "project": "ExoPlayer"}
{"id": 1994, "code": "private void outputPendingMetadataSamples(long sampleTimeUs) {\n  while (!pendingMetadataSampleInfos.isEmpty()) {\n    MetadataSampleInfo metadataSampleInfo = pendingMetadataSampleInfos.removeFirst();\n    pendingMetadataSampleBytes -= metadataSampleInfo.size;\n    long metadataSampleTimeUs = metadataSampleInfo.sampleTimeUs;\n    if (metadataSampleInfo.sampleTimeIsRelative) {\n        \n        \n      metadataSampleTimeUs += sampleTimeUs;\n    }\n    if (timestampAdjuster != null) {\n      metadataSampleTimeUs = timestampAdjuster.adjustSampleTimestamp(metadataSampleTimeUs);\n    }\n    for (TrackOutput emsgTrackOutput : emsgTrackOutputs) {\n      emsgTrackOutput.sampleMetadata(\n          metadataSampleTimeUs,\n          C.BUFFER_FLAG_KEY_FRAME,\n          metadataSampleInfo.size,\n          pendingMetadataSampleBytes,\n          null);\n    }\n  }\n}", "summary_tokens": ["called", "immediately", "after", "outputting", "a", "non", "metadata", "sample", "to", "output", "any", "pending", "metadata", "samples"], "project": "ExoPlayer"}
{"id": 727, "code": "public boolean updateRepeatMode(Timeline timeline, @RepeatMode int repeatMode) {\n  this.repeatMode = repeatMode;\n  return updateForPlaybackModeChange(timeline);\n}", "summary_tokens": ["sets", "the", "repeat", "mode", "and", "returns", "whether", "the", "repeat", "mode", "change", "has", "been", "fully", "handled"], "project": "ExoPlayer"}
{"id": 6, "code": "public boolean removeItem(MediaItem item) {\n  int itemIndex = mediaQueue.indexOf(item);\n  if (itemIndex == -1) {\n    return false;\n  }\n  currentPlayer.removeMediaItem(itemIndex);\n  mediaQueue.remove(itemIndex);\n  if (itemIndex == currentItemIndex && itemIndex == mediaQueue.size()) {\n    maybeSetCurrentItemAndNotify(C.INDEX_UNSET);\n  } else if (itemIndex < currentItemIndex) {\n    maybeSetCurrentItemAndNotify(currentItemIndex - 1);\n  }\n  return true;\n}", "summary_tokens": ["removes", "the", "item", "at", "the", "given", "index", "from", "the", "media", "queue"], "project": "ExoPlayer"}
{"id": 809, "code": "public AudioComponent getAudioComponent() {\n  return this;\n}", "summary_tokens": ["use", "exo", "player", "as", "the", "audio", "component", "methods", "are", "defined", "by", "that", "interface"], "project": "ExoPlayer"}
{"id": 1845, "code": "public static Format parseDtsFormat(\n    byte[] frame,\n    @Nullable String trackId,\n    @Nullable String language,\n    @Nullable DrmInitData drmInitData) {\n  ParsableBitArray frameBits = getNormalizedFrameHeader(frame);\n  frameBits.skipBits(32 + 1 + 5 + 1 + 7 + 14); \n  int amode = frameBits.readBits(6);\n  int channelCount = CHANNELS_BY_AMODE[amode];\n  int sfreq = frameBits.readBits(4);\n  int sampleRate = SAMPLE_RATE_BY_SFREQ[sfreq];\n  int rate = frameBits.readBits(5);\n  int bitrate =\n      rate >= TWICE_BITRATE_KBPS_BY_RATE.length\n          ? Format.NO_VALUE\n          : TWICE_BITRATE_KBPS_BY_RATE[rate] * 1000 / 2;\n  frameBits.skipBits(10); \n  channelCount += frameBits.readBits(2) > 0 ? 1 : 0; \n  return new Format.Builder()\n      .setId(trackId)\n      .setSampleMimeType(MimeTypes.AUDIO_DTS)\n      .setAverageBitrate(bitrate)\n      .setChannelCount(channelCount)\n      .setSampleRate(sampleRate)\n      .setDrmInitData(drmInitData)\n      .setLanguage(language)\n      .build();\n}", "summary_tokens": ["returns", "the", "dts", "format", "given", "data", "containing", "the", "dts", "frame", "according", "to", "etsi", "ts", "0", "0", "subsections", "0"], "project": "ExoPlayer"}
{"id": 2794, "code": "public Renderer[] getRenderers() {\n  return renderers;\n}", "summary_tokens": ["returns", "the", "renderer", "renderers", "that", "have", "been", "set", "with", "set", "renderers", "or", "null", "if", "no", "renderer", "renderers", "have", "been", "explicitly", "set"], "project": "ExoPlayer"}
{"id": 1876, "code": "public synchronized DefaultExtractorsFactory setMp3ExtractorFlags(@Mp3Extractor.Flags int flags) {\n  mp3Flags = flags;\n  return this;\n}", "summary_tokens": ["sets", "flags", "for", "mp", "0", "extractor", "instances", "created", "by", "the", "factory"], "project": "ExoPlayer"}
{"id": 1355, "code": "private long discardSamples(int discardCount) {\n  largestDiscardedTimestampUs =\n      max(largestDiscardedTimestampUs, getLargestTimestamp(discardCount));\n  length -= discardCount;\n  absoluteFirstIndex += discardCount;\n  relativeFirstIndex += discardCount;\n  if (relativeFirstIndex >= capacity) {\n    relativeFirstIndex -= capacity;\n  }\n  readPosition -= discardCount;\n  if (readPosition < 0) {\n    readPosition = 0;\n  }\n  sharedSampleMetadata.discardTo(absoluteFirstIndex);\n\n  if (length == 0) {\n    int relativeLastDiscardIndex = (relativeFirstIndex == 0 ? capacity : relativeFirstIndex) - 1;\n    return offsets[relativeLastDiscardIndex] + sizes[relativeLastDiscardIndex];\n  } else {\n    return offsets[relativeFirstIndex];\n  }\n}", "summary_tokens": ["discards", "the", "specified", "number", "of", "samples"], "project": "ExoPlayer"}
{"id": 8, "code": "public boolean dispatchKeyEvent(KeyEvent event) {\n  return playerView.dispatchKeyEvent(event);\n}", "summary_tokens": ["dispatches", "a", "given", "key", "event", "to", "the", "corresponding", "view", "of", "the", "current", "player"], "project": "ExoPlayer"}
{"id": 794, "code": "public int getMediaItemIndex() {\n  return mediaItemIndex;\n}", "summary_tokens": ["returns", "media", "item", "index", "at", "which", "the", "message", "will", "be", "delivered"], "project": "ExoPlayer"}
{"id": 1725, "code": "public DataSpec subrange(long offset, long length) {\n  if (offset == 0 && this.length == length) {\n    return this;\n  } else {\n    return new DataSpec(\n        uri,\n        uriPositionOffset,\n        httpMethod,\n        httpBody,\n        httpRequestHeaders,\n        position + offset,\n        length,\n        key,\n        flags,\n        customData);\n  }\n}", "summary_tokens": ["returns", "a", "data", "spec", "that", "represents", "a", "subrange", "of", "the", "data", "defined", "by", "this", "data", "spec"], "project": "ExoPlayer"}
{"id": 2786, "code": "public boolean getUseLazyPreparation() {\n  return useLazyPreparation;\n}", "summary_tokens": ["returns", "whether", "the", "player", "will", "use", "lazy", "preparation"], "project": "ExoPlayer"}
{"id": 1822, "code": "private void maybeThrowException() throws E {\n  @Nullable E exception = this.exception;\n  if (exception != null) {\n    throw exception;\n  }\n}", "summary_tokens": ["throws", "a", "decode", "exception", "if", "there", "is", "one"], "project": "ExoPlayer"}
{"id": 2358, "code": "public JSONObject asJsonObject() throws JSONException {\n  JSONObject jsonObject = new JSONObject();\n  if (transformationResult.durationMs != C.LENGTH_UNSET) {\n    jsonObject.put(\"durationMs\", transformationResult.durationMs);\n  }\n  if (transformationResult.fileSizeBytes != C.LENGTH_UNSET) {\n    jsonObject.put(\"fileSizeBytes\", transformationResult.fileSizeBytes);\n  }\n  if (transformationResult.averageAudioBitrate != C.RATE_UNSET_INT) {\n    jsonObject.put(\"averageAudioBitrate\", transformationResult.averageAudioBitrate);\n  }\n  if (transformationResult.averageVideoBitrate != C.RATE_UNSET_INT) {\n    jsonObject.put(\"averageVideoBitrate\", transformationResult.averageVideoBitrate);\n  }\n  if (transformationResult.videoFrameCount > 0) {\n    jsonObject.put(\"videoFrameCount\", transformationResult.videoFrameCount);\n  }\n  if (throughputFps != C.RATE_UNSET) {\n    jsonObject.put(\"throughputFps\", throughputFps);\n  }\n  if (elapsedTimeMs != C.TIME_UNSET) {\n    jsonObject.put(\"elapsedTimeMs\", elapsedTimeMs);\n  }\n  if (ssim != TransformationTestResult.SSIM_UNSET) {\n    jsonObject.put(\"ssim\", ssim);\n  }\n  if (analysisException != null) {\n    jsonObject.put(\"analysisException\", AndroidTestUtil.exceptionAsJsonObject(analysisException));\n  }\n  return jsonObject;\n}", "summary_tokens": ["returns", "a", "jsonobject", "representing", "all", "the", "values", "in", "this"], "project": "ExoPlayer"}
{"id": 900, "code": "default void onDrmSessionReleased(EventTime eventTime) {}", "summary_tokens": ["called", "each", "time", "a", "drm", "session", "is", "released"], "project": "ExoPlayer"}
{"id": 1328, "code": "public void maybeThrowError() throws IOException {\n    \n  if (currentDrmSession != null && currentDrmSession.getState() == DrmSession.STATE_ERROR) {\n    throw Assertions.checkNotNull(currentDrmSession.getError());\n  }\n}", "summary_tokens": ["throws", "an", "error", "that", "s", "preventing", "data", "from", "being", "read"], "project": "ExoPlayer"}
{"id": 1676, "code": "public void release() {\n  released = true;\n  handler.removeCallbacksAndMessages(null);\n}", "summary_tokens": ["release", "this", "emsg", "handler"], "project": "ExoPlayer"}
{"id": 2601, "code": "public boolean getUseController() {\n  return useController;\n}", "summary_tokens": ["returns", "whether", "the", "playback", "controls", "can", "be", "shown"], "project": "ExoPlayer"}
{"id": 2331, "code": "public static RtpPacketStreamDump parse(String jsonString) throws ParserException {\n  try {\n    JSONObject jsonObject = new JSONObject(jsonString);\n    String trackName = jsonObject.getString(\"trackName\");\n    int firstSequenceNumber = jsonObject.getInt(\"firstSequenceNumber\");\n    long firstTimestamp = jsonObject.getLong(\"firstTimestamp\");\n    long transmissionIntervalMs = jsonObject.getLong(\"transmitIntervalMs\");\n    String mediaDescription = jsonObject.getString(\"mediaDescription\");\n\n    ImmutableList.Builder<String> packetsBuilder = new ImmutableList.Builder<>();\n    JSONArray jsonPackets = jsonObject.getJSONArray(\"packets\");\n    for (int i = 0; i < jsonPackets.length(); i++) {\n      packetsBuilder.add(jsonPackets.getString(i));\n    }\n\n    return new RtpPacketStreamDump(\n        trackName,\n        firstSequenceNumber,\n        firstTimestamp,\n        transmissionIntervalMs,\n        mediaDescription,\n        packetsBuilder.build());\n  } catch (JSONException e) {\n    throw ParserException.createForMalformedManifest( null, e);\n  }\n}", "summary_tokens": ["parses", "a", "json", "string", "into", "an", "rtp", "packet", "stream", "dump"], "project": "ExoPlayer"}
{"id": 1927, "code": "public static int iLog(int x) {\n  int val = 0;\n  while (x > 0) {\n    val++;\n    x >>>= 1;\n  }\n  return val;\n}", "summary_tokens": ["returns", "ilog", "x", "which", "is", "the", "index", "of", "the", "highest", "set", "bit", "in", "x"], "project": "ExoPlayer"}
{"id": 2170, "code": "public static int unescapeStream(byte[] data, int limit) {\n  synchronized (scratchEscapePositionsLock) {\n    int position = 0;\n    int scratchEscapeCount = 0;\n    while (position < limit) {\n      position = findNextUnescapeIndex(data, position, limit);\n      if (position < limit) {\n        if (scratchEscapePositions.length <= scratchEscapeCount) {\n            \n          scratchEscapePositions =\n              Arrays.copyOf(scratchEscapePositions, scratchEscapePositions.length * 2);\n        }\n        scratchEscapePositions[scratchEscapeCount++] = position;\n        position += 3;\n      }\n    }\n\n    int unescapedLength = limit - scratchEscapeCount;\n    int escapedPosition = 0; \n    int unescapedPosition = 0; \n    for (int i = 0; i < scratchEscapeCount; i++) {\n      int nextEscapePosition = scratchEscapePositions[i];\n      int copyLength = nextEscapePosition - escapedPosition;\n      System.arraycopy(data, escapedPosition, data, unescapedPosition, copyLength);\n      unescapedPosition += copyLength;\n      data[unescapedPosition++] = 0;\n      data[unescapedPosition++] = 0;\n      escapedPosition += copyLength + 3;\n    }\n\n    int remainingLength = unescapedLength - unescapedPosition;\n    System.arraycopy(data, escapedPosition, data, unescapedPosition, remainingLength);\n    return unescapedLength;\n  }\n}", "summary_tokens": ["unescapes", "data", "up", "to", "the", "specified", "limit", "replacing", "occurrences", "of", "0", "0", "0", "with", "0", "0"], "project": "ExoPlayer"}
{"id": 1335, "code": "public final synchronized boolean isLastSampleQueued() {\n  return isLastSampleQueued;\n}", "summary_tokens": ["returns", "whether", "the", "last", "sample", "of", "the", "stream", "has", "knowingly", "been", "queued"], "project": "ExoPlayer"}
{"id": 2438, "code": "private boolean feedPipelineFromInput() throws TransformationException {\n  @Nullable DecoderInputBuffer samplePipelineInputBuffer = samplePipeline.dequeueInputBuffer();\n  if (samplePipelineInputBuffer == null) {\n    return false;\n  }\n\n  @ReadDataResult\n  int result = readSource(getFormatHolder(), samplePipelineInputBuffer,  0);\n  switch (result) {\n    case C.RESULT_BUFFER_READ:\n      samplePipelineInputBuffer.flip();\n      if (samplePipelineInputBuffer.isEndOfStream()) {\n        samplePipeline.queueInputBuffer();\n        return false;\n      }\n      mediaClock.updateTimeForTrackType(getTrackType(), samplePipelineInputBuffer.timeUs);\n      checkStateNotNull(samplePipelineInputBuffer.data);\n      maybeQueueSampleToPipeline(samplePipelineInputBuffer);\n      return true;\n    case C.RESULT_FORMAT_READ:\n      throw new IllegalStateException(\"Format changes are not supported.\");\n    case C.RESULT_NOTHING_READ:\n    default:\n      return false;\n  }\n}", "summary_tokens": ["attempts", "to", "read", "input", "data", "and", "pass", "the", "input", "data", "to", "the", "sample", "pipeline"], "project": "ExoPlayer"}
{"id": 2014, "code": "public long getSamplePresentationTimeUs(int index) {\n  return samplePresentationTimesUs[index];\n}", "summary_tokens": ["returns", "the", "sample", "presentation", "timestamp", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 2099, "code": "public static IcyHeaders parse(Map<String, List<String>> responseHeaders) {\n  boolean icyHeadersPresent = false;\n  int bitrate = Format.NO_VALUE;\n  String genre = null;\n  String name = null;\n  String url = null;\n  boolean isPublic = false;\n  int metadataInterval = C.LENGTH_UNSET;\n\n  List<String> headers = responseHeaders.get(RESPONSE_HEADER_BITRATE);\n  if (headers != null) {\n    String bitrateHeader = headers.get(0);\n    try {\n      bitrate = Integer.parseInt(bitrateHeader) * 1000;\n      if (bitrate > 0) {\n        icyHeadersPresent = true;\n      } else {\n        Log.w(TAG, \"Invalid bitrate: \" + bitrateHeader);\n        bitrate = Format.NO_VALUE;\n      }\n    } catch (NumberFormatException e) {\n      Log.w(TAG, \"Invalid bitrate header: \" + bitrateHeader);\n    }\n  }\n  headers = responseHeaders.get(RESPONSE_HEADER_GENRE);\n  if (headers != null) {\n    genre = headers.get(0);\n    icyHeadersPresent = true;\n  }\n  headers = responseHeaders.get(RESPONSE_HEADER_NAME);\n  if (headers != null) {\n    name = headers.get(0);\n    icyHeadersPresent = true;\n  }\n  headers = responseHeaders.get(RESPONSE_HEADER_URL);\n  if (headers != null) {\n    url = headers.get(0);\n    icyHeadersPresent = true;\n  }\n  headers = responseHeaders.get(RESPONSE_HEADER_PUB);\n  if (headers != null) {\n    isPublic = headers.get(0).equals(\"1\");\n    icyHeadersPresent = true;\n  }\n  headers = responseHeaders.get(RESPONSE_HEADER_METADATA_INTERVAL);\n  if (headers != null) {\n    String metadataIntervalHeader = headers.get(0);\n    try {\n      metadataInterval = Integer.parseInt(metadataIntervalHeader);\n      if (metadataInterval > 0) {\n        icyHeadersPresent = true;\n      } else {\n        Log.w(TAG, \"Invalid metadata interval: \" + metadataIntervalHeader);\n        metadataInterval = C.LENGTH_UNSET;\n      }\n    } catch (NumberFormatException e) {\n      Log.w(TAG, \"Invalid metadata interval: \" + metadataIntervalHeader);\n    }\n  }\n  return icyHeadersPresent\n      ? new IcyHeaders(bitrate, genre, name, url, isPublic, metadataInterval)\n      : null;\n}", "summary_tokens": ["parses", "icy", "headers", "from", "response", "headers"], "project": "ExoPlayer"}
{"id": 216, "code": "public final boolean hasPreviousWindow() {\n  return hasPreviousMediaItem();\n}", "summary_tokens": ["use", "has", "previous", "media", "item", "instead"], "project": "ExoPlayer"}
{"id": 446, "code": "public static int parseTtmlColor(String colorExpression) {\n  return parseColorInternal(colorExpression, false);\n}", "summary_tokens": ["parses", "a", "ttml", "color", "expression"], "project": "ExoPlayer"}
{"id": 2635, "code": "public SubtitleView getSubtitleView() {\n  return subtitleView;\n}", "summary_tokens": ["gets", "the", "subtitle", "view"], "project": "ExoPlayer"}
{"id": 1155, "code": "protected final void setPendingOutputEndOfStream() {\n  pendingOutputEndOfStream = true;\n}", "summary_tokens": ["notifies", "the", "renderer", "that", "output", "end", "of", "stream", "is", "pending", "and", "should", "be", "handled", "on", "the", "next", "render"], "project": "ExoPlayer"}
{"id": 1991, "code": "private static int parseTrun(\n    TrackBundle trackBundle,\n    int index,\n    @Flags int flags,\n    ParsableByteArray trun,\n    int trackRunStart)\n    throws ParserException {\n  trun.setPosition(Atom.HEADER_SIZE);\n  int fullAtom = trun.readInt();\n  int atomFlags = Atom.parseFullAtomFlags(fullAtom);\n\n  Track track = trackBundle.moovSampleTable.track;\n  TrackFragment fragment = trackBundle.fragment;\n  DefaultSampleValues defaultSampleValues = castNonNull(fragment.header);\n\n  fragment.trunLength[index] = trun.readUnsignedIntToInt();\n  fragment.trunDataPosition[index] = fragment.dataPosition;\n  if ((atomFlags & 0x01 ) != 0) {\n    fragment.trunDataPosition[index] += trun.readInt();\n  }\n\n  boolean firstSampleFlagsPresent = (atomFlags & 0x04 ) != 0;\n  int firstSampleFlags = defaultSampleValues.flags;\n  if (firstSampleFlagsPresent) {\n    firstSampleFlags = trun.readInt();\n  }\n\n  boolean sampleDurationsPresent = (atomFlags & 0x100 ) != 0;\n  boolean sampleSizesPresent = (atomFlags & 0x200 ) != 0;\n  boolean sampleFlagsPresent = (atomFlags & 0x400 ) != 0;\n  boolean sampleCompositionTimeOffsetsPresent =\n      (atomFlags & 0x800 ) != 0;\n\n    \n    \n  long edtsOffset = 0;\n\n    \n    \n  if (track.editListDurations != null\n      && track.editListDurations.length == 1\n      && track.editListDurations[0] == 0) {\n    edtsOffset = castNonNull(track.editListMediaTimes)[0];\n  }\n\n  int[] sampleSizeTable = fragment.sampleSizeTable;\n  long[] samplePresentationTimesUs = fragment.samplePresentationTimesUs;\n  boolean[] sampleIsSyncFrameTable = fragment.sampleIsSyncFrameTable;\n\n  boolean workaroundEveryVideoFrameIsSyncFrame =\n      track.type == C.TRACK_TYPE_VIDEO\n          && (flags & FLAG_WORKAROUND_EVERY_VIDEO_FRAME_IS_SYNC_FRAME) != 0;\n\n  int trackRunEnd = trackRunStart + fragment.trunLength[index];\n  long timescale = track.timescale;\n  long cumulativeTime = fragment.nextFragmentDecodeTime;\n  for (int i = trackRunStart; i < trackRunEnd; i++) {\n      \n    int sampleDuration =\n        checkNonNegative(sampleDurationsPresent ? trun.readInt() : defaultSampleValues.duration);\n    int sampleSize =\n        checkNonNegative(sampleSizesPresent ? trun.readInt() : defaultSampleValues.size);\n    int sampleFlags =\n        sampleFlagsPresent\n            ? trun.readInt()\n            : (i == 0 && firstSampleFlagsPresent) ? firstSampleFlags : defaultSampleValues.flags;\n    int sampleCompositionTimeOffset = 0;\n    if (sampleCompositionTimeOffsetsPresent) {\n        \n        \n        \n        \n        \n      sampleCompositionTimeOffset = trun.readInt();\n    }\n    long samplePresentationTime = cumulativeTime + sampleCompositionTimeOffset - edtsOffset;\n    samplePresentationTimesUs[i] =\n        Util.scaleLargeTimestamp(samplePresentationTime, C.MICROS_PER_SECOND, timescale);\n    if (!fragment.nextFragmentDecodeTimeIncludesMoov) {\n      samplePresentationTimesUs[i] += trackBundle.moovSampleTable.durationUs;\n    }\n    sampleSizeTable[i] = sampleSize;\n    sampleIsSyncFrameTable[i] =\n        ((sampleFlags >> 16) & 0x1) == 0 && (!workaroundEveryVideoFrameIsSyncFrame || i == 0);\n    cumulativeTime += sampleDuration;\n  }\n  fragment.nextFragmentDecodeTime = cumulativeTime;\n  return trackRunEnd;\n}", "summary_tokens": ["parses", "a", "trun", "atom", "defined", "in", "0", "0"], "project": "ExoPlayer"}
{"id": 1239, "code": "private void notifyDownloads(List<Download> downloads) {\n  if (foregroundNotificationUpdater != null) {\n    for (int i = 0; i < downloads.size(); i++) {\n      if (needsStartedService(downloads.get(i).state)) {\n        foregroundNotificationUpdater.startPeriodicUpdates();\n        break;\n      }\n    }\n  }\n}", "summary_tokens": ["called", "after", "the", "service", "is", "created", "once", "the", "downloads", "are", "known"], "project": "ExoPlayer"}
{"id": 2536, "code": "public boolean getControllerHideOnTouch() {\n  return controllerHideOnTouch;\n}", "summary_tokens": ["returns", "whether", "the", "playback", "controls", "are", "hidden", "by", "touch", "events"], "project": "ExoPlayer"}
{"id": 1769, "code": "public boolean removeSpan(CacheSpan span) {\n  if (cachedSpans.remove(span)) {\n    if (span.file != null) {\n      span.file.delete();\n    }\n    return true;\n  }\n  return false;\n}", "summary_tokens": ["removes", "the", "given", "span", "from", "cache"], "project": "ExoPlayer"}
{"id": 2466, "code": "public Player getPlayer() {\n  return player;\n}", "summary_tokens": ["returns", "the", "player", "currently", "being", "controlled", "by", "this", "view", "or", "null", "if", "no", "player", "is", "set"], "project": "ExoPlayer"}
{"id": 2040, "code": "private boolean continueRead(ParsableByteArray source, byte[] target, int targetLength) {\n  int bytesToRead = min(source.bytesLeft(), targetLength - bytesRead);\n  source.readBytes(target, bytesRead, bytesToRead);\n  bytesRead += bytesToRead;\n  return bytesRead == targetLength;\n}", "summary_tokens": ["continues", "a", "read", "from", "the", "provided", "source", "into", "a", "given", "target"], "project": "ExoPlayer"}
{"id": 2474, "code": "public void setShowFastForwardButton(boolean showFastForwardButton) {\n  this.showFastForwardButton = showFastForwardButton;\n  updateNavigation();\n}", "summary_tokens": ["sets", "whether", "the", "fast", "forward", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 1591, "code": "private void writeFormat(Format format) {\n  sampleQueue.format(format);\n}", "summary_tokens": ["writes", "a", "format", "to", "the", "sample", "queue"], "project": "ExoPlayer"}
{"id": 1554, "code": "public CameraMotionListener getCameraMotionListener() {\n  return scene;\n}", "summary_tokens": ["returns", "the", "camera", "motion", "listener", "that", "should", "be", "registered", "during", "playback"], "project": "ExoPlayer"}
{"id": 857, "code": "default void onLoadCompleted(\n    EventTime eventTime, LoadEventInfo loadEventInfo, MediaLoadData mediaLoadData) {}", "summary_tokens": ["called", "when", "a", "media", "source", "completed", "loading", "data"], "project": "ExoPlayer"}
{"id": 723, "code": "private static MediaPeriod createMediaPeriod(\n    MediaPeriodId id,\n    MediaSourceList mediaSourceList,\n    Allocator allocator,\n    long startPositionUs,\n    long endPositionUs) {\n  MediaPeriod mediaPeriod = mediaSourceList.createPeriod(id, allocator, startPositionUs);\n  if (endPositionUs != C.TIME_UNSET) {\n    mediaPeriod =\n        new ClippingMediaPeriod(\n            mediaPeriod,  true,  0, endPositionUs);\n  }\n  return mediaPeriod;\n}", "summary_tokens": ["returns", "a", "media", "period", "corresponding", "to", "the", "given", "id"], "project": "ExoPlayer"}
{"id": 235, "code": "public static synchronized String registeredModules() {\n  return registeredModulesString;\n}", "summary_tokens": ["returns", "a", "string", "consisting", "of", "registered", "module", "names", "separated", "by"], "project": "ExoPlayer"}
{"id": 2319, "code": "private void processSingleNalUnitPacket(ParsableByteArray data) {\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n\n  int numBytesInData = data.bytesLeft();\n  fragmentedSampleSizeBytes += writeStartCode();\n  trackOutput.sampleData(data, numBytesInData);\n  fragmentedSampleSizeBytes += numBytesInData;\n\n  int nalHeaderType = data.getData()[0] & 0x1F;\n  bufferFlags = getBufferFlagsFromNalType(nalHeaderType);\n}", "summary_tokens": ["processes", "single", "nal", "unit", "packet", "rfc", "0", "section", "0"], "project": "ExoPlayer"}
{"id": 1421, "code": "public void setAudioAttributes(AudioAttributes audioAttributes) {\n    \n}", "summary_tokens": ["called", "by", "the", "player", "to", "set", "the", "audio", "attributes", "that", "will", "be", "used", "for", "playback"], "project": "ExoPlayer"}
{"id": 870, "code": "default void onAudioDecoderInitialized(\n    EventTime eventTime, String decoderName, long initializationDurationMs) {}", "summary_tokens": ["use", "on", "audio", "decoder", "initialized", "event", "time", "string", "long", "long"], "project": "ExoPlayer"}
{"id": 1121, "code": "private static final boolean needsRotatedVerticalResolutionWorkaround(String name) {\n  if (\"OMX.MTK.VIDEO.DECODER.HEVC\".equals(name) && \"mcv5a\".equals(Util.DEVICE)) {\n      \n    return false;\n  }\n  return true;\n}", "summary_tokens": ["capabilities", "are", "known", "to", "be", "inaccurately", "reported", "for", "vertical", "resolutions", "on", "some", "devices"], "project": "ExoPlayer"}
{"id": 601, "code": "public static boolean isRepeatModeEnabled(@Player.RepeatMode int repeatMode, int enabledModes) {\n  switch (repeatMode) {\n    case Player.REPEAT_MODE_OFF:\n      return true;\n    case Player.REPEAT_MODE_ONE:\n      return (enabledModes & REPEAT_TOGGLE_MODE_ONE) != 0;\n    case Player.REPEAT_MODE_ALL:\n      return (enabledModes & REPEAT_TOGGLE_MODE_ALL) != 0;\n    default:\n      return false;\n  }\n}", "summary_tokens": ["verifies", "whether", "a", "given", "repeat", "mode", "is", "enabled", "in", "the", "bitmask", "enabled", "modes"], "project": "ExoPlayer"}
{"id": 2501, "code": "public final void setMediaSessionToken(MediaSessionCompat.Token token) {\n  if (!Util.areEqual(this.mediaSessionToken, token)) {\n    mediaSessionToken = token;\n    invalidate();\n  }\n}", "summary_tokens": ["sets", "the", "media", "session", "compat"], "project": "ExoPlayer"}
{"id": 1183, "code": "private static boolean isVendor(android.media.MediaCodecInfo codecInfo) {\n  if (Util.SDK_INT >= 29) {\n    return isVendorV29(codecInfo);\n  }\n  String codecName = Ascii.toLowerCase(codecInfo.getName());\n  return !codecName.startsWith(\"omx.google.\")\n      && !codecName.startsWith(\"c2.android.\")\n      && !codecName.startsWith(\"c2.google.\");\n}", "summary_tokens": ["the", "result", "of", "android"], "project": "ExoPlayer"}
{"id": 204, "code": "public static boolean isAvailable() {\n  return LOADER.isAvailable();\n}", "summary_tokens": ["returns", "whether", "the", "underlying", "library", "is", "available", "loading", "it", "if", "necessary"], "project": "ExoPlayer"}
{"id": 2141, "code": "public static TextEmphasis parse(@Nullable String value) {\n  if (value == null) {\n    return null;\n  }\n\n  String parsingValue = Ascii.toLowerCase(value.trim());\n  if (parsingValue.isEmpty()) {\n    return null;\n  }\n\n  return parseWords(ImmutableSet.copyOf(TextUtils.split(parsingValue, WHITESPACE_PATTERN)));\n}", "summary_tokens": ["parses", "a", "ttml", "a", "href", "https", "www"], "project": "ExoPlayer"}
{"id": 344, "code": "public float getVolume() {\n  return player.getVolume();\n}", "summary_tokens": ["calls", "player", "get", "volume", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2579, "code": "public boolean getShowVrButton() {\n  return controlViewLayoutManager.getShowButton(vrButton);\n}", "summary_tokens": ["returns", "whether", "the", "vr", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 2608, "code": "public boolean dispatchMediaKeyEvent(KeyEvent event) {\n  return useController() && controller.dispatchMediaKeyEvent(event);\n}", "summary_tokens": ["called", "to", "process", "media", "key", "events"], "project": "ExoPlayer"}
{"id": 924, "code": "public long getTotalPlayAndWaitTimeMs() {\n  return getTotalPlayTimeMs() + getTotalWaitTimeMs();\n}", "summary_tokens": ["returns", "the", "total", "time", "spent", "playing", "or", "actively", "waiting", "for", "playback", "in", "milliseconds"], "project": "ExoPlayer"}
{"id": 2382, "code": "public static String findCodecForFormat(MediaFormat format, boolean isDecoder) {\n  MediaCodecList mediaCodecList = new MediaCodecList(MediaCodecList.ALL_CODECS);\n    \n    \n  @Nullable String frameRate = null;\n  if (Util.SDK_INT == 21 && format.containsKey(MediaFormat.KEY_FRAME_RATE)) {\n    frameRate = format.getString(MediaFormat.KEY_FRAME_RATE);\n    format.setString(MediaFormat.KEY_FRAME_RATE, null);\n  }\n\n  String mediaCodecName =\n      isDecoder\n          ? mediaCodecList.findDecoderForFormat(format)\n          : mediaCodecList.findEncoderForFormat(format);\n\n  if (Util.SDK_INT == 21) {\n    MediaFormatUtil.maybeSetString(format, MediaFormat.KEY_FRAME_RATE, frameRate);\n  }\n  return mediaCodecName;\n}", "summary_tokens": ["finds", "a", "media", "codec", "that", "supports", "the", "media", "format", "or", "null", "if", "none", "is", "found"], "project": "ExoPlayer"}
{"id": 2471, "code": "public void removeVisibilityListener(VisibilityListener listener) {\n  visibilityListeners.remove(listener);\n}", "summary_tokens": ["removes", "a", "visibility", "listener"], "project": "ExoPlayer"}
{"id": 488, "code": "public static void focusPlaceholderEglSurface(EGLContext eglContext, EGLDisplay eglDisplay) {\n  EGLSurface eglSurface = createPbufferSurface(eglDisplay,  1,  1);\n  focusEglSurface(eglDisplay, eglContext, eglSurface,  1,  1);\n}", "summary_tokens": ["creates", "and", "focuses", "a", "new", "eglsurface", "wrapping", "a", "0", "x", "0", "pixel", "buffer"], "project": "ExoPlayer"}
{"id": 671, "code": "public DefaultRenderersFactory setExtensionRendererMode(\n    @ExtensionRendererMode int extensionRendererMode) {\n  this.extensionRendererMode = extensionRendererMode;\n  return this;\n}", "summary_tokens": ["sets", "the", "extension", "renderer", "mode", "which", "determines", "if", "and", "how", "available", "extension", "renderers", "are", "used"], "project": "ExoPlayer"}
{"id": 1570, "code": "private static MediaCodec.CodecException createCodecException() throws Exception {\n  Constructor<MediaCodec.CodecException> constructor =\n      MediaCodec.CodecException.class.getDeclaredConstructor(\n          Integer.TYPE, Integer.TYPE, String.class);\n  return constructor.newInstance(\n       0,  0,  \"error from codec\");\n}", "summary_tokens": ["reflectively", "create", "a", "media", "codec"], "project": "ExoPlayer"}
{"id": 265, "code": "public Commands getAvailableCommands() {\n  return player.getAvailableCommands();\n}", "summary_tokens": ["calls", "player", "get", "available", "commands", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2175, "code": "public static SpsData parseSpsNalUnit(byte[] nalData, int nalOffset, int nalLimit) {\n  return parseSpsNalUnitPayload(nalData, nalOffset + 1, nalLimit);\n}", "summary_tokens": ["parses", "a", "sps", "nal", "unit", "using", "the", "syntax", "defined", "in", "itu", "t", "recommendation", "h"], "project": "ExoPlayer"}
{"id": 514, "code": "public static void maybeSetString(MediaFormat format, String key, @Nullable String value) {\n  if (value != null) {\n    format.setString(key, value);\n  }\n}", "summary_tokens": ["sets", "a", "media", "format", "string", "value"], "project": "ExoPlayer"}
{"id": 1880, "code": "public static void checkContainerInput(boolean expression, @Nullable String message)\n    throws ParserException {\n  if (!expression) {\n    throw ParserException.createForMalformedContainer(message,  null);\n  }\n}", "summary_tokens": ["if", "expression", "is", "false", "throws", "a", "parser", "exception", "create", "for", "malformed", "container", "container", "malformed", "parser", "exception", "with", "the", "given", "message"], "project": "ExoPlayer"}
{"id": 2172, "code": "public static boolean isNalUnitSei(@Nullable String mimeType, byte nalUnitHeaderFirstByte) {\n  return (MimeTypes.VIDEO_H264.equals(mimeType)\n          && (nalUnitHeaderFirstByte & 0x1F) == H264_NAL_UNIT_TYPE_SEI)\n      || (MimeTypes.VIDEO_H265.equals(mimeType)\n          && ((nalUnitHeaderFirstByte & 0x7E) >> 1) == H265_NAL_UNIT_TYPE_PREFIX_SEI);\n}", "summary_tokens": ["returns", "whether", "the", "nal", "unit", "with", "the", "specified", "header", "contains", "supplemental", "enhancement", "information"], "project": "ExoPlayer"}
{"id": 1885, "code": "default Extractor[] createExtractors(Uri uri, Map<String, List<String>> responseHeaders) {\n  return createExtractors();\n}", "summary_tokens": ["returns", "an", "array", "of", "new", "extractor", "instances"], "project": "ExoPlayer"}
{"id": 2570, "code": "public void setShowNextButton(boolean showNextButton) {\n  controlViewLayoutManager.setShowButton(nextButton, showNextButton);\n  updateNavigation();\n}", "summary_tokens": ["sets", "whether", "the", "next", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 1774, "code": "public ContentMetadataMutations set(String name, byte[] value) {\n  return checkAndSet(name, Arrays.copyOf(value, value.length));\n}", "summary_tokens": ["adds", "a", "mutation", "to", "set", "a", "metadata", "value"], "project": "ExoPlayer"}
{"id": 897, "code": "default void onDrmSessionManagerError(EventTime eventTime, Exception error) {}", "summary_tokens": ["called", "when", "a", "drm", "error", "occurs"], "project": "ExoPlayer"}
{"id": 2511, "code": "protected List<String> getActions(Player player) {\n  boolean enablePrevious = player.isCommandAvailable(COMMAND_SEEK_TO_PREVIOUS);\n  boolean enableRewind = player.isCommandAvailable(COMMAND_SEEK_BACK);\n  boolean enableFastForward = player.isCommandAvailable(COMMAND_SEEK_FORWARD);\n  boolean enableNext = player.isCommandAvailable(COMMAND_SEEK_TO_NEXT);\n\n  List<String> stringActions = new ArrayList<>();\n  if (usePreviousAction && enablePrevious) {\n    stringActions.add(ACTION_PREVIOUS);\n  }\n  if (useRewindAction && enableRewind) {\n    stringActions.add(ACTION_REWIND);\n  }\n  if (usePlayPauseActions) {\n    if (shouldShowPauseButton(player)) {\n      stringActions.add(ACTION_PAUSE);\n    } else {\n      stringActions.add(ACTION_PLAY);\n    }\n  }\n  if (useFastForwardAction && enableFastForward) {\n    stringActions.add(ACTION_FAST_FORWARD);\n  }\n  if (useNextAction && enableNext) {\n    stringActions.add(ACTION_NEXT);\n  }\n  if (customActionReceiver != null) {\n    stringActions.addAll(customActionReceiver.getCustomActions(player));\n  }\n  if (useStopAction) {\n    stringActions.add(ACTION_STOP);\n  }\n  return stringActions;\n}", "summary_tokens": ["gets", "the", "names", "and", "order", "of", "the", "actions", "to", "be", "included", "in", "the", "notification", "at", "the", "current", "player", "state"], "project": "ExoPlayer"}
{"id": 1555, "code": "public void setDefaultStereoMode(@C.StereoMode int stereoMode) {\n  scene.setDefaultStereoMode(stereoMode);\n}", "summary_tokens": ["sets", "the", "default", "stereo", "mode"], "project": "ExoPlayer"}
{"id": 490, "code": "public static void checkGlError() {\n  int lastError = GLES20.GL_NO_ERROR;\n  int error;\n  while ((error = GLES20.glGetError()) != GLES20.GL_NO_ERROR) {\n    Log.e(TAG, \"glError: \" + gluErrorString(error));\n    lastError = error;\n  }\n  if (lastError != GLES20.GL_NO_ERROR) {\n    throwGlException(\"glError: \" + gluErrorString(lastError));\n  }\n}", "summary_tokens": ["if", "there", "is", "an", "open", "gl", "error", "logs", "the", "error", "and", "if", "gl", "assertions", "enabled", "is", "true", "throws", "a", "gl", "exception"], "project": "ExoPlayer"}
{"id": 1628, "code": "public void selectTracksPreferTrackWithinCapabilitiesOverPreferredLanguage() throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format exceededEnFormat = formatBuilder.setId(\"exceededFormat\").setLanguage(\"eng\").build();\n  Format supportedFrFormat = formatBuilder.setId(\"supportedFormat\").setLanguage(\"fra\").build();\n  TrackGroupArray trackGroups = wrapFormats(exceededEnFormat, supportedFrFormat);\n\n  Map<String, Integer> mappedCapabilities = new HashMap<>();\n  mappedCapabilities.put(exceededEnFormat.id, FORMAT_EXCEEDS_CAPABILITIES);\n  mappedCapabilities.put(supportedFrFormat.id, FORMAT_HANDLED);\n  RendererCapabilities mappedAudioRendererCapabilities =\n      new FakeMappedRendererCapabilities(C.TRACK_TYPE_AUDIO, mappedCapabilities);\n\n  trackSelector.setParameters(defaultParameters.buildUpon().setPreferredAudioLanguage(\"eng\"));\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {mappedAudioRendererCapabilities},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, supportedFrFormat);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "prefer", "tracks", "that", "are", "within", "renderer", "s", "capabilities", "over", "track", "that", "have", "language", "matching", "preferred", "audio", "given", "by", "parameters", "but", "exceed", "renderer", "s", "capabilities"], "project": "ExoPlayer"}
{"id": 1996, "code": "private static DrmInitData getDrmInitDataFromAtoms(List<Atom.LeafAtom> leafChildren) {\n  @Nullable ArrayList<SchemeData> schemeDatas = null;\n  int leafChildrenSize = leafChildren.size();\n  for (int i = 0; i < leafChildrenSize; i++) {\n    LeafAtom child = leafChildren.get(i);\n    if (child.type == Atom.TYPE_pssh) {\n      if (schemeDatas == null) {\n        schemeDatas = new ArrayList<>();\n      }\n      byte[] psshData = child.data.getData();\n      @Nullable UUID uuid = PsshAtomUtil.parseUuid(psshData);\n      if (uuid == null) {\n        Log.w(TAG, \"Skipped pssh atom (failed to extract uuid)\");\n      } else {\n        schemeDatas.add(new SchemeData(uuid, MimeTypes.VIDEO_MP4, psshData));\n      }\n    }\n  }\n  return schemeDatas == null ? null : new DrmInitData(schemeDatas);\n}", "summary_tokens": ["returns", "drm", "init", "data", "from", "leaf", "atoms"], "project": "ExoPlayer"}
{"id": 960, "code": "public boolean supportsEncoding(@C.Encoding int encoding) {\n  return Arrays.binarySearch(supportedEncodings, encoding) >= 0;\n}", "summary_tokens": ["returns", "whether", "this", "device", "supports", "playback", "of", "the", "specified", "audio", "encoding"], "project": "ExoPlayer"}
{"id": 217, "code": "public final void previous() {\n  seekToPreviousMediaItem();\n}", "summary_tokens": ["use", "seek", "to", "previous", "media", "item", "instead"], "project": "ExoPlayer"}
{"id": 1788, "code": "private void addSpan(SimpleCacheSpan span) {\n  contentIndex.getOrAdd(span.key).addSpan(span);\n  totalSpace += span.length;\n  notifySpanAdded(span);\n}", "summary_tokens": ["adds", "a", "cached", "span", "to", "the", "in", "memory", "representation"], "project": "ExoPlayer"}
{"id": 1626, "code": "public void selectTracksWithNoTrackWithinCapabilitiesAndSetByParamsReturnNoSelection()\n    throws Exception {\n  TrackGroupArray trackGroups = singleTrackGroup(AUDIO_FORMAT);\n\n  trackSelector.setParameters(\n      defaultParameters.buildUpon().setExceedRendererCapabilitiesIfNecessary(false));\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_EXCEEDED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertNoSelection(result.selections[0]);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "return", "a", "null", "track", "selection", "for", "a", "renderer", "when", "all", "tracks", "exceed", "that", "renderer", "s", "capabilities", "when", "parameters", "does", "not", "allow", "exceeding", "capabilities", "tracks"], "project": "ExoPlayer"}
{"id": 443, "code": "public static byte[][] splitNalUnits(byte[] data) {\n  if (!isNalStartCode(data, 0)) {\n      \n    return null;\n  }\n  List<Integer> starts = new ArrayList<>();\n  int nalUnitIndex = 0;\n  do {\n    starts.add(nalUnitIndex);\n    nalUnitIndex = findNalStartCode(data, nalUnitIndex + NAL_START_CODE.length);\n  } while (nalUnitIndex != C.INDEX_UNSET);\n  byte[][] split = new byte[starts.size()][];\n  for (int i = 0; i < starts.size(); i++) {\n    int startIndex = starts.get(i);\n    int endIndex = i < starts.size() - 1 ? starts.get(i + 1) : data.length;\n    byte[] nal = new byte[endIndex - startIndex];\n    System.arraycopy(data, startIndex, nal, 0, nal.length);\n    split[i] = nal;\n  }\n  return split;\n}", "summary_tokens": ["splits", "an", "array", "of", "nal", "units"], "project": "ExoPlayer"}
{"id": 1502, "code": "protected void updateVideoFrameProcessingOffsetCounters(long processingOffsetUs) {\n  decoderCounters.addVideoFrameProcessingOffset(processingOffsetUs);\n  totalVideoFrameProcessingOffsetUs += processingOffsetUs;\n  videoFrameProcessingOffsetCount++;\n}", "summary_tokens": ["updates", "local", "counters", "and", "decoder", "counters", "with", "a", "new", "video", "frame", "processing", "offset"], "project": "ExoPlayer"}
{"id": 962, "code": "public boolean isPassthroughPlaybackSupported(Format format) {\n  return getEncodingAndChannelConfigForPassthrough(format) != null;\n}", "summary_tokens": ["returns", "whether", "the", "device", "can", "do", "passthrough", "playback", "for", "format"], "project": "ExoPlayer"}
{"id": 124, "code": "public ImaServerSideAdInsertionUriBuilder setApiKey(@Nullable String apiKey) {\n  this.apiKey = apiKey;\n  return this;\n}", "summary_tokens": ["the", "stream", "request", "api", "key"], "project": "ExoPlayer"}
{"id": 1947, "code": "private static Double readAmfDouble(ParsableByteArray data) {\n  return Double.longBitsToDouble(data.readLong());\n}", "summary_tokens": ["read", "a", "double", "number", "from", "an", "amf", "encoded", "buffer"], "project": "ExoPlayer"}
{"id": 689, "code": "public static ExoPlaybackException createForUnexpected(\n    RuntimeException cause, @ErrorCode int errorCode) {\n  return new ExoPlaybackException(TYPE_UNEXPECTED, cause, errorCode);\n}", "summary_tokens": ["creates", "an", "instance", "of", "type", "type", "unexpected"], "project": "ExoPlayer"}
{"id": 1340, "code": "public final synchronized int getSkipCount(long timeUs, boolean allowEndOfQueue) {\n  int relativeReadIndex = getRelativeIndex(readPosition);\n  if (!hasNextSample() || timeUs < timesUs[relativeReadIndex]) {\n    return 0;\n  }\n  if (timeUs > largestQueuedTimestampUs && allowEndOfQueue) {\n    return length - readPosition;\n  }\n  int offset =\n      findSampleBefore(relativeReadIndex, length - readPosition, timeUs,  true);\n  if (offset == -1) {\n    return 0;\n  }\n  return offset;\n}", "summary_tokens": ["returns", "the", "number", "of", "samples", "that", "need", "to", "be", "skip", "int", "skipped", "to", "advance", "the", "read", "position", "to", "the", "keyframe", "before", "or", "at", "the", "specified", "time"], "project": "ExoPlayer"}
{"id": 705, "code": "public long getRendererOffset() {\n  return rendererPositionOffsetUs;\n}", "summary_tokens": ["returns", "the", "renderer", "time", "of", "the", "start", "of", "the", "period", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 823, "code": "public void setVolume(int volume) {\n  if (volume < getMinVolume() || volume > getMaxVolume()) {\n    return;\n  }\n  audioManager.setStreamVolume(streamType, volume, VOLUME_FLAGS);\n  updateVolumeAndNotifyIfChanged();\n}", "summary_tokens": ["sets", "the", "volume", "with", "the", "given", "value", "for", "the", "current", "audio", "stream"], "project": "ExoPlayer"}
{"id": 1970, "code": "private static Pair<Long, Long> linearlyInterpolate(\n    long x, long[] xReferences, long[] yReferences) {\n  int previousReferenceIndex =\n      Util.binarySearchFloor(xReferences, x,  true,  true);\n  long xPreviousReference = xReferences[previousReferenceIndex];\n  long yPreviousReference = yReferences[previousReferenceIndex];\n  int nextReferenceIndex = previousReferenceIndex + 1;\n  if (nextReferenceIndex == xReferences.length) {\n    return Pair.create(xPreviousReference, yPreviousReference);\n  } else {\n    long xNextReference = xReferences[nextReferenceIndex];\n    long yNextReference = yReferences[nextReferenceIndex];\n    double proportion =\n        xNextReference == xPreviousReference\n            ? 0.0\n            : ((double) x - xPreviousReference) / (xNextReference - xPreviousReference);\n    long y = (long) (proportion * (yNextReference - yPreviousReference)) + yPreviousReference;\n    return Pair.create(x, y);\n  }\n}", "summary_tokens": ["given", "a", "set", "of", "reference", "points", "as", "coordinates", "in", "x", "references", "and", "y", "references", "and", "an", "x", "axis", "value", "linearly", "interpolates", "between", "corresponding", "reference", "points", "to", "give", "a", "y", "axis", "value"], "project": "ExoPlayer"}
{"id": 2030, "code": "private static boolean peekPacketStartsWith(ParsableByteArray packet, byte[] expectedPrefix) {\n  if (packet.bytesLeft() < expectedPrefix.length) {\n    return false;\n  }\n  int startPosition = packet.getPosition();\n  byte[] header = new byte[expectedPrefix.length];\n  packet.readBytes(header, 0, expectedPrefix.length);\n  packet.setPosition(startPosition);\n  return Arrays.equals(header, expectedPrefix);\n}", "summary_tokens": ["returns", "true", "if", "the", "given", "parsable", "byte", "array", "starts", "with", "expected", "prefix"], "project": "ExoPlayer"}
{"id": 966, "code": "public void unregister() {\n  if (!registered) {\n    return;\n  }\n  audioCapabilities = null;\n  if (receiver != null) {\n    context.unregisterReceiver(receiver);\n  }\n  if (externalSurroundSoundSettingObserver != null) {\n    externalSurroundSoundSettingObserver.unregister();\n  }\n  registered = false;\n}", "summary_tokens": ["unregisters", "the", "receiver", "meaning", "it", "will", "no", "longer", "notify", "the", "listener", "when", "audio", "capability", "changes", "occur"], "project": "ExoPlayer"}
{"id": 244, "code": "public Format copyWithMetadata(@Nullable Metadata metadata) {\n  return buildUpon().setMetadata(metadata).build();\n}", "summary_tokens": ["use", "build", "upon", "and", "builder", "set", "metadata", "metadata"], "project": "ExoPlayer"}
{"id": 1310, "code": "private void clearAllocationNodes(AllocationNode fromNode) {\n  if (fromNode.allocation == null) {\n    return;\n  }\n    \n    \n    \n  allocator.release(fromNode);\n  fromNode.clear();\n}", "summary_tokens": ["clears", "allocation", "nodes", "starting", "from", "from", "node"], "project": "ExoPlayer"}
{"id": 1571, "code": "private static MediaCodec.CodecException createCodecException() throws Exception {\n  Constructor<MediaCodec.CodecException> constructor =\n      MediaCodec.CodecException.class.getDeclaredConstructor(\n          Integer.TYPE, Integer.TYPE, String.class);\n  return constructor.newInstance(\n       0,  0,  \"error from codec\");\n}", "summary_tokens": ["reflectively", "create", "a", "media", "codec"], "project": "ExoPlayer"}
{"id": 2659, "code": "public TrackSelectionDialogBuilder setOverride(@Nullable TrackSelectionOverride override) {\n  return setOverrides(\n      override == null\n          ? Collections.emptyMap()\n          : ImmutableMap.of(override.mediaTrackGroup, override));\n}", "summary_tokens": ["sets", "the", "single", "initial", "override"], "project": "ExoPlayer"}
{"id": 54, "code": "private static @RepeatMode int fetchRepeatMode(RemoteMediaClient remoteMediaClient) {\n  MediaStatus mediaStatus = remoteMediaClient.getMediaStatus();\n  if (mediaStatus == null) {\n      \n    return REPEAT_MODE_OFF;\n  }\n  int castRepeatMode = mediaStatus.getQueueRepeatMode();\n  switch (castRepeatMode) {\n    case MediaStatus.REPEAT_MODE_REPEAT_SINGLE:\n      return REPEAT_MODE_ONE;\n    case MediaStatus.REPEAT_MODE_REPEAT_ALL:\n    case MediaStatus.REPEAT_MODE_REPEAT_ALL_AND_SHUFFLE:\n      return REPEAT_MODE_ALL;\n    case MediaStatus.REPEAT_MODE_REPEAT_OFF:\n      return REPEAT_MODE_OFF;\n    default:\n      throw new IllegalStateException();\n  }\n}", "summary_tokens": ["retrieves", "the", "repeat", "mode", "from", "remote", "media", "client", "and", "maps", "it", "into", "a", "player"], "project": "ExoPlayer"}
{"id": 1448, "code": "public Uri getUri() {\n  return dataSource.getLastOpenedUri();\n}", "summary_tokens": ["returns", "the", "uri", "from", "which", "data", "was", "read"], "project": "ExoPlayer"}
{"id": 904, "code": "protected final EventTime generateCurrentPlayerMediaPeriodEventTime() {\n  return generateEventTime(mediaPeriodQueueTracker.getCurrentPlayerMediaPeriod());\n}", "summary_tokens": ["generates", "an", "event", "time", "for", "the", "currently", "playing", "item", "in", "the", "player"], "project": "ExoPlayer"}
{"id": 1064, "code": "default void prepare() {\n    \n}", "summary_tokens": ["acquires", "any", "required", "resources"], "project": "ExoPlayer"}
{"id": 661, "code": "protected final @ReadDataResult int readSource(\n    FormatHolder formatHolder, DecoderInputBuffer buffer, @ReadFlags int readFlags) {\n  @ReadDataResult\n  int result = Assertions.checkNotNull(stream).readData(formatHolder, buffer, readFlags);\n  if (result == C.RESULT_BUFFER_READ) {\n    if (buffer.isEndOfStream()) {\n      readingPositionUs = C.TIME_END_OF_SOURCE;\n      return streamIsFinal ? C.RESULT_BUFFER_READ : C.RESULT_NOTHING_READ;\n    }\n    buffer.timeUs += streamOffsetUs;\n    readingPositionUs = max(readingPositionUs, buffer.timeUs);\n  } else if (result == C.RESULT_FORMAT_READ) {\n    Format format = Assertions.checkNotNull(formatHolder.format);\n    if (format.subsampleOffsetUs != Format.OFFSET_SAMPLE_RELATIVE) {\n      format =\n          format\n              .buildUpon()\n              .setSubsampleOffsetUs(format.subsampleOffsetUs + streamOffsetUs)\n              .build();\n      formatHolder.format = format;\n    }\n  }\n  return result;\n}", "summary_tokens": ["reads", "from", "the", "enabled", "upstream", "source"], "project": "ExoPlayer"}
{"id": 2042, "code": "private void parseHeader() {\n  headerScratchBits.setPosition(0);\n  SyncFrameInfo frameInfo = Ac4Util.parseAc4SyncframeInfo(headerScratchBits);\n  if (format == null\n      || frameInfo.channelCount != format.channelCount\n      || frameInfo.sampleRate != format.sampleRate\n      || !MimeTypes.AUDIO_AC4.equals(format.sampleMimeType)) {\n    format =\n        new Format.Builder()\n            .setId(formatId)\n            .setSampleMimeType(MimeTypes.AUDIO_AC4)\n            .setChannelCount(frameInfo.channelCount)\n            .setSampleRate(frameInfo.sampleRate)\n            .setLanguage(language)\n            .build();\n    output.format(format);\n  }\n  sampleSize = frameInfo.frameSize;\n    \n    \n  sampleDurationUs = C.MICROS_PER_SECOND * frameInfo.sampleCount / format.sampleRate;\n}", "summary_tokens": ["parses", "the", "sample", "header"], "project": "ExoPlayer"}
{"id": 328, "code": "public long getTotalBufferedDuration() {\n  return player.getTotalBufferedDuration();\n}", "summary_tokens": ["calls", "player", "get", "total", "buffered", "duration", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2650, "code": "public void setUserDefaultStyle() {\n  setStyle(getUserCaptionStyle());\n}", "summary_tokens": ["styles", "the", "captions", "using", "captioning", "manager", "get", "user", "style", "if", "captioning", "manager", "is", "available", "and", "enabled"], "project": "ExoPlayer"}
{"id": 2200, "code": "private void insertTableSection(int offset, byte tableId, int sectionLength) {\n  packetPayload[offset++] = tableId;\n  packetPayload[offset++] = (byte) ((sectionLength >> 8) & 0x0F);\n  packetPayload[offset] = (byte) (sectionLength & 0xFF);\n}", "summary_tokens": ["inserts", "a", "private", "section", "header", "to", "packet", "payload"], "project": "ExoPlayer"}
{"id": 266, "code": "public void prepare() {\n  player.prepare();\n}", "summary_tokens": ["calls", "player", "prepare", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1680, "code": "public int getAdaptationSetIndex(int type) {\n  int adaptationCount = adaptationSets.size();\n  for (int i = 0; i < adaptationCount; i++) {\n    if (adaptationSets.get(i).type == type) {\n      return i;\n    }\n  }\n  return C.INDEX_UNSET;\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "first", "adaptation", "set", "of", "a", "given", "type", "or", "c", "index", "unset", "if", "no", "adaptation", "set", "of", "the", "specified", "type", "exists"], "project": "ExoPlayer"}
{"id": 284, "code": "public long getSeekForwardIncrement() {\n  return player.getSeekForwardIncrement();\n}", "summary_tokens": ["calls", "player", "get", "seek", "forward", "increment", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 317, "code": "public int getNextWindowIndex() {\n  return player.getNextWindowIndex();\n}", "summary_tokens": ["calls", "player", "get", "next", "window", "index", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2610, "code": "public void showController() {\n  showController(shouldShowControllerIndefinitely());\n}", "summary_tokens": ["shows", "the", "playback", "controls"], "project": "ExoPlayer"}
{"id": 2598, "code": "public void setUseArtwork(boolean useArtwork) {\n  Assertions.checkState(!useArtwork || artworkView != null);\n  if (this.useArtwork != useArtwork) {\n    this.useArtwork = useArtwork;\n    updateForCurrentTrackSelections( false);\n  }\n}", "summary_tokens": ["sets", "whether", "artwork", "is", "displayed", "if", "present", "in", "the", "media"], "project": "ExoPlayer"}
{"id": 1420, "code": "public boolean isSetParametersSupported() {\n  return false;\n}", "summary_tokens": ["returns", "if", "this", "track", "selector", "supports", "set", "parameters", "track", "selection", "parameters"], "project": "ExoPlayer"}
{"id": 978, "code": "public boolean maybePollTimestamp(long systemTimeUs) {\n  if (audioTimestamp == null || (systemTimeUs - lastTimestampSampleTimeUs) < sampleIntervalUs) {\n    return false;\n  }\n  lastTimestampSampleTimeUs = systemTimeUs;\n  boolean updatedTimestamp = audioTimestamp.maybeUpdateTimestamp();\n  switch (state) {\n    case STATE_INITIALIZING:\n      if (updatedTimestamp) {\n        if (audioTimestamp.getTimestampSystemTimeUs() >= initializeSystemTimeUs) {\n            \n          initialTimestampPositionFrames = audioTimestamp.getTimestampPositionFrames();\n          updateState(STATE_TIMESTAMP);\n        } else {\n            \n          updatedTimestamp = false;\n        }\n      } else if (systemTimeUs - initializeSystemTimeUs > INITIALIZING_DURATION_US) {\n          \n          \n          \n          \n        updateState(STATE_NO_TIMESTAMP);\n      }\n      break;\n    case STATE_TIMESTAMP:\n      if (updatedTimestamp) {\n        long timestampPositionFrames = audioTimestamp.getTimestampPositionFrames();\n        if (timestampPositionFrames > initialTimestampPositionFrames) {\n          updateState(STATE_TIMESTAMP_ADVANCING);\n        }\n      } else {\n        reset();\n      }\n      break;\n    case STATE_TIMESTAMP_ADVANCING:\n      if (!updatedTimestamp) {\n          \n        reset();\n      }\n      break;\n    case STATE_NO_TIMESTAMP:\n      if (updatedTimestamp) {\n          \n        reset();\n      }\n      break;\n    case STATE_ERROR:\n        \n      break;\n    default:\n      throw new IllegalStateException();\n  }\n  return updatedTimestamp;\n}", "summary_tokens": ["polls", "the", "timestamp", "if", "required", "and", "returns", "whether", "it", "was", "updated"], "project": "ExoPlayer"}
{"id": 906, "code": "public static PlaybackStats merge(PlaybackStats... playbackStats) {\n  int playbackCount = 0;\n  long[] playbackStateDurationsMs = new long[PLAYBACK_STATE_COUNT];\n  long firstReportedTimeMs = C.TIME_UNSET;\n  int foregroundPlaybackCount = 0;\n  int abandonedBeforeReadyCount = 0;\n  int endedCount = 0;\n  int backgroundJoiningCount = 0;\n  long totalValidJoinTimeMs = C.TIME_UNSET;\n  int validJoinTimeCount = 0;\n  int totalPauseCount = 0;\n  int totalPauseBufferCount = 0;\n  int totalSeekCount = 0;\n  int totalRebufferCount = 0;\n  long maxRebufferTimeMs = C.TIME_UNSET;\n  int adPlaybackCount = 0;\n  long totalVideoFormatHeightTimeMs = 0;\n  long totalVideoFormatHeightTimeProduct = 0;\n  long totalVideoFormatBitrateTimeMs = 0;\n  long totalVideoFormatBitrateTimeProduct = 0;\n  long totalAudioFormatTimeMs = 0;\n  long totalAudioFormatBitrateTimeProduct = 0;\n  int initialVideoFormatHeightCount = 0;\n  int initialVideoFormatBitrateCount = 0;\n  int totalInitialVideoFormatHeight = C.LENGTH_UNSET;\n  long totalInitialVideoFormatBitrate = C.LENGTH_UNSET;\n  int initialAudioFormatBitrateCount = 0;\n  long totalInitialAudioFormatBitrate = C.LENGTH_UNSET;\n  long totalBandwidthTimeMs = 0;\n  long totalBandwidthBytes = 0;\n  long totalDroppedFrames = 0;\n  long totalAudioUnderruns = 0;\n  int fatalErrorPlaybackCount = 0;\n  int fatalErrorCount = 0;\n  int nonFatalErrorCount = 0;\n  for (PlaybackStats stats : playbackStats) {\n    playbackCount += stats.playbackCount;\n    for (int i = 0; i < PLAYBACK_STATE_COUNT; i++) {\n      playbackStateDurationsMs[i] += stats.playbackStateDurationsMs[i];\n    }\n    if (firstReportedTimeMs == C.TIME_UNSET) {\n      firstReportedTimeMs = stats.firstReportedTimeMs;\n    } else if (stats.firstReportedTimeMs != C.TIME_UNSET) {\n      firstReportedTimeMs = min(firstReportedTimeMs, stats.firstReportedTimeMs);\n    }\n    foregroundPlaybackCount += stats.foregroundPlaybackCount;\n    abandonedBeforeReadyCount += stats.abandonedBeforeReadyCount;\n    endedCount += stats.endedCount;\n    backgroundJoiningCount += stats.backgroundJoiningCount;\n    if (totalValidJoinTimeMs == C.TIME_UNSET) {\n      totalValidJoinTimeMs = stats.totalValidJoinTimeMs;\n    } else if (stats.totalValidJoinTimeMs != C.TIME_UNSET) {\n      totalValidJoinTimeMs += stats.totalValidJoinTimeMs;\n    }\n    validJoinTimeCount += stats.validJoinTimeCount;\n    totalPauseCount += stats.totalPauseCount;\n    totalPauseBufferCount += stats.totalPauseBufferCount;\n    totalSeekCount += stats.totalSeekCount;\n    totalRebufferCount += stats.totalRebufferCount;\n    if (maxRebufferTimeMs == C.TIME_UNSET) {\n      maxRebufferTimeMs = stats.maxRebufferTimeMs;\n    } else if (stats.maxRebufferTimeMs != C.TIME_UNSET) {\n      maxRebufferTimeMs = max(maxRebufferTimeMs, stats.maxRebufferTimeMs);\n    }\n    adPlaybackCount += stats.adPlaybackCount;\n    totalVideoFormatHeightTimeMs += stats.totalVideoFormatHeightTimeMs;\n    totalVideoFormatHeightTimeProduct += stats.totalVideoFormatHeightTimeProduct;\n    totalVideoFormatBitrateTimeMs += stats.totalVideoFormatBitrateTimeMs;\n    totalVideoFormatBitrateTimeProduct += stats.totalVideoFormatBitrateTimeProduct;\n    totalAudioFormatTimeMs += stats.totalAudioFormatTimeMs;\n    totalAudioFormatBitrateTimeProduct += stats.totalAudioFormatBitrateTimeProduct;\n    initialVideoFormatHeightCount += stats.initialVideoFormatHeightCount;\n    initialVideoFormatBitrateCount += stats.initialVideoFormatBitrateCount;\n    if (totalInitialVideoFormatHeight == C.LENGTH_UNSET) {\n      totalInitialVideoFormatHeight = stats.totalInitialVideoFormatHeight;\n    } else if (stats.totalInitialVideoFormatHeight != C.LENGTH_UNSET) {\n      totalInitialVideoFormatHeight += stats.totalInitialVideoFormatHeight;\n    }\n    if (totalInitialVideoFormatBitrate == C.LENGTH_UNSET) {\n      totalInitialVideoFormatBitrate = stats.totalInitialVideoFormatBitrate;\n    } else if (stats.totalInitialVideoFormatBitrate != C.LENGTH_UNSET) {\n      totalInitialVideoFormatBitrate += stats.totalInitialVideoFormatBitrate;\n    }\n    initialAudioFormatBitrateCount += stats.initialAudioFormatBitrateCount;\n    if (totalInitialAudioFormatBitrate == C.LENGTH_UNSET) {\n      totalInitialAudioFormatBitrate = stats.totalInitialAudioFormatBitrate;\n    } else if (stats.totalInitialAudioFormatBitrate != C.LENGTH_UNSET) {\n      totalInitialAudioFormatBitrate += stats.totalInitialAudioFormatBitrate;\n    }\n    totalBandwidthTimeMs += stats.totalBandwidthTimeMs;\n    totalBandwidthBytes += stats.totalBandwidthBytes;\n    totalDroppedFrames += stats.totalDroppedFrames;\n    totalAudioUnderruns += stats.totalAudioUnderruns;\n    fatalErrorPlaybackCount += stats.fatalErrorPlaybackCount;\n    fatalErrorCount += stats.fatalErrorCount;\n    nonFatalErrorCount += stats.nonFatalErrorCount;\n  }\n  return new PlaybackStats(\n      playbackCount,\n      playbackStateDurationsMs,\n       Collections.emptyList(),\n       Collections.emptyList(),\n      firstReportedTimeMs,\n      foregroundPlaybackCount,\n      abandonedBeforeReadyCount,\n      endedCount,\n      backgroundJoiningCount,\n      totalValidJoinTimeMs,\n      validJoinTimeCount,\n      totalPauseCount,\n      totalPauseBufferCount,\n      totalSeekCount,\n      totalRebufferCount,\n      maxRebufferTimeMs,\n      adPlaybackCount,\n       Collections.emptyList(),\n       Collections.emptyList(),\n      totalVideoFormatHeightTimeMs,\n      totalVideoFormatHeightTimeProduct,\n      totalVideoFormatBitrateTimeMs,\n      totalVideoFormatBitrateTimeProduct,\n      totalAudioFormatTimeMs,\n      totalAudioFormatBitrateTimeProduct,\n      initialVideoFormatHeightCount,\n      initialVideoFormatBitrateCount,\n      totalInitialVideoFormatHeight,\n      totalInitialVideoFormatBitrate,\n      initialAudioFormatBitrateCount,\n      totalInitialAudioFormatBitrate,\n      totalBandwidthTimeMs,\n      totalBandwidthBytes,\n      totalDroppedFrames,\n      totalAudioUnderruns,\n      fatalErrorPlaybackCount,\n      fatalErrorCount,\n      nonFatalErrorCount,\n       Collections.emptyList(),\n       Collections.emptyList());\n}", "summary_tokens": ["returns", "the", "combined", "playback", "stats", "for", "all", "input", "playback", "stats"], "project": "ExoPlayer"}
{"id": 736, "code": "public MediaPeriodHolder getReadingPeriod() {\n  return reading;\n}", "summary_tokens": ["returns", "the", "reading", "period", "holder", "or", "null", "if", "the", "queue", "is", "empty"], "project": "ExoPlayer"}
{"id": 2162, "code": "private static void applyDefaultColors(\n    SpannableStringBuilder text, Set<String> classes, int start, int end) {\n  for (String className : classes) {\n    if (DEFAULT_TEXT_COLORS.containsKey(className)) {\n      int color = DEFAULT_TEXT_COLORS.get(className);\n      text.setSpan(new ForegroundColorSpan(color), start, end, Spanned.SPAN_EXCLUSIVE_EXCLUSIVE);\n    } else if (DEFAULT_BACKGROUND_COLORS.containsKey(className)) {\n      int color = DEFAULT_BACKGROUND_COLORS.get(className);\n      text.setSpan(new BackgroundColorSpan(color), start, end, Spanned.SPAN_EXCLUSIVE_EXCLUSIVE);\n    }\n  }\n}", "summary_tokens": ["adds", "foreground", "color", "span", "s", "and", "background", "color", "span", "s", "to", "text", "for", "entries", "in", "classes", "that", "match", "web", "vtt", "s", "a", "href", "https", "www"], "project": "ExoPlayer"}
{"id": 1908, "code": "public Format getFormat(byte[] streamMarkerAndInfoBlock, @Nullable Metadata id3Metadata) {\n    \n  streamMarkerAndInfoBlock[4] = (byte) 0x80;\n  int maxInputSize = maxFrameSize > 0 ? maxFrameSize : Format.NO_VALUE;\n  @Nullable Metadata metadataWithId3 = getMetadataCopyWithAppendedEntriesFrom(id3Metadata);\n  return new Format.Builder()\n      .setSampleMimeType(MimeTypes.AUDIO_FLAC)\n      .setMaxInputSize(maxInputSize)\n      .setChannelCount(channels)\n      .setSampleRate(sampleRate)\n      .setInitializationData(Collections.singletonList(streamMarkerAndInfoBlock))\n      .setMetadata(metadataWithId3)\n      .build();\n}", "summary_tokens": ["returns", "a", "format", "extracted", "from", "the", "flac", "stream", "metadata"], "project": "ExoPlayer"}
{"id": 2475, "code": "public void setShowPreviousButton(boolean showPreviousButton) {\n  this.showPreviousButton = showPreviousButton;\n  updateNavigation();\n}", "summary_tokens": ["sets", "whether", "the", "previous", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 562, "code": "public void setPosition(int position) {\n    \n  Assertions.checkArgument(position >= 0 && position <= limit);\n  this.position = position;\n}", "summary_tokens": ["sets", "the", "reading", "offset", "in", "the", "array"], "project": "ExoPlayer"}
{"id": 1383, "code": "public final Uri getUri() {\n  return dataSource.getLastOpenedUri();\n}", "summary_tokens": ["returns", "the", "uri", "associated", "with", "the", "last", "data", "source", "open", "call"], "project": "ExoPlayer"}
{"id": 1899, "code": "public static void readStreamMarker(ExtractorInput input) throws IOException {\n  ParsableByteArray scratch = new ParsableByteArray(FlacConstants.STREAM_MARKER_SIZE);\n  input.readFully(scratch.getData(), 0, FlacConstants.STREAM_MARKER_SIZE);\n  if (scratch.readUnsignedInt() != STREAM_MARKER) {\n    throw ParserException.createForMalformedContainer(\n        \"Failed to read FLAC stream marker.\",  null);\n  }\n}", "summary_tokens": ["reads", "the", "flac", "stream", "marker"], "project": "ExoPlayer"}
{"id": 2219, "code": "public byte[] put(Uri uri, byte[] encryptionKey) {\n  return backingMap.put(Assertions.checkNotNull(uri), Assertions.checkNotNull(encryptionKey));\n}", "summary_tokens": ["inserts", "an", "entry", "into", "the", "cache"], "project": "ExoPlayer"}
{"id": 2019, "code": "private void skipToPageOfTargetGranule(ExtractorInput input) throws IOException {\n  while (true) {\n      \n      \n    pageHeader.skipToNextPage(input);\n    pageHeader.populate(input,  false);\n    if (pageHeader.granulePosition > targetGranule) {\n      break;\n    }\n    input.skipFully(pageHeader.headerSize + pageHeader.bodySize);\n    start = input.getPosition();\n    startGranule = pageHeader.granulePosition;\n  }\n  input.resetPeekPosition();\n}", "summary_tokens": ["skips", "forward", "to", "the", "start", "of", "the", "page", "containing", "the", "target", "granule"], "project": "ExoPlayer"}
{"id": 408, "code": "public boolean isAd() {\n  return adGroupIndex != C.INDEX_UNSET;\n}", "summary_tokens": ["returns", "whether", "this", "period", "identifier", "identifies", "an", "ad", "in", "an", "ad", "group", "in", "a", "period"], "project": "ExoPlayer"}
{"id": 999, "code": "protected AudioFormat onConfigure(AudioFormat inputAudioFormat)\n    throws UnhandledAudioFormatException {\n  return AudioFormat.NOT_SET;\n}", "summary_tokens": ["called", "when", "the", "processor", "is", "configured", "for", "a", "new", "input", "format"], "project": "ExoPlayer"}
{"id": 1851, "code": "public static List<byte[]> buildInitializationData(byte[] header) {\n  int preSkipSamples = getPreSkipSamples(header);\n  long preSkipNanos = sampleCountToNanoseconds(preSkipSamples);\n  long seekPreRollNanos = sampleCountToNanoseconds(DEFAULT_SEEK_PRE_ROLL_SAMPLES);\n\n  List<byte[]> initializationData = new ArrayList<>(FULL_CODEC_INITIALIZATION_DATA_BUFFER_COUNT);\n  initializationData.add(header);\n  initializationData.add(buildNativeOrderByteArray(preSkipNanos));\n  initializationData.add(buildNativeOrderByteArray(seekPreRollNanos));\n  return initializationData;\n}", "summary_tokens": ["builds", "codec", "initialization", "data", "from", "an", "opus", "identification", "header"], "project": "ExoPlayer"}
{"id": 2154, "code": "private void applySelectorToStyle(WebvttCssStyle style, String selector) {\n  if (\"\".equals(selector)) {\n    return; \n  }\n  int voiceStartIndex = selector.indexOf('[');\n  if (voiceStartIndex != -1) {\n    Matcher matcher = VOICE_NAME_PATTERN.matcher(selector.substring(voiceStartIndex));\n    if (matcher.matches()) {\n      style.setTargetVoice(Assertions.checkNotNull(matcher.group(1)));\n    }\n    selector = selector.substring(0, voiceStartIndex);\n  }\n  String[] classDivision = Util.split(selector, \"\\\\.\");\n  String tagAndIdDivision = classDivision[0];\n  int idPrefixIndex = tagAndIdDivision.indexOf('#');\n  if (idPrefixIndex != -1) {\n    style.setTargetTagName(tagAndIdDivision.substring(0, idPrefixIndex));\n    style.setTargetId(tagAndIdDivision.substring(idPrefixIndex + 1)); \n  } else {\n    style.setTargetTagName(tagAndIdDivision);\n  }\n  if (classDivision.length > 1) {\n    style.setTargetClasses(Util.nullSafeArrayCopyOfRange(classDivision, 1, classDivision.length));\n  }\n}", "summary_tokens": ["sets", "the", "target", "of", "a", "webvtt", "css", "style", "by", "splitting", "a", "selector", "of", "the", "form", "cue", "tag", "id"], "project": "ExoPlayer"}
{"id": 2765, "code": "public Timeline prepareSource() throws IOException {\n  final IOException[] prepareError = new IOException[1];\n  runOnPlaybackThread(\n      () -> {\n        mediaSource.prepareSource(\n            mediaSourceListener,  null, PlayerId.UNSET);\n        try {\n            \n            \n            \n          mediaSource.maybeThrowSourceInfoRefreshError();\n        } catch (IOException e) {\n          prepareError[0] = e;\n        }\n      });\n  if (prepareError[0] != null) {\n    throw prepareError[0];\n  }\n  return assertTimelineChangeBlocking();\n}", "summary_tokens": ["prepares", "the", "source", "on", "the", "playback", "thread", "asserting", "that", "it", "provides", "an", "initial", "timeline"], "project": "ExoPlayer"}
{"id": 489, "code": "public static void focusPlaceholderEglSurfaceBt2020Pq(\n    EGLContext eglContext, EGLDisplay eglDisplay) {\n  int[] pbufferAttributes =\n      new int[] {\n        EGL14.EGL_WIDTH,\n         1,\n        EGL14.EGL_HEIGHT,\n         1,\n        EGL_GL_COLORSPACE_KHR,\n        EGL_GL_COLORSPACE_BT2020_PQ_EXT,\n        EGL14.EGL_NONE\n      };\n  EGLSurface eglSurface =\n      Api17.createEglPbufferSurface(\n          eglDisplay, EGL_CONFIG_ATTRIBUTES_RGBA_1010102, pbufferAttributes);\n  focusEglSurface(eglDisplay, eglContext, eglSurface,  1,  1);\n}", "summary_tokens": ["creates", "and", "focuses", "a", "new", "eglsurface", "wrapping", "a", "0", "x", "0", "pixel", "buffer", "for", "hdr", "rendering", "with", "rec"], "project": "ExoPlayer"}
{"id": 1906, "code": "public long getSampleNumber(long timeUs) {\n  long sampleNumber = (timeUs * sampleRate) / C.MICROS_PER_SECOND;\n  return Util.constrainValue(sampleNumber,  0, totalSamples - 1);\n}", "summary_tokens": ["returns", "the", "sample", "number", "of", "the", "sample", "at", "a", "given", "time"], "project": "ExoPlayer"}
{"id": 1547, "code": "public void drawFrame(float[] viewProjectionMatrix, boolean rightEye) {\n    \n    \n  GLES20.glClear(GLES20.GL_COLOR_BUFFER_BIT);\n  checkGlError();\n\n  if (frameAvailable.compareAndSet(true, false)) {\n    Assertions.checkNotNull(surfaceTexture).updateTexImage();\n    checkGlError();\n    if (resetRotationAtNextFrame.compareAndSet(true, false)) {\n      Matrix.setIdentityM(rotationMatrix, 0);\n    }\n    long lastFrameTimestampNs = surfaceTexture.getTimestamp();\n    Long sampleTimestampUs = sampleTimestampQueue.poll(lastFrameTimestampNs);\n    if (sampleTimestampUs != null) {\n      frameRotationQueue.pollRotationMatrix(rotationMatrix, sampleTimestampUs);\n    }\n    Projection projection = projectionQueue.pollFloor(lastFrameTimestampNs);\n    if (projection != null) {\n      projectionRenderer.setProjection(projection);\n    }\n  }\n  Matrix.multiplyMM(tempMatrix, 0, viewProjectionMatrix, 0, rotationMatrix, 0);\n  projectionRenderer.draw(textureId, tempMatrix, rightEye);\n}", "summary_tokens": ["draws", "the", "scene", "with", "a", "given", "eye", "pose", "and", "type"], "project": "ExoPlayer"}
{"id": 1396, "code": "public void init(TrackOutputProvider trackOutputProvider) {\n  this.trackOutputProvider = trackOutputProvider;\n}", "summary_tokens": ["initializes", "the", "chunk", "for", "loading", "setting", "a", "track", "output", "provider", "for", "track", "outputs", "to", "which", "formats", "will", "be", "written", "as", "they", "are", "loaded"], "project": "ExoPlayer"}
{"id": 349, "code": "public void clearVideoSurfaceHolder(@Nullable SurfaceHolder surfaceHolder) {\n  player.clearVideoSurfaceHolder(surfaceHolder);\n}", "summary_tokens": ["calls", "player", "clear", "video", "surface", "holder", "surface", "holder", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 2015, "code": "public boolean sampleHasSubsampleEncryptionTable(int index) {\n  return definesEncryptionData && sampleHasSubsampleEncryptionTable[index];\n}", "summary_tokens": ["returns", "whether", "the", "sample", "at", "the", "given", "index", "has", "a", "subsample", "encryption", "table"], "project": "ExoPlayer"}
{"id": 214, "code": "public static boolean supportsCryptoType(@C.CryptoType int cryptoType) {\n  return cryptoType == C.CRYPTO_TYPE_NONE\n      || (cryptoType != C.CRYPTO_TYPE_UNSUPPORTED && cryptoType == VpxLibrary.cryptoType);\n}", "summary_tokens": ["returns", "whether", "the", "library", "supports", "the", "given", "c"], "project": "ExoPlayer"}
{"id": 1575, "code": "private static Timeline[] getClippedTimelines(\n    long startUs,\n    long endUs,\n    boolean allowDynamicUpdates,\n    boolean fromDefaultPosition,\n    Timeline firstTimeline,\n    Timeline... additionalTimelines)\n    throws IOException {\n  FakeMediaSource fakeMediaSource = new FakeMediaSource(firstTimeline);\n  ClippingMediaSource mediaSource =\n      new ClippingMediaSource(\n          fakeMediaSource,\n          startUs,\n          endUs,\n           true,\n          allowDynamicUpdates,\n          fromDefaultPosition);\n  return getClippedTimelines(fakeMediaSource, mediaSource, additionalTimelines);\n}", "summary_tokens": ["wraps", "the", "specified", "timelines", "in", "a", "clipping", "media", "source", "and", "returns", "the", "clipped", "timeline", "for", "each", "timeline", "update"], "project": "ExoPlayer"}
{"id": 1012, "code": "protected int getPcmBufferSizeInBytes(int minBufferSizeInBytes, int samplingRate, int frameSize) {\n  int targetBufferSize = minBufferSizeInBytes * pcmBufferMultiplicationFactor;\n  int minAppBufferSize = durationUsToBytes(minPcmBufferDurationUs, samplingRate, frameSize);\n  int maxAppBufferSize = durationUsToBytes(maxPcmBufferDurationUs, samplingRate, frameSize);\n  return constrainValue(targetBufferSize, minAppBufferSize, maxAppBufferSize);\n}", "summary_tokens": ["returns", "the", "buffer", "size", "for", "pcm", "playback"], "project": "ExoPlayer"}
{"id": 246, "code": "public Format copyWithVideoSize(int width, int height) {\n  return buildUpon().setWidth(width).setHeight(height).build();\n}", "summary_tokens": ["use", "build", "upon", "builder", "set", "width", "int", "and", "builder", "set", "height", "int"], "project": "ExoPlayer"}
{"id": 2020, "code": "long readGranuleOfLastPage(ExtractorInput input) throws IOException {\n  pageHeader.reset();\n  if (!pageHeader.skipToNextPage(input)) {\n    throw new EOFException();\n  }\n  pageHeader.populate(input,  false);\n  input.skipFully(pageHeader.headerSize + pageHeader.bodySize);\n  long granulePosition = pageHeader.granulePosition;\n  while ((pageHeader.type & 0x04) != 0x04\n      && pageHeader.skipToNextPage(input)\n      && input.getPosition() < payloadEndPosition) {\n    boolean hasPopulated = pageHeader.populate(input,  true);\n    if (!hasPopulated || !skipFullyQuietly(input, pageHeader.headerSize + pageHeader.bodySize)) {\n        \n        \n      return granulePosition;\n    }\n    granulePosition = pageHeader.granulePosition;\n  }\n  return granulePosition;\n}", "summary_tokens": ["skips", "to", "the", "last", "ogg", "page", "in", "the", "stream", "and", "reads", "the", "header", "s", "granule", "field", "which", "is", "the", "total", "number", "of", "samples", "per", "channel"], "project": "ExoPlayer"}
{"id": 1718, "code": "public static byte[] readToEnd(DataSource dataSource) throws IOException {\n  byte[] data = new byte[1024];\n  int position = 0;\n  int bytesRead = 0;\n  while (bytesRead != C.RESULT_END_OF_INPUT) {\n    if (position == data.length) {\n      data = Arrays.copyOf(data, data.length * 2);\n    }\n    bytesRead = dataSource.read(data, position, data.length - position);\n    if (bytesRead != C.RESULT_END_OF_INPUT) {\n      position += bytesRead;\n    }\n  }\n  return Arrays.copyOf(data, position);\n}", "summary_tokens": ["reads", "data", "from", "the", "specified", "opened", "data", "source", "until", "it", "ends", "and", "returns", "a", "byte", "array", "containing", "the", "read", "data"], "project": "ExoPlayer"}
{"id": 1197, "code": "default boolean isBeforeFirst() {\n  if (getCount() == 0) {\n    return true;\n  }\n  return getPosition() == -1;\n}", "summary_tokens": ["returns", "whether", "the", "cursor", "is", "pointing", "to", "the", "position", "before", "the", "first", "download"], "project": "ExoPlayer"}
{"id": 600, "code": "public static @Player.RepeatMode int getNextRepeatMode(\n    @Player.RepeatMode int currentMode, int enabledModes) {\n  for (int offset = 1; offset <= 2; offset++) {\n    @Player.RepeatMode int proposedMode = (currentMode + offset) % 3;\n    if (isRepeatModeEnabled(proposedMode, enabledModes)) {\n      return proposedMode;\n    }\n  }\n  return currentMode;\n}", "summary_tokens": ["gets", "the", "next", "repeat", "mode", "out", "of", "enabled", "modes", "starting", "from", "current", "mode"], "project": "ExoPlayer"}
{"id": 1195, "code": "default boolean isFirst() {\n  return getPosition() == 0 && getCount() != 0;\n}", "summary_tokens": ["returns", "whether", "the", "cursor", "is", "pointing", "to", "the", "first", "download"], "project": "ExoPlayer"}
{"id": 1010, "code": "private long applyMediaPositionParameters(long positionUs) {\n  while (!mediaPositionParametersCheckpoints.isEmpty()\n      && positionUs >= mediaPositionParametersCheckpoints.getFirst().audioTrackPositionUs) {\n      \n    mediaPositionParameters = mediaPositionParametersCheckpoints.remove();\n  }\n\n  long playoutDurationSinceLastCheckpointUs =\n      positionUs - mediaPositionParameters.audioTrackPositionUs;\n  if (mediaPositionParameters.playbackParameters.equals(PlaybackParameters.DEFAULT)) {\n    return mediaPositionParameters.mediaTimeUs + playoutDurationSinceLastCheckpointUs;\n  } else if (mediaPositionParametersCheckpoints.isEmpty()) {\n    long mediaDurationSinceLastCheckpointUs =\n        audioProcessorChain.getMediaDuration(playoutDurationSinceLastCheckpointUs);\n    return mediaPositionParameters.mediaTimeUs + mediaDurationSinceLastCheckpointUs;\n  } else {\n      \n      \n      \n      \n      \n      \n      \n      \n    MediaPositionParameters nextMediaPositionParameters =\n        mediaPositionParametersCheckpoints.getFirst();\n    long playoutDurationUntilNextCheckpointUs =\n        nextMediaPositionParameters.audioTrackPositionUs - positionUs;\n    long mediaDurationUntilNextCheckpointUs =\n        Util.getMediaDurationForPlayoutDuration(\n            playoutDurationUntilNextCheckpointUs,\n            mediaPositionParameters.playbackParameters.speed);\n    return nextMediaPositionParameters.mediaTimeUs - mediaDurationUntilNextCheckpointUs;\n  }\n}", "summary_tokens": ["applies", "and", "updates", "media", "position", "parameters"], "project": "ExoPlayer"}
{"id": 1969, "code": "public static MlltSeeker create(long firstFramePosition, MlltFrame mlltFrame, long durationUs) {\n  int referenceCount = mlltFrame.bytesDeviations.length;\n  long[] referencePositions = new long[1 + referenceCount];\n  long[] referenceTimesMs = new long[1 + referenceCount];\n  referencePositions[0] = firstFramePosition;\n  referenceTimesMs[0] = 0;\n  long position = firstFramePosition;\n  long timeMs = 0;\n  for (int i = 1; i <= referenceCount; i++) {\n    position += mlltFrame.bytesBetweenReference + mlltFrame.bytesDeviations[i - 1];\n    timeMs += mlltFrame.millisecondsBetweenReference + mlltFrame.millisecondsDeviations[i - 1];\n    referencePositions[i] = position;\n    referenceTimesMs[i] = timeMs;\n  }\n  return new MlltSeeker(referencePositions, referenceTimesMs, durationUs);\n}", "summary_tokens": ["returns", "an", "mllt", "seeker", "for", "seeking", "in", "the", "stream"], "project": "ExoPlayer"}
{"id": 1040, "code": "public void setSpeed(float speed) {\n  if (this.speed != speed) {\n    this.speed = speed;\n    pendingSonicRecreation = true;\n  }\n}", "summary_tokens": ["sets", "the", "target", "playback", "speed"], "project": "ExoPlayer"}
{"id": 1316, "code": "private static AllocationNode getNodeContainingPosition(\n    AllocationNode allocationNode, long absolutePosition) {\n  while (absolutePosition >= allocationNode.endPosition) {\n    allocationNode = allocationNode.next;\n  }\n  return allocationNode;\n}", "summary_tokens": ["returns", "the", "allocation", "node", "in", "allocation", "node", "s", "chain", "which", "contains", "the", "given", "absolute", "position"], "project": "ExoPlayer"}
{"id": 565, "code": "public void skipBytes(int bytes) {\n  setPosition(position + bytes);\n}", "summary_tokens": ["moves", "the", "reading", "offset", "by", "bytes"], "project": "ExoPlayer"}
{"id": 828, "code": "public void setStayAwake(boolean stayAwake) {\n  this.stayAwake = stayAwake;\n  updateWakeLock();\n}", "summary_tokens": ["sets", "whether", "to", "acquire", "or", "release", "the", "wake", "lock"], "project": "ExoPlayer"}
{"id": 1662, "code": "private static int compareBaseUrl(BaseUrl a, BaseUrl b) {\n  int compare = Integer.compare(a.priority, b.priority);\n  return compare != 0 ? compare : a.serviceLocation.compareTo(b.serviceLocation);\n}", "summary_tokens": ["compare", "by", "priority", "and", "service", "location"], "project": "ExoPlayer"}
{"id": 1980, "code": "public static int parseFullAtomVersion(int fullAtomInt) {\n  return 0x000000FF & (fullAtomInt >> 24);\n}", "summary_tokens": ["parses", "the", "version", "number", "out", "of", "the", "additional", "integer", "component", "of", "a", "full", "atom"], "project": "ExoPlayer"}
{"id": 1937, "code": "private void parseIdx1Body(ParsableByteArray body) {\n  long seekOffset = peekSeekOffset(body);\n  while (body.bytesLeft() >= 16) {\n    int chunkId = body.readLittleEndianInt();\n    int flags = body.readLittleEndianInt();\n    long offset = body.readLittleEndianInt() + seekOffset;\n    body.readLittleEndianInt(); \n    ChunkReader chunkReader = getChunkReader(chunkId);\n    if (chunkReader == null) {\n        \n      continue;\n    }\n    if ((flags & AVIIF_KEYFRAME) == AVIIF_KEYFRAME) {\n      chunkReader.appendKeyFrameToIndex(offset);\n    }\n    chunkReader.incrementIndexChunkCount();\n  }\n  for (ChunkReader chunkReader : chunkReaders) {\n    chunkReader.compactIndex();\n  }\n  seekMapHasBeenOutput = true;\n  extractorOutput.seekMap(new AviSeekMap(durationUs));\n}", "summary_tokens": ["builds", "and", "outputs", "the", "seek", "map", "from", "the", "idx", "0", "chunk"], "project": "ExoPlayer"}
{"id": 1598, "code": "private void assertReadSample(\n    long timeUs,\n    boolean isKeyFrame,\n    boolean isDecodeOnly,\n    boolean isEncrypted,\n    byte[] sampleData,\n    int offset,\n    int length) {\n    \n  formatHolder.format = null;\n  DecoderInputBuffer flagsOnlyBuffer = DecoderInputBuffer.newNoDataInstance();\n  int result =\n      sampleQueue.read(\n          formatHolder,\n          flagsOnlyBuffer,\n          FLAG_OMIT_SAMPLE_DATA | FLAG_PEEK,\n           false);\n  assertSampleBufferReadResult(\n      flagsOnlyBuffer, result, timeUs, isKeyFrame, isDecodeOnly, isEncrypted);\n\n    \n  clearFormatHolderAndInputBuffer();\n  result = sampleQueue.read(formatHolder, inputBuffer, FLAG_PEEK,  false);\n  assertSampleBufferReadResult(\n      result, timeUs, isKeyFrame, isDecodeOnly, isEncrypted, sampleData, offset, length);\n\n    \n  clearFormatHolderAndInputBuffer();\n  result =\n      sampleQueue.read(\n          formatHolder, inputBuffer,  0,  false);\n  assertSampleBufferReadResult(\n      result, timeUs, isKeyFrame, isDecodeOnly, isEncrypted, sampleData, offset, length);\n}", "summary_tokens": ["asserts", "sample", "queue", "read", "returns", "c", "result", "buffer", "read", "and", "that", "the", "buffer", "is", "filled", "with", "the", "specified", "sample", "data"], "project": "ExoPlayer"}
{"id": 1436, "code": "public int getMinimumLoadableRetryCount(int dataType) {\n  if (minimumLoadableRetryCount == DEFAULT_BEHAVIOR_MIN_LOADABLE_RETRY_COUNT) {\n    return dataType == C.DATA_TYPE_MEDIA_PROGRESSIVE_LIVE\n        ? DEFAULT_MIN_LOADABLE_RETRY_COUNT_PROGRESSIVE_LIVE\n        : DEFAULT_MIN_LOADABLE_RETRY_COUNT;\n  } else {\n    return minimumLoadableRetryCount;\n  }\n}", "summary_tokens": ["see", "default", "load", "error", "handling", "policy", "and", "default", "load", "error", "handling", "policy", "int", "for", "documentation", "about", "the", "behavior", "of", "this", "method"], "project": "ExoPlayer"}
{"id": 2241, "code": "public HlsMediaPlaylist copyWithEndTag() {\n  if (this.hasEndTag) {\n    return this;\n  }\n  return new HlsMediaPlaylist(\n      playlistType,\n      baseUri,\n      tags,\n      startOffsetUs,\n      preciseStart,\n      startTimeUs,\n      hasDiscontinuitySequence,\n      discontinuitySequence,\n      mediaSequence,\n      version,\n      targetDurationUs,\n      partTargetDurationUs,\n      hasIndependentSegments,\n       true,\n      hasProgramDateTime,\n      protectionSchemes,\n      segments,\n      trailingParts,\n      serverControl,\n      renditionReports);\n}", "summary_tokens": ["returns", "a", "playlist", "identical", "to", "this", "one", "except", "that", "an", "end", "tag", "is", "added"], "project": "ExoPlayer"}
{"id": 2813, "code": "public static byte[] getByteArray(Context context, String fileName) throws IOException {\n  return Util.toByteArray(getInputStream(context, fileName));\n}", "summary_tokens": ["returns", "the", "bytes", "of", "an", "asset", "file"], "project": "ExoPlayer"}
{"id": 2179, "code": "public static int findNalUnit(\n    byte[] data, int startOffset, int endOffset, boolean[] prefixFlags) {\n  int length = endOffset - startOffset;\n\n  Assertions.checkState(length >= 0);\n  if (length == 0) {\n    return endOffset;\n  }\n\n  if (prefixFlags[0]) {\n    clearPrefixFlags(prefixFlags);\n    return startOffset - 3;\n  } else if (length > 1 && prefixFlags[1] && data[startOffset] == 1) {\n    clearPrefixFlags(prefixFlags);\n    return startOffset - 2;\n  } else if (length > 2\n      && prefixFlags[2]\n      && data[startOffset] == 0\n      && data[startOffset + 1] == 1) {\n    clearPrefixFlags(prefixFlags);\n    return startOffset - 1;\n  }\n\n  int limit = endOffset - 1;\n    \n    \n  for (int i = startOffset + 2; i < limit; i += 3) {\n    if ((data[i] & 0xFE) != 0) {\n        \n        \n    } else if (data[i - 2] == 0 && data[i - 1] == 0 && data[i] == 1) {\n      clearPrefixFlags(prefixFlags);\n      return i - 2;\n    } else {\n        \n        \n      i -= 2;\n    }\n  }\n\n    \n  prefixFlags[0] =\n      length > 2\n          ? (data[endOffset - 3] == 0 && data[endOffset - 2] == 0 && data[endOffset - 1] == 1)\n          : length == 2\n              ? (prefixFlags[2] && data[endOffset - 2] == 0 && data[endOffset - 1] == 1)\n              : (prefixFlags[1] && data[endOffset - 1] == 1);\n    \n  prefixFlags[1] =\n      length > 1\n          ? data[endOffset - 2] == 0 && data[endOffset - 1] == 0\n          : prefixFlags[2] && data[endOffset - 1] == 0;\n    \n  prefixFlags[2] = data[endOffset - 1] == 0;\n\n  return endOffset;\n}", "summary_tokens": ["finds", "the", "first", "nal", "unit", "in", "data"], "project": "ExoPlayer"}
{"id": 1071, "code": "public static FrameworkMediaDrm newInstance(UUID uuid) throws UnsupportedDrmException {\n  try {\n    return new FrameworkMediaDrm(uuid);\n  } catch (UnsupportedSchemeException e) {\n    throw new UnsupportedDrmException(UnsupportedDrmException.REASON_UNSUPPORTED_SCHEME, e);\n  } catch (Exception e) {\n    throw new UnsupportedDrmException(UnsupportedDrmException.REASON_INSTANTIATION_ERROR, e);\n  }\n}", "summary_tokens": ["creates", "an", "instance", "with", "an", "initial", "reference", "count", "of", "0"], "project": "ExoPlayer"}
{"id": 2212, "code": "private void assertMp4WebvttSubtitleEquals(Subtitle subtitle, Cue... expectedCues) {\n  assertThat(subtitle.getEventTimeCount()).isEqualTo(1);\n  assertThat(subtitle.getEventTime(0)).isEqualTo(0);\n  List<Cue> subtitleCues = subtitle.getCues(0);\n  assertThat(subtitleCues).hasSize(expectedCues.length);\n  for (int i = 0; i < subtitleCues.size(); i++) {\n    assertCuesEqual(expectedCues[i], subtitleCues.get(i));\n  }\n}", "summary_tokens": ["asserts", "that", "the", "subtitle", "s", "cues", "which", "are", "all", "part", "of", "the", "event", "at", "t", "0", "are", "equal", "to", "the", "expected", "cues"], "project": "ExoPlayer"}
{"id": 737, "code": "public MediaPeriodHolder advanceReadingPeriod() {\n  Assertions.checkState(reading != null && reading.getNext() != null);\n  reading = reading.getNext();\n  notifyQueueUpdate();\n  return reading;\n}", "summary_tokens": ["continues", "reading", "from", "the", "next", "period", "holder", "in", "the", "queue"], "project": "ExoPlayer"}
{"id": 2505, "code": "public final void setPriority(@Priority int priority) {\n  if (this.priority == priority) {\n    return;\n  }\n  switch (priority) {\n    case NotificationCompat.PRIORITY_DEFAULT:\n    case NotificationCompat.PRIORITY_MAX:\n    case NotificationCompat.PRIORITY_HIGH:\n    case NotificationCompat.PRIORITY_LOW:\n    case NotificationCompat.PRIORITY_MIN:\n      this.priority = priority;\n      break;\n    default:\n      throw new IllegalArgumentException();\n  }\n  invalidate();\n}", "summary_tokens": ["sets", "the", "priority", "of", "the", "notification", "required", "for", "api", "0", "and", "lower"], "project": "ExoPlayer"}
{"id": 395, "code": "public boolean isTypeSupportedOrEmpty(\n    @C.TrackType int trackType, boolean allowExceedsCapabilities) {\n  return !containsType(trackType) || isTypeSupported(trackType, allowExceedsCapabilities);\n}", "summary_tokens": ["use", "contains", "type", "int", "and", "is", "type", "supported", "int", "boolean"], "project": "ExoPlayer"}
{"id": 1206, "code": "public int getMaxParallelDownloads() {\n  return maxParallelDownloads;\n}", "summary_tokens": ["returns", "the", "maximum", "number", "of", "parallel", "downloads"], "project": "ExoPlayer"}
{"id": 981, "code": "public boolean hasTimestamp() {\n  return state == STATE_TIMESTAMP || state == STATE_TIMESTAMP_ADVANCING;\n}", "summary_tokens": ["returns", "whether", "this", "instance", "has", "a", "timestamp", "that", "can", "be", "used", "to", "calculate", "the", "audio", "track", "position"], "project": "ExoPlayer"}
{"id": 769, "code": "protected void onReset() {\n    \n}", "summary_tokens": ["called", "when", "the", "renderer", "is", "reset"], "project": "ExoPlayer"}
{"id": 1271, "code": "protected long getMediaTimeForChildMediaTime(@UnknownNull T id, long mediaTimeMs) {\n  return mediaTimeMs;\n}", "summary_tokens": ["returns", "the", "media", "time", "in", "the", "media", "period", "of", "the", "composite", "source", "corresponding", "to", "the", "specified", "media", "time", "in", "the", "media", "period", "of", "the", "child", "source"], "project": "ExoPlayer"}
{"id": 1606, "code": "public void selectTracksWithNullOverrideForDifferentTracks() throws ExoPlaybackException {\n  TrackGroup videoGroup0 = VIDEO_TRACK_GROUP.copyWithId(\"0\");\n  TrackGroup videoGroup1 = VIDEO_TRACK_GROUP.copyWithId(\"1\");\n  trackSelector.setParameters(\n      trackSelector\n          .buildUponParameters()\n          .setSelectionOverride(0, new TrackGroupArray(VIDEO_TRACK_GROUP.copyWithId(\"2\")), null));\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          RENDERER_CAPABILITIES,\n          new TrackGroupArray(videoGroup0, AUDIO_TRACK_GROUP, videoGroup1),\n          periodId,\n          TIMELINE);\n  assertThat(result.selections)\n      .asList()\n      .containsExactly(\n          new FixedTrackSelection(videoGroup0,  0),\n          new FixedTrackSelection(AUDIO_TRACK_GROUP,  0))\n      .inOrder();\n  assertThat(result.rendererConfigurations)\n      .isEqualTo(new RendererConfiguration[] {DEFAULT, DEFAULT});\n}", "summary_tokens": ["tests", "that", "an", "override", "is", "not", "applied", "for", "a", "different", "set", "of", "available", "track", "groups"], "project": "ExoPlayer"}
{"id": 2690, "code": " void start(\n    ExoPlayer player,\n    DefaultTrackSelector trackSelector,\n    @Nullable Surface surface,\n    HandlerWrapper mainHandler,\n    @Nullable Callback callback) {\n  callbackAction.setCallback(callback);\n  rootNode.schedule(player, trackSelector, surface, mainHandler);\n}", "summary_tokens": ["starts", "execution", "of", "the", "schedule"], "project": "ExoPlayer"}
{"id": 1728, "code": "public DataSpec withAdditionalHeaders(Map<String, String> additionalHttpRequestHeaders) {\n  Map<String, String> httpRequestHeaders = new HashMap<>(this.httpRequestHeaders);\n  httpRequestHeaders.putAll(additionalHttpRequestHeaders);\n  return new DataSpec(\n      uri,\n      uriPositionOffset,\n      httpMethod,\n      httpBody,\n      httpRequestHeaders,\n      position,\n      length,\n      key,\n      flags,\n      customData);\n}", "summary_tokens": ["returns", "a", "copy", "this", "data", "spec", "with", "additional", "http", "request", "headers"], "project": "ExoPlayer"}
{"id": 712, "code": "public void continueLoading(long rendererPositionUs) {\n  Assertions.checkState(isLoadingMediaPeriod());\n  long loadingPeriodPositionUs = toPeriodTime(rendererPositionUs);\n  mediaPeriod.continueLoading(loadingPeriodPositionUs);\n}", "summary_tokens": ["continues", "loading", "the", "media", "period", "at", "the", "given", "renderer", "position"], "project": "ExoPlayer"}
{"id": 2602, "code": "public void setUseController(boolean useController) {\n  Assertions.checkState(!useController || controller != null);\n  setClickable(useController || hasOnClickListeners());\n  if (this.useController == useController) {\n    return;\n  }\n  this.useController = useController;\n  if (useController()) {\n    controller.setPlayer(player);\n  } else if (controller != null) {\n    controller.hide();\n    controller.setPlayer( null);\n  }\n  updateContentDescription();\n}", "summary_tokens": ["sets", "whether", "the", "playback", "controls", "can", "be", "shown"], "project": "ExoPlayer"}
{"id": 2136, "code": "private static int addCuePlacerholderByTime(\n    long timeUs, List<Long> sortedCueTimesUs, List<List<Cue>> cues) {\n  int insertionIndex = 0;\n  for (int i = sortedCueTimesUs.size() - 1; i >= 0; i--) {\n    if (sortedCueTimesUs.get(i) == timeUs) {\n      return i;\n    }\n\n    if (sortedCueTimesUs.get(i) < timeUs) {\n      insertionIndex = i + 1;\n      break;\n    }\n  }\n  sortedCueTimesUs.add(insertionIndex, timeUs);\n    \n  cues.add(\n      insertionIndex,\n      insertionIndex == 0 ? new ArrayList<>() : new ArrayList<>(cues.get(insertionIndex - 1)));\n  return insertionIndex;\n}", "summary_tokens": ["searches", "for", "time", "us", "in", "sorted", "cue", "times", "us", "inserting", "it", "if", "it", "s", "not", "found", "and", "returns", "the", "index"], "project": "ExoPlayer"}
{"id": 1269, "code": "protected int getWindowIndexForChildWindowIndex(@UnknownNull T id, int windowIndex) {\n  return windowIndex;\n}", "summary_tokens": ["returns", "the", "window", "index", "in", "the", "composite", "source", "corresponding", "to", "the", "specified", "window", "index", "in", "a", "child", "source"], "project": "ExoPlayer"}
{"id": 314, "code": "public int getCurrentPeriodIndex() {\n  return player.getCurrentPeriodIndex();\n}", "summary_tokens": ["calls", "player", "get", "current", "period", "index", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 233, "code": "public static String getFormatSupportString(@FormatSupport int formatSupport) {\n  return Util.getFormatSupportString(formatSupport);\n}", "summary_tokens": ["use", "util", "get", "format", "support", "string", "int"], "project": "ExoPlayer"}
{"id": 544, "code": "public int bitsLeft() {\n  return (byteLimit - byteOffset) * 8 - bitOffset;\n}", "summary_tokens": ["returns", "the", "number", "of", "bits", "yet", "to", "be", "read"], "project": "ExoPlayer"}
{"id": 400, "code": "public DrmInitData copyWithSchemeType(@Nullable String schemeType) {\n  if (Util.areEqual(this.schemeType, schemeType)) {\n    return this;\n  }\n  return new DrmInitData(schemeType, false, schemeDatas);\n}", "summary_tokens": ["returns", "a", "copy", "with", "the", "specified", "protection", "scheme", "type"], "project": "ExoPlayer"}
{"id": 64, "code": "protected UrlRequest getCurrentUrlRequest() {\n  return currentUrlRequest;\n}", "summary_tokens": ["returns", "current", "url", "request"], "project": "ExoPlayer"}
{"id": 319, "code": "public int getPreviousWindowIndex() {\n  return player.getPreviousWindowIndex();\n}", "summary_tokens": ["calls", "player", "get", "previous", "window", "index", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 1223, "code": "public static Intent buildRemoveAllDownloadsIntent(\n    Context context, Class<? extends DownloadService> clazz, boolean foreground) {\n  return getIntent(context, clazz, ACTION_REMOVE_ALL_DOWNLOADS, foreground);\n}", "summary_tokens": ["builds", "an", "intent", "for", "removing", "all", "downloads"], "project": "ExoPlayer"}
{"id": 2670, "code": "public void setTrackNameProvider(TrackNameProvider trackNameProvider) {\n  this.trackNameProvider = Assertions.checkNotNull(trackNameProvider);\n  updateViews();\n}", "summary_tokens": ["sets", "the", "track", "name", "provider", "used", "to", "generate", "the", "user", "visible", "name", "of", "each", "track", "and", "updates", "the", "view", "with", "track", "names", "queried", "from", "the", "specified", "provider"], "project": "ExoPlayer"}
{"id": 101, "code": "public AdDisplayContainer getAdDisplayContainer() {\n  return adDisplayContainer;\n}", "summary_tokens": ["returns", "the", "ima", "sdk", "ad", "display", "container"], "project": "ExoPlayer"}
{"id": 761, "code": "private static Object getChildPeriodUid(Object periodUid) {\n  return PlaylistTimeline.getChildPeriodUidFromConcatenatedUid(periodUid);\n}", "summary_tokens": ["return", "uid", "of", "child", "period", "from", "period", "uid", "of", "concatenated", "source"], "project": "ExoPlayer"}
{"id": 269, "code": "public boolean isPlaying() {\n  return player.isPlaying();\n}", "summary_tokens": ["calls", "player", "is", "playing", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 1101, "code": "public void experimentalSetSynchronizeCodecInteractionsWithQueueingEnabled(boolean enabled) {\n  enableSynchronizeCodecInteractionsWithQueueing = enabled;\n}", "summary_tokens": ["enable", "synchronizing", "codec", "interactions", "with", "asynchronous", "buffer", "queueing"], "project": "ExoPlayer"}
{"id": 1532, "code": "default void onVideoDisabled(DecoderCounters counters) {}", "summary_tokens": ["called", "when", "the", "renderer", "is", "disabled"], "project": "ExoPlayer"}
{"id": 1829, "code": "public static byte[] buildAudioSpecificConfig(\n    int audioObjectType, int sampleRateIndex, int channelConfig) {\n  byte[] specificConfig = new byte[2];\n  specificConfig[0] = (byte) (((audioObjectType << 3) & 0xF8) | ((sampleRateIndex >> 1) & 0x07));\n  specificConfig[1] = (byte) (((sampleRateIndex << 7) & 0x80) | ((channelConfig << 3) & 0x78));\n  return specificConfig;\n}", "summary_tokens": ["builds", "a", "simple", "audio", "specific", "config", "as", "defined", "in", "iso", "0", "0", "0"], "project": "ExoPlayer"}
{"id": 403, "code": "public Metadata.Entry get(int index) {\n  return entries[index];\n}", "summary_tokens": ["returns", "the", "entry", "at", "the", "specified", "index"], "project": "ExoPlayer"}
{"id": 2434, "code": "public Builder buildUpon() {\n  return new Builder(this);\n}", "summary_tokens": ["returns", "a", "new", "transformation", "request"], "project": "ExoPlayer"}
{"id": 1698, "code": "public void skipDataThenUpdateStreamContinueToReadFromSkippedPosition() {\n  long presentationTimeUs1 = 1000000;\n  long presentationTimeUs2 = 2000000;\n  long presentationTimeUs3 = 3000000;\n  EventMessage eventMessage1 = newEventMessageWithId(1);\n  EventMessage eventMessage2 = newEventMessageWithId(2);\n  EventMessage eventMessage3 = newEventMessageWithId(3);\n  EventStream eventStream1 =\n      new EventStream(\n          SCHEME_ID,\n          VALUE,\n          TIME_SCALE,\n          new long[] {presentationTimeUs1, presentationTimeUs2},\n          new EventMessage[] {eventMessage1, eventMessage2});\n  EventStream eventStream2 =\n      new EventStream(\n          SCHEME_ID,\n          VALUE,\n          TIME_SCALE,\n          new long[] {presentationTimeUs1, presentationTimeUs2, presentationTimeUs3},\n          new EventMessage[] {eventMessage1, eventMessage2, eventMessage3});\n  EventSampleStream sampleStream = new EventSampleStream(eventStream1, FORMAT, true);\n    \n  readData(sampleStream);\n  sampleStream.skipData(presentationTimeUs2 + 1);\n\n  sampleStream.updateEventStream(eventStream2, true);\n  int result = readData(sampleStream);\n  assertThat(result).isEqualTo(C.RESULT_BUFFER_READ);\n  assertThat(inputBuffer.data.array()).isEqualTo(getEncodedMessage(eventMessage3));\n}", "summary_tokens": ["tests", "that", "event", "sample", "stream", "update", "event", "stream", "event", "stream", "boolean", "will", "update", "the", "underlying", "event", "stream", "but", "keep", "the", "timestamp", "the", "stream", "has", "skipped", "to", "so", "the", "next", "event", "sample", "stream", "read", "data", "format", "holder", "decoder", "input", "buffer", "int", "call", "will", "return", "sample", "data", "from", "the", "skipped", "position"], "project": "ExoPlayer"}
{"id": 2057, "code": "private void parseAdtsHeader() throws ParserException {\n  adtsScratch.setPosition(0);\n\n  if (!hasOutputFormat) {\n    int audioObjectType = adtsScratch.readBits(2) + 1;\n    if (audioObjectType != 2) {\n        \n        \n        \n        \n        \n        \n        \n        \n        \n      Log.w(TAG, \"Detected audio object type: \" + audioObjectType + \", but assuming AAC LC.\");\n      audioObjectType = 2;\n    }\n\n    adtsScratch.skipBits(5);\n    int channelConfig = adtsScratch.readBits(3);\n\n    byte[] audioSpecificConfig =\n        AacUtil.buildAudioSpecificConfig(\n            audioObjectType, firstFrameSampleRateIndex, channelConfig);\n    AacUtil.Config aacConfig = AacUtil.parseAudioSpecificConfig(audioSpecificConfig);\n    Format format =\n        new Format.Builder()\n            .setId(formatId)\n            .setSampleMimeType(MimeTypes.AUDIO_AAC)\n            .setCodecs(aacConfig.codecs)\n            .setChannelCount(aacConfig.channelCount)\n            .setSampleRate(aacConfig.sampleRateHz)\n            .setInitializationData(Collections.singletonList(audioSpecificConfig))\n            .setLanguage(language)\n            .build();\n      \n      \n    sampleDurationUs = (C.MICROS_PER_SECOND * 1024) / format.sampleRate;\n    output.format(format);\n    hasOutputFormat = true;\n  } else {\n    adtsScratch.skipBits(10);\n  }\n\n  adtsScratch.skipBits(4);\n  int sampleSize = adtsScratch.readBits(13) - 2  - HEADER_SIZE;\n  if (hasCrc) {\n    sampleSize -= CRC_SIZE;\n  }\n\n  setReadingSampleState(output, sampleDurationUs, 0, sampleSize);\n}", "summary_tokens": ["parses", "the", "sample", "header"], "project": "ExoPlayer"}
{"id": 2815, "code": "public static String getString(Context context, String fileName) throws IOException {\n  return Util.fromUtf8Bytes(getByteArray(context, fileName));\n}", "summary_tokens": ["returns", "a", "string", "read", "from", "an", "asset", "file"], "project": "ExoPlayer"}
{"id": 2376, "code": "public static boolean isSizeSupported(\n    MediaCodecInfo encoderInfo, String mimeType, int width, int height) {\n  if (encoderInfo\n      .getCapabilitiesForType(mimeType)\n      .getVideoCapabilities()\n      .isSizeSupported(width, height)) {\n    return true;\n  }\n\n    \n    \n    \n    \n  if (width == 1920 && height == 1080) {\n    return CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_1080P);\n  }\n  if (width == 3840 && height == 2160) {\n    return CamcorderProfile.hasProfile(CamcorderProfile.QUALITY_2160P);\n  }\n  return false;\n}", "summary_tokens": ["returns", "whether", "the", "media", "codec", "info", "encoder", "supports", "the", "given", "resolution"], "project": "ExoPlayer"}
{"id": 93, "code": "public long getNextFrameFirstSampleIndex() {\n  return flacGetNextFrameFirstSampleIndex(nativeDecoderContext);\n}", "summary_tokens": ["returns", "the", "first", "sample", "index", "of", "the", "frame", "to", "be", "extracted", "next"], "project": "ExoPlayer"}
{"id": 571, "code": "public int readLittleEndianUnsignedShort() {\n  return (data[position++] & 0xFF) | (data[position++] & 0xFF) << 8;\n}", "summary_tokens": ["reads", "the", "next", "two", "bytes", "as", "an", "unsigned", "value"], "project": "ExoPlayer"}
{"id": 1562, "code": "public void readAheadToEndDoesNotResetRenderer() throws Exception {\n    \n  TimelineWindowDefinition windowDefinition0 =\n      new TimelineWindowDefinition(\n           1,\n           0,\n           false,\n           false,\n           100_000);\n  TimelineWindowDefinition windowDefinition1 =\n      new TimelineWindowDefinition(\n           1,\n           1,\n           false,\n           false,\n           100_000);\n  TimelineWindowDefinition windowDefinition2 =\n      new TimelineWindowDefinition(\n           1,\n           2,\n           false,\n           false,\n           100_000);\n  Timeline timeline = new FakeTimeline(windowDefinition0, windowDefinition1, windowDefinition2);\n  final FakeRenderer videoRenderer = new FakeRenderer(C.TRACK_TYPE_VIDEO);\n  FakeMediaClockRenderer audioRenderer =\n      new FakeMediaClockRenderer(C.TRACK_TYPE_AUDIO) {\n        @Override\n        public long getPositionUs() {\n            \n            \n            \n            \n          return isCurrentStreamFinal() ? 30 : 0;\n        }\n\n        @Override\n        public void setPlaybackParameters(PlaybackParameters playbackParameters) {}\n\n        @Override\n        public PlaybackParameters getPlaybackParameters() {\n          return PlaybackParameters.DEFAULT;\n        }\n\n        @Override\n        public boolean isEnded() {\n          return videoRenderer.isEnded();\n        }\n      };\n  ExoPlayer player =\n      new TestExoPlayerBuilder(context).setRenderers(videoRenderer, audioRenderer).build();\n  Player.Listener mockPlayerListener = mock(Player.Listener.class);\n  player.addListener(mockPlayerListener);\n\n  player.setMediaSource(\n      new FakeMediaSource(\n          timeline, ExoPlayerTestRunner.VIDEO_FORMAT, ExoPlayerTestRunner.AUDIO_FORMAT));\n  player.prepare();\n  player.play();\n  runUntilPlaybackState(player, Player.STATE_ENDED);\n\n  InOrder inOrder = inOrder(mockPlayerListener);\n  inOrder\n      .verify(mockPlayerListener)\n      .onTimelineChanged(\n          argThat(noUid(new FakeMediaSource.InitialTimeline(timeline))),\n          eq(Player.TIMELINE_CHANGE_REASON_PLAYLIST_CHANGED));\n  inOrder\n      .verify(mockPlayerListener)\n      .onTimelineChanged(\n          argThat(noUid(timeline)), eq(Player.TIMELINE_CHANGE_REASON_SOURCE_UPDATE));\n  inOrder\n      .verify(mockPlayerListener, times(2))\n      .onPositionDiscontinuity(any(), any(), eq(Player.DISCONTINUITY_REASON_AUTO_TRANSITION));\n  assertThat(audioRenderer.positionResetCount).isEqualTo(1);\n  assertThat(videoRenderer.isEnded).isTrue();\n  assertThat(audioRenderer.isEnded).isTrue();\n}", "summary_tokens": ["tests", "that", "the", "player", "does", "not", "unnecessarily", "reset", "renderers", "when", "playing", "a", "multi", "period", "source"], "project": "ExoPlayer"}
{"id": 2309, "code": "public boolean isLive() {\n  return stopTimeMs == C.TIME_UNSET;\n}", "summary_tokens": ["tests", "whether", "the", "timing", "is", "live"], "project": "ExoPlayer"}
{"id": 2062, "code": "private boolean continueRead(ParsableByteArray source, byte[] target, int targetLength) {\n  int bytesToRead = min(source.bytesLeft(), targetLength - bytesRead);\n  source.readBytes(target, bytesRead, bytesToRead);\n  bytesRead += bytesToRead;\n  return bytesRead == targetLength;\n}", "summary_tokens": ["continues", "a", "read", "from", "the", "provided", "source", "into", "a", "given", "target"], "project": "ExoPlayer"}
{"id": 2719, "code": "public FakeData newDefaultData() {\n  defaultData = new FakeData(this, null);\n  return defaultData;\n}", "summary_tokens": ["sets", "the", "default", "data", "overwrites", "if", "there", "is", "one", "already"], "project": "ExoPlayer"}
{"id": 2734, "code": "public synchronized void setPreparationComplete() {\n  deferOnPrepared = false;\n  if (playerHandler != null && prepareCallback != null) {\n    playerHandler.post(this::finishPreparation);\n  }\n}", "summary_tokens": ["allows", "the", "fake", "media", "period", "to", "complete", "preparation"], "project": "ExoPlayer"}
{"id": 1378, "code": "protected final long getCurrentIndex() {\n  return currentIndex;\n}", "summary_tokens": ["returns", "the", "current", "index", "this", "iterator", "is", "pointing", "to"], "project": "ExoPlayer"}
{"id": 2452, "code": "public @ResizeMode int getResizeMode() {\n  return resizeMode;\n}", "summary_tokens": ["returns", "the", "resize", "mode"], "project": "ExoPlayer"}
{"id": 231, "code": "public static long msToUs(long timeMs) {\n  return Util.msToUs(timeMs);\n}", "summary_tokens": ["use", "util", "ms", "to", "us", "long"], "project": "ExoPlayer"}
{"id": 2710, "code": "public static ImmutableList<SimulationConfig> configs() {\n  return ImmutableList.of(\n      new SimulationConfig(true, false, false, false),\n      new SimulationConfig(true, false, false, true),\n      new SimulationConfig(true, false, true, false),\n      new SimulationConfig(true, false, true, true),\n      new SimulationConfig(true, true, false, false),\n      new SimulationConfig(true, true, false, true),\n      new SimulationConfig(true, true, true, false),\n      new SimulationConfig(true, true, true, true),\n      new SimulationConfig(false, false, false, false));\n}", "summary_tokens": ["returns", "a", "list", "of", "arrays", "containing", "simulation", "config", "objects", "to", "exercise", "different", "extractor", "paths"], "project": "ExoPlayer"}
{"id": 305, "code": "public void release() {\n  player.release();\n}", "summary_tokens": ["calls", "player", "release", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 387, "code": "public final Pair<Object, Long> getPeriodPosition(\n    Window window,\n    Period period,\n    int windowIndex,\n    long windowPositionUs,\n    long defaultPositionProjectionUs) {\n  return getPeriodPositionUs(\n      window, period, windowIndex, windowPositionUs, defaultPositionProjectionUs);\n}", "summary_tokens": ["use", "get", "period", "position", "us", "window", "period", "int", "long", "long", "instead"], "project": "ExoPlayer"}
{"id": 303, "code": "public PlaybackParameters getPlaybackParameters() {\n  return player.getPlaybackParameters();\n}", "summary_tokens": ["calls", "player", "get", "playback", "parameters", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 164, "code": "public static AudioAttributesCompat getAudioAttributesCompat(AudioAttributes audioAttributes) {\n  return new AudioAttributesCompat.Builder()\n      .setContentType(audioAttributes.contentType)\n      .setFlags(audioAttributes.flags)\n      .setUsage(audioAttributes.usage)\n      .build();\n}", "summary_tokens": ["returns", "audio", "attributes", "for", "the", "given", "exo", "player", "audio", "attributes"], "project": "ExoPlayer"}
{"id": 1251, "code": "public boolean checkRequirements(Context context) {\n  return getNotMetRequirements(context) == 0;\n}", "summary_tokens": ["returns", "whether", "the", "requirements", "are", "met"], "project": "ExoPlayer"}
{"id": 108, "code": "public void handlePrepareComplete(int adGroupIndex, int adIndexInAdGroup) {\n  AdInfo adInfo = new AdInfo(adGroupIndex, adIndexInAdGroup);\n  if (configuration.debugModeEnabled) {\n    Log.d(TAG, \"Prepared ad \" + adInfo);\n  }\n  @Nullable AdMediaInfo adMediaInfo = adInfoByAdMediaInfo.inverse().get(adInfo);\n  if (adMediaInfo != null) {\n    for (int i = 0; i < adCallbacks.size(); i++) {\n      adCallbacks.get(i).onLoaded(adMediaInfo);\n    }\n  } else {\n    Log.w(TAG, \"Unexpected prepared ad \" + adInfo);\n  }\n}", "summary_tokens": ["notifies", "the", "ima", "sdk", "that", "the", "specified", "ad", "has", "been", "prepared", "for", "playback"], "project": "ExoPlayer"}
{"id": 698, "code": "public synchronized boolean setForegroundMode(boolean foregroundMode) {\n  if (released || !internalPlaybackThread.isAlive()) {\n    return true;\n  }\n  if (foregroundMode) {\n    handler.obtainMessage(MSG_SET_FOREGROUND_MODE,  1, 0).sendToTarget();\n    return true;\n  } else {\n    AtomicBoolean processedFlag = new AtomicBoolean();\n    handler\n        .obtainMessage(MSG_SET_FOREGROUND_MODE,  0, 0, processedFlag)\n        .sendToTarget();\n    waitUninterruptibly( processedFlag::get, setForegroundModeTimeoutMs);\n    return processedFlag.get();\n  }\n}", "summary_tokens": ["sets", "the", "foreground", "mode"], "project": "ExoPlayer"}
{"id": 788, "code": "public Object getPayload() {\n  return payload;\n}", "summary_tokens": ["returns", "the", "message", "payload", "forwarded", "to", "target", "handle", "message", "int", "object"], "project": "ExoPlayer"}
{"id": 1642, "code": "public void forcedAndDefaultTextTracksInteractWithSelectedAudioLanguageAsExpected()\n    throws ExoPlaybackException {\n  Format.Builder forcedTextBuilder =\n      TEXT_FORMAT.buildUpon().setSelectionFlags(C.SELECTION_FLAG_FORCED);\n  Format.Builder defaultTextBuilder =\n      TEXT_FORMAT.buildUpon().setSelectionFlags(C.SELECTION_FLAG_DEFAULT);\n  Format forcedEnglish = forcedTextBuilder.setLanguage(\"eng\").build();\n  Format defaultEnglish = defaultTextBuilder.setLanguage(\"eng\").build();\n  Format forcedGerman = forcedTextBuilder.setLanguage(\"deu\").build();\n  Format defaultGerman = defaultTextBuilder.setLanguage(\"deu\").build();\n  Format forcedNoLanguage = forcedTextBuilder.setLanguage(C.LANGUAGE_UNDETERMINED).build();\n\n  Format noLanguageAudio = AUDIO_FORMAT.buildUpon().setLanguage(null).build();\n  Format germanAudio = AUDIO_FORMAT.buildUpon().setLanguage(\"deu\").build();\n\n  RendererCapabilities[] rendererCapabilities =\n      new RendererCapabilities[] {\n        ALL_AUDIO_FORMAT_SUPPORTED_RENDERER_CAPABILITIES,\n        ALL_TEXT_FORMAT_SUPPORTED_RENDERER_CAPABILITIES\n      };\n\n    \n    \n  TrackGroupArray trackGroups = wrapFormats(noLanguageAudio, forcedNoLanguage);\n  TrackSelectorResult result =\n      trackSelector.selectTracks(rendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[1], trackGroups, forcedNoLanguage);\n\n    \n    \n  trackGroups = wrapFormats(noLanguageAudio, forcedEnglish, forcedGerman);\n  result = trackSelector.selectTracks(rendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertNoSelection(result.selections[1]);\n\n    \n  trackGroups = wrapFormats(germanAudio, forcedGerman, forcedEnglish);\n  result = trackSelector.selectTracks(rendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[1], trackGroups, forcedGerman);\n\n    \n  trackGroups = wrapFormats(germanAudio, forcedEnglish, forcedGerman);\n  result = trackSelector.selectTracks(rendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[1], trackGroups, forcedGerman);\n\n    \n    \n  trackGroups =\n      wrapFormats(germanAudio, forcedGerman, defaultGerman, forcedEnglish, defaultEnglish);\n  result = trackSelector.selectTracks(rendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[1], trackGroups, defaultGerman);\n\n    \n    \n  trackGroups = wrapFormats(germanAudio, forcedGerman, forcedEnglish, defaultEnglish);\n  result = trackSelector.selectTracks(rendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[1], trackGroups, defaultEnglish);\n}", "summary_tokens": ["tests", "that", "the", "default", "track", "selector", "will", "select"], "project": "ExoPlayer"}
{"id": 2616, "code": "public boolean getControllerAutoShow() {\n  return controllerAutoShow;\n}", "summary_tokens": ["returns", "whether", "the", "playback", "controls", "are", "automatically", "shown", "when", "playback", "starts", "pauses", "ends", "or", "fails"], "project": "ExoPlayer"}
{"id": 14, "code": "public static TrackSelectionDialog createForPlayer(\n    Player player, DialogInterface.OnDismissListener onDismissListener) {\n  return createForTracksAndParameters(\n      R.string.track_selection_title,\n      player.getCurrentTracks(),\n      player.getTrackSelectionParameters(),\n       true,\n       false,\n      player::setTrackSelectionParameters,\n      onDismissListener);\n}", "summary_tokens": ["creates", "a", "dialog", "for", "a", "given", "player", "whose", "parameters", "will", "be", "automatically", "updated", "when", "tracks", "are", "selected"], "project": "ExoPlayer"}
{"id": 2086, "code": "public long getDurationUs() {\n  return durationUs;\n}", "summary_tokens": ["returns", "the", "duration", "last", "read", "from", "read", "duration", "extractor", "input", "position", "holder", "int"], "project": "ExoPlayer"}
{"id": 2294, "code": "public static byte[] getStringBytes(String s) {\n  return s.getBytes(RtspMessageChannel.CHARSET);\n}", "summary_tokens": ["returns", "the", "byte", "array", "representation", "of", "a", "string", "using", "rtsp", "s", "character", "encoding"], "project": "ExoPlayer"}
{"id": 278, "code": "public boolean getShuffleModeEnabled() {\n  return player.getShuffleModeEnabled();\n}", "summary_tokens": ["calls", "player", "get", "shuffle", "mode", "enabled", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 996, "code": "private long getPlaybackHeadPosition() {\n  AudioTrack audioTrack = Assertions.checkNotNull(this.audioTrack);\n  if (stopTimestampUs != C.TIME_UNSET) {\n      \n    long elapsedTimeSinceStopUs = (SystemClock.elapsedRealtime() * 1000) - stopTimestampUs;\n    long framesSinceStop = (elapsedTimeSinceStopUs * outputSampleRate) / C.MICROS_PER_SECOND;\n    return min(endPlaybackHeadPosition, stopPlaybackHeadPosition + framesSinceStop);\n  }\n\n  int state = audioTrack.getPlayState();\n  if (state == PLAYSTATE_STOPPED) {\n      \n    return 0;\n  }\n\n  long rawPlaybackHeadPosition = 0xFFFFFFFFL & audioTrack.getPlaybackHeadPosition();\n  if (needsPassthroughWorkarounds) {\n      \n      \n      \n    if (state == PLAYSTATE_PAUSED && rawPlaybackHeadPosition == 0) {\n      passthroughWorkaroundPauseOffset = lastRawPlaybackHeadPosition;\n    }\n    rawPlaybackHeadPosition += passthroughWorkaroundPauseOffset;\n  }\n\n  if (Util.SDK_INT <= 29) {\n    if (rawPlaybackHeadPosition == 0\n        && lastRawPlaybackHeadPosition > 0\n        && state == PLAYSTATE_PLAYING) {\n        \n        \n        \n        \n        \n      if (forceResetWorkaroundTimeMs == C.TIME_UNSET) {\n        forceResetWorkaroundTimeMs = SystemClock.elapsedRealtime();\n      }\n      return lastRawPlaybackHeadPosition;\n    } else {\n      forceResetWorkaroundTimeMs = C.TIME_UNSET;\n    }\n  }\n\n  if (lastRawPlaybackHeadPosition > rawPlaybackHeadPosition) {\n      \n    rawPlaybackHeadWrapCount++;\n  }\n  lastRawPlaybackHeadPosition = rawPlaybackHeadPosition;\n  return rawPlaybackHeadPosition + (rawPlaybackHeadWrapCount << 32);\n}", "summary_tokens": ["audio", "track", "get", "playback", "head", "position", "returns", "a", "value", "intended", "to", "be", "interpreted", "as", "an", "unsigned", "0", "bit", "integer", "which", "also", "wraps", "around", "periodically"], "project": "ExoPlayer"}
{"id": 1333, "code": "public final synchronized long getLargestQueuedTimestampUs() {\n  return largestQueuedTimestampUs;\n}", "summary_tokens": ["returns", "the", "largest", "sample", "timestamp", "that", "has", "been", "queued", "since", "the", "last", "reset"], "project": "ExoPlayer"}
{"id": 198, "code": " static int getChannelCount(byte[] header) {\n  return header[9] & 0xFF;\n}", "summary_tokens": ["parses", "the", "channel", "count", "from", "an", "opus", "identification", "header"], "project": "ExoPlayer"}
{"id": 402, "code": "public int length() {\n  return entries.length;\n}", "summary_tokens": ["returns", "the", "number", "of", "metadata", "entries"], "project": "ExoPlayer"}
{"id": 97, "code": "private static FlacBinarySearchSeeker outputSeekMap(\n    FlacDecoderJni decoderJni,\n    FlacStreamMetadata streamMetadata,\n    long streamLength,\n    ExtractorOutput output,\n    OutputFrameHolder outputFrameHolder) {\n  boolean haveSeekTable = decoderJni.getSeekPoints( 0) != null;\n  FlacBinarySearchSeeker binarySearchSeeker = null;\n  SeekMap seekMap;\n  if (haveSeekTable) {\n    seekMap = new FlacSeekMap(streamMetadata.getDurationUs(), decoderJni);\n  } else if (streamLength != C.LENGTH_UNSET && streamMetadata.totalSamples > 0) {\n    long firstFramePosition = decoderJni.getDecodePosition();\n    binarySearchSeeker =\n        new FlacBinarySearchSeeker(\n            streamMetadata, firstFramePosition, streamLength, decoderJni, outputFrameHolder);\n    seekMap = binarySearchSeeker.getSeekMap();\n  } else {\n    seekMap = new SeekMap.Unseekable(streamMetadata.getDurationUs());\n  }\n  output.seekMap(seekMap);\n  return binarySearchSeeker;\n}", "summary_tokens": ["outputs", "a", "seek", "map", "and", "returns", "a", "flac", "binary", "search", "seeker", "if", "one", "is", "required", "to", "handle", "seeks"], "project": "ExoPlayer"}
{"id": 2388, "code": "public static int getMaxSupportedInstances(MediaCodecInfo encoderInfo, String mimeType) {\n  return encoderInfo.getCapabilitiesForType(mimeType).getMaxSupportedInstances();\n}", "summary_tokens": ["returns", "the", "number", "of", "max", "number", "of", "the", "supported", "concurrent", "codec", "instances"], "project": "ExoPlayer"}
{"id": 532, "code": "public static String getMimeTypeFromMp4ObjectType(int objectType) {\n  switch (objectType) {\n    case 0x20:\n      return MimeTypes.VIDEO_MP4V;\n    case 0x21:\n      return MimeTypes.VIDEO_H264;\n    case 0x23:\n      return MimeTypes.VIDEO_H265;\n    case 0x60:\n    case 0x61:\n    case 0x62:\n    case 0x63:\n    case 0x64:\n    case 0x65:\n      return MimeTypes.VIDEO_MPEG2;\n    case 0x6A:\n      return MimeTypes.VIDEO_MPEG;\n    case 0x69:\n    case 0x6B:\n      return MimeTypes.AUDIO_MPEG;\n    case 0xA3:\n      return MimeTypes.VIDEO_VC1;\n    case 0xB1:\n      return MimeTypes.VIDEO_VP9;\n    case 0x40:\n    case 0x66:\n    case 0x67:\n    case 0x68:\n      return MimeTypes.AUDIO_AAC;\n    case 0xA5:\n      return MimeTypes.AUDIO_AC3;\n    case 0xA6:\n      return MimeTypes.AUDIO_E_AC3;\n    case 0xA9:\n    case 0xAC:\n      return MimeTypes.AUDIO_DTS;\n    case 0xAA:\n    case 0xAB:\n      return MimeTypes.AUDIO_DTS_HD;\n    case 0xAD:\n      return MimeTypes.AUDIO_OPUS;\n    case 0xAE:\n      return MimeTypes.AUDIO_AC4;\n    default:\n      return null;\n  }\n}", "summary_tokens": ["returns", "the", "mime", "type", "corresponding", "to", "an", "mp", "0", "object", "type", "identifier", "as", "defined", "in", "rfc", "0", "and", "https", "mp", "0", "ra"], "project": "ExoPlayer"}
{"id": 1780, "code": "public void reset(OutputStream out) {\n  Assertions.checkState(closed);\n  this.out = out;\n  count = 0;\n  closed = false;\n}", "summary_tokens": ["resets", "this", "stream", "and", "uses", "the", "given", "output", "stream", "for", "writing"], "project": "ExoPlayer"}
{"id": 1, "code": "public void selectQueueItem(int itemIndex) {\n  setCurrentItem(itemIndex);\n}", "summary_tokens": ["plays", "a", "specified", "queue", "item", "in", "the", "current", "player"], "project": "ExoPlayer"}
{"id": 2336, "code": "public static Uri getTestUri(int serverRtspPortNumber) {\n  return Uri.parse(Util.formatInvariant(TEST_BASE_URI, serverRtspPortNumber));\n}", "summary_tokens": ["returns", "the", "test", "rtsp", "uri"], "project": "ExoPlayer"}
{"id": 167, "code": "public static int getExoPlayerRepeatMode(int repeatMode) {\n  switch (repeatMode) {\n    case SessionPlayer.REPEAT_MODE_ALL:\n    case SessionPlayer.REPEAT_MODE_GROUP:\n      return Player.REPEAT_MODE_ALL;\n    case SessionPlayer.REPEAT_MODE_ONE:\n      return Player.REPEAT_MODE_ONE;\n    case SessionPlayer.REPEAT_MODE_NONE:\n      return Player.REPEAT_MODE_OFF;\n    default:\n      throw new IllegalArgumentException();\n  }\n}", "summary_tokens": ["returns", "the", "exo", "player", "s", "repeat", "mode", "for", "the", "given", "repeat", "mode"], "project": "ExoPlayer"}
{"id": 428, "code": "public static IBinder getBinder(Bundle bundle, @Nullable String key) {\n  if (Util.SDK_INT >= 18) {\n    return bundle.getBinder(key);\n  } else {\n    return getBinderByReflection(bundle, key);\n  }\n}", "summary_tokens": ["gets", "an", "ibinder", "inside", "a", "bundle", "for", "all", "android", "versions"], "project": "ExoPlayer"}
{"id": 1296, "code": "default void onLoadCompleted(\n    int windowIndex,\n    @Nullable MediaPeriodId mediaPeriodId,\n    LoadEventInfo loadEventInfo,\n    MediaLoadData mediaLoadData) {}", "summary_tokens": ["called", "when", "a", "load", "ends"], "project": "ExoPlayer"}
{"id": 2591, "code": "private static boolean canShowMultiWindowTimeBar(Timeline timeline, Timeline.Window window) {\n  if (timeline.getWindowCount() > MAX_WINDOWS_FOR_MULTI_WINDOW_TIME_BAR) {\n    return false;\n  }\n  int windowCount = timeline.getWindowCount();\n  for (int i = 0; i < windowCount; i++) {\n    if (timeline.getWindow(i, window).durationUs == C.TIME_UNSET) {\n      return false;\n    }\n  }\n  return true;\n}", "summary_tokens": ["returns", "whether", "the", "specified", "timeline", "can", "be", "shown", "on", "a", "multi", "window", "time", "bar"], "project": "ExoPlayer"}
{"id": 1268, "code": "protected final void releaseChildSource(@UnknownNull T id) {\n  MediaSourceAndListener<T> removedChild = Assertions.checkNotNull(childSources.remove(id));\n  removedChild.mediaSource.releaseSource(removedChild.caller);\n  removedChild.mediaSource.removeEventListener(removedChild.eventListener);\n  removedChild.mediaSource.removeDrmEventListener(removedChild.eventListener);\n}", "summary_tokens": ["releases", "a", "child", "source"], "project": "ExoPlayer"}
{"id": 1312, "code": "private void postAppend(int length) {\n  totalBytesWritten += length;\n  if (totalBytesWritten == writeAllocationNode.endPosition) {\n    writeAllocationNode = writeAllocationNode.next;\n  }\n}", "summary_tokens": ["called", "after", "writing", "sample", "data"], "project": "ExoPlayer"}
{"id": 2806, "code": "public void resume() {\n    switch (state()) {\n        case CREATED:\n        case RUNNING:\n        case RESTORING:\n                \n            log.trace(\"Skip resuming since state is {}\", state());\n            break;\n\n        case SUSPENDED:\n                \n                \n\n                \n            try {\n                stateMgr.deleteCheckPointFileIfEOSEnabled();\n                log.debug(\"Deleted check point file upon resuming with EOS enabled\");\n            } catch (final IOException ioe) {\n                log.error(\"Encountered error while deleting the checkpoint file due to this exception\", ioe);\n            }\n\n            transitionTo(State.RESTORING);\n            log.info(\"Resumed to restoring state\");\n\n            break;\n\n        case CLOSED:\n            throw new IllegalStateException(\"Illegal state \" + state() + \" while resuming active task \" + id);\n\n        default:\n            throw new IllegalStateException(\"Unknown state \" + state() + \" while resuming active task \" + id);\n    }\n    timeCurrentIdlingStarted = Optional.empty();\n}", "summary_tokens": ["pre", "resume", "the", "task", "pre"], "project": "kafka"}
{"id": 2963, "code": "public boolean executionInfoEnabled() {\n    return executionInfoEnabled;\n}", "summary_tokens": ["whether", "the", "request", "includes", "detailed", "execution", "information"], "project": "kafka"}
{"id": 2377, "code": "public long remainingElectionTimeMs(long currentTimeMs) {\n    electionTimer.update(currentTimeMs);\n    return electionTimer.remainingMs();\n}", "summary_tokens": ["check", "the", "time", "remaining", "until", "the", "timeout", "expires"], "project": "kafka"}
{"id": 1454, "code": "private boolean isCompatible(List<String> serverProtocols, List<String> clientProtocols) {\n    assertNotNull(serverProtocols);\n    assertFalse(serverProtocols.isEmpty());\n    assertNotNull(clientProtocols);\n    assertFalse(clientProtocols.isEmpty());\n\n    return serverProtocols.contains(clientProtocols.get(0)) ||\n        (clientProtocols.get(0).equals(\"TLSv1.3\") && !Collections.disjoint(serverProtocols, clientProtocols));\n}", "summary_tokens": ["p", "the", "explanation", "of", "this", "check", "in", "the", "structure", "of", "the", "client", "hello", "ssl", "message"], "project": "kafka"}
{"id": 2717, "code": "public <NewK> Record<NewK, V> withKey(final NewK key) {\n    return new Record<>(key, value, timestamp, headers);\n}", "summary_tokens": ["a", "convenient", "way", "to", "produce", "a", "new", "record", "if", "you", "only", "need", "to", "change", "the", "key"], "project": "kafka"}
{"id": 1307, "code": "public boolean logIfAllowed() {\n    return logIfAllowed;\n}", "summary_tokens": ["indicates", "if", "audit", "logs", "tracking", "allowed", "access", "should", "include", "this", "action", "if", "result", "is", "allowed"], "project": "kafka"}
{"id": 91, "code": "private void processDisconnection(List<ClientResponse> responses,\n                                  String nodeId,\n                                  long now,\n                                  ChannelState disconnectState) {\n    connectionStates.disconnected(nodeId, now);\n    apiVersions.remove(nodeId);\n    nodesNeedingApiVersionsFetch.remove(nodeId);\n    switch (disconnectState.state()) {\n        case AUTHENTICATION_FAILED:\n            AuthenticationException exception = disconnectState.exception();\n            connectionStates.authenticationFailed(nodeId, now, exception);\n            log.error(\"Connection to node {} ({}) failed authentication due to: {}\", nodeId,\n                disconnectState.remoteAddress(), exception.getMessage());\n            break;\n        case AUTHENTICATE:\n            log.warn(\"Connection to node {} ({}) terminated during authentication. This may happen \" +\n                \"due to any of the following reasons: (1) Authentication failed due to invalid \" +\n                \"credentials with brokers older than 1.0.0, (2) Firewall blocking Kafka TLS \" +\n                \"traffic (eg it may only allow HTTPS traffic), (3) Transient network issue.\",\n                nodeId, disconnectState.remoteAddress());\n            break;\n        case NOT_CONNECTED:\n            log.warn(\"Connection to node {} ({}) could not be established. Broker may not be available.\", nodeId, disconnectState.remoteAddress());\n            break;\n        default:\n            break; \n    }\n\n    cancelInFlightRequests(nodeId, now, responses);\n    metadataUpdater.handleServerDisconnect(now, nodeId, Optional.ofNullable(disconnectState.exception()));\n}", "summary_tokens": ["post", "process", "disconnection", "of", "a", "node"], "project": "kafka"}
{"id": 1314, "code": "public void testIncrementals() {\n    Map<String, Uuid> topicIds = new HashMap<>();\n    Map<Uuid, String> topicNames = new HashMap<>();\n        \n    List<Short> versions = Arrays.asList((short) 12, ApiKeys.FETCH.latestVersion());\n    versions.forEach(version -> {\n        FetchSessionHandler handler = new FetchSessionHandler(LOG_CONTEXT, 1);\n        FetchSessionHandler.Builder builder = handler.newBuilder();\n        addTopicId(topicIds, topicNames, \"foo\", version);\n        Uuid fooId = topicIds.getOrDefault(\"foo\", Uuid.ZERO_UUID);\n        TopicPartition foo0 = new TopicPartition(\"foo\", 0);\n        TopicPartition foo1 = new TopicPartition(\"foo\", 1);\n        builder.add(foo0, new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        builder.add(foo1, new FetchRequest.PartitionData(fooId, 10, 110, 210, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data = builder.build();\n        assertMapsEqual(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 110, 210)),\n                data.toSend(), data.sessionPartitions());\n        assertEquals(INVALID_SESSION_ID, data.metadata().sessionId());\n        assertEquals(INITIAL_EPOCH, data.metadata().epoch());\n\n        FetchResponse resp = FetchResponse.of(Errors.NONE, 0, 123,\n            respMap(new RespEntry(\"foo\", 0, fooId, 10, 20),\n                    new RespEntry(\"foo\", 1, fooId, 10, 20)));\n        handler.handleResponse(resp, version);\n\n            \n        FetchSessionHandler.Builder builder2 = handler.newBuilder();\n        addTopicId(topicIds, topicNames, \"bar\", version);\n        Uuid barId = topicIds.getOrDefault(\"bar\", Uuid.ZERO_UUID);\n        TopicPartition bar0 = new TopicPartition(\"bar\", 0);\n        builder2.add(foo0, new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        builder2.add(foo1, new FetchRequest.PartitionData(fooId, 10, 120, 210, Optional.empty()));\n        builder2.add(bar0, new FetchRequest.PartitionData(barId, 20, 200, 200, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data2 = builder2.build();\n        assertFalse(data2.metadata().isFull());\n        assertMapEquals(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 120, 210),\n                new ReqEntry(\"bar\", barId, 0, 20, 200, 200)),\n                data2.sessionPartitions());\n        assertMapEquals(reqMap(new ReqEntry(\"bar\", barId, 0, 20, 200, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 120, 210)),\n                data2.toSend());\n\n        FetchResponse resp2 = FetchResponse.of(Errors.NONE, 0, 123,\n            respMap(new RespEntry(\"foo\", 1, fooId, 20, 20)));\n        handler.handleResponse(resp2, version);\n\n            \n            \n        FetchResponse resp3 = FetchResponse.of(Errors.INVALID_FETCH_SESSION_EPOCH, 0, INVALID_SESSION_ID,\n            respMap());\n        handler.handleResponse(resp3, version);\n\n        FetchSessionHandler.Builder builder4 = handler.newBuilder();\n        builder4.add(foo0, new FetchRequest.PartitionData(fooId, 0, 100, 200, Optional.empty()));\n        builder4.add(foo1, new FetchRequest.PartitionData(fooId, 10, 120, 210, Optional.empty()));\n        builder4.add(bar0, new FetchRequest.PartitionData(barId, 20, 200, 200, Optional.empty()));\n        FetchSessionHandler.FetchRequestData data4 = builder4.build();\n        assertTrue(data4.metadata().isFull());\n        assertEquals(data2.metadata().sessionId(), data4.metadata().sessionId());\n        assertEquals(INITIAL_EPOCH, data4.metadata().epoch());\n        assertMapsEqual(reqMap(new ReqEntry(\"foo\", fooId, 0, 0, 100, 200),\n                new ReqEntry(\"foo\", fooId, 1, 10, 120, 210),\n                new ReqEntry(\"bar\", barId, 0, 20, 200, 200)),\n                data4.sessionPartitions(), data4.toSend());\n    });\n}", "summary_tokens": ["test", "handling", "an", "incremental", "fetch", "session"], "project": "kafka"}
{"id": 1273, "code": "final public void clear(int expectedNumElements) {\n    if (expectedNumElements == 0) {\n            \n        this.head = HeadElement.EMPTY;\n        this.elements = EMPTY_ELEMENTS;\n        this.size = 0;\n    } else {\n        this.head = new HeadElement();\n        this.elements = new Element[calculateCapacity(expectedNumElements)];\n        this.size = 0;\n    }\n}", "summary_tokens": ["removes", "all", "of", "the", "elements", "from", "this", "set", "and", "resets", "the", "set", "capacity", "based", "on", "the", "provided", "expected", "number", "of", "elements"], "project": "kafka"}
{"id": 2378, "code": "public long append(int epoch, List<T> records) {\n    return append(epoch, records, false);\n}", "summary_tokens": ["append", "a", "list", "of", "records", "into", "as", "many", "batches", "as", "necessary"], "project": "kafka"}
{"id": 1663, "code": "public ConnectorType type() {\n    return type;\n}", "summary_tokens": ["provides", "the", "type", "of", "the", "connector"], "project": "kafka"}
{"id": 2531, "code": "public static ConfigDef configDef() {\n    return new ConfigDef(CONFIG);\n}", "summary_tokens": ["return", "a", "copy", "of", "the", "config", "definition"], "project": "kafka"}
{"id": 2737, "code": "public synchronized ProcessorTopology buildGlobalStateTopology() {\n    Objects.requireNonNull(applicationId, \"topology has not completed optimization\");\n\n    final Set<String> globalGroups = globalNodeGroups();\n    if (globalGroups.isEmpty()) {\n        return null;\n    }\n    return build(globalGroups);\n}", "summary_tokens": ["builds", "the", "topology", "for", "any", "global", "state", "stores", "processor", "topology", "of", "global", "state"], "project": "kafka"}
{"id": 2908, "code": "public NamedTopologyBuilder newNamedTopologyBuilder(final String topologyName) {\n    return newNamedTopologyBuilder(topologyName, new Properties());\n}", "summary_tokens": ["provides", "a", "high", "level", "dsl", "for", "specifying", "the", "processing", "logic", "of", "your", "application", "and", "building", "it", "into", "an", "independent", "topology", "that", "can", "be", "executed", "by", "this", "kafka", "streams"], "project": "kafka"}
{"id": 1953, "code": "public ClusterConfigState snapshot() {\n    synchronized (lock) {\n            \n            \n        return new ClusterConfigState(\n                offset,\n                sessionKey,\n                new HashMap<>(connectorTaskCounts),\n                new HashMap<>(connectorConfigs),\n                new HashMap<>(connectorTargetStates),\n                new HashMap<>(taskConfigs),\n                new HashMap<>(connectorTaskCountRecords),\n                new HashMap<>(connectorTaskConfigGenerations),\n                new HashSet<>(connectorsPendingFencing),\n                new HashSet<>(inconsistent),\n                configTransformer\n        );\n    }\n}", "summary_tokens": ["get", "a", "snapshot", "of", "the", "current", "state", "of", "the", "cluster"], "project": "kafka"}
{"id": 94, "code": "private void handleCompletedSends(List<ClientResponse> responses, long now) {\n        \n    for (NetworkSend send : this.selector.completedSends()) {\n        InFlightRequest request = this.inFlightRequests.lastSent(send.destinationId());\n        if (!request.expectResponse) {\n            this.inFlightRequests.completeLastSent(send.destinationId());\n            responses.add(request.completed(null, now));\n        }\n    }\n}", "summary_tokens": ["handle", "any", "completed", "request", "send"], "project": "kafka"}
{"id": 2307, "code": "private void checkSnapshotSubcontent(\n    List<ApiMessageAndVersion> expected,\n    Iterator<Batch<ApiMessageAndVersion>> iterator\n) throws Exception {\n    RecordTestUtils.deepSortRecords(expected);\n\n    List<ApiMessageAndVersion> actual = StreamSupport\n        .stream(Spliterators.spliteratorUnknownSize(iterator, Spliterator.ORDERED), false)\n        .flatMap(batch ->  batch.records().stream())\n        .collect(Collectors.toList());\n\n    RecordTestUtils.deepSortRecords(actual);\n\n    int expectedIndex = 0;\n    for (ApiMessageAndVersion current : actual) {\n        while (expectedIndex < expected.size() && !expected.get(expectedIndex).equals(current)) {\n            expectedIndex += 1;\n        }\n\n        if (expectedIndex >= expected.size()) {\n            fail(\"Failed to find record \" + current + \" in the expected record set: \" + expected);\n        }\n\n        expectedIndex += 1;\n    }\n}", "summary_tokens": ["this", "function", "checks", "that", "the", "iterator", "is", "a", "subset", "of", "the", "expected", "list"], "project": "kafka"}
{"id": 1098, "code": "private void sendAuthenticationFailureResponse() throws IOException {\n    if (authenticationFailureSend == null)\n        return;\n    sendKafkaResponse(authenticationFailureSend);\n    authenticationFailureSend = null;\n}", "summary_tokens": ["send", "any", "authentication", "failure", "response", "that", "may", "have", "been", "previously", "built"], "project": "kafka"}
{"id": 47, "code": "public boolean canSendMore(String node) {\n    Deque<NetworkClient.InFlightRequest> queue = requests.get(node);\n    return queue == null || queue.isEmpty() ||\n           (queue.peekFirst().send.completed() && queue.size() < this.maxInFlightRequestsPerConnection);\n}", "summary_tokens": ["can", "we", "send", "more", "requests", "to", "this", "node"], "project": "kafka"}
{"id": 2324, "code": "public void testAuthorizationPriorToCompleteInitialLoad() throws Exception {\n    StandardAuthorizer authorizer = new StandardAuthorizer();\n    authorizer.configure(Collections.singletonMap(SUPER_USERS_CONFIG, \"User:superman\"));\n    assertThrows(AuthorizerNotReadyException.class, () ->\n        authorizer.authorize(new MockAuthorizableRequestContext.Builder().\n                setPrincipal(new KafkaPrincipal(USER_TYPE, \"bob\")).build(),\n            Arrays.asList(newAction(READ, TOPIC, \"green1\"),\n                newAction(READ, TOPIC, \"green2\"))));\n    assertEquals(Arrays.asList(ALLOWED, ALLOWED),\n        authorizer.authorize(new MockAuthorizableRequestContext.Builder().\n                setPrincipal(new KafkaPrincipal(USER_TYPE, \"superman\")).build(),\n            Arrays.asList(newAction(READ, TOPIC, \"green1\"),\n                newAction(WRITE, GROUP, \"wheel\"))));\n}", "summary_tokens": ["test", "attempts", "to", "authorize", "prior", "to", "complete", "initial", "load"], "project": "kafka"}
{"id": 1392, "code": "public void testExpireClosedConnectionWithPendingReceives() throws Exception {\n    KafkaChannel channel = createConnectionWithPendingReceives(5);\n    server.closeConnections();\n    verifyChannelExpiry(channel);\n}", "summary_tokens": ["verifies", "that", "a", "muted", "connection", "closed", "by", "peer", "is", "expired", "on", "idle", "timeout", "even", "if", "there", "are", "pending", "receives", "on", "the", "socket"], "project": "kafka"}
{"id": 1061, "code": "public Send buildResponseSend(AbstractResponse body) {\n    return body.toSend(header.toResponseHeader(), apiVersion());\n}", "summary_tokens": ["build", "a", "send", "for", "direct", "transmission", "of", "the", "provided", "response", "over", "the", "network"], "project": "kafka"}
{"id": 1463, "code": "public void testIteratorWithLimits() throws IOException {\n    RecordBatch batch = batches(fileRecords).get(1);\n    int start = fileRecords.searchForOffsetWithSize(1, 0).position;\n    int size = batch.sizeInBytes();\n    FileRecords slice = fileRecords.slice(start, size);\n    assertEquals(Collections.singletonList(batch), batches(slice));\n    FileRecords slice2 = fileRecords.slice(start, size - 1);\n    assertEquals(Collections.emptyList(), batches(slice2));\n}", "summary_tokens": ["test", "that", "the", "message", "set", "iterator", "obeys", "start", "and", "end", "slicing"], "project": "kafka"}
{"id": 324, "code": "public short replicationFactor() {\n    return replicationFactor.orElse(CreateTopicsRequest.NO_REPLICATION_FACTOR);\n}", "summary_tokens": ["the", "replication", "factor", "for", "the", "new", "topic", "or", "0", "if", "a", "replica", "assignment", "has", "been", "specified"], "project": "kafka"}
{"id": 1569, "code": "public static File tempFile(final String contents) throws IOException {\n    final File file = tempFile();\n    Files.write(file.toPath(), contents.getBytes(StandardCharsets.UTF_8));\n    return file;\n}", "summary_tokens": ["create", "a", "file", "with", "the", "given", "contents", "in", "the", "default", "temporary", "file", "directory", "using", "kafka", "as", "the", "prefix", "and", "tmp", "as", "the", "suffix", "to", "generate", "its", "name"], "project": "kafka"}
{"id": 346, "code": "public Set<AclOperation>  authorizedOperations() {\n    return authorizedOperations;\n}", "summary_tokens": ["authorized", "operations", "for", "this", "topic", "or", "null", "if", "this", "is", "not", "known"], "project": "kafka"}
{"id": 192, "code": "public CreatePartitionsOptions retryOnQuotaViolation(boolean retryOnQuotaViolation) {\n    this.retryOnQuotaViolation = retryOnQuotaViolation;\n    return this;\n}", "summary_tokens": ["set", "to", "true", "if", "quota", "violation", "should", "be", "automatically", "retried"], "project": "kafka"}
{"id": 1081, "code": "public static JaasContext loadClientContext(Map<String, ?> configs) {\n    Password dynamicJaasConfig = (Password) configs.get(SaslConfigs.SASL_JAAS_CONFIG);\n    return load(JaasContext.Type.CLIENT, null, GLOBAL_CONTEXT_NAME_CLIENT, dynamicJaasConfig);\n}", "summary_tokens": ["returns", "an", "instance", "of", "this", "class"], "project": "kafka"}
{"id": 1621, "code": "public String getString(String fieldName) {\n    return (String) getCheckType(fieldName, Schema.Type.STRING);\n}", "summary_tokens": ["equivalent", "to", "calling", "get", "string", "and", "casting", "the", "result", "to", "a", "string"], "project": "kafka"}
{"id": 493, "code": "public void validateOffsetsIfNeeded() {\n    RuntimeException exception = cachedOffsetForLeaderException.getAndSet(null);\n    if (exception != null)\n        throw exception;\n\n        \n        \n    validatePositionsOnMetadataChange();\n\n        \n    Map<TopicPartition, FetchPosition> partitionsToValidate = subscriptions\n            .partitionsNeedingValidation(time.milliseconds())\n            .stream()\n            .filter(tp -> subscriptions.position(tp) != null)\n            .collect(Collectors.toMap(Function.identity(), subscriptions::position));\n\n    validateOffsetsAsync(partitionsToValidate);\n}", "summary_tokens": ["validate", "offsets", "for", "all", "assigned", "partitions", "for", "which", "a", "leader", "change", "has", "been", "detected"], "project": "kafka"}
{"id": 448, "code": "private void prepopulateCurrentAssignments(Map<String, Subscription> subscriptions,\n                                           Map<TopicPartition, ConsumerGenerationPair> prevAssignment) {\n        \n        \n        \n\n    for (Map.Entry<String, Subscription> subscriptionEntry: subscriptions.entrySet()) {\n        String consumer = subscriptionEntry.getKey();\n        Subscription subscription = subscriptionEntry.getValue();\n        if (subscription.userData() != null) {\n                \n            subscription.userData().rewind();\n        }\n        MemberData memberData = memberData(subscriptionEntry.getValue());\n\n            \n        if (memberData.generation.isPresent() && memberData.generation.get() < maxGeneration) {\n                \n            updatePrevAssignment(prevAssignment, memberData.partitions, consumer, memberData.generation.get());\n        } else if (!memberData.generation.isPresent() && maxGeneration > DEFAULT_GENERATION) {\n                \n                \n            updatePrevAssignment(prevAssignment, memberData.partitions, consumer, DEFAULT_GENERATION);\n        }\n    }\n}", "summary_tokens": ["filling", "in", "the", "prev", "assignment", "from", "the", "subscriptions"], "project": "kafka"}
{"id": 1318, "code": "public void prepareResponse(RequestMatcher matcher, AbstractResponse response, boolean disconnected) {\n    prepareResponseFrom(matcher, response, null, disconnected, false);\n}", "summary_tokens": ["prepare", "a", "response", "for", "a", "request", "matching", "the", "provided", "matcher"], "project": "kafka"}
{"id": 102, "code": "public short latestUsableVersion(ApiKeys apiKey, short oldestAllowedVersion, short latestAllowedVersion) {\n    if (!supportedVersions.containsKey(apiKey))\n        throw new UnsupportedVersionException(\"The broker does not support \" + apiKey);\n    ApiVersion supportedVersion = supportedVersions.get(apiKey);\n    Optional<ApiVersion> intersectVersion = ApiVersionsResponse.intersect(supportedVersion,\n        new ApiVersion()\n            .setApiKey(apiKey.id)\n            .setMinVersion(oldestAllowedVersion)\n            .setMaxVersion(latestAllowedVersion));\n\n    if (intersectVersion.isPresent())\n        return intersectVersion.get().maxVersion();\n    else\n        throw new UnsupportedVersionException(\"The broker does not support \" + apiKey +\n            \" with version in range [\" + oldestAllowedVersion + \",\" + latestAllowedVersion + \"]. The supported\" +\n            \" range is [\" + supportedVersion.minVersion() + \",\" + supportedVersion.maxVersion() + \"].\");\n}", "summary_tokens": ["get", "the", "latest", "version", "supported", "by", "the", "broker", "within", "an", "allowed", "range", "of", "versions"], "project": "kafka"}
{"id": 166, "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["return", "a", "future", "which", "succeeds", "only", "if", "all", "the", "user", "scram", "credential", "alterations", "succeed"], "project": "kafka"}
{"id": 1306, "code": "public AclOperation operation() {\n    return operation;\n}", "summary_tokens": ["a", "non", "null", "operation", "being", "performed"], "project": "kafka"}
{"id": 1913, "code": "public Connector createConnector(String listener, boolean isAdmin) {\n    Matcher listenerMatcher = LISTENER_PATTERN.matcher(listener);\n\n    if (!listenerMatcher.matches())\n        throw new ConfigException(\"Listener doesn't have the right format (protocol://hostname:port).\");\n\n    String protocol = listenerMatcher.group(1).toLowerCase(Locale.ENGLISH);\n\n    if (!PROTOCOL_HTTP.equals(protocol) && !PROTOCOL_HTTPS.equals(protocol))\n        throw new ConfigException(String.format(\"Listener protocol must be either \\\"%s\\\" or \\\"%s\\\".\", PROTOCOL_HTTP, PROTOCOL_HTTPS));\n\n    String hostname = listenerMatcher.group(2);\n    int port = Integer.parseInt(listenerMatcher.group(3));\n\n    ServerConnector connector;\n\n    if (PROTOCOL_HTTPS.equals(protocol)) {\n        SslContextFactory ssl;\n        if (isAdmin) {\n            ssl = SSLUtils.createServerSideSslContextFactory(config, ADMIN_LISTENERS_HTTPS_CONFIGS_PREFIX);\n        } else {\n            ssl = SSLUtils.createServerSideSslContextFactory(config);\n        }\n        connector = new ServerConnector(jettyServer, ssl);\n        if (!isAdmin) {\n            connector.setName(String.format(\"%s_%s%d\", PROTOCOL_HTTPS, hostname, port));\n        }\n    } else {\n        connector = new ServerConnector(jettyServer);\n        if (!isAdmin) {\n            connector.setName(String.format(\"%s_%s%d\", PROTOCOL_HTTP, hostname, port));\n        }\n    }\n\n    if (isAdmin) {\n        connector.setName(ADMIN_SERVER_CONNECTOR_NAME);\n    }\n\n    if (!hostname.isEmpty())\n        connector.setHost(hostname);\n\n    connector.setPort(port);\n\n    return connector;\n}", "summary_tokens": ["creates", "jetty", "connector", "according", "to", "configuration"], "project": "kafka"}
{"id": 1661, "code": "public ConnectorState connectorState() {\n    return connectorState;\n}", "summary_tokens": ["provides", "the", "current", "state", "of", "the", "connector"], "project": "kafka"}
{"id": 2030, "code": "public void recordConnectorStart() {\n    startAndStopCounter.recordStart();\n}", "summary_tokens": ["record", "that", "this", "connector", "has", "been", "started"], "project": "kafka"}
{"id": 2760, "code": "public String toString(final String indent) {\n    final Map<SourceNode<?, ?>, List<String>> sourceToTopics = new HashMap<>();\n    for (final Map.Entry<String, SourceNode<?, ?>> sourceNodeEntry : sourceNodesByTopic.entrySet()) {\n        final String topic = sourceNodeEntry.getKey();\n        final SourceNode<?, ?> source = sourceNodeEntry.getValue();\n        sourceToTopics.computeIfAbsent(source, s -> new ArrayList<>());\n        sourceToTopics.get(source).add(topic);\n    }\n\n    final StringBuilder sb = new StringBuilder(indent + \"ProcessorTopology:\\n\");\n\n        \n    for (final Map.Entry<SourceNode<?, ?>, List<String>> sourceNodeEntry : sourceToTopics.entrySet()) {\n        final SourceNode<?, ?> source = sourceNodeEntry.getKey();\n        final List<String> topics = sourceNodeEntry.getValue();\n        sb.append(source.toString(indent + \"\\t\"))\n            .append(topicsToString(indent + \"\\t\", topics))\n            .append(childrenToString(indent + \"\\t\", source.children()));\n    }\n    return sb.toString();\n}", "summary_tokens": ["produces", "a", "string", "representation", "containing", "useful", "information", "this", "topology"], "project": "kafka"}
{"id": 1079, "code": "public String findIndefiniteField() {\n    if (resourceType == ResourceType.ANY)\n        return \"Resource type is ANY.\";\n    if (resourceType == ResourceType.UNKNOWN)\n        return \"Resource type is UNKNOWN.\";\n    if (name == null)\n        return \"Resource name is NULL.\";\n    if (patternType == PatternType.MATCH)\n        return \"Resource pattern type is MATCH.\";\n    if (patternType == PatternType.UNKNOWN)\n        return \"Resource pattern type is UNKNOWN.\";\n    return null;\n}", "summary_tokens": ["a", "string", "describing", "any", "any", "or", "unknown", "field", "or", "null", "if", "there", "is", "no", "such", "field"], "project": "kafka"}
{"id": 3234, "code": "public void beginShutdown(boolean stopAgents) {\n    if (shutdown.compareAndSet(false, true)) {\n        executor.submit(new Shutdown(stopAgents));\n    }\n}", "summary_tokens": ["initiate", "shutdown", "but", "do", "not", "wait", "for", "it", "to", "complete"], "project": "kafka"}
{"id": 3188, "code": "public boolean committed() {\n    return committed;\n}", "summary_tokens": ["whether", "processor", "context", "commit", "has", "been", "called", "in", "this", "context"], "project": "kafka"}
{"id": 3098, "code": "public static <K, V> List<ConsumerRecord<K, V>> waitUntilMinRecordsReceived(final Properties consumerConfig,\n                                                                            final String topic,\n                                                                            final int expectedNumRecords,\n                                                                            final long waitTime) throws Exception {\n    final List<ConsumerRecord<K, V>> accumData = new ArrayList<>();\n    final String reason = String.format(\n        \"Did not receive all %d records from topic %s within %d ms\",\n        expectedNumRecords,\n        topic,\n        waitTime\n    );\n    try (final Consumer<K, V> consumer = createConsumer(consumerConfig)) {\n        retryOnExceptionWithTimeout(waitTime, () -> {\n            final List<ConsumerRecord<K, V>> readData =\n                readRecords(topic, consumer, waitTime, expectedNumRecords);\n            accumData.addAll(readData);\n            assertThat(reason, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n        });\n    }\n    return accumData;\n}", "summary_tokens": ["wait", "until", "enough", "data", "consumer", "records", "has", "been", "consumed"], "project": "kafka"}
{"id": 239, "code": "public KafkaFuture<Map<String, ConsumerGroupDescription>> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0])).thenApply(\n        nil -> {\n            Map<String, ConsumerGroupDescription> descriptions = new HashMap<>(futures.size());\n            futures.forEach((key, future) -> {\n                try {\n                    descriptions.put(key, future.get());\n                } catch (InterruptedException | ExecutionException e) {\n                        \n                        \n                    throw new RuntimeException(e);\n                }\n            });\n            return descriptions;\n        });\n}", "summary_tokens": ["return", "a", "future", "which", "yields", "all", "consumer", "group", "description", "objects", "if", "all", "the", "describes", "succeed"], "project": "kafka"}
{"id": 216, "code": "public DeleteTopicsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}", "summary_tokens": ["set", "the", "timeout", "in", "milliseconds", "for", "this", "operation", "or", "null", "if", "the", "default", "api", "timeout", "for", "the", "admin", "client", "should", "be", "used"], "project": "kafka"}
{"id": 719, "code": "public AclPermissionType permissionType() {\n    return data.permissionType();\n}", "summary_tokens": ["return", "the", "acl", "permission", "type"], "project": "kafka"}
{"id": 3169, "code": "public Map<String, StateStore> getAllStateStores() {\n    final Map<String, StateStore> allStores = new HashMap<>();\n    for (final String storeName : internalTopologyBuilder.allStateStoreNames()) {\n        allStores.put(storeName, getStateStore(storeName, false));\n    }\n    return allStores;\n}", "summary_tokens": ["get", "all", "state", "store", "state", "stores", "from", "the", "topology"], "project": "kafka"}
{"id": 2064, "code": "public Collection<TopicPartition> assignment() {\n    return partitions.values().stream()\n            .filter(PartitionHistory::isAssigned)\n            .map(PartitionHistory::topicPartition)\n            .collect(Collectors.toSet());\n}", "summary_tokens": ["the", "complete", "set", "of", "partitions", "currently", "assigned", "to", "this", "sink", "task"], "project": "kafka"}
{"id": 1167, "code": "public String failureOpenIdConfig() {\n    return failureOpenIdConfig;\n}", "summary_tokens": ["return", "the", "potentially", "null", "open", "id", "connect", "configuration", "to", "be", "reported", "with", "the", "failure"], "project": "kafka"}
{"id": 2610, "code": "public static <K, V> Produced<K, V> keySerde(final Serde<K> keySerde) {\n    return new Produced<>(keySerde, null, null, null);\n}", "summary_tokens": ["create", "a", "produced", "instance", "with", "provided", "key", "serde"], "project": "kafka"}
{"id": 1770, "code": "public boolean awaitAllMessages(long timeout, TimeUnit timeUnit) {\n        \n        \n    CountDownLatch messageDrainLatch;\n    synchronized (this) {\n        messageDrainLatch = new CountDownLatch(numUnackedMessages);\n        this.messageDrainLatch = messageDrainLatch;\n    }\n    try {\n        return messageDrainLatch.await(timeout, timeUnit);\n    } catch (InterruptedException e) {\n        return false;\n    }\n}", "summary_tokens": ["wait", "for", "all", "currently", "in", "flight", "messages", "to", "be", "acknowledged", "up", "to", "the", "requested", "timeout"], "project": "kafka"}
{"id": 3131, "code": "public static LegacySubscriptionInfoSerde decode(final ByteBuffer data) {\n\n        \n    data.rewind();\n\n    final int usedVersion = data.getInt();\n    if (usedVersion > 2 && usedVersion < 7) {\n        final int latestSupportedVersion = data.getInt();\n        final UUID processId = decodeProcessId(data);\n        final Set<TaskId> prevTasks = decodeTasks(data, usedVersion);\n        final Set<TaskId> standbyTasks = decodeTasks(data, usedVersion);\n        final String userEndPoint = decodeUserEndpoint(data);\n        return new LegacySubscriptionInfoSerde(usedVersion, latestSupportedVersion, processId, prevTasks, standbyTasks, userEndPoint);\n    } else if (usedVersion == 2) {\n        final UUID processId = decodeProcessId(data);\n        final Set<TaskId> prevTasks = decodeTasks(data, usedVersion);\n        final Set<TaskId> standbyTasks = decodeTasks(data, usedVersion);\n        final String userEndPoint = decodeUserEndpoint(data);\n        return new LegacySubscriptionInfoSerde(2, UNKNOWN, processId, prevTasks, standbyTasks, userEndPoint);\n    } else if (usedVersion == 1) {\n        final UUID processId = decodeProcessId(data);\n        final Set<TaskId> prevTasks = decodeTasks(data, usedVersion);\n        final Set<TaskId> standbyTasks = decodeTasks(data, usedVersion);\n        return new LegacySubscriptionInfoSerde(1, UNKNOWN, processId, prevTasks, standbyTasks, null);\n    } else {\n        final int latestSupportedVersion = data.getInt();\n        log.info(\"Unable to decode subscription data: used version: {}; latest supported version: {}\", usedVersion, LATEST_SUPPORTED_VERSION);\n        return new LegacySubscriptionInfoSerde(usedVersion, latestSupportedVersion, null, null, null, null);\n    }\n}", "summary_tokens": ["task", "assignment", "exception", "if", "method", "fails", "to", "decode", "the", "data"], "project": "kafka"}
{"id": 1388, "code": "public void testConnectionRefused() throws Exception {\n    String node = \"0\";\n    ServerSocket nonListeningSocket = new ServerSocket(0);\n    int nonListeningPort = nonListeningSocket.getLocalPort();\n    selector.connect(node, new InetSocketAddress(\"localhost\", nonListeningPort), BUFFER_SIZE, BUFFER_SIZE);\n    while (selector.disconnected().containsKey(node)) {\n        assertEquals(ChannelState.NOT_CONNECTED, selector.disconnected().get(node));\n        selector.poll(1000L);\n    }\n    nonListeningSocket.close();\n}", "summary_tokens": ["sending", "a", "request", "to", "a", "node", "not", "listening", "on", "that", "port", "should", "result", "in", "disconnection"], "project": "kafka"}
{"id": 551, "code": "private long nextOffset(TopicPartition tp) {\n    Long offset = this.offsets.get(tp);\n    if (offset == null) {\n        this.offsets.put(tp, 1L);\n        return 0L;\n    } else {\n        Long next = offset + 1;\n        this.offsets.put(tp, next);\n        return offset;\n    }\n}", "summary_tokens": ["get", "the", "next", "offset", "for", "this", "topic", "partition"], "project": "kafka"}
{"id": 1799, "code": "public boolean connectorOffsetsTopicsPermitted() {\n    return false;\n}", "summary_tokens": ["determine", "whether", "this", "worker", "supports", "per", "connector", "source", "offsets", "topics"], "project": "kafka"}
{"id": 1295, "code": "public void resetDeadline(long deadlineMs) {\n    if (deadlineMs < 0)\n        throw new IllegalArgumentException(\"Invalid negative deadline \" + deadlineMs);\n\n    this.timeoutMs = Math.max(0, deadlineMs - this.currentTimeMs);\n    this.startMs = this.currentTimeMs;\n    this.deadlineMs = deadlineMs;\n}", "summary_tokens": ["reset", "the", "timer", "s", "deadline", "directly"], "project": "kafka"}
{"id": 2025, "code": "public void expectedCommits(int expected) {\n    expectedCommits = expected;\n    recordsToCommitLatch = new CountDownLatch(expected);\n}", "summary_tokens": ["set", "the", "number", "of", "expected", "commits", "performed", "by", "this", "connector"], "project": "kafka"}
{"id": 2759, "code": "void recycle() {\n    log.debug(\"Recycling state for {} task {}.\", taskType, taskId);\n\n    final List<TopicPartition> allChangelogs = getAllChangelogTopicPartitions();\n    changelogReader.unregister(allChangelogs);\n}", "summary_tokens": ["alternative", "to", "close", "that", "just", "resets", "the", "changelogs", "without", "closing", "any", "of", "the", "underlying", "state", "or", "unregistering", "the", "stores", "themselves"], "project": "kafka"}
{"id": 1719, "code": "public static Set<String> upstreamClusters(Map<String, Object> properties)\n        throws InterruptedException, TimeoutException {\n    try (MirrorClient client = new MirrorClient(properties)) {\n        return client.upstreamClusters();\n    }\n}", "summary_tokens": ["find", "all", "upstream", "clusters"], "project": "kafka"}
{"id": 575, "code": "public ByteBuffer allocate(int size, long maxTimeToBlockMs) throws InterruptedException {\n    if (size > this.totalMemory)\n        throw new IllegalArgumentException(\"Attempt to allocate \" + size\n                                           + \" bytes, but there is a hard limit of \"\n                                           + this.totalMemory\n                                           + \" on memory allocations.\");\n\n    ByteBuffer buffer = null;\n    this.lock.lock();\n\n    if (this.closed) {\n        this.lock.unlock();\n        throw new KafkaException(\"Producer closed while allocating memory\");\n    }\n\n    try {\n            \n        if (size == poolableSize && !this.free.isEmpty())\n            return this.free.pollFirst();\n\n            \n            \n        int freeListSize = freeSize() * this.poolableSize;\n        if (this.nonPooledAvailableMemory + freeListSize >= size) {\n                \n                \n            freeUp(size);\n            this.nonPooledAvailableMemory -= size;\n        } else {\n                \n            int accumulated = 0;\n            Condition moreMemory = this.lock.newCondition();\n            try {\n                long remainingTimeToBlockNs = TimeUnit.MILLISECONDS.toNanos(maxTimeToBlockMs);\n                this.waiters.addLast(moreMemory);\n                    \n                    \n                while (accumulated < size) {\n                    long startWaitNs = time.nanoseconds();\n                    long timeNs;\n                    boolean waitingTimeElapsed;\n                    try {\n                        waitingTimeElapsed = !moreMemory.await(remainingTimeToBlockNs, TimeUnit.NANOSECONDS);\n                    } finally {\n                        long endWaitNs = time.nanoseconds();\n                        timeNs = Math.max(0L, endWaitNs - startWaitNs);\n                        recordWaitTime(timeNs);\n                    }\n\n                    if (this.closed)\n                        throw new KafkaException(\"Producer closed while allocating memory\");\n\n                    if (waitingTimeElapsed) {\n                        this.metrics.sensor(\"buffer-exhausted-records\").record();\n                        throw new BufferExhaustedException(\"Failed to allocate \" + size + \" bytes within the configured max blocking time \"\n                            + maxTimeToBlockMs + \" ms. Total memory: \" + totalMemory() + \" bytes. Available memory: \" + availableMemory()\n                            + \" bytes. Poolable size: \" + poolableSize() + \" bytes\");\n                    }\n\n                    remainingTimeToBlockNs -= timeNs;\n\n                        \n                        \n                    if (accumulated == 0 && size == this.poolableSize && !this.free.isEmpty()) {\n                            \n                        buffer = this.free.pollFirst();\n                        accumulated = size;\n                    } else {\n                            \n                            \n                        freeUp(size - accumulated);\n                        int got = (int) Math.min(size - accumulated, this.nonPooledAvailableMemory);\n                        this.nonPooledAvailableMemory -= got;\n                        accumulated += got;\n                    }\n                }\n                    \n                accumulated = 0;\n            } finally {\n                    \n                this.nonPooledAvailableMemory += accumulated;\n                this.waiters.remove(moreMemory);\n            }\n        }\n    } finally {\n            \n            \n        try {\n            if (!(this.nonPooledAvailableMemory == 0 && this.free.isEmpty()) && !this.waiters.isEmpty())\n                this.waiters.peekFirst().signal();\n        } finally {\n                \n            lock.unlock();\n        }\n    }\n\n    if (buffer == null)\n        return safeAllocateByteBuffer(size);\n    else\n        return buffer;\n}", "summary_tokens": ["allocate", "a", "buffer", "of", "the", "given", "size"], "project": "kafka"}
{"id": 2934, "code": "public Position copy() {\n    return new Position(deepCopy(position));\n}", "summary_tokens": ["create", "a", "deep", "copy", "of", "the", "position"], "project": "kafka"}
{"id": 150, "code": "public static AdminClient create(Map<String, Object> conf) {\n    return (AdminClient) Admin.create(conf);\n}", "summary_tokens": ["create", "a", "new", "admin", "with", "the", "given", "configuration"], "project": "kafka"}
{"id": 509, "code": "public boolean succeeded() {\n    return isDone() && !failed();\n}", "summary_tokens": ["check", "if", "the", "request", "succeeded", "true", "if", "the", "request", "completed", "and", "was", "successful"], "project": "kafka"}
{"id": 1667, "code": "public Map<TopicPartition, OffsetAndMetadata> preCommit(Map<TopicPartition, OffsetAndMetadata> currentOffsets) {\n    flush(currentOffsets);\n    return currentOffsets;\n}", "summary_tokens": ["pre", "commit", "hook", "invoked", "prior", "to", "an", "offset", "commit"], "project": "kafka"}
{"id": 1970, "code": "private synchronized boolean handleFinishWrite(long flushId, Throwable error, Void result) {\n        \n        \n    if (flushId != currentFlushId)\n        return false;\n\n    if (error != null) {\n        cancelFlush();\n    } else {\n        currentFlushId++;\n        toFlush = null;\n    }\n    return true;\n}", "summary_tokens": ["handle", "completion", "of", "a", "write"], "project": "kafka"}
{"id": 3253, "code": "Map<String, List<TopicPartition>> materializeTopics() {\n    Map<String, List<TopicPartition>> partitionsByTopics = new HashMap<>();\n\n    for (String rawTopicName : this.activeTopics) {\n        Set<String> expandedNames = expandTopicName(rawTopicName);\n        if (!expandedNames.iterator().next().matches(VALID_EXPANDED_TOPIC_NAME_PATTERN))\n            throw new IllegalArgumentException(String.format(\"Expanded topic name %s is invalid\", rawTopicName));\n\n        for (String topicName : expandedNames) {\n            TopicPartition partition = null;\n            if (topicName.contains(\":\")) {\n                String[] topicAndPartition = topicName.split(\":\");\n                topicName = topicAndPartition[0];\n                partition = new TopicPartition(topicName, Integer.parseInt(topicAndPartition[1]));\n            }\n            if (!partitionsByTopics.containsKey(topicName)) {\n                partitionsByTopics.put(topicName, new ArrayList<>());\n            }\n            if (partition != null) {\n                partitionsByTopics.get(topicName).add(partition);\n            }\n        }\n    }\n\n    return partitionsByTopics;\n}", "summary_tokens": ["materializes", "a", "list", "of", "topic", "names", "optionally", "with", "ranges", "into", "a", "map", "of", "the", "topics", "and", "their", "partitions"], "project": "kafka"}
{"id": 2891, "code": "public Map<String, String> getProperties(final Map<String, String> defaultProperties, final long additionalRetentionMs) {\n        \n    final Map<String, String> topicConfig = new HashMap<>(WINDOWED_STORE_CHANGELOG_TOPIC_DEFAULT_OVERRIDES);\n\n    topicConfig.putAll(defaultProperties);\n\n    topicConfig.putAll(topicConfigs);\n\n    if (retentionMs != null) {\n        long retentionValue;\n        try {\n            retentionValue = Math.addExact(retentionMs, additionalRetentionMs);\n        } catch (final ArithmeticException swallow) {\n            retentionValue = Long.MAX_VALUE;\n        }\n        topicConfig.put(TopicConfig.RETENTION_MS_CONFIG, String.valueOf(retentionValue));\n    }\n\n    return topicConfig;\n}", "summary_tokens": ["get", "the", "configured", "properties", "for", "this", "topic"], "project": "kafka"}
{"id": 1453, "code": "public void testTlsDefaults(List<String> serverProtocols, List<String> clientProtocols) throws Exception {\n        \n    CertStores serverCertStores = new CertStores(true, \"server\",  \"localhost\");\n    CertStores clientCertStores = new CertStores(false, \"client\", \"localhost\");\n\n    Map<String, Object> sslClientConfigs = getTrustingConfig(clientCertStores, serverCertStores, clientProtocols);\n    Map<String, Object> sslServerConfigs = getTrustingConfig(serverCertStores, clientCertStores, serverProtocols);\n\n    NioEchoServer server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL,\n        new TestSecurityConfig(sslServerConfigs),\n        null,\n        TIME);\n    Selector selector = createClientSelector(sslClientConfigs);\n\n    String node = \"0\";\n    selector.connect(node, new InetSocketAddress(\"localhost\", server.port()), BUFFER_SIZE, BUFFER_SIZE);\n\n    if (isCompatible(serverProtocols, clientProtocols)) {\n        NetworkTestUtils.waitForChannelReady(selector, node);\n\n        int msgSz = 1024 * 1024;\n        String message = TestUtils.randomString(msgSz);\n        selector.send(new NetworkSend(node, ByteBufferSend.sizePrefixed(ByteBuffer.wrap(message.getBytes()))));\n        while (selector.completedReceives().isEmpty()) {\n            selector.poll(100L);\n        }\n        int totalBytes = msgSz + 4; \n        server.waitForMetric(\"incoming-byte\", totalBytes);\n        server.waitForMetric(\"outgoing-byte\", totalBytes);\n        server.waitForMetric(\"request\", 1);\n        server.waitForMetric(\"response\", 1);\n    } else {\n        NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n        server.verifyAuthenticationMetrics(0, 1);\n    }\n}", "summary_tokens": ["tests", "that", "connection", "success", "with", "the", "default", "tls", "version"], "project": "kafka"}
{"id": 1430, "code": "public void testNetReadBufferResize(Args args) throws Exception {\n    String node = \"0\";\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    createSelector(args.sslClientConfigs, 10, null, null);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 64000, 10);\n}", "summary_tokens": ["tests", "handling", "of", "buffer", "underflow", "during", "unwrap", "when", "network", "read", "buffer", "is", "smaller", "than", "ssl", "session", "packet", "buffer", "size"], "project": "kafka"}
{"id": 2089, "code": "public Map<String, SamplingTestPlugin> otherSamples() {\n    return Collections.emptyMap();\n}", "summary_tokens": ["a", "group", "of", "other", "sampling", "test", "plugin", "instances", "known", "by", "this", "plugin", "this", "should", "only", "return", "direct", "children", "and", "not", "reference", "this", "instance", "directly"], "project": "kafka"}
{"id": 556, "code": "public synchronized boolean completeNext() {\n    return errorNext(null);\n}", "summary_tokens": ["complete", "the", "earliest", "uncompleted", "call", "successfully"], "project": "kafka"}
{"id": 587, "code": "void updatePartitionInfo(StickyPartitionInfo partitionInfo, int appendedBytes, Cluster cluster) {\n        \n    if (partitionInfo == null)\n        return;\n\n    assert partitionInfo == stickyPartitionInfo.get();\n    int producedBytes = partitionInfo.producedBytes.addAndGet(appendedBytes);\n    if (producedBytes >= stickyBatchSize) {\n            \n        StickyPartitionInfo newPartitionInfo = new StickyPartitionInfo(nextPartition(cluster));\n        stickyPartitionInfo.set(newPartitionInfo);\n    }\n}", "summary_tokens": ["update", "partition", "info", "with", "the", "number", "of", "bytes", "appended", "and", "maybe", "switch", "partition"], "project": "kafka"}
{"id": 2423, "code": "public static List<String> splitPath(String path) {\n    List<String> results = new ArrayList<>();\n    String[] components = path.split(\"/\");\n    for (int i = 0; i < components.length; i++) {\n        if (!components[i].isEmpty()) {\n            results.add(components[i]);\n        }\n    }\n    return results;\n}", "summary_tokens": ["convert", "a", "path", "to", "a", "list", "of", "path", "components"], "project": "kafka"}
{"id": 540, "code": "public Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) {\n        \n    ProducerRecord<K, V> interceptedRecord = this.interceptors.onSend(record);\n    return doSend(interceptedRecord, callback);\n}", "summary_tokens": ["asynchronously", "send", "a", "record", "to", "a", "topic", "and", "invoke", "the", "provided", "callback", "when", "the", "send", "has", "been", "acknowledged"], "project": "kafka"}
{"id": 1236, "code": "public static long readUnsignedInt(ByteBuffer buffer, int index) {\n    return buffer.getInt(index) & 0xffffffffL;\n}", "summary_tokens": ["read", "an", "unsigned", "integer", "from", "the", "given", "position", "without", "modifying", "the", "buffers", "position"], "project": "kafka"}
{"id": 1042, "code": "public String message() {\n    return message;\n}", "summary_tokens": ["return", "the", "optional", "error", "message", "or", "null"], "project": "kafka"}
{"id": 3191, "code": "public List<CapturedPunctuator> scheduledPunctuators() {\n    return new LinkedList<>(punctuators);\n}", "summary_tokens": ["get", "the", "punctuators", "scheduled", "so", "far"], "project": "kafka"}
{"id": 423, "code": "public Set<TopicPartition> partitions() {\n    return partitions;\n}", "summary_tokens": ["returns", "all", "partitions", "for", "which", "no", "offests", "are", "defined"], "project": "kafka"}
{"id": 1627, "code": "public void validate() {\n    for (Field field : schema.fields()) {\n        Schema fieldSchema = field.schema();\n        Object value = values[field.index()];\n        if (value == null && (fieldSchema.isOptional() || fieldSchema.defaultValue() != null))\n            continue;\n        ConnectSchema.validateValue(field.name(), fieldSchema, value);\n    }\n}", "summary_tokens": ["validates", "that", "this", "struct", "has", "filled", "in", "all", "the", "necessary", "data", "with", "valid", "values"], "project": "kafka"}
{"id": 193, "code": "public boolean shouldRetryOnQuotaViolation() {\n    return retryOnQuotaViolation;\n}", "summary_tokens": ["returns", "true", "if", "quota", "violation", "should", "be", "automatically", "retried"], "project": "kafka"}
{"id": 2299, "code": "public long latestEpoch() {\n    return head.prev().epoch();\n}", "summary_tokens": ["return", "the", "latest", "epoch"], "project": "kafka"}
{"id": 2152, "code": "protected Optional<Boolean> checkConnectorState(\n        String connectorName,\n        AbstractStatus.State connectorState,\n        int numTasks,\n        int numTasksInTasksState,\n        AbstractStatus.State tasksState,\n        BiFunction<Integer, Integer, Boolean> comp\n) {\n    try {\n        ConnectorStateInfo info = connect.connectorStatus(connectorName);\n        boolean result = info != null\n                && comp.apply(info.tasks().size(), numTasks)\n                && info.connector().state().equals(connectorState.toString())\n                && info.tasks().stream().filter(s -> s.state().equals(tasksState.toString())).count() == numTasksInTasksState;\n        return Optional.of(result);\n    } catch (Exception e) {\n        log.error(\"Could not check connector state info.\", e);\n        return Optional.empty();\n    }\n}", "summary_tokens": ["check", "whether", "the", "given", "connector", "state", "matches", "the", "current", "state", "of", "the", "connector", "and", "whether", "it", "has", "at", "least", "the", "given", "number", "of", "tasks", "with", "num", "tasks", "in", "tasks", "state", "matching", "the", "given", "task", "state"], "project": "kafka"}
{"id": 1261, "code": "public static <T> Map<String, T> groupPartitionsByTopic(\n    Collection<TopicPartition> partitions,\n    Function<String, T> buildGroup,\n    BiConsumer<T, Integer> addToGroup\n) {\n    Map<String, T> dataByTopic = new HashMap<>();\n    for (TopicPartition tp : partitions) {\n        String topic = tp.topic();\n        T topicData = dataByTopic.computeIfAbsent(topic, buildGroup);\n        addToGroup.accept(topicData, tp.partition());\n    }\n    return dataByTopic;\n}", "summary_tokens": ["group", "a", "collection", "of", "partitions", "by", "topic"], "project": "kafka"}
{"id": 2365, "code": "public void poll() {\n    pollListeners();\n\n    long currentTimeMs = time.milliseconds();\n    if (maybeCompleteShutdown(currentTimeMs)) {\n        return;\n    }\n\n    long pollStateTimeoutMs = pollCurrentState(currentTimeMs);\n    long cleaningTimeoutMs = snapshotCleaner.maybeClean(currentTimeMs);\n    long pollTimeoutMs = Math.min(pollStateTimeoutMs, cleaningTimeoutMs);\n\n    kafkaRaftMetrics.updatePollStart(currentTimeMs);\n\n    RaftMessage message = messageQueue.poll(pollTimeoutMs);\n\n    currentTimeMs = time.milliseconds();\n    kafkaRaftMetrics.updatePollEnd(currentTimeMs);\n\n    if (message != null) {\n        handleInboundMessage(message, currentTimeMs);\n    }\n}", "summary_tokens": ["poll", "for", "new", "events"], "project": "kafka"}
{"id": 2895, "code": "public long lagFor(final TaskId task) {\n    final Long totalLag = taskLagTotals.get(task);\n    if (totalLag == null) {\n        throw new IllegalStateException(\"Tried to lookup lag for unknown task \" + task);\n    }\n    return totalLag;\n}", "summary_tokens": ["returns", "the", "total", "lag", "across", "all", "logged", "stores", "in", "the", "task"], "project": "kafka"}
{"id": 2506, "code": "public int partition() {\n    return partition;\n}", "summary_tokens": ["get", "the", "store", "partition", "corresponding", "to", "the", "key"], "project": "kafka"}
{"id": 2054, "code": "public StartAndStopLatch expectedStarts(int expectedStarts, List<StartAndStopLatch> dependents) {\n    return expectedRestarts(expectedStarts, 0, dependents);\n}", "summary_tokens": ["obtain", "a", "start", "and", "stop", "latch", "that", "can", "be", "used", "to", "wait", "until", "the", "expected", "number", "of", "starts", "has", "been", "completed"], "project": "kafka"}
{"id": 136, "code": "default ListPartitionReassignmentsResult listPartitionReassignments(ListPartitionReassignmentsOptions options) {\n    return listPartitionReassignments(Optional.empty(), options);\n}", "summary_tokens": ["list", "all", "of", "the", "current", "partition", "reassignments"], "project": "kafka"}
{"id": 1672, "code": "default ErrantRecordReporter errantRecordReporter() {\n    return null;\n}", "summary_tokens": ["get", "the", "reporter", "to", "which", "the", "sink", "task", "can", "report", "problematic", "or", "failed", "sink", "record", "records", "passed", "to", "the", "sink", "task", "put", "java"], "project": "kafka"}
{"id": 1087, "code": "public final int hashCode() {\n    return super.hashCode();\n}", "summary_tokens": ["implements", "code", "hash", "code", "code", "using", "the", "native", "implementation", "from", "object", "hash", "code"], "project": "kafka"}
{"id": 2596, "code": "public Materialized<K, V, S> withLoggingDisabled() {\n    loggingEnabled = false;\n    this.topicConfig.clear();\n    return this;\n}", "summary_tokens": ["disable", "change", "logging", "for", "the", "materialized", "state", "store"], "project": "kafka"}
{"id": 2975, "code": "public boolean isSuccess() {\n    return false;\n}", "summary_tokens": ["true", "iff", "the", "query", "was", "successfully", "executed"], "project": "kafka"}
{"id": 1372, "code": "private void assertIsCancelled(KafkaFuture<?> future) {\n    assertTrue(future.isDone());\n    assertTrue(future.isCancelled());\n    assertTrue(future.isCompletedExceptionally());\n    assertThrows(CancellationException.class, () -> future.getNow(null));\n    assertThrows(CancellationException.class, () -> future.get(0, TimeUnit.MILLISECONDS));\n}", "summary_tokens": ["asserts", "that", "the", "given", "future", "is", "done", "didn", "t", "fail", "and", "was", "cancelled"], "project": "kafka"}
{"id": 2168, "code": "public URI url() {\n    return worker.rest().serverUrl();\n}", "summary_tokens": ["get", "the", "workers", "s", "url", "that", "accepts", "requests", "to", "its", "rest", "endpoint"], "project": "kafka"}
{"id": 476, "code": "public int pendingRequestCount() {\n    lock.lock();\n    try {\n        return unsent.requestCount() + client.inFlightRequestCount();\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["get", "the", "total", "count", "of", "pending", "requests", "from", "all", "nodes"], "project": "kafka"}
{"id": 2918, "code": "public Collection<StreamsMetadata> streamsMetadataForStore(final String storeName, final String topologyName) {\n    verifyTopologyStateStore(topologyName, storeName);\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadataForStore(storeName, topologyName);\n}", "summary_tokens": ["see", "kafka", "streams", "streams", "metadata", "for", "store", "string"], "project": "kafka"}
{"id": 141, "code": "default DescribeUserScramCredentialsResult describeUserScramCredentials(List<String> users) {\n    return describeUserScramCredentials(users, new DescribeUserScramCredentialsOptions());\n}", "summary_tokens": ["describe", "sasl", "scram", "credentials", "for", "the", "given", "users"], "project": "kafka"}
{"id": 860, "code": "void mute() {\n    if (muteState == ChannelMuteState.NOT_MUTED) {\n        if (!disconnected) transportLayer.removeInterestOps(SelectionKey.OP_READ);\n        muteState = ChannelMuteState.MUTED;\n    }\n}", "summary_tokens": ["externally", "muting", "a", "channel", "should", "be", "done", "via", "selector", "to", "ensure", "proper", "state", "handling"], "project": "kafka"}
{"id": 360, "code": "public List<RequestSpec<K>> poll() {\n    List<RequestSpec<K>> requests = new ArrayList<>();\n    collectLookupRequests(requests);\n    collectFulfillmentRequests(requests);\n    return requests;\n}", "summary_tokens": ["check", "whether", "any", "requests", "need", "to", "be", "sent"], "project": "kafka"}
{"id": 3073, "code": "private List<String> getInputValues() {\n    List<String> input = new ArrayList<>();\n    final ClassLoader classLoader = getClass().getClassLoader();\n    final String fileName = \"QueryableStateIntegrationTest\" + File.separator + \"inputValues.txt\";\n    try (final BufferedReader reader = new BufferedReader(\n        new FileReader(Objects.requireNonNull(classLoader.getResource(fileName)).getFile()))) {\n\n        for (String line = reader.readLine(); line != null; line = reader.readLine()) {\n            input.add(line);\n        }\n    } catch (final Exception e) {\n        log.warn(\"Unable to read '{}{}{}'. Using default inputValues list\", \"resources\", File.separator, fileName);\n        input = Arrays.asList(\n                    \"hello world\",\n                    \"all streams lead to kafka\",\n                    \"streams\",\n                    \"kafka streams\",\n                    \"the cat in the hat\",\n                    \"green eggs and ham\",\n                    \"that Sam i am\",\n                    \"up the creek without a paddle\",\n                    \"run forest run\",\n                    \"a tank full of gas\",\n                    \"eat sleep rave repeat\",\n                    \"one jolly sailor\",\n                    \"king of the world\");\n\n    }\n    return input;\n}", "summary_tokens": ["try", "to", "read", "input", "values", "from", "resources", "queryable", "state", "integration", "test", "input", "values"], "project": "kafka"}
{"id": 1744, "code": "default void validateConnectorConfig(Map<String, String> connectorConfig, Callback<ConfigInfos> callback, boolean doLog) {\n    validateConnectorConfig(connectorConfig, callback);\n}", "summary_tokens": ["validate", "the", "provided", "connector", "config", "values", "against", "the", "configuration", "definition"], "project": "kafka"}
{"id": 1156, "code": "public Number issuedAt() throws OAuthBearerIllegalTokenException {\n    return claim(\"iat\", Number.class);\n}", "summary_tokens": ["return", "the", "a", "href", "https", "tools"], "project": "kafka"}
{"id": 2420, "code": "public void testHandleExceptionInAction() {\n    LoggingFaultHandler handler = new LoggingFaultHandler(\"test\", () -> {\n        throw new RuntimeException(\"action failed\");\n    });\n    handler.handleFault(\"uh oh\"); \n    handler.handleFault(\"uh oh\", new RuntimeException(\"yikes\")); \n}", "summary_tokens": ["test", "handling", "an", "exception", "in", "the", "action", "callback"], "project": "kafka"}
{"id": 316, "code": "public String clientId() {\n    return clientId;\n}", "summary_tokens": ["the", "client", "id", "of", "the", "group", "member"], "project": "kafka"}
{"id": 2002, "code": "public Map<TopicPartition, Long> retryEndOffsets(Set<TopicPartition> partitions, Duration timeoutDuration, long retryBackoffMs) {\n\n    try {\n        return RetryUtil.retryUntilTimeout(\n                () -> endOffsets(partitions),\n                () -> \"list offsets for topic partitions\",\n                timeoutDuration,\n                retryBackoffMs);\n    } catch (UnsupportedVersionException e) {\n            \n        throw e;\n    } catch (Exception e) {\n        throw new ConnectException(\"Failed to list offsets for topic partitions.\", e);\n    }\n}", "summary_tokens": ["fetch", "the", "most", "recent", "offset", "for", "each", "of", "the", "supplied", "topic", "partition", "objects", "and", "performs", "retry", "when", "org"], "project": "kafka"}
{"id": 344, "code": "public boolean isInternal() {\n    return internal;\n}", "summary_tokens": ["whether", "the", "topic", "is", "internal", "to", "kafka"], "project": "kafka"}
{"id": 1231, "code": "static public Serde<Void> Void() {\n    return new VoidSerde();\n}", "summary_tokens": ["a", "serde", "for", "void", "type"], "project": "kafka"}
{"id": 2109, "code": "public Set<WorkerHandle> workers() {\n    return new LinkedHashSet<>(connectCluster);\n}", "summary_tokens": ["get", "the", "provisioned", "workers"], "project": "kafka"}
{"id": 724, "code": "public boolean isUnknown() {\n    return pattern.isUnknown() || entry.isUnknown();\n}", "summary_tokens": ["true", "if", "this", "binding", "has", "any", "unknown", "components"], "project": "kafka"}
{"id": 1944, "code": "default void claimWritePrivileges() {\n}", "summary_tokens": ["prepare", "to", "write", "to", "the", "backing", "config", "store"], "project": "kafka"}
{"id": 713, "code": "public boolean isUnknown() {\n    return data.isUnknown();\n}", "summary_tokens": ["return", "true", "if", "this", "acl", "resource", "has", "any", "unknown", "components"], "project": "kafka"}
{"id": 3134, "code": "public Iterable<KeyValue<byte[], byte[]>> restoredEntries() {\n    return restorableEntries;\n}", "summary_tokens": ["get", "the", "entries", "that", "are", "restored", "to", "a", "key", "value", "store", "when", "it", "is", "constructed", "with", "this", "driver", "s", "context", "processor", "context"], "project": "kafka"}
{"id": 2493, "code": "public void pause() {\n    if (topologyMetadata.hasNamedTopologies()) {\n        for (final NamedTopology namedTopology : topologyMetadata.getAllNamedTopologies()) {\n            topologyMetadata.pauseTopology(namedTopology.name());\n        }\n    } else {\n        topologyMetadata.pauseTopology(UNNAMED_TOPOLOGY);\n    }\n}", "summary_tokens": ["this", "method", "pauses", "processing", "for", "the", "kafka", "streams", "instance"], "project": "kafka"}
{"id": 97, "code": "private void handleDisconnections(List<ClientResponse> responses, long now) {\n    for (Map.Entry<String, ChannelState> entry : this.selector.disconnected().entrySet()) {\n        String node = entry.getKey();\n        log.info(\"Node {} disconnected.\", node);\n        processDisconnection(responses, node, now, entry.getValue());\n    }\n}", "summary_tokens": ["handle", "any", "disconnected", "connections"], "project": "kafka"}
{"id": 1349, "code": "public void testError() throws Exception {\n    FutureRecordMetadata future = new FutureRecordMetadata(asyncRequest(baseOffset, new CorruptRecordException(), 50L),\n            relOffset, RecordBatch.NO_TIMESTAMP, 0, 0, Time.SYSTEM);\n    assertThrows(ExecutionException.class, future::get);\n}", "summary_tokens": ["test", "that", "an", "asynchronous", "request", "will", "eventually", "throw", "the", "right", "exception"], "project": "kafka"}
{"id": 2143, "code": "public void assertExactlyNumErrorsOnConnectorConfigValidation(String connectorClass, Map<String, String> connConfig,\n    int numErrors, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkValidationErrors(\n                connectorClass,\n                connConfig,\n                numErrors,\n                (actual, expected) -> actual == expected\n            ).orElse(false),\n            VALIDATION_DURATION_MS,\n            \"Didn't meet the exact requested number of validation errors: \" + numErrors);\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "the", "required", "number", "of", "errors", "are", "produced", "by", "a", "connector", "config", "validation"], "project": "kafka"}
{"id": 2723, "code": "public static Map<TopicPartition, ListOffsetsResultInfo> getEndOffsets(final KafkaFuture<Map<TopicPartition, ListOffsetsResultInfo>> endOffsetsFuture) {\n    try {\n        return endOffsetsFuture.get();\n    } catch (final RuntimeException | InterruptedException | ExecutionException e) {\n        LOG.warn(\"The listOffsets request failed.\", e);\n        throw new StreamsException(\"Unable to obtain end offsets from kafka\", e);\n    }\n}", "summary_tokens": ["a", "helper", "method", "that", "wraps", "the", "future", "get", "call", "and", "rethrows", "any", "thrown", "exception", "as", "a", "streams", "exception", "streams", "exception", "if", "the", "admin", "client", "request", "throws", "an", "exception"], "project": "kafka"}
{"id": 1948, "code": "public void start() {\n        \n    connectorStore.ifPresent(OffsetBackingStore::start);\n}", "summary_tokens": ["if", "configured", "to", "use", "a", "connector", "specific", "offset", "store", "offset", "backing", "store", "start", "start", "that", "store"], "project": "kafka"}
{"id": 2435, "code": "public int brokerId() {\n    return brokerId;\n}", "summary_tokens": ["broker", "id", "from", "which", "this", "event", "is", "generated"], "project": "kafka"}
{"id": 1710, "code": "public Set<String> upstreamClusters() throws InterruptedException {\n    return listTopics().stream()\n        .filter(this::isHeartbeatTopic)\n        .flatMap(x -> allSources(x).stream())\n        .collect(Collectors.toSet());\n}", "summary_tokens": ["find", "upstream", "clusters", "which", "may", "be", "multiple", "hops", "away", "based", "on", "incoming", "heartbeats"], "project": "kafka"}
{"id": 2436, "code": "public TopicIdPartition topicIdPartition() {\n    return topicIdPartition;\n}", "summary_tokens": ["topic", "id", "partition", "of", "this", "remote", "log", "segment"], "project": "kafka"}
{"id": 1024, "code": "public boolean hasRoomFor(long timestamp, ByteBuffer key, ByteBuffer value, Header[] headers) {\n    if (isFull())\n        return false;\n\n        \n    if (numRecords == 0)\n        return true;\n\n    final int recordSize;\n    if (magic < RecordBatch.MAGIC_VALUE_V2) {\n        recordSize = Records.LOG_OVERHEAD + LegacyRecord.recordSize(magic, key, value);\n    } else {\n        int nextOffsetDelta = lastOffset == null ? 0 : (int) (lastOffset - baseOffset + 1);\n        long timestampDelta = baseTimestamp == null ? 0 : timestamp - baseTimestamp;\n        recordSize = DefaultRecord.sizeInBytes(nextOffsetDelta, timestampDelta, key, value, headers);\n    }\n\n        \n    return this.writeLimit >= estimatedBytesWritten() + recordSize;\n}", "summary_tokens": ["check", "if", "we", "have", "room", "for", "a", "new", "record", "containing", "the", "given", "key", "value", "pair"], "project": "kafka"}
{"id": 632, "code": "boolean flushInProgress() {\n    return flushesInProgress.get() > 0;\n}", "summary_tokens": ["are", "there", "any", "threads", "currently", "waiting", "on", "a", "flush"], "project": "kafka"}
{"id": 438, "code": "public synchronized void requestRejoin(final String shortReason,\n                                       final String fullReason) {\n    log.info(\"Request joining group due to: {}\", fullReason);\n    this.rejoinReason = shortReason;\n    this.rejoinNeeded = true;\n}", "summary_tokens": ["request", "to", "rejoin", "the", "group"], "project": "kafka"}
{"id": 821, "code": "public synchronized Sensor sensor(String name, MetricConfig config, long inactiveSensorExpirationTimeSeconds, Sensor... parents) {\n    return this.sensor(name, config, inactiveSensorExpirationTimeSeconds, Sensor.RecordingLevel.INFO, parents);\n}", "summary_tokens": ["get", "or", "create", "a", "sensor", "with", "the", "given", "unique", "name", "and", "zero", "or", "more", "parent", "sensors"], "project": "kafka"}
{"id": 2920, "code": "public <K> KeyQueryMetadata queryMetadataForKey(final String storeName,\n                                                final K key,\n                                                final Serializer<K> keySerializer,\n                                                final String topologyName) {\n    verifyTopologyStateStore(topologyName, storeName);\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getKeyQueryMetadataForKey(storeName, key, keySerializer, topologyName);\n}", "summary_tokens": ["see", "kafka", "streams", "query", "metadata", "for", "key", "string", "object", "serializer"], "project": "kafka"}
{"id": 3114, "code": "private static byte[] mergeChangeArraysIntoSingleLegacyFormattedArray(final Change<byte[]> serialChange) {\n    if (serialChange == null) {\n        return null;\n    }\n\n    final int oldSize = serialChange.oldValue == null ? -1 : serialChange.oldValue.length;\n    final int newSize = serialChange.newValue == null ? -1 : serialChange.newValue.length;\n\n    final ByteBuffer buffer = ByteBuffer.allocate(Integer.BYTES * 2 + Math.max(0, oldSize) + Math.max(0, newSize));\n\n\n    buffer.putInt(oldSize);\n    if (serialChange.oldValue != null) {\n        buffer.put(serialChange.oldValue);\n    }\n\n    buffer.putInt(newSize);\n    if (serialChange.newValue != null) {\n        buffer.put(serialChange.newValue);\n    }\n    return buffer.array();\n}", "summary_tokens": ["we", "used", "to", "serialize", "a", "change", "into", "a", "single", "byte"], "project": "kafka"}
{"id": 1978, "code": "public static void clear() {\n    MDC.clear();\n}", "summary_tokens": ["clear", "all", "mdc", "parameters"], "project": "kafka"}
{"id": 633, "code": "public void beginFlush() {\n    this.flushesInProgress.getAndIncrement();\n}", "summary_tokens": ["initiate", "the", "flushing", "of", "data", "from", "the", "accumulator"], "project": "kafka"}
{"id": 3224, "code": "public static void addConfigsToProperties(\n    Properties props, Map<String, String> commonConf, Map<String, String> clientConf) {\n    for (Map.Entry<String, String> commonEntry : commonConf.entrySet()) {\n        props.setProperty(commonEntry.getKey(), commonEntry.getValue());\n    }\n    for (Map.Entry<String, String> entry : clientConf.entrySet()) {\n        props.setProperty(entry.getKey(), entry.getValue());\n    }\n}", "summary_tokens": ["adds", "all", "properties", "from", "common", "conf", "and", "then", "from", "client", "conf", "to", "given", "props", "in", "that", "order", "over", "writing", "properties", "with", "the", "same", "keys"], "project": "kafka"}
{"id": 2703, "code": "public K key() {\n    return key;\n}", "summary_tokens": ["the", "key", "of", "the", "record"], "project": "kafka"}
{"id": 761, "code": "public Map<String, Object> parse(Map<?, ?> props) {\n        \n    List<String> undefinedConfigKeys = undefinedDependentConfigs();\n    if (!undefinedConfigKeys.isEmpty()) {\n        String joined = Utils.join(undefinedConfigKeys, \",\");\n        throw new ConfigException(\"Some configurations in are referred in the dependents, but not defined: \" + joined);\n    }\n        \n    Map<String, Object> values = new HashMap<>();\n    for (ConfigKey key : configKeys.values())\n        values.put(key.name, parseValue(key, props.get(key.name), props.containsKey(key.name)));\n    return values;\n}", "summary_tokens": ["parse", "and", "validate", "configs", "against", "this", "configuration", "definition"], "project": "kafka"}
{"id": 1316, "code": "public void testIgnoreLeaderEpochInOlderMetadataResponse() {\n    TopicPartition tp = new TopicPartition(\"topic\", 0);\n\n    MetadataResponsePartition partitionMetadata = new MetadataResponsePartition()\n            .setPartitionIndex(tp.partition())\n            .setLeaderId(5)\n            .setLeaderEpoch(10)\n            .setReplicaNodes(Arrays.asList(1, 2, 3))\n            .setIsrNodes(Arrays.asList(1, 2, 3))\n            .setOfflineReplicas(Collections.emptyList())\n            .setErrorCode(Errors.NONE.code());\n\n    MetadataResponseTopic topicMetadata = new MetadataResponseTopic()\n            .setName(tp.topic())\n            .setErrorCode(Errors.NONE.code())\n            .setPartitions(Collections.singletonList(partitionMetadata))\n            .setIsInternal(false);\n\n    MetadataResponseTopicCollection topics = new MetadataResponseTopicCollection();\n    topics.add(topicMetadata);\n\n    MetadataResponseData data = new MetadataResponseData()\n            .setClusterId(\"clusterId\")\n            .setControllerId(0)\n            .setTopics(topics)\n            .setBrokers(new MetadataResponseBrokerCollection());\n\n    for (short version = ApiKeys.METADATA.oldestVersion(); version < 9; version++) {\n        ByteBuffer buffer = MessageUtil.toByteBuffer(data, version);\n        MetadataResponse response = MetadataResponse.parse(buffer, version);\n        assertFalse(response.hasReliableLeaderEpochs());\n        metadata.updateWithCurrentRequestVersion(response, false, 100);\n        assertTrue(metadata.partitionMetadataIfCurrent(tp).isPresent());\n        MetadataResponse.PartitionMetadata responseMetadata = this.metadata.partitionMetadataIfCurrent(tp).get();\n        assertEquals(Optional.empty(), responseMetadata.leaderEpoch);\n    }\n\n    for (short version = 9; version <= ApiKeys.METADATA.latestVersion(); version++) {\n        ByteBuffer buffer = MessageUtil.toByteBuffer(data, version);\n        MetadataResponse response = MetadataResponse.parse(buffer, version);\n        assertTrue(response.hasReliableLeaderEpochs());\n        metadata.updateWithCurrentRequestVersion(response, false, 100);\n        assertTrue(metadata.partitionMetadataIfCurrent(tp).isPresent());\n        MetadataResponse.PartitionMetadata responseMetadata = metadata.partitionMetadataIfCurrent(tp).get();\n        assertEquals(Optional.of(10), responseMetadata.leaderEpoch);\n    }\n}", "summary_tokens": ["prior", "to", "kafka", "version", "0"], "project": "kafka"}
{"id": 1647, "code": "public static Schema inferSchema(Object value) {\n    if (value instanceof String) {\n        return Schema.STRING_SCHEMA;\n    }\n    if (value instanceof Boolean) {\n        return Schema.BOOLEAN_SCHEMA;\n    }\n    if (value instanceof Byte) {\n        return Schema.INT8_SCHEMA;\n    }\n    if (value instanceof Short) {\n        return Schema.INT16_SCHEMA;\n    }\n    if (value instanceof Integer) {\n        return Schema.INT32_SCHEMA;\n    }\n    if (value instanceof Long) {\n        return Schema.INT64_SCHEMA;\n    }\n    if (value instanceof Float) {\n        return Schema.FLOAT32_SCHEMA;\n    }\n    if (value instanceof Double) {\n        return Schema.FLOAT64_SCHEMA;\n    }\n    if (value instanceof byte[] || value instanceof ByteBuffer) {\n        return Schema.BYTES_SCHEMA;\n    }\n    if (value instanceof List) {\n        List<?> list = (List<?>) value;\n        if (list.isEmpty()) {\n            return null;\n        }\n        SchemaDetector detector = new SchemaDetector();\n        for (Object element : list) {\n            if (!detector.canDetect(element)) {\n                return null;\n            }\n        }\n        return SchemaBuilder.array(detector.schema()).build();\n    }\n    if (value instanceof Map) {\n        Map<?, ?> map = (Map<?, ?>) value;\n        if (map.isEmpty()) {\n            return null;\n        }\n        SchemaDetector keyDetector = new SchemaDetector();\n        SchemaDetector valueDetector = new SchemaDetector();\n        for (Map.Entry<?, ?> entry : map.entrySet()) {\n            if (!keyDetector.canDetect(entry.getKey()) || !valueDetector.canDetect(entry.getValue())) {\n                return null;\n            }\n        }\n        return SchemaBuilder.map(keyDetector.schema(), valueDetector.schema()).build();\n    }\n    if (value instanceof Struct) {\n        return ((Struct) value).schema();\n    }\n    return null;\n}", "summary_tokens": ["if", "possible", "infer", "a", "schema", "for", "the", "given", "value"], "project": "kafka"}
{"id": 3007, "code": "public Deserializer<K> keyDeserializer() {\n    return keySerde.deserializer();\n}", "summary_tokens": ["return", "the", "key", "deserializer"], "project": "kafka"}
{"id": 2296, "code": "public void revertToSnapshot(long targetEpoch) {\n    Snapshot target = getSnapshot(targetEpoch);\n    Iterator<Snapshot> iterator = iterator(target);\n    iterator.next();\n    while (iterator.hasNext()) {\n        Snapshot snapshot = iterator.next();\n        log.debug(\"Deleting in-memory snapshot {} because we are reverting to {}\",\n            snapshot.epoch(), targetEpoch);\n        iterator.remove();\n    }\n    target.handleRevert();\n}", "summary_tokens": ["reverts", "the", "state", "of", "all", "data", "structures", "to", "the", "state", "at", "the", "given", "epoch"], "project": "kafka"}
{"id": 2945, "code": "static <R> QueryResult<R> notUpToBound(\n    final Position currentPosition,\n    final PositionBound positionBound,\n    final Integer partition) {\n\n    if (partition == null) {\n        return new FailedQueryResult<>(\n            FailureReason.NOT_UP_TO_BOUND,\n            \"The store is not initialized yet, so it is not yet up to the bound \"\n                + positionBound\n        );\n    } else {\n        return new FailedQueryResult<>(\n            FailureReason.NOT_UP_TO_BOUND,\n            \"For store partition \" + partition + \", the current position \"\n                + currentPosition + \" is not yet up to the bound \"\n                + positionBound\n        );\n    }\n}", "summary_tokens": ["static", "factory", "method", "to", "create", "a", "failed", "query", "result", "object", "to", "indicate", "that", "the", "store", "has", "not", "yet", "caught", "up", "to", "the", "requested", "position", "bound"], "project": "kafka"}
{"id": 2986, "code": "public static HostInfo buildFromEndpoint(final String endPoint) {\n    if (Utils.isBlank(endPoint)) {\n        return null;\n    }\n\n    final String host = getHost(endPoint);\n    final Integer port = getPort(endPoint);\n\n    if (host == null || port == null) {\n        throw new ConfigException(\n            String.format(\"Error parsing host address %s. Expected format host:port.\", endPoint)\n        );\n    }\n    return new HostInfo(host, port);\n}", "summary_tokens": ["config", "exception", "if", "the", "host", "or", "port", "cannot", "be", "parsed", "from", "the", "given", "endpoint", "string", "a", "new", "host", "info", "or", "null", "if", "end", "point", "is", "null", "or", "has", "no", "characters"], "project": "kafka"}
{"id": 2157, "code": "public Set<KafkaServer> brokersInState(Predicate<BrokerState> desiredState) {\n    return Arrays.stream(brokers)\n                 .filter(b -> hasState(b, desiredState))\n                 .collect(Collectors.toSet());\n}", "summary_tokens": ["get", "the", "brokers", "whose", "state", "match", "the", "given", "predicate"], "project": "kafka"}
{"id": 904, "code": "private int readFromAppBuffer(ByteBuffer dst) {\n    appReadBuffer.flip();\n    int remaining = Math.min(appReadBuffer.remaining(), dst.remaining());\n    if (remaining > 0) {\n        int limit = appReadBuffer.limit();\n        appReadBuffer.limit(appReadBuffer.position() + remaining);\n        dst.put(appReadBuffer);\n        appReadBuffer.limit(limit);\n    }\n    appReadBuffer.compact();\n    return remaining;\n}", "summary_tokens": ["transfers", "app", "read", "buffer", "contents", "decrypted", "data", "into", "dst", "bytebuffer", "dst", "byte", "buffer"], "project": "kafka"}
{"id": 1564, "code": "public void serverDisconnect(String id) {\n    this.disconnected.put(id, ChannelState.READY);\n    close(id);\n}", "summary_tokens": ["simulate", "a", "server", "disconnect"], "project": "kafka"}
{"id": 1914, "code": "public URI advertisedUrl() {\n    UriBuilder builder = UriBuilder.fromUri(jettyServer.getURI());\n\n    String advertisedSecurityProtocol = determineAdvertisedProtocol();\n    ServerConnector serverConnector = findConnector(advertisedSecurityProtocol);\n    builder.scheme(advertisedSecurityProtocol);\n\n    String advertisedHostname = config.getString(WorkerConfig.REST_ADVERTISED_HOST_NAME_CONFIG);\n    if (advertisedHostname != null && !advertisedHostname.isEmpty())\n        builder.host(advertisedHostname);\n    else if (serverConnector != null && serverConnector.getHost() != null && serverConnector.getHost().length() > 0)\n        builder.host(serverConnector.getHost());\n\n    Integer advertisedPort = config.getInt(WorkerConfig.REST_ADVERTISED_PORT_CONFIG);\n    if (advertisedPort != null)\n        builder.port(advertisedPort);\n    else if (serverConnector != null && serverConnector.getPort() > 0)\n        builder.port(serverConnector.getPort());\n\n    log.info(\"Advertised URI: {}\", builder.build());\n\n    return builder.build();\n}", "summary_tokens": ["get", "the", "url", "to", "advertise", "to", "other", "workers", "and", "clients"], "project": "kafka"}
{"id": 1898, "code": "public static boolean isClassFile(Path path) {\n    return path.toString().toLowerCase(Locale.ROOT).endsWith(\".class\");\n}", "summary_tokens": ["return", "whether", "a", "path", "corresponds", "java", "class", "file"], "project": "kafka"}
{"id": 1312, "code": "private static Set<TopicPartition> toSet(TopicPartition... arr) {\n    TreeSet<TopicPartition> set = new TreeSet<>(new Comparator<TopicPartition>() {\n        @Override\n        public int compare(TopicPartition o1, TopicPartition o2) {\n            return o1.toString().compareTo(o2.toString());\n        }\n    });\n    set.addAll(Arrays.asList(arr));\n    return set;\n}", "summary_tokens": ["create", "a", "set", "of", "topic", "partitions"], "project": "kafka"}
{"id": 1848, "code": "public static JoinGroupRequestProtocolCollection metadataRequest(ExtendedWorkerState workerState, boolean sessioned) {\n        \n    List<JoinGroupRequestProtocol> joinGroupRequestProtocols = new ArrayList<>();\n    if (sessioned) {\n        joinGroupRequestProtocols.add(new JoinGroupRequestProtocol()\n            .setName(SESSIONED.protocol())\n            .setMetadata(IncrementalCooperativeConnectProtocol.serializeMetadata(workerState, true).array())\n        );\n    }\n    joinGroupRequestProtocols.add(new JoinGroupRequestProtocol()\n                    .setName(COMPATIBLE.protocol())\n                    .setMetadata(IncrementalCooperativeConnectProtocol.serializeMetadata(workerState, false).array())\n    );\n    joinGroupRequestProtocols.add(new JoinGroupRequestProtocol()\n                    .setName(EAGER.protocol())\n                    .setMetadata(ConnectProtocol.serializeMetadata(workerState).array())\n    );\n    return new JoinGroupRequestProtocolCollection(joinGroupRequestProtocols.iterator());\n}", "summary_tokens": ["returns", "the", "collection", "of", "connect", "protocols", "that", "are", "supported", "by", "this", "version", "along", "with", "their", "serialized", "metadata"], "project": "kafka"}
{"id": 2769, "code": "public TopicPartition partition() {\n    return partition;\n}", "summary_tokens": ["returns", "the", "partition", "with", "which", "this", "queue", "is", "associated"], "project": "kafka"}
{"id": 1808, "code": "private void doCommit(Map<TopicPartition, OffsetAndMetadata> offsets, boolean closing, int seqno) {\n    if (closing) {\n        doCommitSync(offsets, seqno);\n    } else {\n        doCommitAsync(offsets, seqno);\n    }\n}", "summary_tokens": ["starts", "an", "offset", "commit", "by", "flushing", "outstanding", "messages", "from", "the", "task", "and", "then", "starting", "the", "write", "commit"], "project": "kafka"}
{"id": 3150, "code": "public void advanceTime(final Duration advance) {\n    if (advance.isNegative()) {\n        throw new IllegalArgumentException(\"advance must be positive\");\n    }\n    currentTime = currentTime.plus(advance);\n}", "summary_tokens": ["advances", "the", "internally", "tracked", "event", "time", "of", "this", "input", "topic"], "project": "kafka"}
{"id": 2947, "code": "public static <K, V> RangeQuery<K, V> withUpperBound(final K upper) {\n    return new RangeQuery<>(Optional.empty(), Optional.of(upper));\n}", "summary_tokens": ["interactive", "range", "query", "using", "an", "upper", "bound", "to", "filter", "the", "keys", "returned"], "project": "kafka"}
{"id": 2520, "code": "public synchronized StreamsBuilder addStateStore(final StoreBuilder<?> builder) {\n    Objects.requireNonNull(builder, \"builder can't be null\");\n    internalStreamsBuilder.addStateStore(builder);\n    return this;\n}", "summary_tokens": ["adds", "a", "state", "store", "to", "the", "underlying", "topology"], "project": "kafka"}
{"id": 2519, "code": "public synchronized <K, V> GlobalKTable<K, V> globalTable(final String topic,\n                                                          final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized) {\n    Objects.requireNonNull(topic, \"topic can't be null\");\n    Objects.requireNonNull(materialized, \"materialized can't be null\");\n    final MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>> materializedInternal =\n        new MaterializedInternal<>(materialized, internalStreamsBuilder, topic + \"-\");\n\n    return internalStreamsBuilder.globalTable(topic,\n                                              new ConsumedInternal<>(Consumed.with(materializedInternal.keySerde(),\n                                                                                   materializedInternal.valueSerde())),\n                                              materializedInternal);\n}", "summary_tokens": ["create", "a", "global", "ktable", "for", "the", "specified", "topic"], "project": "kafka"}
{"id": 1003, "code": "public static LegacyRecord create(byte magic,\n                                  long timestamp,\n                                  byte[] key,\n                                  byte[] value,\n                                  CompressionType compressionType,\n                                  TimestampType timestampType) {\n    int keySize = key == null ? 0 : key.length;\n    int valueSize = value == null ? 0 : value.length;\n    ByteBuffer buffer = ByteBuffer.allocate(recordSize(magic, keySize, valueSize));\n    write(buffer, magic, timestamp, wrapNullable(key), wrapNullable(value), compressionType, timestampType);\n    buffer.rewind();\n    return new LegacyRecord(buffer);\n}", "summary_tokens": ["create", "a", "new", "record", "instance"], "project": "kafka"}
{"id": 105, "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["get", "a", "future", "which", "completes", "when", "the", "transaction", "specified", "by", "abort", "transaction", "spec", "in", "the", "respective", "call", "to", "admin", "abort", "transaction", "abort", "transaction", "spec", "abort", "transaction", "options", "returns", "successfully", "or", "fails", "due", "to", "an", "error", "or", "timeout"], "project": "kafka"}
{"id": 779, "code": "public Map<String, Long> ttls() {\n    return ttls;\n}", "summary_tokens": ["returns", "the", "ttl", "values", "in", "milliseconds", "returned", "from", "the", "config", "provider", "instances", "for", "a", "given", "set", "of", "paths"], "project": "kafka"}
{"id": 625, "code": "public ReadyCheckResult ready(Cluster cluster, long nowMs) {\n    Set<Node> readyNodes = new HashSet<>();\n    long nextReadyCheckDelayMs = Long.MAX_VALUE;\n    Set<String> unknownLeaderTopics = new HashSet<>();\n        \n        \n    for (Map.Entry<String, TopicInfo> topicInfoEntry : this.topicInfoMap.entrySet()) {\n        final String topic = topicInfoEntry.getKey();\n        nextReadyCheckDelayMs = partitionReady(cluster, nowMs, topic, topicInfoEntry.getValue(), nextReadyCheckDelayMs, readyNodes, unknownLeaderTopics);\n    }\n    return new ReadyCheckResult(readyNodes, nextReadyCheckDelayMs, unknownLeaderTopics);\n}", "summary_tokens": ["get", "a", "list", "of", "nodes", "whose", "partitions", "are", "ready", "to", "be", "sent", "and", "the", "earliest", "time", "at", "which", "any", "non", "sendable", "partition", "will", "be", "ready", "also", "return", "the", "flag", "for", "whether", "there", "are", "any", "unknown", "leaders", "for", "the", "accumulated", "partition", "batches"], "project": "kafka"}
{"id": 2158, "code": "public Map<String, Optional<TopicDescription>> describeTopics(Set<String> topicNames) {\n    Map<String, Optional<TopicDescription>> results = new HashMap<>();\n    log.info(\"Describing topics {}\", topicNames);\n    try (Admin admin = createAdminClient()) {\n        DescribeTopicsResult result = admin.describeTopics(topicNames);\n        Map<String, KafkaFuture<TopicDescription>> byName = result.topicNameValues();\n        for (Map.Entry<String, KafkaFuture<TopicDescription>> entry : byName.entrySet()) {\n            String topicName = entry.getKey();\n            try {\n                TopicDescription desc = entry.getValue().get();\n                results.put(topicName, Optional.of(desc));\n                log.info(\"Found topic {} : {}\", topicName, desc);\n            } catch (ExecutionException e) {\n                Throwable cause = e.getCause();\n                if (cause instanceof UnknownTopicOrPartitionException) {\n                    results.put(topicName, Optional.empty());\n                    log.info(\"Found non-existant topic {}\", topicName);\n                    continue;\n                }\n                throw new AssertionError(\"Could not describe topic(s)\" + topicNames, e);\n            }\n        }\n    } catch (Exception e) {\n        throw new AssertionError(\"Could not describe topic(s) \" + topicNames, e);\n    }\n    log.info(\"Found topics {}\", results);\n    return results;\n}", "summary_tokens": ["get", "the", "topic", "descriptions", "of", "the", "named", "topics"], "project": "kafka"}
{"id": 1383, "code": "public void testClientChannelBuilderWithBrokerConfigs() throws Exception {\n    Map<String, Object> configs = new HashMap<>();\n    CertStores certStores = new CertStores(false, \"client\", \"localhost\");\n    configs.putAll(certStores.getTrustingConfig(certStores));\n    configs.put(SaslConfigs.SASL_KERBEROS_SERVICE_NAME, \"kafka\");\n    configs.putAll(new ConfigDef().withClientSaslSupport().parse(configs));\n    for (Field field : BrokerSecurityConfigs.class.getFields()) {\n        if (field.getName().endsWith(\"_CONFIG\"))\n            configs.put(field.get(BrokerSecurityConfigs.class).toString(), \"somevalue\");\n    }\n\n    SaslChannelBuilder plainBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"PLAIN\");\n    plainBuilder.configure(configs);\n\n    SaslChannelBuilder gssapiBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"GSSAPI\");\n    gssapiBuilder.configure(configs);\n\n    SaslChannelBuilder oauthBearerBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"OAUTHBEARER\");\n    oauthBearerBuilder.configure(configs);\n\n    SaslChannelBuilder scramBuilder = createChannelBuilder(SecurityProtocol.SASL_PLAINTEXT, \"SCRAM-SHA-256\");\n    scramBuilder.configure(configs);\n\n    SaslChannelBuilder saslSslBuilder = createChannelBuilder(SecurityProtocol.SASL_SSL, \"PLAIN\");\n    saslSslBuilder.configure(configs);\n}", "summary_tokens": ["verify", "that", "unparsed", "broker", "configs", "don", "t", "break", "clients"], "project": "kafka"}
{"id": 1260, "code": "public static <T> Map<String, Map<Integer, T>> groupPartitionDataByTopic(Map<TopicPartition, ? extends T> data) {\n    Map<String, Map<Integer, T>> dataByTopic = new HashMap<>();\n    for (Map.Entry<TopicPartition, ? extends T> entry : data.entrySet()) {\n        String topic = entry.getKey().topic();\n        int partition = entry.getKey().partition();\n        Map<Integer, T> topicData = dataByTopic.computeIfAbsent(topic, t -> new HashMap<>());\n        topicData.put(partition, entry.getValue());\n    }\n    return dataByTopic;\n}", "summary_tokens": ["group", "data", "by", "topic"], "project": "kafka"}
{"id": 1841, "code": "public ExtendedAssignment assignment() {\n    return assignment;\n}", "summary_tokens": ["this", "method", "returns", "which", "was", "the", "assignment", "of", "connectors", "and", "tasks", "on", "a", "worker", "at", "the", "moment", "that", "its", "state", "was", "captured", "by", "this", "class"], "project": "kafka"}
{"id": 835, "code": "public void checkQuotas() {\n    checkQuotas(time.milliseconds());\n}", "summary_tokens": ["check", "if", "we", "have", "violated", "our", "quota", "for", "any", "metric", "that", "has", "a", "configured", "quota"], "project": "kafka"}
{"id": 2264, "code": "public Map<String, Uuid> topicNameToIdView() {\n    return new TranslatedValueMapView<>(topicsByName, image -> image.id());\n}", "summary_tokens": ["expose", "a", "view", "of", "this", "topics", "image", "as", "a", "map", "from", "topic", "names", "to", "ids"], "project": "kafka"}
{"id": 747, "code": "public Map<String, Object> valuesWithPrefixAllOrNothing(String prefix) {\n    Map<String, Object> withPrefix = originalsWithPrefix(prefix, true);\n\n    if (withPrefix.isEmpty()) {\n        return new RecordingMap<>(values(), \"\", true);\n    } else {\n        Map<String, Object> result = new RecordingMap<>(prefix, true);\n\n        for (Map.Entry<String, ?> entry : withPrefix.entrySet()) {\n            ConfigDef.ConfigKey configKey = definition.configKeys().get(entry.getKey());\n            if (configKey != null)\n                result.put(entry.getKey(), definition.parseValue(configKey, entry.getValue(), true));\n        }\n\n        return result;\n    }\n}", "summary_tokens": ["if", "at", "least", "one", "key", "with", "prefix", "exists", "all", "prefixed", "values", "will", "be", "parsed", "and", "put", "into", "map"], "project": "kafka"}
{"id": 277, "code": "private static boolean topicNameIsUnrepresentable(String topicName) {\n    return topicName == null || topicName.isEmpty();\n}", "summary_tokens": ["returns", "true", "if", "a", "topic", "name", "cannot", "be", "represented", "in", "an", "rpc"], "project": "kafka"}
{"id": 657, "code": "synchronized Integer sequenceNumber(TopicPartition topicPartition) {\n    return txnPartitionMap.getOrCreate(topicPartition).nextSequence;\n}", "summary_tokens": ["returns", "the", "next", "sequence", "number", "to", "be", "written", "to", "the", "given", "topic", "partition"], "project": "kafka"}
{"id": 1750, "code": "public boolean shouldRestartConnector() {\n    return isRestarting(stateInfo.connector());\n}", "summary_tokens": ["determine", "whether", "the", "connector", "instance", "is", "to", "be", "restarted", "based", "upon", "the", "restart", "request", "restart", "request"], "project": "kafka"}
{"id": 1881, "code": "public boolean failed() {\n    return error() != null;\n}", "summary_tokens": ["true", "if", "the", "last", "operation", "encountered", "an", "error", "false", "otherwise"], "project": "kafka"}
{"id": 2312, "code": "public void testParsingMalformedMessageVersionVarint() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(64);\n    buffer.clear();\n    buffer.put((byte) 0x01);\n    buffer.put((byte) 0x08);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.put((byte) 0x80);\n    buffer.position(0);\n    buffer.limit(64);\n    assertStartsWith(\"Error while reading version\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getMessage());\n}", "summary_tokens": ["test", "attempting", "to", "parse", "an", "event", "which", "has", "a", "malformed", "message", "version", "varint"], "project": "kafka"}
{"id": 1390, "code": "public void testSendLargeRequest() throws Exception {\n    String node = \"0\";\n    blockingConnect(node);\n    String big = TestUtils.randomString(10 * BUFFER_SIZE);\n    assertEquals(big, blockingRequest(node, big));\n}", "summary_tokens": ["validate", "that", "we", "can", "send", "and", "receive", "a", "message", "larger", "than", "the", "receive", "and", "send", "buffer", "size"], "project": "kafka"}
{"id": 498, "code": "private RequestFuture<ListOffsetResult> sendListOffsetRequest(final Node node,\n                                                              final Map<TopicPartition, ListOffsetsPartition> timestampsToSearch,\n                                                              boolean requireTimestamp) {\n    ListOffsetsRequest.Builder builder = ListOffsetsRequest.Builder\n            .forConsumer(requireTimestamp, isolationLevel, false)\n            .setTargetTimes(ListOffsetsRequest.toListOffsetsTopics(timestampsToSearch));\n\n    log.debug(\"Sending ListOffsetRequest {} to broker {}\", builder, node);\n    return client.send(node, builder)\n            .compose(new RequestFutureAdapter<ClientResponse, ListOffsetResult>() {\n                @Override\n                public void onSuccess(ClientResponse response, RequestFuture<ListOffsetResult> future) {\n                    ListOffsetsResponse lor = (ListOffsetsResponse) response.responseBody();\n                    log.trace(\"Received ListOffsetResponse {} from broker {}\", lor, node);\n                    handleListOffsetResponse(lor, future);\n                }\n            });\n}", "summary_tokens": ["send", "the", "list", "offset", "request", "to", "a", "specific", "broker", "for", "the", "partitions", "and", "target", "timestamps"], "project": "kafka"}
{"id": 2507, "code": "public static <K, V> KeyValue<K, V> pair(final K key, final V value) {\n    return new KeyValue<>(key, value);\n}", "summary_tokens": ["create", "a", "new", "key", "value", "pair"], "project": "kafka"}
{"id": 2208, "code": "public void testInvalidFieldName() {\n    assertStringContains(\"Invalid field name\",\n        assertThrows(Throwable.class, () -> {\n            MessageGenerator.JSON_SERDE.readValue(String.join(\"\", Arrays.asList(\n                \"{\",\n                \"  \\\"type\\\": \\\"request\\\",\",\n                \"  \\\"name\\\": \\\"FooBar\\\",\",\n                \"  \\\"validVersions\\\": \\\"0-2\\\",\",\n                \"  \\\"flexibleVersions\\\": \\\"0+\\\",\",\n                \"  \\\"fields\\\": [\",\n                \"    { \\\"name\\\": \\\"_badName\\\", \\\"type\\\": \\\"[]int32\\\", \\\"versions\\\": \\\"0+\\\" }\",\n                \"  ]\",\n                \"}\")), MessageSpec.class);\n        }).getMessage());\n}", "summary_tokens": ["test", "attempting", "to", "create", "a", "field", "with", "an", "invalid", "name"], "project": "kafka"}
{"id": 2917, "code": "public <T> T store(final NamedTopologyStoreQueryParameters<T> storeQueryParameters) {\n    final String topologyName = storeQueryParameters.topologyName;\n    final String storeName = storeQueryParameters.storeName();\n    verifyTopologyStateStore(topologyName, storeName);\n    return super.store(storeQueryParameters);\n}", "summary_tokens": ["see", "kafka", "streams", "store", "store", "query", "parameters"], "project": "kafka"}
{"id": 2680, "code": "public long extract(final ConsumerRecord<Object, Object> record, final long partitionTime) {\n    final long timestamp = record.timestamp();\n\n    if (timestamp < 0) {\n        return onInvalidTimestamp(record, timestamp, partitionTime);\n    }\n\n    return timestamp;\n}", "summary_tokens": ["extracts", "the", "embedded", "metadata", "timestamp", "from", "the", "given", "consumer", "record"], "project": "kafka"}
{"id": 825, "code": "public synchronized KafkaMetric removeMetric(MetricName metricName) {\n    KafkaMetric metric = this.metrics.remove(metricName);\n    if (metric != null) {\n        for (MetricsReporter reporter : reporters) {\n            try {\n                reporter.metricRemoval(metric);\n            } catch (Exception e) {\n                log.error(\"Error when removing metric from \" + reporter.getClass().getName(), e);\n            }\n        }\n        log.trace(\"Removed metric named {}\", metricName);\n    }\n    return metric;\n}", "summary_tokens": ["remove", "a", "metric", "if", "it", "exists", "and", "return", "it"], "project": "kafka"}
{"id": 788, "code": "public String groupId() {\n    return groupId;\n}", "summary_tokens": ["return", "the", "group", "id", "that", "failed", "authorization"], "project": "kafka"}
{"id": 1420, "code": "public void testPemFilesWithoutClientKeyPassword(Args args) throws Exception {\n    boolean useInlinePem = args.useInlinePem;\n    TestSslUtils.convertToPem(args.sslServerConfigs, !useInlinePem, true);\n    TestSslUtils.convertToPem(args.sslClientConfigs, !useInlinePem, false);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    verifySslConfigs(args);\n}", "summary_tokens": ["test", "with", "pem", "key", "store", "files", "without", "key", "password", "for", "client", "key", "store"], "project": "kafka"}
{"id": 2261, "code": "public LocalReplicaChanges localChanges(int brokerId) {\n    Set<TopicPartition> deletes = new HashSet<>();\n    Map<TopicPartition, LocalReplicaChanges.PartitionInfo> leaders = new HashMap<>();\n    Map<TopicPartition, LocalReplicaChanges.PartitionInfo> followers = new HashMap<>();\n\n    for (Entry<Integer, PartitionRegistration> entry : partitionChanges.entrySet()) {\n        if (!Replicas.contains(entry.getValue().replicas, brokerId)) {\n            PartitionRegistration prevPartition = image.partitions().get(entry.getKey());\n            if (prevPartition != null && Replicas.contains(prevPartition.replicas, brokerId)) {\n                deletes.add(new TopicPartition(name(), entry.getKey()));\n            }\n        } else if (entry.getValue().leader == brokerId) {\n            PartitionRegistration prevPartition = image.partitions().get(entry.getKey());\n            if (prevPartition == null || prevPartition.partitionEpoch != entry.getValue().partitionEpoch) {\n                leaders.put(\n                    new TopicPartition(name(), entry.getKey()),\n                    new LocalReplicaChanges.PartitionInfo(id(), entry.getValue())\n                );\n            }\n        } else if (\n            entry.getValue().leader != brokerId &&\n            Replicas.contains(entry.getValue().replicas, brokerId)\n        ) {\n            PartitionRegistration prevPartition = image.partitions().get(entry.getKey());\n            if (prevPartition == null || prevPartition.partitionEpoch != entry.getValue().partitionEpoch) {\n                followers.put(\n                    new TopicPartition(name(), entry.getKey()),\n                    new LocalReplicaChanges.PartitionInfo(id(), entry.getValue())\n                );\n            }\n        }\n    }\n\n    return new LocalReplicaChanges(deletes, leaders, followers);\n}", "summary_tokens": ["find", "the", "partitions", "that", "have", "change", "based", "on", "the", "replica", "given"], "project": "kafka"}
{"id": 3182, "code": "public void setTimestamp(final long timestamp) {\n    this.recordTimestamp = timestamp;\n}", "summary_tokens": ["the", "context", "exposes", "this", "metadata", "for", "use", "in", "the", "processor"], "project": "kafka"}
{"id": 2215, "code": "void touch(int brokerId, boolean fenced, long metadataOffset) {\n    BrokerHeartbeatState broker = brokers.get(brokerId);\n    if (broker == null) {\n        broker = new BrokerHeartbeatState(brokerId);\n        brokers.put(brokerId, broker);\n    } else {\n            \n            \n            \n        untrack(broker);\n    }\n    broker.lastContactNs = time.nanoseconds();\n    broker.metadataOffset = metadataOffset;\n    if (fenced) {\n            \n            \n        broker.controlledShutDownOffset = -1;\n    } else {\n        unfenced.add(broker);\n        if (!broker.shuttingDown()) {\n            active.add(broker);\n        }\n    }\n}", "summary_tokens": ["update", "broker", "state", "including", "last", "contact", "ns"], "project": "kafka"}
{"id": 2707, "code": "public <NewV> FixedKeyRecord<K, NewV> withValue(final NewV value) {\n    return new FixedKeyRecord<>(key, value, timestamp, headers);\n}", "summary_tokens": ["a", "convenient", "way", "to", "produce", "a", "new", "record", "if", "you", "only", "need", "to", "change", "the", "value"], "project": "kafka"}
{"id": 2016, "code": "public void testBrokerCoordinator() throws Exception {\n    ConnectorHandle connectorHandle = RuntimeHandles.get().connectorHandle(CONNECTOR_NAME);\n    workerProps.put(DistributedConfig.SCHEDULED_REBALANCE_MAX_DELAY_MS_CONFIG, String.valueOf(5000));\n    connect = connectBuilder.workerProps(workerProps).build();\n        \n    connect.start();\n    int numTasks = 4;\n        \n    connect.kafka().createTopic(TOPIC_NAME, NUM_TOPIC_PARTITIONS);\n\n        \n    Map<String, String> props = defaultSourceConnectorProps(TOPIC_NAME);\n\n    connect.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n            \"Initial group of workers did not start in time.\");\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, numTasks,\n            \"Connector tasks did not start in time.\");\n\n        \n    StartAndStopLatch stopLatch = connectorHandle.expectedStops(1, false);\n\n    connect.kafka().stopOnlyKafka();\n\n    connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n            \"Group of workers did not remain the same after broker shutdown\");\n\n        \n        \n    Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n\n        \n    assertTrue(\"Failed to stop connector and tasks after coordinator failure within \"\n                    + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n            stopLatch.await(CONNECTOR_SETUP_DURATION_MS, TimeUnit.MILLISECONDS));\n\n    StartAndStopLatch startLatch = connectorHandle.expectedStarts(1, false);\n    connect.kafka().startOnlyKafkaOnSamePorts();\n\n        \n    Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n\n    connect.assertions().assertExactlyNumWorkersAreUp(NUM_WORKERS,\n            \"Group of workers did not remain the same within the designated time.\");\n\n        \n    Thread.sleep(TimeUnit.SECONDS.toMillis(10));\n\n    connect.assertions().assertConnectorAndAtLeastNumTasksAreRunning(CONNECTOR_NAME, numTasks,\n            \"Connector tasks did not start in time.\");\n\n        \n    assertTrue(\"Failed to stop connector and tasks after coordinator failure within \"\n                    + CONNECTOR_SETUP_DURATION_MS + \"ms\",\n            startLatch.await(CONNECTOR_SETUP_DURATION_MS, TimeUnit.MILLISECONDS));\n}", "summary_tokens": ["verify", "that", "a", "set", "of", "tasks", "restarts", "correctly", "after", "a", "broker", "goes", "offline", "and", "back", "online"], "project": "kafka"}
{"id": 1855, "code": "public void configSnapshot(ClusterConfigState update) {\n    configSnapshot = update;\n}", "summary_tokens": ["set", "the", "state", "of", "the", "cluster", "configuration", "to", "this", "worker", "coordinator"], "project": "kafka"}
{"id": 1578, "code": "public static <T> boolean sameElementsWithoutOrder(Iterator<T> iterator1,\n                                                   Iterator<T> iterator2) {\n        \n    Set<T> allSegmentsSet = new HashSet<>();\n    iterator1.forEachRemaining(allSegmentsSet::add);\n    Set<T> expectedSegmentsSet = new HashSet<>();\n    iterator2.forEachRemaining(expectedSegmentsSet::add);\n\n    return allSegmentsSet.equals(expectedSegmentsSet);\n}", "summary_tokens": ["returns", "true", "if", "both", "the", "iterators", "have", "same", "set", "of", "elements", "irrespective", "of", "order", "and", "duplicates"], "project": "kafka"}
{"id": 1539, "code": "public void oldSaslScramSslClientWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(true, false, SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\");\n}", "summary_tokens": ["tests", "sasl", "scram", "authentication", "failure", "over", "ssl", "with", "old", "version", "of", "client", "that", "does", "not", "support", "sasl", "authenticate", "headers", "and", "new", "version", "of", "server"], "project": "kafka"}
{"id": 2960, "code": "public Query<R> getQuery() {\n    return query;\n}", "summary_tokens": ["the", "query", "this", "request", "is", "meant", "to", "run"], "project": "kafka"}
{"id": 1475, "code": "public void testVersionLogic() {\n    for (short version : LEADER_AND_ISR.allVersions()) {\n        List<LeaderAndIsrPartitionState> partitionStates = asList(\n            new LeaderAndIsrPartitionState()\n                .setTopicName(\"topic0\")\n                .setPartitionIndex(0)\n                .setControllerEpoch(2)\n                .setLeader(0)\n                .setLeaderEpoch(10)\n                .setIsr(asList(0, 1))\n                .setPartitionEpoch(10)\n                .setReplicas(asList(0, 1, 2))\n                .setAddingReplicas(asList(3))\n                .setRemovingReplicas(asList(2)),\n            new LeaderAndIsrPartitionState()\n                .setTopicName(\"topic0\")\n                .setPartitionIndex(1)\n                .setControllerEpoch(2)\n                .setLeader(1)\n                .setLeaderEpoch(11)\n                .setIsr(asList(1, 2, 3))\n                .setPartitionEpoch(11)\n                .setReplicas(asList(1, 2, 3))\n                .setAddingReplicas(emptyList())\n                .setRemovingReplicas(emptyList()),\n            new LeaderAndIsrPartitionState()\n                .setTopicName(\"topic1\")\n                .setPartitionIndex(0)\n                .setControllerEpoch(2)\n                .setLeader(2)\n                .setLeaderEpoch(11)\n                .setIsr(asList(2, 3, 4))\n                .setPartitionEpoch(11)\n                .setReplicas(asList(2, 3, 4))\n                .setAddingReplicas(emptyList())\n                .setRemovingReplicas(emptyList())\n        );\n\n        List<Node> liveNodes = asList(\n            new Node(0, \"host0\", 9090),\n            new Node(1, \"host1\", 9091)\n        );\n\n        Map<String, Uuid> topicIds = new HashMap<>();\n        topicIds.put(\"topic0\", Uuid.randomUuid());\n        topicIds.put(\"topic1\", Uuid.randomUuid());\n\n        LeaderAndIsrRequest request = new LeaderAndIsrRequest.Builder(version, 1, 2, 3, partitionStates,\n            topicIds, liveNodes).build();\n\n        List<LeaderAndIsrLiveLeader> liveLeaders = liveNodes.stream().map(n -> new LeaderAndIsrLiveLeader()\n            .setBrokerId(n.id())\n            .setHostName(n.host())\n            .setPort(n.port())).collect(Collectors.toList());\n        assertEquals(new HashSet<>(partitionStates), iterableToSet(request.partitionStates()));\n        assertEquals(liveLeaders, request.liveLeaders());\n        assertEquals(1, request.controllerId());\n        assertEquals(2, request.controllerEpoch());\n        assertEquals(3, request.brokerEpoch());\n\n        ByteBuffer byteBuffer = request.serialize();\n        LeaderAndIsrRequest deserializedRequest = new LeaderAndIsrRequest(new LeaderAndIsrRequestData(\n            new ByteBufferAccessor(byteBuffer), version), version);\n\n            \n            \n        if (version < 3) {\n            partitionStates.get(0)\n                .setAddingReplicas(emptyList())\n                .setRemovingReplicas(emptyList());\n        }\n\n            \n            \n        if (version < 2) {\n            topicIds = new HashMap<>();\n        }\n\n            \n            \n        if (version > 1 && version < 5) {\n            topicIds.put(\"topic0\", Uuid.ZERO_UUID);\n            topicIds.put(\"topic1\", Uuid.ZERO_UUID);\n        }\n\n        assertEquals(new HashSet<>(partitionStates), iterableToSet(deserializedRequest.partitionStates()));\n        assertEquals(topicIds, deserializedRequest.topicIds());\n        assertEquals(liveLeaders, deserializedRequest.liveLeaders());\n        assertEquals(1, request.controllerId());\n        assertEquals(2, request.controllerEpoch());\n        assertEquals(3, request.brokerEpoch());\n    }\n}", "summary_tokens": ["verifies", "the", "logic", "we", "have", "in", "leader", "and", "isr", "request", "to", "present", "a", "unified", "interface", "across", "the", "various", "versions", "works", "correctly"], "project": "kafka"}
{"id": 2424, "code": "public static void completePath(MetadataNodeManager nodeManager,\n                                String pathPrefix,\n                                List<Candidate> candidates) throws Exception {\n    nodeManager.visit(data -> {\n        String absolutePath = pathPrefix.startsWith(\"/\") ?\n            pathPrefix : data.workingDirectory() + \"/\" + pathPrefix;\n        List<String> pathComponents = stripDotPathComponents(splitPath(absolutePath));\n        DirectoryNode directory = data.root();\n        int numDirectories = pathPrefix.endsWith(\"/\") ?\n            pathComponents.size() : pathComponents.size() - 1;\n        for (int i = 0; i < numDirectories; i++) {\n            MetadataNode node = directory.child(pathComponents.get(i));\n            if (!(node instanceof DirectoryNode)) {\n                return;\n            }\n            directory = (DirectoryNode) node;\n        }\n        String lastComponent = \"\";\n        if (numDirectories >= 0 && numDirectories < pathComponents.size()) {\n            lastComponent = pathComponents.get(numDirectories);\n        }\n        Entry<String, MetadataNode> candidate =\n            directory.children().ceilingEntry(lastComponent);\n        String effectivePrefix;\n        int lastSlash = pathPrefix.lastIndexOf('/');\n        if (lastSlash < 0) {\n            effectivePrefix = \"\";\n        } else {\n            effectivePrefix = pathPrefix.substring(0, lastSlash + 1);\n        }\n        while (candidate != null && candidate.getKey().startsWith(lastComponent)) {\n            StringBuilder candidateBuilder = new StringBuilder();\n            candidateBuilder.append(effectivePrefix).append(candidate.getKey());\n            boolean complete = true;\n            if (candidate.getValue() instanceof DirectoryNode) {\n                candidateBuilder.append(\"/\");\n                complete = false;\n            }\n            candidates.add(new Candidate(candidateBuilder.toString(),\n                candidateBuilder.toString(), null, null, null, null, complete));\n            candidate = directory.children().higherEntry(candidate.getKey());\n        }\n    });\n}", "summary_tokens": ["generate", "a", "list", "of", "potential", "completions", "for", "a", "path"], "project": "kafka"}
{"id": 1879, "code": "public int attempt() {\n    return attempt;\n}", "summary_tokens": ["the", "number", "of", "attempts", "made", "to", "execute", "the", "current", "operation"], "project": "kafka"}
{"id": 226, "code": "public KafkaFuture<Map<ClientQuotaEntity, Map<String, Double>>> entities() {\n    return entities;\n}", "summary_tokens": ["returns", "a", "map", "from", "quota", "entity", "to", "a", "future", "which", "can", "be", "used", "to", "check", "the", "status", "of", "the", "operation"], "project": "kafka"}
{"id": 2888, "code": "private InternalTopologyBuilder lookupBuilderForTask(final TaskId task) {\n    final InternalTopologyBuilder builder = task.topologyName() == null ?\n        builders.get(UNNAMED_TOPOLOGY) :\n        builders.get(task.topologyName());\n    if (builder == null) {\n        throw new UnknownTopologyException(\"Unable to locate topology builder\", task.topologyName());\n    } else {\n        return builder;\n    }\n}", "summary_tokens": ["the", "internal", "topology", "builder", "for", "this", "task", "s", "topology", "guaranteed", "to", "be", "non", "null"], "project": "kafka"}
{"id": 2602, "code": "private static boolean containsValidPattern(final String topic) {\n    for (int i = 0; i < topic.length(); ++i) {\n        final char c = topic.charAt(i);\n\n            \n        final boolean validLetterOrDigit = (c >= 'a' && c <= 'z') || (c >= '0' && c <= '9') || (c >= 'A' && c <= 'Z');\n        final boolean validChar = validLetterOrDigit || c == '.' || c == '_' || c == '-';\n        if (!validChar) {\n            return false;\n        }\n    }\n    return true;\n}", "summary_tokens": ["valid", "characters", "for", "kafka", "topics", "are", "the", "ascii", "alphanumerics"], "project": "kafka"}
{"id": 3135, "code": "public void addEntryToRestoreLog(final K key, final V value) {\n    restorableEntries.add(new KeyValue<>(stateSerdes.rawKey(key), stateSerdes.rawValue(value)));\n}", "summary_tokens": ["this", "method", "adds", "an", "entry", "to", "the", "restore", "log", "for", "the", "key", "value", "store", "and", "is", "used", "em", "only", "em", "when", "testing", "the", "restore", "functionality", "of", "a", "key", "value", "store", "implementation"], "project": "kafka"}
{"id": 646, "code": "public void forceClose() {\n    this.forceClose = true;\n    initiateClose();\n}", "summary_tokens": ["closes", "the", "sender", "without", "sending", "out", "any", "pending", "messages"], "project": "kafka"}
{"id": 677, "code": "public String name() {\n    return this.name;\n}", "summary_tokens": ["get", "the", "name", "of", "the", "metric"], "project": "kafka"}
{"id": 1396, "code": "public void testConnectDisconnectDuringInSinglePoll() throws Exception {\n        \n    KafkaChannel kafkaChannel = mock(KafkaChannel.class);\n    when(kafkaChannel.id()).thenReturn(\"1\");\n    when(kafkaChannel.socketDescription()).thenReturn(\"\");\n    when(kafkaChannel.state()).thenReturn(ChannelState.NOT_CONNECTED);\n    when(kafkaChannel.finishConnect()).thenReturn(true);\n    when(kafkaChannel.isConnected()).thenReturn(true);\n    when(kafkaChannel.ready()).thenReturn(false);\n    doThrow(new IOException()).when(kafkaChannel).prepare();\n\n    SelectionKey selectionKey = mock(SelectionKey.class);\n    when(kafkaChannel.selectionKey()).thenReturn(selectionKey);\n    when(selectionKey.channel()).thenReturn(SocketChannel.open());\n    when(selectionKey.readyOps()).thenReturn(SelectionKey.OP_CONNECT);\n    when(selectionKey.attachment()).thenReturn(kafkaChannel);\n\n    Set<SelectionKey> selectionKeys = Utils.mkSet(selectionKey);\n    selector.pollSelectionKeys(selectionKeys, false, System.nanoTime());\n\n    assertFalse(selector.connected().contains(kafkaChannel.id()));\n    assertTrue(selector.disconnected().containsKey(kafkaChannel.id()));\n\n    verify(kafkaChannel, atLeastOnce()).ready();\n    verify(kafkaChannel).disconnect();\n    verify(kafkaChannel).close();\n    verify(selectionKey).cancel();\n}", "summary_tokens": ["tests", "that", "a", "connect", "and", "disconnect", "in", "a", "single", "poll", "invocation", "results", "in", "the", "channel", "id", "being", "in", "disconnected", "but", "not", "connected"], "project": "kafka"}
{"id": 3220, "code": "public static String durationString(long periodMs) {\n    StringBuilder bld = new StringBuilder();\n    Duration duration = Duration.ofMillis(periodMs);\n    long hours = duration.toHours();\n    if (hours > 0) {\n        bld.append(hours).append(\"h\");\n        duration = duration.minusHours(hours);\n    }\n    long minutes = duration.toMinutes();\n    if (minutes > 0) {\n        bld.append(minutes).append(\"m\");\n        duration = duration.minusMinutes(minutes);\n    }\n    long seconds = duration.getSeconds();\n    if ((seconds != 0) || bld.toString().isEmpty()) {\n        bld.append(seconds).append(\"s\");\n    }\n    return bld.toString();\n}", "summary_tokens": ["pretty", "print", "a", "duration"], "project": "kafka"}
{"id": 1956, "code": "public void putTaskConfigs(String connector, List<Map<String, String>> configs) {\n        \n        \n    try {\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write root configuration to Kafka: \", e);\n        throw new ConnectException(\"Error writing root configuration to Kafka\", e);\n    }\n\n    int taskCount = configs.size();\n\n        \n    int index = 0;\n    for (Map<String, String> taskConfig: configs) {\n        Struct connectConfig = new Struct(TASK_CONFIGURATION_V0);\n        connectConfig.put(\"properties\", taskConfig);\n        byte[] serializedConfig = converter.fromConnectData(topic, TASK_CONFIGURATION_V0, connectConfig);\n        log.debug(\"Writing configuration for connector '{}' task {}\", connector, index);\n        ConnectorTaskId connectorTaskId = new ConnectorTaskId(connector, index);\n        sendPrivileged(TASK_KEY(connectorTaskId), serializedConfig);\n        index++;\n    }\n\n        \n        \n    try {\n            \n        if (taskCount > 0) {\n            configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n        }\n            \n        Struct connectConfig = new Struct(CONNECTOR_TASKS_COMMIT_V0);\n        connectConfig.put(\"tasks\", taskCount);\n        byte[] serializedConfig = converter.fromConnectData(topic, CONNECTOR_TASKS_COMMIT_V0, connectConfig);\n        log.debug(\"Writing commit for connector '{}' with {} tasks.\", connector, taskCount);\n        sendPrivileged(COMMIT_TASKS_KEY(connector), serializedConfig);\n\n            \n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write root configuration to Kafka: \", e);\n        throw new ConnectException(\"Error writing root configuration to Kafka\", e);\n    }\n}", "summary_tokens": ["write", "these", "task", "configurations", "and", "associated", "commit", "messages", "unless", "an", "inconsistency", "is", "found", "that", "indicates", "that", "we", "would", "be", "leaving", "one", "of", "the", "referenced", "connectors", "with", "an", "inconsistent", "state"], "project": "kafka"}
{"id": 1866, "code": "public void recordRetry() {\n    retries.record();\n}", "summary_tokens": ["the", "number", "of", "retries", "made", "while", "executing", "operations"], "project": "kafka"}
{"id": 582, "code": "public long totalMemory() {\n    return this.totalMemory;\n}", "summary_tokens": ["the", "total", "memory", "managed", "by", "this", "pool"], "project": "kafka"}
{"id": 1468, "code": "public void testPreallocateTrue() throws IOException {\n    File temp = tempFile();\n    FileRecords fileRecords = FileRecords.open(temp, false, 1024 * 1024, true);\n    long position = fileRecords.channel().position();\n    int size = fileRecords.sizeInBytes();\n    assertEquals(0, position);\n    assertEquals(0, size);\n    assertEquals(1024 * 1024, temp.length());\n}", "summary_tokens": ["test", "the", "new", "file", "records", "with", "pre", "allocate", "as", "true"], "project": "kafka"}
{"id": 3040, "code": "public KeyValueIterator<Bytes, byte[]> reverseRange(final Bytes from, final Bytes to) {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support reverseRange() function.\");\n}", "summary_tokens": ["unsupported", "operation", "exception", "at", "every", "invocation"], "project": "kafka"}
{"id": 1687, "code": "public void shouldConvertStringOfListWithMixedElementTypesIntoListWithDifferentElementTypes() {\n    String str = \"[1, 2, \\\"three\\\"]\";\n    List<?> list = Values.convertToList(Schema.STRING_SCHEMA, str);\n    assertEquals(3, list.size());\n    assertEquals(1, ((Number) list.get(0)).intValue());\n    assertEquals(2, ((Number) list.get(1)).intValue());\n    assertEquals(\"three\", list.get(2));\n}", "summary_tokens": ["the", "parsed", "array", "has", "byte", "values", "and", "one", "int", "value", "so", "we", "should", "return", "list", "with", "single", "unified", "type", "of", "integers"], "project": "kafka"}
{"id": 2839, "code": "private RepartitionTopics prepareRepartitionTopics(final Cluster metadata) {\n    final RepartitionTopics repartitionTopics = new RepartitionTopics(\n        taskManager.topologyMetadata(),\n        internalTopicManager,\n        copartitionedTopicsEnforcer,\n        metadata,\n        logPrefix\n    );\n    repartitionTopics.setup();\n    final boolean isMissingInputTopics = !repartitionTopics.missingSourceTopicExceptions().isEmpty();\n    if (isMissingInputTopics) {\n        if (!taskManager.topologyMetadata().hasNamedTopologies()) {\n            throw new MissingSourceTopicException(\"Missing source topics.\");\n        } else {\n            nonFatalExceptionsToHandle.addAll(repartitionTopics.missingSourceTopicExceptions());\n        }\n    }\n    return repartitionTopics;\n}", "summary_tokens": ["computes", "and", "assembles", "all", "repartition", "topic", "metadata", "then", "creates", "the", "topics", "if", "necessary"], "project": "kafka"}
{"id": 3023, "code": "public static SessionBytesStoreSupplier inMemorySessionStore(final String name, final Duration retentionPeriod) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(retentionPeriod, \"retentionPeriod\");\n    final long retentionPeriodMs = validateMillisecondDuration(retentionPeriod, msgPrefix);\n    if (retentionPeriodMs < 0) {\n        throw new IllegalArgumentException(\"retentionPeriod cannot be negative\");\n    }\n    return new InMemorySessionBytesStoreSupplier(name, retentionPeriodMs);\n}", "summary_tokens": ["create", "an", "in", "memory", "session", "bytes", "store", "supplier"], "project": "kafka"}
{"id": 1511, "code": "public void testDisallowedKafkaRequestsBeforeAuthentication() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    MetadataRequest metadataRequest1 = new MetadataRequest.Builder(Collections.singletonList(\"sometopic\"),\n            true).build();\n    RequestHeader metadataRequestHeader1 = new RequestHeader(ApiKeys.METADATA, metadataRequest1.version(),\n            \"someclient\", 1);\n    selector.send(new NetworkSend(node1, metadataRequest1.toSend(metadataRequestHeader1)));\n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n\n        \n    String node2 = \"invalid2\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node2);\n    sendHandshakeRequestReceiveResponse(node2, (short) 1);\n    MetadataRequest metadataRequest2 = new MetadataRequest.Builder(Collections.singletonList(\"sometopic\"), true).build();\n    RequestHeader metadataRequestHeader2 = new RequestHeader(ApiKeys.METADATA,\n            metadataRequest2.version(), \"someclient\", 2);\n    selector.send(new NetworkSend(node2, metadataRequest2.toSend(metadataRequestHeader2)));\n    NetworkTestUtils.waitForChannelClose(selector, node2, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good2\");\n}", "summary_tokens": ["tests", "that", "kafka", "requests", "that", "are", "forbidden", "until", "successful", "authentication", "result", "in", "authentication", "failure", "and", "do", "not", "cause", "any", "failures", "in", "the", "server"], "project": "kafka"}
{"id": 1139, "code": "public short loginRefreshMinPeriodSeconds() {\n    return loginRefreshMinPeriodSeconds;\n}", "summary_tokens": ["the", "desired", "minimum", "time", "between", "checks", "by", "the", "background", "login", "refresh", "thread", "in", "seconds"], "project": "kafka"}
{"id": 53, "code": "public synchronized long timeToAllowUpdate(long nowMs) {\n    return Math.max(this.lastRefreshMs + this.refreshBackoffMs - nowMs, 0);\n}", "summary_tokens": ["return", "the", "next", "time", "when", "the", "current", "cluster", "info", "can", "be", "updated", "i"], "project": "kafka"}
{"id": 1485, "code": "public void testValidSaslPlainOverPlaintext() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n\n    server = createEchoServer(securityProtocol);\n    checkAuthenticationAndReauthentication(securityProtocol, node);\n}", "summary_tokens": ["tests", "good", "path", "sasl", "plain", "client", "and", "server", "channels", "using", "plaintext", "transport", "layer"], "project": "kafka"}
{"id": 2332, "code": "public void testPassLeadership() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(3, Optional.empty())) {\n        LeaderAndEpoch first = env.waitForLeader();\n        LeaderAndEpoch cur = first;\n        do {\n            int currentLeaderId = cur.leaderId().orElseThrow(() ->\n                new AssertionError(\"Current leader is undefined\")\n            );\n            env.logManagers().get(currentLeaderId).resign(cur.epoch());\n\n            LeaderAndEpoch next = env.waitForLeader();\n            while (next.epoch() == cur.epoch()) {\n                Thread.sleep(1);\n                next = env.waitForLeader();\n            }\n            long expectedNextEpoch = cur.epoch() + 2;\n            assertEquals(expectedNextEpoch, next.epoch(), \"Expected next epoch to be \" + expectedNextEpoch +\n                \", but found  \" + next);\n            cur = next;\n        } while (cur.leaderId().equals(first.leaderId()));\n        env.close();\n        assertEquals(null, env.firstError.get());\n    }\n}", "summary_tokens": ["test", "that", "we", "can", "pass", "leadership", "back", "and", "forth", "between", "log", "managers"], "project": "kafka"}
{"id": 511, "code": "public boolean isRetriable() {\n    return exception() instanceof RetriableException;\n}", "summary_tokens": ["check", "if", "the", "request", "is", "retriable", "convenience", "method", "for", "checking", "if", "the", "exception", "is", "an", "instance", "of", "retriable", "exception"], "project": "kafka"}
{"id": 1678, "code": "default TransactionContext transactionContext() {\n    return null;\n}", "summary_tokens": ["get", "a", "transaction", "context", "that", "can", "be", "used", "to", "define", "producer", "transaction", "boundaries", "when", "exactly", "once", "support", "is", "enabled", "for", "the", "connector"], "project": "kafka"}
{"id": 2127, "code": "public int executePut(String url, String body) {\n    return requestPut(url, body).getStatus();\n}", "summary_tokens": ["execute", "a", "put", "request", "on", "the", "given", "url"], "project": "kafka"}
{"id": 1521, "code": "public void testInvalidMechanism() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, \"INVALID\");\n\n    server = createEchoServer(securityProtocol);\n    try {\n        createAndCheckClientConnectionFailure(securityProtocol, node);\n        fail(\"Did not generate exception prior to creating channel\");\n    } catch (IOException expected) {\n        server.verifyAuthenticationMetrics(0, 0);\n        server.verifyReauthenticationMetrics(0, 0);\n        Throwable underlyingCause = expected.getCause().getCause().getCause();\n        assertEquals(SaslAuthenticationException.class, underlyingCause.getClass());\n        assertEquals(\"Failed to create SaslClient with mechanism INVALID\", underlyingCause.getMessage());\n    } finally {\n        closeClientConnectionIfNecessary();\n    }\n}", "summary_tokens": ["tests", "that", "clients", "using", "invalid", "sasl", "mechanisms", "fail", "authentication"], "project": "kafka"}
{"id": 3056, "code": "public HostInfo hostInfo() {\n    return hostInfo;\n}", "summary_tokens": ["the", "value", "of", "org"], "project": "kafka"}
{"id": 3125, "code": "public void testHighAvailabilityTaskAssignorLargePartitionCount() {\n    completeLargeAssignment(6_000, 2, 1, 1, HighAvailabilityTaskAssignor.class);\n}", "summary_tokens": ["high", "availability", "task", "assignor", "tests"], "project": "kafka"}
{"id": 2693, "code": "public static To child(final String childName) {\n    return new To(childName, -1);\n}", "summary_tokens": ["forward", "the", "key", "value", "pair", "to", "one", "of", "the", "downstream", "processors", "designated", "by", "the", "downstream", "processor", "name"], "project": "kafka"}
{"id": 2864, "code": "private void tryToLockAllNonEmptyTaskDirectories() {\n        \n        \n    lockedTaskDirectories.clear();\n\n    for (final TaskDirectory taskDir : stateDirectory.listNonEmptyTaskDirectories()) {\n        final File dir = taskDir.file();\n        final String namedTopology = taskDir.namedTopology();\n        try {\n            final TaskId id = parseTaskDirectoryName(dir.getName(), namedTopology);\n            if (stateDirectory.lock(id)) {\n                lockedTaskDirectories.add(id);\n                if (!tasks.contains(id)) {\n                    log.debug(\"Temporarily locked unassigned task {} for the upcoming rebalance\", id);\n                }\n            }\n        } catch (final TaskIdFormatException e) {\n                \n        }\n    }\n}", "summary_tokens": ["makes", "a", "weak", "attempt", "to", "lock", "all", "non", "empty", "task", "directories", "in", "the", "state", "dir"], "project": "kafka"}
{"id": 2185, "code": "default boolean isArray() {\n    return false;\n}", "summary_tokens": ["returns", "true", "if", "this", "is", "an", "array", "type"], "project": "kafka"}
{"id": 741, "code": "private void writeEndMark() throws IOException {\n    ByteUtils.writeUnsignedIntLE(out, 0);\n        \n}", "summary_tokens": ["similar", "to", "the", "write", "block", "method"], "project": "kafka"}
{"id": 2632, "code": "public static SlidingWindows withTimeDifferenceAndGrace(final Duration timeDifference, final Duration grace) throws IllegalArgumentException {\n    final String msgPrefixSize = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, msgPrefixSize);\n\n    final String msgPrefixGrace = prepareMillisCheckFailMsgPrefix(grace, \"grace\");\n    final long graceMs = validateMillisecondDuration(grace, msgPrefixGrace);\n\n    return new SlidingWindows(timeDifferenceMs, graceMs);\n}", "summary_tokens": ["return", "a", "window", "definition", "with", "the", "window", "size", "based", "on", "the", "given", "maximum", "time", "difference", "inclusive", "between", "records", "in", "the", "same", "window", "and", "given", "window", "grace", "period"], "project": "kafka"}
{"id": 1862, "code": "public Future<RecordMetadata> report(ProcessingContext context) {\n    if (dlqTopicName.isEmpty()) {\n        return CompletableFuture.completedFuture(null);\n    }\n    errorHandlingMetrics.recordDeadLetterQueueProduceRequest();\n\n    ConsumerRecord<byte[], byte[]> originalMessage = context.consumerRecord();\n    if (originalMessage == null) {\n        errorHandlingMetrics.recordDeadLetterQueueProduceFailed();\n        return CompletableFuture.completedFuture(null);\n    }\n\n    ProducerRecord<byte[], byte[]> producerRecord;\n    if (originalMessage.timestamp() == RecordBatch.NO_TIMESTAMP) {\n        producerRecord = new ProducerRecord<>(dlqTopicName, null,\n                originalMessage.key(), originalMessage.value(), originalMessage.headers());\n    } else {\n        producerRecord = new ProducerRecord<>(dlqTopicName, null, originalMessage.timestamp(),\n                originalMessage.key(), originalMessage.value(), originalMessage.headers());\n    }\n\n    if (connConfig.isDlqContextHeadersEnabled()) {\n        populateContextHeaders(producerRecord, context);\n    }\n\n    return this.kafkaProducer.send(producerRecord, (metadata, exception) -> {\n        if (exception != null) {\n            log.error(\"Could not produce message to dead letter queue. topic=\" + dlqTopicName, exception);\n            errorHandlingMetrics.recordDeadLetterQueueProduceFailed();\n        }\n    });\n}", "summary_tokens": ["write", "the", "raw", "records", "into", "a", "kafka", "topic", "and", "return", "the", "producer", "future"], "project": "kafka"}
{"id": 1070, "code": "public ResourceType resourceType() {\n    return resourceType;\n}", "summary_tokens": ["the", "specific", "resource", "type", "this", "pattern", "matches"], "project": "kafka"}
{"id": 2948, "code": "public static <K, V> RangeQuery<K, V> withLowerBound(final K lower) {\n    return new RangeQuery<>(Optional.of(lower), Optional.empty());\n}", "summary_tokens": ["interactive", "range", "query", "using", "a", "lower", "bound", "to", "filter", "the", "keys", "returned"], "project": "kafka"}
{"id": 2994, "code": "default KeyValueIterator<K, V> reverseAll() {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["return", "a", "reverse", "iterator", "over", "all", "keys", "in", "this", "store"], "project": "kafka"}
{"id": 617, "code": "public RecordAppendResult append(String topic,\n                                 int partition,\n                                 long timestamp,\n                                 byte[] key,\n                                 byte[] value,\n                                 Header[] headers,\n                                 AppendCallbacks callbacks,\n                                 long maxTimeToBlock,\n                                 boolean abortOnNewBatch,\n                                 long nowMs,\n                                 Cluster cluster) throws InterruptedException {\n    TopicInfo topicInfo = topicInfoMap.computeIfAbsent(topic, k -> new TopicInfo(logContext, k, batchSize));\n\n        \n        \n    appendsInProgress.incrementAndGet();\n    ByteBuffer buffer = null;\n    if (headers == null) headers = Record.EMPTY_HEADERS;\n    try {\n            \n        while (true) {\n                \n                \n                \n                \n            final BuiltInPartitioner.StickyPartitionInfo partitionInfo;\n            final int effectivePartition;\n            if (partition == RecordMetadata.UNKNOWN_PARTITION) {\n                partitionInfo = topicInfo.builtInPartitioner.peekCurrentPartitionInfo(cluster);\n                effectivePartition = partitionInfo.partition();\n            } else {\n                partitionInfo = null;\n                effectivePartition = partition;\n            }\n\n                \n            setPartition(callbacks, effectivePartition);\n\n                \n            Deque<ProducerBatch> dq = topicInfo.batches.computeIfAbsent(effectivePartition, k -> new ArrayDeque<>());\n            synchronized (dq) {\n                    \n                if (topicInfo.builtInPartitioner.isPartitionChanged(partitionInfo)) {\n                    log.trace(\"Partition {} for topic {} switched by a concurrent append, retrying\",\n                            partitionInfo.partition(), topic);\n                    continue;\n                }\n                RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callbacks, dq, nowMs);\n                if (appendResult != null) {\n                    topicInfo.builtInPartitioner.updatePartitionInfo(partitionInfo, appendResult.appendedBytes, cluster);\n                    return appendResult;\n                }\n            }\n\n                \n            if (abortOnNewBatch) {\n                    \n                return new RecordAppendResult(null, false, false, true, 0);\n            }\n\n            if (buffer == null) {\n                byte maxUsableMagic = apiVersions.maxUsableProduceMagic();\n                int size = Math.max(this.batchSize, AbstractRecords.estimateSizeInBytesUpperBound(maxUsableMagic, compression, key, value, headers));\n                log.trace(\"Allocating a new {} byte message buffer for topic {} partition {} with remaining timeout {}ms\", size, topic, partition, maxTimeToBlock);\n                    \n                buffer = free.allocate(size, maxTimeToBlock);\n                    \n                    \n                    \n                nowMs = time.milliseconds();\n            }\n\n            synchronized (dq) {\n                    \n                if (topicInfo.builtInPartitioner.isPartitionChanged(partitionInfo)) {\n                    log.trace(\"Partition {} for topic {} switched by a concurrent append, retrying\",\n                            partitionInfo.partition(), topic);\n                    continue;\n                }\n                RecordAppendResult appendResult = appendNewBatch(topic, effectivePartition, dq, timestamp, key, value, headers, callbacks, buffer, nowMs);\n                    \n                if (appendResult.newBatchCreated)\n                    buffer = null;\n                topicInfo.builtInPartitioner.updatePartitionInfo(partitionInfo, appendResult.appendedBytes, cluster);\n                return appendResult;\n            }\n        }\n    } finally {\n        free.deallocate(buffer);\n        appendsInProgress.decrementAndGet();\n    }\n}", "summary_tokens": ["add", "a", "record", "to", "the", "accumulator", "return", "the", "append", "result", "p", "the", "append", "result", "will", "contain", "the", "future", "metadata", "and", "flag", "for", "whether", "the", "appended", "batch", "is", "full", "or", "a", "new", "batch", "is", "created", "p"], "project": "kafka"}
{"id": 1825, "code": "void processRestartRequests() {\n    List<RestartRequest> restartRequests;\n    synchronized (this) {\n        if (pendingRestartRequests.isEmpty()) {\n            return;\n        }\n            \n        restartRequests = new ArrayList<>(pendingRestartRequests.values());\n        pendingRestartRequests.clear();\n    }\n    restartRequests.forEach(restartRequest -> {\n        try {\n            doRestartConnectorAndTasks(restartRequest);\n        } catch (Exception e) {\n            log.warn(\"Unexpected error while trying to process \" + restartRequest + \", the restart request will be skipped.\", e);\n        }\n    });\n}", "summary_tokens": ["process", "all", "pending", "restart", "requests"], "project": "kafka"}
{"id": 1262, "code": "public static <T> Map<String, T> translateDeprecatedConfigs(Map<String, T> configs,\n                                                            Map<String, List<String>> aliasGroups) {\n    Set<String> aliasSet = Stream.concat(\n        aliasGroups.keySet().stream(),\n        aliasGroups.values().stream().flatMap(Collection::stream))\n        .collect(Collectors.toSet());\n\n        \n    Map<String, T> newConfigs = configs.entrySet().stream()\n        .filter(e -> !aliasSet.contains(e.getKey()))\n            \n        .filter(e -> Objects.nonNull(e.getValue()))\n        .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n    aliasGroups.forEach((target, aliases) -> {\n        List<String> deprecated = aliases.stream()\n            .filter(configs::containsKey)\n            .collect(Collectors.toList());\n\n        if (deprecated.isEmpty()) {\n                \n            if (configs.containsKey(target)) {\n                newConfigs.put(target, configs.get(target));\n            }\n            return;\n        }\n\n        String aliasString = String.join(\", \", deprecated);\n\n        if (configs.containsKey(target)) {\n                \n            log.error(target + \" was configured, as well as the deprecated alias(es) \" +\n                      aliasString + \".  Using the value of \" + target);\n            newConfigs.put(target, configs.get(target));\n        } else if (deprecated.size() > 1) {\n            log.error(\"The configuration keys \" + aliasString + \" are deprecated and may be \" +\n                      \"removed in the future.  Additionally, this configuration is ambigous because \" +\n                      \"these configuration keys are all aliases for \" + target + \".  Please update \" +\n                      \"your configuration to have only \" + target + \" set.\");\n            newConfigs.put(target, configs.get(deprecated.get(0)));\n        } else {\n            log.warn(\"Configuration key \" + deprecated.get(0) + \" is deprecated and may be removed \" +\n                     \"in the future.  Please update your configuration to use \" + target + \" instead.\");\n            newConfigs.put(target, configs.get(deprecated.get(0)));\n        }\n    });\n\n    return newConfigs;\n}", "summary_tokens": ["translates", "deprecated", "configurations", "into", "their", "non", "deprecated", "equivalents"], "project": "kafka"}
{"id": 2829, "code": "public void shutdown() {\n    log.info(\"Informed to shut down\");\n    final State oldState = setState(State.PENDING_SHUTDOWN);\n    if (oldState == State.CREATED) {\n            \n        completeShutdown(true);\n    }\n}", "summary_tokens": ["shutdown", "this", "stream", "thread"], "project": "kafka"}
{"id": 1384, "code": "public void testServerDisconnect() throws Exception {\n    final String node = \"0\";\n\n        \n    blockingConnect(node);\n    assertEquals(\"hello\", blockingRequest(node, \"hello\"));\n\n    KafkaChannel channel = selector.channel(node);\n\n        \n    this.server.closeConnections();\n    TestUtils.waitForCondition(new TestCondition() {\n        @Override\n        public boolean conditionMet() {\n            try {\n                selector.poll(1000L);\n                return selector.disconnected().containsKey(node);\n            } catch (IOException e) {\n                throw new RuntimeException(e);\n            }\n        }\n    }, 5000, \"Failed to observe disconnected node in disconnected set\");\n\n    assertNull(channel.selectionKey().attachment());\n\n        \n    blockingConnect(node);\n    assertEquals(\"hello\", blockingRequest(node, \"hello\"));\n}", "summary_tokens": ["validate", "that", "when", "the", "server", "disconnects", "a", "client", "send", "ends", "up", "with", "that", "node", "in", "the", "disconnected", "list"], "project": "kafka"}
{"id": 2416, "code": "public long nextBlockFirstId() {\n    return firstProducerId + blockSize;\n}", "summary_tokens": ["get", "the", "first", "id", "of", "the", "next", "block", "following", "this", "one"], "project": "kafka"}
{"id": 2192, "code": "default boolean isStruct() {\n    return false;\n}", "summary_tokens": ["returns", "true", "if", "this", "is", "a", "struct", "type"], "project": "kafka"}
{"id": 2009, "code": "public TopicCreationGroup findFirstGroup(String topic) {\n    return topicGroups.values().stream()\n            .filter(group -> group.matches(topic))\n            .findFirst()\n            .orElse(defaultTopicGroup);\n}", "summary_tokens": ["get", "the", "first", "topic", "creation", "group", "that", "is", "configured", "to", "match", "the", "given", "topic", "name"], "project": "kafka"}
{"id": 2169, "code": "public URI adminUrl() {\n    return worker.rest().adminUrl();\n}", "summary_tokens": ["get", "the", "workers", "s", "url", "that", "accepts", "requests", "to", "its", "admin", "rest", "endpoint"], "project": "kafka"}
{"id": 2944, "code": "static <R> QueryResult<R> forUnknownQueryType(\n    final Query<R> query,\n    final StateStore store) {\n\n    return forFailure(\n        FailureReason.UNKNOWN_QUERY_TYPE,\n        \"This store (\" + store.getClass() + \") doesn't know how to execute \"\n            + \"the given query (\" + query + \").\" +\n            \" Contact the store maintainer if you need support for a new query type.\");\n}", "summary_tokens": ["static", "factory", "method", "to", "create", "a", "failed", "query", "result", "object", "to", "indicate", "that", "the", "store", "does", "not", "know", "how", "to", "handle", "the", "query"], "project": "kafka"}
{"id": 2639, "code": "public StreamJoined<K, V1, V2> withOtherValueSerde(final Serde<V2> otherValueSerde) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}", "summary_tokens": ["configure", "with", "the", "provided", "serde", "serde", "v", "0", "for", "the", "other", "value", "other", "value", "serde", "the", "serde", "to", "use", "for", "the", "other", "value", "other", "or", "right", "side", "of", "the", "join", "a", "new", "stream", "joined", "configured", "with", "the", "other", "value", "serde"], "project": "kafka"}
{"id": 392, "code": "public void assign(Collection<TopicPartition> partitions) {\n    acquireAndEnsureOpen();\n    try {\n        if (partitions == null) {\n            throw new IllegalArgumentException(\"Topic partition collection to assign to cannot be null\");\n        } else if (partitions.isEmpty()) {\n            this.unsubscribe();\n        } else {\n            for (TopicPartition tp : partitions) {\n                String topic = (tp != null) ? tp.topic() : null;\n                if (Utils.isBlank(topic))\n                    throw new IllegalArgumentException(\"Topic partitions to assign to cannot have null or empty topic\");\n            }\n            fetcher.clearBufferedDataForUnassignedPartitions(partitions);\n\n                \n                \n            if (coordinator != null)\n                this.coordinator.maybeAutoCommitOffsetsAsync(time.milliseconds());\n\n            log.info(\"Assigned to partition(s): {}\", Utils.join(partitions, \", \"));\n            if (this.subscriptions.assignFromUser(new HashSet<>(partitions)))\n                metadata.requestUpdateForNewTopics();\n        }\n    } finally {\n        release();\n    }\n}", "summary_tokens": ["manually", "assign", "a", "list", "of", "partitions", "to", "this", "consumer"], "project": "kafka"}
{"id": 1516, "code": "public void testClientLoginOverride() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", \"invaliduser\", \"invalidpassword\");\n    server = createEchoServer(securityProtocol);\n\n        \n    saslClientConfigs.put(SaslConfigs.SASL_LOGIN_CLASS, TestLogin.class.getName());\n    createAndCheckClientConnection(securityProtocol, \"1\");\n    assertEquals(1, TestLogin.loginCount.get());\n\n        \n    saslClientConfigs.remove(SaslConfigs.SASL_LOGIN_CLASS);\n    createAndCheckClientConnectionFailure(securityProtocol, \"invalid\");\n    assertEquals(1, TestLogin.loginCount.get());\n}", "summary_tokens": ["tests", "sasl", "login", "class", "override"], "project": "kafka"}
{"id": 313, "code": "public Set<TopicPartition> topicPartitions() {\n    return topicPartitions;\n}", "summary_tokens": ["the", "topic", "partitions", "assigned", "to", "a", "group", "member"], "project": "kafka"}
{"id": 2880, "code": "public KafkaFuture<Void> unregisterTopology(final KafkaFutureImpl<Void> removeTopologyFuture,\n                                            final String topologyName) {\n    try {\n        lock();\n        log.info(\"Beginning removal of NamedTopology {}, old topology version is {}\", topologyName, version.topologyVersion.get());\n        version.topologyVersion.incrementAndGet();\n        version.activeTopologyUpdateListeners.add(new TopologyVersionListener(topologyVersion(), removeTopologyFuture));\n        final InternalTopologyBuilder removedBuilder = builders.remove(topologyName);\n        removedBuilder.fullSourceTopicNames().forEach(allInputTopics::remove);\n        removedBuilder.allSourcePatternStrings().forEach(allInputTopics::remove);\n        log.info(\"Finished removing NamedTopology {}, topology version was updated to {}\", topologyName, version.topologyVersion.get());\n    } catch (final Throwable throwable) {\n        log.error(\"Failed to remove NamedTopology {}, please retry.\", topologyName);\n        removeTopologyFuture.completeExceptionally(throwable);\n    } finally {\n        unlock();\n    }\n    return removeTopologyFuture;\n}", "summary_tokens": ["removes", "the", "topology", "and", "registers", "a", "future", "that", "listens", "for", "all", "threads", "on", "the", "older", "version", "to", "see", "the", "update"], "project": "kafka"}
{"id": 1, "code": "public static ChannelBuilder createChannelBuilder(AbstractConfig config, Time time, LogContext logContext) {\n    SecurityProtocol securityProtocol = SecurityProtocol.forName(config.getString(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG));\n    String clientSaslMechanism = config.getString(SaslConfigs.SASL_MECHANISM);\n    return ChannelBuilders.clientChannelBuilder(securityProtocol, JaasContext.Type.CLIENT, config, null,\n            clientSaslMechanism, time, true, logContext);\n}", "summary_tokens": ["create", "a", "new", "channel", "builder", "from", "the", "provided", "configuration"], "project": "kafka"}
{"id": 1837, "code": "public int delay() {\n    return delay;\n}", "summary_tokens": ["return", "the", "delay", "for", "the", "rebalance", "that", "is", "scheduled", "by", "this", "assignment"], "project": "kafka"}
{"id": 847, "code": "public MetricName name() {\n    return this.name;\n}", "summary_tokens": ["get", "the", "name", "of", "this", "metric"], "project": "kafka"}
{"id": 3247, "code": "public void waitForShutdown() throws InterruptedException {\n    while (!shutdownExecutor.isShutdown()) {\n        shutdownExecutor.awaitTermination(1, TimeUnit.DAYS);\n    }\n}", "summary_tokens": ["wait", "for", "shutdown", "to", "complete"], "project": "kafka"}
{"id": 2818, "code": "public boolean commitRequested() {\n    return commitRequested;\n}", "summary_tokens": ["whether", "or", "not", "a", "request", "has", "been", "made", "to", "commit", "the", "current", "state"], "project": "kafka"}
{"id": 2781, "code": "public String toString(final String indent) {\n    final StringBuilder sb = new StringBuilder(super.toString(indent));\n    sb.append(indent).append(\"\\ttopic:\\t\\t\");\n    sb.append(topicExtractor);\n    sb.append(\"\\n\");\n    return sb.toString();\n}", "summary_tokens": ["a", "string", "representation", "of", "this", "node", "starting", "with", "the", "given", "indent", "useful", "for", "debugging"], "project": "kafka"}
{"id": 2345, "code": "public boolean isVoteGranted() {\n    return numGranted() >= majoritySize();\n}", "summary_tokens": ["check", "whether", "we", "have", "received", "enough", "votes", "to", "conclude", "the", "election", "and", "become", "leader"], "project": "kafka"}
{"id": 519, "code": "synchronized void resetGroupSubscription() {\n    groupSubscription = Collections.emptySet();\n}", "summary_tokens": ["reset", "the", "group", "s", "subscription", "to", "only", "contain", "topics", "subscribed", "by", "this", "consumer"], "project": "kafka"}
{"id": 2340, "code": "public int epoch() {\n    return epoch;\n}", "summary_tokens": ["the", "epoch", "of", "the", "leader", "that", "appended", "the", "record", "batch"], "project": "kafka"}
{"id": 1446, "code": "public void testCustomServerSslEngineFactory(Args args) throws Exception {\n    args.sslServerConfigs.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    verifySslConfigs(args);\n}", "summary_tokens": ["tests", "if", "server", "can", "plugin", "customize", "ssl"], "project": "kafka"}
{"id": 585, "code": "StickyPartitionInfo peekCurrentPartitionInfo(Cluster cluster) {\n    StickyPartitionInfo partitionInfo = stickyPartitionInfo.get();\n    if (partitionInfo != null)\n        return partitionInfo;\n\n        \n    partitionInfo = new StickyPartitionInfo(nextPartition(cluster));\n    if (stickyPartitionInfo.compareAndSet(null, partitionInfo))\n        return partitionInfo;\n\n        \n    return stickyPartitionInfo.get();\n}", "summary_tokens": ["peek", "currently", "chosen", "sticky", "partition"], "project": "kafka"}
{"id": 983, "code": "public Iterable<FileChannelRecordBatch> batchesFrom(final int start) {\n    return () -> batchIterator(start);\n}", "summary_tokens": ["get", "an", "iterator", "over", "the", "record", "batches", "in", "the", "file", "starting", "at", "a", "specific", "position"], "project": "kafka"}
{"id": 1421, "code": "public void testPemFilesWithoutServerKeyPassword(Args args) throws Exception {\n    TestSslUtils.convertToPem(args.sslServerConfigs, !args.useInlinePem, false);\n    TestSslUtils.convertToPem(args.sslClientConfigs, !args.useInlinePem, true);\n    verifySslConfigs(args);\n}", "summary_tokens": ["test", "with", "pem", "key", "store", "files", "without", "key", "password", "for", "server", "key", "store"], "project": "kafka"}
{"id": 1338, "code": "public void testPoorRoundRobinAssignmentScenario() {\n    Map<String, Integer> partitionsPerTopic = new HashMap<>();\n    for (int i = 1; i <= 5; i++)\n        partitionsPerTopic.put(String.format(\"topic%d\", i), (i % 2) + 1);\n\n    subscriptions.put(\"consumer1\",\n        new Subscription(topics(\"topic1\", \"topic2\", \"topic3\", \"topic4\", \"topic5\")));\n    subscriptions.put(\"consumer2\",\n        new Subscription(topics(\"topic1\", \"topic3\", \"topic5\")));\n    subscriptions.put(\"consumer3\",\n        new Subscription(topics(\"topic1\", \"topic3\", \"topic5\")));\n    subscriptions.put(\"consumer4\",\n        new Subscription(topics(\"topic1\", \"topic2\", \"topic3\", \"topic4\", \"topic5\")));\n\n    Map<String, List<TopicPartition>> assignment = assignor.assign(partitionsPerTopic, subscriptions);\n    verifyValidityAndBalance(subscriptions, assignment, partitionsPerTopic);\n}", "summary_tokens": ["this", "unit", "test", "performs", "sticky", "assignment", "for", "a", "scenario", "that", "round", "robin", "assignor", "handles", "poorly"], "project": "kafka"}
{"id": 3218, "code": "public static <T> T objectFromCommandLineArgument(String argument, Class<T> clazz) throws Exception {\n    if (openBraceComesFirst(argument)) {\n        return JSON_SERDE.readValue(argument, clazz);\n    } else {\n        return JSON_SERDE.readValue(new File(argument), clazz);\n    }\n}", "summary_tokens": ["read", "a", "json", "object", "from", "a", "command", "line", "argument"], "project": "kafka"}
{"id": 2464, "code": "public long endOffset() {\n    return endOffset;\n}", "summary_tokens": ["end", "offset", "of", "this", "segment", "inclusive"], "project": "kafka"}
{"id": 1746, "code": "public String connectorName() {\n    return request.connectorName();\n}", "summary_tokens": ["get", "the", "connector", "name"], "project": "kafka"}
{"id": 3206, "code": "private static ArgumentParser argParser() {\n    ArgumentParser parser = ArgumentParsers\n        .newArgumentParser(\"verifiable-log4j-appender\")\n        .defaultHelp(true)\n        .description(\"This tool produces increasing integers to the specified topic using KafkaLog4jAppender.\");\n\n    parser.addArgument(\"--topic\")\n        .action(store())\n        .required(true)\n        .type(String.class)\n        .metavar(\"TOPIC\")\n        .help(\"Produce messages to this topic.\");\n\n    parser.addArgument(\"--broker-list\")\n        .action(store())\n        .required(true)\n        .type(String.class)\n        .metavar(\"HOST1:PORT1[,HOST2:PORT2[...]]\")\n        .dest(\"brokerList\")\n        .help(\"Comma-separated list of Kafka brokers in the form HOST1:PORT1,HOST2:PORT2,...\");\n\n    parser.addArgument(\"--max-messages\")\n        .action(store())\n        .required(false)\n        .setDefault(-1)\n        .type(Integer.class)\n        .metavar(\"MAX-MESSAGES\")\n        .dest(\"maxMessages\")\n        .help(\"Produce this many messages. If -1, produce messages until the process is killed externally.\");\n\n    parser.addArgument(\"--acks\")\n        .action(store())\n        .required(false)\n        .setDefault(\"-1\")\n        .type(String.class)\n        .choices(\"0\", \"1\", \"-1\")\n        .metavar(\"ACKS\")\n        .help(\"Acks required on each produced message. See Kafka docs on request.required.acks for details.\");\n\n    parser.addArgument(\"--security-protocol\")\n        .action(store())\n        .required(false)\n        .setDefault(\"PLAINTEXT\")\n        .type(String.class)\n        .choices(\"PLAINTEXT\", \"SSL\", \"SASL_PLAINTEXT\", \"SASL_SSL\")\n        .metavar(\"SECURITY-PROTOCOL\")\n        .dest(\"securityProtocol\")\n        .help(\"Security protocol to be used while communicating with Kafka brokers.\");\n\n    parser.addArgument(\"--ssl-truststore-location\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"SSL-TRUSTSTORE-LOCATION\")\n        .dest(\"sslTruststoreLocation\")\n        .help(\"Location of SSL truststore to use.\");\n\n    parser.addArgument(\"--ssl-truststore-password\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"SSL-TRUSTSTORE-PASSWORD\")\n        .dest(\"sslTruststorePassword\")\n        .help(\"Password for SSL truststore to use.\");\n\n    parser.addArgument(\"--appender.config\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"CONFIG_FILE\")\n        .help(\"Log4jAppender config properties file.\");\n\n    parser.addArgument(\"--sasl-kerberos-service-name\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"SASL-KERBEROS-SERVICE-NAME\")\n        .dest(\"saslKerberosServiceName\")\n        .help(\"Name of sasl kerberos service.\");\n\n    parser.addArgument(\"--client-jaas-conf-path\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"CLIENT-JAAS-CONF-PATH\")\n        .dest(\"clientJaasConfPath\")\n        .help(\"Path of JAAS config file of Kafka client.\");\n\n    parser.addArgument(\"--kerb5-conf-path\")\n        .action(store())\n        .required(false)\n        .type(String.class)\n        .metavar(\"KERB5-CONF-PATH\")\n        .dest(\"kerb5ConfPath\")\n        .help(\"Path of Kerb5 config file.\");\n\n    return parser;\n}", "summary_tokens": ["get", "the", "command", "line", "argument", "parser"], "project": "kafka"}
{"id": 2387, "code": "public int numCompletedBatches() {\n    return completed.size();\n}", "summary_tokens": ["get", "the", "number", "of", "completed", "batches", "which", "are", "ready", "to", "be", "drained"], "project": "kafka"}
{"id": 2662, "code": "public Instant endTime() {\n    return endTime;\n}", "summary_tokens": ["return", "the", "end", "time", "of", "this", "window"], "project": "kafka"}
{"id": 1867, "code": "public void recordErrorLogged() {\n    errorsLogged.record();\n}", "summary_tokens": ["the", "number", "of", "errors", "logged", "by", "the", "log", "reporter"], "project": "kafka"}
{"id": 2914, "code": "public void resumeNamedTopology(final String topologyName) {\n    topologyMetadata.resumeTopology(topologyName);\n}", "summary_tokens": ["resumes", "a", "topology", "by", "name", "topology", "name", "name", "of", "the", "topology", "to", "resume"], "project": "kafka"}
{"id": 1410, "code": "public void testListenerConfigOverride(Args args) throws Exception {\n    String node = \"0\";\n    ListenerName clientListenerName = new ListenerName(\"client\");\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    args.sslServerConfigs.put(clientListenerName.configPrefix() + BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"none\");\n\n        \n    server = createEchoServer(args, SecurityProtocol.SSL);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n\n        \n    createSelector(args.sslClientConfigs);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n    selector.close();\n\n        \n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    createSelector(args.sslClientConfigs);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n    selector.close();\n    server.close();\n\n        \n    server = createEchoServer(args, clientListenerName, SecurityProtocol.SSL);\n    addr = new InetSocketAddress(\"localhost\", server.port());\n\n        \n    createSelector(args.sslClientConfigs);\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n}", "summary_tokens": ["tests", "that", "disabling", "client", "authentication", "as", "a", "listener", "override", "has", "the", "desired", "effect"], "project": "kafka"}
{"id": 293, "code": "public KafkaFuture<ListOffsetsResultInfo> partitionResult(final TopicPartition partition) {\n    KafkaFuture<ListOffsetsResultInfo> future = futures.get(partition);\n    if (future == null) {\n        throw new IllegalArgumentException(\n                \"List Offsets for partition \\\"\" + partition + \"\\\" was not attempted\");\n    }\n    return future;\n}", "summary_tokens": ["return", "a", "future", "which", "can", "be", "used", "to", "check", "the", "result", "for", "a", "given", "partition"], "project": "kafka"}
{"id": 2386, "code": "public int epoch() {\n    return epoch;\n}", "summary_tokens": ["get", "the", "leader", "epoch", "which", "is", "constant", "for", "each", "instance"], "project": "kafka"}
{"id": 1494, "code": "public void testValidSaslScramMechanisms() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"SCRAM-SHA-256\", new ArrayList<>(ScramMechanism.mechanismNames()));\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n\n    for (String mechanism : ScramMechanism.mechanismNames()) {\n        saslClientConfigs.put(SaslConfigs.SASL_MECHANISM, mechanism);\n        createAndCheckClientConnection(securityProtocol, \"node-\" + mechanism);\n    }\n}", "summary_tokens": ["tests", "all", "supported", "scram", "client", "and", "server", "channels"], "project": "kafka"}
{"id": 1460, "code": "public void testIterationDoesntChangePosition() throws IOException {\n    long position = fileRecords.channel().position();\n    Iterator<Record> records = fileRecords.records().iterator();\n    for (byte[] value : values) {\n        assertTrue(records.hasNext());\n        assertEquals(records.next().value(), ByteBuffer.wrap(value));\n    }\n    assertEquals(position, fileRecords.channel().position());\n}", "summary_tokens": ["iterating", "over", "the", "file", "does", "file", "reads", "but", "shouldn", "t", "change", "the", "position", "of", "the", "underlying", "file", "channel"], "project": "kafka"}
{"id": 3018, "code": "public static KeyValueBytesStoreSupplier lruMap(final String name, final int maxCacheSize) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    if (maxCacheSize < 0) {\n        throw new IllegalArgumentException(\"maxCacheSize cannot be negative\");\n    }\n    return new KeyValueBytesStoreSupplier() {\n        @Override\n        public String name() {\n            return name;\n        }\n\n        @Override\n        public KeyValueStore<Bytes, byte[]> get() {\n            return new MemoryNavigableLRUCache(name, maxCacheSize);\n        }\n\n        @Override\n        public String metricsScope() {\n            return \"in-memory-lru\";\n        }\n    };\n}", "summary_tokens": ["create", "a", "lru", "map", "key", "value", "bytes", "store", "supplier"], "project": "kafka"}
{"id": 644, "code": "private boolean maybeSendAndPollTransactionalRequest() {\n    if (transactionManager.hasInFlightRequest()) {\n            \n        client.poll(retryBackoffMs, time.milliseconds());\n        return true;\n    }\n\n    if (transactionManager.hasAbortableError() || transactionManager.isAborting()) {\n        if (accumulator.hasIncomplete()) {\n                \n            RuntimeException exception = transactionManager.lastError();\n                \n                \n            if (exception == null) {\n                exception = new TransactionAbortedException();\n            }\n            accumulator.abortUndrainedBatches(exception);\n        }\n    }\n\n    TransactionManager.TxnRequestHandler nextRequestHandler = transactionManager.nextRequest(accumulator.hasIncomplete());\n    if (nextRequestHandler == null)\n        return false;\n\n    AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n    Node targetNode = null;\n    try {\n        FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n        targetNode = coordinatorType != null ?\n                transactionManager.coordinator(coordinatorType) :\n                client.leastLoadedNode(time.milliseconds());\n        if (targetNode != null) {\n            if (!awaitNodeReady(targetNode, coordinatorType)) {\n                log.trace(\"Target node {} not ready within request timeout, will retry when node is ready.\", targetNode);\n                maybeFindCoordinatorAndRetry(nextRequestHandler);\n                return true;\n            }\n        } else if (coordinatorType != null) {\n            log.trace(\"Coordinator not known for {}, will retry {} after finding coordinator.\", coordinatorType, requestBuilder.apiKey());\n            maybeFindCoordinatorAndRetry(nextRequestHandler);\n            return true;\n        } else {\n            log.trace(\"No nodes available to send requests, will poll and retry when until a node is ready.\");\n            transactionManager.retry(nextRequestHandler);\n            client.poll(retryBackoffMs, time.milliseconds());\n            return true;\n        }\n\n        if (nextRequestHandler.isRetry())\n            time.sleep(nextRequestHandler.retryBackoffMs());\n\n        long currentTimeMs = time.milliseconds();\n        ClientRequest clientRequest = client.newClientRequest(targetNode.idString(), requestBuilder, currentTimeMs,\n            true, requestTimeoutMs, nextRequestHandler);\n        log.debug(\"Sending transactional request {} to node {} with correlation ID {}\", requestBuilder, targetNode, clientRequest.correlationId());\n        client.send(clientRequest, currentTimeMs);\n        transactionManager.setInFlightCorrelationId(clientRequest.correlationId());\n        client.poll(retryBackoffMs, time.milliseconds());\n        return true;\n    } catch (IOException e) {\n        log.debug(\"Disconnect from {} while trying to send request {}. Going \" +\n                \"to back off and retry.\", targetNode, requestBuilder, e);\n            \n        maybeFindCoordinatorAndRetry(nextRequestHandler);\n        return true;\n    }\n}", "summary_tokens": ["returns", "true", "if", "a", "transactional", "request", "is", "sent", "or", "polled", "or", "if", "a", "find", "coordinator", "request", "is", "enqueued"], "project": "kafka"}
{"id": 692, "code": "public static TopicIdCollection ofTopicIds(Collection<Uuid> topics) {\n    return new TopicIdCollection(topics);\n}", "summary_tokens": ["a", "collection", "of", "topics", "defined", "by", "topic", "id"], "project": "kafka"}
{"id": 2922, "code": "public String name() {\n    return internalTopologyBuilder.topologyName();\n}", "summary_tokens": ["the", "name", "of", "this", "topology"], "project": "kafka"}
{"id": 1152, "code": "public boolean isClaimType(String claimName, Class<?> type) {\n    Object value = rawClaim(claimName);\n    Objects.requireNonNull(type);\n    if (value == null)\n        return false;\n    if (type == String.class && value instanceof String)\n        return true;\n    if (type == Number.class && value instanceof Number)\n        return true;\n    return type == List.class && value instanceof List;\n}", "summary_tokens": ["indicate", "if", "the", "claim", "exists", "and", "is", "the", "given", "type"], "project": "kafka"}
{"id": 156, "code": "public AlterConfigsOptions validateOnly(boolean validateOnly) {\n    this.validateOnly = validateOnly;\n    return this;\n}", "summary_tokens": ["set", "to", "true", "if", "the", "request", "should", "be", "validated", "without", "altering", "the", "configs"], "project": "kafka"}
{"id": 1713, "code": "public Map<String, Object> adminConfig() {\n    return clientConfig(ADMIN_CLIENT_PREFIX);\n}", "summary_tokens": ["sub", "config", "for", "admin", "clients"], "project": "kafka"}
{"id": 1470, "code": "public void testPreallocateClearShutdown() throws IOException {\n    File temp = tempFile();\n    FileRecords fileRecords = FileRecords.open(temp, false, 1024 * 1024, true);\n    append(fileRecords, values);\n\n    int oldPosition = (int) fileRecords.channel().position();\n    int oldSize = fileRecords.sizeInBytes();\n    assertEquals(this.fileRecords.sizeInBytes(), oldPosition);\n    assertEquals(this.fileRecords.sizeInBytes(), oldSize);\n    fileRecords.close();\n\n    File tempReopen = new File(temp.getAbsolutePath());\n    FileRecords setReopen = FileRecords.open(tempReopen, true, 1024 * 1024, true);\n    int position = (int) setReopen.channel().position();\n    int size = setReopen.sizeInBytes();\n\n    assertEquals(oldPosition, position);\n    assertEquals(oldPosition, size);\n    assertEquals(oldPosition, tempReopen.length());\n}", "summary_tokens": ["test", "the", "new", "file", "records", "with", "pre", "allocate", "as", "true", "and", "file", "has", "been", "clearly", "shut", "down", "the", "file", "will", "be", "truncate", "to", "end", "of", "valid", "data"], "project": "kafka"}
{"id": 2793, "code": "public synchronized void cleanRemovedTasks(final long cleanupDelayMs) {\n    try {\n        cleanRemovedTasksCalledByCleanerThread(cleanupDelayMs);\n    } catch (final Exception cannotHappen) {\n        throw new IllegalStateException(\"Should have swallowed exception.\", cannotHappen);\n    }\n}", "summary_tokens": ["remove", "the", "directories", "for", "any", "task", "id", "s", "that", "are", "no", "longer", "owned", "by", "this", "stream", "thread", "and", "aren", "t", "locked", "by", "either", "another", "process", "or", "another", "stream", "thread", "cleanup", "delay", "ms", "only", "remove", "directories", "if", "they", "haven", "t", "been", "modified", "for", "at", "least", "this", "amount", "of", "time", "milliseconds"], "project": "kafka"}
{"id": 1646, "code": "public static BigDecimal convertToDecimal(Schema schema, Object value, int scale) {\n    return (BigDecimal) convertTo(Decimal.schema(scale), schema, value);\n}", "summary_tokens": ["convert", "the", "specified", "value", "to", "an", "decimal", "decimal", "value"], "project": "kafka"}
{"id": 1184, "code": "public static Long validateIssuedAt(String claimName, Long claimValue) throws ValidateException {\n    if (claimValue != null && claimValue < 0)\n        throw new ValidateException(String.format(\"%s value must be null or non-negative; value given was \\\"%s\\\"\", claimName, claimValue));\n\n    return claimValue;\n}", "summary_tokens": ["validates", "that", "the", "given", "issued", "at", "claim", "name", "is", "valid", "where", "i", "invalid", "i", "means", "i", "any", "i", "of", "the", "following"], "project": "kafka"}
{"id": 1820, "code": "public static WorkerState deserializeMetadata(ByteBuffer buffer) {\n    Struct header = CONNECT_PROTOCOL_HEADER_SCHEMA.read(buffer);\n    Short version = header.getShort(VERSION_KEY_NAME);\n    checkVersionCompatibility(version);\n    Struct struct = CONFIG_STATE_V0.read(buffer);\n    long configOffset = struct.getLong(CONFIG_OFFSET_KEY_NAME);\n    String url = struct.getString(URL_KEY_NAME);\n    return new WorkerState(url, configOffset);\n}", "summary_tokens": ["given", "a", "byte", "buffer", "that", "contains", "protocol", "metadata", "return", "the", "deserialized", "form", "of", "the", "metadata"], "project": "kafka"}
{"id": 928, "code": "public Struct instance(String field) {\n    return instance(schema.get(field));\n}", "summary_tokens": ["create", "a", "struct", "instance", "for", "the", "given", "field", "which", "must", "be", "a", "container", "type", "struct", "or", "array"], "project": "kafka"}
{"id": 650, "code": "private boolean canRetry(ProducerBatch batch, ProduceResponse.PartitionResponse response, long now) {\n    return !batch.hasReachedDeliveryTimeout(accumulator.getDeliveryTimeoutMs(), now) &&\n        batch.attempts() < this.retries &&\n        !batch.isDone() &&\n        (transactionManager == null ?\n                response.error.exception() instanceof RetriableException :\n                transactionManager.canRetry(response, batch));\n}", "summary_tokens": ["we", "can", "retry", "a", "send", "if", "the", "error", "is", "transient", "and", "the", "number", "of", "attempts", "taken", "is", "fewer", "than", "the", "maximum", "allowed"], "project": "kafka"}
{"id": 131, "code": "default ListConsumerGroupOffsetsResult listConsumerGroupOffsets(Map<String, ListConsumerGroupOffsetsSpec> groupSpecs) {\n    return listConsumerGroupOffsets(groupSpecs, new ListConsumerGroupOffsetsOptions());\n}", "summary_tokens": ["list", "the", "consumer", "group", "offsets", "available", "in", "the", "cluster", "for", "the", "specified", "groups", "with", "the", "default", "options"], "project": "kafka"}
{"id": 3211, "code": "public static VerifiableProducer createFromArgs(ArgumentParser parser, String[] args) throws ArgumentParserException {\n    Namespace res = parser.parseArgs(args);\n\n    int maxMessages = res.getInt(\"maxMessages\");\n    String topic = res.getString(\"topic\");\n    int throughput = res.getInt(\"throughput\");\n    String configFile = res.getString(\"producer.config\");\n    Integer valuePrefix = res.getInt(\"valuePrefix\");\n    Long createTime = res.getLong(\"createTime\");\n    Integer repeatingKeys = res.getInt(\"repeatingKeys\");\n\n    if (createTime == -1L)\n        createTime = null;\n\n    Properties producerProps = new Properties();\n\n    if (res.get(\"bootstrapServer\") != null) {\n        producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, res.getString(\"bootstrapServer\"));\n    } else if (res.getString(\"brokerList\") != null) {\n        producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, res.getString(\"brokerList\"));\n    } else {\n        parser.printHelp();\n            \n        System.exit(0);\n    }\n\n    producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n            \"org.apache.kafka.common.serialization.StringSerializer\");\n    producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n            \"org.apache.kafka.common.serialization.StringSerializer\");\n    producerProps.put(ProducerConfig.ACKS_CONFIG, Integer.toString(res.getInt(\"acks\")));\n        \n    producerProps.put(ProducerConfig.RETRIES_CONFIG, \"0\");\n    if (configFile != null) {\n        try {\n            producerProps.putAll(loadProps(configFile));\n        } catch (IOException e) {\n            throw new ArgumentParserException(e.getMessage(), parser);\n        }\n    }\n\n    StringSerializer serializer = new StringSerializer();\n    KafkaProducer<String, String> producer = new KafkaProducer<>(producerProps, serializer, serializer);\n\n    return new VerifiableProducer(producer, topic, throughput, maxMessages, valuePrefix, createTime, repeatingKeys);\n}", "summary_tokens": ["construct", "a", "verifiable", "producer", "object", "from", "command", "line", "arguments"], "project": "kafka"}
{"id": 2285, "code": "public AuthorizationResult authorize(\n    AuthorizableRequestContext requestContext,\n    Action action\n) {\n    KafkaPrincipal principal = baseKafkaPrincipal(requestContext);\n    final MatchingRule rule;\n\n        \n    if (superUsers.contains(principal.toString())) {\n        rule = SuperUserRule.INSTANCE;\n    } else if (!loadingComplete) {\n        throw new AuthorizerNotReadyException();\n    } else {\n        MatchingAclRule aclRule = findAclRule(\n            matchingPrincipals(requestContext),\n            requestContext.clientAddress().getHostAddress(),\n            action\n        );\n\n        if (aclRule != null) {\n            rule = aclRule;\n        } else {\n                \n            rule = defaultRule;\n        }\n    }\n\n    logAuditMessage(principal, requestContext, action, rule);\n    return rule.result();\n}", "summary_tokens": ["authorize", "an", "action", "based", "on", "the", "current", "set", "of", "acls"], "project": "kafka"}
{"id": 1507, "code": "public void testSaslHandshakeRequestWithUnsupportedVersion() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    SaslHandshakeRequest request = buildSaslHandshakeRequest(\"PLAIN\", ApiKeys.SASL_HANDSHAKE.latestVersion());\n    RequestHeader header = new RequestHeader(ApiKeys.SASL_HANDSHAKE, Short.MAX_VALUE, \"someclient\", 2);\n        \n    selector.send(new NetworkSend(node1, request.toSend(header)));\n        \n        \n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n}", "summary_tokens": ["tests", "that", "unsupported", "version", "of", "sasl", "handshake", "request", "returns", "error", "response", "and", "fails", "authentication"], "project": "kafka"}
{"id": 2419, "code": "public void testHandleFault() {\n    AtomicInteger counter = new AtomicInteger(0);\n    LoggingFaultHandler handler = new LoggingFaultHandler(\"test\", () -> {\n        counter.incrementAndGet();\n    });\n    handler.handleFault(\"uh oh\");\n    assertEquals(1, counter.get());\n    handler.handleFault(\"uh oh\", new RuntimeException(\"yikes\"));\n    assertEquals(2, counter.get());\n}", "summary_tokens": ["test", "handling", "faults", "with", "and", "without", "exceptions"], "project": "kafka"}
{"id": 137, "code": "default AlterConsumerGroupOffsetsResult alterConsumerGroupOffsets(String groupId, Map<TopicPartition, OffsetAndMetadata> offsets) {\n    return alterConsumerGroupOffsets(groupId, offsets, new AlterConsumerGroupOffsetsOptions());\n}", "summary_tokens": ["p", "alters", "offsets", "for", "the", "specified", "group"], "project": "kafka"}
{"id": 1403, "code": "public void testValidEndpointIdentificationSanIp(Args args) throws Exception {\n    String node = \"0\";\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).hostAddress(InetAddress.getByName(\"127.0.0.1\")).build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).hostAddress(InetAddress.getByName(\"127.0.0.1\")).build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    createSelector(args.sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"127.0.0.1\", server.port());\n    selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.checkClientConnection(selector, node, 100, 10);\n}", "summary_tokens": ["tests", "that", "server", "certificate", "with", "subject", "alt", "name", "containing", "valid", "ip", "address", "is", "accepted", "by", "a", "client", "that", "connects", "using", "ip", "address", "and", "validates", "server", "endpoint"], "project": "kafka"}
{"id": 198, "code": "public boolean shouldValidateOnly() {\n    return validateOnly;\n}", "summary_tokens": ["return", "true", "if", "the", "request", "should", "be", "validated", "without", "creating", "the", "topic"], "project": "kafka"}
{"id": 2180, "code": "String fieldDefault(HeaderGenerator headerGenerator,\n                    StructRegistry structRegistry) {\n    if (type instanceof FieldType.BoolFieldType) {\n        if (fieldDefault.isEmpty()) {\n            return \"false\";\n        } else if (fieldDefault.equalsIgnoreCase(\"true\")) {\n            return \"true\";\n        } else if (fieldDefault.equalsIgnoreCase(\"false\")) {\n            return \"false\";\n        } else {\n            throw new RuntimeException(\"Invalid default for boolean field \" +\n                name + \": \" + fieldDefault);\n        }\n    } else if ((type instanceof FieldType.Int8FieldType) ||\n        (type instanceof FieldType.Int16FieldType) ||\n        (type instanceof FieldType.Uint16FieldType) ||\n        (type instanceof FieldType.Uint32FieldType) ||\n        (type instanceof FieldType.Int32FieldType) ||\n        (type instanceof FieldType.Int64FieldType)) {\n        int base = 10;\n        String defaultString = fieldDefault;\n        if (defaultString.startsWith(\"0x\")) {\n            base = 16;\n            defaultString = defaultString.substring(2);\n        }\n        if (type instanceof FieldType.Int8FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"(byte) 0\";\n            } else {\n                try {\n                    Byte.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int8 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return \"(byte) \" + fieldDefault;\n            }\n        } else if (type instanceof FieldType.Int16FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"(short) 0\";\n            } else {\n                try {\n                    Short.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int16 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return \"(short) \" + fieldDefault;\n            }\n        } else if (type instanceof FieldType.Uint16FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0\";\n            } else {\n                try {\n                    int value = Integer.valueOf(defaultString, base);\n                    if (value < 0 || value > MessageGenerator.UNSIGNED_SHORT_MAX) {\n                        throw new RuntimeException(\"Invalid default for uint16 field \" +\n                                name + \": out of range.\");\n                    }\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for uint16 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return fieldDefault;\n            }\n        } else if (type instanceof FieldType.Uint32FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0\";\n            } else {\n                try {\n                    long value = Long.valueOf(defaultString, base);\n                    if (value < 0 || value > MessageGenerator.UNSIGNED_INT_MAX) {\n                        throw new RuntimeException(\"Invalid default for uint32 field \" +\n                                name + \": out of range.\");\n                    }\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for uint32 field \" +\n                            name + \": \" + defaultString, e);\n                }\n                return fieldDefault;\n            }\n        } else if (type instanceof FieldType.Int32FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0\";\n            } else {\n                try {\n                    Integer.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int32 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return fieldDefault;\n            }\n        } else if (type instanceof FieldType.Int64FieldType) {\n            if (defaultString.isEmpty()) {\n                return \"0L\";\n            } else {\n                try {\n                    Long.valueOf(defaultString, base);\n                } catch (NumberFormatException e) {\n                    throw new RuntimeException(\"Invalid default for int64 field \" +\n                        name + \": \" + defaultString, e);\n                }\n                return fieldDefault + \"L\";\n            }\n        } else {\n            throw new RuntimeException(\"Unsupported field type \" + type);\n        }\n    } else if (type instanceof FieldType.UUIDFieldType) {\n        headerGenerator.addImport(MessageGenerator.UUID_CLASS);\n        if (fieldDefault.isEmpty()) {\n            return \"Uuid.ZERO_UUID\";\n        } else {\n            try {\n                ByteBuffer uuidBytes = ByteBuffer.wrap(Base64.getUrlDecoder().decode(fieldDefault));\n                uuidBytes.getLong();\n                uuidBytes.getLong();\n            } catch (IllegalArgumentException e) {\n                throw new RuntimeException(\"Invalid default for uuid field \" +\n                    name + \": \" + fieldDefault, e);\n            }\n            headerGenerator.addImport(MessageGenerator.UUID_CLASS);\n            return \"Uuid.fromString(\\\"\" + fieldDefault + \"\\\")\";\n        }\n    } else if (type instanceof FieldType.Float64FieldType) {\n        if (fieldDefault.isEmpty()) {\n            return \"0.0\";\n        } else {\n            try {\n                Double.parseDouble(fieldDefault);\n            } catch (NumberFormatException e) {\n                throw new RuntimeException(\"Invalid default for float64 field \" +\n                    name + \": \" + fieldDefault, e);\n            }\n            return \"Double.parseDouble(\\\"\" + fieldDefault + \"\\\")\";\n        }\n    } else if (type instanceof FieldType.StringFieldType) {\n        if (fieldDefault.equals(\"null\")) {\n            validateNullDefault();\n            return \"null\";\n        } else {\n            return \"\\\"\" + fieldDefault + \"\\\"\";\n        }\n    } else if (type.isBytes()) {\n        if (fieldDefault.equals(\"null\")) {\n            validateNullDefault();\n            return \"null\";\n        } else if (!fieldDefault.isEmpty()) {\n            throw new RuntimeException(\"Invalid default for bytes field \" +\n                name + \".  The only valid default for a bytes field \" +\n                \"is empty or null.\");\n        }\n        if (zeroCopy) {\n            headerGenerator.addImport(MessageGenerator.BYTE_UTILS_CLASS);\n            return \"ByteUtils.EMPTY_BUF\";\n        } else {\n            headerGenerator.addImport(MessageGenerator.BYTES_CLASS);\n            return \"Bytes.EMPTY\";\n        }\n    } else if (type.isRecords()) {\n        return \"null\";\n    } else if (type.isStruct()) {\n        if (!fieldDefault.isEmpty()) {\n            throw new RuntimeException(\"Invalid default for struct field \" +\n                name + \": custom defaults are not supported for struct fields.\");\n        }\n        return \"new \" + type.toString() + \"()\";\n    } else if (type.isArray()) {\n        if (fieldDefault.equals(\"null\")) {\n            validateNullDefault();\n            return \"null\";\n        } else if (!fieldDefault.isEmpty()) {\n            throw new RuntimeException(\"Invalid default for array field \" +\n                name + \".  The only valid default for an array field \" +\n                \"is the empty array or null.\");\n        }\n        return String.format(\"new %s(0)\",\n            concreteJavaType(headerGenerator, structRegistry));\n    } else {\n        throw new RuntimeException(\"Unsupported field type \" + type);\n    }\n}", "summary_tokens": ["get", "a", "string", "representation", "of", "the", "field", "default"], "project": "kafka"}
{"id": 1831, "code": "private boolean refreshConfigSnapshot(long timeoutMs) {\n    try {\n        configBackingStore.refresh(timeoutMs, TimeUnit.MILLISECONDS);\n        configState = configBackingStore.snapshot();\n        log.info(\"Finished reading to end of log and updated config snapshot, new config log offset: {}\", configState.offset());\n        return true;\n    } catch (TimeoutException e) {\n        log.warn(\"Didn't reach end of config log quickly enough\", e);\n        canReadConfigs = false;\n        return false;\n    }\n}", "summary_tokens": ["try", "to", "read", "to", "the", "end", "of", "the", "config", "log", "within", "the", "given", "timeout", "timeout", "ms", "maximum", "time", "to", "wait", "to", "sync", "to", "the", "end", "of", "the", "log", "true", "if", "successful", "false", "if", "timed", "out"], "project": "kafka"}
{"id": 2999, "code": "default KeyValueIterator<Windowed<K>, AGG> backwardFetch(final K keyFrom, final K keyTo) {\n    throw new UnsupportedOperationException(\n        \"This API is not supported by this implementation of ReadOnlySessionStore.\");\n}", "summary_tokens": ["retrieve", "all", "aggregated", "sessions", "for", "the", "given", "range", "of", "keys"], "project": "kafka"}
{"id": 3110, "code": "private Properties effectiveConfigFrom(final Properties initialConfig) {\n    final Properties effectiveConfig = new Properties();\n    effectiveConfig.put(KafkaConfig.BrokerIdProp(), 0);\n    effectiveConfig.put(KafkaConfig.NumPartitionsProp(), 1);\n    effectiveConfig.put(KafkaConfig.AutoCreateTopicsEnableProp(), true);\n    effectiveConfig.put(KafkaConfig.MessageMaxBytesProp(), 1000000);\n    effectiveConfig.put(KafkaConfig.ControlledShutdownEnableProp(), true);\n    effectiveConfig.put(KafkaConfig.ZkSessionTimeoutMsProp(), 10000);\n\n    effectiveConfig.putAll(initialConfig);\n    effectiveConfig.setProperty(KafkaConfig.LogDirProp(), logDir.getAbsolutePath());\n    return effectiveConfig;\n}", "summary_tokens": ["creates", "the", "configuration", "for", "starting", "the", "kafka", "broker", "by", "merging", "default", "values", "with", "overwrites"], "project": "kafka"}
{"id": 2549, "code": "private boolean isTopologyOverride(final String config, final Properties topologyOverrides) {\n        \n        \n    return topologyName != null && topologyOverrides.containsKey(config);\n}", "summary_tokens": ["true", "if", "there", "is", "an", "override", "for", "this", "config", "in", "the", "properties", "of", "this", "named", "topology"], "project": "kafka"}
{"id": 2120, "code": "public void resetConnectorTopics(String connectorName) {\n    String url = endpointForResource(String.format(\"connectors/%s/topics/reset\", connectorName));\n    Response response = requestPut(url, null);\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n                \"Resetting active topics for connector \" + connectorName + \" failed. \"\n                + \"Error response: \" + responseToString(response));\n    }\n}", "summary_tokens": ["reset", "the", "set", "of", "active", "topics", "of", "a", "connector", "running", "in", "this", "cluster"], "project": "kafka"}
{"id": 1360, "code": "public void testBatchExpirationAfterReenqueue() {\n    ProducerBatch batch = new ProducerBatch(new TopicPartition(\"topic\", 1), memoryRecordsBuilder, now);\n        \n    batch.reenqueued(now);\n        \n    assertFalse(batch.hasReachedDeliveryTimeout(10240, now - 2L));\n}", "summary_tokens": ["a", "producer", "batch", "configured", "using", "a", "timestamp", "preceding", "its", "create", "time", "is", "interpreted", "correctly", "as", "not", "expired", "by", "producer", "batch", "has", "reached", "delivery", "timeout", "long", "long"], "project": "kafka"}
{"id": 1416, "code": "public void testClientAuthenticationRequestedNotProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"requested\");\n\n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    verifySslConfigs(args);\n}", "summary_tokens": ["tests", "that", "server", "accepts", "connections", "from", "a", "client", "that", "does", "not", "provide", "a", "certificate", "if", "client", "authentication", "is", "requested", "but", "not", "required"], "project": "kafka"}
{"id": 1407, "code": "public void testInvalidEndpointIdentification(Args args) throws Exception {\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).addHostName(\"notahost\").build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).addHostName(\"localhost\").build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    args.sslClientConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    verifySslConfigsWithHandshakeFailure(args);\n}", "summary_tokens": ["tests", "that", "server", "certificate", "with", "invalid", "host", "name", "is", "not", "accepted", "by", "a", "client", "that", "validates", "server", "endpoint"], "project": "kafka"}
{"id": 1486, "code": "public void testInvalidPasswordSaslPlain() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", TestJaasConfig.USERNAME, \"invalidpassword\");\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"PLAIN\",\n            \"Authentication failed: Invalid username or password\");\n    server.verifyAuthenticationMetrics(0, 1);\n    server.verifyReauthenticationMetrics(0, 0);\n}", "summary_tokens": ["tests", "that", "sasl", "plain", "clients", "with", "invalid", "password", "fail", "authentication"], "project": "kafka"}
{"id": 1888, "code": "public synchronized void consumerRecord(ConsumerRecord<byte[], byte[]> consumedMessage) {\n    this.context.consumerRecord(consumedMessage);\n}", "summary_tokens": ["set", "the", "record", "consumed", "from", "kafka", "in", "a", "sink", "connector"], "project": "kafka"}
{"id": 581, "code": "public int poolableSize() {\n    return this.poolableSize;\n}", "summary_tokens": ["the", "buffer", "size", "that", "will", "be", "retained", "in", "the", "free", "list", "after", "use"], "project": "kafka"}
{"id": 1075, "code": "public ResourceType resourceType() {\n    return resourceType;\n}", "summary_tokens": ["the", "specific", "resource", "type", "this", "pattern", "matches"], "project": "kafka"}
{"id": 2810, "code": "public boolean isProcessable(final long wallClockTime) {\n    if (state() == State.CLOSED) {\n            \n            \n            \n        log.info(\"Stream task {} is already in {} state, skip processing it.\", id(), state());\n\n        return false;\n    }\n\n    if (hasPendingTxCommit) {\n            \n            \n        return false;\n    }\n    final boolean readyToProcess = partitionGroup.readyToProcess(wallClockTime);\n    if (!readyToProcess) {\n        if (!timeCurrentIdlingStarted.isPresent()) {\n            timeCurrentIdlingStarted = Optional.of(wallClockTime);\n        }\n    } else {\n        timeCurrentIdlingStarted = Optional.empty();\n    }\n    return readyToProcess;\n}", "summary_tokens": ["an", "active", "task", "is", "processable", "if", "its", "buffer", "contains", "data", "for", "all", "of", "its", "input", "source", "topic", "partitions", "or", "if", "it", "is", "enforced", "to", "be", "processable"], "project": "kafka"}
{"id": 1369, "code": "public void testNodeNotReady() {\n    final long producerId = 123456L;\n    time = new MockTime(10);\n    client = new MockClient(time, metadata);\n\n    TransactionManager transactionManager = new TransactionManager(new LogContext(), \"testNodeNotReady\",\n            60000, 100L, new ApiVersions());\n    setupWithTransactionState(transactionManager, false, null, true);\n    ProducerIdAndEpoch producerIdAndEpoch = new ProducerIdAndEpoch(producerId, (short) 0);\n    transactionManager.initializeTransactions();\n    sender.runOnce();\n\n    Node node = metadata.fetch().nodes().get(0);\n    client.delayReady(node, REQUEST_TIMEOUT + 20);\n    prepareFindCoordinatorResponse(Errors.NONE, \"testNodeNotReady\");\n    sender.runOnce();\n    sender.runOnce();\n    assertNotNull(transactionManager.coordinator(CoordinatorType.TRANSACTION), \"Coordinator not found\");\n\n    client.throttle(node, REQUEST_TIMEOUT + 20);\n    prepareFindCoordinatorResponse(Errors.NONE, \"Coordinator not found\");\n    prepareInitProducerResponse(Errors.NONE, producerIdAndEpoch.producerId, producerIdAndEpoch.epoch);\n    waitForProducerId(transactionManager, producerIdAndEpoch);\n}", "summary_tokens": ["tests", "the", "code", "path", "where", "the", "target", "node", "to", "send", "find", "coordinator", "or", "init", "producer", "id", "is", "not", "ready"], "project": "kafka"}
{"id": 426, "code": "public Map<TopicPartition, Long> offsetOutOfRangePartitions() {\n    return offsetOutOfRangePartitions;\n}", "summary_tokens": ["get", "a", "map", "of", "the", "topic", "partitions", "and", "the", "respective", "out", "of", "range", "fetch", "offsets"], "project": "kafka"}
{"id": 1272, "code": "private boolean removeElementAtSlot(int slot) {\n    size--;\n    removeFromList(head, elements, slot);\n    slot = (slot + 1) % elements.length;\n\n        \n    int endSlot = slot;\n    for (int seen = 0; seen < elements.length; seen++) {\n        Element element = elements[endSlot];\n        if (element == null) {\n            break;\n        }\n        endSlot = (endSlot + 1) % elements.length;\n    }\n\n        \n        \n        \n        \n    while (slot != endSlot) {\n        reseat(slot);\n        slot = (slot + 1) % elements.length;\n    }\n    return true;\n}", "summary_tokens": ["remove", "an", "element", "in", "a", "particular", "slot"], "project": "kafka"}
{"id": 3093, "code": "public static <K, V> void produceKeyValuesSynchronouslyWithTimestamp(final String topic,\n                                                                     final Collection<KeyValue<K, V>> records,\n                                                                     final Properties producerConfig,\n                                                                     final Headers headers,\n                                                                     final Long timestamp,\n                                                                     final boolean enableTransactions) {\n    try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {\n        if (enableTransactions) {\n            producer.initTransactions();\n            producer.beginTransaction();\n        }\n        for (final KeyValue<K, V> record : records) {\n            producer.send(new ProducerRecord<>(topic, null, timestamp, record.key, record.value, headers));\n        }\n        if (enableTransactions) {\n            producer.commitTransaction();\n        }\n    }\n}", "summary_tokens": ["topic", "kafka", "topic", "to", "write", "the", "data", "records", "to", "records", "data", "records", "to", "write", "to", "kafka", "producer", "config", "kafka", "producer", "configuration", "headers", "headers", "of", "the", "data", "records", "timestamp", "timestamp", "of", "the", "record", "enable", "transactions", "send", "messages", "in", "a", "transaction", "k", "key", "type", "of", "the", "data", "records", "v", "value", "type", "of", "the", "data", "records"], "project": "kafka"}
{"id": 3049, "code": "static void writeEntry(final BufferedWriter writer,\n                       final TopicPartition part,\n                       final long offset) throws IOException {\n    writer.write(part.topic());\n    writer.write(' ');\n    writer.write(Integer.toString(part.partition()));\n    writer.write(' ');\n    writer.write(Long.toString(offset));\n    writer.newLine();\n}", "summary_tokens": ["ioexception", "if", "file", "write", "operations", "failed", "with", "any", "io", "exception"], "project": "kafka"}
{"id": 2511, "code": "public StoreQueryParameters<T> withPartition(final Integer partition) {\n    return new StoreQueryParameters<>(storeName, queryableStoreType, partition, staleStores);\n}", "summary_tokens": ["set", "a", "specific", "partition", "that", "should", "be", "queried", "exclusively"], "project": "kafka"}
{"id": 74, "code": "protected MetadataRequest.Builder newMetadataRequestBuilderForNewTopics() {\n    return null;\n}", "summary_tokens": ["constructs", "and", "returns", "a", "metadata", "request", "builder", "for", "fetching", "cluster", "data", "and", "any", "uncached", "topics", "otherwise", "null", "if", "the", "functionality", "is", "not", "supported"], "project": "kafka"}
{"id": 527, "code": "public synchronized List<TopicPartition> assignedPartitionsList() {\n    return new ArrayList<>(this.assignment.partitionSet());\n}", "summary_tokens": ["a", "modifiable", "copy", "of", "the", "currently", "assigned", "partitions", "as", "a", "list"], "project": "kafka"}
{"id": 846, "code": "public double frequency(MetricConfig config, long now, double centerValue) {\n    purgeObsoleteSamples(config, now);\n    long totalCount = 0;\n    for (Sample sample : samples) {\n        totalCount += sample.eventCount;\n    }\n    if (totalCount == 0) {\n        return 0.0d;\n    }\n        \n    float count = 0.0f;\n    int binNum = binScheme.toBin(centerValue);\n    for (Sample s : samples) {\n        HistogramSample sample = (HistogramSample) s;\n        float[] hist = sample.histogram.counts();\n        count += hist[binNum];\n    }\n        \n    return count / (double) totalCount;\n}", "summary_tokens": ["return", "the", "computed", "frequency", "describing", "the", "number", "of", "occurrences", "of", "the", "values", "in", "the", "bucket", "for", "the", "given", "center", "point", "relative", "to", "the", "total", "number", "of", "occurrences", "in", "the", "samples"], "project": "kafka"}
{"id": 986, "code": "public long checksum() {\n    return ByteUtils.readUnsignedInt(buffer, CRC_OFFSET);\n}", "summary_tokens": ["retrieve", "the", "previously", "computed", "crc", "for", "this", "record"], "project": "kafka"}
{"id": 946, "code": "public boolean strict() {\n    return this.strict;\n}", "summary_tokens": ["whether", "the", "filter", "is", "strict", "i"], "project": "kafka"}
{"id": 2247, "code": "private Errors validateAlterPartitionData(\n    int brokerId,\n    TopicControlInfo topic,\n    int partitionId,\n    PartitionRegistration partition,\n    short requestApiVersion,\n    AlterPartitionRequestData.PartitionData partitionData\n) {\n    if (partition == null) {\n        log.info(\"Rejecting AlterPartition request for unknown partition {}-{}.\",\n                topic.name, partitionId);\n\n        return UNKNOWN_TOPIC_OR_PARTITION;\n    }\n\n        \n        \n        \n    if (partitionData.leaderEpoch() > partition.leaderEpoch) {\n        log.debug(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current leader epoch is {}, which is greater than the local value {}.\",\n            brokerId, topic.name, partitionId, partition.leaderEpoch, partitionData.leaderEpoch());\n        return NOT_CONTROLLER;\n    }\n    if (partitionData.partitionEpoch() > partition.partitionEpoch) {\n        log.debug(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current partition epoch is {}, which is greater than the local value {}.\",\n            brokerId, topic.name, partitionId, partition.partitionEpoch, partitionData.partitionEpoch());\n        return NOT_CONTROLLER;\n    }\n    if (partitionData.leaderEpoch() < partition.leaderEpoch) {\n        log.debug(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current leader epoch is {}, not {}.\", brokerId, topic.name,\n                partitionId, partition.leaderEpoch, partitionData.leaderEpoch());\n\n        return FENCED_LEADER_EPOCH;\n    }\n    if (brokerId != partition.leader) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current leader is {}.\", brokerId, topic.name,\n                partitionId, partition.leader);\n\n        return INVALID_REQUEST;\n    }\n    if (partitionData.partitionEpoch() < partition.partitionEpoch) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the current partition epoch is {}, not {}.\", brokerId,\n                topic.name, partitionId, partition.partitionEpoch,\n                partitionData.partitionEpoch());\n\n        return INVALID_UPDATE_VERSION;\n    }\n    int[] newIsr = Replicas.toArray(partitionData.newIsr());\n    if (!Replicas.validateIsr(partition.replicas, newIsr)) {\n        log.error(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"it specified an invalid ISR {}.\", brokerId,\n                topic.name, partitionId, partitionData.newIsr());\n\n        return INVALID_REQUEST;\n    }\n    if (!Replicas.contains(newIsr, partition.leader)) {\n            \n        log.error(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"it specified an invalid ISR {} that doesn't include itself.\",\n                brokerId, topic.name, partitionId, partitionData.newIsr());\n\n        return INVALID_REQUEST;\n    }\n    LeaderRecoveryState leaderRecoveryState = LeaderRecoveryState.of(partitionData.leaderRecoveryState());\n    if (leaderRecoveryState == LeaderRecoveryState.RECOVERING && newIsr.length > 1) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the ISR {} had more than one replica while the leader was still \" +\n                \"recovering from an unclean leader election {}.\",\n                brokerId, topic.name, partitionId, partitionData.newIsr(),\n                leaderRecoveryState);\n\n        return INVALID_REQUEST;\n    }\n    if (partition.leaderRecoveryState == LeaderRecoveryState.RECOVERED &&\n            leaderRecoveryState == LeaderRecoveryState.RECOVERING) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"the leader recovery state cannot change from RECOVERED to RECOVERING.\",\n                brokerId, topic.name, partitionId);\n\n        return INVALID_REQUEST;\n    }\n\n    List<IneligibleReplica> ineligibleReplicas = ineligibleReplicasForIsr(newIsr);\n    if (!ineligibleReplicas.isEmpty()) {\n        log.info(\"Rejecting AlterPartition request from node {} for {}-{} because \" +\n                \"it specified ineligible replicas {} in the new ISR {}.\",\n                brokerId, topic.name, partitionId, ineligibleReplicas, partitionData.newIsr());\n\n        if (requestApiVersion > 1) {\n            return INELIGIBLE_REPLICA;\n        } else {\n            return OPERATION_NOT_ATTEMPTED;\n        }\n    }\n\n    return Errors.NONE;\n}", "summary_tokens": ["validate", "the", "partition", "information", "included", "in", "the", "alter", "partition", "request"], "project": "kafka"}
{"id": 2031, "code": "public void recordConnectorStop() {\n    startAndStopCounter.recordStop();\n}", "summary_tokens": ["record", "that", "this", "connector", "has", "been", "stopped"], "project": "kafka"}
{"id": 327, "code": "public static OffsetSpec latest() {\n    return new LatestSpec();\n}", "summary_tokens": ["used", "to", "retrieve", "the", "latest", "offset", "of", "a", "partition"], "project": "kafka"}
{"id": 2683, "code": "default void init(final StateStoreContext context, final StateStore root) {\n    init(StoreToProcessorContextAdapter.adapt(context), root);\n}", "summary_tokens": ["initializes", "this", "state", "store"], "project": "kafka"}
{"id": 470, "code": "boolean ensureFreshMetadata(Timer timer) {\n    if (this.metadata.updateRequested() || this.metadata.timeToNextUpdate(timer.currentTimeMs()) == 0) {\n        return awaitMetadataUpdate(timer);\n    } else {\n            \n        return true;\n    }\n}", "summary_tokens": ["ensure", "our", "metadata", "is", "fresh", "if", "an", "update", "is", "expected", "this", "will", "block", "until", "it", "has", "completed"], "project": "kafka"}
{"id": 60, "code": "public synchronized void updateWithCurrentRequestVersion(MetadataResponse response, boolean isPartialUpdate, long nowMs) {\n    this.update(this.requestVersion, response, isPartialUpdate, nowMs);\n}", "summary_tokens": ["update", "metadata", "assuming", "the", "current", "request", "version"], "project": "kafka"}
{"id": 51, "code": "public List<String> nodesWithTimedOutRequests(long now) {\n    List<String> nodeIds = new ArrayList<>();\n    for (Map.Entry<String, Deque<NetworkClient.InFlightRequest>> requestEntry : requests.entrySet()) {\n        String nodeId = requestEntry.getKey();\n        Deque<NetworkClient.InFlightRequest> deque = requestEntry.getValue();\n        if (hasExpiredRequest(now, deque))\n            nodeIds.add(nodeId);\n    }\n    return nodeIds;\n}", "summary_tokens": ["returns", "a", "list", "of", "nodes", "with", "pending", "in", "flight", "request", "that", "need", "to", "be", "timed", "out"], "project": "kafka"}
{"id": 3021, "code": "public static WindowBytesStoreSupplier inMemoryWindowStore(final String name,\n                                                           final Duration retentionPeriod,\n                                                           final Duration windowSize,\n                                                           final boolean retainDuplicates) throws IllegalArgumentException {\n    Objects.requireNonNull(name, \"name cannot be null\");\n\n    final String repartitionPeriodErrorMessagePrefix = prepareMillisCheckFailMsgPrefix(retentionPeriod, \"retentionPeriod\");\n    final long retentionMs = validateMillisecondDuration(retentionPeriod, repartitionPeriodErrorMessagePrefix);\n    if (retentionMs < 0L) {\n        throw new IllegalArgumentException(\"retentionPeriod cannot be negative\");\n    }\n\n    final String windowSizeErrorMessagePrefix = prepareMillisCheckFailMsgPrefix(windowSize, \"windowSize\");\n    final long windowSizeMs = validateMillisecondDuration(windowSize, windowSizeErrorMessagePrefix);\n    if (windowSizeMs < 0L) {\n        throw new IllegalArgumentException(\"windowSize cannot be negative\");\n    }\n\n    if (windowSizeMs > retentionMs) {\n        throw new IllegalArgumentException(\"The retention period of the window store \"\n            + name + \" must be no smaller than its window size. Got size=[\"\n            + windowSize + \"], retention=[\" + retentionPeriod + \"]\");\n    }\n\n    return new InMemoryWindowBytesStoreSupplier(name, retentionMs, windowSizeMs, retainDuplicates);\n}", "summary_tokens": ["create", "an", "in", "memory", "window", "bytes", "store", "supplier"], "project": "kafka"}
{"id": 2678, "code": "protected final ProcessorContext context() {\n    return context;\n}", "summary_tokens": ["get", "the", "processor", "s", "context", "set", "during", "init", "processor", "context", "initialization"], "project": "kafka"}
{"id": 2212, "code": "private void untrack(BrokerHeartbeatState broker) {\n    if (!broker.fenced()) {\n        unfenced.remove(broker);\n        if (!broker.shuttingDown()) {\n            active.remove(broker);\n        }\n    }\n}", "summary_tokens": ["stop", "tracking", "the", "broker", "in", "the", "unfenced", "list", "and", "active", "set", "if", "it", "was", "tracked", "in", "either", "of", "these"], "project": "kafka"}
{"id": 1529, "code": "public void oldSaslPlainSslClientWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(true, false, SecurityProtocol.SASL_SSL, \"PLAIN\");\n}", "summary_tokens": ["tests", "good", "path", "sasl", "plain", "authentication", "over", "ssl", "with", "old", "version", "of", "client", "that", "does", "not", "support", "sasl", "authenticate", "headers", "and", "new", "version", "of", "server"], "project": "kafka"}
{"id": 2626, "code": "public static SessionWindows ofInactivityGapAndGrace(final Duration inactivityGap, final Duration afterWindowEnd) {\n    final String inactivityGapMsgPrefix = prepareMillisCheckFailMsgPrefix(inactivityGap, \"inactivityGap\");\n    final long inactivityGapMs = validateMillisecondDuration(inactivityGap, inactivityGapMsgPrefix);\n\n    final String afterWindowEndMsgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, afterWindowEndMsgPrefix);\n\n    return new SessionWindows(inactivityGapMs, afterWindowEndMs, true);\n}", "summary_tokens": ["creates", "a", "new", "window", "specification", "with", "the", "specified", "inactivity", "gap"], "project": "kafka"}
{"id": 2001, "code": "public Map<TopicPartition, Long> endOffsets(Set<TopicPartition> partitions) {\n    if (partitions == null || partitions.isEmpty()) {\n        return Collections.emptyMap();\n    }\n    Map<TopicPartition, OffsetSpec> offsetSpecMap = partitions.stream().collect(Collectors.toMap(Function.identity(), tp -> OffsetSpec.latest()));\n    ListOffsetsResult resultFuture = admin.listOffsets(offsetSpecMap, new ListOffsetsOptions(IsolationLevel.READ_UNCOMMITTED));\n        \n    Map<TopicPartition, Long> result = new HashMap<>();\n    for (TopicPartition partition : partitions) {\n        try {\n            ListOffsetsResultInfo info = resultFuture.partitionResult(partition).get();\n            result.put(partition, info.offset());\n        } catch (ExecutionException e) {\n            Throwable cause = e.getCause();\n            String topic = partition.topic();\n            if (cause instanceof AuthorizationException) {\n                String msg = String.format(\"Not authorized to get the end offsets for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new ConnectException(msg, e);\n            } else if (cause instanceof UnsupportedVersionException) {\n                    \n                    \n                String msg = String.format(\"API to get the get the end offsets for topic '%s' is unsupported on brokers at %s\", topic, bootstrapServers);\n                throw new UnsupportedVersionException(msg, e);\n            } else if (cause instanceof TimeoutException) {\n                String msg = String.format(\"Timed out while waiting to get end offsets for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new TimeoutException(msg, e);\n            } else if (cause instanceof LeaderNotAvailableException) {\n                String msg = String.format(\"Unable to get end offsets during leader election for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new LeaderNotAvailableException(msg, e);\n            } else if (cause instanceof org.apache.kafka.common.errors.RetriableException) {\n                throw (org.apache.kafka.common.errors.RetriableException) cause;\n            } else {\n                String msg = String.format(\"Error while getting end offsets for topic '%s' on brokers at %s\", topic, bootstrapServers);\n                throw new ConnectException(msg, e);\n            }\n        } catch (InterruptedException e) {\n            Thread.interrupted();\n            String msg = String.format(\"Interrupted while attempting to read end offsets for topic '%s' on brokers at %s\", partition.topic(), bootstrapServers);\n            throw new RetriableException(msg, e);\n        }\n    }\n    return result;\n}", "summary_tokens": ["fetch", "the", "most", "recent", "offset", "for", "each", "of", "the", "supplied", "topic", "partition", "objects"], "project": "kafka"}
{"id": 379, "code": "public long offset() {\n    return offset;\n}", "summary_tokens": ["the", "position", "of", "this", "record", "in", "the", "corresponding", "kafka", "partition"], "project": "kafka"}
{"id": 3008, "code": "public Serializer<K> keySerializer() {\n    return keySerde.serializer();\n}", "summary_tokens": ["return", "the", "key", "serializer"], "project": "kafka"}
{"id": 3185, "code": "public List<CapturedPunctuator> scheduledPunctuators() {\n    return new LinkedList<>(punctuators);\n}", "summary_tokens": ["get", "the", "punctuators", "scheduled", "so", "far"], "project": "kafka"}
{"id": 1441, "code": "public void testInterBrokerSslConfigValidation(Args args) throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SSL;\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    args.sslServerConfigs.put(SslConfigs.SSL_ENDPOINT_IDENTIFICATION_ALGORITHM_CONFIG, \"HTTPS\");\n    args.sslServerConfigs.putAll(args.serverCertStores.keyStoreProps());\n    args.sslServerConfigs.putAll(args.serverCertStores.trustStoreProps());\n    args.sslClientConfigs.putAll(args.serverCertStores.keyStoreProps());\n    args.sslClientConfigs.putAll(args.serverCertStores.trustStoreProps());\n    TestSecurityConfig config = new TestSecurityConfig(args.sslServerConfigs);\n    ListenerName listenerName = ListenerName.forSecurityProtocol(securityProtocol);\n    ChannelBuilder serverChannelBuilder = ChannelBuilders.serverChannelBuilder(listenerName,\n        true, securityProtocol, config, null, null, time, new LogContext(),\n        defaultApiVersionsSupplier());\n    server = new NioEchoServer(listenerName, securityProtocol, config,\n            \"localhost\", serverChannelBuilder, null, time);\n    server.start();\n\n    this.selector = createSelector(args.sslClientConfigs, null, null, null);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(\"0\", addr, BUFFER_SIZE, BUFFER_SIZE);\n    NetworkTestUtils.checkClientConnection(selector, \"0\", 100, 10);\n}", "summary_tokens": ["verifies", "that", "inter", "broker", "listener", "with", "validation", "of", "truststore", "against", "keystore", "works", "with", "configs", "including", "mutual", "authentication", "and", "hostname", "verification"], "project": "kafka"}
{"id": 1965, "code": "public synchronized void offset(Map<String, ?> partition, Map<String, ?> offset) {\n    data.put((Map<String, Object>) partition, (Map<String, Object>) offset);\n}", "summary_tokens": ["set", "an", "offset", "for", "a", "partition", "using", "connect", "data", "values", "partition", "the", "partition", "to", "store", "an", "offset", "for", "offset", "the", "offset"], "project": "kafka"}
{"id": 1248, "code": "public static int sizeOfUnsignedVarint(int value) {\n        \n        \n        \n        \n\n        \n\n        \n\n        \n        \n\n    int leadingZeros = Integer.numberOfLeadingZeros(value);\n    int leadingZerosBelow38DividedBy7 = ((38 - leadingZeros) * 0b10010010010010011) >>> 19;\n    return leadingZerosBelow38DividedBy7 + (leadingZeros >>> 5);\n}", "summary_tokens": ["number", "of", "bytes", "needed", "to", "encode", "an", "integer", "in", "unsigned", "variable", "length", "format"], "project": "kafka"}
{"id": 2578, "code": "public JoinWindows before(final Duration timeDifference) throws IllegalArgumentException {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, msgPrefix);\n    return new JoinWindows(timeDifferenceMs, afterMs, graceMs, enableSpuriousResultFix);\n}", "summary_tokens": ["changes", "the", "start", "window", "boundary", "to", "time", "difference", "but", "keep", "the", "end", "window", "boundary", "as", "is"], "project": "kafka"}
{"id": 3032, "code": "public Set<TopicPartition> standbyTopicPartitions() {\n    return Collections.unmodifiableSet(standbyTopicPartitions);\n}", "summary_tokens": ["source", "topic", "partitions", "for", "which", "the", "instance", "acts", "as", "standby"], "project": "kafka"}
{"id": 95, "code": "private void maybeThrottle(AbstractResponse response, short apiVersion, String nodeId, long now) {\n    int throttleTimeMs = response.throttleTimeMs();\n    if (throttleTimeMs > 0 && response.shouldClientThrottle(apiVersion)) {\n        connectionStates.throttle(nodeId, now + throttleTimeMs);\n        log.trace(\"Connection to node {} is throttled for {} ms until timestamp {}\", nodeId, throttleTimeMs,\n                  now + throttleTimeMs);\n    }\n}", "summary_tokens": ["if", "a", "response", "from", "a", "node", "includes", "a", "non", "zero", "throttle", "delay", "and", "client", "side", "throttling", "has", "been", "enabled", "for", "the", "connection", "to", "the", "node", "throttle", "the", "connection", "for", "the", "specified", "delay"], "project": "kafka"}
{"id": 844, "code": "public static Map<String, String> getTags(String... keyValue) {\n    if ((keyValue.length % 2) != 0)\n        throw new IllegalArgumentException(\"keyValue needs to be specified in pairs\");\n    Map<String, String> tags = new LinkedHashMap<>(keyValue.length / 2);\n\n    for (int i = 0; i < keyValue.length; i += 2)\n        tags.put(keyValue[i], keyValue[i + 1]);\n    return tags;\n}", "summary_tokens": ["create", "a", "set", "of", "tags", "using", "the", "supplied", "key", "and", "value", "pairs"], "project": "kafka"}
{"id": 203, "code": "public KafkaFuture<Config> config(String topic) {\n    return futures.get(topic).thenApply(TopicMetadataAndConfig::config);\n}", "summary_tokens": ["returns", "a", "future", "that", "provides", "topic", "configs", "for", "the", "topic", "when", "the", "request", "completes"], "project": "kafka"}
{"id": 2318, "code": "public static void replayAllBatches(\n    MetadataDelta delta,\n    long highestOffset,\n    int highestEpoch,\n    List<List<ApiMessageAndVersion>> batches\n) {\n    for (List<ApiMessageAndVersion> batch : batches) {\n        replayAll(delta, highestOffset, highestEpoch, batch);\n    }\n}", "summary_tokens": ["replay", "a", "list", "of", "record", "batches", "to", "the", "metadata", "delta"], "project": "kafka"}
{"id": 2335, "code": "private static void assertIteratorYields(Iterator<? extends Object> iter,\n                                         Object... expected) {\n    IdentityHashMap<Object, Boolean> remaining = new IdentityHashMap<>();\n    for (Object object : expected) {\n        remaining.put(object, true);\n    }\n    List<Object> extraObjects = new ArrayList<>();\n    int i = 0;\n    while (iter.hasNext()) {\n        Object object = iter.next();\n        assertNotNull(object);\n        if (remaining.remove(object) == null) {\n            extraObjects.add(object);\n        }\n    }\n    if (!extraObjects.isEmpty() || !remaining.isEmpty()) {\n        throw new RuntimeException(\"Found extra object(s): [\" + String.join(\", \",\n            extraObjects.stream().map(e -> e.toString()).collect(Collectors.toList())) +\n            \"] and didn't find object(s): [\" + String.join(\", \",\n            remaining.keySet().stream().map(e -> e.toString()).collect(Collectors.toList())) + \"]\");\n    }\n}", "summary_tokens": ["assert", "that", "the", "given", "iterator", "contains", "the", "given", "elements", "in", "any", "order"], "project": "kafka"}
{"id": 2167, "code": "public String name() {\n    return workerName;\n}", "summary_tokens": ["get", "the", "workers", "s", "name", "corresponding", "to", "this", "handle"], "project": "kafka"}
{"id": 1044, "code": "public static ApiVersionCollection intersectForwardableApis(\n    final ApiMessageType.ListenerType listenerType,\n    final RecordVersion minRecordVersion,\n    final Map<ApiKeys, ApiVersion> activeControllerApiVersions\n) {\n    ApiVersionCollection apiKeys = new ApiVersionCollection();\n    for (ApiKeys apiKey : ApiKeys.apisForListener(listenerType)) {\n        if (apiKey.minRequiredInterBrokerMagic <= minRecordVersion.value) {\n            ApiVersion brokerApiVersion = toApiVersion(apiKey);\n\n            final ApiVersion finalApiVersion;\n            if (!apiKey.forwardable) {\n                finalApiVersion = brokerApiVersion;\n            } else {\n                Optional<ApiVersion> intersectVersion = intersect(brokerApiVersion,\n                    activeControllerApiVersions.getOrDefault(apiKey, null));\n                if (intersectVersion.isPresent()) {\n                    finalApiVersion = intersectVersion.get();\n                } else {\n                        \n                    continue;\n                }\n            }\n\n            apiKeys.add(finalApiVersion.duplicate());\n        }\n    }\n    return apiKeys;\n}", "summary_tokens": ["find", "the", "common", "range", "of", "supported", "api", "versions", "between", "the", "locally", "known", "range", "and", "that", "of", "another", "set"], "project": "kafka"}
{"id": 2017, "code": "public void testTaskStatuses() throws Exception {\n    connect = connectBuilder.build();\n        \n    connect.start();\n\n    connect.assertions().assertAtLeastNumWorkersAreUp(NUM_WORKERS,\n            \"Initial group of workers did not start in time.\");\n\n        \n    Map<String, String> props = defaultSourceConnectorProps(TOPIC_NAME);\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getSimpleName());\n\n        \n    int initialNumTasks = 1;\n    props.put(TASKS_MAX_CONFIG, String.valueOf(initialNumTasks));\n    connect.configureConnector(CONNECTOR_NAME, props);\n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME,\n            initialNumTasks, \"Connector tasks did not start in time\");\n\n        \n    int increasedNumTasks = 5;\n    props.put(TASKS_MAX_CONFIG, String.valueOf(increasedNumTasks));\n    connect.configureConnector(CONNECTOR_NAME, props);\n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME,\n            increasedNumTasks, \"Connector task statuses did not update in time.\");\n\n        \n    int decreasedNumTasks = 3;\n    props.put(TASKS_MAX_CONFIG, String.valueOf(decreasedNumTasks));\n    connect.configureConnector(CONNECTOR_NAME, props);\n    connect.assertions().assertConnectorAndExactlyNumTasksAreRunning(CONNECTOR_NAME,\n            decreasedNumTasks, \"Connector task statuses did not update in time.\");\n}", "summary_tokens": ["verify", "that", "the", "number", "of", "tasks", "listed", "in", "the", "rest", "api", "is", "updated", "correctly", "after", "changes", "to", "the", "tasks"], "project": "kafka"}
{"id": 2688, "code": "public static TaskId readFrom(final DataInputStream in, final int version) throws IOException {\n    return readTaskIdFrom(in, version);\n}", "summary_tokens": ["ioexception", "if", "cannot", "read", "from", "input", "stream", "since", "0"], "project": "kafka"}
{"id": 456, "code": "private void maybeUpdateGroupSubscription(String assignorName,\n                                          Map<String, Assignment> assignments,\n                                          Set<String> allSubscribedTopics) {\n    if (!isAssignFromSubscribedTopicsAssignor(assignorName)) {\n        Set<String> assignedTopics = new HashSet<>();\n        for (Assignment assigned : assignments.values()) {\n            for (TopicPartition tp : assigned.partitions())\n                assignedTopics.add(tp.topic());\n        }\n\n        if (!assignedTopics.containsAll(allSubscribedTopics)) {\n            SortedSet<String> notAssignedTopics = new TreeSet<>(allSubscribedTopics);\n            notAssignedTopics.removeAll(assignedTopics);\n            log.warn(\"The following subscribed topics are not assigned to any members: {} \", notAssignedTopics);\n        }\n\n        if (!allSubscribedTopics.containsAll(assignedTopics)) {\n            SortedSet<String> newlyAddedTopics = new TreeSet<>(assignedTopics);\n            newlyAddedTopics.removeAll(allSubscribedTopics);\n            log.info(\"The following not-subscribed topics are assigned, and their metadata will be \" +\n                \"fetched from the brokers: {}\", newlyAddedTopics);\n\n            allSubscribedTopics.addAll(newlyAddedTopics);\n            updateGroupSubscription(allSubscribedTopics);\n        }\n    }\n}", "summary_tokens": ["user", "customized", "assignor", "may", "have", "created", "some", "topics", "that", "are", "not", "in", "the", "subscription", "list", "and", "assign", "their", "partitions", "to", "the", "members", "in", "this", "case", "we", "would", "like", "to", "update", "the", "leader", "s", "own", "metadata", "with", "the", "newly", "added", "topics", "so", "that", "it", "will", "not", "trigger", "a", "subsequent", "rebalance", "when", "these", "topics", "gets", "updated", "from", "metadata", "refresh"], "project": "kafka"}
{"id": 3059, "code": "public Set<TopicPartition> standbyTopicPartitions() {\n    return standbyTopicPartitions;\n}", "summary_tokens": ["source", "topic", "partitions", "for", "which", "the", "instance", "acts", "as", "standby"], "project": "kafka"}
{"id": 665, "code": "public Node leaderFor(TopicPartition topicPartition) {\n    PartitionInfo info = partitionsByTopicPartition.get(topicPartition);\n    if (info == null)\n        return null;\n    else\n        return info.leader();\n}", "summary_tokens": ["get", "the", "current", "leader", "for", "the", "given", "topic", "partition", "topic", "partition", "the", "topic", "and", "partition", "we", "want", "to", "know", "the", "leader", "for", "the", "node", "that", "is", "the", "leader", "for", "this", "topic", "partition", "or", "null", "if", "there", "is", "currently", "no", "leader"], "project": "kafka"}
{"id": 1616, "code": "public Integer getInt32(String fieldName) {\n    return (Integer) getCheckType(fieldName, Schema.Type.INT32);\n}", "summary_tokens": ["equivalent", "to", "calling", "get", "string", "and", "casting", "the", "result", "to", "a", "integer"], "project": "kafka"}
{"id": 535, "code": "public void initTransactions() {\n    throwIfNoTransactionManager();\n    throwIfProducerClosed();\n    long now = time.nanoseconds();\n    TransactionalRequestResult result = transactionManager.initializeTransactions();\n    sender.wakeup();\n    result.await(maxBlockTimeMs, TimeUnit.MILLISECONDS);\n    producerMetrics.recordInit(time.nanoseconds() - now);\n}", "summary_tokens": ["needs", "to", "be", "called", "before", "any", "other", "methods", "when", "the", "transactional"], "project": "kafka"}
{"id": 265, "code": "public Optional<Long> finalizedFeaturesEpoch() {\n    return finalizedFeaturesEpoch;\n}", "summary_tokens": ["the", "epoch", "for", "the", "finalized", "features"], "project": "kafka"}
{"id": 485, "code": "public boolean isEmpty() {\n    return numRecords == 0 && !positionAdvanced;\n}", "summary_tokens": ["true", "if", "and", "only", "if", "this", "fetch", "did", "not", "return", "any", "user", "visible", "i"], "project": "kafka"}
{"id": 994, "code": "public boolean hasNullValue() {\n    return valueSize() < 0;\n}", "summary_tokens": ["check", "whether", "the", "value", "field", "of", "this", "record", "is", "null"], "project": "kafka"}
{"id": 2676, "code": "public KTableKTableJoinMerger<K, VR> joinMerger() {\n    final KTableKTableJoinMerger<K, Change<VR>> merger =\n        mergeProcessorParameters().kTableKTableJoinMergerProcessorSupplier();\n        \n    return (KTableKTableJoinMerger<K, VR>) merger;\n}", "summary_tokens": ["the", "supplier", "which", "provides", "processor", "with", "ktable", "ktable", "join", "merge", "functionality"], "project": "kafka"}
{"id": 2646, "code": "public static <K, KO> TableJoined<K, KO> with(final StreamPartitioner<K, Void> partitioner,\n                                              final StreamPartitioner<KO, Void> otherPartitioner) {\n    return new TableJoined<>(partitioner, otherPartitioner, null);\n}", "summary_tokens": ["create", "an", "instance", "of", "table", "joined", "with", "partitioner", "and", "other", "partitioner", "stream", "partitioner", "instances"], "project": "kafka"}
{"id": 2935, "code": "public Position merge(final Position other) {\n    if (other == null) {\n        return this;\n    } else {\n        for (final Entry<String, ConcurrentHashMap<Integer, Long>> entry : other.position.entrySet()) {\n            final String topic = entry.getKey();\n            final Map<Integer, Long> partitionMap =\n                position.computeIfAbsent(topic, k -> new ConcurrentHashMap<>());\n            for (final Entry<Integer, Long> partitionOffset : entry.getValue().entrySet()) {\n                final Integer partition = partitionOffset.getKey();\n                final Long offset = partitionOffset.getValue();\n                if (!partitionMap.containsKey(partition)\n                    || partitionMap.get(partition) < offset) {\n                    partitionMap.put(partition, offset);\n                }\n            }\n        }\n        return this;\n    }\n}", "summary_tokens": ["merges", "the", "provided", "position", "into", "the", "current", "instance"], "project": "kafka"}
{"id": 1235, "code": "public static void unmap(String resourceDescription, ByteBuffer buffer) throws IOException {\n    if (!buffer.isDirect())\n        throw new IllegalArgumentException(\"Unmapping only works with direct buffers\");\n    if (UNMAP == null)\n        throw UNMAP_NOT_SUPPORTED_EXCEPTION;\n\n    try {\n        UNMAP.invokeExact(buffer);\n    } catch (Throwable throwable) {\n        throw new IOException(\"Unable to unmap the mapped buffer: \" + resourceDescription, throwable);\n    }\n}", "summary_tokens": ["unmap", "the", "provided", "mapped", "or", "direct", "byte", "buffer"], "project": "kafka"}
{"id": 2821, "code": "public State state() {\n        \n    return state;\n}", "summary_tokens": ["the", "state", "this", "instance", "is", "in"], "project": "kafka"}
{"id": 1328, "code": "public void testTimeoutWithoutMetadata() throws Exception {\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(Time.SYSTEM, mockBootstrapCluster(),\n            newStrMap(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"10\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        env.kafkaClient().prepareResponse(prepareCreateTopicsResponse(\"myTopic\", Errors.NONE));\n        KafkaFuture<Void> future = env.adminClient().createTopics(\n                singleton(new NewTopic(\"myTopic\", Collections.singletonMap(0, asList(0, 1, 2)))),\n                new CreateTopicsOptions().timeoutMs(1000)).all();\n        TestUtils.assertFutureError(future, TimeoutException.class);\n    }\n}", "summary_tokens": ["test", "that", "the", "client", "properly", "times", "out", "when", "we", "don", "t", "receive", "any", "metadata"], "project": "kafka"}
{"id": 1640, "code": "public static List<?> convertToList(Schema schema, Object value) {\n    return (List<?>) convertTo(ARRAY_SELECTOR_SCHEMA, schema, value);\n}", "summary_tokens": ["convert", "the", "specified", "value", "to", "an", "type", "array", "value"], "project": "kafka"}
{"id": 1500, "code": "public void testUnauthenticatedApiVersionsRequestOverPlaintextHandshakeVersion1() throws Exception {\n    testUnauthenticatedApiVersionsRequest(SecurityProtocol.SASL_PLAINTEXT, (short) 1);\n}", "summary_tokens": ["see", "test", "unauthenticated", "api", "versions", "request", "over", "ssl", "handshake", "version", "0", "for", "test", "scenario"], "project": "kafka"}
{"id": 2828, "code": "private long advanceNowAndComputeLatency() {\n    final long previous = now;\n    now = time.milliseconds();\n\n    return Math.max(now - previous, 0);\n}", "summary_tokens": ["compute", "the", "latency", "based", "on", "the", "current", "marked", "timestamp", "and", "update", "the", "marked", "timestamp", "with", "the", "current", "system", "timestamp"], "project": "kafka"}
{"id": 2563, "code": "public Consumed<K, V> withTimestampExtractor(final TimestampExtractor timestampExtractor) {\n    this.timestampExtractor = timestampExtractor;\n    return this;\n}", "summary_tokens": ["configure", "the", "instance", "of", "consumed", "with", "a", "timestamp", "extractor"], "project": "kafka"}
{"id": 834, "code": "public void record(double value, long timeMs, boolean checkQuotas) {\n    if (shouldRecord()) {\n        recordInternal(value, timeMs, checkQuotas);\n    }\n}", "summary_tokens": ["record", "a", "value", "at", "a", "known", "time"], "project": "kafka"}
{"id": 2943, "code": "static <R> QueryResult<R> forFailure(\n    final FailureReason failureReason,\n    final String failureMessage) {\n\n    return new FailedQueryResult<>(failureReason, failureMessage);\n}", "summary_tokens": ["static", "factory", "method", "to", "create", "a", "result", "object", "for", "a", "failed", "query"], "project": "kafka"}
{"id": 1803, "code": "public void logAll() {\n    StringBuilder b = new StringBuilder();\n    b.append(getClass().getSimpleName());\n    b.append(\" values: \");\n    b.append(Utils.NL);\n\n    for (Map.Entry<String, Object> entry : values.entrySet()) {\n        b.append('\\t');\n        b.append(entry.getKey());\n        b.append(\" = \");\n        b.append(format(entry.getValue()));\n        b.append(Utils.NL);\n    }\n    log.info(b.toString());\n}", "summary_tokens": ["log", "the", "values", "of", "this", "object", "at", "level", "info"], "project": "kafka"}
{"id": 1189, "code": "public Long validateLong(String name) {\n    return validateLong(name, true);\n}", "summary_tokens": ["validates", "that", "if", "a", "value", "is", "supplied", "is", "a", "value", "that"], "project": "kafka"}
{"id": 710, "code": "public AclOperation operation() {\n    return data.operation();\n}", "summary_tokens": ["return", "the", "acl", "operation"], "project": "kafka"}
{"id": 469, "code": "public boolean awaitMetadataUpdate(Timer timer) {\n    int version = this.metadata.requestUpdate();\n    do {\n        poll(timer);\n    } while (this.metadata.updateVersion() == version && timer.notExpired());\n    return this.metadata.updateVersion() > version;\n}", "summary_tokens": ["block", "waiting", "on", "the", "metadata", "refresh", "with", "a", "timeout"], "project": "kafka"}
{"id": 1447, "code": "public void testCustomClientAndServerSslEngineFactory(Args args) throws Exception {\n    args.sslClientConfigs.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    args.sslServerConfigs.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    verifySslConfigs(args);\n}", "summary_tokens": ["tests", "if", "client", "and", "server", "both", "can", "plugin", "customize", "ssl"], "project": "kafka"}
{"id": 1858, "code": "public void ensureActive() {\n    coordinator.poll(0);\n}", "summary_tokens": ["ensure", "that", "the", "connection", "to", "the", "broker", "coordinator", "is", "up", "and", "that", "the", "worker", "is", "an", "active", "member", "of", "the", "group"], "project": "kafka"}
{"id": 1508, "code": "public void testInvalidSaslPacket() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    server = createEchoServer(securityProtocol);\n\n        \n    String node1 = \"invalid1\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node1);\n    sendHandshakeRequestReceiveResponse(node1, (short) 1);\n    Random random = new Random();\n    byte[] bytes = new byte[1024];\n    random.nextBytes(bytes);\n    selector.send(new NetworkSend(node1, ByteBufferSend.sizePrefixed(ByteBuffer.wrap(bytes))));\n    NetworkTestUtils.waitForChannelClose(selector, node1, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good1\");\n\n        \n    String node2 = \"invalid2\";\n    createClientConnection(SecurityProtocol.PLAINTEXT, node2);\n    random.nextBytes(bytes);\n    selector.send(new NetworkSend(node2, ByteBufferSend.sizePrefixed(ByteBuffer.wrap(bytes))));\n    NetworkTestUtils.waitForChannelClose(selector, node2, ChannelState.READY.state());\n    selector.close();\n\n        \n    createAndCheckClientConnection(securityProtocol, \"good2\");\n}", "summary_tokens": ["tests", "that", "any", "invalid", "data", "during", "kafka", "sasl", "handshake", "request", "flow", "or", "the", "actual", "sasl", "authentication", "flow", "result", "in", "authentication", "failure", "and", "do", "not", "cause", "any", "failures", "in", "the", "server"], "project": "kafka"}
{"id": 1514, "code": "public void testServerAuthenticateCallbackHandler() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_PLAINTEXT;\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Collections.singletonList(\"PLAIN\"));\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_SERVER, PlainLoginModule.class.getName(), new HashMap<String, Object>());\n    String callbackPrefix = ListenerName.forSecurityProtocol(securityProtocol).saslMechanismConfigPrefix(\"PLAIN\");\n    saslServerConfigs.put(callbackPrefix + BrokerSecurityConfigs.SASL_SERVER_CALLBACK_HANDLER_CLASS,\n            TestServerCallbackHandler.class.getName());\n    server = createEchoServer(securityProtocol);\n\n        \n    jaasConfig.setClientOptions(\"PLAIN\", TestServerCallbackHandler.USERNAME, TestServerCallbackHandler.PASSWORD);\n    createAndCheckClientConnection(securityProtocol, \"good\");\n\n        \n    jaasConfig.setClientOptions(\"PLAIN\", TestJaasConfig.USERNAME, \"invalid-password\");\n    createAndCheckClientConnectionFailure(securityProtocol, \"invalid\");\n}", "summary_tokens": ["tests", "sasl", "server", "authentication", "callback", "handler", "override"], "project": "kafka"}
{"id": 1371, "code": "private void assertIsFailed(KafkaFuture<?> future) {\n    assertTrue(future.isDone());\n    assertFalse(future.isCancelled());\n    assertTrue(future.isCompletedExceptionally());\n}", "summary_tokens": ["asserts", "that", "the", "given", "future", "is", "done", "failed", "and", "wasn", "t", "cancelled"], "project": "kafka"}
{"id": 1113, "code": "public Map<String, String> invalidExtensions() {\n    return Collections.unmodifiableMap(invalidExtensions);\n}", "summary_tokens": ["an", "immutable", "map", "consisting", "of", "the", "name", "gt", "error", "messages", "of", "extensions", "which", "failed", "validation"], "project": "kafka"}
{"id": 900, "code": "public SSLSession sslSession() throws IllegalStateException {\n    return sslEngine.getSession();\n}", "summary_tokens": ["returns", "an", "ssl", "session", "after", "the", "handshake", "is", "established", "throws", "illegal", "state", "exception", "if", "the", "handshake", "is", "not", "established"], "project": "kafka"}
{"id": 1292, "code": "public boolean notExpired() {\n    return !isExpired();\n}", "summary_tokens": ["check", "whether", "the", "timer", "has", "not", "yet", "expired"], "project": "kafka"}
{"id": 2763, "code": "public <K, V> void send(final String topic,\n                        final K key,\n                        final V value,\n                        final Headers headers,\n                        final Long timestamp,\n                        final Serializer<K> keySerializer,\n                        final Serializer<V> valueSerializer,\n                        final String processorNodeId,\n                        final InternalProcessorContext<Void, Void> context,\n                        final StreamPartitioner<? super K, ? super V> partitioner) {\n    final Integer partition;\n\n    if (partitioner != null) {\n        final List<PartitionInfo> partitions;\n        try {\n            partitions = streamsProducer.partitionsFor(topic);\n        } catch (final TimeoutException timeoutException) {\n            log.warn(\"Could not get partitions for topic {}, will retry\", topic);\n\n                \n            throw timeoutException;\n        } catch (final KafkaException fatal) {\n                \n                \n            throw new StreamsException(\"Could not determine the number of partitions for topic '\" + topic +\n                \"' for task \" + taskId + \" due to \" + fatal,\n                fatal\n            );\n        }\n        if (partitions.size() > 0) {\n            partition = partitioner.partition(topic, key, value, partitions.size());\n        } else {\n            throw new StreamsException(\"Could not get partition information for topic \" + topic + \" for task \" + taskId +\n                \". This can happen if the topic does not exist.\");\n        }\n    } else {\n        partition = null;\n    }\n\n    send(topic, key, value, headers, partition, timestamp, keySerializer, valueSerializer, processorNodeId, context);\n}", "summary_tokens": ["streams", "exception", "fatal", "error", "that", "should", "cause", "the", "thread", "to", "die", "task", "migrated", "exception", "recoverable", "error", "that", "would", "cause", "the", "task", "to", "be", "removed"], "project": "kafka"}
{"id": 685, "code": "public int port() {\n    return port;\n}", "summary_tokens": ["the", "port", "for", "this", "node"], "project": "kafka"}
{"id": 1299, "code": "public long elapsedMs() {\n    return currentTimeMs - startMs;\n}", "summary_tokens": ["get", "the", "amount", "of", "time", "that", "has", "elapsed", "since", "the", "timer", "began"], "project": "kafka"}
{"id": 2753, "code": "public void update(final ProcessorMetadata other) {\n    if (other == null) {\n        return;\n    }\n    for (final Map.Entry<String, Long> kv : other.metadata.entrySet()) {\n        final Long value = metadata.get(kv.getKey());\n        if (value == null || value < kv.getValue()) {\n            metadata.put(kv.getKey(), kv.getValue());\n        }\n    }\n}", "summary_tokens": ["merge", "with", "other", "metadata"], "project": "kafka"}
{"id": 2489, "code": "public Collection<org.apache.kafka.streams.state.StreamsMetadata> allMetadataForStore(final String storeName) {\n    validateIsRunningOrRebalancing();\n    return streamsMetadataState.getAllMetadataForStore(storeName).stream().map(streamsMetadata ->\n            new org.apache.kafka.streams.state.StreamsMetadata(streamsMetadata.hostInfo(),\n                    streamsMetadata.stateStoreNames(),\n                    streamsMetadata.topicPartitions(),\n                    streamsMetadata.standbyStateStoreNames(),\n                    streamsMetadata.standbyTopicPartitions()))\n            .collect(Collectors.toSet());\n}", "summary_tokens": ["find", "all", "currently", "running", "kafka", "streams", "instances", "potentially", "remotely", "that", "ul", "li", "use", "the", "same", "streams", "config", "application", "id", "config", "application", "id", "as", "this", "instance", "i"], "project": "kafka"}
{"id": 1331, "code": "public void testClientSideTimeoutAfterFailureToReceiveResponse() throws Exception {\n    Cluster cluster = mockCluster(3, 0);\n    CompletableFuture<String> disconnectFuture = new CompletableFuture<>();\n    MockTime time = new MockTime();\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(time, cluster,\n        newStrMap(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"1\",\n            AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG, \"100000\",\n            AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, \"0\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        env.kafkaClient().setDisconnectFuture(disconnectFuture);\n        final ListTopicsResult result = env.adminClient().listTopics();\n        TestUtils.waitForCondition(() -> {\n            time.sleep(1);\n            return disconnectFuture.isDone();\n        }, 5000, 1, () -> \"Timed out waiting for expected disconnect\");\n        assertFalse(disconnectFuture.isCompletedExceptionally());\n        assertFalse(result.future.isDone());\n        TestUtils.waitForCondition(env.kafkaClient()::hasInFlightRequests,\n            \"Timed out waiting for retry\");\n        env.kafkaClient().respond(prepareMetadataResponse(cluster, Errors.NONE));\n        assertEquals(0, result.listings().get().size());\n    }\n}", "summary_tokens": ["test", "that", "if", "the", "client", "can", "send", "to", "a", "node", "but", "doesn", "t", "receive", "a", "response", "it", "will", "disconnect", "and", "try", "a", "different", "node"], "project": "kafka"}
{"id": 1651, "code": "protected static double asDouble(Object value, Schema schema, Throwable error) {\n    try {\n        if (value instanceof Number) {\n            Number number = (Number) value;\n            return number.doubleValue();\n        }\n        if (value instanceof String) {\n            return new BigDecimal(value.toString()).doubleValue();\n        }\n    } catch (NumberFormatException e) {\n        error = e;\n            \n    }\n    return asLong(value, schema, error);\n}", "summary_tokens": ["convert", "the", "specified", "value", "with", "the", "desired", "floating", "point", "type"], "project": "kafka"}
{"id": 1288, "code": "public static String execCommand(String[] cmd, long timeout) throws IOException {\n    ShellCommandExecutor exec = new ShellCommandExecutor(cmd, timeout);\n    exec.execute();\n    return exec.output();\n}", "summary_tokens": ["static", "method", "to", "execute", "a", "shell", "command"], "project": "kafka"}
{"id": 2648, "code": "public TableJoined<K, KO> withPartitioner(final StreamPartitioner<K, Void> partitioner) {\n    return new TableJoined<>(partitioner, otherPartitioner, name);\n}", "summary_tokens": ["set", "the", "custom", "stream", "partitioner", "to", "be", "used", "as", "part", "of", "computing", "the", "join"], "project": "kafka"}
{"id": 1359, "code": "public void testBatchExpiration() {\n    long deliveryTimeoutMs = 10240;\n    ProducerBatch batch = new ProducerBatch(new TopicPartition(\"topic\", 1), memoryRecordsBuilder, now);\n        \n    assertFalse(batch.hasReachedDeliveryTimeout(deliveryTimeoutMs, now - 2));\n        \n    assertTrue(batch.hasReachedDeliveryTimeout(deliveryTimeoutMs, now + deliveryTimeoutMs));\n}", "summary_tokens": ["a", "producer", "batch", "configured", "using", "a", "timestamp", "preceding", "its", "create", "time", "is", "interpreted", "correctly", "as", "not", "expired", "by", "producer", "batch", "has", "reached", "delivery", "timeout", "long", "long"], "project": "kafka"}
{"id": 442, "code": "final boolean hasValidMemberId() {\n    return !hasUnknownGeneration() && generation.hasMemberId();\n}", "summary_tokens": ["true", "if", "the", "current", "generation", "s", "member", "id", "is", "valid", "false", "otherwise"], "project": "kafka"}
{"id": 1885, "code": "protected <V> V execAndHandleError(Operation<V> operation, Class<? extends Exception> tolerated) {\n    try {\n        V result = execAndRetry(operation);\n        if (context.failed()) {\n            markAsFailed();\n            errorHandlingMetrics.recordSkipped();\n        }\n        return result;\n    } catch (Exception e) {\n        errorHandlingMetrics.recordFailure();\n        markAsFailed();\n        context.error(e);\n\n        if (!tolerated.isAssignableFrom(e.getClass())) {\n            throw new ConnectException(\"Unhandled exception in error handler\", e);\n        }\n\n        if (!withinToleranceLimits()) {\n            throw new ConnectException(\"Tolerance exceeded in error handler\", e);\n        }\n\n        errorHandlingMetrics.recordSkipped();\n        return null;\n    }\n}", "summary_tokens": ["execute", "a", "given", "operation", "multiple", "times", "if", "needed", "and", "tolerate", "certain", "exceptions"], "project": "kafka"}
{"id": 2472, "code": "public void testOneWord() {\n        \n    inputTopic.pipeInput(\"Hello\");\n        \n    assertThat(outputTopic.readKeyValue(), equalTo(new KeyValue<>(\"hello\", 1L)));\n        \n    assertThat(outputTopic.isEmpty(), is(true));\n}", "summary_tokens": ["simple", "test", "validating", "count", "of", "one", "word"], "project": "kafka"}
{"id": 2777, "code": "public Map<String, String> getProperties(final Map<String, String> defaultProperties, final long additionalRetentionMs) {\n        \n    final Map<String, String> topicConfig = new HashMap<>(REPARTITION_TOPIC_DEFAULT_OVERRIDES);\n\n    topicConfig.putAll(defaultProperties);\n\n    topicConfig.putAll(topicConfigs);\n\n    return topicConfig;\n}", "summary_tokens": ["get", "the", "configured", "properties", "for", "this", "topic"], "project": "kafka"}
{"id": 992, "code": "private int valueSizeOffset() {\n    if (magic() == RecordBatch.MAGIC_VALUE_V0)\n        return KEY_OFFSET_V0 + Math.max(0, keySize());\n    else\n        return KEY_OFFSET_V1 + Math.max(0, keySize());\n}", "summary_tokens": ["the", "position", "where", "the", "value", "size", "is", "stored"], "project": "kafka"}
{"id": 2996, "code": "default KeyValueIterator<Windowed<K>, AGG> findSessions(final K keyFrom,\n                                                        final K keyTo,\n                                                        final Instant earliestSessionEndTime,\n                                                        final Instant latestSessionStartTime) {\n    throw new UnsupportedOperationException(\n        \"This API is not supported by this implementation of ReadOnlySessionStore.\");\n}", "summary_tokens": ["fetch", "any", "sessions", "in", "the", "given", "range", "of", "keys", "and", "the", "sessions", "end", "is", "ge", "earliest", "session", "end", "time", "and", "the", "sessions", "start", "is", "le", "latest", "session", "start", "time", "iterating", "from", "earliest", "to", "latest"], "project": "kafka"}
{"id": 2853, "code": "void abortTransaction() {\n    if (!eosEnabled()) {\n        throw new IllegalStateException(formatException(\"Exactly-once is not enabled\"));\n    }\n    if (transactionInFlight) {\n        try {\n            producer.abortTransaction();\n        } catch (final TimeoutException logAndSwallow) {\n                \n                \n            log.warn(\n                \"Aborting transaction failed due to timeout.\" +\n                    \" Will rely on broker to eventually abort the transaction after the transaction timeout passed.\",\n                logAndSwallow\n            );\n        } catch (final ProducerFencedException | InvalidProducerEpochException error) {\n                \n                \n                \n                \n                \n                \n                \n                \n            log.debug(\"Encountered {} while aborting the transaction; this is expected and hence swallowed\", error.getMessage());\n        } catch (final KafkaException error) {\n            throw new StreamsException(\n                formatException(\"Error encounter trying to abort a transaction\"),\n                error\n            );\n        }\n        transactionInFlight = false;\n    }\n}", "summary_tokens": ["illegal", "state", "exception", "if", "eos", "is", "disabled"], "project": "kafka"}
{"id": 1790, "code": "public void stopAndAwaitTask(ConnectorTaskId taskId) {\n    stopTask(taskId);\n    awaitStopTasks(Collections.singletonList(taskId));\n}", "summary_tokens": ["stop", "a", "task", "that", "belongs", "to", "this", "worker", "and", "await", "its", "termination"], "project": "kafka"}
{"id": 2762, "code": "public T root(final T id) {\n    T current = id;\n    T parent = ids.get(current);\n\n    if (parent == null) {\n        throw new NoSuchElementException(\"id: \" + id.toString());\n    }\n\n    while (!parent.equals(current)) {\n            \n        final T grandparent = ids.get(parent);\n        ids.put(current, grandparent);\n\n        current = parent;\n        parent = grandparent;\n    }\n    return current;\n}", "summary_tokens": ["no", "such", "element", "exception", "if", "the", "parent", "of", "this", "node", "is", "null"], "project": "kafka"}
{"id": 76, "code": "private static <T> Set<T> fillSet(Set<T> baseSet, Set<T> fillSet, Predicate<T> predicate) {\n    Set<T> result = new HashSet<>(baseSet);\n    for (T element : fillSet) {\n        if (predicate.test(element)) {\n            result.add(element);\n        }\n    }\n    return result;\n}", "summary_tokens": ["copies", "base", "set", "and", "adds", "all", "non", "existent", "elements", "in", "fill", "set", "such", "that", "predicate", "is", "true"], "project": "kafka"}
{"id": 201, "code": "public Map<String, KafkaFuture<Void>> values() {\n    return futures.entrySet().stream()\n            .collect(Collectors.toMap(Map.Entry::getKey, e -> e.getValue().thenApply(v -> (Void) null)));\n}", "summary_tokens": ["return", "a", "map", "from", "topic", "names", "to", "futures", "which", "can", "be", "used", "to", "check", "the", "status", "of", "individual", "topic", "creations"], "project": "kafka"}
{"id": 1980, "code": "public static LoggingContext forValidation(String connectorName) {\n    LoggingContext context = new LoggingContext();\n    MDC.put(CONNECTOR_CONTEXT, prefixFor(connectorName, Scope.VALIDATE, null));\n    return context;\n}", "summary_tokens": ["modify", "the", "current", "mdc", "logging", "context", "to", "set", "the", "connector", "context", "connector", "context", "to", "include", "the", "supplied", "connector", "name", "and", "the", "scope", "validate", "scope"], "project": "kafka"}
{"id": 938, "code": "public final boolean isArray() {\n    return arrayElementType().isPresent();\n}", "summary_tokens": ["returns", "true", "if", "the", "type", "is", "an", "array"], "project": "kafka"}
{"id": 3175, "code": "public <K, V> SessionStore<K, V> getSessionStore(final String name) {\n    final StateStore store = getStateStore(name, false);\n    return store instanceof SessionStore ? (SessionStore<K, V>) store : null;\n}", "summary_tokens": ["get", "the", "session", "store", "with", "the", "given", "name"], "project": "kafka"}
{"id": 297, "code": "public ListTopicsOptions listInternal(boolean listInternal) {\n    this.listInternal = listInternal;\n    return this;\n}", "summary_tokens": ["set", "whether", "we", "should", "list", "internal", "topics"], "project": "kafka"}
{"id": 2576, "code": "public static JoinWindows ofTimeDifferenceWithNoGrace(final Duration timeDifference) {\n    return ofTimeDifferenceAndGrace(timeDifference, Duration.ofMillis(NO_GRACE_PERIOD));\n}", "summary_tokens": ["specifies", "that", "records", "of", "the", "same", "key", "are", "joinable", "if", "their", "timestamps", "are", "within", "time", "difference", "i"], "project": "kafka"}
{"id": 1268, "code": "final public boolean contains(Object key) {\n    return findIndexOfEqualElement(key) != INVALID_INDEX;\n}", "summary_tokens": ["returns", "true", "if", "there", "is", "at", "least", "one", "element", "e", "in", "the", "collection", "such", "that", "key"], "project": "kafka"}
{"id": 1065, "code": "public Iterable<StopReplicaTopicState> topicStates() {\n    if (version() < 1) {\n        Map<String, StopReplicaTopicState> topicStates = new HashMap<>();\n        for (StopReplicaPartitionV0 partition : data.ungroupedPartitions()) {\n            StopReplicaTopicState topicState = topicStates.computeIfAbsent(partition.topicName(),\n                topic -> new StopReplicaTopicState().setTopicName(topic));\n            topicState.partitionStates().add(new StopReplicaPartitionState()\n                .setPartitionIndex(partition.partitionIndex())\n                .setDeletePartition(data.deletePartitions()));\n        }\n        return topicStates.values();\n    } else if (version() < 3) {\n        return () -> new MappedIterator<>(data.topics().iterator(), topic ->\n            new StopReplicaTopicState()\n                .setTopicName(topic.name())\n                .setPartitionStates(topic.partitionIndexes().stream()\n                    .map(partition -> new StopReplicaPartitionState()\n                        .setPartitionIndex(partition)\n                        .setDeletePartition(data.deletePartitions()))\n                    .collect(Collectors.toList())));\n    } else {\n        return data.topicStates();\n    }\n}", "summary_tokens": ["note", "that", "this", "method", "has", "allocation", "overhead", "per", "iterated", "element", "so", "callers", "should", "copy", "the", "result", "into", "another", "collection", "if", "they", "need", "to", "iterate", "more", "than", "once"], "project": "kafka"}
{"id": 2562, "code": "public Consumed<K, V> withValueSerde(final Serde<V> valueSerde) {\n    this.valueSerde = valueSerde;\n    return this;\n}", "summary_tokens": ["configure", "the", "instance", "of", "consumed", "with", "a", "value", "serde"], "project": "kafka"}
{"id": 567, "code": "public long timestamp() {\n    return this.timestamp;\n}", "summary_tokens": ["the", "timestamp", "of", "the", "record", "in", "the", "topic", "partition"], "project": "kafka"}
{"id": 3054, "code": "public <T> T getStore(final StoreQueryParameters<T> storeQueryParameters) {\n    final String storeName = storeQueryParameters.storeName();\n    final QueryableStoreType<T> queryableStoreType = storeQueryParameters.queryableStoreType();\n    final List<T> globalStore = globalStoreProvider.stores(storeName, queryableStoreType);\n    if (!globalStore.isEmpty()) {\n        return queryableStoreType.create(globalStoreProvider, storeName);\n    }\n    return queryableStoreType.create(\n        new WrappingStoreProvider(storeProviders.values(), storeQueryParameters),\n        storeName\n    );\n}", "summary_tokens": ["get", "a", "composite", "object", "wrapping", "the", "instances", "of", "the", "state", "store", "with", "the", "provided", "store", "name", "and", "queryable", "store", "type"], "project": "kafka"}
{"id": 984, "code": "private static FileChannel openChannel(File file,\n                                       boolean mutable,\n                                       boolean fileAlreadyExists,\n                                       int initFileSize,\n                                       boolean preallocate) throws IOException {\n    if (mutable) {\n        if (fileAlreadyExists || !preallocate) {\n            return FileChannel.open(file.toPath(), StandardOpenOption.CREATE, StandardOpenOption.READ,\n                    StandardOpenOption.WRITE);\n        } else {\n            RandomAccessFile randomAccessFile = new RandomAccessFile(file, \"rw\");\n            randomAccessFile.setLength(initFileSize);\n            return randomAccessFile.getChannel();\n        }\n    } else {\n        return FileChannel.open(file.toPath());\n    }\n}", "summary_tokens": ["open", "a", "channel", "for", "the", "given", "file", "for", "windows", "ntfs", "and", "some", "old", "linux", "file", "system", "set", "preallocate", "to", "true", "and", "init", "file", "size", "with", "one", "value", "for", "example", "0", "0", "0", "can", "improve", "the", "kafka", "produce", "performance"], "project": "kafka"}
{"id": 1317, "code": "public synchronized void enableBlockingUntilWakeup(int numBlockingWakeups) {\n    this.numBlockingWakeups = numBlockingWakeups;\n}", "summary_tokens": ["simulate", "a", "blocking", "poll", "in", "order", "to", "test", "wakeup", "behavior"], "project": "kafka"}
{"id": 914, "code": "public void writeByteBuffer(ByteBuffer buf) {\n    flushPendingBuffer();\n    addBuffer(buf.duplicate());\n}", "summary_tokens": ["write", "a", "byte", "buffer"], "project": "kafka"}
{"id": 376, "code": "public int partition() {\n    return this.partition;\n}", "summary_tokens": ["the", "partition", "from", "which", "this", "record", "is", "received"], "project": "kafka"}
{"id": 471, "code": "public void wakeup() {\n        \n        \n    log.debug(\"Received user wakeup\");\n    this.wakeup.set(true);\n    this.client.wakeup();\n}", "summary_tokens": ["wakeup", "an", "active", "poll"], "project": "kafka"}
{"id": 1301, "code": "public void sleep(long durationMs) {\n    long sleepDurationMs = Math.min(durationMs, remainingMs());\n    time.sleep(sleepDurationMs);\n    update();\n}", "summary_tokens": ["sleep", "for", "the", "requested", "duration", "and", "update", "the", "timer"], "project": "kafka"}
{"id": 2767, "code": "ConsumerRecord<Object, Object> deserialize(final ProcessorContext<?, ?> processorContext,\n                                           final ConsumerRecord<byte[], byte[]> rawRecord) {\n\n    try {\n        return new ConsumerRecord<>(\n            rawRecord.topic(),\n            rawRecord.partition(),\n            rawRecord.offset(),\n            rawRecord.timestamp(),\n            TimestampType.CREATE_TIME,\n            rawRecord.serializedKeySize(),\n            rawRecord.serializedValueSize(),\n            sourceNode.deserializeKey(rawRecord.topic(), rawRecord.headers(), rawRecord.key()),\n            sourceNode.deserializeValue(rawRecord.topic(), rawRecord.headers(), rawRecord.value()),\n            rawRecord.headers(),\n            Optional.empty()\n        );\n    } catch (final Exception deserializationException) {\n        final DeserializationExceptionHandler.DeserializationHandlerResponse response;\n        try {\n            response = deserializationExceptionHandler.handle(\n                (InternalProcessorContext<?, ?>) processorContext,\n                rawRecord,\n                deserializationException);\n        } catch (final Exception fatalUserException) {\n            log.error(\n                \"Deserialization error callback failed after deserialization error for record {}\",\n                rawRecord,\n                deserializationException);\n            throw new StreamsException(\"Fatal user code error in deserialization error callback\", fatalUserException);\n        }\n\n        if (response == DeserializationExceptionHandler.DeserializationHandlerResponse.FAIL) {\n            throw new StreamsException(\"Deserialization exception handler is set to fail upon\" +\n                \" a deserialization error. If you would rather have the streaming pipeline\" +\n                \" continue after a deserialization error, please set the \" +\n                DEFAULT_DESERIALIZATION_EXCEPTION_HANDLER_CLASS_CONFIG + \" appropriately.\",\n                deserializationException);\n        } else {\n            log.warn(\n                \"Skipping record due to deserialization error. topic=[{}] partition=[{}] offset=[{}]\",\n                rawRecord.topic(),\n                rawRecord.partition(),\n                rawRecord.offset(),\n                deserializationException\n            );\n            droppedRecordsSensor.record();\n            return null;\n        }\n    }\n}", "summary_tokens": ["streams", "exception", "if", "a", "deserialization", "error", "occurs", "and", "the", "deserialization", "callback", "returns", "deserialization", "exception", "handler"], "project": "kafka"}
{"id": 2536, "code": "public Map<String, Object> getAdminConfigs(final String clientId) {\n    final Map<String, Object> clientProvidedProps = getClientPropsWithPrefix(ADMIN_CLIENT_PREFIX, AdminClientConfig.configNames());\n\n    final Map<String, Object> props = new HashMap<>();\n    props.putAll(getClientCustomProps());\n    props.putAll(clientProvidedProps);\n\n        \n    props.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId);\n\n    return props;\n}", "summary_tokens": ["get", "the", "configs", "for", "the", "admin", "admin", "client"], "project": "kafka"}
{"id": 2548, "code": "public synchronized TopologyDescription describe() {\n    return internalTopologyBuilder.describe();\n}", "summary_tokens": ["returns", "a", "description", "of", "the", "specified", "topology"], "project": "kafka"}
{"id": 845, "code": "public static Frequencies forBooleanValues(MetricName falseMetricName, MetricName trueMetricName) {\n    List<Frequency> frequencies = new ArrayList<>();\n    if (falseMetricName != null) {\n        frequencies.add(new Frequency(falseMetricName, 0.0));\n    }\n    if (trueMetricName != null) {\n        frequencies.add(new Frequency(trueMetricName, 1.0));\n    }\n    if (frequencies.isEmpty()) {\n        throw new IllegalArgumentException(\"Must specify at least one metric name\");\n    }\n    Frequency[] frequencyArray = frequencies.toArray(new Frequency[0]);\n    return new Frequencies(2, 0.0, 1.0, frequencyArray);\n}", "summary_tokens": ["create", "a", "frequencies", "instance", "with", "metrics", "for", "the", "frequency", "of", "a", "boolean", "sensor", "that", "records", "0"], "project": "kafka"}
{"id": 2940, "code": "public boolean isUnbounded() {\n    return position.isEmpty();\n}", "summary_tokens": ["returns", "true", "iff", "this", "object", "specifies", "that", "there", "is", "no", "position", "bound"], "project": "kafka"}
{"id": 3045, "code": "public static long hash64(byte[] data, int offset, int length, int seed) {\n    long hash = seed;\n    final int nblocks = length >> 3;\n\n        \n    for (int i = 0; i < nblocks; i++) {\n        final int i8 = i << 3;\n        long k = ((long) data[offset + i8] & 0xff)\n                | (((long) data[offset + i8 + 1] & 0xff) << 8)\n                | (((long) data[offset + i8 + 2] & 0xff) << 16)\n                | (((long) data[offset + i8 + 3] & 0xff) << 24)\n                | (((long) data[offset + i8 + 4] & 0xff) << 32)\n                | (((long) data[offset + i8 + 5] & 0xff) << 40)\n                | (((long) data[offset + i8 + 6] & 0xff) << 48)\n                | (((long) data[offset + i8 + 7] & 0xff) << 56);\n\n            \n        k *= C1;\n        k = Long.rotateLeft(k, R1);\n        k *= C2;\n        hash ^= k;\n        hash = Long.rotateLeft(hash, R2) * M + N1;\n    }\n\n        \n    long k1 = 0;\n    int tailStart = nblocks << 3;\n    switch (length - tailStart) {\n        case 7:\n            k1 ^= ((long) data[offset + tailStart + 6] & 0xff) << 48;\n        case 6:\n            k1 ^= ((long) data[offset + tailStart + 5] & 0xff) << 40;\n        case 5:\n            k1 ^= ((long) data[offset + tailStart + 4] & 0xff) << 32;\n        case 4:\n            k1 ^= ((long) data[offset + tailStart + 3] & 0xff) << 24;\n        case 3:\n            k1 ^= ((long) data[offset + tailStart + 2] & 0xff) << 16;\n        case 2:\n            k1 ^= ((long) data[offset + tailStart + 1] & 0xff) << 8;\n        case 1:\n            k1 ^= ((long) data[offset + tailStart] & 0xff);\n            k1 *= C1;\n            k1 = Long.rotateLeft(k1, R1);\n            k1 *= C2;\n            hash ^= k1;\n    }\n\n        \n    hash ^= length;\n    hash = fmix64(hash);\n\n    return hash;\n}", "summary_tokens": ["murmur", "0", "0", "bit", "variant"], "project": "kafka"}
{"id": 752, "code": "private Map<String, ConfigProvider> instantiateConfigProviders(Map<String, String> indirectConfigs, Map<String, ?> providerConfigProperties) {\n    final String configProviders = indirectConfigs.get(CONFIG_PROVIDERS_CONFIG);\n\n    if (configProviders == null || configProviders.isEmpty()) {\n        return Collections.emptyMap();\n    }\n\n    Map<String, String> providerMap = new HashMap<>();\n\n    for (String provider: configProviders.split(\",\")) {\n        String providerClass = providerClassProperty(provider);\n        if (indirectConfigs.containsKey(providerClass))\n            providerMap.put(provider, indirectConfigs.get(providerClass));\n\n    }\n        \n    Map<String, ConfigProvider> configProviderInstances = new HashMap<>();\n    for (Map.Entry<String, String> entry : providerMap.entrySet()) {\n        try {\n            String prefix = CONFIG_PROVIDERS_CONFIG + \".\" + entry.getKey() + CONFIG_PROVIDERS_PARAM;\n            Map<String, ?> configProperties = configProviderProperties(prefix, providerConfigProperties);\n            ConfigProvider provider = Utils.newInstance(entry.getValue(), ConfigProvider.class);\n            provider.configure(configProperties);\n            configProviderInstances.put(entry.getKey(), provider);\n        } catch (ClassNotFoundException e) {\n            log.error(\"Could not load config provider class \" + entry.getValue(), e);\n            throw new ConfigException(providerClassProperty(entry.getKey()), entry.getValue(), \"Could not load config provider class or one of its dependencies\");\n        }\n    }\n\n    return configProviderInstances;\n}", "summary_tokens": ["instantiates", "and", "configures", "the", "config", "providers"], "project": "kafka"}
{"id": 1660, "code": "public String name() {\n    return name;\n}", "summary_tokens": ["provides", "the", "name", "of", "the", "connector"], "project": "kafka"}
{"id": 880, "code": "public long write(ByteBuffer[] srcs, int offset, int length) throws IOException {\n    return socketChannel.write(srcs, offset, length);\n}", "summary_tokens": ["writes", "a", "sequence", "of", "bytes", "to", "this", "channel", "from", "the", "subsequence", "of", "the", "given", "buffers"], "project": "kafka"}
{"id": 562, "code": "public Long timestamp() {\n    return timestamp;\n}", "summary_tokens": ["the", "timestamp", "which", "is", "in", "milliseconds", "since", "epoch"], "project": "kafka"}
{"id": 1376, "code": "public void testMyTaggedStruct() {\n        \n    SimpleExampleMessageData.TaggedStruct myStruct =\n        new SimpleExampleMessageData.TaggedStruct().setStructId(\"abc\");\n    testRoundTrip(new SimpleExampleMessageData().setMyTaggedStruct(myStruct),\n        message -> assertEquals(myStruct, message.myTaggedStruct()), (short) 2);\n\n        \n    testRoundTrip(new SimpleExampleMessageData().setMyString(\"abc\"),\n        message -> assertEquals(\"abc\", message.myString()), (short) 1);\n    testRoundTrip(new SimpleExampleMessageData().setMyString(\"abc\"),\n        message -> assertEquals(\"abc\", message.myString()), (short) 2);\n}", "summary_tokens": ["check", "following", "cases", "0"], "project": "kafka"}
{"id": 399, "code": "public void seekToEnd(Collection<TopicPartition> partitions) {\n    if (partitions == null)\n        throw new IllegalArgumentException(\"Partitions collection cannot be null\");\n\n    acquireAndEnsureOpen();\n    try {\n        Collection<TopicPartition> parts = partitions.size() == 0 ? this.subscriptions.assignedPartitions() : partitions;\n        subscriptions.requestOffsetReset(parts, OffsetResetStrategy.LATEST);\n    } finally {\n        release();\n    }\n}", "summary_tokens": ["seek", "to", "the", "last", "offset", "for", "each", "of", "the", "given", "partitions"], "project": "kafka"}
{"id": 1169, "code": "public static OAuthBearerValidationResult validateClaimForExistenceAndType(OAuthBearerUnsecuredJws jwt,\n        boolean required, String claimName, Class<?>... allowedTypes) {\n    Object rawClaim = Objects.requireNonNull(jwt).rawClaim(Objects.requireNonNull(claimName));\n    if (rawClaim == null)\n        return required\n                ? OAuthBearerValidationResult.newFailure(String.format(\"Required claim missing: %s\", claimName))\n                : OAuthBearerValidationResult.newSuccess();\n    for (Class<?> allowedType : allowedTypes) {\n        if (allowedType != null && allowedType.isAssignableFrom(rawClaim.getClass()))\n            return OAuthBearerValidationResult.newSuccess();\n    }\n    return OAuthBearerValidationResult.newFailure(String.format(\"The %s claim had the incorrect type: %s\",\n            claimName, rawClaim.getClass().getSimpleName()));\n}", "summary_tokens": ["validate", "the", "given", "claim", "for", "existence", "and", "type"], "project": "kafka"}
{"id": 259, "code": "public KafkaFuture<List<String>> users() {\n    final KafkaFutureImpl<List<String>> retval = new KafkaFutureImpl<>();\n    dataFuture.whenComplete((data, throwable) -> {\n        if (throwable != null) {\n            retval.completeExceptionally(throwable);\n        } else {\n            retval.complete(data.results().stream()\n                    .filter(result -> result.errorCode() != Errors.RESOURCE_NOT_FOUND.code())\n                    .map(result -> result.user()).collect(Collectors.toList()));\n        }\n    });\n    return retval;\n}", "summary_tokens": ["a", "future", "indicating", "the", "distinct", "users", "that", "meet", "the", "request", "criteria", "and", "that", "have", "at", "least", "one", "credential"], "project": "kafka"}
{"id": 1247, "code": "public static void writeDouble(double value, ByteBuffer buffer) {\n    buffer.putDouble(value);\n}", "summary_tokens": ["write", "the", "given", "double", "following", "the", "double", "precision", "0", "bit", "format", "ieee", "0", "value", "into", "the", "buffer"], "project": "kafka"}
{"id": 2771, "code": "public StampedRecord poll(final long wallClockTime) {\n    final StampedRecord recordToReturn = headRecord;\n\n    consumedSensor.record(headRecordSizeInBytes, wallClockTime);\n\n    headRecord = null;\n    headRecordSizeInBytes = 0L;\n    partitionTime = Math.max(partitionTime, recordToReturn.timestamp);\n\n    updateHead();\n\n    return recordToReturn;\n}", "summary_tokens": ["get", "the", "next", "stamped", "record", "from", "the", "queue"], "project": "kafka"}
{"id": 1562, "code": "public void testServerSpecifiedSslEngineFactoryUsed() throws Exception {\n    File trustStoreFile = TestUtils.tempFile(\"truststore\", \".jks\");\n    Map<String, Object> serverSslConfig = sslConfigsBuilder(Mode.SERVER)\n            .createNewTrustStore(trustStoreFile)\n            .useClientCert(false)\n            .build();\n    serverSslConfig.put(SslConfigs.SSL_ENGINE_FACTORY_CLASS_CONFIG, TestSslUtils.TestSslEngineFactory.class);\n    SslFactory sslFactory = new SslFactory(Mode.SERVER);\n    sslFactory.configure(serverSslConfig);\n    assertTrue(sslFactory.sslEngineFactory() instanceof TestSslUtils.TestSslEngineFactory,\n        \"SslEngineFactory must be of expected type\");\n}", "summary_tokens": ["tests", "server", "side", "ssl"], "project": "kafka"}
{"id": 64, "code": "public synchronized void maybeThrowAnyException() {\n    clearErrorsAndMaybeThrowException(this::recoverableException);\n}", "summary_tokens": ["if", "any", "non", "retriable", "exceptions", "were", "encountered", "during", "metadata", "update", "clear", "and", "throw", "the", "exception"], "project": "kafka"}
{"id": 1973, "code": "public static <K, V> KafkaBasedLog<K, V> withExistingClients(String topic,\n                                                             Consumer<K, V> consumer,\n                                                             Producer<K, V> producer,\n                                                             TopicAdmin topicAdmin,\n                                                             Callback<ConsumerRecord<K, V>> consumedCallback,\n                                                             Time time,\n                                                             java.util.function.Consumer<TopicAdmin> initializer) {\n    Objects.requireNonNull(topicAdmin);\n    return new KafkaBasedLog<K, V>(topic,\n            Collections.emptyMap(),\n            Collections.emptyMap(),\n            () -> topicAdmin,\n            consumedCallback,\n            time,\n            initializer) {\n\n        @Override\n        protected Producer<K, V> createProducer() {\n            return producer;\n        }\n\n        @Override\n        protected Consumer<K, V> createConsumer() {\n            return consumer;\n        }\n    };\n}", "summary_tokens": ["create", "a", "new", "kafka", "based", "log", "object", "using", "pre", "existing", "kafka", "clients"], "project": "kafka"}
{"id": 354, "code": "public ScramCredentialInfo credentialInfo() {\n    return info;\n}", "summary_tokens": ["the", "mechanism", "and", "iterations"], "project": "kafka"}
{"id": 207, "code": "public DeleteAclsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}", "summary_tokens": ["set", "the", "timeout", "in", "milliseconds", "for", "this", "operation", "or", "null", "if", "the", "default", "api", "timeout", "for", "the", "admin", "client", "should", "be", "used"], "project": "kafka"}
{"id": 1735, "code": "protected ProducerRecord<byte[], byte[]> convertTransformedRecord(SourceRecord record) {\n    if (record == null) {\n        return null;\n    }\n\n    RecordHeaders headers = retryWithToleranceOperator.execute(() -> convertHeaderFor(record), Stage.HEADER_CONVERTER, headerConverter.getClass());\n\n    byte[] key = retryWithToleranceOperator.execute(() -> keyConverter.fromConnectData(record.topic(), headers, record.keySchema(), record.key()),\n            Stage.KEY_CONVERTER, keyConverter.getClass());\n\n    byte[] value = retryWithToleranceOperator.execute(() -> valueConverter.fromConnectData(record.topic(), headers, record.valueSchema(), record.value()),\n            Stage.VALUE_CONVERTER, valueConverter.getClass());\n\n    if (retryWithToleranceOperator.failed()) {\n        return null;\n    }\n\n    return new ProducerRecord<>(record.topic(), record.kafkaPartition(),\n            ConnectUtils.checkAndConvertTimestamp(record.timestamp()), key, value, headers);\n}", "summary_tokens": ["convert", "the", "source", "record", "into", "a", "producer", "record"], "project": "kafka"}
{"id": 652, "code": "private void sendProduceRequest(long now, int destination, short acks, int timeout, List<ProducerBatch> batches) {\n    if (batches.isEmpty())\n        return;\n\n    final Map<TopicPartition, ProducerBatch> recordsByPartition = new HashMap<>(batches.size());\n\n        \n    byte minUsedMagic = apiVersions.maxUsableProduceMagic();\n    for (ProducerBatch batch : batches) {\n        if (batch.magic() < minUsedMagic)\n            minUsedMagic = batch.magic();\n    }\n    ProduceRequestData.TopicProduceDataCollection tpd = new ProduceRequestData.TopicProduceDataCollection();\n    for (ProducerBatch batch : batches) {\n        TopicPartition tp = batch.topicPartition;\n        MemoryRecords records = batch.records();\n\n            \n            \n            \n            \n            \n            \n            \n        if (!records.hasMatchingMagic(minUsedMagic))\n            records = batch.records().downConvert(minUsedMagic, 0, time).records();\n        ProduceRequestData.TopicProduceData tpData = tpd.find(tp.topic());\n        if (tpData == null) {\n            tpData = new ProduceRequestData.TopicProduceData().setName(tp.topic());\n            tpd.add(tpData);\n        }\n        tpData.partitionData().add(new ProduceRequestData.PartitionProduceData()\n                .setIndex(tp.partition())\n                .setRecords(records));\n        recordsByPartition.put(tp, batch);\n    }\n\n    String transactionalId = null;\n    if (transactionManager != null && transactionManager.isTransactional()) {\n        transactionalId = transactionManager.transactionalId();\n    }\n\n    ProduceRequest.Builder requestBuilder = ProduceRequest.forMagic(minUsedMagic,\n            new ProduceRequestData()\n                    .setAcks(acks)\n                    .setTimeoutMs(timeout)\n                    .setTransactionalId(transactionalId)\n                    .setTopicData(tpd));\n    RequestCompletionHandler callback = response -> handleProduceResponse(response, recordsByPartition, time.milliseconds());\n\n    String nodeId = Integer.toString(destination);\n    ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0,\n            requestTimeoutMs, callback);\n    client.send(clientRequest, now);\n    log.trace(\"Sent produce request to {}: {}\", nodeId, requestBuilder);\n}", "summary_tokens": ["create", "a", "produce", "request", "from", "the", "given", "record", "batches"], "project": "kafka"}
{"id": 1639, "code": "public static String convertToString(Schema schema, Object value) {\n    return (String) convertTo(Schema.OPTIONAL_STRING_SCHEMA, schema, value);\n}", "summary_tokens": ["convert", "the", "specified", "value", "to", "an", "type", "string", "value"], "project": "kafka"}
{"id": 3036, "code": "public static <V1, V2> LeftOrRightValue<V1, V2> makeLeftValue(final V1 leftValue) {\n    return new LeftOrRightValue<>(leftValue, null);\n}", "summary_tokens": ["create", "a", "new", "left", "or", "right", "value", "instance", "with", "the", "v", "0", "value", "as", "left", "value", "and", "v", "0", "value", "as", "null"], "project": "kafka"}
{"id": 1354, "code": "public void testBufferExhaustedExceptionIsThrown() throws Exception {\n    BufferPool pool = new BufferPool(2, 1, metrics, time, metricGroup);\n    pool.allocate(1, maxBlockTimeMs);\n    assertThrows(BufferExhaustedException.class, () -> pool.allocate(2, maxBlockTimeMs));\n}", "summary_tokens": ["test", "if", "buffer", "exhausted", "exception", "is", "thrown", "when", "there", "is", "not", "enough", "memory", "to", "allocate", "and", "the", "elapsed", "time", "is", "greater", "than", "the", "max", "specified", "block", "time"], "project": "kafka"}
{"id": 678, "code": "public String group() {\n    return this.group;\n}", "summary_tokens": ["get", "the", "name", "of", "the", "group"], "project": "kafka"}
{"id": 810, "code": "public List<S> partitionStateValues() {\n    return new ArrayList<>(map.values());\n}", "summary_tokens": ["returns", "the", "partition", "state", "values", "in", "order"], "project": "kafka"}
{"id": 1631, "code": "public static long fromLogical(Schema schema, java.util.Date value) {\n    if (!(LOGICAL_NAME.equals(schema.name())))\n        throw new DataException(\"Requested conversion of Timestamp object but the schema does not match.\");\n    return value.getTime();\n}", "summary_tokens": ["convert", "a", "value", "from", "its", "logical", "format", "date", "to", "it", "s", "encoded", "format"], "project": "kafka"}
{"id": 231, "code": "public KafkaFuture<String> clusterId() {\n    return clusterId;\n}", "summary_tokens": ["returns", "a", "future", "which", "yields", "the", "current", "cluster", "id"], "project": "kafka"}
{"id": 569, "code": "public int serializedValueSize() {\n    return this.serializedValueSize;\n}", "summary_tokens": ["the", "size", "of", "the", "serialized", "uncompressed", "value", "in", "bytes"], "project": "kafka"}
{"id": 2067, "code": "public int timesRevoked(TopicPartition partition) {\n    return partitions.computeIfAbsent(partition, PartitionHistory::new).timesRevoked();\n}", "summary_tokens": ["returns", "the", "number", "of", "times", "the", "partition", "has", "been", "revoked", "from", "this", "sink", "task"], "project": "kafka"}
{"id": 935, "code": "public int numFields() {\n    return this.fields.size();\n}", "summary_tokens": ["the", "number", "of", "tagged", "fields"], "project": "kafka"}
{"id": 240, "code": "public DescribeDelegationTokenOptions owners(List<KafkaPrincipal> owners) {\n    this.owners = owners;\n    return this;\n}", "summary_tokens": ["if", "owners", "is", "null", "all", "the", "user", "owned", "tokens", "and", "tokens", "where", "user", "have", "describe", "permission", "will", "be", "returned"], "project": "kafka"}
{"id": 765, "code": "public String toHtmlTable(Map<String, String> dynamicUpdateModes) {\n    boolean hasUpdateModes = !dynamicUpdateModes.isEmpty();\n    List<ConfigKey> configs = sortedConfigs();\n    StringBuilder b = new StringBuilder();\n    b.append(\"<table class=\\\"data-table\\\"><tbody>\\n\");\n    b.append(\"<tr>\\n\");\n        \n    for (String headerName : headers()) {\n        addHeader(b, headerName);\n    }\n    if (hasUpdateModes)\n        addHeader(b, \"Dynamic Update Mode\");\n    b.append(\"</tr>\\n\");\n    for (ConfigKey key : configs) {\n        if (key.internalConfig) {\n            continue;\n        }\n        b.append(\"<tr>\\n\");\n            \n        for (String headerName : headers()) {\n            addColumnValue(b, getConfigValue(key, headerName));\n            b.append(\"</td>\");\n        }\n        if (hasUpdateModes) {\n            String updateMode = dynamicUpdateModes.get(key.name);\n            if (updateMode == null)\n                updateMode = \"read-only\";\n            addColumnValue(b, updateMode);\n        }\n        b.append(\"</tr>\\n\");\n    }\n    b.append(\"</tbody></table>\");\n    return b.toString();\n}", "summary_tokens": ["converts", "this", "config", "into", "an", "html", "table", "that", "can", "be", "embedded", "into", "docs"], "project": "kafka"}
{"id": 3118, "code": "public void finalResultsShouldDropTombstonesForTimeWindows() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(finalResults(ofMillis(0L)), timeWindowedSerdeFrom(String.class, 100L), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final Windowed<String> key = new Windowed<>(\"hey\", new TimeWindow(0, 100L));\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(0));\n}", "summary_tokens": ["it", "s", "desirable", "to", "drop", "tombstones", "for", "final", "results", "windowed", "streams", "since", "as", "described", "in", "the", "suppressed", "internal", "javadoc", "they", "are", "unnecessary", "to", "emit"], "project": "kafka"}
{"id": 1796, "code": "public String bootstrapServers() {\n    return String.join(\",\", getList(BOOTSTRAP_SERVERS_CONFIG));\n}", "summary_tokens": ["the", "common", "client", "configs", "bootstrap", "servers", "config", "bootstrap", "servers", "property", "used", "by", "the", "worker", "when", "instantiating", "kafka", "clients", "for", "connectors", "and", "tasks", "unless", "overridden", "and", "its", "internal", "topics", "if", "running", "in", "distributed", "mode"], "project": "kafka"}
{"id": 2139, "code": "protected Optional<Boolean> checkBrokersUp(int numBrokers, BiFunction<Integer, Integer, Boolean> comp) {\n    try {\n        int numRunning = connect.kafka().runningBrokers().size();\n        return Optional.of(comp.apply(numRunning, numBrokers));\n    } catch (Exception e) {\n        log.error(\"Could not check running brokers.\", e);\n        return Optional.empty();\n    }\n}", "summary_tokens": ["confirm", "that", "the", "requested", "number", "of", "brokers", "are", "up", "and", "running"], "project": "kafka"}
{"id": 3006, "code": "public Serde<V> valueSerde() {\n    return valueSerde;\n}", "summary_tokens": ["return", "the", "value", "serde"], "project": "kafka"}
{"id": 1009, "code": "private static FilterResult filterTo(TopicPartition partition, Iterable<MutableRecordBatch> batches,\n                                     RecordFilter filter, ByteBuffer destinationBuffer, int maxRecordBatchSize,\n                                     BufferSupplier decompressionBufferSupplier) {\n    FilterResult filterResult = new FilterResult(destinationBuffer);\n    ByteBufferOutputStream bufferOutputStream = new ByteBufferOutputStream(destinationBuffer);\n    for (MutableRecordBatch batch : batches) {\n        final BatchRetentionResult batchRetentionResult = filter.checkBatchRetention(batch);\n        final boolean containsMarkerForEmptyTxn = batchRetentionResult.containsMarkerForEmptyTxn;\n        final BatchRetention batchRetention = batchRetentionResult.batchRetention;\n\n        filterResult.bytesRead += batch.sizeInBytes();\n\n        if (batchRetention == BatchRetention.DELETE)\n            continue;\n\n            \n            \n            \n            \n        byte batchMagic = batch.magic();\n        List<Record> retainedRecords = new ArrayList<>();\n\n        final BatchFilterResult iterationResult = filterBatch(batch, decompressionBufferSupplier, filterResult, filter,\n                batchMagic, true, retainedRecords);\n        boolean containsTombstones = iterationResult.containsTombstones;\n        boolean writeOriginalBatch = iterationResult.writeOriginalBatch;\n        long maxOffset = iterationResult.maxOffset;\n\n        if (!retainedRecords.isEmpty()) {\n                \n                \n                \n            boolean needToSetDeleteHorizon = batch.magic() >= RecordBatch.MAGIC_VALUE_V2 && (containsTombstones || containsMarkerForEmptyTxn)\n                && !batch.deleteHorizonMs().isPresent();\n            if (writeOriginalBatch && !needToSetDeleteHorizon) {\n                batch.writeTo(bufferOutputStream);\n                filterResult.updateRetainedBatchMetadata(batch, retainedRecords.size(), false);\n            } else {\n                final MemoryRecordsBuilder builder;\n                long deleteHorizonMs;\n                if (needToSetDeleteHorizon)\n                    deleteHorizonMs = filter.currentTime + filter.deleteRetentionMs;\n                else\n                    deleteHorizonMs = batch.deleteHorizonMs().orElse(RecordBatch.NO_TIMESTAMP);\n                builder = buildRetainedRecordsInto(batch, retainedRecords, bufferOutputStream, deleteHorizonMs);\n\n                MemoryRecords records = builder.build();\n                int filteredBatchSize = records.sizeInBytes();\n                if (filteredBatchSize > batch.sizeInBytes() && filteredBatchSize > maxRecordBatchSize)\n                    log.warn(\"Record batch from {} with last offset {} exceeded max record batch size {} after cleaning \" +\n                                    \"(new size is {}). Consumers with version earlier than 0.10.1.0 may need to \" +\n                                    \"increase their fetch sizes.\",\n                            partition, batch.lastOffset(), maxRecordBatchSize, filteredBatchSize);\n\n                MemoryRecordsBuilder.RecordsInfo info = builder.info();\n                filterResult.updateRetainedBatchMetadata(info.maxTimestamp, info.shallowOffsetOfMaxTimestamp,\n                        maxOffset, retainedRecords.size(), filteredBatchSize);\n            }\n        } else if (batchRetention == BatchRetention.RETAIN_EMPTY) {\n            if (batchMagic < RecordBatch.MAGIC_VALUE_V2)\n                throw new IllegalStateException(\"Empty batches are only supported for magic v2 and above\");\n\n            bufferOutputStream.ensureRemaining(DefaultRecordBatch.RECORD_BATCH_OVERHEAD);\n            DefaultRecordBatch.writeEmptyHeader(bufferOutputStream.buffer(), batchMagic, batch.producerId(),\n                    batch.producerEpoch(), batch.baseSequence(), batch.baseOffset(), batch.lastOffset(),\n                    batch.partitionLeaderEpoch(), batch.timestampType(), batch.maxTimestamp(),\n                    batch.isTransactional(), batch.isControlBatch());\n            filterResult.updateRetainedBatchMetadata(batch, 0, true);\n        }\n\n            \n            \n        ByteBuffer outputBuffer = bufferOutputStream.buffer();\n        if (outputBuffer != destinationBuffer) {\n            filterResult.outputBuffer = outputBuffer;\n            return filterResult;\n        }\n    }\n\n    return filterResult;\n}", "summary_tokens": ["note", "this", "method", "is", "also", "used", "to", "convert", "the", "first", "timestamp", "of", "the", "batch", "which", "is", "usually", "the", "timestamp", "of", "the", "first", "record", "to", "the", "delete", "horizon", "of", "the", "tombstones", "or", "txn", "markers", "which", "are", "present", "in", "the", "batch"], "project": "kafka"}
{"id": 919, "code": "public int numFields() {\n    return this.fields.length;\n}", "summary_tokens": ["the", "number", "of", "fields", "in", "this", "schema"], "project": "kafka"}
{"id": 548, "code": "public void close(Duration timeout) {\n    close(timeout, false);\n}", "summary_tokens": ["this", "method", "waits", "up", "to", "code", "timeout", "code", "for", "the", "producer", "to", "complete", "the", "sending", "of", "all", "incomplete", "requests"], "project": "kafka"}
{"id": 2337, "code": "public long baseOffset() {\n    return baseOffset;\n}", "summary_tokens": ["the", "offset", "of", "the", "first", "record", "in", "the", "batch"], "project": "kafka"}
{"id": 2104, "code": "public void removeWorker(WorkerHandle worker) {\n    if (connectCluster.isEmpty()) {\n        throw new IllegalStateException(\"Cannot remove worker. Cluster is empty\");\n    }\n    stopWorker(worker);\n    connectCluster.remove(worker);\n}", "summary_tokens": ["decommission", "a", "specific", "worker", "from", "this", "connect", "cluster"], "project": "kafka"}
{"id": 2231, "code": "ControllerResult<Map<ConfigResource, ApiError>> legacyAlterConfigs(\n    Map<ConfigResource, Map<String, String>> newConfigs,\n    boolean newlyCreatedResource\n) {\n    List<ApiMessageAndVersion> outputRecords = new ArrayList<>();\n    Map<ConfigResource, ApiError> outputResults = new HashMap<>();\n    for (Entry<ConfigResource, Map<String, String>> resourceEntry :\n        newConfigs.entrySet()) {\n        legacyAlterConfigResource(resourceEntry.getKey(),\n            resourceEntry.getValue(),\n            newlyCreatedResource,\n            outputRecords,\n            outputResults);\n    }\n    return ControllerResult.atomicOf(outputRecords, outputResults);\n}", "summary_tokens": ["determine", "the", "result", "of", "applying", "a", "batch", "of", "legacy", "configuration", "changes"], "project": "kafka"}
{"id": 1675, "code": "public void initialize(SourceTaskContext context) {\n    this.context = context;\n}", "summary_tokens": ["initialize", "this", "source", "task", "with", "the", "specified", "context", "object"], "project": "kafka"}
{"id": 3062, "code": "public static String taskIDfromCacheName(final String cacheName) {\n    final String[] tokens = cacheName.split(\"-\", 2);\n    return tokens[0];\n}", "summary_tokens": ["given", "a", "cache", "name", "of", "the", "form", "taskid", "storename", "return", "the", "task", "id"], "project": "kafka"}
{"id": 2035, "code": "public void testPreflightValidation() {\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, \"1\");\n    props.put(TOPIC_CONFIG, \"topic\");\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n\n        \n    props.put(EXACTLY_ONCE_SUPPORT_CONFIG, \"required\");\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_NULL);\n    ConfigInfos validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    ConfigInfo propertyValidation = findConfigInfo(EXACTLY_ONCE_SUPPORT_CONFIG, validation);\n    assertFalse(\"Preflight validation for exactly-once support property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_UNSUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(EXACTLY_ONCE_SUPPORT_CONFIG, validation);\n    assertFalse(\"Preflight validation for exactly-once support property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_FAIL);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(EXACTLY_ONCE_SUPPORT_CONFIG, validation);\n    assertFalse(\"Preflight validation for exactly-once support property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_EXACTLY_ONCE_SUPPORT_CONFIG, MonitorableSourceConnector.EXACTLY_ONCE_SUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have zero errors\", 0, validation.errorCount());\n\n        \n    props.put(TRANSACTION_BOUNDARY_CONFIG, CONNECTOR.toString());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_NULL);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(TRANSACTION_BOUNDARY_CONFIG, validation);\n    assertFalse(\"Preflight validation for transaction boundary property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_UNSUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(TRANSACTION_BOUNDARY_CONFIG, validation);\n    assertFalse(\"Preflight validation for transaction boundary property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_FAIL);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have exactly one error\", 1, validation.errorCount());\n    propertyValidation = findConfigInfo(TRANSACTION_BOUNDARY_CONFIG, validation);\n    assertFalse(\"Preflight validation for transaction boundary property should have at least one error message\",\n            propertyValidation.configValue().errors().isEmpty());\n\n        \n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_SUPPORTED);\n    validation = connect.validateConnectorConfig(MonitorableSourceConnector.class.getSimpleName(), props);\n    assertEquals(\"Preflight validation should have zero errors\", 0, validation.errorCount());\n}", "summary_tokens": ["a", "simple", "test", "for", "the", "pre", "flight", "validation", "api", "for", "connectors", "to", "provide", "their", "own", "delivery", "guarantees"], "project": "kafka"}
{"id": 194, "code": "public Map<String, KafkaFuture<Void>> values() {\n    return values;\n}", "summary_tokens": ["return", "a", "map", "from", "topic", "names", "to", "futures", "which", "can", "be", "used", "to", "check", "the", "status", "of", "individual", "partition", "creations"], "project": "kafka"}
{"id": 515, "code": "public <S> RequestFuture<S> compose(final RequestFutureAdapter<T, S> adapter) {\n    final RequestFuture<S> adapted = new RequestFuture<>();\n    addListener(new RequestFutureListener<T>() {\n        @Override\n        public void onSuccess(T value) {\n            adapter.onSuccess(value, adapted);\n        }\n\n        @Override\n        public void onFailure(RuntimeException e) {\n            adapter.onFailure(e, adapted);\n        }\n    });\n    return adapted;\n}", "summary_tokens": ["convert", "from", "a", "request", "future", "of", "one", "type", "to", "another", "type", "adapter", "the", "adapter", "which", "does", "the", "conversion", "s", "the", "type", "of", "the", "future", "adapted", "to", "the", "new", "future"], "project": "kafka"}
{"id": 1878, "code": "public void currentContext(Stage stage, Class<?> klass) {\n    position(stage);\n    executingClass(klass);\n}", "summary_tokens": ["a", "helper", "method", "to", "set", "both", "the", "stage", "and", "the", "class"], "project": "kafka"}
{"id": 1512, "code": "public void testInvalidLoginModule() throws Exception {\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_CLIENT, \"InvalidLoginModule\", TestJaasConfig.defaultClientOptions());\n\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    server = createEchoServer(securityProtocol);\n    try {\n        createSelector(securityProtocol, saslClientConfigs);\n        fail(\"SASL/PLAIN channel created without valid login module\");\n    } catch (KafkaException e) {\n            \n    }\n}", "summary_tokens": ["tests", "that", "connections", "cannot", "be", "created", "if", "the", "login", "module", "class", "is", "unavailable"], "project": "kafka"}
{"id": 2492, "code": "public <T> T store(final StoreQueryParameters<T> storeQueryParameters) {\n    validateIsRunningOrRebalancing();\n    final String storeName = storeQueryParameters.storeName();\n    if (!topologyMetadata.hasStore(storeName)) {\n        throw new UnknownStateStoreException(\n            \"Cannot get state store \" + storeName + \" because no such store is registered in the topology.\"\n        );\n    }\n    return queryableStoreProvider.getStore(storeQueryParameters);\n}", "summary_tokens": ["get", "a", "facade", "wrapping", "the", "local", "state", "store", "instances", "with", "the", "provided", "store", "query", "parameters"], "project": "kafka"}
{"id": 300, "code": "public KafkaFuture<Collection<TopicListing>> listings() {\n    return future.thenApply(namesToDescriptions -> namesToDescriptions.values());\n}", "summary_tokens": ["return", "a", "future", "which", "yields", "a", "collection", "of", "topic", "listing", "objects"], "project": "kafka"}
{"id": 516, "code": "synchronized int assignmentId() {\n    return assignmentId;\n}", "summary_tokens": ["monotonically", "increasing", "id", "which", "is", "incremented", "after", "every", "assignment", "change"], "project": "kafka"}
{"id": 285, "code": "public KafkaFuture<Map<TopicPartition, OffsetAndMetadata>> partitionsToOffsetAndMetadata(String groupId) {\n    if (!futures.containsKey(groupId))\n        throw new IllegalArgumentException(\"Offsets for consumer group '\" + groupId + \"' were not requested.\");\n    return futures.get(groupId);\n}", "summary_tokens": ["return", "a", "future", "which", "yields", "a", "map", "of", "topic", "partitions", "to", "offset", "and", "metadata", "objects", "for", "the", "specified", "group"], "project": "kafka"}
{"id": 3042, "code": "public KeyValueIterator<Bytes, byte[]> reverseAll() {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support reverseAll() function.\");\n}", "summary_tokens": ["unsupported", "operation", "exception", "at", "every", "invocation"], "project": "kafka"}
{"id": 2748, "code": "public Map<TaskId, Set<TopicPartition>> partitionGroups(final Map<Subtopology, Set<String>> topicGroups, final Cluster metadata) {\n    final Map<TaskId, Set<TopicPartition>> groups = new HashMap<>();\n\n    for (final Map.Entry<Subtopology, Set<String>> entry : topicGroups.entrySet()) {\n        final Subtopology subtopology = entry.getKey();\n        final Set<String> topicGroup = entry.getValue();\n\n        final int maxNumPartitions = maxNumPartitions(metadata, topicGroup);\n\n        for (int partitionId = 0; partitionId < maxNumPartitions; partitionId++) {\n            final Set<TopicPartition> group = new HashSet<>(topicGroup.size());\n\n            for (final String topic : topicGroup) {\n                final List<PartitionInfo> partitions = metadata.partitionsForTopic(topic);\n                if (partitionId < partitions.size()) {\n                    group.add(new TopicPartition(topic, partitionId));\n                }\n            }\n            groups.put(new TaskId(subtopology.nodeGroupId, partitionId, subtopology.namedTopology), Collections.unmodifiableSet(group));\n        }\n    }\n\n    return Collections.unmodifiableMap(groups);\n}", "summary_tokens": ["generate", "tasks", "with", "the", "assigned", "topic", "partitions"], "project": "kafka"}
{"id": 2399, "code": "private Optional<Batch<T>> nextBatch() {\n    while (iterator.hasNext()) {\n        Batch<T> batch = iterator.next();\n\n        if (!lastContainedLogTimestamp.isPresent()) {\n                \n                \n            lastContainedLogTimestamp = OptionalLong.of(batch.appendTimestamp());\n        }\n\n        if (!batch.records().isEmpty()) {\n            return Optional.of(batch);\n        }\n    }\n\n    return Optional.empty();\n}", "summary_tokens": ["returns", "the", "next", "non", "control", "batch"], "project": "kafka"}
{"id": 1986, "code": "public TopicAdmin get() {\n    return topicAdmin();\n}", "summary_tokens": ["get", "the", "shared", "topic", "admin", "instance"], "project": "kafka"}
{"id": 3248, "code": "public static <T> HttpResponse<T> httpRequest(Logger logger, String url, String method,\n        Object requestBodyData, TypeReference<T> responseFormat, int maxTries)\n        throws IOException, InterruptedException {\n    IOException exc = null;\n    for (int tries = 0; tries < maxTries; tries++) {\n        if (tries > 0) {\n            Thread.sleep(tries > 1 ? 10 : 2);\n        }\n        try {\n            return httpRequest(logger, url, method, requestBodyData, responseFormat);\n        } catch (IOException e) {\n            logger.info(\"{} {}: error: {}\", method, url, e.getMessage());\n            exc = e;\n        }\n    }\n    throw exc;\n}", "summary_tokens": ["make", "an", "http", "request", "with", "retries"], "project": "kafka"}
{"id": 211, "code": "public KafkaFuture<Void> all() {\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n\n    this.future.whenComplete((topicPartitions, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else {\n            for (TopicPartition partition : partitions) {\n                if (maybeCompleteExceptionally(topicPartitions, partition, result)) {\n                    return;\n                }\n            }\n            result.complete(null);\n        }\n    });\n    return result;\n}", "summary_tokens": ["return", "a", "future", "which", "succeeds", "only", "if", "all", "the", "deletions", "succeed"], "project": "kafka"}
{"id": 693, "code": "public static TopicNameCollection ofTopicNames(Collection<String> topics) {\n    return new TopicNameCollection(topics);\n}", "summary_tokens": ["a", "collection", "of", "topics", "defined", "by", "topic", "name"], "project": "kafka"}
{"id": 2165, "code": "public static WorkerHandle start(String name, Map<String, String> workerProperties) {\n    return new WorkerHandle(name, new ConnectDistributed().startConnect(workerProperties));\n}", "summary_tokens": ["create", "and", "start", "a", "new", "worker", "with", "the", "given", "properties"], "project": "kafka"}
{"id": 2929, "code": "public K getKey() {\n    return key;\n}", "summary_tokens": ["the", "key", "that", "was", "specified", "for", "this", "query"], "project": "kafka"}
{"id": 3005, "code": "public Serde<K> keySerde() {\n    return keySerde;\n}", "summary_tokens": ["return", "the", "key", "serde"], "project": "kafka"}
{"id": 93, "code": "private void handleTimedOutConnections(List<ClientResponse> responses, long now) {\n    List<String> nodes = connectionStates.nodesWithConnectionSetupTimeout(now);\n    for (String nodeId : nodes) {\n        this.selector.close(nodeId);\n        log.info(\n            \"Disconnecting from node {} due to socket connection setup timeout. \" +\n            \"The timeout value is {} ms.\",\n            nodeId,\n            connectionStates.connectionSetupTimeoutMs(nodeId));\n        processDisconnection(responses, nodeId, now, ChannelState.LOCAL_CLOSE);\n    }\n}", "summary_tokens": ["handle", "socket", "channel", "connection", "timeout"], "project": "kafka"}
{"id": 1807, "code": "protected void poll(long timeoutMs) {\n    rewind();\n    long retryTimeout = context.timeout();\n    if (retryTimeout > 0) {\n        timeoutMs = Math.min(timeoutMs, retryTimeout);\n        context.timeout(-1L);\n    }\n\n    log.trace(\"{} Polling consumer with timeout {} ms\", this, timeoutMs);\n    ConsumerRecords<byte[], byte[]> msgs = pollConsumer(timeoutMs);\n    assert messageBatch.isEmpty() || msgs.isEmpty();\n    log.trace(\"{} Polling returned {} messages\", this, msgs.count());\n\n    convertMessages(msgs);\n    deliverMessages();\n}", "summary_tokens": ["poll", "for", "new", "messages", "with", "the", "given", "timeout"], "project": "kafka"}
{"id": 2857, "code": "void commitOffsetsOrTransaction(final Map<Task, Map<TopicPartition, OffsetAndMetadata>> offsetsPerTask) {\n    log.debug(\"Committing task offsets {}\", offsetsPerTask.entrySet().stream().collect(Collectors.toMap(t -> t.getKey().id(), Entry::getValue))); \n\n    final Set<TaskId> corruptedTasks = new HashSet<>();\n\n    if (!offsetsPerTask.isEmpty()) {\n        if (executionMetadata.processingMode() == EXACTLY_ONCE_ALPHA) {\n            for (final Map.Entry<Task, Map<TopicPartition, OffsetAndMetadata>> taskToCommit : offsetsPerTask.entrySet()) {\n                final Task task = taskToCommit.getKey();\n                try {\n                    taskManager.streamsProducerForTask(task.id())\n                        .commitTransaction(taskToCommit.getValue(), taskManager.mainConsumer().groupMetadata());\n                    updateTaskCommitMetadata(taskToCommit.getValue());\n                } catch (final TimeoutException timeoutException) {\n                    log.error(\n                        String.format(\"Committing task %s failed.\", task.id()),\n                        timeoutException\n                    );\n                    corruptedTasks.add(task.id());\n                }\n            }\n        } else {\n            final Map<TopicPartition, OffsetAndMetadata> allOffsets = offsetsPerTask.values().stream()\n                .flatMap(e -> e.entrySet().stream()).collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n            if (executionMetadata.processingMode() == EXACTLY_ONCE_V2) {\n                try {\n                    taskManager.threadProducer().commitTransaction(allOffsets, taskManager.mainConsumer().groupMetadata());\n                    updateTaskCommitMetadata(allOffsets);\n                } catch (final TimeoutException timeoutException) {\n                    log.error(\n                        String.format(\"Committing task(s) %s failed.\",\n                            offsetsPerTask\n                                .keySet()\n                                .stream()\n                                .map(t -> t.id().toString())\n                                .collect(Collectors.joining(\", \"))),\n                        timeoutException\n                    );\n                    offsetsPerTask\n                        .keySet()\n                        .forEach(task -> corruptedTasks.add(task.id()));\n                }\n            } else {\n                try {\n                    taskManager.mainConsumer().commitSync(allOffsets);\n                    updateTaskCommitMetadata(allOffsets);\n                } catch (final CommitFailedException error) {\n                    throw new TaskMigratedException(\"Consumer committing offsets failed, \" +\n                        \"indicating the corresponding thread is no longer part of the group\", error);\n                } catch (final TimeoutException timeoutException) {\n                    log.error(\n                        String.format(\"Committing task(s) %s failed.\",\n                            offsetsPerTask\n                                .keySet()\n                                .stream()\n                                .map(t -> t.id().toString())\n                                .collect(Collectors.joining(\", \"))),\n                        timeoutException\n                    );\n                    throw timeoutException;\n                } catch (final KafkaException error) {\n                    throw new StreamsException(\"Error encountered committing offsets via consumer\", error);\n                }\n            }\n        }\n\n        if (!corruptedTasks.isEmpty()) {\n            throw new TaskCorruptedException(corruptedTasks);\n        }\n    }\n}", "summary_tokens": ["caution", "do", "not", "invoke", "this", "directly", "if", "it", "s", "possible", "a", "rebalance", "is", "occurring", "as", "the", "commit", "will", "fail"], "project": "kafka"}
{"id": 965, "code": "public File file() {\n    return file;\n}", "summary_tokens": ["get", "the", "underlying", "file"], "project": "kafka"}
{"id": 183, "code": "public ConsumerGroupState state() {\n    return state;\n}", "summary_tokens": ["the", "consumer", "group", "state", "or", "unknown", "if", "the", "state", "is", "too", "new", "for", "us", "to", "parse"], "project": "kafka"}
{"id": 1305, "code": "public ResourcePattern resourcePattern() {\n    return resourcePattern;\n}", "summary_tokens": ["a", "non", "null", "resource", "pattern", "on", "which", "this", "action", "is", "being", "performed"], "project": "kafka"}
{"id": 1284, "code": "public static String desanitize(String name) {\n    try {\n        return URLDecoder.decode(name, StandardCharsets.UTF_8.name());\n    } catch (UnsupportedEncodingException e) {\n        throw new KafkaException(e);\n    }\n}", "summary_tokens": ["desanitize", "name", "that", "was", "url", "encoded", "using", "sanitize", "string"], "project": "kafka"}
{"id": 315, "code": "public Optional<String> groupInstanceId() {\n    return groupInstanceId;\n}", "summary_tokens": ["the", "instance", "id", "of", "the", "group", "member"], "project": "kafka"}
{"id": 1623, "code": "public <T> List<T> getArray(String fieldName) {\n    return (List<T>) getCheckType(fieldName, Schema.Type.ARRAY);\n}", "summary_tokens": ["equivalent", "to", "calling", "get", "string", "and", "casting", "the", "result", "to", "a", "list"], "project": "kafka"}
{"id": 486, "code": "protected boolean hasCompletedFetches() {\n    return !completedFetches.isEmpty();\n}", "summary_tokens": ["return", "whether", "we", "have", "any", "completed", "fetches", "pending", "return", "to", "the", "user"], "project": "kafka"}
{"id": 1498, "code": "public void testScramUsernameWithSpecialCharacters() throws Exception {\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    String username = \"special user= test,scram\";\n    String password = username + \"-password\";\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Arrays.asList(\"SCRAM-SHA-256\"));\n    Map<String, Object> options = new HashMap<>();\n    options.put(\"username\", username);\n    options.put(\"password\", password);\n    jaasConfig.createOrUpdateEntry(TestJaasConfig.LOGIN_CONTEXT_CLIENT, ScramLoginModule.class.getName(), options);\n\n    server = createEchoServer(securityProtocol);\n    updateScramCredentialCache(username, password);\n    createAndCheckClientConnection(securityProtocol, \"0\");\n}", "summary_tokens": ["tests", "sasl", "scram", "with", "username", "containing", "characters", "that", "need", "to", "be", "encoded"], "project": "kafka"}
{"id": 531, "code": "public synchronized void updatePreferredReadReplica(TopicPartition tp, int preferredReadReplicaId, LongSupplier timeMs) {\n    assignedState(tp).updatePreferredReadReplica(preferredReadReplicaId, timeMs);\n}", "summary_tokens": ["set", "the", "preferred", "read", "replica", "with", "a", "lease", "timeout"], "project": "kafka"}
{"id": 459, "code": "public boolean refreshCommittedOffsetsIfNeeded(Timer timer) {\n    final Set<TopicPartition> initializingPartitions = subscriptions.initializingPartitions();\n\n    final Map<TopicPartition, OffsetAndMetadata> offsets = fetchCommittedOffsets(initializingPartitions, timer);\n    if (offsets == null) return false;\n\n    for (final Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n        final TopicPartition tp = entry.getKey();\n        final OffsetAndMetadata offsetAndMetadata = entry.getValue();\n        if (offsetAndMetadata != null) {\n                \n            entry.getValue().leaderEpoch().ifPresent(epoch -> this.metadata.updateLastSeenEpochIfNewer(entry.getKey(), epoch));\n\n                \n                \n            if (this.subscriptions.isAssigned(tp)) {\n                final ConsumerMetadata.LeaderAndEpoch leaderAndEpoch = metadata.currentLeader(tp);\n                final SubscriptionState.FetchPosition position = new SubscriptionState.FetchPosition(\n                        offsetAndMetadata.offset(), offsetAndMetadata.leaderEpoch(),\n                        leaderAndEpoch);\n\n                this.subscriptions.seekUnvalidated(tp, position);\n\n                log.info(\"Setting offset for partition {} to the committed offset {}\", tp, position);\n            } else {\n                log.info(\"Ignoring the returned {} since its partition {} is no longer assigned\",\n                    offsetAndMetadata, tp);\n            }\n        }\n    }\n    return true;\n}", "summary_tokens": ["refresh", "the", "committed", "offsets", "for", "provided", "partitions"], "project": "kafka"}
{"id": 1001, "code": "public ByteBuffer key() {\n    if (magic() == RecordBatch.MAGIC_VALUE_V0)\n        return Utils.sizeDelimited(buffer, KEY_SIZE_OFFSET_V0);\n    else\n        return Utils.sizeDelimited(buffer, KEY_SIZE_OFFSET_V1);\n}", "summary_tokens": ["a", "byte", "buffer", "containing", "the", "message", "key", "the", "buffer", "or", "null", "if", "the", "key", "for", "this", "record", "is", "null"], "project": "kafka"}
{"id": 1571, "code": "public static Properties consumerConfig(final String bootstrapServers, final Class<?> keyDeserializer, final Class<?> valueDeserializer) {\n    return consumerConfig(bootstrapServers,\n        UUID.randomUUID().toString(),\n        keyDeserializer,\n        valueDeserializer,\n        new Properties());\n}", "summary_tokens": ["returns", "consumer", "config", "with", "random", "uuid", "for", "the", "group", "id"], "project": "kafka"}
{"id": 2991, "code": "public static <K, V> QueryableStoreType<ReadOnlyWindowStore<K, ValueAndTimestamp<V>>> timestampedWindowStore() {\n    return new TimestampedWindowStoreType<>();\n}", "summary_tokens": ["a", "queryable", "store", "type", "that", "accepts", "read", "only", "window", "store", "read", "only", "window", "store", "k", "value", "and", "timestamp", "v"], "project": "kafka"}
{"id": 1076, "code": "public PatternType patternType() {\n    return patternType;\n}", "summary_tokens": ["the", "resource", "pattern", "type"], "project": "kafka"}
{"id": 3127, "code": "public void testFallbackPriorTaskAssignorLargePartitionCount() {\n    completeLargeAssignment(2_000, 2, 1, 1, FallbackPriorTaskAssignor.class);\n}", "summary_tokens": ["fallback", "prior", "task", "assignor", "tests"], "project": "kafka"}
{"id": 468, "code": "public RequestFuture<ClientResponse> send(Node node,\n                                          AbstractRequest.Builder<?> requestBuilder,\n                                          int requestTimeoutMs) {\n    long now = time.milliseconds();\n    RequestFutureCompletionHandler completionHandler = new RequestFutureCompletionHandler();\n    ClientRequest clientRequest = client.newClientRequest(node.idString(), requestBuilder, now, true,\n        requestTimeoutMs, completionHandler);\n    unsent.put(node, clientRequest);\n\n        \n    client.wakeup();\n    return completionHandler.future;\n}", "summary_tokens": ["send", "a", "new", "request"], "project": "kafka"}
{"id": 2333, "code": "public void testCommits() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(3, Optional.empty())) {\n        LeaderAndEpoch leaderInfo = env.waitForLeader();\n        int leaderId = leaderInfo.leaderId().orElseThrow(() ->\n            new AssertionError(\"Current leader is undefined\")\n        );\n\n        LocalLogManager activeLogManager = env.logManagers().get(leaderId);\n        int epoch = activeLogManager.leaderAndEpoch().epoch();\n        List<ApiMessageAndVersion> messages = Arrays.asList(\n            new ApiMessageAndVersion(new RegisterBrokerRecord().setBrokerId(0), (short) 0),\n            new ApiMessageAndVersion(new RegisterBrokerRecord().setBrokerId(1), (short) 0),\n            new ApiMessageAndVersion(new RegisterBrokerRecord().setBrokerId(2), (short) 0));\n        assertEquals(3, activeLogManager.scheduleAppend(epoch, messages));\n        for (LocalLogManager logManager : env.logManagers()) {\n            waitForLastCommittedOffset(3, logManager);\n        }\n        List<MockMetaLogManagerListener> listeners = env.logManagers().stream().\n            map(m -> (MockMetaLogManagerListener) m.listeners().get(0)).\n            collect(Collectors.toList());\n        env.close();\n        for (MockMetaLogManagerListener listener : listeners) {\n            List<String> events = listener.serializedEvents();\n            assertEquals(SHUTDOWN, events.get(events.size() - 1));\n            int foundIndex = 0;\n            for (String event : events) {\n                if (event.startsWith(COMMIT)) {\n                    assertEquals(messages.get(foundIndex).message().toString(),\n                        event.substring(COMMIT.length() + 1));\n                    foundIndex++;\n                }\n            }\n            assertEquals(messages.size(), foundIndex);\n        }\n    }\n}", "summary_tokens": ["test", "that", "all", "the", "log", "managers", "see", "all", "the", "commits"], "project": "kafka"}
{"id": 673, "code": "public SecurityProtocol securityProtocol() {\n    return securityProtocol;\n}", "summary_tokens": ["returns", "the", "security", "protocol", "of", "this", "endpoint"], "project": "kafka"}
{"id": 1160, "code": "private void handleExtensionsCallback(SaslExtensionsCallback callback) {\n    Map<String, String> extensions = new HashMap<>();\n    for (Map.Entry<String, String> configEntry : this.moduleOptions.entrySet()) {\n        String key = configEntry.getKey();\n        if (!key.startsWith(EXTENSION_PREFIX))\n            continue;\n\n        extensions.put(key.substring(EXTENSION_PREFIX.length()), configEntry.getValue());\n    }\n\n    SaslExtensions saslExtensions = new SaslExtensions(extensions);\n    try {\n        OAuthBearerClientInitialResponse.validateExtensions(saslExtensions);\n    } catch (SaslException e) {\n        throw new ConfigException(e.getMessage());\n    }\n\n    callback.extensions(saslExtensions);\n}", "summary_tokens": ["add", "and", "validate", "all", "the", "configured", "extensions"], "project": "kafka"}
{"id": 2344, "code": "public boolean isBackingOff() {\n    return isBackingOff;\n}", "summary_tokens": ["check", "if", "the", "candidate", "is", "backing", "off", "for", "the", "next", "election"], "project": "kafka"}
{"id": 1828, "code": "private void writeToConfigTopicAsLeader(Runnable write) {\n    try {\n        write.run();\n    } catch (PrivilegedWriteException e) {\n        log.warn(\"Failed to write to config topic as leader; will rejoin group if necessary and, if still leader, attempt to reclaim write privileges for the config topic\", e);\n        fencedFromConfigTopic = true;\n        throw new ConnectException(\"Failed to write to config topic; this may be due to a transient error and the request can be safely retried\", e);\n    }\n}", "summary_tokens": ["perform", "an", "action", "that", "writes", "to", "the", "config", "topic", "and", "if", "it", "fails", "because", "the", "leader", "has", "been", "fenced", "out", "make", "note", "of", "that", "fact", "so", "that", "we", "can", "try", "to", "reclaim", "write", "ownership", "if", "still", "the", "leader", "of", "the", "cluster", "in", "a", "subsequent", "iteration", "of", "the", "tick", "loop"], "project": "kafka"}
{"id": 77, "code": "public boolean ready(Node node, long now) {\n    if (node.isEmpty())\n        throw new IllegalArgumentException(\"Cannot connect to empty node \" + node);\n\n    if (isReady(node, now))\n        return true;\n\n    if (connectionStates.canConnect(node.idString(), now))\n            \n        initiateConnect(node, now);\n\n    return false;\n}", "summary_tokens": ["begin", "connecting", "to", "the", "given", "node", "return", "true", "if", "we", "are", "already", "connected", "and", "ready", "to", "send", "to", "that", "node"], "project": "kafka"}
{"id": 1233, "code": "public int initialCapacity() {\n    return initialCapacity;\n}", "summary_tokens": ["the", "capacity", "of", "the", "first", "internal", "byte", "buffer", "used", "by", "this", "class"], "project": "kafka"}
{"id": 1412, "code": "public void testClientAuthenticationRequiredNotProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    verifySslConfigsWithHandshakeFailure(args);\n}", "summary_tokens": ["tests", "that", "server", "does", "not", "accept", "connections", "from", "clients", "which", "don", "t", "provide", "a", "certificate", "when", "client", "authentication", "is", "required"], "project": "kafka"}
{"id": 336, "code": "public KafkaFuture<Void> all() {\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n    this.future.whenComplete((memberErrors, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else {\n            if (removeAll()) {\n                for (Map.Entry<MemberIdentity, Errors> entry: memberErrors.entrySet()) {\n                    Exception exception = entry.getValue().exception();\n                    if (exception != null) {\n                        Throwable ex = new KafkaException(\"Encounter exception when trying to remove: \"\n                                + entry.getKey(), exception);\n                        result.completeExceptionally(ex);\n                        return;\n                    }\n                }\n            } else {\n                for (MemberToRemove memberToRemove : memberInfos) {\n                    if (maybeCompleteExceptionally(memberErrors, memberToRemove.toMemberIdentity(), result)) {\n                        return;\n                    }\n                }\n            }\n            result.complete(null);\n        }\n    });\n    return result;\n}", "summary_tokens": ["returns", "a", "future", "which", "indicates", "whether", "the", "request", "was", "0", "success", "i"], "project": "kafka"}
{"id": 1367, "code": "public void testInitProducerIdWithMaxInFlightOne() throws Exception {\n    final long producerId = 123456L;\n    createMockClientWithMaxFlightOneMetadataPending();\n\n        \n        \n    TransactionManager transactionManager = new TransactionManager(new LogContext(), \"testInitProducerIdWithPendingMetadataRequest\",\n            60000, 100L, new ApiVersions());\n    setupWithTransactionState(transactionManager, false, null, false);\n    ProducerIdAndEpoch producerIdAndEpoch = new ProducerIdAndEpoch(producerId, (short) 0);\n    transactionManager.initializeTransactions();\n    sender.runOnce();\n\n        \n        \n    MetadataResponse metadataUpdate = RequestTestUtils.metadataUpdateWith(1, Collections.emptyMap());\n    client.respond(metadataUpdate);\n    prepareFindCoordinatorResponse(Errors.NONE, \"testInitProducerIdWithPendingMetadataRequest\");\n    prepareInitProducerResponse(Errors.NONE, producerIdAndEpoch.producerId, producerIdAndEpoch.epoch);\n    waitForProducerId(transactionManager, producerIdAndEpoch);\n}", "summary_tokens": ["verifies", "that", "init", "producer", "id", "of", "transactional", "producer", "succeeds", "even", "if", "metadata", "requests", "are", "pending", "with", "only", "one", "bootstrap", "node", "available", "and", "max", "in", "flight", "0", "where", "multiple", "polls", "are", "necessary", "to", "send", "requests"], "project": "kafka"}
{"id": 2526, "code": "public static String clientTagPrefix(final String clientTagKey) {\n    return CLIENT_TAG_PREFIX + clientTagKey;\n}", "summary_tokens": ["prefix", "a", "client", "tag", "key", "with", "client", "tag", "prefix"], "project": "kafka"}
{"id": 2233, "code": "default boolean isActive() {\n    return curClaimEpoch() != -1;\n}", "summary_tokens": ["returns", "true", "if", "this", "controller", "is", "currently", "active"], "project": "kafka"}
{"id": 1237, "code": "public static int readUnsignedIntLE(byte[] buffer, int offset) {\n    return (buffer[offset] << 0 & 0xff)\n            | ((buffer[offset + 1] & 0xff) << 8)\n            | ((buffer[offset + 2] & 0xff) << 16)\n            | ((buffer[offset + 3] & 0xff) << 24);\n}", "summary_tokens": ["read", "an", "unsigned", "integer", "stored", "in", "little", "endian", "format", "from", "a", "byte", "array", "at", "a", "given", "offset"], "project": "kafka"}
{"id": 732, "code": "public String findIndefiniteField() {\n    String indefinite = patternFilter.findIndefiniteField();\n    if (indefinite != null)\n        return indefinite;\n    return entryFilter.findIndefiniteField();\n}", "summary_tokens": ["return", "a", "string", "describing", "an", "any", "or", "unknown", "field", "or", "null", "if", "there", "is", "no", "such", "field"], "project": "kafka"}
{"id": 2100, "code": "private ListOffsetsResponse listOffsetsResult(ApiError error, Map<TopicPartition, Long> offsetsByPartitions) {\n    if (error == null) error = new ApiError(Errors.UNKNOWN_TOPIC_OR_PARTITION, \"unknown topic\");\n    List<ListOffsetsTopicResponse> tpResponses = new ArrayList<>();\n    for (TopicPartition partition : offsetsByPartitions.keySet()) {\n        Long offset = offsetsByPartitions.get(partition);\n        ListOffsetsTopicResponse topicResponse;\n        if (offset == null) {\n            topicResponse = ListOffsetsResponse.singletonListOffsetsTopicResponse(partition, error.error(), -1L, 0, 321);\n        } else {\n            topicResponse = ListOffsetsResponse.singletonListOffsetsTopicResponse(partition, Errors.NONE, -1L, offset, 321);\n        }\n        tpResponses.add(topicResponse);\n    }\n    ListOffsetsResponseData responseData = new ListOffsetsResponseData()\n            .setThrottleTimeMs(0)\n            .setTopics(tpResponses);\n\n    return new ListOffsetsResponse(responseData);\n}", "summary_tokens": ["create", "a", "list", "offset", "response", "that", "exposes", "the", "supplied", "error", "and", "includes", "offsets", "for", "the", "supplied", "partitions"], "project": "kafka"}
{"id": 1094, "code": "private boolean sendSaslClientToken(byte[] serverToken, boolean isInitial) throws IOException {\n    if (!saslClient.isComplete()) {\n        byte[] saslToken = createSaslToken(serverToken, isInitial);\n        if (saslToken != null) {\n            ByteBuffer tokenBuf = ByteBuffer.wrap(saslToken);\n            Send send;\n            if (saslAuthenticateVersion == DISABLE_KAFKA_SASL_AUTHENTICATE_HEADER) {\n                send = ByteBufferSend.sizePrefixed(tokenBuf);\n            } else {\n                SaslAuthenticateRequestData data = new SaslAuthenticateRequestData()\n                        .setAuthBytes(tokenBuf.array());\n                SaslAuthenticateRequest request = new SaslAuthenticateRequest.Builder(data).build(saslAuthenticateVersion);\n                send = request.toSend(nextRequestHeader(ApiKeys.SASL_AUTHENTICATE, saslAuthenticateVersion));\n            }\n            send(send);\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["sends", "a", "sasl", "client", "token", "to", "server", "if", "required"], "project": "kafka"}
{"id": 2081, "code": "public static String currentMetricValueAsString(ConnectMetrics metrics, MetricGroup metricGroup, String name) {\n    Object value = currentMetricValue(metrics, metricGroup, name);\n    return value instanceof String ? (String) value : null;\n}", "summary_tokens": ["get", "the", "current", "value", "of", "the", "named", "metric", "which", "may", "have", "already", "been", "removed", "from", "the", "org"], "project": "kafka"}
{"id": 749, "code": "public <T> T getConfiguredInstance(String key, Class<T> t, Map<String, Object> configOverrides) {\n    Class<?> c = getClass(key);\n\n    return getConfiguredInstance(c, t, originals(configOverrides));\n}", "summary_tokens": ["get", "a", "configured", "instance", "of", "the", "give", "class", "specified", "by", "the", "given", "configuration", "key"], "project": "kafka"}
{"id": 1611, "code": "public Schema schema() {\n    return schema;\n}", "summary_tokens": ["get", "the", "schema", "for", "this", "struct"], "project": "kafka"}
{"id": 901, "code": "public void addInterestOps(int ops) {\n    if (!key.isValid())\n        throw new CancelledKeyException();\n    else if (!ready())\n        throw new IllegalStateException(\"handshake is not completed\");\n\n    key.interestOps(key.interestOps() | ops);\n}", "summary_tokens": ["adds", "interest", "ops", "to", "selection", "key", "of", "the", "transport", "layer", "ops", "selection", "key", "interest", "ops"], "project": "kafka"}
{"id": 2789, "code": "boolean directoryForTaskIsEmpty(final TaskId taskId) {\n    final File taskDir = getOrCreateDirectoryForTask(taskId);\n\n    return taskDirIsEmpty(taskDir);\n}", "summary_tokens": ["decide", "if", "the", "directory", "of", "the", "task", "is", "empty", "or", "not"], "project": "kafka"}
{"id": 2087, "code": "private void assertTaskAllocations(int... taskCounts) {\n    assertAllocations(\"tasks\", ConnectorsAndTasks::tasks, taskCounts);\n}", "summary_tokens": ["assert", "that", "the", "task", "counts", "for", "each", "worker", "in", "the", "cluster", "match", "the", "expected", "counts"], "project": "kafka"}
{"id": 1400, "code": "private void injectNetworkReceive(KafkaChannel channel, int size) throws Exception {\n    NetworkReceive receive = new NetworkReceive();\n    TestUtils.setFieldValue(channel, \"receive\", receive);\n    ByteBuffer sizeBuffer = TestUtils.fieldValue(receive, NetworkReceive.class, \"size\");\n    sizeBuffer.putInt(size);\n    TestUtils.setFieldValue(receive, \"buffer\", ByteBuffer.allocate(size));\n}", "summary_tokens": ["injects", "a", "network", "receive", "for", "channel", "with", "size", "buffer", "filled", "in", "with", "the", "provided", "size", "and", "a", "payload", "buffer", "allocated", "with", "that", "size", "but", "no", "data", "in", "the", "payload", "buffer"], "project": "kafka"}
{"id": 869, "code": "public boolean maybeBeginServerReauthentication(NetworkReceive saslHandshakeNetworkReceive,\n        Supplier<Long> nowNanosSupplier) throws AuthenticationException, IOException {\n    if (!ready())\n        throw new IllegalStateException(\n                \"KafkaChannel should be \\\"ready\\\" when processing SASL Handshake for potential re-authentication\");\n        \n    if (authenticator.serverSessionExpirationTimeNanos() == null)\n        return false;\n        \n    long nowNanos = nowNanosSupplier.get();\n        \n    if (lastReauthenticationStartNanos != 0\n            && nowNanos - lastReauthenticationStartNanos < MIN_REAUTH_INTERVAL_ONE_SECOND_NANOS)\n        return false;\n    lastReauthenticationStartNanos = nowNanos;\n    swapAuthenticatorsAndBeginReauthentication(\n            new ReauthenticationContext(authenticator, saslHandshakeNetworkReceive, nowNanos));\n    return true;\n}", "summary_tokens": ["if", "this", "is", "a", "server", "side", "connection", "that", "has", "an", "expiration", "time", "and", "at", "least", "0", "second", "has", "passed", "since", "the", "prior", "re", "authentication", "if", "any", "started", "then", "begin", "the", "process", "of", "re", "authenticating", "the", "connection", "and", "return", "true", "otherwise", "return", "false"], "project": "kafka"}
{"id": 2004, "code": "public boolean isTopicCreationEnabled() {\n    return isTopicCreationEnabled;\n}", "summary_tokens": ["check", "whether", "topic", "creation", "is", "enabled", "for", "this", "utility", "instance"], "project": "kafka"}
{"id": 2465, "code": "public int segmentSizeInBytes() {\n    return segmentSizeInBytes;\n}", "summary_tokens": ["total", "size", "of", "this", "segment", "in", "bytes"], "project": "kafka"}
{"id": 181, "code": "public Collection<MemberDescription> members() {\n    return members;\n}", "summary_tokens": ["a", "list", "of", "the", "members", "of", "the", "consumer", "group"], "project": "kafka"}
{"id": 232, "code": "public KafkaFuture<Set<AclOperation>> authorizedOperations() {\n    return authorizedOperations;\n}", "summary_tokens": ["returns", "a", "future", "which", "yields", "authorized", "operations"], "project": "kafka"}
{"id": 614, "code": "public void close() {\n    for (ProducerInterceptor<K, V> interceptor : this.interceptors) {\n        try {\n            interceptor.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close producer interceptor \", e);\n        }\n    }\n}", "summary_tokens": ["closes", "every", "interceptor", "in", "a", "container"], "project": "kafka"}
{"id": 1550, "code": "public void savesCustomExtensionAsNegotiatedProperty() throws Exception {\n    Map<String, String> customExtensions = new HashMap<>();\n    customExtensions.put(\"firstKey\", \"value1\");\n    customExtensions.put(\"secondKey\", \"value2\");\n\n    byte[] nextChallenge = saslServer\n            .evaluateResponse(clientInitialResponse(null, false, customExtensions));\n\n    assertTrue(nextChallenge.length == 0, \"Next challenge is not empty\");\n    assertEquals(\"value1\", saslServer.getNegotiatedProperty(\"firstKey\"));\n    assertEquals(\"value2\", saslServer.getNegotiatedProperty(\"secondKey\"));\n}", "summary_tokens": ["sasl", "extensions", "that", "are", "validated", "by", "the", "callback", "handler", "should", "be", "accessible", "through", "the", "get", "negotiated", "property", "method"], "project": "kafka"}
{"id": 662, "code": "public List<Node> nodes() {\n    return this.nodes;\n}", "summary_tokens": ["the", "known", "set", "of", "nodes"], "project": "kafka"}
{"id": 839, "code": "private Object metricLock() {\n    return metricLock;\n}", "summary_tokens": ["kafka", "metrics", "of", "sensors", "which", "use", "sampled", "stat", "should", "be", "synchronized", "on", "the", "same", "lock", "for", "sensor", "record", "and", "metric", "value", "read", "to", "allow", "concurrent", "reads", "and", "updates"], "project": "kafka"}
{"id": 2623, "code": "public Repartitioned<K, V> withValueSerde(final Serde<V> valueSerde) {\n    return new Repartitioned<>(name, keySerde, valueSerde, numberOfPartitions, partitioner);\n}", "summary_tokens": ["create", "a", "new", "instance", "of", "repartitioned", "with", "the", "provided", "value", "serde"], "project": "kafka"}
{"id": 2134, "code": "public EmbeddedConnectClusterAssertions assertions() {\n    return assertions;\n}", "summary_tokens": ["return", "the", "available", "assertions", "for", "this", "connect", "cluster"], "project": "kafka"}
{"id": 3109, "code": "private static <K, V> KafkaConsumer<K, V> createConsumer(final Properties consumerConfig) {\n    final Properties filtered = new Properties();\n    filtered.putAll(consumerConfig);\n    filtered.setProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n    filtered.setProperty(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, \"true\");\n    return new KafkaConsumer<>(filtered);\n}", "summary_tokens": ["sets", "up", "a", "kafka", "consumer", "from", "a", "copy", "of", "the", "given", "configuration", "that", "has", "consumer", "config", "auto", "offset", "reset", "config", "set", "to", "earliest", "and", "consumer", "config", "enable", "auto", "commit", "config", "set", "to", "true", "to", "prevent", "missing", "events", "as", "well", "as", "repeat", "consumption"], "project": "kafka"}
{"id": 2985, "code": "public R getResult() {\n    return result;\n}", "summary_tokens": ["returns", "the", "result", "of", "executing", "the", "query", "on", "one", "partition"], "project": "kafka"}
{"id": 2541, "code": "private Map<String, Object> clientProps(final Set<String> configNames,\n                                        final Map<String, Object> originals) {\n        \n        \n    final Map<String, Object> parsed = new HashMap<>();\n    for (final String configName: configNames) {\n        if (originals.containsKey(configName)) {\n            parsed.put(configName, originals.get(configName));\n        }\n    }\n\n    return parsed;\n}", "summary_tokens": ["override", "any", "client", "properties", "in", "the", "original", "configs", "with", "overrides"], "project": "kafka"}
{"id": 565, "code": "public long offset() {\n    return this.offset;\n}", "summary_tokens": ["the", "offset", "of", "the", "record", "in", "the", "topic", "partition"], "project": "kafka"}
{"id": 101, "code": "public static NodeApiVersions create(short apiKey, short minVersion, short maxVersion) {\n    return create(Collections.singleton(new ApiVersion()\n            .setApiKey(apiKey)\n            .setMinVersion(minVersion)\n            .setMaxVersion(maxVersion)));\n}", "summary_tokens": ["create", "a", "node", "api", "versions", "object", "with", "a", "single", "api", "key"], "project": "kafka"}
{"id": 1617, "code": "public Long getInt64(String fieldName) {\n    return (Long) getCheckType(fieldName, Schema.Type.INT64);\n}", "summary_tokens": ["equivalent", "to", "calling", "get", "string", "and", "casting", "the", "result", "to", "a", "long"], "project": "kafka"}
{"id": 387, "code": "public int count() {\n    int count = 0;\n    for (List<ConsumerRecord<K, V>> recs: this.records.values())\n        count += recs.size();\n    return count;\n}", "summary_tokens": ["the", "number", "of", "records", "for", "all", "topics"], "project": "kafka"}
{"id": 3101, "code": "public static <K, V> List<KeyValue<K, V>> waitUntilFinalKeyValueRecordsReceived(final Properties consumerConfig,\n                                                                                final String topic,\n                                                                                final List<KeyValue<K, V>> expectedRecords,\n                                                                                final long waitTime) throws Exception {\n    return waitUntilFinalKeyValueRecordsReceived(consumerConfig, topic, expectedRecords, waitTime, false);\n}", "summary_tokens": ["wait", "until", "final", "key", "value", "mappings", "have", "been", "consumed"], "project": "kafka"}
{"id": 1434, "code": "public void testIOExceptionsDuringHandshakeRead(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, FailureAction.THROW_IO_EXCEPTION, FailureAction.NO_OP);\n}", "summary_tokens": ["tests", "that", "ioexceptions", "from", "read", "during", "ssl", "handshake", "are", "not", "treated", "as", "authentication", "failures"], "project": "kafka"}
{"id": 2396, "code": "public List<T> records() {\n    return records;\n}", "summary_tokens": ["get", "a", "list", "of", "the", "records", "appended", "to", "the", "batch"], "project": "kafka"}
{"id": 2150, "code": "public void assertConnectorAndTasksAreStopped(String connectorName, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorAndTasksAreStopped(connectorName),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"At least the connector or one of its tasks is still running\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "a", "connector", "and", "its", "tasks", "are", "not", "running"], "project": "kafka"}
{"id": 1961, "code": "private Set<Integer> taskIds(String connector, Map<ConnectorTaskId, Map<String, String>> configs) {\n    Set<Integer> tasks = new TreeSet<>();\n    if (configs == null) {\n        return tasks;\n    }\n    for (ConnectorTaskId taskId : configs.keySet()) {\n        assert taskId.connector().equals(connector);\n        tasks.add(taskId.task());\n    }\n    return tasks;\n}", "summary_tokens": ["given", "task", "configurations", "get", "a", "set", "of", "integer", "task", "ids", "for", "the", "connector"], "project": "kafka"}
{"id": 122, "code": "default DescribeReplicaLogDirsResult describeReplicaLogDirs(Collection<TopicPartitionReplica> replicas) {\n    return describeReplicaLogDirs(replicas, new DescribeReplicaLogDirsOptions());\n}", "summary_tokens": ["query", "the", "replica", "log", "directory", "information", "for", "the", "specified", "replicas"], "project": "kafka"}
{"id": 125, "code": "default CreateDelegationTokenResult createDelegationToken() {\n    return createDelegationToken(new CreateDelegationTokenOptions());\n}", "summary_tokens": ["create", "a", "delegation", "token"], "project": "kafka"}
{"id": 3050, "code": "public Map<TopicPartition, Long> read() throws IOException {\n    synchronized (lock) {\n        try (final BufferedReader reader = Files.newBufferedReader(file.toPath())) {\n            final int version = readInt(reader);\n            switch (version) {\n                case 0:\n                    int expectedSize = readInt(reader);\n                    final Map<TopicPartition, Long> offsets = new HashMap<>();\n                    String line = reader.readLine();\n                    while (line != null) {\n                        final String[] pieces = WHITESPACE_MINIMUM_ONCE.split(line);\n                        if (pieces.length != 3) {\n                            throw new IOException(\n                                String.format(\"Malformed line in offset checkpoint file: '%s'.\", line));\n                        }\n\n                        final String topic = pieces[0];\n                        final int partition = Integer.parseInt(pieces[1]);\n                        final TopicPartition tp = new TopicPartition(topic, partition);\n                        final long offset = Long.parseLong(pieces[2]);\n                        if (isValid(offset)) {\n                            offsets.put(tp, offset);\n                        } else {\n                            LOG.warn(\"Read offset={} from checkpoint file for {}\", offset, tp);\n                            --expectedSize;\n                        }\n\n                        line = reader.readLine();\n                    }\n                    if (offsets.size() != expectedSize) {\n                        throw new IOException(\n                            String.format(\"Expected %d entries but found only %d\", expectedSize, offsets.size()));\n                    }\n                    return offsets;\n\n                default:\n                    throw new IllegalArgumentException(\"Unknown offset checkpoint version: \" + version);\n            }\n        } catch (final NoSuchFileException e) {\n            return Collections.emptyMap();\n        }\n    }\n}", "summary_tokens": ["reads", "the", "offsets", "from", "the", "local", "checkpoint", "file", "skipping", "any", "negative", "offsets", "it", "finds"], "project": "kafka"}
{"id": 1668, "code": "public void open(Collection<TopicPartition> partitions) {\n    this.onPartitionsAssigned(partitions);\n}", "summary_tokens": ["the", "sink", "task", "use", "this", "method", "to", "create", "writers", "for", "newly", "assigned", "partitions", "in", "case", "of", "partition", "rebalance"], "project": "kafka"}
{"id": 3087, "code": "public void deleteAllTopicsAndWait(final long timeoutMs) throws InterruptedException {\n    final Set<String> topics = getAllTopicsInCluster();\n    for (final String topic : topics) {\n        try {\n            brokers[0].deleteTopic(topic);\n        } catch (final UnknownTopicOrPartitionException ignored) { }\n    }\n\n    if (timeoutMs > 0) {\n        TestUtils.waitForCondition(new TopicsDeletedCondition(topics), timeoutMs, \"Topics not deleted after \" + timeoutMs + \" milli seconds.\");\n    }\n}", "summary_tokens": ["deletes", "all", "topics", "and", "blocks", "until", "all", "topics", "got", "deleted"], "project": "kafka"}
{"id": 2113, "code": "public void pauseConnector(String connName) {\n    String url = endpointForResource(String.format(\"connectors/%s/pause\", connName));\n    Response response = requestPut(url, \"\");\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n            \"Could not execute PUT request. Error response: \" + responseToString(response));\n    }\n}", "summary_tokens": ["pause", "an", "existing", "connector"], "project": "kafka"}
{"id": 3147, "code": "public static void main(final String[] args) throws IOException {\n    if (args.length < 2) {\n        System.err.println(\"StreamsSmokeTest are expecting two parameters: propFile, command; but only see \" + args.length + \" parameter\");\n        Exit.exit(1);\n    }\n\n    final String propFileName = args[0];\n    final String command = args[1];\n    final boolean disableAutoTerminate = args.length > 2;\n\n    final Properties streamsProperties = Utils.loadProps(propFileName);\n    final String kafka = streamsProperties.getProperty(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG);\n    final String processingGuarantee = streamsProperties.getProperty(StreamsConfig.PROCESSING_GUARANTEE_CONFIG);\n\n    if (kafka == null) {\n        System.err.println(\"No bootstrap kafka servers specified in \" + StreamsConfig.BOOTSTRAP_SERVERS_CONFIG);\n        Exit.exit(1);\n    }\n\n    if (\"process\".equals(command)) {\n        if (!StreamsConfig.AT_LEAST_ONCE.equals(processingGuarantee) &&\n            !StreamsConfig.EXACTLY_ONCE_V2.equals(processingGuarantee)) {\n\n            System.err.println(\"processingGuarantee must be either \" + StreamsConfig.AT_LEAST_ONCE + \" or \" +\n                StreamsConfig.EXACTLY_ONCE_V2);\n\n            Exit.exit(1);\n        }\n    }\n\n    System.out.println(\"StreamsTest instance started (StreamsSmokeTest)\");\n    System.out.println(\"command=\" + command);\n    System.out.println(\"props=\" + streamsProperties);\n    System.out.println(\"disableAutoTerminate=\" + disableAutoTerminate);\n\n    switch (command) {\n        case \"run\":\n                \n            final int numKeys = 10;\n            final int maxRecordsPerKey = 500;\n            if (disableAutoTerminate) {\n                generatePerpetually(kafka, numKeys, maxRecordsPerKey);\n            } else {\n                    \n                    \n                final Map<String, Set<Integer>> allData =\n                    generate(kafka, numKeys, maxRecordsPerKey, Duration.ofSeconds(30));\n                SmokeTestDriver.verify(kafka, allData, maxRecordsPerKey);\n            }\n            break;\n        case \"process\":\n                \n            new SmokeTestClient(UUID.randomUUID().toString()).start(streamsProperties);\n            break;\n        default:\n            System.out.println(\"unknown command: \" + command);\n    }\n}", "summary_tokens": ["args", "kafka", "prop", "file", "name", "command", "disable", "auto", "terminate", "command", "run", "process"], "project": "kafka"}
{"id": 3057, "code": "public Set<String> stateStoreNames() {\n    return stateStoreNames;\n}", "summary_tokens": ["state", "stores", "owned", "by", "the", "instance", "as", "an", "active", "replica"], "project": "kafka"}
{"id": 1628, "code": "public static SchemaBuilder builder() {\n    return SchemaBuilder.int32()\n            .name(LOGICAL_NAME)\n            .version(1);\n}", "summary_tokens": ["returns", "a", "schema", "builder", "for", "a", "time"], "project": "kafka"}
{"id": 278, "code": "private static <K, V> void completeUnrealizedFutures(\n        Stream<Map.Entry<K, KafkaFutureImpl<V>>> futures,\n        Function<K, String> messageFormatter) {\n    futures.filter(entry -> !entry.getValue().isDone()).forEach(entry ->\n            entry.getValue().completeExceptionally(new ApiException(messageFormatter.apply(entry.getKey()))));\n}", "summary_tokens": ["fail", "futures", "in", "the", "given", "stream", "which", "are", "not", "done"], "project": "kafka"}
{"id": 1018, "code": "public void appendControlRecordWithOffset(long offset, SimpleRecord record) {\n    short typeId = ControlRecordType.parseTypeId(record.key());\n    ControlRecordType type = ControlRecordType.fromTypeId(typeId);\n    if (type == ControlRecordType.UNKNOWN)\n        throw new IllegalArgumentException(\"Cannot append record with unknown control record type \" + typeId);\n\n    appendWithOffset(offset, true, record.timestamp(),\n        record.key(), record.value(), record.headers());\n}", "summary_tokens": ["append", "a", "control", "record", "at", "the", "given", "offset"], "project": "kafka"}
{"id": 2146, "code": "public void assertConnectorAndExactlyNumTasksAreRunning(String connectorName, int numTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorState(\n                connectorName,\n                AbstractStatus.State.RUNNING,\n                numTasks,\n                AbstractStatus.State.RUNNING,\n                (actual, expected) -> actual == expected\n            ).orElse(false),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"The connector or exactly \" + numTasks + \" tasks are not running.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "a", "connector", "is", "running", "with", "at", "least", "the", "given", "number", "of", "tasks", "all", "in", "running", "state"], "project": "kafka"}
{"id": 1641, "code": "public static Map<?, ?> convertToMap(Schema schema, Object value) {\n    return (Map<?, ?>) convertTo(MAP_SELECTOR_SCHEMA, schema, value);\n}", "summary_tokens": ["convert", "the", "specified", "value", "to", "an", "type", "map", "value"], "project": "kafka"}
{"id": 2969, "code": "public QueryResult<R> getGlobalResult() {\n    return globalResult;\n}", "summary_tokens": ["the", "query", "s", "result", "for", "global", "store", "queries"], "project": "kafka"}
{"id": 987, "code": "public boolean isValid() {\n    return sizeInBytes() >= RECORD_OVERHEAD_V0 && checksum() == computeChecksum();\n}", "summary_tokens": ["returns", "true", "if", "the", "crc", "stored", "with", "the", "record", "matches", "the", "crc", "computed", "off", "the", "record", "contents"], "project": "kafka"}
{"id": 705, "code": "public int hashCode() {\n    long xor = mostSignificantBits ^ leastSignificantBits;\n    return (int) (xor >> 32) ^ (int) xor;\n}", "summary_tokens": ["returns", "a", "hash", "code", "for", "this", "uuid"], "project": "kafka"}
{"id": 789, "code": "public String resource() {\n    return this.resource;\n}", "summary_tokens": ["the", "potentially", "null", "resource", "that", "was", "not", "found"], "project": "kafka"}
{"id": 234, "code": "public DescribeConfigsOptions includeSynonyms(boolean includeSynonyms) {\n    this.includeSynonyms = includeSynonyms;\n    return this;\n}", "summary_tokens": ["set", "to", "true", "if", "synonym", "configs", "should", "be", "returned", "in", "the", "response"], "project": "kafka"}
{"id": 1595, "code": "public Schema schema() {\n    return schema;\n}", "summary_tokens": ["get", "the", "schema", "of", "this", "field", "the", "schema", "of", "values", "of", "this", "field"], "project": "kafka"}
{"id": 1111, "code": "public SaslExtensions inputExtensions() {\n    return inputExtensions;\n}", "summary_tokens": ["sasl", "extensions", "consisting", "of", "the", "unvalidated", "extension", "names", "and", "values", "that", "were", "sent", "by", "the", "client"], "project": "kafka"}
{"id": 81, "code": "public long pollDelayMs(Node node, long now) {\n    return connectionStates.pollDelayMs(node.idString(), now);\n}", "summary_tokens": ["return", "the", "poll", "delay", "in", "milliseconds", "based", "on", "both", "connection", "and", "throttle", "delay"], "project": "kafka"}
{"id": 785, "code": "public String toString() {\n    return HIDDEN;\n}", "summary_tokens": ["returns", "hidden", "password", "string"], "project": "kafka"}
{"id": 130, "code": "default ListConsumerGroupsResult listConsumerGroups() {\n    return listConsumerGroups(new ListConsumerGroupsOptions());\n}", "summary_tokens": ["list", "the", "consumer", "groups", "available", "in", "the", "cluster", "with", "the", "default", "options"], "project": "kafka"}
{"id": 731, "code": "public boolean matchesAtMostOne() {\n    return patternFilter.matchesAtMostOne() && entryFilter.matchesAtMostOne();\n}", "summary_tokens": ["return", "true", "if", "the", "resource", "and", "entry", "filters", "can", "only", "match", "one", "ace"], "project": "kafka"}
{"id": 296, "code": "public ListTopicsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}", "summary_tokens": ["set", "the", "timeout", "in", "milliseconds", "for", "this", "operation", "or", "null", "if", "the", "default", "api", "timeout", "for", "the", "admin", "client", "should", "be", "used"], "project": "kafka"}
{"id": 2673, "code": "public boolean overlap(final Window other) throws IllegalArgumentException {\n    if (getClass() != other.getClass()) {\n        throw new IllegalArgumentException(\"Cannot compare windows of different type. Other window has type \"\n            + other.getClass() + \".\");\n    }\n    final TimeWindow otherWindow = (TimeWindow) other;\n    return startMs < otherWindow.endMs && otherWindow.startMs < endMs;\n}", "summary_tokens": ["check", "if", "the", "given", "window", "overlaps", "with", "this", "window"], "project": "kafka"}
{"id": 2327, "code": "public void testMultiPartitionTopicPlacementOnSingleUnfencedBroker() {\n    MockRandom random = new MockRandom();\n    StripedReplicaPlacer placer = new StripedReplicaPlacer(random);\n    assertEquals(Arrays.asList(Arrays.asList(0),\n            Arrays.asList(0),\n            Arrays.asList(0)),\n            place(placer, 0, 3, (short) 1, Arrays.asList(\n                    new UsableBroker(0, Optional.empty(), false),\n                    new UsableBroker(1, Optional.empty(), true))));\n}", "summary_tokens": ["test", "that", "we", "perform", "striped", "replica", "placement", "as", "expected", "for", "a", "multi", "partition", "topic", "on", "a", "single", "unfenced", "broker"], "project": "kafka"}
{"id": 2092, "code": "public static void assertAvailable() throws AssertionError {\n    if (INITIALIZATION_EXCEPTION != null) {\n        throw new AssertionError(\"TestPlugins did not initialize completely\",\n            INITIALIZATION_EXCEPTION);\n    }\n    if (PLUGIN_JARS.isEmpty()) {\n        throw new AssertionError(\"No test plugins loaded\");\n    }\n}", "summary_tokens": ["ensure", "that", "the", "test", "plugin", "jars", "were", "assembled", "without", "error", "before", "continuing"], "project": "kafka"}
{"id": 2267, "code": "public static DescribeConfigsResponse.ConfigSource translateConfigSource(ConfigEntry.ConfigSource configSource) {\n    DescribeConfigsResponse.ConfigSource result = TRANSLATE_CONFIG_SOURCE_MAP.get(configSource);\n    if (result != null) return result;\n    return DescribeConfigsResponse.ConfigSource.UNKNOWN;\n}", "summary_tokens": ["translate", "a", "config", "entry"], "project": "kafka"}
{"id": 1374, "code": "private void testAllMessageRoundTripsBetweenVersions(short startVersion, short endVersion, Message message, Message expected) throws Exception {\n    for (short version = startVersion; version < endVersion; version++) {\n        testMessageRoundTrip(version, message, expected);\n    }\n}", "summary_tokens": ["start", "version", "the", "version", "we", "want", "to", "start", "at", "inclusive", "end", "version", "the", "version", "we", "want", "to", "end", "at", "exclusive"], "project": "kafka"}
{"id": 160, "code": "public KafkaFuture<Void> all() {\n    return this.future.thenApply(topicPartitionErrorsMap ->  {\n        List<TopicPartition> partitionsFailed = topicPartitionErrorsMap.entrySet()\n            .stream()\n            .filter(e -> e.getValue() != Errors.NONE)\n            .map(Map.Entry::getKey)\n            .collect(Collectors.toList());\n        for (Errors error : topicPartitionErrorsMap.values()) {\n            if (error != Errors.NONE) {\n                throw error.exception(\n                    \"Failed altering consumer group offsets for the following partitions: \" + partitionsFailed);\n            }\n        }\n        return null;\n    });\n}", "summary_tokens": ["return", "a", "future", "which", "succeeds", "if", "all", "the", "alter", "offsets", "succeed"], "project": "kafka"}
{"id": 1267, "code": "final public int size() {\n    return size;\n}", "summary_tokens": ["returns", "the", "number", "of", "elements", "in", "the", "set"], "project": "kafka"}
{"id": 1725, "code": "default boolean isHeartbeatsTopic(String topic) {\n    return heartbeatsTopic().equals(originalTopic(topic));\n}", "summary_tokens": ["check", "if", "topic", "is", "a", "heartbeat", "topic", "e"], "project": "kafka"}
{"id": 884, "code": "public void removeInterestOps(int ops) {\n    key.interestOps(key.interestOps() & ~ops);\n}", "summary_tokens": ["removes", "the", "interest", "ops", "from", "selection", "key"], "project": "kafka"}
{"id": 2330, "code": "public void testCreateAndClose() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(1, Optional.empty())) {\n        env.close();\n        assertEquals(null, env.firstError.get());\n    }\n}", "summary_tokens": ["test", "creating", "a", "local", "log", "manager", "and", "closing", "it"], "project": "kafka"}
{"id": 2500, "code": "public <R> StateQueryResult<R> query(final StateQueryRequest<R> request) {\n    final String storeName = request.getStoreName();\n    if (!topologyMetadata.hasStore(storeName)) {\n        throw new UnknownStateStoreException(\n            \"Cannot get state store \"\n                + storeName\n                + \" because no such store is registered in the topology.\"\n        );\n    }\n    if (state().hasNotStarted()) {\n        throw new StreamsNotStartedException(\n            \"KafkaStreams has not been started, you can retry after calling start().\"\n        );\n    }\n    if (state().isShuttingDown() || state.hasCompletedShutdown()) {\n        throw new StreamsStoppedException(\n            \"KafkaStreams has been stopped (\" + state + \").\"\n                + \" This instance can no longer serve queries.\"\n        );\n    }\n    final StateQueryResult<R> result = new StateQueryResult<>();\n\n    final Map<String, StateStore> globalStateStores = topologyMetadata.globalStateStores();\n    if (globalStateStores.containsKey(storeName)) {\n            \n        result.setGlobalResult(\n            QueryResult.forFailure(\n                FailureReason.UNKNOWN_QUERY_TYPE,\n                \"Global stores do not yet support the KafkaStreams#query API. Use KafkaStreams#store instead.\"\n            )\n        );\n    } else {\n        for (final StreamThread thread : threads) {\n            final Map<TaskId, Task> tasks = thread.allTasks();\n            for (final Entry<TaskId, Task> entry : tasks.entrySet()) {\n\n                final TaskId taskId = entry.getKey();\n                final int partition = taskId.partition();\n                if (request.isAllPartitions()\n                    || request.getPartitions().contains(partition)) {\n                    final Task task = entry.getValue();\n                    final StateStore store = task.getStore(storeName);\n                    if (store != null) {\n                        final StreamThread.State state = thread.state();\n                        final boolean active = task.isActive();\n                        if (request.isRequireActive()\n                            && (state != StreamThread.State.RUNNING\n                            || !active)) {\n                            result.addResult(\n                                partition,\n                                QueryResult.forFailure(\n                                    FailureReason.NOT_ACTIVE,\n                                    \"Query requires a running active task,\"\n                                        + \" but partition was in state \"\n                                        + state + \" and was \"\n                                        + (active ? \"active\" : \"not active\") + \".\"\n                                )\n                            );\n                        } else {\n                            final QueryResult<R> r = store.query(\n                                request.getQuery(),\n                                request.isRequireActive()\n                                    ? PositionBound.unbounded()\n                                    : request.getPositionBound(),\n                                new QueryConfig(request.executionInfoEnabled())\n                            );\n                            result.addResult(partition, r);\n                        }\n\n\n                            \n                            \n                        if (!request.isAllPartitions()\n                            && result.getPartitionResults().keySet().containsAll(request.getPartitions())) {\n                            return result;\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    if (!request.isAllPartitions()) {\n        for (final Integer partition : request.getPartitions()) {\n            if (!result.getPartitionResults().containsKey(partition)) {\n                result.addResult(partition, QueryResult.forFailure(\n                    FailureReason.NOT_PRESENT,\n                    \"The requested partition was not present at the time of the query.\"\n                ));\n            }\n        }\n    }\n\n    return result;\n}", "summary_tokens": ["run", "an", "interactive", "query", "against", "a", "state", "store"], "project": "kafka"}
{"id": 1341, "code": "public void testPendingMemberShouldLeaveGroup() {\n    final String consumerId = \"consumer-id\";\n    subscriptions.subscribe(singleton(topic1), rebalanceListener);\n\n    client.prepareResponse(groupCoordinatorResponse(node, Errors.NONE));\n    coordinator.ensureCoordinatorReady(time.timer(Long.MAX_VALUE));\n\n        \n    client.prepareResponse(joinGroupFollowerResponse(-1, consumerId, \"leader-id\", Errors.MEMBER_ID_REQUIRED));\n\n        \n    coordinator.joinGroupIfNeeded(time.timer(0));\n\n    final AtomicBoolean received = new AtomicBoolean(false);\n    client.prepareResponse(body -> {\n        received.set(true);\n        LeaveGroupRequest leaveRequest = (LeaveGroupRequest) body;\n        return validateLeaveGroup(groupId, consumerId, leaveRequest);\n    }, new LeaveGroupResponse(new LeaveGroupResponseData().setErrorCode(Errors.NONE.code())));\n\n    coordinator.maybeLeaveGroup(\"pending member leaves\");\n    assertTrue(received.get());\n}", "summary_tokens": ["this", "test", "checks", "if", "a", "consumer", "that", "has", "a", "valid", "member", "id", "but", "an", "invalid", "generation", "org"], "project": "kafka"}
{"id": 31, "code": "public long connectionSetupTimeoutMs(String id) {\n    NodeConnectionState nodeState = this.nodeState(id);\n    return nodeState.connectionSetupTimeoutMs;\n}", "summary_tokens": ["get", "the", "current", "socket", "connection", "setup", "timeout", "of", "the", "given", "node"], "project": "kafka"}
{"id": 513, "code": "public void complete(T value) {\n    try {\n        if (value instanceof RuntimeException)\n            throw new IllegalArgumentException(\"The argument to complete can not be an instance of RuntimeException\");\n\n        if (!result.compareAndSet(INCOMPLETE_SENTINEL, value))\n            throw new IllegalStateException(\"Invalid attempt to complete a request future which is already complete\");\n        fireSuccess();\n    } finally {\n        completedLatch.countDown();\n    }\n}", "summary_tokens": ["complete", "the", "request", "successfully"], "project": "kafka"}
{"id": 2521, "code": "public synchronized <KIn, VIn> StreamsBuilder addGlobalStore(final StoreBuilder<?> storeBuilder,\n                                                             final String topic,\n                                                             final Consumed<KIn, VIn> consumed,\n                                                             final ProcessorSupplier<KIn, VIn, Void, Void> stateUpdateSupplier) {\n    Objects.requireNonNull(storeBuilder, \"storeBuilder can't be null\");\n    Objects.requireNonNull(consumed, \"consumed can't be null\");\n    internalStreamsBuilder.addGlobalStore(\n        storeBuilder,\n        topic,\n        new ConsumedInternal<>(consumed),\n        stateUpdateSupplier\n    );\n    return this;\n}", "summary_tokens": ["adds", "a", "global", "state", "store", "to", "the", "topology"], "project": "kafka"}
{"id": 2265, "code": "public Map<Uuid, String> topicIdToNameView() {\n    return new TranslatedValueMapView<>(topicsById, image -> image.name());\n}", "summary_tokens": ["expose", "a", "view", "of", "this", "topics", "image", "as", "a", "map", "from", "ids", "to", "names"], "project": "kafka"}
{"id": 2130, "code": "public Response requestPost(String url, String body, Map<String, String> headers) {\n    return requestHttpMethod(url, body, headers, \"POST\");\n}", "summary_tokens": ["execute", "a", "post", "request", "on", "the", "given", "url"], "project": "kafka"}
{"id": 17, "code": "public boolean isReady(String id, long now) {\n    return isReady(nodeState.get(id), now);\n}", "summary_tokens": ["return", "true", "if", "the", "connection", "is", "in", "the", "ready", "state", "and", "currently", "not", "throttled"], "project": "kafka"}
{"id": 2515, "code": "public Integer partition() {\n    return partition;\n}", "summary_tokens": ["get", "the", "store", "partition", "that", "will", "be", "queried"], "project": "kafka"}
{"id": 1699, "code": "public int schemaCacheSize() {\n    return schemaCacheSize;\n}", "summary_tokens": ["get", "the", "cache", "size"], "project": "kafka"}
{"id": 1254, "code": "public static Bytes increment(Bytes input) throws IndexOutOfBoundsException {\n    byte[] inputArr = input.get();\n    byte[] ret = new byte[inputArr.length];\n    int carry = 1;\n    for (int i = inputArr.length - 1; i >= 0; i--) {\n        if (inputArr[i] == (byte) 0xFF && carry == 1) {\n            ret[i] = (byte) 0x00;\n        } else {\n            ret[i] = (byte) (inputArr[i] + carry);\n            carry = 0;\n        }\n    }\n    if (carry == 0) {\n        return wrap(ret);\n    } else {\n        throw new IndexOutOfBoundsException();\n    }\n}", "summary_tokens": ["increment", "the", "underlying", "byte", "array", "by", "adding", "0"], "project": "kafka"}
{"id": 910, "code": "public int zeroCopySize() {\n    return zeroCopySize;\n}", "summary_tokens": ["get", "the", "total", "zero", "copy", "size", "of", "the", "message"], "project": "kafka"}
{"id": 1462, "code": "public void testSearch() throws IOException {\n        \n    SimpleRecord lastMessage = new SimpleRecord(\"test\".getBytes());\n    fileRecords.append(MemoryRecords.withRecords(50L, CompressionType.NONE, lastMessage));\n\n    List<RecordBatch> batches = batches(fileRecords);\n    int position = 0;\n\n    int message1Size = batches.get(0).sizeInBytes();\n    assertEquals(new FileRecords.LogOffsetPosition(0L, position, message1Size),\n        fileRecords.searchForOffsetWithSize(0, 0),\n        \"Should be able to find the first message by its offset\");\n    position += message1Size;\n\n    int message2Size = batches.get(1).sizeInBytes();\n    assertEquals(new FileRecords.LogOffsetPosition(1L, position, message2Size),\n        fileRecords.searchForOffsetWithSize(1, 0),\n        \"Should be able to find second message when starting from 0\");\n    assertEquals(new FileRecords.LogOffsetPosition(1L, position, message2Size),\n        fileRecords.searchForOffsetWithSize(1, position),\n        \"Should be able to find second message starting from its offset\");\n    position += message2Size + batches.get(2).sizeInBytes();\n\n    int message4Size = batches.get(3).sizeInBytes();\n    assertEquals(new FileRecords.LogOffsetPosition(50L, position, message4Size),\n        fileRecords.searchForOffsetWithSize(3, position),\n        \"Should be able to find fourth message from a non-existent offset\");\n    assertEquals(new FileRecords.LogOffsetPosition(50L, position, message4Size),\n        fileRecords.searchForOffsetWithSize(50,  position),\n        \"Should be able to find fourth message by correct offset\");\n}", "summary_tokens": ["test", "the", "message", "set"], "project": "kafka"}
{"id": 971, "code": "public void flush() throws IOException {\n    channel.force(true);\n}", "summary_tokens": ["commit", "all", "written", "data", "to", "the", "physical", "disk"], "project": "kafka"}
{"id": 2153, "code": "public void assertConnectorActiveTopics(String connectorName, Collection<String> topics, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorActiveTopics(connectorName, topics).orElse(false),\n            CONNECT_INTERNAL_TOPIC_UPDATES_DURATION_MS,\n            \"Connector active topics don't match the expected collection\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "a", "connector", "s", "set", "of", "active", "topics", "matches", "the", "given", "collection", "of", "topic", "names"], "project": "kafka"}
{"id": 1960, "code": "public void putRestartRequest(RestartRequest restartRequest) {\n    log.debug(\"Writing {} to Kafka\", restartRequest);\n    String key = RESTART_KEY(restartRequest.connectorName());\n    Struct value = new Struct(RESTART_REQUEST_V0);\n    value.put(INCLUDE_TASKS_FIELD_NAME, restartRequest.includeTasks());\n    value.put(ONLY_FAILED_FIELD_NAME, restartRequest.onlyFailed());\n    byte[] serializedValue = converter.fromConnectData(topic, value.schema(), value);\n    try {\n        sendPrivileged(key, serializedValue);\n        configLog.readToEnd().get(READ_TO_END_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        log.error(\"Failed to write {} to Kafka: \", restartRequest, e);\n        throw new ConnectException(\"Error writing \" + restartRequest + \" to Kafka\", e);\n    }\n}", "summary_tokens": ["write", "a", "restart", "request", "for", "the", "connector", "and", "optionally", "its", "tasks", "to", "persistent", "storage", "and", "wait", "until", "it", "has", "been", "acknowledged", "and", "read", "back", "by", "tailing", "the", "kafka", "log", "with", "a", "consumer"], "project": "kafka"}
{"id": 491, "code": "private RequestFuture<ClientResponse> sendMetadataRequest(MetadataRequest.Builder request) {\n    final Node node = client.leastLoadedNode();\n    if (node == null)\n        return RequestFuture.noBrokersAvailable();\n    else\n        return client.send(node, request);\n}", "summary_tokens": ["send", "metadata", "request", "to", "least", "loaded", "node", "in", "kafka", "cluster", "asynchronously", "a", "future", "that", "indicates", "result", "of", "sent", "metadata", "request"], "project": "kafka"}
{"id": 1089, "code": "default void configure(Map<String, ?> config) {\n\n}", "summary_tokens": ["configure", "method", "is", "used", "to", "configure", "the", "generator", "to", "create", "the", "security", "provider", "config", "configuration", "parameters", "for", "initialising", "security", "provider"], "project": "kafka"}
{"id": 1823, "code": "public boolean transactionalLeaderEnabled() {\n    return exactlyOnceSourceSupport.usesTransactionalLeader;\n}", "summary_tokens": ["whether", "the", "connect", "cluster", "s", "leader", "should", "use", "a", "transactional", "producer", "to", "perform", "writes", "to", "the", "config", "topic", "which", "is", "useful", "for", "ensuring", "that", "zombie", "leaders", "are", "fenced", "out", "and", "unable", "to", "write", "to", "the", "topic", "after", "a", "new", "leader", "has", "been", "elected"], "project": "kafka"}
{"id": 2360, "code": "private Optional<Boolean> maybeHandleCommonResponse(\n    Errors error,\n    OptionalInt leaderId,\n    int epoch,\n    long currentTimeMs\n) {\n    if (epoch < quorum.epoch() || error == Errors.UNKNOWN_LEADER_EPOCH) {\n            \n        return Optional.of(true);\n    } else if (epoch > quorum.epoch()\n        || error == Errors.FENCED_LEADER_EPOCH\n        || error == Errors.NOT_LEADER_OR_FOLLOWER) {\n\n            \n            \n        maybeTransition(leaderId, epoch, currentTimeMs);\n        return Optional.of(true);\n    } else if (epoch == quorum.epoch()\n        && leaderId.isPresent()\n        && !quorum.hasLeader()) {\n\n            \n            \n            \n            \n            \n        transitionToFollower(epoch, leaderId.getAsInt(), currentTimeMs);\n        if (error == Errors.NONE) {\n            return Optional.empty();\n        } else {\n            return Optional.of(true);\n        }\n    } else if (error == Errors.BROKER_NOT_AVAILABLE) {\n        return Optional.of(false);\n    } else if (error == Errors.INCONSISTENT_GROUP_PROTOCOL) {\n            \n            \n            \n            \n        throw new IllegalStateException(\"Received error indicating inconsistent voter sets\");\n    } else if (error == Errors.INVALID_REQUEST) {\n        throw new IllegalStateException(\"Received unexpected invalid request error\");\n    }\n\n    return Optional.empty();\n}", "summary_tokens": ["handle", "response", "errors", "that", "are", "common", "across", "request", "types"], "project": "kafka"}
{"id": 2508, "code": "public long currentOffsetPosition() {\n    return this.currentOffsetPosition;\n}", "summary_tokens": ["get", "the", "current", "maximum", "offset", "on", "the", "store", "partition", "s", "changelog", "topic", "that", "has", "been", "successfully", "written", "into", "the", "store", "partition", "s", "state", "store"], "project": "kafka"}
{"id": 689, "code": "public Node[] replicas() {\n    return replicas;\n}", "summary_tokens": ["the", "complete", "set", "of", "replicas", "for", "this", "partition", "regardless", "of", "whether", "they", "are", "alive", "or", "up", "to", "date"], "project": "kafka"}
{"id": 1947, "code": "public static ConnectorOffsetBackingStore withOnlyConnectorStore(\n        Supplier<LoggingContext> loggingContext,\n        KafkaOffsetBackingStore connectorStore,\n        String connectorOffsetsTopic,\n        TopicAdmin connectorStoreAdmin\n) {\n    Objects.requireNonNull(loggingContext);\n    Objects.requireNonNull(connectorOffsetsTopic);\n    Objects.requireNonNull(connectorStoreAdmin);\n    return new ConnectorOffsetBackingStore(\n            Time.SYSTEM,\n            loggingContext,\n            connectorOffsetsTopic,\n            null,\n            connectorStore,\n            connectorStoreAdmin\n    );\n}", "summary_tokens": ["builds", "an", "offset", "store", "that", "uses", "a", "connector", "specific", "offset", "topic", "as", "the", "primary", "store", "and", "no", "secondary", "store"], "project": "kafka"}
{"id": 1971, "code": "public static void ensureProperty(\n        Map<String, ? super String> props,\n        String key,\n        String expectedValue,\n        String justification,\n        boolean caseSensitive\n) {\n    ensurePropertyAndGetWarning(props, key, expectedValue, justification, caseSensitive).ifPresent(log::warn);\n}", "summary_tokens": ["ensure", "that", "the", "map", "properties", "contain", "an", "expected", "value", "for", "the", "given", "key", "inserting", "the", "expected", "value", "into", "the", "properties", "if", "necessary"], "project": "kafka"}
{"id": 2815, "code": "public boolean maybePunctuateStreamTime() {\n    final long streamTime = partitionGroup.streamTime();\n\n        \n        \n    if (streamTime == RecordQueue.UNKNOWN) {\n        return false;\n    } else {\n        final boolean punctuated = streamTimePunctuationQueue.mayPunctuate(streamTime, PunctuationType.STREAM_TIME, this);\n\n        if (punctuated) {\n            commitNeeded = true;\n        }\n\n        return punctuated;\n    }\n}", "summary_tokens": ["possibly", "trigger", "registered", "stream", "time", "punctuation", "functions", "if", "current", "partition", "group", "timestamp", "has", "reached", "the", "defined", "stamp", "note", "this", "is", "only", "called", "in", "the", "presence", "of", "new", "records"], "project": "kafka"}
{"id": 3176, "code": "public void close() {\n    if (task != null) {\n        task.suspend();\n        task.prepareCommit();\n        task.postCommit(true);\n        task.closeClean();\n    }\n    if (globalStateTask != null) {\n        try {\n            globalStateTask.close(false);\n        } catch (final IOException e) {\n                \n        }\n    }\n    completeAllProcessableWork();\n    if (task != null && task.hasRecordsQueued()) {\n        log.warn(\"Found some records that cannot be processed due to the\" +\n                     \" {} configuration during TopologyTestDriver#close().\",\n                 StreamsConfig.MAX_TASK_IDLE_MS_CONFIG);\n    }\n    if (processingMode == AT_LEAST_ONCE) {\n        producer.close();\n    }\n    stateDirectory.clean();\n}", "summary_tokens": ["close", "the", "driver", "its", "topology", "and", "all", "processors"], "project": "kafka"}
{"id": 3089, "code": "public static <R> StateQueryResult<R> iqv2WaitForResult(\n    final KafkaStreams kafkaStreams,\n    final StateQueryRequest<R> request) {\n\n    final long start = System.currentTimeMillis();\n    final long deadline = start + DEFAULT_TIMEOUT;\n\n    StateQueryResult<R> result;\n    do {\n        if (Thread.currentThread().isInterrupted()) {\n            fail(\"Test was interrupted.\");\n        }\n\n        result = kafkaStreams.query(request);\n        final LinkedList<QueryResult<R>> allResults = getAllResults(result);\n\n        if (allResults.isEmpty()) {\n            sleep(100L);\n        } else {\n            final boolean needToWait = allResults\n                .stream()\n                .anyMatch(IntegrationTestUtils::needToWait);\n            if (needToWait) {\n                sleep(100L);\n            } else {\n                return result;\n            }\n        }\n    } while (System.currentTimeMillis() < deadline);\n\n    throw new TimeoutException(\n        \"The query never returned within the bound. Last result: \"\n        + result\n    );\n}", "summary_tokens": ["repeatedly", "runs", "the", "query", "until", "the", "response", "is", "valid", "and", "then", "return", "the", "response"], "project": "kafka"}
{"id": 2407, "code": "default void append(Event event) {\n    enqueue(EventInsertionType.APPEND, null, NoDeadlineFunction.INSTANCE, event);\n}", "summary_tokens": ["add", "an", "element", "to", "the", "end", "of", "the", "queue"], "project": "kafka"}
{"id": 1264, "code": "final public Iterator<E> iterator() {\n    return listIterator(0);\n}", "summary_tokens": ["returns", "an", "iterator", "that", "will", "yield", "every", "element", "in", "the", "set"], "project": "kafka"}
{"id": 33, "code": "public List<String> nodesWithConnectionSetupTimeout(long now) {\n    return connectingNodes.stream()\n        .filter(id -> isConnectionSetupTimeout(id, now))\n        .collect(Collectors.toList());\n}", "summary_tokens": ["return", "the", "list", "of", "nodes", "whose", "connection", "setup", "has", "timed", "out"], "project": "kafka"}
{"id": 2643, "code": "public StreamJoined<K, V1, V2> withLoggingDisabled() {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        false,\n        new HashMap<>()\n    );\n}", "summary_tokens": ["disable", "change", "logging", "for", "both", "state", "stores"], "project": "kafka"}
{"id": 2881, "code": "public boolean hasNamedTopologies() {\n    return !builders.containsKey(UNNAMED_TOPOLOGY);\n}", "summary_tokens": ["true", "iff", "the", "app", "is", "using", "named", "topologies", "or", "was", "started", "up", "with", "no", "topology", "at", "all"], "project": "kafka"}
{"id": 2073, "code": "public void recordTaskStop() {\n    startAndStopCounter.recordStop();\n}", "summary_tokens": ["record", "that", "this", "task", "has", "been", "stopped"], "project": "kafka"}
{"id": 2121, "code": "public String adminEndpoint(String resource) {\n    String url = connectCluster.stream()\n            .map(WorkerHandle::adminUrl)\n            .filter(Objects::nonNull)\n            .findFirst()\n            .orElseThrow(() -> new ConnectException(\"Admin endpoint is disabled.\"))\n            .toString();\n    return url + resource;\n}", "summary_tokens": ["get", "the", "full", "url", "of", "the", "admin", "endpoint", "that", "corresponds", "to", "the", "given", "rest", "resource"], "project": "kafka"}
{"id": 229, "code": "public KafkaFuture<Collection<Node>> nodes() {\n    return nodes;\n}", "summary_tokens": ["returns", "a", "future", "which", "yields", "a", "collection", "of", "nodes"], "project": "kafka"}
{"id": 417, "code": "private void acquire() {\n    long threadId = Thread.currentThread().getId();\n    if (threadId != currentThread.get() && !currentThread.compareAndSet(NO_CURRENT_THREAD, threadId))\n        throw new ConcurrentModificationException(\"KafkaConsumer is not safe for multi-threaded access\");\n    refcount.incrementAndGet();\n}", "summary_tokens": ["acquire", "the", "light", "lock", "protecting", "this", "consumer", "from", "multi", "threaded", "access"], "project": "kafka"}
{"id": 1749, "code": "public Collection<ConnectorTaskId> taskIdsToRestart() {\n    return idsToRestart;\n}", "summary_tokens": ["get", "the", "immutable", "collection", "of", "connector", "task", "id", "for", "all", "tasks", "to", "be", "restarted", "based", "upon", "the", "restart", "request", "restart", "request"], "project": "kafka"}
{"id": 1969, "code": "public synchronized void cancelFlush() {\n        \n        \n    if (flushing()) {\n            \n        toFlush.putAll(data);\n        data = toFlush;\n        currentFlushId++;\n        toFlush = null;\n    }\n}", "summary_tokens": ["cancel", "a", "flush", "that", "has", "been", "initiated", "by", "begin", "flush"], "project": "kafka"}
{"id": 2428, "code": "static String toRegularExpression(String glob) {\n    StringBuilder output = new StringBuilder(\"^\");\n    boolean literal = true;\n    boolean processingGroup = false;\n\n    for (int i = 0; i < glob.length(); ) {\n        char c = glob.charAt(i++);\n        switch (c) {\n            case '?':\n                literal = false;\n                output.append(\".\");\n                break;\n            case '*':\n                literal = false;\n                output.append(\".*\");\n                break;\n            case '\\\\':\n                if (i == glob.length()) {\n                    output.append(c);\n                } else {\n                    char next = glob.charAt(i);\n                    i++;\n                    if (isGlobSpecialCharacter(next) ||\n                            isRegularExpressionSpecialCharacter(next)) {\n                        output.append('\\\\');\n                    }\n                    output.append(next);\n                }\n                break;\n            case '{':\n                if (processingGroup) {\n                    throw new RuntimeException(\"Can't nest glob groups.\");\n                }\n                literal = false;\n                output.append(\"(?:(?:\");\n                processingGroup = true;\n                break;\n            case ',':\n                if (processingGroup) {\n                    literal = false;\n                    output.append(\")|(?:\");\n                } else {\n                    output.append(c);\n                }\n                break;\n            case '}':\n                if (processingGroup) {\n                    literal = false;\n                    output.append(\"))\");\n                    processingGroup = false;\n                } else {\n                    output.append(c);\n                }\n                break;\n                \n            default:\n                if (isRegularExpressionSpecialCharacter(c)) {\n                    output.append('\\\\');\n                }\n                output.append(c);\n        }\n    }\n    if (processingGroup) {\n        throw new RuntimeException(\"Unterminated glob group.\");\n    }\n    if (literal) {\n        return null;\n    }\n    output.append('$');\n    return output.toString();\n}", "summary_tokens": ["converts", "a", "glob", "string", "to", "a", "regular", "expression", "string"], "project": "kafka"}
{"id": 220, "code": "public Map<String, KafkaFuture<Void>> topicNameValues() {\n    return nameFutures;\n}", "summary_tokens": ["use", "when", "admin", "delete", "topics", "topic", "collection", "delete", "topics", "options", "used", "a", "topic", "name", "collection", "a", "map", "from", "topic", "names", "to", "futures", "which", "can", "be", "used", "to", "check", "the", "status", "of", "individual", "deletions", "if", "the", "delete", "topics", "request", "used", "topic", "names"], "project": "kafka"}
{"id": 607, "code": "private boolean done(\n    long baseOffset,\n    long logAppendTime,\n    RuntimeException topLevelException,\n    Function<Integer, RuntimeException> recordExceptions\n) {\n    final FinalState tryFinalState = (topLevelException == null) ? FinalState.SUCCEEDED : FinalState.FAILED;\n    if (tryFinalState == FinalState.SUCCEEDED) {\n        log.trace(\"Successfully produced messages to {} with base offset {}.\", topicPartition, baseOffset);\n    } else {\n        log.trace(\"Failed to produce messages to {} with base offset {}.\", topicPartition, baseOffset, topLevelException);\n    }\n\n    if (this.finalState.compareAndSet(null, tryFinalState)) {\n        completeFutureAndFireCallbacks(baseOffset, logAppendTime, recordExceptions);\n        return true;\n    }\n\n    if (this.finalState.get() != FinalState.SUCCEEDED) {\n        if (tryFinalState == FinalState.SUCCEEDED) {\n                \n            log.debug(\"ProduceResponse returned {} for {} after batch with base offset {} had already been {}.\",\n                tryFinalState, topicPartition, baseOffset, this.finalState.get());\n        } else {\n                \n            log.debug(\"Ignored state transition {} -> {} for {} batch with base offset {}\",\n                this.finalState.get(), tryFinalState, topicPartition, baseOffset);\n        }\n    } else {\n            \n        throw new IllegalStateException(\"A \" + this.finalState.get() + \" batch must not attempt another state change to \" + tryFinalState);\n    }\n    return false;\n}", "summary_tokens": ["finalize", "the", "state", "of", "a", "batch"], "project": "kafka"}
{"id": 2933, "code": "public Position withComponent(final String topic, final int partition, final long offset) {\n    position\n        .computeIfAbsent(topic, k -> new ConcurrentHashMap<>())\n        .compute(\n            partition,\n            (integer, prior) -> prior == null || offset > prior ? offset : prior\n        );\n    return this;\n}", "summary_tokens": ["augment", "an", "existing", "position", "by", "setting", "a", "new", "offset", "for", "a", "topic", "and", "partition"], "project": "kafka"}
{"id": 1853, "code": "public int lastCompletedGenerationId() {\n    return lastCompletedGenerationId;\n}", "summary_tokens": ["return", "id", "that", "corresponds", "to", "the", "group", "generation", "that", "was", "active", "when", "the", "last", "join", "was", "successful"], "project": "kafka"}
{"id": 453, "code": "private void balance(Map<String, List<TopicPartition>> currentAssignment,\n                     Map<TopicPartition, ConsumerGenerationPair> prevAssignment,\n                     List<TopicPartition> sortedPartitions,\n                     List<TopicPartition> unassignedPartitions,\n                     TreeSet<String> sortedCurrentSubscriptions,\n                     Map<String, List<String>> consumer2AllPotentialTopics,\n                     Map<String, List<String>> topic2AllPotentialConsumers,\n                     Map<TopicPartition, String> currentPartitionConsumer,\n                     boolean revocationRequired,\n                     Map<String, Integer> partitionsPerTopic,\n                     int totalPartitionCount) {\n    boolean initializing = currentAssignment.get(sortedCurrentSubscriptions.last()).isEmpty();\n\n        \n    for (TopicPartition partition: unassignedPartitions) {\n            \n        if (topic2AllPotentialConsumers.get(partition.topic()).isEmpty())\n            continue;\n\n        assignPartition(partition, sortedCurrentSubscriptions, currentAssignment,\n            consumer2AllPotentialTopics, currentPartitionConsumer);\n    }\n\n        \n    Set<TopicPartition> fixedPartitions = new HashSet<>();\n    for (String topic: topic2AllPotentialConsumers.keySet())\n        if (!canParticipateInReassignment(topic, topic2AllPotentialConsumers)) {\n            for (int i = 0; i < partitionsPerTopic.get(topic); i++) {\n                fixedPartitions.add(new TopicPartition(topic, i));\n            }\n        }\n    sortedPartitions.removeAll(fixedPartitions);\n    unassignedPartitions.removeAll(fixedPartitions);\n\n        \n    Map<String, List<TopicPartition>> fixedAssignments = new HashMap<>();\n    for (String consumer: consumer2AllPotentialTopics.keySet())\n        if (!canParticipateInReassignment(consumer, currentAssignment,\n            consumer2AllPotentialTopics, topic2AllPotentialConsumers, partitionsPerTopic, totalPartitionCount)) {\n            sortedCurrentSubscriptions.remove(consumer);\n            fixedAssignments.put(consumer, currentAssignment.remove(consumer));\n        }\n\n        \n    Map<String, List<TopicPartition>> preBalanceAssignment = deepCopy(currentAssignment);\n    Map<TopicPartition, String> preBalancePartitionConsumers = new HashMap<>(currentPartitionConsumer);\n\n        \n    if (!revocationRequired) {\n        performReassignments(unassignedPartitions, currentAssignment, prevAssignment, sortedCurrentSubscriptions,\n            consumer2AllPotentialTopics, topic2AllPotentialConsumers, currentPartitionConsumer, partitionsPerTopic, totalPartitionCount);\n    }\n\n    boolean reassignmentPerformed = performReassignments(sortedPartitions, currentAssignment, prevAssignment, sortedCurrentSubscriptions,\n        consumer2AllPotentialTopics, topic2AllPotentialConsumers, currentPartitionConsumer, partitionsPerTopic, totalPartitionCount);\n\n        \n        \n    if (!initializing && reassignmentPerformed && getBalanceScore(currentAssignment) >= getBalanceScore(preBalanceAssignment)) {\n        deepCopy(preBalanceAssignment, currentAssignment);\n        currentPartitionConsumer.clear();\n        currentPartitionConsumer.putAll(preBalancePartitionConsumers);\n    }\n\n        \n    for (Entry<String, List<TopicPartition>> entry: fixedAssignments.entrySet()) {\n        String consumer = entry.getKey();\n        currentAssignment.put(consumer, entry.getValue());\n        sortedCurrentSubscriptions.add(consumer);\n    }\n\n    fixedAssignments.clear();\n}", "summary_tokens": ["balance", "the", "current", "assignment", "using", "the", "data", "structures", "created", "in", "the", "assign"], "project": "kafka"}
{"id": 20, "code": "public boolean isDisconnected(String id) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null && state.state.isDisconnected();\n}", "summary_tokens": ["return", "true", "if", "the", "connection", "has", "been", "disconnected", "id", "the", "id", "of", "the", "node", "to", "check"], "project": "kafka"}
{"id": 3100, "code": "public static <K, V> List<KeyValueTimestamp<K, V>> waitUntilMinKeyValueWithTimestampRecordsReceived(final Properties consumerConfig,\n                                                                                                    final String topic,\n                                                                                                    final int expectedNumRecords,\n                                                                                                    final long waitTime) throws Exception {\n    final List<KeyValueTimestamp<K, V>> accumData = new ArrayList<>();\n    final String reason = String.format(\n        \"Did not receive all %d records from topic %s within %d ms\",\n        expectedNumRecords,\n        topic,\n        waitTime\n    );\n    try (final Consumer<K, V> consumer = createConsumer(consumerConfig)) {\n        retryOnExceptionWithTimeout(waitTime, () -> {\n            final List<KeyValueTimestamp<K, V>> readData =\n                readKeyValuesWithTimestamp(topic, consumer, waitTime, expectedNumRecords);\n            accumData.addAll(readData);\n            assertThat(reason, accumData.size(), is(greaterThanOrEqualTo(expectedNumRecords)));\n        });\n    }\n    return accumData;\n}", "summary_tokens": ["wait", "until", "enough", "data", "timestamped", "key", "value", "records", "has", "been", "consumed"], "project": "kafka"}
{"id": 806, "code": "public boolean isCancelled() {\n    if (isDependant) {\n            \n            \n            \n            \n            \n            \n        try {\n            completableFuture.getNow(null);\n            return false;\n        } catch (Exception e) {\n            return e instanceof CompletionException\n                    && e.getCause() instanceof CancellationException;\n        }\n    } else {\n        return completableFuture.isCancelled();\n    }\n}", "summary_tokens": ["returns", "true", "if", "this", "completable", "future", "was", "cancelled", "before", "it", "completed", "normally"], "project": "kafka"}
{"id": 1924, "code": "public static SslContextFactory createClientSideSslContextFactory(WorkerConfig config) {\n    Map<String, Object> sslConfigValues = config.valuesWithPrefixAllOrNothing(\"listeners.https.\");\n\n    final SslContextFactory.Client ssl = new SslContextFactory.Client();\n\n    configureSslContextFactoryKeyStore(ssl, sslConfigValues);\n    configureSslContextFactoryTrustStore(ssl, sslConfigValues);\n    configureSslContextFactoryAlgorithms(ssl, sslConfigValues);\n    configureSslContextFactoryEndpointIdentification(ssl, sslConfigValues);\n\n    return ssl;\n}", "summary_tokens": ["configures", "ssl", "tls", "for", "https", "jetty", "client"], "project": "kafka"}
{"id": 2401, "code": "private void finalizeSnapshotWithFooter() {\n    SnapshotFooterRecord footerRecord = new SnapshotFooterRecord()\n        .setVersion(ControlRecordUtils.SNAPSHOT_FOOTER_CURRENT_VERSION);\n    accumulator.appendSnapshotFooterRecord(footerRecord, time.milliseconds());\n    accumulator.forceDrain();\n}", "summary_tokens": ["adds", "a", "snapshot", "footer", "record", "to", "the", "snapshot"], "project": "kafka"}
{"id": 218, "code": "public boolean shouldRetryOnQuotaViolation() {\n    return retryOnQuotaViolation;\n}", "summary_tokens": ["returns", "true", "if", "quota", "violation", "should", "be", "automatically", "retried"], "project": "kafka"}
{"id": 723, "code": "public String findIndefiniteField() {\n    return data.findIndefiniteField();\n}", "summary_tokens": ["returns", "a", "string", "describing", "an", "any", "or", "unknown", "field", "or", "null", "if", "there", "is", "no", "such", "field"], "project": "kafka"}
{"id": 2840, "code": "private void populateTasksForMaps(final Map<TopicPartition, TaskId> taskForPartition,\n                                  final Map<Subtopology, Set<TaskId>> tasksForTopicGroup,\n                                  final Set<String> allSourceTopics,\n                                  final Map<TaskId, Set<TopicPartition>> partitionsForTask,\n                                  final Cluster fullMetadata) {\n        \n    final Set<TopicPartition> allAssignedPartitions = new HashSet<>();\n    for (final Map.Entry<TaskId, Set<TopicPartition>> entry : partitionsForTask.entrySet()) {\n        final TaskId id = entry.getKey();\n        final Set<TopicPartition> partitions = entry.getValue();\n\n        for (final TopicPartition partition : partitions) {\n            taskForPartition.put(partition, id);\n            if (allAssignedPartitions.contains(partition)) {\n                log.warn(\"Partition {} is assigned to more than one tasks: {}\", partition, partitionsForTask);\n            }\n        }\n        allAssignedPartitions.addAll(partitions);\n\n        tasksForTopicGroup.computeIfAbsent(new Subtopology(id.subtopology(), id.topologyName()), k -> new HashSet<>()).add(id);\n    }\n\n    checkAllPartitions(allSourceTopics, partitionsForTask, allAssignedPartitions, fullMetadata);\n}", "summary_tokens": ["populates", "the", "task", "for", "partition", "and", "tasks", "for", "topic", "group", "maps", "and", "checks", "that", "partitions", "are", "assigned", "to", "exactly", "one", "task"], "project": "kafka"}
{"id": 1977, "code": "Map<TopicPartition, Long> readEndOffsets(Set<TopicPartition> assignment, boolean shouldRetry) throws UnsupportedVersionException {\n    log.trace(\"Reading to end of offset log\");\n\n        \n        \n        \n        \n        \n        \n\n        \n    if (admin != null) {\n            \n            \n        try {\n            if (shouldRetry) {\n                return admin.retryEndOffsets(assignment,\n                        ADMIN_CLIENT_RETRY_DURATION,\n                        ADMIN_CLIENT_RETRY_BACKOFF_MS);\n            }\n\n            return admin.endOffsets(assignment);\n        } catch (UnsupportedVersionException e) {\n                \n                \n            if (requireAdminForOffsets) {\n                    \n                throw e;\n            }\n            log.debug(\"Reading to end of log offsets with consumer since admin client is unsupported: {}\", e.getMessage());\n                \n            admin = null;\n                \n        }\n            \n    }\n        \n        \n    return consumer.endOffsets(assignment);\n}", "summary_tokens": ["read", "to", "the", "end", "of", "the", "given", "list", "of", "topic", "partitions", "assignment", "the", "topic", "partitions", "to", "read", "to", "the", "end", "of", "should", "retry", "boolean", "flag", "to", "enable", "retry", "for", "the", "admin", "client", "list", "offsets", "call"], "project": "kafka"}
{"id": 1389, "code": "public void testNormalOperation() throws Exception {\n    int conns = 5;\n    int reqs = 500;\n\n        \n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port);\n    for (int i = 0; i < conns; i++)\n        connect(Integer.toString(i), addr);\n        \n    Map<String, Integer> requests = new HashMap<>();\n    Map<String, Integer> responses = new HashMap<>();\n    int responseCount = 0;\n    for (int i = 0; i < conns; i++) {\n        String node = Integer.toString(i);\n        selector.send(createSend(node, node + \"-0\"));\n    }\n\n        \n    while (responseCount < conns * reqs) {\n            \n        selector.poll(0L);\n\n        assertEquals(0, selector.disconnected().size(), \"No disconnects should have occurred.\");\n\n            \n        for (NetworkReceive receive : selector.completedReceives()) {\n            String[] pieces = asString(receive).split(\"-\");\n            assertEquals(2, pieces.length, \"Should be in the form 'conn-counter'\");\n            assertEquals(receive.source(), pieces[0], \"Check the source\");\n            assertEquals(0, receive.payload().position(), \"Check that the receive has kindly been rewound\");\n            if (responses.containsKey(receive.source())) {\n                assertEquals((int) responses.get(receive.source()), Integer.parseInt(pieces[1]), \"Check the request counter\");\n                responses.put(receive.source(), responses.get(receive.source()) + 1);\n            } else {\n                assertEquals(0, Integer.parseInt(pieces[1]), \"Check the request counter\");\n                responses.put(receive.source(), 1);\n            }\n            responseCount++;\n        }\n\n            \n        for (NetworkSend send : selector.completedSends()) {\n            String dest = send.destinationId();\n            if (requests.containsKey(dest))\n                requests.put(dest, requests.get(dest) + 1);\n            else\n                requests.put(dest, 1);\n            if (requests.get(dest) < reqs)\n                selector.send(createSend(dest, dest + \"-\" + requests.get(dest)));\n        }\n    }\n    if (channelBuilder instanceof PlaintextChannelBuilder) {\n        assertEquals(0, cipherMetrics(metrics).size());\n    } else {\n        TestUtils.waitForCondition(() -> cipherMetrics(metrics).size() == 1,\n            \"Waiting for cipher metrics to be created.\");\n        assertEquals(Integer.valueOf(5), cipherMetrics(metrics).get(0).metricValue());\n    }\n}", "summary_tokens": ["send", "multiple", "requests", "to", "several", "connections", "in", "parallel"], "project": "kafka"}
{"id": 2936, "code": "public Set<String> getTopics() {\n    return Collections.unmodifiableSet(position.keySet());\n}", "summary_tokens": ["return", "the", "topics", "that", "are", "represented", "in", "this", "position"], "project": "kafka"}
{"id": 1138, "code": "public double loginRefreshWindowJitter() {\n    return loginRefreshWindowJitter;\n}", "summary_tokens": ["amount", "of", "random", "jitter", "added", "to", "the", "background", "login", "refresh", "thread", "s", "sleep", "time"], "project": "kafka"}
{"id": 1558, "code": "private HttpsJwks spyHttpsJwks() {\n    HttpsJwks httpsJwks = new HttpsJwks(\"https://www.example.com\");\n\n    SimpleResponse simpleResponse = new SimpleResponse() {\n        @Override\n        public int getStatusCode() {\n            return 200;\n        }\n\n        @Override\n        public String getStatusMessage() {\n            return \"OK\";\n        }\n\n        @Override\n        public Collection<String> getHeaderNames() {\n            return Collections.emptyList();\n        }\n\n        @Override\n        public List<String> getHeaderValues(String name) {\n            return Collections.emptyList();\n        }\n\n        @Override\n        public String getBody() {\n            return \"{\\\"keys\\\": []}\";\n        }\n    };\n\n    httpsJwks.setSimpleHttpGet(l -> simpleResponse);\n\n    return Mockito.spy(httpsJwks);\n}", "summary_tokens": ["we", "spy", "not", "mock", "the", "https", "jwks", "instance", "because", "we", "want", "to", "have", "it", "partially", "mocked", "to", "determine", "if", "it", "s", "calling", "its", "internal", "refresh", "method"], "project": "kafka"}
{"id": 683, "code": "public String idString() {\n    return idString;\n}", "summary_tokens": ["string", "representation", "of", "the", "node", "id"], "project": "kafka"}
{"id": 1700, "code": "public DecimalFormat decimalFormat() {\n    return decimalFormat;\n}", "summary_tokens": ["get", "the", "serialization", "format", "for", "decimal", "types"], "project": "kafka"}
{"id": 2937, "code": "public Map<Integer, Long> getPartitionPositions(final String topic) {\n    final ConcurrentHashMap<Integer, Long> bound = position.get(topic);\n    return bound == null ? Collections.emptyMap() : Collections.unmodifiableMap(bound);\n}", "summary_tokens": ["return", "the", "partition", "offset", "mapping", "for", "a", "specific", "topic"], "project": "kafka"}
{"id": 892, "code": "public void handshake() throws IOException {\n    if (state == State.NOT_INITIALIZED) {\n        try {\n            startHandshake();\n        } catch (SSLException e) {\n            maybeProcessHandshakeFailure(e, false, null);\n        }\n    }\n    if (ready())\n        throw renegotiationException();\n    if (state == State.CLOSING)\n        throw closingException();\n\n    int read = 0;\n    boolean readable = key.isReadable();\n    try {\n            \n            \n            \n        if (readable)\n            read = readFromSocketChannel();\n\n        doHandshake();\n        if (ready())\n            updateBytesBuffered(true);\n    } catch (SSLException e) {\n        maybeProcessHandshakeFailure(e, true, null);\n    } catch (IOException e) {\n        maybeThrowSslAuthenticationException();\n\n            \n            \n        try {\n            do {\n                log.trace(\"Process any available bytes from peer, netReadBuffer {} netWriterBuffer {} handshakeStatus {} readable? {}\",\n                    netReadBuffer, netWriteBuffer, handshakeStatus, readable);\n                handshakeWrapAfterFailure(false);\n                handshakeUnwrap(false, true);\n            } while (readable && readFromSocketChannel() > 0);\n        } catch (SSLException e1) {\n            maybeProcessHandshakeFailure(e1, false, e);\n        }\n\n            \n        throw e;\n    }\n\n        \n    if (read == -1) {\n        maybeThrowSslAuthenticationException();\n        throw new EOFException(\"EOF during handshake, handshake status is \" + handshakeStatus);\n    }\n}", "summary_tokens": ["performs", "ssl", "handshake", "non", "blocking"], "project": "kafka"}
{"id": 2255, "code": "long lastContainedLogOffset() {\n    return writer.lastContainedLogOffset();\n}", "summary_tokens": ["returns", "the", "last", "offset", "from", "the", "log", "that", "will", "be", "included", "in", "the", "snapshot"], "project": "kafka"}
{"id": 2868, "code": "void addRecordsToTasks(final ConsumerRecords<byte[], byte[]> records) {\n    for (final TopicPartition partition : records.partitions()) {\n        final Task activeTask = tasks.activeTasksForInputPartition(partition);\n\n        if (activeTask == null) {\n            log.error(\"Unable to locate active task for received-record partition {}. Current tasks: {}\",\n                partition, toString(\">\"));\n            throw new NullPointerException(\"Task was unexpectedly missing for partition \" + partition);\n        }\n\n        activeTask.addRecords(partition, records.records(partition));\n    }\n}", "summary_tokens": ["take", "records", "and", "add", "them", "to", "each", "respective", "task"], "project": "kafka"}
{"id": 1170, "code": "public static OAuthBearerValidationResult validateIssuedAt(OAuthBearerUnsecuredJws jwt, boolean required,\n        long whenCheckTimeMs, int allowableClockSkewMs) throws OAuthBearerConfigException {\n    Number value;\n    try {\n        value = Objects.requireNonNull(jwt).issuedAt();\n    } catch (OAuthBearerIllegalTokenException e) {\n        return e.reason();\n    }\n    boolean exists = value != null;\n    if (!exists)\n        return doesNotExistResult(required, \"iat\");\n    double doubleValue = value.doubleValue();\n    return 1000 * doubleValue > whenCheckTimeMs + confirmNonNegative(allowableClockSkewMs)\n            ? OAuthBearerValidationResult.newFailure(String.format(\n                    \"The Issued At value (%f seconds) was after the indicated time (%d ms) plus allowable clock skew (%d ms)\",\n                    doubleValue, whenCheckTimeMs, allowableClockSkewMs))\n            : OAuthBearerValidationResult.newSuccess();\n}", "summary_tokens": ["validate", "the", "iat", "issued", "at", "claim"], "project": "kafka"}
{"id": 3165, "code": "public void advanceWallClockTime(final Duration advance) {\n    Objects.requireNonNull(advance, \"advance cannot be null\");\n    mockWallClockTime.sleep(advance.toMillis());\n    if (task != null) {\n        task.maybePunctuateSystemTime();\n        commit(task.prepareCommit());\n        task.postCommit(true);\n    }\n    completeAllProcessableWork();\n}", "summary_tokens": ["advances", "the", "internally", "mocked", "wall", "clock", "time"], "project": "kafka"}
{"id": 3, "code": "public boolean canConnect(String id, long now) {\n    NodeConnectionState state = nodeState.get(id);\n    if (state == null)\n        return true;\n    else\n        return state.state.isDisconnected() &&\n               now - state.lastConnectAttemptMs >= state.reconnectBackoffMs;\n}", "summary_tokens": ["return", "true", "iff", "we", "can", "currently", "initiate", "a", "new", "connection"], "project": "kafka"}
{"id": 882, "code": "public Principal peerPrincipal() {\n    return principal;\n}", "summary_tokens": ["returns", "anonymous", "as", "principal"], "project": "kafka"}
{"id": 3158, "code": "public List<TestRecord<K, V>> readRecordsToList() {\n    final List<TestRecord<K, V>> output = new LinkedList<>();\n    while (!isEmpty()) {\n        output.add(readRecord());\n    }\n    return output;\n}", "summary_tokens": ["read", "output", "to", "list"], "project": "kafka"}
{"id": 939, "code": "public ClientQuotaEntity entity() {\n    return this.entity;\n}", "summary_tokens": ["the", "entity", "whose", "config", "will", "be", "modified"], "project": "kafka"}
{"id": 1320, "code": "public static ListPartitionReassignmentsResult listPartitionReassignmentsResult(Throwable t) {\n    KafkaFutureImpl<Map<TopicPartition, PartitionReassignment>> future = new KafkaFutureImpl<>();\n    future.completeExceptionally(t);\n    return new ListPartitionReassignmentsResult(future);\n}", "summary_tokens": ["helper", "to", "create", "a", "list", "partition", "reassignments", "result", "instance", "for", "a", "given", "throwable"], "project": "kafka"}
{"id": 2082, "code": "public void testExternalZombieFencingRequestImmediateCompletion() throws Exception {\n    expectHerderStartup();\n    EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n    EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V2);\n    expectConfigRefreshAndSnapshot(SNAPSHOT);\n\n    expectRebalance(1, Collections.emptyList(), Collections.emptyList(), true);\n    SessionKey sessionKey = expectNewSessionKey();\n\n    expectAnyTicks();\n\n    member.wakeup();\n    EasyMock.expectLastCall();\n\n    ClusterConfigState configState = exactlyOnceSnapshot(\n            sessionKey,\n            TASK_CONFIGS_MAP,\n            Collections.singletonMap(CONN1, 2),\n            Collections.singletonMap(CONN1, 5),\n            Collections.singleton(CONN1)\n    );\n    expectConfigRefreshAndSnapshot(configState);\n\n        \n    KafkaFuture<Void> workerFencingFuture = EasyMock.mock(KafkaFuture.class);\n        \n    KafkaFuture<Void> herderFencingFuture = EasyMock.mock(KafkaFuture.class);\n\n        \n    for (int i = 0; i < 2; i++) {\n        Capture<KafkaFuture.BiConsumer<Void, Throwable>> herderFencingCallback = EasyMock.newCapture();\n        EasyMock.expect(herderFencingFuture.whenComplete(EasyMock.capture(herderFencingCallback))).andAnswer(() -> {\n            herderFencingCallback.getValue().accept(null, null);\n            return null;\n        });\n    }\n\n    Capture<KafkaFuture.BaseFunction<Void, Void>> fencingFollowup = EasyMock.newCapture();\n    EasyMock.expect(workerFencingFuture.thenApply(EasyMock.capture(fencingFollowup))).andAnswer(() -> {\n        fencingFollowup.getValue().apply(null);\n        return herderFencingFuture;\n    });\n    EasyMock.expect(worker.fenceZombies(EasyMock.eq(CONN1), EasyMock.eq(2), EasyMock.eq(CONN1_CONFIG)))\n            .andReturn(workerFencingFuture);\n\n    expectConfigRefreshAndSnapshot(configState);\n\n    configBackingStore.putTaskCountRecord(CONN1, 1);\n    EasyMock.expectLastCall();\n\n    expectHerderShutdown(true);\n\n    PowerMock.replayAll(workerFencingFuture, herderFencingFuture);\n\n\n    startBackgroundHerder();\n\n    FutureCallback<Void> fencing = new FutureCallback<>();\n    herder.fenceZombieSourceTasks(CONN1, fencing);\n\n    fencing.get(10, TimeUnit.SECONDS);\n\n    stopBackgroundHerder();\n\n    PowerMock.verifyAll();\n}", "summary_tokens": ["tests", "zombie", "fencing", "that", "completes", "extremely", "quickly", "and", "causes", "all", "callback", "related", "logic", "to", "be", "invoked", "effectively", "as", "soon", "as", "it", "s", "put", "into", "place"], "project": "kafka"}
{"id": 1826, "code": "protected synchronized void doRestartConnectorAndTasks(RestartRequest request) {\n    String connectorName = request.connectorName();\n    Optional<RestartPlan> maybePlan = buildRestartPlan(request);\n    if (!maybePlan.isPresent()) {\n        log.debug(\"Skipping restart of connector '{}' since no status is available: {}\", connectorName, request);\n        return;\n    }\n    RestartPlan plan = maybePlan.get();\n    log.info(\"Executing {}\", plan);\n\n        \n    final ExtendedAssignment currentAssignments = assignment;\n    final Collection<ConnectorTaskId> assignedIdsToRestart = plan.taskIdsToRestart()\n            .stream()\n            .filter(taskId -> currentAssignments.tasks().contains(taskId))\n            .collect(Collectors.toList());\n    final boolean restartConnector = plan.shouldRestartConnector() && currentAssignments.connectors().contains(connectorName);\n    final boolean restartTasks = !assignedIdsToRestart.isEmpty();\n    if (restartConnector) {\n        worker.stopAndAwaitConnector(connectorName);\n        onRestart(connectorName);\n    }\n    if (restartTasks) {\n            \n        worker.stopAndAwaitTasks(assignedIdsToRestart);\n        assignedIdsToRestart.forEach(this::onRestart);\n    }\n\n        \n    if (restartConnector) {\n        try {\n            startConnector(connectorName, (error, targetState) -> {\n                if (error == null) {\n                    log.info(\"Connector '{}' restart successful\", connectorName);\n                } else {\n                    log.error(\"Connector '{}' restart failed\", connectorName, error);\n                }\n            });\n        } catch (Throwable t) {\n            log.error(\"Connector '{}' restart failed\", connectorName, t);\n        }\n    }\n    if (restartTasks) {\n        log.debug(\"Restarting {} of {} tasks for {}\", assignedIdsToRestart.size(), plan.totalTaskCount(), request);\n        assignedIdsToRestart.forEach(taskId -> {\n            try {\n                if (startTask(taskId)) {\n                    log.info(\"Task '{}' restart successful\", taskId);\n                } else {\n                    log.error(\"Task '{}' restart failed\", taskId);\n                }\n            } catch (Throwable t) {\n                log.error(\"Task '{}' restart failed\", taskId, t);\n            }\n        });\n        log.debug(\"Restarted {} of {} tasks for {} as requested\", assignedIdsToRestart.size(), plan.totalTaskCount(), request);\n    }\n    log.info(\"Completed {}\", plan);\n}", "summary_tokens": ["builds", "and", "executes", "a", "restart", "plan", "for", "the", "connector", "and", "its", "tasks", "from", "code", "request", "code"], "project": "kafka"}
{"id": 390, "code": "public void subscribe(Pattern pattern) {\n    subscribe(pattern, new NoOpConsumerRebalanceListener());\n}", "summary_tokens": ["subscribe", "to", "all", "topics", "matching", "specified", "pattern", "to", "get", "dynamically", "assigned", "partitions"], "project": "kafka"}
{"id": 1802, "code": "public boolean awaitShutdown(long timeoutMs) {\n    try {\n        return shutdownLatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        return false;\n    }\n}", "summary_tokens": ["wait", "for", "this", "connector", "to", "finish", "shutting", "down"], "project": "kafka"}
{"id": 9232, "code": "public void onEventTime(InternalTimer<Object, VoidNamespace> timer) throws Exception {}", "summary_tokens": ["invoked", "when", "an", "event", "time", "timer", "fires"], "project": "flink"}
{"id": 788, "code": "public int getRegisterStreamMaxRetries() {\n    return registerStreamMaxRetries;\n}", "summary_tokens": ["get", "maximum", "retry", "attempts", "for", "the", "register", "stream", "operation"], "project": "flink"}
{"id": 8127, "code": "public Set<String> listFunctions() {\n    return usedModules.stream()\n            .map(name -> loadedModules.get(name).listFunctions())\n            .flatMap(Collection::stream)\n            .collect(Collectors.toSet());\n}", "summary_tokens": ["get", "names", "of", "all", "functions", "from", "used", "modules"], "project": "flink"}
{"id": 2113, "code": "public static <T> T getWithoutException(CompletableFuture<T> future) {\n    if (isCompletedNormally(future)) {\n        try {\n            return future.get();\n        } catch (InterruptedException | ExecutionException ignored) {\n        }\n    }\n    return null;\n}", "summary_tokens": ["gets", "the", "result", "of", "a", "completable", "future", "without", "any", "exception", "thrown"], "project": "flink"}
{"id": 8835, "code": "public FlinkContext getFlinkContext() {\n    return context;\n}", "summary_tokens": ["returns", "the", "flink", "context"], "project": "flink"}
{"id": 3090, "code": "public AfterMatchSkipStrategy getAfterMatchSkipStrategy() {\n    return afterMatchSkipStrategy;\n}", "summary_tokens": ["the", "pattern", "s", "after", "match", "skip", "strategy"], "project": "flink"}
{"id": 2131, "code": "static Runnable unchecked(ThrowingRunnable<?> throwingRunnable) {\n    return () -> {\n        try {\n            throwingRunnable.run();\n        } catch (Throwable t) {\n            ExceptionUtils.rethrow(t);\n        }\n    };\n}", "summary_tokens": ["converts", "a", "throwing", "runnable", "into", "a", "runnable", "which", "throws", "all", "checked", "exceptions", "as", "unchecked"], "project": "flink"}
{"id": 5693, "code": "public static <T extends Serializable>\n        FileSystemStateStorageHelper<T> createFileSystemStateStorage(\n                Configuration configuration, String prefix) throws IOException {\n\n    return new FileSystemStateStorageHelper<>(\n            HighAvailabilityServicesUtils.getClusterHighAvailableStoragePath(configuration),\n            prefix);\n}", "summary_tokens": ["creates", "a", "file", "system", "state", "storage", "helper", "instance"], "project": "flink"}
{"id": 4441, "code": "public Set<ExecutionVertexID> getTasksNeedingRestart(\n        ExecutionVertexID executionVertexId, Throwable cause) {\n    return IterableUtils.toStream(topology.getVertices())\n            .map(SchedulingExecutionVertex::getId)\n            .collect(Collectors.toSet());\n}", "summary_tokens": ["returns", "all", "vertices", "on", "any", "task", "failure"], "project": "flink"}
{"id": 838, "code": "public static Properties getConsumerProperties(Map<String, String> tableOptions) {\n    Properties properties = new Properties();\n\n    for (Map.Entry<String, String> entry : tableOptions.entrySet()) {\n        String sourceKey = entry.getKey();\n        String sourceVal = entry.getValue();\n\n        if (!TABLE_LEVEL_OPTIONS.contains(sourceKey)) {\n            if (sourceKey.startsWith(AWS_PROPERTIES_PREFIX)) {\n                properties.put(translateAwsKey(sourceKey), sourceVal);\n            } else if (sourceKey.startsWith(CONSUMER_PREFIX)) {\n                properties.put(translateConsumerKey(sourceKey), sourceVal);\n            }\n        }\n    }\n\n    return properties;\n}", "summary_tokens": ["derive", "properties", "to", "be", "passed", "to", "the", "flink", "kinesis", "consumer"], "project": "flink"}
{"id": 8120, "code": "static String sqlToRegexLike(String sqlPattern, char escapeChar) {\n    int i;\n    final int len = sqlPattern.length();\n    final StringBuilder javaPattern = new StringBuilder(len + len);\n    for (i = 0; i < len; i++) {\n        char c = sqlPattern.charAt(i);\n        if (JAVA_REGEX_SPECIALS.indexOf(c) >= 0) {\n            javaPattern.append('\\\\');\n        }\n        if (c == escapeChar) {\n            if (i == (sqlPattern.length() - 1)) {\n                throw invalidEscapeSequence(sqlPattern, i);\n            }\n            char nextChar = sqlPattern.charAt(i + 1);\n            if ((nextChar == '_') || (nextChar == '%') || (nextChar == escapeChar)) {\n                javaPattern.append(nextChar);\n                i++;\n            } else {\n                throw invalidEscapeSequence(sqlPattern, i);\n            }\n        } else if (c == '_') {\n            javaPattern.append('.');\n        } else if (c == '%') {\n            javaPattern.append(\"(?s:.*)\");\n        } else {\n            javaPattern.append(c);\n        }\n    }\n    return javaPattern.toString();\n}", "summary_tokens": ["translates", "a", "sql", "like", "pattern", "to", "java", "regex", "pattern"], "project": "flink"}
{"id": 3592, "code": "public void setNextPartialSolution(\n        OptimizerNode nextPartialSolution, OptimizerNode terminationCriterion) {\n\n        \n        \n    if (nextPartialSolution.getParallelism() != getParallelism()\n            || nextPartialSolution == partialSolution\n            || nextPartialSolution instanceof BinaryUnionNode) {\n            \n        NoOpNode noop = new NoOpNode();\n        noop.setParallelism(getParallelism());\n\n        DagConnection noOpConn =\n                new DagConnection(nextPartialSolution, noop, ExecutionMode.PIPELINED);\n        noop.setIncomingConnection(noOpConn);\n        nextPartialSolution.addOutgoingConnection(noOpConn);\n\n        nextPartialSolution = noop;\n    }\n\n    this.nextPartialSolution = nextPartialSolution;\n    this.terminationCriterion = terminationCriterion;\n\n    if (terminationCriterion == null) {\n        this.singleRoot = nextPartialSolution;\n        this.rootConnection = new DagConnection(nextPartialSolution, ExecutionMode.PIPELINED);\n    } else {\n            \n        SingleRootJoiner singleRootJoiner = new SingleRootJoiner();\n        this.rootConnection =\n                new DagConnection(\n                        nextPartialSolution, singleRootJoiner, ExecutionMode.PIPELINED);\n        this.terminationCriterionRootConnection =\n                new DagConnection(\n                        terminationCriterion, singleRootJoiner, ExecutionMode.PIPELINED);\n\n        singleRootJoiner.setInputs(\n                this.rootConnection, this.terminationCriterionRootConnection);\n\n        this.singleRoot = singleRootJoiner;\n\n            \n        terminationCriterion.addOutgoingConnection(terminationCriterionRootConnection);\n    }\n\n    nextPartialSolution.addOutgoingConnection(rootConnection);\n}", "summary_tokens": ["sets", "the", "next", "partial", "solution", "for", "this", "bulk", "iteration", "node"], "project": "flink"}
{"id": 7909, "code": "public OperatorSnapshotFinalizer snapshotWithLocalState(\n        long checkpointId, long timestamp, CheckpointType checkpointType) throws Exception {\n\n    CheckpointStorageLocationReference locationReference =\n            CheckpointStorageLocationReference.getDefault();\n    OperatorSnapshotFutures operatorStateResult =\n            operator.snapshotState(\n                    checkpointId,\n                    timestamp,\n                    new CheckpointOptions(checkpointType, locationReference),\n                    checkpointStorageAccess.resolveCheckpointStorageLocation(\n                            checkpointId, locationReference));\n\n    return new OperatorSnapshotFinalizer(operatorStateResult);\n}", "summary_tokens": ["calls", "stream", "operator", "snapshot", "state", "long", "long", "checkpoint", "options", "org"], "project": "flink"}
{"id": 2021, "code": "public static String ipAddressAndPortToUrlString(InetAddress address, int port) {\n    return ipAddressToUrlString(address) + ':' + port;\n}", "summary_tokens": ["encodes", "an", "ip", "address", "and", "port", "to", "be", "included", "in", "url"], "project": "flink"}
{"id": 5252, "code": "public static String getDefaultMimeType() {\n    return DEFAULT_MIME_TYPE;\n}", "summary_tokens": ["gets", "the", "default", "mime", "type", "which", "is", "application", "octet", "stream"], "project": "flink"}
{"id": 4600, "code": "private void enqueueAvailableReader(final NetworkSequenceViewReader reader) throws Exception {\n    if (reader.isRegisteredAsAvailable()) {\n        return;\n    }\n\n    ResultSubpartitionView.AvailabilityWithBacklog availabilityWithBacklog =\n            reader.getAvailabilityAndBacklog();\n    if (!availabilityWithBacklog.isAvailable()) {\n        int backlog = availabilityWithBacklog.getBacklog();\n        if (backlog > 0 && reader.needAnnounceBacklog()) {\n            announceBacklog(reader, backlog);\n        }\n        return;\n    }\n\n        \n        \n        \n    boolean triggerWrite = availableReaders.isEmpty();\n    registerAvailableReader(reader);\n\n    if (triggerWrite) {\n        writeAndFlushNextMessageIfPossible(ctx.channel());\n    }\n}", "summary_tokens": ["try", "to", "enqueue", "the", "reader", "once", "receiving", "credit", "notification", "from", "the", "consumer", "or", "receiving", "non", "empty", "reader", "notification", "from", "the", "producer"], "project": "flink"}
{"id": 175, "code": "public CassandraSink<IN> setParallelism(int parallelism) {\n    if (useDataStreamSink) {\n        sink1.setParallelism(parallelism);\n    } else {\n        sink2.setParallelism(parallelism);\n    }\n    return this;\n}", "summary_tokens": ["sets", "the", "parallelism", "for", "this", "sink"], "project": "flink"}
{"id": 423, "code": "public void setAllowStatefulFunctions(boolean allowStatefulFunctions) {\n    this.allowStatefulFunctions = allowStatefulFunctions;\n}", "summary_tokens": ["allow", "stateful", "functions", "whether", "to", "allow", "stateful", "udf", "invocations"], "project": "flink"}
{"id": 8261, "code": "default void applyReadableMetadata(List<String> metadataKeys) {\n    throw new UnsupportedOperationException(\n            \"A decoding format must override this method to apply metadata keys.\");\n}", "summary_tokens": ["provides", "a", "list", "of", "metadata", "keys", "that", "the", "produced", "row", "must", "contain", "as", "appended", "metadata", "columns"], "project": "flink"}
{"id": 4908, "code": "public Optional<HaLeadershipControl> getHaLeadershipControl() {\n    synchronized (lock) {\n        return haServices instanceof HaLeadershipControl\n                ? Optional.of((HaLeadershipControl) haServices)\n                : Optional.empty();\n    }\n}", "summary_tokens": ["returns", "ha", "leadership", "control", "if", "enabled"], "project": "flink"}
{"id": 7929, "code": "public void testRowTypeInfo() {\n    TypeInformation<?>[] typeList =\n            new TypeInformation<?>[] {\n                new RowTypeInfo(BasicTypeInfo.SHORT_TYPE_INFO, BasicTypeInfo.BIG_DEC_TYPE_INFO)\n            };\n\n    String[] fieldNames = new String[] {\"row\"};\n    RowTypeInfo rowTypeInfo = new RowTypeInfo(typeList, fieldNames);\n\n    FieldAccessor f = FieldAccessorFactory.getAccessor(rowTypeInfo, \"row.0\", null);\n}", "summary_tokens": ["validates", "that", "no", "class", "cast", "exception", "happens", "should", "not", "fail", "e"], "project": "flink"}
{"id": 661, "code": "public void testSetFilterRestoredParitionsWithRemovedTopic() throws Exception {\n    checkFilterRestoredPartitionsWithDisovered(\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\"}),\n            false);\n}", "summary_tokens": ["tests", "that", "removed", "partitions", "will", "be", "removed", "from", "subscribed", "partitions", "even", "if", "it", "s", "still", "in", "restored", "partitions"], "project": "flink"}
{"id": 1682, "code": "public long getGibiBytes() {\n    return bytes >> 30;\n}", "summary_tokens": ["gets", "the", "memory", "size", "in", "gibibytes", "0", "mebibytes"], "project": "flink"}
{"id": 2769, "code": "public int getParallelism() {\n    return parallelism;\n}", "summary_tokens": ["gets", "the", "iteration", "s", "parallelism"], "project": "flink"}
{"id": 7663, "code": "public void testDeleteEventTimeTimers() throws Exception {\n    @SuppressWarnings(\"unchecked\")\n    Triggerable<Integer, String> mockTriggerable = mock(Triggerable.class);\n\n    TestKeyContext keyContext = new TestKeyContext();\n    TestProcessingTimeService processingTimeService = new TestProcessingTimeService();\n    InternalTimerServiceImpl<Integer, String> timerService =\n            createAndStartInternalTimerService(\n                    mockTriggerable,\n                    keyContext,\n                    processingTimeService,\n                    testKeyGroupRange,\n                    createQueueFactory());\n\n        \n    int key1 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    int key2 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    while (key2 == key1) {\n        key2 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    }\n\n    keyContext.setCurrentKey(key1);\n\n    timerService.registerEventTimeTimer(\"ciao\", 10);\n    timerService.registerEventTimeTimer(\"hello\", 10);\n\n    keyContext.setCurrentKey(key2);\n\n    timerService.registerEventTimeTimer(\"ciao\", 10);\n    timerService.registerEventTimeTimer(\"hello\", 10);\n\n    assertEquals(4, timerService.numEventTimeTimers());\n    assertEquals(2, timerService.numEventTimeTimers(\"hello\"));\n    assertEquals(2, timerService.numEventTimeTimers(\"ciao\"));\n\n    keyContext.setCurrentKey(key1);\n    timerService.deleteEventTimeTimer(\"hello\", 10);\n\n    keyContext.setCurrentKey(key2);\n    timerService.deleteEventTimeTimer(\"ciao\", 10);\n\n    assertEquals(2, timerService.numEventTimeTimers());\n    assertEquals(1, timerService.numEventTimeTimers(\"hello\"));\n    assertEquals(1, timerService.numEventTimeTimers(\"ciao\"));\n\n    timerService.advanceWatermark(10);\n\n    verify(mockTriggerable, times(2)).onEventTime(anyInternalTimer());\n    verify(mockTriggerable, times(1))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key1, \"ciao\")));\n    verify(mockTriggerable, times(0))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key1, \"hello\")));\n    verify(mockTriggerable, times(0))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key2, \"ciao\")));\n    verify(mockTriggerable, times(1))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key2, \"hello\")));\n\n    assertEquals(0, timerService.numEventTimeTimers());\n}", "summary_tokens": ["this", "also", "verifies", "that", "we", "don", "t", "have", "leakage", "between", "keys", "namespaces"], "project": "flink"}
{"id": 9641, "code": "public void testKeyedCoProcessFunctionSideOutputWithMultipleConsumers() throws Exception {\n    final OutputTag<String> sideOutputTag1 = new OutputTag<String>(\"side1\") {};\n    final OutputTag<String> sideOutputTag2 = new OutputTag<String>(\"side2\") {};\n\n    TestListResultSink<String> sideOutputResultSink1 = new TestListResultSink<>();\n    TestListResultSink<String> sideOutputResultSink2 = new TestListResultSink<>();\n    TestListResultSink<Integer> resultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(3);\n\n    DataStream<Integer> ds1 = see.fromCollection(elements);\n    DataStream<Integer> ds2 = see.fromCollection(elements);\n\n    SingleOutputStreamOperator<Integer> passThroughtStream =\n            ds1.keyBy(i -> i)\n                    .connect(ds2.keyBy(i -> i))\n                    .process(\n                            new KeyedCoProcessFunction<Integer, Integer, Integer, Integer>() {\n                                @Override\n                                public void processElement1(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value < 4) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag1,\n                                                \"sideout1-\"\n                                                        + ctx.getCurrentKey()\n                                                        + \"-\"\n                                                        + String.valueOf(value));\n                                    }\n                                }\n\n                                @Override\n                                public void processElement2(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value >= 4) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag2,\n                                                \"sideout2-\"\n                                                        + ctx.getCurrentKey()\n                                                        + \"-\"\n                                                        + String.valueOf(value));\n                                    }\n                                }\n                            });\n\n    passThroughtStream.getSideOutput(sideOutputTag1).addSink(sideOutputResultSink1);\n    passThroughtStream.getSideOutput(sideOutputTag2).addSink(sideOutputResultSink2);\n    passThroughtStream.addSink(resultSink);\n    see.execute();\n\n    assertEquals(\n            Arrays.asList(\"sideout1-1-1\", \"sideout1-2-2\", \"sideout1-3-3\"),\n            sideOutputResultSink1.getSortedResult());\n    assertEquals(\n            Arrays.asList(\"sideout2-4-4\", \"sideout2-5-5\"),\n            sideOutputResultSink2.getSortedResult());\n    assertEquals(Arrays.asList(1, 2, 3, 4, 5), resultSink.getSortedResult());\n}", "summary_tokens": ["test", "keyed", "keyed", "co", "process", "function", "side", "output", "with", "multiple", "consumers"], "project": "flink"}
{"id": 6182, "code": "public void testValidSslConnection() throws Exception {\n    testValidSslConnection(createSslConfig());\n}", "summary_tokens": ["verify", "valid", "ssl", "configuration", "and", "connection"], "project": "flink"}
{"id": 8724, "code": "public RexNode simplifyUnknownAs(RexNode e, RexUnknownAs unknownAs) {\n    final RexNode simplified = withParanoid(false).simplify(e, unknownAs);\n    if (paranoid) {\n        verify(e, simplified, unknownAs);\n    }\n    return simplified;\n}", "summary_tokens": ["as", "simplify", "rex", "node", "but", "specifying", "how", "unknown", "values", "are", "to", "be", "treated"], "project": "flink"}
{"id": 4019, "code": "public void testTerminationFuture() throws Exception {\n    final AkkaRpcService rpcService = startAkkaRpcService();\n\n    CompletableFuture<Void> terminationFuture = rpcService.getTerminationFuture();\n\n    assertFalse(terminationFuture.isDone());\n\n    rpcService.stopService();\n\n    terminationFuture.get();\n}", "summary_tokens": ["tests", "that", "we", "can", "wait", "for", "the", "termination", "of", "the", "rpc", "service"], "project": "flink"}
{"id": 9206, "code": "static void checkInsertOnly(RowData currentRow) {\n    Preconditions.checkArgument(currentRow.getRowKind() == RowKind.INSERT);\n}", "summary_tokens": ["check", "message", "should", "be", "insert", "only"], "project": "flink"}
{"id": 6299, "code": "public void testPendingBatchSlotRequestDoesNotFailIfResourceDeclaringFails() throws Exception {\n    final TestingResourceManagerGateway testingResourceManagerGateway =\n            new TestingResourceManagerGateway();\n    testingResourceManagerGateway.setDeclareRequiredResourcesFunction(\n            (jobMasterId, resourceRequirements) ->\n                    FutureUtils.completedExceptionally(new FlinkException(\"Failed request\")));\n\n    final Time batchSlotTimeout = Time.milliseconds(1000L);\n    try (final SlotPool slotPool =\n            createAndSetUpSlotPool(\n                    mainThreadExecutor, testingResourceManagerGateway, batchSlotTimeout)) {\n\n        final CompletableFuture<PhysicalSlot> slotFuture =\n                SlotPoolUtils.requestNewAllocatedBatchSlot(\n                        slotPool, mainThreadExecutor, resourceProfile);\n\n        assertThat(slotFuture, FlinkMatchers.willNotComplete(Duration.ofMillis(50L)));\n    }\n}", "summary_tokens": ["tests", "that", "a", "batch", "slot", "request", "won", "t", "fail", "if", "its", "resource", "manager", "request", "fails", "with", "exceptions", "other", "than", "unfulfillable", "slot", "request", "exception"], "project": "flink"}
{"id": 9439, "code": "public static MemorySegment[] splitBytes(byte[] bytes, int baseOffset) {\n    int newSize = (bytes.length + 1) / 2 + baseOffset;\n    MemorySegment[] ret = new MemorySegment[2];\n    ret[0] = MemorySegmentFactory.wrap(new byte[newSize]);\n    ret[1] = MemorySegmentFactory.wrap(new byte[newSize]);\n\n    ret[0].put(baseOffset, bytes, 0, newSize - baseOffset);\n    ret[1].put(0, bytes, newSize - baseOffset, bytes.length - (newSize - baseOffset));\n    return ret;\n}", "summary_tokens": ["split", "the", "given", "byte", "array", "into", "two", "memory", "segments"], "project": "flink"}
{"id": 18, "code": "protected void info(String[] args) throws Exception {\n    LOG.info(\"Running 'info' command.\");\n\n    final Options commandOptions = CliFrontendParser.getInfoCommandOptions();\n\n    final CommandLine commandLine = CliFrontendParser.parse(commandOptions, args, true);\n\n    final ProgramOptions programOptions = ProgramOptions.create(commandLine);\n\n        \n    if (commandLine.hasOption(HELP_OPTION.getOpt())) {\n        CliFrontendParser.printHelpForInfo();\n        return;\n    }\n\n        \n\n    LOG.info(\"Building program from JAR file\");\n\n    PackagedProgram program = null;\n\n    try {\n        int parallelism = programOptions.getParallelism();\n        if (ExecutionConfig.PARALLELISM_DEFAULT == parallelism) {\n            parallelism = defaultParallelism;\n        }\n\n        LOG.info(\"Creating program plan dump\");\n\n        final CustomCommandLine activeCommandLine =\n                validateAndGetActiveCommandLine(checkNotNull(commandLine));\n\n        final Configuration effectiveConfiguration =\n                getEffectiveConfiguration(\n                        activeCommandLine,\n                        commandLine,\n                        programOptions,\n                        getJobJarAndDependencies(programOptions));\n\n        program = buildProgram(programOptions, effectiveConfiguration);\n\n        Pipeline pipeline =\n                PackagedProgramUtils.getPipelineFromProgram(\n                        program, effectiveConfiguration, parallelism, true);\n        String jsonPlan = FlinkPipelineTranslationUtil.translateToJSONExecutionPlan(pipeline);\n\n        if (jsonPlan != null) {\n            System.out.println(\n                    \"----------------------- Execution Plan -----------------------\");\n            System.out.println(jsonPlan);\n            System.out.println(\n                    \"--------------------------------------------------------------\");\n        } else {\n            System.out.println(\"JSON plan could not be generated.\");\n        }\n\n        String description = program.getDescription();\n        if (description != null) {\n            System.out.println();\n            System.out.println(description);\n        } else {\n            System.out.println();\n            System.out.println(\"No description provided.\");\n        }\n    } finally {\n        if (program != null) {\n            program.close();\n        }\n    }\n}", "summary_tokens": ["executes", "the", "info", "action"], "project": "flink"}
{"id": 9532, "code": "public static void assumeCredentialsAvailable() {\n    Assume.assumeTrue(\n            \"No S3 credentials available in this test's environment\", credentialsAvailable());\n}", "summary_tokens": ["checks", "whether", "credentials", "are", "available", "in", "the", "environment", "variables", "of", "this", "jvm"], "project": "flink"}
{"id": 1730, "code": "private String normalizePath(String path) {\n        \n    path = path.replace(\"\\\\\", \"/\");\n    path = path.replaceAll(\"/+\", \"/\");\n\n        \n    if (path.endsWith(SEPARATOR)\n            && !path.equals(SEPARATOR)\n            && \n            !WINDOWS_ROOT_DIR_REGEX.matcher(path).matches()) { \n\n            \n        path = path.substring(0, path.length() - SEPARATOR.length());\n    }\n\n    return path;\n}", "summary_tokens": ["normalizes", "a", "path", "string"], "project": "flink"}
{"id": 4052, "code": "protected void scheduleRunAsync(Runnable runnable, long delay, TimeUnit unit) {\n    rpcServer.scheduleRunAsync(runnable, unit.toMillis(delay));\n}", "summary_tokens": ["execute", "the", "runnable", "in", "the", "main", "thread", "of", "the", "underlying", "rpc", "endpoint", "with", "a", "delay", "of", "the", "given", "number", "of", "milliseconds"], "project": "flink"}
{"id": 8640, "code": "public static DecimalType findAdditionDecimalType(\n        int precision1, int scale1, int precision2, int scale2) {\n    final int scale = Math.max(scale1, scale2);\n    int precision = Math.max(precision1 - scale1, precision2 - scale2) + scale + 1;\n    return adjustPrecisionScale(precision, scale);\n}", "summary_tokens": ["finds", "the", "result", "type", "of", "a", "decimal", "addition", "operation"], "project": "flink"}
{"id": 8190, "code": "public Iterable<T> get() throws Exception {\n    return list;\n}", "summary_tokens": ["returns", "an", "iterable", "of", "the", "list", "view"], "project": "flink"}
{"id": 1560, "code": "public TypeInformation<K> getKeyTypeInfo() {\n    return keyTypeInfo;\n}", "summary_tokens": ["gets", "the", "type", "information", "for", "the", "keys", "in", "the", "map"], "project": "flink"}
{"id": 6178, "code": "public void testReceivePartitionNotFoundException() throws Exception {\n        \n    final BufferProvider bufferProvider = mock(BufferProvider.class);\n    when(bufferProvider.requestBuffer()).thenReturn(TestBufferFactory.createBuffer(0));\n\n    final RemoteInputChannel inputChannel = mock(RemoteInputChannel.class);\n    when(inputChannel.getInputChannelId()).thenReturn(new InputChannelID());\n    when(inputChannel.getBufferProvider()).thenReturn(bufferProvider);\n\n    final ErrorResponse partitionNotFound =\n            new ErrorResponse(\n                    new PartitionNotFoundException(new ResultPartitionID()),\n                    inputChannel.getInputChannelId());\n\n    final CreditBasedPartitionRequestClientHandler client =\n            new CreditBasedPartitionRequestClientHandler();\n    client.addInputChannel(inputChannel);\n\n        \n    ChannelHandlerContext ctx = mock(ChannelHandlerContext.class);\n    when(ctx.channel()).thenReturn(mock(Channel.class));\n\n    client.channelActive(ctx);\n\n    client.channelRead(ctx, partitionNotFound);\n\n    verify(inputChannel, times(1)).onFailedPartitionRequest();\n}", "summary_tokens": ["verifies", "that", "remote", "input", "channel", "on", "failed", "partition", "request", "is", "called", "when", "a", "partition", "not", "found", "exception", "is", "received"], "project": "flink"}
{"id": 4404, "code": "public void notifyCheckpointOnComplete(\n        long completedCheckpointId, long completedTimestamp, long lastSubsumedCheckpointId) {\n    final LogicalSlot slot = assignedResource;\n\n    if (slot != null) {\n        final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway();\n\n        taskManagerGateway.notifyCheckpointOnComplete(\n                attemptId,\n                getVertex().getJobId(),\n                completedCheckpointId,\n                completedTimestamp,\n                lastSubsumedCheckpointId);\n    } else {\n        LOG.debug(\n                \"The execution has no slot assigned. This indicates that the execution is \"\n                        + \"no longer running.\");\n    }\n}", "summary_tokens": ["notify", "the", "task", "of", "this", "execution", "about", "a", "completed", "checkpoint", "and", "the", "last", "subsumed", "checkpoint", "id", "if", "possible"], "project": "flink"}
{"id": 8886, "code": "private Operation convertShowCatalogs(SqlShowCatalogs sqlShowCatalogs) {\n    return new ShowCatalogsOperation();\n}", "summary_tokens": ["convert", "show", "catalogs", "statement"], "project": "flink"}
{"id": 849, "code": "public static StartingPosition getStartingPosition(\n        final SequenceNumber sequenceNumber, final Properties configProps) {\n    if (sequenceNumber.equals(SENTINEL_LATEST_SEQUENCE_NUM.get())) {\n            \n            \n            \n            \n            \n            \n            \n            \n            \n            \n        return StartingPosition.fromTimestamp(new Date());\n    } else if (SENTINEL_AT_TIMESTAMP_SEQUENCE_NUM.get().equals(sequenceNumber)) {\n        Date timestamp = KinesisConfigUtil.parseStreamTimestampStartingPosition(configProps);\n        return StartingPosition.fromTimestamp(timestamp);\n    } else {\n        return StartingPosition.restartFromSequenceNumber(sequenceNumber);\n    }\n}", "summary_tokens": ["creates", "a", "starting", "position", "from", "the", "given", "sequence", "number", "and", "properties"], "project": "flink"}
{"id": 1099, "code": "public Collection<? extends GenericDataSinkBase<?>> getDataSinks() {\n    return this.sinks;\n}", "summary_tokens": ["gets", "all", "the", "data", "sinks", "of", "this", "job"], "project": "flink"}
{"id": 5737, "code": "public int getMaxStackTraceDepth() {\n    return maxStackTraceDepth;\n}", "summary_tokens": ["returns", "the", "configured", "maximum", "depth", "of", "the", "collected", "stack", "traces"], "project": "flink"}
{"id": 6646, "code": "public void doesNotReconnectAfterTargetLostLeadership() throws Exception {\n    final JobID jobId = new JobID();\n\n    final SettableLeaderRetrievalService leaderRetrievalService =\n            new SettableLeaderRetrievalService();\n    final TestingHighAvailabilityServices haServices =\n            new TestingHighAvailabilityServicesBuilder()\n                    .setJobMasterLeaderRetrieverFunction(ignored -> leaderRetrievalService)\n                    .build();\n    final TestingJobMasterGateway jobMasterGateway = registerJobMaster();\n\n    final OneShotLatch jobManagerGainedLeadership = new OneShotLatch();\n    final TestingJobLeaderListener testingJobLeaderListener =\n            new TestingJobLeaderListener(ignored -> jobManagerGainedLeadership.trigger());\n\n    final JobLeaderService jobLeaderService =\n            createAndStartJobLeaderService(haServices, testingJobLeaderListener);\n\n    try {\n        jobLeaderService.addJob(jobId, jobMasterGateway.getAddress());\n\n        leaderRetrievalService.notifyListener(jobMasterGateway.getAddress(), UUID.randomUUID());\n\n        jobManagerGainedLeadership.await();\n\n            \n        leaderRetrievalService.notifyListener(null, null);\n        testingJobLeaderListener.waitUntilJobManagerLostLeadership();\n\n        jobLeaderService.reconnect(jobId);\n    } finally {\n        jobLeaderService.stop();\n    }\n}", "summary_tokens": ["tests", "that", "the", "job", "leader", "service", "won", "t", "try", "to", "reconnect", "to", "job", "master", "after", "it", "has", "lost", "the", "leadership"], "project": "flink"}
{"id": 2225, "code": "private static boolean checkSkipMethodForwardCheck(\n        Method delegateMethod, Set<Method> skipMethods) {\n\n    if (delegateMethod.isBridge()\n            || delegateMethod.isDefault()\n            || skipMethods.contains(delegateMethod)) {\n        return true;\n    }\n\n        \n    try {\n        Object.class.getMethod(delegateMethod.getName(), delegateMethod.getParameterTypes());\n        return true;\n    } catch (Exception ignore) {\n    }\n    return false;\n}", "summary_tokens": ["test", "if", "this", "method", "should", "be", "skipped", "in", "our", "check", "for", "proper", "forwarding", "e"], "project": "flink"}
{"id": 253, "code": "void addBack(T object) {\n    pool.add(object);\n}", "summary_tokens": ["internal", "callback", "to", "put", "an", "entry", "back", "to", "the", "pool"], "project": "flink"}
{"id": 5318, "code": "public MemorySize computeShuffleMemorySizeForTask(TaskInputsOutputsDescriptor desc) {\n    checkNotNull(desc);\n\n    int numTotalInputChannels =\n            desc.getInputChannelNums().values().stream().mapToInt(Integer::intValue).sum();\n    int numTotalInputGates = desc.getInputChannelNums().size();\n\n    int numRequiredNetworkBuffers =\n            NettyShuffleUtils.computeNetworkBuffersForAnnouncing(\n                    buffersPerInputChannel,\n                    buffersPerInputGate,\n                    sortShuffleMinParallelism,\n                    sortShuffleMinBuffers,\n                    numTotalInputChannels,\n                    numTotalInputGates,\n                    desc.getSubpartitionNums(),\n                    desc.getPartitionTypes());\n\n    return new MemorySize((long) networkBufferSize * numRequiredNetworkBuffers);\n}", "summary_tokens": ["jm", "announces", "network", "memory", "requirement", "from", "the", "calculating", "result", "of", "this", "method"], "project": "flink"}
{"id": 6210, "code": "public void testFlushWithUnfinishedBufferBehindFinished2() throws Exception {\n        \n    subpartition.flush();\n    assertEquals(0, availablityListener.getNumNotifications());\n\n    subpartition.add(createFilledFinishedBufferConsumer(1025)); \n    subpartition.add(createFilledUnfinishedBufferConsumer(1024)); \n\n    assertEquals(1, subpartition.getBuffersInBacklogUnsafe());\n    assertNextBuffer(readView, 1025, false, 0, false, true);\n\n    long oldNumNotifications = availablityListener.getNumNotifications();\n    subpartition.flush();\n        \n    assertEquals(oldNumNotifications + 1, availablityListener.getNumNotifications());\n    subpartition.flush();\n        \n    assertEquals(oldNumNotifications + 1, availablityListener.getNumNotifications());\n\n    assertEquals(1, subpartition.getBuffersInBacklogUnsafe());\n    assertNextBuffer(readView, 1024, false, 0, false, false);\n    assertNoNextBuffer(readView);\n}", "summary_tokens": ["a", "flush", "call", "with", "a", "buffer", "size", "of", "0", "should", "always", "notify", "consumers", "unless", "already", "flushed"], "project": "flink"}
{"id": 6034, "code": "public void testSuspendedOutOfDeploying() throws Exception {\n    final int parallelism = 10;\n    final InteractionsCountingTaskManagerGateway gateway =\n            new InteractionsCountingTaskManagerGateway(parallelism);\n    final SchedulerBase scheduler = createScheduler(gateway, parallelism);\n    final ExecutionGraph eg = scheduler.getExecutionGraph();\n\n    scheduler.startScheduling();\n    assertEquals(JobStatus.RUNNING, eg.getState());\n    validateAllVerticesInState(eg, ExecutionState.DEPLOYING);\n\n        \n    scheduler.closeAsync();\n\n    assertEquals(JobStatus.SUSPENDED, eg.getState());\n    validateCancelRpcCalls(gateway, parallelism);\n\n    ensureCannotLeaveSuspendedState(scheduler, gateway);\n}", "summary_tokens": ["going", "into", "suspended", "out", "of", "deploying", "vertices", "should", "cancel", "all", "vertices", "once", "with", "rpc", "calls"], "project": "flink"}
{"id": 4575, "code": "int refreshAndGetMax() {\n    int max = 0;\n    int numSubpartitions = partition.getNumberOfSubpartitions();\n\n    for (int targetSubpartition = 0;\n            targetSubpartition < numSubpartitions;\n            ++targetSubpartition) {\n        int size = partition.getNumberOfQueuedBuffers(targetSubpartition);\n        max = Math.max(max, size);\n    }\n\n    return max;\n}", "summary_tokens": ["iterates", "over", "all", "sub", "partitions", "and", "collects", "the", "maximum", "number", "of", "queued", "buffers", "in", "a", "sub", "partition", "in", "a", "best", "effort", "way"], "project": "flink"}
{"id": 3698, "code": "public void setShipStrategyComparator(TypeComparatorFactory<?> shipStrategyComparator) {\n    this.shipStrategyComparator = shipStrategyComparator;\n}", "summary_tokens": ["sets", "the", "ship", "strategy", "comparator", "for", "this", "channel"], "project": "flink"}
{"id": 3385, "code": "private void initialize(int bytes) {\n    int capacity = bytes / ELEMENT_LENGTH_IN_BYTES;\n\n    Preconditions.checkArgument(capacity > 0, \"Requested array with zero capacity\");\n    Preconditions.checkArgument(\n            capacity <= MAX_ARRAY_SIZE,\n            \"Requested capacity exceeds limit of \" + MAX_ARRAY_SIZE);\n\n    data = new char[capacity];\n}", "summary_tokens": ["initializes", "the", "array", "with", "the", "provided", "number", "of", "bytes"], "project": "flink"}
{"id": 1461, "code": "public void setFields(T0 f0, T1 f1, T2 f2, T3 f3, T4 f4, T5 f5, T6 f6, T7 f7, T8 f8, T9 f9) {\n    this.f0 = f0;\n    this.f1 = f1;\n    this.f2 = f2;\n    this.f3 = f3;\n    this.f4 = f4;\n    this.f5 = f5;\n    this.f6 = f6;\n    this.f7 = f7;\n    this.f8 = f8;\n    this.f9 = f9;\n}", "summary_tokens": ["sets", "new", "values", "to", "all", "fields", "of", "the", "tuple"], "project": "flink"}
{"id": 9241, "code": "private void insertToSortedList(Long recordTimestamp) {\n    ListIterator<Long> listIterator = sortedTimestamps.listIterator(sortedTimestamps.size());\n    boolean isContinue = true;\n    while (listIterator.hasPrevious() && isContinue) {\n        Long timestamp = listIterator.previous();\n        if (recordTimestamp >= timestamp) {\n            listIterator.next();\n            listIterator.add(recordTimestamp);\n            isContinue = false;\n        }\n    }\n\n    if (isContinue) {\n        sortedTimestamps.addFirst(recordTimestamp);\n    }\n}", "summary_tokens": ["inserts", "timestamps", "in", "order", "into", "a", "linked", "list"], "project": "flink"}
{"id": 611, "code": "public void produce(final ConsumerRecords<byte[], byte[]> element)\n        throws InterruptedException, WakeupException, ClosedException {\n\n    checkNotNull(element);\n\n    synchronized (lock) {\n        while (next != null && !wakeupProducer) {\n            lock.wait();\n        }\n\n        wakeupProducer = false;\n\n            \n        if (next != null) {\n            throw new WakeupException();\n        }\n            \n        else if (error == null) {\n            next = element;\n            lock.notifyAll();\n        }\n            \n        else {\n            throw new ClosedException();\n        }\n    }\n}", "summary_tokens": ["hands", "over", "an", "element", "from", "the", "producer"], "project": "flink"}
{"id": 3538, "code": "public void inc(long n) {\n    count += n;\n}", "summary_tokens": ["increment", "the", "current", "count", "by", "the", "given", "value"], "project": "flink"}
{"id": 5605, "code": "public String getHostname() {\n    return hostNameSupplier.getHostName();\n}", "summary_tokens": ["gets", "the", "hostname", "of", "the", "task", "manager", "from", "host", "name", "supplier"], "project": "flink"}
{"id": 403, "code": "public boolean isPartialScanAnalyzeCommand() {\n    return isPartialScanAnalyzeCommand;\n}", "summary_tokens": ["the", "is", "partial", "scan", "analyze", "command"], "project": "flink"}
{"id": 208, "code": "public void testBulkFailureRethrownOnInvoke() throws Throwable {\n    final DummyElasticsearchSink<String> sink =\n            new DummyElasticsearchSink<>(\n                    new HashMap<String, String>(),\n                    new SimpleSinkFunction<String>(),\n                    new NoOpFailureHandler());\n\n    final OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(new StreamSink<>(sink));\n\n    testHarness.open();\n\n        \n    sink.setFailNextBulkRequestCompletely(new Exception(\"artificial failure for bulk request\"));\n    testHarness.processElement(new StreamRecord<>(\"msg\"));\n    verify(sink.getMockBulkProcessor(), times(1)).add(any(IndexRequest.class));\n\n        \n    sink.manualBulkRequestWithAllPendingRequests();\n\n    try {\n        testHarness.processElement(new StreamRecord<>(\"next msg\"));\n    } catch (Exception e) {\n            \n        Assert.assertTrue(\n                e.getCause().getMessage().contains(\"artificial failure for bulk request\"));\n\n            \n        return;\n    }\n\n    Assert.fail();\n}", "summary_tokens": ["tests", "that", "any", "bulk", "failure", "in", "the", "listener", "callbacks", "is", "rethrown", "on", "an", "immediately", "following", "invoke", "call"], "project": "flink"}
{"id": 7063, "code": "public IterativeStream<T> iterate(long maxWaitTimeMillis) {\n    return new IterativeStream<>(this, maxWaitTimeMillis);\n}", "summary_tokens": ["initiates", "an", "iterative", "part", "of", "the", "program", "that", "feeds", "back", "data", "streams"], "project": "flink"}
{"id": 3111, "code": "public void writeAfterBranchingPatternSnapshot() throws Exception {\n\n    KeySelector<Event, Integer> keySelector =\n            new KeySelector<Event, Integer>() {\n                private static final long serialVersionUID = -4873366487571254798L;\n\n                @Override\n                public Integer getKey(Event value) throws Exception {\n                    return value.getId();\n                }\n            };\n\n    final Event startEvent = new Event(42, \"start\", 1.0);\n    final SubEvent middleEvent1 = new SubEvent(42, \"foo1\", 1.0, 10.0);\n    final SubEvent middleEvent2 = new SubEvent(42, \"foo2\", 2.0, 10.0);\n\n    OneInputStreamOperatorTestHarness<Event, Map<String, List<Event>>> harness =\n            new KeyedOneInputStreamOperatorTestHarness<>(\n                    CepOperatorTestUtilities.getKeyedCepOperator(false, new NFAFactory()),\n                    keySelector,\n                    BasicTypeInfo.INT_TYPE_INFO);\n\n    try {\n        harness.setup();\n        harness.open();\n\n        harness.processElement(new StreamRecord<Event>(startEvent, 1));\n        harness.processElement(new StreamRecord<Event>(new Event(42, \"foobar\", 1.0), 2));\n        harness.processElement(\n                new StreamRecord<Event>(new SubEvent(42, \"barfoo\", 1.0, 5.0), 3));\n        harness.processElement(new StreamRecord<Event>(middleEvent1, 2));\n        harness.processElement(new StreamRecord<Event>(middleEvent2, 3));\n\n        harness.processWatermark(new Watermark(5));\n\n            \n        OperatorSubtaskState snapshot = harness.snapshot(0L, 0L);\n        OperatorSnapshotUtil.writeStateHandle(\n                snapshot,\n                \"src/test/resources/cep-migration-after-branching-flink\"\n                        + flinkGenerateSavepointVersion\n                        + \"-snapshot\");\n    } finally {\n        harness.close();\n    }\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 1683, "code": "public long getTebiBytes() {\n    return bytes >> 40;\n}", "summary_tokens": ["gets", "the", "memory", "size", "in", "tebibytes", "0", "gibibytes"], "project": "flink"}
{"id": 7483, "code": "public static void mergeWindows(\n        Collection<TimeWindow> windows, MergingWindowAssigner.MergeCallback<TimeWindow> c) {\n\n        \n\n    List<TimeWindow> sortedWindows = new ArrayList<>(windows);\n\n    Collections.sort(\n            sortedWindows,\n            new Comparator<TimeWindow>() {\n                @Override\n                public int compare(TimeWindow o1, TimeWindow o2) {\n                    return Long.compare(o1.getStart(), o2.getStart());\n                }\n            });\n\n    List<Tuple2<TimeWindow, Set<TimeWindow>>> merged = new ArrayList<>();\n    Tuple2<TimeWindow, Set<TimeWindow>> currentMerge = null;\n\n    for (TimeWindow candidate : sortedWindows) {\n        if (currentMerge == null) {\n            currentMerge = new Tuple2<>();\n            currentMerge.f0 = candidate;\n            currentMerge.f1 = new HashSet<>();\n            currentMerge.f1.add(candidate);\n        } else if (currentMerge.f0.intersects(candidate)) {\n            currentMerge.f0 = currentMerge.f0.cover(candidate);\n            currentMerge.f1.add(candidate);\n        } else {\n            merged.add(currentMerge);\n            currentMerge = new Tuple2<>();\n            currentMerge.f0 = candidate;\n            currentMerge.f1 = new HashSet<>();\n            currentMerge.f1.add(candidate);\n        }\n    }\n\n    if (currentMerge != null) {\n        merged.add(currentMerge);\n    }\n\n    for (Tuple2<TimeWindow, Set<TimeWindow>> m : merged) {\n        if (m.f1.size() > 1) {\n            c.merge(m.f1, m.f0);\n        }\n    }\n}", "summary_tokens": ["merge", "overlapping", "time", "window", "s"], "project": "flink"}
{"id": 7074, "code": "public SingleOutputStreamOperator<T> assignTimestampsAndWatermarks(\n        AssignerWithPunctuatedWatermarks<T> timestampAndWatermarkAssigner) {\n\n    final AssignerWithPunctuatedWatermarks<T> cleanedAssigner =\n            clean(timestampAndWatermarkAssigner);\n    final WatermarkStrategy<T> wms =\n            new AssignerWithPunctuatedWatermarksAdapter.Strategy<>(cleanedAssigner);\n\n    return assignTimestampsAndWatermarks(wms);\n}", "summary_tokens": ["assigns", "timestamps", "to", "the", "elements", "in", "the", "data", "stream", "and", "creates", "watermarks", "based", "on", "events", "to", "signal", "event", "time", "progress"], "project": "flink"}
{"id": 5867, "code": "public void testDefaultBlobStorageDirectory() throws IOException {\n    Configuration config = new Configuration();\n    String blobStorageDir = temporaryFolder.newFolder().getAbsolutePath();\n    config.setString(BlobServerOptions.STORAGE_DIRECTORY, blobStorageDir);\n    config.setString(CoreOptions.TMP_DIRS, temporaryFolder.newFolder().getAbsolutePath());\n\n    File dir = BlobUtils.initLocalStorageDirectory(config);\n    assertThat(dir.getAbsolutePath(), startsWith(blobStorageDir));\n}", "summary_tokens": ["tests", "blob", "utils", "init", "local", "storage", "directory", "using", "blob", "server", "options", "storage", "directory", "per", "default"], "project": "flink"}
{"id": 8875, "code": "private Operation convertDropFunction(SqlDropFunction sqlDropFunction) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlDropFunction.getFunctionIdentifier());\n    if (sqlDropFunction.isSystemFunction()) {\n        return new DropTempSystemFunctionOperation(\n                unresolvedIdentifier.getObjectName(), sqlDropFunction.getIfExists());\n    } else {\n        ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n\n        return new DropCatalogFunctionOperation(\n                identifier, sqlDropFunction.getIfExists(), sqlDropFunction.isTemporary());\n    }\n}", "summary_tokens": ["convert", "drop", "function", "statement"], "project": "flink"}
{"id": 4295, "code": "public long getEndToEndDuration(long triggerTimestamp) {\n    return Math.max(0, ackTimestamp - triggerTimestamp);\n}", "summary_tokens": ["computes", "the", "duration", "since", "the", "given", "trigger", "timestamp"], "project": "flink"}
{"id": 1922, "code": "public static final Timestamp parseField(\n        byte[] bytes, int startPos, int length, char delimiter) {\n    final int limitedLen = nextStringLength(bytes, startPos, length, delimiter);\n\n    if (limitedLen > 0\n            && (Character.isWhitespace(bytes[startPos])\n                    || Character.isWhitespace(bytes[startPos + limitedLen - 1]))) {\n        throw new NumberFormatException(\n                \"There is leading or trailing whitespace in the numeric field.\");\n    }\n\n    final String str = new String(bytes, startPos, limitedLen, ConfigConstants.DEFAULT_CHARSET);\n    return Timestamp.valueOf(str);\n}", "summary_tokens": ["static", "utility", "to", "parse", "a", "field", "of", "type", "timestamp", "from", "a", "byte", "sequence", "that", "represents", "text", "characters", "such", "as", "when", "read", "from", "a", "file", "stream"], "project": "flink"}
{"id": 9711, "code": "protected void runWithArgs(\n        String[] args,\n        String terminateAfterString,\n        String[] failOnPatterns,\n        RunTypes type,\n        int expectedReturnValue,\n        Supplier<Collection<String>> logMessageSupplier)\n        throws IOException {\n    LOG.info(\"Running with args {}\", Arrays.toString(args));\n\n    outContent = new ByteArrayOutputStream();\n    errContent = new ByteArrayOutputStream();\n    PipedOutputStream out = new PipedOutputStream();\n    PipedInputStream in = new PipedInputStream(out);\n    PrintStream stdinPrintStream = new PrintStream(out);\n    System.setOut(new PrintStream(outContent));\n    System.setErr(new PrintStream(errContent));\n    System.setIn(in);\n\n        \n    final int startTimeoutSeconds = 180;\n    final long deadline = System.currentTimeMillis() + (startTimeoutSeconds * 1000);\n\n    Runner runner =\n            new Runner(\n                    args,\n                    flinkConfiguration,\n                    CliFrontend.getConfigurationDirectoryFromEnv(),\n                    type,\n                    expectedReturnValue,\n                    stdinPrintStream);\n    runner.start();\n\n    boolean expectedStringSeen = false;\n    boolean testPassedFromLog4j = false;\n    long shutdownTimeout = 30000L;\n    do {\n        sleep(1000);\n        String outContentString = outContent.toString();\n        String errContentString = errContent.toString();\n        if (failOnPatterns != null) {\n            for (String failOnString : failOnPatterns) {\n                Pattern pattern = Pattern.compile(failOnString);\n                if (pattern.matcher(outContentString).find()\n                        || pattern.matcher(errContentString).find()) {\n                    LOG.warn(\n                            \"Failing test. Output contained illegal string '\"\n                                    + failOnString\n                                    + \"'\");\n                    resetStreamsAndSendOutput();\n                        \n                    runner.sendStop();\n                        \n                    try {\n                        runner.join(shutdownTimeout);\n                    } catch (InterruptedException e) {\n                        LOG.warn(\"Interrupted while stopping runner\", e);\n                    }\n                    Assert.fail(\"Output contained illegal string '\" + failOnString + \"'\");\n                }\n            }\n        }\n\n        for (String logMessage : logMessageSupplier.get()) {\n            if (logMessage.contains(terminateAfterString)) {\n                testPassedFromLog4j = true;\n                LOG.info(\"Found expected output in logging event {}\", logMessage);\n            }\n        }\n\n        if (outContentString.contains(terminateAfterString)\n                || errContentString.contains(terminateAfterString)\n                || testPassedFromLog4j) {\n            expectedStringSeen = true;\n            LOG.info(\"Found expected output in redirected streams\");\n                \n            LOG.info(\"RunWithArgs: request runner to stop\");\n            runner.sendStop();\n                \n            try {\n                runner.join(shutdownTimeout);\n            } catch (InterruptedException e) {\n                LOG.warn(\"Interrupted while stopping runner\", e);\n            }\n            LOG.warn(\"RunWithArgs runner stopped.\");\n        } else {\n                \n            if (!runner.isAlive()) {\n                    \n                break;\n            }\n        }\n    } while (runner.getRunnerError() == null\n            && !expectedStringSeen\n            && System.currentTimeMillis() < deadline);\n\n    resetStreamsAndSendOutput();\n\n    if (runner.getRunnerError() != null) {\n            \n        throw new RuntimeException(\"Runner failed\", runner.getRunnerError());\n    }\n    Assert.assertTrue(\n            \"During the timeout period of \"\n                    + startTimeoutSeconds\n                    + \" seconds the \"\n                    + \"expected string \\\"\"\n                    + terminateAfterString\n                    + \"\\\" did not show up.\",\n            expectedStringSeen);\n\n    LOG.info(\"Test was successful\");\n}", "summary_tokens": ["the", "test", "has", "been", "passed", "once", "the", "terminate", "after", "string", "has", "been", "seen"], "project": "flink"}
{"id": 73, "code": "public CompletableFuture<JobResult> requestJobResult(@Nonnull JobID jobId) {\n    final CheckedSupplier<CompletableFuture<JobResult>> operation =\n            () -> requestJobResultInternal(jobId);\n    return retry(operation, unknownJobStateRetryable);\n}", "summary_tokens": ["requests", "the", "job", "result", "for", "the", "given", "job", "id"], "project": "flink"}
{"id": 4284, "code": "public long getSum() {\n    return sum;\n}", "summary_tokens": ["returns", "the", "sum", "of", "all", "seen", "values"], "project": "flink"}
{"id": 7405, "code": "static <IN> void putNormalizedKey(\n        Tuple2<byte[], StreamRecord<IN>> record,\n        int dataLength,\n        MemorySegment target,\n        int offset,\n        int numBytes) {\n    byte[] data = record.f0;\n\n    if (dataLength >= numBytes) {\n        putBytesArray(target, offset, numBytes, data);\n    } else {\n            \n        putBytesArray(target, offset, dataLength, data);\n        int lastOffset = offset + numBytes;\n        offset += dataLength;\n        long valueOfTimestamp = record.f1.asRecord().getTimestamp() - Long.MIN_VALUE;\n        if (dataLength + TIMESTAMP_BYTE_SIZE <= numBytes) {\n                \n            target.putLong(offset, valueOfTimestamp);\n            offset += TIMESTAMP_BYTE_SIZE;\n                \n            while (offset < lastOffset) {\n                target.put(offset++, (byte) 0);\n            }\n        } else {\n                \n            for (int i = 0; offset < lastOffset; offset++, i++) {\n                target.put(offset, (byte) (valueOfTimestamp >>> ((7 - i) << 3)));\n            }\n        }\n    }\n}", "summary_tokens": ["writes", "the", "normalized", "key", "of", "given", "record"], "project": "flink"}
{"id": 3704, "code": "public Collection<SourcePlanNode> getDataSources() {\n    return dataSources;\n}", "summary_tokens": ["gets", "the", "data", "sources", "from", "this", "optimized", "plan"], "project": "flink"}
{"id": 2832, "code": "public ReduceOperator<T> maxBy(int... fields) {\n\n        \n    if (!this.inputDataSet.getType().isTupleType()\n            || !(this.inputDataSet.getType() instanceof TupleTypeInfo)) {\n        throw new InvalidProgramException(\"Method maxBy(int) only works on tuples.\");\n    }\n\n    return new ReduceOperator<T>(\n            this,\n            new SelectByMaxFunction((TupleTypeInfo) this.inputDataSet.getType(), fields),\n            Utils.getCallLocationName());\n}", "summary_tokens": ["applies", "a", "special", "case", "of", "a", "reduce", "transformation", "max", "by", "on", "a", "grouped", "data", "set"], "project": "flink"}
{"id": 8398, "code": "public static <V> Optional<V> extractValue(Expression expression, Class<V> targetClass) {\n    if (expression instanceof ValueLiteralExpression) {\n        final ValueLiteralExpression valueLiteral = (ValueLiteralExpression) expression;\n        return valueLiteral.getValueAs(targetClass);\n    }\n    return Optional.empty();\n}", "summary_tokens": ["extracts", "the", "value", "excluding", "null", "of", "a", "given", "class", "from", "an", "expression", "assuming", "it", "is", "a", "value", "literal", "expression"], "project": "flink"}
{"id": 744, "code": "public void setDefaultStream(String defaultStream) {\n    this.defaultStream = defaultStream;\n}", "summary_tokens": ["set", "a", "default", "stream", "name"], "project": "flink"}
{"id": 7906, "code": "public void open() throws Exception {\n    if (!initializeCalled) {\n        initializeEmptyState();\n    }\n    operator.open();\n}", "summary_tokens": ["calls", "stream", "operator", "open"], "project": "flink"}
{"id": 5554, "code": "public static ResourceProfile generateDefaultSlotResourceProfile(\n        TaskExecutorResourceSpec taskExecutorResourceSpec, int numberOfSlots) {\n    final ResourceProfile.Builder resourceProfileBuilder =\n            ResourceProfile.newBuilder()\n                    .setCpuCores(taskExecutorResourceSpec.getCpuCores().divide(numberOfSlots))\n                    .setTaskHeapMemory(\n                            taskExecutorResourceSpec.getTaskHeapSize().divide(numberOfSlots))\n                    .setTaskOffHeapMemory(\n                            taskExecutorResourceSpec.getTaskOffHeapSize().divide(numberOfSlots))\n                    .setManagedMemory(\n                            taskExecutorResourceSpec\n                                    .getManagedMemorySize()\n                                    .divide(numberOfSlots))\n                    .setNetworkMemory(\n                            taskExecutorResourceSpec.getNetworkMemSize().divide(numberOfSlots));\n    taskExecutorResourceSpec\n            .getExtendedResources()\n            .forEach(\n                    (name, resource) ->\n                            resourceProfileBuilder.setExtendedResource(\n                                    resource.divide(numberOfSlots)));\n    return resourceProfileBuilder.build();\n}", "summary_tokens": ["this", "must", "be", "consist", "with", "org"], "project": "flink"}
{"id": 173, "code": "public CassandraSink<IN> uid(String uid) {\n    if (useDataStreamSink) {\n        getSinkTransformation().setUid(uid);\n    } else {\n        getTransformation().setUid(uid);\n    }\n    return this;\n}", "summary_tokens": ["sets", "an", "id", "for", "this", "operator"], "project": "flink"}
{"id": 7748, "code": "public void testReaderScalingUp() throws Exception {\n    try (HarnessWithFormat beforeRescale = buildAndStart(1, 0, 5, null, buildSplits(2))) {\n        OperatorSubtaskState snapshot = beforeRescale.getHarness().snapshot(0, 0);\n        try (HarnessWithFormat afterRescale0 =\n                        buildAndStart(\n                                2,\n                                0,\n                                15,\n                                repartitionOperatorState(snapshot, maxParallelism, 1, 2, 0));\n                HarnessWithFormat afterRescale1 =\n                        buildAndStart(\n                                2,\n                                1,\n                                15,\n                                repartitionOperatorState(snapshot, maxParallelism, 1, 2, 1))) {\n\n            beforeRescale.getHarness().getOutput().clear();\n\n            for (HarnessWithFormat harness :\n                    Arrays.asList(beforeRescale, afterRescale0, afterRescale1)) {\n                harness.awaitEverythingProcessed();\n            }\n\n            Assert.assertEquals(\n                    collectOutput(beforeRescale), collectOutput(afterRescale0, afterRescale1));\n        }\n    }\n}", "summary_tokens": ["simulates", "the", "scenario", "of", "scaling", "up", "from", "0", "to", "0", "instances"], "project": "flink"}
{"id": 1326, "code": "default void notifyCheckpointAborted(long checkpointId) throws Exception {}", "summary_tokens": ["this", "method", "is", "called", "as", "a", "notification", "once", "a", "distributed", "checkpoint", "has", "been", "aborted"], "project": "flink"}
{"id": 5231, "code": "public Map<String, String> pathParams() {\n    return pathParams;\n}", "summary_tokens": ["returns", "all", "params", "embedded", "in", "the", "request", "path"], "project": "flink"}
{"id": 2743, "code": "public <\n                T0,\n                T1,\n                T2,\n                T3,\n                T4,\n                T5,\n                T6,\n                T7,\n                T8,\n                T9,\n                T10,\n                T11,\n                T12,\n                T13,\n                T14,\n                T15,\n                T16,\n                T17,\n                T18,\n                T19,\n                T20,\n                T21,\n                T22,\n                T23,\n                T24>\n        DataSource<\n                        Tuple25<\n                                T0,\n                                T1,\n                                T2,\n                                T3,\n                                T4,\n                                T5,\n                                T6,\n                                T7,\n                                T8,\n                                T9,\n                                T10,\n                                T11,\n                                T12,\n                                T13,\n                                T14,\n                                T15,\n                                T16,\n                                T17,\n                                T18,\n                                T19,\n                                T20,\n                                T21,\n                                T22,\n                                T23,\n                                T24>>\n                types(\n                        Class<T0> type0,\n                        Class<T1> type1,\n                        Class<T2> type2,\n                        Class<T3> type3,\n                        Class<T4> type4,\n                        Class<T5> type5,\n                        Class<T6> type6,\n                        Class<T7> type7,\n                        Class<T8> type8,\n                        Class<T9> type9,\n                        Class<T10> type10,\n                        Class<T11> type11,\n                        Class<T12> type12,\n                        Class<T13> type13,\n                        Class<T14> type14,\n                        Class<T15> type15,\n                        Class<T16> type16,\n                        Class<T17> type17,\n                        Class<T18> type18,\n                        Class<T19> type19,\n                        Class<T20> type20,\n                        Class<T21> type21,\n                        Class<T22> type22,\n                        Class<T23> type23,\n                        Class<T24> type24) {\n    TupleTypeInfo<\n                    Tuple25<\n                            T0,\n                            T1,\n                            T2,\n                            T3,\n                            T4,\n                            T5,\n                            T6,\n                            T7,\n                            T8,\n                            T9,\n                            T10,\n                            T11,\n                            T12,\n                            T13,\n                            T14,\n                            T15,\n                            T16,\n                            T17,\n                            T18,\n                            T19,\n                            T20,\n                            T21,\n                            T22,\n                            T23,\n                            T24>>\n            types =\n                    TupleTypeInfo.getBasicAndBasicValueTupleTypeInfo(\n                            type0, type1, type2, type3, type4, type5, type6, type7, type8,\n                            type9, type10, type11, type12, type13, type14, type15, type16,\n                            type17, type18, type19, type20, type21, type22, type23, type24);\n    CsvInputFormat<\n                    Tuple25<\n                            T0,\n                            T1,\n                            T2,\n                            T3,\n                            T4,\n                            T5,\n                            T6,\n                            T7,\n                            T8,\n                            T9,\n                            T10,\n                            T11,\n                            T12,\n                            T13,\n                            T14,\n                            T15,\n                            T16,\n                            T17,\n                            T18,\n                            T19,\n                            T20,\n                            T21,\n                            T22,\n                            T23,\n                            T24>>\n            inputFormat =\n                    new TupleCsvInputFormat<\n                            Tuple25<\n                                    T0,\n                                    T1,\n                                    T2,\n                                    T3,\n                                    T4,\n                                    T5,\n                                    T6,\n                                    T7,\n                                    T8,\n                                    T9,\n                                    T10,\n                                    T11,\n                                    T12,\n                                    T13,\n                                    T14,\n                                    T15,\n                                    T16,\n                                    T17,\n                                    T18,\n                                    T19,\n                                    T20,\n                                    T21,\n                                    T22,\n                                    T23,\n                                    T24>>(path, types, this.includedMask);\n    configureInputFormat(inputFormat);\n    return new DataSource<\n            Tuple25<\n                    T0,\n                    T1,\n                    T2,\n                    T3,\n                    T4,\n                    T5,\n                    T6,\n                    T7,\n                    T8,\n                    T9,\n                    T10,\n                    T11,\n                    T12,\n                    T13,\n                    T14,\n                    T15,\n                    T16,\n                    T17,\n                    T18,\n                    T19,\n                    T20,\n                    T21,\n                    T22,\n                    T23,\n                    T24>>(executionContext, inputFormat, types, Utils.getCallLocationName());\n}", "summary_tokens": ["specifies", "the", "types", "for", "the", "csv", "fields"], "project": "flink"}
{"id": 8591, "code": "public static TypeStrategy first(TypeStrategy... strategies) {\n    return new FirstTypeStrategy(Arrays.asList(strategies));\n}", "summary_tokens": ["type", "strategy", "that", "returns", "the", "first", "type", "that", "could", "be", "inferred"], "project": "flink"}
{"id": 5572, "code": "default int freeSlot(AllocationID allocationId) throws SlotNotFoundException {\n    return freeSlot(allocationId, new Exception(\"The task slot of this task is being freed.\"));\n}", "summary_tokens": ["try", "to", "free", "the", "slot"], "project": "flink"}
{"id": 7201, "code": "public boolean isUnalignedCheckpointsEnabled() {\n    return unalignedCheckpointsEnabled;\n}", "summary_tokens": ["returns", "whether", "unaligned", "checkpoints", "are", "enabled"], "project": "flink"}
{"id": 1622, "code": "private static Tuple4<int[], Integer, Integer, Boolean> createAuxiliaryFields(\n        int[] keyPositions, NullAwareComparator<Object>[] comparators) {\n\n    int[] normalizedKeyLengths = new int[keyPositions.length];\n    int numLeadingNormalizableKeys = 0;\n    int normalizableKeyPrefixLen = 0;\n    boolean inverted = false;\n\n    for (int i = 0; i < keyPositions.length; i++) {\n        NullAwareComparator<Object> k = comparators[i];\n            \n            \n        if (k.supportsNormalizedKey()) {\n            if (i == 0) {\n                    \n                inverted = k.invertNormalizedKey();\n            } else if (k.invertNormalizedKey() != inverted) {\n                    \n                    \n                    \n                return new Tuple4<>(\n                        normalizedKeyLengths,\n                        numLeadingNormalizableKeys,\n                        normalizableKeyPrefixLen,\n                        inverted);\n            }\n            numLeadingNormalizableKeys++;\n            int len = k.getNormalizeKeyLen();\n            if (len < 0) {\n                throw new RuntimeException(\n                        \"Comparator \"\n                                + k.getClass().getName()\n                                + \" specifies an invalid length for the normalized key: \"\n                                + len);\n            }\n            normalizedKeyLengths[i] = len;\n            normalizableKeyPrefixLen += len;\n            if (normalizableKeyPrefixLen < 0) {\n                    \n                return new Tuple4<>(\n                        normalizedKeyLengths,\n                        numLeadingNormalizableKeys,\n                        Integer.MAX_VALUE,\n                        inverted);\n            }\n        } else {\n            return new Tuple4<>(\n                    normalizedKeyLengths,\n                    numLeadingNormalizableKeys,\n                    normalizableKeyPrefixLen,\n                    inverted);\n        }\n    }\n    return new Tuple4<>(\n            normalizedKeyLengths,\n            numLeadingNormalizableKeys,\n            normalizableKeyPrefixLen,\n            inverted);\n}", "summary_tokens": ["creates", "auxiliary", "fields", "for", "normalized", "key", "support"], "project": "flink"}
{"id": 1433, "code": "public void setResources(ResourceSpec minResources, ResourceSpec preferredResources) {\n    OperatorValidationUtils.validateMinAndPreferredResources(minResources, preferredResources);\n    this.minResources = checkNotNull(minResources);\n    this.preferredResources = checkNotNull(preferredResources);\n}", "summary_tokens": ["sets", "the", "minimum", "and", "preferred", "resources", "for", "this", "stream", "transformation"], "project": "flink"}
{"id": 5905, "code": "public void testSetState() {\n    try {\n        KeyGroupRange keyGroupRange = KeyGroupRange.of(0, 0);\n        List<SerializableObject> testStates =\n                Collections.singletonList(new SerializableObject());\n        final KeyedStateHandle serializedKeyGroupStates =\n                CheckpointCoordinatorTestingUtils.generateKeyGroupState(\n                        keyGroupRange, testStates);\n\n        final JobVertexID statefulId = new JobVertexID();\n        final JobVertexID statelessId = new JobVertexID();\n\n        ExecutionGraph graph =\n                new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                        .addJobVertex(statefulId, 3, 256)\n                        .addJobVertex(statelessId, 2, 256)\n                        .build();\n\n        ExecutionJobVertex stateful = graph.getJobVertex(statefulId);\n        ExecutionJobVertex stateless = graph.getJobVertex(statelessId);\n\n        ExecutionVertex stateful1 = stateful.getTaskVertices()[0];\n        ExecutionVertex stateful2 = stateful.getTaskVertices()[1];\n        ExecutionVertex stateful3 = stateful.getTaskVertices()[2];\n        ExecutionVertex stateless1 = stateless.getTaskVertices()[0];\n        ExecutionVertex stateless2 = stateless.getTaskVertices()[1];\n\n        Execution statefulExec1 = stateful1.getCurrentExecutionAttempt();\n        Execution statefulExec2 = stateful2.getCurrentExecutionAttempt();\n        Execution statefulExec3 = stateful3.getCurrentExecutionAttempt();\n        Execution statelessExec1 = stateless1.getCurrentExecutionAttempt();\n        Execution statelessExec2 = stateless2.getCurrentExecutionAttempt();\n\n        ManuallyTriggeredScheduledExecutor manuallyTriggeredScheduledExecutor =\n                new ManuallyTriggeredScheduledExecutor();\n\n        CheckpointCoordinator coord =\n                new CheckpointCoordinatorBuilder()\n                        .setExecutionGraph(graph)\n                        .setTimer(manuallyTriggeredScheduledExecutor)\n                        .build();\n\n            \n        coord.triggerCheckpoint(false);\n        manuallyTriggeredScheduledExecutor.triggerAll();\n\n        PendingCheckpoint pending = coord.getPendingCheckpoints().values().iterator().next();\n        final long checkpointId = pending.getCheckpointId();\n\n        final TaskStateSnapshot subtaskStates = new TaskStateSnapshot();\n\n        subtaskStates.putSubtaskStateByOperatorID(\n                OperatorID.fromJobVertexID(statefulId),\n                OperatorSubtaskState.builder()\n                        .setManagedKeyedState(serializedKeyGroupStates)\n                        .build());\n\n        coord.receiveAcknowledgeMessage(\n                new AcknowledgeCheckpoint(\n                        graph.getJobID(),\n                        statefulExec1.getAttemptId(),\n                        checkpointId,\n                        new CheckpointMetrics(),\n                        subtaskStates),\n                TASK_MANAGER_LOCATION_INFO);\n        coord.receiveAcknowledgeMessage(\n                new AcknowledgeCheckpoint(\n                        graph.getJobID(),\n                        statefulExec2.getAttemptId(),\n                        checkpointId,\n                        new CheckpointMetrics(),\n                        subtaskStates),\n                TASK_MANAGER_LOCATION_INFO);\n        coord.receiveAcknowledgeMessage(\n                new AcknowledgeCheckpoint(\n                        graph.getJobID(),\n                        statefulExec3.getAttemptId(),\n                        checkpointId,\n                        new CheckpointMetrics(),\n                        subtaskStates),\n                TASK_MANAGER_LOCATION_INFO);\n        coord.receiveAcknowledgeMessage(\n                new AcknowledgeCheckpoint(\n                        graph.getJobID(), statelessExec1.getAttemptId(), checkpointId),\n                TASK_MANAGER_LOCATION_INFO);\n        coord.receiveAcknowledgeMessage(\n                new AcknowledgeCheckpoint(\n                        graph.getJobID(), statelessExec2.getAttemptId(), checkpointId),\n                TASK_MANAGER_LOCATION_INFO);\n\n        assertEquals(1, coord.getNumberOfRetainedSuccessfulCheckpoints());\n        assertEquals(0, coord.getNumberOfPendingCheckpoints());\n\n            \n        assertTrue(\n                coord.restoreLatestCheckpointedStateToAll(\n                        new HashSet<>(Arrays.asList(stateful, stateless)), false));\n\n            \n        assertEquals(subtaskStates, statefulExec1.getTaskRestore().getTaskStateSnapshot());\n        assertEquals(subtaskStates, statefulExec2.getTaskRestore().getTaskStateSnapshot());\n        assertEquals(subtaskStates, statefulExec3.getTaskRestore().getTaskStateSnapshot());\n        assertNull(statelessExec1.getTaskRestore());\n        assertNull(statelessExec2.getTaskRestore());\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["tests", "that", "on", "restore", "the", "task", "state", "is", "reset", "for", "each", "stateful", "task"], "project": "flink"}
{"id": 6738, "code": "S getNode(MemorySegment keySegment, int keyOffset, int keyLen) {\n    SkipListIterateAndProcessResult result =\n            iterateAndProcess(\n                    keySegment,\n                    keyOffset,\n                    keyLen,\n                    (pointers, isRemoved) -> {\n                        long currentNode = pointers.currentNode;\n                        return isRemoved ? null : getNodeStateHelper(currentNode);\n                    });\n    return result.isKeyFound ? result.state : null;\n}", "summary_tokens": ["find", "the", "node", "containing", "the", "given", "key"], "project": "flink"}
{"id": 6422, "code": "public void testDuplicateResourceRequirementDeclarationAfterSuccessfulAllocation()\n        throws Exception {\n    final List<CompletableFuture<Void>> allocateResourceFutures = new ArrayList<>();\n    allocateResourceFutures.add(new CompletableFuture<>());\n    allocateResourceFutures.add(new CompletableFuture<>());\n    final ResourceRequirements requirements = createResourceRequirementsForSingleSlot();\n\n    new Context() {\n        {\n            resourceActionsBuilder.setAllocateResourceConsumer(\n                    ignored -> {\n                        if (allocateResourceFutures.get(0).isDone()) {\n                            allocateResourceFutures.get(1).complete(null);\n                        } else {\n                            allocateResourceFutures.get(0).complete(null);\n                        }\n                    });\n            runTest(\n                    () -> {\n                        runInMainThread(\n                                () ->\n                                        getSlotManager()\n                                                .processResourceRequirements(requirements));\n                        assertFutureCompleteAndReturn(allocateResourceFutures.get(0));\n\n                        runInMainThread(\n                                () ->\n                                        getSlotManager()\n                                                .processResourceRequirements(requirements));\n                            \n                            \n                        assertFutureNotComplete(allocateResourceFutures.get(1));\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "that", "duplicate", "resource", "requirement", "declaration", "do", "not", "result", "in", "additional", "slots", "being", "allocated", "after", "a", "pending", "slot", "request", "has", "been", "fulfilled", "but", "not", "yet", "freed"], "project": "flink"}
{"id": 6967, "code": "public String[] getDbStoragePaths() {\n    return rocksDBStateBackend.getDbStoragePaths();\n}", "summary_tokens": ["gets", "the", "configured", "local", "db", "storage", "paths", "or", "null", "if", "none", "were", "configured"], "project": "flink"}
{"id": 3143, "code": "public static boolean isInSSSP(\n        final Edge<Long, Double> edgeToBeRemoved, DataSet<Edge<Long, Double>> edgesInSSSP)\n        throws Exception {\n\n    return edgesInSSSP\n                    .filter(\n                            new FilterFunction<Edge<Long, Double>>() {\n                                @Override\n                                public boolean filter(Edge<Long, Double> edge)\n                                        throws Exception {\n                                    return edge.equals(edgeToBeRemoved);\n                                }\n                            })\n                    .count()\n            > 0;\n}", "summary_tokens": ["function", "that", "verifies", "whether", "the", "edge", "to", "be", "removed", "is", "part", "of", "the", "sssp", "or", "not"], "project": "flink"}
{"id": 9613, "code": "public void testOperatorStatesSnapshotRestore() throws Exception {\n    testOperatorStatesSnapshotRestoreInternal(ONLY_JM_RECOVERY);\n}", "summary_tokens": ["test", "restoring", "an", "operator", "from", "a", "snapshot", "local", "recovery", "deactivated"], "project": "flink"}
{"id": 6799, "code": "public static long getKeyPointer(MemorySegment memorySegment, int offset) {\n    return memorySegment.getLong(offset + KEY_POINTER_OFFSET);\n}", "summary_tokens": ["return", "the", "pointer", "to", "key", "space"], "project": "flink"}
{"id": 627, "code": "public static <T, K> KeyedStream<T, K> readKeyBy(\n        String topic,\n        StreamExecutionEnvironment env,\n        TypeInformation<T> typeInformation,\n        Properties kafkaProperties,\n        KeySelector<T, K> keySelector) {\n\n    TypeSerializer<T> typeSerializer = typeInformation.createSerializer(env.getConfig());\n    TypeInformationSerializationSchema<T> schema =\n            new TypeInformationSerializationSchema<>(typeInformation, typeSerializer);\n\n    SourceFunction<T> kafkaConsumer =\n            new FlinkKafkaShuffleConsumer<>(topic, schema, typeSerializer, kafkaProperties);\n\n        \n    Preconditions.checkArgument(\n            kafkaProperties.getProperty(PARTITION_NUMBER) != null,\n            \"Missing partition number for Kafka Shuffle\");\n    int numberOfPartitions =\n            PropertiesUtil.getInt(kafkaProperties, PARTITION_NUMBER, Integer.MIN_VALUE);\n    DataStream<T> outputDataStream =\n            env.addSource(kafkaConsumer).setParallelism(numberOfPartitions);\n\n    return DataStreamUtils.reinterpretAsKeyedStream(outputDataStream, keySelector);\n}", "summary_tokens": ["the", "read", "side", "of", "flink", "kafka", "shuffle", "persistent", "key", "by"], "project": "flink"}
{"id": 5003, "code": "public void insertOrReplaceRecord(T record) throws IOException {\n    if (closed) {\n        return;\n    }\n\n    T match = prober.getMatchFor(record, reuse);\n    if (match == null) {\n        prober.insertAfterNoMatch(record);\n    } else {\n        prober.updateMatch(record);\n    }\n}", "summary_tokens": ["searches", "the", "hash", "table", "for", "a", "record", "with", "the", "given", "key"], "project": "flink"}
{"id": 951, "code": "protected ConnectionFactory setupConnectionFactory() throws Exception {\n    return rmqConnectionConfig.getConnectionFactory();\n}", "summary_tokens": ["initializes", "the", "connection", "to", "rmq", "with", "a", "default", "connection", "factory"], "project": "flink"}
{"id": 2356, "code": "public long getTimeDurationHelper(String name, String vStr, TimeUnit unit) {\n    vStr = vStr.trim();\n    vStr = StringUtils.toLowerCase(vStr);\n    ParsedTimeDuration vUnit = ParsedTimeDuration.unitFor(vStr);\n    if (null == vUnit) {\n        logDeprecation(\"No unit for \" + name + \"(\" + vStr + \") assuming \" + unit);\n        vUnit = ParsedTimeDuration.unitFor(unit);\n    } else {\n        vStr = vStr.substring(0, vStr.lastIndexOf(vUnit.suffix()));\n    }\n\n    long raw = Long.parseLong(vStr);\n    long converted = unit.convert(raw, vUnit.unit());\n    if (vUnit.unit().convert(converted, unit) < raw) {\n        logDeprecation(\n                \"Possible loss of precision converting \"\n                        + vStr\n                        + vUnit.suffix()\n                        + \" to \"\n                        + unit\n                        + \" for \"\n                        + name);\n    }\n    return converted;\n}", "summary_tokens": ["return", "time", "duration", "in", "the", "given", "time", "unit"], "project": "flink"}
{"id": 8097, "code": "private boolean isFullPartitionSpec(ObjectPath tablePath, CatalogPartitionSpec partitionSpec)\n        throws TableNotExistException {\n    CatalogBaseTable baseTable = getTable(tablePath);\n\n    if (!(baseTable instanceof CatalogTable)) {\n        return false;\n    }\n\n    CatalogTable table = (CatalogTable) baseTable;\n    List<String> partitionKeys = table.getPartitionKeys();\n    Map<String, String> spec = partitionSpec.getPartitionSpec();\n\n        \n    return partitionKeys.size() == spec.size() && spec.keySet().containsAll(partitionKeys);\n}", "summary_tokens": ["check", "if", "the", "given", "partition", "spec", "is", "full", "partition", "spec", "for", "the", "given", "table"], "project": "flink"}
{"id": 9357, "code": "private int checkSkipWriteForFixLengthPart(AbstractPagedOutputView out) throws IOException {\n        \n    int available = out.getSegmentSize() - out.getCurrentPositionInSegment();\n    if (available < getSerializedRowFixedPartLength()) {\n        out.advance();\n        return available;\n    }\n    return 0;\n}", "summary_tokens": ["we", "need", "skip", "bytes", "to", "write", "when", "the", "remain", "bytes", "of", "current", "segment", "is", "not", "enough", "to", "write", "binary", "row", "fixed", "part"], "project": "flink"}
{"id": 1276, "code": "public void setGroupOrderForInputTwo(Ordering order) {\n    setGroupOrder(1, order);\n}", "summary_tokens": ["sets", "the", "order", "of", "the", "elements", "within", "a", "group", "for", "the", "second", "input"], "project": "flink"}
{"id": 9373, "code": "public static void copyToUnsafe(\n        MemorySegment[] segments, int offset, Object target, int pointer, int numBytes) {\n    if (inFirstSegment(segments, offset, numBytes)) {\n        segments[0].copyToUnsafe(offset, target, pointer, numBytes);\n    } else {\n        copyMultiSegmentsToUnsafe(segments, offset, target, pointer, numBytes);\n    }\n}", "summary_tokens": ["copy", "segments", "to", "target", "unsafe", "pointer"], "project": "flink"}
{"id": 6521, "code": "public void testGetConsumedResultPartitionsProducers() throws Exception {\n    final JobVertex producer1 = ExecutionGraphTestUtils.createNoOpVertex(1);\n    final JobVertex producer2 = ExecutionGraphTestUtils.createNoOpVertex(1);\n    final JobVertex consumer = ExecutionGraphTestUtils.createNoOpVertex(1);\n    consumer.connectNewDataSetAsInput(\n            producer1, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);\n    consumer.connectNewDataSetAsInput(\n            producer2, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);\n\n    final ExecutionGraph eg =\n            ExecutionGraphTestUtils.createSimpleTestGraph(producer1, producer2, consumer);\n    final ExecutionGraphToInputsLocationsRetrieverAdapter inputsLocationsRetriever =\n            new ExecutionGraphToInputsLocationsRetrieverAdapter(eg);\n\n    ExecutionVertexID evIdOfProducer1 = new ExecutionVertexID(producer1.getID(), 0);\n    ExecutionVertexID evIdOfProducer2 = new ExecutionVertexID(producer2.getID(), 0);\n    ExecutionVertexID evIdOfConsumer = new ExecutionVertexID(consumer.getID(), 0);\n\n    Collection<Collection<ExecutionVertexID>> producersOfProducer1 =\n            inputsLocationsRetriever.getConsumedResultPartitionsProducers(evIdOfProducer1);\n    Collection<Collection<ExecutionVertexID>> producersOfProducer2 =\n            inputsLocationsRetriever.getConsumedResultPartitionsProducers(evIdOfProducer2);\n    Collection<Collection<ExecutionVertexID>> producersOfConsumer =\n            inputsLocationsRetriever.getConsumedResultPartitionsProducers(evIdOfConsumer);\n\n    assertThat(producersOfProducer1, is(empty()));\n    assertThat(producersOfProducer2, is(empty()));\n    assertThat(producersOfConsumer, hasSize(2));\n    assertThat(producersOfConsumer, hasItem(Collections.singletonList(evIdOfProducer1)));\n    assertThat(producersOfConsumer, hasItem(Collections.singletonList(evIdOfProducer2)));\n}", "summary_tokens": ["tests", "that", "can", "get", "the", "producers", "of", "consumed", "result", "partitions"], "project": "flink"}
{"id": 5800, "code": "public void testBlobForJobCacheHa2() throws IOException {\n    Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n    config.setString(HighAvailabilityOptions.HA_MODE, \"ZOOKEEPER\");\n    config.setString(\n            HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getPath());\n    uploadFileGetTest(config, new JobID(), false, true, PERMANENT_BLOB);\n}", "summary_tokens": ["blob", "cache", "is", "configured", "in", "ha", "mode", "and", "the", "cache", "can", "download", "files", "from", "the", "file", "system", "directly", "and", "does", "not", "need", "to", "download", "blobs", "from", "the", "blob", "server", "which", "is", "shut", "down", "after", "the", "blob", "upload"], "project": "flink"}
{"id": 8829, "code": "private static void pushWatermarkAssigner(FlinkRelBuilder relBuilder, ResolvedSchema schema) {\n    final ExpressionConverter converter = new ExpressionConverter(relBuilder);\n    final RelDataType inputRelDataType = relBuilder.peek().getRowType();\n\n        \n    final WatermarkSpec watermarkSpec = schema.getWatermarkSpecs().get(0);\n\n    final String rowtimeColumn = watermarkSpec.getRowtimeAttribute();\n    final int rowtimeColumnIdx = inputRelDataType.getFieldNames().indexOf(rowtimeColumn);\n\n    final RexNode watermarkRexNode = watermarkSpec.getWatermarkExpression().accept(converter);\n\n    relBuilder.watermark(rowtimeColumnIdx, watermarkRexNode);\n}", "summary_tokens": ["creates", "a", "specialized", "node", "for", "assigning", "watermarks"], "project": "flink"}
{"id": 2961, "code": "protected NumericColumnSummary<Long> summarize(Long... values) {\n    return new AggregateCombineHarness<\n            Long, NumericColumnSummary<Long>, LongSummaryAggregator>() {\n\n        @Override\n        protected void compareResults(\n                NumericColumnSummary<Long> result1, NumericColumnSummary<Long> result2) {\n\n            Assert.assertEquals(result1.getTotalCount(), result2.getTotalCount());\n            Assert.assertEquals(result1.getNullCount(), result2.getNullCount());\n            Assert.assertEquals(result1.getMissingCount(), result2.getMissingCount());\n            Assert.assertEquals(result1.getNonMissingCount(), result2.getNonMissingCount());\n            Assert.assertEquals(result1.getInfinityCount(), result2.getInfinityCount());\n            Assert.assertEquals(result1.getNanCount(), result2.getNanCount());\n\n            Assert.assertEquals(result1.containsNull(), result2.containsNull());\n            Assert.assertEquals(result1.containsNonNull(), result2.containsNonNull());\n\n            Assert.assertEquals(result1.getMin().longValue(), result2.getMin().longValue());\n            Assert.assertEquals(result1.getMax().longValue(), result2.getMax().longValue());\n            Assert.assertEquals(result1.getSum().longValue(), result2.getSum().longValue());\n            Assert.assertEquals(\n                    result1.getMean().doubleValue(), result2.getMean().doubleValue(), 1e-12d);\n            Assert.assertEquals(\n                    result1.getVariance().doubleValue(),\n                    result2.getVariance().doubleValue(),\n                    1e-9d);\n            Assert.assertEquals(\n                    result1.getStandardDeviation().doubleValue(),\n                    result2.getStandardDeviation().doubleValue(),\n                    1e-12d);\n        }\n    }.summarize(values);\n}", "summary_tokens": ["helper", "method", "for", "summarizing", "a", "list", "of", "values"], "project": "flink"}
{"id": 485, "code": "private TransactionalRequestResult enqueueNewPartitions() {\n    Object transactionManager = getTransactionManager();\n    synchronized (transactionManager) {\n        Object newPartitionsInTransaction =\n                getField(transactionManager, \"newPartitionsInTransaction\");\n        Object newPartitionsInTransactionIsEmpty =\n                invoke(newPartitionsInTransaction, \"isEmpty\");\n        TransactionalRequestResult result;\n        if (newPartitionsInTransactionIsEmpty instanceof Boolean\n                && !((Boolean) newPartitionsInTransactionIsEmpty)) {\n            Object txnRequestHandler =\n                    invoke(transactionManager, \"addPartitionsToTransactionHandler\");\n            invoke(\n                    transactionManager,\n                    \"enqueueRequest\",\n                    new Class[] {txnRequestHandler.getClass().getSuperclass()},\n                    new Object[] {txnRequestHandler});\n            result =\n                    (TransactionalRequestResult)\n                            getField(\n                                    txnRequestHandler,\n                                    txnRequestHandler.getClass().getSuperclass(),\n                                    \"result\");\n        } else {\n                \n                \n            result = new TransactionalRequestResult(\"AddPartitionsToTxn\");\n            result.done();\n        }\n        return result;\n    }\n}", "summary_tokens": ["enqueues", "new", "transactions", "at", "the", "transaction", "manager", "and", "returns", "a", "transactional", "request", "result", "that", "allows", "waiting", "on", "them"], "project": "flink"}
{"id": 889, "code": "public static <T extends Exception> void sneakyThrow(Exception t) throws T {\n    throw (T) t;\n}", "summary_tokens": ["javac", "hack", "for", "unchecking", "the", "checked", "exception"], "project": "flink"}
{"id": 5472, "code": "private StateMapEntry<K, N, S>[] makeTable(int newCapacity) {\n\n    if (newCapacity < MAXIMUM_CAPACITY) {\n        threshold = (newCapacity >> 1) + (newCapacity >> 2); \n    } else {\n        if (size() > MAX_ARRAY_SIZE) {\n\n            throw new IllegalStateException(\n                    \"Maximum capacity of CopyOnWriteStateMap is reached and the job \"\n                            + \"cannot continue. Please consider scaling-out your job or using a different keyed state backend \"\n                            + \"implementation!\");\n        } else {\n\n            LOG.warn(\n                    \"Maximum capacity of 2^30 in StateMap reached. Cannot increase hash map size. This can \"\n                            + \"lead to more collisions and lower performance. Please consider scaling-out your job or using a \"\n                            + \"different keyed state backend implementation!\");\n            threshold = MAX_ARRAY_SIZE;\n        }\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    StateMapEntry<K, N, S>[] newMap = (StateMapEntry<K, N, S>[]) new StateMapEntry[newCapacity];\n    return newMap;\n}", "summary_tokens": ["allocate", "a", "table", "of", "the", "given", "capacity", "and", "set", "the", "threshold", "accordingly"], "project": "flink"}
{"id": 6205, "code": "public void testCleanupReleasedPartitionNoView() throws Exception {\n    testCleanupReleasedPartition(false);\n}", "summary_tokens": ["tests", "cleanup", "of", "pipelined", "subpartition", "release", "with", "no", "read", "view", "attached"], "project": "flink"}
{"id": 7292, "code": "public void open(Configuration parameters) throws Exception {\n    try {\n        synchronized (lock) {\n            createConnection();\n        }\n    } catch (IOException e) {\n        throw new IOException(\"Cannot connect to socket server at \" + hostName + \":\" + port, e);\n    }\n}", "summary_tokens": ["initialize", "the", "connection", "with", "the", "socket", "in", "the", "server"], "project": "flink"}
{"id": 6519, "code": "public static void doTestCheckpointCleanerIsClosedAfterCheckpointServices(\n        BiFunction<CheckpointRecoveryFactory, CheckpointsCleaner, SchedulerNG> schedulerFactory,\n        ScheduledExecutorService executorService)\n        throws Exception {\n    final CountDownLatch checkpointServicesShutdownBlocked = new CountDownLatch(1);\n    final CountDownLatch cleanerClosed = new CountDownLatch(1);\n    final CompletedCheckpointStore completedCheckpointStore =\n            new StandaloneCompletedCheckpointStore(1) {\n\n                @Override\n                public void shutdown(JobStatus jobStatus, CheckpointsCleaner checkpointsCleaner)\n                        throws Exception {\n                    checkpointServicesShutdownBlocked.await();\n                    super.shutdown(jobStatus, checkpointsCleaner);\n                }\n            };\n    final CheckpointIDCounter checkpointIDCounter =\n            new StandaloneCheckpointIDCounter() {\n\n                @Override\n                public void shutdown(JobStatus jobStatus) throws Exception {\n                    checkpointServicesShutdownBlocked.await();\n                    super.shutdown(jobStatus);\n                }\n            };\n    final CheckpointsCleaner checkpointsCleaner =\n            new CheckpointsCleaner() {\n\n                @Override\n                public synchronized CompletableFuture<Void> closeAsync() {\n                    cleanerClosed.countDown();\n                    return super.closeAsync();\n                }\n            };\n\n    final SchedulerNG scheduler =\n            schedulerFactory.apply(\n                    new TestingCheckpointRecoveryFactory(\n                            completedCheckpointStore, checkpointIDCounter),\n                    checkpointsCleaner);\n    final CompletableFuture<Void> schedulerClosed = new CompletableFuture<>();\n    final CountDownLatch schedulerClosing = new CountDownLatch(1);\n\n    executorService.submit(\n            () -> {\n                scheduler.closeAsync().thenRun(() -> schedulerClosed.complete(null));\n                schedulerClosing.countDown();\n            });\n\n        \n    schedulerClosing.await();\n    assertFalse(\n            \"CheckpointCleaner should not close before checkpoint services.\",\n            cleanerClosed.await(10, TimeUnit.MILLISECONDS));\n    checkpointServicesShutdownBlocked.countDown();\n    cleanerClosed.await();\n    schedulerClosed.get();\n}", "summary_tokens": ["visible", "for", "re", "use", "in", "org"], "project": "flink"}
{"id": 8524, "code": "public static String createMethodSignatureString(\n        String methodName, Class<?>[] parameters, @Nullable Class<?> returnType) {\n    final StringBuilder builder = new StringBuilder();\n    if (returnType != null) {\n        builder.append(returnType.getCanonicalName()).append(\" \");\n    }\n    builder.append(methodName)\n            .append(\n                    Stream.of(parameters)\n                            .map(\n                                    parameter -> {\n                                            \n                                            \n                                        if (parameter == null) {\n                                            return \"_\";\n                                        } else {\n                                            return parameter.getCanonicalName();\n                                        }\n                                    })\n                            .collect(Collectors.joining(\", \", \"(\", \")\")));\n    return builder.toString();\n}", "summary_tokens": ["creates", "a", "method", "signature", "string", "like", "int", "eval", "integer", "string"], "project": "flink"}
{"id": 7821, "code": "public void testReportingFromSnapshotToTaskStateManager() throws Exception {\n\n    TestTaskStateManager taskStateManager = new TestTaskStateManager();\n\n    StreamMockEnvironment streamMockEnvironment =\n            new StreamMockEnvironment(\n                    new Configuration(),\n                    new Configuration(),\n                    new ExecutionConfig(),\n                    1024 * 1024,\n                    new MockInputSplitProvider(),\n                    0,\n                    taskStateManager);\n\n    StreamTask testStreamTask = new StreamTaskTest.NoOpStreamTask(streamMockEnvironment);\n    CheckpointMetaData checkpointMetaData = new CheckpointMetaData(0L, 0L);\n    CheckpointMetricsBuilder checkpointMetrics = new CheckpointMetricsBuilder();\n\n    Map<OperatorID, OperatorSnapshotFutures> snapshots = new HashMap<>(1);\n    OperatorSnapshotFutures osFuture = new OperatorSnapshotFutures();\n\n    osFuture.setKeyedStateManagedFuture(createSnapshotResult(KeyedStateHandle.class));\n    osFuture.setKeyedStateRawFuture(createSnapshotResult(KeyedStateHandle.class));\n    osFuture.setOperatorStateManagedFuture(createSnapshotResult(OperatorStateHandle.class));\n    osFuture.setOperatorStateRawFuture(createSnapshotResult(OperatorStateHandle.class));\n    osFuture.setInputChannelStateFuture(\n            createSnapshotCollectionResult(InputChannelStateHandle.class));\n    osFuture.setResultSubpartitionStateFuture(\n            createSnapshotCollectionResult(ResultSubpartitionStateHandle.class));\n\n    OperatorID operatorID = new OperatorID();\n    snapshots.put(operatorID, osFuture);\n\n    AsyncCheckpointRunnable checkpointRunnable =\n            new AsyncCheckpointRunnable(\n                    snapshots,\n                    checkpointMetaData,\n                    checkpointMetrics,\n                    0L,\n                    testStreamTask.getName(),\n                    asyncCheckpointRunnable -> {},\n                    testStreamTask.getEnvironment(),\n                    testStreamTask,\n                    false,\n                    false,\n                    () -> true);\n\n    checkpointMetrics.setAlignmentDurationNanos(0L);\n    checkpointMetrics.setBytesProcessedDuringAlignment(0L);\n    checkpointRunnable.run();\n\n    TaskStateSnapshot lastJobManagerTaskStateSnapshot =\n            taskStateManager.getLastJobManagerTaskStateSnapshot();\n    TaskStateSnapshot lastTaskManagerTaskStateSnapshot =\n            taskStateManager.getLastTaskManagerTaskStateSnapshot();\n\n    OperatorSubtaskState jmState =\n            lastJobManagerTaskStateSnapshot.getSubtaskStateByOperatorID(operatorID);\n\n    OperatorSubtaskState tmState =\n            lastTaskManagerTaskStateSnapshot.getSubtaskStateByOperatorID(operatorID);\n\n    performCheck(\n            osFuture.getKeyedStateManagedFuture(),\n            jmState.getManagedKeyedState(),\n            tmState.getManagedKeyedState());\n    performCheck(\n            osFuture.getKeyedStateRawFuture(),\n            jmState.getRawKeyedState(),\n            tmState.getRawKeyedState());\n    performCheck(\n            osFuture.getOperatorStateManagedFuture(),\n            jmState.getManagedOperatorState(),\n            tmState.getManagedOperatorState());\n    performCheck(\n            osFuture.getOperatorStateRawFuture(),\n            jmState.getRawOperatorState(),\n            tmState.getRawOperatorState());\n    performCollectionCheck(\n            osFuture.getInputChannelStateFuture(),\n            jmState.getInputChannelState(),\n            tmState.getInputChannelState());\n    performCollectionCheck(\n            osFuture.getResultSubpartitionStateFuture(),\n            jmState.getResultSubpartitionState(),\n            tmState.getResultSubpartitionState());\n}", "summary_tokens": ["this", "tests", "the", "forwarding", "of", "jm", "and", "tm", "local", "state", "from", "the", "futures", "reported", "by", "the", "backends", "through", "the", "async", "checkpointing", "thread", "to", "the", "org"], "project": "flink"}
{"id": 2078, "code": "public static Duration toDuration(Time time) {\n    return Duration.of(time.getSize(), toChronoUnit(time.getUnit()));\n}", "summary_tokens": ["translates", "time", "to", "duration"], "project": "flink"}
{"id": 9008, "code": "public double getRowCount() {\n    Double rowCnt = getStatistic().getRowCount();\n    return rowCnt == null ? DEFAULT_ROWCOUNT : rowCnt;\n}", "summary_tokens": ["returns", "an", "estimate", "of", "the", "number", "of", "rows", "in", "the", "table"], "project": "flink"}
{"id": 5061, "code": "public final void put(T element) {\n    size++;\n    heap[size] = element;\n    upHeap();\n}", "summary_tokens": ["adds", "a", "buffer", "to", "a", "priority", "queue", "in", "log", "size", "time"], "project": "flink"}
{"id": 63, "code": "default CompletableFuture<Map<String, Object>> getAccumulators(JobID jobID) {\n    return getAccumulators(jobID, ClassLoader.getSystemClassLoader());\n}", "summary_tokens": ["requests", "and", "returns", "the", "accumulators", "for", "the", "given", "job", "identifier"], "project": "flink"}
{"id": 9518, "code": "public void await(long timeout, TimeUnit timeUnit)\n        throws InterruptedException, TimeoutException {\n    if (timeout < 0) {\n        throw new IllegalArgumentException(\"time may not be negative\");\n    }\n    if (timeUnit == null) {\n        throw new NullPointerException(\"timeUnit\");\n    }\n\n    if (timeout == 0) {\n        await();\n    } else {\n        final long deadline = System.nanoTime() + timeUnit.toNanos(timeout);\n        long millisToWait;\n\n        synchronized (lock) {\n            while (!triggered\n                    && (millisToWait = (deadline - System.nanoTime()) / 1_000_000) > 0) {\n                lock.wait(millisToWait);\n            }\n\n            if (!triggered) {\n                throw new TimeoutException();\n            }\n        }\n    }\n}", "summary_tokens": ["waits", "until", "one", "shot", "latch", "trigger", "is", "called"], "project": "flink"}
{"id": 4946, "code": "public static void openChainedTasks(List<ChainedDriver<?, ?>> tasks, AbstractInvokable parent)\n        throws Exception {\n        \n    for (ChainedDriver<?, ?> task : tasks) {\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(constructLogString(\"Start task code\", task.getTaskName(), parent));\n        }\n        task.openTask();\n    }\n}", "summary_tokens": ["opens", "all", "chained", "tasks", "in", "the", "order", "as", "they", "are", "stored", "in", "the", "array"], "project": "flink"}
{"id": 5964, "code": "public void testAddRandomNumbers() throws Exception {\n    ThreadLocalRandom rand = ThreadLocalRandom.current();\n\n    StatsSummary mma = new StatsSummary();\n\n    long count = 13;\n    long sum = 0;\n    long min = Integer.MAX_VALUE;\n    long max = Integer.MIN_VALUE;\n\n    for (int i = 0; i < count; i++) {\n        int number = rand.nextInt(124) + 1;\n        sum += number;\n        min = Math.min(min, number);\n        max = Math.max(max, number);\n\n        mma.add(number);\n    }\n\n    assertEquals(min, mma.getMinimum());\n    assertEquals(max, mma.getMaximum());\n    assertEquals(sum, mma.getSum());\n    assertEquals(count, mma.getCount());\n    assertEquals(sum / count, mma.getAverage());\n}", "summary_tokens": ["test", "sequence", "of", "random", "numbers"], "project": "flink"}
{"id": 125, "code": "default void recycle() {}", "summary_tokens": ["this", "method", "is", "called", "when", "all", "records", "from", "this", "batch", "have", "been", "emitted"], "project": "flink"}
{"id": 6898, "code": "public void setWriteBufferRatio(double writeBufferRatio) {\n    Preconditions.checkArgument(\n            writeBufferRatio > 0 && writeBufferRatio < 1.0,\n            \"Write Buffer ratio %s must be in (0, 1)\",\n            writeBufferRatio);\n    this.writeBufferRatio = writeBufferRatio;\n}", "summary_tokens": ["sets", "the", "fraction", "of", "the", "total", "memory", "to", "be", "used", "for", "write", "buffers"], "project": "flink"}
{"id": 2756, "code": "public ResourceSpec getPreferredResources() {\n    return this.preferredResources;\n}", "summary_tokens": ["returns", "the", "preferred", "resources", "of", "this", "data", "sink"], "project": "flink"}
{"id": 4153, "code": "public File getStorageLocation(JobID jobId, BlobKey key) throws IOException {\n    checkNotNull(jobId);\n    return BlobUtils.getStorageLocation(storageDir, jobId, key);\n}", "summary_tokens": ["returns", "a", "file", "handle", "to", "the", "file", "associated", "with", "the", "given", "blob", "key", "on", "the", "blob", "server"], "project": "flink"}
{"id": 8579, "code": "public static InputTypeStrategy commonType(int count) {\n    return new CommonInputTypeStrategy(ConstantArgumentCount.of(count));\n}", "summary_tokens": ["an", "input", "type", "strategy", "that", "expects", "count", "arguments", "that", "have", "a", "common", "type"], "project": "flink"}
{"id": 6405, "code": "public void testRegisterTaskExecutor() throws Exception {\n        \n    CompletableFuture<RegistrationResponse> successfulFuture =\n            registerTaskExecutor(rmGateway, taskExecutorGateway.getAddress());\n\n    RegistrationResponse response =\n            successfulFuture.get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);\n    assertTrue(response instanceof TaskExecutorRegistrationSuccess);\n    final TaskManagerInfoWithSlots taskManagerInfoWithSlots =\n            rmGateway.requestTaskManagerDetailsInfo(taskExecutorResourceID, TIMEOUT).get();\n    assertThat(\n            taskManagerInfoWithSlots.getTaskManagerInfo().getResourceId(),\n            equalTo(taskExecutorResourceID));\n\n        \n        \n    CompletableFuture<RegistrationResponse> duplicateFuture =\n            registerTaskExecutor(rmGateway, taskExecutorGateway.getAddress());\n\n    RegistrationResponse duplicateResponse = duplicateFuture.get();\n    assertTrue(duplicateResponse instanceof TaskExecutorRegistrationSuccess);\n    assertNotEquals(\n            ((TaskExecutorRegistrationSuccess) response).getRegistrationId(),\n            ((TaskExecutorRegistrationSuccess) duplicateResponse).getRegistrationId());\n\n    assertThat(rmGateway.requestResourceOverview(TIMEOUT).get().getNumberTaskManagers(), is(1));\n}", "summary_tokens": ["test", "receive", "normal", "registration", "from", "task", "executor", "and", "receive", "duplicate", "registration", "from", "task", "executor"], "project": "flink"}
{"id": 9332, "code": "public Iterator<Map.Entry<RowData, UV>> iterator(W window) throws Exception {\n    windowState.setCurrentNamespace(window);\n    return windowState.iterator();\n}", "summary_tokens": ["iterates", "over", "all", "the", "mappings", "in", "the", "state"], "project": "flink"}
{"id": 2249, "code": "public static void main(String[] args) throws IOException, ConfigurationException {\n    String outputDirectory = args[0];\n\n    for (final RestAPIVersion apiVersion : RestAPIVersion.values()) {\n        if (apiVersion == RestAPIVersion.V0) {\n                \n            continue;\n        }\n        createHtmlFile(\n                new DocumentingDispatcherRestEndpoint(),\n                apiVersion,\n                Paths.get(\n                        outputDirectory,\n                        \"rest_\" + apiVersion.getURLVersionPrefix() + \"_dispatcher.html\"));\n    }\n}", "summary_tokens": ["generates", "the", "rest", "api", "documentation"], "project": "flink"}
{"id": 623, "code": "public Set<String> generateIdsToAbort() {\n    Set<String> idsToAbort = new HashSet<>();\n    for (int i = 0; i < safeScaleDownFactor; i++) {\n        idsToAbort.addAll(generateIdsToUse(i * poolSize * totalNumberOfSubtasks));\n    }\n    return idsToAbort;\n}", "summary_tokens": ["if", "we", "have", "to", "abort", "previous", "transactional", "id", "in", "case", "of", "restart", "after", "a", "failure", "before", "first", "checkpoint", "completed", "we", "don", "t", "know", "what", "was", "the", "parallelism", "used", "in", "previous", "attempt"], "project": "flink"}
{"id": 8165, "code": "public static TypeInformation<Long> LONG() {\n    return org.apache.flink.api.common.typeinfo.Types.LONG;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "long", "or", "sql", "bigint", "type"], "project": "flink"}
{"id": 633, "code": "private static boolean hasKafkaClientProperties(Map<String, String> tableOptions) {\n    return tableOptions.keySet().stream().anyMatch(k -> k.startsWith(PROPERTIES_PREFIX));\n}", "summary_tokens": ["decides", "if", "the", "table", "options", "contains", "kafka", "client", "properties", "that", "start", "with", "prefix", "properties"], "project": "flink"}
{"id": 4574, "code": "int refreshAndGetMin() {\n    int min = Integer.MAX_VALUE;\n    int numSubpartitions = partition.getNumberOfSubpartitions();\n\n    if (numSubpartitions == 0) {\n            \n        return 0;\n    }\n\n    for (int targetSubpartition = 0;\n            targetSubpartition < numSubpartitions;\n            ++targetSubpartition) {\n        int size = partition.getNumberOfQueuedBuffers(targetSubpartition);\n        min = Math.min(min, size);\n    }\n\n    return min;\n}", "summary_tokens": ["iterates", "over", "all", "sub", "partitions", "and", "collects", "the", "minimum", "number", "of", "queued", "buffers", "in", "a", "sub", "partition", "in", "a", "best", "effort", "way"], "project": "flink"}
{"id": 7311, "code": "protected boolean addId(UId uid) {\n    idsForCurrentCheckpoint.add(uid);\n    return idsProcessedButNotAcknowledged.add(uid);\n}", "summary_tokens": ["adds", "an", "id", "to", "be", "stored", "with", "the", "current", "checkpoint"], "project": "flink"}
{"id": 4958, "code": "public static CompletableFuture<Void> closeAsyncWithTimeout(\n        String componentName,\n        ThrowingRunnable<Exception> closingSequence,\n        Duration closeTimeout) {\n\n    final CompletableFuture<Void> future = new CompletableFuture<>();\n        \n    final Thread t =\n            new Thread(\n                    () -> {\n                        try {\n                            closingSequence.run();\n                            future.complete(null);\n                        } catch (Throwable error) {\n                            future.completeExceptionally(error);\n                        }\n                    });\n    t.start();\n\n        \n    future.exceptionally(\n            (error) -> {\n                if (error instanceof TimeoutException && t.isAlive()) {\n                    abortThread(t);\n                }\n                return null;\n            });\n\n    FutureUtils.orTimeout(\n            future,\n            closeTimeout.toMillis(),\n            TimeUnit.MILLISECONDS,\n            String.format(\n                    \"Failed to close the %s before timeout of %d ms\",\n                    componentName, closeTimeout.toMillis()));\n\n    return future;\n}", "summary_tokens": ["close", "a", "component", "with", "a", "timeout"], "project": "flink"}
{"id": 630, "code": "private static StartupMode fromOption(ScanStartupMode scanStartupMode) {\n    switch (scanStartupMode) {\n        case EARLIEST_OFFSET:\n            return StartupMode.EARLIEST;\n        case LATEST_OFFSET:\n            return StartupMode.LATEST;\n        case GROUP_OFFSETS:\n            return StartupMode.GROUP_OFFSETS;\n        case SPECIFIC_OFFSETS:\n            return StartupMode.SPECIFIC_OFFSETS;\n        case TIMESTAMP:\n            return StartupMode.TIMESTAMP;\n\n        default:\n            throw new TableException(\n                    \"Unsupported startup mode. Validator should have checked that.\");\n    }\n}", "summary_tokens": ["returns", "the", "startup", "mode", "of", "kafka", "consumer", "by", "passed", "in", "table", "specific", "scan", "startup", "mode"], "project": "flink"}
{"id": 515, "code": "public KafkaSourceBuilder<OUT> setTopics(String... topics) {\n    return setTopics(Arrays.asList(topics));\n}", "summary_tokens": ["set", "a", "list", "of", "topics", "the", "kafka", "source", "should", "consume", "from"], "project": "flink"}
{"id": 4475, "code": "public static Collection<ArchivedJson> getArchivedJsons(Path file) throws IOException {\n    try (FSDataInputStream input = file.getFileSystem().open(file);\n            ByteArrayOutputStream output = new ByteArrayOutputStream()) {\n        IOUtils.copyBytes(input, output);\n\n        try {\n            JsonNode archive = mapper.readTree(output.toByteArray());\n\n            Collection<ArchivedJson> archives = new ArrayList<>();\n            for (JsonNode archivePart : archive.get(ARCHIVE)) {\n                String path = archivePart.get(PATH).asText();\n                String json = archivePart.get(JSON).asText();\n                archives.add(new ArchivedJson(path, json));\n            }\n            return archives;\n        } catch (NullPointerException npe) {\n                \n            throw new IOException(\n                    \"Job archive (\" + file.getPath() + \") did not conform to expected format.\");\n        }\n    }\n}", "summary_tokens": ["reads", "the", "given", "archive", "file", "and", "returns", "a", "collection", "of", "contained", "archived", "json"], "project": "flink"}
{"id": 590, "code": "public void wakeup() {\n    wakeup = true;\n    wakeupConnections();\n}", "summary_tokens": ["interrupt", "an", "in", "progress", "discovery", "attempt", "by", "throwing", "a", "wakeup", "exception"], "project": "flink"}
{"id": 729, "code": "private void testWatermarkIncremental(int numElementsPerProducer) throws Exception {\n    TimeCharacteristic timeCharacteristic = EventTime;\n    String topic = topic(\"test_watermark_incremental\", timeCharacteristic);\n    final int numberOfPartitions = 3;\n    final int producerParallelism = 2;\n\n    createTestTopic(topic, numberOfPartitions, 1);\n\n    final StreamExecutionEnvironment env =\n            createEnvironment(producerParallelism, timeCharacteristic);\n\n    KeyedStream<Tuple3<Integer, Long, Integer>, Tuple> keyedStream =\n            createKafkaShuffle(\n                    env,\n                    topic,\n                    numElementsPerProducer,\n                    producerParallelism,\n                    timeCharacteristic,\n                    numberOfPartitions,\n                    true);\n    keyedStream\n            .process(new WatermarkValidator())\n            .setParallelism(numberOfPartitions)\n            .map(\n                    new ElementCountNoMoreThanValidator(\n                            numElementsPerProducer * producerParallelism))\n            .setParallelism(1)\n            .map(\n                    new ElementCountNoLessThanValidator(\n                            numElementsPerProducer * producerParallelism))\n            .setParallelism(1);\n\n    tryExecute(env, topic);\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["to", "watermark", "from", "the", "consumer", "side", "always", "increase"], "project": "flink"}
{"id": 5834, "code": "public static <T> int checkFilesExist(\n        JobID jobId, Collection<? extends BlobKey> keys, T blobService, boolean doThrow)\n        throws IOException {\n\n    int numFiles = 0;\n\n    for (BlobKey key : keys) {\n        final File storageDir;\n        if (blobService instanceof BlobServer) {\n            BlobServer server = (BlobServer) blobService;\n            storageDir = server.getStorageDir();\n        } else if (blobService instanceof PermanentBlobCache) {\n            PermanentBlobCache cache = (PermanentBlobCache) blobService;\n            storageDir = cache.getStorageDir();\n        } else if (blobService instanceof TransientBlobCache) {\n            TransientBlobCache cache = (TransientBlobCache) blobService;\n            storageDir = cache.getStorageDir();\n        } else {\n            throw new UnsupportedOperationException(\n                    \"unsupported BLOB service class: \"\n                            + blobService.getClass().getCanonicalName());\n        }\n\n        final File blobFile =\n                new File(\n                        BlobUtils.getStorageLocationPath(\n                                storageDir.getAbsolutePath(), jobId, key));\n        if (blobFile.exists()) {\n            ++numFiles;\n        } else if (doThrow) {\n            throw new IOException(\"File \" + blobFile + \" does not exist.\");\n        }\n    }\n\n    return numFiles;\n}", "summary_tokens": ["checks", "how", "many", "of", "the", "files", "given", "by", "blob", "keys", "are", "accessible"], "project": "flink"}
{"id": 8898, "code": "private Operation convertDropView(SqlDropView sqlDropView) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlDropView.fullViewName());\n    ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n\n    return new DropViewOperation(\n            identifier, sqlDropView.getIfExists(), sqlDropView.isTemporary());\n}", "summary_tokens": ["convert", "drop", "view", "statement"], "project": "flink"}
{"id": 3570, "code": "public double getDiskCost() {\n    return diskCost;\n}", "summary_tokens": ["gets", "the", "costs", "for", "disk"], "project": "flink"}
{"id": 8154, "code": "public static ComputedColumn computed(String name, DataType type, String expression) {\n    Preconditions.checkNotNull(name, \"Column name can not be null.\");\n    Preconditions.checkNotNull(type, \"Column type can not be null.\");\n    Preconditions.checkNotNull(expression, \"Column expression can not be null.\");\n    return new ComputedColumn(name, type, expression);\n}", "summary_tokens": ["creates", "a", "computed", "column", "that", "is", "computed", "from", "the", "given", "sql", "expression"], "project": "flink"}
{"id": 7494, "code": "long getLatestCheckpointId() {\n    return barrierHandler.getLatestCheckpointId();\n}", "summary_tokens": ["gets", "the", "id", "defining", "the", "current", "pending", "or", "just", "completed", "checkpoint"], "project": "flink"}
{"id": 7037, "code": "public <OUT> SingleOutputStreamOperator<OUT> process(\n        final BroadcastProcessFunction<IN1, IN2, OUT> function,\n        final TypeInformation<OUT> outTypeInfo) {\n\n    Preconditions.checkNotNull(function);\n    Preconditions.checkArgument(\n            !(nonBroadcastStream instanceof KeyedStream),\n            \"A BroadcastProcessFunction can only be used on a non-keyed stream.\");\n\n    return transform(function, outTypeInfo);\n}", "summary_tokens": ["assumes", "as", "inputs", "a", "broadcast", "stream", "and", "a", "non", "keyed", "data", "stream", "and", "applies", "the", "given", "broadcast", "process", "function", "on", "them", "thereby", "creating", "a", "transformed", "output", "stream"], "project": "flink"}
{"id": 6393, "code": "public void testLegacyCodePathPreference() {\n    final KvStateRegistry kvStateRegistry = new KvStateRegistry();\n    final ArrayDeque<JobID> stateRegistrationNotifications = new ArrayDeque<>(2);\n    final ArrayDeque<JobID> stateDeregistrationNotifications = new ArrayDeque<>(2);\n    final TestingKvStateRegistryListener testingListener =\n            new TestingKvStateRegistryListener(\n                    stateRegistrationNotifications, stateDeregistrationNotifications);\n\n    final ArrayDeque<JobID> anotherQueue = new ArrayDeque<>(2);\n    final TestingKvStateRegistryListener anotherListener =\n            new TestingKvStateRegistryListener(anotherQueue, anotherQueue);\n\n    final JobID jobId = new JobID();\n\n    kvStateRegistry.registerListener(HighAvailabilityServices.DEFAULT_JOB_ID, testingListener);\n    kvStateRegistry.registerListener(jobId, anotherListener);\n\n    final JobVertexID jobVertexId = new JobVertexID();\n\n    final KeyGroupRange keyGroupRange = new KeyGroupRange(0, 1);\n    final String registrationName = \"registrationName\";\n    final KvStateID kvStateID =\n            kvStateRegistry.registerKvState(\n                    jobId,\n                    jobVertexId,\n                    keyGroupRange,\n                    registrationName,\n                    new DummyKvState(),\n                    getClass().getClassLoader());\n\n    assertThat(stateRegistrationNotifications.poll(), equalTo(jobId));\n        \n    assertThat(anotherQueue.isEmpty(), is(true));\n\n    kvStateRegistry.unregisterKvState(\n            jobId, jobVertexId, keyGroupRange, registrationName, kvStateID);\n\n    assertThat(stateDeregistrationNotifications.poll(), equalTo(jobId));\n        \n    assertThat(anotherQueue.isEmpty(), is(true));\n}", "summary_tokens": ["tests", "that", "kv", "state", "registry", "listener", "registered", "under", "high", "availability", "services", "default", "job", "id", "will", "be", "used", "for", "all", "notifications"], "project": "flink"}
{"id": 3631, "code": "public void setParallelism(int parallelism) {\n    if (parallelism < 1 && parallelism != ExecutionConfig.PARALLELISM_DEFAULT) {\n        throw new IllegalArgumentException(\"Parallelism of \" + parallelism + \" is invalid.\");\n    }\n    this.parallelism = parallelism;\n}", "summary_tokens": ["sets", "the", "parallelism", "for", "this", "optimizer", "node"], "project": "flink"}
{"id": 7678, "code": "public void testFailingBackendSnapshotMethod() throws Exception {\n    final long checkpointId = 42L;\n    final long timestamp = 1L;\n\n    try (CloseableRegistry closeableRegistry = new CloseableRegistry()) {\n        RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture =\n                new CancelableFuture<>();\n        RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture =\n                new CancelableFuture<>();\n        RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture =\n                new CancelableFuture<>();\n        RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture =\n                new CancelableFuture<>();\n        RunnableFuture<SnapshotResult<StateObjectCollection<InputChannelStateHandle>>>\n                inputChannelStateFuture = new CancelableFuture<>();\n        RunnableFuture<SnapshotResult<StateObjectCollection<ResultSubpartitionStateHandle>>>\n                resultSubpartitionStateFuture = new CancelableFuture<>();\n\n        OperatorSnapshotFutures operatorSnapshotResult =\n                new OperatorSnapshotFutures(\n                        keyedStateManagedFuture,\n                        keyedStateRawFuture,\n                        operatorStateManagedFuture,\n                        operatorStateRawFuture,\n                        inputChannelStateFuture,\n                        resultSubpartitionStateFuture);\n\n        StateSnapshotContextSynchronousImpl context =\n                new TestStateSnapshotContextSynchronousImpl(\n                        checkpointId, timestamp, closeableRegistry);\n        context.getRawKeyedOperatorStateOutput();\n        context.getRawOperatorStateOutput();\n\n        StreamTaskStateInitializerImpl stateInitializer =\n                new StreamTaskStateInitializerImpl(\n                        new MockEnvironmentBuilder().build(), new MemoryStateBackend());\n        StreamOperatorStateContext stateContext =\n                stateInitializer.streamOperatorStateContext(\n                        new OperatorID(),\n                        \"whatever\",\n                        new TestProcessingTimeService(),\n                        new UnUsedKeyContext(),\n                        IntSerializer.INSTANCE,\n                        closeableRegistry,\n                        new InterceptingOperatorMetricGroup(),\n                        1.0,\n                        false);\n        StreamOperatorStateHandler stateHandler =\n                new StreamOperatorStateHandler(\n                        stateContext, new ExecutionConfig(), closeableRegistry);\n\n        final String keyedStateField = \"keyedStateField\";\n        final String operatorStateField = \"operatorStateField\";\n\n        CheckpointedStreamOperator checkpointedStreamOperator =\n                new CheckpointedStreamOperator() {\n                    @Override\n                    public void initializeState(StateInitializationContext context)\n                            throws Exception {\n                        context.getKeyedStateStore()\n                                .getState(\n                                        new ValueStateDescriptor<>(\n                                                keyedStateField, LongSerializer.INSTANCE))\n                                .update(42L);\n                        context.getOperatorStateStore()\n                                .getListState(\n                                        new ListStateDescriptor<>(\n                                                operatorStateField, LongSerializer.INSTANCE))\n                                .add(42L);\n                    }\n\n                    @Override\n                    public void snapshotState(StateSnapshotContext context) throws Exception {\n                        throw new ExpectedTestException();\n                    }\n                };\n\n        stateHandler.setCurrentKey(\"44\");\n        stateHandler.initializeOperatorState(checkpointedStreamOperator);\n\n        assertThat(\n                stateContext.operatorStateBackend().getRegisteredStateNames(),\n                is(not(empty())));\n        assertThat(\n                ((AbstractKeyedStateBackend<?>) stateContext.keyedStateBackend())\n                        .numKeyValueStatesByName(),\n                equalTo(1));\n\n        try {\n            stateHandler.snapshotState(\n                    checkpointedStreamOperator,\n                    Optional.of(stateContext.internalTimerServiceManager()),\n                    \"42\",\n                    42,\n                    42,\n                    CheckpointOptions.forCheckpointWithDefaultLocation(),\n                    new MemCheckpointStreamFactory(1024),\n                    operatorSnapshotResult,\n                    context,\n                    false);\n            fail(\"Exception expected.\");\n        } catch (CheckpointException e) {\n                \n                \n            if (!ExceptionUtils.findThrowableWithMessage(e, ExpectedTestException.MESSAGE)\n                    .isPresent()) {\n                throw e;\n            }\n        }\n\n        assertTrue(keyedStateManagedFuture.isCancelled());\n        assertTrue(keyedStateRawFuture.isCancelled());\n        assertTrue(context.getKeyedStateStreamFuture().isCancelled());\n        assertTrue(operatorStateManagedFuture.isCancelled());\n        assertTrue(operatorStateRawFuture.isCancelled());\n        assertTrue(context.getOperatorStateStreamFuture().isCancelled());\n        assertTrue(inputChannelStateFuture.isCancelled());\n        assertTrue(resultSubpartitionStateFuture.isCancelled());\n\n        stateHandler.dispose();\n\n        assertThat(\n                stateContext.operatorStateBackend().getRegisteredBroadcastStateNames(),\n                is(empty()));\n        assertThat(stateContext.operatorStateBackend().getRegisteredStateNames(), is(empty()));\n        assertThat(\n                ((AbstractKeyedStateBackend<?>) stateContext.keyedStateBackend())\n                        .numKeyValueStatesByName(),\n                equalTo(0));\n    }\n}", "summary_tokens": ["tests", "that", "a", "failing", "snapshot", "method", "call", "to", "the", "keyed", "state", "backend", "will", "trigger", "the", "closing", "of", "the", "state", "snapshot", "context", "synchronous", "impl", "and", "the", "cancellation", "of", "the", "operator", "snapshot", "result"], "project": "flink"}
{"id": 1981, "code": "public static <T> T instantiate(Class<T> clazz) {\n    if (clazz == null) {\n        throw new NullPointerException();\n    }\n\n        \n    try {\n        return clazz.newInstance();\n    } catch (InstantiationException | IllegalAccessException iex) {\n            \n        checkForInstantiation(clazz);\n\n            \n            \n        throw new RuntimeException(\n                \"Could not instantiate type '\"\n                        + clazz.getName()\n                        + \"' due to an unspecified exception: \"\n                        + iex.getMessage(),\n                iex);\n    } catch (Throwable t) {\n        String message = t.getMessage();\n        throw new RuntimeException(\n                \"Could not instantiate type '\"\n                        + clazz.getName()\n                        + \"' Most likely the constructor (or a member variable initialization) threw an exception\"\n                        + (message == null ? \".\" : \": \" + message),\n                t);\n    }\n}", "summary_tokens": ["creates", "a", "new", "instance", "of", "the", "given", "class"], "project": "flink"}
{"id": 6832, "code": "public void testPutWithAllocationFailure() {\n    Allocator exceptionalAllocator =\n            new Allocator() {\n                @Override\n                public long allocate(int size) {\n                    throw new RuntimeException(\"Exception on purpose\");\n                }\n\n                @Override\n                public void free(long address) {}\n\n                @Override\n                @Nullable\n                public Chunk getChunkById(int chunkId) {\n                    return null;\n                }\n\n                @Override\n                public void close() {}\n            };\n    try (CopyOnWriteSkipListStateMap<Integer, Long, String> stateMap =\n            createEmptyStateMap(0, 0.0f, exceptionalAllocator)) {\n        stateMap.put(1, 1L, \"test-value\");\n        fail(\"Should have thrown exception when space allocation fails\");\n    } catch (FlinkRuntimeException e) {\n            \n    }\n}", "summary_tokens": ["make", "sure", "exception", "will", "be", "thrown", "with", "allocation", "failure", "rather", "than", "swallowed"], "project": "flink"}
{"id": 6367, "code": "public void testSpillingFreesOnlyOverflowSegments() {\n    final TypeSerializer<ByteValue> serializer = ByteValueSerializer.INSTANCE;\n    final TypeComparator<ByteValue> buildComparator =\n            new ValueComparator<>(true, ByteValue.class);\n    final TypeComparator<ByteValue> probeComparator =\n            new ValueComparator<>(true, ByteValue.class);\n\n    @SuppressWarnings(\"unchecked\")\n    final TypePairComparator<ByteValue, ByteValue> pairComparator =\n            Mockito.mock(TypePairComparator.class);\n\n    try (final IOManager ioMan = new IOManagerAsync()) {\n        final int pageSize = 32 * 1024;\n        final int numSegments = 34;\n\n        List<MemorySegment> memory = getMemory(numSegments, pageSize);\n\n        MutableHashTable<ByteValue, ByteValue> table =\n                new MutableHashTable<>(\n                        serializer,\n                        serializer,\n                        buildComparator,\n                        probeComparator,\n                        pairComparator,\n                        memory,\n                        ioMan,\n                        1,\n                        false);\n\n        table.open(new ByteValueIterator(100000000), new ByteValueIterator(1));\n\n        table.close();\n\n        checkNoTempFilesRemain(ioMan);\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["this", "tests", "the", "case", "where", "no", "additional", "partition", "buffers", "are", "used", "at", "the", "point", "when", "spilling", "is", "triggered", "testing", "that", "overflow", "bucket", "buffers", "are", "taken", "into", "account", "when", "deciding", "which", "partition", "to", "spill"], "project": "flink"}
{"id": 617, "code": "public static int assign(KafkaTopicPartition partition, int numParallelSubtasks) {\n    int startIndex =\n            ((partition.getTopic().hashCode() * 31) & 0x7FFFFFFF) % numParallelSubtasks;\n\n        \n        \n        \n    return (startIndex + partition.getPartition()) % numParallelSubtasks;\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "target", "subtask", "that", "a", "specific", "kafka", "partition", "should", "be", "assigned", "to"], "project": "flink"}
{"id": 924, "code": "public String getFullTopicName() {\n    if (partitionId >= 0) {\n        return topicNameWithPartition(topic, partitionId);\n    } else {\n        return topic;\n    }\n}", "summary_tokens": ["pulsar", "split", "the", "topic", "partition", "into", "a", "bunch", "of", "small", "topics", "we", "would", "get", "the", "real", "topic", "name", "by", "using", "this", "method"], "project": "flink"}
{"id": 3989, "code": "public static Config getAkkaConfig(\n        Configuration configuration,\n        @Nullable HostAndPort externalAddress,\n        @Nullable HostAndPort bindAddress,\n        Config executorConfig) {\n\n    final Config defaultConfig =\n            AkkaUtils.getBasicAkkaConfig(configuration).withFallback(executorConfig);\n\n    if (externalAddress != null) {\n        if (bindAddress != null) {\n            final Config remoteConfig =\n                    AkkaUtils.getRemoteAkkaConfig(\n                            configuration,\n                            bindAddress.getHost(),\n                            bindAddress.getPort(),\n                            externalAddress.getHost(),\n                            externalAddress.getPort());\n\n            return remoteConfig.withFallback(defaultConfig);\n        } else {\n            final Config remoteConfig =\n                    AkkaUtils.getRemoteAkkaConfig(\n                            configuration,\n                            NetUtils.getWildcardIPAddress(),\n                            externalAddress.getPort(),\n                            externalAddress.getHost(),\n                            externalAddress.getPort());\n\n            return remoteConfig.withFallback(defaultConfig);\n        }\n    }\n\n    return defaultConfig;\n}", "summary_tokens": ["creates", "an", "akka", "config", "with", "the", "provided", "configuration", "values"], "project": "flink"}
{"id": 6637, "code": "private static void testStateIteratorWithUpdate(\n        StateIncrementalVisitor<Integer, Integer, ArrayList<Integer>> updatingIterator,\n        CopyOnWriteStateMap<Integer, Integer, ArrayList<Integer>> stateMap,\n        HashMap<Tuple2<Integer, Integer>, ArrayList<Integer>> referenceMap,\n        boolean update,\n        boolean remove) {\n\n    for (StateEntry<Integer, Integer, ArrayList<Integer>> stateEntry :\n            updatingIterator.nextEntries()) {\n        Integer key = stateEntry.getKey();\n        Integer namespace = stateEntry.getNamespace();\n        Tuple2<Integer, Integer> compositeKey = new Tuple2<>(key, namespace);\n        Assert.assertEquals(referenceMap.get(compositeKey), stateEntry.getState());\n\n        if (update) {\n            ArrayList<Integer> newState = new ArrayList<>(stateEntry.getState());\n            if (!newState.isEmpty()) {\n                newState.remove(0);\n            }\n            updatingIterator.update(stateEntry, newState);\n            referenceMap.put(compositeKey, new ArrayList<>(newState));\n            Assert.assertEquals(newState, stateMap.get(key, namespace));\n        }\n\n        if (remove) {\n            updatingIterator.remove(stateEntry);\n            referenceMap.remove(compositeKey);\n        }\n    }\n}", "summary_tokens": ["test", "operations", "specific", "for", "state", "incremental", "visitor", "in", "test", "random", "modifications", "and", "copy", "on", "write", "isolation"], "project": "flink"}
{"id": 1452, "code": "public static void clean(\n        Object func, ExecutionConfig.ClosureCleanerLevel level, boolean checkSerializable) {\n    clean(func, level, checkSerializable, Collections.newSetFromMap(new IdentityHashMap<>()));\n}", "summary_tokens": ["tries", "to", "clean", "the", "closure", "of", "the", "given", "object", "if", "the", "object", "is", "a", "non", "static", "inner", "class"], "project": "flink"}
{"id": 6572, "code": "public void testLoadMemoryStateWithParameters() throws Exception {\n    final String checkpointDir = new Path(tmp.newFolder().toURI()).toString();\n    final String savepointDir = new Path(tmp.newFolder().toURI()).toString();\n    final Path expectedCheckpointPath = new Path(checkpointDir);\n    final Path expectedSavepointPath = new Path(savepointDir);\n\n        \n        \n        \n\n    final Configuration config1 = new Configuration();\n    config1.setString(backendKey, \"jobmanager\");\n    config1.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir);\n    config1.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir);\n\n    final Configuration config2 = new Configuration();\n    config2.setString(backendKey, MemoryStateBackendFactory.class.getName());\n    config2.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir);\n    config2.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir);\n\n    MemoryStateBackend backend1 =\n            (MemoryStateBackend)\n                    StateBackendLoader.loadStateBackendFromConfig(config1, cl, null);\n    MemoryStateBackend backend2 =\n            (MemoryStateBackend)\n                    StateBackendLoader.loadStateBackendFromConfig(config2, cl, null);\n\n    assertNotNull(backend1);\n    assertNotNull(backend2);\n\n    assertEquals(expectedCheckpointPath, backend1.getCheckpointPath());\n    assertEquals(expectedSavepointPath, backend1.getSavepointPath());\n    assertEquals(expectedCheckpointPath, backend2.getCheckpointPath());\n    assertEquals(expectedSavepointPath, backend2.getSavepointPath());\n}", "summary_tokens": ["validates", "loading", "a", "memory", "state", "backend", "with", "additional", "parameters", "from", "the", "cluster", "configuration"], "project": "flink"}
{"id": 417, "code": "public ExprNodeDesc genExprNodeDesc(\n        HiveParserASTNode expr, HiveParserRowResolver input, HiveParserTypeCheckCtx tcCtx)\n        throws SemanticException {\n        \n        \n        \n        \n        \n        \n\n        \n    ExprNodeDesc cached = null;\n    if (tcCtx.isUseCaching()) {\n        cached = getExprNodeDescCached(expr, input);\n    }\n    if (cached == null) {\n        Map<HiveParserASTNode, ExprNodeDesc> allExprs = genAllExprNodeDesc(expr, input, tcCtx);\n        return allExprs.get(expr);\n    }\n    return cached;\n}", "summary_tokens": ["returns", "expression", "node", "descriptor", "for", "the", "expression"], "project": "flink"}
{"id": 86, "code": "public void testDetachedMode() throws Exception {\n    final ClusterClient<?> clusterClient =\n            new MiniClusterClient(new Configuration(), MINI_CLUSTER_RESOURCE.getMiniCluster());\n\n    try {\n        PackagedProgram prg =\n                PackagedProgram.newBuilder()\n                        .setEntryPointClassName(TestEager.class.getName())\n                        .build();\n        final Configuration configuration = fromPackagedProgram(prg, 1, true);\n\n        ClientUtils.executeProgram(\n                new TestExecutorServiceLoader(clusterClient, plan),\n                configuration,\n                prg,\n                false,\n                false);\n        fail(FAIL_MESSAGE);\n    } catch (ProgramInvocationException e) {\n        assertEquals(\n                DetachedJobExecutionResult.DETACHED_MESSAGE\n                        + DetachedJobExecutionResult.JOB_RESULT_MESSAGE\n                        + DetachedJobExecutionResult.EAGER_FUNCTION_MESSAGE,\n                e.getCause().getMessage());\n    }\n\n    try {\n        PackagedProgram prg =\n                PackagedProgram.newBuilder()\n                        .setEntryPointClassName(TestGetRuntime.class.getName())\n                        .build();\n        final Configuration configuration = fromPackagedProgram(prg, 1, true);\n\n        ClientUtils.executeProgram(\n                new TestExecutorServiceLoader(clusterClient, plan),\n                configuration,\n                prg,\n                false,\n                false);\n        fail(FAIL_MESSAGE);\n    } catch (ProgramInvocationException e) {\n        assertEquals(\n                DetachedJobExecutionResult.DETACHED_MESSAGE\n                        + DetachedJobExecutionResult.JOB_RESULT_MESSAGE,\n                e.getCause().getMessage());\n    }\n\n    try {\n        PackagedProgram prg =\n                PackagedProgram.newBuilder()\n                        .setEntryPointClassName(TestGetAccumulator.class.getName())\n                        .build();\n        final Configuration configuration = fromPackagedProgram(prg, 1, true);\n\n        ClientUtils.executeProgram(\n                new TestExecutorServiceLoader(clusterClient, plan),\n                configuration,\n                prg,\n                false,\n                false);\n        fail(FAIL_MESSAGE);\n    } catch (ProgramInvocationException e) {\n        assertEquals(\n                DetachedJobExecutionResult.DETACHED_MESSAGE\n                        + DetachedJobExecutionResult.JOB_RESULT_MESSAGE\n                        + DetachedJobExecutionResult.EAGER_FUNCTION_MESSAGE,\n                e.getCause().getMessage());\n    }\n\n    try {\n        PackagedProgram prg =\n                PackagedProgram.newBuilder()\n                        .setEntryPointClassName(TestGetAllAccumulator.class.getName())\n                        .build();\n        final Configuration configuration = fromPackagedProgram(prg, 1, true);\n\n        ClientUtils.executeProgram(\n                new TestExecutorServiceLoader(clusterClient, plan),\n                configuration,\n                prg,\n                false,\n                false);\n        fail(FAIL_MESSAGE);\n    } catch (ProgramInvocationException e) {\n        assertEquals(\n                DetachedJobExecutionResult.DETACHED_MESSAGE\n                        + DetachedJobExecutionResult.JOB_RESULT_MESSAGE,\n                e.getCause().getMessage());\n    }\n}", "summary_tokens": ["tests", "that", "invalid", "detached", "mode", "programs", "fail"], "project": "flink"}
{"id": 7029, "code": "public SingleOutputStreamOperator<T> maxBy(String field, boolean first) {\n    return aggregate(\n            new ComparableAggregator<>(\n                    field,\n                    input.getType(),\n                    AggregationFunction.AggregationType.MAXBY,\n                    first,\n                    input.getExecutionConfig()));\n}", "summary_tokens": ["applies", "an", "aggregation", "that", "that", "gives", "the", "maximum", "element", "of", "the", "pojo", "data", "stream", "by", "the", "given", "field", "expression", "for", "every", "window"], "project": "flink"}
{"id": 3325, "code": "public void postSuperstep() throws Exception {}", "summary_tokens": ["this", "method", "is", "executed", "once", "per", "superstep", "after", "the", "vertex", "update", "function", "has", "been", "invoked", "for", "each", "vertex"], "project": "flink"}
{"id": 683, "code": "public void runFailOnNoBrokerTest() throws Exception {\n    try {\n        Properties properties = new Properties();\n\n        StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n        see.setRestartStrategy(RestartStrategies.noRestart());\n        see.setParallelism(1);\n\n            \n        properties.setProperty(\"bootstrap.servers\", \"localhost:80\");\n        properties.setProperty(\"group.id\", \"test\");\n        properties.setProperty(\"request.timeout.ms\", \"3000\"); \n        properties.setProperty(\"socket.timeout.ms\", \"3000\");\n        properties.setProperty(\"session.timeout.ms\", \"2000\");\n        properties.setProperty(\"fetch.max.wait.ms\", \"2000\");\n        properties.setProperty(\"heartbeat.interval.ms\", \"1000\");\n        properties.putAll(secureProps);\n        DataStream<String> stream =\n                getStream(see, \"doesntexist\", new SimpleStringSchema(), properties);\n        stream.print();\n        see.execute(\"No broker test\");\n    } catch (JobExecutionException jee) {\n        if (kafkaServer.getVersion().equals(\"0.9\")\n                || kafkaServer.getVersion().equals(\"0.10\")\n                || kafkaServer.getVersion().equals(\"0.11\")\n                || kafkaServer.getVersion().equals(\"2.0\")) {\n            final Optional<TimeoutException> optionalTimeoutException =\n                    ExceptionUtils.findThrowable(jee, TimeoutException.class);\n            assertTrue(optionalTimeoutException.isPresent());\n\n            final TimeoutException timeoutException = optionalTimeoutException.get();\n            if (useNewSource) {\n                assertThat(\n                        timeoutException.getCause().getMessage(),\n                        containsString(\"Timed out waiting for a node assignment.\"));\n            } else {\n                assertEquals(\n                        \"Timeout expired while fetching topic metadata\",\n                        timeoutException.getMessage());\n            }\n        } else {\n            final Optional<Throwable> optionalThrowable =\n                    ExceptionUtils.findThrowableWithMessage(\n                            jee, \"Unable to retrieve any partitions\");\n            assertTrue(optionalThrowable.isPresent());\n            assertTrue(optionalThrowable.get() instanceof RuntimeException);\n        }\n    }\n}", "summary_tokens": ["test", "that", "ensures", "the", "kafka", "consumer", "is", "properly", "failing", "if", "the", "topic", "doesn", "t", "exist", "and", "a", "wrong", "broker", "was", "specified"], "project": "flink"}
{"id": 7918, "code": "public static <IN1, IN2, OUT>\n        BroadcastOperatorTestHarness<IN1, IN2, OUT> forBroadcastProcessFunction(\n                final BroadcastProcessFunction<IN1, IN2, OUT> function,\n                final MapStateDescriptor<?, ?>... descriptors)\n                throws Exception {\n\n    BroadcastOperatorTestHarness<IN1, IN2, OUT> testHarness =\n            new BroadcastOperatorTestHarness<>(\n                    new CoBroadcastWithNonKeyedOperator<>(\n                            Preconditions.checkNotNull(function), Arrays.asList(descriptors)),\n                    1,\n                    1,\n                    0);\n    testHarness.open();\n    return testHarness;\n}", "summary_tokens": ["returns", "an", "initialized", "test", "harness", "for", "broadcast", "process", "function"], "project": "flink"}
{"id": 8672, "code": "public static int subtractMonths(int date0, int date1) {\n    if (date0 < date1) {\n        return -subtractMonths(date1, date0);\n    }\n        \n        \n    int m = (date0 - date1) / 31;\n    while (true) {\n        int date2 = addMonths(date1, m);\n        if (date2 >= date0) {\n            return m;\n        }\n        int date3 = addMonths(date1, m + 1);\n        if (date3 > date0) {\n            return m;\n        }\n        ++m;\n    }\n}", "summary_tokens": ["finds", "the", "number", "of", "months", "between", "two", "dates", "each", "represented", "as", "the", "number", "of", "days", "since", "the", "epoch"], "project": "flink"}
{"id": 1141, "code": "public long getTimestamp() {\n    return timestamp;\n}", "summary_tokens": ["returns", "the", "timestamp", "associated", "with", "this", "watermark"], "project": "flink"}
{"id": 7575, "code": "protected Optional<CheckpointBarrierHandler> getCheckpointBarrierHandler() {\n    return Optional.empty();\n}", "summary_tokens": ["acquires", "the", "optional", "checkpoint", "barrier", "handler", "associated", "with", "this", "stream", "task"], "project": "flink"}
{"id": 2849, "code": "public Double getVariance() {\n    return variance;\n}", "summary_tokens": ["variance", "is", "a", "measure", "of", "how", "far", "a", "set", "of", "numbers", "are", "spread", "out"], "project": "flink"}
{"id": 960, "code": "static void declareQueueDefaults(Channel channel, String queueName) throws IOException {\n    channel.queueDeclare(queueName, true, false, false, null);\n}", "summary_tokens": ["declares", "a", "queue", "with", "sensible", "defaults", "durable", "non", "exclusive", "non", "auto", "delete", "and", "no", "arguments"], "project": "flink"}
{"id": 4478, "code": "public long getSizeOfJvmHeap() {\n    return this.sizeOfJvmHeap;\n}", "summary_tokens": ["returns", "the", "size", "of", "the", "jvm", "heap", "memory"], "project": "flink"}
{"id": 2959, "code": "protected NumericColumnSummary<Float> summarize(Float... values) {\n\n    FloatValue[] floatValues = new FloatValue[values.length];\n    for (int i = 0; i < values.length; i++) {\n        if (values[i] != null) {\n            floatValues[i] = new FloatValue(values[i]);\n        }\n    }\n\n    return new AggregateCombineHarness<\n            FloatValue,\n            NumericColumnSummary<Float>,\n            ValueSummaryAggregator.FloatValueSummaryAggregator>() {\n\n        @Override\n        protected void compareResults(\n                NumericColumnSummary<Float> result1, NumericColumnSummary<Float> result2) {\n            Assert.assertEquals(result1.getMin(), result2.getMin(), 0.0f);\n            Assert.assertEquals(result1.getMax(), result2.getMax(), 0.0f);\n            Assert.assertEquals(result1.getMean(), result2.getMean(), 1e-10d);\n            Assert.assertEquals(result1.getVariance(), result2.getVariance(), 1e-9d);\n            Assert.assertEquals(\n                    result1.getStandardDeviation(), result2.getStandardDeviation(), 1e-10d);\n        }\n    }.summarize(floatValues);\n}", "summary_tokens": ["helper", "method", "for", "summarizing", "a", "list", "of", "values"], "project": "flink"}
{"id": 6672, "code": "public void testRetrievingAllActiveSlots() throws Exception {\n    try (final TaskSlotTableImpl<?> taskSlotTable = createTaskSlotTableAndStart(3)) {\n        final JobID jobId1 = new JobID();\n        final AllocationID allocationId1 = new AllocationID();\n        taskSlotTable.allocateSlot(0, jobId1, allocationId1, SLOT_TIMEOUT);\n        final AllocationID allocationId2 = new AllocationID();\n        taskSlotTable.allocateSlot(1, jobId1, allocationId2, SLOT_TIMEOUT);\n        final AllocationID allocationId3 = new AllocationID();\n        final JobID jobId2 = new JobID();\n        taskSlotTable.allocateSlot(2, jobId2, allocationId3, SLOT_TIMEOUT);\n\n        taskSlotTable.markSlotActive(allocationId1);\n        taskSlotTable.markSlotActive(allocationId3);\n\n        assertThat(\n                taskSlotTable.getActiveTaskSlotAllocationIds(),\n                is(Sets.newHashSet(allocationId1, allocationId3)));\n    }\n}", "summary_tokens": ["tests", "task", "slot", "table", "impl", "get", "active", "task", "slot", "allocation", "ids"], "project": "flink"}
{"id": 4666, "code": "boolean readBuffers(Queue<MemorySegment> buffers, BufferRecycler recycler) throws IOException {\n    while (!buffers.isEmpty()) {\n        MemorySegment segment = buffers.poll();\n\n        Buffer buffer;\n        try {\n            if ((buffer = fileReader.readCurrentRegion(segment, recycler)) == null) {\n                buffers.add(segment);\n                break;\n            }\n        } catch (Throwable throwable) {\n            buffers.add(segment);\n            throw throwable;\n        }\n        addBuffer(buffer);\n    }\n    return fileReader.hasRemaining();\n}", "summary_tokens": ["this", "method", "is", "called", "by", "the", "io", "thread", "of", "sort", "merge", "result", "partition", "read", "scheduler"], "project": "flink"}
{"id": 1291, "code": "public Operator<ST> getSolutionSetDelta() {\n    return this.solutionSetDelta;\n}", "summary_tokens": ["gets", "the", "contract", "that", "has", "been", "set", "as", "the", "solution", "set", "delta"], "project": "flink"}
{"id": 8443, "code": "public String getJobParameter(String key, String defaultValue) {\n    final GlobalJobParameters conf = context.getExecutionConfig().getGlobalJobParameters();\n    if (conf != null) {\n        return conf.toMap().getOrDefault(key, defaultValue);\n    }\n    return defaultValue;\n}", "summary_tokens": ["gets", "the", "global", "job", "parameter", "value", "associated", "with", "the", "given", "key", "as", "a", "string"], "project": "flink"}
{"id": 8023, "code": "public void addJobParameter(String key, String value) {\n    Map<String, String> params =\n            getConfiguration()\n                    .getOptional(PipelineOptions.GLOBAL_JOB_PARAMETERS)\n                    .map(HashMap::new)\n                    .orElseGet(HashMap::new);\n    params.put(key, value);\n    getConfiguration().set(PipelineOptions.GLOBAL_JOB_PARAMETERS, params);\n}", "summary_tokens": ["sets", "a", "custom", "user", "parameter", "that", "can", "be", "accessed", "via", "org"], "project": "flink"}
{"id": 7641, "code": "public void testResourcesForIteration() throws Exception {\n    ResourceSpec resource1 = ResourceSpec.newBuilder(0.1, 100).build();\n    ResourceSpec resource2 = ResourceSpec.newBuilder(0.2, 200).build();\n    ResourceSpec resource3 = ResourceSpec.newBuilder(0.3, 300).build();\n    ResourceSpec resource4 = ResourceSpec.newBuilder(0.4, 400).build();\n    ResourceSpec resource5 = ResourceSpec.newBuilder(0.5, 500).build();\n\n    Method opMethod = getSetResourcesMethodAndSetAccessible(SingleOutputStreamOperator.class);\n    Method sinkMethod = getSetResourcesMethodAndSetAccessible(DataStreamSink.class);\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStream<Integer> source =\n            env.addSource(\n                            new ParallelSourceFunction<Integer>() {\n                                @Override\n                                public void run(SourceContext<Integer> ctx) throws Exception {}\n\n                                @Override\n                                public void cancel() {}\n                            })\n                    .name(\"test_source\");\n    opMethod.invoke(source, resource1);\n\n    IterativeStream<Integer> iteration = source.iterate(3000);\n    opMethod.invoke(iteration, resource2);\n\n    DataStream<Integer> flatMap =\n            iteration\n                    .flatMap(\n                            new FlatMapFunction<Integer, Integer>() {\n                                @Override\n                                public void flatMap(Integer value, Collector<Integer> out)\n                                        throws Exception {\n                                    out.collect(value);\n                                }\n                            })\n                    .name(\"test_flatMap\");\n    opMethod.invoke(flatMap, resource3);\n\n        \n    DataStream<Integer> increment =\n            flatMap.filter(\n                            new FilterFunction<Integer>() {\n                                @Override\n                                public boolean filter(Integer value) throws Exception {\n                                    return false;\n                                }\n                            })\n                    .name(\"test_filter\");\n    opMethod.invoke(increment, resource4);\n\n    DataStreamSink<Integer> sink =\n            iteration\n                    .closeWith(increment)\n                    .addSink(\n                            new SinkFunction<Integer>() {\n                                @Override\n                                public void invoke(Integer value) throws Exception {}\n                            })\n                    .disableChaining()\n                    .name(\"test_sink\");\n    sinkMethod.invoke(sink, resource5);\n\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\n    for (JobVertex jobVertex : jobGraph.getVertices()) {\n        if (jobVertex.getName().contains(\"test_source\")) {\n            assertTrue(jobVertex.getMinResources().equals(resource1));\n        } else if (jobVertex.getName().contains(\"Iteration_Source\")) {\n            assertTrue(jobVertex.getPreferredResources().equals(resource2));\n        } else if (jobVertex.getName().contains(\"test_flatMap\")) {\n            assertTrue(jobVertex.getMinResources().equals(resource3.merge(resource4)));\n        } else if (jobVertex.getName().contains(\"Iteration_Tail\")) {\n            assertTrue(jobVertex.getPreferredResources().equals(ResourceSpec.DEFAULT));\n        } else if (jobVertex.getName().contains(\"test_sink\")) {\n            assertTrue(jobVertex.getMinResources().equals(resource5));\n        }\n    }\n}", "summary_tokens": ["verifies", "that", "the", "resources", "are", "merged", "correctly", "for", "chained", "operators", "covers", "middle", "chaining", "and", "iteration", "cases", "when", "generating", "job", "graph"], "project": "flink"}
{"id": 8026, "code": "public CatalogTable toCatalogTable() {\n    final Schema schema =\n            getSchema()\n                    .orElseThrow(\n                            () ->\n                                    new ValidationException(\n                                            \"Missing schema in TableDescriptor. \"\n                                                    + \"A schema is typically required. \"\n                                                    + \"It can only be omitted at certain \"\n                                                    + \"documented locations.\"));\n\n    return CatalogTable.of(schema, getComment().orElse(null), getPartitionKeys(), getOptions());\n}", "summary_tokens": ["converts", "this", "descriptor", "into", "a", "catalog", "table"], "project": "flink"}
{"id": 5515, "code": "public int getMinFileSizeThreshold() {\n    return fileStateThreshold >= 0\n            ? fileStateThreshold\n            : MathUtils.checkedDownCast(FS_SMALL_FILE_THRESHOLD.defaultValue().getBytes());\n}", "summary_tokens": ["gets", "the", "threshold", "below", "which", "state", "is", "stored", "as", "part", "of", "the", "metadata", "rather", "than", "in", "files"], "project": "flink"}
{"id": 6680, "code": "public void testFatalErrorAfterUnInterruptibleInvoke() throws Exception {\n    final CompletableFuture<Throwable> fatalErrorFuture = new CompletableFuture<>();\n    final TestingTaskManagerActions taskManagerActions =\n            TestingTaskManagerActions.newBuilder()\n                    .setNotifyFatalErrorConsumer(\n                            (s, throwable) -> fatalErrorFuture.complete(throwable))\n                    .build();\n\n    final Configuration config = new Configuration();\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT, 10);\n\n    final Task task =\n            createTaskBuilder()\n                    .setInvokable(InvokableUnInterruptibleBlockingInvoke.class)\n                    .setTaskManagerConfig(config)\n                    .setTaskManagerActions(taskManagerActions)\n                    .build();\n\n    try {\n        task.startTaskThread();\n\n        awaitLatch.await();\n\n        task.cancelExecution();\n\n            \n        final Throwable fatalError = fatalErrorFuture.join();\n        assertThat(fatalError, is(notNullValue()));\n    } finally {\n            \n        triggerLatch.trigger();\n        task.getExecutingThread().interrupt();\n        task.getExecutingThread().join();\n    }\n}", "summary_tokens": ["the", "invoke", "method", "blocks", "infinitely", "but", "cancel", "does", "not", "block"], "project": "flink"}
{"id": 5139, "code": "protected Configuration getEffectiveConfigurationForResourceManager(\n        final Configuration configuration) {\n    return configuration;\n}", "summary_tokens": ["configuration", "changes", "in", "this", "method", "will", "be", "visible", "to", "only", "resource", "manager"], "project": "flink"}
{"id": 4811, "code": "public static JobMasterId fromUuidOrNull(@Nullable UUID uuid) {\n    return uuid == null ? null : new JobMasterId(uuid);\n}", "summary_tokens": ["if", "the", "given", "uuid", "is", "null", "this", "returns", "null", "otherwise", "a", "job", "master", "id", "that", "corresponds", "to", "the", "uuid", "via", "job", "master", "id", "uuid"], "project": "flink"}
{"id": 2755, "code": "public ResourceSpec getMinResources() {\n    return this.minResources;\n}", "summary_tokens": ["returns", "the", "minimum", "resources", "of", "this", "data", "sink"], "project": "flink"}
{"id": 1305, "code": "public void setCombinable(boolean combinable) {\n        \n    if (combinable\n            && !GroupCombineFunction.class.isAssignableFrom(\n                    this.userFunction.getUserCodeClass())) {\n        throw new IllegalArgumentException(\n                \"Cannot set a UDF as combinable if it does not implement the interface \"\n                        + GroupCombineFunction.class.getName());\n    } else {\n        this.combinable = combinable;\n    }\n}", "summary_tokens": ["marks", "the", "group", "reduce", "operation", "as", "combinable"], "project": "flink"}
{"id": 601, "code": "public List<E> pollBatch() {\n    lock.lock();\n    try {\n        if (open) {\n            if (elements.size() > 0) {\n                ArrayList<E> result = new ArrayList<>(elements);\n                elements.clear();\n                return result;\n            } else {\n                return null;\n            }\n        } else {\n            throw new IllegalStateException(\"queue is closed\");\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["returns", "all", "of", "the", "queue", "s", "current", "elements", "in", "a", "list", "if", "the", "queue", "is", "non", "empty"], "project": "flink"}
{"id": 60, "code": "public static Optional<String> findFirstManifestAttribute(File jarFile, String... attributes)\n        throws IOException {\n    if (attributes.length == 0) {\n        return Optional.empty();\n    }\n    try (JarFile f = new JarFile(jarFile)) {\n        return findFirstManifestAttribute(f, attributes);\n    }\n}", "summary_tokens": ["returns", "the", "value", "of", "the", "first", "manifest", "attribute", "found", "in", "the", "provided", "jar", "file"], "project": "flink"}
{"id": 5383, "code": "public long getKeyGroupOffset(int keyGroup) {\n    return offsets[computeKeyGroupIndex(keyGroup)];\n}", "summary_tokens": ["returns", "the", "offset", "for", "the", "given", "key", "group"], "project": "flink"}
{"id": 6444, "code": "public void testRequestNewResources() throws Exception {\n    final int numberSlots = 2;\n    final AtomicInteger resourceRequests = new AtomicInteger(0);\n    final TestingResourceActions testingResourceActions =\n            new TestingResourceActionsBuilder()\n                    .setAllocateResourceFunction(\n                            ignored -> {\n                                resourceRequests.incrementAndGet();\n                                return true;\n                            })\n                    .build();\n\n    try (final DeclarativeSlotManager slotManager =\n            createSlotManager(\n                    ResourceManagerId.generate(), testingResourceActions, numberSlots)) {\n\n        final JobID jobId = new JobID();\n\n            \n            \n        slotManager.processResourceRequirements(createResourceRequirements(jobId, 1));\n        assertThat(resourceRequests.get(), is(1));\n\n        slotManager.processResourceRequirements(createResourceRequirements(jobId, 2));\n        assertThat(resourceRequests.get(), is(1));\n\n        slotManager.processResourceRequirements(createResourceRequirements(jobId, 3));\n        assertThat(resourceRequests.get(), is(2));\n    }\n}", "summary_tokens": ["tests", "that", "we", "only", "request", "new", "resources", "containers", "once", "we", "have", "assigned", "all", "pending", "task", "manager", "slots"], "project": "flink"}
{"id": 658, "code": "public void ignoreCheckpointWhenNotRunning() throws Exception {\n    @SuppressWarnings(\"unchecked\")\n    final MockFetcher<String> fetcher = new MockFetcher<>();\n    final FlinkKafkaConsumerBase<String> consumer =\n            new DummyFlinkKafkaConsumer<>(\n                    fetcher, mock(AbstractPartitionDiscoverer.class), false);\n\n    final TestingListState<Tuple2<KafkaTopicPartition, Long>> listState =\n            new TestingListState<>();\n    setupConsumer(consumer, false, listState, true, 0, 1);\n\n        \n    consumer.snapshotState(new StateSnapshotContextSynchronousImpl(1, 1));\n\n        \n    assertFalse(listState.get().iterator().hasNext());\n\n        \n    consumer.notifyCheckpointComplete(1L);\n    assertNull(fetcher.getAndClearLastCommittedOffsets());\n    assertEquals(0, fetcher.getCommitCount());\n}", "summary_tokens": ["tests", "that", "no", "checkpoints", "happen", "when", "the", "fetcher", "is", "not", "running"], "project": "flink"}
{"id": 4346, "code": "public ResourceProfile subtract(final ResourceProfile other) {\n    checkNotNull(other, \"Cannot subtract with null resources\");\n\n    if (equals(ANY) || other.equals(ANY)) {\n        return ANY;\n    }\n\n    if (this.equals(UNKNOWN) || other.equals(UNKNOWN)) {\n        return UNKNOWN;\n    }\n\n    checkArgument(\n            allFieldsNoLessThan(other),\n            \"Try to subtract an unmatched resource profile from this one.\");\n\n    Map<String, ExternalResource> resultExtendedResource = new HashMap<>(extendedResources);\n\n    other.extendedResources.forEach(\n            (String name, ExternalResource resource) ->\n                    resultExtendedResource.compute(\n                            name, (ignored, oldResource) -> oldResource.subtract(resource)));\n\n    return new ResourceProfile(\n            cpuCores.subtract(other.cpuCores),\n            taskHeapMemory.subtract(other.taskHeapMemory),\n            taskOffHeapMemory.subtract(other.taskOffHeapMemory),\n            managedMemory.subtract(other.managedMemory),\n            networkMemory.subtract(other.networkMemory),\n            resultExtendedResource);\n}", "summary_tokens": ["subtracts", "another", "piece", "of", "resource", "profile", "from", "this", "one"], "project": "flink"}
{"id": 4090, "code": "public void track(JobID jobId, BlobKey blobKey, long size) {\n    checkNotNull(jobId);\n    checkNotNull(blobKey);\n    checkArgument(size >= 0);\n\n    synchronized (lock) {\n        if (caches.putIfAbsent(Tuple2.of(jobId, blobKey), size) == null) {\n            blobKeyByJob.computeIfAbsent(jobId, ignore -> new HashSet<>()).add(blobKey);\n\n            total += size;\n            if (total > sizeLimit) {\n                LOG.warn(\n                        \"The overall size of BLOBs in the cache exceeds \"\n                                + \"the limit. Limit = [{}], Current: [{}], \"\n                                + \"The size of next BLOB: [{}].\",\n                        sizeLimit,\n                        total,\n                        size);\n            }\n        } else {\n            LOG.warn(\n                    \"Attempt to track a duplicated BLOB. This may indicate a duplicate upload \"\n                            + \"or a hash collision. Ignoring newest upload. \"\n                            + \"JobID = [{}], BlobKey = [{}]\",\n                    jobId,\n                    blobKey);\n        }\n    }\n}", "summary_tokens": ["register", "the", "blob", "to", "the", "tracker"], "project": "flink"}
{"id": 2623, "code": "public void testDeletePathIfEmpty() throws IOException {\n    final Path basePath = new Path(hdfsURI);\n    final Path directory = new Path(basePath, UUID.randomUUID().toString());\n    final Path directoryFile = new Path(directory, UUID.randomUUID().toString());\n    final Path singleFile = new Path(basePath, UUID.randomUUID().toString());\n\n    FileSystem fs = basePath.getFileSystem();\n\n    fs.mkdirs(directory);\n\n    byte[] data = \"HDFSTest#testDeletePathIfEmpty\".getBytes(ConfigConstants.DEFAULT_CHARSET);\n\n    for (Path file : Arrays.asList(singleFile, directoryFile)) {\n        org.apache.flink.core.fs.FSDataOutputStream outputStream =\n                fs.create(file, FileSystem.WriteMode.OVERWRITE);\n        outputStream.write(data);\n        outputStream.close();\n    }\n\n        \n    assertTrue(fs.exists(singleFile));\n    assertTrue(fs.exists(directoryFile));\n\n        \n    assertFalse(FileUtils.deletePathIfEmpty(fs, singleFile));\n    assertTrue(fs.exists(singleFile));\n\n        \n    assertFalse(FileUtils.deletePathIfEmpty(fs, directory));\n    assertTrue(fs.exists(directory));\n\n        \n    assertTrue(fs.delete(directoryFile, false));\n\n        \n    assertTrue(FileUtils.deletePathIfEmpty(fs, directory));\n    assertFalse(fs.exists(directory));\n}", "summary_tokens": ["test", "that", "file", "utils", "delete", "path", "if", "empty", "file", "system", "path", "deletes", "the", "path", "if", "it", "is", "empty"], "project": "flink"}
{"id": 8777, "code": "protected RelDataType createTargetRowType(\n        SqlValidatorTable table, SqlNodeList targetColumnList, boolean append) {\n    RelDataType baseRowType = table.getRowType();\n    if (targetColumnList == null) {\n        return baseRowType;\n    }\n    List<RelDataTypeField> targetFields = baseRowType.getFieldList();\n    final List<Map.Entry<String, RelDataType>> fields = new ArrayList<>();\n    if (append) {\n        for (RelDataTypeField targetField : targetFields) {\n            fields.add(\n                    Pair.of(\n                            SqlUtil.deriveAliasFromOrdinal(fields.size()),\n                            targetField.getType()));\n        }\n    }\n    final Set<Integer> assignedFields = new HashSet<>();\n    final RelOptTable relOptTable = table instanceof RelOptTable ? ((RelOptTable) table) : null;\n    for (SqlNode node : targetColumnList) {\n        SqlIdentifier id = (SqlIdentifier) node;\n        RelDataTypeField targetField =\n                SqlValidatorUtil.getTargetField(\n                        baseRowType, typeFactory, id, catalogReader, relOptTable);\n        if (targetField == null) {\n            throw newValidationError(id, RESOURCE.unknownTargetColumn(id.toString()));\n        }\n        if (!assignedFields.add(targetField.getIndex())) {\n            throw newValidationError(id, RESOURCE.duplicateTargetColumn(targetField.getName()));\n        }\n        fields.add(targetField);\n    }\n    return typeFactory.createStructType(fields);\n}", "summary_tokens": ["derives", "a", "row", "type", "for", "insert", "and", "update", "operations"], "project": "flink"}
{"id": 995, "code": "public void open(int taskNumber, int numTasks) throws IOException {\n\n        \n    synchronized (OPEN_MUTEX) {\n        if (Integer.toString(taskNumber + 1).length() > 6) {\n            throw new IOException(\"Task id too large.\");\n        }\n\n        this.taskNumber = taskNumber + 1;\n\n            \n        this.configuration.set(\"mapreduce.output.basename\", \"tmp\");\n\n        TaskAttemptID taskAttemptID =\n                TaskAttemptID.forName(\n                        \"attempt__0000_r_\"\n                                + String.format(\n                                                \"%\"\n                                                        + (6\n                                                                - Integer.toString(\n                                                                                taskNumber + 1)\n                                                                        .length())\n                                                        + \"s\",\n                                                \" \")\n                                        .replace(\" \", \"0\")\n                                + Integer.toString(taskNumber + 1)\n                                + \"_0\");\n\n        this.configuration.set(\"mapred.task.id\", taskAttemptID.toString());\n        this.configuration.setInt(\"mapred.task.partition\", taskNumber + 1);\n            \n        this.configuration.set(\"mapreduce.task.attempt.id\", taskAttemptID.toString());\n        this.configuration.setInt(\"mapreduce.task.partition\", taskNumber + 1);\n\n        try {\n            this.context = new TaskAttemptContextImpl(this.configuration, taskAttemptID);\n            this.outputCommitter = this.mapreduceOutputFormat.getOutputCommitter(this.context);\n            this.outputCommitter.setupJob(new JobContextImpl(this.configuration, new JobID()));\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n\n        this.context.getCredentials().addAll(this.credentials);\n        Credentials currentUserCreds =\n                getCredentialsFromUGI(UserGroupInformation.getCurrentUser());\n        if (currentUserCreds != null) {\n            this.context.getCredentials().addAll(currentUserCreds);\n        }\n\n            \n            \n        if (outputCommitter instanceof FileOutputCommitter) {\n            this.configuration.set(\n                    \"mapreduce.task.output.dir\",\n                    ((FileOutputCommitter) this.outputCommitter).getWorkPath().toString());\n        }\n\n        try {\n            this.recordWriter = this.mapreduceOutputFormat.getRecordWriter(this.context);\n        } catch (InterruptedException e) {\n            throw new IOException(\"Could not create RecordWriter.\", e);\n        }\n    }\n}", "summary_tokens": ["create", "the", "temporary", "output", "file", "for", "hadoop", "record", "writer"], "project": "flink"}
{"id": 7878, "code": "public void testConcurrentPutTakeNonBlockingAndWait() throws Exception {\n    testPutTake(\n            (mailbox -> {\n                Optional<Mail> optionalMail = mailbox.tryTake(DEFAULT_PRIORITY);\n                while (!optionalMail.isPresent()) {\n                    optionalMail = mailbox.tryTake(DEFAULT_PRIORITY);\n                }\n                return optionalMail.get();\n            }));\n}", "summary_tokens": ["test", "the", "producer", "consumer", "pattern", "using", "the", "non", "blocking", "methods", "waits", "on", "the", "mailbox"], "project": "flink"}
{"id": 7023, "code": "public <R> SingleOutputStreamOperator<R> apply(\n        ReduceFunction<T> reduceFunction,\n        AllWindowFunction<T, R, W> function,\n        TypeInformation<R> resultType) {\n    if (reduceFunction instanceof RichFunction) {\n        throw new UnsupportedOperationException(\n                \"ReduceFunction of apply can not be a RichFunction.\");\n    }\n\n        \n    function = input.getExecutionEnvironment().clean(function);\n    reduceFunction = input.getExecutionEnvironment().clean(reduceFunction);\n\n    String callLocation = Utils.getCallLocationName();\n    String udfName = \"AllWindowedStream.\" + callLocation;\n\n    String opName;\n    KeySelector<T, Byte> keySel = input.getKeySelector();\n\n    OneInputStreamOperator<T, R> operator;\n\n    if (evictor != null) {\n        @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n        TypeSerializer<StreamRecord<T>> streamRecordSerializer =\n                (TypeSerializer<StreamRecord<T>>)\n                        new StreamElementSerializer(\n                                input.getType()\n                                        .createSerializer(\n                                                getExecutionEnvironment().getConfig()));\n\n        ListStateDescriptor<StreamRecord<T>> stateDesc =\n                new ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n        opName =\n                \"TriggerWindow(\"\n                        + windowAssigner\n                        + \", \"\n                        + stateDesc\n                        + \", \"\n                        + trigger\n                        + \", \"\n                        + evictor\n                        + \", \"\n                        + udfName\n                        + \")\";\n\n        operator =\n                new EvictingWindowOperator<>(\n                        windowAssigner,\n                        windowAssigner.getWindowSerializer(\n                                getExecutionEnvironment().getConfig()),\n                        keySel,\n                        input.getKeyType()\n                                .createSerializer(getExecutionEnvironment().getConfig()),\n                        stateDesc,\n                        new InternalIterableAllWindowFunction<>(\n                                new ReduceApplyAllWindowFunction<>(reduceFunction, function)),\n                        trigger,\n                        evictor,\n                        allowedLateness,\n                        lateDataOutputTag);\n\n    } else {\n        ReducingStateDescriptor<T> stateDesc =\n                new ReducingStateDescriptor<>(\n                        \"window-contents\",\n                        reduceFunction,\n                        input.getType()\n                                .createSerializer(getExecutionEnvironment().getConfig()));\n\n        opName =\n                \"TriggerWindow(\"\n                        + windowAssigner\n                        + \", \"\n                        + stateDesc\n                        + \", \"\n                        + trigger\n                        + \", \"\n                        + udfName\n                        + \")\";\n\n        operator =\n                new WindowOperator<>(\n                        windowAssigner,\n                        windowAssigner.getWindowSerializer(\n                                getExecutionEnvironment().getConfig()),\n                        keySel,\n                        input.getKeyType()\n                                .createSerializer(getExecutionEnvironment().getConfig()),\n                        stateDesc,\n                        new InternalSingleValueAllWindowFunction<>(function),\n                        trigger,\n                        allowedLateness,\n                        lateDataOutputTag);\n    }\n\n    return input.transform(opName, resultType, operator).forceNonParallel();\n}", "summary_tokens": ["applies", "the", "given", "window", "function", "to", "each", "window"], "project": "flink"}
{"id": 7850, "code": "public void testInputStarvation() throws Exception {\n    try (StreamTaskMailboxTestHarness<String> testHarness =\n            new StreamTaskMailboxTestHarnessBuilder<>(\n                            MultipleInputStreamTask::new, BasicTypeInfo.STRING_TYPE_INFO)\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO)\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO)\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO)\n                    .setupOutputForSingletonOperatorChain(\n                            new TestInputStarvationMultipleInputOperatorFactory())\n                    .build()) {\n\n        testHarness.processAll(); \n\n        Queue<StreamRecord> expectedOutput = new ArrayDeque<>();\n\n        testHarness.setAutoProcess(false);\n            \n            \n        testHarness.processSingleStep();\n        assertTrue(testHarness.getOutput().isEmpty());\n\n        testHarness.processElement(new StreamRecord<>(\"NOT_SELECTED\"), 0);\n\n        testHarness.processElement(new StreamRecord<>(\"1\"), 1);\n        testHarness.processElement(new StreamRecord<>(\"2\"), 1);\n        testHarness.processElement(new StreamRecord<>(\"3\"), 1);\n        testHarness.processElement(new StreamRecord<>(\"4\"), 1);\n\n        testHarness.processSingleStep();\n        expectedOutput.add(new StreamRecord<>(\"[2]: 1\"));\n        testHarness.processSingleStep();\n        expectedOutput.add(new StreamRecord<>(\"[2]: 2\"));\n        assertThat(testHarness.getOutput(), contains(expectedOutput.toArray()));\n\n            \n            \n        testHarness.processElement(new StreamRecord<>(\"1\"), 2);\n        testHarness.processSingleStep();\n        testHarness.processSingleStep();\n\n            \n            \n        expectedOutput.add(new StreamRecord<>(\"[3]: 1\"));\n        expectedOutput.add(new StreamRecord<>(\"[2]: 3\"));\n\n        assertThat(testHarness.getOutput(), containsInAnyOrder(expectedOutput.toArray()));\n    }\n}", "summary_tokens": ["setup", "three", "inputs", "only", "two", "selected", "and", "make", "sure", "that", "neither", "of", "the", "two", "inputs", "is", "starved", "when", "one", "has", "some", "data", "all", "the", "time", "but", "the", "other", "only", "rarely"], "project": "flink"}
{"id": 7822, "code": "public void testReportingFromTaskStateManagerToResponderAndTaskLocalStateStore()\n        throws Exception {\n\n    final JobID jobID = new JobID();\n    final AllocationID allocationID = new AllocationID();\n    final ExecutionAttemptID executionAttemptID = new ExecutionAttemptID();\n    final CheckpointMetaData checkpointMetaData = new CheckpointMetaData(42L, 4711L);\n    final CheckpointMetrics checkpointMetrics = new CheckpointMetrics();\n    final int subtaskIdx = 42;\n    JobVertexID jobVertexID = new JobVertexID();\n\n    TaskStateSnapshot jmSnapshot = new TaskStateSnapshot();\n    TaskStateSnapshot tmSnapshot = new TaskStateSnapshot();\n\n    final AtomicBoolean jmReported = new AtomicBoolean(false);\n    final AtomicBoolean tmReported = new AtomicBoolean(false);\n\n    TestCheckpointResponder checkpointResponder =\n            new TestCheckpointResponder() {\n\n                @Override\n                public void acknowledgeCheckpoint(\n                        JobID lJobID,\n                        ExecutionAttemptID lExecutionAttemptID,\n                        long lCheckpointId,\n                        CheckpointMetrics lCheckpointMetrics,\n                        TaskStateSnapshot lSubtaskState) {\n\n                    Assert.assertEquals(jobID, lJobID);\n                    Assert.assertEquals(executionAttemptID, lExecutionAttemptID);\n                    Assert.assertEquals(checkpointMetaData.getCheckpointId(), lCheckpointId);\n                    Assert.assertEquals(checkpointMetrics, lCheckpointMetrics);\n                    jmReported.set(true);\n                }\n            };\n\n    Executor executor = Executors.directExecutor();\n\n    LocalRecoveryDirectoryProviderImpl directoryProvider =\n            new LocalRecoveryDirectoryProviderImpl(\n                    temporaryFolder.newFolder(), jobID, jobVertexID, subtaskIdx);\n\n    LocalRecoveryConfig localRecoveryConfig = new LocalRecoveryConfig(true, directoryProvider);\n\n    TaskLocalStateStore taskLocalStateStore =\n            new TaskLocalStateStoreImpl(\n                    jobID,\n                    allocationID,\n                    jobVertexID,\n                    subtaskIdx,\n                    localRecoveryConfig,\n                    executor) {\n                @Override\n                public void storeLocalState(\n                        @Nonnegative long checkpointId,\n                        @Nullable TaskStateSnapshot localState) {\n\n                    Assert.assertEquals(tmSnapshot, localState);\n                    tmReported.set(true);\n                }\n            };\n\n    StateChangelogStorage<?> stateChangelogStorage = new InMemoryStateChangelogStorage();\n\n    TaskStateManagerImpl taskStateManager =\n            new TaskStateManagerImpl(\n                    jobID,\n                    executionAttemptID,\n                    taskLocalStateStore,\n                    stateChangelogStorage,\n                    null,\n                    checkpointResponder);\n\n    taskStateManager.reportTaskStateSnapshots(\n            checkpointMetaData, checkpointMetrics, jmSnapshot, tmSnapshot);\n\n    Assert.assertTrue(\"Reporting for JM state was not called.\", jmReported.get());\n    Assert.assertTrue(\"Reporting for TM state was not called.\", tmReported.get());\n}", "summary_tokens": ["this", "tests", "that", "state", "that", "was", "reported", "to", "the", "org"], "project": "flink"}
{"id": 8650, "code": "public static DataType toDataType(LogicalType logicalType) {\n    return logicalType.accept(dataTypeCreator);\n}", "summary_tokens": ["returns", "the", "data", "type", "of", "a", "logical", "type", "without", "explicit", "conversions"], "project": "flink"}
{"id": 7248, "code": "public void registerTypeWithKryoSerializer(\n        Class<?> type, Class<? extends Serializer> serializerClass) {\n    config.registerTypeWithKryoSerializer(type, serializerClass);\n}", "summary_tokens": ["registers", "the", "given", "serializer", "via", "its", "class", "as", "a", "serializer", "for", "the", "given", "type", "at", "the", "kryo", "serializer"], "project": "flink"}
{"id": 9383, "code": "public static void bitSet(MemorySegment[] segments, int baseOffset, int index) {\n    if (segments.length == 1) {\n        int offset = baseOffset + byteIndex(index);\n        MemorySegment segment = segments[0];\n        byte current = segment.get(offset);\n        current |= (1 << (index & BIT_BYTE_INDEX_MASK));\n        segment.put(offset, current);\n    } else {\n        bitSetMultiSegments(segments, baseOffset, index);\n    }\n}", "summary_tokens": ["set", "bit", "from", "segments"], "project": "flink"}
{"id": 8950, "code": "private Transformation<T> translateToTransformation(\n        PlannerBase planner, boolean withChangeFlag) {\n        \n    if (!withChangeFlag && needRetraction) {\n        throw new TableException(\n                \"Table is not an append-only table. \"\n                        + \"Use the toRetractStream() in order to handle add and retract messages.\");\n    }\n\n    final ExecEdge inputEdge = getInputEdges().get(0);\n    final Transformation<RowData> inputTransform =\n            (Transformation<RowData>) inputEdge.translateToPlan(planner);\n    final RowType inputRowType = (RowType) inputEdge.getOutputType();\n    final RowType convertedInputRowType = checkAndConvertInputTypeIfNeeded(inputRowType);\n    final DataType resultDataType = tableSink.getConsumedDataType();\n    if (CodeGenUtils.isInternalClass(resultDataType)) {\n        return (Transformation<T>) inputTransform;\n    } else {\n        final int rowtimeIndex = getRowtimeIndex(inputRowType);\n\n        final DataType physicalOutputType =\n                TableSinkUtils.inferSinkPhysicalDataType(\n                        resultDataType, convertedInputRowType, withChangeFlag);\n\n        final TypeInformation<T> outputTypeInfo =\n                SinkCodeGenerator.deriveSinkOutputTypeInfo(\n                        tableSink, physicalOutputType, withChangeFlag);\n\n        final CodeGenOperatorFactory<T> converterOperator =\n                SinkCodeGenerator.generateRowConverterOperator(\n                        new CodeGeneratorContext(planner.getTableConfig()),\n                        convertedInputRowType,\n                        tableSink,\n                        physicalOutputType,\n                        withChangeFlag,\n                        \"SinkConversion\",\n                        rowtimeIndex);\n        final Configuration config = planner.getTableConfig().getConfiguration();\n        final String description =\n                \"SinkConversion To \" + resultDataType.getConversionClass().getSimpleName();\n        return ExecNodeUtil.createOneInputTransformation(\n                inputTransform,\n                getFormattedOperatorName(description, \"SinkConversion\", config),\n                getFormattedOperatorDescription(description, config),\n                converterOperator,\n                outputTypeInfo,\n                inputTransform.getParallelism());\n    }\n}", "summary_tokens": ["translates", "table", "sink", "into", "a", "transformation"], "project": "flink"}
{"id": 7914, "code": "public static <IN, OUT> OneInputStreamOperatorTestHarness<IN, OUT> forProcessFunction(\n        final ProcessFunction<IN, OUT> function) throws Exception {\n\n    OneInputStreamOperatorTestHarness<IN, OUT> testHarness =\n            new OneInputStreamOperatorTestHarness<>(\n                    new ProcessOperator<>(Preconditions.checkNotNull(function)), 1, 1, 0);\n    testHarness.setup();\n    testHarness.open();\n    return testHarness;\n}", "summary_tokens": ["returns", "an", "initialized", "test", "harness", "for", "process", "function"], "project": "flink"}
{"id": 5336, "code": "void unregisterSourceReader(int subtaskId) {\n    registeredReaders.remove(subtaskId);\n}", "summary_tokens": ["unregister", "a", "source", "reader"], "project": "flink"}
{"id": 8446, "code": "default boolean isDeterministic() {\n    return true;\n}", "summary_tokens": ["returns", "information", "about", "the", "determinism", "of", "the", "function", "s", "results"], "project": "flink"}
{"id": 5928, "code": "public void testDiscardAllCheckpoints() throws Exception {\n    SharedStateRegistry sharedStateRegistry = new SharedStateRegistryImpl();\n    CompletedCheckpointStore checkpoints = createRecoveredCompletedCheckpointStore(4);\n\n    TestCompletedCheckpoint[] expected =\n            new TestCompletedCheckpoint[] {\n                createCheckpoint(0, sharedStateRegistry),\n                        createCheckpoint(1, sharedStateRegistry),\n                createCheckpoint(2, sharedStateRegistry),\n                        createCheckpoint(3, sharedStateRegistry)\n            };\n\n    for (TestCompletedCheckpoint checkpoint : expected) {\n        checkpoints.addCheckpointAndSubsumeOldestOne(\n                checkpoint, new CheckpointsCleaner(), () -> {});\n    }\n\n    checkpoints.shutdown(JobStatus.FINISHED, new CheckpointsCleaner());\n\n        \n    assertNull(checkpoints.getLatestCheckpoint());\n    assertEquals(0, checkpoints.getAllCheckpoints().size());\n    assertEquals(0, checkpoints.getNumberOfRetainedCheckpoints());\n\n        \n    for (TestCompletedCheckpoint checkpoint : expected) {\n            \n        checkpoint.awaitDiscard();\n        assertTrue(checkpoint.isDiscarded());\n    }\n}", "summary_tokens": ["tests", "that", "all", "checkpoints", "are", "discarded", "using", "the", "correct", "class", "loader"], "project": "flink"}
{"id": 6615, "code": "public void storeAndRetrieve() throws Exception {\n\n    final int chkCount = 3;\n\n    for (int i = 0; i < chkCount; ++i) {\n        Assert.assertNull(taskLocalStateStore.retrieveLocalState(i));\n    }\n\n    List<TestingTaskStateSnapshot> taskStateSnapshots = storeStates(chkCount);\n\n    checkStoredAsExpected(taskStateSnapshots, 0, chkCount);\n\n    Assert.assertNull(taskLocalStateStore.retrieveLocalState(chkCount + 1));\n}", "summary_tokens": ["tests", "basic", "store", "retrieve", "of", "local", "state"], "project": "flink"}
{"id": 8175, "code": "public static TypeInformation<Integer> INTERVAL_MONTHS() {\n    return TimeIntervalTypeInfo.INTERVAL_MONTHS;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "interval", "of", "months"], "project": "flink"}
{"id": 6622, "code": "public void testEmptyState() throws Exception {\n    final FileSystem fs = FileSystem.getLocalFileSystem();\n    final Path folder = baseFolder();\n    final String fileName = \"myFileName\";\n    final Path filePath = new Path(folder, fileName);\n\n    final FileStateHandle handle;\n    try (FSDataOutputStream stream = createTestStream(fs, folder, fileName)) {\n        handle = closeAndGetResult(stream);\n    }\n\n        \n    assertNotNull(handle);\n    assertEquals(filePath, handle.getFilePath());\n\n        \n    assertTrue(fs.exists(handle.getFilePath()));\n    assertFalse(fs.getFileStatus(filePath).isDir());\n\n        \n    try (FSDataInputStream in = handle.openInputStream()) {\n        assertEquals(-1, in.read());\n    }\n}", "summary_tokens": ["validates", "that", "even", "empty", "streams", "create", "a", "file", "and", "a", "file", "state", "handle"], "project": "flink"}
{"id": 3387, "code": "private void initialize(int bytes) {\n    int capacity = bytes / ELEMENT_LENGTH_IN_BYTES;\n\n    Preconditions.checkArgument(capacity > 0, \"Requested array with zero capacity\");\n    Preconditions.checkArgument(\n            capacity <= MAX_ARRAY_SIZE,\n            \"Requested capacity exceeds limit of \" + MAX_ARRAY_SIZE);\n\n    data = new double[capacity];\n}", "summary_tokens": ["initializes", "the", "array", "with", "the", "provided", "number", "of", "bytes"], "project": "flink"}
{"id": 3027, "code": "public void open(RuntimeContext cepRuntimeContext, Configuration conf) throws Exception {\n    for (State<T> state : getStates()) {\n        for (StateTransition<T> transition : state.getStateTransitions()) {\n            IterativeCondition condition = transition.getCondition();\n            FunctionUtils.setFunctionRuntimeContext(condition, cepRuntimeContext);\n            FunctionUtils.openFunction(condition, conf);\n        }\n    }\n}", "summary_tokens": ["initialization", "method", "for", "the", "nfa"], "project": "flink"}
{"id": 8860, "code": "private static void adjustTypeForMultisetConstructor(\n        RelDataType evenType, RelDataType oddType, SqlCallBinding sqlCallBinding) {\n    SqlCall call = sqlCallBinding.getCall();\n    List<RelDataType> operandTypes = sqlCallBinding.collectOperandTypes();\n    List<SqlNode> operands = call.getOperandList();\n    RelDataType elementType;\n    for (int i = 0; i < operands.size(); i++) {\n        if (i % 2 == 0) {\n            elementType = evenType;\n        } else {\n            elementType = oddType;\n        }\n        if (operandTypes.get(i).equalsSansFieldNames(elementType)) {\n            continue;\n        }\n        call.setOperand(i, castTo(operands.get(i), elementType));\n    }\n}", "summary_tokens": ["when", "the", "element", "element", "does", "not", "equal", "with", "the", "component", "type", "making", "explicit", "casting"], "project": "flink"}
{"id": 2536, "code": "public void testSerializePOJO_withValidParams_withoutCompression_succeeds() {\n    AWSSchemaRegistryConstants.COMPRESSION compressionType =\n            AWSSchemaRegistryConstants.COMPRESSION.NONE;\n    configs.put(AWSSchemaRegistryConstants.COMPRESSION_TYPE, compressionType.name());\n\n    GlueSchemaRegistryJsonSchemaCoder glueSchemaRegistryJsonSchemaCoder =\n            new GlueSchemaRegistryJsonSchemaCoder(\n                    testTopic, configs, mockSerializationFacade, null);\n\n    GlueSchemaRegistryJsonSerializationSchema glueSchemaRegistryJsonSerializationSchema =\n            new GlueSchemaRegistryJsonSerializationSchema<>(glueSchemaRegistryJsonSchemaCoder);\n\n    byte[] serializedData =\n            glueSchemaRegistryJsonSerializationSchema.serialize(userDefinedPojo);\n    assertThat(serializedData, equalTo(serializedBytes));\n}", "summary_tokens": ["test", "whether", "serialize", "method", "for", "specific", "type", "json", "schema", "data", "when", "compression", "is", "not", "enabled", "works"], "project": "flink"}
{"id": 6684, "code": "public static File createTemporaryLog4JProperties() throws IOException {\n    File log4jProps = File.createTempFile(FileUtils.getRandomFilename(\"\"), \"-log4j.properties\");\n    log4jProps.deleteOnExit();\n    CommonTestUtils.printLog4jDebugConfig(log4jProps);\n\n    return log4jProps;\n}", "summary_tokens": ["create", "a", "temporary", "log", "0", "j", "configuration", "for", "the", "test"], "project": "flink"}
{"id": 9222, "code": "public InternalTypeInfo<RowData> getUniqueKeyType() {\n    return uniqueKeyType;\n}", "summary_tokens": ["returns", "the", "type", "information", "of", "the", "unique", "key"], "project": "flink"}
{"id": 3871, "code": "public ExecutionConfig getExecutionConfig() {\n    return executionConfig;\n}", "summary_tokens": ["gets", "the", "execution", "config"], "project": "flink"}
{"id": 9521, "code": "public static SharedObjects create() {\n    return new SharedObjects(LAST_ID.getAndIncrement());\n}", "summary_tokens": ["creates", "a", "new", "instance"], "project": "flink"}
{"id": 6027, "code": "public void testNoResourceAvailableFailure() throws Exception {\n    JobVertex v1 = new JobVertex(\"source\");\n    JobVertex v2 = new JobVertex(\"sink\");\n\n    int dop1 = 2;\n    int dop2 = 2;\n\n    v1.setParallelism(dop1);\n    v2.setParallelism(dop2);\n\n    v1.setInvokableClass(BatchTask.class);\n    v2.setInvokableClass(BatchTask.class);\n\n    v2.connectNewDataSetAsInput(\n            v1, DistributionPattern.POINTWISE, ResultPartitionType.BLOCKING);\n\n    final JobGraph graph = JobGraphTestUtils.batchJobGraph(v1, v2);\n\n    DirectScheduledExecutorService directExecutor = new DirectScheduledExecutorService();\n\n        \n    final SchedulerBase scheduler =\n            SchedulerTestingUtils.newSchedulerBuilder(\n                            graph, ComponentMainThreadExecutorServiceAdapter.forMainThread())\n                    .setExecutionSlotAllocatorFactory(\n                            SchedulerTestingUtils.newSlotSharingExecutionSlotAllocatorFactory(\n                                    TestingPhysicalSlotProvider\n                                            .createWithLimitedAmountOfPhysicalSlots(1)))\n                    .setFutureExecutor(directExecutor)\n                    .setBlobWriter(blobWriter)\n                    .build();\n\n    final ExecutionGraph eg = scheduler.getExecutionGraph();\n\n    checkJobOffloaded((DefaultExecutionGraph) eg);\n\n        \n    scheduler.startScheduling();\n\n    ExecutionAttemptID attemptID =\n            eg.getJobVertex(v1.getID())\n                    .getTaskVertices()[0]\n                    .getCurrentExecutionAttempt()\n                    .getAttemptId();\n    scheduler.updateTaskExecutionState(\n            new TaskExecutionState(attemptID, ExecutionState.RUNNING));\n    scheduler.updateTaskExecutionState(\n            new TaskExecutionState(attemptID, ExecutionState.FINISHED, null));\n\n    assertEquals(JobStatus.FAILED, eg.getState());\n}", "summary_tokens": ["tests", "that", "a", "blocking", "batch", "job", "fails", "if", "there", "are", "not", "enough", "resources", "left", "to", "schedule", "the", "succeeding", "tasks"], "project": "flink"}
{"id": 4170, "code": "void handleJobLevelCheckpointException(\n        CheckpointProperties checkpointProperties,\n        CheckpointException exception,\n        long checkpointId) {\n    if (!checkpointProperties.isSavepoint()) {\n        checkFailureAgainstCounter(exception, checkpointId, failureCallback::failJob);\n    }\n}", "summary_tokens": ["handle", "job", "level", "checkpoint", "exception", "with", "a", "handler", "callback"], "project": "flink"}
{"id": 917, "code": "public void seekPosition(Consumer<?> consumer) throws PulsarClientException {\n    if (type == Type.MESSAGE_ID) {\n        consumer.seek(messageId);\n    } else {\n        if (timestamp != null) {\n            consumer.seek(timestamp);\n        } else {\n            consumer.seek(System.currentTimeMillis());\n        }\n    }\n}", "summary_tokens": ["pulsar", "consumer", "could", "be", "subscribed", "by", "the", "position"], "project": "flink"}
{"id": 663, "code": "public void testDisableFilterRestoredParitionsNoChange() throws Exception {\n    checkFilterRestoredPartitionsWithDisovered(\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            true);\n}", "summary_tokens": ["tests", "that", "subscribed", "partitions", "are", "the", "same", "when", "there", "s", "no", "change", "on", "the", "initial", "topics"], "project": "flink"}
{"id": 8270, "code": "static SourceProvider of(Source<RowData, ?, ?> source) {\n    return new SourceProvider() {\n        @Override\n        public Source<RowData, ?, ?> createSource() {\n            return source;\n        }\n\n        @Override\n        public boolean isBounded() {\n            return Boundedness.BOUNDED.equals(source.getBoundedness());\n        }\n    };\n}", "summary_tokens": ["helper", "method", "for", "creating", "a", "static", "provider"], "project": "flink"}
{"id": 6375, "code": "public void testResettableIterator() {\n    try {\n            \n        SpillingResettableIterator<IntValue> iterator =\n                new SpillingResettableIterator<IntValue>(\n                        this.reader,\n                        this.serializer,\n                        this.memman,\n                        this.ioman,\n                        2,\n                        this.memOwner);\n            \n        iterator.open();\n\n            \n        int count = 0;\n        while (iterator.hasNext()) {\n            Assert.assertEquals(\n                    \"In initial run, element \" + count + \" does not match expected value!\",\n                    count++,\n                    iterator.next().getValue());\n        }\n        Assert.assertEquals(\n                \"Too few elements were deserialzied in initial run!\", NUM_TESTRECORDS, count);\n            \n        for (int j = 0; j < 10; ++j) {\n            count = 0;\n            iterator.reset();\n                \n            while (iterator.hasNext()) {\n                Assert.assertEquals(\n                        \"After reset nr. \"\n                                + j\n                                + 1\n                                + \" element \"\n                                + count\n                                + \" does not match expected value!\",\n                        count++,\n                        iterator.next().getValue());\n            }\n            Assert.assertEquals(\n                    \"Too few elements were deserialzied after reset nr. \" + j + 1 + \"!\",\n                    NUM_TESTRECORDS,\n                    count);\n        }\n            \n        iterator.close();\n    } catch (Exception ex) {\n        ex.printStackTrace();\n        Assert.fail(\"Test encountered an exception.\");\n    }\n}", "summary_tokens": ["tests", "the", "resettable", "iterator", "with", "too", "few", "memory", "so", "that", "the", "data", "has", "to", "be", "written", "to", "disk"], "project": "flink"}
{"id": 7661, "code": "public void testSetAndFireEventTimeTimers() throws Exception {\n    @SuppressWarnings(\"unchecked\")\n    Triggerable<Integer, String> mockTriggerable = mock(Triggerable.class);\n\n    TestKeyContext keyContext = new TestKeyContext();\n    TestProcessingTimeService processingTimeService = new TestProcessingTimeService();\n    InternalTimerServiceImpl<Integer, String> timerService =\n            createAndStartInternalTimerService(\n                    mockTriggerable,\n                    keyContext,\n                    processingTimeService,\n                    testKeyGroupRange,\n                    createQueueFactory());\n\n        \n    int key1 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    int key2 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    while (key2 == key1) {\n        key2 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    }\n\n    keyContext.setCurrentKey(key1);\n\n    timerService.registerEventTimeTimer(\"ciao\", 10);\n    timerService.registerEventTimeTimer(\"hello\", 10);\n\n    keyContext.setCurrentKey(key2);\n\n    timerService.registerEventTimeTimer(\"ciao\", 10);\n    timerService.registerEventTimeTimer(\"hello\", 10);\n\n    assertEquals(4, timerService.numEventTimeTimers());\n    assertEquals(2, timerService.numEventTimeTimers(\"hello\"));\n    assertEquals(2, timerService.numEventTimeTimers(\"ciao\"));\n\n    timerService.advanceWatermark(10);\n\n    verify(mockTriggerable, times(4)).onEventTime(anyInternalTimer());\n    verify(mockTriggerable, times(1))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key1, \"ciao\")));\n    verify(mockTriggerable, times(1))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key1, \"hello\")));\n    verify(mockTriggerable, times(1))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key2, \"ciao\")));\n    verify(mockTriggerable, times(1))\n            .onEventTime(eq(new TimerHeapInternalTimer<>(10, key2, \"hello\")));\n\n    assertEquals(0, timerService.numEventTimeTimers());\n}", "summary_tokens": ["this", "also", "verifies", "that", "we", "don", "t", "have", "leakage", "between", "keys", "namespaces"], "project": "flink"}
{"id": 1046, "code": "public long getTaskCancellationInterval() {\n    return this.taskCancellationIntervalMillis;\n}", "summary_tokens": ["gets", "the", "interval", "in", "milliseconds", "between", "consecutive", "attempts", "to", "cancel", "a", "running", "task"], "project": "flink"}
{"id": 7126, "code": "public SingleOutputStreamOperator<T> setUidHash(String uidHash) {\n    transformation.setUidHash(uidHash);\n    return this;\n}", "summary_tokens": ["sets", "an", "user", "provided", "hash", "for", "this", "operator"], "project": "flink"}
{"id": 1428, "code": "public String getDescription() {\n    return description;\n}", "summary_tokens": ["returns", "the", "description", "of", "this", "transformation"], "project": "flink"}
{"id": 3024, "code": "public DeweyNumber addStage() {\n    int[] newDeweyNumber = Arrays.copyOf(deweyNumber, deweyNumber.length + 1);\n\n    return new DeweyNumber(newDeweyNumber);\n}", "summary_tokens": ["creates", "a", "new", "dewey", "number", "from", "this", "such", "that", "a", "0", "is", "appended", "as", "new", "last", "digit"], "project": "flink"}
{"id": 5182, "code": "public Map<String, String> getResponseHeaders() {\n    return responseHeaders;\n}", "summary_tokens": ["response", "headers", "that", "should", "be", "added", "to", "every", "http", "response"], "project": "flink"}
{"id": 8867, "code": "public Map<String, String> mergeOptions(\n        MergingStrategy mergingStrategy,\n        Map<String, String> sourceOptions,\n        Map<String, String> derivedOptions) {\n    Map<String, String> options = new HashMap<>();\n    if (mergingStrategy != MergingStrategy.EXCLUDING) {\n        options.putAll(sourceOptions);\n    }\n\n    derivedOptions.forEach(\n            (key, value) -> {\n                if (mergingStrategy != MergingStrategy.OVERWRITING\n                        && options.containsKey(key)) {\n                    throw new ValidationException(\n                            String.format(\n                                    \"There already exists an option ['%s' -> '%s']  in the \"\n                                            + \"base table. You might want to specify EXCLUDING OPTIONS or OVERWRITING OPTIONS.\",\n                                    key, options.get(key)));\n                }\n\n                options.put(key, value);\n            });\n    return options;\n}", "summary_tokens": ["merges", "the", "options", "part", "of", "create", "table", "statement"], "project": "flink"}
{"id": 6337, "code": "public void testUserDefinedVariable() {\n    MetricRegistry registry = NoOpMetricRegistry.INSTANCE;\n    GenericMetricGroup root =\n            new GenericMetricGroup(registry, new DummyAbstractMetricGroup(registry), \"root\");\n\n    String key = \"key\";\n    String value = \"value\";\n    MetricGroup group = root.addGroup(key, value);\n\n    String variableValue = group.getAllVariables().get(ScopeFormat.asVariable(\"key\"));\n    assertEquals(value, variableValue);\n\n    String identifier = group.getMetricIdentifier(\"metric\");\n    assertTrue(\"Key is missing from metric identifier.\", identifier.contains(\"key\"));\n    assertTrue(\"Value is missing from metric identifier.\", identifier.contains(\"value\"));\n\n    String logicalScope =\n            ((AbstractMetricGroup) group).getLogicalScope(new DummyCharacterFilter());\n    assertTrue(\"Key is missing from logical scope.\", logicalScope.contains(key));\n    assertFalse(\"Value is present in logical scope.\", logicalScope.contains(value));\n}", "summary_tokens": ["verifies", "the", "basic", "behavior", "when", "defining", "user", "defined", "variables"], "project": "flink"}
{"id": 874, "code": "public static KinesisProxyInterface aggregatedRecords(\n        final int numOfAggregatedRecords,\n        final int numOfChildRecords,\n        final int numOfGetRecordsCalls) {\n    return new SingleShardEmittingAggregatedRecordsKinesis(\n            numOfAggregatedRecords, numOfChildRecords, numOfGetRecordsCalls);\n}", "summary_tokens": ["creates", "a", "mocked", "kinesis", "proxy", "that", "will", "emit", "aggregated", "records", "from", "a", "fake", "stream", "there", "will", "be", "num", "of", "get", "records", "calls", "batches", "available", "in", "the", "stream", "each", "batch", "will", "contain", "num", "of", "aggregated", "records", "aggregated", "records", "each", "aggregated", "record", "will", "contain", "num", "of", "child", "records", "child", "records", "therefore", "this", "class", "will", "emit", "a", "total", "of", "num", "of", "get", "records", "calls", "num", "of", "aggregated", "records", "num", "of", "child", "records", "records"], "project": "flink"}
{"id": 4556, "code": "public boolean isDataAvailable() {\n    return currentReaderPosition < writerPosition.getLatest();\n}", "summary_tokens": ["returns", "true", "if", "there", "is", "new", "data", "available", "for", "reading"], "project": "flink"}
{"id": 331, "code": "private void updateStats(CatalogTableStatistics newTableStats, Map<String, String> parameters) {\n    parameters.put(StatsSetupConst.ROW_COUNT, String.valueOf(newTableStats.getRowCount()));\n    parameters.put(StatsSetupConst.TOTAL_SIZE, String.valueOf(newTableStats.getTotalSize()));\n    parameters.put(StatsSetupConst.NUM_FILES, String.valueOf(newTableStats.getFileCount()));\n    parameters.put(\n            StatsSetupConst.RAW_DATA_SIZE, String.valueOf(newTableStats.getRawDataSize()));\n}", "summary_tokens": ["update", "original", "table", "statistics", "parameters"], "project": "flink"}
{"id": 8949, "code": "protected OverWindowMode inferGroupMode(GroupSpec group) {\n    AggregateCall aggCall = group.getAggCalls().get(0);\n    if (aggCall.getAggregation().allowsFraming()) {\n        if (group.isRows()) {\n            return OverWindowMode.ROW;\n        } else {\n            return OverWindowMode.RANGE;\n        }\n    } else {\n        if (aggCall.getAggregation() instanceof SqlLeadLagAggFunction) {\n            return OverWindowMode.OFFSET;\n        } else {\n            return OverWindowMode.INSENSITIVE;\n        }\n    }\n}", "summary_tokens": ["infer", "the", "over", "window", "mode", "based", "on", "given", "group", "info"], "project": "flink"}
{"id": 6668, "code": "public void testThrowExceptionIfNumSamplesIsNegative() {\n    try {\n        threadInfoSampleService.requestThreadInfoSamples(\n                new TestTask(),\n                new ThreadInfoSamplesRequest(\n                        1, -1, DELAY_BETWEEN_SAMPLES, MAX_STACK_TRACK_DEPTH));\n        fail(\"Expected exception not thrown\");\n    } catch (final IllegalArgumentException e) {\n        assertThat(e.getMessage(), is(equalTo(\"numSamples must be positive\")));\n    }\n}", "summary_tokens": ["test", "that", "negative", "num", "samples", "parameter", "is", "handled"], "project": "flink"}
{"id": 8364, "code": "public int indexOf(BinaryStringData str, int fromIndex) {\n    ensureMaterialized();\n    str.ensureMaterialized();\n    if (str.binarySection.sizeInBytes == 0) {\n        return 0;\n    }\n    if (inFirstSegment()) {\n            \n        int byteIdx = 0;\n            \n        int charIdx = 0;\n        while (byteIdx < binarySection.sizeInBytes && charIdx < fromIndex) {\n            byteIdx += numBytesForFirstByte(getByteOneSegment(byteIdx));\n            charIdx++;\n        }\n        do {\n            if (byteIdx + str.binarySection.sizeInBytes > binarySection.sizeInBytes) {\n                return -1;\n            }\n            if (BinarySegmentUtils.equals(\n                    binarySection.segments,\n                    binarySection.offset + byteIdx,\n                    str.binarySection.segments,\n                    str.binarySection.offset,\n                    str.binarySection.sizeInBytes)) {\n                return charIdx;\n            }\n            byteIdx += numBytesForFirstByte(getByteOneSegment(byteIdx));\n            charIdx++;\n        } while (byteIdx < binarySection.sizeInBytes);\n\n        return -1;\n    } else {\n        return indexOfMultiSegs(str, fromIndex);\n    }\n}", "summary_tokens": ["returns", "the", "index", "within", "this", "string", "of", "the", "first", "occurrence", "of", "the", "specified", "substring", "starting", "at", "the", "specified", "index"], "project": "flink"}
{"id": 4851, "code": "public void allocatePages(Object owner, Collection<MemorySegment> target, int numberOfPages)\n        throws MemoryAllocationException {\n        \n    Preconditions.checkNotNull(owner, \"The memory owner must not be null.\");\n    Preconditions.checkState(!isShutDown, \"Memory manager has been shut down.\");\n    Preconditions.checkArgument(\n            numberOfPages <= totalNumberOfPages,\n            \"Cannot allocate more segments %s than the max number %s\",\n            numberOfPages,\n            totalNumberOfPages);\n\n        \n    if (target instanceof ArrayList) {\n        ((ArrayList<MemorySegment>) target).ensureCapacity(numberOfPages);\n    }\n\n    long memoryToReserve = numberOfPages * pageSize;\n    try {\n        memoryBudget.reserveMemory(memoryToReserve);\n    } catch (MemoryReservationException e) {\n        throw new MemoryAllocationException(\n                String.format(\"Could not allocate %d pages\", numberOfPages), e);\n    }\n\n    Runnable pageCleanup = this::releasePage;\n    allocatedSegments.compute(\n            owner,\n            (o, currentSegmentsForOwner) -> {\n                Set<MemorySegment> segmentsForOwner =\n                        currentSegmentsForOwner == null\n                                ? new HashSet<>(numberOfPages)\n                                : currentSegmentsForOwner;\n                for (long i = numberOfPages; i > 0; i--) {\n                    MemorySegment segment =\n                            allocateOffHeapUnsafeMemory(getPageSize(), owner, pageCleanup);\n                    target.add(segment);\n                    segmentsForOwner.add(segment);\n                }\n                return segmentsForOwner;\n            });\n\n    Preconditions.checkState(!isShutDown, \"Memory manager has been concurrently shut down.\");\n}", "summary_tokens": ["allocates", "a", "set", "of", "memory", "segments", "from", "this", "memory", "manager"], "project": "flink"}
{"id": 3405, "code": "public GraphAlgorithmWrappingBase<K, VV, EV, R> setParallelism(int parallelism) {\n    Preconditions.checkArgument(\n            parallelism > 0 || parallelism == PARALLELISM_DEFAULT,\n            \"The parallelism must be at least one, or ExecutionConfig.PARALLELISM_DEFAULT (use system default).\");\n\n    this.parallelism = parallelism;\n\n    return this;\n}", "summary_tokens": ["set", "the", "parallelism", "for", "this", "algorithm", "s", "operators"], "project": "flink"}
{"id": 2412, "code": "private static boolean waitUntilLeaseIsRevoked(final FileSystem fs, final Path path)\n        throws IOException {\n    Preconditions.checkState(fs instanceof DistributedFileSystem);\n\n    final DistributedFileSystem dfs = (DistributedFileSystem) fs;\n    dfs.recoverLease(path);\n\n    final Deadline deadline = Deadline.now().plus(Duration.ofMillis(LEASE_TIMEOUT));\n\n    boolean isClosed = dfs.isFileClosed(path);\n    while (!isClosed && deadline.hasTimeLeft()) {\n        try {\n            Thread.sleep(500L);\n        } catch (InterruptedException e1) {\n            throw new IOException(\"Recovering the lease failed: \", e1);\n        }\n        isClosed = dfs.isFileClosed(path);\n    }\n    return isClosed;\n}", "summary_tokens": ["called", "when", "resuming", "execution", "after", "a", "failure", "and", "waits", "until", "the", "lease", "of", "the", "file", "we", "are", "resuming", "is", "free"], "project": "flink"}
{"id": 3213, "code": "public <K, EV> Graph<K, NullValue, EV> edgeTypes(Class<K> vertexKey, Class<EV> edgeValue) {\n\n    if (edgeReader == null) {\n        throw new RuntimeException(\"The edge input file cannot be null!\");\n    }\n\n    DataSet<Tuple3<K, K, EV>> edges =\n            edgeReader\n                    .types(vertexKey, vertexKey, edgeValue)\n                    .name(GraphCsvReader.class.getName());\n\n    return Graph.fromTupleDataSet(edges, executionContext);\n}", "summary_tokens": ["creates", "a", "graph", "from", "csv", "input", "with", "edge", "values", "but", "without", "vertex", "values"], "project": "flink"}
{"id": 4298, "code": "public long getProcessedData() {\n    return processedData;\n}", "summary_tokens": ["the", "total", "number", "of", "processed", "bytes", "during", "the", "checkpoint"], "project": "flink"}
{"id": 947, "code": "public Delivery nextDelivery(long timeout, TimeUnit unit)\n        throws InterruptedException, ShutdownSignalException, ConsumerCancelledException {\n    return handle(queue.poll(timeout, unit));\n}", "summary_tokens": ["main", "application", "side", "api", "wait", "for", "the", "next", "message", "delivery", "and", "return", "it"], "project": "flink"}
{"id": 2446, "code": "public static <T extends SpecificRecord>\n        GlueSchemaRegistryAvroDeserializationSchema<T> forSpecific(\n                Class<T> clazz, Map<String, Object> configs) {\n    return new GlueSchemaRegistryAvroDeserializationSchema<>(\n            clazz, null, new GlueSchemaRegistryAvroSchemaCoderProvider(configs));\n}", "summary_tokens": ["creates", "glue", "schema", "registry", "avro", "deserialization", "schema", "that", "produces", "classes", "that", "were", "generated", "from", "avro", "schema"], "project": "flink"}
{"id": 8730, "code": "private CaseBranch generateBranch(\n        boolean simplifyCond, RexSimplify simplifier, CaseBranch branch) {\n    if (simplifyCond) {\n            \n            \n        return new CaseBranch(\n                simplifier.simplify(branch.cond, RexUnknownAs.FALSE), branch.value);\n    }\n    return branch;\n}", "summary_tokens": ["if", "boolean", "is", "true", "simplify", "cond", "in", "input", "branch", "and", "return", "new", "branch"], "project": "flink"}
{"id": 7807, "code": "public void writeSessionWindowsWithCountTriggerSnapshot() throws Exception {\n    final int sessionSize = 3;\n\n    ListStateDescriptor<Tuple2<String, Integer>> stateDesc =\n            new ListStateDescriptor<>(\n                    \"window-contents\",\n                    STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n    WindowOperator<\n                    String,\n                    Tuple2<String, Integer>,\n                    Iterable<Tuple2<String, Integer>>,\n                    Tuple3<String, Long, Long>,\n                    TimeWindow>\n            operator =\n                    new WindowOperator<>(\n                            EventTimeSessionWindows.withGap(Time.seconds(sessionSize)),\n                            new TimeWindow.Serializer(),\n                            new TupleKeySelector<String>(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()),\n                            stateDesc,\n                            new InternalIterableWindowFunction<>(new SessionWindowFunction()),\n                            PurgingTrigger.of(CountTrigger.of(4)),\n                            0,\n                            null );\n\n    OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple3<String, Long, Long>>\n            testHarness =\n                    new KeyedOneInputStreamOperatorTestHarness<>(\n                            operator, new TupleKeySelector<>(), BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n        \n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 0));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 2), 1000));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 3), 2500));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), 3500));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 10));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 2), 1000));\n\n        \n    OperatorSubtaskState snapshot = testHarness.snapshot(0L, 0L);\n\n    OperatorSnapshotUtil.writeStateHandle(\n            snapshot,\n            \"src/test/resources/win-op-migration-test-session-with-stateful-trigger-flink\"\n                    + flinkGenerateSavepointVersion\n                    + \"-snapshot\");\n\n    testHarness.close();\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 910, "code": "private void checkPartitionChanges(Set<TopicPartition> fetchedPartitions, Throwable throwable) {\n    if (throwable != null) {\n        throw new FlinkRuntimeException(\n                \"Failed to list subscribed topic partitions due to \", throwable);\n    }\n\n        \n    assignmentState.appendTopicPartitions(fetchedPartitions);\n    List<Integer> registeredReaders = new ArrayList<>(context.registeredReaders().keySet());\n\n        \n    assignPendingPartitionSplits(registeredReaders);\n}", "summary_tokens": ["check", "if", "there", "s", "any", "partition", "changes", "within", "subscribed", "topic", "partitions", "fetched", "by", "worker", "thread", "and", "convert", "them", "to", "splits", "the", "assign", "them", "to", "pulsar", "readers"], "project": "flink"}
{"id": 4238, "code": "default void close() throws Exception {}", "summary_tokens": ["tear", "down", "method", "for", "the", "hook"], "project": "flink"}
{"id": 4511, "code": "public int getBlockCount() {\n    return this.blockCount;\n}", "summary_tokens": ["gets", "the", "number", "of", "blocks", "used", "by", "this", "view"], "project": "flink"}
{"id": 7488, "code": "public boolean hasNext() {\n    if (next == null) {\n        try {\n            next = readNextFromStream();\n        } catch (Exception e) {\n            throw new RuntimeException(\"Failed to receive next element: \" + e.getMessage(), e);\n        }\n    }\n\n    return next != null;\n}", "summary_tokens": ["returns", "true", "if", "the", "data", "stream", "has", "more", "elements"], "project": "flink"}
{"id": 7209, "code": "public void setCheckpointStorage(Path checkpointDirectory) {\n    Preconditions.checkNotNull(checkpointDirectory, \"Checkpoint directory must not be null\");\n    this.storage = new FileSystemCheckpointStorage(checkpointDirectory);\n}", "summary_tokens": ["configures", "the", "application", "to", "write", "out", "checkpoint", "snapshots", "to", "the", "configured", "directory"], "project": "flink"}
{"id": 6585, "code": "public void testListStateAddAllNullEntries() throws Exception {\n    final ListStateDescriptor<Long> stateDescr =\n            new ListStateDescriptor<>(\"my-state\", Long.class);\n\n    CheckpointableKeyedStateBackend<String> keyedBackend =\n            createKeyedBackend(StringSerializer.INSTANCE);\n    try {\n        ListState<Long> state =\n                keyedBackend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, stateDescr);\n\n        keyedBackend.setCurrentKey(\"abc\");\n        assertNull(state.get());\n\n        expectedException.expect(NullPointerException.class);\n\n        List<Long> adding = new ArrayList<>();\n        adding.add(3L);\n        adding.add(null);\n        adding.add(5L);\n        state.addAll(adding);\n    } finally {\n        IOUtils.closeQuietly(keyedBackend);\n        keyedBackend.dispose();\n    }\n}", "summary_tokens": ["this", "test", "verifies", "that", "all", "list", "state", "implementations", "are", "consistent", "in", "not", "allowing", "list", "state", "add", "all", "list", "to", "be", "called", "with", "null", "entries", "in", "the", "list", "of", "entries", "to", "add"], "project": "flink"}
{"id": 5377, "code": "public static int assignKeyToParallelOperator(Object key, int maxParallelism, int parallelism) {\n    Preconditions.checkNotNull(key, \"Assigned key must not be null!\");\n    return computeOperatorIndexForKeyGroup(\n            maxParallelism, parallelism, assignToKeyGroup(key, maxParallelism));\n}", "summary_tokens": ["assigns", "the", "given", "key", "to", "a", "parallel", "operator", "index"], "project": "flink"}
{"id": 3849, "code": "public int getCount() {\n    return count;\n}", "summary_tokens": ["returns", "the", "current", "count", "of", "elements", "written"], "project": "flink"}
{"id": 7547, "code": "public final <E> StreamRecord<E> asRecord() {\n    return (StreamRecord<E>) this;\n}", "summary_tokens": ["casts", "this", "element", "into", "a", "stream", "record"], "project": "flink"}
{"id": 3177, "code": "public <T> Graph<K, VV, EV> joinWithEdgesOnTarget(\n        DataSet<Tuple2<K, T>> inputDataSet, final EdgeJoinFunction<EV, T> edgeJoinFunction) {\n\n    DataSet<Edge<K, EV>> resultedEdges =\n            this.getEdges()\n                    .coGroup(inputDataSet)\n                    .where(1)\n                    .equalTo(0)\n                    .with(\n                            new ApplyCoGroupToEdgeValuesOnEitherSourceOrTarget<>(\n                                    edgeJoinFunction))\n                    .name(\"Join with edges on target\");\n\n    return new Graph<>(this.vertices, resultedEdges, this.context);\n}", "summary_tokens": ["joins", "the", "edge", "data", "set", "with", "an", "input", "tuple", "0", "data", "set", "and", "applies", "a", "user", "defined", "transformation", "on", "the", "values", "of", "the", "matched", "records"], "project": "flink"}
{"id": 3627, "code": "public void addOutgoingConnection(DagConnection connection) {\n    if (this.outgoingConnections == null) {\n        this.outgoingConnections = new ArrayList<DagConnection>();\n    } else {\n        if (this.outgoingConnections.size() == 64) {\n            throw new CompilerException(\n                    \"Cannot currently handle nodes with more than 64 outputs.\");\n        }\n    }\n\n    this.outgoingConnections.add(connection);\n}", "summary_tokens": ["adds", "a", "new", "outgoing", "connection", "to", "this", "node"], "project": "flink"}
{"id": 2228, "code": "public void testRetryFailure() throws Throwable {\n    new FixedRetryStrategy(0, Duration.ofMillis(5L)).getNextRetryStrategy();\n}", "summary_tokens": ["tests", "that", "getting", "a", "next", "retry", "strategy", "below", "zero", "remaining", "retries", "fails"], "project": "flink"}
{"id": 7220, "code": "public StreamExecutionEnvironment setParallelism(int parallelism) {\n    config.setParallelism(parallelism);\n    return this;\n}", "summary_tokens": ["sets", "the", "parallelism", "for", "operations", "executed", "through", "this", "environment"], "project": "flink"}
{"id": 8070, "code": "public void dropTable(ObjectIdentifier objectIdentifier, boolean ignoreIfNotExists) {\n    dropTableInternal(objectIdentifier, ignoreIfNotExists, true);\n}", "summary_tokens": ["drops", "a", "table", "in", "a", "given", "fully", "qualified", "path"], "project": "flink"}
{"id": 8803, "code": "Frame register(\n        RelNode rel,\n        RelNode newRel,\n        Map<Integer, Integer> oldToNewOutputs,\n        SortedMap<CorDef, Integer> corDefOutputs) {\n    final Frame frame = new Frame(rel, newRel, corDefOutputs, oldToNewOutputs);\n    map.put(rel, frame);\n    return frame;\n}", "summary_tokens": ["registers", "a", "relational", "expression", "and", "the", "relational", "expression", "it", "became", "after", "decorrelation"], "project": "flink"}
{"id": 3715, "code": "public DriverStrategy getDriverStrategy() {\n    return this.driverStrategy;\n}", "summary_tokens": ["gets", "the", "driver", "strategy", "from", "this", "node"], "project": "flink"}
{"id": 9303, "code": "public boolean hasTriggerWindow() {\n    skipEmptyWindow();\n    Preconditions.checkState(\n            watermark == Long.MIN_VALUE || nextWindow != null,\n            \"next trigger window cannot be null.\");\n    return nextWindow != null && nextWindow.getEnd() <= watermark;\n}", "summary_tokens": ["check", "if", "there", "are", "windows", "could", "be", "triggered", "according", "to", "the", "current", "watermark"], "project": "flink"}
{"id": 6070, "code": "public void testRegionFailoverForRegionInternalErrors() {\n    final TestingSchedulingTopology topology = new TestingSchedulingTopology();\n\n    TestingSchedulingExecutionVertex v1 = topology.newExecutionVertex(ExecutionState.FINISHED);\n    TestingSchedulingExecutionVertex v2 = topology.newExecutionVertex(ExecutionState.FINISHED);\n    TestingSchedulingExecutionVertex v3 = topology.newExecutionVertex(ExecutionState.FINISHED);\n    TestingSchedulingExecutionVertex v4 = topology.newExecutionVertex(ExecutionState.FINISHED);\n    TestingSchedulingExecutionVertex v5 = topology.newExecutionVertex(ExecutionState.SCHEDULED);\n    TestingSchedulingExecutionVertex v6 = topology.newExecutionVertex(ExecutionState.RUNNING);\n\n    topology.connect(v1, v4, ResultPartitionType.BLOCKING);\n    topology.connect(v1, v5, ResultPartitionType.BLOCKING);\n    topology.connect(v2, v4, ResultPartitionType.BLOCKING);\n    topology.connect(v2, v5, ResultPartitionType.BLOCKING);\n    topology.connect(v3, v6, ResultPartitionType.BLOCKING);\n\n    RestartPipelinedRegionFailoverStrategy strategy =\n            new RestartPipelinedRegionFailoverStrategy(topology);\n\n    verifyThatFailedExecution(strategy, v1).restarts(v1, v4, v5);\n    verifyThatFailedExecution(strategy, v2).restarts(v2, v4, v5);\n    verifyThatFailedExecution(strategy, v3).restarts(v3, v6);\n    verifyThatFailedExecution(strategy, v4).restarts(v4);\n    verifyThatFailedExecution(strategy, v5).restarts(v5);\n    verifyThatFailedExecution(strategy, v6).restarts(v6);\n}", "summary_tokens": ["tests", "for", "scenes", "that", "a", "task", "fails", "for", "its", "own", "error", "in", "which", "case", "the", "region", "containing", "the", "failed", "task", "and", "its", "consumer", "regions", "should", "be", "restarted"], "project": "flink"}
{"id": 7952, "code": "public SqlNode getTargetTableID() {\n    return targetTableID;\n}", "summary_tokens": ["returns", "the", "target", "table", "identifier"], "project": "flink"}
{"id": 5808, "code": "public void testSSLServerFailure() throws Exception {\n        \n    uploadJarFile(blobSslServer, clientConfig);\n}", "summary_tokens": ["verify", "non", "ssl", "client", "to", "ssl", "server", "failure"], "project": "flink"}
{"id": 1836, "code": "public static <L, R> Either<L, R> Left(L value) {\n    return new Left<L, R>(value);\n}", "summary_tokens": ["create", "a", "left", "value", "of", "either"], "project": "flink"}
{"id": 2028, "code": "public static boolean isValidClientPort(int port) {\n    return 1 <= port && port <= 65535;\n}", "summary_tokens": ["check", "whether", "the", "given", "port", "is", "in", "right", "range", "when", "connecting", "to", "somewhere"], "project": "flink"}
{"id": 1234, "code": "public void setStatisticsKey(String statisticsKey) {\n    this.statisticsKey = statisticsKey;\n}", "summary_tokens": ["sets", "the", "key", "under", "which", "statistics", "about", "this", "data", "source", "may", "be", "obtained", "from", "the", "statistics", "cache"], "project": "flink"}
{"id": 650, "code": "public static List<ProducerRecord<String, Integer>> getRecordsForPartitionWithoutTimestamp(\n        TopicPartition tp) {\n    List<ProducerRecord<String, Integer>> records = new ArrayList<>();\n    for (int i = 0; i < NUM_RECORDS_PER_PARTITION; i++) {\n        records.add(new ProducerRecord<>(tp.topic(), tp.partition(), null, tp.toString(), i));\n    }\n    return records;\n}", "summary_tokens": ["for", "a", "given", "partition", "topic", "partition", "the", "i", "th", "records", "looks", "like", "following"], "project": "flink"}
{"id": 4557, "code": "public Buffer decompressToIntermediateBuffer(Buffer buffer) {\n    int decompressedLen = decompress(buffer);\n    internalBuffer.setSize(decompressedLen);\n\n    return internalBuffer.retainBuffer();\n}", "summary_tokens": ["decompresses", "the", "given", "buffer", "using", "block", "decompressor"], "project": "flink"}
{"id": 3384, "code": "private void ensureCapacity(int minCapacity) {\n    long currentCapacity = data.length;\n\n    if (minCapacity <= currentCapacity) {\n        return;\n    }\n\n        \n    long expandedCapacity = Math.max(minCapacity, currentCapacity + (currentCapacity >> 1));\n    int newCapacity = (int) Math.min(MAX_ARRAY_SIZE, expandedCapacity);\n\n    if (newCapacity < minCapacity) {\n            \n        throw new RuntimeException(\n                \"Requested array size \" + minCapacity + \" exceeds limit of \" + MAX_ARRAY_SIZE);\n    }\n\n    data = Arrays.copyOf(data, newCapacity);\n}", "summary_tokens": ["if", "the", "size", "of", "the", "array", "is", "insufficient", "to", "hold", "the", "given", "capacity", "then", "copy", "the", "array", "into", "a", "new", "larger", "array"], "project": "flink"}
{"id": 7933, "code": "private void executeInteractive() {\n    isRunning = true;\n    LineReader lineReader = createLineReader(terminal);\n\n        \n    terminal.writer().println();\n    terminal.writer().flush();\n\n        \n    terminal.writer().append(CliStrings.MESSAGE_WELCOME);\n\n        \n    while (isRunning) {\n            \n        terminal.writer().append(\"\\n\");\n        terminal.flush();\n\n        String line;\n        try {\n            line = lineReader.readLine(prompt, null, inputTransformer, null);\n        } catch (UserInterruptException e) {\n                \n            continue;\n        } catch (EndOfFileException | IOError e) {\n                \n            break;\n        } catch (Throwable t) {\n            throw new SqlClientException(\"Could not read from command line.\", t);\n        }\n        if (line == null) {\n            continue;\n        }\n\n        executeStatement(line, ExecutionMode.INTERACTIVE_EXECUTION);\n    }\n}", "summary_tokens": ["execute", "statement", "from", "the", "user", "input", "and", "prints", "status", "information", "and", "or", "errors", "on", "the", "terminal"], "project": "flink"}
{"id": 7941, "code": "public <R> R wrapClassLoader(Supplier<R> supplier) {\n    try (TemporaryClassLoaderContext ignored = TemporaryClassLoaderContext.of(classLoader)) {\n        return supplier.get();\n    }\n}", "summary_tokens": ["executes", "the", "given", "supplier", "using", "the", "execution", "context", "s", "classloader", "as", "thread", "classloader"], "project": "flink"}
{"id": 4152, "code": "private boolean deleteFile(JobID jobId, BlobKey blobKey) {\n    final File localFile =\n            new File(\n                    BlobUtils.getStorageLocationPath(\n                            storageDir.getAbsolutePath(), jobId, blobKey));\n    if (!localFile.delete() && localFile.exists()) {\n        log.warn(\n                \"Failed to delete locally cached BLOB {} at {}\",\n                blobKey,\n                localFile.getAbsolutePath());\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["delete", "the", "blob", "file", "with", "the", "given", "key"], "project": "flink"}
{"id": 6786, "code": "public static long getValuePointer(MemorySegment memorySegment, int offset) {\n    return memorySegment.getLong(offset + VALUE_POINTER_OFFSET);\n}", "summary_tokens": ["returns", "the", "value", "pointer"], "project": "flink"}
{"id": 6260, "code": "public void waitForNotification(int current) throws InterruptedException {\n    synchronized (numberOfNotifications) {\n        while (current == numberOfNotifications.get()) {\n            numberOfNotifications.wait();\n        }\n    }\n}", "summary_tokens": ["waits", "on", "a", "notification"], "project": "flink"}
{"id": 5059, "code": "private final boolean lessThan(T a, T b) {\n    return comparator.compare(a, b) < 0;\n}", "summary_tokens": ["determines", "the", "ordering", "of", "objects", "in", "this", "priority", "queue"], "project": "flink"}
{"id": 8454, "code": "public TypeInformation<?>[] getParameterTypes(Class<?>[] signature) {\n    final TypeInformation<?>[] types = new TypeInformation<?>[signature.length];\n    for (int i = 0; i < signature.length; i++) {\n        try {\n            types[i] = TypeExtractor.getForClass(signature[i]);\n        } catch (InvalidTypesException e) {\n            throw new ValidationException(\n                    \"Parameter types of scalar function \"\n                            + this.getClass().getCanonicalName()\n                            + \" cannot be automatically determined. Please provide type information manually.\");\n        }\n    }\n    return types;\n}", "summary_tokens": ["returns", "type", "information", "about", "the", "operands", "of", "the", "evaluation", "method", "with", "a", "given", "signature"], "project": "flink"}
{"id": 2000, "code": "public static int log2floor(int value) throws ArithmeticException {\n    if (value == 0) {\n        throw new ArithmeticException(\"Logarithm of zero is undefined.\");\n    }\n\n    return 31 - Integer.numberOfLeadingZeros(value);\n}", "summary_tokens": ["computes", "the", "logarithm", "of", "the", "given", "value", "to", "the", "base", "of", "0", "rounded", "down"], "project": "flink"}
{"id": 4163, "code": "public CheckpointProperties getProperties() {\n    return props;\n}", "summary_tokens": ["returns", "the", "properties", "of", "this", "checkpoint"], "project": "flink"}
{"id": 4579, "code": "public void userEventTriggered(ChannelHandlerContext ctx, Object msg) throws Exception {\n    if (msg instanceof ClientOutboundMessage) {\n        boolean triggerWrite = clientOutboundMessages.isEmpty();\n\n        clientOutboundMessages.add((ClientOutboundMessage) msg);\n\n        if (triggerWrite) {\n            writeAndFlushNextMessageIfPossible(ctx.channel());\n        }\n    } else {\n        ctx.fireUserEventTriggered(msg);\n    }\n}", "summary_tokens": ["triggered", "by", "notifying", "credit", "available", "in", "the", "client", "handler", "pipeline"], "project": "flink"}
{"id": 5332, "code": "private EnumChkT deserializeCheckpoint(byte[] bytes) throws Exception {\n    try (ByteArrayInputStream bais = new ByteArrayInputStream(bytes);\n            DataInputStream in = new DataInputViewStreamWrapper(bais)) {\n        final int coordinatorSerdeVersion = readAndVerifyCoordinatorSerdeVersion(in);\n        int enumSerializerVersion = in.readInt();\n        int serializedEnumChkptSize = in.readInt();\n        byte[] serializedEnumChkpt = readBytes(in, serializedEnumChkptSize);\n\n        if (coordinatorSerdeVersion != SourceCoordinatorSerdeUtils.VERSION_0\n                && bais.available() > 0) {\n            throw new IOException(\"Unexpected trailing bytes in enumerator checkpoint data\");\n        }\n\n        return enumCheckpointSerializer.deserialize(enumSerializerVersion, serializedEnumChkpt);\n    }\n}", "summary_tokens": ["restore", "the", "state", "of", "this", "source", "coordinator", "from", "the", "state", "bytes"], "project": "flink"}
{"id": 7826, "code": "public void testSourceCheckpointLastUnaligned() throws Exception {\n    boolean unaligned = true;\n    try (StreamTaskMailboxTestHarness<String> testHarness =\n            buildTestHarness(unaligned, objectReuse)) {\n        testHarness.setAutoProcess(false);\n        ArrayDeque<Object> expectedOutput = new ArrayDeque<>();\n\n        addNetworkRecords(testHarness);\n        CheckpointBarrier barrier = createBarrier(testHarness);\n        addBarriers(testHarness, barrier);\n\n        testHarness.processAll();\n        addSourceRecords(testHarness, 1, 1337, 1337, 1337);\n        testHarness.processAll();\n\n        expectedOutput.add(new StreamRecord<>(\"44\", TimestampAssigner.NO_TIMESTAMP));\n        expectedOutput.add(new StreamRecord<>(\"44\", TimestampAssigner.NO_TIMESTAMP));\n        expectedOutput.add(new StreamRecord<>(\"47.0\", TimestampAssigner.NO_TIMESTAMP));\n        expectedOutput.add(new StreamRecord<>(\"47.0\", TimestampAssigner.NO_TIMESTAMP));\n        expectedOutput.add(barrier);\n\n        assertThat(testHarness.getOutput(), containsInAnyOrder(expectedOutput.toArray()));\n    }\n}", "summary_tokens": ["in", "this", "scenario", "0"], "project": "flink"}
{"id": 9258, "code": "public int getCurrentTopNum() {\n    return currentTopNum;\n}", "summary_tokens": ["gets", "number", "of", "total", "records"], "project": "flink"}
{"id": 1431, "code": "public int getMaxParallelism() {\n    return maxParallelism;\n}", "summary_tokens": ["gets", "the", "maximum", "parallelism", "for", "this", "stream", "transformation"], "project": "flink"}
{"id": 3726, "code": "public void setPruningMarker() {\n    this.pFlag = true;\n}", "summary_tokens": ["sets", "the", "pruning", "marker", "to", "true"], "project": "flink"}
{"id": 9077, "code": "private static DataLengthValidator createDataLengthValidator(LogicalType type) {\n        \n    switch (type.getTypeRoot()) {\n        case CHAR:\n        case VARCHAR:\n        case VARBINARY:\n        case BINARY:\n        case RAW:\n            return data -> {};\n        case BOOLEAN:\n            return createDataLengthValidator(1, \"BOOLEAN\");\n        case TINYINT:\n            return createDataLengthValidator(1, \"TINYINT\");\n        case SMALLINT:\n            return createDataLengthValidator(2, \"SMALLINT\");\n        case INTEGER:\n            return createDataLengthValidator(4, \"INT\");\n        case BIGINT:\n            return createDataLengthValidator(8, \"BIGINT\");\n        case FLOAT:\n            return createDataLengthValidator(4, \"FLOAT\");\n        case DOUBLE:\n            return createDataLengthValidator(8, \"DOUBLE\");\n        default:\n            throw new UnsupportedOperationException(\n                    \"'raw' format currently doesn't support type: \" + type);\n    }\n}", "summary_tokens": ["creates", "a", "validator", "for", "the", "received", "data"], "project": "flink"}
{"id": 4836, "code": "public MemorySegment getCurrentSegment() {\n    return this.currentSegment;\n}", "summary_tokens": ["gets", "the", "memory", "segment", "that", "will", "be", "used", "to", "read", "the", "next", "bytes", "from"], "project": "flink"}
{"id": 7515, "code": "public boolean isEmpty() {\n    return numElements == 0;\n}", "summary_tokens": ["checks", "whether", "the", "map", "is", "empty"], "project": "flink"}
{"id": 3854, "code": "protected FlinkFnApi.UserDefinedAggregateFunctions getUserDefinedFunctionsProto() {\n    FlinkFnApi.UserDefinedAggregateFunctions.Builder builder =\n            FlinkFnApi.UserDefinedAggregateFunctions.newBuilder();\n    builder.setMetricEnabled(pythonConfig.isMetricEnabled());\n    builder.setProfileEnabled(pythonConfig.isProfileEnabled());\n    builder.addAllGrouping(Arrays.stream(grouping).boxed().collect(Collectors.toList()));\n    builder.setGenerateUpdateBefore(generateUpdateBefore);\n    builder.setIndexOfCountStar(indexOfCountStar);\n    builder.setKeyType(toProtoType(getKeyType()));\n    builder.setStateCacheSize(stateCacheSize);\n    builder.setMapStateReadCacheSize(mapStateReadCacheSize);\n    builder.setMapStateWriteCacheSize(mapStateWriteCacheSize);\n    for (int i = 0; i < aggregateFunctions.length; i++) {\n        DataViewSpec[] specs = null;\n        if (i < dataViewSpecs.length) {\n            specs = dataViewSpecs[i];\n        }\n        builder.addUdfs(\n                ProtoUtils.getUserDefinedAggregateFunctionProto(aggregateFunctions[i], specs));\n    }\n    return builder.build();\n}", "summary_tokens": ["gets", "the", "proto", "representation", "of", "the", "python", "user", "defined", "aggregate", "functions", "to", "be", "executed"], "project": "flink"}
{"id": 2289, "code": "public FlinkImageBuilder setTimeout(Duration timeout) {\n    this.timeout = timeout;\n    return this;\n}", "summary_tokens": ["sets", "timeout", "for", "building", "the", "image"], "project": "flink"}
{"id": 3476, "code": "public static SavepointReader read(\n        StreamExecutionEnvironment env, String path, StateBackend stateBackend)\n        throws IOException {\n    CheckpointMetadata metadata = SavepointLoader.loadSavepointMetadata(path);\n\n    int maxParallelism =\n            metadata.getOperatorStates().stream()\n                    .map(OperatorState::getMaxParallelism)\n                    .max(Comparator.naturalOrder())\n                    .orElseThrow(\n                            () ->\n                                    new RuntimeException(\n                                            \"Savepoint must contain at least one operator state.\"));\n\n    SavepointMetadata savepointMetadata =\n            new SavepointMetadata(\n                    maxParallelism, metadata.getMasterStates(), metadata.getOperatorStates());\n    return new SavepointReader(env, savepointMetadata, stateBackend);\n}", "summary_tokens": ["loads", "an", "existing", "savepoint"], "project": "flink"}
{"id": 7149, "code": "public <T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>\n        SingleOutputStreamOperator<Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>>\n                projectTuple10() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>> tType =\n            new TupleTypeInfo<Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>>(fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<IN, Tuple10<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 7653, "code": "public void testStateAndTimerStateShufflingScalingUp() throws Exception {\n    final int maxParallelism = 10;\n\n        \n        \n\n        \n    KeyGroupRange subKeyGroupRange1 = new KeyGroupRange(0, (maxParallelism / 2) - 1);\n    KeyGroupRange subKeyGroupRange2 =\n            new KeyGroupRange(subKeyGroupRange1.getEndKeyGroup() + 1, maxParallelism - 1);\n\n        \n    int key1 = getKeyInKeyGroupRange(subKeyGroupRange1, maxParallelism);\n    int key2 = getKeyInKeyGroupRange(subKeyGroupRange2, maxParallelism);\n\n    OperatorSubtaskState snapshot;\n\n    try (KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String>\n            testHarness = createTestHarness(maxParallelism, 1, 0)) {\n        testHarness.open();\n\n        testHarness.processWatermark(0L);\n        testHarness.setProcessingTime(0L);\n\n        testHarness.processElement(new Tuple2<>(key1, \"SET_EVENT_TIME_TIMER:10\"), 0);\n        testHarness.processElement(new Tuple2<>(key2, \"SET_EVENT_TIME_TIMER:20\"), 0);\n\n        testHarness.processElement(new Tuple2<>(key1, \"SET_PROC_TIME_TIMER:10\"), 0);\n        testHarness.processElement(new Tuple2<>(key2, \"SET_PROC_TIME_TIMER:20\"), 0);\n\n        testHarness.processElement(new Tuple2<>(key1, \"SET_STATE:HELLO\"), 0);\n        testHarness.processElement(new Tuple2<>(key2, \"SET_STATE:CIAO\"), 0);\n\n        assertTrue(extractResult(testHarness).isEmpty());\n\n        snapshot = testHarness.snapshot(0, 0);\n    }\n\n        \n    OperatorSubtaskState initState1 =\n            AbstractStreamOperatorTestHarness.repartitionOperatorState(\n                    snapshot, maxParallelism, 1, 2, 0);\n\n    try (KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String>\n            testHarness1 = createTestHarness(maxParallelism, 2, 0)) {\n        testHarness1.setup();\n        testHarness1.initializeState(initState1);\n        testHarness1.open();\n\n        testHarness1.processWatermark(10L);\n\n        assertThat(extractResult(testHarness1), contains(\"ON_EVENT_TIME:HELLO\"));\n\n        assertTrue(extractResult(testHarness1).isEmpty());\n\n            \n            \n        testHarness1.processWatermark(20L);\n\n        assertTrue(extractResult(testHarness1).isEmpty());\n\n        testHarness1.setProcessingTime(10L);\n\n        assertThat(extractResult(testHarness1), contains(\"ON_PROC_TIME:HELLO\"));\n\n        assertTrue(extractResult(testHarness1).isEmpty());\n\n            \n            \n        testHarness1.setProcessingTime(20L);\n\n        assertTrue(extractResult(testHarness1).isEmpty());\n    }\n\n        \n    OperatorSubtaskState initState2 =\n            AbstractStreamOperatorTestHarness.repartitionOperatorState(\n                    snapshot, maxParallelism, 1, 2, 1);\n\n    try (KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String>\n            testHarness2 = createTestHarness(maxParallelism, 2, 1)) {\n        testHarness2.setup();\n        testHarness2.initializeState(initState2);\n        testHarness2.open();\n\n        testHarness2.processWatermark(10L);\n\n            \n        assertTrue(extractResult(testHarness2).isEmpty());\n\n        testHarness2.processWatermark(20L);\n\n        assertThat(extractResult(testHarness2), contains(\"ON_EVENT_TIME:CIAO\"));\n\n        testHarness2.setProcessingTime(10L);\n\n            \n        assertTrue(extractResult(testHarness2).isEmpty());\n\n        testHarness2.setProcessingTime(20L);\n\n        assertThat(extractResult(testHarness2), contains(\"ON_PROC_TIME:CIAO\"));\n\n        assertTrue(extractResult(testHarness2).isEmpty());\n    }\n}", "summary_tokens": ["verify", "that", "state", "and", "timers", "are", "checkpointed", "per", "key", "group", "and", "that", "they", "are", "correctly", "assigned", "to", "operator", "subtasks", "when", "restoring"], "project": "flink"}
{"id": 7134, "code": "public SingleOutputStreamOperator<T> startNewChain() {\n    return setChainingStrategy(ChainingStrategy.HEAD);\n}", "summary_tokens": ["starts", "a", "new", "task", "chain", "beginning", "at", "this", "operator"], "project": "flink"}
{"id": 1892, "code": "public char[] getCharArray() {\n    return this.value;\n}", "summary_tokens": ["returns", "this", "string", "value", "s", "internal", "character", "data"], "project": "flink"}
{"id": 7159, "code": "public <\n                T0,\n                T1,\n                T2,\n                T3,\n                T4,\n                T5,\n                T6,\n                T7,\n                T8,\n                T9,\n                T10,\n                T11,\n                T12,\n                T13,\n                T14,\n                T15,\n                T16,\n                T17,\n                T18,\n                T19>\n        SingleOutputStreamOperator<\n                        Tuple20<\n                                T0,\n                                T1,\n                                T2,\n                                T3,\n                                T4,\n                                T5,\n                                T6,\n                                T7,\n                                T8,\n                                T9,\n                                T10,\n                                T11,\n                                T12,\n                                T13,\n                                T14,\n                                T15,\n                                T16,\n                                T17,\n                                T18,\n                                T19>>\n                projectTuple20() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<\n                    Tuple20<\n                            T0,\n                            T1,\n                            T2,\n                            T3,\n                            T4,\n                            T5,\n                            T6,\n                            T7,\n                            T8,\n                            T9,\n                            T10,\n                            T11,\n                            T12,\n                            T13,\n                            T14,\n                            T15,\n                            T16,\n                            T17,\n                            T18,\n                            T19>>\n            tType =\n                    new TupleTypeInfo<\n                            Tuple20<\n                                    T0,\n                                    T1,\n                                    T2,\n                                    T3,\n                                    T4,\n                                    T5,\n                                    T6,\n                                    T7,\n                                    T8,\n                                    T9,\n                                    T10,\n                                    T11,\n                                    T12,\n                                    T13,\n                                    T14,\n                                    T15,\n                                    T16,\n                                    T17,\n                                    T18,\n                                    T19>>(fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<\n                    IN,\n                    Tuple20<\n                            T0,\n                            T1,\n                            T2,\n                            T3,\n                            T4,\n                            T5,\n                            T6,\n                            T7,\n                            T8,\n                            T9,\n                            T10,\n                            T11,\n                            T12,\n                            T13,\n                            T14,\n                            T15,\n                            T16,\n                            T17,\n                            T18,\n                            T19>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 8188, "code": "public List<T> getList() {\n    return list;\n}", "summary_tokens": ["returns", "the", "entire", "view", "s", "content", "as", "an", "instance", "of", "list"], "project": "flink"}
{"id": 1864, "code": "public Record createCopy() {\n    final Record rec = new Record();\n    copyTo(rec);\n    return rec;\n}", "summary_tokens": ["creates", "an", "exact", "copy", "of", "this", "record"], "project": "flink"}
{"id": 8713, "code": "public Object getValue2() {\n    if (value == null) {\n        return null;\n    }\n    switch (typeName) {\n        case CHAR:\n            return getValueAs(String.class);\n        case DECIMAL:\n        case TIMESTAMP:\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            return getValueAs(Long.class);\n        case DATE:\n        case TIME:\n        case TIME_WITH_LOCAL_TIME_ZONE:\n            return getValueAs(Integer.class);\n        default:\n            return value;\n    }\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "literal", "in", "the", "form", "that", "the", "calculator", "program", "builder", "wants", "it"], "project": "flink"}
{"id": 487, "code": "public void resumeTransaction(long producerId, short epoch) {\n    checkState(!inTransaction, \"Already in transaction %s\", transactionalId);\n    checkState(\n            producerId >= 0 && epoch >= 0,\n            \"Incorrect values for producerId %s and epoch %s\",\n            producerId,\n            epoch);\n    LOG.info(\n            \"Attempting to resume transaction {} with producerId {} and epoch {}\",\n            transactionalId,\n            producerId,\n            epoch);\n\n    Object transactionManager = getTransactionManager();\n    synchronized (transactionManager) {\n        Object topicPartitionBookkeeper =\n                getField(transactionManager, \"topicPartitionBookkeeper\");\n\n        transitionTransactionManagerStateTo(transactionManager, \"INITIALIZING\");\n        invoke(topicPartitionBookkeeper, \"reset\");\n\n        setField(\n                transactionManager,\n                PRODUCER_ID_AND_EPOCH_FIELD_NAME,\n                createProducerIdAndEpoch(producerId, epoch));\n\n        transitionTransactionManagerStateTo(transactionManager, \"READY\");\n\n        transitionTransactionManagerStateTo(transactionManager, \"IN_TRANSACTION\");\n        setField(transactionManager, \"transactionStarted\", true);\n        this.inTransaction = true;\n    }\n}", "summary_tokens": ["instead", "of", "obtaining", "producer", "id", "and", "epoch", "from", "the", "transaction", "coordinator", "re", "use", "previously", "obtained", "ones", "so", "that", "we", "can", "resume", "transaction", "after", "a", "restart"], "project": "flink"}
{"id": 6181, "code": "private static BufferResponse createBufferResponse(\n        Buffer buffer,\n        int sequenceNumber,\n        InputChannelID receivingChannelId,\n        int backlog,\n        NetworkBufferAllocator allocator)\n        throws IOException {\n        \n    BufferResponse resp =\n            new BufferResponse(buffer, sequenceNumber, receivingChannelId, backlog);\n\n    ByteBuf serialized = resp.write(UnpooledByteBufAllocator.DEFAULT);\n\n        \n    serialized.readBytes(NettyMessage.FRAME_HEADER_LENGTH);\n\n        \n    return BufferResponse.readFrom(serialized, allocator);\n}", "summary_tokens": ["returns", "a", "deserialized", "buffer", "message", "as", "it", "would", "be", "received", "during", "runtime"], "project": "flink"}
{"id": 7355, "code": "protected MailboxExecutor getMailboxExecutor() {\n    return checkNotNull(\n            mailboxExecutor, \"Factory does not implement %s\", YieldingOperatorFactory.class);\n}", "summary_tokens": ["provides", "the", "mailbox", "executor", "iff", "this", "factory", "implements", "yielding", "operator", "factory"], "project": "flink"}
{"id": 98, "code": "public static AwsCredentialsProvider getCredentialsProvider(final Properties configProps) {\n    return getCredentialsProvider(configProps, AWSConfigConstants.AWS_CREDENTIALS_PROVIDER);\n}", "summary_tokens": ["return", "a", "aws", "credentials", "provider", "instance", "corresponding", "to", "the", "configuration", "properties"], "project": "flink"}
{"id": 6401, "code": "public void testRegisterJobMasterWithUnmatchedLeaderSessionId1() throws Exception {\n    final ResourceManagerGateway wronglyFencedGateway =\n            rpcService\n                    .connect(\n                            resourceManagerGateway.getAddress(),\n                            ResourceManagerId.generate(),\n                            ResourceManagerGateway.class)\n                    .get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);\n\n        \n        \n    CompletableFuture<RegistrationResponse> unMatchedLeaderFuture =\n            wronglyFencedGateway.registerJobMaster(\n                    jobMasterGateway.getFencingToken(),\n                    jobMasterResourceId,\n                    jobMasterGateway.getAddress(),\n                    jobId,\n                    TIMEOUT);\n\n    try {\n        unMatchedLeaderFuture.get(5L, TimeUnit.SECONDS);\n        fail(\"Should fail because we are using the wrong fencing token.\");\n    } catch (ExecutionException e) {\n        assertTrue(ExceptionUtils.stripExecutionException(e) instanceof FencingTokenException);\n    }\n}", "summary_tokens": ["test", "receive", "registration", "with", "unmatched", "leadership", "id", "from", "job", "master"], "project": "flink"}
{"id": 1161, "code": "public void setRecordCount(long recordCount) {\n    this.recordCount = recordCount;\n}", "summary_tokens": ["sets", "the", "record", "count", "to", "the", "specified", "value"], "project": "flink"}
{"id": 294, "code": "public void open(TableInputSplit split) throws IOException {\n    initTable();\n\n    if (split == null) {\n        throw new IOException(\"Input split is null!\");\n    }\n\n    logSplitInfo(\"opening\", split);\n\n        \n    currentRow = split.getStartRow();\n    scan.setStartRow(currentRow);\n    scan.setStopRow(split.getEndRow());\n\n    resultScanner = table.getScanner(scan);\n    endReached = false;\n    scannedRows = 0;\n}", "summary_tokens": ["creates", "a", "scan", "object", "and", "opens", "the", "htable", "connection"], "project": "flink"}
{"id": 855, "code": "public static KinesisProducerConfiguration getValidatedProducerConfiguration(\n        Properties config) {\n    checkNotNull(config, \"config can not be null\");\n\n    validateAwsConfiguration(config);\n\n    if (!config.containsKey(AWSConfigConstants.AWS_REGION)) {\n            \n        throw new IllegalArgumentException(\n                String.format(\n                        \"For FlinkKinesisProducer AWS region ('%s') must be set in the config.\",\n                        AWSConfigConstants.AWS_REGION));\n    }\n\n    KinesisProducerConfiguration kpc = KinesisProducerConfiguration.fromProperties(config);\n    kpc.setRegion(config.getProperty(AWSConfigConstants.AWS_REGION));\n\n    kpc.setCredentialsProvider(AWSUtil.getCredentialsProvider(config));\n\n        \n        \n        \n    kpc.setCredentialsRefreshDelay(100);\n\n        \n    if (!config.containsKey(RATE_LIMIT)) {\n        kpc.setRateLimit(DEFAULT_RATE_LIMIT);\n    }\n    if (!config.containsKey(THREADING_MODEL)) {\n        kpc.setThreadingModel(DEFAULT_THREADING_MODEL);\n    }\n    if (!config.containsKey(THREAD_POOL_SIZE)) {\n        kpc.setThreadPoolSize(DEFAULT_THREAD_POOL_SIZE);\n    }\n\n    return kpc;\n}", "summary_tokens": ["validate", "configuration", "properties", "for", "flink", "kinesis", "producer", "and", "return", "a", "constructed", "kinesis", "producer", "configuration"], "project": "flink"}
{"id": 3477, "code": "public <T> DataStream<T> readListState(\n        String uid, String name, TypeInformation<T> typeInfo, TypeSerializer<T> serializer)\n        throws IOException {\n\n    OperatorState operatorState = metadata.getOperatorState(uid);\n    ListStateDescriptor<T> descriptor = new ListStateDescriptor<>(name, serializer);\n    ListStateInputFormat<T> inputFormat = new ListStateInputFormat<>(operatorState, descriptor);\n    return SourceBuilder.fromFormat(env, inputFormat, typeInfo);\n}", "summary_tokens": ["read", "operator", "list", "state", "from", "a", "savepoint", "when", "a", "custom", "serializer", "was", "used", "e"], "project": "flink"}
{"id": 6828, "code": "public void testRemoveAndGetOldState() {\n    int totalSize = 4;\n    for (int i = 1; i <= totalSize; i++) {\n        stateMap.put(i, namespace, String.valueOf(i));\n    }\n        \n    totalSize = removeAndGetOldVerify(2, totalSize);\n        \n    totalSize = removeAndGetOldVerify(4, totalSize);\n        \n    totalSize = removeAndGetOldVerify(1, totalSize);\n        \n    removeAndGetOldVerify(3, totalSize);\n}", "summary_tokens": ["test", "state", "remove", "and", "get", "old"], "project": "flink"}
{"id": 7764, "code": "public void testTriggerHandlesAllOnTimerCalls() throws Exception {\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(\n                    ContinuousEventTimeTrigger.<TimeWindow>of(Time.milliseconds(5)),\n                    new TimeWindow.Serializer());\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers());\n\n        \n        \n    testHarness.advanceWatermark(10);\n\n        \n    assertEquals(\n            TriggerResult.FIRE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n\n        \n    testHarness.invokeOnEventTime(20, new TimeWindow(0, 2));\n}", "summary_tokens": ["verify", "that", "the", "trigger", "doesn", "t", "fail", "with", "an", "npe", "if", "we", "insert", "a", "timer", "firing", "when", "there", "is", "no", "trigger", "state"], "project": "flink"}
{"id": 4351, "code": "public Collection<AllocationID> getPreferredAllocations() {\n    return preferredAllocations;\n}", "summary_tokens": ["returns", "the", "desired", "allocation", "ids", "for", "the", "slot"], "project": "flink"}
{"id": 2898, "code": "public Properties getProperties() {\n    Properties props = new Properties();\n    props.putAll(this.data);\n    return props;\n}", "summary_tokens": ["returns", "a", "properties", "object", "from", "this", "parameter", "tool"], "project": "flink"}
{"id": 350, "code": "public String getClassName() {\n    return className;\n}", "summary_tokens": ["get", "class", "name", "of", "the", "hive", "function"], "project": "flink"}
{"id": 6464, "code": "private void verifyNoFileIsRegisteredToDeleteOnExitHook() {\n    try {\n        Class<?> clazz = Class.forName(\"java.io.DeleteOnExitHook\");\n        Field field = clazz.getDeclaredField(\"files\");\n        field.setAccessible(true);\n        LinkedHashSet files = (LinkedHashSet) field.get(null);\n        assertTrue(files.isEmpty());\n    } catch (ClassNotFoundException | IllegalAccessException | NoSuchFieldException e) {\n        fail(\"This should never happen.\");\n    }\n}", "summary_tokens": ["disk", "attribute", "and", "disk", "file", "upload", "class", "of", "netty", "store", "post", "chunks", "and", "file", "chunks", "as", "temp", "files", "on", "local", "disk"], "project": "flink"}
{"id": 615, "code": "void reassignPartitions(List<KafkaTopicPartitionState<T, TopicPartition>> newPartitions)\n        throws Exception {\n    if (newPartitions.size() == 0) {\n        return;\n    }\n    hasAssignedPartitions = true;\n    boolean reassignmentStarted = false;\n\n        \n        \n        \n        \n        \n    final KafkaConsumer<byte[], byte[]> consumerTmp;\n    synchronized (consumerReassignmentLock) {\n        consumerTmp = this.consumer;\n        this.consumer = null;\n    }\n\n    final Map<TopicPartition, Long> oldPartitionAssignmentsToPosition = new HashMap<>();\n    try {\n        for (TopicPartition oldPartition : consumerTmp.assignment()) {\n            oldPartitionAssignmentsToPosition.put(\n                    oldPartition, consumerTmp.position(oldPartition));\n        }\n\n        final List<TopicPartition> newPartitionAssignments =\n                new ArrayList<>(\n                        newPartitions.size() + oldPartitionAssignmentsToPosition.size());\n        newPartitionAssignments.addAll(oldPartitionAssignmentsToPosition.keySet());\n        newPartitionAssignments.addAll(convertKafkaPartitions(newPartitions));\n\n            \n        consumerTmp.assign(newPartitionAssignments);\n        reassignmentStarted = true;\n\n            \n        for (Map.Entry<TopicPartition, Long> oldPartitionToPosition :\n                oldPartitionAssignmentsToPosition.entrySet()) {\n            consumerTmp.seek(\n                    oldPartitionToPosition.getKey(), oldPartitionToPosition.getValue());\n        }\n\n            \n            \n            \n            \n            \n            \n            \n        for (KafkaTopicPartitionState<T, TopicPartition> newPartitionState : newPartitions) {\n            if (newPartitionState.getOffset()\n                    == KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET) {\n                consumerTmp.seekToBeginning(\n                        Collections.singletonList(newPartitionState.getKafkaPartitionHandle()));\n                newPartitionState.setOffset(\n                        consumerTmp.position(newPartitionState.getKafkaPartitionHandle()) - 1);\n            } else if (newPartitionState.getOffset()\n                    == KafkaTopicPartitionStateSentinel.LATEST_OFFSET) {\n                consumerTmp.seekToEnd(\n                        Collections.singletonList(newPartitionState.getKafkaPartitionHandle()));\n                newPartitionState.setOffset(\n                        consumerTmp.position(newPartitionState.getKafkaPartitionHandle()) - 1);\n            } else if (newPartitionState.getOffset()\n                    == KafkaTopicPartitionStateSentinel.GROUP_OFFSET) {\n                    \n                    \n\n                newPartitionState.setOffset(\n                        consumerTmp.position(newPartitionState.getKafkaPartitionHandle()) - 1);\n            } else {\n                consumerTmp.seek(\n                        newPartitionState.getKafkaPartitionHandle(),\n                        newPartitionState.getOffset() + 1);\n            }\n        }\n    } catch (WakeupException e) {\n            \n            \n            \n\n        synchronized (consumerReassignmentLock) {\n            this.consumer = consumerTmp;\n\n                \n                \n            if (reassignmentStarted) {\n                this.consumer.assign(\n                        new ArrayList<>(oldPartitionAssignmentsToPosition.keySet()));\n\n                for (Map.Entry<TopicPartition, Long> oldPartitionToPosition :\n                        oldPartitionAssignmentsToPosition.entrySet()) {\n                    this.consumer.seek(\n                            oldPartitionToPosition.getKey(), oldPartitionToPosition.getValue());\n                }\n            }\n\n                \n                \n            hasBufferedWakeup = false;\n\n                \n                \n            for (KafkaTopicPartitionState<T, TopicPartition> newPartition : newPartitions) {\n                unassignedPartitionsQueue.add(newPartition);\n            }\n\n                \n            throw new AbortedReassignmentException();\n        }\n    }\n\n        \n    synchronized (consumerReassignmentLock) {\n        this.consumer = consumerTmp;\n\n            \n        if (hasBufferedWakeup) {\n            this.consumer.wakeup();\n            hasBufferedWakeup = false;\n        }\n    }\n}", "summary_tokens": ["reestablishes", "the", "assigned", "partitions", "for", "the", "consumer"], "project": "flink"}
{"id": 9290, "code": "private void registerCleanupTimer(W window) {\n    long cleanupTime = toEpochMillsForTimer(cleanupTime(window), shiftTimeZone);\n    if (cleanupTime == Long.MAX_VALUE) {\n            \n        return;\n    }\n\n    if (windowAssigner.isEventTime()) {\n        triggerContext.registerEventTimeTimer(cleanupTime);\n    } else {\n        triggerContext.registerProcessingTimeTimer(cleanupTime);\n    }\n}", "summary_tokens": ["registers", "a", "timer", "to", "cleanup", "the", "content", "of", "the", "window"], "project": "flink"}
{"id": 3379, "code": "private CoGroupOperator<?, ?, Tuple2<K, Message>> buildScatterFunctionVerticesWithDegrees(\n        DeltaIteration<\n                        Vertex<K, Tuple3<VV, LongValue, LongValue>>,\n                        Vertex<K, Tuple3<VV, LongValue, LongValue>>>\n                iteration,\n        TypeInformation<Tuple2<K, Message>> messageTypeInfo,\n        int whereArg,\n        int equalToArg,\n        DataSet<LongValue> numberOfVertices) {\n\n        \n    CoGroupOperator<?, ?, Tuple2<K, Message>> messages;\n    ScatterUdfWithEdgeValues<K, Tuple3<VV, LongValue, LongValue>, VV, Message, EV> messenger =\n            new ScatterUdfWithEVsVVWithDegrees<>(scatterFunction, messageTypeInfo);\n\n    messages =\n            this.edgesWithValue\n                    .coGroup(iteration.getWorkset())\n                    .where(whereArg)\n                    .equalTo(equalToArg)\n                    .with(messenger);\n\n        \n    messages = messages.name(\"Messaging\");\n\n    if (this.configuration != null) {\n        for (Tuple2<String, DataSet<?>> e : this.configuration.getScatterBcastVars()) {\n            messages = messages.withBroadcastSet(e.f1, e.f0);\n        }\n        if (this.configuration.isOptNumVertices()) {\n            messages = messages.withBroadcastSet(numberOfVertices, \"number of vertices\");\n        }\n    }\n\n    return messages;\n}", "summary_tokens": ["method", "that", "builds", "the", "scatter", "function", "using", "a", "co", "group", "operator", "for", "a", "vertex", "containing", "degree", "information"], "project": "flink"}
{"id": 7745, "code": "public void testPersisting(boolean drainGate) throws Exception {\n\n    int numberOfChannels = 3;\n    NetworkBufferPool bufferPool = new NetworkBufferPool(numberOfChannels * 3, 1024);\n    try {\n        long checkpointId = 2L;\n        long obsoleteCheckpointId = 1L;\n        ValidatingCheckpointHandler validatingHandler =\n                new ValidatingCheckpointHandler(checkpointId);\n        RecordingChannelStateWriter stateWriter = new RecordingChannelStateWriter();\n        CheckpointedInputGate gate =\n                setupInputGateWithAlternatingController(\n                        numberOfChannels, bufferPool, validatingHandler, stateWriter);\n\n            \n            \n        enqueue(gate, 0, buildSomeBuffer());\n        enqueue(gate, 0, barrier(checkpointId));\n        enqueue(gate, 0, buildSomeBuffer());\n        enqueue(gate, 1, buildSomeBuffer());\n        enqueue(gate, 1, barrier(obsoleteCheckpointId));\n        enqueue(gate, 1, buildSomeBuffer());\n        enqueue(gate, 2, buildSomeBuffer());\n\n        assertEquals(0, validatingHandler.getTriggeredCheckpointCounter());\n            \n        gate.pollNext();\n        assertEquals(1, validatingHandler.getTriggeredCheckpointCounter());\n\n        assertAddedInputSize(stateWriter, 0, 1);\n        assertAddedInputSize(stateWriter, 1, 2);\n        assertAddedInputSize(stateWriter, 2, 1);\n\n        enqueue(gate, 0, buildSomeBuffer());\n        enqueue(gate, 1, buildSomeBuffer());\n        enqueue(gate, 2, buildSomeBuffer());\n\n        while (drainGate && gate.pollNext().isPresent()) {}\n\n        assertAddedInputSize(stateWriter, 0, 1);\n        assertAddedInputSize(stateWriter, 1, 3);\n        assertAddedInputSize(stateWriter, 2, 2);\n\n        enqueue(gate, 1, barrier(checkpointId));\n        enqueue(gate, 1, buildSomeBuffer());\n            \n        enqueue(gate, 2, barrier(obsoleteCheckpointId));\n        enqueue(gate, 2, buildSomeBuffer());\n\n        while (drainGate && gate.pollNext().isPresent()) {}\n\n        assertAddedInputSize(stateWriter, 0, 1);\n        assertAddedInputSize(stateWriter, 1, 3);\n        assertAddedInputSize(stateWriter, 2, 3);\n\n        enqueue(gate, 2, barrier(checkpointId));\n        enqueue(gate, 2, buildSomeBuffer());\n\n        while (drainGate && gate.pollNext().isPresent()) {}\n\n        assertAddedInputSize(stateWriter, 0, 1);\n        assertAddedInputSize(stateWriter, 1, 3);\n        assertAddedInputSize(stateWriter, 2, 3);\n    } finally {\n        bufferPool.destroy();\n    }\n}", "summary_tokens": ["this", "tests", "a", "scenario", "where", "an", "older", "triggered", "checkpoint", "was", "cancelled", "and", "a", "newer", "checkpoint", "was", "triggered", "very", "quickly", "after", "the", "cancellation"], "project": "flink"}
{"id": 7076, "code": "public DataStreamSink<T> printToErr(String sinkIdentifier) {\n    PrintSinkFunction<T> printFunction = new PrintSinkFunction<>(sinkIdentifier, true);\n    return addSink(printFunction).name(\"Print to Std. Err\");\n}", "summary_tokens": ["writes", "a", "data", "stream", "to", "the", "standard", "error", "stream", "stderr"], "project": "flink"}
{"id": 1448, "code": "public void setOutputType(TypeInformation<T> outputType) {\n    if (typeUsed) {\n        throw new IllegalStateException(\n                \"TypeInformation cannot be filled in for the type after it has been used. \"\n                        + \"Please make sure that the type info hints are the first call after\"\n                        + \" the transformation function, \"\n                        + \"before any access to types or semantic properties, etc.\");\n    }\n    this.outputType = outputType;\n}", "summary_tokens": ["tries", "to", "fill", "in", "the", "type", "information"], "project": "flink"}
{"id": 8977, "code": "public static <I1, I2, O> TwoInputTransformation<I1, I2, O> createTwoInputTransformation(\n        Transformation<I1> input1,\n        Transformation<I2> input2,\n        String name,\n        String desc,\n        StreamOperatorFactory<O> operatorFactory,\n        TypeInformation<O> outputType,\n        int parallelism,\n        long memoryBytes) {\n    TwoInputTransformation<I1, I2, O> transformation =\n            new TwoInputTransformation<>(\n                    input1, input2, name, operatorFactory, outputType, parallelism);\n    setManagedMemoryWeight(transformation, memoryBytes);\n    transformation.setDescription(desc);\n    return transformation;\n}", "summary_tokens": ["create", "a", "two", "input", "transformation", "with", "memory", "bytes"], "project": "flink"}
{"id": 1972, "code": "public static int tryReadFully(final InputStream in, final byte[] buf) throws IOException {\n    int totalRead = 0;\n    while (totalRead != buf.length) {\n        int read = in.read(buf, totalRead, buf.length - totalRead);\n        if (read == -1) {\n            break;\n        }\n        totalRead += read;\n    }\n    return totalRead;\n}", "summary_tokens": ["similar", "to", "read", "fully", "input", "stream", "byte", "int", "int"], "project": "flink"}
{"id": 2578, "code": "private static MapData readMap(MapColumnVector mapVector, int row) {\n    int offset = (int) mapVector.offsets[row];\n    StringData keyData = readStringData((BytesColumnVector) mapVector.keys, offset);\n    GenericRowData valueData = new GenericRowData(2);\n    StructColumnVector structVector = (StructColumnVector) mapVector.values;\n    BytesColumnVector bytesVector = (BytesColumnVector) structVector.fields[0];\n    TimestampColumnVector timestampVector = (TimestampColumnVector) structVector.fields[1];\n    StringData strValueData = readStringData(bytesVector, offset);\n    TimestampData timestampData = readTimestamp(timestampVector, offset);\n    valueData.setField(0, strValueData);\n    valueData.setField(1, timestampData);\n    Map<StringData, RowData> mapDataMap = new HashMap<>();\n    mapDataMap.put(keyData, valueData);\n    return new GenericMapData(mapDataMap);\n}", "summary_tokens": ["read", "map", "column", "vector", "with", "specify", "schema", "map", "string", "struct", "col", "0", "col", "0", "string", "col", "0", "col", "0", "timestamp"], "project": "flink"}
{"id": 1782, "code": "public int getInt(int index) {\n    final long pos = address + index;\n    if (index >= 0 && pos <= addressLimit - 4) {\n        return UNSAFE.getInt(heapMemory, pos);\n    } else if (address > addressLimit) {\n        throw new IllegalStateException(\"segment has been freed\");\n    } else {\n            \n        throw new IndexOutOfBoundsException();\n    }\n}", "summary_tokens": ["reads", "an", "int", "value", "0", "bit", "0", "bytes", "from", "the", "given", "position", "in", "the", "system", "s", "native", "byte", "order"], "project": "flink"}
{"id": 4729, "code": "protected Collector<OT> createSolutionSetUpdateOutputCollector(Collector<OT> delegate) {\n    Broker<Object> solutionSetBroker = SolutionSetBroker.instance();\n\n    Object ss = solutionSetBroker.get(brokerKey());\n    if (ss instanceof CompactingHashTable) {\n        @SuppressWarnings(\"unchecked\")\n        CompactingHashTable<OT> solutionSet = (CompactingHashTable<OT>) ss;\n        return new SolutionSetUpdateOutputCollector<OT>(solutionSet, delegate);\n    } else if (ss instanceof JoinHashMap) {\n        @SuppressWarnings(\"unchecked\")\n        JoinHashMap<OT> map = (JoinHashMap<OT>) ss;\n        return new SolutionSetObjectsUpdateOutputCollector<OT>(map, delegate);\n    } else {\n        throw new RuntimeException(\"Unrecognized solution set handle: \" + ss);\n    }\n}", "summary_tokens": ["creates", "a", "new", "solution", "set", "update", "output", "collector"], "project": "flink"}
{"id": 5339, "code": "private <V> V callInCoordinatorThread(Callable<V> callable, String errorMessage) {\n        \n    if (!coordinatorThreadFactory.isCurrentThreadCoordinatorThread()) {\n        try {\n            final Callable<V> guardedCallable =\n                    () -> {\n                        try {\n                            return callable.call();\n                        } catch (Throwable t) {\n                            LOG.error(\"Uncaught Exception in Source Coordinator Executor\", t);\n                            ExceptionUtils.rethrowException(t);\n                            return null;\n                        }\n                    };\n\n            return coordinatorExecutor.submit(guardedCallable).get();\n        } catch (InterruptedException | ExecutionException e) {\n            throw new FlinkRuntimeException(errorMessage, e);\n        }\n    }\n\n    try {\n        return callable.call();\n    } catch (Throwable t) {\n        LOG.error(\"Uncaught Exception in Source Coordinator Executor\", t);\n        throw new FlinkRuntimeException(errorMessage, t);\n    }\n}", "summary_tokens": ["a", "helper", "method", "that", "delegates", "the", "callable", "to", "the", "coordinator", "thread", "if", "the", "current", "thread", "is", "not", "the", "coordinator", "thread", "otherwise", "call", "the", "callable", "right", "away"], "project": "flink"}
{"id": 3619, "code": "protected void computeOperatorSpecificDefaultEstimates(DataStatistics statistics) {\n    this.estimatedNumRecords = getPredecessorNode().getEstimatedNumRecords();\n}", "summary_tokens": ["computes", "the", "estimates", "for", "the", "map", "operator"], "project": "flink"}
{"id": 7518, "code": "int traverseAndCountElements() {\n    int num = 0;\n\n    for (Entry<?, ?> entry : table) {\n        while (entry != null) {\n            num++;\n            entry = entry.next;\n        }\n    }\n\n    return num;\n}", "summary_tokens": ["for", "testing", "only", "actively", "counts", "the", "number", "of", "entries", "rather", "than", "using", "the", "counter", "variable"], "project": "flink"}
{"id": 5341, "code": "static int readAndVerifyCoordinatorSerdeVersion(DataInputStream in) throws IOException {\n    int version = in.readInt();\n    if (version > CURRENT_VERSION) {\n        throw new IOException(\"Unsupported source coordinator serde version \" + version);\n    }\n    return version;\n}", "summary_tokens": ["read", "and", "verify", "the", "serde", "version"], "project": "flink"}
{"id": 5527, "code": "public int numProxyServerThreads() {\n    return numProxyThreads;\n}", "summary_tokens": ["returns", "the", "number", "of", "threads", "for", "the", "query", "proxy", "nio", "event", "loop"], "project": "flink"}
{"id": 4581, "code": "private void writeAndFlushNextMessageIfPossible(Channel channel) {\n    if (channelError.get() != null || !channel.isWritable()) {\n        return;\n    }\n\n    while (true) {\n        ClientOutboundMessage outboundMessage = clientOutboundMessages.poll();\n\n            \n            \n        if (outboundMessage == null) {\n            return;\n        }\n\n            \n        if (!outboundMessage.inputChannel.isReleased()) {\n            Object msg = outboundMessage.buildMessage();\n            if (msg == null) {\n                continue;\n            }\n\n                \n                \n            channel.writeAndFlush(msg).addListener(writeListener);\n\n            return;\n        }\n    }\n}", "summary_tokens": ["tries", "to", "write", "flush", "unannounced", "credits", "for", "the", "next", "input", "channel", "in", "queue"], "project": "flink"}
{"id": 3558, "code": "public void testAddingMetrics() {\n    String counterName = \"testCounter\";\n\n    final String scope = \"scope\";\n    final char delimiter = '_';\n\n    MetricGroup metricGroup =\n            TestMetricGroup.newBuilder()\n                    .setMetricIdentifierFunction(\n                            (metricName, characterFilter) -> scope + delimiter + metricName)\n                    .build();\n\n    TestingStatsDReporter reporter = new TestingStatsDReporter();\n    reporter.open(new MetricConfig());\n\n    SimpleCounter myCounter = new SimpleCounter();\n    reporter.notifyOfAddedMetric(myCounter, counterName, metricGroup);\n\n    Map<Counter, String> counters = reporter.getCounters();\n\n    assertTrue(counters.containsKey(myCounter));\n\n    String expectedCounterName =\n            reporter.filterCharacters(scope)\n                    + delimiter\n                    + reporter.filterCharacters(counterName);\n\n    assertEquals(expectedCounterName, counters.get(myCounter));\n}", "summary_tokens": ["tests", "that", "the", "registered", "metrics", "names", "don", "t", "contain", "invalid", "characters"], "project": "flink"}
{"id": 4042, "code": "public final CompletableFuture<Void> internalCallOnStop() {\n    validateRunsInMainThread();\n    CompletableFuture<Void> stopFuture = onStop();\n    isRunning = false;\n    return stopFuture;\n}", "summary_tokens": ["internal", "method", "which", "is", "called", "by", "the", "rpc", "service", "implementation", "to", "stop", "the", "rpc", "endpoint"], "project": "flink"}
{"id": 3193, "code": "public Graph<K, VV, EV> addEdge(Vertex<K, VV> source, Vertex<K, VV> target, EV edgeValue) {\n    Graph<K, VV, EV> partialGraph =\n            fromCollection(\n                    Arrays.asList(source, target),\n                    Collections.singletonList(new Edge<>(source.f0, target.f0, edgeValue)),\n                    this.context);\n    return this.union(partialGraph);\n}", "summary_tokens": ["adds", "the", "given", "edge", "to", "the", "graph"], "project": "flink"}
{"id": 8321, "code": "public static int hash(MemorySegment[] segments, int offset, int numBytes) {\n    if (inFirstSegment(segments, offset, numBytes)) {\n        return MurmurHashUtils.hashBytes(segments[0], offset, numBytes);\n    } else {\n        return hashMultiSeg(segments, offset, numBytes);\n    }\n}", "summary_tokens": ["hash", "segments", "to", "int"], "project": "flink"}
{"id": 7565, "code": "public static long getProcessingTimeDelay(long processingTimestamp, long currentTimestamp) {\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n    if (processingTimestamp >= currentTimestamp) {\n        return processingTimestamp - currentTimestamp + 1;\n    } else {\n        return 0;\n    }\n}", "summary_tokens": ["returns", "the", "remaining", "delay", "of", "the", "processing", "time", "specified", "by", "processing", "timestamp"], "project": "flink"}
{"id": 7611, "code": "public void testNaming() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStream<Long> dataStream1 =\n            env.generateSequence(0, 0)\n                    .name(\"testSource1\")\n                    .map(\n                            new MapFunction<Long, Long>() {\n                                @Override\n                                public Long map(Long value) throws Exception {\n                                    return null;\n                                }\n                            })\n                    .name(\"testMap\");\n\n    DataStream<Long> dataStream2 =\n            env.generateSequence(0, 0)\n                    .name(\"testSource2\")\n                    .map(\n                            new MapFunction<Long, Long>() {\n                                @Override\n                                public Long map(Long value) throws Exception {\n                                    return null;\n                                }\n                            })\n                    .name(\"testMap\");\n\n    dataStream1\n            .connect(dataStream2)\n            .flatMap(\n                    new CoFlatMapFunction<Long, Long, Long>() {\n\n                        @Override\n                        public void flatMap1(Long value, Collector<Long> out)\n                                throws Exception {}\n\n                        @Override\n                        public void flatMap2(Long value, Collector<Long> out)\n                                throws Exception {}\n                    })\n            .name(\"testCoFlatMap\")\n            .windowAll(GlobalWindows.create())\n            .trigger(PurgingTrigger.of(CountTrigger.of(10)))\n            .reduce(\n                    new ReduceFunction<Long>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public Long reduce(Long value1, Long value2) throws Exception {\n                            return null;\n                        }\n                    })\n            .name(\"testWindowReduce\")\n            .print();\n\n        \n    String plan = env.getExecutionPlan();\n\n    assertTrue(plan.contains(\"testSource1\"));\n    assertTrue(plan.contains(\"testSource2\"));\n    assertTrue(plan.contains(\"testMap\"));\n    assertTrue(plan.contains(\"testMap\"));\n    assertTrue(plan.contains(\"testCoFlatMap\"));\n    assertTrue(plan.contains(\"testWindowReduce\"));\n}", "summary_tokens": ["tests", "single", "output", "stream", "operator", "name", "string", "functionality"], "project": "flink"}
{"id": 9355, "code": "public void copyFromPagesToView(AbstractPagedInputView source, DataOutputView target)\n        throws IOException {\n    checkSkipReadForFixLengthPart(source);\n    int length = source.readInt();\n    target.writeInt(length);\n    target.write(source, length);\n}", "summary_tokens": ["copy", "a", "binary", "row", "which", "stored", "in", "paged", "input", "view", "to", "output", "view"], "project": "flink"}
{"id": 7056, "code": "public <K> DataStream<T> partitionCustom(\n        Partitioner<K> partitioner, KeySelector<T, K> keySelector) {\n    return setConnectionType(\n            new CustomPartitionerWrapper<>(clean(partitioner), clean(keySelector)));\n}", "summary_tokens": ["partitions", "a", "data", "stream", "on", "the", "key", "returned", "by", "the", "selector", "using", "a", "custom", "partitioner"], "project": "flink"}
{"id": 9643, "code": "public void testAllWindowLateArrivingEvents() throws Exception {\n    TestListResultSink<String> sideOutputResultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(1);\n\n    DataStream<Integer> dataStream = see.fromCollection(elements);\n\n    OutputTag<Integer> lateDataTag = new OutputTag<Integer>(\"late\") {};\n\n    SingleOutputStreamOperator<Integer> windowOperator =\n            dataStream\n                    .assignTimestampsAndWatermarks(new TestWatermarkAssigner())\n                    .windowAll(\n                            SlidingEventTimeWindows.of(\n                                    Time.milliseconds(1), Time.milliseconds(1)))\n                    .sideOutputLateData(lateDataTag)\n                    .apply(\n                            new AllWindowFunction<Integer, Integer, TimeWindow>() {\n                                private static final long serialVersionUID = 1L;\n\n                                @Override\n                                public void apply(\n                                        TimeWindow window,\n                                        Iterable<Integer> values,\n                                        Collector<Integer> out)\n                                        throws Exception {\n                                    for (Integer val : values) {\n                                        out.collect(val);\n                                    }\n                                }\n                            });\n\n    windowOperator\n            .getSideOutput(lateDataTag)\n            .flatMap(\n                    new FlatMapFunction<Integer, String>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public void flatMap(Integer value, Collector<String> out)\n                                throws Exception {\n                            out.collect(\"late-\" + String.valueOf(value));\n                        }\n                    })\n            .addSink(sideOutputResultSink);\n\n    see.execute();\n    assertEquals(sideOutputResultSink.getSortedResult(), Arrays.asList(\"late-3\", \"late-4\"));\n}", "summary_tokens": ["test", "window", "late", "arriving", "events", "stream"], "project": "flink"}
{"id": 1855, "code": "public <T extends Value> T getField(int fieldNum, T target) {\n        \n    if (fieldNum < 0 || fieldNum >= this.numFields) {\n        throw new IndexOutOfBoundsException();\n    }\n    if (target == null) {\n        throw new NullPointerException(\"The target object may not be null\");\n    }\n\n        \n    final int offset = this.offsets[fieldNum];\n    if (offset == NULL_INDICATOR_OFFSET) {\n        return null;\n    } else if (offset == MODIFIED_INDICATOR_OFFSET) {\n            \n            \n        return (T) this.writeFields[fieldNum];\n    }\n\n    final int limit = offset + this.lengths[fieldNum];\n    deserialize(target, offset, limit, fieldNum);\n    return target;\n}", "summary_tokens": ["gets", "the", "field", "at", "the", "given", "position"], "project": "flink"}
{"id": 5577, "code": "public static String getGarbageCollectorStatsAsString(List<GarbageCollectorMXBean> gcMXBeans) {\n    StringBuilder bld = new StringBuilder(\"Garbage collector stats: \");\n\n    for (GarbageCollectorMXBean bean : gcMXBeans) {\n        bld.append('[')\n                .append(bean.getName())\n                .append(\", GC TIME (ms): \")\n                .append(bean.getCollectionTime());\n        bld.append(\", GC COUNT: \").append(bean.getCollectionCount()).append(']');\n\n        bld.append(\", \");\n    }\n\n    if (!gcMXBeans.isEmpty()) {\n        bld.setLength(bld.length() - 2);\n    }\n\n    return bld.toString();\n}", "summary_tokens": ["gets", "the", "garbage", "collection", "statistics", "from", "the", "jvm"], "project": "flink"}
{"id": 179, "code": "default void open() throws Exception {}", "summary_tokens": ["initialization", "method", "for", "the", "function"], "project": "flink"}
{"id": 6972, "code": "public PredefinedOptions getPredefinedOptions() {\n    return rocksDBStateBackend.getPredefinedOptions();\n}", "summary_tokens": ["gets", "the", "currently", "set", "predefined", "options", "for", "rocks", "db"], "project": "flink"}
{"id": 5922, "code": "public void testSimpleUpdates() throws Exception {\n    long triggerTimestamp = 123123L;\n    long ackTimestamp = 123123 + 1212312399L;\n    long stateSize = Integer.MAX_VALUE + 17787L;\n    long processedData = Integer.MAX_VALUE + 123123L;\n    long persistedData = Integer.MAX_VALUE + 42L;\n\n    CompletedCheckpointStatsSummary summary = new CompletedCheckpointStatsSummary();\n    assertEquals(0, summary.getStateSizeStats().getCount());\n    assertEquals(0, summary.getEndToEndDurationStats().getCount());\n    assertEquals(0, summary.getProcessedDataStats().getCount());\n    assertEquals(0, summary.getPersistedDataStats().getCount());\n\n    int numCheckpoints = 10;\n\n    for (int i = 0; i < numCheckpoints; i++) {\n        CompletedCheckpointStats completed =\n                createCompletedCheckpoint(\n                        i,\n                        triggerTimestamp,\n                        ackTimestamp + i,\n                        stateSize + i,\n                        processedData + i,\n                        persistedData + i);\n\n        summary.updateSummary(completed);\n\n        assertEquals(i + 1, summary.getStateSizeStats().getCount());\n        assertEquals(i + 1, summary.getEndToEndDurationStats().getCount());\n        assertEquals(i + 1, summary.getProcessedDataStats().getCount());\n        assertEquals(i + 1, summary.getPersistedDataStats().getCount());\n    }\n\n    StatsSummary stateSizeStats = summary.getStateSizeStats();\n    assertEquals(stateSize, stateSizeStats.getMinimum());\n    assertEquals(stateSize + numCheckpoints - 1, stateSizeStats.getMaximum());\n\n    StatsSummary durationStats = summary.getEndToEndDurationStats();\n    assertEquals(ackTimestamp - triggerTimestamp, durationStats.getMinimum());\n    assertEquals(\n            ackTimestamp - triggerTimestamp + numCheckpoints - 1, durationStats.getMaximum());\n\n    StatsSummary processedDataStats = summary.getProcessedDataStats();\n    assertEquals(processedData, processedDataStats.getMinimum());\n    assertEquals(processedData + numCheckpoints - 1, processedDataStats.getMaximum());\n\n    StatsSummary persistedDataStats = summary.getPersistedDataStats();\n    assertEquals(persistedData, persistedDataStats.getMinimum());\n    assertEquals(persistedData + numCheckpoints - 1, persistedDataStats.getMaximum());\n}", "summary_tokens": ["tests", "simple", "updates", "of", "the", "completed", "checkpoint", "stats"], "project": "flink"}
{"id": 6501, "code": "public void testRunAsyncWithoutFencing() throws Exception {\n    final CompletableFuture<UUID> resultFuture = new CompletableFuture<>();\n    final UUID newFencingToken = UUID.randomUUID();\n\n    testRunAsync(\n            endpoint -> {\n                endpoint.runAsyncWithoutFencing(\n                        () -> resultFuture.complete(endpoint.getFencingToken()));\n                return resultFuture;\n            },\n            newFencingToken);\n\n    assertEquals(\n            newFencingToken, resultFuture.get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS));\n}", "summary_tokens": ["tests", "that", "code", "can", "be", "executed", "in", "the", "main", "thread", "without", "respecting", "the", "fencing", "token"], "project": "flink"}
{"id": 4329, "code": "public static String formatSystemProperties(Configuration jvmArgs) {\n    StringBuilder sb = new StringBuilder();\n    for (Map.Entry<String, String> entry : jvmArgs.toMap().entrySet()) {\n        if (sb.length() > 0) {\n            sb.append(\" \");\n        }\n        final String dynamicProperty = createDynamicProperty(entry.getKey(), entry.getValue());\n        sb.append(dynamicProperty);\n    }\n    return sb.toString();\n}", "summary_tokens": ["format", "the", "system", "properties", "as", "a", "shell", "compatible", "command", "line", "argument"], "project": "flink"}
{"id": 7545, "code": "public final boolean isRecord() {\n    return getClass() == StreamRecord.class;\n}", "summary_tokens": ["checks", "whether", "this", "element", "is", "a", "record"], "project": "flink"}
{"id": 6673, "code": "public void testInconsistentStaticSlotAllocation() throws Exception {\n    try (final TaskSlotTable<TaskSlotPayload> taskSlotTable = createTaskSlotTableAndStart(2)) {\n        final JobID jobId = new JobID();\n        final AllocationID allocationId1 = new AllocationID();\n        final AllocationID allocationId2 = new AllocationID();\n\n        assertThat(taskSlotTable.allocateSlot(0, jobId, allocationId1, SLOT_TIMEOUT), is(true));\n        assertThat(\n                taskSlotTable.allocateSlot(1, jobId, allocationId1, SLOT_TIMEOUT), is(false));\n        assertThat(\n                taskSlotTable.allocateSlot(0, jobId, allocationId2, SLOT_TIMEOUT), is(false));\n\n        assertThat(taskSlotTable.isAllocated(0, jobId, allocationId1), is(true));\n        assertThat(taskSlotTable.isSlotFree(1), is(true));\n\n        Iterator<TaskSlot<TaskSlotPayload>> allocatedSlots =\n                taskSlotTable.getAllocatedSlots(jobId);\n        assertThat(allocatedSlots.next().getIndex(), is(0));\n        assertThat(allocatedSlots.hasNext(), is(false));\n    }\n}", "summary_tokens": ["tests", "that", "inconsistent", "static", "slot", "allocation", "with", "the", "same", "allocation", "id", "to", "a", "different", "slot", "is", "rejected"], "project": "flink"}
{"id": 7337, "code": "private byte[] generateDeterministicHash(\n        StreamNode node,\n        Hasher hasher,\n        Map<Integer, byte[]> hashes,\n        boolean isChainingEnabled,\n        StreamGraph streamGraph) {\n\n        \n        \n        \n        \n    generateNodeLocalHash(hasher, hashes.size());\n\n        \n    for (StreamEdge outEdge : node.getOutEdges()) {\n        if (isChainable(outEdge, isChainingEnabled, streamGraph)) {\n\n                \n                \n            generateNodeLocalHash(hasher, hashes.size());\n        }\n    }\n\n    byte[] hash = hasher.hash().asBytes();\n\n        \n        \n    for (StreamEdge inEdge : node.getInEdges()) {\n        byte[] otherHash = hashes.get(inEdge.getSourceId());\n\n            \n        if (otherHash == null) {\n            throw new IllegalStateException(\n                    \"Missing hash for input node \"\n                            + streamGraph.getSourceVertex(inEdge)\n                            + \". Cannot generate hash for \"\n                            + node\n                            + \".\");\n        }\n\n        for (int j = 0; j < hash.length; j++) {\n            hash[j] = (byte) (hash[j] * 37 ^ otherHash[j]);\n        }\n    }\n\n    if (LOG.isDebugEnabled()) {\n        String udfClassName = \"\";\n        if (node.getOperatorFactory() instanceof UdfStreamOperatorFactory) {\n            udfClassName =\n                    ((UdfStreamOperatorFactory) node.getOperatorFactory())\n                            .getUserFunctionClassName();\n        }\n\n        LOG.debug(\n                \"Generated hash '\"\n                        + byteToHexString(hash)\n                        + \"' for node \"\n                        + \"'\"\n                        + node.toString()\n                        + \"' {id: \"\n                        + node.getId()\n                        + \", \"\n                        + \"parallelism: \"\n                        + node.getParallelism()\n                        + \", \"\n                        + \"user function: \"\n                        + udfClassName\n                        + \"}\");\n    }\n\n    return hash;\n}", "summary_tokens": ["generates", "a", "deterministic", "hash", "from", "node", "local", "properties", "and", "input", "and", "output", "edges"], "project": "flink"}
{"id": 796, "code": "public long getDescribeStreamBaseBackoffMillis() {\n    return describeStreamBaseBackoffMillis;\n}", "summary_tokens": ["get", "base", "backoff", "millis", "for", "the", "describe", "stream", "operation"], "project": "flink"}
{"id": 7348, "code": "public void initializeState(StateInitializationContext context) throws Exception {}", "summary_tokens": ["stream", "operators", "with", "state", "which", "can", "be", "restored", "need", "to", "override", "this", "hook", "method"], "project": "flink"}
{"id": 3994, "code": "public static CompletableFuture<Void> terminateActorSystem(ActorSystem actorSystem) {\n    return AkkaFutureUtils.toJava(actorSystem.terminate()).thenAccept(FunctionUtils.ignoreFn());\n}", "summary_tokens": ["terminates", "the", "given", "actor", "system", "and", "returns", "its", "termination", "future"], "project": "flink"}
{"id": 8864, "code": "public Map<FeatureOption, MergingStrategy> computeMergingStrategies(\n        List<SqlTableLike.SqlTableLikeOption> mergingOptions) {\n\n    Map<FeatureOption, MergingStrategy> result = new HashMap<>(defaultMergingStrategies);\n\n    Optional<SqlTableLike.SqlTableLikeOption> maybeAllOption =\n            mergingOptions.stream()\n                    .filter(option -> option.getFeatureOption() == FeatureOption.ALL)\n                    .findFirst();\n\n    maybeAllOption.ifPresent(\n            (allOption) -> {\n                MergingStrategy strategy = allOption.getMergingStrategy();\n                for (FeatureOption featureOption : FeatureOption.values()) {\n                    if (featureOption != FeatureOption.ALL) {\n                        result.put(featureOption, strategy);\n                    }\n                }\n            });\n\n    for (SqlTableLike.SqlTableLikeOption mergingOption : mergingOptions) {\n        result.put(mergingOption.getFeatureOption(), mergingOption.getMergingStrategy());\n    }\n\n    return result;\n}", "summary_tokens": ["calculates", "merging", "strategies", "for", "all", "options"], "project": "flink"}
{"id": 3391, "code": "private void initialize(int bytes) {\n    int capacity = bytes / ELEMENT_LENGTH_IN_BYTES;\n\n    Preconditions.checkArgument(capacity > 0, \"Requested array with zero capacity\");\n    Preconditions.checkArgument(\n            capacity <= MAX_ARRAY_SIZE,\n            \"Requested capacity exceeds limit of \" + MAX_ARRAY_SIZE);\n\n    data = new int[capacity];\n}", "summary_tokens": ["initializes", "the", "array", "with", "the", "provided", "number", "of", "bytes"], "project": "flink"}
{"id": 7210, "code": "public CheckpointStorage getCheckpointStorage() {\n    return this.storage;\n}", "summary_tokens": ["the", "checkpoint", "storage", "that", "has", "been", "configured", "for", "the", "job"], "project": "flink"}
{"id": 6421, "code": "public void testRequirementDeclarationWithPendingResource() throws Exception {\n    testRequirementDeclaration(\n            RequirementDeclarationScenario\n                    .TASK_EXECUTOR_REGISTRATION_AFTER_REQUIREMENT_DECLARATION);\n}", "summary_tokens": ["tests", "that", "resource", "requirements", "can", "be", "fulfilled", "with", "resource", "that", "are", "registered", "after", "the", "requirement", "declaration"], "project": "flink"}
{"id": 3883, "code": "public static <T> T deserializeValue(byte[] serializedValue, TypeSerializer<T> serializer)\n        throws IOException {\n    if (serializedValue == null) {\n        return null;\n    } else {\n        final DataInputDeserializer deser =\n                new DataInputDeserializer(serializedValue, 0, serializedValue.length);\n        final T value = serializer.deserialize(deser);\n        if (deser.available() > 0) {\n            throw new IOException(\n                    \"Unconsumed bytes in the deserialized value. \"\n                            + \"This indicates a mismatch in the value serializers \"\n                            + \"used by the KvState instance and this access.\");\n        }\n        return value;\n    }\n}", "summary_tokens": ["deserializes", "the", "value", "with", "the", "given", "serializer"], "project": "flink"}
{"id": 338, "code": "private static ColumnStatisticsData getColumnStatisticsData(\n        DataType colType, CatalogColumnStatisticsDataBase colStat, String hiveVersion) {\n    LogicalTypeRoot type = colType.getLogicalType().getTypeRoot();\n    if (type.equals(LogicalTypeRoot.CHAR) || type.equals(LogicalTypeRoot.VARCHAR)) {\n        if (colStat instanceof CatalogColumnStatisticsDataString) {\n            CatalogColumnStatisticsDataString stringColStat =\n                    (CatalogColumnStatisticsDataString) colStat;\n            StringColumnStatsData hiveStringColumnStats = new StringColumnStatsData();\n            hiveStringColumnStats.clear();\n            if (null != stringColStat.getMaxLength()) {\n                hiveStringColumnStats.setMaxColLen(stringColStat.getMaxLength());\n            }\n            if (null != stringColStat.getAvgLength()) {\n                hiveStringColumnStats.setAvgColLen(stringColStat.getAvgLength());\n            }\n            if (null != stringColStat.getNullCount()) {\n                hiveStringColumnStats.setNumNulls(stringColStat.getNullCount());\n            }\n            if (null != stringColStat.getNdv()) {\n                hiveStringColumnStats.setNumDVs(stringColStat.getNdv());\n            }\n            return ColumnStatisticsData.stringStats(hiveStringColumnStats);\n        }\n    } else if (type.equals(LogicalTypeRoot.BOOLEAN)) {\n        if (colStat instanceof CatalogColumnStatisticsDataBoolean) {\n            CatalogColumnStatisticsDataBoolean booleanColStat =\n                    (CatalogColumnStatisticsDataBoolean) colStat;\n            BooleanColumnStatsData hiveBoolStats = new BooleanColumnStatsData();\n            hiveBoolStats.clear();\n            if (null != booleanColStat.getTrueCount()) {\n                hiveBoolStats.setNumTrues(booleanColStat.getTrueCount());\n            }\n            if (null != booleanColStat.getFalseCount()) {\n                hiveBoolStats.setNumFalses(booleanColStat.getFalseCount());\n            }\n            if (null != booleanColStat.getNullCount()) {\n                hiveBoolStats.setNumNulls(booleanColStat.getNullCount());\n            }\n            return ColumnStatisticsData.booleanStats(hiveBoolStats);\n        }\n    } else if (type.equals(LogicalTypeRoot.TINYINT)\n            || type.equals(LogicalTypeRoot.SMALLINT)\n            || type.equals(LogicalTypeRoot.INTEGER)\n            || type.equals(LogicalTypeRoot.BIGINT)\n            || type.equals(LogicalTypeRoot.TIMESTAMP_WITH_LOCAL_TIME_ZONE)\n            || type.equals(LogicalTypeRoot.TIME_WITHOUT_TIME_ZONE)\n            || type.equals(LogicalTypeRoot.TIMESTAMP_WITH_TIME_ZONE)) {\n        if (colStat instanceof CatalogColumnStatisticsDataLong) {\n            CatalogColumnStatisticsDataLong longColStat =\n                    (CatalogColumnStatisticsDataLong) colStat;\n            LongColumnStatsData hiveLongColStats = new LongColumnStatsData();\n            hiveLongColStats.clear();\n            if (null != longColStat.getMax()) {\n                hiveLongColStats.setHighValue(longColStat.getMax());\n            }\n            if (null != longColStat.getMin()) {\n                hiveLongColStats.setLowValue(longColStat.getMin());\n            }\n            if (null != longColStat.getNdv()) {\n                hiveLongColStats.setNumDVs(longColStat.getNdv());\n            }\n            if (null != longColStat.getNullCount()) {\n                hiveLongColStats.setNumNulls(longColStat.getNullCount());\n            }\n            return ColumnStatisticsData.longStats(hiveLongColStats);\n        }\n    } else if (type.equals(LogicalTypeRoot.FLOAT) || type.equals(LogicalTypeRoot.DOUBLE)) {\n        if (colStat instanceof CatalogColumnStatisticsDataDouble) {\n            CatalogColumnStatisticsDataDouble doubleColumnStatsData =\n                    (CatalogColumnStatisticsDataDouble) colStat;\n            DoubleColumnStatsData hiveFloatStats = new DoubleColumnStatsData();\n            hiveFloatStats.clear();\n            if (null != doubleColumnStatsData.getMax()) {\n                hiveFloatStats.setHighValue(doubleColumnStatsData.getMax());\n            }\n            if (null != doubleColumnStatsData.getMin()) {\n                hiveFloatStats.setLowValue(doubleColumnStatsData.getMin());\n            }\n            if (null != doubleColumnStatsData.getNullCount()) {\n                hiveFloatStats.setNumNulls(doubleColumnStatsData.getNullCount());\n            }\n            if (null != doubleColumnStatsData.getNdv()) {\n                hiveFloatStats.setNumDVs(doubleColumnStatsData.getNdv());\n            }\n            return ColumnStatisticsData.doubleStats(hiveFloatStats);\n        }\n    } else if (type.equals(LogicalTypeRoot.DATE)) {\n        if (colStat instanceof CatalogColumnStatisticsDataDate) {\n            HiveShim hiveShim = HiveShimLoader.loadHiveShim(hiveVersion);\n            return hiveShim.toHiveDateColStats((CatalogColumnStatisticsDataDate) colStat);\n        }\n    } else if (type.equals(LogicalTypeRoot.VARBINARY) || type.equals(LogicalTypeRoot.BINARY)) {\n        if (colStat instanceof CatalogColumnStatisticsDataBinary) {\n            CatalogColumnStatisticsDataBinary binaryColumnStatsData =\n                    (CatalogColumnStatisticsDataBinary) colStat;\n            BinaryColumnStatsData hiveBinaryColumnStats = new BinaryColumnStatsData();\n            hiveBinaryColumnStats.clear();\n            if (null != binaryColumnStatsData.getMaxLength()) {\n                hiveBinaryColumnStats.setMaxColLen(binaryColumnStatsData.getMaxLength());\n            }\n            if (null != binaryColumnStatsData.getAvgLength()) {\n                hiveBinaryColumnStats.setAvgColLen(binaryColumnStatsData.getAvgLength());\n            }\n            if (null != binaryColumnStatsData.getNullCount()) {\n                hiveBinaryColumnStats.setNumNulls(binaryColumnStatsData.getNullCount());\n            }\n            return ColumnStatisticsData.binaryStats(hiveBinaryColumnStats);\n        }\n    } else if (type.equals(LogicalTypeRoot.DECIMAL)) {\n        if (colStat instanceof CatalogColumnStatisticsDataDouble) {\n            CatalogColumnStatisticsDataDouble flinkStats =\n                    (CatalogColumnStatisticsDataDouble) colStat;\n            DecimalColumnStatsData hiveStats = new DecimalColumnStatsData();\n            if (flinkStats.getMax() != null) {\n                    \n                    \n                hiveStats.setHighValue(\n                        toThriftDecimal(\n                                HiveDecimal.create(BigDecimal.valueOf(flinkStats.getMax()))));\n            }\n            if (flinkStats.getMin() != null) {\n                hiveStats.setLowValue(\n                        toThriftDecimal(\n                                HiveDecimal.create(BigDecimal.valueOf(flinkStats.getMin()))));\n            }\n            if (flinkStats.getNdv() != null) {\n                hiveStats.setNumDVs(flinkStats.getNdv());\n            }\n            if (flinkStats.getNullCount() != null) {\n                hiveStats.setNumNulls(flinkStats.getNullCount());\n            }\n            return ColumnStatisticsData.decimalStats(hiveStats);\n        }\n    }\n    throw new CatalogException(\n            String.format(\n                    \"Flink does not support converting ColumnStats '%s' for Hive column \"\n                            + \"type '%s' yet\",\n                    colStat, colType));\n}", "summary_tokens": ["convert", "flink", "column", "stats", "to", "hive", "column", "statistics", "data", "according", "to", "hive", "column", "type"], "project": "flink"}
{"id": 858, "code": "public RecordQueue<T> getQueue(int producerIndex) {\n    return queues.computeIfAbsent(\n            producerIndex,\n            (key) -> {\n                AsyncRecordQueue<T> q = new AsyncRecordQueue<>(producerIndex);\n                emptyQueues.put(q, false);\n                return q;\n            });\n}", "summary_tokens": ["the", "queue", "for", "the", "given", "producer", "i"], "project": "flink"}
{"id": 1957, "code": "public static Optional<Throwable> findThrowable(\n        Throwable throwable, Predicate<Throwable> predicate) {\n    if (throwable == null || predicate == null) {\n        return Optional.empty();\n    }\n\n    Throwable t = throwable;\n    while (t != null) {\n        if (predicate.test(t)) {\n            return Optional.of(t);\n        } else {\n            t = t.getCause();\n        }\n    }\n\n    return Optional.empty();\n}", "summary_tokens": ["checks", "whether", "a", "throwable", "chain", "contains", "an", "exception", "matching", "a", "predicate", "and", "returns", "it"], "project": "flink"}
{"id": 2720, "code": "public static String getKeyFromArgs(String[] args, int index) {\n    String key;\n    if (args[index].startsWith(\"--\")) {\n        key = args[index].substring(2);\n    } else if (args[index].startsWith(\"-\")) {\n        key = args[index].substring(1);\n    } else {\n        throw new IllegalArgumentException(\n                String.format(\n                        \"Error parsing arguments '%s' on '%s'. Please prefix keys with -- or -.\",\n                        Arrays.toString(args), args[index]));\n    }\n\n    if (key.isEmpty()) {\n        throw new IllegalArgumentException(\n                \"The input \" + Arrays.toString(args) + \" contains an empty argument\");\n    }\n\n    return key;\n}", "summary_tokens": ["get", "the", "key", "from", "the", "given", "args"], "project": "flink"}
{"id": 7047, "code": "public int getId() {\n    return transformation.getId();\n}", "summary_tokens": ["returns", "the", "id", "of", "the", "data", "stream", "in", "the", "current", "stream", "execution", "environment"], "project": "flink"}
{"id": 334, "code": "public FunctionDefinition createFunctionDefinitionFromHiveFunction(\n        String name, String functionClassName) {\n    Class clazz;\n    try {\n        clazz = Thread.currentThread().getContextClassLoader().loadClass(functionClassName);\n\n        LOG.info(\"Successfully loaded Hive udf '{}' with class '{}'\", name, functionClassName);\n    } catch (ClassNotFoundException e) {\n        throw new TableException(\n                String.format(\"Failed to initiate an instance of class %s.\", functionClassName),\n                e);\n    }\n\n    if (UDF.class.isAssignableFrom(clazz)) {\n        LOG.info(\"Transforming Hive function '{}' into a HiveSimpleUDF\", name);\n\n        return new HiveSimpleUDF(new HiveFunctionWrapper<>(functionClassName), hiveShim);\n    } else if (GenericUDF.class.isAssignableFrom(clazz)) {\n        LOG.info(\"Transforming Hive function '{}' into a HiveGenericUDF\", name);\n\n        return new HiveGenericUDF(new HiveFunctionWrapper<>(functionClassName), hiveShim);\n    } else if (GenericUDTF.class.isAssignableFrom(clazz)) {\n        LOG.info(\"Transforming Hive function '{}' into a HiveGenericUDTF\", name);\n\n        HiveGenericUDTF udtf =\n                new HiveGenericUDTF(new HiveFunctionWrapper<>(functionClassName), hiveShim);\n\n        return new TableFunctionDefinition(name, udtf, GenericTypeInfo.of(Row.class));\n    } else if (GenericUDAFResolver2.class.isAssignableFrom(clazz)\n            || UDAF.class.isAssignableFrom(clazz)) {\n        HiveGenericUDAF udaf;\n\n        if (GenericUDAFResolver2.class.isAssignableFrom(clazz)) {\n            LOG.info(\n                    \"Transforming Hive function '{}' into a HiveGenericUDAF without UDAF bridging\",\n                    name);\n\n            udaf =\n                    new HiveGenericUDAF(\n                            new HiveFunctionWrapper<>(functionClassName), false, hiveShim);\n        } else {\n            LOG.info(\n                    \"Transforming Hive function '{}' into a HiveGenericUDAF with UDAF bridging\",\n                    name);\n\n            udaf =\n                    new HiveGenericUDAF(\n                            new HiveFunctionWrapper<>(functionClassName), true, hiveShim);\n        }\n\n        return new AggregateFunctionDefinition(\n                name,\n                udaf,\n                GenericTypeInfo.of(Object.class),\n                GenericTypeInfo.of(GenericUDAFEvaluator.AggregationBuffer.class));\n    } else {\n        throw new IllegalArgumentException(\n                String.format(\n                        \"HiveFunctionDefinitionFactory cannot initiate FunctionDefinition for class %s\",\n                        functionClassName));\n    }\n}", "summary_tokens": ["create", "a", "function", "definition", "from", "a", "hive", "function", "s", "class", "name"], "project": "flink"}
{"id": 5854, "code": "private void testPutStreamSuccessfulGet(\n        @Nullable JobID jobId1, @Nullable JobID jobId2, BlobKey.BlobType blobType)\n        throws IOException {\n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore())) {\n\n        server.start();\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n        byte[] data2 = Arrays.copyOfRange(data, 10, 54);\n\n            \n        BlobKey key1a = put(server, jobId1, new ByteArrayInputStream(data), blobType);\n        assertNotNull(key1a);\n            \n        BlobKey key1a2 = put(server, jobId1, new ByteArrayInputStream(data), blobType);\n        assertNotNull(key1a2);\n        verifyKeyDifferentHashEquals(key1a, key1a2);\n\n        BlobKey key1b = put(server, jobId1, new ByteArrayInputStream(data2), blobType);\n        assertNotNull(key1b);\n\n        verifyContents(server, jobId1, key1a, data);\n        verifyContents(server, jobId1, key1a2, data);\n        verifyContents(server, jobId1, key1b, data2);\n\n            \n        BlobKey key2a = put(server, jobId2, new ByteArrayInputStream(data), blobType);\n        assertNotNull(key2a);\n        verifyKeyDifferentHashEquals(key1a, key2a);\n\n        BlobKey key2b = put(server, jobId2, new ByteArrayInputStream(data2), blobType);\n        assertNotNull(key2b);\n        verifyKeyDifferentHashEquals(key1b, key2b);\n\n            \n        verifyContents(server, jobId2, key2a, data);\n        verifyContents(server, jobId2, key2b, data2);\n\n            \n            \n        verifyContents(server, jobId1, key1a, data);\n        verifyContents(server, jobId1, key1a2, data);\n        verifyContents(server, jobId1, key1b, data2);\n        verifyContents(server, jobId2, key2a, data);\n        verifyContents(server, jobId2, key2b, data2);\n    }\n}", "summary_tokens": ["uploads", "two", "file", "streams", "for", "different", "jobs", "into", "the", "server", "via", "the", "blob", "server"], "project": "flink"}
{"id": 4486, "code": "public void destroy() {\n    synchronized (buffers) {\n        destroyed = true;\n\n        buffers.clear();\n        buffers.notifyAll();\n    }\n}", "summary_tokens": ["destroys", "this", "buffer", "pool", "and", "after", "which", "no", "buffer", "can", "be", "allocated", "any", "more"], "project": "flink"}
{"id": 1951, "code": "public static void rethrow(Throwable t, String parentMessage) {\n    if (t instanceof Error) {\n        throw (Error) t;\n    } else if (t instanceof RuntimeException) {\n        throw (RuntimeException) t;\n    } else {\n        throw new RuntimeException(parentMessage, t);\n    }\n}", "summary_tokens": ["throws", "the", "given", "throwable", "in", "scenarios", "where", "the", "signatures", "do", "not", "allow", "you", "to", "throw", "an", "arbitrary", "throwable"], "project": "flink"}
{"id": 2908, "code": "public void checkInputSplits() throws IOException {\n    FileInputSplit[] inputSplits = this.createInputFormat().createInputSplits(0);\n    Arrays.sort(inputSplits, new InputSplitSorter());\n\n    int splitIndex = 0;\n    for (int fileIndex = 0; fileIndex < this.parallelism; fileIndex++) {\n        List<FileInputSplit> sameFileSplits = new ArrayList<FileInputSplit>();\n        Path lastPath = inputSplits[splitIndex].getPath();\n        for (; splitIndex < inputSplits.length; splitIndex++) {\n            if (!inputSplits[splitIndex].getPath().equals(lastPath)) {\n                break;\n            }\n            sameFileSplits.add(inputSplits[splitIndex]);\n        }\n\n        Assert.assertEquals(this.getExpectedBlockCount(fileIndex), sameFileSplits.size());\n\n        long lastBlockLength =\n                this.rawDataSizes[fileIndex] % (this.blockSize - getInfoSize()) + getInfoSize();\n        for (int index = 0; index < sameFileSplits.size(); index++) {\n            Assert.assertEquals(this.blockSize * index, sameFileSplits.get(index).getStart());\n            if (index < sameFileSplits.size() - 1) {\n                Assert.assertEquals(this.blockSize, sameFileSplits.get(index).getLength());\n            }\n        }\n        Assert.assertEquals(\n                lastBlockLength, sameFileSplits.get(sameFileSplits.size() - 1).getLength());\n    }\n}", "summary_tokens": ["checks", "if", "the", "expected", "input", "splits", "were", "created"], "project": "flink"}
{"id": 3040, "code": "public static NoSkipStrategy noSkip() {\n    return NoSkipStrategy.INSTANCE;\n}", "summary_tokens": ["every", "possible", "match", "will", "be", "emitted"], "project": "flink"}
{"id": 8338, "code": "public static void setFloat(MemorySegment[] segments, int offset, float value) {\n    if (inFirstSegment(segments, offset, 4)) {\n        segments[0].putFloat(offset, value);\n    } else {\n        setFloatMultiSegments(segments, offset, value);\n    }\n}", "summary_tokens": ["set", "float", "from", "segments"], "project": "flink"}
{"id": 9653, "code": "public void testDisabledTimestamps() throws Exception {\n    final int numElements = 10;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    env.setParallelism(PARALLELISM);\n\n    DataStream<Integer> source1 = env.addSource(new MyNonWatermarkingSource(numElements));\n    DataStream<Integer> source2 = env.addSource(new MyNonWatermarkingSource(numElements));\n\n    source1.map(new IdentityMap())\n            .connect(source2)\n            .map(new IdentityCoMap())\n            .transform(\n                    \"Custom Operator\",\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    new DisabledTimestampCheckingOperator())\n            .addSink(new DiscardingSink<Integer>());\n\n    env.execute();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "timestamps", "when", "the", "source", "doesn", "t", "emit", "them", "with", "the", "records"], "project": "flink"}
{"id": 4501, "code": "public void close() throws IOException {\n        \n    synchronized (this.closeLock) {\n        if (this.closed) {\n            return;\n        }\n        this.closed = true;\n\n        try {\n                \n                \n            while (this.requestsNotReturned.get() > 0) {\n                try {\n                        \n                        \n                        \n                    this.closeLock.wait(1000);\n                    checkErroneous();\n                } catch (InterruptedException iex) {\n                    throw new IOException(\n                            \"Closing of asynchronous file channel was interrupted.\");\n                }\n            }\n\n                \n            checkErroneous();\n        } finally {\n                \n            if (this.fileChannel.isOpen()) {\n                this.fileChannel.close();\n            }\n        }\n    }\n}", "summary_tokens": ["closes", "the", "channel", "and", "waits", "until", "all", "pending", "asynchronous", "requests", "are", "processed"], "project": "flink"}
{"id": 7719, "code": "public void testChangedOperatorName() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();\n    env.addSource(new NoOpSourceFunction(), \"A\").map(new NoOpMapFunction());\n    JobGraph jobGraph = env.getStreamGraph().getJobGraph();\n\n    JobVertexID expected = jobGraph.getVerticesAsArray()[0].getID();\n\n    env = StreamExecutionEnvironment.createLocalEnvironment();\n    env.addSource(new NoOpSourceFunction(), \"B\").map(new NoOpMapFunction());\n    jobGraph = env.getStreamGraph().getJobGraph();\n\n    JobVertexID actual = jobGraph.getVerticesAsArray()[0].getID();\n\n    assertEquals(expected, actual);\n}", "summary_tokens": ["tests", "that", "a", "changed", "operator", "name", "does", "not", "affect", "the", "hash"], "project": "flink"}
{"id": 9161, "code": "protected int maxNumPartition() {\n    return (internalPool.freePages() + buildSpillRetBufferNumbers) / 2;\n}", "summary_tokens": ["bucket", "area", "need", "at", "least", "one", "and", "data", "need", "at", "least", "one"], "project": "flink"}
{"id": 8178, "code": "public static TypeInformation<?> PRIMITIVE_ARRAY(TypeInformation<?> elementType) {\n    if (elementType.equals(BOOLEAN())) {\n        return PrimitiveArrayTypeInfo.BOOLEAN_PRIMITIVE_ARRAY_TYPE_INFO;\n    } else if (elementType.equals(BYTE())) {\n        return PrimitiveArrayTypeInfo.BYTE_PRIMITIVE_ARRAY_TYPE_INFO;\n    } else if (elementType.equals(SHORT())) {\n        return PrimitiveArrayTypeInfo.SHORT_PRIMITIVE_ARRAY_TYPE_INFO;\n    } else if (elementType.equals(INT())) {\n        return PrimitiveArrayTypeInfo.INT_PRIMITIVE_ARRAY_TYPE_INFO;\n    } else if (elementType.equals(LONG())) {\n        return PrimitiveArrayTypeInfo.LONG_PRIMITIVE_ARRAY_TYPE_INFO;\n    } else if (elementType.equals(FLOAT())) {\n        return PrimitiveArrayTypeInfo.FLOAT_PRIMITIVE_ARRAY_TYPE_INFO;\n    } else if (elementType.equals(DOUBLE())) {\n        return PrimitiveArrayTypeInfo.DOUBLE_PRIMITIVE_ARRAY_TYPE_INFO;\n    }\n    throw new TableException(\n            String.format(\n                    \"%s cannot be an element of a primitive array. Only Java primitive types are supported.\",\n                    elementType));\n}", "summary_tokens": ["generates", "type", "information", "for", "an", "array", "consisting", "of", "java", "primitive", "elements"], "project": "flink"}
{"id": 5762, "code": "private void testDeleteTransientAlreadyDeleted(@Nullable final JobID jobId) throws IOException {\n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n\n            \n        TransientBlobKey key = (TransientBlobKey) put(server, jobId, data, TRANSIENT_BLOB);\n        assertNotNull(key);\n\n        File blobFile = server.getStorageLocation(jobId, key);\n        assertTrue(blobFile.delete());\n\n            \n        assertTrue(delete(cache, jobId, key));\n        verifyDeleted(cache, jobId, key);\n\n            \n        assertTrue(delete(cache, jobId, key));\n        verifyDeleted(cache, jobId, key);\n    }\n}", "summary_tokens": ["uploads", "a", "byte", "array", "for", "the", "given", "job", "and", "verifies", "that", "deleting", "it", "via", "the", "blob", "cache", "service", "does", "not", "fail", "independent", "of", "whether", "the", "file", "exists"], "project": "flink"}
{"id": 3699, "code": "public TypeComparatorFactory<?> getLocalStrategyComparator() {\n    return localStrategyComparator;\n}", "summary_tokens": ["gets", "the", "local", "strategy", "comparator", "from", "this", "channel"], "project": "flink"}
{"id": 978, "code": "public void testCorrelationIdNotSet() throws InterruptedException {\n    generateCorrelationIds = false;\n    source.autoAck = false;\n    sourceThread.start();\n\n    sourceThread.join();\n\n    assertNotNull(exception);\n    assertTrue(exception instanceof NullPointerException);\n}", "summary_tokens": ["tests", "error", "reporting", "in", "case", "of", "invalid", "correlation", "ids"], "project": "flink"}
{"id": 5444, "code": "static SequenceNumberRange generic(SequenceNumber from, SequenceNumber to) {\n    return new GenericSequenceNumberRange(\n            (GenericSequenceNumber) from, (GenericSequenceNumber) to);\n}", "summary_tokens": ["from", "inclusive", "to", "exclusive"], "project": "flink"}
{"id": 1417, "code": "public String getLocation() {\n    return location;\n}", "summary_tokens": ["the", "location", "of", "the", "subtask", "that", "runs", "this", "source", "reader"], "project": "flink"}
{"id": 6400, "code": "public void testRegisterJobMaster() throws Exception {\n        \n    CompletableFuture<RegistrationResponse> successfulFuture =\n            resourceManagerGateway.registerJobMaster(\n                    jobMasterGateway.getFencingToken(),\n                    jobMasterResourceId,\n                    jobMasterGateway.getAddress(),\n                    jobId,\n                    TIMEOUT);\n    RegistrationResponse response =\n            successfulFuture.get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);\n    assertTrue(response instanceof JobMasterRegistrationSuccess);\n}", "summary_tokens": ["test", "receive", "normal", "registration", "from", "job", "master", "and", "receive", "duplicate", "registration", "from", "job", "master"], "project": "flink"}
{"id": 2270, "code": "public @Nullable RestClusterClient<StandaloneClusterId> getRestClusterClient() {\n    return this.restClusterClient;\n}", "summary_tokens": ["gets", "rest", "client", "connected", "to", "job", "manager"], "project": "flink"}
{"id": 427, "code": "public void addTranslation(HiveParserASTNode node, String replacementText) {\n    if (!enabled) {\n        return;\n    }\n\n    if (node.getOrigin() != null) {\n            \n            \n            \n        return;\n    }\n\n    int tokenStartIndex = node.getTokenStartIndex();\n    int tokenStopIndex = node.getTokenStopIndex();\n    if (tokenStopIndex < 0) {\n            \n        return;\n    }\n    Translation translation = new Translation();\n    translation.tokenStopIndex = tokenStopIndex;\n    translation.replacementText = replacementText;\n\n        \n    assert (tokenStopIndex >= tokenStartIndex);\n\n    List<Integer> subsetEntries = new ArrayList<>();\n        \n    for (Map.Entry<Integer, Translation> existingEntry :\n            translations.headMap(tokenStopIndex, true).entrySet()) {\n            \n        if (existingEntry.getValue().tokenStopIndex <= tokenStopIndex\n                && existingEntry.getKey() >= tokenStartIndex) {\n                \n            assert (replacementText.contains(existingEntry.getValue().replacementText));\n            subsetEntries.add(existingEntry.getKey());\n                \n        } else if (existingEntry.getValue().tokenStopIndex >= tokenStopIndex\n                && existingEntry.getKey() <= tokenStartIndex) {\n            assert (existingEntry.getValue().replacementText.contains(replacementText));\n                \n            return;\n        }\n    }\n        \n    for (Integer index : subsetEntries) {\n        translations.remove(index);\n    }\n\n        \n    translations.put(tokenStartIndex, translation);\n}", "summary_tokens": ["register", "a", "translation", "to", "be", "performed", "as", "part", "of", "unparse"], "project": "flink"}
{"id": 4808, "code": "public CompletableFuture<Acknowledge> updateTaskExecutionState(\n        final TaskExecutionState taskExecutionState) {\n    FlinkException taskExecutionException;\n    try {\n        checkNotNull(taskExecutionState, \"taskExecutionState\");\n\n        if (schedulerNG.updateTaskExecutionState(taskExecutionState)) {\n            return CompletableFuture.completedFuture(Acknowledge.get());\n        } else {\n            taskExecutionException =\n                    new ExecutionGraphException(\n                            \"The execution attempt \"\n                                    + taskExecutionState.getID()\n                                    + \" was not found.\");\n        }\n    } catch (Exception e) {\n        taskExecutionException =\n                new JobMasterException(\n                        \"Could not update the state of task execution for JobMaster.\", e);\n        handleJobMasterError(taskExecutionException);\n    }\n    return FutureUtils.completedExceptionally(taskExecutionException);\n}", "summary_tokens": ["updates", "the", "task", "execution", "state", "for", "a", "given", "task"], "project": "flink"}
{"id": 6790, "code": "public static long getNextIndexNode(MemorySegment memorySegment, int offset, int level) {\n    return memorySegment.getLong(offset + INDEX_NEXT_OFFSET_BY_LEVEL_ARRAY[level]);\n}", "summary_tokens": ["returns", "next", "key", "pointer", "on", "the", "given", "index", "level"], "project": "flink"}
{"id": 5012, "code": "protected HashPartition<BT, PT> getNewInMemoryPartition(int number, int recursionLevel) {\n    return new HashPartition<BT, PT>(\n            this.buildSideSerializer,\n            this.probeSideSerializer,\n            number,\n            recursionLevel,\n            this.availableMemory.remove(this.availableMemory.size() - 1),\n            this,\n            this.segmentSize);\n}", "summary_tokens": ["returns", "a", "new", "in", "memory", "partition", "object"], "project": "flink"}
{"id": 8993, "code": "private List<Integer> getAffectedArgs(AggregateCall aggCall) {\n    if (aggCall.getAggregation() instanceof SqlJsonObjectAggAggFunction) {\n            \n        final int valueIndex = aggCall.getArgList().get(1);\n        return Collections.singletonList(valueIndex);\n    }\n\n    return aggCall.getArgList().stream().distinct().collect(Collectors.toList());\n}", "summary_tokens": ["returns", "the", "aggregation", "s", "arguments", "which", "need", "to", "be", "wrapped"], "project": "flink"}
{"id": 3112, "code": "public void writeStartingNewPatternAfterMigrationSnapshot() throws Exception {\n\n    KeySelector<Event, Integer> keySelector =\n            new KeySelector<Event, Integer>() {\n                private static final long serialVersionUID = -4873366487571254798L;\n\n                @Override\n                public Integer getKey(Event value) throws Exception {\n                    return value.getId();\n                }\n            };\n\n    final Event startEvent1 = new Event(42, \"start\", 1.0);\n    final SubEvent middleEvent1 = new SubEvent(42, \"foo1\", 1.0, 10.0);\n\n    OneInputStreamOperatorTestHarness<Event, Map<String, List<Event>>> harness =\n            new KeyedOneInputStreamOperatorTestHarness<>(\n                    CepOperatorTestUtilities.getKeyedCepOperator(false, new NFAFactory()),\n                    keySelector,\n                    BasicTypeInfo.INT_TYPE_INFO);\n\n    try {\n        harness.setup();\n        harness.open();\n        harness.processElement(new StreamRecord<Event>(startEvent1, 1));\n        harness.processElement(new StreamRecord<Event>(new Event(42, \"foobar\", 1.0), 2));\n        harness.processElement(\n                new StreamRecord<Event>(new SubEvent(42, \"barfoo\", 1.0, 5.0), 3));\n        harness.processElement(new StreamRecord<Event>(middleEvent1, 2));\n        harness.processWatermark(new Watermark(5));\n\n            \n        OperatorSubtaskState snapshot = harness.snapshot(0L, 0L);\n        OperatorSnapshotUtil.writeStateHandle(\n                snapshot,\n                \"src/test/resources/cep-migration-starting-new-pattern-flink\"\n                        + flinkGenerateSavepointVersion\n                        + \"-snapshot\");\n    } finally {\n        harness.close();\n    }\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 2750, "code": "public DataSink<T> withParameters(Configuration parameters) {\n    this.parameters = parameters;\n    return this;\n}", "summary_tokens": ["pass", "a", "configuration", "to", "the", "output", "format"], "project": "flink"}
{"id": 790, "code": "public long getDeregisterStreamBaseBackoffMillis() {\n    return deregisterStreamBaseBackoffMillis;\n}", "summary_tokens": ["get", "base", "backoff", "millis", "for", "the", "deregister", "stream", "operation"], "project": "flink"}
{"id": 9004, "code": "public List<String> getNames() {\n    return names;\n}", "summary_tokens": ["returns", "the", "table", "path", "in", "the", "rel", "opt", "schema"], "project": "flink"}
{"id": 178, "code": "public static <IN> CassandraSinkBuilder<IN> addSink(DataStream<IN> input) {\n    TypeInformation<IN> typeInfo = input.getType();\n    if (typeInfo instanceof TupleTypeInfo) {\n        DataStream<Tuple> tupleInput = (DataStream<Tuple>) input;\n        return (CassandraSinkBuilder<IN>)\n                new CassandraTupleSinkBuilder<>(\n                        tupleInput,\n                        tupleInput.getType(),\n                        tupleInput\n                                .getType()\n                                .createSerializer(\n                                        tupleInput.getExecutionEnvironment().getConfig()));\n    }\n    if (typeInfo instanceof RowTypeInfo) {\n        DataStream<Row> rowInput = (DataStream<Row>) input;\n        return (CassandraSinkBuilder<IN>)\n                new CassandraRowSinkBuilder(\n                        rowInput,\n                        rowInput.getType(),\n                        rowInput.getType()\n                                .createSerializer(\n                                        rowInput.getExecutionEnvironment().getConfig()));\n    }\n    if (typeInfo instanceof PojoTypeInfo) {\n        return new CassandraPojoSinkBuilder<>(\n                input,\n                input.getType(),\n                input.getType().createSerializer(input.getExecutionEnvironment().getConfig()));\n    }\n    if (typeInfo instanceof CaseClassTypeInfo) {\n        DataStream<Product> productInput = (DataStream<Product>) input;\n        return (CassandraSinkBuilder<IN>)\n                new CassandraScalaProductSinkBuilder<>(\n                        productInput,\n                        productInput.getType(),\n                        productInput\n                                .getType()\n                                .createSerializer(input.getExecutionEnvironment().getConfig()));\n    }\n    throw new IllegalArgumentException(\n            \"No support for the type of the given DataStream: \" + input.getType());\n}", "summary_tokens": ["writes", "a", "data", "stream", "into", "a", "cassandra", "database"], "project": "flink"}
{"id": 2261, "code": "static KafkaResource get(final String version) {\n    return FactoryUtils.loadAndInvokeFactory(\n            KafkaResourceFactory.class,\n            factory -> factory.create(version),\n            LocalStandaloneKafkaResourceFactory::new);\n}", "summary_tokens": ["returns", "the", "configured", "kafka", "resource", "implementation", "or", "a", "local", "standalone", "kafka", "resource", "if", "none", "is", "configured"], "project": "flink"}
{"id": 609, "code": "protected static void setField(Object object, String fieldName, Object value) {\n    try {\n        Field field = object.getClass().getDeclaredField(fieldName);\n        field.setAccessible(true);\n        field.set(object, value);\n    } catch (NoSuchFieldException | IllegalAccessException e) {\n        throw new RuntimeException(\"Incompatible KafkaProducer version\", e);\n    }\n}", "summary_tokens": ["sets", "the", "field", "field", "name", "on", "the", "given", "object", "object", "to", "value", "using", "reflection"], "project": "flink"}
{"id": 5912, "code": "public void testCheckpointHistory() throws Exception {\n    CheckpointStatsHistory history = new CheckpointStatsHistory(3);\n\n    history.addInProgressCheckpoint(createPendingCheckpointStats(0));\n\n    CheckpointStatsHistory snapshot = history.createSnapshot();\n    for (AbstractCheckpointStats stats : snapshot.getCheckpoints()) {\n        assertEquals(0, stats.getCheckpointId());\n        assertTrue(stats.getStatus().isInProgress());\n    }\n\n    history.addInProgressCheckpoint(createPendingCheckpointStats(1));\n    history.addInProgressCheckpoint(createPendingCheckpointStats(2));\n    history.addInProgressCheckpoint(createPendingCheckpointStats(3));\n\n    snapshot = history.createSnapshot();\n\n        \n    Iterator<AbstractCheckpointStats> it = snapshot.getCheckpoints().iterator();\n    for (int i = 3; i > 0; i--) {\n        assertTrue(it.hasNext());\n        AbstractCheckpointStats stats = it.next();\n        assertEquals(i, stats.getCheckpointId());\n        assertTrue(stats.getStatus().isInProgress());\n    }\n    assertFalse(it.hasNext());\n\n        \n    history.replacePendingCheckpointById(createFailedCheckpointStats(1));\n    history.replacePendingCheckpointById(createCompletedCheckpointStats(3));\n    history.replacePendingCheckpointById(createFailedCheckpointStats(2));\n\n    snapshot = history.createSnapshot();\n    it = snapshot.getCheckpoints().iterator();\n\n    assertTrue(it.hasNext());\n    AbstractCheckpointStats stats = it.next();\n    assertEquals(3, stats.getCheckpointId());\n    assertNotNull(snapshot.getCheckpointById(3));\n    assertTrue(stats.getStatus().isCompleted());\n    assertTrue(snapshot.getCheckpointById(3).getStatus().isCompleted());\n\n    assertTrue(it.hasNext());\n    stats = it.next();\n    assertEquals(2, stats.getCheckpointId());\n    assertNotNull(snapshot.getCheckpointById(2));\n    assertTrue(stats.getStatus().isFailed());\n    assertTrue(snapshot.getCheckpointById(2).getStatus().isFailed());\n\n    assertTrue(it.hasNext());\n    stats = it.next();\n    assertEquals(1, stats.getCheckpointId());\n    assertNotNull(snapshot.getCheckpointById(1));\n    assertTrue(stats.getStatus().isFailed());\n    assertTrue(snapshot.getCheckpointById(1).getStatus().isFailed());\n\n    assertFalse(it.hasNext());\n}", "summary_tokens": ["tests", "the", "checkpoint", "history", "with", "multiple", "checkpoints"], "project": "flink"}
{"id": 2631, "code": "public <R> MapOperator<T, R> map(MapFunction<T, R> mapper) {\n    if (mapper == null) {\n        throw new NullPointerException(\"Map function must not be null.\");\n    }\n\n    String callLocation = Utils.getCallLocationName();\n    TypeInformation<R> resultType =\n            TypeExtractor.getMapReturnTypes(mapper, getType(), callLocation, true);\n    return new MapOperator<>(this, resultType, clean(mapper), callLocation);\n}", "summary_tokens": ["applies", "a", "map", "transformation", "on", "this", "data", "set"], "project": "flink"}
{"id": 2441, "code": "public static <T extends SpecificRecord>\n        ConfluentRegistryAvroDeserializationSchema<T> forSpecific(\n                Class<T> tClass,\n                String url,\n                int identityMapCapacity,\n                @Nullable Map<String, ?> registryConfigs) {\n    return new ConfluentRegistryAvroDeserializationSchema<>(\n            tClass,\n            null,\n            new CachedSchemaCoderProvider(null, url, identityMapCapacity, registryConfigs));\n}", "summary_tokens": ["creates", "avro", "deserialization", "schema", "that", "produces", "classes", "that", "were", "generated", "from", "avro", "schema", "and", "looks", "up", "the", "writer", "schema", "in", "the", "confluent", "schema", "registry"], "project": "flink"}
{"id": 8103, "code": "public static boolean isFunctionOfKind(Expression expression, FunctionKind kind) {\n    if (expression instanceof UnresolvedCallExpression) {\n        return ((UnresolvedCallExpression) expression).getFunctionDefinition().getKind()\n                == kind;\n    }\n    if (expression instanceof CallExpression) {\n        return ((CallExpression) expression).getFunctionDefinition().getKind() == kind;\n    }\n    return false;\n}", "summary_tokens": ["checks", "if", "the", "expression", "is", "a", "function", "call", "of", "given", "type"], "project": "flink"}
{"id": 7705, "code": "public void testListStateUpdateNullEntries() throws Exception {\n    CheckpointableKeyedStateBackend<String> keyedBackend =\n            createKeyedBackend(StringSerializer.INSTANCE);\n\n    final ListStateDescriptor<Long> stateDescr =\n            new ListStateDescriptor<>(\"my-state\", Long.class);\n\n    try {\n        ListState<Long> state =\n                keyedBackend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, stateDescr);\n\n        keyedBackend.setCurrentKey(\"abc\");\n        assertNull(state.get());\n\n        expectedException.expect(NullPointerException.class);\n\n        List<Long> adding = new ArrayList<>();\n        adding.add(3L);\n        adding.add(null);\n        adding.add(5L);\n        state.update(adding);\n    } finally {\n        keyedBackend.close();\n        keyedBackend.dispose();\n    }\n}", "summary_tokens": ["this", "test", "verifies", "that", "all", "list", "state", "implementations", "are", "consistent", "in", "not", "allowing", "list", "state", "update", "list", "to", "be", "called", "with", "null", "entries", "in", "the", "list", "of", "entries", "to", "add"], "project": "flink"}
{"id": 8486, "code": "public ColumnStats merge(ColumnStats other) {\n    Long ndv = combineIfNonNull(Long::sum, this.ndv, other.ndv);\n    Long nullCount = combineIfNonNull(Long::sum, this.nullCount, other.nullCount);\n    Double avgLen = combineIfNonNull((a1, a2) -> (a1 + a2) / 2, this.avgLen, other.avgLen);\n    Integer maxLen = combineIfNonNull(Math::max, this.maxLen, other.maxLen);\n\n    Number maxValue =\n            combineIfNonNull(\n                    (n1, n2) -> n1.doubleValue() > n2.doubleValue() ? n1 : n2,\n                    this.maxValue,\n                    other.maxValue);\n    Number minValue =\n            combineIfNonNull(\n                    (n1, n2) -> n1.doubleValue() < n2.doubleValue() ? n1 : n2,\n                    this.minValue,\n                    other.minValue);\n\n    @SuppressWarnings(\"unchecked\")\n    Comparable max =\n            combineIfNonNull(\n                    (c1, c2) -> ((Comparable) c1).compareTo(c2) > 0 ? c1 : c2,\n                    this.max,\n                    other.max);\n    @SuppressWarnings(\"unchecked\")\n    Comparable min =\n            combineIfNonNull(\n                    (c1, c2) -> ((Comparable) c1).compareTo(c2) < 0 ? c1 : c2,\n                    this.min,\n                    other.min);\n\n    if (max != null || min != null) {\n        return new ColumnStats(ndv, nullCount, avgLen, maxLen, max, min);\n    } else {\n        return new ColumnStats(ndv, nullCount, avgLen, maxLen, maxValue, minValue);\n    }\n}", "summary_tokens": ["merges", "two", "column", "stats"], "project": "flink"}
{"id": 1081, "code": "public LinkedHashMap<Class<?>, SerializableSerializer<?>> getDefaultKryoSerializers() {\n    return defaultKryoSerializers;\n}", "summary_tokens": ["returns", "the", "registered", "default", "kryo", "serializers"], "project": "flink"}
{"id": 2618, "code": "public void writeMonitoringSourceSnapshot() throws Exception {\n\n    File testFolder = tempFolder.newFolder();\n\n    long fileModTime = Long.MIN_VALUE;\n    for (int i = 0; i < 1; i++) {\n        Tuple2<File, String> file =\n                createFileAndFillWithData(testFolder, \"file\", i, \"This is test line.\");\n        fileModTime = file.f0.lastModified();\n    }\n\n    TextInputFormat format = new TextInputFormat(new Path(testFolder.getAbsolutePath()));\n\n    final ContinuousFileMonitoringFunction<String> monitoringFunction =\n            new ContinuousFileMonitoringFunction<>(\n                    format, FileProcessingMode.PROCESS_CONTINUOUSLY, 1, INTERVAL);\n\n    StreamSource<TimestampedFileInputSplit, ContinuousFileMonitoringFunction<String>> src =\n            new StreamSource<>(monitoringFunction);\n\n    final AbstractStreamOperatorTestHarness<TimestampedFileInputSplit> testHarness =\n            new AbstractStreamOperatorTestHarness<>(src, 1, 1, 0);\n\n    testHarness.open();\n\n    final Throwable[] error = new Throwable[1];\n\n    final OneShotLatch latch = new OneShotLatch();\n\n        \n    Thread runner =\n            new Thread() {\n                @Override\n                public void run() {\n                    try {\n                        monitoringFunction.run(\n                                new DummySourceContext() {\n                                    @Override\n                                    public void collect(TimestampedFileInputSplit element) {\n                                        latch.trigger();\n                                    }\n\n                                    @Override\n                                    public void markAsTemporarilyIdle() {}\n                                });\n                    } catch (Throwable t) {\n                        t.printStackTrace();\n                        error[0] = t;\n                    }\n                }\n            };\n    runner.start();\n\n    if (!latch.isTriggered()) {\n        latch.await();\n    }\n\n    final OperatorSubtaskState snapshot;\n    synchronized (testHarness.getCheckpointLock()) {\n        snapshot = testHarness.snapshot(0L, 0L);\n    }\n\n    OperatorSnapshotUtil.writeStateHandle(\n            snapshot,\n            \"src/test/resources/monitoring-function-migration-test-\"\n                    + fileModTime\n                    + \"-flink\"\n                    + flinkGenerateSavepointVersion\n                    + \"-snapshot\");\n\n    monitoringFunction.cancel();\n    runner.join();\n\n    testHarness.close();\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 7058, "code": "public DataStream<T> shuffle() {\n    return setConnectionType(new ShufflePartitioner<T>());\n}", "summary_tokens": ["sets", "the", "partitioning", "of", "the", "data", "stream", "so", "that", "the", "output", "elements", "are", "shuffled", "uniformly", "randomly", "to", "the", "next", "operation"], "project": "flink"}
{"id": 9256, "code": "public Map.Entry<RowData, Collection<RowData>> lastEntry() {\n    return treeMap.lastEntry();\n}", "summary_tokens": ["returns", "the", "last", "entry", "in", "the", "buffer"], "project": "flink"}
{"id": 1202, "code": "protected static <U> Class<U>[] emptyClassArray() {\n    @SuppressWarnings(\"unchecked\")\n    Class<U>[] array = new Class[0];\n    return array;\n}", "summary_tokens": ["generic", "utility", "function", "that", "returns", "an", "empty", "class", "array"], "project": "flink"}
{"id": 2564, "code": "private static ColumnVector createHiveVectorFromConstant(\n        LogicalType type, Object value, int batchSize) {\n    switch (type.getTypeRoot()) {\n        case CHAR:\n        case VARCHAR:\n        case BINARY:\n        case VARBINARY:\n            return createBytesVector(batchSize, value);\n        case BOOLEAN:\n            return createLongVector(batchSize, (Boolean) value ? 1 : 0);\n        case TINYINT:\n        case SMALLINT:\n        case INTEGER:\n        case BIGINT:\n            return createLongVector(batchSize, value);\n        case DECIMAL:\n            DecimalType decimalType = (DecimalType) type;\n            return createDecimalVector(\n                    batchSize, decimalType.getPrecision(), decimalType.getScale(), value);\n        case FLOAT:\n        case DOUBLE:\n            return createDoubleVector(batchSize, value);\n        case DATE:\n            if (value instanceof LocalDate) {\n                value = Date.valueOf((LocalDate) value);\n            }\n            return createLongVector(batchSize, toInternal((Date) value));\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n            return createTimestampVector(batchSize, value);\n        default:\n            throw new UnsupportedOperationException(\"Unsupported type: \" + type);\n    }\n}", "summary_tokens": ["create", "a", "orc", "vector", "from", "partition", "spec", "value"], "project": "flink"}
{"id": 3773, "code": "public void testUnionWithTwoOutputs() throws Exception {\n\n        \n        \n        \n\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    DataSet<Tuple2<Long, Long>> src1 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src2 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src3 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src4 = env.fromElements(new Tuple2<>(0L, 0L));\n\n    DataSet<Tuple2<Long, Long>> union23 = src2.union(src3);\n    DataSet<Tuple2<Long, Long>> union123 = src1.union(union23);\n    DataSet<Tuple2<Long, Long>> union234 = src4.union(union23);\n\n    union123.groupBy(0)\n            .sum(1)\n            .name(\"1\")\n            .output(new DiscardingOutputFormat<Tuple2<Long, Long>>());\n    union234.groupBy(1)\n            .sum(0)\n            .name(\"2\")\n            .output(new DiscardingOutputFormat<Tuple2<Long, Long>>());\n\n        \n        \n        \n\n    OptimizedPlan optimizedPlan = compileNoStats(env.createProgramPlan());\n\n    OptimizerPlanNodeResolver resolver = getOptimizerPlanNodeResolver(optimizedPlan);\n\n    SingleInputPlanNode groupRed1 = resolver.getNode(\"1\");\n    SingleInputPlanNode groupRed2 = resolver.getNode(\"2\");\n\n        \n    assertTrue(\n            \"Reduce input should be partitioned on 0.\",\n            groupRed1\n                    .getInput()\n                    .getGlobalProperties()\n                    .getPartitioningFields()\n                    .isExactMatch(new FieldList(0)));\n    assertTrue(\n            \"Reduce input should be partitioned on 1.\",\n            groupRed2\n                    .getInput()\n                    .getGlobalProperties()\n                    .getPartitioningFields()\n                    .isExactMatch(new FieldList(1)));\n\n        \n    assertTrue(\n            \"Reduce input should be n-ary union with three inputs.\",\n            groupRed1.getInput().getSource() instanceof NAryUnionPlanNode\n                    && ((NAryUnionPlanNode) groupRed1.getInput().getSource())\n                                    .getListOfInputs()\n                                    .size()\n                            == 3);\n    assertTrue(\n            \"Reduce input should be n-ary union with three inputs.\",\n            groupRed2.getInput().getSource() instanceof NAryUnionPlanNode\n                    && ((NAryUnionPlanNode) groupRed2.getInput().getSource())\n                                    .getListOfInputs()\n                                    .size()\n                            == 3);\n\n        \n    assertTrue(\n            \"Channel between union and group reduce should be forwarding\",\n            groupRed1.getInput().getShipStrategy().equals(ShipStrategyType.FORWARD));\n    assertTrue(\n            \"Channel between union and group reduce should be forwarding\",\n            groupRed2.getInput().getShipStrategy().equals(ShipStrategyType.FORWARD));\n\n        \n    List<Channel> union123In =\n            ((NAryUnionPlanNode) groupRed1.getInput().getSource()).getListOfInputs();\n    for (Channel i : union123In) {\n        assertTrue(\n                \"Union input channel should hash partition on 0\",\n                i.getShipStrategy().equals(ShipStrategyType.PARTITION_HASH)\n                        && i.getShipStrategyKeys().isExactMatch(new FieldList(0)));\n    }\n    List<Channel> union234In =\n            ((NAryUnionPlanNode) groupRed2.getInput().getSource()).getListOfInputs();\n    for (Channel i : union234In) {\n        assertTrue(\n                \"Union input channel should hash partition on 0\",\n                i.getShipStrategy().equals(ShipStrategyType.PARTITION_HASH)\n                        && i.getShipStrategyKeys().isExactMatch(new FieldList(1)));\n    }\n}", "summary_tokens": ["test", "for", "flink", "0"], "project": "flink"}
{"id": 6209, "code": "public void testFlushWithUnfinishedBufferBehindFinished() throws Exception {\n    subpartition.add(createFilledFinishedBufferConsumer(1025)); \n    subpartition.add(createFilledUnfinishedBufferConsumer(1024)); \n    long oldNumNotifications = availablityListener.getNumNotifications();\n\n    assertEquals(1, subpartition.getBuffersInBacklogUnsafe());\n\n    subpartition.flush();\n        \n    assertThat(oldNumNotifications, greaterThan(0L));\n    assertEquals(oldNumNotifications, availablityListener.getNumNotifications());\n\n    assertEquals(2, subpartition.getBuffersInBacklogUnsafe());\n    assertNextBuffer(readView, 1025, true, 1, false, true);\n    assertNextBuffer(readView, 1024, false, 0, false, false);\n    assertNoNextBuffer(readView);\n}", "summary_tokens": ["after", "flush", "call", "unfinished", "buffer", "consumers", "should", "be", "reported", "as", "available", "otherwise", "we", "might", "not", "flush", "some", "of", "the", "data"], "project": "flink"}
{"id": 4037, "code": "protected boolean isRunning() {\n    validateRunsInMainThread();\n    return isRunning;\n}", "summary_tokens": ["returns", "whether", "the", "rpc", "endpoint", "is", "started", "and", "not", "stopped", "or", "being", "stopped"], "project": "flink"}
{"id": 473, "code": "private void beginTx(long checkpointId) throws Exception {\n    Preconditions.checkState(currentXid == null, \"currentXid not null\");\n    currentXid = xidGenerator.generateXid(getRuntimeContext(), checkpointId);\n    hangingXids.offerLast(currentXid);\n    xaFacade.start(currentXid);\n    if (checkpointId > 0) {\n            \n        outputFormat.updateExecutor(false);\n    }\n}", "summary_tokens": ["checkpoint", "id", "to", "associate", "with", "the", "new", "transaction"], "project": "flink"}
{"id": 4327, "code": "public Configuration getFlinkConfiguration() {\n    return flinkConfiguration;\n}", "summary_tokens": ["get", "the", "dynamic", "configuration"], "project": "flink"}
{"id": 7242, "code": "public Path getDefaultSavepointDirectory() {\n    return defaultSavepointDirectory;\n}", "summary_tokens": ["gets", "the", "default", "savepoint", "directory", "for", "this", "job"], "project": "flink"}
{"id": 5189, "code": "public boolean registerRequest() {\n    return phaser.register() >= 0;\n}", "summary_tokens": ["registers", "an", "in", "flight", "request"], "project": "flink"}
{"id": 8755, "code": "public final void setValidatedNodeType(SqlNode node, RelDataType type) {\n    Objects.requireNonNull(type);\n    Objects.requireNonNull(node);\n    if (type.equals(unknownType)) {\n            \n            \n        return;\n    }\n    nodeToTypeMap.put(node, type);\n}", "summary_tokens": ["saves", "the", "type", "of", "a", "sql", "node", "now", "that", "it", "has", "been", "validated"], "project": "flink"}
{"id": 8130, "code": "static String indent(String item) {\n    return \"\\n\"\n            + OPERATION_INDENT\n            + item.replace(\"\\n\" + OPERATION_INDENT, \"\\n\" + OPERATION_INDENT + OPERATION_INDENT);\n}", "summary_tokens": ["increases", "indentation", "for", "description", "of", "string", "of", "child", "operation"], "project": "flink"}
{"id": 6160, "code": "public void testGetSetReaderIndex1() {\n    testGetSetReaderIndex(buffer.readOnlySlice());\n}", "summary_tokens": ["tests", "the", "independence", "of", "the", "reader", "index", "via", "read", "only", "sliced", "network", "buffer", "set", "reader", "index", "int", "and", "read", "only", "sliced", "network", "buffer", "get", "reader", "index"], "project": "flink"}
{"id": 9492, "code": "public final void run() {\n    try {\n        go();\n    } catch (Throwable t) {\n        error = t;\n    }\n}", "summary_tokens": ["this", "method", "is", "final", "thread", "work", "should", "go", "into", "the", "go", "method", "instead"], "project": "flink"}
{"id": 7436, "code": "public KeySelector<IN1, ?> getStateKeySelector1() {\n    return stateKeySelector1;\n}", "summary_tokens": ["returns", "the", "key", "selector", "that", "must", "be", "used", "for", "partitioning", "keyed", "state", "in", "this", "operation", "for", "the", "first", "input"], "project": "flink"}
{"id": 5897, "code": "public void testAllStateRestored() throws Exception {\n    final JobID jobId = new JobID();\n    final OperatorID operatorId = new OperatorID();\n    final long checkpointId = Integer.MAX_VALUE + 123123L;\n    final int parallelism = 128128;\n\n    final CompletedCheckpointStorageLocation testSavepoint =\n            createSavepointWithOperatorSubtaskState(checkpointId, operatorId, parallelism);\n    final Map<JobVertexID, ExecutionJobVertex> tasks =\n            createTasks(operatorId, parallelism, parallelism);\n\n    final CompletedCheckpoint loaded =\n            Checkpoints.loadAndValidateCheckpoint(\n                    jobId,\n                    tasks,\n                    testSavepoint,\n                    cl,\n                    false,\n                    CheckpointProperties.forSavepoint(false));\n\n    assertEquals(jobId, loaded.getJobId());\n    assertEquals(checkpointId, loaded.getCheckpointID());\n}", "summary_tokens": ["tests", "correct", "savepoint", "loading"], "project": "flink"}
{"id": 7671, "code": "public void testEventTimeTimerWithState() throws Exception {\n\n    LegacyKeyedProcessOperator<Integer, Integer, String> operator =\n            new LegacyKeyedProcessOperator<>(\n                    new TriggeringStatefulFlatMapFunction(TimeDomain.EVENT_TIME));\n\n    OneInputStreamOperatorTestHarness<Integer, String> testHarness =\n            new KeyedOneInputStreamOperatorTestHarness<>(\n                    operator, new IdentityKeySelector<Integer>(), BasicTypeInfo.INT_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.processWatermark(new Watermark(1));\n    testHarness.processElement(new StreamRecord<>(17, 0L)); \n\n    testHarness.processWatermark(new Watermark(2));\n    testHarness.processElement(new StreamRecord<>(42, 1L)); \n\n    testHarness.processWatermark(new Watermark(6));\n    testHarness.processWatermark(new Watermark(7));\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    expectedOutput.add(new Watermark(1L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:17\", 0L));\n    expectedOutput.add(new Watermark(2L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:42\", 1L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:17\", 6L));\n    expectedOutput.add(new Watermark(6L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:42\", 7L));\n    expectedOutput.add(new Watermark(7L));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.close();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "leakage", "between", "different", "keys"], "project": "flink"}
{"id": 1871, "code": "public RowKind getKind() {\n    return kind;\n}", "summary_tokens": ["returns", "the", "kind", "of", "change", "that", "this", "row", "describes", "in", "a", "changelog"], "project": "flink"}
{"id": 4681, "code": "protected void setError(Throwable cause) {\n    if (this.cause.compareAndSet(null, checkNotNull(cause))) {\n            \n        notifyChannelNonEmpty();\n    }\n}", "summary_tokens": ["atomically", "sets", "an", "error", "for", "this", "channel", "and", "notifies", "the", "input", "gate", "about", "available", "data", "to", "trigger", "querying", "this", "channel", "by", "the", "task", "thread"], "project": "flink"}
{"id": 4197, "code": "void incrementFailedCheckpoints() {\n    if (canDecrementOfInProgressCheckpointsNumber()) {\n        numInProgressCheckpoints--;\n    }\n    numFailedCheckpoints++;\n}", "summary_tokens": ["increments", "the", "number", "of", "failed", "checkpoints"], "project": "flink"}
{"id": 186, "code": "public B setBulkFlushInterval(long intervalMillis) {\n    checkState(\n            intervalMillis == -1 || intervalMillis >= 0,\n            \"Interval (in milliseconds) between each flush must be larger than \"\n                    + \"or equal to 0.\");\n    this.bulkFlushInterval = intervalMillis;\n    return self();\n}", "summary_tokens": ["sets", "the", "bulk", "flush", "interval", "in", "milliseconds"], "project": "flink"}
{"id": 2495, "code": "private static Optional<Schema> tryExtractAvroSchemaViaInstance(Class<?> type) {\n    try {\n        SpecificRecord instance = (SpecificRecord) type.newInstance();\n        return Optional.ofNullable(instance.getSchema());\n    } catch (InstantiationException | IllegalAccessException e) {\n        LOG.warn(\n                \"Could not extract schema from Avro-generated SpecificRecord class {}: {}.\",\n                type,\n                e);\n        return Optional.empty();\n    }\n}", "summary_tokens": ["extracts", "an", "avro", "schema", "from", "a", "specific", "record"], "project": "flink"}
{"id": 4408, "code": "public CompletableFuture<Acknowledge> sendOperatorEvent(\n        OperatorID operatorId, SerializedValue<OperatorEvent> event) {\n\n    assertRunningInJobMasterMainThread();\n    final LogicalSlot slot = assignedResource;\n\n    if (slot != null && (getState() == RUNNING || getState() == INITIALIZING)) {\n        final TaskExecutorOperatorEventGateway eventGateway = slot.getTaskManagerGateway();\n        return eventGateway.sendOperatorEventToTask(getAttemptId(), operatorId, event);\n    } else {\n        return FutureUtils.completedExceptionally(\n                new TaskNotRunningException(\n                        '\"'\n                                + vertex.getTaskNameWithSubtaskIndex()\n                                + \"\\\" is not running, but in state \"\n                                + getState()));\n    }\n}", "summary_tokens": ["sends", "the", "operator", "event", "to", "the", "task", "on", "the", "task", "executor"], "project": "flink"}
{"id": 2432, "code": "public RequestPaymentConfigurationHandler parseRequestPaymentConfigurationResponse(\n        InputStream inputStream) throws IOException {\n    RequestPaymentConfigurationHandler handler = new RequestPaymentConfigurationHandler();\n    parseXmlInputStream(handler, inputStream);\n    return handler;\n}", "summary_tokens": ["input", "stream", "true", "if", "the", "bucket", "s", "is", "configured", "as", "requester", "pays", "false", "if", "it", "is", "configured", "as", "owner", "pays"], "project": "flink"}
{"id": 6333, "code": "public void testReflectionInterception() {\n    final Configuration config = new Configuration();\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test.\"\n                    + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,\n            InstantiationTypeTrackingTestReporter.class.getName());\n\n    final List<ReporterSetup> reporterSetups =\n            ReporterSetup.fromConfiguration(\n                    config,\n                    new TestingPluginManager(\n                            Collections.singletonMap(\n                                    MetricReporterFactory.class,\n                                    Collections.singletonList(\n                                                    new InterceptingInstantiationTypeTrackingTestReporterFactory())\n                                            .iterator())));\n\n    assertEquals(1, reporterSetups.size());\n\n    final ReporterSetup reporterSetup = reporterSetups.get(0);\n    final InstantiationTypeTrackingTestReporter metricReporter =\n            (InstantiationTypeTrackingTestReporter) reporterSetup.getReporter();\n\n    assertTrue(metricReporter.createdByFactory);\n}", "summary_tokens": ["verifies", "that", "the", "factory", "approach", "is", "used", "if", "the", "factory", "is", "annotated", "with", "org"], "project": "flink"}
{"id": 3487, "code": "public final void write(String path) {\n    final Path savepointPath = new Path(path);\n\n    List<StateBootstrapTransformationWithID<?>> newOperatorTransformations =\n            metadata.getNewOperators();\n    DataStream<OperatorState> newOperatorStates =\n            writeOperatorStates(newOperatorTransformations, configuration, savepointPath);\n\n    List<OperatorState> existingOperators = metadata.getExistingOperators();\n\n    DataStream<OperatorState> finalOperatorStates;\n    if (existingOperators.isEmpty()) {\n        finalOperatorStates = newOperatorStates;\n    } else {\n        DataStream<OperatorState> existingOperatorStates =\n                newOperatorStates\n                        .getExecutionEnvironment()\n                        .fromCollection(existingOperators)\n                        .name(\"existingOperatorStates\");\n\n        existingOperatorStates\n                .flatMap(new StatePathExtractor())\n                .setParallelism(1)\n                .addSink(new OutputFormatSinkFunction<>(new FileCopyFunction(path)));\n\n        finalOperatorStates = newOperatorStates.union(existingOperatorStates);\n    }\n    finalOperatorStates\n            .transform(\n                    \"reduce(OperatorState)\",\n                    TypeInformation.of(CheckpointMetadata.class),\n                    new GroupReduceOperator<>(\n                            new MergeOperatorStates(metadata.getMasterStates())))\n            .forceNonParallel()\n            .addSink(new OutputFormatSinkFunction<>(new SavepointOutputFormat(savepointPath)))\n            .setParallelism(1)\n            .name(path);\n}", "summary_tokens": ["write", "out", "a", "new", "or", "updated", "savepoint"], "project": "flink"}
{"id": 2741, "code": "public <T> DataSource<T> pojoType(Class<T> pojoType, String... pojoFields) {\n    Preconditions.checkNotNull(pojoType, \"The POJO type class must not be null.\");\n    Preconditions.checkArgument(\n            pojoFields != null && pojoFields.length > 0,\n            \"POJO fields must be specified (not null) if output type is a POJO.\");\n\n    final TypeInformation<T> ti = TypeExtractor.createTypeInfo(pojoType);\n    if (!(ti instanceof PojoTypeInfo)) {\n        throw new IllegalArgumentException(\n                \"The specified class is not a POJO. The type class must meet the POJO requirements. Found: \"\n                        + ti);\n    }\n    final PojoTypeInfo<T> pti = (PojoTypeInfo<T>) ti;\n\n    CsvInputFormat<T> inputFormat =\n            new PojoCsvInputFormat<T>(\n                    path,\n                    this.lineDelimiter,\n                    this.fieldDelimiter,\n                    pti,\n                    pojoFields,\n                    this.includedMask);\n\n    configureInputFormat(inputFormat);\n\n    return new DataSource<T>(executionContext, inputFormat, pti, Utils.getCallLocationName());\n}", "summary_tokens": ["configures", "the", "reader", "to", "read", "the", "csv", "data", "and", "parse", "it", "to", "the", "given", "type"], "project": "flink"}
{"id": 4611, "code": "public void finishWrite() throws IOException {\n    mapRegionAndStartNext();\n    fileChannel.close();\n}", "summary_tokens": ["finishes", "the", "current", "region", "and", "prevents", "further", "writes"], "project": "flink"}
{"id": 4832, "code": "public UUID getLeaderSessionID() {\n    return confirmedLeaderInformation.getLeaderSessionID();\n}", "summary_tokens": ["returns", "the", "current", "leader", "session", "id", "or", "null", "if", "the", "contender", "is", "not", "the", "leader"], "project": "flink"}
{"id": 9425, "code": "public void free(boolean reservedFixedMemory) {\n    recordArea.release();\n    numKeys = 0;\n    super.free(reservedFixedMemory);\n}", "summary_tokens": ["reserved", "fixed", "memory", "reserved", "fixed", "memory", "or", "not"], "project": "flink"}
{"id": 8, "code": "public static DescribedPredicate<JavaField> arePublicStaticOfType(Class<?> clazz) {\n    return DescribedPredicate.describe(\n            \"are public, static, and of type \" + clazz.getSimpleName(),\n            field ->\n                    field.getModifiers().contains(JavaModifier.PUBLIC)\n                            && field.getModifiers().contains(JavaModifier.STATIC)\n                            && field.getRawType().isEquivalentTo(clazz));\n}", "summary_tokens": ["tests", "that", "the", "given", "field", "is", "public", "static", "and", "of", "the", "given", "type"], "project": "flink"}
{"id": 3310, "code": "public LocalClusteringCoefficient<K, VV, EV> setIncludeZeroDegreeVertices(\n        boolean includeZeroDegreeVertices) {\n    this.includeZeroDegreeVertices.set(includeZeroDegreeVertices);\n\n    return this;\n}", "summary_tokens": ["by", "default", "the", "vertex", "set", "is", "checked", "for", "zero", "degree", "vertices"], "project": "flink"}
{"id": 353, "code": "public static ObjectInspector[] toInspectors(\n        HiveShim hiveShim, Object[] args, DataType[] argTypes) {\n    assert args.length == argTypes.length;\n\n    ObjectInspector[] argumentInspectors = new ObjectInspector[argTypes.length];\n\n    for (int i = 0; i < argTypes.length; i++) {\n        Object constant = args[i];\n\n        if (constant == null) {\n            argumentInspectors[i] =\n                    TypeInfoUtils.getStandardJavaObjectInspectorFromTypeInfo(\n                            HiveTypeUtil.toHiveTypeInfo(argTypes[i], false));\n        } else {\n            PrimitiveTypeInfo primitiveTypeInfo =\n                    (PrimitiveTypeInfo) HiveTypeUtil.toHiveTypeInfo(argTypes[i], false);\n            constant =\n                    getConversion(\n                                    getObjectInspector(primitiveTypeInfo),\n                                    argTypes[i].getLogicalType(),\n                                    hiveShim)\n                            .toHiveObject(constant);\n            argumentInspectors[i] =\n                    getObjectInspectorForPrimitiveConstant(\n                            primitiveTypeInfo, constant, hiveShim);\n        }\n    }\n\n    return argumentInspectors;\n}", "summary_tokens": ["get", "an", "array", "of", "object", "inspector", "from", "the", "give", "array", "of", "args", "and", "their", "types"], "project": "flink"}
{"id": 4757, "code": "public int getNumberOfVertices() {\n    return this.taskVertices.size();\n}", "summary_tokens": ["returns", "the", "number", "of", "all", "vertices"], "project": "flink"}
{"id": 6398, "code": "public void testLeaderFutureWaitsForValidLeader() throws Exception {\n    final JobID jobId = new JobID();\n    TestingHighAvailabilityServices highAvailabilityServices =\n            new TestingHighAvailabilityServices();\n    SettableLeaderRetrievalService leaderRetrievalService =\n            new SettableLeaderRetrievalService(null, null);\n\n    highAvailabilityServices.setJobMasterLeaderRetriever(jobId, leaderRetrievalService);\n\n    JobLeaderIdService jobLeaderIdService =\n            new DefaultJobLeaderIdService(\n                    highAvailabilityServices,\n                    new ManuallyTriggeredScheduledExecutor(),\n                    Time.milliseconds(5000L));\n\n    jobLeaderIdService.start(new NoOpJobLeaderIdActions());\n\n    jobLeaderIdService.addJob(jobId);\n\n        \n    leaderRetrievalService.notifyListener(\"foo\", UUID.randomUUID());\n\n        \n    leaderRetrievalService.notifyListener(null, null);\n\n    final CompletableFuture<JobMasterId> leaderIdFuture = jobLeaderIdService.getLeaderId(jobId);\n        \n    assertThat(leaderIdFuture.isDone(), is(false));\n\n        \n    final UUID newLeaderId = UUID.randomUUID();\n    leaderRetrievalService.notifyListener(\"foo\", newLeaderId);\n    assertThat(leaderIdFuture.get(), is(JobMasterId.fromUuidOrNull(newLeaderId)));\n}", "summary_tokens": ["tests", "that", "the", "leader", "id", "future", "is", "only", "completed", "once", "the", "service", "is", "notified", "about", "an", "actual", "leader", "being", "elected"], "project": "flink"}
{"id": 4703, "code": "private List<Buffer> getInflightBuffersUnsafe(long checkpointId) {\n    assert Thread.holdsLock(receivedBuffers);\n\n    checkState(checkpointId == lastBarrierId || lastBarrierId == NONE);\n\n    final List<Buffer> inflightBuffers = new ArrayList<>();\n    Iterator<SequenceBuffer> iterator = receivedBuffers.iterator();\n        \n    Iterators.advance(iterator, receivedBuffers.getNumPriorityElements());\n\n    while (iterator.hasNext()) {\n        SequenceBuffer sequenceBuffer = iterator.next();\n        if (sequenceBuffer.buffer.isBuffer()) {\n            if (shouldBeSpilled(sequenceBuffer.sequenceNumber)) {\n                inflightBuffers.add(sequenceBuffer.buffer.retainBuffer());\n            } else {\n                break;\n            }\n        }\n    }\n\n    return inflightBuffers;\n}", "summary_tokens": ["returns", "a", "list", "of", "buffers", "checking", "the", "first", "n", "non", "priority", "buffers", "and", "skipping", "all", "events"], "project": "flink"}
{"id": 8974, "code": "public static String dagToString(List<ExecNode<?>> nodes) {\n    Preconditions.checkArgument(\n            nodes != null && !nodes.isEmpty(), \"nodes should not be null or empty.\");\n    if (nodes.size() == 1) {\n        return treeToString(nodes.get(0));\n    }\n\n        \n    final List<ExecNode<?>> stopVisitNodes = new ArrayList<>();\n    final StringBuilder sb = new StringBuilder();\n    final DagReuseInfo reuseInfo = new DagReuseInfo(nodes, new ArrayList<>());\n\n    final ExecNodeVisitor visitor =\n            new ExecNodeVisitorImpl() {\n                @Override\n                public void visit(ExecNode<?> node) {\n                    int visitedTimes = reuseInfo.addVisitedTimes(node);\n                    boolean isFirstVisit = visitedTimes == 1;\n                    if (isFirstVisit) {\n                        super.visit(node);\n                    }\n\n                    int reuseId = reuseInfo.getReuseId(node);\n                    boolean isReuseNode = reuseId >= 0;\n                    if (node instanceof CommonExecLegacySink\n                            || node instanceof CommonExecSink\n                            || (isReuseNode && isFirstVisit)) {\n                        if (isReuseNode) {\n                            reuseInfo.setFirstVisited(node, true);\n                        }\n\n                        String reusePlan =\n                                doConvertTreeToString(\n                                        node, reuseInfo, false, stopVisitNodes, false);\n                        sb.append(reusePlan).append(System.lineSeparator());\n\n                        if (isReuseNode) {\n                                \n                            stopVisitNodes.add(node);\n                            reuseInfo.setFirstVisited(node, false);\n                        }\n                    }\n                }\n            };\n    nodes.forEach(visitor::visit);\n\n    if (sb.length() > 0) {\n            \n        sb.deleteCharAt(sb.length() - 1);\n    }\n    return sb.toString();\n}", "summary_tokens": ["converts", "an", "exec", "node", "dag", "to", "a", "string", "as", "a", "tree", "style"], "project": "flink"}
{"id": 7739, "code": "public void testChannelResetOnNewBarrier() throws Exception {\n    RecordingChannelStateWriter stateWriter = new RecordingChannelStateWriter();\n    try (CheckpointedInputGate gate =\n            new TestCheckpointedInputGateBuilder(\n                            2, getTestBarrierHandlerFactory(new ValidatingCheckpointHandler()))\n                    .withChannelStateWriter(stateWriter)\n                    .withRemoteChannels()\n                    .withMailboxExecutor()\n                    .build()) {\n\n        sendBarrier(\n                0,\n                clock.relativeTimeMillis(),\n                SAVEPOINT,\n                gate,\n                0); \n        ((RemoteInputChannel) gate.getChannel(0))\n                .onBuffer(createBuffer(1024), 1, 0); \n        send(\n                toBuffer(\n                        new CheckpointBarrier(\n                                1,\n                                clock.relativeTimeMillis(),\n                                unaligned(CheckpointType.CHECKPOINT, getDefault())),\n                        true),\n                1,\n                gate);\n\n        assertFalse(stateWriter.getAddedInput().isEmpty());\n    }\n}", "summary_tokens": ["upon", "subsuming", "or", "canceling", "a", "checkpoint", "channels", "should", "be", "notified", "regardless", "of", "whether", "uc", "controller", "is", "currently", "being", "used", "or", "not"], "project": "flink"}
{"id": 7983, "code": "public boolean isBlinkPlanner() {\n    return true;\n}", "summary_tokens": ["tells", "if", "the", "table", "environment", "should", "work", "in", "the", "blink", "planner", "or", "old", "planner"], "project": "flink"}
{"id": 8035, "code": "public String getJsonPlan() {\n    return tableEnvironment.getJsonPlan(operations);\n}", "summary_tokens": ["get", "the", "json", "plan", "of", "the", "all", "statements", "and", "tables", "as", "a", "batch"], "project": "flink"}
{"id": 1343, "code": "public boolean isOverdue() {\n    return timeNanos < clock.relativeTimeNanos();\n}", "summary_tokens": ["determines", "whether", "the", "deadline", "is", "in", "the", "past", "i"], "project": "flink"}
{"id": 222, "code": "public static void verifyProducedSinkData(Client client, String index) {\n    for (int i = 0; i < NUM_ELEMENTS; i++) {\n        GetResponse response =\n                client.get(new GetRequest(index, TYPE_NAME, Integer.toString(i))).actionGet();\n        Assert.assertEquals(DATA_PREFIX + i, response.getSource().get(DATA_FIELD_NAME));\n    }\n}", "summary_tokens": ["verify", "the", "results", "in", "an", "elasticsearch", "index"], "project": "flink"}
{"id": 6891, "code": "public void dispose() {\n    if (this.disposed) {\n        return;\n    }\n    super.dispose();\n\n        \n        \n        \n        \n    rocksDBResourceGuard.close();\n\n        \n        \n        \n    if (db != null) {\n\n        IOUtils.closeQuietly(writeBatchWrapper);\n\n            \n            \n            \n        if (nativeMetricMonitor != null) {\n            nativeMetricMonitor.close();\n        }\n\n        List<ColumnFamilyOptions> columnFamilyOptions =\n                new ArrayList<>(kvStateInformation.values().size());\n\n            \n            \n            \n            \n            \n        RocksDBOperationUtils.addColumnFamilyOptionsToCloseLater(\n                columnFamilyOptions, defaultColumnFamily);\n        IOUtils.closeQuietly(defaultColumnFamily);\n\n            \n        for (RocksDbKvStateInfo kvStateInfo : kvStateInformation.values()) {\n            RocksDBOperationUtils.addColumnFamilyOptionsToCloseLater(\n                    columnFamilyOptions, kvStateInfo.columnFamilyHandle);\n            IOUtils.closeQuietly(kvStateInfo.columnFamilyHandle);\n        }\n\n            \n        IOUtils.closeQuietly(db);\n\n        columnFamilyOptions.forEach(IOUtils::closeQuietly);\n\n        IOUtils.closeQuietly(optionsContainer);\n\n        ttlCompactFiltersManager.disposeAndClearRegisteredCompactionFactories();\n\n        kvStateInformation.clear();\n\n        cleanInstanceBasePath();\n    }\n    IOUtils.closeQuietly(checkpointSnapshotStrategy);\n    this.disposed = true;\n}", "summary_tokens": ["should", "only", "be", "called", "by", "one", "thread", "and", "only", "after", "all", "accesses", "to", "the", "db", "happened"], "project": "flink"}
{"id": 4915, "code": "protected RpcService createRemoteRpcService(\n        Configuration configuration,\n        String externalAddress,\n        String externalPortRange,\n        String bindAddress,\n        RpcSystem rpcSystem)\n        throws Exception {\n    return rpcSystem\n            .remoteServiceBuilder(configuration, externalAddress, externalPortRange)\n            .withBindAddress(bindAddress)\n            .withExecutorConfiguration(RpcUtils.getTestForkJoinExecutorConfiguration())\n            .createAndStart();\n}", "summary_tokens": ["factory", "method", "to", "instantiate", "the", "remote", "rpc", "service"], "project": "flink"}
{"id": 1229, "code": "public UserCodeWrapper<? extends OutputFormat<IN>> getUserCodeWrapper() {\n    return this.formatWrapper;\n}", "summary_tokens": ["gets", "the", "class", "describing", "the", "output", "format"], "project": "flink"}
{"id": 5513, "code": "public Path getCheckpointPath() {\n        \n        \n    return location.getBaseCheckpointPath();\n}", "summary_tokens": ["gets", "the", "base", "directory", "where", "all", "the", "checkpoints", "are", "stored"], "project": "flink"}
{"id": 4431, "code": "public static FailoverStrategy.Factory loadFailoverStrategyFactory(final Configuration config) {\n    checkNotNull(config);\n\n    final String strategyParam =\n            config.getString(JobManagerOptions.EXECUTION_FAILOVER_STRATEGY);\n\n    switch (strategyParam.toLowerCase()) {\n        case FULL_RESTART_STRATEGY_NAME:\n            return new RestartAllFailoverStrategy.Factory();\n\n        case PIPELINED_REGION_RESTART_STRATEGY_NAME:\n            return new RestartPipelinedRegionFailoverStrategy.Factory();\n\n        default:\n            throw new IllegalConfigurationException(\n                    \"Unknown failover strategy: \" + strategyParam);\n    }\n}", "summary_tokens": ["loads", "a", "failover", "strategy"], "project": "flink"}
{"id": 3210, "code": "public DataSet<Tuple2<K, EV>> reduceOnEdges(\n        ReduceEdgesFunction<EV> reduceEdgesFunction, EdgeDirection direction)\n        throws IllegalArgumentException {\n\n    switch (direction) {\n        case IN:\n            return edges.map(new ProjectVertexWithEdgeValueMap<>(1))\n                    .withForwardedFields(\"f1->f0\")\n                    .name(\"Vertex with in-edges\")\n                    .groupBy(0)\n                    .reduce(new ApplyReduceFunction<>(reduceEdgesFunction))\n                    .name(\"Reduce on edges\");\n        case OUT:\n            return edges.map(new ProjectVertexWithEdgeValueMap<>(0))\n                    .withForwardedFields(\"f0->f0\")\n                    .name(\"Vertex with out-edges\")\n                    .groupBy(0)\n                    .reduce(new ApplyReduceFunction<>(reduceEdgesFunction))\n                    .name(\"Reduce on edges\");\n        case ALL:\n            return edges.flatMap(new EmitOneVertexWithEdgeValuePerNode<>())\n                    .withForwardedFields(\"f2->f1\")\n                    .name(\"Vertex with all edges\")\n                    .groupBy(0)\n                    .reduce(new ApplyReduceFunction<>(reduceEdgesFunction))\n                    .name(\"Reduce on edges\");\n        default:\n            throw new IllegalArgumentException(\"Illegal edge direction\");\n    }\n}", "summary_tokens": ["compute", "a", "reduce", "transformation", "over", "the", "edge", "values", "of", "each", "vertex"], "project": "flink"}
{"id": 3595, "code": "public CoGroupRawOperatorBase<?, ?, ?, ?> getOperator() {\n    return (CoGroupRawOperatorBase<?, ?, ?, ?>) super.getOperator();\n}", "summary_tokens": ["gets", "the", "operator", "for", "this", "co", "group", "node"], "project": "flink"}
{"id": 2332, "code": "public boolean onlyKeyExists(String name) {\n    String[] names = handleDeprecation(deprecationContext.get(), name);\n    for (String n : names) {\n        if (getProps().getProperty(n, DEFAULT_STRING_CHECK).equals(DEFAULT_STRING_CHECK)) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["return", "existence", "of", "the", "code", "name", "code", "property", "but", "only", "for", "names", "which", "have", "no", "valid", "value", "usually", "non", "existent", "or", "commented", "out", "in", "xml"], "project": "flink"}
{"id": 474, "code": "public Collection<CheckpointAndXid> getPrepared() {\n    return prepared;\n}", "summary_tokens": ["immutable", "collection", "of", "prepared", "xa", "transactions", "to", "javax"], "project": "flink"}
{"id": 6321, "code": "public void testReporterNotifications() throws Exception {\n    Configuration config = new Configuration();\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test1.\"\n                    + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,\n            TestReporter6.class.getName());\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test2.\"\n                    + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,\n            TestReporter7.class.getName());\n\n    MetricRegistryImpl registry =\n            new MetricRegistryImpl(\n                    MetricRegistryTestUtils.defaultMetricRegistryConfiguration(),\n                    Arrays.asList(\n                            ReporterSetup.forReporter(\"test1\", new TestReporter6()),\n                            ReporterSetup.forReporter(\"test2\", new TestReporter7())));\n\n    TaskManagerMetricGroup root =\n            TaskManagerMetricGroup.createTaskManagerMetricGroup(\n                    registry, \"host\", new ResourceID(\"id\"));\n    root.counter(\"rootCounter\");\n\n    assertTrue(TestReporter6.addedMetric instanceof Counter);\n    assertEquals(\"rootCounter\", TestReporter6.addedMetricName);\n\n    assertTrue(TestReporter7.addedMetric instanceof Counter);\n    assertEquals(\"rootCounter\", TestReporter7.addedMetricName);\n\n    root.close();\n\n    assertTrue(TestReporter6.removedMetric instanceof Counter);\n    assertEquals(\"rootCounter\", TestReporter6.removedMetricName);\n\n    assertTrue(TestReporter7.removedMetric instanceof Counter);\n    assertEquals(\"rootCounter\", TestReporter7.removedMetricName);\n\n    registry.shutdown().get();\n}", "summary_tokens": ["verifies", "that", "reporters", "are", "notified", "of", "added", "removed", "metrics"], "project": "flink"}
{"id": 8136, "code": "static List<Expression> addOrReplaceColumns(\n        List<String> inputFields, List<Expression> newExpressions) {\n    LinkedHashMap<String, Expression> finalFields = new LinkedHashMap<>();\n\n    inputFields.forEach(field -> finalFields.put(field, unresolvedRef(field)));\n    newExpressions.forEach(\n            expr -> {\n                String name = extractName(expr).orElse(expr.toString());\n                finalFields.put(name, expr);\n            });\n\n    return new ArrayList<>(finalFields.values());\n}", "summary_tokens": ["creates", "a", "projection", "list", "that", "adds", "new", "or", "replaces", "existing", "if", "a", "column", "with", "corresponding", "name", "already", "exists", "columns"], "project": "flink"}
{"id": 3888, "code": "protected ExecutorService getQueryExecutor() {\n    return queryExecutor;\n}", "summary_tokens": ["returns", "the", "thread", "pool", "responsible", "for", "processing", "incoming", "requests"], "project": "flink"}
{"id": 7572, "code": "protected void finalize() throws Throwable {\n    super.finalize();\n    if (!timerService.isTerminated()) {\n        LOG.info(\"Timer service is shutting down.\");\n        timerService.shutdownService();\n    }\n\n    if (!systemTimerService.isTerminated()) {\n        LOG.info(\"System timer service is shutting down.\");\n        systemTimerService.shutdownService();\n    }\n\n    cancelables.close();\n}", "summary_tokens": ["the", "finalize", "method", "shuts", "down", "the", "timer"], "project": "flink"}
{"id": 8453, "code": "public TypeInformation<?> getResultType(Class<?>[] signature) {\n    return null;\n}", "summary_tokens": ["returns", "the", "result", "type", "of", "the", "evaluation", "method", "with", "a", "given", "signature"], "project": "flink"}
{"id": 3063, "code": "public Map<String, List<V>> materializeMatch(Map<String, List<EventId>> match) {\n    Map<String, List<V>> materializedMatch = new LinkedHashMap<>(match.size());\n\n    for (Map.Entry<String, List<EventId>> pattern : match.entrySet()) {\n        List<V> events = new ArrayList<>(pattern.getValue().size());\n        for (EventId eventId : pattern.getValue()) {\n            try {\n                V event = sharedBuffer.getEvent(eventId).getElement();\n                events.add(event);\n            } catch (Exception ex) {\n                throw new WrappingRuntimeException(ex);\n            }\n        }\n        materializedMatch.put(pattern.getKey(), events);\n    }\n\n    return materializedMatch;\n}", "summary_tokens": ["extracts", "the", "real", "event", "from", "the", "shared", "buffer", "with", "pre", "extracted", "event", "id"], "project": "flink"}
{"id": 6096, "code": "public void testCloseAndCleanupAllDataDoesNotDeleteBlobsIfCleaningUpHADataFails() {\n    final Queue<CloseOperations> closeOperations = new ArrayDeque<>(3);\n\n    final TestingBlobStoreService testingBlobStoreService =\n            new TestingBlobStoreService(closeOperations);\n\n    final TestingHaServices haServices =\n            new TestingHaServices(\n                    new Configuration(),\n                    Executors.directExecutor(),\n                    testingBlobStoreService,\n                    closeOperations,\n                    () -> {\n                        throw new FlinkException(\"test exception\");\n                    },\n                    ignored -> {});\n\n    try {\n        haServices.closeAndCleanupAllData();\n        fail(\"Expected that the close operation fails.\");\n    } catch (Exception expected) {\n\n    }\n\n    assertThat(closeOperations, contains(CloseOperations.HA_CLOSE, CloseOperations.BLOB_CLOSE));\n}", "summary_tokens": ["tests", "that", "we", "don", "t", "delete", "the", "ha", "blobs", "if", "we", "could", "not", "clean", "up", "the", "pointers", "from", "the", "ha", "services"], "project": "flink"}
{"id": 4694, "code": "public void notifyBufferAvailable(int numAvailableBuffers) throws IOException {\n    if (numAvailableBuffers > 0 && unannouncedCredit.getAndAdd(numAvailableBuffers) == 0) {\n        notifyCreditAvailable();\n    }\n}", "summary_tokens": ["the", "unannounced", "credit", "is", "increased", "by", "the", "given", "amount", "and", "might", "notify", "increased", "credit", "to", "the", "producer"], "project": "flink"}
{"id": 22, "code": "protected void savepoint(String[] args) throws Exception {\n    LOG.info(\"Running 'savepoint' command.\");\n\n    final Options commandOptions = CliFrontendParser.getSavepointCommandOptions();\n\n    final Options commandLineOptions =\n            CliFrontendParser.mergeOptions(commandOptions, customCommandLineOptions);\n\n    final CommandLine commandLine = CliFrontendParser.parse(commandLineOptions, args, false);\n\n    final SavepointOptions savepointOptions = new SavepointOptions(commandLine);\n\n        \n    if (savepointOptions.isPrintHelp()) {\n        CliFrontendParser.printHelpForSavepoint(customCommandLines);\n        return;\n    }\n\n    final CustomCommandLine activeCommandLine = validateAndGetActiveCommandLine(commandLine);\n\n    if (savepointOptions.isDispose()) {\n        runClusterAction(\n                activeCommandLine,\n                commandLine,\n                clusterClient ->\n                        disposeSavepoint(clusterClient, savepointOptions.getSavepointPath()));\n    } else {\n        String[] cleanedArgs = savepointOptions.getArgs();\n\n        final JobID jobId;\n\n        if (cleanedArgs.length >= 1) {\n            String jobIdString = cleanedArgs[0];\n\n            jobId = parseJobId(jobIdString);\n        } else {\n            throw new CliArgsException(\n                    \"Missing JobID. \" + \"Specify a Job ID to trigger a savepoint.\");\n        }\n\n        final String savepointDirectory;\n        if (cleanedArgs.length >= 2) {\n            savepointDirectory = cleanedArgs[1];\n        } else {\n            savepointDirectory = null;\n        }\n\n            \n        if (cleanedArgs.length >= 3) {\n            logAndSysout(\n                    \"Provided more arguments than required. Ignoring not needed arguments.\");\n        }\n\n        runClusterAction(\n                activeCommandLine,\n                commandLine,\n                clusterClient -> triggerSavepoint(clusterClient, jobId, savepointDirectory));\n    }\n}", "summary_tokens": ["executes", "the", "savepoint", "action"], "project": "flink"}
{"id": 5707, "code": "public static <T extends RestfulGateway> Optional<StaticFileServerHandler<T>> tryLoadWebContent(\n        GatewayRetriever<? extends T> leaderRetriever, Time timeout, File tmpDir)\n        throws IOException {\n\n    if (isFlinkRuntimeWebInClassPath()) {\n        return Optional.of(new StaticFileServerHandler<>(leaderRetriever, timeout, tmpDir));\n    } else {\n        return Optional.empty();\n    }\n}", "summary_tokens": ["checks", "whether", "the", "flink", "runtime", "web", "dependency", "is", "available", "and", "if", "so", "returns", "a", "static", "file", "server", "handler", "which", "can", "serve", "the", "static", "file", "contents"], "project": "flink"}
{"id": 3676, "code": "public Ordering getOrdering() {\n    return ordering;\n}", "summary_tokens": ["gets", "the", "key", "order"], "project": "flink"}
{"id": 6429, "code": "public void testRequirementDeclarationWithoutFreeSlotsTriggersWorkerAllocation()\n        throws Exception {\n    final ResourceManagerId resourceManagerId = ResourceManagerId.generate();\n\n    final ResourceRequirements resourceRequirements = createResourceRequirementsForSingleSlot();\n\n    CompletableFuture<WorkerResourceSpec> allocateResourceFuture = new CompletableFuture<>();\n    ResourceActions resourceManagerActions =\n            new TestingResourceActionsBuilder()\n                    .setAllocateResourceConsumer(allocateResourceFuture::complete)\n                    .build();\n\n    try (SlotManager slotManager =\n            createSlotManager(resourceManagerId, resourceManagerActions)) {\n\n        slotManager.processResourceRequirements(resourceRequirements);\n\n        allocateResourceFuture.get();\n    }\n}", "summary_tokens": ["tests", "that", "a", "slot", "request", "with", "no", "free", "slots", "will", "trigger", "the", "resource", "allocation"], "project": "flink"}
{"id": 3292, "code": "public int getSuperstepNumber() {\n    return this.runtimeContext.getSuperstepNumber();\n}", "summary_tokens": ["gets", "the", "number", "of", "the", "superstep", "starting", "at", "tt", "0", "tt"], "project": "flink"}
{"id": 4993, "code": "public ArrayList<MemorySegment> resetOverflowBuckets() {\n    this.numOverflowSegments = 0;\n    this.nextOverflowBucket = 0;\n\n    ArrayList<MemorySegment> result =\n            new ArrayList<MemorySegment>(this.overflowSegments.length);\n    for (int i = 0; i < this.overflowSegments.length; i++) {\n        if (this.overflowSegments[i] != null) {\n            result.add(this.overflowSegments[i]);\n        }\n    }\n    this.overflowSegments = new MemorySegment[2];\n    return result;\n}", "summary_tokens": ["resets", "overflow", "bucket", "counters", "and", "returns", "freed", "memory", "and", "should", "only", "be", "used", "for", "resizing"], "project": "flink"}
{"id": 3172, "code": "public <NEW> Graph<K, NEW, EV> translateVertexValues(TranslateFunction<VV, NEW> translator)\n        throws Exception {\n    return run(new TranslateVertexValues<>(translator));\n}", "summary_tokens": ["translate", "vertex", "values", "using", "the", "given", "map", "function"], "project": "flink"}
{"id": 4788, "code": "public void setSlotSharingGroup(SlotSharingGroup grp) {\n    checkNotNull(grp);\n\n    if (this.slotSharingGroup != null) {\n        this.slotSharingGroup.removeVertexFromGroup(this.getID());\n    }\n\n    grp.addVertexToGroup(this.getID());\n    this.slotSharingGroup = grp;\n}", "summary_tokens": ["associates", "this", "vertex", "with", "a", "slot", "sharing", "group", "for", "scheduling"], "project": "flink"}
{"id": 4065, "code": "public static RpcService createRemoteRpcService(\n        RpcSystem rpcSystem,\n        Configuration configuration,\n        @Nullable String externalAddress,\n        String externalPortRange,\n        @Nullable String bindAddress,\n        @SuppressWarnings(\"OptionalUsedAsFieldOrParameterType\") Optional<Integer> bindPort)\n        throws Exception {\n    RpcSystem.RpcServiceBuilder rpcServiceBuilder =\n            rpcSystem.remoteServiceBuilder(configuration, externalAddress, externalPortRange);\n    if (bindAddress != null) {\n        rpcServiceBuilder = rpcServiceBuilder.withBindAddress(bindAddress);\n    }\n    if (bindPort.isPresent()) {\n        rpcServiceBuilder = rpcServiceBuilder.withBindPort(bindPort.get());\n    }\n    return rpcServiceBuilder.createAndStart();\n}", "summary_tokens": ["convenient", "shortcut", "for", "constructing", "a", "remote", "rpc", "service", "that", "takes", "care", "of", "checking", "for", "null", "and", "empty", "optionals"], "project": "flink"}
{"id": 7202, "code": "public void setAlignmentTimeout(Duration alignmentTimeout) {\n    this.alignedCheckpointTimeout = alignmentTimeout;\n}", "summary_tokens": ["only", "relevant", "if", "unaligned", "checkpoints", "enabled", "is", "enabled"], "project": "flink"}
{"id": 7506, "code": "default void snapshotState(StateSnapshotContext context) throws Exception {}", "summary_tokens": ["snapshots", "the", "state", "of", "the", "committer", "and", "this", "handler"], "project": "flink"}
{"id": 647, "code": "public static <T> KafkaSourceReader<T> createReaderWithFinishedSplitHook(\n        KafkaSource<T> kafkaSource,\n        SourceReaderContext sourceReaderContext,\n        Consumer<Collection<String>> splitFinishedHook)\n        throws Exception {\n    return ((KafkaSourceReader<T>)\n            kafkaSource.createReader(sourceReaderContext, splitFinishedHook));\n}", "summary_tokens": ["create", "kafka", "source", "reader", "with", "a", "custom", "hook", "handling", "ids", "of", "finished", "org"], "project": "flink"}
{"id": 5987, "code": "public void testSerializationOfUnknownShuffleDescriptor() throws IOException {\n    ShuffleDescriptor shuffleDescriptor = new UnknownShuffleDescriptor(resultPartitionID);\n    ShuffleDescriptor shuffleDescriptorCopy =\n            CommonTestUtils.createCopySerializable(shuffleDescriptor);\n    assertThat(shuffleDescriptorCopy, instanceOf(UnknownShuffleDescriptor.class));\n    assertThat(shuffleDescriptorCopy.getResultPartitionID(), is(resultPartitionID));\n    assertThat(shuffleDescriptorCopy.isUnknown(), is(true));\n}", "summary_tokens": ["tests", "simple", "de", "serialization", "with", "unknown", "shuffle", "descriptor"], "project": "flink"}
{"id": 7786, "code": "public void testClear() throws Exception {\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(\n                    ProcessingTimeTrigger.create(), new TimeWindow.Serializer());\n\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numEventTimeTimers());\n    assertEquals(2, testHarness.numProcessingTimeTimers());\n    assertEquals(1, testHarness.numProcessingTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(1, testHarness.numProcessingTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(2, 4));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numEventTimeTimers());\n    assertEquals(1, testHarness.numProcessingTimeTimers());\n    assertEquals(1, testHarness.numProcessingTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(0, testHarness.numProcessingTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(0, 2));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n}", "summary_tokens": ["verify", "that", "clear", "does", "not", "leak", "across", "windows"], "project": "flink"}
{"id": 3220, "code": "public GraphCsvReader parseQuotedStringsEdges(char quoteCharacter) {\n    this.edgeReader.parseQuotedStrings(quoteCharacter);\n    return this;\n}", "summary_tokens": ["enables", "quoted", "string", "parsing", "for", "edge", "csv", "reader"], "project": "flink"}
{"id": 2916, "code": "public void testMaxByComparisonMultiple() {\n    SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>> maxByTuple =\n            new SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>>(\n                    tupleTypeInfo, new int[] {0, 1, 2, 3, 4});\n\n    try {\n        Assert.assertSame(\n                \"SelectByMax must return bigger tuple\",\n                bigger,\n                maxByTuple.reduce(smaller, bigger));\n        Assert.assertSame(\n                \"SelectByMax must return bigger tuple\",\n                bigger,\n                maxByTuple.reduce(bigger, smaller));\n    } catch (Exception e) {\n        Assert.fail(\"No exception should be thrown while comparing both tuples\");\n    }\n}", "summary_tokens": ["this", "test", "validates", "that", "equality", "is", "independent", "of", "the", "amount", "of", "used", "indices"], "project": "flink"}
{"id": 3774, "code": "public void testConsecutiveUnionsWithHashPartitioning() throws Exception {\n\n        \n        \n        \n\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    DataSet<Tuple2<Long, Long>> src1 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src2 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src3 = env.fromElements(new Tuple2<>(0L, 0L));\n\n    DataSet<Tuple2<Long, Long>> union12 = src1.union(src2);\n    DataSet<Tuple2<Long, Long>> union123 = union12.union(src3);\n\n    union123.partitionByHash(1)\n            .output(new DiscardingOutputFormat<Tuple2<Long, Long>>())\n            .name(\"out\");\n\n        \n        \n        \n\n    OptimizedPlan optimizedPlan = compileNoStats(env.createProgramPlan());\n\n    OptimizerPlanNodeResolver resolver = getOptimizerPlanNodeResolver(optimizedPlan);\n\n    SingleInputPlanNode sink = resolver.getNode(\"out\");\n\n        \n    assertEquals(\n            \"Sink input should be hash partitioned.\",\n            PartitioningProperty.HASH_PARTITIONED,\n            sink.getInput().getGlobalProperties().getPartitioning());\n    assertEquals(\n            \"Sink input should be hash partitioned on 1.\",\n            new FieldList(1),\n            sink.getInput().getGlobalProperties().getPartitioningFields());\n\n    SingleInputPlanNode partitioner = (SingleInputPlanNode) sink.getInput().getSource();\n    assertTrue(partitioner.getDriverStrategy() == DriverStrategy.UNARY_NO_OP);\n    assertEquals(\n            \"Partitioner input should be hash partitioned.\",\n            PartitioningProperty.HASH_PARTITIONED,\n            partitioner.getInput().getGlobalProperties().getPartitioning());\n    assertEquals(\n            \"Partitioner input should be hash partitioned on 1.\",\n            new FieldList(1),\n            partitioner.getInput().getGlobalProperties().getPartitioningFields());\n    assertEquals(\n            \"Partitioner input channel should be forwarding\",\n            ShipStrategyType.FORWARD,\n            partitioner.getInput().getShipStrategy());\n\n    NAryUnionPlanNode union = (NAryUnionPlanNode) partitioner.getInput().getSource();\n        \n    for (Channel c : union.getInputs()) {\n        assertEquals(\n                \"Union input should be hash partitioned\",\n                PartitioningProperty.HASH_PARTITIONED,\n                c.getGlobalProperties().getPartitioning());\n        assertEquals(\n                \"Union input channel should be hash partitioning\",\n                ShipStrategyType.PARTITION_HASH,\n                c.getShipStrategy());\n        assertTrue(\n                \"Union input should be data source\", c.getSource() instanceof SourcePlanNode);\n    }\n}", "summary_tokens": ["checks", "that", "a", "plan", "with", "consecutive", "unions", "followed", "by", "partition", "by", "hash", "is", "correctly", "translated"], "project": "flink"}
{"id": 3594, "code": "public CoGroupOperatorBase<?, ?, ?, ?> getOperator() {\n    return (CoGroupOperatorBase<?, ?, ?, ?>) super.getOperator();\n}", "summary_tokens": ["gets", "the", "operator", "for", "this", "co", "group", "node"], "project": "flink"}
{"id": 8432, "code": "private static <T extends TableFactory> List<T> filterBySupportedProperties(\n        Class<T> factoryClass,\n        Map<String, String> properties,\n        List<T> classFactories,\n        List<T> contextFactories) {\n\n    final List<String> plainGivenKeys = new LinkedList<>();\n    properties\n            .keySet()\n            .forEach(\n                    k -> {\n                            \n                        String key = k.replaceAll(\".\\\\d+\", \".#\");\n                            \n                        if (!plainGivenKeys.contains(key)) {\n                            plainGivenKeys.add(key);\n                        }\n                    });\n\n    List<T> supportedFactories = new LinkedList<>();\n    Tuple2<T, List<String>> bestMatched = null;\n    for (T factory : contextFactories) {\n        Set<String> requiredContextKeys = normalizeContext(factory).keySet();\n        Tuple2<List<String>, List<String>> tuple2 = normalizeSupportedProperties(factory);\n            \n        List<String> givenContextFreeKeys =\n                plainGivenKeys.stream()\n                        .filter(p -> !requiredContextKeys.contains(p))\n                        .collect(Collectors.toList());\n        List<String> givenFilteredKeys =\n                filterSupportedPropertiesFactorySpecific(factory, givenContextFreeKeys);\n\n        boolean allTrue = true;\n        List<String> unsupportedKeys = new ArrayList<>();\n        for (String k : givenFilteredKeys) {\n            if (!(tuple2.f0.contains(k) || tuple2.f1.stream().anyMatch(k::startsWith))) {\n                allTrue = false;\n                unsupportedKeys.add(k);\n            }\n        }\n        if (allTrue) {\n            supportedFactories.add(factory);\n        } else {\n            if (bestMatched == null || unsupportedKeys.size() < bestMatched.f1.size()) {\n                bestMatched = new Tuple2<>(factory, unsupportedKeys);\n            }\n        }\n    }\n\n    if (supportedFactories.isEmpty()) {\n        String bestMatchedMessage = null;\n        if (bestMatched != null) {\n            bestMatchedMessage =\n                    String.format(\n                            \"%s\\nUnsupported property keys:\\n%s\",\n                            bestMatched.f0.getClass().getName(),\n                            String.join(\"\\n\", bestMatched.f1));\n        }\n\n            \n        throw new NoMatchingTableFactoryException(\n                \"No factory supports all properties.\",\n                bestMatchedMessage,\n                factoryClass,\n                (List<TableFactory>) classFactories,\n                properties);\n    }\n\n    return supportedFactories;\n}", "summary_tokens": ["filters", "the", "matching", "class", "factories", "by", "supported", "properties"], "project": "flink"}
{"id": 4120, "code": "public boolean deleteFromCache(JobID jobId, TransientBlobKey key) {\n    checkNotNull(jobId);\n    return deleteInternal(jobId, key);\n}", "summary_tokens": ["deletes", "the", "file", "associated", "with", "the", "blob", "key", "in", "the", "local", "storage", "of", "the", "blob", "server"], "project": "flink"}
{"id": 7316, "code": "public static <T> SerializedCheckpointData[] fromDeque(\n        ArrayDeque<Tuple2<Long, Set<T>>> checkpoints,\n        TypeSerializer<T> serializer,\n        DataOutputSerializer outputBuffer)\n        throws IOException {\n\n    SerializedCheckpointData[] serializedCheckpoints =\n            new SerializedCheckpointData[checkpoints.size()];\n\n    int pos = 0;\n    for (Tuple2<Long, Set<T>> checkpoint : checkpoints) {\n        outputBuffer.clear();\n        Set<T> checkpointIds = checkpoint.f1;\n\n        for (T id : checkpointIds) {\n            serializer.serialize(id, outputBuffer);\n        }\n\n        serializedCheckpoints[pos++] =\n                new SerializedCheckpointData(\n                        checkpoint.f0, outputBuffer.getCopyOfBuffer(), checkpointIds.size());\n    }\n\n    return serializedCheckpoints;\n}", "summary_tokens": ["converts", "a", "list", "of", "checkpoints", "into", "an", "array", "of", "serialized", "checkpoint", "data"], "project": "flink"}
{"id": 5945, "code": "public void testCanBeSubsumed() throws Exception {\n        \n    CheckpointProperties forced =\n            new CheckpointProperties(\n                    true, CheckpointType.SAVEPOINT, false, false, false, false, false, false);\n    PendingCheckpoint pending = createPendingCheckpoint(forced);\n    assertFalse(pending.canBeSubsumed());\n\n    try {\n        abort(pending, CheckpointFailureReason.CHECKPOINT_SUBSUMED);\n        fail(\"Did not throw expected Exception\");\n    } catch (IllegalStateException ignored) {\n            \n    }\n\n        \n    CheckpointProperties subsumed =\n            new CheckpointProperties(\n                    false, CheckpointType.SAVEPOINT, false, false, false, false, false, false);\n    pending = createPendingCheckpoint(subsumed);\n    assertFalse(pending.canBeSubsumed());\n}", "summary_tokens": ["tests", "that", "pending", "checkpoints", "can", "be", "subsumed", "iff", "they", "are", "forced"], "project": "flink"}
{"id": 3183, "code": "public DataSet<Tuple2<K, LongValue>> getDegrees() {\n    return outDegrees()\n            .union(inDegrees())\n            .name(\"In- and out-degree\")\n            .groupBy(0)\n            .sum(1)\n            .name(\"Sum\");\n}", "summary_tokens": ["return", "the", "degree", "of", "all", "vertices", "in", "the", "graph"], "project": "flink"}
{"id": 8823, "code": "public static RelNode convertSourceToRel(\n        boolean isBatchMode,\n        ReadableConfig config,\n        FlinkRelBuilder relBuilder,\n        ObjectIdentifier identifier,\n        ResolvedCatalogTable catalogTable,\n        FlinkStatistic statistic,\n        List<RelHint> hints,\n        DynamicTableSource tableSource) {\n\n        \n    prepareDynamicSource(identifier, catalogTable, tableSource, isBatchMode, config);\n\n        \n    pushTableScan(\n            isBatchMode, relBuilder, identifier, catalogTable, statistic, hints, tableSource);\n\n        \n    final ResolvedSchema schema = catalogTable.getResolvedSchema();\n    if (!schema.getColumns().stream().allMatch(Column::isPhysical)) {\n        pushMetadataProjection(relBuilder, schema);\n        pushGeneratedProjection(relBuilder, schema);\n    }\n\n        \n    if (!isBatchMode && !schema.getWatermarkSpecs().isEmpty()) {\n        pushWatermarkAssigner(relBuilder, schema);\n    }\n\n    return relBuilder.build();\n}", "summary_tokens": ["converts", "a", "given", "dynamic", "table", "source", "to", "a", "rel", "node"], "project": "flink"}
{"id": 8251, "code": "public ResolvedExpression getWatermarkExpression() {\n    return watermarkExpression;\n}", "summary_tokens": ["returns", "the", "resolved", "expression", "for", "watermark", "generation"], "project": "flink"}
{"id": 5416, "code": "default <K> CheckpointableKeyedStateBackend<K> createKeyedStateBackend(\n        Environment env,\n        JobID jobID,\n        String operatorIdentifier,\n        TypeSerializer<K> keySerializer,\n        int numberOfKeyGroups,\n        KeyGroupRange keyGroupRange,\n        TaskKvStateRegistry kvStateRegistry,\n        TtlTimeProvider ttlTimeProvider,\n        MetricGroup metricGroup,\n        @Nonnull Collection<KeyedStateHandle> stateHandles,\n        CloseableRegistry cancelStreamRegistry,\n        double managedMemoryFraction)\n        throws Exception {\n\n        \n    return createKeyedStateBackend(\n            env,\n            jobID,\n            operatorIdentifier,\n            keySerializer,\n            numberOfKeyGroups,\n            keyGroupRange,\n            kvStateRegistry,\n            ttlTimeProvider,\n            metricGroup,\n            stateHandles,\n            cancelStreamRegistry);\n}", "summary_tokens": ["creates", "a", "new", "checkpointable", "keyed", "state", "backend", "with", "the", "given", "managed", "memory", "fraction"], "project": "flink"}
{"id": 5505, "code": "public boolean isUsingAsynchronousSnapshots() {\n    return true;\n}", "summary_tokens": ["gets", "whether", "the", "key", "value", "data", "structures", "are", "asynchronously", "snapshotted", "which", "is", "always", "true", "for", "this", "state", "backend"], "project": "flink"}
{"id": 8623, "code": "public static boolean supportsImplicitCast(LogicalType sourceType, LogicalType targetType) {\n    return supportsCasting(sourceType, targetType, false);\n}", "summary_tokens": ["returns", "whether", "the", "source", "type", "can", "be", "safely", "casted", "to", "the", "target", "type", "without", "loosing", "information"], "project": "flink"}
{"id": 3403, "code": "public MurmurHash reset() {\n    count = 0;\n    hash = seed;\n    return this;\n}", "summary_tokens": ["re", "initialize", "the", "murmur", "hash", "state"], "project": "flink"}
{"id": 7928, "code": "public static Matcher<Watermark> legacyWatermark(long timestamp) {\n    return new FeatureMatcher<Watermark, Long>(\n            equalTo(timestamp), \"a watermark with value\", \"value of watermark\") {\n        @Override\n        protected Long featureValueOf(Watermark actual) {\n            return actual.getTimestamp();\n        }\n    };\n}", "summary_tokens": ["creates", "a", "matcher", "that", "matches", "when", "the", "examined", "watermark", "has", "the", "given", "timestamp"], "project": "flink"}
{"id": 3028, "code": "public void close() throws Exception {\n    for (State<T> state : getStates()) {\n        for (StateTransition<T> transition : state.getStateTransitions()) {\n            IterativeCondition condition = transition.getCondition();\n            FunctionUtils.closeFunction(condition);\n        }\n    }\n}", "summary_tokens": ["tear", "down", "method", "for", "the", "nfa"], "project": "flink"}
{"id": 6920, "code": "public void enableBackgroundErrors() {\n    this.properties.add(RocksDBProperty.BackgroundErrors.getRocksDBProperty());\n}", "summary_tokens": ["returns", "accumulated", "number", "of", "background", "errors"], "project": "flink"}
{"id": 4314, "code": "public long getEndToEndDuration(long triggerTimestamp) {\n    SubtaskStateStats subtask = getLatestAcknowledgedSubtaskStats();\n    if (subtask != null) {\n        return Math.max(0, subtask.getAckTimestamp() - triggerTimestamp);\n    } else {\n        return -1;\n    }\n}", "summary_tokens": ["returns", "the", "duration", "of", "this", "checkpoint", "at", "the", "task", "operator", "calculated", "as", "the", "time", "since", "triggering", "until", "the", "latest", "acknowledged", "subtask", "or", "code", "0", "code", "if", "no", "subtask", "was", "acknowledged", "yet"], "project": "flink"}
{"id": 3426, "code": "private static <T extends Comparable<T>> void validate(\n        Graph<T, NullValue, NullValue> graph, Result result) throws Exception {\n    Result edgeMetrics = new EdgeMetrics<T, NullValue, NullValue>().run(graph).execute();\n\n    assertEquals(result, edgeMetrics);\n}", "summary_tokens": ["validate", "a", "test", "result"], "project": "flink"}
{"id": 3620, "code": "protected void computeOperatorSpecificDefaultEstimates(DataStatistics statistics) {\n        \n}", "summary_tokens": ["computes", "the", "estimates", "for", "the", "map", "partition", "operator"], "project": "flink"}
{"id": 8873, "code": "private Operation convertCreateFunction(SqlCreateFunction sqlCreateFunction) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlCreateFunction.getFunctionIdentifier());\n\n    if (sqlCreateFunction.isSystemFunction()) {\n        return new CreateTempSystemFunctionOperation(\n                unresolvedIdentifier.getObjectName(),\n                sqlCreateFunction.getFunctionClassName().getValueAs(String.class),\n                sqlCreateFunction.isIfNotExists(),\n                parseLanguage(sqlCreateFunction.getFunctionLanguage()));\n    } else {\n        FunctionLanguage language = parseLanguage(sqlCreateFunction.getFunctionLanguage());\n        CatalogFunction catalogFunction =\n                new CatalogFunctionImpl(\n                        sqlCreateFunction.getFunctionClassName().getValueAs(String.class),\n                        language);\n        ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n\n        return new CreateCatalogFunctionOperation(\n                identifier,\n                catalogFunction,\n                sqlCreateFunction.isIfNotExists(),\n                sqlCreateFunction.isTemporary());\n    }\n}", "summary_tokens": ["convert", "create", "function", "statement"], "project": "flink"}
{"id": 3651, "code": "public boolean isTrivial() {\n    return partitioning == PartitioningProperty.RANDOM_PARTITIONED;\n}", "summary_tokens": ["checks", "if", "the", "properties", "in", "this", "object", "are", "trivial", "i"], "project": "flink"}
{"id": 2866, "code": "public byte getByte(String key, byte defaultValue) {\n    addToDefaults(key, Byte.toString(defaultValue));\n    String value = get(key);\n    if (value == null) {\n        return defaultValue;\n    } else {\n        return Byte.valueOf(value);\n    }\n}", "summary_tokens": ["returns", "the", "byte", "value", "for", "the", "given", "key"], "project": "flink"}
{"id": 5804, "code": "public static void stopServers() throws IOException {\n    if (blobSslServer != null) {\n        blobSslServer.close();\n    }\n    if (blobNonSslServer != null) {\n        blobNonSslServer.close();\n    }\n}", "summary_tokens": ["shuts", "the", "blob", "server", "down"], "project": "flink"}
{"id": 7279, "code": "public static int getDefaultLocalParallelism() {\n    return defaultLocalParallelism;\n}", "summary_tokens": ["gets", "the", "default", "parallelism", "that", "will", "be", "used", "for", "the", "local", "execution", "environment", "created", "by", "create", "local", "environment"], "project": "flink"}
{"id": 7463, "code": "public static Time milliseconds(long milliseconds) {\n    return of(milliseconds, TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["creates", "a", "new", "time", "that", "represents", "the", "given", "number", "of", "milliseconds"], "project": "flink"}
{"id": 4982, "code": "public int getNumOccupiedMemorySegments() {\n        \n    final int numPartitionBuffers =\n            this.partitionBuffers != null\n                    ? this.partitionBuffers.length\n                    : this.buildSideWriteBuffer.getNumOccupiedMemorySegments();\n    return numPartitionBuffers + numOverflowSegments;\n}", "summary_tokens": ["gets", "the", "number", "of", "memory", "segments", "used", "by", "this", "partition", "which", "includes", "build", "side", "memory", "buffers", "and", "overflow", "memory", "segments"], "project": "flink"}
{"id": 1963, "code": "public static Throwable stripCompletionException(Throwable throwable) {\n    return stripException(throwable, CompletionException.class);\n}", "summary_tokens": ["unpacks", "an", "completion", "exception", "and", "returns", "its", "cause"], "project": "flink"}
{"id": 3573, "code": "public double getCpuCost() {\n    return this.cpuCost;\n}", "summary_tokens": ["gets", "the", "cost", "for", "the", "cpu"], "project": "flink"}
{"id": 1052, "code": "public int getNumberOfExecutionRetries() {\n    return numberOfExecutionRetries;\n}", "summary_tokens": ["gets", "the", "number", "of", "times", "the", "system", "will", "try", "to", "re", "execute", "failed", "tasks"], "project": "flink"}
{"id": 6038, "code": "public void testSuspendedOutOfCanceling() throws Exception {\n    final int parallelism = 10;\n    final InteractionsCountingTaskManagerGateway gateway =\n            new InteractionsCountingTaskManagerGateway(parallelism);\n    final SchedulerBase scheduler = createScheduler(gateway, parallelism);\n    final ExecutionGraph eg = scheduler.getExecutionGraph();\n\n    scheduler.startScheduling();\n    ExecutionGraphTestUtils.switchAllVerticesToRunning(eg);\n\n    scheduler.cancel();\n\n    assertEquals(JobStatus.CANCELLING, eg.getState());\n    validateCancelRpcCalls(gateway, parallelism);\n\n        \n    scheduler.closeAsync();\n\n    assertEquals(JobStatus.SUSPENDED, eg.getState());\n\n    ensureCannotLeaveSuspendedState(scheduler, gateway);\n}", "summary_tokens": ["suspending", "from", "canceling", "goes", "to", "suspended", "and", "sends", "no", "additional", "rpc", "calls"], "project": "flink"}
{"id": 4769, "code": "public Map<String, DistributedCache.DistributedCacheEntry> getUserArtifacts() {\n    return userArtifacts;\n}", "summary_tokens": ["gets", "the", "list", "of", "assigned", "user", "jar", "paths"], "project": "flink"}
{"id": 9440, "code": "private Map<String, String> getModifiedOptions(Consumer<Map<String, String>> optionModifier) {\n    Map<String, String> options = getBasicOptions();\n    optionModifier.accept(options);\n    return options;\n}", "summary_tokens": ["returns", "the", "full", "options", "modified", "by", "the", "given", "consumer", "option", "modifier"], "project": "flink"}
{"id": 2247, "code": "public void triggerNonPeriodicScheduledTasksWithRecursion() {\n    execService.triggerNonPeriodicScheduledTasksWithRecursion();\n}", "summary_tokens": ["triggers", "all", "non", "periodically", "scheduled", "tasks"], "project": "flink"}
{"id": 3459, "code": "public <K, V> DataSource<Tuple2<K, V>> readBroadcastState(\n        String uid,\n        String name,\n        TypeInformation<K> keyTypeInfo,\n        TypeInformation<V> valueTypeInfo,\n        TypeSerializer<K> keySerializer,\n        TypeSerializer<V> valueSerializer)\n        throws IOException {\n\n    OperatorState operatorState = metadata.getOperatorState(uid);\n    MapStateDescriptor<K, V> descriptor =\n            new MapStateDescriptor<>(name, keySerializer, valueSerializer);\n    BroadcastStateInputFormat<K, V> inputFormat =\n            new BroadcastStateInputFormat<>(operatorState, descriptor);\n    return env.createInput(inputFormat, new TupleTypeInfo<>(keyTypeInfo, valueTypeInfo));\n}", "summary_tokens": ["read", "operator", "broadcast", "state", "from", "a", "savepoint", "when", "a", "custom", "serializer", "was", "used", "e"], "project": "flink"}
{"id": 2379, "code": "public <U> Class<? extends U> getClass(\n        String name, Class<? extends U> defaultValue, Class<U> xface) {\n    try {\n        Class<?> theClass = getClass(name, defaultValue);\n        if (theClass != null && !xface.isAssignableFrom(theClass))\n            throw new RuntimeException(theClass + \" not \" + xface.getName());\n        else if (theClass != null) return theClass.asSubclass(xface);\n        else return null;\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    }\n}", "summary_tokens": ["get", "the", "value", "of", "the", "code", "name", "code", "property", "as", "a", "code", "class", "code", "implementing", "the", "interface", "specified", "by", "code", "xface", "code"], "project": "flink"}
{"id": 155, "code": "public void testHybridSource() throws Exception {\n    testHybridSource(FailoverType.NONE, sourceWithFixedSwitchPosition());\n}", "summary_tokens": ["test", "the", "source", "in", "the", "happy", "path"], "project": "flink"}
{"id": 9515, "code": "public void triggerNonPeriodicScheduledTasksWithRecursion() {\n    while (!nonPeriodicScheduledTasks.isEmpty()) {\n        final ScheduledTask<?> scheduledTask = nonPeriodicScheduledTasks.poll();\n\n        if (!scheduledTask.isCancelled()) {\n            scheduledTask.execute();\n        }\n    }\n}", "summary_tokens": ["triggers", "all", "non", "periodically", "scheduled", "tasks"], "project": "flink"}
{"id": 8929, "code": "public static List<RelCollation> enumerableNestedLoopJoin(\n        RelMetadataQuery mq, RelNode left, RelNode right, JoinRelType joinType) {\n    return enumerableJoin0(mq, left, right, joinType);\n}", "summary_tokens": ["returns", "the", "collation", "of", "enumerable", "nested", "loop", "join", "based", "on", "its", "inputs", "and", "the", "join", "type"], "project": "flink"}
{"id": 3552, "code": "public void testPortConflictHandling() throws Exception {\n    final MetricReporter rep1 = new JMXReporter(\"9020-9035\");\n    final MetricReporter rep2 = new JMXReporter(\"9020-9035\");\n\n    Gauge<Integer> g1 = () -> 1;\n    Gauge<Integer> g2 = () -> 2;\n\n    rep1.notifyOfAddedMetric(g1, \"rep1\", metricGroup);\n    rep2.notifyOfAddedMetric(g2, \"rep2\", metricGroup);\n\n    MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer();\n\n    ObjectName objectName1 =\n            new ObjectName(\n                    JMX_DOMAIN_PREFIX + \"taskmanager.rep1\",\n                    JMXReporter.generateJmxTable(metricGroup.getAllVariables()));\n    ObjectName objectName2 =\n            new ObjectName(\n                    JMX_DOMAIN_PREFIX + \"taskmanager.rep2\",\n                    JMXReporter.generateJmxTable(metricGroup.getAllVariables()));\n\n    assertEquals(1, mBeanServer.getAttribute(objectName1, \"Value\"));\n    assertEquals(2, mBeanServer.getAttribute(objectName2, \"Value\"));\n\n    rep1.notifyOfRemovedMetric(g1, \"rep1\", null);\n    rep1.notifyOfRemovedMetric(g2, \"rep2\", null);\n}", "summary_tokens": ["verifies", "that", "multiple", "jmxreporters", "can", "be", "started", "on", "the", "same", "machine", "and", "register", "metrics", "at", "the", "mbean", "server"], "project": "flink"}
{"id": 9593, "code": "public void testFaultyCast() throws Exception {\n    ExecutionEnvironment ee = ExecutionEnvironment.getExecutionEnvironment();\n\n    DataSet<String> b = ee.fromElements(\"a\", \"b\");\n    GroupReduceOperator<String, String> a =\n            b.groupBy(\n                            new KeySelector<String, Long>() {\n                                @Override\n                                public Long getKey(String value) throws Exception {\n                                    return 1L;\n                                }\n                            })\n                    .sortGroup(\n                            new KeySelector<String, Double>() {\n                                @Override\n                                public Double getKey(String value) throws Exception {\n                                    return 1.0;\n                                }\n                            },\n                            Order.DESCENDING)\n                    .first(1);\n\n    List<String> result = b.collect();\n\n    String expected = \"a\\nb\";\n\n    compareResultAsText(result, expected);\n}", "summary_tokens": ["test", "for", "flink", "0"], "project": "flink"}
{"id": 6175, "code": "public void testReceiveCompressedBuffer() throws Exception {\n    int bufferSize = 1024;\n    String compressionCodec = \"LZ4\";\n    BufferCompressor compressor = new BufferCompressor(bufferSize, compressionCodec);\n    BufferDecompressor decompressor = new BufferDecompressor(bufferSize, compressionCodec);\n    NetworkBufferPool networkBufferPool = new NetworkBufferPool(10, bufferSize);\n    SingleInputGate inputGate =\n            new SingleInputGateBuilder()\n                    .setBufferDecompressor(decompressor)\n                    .setSegmentProvider(networkBufferPool)\n                    .build();\n    RemoteInputChannel inputChannel = createRemoteInputChannel(inputGate, null);\n    inputGate.setInputChannels(inputChannel);\n\n    try {\n        BufferPool bufferPool = networkBufferPool.createBufferPool(8, 8);\n        inputGate.setBufferPool(bufferPool);\n        inputGate.setupChannels();\n\n        CreditBasedPartitionRequestClientHandler handler =\n                new CreditBasedPartitionRequestClientHandler();\n        handler.addInputChannel(inputChannel);\n\n        Buffer buffer =\n                compressor.compressToOriginalBuffer(TestBufferFactory.createBuffer(bufferSize));\n        BufferResponse bufferResponse =\n                createBufferResponse(\n                        buffer,\n                        0,\n                        inputChannel.getInputChannelId(),\n                        2,\n                        new NetworkBufferAllocator(handler));\n        assertTrue(bufferResponse.isCompressed);\n        handler.channelRead(null, bufferResponse);\n\n        Buffer receivedBuffer = inputChannel.getNextReceivedBuffer();\n        assertNotNull(receivedBuffer);\n        assertTrue(receivedBuffer.isCompressed());\n        receivedBuffer.recycleBuffer();\n    } finally {\n        releaseResource(inputGate, networkBufferPool);\n    }\n}", "summary_tokens": ["verifies", "that", "buffer", "response", "of", "compressed", "buffer", "can", "be", "handled", "correctly"], "project": "flink"}
{"id": 3807, "code": "public String createRetrievalToken() throws IOException {\n    File retrievalToken =\n            new File(\n                    resource.baseDirectory,\n                    \"retrieval_token_\" + UUID.randomUUID().toString() + \".json\");\n    if (retrievalToken.createNewFile()) {\n        final DataOutputStream dos = new DataOutputStream(new FileOutputStream(retrievalToken));\n        dos.writeBytes(\"{\\\"manifest\\\": {}}\");\n        dos.flush();\n        dos.close();\n        return retrievalToken.getAbsolutePath();\n    } else {\n        throw new IOException(\n                \"Could not create the RetrievalToken file: \"\n                        + retrievalToken.getAbsolutePath());\n    }\n}", "summary_tokens": ["returns", "an", "empty", "retrieval", "token", "because", "no", "files", "will", "be", "transmit", "via", "artifact", "service", "in", "process", "mode"], "project": "flink"}
{"id": 5109, "code": "void unregisterKvState(KeyGroupRange keyGroupRange) {\n    if (keyGroupRange.getStartKeyGroup() < 0\n            || keyGroupRange.getEndKeyGroup() >= numKeyGroups) {\n        throw new IndexOutOfBoundsException(\"Key group index\");\n    }\n\n    for (int kgIdx = keyGroupRange.getStartKeyGroup();\n            kgIdx <= keyGroupRange.getEndKeyGroup();\n            ++kgIdx) {\n        if (kvStateIds[kgIdx] == null || kvStateAddresses[kgIdx] == null) {\n            throw new IllegalArgumentException(\n                    \"Not registered. Probably registration/unregistration race.\");\n        }\n\n        numRegisteredKeyGroups--;\n\n        kvStateIds[kgIdx] = null;\n        kvStateAddresses[kgIdx] = null;\n    }\n}", "summary_tokens": ["registers", "a", "kv", "state", "instance", "for", "the", "given", "key", "group", "index"], "project": "flink"}
{"id": 8054, "code": "public String getBuiltInDatabaseName() {\n        \n    return catalogs.get(getBuiltInCatalogName()).getDefaultDatabase();\n}", "summary_tokens": ["gets", "the", "built", "in", "database", "name", "in", "the", "built", "in", "catalog"], "project": "flink"}
{"id": 4492, "code": "public List<MemorySegment> close() throws IOException {\n    final ArrayList<MemorySegment> segments =\n            new ArrayList<MemorySegment>(\n                    this.fullSegments.size() + this.numMemorySegmentsInWriter);\n\n        \n    if (getCurrentSegment() != null) {\n        segments.add(getCurrentSegment());\n        clear();\n    }\n\n    moveAll(this.fullSegments, segments);\n    this.fullSegments.clear();\n\n        \n    if (this.writer != null) {\n            \n        this.writer.close();\n        for (int i = this.numMemorySegmentsInWriter; i > 0; i--) {\n            segments.add(this.writer.getNextReturnedBlock());\n        }\n        this.writer.closeAndDelete();\n        this.writer = null;\n    }\n\n        \n    if (this.inMemInView != null) {\n        this.inMemInView = null;\n    }\n    if (this.externalInView != null) {\n        if (!this.externalInView.isClosed()) {\n            this.externalInView.close();\n        }\n        this.externalInView = null;\n    }\n    return segments;\n}", "summary_tokens": ["a", "list", "with", "all", "memory", "segments", "that", "have", "been", "taken", "from", "the", "memory", "segment", "source"], "project": "flink"}
{"id": 4075, "code": "public void sendRequest(HttpRequest request, Duration timeout)\n        throws InterruptedException, TimeoutException {\n    LOG.debug(\"Writing {}.\", request);\n\n        \n    ChannelFuture connect = bootstrap.connect(host, port);\n\n    Channel channel;\n    if (connect.await(timeout.toMillis(), TimeUnit.MILLISECONDS)) {\n        channel = connect.channel();\n    } else {\n        throw new TimeoutException(\"Connection failed\");\n    }\n\n    channel.writeAndFlush(request);\n}", "summary_tokens": ["sends", "a", "request", "to", "to", "the", "server"], "project": "flink"}
{"id": 1356, "code": "public static Time fromDuration(Duration duration) {\n    return milliseconds(duration.toMillis());\n}", "summary_tokens": ["creates", "a", "new", "time", "that", "represents", "the", "number", "of", "milliseconds", "in", "the", "given", "duration"], "project": "flink"}
{"id": 1136, "code": "public boolean isConverged(int iteration, DoubleValue value) {\n    return value.getValue() == 0;\n}", "summary_tokens": ["returns", "true", "if", "the", "aggregator", "value", "is", "zero", "false", "otherwise"], "project": "flink"}
{"id": 3294, "code": "public <T extends Value> T getPreviousIterationAggregate(String name) {\n    return this.runtimeContext.getPreviousIterationAggregate(name);\n}", "summary_tokens": ["get", "the", "aggregated", "value", "that", "an", "aggregator", "computed", "in", "the", "previous", "iteration"], "project": "flink"}
{"id": 8793, "code": "private Frame maybeAddValueGenerator(RelNode rel, Frame frame) {\n    final CorelMap cm1 = new CorelMapBuilder().build(frame.r, rel);\n    if (!cm1.mapRefRelToCorRef.containsKey(rel)) {\n        return frame;\n    }\n    final Collection<CorRef> needs = cm1.mapRefRelToCorRef.get(rel);\n    final ImmutableSortedSet<CorDef> haves = frame.corDefOutputs.keySet();\n    if (hasAll(needs, haves)) {\n        return frame;\n    }\n    return decorrelateInputWithValueGenerator(rel, frame);\n}", "summary_tokens": ["adds", "a", "value", "generator", "to", "satisfy", "the", "correlating", "variables", "used", "by", "a", "relational", "expression", "if", "those", "variables", "are", "not", "already", "provided", "by", "its", "input"], "project": "flink"}
{"id": 5316, "code": "default boolean isCompatibleWith(final SecurityConfiguration securityConfig) {\n    return false;\n}", "summary_tokens": ["check", "if", "this", "factory", "is", "compatible", "with", "the", "security", "configuration"], "project": "flink"}
{"id": 2054, "code": "public static Thread addShutdownHook(\n        final AutoCloseable service, final String serviceName, final Logger logger) {\n\n    checkNotNull(service);\n    checkNotNull(logger);\n\n    final Thread shutdownHook =\n            new Thread(\n                    () -> {\n                        try {\n                            service.close();\n                        } catch (Throwable t) {\n                            logger.error(\n                                    \"Error during shutdown of {} via JVM shutdown hook.\",\n                                    serviceName,\n                                    t);\n                        }\n                    },\n                    serviceName + \" shutdown hook\");\n\n    return addShutdownHookThread(shutdownHook, serviceName, logger) ? shutdownHook : null;\n}", "summary_tokens": ["adds", "a", "shutdown", "hook", "to", "the", "jvm", "and", "returns", "the", "thread", "which", "has", "been", "registered"], "project": "flink"}
{"id": 8655, "code": "public static java.sql.Timestamp toSQLTimestamp(long v) {\n    return new java.sql.Timestamp(v - LOCAL_TZ.getOffset(v));\n}", "summary_tokens": ["converts", "the", "internal", "representation", "of", "a", "sql", "timestamp", "long", "to", "the", "java", "type", "used", "for", "udf", "parameters", "java"], "project": "flink"}
{"id": 165, "code": "public void close() throws IOException {\n    try {\n        if (session != null) {\n            session.close();\n        }\n    } catch (Exception e) {\n        LOG.error(\"Error while closing session.\", e);\n    }\n\n    try {\n        if (cluster != null) {\n            cluster.close();\n        }\n    } catch (Exception e) {\n        LOG.error(\"Error while closing cluster.\", e);\n    }\n}", "summary_tokens": ["closes", "all", "resources", "used"], "project": "flink"}
{"id": 7747, "code": "public void testReaderScalingDown() throws Exception {\n    HarnessWithFormat[] beforeRescale = {};\n    try {\n        beforeRescale = buildAndStart(5, 15);\n        try (HarnessWithFormat afterRescale =\n                buildAndStart(1, 0, 5, snapshotAndMergeState(beforeRescale))) {\n\n            afterRescale.awaitEverythingProcessed();\n\n            for (HarnessWithFormat i : beforeRescale) {\n                i.getHarness()\n                        .getOutput()\n                        .clear(); \n                    \n                i.awaitEverythingProcessed();\n            }\n\n            Assert.assertEquals(collectOutput(beforeRescale), collectOutput(afterRescale));\n        }\n    } finally {\n        for (HarnessWithFormat harness : beforeRescale) {\n            harness.close();\n        }\n    }\n}", "summary_tokens": ["simulates", "the", "scenario", "of", "scaling", "down", "from", "0", "to", "0", "instances"], "project": "flink"}
{"id": 4748, "code": "public String getName() {\n    return this.jobName;\n}", "summary_tokens": ["returns", "the", "name", "assigned", "to", "the", "job", "graph"], "project": "flink"}
{"id": 7011, "code": "public void testUseOptimizePointLookupWithMapState() throws Exception {\n    RocksDBStateBackend rocksDBStateBackend = createStateBackendWithOptimizePointLookup();\n    RocksDBKeyedStateBackend<Integer> keyedStateBackend =\n            createKeyedStateBackend(\n                    rocksDBStateBackend.getEmbeddedRocksDBStateBackend(),\n                    new MockEnvironmentBuilder().build(),\n                    IntSerializer.INSTANCE);\n    try {\n        MapStateDescriptor<Integer, Long> stateDescriptor =\n                new MapStateDescriptor<>(\n                        \"map\", IntSerializer.INSTANCE, LongSerializer.INSTANCE);\n        MapState<Integer, Long> mapState =\n                keyedStateBackend.getPartitionedState(\n                        VoidNamespace.INSTANCE,\n                        VoidNamespaceSerializer.INSTANCE,\n                        stateDescriptor);\n\n        keyedStateBackend.setCurrentKey(1);\n        Map<Integer, Long> expectedResult = new HashMap<>();\n        for (int i = 0; i < 100; i++) {\n            long uv = ThreadLocalRandom.current().nextLong();\n            mapState.put(i, uv);\n            expectedResult.put(i, uv);\n        }\n\n        Iterator<Map.Entry<Integer, Long>> iterator = mapState.entries().iterator();\n        while (iterator.hasNext()) {\n            Map.Entry<Integer, Long> entry = iterator.next();\n            assertEquals(entry.getValue(), expectedResult.remove(entry.getKey()));\n            iterator.remove();\n        }\n        assertTrue(expectedResult.isEmpty());\n        assertTrue(mapState.isEmpty());\n    } finally {\n        keyedStateBackend.dispose();\n    }\n}", "summary_tokens": ["tests", "to", "cover", "case", "when", "user", "choose", "optimize", "for", "point", "lookup", "with", "iterator", "interfaces", "on", "map", "state"], "project": "flink"}
{"id": 5587, "code": "private Throwable preProcessException(Throwable t) {\n        \n    if (t instanceof WrappingRuntimeException) {\n        t = ((WrappingRuntimeException) t).unwrap();\n    }\n\n    TaskManagerExceptionUtils.tryEnrichTaskManagerError(t);\n\n        \n    if (ExceptionUtils.isJvmFatalError(t)\n            || (t instanceof OutOfMemoryError\n                    && taskManagerConfig.shouldExitJvmOnOutOfMemoryError())) {\n\n            \n            \n            \n        try {\n            LOG.error(\n                    \"Encountered fatal error {} - terminating the JVM\",\n                    t.getClass().getName(),\n                    t);\n        } finally {\n            Runtime.getRuntime().halt(-1);\n        }\n    }\n\n    return t;\n}", "summary_tokens": ["unwrap", "enrich", "and", "handle", "fatal", "errors"], "project": "flink"}
{"id": 7004, "code": "public void testSetEmptyPaths() throws Exception {\n    String checkpointPath = tempFolder.newFolder().toURI().toString();\n    RocksDBStateBackend rocksDbBackend = new RocksDBStateBackend(checkpointPath);\n    rocksDbBackend.setDbStoragePaths();\n}", "summary_tokens": ["validates", "that", "empty", "arguments", "for", "the", "local", "db", "path", "are", "invalid"], "project": "flink"}
{"id": 6591, "code": "public void testValueStateDefaultValue() throws Exception {\n    ValueStateDescriptor<String> kvId = new ValueStateDescriptor<>(\"id\", String.class, \"Hello\");\n\n    KeyedStateHandle keyedStateHandle;\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n    try {\n        ValueState<String> state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n        backend.setCurrentKey(1);\n        assertEquals(\"Hello\", state.value());\n\n        state.update(\"Ciao\");\n        assertEquals(\"Ciao\", state.value());\n\n        state.clear();\n        assertEquals(\"Hello\", state.value());\n\n        keyedStateHandle =\n                runSnapshot(\n                        backend.snapshot(\n                                1L,\n                                1L,\n                                createStreamFactory(),\n                                CheckpointOptions.forCheckpointWithDefaultLocation()),\n                        new SharedStateRegistryImpl());\n    } finally {\n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n\n    try {\n        backend = restoreKeyedBackend(IntSerializer.INSTANCE, keyedStateHandle);\n        ValueState<String> state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n        backend.setCurrentKey(1);\n        assertEquals(\"Hello\", state.value());\n\n    } finally {\n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["verify", "that", "an", "empty", "value", "state", "will", "yield", "the", "default", "value"], "project": "flink"}
{"id": 6757, "code": "long getAndPruneValueForSnapshot(long node, int snapshotVersion) {\n        \n    boolean isPruning = pruningValueNodes.add(node);\n    try {\n        long snapshotValuePointer = NIL_VALUE_POINTER;\n        long valuePointer;\n        ValueVersionIterator versionIterator = new ValueVersionIterator(node);\n        while (versionIterator.hasNext()) {\n            valuePointer = versionIterator.getValuePointer();\n            int version = versionIterator.next();\n                \n            if (snapshotValuePointer == NIL_VALUE_POINTER && version < snapshotVersion) {\n                snapshotValuePointer = valuePointer;\n                if (!isPruning) {\n                    break;\n                }\n            }\n\n                \n                \n                \n            if (highestFinishedSnapshotVersion >= version) {\n                long nextValuePointer =\n                        SkipListUtils.helpGetNextValuePointer(valuePointer, spaceAllocator);\n                if (nextValuePointer != NIL_VALUE_POINTER) {\n                    SkipListUtils.helpSetNextValuePointer(\n                            valuePointer, NIL_VALUE_POINTER, spaceAllocator);\n                    SkipListUtils.removeAllValues(nextValuePointer, spaceAllocator);\n                }\n                break;\n            }\n        }\n\n        return snapshotValuePointer;\n    } finally {\n            \n        if (isPruning) {\n            pruningValueNodes.remove(node);\n        }\n    }\n}", "summary_tokens": ["returns", "the", "value", "pointer", "used", "by", "the", "snapshot", "of", "the", "given", "version", "and", "useless", "version", "values", "will", "be", "pruned"], "project": "flink"}
{"id": 1783, "code": "public int getIntLittleEndian(int index) {\n    if (LITTLE_ENDIAN) {\n        return getInt(index);\n    } else {\n        return Integer.reverseBytes(getInt(index));\n    }\n}", "summary_tokens": ["reads", "an", "int", "value", "0", "bit", "0", "bytes", "from", "the", "given", "position", "in", "little", "endian", "byte", "order"], "project": "flink"}
{"id": 8905, "code": "private Operation convertShowModules(SqlShowModules sqlShowModules) {\n    return new ShowModulesOperation(sqlShowModules.requireFull());\n}", "summary_tokens": ["convert", "show", "full", "modules", "statement"], "project": "flink"}
{"id": 6270, "code": "public void testJobGraphRemovalFailureAndLockRelease() throws Exception {\n    final JobGraphStore submittedJobGraphStore =\n            createZooKeeperJobGraphStore(\"/testConcurrentAddJobGraph\");\n    final JobGraphStore otherSubmittedJobGraphStore =\n            createZooKeeperJobGraphStore(\"/testConcurrentAddJobGraph\");\n\n    final TestingJobGraphListener listener = new TestingJobGraphListener();\n    submittedJobGraphStore.start(listener);\n    otherSubmittedJobGraphStore.start(listener);\n\n    final JobGraph jobGraph = JobGraphTestUtils.emptyJobGraph();\n    submittedJobGraphStore.putJobGraph(jobGraph);\n\n    final JobGraph recoveredJobGraph =\n            otherSubmittedJobGraphStore.recoverJobGraph(jobGraph.getJobID());\n\n    assertThat(recoveredJobGraph, is(notNullValue()));\n\n    try {\n        otherSubmittedJobGraphStore.removeJobGraph(recoveredJobGraph.getJobID());\n        fail(\n                \"It should not be possible to remove the JobGraph since the first store still has a lock on it.\");\n    } catch (Exception ignored) {\n            \n    }\n\n    submittedJobGraphStore.stop();\n\n        \n    otherSubmittedJobGraphStore.removeJobGraph(recoveredJobGraph.getJobID());\n\n    assertThat(\n            otherSubmittedJobGraphStore.recoverJobGraph(recoveredJobGraph.getJobID()),\n            is(nullValue()));\n\n    otherSubmittedJobGraphStore.stop();\n}", "summary_tokens": ["tests", "that", "we", "fail", "with", "an", "exception", "if", "the", "job", "cannot", "be", "removed", "from", "the", "zoo", "keeper", "job", "graph", "store"], "project": "flink"}
{"id": 1389, "code": "public final void setPriorSerializer(TypeSerializer<T> serializer) {\n    this.serializer = Preconditions.checkNotNull(serializer);\n}", "summary_tokens": ["set", "the", "originating", "serializer", "of", "this", "configuration", "snapshot"], "project": "flink"}
{"id": 6996, "code": "public void testCleanupOfSnapshotsInFailureCase() throws Exception {\n    long checkpointId = 1L;\n    long timestamp = 42L;\n\n    MockEnvironment env = MockEnvironment.builder().build();\n\n    final IOException testException = new IOException(\"Test exception\");\n    CheckpointStateOutputStream outputStream = spy(new FailingStream(testException));\n\n    RocksDBStateBackend backend =\n            new RocksDBStateBackend((StateBackend) new MemoryStateBackend());\n\n    backend.setDbStoragePath(temporaryFolder.newFolder().toURI().toString());\n\n    AbstractKeyedStateBackend<Void> keyedStateBackend =\n            backend.createKeyedStateBackend(\n                    env,\n                    new JobID(),\n                    \"test operator\",\n                    VoidSerializer.INSTANCE,\n                    1,\n                    new KeyGroupRange(0, 0),\n                    null,\n                    TtlTimeProvider.DEFAULT,\n                    new UnregisteredMetricsGroup(),\n                    Collections.emptyList(),\n                    new CloseableRegistry());\n\n    try {\n            \n        keyedStateBackend.getPartitionedState(\n                \"namespace\",\n                StringSerializer.INSTANCE,\n                new ValueStateDescriptor<>(\"foobar\", String.class));\n\n        RunnableFuture<SnapshotResult<KeyedStateHandle>> snapshotFuture =\n                keyedStateBackend.snapshot(\n                        checkpointId,\n                        timestamp,\n                        new TestCheckpointStreamFactory(() -> outputStream),\n                        CheckpointOptions.forCheckpointWithDefaultLocation());\n\n        try {\n            FutureUtils.runIfNotDoneAndGet(snapshotFuture);\n            fail(\"Expected an exception to be thrown here.\");\n        } catch (ExecutionException e) {\n            Assert.assertEquals(testException, e.getCause());\n        }\n\n        verify(outputStream).close();\n    } finally {\n        IOUtils.closeQuietly(keyedStateBackend);\n        keyedStateBackend.dispose();\n        IOUtils.closeQuietly(env);\n    }\n}", "summary_tokens": ["test", "that", "the", "snapshot", "files", "are", "cleaned", "up", "in", "case", "of", "a", "failure", "during", "the", "snapshot", "procedure"], "project": "flink"}
{"id": 1625, "code": "private static void getContainedGenericTypes(\n        CompositeType<?> typeInfo, List<GenericTypeInfo<?>> target) {\n    for (int i = 0; i < typeInfo.getArity(); i++) {\n        TypeInformation<?> type = typeInfo.getTypeAt(i);\n        if (type instanceof CompositeType) {\n            getContainedGenericTypes((CompositeType<?>) type, target);\n        } else if (type instanceof GenericTypeInfo) {\n            if (!target.contains(type)) {\n                target.add((GenericTypeInfo<?>) type);\n            }\n        }\n    }\n}", "summary_tokens": ["returns", "all", "generic", "type", "infos", "contained", "in", "a", "composite", "type"], "project": "flink"}
{"id": 6497, "code": "protected void assertOriginalEqualsToUnmarshalled(R expected, R actual) {\n    Assert.assertEquals(expected, actual);\n}", "summary_tokens": ["asserts", "that", "two", "objects", "are", "equal"], "project": "flink"}
{"id": 4933, "code": "protected Collector<OT> getLastOutputCollector() {\n    int numChained = this.chainedTasks.size();\n    return (numChained == 0)\n            ? output\n            : (Collector<OT>) chainedTasks.get(numChained - 1).getOutputCollector();\n}", "summary_tokens": ["the", "last", "output", "collector", "in", "the", "collector", "chain"], "project": "flink"}
{"id": 1702, "code": "public Path getPath() {\n    return file;\n}", "summary_tokens": ["returns", "the", "path", "of", "the", "file", "containing", "this", "split", "s", "data"], "project": "flink"}
{"id": 1140, "code": "public boolean updateCombinedWatermark() {\n    long minimumOverAllOutputs = Long.MAX_VALUE;\n\n        \n        \n    if (partialWatermarks.isEmpty()) {\n        return false;\n    }\n\n    boolean allIdle = true;\n    for (PartialWatermark partialWatermark : partialWatermarks) {\n        if (!partialWatermark.isIdle()) {\n            minimumOverAllOutputs =\n                    Math.min(minimumOverAllOutputs, partialWatermark.getWatermark());\n            allIdle = false;\n        }\n    }\n\n    this.idle = allIdle;\n\n    if (!allIdle && minimumOverAllOutputs > combinedWatermark) {\n        combinedWatermark = minimumOverAllOutputs;\n        return true;\n    }\n\n    return false;\n}", "summary_tokens": ["checks", "whether", "we", "need", "to", "update", "the", "combined", "watermark"], "project": "flink"}
{"id": 4424, "code": "public void markFailed(Throwable t) {\n    currentExecution.markFailed(t);\n}", "summary_tokens": ["this", "method", "marks", "the", "task", "as", "failed", "but", "will", "make", "no", "attempt", "to", "remove", "task", "execution", "from", "the", "task", "manager"], "project": "flink"}
{"id": 3330, "code": "public final <T extends Aggregator<?>> T getIterationAggregator(String name) {\n    return this.runtimeContext.getIterationAggregator(name);\n}", "summary_tokens": ["gets", "the", "iteration", "aggregator", "registered", "under", "the", "given", "name"], "project": "flink"}
{"id": 1840, "code": "public static <L, R> Left<L, R> obtainLeft(\n        Either<L, R> input, TypeSerializer<L> leftSerializer) {\n    if (input.isLeft()) {\n        return (Left<L, R>) input;\n    } else {\n        Right<L, R> right = (Right<L, R>) input;\n        if (right.left == null) {\n            right.left = Left.of(leftSerializer.createInstance());\n            right.left.right = right;\n        }\n        return right.left;\n    }\n}", "summary_tokens": ["utility", "function", "for", "either", "serializer", "to", "support", "object", "reuse"], "project": "flink"}
{"id": 411, "code": "public static HiveParserRowResolver getCombinedRR(\n        HiveParserRowResolver leftRR, HiveParserRowResolver rightRR) throws SemanticException {\n    HiveParserRowResolver combinedRR = new HiveParserRowResolver();\n    HiveParserRowResolver.IntRef outputColPos = new HiveParserRowResolver.IntRef();\n    if (!add(combinedRR, leftRR, outputColPos)) {\n        LOG.warn(\"Duplicates detected when adding columns to RR: see previous message\");\n    }\n    if (!add(combinedRR, rightRR, outputColPos)) {\n        LOG.warn(\"Duplicates detected when adding columns to RR: see previous message\");\n    }\n    return combinedRR;\n}", "summary_tokens": ["return", "a", "new", "row", "resolver", "that", "is", "combination", "of", "left", "rr", "and", "right", "rr"], "project": "flink"}
{"id": 2818, "code": "public O withForwardedFieldsSecond(String... forwardedFieldsSecond) {\n    if (this.udfSemantics == null || this.analyzedUdfSemantics) {\n            \n        setSemanticProperties(extractSemanticAnnotationsFromUdf(getFunction().getClass()));\n    }\n\n    if (this.udfSemantics == null || this.analyzedUdfSemantics) {\n        setSemanticProperties(new DualInputSemanticProperties());\n        SemanticPropUtil.getSemanticPropsDualFromString(\n                this.udfSemantics,\n                null,\n                forwardedFieldsSecond,\n                null,\n                null,\n                null,\n                null,\n                getInput1Type(),\n                getInput2Type(),\n                getResultType());\n    } else {\n        if (udfWithForwardedFieldsSecondAnnotation(getFunction().getClass())) {\n                \n            throw new SemanticProperties.InvalidSemanticAnnotationException(\n                    \"Forwarded field information \"\n                            + \"has already been added by a function annotation for the second input of this operator. \"\n                            + \"Cannot overwrite function annotations.\");\n        } else {\n            SemanticPropUtil.getSemanticPropsDualFromString(\n                    this.udfSemantics,\n                    null,\n                    forwardedFieldsSecond,\n                    null,\n                    null,\n                    null,\n                    null,\n                    getInput1Type(),\n                    getInput2Type(),\n                    getResultType());\n        }\n    }\n\n    O returnType = (O) this;\n    return returnType;\n}", "summary_tokens": ["adds", "semantic", "information", "about", "forwarded", "fields", "of", "the", "second", "input", "of", "the", "user", "defined", "function"], "project": "flink"}
{"id": 8895, "code": "private Operation convertShowPartitions(SqlShowPartitions sqlShowPartitions) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlShowPartitions.fullTableName());\n    ObjectIdentifier tableIdentifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n    LinkedHashMap<String, String> partitionKVs = sqlShowPartitions.getPartitionKVs();\n    if (partitionKVs != null) {\n        CatalogPartitionSpec partitionSpec = new CatalogPartitionSpec(partitionKVs);\n        return new ShowPartitionsOperation(tableIdentifier, partitionSpec);\n    }\n    return new ShowPartitionsOperation(tableIdentifier, null);\n}", "summary_tokens": ["convert", "show", "partitions", "statement"], "project": "flink"}
{"id": 7538, "code": "private long cleanupTime(W window) {\n    if (windowAssigner.isEventTime()) {\n        long cleanupTime = window.maxTimestamp() + allowedLateness;\n        return cleanupTime >= window.maxTimestamp() ? cleanupTime : Long.MAX_VALUE;\n    } else {\n        return window.maxTimestamp();\n    }\n}", "summary_tokens": ["returns", "the", "cleanup", "time", "for", "a", "window", "which", "is", "window"], "project": "flink"}
{"id": 2250, "code": "public void testConfigOptionExclusion() {\n    final String expectedTable =\n            \"<table class=\\\"configuration table table-bordered\\\">\\n\"\n                    + \"    <thead>\\n\"\n                    + \"        <tr>\\n\"\n                    + \"            <th class=\\\"text-left\\\" style=\\\"width: 20%\\\">Key</th>\\n\"\n                    + \"            <th class=\\\"text-left\\\" style=\\\"width: 15%\\\">Default</th>\\n\"\n                    + \"            <th class=\\\"text-left\\\" style=\\\"width: 10%\\\">Type</th>\\n\"\n                    + \"            <th class=\\\"text-left\\\" style=\\\"width: 55%\\\">Description</th>\\n\"\n                    + \"        </tr>\\n\"\n                    + \"    </thead>\\n\"\n                    + \"    <tbody>\\n\"\n                    + \"        <tr>\\n\"\n                    + \"            <td><h5>first.option.a</h5></td>\\n\"\n                    + \"            <td style=\\\"word-wrap: break-word;\\\">2</td>\\n\"\n                    + \"            <td>Integer</td>\\n\"\n                    + \"            <td>This is example description for the first option.</td>\\n\"\n                    + \"        </tr>\\n\"\n                    + \"    </tbody>\\n\"\n                    + \"</table>\\n\";\n    final String htmlTable =\n            ConfigOptionsDocGenerator.generateTablesForClass(TestConfigGroupWithExclusion.class)\n                    .get(0)\n                    .f1;\n\n    assertEquals(expectedTable, htmlTable);\n}", "summary_tokens": ["tests", "that", "config", "option", "annotated", "with", "documentation"], "project": "flink"}
{"id": 3191, "code": "public Graph<K, VV, EV> addVertex(final Vertex<K, VV> vertex) {\n    List<Vertex<K, VV>> newVertex = new ArrayList<>();\n    newVertex.add(vertex);\n\n    return addVertices(newVertex);\n}", "summary_tokens": ["adds", "the", "input", "vertex", "to", "the", "graph"], "project": "flink"}
{"id": 153, "code": "public void testThatInterleavingThreadsMayBlockEachOtherButDoNotCauseRaceConditions()\n        throws Exception {\n    CountDownLatch blockedWriteLatch = new CountDownLatch(1);\n    CountDownLatch delayedStartLatch = new CountDownLatch(1);\n    AsyncSinkWriterImpl sink =\n            new AsyncSinkReleaseAndBlockWriterImpl(\n                    sinkInitContext,\n                    3,\n                    1,\n                    20,\n                    100,\n                    100,\n                    100,\n                    blockedWriteLatch,\n                    delayedStartLatch,\n                    true);\n\n    writeTwoElementsAndInterleaveTheNextTwoElements(sink, blockedWriteLatch, delayedStartLatch);\n    assertEquals(Arrays.asList(1, 2, 3, 4), res);\n}", "summary_tokens": ["this", "test", "considers", "what", "could", "happen", "if", "the", "timer", "elapses", "triggering", "a", "flush", "while", "a", "long", "running", "call", "to", "submit", "request", "entries", "remains", "uncompleted", "for", "some", "time"], "project": "flink"}
{"id": 7569, "code": "public void finish(StreamTaskActionExecutor actionExecutor, StopMode stopMode)\n        throws Exception {\n    if (!isHead && stopMode == StopMode.DRAIN) {\n            \n            \n        actionExecutor.runThrowing(() -> endOperatorInput(1));\n    }\n\n    quiesceTimeServiceAndFinishOperator(actionExecutor, stopMode);\n\n        \n    if (next != null) {\n        next.finish(actionExecutor, stopMode);\n    }\n}", "summary_tokens": ["finishes", "the", "wrapped", "operator", "and", "propagates", "the", "finish", "operation", "to", "the", "next", "wrapper", "that", "the", "next", "points", "to"], "project": "flink"}
{"id": 933, "code": "protected Consumer<byte[]> createPulsarConsumer(TopicPartition partition) {\n    ConsumerBuilder<byte[]> consumerBuilder =\n            createConsumerBuilder(pulsarClient, Schema.BYTES, configuration);\n\n    consumerBuilder.topic(partition.getFullTopicName());\n\n        \n    if (sourceConfiguration.getSubscriptionType() == SubscriptionType.Key_Shared) {\n        KeySharedPolicy policy =\n                KeySharedPolicy.stickyHashRange().ranges(partition.getPulsarRange());\n        consumerBuilder.keySharedPolicy(policy);\n    }\n\n        \n    return sneakyClient(consumerBuilder::subscribe);\n}", "summary_tokens": ["create", "a", "specified", "consumer", "by", "the", "given", "topic", "partition"], "project": "flink"}
{"id": 6980, "code": "public void transferAllStateDataToDirectory(\n        IncrementalRemoteKeyedStateHandle restoreStateHandle,\n        Path dest,\n        CloseableRegistry closeableRegistry)\n        throws Exception {\n\n    final Map<StateHandleID, StreamStateHandle> sstFiles = restoreStateHandle.getSharedState();\n    final Map<StateHandleID, StreamStateHandle> miscFiles =\n            restoreStateHandle.getPrivateState();\n\n    downloadDataForAllStateHandles(sstFiles, dest, closeableRegistry);\n    downloadDataForAllStateHandles(miscFiles, dest, closeableRegistry);\n}", "summary_tokens": ["transfer", "all", "state", "data", "to", "the", "target", "directory", "using", "specified", "number", "of", "threads"], "project": "flink"}
{"id": 4870, "code": "public List<ThreadInfoSample> getSamples() {\n    return samples;\n}", "summary_tokens": ["returns", "a", "list", "of", "thread", "info", "sample"], "project": "flink"}
{"id": 4547, "code": "public void trim(int newSize) {\n    maxCapacity =\n            Math.min(Math.max(newSize, positionMarker.getCached()), buffer.getMaxCapacity());\n}", "summary_tokens": ["the", "result", "capacity", "can", "not", "be", "greater", "than", "allocated", "memory", "segment"], "project": "flink"}
{"id": 4474, "code": "public static Path archiveJob(\n        Path rootPath, JobID jobId, Collection<ArchivedJson> jsonToArchive) throws IOException {\n    try {\n        FileSystem fs = rootPath.getFileSystem();\n        Path path = new Path(rootPath, jobId.toString());\n        OutputStream out = fs.create(path, FileSystem.WriteMode.NO_OVERWRITE);\n\n        try (JsonGenerator gen = jacksonFactory.createGenerator(out, JsonEncoding.UTF8)) {\n            gen.writeStartObject();\n            gen.writeArrayFieldStart(ARCHIVE);\n            for (ArchivedJson archive : jsonToArchive) {\n                gen.writeStartObject();\n                gen.writeStringField(PATH, archive.getPath());\n                gen.writeStringField(JSON, archive.getJson());\n                gen.writeEndObject();\n            }\n            gen.writeEndArray();\n            gen.writeEndObject();\n        } catch (Exception e) {\n            fs.delete(path, false);\n            throw e;\n        }\n        LOG.info(\"Job {} has been archived at {}.\", jobId, path);\n        return path;\n    } catch (IOException e) {\n        LOG.error(\"Failed to archive job.\", e);\n        throw e;\n    }\n}", "summary_tokens": ["writes", "the", "given", "access", "execution", "graph", "to", "the", "file", "system", "pointed", "to", "by", "job", "manager", "options", "archive", "dir"], "project": "flink"}
{"id": 774, "code": "private void deserializeRecordForCollectionAndUpdateState(final UserRecord record) {\n    ByteBuffer recordData = record.getData();\n\n    byte[] dataBytes = new byte[recordData.remaining()];\n    recordData.get(dataBytes);\n\n    final long approxArrivalTimestamp = record.getApproximateArrivalTimestamp().getTime();\n\n    final T value;\n    try {\n        value =\n                deserializer.deserialize(\n                        dataBytes,\n                        record.getPartitionKey(),\n                        record.getSequenceNumber(),\n                        approxArrivalTimestamp,\n                        subscribedShard.getStreamName(),\n                        subscribedShard.getShard().getShardId());\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n\n    SequenceNumber collectedSequenceNumber =\n            (record.isAggregated())\n                    ? new SequenceNumber(\n                            record.getSequenceNumber(), record.getSubSequenceNumber())\n                    : new SequenceNumber(record.getSequenceNumber());\n\n    fetcherRef.emitRecordAndUpdateState(\n            value, approxArrivalTimestamp, subscribedShardStateIndex, collectedSequenceNumber);\n\n    this.lastSequenceNum = collectedSequenceNumber;\n}", "summary_tokens": ["deserializes", "a", "record", "for", "collection", "and", "accordingly", "updates", "the", "shard", "state", "in", "the", "fetcher"], "project": "flink"}
{"id": 68, "code": "public static List<URL> getJobJarAndDependencies(\n        File jarFile, @Nullable String entryPointClassName) throws ProgramInvocationException {\n    URL jarFileUrl = loadJarFile(jarFile);\n\n    List<File> extractedTempLibraries =\n            jarFileUrl == null\n                    ? Collections.emptyList()\n                    : extractContainedLibraries(jarFileUrl);\n\n    List<URL> libs = new ArrayList<URL>(extractedTempLibraries.size() + 1);\n\n    if (jarFileUrl != null) {\n        libs.add(jarFileUrl);\n    }\n    for (File tmpLib : extractedTempLibraries) {\n        try {\n            libs.add(tmpLib.getAbsoluteFile().toURI().toURL());\n        } catch (MalformedURLException e) {\n            throw new RuntimeException(\"URL is invalid. This should not happen.\", e);\n        }\n    }\n\n    if (isPython(entryPointClassName)) {\n        libs.add(PackagedProgramUtils.getPythonJar());\n    }\n\n    return libs;\n}", "summary_tokens": ["returns", "all", "provided", "libraries", "needed", "to", "run", "the", "program"], "project": "flink"}
{"id": 9636, "code": "public void testCoProcessFunctionSideOutputWithMultipleConsumers() throws Exception {\n    final OutputTag<String> sideOutputTag1 = new OutputTag<String>(\"side1\") {};\n    final OutputTag<String> sideOutputTag2 = new OutputTag<String>(\"side2\") {};\n\n    TestListResultSink<String> sideOutputResultSink1 = new TestListResultSink<>();\n    TestListResultSink<String> sideOutputResultSink2 = new TestListResultSink<>();\n    TestListResultSink<Integer> resultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(3);\n\n    DataStream<Integer> ds1 = see.fromCollection(elements);\n    DataStream<Integer> ds2 = see.fromCollection(elements);\n\n    SingleOutputStreamOperator<Integer> passThroughtStream =\n            ds1.connect(ds2)\n                    .process(\n                            new CoProcessFunction<Integer, Integer, Integer>() {\n                                @Override\n                                public void processElement1(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value < 4) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag1,\n                                                \"sideout1-\" + String.valueOf(value));\n                                    }\n                                }\n\n                                @Override\n                                public void processElement2(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value >= 4) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag2,\n                                                \"sideout2-\" + String.valueOf(value));\n                                    }\n                                }\n                            });\n\n    passThroughtStream.getSideOutput(sideOutputTag1).addSink(sideOutputResultSink1);\n    passThroughtStream.getSideOutput(sideOutputTag2).addSink(sideOutputResultSink2);\n    passThroughtStream.addSink(resultSink);\n    see.execute();\n\n    assertEquals(\n            Arrays.asList(\"sideout1-1\", \"sideout1-2\", \"sideout1-3\"),\n            sideOutputResultSink1.getSortedResult());\n    assertEquals(\n            Arrays.asList(\"sideout2-4\", \"sideout2-5\"), sideOutputResultSink2.getSortedResult());\n    assertEquals(Arrays.asList(1, 2, 3, 4, 5), resultSink.getSortedResult());\n}", "summary_tokens": ["test", "co", "process", "function", "side", "output", "with", "multiple", "consumers"], "project": "flink"}
{"id": 6784, "code": "public static int getKeyLen(MemorySegment memorySegment, int offset) {\n    return memorySegment.getInt(offset + KEY_LEN_OFFSET);\n}", "summary_tokens": ["returns", "the", "length", "of", "the", "key"], "project": "flink"}
{"id": 7856, "code": "public void testFailingAsyncCheckpointRunnable() throws Exception {\n\n        \n    OperatorSnapshotFutures operatorSnapshotResult1 = mock(OperatorSnapshotFutures.class);\n    OperatorSnapshotFutures operatorSnapshotResult2 = mock(OperatorSnapshotFutures.class);\n    OperatorSnapshotFutures operatorSnapshotResult3 = mock(OperatorSnapshotFutures.class);\n\n    RunnableFuture<SnapshotResult<OperatorStateHandle>> failingFuture =\n            mock(RunnableFuture.class);\n    when(failingFuture.get())\n            .thenThrow(new ExecutionException(new Exception(\"Test exception\")));\n\n    when(operatorSnapshotResult3.getOperatorStateRawFuture()).thenReturn(failingFuture);\n\n    try (MockEnvironment mockEnvironment = new MockEnvironmentBuilder().build()) {\n        RunningTask<MockStreamTask> task =\n                runTask(\n                        () ->\n                                createMockStreamTask(\n                                        mockEnvironment,\n                                        operatorChain(\n                                                streamOperatorWithSnapshot(\n                                                        operatorSnapshotResult1),\n                                                streamOperatorWithSnapshot(\n                                                        operatorSnapshotResult2),\n                                                streamOperatorWithSnapshot(\n                                                        operatorSnapshotResult3))));\n\n        MockStreamTask streamTask = task.streamTask;\n\n        waitTaskIsRunning(streamTask, task.invocationFuture);\n\n        mockEnvironment.setExpectedExternalFailureCause(Throwable.class);\n        streamTask\n                .triggerCheckpointAsync(\n                        new CheckpointMetaData(42L, 1L),\n                        CheckpointOptions.forCheckpointWithDefaultLocation())\n                .get();\n\n            \n        ExecutorService executor = streamTask.getAsyncOperationsThreadPool();\n        executor.shutdown();\n        if (!executor.awaitTermination(10000L, TimeUnit.MILLISECONDS)) {\n            fail(\n                    \"Executor did not shut down within the given timeout. This indicates that the \"\n                            + \"checkpointing did not resume.\");\n        }\n\n        assertTrue(mockEnvironment.getActualExternalFailureCause().isPresent());\n\n        verify(operatorSnapshotResult1).cancel();\n        verify(operatorSnapshotResult2).cancel();\n        verify(operatorSnapshotResult3).cancel();\n\n        streamTask.finishInput();\n        task.waitForTaskCompletion(false);\n    }\n}", "summary_tokens": ["tests", "that", "in", "case", "of", "a", "failing", "async", "checkpoint", "runnable", "all", "operator", "snapshot", "results", "are", "cancelled", "and", "all", "non", "partitioned", "state", "handles", "are", "discarded"], "project": "flink"}
{"id": 7295, "code": "protected void cleanFile(String path) {\n    try {\n        PrintWriter writer;\n        writer = new PrintWriter(path);\n        writer.print(\"\");\n        writer.close();\n    } catch (FileNotFoundException e) {\n        throw new RuntimeException(\n                \"An error occurred while cleaning the file: \" + e.getMessage(), e);\n    }\n}", "summary_tokens": ["creates", "target", "file", "if", "it", "does", "not", "exist", "cleans", "it", "if", "it", "exists"], "project": "flink"}
{"id": 2944, "code": "public void testOutOfTupleBoundsGrouping2() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    UnsortedGrouping<Tuple5<Integer, Long, String, Long, Integer>> groupDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo).groupBy(0);\n\n        \n    groupDs.minBy(-1);\n}", "summary_tokens": ["this", "test", "validates", "that", "an", "index", "which", "is", "out", "of", "bounds", "throws", "an", "index", "out", "of", "bounds", "exception"], "project": "flink"}
{"id": 8899, "code": "private Operation convertShowViews(SqlShowViews sqlShowViews) {\n    return new ShowViewsOperation();\n}", "summary_tokens": ["convert", "show", "views", "statement"], "project": "flink"}
{"id": 6901, "code": "public boolean isUsingFixedMemoryPerSlot() {\n    return fixedMemoryPerSlot != null;\n}", "summary_tokens": ["gets", "whether", "the", "state", "backend", "is", "configured", "to", "use", "a", "fixed", "amount", "of", "memory", "shared", "between", "all", "rocks", "db", "instances", "in", "all", "tasks", "and", "operators", "of", "a", "slot"], "project": "flink"}
{"id": 5763, "code": "private void testDeleteTransientLocalFails(@Nullable final JobID jobId)\n        throws IOException, InterruptedException {\n    assumeTrue(!OperatingSystem.isWindows()); \n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    File blobFile = null;\n    File directory = null;\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n        try {\n            byte[] data = new byte[2000000];\n            rnd.nextBytes(data);\n\n                \n            TransientBlobKey key = (TransientBlobKey) put(server, jobId, data, TRANSIENT_BLOB);\n            assertNotNull(key);\n\n                \n            verifyContents(cache, jobId, key, data);\n\n            blobFile = cache.getTransientBlobService().getStorageLocation(jobId, key);\n            directory = blobFile.getParentFile();\n\n            assertTrue(blobFile.setWritable(false, false));\n            assertTrue(directory.setWritable(false, false));\n\n                \n            assertFalse(delete(cache, jobId, key));\n\n                \n            verifyContents(cache, jobId, key, data);\n                \n                \n            verifyDeletedEventually(server, jobId, key);\n        } finally {\n            if (blobFile != null && directory != null) {\n                    \n                blobFile.setWritable(true, false);\n                    \n                directory.setWritable(true, false);\n            }\n        }\n    }\n}", "summary_tokens": ["uploads", "a", "byte", "array", "for", "the", "given", "job", "and", "verifies", "that", "a", "delete", "operation", "via", "the", "blob", "cache", "service", "does", "not", "fail", "even", "if", "the", "file", "is", "not", "deletable", "locally", "e"], "project": "flink"}
{"id": 6438, "code": "public void testSlotAllocationTimeout() throws Exception {\n    final CompletableFuture<Void> secondSlotRequestFuture = new CompletableFuture<>();\n\n    final BlockingQueue<Supplier<CompletableFuture<Acknowledge>>> responseQueue =\n            new ArrayBlockingQueue<>(2);\n    responseQueue.add(\n            () -> FutureUtils.completedExceptionally(new TimeoutException(\"timeout\")));\n    responseQueue.add(\n            () -> {\n                secondSlotRequestFuture.complete(null);\n                return new CompletableFuture<>();\n            });\n\n    final TaskExecutorConnection taskManagerConnection =\n            createTaskExecutorConnection(\n                    new TestingTaskExecutorGatewayBuilder()\n                            .setRequestSlotFunction(ignored -> responseQueue.remove().get())\n                            .createTestingTaskExecutorGateway());\n\n    final SlotReport slotReport = createSlotReport(taskManagerConnection.getResourceID(), 2);\n\n    final Executor mainThreadExecutor = TestingUtils.defaultExecutor();\n\n    try (DeclarativeSlotManager slotManager = createDeclarativeSlotManagerBuilder().build()) {\n\n        slotManager.start(\n                ResourceManagerId.generate(),\n                mainThreadExecutor,\n                new TestingResourceActionsBuilder().build());\n\n        CompletableFuture.runAsync(\n                        () ->\n                                slotManager.registerTaskManager(\n                                        taskManagerConnection,\n                                        slotReport,\n                                        ResourceProfile.ANY,\n                                        ResourceProfile.ANY),\n                        mainThreadExecutor)\n                .thenRun(\n                        () ->\n                                slotManager.processResourceRequirements(\n                                        createResourceRequirementsForSingleSlot()))\n                .get(5, TimeUnit.SECONDS);\n\n            \n        secondSlotRequestFuture.get();\n    }\n}", "summary_tokens": ["tests", "that", "if", "a", "slot", "allocation", "times", "out", "we", "try", "to", "allocate", "another", "slot"], "project": "flink"}
{"id": 4584, "code": "int getChunkSize() {\n    return chunkSize;\n}", "summary_tokens": ["returns", "the", "chunk", "size"], "project": "flink"}
{"id": 975, "code": "FunctionInitializationContext getMockContext() throws Exception {\n    OperatorStateStore mockStore = Mockito.mock(OperatorStateStore.class);\n    FunctionInitializationContext mockContext =\n            Mockito.mock(FunctionInitializationContext.class);\n    Mockito.when(mockContext.getOperatorStateStore()).thenReturn(mockStore);\n    Mockito.when(mockStore.getListState(any(ListStateDescriptor.class))).thenReturn(null);\n    return mockContext;\n}", "summary_tokens": ["gets", "a", "mock", "context", "for", "initializing", "the", "source", "s", "state", "via", "org"], "project": "flink"}
{"id": 118, "code": "public ConcreteBuilderT setMaxRecordSizeInBytes(long maxRecordSizeInBytes) {\n    this.maxRecordSizeInBytes = maxRecordSizeInBytes;\n    return (ConcreteBuilderT) this;\n}", "summary_tokens": ["max", "record", "size", "in", "bytes", "the", "maximum", "size", "of", "each", "records", "in", "bytes"], "project": "flink"}
{"id": 2887, "code": "public Option defaultValue(String defaultValue) throws RequiredParametersException {\n    if (this.choices.isEmpty()) {\n        return this.setDefaultValue(defaultValue);\n    } else {\n        if (this.choices.contains(defaultValue)) {\n            return this.setDefaultValue(defaultValue);\n        } else {\n            throw new RequiredParametersException(\n                    \"Default value \"\n                            + defaultValue\n                            + \" is not in the list of valid values for option \"\n                            + this.longName);\n        }\n    }\n}", "summary_tokens": ["define", "a", "default", "value", "for", "the", "option"], "project": "flink"}
{"id": 1826, "code": "public static void forceProcessExit(int exitCode) {\n        \n    System.setSecurityManager(null);\n    if (flinkSecurityManager != null && flinkSecurityManager.haltOnSystemExit) {\n        Runtime.getRuntime().halt(exitCode);\n    } else {\n        System.exit(exitCode);\n    }\n}", "summary_tokens": ["use", "this", "method", "to", "circumvent", "the", "configured", "flink", "security", "manager", "behavior", "ensuring", "that", "the", "current", "jvm", "process", "will", "always", "stop", "via", "system"], "project": "flink"}
{"id": 3154, "code": "public <V, A extends Serializable> void addAccumulator(\n        String name, Accumulator<V, A> accumulator) {\n    getRuntimeContext().addAccumulator(id + SEPARATOR + name, accumulator);\n}", "summary_tokens": ["adds", "an", "accumulator", "by", "prepending", "the", "given", "name", "with", "a", "random", "string"], "project": "flink"}
{"id": 5446, "code": "public Path getSavepointPath() {\n    return baseSavepointPath;\n}", "summary_tokens": ["gets", "the", "directory", "where", "savepoints", "are", "stored", "by", "default", "when", "no", "custom", "path", "is", "given", "to", "the", "savepoint", "trigger", "command"], "project": "flink"}
{"id": 2544, "code": "static void validateTimestampFormat(ReadableConfig tableOptions) {\n    String timestampFormat = tableOptions.get(TIMESTAMP_FORMAT);\n    if (!TIMESTAMP_FORMAT_ENUM.contains(timestampFormat)) {\n        throw new ValidationException(\n                String.format(\n                        \"Unsupported value '%s' for %s. Supported values are [SQL, ISO-8601].\",\n                        timestampFormat, TIMESTAMP_FORMAT.key()));\n    }\n}", "summary_tokens": ["validates", "timestamp", "format", "which", "value", "should", "be", "sql", "or", "iso", "0"], "project": "flink"}
{"id": 1028, "code": "public void dropTable(String catName, String dbname, String name, boolean deleteData,\n    boolean ignoreUnknownTab, EnvironmentContext envContext) throws MetaException, TException,\n    NoSuchObjectException, UnsupportedOperationException {\n  Table tbl;\n  try {\n    tbl = getTable(catName, dbname, name);\n  } catch (NoSuchObjectException e) {\n    if (!ignoreUnknownTab) {\n      throw e;\n    }\n    return;\n  }\n  HiveMetaHook hook = getHook(tbl);\n  if (hook != null) {\n    hook.preDropTable(tbl);\n  }\n  boolean success = false;\n  try {\n    drop_table_with_environment_context(catName, dbname, name, deleteData, envContext);\n    if (hook != null) {\n      hook.commitDropTable(tbl, deleteData || (envContext != null && \"TRUE\".equals(envContext.getProperties().get(\"ifPurge\"))));\n    }\n    success=true;\n  } catch (NoSuchObjectException e) {\n    if (!ignoreUnknownTab) {\n      throw e;\n    }\n  } finally {\n    if (!success && (hook != null)) {\n      hook.rollbackDropTable(tbl);\n    }\n  }\n}", "summary_tokens": ["drop", "the", "table", "and", "choose", "whether", "to", "delete", "the", "underlying", "table", "data", "throw", "if", "the", "table", "doesn", "t", "exist", "save", "the", "data", "in", "the", "trash"], "project": "flink"}
{"id": 6284, "code": "public void testRequestNextInputSplitWithLocalFailover() throws Exception {\n\n    configuration.setString(\n            JobManagerOptions.EXECUTION_FAILOVER_STRATEGY,\n            FailoverStrategyFactoryLoader.PIPELINED_REGION_RESTART_STRATEGY_NAME);\n\n    final Function<List<List<InputSplit>>, Collection<InputSplit>>\n            expectFailedExecutionInputSplits = inputSplitsPerTask -> inputSplitsPerTask.get(0);\n\n    runRequestNextInputSplitTest(expectFailedExecutionInputSplits);\n}", "summary_tokens": ["tests", "that", "input", "splits", "assigned", "to", "an", "execution", "will", "be", "returned", "to", "the", "input", "split", "assigner", "if", "this", "execution", "fails"], "project": "flink"}
{"id": 5237, "code": "private static int maxLength(List<String> coll) {\n    int max = 0;\n    for (String e : coll) {\n        int length = e.length();\n        if (length > max) {\n            max = length;\n        }\n    }\n    return max;\n}", "summary_tokens": ["helper", "for", "to", "string"], "project": "flink"}
{"id": 9160, "code": "public Class<T> compile(ClassLoader classLoader) {\n    if (compiledClass == null) {\n            \n        try {\n                \n            compiledClass = CompileUtils.compile(classLoader, className, splitCode);\n        } catch (Throwable t) {\n                \n            LOG.warn(\"Failed to compile split code, falling back to original code\", t);\n            compiledClass = CompileUtils.compile(classLoader, className, code);\n        }\n    }\n    return compiledClass;\n}", "summary_tokens": ["compiles", "the", "generated", "code", "the", "compiled", "class", "will", "be", "cached", "in", "the", "generated", "class"], "project": "flink"}
{"id": 6609, "code": "protected boolean supportsMetaInfoVerification() {\n    return true;\n}", "summary_tokens": ["true", "if", "metadata", "serialization", "supports", "verification"], "project": "flink"}
{"id": 8749, "code": "public final void lookupNameCompletionHints(\n        SqlValidatorScope scope,\n        List<String> names,\n        SqlParserPos pos,\n        Collection<SqlMoniker> hintList) {\n        \n    List<String> subNames = Util.skipLast(names);\n\n    if (subNames.size() > 0) {\n            \n        SqlValidatorNamespace ns = null;\n        for (String name : subNames) {\n            if (ns == null) {\n                final SqlValidatorScope.ResolvedImpl resolved =\n                        new SqlValidatorScope.ResolvedImpl();\n                final SqlNameMatcher nameMatcher = catalogReader.nameMatcher();\n                scope.resolve(ImmutableList.of(name), nameMatcher, false, resolved);\n                if (resolved.count() == 1) {\n                    ns = resolved.only().namespace;\n                }\n            } else {\n                ns = ns.lookupChild(name);\n            }\n            if (ns == null) {\n                break;\n            }\n        }\n        if (ns != null) {\n            RelDataType rowType = ns.getRowType();\n            if (rowType.isStruct()) {\n                for (RelDataTypeField field : rowType.getFieldList()) {\n                    hintList.add(new SqlMonikerImpl(field.getName(), SqlMonikerType.COLUMN));\n                }\n            }\n        }\n\n            \n            \n        findAllValidFunctionNames(names, this, hintList, pos);\n    } else {\n            \n            \n        scope.findAliases(hintList);\n\n            \n        SelectScope selectScope = SqlValidatorUtil.getEnclosingSelectScope(scope);\n        if ((selectScope != null) && (selectScope.getChildren().size() == 1)) {\n            RelDataType rowType = selectScope.getChildren().get(0).getRowType();\n            for (RelDataTypeField field : rowType.getFieldList()) {\n                hintList.add(new SqlMonikerImpl(field.getName(), SqlMonikerType.COLUMN));\n            }\n        }\n    }\n\n    findAllValidUdfNames(names, this, hintList);\n}", "summary_tokens": ["populates", "a", "list", "of", "all", "the", "valid", "alternatives", "for", "an", "identifier"], "project": "flink"}
{"id": 7763, "code": "private static <K, IN, OUT> void processElementAndEnsureOutput(\n        OneInputStreamOperator<IN, OUT> operator,\n        KeySelector<IN, K> keySelector,\n        TypeInformation<K> keyType,\n        IN element)\n        throws Exception {\n\n    KeyedOneInputStreamOperatorTestHarness<K, IN, OUT> testHarness =\n            new KeyedOneInputStreamOperatorTestHarness<>(operator, keySelector, keyType);\n\n    testHarness.open();\n\n    testHarness.setProcessingTime(0);\n    testHarness.processWatermark(Long.MIN_VALUE);\n\n    testHarness.processElement(new StreamRecord<>(element, 0));\n\n        \n    testHarness.setProcessingTime(Long.MAX_VALUE);\n    testHarness.processWatermark(Long.MAX_VALUE);\n\n        \n    assertTrue(testHarness.getOutput().size() >= 3);\n\n    testHarness.close();\n}", "summary_tokens": ["ensure", "that", "we", "get", "some", "output", "from", "the", "given", "operator", "when", "pushing", "in", "an", "element", "and", "setting", "watermark", "and", "processing", "time", "to", "long"], "project": "flink"}
{"id": 184, "code": "public B setBulkFlushMaxActions(int numMaxActions) {\n    checkState(\n            numMaxActions == -1 || numMaxActions > 0,\n            \"Max number of buffered actions must be larger than 0.\");\n    this.bulkFlushMaxActions = numMaxActions;\n    return self();\n}", "summary_tokens": ["sets", "the", "maximum", "number", "of", "actions", "to", "buffer", "for", "each", "bulk", "request"], "project": "flink"}
{"id": 2240, "code": "public void testScheduleWithInfiniteDelayNeverSchedulesOperation() {\n    final Runnable noOpRunnable = () -> {};\n    final CompletableFuture<Void> completableFuture =\n            FutureUtils.scheduleWithDelay(\n                    noOpRunnable,\n                    TestingUtils.infiniteTime(),\n                    TestingUtils.defaultScheduledExecutor());\n\n    assertFalse(completableFuture.isDone());\n\n    completableFuture.cancel(false);\n}", "summary_tokens": ["tests", "that", "the", "operation", "is", "never", "scheduled", "if", "the", "delay", "is", "virtually", "infinite"], "project": "flink"}
{"id": 7426, "code": "public StreamExchangeMode getExchangeMode() {\n    return exchangeMode;\n}", "summary_tokens": ["returns", "the", "stream", "exchange", "mode", "of", "this", "partition", "transformation"], "project": "flink"}
{"id": 3349, "code": "public <T> Collection<T> getBroadcastSet(String name) {\n    return this.runtimeContext.getBroadcastVariable(name);\n}", "summary_tokens": ["gets", "the", "broadcast", "data", "set", "registered", "under", "the", "given", "name"], "project": "flink"}
{"id": 2528, "code": "public void testCreatingBuildWithinUserClassLoader() throws Exception {\n    ClassLoader appClassLoader = getClass().getClassLoader();\n    Assume.assumeTrue(appClassLoader instanceof URLClassLoader);\n\n    ClassLoader userClassLoader =\n            new SpecifiedChildFirstUserClassLoader(\n                    HadoopPathBasedBulkFormatBuilder.class.getName(),\n                    appClassLoader,\n                    ((URLClassLoader) appClassLoader).getURLs());\n\n    Class<HadoopPathBasedBulkFormatBuilder> userHadoopFormatBuildClass =\n            (Class<HadoopPathBasedBulkFormatBuilder>)\n                    userClassLoader.loadClass(HadoopPathBasedBulkFormatBuilder.class.getName());\n    Constructor<?> constructor =\n            userHadoopFormatBuildClass.getConstructor(\n                    Path.class,\n                    HadoopPathBasedBulkWriter.Factory.class,\n                    Configuration.class,\n                    BucketAssigner.class);\n    Object hadoopFormatBuilder =\n            constructor.newInstance(\n                    new Path(\"/tmp\"),\n                    new TestHadoopPathBasedBulkWriterFactory(),\n                    new Configuration(),\n                    new DateTimeBucketAssigner<>());\n\n    Buckets<String, String> buckets =\n            (Buckets<String, String>)\n                    userHadoopFormatBuildClass\n                            .getMethod(\"createBuckets\", int.class)\n                            .invoke(hadoopFormatBuilder, 0);\n    assertNotNull(buckets);\n}", "summary_tokens": ["tests", "if", "we", "could", "create", "hadoop", "path", "based", "bulk", "format", "builder", "within", "user", "classloader"], "project": "flink"}
{"id": 8457, "code": "protected final void collect(T row) {\n    collector.collect(row);\n}", "summary_tokens": ["emits", "an", "implicit", "or", "explicit", "output", "row"], "project": "flink"}
{"id": 238, "code": "public SplitT toFileSourceSplit() {\n    final CheckpointedPosition position =\n            (offset == CheckpointedPosition.NO_OFFSET && recordsToSkipAfterOffset == 0)\n                    ? null\n                    : new CheckpointedPosition(offset, recordsToSkipAfterOffset);\n\n    final FileSourceSplit updatedSplit = split.updateWithCheckpointedPosition(position);\n\n        \n    if (updatedSplit == null) {\n        throw new FlinkRuntimeException(\n                \"Split returned 'null' in updateWithCheckpointedPosition(): \" + split);\n    }\n    if (updatedSplit.getClass() != split.getClass()) {\n        throw new FlinkRuntimeException(\n                String.format(\n                        \"Split returned different type in updateWithCheckpointedPosition(). \"\n                                + \"Split type is %s, returned type is %s\",\n                        split.getClass().getName(), updatedSplit.getClass().getName()));\n    }\n\n    return (SplitT) updatedSplit;\n}", "summary_tokens": ["use", "the", "current", "row", "count", "as", "the", "starting", "row", "count", "to", "create", "a", "new", "file", "source", "split"], "project": "flink"}
{"id": 5635, "code": "public static Instant getBuildTime() {\n    return getVersionsInstance().gitBuildTime;\n}", "summary_tokens": ["the", "instant", "this", "version", "of", "the", "software", "was", "built"], "project": "flink"}
{"id": 7773, "code": "public void testClear() throws Exception {\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(EventTimeTrigger.create(), new TimeWindow.Serializer());\n\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(2, testHarness.numEventTimeTimers());\n    assertEquals(1, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(1, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(2, 4));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(1, testHarness.numEventTimeTimers());\n    assertEquals(1, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(0, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(0, 2));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers());\n}", "summary_tokens": ["verify", "that", "clear", "does", "not", "leak", "across", "windows"], "project": "flink"}
{"id": 779, "code": "private software.amazon.awssdk.services.kinesis.model.StartingPosition toSdkV2StartingPosition(\n        StartingPosition startingPosition) {\n    software.amazon.awssdk.services.kinesis.model.StartingPosition.Builder builder =\n            builder().type(startingPosition.getShardIteratorType().toString());\n\n    Object marker = startingPosition.getStartingMarker();\n\n    switch (startingPosition.getShardIteratorType()) {\n        case AT_TIMESTAMP:\n            {\n                Preconditions.checkNotNull(\n                        marker, \"StartingPosition AT_TIMESTAMP date marker is null.\");\n                builder.timestamp(((Date) marker).toInstant());\n                break;\n            }\n        case AT_SEQUENCE_NUMBER:\n        case AFTER_SEQUENCE_NUMBER:\n            {\n                Preconditions.checkNotNull(\n                        marker, \"StartingPosition *_SEQUENCE_NUMBER position is null.\");\n                builder.sequenceNumber(marker.toString());\n                break;\n            }\n    }\n\n    return builder.build();\n}", "summary_tokens": ["converts", "a", "local", "starting", "position", "to", "an", "aws", "sdk", "v", "0", "object", "representation"], "project": "flink"}
{"id": 7577, "code": "public void handleAsyncException(String message, Throwable exception) {\n    if (isRunning) {\n            \n        asyncExceptionHandler.handleAsyncException(message, exception);\n    }\n}", "summary_tokens": ["handles", "an", "exception", "thrown", "by", "another", "thread", "e"], "project": "flink"}
{"id": 6787, "code": "public static void putValuePointer(MemorySegment memorySegment, int offset, long valuePointer) {\n    memorySegment.putLong(offset + VALUE_POINTER_OFFSET, valuePointer);\n}", "summary_tokens": ["puts", "the", "value", "pointer", "to", "key", "space"], "project": "flink"}
{"id": 8788, "code": "protected void validateFeature(Feature feature, SqlParserPos context) {\n        \n        \n    assert feature.getProperties().get(\"FeatureDefinition\") != null;\n}", "summary_tokens": ["validates", "that", "a", "particular", "feature", "is", "enabled"], "project": "flink"}
{"id": 8735, "code": "private <C extends Comparable<C>> RangeSet<C> residue(\n        RexNode ref, RangeSet<C> r0, List<RexNode> predicates, Class<C> clazz) {\n    RangeSet<C> result = r0;\n    for (RexNode predicate : predicates) {\n        switch (predicate.getKind()) {\n            case EQUALS:\n            case NOT_EQUALS:\n            case LESS_THAN:\n            case LESS_THAN_OR_EQUAL:\n            case GREATER_THAN:\n            case GREATER_THAN_OR_EQUAL:\n                final RexCall call = (RexCall) predicate;\n                if (call.operands.get(0).equals(ref)\n                        && call.operands.get(1) instanceof RexLiteral) {\n                    final RexLiteral literal = (RexLiteral) call.operands.get(1);\n                    final C c1 = literal.getValueAs(clazz);\n                    switch (predicate.getKind()) {\n                        case NOT_EQUALS:\n                                \n                                \n                            final Range<C> pointRange = range(SqlKind.EQUALS, c1);\n                            final RangeSet<C> notEqualsRangeSet =\n                                    ImmutableRangeSet.of(pointRange).complement();\n                            if (result.enclosesAll(notEqualsRangeSet)) {\n                                result = RangeSets.rangeSetAll();\n                                continue;\n                            }\n                            result = RangeSets.minus(result, pointRange);\n                            break;\n                        default:\n                            final Range<C> r1 = range(predicate.getKind(), c1);\n                            if (result.encloses(r1)) {\n                                    \n                                    \n                                result = RangeSets.rangeSetAll();\n                                continue;\n                            }\n                            result = result.subRangeSet(r1);\n                    }\n                    if (result.isEmpty()) {\n                        break; \n                    }\n                }\n        }\n    }\n    return result;\n}", "summary_tokens": ["weakens", "a", "term", "so", "that", "it", "checks", "only", "what", "is", "not", "implied", "by", "predicates"], "project": "flink"}
{"id": 9444, "code": "public void testProcTimeTemporalJoin() throws Exception {\n    TemporalProcessTimeJoinOperator joinOperator =\n            new TemporalProcessTimeJoinOperator(rowType, joinCondition, 0, 0, false);\n    KeyedTwoInputStreamOperatorTestHarness<RowData, RowData, RowData, RowData> testHarness =\n            createTestHarness(joinOperator);\n    testHarness.open();\n    testHarness.setProcessingTime(1);\n    testHarness.processElement1(insertRecord(1L, \"1a1\"));\n\n    testHarness.setProcessingTime(2);\n    testHarness.processElement2(insertRecord(2L, \"2a2\"));\n\n    testHarness.setProcessingTime(3);\n    testHarness.processElement1(insertRecord(2L, \"2a3\"));\n\n    testHarness.setProcessingTime(4);\n    testHarness.processElement2(insertRecord(1L, \"1a4\"));\n\n    testHarness.setProcessingTime(5);\n    testHarness.processElement1(insertRecord(1L, \"1a5\"));\n\n    List<Object> expectedOutput = new ArrayList<>();\n    expectedOutput.add(insertRecord(2L, \"2a3\", 2L, \"2a2\"));\n    expectedOutput.add(insertRecord(1L, \"1a5\", 1L, \"1a4\"));\n    assertor.assertOutputEquals(\"output wrong.\", expectedOutput, testHarness.getOutput());\n    testHarness.close();\n}", "summary_tokens": ["test", "proctime", "temporal", "join"], "project": "flink"}
{"id": 162, "code": "public void open(int taskNumber, int numTasks) throws IOException {\n    this.session = cluster.connect();\n    this.prepared = session.prepare(insertQuery);\n    this.callback =\n            new FutureCallback<ResultSet>() {\n                @Override\n                public void onSuccess(ResultSet ignored) {\n                    onWriteSuccess(ignored);\n                }\n\n                @Override\n                public void onFailure(Throwable t) {\n                    onWriteFailure(t);\n                }\n            };\n}", "summary_tokens": ["opens", "a", "session", "to", "cassandra", "and", "initializes", "the", "prepared", "statement"], "project": "flink"}
{"id": 6020, "code": "public void testLibraryCacheManagerCleanup() throws Exception {\n\n    JobID jobId = new JobID();\n    List<PermanentBlobKey> keys = new ArrayList<>();\n    BlobServer server = null;\n    PermanentBlobCache cache = null;\n    BlobLibraryCacheManager libCache = null;\n\n    final byte[] buf = new byte[128];\n\n    try {\n        Configuration config = new Configuration();\n        config.setString(\n                BlobServerOptions.STORAGE_DIRECTORY,\n                temporaryFolder.newFolder().getAbsolutePath());\n        config.setLong(BlobServerOptions.CLEANUP_INTERVAL, 1L);\n\n        server = new BlobServer(config, new VoidBlobStore());\n        server.start();\n        InetSocketAddress serverAddress = new InetSocketAddress(\"localhost\", server.getPort());\n        cache = new PermanentBlobCache(config, new VoidBlobStore(), serverAddress);\n\n        keys.add(server.putPermanent(jobId, buf));\n        buf[0] += 1;\n        keys.add(server.putPermanent(jobId, buf));\n\n        libCache = createBlobLibraryCacheManager(cache);\n        cache.registerJob(jobId);\n\n        assertEquals(0, libCache.getNumberOfManagedJobs());\n        assertEquals(0, libCache.getNumberOfReferenceHolders(jobId));\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(0, jobId, cache);\n\n        final LibraryCacheManager.ClassLoaderLease classLoaderLease1 =\n                libCache.registerClassLoaderLease(jobId);\n        UserCodeClassLoader classLoader1 =\n                classLoaderLease1.getOrResolveClassLoader(keys, Collections.emptyList());\n\n        assertEquals(1, libCache.getNumberOfManagedJobs());\n        assertEquals(1, libCache.getNumberOfReferenceHolders(jobId));\n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(2, jobId, cache);\n\n        final LibraryCacheManager.ClassLoaderLease classLoaderLease2 =\n                libCache.registerClassLoaderLease(jobId);\n        final UserCodeClassLoader classLoader2 =\n                classLoaderLease2.getOrResolveClassLoader(keys, Collections.emptyList());\n        assertThat(classLoader1, sameInstance(classLoader2));\n\n        try {\n            classLoaderLease1.getOrResolveClassLoader(\n                    Collections.emptyList(), Collections.emptyList());\n            fail(\"Should fail with an IllegalStateException\");\n        } catch (IllegalStateException e) {\n                \n        }\n\n        try {\n            classLoaderLease1.getOrResolveClassLoader(\n                    keys, Collections.singletonList(new URL(\"file:///tmp/does-not-exist\")));\n            fail(\"Should fail with an IllegalStateException\");\n        } catch (IllegalStateException e) {\n                \n        }\n\n        assertEquals(1, libCache.getNumberOfManagedJobs());\n        assertEquals(2, libCache.getNumberOfReferenceHolders(jobId));\n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(2, jobId, cache);\n\n        classLoaderLease1.release();\n\n        assertEquals(1, libCache.getNumberOfManagedJobs());\n        assertEquals(1, libCache.getNumberOfReferenceHolders(jobId));\n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(2, jobId, cache);\n\n        classLoaderLease2.release();\n\n        assertEquals(0, libCache.getNumberOfManagedJobs());\n        assertEquals(0, libCache.getNumberOfReferenceHolders(jobId));\n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(2, jobId, cache);\n\n            \n            \n    } finally {\n        if (libCache != null) {\n            libCache.shutdown();\n        }\n\n            \n        if (cache != null) {\n            cache.close();\n        }\n\n        if (server != null) {\n            server.close();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "the", "blob", "library", "cache", "manager", "cleans", "up", "after", "all", "class", "loader", "leases", "for", "a", "single", "job", "a", "closed"], "project": "flink"}
{"id": 3533, "code": "default Counter counter(int name) {\n    return counter(String.valueOf(name));\n}", "summary_tokens": ["creates", "and", "registers", "a", "new", "org"], "project": "flink"}
{"id": 58, "code": "static JarFileWithEntryClass findOnlyEntryClass(Iterable<File> jarFiles) throws IOException {\n    List<JarFileWithEntryClass> jarsWithEntryClasses = new ArrayList<>();\n    for (File jarFile : jarFiles) {\n        findEntryClass(jarFile)\n                .ifPresent(\n                        entryClass ->\n                                jarsWithEntryClasses.add(\n                                        new JarFileWithEntryClass(jarFile, entryClass)));\n    }\n    int size = jarsWithEntryClasses.size();\n    if (size == 0) {\n        throw new NoSuchElementException(\"No JAR with manifest attribute for entry class\");\n    }\n    if (size == 1) {\n        return jarsWithEntryClasses.get(0);\n    }\n        \n    throw new IllegalArgumentException(\n            \"Multiple JARs with manifest attribute for entry class: \" + jarsWithEntryClasses);\n}", "summary_tokens": ["returns", "a", "jar", "file", "with", "its", "entry", "class", "as", "specified", "in", "the", "manifest"], "project": "flink"}
{"id": 9011, "code": "public RelDistribution getDistribution() {\n    return null;\n}", "summary_tokens": ["returns", "a", "description", "of", "the", "physical", "distribution", "of", "the", "rows", "in", "this", "table"], "project": "flink"}
{"id": 8476, "code": "default boolean takesRowAsInput() {\n    return false;\n}", "summary_tokens": ["returns", "whether", "the", "python", "function", "takes", "row", "as", "input", "instead", "of", "each", "columns", "of", "a", "row"], "project": "flink"}
{"id": 9133, "code": "public static String lpad(String base, int len, String pad) {\n    if (len < 0 || \"\".equals(pad)) {\n        return null;\n    } else if (len == 0) {\n        return \"\";\n    }\n\n    char[] data = new char[len];\n    char[] baseChars = base.toCharArray();\n    char[] padChars = pad.toCharArray();\n\n        \n    int pos = Math.max(len - base.length(), 0);\n\n        \n    for (int i = 0; i < pos; i += pad.length()) {\n        for (int j = 0; j < pad.length() && j < pos - i; j++) {\n            data[i + j] = padChars[j];\n        }\n    }\n\n        \n    int i = 0;\n    while (pos + i < len && i < base.length()) {\n        data[pos + i] = baseChars[i];\n        i += 1;\n    }\n\n    return new String(data);\n}", "summary_tokens": ["returns", "the", "string", "str", "left", "padded", "with", "the", "string", "pad", "to", "a", "length", "of", "len", "characters"], "project": "flink"}
{"id": 5107, "code": "public InetSocketAddress getKvStateServerAddress(int keyGroupIndex) {\n    if (keyGroupIndex < 0 || keyGroupIndex >= numKeyGroups) {\n        throw new IndexOutOfBoundsException(\"Key group index\");\n    }\n\n    return kvStateAddresses[keyGroupIndex];\n}", "summary_tokens": ["returns", "the", "registered", "server", "address", "for", "the", "key", "group", "index", "or", "code", "null", "code", "if", "none", "is", "registered", "yet"], "project": "flink"}
{"id": 6329, "code": "public void testFactoryPrioritization() throws Exception {\n    final Configuration config = new Configuration();\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test.\"\n                    + ConfigConstants.METRICS_REPORTER_FACTORY_CLASS_SUFFIX,\n            InstantiationTypeTrackingTestReporterFactory.class.getName());\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test.\"\n                    + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,\n            InstantiationTypeTrackingTestReporter.class.getName());\n\n    final List<ReporterSetup> reporterSetups = ReporterSetup.fromConfiguration(config, null);\n\n    assertEquals(1, reporterSetups.size());\n\n    final ReporterSetup reporterSetup = reporterSetups.get(0);\n    final InstantiationTypeTrackingTestReporter metricReporter =\n            (InstantiationTypeTrackingTestReporter) reporterSetup.getReporter();\n\n    assertTrue(metricReporter.createdByFactory);\n}", "summary_tokens": ["verifies", "that", "the", "factory", "approach", "is", "prioritized", "if", "both", "the", "factory", "and", "reflection", "approach", "are", "configured"], "project": "flink"}
{"id": 3082, "code": "public GroupPattern<T, F> followedByAny(Pattern<T, F> group) {\n    return new GroupPattern<>(\n            this, group, ConsumingStrategy.SKIP_TILL_ANY, afterMatchSkipStrategy);\n}", "summary_tokens": ["appends", "a", "new", "group", "pattern", "to", "the", "existing", "one"], "project": "flink"}
{"id": 5919, "code": "public void testMetricsRegistration() throws Exception {\n    final Collection<String> registeredGaugeNames = new ArrayList<>();\n\n    MetricGroup metricGroup =\n            new UnregisteredMetricsGroup() {\n                @Override\n                public <T, G extends Gauge<T>> G gauge(String name, G gauge) {\n                    if (gauge != null) {\n                        registeredGaugeNames.add(name);\n                    }\n                    return gauge;\n                }\n            };\n\n    new CheckpointStatsTracker(0, metricGroup);\n\n        \n    assertTrue(\n            registeredGaugeNames.containsAll(\n                    Arrays.asList(\n                            CheckpointStatsTracker.NUMBER_OF_CHECKPOINTS_METRIC,\n                            CheckpointStatsTracker.NUMBER_OF_IN_PROGRESS_CHECKPOINTS_METRIC,\n                            CheckpointStatsTracker.NUMBER_OF_COMPLETED_CHECKPOINTS_METRIC,\n                            CheckpointStatsTracker.NUMBER_OF_FAILED_CHECKPOINTS_METRIC,\n                            CheckpointStatsTracker.LATEST_RESTORED_CHECKPOINT_TIMESTAMP_METRIC,\n                            CheckpointStatsTracker.LATEST_COMPLETED_CHECKPOINT_SIZE_METRIC,\n                            CheckpointStatsTracker.LATEST_COMPLETED_CHECKPOINT_DURATION_METRIC,\n                            CheckpointStatsTracker\n                                    .LATEST_COMPLETED_CHECKPOINT_PROCESSED_DATA_METRIC,\n                            CheckpointStatsTracker\n                                    .LATEST_COMPLETED_CHECKPOINT_PERSISTED_DATA_METRIC,\n                            CheckpointStatsTracker\n                                    .LATEST_COMPLETED_CHECKPOINT_EXTERNAL_PATH_METRIC)));\n    assertEquals(10, registeredGaugeNames.size());\n}", "summary_tokens": ["tests", "the", "registration", "of", "the", "checkpoint", "metrics"], "project": "flink"}
{"id": 6028, "code": "public void testExecutionGraphIsDeployedInTopologicalOrder() throws Exception {\n    final int sourceParallelism = 2;\n    final int sinkParallelism = 1;\n\n    final JobVertex sourceVertex = new JobVertex(\"source\");\n    sourceVertex.setInvokableClass(NoOpInvokable.class);\n    sourceVertex.setParallelism(sourceParallelism);\n\n    final JobVertex sinkVertex = new JobVertex(\"sink\");\n    sinkVertex.setInvokableClass(NoOpInvokable.class);\n    sinkVertex.setParallelism(sinkParallelism);\n\n    sinkVertex.connectNewDataSetAsInput(\n            sourceVertex, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);\n\n    final int numberTasks = sourceParallelism + sinkParallelism;\n    final ArrayBlockingQueue<ExecutionAttemptID> submittedTasksQueue =\n            new ArrayBlockingQueue<>(numberTasks);\n    TestingTaskExecutorGatewayBuilder testingTaskExecutorGatewayBuilder =\n            new TestingTaskExecutorGatewayBuilder();\n    testingTaskExecutorGatewayBuilder.setSubmitTaskConsumer(\n            (taskDeploymentDescriptor, jobMasterId) -> {\n                submittedTasksQueue.offer(taskDeploymentDescriptor.getExecutionAttemptId());\n                return CompletableFuture.completedFuture(Acknowledge.get());\n            });\n\n    final TaskManagerLocation taskManagerLocation = new LocalTaskManagerLocation();\n    final TestingTaskExecutorGateway taskExecutorGateway =\n            testingTaskExecutorGatewayBuilder.createTestingTaskExecutorGateway();\n    final RpcTaskManagerGateway taskManagerGateway =\n            new RpcTaskManagerGateway(taskExecutorGateway, JobMasterId.generate());\n\n    final JobGraph jobGraph = JobGraphTestUtils.streamingJobGraph(sourceVertex, sinkVertex);\n\n    final TestingPhysicalSlotProvider physicalSlotProvider =\n            TestingPhysicalSlotProvider.createWithoutImmediatePhysicalSlotCreation();\n    final SchedulerBase scheduler =\n            SchedulerTestingUtils.newSchedulerBuilder(\n                            jobGraph, ComponentMainThreadExecutorServiceAdapter.forMainThread())\n                    .setExecutionSlotAllocatorFactory(\n                            SchedulerTestingUtils.newSlotSharingExecutionSlotAllocatorFactory(\n                                    physicalSlotProvider))\n                    .setFutureExecutor(new DirectScheduledExecutorService())\n                    .build();\n    final ExecutionGraph executionGraph = scheduler.getExecutionGraph();\n\n    scheduler.startScheduling();\n\n        \n    final List<CompletableFuture<TestingPhysicalSlot>> shuffledFutures =\n            new ArrayList<>(physicalSlotProvider.getResponses().values());\n    Collections.shuffle(shuffledFutures);\n\n    for (CompletableFuture<TestingPhysicalSlot> slotFuture : shuffledFutures) {\n        slotFuture.complete(\n                TestingPhysicalSlot.builder()\n                        .withTaskManagerLocation(taskManagerLocation)\n                        .withTaskManagerGateway(taskManagerGateway)\n                        .build());\n    }\n\n    final List<ExecutionAttemptID> submittedTasks = new ArrayList<>(numberTasks);\n\n    for (int i = 0; i < numberTasks; i++) {\n        submittedTasks.add(submittedTasksQueue.take());\n    }\n\n    final Collection<ExecutionAttemptID> firstStage = new ArrayList<>(sourceParallelism);\n    for (ExecutionVertex taskVertex :\n            executionGraph.getJobVertex(sourceVertex.getID()).getTaskVertices()) {\n        firstStage.add(taskVertex.getCurrentExecutionAttempt().getAttemptId());\n    }\n\n    final Collection<ExecutionAttemptID> secondStage = new ArrayList<>(sinkParallelism);\n    for (ExecutionVertex taskVertex :\n            executionGraph.getJobVertex(sinkVertex.getID()).getTaskVertices()) {\n        secondStage.add(taskVertex.getCurrentExecutionAttempt().getAttemptId());\n    }\n\n    assertThat(\n            submittedTasks, new ExecutionStageMatcher(Arrays.asList(firstStage, secondStage)));\n}", "summary_tokens": ["tests", "that", "the", "execution", "graph", "is", "deployed", "in", "topological", "order"], "project": "flink"}
{"id": 4665, "code": "CompletableFuture<?> release() {\n    List<SortMergeSubpartitionReader> pendingReaders;\n    synchronized (lock) {\n        if (isReleased) {\n            return releaseFuture;\n        }\n        isReleased = true;\n\n        failedReaders.addAll(allReaders);\n        pendingReaders = new ArrayList<>(allReaders);\n        mayNotifyReleased();\n    }\n\n    failSubpartitionReaders(\n            pendingReaders,\n            new IllegalStateException(\"Result partition has been already released.\"));\n    return releaseFuture;\n}", "summary_tokens": ["releases", "this", "read", "scheduler", "and", "returns", "a", "completable", "future", "which", "will", "be", "completed", "when", "all", "resources", "are", "released"], "project": "flink"}
{"id": 2098, "code": "public static CompletableFuture<Void> runAfterwardsAsync(\n        CompletableFuture<?> future, RunnableWithException runnable, Executor executor) {\n    final CompletableFuture<Void> resultFuture = new CompletableFuture<>();\n\n    future.whenCompleteAsync(\n            (Object ignored, Throwable throwable) -> {\n                try {\n                    runnable.run();\n                } catch (Throwable e) {\n                    throwable = ExceptionUtils.firstOrSuppressed(e, throwable);\n                }\n\n                if (throwable != null) {\n                    resultFuture.completeExceptionally(throwable);\n                } else {\n                    resultFuture.complete(null);\n                }\n            },\n            executor);\n\n    return resultFuture;\n}", "summary_tokens": ["run", "the", "given", "action", "after", "the", "completion", "of", "the", "given", "future"], "project": "flink"}
{"id": 4942, "code": "public static void logAndThrowException(Exception ex, AbstractInvokable parent)\n        throws Exception {\n    String taskName;\n    if (ex instanceof ExceptionInChainedStubException) {\n        do {\n            ExceptionInChainedStubException cex = (ExceptionInChainedStubException) ex;\n            taskName = cex.getTaskName();\n            ex = cex.getWrappedException();\n        } while (ex instanceof ExceptionInChainedStubException);\n    } else {\n        taskName = parent.getEnvironment().getTaskInfo().getTaskName();\n    }\n\n    if (LOG.isErrorEnabled()) {\n        LOG.error(constructLogString(\"Error in task code\", taskName, parent), ex);\n    }\n\n    throw ex;\n}", "summary_tokens": ["prints", "an", "error", "message", "and", "throws", "the", "given", "exception"], "project": "flink"}
{"id": 9487, "code": "protected List<T> generateAndWriteTestData(int splitIndex, ExternalContext<T> externalContext) {\n    final List<T> testRecords =\n            externalContext.generateTestData(\n                    splitIndex, ThreadLocalRandom.current().nextLong());\n    LOG.debug(\"Writing {} records to external system\", testRecords.size());\n    externalContext.createSourceSplitDataWriter().writeRecords(testRecords);\n    return testRecords;\n}", "summary_tokens": ["generate", "a", "set", "of", "test", "records", "and", "write", "it", "to", "the", "given", "split", "writer"], "project": "flink"}
{"id": 4222, "code": "default long getLatestCheckpointId() {\n    try {\n        List<CompletedCheckpoint> allCheckpoints = getAllCheckpoints();\n        if (allCheckpoints.isEmpty()) {\n            return 0;\n        }\n\n        return allCheckpoints.get(allCheckpoints.size() - 1).getCheckpointID();\n    } catch (Throwable throwable) {\n        LOG.warn(\"Get the latest completed checkpoints failed\", throwable);\n        return 0;\n    }\n}", "summary_tokens": ["returns", "the", "id", "of", "the", "latest", "completed", "checkpoints"], "project": "flink"}
{"id": 9736, "code": "private void failSessionDuringDeployment(\n        YarnClient yarnClient, YarnClientApplication yarnApplication) {\n    LOG.info(\"Killing YARN application\");\n\n    try {\n        yarnClient.killApplication(\n                yarnApplication.getNewApplicationResponse().getApplicationId());\n    } catch (Exception e) {\n            \n            \n        LOG.debug(\"Error while killing YARN application\", e);\n    }\n}", "summary_tokens": ["kills", "yarn", "application", "and", "stops", "yarn", "client"], "project": "flink"}
{"id": 4361, "code": "private boolean isDuplicateJob(JobID jobId) throws FlinkException {\n    return isInGloballyTerminalState(jobId) || runningJobs.containsKey(jobId);\n}", "summary_tokens": ["checks", "whether", "the", "given", "job", "has", "already", "been", "submitted", "or", "executed"], "project": "flink"}
{"id": 4963, "code": "public void open() {\n    synchronized (stateLock) {\n        if (!closed) {\n            throw new IllegalStateException(\"currently not closed.\");\n        }\n        closed = false;\n    }\n\n        \n    final int partitionFanOut = getPartitioningFanOutNoEstimates(this.availableMemory.size());\n    createPartitions(partitionFanOut);\n\n        \n        \n    final int numBuckets =\n            getInitialTableSize(\n                    this.availableMemory.size(),\n                    this.segmentSize,\n                    partitionFanOut,\n                    this.avgRecordLen);\n\n    initTable(numBuckets, (byte) partitionFanOut);\n}", "summary_tokens": ["initialize", "the", "hash", "table"], "project": "flink"}
{"id": 9302, "code": "public void advanceWatermarkToTriggerAllWindows() {\n    skipEmptyWindow();\n    advanceWatermark(watermark + windowSize);\n}", "summary_tokens": ["advance", "the", "watermark", "to", "trigger", "all", "the", "possible", "windows"], "project": "flink"}
{"id": 5965, "code": "public void testSimpleAccess() throws Exception {\n    test(false);\n}", "summary_tokens": ["tests", "simple", "access", "via", "the", "getters"], "project": "flink"}
{"id": 1898, "code": "public boolean startsWith(CharSequence prefix) {\n    return startsWith(prefix, 0);\n}", "summary_tokens": ["checks", "whether", "this", "string", "value", "starts", "with", "the", "given", "prefix", "string"], "project": "flink"}
{"id": 5077, "code": "synchronized void registerOpenChannelToBeRemovedAtShutdown(FileIOChannel channel) {\n    openChannels.add(channel);\n}", "summary_tokens": ["adds", "a", "channel", "reader", "writer", "to", "the", "list", "of", "channels", "that", "are", "to", "be", "removed", "at", "shutdown"], "project": "flink"}
{"id": 5469, "code": "private StateMapEntry<K, N, S> putEntry(K key, N namespace) {\n\n    final int hash = computeHashForOperationAndDoIncrementalRehash(key, namespace);\n    final StateMapEntry<K, N, S>[] tab = selectActiveTable(hash);\n    int index = hash & (tab.length - 1);\n\n    for (StateMapEntry<K, N, S> e = tab[index]; e != null; e = e.next) {\n        if (e.hash == hash && key.equals(e.key) && namespace.equals(e.namespace)) {\n\n                \n            if (e.entryVersion < highestRequiredSnapshotVersion) {\n                e = handleChainedEntryCopyOnWrite(tab, index, e);\n            }\n\n            return e;\n        }\n    }\n\n    ++modCount;\n    if (size() > threshold) {\n        doubleCapacity();\n    }\n\n    return addNewStateMapEntry(tab, key, namespace, hash);\n}", "summary_tokens": ["helper", "method", "that", "is", "the", "basis", "for", "operations", "that", "add", "mappings"], "project": "flink"}
{"id": 7313, "code": "public long getCheckpointId() {\n    return checkpointId;\n}", "summary_tokens": ["gets", "the", "checkpoint", "id", "of", "the", "checkpoint"], "project": "flink"}
{"id": 8177, "code": "public static TypeInformation<Row> ROW(String[] fieldNames, TypeInformation<?>[] types) {\n    return org.apache.flink.api.common.typeinfo.Types.ROW_NAMED(fieldNames, types);\n}", "summary_tokens": ["returns", "type", "information", "for", "row", "with", "fields", "of", "the", "given", "types", "and", "with", "given", "names"], "project": "flink"}
{"id": 7596, "code": "private boolean processMail(TaskMailbox mailbox, boolean singleStep) throws Exception {\n        \n        \n        \n    boolean isBatchAvailable = mailbox.createBatch();\n\n        \n    boolean processed = isBatchAvailable && processMailsNonBlocking(singleStep);\n    if (singleStep) {\n        return processed;\n    }\n\n        \n        \n    processed |= processMailsWhenDefaultActionUnavailable();\n\n    return processed;\n}", "summary_tokens": ["this", "helper", "method", "handles", "all", "special", "actions", "from", "the", "mailbox"], "project": "flink"}
{"id": 6149, "code": "public void testIsAvailableOrNotAfterRequestAndRecycleSingleSegment() {\n    final int numBuffers = 2;\n\n    final NetworkBufferPool globalPool = new NetworkBufferPool(numBuffers, 128);\n\n    try {\n            \n        assertTrue(globalPool.getAvailableFuture().isDone());\n\n            \n        final MemorySegment segment1 = checkNotNull(globalPool.requestMemorySegment());\n        assertTrue(globalPool.getAvailableFuture().isDone());\n\n            \n        final MemorySegment segment2 = checkNotNull(globalPool.requestMemorySegment());\n        assertFalse(globalPool.getAvailableFuture().isDone());\n\n        final CompletableFuture<?> availableFuture = globalPool.getAvailableFuture();\n\n            \n        globalPool.recycle(segment1);\n        assertTrue(availableFuture.isDone());\n        assertTrue(globalPool.getAvailableFuture().isDone());\n\n            \n        globalPool.recycle(segment2);\n        assertTrue(globalPool.getAvailableFuture().isDone());\n\n    } finally {\n        globalPool.destroy();\n    }\n}", "summary_tokens": ["tests", "network", "buffer", "pool", "is", "available", "verifying", "that", "the", "buffer", "availability", "is", "correctly", "maintained", "after", "memory", "segments", "are", "requested", "by", "network", "buffer", "pool", "request", "memory", "segment", "and", "recycled", "by", "network", "buffer", "pool", "recycle", "memory", "segment"], "project": "flink"}
{"id": 2299, "code": "private static double round(double x, int m) {\n    if (x < 0) {\n        throw new IllegalArgumentException(\"x must be non-negative\");\n    }\n    double y = x + 5 * Math.pow(10, -m - 1);\n    double z = y * Math.pow(10, m);\n    double q = Math.floor(z);\n    return q / Math.pow(10, m);\n}", "summary_tokens": ["rounding", "function", "defined", "in", "tpc", "h", "standard", "specification", "v", "0"], "project": "flink"}
{"id": 2935, "code": "public void testMaxByRowTypeInfoKeyFieldsForUnsortedGrouping() {\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n    TypeInformation[] types = new TypeInformation[] {Types.INT, Types.INT};\n\n    String[] fieldNames = new String[] {\"id\", \"value\"};\n    RowTypeInfo rowTypeInfo = new RowTypeInfo(types, fieldNames);\n\n    UnsortedGrouping groupDs =\n            env.fromCollection(Collections.singleton(new Row(2)), rowTypeInfo).groupBy(0);\n\n    groupDs.maxBy(1);\n}", "summary_tokens": ["validates", "that", "no", "class", "cast", "exception", "happens", "should", "not", "fail", "e"], "project": "flink"}
{"id": 1259, "code": "public boolean lessThanOrEqual(final ResourceSpec other) {\n    checkNotNull(other, \"Cannot compare with null resources\");\n\n    if (this.equals(UNKNOWN) && other.equals(UNKNOWN)) {\n        return true;\n    } else if (this.equals(UNKNOWN) || other.equals(UNKNOWN)) {\n        throw new IllegalArgumentException(\n                \"Cannot compare specified resources with UNKNOWN resources.\");\n    }\n\n    int cmp1 = this.cpuCores.getValue().compareTo(other.getCpuCores().getValue());\n    int cmp2 = this.taskHeapMemory.compareTo(other.taskHeapMemory);\n    int cmp3 = this.taskOffHeapMemory.compareTo(other.taskOffHeapMemory);\n    int cmp4 = this.managedMemory.compareTo(other.managedMemory);\n    if (cmp1 <= 0 && cmp2 <= 0 && cmp3 <= 0 && cmp4 <= 0) {\n        for (ExternalResource resource : extendedResources.values()) {\n            if (!other.extendedResources.containsKey(resource.getName())\n                    || other.extendedResources\n                                    .get(resource.getName())\n                                    .getValue()\n                                    .compareTo(resource.getValue())\n                            < 0) {\n                return false;\n            }\n        }\n        return true;\n    }\n    return false;\n}", "summary_tokens": ["checks", "the", "current", "resource", "less", "than", "or", "equal", "with", "the", "other", "resource", "by", "comparing", "all", "the", "fields", "in", "the", "resource"], "project": "flink"}
{"id": 2001, "code": "public static int log2strict(int value) throws ArithmeticException, IllegalArgumentException {\n    if (value == 0) {\n        throw new ArithmeticException(\"Logarithm of zero is undefined.\");\n    }\n    if ((value & (value - 1)) != 0) {\n        throw new IllegalArgumentException(\n                \"The given value \" + value + \" is not a power of two.\");\n    }\n    return 31 - Integer.numberOfLeadingZeros(value);\n}", "summary_tokens": ["computes", "the", "logarithm", "of", "the", "given", "value", "to", "the", "base", "of", "0"], "project": "flink"}
{"id": 7260, "code": "public DataStream<String> readFileStream(\n        String filePath, long intervalMillis, FileMonitoringFunction.WatchType watchType) {\n    DataStream<Tuple3<String, Long, Long>> source =\n            addSource(\n                    new FileMonitoringFunction(filePath, intervalMillis, watchType),\n                    \"Read File Stream source\");\n\n    return source.flatMap(new FileReadFunction());\n}", "summary_tokens": ["creates", "a", "data", "stream", "that", "contains", "the", "contents", "of", "file", "created", "while", "system", "watches", "the", "given", "path"], "project": "flink"}
{"id": 8087, "code": "public boolean hasTemporarySystemFunction(String functionName) {\n    return tempSystemFunctions.containsKey(functionName);\n}", "summary_tokens": ["check", "whether", "a", "temporary", "system", "function", "is", "already", "registered"], "project": "flink"}
{"id": 6752, "code": "private void doWriteValue(\n        long valuePointer, byte[] value, int version, long keyPointer, long nextValuePointer) {\n    Node node = getNodeSegmentAndOffset(valuePointer);\n    MemorySegment segment = node.nodeSegment;\n    int offsetInSegment = node.nodeOffset;\n\n    SkipListUtils.putValueVersion(segment, offsetInSegment, version);\n    SkipListUtils.putKeyPointer(segment, offsetInSegment, keyPointer);\n    SkipListUtils.putNextValuePointer(segment, offsetInSegment, nextValuePointer);\n    SkipListUtils.putValueLen(segment, offsetInSegment, value == null ? 0 : value.length);\n    if (value != null) {\n        SkipListUtils.putValueData(segment, offsetInSegment, value);\n    }\n}", "summary_tokens": ["write", "the", "meta", "and", "data", "for", "the", "value", "to", "the", "space", "where", "the", "value", "pointer", "points"], "project": "flink"}
{"id": 6720, "code": "public void testGetAllSortedByName() throws Exception {\n        \n    final TestingLongStateHandleHelper stateHandleProvider = new TestingLongStateHandleHelper();\n\n    ZooKeeperStateHandleStore<TestingLongStateHandleHelper.LongStateHandle> store =\n            new ZooKeeperStateHandleStore<>(ZOOKEEPER.getClient(), stateHandleProvider);\n\n        \n    final String basePath = \"/testGetAllSortedByName\";\n\n    final Long[] expected = new Long[] {311222268470898L, 132812888L, 27255442L, 11122233124L};\n\n        \n    for (long val : expected) {\n        final String pathInZooKeeper = String.format(\"%s%016d\", basePath, val);\n        store.addAndLock(\n                pathInZooKeeper, new TestingLongStateHandleHelper.LongStateHandle(val));\n    }\n\n    List<Tuple2<RetrievableStateHandle<TestingLongStateHandleHelper.LongStateHandle>, String>>\n            actual = store.getAllAndLock();\n    assertEquals(expected.length, actual.size());\n\n        \n    Arrays.sort(expected);\n    Collections.sort(actual, Comparator.comparing(o -> o.f1));\n\n    for (int i = 0; i < expected.length; i++) {\n        assertEquals(expected[i], (Long) actual.get(i).f0.retrieveState().getValue());\n    }\n}", "summary_tokens": ["tests", "that", "the", "state", "is", "returned", "sorted"], "project": "flink"}
{"id": 628, "code": "private static <T, K> void addKafkaShuffle(\n        DataStream<T> inputStream,\n        FlinkKafkaShuffleProducer<T, K> kafkaShuffleProducer,\n        int producerParallelism) {\n\n        \n    inputStream.getTransformation().getOutputType();\n\n    StreamKafkaShuffleSink<T> shuffleSinkOperator =\n            new StreamKafkaShuffleSink<>(kafkaShuffleProducer);\n    LegacySinkTransformation<T> transformation =\n            new LegacySinkTransformation<>(\n                    inputStream.getTransformation(),\n                    \"kafka_shuffle\",\n                    shuffleSinkOperator,\n                    inputStream.getExecutionEnvironment().getParallelism());\n    inputStream.getExecutionEnvironment().addOperator(transformation);\n    transformation.setParallelism(producerParallelism);\n}", "summary_tokens": ["adds", "a", "stream", "kafka", "shuffle", "sink", "to", "data", "stream"], "project": "flink"}
{"id": 1063, "code": "public void disableGenericTypes() {\n    disableGenericTypes = true;\n}", "summary_tokens": ["disables", "the", "use", "of", "generic", "types", "types", "that", "would", "be", "serialized", "via", "kryo"], "project": "flink"}
{"id": 3013, "code": "static <IN, OUT> FlatSelectBuilder<IN, OUT> fromFlatSelect(\n        final PatternFlatSelectFunction<IN, OUT> function) {\n    return new FlatSelectBuilder<>(function);\n}", "summary_tokens": ["starts", "constructing", "a", "pattern", "process", "function", "from", "a", "pattern", "flat", "select", "function", "that", "emitted", "elements", "through", "org"], "project": "flink"}
{"id": 1729, "code": "private void initialize(String scheme, String authority, String path) {\n    try {\n        this.uri = new URI(scheme, authority, normalizePath(path), null, null).normalize();\n    } catch (URISyntaxException e) {\n        throw new IllegalArgumentException(e);\n    }\n}", "summary_tokens": ["initializes", "a", "path", "object", "given", "the", "scheme", "authority", "and", "path", "string"], "project": "flink"}
{"id": 6191, "code": "public void testClientMessageDecodeWithRemovedInputChannel() throws Exception {\n    testNettyMessageClientDecoding(false, false, true);\n}", "summary_tokens": ["verifies", "that", "the", "client", "side", "decoder", "works", "well", "with", "buffers", "sent", "to", "a", "removed", "input", "channel"], "project": "flink"}
{"id": 6340, "code": "public void testNameCollisionForKeyAndValueAfterGenericGroup() {\n    MetricRegistry registry = NoOpMetricRegistry.INSTANCE;\n    GenericMetricGroup root =\n            new GenericMetricGroup(registry, new DummyAbstractMetricGroup(registry), \"root\");\n\n    String key = \"key\";\n    String value = \"value\";\n\n    root.addGroup(key).addGroup(value);\n    MetricGroup group = root.addGroup(key, value);\n\n    String variableValue = group.getAllVariables().get(ScopeFormat.asVariable(\"key\"));\n    assertNull(variableValue);\n\n    String identifier = group.getMetricIdentifier(\"metric\");\n    assertTrue(\"Key is missing from metric identifier.\", identifier.contains(\"key\"));\n    assertTrue(\"Value is missing from metric identifier.\", identifier.contains(\"value\"));\n\n    String logicalScope =\n            ((AbstractMetricGroup) group).getLogicalScope(new DummyCharacterFilter());\n    assertTrue(\"Key is missing from logical scope.\", logicalScope.contains(key));\n    assertTrue(\"Value is missing from logical scope.\", logicalScope.contains(value));\n}", "summary_tokens": ["verifies", "that", "calling", "metric", "group", "add", "group", "string", "string", "if", "a", "generic", "group", "with", "the", "key", "and", "value", "name", "already", "exists", "goes", "through", "the", "generic", "code", "path"], "project": "flink"}
{"id": 6099, "code": "public void testJobManagerLeaderRetrieval() throws Exception {\n    JobID jobId = new JobID();\n\n    LeaderElectionService leaderElectionService =\n            embeddedHaServices.getJobManagerLeaderElectionService(jobId);\n    LeaderRetrievalService leaderRetrievalService =\n            embeddedHaServices.getJobManagerLeaderRetriever(jobId);\n\n    runLeaderRetrievalTest(leaderElectionService, leaderRetrievalService);\n}", "summary_tokens": ["tests", "the", "job", "manager", "leader", "retrieval", "for", "a", "given", "job"], "project": "flink"}
{"id": 3314, "code": "public EdgeMetrics<K, VV, EV> setReduceOnTargetId(boolean reduceOnTargetId) {\n    this.reduceOnTargetId = reduceOnTargetId;\n\n    return this;\n}", "summary_tokens": ["the", "degree", "can", "be", "counted", "from", "either", "the", "edge", "source", "or", "target", "ids"], "project": "flink"}
{"id": 6548, "code": "public void testLoadFileSystemCheckpointStorage() throws Exception {\n    final String checkpointDir = new Path(tmp.newFolder().toURI()).toString();\n    final String savepointDir = new Path(tmp.newFolder().toURI()).toString();\n    final Path expectedCheckpointsPath = new Path(checkpointDir);\n    final Path expectedSavepointsPath = new Path(savepointDir);\n    final MemorySize threshold = MemorySize.parse(\"900kb\");\n    final int minWriteBufferSize = 1024;\n\n        \n        \n        \n    final Configuration config1 = new Configuration();\n    config1.set(CheckpointingOptions.CHECKPOINT_STORAGE, \"filesystem\");\n    config1.set(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir);\n    config1.set(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir);\n    config1.set(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, threshold);\n    config1.setInteger(CheckpointingOptions.FS_WRITE_BUFFER_SIZE, minWriteBufferSize);\n\n    CheckpointStorage storage1 = CheckpointStorageLoader.fromConfig(config1, cl, null).get();\n\n    Assert.assertThat(storage1, Matchers.instanceOf(FileSystemCheckpointStorage.class));\n\n    FileSystemCheckpointStorage fs1 = (FileSystemCheckpointStorage) storage1;\n\n    Assert.assertThat(fs1.getCheckpointPath(), normalizedPath(expectedCheckpointsPath));\n    Assert.assertThat(fs1.getSavepointPath(), normalizedPath(expectedSavepointsPath));\n    Assert.assertEquals(threshold.getBytes(), fs1.getMinFileSizeThreshold());\n    Assert.assertEquals(\n            Math.max(threshold.getBytes(), minWriteBufferSize), fs1.getWriteBufferSize());\n}", "summary_tokens": ["validates", "loading", "a", "file", "system", "checkpoint", "storage", "with", "additional", "parameters", "from", "the", "cluster", "configuration"], "project": "flink"}
{"id": 5420, "code": "private static StateBackend loadFromApplicationOrConfigOrDefaultInternal(\n        @Nullable StateBackend fromApplication,\n        Configuration config,\n        ClassLoader classLoader,\n        @Nullable Logger logger)\n        throws IllegalConfigurationException, DynamicCodeLoadingException, IOException {\n\n    checkNotNull(config, \"config\");\n    checkNotNull(classLoader, \"classLoader\");\n\n    final StateBackend backend;\n\n        \n    if (fromApplication != null) {\n            \n        if (fromApplication instanceof ConfigurableStateBackend) {\n                \n            if (logger != null) {\n                logger.info(\n                        \"Using job/cluster config to configure application-defined state backend: {}\",\n                        fromApplication);\n            }\n\n            backend =\n                    ((ConfigurableStateBackend) fromApplication).configure(config, classLoader);\n        } else {\n                \n            backend = fromApplication;\n        }\n\n        if (logger != null) {\n            logger.info(\"Using application-defined state backend: {}\", backend);\n        }\n    } else {\n            \n        final StateBackend fromConfig = loadStateBackendFromConfig(config, classLoader, logger);\n        if (fromConfig != null) {\n            backend = fromConfig;\n        } else {\n                \n            backend = new HashMapStateBackendFactory().createFromConfig(config, classLoader);\n            if (logger != null) {\n                logger.info(\n                        \"No state backend has been configured, using default (HashMap) {}\",\n                        backend);\n            }\n        }\n    }\n\n    return backend;\n}", "summary_tokens": ["checks", "if", "an", "application", "defined", "state", "backend", "is", "given", "and", "if", "not", "loads", "the", "state", "backend", "from", "the", "configuration", "from", "the", "parameter", "state"], "project": "flink"}
{"id": 6599, "code": "public void testKeyGroupsSnapshotRestoreScaleDownUnEvenDistribute() throws Exception {\n    testKeyGroupSnapshotRestore(77, 15, 128);\n}", "summary_tokens": ["similar", "with", "test", "key", "group", "snapshot", "restore", "scale", "down", "but", "the", "key", "groups", "were", "distributed", "unevenly"], "project": "flink"}
{"id": 7017, "code": "public AllWindowedStream<T, W> trigger(Trigger<? super T, ? super W> trigger) {\n    if (windowAssigner instanceof MergingWindowAssigner && !trigger.canMerge()) {\n        throw new UnsupportedOperationException(\n                \"A merging window assigner cannot be used with a trigger that does not support merging.\");\n    }\n\n    this.trigger = trigger;\n    return this;\n}", "summary_tokens": ["sets", "the", "trigger", "that", "should", "be", "used", "to", "trigger", "window", "emission"], "project": "flink"}
{"id": 6696, "code": "public void testSizeWithMaxSize0() {\n    final BoundedFIFOQueue<Integer> testInstance = new BoundedFIFOQueue<>(0);\n    assertThat(testInstance.size(), is(0));\n\n    testInstance.add(1);\n    assertThat(testInstance.size(), is(0));\n}", "summary_tokens": ["tests", "that", "bounded", "fifoqueue", "size", "returns", "the", "number", "of", "elements", "currently", "stored", "in", "the", "queue", "with", "a", "max", "size", "of", "0"], "project": "flink"}
{"id": 7112, "code": "public <W extends Window> WindowedStream<T, KEY, W> window(\n        WindowAssigner<? super T, W> assigner) {\n    return new WindowedStream<>(this, assigner);\n}", "summary_tokens": ["windows", "this", "data", "stream", "to", "a", "windowed", "stream", "which", "evaluates", "windows", "over", "a", "key", "grouped", "stream"], "project": "flink"}
{"id": 3918, "code": "public void testFailureClosesChannel() throws Exception {\n    AtomicKvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n    final MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    Client<KvStateInternalRequest, KvStateResponse> client = null;\n    Channel serverChannel = null;\n\n    try {\n        client = new Client<>(\"Test Client\", 1, serializer, stats);\n\n        final LinkedBlockingQueue<ByteBuf> received = new LinkedBlockingQueue<>();\n        final AtomicReference<Channel> channel = new AtomicReference<>();\n\n        serverChannel =\n                createServerChannel(new ChannelDataCollectingHandler(channel, received));\n\n        InetSocketAddress serverAddress = getKvStateServerAddress(serverChannel);\n\n            \n        List<Future<KvStateResponse>> futures = new ArrayList<>();\n        KvStateInternalRequest request =\n                new KvStateInternalRequest(new KvStateID(), new byte[0]);\n\n        futures.add(client.sendRequest(serverAddress, request));\n        futures.add(client.sendRequest(serverAddress, request));\n\n        ByteBuf buf = received.take();\n        assertNotNull(\"Receive timed out\", buf);\n        buf.release();\n\n        buf = received.take();\n        assertNotNull(\"Receive timed out\", buf);\n        buf.release();\n\n        assertEquals(1L, stats.getNumConnections());\n\n        Channel ch = channel.get();\n        assertNotNull(\"Channel not active\", ch);\n\n            \n        ch.writeAndFlush(\n                MessageSerializer.serializeServerFailure(\n                        serverChannel.alloc(),\n                        new RuntimeException(\"Expected test server failure\")));\n\n        try {\n            futures.remove(0).get();\n            fail(\"Did not throw expected server failure\");\n        } catch (ExecutionException e) {\n\n            if (!(e.getCause() instanceof RuntimeException)) {\n                fail(\"Did not throw expected Exception\");\n            }\n                \n        }\n\n        try {\n            futures.remove(0).get();\n            fail(\"Did not throw expected server failure\");\n        } catch (ExecutionException e) {\n\n            if (!(e.getCause() instanceof RuntimeException)) {\n                fail(\"Did not throw expected Exception\");\n            }\n                \n        }\n\n        assertEquals(0L, stats.getNumConnections());\n\n            \n        while (stats.getNumSuccessful() != 0L || stats.getNumFailed() != 2L) {\n            Thread.sleep(100L);\n        }\n\n        assertEquals(2L, stats.getNumRequests());\n        assertEquals(0L, stats.getNumSuccessful());\n        assertEquals(2L, stats.getNumFailed());\n    } finally {\n        if (client != null) {\n            try {\n                client.shutdown().get();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            Assert.assertTrue(client.isEventGroupShutdown());\n        }\n\n        if (serverChannel != null) {\n            serverChannel.close();\n        }\n\n        assertEquals(\"Channel leak\", 0L, stats.getNumConnections());\n    }\n}", "summary_tokens": ["tests", "that", "a", "server", "failure", "closes", "the", "connection", "and", "removes", "it", "from", "the", "established", "connections"], "project": "flink"}
{"id": 8705, "code": "public static boolean validConstant(Object o, Litmus litmus) {\n    if (o == null\n            || o instanceof BigDecimal\n            || o instanceof NlsString\n            || o instanceof ByteString\n            || o instanceof Boolean) {\n        return litmus.succeed();\n    } else if (o instanceof List) {\n        List list = (List) o;\n        for (Object o1 : list) {\n            if (!validConstant(o1, litmus)) {\n                return litmus.fail(\"not a constant: {}\", o1);\n            }\n        }\n        return litmus.succeed();\n    } else if (o instanceof Map) {\n        @SuppressWarnings(\"unchecked\")\n        final Map<Object, Object> map = (Map) o;\n        for (Map.Entry entry : map.entrySet()) {\n            if (!validConstant(entry.getKey(), litmus)) {\n                return litmus.fail(\"not a constant: {}\", entry.getKey());\n            }\n            if (!validConstant(entry.getValue(), litmus)) {\n                return litmus.fail(\"not a constant: {}\", entry.getValue());\n            }\n        }\n        return litmus.succeed();\n    } else {\n        return litmus.fail(\"not a constant: {}\", o);\n    }\n}", "summary_tokens": ["returns", "whether", "a", "value", "is", "valid", "as", "a", "constant", "value", "using", "the", "same", "criteria", "as", "value", "matches", "type"], "project": "flink"}
{"id": 2336, "code": "public void set(String name, String value, String source) {\n    Preconditions.checkArgument(name != null, \"Property name must not be null\");\n    Preconditions.checkArgument(\n            value != null, \"The value of property %s must not be null\", name);\n    name = name.trim();\n    DeprecationContext deprecations = deprecationContext.get();\n    if (deprecations.getDeprecatedKeyMap().isEmpty()) {\n        getProps();\n    }\n    getOverlay().setProperty(name, value);\n    getProps().setProperty(name, value);\n    String newSource = (source == null ? \"programmatically\" : source);\n\n    if (!isDeprecated(name)) {\n        putIntoUpdatingResource(name, new String[] {newSource});\n        String[] altNames = getAlternativeNames(name);\n        if (altNames != null) {\n            for (String n : altNames) {\n                if (!n.equals(name)) {\n                    getOverlay().setProperty(n, value);\n                    getProps().setProperty(n, value);\n                    putIntoUpdatingResource(n, new String[] {newSource});\n                }\n            }\n        }\n    } else {\n        String[] names = handleDeprecation(deprecationContext.get(), name);\n        String altSource = \"because \" + name + \" is deprecated\";\n        for (String n : names) {\n            getOverlay().setProperty(n, value);\n            getProps().setProperty(n, value);\n            putIntoUpdatingResource(n, new String[] {altSource});\n        }\n    }\n}", "summary_tokens": ["set", "the", "code", "value", "code", "of", "the", "code", "name", "code", "property"], "project": "flink"}
{"id": 3949, "code": "public void testUnexpectedMessage() throws Exception {\n    KvStateRegistry registry = new KvStateRegistry();\n    AtomicKvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n    MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    KvStateServerHandler handler =\n            new KvStateServerHandler(testServer, registry, serializer, stats);\n    EmbeddedChannel channel = new EmbeddedChannel(getFrameDecoder(), handler);\n\n        \n    ByteBuf unexpectedMessage = Unpooled.buffer(8);\n    unexpectedMessage.writeInt(4);\n    unexpectedMessage.writeInt(123238213);\n\n    channel.writeInbound(unexpectedMessage);\n\n    ByteBuf buf = (ByteBuf) readInboundBlocking(channel);\n    buf.skipBytes(4); \n\n        \n    assertEquals(MessageType.SERVER_FAILURE, MessageSerializer.deserializeHeader(buf));\n    Throwable response = MessageSerializer.deserializeServerFailure(buf);\n    buf.release();\n\n    assertEquals(0L, stats.getNumRequests());\n    assertEquals(0L, stats.getNumFailed());\n\n    KvStateResponse stateResponse = new KvStateResponse(new byte[0]);\n    unexpectedMessage =\n            MessageSerializer.serializeResponse(channel.alloc(), 192L, stateResponse);\n\n    channel.writeInbound(unexpectedMessage);\n\n    buf = (ByteBuf) readInboundBlocking(channel);\n    buf.skipBytes(4); \n\n        \n    assertEquals(MessageType.SERVER_FAILURE, MessageSerializer.deserializeHeader(buf));\n    response = MessageSerializer.deserializeServerFailure(buf);\n    buf.release();\n\n    assertTrue(\n            \"Unexpected failure cause \" + response.getClass().getName(),\n            response instanceof IllegalArgumentException);\n\n    assertEquals(0L, stats.getNumRequests());\n    assertEquals(0L, stats.getNumFailed());\n}", "summary_tokens": ["tests", "response", "on", "unexpected", "messages"], "project": "flink"}
{"id": 7627, "code": "public void testIterationRuntimeContext() throws Exception {\n    RichAsyncFunction<Integer, Integer> function =\n            new RichAsyncFunction<Integer, Integer>() {\n                private static final long serialVersionUID = -2023923961609455894L;\n\n                @Override\n                public void asyncInvoke(Integer input, ResultFuture<Integer> resultFuture)\n                        throws Exception {\n                        \n                }\n            };\n\n    int superstepNumber = 42;\n\n    IterationRuntimeContext mockedIterationRuntimeContext = mock(IterationRuntimeContext.class);\n    when(mockedIterationRuntimeContext.getSuperstepNumber()).thenReturn(superstepNumber);\n    function.setRuntimeContext(mockedIterationRuntimeContext);\n\n    IterationRuntimeContext iterationRuntimeContext = function.getIterationRuntimeContext();\n\n    assertEquals(superstepNumber, iterationRuntimeContext.getSuperstepNumber());\n\n    try {\n        iterationRuntimeContext.getIterationAggregator(\"foobar\");\n        fail(\"Expected getIterationAggregator to fail with unsupported operation exception\");\n    } catch (UnsupportedOperationException e) {\n            \n    }\n\n    try {\n        iterationRuntimeContext.getPreviousIterationAggregate(\"foobar\");\n        fail(\n                \"Expected getPreviousIterationAggregator to fail with unsupported operation exception\");\n    } catch (UnsupportedOperationException e) {\n            \n    }\n}", "summary_tokens": ["test", "the", "set", "of", "iteration", "runtime", "context", "methods", "in", "the", "context", "of", "a", "rich", "async", "function"], "project": "flink"}
{"id": 7179, "code": "public CheckpointingMode getCheckpointingMode() {\n    return checkpointingMode;\n}", "summary_tokens": ["gets", "the", "checkpointing", "mode", "exactly", "once", "vs"], "project": "flink"}
{"id": 4911, "code": "public CompletableFuture<Void> terminateTaskManager(int index) {\n    synchronized (lock) {\n        final TaskExecutor taskExecutor = taskManagers.get(index);\n        return taskExecutor.closeAsync();\n    }\n}", "summary_tokens": ["terminates", "a", "task", "manager", "with", "the", "given", "index"], "project": "flink"}
{"id": 1849, "code": "public int getFieldPos() {\n    return this.fieldPos;\n}", "summary_tokens": ["gets", "the", "field", "number", "that", "was", "attempted", "to", "access"], "project": "flink"}
{"id": 696, "code": "public void runCancelingOnEmptyInputTest() throws Exception {\n    final String topic = \"cancelingOnEmptyInputTopic\";\n\n    final int parallelism = 3;\n    createTestTopic(topic, parallelism, 1);\n\n    final AtomicReference<Throwable> error = new AtomicReference<>();\n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(parallelism);\n    env.enableCheckpointing(100);\n\n    Properties props = new Properties();\n    props.putAll(standardProps);\n    props.putAll(secureProps);\n\n    getStream(env, topic, new SimpleStringSchema(), props)\n            .addSink(new DiscardingSink<String>());\n\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n    final JobID jobId = jobGraph.getJobID();\n\n    final Runnable jobRunner =\n            () -> {\n                try {\n                    submitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n                } catch (Throwable t) {\n                    LOG.error(\"Job Runner failed with exception\", t);\n                    error.set(t);\n                }\n            };\n\n    Thread runnerThread = new Thread(jobRunner, \"program runner thread\");\n    runnerThread.start();\n\n        \n    Thread.sleep(2000);\n\n    Throwable failueCause = error.get();\n    if (failueCause != null) {\n        failueCause.printStackTrace();\n        Assert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n    }\n        \n    client.cancel(jobId).get();\n\n        \n    runnerThread.join();\n\n    assertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["tests", "that", "the", "source", "can", "be", "properly", "canceled", "when", "reading", "empty", "partitions"], "project": "flink"}
{"id": 1251, "code": "public void setResources(ResourceSpec minResources, ResourceSpec preferredResources) {\n    this.minResources = minResources;\n    this.preferredResources = preferredResources;\n}", "summary_tokens": ["sets", "the", "minimum", "and", "preferred", "resources", "for", "this", "contract", "instance"], "project": "flink"}
{"id": 9500, "code": "public static void waitUtil(Supplier<Boolean> condition, Duration timeout, String errorMsg)\n        throws TimeoutException, InterruptedException {\n    waitUtil(condition, timeout, Duration.ofMillis(1), errorMsg);\n}", "summary_tokens": ["wait", "util", "the", "given", "condition", "is", "met", "or", "timeout"], "project": "flink"}
{"id": 1824, "code": "public <P> Iterator<P> load(Class<P> service) {\n    try (TemporaryClassLoaderContext ignored =\n            TemporaryClassLoaderContext.of(pluginClassLoader)) {\n        return new ContextClassLoaderSettingIterator<>(\n                ServiceLoader.load(service, pluginClassLoader).iterator(), pluginClassLoader);\n    }\n}", "summary_tokens": ["returns", "in", "iterator", "over", "all", "available", "implementations", "of", "the", "given", "service", "interface", "spi", "for", "the", "plugin"], "project": "flink"}
{"id": 4894, "code": "public void close() {\n    synchronized (this) {\n        if (!isClosed()) {\n                \n            super.close();\n\n                \n            for (ComponentMetricGroup group : subComponents()) {\n                group.close();\n            }\n        }\n    }\n}", "summary_tokens": ["closes", "the", "component", "group", "by", "removing", "and", "closing", "all", "metrics", "and", "subgroups", "inherited", "from", "abstract", "metric", "group", "plus", "closing", "and", "removing", "all", "dedicated", "component", "subgroups"], "project": "flink"}
{"id": 6903, "code": "public double getWriteBufferRatio() {\n    return writeBufferRatio != null\n            ? writeBufferRatio\n            : RocksDBOptions.WRITE_BUFFER_RATIO.defaultValue();\n}", "summary_tokens": ["gets", "the", "fraction", "of", "the", "total", "memory", "to", "be", "used", "for", "write", "buffers"], "project": "flink"}
{"id": 1231, "code": "public UserCodeWrapper<? extends T> getFormatWrapper() {\n    return this.formatWrapper;\n}", "summary_tokens": ["gets", "the", "class", "describing", "the", "input", "format"], "project": "flink"}
{"id": 1947, "code": "public static boolean isDirectOutOfMemoryError(@Nullable Throwable t) {\n    return isOutOfMemoryErrorWithMessageContaining(t, \"Direct buffer memory\");\n}", "summary_tokens": ["checks", "whether", "the", "given", "exception", "indicates", "a", "jvm", "direct", "out", "of", "memory", "error"], "project": "flink"}
{"id": 4860, "code": "public long getMemorySize() {\n    return memoryBudget.getTotalMemorySize();\n}", "summary_tokens": ["returns", "the", "total", "size", "of", "memory", "handled", "by", "this", "memory", "manager"], "project": "flink"}
{"id": 5864, "code": "public void testOnePortAvailable() throws IOException {\n    int numAllocated = 2;\n    ServerSocket[] sockets = new ServerSocket[numAllocated];\n    for (int i = 0; i < numAllocated; i++) {\n        try {\n            sockets[i] = new ServerSocket(0);\n        } catch (IOException e) {\n            e.printStackTrace();\n            Assert.fail(\"An exception was thrown while preparing the test \" + e.getMessage());\n        }\n    }\n    Configuration conf = new Configuration();\n    conf.setString(\n            BlobServerOptions.PORT,\n            sockets[0].getLocalPort() + \",\" + sockets[1].getLocalPort() + \",50000-50050\");\n    conf.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n        \n    try {\n        BlobServer server = new BlobServer(conf, new VoidBlobStore());\n        server.start();\n        assertThat(\n                server.getPort(), allOf(greaterThanOrEqualTo(50000), lessThanOrEqualTo(50050)));\n        server.close();\n    } finally {\n        for (int i = 0; i < numAllocated; ++i) {\n            sockets[i].close();\n        }\n    }\n}", "summary_tokens": ["give", "the", "blob", "server", "a", "choice", "of", "three", "ports", "where", "two", "of", "them", "are", "allocated"], "project": "flink"}
{"id": 3233, "code": "public int getParallelism() {\n    return parallelism;\n}", "summary_tokens": ["gets", "the", "iteration", "s", "parallelism"], "project": "flink"}
{"id": 468, "code": "public boolean reachedEnd() throws IOException {\n    return !hasNext;\n}", "summary_tokens": ["checks", "whether", "all", "data", "has", "been", "read"], "project": "flink"}
{"id": 7374, "code": "public void startTimerService(\n        TypeSerializer<K> keySerializer,\n        TypeSerializer<N> namespaceSerializer,\n        Triggerable<K, N> triggerTarget) {\n\n    if (!isInitialized) {\n\n        if (keySerializer == null || namespaceSerializer == null) {\n            throw new IllegalArgumentException(\"The TimersService serializers cannot be null.\");\n        }\n\n        if (this.keySerializer != null\n                || this.namespaceSerializer != null\n                || this.triggerTarget != null) {\n            throw new IllegalStateException(\"The TimerService has already been initialized.\");\n        }\n\n            \n        if (restoredTimersSnapshot != null) {\n            TypeSerializerSchemaCompatibility<K> keySerializerCompatibility =\n                    restoredTimersSnapshot\n                            .getKeySerializerSnapshot()\n                            .resolveSchemaCompatibility(keySerializer);\n\n            if (keySerializerCompatibility.isIncompatible()\n                    || keySerializerCompatibility.isCompatibleAfterMigration()) {\n                throw new IllegalStateException(\n                        \"Tried to initialize restored TimerService with new key serializer that requires migration or is incompatible.\");\n            }\n\n            TypeSerializerSchemaCompatibility<N> namespaceSerializerCompatibility =\n                    restoredTimersSnapshot\n                            .getNamespaceSerializerSnapshot()\n                            .resolveSchemaCompatibility(namespaceSerializer);\n\n            restoredTimersSnapshot = null;\n\n            if (namespaceSerializerCompatibility.isIncompatible()\n                    || namespaceSerializerCompatibility.isCompatibleAfterMigration()) {\n                throw new IllegalStateException(\n                        \"Tried to initialize restored TimerService with new namespace serializer that requires migration or is incompatible.\");\n            }\n\n            this.keySerializer =\n                    keySerializerCompatibility.isCompatibleAsIs()\n                            ? keySerializer\n                            : keySerializerCompatibility.getReconfiguredSerializer();\n            this.namespaceSerializer =\n                    namespaceSerializerCompatibility.isCompatibleAsIs()\n                            ? namespaceSerializer\n                            : namespaceSerializerCompatibility.getReconfiguredSerializer();\n        } else {\n            this.keySerializer = keySerializer;\n            this.namespaceSerializer = namespaceSerializer;\n        }\n\n        this.keyDeserializer = null;\n        this.namespaceDeserializer = null;\n\n        this.triggerTarget = Preconditions.checkNotNull(triggerTarget);\n\n            \n        final InternalTimer<K, N> headTimer = processingTimeTimersQueue.peek();\n        if (headTimer != null) {\n            nextTimer =\n                    processingTimeService.registerTimer(\n                            headTimer.getTimestamp(), this::onProcessingTime);\n        }\n        this.isInitialized = true;\n    } else {\n        if (!(this.keySerializer.equals(keySerializer)\n                && this.namespaceSerializer.equals(namespaceSerializer))) {\n            throw new IllegalArgumentException(\n                    \"Already initialized Timer Service \"\n                            + \"tried to be initialized with different key and namespace serializers.\");\n        }\n    }\n}", "summary_tokens": ["starts", "the", "local", "internal", "timer", "service", "impl", "by"], "project": "flink"}
{"id": 1385, "code": "protected OuterSchemaCompatibility resolveOuterSchemaCompatibility(S newSerializer) {\n    return (isOuterSnapshotCompatible(newSerializer))\n            ? OuterSchemaCompatibility.COMPATIBLE_AS_IS\n            : OuterSchemaCompatibility.INCOMPATIBLE;\n}", "summary_tokens": ["checks", "the", "schema", "compatibility", "of", "the", "given", "new", "serializer", "based", "on", "the", "outer", "snapshot"], "project": "flink"}
{"id": 567, "code": "private void cleanUpUserContext(\n        Collection<FlinkKafkaProducer.KafkaTransactionState> handledTransactions) {\n    if (!getUserContext().isPresent()) {\n        return;\n    }\n    HashSet<String> abortTransactions = new HashSet<>(getUserContext().get().transactionalIds);\n    handledTransactions.forEach(\n            kafkaTransactionState ->\n                    abortTransactions.remove(kafkaTransactionState.transactionalId));\n    abortTransactions(abortTransactions);\n}", "summary_tokens": ["after", "initialization", "make", "sure", "that", "all", "previous", "transactions", "from", "the", "current", "user", "context", "have", "been", "completed"], "project": "flink"}
{"id": 4344, "code": "public boolean allFieldsNoLessThan(final ResourceProfile other) {\n    checkNotNull(other, \"Cannot compare null resources\");\n\n    if (this.equals(ANY)) {\n        return true;\n    }\n\n    if (this.equals(other)) {\n        return true;\n    }\n\n    if (this.equals(UNKNOWN)) {\n        return false;\n    }\n\n    if (other.equals(UNKNOWN)) {\n        return true;\n    }\n\n    if (cpuCores.getValue().compareTo(other.cpuCores.getValue()) >= 0\n            && taskHeapMemory.compareTo(other.taskHeapMemory) >= 0\n            && taskOffHeapMemory.compareTo(other.taskOffHeapMemory) >= 0\n            && managedMemory.compareTo(other.managedMemory) >= 0\n            && networkMemory.compareTo(other.networkMemory) >= 0) {\n\n        for (Map.Entry<String, ExternalResource> resource :\n                other.extendedResources.entrySet()) {\n            if (!extendedResources.containsKey(resource.getKey())\n                    || extendedResources\n                                    .get(resource.getKey())\n                                    .getValue()\n                                    .compareTo(resource.getValue().getValue())\n                            < 0) {\n                return false;\n            }\n        }\n        return true;\n    }\n    return false;\n}", "summary_tokens": ["check", "whether", "all", "fields", "of", "this", "resource", "profile", "are", "no", "less", "than", "the", "given", "resource", "profile"], "project": "flink"}
{"id": 4397, "code": "public boolean tryAssignResource(final LogicalSlot logicalSlot) {\n\n    assertRunningInJobMasterMainThread();\n\n    checkNotNull(logicalSlot);\n\n        \n        \n    if (state == SCHEDULED || state == CREATED) {\n        if (assignedResource == null) {\n            assignedResource = logicalSlot;\n            if (logicalSlot.tryAssignPayload(this)) {\n                    \n                if ((state == SCHEDULED || state == CREATED)\n                        && !taskManagerLocationFuture.isDone()) {\n                    taskManagerLocationFuture.complete(logicalSlot.getTaskManagerLocation());\n                    assignedAllocationID = logicalSlot.getAllocationId();\n                    return true;\n                } else {\n                        \n                    assignedResource = null;\n                    return false;\n                }\n            } else {\n                assignedResource = null;\n                return false;\n            }\n        } else {\n                \n            return false;\n        }\n    } else {\n            \n        return false;\n    }\n}", "summary_tokens": ["tries", "to", "assign", "the", "given", "slot", "to", "the", "execution"], "project": "flink"}
{"id": 8074, "code": "public ResolvedCatalogView resolveCatalogView(CatalogView view) {\n    Preconditions.checkState(schemaResolver != null, \"Schema resolver is not initialized.\");\n    if (view instanceof ResolvedCatalogView) {\n        return (ResolvedCatalogView) view;\n    }\n    final ResolvedSchema resolvedSchema = view.getUnresolvedSchema().resolve(schemaResolver);\n    return new ResolvedCatalogView(view, resolvedSchema);\n}", "summary_tokens": ["resolves", "a", "catalog", "view", "to", "a", "validated", "resolved", "catalog", "view"], "project": "flink"}
{"id": 6516, "code": "public void testCallAsyncTimeout()\n        throws InterruptedException, ExecutionException, TimeoutException {\n    final RpcEndpoint endpoint = new BaseEndpoint(rpcService);\n    final Time timeout = Time.milliseconds(100);\n    CountDownLatch latch = new CountDownLatch(1);\n    try {\n        endpoint.start();\n        final CompletableFuture<Throwable> throwableFuture =\n                endpoint.callAsync(\n                                () -> {\n                                    endpoint.validateRunsInMainThread();\n                                    latch.await();\n                                    return 12345;\n                                },\n                                timeout)\n                        .handle((ignore, throwable) -> throwable);\n        final Throwable throwable = throwableFuture.get();\n\n        assertNotNull(throwable);\n        assertThat(throwable, instanceOf(TimeoutException.class));\n    } finally {\n        latch.countDown();\n        RpcUtils.terminateRpcEndpoint(endpoint, TIMEOUT);\n    }\n}", "summary_tokens": ["make", "the", "callable", "sleep", "some", "time", "more", "than", "specified", "timeout", "so", "timeout", "exception", "is", "expected"], "project": "flink"}
{"id": 6168, "code": "public void testExceptionOnRemoteClose() throws Exception {\n\n    NettyProtocol protocol =\n            new NettyProtocol(\n                    mock(ResultPartitionProvider.class), mock(TaskEventDispatcher.class)) {\n\n                @Override\n                public ChannelHandler[] getServerChannelHandlers() {\n                    return new ChannelHandler[] {\n                            \n                        new ChannelInboundHandlerAdapter() {\n                            @Override\n                            public void channelRead(ChannelHandlerContext ctx, Object msg)\n                                    throws Exception {\n\n                                ctx.channel().close();\n                            }\n                        }\n                    };\n                }\n            };\n\n    NettyServerAndClient serverAndClient = initServerAndClient(protocol, createConfig());\n\n    Channel ch = connect(serverAndClient);\n\n    NetworkClientHandler handler = getClientHandler(ch);\n\n        \n    RemoteInputChannel[] rich =\n            new RemoteInputChannel[] {createRemoteInputChannel(), createRemoteInputChannel()};\n\n    final CountDownLatch sync = new CountDownLatch(rich.length);\n\n    Answer<Void> countDownLatch =\n            new Answer<Void>() {\n                @Override\n                public Void answer(InvocationOnMock invocation) throws Throwable {\n                    sync.countDown();\n                    return null;\n                }\n            };\n\n    for (RemoteInputChannel r : rich) {\n        doAnswer(countDownLatch).when(r).onError(any(Throwable.class));\n        handler.addInputChannel(r);\n    }\n\n        \n    ch.writeAndFlush(Unpooled.buffer().writerIndex(16));\n\n        \n    if (!sync.await(TestingUtils.TESTING_DURATION.toMillis(), TimeUnit.MILLISECONDS)) {\n        fail(\n                \"Timed out after waiting for \"\n                        + TestingUtils.TESTING_DURATION.toMillis()\n                        + \" ms to be notified about remote connection close.\");\n    }\n\n        \n    for (RemoteInputChannel r : rich) {\n        verify(r).onError(isA(RemoteTransportException.class));\n    }\n\n    shutdown(serverAndClient);\n}", "summary_tokens": ["verifies", "that", "unexpected", "remote", "closes", "are", "reported", "as", "an", "instance", "of", "remote", "transport", "exception"], "project": "flink"}
{"id": 1740, "code": "public static Path fromLocalFile(File file) {\n    return new Path(file.toURI());\n}", "summary_tokens": ["creates", "a", "path", "for", "the", "given", "local", "file"], "project": "flink"}
{"id": 5014, "code": "protected void releaseTable() {\n        \n    this.numBuckets = 0;\n\n    if (this.buckets != null) {\n        for (MemorySegment bucket : this.buckets) {\n            this.availableMemory.add(bucket);\n        }\n        this.buckets = null;\n    }\n}", "summary_tokens": ["releases", "the", "table", "the", "array", "of", "buckets", "and", "returns", "the", "occupied", "memory", "segments", "to", "the", "list", "of", "free", "segments"], "project": "flink"}
{"id": 6356, "code": "public void testRESTServerSSLDisabled() throws Exception {\n    Configuration serverConfig = createRestSslConfigWithKeyStore();\n    serverConfig.setBoolean(SecurityOptions.SSL_REST_ENABLED, false);\n\n    try {\n        SSLUtils.createRestServerSSLEngineFactory(serverConfig);\n        fail(\"exception expected\");\n    } catch (IllegalConfigurationException ignored) {\n    }\n}", "summary_tokens": ["tests", "that", "rest", "server", "ssl", "engine", "is", "not", "created", "if", "ssl", "is", "disabled"], "project": "flink"}
{"id": 7516, "code": "public int getCurrentTableCapacity() {\n    return table.length;\n}", "summary_tokens": ["gets", "the", "current", "table", "capacity", "i"], "project": "flink"}
{"id": 5875, "code": "public void ensureRegisteredAtHookTime() throws Exception {\n    final String id = \"id\";\n\n        \n    ExecutionGraph graph =\n            new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                    .addJobVertex(new JobVertexID())\n                    .build();\n    final ManuallyTriggeredScheduledExecutor manuallyTriggeredScheduledExecutor =\n            new ManuallyTriggeredScheduledExecutor();\n    CheckpointCoordinator cc =\n            instantiateCheckpointCoordinator(graph, manuallyTriggeredScheduledExecutor);\n\n    final MasterTriggerRestoreHook<Void> hook = mockGeneric(MasterTriggerRestoreHook.class);\n    when(hook.getIdentifier()).thenReturn(id);\n    when(hook.triggerCheckpoint(anyLong(), anyLong(), any(Executor.class)))\n            .thenAnswer(\n                    new Answer<CompletableFuture<Void>>() {\n\n                        @Override\n                        public CompletableFuture<Void> answer(InvocationOnMock invocation)\n                                throws Throwable {\n                            assertEquals(1, cc.getNumberOfPendingCheckpoints());\n\n                            long checkpointId = (Long) invocation.getArguments()[0];\n                            assertNotNull(cc.getPendingCheckpoints().get(checkpointId));\n                            return null;\n                        }\n                    });\n\n    cc.addMasterHook(hook);\n\n        \n    final CompletableFuture<CompletedCheckpoint> checkpointFuture = cc.triggerCheckpoint(false);\n    manuallyTriggeredScheduledExecutor.triggerAll();\n    assertFalse(checkpointFuture.isCompletedExceptionally());\n}", "summary_tokens": ["this", "test", "makes", "sure", "that", "the", "checkpoint", "is", "already", "registered", "by", "the", "time"], "project": "flink"}
{"id": 1362, "code": "public Map<String, TypeInformation<?>> getGenericParameters() {\n        \n    return Collections.emptyMap();\n}", "summary_tokens": ["optional", "method", "for", "giving", "flink", "s", "type", "extraction", "system", "information", "about", "the", "mapping", "of", "a", "generic", "type", "parameter", "to", "the", "type", "information", "of", "a", "subtype"], "project": "flink"}
{"id": 4966, "code": "private void insertBucketEntryFromStart(\n        MemorySegment bucket,\n        int bucketInSegmentPos,\n        int hashCode,\n        long pointer,\n        int partitionNumber)\n        throws IOException {\n    boolean checkForResize = false;\n        \n    final int count = bucket.getInt(bucketInSegmentPos + HEADER_COUNT_OFFSET);\n    if (count < NUM_ENTRIES_PER_BUCKET) {\n            \n        bucket.putInt(\n                bucketInSegmentPos + BUCKET_HEADER_LENGTH + (count * HASH_CODE_LEN),\n                hashCode); \n        bucket.putLong(\n                bucketInSegmentPos + BUCKET_POINTER_START_OFFSET + (count * POINTER_LEN),\n                pointer); \n        bucket.putInt(bucketInSegmentPos + HEADER_COUNT_OFFSET, count + 1); \n    } else {\n            \n        final InMemoryPartition<T> p = this.partitions.get(partitionNumber);\n\n        final long originalForwardPointer =\n                bucket.getLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET);\n        final long forwardForNewBucket;\n\n        if (originalForwardPointer != BUCKET_FORWARD_POINTER_NOT_SET) {\n\n                \n            final int overflowSegNum = (int) (originalForwardPointer >>> 32);\n            final int segOffset = (int) originalForwardPointer;\n            final MemorySegment seg = p.overflowSegments[overflowSegNum];\n\n            final int obCount = seg.getInt(segOffset + HEADER_COUNT_OFFSET);\n\n                \n            if (obCount < NUM_ENTRIES_PER_BUCKET) {\n                    \n                seg.putInt(\n                        segOffset + BUCKET_HEADER_LENGTH + (obCount * HASH_CODE_LEN),\n                        hashCode); \n                seg.putLong(\n                        segOffset + BUCKET_POINTER_START_OFFSET + (obCount * POINTER_LEN),\n                        pointer); \n                seg.putInt(segOffset + HEADER_COUNT_OFFSET, obCount + 1); \n                return;\n            } else {\n                    \n                    \n                forwardForNewBucket = originalForwardPointer;\n            }\n        } else {\n                \n            forwardForNewBucket = BUCKET_FORWARD_POINTER_NOT_SET;\n        }\n\n            \n        MemorySegment overflowSeg;\n        final int overflowBucketNum;\n        final int overflowBucketOffset;\n\n            \n            \n        if (p.nextOverflowBucket == 0) {\n                \n            overflowSeg = getNextBuffer();\n            overflowBucketOffset = 0;\n            overflowBucketNum = p.numOverflowSegments;\n\n                \n            if (p.overflowSegments.length <= p.numOverflowSegments) {\n                MemorySegment[] newSegsArray = new MemorySegment[p.overflowSegments.length * 2];\n                System.arraycopy(\n                        p.overflowSegments, 0, newSegsArray, 0, p.overflowSegments.length);\n                p.overflowSegments = newSegsArray;\n            }\n            p.overflowSegments[p.numOverflowSegments] = overflowSeg;\n            p.numOverflowSegments++;\n            checkForResize = true;\n        } else {\n                \n            overflowBucketNum = p.numOverflowSegments - 1;\n            overflowSeg = p.overflowSegments[overflowBucketNum];\n            overflowBucketOffset = p.nextOverflowBucket << NUM_INTRA_BUCKET_BITS;\n        }\n\n            \n            \n            \n        p.nextOverflowBucket =\n                (p.nextOverflowBucket == this.bucketsPerSegmentMask\n                        ? 0\n                        : p.nextOverflowBucket + 1);\n\n            \n            \n            \n        overflowSeg.putLong(overflowBucketOffset + HEADER_FORWARD_OFFSET, forwardForNewBucket);\n        final long pointerToNewBucket =\n                (((long) overflowBucketNum) << 32) | ((long) overflowBucketOffset);\n        bucket.putLong(bucketInSegmentPos + HEADER_FORWARD_OFFSET, pointerToNewBucket);\n\n            \n        overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode); \n        overflowSeg.putLong(\n                overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer); \n\n            \n        overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1);\n\n        if (checkForResize && !this.isResizing) {\n                \n            if (this.buckets.length <= getOverflowSegmentCount()) {\n                resizeHashTable();\n            }\n        }\n    }\n}", "summary_tokens": ["important", "we", "pass", "only", "the", "partition", "number", "because", "we", "must", "make", "sure", "we", "get", "a", "fresh", "partition", "reference"], "project": "flink"}
{"id": 5951, "code": "public boolean checkContainedObjectsReferentialEquality(\n        StateObjectCollection<?> a, StateObjectCollection<?> b) {\n\n    if (a == b) {\n        return true;\n    }\n\n    if (a == null || b == null) {\n        return false;\n    }\n\n    if (a.size() != b.size()) {\n        return false;\n    }\n\n    Iterator<?> bIter = b.iterator();\n    for (StateObject stateObject : a) {\n        if (!bIter.hasNext() || bIter.next() != stateObject) {\n            return false;\n        }\n    }\n    return true;\n}", "summary_tokens": ["returns", "true", "iff", "in", "iteration", "order", "all", "objects", "in", "the", "first", "collection", "are", "equal", "by", "reference", "to", "their", "corresponding", "object", "by", "order", "in", "the", "second", "collection", "and", "the", "size", "of", "the", "collections", "is", "equal"], "project": "flink"}
{"id": 2550, "code": "private static void validateDecodingFormatOptions(ReadableConfig tableOptions) {\n    JsonFormatOptionsUtil.validateDecodingFormatOptions(tableOptions);\n}", "summary_tokens": ["validator", "for", "debezium", "decoding", "format"], "project": "flink"}
{"id": 6965, "code": "public void setDbStoragePath(String path) {\n    setDbStoragePaths(path == null ? null : new String[] {path});\n}", "summary_tokens": ["sets", "the", "path", "where", "the", "rocks", "db", "local", "database", "files", "should", "be", "stored", "on", "the", "local", "file", "system"], "project": "flink"}
{"id": 8731, "code": "private boolean sameTypeOrNarrowsNullability(RelDataType oldType, RelDataType newType) {\n    return oldType.equals(newType)\n            || (SqlTypeUtil.equalSansNullability(rexBuilder.typeFactory, oldType, newType)\n                    && oldType.isNullable());\n}", "summary_tokens": ["return", "if", "the", "new", "type", "is", "the", "same", "and", "at", "most", "narrows", "the", "nullability"], "project": "flink"}
{"id": 5937, "code": "public void testClosingSchedulerShutsDownCheckpointCoordinatorOnSuspendedExecutionGraph()\n        throws Exception {\n    final CompletableFuture<JobStatus> counterShutdownFuture = new CompletableFuture<>();\n    CheckpointIDCounter counter = new TestingCheckpointIDCounter(counterShutdownFuture);\n\n    final CompletableFuture<JobStatus> storeShutdownFuture = new CompletableFuture<>();\n    CompletedCheckpointStore store = new TestingCompletedCheckpointStore(storeShutdownFuture);\n\n    final SchedulerBase scheduler = createSchedulerAndEnableCheckpointing(counter, store);\n    final ExecutionGraph graph = scheduler.getExecutionGraph();\n    final CheckpointCoordinator checkpointCoordinator = graph.getCheckpointCoordinator();\n\n    assertThat(checkpointCoordinator, Matchers.notNullValue());\n    assertThat(checkpointCoordinator.isShutdown(), is(false));\n\n    graph.suspend(new Exception(\"Test Exception\"));\n\n    scheduler.closeAsync().get();\n\n    assertThat(checkpointCoordinator.isShutdown(), is(true));\n    assertThat(counterShutdownFuture.get(), is(JobStatus.SUSPENDED));\n    assertThat(storeShutdownFuture.get(), is(JobStatus.SUSPENDED));\n}", "summary_tokens": ["tests", "that", "the", "checkpoint", "coordinator", "is", "shut", "down", "if", "the", "execution", "graph", "is", "suspended"], "project": "flink"}
{"id": 8161, "code": "public static TypeInformation<Boolean> BOOLEAN() {\n    return org.apache.flink.api.common.typeinfo.Types.BOOLEAN;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "boolean", "or", "sql", "boolean", "type"], "project": "flink"}
{"id": 6135, "code": "public void testOverprovisioned() throws IOException {\n        \n    int buffersToTakeFromPool1 = numBuffers / 2 + 1;\n        \n    int buffersToTakeFromPool2 = numBuffers - buffersToTakeFromPool1;\n\n    List<Buffer> buffers = new ArrayList<>(numBuffers);\n    BufferPool bufferPool1 = null, bufferPool2 = null;\n    try {\n        bufferPool1 = networkBufferPool.createBufferPool(buffersToTakeFromPool2, numBuffers);\n\n            \n        for (int i = 0; i < buffersToTakeFromPool1; ++i) {\n            Buffer buffer = bufferPool1.requestBuffer();\n            assertNotNull(buffer);\n            buffers.add(buffer);\n        }\n        assertEquals(buffersToTakeFromPool1, bufferPool1.bestEffortGetNumOfUsedBuffers());\n        assertEquals(numBuffers, bufferPool1.getNumBuffers());\n\n            \n        bufferPool2 = networkBufferPool.createBufferPool(buffersToTakeFromPool1, numBuffers);\n\n        assertEquals(\n                bufferPool2.getNumberOfRequiredMemorySegments(), bufferPool2.getNumBuffers());\n        assertEquals(\n                bufferPool1.getNumberOfRequiredMemorySegments(), bufferPool1.getNumBuffers());\n        assertNull(bufferPool1.requestBuffer());\n\n            \n        for (int i = 0; i < buffersToTakeFromPool2; ++i) {\n            Buffer buffer = bufferPool2.requestBuffer();\n            assertNotNull(buffer);\n            buffers.add(buffer);\n        }\n        assertEquals(buffersToTakeFromPool2, bufferPool2.bestEffortGetNumOfUsedBuffers());\n\n            \n            \n        assertNull(bufferPool2.requestBuffer());\n\n            \n            \n        buffers.remove(0).recycleBuffer();\n            \n            \n        assertEquals(0, networkBufferPool.getNumberOfAvailableMemorySegments());\n            \n        assertEquals(\n                buffersToTakeFromPool1 - 1,\n                bufferPool1.bestEffortGetNumOfUsedBuffers()\n                        + bufferPool1.getNumberOfAvailableMemorySegments());\n        assertEquals(\n                buffersToTakeFromPool2 + 1,\n                bufferPool2.bestEffortGetNumOfUsedBuffers()\n                        + bufferPool2.getNumberOfAvailableMemorySegments());\n    } finally {\n        for (Buffer buffer : buffers) {\n            buffer.recycleBuffer();\n        }\n        if (bufferPool1 != null) {\n            bufferPool1.lazyDestroy();\n        }\n        if (bufferPool2 != null) {\n            bufferPool2.lazyDestroy();\n        }\n    }\n}", "summary_tokens": ["tests", "creating", "two", "buffer", "pools", "which", "together", "require", "as", "many", "buffers", "as", "available", "but", "where", "there", "are", "less", "buffers", "available", "to", "the", "network", "buffer", "pool", "at", "the", "time", "of", "the", "second", "local", "buffer", "pool", "creation"], "project": "flink"}
{"id": 5370, "code": "private int buildHistogramByAccumulatingCounts() {\n    int sum = 0;\n    for (int i = 0; i < counterHistogram.length; ++i) {\n        int currentSlotValue = counterHistogram[i];\n        counterHistogram[i] = sum;\n        sum += currentSlotValue;\n    }\n    return sum;\n}", "summary_tokens": ["this", "method", "creates", "a", "histogram", "from", "the", "counts", "per", "key", "group", "in", "counter", "histogram"], "project": "flink"}
{"id": 2443, "code": "public static ConfluentRegistryAvroSerializationSchema<GenericRecord> forGeneric(\n        String subject,\n        Schema schema,\n        String schemaRegistryUrl,\n        @Nullable Map<String, ?> registryConfigs) {\n    return new ConfluentRegistryAvroSerializationSchema<>(\n            GenericRecord.class,\n            schema,\n            new CachedSchemaCoderProvider(\n                    subject,\n                    schemaRegistryUrl,\n                    DEFAULT_IDENTITY_MAP_CAPACITY,\n                    registryConfigs));\n}", "summary_tokens": ["creates", "avro", "serialization", "schema", "that", "produces", "byte", "arrays", "that", "were", "generated", "from", "avro", "schema", "and", "writes", "the", "writer", "schema", "to", "confluent", "schema", "registry"], "project": "flink"}
{"id": 8083, "code": "public boolean dropCatalogFunction(\n        UnresolvedIdentifier unresolvedIdentifier, boolean ignoreIfNotExist) {\n    final ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n    final ObjectIdentifier normalizedIdentifier =\n            FunctionIdentifier.normalizeObjectIdentifier(identifier);\n\n    final Catalog catalog =\n            catalogManager\n                    .getCatalog(normalizedIdentifier.getCatalogName())\n                    .orElseThrow(IllegalStateException::new);\n    final ObjectPath path = identifier.toObjectPath();\n\n        \n    if (tempCatalogFunctions.containsKey(normalizedIdentifier)) {\n        throw new ValidationException(\n                String.format(\n                        \"Could not drop catalog function. A temporary function '%s' does already exist. \"\n                                + \"Please drop the temporary function first.\",\n                        identifier.asSummaryString()));\n    }\n\n    if (!catalog.functionExists(path)) {\n        if (ignoreIfNotExist) {\n            return false;\n        }\n        throw new ValidationException(\n                String.format(\n                        \"Could not drop catalog function. A function '%s' doesn't exist.\",\n                        identifier.asSummaryString()));\n    }\n\n    try {\n        catalog.dropFunction(path, ignoreIfNotExist);\n    } catch (Throwable t) {\n        throw new TableException(\n                String.format(\n                        \"Could not drop catalog function '%s'.\", identifier.asSummaryString()),\n                t);\n    }\n    return true;\n}", "summary_tokens": ["drops", "a", "catalog", "function", "by", "also", "considering", "temporary", "catalog", "functions"], "project": "flink"}
{"id": 1671, "code": "private static String keyWithResourceNameAndSuffix(String resourceName, String suffix) {\n    return String.format(\n            \"%s.%s.%s\",\n            EXTERNAL_RESOURCE_PREFIX,\n            Preconditions.checkNotNull(resourceName),\n            Preconditions.checkNotNull(suffix));\n}", "summary_tokens": ["generate", "the", "config", "option", "key", "with", "resource", "name", "and", "suffix"], "project": "flink"}
{"id": 2765, "code": "public WorksetPlaceHolder<WT> getWorkset() {\n    return worksetPlaceholder;\n}", "summary_tokens": ["gets", "the", "working", "set", "of", "the", "delta", "iteration"], "project": "flink"}
{"id": 4643, "code": "public T poll() {\n    final T polled = deque.poll();\n    if (polled != null && numPriorityElements > 0) {\n        numPriorityElements--;\n    }\n    return polled;\n}", "summary_tokens": ["polls", "the", "first", "priority", "element", "or", "non", "priority", "element", "if", "the", "former", "does", "not", "exist"], "project": "flink"}
{"id": 7562, "code": "private <IN, OUT> WatermarkGaugeExposingOutput<StreamRecord<IN>> createOperatorChain(\n        StreamTask<OUT, ?> containingTask,\n        StreamConfig operatorConfig,\n        Map<Integer, StreamConfig> chainedConfigs,\n        ClassLoader userCodeClassloader,\n        Map<StreamEdge, RecordWriterOutput<?>> streamOutputs,\n        List<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n        OutputTag<IN> outputTag,\n        MailboxExecutorFactory mailboxExecutorFactory) {\n        \n        \n    WatermarkGaugeExposingOutput<StreamRecord<OUT>> chainedOperatorOutput =\n            createOutputCollector(\n                    containingTask,\n                    operatorConfig,\n                    chainedConfigs,\n                    userCodeClassloader,\n                    streamOutputs,\n                    allOperatorWrappers,\n                    mailboxExecutorFactory);\n\n    OneInputStreamOperator<IN, OUT> chainedOperator =\n            createOperator(\n                    containingTask,\n                    operatorConfig,\n                    userCodeClassloader,\n                    chainedOperatorOutput,\n                    allOperatorWrappers,\n                    false);\n\n    return wrapOperatorIntoOutput(\n            chainedOperator, containingTask, operatorConfig, userCodeClassloader, outputTag);\n}", "summary_tokens": ["recursively", "create", "chain", "of", "operators", "that", "starts", "from", "the", "given", "operator", "config"], "project": "flink"}
{"id": 1042, "code": "public int getParallelism() {\n    return parallelism;\n}", "summary_tokens": ["gets", "the", "parallelism", "with", "which", "operation", "are", "executed", "by", "default"], "project": "flink"}
{"id": 3656, "code": "public Ordering getOrdering() {\n    return ordering;\n}", "summary_tokens": ["gets", "the", "key", "order"], "project": "flink"}
{"id": 3458, "code": "public <T> DataSource<T> readUnionState(\n        String uid, String name, TypeInformation<T> typeInfo, TypeSerializer<T> serializer)\n        throws IOException {\n\n    OperatorState operatorState = metadata.getOperatorState(uid);\n    ListStateDescriptor<T> descriptor = new ListStateDescriptor<>(name, serializer);\n    UnionStateInputFormat<T> inputFormat =\n            new UnionStateInputFormat<>(operatorState, descriptor);\n    return env.createInput(inputFormat, typeInfo);\n}", "summary_tokens": ["read", "operator", "union", "state", "from", "a", "savepoint", "when", "a", "custom", "serializer", "was", "used", "e"], "project": "flink"}
{"id": 5405, "code": "public RegisteredOperatorStateBackendMetaInfo<S> deepCopy() {\n    return new RegisteredOperatorStateBackendMetaInfo<>(this);\n}", "summary_tokens": ["creates", "a", "deep", "copy", "of", "the", "itself"], "project": "flink"}
{"id": 6093, "code": "public void testHeartbeatManagerTargetPayload() throws Exception {\n    final long heartbeatTimeout = 100L;\n\n    final ResourceID someTargetId = ResourceID.generate();\n    final ResourceID specialTargetId = ResourceID.generate();\n\n    final Map<ResourceID, Integer> payloads = new HashMap<>(2);\n    payloads.put(someTargetId, 0);\n    payloads.put(specialTargetId, 1);\n\n    final CompletableFuture<Integer> someHeartbeatPayloadFuture = new CompletableFuture<>();\n    final TestingHeartbeatTarget<Integer> someHeartbeatTarget =\n            new TestingHeartbeatTargetBuilder<Integer>()\n                    .setReceiveHeartbeatFunction(\n                            (ignored, payload) -> {\n                                someHeartbeatPayloadFuture.complete(payload);\n                                return FutureUtils.completedVoidFuture();\n                            })\n                    .createTestingHeartbeatTarget();\n\n    final CompletableFuture<Integer> specialHeartbeatPayloadFuture = new CompletableFuture<>();\n    final TestingHeartbeatTarget<Integer> specialHeartbeatTarget =\n            new TestingHeartbeatTargetBuilder<Integer>()\n                    .setReceiveHeartbeatFunction(\n                            (ignored, payload) -> {\n                                specialHeartbeatPayloadFuture.complete(payload);\n                                return FutureUtils.completedVoidFuture();\n                            })\n                    .createTestingHeartbeatTarget();\n\n    final TestingHeartbeatListener<Void, Integer> testingHeartbeatListener =\n            new TestingHeartbeatListenerBuilder<Void, Integer>()\n                    .setRetrievePayloadFunction(payloads::get)\n                    .createNewTestingHeartbeatListener();\n\n    HeartbeatManager<?, Integer> heartbeatManager =\n            new HeartbeatManagerImpl<>(\n                    heartbeatTimeout,\n                    FAILED_RPC_THRESHOLD,\n                    ResourceID.generate(),\n                    testingHeartbeatListener,\n                    TestingUtils.defaultScheduledExecutor(),\n                    LOG);\n\n    try {\n        heartbeatManager.monitorTarget(someTargetId, someHeartbeatTarget);\n        heartbeatManager.monitorTarget(specialTargetId, specialHeartbeatTarget);\n\n        heartbeatManager.requestHeartbeat(someTargetId, null);\n        assertThat(someHeartbeatPayloadFuture.get(), is(payloads.get(someTargetId)));\n\n        heartbeatManager.requestHeartbeat(specialTargetId, null);\n        assertThat(specialHeartbeatPayloadFuture.get(), is(payloads.get(specialTargetId)));\n    } finally {\n        heartbeatManager.stop();\n    }\n}", "summary_tokens": ["tests", "that", "the", "heartbeat", "target", "resource", "id", "is", "properly", "passed", "to", "the", "heartbeat", "listener", "by", "the", "heartbeat", "manager", "impl"], "project": "flink"}
{"id": 7465, "code": "public static Time minutes(long minutes) {\n    return of(minutes, TimeUnit.MINUTES);\n}", "summary_tokens": ["creates", "a", "new", "time", "that", "represents", "the", "given", "number", "of", "minutes"], "project": "flink"}
{"id": 1666, "code": "public static ConfigOption<Integer> fileSystemConnectionLimit(String scheme) {\n    return ConfigOptions.key(\"fs.\" + scheme + \".limit.total\").defaultValue(-1);\n}", "summary_tokens": ["the", "total", "number", "of", "input", "plus", "output", "connections", "that", "a", "file", "system", "for", "the", "given", "scheme", "may", "open"], "project": "flink"}
{"id": 8753, "code": "protected SqlSelect createSourceSelectForDelete(SqlDelete call) {\n    final SqlNodeList selectList = new SqlNodeList(SqlParserPos.ZERO);\n    selectList.add(SqlIdentifier.star(SqlParserPos.ZERO));\n    SqlNode sourceTable = call.getTargetTable();\n    if (call.getAlias() != null) {\n        sourceTable = SqlValidatorUtil.addAlias(sourceTable, call.getAlias().getSimple());\n    }\n    return new SqlSelect(\n            SqlParserPos.ZERO,\n            null,\n            selectList,\n            sourceTable,\n            call.getCondition(),\n            null,\n            null,\n            null,\n            null,\n            null,\n            null,\n            null);\n}", "summary_tokens": ["creates", "the", "select", "statement", "that", "putatively", "feeds", "rows", "into", "a", "delete", "statement", "to", "be", "deleted"], "project": "flink"}
{"id": 4194, "code": "void incrementRestoredCheckpoints() {\n    numRestoredCheckpoints++;\n}", "summary_tokens": ["increments", "the", "number", "of", "restored", "checkpoints"], "project": "flink"}
{"id": 3256, "code": "public DataSet<Vertex<KB, VVB>> getBottomVertices() {\n    return bottomVertices;\n}", "summary_tokens": ["get", "dataset", "with", "bottom", "vertices"], "project": "flink"}
{"id": 6775, "code": "byte[] serialize(K key, N namespace) {\n        \n        \n    return serializeToSegment(key, namespace).getArray();\n}", "summary_tokens": ["serialize", "the", "key", "and", "namespace", "to", "bytes"], "project": "flink"}
{"id": 8383, "code": "public Rowtime timestampsFromField(String fieldName) {\n    internalProperties.putString(\n            ROWTIME_TIMESTAMPS_TYPE, ROWTIME_TIMESTAMPS_TYPE_VALUE_FROM_FIELD);\n    internalProperties.putString(ROWTIME_TIMESTAMPS_FROM, fieldName);\n    return this;\n}", "summary_tokens": ["sets", "a", "built", "in", "timestamp", "extractor", "that", "converts", "an", "existing", "long", "or", "types", "sql", "timestamp", "field", "into", "the", "rowtime", "attribute"], "project": "flink"}
{"id": 4912, "code": "public void runDetached(JobGraph job) throws JobExecutionException, InterruptedException {\n    checkNotNull(job, \"job is null\");\n\n    final CompletableFuture<JobSubmissionResult> submissionFuture = submitJob(job);\n\n    try {\n        submissionFuture.get();\n    } catch (ExecutionException e) {\n        throw new JobExecutionException(\n                job.getJobID(), ExceptionUtils.stripExecutionException(e));\n    }\n}", "summary_tokens": ["this", "method", "executes", "a", "job", "in", "detached", "mode"], "project": "flink"}
{"id": 4050, "code": "public CompletableFuture<Void> getTerminationFuture() {\n    return rpcServer.getTerminationFuture();\n}", "summary_tokens": ["return", "a", "future", "which", "is", "completed", "with", "true", "when", "the", "rpc", "endpoint", "has", "been", "terminated"], "project": "flink"}
{"id": 2871, "code": "public static <T> DataSet<T> sampleWithSize(\n        DataSet<T> input,\n        final boolean withReplacement,\n        final int numSamples,\n        final long seed) {\n\n    SampleInPartition<T> sampleInPartition =\n            new SampleInPartition<>(withReplacement, numSamples, seed);\n    MapPartitionOperator mapPartitionOperator = input.mapPartition(sampleInPartition);\n\n        \n    String callLocation = Utils.getCallLocationName();\n    SampleInCoordinator<T> sampleInCoordinator =\n            new SampleInCoordinator<>(withReplacement, numSamples, seed);\n    return new GroupReduceOperator<>(\n            mapPartitionOperator, input.getType(), sampleInCoordinator, callLocation);\n}", "summary_tokens": ["generate", "a", "sample", "of", "data", "set", "which", "contains", "fixed", "size", "elements"], "project": "flink"}
{"id": 201, "code": "default void close() throws Exception {}", "summary_tokens": ["tear", "down", "method", "for", "the", "function"], "project": "flink"}
{"id": 2749, "code": "public Partitioner<?> getPartitioner() {\n    return customPartitioner;\n}", "summary_tokens": ["gets", "the", "custom", "partitioner", "used", "by", "this", "join", "or", "null", "if", "none", "is", "set"], "project": "flink"}
{"id": 1525, "code": "public static <\n                T0,\n                T1,\n                T2,\n                T3,\n                T4,\n                T5,\n                T6,\n                T7,\n                T8,\n                T9,\n                T10,\n                T11,\n                T12,\n                T13,\n                T14,\n                T15,\n                T16,\n                T17,\n                T18,\n                T19,\n                T20,\n                T21,\n                T22,\n                T23>\n        Tuple24<\n                        T0,\n                        T1,\n                        T2,\n                        T3,\n                        T4,\n                        T5,\n                        T6,\n                        T7,\n                        T8,\n                        T9,\n                        T10,\n                        T11,\n                        T12,\n                        T13,\n                        T14,\n                        T15,\n                        T16,\n                        T17,\n                        T18,\n                        T19,\n                        T20,\n                        T21,\n                        T22,\n                        T23>\n                of(\n                        T0 f0,\n                        T1 f1,\n                        T2 f2,\n                        T3 f3,\n                        T4 f4,\n                        T5 f5,\n                        T6 f6,\n                        T7 f7,\n                        T8 f8,\n                        T9 f9,\n                        T10 f10,\n                        T11 f11,\n                        T12 f12,\n                        T13 f13,\n                        T14 f14,\n                        T15 f15,\n                        T16 f16,\n                        T17 f17,\n                        T18 f18,\n                        T19 f19,\n                        T20 f20,\n                        T21 f21,\n                        T22 f22,\n                        T23 f23) {\n    return new Tuple24<>(\n            f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17, f18,\n            f19, f20, f21, f22, f23);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 8214, "code": "default TableSchema getSchema() {\n    return null;\n}", "summary_tokens": ["this", "method", "returns", "the", "deprecated", "table", "schema", "class"], "project": "flink"}
{"id": 9684, "code": "private boolean isTriggered(long globalWatermark) {\n    return globalWatermark >= maxTimestamp + getGap() - 1;\n}", "summary_tokens": ["global", "watermark", "the", "current", "global", "watermark", "true", "if", "the", "session", "window", "for", "this", "session", "has", "already", "triggered", "at", "global", "watermark"], "project": "flink"}
{"id": 6536, "code": "public void testTransitionToCreatingExecutionGraph() throws Exception {\n    try (MockContext ctx = new MockContext()) {\n        ctx.setHasDesiredResources(() -> true);\n\n        ctx.setExpectCreatingExecutionGraph();\n\n        new WaitingForResources(\n                ctx, log, RESOURCE_COUNTER, Duration.ZERO, STABILIZATION_TIMEOUT);\n\n        ctx.runScheduledTasks();\n    }\n}", "summary_tokens": ["waiting", "for", "resources", "is", "transitioning", "to", "executing", "if", "there", "are", "enough", "resources"], "project": "flink"}
{"id": 8217, "code": "static CatalogTable of(\n        Schema schema,\n        @Nullable String comment,\n        List<String> partitionKeys,\n        Map<String, String> options) {\n    return new DefaultCatalogTable(schema, comment, partitionKeys, options);\n}", "summary_tokens": ["creates", "a", "basic", "implementation", "of", "this", "interface"], "project": "flink"}
{"id": 1851, "code": "public static NullValue getInstance() {\n    return INSTANCE;\n}", "summary_tokens": ["returns", "the", "null", "value", "singleton", "instance"], "project": "flink"}
{"id": 8796, "code": "private void findCorrelationEquivalent(CorRef correlation, RexNode e) throws Util.FoundOne {\n    switch (e.getKind()) {\n        case EQUALS:\n            final RexCall call = (RexCall) e;\n            final List<RexNode> operands = call.getOperands();\n            if (references(operands.get(0), correlation)) {\n                throw new Util.FoundOne(operands.get(1));\n            }\n            if (references(operands.get(1), correlation)) {\n                throw new Util.FoundOne(operands.get(0));\n            }\n            break;\n        case AND:\n            for (RexNode operand : ((RexCall) e).getOperands()) {\n                findCorrelationEquivalent(correlation, operand);\n            }\n    }\n}", "summary_tokens": ["finds", "a", "rex", "input", "ref", "that", "is", "equivalent", "to", "a", "cor", "ref", "and", "if", "found", "throws", "a", "org"], "project": "flink"}
{"id": 9623, "code": "public void testPortForwarding() throws Exception {\n    String host = \"fakeHost\";\n    int port = 99;\n    JobID jobId = new JobID();\n\n    final Configuration clientConfiguration = new Configuration();\n    TestExecutorServiceLoader testExecutorServiceLoader = new TestExecutorServiceLoader(jobId);\n    final StreamExecutionEnvironment env =\n            new RemoteStreamEnvironment(\n                    testExecutorServiceLoader,\n                    host,\n                    port,\n                    clientConfiguration,\n                    null,\n                    null,\n                    null);\n    env.fromElements(1).map(x -> x * 2);\n\n    JobExecutionResult actualResult = env.execute(\"fakeJobName\");\n    TestClusterClient testClient = testExecutorServiceLoader.getCreatedClusterClient();\n    assertThat(actualResult.getJobID(), is(jobId));\n    assertThat(testClient.getConfiguration().getString(RestOptions.ADDRESS), is(host));\n    assertThat(testClient.getConfiguration().getInteger(RestOptions.PORT), is(99));\n}", "summary_tokens": ["verifies", "that", "the", "port", "passed", "to", "the", "remote", "stream", "environment", "is", "used", "for", "connecting", "to", "the", "cluster"], "project": "flink"}
{"id": 586, "code": "private List<KafkaTopicPartitionState<T, KPH>> createPartitionStateHolders(\n        List<KafkaTopicPartition> partitions,\n        long initialOffset,\n        int timestampWatermarkMode,\n        SerializedValue<WatermarkStrategy<T>> watermarkStrategy,\n        ClassLoader userCodeClassLoader)\n        throws IOException, ClassNotFoundException {\n\n    Map<KafkaTopicPartition, Long> partitionsToInitialOffset = new HashMap<>(partitions.size());\n    for (KafkaTopicPartition partition : partitions) {\n        partitionsToInitialOffset.put(partition, initialOffset);\n    }\n\n    return createPartitionStateHolders(\n            partitionsToInitialOffset,\n            timestampWatermarkMode,\n            watermarkStrategy,\n            userCodeClassLoader);\n}", "summary_tokens": ["shortcut", "variant", "of", "create", "partition", "state", "holders", "map", "int", "serialized", "value", "class", "loader", "that", "uses", "the", "same", "offset", "for", "all", "partitions", "when", "creating", "their", "state", "holders"], "project": "flink"}
{"id": 8502, "code": "default TypeInformation<T> getReturnType() {\n    return null;\n}", "summary_tokens": ["this", "method", "will", "be", "removed", "in", "future", "versions", "as", "it", "uses", "the", "old", "type", "system"], "project": "flink"}
{"id": 7643, "code": "public void testExchangeModeBatch() {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setBufferTimeout(-1);\n        \n    DataStream<Integer> sourceDataStream = env.fromElements(1, 2, 3);\n\n    DataStream<Integer> partitionAfterSourceDataStream =\n            new DataStream<>(\n                    env,\n                    new PartitionTransformation<>(\n                            sourceDataStream.getTransformation(),\n                            new ForwardPartitioner<>(),\n                            StreamExchangeMode.BATCH));\n    DataStream<Integer> mapDataStream =\n            partitionAfterSourceDataStream.map(value -> value).setParallelism(1);\n\n    DataStream<Integer> partitionAfterMapDataStream =\n            new DataStream<>(\n                    env,\n                    new PartitionTransformation<>(\n                            mapDataStream.getTransformation(),\n                            new RescalePartitioner<>(),\n                            StreamExchangeMode.BATCH));\n    partitionAfterMapDataStream.print().setParallelism(2);\n\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\n    List<JobVertex> verticesSorted = jobGraph.getVerticesSortedTopologicallyFromSources();\n    assertEquals(3, verticesSorted.size());\n\n        \n    JobVertex sourceVertex = verticesSorted.get(0);\n    JobVertex mapVertex = verticesSorted.get(1);\n\n        \n    assertEquals(\n            ResultPartitionType.BLOCKING,\n            sourceVertex.getProducedDataSets().get(0).getResultType());\n    assertEquals(\n            ResultPartitionType.BLOCKING,\n            mapVertex.getProducedDataSets().get(0).getResultType());\n}", "summary_tokens": ["test", "setting", "exchange", "mode", "to", "stream", "exchange", "mode", "batch"], "project": "flink"}
{"id": 9758, "code": "private static void testCopySymbolicPathFromLocal(\n        FileSystem targetFileSystem,\n        Path targetDir,\n        String localResourceDirectory,\n        TemporaryFolder temporaryFolder)\n        throws IOException, InterruptedException, URISyntaxException {\n\n    final File srcDir = temporaryFolder.newFolder();\n    final String srcPath = srcDir.getAbsolutePath();\n\n    final String localSymbolicFile = \"local.lnk\";\n\n    final HashMap<String ,  String> srcFiles =\n            new HashMap<>(4);\n    srcFiles.put(\"1\", \"Hello file\");\n    srcFiles.put(\"nested/local.jar\", \"Local Jar Content\");\n\n    generateFilesInDirectory(srcDir, srcFiles);\n\n    Files.createSymbolicLink(\n            Paths.get(srcPath, localSymbolicFile), Paths.get(srcPath, \"nested\"));\n\n    try {\n        final List<Path> remotePaths = new ArrayList<>();\n\n        final ApplicationId applicationId = ApplicationId.newInstance(0, 0);\n        final YarnApplicationFileUploader uploader =\n                YarnApplicationFileUploader.from(\n                        targetFileSystem,\n                        targetDir,\n                        Collections.emptyList(),\n                        applicationId,\n                        DFSConfigKeys.DFS_REPLICATION_DEFAULT);\n\n        final List<String> classpath =\n                uploader.registerMultipleLocalResources(\n                        Lists.newArrayList(\n                                new Path(srcPath, localSymbolicFile), new Path(srcPath, \"1\")),\n                        localResourceDirectory,\n                        LocalResourceType.FILE);\n\n            \n        assertThat(\n                classpath,\n                containsInAnyOrder(\n                        new Path(localResourceDirectory).toString(),\n                        new Path(localResourceDirectory, \"nested/local.jar\").toString()));\n\n        final Map<String, LocalResource> localResources =\n                uploader.getRegisteredLocalResources();\n        final Path workDir =\n                ConverterUtils.getPathFromYarnURL(\n                                localResources\n                                        .get(new Path(localResourceDirectory, \"1\").toString())\n                                        .getResource())\n                        .getParent();\n        verifyDirectoryRecursive(targetFileSystem, workDir, srcFiles);\n    } finally {\n        targetFileSystem.delete(targetDir, true);\n    }\n}", "summary_tokens": ["verifies", "that", "a", "symbolic", "path", "is", "properly", "uploaded"], "project": "flink"}
{"id": 5642, "code": "public static long getMaxJvmHeapMemory() {\n    final long maxMemory = Runtime.getRuntime().maxMemory();\n    if (maxMemory != Long.MAX_VALUE) {\n            \n        return maxMemory;\n    } else {\n            \n        final long physicalMemory = Hardware.getSizeOfPhysicalMemory();\n        if (physicalMemory != -1) {\n                \n            return physicalMemory / 4;\n        } else {\n            throw new RuntimeException(\n                    \"Could not determine the amount of free memory.\\n\"\n                            + \"Please set the maximum memory for the JVM, e.g. -Xmx512M for 512 megabytes.\");\n        }\n    }\n}", "summary_tokens": ["the", "maximum", "jvm", "heap", "size", "in", "bytes"], "project": "flink"}
{"id": 5226, "code": "public String pattern() {\n    return pattern;\n}", "summary_tokens": ["returns", "the", "pattern", "given", "at", "the", "constructor", "without", "slashes", "at", "both", "ends"], "project": "flink"}
{"id": 7, "code": "public static GivenClassesConjunction noJavaClassesThat(\n        DescribedPredicate<JavaClass> predicate) {\n    return noClasses().that(areJavaClasses()).and(predicate);\n}", "summary_tokens": ["equivalent", "of", "arch", "rule", "definition", "no", "classes", "but", "only", "for", "java", "classes"], "project": "flink"}
{"id": 2222, "code": "private void verifyDirectoryCompression(\n        final java.nio.file.Path testDir, final java.nio.file.Path compressDir)\n        throws IOException {\n    final String testFileContent =\n            \"Goethe - Faust: Der Tragoedie erster Teil\\n\"\n                    + \"Prolog im Himmel.\\n\"\n                    + \"Der Herr. Die himmlischen Heerscharen. Nachher Mephistopheles. Die drei\\n\"\n                    + \"Erzengel treten vor.\\n\"\n                    + \"RAPHAEL: Die Sonne toent, nach alter Weise, In Brudersphaeren Wettgesang,\\n\"\n                    + \"Und ihre vorgeschriebne Reise Vollendet sie mit Donnergang. Ihr Anblick\\n\"\n                    + \"gibt den Engeln Staerke, Wenn keiner Sie ergruenden mag; die unbegreiflich\\n\"\n                    + \"hohen Werke Sind herrlich wie am ersten Tag.\\n\"\n                    + \"GABRIEL: Und schnell und unbegreiflich schnelle Dreht sich umher der Erde\\n\"\n                    + \"Pracht; Es wechselt Paradieseshelle Mit tiefer, schauervoller Nacht. Es\\n\"\n                    + \"schaeumt das Meer in breiten Fluessen Am tiefen Grund der Felsen auf, Und\\n\"\n                    + \"Fels und Meer wird fortgerissen Im ewig schnellem Sphaerenlauf.\\n\"\n                    + \"MICHAEL: Und Stuerme brausen um die Wette Vom Meer aufs Land, vom Land\\n\"\n                    + \"aufs Meer, und bilden wuetend eine Kette Der tiefsten Wirkung rings umher.\\n\"\n                    + \"Da flammt ein blitzendes Verheeren Dem Pfade vor des Donnerschlags. Doch\\n\"\n                    + \"deine Boten, Herr, verehren Das sanfte Wandeln deines Tags.\";\n\n    final java.nio.file.Path extractDir = tmp.newFolder(\"extractDir\").toPath();\n\n    final java.nio.file.Path originalDir = Paths.get(\"rootDir\");\n    final java.nio.file.Path emptySubDir = originalDir.resolve(\"emptyDir\");\n    final java.nio.file.Path fullSubDir = originalDir.resolve(\"fullDir\");\n    final java.nio.file.Path file1 = originalDir.resolve(\"file1\");\n    final java.nio.file.Path file2 = originalDir.resolve(\"file2\");\n    final java.nio.file.Path file3 = fullSubDir.resolve(\"file3\");\n\n    Files.createDirectory(testDir.resolve(originalDir));\n    Files.createDirectory(testDir.resolve(emptySubDir));\n    Files.createDirectory(testDir.resolve(fullSubDir));\n    Files.copy(\n            new ByteArrayInputStream(testFileContent.getBytes(StandardCharsets.UTF_8)),\n            testDir.resolve(file1));\n    Files.createFile(testDir.resolve(file2));\n    Files.copy(\n            new ByteArrayInputStream(testFileContent.getBytes(StandardCharsets.UTF_8)),\n            testDir.resolve(file3));\n\n    final Path zip =\n            FileUtils.compressDirectory(\n                    new Path(compressDir.resolve(originalDir).toString()),\n                    new Path(compressDir.resolve(originalDir) + \".zip\"));\n\n    FileUtils.expandDirectory(zip, new Path(extractDir.toAbsolutePath().toString()));\n\n    assertDirEquals(compressDir.resolve(originalDir), extractDir.resolve(originalDir));\n}", "summary_tokens": ["generate", "some", "directories", "in", "a", "original", "directory", "based", "on", "the", "test", "dir"], "project": "flink"}
{"id": 8714, "code": "public Object getValue3() {\n    if (value == null) {\n        return null;\n    }\n    switch (typeName) {\n        case DECIMAL:\n            assert value instanceof BigDecimal;\n            return value;\n        default:\n            return getValue2();\n    }\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "literal", "in", "the", "form", "that", "the", "rex", "to", "lix", "translator", "wants", "it"], "project": "flink"}
{"id": 9719, "code": "Map<String, Long> getExternalResourcesUnSafe(Object resource) {\n    if (!isYarnResourceTypesAvailable) {\n        return Collections.emptyMap();\n    }\n\n    final Map<String, Long> externalResources = new HashMap<>();\n    final Object[] externalResourcesInfo;\n    try {\n        externalResourcesInfo = (Object[]) resourceGetResourcesMethod.invoke(resource);\n            \n        for (int i = 2; i < externalResourcesInfo.length; i++) {\n            final String name =\n                    (String) resourceInformationGetNameMethod.invoke(externalResourcesInfo[i]);\n            final long value =\n                    (long) resourceInformationGetValueMethod.invoke(externalResourcesInfo[i]);\n            externalResources.put(name, value);\n        }\n    } catch (Exception e) {\n        LOG.warn(\"Could not obtain the external resources supported by the given Resource.\", e);\n        return Collections.emptyMap();\n    }\n    return externalResources;\n}", "summary_tokens": ["same", "as", "get", "external", "resources", "resource", "but", "allows", "to", "pass", "objects", "that", "are", "not", "of", "type", "resource"], "project": "flink"}
{"id": 8342, "code": "public static TimestampData readTimestampData(\n        MemorySegment[] segments, int baseOffset, long offsetAndNanos) {\n    final int nanoOfMillisecond = (int) offsetAndNanos;\n    final int subOffset = (int) (offsetAndNanos >> 32);\n    final long millisecond = getLong(segments, baseOffset + subOffset);\n    return TimestampData.fromEpochMillis(millisecond, nanoOfMillisecond);\n}", "summary_tokens": ["gets", "an", "instance", "of", "timestamp", "data", "from", "underlying", "memory", "segment"], "project": "flink"}
{"id": 4490, "code": "public int getBlockCount() {\n    return numBlocksWritten;\n}", "summary_tokens": ["gets", "the", "number", "of", "blocks", "written", "by", "this", "output", "view"], "project": "flink"}
{"id": 274, "code": "protected void commitUpToCheckpoint(long checkpointId) throws Exception {\n    helper.commitUpToCheckpoint(checkpointId);\n}", "summary_tokens": ["commit", "up", "to", "this", "checkpoint", "id"], "project": "flink"}
{"id": 8675, "code": "public static String generateRuntimeName(Class<?> clazz, String[] fields) {\n    String className = clazz.getSimpleName();\n    if (null == fields) {\n        return className + \"(*)\";\n    } else {\n        return className + \"(\" + String.join(\", \", fields) + \")\";\n    }\n}", "summary_tokens": ["returns", "the", "table", "connector", "name", "used", "for", "logging", "and", "web", "ui"], "project": "flink"}
{"id": 2095, "code": "public static <T> void completeDelayed(CompletableFuture<T> future, T success, Duration delay) {\n    Delayer.delay(() -> future.complete(success), delay.toMillis(), TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["asynchronously", "completes", "the", "future", "after", "a", "certain", "delay"], "project": "flink"}
{"id": 1645, "code": "public byte[] getBytes(String key, byte[] defaultValue) {\n    return getRawValue(key)\n            .map(\n                    o -> {\n                        if (o.getClass().equals(byte[].class)) {\n                            return (byte[]) o;\n                        } else {\n                            throw new IllegalArgumentException(\n                                    String.format(\n                                            \"Configuration cannot evaluate value %s as a byte[] value\",\n                                            o));\n                        }\n                    })\n            .orElse(defaultValue);\n}", "summary_tokens": ["returns", "the", "value", "associated", "with", "the", "given", "key", "as", "a", "byte", "array"], "project": "flink"}
{"id": 7898, "code": "public void testNoOutputWhenAllActiveChannelsAreUnaligned() throws Exception {\n    StatusWatermarkOutput valveOutput = new StatusWatermarkOutput();\n    StatusWatermarkValve valve = new StatusWatermarkValve(3);\n\n    valve.inputWatermark(new Watermark(10), 0, valveOutput);\n    valve.inputWatermark(new Watermark(7), 1, valveOutput);\n\n        \n    valve.inputWatermarkStatus(WatermarkStatus.IDLE, 2, valveOutput);\n    assertEquals(new Watermark(7), valveOutput.popLastSeenOutput());\n    assertEquals(null, valveOutput.popLastSeenOutput());\n\n        \n    valve.inputWatermarkStatus(WatermarkStatus.ACTIVE, 2, valveOutput);\n    assertEquals(null, valveOutput.popLastSeenOutput());\n\n        \n    valve.inputWatermarkStatus(WatermarkStatus.IDLE, 0, valveOutput);\n    valve.inputWatermarkStatus(WatermarkStatus.IDLE, 1, valveOutput);\n\n        \n    assertEquals(null, valveOutput.popLastSeenOutput());\n}", "summary_tokens": ["verify", "that", "we", "don", "t", "see", "any", "state", "changes", "watermarks", "when", "all", "active", "channels", "are", "unaligned"], "project": "flink"}
{"id": 2568, "code": "static OrcShim<VectorizedRowBatch> defaultShim() {\n    return new OrcShimV230();\n}", "summary_tokens": ["default", "with", "orc", "dependent", "we", "should", "use", "v", "0"], "project": "flink"}
{"id": 476, "code": "static XaFacade fromXaDataSourceSupplier(\n        Supplier<XADataSource> dataSourceSupplier,\n        Integer timeoutSec,\n        boolean transactionPerConnection) {\n    return transactionPerConnection\n            ? new XaFacadePoolingImpl(() -> new XaFacadeImpl(dataSourceSupplier, timeoutSec))\n            : new XaFacadeImpl(dataSourceSupplier, timeoutSec);\n}", "summary_tokens": ["a", "non", "serializable", "instance"], "project": "flink"}
{"id": 7025, "code": "public SingleOutputStreamOperator<T> sum(String field) {\n    return aggregate(new SumAggregator<>(field, input.getType(), input.getExecutionConfig()));\n}", "summary_tokens": ["applies", "an", "aggregation", "that", "sums", "every", "window", "of", "the", "pojo", "data", "stream", "at", "the", "given", "field", "for", "every", "window"], "project": "flink"}
{"id": 362, "code": "public HiveParserTypeCheckProcFactory.IntervalExprProcessor getIntervalExprProcessor() {\n    return new HiveParserTypeCheckProcFactory.IntervalExprProcessor();\n}", "summary_tokens": ["factory", "method", "to", "get", "interval", "expr", "processor"], "project": "flink"}
{"id": 9274, "code": "protected void writeIndexAndNormalizedKey(RowData record, long currOffset) {\n        \n    this.currentSortIndexSegment.putLong(this.currentSortIndexOffset, currOffset);\n\n    if (this.numKeyBytes != 0) {\n        normalizedKeyComputer.putKey(\n                record, this.currentSortIndexSegment, this.currentSortIndexOffset + OFFSET_LEN);\n    }\n\n    this.currentSortIndexOffset += this.indexEntrySize;\n    this.numRecords++;\n}", "summary_tokens": ["write", "of", "index", "and", "normalized", "key"], "project": "flink"}
{"id": 9501, "code": "public static ThrowingConsumer<? extends Throwable> anyCauseMatches(String containsMessage) {\n    return t ->\n            assertThatChainOfCauses(t)\n                    .anySatisfy(t1 -> assertThat(t1).hasMessageContaining(containsMessage));\n}", "summary_tokens": ["shorthand", "to", "assert", "the", "chain", "of", "causes", "includes", "a", "throwable", "matching", "a", "specific", "class", "and", "containing", "the", "provided", "message"], "project": "flink"}
{"id": 5180, "code": "public Path getUploadDir() {\n    return uploadDir;\n}", "summary_tokens": ["returns", "the", "directory", "used", "to", "temporarily", "store", "multipart", "form", "data", "uploads"], "project": "flink"}
{"id": 5692, "code": "public static ZooKeeperCheckpointIDCounter createCheckpointIDCounter(CuratorFramework client) {\n    return new ZooKeeperCheckpointIDCounter(\n            client, new DefaultLastStateConnectionStateListener());\n}", "summary_tokens": ["creates", "a", "zoo", "keeper", "checkpoint", "idcounter", "instance"], "project": "flink"}
{"id": 4304, "code": "public OperatorSubtaskState putSubtaskStateByOperatorID(\n        @Nonnull OperatorID operatorID, @Nonnull OperatorSubtaskState state) {\n\n    return subtaskStatesByOperatorID.put(operatorID, Preconditions.checkNotNull(state));\n}", "summary_tokens": ["maps", "the", "given", "operator", "id", "to", "the", "given", "subtask", "state"], "project": "flink"}
{"id": 7893, "code": "public void testMultipleInputWatermarkStatusToggling() throws Exception {\n    StatusWatermarkOutput valveOutput = new StatusWatermarkOutput();\n    StatusWatermarkValve valve = new StatusWatermarkValve(2);\n\n        \n    valve.inputWatermarkStatus(WatermarkStatus.ACTIVE, 0, valveOutput);\n    valve.inputWatermarkStatus(WatermarkStatus.ACTIVE, 1, valveOutput);\n    assertEquals(null, valveOutput.popLastSeenOutput());\n\n    valve.inputWatermarkStatus(WatermarkStatus.IDLE, 1, valveOutput);\n    assertEquals(null, valveOutput.popLastSeenOutput());\n\n        \n    valve.inputWatermarkStatus(WatermarkStatus.IDLE, 0, valveOutput);\n    assertEquals(WatermarkStatus.IDLE, valveOutput.popLastSeenOutput());\n\n    valve.inputWatermarkStatus(WatermarkStatus.IDLE, 0, valveOutput);\n    valve.inputWatermarkStatus(WatermarkStatus.IDLE, 1, valveOutput);\n    assertEquals(null, valveOutput.popLastSeenOutput());\n\n        \n    valve.inputWatermarkStatus(WatermarkStatus.ACTIVE, 1, valveOutput);\n    assertEquals(WatermarkStatus.ACTIVE, valveOutput.popLastSeenOutput());\n\n    valve.inputWatermarkStatus(WatermarkStatus.ACTIVE, 0, valveOutput);\n        \n    assertEquals(null, valveOutput.popLastSeenOutput());\n}", "summary_tokens": ["tests", "that", "watermark", "status", "toggling", "works", "correctly", "as", "well", "as", "that", "non", "toggling", "status", "inputs", "do", "not", "yield", "output", "for", "a", "multiple", "input", "valve"], "project": "flink"}
{"id": 6930, "code": "public void enableNumSnapshots() {\n    this.properties.add(RocksDBProperty.NumSnapshots.getRocksDBProperty());\n}", "summary_tokens": ["returns", "number", "of", "unreleased", "snapshots", "of", "the", "database"], "project": "flink"}
{"id": 9726, "code": "static ContainerLaunchContext createTaskExecutorContext(\n        org.apache.flink.configuration.Configuration flinkConfig,\n        YarnConfiguration yarnConfig,\n        YarnResourceManagerDriverConfiguration configuration,\n        ContaineredTaskManagerParameters tmParams,\n        String taskManagerDynamicProperties,\n        String workingDirectory,\n        Class<?> taskManagerMainClass,\n        Logger log)\n        throws Exception {\n\n        \n\n    String remoteFlinkJarPath =\n            checkNotNull(\n                    configuration.getFlinkDistJar(),\n                    \"Environment variable %s not set\",\n                    YarnConfigKeys.FLINK_DIST_JAR);\n\n    String shipListString =\n            checkNotNull(\n                    configuration.getClientShipFiles(),\n                    \"Environment variable %s not set\",\n                    YarnConfigKeys.ENV_CLIENT_SHIP_FILES);\n\n    final String remoteKeytabPath = configuration.getRemoteKeytabPath();\n    final String localKeytabPath = configuration.getLocalKeytabPath();\n    final String keytabPrincipal = configuration.getKeytabPrinciple();\n    final String remoteYarnConfPath = configuration.getYarnSiteXMLPath();\n    final String remoteKrb5Path = configuration.getKrb5Path();\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"TM:remote keytab path obtained {}\", remoteKeytabPath);\n        log.debug(\"TM:local keytab path obtained {}\", localKeytabPath);\n        log.debug(\"TM:keytab principal obtained {}\", keytabPrincipal);\n        log.debug(\"TM:remote yarn conf path obtained {}\", remoteYarnConfPath);\n        log.debug(\"TM:remote krb5 path obtained {}\", remoteKrb5Path);\n    }\n\n    String classPathString =\n            checkNotNull(\n                    configuration.getFlinkClasspath(),\n                    \"Environment variable %s not set\",\n                    YarnConfigKeys.ENV_FLINK_CLASSPATH);\n\n        \n    LocalResource keytabResource = null;\n    if (remoteKeytabPath != null) {\n        log.info(\n                \"TM:Adding keytab {} to the container local resource bucket\", remoteKeytabPath);\n        Path keytabPath = new Path(remoteKeytabPath);\n        FileSystem fs = keytabPath.getFileSystem(yarnConfig);\n        keytabResource = registerLocalResource(fs, keytabPath, LocalResourceType.FILE);\n    }\n\n        \n    LocalResource yarnConfResource = null;\n    if (remoteYarnConfPath != null) {\n        log.info(\n                \"TM:Adding remoteYarnConfPath {} to the container local resource bucket\",\n                remoteYarnConfPath);\n        Path yarnConfPath = new Path(remoteYarnConfPath);\n        FileSystem fs = yarnConfPath.getFileSystem(yarnConfig);\n        yarnConfResource = registerLocalResource(fs, yarnConfPath, LocalResourceType.FILE);\n    }\n\n        \n    LocalResource krb5ConfResource = null;\n    boolean hasKrb5 = false;\n    if (remoteKrb5Path != null) {\n        log.info(\n                \"Adding remoteKrb5Path {} to the container local resource bucket\",\n                remoteKrb5Path);\n        Path krb5ConfPath = new Path(remoteKrb5Path);\n        FileSystem fs = krb5ConfPath.getFileSystem(yarnConfig);\n        krb5ConfResource = registerLocalResource(fs, krb5ConfPath, LocalResourceType.FILE);\n        hasKrb5 = true;\n    }\n\n    Map<String, LocalResource> taskManagerLocalResources = new HashMap<>();\n\n        \n    final YarnLocalResourceDescriptor flinkDistLocalResourceDesc =\n            YarnLocalResourceDescriptor.fromString(remoteFlinkJarPath);\n    taskManagerLocalResources.put(\n            flinkDistLocalResourceDesc.getResourceKey(),\n            flinkDistLocalResourceDesc.toLocalResource());\n\n        \n    if (yarnConfResource != null) {\n        taskManagerLocalResources.put(YARN_SITE_FILE_NAME, yarnConfResource);\n    }\n    if (krb5ConfResource != null) {\n        taskManagerLocalResources.put(KRB5_FILE_NAME, krb5ConfResource);\n    }\n    if (keytabResource != null) {\n        taskManagerLocalResources.put(localKeytabPath, keytabResource);\n    }\n\n        \n    decodeYarnLocalResourceDescriptorListFromString(shipListString)\n            .forEach(\n                    resourceDesc ->\n                            taskManagerLocalResources.put(\n                                    resourceDesc.getResourceKey(),\n                                    resourceDesc.toLocalResource()));\n\n        \n\n    log.info(\"Creating container launch context for TaskManagers\");\n\n    boolean hasLogback = new File(workingDirectory, \"logback.xml\").exists();\n    boolean hasLog4j = new File(workingDirectory, \"log4j.properties\").exists();\n\n    String launchCommand =\n            BootstrapTools.getTaskManagerShellCommand(\n                    flinkConfig,\n                    tmParams,\n                    \".\",\n                    ApplicationConstants.LOG_DIR_EXPANSION_VAR,\n                    hasLogback,\n                    hasLog4j,\n                    hasKrb5,\n                    taskManagerMainClass,\n                    taskManagerDynamicProperties);\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"Starting TaskManagers with command: \" + launchCommand);\n    } else {\n        log.info(\"Starting TaskManagers\");\n    }\n\n    ContainerLaunchContext ctx = Records.newRecord(ContainerLaunchContext.class);\n    ctx.setCommands(Collections.singletonList(launchCommand));\n    ctx.setLocalResources(taskManagerLocalResources);\n\n    Map<String, String> containerEnv = new HashMap<>();\n    containerEnv.putAll(tmParams.taskManagerEnv());\n\n        \n    containerEnv.put(ENV_FLINK_CLASSPATH, classPathString);\n    setupYarnClassPath(yarnConfig, containerEnv);\n\n    containerEnv.put(\n            YarnConfigKeys.ENV_HADOOP_USER_NAME,\n            UserGroupInformation.getCurrentUser().getUserName());\n\n    if (remoteKeytabPath != null && localKeytabPath != null && keytabPrincipal != null) {\n        containerEnv.put(YarnConfigKeys.REMOTE_KEYTAB_PATH, remoteKeytabPath);\n        containerEnv.put(YarnConfigKeys.LOCAL_KEYTAB_PATH, localKeytabPath);\n        containerEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, keytabPrincipal);\n    } else if (localKeytabPath != null && keytabPrincipal != null) {\n        containerEnv.put(YarnConfigKeys.LOCAL_KEYTAB_PATH, localKeytabPath);\n        containerEnv.put(YarnConfigKeys.KEYTAB_PRINCIPAL, keytabPrincipal);\n    }\n\n    ctx.setEnvironment(containerEnv);\n\n        \n        \n        \n        \n        \n    final String fileLocation = System.getenv(UserGroupInformation.HADOOP_TOKEN_FILE_LOCATION);\n\n    if (fileLocation != null) {\n        log.debug(\"Adding security tokens to TaskExecutor's container launch context.\");\n\n        try (DataOutputBuffer dob = new DataOutputBuffer()) {\n            Credentials cred =\n                    Credentials.readTokenStorageFile(\n                            new File(fileLocation),\n                            HadoopUtils.getHadoopConfiguration(flinkConfig));\n\n                \n                \n            Credentials taskManagerCred = new Credentials();\n            Collection<Token<? extends TokenIdentifier>> userTokens = cred.getAllTokens();\n            for (Token<? extends TokenIdentifier> token : userTokens) {\n                if (!token.getKind().equals(AMRMTokenIdentifier.KIND_NAME)) {\n                    taskManagerCred.addToken(token.getService(), token);\n                }\n            }\n\n            taskManagerCred.writeTokenStorageToStream(dob);\n            ByteBuffer securityTokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());\n            ctx.setTokens(securityTokens);\n        } catch (Throwable t) {\n            log.error(\"Failed to add Hadoop's security tokens.\", t);\n        }\n    } else {\n        log.info(\n                \"Could not set security tokens because Hadoop's token file location is unknown.\");\n    }\n\n    return ctx;\n}", "summary_tokens": ["creates", "the", "launch", "context", "which", "describes", "how", "to", "bring", "up", "a", "task", "executor", "task", "manager", "process", "in", "an", "allocated", "yarn", "container"], "project": "flink"}
{"id": 3622, "code": "public int getId() {\n    return this.id;\n}", "summary_tokens": ["gets", "the", "id", "of", "this", "node"], "project": "flink"}
{"id": 9240, "code": "public void processElement(\n        RowData input,\n        KeyedProcessFunction<K, RowData, RowData>.Context ctx,\n        Collector<RowData> out)\n        throws Exception {\n        \n    registerProcessingCleanupTimer(ctx, ctx.timerService().currentProcessingTime());\n\n    long timestamp = input.getLong(rowTimeIdx);\n    long curWatermark = ctx.timerService().currentWatermark();\n\n    if (timestamp > curWatermark) {\n            \n            \n        long triggerTs = curWatermark < 0 ? 0 : curWatermark + 1;\n        ctx.timerService().registerEventTimeTimer(triggerTs);\n\n            \n        List<RowData> rowList = inputState.get(timestamp);\n        if (rowList == null) {\n            rowList = new ArrayList<RowData>();\n        }\n        rowList.add(input);\n        inputState.put(timestamp, rowList);\n    } else {\n            \n        numLateRecordsDropped.inc();\n    }\n}", "summary_tokens": ["puts", "an", "element", "from", "the", "input", "stream", "into", "state", "if", "it", "is", "not", "late"], "project": "flink"}
{"id": 8201, "code": "public void remove(K key) throws Exception {\n    map.remove(key);\n}", "summary_tokens": ["deletes", "the", "value", "for", "the", "given", "key"], "project": "flink"}
{"id": 7475, "code": "public static <T, W extends Window> PurgingTrigger<T, W> of(Trigger<T, W> nestedTrigger) {\n    return new PurgingTrigger<>(nestedTrigger);\n}", "summary_tokens": ["creates", "a", "new", "purging", "trigger", "from", "the", "given", "trigger"], "project": "flink"}
{"id": 221, "code": "private void waitForCluster() {\n    AdminClient adminClient = embeddedNodeEnv.getClient().admin();\n    ClusterAdminClient clusterAdminClient = adminClient.cluster();\n\n    ClusterHealthRequestBuilder requestBuilder = clusterAdminClient.prepareHealth(\"_all\");\n    requestBuilder = requestBuilder.setTimeout(TimeValue.timeValueSeconds(120));\n\n    ActionFuture<ClusterHealthResponse> healthFuture =\n            clusterAdminClient.health(requestBuilder.request());\n\n    ClusterHealthResponse health = healthFuture.actionGet(TimeValue.timeValueSeconds(120));\n\n    assertThat(health.getNumberOfNodes(), greaterThanOrEqualTo(1));\n    assertThat(health.getNumberOfDataNodes(), greaterThanOrEqualTo(1));\n}", "summary_tokens": ["blocks", "until", "the", "cluster", "is", "ready", "and", "data", "nodes", "nodes", "are", "live"], "project": "flink"}
{"id": 478, "code": "public void endAndPrepare(Xid xid) throws Exception {\n    checkState(active == mappedToXids.get(xid));\n    try {\n        active.endAndPrepare(xid);\n    } finally {\n        active = null;\n    }\n}", "summary_tokens": ["must", "be", "called", "after", "start", "xid", "with", "the", "same", "xid"], "project": "flink"}
{"id": 3245, "code": "public EdgeTargetDegree<K, VV, EV> setReduceOnSourceId(boolean reduceOnSourceId) {\n    this.reduceOnSourceId.set(reduceOnSourceId);\n\n    return this;\n}", "summary_tokens": ["the", "degree", "can", "be", "counted", "from", "either", "the", "edge", "source", "or", "target", "ids"], "project": "flink"}
{"id": 3239, "code": "public Map<String, Aggregator<?>> getAggregators() {\n    return this.aggregators;\n}", "summary_tokens": ["gets", "the", "set", "of", "aggregators", "that", "are", "registered", "for", "this", "vertex", "centric", "iteration"], "project": "flink"}
{"id": 3035, "code": "public void setStateChanged() {\n    this.stateChanged = true;\n}", "summary_tokens": ["set", "the", "changed", "bit", "checked", "via", "is", "state", "changed", "to", "true"], "project": "flink"}
{"id": 6809, "code": "static void helpSetPrevNode(long node, long prevNode, int level, Allocator spaceAllocator) {\n    Preconditions.checkArgument(level > 0, \"only index level have previous node\");\n\n    if (node == HEAD_NODE || node == NIL_NODE) {\n        return;\n    }\n\n    Chunk chunk = spaceAllocator.getChunkById(SpaceUtils.getChunkIdByAddress(node));\n    int offsetInChunk = SpaceUtils.getChunkOffsetByAddress(node);\n    MemorySegment segment = chunk.getMemorySegment(offsetInChunk);\n    int offsetInByteBuffer = chunk.getOffsetInSegment(offsetInChunk);\n\n    int topLevel = getLevel(segment, offsetInByteBuffer);\n\n    putPrevIndexNode(segment, offsetInByteBuffer, topLevel, level, prevNode);\n}", "summary_tokens": ["set", "the", "previous", "node", "of", "the", "given", "node", "at", "the", "given", "level"], "project": "flink"}
{"id": 824, "code": "public static KinesisProxyInterface create(Properties configProps) {\n    return new DynamoDBStreamsProxy(configProps);\n}", "summary_tokens": ["creates", "a", "dynamo", "db", "streams", "proxy"], "project": "flink"}
{"id": 3684, "code": "public void parameterizeChannel(Channel channel) {\n    LocalProperties current = channel.getLocalProperties();\n\n    if (isMetBy(current)) {\n            \n        channel.setLocalStrategy(LocalStrategy.NONE);\n    } else if (this.ordering != null) {\n        channel.setLocalStrategy(\n                LocalStrategy.SORT,\n                this.ordering.getInvolvedIndexes(),\n                this.ordering.getFieldSortDirections());\n    } else if (this.groupedFields != null) {\n        boolean[] dirs = new boolean[this.groupedFields.size()];\n        Arrays.fill(dirs, true);\n        channel.setLocalStrategy(\n                LocalStrategy.SORT, Utils.createOrderedFromSet(this.groupedFields), dirs);\n    } else {\n        channel.setLocalStrategy(LocalStrategy.NONE);\n    }\n}", "summary_tokens": ["parametrizes", "the", "local", "strategy", "fields", "of", "a", "channel", "such", "that", "the", "channel", "produces", "the", "desired", "local", "properties"], "project": "flink"}
{"id": 7380, "code": "default boolean isStreamSource() {\n    return false;\n}", "summary_tokens": ["is", "this", "factory", "for", "stream", "source"], "project": "flink"}
{"id": 7433, "code": "public TypeInformation<IN2> getInputType2() {\n    return input2.getOutputType();\n}", "summary_tokens": ["returns", "the", "type", "information", "for", "the", "elements", "from", "the", "second", "input"], "project": "flink"}
{"id": 6978, "code": "public long getWriteBatchSize() {\n    return rocksDBStateBackend.getWriteBatchSize();\n}", "summary_tokens": ["gets", "the", "max", "batch", "size", "will", "be", "used", "in", "rocks", "dbwrite", "batch", "wrapper"], "project": "flink"}
{"id": 3587, "code": "public int compareTo(Costs o) {\n        \n        \n    if (this.networkCost != UNKNOWN && o.networkCost != UNKNOWN) {\n        if (this.networkCost != o.networkCost) {\n            return this.networkCost < o.networkCost ? -1 : 1;\n        }\n    } else if (this.heuristicNetworkCost < o.heuristicNetworkCost) {\n        return -1;\n    } else if (this.heuristicNetworkCost > o.heuristicNetworkCost) {\n        return 1;\n    }\n\n        \n        \n    if (this.diskCost != UNKNOWN && o.diskCost != UNKNOWN) {\n        if (this.diskCost != o.diskCost) {\n            return this.diskCost < o.diskCost ? -1 : 1;\n        }\n    } else if (this.heuristicDiskCost < o.heuristicDiskCost) {\n        return -1;\n    } else if (this.heuristicDiskCost > o.heuristicDiskCost) {\n        return 1;\n    }\n\n        \n        \n    if (this.cpuCost != UNKNOWN && o.cpuCost != UNKNOWN) {\n        return this.cpuCost < o.cpuCost ? -1 : this.cpuCost > o.cpuCost ? 1 : 0;\n    } else if (this.heuristicCpuCost < o.heuristicCpuCost) {\n        return -1;\n    } else if (this.heuristicCpuCost > o.heuristicCpuCost) {\n        return 1;\n    } else {\n        return 0;\n    }\n}", "summary_tokens": ["the", "order", "of", "comparison", "is", "network", "first", "then", "disk", "then", "cpu"], "project": "flink"}
{"id": 4545, "code": "public void commit() {\n    positionMarker.commit();\n}", "summary_tokens": ["make", "the", "change", "visible", "to", "the", "readers"], "project": "flink"}
{"id": 8459, "code": "public void open(FunctionContext context) throws Exception {\n        \n}", "summary_tokens": ["setup", "method", "for", "user", "defined", "function"], "project": "flink"}
{"id": 4177, "code": "boolean discardOnJobFinished() {\n    return discardFinished;\n}", "summary_tokens": ["returns", "whether", "the", "checkpoint", "should", "be", "discarded", "when", "the", "owning", "job", "reaches", "the", "job", "status", "finished", "state"], "project": "flink"}
{"id": 666, "code": "public void testExplicitStateSerializerCompatibility() throws Exception {\n    ExecutionConfig executionConfig = new ExecutionConfig();\n\n    Tuple2<KafkaTopicPartition, Long> tuple =\n            new Tuple2<>(new KafkaTopicPartition(\"dummy\", 0), 42L);\n\n        \n    TypeInformation<Tuple2<KafkaTopicPartition, Long>> originalTypeHintTypeInfo =\n            new TypeHint<Tuple2<KafkaTopicPartition, Long>>() {}.getTypeInfo();\n    TypeSerializer<Tuple2<KafkaTopicPartition, Long>> serializerFromTypeHint =\n            originalTypeHintTypeInfo.createSerializer(executionConfig);\n    byte[] bytes = InstantiationUtil.serializeToByteArray(serializerFromTypeHint, tuple);\n\n        \n    TupleSerializer<Tuple2<KafkaTopicPartition, Long>> kafkaConsumerSerializer =\n            FlinkKafkaConsumerBase.createStateSerializer(executionConfig);\n    Tuple2<KafkaTopicPartition, Long> actualTuple =\n            InstantiationUtil.deserializeFromByteArray(kafkaConsumerSerializer, bytes);\n\n    Assert.assertEquals(\n            \"Explicit Serializer is not compatible with previous method of creating Serializer using TypeHint.\",\n            tuple,\n            actualTuple);\n}", "summary_tokens": ["before", "using", "an", "explicit", "type", "serializer", "for", "the", "partition", "state", "the", "flink", "kafka", "consumer", "base", "was", "creating", "a", "serializer", "using", "a", "type", "hint"], "project": "flink"}
{"id": 8564, "code": "public static TypeInference forAsyncTableFunction(\n        DataTypeFactory typeFactory, Class<? extends AsyncTableFunction<?>> function) {\n    final FunctionMappingExtractor mappingExtractor =\n            new FunctionMappingExtractor(\n                    typeFactory,\n                    function,\n                    UserDefinedFunctionHelper.ASYNC_TABLE_EVAL,\n                    createParameterSignatureExtraction(1),\n                    null,\n                    createGenericResultExtraction(AsyncTableFunction.class, 0, true),\n                    createParameterWithArgumentVerification(CompletableFuture.class));\n    return extractTypeInference(mappingExtractor);\n}", "summary_tokens": ["extracts", "a", "type", "inference", "from", "a", "async", "table", "function"], "project": "flink"}
{"id": 5823, "code": "static void uploadJarFile(BlobServer blobServer, Configuration blobClientConfig)\n        throws Exception {\n    final File testFile = File.createTempFile(\"testfile\", \".dat\");\n    testFile.deleteOnExit();\n    prepareTestFile(testFile);\n\n    InetSocketAddress serverAddress = new InetSocketAddress(\"localhost\", blobServer.getPort());\n\n    uploadJarFile(serverAddress, blobClientConfig, testFile);\n    uploadJarFile(serverAddress, blobClientConfig, testFile);\n}", "summary_tokens": ["tests", "the", "static", "blob", "client", "upload", "files", "inet", "socket", "address", "configuration", "job", "id", "list", "helper"], "project": "flink"}
{"id": 7310, "code": "public InputFormat<OUT, InputSplit> getFormat() {\n    return format;\n}", "summary_tokens": ["returns", "the", "input", "format"], "project": "flink"}
{"id": 438, "code": "public void testReadPartitionTable() throws Exception {\n    final String dbName = \"source_db\";\n    final String tblName = \"test_table_pt\";\n    batchTableEnv.executeSql(\n            \"CREATE TABLE source_db.test_table_pt \"\n                    + \"(`year` STRING, `value` INT) partitioned by (pt int)\");\n    HiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n            .addRow(new Object[] {\"2014\", 3})\n            .addRow(new Object[] {\"2014\", 4})\n            .commit(\"pt=0\");\n    HiveTestUtils.createTextTableInserter(hiveCatalog, dbName, tblName)\n            .addRow(new Object[] {\"2015\", 2})\n            .addRow(new Object[] {\"2015\", 5})\n            .commit(\"pt=1\");\n    Table src = batchTableEnv.sqlQuery(\"select * from hive.source_db.test_table_pt\");\n    List<Row> rows = CollectionUtil.iteratorToList(src.execute().collect());\n\n    assertEquals(4, rows.size());\n    Object[] rowStrings = rows.stream().map(Row::toString).sorted().toArray();\n    assertArrayEquals(\n            new String[] {\n                \"+I[2014, 3, 0]\", \"+I[2014, 4, 0]\", \"+I[2015, 2, 1]\", \"+I[2015, 5, 1]\"\n            },\n            rowStrings);\n}", "summary_tokens": ["test", "to", "read", "from", "partition", "table"], "project": "flink"}
{"id": 7098, "code": "public static <E> List<E> collectBoundedStream(DataStream<E> stream, String jobName)\n        throws Exception {\n    final ArrayList<E> list = new ArrayList<>();\n    final Iterator<E> iter = collectWithClient(stream, jobName).iterator;\n    while (iter.hasNext()) {\n        list.add(iter.next());\n    }\n    list.trimToSize();\n    return list;\n}", "summary_tokens": ["collects", "contents", "the", "given", "data", "stream", "into", "a", "list", "assuming", "that", "the", "stream", "is", "a", "bounded", "stream"], "project": "flink"}
{"id": 2747, "code": "public SplitDataProperties<T> splitsOrderedBy(String orderFields, Order[] orders) {\n\n    if (orderFields == null || orders == null) {\n        throw new InvalidProgramException(\"OrderFields or Orders may not be null.\");\n    }\n\n    String[] orderKeysA = orderFields.split(\";\");\n    if (orderKeysA.length == 0) {\n        throw new InvalidProgramException(\"OrderFields may not be empty.\");\n    } else if (orders.length == 0) {\n        throw new InvalidProgramException(\"Orders may not be empty\");\n    } else if (orderKeysA.length != orders.length) {\n        throw new InvalidProgramException(\"Number of OrderFields and Orders must match.\");\n    }\n\n    if (this.splitGroupKeys != null) {\n        throw new InvalidProgramException(\"DataSource may either be grouped or sorted.\");\n    }\n\n    this.splitOrdering = new Ordering();\n\n    for (int i = 0; i < orderKeysA.length; i++) {\n        String keyExp = orderKeysA[i];\n        Keys.ExpressionKeys<T> ek = new Keys.ExpressionKeys<>(keyExp, this.type);\n        int[] flatKeys = ek.computeLogicalKeyPositions();\n\n        for (int key : flatKeys) {\n                \n            for (int okey : splitOrdering.getFieldPositions()) {\n                if (key == okey) {\n                    throw new InvalidProgramException(\n                            \"Duplicate field in field expression \" + keyExp);\n                }\n            }\n                \n            this.splitOrdering.appendOrdering(key, null, orders[i]);\n        }\n    }\n    return this;\n}", "summary_tokens": ["defines", "that", "the", "data", "within", "an", "input", "split", "is", "sorted", "on", "the", "fields", "defined", "by", "the", "field", "expressions", "in", "the", "specified", "orders"], "project": "flink"}
{"id": 2087, "code": "public static <T> CompletableFuture<T> unsupportedOperationFuture() {\n    return (CompletableFuture<T>) UNSUPPORTED_OPERATION_FUTURE;\n}", "summary_tokens": ["returns", "an", "exceptionally", "completed", "future", "with", "an", "unsupported", "operation", "exception"], "project": "flink"}
{"id": 2722, "code": "public static Set<Annotation> readSingleForwardAnnotations(Class<?> udfClass) {\n    ForwardedFields forwardedFields = udfClass.getAnnotation(ForwardedFields.class);\n    NonForwardedFields nonForwardedFields = udfClass.getAnnotation(NonForwardedFields.class);\n    ReadFields readSet = udfClass.getAnnotation(ReadFields.class);\n\n    Set<Annotation> annotations = new HashSet<Annotation>();\n    if (forwardedFields != null) {\n        annotations.add(forwardedFields);\n    }\n    if (nonForwardedFields != null) {\n        if (!annotations.isEmpty()) {\n            throw new InvalidProgramException(\n                    \"Either \"\n                            + ForwardedFields.class.getSimpleName()\n                            + \" or \"\n                            + NonForwardedFields.class.getSimpleName()\n                            + \" can be annotated to a function, not both.\");\n        }\n        annotations.add(nonForwardedFields);\n    }\n    if (readSet != null) {\n        annotations.add(readSet);\n    }\n\n    return !annotations.isEmpty() ? annotations : null;\n}", "summary_tokens": ["reads", "the", "annotations", "of", "a", "user", "defined", "function", "with", "one", "input", "and", "returns", "semantic", "properties", "according", "to", "the", "forwarded", "fields", "annotated"], "project": "flink"}
{"id": 8680, "code": "public static TableSchema.Builder builderWithGivenSchema(TableSchema oriSchema) {\n    TableSchema.Builder builder = builderWithGivenColumns(oriSchema.getTableColumns());\n        \n    for (WatermarkSpec wms : oriSchema.getWatermarkSpecs()) {\n        builder.watermark(\n                wms.getRowtimeAttribute(),\n                wms.getWatermarkExpr(),\n                wms.getWatermarkExprOutputType());\n    }\n        \n    oriSchema\n            .getPrimaryKey()\n            .map(\n                    pk ->\n                            builder.primaryKey(\n                                    pk.getName(), pk.getColumns().toArray(new String[0])));\n    return builder;\n}", "summary_tokens": ["creates", "a", "builder", "with", "given", "table", "schema"], "project": "flink"}
{"id": 5967, "code": "public void testHandInSubtasks() throws Exception {\n    test(false);\n}", "summary_tokens": ["tests", "that", "subtask", "stats", "are", "correctly", "collected"], "project": "flink"}
{"id": 2002, "code": "public static int roundDownToPowerOf2(int value) {\n    return Integer.highestOneBit(value);\n}", "summary_tokens": ["decrements", "the", "given", "number", "down", "to", "the", "closest", "power", "of", "two"], "project": "flink"}
{"id": 9334, "code": "public RowData value(W window) throws IOException {\n    windowState.setCurrentNamespace(window);\n    return windowState.value();\n}", "summary_tokens": ["returns", "the", "current", "value", "for", "the", "state", "under", "current", "key", "and", "the", "given", "window"], "project": "flink"}
{"id": 7253, "code": "public DataStreamSource<Long> generateSequence(long from, long to) {\n    if (from > to) {\n        throw new IllegalArgumentException(\n                \"Start of sequence must not be greater than the end\");\n    }\n    return addSource(new StatefulSequenceSource(from, to), \"Sequence Source (Deprecated)\");\n}", "summary_tokens": ["creates", "a", "new", "data", "stream", "that", "contains", "a", "sequence", "of", "numbers"], "project": "flink"}
{"id": 9622, "code": "public void testMultipleJobsAfterAnother() throws Exception {\n    LocalStreamEnvironment env = new LocalStreamEnvironment();\n\n    addSmallBoundedJob(env, 3);\n    env.execute();\n\n    addSmallBoundedJob(env, 5);\n    env.execute();\n}", "summary_tokens": ["test", "test", "verifies", "that", "the", "execution", "environment", "can", "be", "used", "to", "execute", "multiple", "bounded", "streaming", "jobs", "after", "one", "another"], "project": "flink"}
{"id": 7829, "code": "public void testMetrics() throws Exception {\n\n    HashMap<String, OperatorMetricGroup> operatorMetrics = new HashMap<>();\n\n    TaskMetricGroup taskMetricGroup =\n            new UnregisteredMetricGroups.UnregisteredTaskMetricGroup() {\n                @Override\n                public InternalOperatorMetricGroup getOrAddOperator(\n                        OperatorID operatorID, String name) {\n                    InternalOperatorMetricGroup operatorMetricGroup =\n                            super.getOrAddOperator(operatorID, name);\n                    operatorMetrics.put(name, operatorMetricGroup);\n                    return operatorMetricGroup;\n                }\n            };\n\n    String mainOperatorName = \"MainOperator\";\n    try (StreamTaskMailboxTestHarness<String> testHarness =\n            new StreamTaskMailboxTestHarnessBuilder<>(\n                            MultipleInputStreamTask::new, BasicTypeInfo.STRING_TYPE_INFO)\n                    .modifyExecutionConfig(applyObjectReuse(objectReuse))\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO)\n                    .addSourceInput(\n                            new SourceOperatorFactory<>(\n                                    new LifeCycleTrackingMockSource(Boundedness.BOUNDED, 1),\n                                    WatermarkStrategy.noWatermarks()),\n                            BasicTypeInfo.INT_TYPE_INFO)\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO)\n                    .setupOperatorChain(new MapToStringMultipleInputOperatorFactory(3))\n                    .name(mainOperatorName)\n                    .chain(\n                            new OneInputStreamTaskTest.DuplicatingOperator(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()))\n                    .chain(\n                            new OneInputStreamTaskTest.DuplicatingOperator(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()))\n                    .chain(\n                            new OneInputStreamTaskTest.DuplicatingOperator(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()))\n                    .finish()\n                    .setTaskMetricGroup(taskMetricGroup)\n                    .build()) {\n\n        assertTrue(operatorMetrics.containsKey(mainOperatorName));\n        OperatorMetricGroup mainOperatorMetrics = operatorMetrics.get(mainOperatorName);\n        Counter numRecordsInCounter =\n                taskMetricGroup.getIOMetricGroup().getNumRecordsInCounter();\n        Counter numRecordsOutCounter =\n                taskMetricGroup.getIOMetricGroup().getNumRecordsOutCounter();\n\n        int numRecords1 = 5;\n        int numRecords2 = 3;\n        int numRecords3 = 2;\n            \n            \n        for (int x = 0; x < numRecords2; x++) {\n            addSourceRecords(testHarness, 1, 42);\n        }\n        for (int x = 0; x < numRecords1; x++) {\n            testHarness.processElement(new StreamRecord<>(\"hello\"), 0, 0);\n        }\n        for (int x = 0; x < numRecords3; x++) {\n            testHarness.processElement(new StreamRecord<>(\"hello\"), 1, 0);\n        }\n\n        int networkRecordsIn = numRecords1 + numRecords3;\n        int mainOperatorRecordsIn = networkRecordsIn + numRecords2;\n        int totalRecordsOut =\n                mainOperatorRecordsIn\n                        * 2\n                        * 2\n                        * 2; \n        assertEquals(\n                mainOperatorRecordsIn,\n                mainOperatorMetrics.getIOMetricGroup().getNumRecordsInCounter().getCount());\n        assertEquals(networkRecordsIn, numRecordsInCounter.getCount());\n        assertEquals(totalRecordsOut, numRecordsOutCounter.getCount());\n        testHarness.waitForTaskCompletion();\n    }\n}", "summary_tokens": ["with", "chained", "sources", "task", "s", "and", "main", "operator", "s", "number", "of", "input", "records", "are", "two", "different", "things"], "project": "flink"}
{"id": 2828, "code": "public <R> GroupReduceOperator<T, R> reduceGroup(GroupReduceFunction<T, R> reducer) {\n    if (reducer == null) {\n        throw new NullPointerException(\"GroupReduce function must not be null.\");\n    }\n    TypeInformation<R> resultType =\n            TypeExtractor.getGroupReduceReturnTypes(\n                    reducer,\n                    this.getInputDataSet().getType(),\n                    Utils.getCallLocationName(),\n                    true);\n\n    return new GroupReduceOperator<T, R>(\n            this, resultType, inputDataSet.clean(reducer), Utils.getCallLocationName());\n}", "summary_tokens": ["applies", "a", "group", "reduce", "transformation", "on", "a", "grouped", "data", "set"], "project": "flink"}
{"id": 2923, "code": "public void testJoinKeyMixedKeySelector() {\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    DataSet<CustomType> ds1 = env.fromCollection(customTypeData);\n    DataSet<CustomType> ds2 = env.fromCollection(customTypeData);\n    try {\n        ds1.join(ds2)\n                .where(\"myInt\")\n                .equalTo(\n                        new KeySelector<CustomType, Integer>() {\n                            @Override\n                            public Integer getKey(CustomType value) throws Exception {\n                                return value.myInt;\n                            }\n                        });\n    } catch (Exception e) {\n        e.printStackTrace();\n        Assert.fail();\n    }\n}", "summary_tokens": ["test", "if", "mixed", "types", "of", "key", "selectors", "are", "properly", "working"], "project": "flink"}
{"id": 8420, "code": "default Map<String, String> requiredContext() {\n        \n    return null;\n}", "summary_tokens": ["implement", "the", "factory", "based", "stack", "instead"], "project": "flink"}
{"id": 3588, "code": "public void addCachedHybridHashCosts(\n        EstimateProvider buildSideInput,\n        EstimateProvider probeSideInput,\n        Costs costs,\n        int costWeight) {\n    if (costWeight < 1) {\n        throw new IllegalArgumentException(\"The cost weight must be at least one.\");\n    }\n\n    long bs = buildSideInput.getEstimatedOutputSize();\n    long ps = probeSideInput.getEstimatedOutputSize();\n\n    if (bs > 0 && ps > 0) {\n        long overall = 2 * bs + costWeight * ps;\n        costs.addDiskCost(overall);\n        costs.addCpuCost((long) (overall * HASHING_CPU_FACTOR));\n    } else {\n        costs.setDiskCost(Costs.UNKNOWN);\n        costs.setCpuCost(Costs.UNKNOWN);\n    }\n\n        \n    costs.addHeuristicDiskCost((1 + costWeight) * HEURISTIC_COST_BASE);\n    costs.addHeuristicCpuCost(\n            (long) ((1 + costWeight) * HEURISTIC_COST_BASE * HASHING_CPU_FACTOR));\n}", "summary_tokens": ["calculates", "the", "costs", "for", "the", "cached", "variant", "of", "the", "hybrid", "hash", "join"], "project": "flink"}
{"id": 6390, "code": "public void testUnregisterFailures() throws Exception {\n    String name = \"IrGnc73237TAs\";\n\n    ExecutionJobVertex[] vertices =\n            new ExecutionJobVertex[] {createJobVertex(32), createJobVertex(13)};\n\n    Map<JobVertexID, ExecutionJobVertex> vertexMap = new HashMap<>();\n    for (ExecutionJobVertex vertex : vertices) {\n        vertexMap.put(vertex.getJobVertexId(), vertex);\n    }\n\n    KvStateLocationRegistry registry = new KvStateLocationRegistry(new JobID(), vertexMap);\n\n        \n    registry.notifyKvStateRegistered(\n            vertices[0].getJobVertexId(),\n            new KeyGroupRange(0, 0),\n            name,\n            new KvStateID(),\n            mock(InetSocketAddress.class));\n\n    try {\n            \n        int notRegisteredKeyGroupIndex = 2;\n\n        registry.notifyKvStateUnregistered(\n                vertices[0].getJobVertexId(),\n                new KeyGroupRange(notRegisteredKeyGroupIndex, notRegisteredKeyGroupIndex),\n                name);\n\n        fail(\"Did not throw expected Exception\");\n    } catch (IllegalArgumentException expected) {\n    }\n\n    try {\n            \n        registry.notifyKvStateUnregistered(\n                vertices[1].getJobVertexId(), new KeyGroupRange(0, 0), name);\n\n        fail(\"Did not throw expected Exception\");\n    } catch (IllegalArgumentException expected) {\n    }\n}", "summary_tokens": ["tests", "failures", "during", "unregistration"], "project": "flink"}
{"id": 5372, "code": "public KeyGroupRange getIntersection(KeyGroupRange other) {\n    int start = Math.max(startKeyGroup, other.startKeyGroup);\n    int end = Math.min(endKeyGroup, other.endKeyGroup);\n    return start <= end ? new KeyGroupRange(start, end) : EMPTY_KEY_GROUP_RANGE;\n}", "summary_tokens": ["create", "a", "range", "that", "represent", "the", "intersection", "between", "this", "range", "and", "the", "given", "range"], "project": "flink"}
{"id": 6078, "code": "public void testOneComponentViaTwoExchanges() {\n    TestingSchedulingTopology topology = new TestingSchedulingTopology();\n\n    TestingSchedulingExecutionVertex va1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex va2 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vb1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vb2 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vc1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vc2 = topology.newExecutionVertex();\n\n    topology.connect(va1, vb1, ResultPartitionType.PIPELINED)\n            .connect(va1, vb2, ResultPartitionType.PIPELINED)\n            .connect(va2, vb1, ResultPartitionType.PIPELINED)\n            .connect(va2, vb2, ResultPartitionType.PIPELINED)\n            .connect(vb1, vc1, ResultPartitionType.PIPELINED)\n            .connect(vb1, vc2, ResultPartitionType.PIPELINED)\n            .connect(vb2, vc1, ResultPartitionType.PIPELINED)\n            .connect(vb2, vc2, ResultPartitionType.PIPELINED);\n\n    Map<ExecutionVertexID, Set<SchedulingExecutionVertex>> pipelinedRegionByVertex =\n            computePipelinedRegionByVertex(topology);\n\n    Set<SchedulingExecutionVertex> ra1 = pipelinedRegionByVertex.get(va1.getId());\n    Set<SchedulingExecutionVertex> ra2 = pipelinedRegionByVertex.get(va2.getId());\n    Set<SchedulingExecutionVertex> rb1 = pipelinedRegionByVertex.get(vb1.getId());\n    Set<SchedulingExecutionVertex> rb2 = pipelinedRegionByVertex.get(vb2.getId());\n    Set<SchedulingExecutionVertex> rc1 = pipelinedRegionByVertex.get(vc1.getId());\n    Set<SchedulingExecutionVertex> rc2 = pipelinedRegionByVertex.get(vc2.getId());\n\n    assertSameRegion(ra1, ra2, rb1, rb2, rc1, rc2);\n}", "summary_tokens": ["tests", "that", "validates", "that", "a", "single", "pipelined", "component", "via", "a", "sequence", "of", "all", "to", "all", "connections", "works", "correctly"], "project": "flink"}
{"id": 5876, "code": "public void testRestoreLatestCheckpointedState() throws Exception {\n    final List<TestingVertex> vertices =\n            Arrays.asList(\n                    new TestingVertex(new JobVertexID(), 3, 42),\n                    new TestingVertex(new JobVertexID(), 2, 13));\n    testRestoreLatestCheckpointedState(\n            vertices,\n            testSuccessfulCheckpointsArePersistedToCompletedCheckpointStore(vertices));\n}", "summary_tokens": ["tests", "that", "the", "checkpointed", "partitioned", "and", "non", "partitioned", "state", "is", "assigned", "properly", "to", "the", "execution", "upon", "recovery"], "project": "flink"}
{"id": 6483, "code": "public static BiFunction<AsynchronousJobOperationKey, String, CompletableFuture<Acknowledge>>\n        setReferenceToOperationKey(AtomicReference<AsynchronousJobOperationKey> keyReference) {\n    return (AsynchronousJobOperationKey operationKey, String directory) -> {\n        keyReference.set(operationKey);\n        return CompletableFuture.completedFuture(Acknowledge.get());\n    };\n}", "summary_tokens": ["returns", "a", "function", "which", "when", "called", "sets", "the", "provided", "reference", "to", "the", "asynchronous", "job", "operation", "key", "that", "the", "function", "was", "called", "with", "then", "returns", "a", "future", "containing", "an", "acknowledge"], "project": "flink"}
{"id": 3502, "code": "public <R> BootstrapTransformation<T> apply(\n        WindowFunction<T, R, K, W> function, TypeInformation<R> resultType) {\n    function = input.clean(function);\n\n    WindowOperator<K, T, ?, R, W> operator = builder.apply(function);\n\n    SavepointWriterOperatorFactory factory =\n            (timestamp, path) -> new StateBootstrapWrapperOperator<>(timestamp, path, operator);\n    return new BootstrapTransformation<>(\n            input, operatorMaxParallelism, timestamper, factory, keySelector, keyType);\n}", "summary_tokens": ["applies", "the", "given", "window", "function", "to", "each", "window"], "project": "flink"}
{"id": 2605, "code": "protected boolean supportLazyDecode() {\n    return true;\n}", "summary_tokens": ["support", "lazy", "dictionary", "ids", "decode"], "project": "flink"}
{"id": 4920, "code": "private static boolean hasCommonPrefix(byte[] address, byte[] address2) {\n    return address[0] == address2[0] && address[1] == address2[1];\n}", "summary_tokens": ["checks", "if", "two", "addresses", "have", "a", "common", "prefix", "first", "0", "bytes"], "project": "flink"}
{"id": 3545, "code": "private String getVariableName(String str) {\n    return str.substring(1, str.length() - 1);\n}", "summary_tokens": ["removes", "leading", "and", "trailing", "angle", "brackets"], "project": "flink"}
{"id": 3707, "code": "public String getJobName() {\n    return this.jobName;\n}", "summary_tokens": ["returns", "the", "name", "of", "the", "program"], "project": "flink"}
{"id": 2940, "code": "public void testOutOfTupleBoundsDataset3() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    DataSet<Tuple5<Integer, Long, String, Long, Integer>> tupleDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo);\n\n        \n    tupleDs.minBy(1, 2, 3, 4, -1);\n}", "summary_tokens": ["this", "test", "validates", "that", "an", "index", "which", "is", "out", "of", "bounds", "throws", "an", "index", "out", "of", "bounds", "exception"], "project": "flink"}
{"id": 4405, "code": "public void notifyCheckpointAborted(\n        long abortCheckpointId, long latestCompletedCheckpointId, long timestamp) {\n    final LogicalSlot slot = assignedResource;\n\n    if (slot != null) {\n        final TaskManagerGateway taskManagerGateway = slot.getTaskManagerGateway();\n\n        taskManagerGateway.notifyCheckpointAborted(\n                attemptId,\n                getVertex().getJobId(),\n                abortCheckpointId,\n                latestCompletedCheckpointId,\n                timestamp);\n    } else {\n        LOG.debug(\n                \"The execution has no slot assigned. This indicates that the execution is \"\n                        + \"no longer running.\");\n    }\n}", "summary_tokens": ["notify", "the", "task", "of", "this", "execution", "about", "a", "aborted", "checkpoint"], "project": "flink"}
{"id": 7712, "code": "public void testMapStateDefaultValue() throws Exception {\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n\n    MapStateDescriptor<String, String> kvId =\n            new MapStateDescriptor<>(\"id\", String.class, String.class);\n\n    MapState<String, String> state =\n            backend.getPartitionedState(\n                    VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n    backend.setCurrentKey(1);\n    assertNotNull(state.entries());\n    assertFalse(state.entries().iterator().hasNext());\n\n    state.put(\"Ciao\", \"Hello\");\n    state.put(\"Bello\", \"Nice\");\n\n    assertNotNull(state.entries());\n    assertEquals(state.get(\"Ciao\"), \"Hello\");\n    assertEquals(state.get(\"Bello\"), \"Nice\");\n\n    state.clear();\n    assertNotNull(state.entries());\n    assertFalse(state.entries().iterator().hasNext());\n\n    backend.dispose();\n}", "summary_tokens": ["verify", "that", "an", "empty", "map", "state", "yields", "null"], "project": "flink"}
{"id": 3144, "code": "public static DataSet<Vertex<Long, String>> getVertices(ExecutionEnvironment env) {\n    List<Vertex<Long, String>> vertices = new ArrayList<>(INPUT_VERTICES.length);\n    for (String vertex : INPUT_VERTICES) {\n        String[] tokens = vertex.split(\";\");\n        vertices.add(new Vertex<>(Long.parseLong(tokens[0]), tokens[1]));\n    }\n\n    return env.fromCollection(vertices);\n}", "summary_tokens": ["creates", "a", "set", "of", "vertices", "with", "attached", "string", "values"], "project": "flink"}
{"id": 3010, "code": "public void testHeapMemoryPropertyWithOldConfigKey() throws Exception {\n    Configuration configuration = new Configuration();\n    configuration.set(DeploymentOptions.TARGET, KubernetesSessionClusterExecutor.NAME);\n    configuration.setInteger(JobManagerOptions.JOB_MANAGER_HEAP_MEMORY_MB, 2048);\n    configuration.setInteger(TaskManagerOptions.TASK_MANAGER_HEAP_MEMORY_MB, 4096);\n\n    final KubernetesSessionCli cli =\n            new KubernetesSessionCli(configuration, tmp.getRoot().getAbsolutePath());\n\n    final Configuration executorConfig = cli.getEffectiveConfiguration(new String[] {});\n    final ClusterClientFactory<String> clientFactory = getClusterClientFactory(executorConfig);\n    final ClusterSpecification clusterSpecification =\n            clientFactory.getClusterSpecification(executorConfig);\n\n    assertThat(clusterSpecification.getMasterMemoryMB(), is(2048));\n    assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(4096));\n}", "summary_tokens": ["tests", "the", "specifying", "heap", "memory", "with", "old", "config", "key", "for", "job", "manager", "and", "task", "manager"], "project": "flink"}
{"id": 7367, "code": "public Configuration getUserFunctionParameters() {\n    return new Configuration();\n}", "summary_tokens": ["since", "the", "streaming", "api", "does", "not", "implement", "any", "parametrization", "of", "functions", "via", "a", "configuration", "the", "config", "returned", "here", "is", "actually", "empty"], "project": "flink"}
{"id": 333, "code": "default boolean isMaterializedView(org.apache.hadoop.hive.ql.metadata.Table table) {\n    return false;\n}", "summary_tokens": ["checks", "whether", "a", "hive", "table", "is", "a", "materialized", "view"], "project": "flink"}
{"id": 3972, "code": "private static boolean isRpcTimeout(Annotation[] annotations) {\n    for (Annotation annotation : annotations) {\n        if (annotation.annotationType().equals(RpcTimeout.class)) {\n            return true;\n        }\n    }\n\n    return false;\n}", "summary_tokens": ["checks", "whether", "any", "of", "the", "annotations", "is", "of", "type", "rpc", "timeout"], "project": "flink"}
{"id": 4440, "code": "public static FailureHandlingResult unrecoverable(\n        @Nullable ExecutionVertexID failingExecutionVertexId,\n        @Nonnull Throwable error,\n        long timestamp,\n        boolean globalFailure) {\n    return new FailureHandlingResult(failingExecutionVertexId, error, timestamp, globalFailure);\n}", "summary_tokens": ["creates", "a", "result", "that", "the", "failure", "is", "not", "recoverable", "and", "no", "restarting", "should", "be", "conducted"], "project": "flink"}
{"id": 8918, "code": "public static List<RelCollation> values(\n        RelMetadataQuery mq,\n        RelDataType rowType,\n        com.google.common.collect.ImmutableList<\n                        com.google.common.collect.ImmutableList<RexLiteral>>\n                tuples) {\n    Util.discard(mq); \n    final List<RelCollation> list = new ArrayList<>();\n    final int n = rowType.getFieldCount();\n    final List<Pair<RelFieldCollation, com.google.common.collect.Ordering<List<RexLiteral>>>>\n            pairs = new ArrayList<>();\n    outer:\n    for (int i = 0; i < n; i++) {\n        pairs.clear();\n        for (int j = i; j < n; j++) {\n            final RelFieldCollation fieldCollation = new RelFieldCollation(j);\n            com.google.common.collect.Ordering<List<RexLiteral>> comparator =\n                    comparator(fieldCollation);\n            com.google.common.collect.Ordering<List<RexLiteral>> ordering;\n            if (pairs.isEmpty()) {\n                ordering = comparator;\n            } else {\n                ordering = Util.last(pairs).right.compound(comparator);\n            }\n            pairs.add(Pair.of(fieldCollation, ordering));\n            if (!ordering.isOrdered(tuples)) {\n                if (j == i) {\n                    continue outer;\n                }\n                pairs.remove(pairs.size() - 1);\n            }\n        }\n        if (!pairs.isEmpty()) {\n            list.add(RelCollations.of(Pair.left(pairs)));\n        }\n    }\n    return list;\n}", "summary_tokens": ["helper", "method", "to", "determine", "a", "org"], "project": "flink"}
{"id": 7820, "code": "private static <K, IN, OUT> void processElementAndEnsureOutput(\n        OneInputStreamOperator<IN, OUT> operator,\n        KeySelector<IN, K> keySelector,\n        TypeInformation<K> keyType,\n        IN element)\n        throws Exception {\n\n    KeyedOneInputStreamOperatorTestHarness<K, IN, OUT> testHarness =\n            new KeyedOneInputStreamOperatorTestHarness<>(operator, keySelector, keyType);\n\n    if (operator instanceof OutputTypeConfigurable) {\n            \n            \n        ((OutputTypeConfigurable) operator)\n                .setOutputType(BasicTypeInfo.STRING_TYPE_INFO, new ExecutionConfig());\n    }\n\n    testHarness.open();\n\n    testHarness.setProcessingTime(0);\n    testHarness.processWatermark(Long.MIN_VALUE);\n\n    testHarness.processElement(new StreamRecord<>(element, 0));\n\n        \n    testHarness.setProcessingTime(Long.MAX_VALUE);\n    testHarness.processWatermark(Long.MAX_VALUE);\n\n        \n    assertTrue(testHarness.getOutput().size() >= 3);\n\n    testHarness.close();\n}", "summary_tokens": ["ensure", "that", "we", "get", "some", "output", "from", "the", "given", "operator", "when", "pushing", "in", "an", "element", "and", "setting", "watermark", "and", "processing", "time", "to", "long"], "project": "flink"}
{"id": 339, "code": "public static TableSchema createTableSchema(\n        List<FieldSchema> cols,\n        List<FieldSchema> partitionKeys,\n        Set<String> notNullColumns,\n        UniqueConstraint primaryKey) {\n    List<FieldSchema> allCols = new ArrayList<>(cols);\n    allCols.addAll(partitionKeys);\n\n    String[] colNames = new String[allCols.size()];\n    DataType[] colTypes = new DataType[allCols.size()];\n\n    for (int i = 0; i < allCols.size(); i++) {\n        FieldSchema fs = allCols.get(i);\n\n        colNames[i] = fs.getName();\n        colTypes[i] =\n                HiveTypeUtil.toFlinkType(TypeInfoUtils.getTypeInfoFromTypeString(fs.getType()));\n        if (notNullColumns.contains(colNames[i])) {\n            colTypes[i] = colTypes[i].notNull();\n        }\n    }\n\n    TableSchema.Builder builder = TableSchema.builder().fields(colNames, colTypes);\n    if (primaryKey != null) {\n        builder.primaryKey(\n                primaryKey.getName(), primaryKey.getColumns().toArray(new String[0]));\n    }\n    return builder.build();\n}", "summary_tokens": ["create", "a", "flink", "s", "table", "schema", "from", "hive", "table", "s", "columns", "and", "partition", "keys"], "project": "flink"}
{"id": 414, "code": "private String processLateralView(HiveParserQB qb, HiveParserASTNode lateralView)\n        throws SemanticException {\n    int numChildren = lateralView.getChildCount();\n\n    assert (numChildren == 2);\n    HiveParserASTNode next = (HiveParserASTNode) lateralView.getChild(1);\n\n    String alias;\n\n    switch (next.getToken().getType()) {\n        case HiveASTParser.TOK_TABREF:\n            alias = processTable(qb, next);\n            break;\n        case HiveASTParser.TOK_SUBQUERY:\n            alias = processSubQuery(qb, next);\n            break;\n        case HiveASTParser.TOK_LATERAL_VIEW:\n        case HiveASTParser.TOK_LATERAL_VIEW_OUTER:\n            alias = processLateralView(qb, next);\n            break;\n        default:\n            throw new SemanticException(\n                    HiveParserErrorMsg.getMsg(\n                            ErrorMsg.LATERAL_VIEW_INVALID_CHILD, lateralView));\n    }\n    alias = alias.toLowerCase();\n    qb.getParseInfo().addLateralViewForAlias(alias, lateralView);\n    qb.addAlias(alias);\n    return alias;\n}", "summary_tokens": ["given", "the", "ast", "with", "tok", "lateral", "view", "as", "the", "root", "get", "the", "alias", "for", "the", "table", "or", "subquery", "in", "the", "lateral", "view", "and", "also", "make", "a", "mapping", "from", "the", "alias", "to", "all", "the", "lateral", "view", "ast", "s"], "project": "flink"}
{"id": 6985, "code": "private void restoreKVStateData(\n        ThrowingIterator<KeyGroup> keyGroups, Map<Integer, ColumnFamilyHandle> columnFamilies)\n        throws IOException, RocksDBException, StateMigrationException {\n        \n    try (RocksDBWriteBatchWrapper writeBatchWrapper =\n            new RocksDBWriteBatchWrapper(this.rocksHandle.getDb(), writeBatchSize)) {\n        ColumnFamilyHandle handle = null;\n        while (keyGroups.hasNext()) {\n            KeyGroup keyGroup = keyGroups.next();\n            try (ThrowingIterator<KeyGroupEntry> groupEntries = keyGroup.getKeyGroupEntries()) {\n                int oldKvStateId = -1;\n                while (groupEntries.hasNext()) {\n                    KeyGroupEntry groupEntry = groupEntries.next();\n                    int kvStateId = groupEntry.getKvStateId();\n                    if (kvStateId != oldKvStateId) {\n                        oldKvStateId = kvStateId;\n                        handle = columnFamilies.get(kvStateId);\n                    }\n                    writeBatchWrapper.put(handle, groupEntry.getKey(), groupEntry.getValue());\n                }\n            }\n        }\n    }\n}", "summary_tokens": ["restore", "the", "kv", "state", "column", "family", "data", "for", "all", "key", "groups", "referenced", "by", "the", "current", "state", "handle"], "project": "flink"}
{"id": 1662, "code": "public static Map<String, String> getPrefixedKeyValuePairs(\n        String prefix, Configuration configuration) {\n    Map<String, String> result = new HashMap<>();\n    for (Map.Entry<String, String> entry : configuration.toMap().entrySet()) {\n        if (entry.getKey().startsWith(prefix) && entry.getKey().length() > prefix.length()) {\n            String key = entry.getKey().substring(prefix.length());\n            result.put(key, entry.getValue());\n        }\n    }\n    return result;\n}", "summary_tokens": ["extract", "and", "parse", "flink", "configuration", "properties", "with", "a", "given", "name", "prefix", "and", "return", "the", "result", "as", "a", "map"], "project": "flink"}
{"id": 2057, "code": "public Iterator<T> getSplit(int num, int numPartitions) {\n    if (numPartitions < 1 || num < 0 || num >= numPartitions) {\n        throw new IllegalArgumentException();\n    }\n\n    return split(numPartitions)[num];\n}", "summary_tokens": ["splits", "this", "iterator", "into", "i", "n", "i", "partitions", "and", "returns", "the", "i", "i", "th", "i", "partition", "out", "of", "those"], "project": "flink"}
{"id": 928, "code": "static <T> PulsarDeserializationSchema<T> flinkSchema(\n        DeserializationSchema<T> deserializationSchema) {\n    return new PulsarDeserializationSchemaWrapper<>(deserializationSchema);\n}", "summary_tokens": ["create", "a", "pulsar", "deserialization", "schema", "by", "using", "the", "flink", "s", "deserialization", "schema"], "project": "flink"}
{"id": 7212, "code": "public long getCheckpointIdOfIgnoredInFlightData() {\n    return checkpointIdOfIgnoredInFlightData;\n}", "summary_tokens": ["checkpoint", "id", "for", "which", "in", "flight", "data", "should", "be", "ignored"], "project": "flink"}
{"id": 7601, "code": "private <IN, OUT> int addOperatorToStreamGraph(\n        StreamOperatorFactory<OUT> operatorFactory,\n        Collection<Integer> inputs,\n        TypeInformation<IN> inTypeInfo,\n        TypeInformation<OUT> outTypInfo,\n        String name,\n        @Nullable String uid,\n        int parallelism,\n        int maxParallelism,\n        SinkTransformation<InputT, CommT, WriterStateT, GlobalCommT> sinkTransformation,\n        Context context) {\n    final StreamGraph streamGraph = context.getStreamGraph();\n    final String slotSharingGroup = context.getSlotSharingGroup();\n    final int transformationId = Transformation.getNewNodeId();\n\n    streamGraph.addOperator(\n            transformationId,\n            slotSharingGroup,\n            sinkTransformation.getCoLocationGroupKey(),\n            operatorFactory,\n            inTypeInfo,\n            outTypInfo,\n            name);\n\n    streamGraph.setParallelism(transformationId, parallelism);\n    streamGraph.setMaxParallelism(transformationId, maxParallelism);\n\n    StreamGraphUtils.configureBufferTimeout(\n            streamGraph,\n            transformationId,\n            sinkTransformation,\n            context.getDefaultBufferTimeout());\n    if (uid != null) {\n        streamGraph.setTransformationUID(transformationId, uid);\n    }\n\n    for (int input : inputs) {\n        streamGraph.addEdge(input, transformationId, 0);\n    }\n\n    return transformationId;\n}", "summary_tokens": ["add", "a", "operator", "to", "the", "stream", "graph"], "project": "flink"}
{"id": 6408, "code": "public void testRegisterTaskExecutorWithUnmatchedLeaderSessionId() throws Exception {\n        \n        \n    CompletableFuture<RegistrationResponse> unMatchedLeaderFuture =\n            registerTaskExecutor(wronglyFencedGateway, taskExecutorGateway.getAddress());\n\n    try {\n        unMatchedLeaderFuture.get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);\n        fail(\n                \"Should have failed because we are using a wrongly fenced ResourceManagerGateway.\");\n    } catch (ExecutionException e) {\n        assertTrue(ExceptionUtils.stripExecutionException(e) instanceof FencingTokenException);\n    }\n}", "summary_tokens": ["test", "receive", "registration", "with", "unmatched", "leadership", "id", "from", "task", "executor"], "project": "flink"}
{"id": 3078, "code": "public GroupPattern<T, F> next(Pattern<T, F> group) {\n    return new GroupPattern<>(this, group, ConsumingStrategy.STRICT, afterMatchSkipStrategy);\n}", "summary_tokens": ["appends", "a", "new", "group", "pattern", "to", "the", "existing", "one"], "project": "flink"}
{"id": 5866, "code": "public void testFailureIfStorageDirectoryCannotBeCreated() throws IOException {\n    final Configuration configuration = new Configuration();\n    final File blobStorageDirectory = createNonWritableDirectory();\n\n    final String nonExistDirectory =\n            new File(blobStorageDirectory, \"does_not_exist_for_sure\").getAbsolutePath();\n    configuration.setString(BlobServerOptions.STORAGE_DIRECTORY, nonExistDirectory);\n\n    try (BlobServer ignored = new BlobServer(configuration, new VoidBlobStore())) {\n        fail(\"Expected that the BlobServer initialization fails.\");\n    } catch (IOException expected) {\n            \n    }\n}", "summary_tokens": ["tests", "that", "the", "blob", "server", "fails", "if", "the", "blob", "storage", "directory", "cannot", "be", "created"], "project": "flink"}
{"id": 9352, "code": "public TypeSerializer<V> getValueSerializer() {\n    return valueSerializer;\n}", "summary_tokens": ["returns", "the", "serializer", "for", "the", "values", "in", "the", "map"], "project": "flink"}
{"id": 8076, "code": "public static Map<String, String> removeRedundant(\n        Map<String, String> properties, TableSchema schema, List<String> partitionKeys) {\n    Map<String, String> ret = new HashMap<>(properties);\n    DescriptorProperties descriptorProperties = new DescriptorProperties(false);\n    descriptorProperties.putTableSchema(SCHEMA, schema);\n    descriptorProperties.putPartitionKeys(partitionKeys);\n    descriptorProperties.asMap().keySet().forEach(ret::remove);\n    return ret;\n}", "summary_tokens": ["construct", "catalog", "table", "properties", "from", "to", "properties"], "project": "flink"}
{"id": 181, "code": "public <T extends IN> ElasticsearchSinkBuilderBase<T, ?> setEmitter(\n        ElasticsearchEmitter<? super T> emitter) {\n    checkNotNull(emitter);\n    checkState(\n            InstantiationUtil.isSerializable(emitter),\n            \"The elasticsearch emitter must be serializable.\");\n\n    final ElasticsearchSinkBuilderBase<T, ?> self = self();\n    self.emitter = emitter;\n    return self;\n}", "summary_tokens": ["sets", "the", "emitter", "which", "is", "invoked", "on", "every", "record", "to", "convert", "it", "to", "elasticsearch", "actions"], "project": "flink"}
{"id": 6180, "code": "public void testNotifyCreditAvailableAfterReleased() throws Exception {\n    final CreditBasedPartitionRequestClientHandler handler =\n            new CreditBasedPartitionRequestClientHandler();\n    final EmbeddedChannel channel = new EmbeddedChannel(handler);\n    final PartitionRequestClient client =\n            new NettyPartitionRequestClient(\n                    channel,\n                    handler,\n                    mock(ConnectionID.class),\n                    mock(PartitionRequestClientFactory.class));\n\n    final NetworkBufferPool networkBufferPool = new NetworkBufferPool(10, 32);\n    final SingleInputGate inputGate = createSingleInputGate(1, networkBufferPool);\n    final RemoteInputChannel inputChannel = createRemoteInputChannel(inputGate, client);\n    try {\n        inputGate.setInputChannels(inputChannel);\n        final BufferPool bufferPool = networkBufferPool.createBufferPool(6, 6);\n        inputGate.setBufferPool(bufferPool);\n        inputGate.setupChannels();\n\n        inputChannel.requestSubpartition(0);\n\n            \n        Object readFromOutbound = channel.readOutbound();\n        assertThat(readFromOutbound, instanceOf(PartitionRequest.class));\n        assertEquals(2, ((PartitionRequest) readFromOutbound).credit);\n\n            \n        final BufferResponse bufferResponse =\n                createBufferResponse(\n                        TestBufferFactory.createBuffer(32),\n                        0,\n                        inputChannel.getInputChannelId(),\n                        1,\n                        new NetworkBufferAllocator(handler));\n        handler.channelRead(mock(ChannelHandlerContext.class), bufferResponse);\n\n        assertEquals(2, inputChannel.getUnannouncedCredit());\n\n            \n        inputGate.close();\n\n            \n            \n        readFromOutbound = channel.readOutbound();\n        assertThat(readFromOutbound, instanceOf(CloseRequest.class));\n\n        channel.runPendingTasks();\n\n        assertNull(channel.readOutbound());\n    } finally {\n        releaseResource(inputGate, networkBufferPool);\n        channel.close();\n    }\n}", "summary_tokens": ["verifies", "that", "remote", "input", "channel", "is", "enqueued", "in", "the", "pipeline", "but", "add", "credit", "message", "is", "not", "sent", "actually", "when", "this", "input", "channel", "is", "released"], "project": "flink"}
{"id": 1688, "code": "public static boolean isRestSSLAuthenticationEnabled(Configuration sslConfig) {\n    checkNotNull(sslConfig, \"sslConfig\");\n    return isRestSSLEnabled(sslConfig) && sslConfig.getBoolean(SSL_REST_AUTHENTICATION_ENABLED);\n}", "summary_tokens": ["checks", "whether", "mutual", "ssl", "authentication", "for", "the", "external", "rest", "endpoint", "is", "enabled"], "project": "flink"}
{"id": 7580, "code": "private boolean cancelAsyncCheckpointRunnable(long checkpointId) {\n    AsyncCheckpointRunnable asyncCheckpointRunnable;\n    synchronized (lock) {\n        asyncCheckpointRunnable = checkpoints.remove(checkpointId);\n    }\n    closeQuietly(asyncCheckpointRunnable);\n    return asyncCheckpointRunnable != null;\n}", "summary_tokens": ["cancel", "the", "async", "checkpoint", "runnable", "with", "given", "checkpoint", "id"], "project": "flink"}
{"id": 2679, "code": "public int getParallelism() {\n    return config.getParallelism();\n}", "summary_tokens": ["gets", "the", "parallelism", "with", "which", "operation", "are", "executed", "by", "default"], "project": "flink"}
{"id": 3666, "code": "public PartitioningProperty getPartitioning() {\n    return partitioning;\n}", "summary_tokens": ["gets", "the", "partitioning", "property"], "project": "flink"}
{"id": 9649, "code": "public void testOperatorChainedToSource() throws Exception {\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setStreamTimeCharacteristic(timeCharacteristic);\n    env.setParallelism(1);\n\n    DataStream<String> source = env.addSource(new InfiniteTestSource());\n\n    source.transform(\n            \"Custom Operator\",\n            BasicTypeInfo.STRING_TYPE_INFO,\n            new TimerOperator(ChainingStrategy.ALWAYS));\n\n    try {\n        env.execute(\"Timer test\");\n    } catch (JobExecutionException e) {\n        verifyJobExecutionException(e);\n    }\n}", "summary_tokens": ["note", "this", "test", "fails", "if", "we", "don", "t", "check", "for", "exceptions", "in", "the", "source", "contexts", "and", "do", "not", "synchronize", "in", "the", "source", "contexts"], "project": "flink"}
{"id": 4564, "code": "private void mayNotifyAvailable(@Nullable CompletableFuture<?> toNotify) {\n    if (toNotify != null) {\n        toNotify.complete(null);\n    }\n}", "summary_tokens": ["notifies", "the", "potential", "segment", "consumer", "of", "the", "new", "available", "segments", "by", "completing", "the", "previous", "uncompleted", "future"], "project": "flink"}
{"id": 6451, "code": "public void testReceivingUnknownSlotReport() throws Exception {\n    final InstanceID unknownInstanceID = new InstanceID();\n    final SlotReport unknownSlotReport = new SlotReport();\n    new Context() {\n        {\n            runTest(\n                    () -> {\n                            \n                        assertThat(getSlotManager().getNumberRegisteredSlots(), is(0));\n\n                            \n                            \n                        final CompletableFuture<Boolean> reportSlotFuture =\n                                new CompletableFuture<>();\n                        runInMainThread(\n                                () ->\n                                        reportSlotFuture.complete(\n                                                getSlotManager()\n                                                        .reportSlotStatus(\n                                                                unknownInstanceID,\n                                                                unknownSlotReport)));\n                        assertFalse(assertFutureCompleteAndReturn(reportSlotFuture));\n                        assertThat(getSlotManager().getNumberRegisteredSlots(), is(0));\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "that", "the", "slot", "manager", "ignores", "slot", "reports", "of", "unknown", "origin", "not", "registered", "task", "managers"], "project": "flink"}
{"id": 6954, "code": "public ColumnFamilyOptions getColumnOptions() {\n        \n    ColumnFamilyOptions opt = createBaseCommonColumnOptions();\n    handlesToClose.add(opt);\n\n        \n    setColumnFamilyOptionsFromConfigurableOptions(opt, handlesToClose);\n\n        \n    if (optionsFactory != null) {\n        opt = optionsFactory.createColumnOptions(opt, handlesToClose);\n    }\n\n        \n        \n    if (sharedResources != null) {\n        final RocksDBSharedResources rocksResources = sharedResources.getResourceHandle();\n        final Cache blockCache = rocksResources.getCache();\n        TableFormatConfig tableFormatConfig = opt.tableFormatConfig();\n        BlockBasedTableConfig blockBasedTableConfig;\n        if (tableFormatConfig == null) {\n            blockBasedTableConfig = new BlockBasedTableConfig();\n        } else {\n            Preconditions.checkArgument(\n                    tableFormatConfig instanceof BlockBasedTableConfig,\n                    \"We currently only support BlockBasedTableConfig When bounding total memory.\");\n            blockBasedTableConfig = (BlockBasedTableConfig) tableFormatConfig;\n        }\n        if (rocksResources.isUsingPartitionedIndexFilters()\n                && overwriteFilterIfExist(blockBasedTableConfig)) {\n            blockBasedTableConfig.setIndexType(IndexType.kTwoLevelIndexSearch);\n            blockBasedTableConfig.setPartitionFilters(true);\n            blockBasedTableConfig.setPinTopLevelIndexAndFilter(true);\n        }\n        blockBasedTableConfig.setBlockCache(blockCache);\n        blockBasedTableConfig.setCacheIndexAndFilterBlocks(true);\n        blockBasedTableConfig.setCacheIndexAndFilterBlocksWithHighPriority(true);\n        blockBasedTableConfig.setPinL0FilterAndIndexBlocksInCache(true);\n        opt.setTableFormatConfig(blockBasedTableConfig);\n    }\n\n    return opt;\n}", "summary_tokens": ["gets", "the", "rocks", "db", "column", "family", "options", "to", "be", "used", "for", "all", "rocks", "db", "instances"], "project": "flink"}
{"id": 8989, "code": "protected FlinkLogicalTableSourceScan getNewScan(\n        FlinkLogicalWatermarkAssigner watermarkAssigner,\n        RexNode watermarkExpr,\n        FlinkLogicalTableSourceScan scan,\n        TableConfig tableConfig,\n        boolean useWatermarkAssignerRowType) {\n    final TableSourceTable tableSourceTable = scan.getTable().unwrap(TableSourceTable.class);\n    final DynamicTableSource newDynamicTableSource = tableSourceTable.tableSource().copy();\n\n    final boolean isSourceWatermark =\n            newDynamicTableSource instanceof SupportsSourceWatermark\n                    && hasSourceWatermarkDeclaration(watermarkExpr);\n\n    final RelDataType newType;\n    if (useWatermarkAssignerRowType) {\n            \n        newType = watermarkAssigner.getRowType();\n    } else {\n            \n        newType = scan.getRowType();\n    }\n\n    final RowType producedType = (RowType) FlinkTypeFactory.toLogicalType(newType);\n    final SourceAbilityContext abilityContext = SourceAbilityContext.from(scan);\n\n    final SourceAbilitySpec abilitySpec;\n    if (isSourceWatermark) {\n        final SourceWatermarkSpec sourceWatermarkSpec =\n                new SourceWatermarkSpec(true, producedType);\n        sourceWatermarkSpec.apply(newDynamicTableSource, abilityContext);\n        abilitySpec = sourceWatermarkSpec;\n    } else {\n        final Duration idleTimeout =\n                tableConfig\n                        .getConfiguration()\n                        .get(ExecutionConfigOptions.TABLE_EXEC_SOURCE_IDLE_TIMEOUT);\n        final long idleTimeoutMillis;\n        if (!idleTimeout.isZero() && !idleTimeout.isNegative()) {\n            idleTimeoutMillis = idleTimeout.toMillis();\n        } else {\n            idleTimeoutMillis = -1L;\n        }\n\n        final WatermarkPushDownSpec watermarkPushDownSpec =\n                new WatermarkPushDownSpec(watermarkExpr, idleTimeoutMillis, producedType);\n        watermarkPushDownSpec.apply(newDynamicTableSource, abilityContext);\n        abilitySpec = watermarkPushDownSpec;\n    }\n\n    TableSourceTable newTableSourceTable =\n            tableSourceTable.copy(\n                    newDynamicTableSource, newType, new SourceAbilitySpec[] {abilitySpec});\n    return FlinkLogicalTableSourceScan.create(\n            scan.getCluster(), scan.getHints(), newTableSourceTable);\n}", "summary_tokens": ["it", "uses", "the", "input", "watermark", "expression", "to", "generate", "the", "watermark", "generator", "supplier"], "project": "flink"}
{"id": 5083, "code": "private ChannelWithBlockCount mergeChannels(\n        List<ChannelWithBlockCount> channelIDs,\n        List<List<MemorySegment>> readBuffers,\n        List<MemorySegment> writeBuffers)\n        throws IOException {\n        \n    final List<FileIOChannel> channelAccesses = new ArrayList<>(channelIDs.size());\n\n        \n    final MergeIterator<E> mergeIterator =\n            getMergingIterator(channelIDs, readBuffers, channelAccesses, null);\n\n        \n    final FileIOChannel.ID mergedChannelID = this.ioManager.createChannel();\n    spillChannelManager.registerChannelToBeRemovedAtShutdown(mergedChannelID);\n    final BlockChannelWriter<MemorySegment> writer =\n            this.ioManager.createBlockChannelWriter(mergedChannelID);\n    spillChannelManager.registerOpenChannelToBeRemovedAtShutdown(writer);\n    final ChannelWriterOutputView output =\n            new ChannelWriterOutputView(writer, writeBuffers, this.memManager.getPageSize());\n\n    openSpillingBehaviour();\n    spillingBehaviour.mergeRecords(mergeIterator, output);\n    output.close();\n    final int numBlocksWritten = output.getBlockCount();\n\n        \n    spillChannelManager.unregisterOpenChannelToBeRemovedAtShutdown(writer);\n\n        \n    for (FileIOChannel access : channelAccesses) {\n        access.closeAndDelete();\n        spillChannelManager.unregisterOpenChannelToBeRemovedAtShutdown(access);\n    }\n\n    return new ChannelWithBlockCount(mergedChannelID, numBlocksWritten);\n}", "summary_tokens": ["merges", "the", "sorted", "runs", "described", "by", "the", "given", "channel", "ids", "into", "a", "single", "sorted", "run"], "project": "flink"}
{"id": 7075, "code": "public DataStreamSink<T> print(String sinkIdentifier) {\n    PrintSinkFunction<T> printFunction = new PrintSinkFunction<>(sinkIdentifier, false);\n    return addSink(printFunction).name(\"Print to Std. Out\");\n}", "summary_tokens": ["writes", "a", "data", "stream", "to", "the", "standard", "output", "stream", "stdout"], "project": "flink"}
{"id": 342, "code": "public static Optional<String> makePartitionFilter(\n        int partColOffset,\n        List<String> partColNames,\n        List<Expression> expressions,\n        HiveShim hiveShim) {\n    List<String> filters = new ArrayList<>(expressions.size());\n    ExpressionExtractor extractor =\n            new ExpressionExtractor(partColOffset, partColNames, hiveShim);\n    for (Expression expression : expressions) {\n        String str = expression.accept(extractor);\n        if (str == null) {\n            return Optional.empty();\n        }\n        filters.add(str);\n    }\n    return Optional.of(String.join(\" and \", filters));\n}", "summary_tokens": ["generates", "a", "filter", "string", "for", "partition", "columns", "from", "the", "given", "filter", "expressions"], "project": "flink"}
{"id": 8013, "code": "public void setPlannerConfig(PlannerConfig plannerConfig) {\n    this.plannerConfig = Preconditions.checkNotNull(plannerConfig);\n}", "summary_tokens": ["sets", "the", "configuration", "of", "planner", "for", "table", "api", "and", "sql", "queries"], "project": "flink"}
{"id": 5356, "code": "public static CheckpointStorage load(\n        @Nullable CheckpointStorage fromApplication,\n        @Nullable Path defaultSavepointDirectory,\n        StateBackend configuredStateBackend,\n        Configuration config,\n        ClassLoader classLoader,\n        @Nullable Logger logger)\n        throws IllegalConfigurationException, DynamicCodeLoadingException {\n\n    Preconditions.checkNotNull(config, \"config\");\n    Preconditions.checkNotNull(classLoader, \"classLoader\");\n    Preconditions.checkNotNull(configuredStateBackend, \"statebackend\");\n\n    if (defaultSavepointDirectory != null) {\n            \n            \n            \n            \n            \n        config.set(\n                CheckpointingOptions.SAVEPOINT_DIRECTORY, defaultSavepointDirectory.toString());\n    }\n\n        \n    StateBackend rootStateBackend =\n            (configuredStateBackend instanceof DelegatingStateBackend)\n                    ? ((DelegatingStateBackend) configuredStateBackend)\n                            .getDelegatedStateBackend()\n                    : configuredStateBackend;\n\n    if (rootStateBackend instanceof CheckpointStorage) {\n        if (logger != null) {\n            logger.info(\n                    \"Using legacy state backend {} as Job checkpoint storage\",\n                    rootStateBackend);\n            if (fromApplication != null) {\n                logger.warn(\n                        \"Checkpoint storage passed via StreamExecutionEnvironment is ignored because legacy state backend '{}' is used. {}\",\n                        rootStateBackend.getClass().getName(),\n                        LEGACY_PRECEDENCE_LOG_MESSAGE);\n            }\n            if (config.get(CheckpointingOptions.CHECKPOINT_STORAGE) != null) {\n                logger.warn(\n                        \"Config option '{}' is ignored because legacy state backend '{}' is used. {}\",\n                        CheckpointingOptions.CHECKPOINT_STORAGE.key(),\n                        rootStateBackend.getClass().getName(),\n                        LEGACY_PRECEDENCE_LOG_MESSAGE);\n            }\n        }\n        return (CheckpointStorage) rootStateBackend;\n    }\n\n    if (fromApplication != null) {\n        if (fromApplication instanceof ConfigurableCheckpointStorage) {\n            if (logger != null) {\n                logger.info(\n                        \"Using job/cluster config to configure application-defined checkpoint storage: {}\",\n                        fromApplication);\n                if (config.get(CheckpointingOptions.CHECKPOINT_STORAGE) != null) {\n                    logger.warn(\n                            \"Config option '{}' is ignored because the checkpoint storage passed via StreamExecutionEnvironment takes precedence.\",\n                            CheckpointingOptions.CHECKPOINT_STORAGE.key());\n                }\n            }\n            return ((ConfigurableCheckpointStorage) fromApplication)\n                    .configure(config, classLoader);\n        }\n        if (logger != null) {\n            logger.info(\"Using application defined checkpoint storage: {}\", fromApplication);\n        }\n        return fromApplication;\n    }\n\n    return fromConfig(config, classLoader, logger)\n            .orElseGet(() -> createDefaultCheckpointStorage(config, classLoader, logger));\n}", "summary_tokens": ["loads", "the", "configured", "checkpoint", "storage", "for", "the", "job", "based", "on", "the", "following", "precedent", "rules"], "project": "flink"}
{"id": 4720, "code": "private BlockingQueue<V> retrieveSharedQueue(String key) {\n    BlockingQueue<V> queue = mediations.get(key);\n    if (queue == null) {\n        queue = new ArrayBlockingQueue<V>(1);\n        BlockingQueue<V> commonQueue = mediations.putIfAbsent(key, queue);\n        return commonQueue != null ? commonQueue : queue;\n    } else {\n        return queue;\n    }\n}", "summary_tokens": ["thread", "safe", "call", "to", "get", "a", "shared", "blocking", "queue"], "project": "flink"}
{"id": 4561, "code": "public void recycle(MemorySegment memorySegment) {\n    memorySegment.free();\n}", "summary_tokens": ["frees", "the", "given", "memory", "segment"], "project": "flink"}
{"id": 4801, "code": "public final Configuration getTaskConfiguration() {\n    return this.environment.getTaskConfiguration();\n}", "summary_tokens": ["returns", "the", "task", "configuration", "object", "which", "was", "attached", "to", "the", "original", "org"], "project": "flink"}
{"id": 3667, "code": "public FieldSet getPartitionedFields() {\n    return this.partitioningFields;\n}", "summary_tokens": ["gets", "the", "fields", "on", "which", "the", "data", "is", "partitioned"], "project": "flink"}
{"id": 4520, "code": "public BlockChannelWriter<MemorySegment> createBlockChannelWriter(ID channelID)\n        throws IOException {\n    return createBlockChannelWriter(channelID, new LinkedBlockingQueue<>());\n}", "summary_tokens": ["creates", "a", "block", "channel", "writer", "that", "writes", "to", "the", "given", "channel"], "project": "flink"}
{"id": 1230, "code": "public void accept(Visitor<Operator<?>> visitor) {\n    boolean descend = visitor.preVisit(this);\n    if (descend) {\n        this.input.accept(visitor);\n        visitor.postVisit(this);\n    }\n}", "summary_tokens": ["accepts", "the", "visitor", "and", "applies", "it", "this", "instance"], "project": "flink"}
{"id": 1088, "code": "public <T> T getAccumulatorResult(String accumulatorName) {\n    OptionalFailure<Object> result = this.accumulatorResults.get(accumulatorName);\n    if (result != null) {\n        return (T) result.getUnchecked();\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["gets", "the", "accumulator", "with", "the", "given", "name"], "project": "flink"}
{"id": 8497, "code": "public final TableSink<T> configure(String[] fieldNames, TypeInformation<?>[] fieldTypes) {\n\n    final TableSinkBase<T> configuredSink = this.copy();\n    configuredSink.fieldNames = Optional.of(fieldNames);\n    configuredSink.fieldTypes = Optional.of(fieldTypes);\n\n    return configuredSink;\n}", "summary_tokens": ["returns", "a", "copy", "of", "this", "table", "sink", "configured", "with", "the", "field", "names", "and", "types", "of", "the", "table", "to", "emit"], "project": "flink"}
{"id": 8000, "code": "public SlideWithSizeAndSlideOnTimeWithAlias as(Expression alias) {\n    return new SlideWithSizeAndSlideOnTimeWithAlias(alias, timeField, size, slide);\n}", "summary_tokens": ["assigns", "an", "alias", "for", "this", "window", "that", "the", "following", "group", "by", "and", "select", "clause", "can", "refer", "to"], "project": "flink"}
{"id": 6655, "code": "public void testTaskSubmissionAndCancelling() throws Exception {\n    final ExecutionAttemptID eid1 = new ExecutionAttemptID();\n    final ExecutionAttemptID eid2 = new ExecutionAttemptID();\n\n    final TaskDeploymentDescriptor tdd1 =\n            createTestTaskDeploymentDescriptor(\"test task\", eid1, BlockingNoOpInvokable.class);\n    final TaskDeploymentDescriptor tdd2 =\n            createTestTaskDeploymentDescriptor(\"test task\", eid2, BlockingNoOpInvokable.class);\n\n    final CompletableFuture<Void> task1RunningFuture = new CompletableFuture<>();\n    final CompletableFuture<Void> task2RunningFuture = new CompletableFuture<>();\n    final CompletableFuture<Void> task1CanceledFuture = new CompletableFuture<>();\n\n    try (TaskSubmissionTestEnvironment env =\n            new TaskSubmissionTestEnvironment.Builder(jobId)\n                    .setSlotSize(2)\n                    .addTaskManagerActionListener(\n                            eid1, ExecutionState.RUNNING, task1RunningFuture)\n                    .addTaskManagerActionListener(\n                            eid2, ExecutionState.RUNNING, task2RunningFuture)\n                    .addTaskManagerActionListener(\n                            eid1, ExecutionState.CANCELED, task1CanceledFuture)\n                    .build()) {\n        TaskExecutorGateway tmGateway = env.getTaskExecutorGateway();\n        TaskSlotTable<Task> taskSlotTable = env.getTaskSlotTable();\n\n        taskSlotTable.allocateSlot(0, jobId, tdd1.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd1, env.getJobMasterId(), timeout).get();\n        task1RunningFuture.get();\n\n        taskSlotTable.allocateSlot(1, jobId, tdd2.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd2, env.getJobMasterId(), timeout).get();\n        task2RunningFuture.get();\n\n        assertSame(taskSlotTable.getTask(eid1).getExecutionState(), ExecutionState.RUNNING);\n        assertSame(taskSlotTable.getTask(eid2).getExecutionState(), ExecutionState.RUNNING);\n\n        tmGateway.cancelTask(eid1, timeout);\n        task1CanceledFuture.get();\n\n        assertSame(taskSlotTable.getTask(eid1).getExecutionState(), ExecutionState.CANCELED);\n        assertSame(taskSlotTable.getTask(eid2).getExecutionState(), ExecutionState.RUNNING);\n    }\n}", "summary_tokens": ["tests", "that", "we", "can", "cancel", "the", "task", "of", "the", "task", "manager", "given", "that", "we", "ve", "submitted", "it"], "project": "flink"}
{"id": 2947, "code": "public void testMinByRowTypeInfoKeyFieldsForUnsortedGrouping() {\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n    TypeInformation[] types = new TypeInformation[] {Types.INT, Types.INT};\n\n    String[] fieldNames = new String[] {\"id\", \"value\"};\n    RowTypeInfo rowTypeInfo = new RowTypeInfo(types, fieldNames);\n\n    UnsortedGrouping groupDs =\n            env.fromCollection(Collections.singleton(new Row(2)), rowTypeInfo).groupBy(0);\n\n    groupDs.minBy(1);\n}", "summary_tokens": ["validates", "that", "no", "class", "cast", "exception", "happens", "should", "not", "fail", "e"], "project": "flink"}
{"id": 8600, "code": "public static TypeTransformation timeToSqlTypes() {\n    Map<LogicalTypeRoot, Class<?>> conversions = new HashMap<>();\n    conversions.put(LogicalTypeRoot.TIMESTAMP_WITHOUT_TIME_ZONE, Timestamp.class);\n    conversions.put(LogicalTypeRoot.TIME_WITHOUT_TIME_ZONE, Time.class);\n    conversions.put(LogicalTypeRoot.DATE, Date.class);\n    return new DataTypeConversionClassTransformation(conversions);\n}", "summary_tokens": ["returns", "a", "type", "transformation", "that", "transforms", "data", "type", "to", "a", "new", "data", "type", "whose", "conversion", "class", "is", "java"], "project": "flink"}
{"id": 8424, "code": "public static <T extends TableFactory> List<T> findAll(\n        Class<T> factoryClass, Map<String, String> propertyMap) {\n    return findAllInternal(factoryClass, propertyMap, Optional.empty());\n}", "summary_tokens": ["finds", "all", "table", "factories", "of", "the", "given", "class", "and", "property", "map"], "project": "flink"}
{"id": 6306, "code": "public synchronized CompletableFuture<Void> getStartFuture() {\n    return startFuture;\n}", "summary_tokens": ["returns", "the", "start", "future", "indicating", "whether", "this", "leader", "election", "service", "has", "been", "started", "or", "not"], "project": "flink"}
{"id": 6109, "code": "public void testCloseAndCleanupAllDataWithUncle() throws Exception {\n    final String prefix = \"/foo/bar\";\n    final String flinkPath = prefix + \"/flink\";\n    final Configuration configuration = createConfiguration(flinkPath);\n\n    final TestingBlobStoreService blobStoreService = new TestingBlobStoreService();\n\n    final String unclePath = prefix + \"/foobar\";\n    client.create().creatingParentContainersIfNeeded().forPath(unclePath);\n\n    runCleanupTest(\n            configuration, blobStoreService, ZooKeeperHaServices::closeAndCleanupAllData);\n\n    assertThat(blobStoreService.isClosedAndCleanedUpAllData(), is(true));\n\n    assertThat(client.checkExists().forPath(flinkPath), is(nullValue()));\n    assertThat(client.checkExists().forPath(unclePath), is(notNullValue()));\n}", "summary_tokens": ["tests", "that", "we", "can", "only", "delete", "the", "parent", "znodes", "as", "long", "as", "they", "are", "empty"], "project": "flink"}
{"id": 1125, "code": "public void add(Double value) {\n    localValue += value;\n}", "summary_tokens": ["consider", "using", "add", "double", "instead", "for", "primitive", "double", "values"], "project": "flink"}
{"id": 265, "code": "public void loadPartition(LinkedHashMap<String, String> partSpec, List<Path> srcDirs)\n        throws Exception {\n    Optional<Path> pathFromMeta = metaStore.getPartition(partSpec);\n    Path path =\n            pathFromMeta.orElseGet(\n                    () ->\n                            new Path(\n                                    metaStore.getLocationPath(),\n                                    generatePartitionPath(partSpec)));\n\n    overwriteAndRenameFiles(srcDirs, path);\n    metaStore.createOrAlterPartition(partSpec, path);\n}", "summary_tokens": ["load", "a", "single", "partition"], "project": "flink"}
{"id": 8669, "code": "private static StringBuilder ymdhms(\n        StringBuilder b, int year, int month, int day, int h, int m, int s) {\n    ymd(b, year, month, day);\n    b.append(' ');\n    hms(b, h, m, s);\n    return b;\n}", "summary_tokens": ["appends", "year", "month", "day", "and", "hour", "minute", "second", "to", "a", "buffer", "assumes", "they", "are", "valid"], "project": "flink"}
{"id": 3981, "code": "public static AkkaRpcSerializedValue valueOf(@Nullable Object value) throws IOException {\n    byte[] serializedData = value == null ? null : InstantiationUtil.serializeObject(value);\n    return new AkkaRpcSerializedValue(serializedData);\n}", "summary_tokens": ["construct", "a", "serialized", "value", "to", "transfer", "on", "wire"], "project": "flink"}
{"id": 6122, "code": "public void testBroadcastMixedRandomEmitRecord() throws Exception {\n    final int numberOfChannels = 8;\n    final int numberOfRecords = 8;\n    final int bufferSize = 32;\n\n    final ResultPartition partition = createResultPartition(bufferSize, numberOfChannels);\n    final BroadcastRecordWriter<SerializationTestType> writer =\n            new BroadcastRecordWriter<>(partition, -1, \"test\");\n    final RecordDeserializer<SerializationTestType> deserializer =\n            new SpillingAdaptiveSpanningRecordDeserializer<>(\n                    new String[] {tempFolder.getRoot().getAbsolutePath()});\n\n        \n    final Iterable<SerializationTestType> records =\n            Util.randomRecords(numberOfRecords, SerializationTestTypeFactory.INT);\n        \n    final Map<Integer, ArrayDeque<SerializationTestType>> serializedRecords = new HashMap<>();\n    for (int i = 0; i < numberOfChannels; i++) {\n        serializedRecords.put(i, new ArrayDeque<>());\n    }\n\n        \n        \n    int index = 0;\n    for (SerializationTestType record : records) {\n        int randomChannel = index++ % numberOfChannels;\n        writer.emit(record, randomChannel);\n        serializedRecords.get(randomChannel).add(record);\n\n        writer.broadcastEmit(record);\n        for (int i = 0; i < numberOfChannels; i++) {\n            serializedRecords.get(i).add(record);\n        }\n    }\n\n    final int numberOfCreatedBuffers =\n            partition.getBufferPool().bestEffortGetNumOfUsedBuffers();\n        \n        \n    assertEquals(2 * numberOfRecords, numberOfCreatedBuffers);\n\n    for (int i = 0; i < numberOfChannels; i++) {\n            \n        assertEquals(numberOfRecords + 1, partition.getNumberOfQueuedBuffers(i));\n\n        final int excessRandomRecords = i < numberOfRecords % numberOfChannels ? 1 : 0;\n        final int numberOfRandomRecords =\n                numberOfRecords / numberOfChannels + excessRandomRecords;\n        final int numberOfTotalRecords = numberOfRecords + numberOfRandomRecords;\n            \n        verifyDeserializationResults(\n                partition.createSubpartitionView(i, new NoOpBufferAvailablityListener()),\n                deserializer,\n                serializedRecords.get(i),\n                numberOfRecords + 1,\n                numberOfTotalRecords);\n    }\n}", "summary_tokens": ["tests", "the", "number", "of", "requested", "buffers", "and", "results", "are", "correct", "in", "the", "case", "of", "switching", "modes", "between", "broadcast", "record", "writer", "broadcast", "emit", "ioreadable", "writable", "and", "broadcast", "record", "writer", "random", "emit", "ioreadable", "writable"], "project": "flink"}
{"id": 863, "code": "public static void eagerlyRegisterStreamConsumers(\n        final Properties configProps, final List<String> streams) {\n    if (!isUsingEfoRecordPublisher(configProps) || !isEagerEfoRegistrationType(configProps)) {\n        return;\n    }\n\n    registerStreamConsumers(configProps, streams);\n}", "summary_tokens": ["registers", "stream", "consumers", "for", "the", "given", "streams", "if", "efo", "is", "enabled", "with", "eager", "registration", "strategy"], "project": "flink"}
{"id": 2604, "code": "protected void afterReadPage() {}", "summary_tokens": ["after", "read", "a", "page", "we", "may", "need", "some", "initialization"], "project": "flink"}
{"id": 6033, "code": "public void testSuspendedOutOfCreated() throws Exception {\n    final InteractionsCountingTaskManagerGateway gateway =\n            new InteractionsCountingTaskManagerGateway();\n    final int parallelism = 10;\n    final SchedulerBase scheduler = createScheduler(gateway, parallelism);\n    final ExecutionGraph eg = scheduler.getExecutionGraph();\n\n    assertEquals(JobStatus.CREATED, eg.getState());\n\n        \n\n    scheduler.closeAsync();\n\n    assertEquals(JobStatus.SUSPENDED, eg.getState());\n    validateAllVerticesInState(eg, ExecutionState.CANCELED);\n    validateCancelRpcCalls(gateway, 0);\n\n    ensureCannotLeaveSuspendedState(scheduler, gateway);\n}", "summary_tokens": ["going", "into", "suspended", "out", "of", "created", "should", "immediately", "cancel", "everything", "and", "not", "send", "out", "rpc", "calls"], "project": "flink"}
{"id": 460, "code": "public void open(int taskNumber, int numTasks) throws IOException {\n    try {\n        connectionProvider.getOrEstablishConnection();\n    } catch (Exception e) {\n        throw new IOException(\"unable to open JDBC writer\", e);\n    }\n    jdbcStatementExecutor = createAndOpenStatementExecutor(statementExecutorFactory);\n    if (executionOptions.getBatchIntervalMs() != 0 && executionOptions.getBatchSize() != 1) {\n        this.scheduler =\n                Executors.newScheduledThreadPool(\n                        1, new ExecutorThreadFactory(\"jdbc-upsert-output-format\"));\n        this.scheduledFuture =\n                this.scheduler.scheduleWithFixedDelay(\n                        () -> {\n                            synchronized (JdbcOutputFormat.this) {\n                                if (!closed) {\n                                    try {\n                                        flush();\n                                    } catch (Exception e) {\n                                        flushException = e;\n                                    }\n                                }\n                            }\n                        },\n                        executionOptions.getBatchIntervalMs(),\n                        executionOptions.getBatchIntervalMs(),\n                        TimeUnit.MILLISECONDS);\n    }\n}", "summary_tokens": ["connects", "to", "the", "target", "database", "and", "initializes", "the", "prepared", "statement"], "project": "flink"}
{"id": 5428, "code": "public final TypeSerializerSnapshot<T> getPreviousSerializerSnapshot() {\n    return previousSerializerSnapshot;\n}", "summary_tokens": ["gets", "the", "previous", "serializer", "snapshot"], "project": "flink"}
{"id": 945, "code": "private void checkShutdown() {\n    if (shutdown != null) {\n        throw Utility.fixStackTrace(shutdown);\n    }\n}", "summary_tokens": ["check", "if", "we", "are", "in", "shutdown", "mode", "and", "if", "so", "throw", "an", "exception"], "project": "flink"}
{"id": 4957, "code": "public MutableObjectIterator<T> getIterator() throws InterruptedException, IOException {\n    synchronized (this.lock) {\n        while (this.exception == null && !this.writingDone) {\n            this.lock.wait(5000);\n        }\n    }\n\n    if (this.exception != null) {\n        throw new RuntimeException(\n                \"An error occurred creating the temp table.\", this.exception);\n    } else if (this.writingDone) {\n        final DataInputView in = this.buffer.flip();\n        return new InputViewIterator<>(in, this.serializer);\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["this", "method", "resets", "the", "input"], "project": "flink"}
{"id": 5934, "code": "public void testRecoverSortedCheckpoints() throws Exception {\n    final TestingStateHandleStore<CompletedCheckpoint> stateHandleStore =\n            builder.setGetAllSupplier(() -> createStateHandles(3)).build();\n    final CompletedCheckpointStore completedCheckpointStore =\n            createCompletedCheckpointStore(stateHandleStore);\n    final List<CompletedCheckpoint> recoveredCompletedCheckpoint =\n            completedCheckpointStore.getAllCheckpoints();\n    assertThat(recoveredCompletedCheckpoint.size(), is(3));\n    final List<Long> checkpointIds =\n            recoveredCompletedCheckpoint.stream()\n                    .map(CompletedCheckpoint::getCheckpointID)\n                    .collect(Collectors.toList());\n    assertThat(checkpointIds, contains(1L, 2L, 3L));\n}", "summary_tokens": ["we", "have", "three", "completed", "checkpoints", "0", "0", "0", "in", "the", "state", "handle", "store"], "project": "flink"}
{"id": 7635, "code": "public void testMaxParallelismWithConnectedKeyedStream() {\n    int maxParallelism = 42;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    DataStream<Integer> input1 = env.fromElements(1, 2, 3, 4).setMaxParallelism(128);\n    DataStream<Integer> input2 = env.fromElements(1, 2, 3, 4).setMaxParallelism(129);\n\n    env.getConfig().setMaxParallelism(maxParallelism);\n\n    DataStream<Integer> keyedResult =\n            input1.connect(input2)\n                    .keyBy(value -> value, value -> value)\n                    .map(new NoOpIntCoMap());\n\n    keyedResult.addSink(new DiscardingSink<>());\n\n    StreamGraph graph = env.getStreamGraph();\n\n    StreamNode keyedResultNode = graph.getStreamNode(keyedResult.getId());\n\n    StreamPartitioner<?> streamPartitioner1 =\n            keyedResultNode.getInEdges().get(0).getPartitioner();\n    StreamPartitioner<?> streamPartitioner2 =\n            keyedResultNode.getInEdges().get(1).getPartitioner();\n}", "summary_tokens": ["tests", "that", "the", "max", "parallelism", "is", "properly", "set", "for", "connected", "streams"], "project": "flink"}
{"id": 4578, "code": "public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\n    if (cause instanceof TransportException) {\n        notifyAllChannelsOfErrorAndClose(cause);\n    } else {\n        final SocketAddress remoteAddr = ctx.channel().remoteAddress();\n\n        final TransportException tex;\n\n            \n        if (cause.getMessage() != null\n                && cause.getMessage().contains(\"Connection reset by peer\")) {\n            tex =\n                    new RemoteTransportException(\n                            \"Lost connection to task manager '\"\n                                    + remoteAddr\n                                    + \"'. \"\n                                    + \"This indicates that the remote task manager was lost.\",\n                            remoteAddr,\n                            cause);\n        } else {\n            final SocketAddress localAddr = ctx.channel().localAddress();\n            tex =\n                    new LocalTransportException(\n                            String.format(\n                                    \"%s (connection to '%s')\", cause.getMessage(), remoteAddr),\n                            localAddr,\n                            cause);\n        }\n\n        notifyAllChannelsOfErrorAndClose(tex);\n    }\n}", "summary_tokens": ["called", "on", "exceptions", "in", "the", "client", "handler", "pipeline"], "project": "flink"}
{"id": 1734, "code": "public String getName() {\n    final String path = uri.getPath();\n    final int slash = path.lastIndexOf(SEPARATOR);\n    return path.substring(slash + 1);\n}", "summary_tokens": ["returns", "the", "final", "component", "of", "this", "path", "i"], "project": "flink"}
{"id": 8883, "code": "private Operation convertCreateDatabase(SqlCreateDatabase sqlCreateDatabase) {\n    String[] fullDatabaseName = sqlCreateDatabase.fullDatabaseName();\n    if (fullDatabaseName.length > 2) {\n        throw new ValidationException(\"create database identifier format error\");\n    }\n    String catalogName =\n            (fullDatabaseName.length == 1)\n                    ? catalogManager.getCurrentCatalog()\n                    : fullDatabaseName[0];\n    String databaseName =\n            (fullDatabaseName.length == 1) ? fullDatabaseName[0] : fullDatabaseName[1];\n    boolean ignoreIfExists = sqlCreateDatabase.isIfNotExists();\n    String databaseComment =\n            sqlCreateDatabase\n                    .getComment()\n                    .map(comment -> comment.getNlsString().getValue())\n                    .orElse(null);\n        \n    Map<String, String> properties = new HashMap<>();\n    sqlCreateDatabase\n            .getPropertyList()\n            .getList()\n            .forEach(\n                    p ->\n                            properties.put(\n                                    ((SqlTableOption) p).getKeyString(),\n                                    ((SqlTableOption) p).getValueString()));\n    CatalogDatabase catalogDatabase = new CatalogDatabaseImpl(properties, databaseComment);\n    return new CreateDatabaseOperation(\n            catalogName, databaseName, catalogDatabase, ignoreIfExists);\n}", "summary_tokens": ["convert", "create", "database", "statement"], "project": "flink"}
{"id": 6864, "code": "public DefaultConfigurableOptionsFactory setMaxLogFileSize(String maxLogFileSize) {\n    Preconditions.checkArgument(\n            MemorySize.parseBytes(maxLogFileSize) >= 0,\n            \"Invalid configuration \" + maxLogFileSize + \" for max log file size.\");\n    setInternal(LOG_MAX_FILE_SIZE.key(), maxLogFileSize);\n\n    return this;\n}", "summary_tokens": ["the", "maximum", "size", "of", "rocks", "db", "s", "file", "used", "for", "logging"], "project": "flink"}
{"id": 6617, "code": "public void abortCheckpoint() throws Exception {\n\n    final int chkCount = 4;\n    final int aborted = chkCount - 2;\n    List<TestingTaskStateSnapshot> taskStateSnapshots = storeStates(chkCount);\n    taskLocalStateStore.abortCheckpoint(aborted);\n    checkPrunedAndDiscarded(taskStateSnapshots, aborted, aborted + 1);\n    checkStoredAsExpected(taskStateSnapshots, 0, aborted);\n    checkStoredAsExpected(taskStateSnapshots, aborted + 1, chkCount);\n}", "summary_tokens": ["tests", "pruning", "of", "target", "previous", "checkpoints", "if", "that", "checkpoint", "is", "aborted"], "project": "flink"}
{"id": 7872, "code": "public void testOpenCloseAndTimestamps() throws Exception {\n    final TwoInputStreamTaskTestHarness<String, Integer, String> testHarness =\n            new TwoInputStreamTaskTestHarness<>(\n                    TwoInputStreamTask::new,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n    testHarness.setupOutputForSingletonOperatorChain();\n\n    StreamConfig streamConfig = testHarness.getStreamConfig();\n    CoStreamMap<String, Integer, String> coMapOperator =\n            new CoStreamMap<>(new TestOpenCloseMapFunction());\n    streamConfig.setStreamOperator(coMapOperator);\n    streamConfig.setOperatorID(new OperatorID());\n\n    long initialTime = 0L;\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    testHarness.invoke();\n    testHarness.waitForTaskRunning();\n\n    testHarness.processElement(new StreamRecord<>(\"Hello\", initialTime + 1), 0, 0);\n    expectedOutput.add(new StreamRecord<>(\"Hello\", initialTime + 1));\n\n        \n    testHarness.waitForInputProcessing();\n\n    testHarness.processElement(new StreamRecord<>(1337, initialTime + 2), 1, 0);\n\n    expectedOutput.add(new StreamRecord<>(\"1337\", initialTime + 2));\n\n    testHarness.waitForInputProcessing();\n\n    testHarness.endInput();\n\n    testHarness.waitForTaskCompletion();\n\n    Assert.assertTrue(\n            \"RichFunction methods were not called.\", TestOpenCloseMapFunction.closeCalled);\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n}", "summary_tokens": ["this", "test", "verifies", "that", "open", "and", "close", "are", "correctly", "called"], "project": "flink"}
{"id": 795, "code": "public int getDescribeStreamMaxRetries() {\n    return describeStreamMaxRetries;\n}", "summary_tokens": ["get", "maximum", "retry", "attempts", "for", "the", "describe", "stream", "operation"], "project": "flink"}
{"id": 2524, "code": "private static void validateCharacterVal(\n        ReadableConfig tableOptions, ConfigOption<String> option, boolean unescape) {\n    if (tableOptions.getOptional(option).isPresent()) {\n        final String value =\n                unescape\n                        ? StringEscapeUtils.unescapeJava(tableOptions.get(option))\n                        : tableOptions.get(option);\n        if (value.length() != 1) {\n            throw new ValidationException(\n                    String.format(\n                            \"Option '%s.%s' must be a string with single character, but was: %s\",\n                            IDENTIFIER, option.key(), tableOptions.get(option)));\n        }\n    }\n}", "summary_tokens": ["validates", "the", "option", "option", "value", "must", "be", "a", "character"], "project": "flink"}
{"id": 5523, "code": "public boolean containsJob(JobID jobId) {\n    Preconditions.checkState(\n            DefaultJobLeaderService.State.STARTED == state,\n            \"The service is currently not running.\");\n\n    return jobLeaderServices.containsKey(jobId);\n}", "summary_tokens": ["check", "whether", "the", "service", "monitors", "the", "given", "job"], "project": "flink"}
{"id": 1574, "code": "public static <T> Class<T> typeToClass(Type t) {\n    if (t instanceof Class) {\n        return (Class<T>) t;\n    } else if (t instanceof ParameterizedType) {\n        return ((Class<T>) ((ParameterizedType) t).getRawType());\n    }\n    throw new IllegalArgumentException(\"Cannot convert type to class\");\n}", "summary_tokens": ["convert", "parameterized", "type", "or", "class", "to", "a", "class"], "project": "flink"}
{"id": 655, "code": "public void testRestoreFromEmptyStateWithPartitions() throws Exception {\n    final List<KafkaTopicPartition> partitions = new ArrayList<>(PARTITION_STATE.keySet());\n\n    final DummyFlinkKafkaConsumer<String> consumerFunction =\n            new DummyFlinkKafkaConsumer<>(\n                    TOPICS, partitions, FlinkKafkaConsumerBase.PARTITION_DISCOVERY_DISABLED);\n\n    StreamSource<String, DummyFlinkKafkaConsumer<String>> consumerOperator =\n            new StreamSource<>(consumerFunction);\n\n    final AbstractStreamOperatorTestHarness<String> testHarness =\n            new AbstractStreamOperatorTestHarness<>(consumerOperator, 1, 1, 0);\n\n    testHarness.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);\n\n    testHarness.setup();\n\n        \n    testHarness.initializeState(\n            OperatorSnapshotUtil.getResourceFilename(\n                    \"kafka-consumer-migration-test-flink\"\n                            + testMigrateVersion\n                            + \"-empty-state-snapshot\"));\n\n    testHarness.open();\n\n        \n        \n        \n        \n    final HashMap<KafkaTopicPartition, Long> expectedSubscribedPartitionsWithStartOffsets =\n            new HashMap<>();\n    for (KafkaTopicPartition partition : PARTITION_STATE.keySet()) {\n        expectedSubscribedPartitionsWithStartOffsets.put(\n                partition, KafkaTopicPartitionStateSentinel.EARLIEST_OFFSET);\n    }\n\n        \n    assertTrue(consumerFunction.getSubscribedPartitionsToStartOffsets() != null);\n    assertTrue(!consumerFunction.getSubscribedPartitionsToStartOffsets().isEmpty());\n    assertEquals(\n            expectedSubscribedPartitionsWithStartOffsets,\n            consumerFunction.getSubscribedPartitionsToStartOffsets());\n\n        \n    assertTrue(consumerFunction.getRestoredState() != null);\n    assertTrue(!consumerFunction.getSubscribedPartitionsToStartOffsets().isEmpty());\n    for (Map.Entry<KafkaTopicPartition, Long> expectedEntry :\n            expectedSubscribedPartitionsWithStartOffsets.entrySet()) {\n        assertEquals(\n                expectedEntry.getValue(),\n                consumerFunction.getRestoredState().get(expectedEntry.getKey()));\n    }\n\n    consumerOperator.close();\n    consumerOperator.cancel();\n}", "summary_tokens": ["test", "restoring", "from", "an", "empty", "state", "taken", "using", "a", "previous", "flink", "version", "when", "some", "partitions", "could", "be", "found", "for", "topics"], "project": "flink"}
{"id": 7283, "code": "public void onTimer(long timestamp, OnTimerContext ctx, Collector<O> out) throws Exception {}", "summary_tokens": ["called", "when", "a", "timer", "set", "using", "timer", "service", "fires"], "project": "flink"}
{"id": 2180, "code": "public void testReconfigureWithPreviouslyNonregisteredSubclasses() throws Exception {\n        \n    PojoSerializer<TestUserClass> pojoSerializer =\n            (PojoSerializer<TestUserClass>) type.createSerializer(new ExecutionConfig());\n\n        \n    pojoSerializer.getSubclassSerializer(SubTestUserClassA.class);\n    pojoSerializer.getSubclassSerializer(SubTestUserClassB.class);\n\n        \n    assertEquals(2, pojoSerializer.getSubclassSerializerCache().size());\n    assertTrue(\n            pojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassA.class));\n    assertTrue(\n            pojoSerializer.getSubclassSerializerCache().containsKey(SubTestUserClassB.class));\n\n        \n    assertTrue(pojoSerializer.getRegisteredClasses().isEmpty());\n    assertEquals(0, pojoSerializer.getRegisteredSerializers().length);\n\n        \n    TypeSerializerSnapshot pojoSerializerConfigSnapshot =\n            pojoSerializer.snapshotConfiguration();\n    byte[] serializedConfig;\n    try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n        TypeSerializerSnapshotSerializationUtil.writeSerializerSnapshot(\n                new DataOutputViewStreamWrapper(out),\n                pojoSerializerConfigSnapshot,\n                pojoSerializer);\n        serializedConfig = out.toByteArray();\n    }\n\n        \n        \n    ExecutionConfig newExecutionConfig = new ExecutionConfig();\n    newExecutionConfig.registerPojoType(SubTestUserClassA.class);\n    newExecutionConfig.registerPojoType(SubTestUserClassB.class);\n    pojoSerializer = (PojoSerializer<TestUserClass>) type.createSerializer(newExecutionConfig);\n\n        \n    try (ByteArrayInputStream in = new ByteArrayInputStream(serializedConfig)) {\n        pojoSerializerConfigSnapshot =\n                TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(\n                        new DataInputViewStreamWrapper(in),\n                        Thread.currentThread().getContextClassLoader(),\n                        pojoSerializer);\n    }\n\n        \n        \n        \n    @SuppressWarnings(\"unchecked\")\n    TypeSerializerSchemaCompatibility<TestUserClass> compatResult =\n            pojoSerializerConfigSnapshot.resolveSchemaCompatibility(pojoSerializer);\n    assertTrue(compatResult.isCompatibleWithReconfiguredSerializer());\n    assertThat(compatResult.getReconfiguredSerializer(), instanceOf(PojoSerializer.class));\n\n    PojoSerializer<TestUserClass> reconfiguredPojoSerializer =\n            (PojoSerializer<TestUserClass>) compatResult.getReconfiguredSerializer();\n    assertEquals(2, reconfiguredPojoSerializer.getSubclassSerializerCache().size());\n    assertTrue(\n            reconfiguredPojoSerializer\n                    .getSubclassSerializerCache()\n                    .containsKey(SubTestUserClassA.class));\n    assertTrue(\n            reconfiguredPojoSerializer\n                    .getSubclassSerializerCache()\n                    .containsKey(SubTestUserClassB.class));\n    assertEquals(2, reconfiguredPojoSerializer.getRegisteredClasses().size());\n    assertTrue(\n            reconfiguredPojoSerializer\n                    .getRegisteredClasses()\n                    .containsKey(SubTestUserClassA.class));\n    assertTrue(\n            reconfiguredPojoSerializer\n                    .getRegisteredClasses()\n                    .containsKey(SubTestUserClassB.class));\n}", "summary_tokens": ["tests", "that", "previous", "pojo", "serializer", "did", "not", "have", "registrations", "and", "created", "cached", "serializers", "for", "subclasses", "on", "restore", "it", "had", "those", "subclasses", "registered"], "project": "flink"}
{"id": 3736, "code": "public void setSerializer(TypeSerializerFactory<?> serializer) {\n    this.serializer = serializer;\n}", "summary_tokens": ["sets", "the", "serializer", "for", "this", "plan", "node"], "project": "flink"}
{"id": 1129, "code": "public void add(Integer value) {\n    this.max = Math.max(this.max, value);\n}", "summary_tokens": ["consider", "using", "add", "int", "instead", "for", "primitive", "integer", "values"], "project": "flink"}
{"id": 9119, "code": "public boolean isCollected() {\n    return collected;\n}", "summary_tokens": ["whether", "collect", "object", "has", "been", "called"], "project": "flink"}
{"id": 3251, "code": "public static <OLD, NEW, EV> DataSet<Edge<NEW, EV>> translateEdgeIds(\n        DataSet<Edge<OLD, EV>> edges, TranslateFunction<OLD, NEW> translator, int parallelism) {\n    Preconditions.checkNotNull(edges);\n    Preconditions.checkNotNull(translator);\n\n    Class<Edge<NEW, EV>> edgeClass = (Class<Edge<NEW, EV>>) (Class<? extends Edge>) Edge.class;\n    TypeInformation<OLD> oldType =\n            ((TupleTypeInfo<Edge<OLD, EV>>) edges.getType()).getTypeAt(0);\n    TypeInformation<NEW> newType =\n            TypeExtractor.getUnaryOperatorReturnType(\n                    translator,\n                    TranslateFunction.class,\n                    0,\n                    1,\n                    new int[] {1},\n                    oldType,\n                    null,\n                    false);\n    TypeInformation<EV> edgeValueType =\n            ((TupleTypeInfo<Edge<OLD, EV>>) edges.getType()).getTypeAt(2);\n\n    TupleTypeInfo<Edge<NEW, EV>> returnType =\n            new TupleTypeInfo<>(edgeClass, newType, newType, edgeValueType);\n\n    return edges.map(new TranslateEdgeId<>(translator))\n            .returns(returnType)\n            .setParallelism(parallelism)\n            .name(\"Translate edge IDs\");\n}", "summary_tokens": ["translate", "edge", "ids", "using", "the", "given", "translate", "function"], "project": "flink"}
{"id": 1854, "code": "public void makeSpace(int numFields) {\n    final int oldNumFields = this.numFields;\n        \n    if (this.offsets == null) {\n        this.offsets = new int[numFields];\n    } else if (this.offsets.length < numFields) {\n        int[] newOffs = new int[Math.max(numFields + 1, oldNumFields << 1)];\n        System.arraycopy(this.offsets, 0, newOffs, 0, oldNumFields);\n        this.offsets = newOffs;\n    }\n\n    if (this.lengths == null) {\n        this.lengths = new int[numFields];\n    } else if (this.lengths.length < numFields) {\n        int[] newLens = new int[Math.max(numFields + 1, oldNumFields << 1)];\n        System.arraycopy(this.lengths, 0, newLens, 0, oldNumFields);\n        this.lengths = newLens;\n    }\n\n    if (this.readFields == null) {\n        this.readFields = new Value[numFields];\n    } else if (this.readFields.length < numFields) {\n        Value[] newFields = new Value[Math.max(numFields + 1, oldNumFields << 1)];\n        System.arraycopy(this.readFields, 0, newFields, 0, oldNumFields);\n        this.readFields = newFields;\n    }\n\n    if (this.writeFields == null) {\n        this.writeFields = new Value[numFields];\n    } else if (this.writeFields.length < numFields) {\n        Value[] newFields = new Value[Math.max(numFields + 1, oldNumFields << 1)];\n        System.arraycopy(this.writeFields, 0, newFields, 0, oldNumFields);\n        this.writeFields = newFields;\n    }\n}", "summary_tokens": ["reserves", "space", "for", "at", "least", "the", "given", "number", "of", "fields", "in", "the", "internal", "arrays"], "project": "flink"}
{"id": 4664, "code": "private void writeLargeRecord(\n        ByteBuffer record, int targetSubpartition, DataType dataType, boolean isBroadcast)\n        throws IOException {\n    fileWriter.startNewRegion(isBroadcast);\n\n    List<BufferWithChannel> toWrite = new ArrayList<>();\n    Queue<MemorySegment> segments = getWriteSegments();\n\n    while (record.hasRemaining()) {\n        if (segments.isEmpty()) {\n            fileWriter.writeBuffers(toWrite);\n            toWrite.clear();\n            segments = getWriteSegments();\n        }\n\n        int toCopy = Math.min(record.remaining(), networkBufferSize);\n        MemorySegment writeBuffer = checkNotNull(segments.poll());\n        writeBuffer.put(0, record, toCopy);\n\n        NetworkBuffer buffer = new NetworkBuffer(writeBuffer, (buf) -> {}, dataType, toCopy);\n        BufferWithChannel bufferWithChannel = new BufferWithChannel(buffer, targetSubpartition);\n        updateStatistics(buffer, isBroadcast);\n        toWrite.add(compressBufferIfPossible(bufferWithChannel));\n    }\n\n    fileWriter.writeBuffers(toWrite);\n}", "summary_tokens": ["spills", "the", "large", "record", "into", "the", "target", "partitioned", "file", "as", "a", "separate", "data", "region"], "project": "flink"}
{"id": 2181, "code": "public void testOutputBufferedBeingClearedInCaseOfException() throws Exception {\n    ExecutionConfig executionConfig = new ExecutionConfig();\n    executionConfig.registerTypeWithKryoSerializer(\n            TestRecord.class, new TestRecordSerializer());\n    executionConfig.registerKryoType(TestRecord.class);\n\n    KryoSerializer<TestRecord> kryoSerializer =\n            new KryoSerializer<TestRecord>(TestRecord.class, executionConfig);\n\n    int size = 94;\n    int bufferSize = 150;\n\n    TestRecord testRecord = new TestRecord(size);\n\n    TestDataOutputView target = new TestDataOutputView(bufferSize);\n\n    kryoSerializer.serialize(testRecord, target);\n\n    try {\n        kryoSerializer.serialize(testRecord, target);\n        Assert.fail(\"Expected an EOFException.\");\n    } catch (EOFException eofException) {\n            \n            \n    }\n\n    TestRecord actualRecord =\n            kryoSerializer.deserialize(\n                    new DataInputViewStreamWrapper(\n                            new ByteArrayInputStream(target.getBuffer())));\n\n    Assert.assertEquals(testRecord, actualRecord);\n\n    target.clear();\n\n        \n        \n        \n    kryoSerializer.serialize(testRecord, target);\n\n    byte[] buffer = target.getBuffer();\n    int counter = 0;\n\n    for (int i = 0; i < buffer.length; i++) {\n        if (buffer[i] == 42) {\n            counter++;\n        }\n    }\n\n    Assert.assertEquals(size, counter);\n}", "summary_tokens": ["tests", "that", "the", "kryo", "output", "buffer", "is", "cleared", "in", "case", "of", "an", "exception"], "project": "flink"}
{"id": 5734, "code": "public int getRequestId() {\n    return requestId;\n}", "summary_tokens": ["returns", "the", "id", "of", "the", "sampling", "request"], "project": "flink"}
{"id": 5324, "code": "", "summary_tokens": ["closes", "this", "shuffle", "master", "service", "which", "should", "release", "all", "resources"], "project": "flink"}
{"id": 6490, "code": "public void testFileServing() throws Exception {\n    final Time cacheEntryDuration = Time.milliseconds(1000L);\n\n    final Queue<CompletableFuture<TransientBlobKey>> requestFileUploads = new ArrayDeque<>(1);\n\n    requestFileUploads.add(CompletableFuture.completedFuture(transientBlobKey1));\n\n    final TestTaskManagerFileHandler testTaskManagerFileHandler =\n            createTestTaskManagerFileHandler(\n                    cacheEntryDuration, requestFileUploads, EXPECTED_TASK_MANAGER_ID);\n\n    final File outputFile = temporaryFolder.newFile();\n    final TestingChannelHandlerContext testingContext =\n            new TestingChannelHandlerContext(outputFile);\n\n    testTaskManagerFileHandler.respondToRequest(\n            testingContext, HTTP_REQUEST, handlerRequest, null);\n\n    assertThat(outputFile.length(), is(greaterThan(0L)));\n    assertThat(FileUtils.readFileUtf8(outputFile), is(equalTo(fileContent1)));\n}", "summary_tokens": ["tests", "that", "the", "abstract", "task", "manager", "file", "handler", "serves", "the", "requested", "file"], "project": "flink"}
{"id": 2208, "code": "public void testSetPositionWhenBufferIsFull() throws Exception {\n    stream.write(new byte[BUFFER_SIZE]);\n\n        \n    Assert.assertEquals(BUFFER_SIZE, stream.getBuf().length);\n\n        \n    Assert.assertEquals(BUFFER_SIZE, stream.getPosition());\n\n    stream.setPosition(BUFFER_SIZE);\n\n        \n    Assert.assertEquals(BUFFER_SIZE, stream.getPosition());\n}", "summary_tokens": ["test", "setting", "position", "which", "is", "exactly", "the", "same", "with", "the", "buffer", "size"], "project": "flink"}
{"id": 9555, "code": "public void batchFailoverWithRebalanceBarrier() throws Exception {\n\n    final StreamExecutionEnvironment env = getExecutionEnvironment();\n\n    DataStreamSource<String> source = env.fromElements(\"foo\", \"bar\");\n\n    SingleOutputStreamOperator<String> mapped =\n            source.map(new SuffixAttemptId(\"a\"))\n                    .map(new SuffixAttemptId(\"b\"))\n                    .rebalance()\n                    .map(new SuffixAttemptId(\"c\"))\n                    .map(new OnceFailingMapper(\"d\"));\n\n    try (CloseableIterator<String> result = mapped.executeAndCollect()) {\n\n            \n            \n        assertThat(\n                iteratorToList(result),\n                containsInAnyOrder(\"foo-a0-b0-c1-d1\", \"bar-a0-b0-c1-d1\"));\n    }\n}", "summary_tokens": ["we", "induce", "a", "failure", "in", "the", "last", "mapper"], "project": "flink"}
{"id": 1139, "code": "public static List<Tuple2<String, DistributedCacheEntry>> parseCachedFilesFromString(\n        List<String> files) {\n    return files.stream()\n            .map(ConfigurationUtils::parseMap)\n            .map(\n                    m ->\n                            Tuple2.of(\n                                    m.get(\"name\"),\n                                    new DistributedCacheEntry(\n                                            m.get(\"path\"),\n                                            Optional.ofNullable(m.get(\"executable\"))\n                                                    .map(Boolean::parseBoolean)\n                                                    .orElse(false))))\n            .collect(Collectors.toList());\n}", "summary_tokens": ["parses", "a", "list", "of", "distributed", "cache", "entries", "encoded", "in", "a", "string"], "project": "flink"}
{"id": 5049, "code": "public boolean write(T record) throws IOException {\n        \n    if (this.currentSortBufferOffset > this.lastEntryOffset) {\n        if (memoryAvailable()) {\n            this.currentSortBufferSegment = nextMemorySegment();\n            this.sortBuffer.add(this.currentSortBufferSegment);\n            this.outView.set(this.currentSortBufferSegment);\n            this.currentSortBufferOffset = 0;\n            this.sortBufferBytes += this.segmentSize;\n        } else {\n            return false;\n        }\n    }\n\n        \n    try {\n        this.comparator.writeWithKeyNormalization(record, this.outView);\n        this.numRecords++;\n        this.currentSortBufferOffset += this.recordSize;\n        return true;\n    } catch (EOFException eofex) {\n        throw new IOException(\n                \"Error: Serialization consumes more bytes than announced by the serializer.\");\n    }\n}", "summary_tokens": ["writes", "a", "given", "record", "to", "this", "sort", "buffer"], "project": "flink"}
{"id": 8922, "code": "public static List<RelCollation> snapshot(RelMetadataQuery mq, RelNode input) {\n    return mq.collations(input);\n}", "summary_tokens": ["helper", "method", "to", "determine", "a", "org"], "project": "flink"}
{"id": 2367, "code": "public String[] getTrimmedStrings(String name, String... defaultValue) {\n    String valueString = get(name);\n    if (null == valueString) {\n        return defaultValue;\n    } else {\n        return StringUtils.getTrimmedStrings(valueString);\n    }\n}", "summary_tokens": ["get", "the", "comma", "delimited", "values", "of", "the", "code", "name", "code", "property", "as", "an", "array", "of", "code", "string", "code", "s", "trimmed", "of", "the", "leading", "and", "trailing", "whitespace"], "project": "flink"}
{"id": 2361, "code": "public void setPattern(String name, Pattern pattern) {\n    assert pattern != null : \"Pattern cannot be null\";\n    set(name, pattern.pattern());\n}", "summary_tokens": ["set", "the", "given", "property", "to", "code", "pattern", "code"], "project": "flink"}
{"id": 853, "code": "public static Properties replaceDeprecatedProducerKeys(Properties configProps) {\n        \n    if (configProps.containsKey(ProducerConfigConstants.COLLECTION_MAX_COUNT)) {\n        configProps.setProperty(\n                COLLECTION_MAX_COUNT,\n                configProps.getProperty(ProducerConfigConstants.COLLECTION_MAX_COUNT));\n        configProps.remove(ProducerConfigConstants.COLLECTION_MAX_COUNT);\n    }\n        \n    if (configProps.containsKey(ProducerConfigConstants.AGGREGATION_MAX_COUNT)) {\n        configProps.setProperty(\n                AGGREGATION_MAX_COUNT,\n                configProps.getProperty(ProducerConfigConstants.AGGREGATION_MAX_COUNT));\n        configProps.remove(ProducerConfigConstants.AGGREGATION_MAX_COUNT);\n    }\n    return configProps;\n}", "summary_tokens": ["replace", "deprecated", "configuration", "properties", "for", "flink", "kinesis", "producer"], "project": "flink"}
{"id": 511, "code": "public List<String> getTransactionsToAbort(Map<Integer, Map<Long, String>> openTransactions) {\n    final List<String> transactionalIdsToAbort = new ArrayList<>();\n    for (final Map.Entry<Integer, Map<Long, String>> subtaskOffsetMapping :\n            openTransactions.entrySet()) {\n        final Map<Long, String> checkpointOffsetTransactionalIdMapping =\n                subtaskOffsetMapping.getValue();\n            \n        if (checkpointOffsetTransactionalIdMapping.isEmpty()) {\n            continue;\n        }\n            \n            \n            \n        if (Collections.min(checkpointOffsetTransactionalIdMapping.keySet())\n                        == MINIMUM_CHECKPOINT_OFFSET\n                && subtaskOffsetMapping.getKey() % numberOfParallelSubtasks == subtaskId) {\n            transactionalIdsToAbort.addAll(checkpointOffsetTransactionalIdMapping.values());\n        } else {\n                \n                \n            for (final Map.Entry<Long, String> offsetTransactionId :\n                    checkpointOffsetTransactionalIdMapping.entrySet()) {\n                if (!hasSameSubtaskWithHigherCheckpoint(\n                        subtaskOffsetMapping.getKey(), offsetTransactionId.getKey())) {\n                    continue;\n                }\n                transactionalIdsToAbort.add(offsetTransactionId.getValue());\n            }\n        }\n    }\n    return transactionalIdsToAbort;\n}", "summary_tokens": ["iterates", "through", "all", "open", "transactions", "and", "filters", "for", "the", "following", "attributes"], "project": "flink"}
{"id": 4086, "code": "public void setBlobServerAddress(InetSocketAddress blobServerAddress) {\n    serverAddress = checkNotNull(blobServerAddress);\n}", "summary_tokens": ["sets", "the", "address", "of", "the", "blob", "server"], "project": "flink"}
{"id": 396, "code": "public void setClusterByExprForClause(String clause, HiveParserASTNode ast) {\n    destToClusterby.put(clause, ast);\n}", "summary_tokens": ["set", "the", "cluster", "by", "ast", "for", "the", "clause"], "project": "flink"}
{"id": 4425, "code": "public List<IntermediateResultPartition> finishAllBlockingPartitions() {\n    List<IntermediateResultPartition> finishedBlockingPartitions = null;\n\n    for (IntermediateResultPartition partition : resultPartitions.values()) {\n        if (partition.getResultType().isBlocking()) {\n\n            partition.markFinished();\n\n            if (finishedBlockingPartitions == null) {\n                finishedBlockingPartitions = new LinkedList<>();\n            }\n\n            finishedBlockingPartitions.add(partition);\n        }\n    }\n\n    if (finishedBlockingPartitions == null) {\n        return Collections.emptyList();\n    } else {\n        return finishedBlockingPartitions;\n    }\n}", "summary_tokens": ["returns", "all", "blocking", "result", "partitions", "whose", "receivers", "can", "be", "scheduled", "updated"], "project": "flink"}
{"id": 1284, "code": "public Ordering getGroupOrderForInputOne() {\n    return getGroupOrder(0);\n}", "summary_tokens": ["gets", "the", "order", "of", "elements", "within", "a", "group", "for", "the", "first", "input"], "project": "flink"}
{"id": 4141, "code": "static MessageDigest createMessageDigest() {\n    try {\n        return MessageDigest.getInstance(HASHING_ALGORITHM);\n    } catch (NoSuchAlgorithmException e) {\n        throw new RuntimeException(\n                \"Cannot instantiate the message digest algorithm \" + HASHING_ALGORITHM, e);\n    }\n}", "summary_tokens": ["creates", "a", "new", "instance", "of", "the", "message", "digest", "to", "use", "for", "the", "blob", "key", "computation"], "project": "flink"}
{"id": 7922, "code": "public TestCheckpointedInputGateBuilder withTestChannels() {\n    this.gateBuilder = this::buildTestGate;\n    return this;\n}", "summary_tokens": ["uses", "test", "input", "channel", "test", "input", "channels"], "project": "flink"}
{"id": 820, "code": "public static StreamShardMetadata convertToStreamShardMetadata(\n        KinesisStreamShard kinesisStreamShard) {\n    StreamShardMetadata streamShardMetadata = new StreamShardMetadata();\n\n    streamShardMetadata.setStreamName(kinesisStreamShard.getStreamName());\n    streamShardMetadata.setShardId(kinesisStreamShard.getShard().getShardId());\n    streamShardMetadata.setParentShardId(kinesisStreamShard.getShard().getParentShardId());\n    streamShardMetadata.setAdjacentParentShardId(\n            kinesisStreamShard.getShard().getAdjacentParentShardId());\n\n    if (kinesisStreamShard.getShard().getHashKeyRange() != null) {\n        streamShardMetadata.setStartingHashKey(\n                kinesisStreamShard.getShard().getHashKeyRange().getStartingHashKey());\n        streamShardMetadata.setEndingHashKey(\n                kinesisStreamShard.getShard().getHashKeyRange().getEndingHashKey());\n    }\n\n    if (kinesisStreamShard.getShard().getSequenceNumberRange() != null) {\n        streamShardMetadata.setStartingSequenceNumber(\n                kinesisStreamShard\n                        .getShard()\n                        .getSequenceNumberRange()\n                        .getStartingSequenceNumber());\n        streamShardMetadata.setEndingSequenceNumber(\n                kinesisStreamShard\n                        .getShard()\n                        .getSequenceNumberRange()\n                        .getEndingSequenceNumber());\n    }\n\n    return streamShardMetadata;\n}", "summary_tokens": ["utility", "function", "to", "convert", "kinesis", "stream", "shard", "into", "the", "new", "stream", "shard", "metadata", "model"], "project": "flink"}
{"id": 3056, "code": "Lockable<SharedBufferNode> getEntry(NodeId nodeId) {\n    try {\n        Lockable<SharedBufferNode> lockableFromCache = entryCache.getIfPresent(nodeId);\n        if (Objects.nonNull(lockableFromCache)) {\n            return lockableFromCache;\n        } else {\n            Lockable<SharedBufferNode> lockableFromState = entries.get(nodeId);\n            if (Objects.nonNull(lockableFromState)) {\n                entryCache.put(nodeId, lockableFromState);\n            }\n            return lockableFromState;\n        }\n    } catch (Exception ex) {\n        throw new WrappingRuntimeException(ex);\n    }\n}", "summary_tokens": ["it", "always", "returns", "node", "either", "from", "state", "or", "cache"], "project": "flink"}
{"id": 99, "code": "public static Region getRegion(final Properties configProps) {\n    return Region.of(configProps.getProperty(AWSConfigConstants.AWS_REGION));\n}", "summary_tokens": ["creates", "a", "region", "object", "from", "the", "given", "properties"], "project": "flink"}
{"id": 1877, "code": "public @Nullable Set<String> getFieldNames(boolean includeNamedPositions) {\n    if (fieldByName != null) {\n        return fieldByName.keySet();\n    }\n    if (includeNamedPositions && positionByName != null) {\n        return positionByName.keySet();\n    }\n    return null;\n}", "summary_tokens": ["returns", "the", "set", "of", "field", "names", "if", "this", "row", "operates", "in", "name", "based", "field", "mode", "otherwise", "null"], "project": "flink"}
{"id": 1075, "code": "public void addDefaultKryoSerializer(\n        Class<?> type, Class<? extends Serializer<?>> serializerClass) {\n    if (type == null || serializerClass == null) {\n        throw new NullPointerException(\"Cannot register null class or serializer.\");\n    }\n    defaultKryoSerializerClasses.put(type, serializerClass);\n}", "summary_tokens": ["adds", "a", "new", "kryo", "default", "serializer", "to", "the", "runtime"], "project": "flink"}
{"id": 9679, "code": "public long getWatermark() {\n    long watermark = Long.MAX_VALUE;\n\n    for (EventGenerator<K, E> eventGenerator : subGeneratorLists) {\n        watermark = Math.min(watermark, eventGenerator.getLocalWatermark());\n    }\n    return watermark;\n}", "summary_tokens": ["a", "global", "watermark", "that", "is", "the", "minimum", "of", "all", "individual", "watermarks", "of", "the", "sub", "generators"], "project": "flink"}
{"id": 9642, "code": "public void testProcessFunctionSideOutputWithWrongTag() throws Exception {\n    final OutputTag<String> sideOutputTag1 = new OutputTag<String>(\"side\") {};\n    final OutputTag<String> sideOutputTag2 = new OutputTag<String>(\"other-side\") {};\n\n    TestListResultSink<String> sideOutputResultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(3);\n\n    DataStream<Integer> dataStream = see.fromCollection(elements);\n\n    dataStream\n            .process(\n                    new ProcessFunction<Integer, Integer>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public void processElement(\n                                Integer value, Context ctx, Collector<Integer> out)\n                                throws Exception {\n                            out.collect(value);\n                            ctx.output(sideOutputTag2, \"sideout-\" + String.valueOf(value));\n                        }\n                    })\n            .getSideOutput(sideOutputTag1)\n            .addSink(sideOutputResultSink);\n\n    see.execute();\n\n    assertEquals(Arrays.asList(), sideOutputResultSink.getSortedResult());\n}", "summary_tokens": ["test", "process", "function", "side", "outputs", "with", "wrong", "output", "tag"], "project": "flink"}
{"id": 8014, "code": "public MathContext getDecimalContext() {\n    return decimalContext;\n}", "summary_tokens": ["returns", "the", "default", "context", "for", "decimal", "division", "calculation"], "project": "flink"}
{"id": 9229, "code": "protected void registerProcessingCleanupTimer() throws IOException {\n    if (stateCleaningEnabled) {\n        long currentProcessingTime = timerService.currentProcessingTime();\n        Optional<Long> currentCleanupTime =\n                Optional.ofNullable(latestRegisteredCleanupTimer.value());\n\n        if (!currentCleanupTime.isPresent()\n                || (currentProcessingTime + minRetentionTime) > currentCleanupTime.get()) {\n\n            updateCleanupTimer(currentProcessingTime, currentCleanupTime);\n        }\n    }\n}", "summary_tokens": ["if", "the", "user", "has", "specified", "a", "min", "retention", "time", "and", "max", "retention", "time", "this", "method", "registers", "a", "cleanup", "timer", "for", "current", "processing", "time", "min", "retention", "time"], "project": "flink"}
{"id": 7332, "code": "private List<Collection<Integer>> getParentInputIds(\n        @Nullable final Collection<Transformation<?>> parentTransformations) {\n    final List<Collection<Integer>> allInputIds = new ArrayList<>();\n    if (parentTransformations == null) {\n        return allInputIds;\n    }\n\n    for (Transformation<?> transformation : parentTransformations) {\n        allInputIds.add(transform(transformation));\n    }\n    return allInputIds;\n}", "summary_tokens": ["returns", "a", "list", "of", "lists", "containing", "the", "ids", "of", "the", "nodes", "in", "the", "transformation", "graph", "that", "correspond", "to", "the", "provided", "transformations"], "project": "flink"}
{"id": 5916, "code": "public void testTrackerWithoutHistory() throws Exception {\n    JobVertexID jobVertexID = new JobVertexID();\n    ExecutionGraph graph =\n            new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                    .addJobVertex(jobVertexID, 3, 256)\n                    .build();\n    ExecutionJobVertex jobVertex = graph.getJobVertex(jobVertexID);\n\n    CheckpointStatsTracker tracker =\n            new CheckpointStatsTracker(0, new UnregisteredMetricsGroup());\n\n    PendingCheckpointStats pending =\n            tracker.reportPendingCheckpoint(\n                    0,\n                    1,\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    singletonMap(jobVertexID, jobVertex.getParallelism()));\n\n    pending.reportSubtaskStats(jobVertexID, createSubtaskStats(0));\n    pending.reportSubtaskStats(jobVertexID, createSubtaskStats(1));\n    pending.reportSubtaskStats(jobVertexID, createSubtaskStats(2));\n\n    pending.reportCompletedCheckpoint(null);\n\n    CheckpointStatsSnapshot snapshot = tracker.createSnapshot();\n        \n    assertFalse(snapshot.getHistory().getCheckpoints().iterator().hasNext());\n\n        \n    CheckpointStatsCounts counts = snapshot.getCounts();\n    assertEquals(1, counts.getNumberOfCompletedCheckpoints());\n    assertEquals(1, counts.getTotalNumberOfCheckpoints());\n\n        \n    CompletedCheckpointStatsSummarySnapshot summary = snapshot.getSummaryStats();\n    assertEquals(1, summary.getStateSizeStats().getCount());\n    assertEquals(1, summary.getEndToEndDurationStats().getCount());\n\n        \n    assertNotNull(snapshot.getHistory().getLatestCompletedCheckpoint());\n    assertEquals(0, snapshot.getHistory().getLatestCompletedCheckpoint().getCheckpointId());\n}", "summary_tokens": ["tests", "that", "the", "number", "of", "remembered", "checkpoints", "configuration", "is", "respected"], "project": "flink"}
{"id": 6025, "code": "public void testAccumulatorsAndMetricsForwarding() throws Exception {\n    final JobVertexID jid1 = new JobVertexID();\n    final JobVertexID jid2 = new JobVertexID();\n\n    JobVertex v1 = new JobVertex(\"v1\", jid1);\n    JobVertex v2 = new JobVertex(\"v2\", jid2);\n\n    SchedulerBase scheduler = setupScheduler(v1, 1, v2, 1);\n    ExecutionGraph graph = scheduler.getExecutionGraph();\n    Map<ExecutionAttemptID, Execution> executions = graph.getRegisteredExecutions();\n\n        \n    Execution execution1 = executions.values().iterator().next();\n\n    IOMetrics ioMetrics = new IOMetrics(0, 0, 0, 0);\n    Map<String, Accumulator<?, ?>> accumulators = new HashMap<>();\n    accumulators.put(\"acc\", new IntCounter(4));\n    AccumulatorSnapshot accumulatorSnapshot =\n            new AccumulatorSnapshot(graph.getJobID(), execution1.getAttemptId(), accumulators);\n\n    TaskExecutionState state =\n            new TaskExecutionState(\n                    execution1.getAttemptId(),\n                    ExecutionState.CANCELED,\n                    null,\n                    accumulatorSnapshot,\n                    ioMetrics);\n\n    scheduler.updateTaskExecutionState(state);\n\n    assertEquals(ioMetrics, execution1.getIOMetrics());\n    assertNotNull(execution1.getUserAccumulators());\n    assertEquals(4, execution1.getUserAccumulators().get(\"acc\").getLocalValue());\n\n        \n    Execution execution2 = executions.values().iterator().next();\n\n    IOMetrics ioMetrics2 = new IOMetrics(0, 0, 0, 0);\n    Map<String, Accumulator<?, ?>> accumulators2 = new HashMap<>();\n    accumulators2.put(\"acc\", new IntCounter(8));\n    AccumulatorSnapshot accumulatorSnapshot2 =\n            new AccumulatorSnapshot(graph.getJobID(), execution2.getAttemptId(), accumulators2);\n\n    TaskExecutionState state2 =\n            new TaskExecutionState(\n                    execution2.getAttemptId(),\n                    ExecutionState.FAILED,\n                    null,\n                    accumulatorSnapshot2,\n                    ioMetrics2);\n\n    scheduler.updateTaskExecutionState(state2);\n\n    assertEquals(ioMetrics2, execution2.getIOMetrics());\n    assertNotNull(execution2.getUserAccumulators());\n    assertEquals(8, execution2.getUserAccumulators().get(\"acc\").getLocalValue());\n}", "summary_tokens": ["verifies", "that", "scheduler", "ng", "update", "task", "execution", "state", "task", "execution", "state", "updates", "the", "accumulators", "and", "metrics", "for", "an", "execution", "that", "failed", "or", "was", "canceled"], "project": "flink"}
{"id": 573, "code": "public void invoke(IN next, Context context) throws Exception {\n        \n    checkErroneous();\n\n    byte[] serializedKey = schema.serializeKey(next);\n    byte[] serializedValue = schema.serializeValue(next);\n    String targetTopic = schema.getTargetTopic(next);\n    if (targetTopic == null) {\n        targetTopic = defaultTopicId;\n    }\n\n    int[] partitions = this.topicPartitionsMap.get(targetTopic);\n    if (null == partitions) {\n        partitions = getPartitionsByTopic(targetTopic, producer);\n        this.topicPartitionsMap.put(targetTopic, partitions);\n    }\n\n    ProducerRecord<byte[], byte[]> record;\n    if (flinkKafkaPartitioner == null) {\n        record = new ProducerRecord<>(targetTopic, serializedKey, serializedValue);\n    } else {\n        record =\n                new ProducerRecord<>(\n                        targetTopic,\n                        flinkKafkaPartitioner.partition(\n                                next, serializedKey, serializedValue, targetTopic, partitions),\n                        serializedKey,\n                        serializedValue);\n    }\n    if (flushOnCheckpoint) {\n        synchronized (pendingRecordsLock) {\n            pendingRecords++;\n        }\n    }\n    producer.send(record, callback);\n}", "summary_tokens": ["called", "when", "new", "data", "arrives", "to", "the", "sink", "and", "forwards", "it", "to", "kafka"], "project": "flink"}
{"id": 4074, "code": "public void testLoadWebSubmissionExtension() throws Exception {\n    final Configuration configuration = new Configuration();\n    configuration.setString(JobManagerOptions.ADDRESS, \"localhost\");\n    final WebMonitorExtension webMonitorExtension =\n            WebMonitorUtils.loadWebSubmissionExtension(\n                    CompletableFuture::new,\n                    Time.seconds(10),\n                    Collections.emptyMap(),\n                    CompletableFuture.completedFuture(\"localhost:12345\"),\n                    Paths.get(\"/tmp\"),\n                    Executors.directExecutor(),\n                    configuration);\n\n    assertThat(webMonitorExtension, is(not(nullValue())));\n}", "summary_tokens": ["tests", "dynamically", "loading", "of", "handlers", "such", "as", "jar", "upload", "handler"], "project": "flink"}
{"id": 2343, "code": "public long getLongBytes(String name, long defaultValue) {\n    String valueString = getTrimmed(name);\n    if (valueString == null) return defaultValue;\n    return StringUtils.TraditionalBinaryPrefix.string2long(valueString);\n}", "summary_tokens": ["get", "the", "value", "of", "the", "code", "name", "code", "property", "as", "a", "code", "long", "code", "or", "human", "readable", "format"], "project": "flink"}
{"id": 5745, "code": "public Collection<String> getAllHandles() throws Exception {\n    final String path = \"/\";\n\n    while (true) {\n        Stat stat = client.checkExists().forPath(path);\n\n        if (stat == null) {\n            return Collections.emptyList();\n        } else {\n            try {\n                return client.getChildren().forPath(path);\n            } catch (KeeperException.NoNodeException ignored) {\n                    \n            }\n        }\n    }\n}", "summary_tokens": ["return", "a", "list", "of", "all", "valid", "paths", "for", "state", "handles"], "project": "flink"}
{"id": 9727, "code": "public static YarnConfiguration getYarnConfiguration(\n        org.apache.flink.configuration.Configuration flinkConfig) {\n    final YarnConfiguration yarnConfig = new YarnConfiguration();\n\n    for (String key : flinkConfig.keySet()) {\n        for (String prefix : FLINK_CONFIG_PREFIXES) {\n            if (key.startsWith(prefix)) {\n                String newKey = key.substring(\"flink.\".length());\n                String value = flinkConfig.getString(key, null);\n                yarnConfig.set(newKey, value);\n                LOG.debug(\n                        \"Adding Flink config entry for {} as {}={} to Yarn config\",\n                        key,\n                        newKey,\n                        value);\n            }\n        }\n    }\n\n    return yarnConfig;\n}", "summary_tokens": ["add", "additional", "config", "entries", "from", "the", "flink", "config", "to", "the", "yarn", "config"], "project": "flink"}
{"id": 1623, "code": "private Kryo getKryoInstance() {\n\n    try {\n            \n            \n            \n        Class<?> chillInstantiatorClazz =\n                Class.forName(\"org.apache.flink.runtime.types.FlinkScalaKryoInstantiator\");\n        Object chillInstantiator = chillInstantiatorClazz.newInstance();\n\n            \n        Method m = chillInstantiatorClazz.getMethod(\"newKryo\");\n\n        return (Kryo) m.invoke(chillInstantiator);\n    } catch (ClassNotFoundException\n            | InstantiationException\n            | NoSuchMethodException\n            | IllegalAccessException\n            | InvocationTargetException e) {\n\n        LOG.warn(\n                \"Falling back to default Kryo serializer because Chill serializer couldn't be found.\",\n                e);\n\n        Kryo.DefaultInstantiatorStrategy initStrategy = new Kryo.DefaultInstantiatorStrategy();\n        initStrategy.setFallbackInstantiatorStrategy(new StdInstantiatorStrategy());\n\n        Kryo kryo = new Kryo();\n        kryo.setInstantiatorStrategy(initStrategy);\n\n        if (flinkChillPackageRegistrar != null) {\n            flinkChillPackageRegistrar.registerSerializers(kryo);\n        }\n\n        return kryo;\n    }\n}", "summary_tokens": ["returns", "the", "chill", "kryo", "serializer", "which", "is", "implicitly", "added", "to", "the", "classpath", "via", "flink", "runtime"], "project": "flink"}
{"id": 7032, "code": "public static <IN, OUT> SingleOutputStreamOperator<OUT> orderedWait(\n        DataStream<IN> in, AsyncFunction<IN, OUT> func, long timeout, TimeUnit timeUnit) {\n    return addOperator(\n            in, func, timeUnit.toMillis(timeout), DEFAULT_QUEUE_CAPACITY, OutputMode.ORDERED);\n}", "summary_tokens": ["add", "an", "async", "wait", "operator"], "project": "flink"}
{"id": 3166, "code": "public DataSet<Tuple2<K, VV>> getVerticesAsTuple2() {\n    return vertices.map(new VertexToTuple2Map<>());\n}", "summary_tokens": ["the", "vertex", "data", "set", "as", "tuple", "0"], "project": "flink"}
{"id": 5286, "code": "<T extends State> T transitionToState(StateFactory<T> targetState) {\n    Preconditions.checkState(\n            !isTransitioningState,\n            \"State transitions must not be triggered while another state transition is in progress.\");\n    Preconditions.checkState(\n            state.getClass() != targetState.getStateClass(),\n            \"Attempted to transition into the very state the scheduler is already in.\");\n\n    try {\n        isTransitioningState = true;\n        LOG.debug(\n                \"Transition from state {} to {}.\",\n                state.getClass().getSimpleName(),\n                targetState.getStateClass().getSimpleName());\n\n        final JobStatus previousJobStatus = state.getJobStatus();\n\n        state.onLeave(targetState.getStateClass());\n        T targetStateInstance = targetState.getState();\n        state = targetStateInstance;\n\n        final JobStatus newJobStatus = state.getJobStatus();\n\n        if (previousJobStatus != newJobStatus) {\n            final long timestamp = System.currentTimeMillis();\n            jobStatusListeners.forEach(\n                    listener ->\n                            listener.jobStatusChanges(\n                                    jobInformation.getJobID(), newJobStatus, timestamp));\n        }\n\n        return targetStateInstance;\n    } finally {\n        isTransitioningState = false;\n    }\n}", "summary_tokens": ["transition", "the", "scheduler", "to", "another", "state"], "project": "flink"}
{"id": 5152, "code": "public void freeSlot(SlotID slotId, AllocationID allocationId) {\n    checkInit();\n    LOG.debug(\"Freeing slot {}.\", slotId);\n\n    slotTracker.notifyFree(slotId);\n    checkResourceRequirements();\n}", "summary_tokens": ["free", "the", "given", "slot", "from", "the", "given", "allocation"], "project": "flink"}
{"id": 6101, "code": "public void testConcurrentLeadershipOperations() throws Exception {\n    final LeaderElectionService dispatcherLeaderElectionService =\n            embeddedHaServices.getDispatcherLeaderElectionService();\n    final TestingLeaderContender leaderContender = new TestingLeaderContender();\n\n    dispatcherLeaderElectionService.start(leaderContender);\n\n    final UUID oldLeaderSessionId = leaderContender.getLeaderSessionFuture().get();\n\n    assertThat(dispatcherLeaderElectionService.hasLeadership(oldLeaderSessionId), is(true));\n\n    embeddedHaServices.getDispatcherLeaderService().revokeLeadership().get();\n    assertThat(dispatcherLeaderElectionService.hasLeadership(oldLeaderSessionId), is(false));\n\n    embeddedHaServices.getDispatcherLeaderService().grantLeadership();\n    final UUID newLeaderSessionId = leaderContender.getLeaderSessionFuture().get();\n\n    assertThat(dispatcherLeaderElectionService.hasLeadership(newLeaderSessionId), is(true));\n\n    dispatcherLeaderElectionService.confirmLeadership(oldLeaderSessionId, ADDRESS);\n    dispatcherLeaderElectionService.confirmLeadership(newLeaderSessionId, ADDRESS);\n\n    assertThat(dispatcherLeaderElectionService.hasLeadership(newLeaderSessionId), is(true));\n\n    leaderContender.tryRethrowException();\n}", "summary_tokens": ["tests", "that", "concurrent", "leadership", "operations", "granting", "and", "revoking", "leadership", "leave", "the", "system", "in", "a", "sane", "state"], "project": "flink"}
{"id": 6994, "code": "public void testFullyAsyncSnapshot() throws Exception {\n\n    final OneInputStreamTaskTestHarness<String, String> testHarness =\n            new OneInputStreamTaskTestHarness<>(\n                    OneInputStreamTask::new,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n    testHarness.setupOutputForSingletonOperatorChain();\n\n    testHarness.configureForKeyedStream(\n            new KeySelector<String, String>() {\n                @Override\n                public String getKey(String value) throws Exception {\n                    return value;\n                }\n            },\n            BasicTypeInfo.STRING_TYPE_INFO);\n\n    StreamConfig streamConfig = testHarness.getStreamConfig();\n\n    File dbDir = temporaryFolder.newFolder();\n\n    RocksDBStateBackend backend = new RocksDBStateBackend(new MemoryStateBackend());\n    backend.setDbStoragePath(dbDir.getAbsolutePath());\n\n    streamConfig.setStateBackend(backend);\n\n    streamConfig.setStreamOperator(new AsyncCheckpointOperator());\n    streamConfig.setOperatorID(new OperatorID());\n\n    final OneShotLatch delayCheckpointLatch = new OneShotLatch();\n    final OneShotLatch ensureCheckpointLatch = new OneShotLatch();\n\n    CheckpointResponder checkpointResponderMock =\n            new CheckpointResponder() {\n\n                @Override\n                public void acknowledgeCheckpoint(\n                        JobID jobID,\n                        ExecutionAttemptID executionAttemptID,\n                        long checkpointId,\n                        CheckpointMetrics checkpointMetrics,\n                        TaskStateSnapshot subtaskState) {\n                        \n                        \n                    try {\n                        delayCheckpointLatch.await();\n                    } catch (InterruptedException e) {\n                        throw new RuntimeException(e);\n                    }\n\n                    boolean hasManagedKeyedState = false;\n                    for (Map.Entry<OperatorID, OperatorSubtaskState> entry :\n                            subtaskState.getSubtaskStateMappings()) {\n                        OperatorSubtaskState state = entry.getValue();\n                        if (state != null) {\n                            hasManagedKeyedState |= state.getManagedKeyedState() != null;\n                        }\n                    }\n\n                        \n                    assertTrue(hasManagedKeyedState);\n\n                        \n                    ensureCheckpointLatch.trigger();\n                }\n\n                @Override\n                public void reportCheckpointMetrics(\n                        JobID jobID,\n                        ExecutionAttemptID executionAttemptID,\n                        long checkpointId,\n                        CheckpointMetrics checkpointMetrics) {}\n\n                @Override\n                public void declineCheckpoint(\n                        JobID jobID,\n                        ExecutionAttemptID executionAttemptID,\n                        long checkpointId,\n                        CheckpointException checkpointException) {}\n            };\n\n    JobID jobID = new JobID();\n    ExecutionAttemptID executionAttemptID = new ExecutionAttemptID();\n    TestTaskStateManager taskStateManagerTestMock =\n            new TestTaskStateManager(\n                    jobID,\n                    executionAttemptID,\n                    checkpointResponderMock,\n                    TestLocalRecoveryConfig.disabled(),\n                    new InMemoryStateChangelogStorage(),\n                    new HashMap<>(),\n                    -1L,\n                    new OneShotLatch());\n\n    StreamMockEnvironment mockEnv =\n            new StreamMockEnvironment(\n                    testHarness.jobConfig,\n                    testHarness.taskConfig,\n                    testHarness.memorySize,\n                    new MockInputSplitProvider(),\n                    testHarness.bufferSize,\n                    taskStateManagerTestMock);\n\n    AtomicReference<Throwable> errorRef = new AtomicReference<>();\n    mockEnv.setExternalExceptionHandler(errorRef::set);\n    testHarness.invoke(mockEnv);\n    testHarness.waitForTaskRunning();\n\n    final OneInputStreamTask<String, String> task = testHarness.getTask();\n\n    task.triggerCheckpointAsync(\n                    new CheckpointMetaData(42, 17),\n                    CheckpointOptions.forCheckpointWithDefaultLocation())\n            .get();\n\n    testHarness.processElement(new StreamRecord<>(\"Wohoo\", 0));\n\n        \n    delayCheckpointLatch.trigger();\n\n        \n    ensureCheckpointLatch.await();\n\n    testHarness.endInput();\n\n    ExecutorService threadPool = task.getAsyncOperationsThreadPool();\n    threadPool.shutdown();\n    Assert.assertTrue(threadPool.awaitTermination(60_000, TimeUnit.MILLISECONDS));\n\n    testHarness.waitForTaskCompletion();\n    if (errorRef.get() != null) {\n        fail(\"Unexpected exception during execution.\");\n    }\n}", "summary_tokens": ["this", "ensures", "that", "asynchronous", "state", "handles", "are", "actually", "materialized", "asynchronously"], "project": "flink"}
{"id": 157, "code": "public void testHybridSourceWithTaskManagerFailover() throws Exception {\n    testHybridSource(FailoverType.TM, sourceWithFixedSwitchPosition());\n}", "summary_tokens": ["test", "the", "source", "with", "task", "manager", "restart"], "project": "flink"}
{"id": 6669, "code": "public void testShouldThrowExceptionIfTaskIsNotRunningBeforeSampling() {\n    final CompletableFuture<List<ThreadInfoSample>> sampleFuture =\n            threadInfoSampleService.requestThreadInfoSamples(\n                    new NotRunningTask(), requestParams);\n    assertThat(\n            sampleFuture,\n            FlinkMatchers.futureWillCompleteExceptionally(\n                    IllegalStateException.class, Duration.ofSeconds(10)));\n}", "summary_tokens": ["test", "that", "sampling", "a", "non", "running", "task", "throws", "an", "exception"], "project": "flink"}
{"id": 8242, "code": "public DataType toSourceRowDataType() {\n    return toRowDataType(c -> true);\n}", "summary_tokens": ["converts", "all", "columns", "of", "this", "schema", "into", "a", "possibly", "nested", "row", "data", "type"], "project": "flink"}
{"id": 7340, "code": "void setMaxParallelism(int maxParallelism) {\n    this.maxParallelism = maxParallelism;\n}", "summary_tokens": ["set", "the", "maximum", "parallelism", "for", "this", "stream", "node"], "project": "flink"}
{"id": 7128, "code": "public SingleOutputStreamOperator<T> setMaxParallelism(int maxParallelism) {\n    OperatorValidationUtils.validateMaxParallelism(maxParallelism, canBeParallel());\n    transformation.setMaxParallelism(maxParallelism);\n\n    return this;\n}", "summary_tokens": ["sets", "the", "maximum", "parallelism", "of", "this", "operator"], "project": "flink"}
{"id": 6257, "code": "public void testBasicGetNextLogic() throws Exception {\n        \n    final SingleInputGate ig1 = createInputGate(3);\n    final SingleInputGate ig2 = createInputGate(5);\n\n    final UnionInputGate union = new UnionInputGate(new SingleInputGate[] {ig1, ig2});\n\n    assertEquals(\n            ig1.getNumberOfInputChannels() + ig2.getNumberOfInputChannels(),\n            union.getNumberOfInputChannels());\n\n    final TestInputChannel[][] inputChannels =\n            new TestInputChannel[][] {\n                TestInputChannel.createInputChannels(ig1, 3),\n                TestInputChannel.createInputChannels(ig2, 5)\n            };\n\n    inputChannels[0][0].readBuffer(); \n    inputChannels[0][0].readEndOfData(); \n    inputChannels[0][0].readEndOfPartitionEvent(); \n    inputChannels[1][2].readBuffer(); \n    inputChannels[1][2].readEndOfData(); \n    inputChannels[1][2].readEndOfPartitionEvent(); \n    inputChannels[1][0].readBuffer(); \n    inputChannels[1][1].readBuffer(); \n    inputChannels[0][1].readBuffer(); \n    inputChannels[1][3].readBuffer(); \n    inputChannels[0][1].readEndOfData(); \n    inputChannels[1][3].readEndOfData(); \n    inputChannels[0][1].readEndOfPartitionEvent(); \n    inputChannels[1][3].readEndOfPartitionEvent(); \n    inputChannels[0][2].readBuffer(); \n    inputChannels[0][2].readEndOfData(); \n    inputChannels[0][2].readEndOfPartitionEvent(); \n    inputChannels[1][4].readBuffer(); \n    inputChannels[1][4].readEndOfData(); \n    inputChannels[1][1].readEndOfData(); \n    inputChannels[1][0].readEndOfData(); \n    inputChannels[1][4].readEndOfPartitionEvent(); \n    inputChannels[1][1].readEndOfPartitionEvent(); \n    inputChannels[1][0].readEndOfPartitionEvent(); \n\n    ig1.notifyChannelNonEmpty(inputChannels[0][0]);\n    ig1.notifyChannelNonEmpty(inputChannels[0][1]);\n    ig1.notifyChannelNonEmpty(inputChannels[0][2]);\n\n    ig2.notifyChannelNonEmpty(inputChannels[1][0]);\n    ig2.notifyChannelNonEmpty(inputChannels[1][1]);\n    ig2.notifyChannelNonEmpty(inputChannels[1][2]);\n    ig2.notifyChannelNonEmpty(inputChannels[1][3]);\n    ig2.notifyChannelNonEmpty(inputChannels[1][4]);\n\n    verifyBufferOrEvent(union, true, 0, true); \n    verifyBufferOrEvent(union, true, 3, true); \n    verifyBufferOrEvent(union, true, 1, true); \n    verifyBufferOrEvent(union, true, 4, true); \n    verifyBufferOrEvent(union, true, 2, true); \n    verifyBufferOrEvent(union, true, 5, true); \n    verifyBufferOrEvent(union, false, 0, true); \n    verifyBufferOrEvent(union, true, 6, true); \n    verifyBufferOrEvent(union, false, 1, true); \n    verifyBufferOrEvent(union, true, 7, true); \n    verifyBufferOrEvent(union, false, 2, true); \n    verifyBufferOrEvent(union, false, 3, true); \n    verifyBufferOrEvent(union, false, 0, true); \n    verifyBufferOrEvent(union, false, 4, true); \n    verifyBufferOrEvent(union, false, 1, true); \n    assertEquals(\n            PullingAsyncDataInput.EndOfDataStatus.NOT_END_OF_DATA,\n            union.hasReceivedEndOfData());\n    verifyBufferOrEvent(union, false, 5, true); \n    verifyBufferOrEvent(union, false, 2, true); \n    verifyBufferOrEvent(union, false, 6, true); \n    verifyBufferOrEvent(union, false, 7, true); \n    assertEquals(PullingAsyncDataInput.EndOfDataStatus.DRAINED, union.hasReceivedEndOfData());\n    assertFalse(union.isFinished());\n    verifyBufferOrEvent(union, false, 3, true); \n    verifyBufferOrEvent(union, false, 4, true); \n    verifyBufferOrEvent(union, false, 5, true); \n    verifyBufferOrEvent(union, false, 6, true); \n    verifyBufferOrEvent(union, false, 7, false); \n\n        \n    assertTrue(union.isFinished());\n    assertFalse(union.getNext().isPresent());\n}", "summary_tokens": ["tests", "basic", "correctness", "of", "buffer", "or", "event", "interleaving", "and", "correct", "code", "null", "code", "return", "value", "after", "receiving", "all", "end", "of", "partition", "events"], "project": "flink"}
{"id": 4027, "code": "public void testNonSerializableRemoteMessageTransfer() throws Exception {\n    LinkedBlockingQueue<Object> linkedBlockingQueue = new LinkedBlockingQueue<>();\n\n    TestEndpoint testEndpoint = new TestEndpoint(akkaRpcService1, linkedBlockingQueue);\n    testEndpoint.start();\n\n    String address = testEndpoint.getAddress();\n\n    CompletableFuture<TestGateway> remoteGatewayFuture =\n            akkaRpcService2.connect(address, TestGateway.class);\n\n    TestGateway remoteGateway = remoteGatewayFuture.get(timeout.getSize(), timeout.getUnit());\n\n    remoteGateway.foobar(new Object());\n\n    fail(\"Should have failed because Object is not serializable.\");\n}", "summary_tokens": ["tests", "that", "a", "remote", "rpc", "call", "with", "a", "non", "serializable", "argument", "fails", "with", "an", "ioexception", "or", "an", "java"], "project": "flink"}
{"id": 2553, "code": "private static void validateEncodingFormatOptions(ReadableConfig tableOptions) {\n    JsonFormatOptionsUtil.validateEncodingFormatOptions(tableOptions);\n}", "summary_tokens": ["validator", "for", "maxwell", "encoding", "format"], "project": "flink"}
{"id": 2629, "code": "protected void fillInType(TypeInformation<T> typeInfo) {\n    if (typeUsed) {\n        throw new IllegalStateException(\n                \"TypeInformation cannot be filled in for the type after it has been used. \"\n                        + \"Please make sure that the type info hints are the first call after the transformation function, \"\n                        + \"before any access to types or semantic properties, etc.\");\n    }\n    this.type = typeInfo;\n}", "summary_tokens": ["tries", "to", "fill", "in", "the", "type", "information"], "project": "flink"}
{"id": 9407, "code": "public static long getNextTriggerWatermark(\n        long currentWatermark, long interval, ZoneId shiftTimezone, boolean useDayLightSaving) {\n    if (currentWatermark == Long.MAX_VALUE) {\n        return currentWatermark;\n    }\n\n    long triggerWatermark;\n        \n    if (useDayLightSaving) {\n        long utcWindowStart =\n                getWindowStartWithOffset(\n                        toUtcTimestampMills(currentWatermark, shiftTimezone), 0L, interval);\n        triggerWatermark = toEpochMillsForTimer(utcWindowStart + interval - 1, shiftTimezone);\n    } else {\n        long start = getWindowStartWithOffset(currentWatermark, 0L, interval);\n        triggerWatermark = start + interval - 1;\n    }\n\n    if (triggerWatermark > currentWatermark) {\n        return triggerWatermark;\n    } else {\n        return triggerWatermark + interval;\n    }\n}", "summary_tokens": ["method", "to", "get", "the", "next", "watermark", "to", "trigger", "window"], "project": "flink"}
{"id": 4302, "code": "public boolean isTaskFinished() {\n    return isTaskFinished;\n}", "summary_tokens": ["returns", "whether", "all", "the", "operators", "of", "the", "task", "have", "called", "finished", "methods"], "project": "flink"}
{"id": 7026, "code": "public SingleOutputStreamOperator<T> min(String field) {\n    return aggregate(\n            new ComparableAggregator<>(\n                    field,\n                    input.getType(),\n                    AggregationFunction.AggregationType.MIN,\n                    false,\n                    input.getExecutionConfig()));\n}", "summary_tokens": ["applies", "an", "aggregation", "that", "that", "gives", "the", "minimum", "value", "of", "the", "pojo", "data", "stream", "at", "the", "given", "field", "expression", "for", "every", "window"], "project": "flink"}
{"id": 2592, "code": "public static ParquetWriterFactory<GenericRecord> forGenericRecord(Schema schema) {\n    return AvroParquetWriters.forGenericRecord(schema);\n}", "summary_tokens": ["creates", "a", "parquet", "writer", "factory", "that", "accepts", "and", "writes", "avro", "generic", "types"], "project": "flink"}
{"id": 952, "code": "protected Connection setupConnection() throws Exception {\n    return setupConnectionFactory().newConnection();\n}", "summary_tokens": ["initializes", "the", "connection", "to", "rmq", "using", "the", "default", "connection", "factory", "from", "setup", "connection", "factory"], "project": "flink"}
{"id": 3611, "code": "public GenericDataSourceBase<?, ?> getOperator() {\n    return (GenericDataSourceBase<?, ?>) super.getOperator();\n}", "summary_tokens": ["gets", "the", "contract", "object", "for", "this", "data", "source", "node"], "project": "flink"}
{"id": 1831, "code": "public void setValue(byte value) {\n    this.value = value;\n}", "summary_tokens": ["sets", "the", "encapsulated", "byte", "to", "the", "specified", "value"], "project": "flink"}
{"id": 4024, "code": "public void testAkkaRpcServiceShutDownWithRpcEndpoints() throws Exception {\n    final AkkaRpcService akkaRpcService = startAkkaRpcService();\n\n    try {\n        final int numberActors = 5;\n\n        CompletableFuture<Void> terminationFuture = akkaRpcService.getTerminationFuture();\n\n        final Collection<CompletableFuture<Void>> onStopFutures =\n                startStopNCountingAsynchronousOnStopEndpoints(akkaRpcService, numberActors);\n\n        for (CompletableFuture<Void> onStopFuture : onStopFutures) {\n            onStopFuture.complete(null);\n        }\n\n        terminationFuture.get();\n        assertThat(akkaRpcService.getActorSystem().whenTerminated().isCompleted(), is(true));\n    } finally {\n        RpcUtils.terminateRpcService(akkaRpcService, TIMEOUT);\n    }\n}", "summary_tokens": ["tests", "that", "the", "akka", "rpc", "service", "terminates", "all", "its", "rpc", "endpoints", "when", "shutting", "down"], "project": "flink"}
{"id": 3971, "code": "private static Time extractRpcTimeout(\n        Annotation[][] parameterAnnotations, Object[] args, Time defaultTimeout) {\n    if (args != null) {\n        Preconditions.checkArgument(parameterAnnotations.length == args.length);\n\n        for (int i = 0; i < parameterAnnotations.length; i++) {\n            if (isRpcTimeout(parameterAnnotations[i])) {\n                if (args[i] instanceof Time) {\n                    return (Time) args[i];\n                } else {\n                    throw new RuntimeException(\n                            \"The rpc timeout parameter must be of type \"\n                                    + Time.class.getName()\n                                    + \". The type \"\n                                    + args[i].getClass().getName()\n                                    + \" is not supported.\");\n                }\n            }\n        }\n    }\n\n    return defaultTimeout;\n}", "summary_tokens": ["extracts", "the", "rpc", "timeout", "annotated", "rpc", "timeout", "value", "from", "the", "list", "of", "given", "method", "arguments"], "project": "flink"}
{"id": 9489, "code": "public void block() throws InterruptedException {\n    synchronized (lock) {\n        blockerReady = true;\n        lock.notifyAll();\n\n        while (!blockerReleased) {\n            lock.wait();\n        }\n    }\n}", "summary_tokens": ["blocks", "until", "release", "blocker", "is", "called", "or", "this", "thread", "is", "interrupted"], "project": "flink"}
{"id": 701, "code": "public void runCollectingSchemaTest() throws Exception {\n\n    final int elementCount = 20;\n    final String topic = writeSequence(\"testCollectingSchema\", elementCount, 1, 1);\n\n        \n    final StreamExecutionEnvironment env1 =\n            StreamExecutionEnvironment.getExecutionEnvironment();\n    env1.setParallelism(1);\n    env1.getConfig().setRestartStrategy(RestartStrategies.noRestart());\n\n    Properties props = new Properties();\n    props.putAll(standardProps);\n    props.putAll(secureProps);\n\n    DataStream<Tuple2<Integer, String>> fromKafka =\n            env1.addSource(\n                    kafkaServer\n                            .getConsumer(\n                                    topic,\n                                    new CollectingDeserializationSchema(elementCount),\n                                    props)\n                            .assignTimestampsAndWatermarks(\n                                    new AscendingTimestampExtractor<Tuple2<Integer, String>>() {\n                                        @Override\n                                        public long extractAscendingTimestamp(\n                                                Tuple2<Integer, String> element) {\n                                            String string = element.f1;\n                                            return Long.parseLong(\n                                                    string.substring(0, string.length() - 1));\n                                        }\n                                    }));\n    fromKafka\n            .keyBy(t -> t.f0)\n            .process(\n                    new KeyedProcessFunction<Integer, Tuple2<Integer, String>, Void>() {\n                        private boolean registered = false;\n\n                        @Override\n                        public void processElement(\n                                Tuple2<Integer, String> value, Context ctx, Collector<Void> out)\n                                throws Exception {\n                            if (!registered) {\n                                ctx.timerService().registerEventTimeTimer(elementCount - 2);\n                                registered = true;\n                            }\n                        }\n\n                        @Override\n                        public void onTimer(\n                                long timestamp, OnTimerContext ctx, Collector<Void> out)\n                                throws Exception {\n                            throw new SuccessException();\n                        }\n                    });\n\n    tryExecute(env1, \"Consume \" + elementCount + \" elements from Kafka\");\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["test", "that", "ensures", "that", "deserialization", "schema", "can", "emit", "multiple", "records", "via", "a", "collector"], "project": "flink"}
{"id": 351, "code": "public Class<UDFType> getUDFClass() throws ClassNotFoundException {\n    return (Class<UDFType>) Thread.currentThread().getContextClassLoader().loadClass(className);\n}", "summary_tokens": ["get", "class", "of", "the", "hive", "function"], "project": "flink"}
{"id": 6844, "code": "public void testRemoveAndPutWithSnapshot() {\n    CopyOnWriteSkipListStateMapSnapshot<Integer, Long, String> snapshot =\n            stateMapWithStates.stateSnapshot();\n    TestExecutionResult result = testRemoveAndPut();\n    snapshot.release();\n    verify(result);\n}", "summary_tokens": ["test", "remove", "put", "during", "snapshot", "remove", "should", "trigger", "copy", "on", "write", "and", "put", "shouldn", "t"], "project": "flink"}
{"id": 4157, "code": "ConcurrentMap<Tuple2<JobID, TransientBlobKey>, Long> getBlobExpiryTimes() {\n    return blobExpiryTimes;\n}", "summary_tokens": ["returns", "the", "blob", "expiry", "times", "for", "testing", "purposes", "only"], "project": "flink"}
{"id": 1142, "code": "public String getFormattedTimestamp() {\n    return TS_FORMATTER.get().format(new Date(timestamp));\n}", "summary_tokens": ["formats", "the", "timestamp", "of", "this", "watermark", "assuming", "it", "is", "a", "millisecond", "timestamp"], "project": "flink"}
{"id": 3377, "code": "public ScatterGatherConfiguration getIterationConfiguration() {\n    return this.configuration;\n}", "summary_tokens": ["the", "configuration", "parameters", "of", "this", "scatter", "gather", "iteration"], "project": "flink"}
{"id": 2452, "code": "public void testForGeneric_withValidParams_succeeds() {\n    assertThat(\n            GlueSchemaRegistryAvroDeserializationSchema.forGeneric(userSchema, configs),\n            notNullValue());\n    assertThat(\n            GlueSchemaRegistryAvroDeserializationSchema.forGeneric(userSchema, configs),\n            instanceOf(GlueSchemaRegistryAvroDeserializationSchema.class));\n}", "summary_tokens": ["test", "whether", "for", "generic", "method", "works"], "project": "flink"}
{"id": 5148, "code": "public void start(\n        ResourceManagerId newResourceManagerId,\n        Executor newMainThreadExecutor,\n        ResourceActions newResourceActions) {\n    LOG.debug(\"Starting the slot manager.\");\n\n    this.resourceManagerId = Preconditions.checkNotNull(newResourceManagerId);\n    mainThreadExecutor = Preconditions.checkNotNull(newMainThreadExecutor);\n    resourceActions = Preconditions.checkNotNull(newResourceActions);\n    taskExecutorManager =\n            taskExecutorManagerFactory.apply(newMainThreadExecutor, newResourceActions);\n\n    started = true;\n\n    registerSlotManagerMetrics();\n}", "summary_tokens": ["starts", "the", "slot", "manager", "with", "the", "given", "leader", "id", "and", "resource", "manager", "actions"], "project": "flink"}
{"id": 4335, "code": "public CPUResource getCpuCores() {\n    throwUnsupportedOperationExceptionIfUnknown();\n    return cpuCores;\n}", "summary_tokens": ["get", "the", "cpu", "cores", "needed"], "project": "flink"}
{"id": 1555, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f5)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f6)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f7)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f8)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 5674, "code": "public boolean nextKey() throws IOException {\n        \n    if (this.current == null) {\n        if (this.done) {\n            this.valuesIterator = null;\n            return false;\n        }\n        this.current = this.reuse;\n        if ((this.current = this.iterator.next(this.current)) != null) {\n            this.comparator.setReference(this.current);\n            this.lookAheadHasNext = false;\n            this.valuesIterator = new ValuesIterator();\n            this.valuesIterator.currentIsUnconsumed = true;\n            return true;\n        } else {\n                \n            this.valuesIterator = null;\n            this.current = null;\n            this.done = true;\n            return false;\n        }\n    }\n\n    this.valuesIterator.iteratorAvailable = true;\n\n        \n    if (this.lookAheadHasNext) {\n        this.lookAheadHasNext = false;\n        this.current = this.lookahead;\n        this.lookahead = null;\n        this.comparator.setReference(this.current);\n        this.valuesIterator.currentIsUnconsumed = true;\n        return true;\n    }\n\n        \n        \n    while (true) {\n        if (!this.done && ((this.current = this.iterator.next(this.current)) != null)) {\n            if (!this.comparator.equalToReference(this.current)) {\n                    \n                this.comparator.setReference(this.current);\n                this.lookAheadHasNext = false;\n                this.valuesIterator.currentIsUnconsumed = true;\n                return true;\n            }\n        } else {\n            this.valuesIterator = null;\n            this.current = null;\n            this.done = true;\n            return false;\n        }\n    }\n}", "summary_tokens": ["moves", "the", "iterator", "to", "the", "next", "key"], "project": "flink"}
{"id": 5094, "code": "public Configuration getConfiguration() {\n    return this.config;\n}", "summary_tokens": ["gets", "the", "configuration", "that", "holds", "the", "actual", "values", "encoded"], "project": "flink"}
{"id": 8697, "code": "public static CalciteSchema asRootSchema(Schema root) {\n    return new SimpleCalciteSchema(null, root, \"\");\n}", "summary_tokens": ["creates", "a", "calcite", "schema", "with", "a", "given", "schema", "as", "the", "root"], "project": "flink"}
{"id": 7454, "code": "public static <W extends Window> CountEvictor<W> of(long maxCount, boolean doEvictAfter) {\n    return new CountEvictor<>(maxCount, doEvictAfter);\n}", "summary_tokens": ["creates", "a", "count", "evictor", "that", "keeps", "the", "given", "number", "of", "elements", "in", "the", "pane", "eviction", "is", "done", "before", "after", "the", "window", "function", "based", "on", "the", "value", "of", "do", "evict", "after"], "project": "flink"}
{"id": 5348, "code": "public <N, S extends State> S getPartitionedState(\n        final N namespace,\n        final TypeSerializer<N> namespaceSerializer,\n        final StateDescriptor<S, ?> stateDescriptor)\n        throws Exception {\n\n    checkNotNull(namespace, \"Namespace\");\n\n    if (lastName != null && lastName.equals(stateDescriptor.getName())) {\n        lastState.setCurrentNamespace(namespace);\n        return (S) lastState;\n    }\n\n    InternalKvState<K, ?, ?> previous = keyValueStatesByName.get(stateDescriptor.getName());\n    if (previous != null) {\n        lastState = previous;\n        lastState.setCurrentNamespace(namespace);\n        lastName = stateDescriptor.getName();\n        return (S) previous;\n    }\n\n    final S state = getOrCreateKeyedState(namespaceSerializer, stateDescriptor);\n    final InternalKvState<K, N, ?> kvState = (InternalKvState<K, N, ?>) state;\n\n    lastName = stateDescriptor.getName();\n    lastState = kvState;\n    kvState.setCurrentNamespace(namespace);\n\n    return state;\n}", "summary_tokens": ["todo", "note", "this", "method", "does", "a", "lot", "of", "work", "caching", "retrieving", "states", "just", "to", "update", "the", "namespace"], "project": "flink"}
{"id": 6710, "code": "public void testThreadInfoRequestTimeout() throws Exception {\n    Map<ExecutionAttemptID, CompletableFuture<TaskExecutorThreadInfoGateway>>\n            executionWithGateways =\n                    createMockSubtaskWithGateways(\n                            CompletionType.SUCCESSFULLY, CompletionType.TIMEOUT);\n\n    CompletableFuture<JobVertexThreadInfoStats> requestFuture =\n            coordinator.triggerThreadInfoRequest(\n                    executionWithGateways,\n                    DEFAULT_NUMBER_OF_SAMPLES,\n                    DEFAULT_DELAY_BETWEEN_SAMPLES,\n                    DEFAULT_MAX_STACK_TRACE_DEPTH);\n\n    try {\n        requestFuture.get();\n        fail(\"Exception expected.\");\n    } catch (ExecutionException e) {\n        assertTrue(\n                ExceptionUtils.findThrowableWithMessage(e, REQUEST_TIMEOUT_MESSAGE)\n                        .isPresent());\n    } finally {\n        coordinator.shutDown();\n    }\n}", "summary_tokens": ["tests", "that", "thread", "info", "stats", "request", "times", "out", "if", "not", "finished", "in", "time"], "project": "flink"}
{"id": 9469, "code": "public static StreamRecord<RowData> record(RowKind rowKind, Object... fields) {\n    RowData row = row(fields);\n    row.setRowKind(rowKind);\n    return new StreamRecord<>(row);\n}", "summary_tokens": ["creates", "n", "new", "stream", "record", "of", "row", "data", "based", "on", "the", "given", "fields", "array", "and", "the", "give", "row", "kind"], "project": "flink"}
{"id": 8967, "code": "public static boolean hasJsonCreatorAnnotation(Class<?> clazz) {\n    for (Constructor<?> constructor : clazz.getDeclaredConstructors()) {\n        for (Annotation annotation : constructor.getAnnotations()) {\n            if (annotation instanceof JsonCreator) {\n                return true;\n            }\n        }\n    }\n    return false;\n}", "summary_tokens": ["return", "true", "if", "the", "given", "class", "s", "constructors", "have", "annotation", "else", "false"], "project": "flink"}
{"id": 3690, "code": "public void setTempMode(TempMode tempMode) {\n    this.tempMode = tempMode;\n}", "summary_tokens": ["sets", "the", "temp", "mode", "of", "the", "connection"], "project": "flink"}
{"id": 7566, "code": "public static String createBrokerIdString(JobID jid, String iterationID, int subtaskIndex) {\n    return jid + \"-\" + iterationID + \"-\" + subtaskIndex;\n}", "summary_tokens": ["creates", "the", "identification", "string", "with", "which", "head", "and", "tail", "task", "find", "the", "shared", "blocking", "queue", "for", "the", "back", "channel"], "project": "flink"}
{"id": 7193, "code": "public boolean isFailOnCheckpointingErrors() {\n    return failOnCheckpointingErrors;\n}", "summary_tokens": ["this", "determines", "the", "behaviour", "when", "meeting", "checkpoint", "errors"], "project": "flink"}
{"id": 3022, "code": "public boolean isCompatibleWith(DeweyNumber other) {\n    if (length() > other.length()) {\n            \n        for (int i = 0; i < other.length(); i++) {\n            if (other.deweyNumber[i] != deweyNumber[i]) {\n                return false;\n            }\n        }\n\n        return true;\n    } else if (length() == other.length()) {\n            \n        int lastIndex = length() - 1;\n        for (int i = 0; i < lastIndex; i++) {\n            if (other.deweyNumber[i] != deweyNumber[i]) {\n                return false;\n            }\n        }\n\n            \n        return deweyNumber[lastIndex] >= other.deweyNumber[lastIndex];\n    } else {\n        return false;\n    }\n}", "summary_tokens": ["checks", "whether", "this", "dewey", "number", "is", "compatible", "to", "the", "other", "dewey", "number"], "project": "flink"}
{"id": 3964, "code": "public static Executor withContextClassLoader(\n        Executor executor, ClassLoader contextClassLoader) {\n    return new ContextClassLoaderSettingExecutor(executor, contextClassLoader);\n}", "summary_tokens": ["wraps", "the", "given", "executor", "such", "that", "all", "submitted", "are", "runnables", "are", "run", "in", "a", "temporary", "class", "loader", "context", "based", "on", "the", "given", "classloader"], "project": "flink"}
{"id": 764, "code": "protected final void updateState(int shardStateIndex, SequenceNumber lastSequenceNumber) {\n    synchronized (checkpointLock) {\n        subscribedShardsState\n                .get(shardStateIndex)\n                .setLastProcessedSequenceNum(lastSequenceNumber);\n\n            \n            \n            \n        if (lastSequenceNumber.equals(\n                SentinelSequenceNumber.SENTINEL_SHARD_ENDING_SEQUENCE_NUM.get())) {\n            LOG.info(\n                    \"Subtask {} has reached the end of subscribed shard: {}\",\n                    indexOfThisConsumerSubtask,\n                    subscribedShardsState.get(shardStateIndex).getStreamShardHandle());\n\n                \n                \n                \n                \n                \n                \n                \n            if (this.numberOfActiveShards.decrementAndGet() == 0) {\n                LOG.info(\n                        \"Subtask {} has reached the end of all currently subscribed shards; marking the subtask as temporarily idle ...\",\n                        indexOfThisConsumerSubtask);\n\n                sourceContext.markAsTemporarilyIdle();\n            }\n        }\n    }\n}", "summary_tokens": ["update", "the", "shard", "to", "last", "processed", "sequence", "number", "state"], "project": "flink"}
{"id": 8944, "code": "public static int getNewNodeId() {\n    idCounter++;\n    return idCounter;\n}", "summary_tokens": ["generate", "an", "unique", "id", "for", "exec", "node"], "project": "flink"}
{"id": 1969, "code": "protected Class<?> loadClassWithoutExceptionHandling(String name, boolean resolve)\n        throws ClassNotFoundException {\n    return super.loadClass(name, resolve);\n}", "summary_tokens": ["same", "as", "load", "class", "string", "boolean", "but", "without", "exception", "handling"], "project": "flink"}
{"id": 93, "code": "public void testRetriableSendOperationIfConnectionErrorOrServiceUnavailable() throws Exception {\n    final PingRestHandler pingRestHandler =\n            new PingRestHandler(\n                    FutureUtils.completedExceptionally(\n                            new RestHandlerException(\n                                    \"test exception\", HttpResponseStatus.SERVICE_UNAVAILABLE)),\n                    CompletableFuture.completedFuture(EmptyResponseBody.getInstance()));\n\n    try (final TestRestServerEndpoint restServerEndpoint =\n            createRestServerEndpoint(pingRestHandler)) {\n        RestClusterClient<?> restClusterClient =\n                createRestClusterClient(restServerEndpoint.getServerAddress().getPort());\n\n        try {\n            final AtomicBoolean firstPollFailed = new AtomicBoolean();\n            failHttpRequest =\n                    (messageHeaders, messageParameters, requestBody) ->\n                            messageHeaders instanceof PingRestHandlerHeaders\n                                    && !firstPollFailed.getAndSet(true);\n\n            restClusterClient.sendRequest(PingRestHandlerHeaders.INSTANCE).get();\n        } finally {\n            restClusterClient.close();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "the", "send", "operation", "is", "being", "retried"], "project": "flink"}
{"id": 5618, "code": "public boolean isDisposed() {\n    synchronized (lock) {\n        return isDisposed;\n    }\n}", "summary_tokens": ["returns", "whether", "the", "reference", "count", "has", "reached", "the", "disposed", "state"], "project": "flink"}
{"id": 9524, "code": "public <T> SharedReference<T> add(T object) {\n    SharedReference<T> tag = new SharedObjectsExtension.DefaultTag<>(id, objects.size());\n    objects.put(tag, object);\n    return tag;\n}", "summary_tokens": ["adds", "a", "new", "object", "to", "this", "shared", "objects"], "project": "flink"}
{"id": 5630, "code": "public boolean hasNext() {\n    return false;\n}", "summary_tokens": ["always", "returns", "false", "since", "this", "iterator", "is", "empty"], "project": "flink"}
{"id": 9535, "code": "public static String getTestBucketUri() {\n    return getTestBucketUriWithScheme(\"s3\");\n}", "summary_tokens": ["gets", "the", "uri", "for", "the", "path", "under", "which", "all", "tests", "should", "put", "their", "data"], "project": "flink"}
{"id": 8409, "code": "public static CatalogFactoryHelper createCatalogFactoryHelper(\n        CatalogFactory factory, CatalogFactory.Context context) {\n    return new CatalogFactoryHelper(factory, context);\n}", "summary_tokens": ["creates", "a", "utility", "that", "helps", "validating", "options", "for", "a", "catalog", "factory"], "project": "flink"}
{"id": 9377, "code": "public static boolean equals(\n        MemorySegment[] segments1,\n        int offset1,\n        MemorySegment[] segments2,\n        int offset2,\n        int len) {\n    if (inFirstSegment(segments1, offset1, len) && inFirstSegment(segments2, offset2, len)) {\n        return segments1[0].equalTo(segments2[0], offset1, offset2, len);\n    } else {\n        return equalsMultiSegments(segments1, offset1, segments2, offset2, len);\n    }\n}", "summary_tokens": ["equals", "two", "memory", "segments", "regions"], "project": "flink"}
{"id": 9579, "code": "public void testSavepointRescalingNonPartitionedStateCausesException() throws Exception {\n    final int parallelism = numSlots / 2;\n    final int parallelism2 = numSlots;\n    final int maxParallelism = 13;\n\n    Duration timeout = Duration.ofMinutes(3);\n    Deadline deadline = Deadline.now().plus(timeout);\n\n    ClusterClient<?> client = cluster.getClusterClient();\n\n    try {\n        JobGraph jobGraph =\n                createJobGraphWithOperatorState(\n                        parallelism, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n            \n        StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n        final JobID jobID = jobGraph.getJobID();\n\n        client.submitJob(jobGraph).get();\n\n            \n        waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID(), false);\n            \n        StateSourceBase.workStartedLatch.await();\n\n        CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n        final String savepointPath =\n                savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \n        StateSourceBase.canFinishLatch.countDown();\n        client.cancel(jobID).get();\n        while (!getRunningJobs(client).isEmpty()) {\n            Thread.sleep(50);\n        }\n\n            \n        JobGraph scaledJobGraph =\n                createJobGraphWithOperatorState(\n                        parallelism2, maxParallelism, OperatorCheckpointMethod.NON_PARTITIONED);\n\n        scaledJobGraph.setSavepointRestoreSettings(\n                SavepointRestoreSettings.forPath(savepointPath));\n\n        submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n    } catch (JobExecutionException exception) {\n        if (exception.getCause() instanceof IllegalStateException) {\n                \n                \n                \n        } else {\n            throw exception;\n        }\n    }\n}", "summary_tokens": ["tests", "that", "a", "job", "cannot", "be", "restarted", "from", "a", "savepoint", "with", "a", "different", "parallelism", "if", "the", "rescaled", "operator", "has", "non", "partitioned", "state"], "project": "flink"}
{"id": 5899, "code": "public void testNonRestoredStateWhenDisallowed() throws Exception {\n    final OperatorID operatorId = new OperatorID();\n    final int parallelism = 9;\n\n    final CompletedCheckpointStorageLocation testSavepoint =\n            createSavepointWithOperatorSubtaskState(242L, operatorId, parallelism);\n    final Map<JobVertexID, ExecutionJobVertex> tasks = Collections.emptyMap();\n\n    try {\n        Checkpoints.loadAndValidateCheckpoint(\n                new JobID(),\n                tasks,\n                testSavepoint,\n                cl,\n                false,\n                CheckpointProperties.forSavepoint(false));\n        fail(\"Did not throw expected Exception\");\n    } catch (IllegalStateException expected) {\n        assertTrue(expected.getMessage().contains(\"allowNonRestoredState\"));\n    }\n}", "summary_tokens": ["tests", "that", "savepoint", "loading", "fails", "when", "there", "is", "non", "restored", "state", "but", "it", "is", "not", "allowed"], "project": "flink"}
{"id": 1269, "code": "public Operator<T> getNextPartialSolution() {\n    return this.iterationResult;\n}", "summary_tokens": ["the", "operator", "representing", "the", "next", "partial", "solution"], "project": "flink"}
{"id": 9567, "code": "private void runTest(boolean intermittentFailure) throws Exception {\n    final int numElements = 100;\n    final int failAt = intermittentFailure ? numElements / 2 : numElements * 2;\n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(1);\n    env.enableCheckpointing(50);\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n\n    final DataStream<Long> numbers =\n            env.fromSource(\n                            new TestingNumberSequenceSource(1L, numElements, 3),\n                            WatermarkStrategy.noWatermarks(),\n                            \"numbers\")\n                    .map(\n                            new MapFunction<Long, Long>() {\n                                private int num;\n\n                                @Override\n                                public Long map(Long value) throws Exception {\n                                    if (++num > failAt) {\n                                        throw new Exception(\"Artificial intermittent failure.\");\n                                    }\n                                    return value;\n                                }\n                            });\n\n    final List<Long> sequence = numbers.executeAndCollect(numElements);\n        \n    sequence.sort(Long::compareTo);\n\n    final List<Long> expectedSequence =\n            LongStream.rangeClosed(1L, numElements).boxed().collect(Collectors.toList());\n\n    assertEquals(expectedSequence, sequence);\n}", "summary_tokens": ["runs", "the", "test", "program", "which", "uses", "a", "single", "reader", "parallelism", "0", "and", "has", "three", "splits", "of", "data", "to", "be", "assigned", "to", "the", "same", "reader"], "project": "flink"}
{"id": 6571, "code": "public void testLoadMemoryStateBackendNoParameters() throws Exception {\n        \n        \n        \n\n    final Configuration config1 = new Configuration();\n    config1.setString(backendKey, \"jobmanager\");\n\n    final Configuration config2 = new Configuration();\n    config2.setString(backendKey, MemoryStateBackendFactory.class.getName());\n\n    StateBackend backend1 = StateBackendLoader.loadStateBackendFromConfig(config1, cl, null);\n    StateBackend backend2 = StateBackendLoader.loadStateBackendFromConfig(config2, cl, null);\n\n    assertTrue(backend1 instanceof MemoryStateBackend);\n    assertTrue(backend2 instanceof MemoryStateBackend);\n}", "summary_tokens": ["validates", "loading", "a", "memory", "state", "backend", "from", "the", "cluster", "configuration"], "project": "flink"}
{"id": 1731, "code": "public URI toUri() {\n    return uri;\n}", "summary_tokens": ["converts", "the", "path", "object", "to", "a", "uri"], "project": "flink"}
{"id": 7864, "code": "public void waitForTaskRunning() throws Exception {\n    Preconditions.checkState(taskThread != null, \"Task thread was not started.\");\n    StreamTask<?, ?> streamTask = taskThread.task;\n    while (!streamTask.isRunning()) {\n        Thread.sleep(10);\n        if (!taskThread.isAlive()) {\n            if (taskThread.getError() != null) {\n                throw new Exception(\n                        \"Task Thread failed due to an error.\", taskThread.getError());\n            } else {\n                throw new Exception(\"Task Thread unexpectedly shut down.\");\n            }\n        }\n    }\n}", "summary_tokens": ["waits", "for", "the", "task", "to", "be", "running"], "project": "flink"}
{"id": 4954, "code": "private void initOutputs(UserCodeClassLoader cl) throws Exception {\n    this.chainedTasks = new ArrayList<ChainedDriver<?, ?>>();\n    this.eventualOutputs = new ArrayList<RecordWriter<?>>();\n\n    this.output =\n            BatchTask.initOutputs(\n                    this,\n                    cl,\n                    this.config,\n                    this.chainedTasks,\n                    this.eventualOutputs,\n                    getExecutionConfig(),\n                    getEnvironment().getAccumulatorRegistry().getUserMap());\n}", "summary_tokens": ["creates", "a", "writer", "for", "each", "output"], "project": "flink"}
{"id": 428, "code": "public void addIdentifierTranslation(HiveParserASTNode identifier) {\n    if (!enabled) {\n        return;\n    }\n    assert (identifier.getToken().getType() == HiveASTParser.Identifier);\n    String replacementText = identifier.getText();\n    replacementText = HiveParserBaseSemanticAnalyzer.unescapeIdentifier(replacementText);\n    replacementText = HiveUtils.unparseIdentifier(replacementText, conf);\n    addTranslation(identifier, replacementText);\n}", "summary_tokens": ["register", "a", "translation", "for", "an", "identifier"], "project": "flink"}
{"id": 9082, "code": "public static int signum(DecimalData decimal) {\n    if (decimal.isCompact()) {\n        return Long.signum(decimal.toUnscaledLong());\n    } else {\n        return decimal.toBigDecimal().signum();\n    }\n}", "summary_tokens": ["returns", "the", "signum", "function", "of", "this", "decimal"], "project": "flink"}
{"id": 6600, "code": "public void testRequireNonNullNamespace() throws Exception {\n    ValueStateDescriptor<IntValue> kvId =\n            new ValueStateDescriptor<>(\"id\", IntValue.class, new IntValue(-1));\n\n    final CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n    try {\n        try {\n            backend.getPartitionedState(null, VoidNamespaceSerializer.INSTANCE, kvId);\n            fail(\"Did not throw expected NullPointerException\");\n        } catch (NullPointerException ignored) {\n        }\n\n        try {\n            backend.getPartitionedState(VoidNamespace.INSTANCE, null, kvId);\n            fail(\"Did not throw expected NullPointerException\");\n        } catch (NullPointerException ignored) {\n        }\n\n        try {\n            backend.getPartitionedState(null, null, kvId);\n            fail(\"Did not throw expected NullPointerException\");\n        } catch (NullPointerException ignored) {\n        }\n    } finally {\n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["previously", "it", "was", "possible", "to", "create", "partitioned", "state", "with", "code", "null", "code", "namespace"], "project": "flink"}
{"id": 8970, "code": "public int[] getFieldIndices() {\n    return fields;\n}", "summary_tokens": ["gets", "field", "index", "of", "all", "fields", "in", "input"], "project": "flink"}
{"id": 7099, "code": "public static <E> List<E> collectUnboundedStream(\n        DataStream<E> stream, int numElements, String jobName) throws Exception {\n    final ClientAndIterator<E> clientAndIterator = collectWithClient(stream, jobName);\n    final List<E> result = collectRecordsFromUnboundedStream(clientAndIterator, numElements);\n\n        \n    clientAndIterator.client.cancel().get();\n\n    return result;\n}", "summary_tokens": ["triggers", "execution", "of", "the", "data", "stream", "application", "and", "collects", "the", "given", "number", "of", "records", "from", "the", "stream"], "project": "flink"}
{"id": 7880, "code": "public void testQuiesceUnblocks() throws InterruptedException {\n    testAllPuttingUnblocksInternal(TaskMailbox::quiesce);\n}", "summary_tokens": ["test", "that", "silencing", "the", "mailbox", "unblocks", "pending", "accesses", "with", "correct", "exceptions"], "project": "flink"}
{"id": 2044, "code": "public static Properties flatten(Properties config) {\n    final Properties flattenProperties = new Properties();\n\n    Collections.list(config.propertyNames()).stream()\n            .forEach(\n                    name -> {\n                        Preconditions.checkArgument(name instanceof String);\n                        flattenProperties.setProperty(\n                                (String) name, config.getProperty((String) name));\n                    });\n\n    return flattenProperties;\n}", "summary_tokens": ["flatten", "a", "recursive", "properties", "to", "a", "first", "level", "property", "map"], "project": "flink"}
{"id": 6719, "code": "public void testGetAll() throws Exception {\n        \n    final TestingLongStateHandleHelper stateHandleProvider = new TestingLongStateHandleHelper();\n\n    ZooKeeperStateHandleStore<TestingLongStateHandleHelper.LongStateHandle> store =\n            new ZooKeeperStateHandleStore<>(ZOOKEEPER.getClient(), stateHandleProvider);\n\n        \n    final String pathInZooKeeper = \"/testGetAll\";\n\n    final Set<Long> expected = new HashSet<>();\n    expected.add(311222268470898L);\n    expected.add(132812888L);\n    expected.add(27255442L);\n    expected.add(11122233124L);\n\n        \n    for (long val : expected) {\n        store.addAndLock(\n                pathInZooKeeper + val, new TestingLongStateHandleHelper.LongStateHandle(val));\n    }\n\n    for (Tuple2<RetrievableStateHandle<TestingLongStateHandleHelper.LongStateHandle>, String>\n            val : store.getAllAndLock()) {\n        assertTrue(expected.remove(val.f0.retrieveState().getValue()));\n    }\n    assertEquals(0, expected.size());\n}", "summary_tokens": ["tests", "that", "all", "added", "state", "is", "returned"], "project": "flink"}
{"id": 5562, "code": "public void startTrackingPartitions(K key, Collection<ResultPartitionID> newPartitionIds) {\n    Preconditions.checkNotNull(key);\n    Preconditions.checkNotNull(newPartitionIds);\n\n    if (newPartitionIds.isEmpty()) {\n        return;\n    }\n\n    trackedPartitionsPerKey.compute(\n            key,\n            (ignored, partitionIds) -> {\n                if (partitionIds == null) {\n                    partitionIds = new HashSet<>(8);\n                }\n                partitionIds.addAll(newPartitionIds);\n                return partitionIds;\n            });\n}", "summary_tokens": ["starts", "the", "tracking", "of", "the", "given", "partition", "for", "the", "given", "key"], "project": "flink"}
{"id": 886, "code": "public static <T> Schema<T> createSchema(SchemaInfo info) {\n    PulsarSchemaFactory<?> factory = FACTORY_REGISTER.get(info.getType());\n    checkNotNull(factory, \"This schema info %s is not supported.\", info);\n\n    return (Schema<T>) factory.createSchema(info);\n}", "summary_tokens": ["pulsar", "has", "a", "hugh", "set", "of", "built", "in", "schemas"], "project": "flink"}
{"id": 5250, "code": "public static String getMimeTypeForExtension(String fileExtension) {\n    return MIME_MAP.get(fileExtension.toLowerCase());\n}", "summary_tokens": ["gets", "the", "mime", "type", "for", "the", "file", "with", "the", "given", "extension"], "project": "flink"}
{"id": 1432, "code": "public void setMaxParallelism(int maxParallelism) {\n    OperatorValidationUtils.validateMaxParallelism(maxParallelism, UPPER_BOUND_MAX_PARALLELISM);\n    this.maxParallelism = maxParallelism;\n}", "summary_tokens": ["sets", "the", "maximum", "parallelism", "for", "this", "stream", "transformation"], "project": "flink"}
{"id": 4035, "code": "public static boolean isRunningInExpectedThread(@Nullable Thread expected) {\n    Thread actual = Thread.currentThread();\n    if (expected != actual) {\n\n        String violationMsg =\n                \"Violation of main thread constraint detected: expected <\"\n                        + expected\n                        + \"> but running in <\"\n                        + actual\n                        + \">.\";\n\n        LOG.warn(violationMsg, new Exception(violationMsg));\n\n        return false;\n    }\n\n    return true;\n}", "summary_tokens": ["returns", "true", "iff", "the", "current", "thread", "is", "equals", "to", "the", "provided", "expected", "thread", "and", "logs", "violations"], "project": "flink"}
{"id": 7045, "code": "public <R> SingleOutputStreamOperator<R> flatMap(\n        CoFlatMapFunction<IN1, IN2, R> coFlatMapper, TypeInformation<R> outputType) {\n    return transform(\n            \"Co-Flat Map\", outputType, new CoStreamFlatMap<>(inputStream1.clean(coFlatMapper)));\n}", "summary_tokens": ["applies", "a", "co", "flat", "map", "transformation", "on", "a", "connected", "streams", "and", "maps", "the", "output", "to", "a", "common", "type"], "project": "flink"}
{"id": 9362, "code": "public static <T> RowDataSerializer create(RowType type) {\n    return (RowDataSerializer) createInternal(type);\n}", "summary_tokens": ["creates", "a", "type", "serializer", "for", "internal", "data", "structures", "of", "the", "given", "row", "type"], "project": "flink"}
{"id": 8469, "code": "public static UserDefinedFunction createSpecializedFunction(\n        String functionName,\n        FunctionDefinition definition,\n        CallContext callContext,\n        ClassLoader builtInClassLoader,\n        @Nullable ReadableConfig configuration) {\n    if (definition instanceof SpecializedFunction) {\n        final SpecializedFunction specialized = (SpecializedFunction) definition;\n        final SpecializedContext specializedContext =\n                new SpecializedContext() {\n                    @Override\n                    public CallContext getCallContext() {\n                        return callContext;\n                    }\n\n                    @Override\n                    public ReadableConfig getConfiguration() {\n                        if (configuration == null) {\n                            throw new TableException(\n                                    \"Access to configuration is currently not supported for all kinds of calls.\");\n                        }\n                        return configuration;\n                    }\n\n                    @Override\n                    public ClassLoader getBuiltInClassLoader() {\n                        return builtInClassLoader;\n                    }\n                };\n        final UserDefinedFunction udf = specialized.specialize(specializedContext);\n        checkState(\n                udf.getKind() == definition.getKind(),\n                \"Function kind must not change during specialization.\");\n        return udf;\n    } else if (definition instanceof UserDefinedFunction) {\n        return (UserDefinedFunction) definition;\n    } else {\n        throw new TableException(\n                String.format(\n                        \"Could not find a runtime implementation for function definition '%s'.\",\n                        functionName));\n    }\n}", "summary_tokens": ["creates", "the", "runtime", "implementation", "of", "a", "function", "definition", "as", "an", "instance", "of", "user", "defined", "function"], "project": "flink"}
{"id": 2805, "code": "public O returns(TypeInformation<OUT> typeInfo) {\n    requireNonNull(typeInfo, \"TypeInformation must not be null\");\n\n    fillInType(typeInfo);\n    @SuppressWarnings(\"unchecked\")\n    O returnType = (O) this;\n    return returnType;\n}", "summary_tokens": ["adds", "a", "type", "information", "hint", "about", "the", "return", "type", "of", "this", "operator"], "project": "flink"}
{"id": 4938, "code": "protected void initBroadcastInputsSerializers(int numBroadcastInputs) {\n    this.broadcastInputSerializers = new TypeSerializerFactory<?>[numBroadcastInputs];\n\n    ClassLoader userCodeClassLoader = getUserCodeClassLoader();\n\n    for (int i = 0; i < numBroadcastInputs; i++) {\n            \n        final TypeSerializerFactory<?> serializerFactory =\n                this.config.getBroadcastInputSerializer(i, userCodeClassLoader);\n        this.broadcastInputSerializers[i] = serializerFactory;\n    }\n}", "summary_tokens": ["creates", "all", "the", "serializers", "and", "iterators", "for", "the", "broadcast", "inputs"], "project": "flink"}
{"id": 1418, "code": "default void handleSourceEvents(SourceEvent sourceEvent) {}", "summary_tokens": ["handle", "a", "custom", "source", "event", "sent", "by", "the", "split", "enumerator"], "project": "flink"}
{"id": 6741, "code": "private SkipListIterateAndProcessResult iterateAndProcess(\n        MemorySegment keySegment,\n        int keyOffset,\n        int keyLen,\n        BiFunction<SkipListNodePointers, Boolean, S> function) {\n    int deleteCount = 0;\n    long prevNode = findPredecessor(keySegment, keyOffset, 1);\n    long currentNode = helpGetNextNode(prevNode, 0);\n    long nextNode;\n\n    int c;\n    while (currentNode != NIL_NODE) {\n        nextNode = helpGetNextNode(currentNode, 0);\n\n            \n            \n            \n            \n            \n        boolean isRemoved = isNodeRemoved(currentNode);\n        if (isRemoved\n                && highestRequiredSnapshotVersionPlusOne == 0\n                && deleteCount < numKeysToDeleteOneTime) {\n            doPhysicalRemove(currentNode, prevNode, nextNode);\n            logicallyRemovedNodes.remove(currentNode);\n            currentNode = nextNode;\n            deleteCount++;\n            continue;\n        }\n\n        c = compareSegmentAndNode(keySegment, keyOffset, keyLen, currentNode);\n\n        if (c < 0) {\n                \n            break;\n        } else if (c > 0) {\n                \n            prevNode = currentNode;\n            currentNode = nextNode;\n        } else {\n                \n            S state =\n                    function.apply(\n                            new SkipListNodePointers(prevNode, currentNode, nextNode),\n                            isRemoved);\n            return new SkipListIterateAndProcessResult(prevNode, currentNode, true, state);\n        }\n    }\n    return new SkipListIterateAndProcessResult(prevNode, currentNode, false, null);\n}", "summary_tokens": ["iterate", "the", "skip", "list", "and", "perform", "given", "function"], "project": "flink"}
{"id": 1203, "code": "public Set<FieldSet> getUniqueFields() {\n    return this.uniqueFields;\n}", "summary_tokens": ["gets", "the", "field", "sets", "that", "are", "unique"], "project": "flink"}
{"id": 3829, "code": "private RunnerApi.Coder getWindowCoderProto() {\n    return RunnerApi.Coder.newBuilder()\n            .setSpec(\n                    RunnerApi.FunctionSpec.newBuilder()\n                            .setUrn(ModelCoders.GLOBAL_WINDOW_CODER_URN)\n                            .build())\n            .build();\n}", "summary_tokens": ["gets", "the", "proto", "representation", "of", "the", "window", "coder"], "project": "flink"}
{"id": 108, "code": "public Properties getContainerProperties() {\n    return getProperties(getContainerEndpointUrl());\n}", "summary_tokens": ["returns", "the", "properties", "to", "access", "the", "container", "from", "outside", "the", "docker", "network"], "project": "flink"}
{"id": 6293, "code": "public void testAllocatedSlotRelease() {\n    final CompletableFuture<LogicalSlot> returnSlotFuture = new CompletableFuture<>();\n    final WaitingSlotOwner waitingSlotOwner =\n            new WaitingSlotOwner(returnSlotFuture, new CompletableFuture<>());\n    final SingleLogicalSlot singleLogicalSlot = createSingleLogicalSlot(waitingSlotOwner);\n\n    final CompletableFuture<?> terminalStateFuture = new CompletableFuture<>();\n    final CompletableFuture<?> failFuture = new CompletableFuture<>();\n    final ManualTestingPayload dummyPayload =\n            new ManualTestingPayload(failFuture, terminalStateFuture);\n\n    assertThat(singleLogicalSlot.tryAssignPayload(dummyPayload), is(true));\n\n    singleLogicalSlot.release(new FlinkException(\"Test exception\"));\n\n    assertThat(failFuture.isDone(), is(true));\n        \n        \n    assertThat(returnSlotFuture.isDone(), is(false));\n}", "summary_tokens": ["tests", "that", "the", "physical", "slot"], "project": "flink"}
{"id": 7593, "code": "public void allActionsCompleted() {\n    sendPoisonMail(\n            () -> {\n                mailboxLoopRunning = false;\n                suspended = true;\n            });\n}", "summary_tokens": ["this", "method", "must", "be", "called", "to", "end", "the", "stream", "task", "when", "all", "actions", "for", "the", "tasks", "have", "been", "performed"], "project": "flink"}
{"id": 4767, "code": "public List<Path> getUserJars() {\n    return userJars;\n}", "summary_tokens": ["gets", "the", "list", "of", "assigned", "user", "jar", "paths"], "project": "flink"}
{"id": 499, "code": "public KafkaRecordSerializationSchema<IN> build() {\n    checkState(valueSerializationSchema != null, \"No value serializer is configured.\");\n    checkState(topicSelector != null, \"No topic selector is configured.\");\n    return new KafkaRecordSerializationSchemaWrapper<>(\n            topicSelector, valueSerializationSchema, keySerializationSchema, partitioner);\n}", "summary_tokens": ["constructs", "the", "kafka", "record", "serialization", "schema", "builder", "with", "the", "configured", "properties"], "project": "flink"}
{"id": 218, "code": "public void runEmptyAddressesTest() {\n    try {\n        createElasticsearchSink(\n                1,\n                getClusterName(),\n                Collections.emptyList(),\n                SourceSinkDataTestKit.getJsonSinkFunction(\"test\"));\n    } catch (IllegalArgumentException expectedException) {\n            \n        return;\n    }\n\n    fail();\n}", "summary_tokens": ["tests", "that", "the", "elasticsearch", "sink", "fails", "eagerly", "if", "the", "provided", "list", "of", "addresses", "is", "empty"], "project": "flink"}
{"id": 1842, "code": "public float getValue() {\n    return this.value;\n}", "summary_tokens": ["returns", "the", "value", "of", "the", "encapsulated", "primitive", "float"], "project": "flink"}
{"id": 1603, "code": "static Field getField(String fieldName, Class<?> declaringClass) {\n    Class<?> clazz = declaringClass;\n\n    while (clazz != null) {\n        try {\n            Field field = clazz.getDeclaredField(fieldName);\n            field.setAccessible(true);\n            return field;\n        } catch (NoSuchFieldException e) {\n            clazz = clazz.getSuperclass();\n        }\n    }\n\n    return null;\n}", "summary_tokens": ["finds", "a", "field", "by", "name", "from", "its", "declaring", "class"], "project": "flink"}
{"id": 3359, "code": "public int getSuperstepNumber() {\n    return this.runtimeContext.getSuperstepNumber();\n}", "summary_tokens": ["gets", "the", "number", "of", "the", "superstep", "starting", "at", "tt", "0", "tt"], "project": "flink"}
{"id": 8367, "code": "static int numBytesForFirstByte(final byte b) {\n    if (b >= 0) {\n            \n        return 1;\n    } else if ((b >> 5) == -2 && (b & 0x1e) != 0) {\n            \n        return 2;\n    } else if ((b >> 4) == -2) {\n            \n        return 3;\n    } else if ((b >> 3) == -2) {\n            \n        return 4;\n    } else {\n            \n            \n        return 1;\n    }\n}", "summary_tokens": ["returns", "the", "number", "of", "bytes", "for", "a", "code", "point", "with", "the", "first", "byte", "as", "b"], "project": "flink"}
{"id": 6290, "code": "public void testJobMasterRejectsTaskExecutorRegistrationIfJobIdsAreNotEqual() throws Exception {\n    final JobMaster jobMaster = new JobMasterBuilder(jobGraph, rpcService).createJobMaster();\n\n    try {\n        jobMaster.start();\n\n        final CompletableFuture<RegistrationResponse> registrationResponse =\n                jobMaster.registerTaskManager(\n                        \"foobar\",\n                        new LocalUnresolvedTaskManagerLocation(),\n                        new JobID(),\n                        testingTimeout);\n\n        assertThat(registrationResponse.get(), instanceOf(JMTMRegistrationRejection.class));\n    } finally {\n        RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout);\n    }\n}", "summary_tokens": ["tests", "that", "the", "job", "master", "rejects", "a", "task", "executor", "registration", "attempt", "if", "the", "expected", "and", "actual", "job", "id", "are", "not", "equal"], "project": "flink"}
{"id": 8434, "code": "private static List<String> extractWildcardPrefixes(List<String> propertyKeys) {\n    return propertyKeys.stream()\n            .filter(p -> p.endsWith(\"*\"))\n            .map(s -> s.substring(0, s.length() - 1))\n            .collect(Collectors.toList());\n}", "summary_tokens": ["converts", "the", "prefix", "of", "properties", "with", "wildcards", "e"], "project": "flink"}
{"id": 5302, "code": "public long getTimestamp() {\n    return timestamp;\n}", "summary_tokens": ["the", "time", "the", "failure", "occurred"], "project": "flink"}
{"id": 3572, "code": "public void addDiskCost(double bytes) {\n    this.diskCost = (this.diskCost < 0 || bytes < 0) ? UNKNOWN : this.diskCost + bytes;\n}", "summary_tokens": ["adds", "the", "costs", "for", "disk", "to", "the", "current", "disk", "costs", "for", "this", "costs", "object"], "project": "flink"}
{"id": 3763, "code": "public void checkJoinWithReplicatedSourceInputBehindFilter() {\n\n    ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    TupleTypeInfo<Tuple1<String>> typeInfo = TupleTypeInfo.getBasicTupleTypeInfo(String.class);\n    ReplicatingInputFormat<Tuple1<String>, FileInputSplit> rif =\n            new ReplicatingInputFormat<Tuple1<String>, FileInputSplit>(\n                    new TupleCsvInputFormat<Tuple1<String>>(new Path(\"/some/path\"), typeInfo));\n\n    DataSet<Tuple1<String>> source1 =\n            env.createInput(\n                    rif, new TupleTypeInfo<Tuple1<String>>(BasicTypeInfo.STRING_TYPE_INFO));\n    DataSet<Tuple1<String>> source2 = env.readCsvFile(\"/some/otherpath\").types(String.class);\n\n    DataSink<Tuple2<Tuple1<String>, Tuple1<String>>> out =\n            source1.filter(new NoFilter())\n                    .join(source2)\n                    .where(\"*\")\n                    .equalTo(\"*\")\n                    .writeAsText(\"/some/newpath\");\n\n    Plan plan = env.createProgramPlan();\n\n        \n    OptimizedPlan oPlan = compileNoStats(plan);\n\n        \n        \n    SinkPlanNode sinkNode = oPlan.getDataSinks().iterator().next();\n    DualInputPlanNode joinNode = (DualInputPlanNode) sinkNode.getPredecessor();\n\n    ShipStrategyType joinIn1 = joinNode.getInput1().getShipStrategy();\n    ShipStrategyType joinIn2 = joinNode.getInput2().getShipStrategy();\n\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\", ShipStrategyType.FORWARD, joinIn1);\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\", ShipStrategyType.FORWARD, joinIn2);\n}", "summary_tokens": ["tests", "join", "program", "with", "replicated", "data", "source", "behind", "filter"], "project": "flink"}
{"id": 6035, "code": "public void testSuspendedOutOfRunning() throws Exception {\n    final int parallelism = 10;\n    final InteractionsCountingTaskManagerGateway gateway =\n            new InteractionsCountingTaskManagerGateway(parallelism);\n    final SchedulerBase scheduler = createScheduler(gateway, parallelism);\n    final ExecutionGraph eg = scheduler.getExecutionGraph();\n\n    scheduler.startScheduling();\n    ExecutionGraphTestUtils.switchAllVerticesToRunning(eg);\n\n    assertEquals(JobStatus.RUNNING, eg.getState());\n    validateAllVerticesInState(eg, ExecutionState.RUNNING);\n\n        \n    scheduler.closeAsync();\n\n    assertEquals(JobStatus.SUSPENDED, eg.getState());\n    validateCancelRpcCalls(gateway, parallelism);\n\n    ensureCannotLeaveSuspendedState(scheduler, gateway);\n}", "summary_tokens": ["going", "into", "suspended", "out", "of", "running", "vertices", "should", "cancel", "all", "vertices", "once", "with", "rpc", "calls"], "project": "flink"}
{"id": 1581, "code": "public static <IN, OUT> TypeInformation<OUT> getUnaryOperatorReturnType(\n        Function function,\n        Class<?> baseClass,\n        int inputTypeArgumentIndex,\n        int outputTypeArgumentIndex,\n        int[] lambdaOutputTypeArgumentIndices,\n        TypeInformation<IN> inType,\n        String functionName,\n        boolean allowMissing) {\n\n    Preconditions.checkArgument(\n            inType == null || inputTypeArgumentIndex >= 0,\n            \"Input type argument index was not provided\");\n    Preconditions.checkArgument(\n            outputTypeArgumentIndex >= 0, \"Output type argument index was not provided\");\n    Preconditions.checkArgument(\n            lambdaOutputTypeArgumentIndices != null,\n            \"Indices for output type arguments within lambda not provided\");\n\n        \n    if (function instanceof ResultTypeQueryable) {\n        return ((ResultTypeQueryable<OUT>) function).getProducedType();\n    }\n\n        \n    try {\n        final LambdaExecutable exec;\n        try {\n            exec = checkAndExtractLambda(function);\n        } catch (TypeExtractionException e) {\n            throw new InvalidTypesException(\"Internal error occurred.\", e);\n        }\n        if (exec != null) {\n\n                \n                \n                \n                \n            final int paramLen = exec.getParameterTypes().length;\n\n            final Method sam = TypeExtractionUtils.getSingleAbstractMethod(baseClass);\n\n                \n                \n            final int baseParametersLen = sam.getParameterTypes().length;\n\n            final Type output;\n            if (lambdaOutputTypeArgumentIndices.length > 0) {\n                output =\n                        TypeExtractionUtils.extractTypeFromLambda(\n                                baseClass,\n                                exec,\n                                lambdaOutputTypeArgumentIndices,\n                                paramLen,\n                                baseParametersLen);\n            } else {\n                output = exec.getReturnType();\n                TypeExtractionUtils.validateLambdaType(baseClass, output);\n            }\n\n            return new TypeExtractor().privateCreateTypeInfo(output, inType, null);\n        } else {\n            if (inType != null) {\n                validateInputType(\n                        baseClass, function.getClass(), inputTypeArgumentIndex, inType);\n            }\n            return new TypeExtractor()\n                    .privateCreateTypeInfo(\n                            baseClass,\n                            function.getClass(),\n                            outputTypeArgumentIndex,\n                            inType,\n                            null);\n        }\n    } catch (InvalidTypesException e) {\n        if (allowMissing) {\n            return (TypeInformation<OUT>)\n                    new MissingTypeInfo(\n                            functionName != null ? functionName : function.toString(), e);\n        } else {\n            throw e;\n        }\n    }\n}", "summary_tokens": ["returns", "the", "unary", "operator", "s", "return", "type"], "project": "flink"}
{"id": 8245, "code": "public static UniqueConstraint primaryKey(String name, List<String> columns) {\n    return new UniqueConstraint(name, false, ConstraintType.PRIMARY_KEY, columns);\n}", "summary_tokens": ["creates", "a", "non", "enforced", "constraint", "type", "primary", "key", "constraint"], "project": "flink"}
{"id": 3859, "code": "private boolean isWindowLate(W window) {\n    return windowAssigner.isEventTime()\n            && (toEpochMillsForTimer(cleanupTime(window), shiftTimeZone)\n                    <= internalTimerService.currentWatermark());\n}", "summary_tokens": ["returns", "true", "if", "the", "watermark", "is", "after", "the", "end", "timestamp", "plus", "the", "allowed", "lateness", "of", "the", "given", "window"], "project": "flink"}
{"id": 5858, "code": "private void testPutBufferFailsStore(@Nullable final JobID jobId, BlobKey.BlobType blobType)\n        throws IOException {\n    assumeTrue(!OperatingSystem.isWindows()); \n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    File jobStoreDir = null;\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore())) {\n\n        server.start();\n\n            \n        jobStoreDir =\n                server.getStorageLocation(jobId, BlobKey.createKey(blobType)).getParentFile();\n        assertTrue(jobStoreDir.setExecutable(true, false));\n        assertTrue(jobStoreDir.setReadable(true, false));\n        assertTrue(jobStoreDir.setWritable(false, false));\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n\n            \n        exception.expect(AccessDeniedException.class);\n\n        try {\n            put(server, jobId, data, blobType);\n        } finally {\n                \n            File incomingFileDir = new File(jobStoreDir.getParent(), \"incoming\");\n            assertArrayEquals(new String[] {}, incomingFileDir.list());\n\n                \n            assertArrayEquals(new String[] {}, jobStoreDir.list());\n        }\n    } finally {\n            \n        if (jobStoreDir != null) {\n                \n            jobStoreDir.setWritable(true, false);\n        }\n    }\n}", "summary_tokens": ["uploads", "a", "byte", "array", "to", "a", "server", "which", "cannot", "move", "incoming", "files", "to", "the", "final", "blob", "store", "via", "the", "blob", "server"], "project": "flink"}
{"id": 5551, "code": "public InstanceID getRegistrationId() {\n    return registrationId;\n}", "summary_tokens": ["gets", "the", "id", "that", "the", "resource", "manager", "assigned", "the", "registration"], "project": "flink"}
{"id": 5711, "code": "public Optional<Tuple2<String, UUID>> getLeaderNow() throws Exception {\n    CompletableFuture<Tuple2<String, UUID>> leaderFuture = this.atomicLeaderFuture.get();\n    if (leaderFuture != null) {\n        if (leaderFuture.isDone()) {\n            return Optional.of(leaderFuture.get());\n        } else {\n            return Optional.empty();\n        }\n    } else {\n        return Optional.empty();\n    }\n}", "summary_tokens": ["returns", "the", "current", "leader", "information", "if", "available"], "project": "flink"}
{"id": 236, "code": "public Optional<CheckpointedPosition> getReaderPosition() {\n    return Optional.ofNullable(readerPosition);\n}", "summary_tokens": ["gets", "the", "checkpointed", "position", "of", "the", "reader", "if", "set"], "project": "flink"}
{"id": 5809, "code": "public void testSSLServerFailure2() throws Exception {\n        \n    uploadJarFile(blobSslServer, nonSslClientConfig);\n}", "summary_tokens": ["verify", "non", "ssl", "client", "to", "ssl", "server", "failure"], "project": "flink"}
{"id": 6683, "code": "public static String getCurrentClasspath() {\n    RuntimeMXBean bean = ManagementFactory.getRuntimeMXBean();\n    return bean.getClassPath();\n}", "summary_tokens": ["gets", "the", "classpath", "with", "which", "the", "current", "jvm", "was", "started"], "project": "flink"}
{"id": 7879, "code": "public void testCloseUnblocks() throws InterruptedException {\n    testAllPuttingUnblocksInternal(TaskMailbox::close);\n}", "summary_tokens": ["test", "that", "closing", "the", "mailbox", "unblocks", "pending", "accesses", "with", "correct", "exceptions"], "project": "flink"}
{"id": 4803, "code": "public ExecutionConfig getExecutionConfig() {\n    return this.environment.getExecutionConfig();\n}", "summary_tokens": ["returns", "the", "global", "execution", "config"], "project": "flink"}
{"id": 8094, "code": "private void registerTempSystemFunction(String name, FunctionDefinition functionDefinition) {\n        \n        \n        \n        \n        \n        \n        \n    tempSystemFunctions.put(\n            FunctionIdentifier.normalizeName(name),\n            new InlineCatalogFunction(functionDefinition));\n}", "summary_tokens": ["use", "register", "temporary", "system", "function", "string", "function", "definition", "boolean", "instead"], "project": "flink"}
{"id": 7981, "code": "public String getBuiltInDatabaseName() {\n    return builtInDatabaseName;\n}", "summary_tokens": ["gets", "the", "specified", "name", "of", "the", "default", "database", "in", "the", "initial", "catalog", "to", "be", "created", "when", "instantiating", "a", "table", "environment"], "project": "flink"}
{"id": 3009, "code": "public void testHeapMemoryPropertyWithArbitraryUnit() throws Exception {\n    final String[] args =\n            new String[] {\n                \"-e\",\n                KubernetesSessionClusterExecutor.NAME,\n                \"-D\" + JobManagerOptions.TOTAL_PROCESS_MEMORY.key() + \"=1g\",\n                \"-D\" + TaskManagerOptions.TOTAL_PROCESS_MEMORY.key() + \"=3g\"\n            };\n\n    final KubernetesSessionCli cli = createFlinkKubernetesCustomCliWithJmAndTmTotalMemory(1024);\n\n    final Configuration executorConfig = cli.getEffectiveConfiguration(args);\n    final ClusterClientFactory<String> clientFactory = getClusterClientFactory(executorConfig);\n    final ClusterSpecification clusterSpecification =\n            clientFactory.getClusterSpecification(executorConfig);\n\n    assertThat(clusterSpecification.getMasterMemoryMB(), is(1024));\n    assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(3072));\n}", "summary_tokens": ["tests", "the", "specifying", "heap", "memory", "with", "arbitrary", "unit", "for", "job", "manager", "and", "task", "manager"], "project": "flink"}
{"id": 9227, "code": "public static JoinRecordStateView create(\n        RuntimeContext ctx,\n        String stateName,\n        JoinInputSideSpec inputSideSpec,\n        InternalTypeInfo<RowData> recordType,\n        long retentionTime) {\n    StateTtlConfig ttlConfig = createTtlConfig(retentionTime);\n    if (inputSideSpec.hasUniqueKey()) {\n        if (inputSideSpec.joinKeyContainsUniqueKey()) {\n            return new JoinKeyContainsUniqueKey(ctx, stateName, recordType, ttlConfig);\n        } else {\n            return new InputSideHasUniqueKey(\n                    ctx,\n                    stateName,\n                    recordType,\n                    inputSideSpec.getUniqueKeyType(),\n                    inputSideSpec.getUniqueKeySelector(),\n                    ttlConfig);\n        }\n    } else {\n        return new InputSideHasNoUniqueKey(ctx, stateName, recordType, ttlConfig);\n    }\n}", "summary_tokens": ["creates", "a", "join", "record", "state", "view", "depends", "on", "join", "input", "side", "spec"], "project": "flink"}
{"id": 7095, "code": "public DataStreamSink<T> slotSharingGroup(SlotSharingGroup slotSharingGroup) {\n    transformation.setSlotSharingGroup(slotSharingGroup);\n    return this;\n}", "summary_tokens": ["sets", "the", "slot", "sharing", "group", "of", "this", "operation"], "project": "flink"}
{"id": 2926, "code": "public void testOutOfTupleBoundsDataset1() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    DataSet<Tuple5<Integer, Long, String, Long, Integer>> tupleDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo);\n\n        \n    tupleDs.maxBy(5);\n}", "summary_tokens": ["this", "test", "validates", "that", "an", "index", "which", "is", "out", "of", "bounds", "throws", "an", "index", "out", "of", "bounds", "exception"], "project": "flink"}
{"id": 3174, "code": "public <T> Graph<K, VV, EV> joinWithVertices(\n        DataSet<Tuple2<K, T>> inputDataSet,\n        final VertexJoinFunction<VV, T> vertexJoinFunction) {\n\n    DataSet<Vertex<K, VV>> resultedVertices =\n            this.getVertices()\n                    .coGroup(inputDataSet)\n                    .where(0)\n                    .equalTo(0)\n                    .with(new ApplyCoGroupToVertexValues<>(vertexJoinFunction))\n                    .name(\"Join with vertices\");\n    return new Graph<>(resultedVertices, this.edges, this.context);\n}", "summary_tokens": ["joins", "the", "vertex", "data", "set", "of", "this", "graph", "with", "an", "input", "tuple", "0", "data", "set", "and", "applies", "a", "user", "defined", "transformation", "on", "the", "values", "of", "the", "matched", "records"], "project": "flink"}
{"id": 2530, "code": "public byte[] serialize(T object) {\n    if (object == null) {\n        return null;\n    }\n\n    if (glueSchemaRegistryJsonSchemaCoder == null) {\n        glueSchemaRegistryJsonSchemaCoder = glueSchemaRegistryJsonSchemaCoderProvider.get();\n    }\n    return glueSchemaRegistryJsonSchemaCoder.registerSchemaAndSerialize(object);\n}", "summary_tokens": ["serializes", "the", "incoming", "element", "to", "a", "byte", "array", "containing", "bytes", "of", "aws", "glue", "schema", "registry", "information"], "project": "flink"}
{"id": 7324, "code": "public void clear(Context context) throws Exception {}", "summary_tokens": ["deletes", "any", "state", "in", "the", "context", "when", "the", "window", "expires", "the", "watermark", "passes", "its", "max", "timestamp", "allowed", "lateness"], "project": "flink"}
{"id": 6595, "code": "public void testKeyGroupSnapshotRestoreScaleDown() throws Exception {\n    testKeyGroupSnapshotRestore(4, 2, 128);\n}", "summary_tokens": ["this", "test", "verifies", "that", "state", "is", "correctly", "assigned", "to", "key", "groups", "and", "that", "restore", "restores", "the", "relevant", "key", "groups", "in", "the", "backend"], "project": "flink"}
{"id": 813, "code": "public void close() {\n    kinesisProxyV2Interface.close();\n}", "summary_tokens": ["destroy", "any", "open", "resources", "used", "by", "the", "factory"], "project": "flink"}
{"id": 6320, "code": "public void testReporterScheduling() throws Exception {\n    MetricConfig config = new MetricConfig();\n    config.setProperty(\"arg1\", \"hello\");\n    config.setProperty(ConfigConstants.METRICS_REPORTER_INTERVAL_SUFFIX, \"50 MILLISECONDS\");\n\n    MetricRegistryImpl registry =\n            new MetricRegistryImpl(\n                    MetricRegistryTestUtils.defaultMetricRegistryConfiguration(),\n                    Collections.singletonList(\n                            ReporterSetup.forReporter(\"test\", config, new TestReporter3())));\n\n    long start = System.currentTimeMillis();\n\n        \n    TestReporter3.reportCount = 0;\n\n    for (int x = 0; x < 10; x++) {\n        Thread.sleep(100);\n        int reportCount = TestReporter3.reportCount;\n        long curT = System.currentTimeMillis();\n            \n        long maxAllowedReports = (curT - start) / 50 + 2;\n        Assert.assertTrue(\"Too many reports were triggered.\", maxAllowedReports >= reportCount);\n    }\n    Assert.assertTrue(\"No report was triggered.\", TestReporter3.reportCount > 0);\n\n    registry.shutdown().get();\n}", "summary_tokens": ["verifies", "that", "reporters", "implementing", "the", "scheduled", "interface", "are", "regularly", "called", "to", "report", "the", "metrics"], "project": "flink"}
{"id": 8708, "code": "private static void appendAsJava(\n        Comparable value,\n        StringBuilder sb,\n        SqlTypeName typeName,\n        RelDataType type,\n        boolean java,\n        RexDigestIncludeType includeType) {\n    switch (typeName) {\n        case CHAR:\n            NlsString nlsString = (NlsString) value;\n            if (java) {\n                Util.printJavaString(sb, nlsString.getValue(), true);\n            } else {\n                boolean includeCharset =\n                        (nlsString.getCharsetName() != null)\n                                && !nlsString\n                                        .getCharsetName()\n                                        .equals(CalciteSystemProperty.DEFAULT_CHARSET.value());\n                sb.append(nlsString.asSql(includeCharset, false));\n            }\n            break;\n        case BOOLEAN:\n            assert value instanceof Boolean;\n            sb.append(value.toString());\n            break;\n        case DECIMAL:\n            assert value instanceof BigDecimal;\n            sb.append(value.toString());\n            break;\n        case DOUBLE:\n            assert value instanceof BigDecimal;\n            sb.append(Util.toScientificNotation((BigDecimal) value));\n            break;\n        case BIGINT:\n            assert value instanceof BigDecimal;\n            long narrowLong = ((BigDecimal) value).longValue();\n            sb.append(String.valueOf(narrowLong));\n            sb.append('L');\n            break;\n        case BINARY:\n            assert value instanceof ByteString;\n            sb.append(\"X'\");\n            sb.append(((ByteString) value).toString(16));\n            sb.append(\"'\");\n            break;\n        case NULL:\n            assert value == null;\n            sb.append(\"null\");\n            break;\n        case SARG:\n            assert value instanceof Sarg;\n                \n            Util.asStringBuilder(sb, sb2 -> printSarg(sb2, (Sarg) value, type));\n            break;\n        case SYMBOL:\n            assert value instanceof Enum;\n            sb.append(\"FLAG(\");\n            sb.append(value.toString());\n            sb.append(\")\");\n            break;\n        case DATE:\n            assert value instanceof DateString;\n            sb.append(value.toString());\n            break;\n        case TIME:\n        case TIME_WITH_LOCAL_TIME_ZONE:\n            assert value instanceof TimeString;\n            sb.append(value.toString());\n            break;\n        case TIMESTAMP:\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            assert value instanceof TimestampString;\n            sb.append(value.toString());\n            break;\n        case INTERVAL_YEAR:\n        case INTERVAL_YEAR_MONTH:\n        case INTERVAL_MONTH:\n        case INTERVAL_DAY:\n        case INTERVAL_DAY_HOUR:\n        case INTERVAL_DAY_MINUTE:\n        case INTERVAL_DAY_SECOND:\n        case INTERVAL_HOUR:\n        case INTERVAL_HOUR_MINUTE:\n        case INTERVAL_HOUR_SECOND:\n        case INTERVAL_MINUTE:\n        case INTERVAL_MINUTE_SECOND:\n        case INTERVAL_SECOND:\n            assert value instanceof BigDecimal;\n            sb.append(value.toString());\n            break;\n        case MULTISET:\n        case ROW:\n            final List<RexLiteral> list = (List) value;\n            Util.asStringBuilder(\n                    sb,\n                    sb2 ->\n                            Util.printList(\n                                    sb,\n                                    list.size(),\n                                    (sb3, i) ->\n                                            sb3.append(\n                                                    list.get(i).computeDigest(includeType))));\n            break;\n        case GEOMETRY:\n            final String wkt = GeoFunctions.ST_AsWKT((Geometries.Geom) value);\n            sb.append(wkt);\n            break;\n        default:\n            assert valueMatchesType(value, typeName, true);\n            throw Util.needToImplement(typeName);\n    }\n}", "summary_tokens": ["appends", "the", "specified", "value", "in", "the", "provided", "destination", "as", "a", "java", "string"], "project": "flink"}
{"id": 2807, "code": "public boolean useKeySelector() {\n    return useKeySelector;\n}", "summary_tokens": ["returns", "whether", "using", "key", "selector", "or", "not"], "project": "flink"}
{"id": 3662, "code": "public LocalProperties filterBySemanticProperties(SemanticProperties props, int input) {\n\n    if (props == null) {\n        throw new NullPointerException(\"SemanticProperties may not be null.\");\n    }\n\n    LocalProperties returnProps = new LocalProperties();\n\n        \n    if (this.ordering != null) {\n        Ordering newOrdering = new Ordering();\n\n        for (int i = 0; i < this.ordering.getInvolvedIndexes().size(); i++) {\n            int sourceField = this.ordering.getInvolvedIndexes().get(i);\n            FieldSet targetField = props.getForwardingTargetFields(input, sourceField);\n            if (targetField == null || targetField.size() == 0) {\n                if (i == 0) {\n                        \n                    newOrdering = null;\n                    break;\n                } else {\n                        \n                    break;\n                }\n            } else {\n                    \n                    \n                if (targetField.size() > 1) {\n                    LOG.warn(\n                            \"Found that a field is forwarded to more than one target field in \"\n                                    + \"semantic forwarded field information. Will only use the field with the lowest index.\");\n                }\n                newOrdering.appendOrdering(\n                        targetField.toArray()[0],\n                        this.ordering.getType(i),\n                        this.ordering.getOrder(i));\n            }\n        }\n\n        returnProps.ordering = newOrdering;\n        if (newOrdering != null) {\n            returnProps.groupedFields = newOrdering.getInvolvedIndexes();\n        } else {\n            returnProps.groupedFields = null;\n        }\n    }\n        \n    else if (this.groupedFields != null) {\n        FieldList newGroupedFields = new FieldList();\n\n        for (Integer sourceField : this.groupedFields) {\n            FieldSet targetField = props.getForwardingTargetFields(input, sourceField);\n            if (targetField == null || targetField.size() == 0) {\n                newGroupedFields = null;\n                break;\n            } else {\n                    \n                    \n                if (targetField.size() > 1) {\n                    LOG.warn(\n                            \"Found that a field is forwarded to more than one target field in \"\n                                    + \"semantic forwarded field information. Will only use the field with the lowest index.\");\n                }\n                newGroupedFields = newGroupedFields.addField(targetField.toArray()[0]);\n            }\n        }\n        returnProps.groupedFields = newGroupedFields;\n    }\n\n    if (this.uniqueFields != null) {\n        Set<FieldSet> newUniqueFields = new HashSet<FieldSet>();\n        for (FieldSet fields : this.uniqueFields) {\n            FieldSet newFields = new FieldSet();\n            for (Integer sourceField : fields) {\n                FieldSet targetField = props.getForwardingTargetFields(input, sourceField);\n\n                if (targetField == null || targetField.size() == 0) {\n                    newFields = null;\n                    break;\n                } else {\n                        \n                        \n                    if (targetField.size() > 1) {\n                        LOG.warn(\n                                \"Found that a field is forwarded to more than one target field in \"\n                                        + \"semantic forwarded field information. Will only use the field with the lowest index.\");\n                    }\n                    newFields = newFields.addField(targetField.toArray()[0]);\n                }\n            }\n            if (newFields != null) {\n                newUniqueFields.add(newFields);\n            }\n        }\n\n        if (!newUniqueFields.isEmpty()) {\n            returnProps.uniqueFields = newUniqueFields;\n        } else {\n            returnProps.uniqueFields = null;\n        }\n    }\n\n    return returnProps;\n}", "summary_tokens": ["filters", "these", "local", "properties", "by", "the", "fields", "that", "are", "forwarded", "to", "the", "output", "as", "described", "by", "the", "semantic", "properties"], "project": "flink"}
{"id": 386, "code": "public long getTotalSeconds() {\n    return totalSeconds;\n}", "summary_tokens": ["returns", "days", "hours", "minutes", "all", "converted", "into", "seconds"], "project": "flink"}
{"id": 5238, "code": "private static String targetToString(Object target) {\n    if (target instanceof Class) {\n        return ((Class<?>) target).getName();\n    } else {\n        return target.toString();\n    }\n}", "summary_tokens": ["helper", "for", "to", "string"], "project": "flink"}
{"id": 8506, "code": "public LogicalType getLogicalType() {\n    return logicalType;\n}", "summary_tokens": ["returns", "the", "corresponding", "logical", "type"], "project": "flink"}
{"id": 7252, "code": "public void configure(ReadableConfig configuration, ClassLoader classLoader) {\n    configuration\n            .getOptional(StreamPipelineOptions.TIME_CHARACTERISTIC)\n            .ifPresent(this::setStreamTimeCharacteristic);\n    configuration\n            .getOptional(StateChangelogOptions.ENABLE_STATE_CHANGE_LOG)\n            .ifPresent(this::enableChangelogStateBackend);\n    Optional.ofNullable(loadStateBackend(configuration, classLoader))\n            .ifPresent(this::setStateBackend);\n    configuration\n            .getOptional(PipelineOptions.OPERATOR_CHAINING)\n            .ifPresent(c -> this.isChainingEnabled = c);\n    configuration\n            .getOptional(ExecutionOptions.BUFFER_TIMEOUT)\n            .ifPresent(t -> this.setBufferTimeout(t.toMillis()));\n    configuration\n            .getOptional(DeploymentOptions.JOB_LISTENERS)\n            .ifPresent(listeners -> registerCustomListeners(classLoader, listeners));\n    configuration\n            .getOptional(PipelineOptions.CACHED_FILES)\n            .ifPresent(\n                    f -> {\n                        this.cacheFile.clear();\n                        this.cacheFile.addAll(DistributedCache.parseCachedFilesFromString(f));\n                    });\n    configuration\n            .getOptional(ExecutionOptions.RUNTIME_MODE)\n            .ifPresent(\n                    runtimeMode ->\n                            this.configuration.set(ExecutionOptions.RUNTIME_MODE, runtimeMode));\n\n    configuration\n            .getOptional(ExecutionOptions.BATCH_SHUFFLE_MODE)\n            .ifPresent(\n                    shuffleMode ->\n                            this.configuration.set(\n                                    ExecutionOptions.BATCH_SHUFFLE_MODE, shuffleMode));\n\n    configuration\n            .getOptional(ExecutionOptions.SORT_INPUTS)\n            .ifPresent(\n                    sortInputs ->\n                            this.configuration.set(ExecutionOptions.SORT_INPUTS, sortInputs));\n    configuration\n            .getOptional(ExecutionOptions.USE_BATCH_STATE_BACKEND)\n            .ifPresent(\n                    sortInputs ->\n                            this.configuration.set(\n                                    ExecutionOptions.USE_BATCH_STATE_BACKEND, sortInputs));\n    configuration\n            .getOptional(PipelineOptions.NAME)\n            .ifPresent(jobName -> this.configuration.set(PipelineOptions.NAME, jobName));\n\n    configuration\n            .getOptional(ExecutionCheckpointingOptions.ENABLE_CHECKPOINTS_AFTER_TASKS_FINISH)\n            .ifPresent(\n                    flag ->\n                            this.configuration.set(\n                                    ExecutionCheckpointingOptions\n                                            .ENABLE_CHECKPOINTS_AFTER_TASKS_FINISH,\n                                    flag));\n\n    config.configure(configuration, classLoader);\n    checkpointCfg.configure(configuration);\n}", "summary_tokens": ["sets", "all", "relevant", "options", "contained", "in", "the", "readable", "config", "such", "as", "e"], "project": "flink"}
{"id": 9170, "code": "public static int hash(int hashCode, int level) {\n    final int rotation = level * 11;\n    int code = Integer.rotateLeft(hashCode, rotation);\n    return code >= 0 ? code : -(code + 1);\n}", "summary_tokens": ["the", "level", "parameter", "is", "needed", "so", "that", "we", "can", "have", "different", "hash", "functions", "when", "we", "recursively", "apply", "the", "partitioning", "so", "that", "the", "working", "set", "eventually", "fits", "into", "memory"], "project": "flink"}
{"id": 2214, "code": "public void testJMXServiceInit() throws Exception {\n    try {\n        JMXService.startInstance(\"23456-23466\");\n        assertTrue(JMXService.getPort().isPresent());\n    } finally {\n        JMXService.stopInstance();\n    }\n}", "summary_tokens": ["verifies", "initialize", "with", "port", "range"], "project": "flink"}
{"id": 9085, "code": "public static DecimalData sround(DecimalData b0, int r) {\n    if (r >= b0.scale) {\n        return b0;\n    }\n\n    BigDecimal b2 =\n            b0.toBigDecimal()\n                    .movePointRight(r)\n                    .setScale(0, RoundingMode.HALF_UP)\n                    .movePointLeft(r);\n    int p = b0.precision;\n    int s = b0.scale;\n    if (r < 0) {\n        return fromBigDecimal(b2, Math.min(38, 1 + p - s), 0);\n    } else { \n        return fromBigDecimal(b2, 1 + p - s + r, r);\n    }\n}", "summary_tokens": ["sql", "code", "round", "code", "operator", "applied", "to", "big", "decimal", "values"], "project": "flink"}
{"id": 7293, "code": "public void invoke(IN value) throws Exception {\n    byte[] msg = schema.serialize(value);\n\n    try {\n        outputStream.write(msg);\n        if (autoFlush) {\n            outputStream.flush();\n        }\n    } catch (IOException e) {\n            \n        if (maxNumRetries == 0) {\n            throw new IOException(\n                    \"Failed to send message '\"\n                            + value\n                            + \"' to socket server at \"\n                            + hostName\n                            + \":\"\n                            + port\n                            + \". Connection re-tries are not enabled.\",\n                    e);\n        }\n\n        LOG.error(\n                \"Failed to send message '\"\n                        + value\n                        + \"' to socket server at \"\n                        + hostName\n                        + \":\"\n                        + port\n                        + \". Trying to reconnect...\",\n                e);\n\n            \n            \n\n        synchronized (lock) {\n            IOException lastException = null;\n            retries = 0;\n\n            while (isRunning && (maxNumRetries < 0 || retries < maxNumRetries)) {\n\n                    \n                try {\n                    if (outputStream != null) {\n                        outputStream.close();\n                    }\n                } catch (IOException ee) {\n                    LOG.error(\"Could not close output stream from failed write attempt\", ee);\n                }\n                try {\n                    if (client != null) {\n                        client.close();\n                    }\n                } catch (IOException ee) {\n                    LOG.error(\"Could not close socket from failed write attempt\", ee);\n                }\n\n                    \n                retries++;\n\n                try {\n                        \n                    createConnection();\n\n                        \n                    outputStream.write(msg);\n\n                        \n                    return;\n                } catch (IOException ee) {\n                    lastException = ee;\n                    LOG.error(\n                            \"Re-connect to socket server and send message failed. Retry time(s): \"\n                                    + retries,\n                            ee);\n                }\n\n                    \n                lock.wait(CONNECTION_RETRY_DELAY);\n            }\n\n                \n                \n            if (isRunning) {\n                throw new IOException(\n                        \"Failed to send message '\"\n                                + value\n                                + \"' to socket server at \"\n                                + hostName\n                                + \":\"\n                                + port\n                                + \". Failed after \"\n                                + retries\n                                + \" retries.\",\n                        lastException);\n            }\n        }\n    }\n}", "summary_tokens": ["called", "when", "new", "data", "arrives", "to", "the", "sink", "and", "forwards", "it", "to", "socket"], "project": "flink"}
{"id": 8951, "code": "private Transformation<RowData> applyConstraintValidations(\n        Transformation<RowData> inputTransform, TableConfig config, RowType physicalRowType) {\n    final ConstraintEnforcer.Builder validatorBuilder = ConstraintEnforcer.newBuilder();\n    final String[] fieldNames = physicalRowType.getFieldNames().toArray(new String[0]);\n\n        \n    final int[] notNullFieldIndices = getNotNullFieldIndices(physicalRowType);\n    if (notNullFieldIndices.length > 0) {\n        final ExecutionConfigOptions.NotNullEnforcer notNullEnforcer =\n                config.getConfiguration()\n                        .get(ExecutionConfigOptions.TABLE_EXEC_SINK_NOT_NULL_ENFORCER);\n        final List<String> notNullFieldNames =\n                Arrays.stream(notNullFieldIndices)\n                        .mapToObj(idx -> fieldNames[idx])\n                        .collect(Collectors.toList());\n\n        validatorBuilder.addNotNullConstraint(\n                notNullEnforcer, notNullFieldIndices, notNullFieldNames, fieldNames);\n    }\n\n    final ExecutionConfigOptions.TypeLengthEnforcer typeLengthEnforcer =\n            config.getConfiguration()\n                    .get(ExecutionConfigOptions.TABLE_EXEC_SINK_TYPE_LENGTH_ENFORCER);\n\n        \n    final List<ConstraintEnforcer.FieldInfo> charFieldInfo =\n            getFieldInfoForLengthEnforcer(physicalRowType, LengthEnforcerType.CHAR);\n    if (!charFieldInfo.isEmpty()) {\n        final List<String> charFieldNames =\n                charFieldInfo.stream()\n                        .map(cfi -> fieldNames[cfi.fieldIdx()])\n                        .collect(Collectors.toList());\n\n        validatorBuilder.addCharLengthConstraint(\n                typeLengthEnforcer, charFieldInfo, charFieldNames, fieldNames);\n    }\n\n        \n    final List<ConstraintEnforcer.FieldInfo> binaryFieldInfo =\n            getFieldInfoForLengthEnforcer(physicalRowType, LengthEnforcerType.BINARY);\n    if (!binaryFieldInfo.isEmpty()) {\n        final List<String> binaryFieldNames =\n                binaryFieldInfo.stream()\n                        .map(cfi -> fieldNames[cfi.fieldIdx()])\n                        .collect(Collectors.toList());\n\n        validatorBuilder.addBinaryLengthConstraint(\n                typeLengthEnforcer, binaryFieldInfo, binaryFieldNames, fieldNames);\n    }\n\n    ConstraintEnforcer constraintEnforcer = validatorBuilder.build();\n    if (constraintEnforcer != null) {\n        final String operatorDesc =\n                getFormattedOperatorDescription(\n                        constraintEnforcer.getOperatorName(), config.getConfiguration());\n        final String operatorName =\n                getFormattedOperatorName(\n                        constraintEnforcer.getOperatorName(),\n                        \"ConstraintEnforcer\",\n                        config.getConfiguration());\n        return ExecNodeUtil.createOneInputTransformation(\n                inputTransform,\n                operatorName,\n                operatorDesc,\n                constraintEnforcer,\n                getInputTypeInfo(),\n                inputTransform.getParallelism());\n    } else {\n            \n        return inputTransform;\n    }\n}", "summary_tokens": ["apply", "an", "operator", "to", "filter", "or", "report", "error", "to", "process", "not", "null", "values", "for", "not", "null", "fields"], "project": "flink"}
{"id": 1643, "code": "public double getDouble(ConfigOption<Double> configOption, double overrideDefault) {\n    return getOptional(configOption).orElse(overrideDefault);\n}", "summary_tokens": ["returns", "the", "value", "associated", "with", "the", "given", "config", "option", "as", "a", "double"], "project": "flink"}
{"id": 5720, "code": "public long getStartTime() {\n    return startTime;\n}", "summary_tokens": ["returns", "the", "timestamp", "when", "the", "sample", "was", "triggered"], "project": "flink"}
{"id": 4603, "code": "private void announceBacklog(NetworkSequenceViewReader reader, int backlog) {\n    checkArgument(backlog > 0, \"Backlog must be positive.\");\n\n    NettyMessage.BacklogAnnouncement announcement =\n            new NettyMessage.BacklogAnnouncement(backlog, reader.getReceiverId());\n    ctx.channel()\n            .writeAndFlush(announcement)\n            .addListener(\n                    (ChannelFutureListener)\n                            future -> {\n                                if (!future.isSuccess()) {\n                                    onChannelFutureFailure(future);\n                                }\n                            });\n}", "summary_tokens": ["announces", "remaining", "backlog", "to", "the", "consumer", "after", "the", "available", "data", "notification", "or", "data", "consumption", "resumption"], "project": "flink"}
{"id": 3276, "code": "public void postSuperstep() {}", "summary_tokens": ["this", "method", "is", "executed", "once", "per", "superstep", "after", "the", "vertex", "update", "function", "has", "been", "invoked", "for", "each", "vertex"], "project": "flink"}
{"id": 1146, "code": "public void onPeriodicEmit() {\n    updateCombinedWatermark();\n}", "summary_tokens": ["tells", "the", "watermark", "output", "multiplexer", "to", "combine", "all", "outstanding", "deferred", "watermark", "updates", "and", "possibly", "emit", "a", "new", "update", "to", "the", "underlying", "watermark", "output"], "project": "flink"}
{"id": 7664, "code": "public void testDeleteProcessingTimeTimers() throws Exception {\n    @SuppressWarnings(\"unchecked\")\n    Triggerable<Integer, String> mockTriggerable = mock(Triggerable.class);\n\n    TestKeyContext keyContext = new TestKeyContext();\n    TestProcessingTimeService processingTimeService = new TestProcessingTimeService();\n    InternalTimerServiceImpl<Integer, String> timerService =\n            createAndStartInternalTimerService(\n                    mockTriggerable,\n                    keyContext,\n                    processingTimeService,\n                    testKeyGroupRange,\n                    createQueueFactory());\n\n        \n    int key1 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    int key2 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    while (key2 == key1) {\n        key2 = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    }\n\n    keyContext.setCurrentKey(key1);\n\n    timerService.registerProcessingTimeTimer(\"ciao\", 10);\n    timerService.registerProcessingTimeTimer(\"hello\", 10);\n\n    keyContext.setCurrentKey(key2);\n\n    timerService.registerProcessingTimeTimer(\"ciao\", 10);\n    timerService.registerProcessingTimeTimer(\"hello\", 10);\n\n    assertEquals(4, timerService.numProcessingTimeTimers());\n    assertEquals(2, timerService.numProcessingTimeTimers(\"hello\"));\n    assertEquals(2, timerService.numProcessingTimeTimers(\"ciao\"));\n\n    keyContext.setCurrentKey(key1);\n    timerService.deleteProcessingTimeTimer(\"hello\", 10);\n\n    keyContext.setCurrentKey(key2);\n    timerService.deleteProcessingTimeTimer(\"ciao\", 10);\n\n    assertEquals(2, timerService.numProcessingTimeTimers());\n    assertEquals(1, timerService.numProcessingTimeTimers(\"hello\"));\n    assertEquals(1, timerService.numProcessingTimeTimers(\"ciao\"));\n\n    processingTimeService.setCurrentTime(10);\n\n    verify(mockTriggerable, times(2)).onProcessingTime(anyInternalTimer());\n    verify(mockTriggerable, times(1))\n            .onProcessingTime(eq(new TimerHeapInternalTimer<>(10, key1, \"ciao\")));\n    verify(mockTriggerable, times(0))\n            .onProcessingTime(eq(new TimerHeapInternalTimer<>(10, key1, \"hello\")));\n    verify(mockTriggerable, times(0))\n            .onProcessingTime(eq(new TimerHeapInternalTimer<>(10, key2, \"ciao\")));\n    verify(mockTriggerable, times(1))\n            .onProcessingTime(eq(new TimerHeapInternalTimer<>(10, key2, \"hello\")));\n\n    assertEquals(0, timerService.numEventTimeTimers());\n}", "summary_tokens": ["this", "also", "verifies", "that", "we", "don", "t", "have", "leakage", "between", "keys", "namespaces"], "project": "flink"}
{"id": 4171, "code": "void handleTaskLevelCheckpointException(\n        PendingCheckpoint pendingCheckpoint,\n        CheckpointException exception,\n        ExecutionAttemptID executionAttemptID) {\n    CheckpointProperties checkpointProps = pendingCheckpoint.getProps();\n    if (checkpointProps.isSavepoint() && checkpointProps.isSynchronous()) {\n        failureCallback.failJob(exception);\n    } else {\n        checkFailureAgainstCounter(\n                exception,\n                pendingCheckpoint.getCheckpointID(),\n                e -> failureCallback.failJobDueToTaskFailure(e, executionAttemptID));\n    }\n}", "summary_tokens": ["handle", "task", "level", "checkpoint", "exception", "with", "a", "handler", "callback"], "project": "flink"}
{"id": 4204, "code": "public CheckpointStatsHistory getHistory() {\n    return history;\n}", "summary_tokens": ["returns", "the", "snapshotted", "checkpoint", "history"], "project": "flink"}
{"id": 3268, "code": "public RandomGenerable<T> getRandomGenerable() {\n    return randomGenerable;\n}", "summary_tokens": ["the", "source", "of", "randomness"], "project": "flink"}
{"id": 3157, "code": "public static <K, VV, EV> Graph<K, VV, EV> fromCollection(\n        Collection<Edge<K, EV>> edges,\n        final MapFunction<K, VV> vertexValueInitializer,\n        ExecutionEnvironment context) {\n\n    return fromDataSet(context.fromCollection(edges), vertexValueInitializer, context);\n}", "summary_tokens": ["creates", "a", "graph", "from", "a", "collection", "of", "edges"], "project": "flink"}
{"id": 4149, "code": "public void releaseJob(JobID jobId) {\n    checkNotNull(jobId);\n\n    synchronized (jobRefCounters) {\n        RefCount ref = jobRefCounters.get(jobId);\n\n        if (ref == null || ref.references == 0) {\n            log.warn(\n                    \"improper use of releaseJob() without a matching number of registerJob() calls for jobId \"\n                            + jobId);\n            return;\n        }\n\n        --ref.references;\n        if (ref.references == 0) {\n            ref.keepUntil = System.currentTimeMillis() + cleanupInterval;\n        }\n    }\n}", "summary_tokens": ["unregisters", "use", "of", "job", "related", "blobs", "and", "allow", "them", "to", "be", "released"], "project": "flink"}
{"id": 5412, "code": "public boolean cleanup() throws IOException {\n    if (state.compareAndSet(State.ONGOING, State.DELETED)) {\n        FileUtils.deleteDirectory(directory.toFile());\n    }\n    return true;\n}", "summary_tokens": ["calling", "this", "method", "will", "attempt", "delete", "the", "underlying", "snapshot", "directory", "recursively", "if", "the", "state", "is", "ongoing"], "project": "flink"}
{"id": 4636, "code": "private void increaseBuffersInBacklog(BufferConsumer buffer) {\n    assert Thread.holdsLock(buffers);\n\n    if (buffer != null && buffer.isBuffer()) {\n        buffersInBacklog++;\n    }\n}", "summary_tokens": ["increases", "the", "number", "of", "non", "event", "buffers", "by", "one", "after", "adding", "a", "non", "event", "buffer", "into", "this", "subpartition"], "project": "flink"}
{"id": 2971, "code": "static Configuration loadConfiguration(Configuration dynamicParameters) {\n    final String configDir = System.getenv(ConfigConstants.ENV_FLINK_CONF_DIR);\n    Preconditions.checkNotNull(\n            configDir,\n            \"Flink configuration directory (%s) in environment should not be null!\",\n            ConfigConstants.ENV_FLINK_CONF_DIR);\n\n    final Configuration configuration =\n            GlobalConfiguration.loadConfiguration(configDir, dynamicParameters);\n\n    if (HighAvailabilityMode.isHighAvailabilityModeActivated(configuration)) {\n        final String ipAddress = System.getenv().get(Constants.ENV_FLINK_POD_IP_ADDRESS);\n        Preconditions.checkState(\n                ipAddress != null,\n                \"JobManager ip address environment variable %s not set\",\n                Constants.ENV_FLINK_POD_IP_ADDRESS);\n        configuration.setString(JobManagerOptions.ADDRESS, ipAddress);\n        configuration.setString(RestOptions.ADDRESS, ipAddress);\n    }\n\n    return configuration;\n}", "summary_tokens": ["for", "non", "ha", "cluster", "job", "manager", "options", "address", "has", "be", "set", "to", "kubernetes", "service", "name", "on", "client", "side"], "project": "flink"}
{"id": 9040, "code": "public static LocalDateTime toLocalDateTime(TimestampString timestampString) {\n    final String v = timestampString.toString();\n    final int year = Integer.parseInt(v.substring(0, 4));\n    final int month = Integer.parseInt(v.substring(5, 7));\n    final int day = Integer.parseInt(v.substring(8, 10));\n    final int h = Integer.parseInt(v.substring(11, 13));\n    final int m = Integer.parseInt(v.substring(14, 16));\n    final int s = Integer.parseInt(v.substring(17, 19));\n    final int nano = getNanosInSecond(v);\n    return LocalDateTime.of(year, month, day, h, m, s, nano);\n}", "summary_tokens": ["convert", "a", "calcite", "s", "timestamp", "string", "to", "a", "local", "date", "time"], "project": "flink"}
{"id": 9384, "code": "public static boolean bitGet(MemorySegment[] segments, int baseOffset, int index) {\n    int offset = baseOffset + byteIndex(index);\n    byte current = getByte(segments, offset);\n    return (current & (1 << (index & BIT_BYTE_INDEX_MASK))) != 0;\n}", "summary_tokens": ["read", "bit", "from", "segments"], "project": "flink"}
{"id": 8222, "code": "public static ComputedColumn computed(String name, ResolvedExpression expression) {\n    Preconditions.checkNotNull(name, \"Column name can not be null.\");\n    Preconditions.checkNotNull(expression, \"Column expression can not be null.\");\n    return new ComputedColumn(name, expression.getOutputDataType(), expression);\n}", "summary_tokens": ["creates", "a", "computed", "column", "that", "is", "computed", "from", "the", "given", "resolved", "expression"], "project": "flink"}
{"id": 4586, "code": "private long getNumberOfAllocatedChunks(Object arena, String chunkListFieldName)\n        throws NoSuchFieldException, IllegalAccessException {\n\n        \n        \n        \n        \n\n        \n    Field chunkListField =\n            arena.getClass().getSuperclass().getDeclaredField(chunkListFieldName);\n    chunkListField.setAccessible(true);\n    Object chunkList = chunkListField.get(arena);\n\n        \n    Field headChunkField = chunkList.getClass().getDeclaredField(\"head\");\n    headChunkField.setAccessible(true);\n    Object headChunk = headChunkField.get(chunkList);\n\n    if (headChunk == null) {\n        return 0;\n    } else {\n        int numChunks = 0;\n\n        Object current = headChunk;\n\n        while (current != null) {\n            Field nextChunkField = headChunk.getClass().getDeclaredField(\"next\");\n            nextChunkField.setAccessible(true);\n            current = nextChunkField.get(current);\n            numChunks++;\n        }\n\n        return numChunks;\n    }\n}", "summary_tokens": ["returns", "the", "number", "of", "allocated", "bytes", "of", "the", "given", "arena", "and", "chunk", "list"], "project": "flink"}
{"id": 1273, "code": "public <X> void setBroadcastVariables(Map<String, Operator<X>> inputs) {\n    throw new UnsupportedOperationException(\n            \"The BulkIteration meta operator cannot have broadcast inputs.\");\n}", "summary_tokens": ["the", "bulk", "iteration", "meta", "operator", "cannot", "have", "broadcast", "inputs"], "project": "flink"}
{"id": 1039, "code": "public long getAutoWatermarkInterval() {\n    return this.autoWatermarkInterval;\n}", "summary_tokens": ["returns", "the", "interval", "of", "the", "automatic", "watermark", "emission"], "project": "flink"}
{"id": 2072, "code": "public static void replaceNonWordChars(StringValue string, char replacement) {\n    final char[] chars = string.getCharArray();\n    final int len = string.length();\n\n    for (int i = 0; i < len; i++) {\n        final char c = chars[i];\n        if (!(Character.isLetter(c) || Character.isDigit(c) || c == '_')) {\n            chars[i] = replacement;\n        }\n    }\n}", "summary_tokens": ["replaces", "all", "non", "word", "characters", "in", "a", "string", "by", "a", "given", "character"], "project": "flink"}
{"id": 5054, "code": "public void reset() {\n        \n    this.numRecords = 0;\n    this.currentSortIndexOffset = 0;\n    this.currentDataBufferOffset = 0;\n    this.sortIndexBytes = 0;\n\n        \n    this.freeMemory.addAll(this.sortIndex);\n    this.freeMemory.addAll(this.recordBufferSegments);\n    this.sortIndex.clear();\n    this.recordBufferSegments.clear();\n\n        \n    this.currentSortIndexSegment = nextMemorySegment();\n    this.sortIndex.add(this.currentSortIndexSegment);\n    this.recordCollector.reset();\n}", "summary_tokens": ["resets", "the", "sort", "buffer", "back", "to", "the", "state", "where", "it", "is", "empty"], "project": "flink"}
{"id": 9163, "code": "private static int findSmallerPrime(int num) {\n    for (; num > 1; num--) {\n        if (isPrimeNumber(num)) {\n            return num;\n        }\n    }\n    return num;\n}", "summary_tokens": ["let", "prime", "number", "be", "the", "num", "buckets", "to", "avoid", "partition", "hash", "and", "bucket", "hash", "congruences"], "project": "flink"}
{"id": 8384, "code": "public Rowtime timestampsFromSource() {\n    internalProperties.putString(\n            ROWTIME_TIMESTAMPS_TYPE, ROWTIME_TIMESTAMPS_TYPE_VALUE_FROM_SOURCE);\n    return this;\n}", "summary_tokens": ["sets", "a", "built", "in", "timestamp", "extractor", "that", "converts", "the", "assigned", "timestamps", "from", "a", "data", "stream", "api", "record", "into", "the", "rowtime", "attribute", "and", "thus", "preserves", "the", "assigned", "timestamps", "from", "the", "source"], "project": "flink"}
{"id": 1896, "code": "public void substring(StringValue target, int start, int end) {\n    target.setValue(this, start, end - start);\n}", "summary_tokens": ["copies", "a", "substring", "of", "this", "string", "into", "the", "given", "target", "string", "value"], "project": "flink"}
{"id": 2164, "code": "private static <T> void assertSerializerIsValid(\n        TypeSerializer<T> serializer, DataInputView dataInput, Matcher<T> testDataMatcher)\n        throws Exception {\n\n    DataInputView serializedData =\n            readAndThenWriteData(dataInput, serializer, serializer, testDataMatcher);\n    TypeSerializerSnapshot<T> snapshot = writeAndThenReadSerializerSnapshot(serializer);\n    TypeSerializer<T> restoreSerializer = snapshot.restoreSerializer();\n    readAndThenWriteData(serializedData, restoreSerializer, restoreSerializer, testDataMatcher);\n}", "summary_tokens": ["asserts", "that", "a", "given", "type", "serializer", "is", "valid", "given", "a", "data", "input", "view", "of", "serialized", "data"], "project": "flink"}
{"id": 1147, "code": "private void updateCombinedWatermark() {\n    if (combinedWatermarkStatus.updateCombinedWatermark()) {\n        underlyingOutput.emitWatermark(\n                new Watermark(combinedWatermarkStatus.getCombinedWatermark()));\n    } else if (combinedWatermarkStatus.isIdle()) {\n        underlyingOutput.markIdle();\n    }\n}", "summary_tokens": ["checks", "whether", "we", "need", "to", "update", "the", "combined", "watermark"], "project": "flink"}
{"id": 5448, "code": "public Path getDefaultSavepointDirectory() {\n    return defaultSavepointDirectory;\n}", "summary_tokens": ["gets", "the", "default", "directory", "for", "savepoints"], "project": "flink"}
{"id": 2387, "code": "public Set<String> getFinalParameters() {\n    Set<String> setFinalParams =\n            Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>());\n    setFinalParams.addAll(finalParameters);\n    return setFinalParams;\n}", "summary_tokens": ["get", "the", "set", "of", "parameters", "marked", "final"], "project": "flink"}
{"id": 1507, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f5)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f6)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f7)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f8)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f9)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f10)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f11)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f12)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f13)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f14)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f15)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f16)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f17)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f18)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f19)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 9648, "code": "public void testStateBackendWithoutCheckpointing() throws Exception {\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(1);\n\n    see.getConfig().setRestartStrategy(RestartStrategies.noRestart());\n    see.setStateBackend(new FailingStateBackend());\n\n    see.fromElements(new Tuple2<>(\"Hello\", 1))\n            .keyBy(0)\n            .map(\n                    new RichMapFunction<Tuple2<String, Integer>, String>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public void open(Configuration parameters) throws Exception {\n                            super.open(parameters);\n                            getRuntimeContext()\n                                    .getState(\n                                            new ValueStateDescriptor<>(\"Test\", Integer.class));\n                        }\n\n                        @Override\n                        public String map(Tuple2<String, Integer> value) throws Exception {\n                            return value.f0;\n                        }\n                    })\n            .print();\n\n    try {\n        see.execute();\n        fail();\n    } catch (JobExecutionException e) {\n        assertTrue(ExceptionUtils.findThrowable(e, SuccessException.class).isPresent());\n    }\n}", "summary_tokens": ["verify", "that", "the", "user", "specified", "state", "backend", "is", "used", "even", "if", "checkpointing", "is", "disabled"], "project": "flink"}
{"id": 1728, "code": "private String checkPathArg(String path) {\n        \n    if (path == null) {\n        throw new IllegalArgumentException(\"Can not create a Path from a null string\");\n    }\n    if (path.length() == 0) {\n        throw new IllegalArgumentException(\"Can not create a Path from an empty string\");\n    }\n    return path;\n}", "summary_tokens": ["checks", "if", "the", "provided", "path", "string", "is", "either", "null", "or", "has", "zero", "length", "and", "throws", "a", "illegal", "argument", "exception", "if", "any", "of", "the", "two", "conditions", "apply"], "project": "flink"}
{"id": 689, "code": "public void runStartFromSpecificOffsets() throws Exception {\n        \n    final int parallelism = 4;\n    final int recordsInEachPartition = 50;\n\n    final String topicName =\n            writeSequence(\n                    \"testStartFromSpecificOffsetsTopic\",\n                    recordsInEachPartition,\n                    parallelism,\n                    1);\n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(parallelism);\n\n    Properties readProps = new Properties();\n    readProps.putAll(standardProps);\n    readProps.setProperty(\n            \"auto.offset.reset\",\n            \"earliest\"); \n\n    Map<KafkaTopicPartition, Long> specificStartupOffsets = new HashMap<>();\n    specificStartupOffsets.put(new KafkaTopicPartition(topicName, 0), 19L);\n    specificStartupOffsets.put(new KafkaTopicPartition(topicName, 2), 22L);\n    specificStartupOffsets.put(\n            new KafkaTopicPartition(topicName, 4),\n            26L); \n\n        \n        \n    KafkaTestEnvironment.KafkaOffsetHandler kafkaOffsetHandler =\n            kafkaServer.createOffsetHandler();\n    kafkaOffsetHandler.setCommittedOffset(topicName, 0, 23);\n    kafkaOffsetHandler.setCommittedOffset(topicName, 1, 31);\n    kafkaOffsetHandler.setCommittedOffset(topicName, 2, 43);\n\n    Map<Integer, Tuple2<Integer, Integer>> partitionsToValueCountAndStartOffsets =\n            new HashMap<>();\n    partitionsToValueCountAndStartOffsets.put(\n            0, new Tuple2<>(31, 19)); \n    partitionsToValueCountAndStartOffsets.put(\n            1, new Tuple2<>(19, 31)); \n    partitionsToValueCountAndStartOffsets.put(\n            2, new Tuple2<>(28, 22)); \n    partitionsToValueCountAndStartOffsets.put(\n            3, new Tuple2<>(50, 0)); \n\n    readSequence(\n            env,\n            StartupMode.SPECIFIC_OFFSETS,\n            specificStartupOffsets,\n            null,\n            readProps,\n            topicName,\n            partitionsToValueCountAndStartOffsets);\n\n    kafkaOffsetHandler.close();\n    deleteTestTopic(topicName);\n}", "summary_tokens": ["this", "test", "ensures", "that", "the", "consumer", "correctly", "uses", "user", "supplied", "specific", "offsets", "when", "explicitly", "configured", "to", "start", "from", "specific", "offsets"], "project": "flink"}
{"id": 2005, "code": "public static int jenkinsHash(int code) {\n    code = (code + 0x7ed55d16) + (code << 12);\n    code = (code ^ 0xc761c23c) ^ (code >>> 19);\n    code = (code + 0x165667b1) + (code << 5);\n    code = (code + 0xd3a2646c) ^ (code << 9);\n    code = (code + 0xfd7046c5) + (code << 3);\n    code = (code ^ 0xb55a4f09) ^ (code >>> 16);\n    return code >= 0 ? code : -(code + 1);\n}", "summary_tokens": ["this", "function", "hashes", "an", "integer", "value"], "project": "flink"}
{"id": 6715, "code": "public void testReplace() throws Exception {\n        \n    final TestingLongStateHandleHelper stateHandleProvider = new TestingLongStateHandleHelper();\n\n    ZooKeeperStateHandleStore<TestingLongStateHandleHelper.LongStateHandle> store =\n            new ZooKeeperStateHandleStore<>(ZOOKEEPER.getClient(), stateHandleProvider);\n\n        \n    final String pathInZooKeeper = \"/testReplace\";\n    final long initialState = 30968470898L;\n    final long replaceState = 88383776661L;\n\n        \n    store.addAndLock(\n            pathInZooKeeper, new TestingLongStateHandleHelper.LongStateHandle(initialState));\n    store.replace(\n            pathInZooKeeper,\n            IntegerResourceVersion.valueOf(0),\n            new TestingLongStateHandleHelper.LongStateHandle(replaceState));\n\n        \n        \n    assertEquals(2, TestingLongStateHandleHelper.getGlobalStorageSize());\n    assertEquals(initialState, TestingLongStateHandleHelper.getStateHandleValueByIndex(0));\n    assertEquals(replaceState, TestingLongStateHandleHelper.getStateHandleValueByIndex(1));\n\n        \n    Stat stat = ZOOKEEPER.getClient().checkExists().forPath(pathInZooKeeper);\n    assertNotNull(stat);\n    assertEquals(0, stat.getEphemeralOwner());\n\n        \n    @SuppressWarnings(\"unchecked\")\n    final long actual =\n            ((RetrievableStateHandle<TestingLongStateHandleHelper.LongStateHandle>)\n                            InstantiationUtil.deserializeObject(\n                                    ZOOKEEPER.getClient().getData().forPath(pathInZooKeeper),\n                                    ClassLoader.getSystemClassLoader()))\n                    .retrieveState()\n                    .getValue();\n\n    assertEquals(replaceState, actual);\n}", "summary_tokens": ["tests", "that", "a", "state", "handle", "is", "replaced"], "project": "flink"}
{"id": 911, "code": "public void appendTopicPartitions(Set<TopicPartition> fetchedPartitions) {\n    for (TopicPartition partition : fetchedPartitions) {\n            \n        if (!appendedPartitions.contains(partition)) {\n            if (!sharePartition()) {\n                    \n                pendingPartitionSplits.add(createSplit(partition));\n            }\n\n                \n            appendedPartitions.add(partition);\n        }\n    }\n\n        \n    if (!initialized) {\n        this.initialized = true;\n    }\n}", "summary_tokens": ["append", "the", "new", "fetched", "partitions", "to", "current", "state"], "project": "flink"}
{"id": 5108, "code": "public void registerKvState(\n        KeyGroupRange keyGroupRange, KvStateID kvStateId, InetSocketAddress kvStateAddress) {\n\n    if (keyGroupRange.getStartKeyGroup() < 0\n            || keyGroupRange.getEndKeyGroup() >= numKeyGroups) {\n        throw new IndexOutOfBoundsException(\"Key group index\");\n    }\n\n    for (int kgIdx = keyGroupRange.getStartKeyGroup();\n            kgIdx <= keyGroupRange.getEndKeyGroup();\n            ++kgIdx) {\n\n        if (kvStateIds[kgIdx] == null && kvStateAddresses[kgIdx] == null) {\n            numRegisteredKeyGroups++;\n        }\n\n        kvStateIds[kgIdx] = kvStateId;\n        kvStateAddresses[kgIdx] = kvStateAddress;\n    }\n}", "summary_tokens": ["registers", "a", "kv", "state", "instance", "for", "the", "given", "key", "group", "index"], "project": "flink"}
{"id": 5584, "code": "public Throwable getFailureCause() {\n    return failureCause;\n}", "summary_tokens": ["if", "the", "task", "has", "failed", "this", "method", "gets", "the", "exception", "that", "caused", "this", "task", "to", "fail"], "project": "flink"}
{"id": 7151, "code": "public <T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>\n        SingleOutputStreamOperator<Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>>\n                projectTuple12() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>> tType =\n            new TupleTypeInfo<Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>>(\n                    fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<IN, Tuple12<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 6151, "code": "public void testBlockingRequestFromMultiLocalBufferPool()\n        throws IOException, InterruptedException {\n    final int localPoolRequiredSize = 5;\n    final int localPoolMaxSize = 10;\n    final int numLocalBufferPool = 2;\n    final int numberOfSegmentsToRequest = 10;\n    final int numBuffers = numLocalBufferPool * localPoolMaxSize;\n\n    final ExecutorService executorService = Executors.newFixedThreadPool(numLocalBufferPool);\n    final NetworkBufferPool globalPool = new NetworkBufferPool(numBuffers, 128);\n    final List<BufferPool> localBufferPools = new ArrayList<>(numLocalBufferPool);\n\n    try {\n            \n        for (int i = 0; i < numLocalBufferPool; ++i) {\n            final BufferPool localPool =\n                    globalPool.createBufferPool(localPoolRequiredSize, localPoolMaxSize);\n            localBufferPools.add(localPool);\n            assertTrue(localPool.getAvailableFuture().isDone());\n        }\n\n            \n        final List<MemorySegment> segments = new ArrayList<>(numberOfSegmentsToRequest - 1);\n        for (int i = 0; i < numberOfSegmentsToRequest - 1; ++i) {\n            segments.add(globalPool.requestMemorySegment());\n        }\n        final List<MemorySegment> exclusiveSegments =\n                globalPool.requestMemorySegments(\n                        globalPool.getNumberOfAvailableMemorySegments() - 1);\n        assertTrue(globalPool.getAvailableFuture().isDone());\n        for (final BufferPool localPool : localBufferPools) {\n            assertTrue(localPool.getAvailableFuture().isDone());\n        }\n\n            \n        final CountDownLatch latch = new CountDownLatch(numLocalBufferPool);\n        final BlockingQueue<BufferBuilder> segmentsRequested =\n                new ArrayBlockingQueue<>(numBuffers);\n        final AtomicReference<Throwable> cause = new AtomicReference<>();\n        for (final BufferPool localPool : localBufferPools) {\n            executorService.submit(\n                    () -> {\n                        try {\n                            for (int num = localPoolMaxSize; num > 0; --num) {\n                                segmentsRequested.add(localPool.requestBufferBuilderBlocking());\n                            }\n                        } catch (Exception e) {\n                            cause.set(e);\n                        } finally {\n                            latch.countDown();\n                        }\n                    });\n        }\n\n            \n        while (segmentsRequested.size() + segments.size() + exclusiveSegments.size()\n                < numBuffers) {\n            Thread.sleep(100);\n            assertNull(cause.get());\n        }\n\n        final CompletableFuture<?> globalPoolAvailableFuture = globalPool.getAvailableFuture();\n        assertFalse(globalPoolAvailableFuture.isDone());\n\n        final List<CompletableFuture<?>> localPoolAvailableFutures =\n                new ArrayList<>(numLocalBufferPool);\n        for (BufferPool localPool : localBufferPools) {\n            CompletableFuture<?> localPoolAvailableFuture = localPool.getAvailableFuture();\n            localPoolAvailableFutures.add(localPoolAvailableFuture);\n            assertFalse(localPoolAvailableFuture.isDone());\n        }\n\n            \n        for (MemorySegment segment : segments) {\n            globalPool.recycle(segment);\n        }\n        globalPool.recycleMemorySegments(exclusiveSegments);\n\n        assertTrue(globalPoolAvailableFuture.isDone());\n        for (CompletableFuture<?> localPoolAvailableFuture : localPoolAvailableFutures) {\n            assertTrue(localPoolAvailableFuture.isDone());\n        }\n\n            \n        latch.await();\n\n        assertNull(cause.get());\n        assertEquals(0, globalPool.getNumberOfAvailableMemorySegments());\n        assertFalse(globalPool.getAvailableFuture().isDone());\n        for (BufferPool localPool : localBufferPools) {\n            assertFalse(localPool.getAvailableFuture().isDone());\n            assertEquals(localPoolMaxSize, localPool.bestEffortGetNumOfUsedBuffers());\n        }\n\n            \n        for (BufferBuilder bufferBuilder : segmentsRequested) {\n            bufferBuilder.close();\n        }\n\n    } finally {\n        for (BufferPool bufferPool : localBufferPools) {\n            bufferPool.lazyDestroy();\n        }\n        executorService.shutdown();\n        globalPool.destroy();\n    }\n}", "summary_tokens": ["tests", "that", "blocking", "request", "of", "multi", "local", "buffer", "pools", "can", "be", "fulfilled", "by", "recycled", "segments", "to", "the", "global", "network", "buffer", "pool"], "project": "flink"}
{"id": 2725, "code": "public T reduce(T value1, T value2) throws Exception {\n\n    for (int position : fields) {\n            \n            \n        Comparable comparable1 = value1.getFieldNotNull(position);\n        Comparable comparable2 = value2.getFieldNotNull(position);\n\n            \n        int comp = comparable1.compareTo(comparable2);\n            \n            \n        if (comp < 0) {\n            return value1;\n        } else if (comp > 0) {\n            return value2;\n        }\n    }\n    return value1;\n}", "summary_tokens": ["reduce", "implementation", "returns", "smaller", "tuple", "or", "value", "0", "if", "both", "tuples", "are", "equal"], "project": "flink"}
{"id": 1393, "code": "public static <T> TypeSerializerSchemaCompatibility<T> compatibleAsIs() {\n    return new TypeSerializerSchemaCompatibility<>(Type.COMPATIBLE_AS_IS, null);\n}", "summary_tokens": ["returns", "a", "result", "that", "indicates", "that", "the", "new", "serializer", "is", "compatible", "and", "no", "migration", "is", "required"], "project": "flink"}
{"id": 7254, "code": "public DataStreamSource<Long> fromSequence(long from, long to) {\n    if (from > to) {\n        throw new IllegalArgumentException(\n                \"Start of sequence must not be greater than the end\");\n    }\n    return fromSource(\n            new NumberSequenceSource(from, to),\n            WatermarkStrategy.noWatermarks(),\n            \"Sequence Source\");\n}", "summary_tokens": ["creates", "a", "new", "data", "stream", "that", "contains", "a", "sequence", "of", "numbers", "longs", "and", "is", "useful", "for", "testing", "and", "for", "cases", "that", "just", "need", "a", "stream", "of", "n", "events", "of", "any", "kind"], "project": "flink"}
{"id": 2060, "code": "public static String arrayAwareToString(Object o) {\n    final String arrayString = Arrays.deepToString(new Object[] {o});\n    return arrayString.substring(1, arrayString.length() - 1);\n}", "summary_tokens": ["converts", "the", "given", "object", "into", "a", "string", "representation", "by", "calling", "object", "to", "string", "and", "formatting", "possibly", "nested", "arrays", "and", "null"], "project": "flink"}
{"id": 2858, "code": "public String getRequired(String key) {\n    addToDefaults(key, null);\n    String value = get(key);\n    if (value == null) {\n        throw new RuntimeException(\"No data for required key '\" + key + \"'\");\n    }\n    return value;\n}", "summary_tokens": ["returns", "the", "string", "value", "for", "the", "given", "key"], "project": "flink"}
{"id": 7573, "code": "public final String getName() {\n    return getEnvironment().getTaskInfo().getTaskNameWithSubtasks();\n}", "summary_tokens": ["gets", "the", "name", "of", "the", "task", "in", "the", "form", "taskname", "0", "0"], "project": "flink"}
{"id": 8559, "code": "static Set<FunctionSignatureTemplate> findInputOnlyTemplates(\n        Set<FunctionTemplate> global,\n        Set<FunctionTemplate> local,\n        Function<FunctionTemplate, FunctionResultTemplate> accessor) {\n    return Stream.concat(global.stream(), local.stream())\n            .filter(t -> t.getSignatureTemplate() != null && accessor.apply(t) == null)\n            .map(FunctionTemplate::getSignatureTemplate)\n            .collect(Collectors.toCollection(LinkedHashSet::new));\n}", "summary_tokens": ["hints", "that", "only", "declare", "an", "input"], "project": "flink"}
{"id": 4758, "code": "public Set<CoLocationGroup> getCoLocationGroups() {\n    final Set<CoLocationGroup> coLocationGroups =\n            IterableUtils.toStream(getVertices())\n                    .map(JobVertex::getCoLocationGroup)\n                    .filter(Objects::nonNull)\n                    .collect(Collectors.toSet());\n    return Collections.unmodifiableSet(coLocationGroups);\n}", "summary_tokens": ["returns", "all", "co", "location", "group", "instances", "associated", "with", "this", "job", "graph"], "project": "flink"}
{"id": 5359, "code": "public boolean isDefaultReference() {\n    return encodedReference == null;\n}", "summary_tokens": ["returns", "true", "if", "this", "object", "is", "the", "default", "reference"], "project": "flink"}
{"id": 6580, "code": "public void testKryoRegisteringRestoreResilienceWithDefaultSerializer() throws Exception {\n    assumeTrue(supportsMetaInfoVerification());\n    CheckpointStreamFactory streamFactory = createStreamFactory();\n    SharedStateRegistry sharedStateRegistry = new SharedStateRegistryImpl();\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE, env);\n    try {\n        TypeInformation<TestPojo> pojoType = new GenericTypeInfo<>(TestPojo.class);\n\n            \n        assertTrue(\n                pojoType.createSerializer(env.getExecutionConfig()) instanceof KryoSerializer);\n\n        ValueStateDescriptor<TestPojo> kvId = new ValueStateDescriptor<>(\"id\", pojoType);\n\n        ValueState<TestPojo> state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n            \n            \n\n            \n        backend.setCurrentKey(1);\n        state.update(new TestPojo(\"u1\", 1));\n\n        backend.setCurrentKey(2);\n        state.update(new TestPojo(\"u2\", 2));\n\n        KeyedStateHandle snapshot =\n                runSnapshot(\n                        backend.snapshot(\n                                682375462378L,\n                                2,\n                                streamFactory,\n                                CheckpointOptions.forCheckpointWithDefaultLocation()),\n                        sharedStateRegistry);\n\n        backend.dispose();\n\n            \n            \n\n            \n        env.getExecutionConfig()\n                .addDefaultKryoSerializer(\n                        TestPojo.class, (Class) CustomKryoTestSerializer.class);\n\n        backend = restoreKeyedBackend(IntSerializer.INSTANCE, snapshot, env);\n\n            \n            \n        kvId = new ValueStateDescriptor<>(\"id\", pojoType);\n        state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n        backend.setCurrentKey(1);\n\n            \n        state.update(new TestPojo(\"u1\", 11));\n\n        KeyedStateHandle snapshot2 =\n                runSnapshot(\n                        backend.snapshot(\n                                682375462378L,\n                                2,\n                                streamFactory,\n                                CheckpointOptions.forCheckpointWithDefaultLocation()),\n                        sharedStateRegistry);\n\n        snapshot.discardState();\n\n        backend.dispose();\n\n            \n            \n\n            \n        env.getExecutionConfig()\n                .addDefaultKryoSerializer(\n                        TestPojo.class, (Class) CustomKryoTestSerializer.class);\n\n            \n            \n        expectedException.expect(\n                anyOf(\n                        isA(ExpectedKryoTestException.class),\n                        Matchers.<Throwable>hasProperty(\n                                \"cause\", isA(ExpectedKryoTestException.class))));\n\n            \n            \n        backend = restoreKeyedBackend(IntSerializer.INSTANCE, snapshot2, env);\n\n        state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n        backend.setCurrentKey(1);\n            \n        state.value();\n\n        snapshot2.discardState();\n    } finally {\n            \n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["verify", "state", "restore", "resilience", "when", "snapshot", "was", "taken", "without", "any", "kryo", "registrations", "specific", "serializers", "or", "default", "serializers", "for", "the", "state", "type", "restored", "with", "a", "default", "serializer", "for", "the", "state", "type"], "project": "flink"}
{"id": 8608, "code": "public static BinaryType ofEmptyLiteral() {\n    return new BinaryType(EMPTY_LITERAL_LENGTH, false);\n}", "summary_tokens": ["the", "sql", "standard", "defines", "that", "character", "string", "literals", "are", "allowed", "to", "be", "zero", "length", "strings", "i"], "project": "flink"}
{"id": 2305, "code": "void publish(int amountOfMessages) {\n    Publisher publisher = null;\n    try {\n        publisher = Publisher.newBuilder(TopicName.of(projectName, topicName)).build();\n        for (int i = 0; i < amountOfMessages; i++) {\n            ByteString messageData = ByteString.copyFrom(BigInteger.valueOf(i).toByteArray());\n            PubsubMessage message = PubsubMessage.newBuilder().setData(messageData).build();\n            publisher.publish(message).get();\n\n            System.out.println(\"Published message: \" + i);\n            Thread.sleep(100L);\n        }\n    } catch (Exception e) {\n        throw new RuntimeException(e);\n    } finally {\n        try {\n            if (publisher != null) {\n                publisher.shutdown();\n            }\n        } catch (Exception e) {\n        }\n    }\n}", "summary_tokens": ["publish", "messages", "with", "as", "payload", "a", "single", "integer"], "project": "flink"}
{"id": 8274, "code": "static ElementGetter createElementGetter(LogicalType elementType) {\n    final ElementGetter elementGetter;\n        \n    switch (elementType.getTypeRoot()) {\n        case CHAR:\n        case VARCHAR:\n            elementGetter = ArrayData::getString;\n            break;\n        case BOOLEAN:\n            elementGetter = ArrayData::getBoolean;\n            break;\n        case BINARY:\n        case VARBINARY:\n            elementGetter = ArrayData::getBinary;\n            break;\n        case DECIMAL:\n            final int decimalPrecision = getPrecision(elementType);\n            final int decimalScale = getScale(elementType);\n            elementGetter =\n                    (array, pos) -> array.getDecimal(pos, decimalPrecision, decimalScale);\n            break;\n        case TINYINT:\n            elementGetter = ArrayData::getByte;\n            break;\n        case SMALLINT:\n            elementGetter = ArrayData::getShort;\n            break;\n        case INTEGER:\n        case DATE:\n        case TIME_WITHOUT_TIME_ZONE:\n        case INTERVAL_YEAR_MONTH:\n            elementGetter = ArrayData::getInt;\n            break;\n        case BIGINT:\n        case INTERVAL_DAY_TIME:\n            elementGetter = ArrayData::getLong;\n            break;\n        case FLOAT:\n            elementGetter = ArrayData::getFloat;\n            break;\n        case DOUBLE:\n            elementGetter = ArrayData::getDouble;\n            break;\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            final int timestampPrecision = getPrecision(elementType);\n            elementGetter = (array, pos) -> array.getTimestamp(pos, timestampPrecision);\n            break;\n        case TIMESTAMP_WITH_TIME_ZONE:\n            throw new UnsupportedOperationException();\n        case ARRAY:\n            elementGetter = ArrayData::getArray;\n            break;\n        case MULTISET:\n        case MAP:\n            elementGetter = ArrayData::getMap;\n            break;\n        case ROW:\n        case STRUCTURED_TYPE:\n            final int rowFieldCount = getFieldCount(elementType);\n            elementGetter = (array, pos) -> array.getRow(pos, rowFieldCount);\n            break;\n        case DISTINCT_TYPE:\n            elementGetter = createElementGetter(((DistinctType) elementType).getSourceType());\n            break;\n        case RAW:\n            elementGetter = ArrayData::getRawValue;\n            break;\n        case NULL:\n        case SYMBOL:\n        case UNRESOLVED:\n        default:\n            throw new IllegalArgumentException();\n    }\n    if (!elementType.isNullable()) {\n        return elementGetter;\n    }\n    return (array, pos) -> {\n        if (array.isNullAt(pos)) {\n            return null;\n        }\n        return elementGetter.getElementOrNull(array, pos);\n    };\n}", "summary_tokens": ["creates", "an", "accessor", "for", "getting", "elements", "in", "an", "internal", "array", "data", "structure", "at", "the", "given", "position"], "project": "flink"}
{"id": 443, "code": "public Row nextRecord(Row reuse) throws IOException {\n    try {\n        if (!hasNext) {\n            return null;\n        }\n        for (int pos = 0; pos < reuse.getArity(); pos++) {\n            reuse.setField(pos, resultSet.getObject(pos + 1));\n        }\n            \n        hasNext = resultSet.next();\n        return reuse;\n    } catch (SQLException se) {\n        throw new IOException(\"Couldn't read data - \" + se.getMessage(), se);\n    } catch (NullPointerException npe) {\n        throw new IOException(\"Couldn't access resultSet\", npe);\n    }\n}", "summary_tokens": ["stores", "the", "next", "result", "set", "row", "in", "a", "tuple"], "project": "flink"}
{"id": 4414, "code": "public void setAccumulators(Map<String, Accumulator<?, ?>> userAccumulators) {\n    synchronized (accumulatorLock) {\n        if (!state.isTerminal()) {\n            this.userAccumulators = userAccumulators;\n        }\n    }\n}", "summary_tokens": ["update", "accumulators", "discarded", "when", "the", "execution", "has", "already", "been", "terminated"], "project": "flink"}
{"id": 7084, "code": "public DataStreamSink<T> sinkTo(Sink<T, ?, ?, ?> sink) {\n        \n    transformation.getOutputType();\n\n    return new DataStreamSink<>(this, sink);\n}", "summary_tokens": ["adds", "the", "given", "sink", "to", "this", "data", "stream"], "project": "flink"}
{"id": 8088, "code": "public FunctionLookup asLookup(Function<String, UnresolvedIdentifier> parser) {\n    return new FunctionLookup() {\n        @Override\n        public Optional<Result> lookupFunction(String stringIdentifier) {\n            UnresolvedIdentifier unresolvedIdentifier = parser.apply(stringIdentifier);\n            return lookupFunction(unresolvedIdentifier);\n        }\n\n        @Override\n        public Optional<FunctionLookup.Result> lookupFunction(UnresolvedIdentifier identifier) {\n            return FunctionCatalog.this.lookupFunction(identifier);\n        }\n\n        @Override\n        public PlannerTypeInferenceUtil getPlannerTypeInferenceUtil() {\n            Preconditions.checkNotNull(\n                    plannerTypeInferenceUtil,\n                    \"A planner should have set the type inference utility.\");\n            return plannerTypeInferenceUtil;\n        }\n    };\n}", "summary_tokens": ["creates", "a", "function", "lookup", "to", "this", "function", "catalog"], "project": "flink"}
{"id": 9058, "code": "public int getNumElements() {\n    return numElements;\n}", "summary_tokens": ["gets", "the", "number", "of", "elements", "produced", "in", "total", "by", "this", "function"], "project": "flink"}
{"id": 6747, "code": "private void doPhysicalRemove(long node, long prevNode, long nextNode) {\n        \n    long valuePointer = deleteNodeMeta(node, prevNode, nextNode);\n        \n    SkipListUtils.removeAllValues(valuePointer, spaceAllocator);\n}", "summary_tokens": ["removes", "the", "node", "physically", "and", "free", "all", "space", "used", "by", "the", "key", "and", "value"], "project": "flink"}
{"id": 6896, "code": "public void setUseManagedMemory(boolean useManagedMemory) {\n    this.useManagedMemory = useManagedMemory;\n}", "summary_tokens": ["configures", "rocks", "db", "to", "use", "the", "managed", "memory", "of", "a", "slot"], "project": "flink"}
{"id": 5190, "code": "public void deregisterRequest() {\n    phaser.arriveAndDeregister();\n}", "summary_tokens": ["deregisters", "an", "in", "flight", "request"], "project": "flink"}
{"id": 3697, "code": "public TypeComparatorFactory<?> getShipStrategyComparator() {\n    return shipStrategyComparator;\n}", "summary_tokens": ["gets", "the", "ship", "strategy", "comparator", "from", "this", "channel"], "project": "flink"}
{"id": 6090, "code": "public void testTargetUnmonitoring() throws Exception {\n        \n    long heartbeatTimeout = 50L;\n    ResourceID resourceID = new ResourceID(\"foobar\");\n    ResourceID targetID = new ResourceID(\"target\");\n    final int payload = 42;\n\n    final CompletableFuture<ResourceID> timeoutFuture = new CompletableFuture<>();\n    final TestingHeartbeatListener<Integer, Integer> heartbeatListener =\n            new TestingHeartbeatListenerBuilder<Integer, Integer>()\n                    .setRetrievePayloadFunction(ignored -> payload)\n                    .setNotifyHeartbeatTimeoutConsumer(timeoutFuture::complete)\n                    .createNewTestingHeartbeatListener();\n\n    HeartbeatManager<Integer, Integer> heartbeatManager =\n            new HeartbeatManagerImpl<>(\n                    heartbeatTimeout,\n                    FAILED_RPC_THRESHOLD,\n                    resourceID,\n                    heartbeatListener,\n                    TestingUtils.defaultScheduledExecutor(),\n                    LOG);\n\n    final HeartbeatTarget<Integer> heartbeatTarget =\n            new TestingHeartbeatTargetBuilder<Integer>().createTestingHeartbeatTarget();\n    heartbeatManager.monitorTarget(targetID, heartbeatTarget);\n\n    heartbeatManager.unmonitorTarget(targetID);\n\n    try {\n        timeoutFuture.get(2 * heartbeatTimeout, TimeUnit.MILLISECONDS);\n        fail(\"Timeout should time out.\");\n    } catch (TimeoutException ignored) {\n            \n    }\n}", "summary_tokens": ["tests", "that", "after", "unmonitoring", "a", "target", "there", "won", "t", "be", "a", "timeout", "triggered"], "project": "flink"}
{"id": 7917, "code": "public static <K, IN1, IN2, OUT>\n        KeyedTwoInputStreamOperatorTestHarness<K, IN1, IN2, OUT> forKeyedCoProcessFunction(\n                final KeyedCoProcessFunction<K, IN1, IN2, OUT> function,\n                final KeySelector<IN1, K> keySelector1,\n                final KeySelector<IN2, K> keySelector2,\n                final TypeInformation<K> keyType)\n                throws Exception {\n\n    KeyedTwoInputStreamOperatorTestHarness<K, IN1, IN2, OUT> testHarness =\n            new KeyedTwoInputStreamOperatorTestHarness<>(\n                    new KeyedCoProcessOperator<>(Preconditions.checkNotNull(function)),\n                    keySelector1,\n                    keySelector2,\n                    keyType,\n                    1,\n                    1,\n                    0);\n\n    testHarness.open();\n    return testHarness;\n}", "summary_tokens": ["returns", "an", "initialized", "test", "harness", "for", "keyed", "co", "process", "function", "with", "two", "input", "streams"], "project": "flink"}
{"id": 6706, "code": "public void testCachedStatsNotCleanedWithinCleanupInterval() throws Exception {\n    final JobVertexThreadInfoTracker<JobVertexThreadInfoStats> tracker =\n            createThreadInfoTracker();\n\n    doInitialRequestAndVerifyResult(tracker);\n\n    tracker.cleanUpVertexStatsCache();\n        \n    assertExpectedEqualsReceived(\n            threadInfoStatsDefaultSample, tracker.getVertexStats(JOB_ID, EXECUTION_JOB_VERTEX));\n}", "summary_tokens": ["tests", "that", "cached", "results", "are", "not", "removed", "within", "the", "cleanup", "interval"], "project": "flink"}
{"id": 6792, "code": "public static long getPrevIndexNode(\n        MemorySegment memorySegment, int offset, int totalLevel, int level) {\n    int of = getIndexOffset(offset, totalLevel, level);\n    return memorySegment.getLong(of);\n}", "summary_tokens": ["returns", "previous", "key", "pointer", "on", "the", "given", "index", "level"], "project": "flink"}
{"id": 8122, "code": "public void loadModule(String name, Module module) {\n    checkArgument(\n            !StringUtils.isNullOrWhitespaceOnly(name), \"name cannot be null or empty string\");\n    checkNotNull(module, \"module cannot be null\");\n\n    if (loadedModules.containsKey(name)) {\n        throw new ValidationException(\n                String.format(\"A module with name '%s' already exists\", name));\n    } else {\n        usedModules.add(name);\n        loadedModules.put(name, module);\n        LOG.info(\"Loaded module '{}' from class {}\", name, module.getClass().getName());\n    }\n}", "summary_tokens": ["load", "a", "module", "under", "a", "unique", "name"], "project": "flink"}
{"id": 1379, "code": "public TypeComparator<T> createComparator(\n        int[] logicalKeyFields,\n        boolean[] orders,\n        int logicalFieldOffset,\n        ExecutionConfig config) {\n\n    TypeComparatorBuilder<T> builder = createTypeComparatorBuilder();\n\n    builder.initializeTypeComparatorBuilder(logicalKeyFields.length);\n\n    for (int logicalKeyFieldIndex = 0;\n            logicalKeyFieldIndex < logicalKeyFields.length;\n            logicalKeyFieldIndex++) {\n        int logicalKeyField = logicalKeyFields[logicalKeyFieldIndex];\n        int logicalField = logicalFieldOffset; \n        boolean comparatorAdded = false;\n\n        for (int localFieldId = 0;\n                localFieldId < this.getArity()\n                        && logicalField <= logicalKeyField\n                        && !comparatorAdded;\n                localFieldId++) {\n            TypeInformation<?> localFieldType = this.getTypeAt(localFieldId);\n\n            if (localFieldType instanceof AtomicType && logicalField == logicalKeyField) {\n                    \n                builder.addComparatorField(\n                        localFieldId,\n                        ((AtomicType<?>) localFieldType)\n                                .createComparator(orders[logicalKeyFieldIndex], config));\n\n                comparatorAdded = true;\n            }\n                \n                \n            else if (localFieldType instanceof CompositeType\n                    && logicalField <= logicalKeyField\n                    && logicalKeyField\n                            <= logicalField + (localFieldType.getTotalFields() - 1)) {\n                    \n                    \n                builder.addComparatorField(\n                        localFieldId,\n                        ((CompositeType<?>) localFieldType)\n                                .createComparator(\n                                        new int[] {logicalKeyField},\n                                        new boolean[] {orders[logicalKeyFieldIndex]},\n                                        logicalField,\n                                        config));\n\n                comparatorAdded = true;\n            }\n\n            if (localFieldType instanceof CompositeType) {\n                    \n                    \n                logicalField += localFieldType.getTotalFields() - 1;\n            }\n\n            logicalField++;\n        }\n\n        if (!comparatorAdded) {\n            throw new IllegalArgumentException(\n                    \"Could not add a comparator for the logical\"\n                            + \"key field index \"\n                            + logicalKeyFieldIndex\n                            + \".\");\n        }\n    }\n\n    return builder.createTypeComparator(config);\n}", "summary_tokens": ["generic", "implementation", "of", "the", "comparator", "creation"], "project": "flink"}
{"id": 6092, "code": "public void testLastHeartbeatFrom() {\n    final long heartbeatTimeout = 100L;\n    final ResourceID resourceId = ResourceID.generate();\n    final ResourceID target = ResourceID.generate();\n\n    HeartbeatManager<Object, Object> heartbeatManager =\n            new HeartbeatManagerImpl<>(\n                    heartbeatTimeout,\n                    FAILED_RPC_THRESHOLD,\n                    resourceId,\n                    new TestingHeartbeatListenerBuilder<>().createNewTestingHeartbeatListener(),\n                    TestingUtils.defaultScheduledExecutor(),\n                    LOG);\n\n    try {\n        heartbeatManager.monitorTarget(\n                target, new TestingHeartbeatTargetBuilder<>().createTestingHeartbeatTarget());\n\n        assertEquals(0L, heartbeatManager.getLastHeartbeatFrom(target));\n\n        final long currentTime = System.currentTimeMillis();\n\n        heartbeatManager.receiveHeartbeat(target, null);\n\n        assertTrue(heartbeatManager.getLastHeartbeatFrom(target) >= currentTime);\n    } finally {\n        heartbeatManager.stop();\n    }\n}", "summary_tokens": ["tests", "that", "we", "can", "correctly", "retrieve", "the", "last", "heartbeat", "for", "registered", "targets"], "project": "flink"}
{"id": 5161, "code": "private void checkResourceRequirementsWithDelay() {\n    if (requirementsCheckFuture == null || requirementsCheckFuture.isDone()) {\n        requirementsCheckFuture = new CompletableFuture<>();\n        scheduledExecutor.schedule(\n                () ->\n                        mainThreadExecutor.execute(\n                                () -> {\n                                    checkResourceRequirements();\n                                    Preconditions.checkNotNull(requirementsCheckFuture)\n                                            .complete(null);\n                                }),\n                requirementsCheckDelay.toMilliseconds(),\n                TimeUnit.MILLISECONDS);\n    }\n}", "summary_tokens": ["depending", "on", "the", "implementation", "of", "resource", "allocation", "strategy", "checking", "resource", "requirements", "and", "potentially", "making", "a", "re", "allocation", "can", "be", "heavy"], "project": "flink"}
{"id": 7274, "code": "public ReadableConfig getConfiguration() {\n    return new UnmodifiableConfiguration(configuration);\n}", "summary_tokens": ["gives", "read", "only", "access", "to", "the", "underlying", "configuration", "of", "this", "environment"], "project": "flink"}
{"id": 4730, "code": "private TypeSerializer<OT> getOutputSerializer() {\n    TypeSerializerFactory<OT> serializerFactory;\n\n    if ((serializerFactory = getLastTasksConfig().getOutputSerializer(getUserCodeClassLoader()))\n            == null) {\n        throw new RuntimeException(\"Missing output serializer for workset update.\");\n    }\n\n    return serializerFactory.getSerializer();\n}", "summary_tokens": ["output", "serializer", "of", "this", "task"], "project": "flink"}
{"id": 1611, "code": "private static Tuple2<LinkedHashMap<Class<?>, Integer>, TypeSerializer<Object>[]>\n        decomposeSubclassSerializerRegistry(\n                LinkedHashMap<Class<?>, TypeSerializer<?>> subclassSerializerRegistry) {\n\n    final LinkedHashMap<Class<?>, Integer> subclassIds =\n            new LinkedHashMap<>(subclassSerializerRegistry.size());\n    final TypeSerializer[] subclassSerializers =\n            new TypeSerializer[subclassSerializerRegistry.size()];\n\n    subclassSerializerRegistry.forEach(\n            (registeredSubclassClass, serializer) -> {\n                int id = subclassIds.size();\n                subclassIds.put(registeredSubclassClass, id);\n                subclassSerializers[id] = serializer;\n            });\n\n    return Tuple2.of(subclassIds, subclassSerializers);\n}", "summary_tokens": ["transforms", "the", "subclass", "serializer", "registry", "structure", "linked", "hash", "map", "class", "type", "serializer", "to", "0", "separate", "structures", "a", "map", "containing", "with", "registered", "classes", "as", "key", "and", "their", "corresponding", "ids", "order", "in", "the", "original", "map", "as", "value", "as", "well", "as", "a", "separate", "array", "of", "the", "corresponding", "subclass", "serializers"], "project": "flink"}
{"id": 8691, "code": "public void testEmptyProjection() {\n    TableSource<?> source =\n            createTableSource(TableSchema.builder().field(\"f0\", DataTypes.INT()).build());\n    assumeThat(source, instanceOf(ProjectableTableSource.class));\n\n    ProjectableTableSource<?> projectableTableSource = (ProjectableTableSource<?>) source;\n\n    TableSource<?> newTableSource = projectableTableSource.projectFields(new int[0]);\n    assertThat(newTableSource.explainSource(), not(equalTo(source.explainSource())));\n}", "summary_tokens": ["checks", "that", "projectable", "table", "source", "project", "fields", "int", "returns", "a", "table", "source", "with", "a", "different", "table", "source", "explain", "source", "even", "when", "filtering", "out", "all", "fields"], "project": "flink"}
{"id": 4623, "code": "public static int getSystemPageSizeOrDefault() {\n    final int pageSize = getSystemPageSize();\n    return pageSize == PAGE_SIZE_UNKNOWN ? DEFAULT_PAGE_SIZE : pageSize;\n}", "summary_tokens": ["tries", "to", "get", "the", "system", "page", "size"], "project": "flink"}
{"id": 5022, "code": "public static byte assignPartition(int bucket, byte numPartitions) {\n    return (byte) (bucket % numPartitions);\n}", "summary_tokens": ["assigns", "a", "partition", "to", "a", "bucket"], "project": "flink"}
{"id": 4320, "code": "public static void restoreMasterHooks(\n        final Map<String, MasterTriggerRestoreHook<?>> masterHooks,\n        final Collection<MasterState> states,\n        final long checkpointId,\n        final boolean allowUnmatchedState,\n        final Logger log)\n        throws FlinkException {\n\n        \n    if (states == null || states.isEmpty() || masterHooks == null || masterHooks.isEmpty()) {\n        log.info(\"No master state to restore\");\n        return;\n    }\n\n    log.info(\"Calling master restore hooks\");\n\n        \n    final LinkedHashMap<String, MasterTriggerRestoreHook<?>> allHooks =\n            new LinkedHashMap<>(masterHooks);\n\n        \n    final ArrayList<Tuple2<MasterTriggerRestoreHook<?>, Object>> hooksAndStates =\n            new ArrayList<>();\n\n    for (MasterState state : states) {\n        if (state != null) {\n            final String name = state.name();\n            final MasterTriggerRestoreHook<?> hook = allHooks.remove(name);\n\n            if (hook != null) {\n                log.debug(\"Found state to restore for hook '{}'\", name);\n\n                Object deserializedState = deserializeState(state, hook);\n                hooksAndStates.add(new Tuple2<>(hook, deserializedState));\n            } else if (!allowUnmatchedState) {\n                throw new IllegalStateException(\n                        \"Found state '\" + state.name() + \"' which is not resumed by any hook.\");\n            } else {\n                log.info(\"Dropping unmatched state from '{}'\", name);\n            }\n        }\n    }\n\n        \n    for (Tuple2<MasterTriggerRestoreHook<?>, Object> hookAndState : hooksAndStates) {\n        restoreHook(hookAndState.f1, hookAndState.f0, checkpointId);\n    }\n\n        \n    for (MasterTriggerRestoreHook<?> hook : allHooks.values()) {\n        restoreHook(null, hook, checkpointId);\n    }\n}", "summary_tokens": ["calls", "the", "restore", "method", "given", "checkpoint", "master", "hooks", "and", "passes", "the", "given", "master", "state", "to", "them", "where", "state", "with", "a", "matching", "name", "is", "found"], "project": "flink"}
{"id": 8534, "code": "static List<Type> collectTypeHierarchy(Type type) {\n    Type currentType = type;\n    Class<?> currentClass = toClass(type);\n    final List<Type> typeHierarchy = new ArrayList<>();\n    while (currentClass != null) {\n            \n        typeHierarchy.add(currentType);\n            \n        for (Type genericInterface : currentClass.getGenericInterfaces()) {\n            final Class<?> interfaceClass = toClass(genericInterface);\n            if (interfaceClass != null) {\n                typeHierarchy.addAll(collectTypeHierarchy(genericInterface));\n            }\n        }\n        currentType = currentClass.getGenericSuperclass();\n        currentClass = toClass(currentType);\n    }\n    return typeHierarchy;\n}", "summary_tokens": ["collects", "the", "partially", "ordered", "type", "hierarchy", "i"], "project": "flink"}
{"id": 7946, "code": "public SqlNodeList getPartitionSpec() {\n    return partitionSpec;\n}", "summary_tokens": ["returns", "the", "partition", "spec", "if", "the", "alter", "should", "be", "applied", "to", "partitions", "and", "null", "otherwise"], "project": "flink"}
{"id": 6767, "code": "byte[] helpGetBytesForState(long valuePointer) {\n    Node node = getNodeSegmentAndOffset(valuePointer);\n    MemorySegment segment = node.nodeSegment;\n    int offsetInSegment = node.nodeOffset;\n\n    int valueLen = SkipListUtils.getValueLen(segment, offsetInSegment);\n    MemorySegment valueSegment = MemorySegmentFactory.allocateUnpooledSegment(valueLen);\n    segment.copyTo(\n            offsetInSegment + SkipListUtils.getValueMetaLen(), valueSegment, 0, valueLen);\n\n    return valueSegment.getArray();\n}", "summary_tokens": ["returns", "the", "byte", "array", "of", "serialized", "state"], "project": "flink"}
{"id": 6105, "code": "public void testJobManagerLeaderRetrieval() throws Exception {\n    JobID jobId1 = new JobID();\n    JobID jobId2 = new JobID();\n    LeaderRetrievalListener jmListener1 = mock(LeaderRetrievalListener.class);\n    LeaderRetrievalListener jmListener2 = mock(LeaderRetrievalListener.class);\n    LeaderRetrievalListener rmListener = mock(LeaderRetrievalListener.class);\n\n    LeaderRetrievalService jmLeaderRetrievalService1 =\n            standaloneHaServices.getJobManagerLeaderRetriever(jobId1);\n    LeaderRetrievalService jmLeaderRetrievalService2 =\n            standaloneHaServices.getJobManagerLeaderRetriever(jobId2);\n    LeaderRetrievalService rmLeaderRetrievalService =\n            standaloneHaServices.getResourceManagerLeaderRetriever();\n\n    jmLeaderRetrievalService1.start(jmListener1);\n    jmLeaderRetrievalService2.start(jmListener2);\n    rmLeaderRetrievalService.start(rmListener);\n\n    verify(jmListener1)\n            .notifyLeaderAddress(eq(\"UNKNOWN\"), eq(HighAvailabilityServices.DEFAULT_LEADER_ID));\n    verify(jmListener2)\n            .notifyLeaderAddress(eq(\"UNKNOWN\"), eq(HighAvailabilityServices.DEFAULT_LEADER_ID));\n    verify(rmListener)\n            .notifyLeaderAddress(\n                    eq(resourceManagerAddress), eq(HighAvailabilityServices.DEFAULT_LEADER_ID));\n}", "summary_tokens": ["tests", "that", "the", "standalone", "leader", "retrieval", "services", "return", "the", "specified", "address", "and", "the", "fixed", "leader", "session", "id"], "project": "flink"}
{"id": 5661, "code": "public boolean nextKey() throws IOException {\n\n    if (lookahead != null) {\n            \n        this.comparator.setReference(this.lookahead);\n        this.valuesIterator.next = this.lookahead;\n        this.lastKeyRecord = this.lookahead;\n        this.lookahead = null;\n        this.valuesIterator.iteratorAvailable = true;\n        return true;\n    }\n\n        \n    if (this.done) {\n        return false;\n    }\n\n    if (this.valuesIterator != null) {\n            \n            \n        E next;\n        while (true) {\n            if ((next = this.iterator.next()) != null) {\n                if (!this.comparator.equalToReference(next)) {\n                        \n                    this.comparator.setReference(next);\n                    this.valuesIterator.next = next;\n                    this.lastKeyRecord = next;\n                    this.valuesIterator.iteratorAvailable = true;\n                    return true;\n                }\n            } else {\n                    \n                this.valuesIterator.next = null;\n                this.valuesIterator = null;\n                this.lastKeyRecord = null;\n                this.done = true;\n                return false;\n            }\n        }\n    } else {\n            \n            \n        E first = this.iterator.next();\n        if (first != null) {\n            this.comparator.setReference(first);\n            this.valuesIterator = new ValuesIterator(first);\n            this.lastKeyRecord = first;\n            return true;\n        } else {\n                \n            this.done = true;\n            return false;\n        }\n    }\n}", "summary_tokens": ["moves", "the", "iterator", "to", "the", "next", "key"], "project": "flink"}
{"id": 6470, "code": "public void testShouldRespectMaxContentLengthLimitForResponses() throws Exception {\n    testHandler.handlerBody =\n            id ->\n                    CompletableFuture.completedFuture(\n                            new TestResponse(\n                                    id, createStringOfSize(TEST_REST_MAX_CONTENT_LENGTH)));\n\n    try {\n        sendRequestToTestHandler(new TestRequest(1)).get();\n        fail(\"Expected exception not thrown\");\n    } catch (final ExecutionException e) {\n        final Throwable throwable = ExceptionUtils.stripExecutionException(e);\n        assertThat(throwable, instanceOf(TooLongFrameException.class));\n        assertThat(throwable.getMessage(), containsString(\"Try to raise\"));\n    }\n}", "summary_tokens": ["tests", "that", "responses", "larger", "than", "test", "rest", "max", "content", "length", "are", "rejected"], "project": "flink"}
{"id": 3270, "code": "public int getBlockCount() {\n    return blockCount;\n}", "summary_tokens": ["the", "total", "number", "of", "blocks"], "project": "flink"}
{"id": 5729, "code": "JobVertexThreadInfoTrackerBuilder<T> setVertexStatsCache(Cache<Key, T> vertexStatsCache) {\n    this.vertexStatsCache = vertexStatsCache;\n    return this;\n}", "summary_tokens": ["sets", "vertex", "stats", "cache"], "project": "flink"}
{"id": 5081, "code": "private MergeIterator<E> getMergingIterator(\n        final List<ChannelWithBlockCount> channelIDs,\n        final List<List<MemorySegment>> inputSegments,\n        List<FileIOChannel> readerList,\n        MutableObjectIterator<E> largeRecords)\n        throws IOException {\n        \n    LOG.debug(\"Performing merge of {} sorted streams.\", channelIDs.size());\n\n    final List<MutableObjectIterator<E>> iterators = new ArrayList<>(channelIDs.size() + 1);\n\n    for (int i = 0; i < channelIDs.size(); i++) {\n        final ChannelWithBlockCount channel = channelIDs.get(i);\n        final List<MemorySegment> segsForChannel = inputSegments.get(i);\n\n            \n            \n        final BlockChannelReader<MemorySegment> reader =\n                this.ioManager.createBlockChannelReader(channel.getChannel());\n\n        readerList.add(reader);\n        spillChannelManager.registerOpenChannelToBeRemovedAtShutdown(reader);\n        spillChannelManager.unregisterChannelToBeRemovedAtShutdown(channel.getChannel());\n\n            \n        final ChannelReaderInputView inView =\n                new ChannelReaderInputView(\n                        reader, segsForChannel, channel.getBlockCount(), false);\n        iterators.add(new ChannelReaderInputViewIterator<>(inView, null, this.serializer));\n    }\n\n    if (largeRecords != null) {\n        iterators.add(largeRecords);\n    }\n\n    return new MergeIterator<>(iterators, this.comparator);\n}", "summary_tokens": ["returns", "an", "iterator", "that", "iterates", "over", "the", "merged", "result", "from", "all", "given", "channels"], "project": "flink"}
{"id": 5274, "code": "CompletableFuture<LogicalSlot> allocateLogicalSlot(ExecutionVertexID executionVertexId) {\n    Preconditions.checkArgument(\n            executionSlotSharingGroup.getExecutionVertexIds().contains(executionVertexId),\n            \"Trying to allocate a logical slot for execution %s which is not in the ExecutionSlotSharingGroup\",\n            executionVertexId);\n    CompletableFuture<SingleLogicalSlot> logicalSlotFuture =\n            requestedLogicalSlots.getValueByKeyA(executionVertexId);\n    if (logicalSlotFuture != null) {\n        LOG.debug(\"Request for {} already exists\", getLogicalSlotString(executionVertexId));\n    } else {\n        logicalSlotFuture = allocateNonExistentLogicalSlot(executionVertexId);\n    }\n    return logicalSlotFuture.thenApply(Function.identity());\n}", "summary_tokens": ["registers", "an", "allocation", "request", "for", "a", "logical", "slot"], "project": "flink"}
{"id": 6561, "code": "public void testFixTypeOrder() {\n        \n    Assert.assertEquals(7, StateDescriptor.Type.values().length);\n        \n    Assert.assertEquals(0, StateDescriptor.Type.UNKNOWN.ordinal());\n    Assert.assertEquals(1, StateDescriptor.Type.VALUE.ordinal());\n    Assert.assertEquals(2, StateDescriptor.Type.LIST.ordinal());\n    Assert.assertEquals(3, StateDescriptor.Type.REDUCING.ordinal());\n    Assert.assertEquals(4, StateDescriptor.Type.FOLDING.ordinal());\n    Assert.assertEquals(5, StateDescriptor.Type.AGGREGATING.ordinal());\n    Assert.assertEquals(6, StateDescriptor.Type.MAP.ordinal());\n}", "summary_tokens": ["this", "test", "fixes", "the", "order", "of", "elements", "in", "the", "enum", "which", "is", "important", "for", "serialization"], "project": "flink"}
{"id": 1932, "code": "private static void longToByteArray(long l, byte[] ba, int offset) {\n    for (int i = 0; i < SIZE_OF_LONG; ++i) {\n        final int shift = i << 3; \n        ba[offset + SIZE_OF_LONG - 1 - i] = (byte) ((l & (0xffL << shift)) >>> shift);\n    }\n}", "summary_tokens": ["converts", "a", "long", "to", "a", "byte", "array"], "project": "flink"}
{"id": 94, "code": "public void testSendIsNotRetriableIfHttpNotFound() throws Exception {\n    final String exceptionMessage = \"test exception\";\n    final PingRestHandler pingRestHandler =\n            new PingRestHandler(\n                    FutureUtils.completedExceptionally(\n                            new RestHandlerException(\n                                    exceptionMessage, HttpResponseStatus.NOT_FOUND)));\n\n    try (final TestRestServerEndpoint restServerEndpoint =\n            createRestServerEndpoint(pingRestHandler)) {\n        RestClusterClient<?> restClusterClient =\n                createRestClusterClient(restServerEndpoint.getServerAddress().getPort());\n\n        try {\n            restClusterClient.sendRequest(PingRestHandlerHeaders.INSTANCE).get();\n            fail(\"The rest request should have failed.\");\n        } catch (Exception e) {\n            assertThat(\n                    ExceptionUtils.findThrowableWithMessage(e, exceptionMessage).isPresent(),\n                    is(true));\n        } finally {\n            restClusterClient.close();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "the", "send", "operation", "is", "not", "being", "retried", "when", "receiving", "a", "not", "found", "return", "code"], "project": "flink"}
{"id": 1830, "code": "public byte getValue() {\n    return this.value;\n}", "summary_tokens": ["returns", "the", "value", "of", "the", "encapsulated", "byte"], "project": "flink"}
{"id": 435, "code": "private void runTestMethod(FrameworkMethod method, EachTestNotifier notifier) {\n    Statement statement = methodBlock(method);\n\n    try {\n        statement.evaluate();\n    } catch (AssumptionViolatedException e) {\n        notifier.addFailedAssumption(e);\n    } catch (Throwable e) {\n        notifier.addFailure(e);\n    }\n}", "summary_tokens": ["runs", "a", "statement", "that", "represents", "a", "leaf", "aka", "atomic", "test"], "project": "flink"}
{"id": 9578, "code": "public void testSavepointRescalingKeyedState(boolean scaleOut, boolean deriveMaxParallelism)\n        throws Exception {\n    final int numberKeys = 42;\n    final int numberElements = 1000;\n    final int numberElements2 = 500;\n    final int parallelism = scaleOut ? numSlots / 2 : numSlots;\n    final int parallelism2 = scaleOut ? numSlots : numSlots / 2;\n    final int maxParallelism = 13;\n\n    Duration timeout = Duration.ofMinutes(3);\n    Deadline deadline = Deadline.now().plus(timeout);\n\n    ClusterClient<?> client = cluster.getClusterClient();\n\n    try {\n        JobGraph jobGraph =\n                createJobGraphWithKeyedState(\n                        parallelism, maxParallelism, numberKeys, numberElements, false, 100);\n\n        final JobID jobID = jobGraph.getJobID();\n\n        client.submitJob(jobGraph).get();\n\n            \n            \n        assertTrue(\n                SubtaskIndexFlatMapper.workCompletedLatch.await(\n                        deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS));\n\n            \n\n        Set<Tuple2<Integer, Integer>> actualResult = CollectionSink.getElementsSet();\n\n        Set<Tuple2<Integer, Integer>> expectedResult = new HashSet<>();\n\n        for (int key = 0; key < numberKeys; key++) {\n            int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism);\n\n            expectedResult.add(\n                    Tuple2.of(\n                            KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(\n                                    maxParallelism, parallelism, keyGroupIndex),\n                            numberElements * key));\n        }\n\n        assertEquals(expectedResult, actualResult);\n\n            \n        CollectionSink.clearElementsSet();\n\n        waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID(), false);\n        CompletableFuture<String> savepointPathFuture = client.triggerSavepoint(jobID, null);\n\n        final String savepointPath =\n                savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n        client.cancel(jobID).get();\n\n        while (!getRunningJobs(client).isEmpty()) {\n            Thread.sleep(50);\n        }\n\n        int restoreMaxParallelism =\n                deriveMaxParallelism ? JobVertex.MAX_PARALLELISM_DEFAULT : maxParallelism;\n\n        JobGraph scaledJobGraph =\n                createJobGraphWithKeyedState(\n                        parallelism2,\n                        restoreMaxParallelism,\n                        numberKeys,\n                        numberElements2,\n                        true,\n                        100);\n\n        scaledJobGraph.setSavepointRestoreSettings(\n                SavepointRestoreSettings.forPath(savepointPath));\n\n        submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n        Set<Tuple2<Integer, Integer>> actualResult2 = CollectionSink.getElementsSet();\n\n        Set<Tuple2<Integer, Integer>> expectedResult2 = new HashSet<>();\n\n        for (int key = 0; key < numberKeys; key++) {\n            int keyGroupIndex = KeyGroupRangeAssignment.assignToKeyGroup(key, maxParallelism);\n            expectedResult2.add(\n                    Tuple2.of(\n                            KeyGroupRangeAssignment.computeOperatorIndexForKeyGroup(\n                                    maxParallelism, parallelism2, keyGroupIndex),\n                            key * (numberElements + numberElements2)));\n        }\n\n        assertEquals(expectedResult2, actualResult2);\n\n    } finally {\n            \n        CollectionSink.clearElementsSet();\n    }\n}", "summary_tokens": ["tests", "that", "a", "job", "with", "purely", "keyed", "state", "can", "be", "restarted", "from", "a", "savepoint", "with", "a", "different", "parallelism"], "project": "flink"}
{"id": 577, "code": "default void open(DeserializationSchema.InitializationContext context) throws Exception {}", "summary_tokens": ["initialization", "method", "for", "the", "schema"], "project": "flink"}
{"id": 3231, "code": "public String getName(String defaultName) {\n    if (name != null) {\n        return name;\n    } else {\n        return defaultName;\n    }\n}", "summary_tokens": ["gets", "the", "name", "of", "the", "iteration"], "project": "flink"}
{"id": 5438, "code": "private void deleteDirectory(File directory) throws IOException {\n    Path path = new Path(directory.toURI());\n    FileSystem fileSystem = path.getFileSystem();\n    if (fileSystem.exists(path)) {\n        fileSystem.delete(path, true);\n    }\n}", "summary_tokens": ["helper", "method", "to", "delete", "a", "directory"], "project": "flink"}
{"id": 7445, "code": "public void mergeWindows(\n        Collection<TimeWindow> windows, MergingWindowAssigner.MergeCallback<TimeWindow> c) {\n    TimeWindow.mergeWindows(windows, c);\n}", "summary_tokens": ["merge", "overlapping", "time", "window", "s"], "project": "flink"}
{"id": 854, "code": "public static Properties backfillConsumerKeys(Properties configProps) {\n    HashMap<String, String> oldKeyToNewKeys = new HashMap<>();\n    oldKeyToNewKeys.put(\n            ConsumerConfigConstants.STREAM_DESCRIBE_BACKOFF_BASE,\n            ConsumerConfigConstants.LIST_SHARDS_BACKOFF_BASE);\n    oldKeyToNewKeys.put(\n            ConsumerConfigConstants.STREAM_DESCRIBE_BACKOFF_MAX,\n            ConsumerConfigConstants.LIST_SHARDS_BACKOFF_MAX);\n    oldKeyToNewKeys.put(\n            ConsumerConfigConstants.STREAM_DESCRIBE_BACKOFF_EXPONENTIAL_CONSTANT,\n            ConsumerConfigConstants.LIST_SHARDS_BACKOFF_EXPONENTIAL_CONSTANT);\n    for (Map.Entry<String, String> entry : oldKeyToNewKeys.entrySet()) {\n        String oldKey = entry.getKey();\n        String newKey = entry.getValue();\n        if (configProps.containsKey(oldKey)) {\n            configProps.setProperty(newKey, configProps.getProperty(oldKey));\n                \n                \n        }\n    }\n    return configProps;\n}", "summary_tokens": ["a", "set", "of", "configuration", "parameters", "associated", "with", "the", "describe", "streams", "api", "may", "be", "used", "if", "0", "an", "legacy", "client", "wants", "to", "consume", "from", "kinesis", "0", "a", "current", "client", "wants", "to", "consumer", "from", "dynamo", "db", "streams"], "project": "flink"}
{"id": 4366, "code": "default CompletableFuture<String> triggerSavepointAndGetLocation(\n        JobID jobId,\n        String targetDirectory,\n        TriggerSavepointMode savepointMode,\n        @RpcTimeout Time timeout) {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["triggers", "a", "savepoint", "with", "the", "given", "savepoint", "directory", "as", "a", "target", "returning", "a", "future", "that", "completes", "with", "the", "savepoint", "location", "when", "it", "is", "complete"], "project": "flink"}
{"id": 6037, "code": "public void testSuspendedOutOfFailed() throws Exception {\n    final InteractionsCountingTaskManagerGateway gateway =\n            new InteractionsCountingTaskManagerGateway();\n    final int parallelism = 10;\n    final SchedulerBase scheduler = createScheduler(gateway, parallelism);\n    final ExecutionGraph eg = scheduler.getExecutionGraph();\n\n    scheduler.startScheduling();\n    ExecutionGraphTestUtils.switchAllVerticesToRunning(eg);\n\n    scheduler.handleGlobalFailure(new Exception(\"fail global\"));\n\n    assertEquals(JobStatus.FAILING, eg.getState());\n    validateCancelRpcCalls(gateway, parallelism);\n\n    ExecutionGraphTestUtils.completeCancellingForAllVertices(eg);\n    assertEquals(JobStatus.FAILED, eg.getState());\n\n        \n    scheduler.closeAsync();\n\n        \n    assertEquals(JobStatus.FAILED, eg.getState());\n    validateCancelRpcCalls(gateway, parallelism);\n}", "summary_tokens": ["suspending", "from", "failed", "should", "do", "nothing"], "project": "flink"}
{"id": 4952, "code": "private String getLogString(String message) {\n    return BatchTask.constructLogString(\n            message, this.getEnvironment().getTaskInfo().getTaskName(), this);\n}", "summary_tokens": ["utility", "function", "that", "composes", "a", "string", "for", "logging", "purposes"], "project": "flink"}
{"id": 8048, "code": "public Optional<Catalog> getCatalog(String catalogName) {\n    return Optional.ofNullable(catalogs.get(catalogName));\n}", "summary_tokens": ["gets", "a", "catalog", "by", "name"], "project": "flink"}
{"id": 552, "code": "public FlinkKafkaConsumerBase<T> assignTimestampsAndWatermarks(\n        AssignerWithPeriodicWatermarks<T> assigner) {\n    checkNotNull(assigner);\n\n    if (this.watermarkStrategy != null) {\n        throw new IllegalStateException(\"Some watermark strategy has already been set.\");\n    }\n\n    try {\n        ClosureCleaner.clean(assigner, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n        final WatermarkStrategy<T> wms =\n                new AssignerWithPeriodicWatermarksAdapter.Strategy<>(assigner);\n\n        return assignTimestampsAndWatermarks(wms);\n    } catch (Exception e) {\n        throw new IllegalArgumentException(\"The given assigner is not serializable\", e);\n    }\n}", "summary_tokens": ["specifies", "an", "assigner", "with", "punctuated", "watermarks", "to", "emit", "watermarks", "in", "a", "punctuated", "manner"], "project": "flink"}
{"id": 4949, "code": "public static <T> T instantiateUserCode(\n        TaskConfig config, ClassLoader cl, Class<? super T> superClass) {\n    try {\n        T stub = config.<T>getStubWrapper(cl).getUserCodeObject(superClass, cl);\n            \n        if (superClass != null && !superClass.isAssignableFrom(stub.getClass())) {\n            throw new RuntimeException(\n                    \"The class '\"\n                            + stub.getClass().getName()\n                            + \"' is not a subclass of '\"\n                            + superClass.getName()\n                            + \"' as is required.\");\n        }\n        return stub;\n    } catch (ClassCastException ccex) {\n        throw new RuntimeException(\n                \"The UDF class is not a proper subclass of \" + superClass.getName(), ccex);\n    }\n}", "summary_tokens": ["instantiates", "a", "user", "code", "class", "from", "is", "definition", "in", "the", "task", "configuration"], "project": "flink"}
{"id": 4001, "code": "public void testLocalOverSizedResponseMsgAsync() throws Exception {\n    final String message =\n            runLocalMessageResponseTest(OVERSIZED_PAYLOAD, this::requestMessageAsync);\n    assertThat(message, is(equalTo(OVERSIZED_PAYLOAD)));\n}", "summary_tokens": ["tests", "that", "we", "can", "send", "arbitrarily", "large", "objects", "when", "communicating", "locally", "with", "the", "rpc", "endpoint"], "project": "flink"}
{"id": 1398, "code": "public boolean isCompatibleAfterMigration() {\n    return resultType == Type.COMPATIBLE_AFTER_MIGRATION;\n}", "summary_tokens": ["returns", "whether", "or", "not", "the", "type", "of", "the", "compatibility", "is", "type", "compatible", "after", "migration"], "project": "flink"}
{"id": 4228, "code": "private CheckpointPlan calculateAfterTasksFinished() {\n        \n        \n        \n    Map<JobVertexID, BitSet> taskRunningStatusByVertex = collectTaskRunningStatus();\n\n    List<Execution> tasksToTrigger = new ArrayList<>();\n    List<Execution> tasksToWaitFor = new ArrayList<>();\n    List<ExecutionVertex> tasksToCommitTo = new ArrayList<>();\n    List<Execution> finishedTasks = new ArrayList<>();\n    List<ExecutionJobVertex> fullyFinishedJobVertex = new ArrayList<>();\n\n    for (ExecutionJobVertex jobVertex : jobVerticesInTopologyOrder) {\n        BitSet taskRunningStatus = taskRunningStatusByVertex.get(jobVertex.getJobVertexId());\n\n        if (taskRunningStatus.cardinality() == 0) {\n            fullyFinishedJobVertex.add(jobVertex);\n\n            for (ExecutionVertex task : jobVertex.getTaskVertices()) {\n                finishedTasks.add(task.getCurrentExecutionAttempt());\n            }\n\n            continue;\n        }\n\n        List<JobEdge> prevJobEdges = jobVertex.getJobVertex().getInputs();\n\n            \n            \n        boolean someTasksMustBeTriggered =\n                someTasksMustBeTriggered(taskRunningStatusByVertex, prevJobEdges);\n\n        for (int i = 0; i < jobVertex.getTaskVertices().length; ++i) {\n            ExecutionVertex task = jobVertex.getTaskVertices()[i];\n            if (taskRunningStatus.get(task.getParallelSubtaskIndex())) {\n                tasksToWaitFor.add(task.getCurrentExecutionAttempt());\n                tasksToCommitTo.add(task);\n\n                if (someTasksMustBeTriggered) {\n                    boolean hasRunningPrecedentTasks =\n                            hasRunningPrecedentTasks(\n                                    task, prevJobEdges, taskRunningStatusByVertex);\n\n                    if (!hasRunningPrecedentTasks) {\n                        tasksToTrigger.add(task.getCurrentExecutionAttempt());\n                    }\n                }\n            } else {\n                finishedTasks.add(task.getCurrentExecutionAttempt());\n            }\n        }\n    }\n\n    return new DefaultCheckpointPlan(\n            Collections.unmodifiableList(tasksToTrigger),\n            Collections.unmodifiableList(tasksToWaitFor),\n            Collections.unmodifiableList(tasksToCommitTo),\n            Collections.unmodifiableList(finishedTasks),\n            Collections.unmodifiableList(fullyFinishedJobVertex),\n            allowCheckpointsAfterTasksFinished);\n}", "summary_tokens": ["calculates", "the", "checkpoint", "plan", "after", "some", "tasks", "have", "finished"], "project": "flink"}
{"id": 9581, "code": "public void testSavepointRescalingPartitionedOperatorState(\n        boolean scaleOut, OperatorCheckpointMethod checkpointMethod) throws Exception {\n    final int parallelism = scaleOut ? numSlots : numSlots / 2;\n    final int parallelism2 = scaleOut ? numSlots / 2 : numSlots;\n    final int maxParallelism = 13;\n\n    Duration timeout = Duration.ofMinutes(3);\n    Deadline deadline = Deadline.now().plus(timeout);\n\n    ClusterClient<?> client = cluster.getClusterClient();\n\n    int counterSize = Math.max(parallelism, parallelism2);\n\n    if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION\n            || checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n        PartitionedStateSource.checkCorrectSnapshot = new int[counterSize];\n        PartitionedStateSource.checkCorrectRestore = new int[counterSize];\n    } else {\n        PartitionedStateSourceListCheckpointed.checkCorrectSnapshot = new int[counterSize];\n        PartitionedStateSourceListCheckpointed.checkCorrectRestore = new int[counterSize];\n    }\n\n    try {\n        JobGraph jobGraph =\n                createJobGraphWithOperatorState(parallelism, maxParallelism, checkpointMethod);\n            \n        StateSourceBase.canFinishLatch = new CountDownLatch(1);\n\n        final JobID jobID = jobGraph.getJobID();\n\n        client.submitJob(jobGraph).get();\n\n            \n        waitForAllTaskRunning(cluster.getMiniCluster(), jobGraph.getJobID(), false);\n            \n        StateSourceBase.workStartedLatch.await();\n\n        CompletableFuture<String> savepointPathFuture =\n                FutureUtils.retryWithDelay(\n                        () -> client.triggerSavepoint(jobID, null),\n                        (int) deadline.timeLeft().getSeconds() / 10,\n                        Time.seconds(10),\n                        (throwable) -> true,\n                        TestingUtils.defaultScheduledExecutor());\n\n        final String savepointPath =\n                savepointPathFuture.get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n\n            \n        StateSourceBase.canFinishLatch.countDown();\n        client.cancel(jobID).get();\n        while (!getRunningJobs(client).isEmpty()) {\n            Thread.sleep(50);\n        }\n\n        JobGraph scaledJobGraph =\n                createJobGraphWithOperatorState(parallelism2, maxParallelism, checkpointMethod);\n\n        scaledJobGraph.setSavepointRestoreSettings(\n                SavepointRestoreSettings.forPath(savepointPath));\n\n        submitJobAndWaitForResult(client, scaledJobGraph, getClass().getClassLoader());\n\n        int sumExp = 0;\n        int sumAct = 0;\n\n        if (checkpointMethod == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION) {\n            for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                sumExp += c;\n            }\n\n            for (int c : PartitionedStateSource.checkCorrectRestore) {\n                sumAct += c;\n            }\n        } else if (checkpointMethod\n                == OperatorCheckpointMethod.CHECKPOINTED_FUNCTION_BROADCAST) {\n            for (int c : PartitionedStateSource.checkCorrectSnapshot) {\n                sumExp += c;\n            }\n\n            for (int c : PartitionedStateSource.checkCorrectRestore) {\n                sumAct += c;\n            }\n\n            sumExp *= parallelism2;\n        } else {\n            for (int c : PartitionedStateSourceListCheckpointed.checkCorrectSnapshot) {\n                sumExp += c;\n            }\n\n            for (int c : PartitionedStateSourceListCheckpointed.checkCorrectRestore) {\n                sumAct += c;\n            }\n        }\n\n        assertEquals(sumExp, sumAct);\n    } finally {\n    }\n}", "summary_tokens": ["tests", "rescaling", "of", "partitioned", "operator", "state"], "project": "flink"}
{"id": 8493, "code": "default String[] getFieldNames() {\n    return null;\n}", "summary_tokens": ["use", "the", "field", "names", "of", "get", "table", "schema", "instead"], "project": "flink"}
{"id": 3742, "code": "public void testBranchingSourceMultipleTimes() {\n    try {\n        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(DEFAULT_PARALLELISM);\n\n        DataSet<Tuple2<Long, Long>> source =\n                env.generateSequence(1, 10000000).map(new Duplicator<Long>());\n\n        DataSet<Tuple2<Long, Long>> joined1 =\n                source.join(source)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined2 =\n                source.join(joined1)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined3 =\n                source.join(joined2)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined4 =\n                source.join(joined3)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined5 =\n                source.join(joined4)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> mapped =\n                source.map(\n                        new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {\n                            @Override\n                            public Tuple2<Long, Long> map(Tuple2<Long, Long> value) {\n                                return null;\n                            }\n                        });\n\n        DataSet<Tuple2<Long, Long>> joined6 =\n                mapped.join(mapped)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined7 =\n                mapped.join(joined6)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined8 =\n                mapped.join(joined7)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined9 =\n                mapped.join(joined8)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> joined10 =\n                mapped.join(joined9)\n                        .where(0)\n                        .equalTo(0)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        joined5.coGroup(joined10)\n                .where(1)\n                .equalTo(1)\n                .with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())\n                .output(\n                        new DiscardingOutputFormat<\n                                Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>());\n\n        Plan plan = env.createProgramPlan();\n        OptimizedPlan oPlan = compileNoStats(plan);\n        new JobGraphGenerator().compileJobGraph(oPlan);\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["pre", "sink", "cogroup", "match", "0", "match", "0", "match", "0", "match", "0", "match", "0", "match", "0", "match", "0", "match", "0", "match", "0", "match", "0", "map", "data", "source", "one", "pre"], "project": "flink"}
{"id": 7232, "code": "public long getCheckpointInterval() {\n    return checkpointCfg.getCheckpointInterval();\n}", "summary_tokens": ["returns", "the", "checkpointing", "interval", "or", "0", "if", "checkpointing", "is", "disabled"], "project": "flink"}
{"id": 105, "code": "public static KinesisAsyncClient createKinesisAsyncClient(\n        final Properties configProps,\n        final SdkClientConfiguration clientConfiguration,\n        final SdkAsyncHttpClient httpClient) {\n    String flinkUserAgentPrefix =\n            Optional.ofNullable(\n                            configProps.getProperty(\n                                    AWSKinesisDataStreamsConfigConstants\n                                            .KINESIS_CLIENT_USER_AGENT_PREFIX))\n                    .orElse(formatFlinkUserAgentPrefix(USER_AGENT_FORMAT));\n\n    final ClientOverrideConfiguration overrideConfiguration =\n            createClientOverrideConfiguration(\n                    clientConfiguration,\n                    ClientOverrideConfiguration.builder(),\n                    flinkUserAgentPrefix);\n    final KinesisAsyncClientBuilder clientBuilder = KinesisAsyncClient.builder();\n\n    return createKinesisAsyncClient(\n            configProps, clientBuilder, httpClient, overrideConfiguration);\n}", "summary_tokens": ["config", "props", "configuration", "properties", "client", "configuration", "the", "aws", "sdk", "v", "0", "config", "to", "instantiate", "the", "client", "http", "client", "the", "underlying", "http", "client", "used", "to", "talk", "to", "kinesis", "a", "new", "amazon", "kinesis", "client"], "project": "flink"}
{"id": 1082, "code": "public LinkedHashMap<Class<?>, Class<? extends Serializer<?>>>\n        getDefaultKryoSerializerClasses() {\n    return defaultKryoSerializerClasses;\n}", "summary_tokens": ["returns", "the", "registered", "default", "kryo", "serializer", "classes"], "project": "flink"}
{"id": 112, "code": "public ConcreteBuilderT setElementConverter(\n        ElementConverter<InputT, RequestEntryT> elementConverter) {\n    this.elementConverter = elementConverter;\n    return (ConcreteBuilderT) this;\n}", "summary_tokens": ["element", "converter", "the", "element", "converter", "to", "be", "used", "for", "the", "sink", "concrete", "builder", "t", "itself"], "project": "flink"}
{"id": 5500, "code": "public StateMap<K, N, S>[] getState() {\n    return keyGroupedStateMaps;\n}", "summary_tokens": ["returns", "the", "internal", "data", "structure"], "project": "flink"}
{"id": 912, "code": "public void putSplitsBackToPendingList(List<PulsarPartitionSplit> splits, int readerId) {\n    if (!sharePartition()) {\n            \n        pendingPartitionSplits.addAll(splits);\n    } else {\n            \n        Set<PulsarPartitionSplit> pending =\n                sharedPendingPartitionSplits.computeIfAbsent(readerId, id -> new HashSet<>());\n        pending.addAll(splits);\n    }\n}", "summary_tokens": ["put", "these", "splits", "back", "to", "pending", "list"], "project": "flink"}
{"id": 9051, "code": "public void testCorrelate() {\n    createTestSource();\n    util.addTemporarySystemFunction(\"func1\", new TableFunc1());\n    verifyQuery(\"SELECT s FROM MyTable, LATERAL TABLE(func1(c)) AS T(s)\");\n}", "summary_tokens": ["verify", "correlate", "and", "calc"], "project": "flink"}
{"id": 3675, "code": "public void parameterizeChannel(\n        Channel channel,\n        boolean globalDopChange,\n        ExecutionMode exchangeMode,\n        boolean breakPipeline) {\n\n        \n    if (channel.getSource().getGlobalProperties().isFullyReplicated()\n            && !(this.partitioning == PartitioningProperty.FULL_REPLICATION\n                    || this.partitioning == PartitioningProperty.ANY_DISTRIBUTION)) {\n        throw new CompilerException(\n                \"Fully replicated input must be preserved \"\n                        + \"and may not be converted into another global property.\");\n    }\n\n        \n        \n        \n    if (isTrivial() || this.partitioning == PartitioningProperty.ANY_DISTRIBUTION) {\n        ShipStrategyType shipStrategy =\n                globalDopChange ? ShipStrategyType.PARTITION_RANDOM : ShipStrategyType.FORWARD;\n\n        DataExchangeMode em =\n                DataExchangeMode.select(exchangeMode, shipStrategy, breakPipeline);\n        channel.setShipStrategy(shipStrategy, em);\n        return;\n    }\n\n    final GlobalProperties inGlobals = channel.getSource().getGlobalProperties();\n        \n        \n    if (!globalDopChange && isMetBy(inGlobals)) {\n        DataExchangeMode em =\n                DataExchangeMode.select(exchangeMode, ShipStrategyType.FORWARD, breakPipeline);\n        channel.setShipStrategy(ShipStrategyType.FORWARD, em);\n        return;\n    }\n\n        \n    ShipStrategyType shipType;\n    FieldList partitionKeys;\n    boolean[] sortDirection;\n    Partitioner<?> partitioner;\n\n    switch (this.partitioning) {\n        case FULL_REPLICATION:\n            shipType = ShipStrategyType.BROADCAST;\n            partitionKeys = null;\n            sortDirection = null;\n            partitioner = null;\n            break;\n\n        case ANY_PARTITIONING:\n        case HASH_PARTITIONED:\n            shipType = ShipStrategyType.PARTITION_HASH;\n            partitionKeys = Utils.createOrderedFromSet(this.partitioningFields);\n            sortDirection = null;\n            partitioner = null;\n            break;\n\n        case RANGE_PARTITIONED:\n            shipType = ShipStrategyType.PARTITION_RANGE;\n            partitionKeys = this.ordering.getInvolvedIndexes();\n            sortDirection = this.ordering.getFieldSortDirections();\n            partitioner = null;\n\n            if (this.dataDistribution != null) {\n                channel.setDataDistribution(this.dataDistribution);\n            }\n            break;\n\n        case FORCED_REBALANCED:\n            shipType = ShipStrategyType.PARTITION_FORCED_REBALANCE;\n            partitionKeys = null;\n            sortDirection = null;\n            partitioner = null;\n            break;\n\n        case CUSTOM_PARTITIONING:\n            shipType = ShipStrategyType.PARTITION_CUSTOM;\n            partitionKeys = Utils.createOrderedFromSet(this.partitioningFields);\n            sortDirection = null;\n            partitioner = this.customPartitioner;\n            break;\n\n        default:\n            throw new CompilerException(\n                    \"Invalid partitioning to create through a data exchange: \"\n                            + this.partitioning.name());\n    }\n\n    DataExchangeMode exMode = DataExchangeMode.select(exchangeMode, shipType, breakPipeline);\n    channel.setShipStrategy(shipType, partitionKeys, sortDirection, partitioner, exMode);\n}", "summary_tokens": ["parametrizes", "the", "ship", "strategy", "fields", "of", "a", "channel", "such", "that", "the", "channel", "produces", "the", "desired", "global", "properties"], "project": "flink"}
{"id": 5933, "code": "public void testCompletedCheckpointStatsCallbacks() throws Exception {\n    CompletedCheckpoint completed =\n            new CompletedCheckpoint(\n                    new JobID(),\n                    0,\n                    0,\n                    1,\n                    Collections.emptyMap(),\n                    Collections.emptyList(),\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    new TestCompletedCheckpointStorageLocation());\n\n    CompletedCheckpointStats.DiscardCallback callback =\n            mock(CompletedCheckpointStats.DiscardCallback.class);\n    completed.setDiscardCallback(callback);\n\n    completed.discardOnShutdown(JobStatus.FINISHED);\n    verify(callback, times(1)).notifyDiscardedCheckpoint();\n}", "summary_tokens": ["tests", "that", "the", "stats", "callbacks", "happen", "if", "the", "callback", "is", "registered"], "project": "flink"}
{"id": 3819, "code": "protected void checkInvokeFinishBundleByCount() throws Exception {\n    if (elementCount >= maxBundleSize) {\n        invokeFinishBundle();\n    }\n}", "summary_tokens": ["checks", "whether", "to", "invoke", "finish", "bundle", "by", "elements", "count"], "project": "flink"}
{"id": 1128, "code": "public void add(Integer value) {\n    localValue += value;\n}", "summary_tokens": ["consider", "using", "add", "int", "instead", "for", "primitive", "int", "values"], "project": "flink"}
{"id": 30, "code": "private static int handleError(Throwable t) {\n    LOG.error(\"Error while running the command.\", t);\n\n    System.err.println();\n    System.err.println(\"------------------------------------------------------------\");\n    System.err.println(\" The program finished with the following exception:\");\n    System.err.println();\n\n    if (t.getCause() instanceof InvalidProgramException) {\n        System.err.println(t.getCause().getMessage());\n        StackTraceElement[] trace = t.getCause().getStackTrace();\n        for (StackTraceElement ele : trace) {\n            System.err.println(\"\\t\" + ele);\n            if (ele.getMethodName().equals(\"main\")) {\n                break;\n            }\n        }\n    } else {\n        t.printStackTrace();\n    }\n    return 1;\n}", "summary_tokens": ["displays", "an", "exception", "message"], "project": "flink"}
{"id": 8152, "code": "public ResolvedSchema resolve(SchemaResolver resolver) {\n    return resolver.resolve(this);\n}", "summary_tokens": ["resolves", "the", "given", "schema", "to", "a", "validated", "resolved", "schema"], "project": "flink"}
{"id": 2737, "code": "public void setCharset(String charset) {\n    this.charset = Preconditions.checkNotNull(charset);\n}", "summary_tokens": ["sets", "the", "charset", "of", "the", "reader"], "project": "flink"}
{"id": 8336, "code": "public static void setShort(MemorySegment[] segments, int offset, short value) {\n    if (inFirstSegment(segments, offset, 2)) {\n        segments[0].putShort(offset, value);\n    } else {\n        setShortMultiSegments(segments, offset, value);\n    }\n}", "summary_tokens": ["set", "short", "from", "segments"], "project": "flink"}
{"id": 4888, "code": "protected void putVariables(Map<String, String> variables) {}", "summary_tokens": ["enters", "all", "variables", "specific", "to", "this", "abstract", "metric", "group", "and", "their", "associated", "values", "into", "the", "map"], "project": "flink"}
{"id": 6518, "code": "public void handleGlobalFailureWithLocalFailure() {\n    final JobGraph jobGraph = singleJobVertexJobGraph(2);\n    final JobVertex onlyJobVertex = getOnlyJobVertex(jobGraph);\n    enableCheckpointing(jobGraph);\n\n    final DefaultScheduler scheduler = createSchedulerAndStartScheduling(jobGraph);\n\n    final List<ExecutionAttemptID> attemptIds =\n            StreamSupport.stream(\n                            scheduler\n                                    .requestJob()\n                                    .getArchivedExecutionGraph()\n                                    .getAllExecutionVertices()\n                                    .spliterator(),\n                            false)\n                    .map(ArchivedExecutionVertex::getCurrentExecutionAttempt)\n                    .map(ArchivedExecution::getAttemptId)\n                    .collect(Collectors.toList());\n    final ExecutionAttemptID localFailureAttemptId = attemptIds.get(0);\n    scheduler.handleGlobalFailure(new Exception(\"global failure\"));\n        \n    scheduler.updateTaskExecutionState(\n            new TaskExecutionState(\n                    localFailureAttemptId,\n                    ExecutionState.FAILED,\n                    new Exception(\"local failure\")));\n\n    for (ExecutionAttemptID attemptId : attemptIds) {\n        scheduler.updateTaskExecutionState(\n                new TaskExecutionState(attemptId, ExecutionState.CANCELED));\n    }\n\n    taskRestartExecutor.triggerScheduledTasks();\n\n    final ExecutionVertexID executionVertexId0 =\n            new ExecutionVertexID(onlyJobVertex.getID(), 0);\n    final ExecutionVertexID executionVertexId1 =\n            new ExecutionVertexID(onlyJobVertex.getID(), 1);\n    assertThat(\n            \"The execution vertices should be deployed in a specific order reflecting the scheduling start and the global fail-over afterwards.\",\n            testExecutionVertexOperations.getDeployedVertices(),\n            contains(\n                    executionVertexId0,\n                    executionVertexId1,\n                    executionVertexId0,\n                    executionVertexId1));\n}", "summary_tokens": ["this", "test", "covers", "the", "use", "case", "where", "a", "global", "fail", "over", "is", "followed", "by", "a", "local", "task", "failure"], "project": "flink"}
{"id": 5486, "code": "public boolean add(@Nonnull T element) {\n    return getDedupMapForElement(element).putIfAbsent(element, element) == null\n            && super.add(element);\n}", "summary_tokens": ["adds", "the", "element", "to", "the", "queue"], "project": "flink"}
{"id": 3967, "code": "public static ActorSystem startLocalActorSystem(\n        Configuration configuration,\n        String actorSystemName,\n        Logger logger,\n        Config actorSystemExecutorConfiguration,\n        Config customConfig)\n        throws Exception {\n\n    logger.info(\"Trying to start local actor system\");\n\n    try {\n        Config akkaConfig =\n                AkkaUtils.getAkkaConfig(\n                        configuration, null, null, actorSystemExecutorConfiguration);\n\n        if (customConfig != null) {\n            akkaConfig = customConfig.withFallback(akkaConfig);\n        }\n\n        return startActorSystem(akkaConfig, actorSystemName, logger);\n    } catch (Throwable t) {\n        throw new Exception(\"Could not create actor system\", t);\n    }\n}", "summary_tokens": ["starts", "a", "local", "actor", "system"], "project": "flink"}
{"id": 193, "code": "public B setSocketTimeout(int timeout) {\n    checkState(timeout >= 0, \"Socket timeout must be larger than or equal to 0.\");\n    this.socketTimeout = timeout;\n    return self();\n}", "summary_tokens": ["sets", "the", "timeout", "for", "waiting", "for", "data", "or", "put", "differently", "a", "maximum", "period", "inactivity", "between", "two", "consecutive", "data", "packets"], "project": "flink"}
{"id": 1960, "code": "public static Optional<Throwable> findThrowableWithMessage(\n        Throwable throwable, String searchMessage) {\n    if (throwable == null || searchMessage == null) {\n        return Optional.empty();\n    }\n\n    Throwable t = throwable;\n    while (t != null) {\n        if (t.getMessage() != null && t.getMessage().contains(searchMessage)) {\n            return Optional.of(t);\n        } else {\n            t = t.getCause();\n        }\n    }\n\n    return Optional.empty();\n}", "summary_tokens": ["checks", "whether", "a", "throwable", "chain", "contains", "a", "specific", "error", "message", "and", "returns", "the", "corresponding", "throwable"], "project": "flink"}
{"id": 1684, "code": "public static MemorySize parse(String text, MemoryUnit defaultUnit)\n        throws IllegalArgumentException {\n    if (!hasUnit(text)) {\n        return parse(text + defaultUnit.getUnits()[0]);\n    }\n\n    return parse(text);\n}", "summary_tokens": ["parses", "the", "given", "string", "with", "a", "default", "unit"], "project": "flink"}
{"id": 1427, "code": "public void setDescription(String description) {\n    this.description = Preconditions.checkNotNull(description);\n}", "summary_tokens": ["changes", "the", "description", "of", "this", "transformation"], "project": "flink"}
{"id": 6266, "code": "private static void waitForEmptyBlobDir(File blobDir, Duration remaining)\n        throws InterruptedException {\n    long deadline = System.currentTimeMillis() + remaining.toMillis();\n    String[] blobDirContents;\n    final FilenameFilter jobDirFilter = (dir, name) -> name.startsWith(\"job_\");\n\n    do {\n        blobDirContents = blobDir.list(jobDirFilter);\n        if (blobDirContents == null || blobDirContents.length == 0) {\n            return;\n        }\n        Thread.sleep(RETRY_INTERVAL);\n    } while (System.currentTimeMillis() < deadline);\n\n    fail(\n            \"Timeout while waiting for \"\n                    + blobDir.getAbsolutePath()\n                    + \" to become empty. Current contents: \"\n                    + Arrays.toString(blobDirContents));\n}", "summary_tokens": ["waits", "until", "the", "given", "org"], "project": "flink"}
{"id": 6018, "code": "public void testStringTaskEvent() {\n\n    try {\n\n        final StringTaskEvent orig = new StringTaskEvent(\"Test\");\n        final StringTaskEvent copy = InstantiationUtil.createCopyWritable(orig);\n\n        assertEquals(orig.getString(), copy.getString());\n        assertEquals(orig.hashCode(), copy.hashCode());\n        assertTrue(orig.equals(copy));\n\n    } catch (IOException ioe) {\n        fail(ioe.getMessage());\n    }\n}", "summary_tokens": ["this", "test", "checks", "the", "serialization", "deserialization", "of", "string", "task", "event", "objects"], "project": "flink"}
{"id": 1905, "code": "public int resetErrorStateAndParse(\n        byte[] bytes, int startPos, int limit, byte[] delim, T reuse) {\n    resetParserState();\n    return parseField(bytes, startPos, limit, delim, reuse);\n}", "summary_tokens": ["parses", "the", "value", "of", "a", "field", "from", "the", "byte", "array", "taking", "care", "of", "properly", "reset", "the", "state", "of", "this", "parser"], "project": "flink"}
{"id": 2384, "code": "public URL getResource(String name) {\n    return classLoader.getResource(name);\n}", "summary_tokens": ["get", "the", "url", "for", "the", "named", "resource"], "project": "flink"}
{"id": 4867, "code": "<T extends AutoCloseable> ResourceAndSize<T> getOrAllocateSharedResource(\n        String type,\n        Object leaseHolder,\n        LongFunctionWithException<T, Exception> initializer,\n        long sizeForInitialization)\n        throws Exception {\n\n        \n        \n        \n        \n    try {\n        lock.lockInterruptibly();\n    } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new MemoryAllocationException(\"Interrupted while acquiring memory\");\n    }\n\n    try {\n            \n            \n        @SuppressWarnings(\"unchecked\")\n        LeasedResource<T> resource = (LeasedResource<T>) reservedResources.get(type);\n        if (resource == null) {\n            resource = createResource(initializer, sizeForInitialization);\n            reservedResources.put(type, resource);\n        }\n\n        resource.addLeaseHolder(leaseHolder);\n        return resource;\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["gets", "the", "shared", "memory", "resource", "for", "the", "given", "owner", "and", "registers", "a", "lease"], "project": "flink"}
{"id": 2310, "code": "public Event next(int minIp, int maxIp) {\n    final double p = rnd.nextDouble();\n\n    if (p * 1000 >= states.size()) {\n            \n        final int nextIP = rnd.nextInt(maxIp - minIp) + minIp;\n\n        if (!states.containsKey(nextIP)) {\n            EventTypeAndState eventAndState = State.Initial.randomTransition(rnd);\n            states.put(nextIP, eventAndState.state);\n            return new Event(eventAndState.eventType, nextIP);\n        } else {\n                \n            return next(minIp, maxIp);\n        }\n    } else {\n            \n\n            \n            \n\n        int numToSkip = Math.min(20, rnd.nextInt(states.size()));\n        Iterator<Entry<Integer, State>> iter = states.entrySet().iterator();\n\n        for (int i = numToSkip; i > 0; --i) {\n            iter.next();\n        }\n\n        Entry<Integer, State> entry = iter.next();\n        State currentState = entry.getValue();\n        int address = entry.getKey();\n\n        iter.remove();\n\n        if (p < errorProb) {\n            EventType event = currentState.randomInvalidTransition(rnd);\n            return new Event(event, address);\n        } else {\n            EventTypeAndState eventAndState = currentState.randomTransition(rnd);\n            if (!eventAndState.state.isTerminal()) {\n                    \n                states.put(address, eventAndState.state);\n            }\n\n            return new Event(eventAndState.eventType, address);\n        }\n    }\n}", "summary_tokens": ["creates", "a", "new", "random", "event"], "project": "flink"}
{"id": 576, "code": "default void setPartitions(int[] partitions) {}", "summary_tokens": ["sets", "the", "available", "partitions", "for", "the", "topic", "returned", "from", "get", "target", "topic", "object"], "project": "flink"}
{"id": 6419, "code": "public void testRequirementDeclarationWithoutFreeSlotsTriggersWorkerAllocation()\n        throws Exception {\n    final ResourceRequirements resourceRequirements = createResourceRequirementsForSingleSlot();\n\n    final CompletableFuture<WorkerResourceSpec> allocateResourceFuture =\n            new CompletableFuture<>();\n    new Context() {\n        {\n            resourceActionsBuilder.setAllocateResourceConsumer(\n                    allocateResourceFuture::complete);\n            runTest(\n                    () -> {\n                        runInMainThread(\n                                () ->\n                                        getSlotManager()\n                                                .processResourceRequirements(\n                                                        resourceRequirements));\n\n                        assertFutureCompleteAndReturn(allocateResourceFuture);\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "that", "a", "requirement", "declaration", "with", "no", "free", "slots", "will", "trigger", "the", "resource", "allocation"], "project": "flink"}
{"id": 9132, "code": "public static double log2(double x) {\n    return Math.log(x) / Math.log(2);\n}", "summary_tokens": ["returns", "the", "logarithm", "of", "a", "with", "base", "0"], "project": "flink"}
{"id": 2533, "code": "public void testDeserializePOJO_withValidParams_succeeds() {\n    GlueSchemaRegistryJsonSchemaCoder glueSchemaRegistryJsonSchemaCoder =\n            new GlueSchemaRegistryJsonSchemaCoder(\n                    testTopic, configs, null, mockDeserializationFacadeForSpecific);\n\n    GlueSchemaRegistryJsonDeserializationSchema glueSchemaRegistryJsonDeserializationSchema =\n            new GlueSchemaRegistryJsonDeserializationSchema(\n                    Car.class, glueSchemaRegistryJsonSchemaCoder);\n\n    Object deserializedObject =\n            glueSchemaRegistryJsonDeserializationSchema.deserialize(serializedBytes);\n    assertThat(deserializedObject, instanceOf(Car.class));\n    assertThat(deserializedObject, is(userDefinedPojo));\n}", "summary_tokens": ["test", "whether", "deserialize", "method", "for", "specific", "type", "json", "schema", "data", "works"], "project": "flink"}
{"id": 1516, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple22)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple22 tuple = (Tuple22) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    if (f5 != null ? !f5.equals(tuple.f5) : tuple.f5 != null) {\n        return false;\n    }\n    if (f6 != null ? !f6.equals(tuple.f6) : tuple.f6 != null) {\n        return false;\n    }\n    if (f7 != null ? !f7.equals(tuple.f7) : tuple.f7 != null) {\n        return false;\n    }\n    if (f8 != null ? !f8.equals(tuple.f8) : tuple.f8 != null) {\n        return false;\n    }\n    if (f9 != null ? !f9.equals(tuple.f9) : tuple.f9 != null) {\n        return false;\n    }\n    if (f10 != null ? !f10.equals(tuple.f10) : tuple.f10 != null) {\n        return false;\n    }\n    if (f11 != null ? !f11.equals(tuple.f11) : tuple.f11 != null) {\n        return false;\n    }\n    if (f12 != null ? !f12.equals(tuple.f12) : tuple.f12 != null) {\n        return false;\n    }\n    if (f13 != null ? !f13.equals(tuple.f13) : tuple.f13 != null) {\n        return false;\n    }\n    if (f14 != null ? !f14.equals(tuple.f14) : tuple.f14 != null) {\n        return false;\n    }\n    if (f15 != null ? !f15.equals(tuple.f15) : tuple.f15 != null) {\n        return false;\n    }\n    if (f16 != null ? !f16.equals(tuple.f16) : tuple.f16 != null) {\n        return false;\n    }\n    if (f17 != null ? !f17.equals(tuple.f17) : tuple.f17 != null) {\n        return false;\n    }\n    if (f18 != null ? !f18.equals(tuple.f18) : tuple.f18 != null) {\n        return false;\n    }\n    if (f19 != null ? !f19.equals(tuple.f19) : tuple.f19 != null) {\n        return false;\n    }\n    if (f20 != null ? !f20.equals(tuple.f20) : tuple.f20 != null) {\n        return false;\n    }\n    if (f21 != null ? !f21.equals(tuple.f21) : tuple.f21 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 3386, "code": "private void ensureCapacity(int minCapacity) {\n    long currentCapacity = data.length;\n\n    if (minCapacity <= currentCapacity) {\n        return;\n    }\n\n        \n    long expandedCapacity = Math.max(minCapacity, currentCapacity + (currentCapacity >> 1));\n    int newCapacity = (int) Math.min(MAX_ARRAY_SIZE, expandedCapacity);\n\n    if (newCapacity < minCapacity) {\n            \n        throw new RuntimeException(\n                \"Requested array size \" + minCapacity + \" exceeds limit of \" + MAX_ARRAY_SIZE);\n    }\n\n    data = Arrays.copyOf(data, newCapacity);\n}", "summary_tokens": ["if", "the", "size", "of", "the", "array", "is", "insufficient", "to", "hold", "the", "given", "capacity", "then", "copy", "the", "array", "into", "a", "new", "larger", "array"], "project": "flink"}
{"id": 2091, "code": "public static <T> CompletableFuture<T> retryWithDelay(\n        final Supplier<CompletableFuture<T>> operation,\n        final RetryStrategy retryStrategy,\n        final ScheduledExecutor scheduledExecutor) {\n    return retryWithDelay(operation, retryStrategy, (throwable) -> true, scheduledExecutor);\n}", "summary_tokens": ["retry", "the", "given", "operation", "with", "the", "given", "delay", "in", "between", "failures"], "project": "flink"}
{"id": 5748, "code": "public void releaseAndTryRemoveAll() throws Exception {\n    Collection<String> children = getAllHandles();\n\n    Exception exception = null;\n\n    for (String child : children) {\n        try {\n            releaseAndTryRemove('/' + child);\n        } catch (Exception e) {\n            exception = ExceptionUtils.firstOrSuppressed(e, exception);\n        }\n    }\n\n    if (exception != null) {\n        throw new Exception(\n                \"Could not properly release and try removing all state nodes.\", exception);\n    }\n}", "summary_tokens": ["releases", "all", "lock", "nodes", "of", "this", "zoo", "keeper", "state", "handle", "stores", "and", "tries", "to", "remove", "all", "state", "nodes", "which", "are", "not", "locked", "anymore"], "project": "flink"}
{"id": 9220, "code": "public boolean hasUniqueKey() {\n    return inputSideHasUniqueKey;\n}", "summary_tokens": ["returns", "true", "if", "the", "input", "has", "unique", "key", "otherwise", "false"], "project": "flink"}
{"id": 5915, "code": "public void testStatusValues() throws Exception {\n    CheckpointStatsStatus inProgress = CheckpointStatsStatus.IN_PROGRESS;\n    assertTrue(inProgress.isInProgress());\n    assertFalse(inProgress.isCompleted());\n    assertFalse(inProgress.isFailed());\n\n    CheckpointStatsStatus completed = CheckpointStatsStatus.COMPLETED;\n    assertFalse(completed.isInProgress());\n    assertTrue(completed.isCompleted());\n    assertFalse(completed.isFailed());\n\n    CheckpointStatsStatus failed = CheckpointStatsStatus.FAILED;\n    assertFalse(failed.isInProgress());\n    assertFalse(failed.isCompleted());\n    assertTrue(failed.isFailed());\n}", "summary_tokens": ["tests", "the", "getters", "of", "each", "status"], "project": "flink"}
{"id": 8979, "code": "public static void makeLegacySourceTransformationsBounded(Transformation<?> transformation) {\n    if (transformation instanceof LegacySourceTransformation) {\n        ((LegacySourceTransformation<?>) transformation).setBoundedness(Boundedness.BOUNDED);\n    }\n    transformation.getInputs().forEach(ExecNodeUtil::makeLegacySourceTransformationsBounded);\n}", "summary_tokens": ["the", "planner", "might", "have", "more", "information", "than", "expressed", "in", "legacy", "source", "transformations"], "project": "flink"}
{"id": 5998, "code": "public void testSavepointDisposal() throws Exception {\n    final URI externalPointer = createTestingSavepoint();\n    final Path savepointPath = Paths.get(externalPointer);\n\n    dispatcher =\n            createAndStartDispatcher(\n                    heartbeatServices,\n                    haServices,\n                    new ExpectedJobIdJobManagerRunnerFactory(\n                            jobId, createdJobManagerRunnerLatch));\n\n    final DispatcherGateway dispatcherGateway =\n            dispatcher.getSelfGateway(DispatcherGateway.class);\n\n    assertThat(Files.exists(savepointPath), is(true));\n\n    dispatcherGateway.disposeSavepoint(externalPointer.toString(), TIMEOUT).get();\n\n    assertThat(Files.exists(savepointPath), is(false));\n}", "summary_tokens": ["tests", "that", "we", "can", "dispose", "a", "savepoint"], "project": "flink"}
{"id": 7581, "code": "public ScheduledFuture<?> registerTimer(long timestamp, ProcessingTimeCallback callback) {\n\n    long delay =\n            ProcessingTimeServiceUtil.getProcessingTimeDelay(\n                    timestamp, getCurrentProcessingTime());\n\n        \n        \n    try {\n        return timerService.schedule(\n                wrapOnTimerCallback(callback, timestamp), delay, TimeUnit.MILLISECONDS);\n    } catch (RejectedExecutionException e) {\n        final int status = this.status.get();\n        if (status == STATUS_QUIESCED) {\n            return new NeverCompleteFuture(delay);\n        } else if (status == STATUS_SHUTDOWN) {\n            throw new IllegalStateException(\"Timer service is shut down\");\n        } else {\n                \n            throw e;\n        }\n    }\n}", "summary_tokens": ["registers", "a", "task", "to", "be", "executed", "no", "sooner", "than", "time", "timestamp", "but", "without", "strong", "guarantees", "of", "order"], "project": "flink"}
{"id": 3452, "code": "public <K, T, ACC, R, OUT> DataSet<OUT> aggregate(\n        String uid,\n        AggregateFunction<T, ACC, R> aggregateFunction,\n        WindowReaderFunction<R, OUT, K, W> readerFunction,\n        TypeInformation<K> keyType,\n        TypeInformation<T> inputType,\n        TypeInformation<OUT> outputType)\n        throws IOException {\n\n    WindowReaderOperator<?, K, StreamRecord<T>, W, OUT> operator =\n            WindowReaderOperator.evictingWindow(\n                    new AggregateEvictingWindowReaderFunction<>(\n                            readerFunction, aggregateFunction),\n                    keyType,\n                    windowSerializer,\n                    inputType,\n                    env.getConfig());\n\n    return readWindowOperator(uid, outputType, operator);\n}", "summary_tokens": ["reads", "window", "state", "generated", "using", "an", "aggregate", "function"], "project": "flink"}
{"id": 7425, "code": "public StreamPartitioner<T> getPartitioner() {\n    return partitioner;\n}", "summary_tokens": ["returns", "the", "stream", "partitioner", "that", "must", "be", "used", "for", "partitioning", "the", "elements", "of", "the", "input", "transformation"], "project": "flink"}
{"id": 1374, "code": "public static <E> TypeInformation<List<E>> LIST(TypeInformation<E> elementType) {\n    return new ListTypeInfo<>(elementType);\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "java", "java"], "project": "flink"}
{"id": 7492, "code": "private void processPriorityEvents() throws IOException, InterruptedException {\n        \n        \n    boolean hasPriorityEvent = inputGate.getPriorityEventAvailableFuture().isDone();\n    while (hasPriorityEvent) {\n            \n        final Optional<BufferOrEvent> bufferOrEventOpt = pollNext();\n        if (!bufferOrEventOpt.isPresent()) {\n            break;\n        }\n        final BufferOrEvent bufferOrEvent = bufferOrEventOpt.get();\n        checkState(bufferOrEvent.hasPriority(), \"Should only poll priority events\");\n        hasPriorityEvent = bufferOrEvent.morePriorityEvents();\n    }\n\n        \n    waitForPriorityEvents(inputGate, mailboxExecutor);\n}", "summary_tokens": ["eagerly", "pulls", "and", "processes", "all", "priority", "events"], "project": "flink"}
{"id": 8401, "code": "private static String stringifyValue(Object value) {\n    if (value instanceof String[]) {\n        final String[] array = (String[]) value;\n        return Stream.of(array)\n                .map(ValueLiteralExpression::stringifyValue)\n                .collect(Collectors.joining(\", \", \"[\", \"]\"));\n    } else if (value instanceof Object[]) {\n        final Object[] array = (Object[]) value;\n        return Stream.of(array)\n                .map(ValueLiteralExpression::stringifyValue)\n                .collect(Collectors.joining(\", \", \"[\", \"]\"));\n    } else if (value instanceof String) {\n        return \"'\" + ((String) value).replace(\"'\", \"''\") + \"'\";\n    }\n    return StringUtils.arrayAwareToString(value);\n}", "summary_tokens": ["supports", "nested", "arrays", "and", "makes", "string", "values", "more", "explicit"], "project": "flink"}
{"id": 929, "code": "static <K, V> PulsarDeserializationSchema<KeyValue<K, V>> pulsarSchema(\n        Schema<KeyValue<K, V>> schema, Class<K> keyClass, Class<V> valueClass) {\n    PulsarSchema<KeyValue<K, V>> pulsarSchema =\n            new PulsarSchema<>(schema, keyClass, valueClass);\n    return new PulsarSchemaWrapper<>(pulsarSchema);\n}", "summary_tokens": ["create", "a", "pulsar", "deserialization", "schema", "by", "using", "the", "pulsar", "schema", "instance"], "project": "flink"}
{"id": 9688, "code": "public long getWatermark() {\n    return watermark;\n}", "summary_tokens": ["global", "watermark", "at", "the", "time", "this", "event", "was", "generated"], "project": "flink"}
{"id": 2790, "code": "public TypeInformation<OUT> getResultType() {\n    return getType();\n}", "summary_tokens": ["returns", "the", "type", "of", "the", "result", "of", "this", "operator"], "project": "flink"}
{"id": 4635, "code": "void onConsumedSubpartition(int subpartitionIndex) {\n    decrementNumberOfUsers(subpartitionIndex);\n}", "summary_tokens": ["the", "pipelined", "partition", "releases", "automatically", "once", "all", "subpartition", "readers", "are", "released"], "project": "flink"}
{"id": 4701, "code": "private boolean addPriorityBuffer(SequenceBuffer sequenceBuffer) {\n    receivedBuffers.addPriorityElement(sequenceBuffer);\n    return receivedBuffers.getNumPriorityElements() == 1;\n}", "summary_tokens": ["true", "if", "this", "was", "first", "priority", "buffer", "added"], "project": "flink"}
{"id": 8641, "code": "public static DecimalType findRoundDecimalType(int precision, int scale, int round) {\n    if (round >= scale) {\n        return new DecimalType(false, precision, scale);\n    }\n    if (round < 0) {\n        return new DecimalType(\n                false, Math.min(DecimalType.MAX_PRECISION, 1 + precision - scale), 0);\n    }\n        \n        \n    return new DecimalType(false, 1 + precision - scale + round, round);\n}", "summary_tokens": ["finds", "the", "result", "type", "of", "a", "decimal", "rounding", "operation"], "project": "flink"}
{"id": 3006, "code": "public void testCommandLineClusterSpecification() throws Exception {\n    final Configuration configuration = new Configuration();\n    final int jobManagerMemory = 1337;\n    final int taskManagerMemory = 7331;\n    final int slotsPerTaskManager = 30;\n\n    configuration.set(\n            JobManagerOptions.TOTAL_PROCESS_MEMORY, MemorySize.ofMebiBytes(jobManagerMemory));\n    configuration.set(\n            TaskManagerOptions.TOTAL_PROCESS_MEMORY, MemorySize.ofMebiBytes(taskManagerMemory));\n    configuration.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, slotsPerTaskManager);\n\n    final String[] args = {\n        \"-e\",\n        KubernetesSessionClusterExecutor.NAME,\n        \"-D\" + JobManagerOptions.TOTAL_PROCESS_MEMORY.key() + \"=\" + jobManagerMemory + \"m\",\n        \"-D\" + TaskManagerOptions.TOTAL_PROCESS_MEMORY.key() + \"=\" + taskManagerMemory + \"m\",\n        \"-D\" + TaskManagerOptions.NUM_TASK_SLOTS.key() + \"=\" + slotsPerTaskManager\n    };\n\n    final KubernetesSessionCli cli =\n            new KubernetesSessionCli(configuration, tmp.getRoot().getAbsolutePath());\n\n    Configuration executorConfig = cli.getEffectiveConfiguration(args);\n    ClusterClientFactory<String> clientFactory = getClusterClientFactory(executorConfig);\n    ClusterSpecification clusterSpecification =\n            clientFactory.getClusterSpecification(executorConfig);\n\n    assertThat(clusterSpecification.getMasterMemoryMB(), is(jobManagerMemory));\n    assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(taskManagerMemory));\n    assertThat(clusterSpecification.getSlotsPerTaskManager(), is(slotsPerTaskManager));\n}", "summary_tokens": ["tests", "that", "the", "command", "line", "arguments", "override", "the", "configuration", "settings", "when", "the", "cluster", "specification", "is", "created"], "project": "flink"}
{"id": 3015, "code": "public PatternStream<T> sideOutputLateData(OutputTag<T> lateDataOutputTag) {\n    return new PatternStream<>(builder.withLateDataOutputTag(lateDataOutputTag));\n}", "summary_tokens": ["send", "late", "arriving", "data", "to", "the", "side", "output", "identified", "by", "the", "given", "output", "tag"], "project": "flink"}
{"id": 7640, "code": "public void testResourcesForChainedSourceSink() throws Exception {\n    ResourceSpec resource1 = ResourceSpec.newBuilder(0.1, 100).build();\n    ResourceSpec resource2 = ResourceSpec.newBuilder(0.2, 200).build();\n    ResourceSpec resource3 = ResourceSpec.newBuilder(0.3, 300).build();\n    ResourceSpec resource4 = ResourceSpec.newBuilder(0.4, 400).build();\n    ResourceSpec resource5 = ResourceSpec.newBuilder(0.5, 500).build();\n\n    Method opMethod = getSetResourcesMethodAndSetAccessible(SingleOutputStreamOperator.class);\n    Method sinkMethod = getSetResourcesMethodAndSetAccessible(DataStreamSink.class);\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStream<Tuple2<Integer, Integer>> source =\n            env.addSource(\n                    new ParallelSourceFunction<Tuple2<Integer, Integer>>() {\n                        @Override\n                        public void run(SourceContext<Tuple2<Integer, Integer>> ctx)\n                                throws Exception {}\n\n                        @Override\n                        public void cancel() {}\n                    });\n    opMethod.invoke(source, resource1);\n\n    DataStream<Tuple2<Integer, Integer>> map =\n            source.map(\n                    new MapFunction<Tuple2<Integer, Integer>, Tuple2<Integer, Integer>>() {\n                        @Override\n                        public Tuple2<Integer, Integer> map(Tuple2<Integer, Integer> value)\n                                throws Exception {\n                            return value;\n                        }\n                    });\n    opMethod.invoke(map, resource2);\n\n        \n    DataStream<Tuple2<Integer, Integer>> filter =\n            map.filter(\n                    new FilterFunction<Tuple2<Integer, Integer>>() {\n                        @Override\n                        public boolean filter(Tuple2<Integer, Integer> value) throws Exception {\n                            return false;\n                        }\n                    });\n    opMethod.invoke(filter, resource3);\n\n    DataStream<Tuple2<Integer, Integer>> reduce =\n            filter.keyBy(0)\n                    .reduce(\n                            new ReduceFunction<Tuple2<Integer, Integer>>() {\n                                @Override\n                                public Tuple2<Integer, Integer> reduce(\n                                        Tuple2<Integer, Integer> value1,\n                                        Tuple2<Integer, Integer> value2)\n                                        throws Exception {\n                                    return new Tuple2<>(value1.f0, value1.f1 + value2.f1);\n                                }\n                            });\n    opMethod.invoke(reduce, resource4);\n\n    DataStreamSink<Tuple2<Integer, Integer>> sink =\n            reduce.addSink(\n                    new SinkFunction<Tuple2<Integer, Integer>>() {\n                        @Override\n                        public void invoke(Tuple2<Integer, Integer> value) throws Exception {}\n                    });\n    sinkMethod.invoke(sink, resource5);\n\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\n    JobVertex sourceMapFilterVertex =\n            jobGraph.getVerticesSortedTopologicallyFromSources().get(0);\n    JobVertex reduceSinkVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(1);\n\n    assertTrue(\n            sourceMapFilterVertex\n                    .getMinResources()\n                    .equals(resource3.merge(resource2).merge(resource1)));\n    assertTrue(reduceSinkVertex.getPreferredResources().equals(resource4.merge(resource5)));\n}", "summary_tokens": ["verifies", "that", "the", "resources", "are", "merged", "correctly", "for", "chained", "operators", "covers", "source", "and", "sink", "cases", "when", "generating", "job", "graph"], "project": "flink"}
{"id": 6058, "code": "public void testAssignSlotSharingGroup() {\n    try {\n        JobVertex v1 = new JobVertex(\"v1\");\n        JobVertex v2 = new JobVertex(\"v2\");\n        JobVertex v3 = new JobVertex(\"v3\");\n        JobVertex v4 = new JobVertex(\"v4\");\n        JobVertex v5 = new JobVertex(\"v5\");\n\n        v1.setParallelism(4);\n        v2.setParallelism(5);\n        v3.setParallelism(7);\n        v4.setParallelism(1);\n        v5.setParallelism(11);\n\n        v1.setInvokableClass(AbstractInvokable.class);\n        v2.setInvokableClass(AbstractInvokable.class);\n        v3.setInvokableClass(AbstractInvokable.class);\n        v4.setInvokableClass(AbstractInvokable.class);\n        v5.setInvokableClass(AbstractInvokable.class);\n\n        v2.connectNewDataSetAsInput(\n                v1, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);\n        v5.connectNewDataSetAsInput(\n                v4, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);\n\n        SlotSharingGroup jg1 = new SlotSharingGroup();\n        v2.setSlotSharingGroup(jg1);\n        v3.setSlotSharingGroup(jg1);\n\n        SlotSharingGroup jg2 = new SlotSharingGroup();\n        v4.setSlotSharingGroup(jg2);\n        v5.setSlotSharingGroup(jg2);\n\n        List<JobVertex> vertices = new ArrayList<>(Arrays.asList(v1, v2, v3, v4, v5));\n\n        ExecutionGraph eg =\n                TestingDefaultExecutionGraphBuilder.newBuilder()\n                        .setVertexParallelismStore(\n                                SchedulerBase.computeVertexParallelismStore(vertices))\n                        .build();\n        eg.attachJobGraph(vertices);\n\n            \n        SlotSharingGroup group1;\n        SlotSharingGroup group2;\n\n            \n        assertNotEquals(\n                eg.getJobVertex(v1.getID()).getSlotSharingGroup(),\n                eg.getJobVertex(v2.getID()).getSlotSharingGroup());\n\n            \n        group1 = eg.getJobVertex(v2.getID()).getSlotSharingGroup();\n        assertNotNull(group1);\n        assertEquals(group1, eg.getJobVertex(v3.getID()).getSlotSharingGroup());\n\n        assertEquals(2, group1.getJobVertexIds().size());\n        assertTrue(group1.getJobVertexIds().contains(v2.getID()));\n        assertTrue(group1.getJobVertexIds().contains(v3.getID()));\n\n            \n        group2 = eg.getJobVertex(v4.getID()).getSlotSharingGroup();\n        assertNotNull(group2);\n        assertEquals(group2, eg.getJobVertex(v5.getID()).getSlotSharingGroup());\n\n        assertEquals(2, group1.getJobVertexIds().size());\n        assertTrue(group2.getJobVertexIds().contains(v4.getID()));\n        assertTrue(group2.getJobVertexIds().contains(v5.getID()));\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["test", "setup", "v", "0", "is", "isolated", "no", "slot", "sharing"], "project": "flink"}
{"id": 400, "code": "public HiveParserASTNode getDistributeByForClause(String clause) {\n    return destToDistributeby.get(clause);\n}", "summary_tokens": ["get", "the", "distribute", "by", "ast", "for", "the", "clause"], "project": "flink"}
{"id": 2845, "code": "public long getNonNullCount() {\n    return nonMissingCount + nanCount + infinityCount;\n}", "summary_tokens": ["the", "number", "of", "non", "null", "values", "in", "this", "column"], "project": "flink"}
{"id": 8353, "code": "public static BinaryStringData blankString(int length) {\n    byte[] spaces = new byte[length];\n    Arrays.fill(spaces, (byte) ' ');\n    return fromBytes(spaces);\n}", "summary_tokens": ["creates", "a", "binary", "string", "data", "instance", "that", "contains", "length", "spaces"], "project": "flink"}
{"id": 4798, "code": "public final ClassLoader getUserCodeClassLoader() {\n    return getEnvironment().getUserCodeClassLoader().asClassLoader();\n}", "summary_tokens": ["returns", "the", "user", "code", "class", "loader", "of", "this", "invokable"], "project": "flink"}
{"id": 9288, "code": "public TimeWindow cover(TimeWindow other) {\n    return new TimeWindow(Math.min(start, other.start), Math.max(end, other.end));\n}", "summary_tokens": ["returns", "the", "minimal", "window", "covers", "both", "this", "window", "and", "the", "given", "window"], "project": "flink"}
{"id": 2200, "code": "public void testSlowInputStreamNotClosed() throws Exception {\n    final File file = tempFolder.newFile();\n    createRandomContents(file, new Random(), 50);\n\n    final LimitedConnectionsFileSystem fs =\n            new LimitedConnectionsFileSystem(LocalFileSystem.getSharedInstance(), 1, 0L, 1000L);\n\n        \n    final WriterThread[] threads = new WriterThread[10];\n    for (int i = 0; i < threads.length; i++) {\n        Path path = new Path(tempFolder.newFile().toURI());\n        threads[i] = new WriterThread(fs, path, 1, Integer.MAX_VALUE);\n    }\n\n        \n    try (FSDataInputStream in = fs.open(new Path(file.toURI()))) {\n\n            \n        for (WriterThread t : threads) {\n            t.start();\n        }\n\n            \n        Thread.sleep(5);\n        while (in.read() != -1) {\n            Thread.sleep(5);\n        }\n    }\n\n        \n    for (WriterThread t : threads) {\n        t.sync();\n    }\n}", "summary_tokens": ["tests", "that", "a", "slowly", "read", "stream", "is", "not", "accidentally", "closed", "too", "aggressively", "due", "to", "a", "wrong", "initialization", "of", "the", "timestamps", "or", "bytes", "written", "that", "mark", "when", "the", "last", "progress", "was", "checked"], "project": "flink"}
{"id": 2487, "code": "public static <T extends SpecificRecord> AvroSerializationSchema<T> forSpecific(\n        Class<T> tClass) {\n    return new AvroSerializationSchema<>(tClass, null);\n}", "summary_tokens": ["creates", "avro", "serialization", "schema", "that", "serializes", "specific", "record", "using", "provided", "schema"], "project": "flink"}
{"id": 1319, "code": "public TypeInformation<T> getProducedType() {\n    return type;\n}", "summary_tokens": ["gets", "the", "type", "produced", "by", "this", "deserializer"], "project": "flink"}
{"id": 4905, "code": "public static ScopeFormats fromConfig(Configuration config) {\n    String jmFormat = config.getString(MetricOptions.SCOPE_NAMING_JM);\n    String jmJobFormat = config.getString(MetricOptions.SCOPE_NAMING_JM_JOB);\n    String tmFormat = config.getString(MetricOptions.SCOPE_NAMING_TM);\n    String tmJobFormat = config.getString(MetricOptions.SCOPE_NAMING_TM_JOB);\n    String taskFormat = config.getString(MetricOptions.SCOPE_NAMING_TASK);\n    String operatorFormat = config.getString(MetricOptions.SCOPE_NAMING_OPERATOR);\n\n    return new ScopeFormats(\n            jmFormat, jmJobFormat, tmFormat, tmJobFormat, taskFormat, operatorFormat);\n}", "summary_tokens": ["creates", "the", "scope", "formats", "as", "defined", "in", "the", "given", "configuration"], "project": "flink"}
{"id": 3841, "code": "public ArrowFieldWriter<IN>[] getFieldWriters() {\n    return fieldWriters;\n}", "summary_tokens": ["gets", "the", "field", "writers"], "project": "flink"}
{"id": 3641, "code": "protected final boolean mergeLists(\n        List<UnclosedBranchDescriptor> child1open,\n        List<UnclosedBranchDescriptor> child2open,\n        List<UnclosedBranchDescriptor> result,\n        boolean markJoinedBranchesAsPipelineBreaking) {\n\n        \n    removeClosedBranches(child1open);\n    removeClosedBranches(child2open);\n\n    result.clear();\n\n        \n        \n        \n        \n    if (child1open == null || child1open.isEmpty()) {\n        if (child2open != null && !child2open.isEmpty()) {\n            result.addAll(child2open);\n        }\n        return false;\n    }\n\n    if (child2open == null || child2open.isEmpty()) {\n        result.addAll(child1open);\n        return false;\n    }\n\n    int index1 = child1open.size() - 1;\n    int index2 = child2open.size() - 1;\n\n    boolean didCloseABranch = false;\n\n        \n        \n        \n    while (index1 >= 0 || index2 >= 0) {\n        int id1 = -1;\n        int id2 = index2 >= 0 ? child2open.get(index2).getBranchingNode().getId() : -1;\n\n        while (index1 >= 0 && (id1 = child1open.get(index1).getBranchingNode().getId()) > id2) {\n            result.add(child1open.get(index1));\n            index1--;\n        }\n        while (index2 >= 0 && (id2 = child2open.get(index2).getBranchingNode().getId()) > id1) {\n            result.add(child2open.get(index2));\n            index2--;\n        }\n\n            \n        if (id1 == id2) {\n            didCloseABranch = true;\n\n                \n            OptimizerNode currBanchingNode = child1open.get(index1).getBranchingNode();\n\n            long vector1 = child1open.get(index1).getJoinedPathsVector();\n            long vector2 = child2open.get(index2).getJoinedPathsVector();\n\n                \n                \n            if (vector1 == vector2) {\n                result.add(child1open.get(index1));\n            } else {\n                    \n\n                    \n                if (markJoinedBranchesAsPipelineBreaking) {\n                    currBanchingNode.markAllOutgoingConnectionsAsPipelineBreaking();\n                }\n\n                if (this.hereJoinedBranches == null) {\n                    this.hereJoinedBranches = new ArrayList<OptimizerNode>(2);\n                }\n                this.hereJoinedBranches.add(currBanchingNode);\n\n                    \n                long joinedInputs = vector1 | vector2;\n\n                    \n                long allInputs = (0x1L << currBanchingNode.getOutgoingConnections().size()) - 1;\n\n                if (joinedInputs == allInputs) {\n                        \n                    addClosedBranch(currBanchingNode);\n                } else {\n                        \n                    result.add(new UnclosedBranchDescriptor(currBanchingNode, joinedInputs));\n                }\n            }\n\n            index1--;\n            index2--;\n        }\n    }\n\n        \n    Collections.reverse(result);\n    return didCloseABranch;\n}", "summary_tokens": ["the", "node", "ids", "are", "assigned", "in", "graph", "traversal", "order", "pre", "order", "hence", "each", "list", "is", "sorted", "by", "id", "in", "ascending", "order", "and", "all", "consecutive", "lists", "start", "with", "ids", "in", "ascending", "order"], "project": "flink"}
{"id": 7535, "code": "protected boolean isElementLate(StreamRecord<IN> element) {\n    return (windowAssigner.isEventTime())\n            && (element.getTimestamp() + allowedLateness\n                    <= internalTimerService.currentWatermark());\n}", "summary_tokens": ["decide", "if", "a", "record", "is", "currently", "late", "based", "on", "current", "watermark", "and", "allowed", "lateness"], "project": "flink"}
{"id": 9136, "code": "public static String replace(String str, String oldStr, String replacement) {\n    return str.replace(oldStr, replacement);\n}", "summary_tokens": ["replaces", "all", "the", "old", "strings", "with", "the", "replacement", "string"], "project": "flink"}
{"id": 1163, "code": "public Charset getCharset() {\n    if (this.charset == null) {\n        this.charset = Charset.forName(charsetName);\n    }\n    return this.charset;\n}", "summary_tokens": ["get", "the", "character", "set", "used", "for", "the", "row", "delimiter"], "project": "flink"}
{"id": 9654, "code": "public void testTimestampExtractorWithAutoInterval() throws Exception {\n    final int numElements = 10;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    env.getConfig().setAutoWatermarkInterval(10);\n    env.setParallelism(1);\n\n    DataStream<Integer> source1 =\n            env.addSource(\n                    new SourceFunction<Integer>() {\n                        @Override\n                        public void run(SourceContext<Integer> ctx) throws Exception {\n                            int index = 1;\n                            while (index <= numElements) {\n                                ctx.collect(index);\n                                latch.await();\n                                index++;\n                            }\n                        }\n\n                        @Override\n                        public void cancel() {}\n                    });\n\n    DataStream<Integer> extractOp =\n            source1.assignTimestampsAndWatermarks(\n                    new AscendingTimestampExtractor<Integer>() {\n                        @Override\n                        public long extractAscendingTimestamp(Integer element) {\n                            return element;\n                        }\n                    });\n\n    extractOp\n            .transform(\"Watermark Check\", BasicTypeInfo.INT_TYPE_INFO, new CustomOperator(true))\n            .transform(\n                    \"Timestamp Check\",\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    new TimestampCheckingOperator());\n\n        \n    Assert.assertEquals(\n            extractOp.getTransformation().getParallelism(),\n            source1.getTransformation().getParallelism());\n\n    env.execute();\n\n        \n    for (int j = 0; j < numElements; j++) {\n        if (!CustomOperator.finalWatermarks[0].get(j).equals(new Watermark(j))) {\n            long wm = CustomOperator.finalWatermarks[0].get(j).getTimestamp();\n            Assert.fail(\n                    \"Wrong watermark. Expected: \"\n                            + j\n                            + \" Found: \"\n                            + wm\n                            + \" All: \"\n                            + CustomOperator.finalWatermarks[0]);\n        }\n    }\n\n        \n    assertEquals(\n            Watermark.MAX_WATERMARK,\n            CustomOperator.finalWatermarks[0].get(\n                    CustomOperator.finalWatermarks[0].size() - 1));\n}", "summary_tokens": ["this", "tests", "whether", "timestamps", "are", "properly", "extracted", "in", "the", "timestamp", "extractor", "and", "whether", "watermarks", "are", "also", "correctly", "forwarded", "from", "this", "with", "the", "auto", "watermark", "interval"], "project": "flink"}
{"id": 4519, "code": "public String[] getSpillingDirectoriesPaths() {\n    File[] paths = fileChannelManager.getPaths();\n    String[] strings = new String[paths.length];\n    for (int i = 0; i < strings.length; i++) {\n        strings[i] = paths[i].getAbsolutePath();\n    }\n    return strings;\n}", "summary_tokens": ["gets", "the", "directories", "that", "the", "i", "o", "manager", "spills", "to", "as", "path", "strings"], "project": "flink"}
{"id": 2552, "code": "private static void validateDecodingFormatOptions(ReadableConfig tableOptions) {\n    JsonFormatOptionsUtil.validateDecodingFormatOptions(tableOptions);\n}", "summary_tokens": ["validator", "for", "maxwell", "decoding", "format"], "project": "flink"}
{"id": 8213, "code": "default boolean supportsManagedTable() {\n    return false;\n}", "summary_tokens": ["if", "true", "tables", "which", "do", "not", "specify", "a", "connector", "will", "be", "translated", "to", "managed", "tables"], "project": "flink"}
{"id": 7417, "code": "public void setStateKeySelector(KeySelector<T, ?> stateKeySelector) {\n    this.stateKeySelector = stateKeySelector;\n    updateManagedMemoryStateBackendUseCase(stateKeySelector != null);\n}", "summary_tokens": ["sets", "the", "key", "selector", "that", "must", "be", "used", "for", "partitioning", "keyed", "state", "of", "this", "sink"], "project": "flink"}
{"id": 9069, "code": "public static synchronized DiffRepository lookup(\n        Class clazz, DiffRepository baseRepository, Filter filter) {\n    DiffRepository diffRepository = MAP_CLASS_TO_REPOSITORY.get(clazz);\n    if (diffRepository == null) {\n        final URL refFile = findFile(clazz, \".xml\");\n        final File logFile = new File(refFile.getFile().replace(\"test-classes\", \"surefire\"));\n        diffRepository = new DiffRepository(refFile, logFile, baseRepository, filter);\n        MAP_CLASS_TO_REPOSITORY.put(clazz, diffRepository);\n    }\n    return diffRepository;\n}", "summary_tokens": ["finds", "the", "repository", "instance", "for", "a", "given", "class"], "project": "flink"}
{"id": 9556, "code": "public void batchFailoverWithRescaleBarrier() throws Exception {\n\n    final StreamExecutionEnvironment env = getExecutionEnvironment();\n\n    DataStreamSource<String> source = env.fromElements(\"foo\", \"bar\");\n    env.setParallelism(1);\n\n    SingleOutputStreamOperator<String> mapped =\n            source.map(new SuffixAttemptId(\"a\"))\n                    .map(new SuffixAttemptId(\"b\"))\n                    .rescale()\n                    .map(new SuffixAttemptId(\"c\"))\n                    .setParallelism(2)\n                    .map(new OnceFailingMapper(\"d\"))\n                    .setParallelism(2);\n\n    try (CloseableIterator<String> result = mapped.executeAndCollect()) {\n\n            \n            \n        assertThat(\n                iteratorToList(result),\n                containsInAnyOrder(\"foo-a0-b0-c1-d1\", \"bar-a0-b0-c1-d1\"));\n    }\n}", "summary_tokens": ["we", "induce", "a", "failure", "in", "the", "last", "mapper"], "project": "flink"}
{"id": 3368, "code": "public List<Tuple2<String, DataSet<?>>> getGatherBcastVars() {\n    return this.bcVarsGather;\n}", "summary_tokens": ["get", "the", "broadcast", "variables", "of", "the", "gather", "function"], "project": "flink"}
{"id": 8240, "code": "public Optional<UniqueConstraint> getPrimaryKey() {\n    return Optional.ofNullable(primaryKey);\n}", "summary_tokens": ["returns", "the", "primary", "key", "if", "it", "has", "been", "defined"], "project": "flink"}
{"id": 6080, "code": "public void testOneComponentInstanceFromOneSource() {\n    TestingSchedulingTopology topology = new TestingSchedulingTopology();\n\n    TestingSchedulingExecutionVertex v1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v2 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v3 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v4 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v5 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v6 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v7 = topology.newExecutionVertex();\n\n    topology.connect(v1, v2, ResultPartitionType.PIPELINED)\n            .connect(v1, v3, ResultPartitionType.PIPELINED)\n            .connect(v2, v4, ResultPartitionType.PIPELINED)\n            .connect(v2, v5, ResultPartitionType.PIPELINED)\n            .connect(v3, v6, ResultPartitionType.PIPELINED)\n            .connect(v3, v7, ResultPartitionType.PIPELINED);\n\n    Map<ExecutionVertexID, Set<SchedulingExecutionVertex>> pipelinedRegionByVertex =\n            computePipelinedRegionByVertex(topology);\n\n    Set<SchedulingExecutionVertex> r1 = pipelinedRegionByVertex.get(v1.getId());\n    Set<SchedulingExecutionVertex> r2 = pipelinedRegionByVertex.get(v2.getId());\n    Set<SchedulingExecutionVertex> r3 = pipelinedRegionByVertex.get(v3.getId());\n    Set<SchedulingExecutionVertex> r4 = pipelinedRegionByVertex.get(v4.getId());\n    Set<SchedulingExecutionVertex> r5 = pipelinedRegionByVertex.get(v5.getId());\n    Set<SchedulingExecutionVertex> r6 = pipelinedRegionByVertex.get(v6.getId());\n    Set<SchedulingExecutionVertex> r7 = pipelinedRegionByVertex.get(v7.getId());\n\n    assertSameRegion(r1, r2, r3, r4, r5, r6, r7);\n}", "summary_tokens": ["tests", "that", "validates", "that", "a", "single", "pipelined", "component", "instance", "from", "one", "source", "works", "correctly"], "project": "flink"}
{"id": 38, "code": "private static void printCustomCliOptions(\n        Collection<CustomCommandLine> customCommandLines,\n        HelpFormatter formatter,\n        boolean runOptions) {\n        \n    for (CustomCommandLine cli : customCommandLines) {\n        formatter.setSyntaxPrefix(\"  Options for \" + cli.getId() + \" mode:\");\n        Options customOpts = new Options();\n        cli.addGeneralOptions(customOpts);\n        if (runOptions) {\n            cli.addRunOptions(customOpts);\n        }\n        formatter.printHelp(\" \", customOpts);\n        System.out.println();\n    }\n}", "summary_tokens": ["prints", "custom", "cli", "options"], "project": "flink"}
{"id": 8463, "code": "public static <T, ACC> TypeInformation<ACC> getAccumulatorTypeOfAggregateFunction(\n        ImperativeAggregateFunction<T, ACC> aggregateFunction, TypeInformation<ACC> scalaType) {\n\n    TypeInformation<ACC> userProvidedType = aggregateFunction.getAccumulatorType();\n    if (userProvidedType != null) {\n        return userProvidedType;\n    } else if (scalaType != null) {\n        return scalaType;\n    } else {\n        return TypeExtractor.createTypeInfo(\n                aggregateFunction,\n                ImperativeAggregateFunction.class,\n                aggregateFunction.getClass(),\n                1);\n    }\n}", "summary_tokens": ["tries", "to", "infer", "the", "type", "information", "of", "an", "aggregate", "function", "s", "accumulator", "type"], "project": "flink"}
{"id": 4658, "code": "public void finish() throws IOException {\n    checkInProduceState();\n\n    isFinished = true;\n}", "summary_tokens": ["finishes", "the", "result", "partition"], "project": "flink"}
{"id": 2909, "code": "public void checkRead() throws Exception {\n    BinaryInputFormat<T> input = this.createInputFormat();\n    FileInputSplit[] inputSplits = input.createInputSplits(0);\n    Arrays.sort(inputSplits, new InputSplitSorter());\n\n    int readCount = 0;\n\n    for (FileInputSplit inputSplit : inputSplits) {\n        input.open(inputSplit);\n        input.reopen(inputSplit, input.getCurrentState());\n\n        T record = createInstance();\n\n        while (!input.reachedEnd()) {\n            if (input.nextRecord(record) != null) {\n                this.checkEquals(this.getRecord(readCount), record);\n\n                if (!input.reachedEnd()) {\n                    Tuple2<Long, Long> state = input.getCurrentState();\n\n                    input = this.createInputFormat();\n                    input.reopen(inputSplit, state);\n                }\n                readCount++;\n            }\n        }\n    }\n    Assert.assertEquals(this.numberOfTuples, readCount);\n}", "summary_tokens": ["tests", "if", "the", "expected", "sequence", "and", "amount", "of", "data", "can", "be", "read"], "project": "flink"}
{"id": 2246, "code": "public void triggerNonPeriodicScheduledTask() {\n    execService.triggerNonPeriodicScheduledTask();\n}", "summary_tokens": ["triggers", "a", "single", "non", "periodically", "scheduled", "task"], "project": "flink"}
{"id": 8743, "code": "public SqlGroupedWindowFunction auxiliary(String name, SqlKind kind) {\n    switch (kind) {\n        case TUMBLE_START:\n        case TUMBLE_END:\n        case HOP_START:\n        case HOP_END:\n        case SESSION_START:\n        case SESSION_END:\n            return new SqlGroupedWindowFunction(\n                    name,\n                    kind,\n                    this,\n                    windowStartEndInf,\n                    null,\n                    getOperandTypeChecker(),\n                    SqlFunctionCategory.SYSTEM);\n        default:\n            return new SqlGroupedWindowFunction(\n                    name,\n                    kind,\n                    this,\n                    ReturnTypes.ARG0,\n                    null,\n                    getOperandTypeChecker(),\n                    SqlFunctionCategory.SYSTEM);\n    }\n}", "summary_tokens": ["creates", "an", "auxiliary", "function", "from", "this", "grouped", "window", "function"], "project": "flink"}
{"id": 580, "code": "public static OffsetCommitMode fromConfiguration(\n        boolean enableAutoCommit,\n        boolean enableCommitOnCheckpoint,\n        boolean enableCheckpointing) {\n\n    if (enableCheckpointing) {\n            \n            \n        return (enableCommitOnCheckpoint)\n                ? OffsetCommitMode.ON_CHECKPOINTS\n                : OffsetCommitMode.DISABLED;\n    } else {\n            \n            \n        return (enableAutoCommit) ? OffsetCommitMode.KAFKA_PERIODIC : OffsetCommitMode.DISABLED;\n    }\n}", "summary_tokens": ["determine", "the", "offset", "commit", "mode", "using", "several", "configuration", "values"], "project": "flink"}
{"id": 802, "code": "public double getDescribeStreamConsumerExpConstant() {\n    return describeStreamConsumerExpConstant;\n}", "summary_tokens": ["get", "exponential", "backoff", "power", "constant", "for", "the", "describe", "stream", "operation"], "project": "flink"}
{"id": 6336, "code": "public void testDuplicateGroupName() throws Exception {\n    Configuration config = new Configuration();\n\n    MetricRegistryImpl registry =\n            new MetricRegistryImpl(MetricRegistryTestUtils.fromConfiguration(config));\n\n    MetricGroup root =\n            TaskManagerMetricGroup.createTaskManagerMetricGroup(\n                    registry, \"host\", new ResourceID(\"id\"));\n\n    MetricGroup group1 = root.addGroup(\"group\");\n    MetricGroup group2 = root.addGroup(\"group\");\n    MetricGroup group3 = root.addGroup(\"group\");\n    Assert.assertTrue(group1 == group2 && group2 == group3);\n\n    registry.shutdown().get();\n}", "summary_tokens": ["verifies", "that", "when", "attempting", "to", "create", "a", "group", "with", "the", "name", "of", "an", "existing", "one", "the", "existing", "one", "will", "be", "returned", "instead"], "project": "flink"}
{"id": 514, "code": "public KafkaSourceBuilder<OUT> setGroupId(String groupId) {\n    return setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n}", "summary_tokens": ["sets", "the", "consumer", "group", "id", "of", "the", "kafka", "source"], "project": "flink"}
{"id": 8125, "code": "public List<String> listModules() {\n    return new ArrayList<>(usedModules);\n}", "summary_tokens": ["get", "names", "of", "all", "used", "modules", "in", "resolution", "order"], "project": "flink"}
{"id": 5347, "code": "public void dispose() {\n\n    IOUtils.closeQuietly(cancelStreamRegistry);\n\n    if (kvStateRegistry != null) {\n        kvStateRegistry.unregisterAll();\n    }\n\n    lastName = null;\n    lastState = null;\n    keyValueStatesByName.clear();\n}", "summary_tokens": ["closes", "the", "state", "backend", "releasing", "all", "internal", "resources", "but", "does", "not", "delete", "any", "persistent", "checkpoint", "data"], "project": "flink"}
{"id": 606, "code": "public void resumeTransaction(long producerId, short epoch) {\n    synchronized (producerClosingLock) {\n        ensureNotClosed();\n        Preconditions.checkState(\n                producerId >= 0 && epoch >= 0,\n                \"Incorrect values for producerId %s and epoch %s\",\n                producerId,\n                epoch);\n        LOG.info(\n                \"Attempting to resume transaction {} with producerId {} and epoch {}\",\n                transactionalId,\n                producerId,\n                epoch);\n\n        Object transactionManager = getField(kafkaProducer, \"transactionManager\");\n        synchronized (transactionManager) {\n            Object topicPartitionBookkeeper =\n                    getField(transactionManager, \"topicPartitionBookkeeper\");\n\n            invoke(\n                    transactionManager,\n                    \"transitionTo\",\n                    getEnum(\n                            \"org.apache.kafka.clients.producer.internals.TransactionManager$State.INITIALIZING\"));\n            invoke(topicPartitionBookkeeper, \"reset\");\n\n            setField(\n                    transactionManager,\n                    \"producerIdAndEpoch\",\n                    createProducerIdAndEpoch(producerId, epoch));\n\n            invoke(\n                    transactionManager,\n                    \"transitionTo\",\n                    getEnum(\n                            \"org.apache.kafka.clients.producer.internals.TransactionManager$State.READY\"));\n\n            invoke(\n                    transactionManager,\n                    \"transitionTo\",\n                    getEnum(\n                            \"org.apache.kafka.clients.producer.internals.TransactionManager$State.IN_TRANSACTION\"));\n            setField(transactionManager, \"transactionStarted\", true);\n        }\n    }\n}", "summary_tokens": ["instead", "of", "obtaining", "producer", "id", "and", "epoch", "from", "the", "transaction", "coordinator", "re", "use", "previously", "obtained", "ones", "so", "that", "we", "can", "resume", "transaction", "after", "a", "restart"], "project": "flink"}
{"id": 8613, "code": "public boolean is(LogicalTypeFamily family) {\n    return typeRoot.getFamilies().contains(family);\n}", "summary_tokens": ["returns", "whether", "the", "family", "type", "of", "the", "type", "equals", "to", "the", "family", "or", "not"], "project": "flink"}
{"id": 5305, "code": "public static RootExceptionHistoryEntry fromGlobalFailure(ErrorInfo errorInfo) {\n    Preconditions.checkNotNull(errorInfo, \"errorInfo\");\n    return fromGlobalFailure(\n            errorInfo.getException(), errorInfo.getTimestamp(), Collections.emptyList());\n}", "summary_tokens": ["creates", "a", "root", "exception", "history", "entry", "based", "on", "the", "passed", "error", "info"], "project": "flink"}
{"id": 5891, "code": "public void testMinTimeBetweenCheckpointsInterval() throws Exception {\n    JobVertexID jobVertexID = new JobVertexID();\n\n    CheckpointCoordinatorTestingUtils.CheckpointRecorderTaskManagerGateway gateway =\n            new CheckpointCoordinatorTestingUtils.CheckpointRecorderTaskManagerGateway();\n\n    ExecutionGraph graph =\n            new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                    .addJobVertex(jobVertexID)\n                    .setTaskManagerGateway(gateway)\n                    .build();\n\n    ExecutionVertex vertex = graph.getJobVertex(jobVertexID).getTaskVertices()[0];\n    ExecutionAttemptID attemptID = vertex.getCurrentExecutionAttempt().getAttemptId();\n\n    final long delay = 50;\n    final long checkpointInterval = 12;\n\n    CheckpointCoordinatorConfiguration checkpointCoordinatorConfiguration =\n            new CheckpointCoordinatorConfigurationBuilder()\n                    .setCheckpointInterval(checkpointInterval) \n                    .setCheckpointTimeout(200_000) \n                    .setMinPauseBetweenCheckpoints(delay) \n                    .setMaxConcurrentCheckpoints(1)\n                    .build();\n    final CheckpointCoordinator checkpointCoordinator =\n            new CheckpointCoordinatorBuilder()\n                    .setExecutionGraph(graph)\n                    .setCheckpointCoordinatorConfiguration(checkpointCoordinatorConfiguration)\n                    .setCompletedCheckpointStore(new StandaloneCompletedCheckpointStore(2))\n                    .setTimer(manuallyTriggeredScheduledExecutor)\n                    .build();\n\n    try {\n        checkpointCoordinator.startCheckpointScheduler();\n        manuallyTriggeredScheduledExecutor.triggerPeriodicScheduledTasks();\n        manuallyTriggeredScheduledExecutor.triggerAll();\n\n            \n        Long firstCallId = gateway.getTriggeredCheckpoints(attemptID).get(0).checkpointId;\n        assertEquals(1L, firstCallId.longValue());\n\n        AcknowledgeCheckpoint ackMsg =\n                new AcknowledgeCheckpoint(graph.getJobID(), attemptID, 1L);\n\n            \n        final long ackTime = System.nanoTime();\n        checkpointCoordinator.receiveAcknowledgeMessage(ackMsg, TASK_MANAGER_LOCATION_INFO);\n\n        gateway.resetCount();\n        manuallyTriggeredScheduledExecutor.triggerPeriodicScheduledTasks();\n        manuallyTriggeredScheduledExecutor.triggerAll();\n        while (gateway.getTriggeredCheckpoints(attemptID).isEmpty()) {\n                \n            Thread.sleep(checkpointInterval);\n            manuallyTriggeredScheduledExecutor.triggerPeriodicScheduledTasks();\n            manuallyTriggeredScheduledExecutor.triggerAll();\n        }\n            \n        Long nextCallId = gateway.getTriggeredCheckpoints(attemptID).get(0).checkpointId;\n        final long nextCheckpointTime = System.nanoTime();\n        assertEquals(2L, nextCallId.longValue());\n\n        final long delayMillis = (nextCheckpointTime - ackTime) / 1_000_000;\n\n            \n        if (delayMillis + 1 < delay) {\n            fail(\n                    \"checkpoint came too early: delay was \"\n                            + delayMillis\n                            + \" but should have been at least \"\n                            + delay);\n        }\n    } finally {\n        checkpointCoordinator.stopCheckpointScheduler();\n        checkpointCoordinator.shutdown();\n    }\n}", "summary_tokens": ["this", "test", "verified", "that", "after", "a", "completed", "checkpoint", "a", "certain", "time", "has", "passed", "before", "another", "is", "triggered"], "project": "flink"}
{"id": 2280, "code": "public FlinkContainersBuilder setLogProperty(String key, String value) {\n    this.logProperties.setProperty(key, value);\n    return this;\n}", "summary_tokens": ["sets", "log", "0", "j", "property"], "project": "flink"}
{"id": 7953, "code": "public SqlNodeList getTableHints() {\n    return this.tableHints;\n}", "summary_tokens": ["returns", "the", "table", "hints", "as", "list", "of", "sql", "node", "for", "current", "insert", "node"], "project": "flink"}
{"id": 8352, "code": "public static BinaryStringData fromBytes(byte[] bytes, int offset, int numBytes) {\n    return new BinaryStringData(\n            new MemorySegment[] {MemorySegmentFactory.wrap(bytes)}, offset, numBytes);\n}", "summary_tokens": ["creates", "a", "binary", "string", "data", "instance", "from", "the", "given", "utf", "0", "bytes", "with", "offset", "and", "number", "of", "bytes"], "project": "flink"}
{"id": 2409, "code": "public org.apache.hadoop.fs.FileSystem getHadoopFileSystem() {\n    return this.fs;\n}", "summary_tokens": ["gets", "the", "underlying", "hadoop", "file", "system"], "project": "flink"}
{"id": 3127, "code": "public Runner run() throws Exception {\n        \n    env = ExecutionEnvironment.getExecutionEnvironment();\n    ExecutionConfig config = env.getConfig();\n\n        \n    config.disableForceAvro();\n    config.disableForceKryo();\n\n    config.setGlobalJobParameters(parameters);\n    parameterize(this);\n\n        \n    try {\n        this.configure(parameters);\n    } catch (RuntimeException ex) {\n        throw new ProgramParametrizationException(ex.getMessage());\n    }\n\n        \n    if (disableObjectReuse.getValue()) {\n        config.disableObjectReuse();\n    } else {\n        config.enableObjectReuse();\n    }\n\n        \n        \n        \n\n        \n    if (!parameters.has(ALGORITHM)) {\n        throw new ProgramParametrizationException(getAlgorithmsListing());\n    }\n\n    String algorithmName = parameters.get(ALGORITHM);\n    algorithm = driverFactory.get(algorithmName);\n\n    if (algorithm == null) {\n        throw new ProgramParametrizationException(\"Unknown algorithm name: \" + algorithmName);\n    }\n\n        \n    if (!parameters.has(INPUT)) {\n        if (!parameters.has(OUTPUT)) {\n                \n            throw new ProgramParametrizationException(getAlgorithmUsage(algorithmName));\n        }\n        throw new ProgramParametrizationException(\"No input given\");\n    }\n\n    parameterize(algorithm);\n\n    String inputName = parameters.get(INPUT);\n    Input input = inputFactory.get(inputName);\n\n    if (input == null) {\n        throw new ProgramParametrizationException(\"Unknown input type: \" + inputName);\n    }\n\n    parameterize(input);\n\n        \n    if (!parameters.has(OUTPUT)) {\n        throw new ProgramParametrizationException(\"No output given\");\n    }\n\n    String outputName = parameters.get(OUTPUT);\n    output = outputFactory.get(outputName);\n\n    if (output == null) {\n        throw new ProgramParametrizationException(\"Unknown output type: \" + outputName);\n    }\n\n    parameterize(output);\n\n        \n        \n        \n\n    List<Transform> transforms = new ArrayList<>();\n\n    if (input instanceof Transformable) {\n        transforms.addAll(((Transformable) input).getTransformers());\n    }\n\n    if (algorithm instanceof Transformable) {\n        transforms.addAll(((Transformable) algorithm).getTransformers());\n    }\n\n    for (Transform transform : transforms) {\n        parameterize(transform);\n    }\n\n        \n    if (parameters.getUnrequestedParameters().size() > 0) {\n        throw new ProgramParametrizationException(\n                \"Unrequested parameters: \" + parameters.getUnrequestedParameters());\n    }\n\n        \n        \n        \n\n        \n    Graph graph = input.create(env);\n\n        \n    for (Transform transform : transforms) {\n        graph = (Graph) transform.transformInput(graph);\n    }\n\n        \n    result = algorithm.plan(graph);\n\n        \n    executionName = jobName.getValue() != null ? jobName.getValue() + \": \" : \"\";\n\n    executionName += input.getIdentity() + \" \u21e8 \" + algorithmName + \" \u21e8 \" + output.getName();\n\n    if (transforms.size() > 0) {\n            \n        StringBuffer buffer = new StringBuffer(executionName).append(\" [\");\n\n        for (Transform transform : transforms) {\n            buffer.append(transform.getIdentity());\n        }\n\n        executionName = buffer.append(\"]\").toString();\n    }\n\n    if (output == null) {\n        throw new ProgramParametrizationException(\"Unknown output type: \" + outputName);\n    }\n\n    try {\n        output.configure(parameters);\n    } catch (RuntimeException ex) {\n        throw new ProgramParametrizationException(ex.getMessage());\n    }\n\n    if (result != null) {\n            \n        if (transforms.size() > 0) {\n            Collections.reverse(transforms);\n            for (Transform transform : transforms) {\n                result = (DataSet) transform.transformResult(result);\n            }\n        }\n    }\n\n    return this;\n}", "summary_tokens": ["setup", "the", "flink", "job", "with", "the", "graph", "input", "algorithm", "and", "output"], "project": "flink"}
{"id": 4985, "code": "public int spillPartition(\n        List<MemorySegment> target,\n        IOManager ioAccess,\n        FileIOChannel.ID targetChannel,\n        LinkedBlockingQueue<MemorySegment> bufferReturnQueue)\n        throws IOException {\n        \n    if (!isInMemory()) {\n        throw new RuntimeException(\n                \"Bug in Hybrid Hash Join: \"\n                        + \"Request to spill a partition that has already been spilled.\");\n    }\n    if (getNumOccupiedMemorySegments() < 2) {\n        throw new RuntimeException(\n                \"Bug in Hybrid Hash Join: \"\n                        + \"Request to spill a partition with less than two buffers.\");\n    }\n\n        \n    for (int i = 0; i < this.numOverflowSegments; i++) {\n        target.add(this.overflowSegments[i]);\n    }\n    this.overflowSegments = null;\n    this.numOverflowSegments = 0;\n    this.nextOverflowBucket = 0;\n\n        \n        \n        \n    this.buildSideChannel = ioAccess.createBlockChannelWriter(targetChannel, bufferReturnQueue);\n    return this.buildSideWriteBuffer.spill(this.buildSideChannel);\n}", "summary_tokens": ["spills", "this", "partition", "to", "disk", "and", "sets", "it", "up", "such", "that", "it", "continues", "spilling", "records", "that", "are", "added", "to", "it"], "project": "flink"}
{"id": 6355, "code": "public void testRESTServerSSL() throws Exception {\n    Configuration serverConfig = createRestSslConfigWithKeyStore();\n\n    SSLHandlerFactory ssl = SSLUtils.createRestServerSSLEngineFactory(serverConfig);\n    assertNotNull(ssl);\n}", "summary_tokens": ["tests", "that", "rest", "server", "ssl", "engine", "is", "created", "given", "a", "valid", "ssl", "configuration"], "project": "flink"}
{"id": 1820, "code": "static ByteBuffer wrapUnsafeMemoryWithByteBuffer(long address, int size) {\n        \n    try {\n        ByteBuffer buffer = (ByteBuffer) UNSAFE.allocateInstance(DIRECT_BYTE_BUFFER_CLASS);\n        UNSAFE.putLong(buffer, BUFFER_ADDRESS_FIELD_OFFSET, address);\n        UNSAFE.putInt(buffer, BUFFER_CAPACITY_FIELD_OFFSET, size);\n        buffer.clear();\n        return buffer;\n    } catch (Throwable t) {\n        throw new Error(\"Failed to wrap unsafe off-heap memory with ByteBuffer\", t);\n    }\n}", "summary_tokens": ["wraps", "the", "unsafe", "native", "memory", "with", "a", "byte", "buffer"], "project": "flink"}
{"id": 7874, "code": "public void testCheckpointBarriers() throws Exception {\n\n    final TwoInputStreamTaskTestHarness<String, Integer, String> testHarness =\n            new TwoInputStreamTaskTestHarness<>(\n                    TwoInputStreamTask::new,\n                    2,\n                    2,\n                    new int[] {1, 2},\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n    testHarness.setupOutputForSingletonOperatorChain();\n\n    StreamConfig streamConfig = testHarness.getStreamConfig();\n    CoStreamMap<String, Integer, String> coMapOperator = new CoStreamMap<>(new IdentityMap());\n    streamConfig.setStreamOperator(coMapOperator);\n    streamConfig.setOperatorID(new OperatorID());\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n    long initialTime = 0L;\n\n    testHarness.invoke();\n    testHarness.waitForTaskRunning();\n\n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            0,\n            0);\n\n        \n    testHarness.processElement(new StreamRecord<>(\"Ciao-0-0\", initialTime), 0, 1);\n    expectedOutput.add(new StreamRecord<>(\"Ciao-0-0\", initialTime));\n\n    testHarness.waitForInputProcessing();\n\n        \n        \n        \n    testHarness.processElement(new StreamRecord<>(11, initialTime), 1, 1);\n    testHarness.processElement(new StreamRecord<>(111, initialTime), 1, 1);\n    expectedOutput.add(new StreamRecord<>(\"11\", initialTime));\n    expectedOutput.add(new StreamRecord<>(\"111\", initialTime));\n\n    testHarness.waitForInputProcessing();\n\n        \n        \n    for (int i = 0; i < 20; ++i) {\n        if (testHarness.getOutput().size() >= expectedOutput.size()) {\n            break;\n        } else {\n            Thread.sleep(100);\n        }\n    }\n\n        \n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            0,\n            1);\n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            1,\n            0);\n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            1,\n            1);\n\n    testHarness.waitForInputProcessing();\n    testHarness.endInput();\n    testHarness.waitForTaskCompletion();\n\n        \n    expectedOutput.add(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    List<String> resultElements =\n            TestHarnessUtil.getRawElementsFromOutput(testHarness.getOutput());\n    Assert.assertEquals(3, resultElements.size());\n}", "summary_tokens": ["this", "test", "verifies", "that", "checkpoint", "barriers", "are", "correctly", "forwarded"], "project": "flink"}
{"id": 7697, "code": "public void testAccessToKeyedStateIt() throws Exception {\n    final List<String> test1content = new ArrayList<>();\n    test1content.add(\"test1\");\n    test1content.add(\"test1\");\n\n    final List<String> test2content = new ArrayList<>();\n    test2content.add(\"test2\");\n    test2content.add(\"test2\");\n    test2content.add(\"test2\");\n    test2content.add(\"test2\");\n\n    final List<String> test3content = new ArrayList<>();\n    test3content.add(\"test3\");\n    test3content.add(\"test3\");\n    test3content.add(\"test3\");\n\n    final Map<String, List<String>> expectedState = new HashMap<>();\n    expectedState.put(\"test1\", test1content);\n    expectedState.put(\"test2\", test2content);\n    expectedState.put(\"test3\", test3content);\n\n    try (TwoInputStreamOperatorTestHarness<String, Integer, String> testHarness =\n            getInitializedTestHarness(\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    new IdentityKeySelector<>(),\n                    new StatefulFunctionWithKeyedStateAccessedOnBroadcast(expectedState))) {\n\n            \n        testHarness.processElement1(new StreamRecord<>(\"test1\", 12L));\n        testHarness.processElement1(new StreamRecord<>(\"test1\", 12L));\n\n        testHarness.processElement1(new StreamRecord<>(\"test2\", 13L));\n        testHarness.processElement1(new StreamRecord<>(\"test2\", 13L));\n        testHarness.processElement1(new StreamRecord<>(\"test2\", 13L));\n\n        testHarness.processElement1(new StreamRecord<>(\"test3\", 14L));\n        testHarness.processElement1(new StreamRecord<>(\"test3\", 14L));\n        testHarness.processElement1(new StreamRecord<>(\"test3\", 14L));\n\n        testHarness.processElement1(new StreamRecord<>(\"test2\", 13L));\n\n            \n            \n        testHarness.processElement2(new StreamRecord<>(1, 13L));\n    }\n}", "summary_tokens": ["test", "the", "iteration", "over", "the", "keyed", "state", "on", "the", "broadcast", "side"], "project": "flink"}
{"id": 6976, "code": "public int getNumberOfTransferingThreads() {\n    return getNumberOfTransferThreads();\n}", "summary_tokens": ["typo", "in", "method", "name"], "project": "flink"}
{"id": 2596, "code": "public void write(final RowData record) {\n    recordConsumer.startMessage();\n    rowWriter.write(record);\n    recordConsumer.endMessage();\n}", "summary_tokens": ["it", "writes", "a", "record", "to", "parquet"], "project": "flink"}
{"id": 7191, "code": "public boolean isForceUnalignedCheckpoints() {\n    return forceUnalignedCheckpoints;\n}", "summary_tokens": ["checks", "whether", "unaligned", "checkpoints", "are", "forced", "despite", "iteration", "feedback"], "project": "flink"}
{"id": 8339, "code": "public static double getDouble(MemorySegment[] segments, int offset) {\n    if (inFirstSegment(segments, offset, 8)) {\n        return segments[0].getDouble(offset);\n    } else {\n        return getDoubleMultiSegments(segments, offset);\n    }\n}", "summary_tokens": ["get", "double", "from", "segments"], "project": "flink"}
{"id": 9651, "code": "public void testWatermarkPropagation() throws Exception {\n    final int numWatermarks = 10;\n\n    long initialTime = 0L;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    env.setParallelism(PARALLELISM);\n\n    DataStream<Integer> source1 =\n            env.addSource(new MyTimestampSource(initialTime, numWatermarks));\n    DataStream<Integer> source2 =\n            env.addSource(new MyTimestampSource(initialTime, numWatermarks / 2));\n\n    source1.union(source2)\n            .map(new IdentityMap())\n            .connect(source2)\n            .map(new IdentityCoMap())\n            .transform(\"Custom Operator\", BasicTypeInfo.INT_TYPE_INFO, new CustomOperator(true))\n            .addSink(new DiscardingSink<Integer>());\n\n    env.execute();\n\n        \n    for (int i = 0; i < PARALLELISM; i++) {\n            \n            \n        for (int j = 0; j < numWatermarks / 2; j++) {\n            if (!CustomOperator.finalWatermarks[i]\n                    .get(j)\n                    .equals(new Watermark(initialTime + j))) {\n                System.err.println(\"All Watermarks: \");\n                for (int k = 0; k <= numWatermarks / 2; k++) {\n                    System.err.println(CustomOperator.finalWatermarks[i].get(k));\n                }\n\n                fail(\"Wrong watermark.\");\n            }\n        }\n\n        assertEquals(\n                Watermark.MAX_WATERMARK,\n                CustomOperator.finalWatermarks[i].get(\n                        CustomOperator.finalWatermarks[i].size() - 1));\n    }\n}", "summary_tokens": ["these", "check", "whether", "custom", "timestamp", "emission", "works", "at", "sources", "and", "also", "whether", "timestamps", "arrive", "at", "operators", "throughout", "a", "topology"], "project": "flink"}
{"id": 1869, "code": "public static Row withPositions(int arity) {\n    return withPositions(RowKind.INSERT, arity);\n}", "summary_tokens": ["creates", "a", "fixed", "length", "row", "in", "position", "based", "field", "mode"], "project": "flink"}
{"id": 8992, "code": "private static RexNode adjustInputRefs(\n        final RexNode c,\n        final Map<Integer, Integer> mapOldToNewIndex,\n        final RelDataType rowType) {\n    return c.accept(\n            new RexShuttle() {\n                @Override\n                public RexNode visitInputRef(RexInputRef inputRef) {\n                    assert mapOldToNewIndex.containsKey(inputRef.getIndex());\n                    int newIndex = mapOldToNewIndex.get(inputRef.getIndex());\n                    final RexInputRef ref = RexInputRef.of(newIndex, rowType);\n                    if (ref.getIndex() == inputRef.getIndex()\n                            && ref.getType() == inputRef.getType()) {\n                        return inputRef; \n                    } else {\n                        return ref;\n                    }\n                }\n            });\n}", "summary_tokens": ["adjust", "the", "condition", "s", "field", "indices", "according", "to", "map", "old", "to", "new", "index"], "project": "flink"}
{"id": 8308, "code": "public static int calculateFixLengthPartSize(LogicalType type) {\n        \n    switch (type.getTypeRoot()) {\n        case BOOLEAN:\n        case TINYINT:\n            return 1;\n        case CHAR:\n        case VARCHAR:\n        case BINARY:\n        case VARBINARY:\n        case DECIMAL:\n        case BIGINT:\n        case DOUBLE:\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n        case INTERVAL_DAY_TIME:\n        case ARRAY:\n        case MULTISET:\n        case MAP:\n        case ROW:\n        case STRUCTURED_TYPE:\n        case RAW:\n                \n                \n                \n            return 8;\n        case TIMESTAMP_WITH_TIME_ZONE:\n            throw new UnsupportedOperationException();\n        case SMALLINT:\n            return 2;\n        case INTEGER:\n        case FLOAT:\n        case DATE:\n        case TIME_WITHOUT_TIME_ZONE:\n        case INTERVAL_YEAR_MONTH:\n            return 4;\n        case DISTINCT_TYPE:\n            return calculateFixLengthPartSize(((DistinctType) type).getSourceType());\n        case NULL:\n        case SYMBOL:\n        case UNRESOLVED:\n        default:\n            throw new IllegalArgumentException();\n    }\n}", "summary_tokens": ["it", "store", "real", "value", "when", "type", "is", "primitive"], "project": "flink"}
{"id": 8884, "code": "private Operation convertDropDatabase(SqlDropDatabase sqlDropDatabase) {\n    String[] fullDatabaseName = sqlDropDatabase.fullDatabaseName();\n    if (fullDatabaseName.length > 2) {\n        throw new ValidationException(\"drop database identifier format error\");\n    }\n    String catalogName =\n            (fullDatabaseName.length == 1)\n                    ? catalogManager.getCurrentCatalog()\n                    : fullDatabaseName[0];\n    String databaseName =\n            (fullDatabaseName.length == 1) ? fullDatabaseName[0] : fullDatabaseName[1];\n    return new DropDatabaseOperation(\n            catalogName,\n            databaseName,\n            sqlDropDatabase.getIfExists(),\n            sqlDropDatabase.isCascade());\n}", "summary_tokens": ["convert", "drop", "database", "statement"], "project": "flink"}
{"id": 7992, "code": "public OverWindow as(Expression alias) {\n    return new OverWindow(alias, partitionBy, orderBy, preceding, optionalFollowing);\n}", "summary_tokens": ["assigns", "an", "alias", "for", "this", "window", "that", "the", "following", "select", "clause", "can", "refer", "to"], "project": "flink"}
{"id": 5901, "code": "public void testUnmatchedCoordinatorOnlyStateFails() throws Exception {\n    final OperatorID operatorID = new OperatorID();\n    final int maxParallelism = 1234;\n\n    final OperatorState state =\n            new OperatorState(operatorID, maxParallelism / 2, maxParallelism);\n    state.setCoordinatorState(new ByteStreamStateHandle(\"coordinatorState\", new byte[0]));\n\n    final CompletedCheckpointStorageLocation testSavepoint =\n            createSavepointWithOperatorState(42L, state);\n    final Map<JobVertexID, ExecutionJobVertex> tasks = Collections.emptyMap();\n\n    try {\n        Checkpoints.loadAndValidateCheckpoint(\n                new JobID(),\n                tasks,\n                testSavepoint,\n                cl,\n                false,\n                CheckpointProperties.forSavepoint(false));\n        fail(\"Did not throw expected Exception\");\n    } catch (IllegalStateException expected) {\n        assertTrue(expected.getMessage().contains(\"allowNonRestoredState\"));\n    }\n}", "summary_tokens": ["tests", "that", "savepoint", "loading", "fails", "when", "there", "is", "non", "restored", "coordinator", "state", "only", "and", "non", "restored", "state", "is", "not", "allowed"], "project": "flink"}
{"id": 7218, "code": "public List<Tuple2<String, DistributedCache.DistributedCacheEntry>> getCachedFiles() {\n    return cacheFile;\n}", "summary_tokens": ["get", "the", "list", "of", "cached", "files", "that", "were", "registered", "for", "distribution", "among", "the", "task", "managers"], "project": "flink"}
{"id": 2837, "code": "public Iterator<T> sample(Iterator<T> input) {\n    return sampleInCoordinator(sampleInPartition(input));\n}", "summary_tokens": ["combine", "the", "first", "phase", "and", "second", "phase", "in", "sequence", "implemented", "for", "test", "purpose", "only"], "project": "flink"}
{"id": 8313, "code": "public static byte[] allocateReuseBytes(int length) {\n    byte[] bytes = BYTES_LOCAL.get();\n\n    if (bytes == null) {\n        if (length <= MAX_BYTES_LENGTH) {\n            bytes = new byte[MAX_BYTES_LENGTH];\n            BYTES_LOCAL.set(bytes);\n        } else {\n            bytes = new byte[length];\n        }\n    } else if (bytes.length < length) {\n        bytes = new byte[length];\n    }\n\n    return bytes;\n}", "summary_tokens": ["allocate", "bytes", "that", "is", "only", "for", "temporary", "usage", "it", "should", "not", "be", "stored", "in", "somewhere", "else"], "project": "flink"}
{"id": 7868, "code": "public void waitForInputProcessing() throws Exception {\n    while (taskThread.isAlive()) {\n        boolean allEmpty = true;\n        for (int i = 0; i < numInputGates; i++) {\n            if (!inputGates[i].allQueuesEmpty()) {\n                allEmpty = false;\n            }\n        }\n\n        if (allEmpty) {\n            break;\n        }\n    }\n\n        \n    final AtomicBoolean allInputProcessed = new AtomicBoolean();\n    final MailboxProcessor mailboxProcessor = taskThread.task.mailboxProcessor;\n    final MailboxExecutor mailboxExecutor = mailboxProcessor.getMainMailboxExecutor();\n    while (taskThread.isAlive()) {\n        try {\n            final CountDownLatch latch = new CountDownLatch(1);\n            mailboxExecutor.execute(\n                    () -> {\n                        allInputProcessed.set(!mailboxProcessor.isDefaultActionAvailable());\n                        latch.countDown();\n                    },\n                    \"query-whether-processInput-has-suspend-itself\");\n                \n            latch.await(1, TimeUnit.SECONDS);\n        } catch (RejectedExecutionException ex) {\n                \n        }\n\n        if (allInputProcessed.get()) {\n            break;\n        }\n\n        try {\n            Thread.sleep(1);\n        } catch (InterruptedException ignored) {\n        }\n    }\n\n    Throwable error = taskThread.getError();\n    if (error != null) {\n        throw new Exception(\"Exception in the task thread\", error);\n    }\n}", "summary_tokens": ["this", "only", "returns", "after", "all", "input", "queues", "are", "empty"], "project": "flink"}
{"id": 3002, "code": "public static ResourceRequirements getResourceRequirements(\n        ResourceRequirements resourceRequirements,\n        int mem,\n        double cpu,\n        Map<String, ExternalResource> externalResources,\n        Map<String, String> externalResourceConfigKeys) {\n    final Quantity cpuQuantity = new Quantity(String.valueOf(cpu));\n    final Quantity memQuantity = new Quantity(mem + Constants.RESOURCE_UNIT_MB);\n\n    ResourceRequirementsBuilder resourceRequirementsBuilder =\n            new ResourceRequirementsBuilder(resourceRequirements)\n                    .addToRequests(Constants.RESOURCE_NAME_MEMORY, memQuantity)\n                    .addToRequests(Constants.RESOURCE_NAME_CPU, cpuQuantity)\n                    .addToLimits(Constants.RESOURCE_NAME_MEMORY, memQuantity)\n                    .addToLimits(Constants.RESOURCE_NAME_CPU, cpuQuantity);\n\n        \n    for (Map.Entry<String, ExternalResource> externalResource : externalResources.entrySet()) {\n        final String configKey = externalResourceConfigKeys.get(externalResource.getKey());\n        if (!StringUtils.isNullOrWhitespaceOnly(configKey)) {\n            final Quantity resourceQuantity =\n                    new Quantity(\n                            String.valueOf(externalResource.getValue().getValue().longValue()));\n            resourceRequirementsBuilder\n                    .addToRequests(configKey, resourceQuantity)\n                    .addToLimits(configKey, resourceQuantity);\n            LOG.info(\n                    \"Request external resource {} with config key {}.\",\n                    resourceQuantity.getAmount(),\n                    configKey);\n        }\n    }\n\n    return resourceRequirementsBuilder.build();\n}", "summary_tokens": ["get", "resource", "requirements", "from", "memory", "and", "cpu"], "project": "flink"}
{"id": 2632, "code": "public <R> MapPartitionOperator<T, R> mapPartition(MapPartitionFunction<T, R> mapPartition) {\n    if (mapPartition == null) {\n        throw new NullPointerException(\"MapPartition function must not be null.\");\n    }\n\n    String callLocation = Utils.getCallLocationName();\n    TypeInformation<R> resultType =\n            TypeExtractor.getMapPartitionReturnTypes(\n                    mapPartition, getType(), callLocation, true);\n    return new MapPartitionOperator<>(this, resultType, clean(mapPartition), callLocation);\n}", "summary_tokens": ["applies", "a", "map", "style", "operation", "to", "the", "entire", "partition", "of", "the", "data"], "project": "flink"}
{"id": 6762, "code": "long helpGetNextNode(long node, int level) {\n    return SkipListUtils.helpGetNextNode(\n            node, level, this.levelIndexHeader, this.spaceAllocator);\n}", "summary_tokens": ["return", "the", "next", "of", "the", "given", "node", "at", "the", "given", "level"], "project": "flink"}
{"id": 9410, "code": "public boolean contains(final double k) {\n    long longKey = Double.doubleToLongBits(k);\n    if (longKey == 0L) {\n        return this.containsZero;\n    } else {\n        double[] key = this.key;\n        long curr;\n        int pos;\n        if ((curr =\n                        Double.doubleToLongBits(\n                                key[pos = (int) MurmurHashUtil.fmix(longKey) & this.mask]))\n                == 0L) {\n            return false;\n        } else if (longKey == curr) {\n            return true;\n        } else {\n            while ((curr = Double.doubleToLongBits(key[pos = pos + 1 & this.mask])) != 0L) {\n                if (longKey == curr) {\n                    return true;\n                }\n            }\n\n            return false;\n        }\n    }\n}", "summary_tokens": ["see", "double", "equals", "object"], "project": "flink"}
{"id": 561, "code": "public void setWriteTimestampToKafka(boolean writeTimestampToKafka) {\n    this.writeTimestampToKafka = writeTimestampToKafka;\n    if (kafkaSchema instanceof KafkaSerializationSchemaWrapper) {\n        ((KafkaSerializationSchemaWrapper<IN>) kafkaSchema)\n                .setWriteTimestamp(writeTimestampToKafka);\n    }\n}", "summary_tokens": ["if", "set", "to", "true", "flink", "will", "write", "the", "event", "time", "timestamp", "attached", "to", "each", "record", "into", "kafka"], "project": "flink"}
{"id": 6106, "code": "public void testJobMasterLeaderRetrieval() throws Exception {\n    JobID jobId1 = new JobID();\n    JobID jobId2 = new JobID();\n    final String jobManagerAddress1 = \"foobar\";\n    final String jobManagerAddress2 = \"barfoo\";\n    LeaderRetrievalListener jmListener1 = mock(LeaderRetrievalListener.class);\n    LeaderRetrievalListener jmListener2 = mock(LeaderRetrievalListener.class);\n\n    LeaderRetrievalService jmLeaderRetrievalService1 =\n            standaloneHaServices.getJobManagerLeaderRetriever(jobId1, jobManagerAddress1);\n    LeaderRetrievalService jmLeaderRetrievalService2 =\n            standaloneHaServices.getJobManagerLeaderRetriever(jobId2, jobManagerAddress2);\n\n    jmLeaderRetrievalService1.start(jmListener1);\n    jmLeaderRetrievalService2.start(jmListener2);\n\n    verify(jmListener1)\n            .notifyLeaderAddress(\n                    eq(jobManagerAddress1), eq(HighAvailabilityServices.DEFAULT_LEADER_ID));\n    verify(jmListener2)\n            .notifyLeaderAddress(\n                    eq(jobManagerAddress2), eq(HighAvailabilityServices.DEFAULT_LEADER_ID));\n}", "summary_tokens": ["tests", "that", "the", "standalone", "leader", "retrieval", "services", "return", "the", "given", "address", "and", "the", "fixed", "leader", "session", "id"], "project": "flink"}
{"id": 5106, "code": "public KvStateID getKvStateID(int keyGroupIndex) {\n    if (keyGroupIndex < 0 || keyGroupIndex >= numKeyGroups) {\n        throw new IndexOutOfBoundsException(\"Key group index\");\n    }\n\n    return kvStateIds[keyGroupIndex];\n}", "summary_tokens": ["returns", "the", "registered", "kv", "state", "id", "for", "the", "key", "group", "index", "or", "code", "null", "code", "if", "none", "is", "registered", "yet"], "project": "flink"}
{"id": 364, "code": "public HiveParserTypeCheckProcFactory.ColumnExprProcessor getColumnExprProcessor() {\n    return new HiveParserTypeCheckProcFactory.ColumnExprProcessor();\n}", "summary_tokens": ["factory", "method", "to", "get", "column", "expr", "processor"], "project": "flink"}
{"id": 5811, "code": "public void testNonSSLConnection2() throws Exception {\n    uploadJarFile(blobServer, nonSslClientConfig);\n}", "summary_tokens": ["verify", "non", "ssl", "connection", "sanity"], "project": "flink"}
{"id": 3282, "code": "public void addBroadcastSetForSumFunction(String name, DataSet<?> data) {\n    this.bcVarsSum.add(new Tuple2<>(name, data));\n}", "summary_tokens": ["adds", "a", "data", "set", "as", "a", "broadcast", "set", "to", "the", "sum", "function"], "project": "flink"}
{"id": 9010, "code": "public List<RelCollation> getCollationList() {\n    return ImmutableList.of();\n}", "summary_tokens": ["returns", "a", "description", "of", "the", "physical", "ordering", "or", "orderings", "of", "the", "rows", "returned", "from", "this", "table"], "project": "flink"}
{"id": 8354, "code": "public int compareTo(@Nonnull StringData o) {\n        \n    BinaryStringData other = (BinaryStringData) o;\n    if (javaObject != null && other.javaObject != null) {\n        return javaObject.compareTo(other.javaObject);\n    }\n\n    ensureMaterialized();\n    other.ensureMaterialized();\n    if (binarySection.segments.length == 1 && other.binarySection.segments.length == 1) {\n\n        int len = Math.min(binarySection.sizeInBytes, other.binarySection.sizeInBytes);\n        MemorySegment seg1 = binarySection.segments[0];\n        MemorySegment seg2 = other.binarySection.segments[0];\n\n        for (int i = 0; i < len; i++) {\n            int res =\n                    (seg1.get(binarySection.offset + i) & 0xFF)\n                            - (seg2.get(other.binarySection.offset + i) & 0xFF);\n            if (res != 0) {\n                return res;\n            }\n        }\n        return binarySection.sizeInBytes - other.binarySection.sizeInBytes;\n    }\n\n        \n    return compareMultiSegments(other);\n}", "summary_tokens": ["compares", "two", "strings", "lexicographically"], "project": "flink"}
{"id": 9722, "code": "private static LocalResource registerLocalResource(\n        FileSystem fs, Path remoteRsrcPath, LocalResourceType resourceType) throws IOException {\n    FileStatus jarStat = fs.getFileStatus(remoteRsrcPath);\n    return registerLocalResource(\n            remoteRsrcPath,\n            jarStat.getLen(),\n            jarStat.getModificationTime(),\n            LocalResourceVisibility.APPLICATION,\n            resourceType);\n}", "summary_tokens": ["creates", "a", "yarn", "resource", "for", "the", "remote", "object", "at", "the", "given", "location"], "project": "flink"}
{"id": 9689, "code": "public int getSessionId() {\n    return sessionId;\n}", "summary_tokens": ["id", "of", "the", "session", "to", "identify", "a", "sessions", "in", "the", "sequence", "of", "all", "sessions", "for", "the", "same", "key"], "project": "flink"}
{"id": 4783, "code": "public int getMaxParallelism() {\n    return maxParallelism;\n}", "summary_tokens": ["gets", "the", "maximum", "parallelism", "for", "the", "task"], "project": "flink"}
{"id": 4964, "code": "public void close() {\n        \n    synchronized (this.stateLock) {\n        if (this.closed) {\n            return;\n        }\n        this.closed = true;\n    }\n\n    LOG.debug(\"Closing hash table and releasing resources.\");\n\n        \n    releaseTable();\n\n        \n    clearPartitions();\n}", "summary_tokens": ["closes", "the", "hash", "table"], "project": "flink"}
{"id": 8624, "code": "public static boolean supportsExplicitCast(LogicalType sourceType, LogicalType targetType) {\n    return supportsCasting(sourceType, targetType, true);\n}", "summary_tokens": ["returns", "whether", "the", "source", "type", "can", "be", "casted", "to", "the", "target", "type"], "project": "flink"}
{"id": 4777, "code": "public int getNumberOfInputs() {\n    return this.inputs.size();\n}", "summary_tokens": ["returns", "the", "number", "of", "inputs"], "project": "flink"}
{"id": 7633, "code": "public void testMaxParallelismForwarding() {\n    int globalMaxParallelism = 42;\n    int keyedResult2MaxParallelism = 17;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.getConfig().setMaxParallelism(globalMaxParallelism);\n\n    DataStream<Integer> source = env.fromElements(1, 2, 3);\n\n    DataStream<Integer> keyedResult1 = source.keyBy(value -> value).map(new NoOpIntMap());\n\n    DataStream<Integer> keyedResult2 =\n            keyedResult1\n                    .keyBy(value -> value)\n                    .map(new NoOpIntMap())\n                    .setMaxParallelism(keyedResult2MaxParallelism);\n\n    keyedResult2.addSink(new DiscardingSink<>());\n\n    StreamGraph graph = env.getStreamGraph();\n\n    StreamNode keyedResult1Node = graph.getStreamNode(keyedResult1.getId());\n    StreamNode keyedResult2Node = graph.getStreamNode(keyedResult2.getId());\n\n    assertEquals(globalMaxParallelism, keyedResult1Node.getMaxParallelism());\n    assertEquals(keyedResult2MaxParallelism, keyedResult2Node.getMaxParallelism());\n}", "summary_tokens": ["tests", "that", "the", "global", "and", "operator", "wide", "max", "parallelism", "setting", "is", "respected"], "project": "flink"}
{"id": 637, "code": "public static DynamicTableFactory.Context autoCompleteSchemaRegistrySubject(\n        DynamicTableFactory.Context context) {\n    Map<String, String> tableOptions = context.getCatalogTable().getOptions();\n    Map<String, String> newOptions = autoCompleteSchemaRegistrySubject(tableOptions);\n    if (newOptions.size() > tableOptions.size()) {\n            \n        return new FactoryUtil.DefaultDynamicTableContext(\n                context.getObjectIdentifier(),\n                context.getCatalogTable().copy(newOptions),\n                context.getConfiguration(),\n                context.getClassLoader(),\n                context.isTemporary());\n    } else {\n        return context;\n    }\n}", "summary_tokens": ["returns", "a", "new", "table", "context", "with", "a", "default", "schema", "registry", "subject", "value", "in", "the", "options", "if", "the", "format", "is", "a", "schema", "registry", "format", "e"], "project": "flink"}
{"id": 6217, "code": "private void testAddOnFinishedPartition(final ResultPartitionType partitionType)\n        throws Exception {\n    TestResultPartitionConsumableNotifier notifier =\n            new TestResultPartitionConsumableNotifier();\n    BufferWritingResultPartition bufferWritingResultPartition =\n            createResultPartition(partitionType);\n    ResultPartitionWriter partitionWriter =\n            ConsumableNotifyingResultPartitionWriterDecorator.decorate(\n                    Collections.singleton(\n                            PartitionTestUtils.createPartitionDeploymentDescriptor(\n                                    partitionType)),\n                    new ResultPartitionWriter[] {bufferWritingResultPartition},\n                    new NoOpTaskActions(),\n                    new JobID(),\n                    notifier)[0];\n    try {\n        partitionWriter.finish();\n        notifier.reset();\n            \n        partitionWriter.emitRecord(ByteBuffer.allocate(bufferSize), 0);\n    } catch (IllegalStateException e) {\n            \n    } finally {\n        assertEquals(0, bufferWritingResultPartition.numBuffersOut.getCount());\n        assertEquals(0, bufferWritingResultPartition.numBytesOut.getCount());\n        assertEquals(\n                0,\n                bufferWritingResultPartition.getBufferPool().bestEffortGetNumOfUsedBuffers());\n            \n        notifier.check(null, null, null, 0);\n    }\n}", "summary_tokens": ["tests", "result", "partition", "emit", "record", "on", "a", "partition", "which", "has", "already", "finished"], "project": "flink"}
{"id": 6357, "code": "public void testRESTServerSSLBadKeystorePassword() {\n    Configuration serverConfig = createRestSslConfigWithKeyStore();\n    serverConfig.setString(SecurityOptions.SSL_REST_KEYSTORE_PASSWORD, \"badpassword\");\n\n    try {\n        SSLUtils.createRestServerSSLEngineFactory(serverConfig);\n        fail(\"exception expected\");\n    } catch (Exception ignored) {\n    }\n}", "summary_tokens": ["tests", "that", "rest", "server", "ssl", "engine", "creation", "fails", "with", "bad", "ssl", "configuration"], "project": "flink"}
{"id": 6452, "code": "public void testRequirementCheckOnlyTriggeredOnce() throws Exception {\n    new Context() {\n        {\n            final List<CompletableFuture<Void>> checkRequirementFutures = new ArrayList<>();\n            checkRequirementFutures.add(new CompletableFuture<>());\n            checkRequirementFutures.add(new CompletableFuture<>());\n            final long requirementCheckDelay = 50;\n            resourceAllocationStrategyBuilder.setTryFulfillRequirementsFunction(\n                    (ignored1, ignored2) -> {\n                        if (checkRequirementFutures.get(0).isDone()) {\n                            checkRequirementFutures.get(1).complete(null);\n                        } else {\n                            checkRequirementFutures.get(0).complete(null);\n                        }\n                        return ResourceAllocationResult.builder().build();\n                    });\n            setRequirementCheckDelay(requirementCheckDelay);\n            runTest(\n                    () -> {\n                        final ResourceRequirements resourceRequirements1 =\n                                createResourceRequirementsForSingleSlot();\n                        final ResourceRequirements resourceRequirements2 =\n                                createResourceRequirementsForSingleSlot();\n                        final ResourceRequirements resourceRequirements3 =\n                                createResourceRequirementsForSingleSlot();\n                        final TaskExecutorConnection taskExecutionConnection =\n                                createTaskExecutorConnection();\n                        final CompletableFuture<Void> registrationFuture =\n                                new CompletableFuture<>();\n                        final long start = System.nanoTime();\n                        runInMainThread(\n                                () -> {\n                                    getSlotManager()\n                                            .processResourceRequirements(resourceRequirements1);\n                                    getSlotManager()\n                                            .processResourceRequirements(resourceRequirements2);\n                                    getSlotManager()\n                                            .registerTaskManager(\n                                                    taskExecutionConnection,\n                                                    new SlotReport(),\n                                                    DEFAULT_TOTAL_RESOURCE_PROFILE,\n                                                    DEFAULT_SLOT_RESOURCE_PROFILE);\n                                    registrationFuture.complete(null);\n                                });\n\n                        assertFutureCompleteAndReturn(registrationFuture);\n                        final long registrationTime = (System.nanoTime() - start) / 1_000_000;\n                        assumeTrue(\n                                \"The time of process requirement and register task manager must not take longer than the requirement check delay. If it does, then this indicates a very slow machine.\",\n                                registrationTime < requirementCheckDelay);\n\n                        assertFutureCompleteAndReturn(checkRequirementFutures.get(0));\n                        assertFutureNotComplete(checkRequirementFutures.get(1));\n\n                            \n                        Thread.sleep(requirementCheckDelay * 2);\n                        assertFutureNotComplete(checkRequirementFutures.get(1));\n\n                            \n                            \n                        runInMainThread(\n                                () ->\n                                        getSlotManager()\n                                                .processResourceRequirements(\n                                                        resourceRequirements3));\n                        assertFutureCompleteAndReturn(checkRequirementFutures.get(1));\n                    });\n        }\n    };\n}", "summary_tokens": ["test", "that", "check", "resource", "requirements", "will", "only", "be", "triggered", "once", "after", "multiple", "trigger", "function", "calls"], "project": "flink"}
{"id": 4705, "code": "public ResultPartitionType getConsumedPartitionType() {\n    return consumedPartitionType;\n}", "summary_tokens": ["returns", "the", "type", "of", "this", "input", "channel", "s", "consumed", "result", "partition"], "project": "flink"}
{"id": 2464, "code": "public void testConstructor_withDeserializer_succeeds() {\n    GlueSchemaRegistryInputStreamDeserializer glueSchemaRegistryInputStreamDeserializer =\n            new GlueSchemaRegistryInputStreamDeserializer(\n                    glueSchemaRegistryDeserializationFacade);\n    assertThat(\n            glueSchemaRegistryInputStreamDeserializer,\n            instanceOf(GlueSchemaRegistryInputStreamDeserializer.class));\n}", "summary_tokens": ["test", "whether", "constructor", "works", "with", "aws", "de", "serializer", "input"], "project": "flink"}
{"id": 7240, "code": "public TernaryBoolean isChangelogStateBackendEnabled() {\n    return changelogStateBackendEnabled;\n}", "summary_tokens": ["gets", "the", "enable", "status", "of", "change", "log", "for", "state", "backend"], "project": "flink"}
{"id": 9164, "code": "public MemorySegment getNextBuffer() {\n        \n    MemorySegment segment = this.internalPool.nextSegment();\n    if (segment != null) {\n        return segment;\n    }\n\n        \n    if (this.buildSpillRetBufferNumbers > 0) {\n            \n        MemorySegment toReturn;\n        try {\n            toReturn = this.buildSpillReturnBuffers.take();\n        } catch (InterruptedException iex) {\n            throw new RuntimeException(\n                    \"Hybrid Hash Join was interrupted while taking a buffer.\");\n        }\n        this.buildSpillRetBufferNumbers--;\n\n            \n        MemorySegment currBuff;\n        while (this.buildSpillRetBufferNumbers > 0\n                && (currBuff = this.buildSpillReturnBuffers.poll()) != null) {\n            returnPage(currBuff);\n            this.buildSpillRetBufferNumbers--;\n        }\n        return toReturn;\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["gets", "the", "next", "buffer", "to", "be", "used", "with", "the", "hash", "table", "either", "for", "an", "in", "memory", "partition", "or", "for", "the", "table", "buckets"], "project": "flink"}
{"id": 5993, "code": "public void testDuplicateJobSubmissionDoesNotDeleteJobMetaData() throws Exception {\n    final TestingJobManagerRunnerFactory testingJobManagerRunnerFactoryNG =\n            startDispatcherAndSubmitJob();\n\n    final CompletableFuture<Acknowledge> submissionFuture =\n            dispatcherGateway.submitJob(jobGraph, timeout);\n\n    try {\n        try {\n            submissionFuture.get();\n            fail(\"Expected a DuplicateJobSubmissionFailure.\");\n        } catch (ExecutionException ee) {\n            assertThat(\n                    ExceptionUtils.findThrowable(ee, DuplicateJobSubmissionException.class)\n                            .isPresent(),\n                    is(true));\n        }\n\n        assertThatHABlobsHaveNotBeenRemoved();\n    } finally {\n        finishJob(testingJobManagerRunnerFactoryNG.takeCreatedJobManagerRunner());\n    }\n\n    assertThatHABlobsHaveBeenRemoved();\n}", "summary_tokens": ["tests", "that", "a", "duplicate", "job", "submission", "won", "t", "delete", "any", "job", "meta", "data", "submitted", "job", "graphs", "blobs", "etc"], "project": "flink"}
{"id": 578, "code": "default void deserialize(ConsumerRecord<byte[], byte[]> message, Collector<T> out)\n        throws Exception {\n    T deserialized = deserialize(message);\n    if (deserialized != null) {\n        out.collect(deserialized);\n    }\n}", "summary_tokens": ["deserializes", "the", "kafka", "record"], "project": "flink"}
{"id": 1095, "code": "public JobID getJobID() {\n    return jobID;\n}", "summary_tokens": ["returns", "the", "job", "id", "assigned", "to", "the", "job", "by", "the", "flink", "runtime"], "project": "flink"}
{"id": 3047, "code": "public void clear() {\n    usedNames.clear();\n}", "summary_tokens": ["clear", "the", "names", "added", "during", "checking", "name", "uniqueness"], "project": "flink"}
{"id": 3526, "code": "public void testSavepointDeepCopy() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStream<String> words = env.fromElements(TEXT.split(\" \"));\n\n    StateBootstrapTransformation<String> transformation =\n            OperatorTransformation.bootstrapWith(words)\n                    .keyBy(e -> e)\n                    .transform(new WordMapBootstrapper());\n\n    File savepointUrl1 = createAndRegisterTempFile(new AbstractID().toHexString());\n    String savepointPath1 = savepointUrl1.getPath();\n\n    SavepointWriter.newSavepoint(backend, 128)\n            .withConfiguration(FS_SMALL_FILE_THRESHOLD, FILE_STATE_SIZE_THRESHOLD)\n            .withOperator(\"Operator1\", transformation)\n            .write(savepointPath1);\n\n    env.execute(\"bootstrap savepoint1\");\n\n    Assert.assertTrue(\n            \"Failed to bootstrap savepoint1 with additional state files\",\n            Files.list(Paths.get(savepointPath1)).count() > 1);\n\n    Set<String> stateFiles1 =\n            Files.list(Paths.get(savepointPath1))\n                    .map(path -> path.getFileName().toString())\n                    .collect(Collectors.toSet());\n\n        \n    File savepointUrl2 = createAndRegisterTempFile(new AbstractID().toHexString());\n    String savepointPath2 = savepointUrl2.getPath();\n\n    SavepointWriter savepoint2 =\n            SavepointWriter.fromExistingSavepoint(savepointPath1, backend)\n                    .withConfiguration(FS_SMALL_FILE_THRESHOLD, FILE_STATE_SIZE_THRESHOLD);\n\n    savepoint2.withOperator(\"Operator2\", transformation).write(savepointPath2);\n    env.execute(\"create savepoint2\");\n\n    Assert.assertTrue(\n            \"Failed to create savepoint2 from savepoint1 with additional state files\",\n            Files.list(Paths.get(savepointPath2)).count() > 1);\n\n    Set<String> stateFiles2 =\n            Files.list(Paths.get(savepointPath2))\n                    .map(path -> path.getFileName().toString())\n                    .collect(Collectors.toSet());\n\n    assertThat(\n            \"At least one state file in savepoint1 are not in savepoint2\",\n            stateFiles1,\n            everyItem(isIn(stateFiles2)));\n\n        \n        \n        \n        \n    long actuallyKeyNum =\n            JobResultRetriever.collect(\n                            SavepointReader.read(env, savepointPath2, backend)\n                                    .readKeyedState(\"Operator1\", new ReadFunction()))\n                    .size();\n\n    long expectedKeyNum = Arrays.stream(TEXT.split(\" \")).distinct().count();\n    Assert.assertEquals(\n            \"Unexpected number of keys in the state of Operator1\",\n            expectedKeyNum,\n            actuallyKeyNum);\n}", "summary_tokens": ["test", "savepoint", "deep", "copy"], "project": "flink"}
{"id": 5654, "code": "private static long getSizeOfPhysicalMemoryForMac() {\n    BufferedReader bi = null;\n    try {\n        Process proc = Runtime.getRuntime().exec(\"sysctl hw.memsize\");\n\n        bi =\n                new BufferedReader(\n                        new InputStreamReader(proc.getInputStream(), StandardCharsets.UTF_8));\n\n        String line;\n        while ((line = bi.readLine()) != null) {\n            if (line.startsWith(\"hw.memsize\")) {\n                long memsize = Long.parseLong(line.split(\":\")[1].trim());\n                bi.close();\n                proc.destroy();\n                return memsize;\n            }\n        }\n\n    } catch (Throwable t) {\n        LOG.error(\"Cannot determine physical memory of machine for MacOS host\", t);\n        return -1;\n    } finally {\n        if (bi != null) {\n            try {\n                bi.close();\n            } catch (IOException ignored) {\n            }\n        }\n    }\n    return -1;\n}", "summary_tokens": ["returns", "the", "size", "of", "the", "physical", "memory", "in", "bytes", "on", "a", "mac", "os", "based", "operating", "system"], "project": "flink"}
{"id": 6253, "code": "public void testRequestBuffersWithUnknownInputChannel() throws Exception {\n    final NettyShuffleEnvironment network = createNettyShuffleEnvironment();\n    final SingleInputGate inputGate =\n            createInputGate(network, 1, ResultPartitionType.PIPELINED_BOUNDED);\n    int buffersPerChannel = 2;\n    int extraNetworkBuffersPerGate = 8;\n\n    try (Closer closer = Closer.create()) {\n        closer.register(network::close);\n        closer.register(inputGate::close);\n\n        final ResultPartitionID resultPartitionId = new ResultPartitionID();\n        InputChannel inputChannel =\n                buildUnknownInputChannel(network, inputGate, resultPartitionId, 0);\n\n        inputGate.setInputChannels(inputChannel);\n        inputGate.setup();\n        NetworkBufferPool bufferPool = network.getNetworkBufferPool();\n\n        assertEquals(\n                bufferPool.getTotalNumberOfMemorySegments() - 1,\n                bufferPool.getNumberOfAvailableMemorySegments());\n            \n            \n        assertEquals(extraNetworkBuffersPerGate, bufferPool.countBuffers());\n\n            \n        inputGate.updateInputChannel(\n                ResourceID.generate(),\n                createRemoteWithIdAndLocation(\n                        resultPartitionId.getPartitionId(), ResourceID.generate()));\n\n        RemoteInputChannel remote =\n                (RemoteInputChannel)\n                        inputGate.getInputChannels().get(resultPartitionId.getPartitionId());\n            \n        assertEquals(buffersPerChannel, remote.getNumberOfAvailableBuffers());\n\n        assertEquals(\n                bufferPool.getTotalNumberOfMemorySegments() - buffersPerChannel - 1,\n                bufferPool.getNumberOfAvailableMemorySegments());\n            \n            \n        assertEquals(extraNetworkBuffersPerGate, bufferPool.countBuffers());\n    }\n}", "summary_tokens": ["tests", "that", "input", "gate", "requests", "and", "assigns", "network", "buffers", "when", "unknown", "input", "channel", "updates", "to", "remote", "input", "channel"], "project": "flink"}
{"id": 3265, "code": "public GridGraph addDimension(long size, boolean wrapEndpoints) {\n    Preconditions.checkArgument(size >= 2, \"Dimension size must be at least 2\");\n\n    vertexCount = Math.multiplyExact(vertexCount, size);\n\n        \n    if (size == 2) {\n        wrapEndpoints = false;\n    }\n\n    dimensions.add(new Tuple2<>(size, wrapEndpoints));\n\n    return this;\n}", "summary_tokens": ["required", "configuration", "for", "each", "dimension", "of", "the", "graph"], "project": "flink"}
{"id": 1749, "code": "public static <T> byte[] writeVersionAndSerialize(\n        SimpleVersionedSerializer<T> serializer, T datum) throws IOException {\n    checkNotNull(serializer, \"serializer\");\n    checkNotNull(datum, \"datum\");\n\n    final byte[] data = serializer.serialize(datum);\n    final byte[] versionAndData = new byte[data.length + 8];\n\n    final int version = serializer.getVersion();\n    versionAndData[0] = (byte) (version >> 24);\n    versionAndData[1] = (byte) (version >> 16);\n    versionAndData[2] = (byte) (version >> 8);\n    versionAndData[3] = (byte) version;\n\n    final int length = data.length;\n    versionAndData[4] = (byte) (length >> 24);\n    versionAndData[5] = (byte) (length >> 16);\n    versionAndData[6] = (byte) (length >> 8);\n    versionAndData[7] = (byte) length;\n\n        \n    System.arraycopy(data, 0, versionAndData, 8, data.length);\n\n    return versionAndData;\n}", "summary_tokens": ["serializes", "the", "version", "and", "datum", "into", "a", "byte", "array"], "project": "flink"}
{"id": 6607, "code": "private static <V, K, N> List<V> getSerializedList(\n        InternalKvState<K, N, V> kvState,\n        K key,\n        TypeSerializer<K> keySerializer,\n        N namespace,\n        TypeSerializer<N> namespaceSerializer,\n        TypeSerializer<V> valueSerializer)\n        throws Exception {\n\n    byte[] serializedKeyAndNamespace =\n            KvStateSerializer.serializeKeyAndNamespace(\n                    key, keySerializer, namespace, namespaceSerializer);\n\n    byte[] serializedValue =\n            kvState.getSerializedValue(\n                    serializedKeyAndNamespace,\n                    kvState.getKeySerializer(),\n                    kvState.getNamespaceSerializer(),\n                    kvState.getValueSerializer());\n\n    if (serializedValue == null) {\n        return null;\n    } else {\n        return KvStateSerializer.deserializeList(serializedValue, valueSerializer);\n    }\n}", "summary_tokens": ["returns", "the", "value", "by", "getting", "the", "serialized", "value", "and", "deserializing", "it", "if", "it", "is", "not", "null"], "project": "flink"}
{"id": 5244, "code": "public Set<HttpMethod> allAllowedMethods() {\n    if (anyMethodRouter.size() > 0) {\n        Set<HttpMethod> ret = new HashSet<HttpMethod>(9);\n        ret.add(HttpMethod.CONNECT);\n        ret.add(HttpMethod.DELETE);\n        ret.add(HttpMethod.GET);\n        ret.add(HttpMethod.HEAD);\n        ret.add(HttpMethod.OPTIONS);\n        ret.add(HttpMethod.PATCH);\n        ret.add(HttpMethod.POST);\n        ret.add(HttpMethod.PUT);\n        ret.add(HttpMethod.TRACE);\n        return ret;\n    } else {\n        return new HashSet<HttpMethod>(routers.keySet());\n    }\n}", "summary_tokens": ["returns", "all", "methods", "that", "this", "router", "handles"], "project": "flink"}
{"id": 4022, "code": "public void testScheduledExecutorServiceWithFixedDelaySchedule() throws Exception {\n    ScheduledExecutor scheduledExecutor = akkaRpcService.getScheduledExecutor();\n\n    final int tries = 4;\n    final long delay = 10L;\n    final CountDownLatch countDownLatch = new CountDownLatch(tries);\n\n    long currentTime = System.nanoTime();\n\n    ScheduledFuture<?> future =\n            scheduledExecutor.scheduleWithFixedDelay(\n                    countDownLatch::countDown, delay, delay, TimeUnit.MILLISECONDS);\n\n    assertTrue(!future.isDone());\n\n    countDownLatch.await();\n\n        \n    assertTrue(!future.isDone());\n\n    long finalTime = System.nanoTime() - currentTime;\n\n        \n    assertTrue(finalTime >= tries * delay);\n\n    future.cancel(true);\n}", "summary_tokens": ["tests", "that", "the", "rpc", "service", "s", "scheduled", "executor", "service", "can", "execute", "runnable", "with", "a", "fixed", "delay"], "project": "flink"}
{"id": 5601, "code": "public int dataPort() {\n    return dataPort;\n}", "summary_tokens": ["returns", "the", "port", "instance", "s", "task", "manager", "expects", "to", "receive", "transfer", "envelopes", "on"], "project": "flink"}
{"id": 1577, "code": "public static Type getTypeHierarchy(List<Type> typeHierarchy, Type t, Class<?> stopAtClass) {\n    while (!(isClassType(t) && typeToClass(t).equals(stopAtClass))) {\n        typeHierarchy.add(t);\n        t = typeToClass(t).getGenericSuperclass();\n\n        if (t == null) {\n            break;\n        }\n    }\n    return t;\n}", "summary_tokens": ["traverses", "the", "type", "hierarchy", "of", "a", "type", "up", "until", "a", "certain", "stop", "class", "is", "found"], "project": "flink"}
{"id": 5917, "code": "public void testCheckpointTracking() throws Exception {\n    JobVertexID jobVertexID = new JobVertexID();\n    ExecutionGraph graph =\n            new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                    .addJobVertex(jobVertexID, 3, 256)\n                    .build();\n    ExecutionJobVertex jobVertex = graph.getJobVertex(jobVertexID);\n    Map<JobVertexID, Integer> vertexToDop =\n            singletonMap(jobVertexID, jobVertex.getParallelism());\n\n    CheckpointStatsTracker tracker =\n            new CheckpointStatsTracker(10, new UnregisteredMetricsGroup());\n\n        \n    PendingCheckpointStats completed1 =\n            tracker.reportPendingCheckpoint(\n                    0,\n                    1,\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    vertexToDop);\n\n    completed1.reportSubtaskStats(jobVertexID, createSubtaskStats(0));\n    completed1.reportSubtaskStats(jobVertexID, createSubtaskStats(1));\n    completed1.reportSubtaskStats(jobVertexID, createSubtaskStats(2));\n\n    completed1.reportCompletedCheckpoint(null);\n\n        \n    PendingCheckpointStats failed =\n            tracker.reportPendingCheckpoint(\n                    1,\n                    1,\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    vertexToDop);\n\n    failed.reportFailedCheckpoint(12, null);\n\n        \n    PendingCheckpointStats savepoint =\n            tracker.reportPendingCheckpoint(\n                    2, 1, CheckpointProperties.forSavepoint(true), vertexToDop);\n\n    savepoint.reportSubtaskStats(jobVertexID, createSubtaskStats(0));\n    savepoint.reportSubtaskStats(jobVertexID, createSubtaskStats(1));\n    savepoint.reportSubtaskStats(jobVertexID, createSubtaskStats(2));\n\n    savepoint.reportCompletedCheckpoint(null);\n\n        \n    PendingCheckpointStats inProgress =\n            tracker.reportPendingCheckpoint(\n                    3,\n                    1,\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    vertexToDop);\n\n    RestoredCheckpointStats restored =\n            new RestoredCheckpointStats(\n                    81,\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    123,\n                    null);\n    tracker.reportRestoredCheckpoint(restored);\n\n    CheckpointStatsSnapshot snapshot = tracker.createSnapshot();\n\n        \n    CheckpointStatsCounts counts = snapshot.getCounts();\n    assertEquals(4, counts.getTotalNumberOfCheckpoints());\n    assertEquals(1, counts.getNumberOfInProgressCheckpoints());\n    assertEquals(2, counts.getNumberOfCompletedCheckpoints());\n    assertEquals(1, counts.getNumberOfFailedCheckpoints());\n\n        \n    CompletedCheckpointStatsSummarySnapshot summary = snapshot.getSummaryStats();\n    assertEquals(2, summary.getStateSizeStats().getCount());\n    assertEquals(2, summary.getEndToEndDurationStats().getCount());\n\n        \n    CheckpointStatsHistory history = snapshot.getHistory();\n    Iterator<AbstractCheckpointStats> it = history.getCheckpoints().iterator();\n\n    assertTrue(it.hasNext());\n    AbstractCheckpointStats stats = it.next();\n    assertEquals(3, stats.getCheckpointId());\n    assertTrue(stats.getStatus().isInProgress());\n\n    assertTrue(it.hasNext());\n    stats = it.next();\n    assertEquals(2, stats.getCheckpointId());\n    assertTrue(stats.getStatus().isCompleted());\n\n    assertTrue(it.hasNext());\n    stats = it.next();\n    assertEquals(1, stats.getCheckpointId());\n    assertTrue(stats.getStatus().isFailed());\n\n    assertTrue(it.hasNext());\n    stats = it.next();\n    assertEquals(0, stats.getCheckpointId());\n    assertTrue(stats.getStatus().isCompleted());\n\n    assertFalse(it.hasNext());\n\n        \n    assertEquals(\n            completed1.getCheckpointId(),\n            snapshot.getHistory().getLatestCompletedCheckpoint().getCheckpointId());\n    assertEquals(\n            savepoint.getCheckpointId(),\n            snapshot.getHistory().getLatestSavepoint().getCheckpointId());\n    assertEquals(\n            failed.getCheckpointId(),\n            snapshot.getHistory().getLatestFailedCheckpoint().getCheckpointId());\n    assertEquals(restored, snapshot.getLatestRestoredCheckpoint());\n}", "summary_tokens": ["tests", "tracking", "of", "checkpoints"], "project": "flink"}
{"id": 8782, "code": "private SqlNode getNthExpr(SqlNode query, int ordinal, int sourceCount) {\n    if (query instanceof SqlInsert) {\n        SqlInsert insert = (SqlInsert) query;\n        if (insert.getTargetColumnList() != null) {\n            return insert.getTargetColumnList().get(ordinal);\n        } else {\n            return getNthExpr(insert.getSource(), ordinal, sourceCount);\n        }\n    } else if (query instanceof SqlUpdate) {\n        SqlUpdate update = (SqlUpdate) query;\n        if (update.getSourceExpressionList() != null) {\n            return update.getSourceExpressionList().get(ordinal);\n        } else {\n            return getNthExpr(update.getSourceSelect(), ordinal, sourceCount);\n        }\n    } else if (query instanceof SqlSelect) {\n        SqlSelect select = (SqlSelect) query;\n        if (select.getSelectList().size() == sourceCount) {\n            return select.getSelectList().get(ordinal);\n        } else {\n            return query; \n        }\n    } else {\n        return query; \n    }\n}", "summary_tokens": ["locates", "the", "n", "th", "expression", "in", "an", "insert", "or", "update", "query"], "project": "flink"}
{"id": 8756, "code": "RelDataType deriveTypeImpl(SqlValidatorScope scope, SqlNode operand) {\n    DeriveTypeVisitor v = new DeriveTypeVisitor(scope);\n    final RelDataType type = operand.accept(v);\n    return Objects.requireNonNull(scope.nullifyType(operand, type));\n}", "summary_tokens": ["derives", "the", "type", "of", "a", "node", "never", "null"], "project": "flink"}
{"id": 3593, "code": "public PartialSolutionPlaceHolder<?> getOperator() {\n    return (PartialSolutionPlaceHolder<?>) super.getOperator();\n}", "summary_tokens": ["gets", "the", "operator", "here", "the", "partial", "solution", "place", "holder", "that", "is", "represented", "by", "this", "optimizer", "node"], "project": "flink"}
{"id": 2799, "code": "public Partitioner<?> getCustomPartitioner() {\n    return customPartitioner;\n}", "summary_tokens": ["gets", "the", "custom", "partitioner", "from", "this", "partitioning"], "project": "flink"}
{"id": 5628, "code": "public static Configuration loadCommonConfiguration(String[] args, String cmdLineSyntax)\n        throws FlinkParseException {\n    final CommandLineParser<ClusterConfiguration> commandLineParser =\n            new CommandLineParser<>(new ClusterConfigurationParserFactory());\n\n    final ClusterConfiguration clusterConfiguration;\n\n    try {\n        clusterConfiguration = commandLineParser.parse(args);\n    } catch (FlinkParseException e) {\n        LOG.error(\"Could not parse the command line options.\", e);\n        commandLineParser.printHelp(cmdLineSyntax);\n        throw e;\n    }\n\n    final Configuration dynamicProperties =\n            ConfigurationUtils.createConfiguration(clusterConfiguration.getDynamicProperties());\n    return GlobalConfiguration.loadConfiguration(\n            clusterConfiguration.getConfigDir(), dynamicProperties);\n}", "summary_tokens": ["generate", "configuration", "from", "only", "the", "config", "file", "and", "dynamic", "properties"], "project": "flink"}
{"id": 5517, "code": "public int getMaxStateSize() {\n    return maxStateSize;\n}", "summary_tokens": ["gets", "the", "maximum", "size", "that", "an", "individual", "state", "can", "have", "as", "configured", "in", "the", "constructor", "by", "default", "default", "max", "state", "size"], "project": "flink"}
{"id": 2265, "code": "public static FlinkContainersBuilder builder() {\n    return new FlinkContainersBuilder();\n}", "summary_tokens": ["creates", "a", "builder", "for", "flink", "containers"], "project": "flink"}
{"id": 8646, "code": "public static RowType toRowType(LogicalType t) {\n    switch (t.getTypeRoot()) {\n        case ROW:\n            return (RowType) t;\n        case STRUCTURED_TYPE:\n            final StructuredType structuredType = (StructuredType) t;\n            final List<RowField> fields =\n                    structuredType.getAttributes().stream()\n                            .map(\n                                    attribute ->\n                                            new RowField(\n                                                    attribute.getName(),\n                                                    attribute.getType(),\n                                                    attribute.getDescription().orElse(null)))\n                            .collect(Collectors.toList());\n            return new RowType(structuredType.isNullable(), fields);\n        case DISTINCT_TYPE:\n            return toRowType(((DistinctType) t).getSourceType());\n        default:\n            return RowType.of(t);\n    }\n}", "summary_tokens": ["converts", "any", "logical", "type", "to", "a", "row", "type"], "project": "flink"}
{"id": 278, "code": "private void coordinate(long checkpointId, Map<String, List<Path>> partFiles) {\n    Function<Path, Long> sizeFunc =\n            path -> {\n                try {\n                    return fileSystem.getFileStatus(path).getLen();\n                } catch (IOException e) {\n                    throw new UncheckedIOException(e);\n                }\n            };\n\n        \n    Map<String, List<List<Path>>> compactUnits = new HashMap<>();\n    partFiles.forEach(\n            (p, files) -> {\n                    \n                files.sort(Comparator.comparing(Path::getPath));\n                compactUnits.put(p, BinPacking.pack(files, sizeFunc, targetFileSize));\n            });\n\n        \n        \n        \n    int unitId = 0;\n    for (Map.Entry<String, List<List<Path>>> unitsEntry : compactUnits.entrySet()) {\n        String partition = unitsEntry.getKey();\n        for (List<Path> unit : unitsEntry.getValue()) {\n            output.collect(new StreamRecord<>(new CompactionUnit(unitId, partition, unit)));\n            unitId++;\n        }\n    }\n\n    LOG.debug(\"Coordinate checkpoint-{}, compaction units are: {}\", checkpointId, compactUnits);\n\n        \n    output.collect(new StreamRecord<>(new EndCompaction(checkpointId)));\n}", "summary_tokens": ["do", "stable", "compaction", "coordination"], "project": "flink"}
{"id": 1722, "code": "public long getStreamInactivityTimeout() {\n    return streamInactivityTimeoutNanos / 1_000_000;\n}", "summary_tokens": ["gets", "the", "milliseconds", "that", "a", "stream", "may", "spend", "not", "writing", "any", "bytes", "before", "it", "is", "closed", "as", "inactive"], "project": "flink"}
{"id": 2717, "code": "public static String getExecutionPlanAsJSON(Plan plan) {\n    checkNotNull(plan);\n    ExecutionPlanJSONGenerator jsonGenerator = getJSONGenerator();\n    return jsonGenerator.getExecutionPlan(plan);\n}", "summary_tokens": ["extracts", "the", "execution", "plan", "as", "json", "from", "the", "given", "plan"], "project": "flink"}
{"id": 2888, "code": "public Option choices(String... choices) throws RequiredParametersException {\n    if (this.defaultValue != null) {\n        if (Arrays.asList(choices).contains(defaultValue)) {\n            Collections.addAll(this.choices, choices);\n        } else {\n            throw new RequiredParametersException(\n                    \"Valid values for option \"\n                            + this.longName\n                            + \" do not contain defined default value \"\n                            + defaultValue);\n        }\n    } else {\n        Collections.addAll(this.choices, choices);\n    }\n    return this;\n}", "summary_tokens": ["restrict", "the", "list", "of", "possible", "values", "of", "the", "parameter"], "project": "flink"}
{"id": 784, "code": "public double getSubscribeToShardExpConstant() {\n    return subscribeToShardExpConstant;\n}", "summary_tokens": ["get", "exponential", "backoff", "power", "constant", "for", "the", "subscribe", "to", "shard", "operation"], "project": "flink"}
{"id": 6816, "code": "static void buildLevelIndex(\n        long node,\n        int level,\n        MemorySegment keySegment,\n        int keyOffset,\n        LevelIndexHeader levelIndexHeader,\n        Allocator spaceAllocator) {\n    int currLevel = level;\n    long prevNode =\n            findPredecessor(keySegment, keyOffset, currLevel, levelIndexHeader, spaceAllocator);\n    long currentNode = helpGetNextNode(prevNode, currLevel, levelIndexHeader, spaceAllocator);\n\n    for (; ; ) {\n        if (currentNode != NIL_NODE) {\n            int c = compareSegmentAndNode(keySegment, keyOffset, currentNode, spaceAllocator);\n            if (c > 0) {\n                prevNode = currentNode;\n                currentNode =\n                        helpGetNextNode(\n                                currentNode, currLevel, levelIndexHeader, spaceAllocator);\n                continue;\n            }\n        }\n\n        helpSetPrevAndNextNode(node, prevNode, currentNode, currLevel, spaceAllocator);\n        helpSetNextNode(prevNode, node, currLevel, levelIndexHeader, spaceAllocator);\n        helpSetPrevNode(currentNode, node, currLevel, spaceAllocator);\n\n        currLevel--;\n        if (currLevel == 0) {\n            break;\n        }\n\n        currentNode = helpGetNextNode(prevNode, currLevel, levelIndexHeader, spaceAllocator);\n    }\n}", "summary_tokens": ["build", "the", "level", "index", "for", "the", "given", "node"], "project": "flink"}
{"id": 3373, "code": "public void setInput(DataSet<Vertex<K, VV>> inputData) {\n    this.initialVertices = inputData;\n}", "summary_tokens": ["sets", "the", "input", "data", "set", "for", "this", "operator"], "project": "flink"}
{"id": 2967, "code": "public void testSystemProperties() {\n    System.setProperty(\"input\", \"myInput\");\n    System.setProperty(\"expectedCount\", \"15\");\n    ParameterTool parameter = ParameterTool.fromSystemProperties();\n    validate(parameter);\n}", "summary_tokens": ["this", "is", "mainly", "meant", "to", "be", "used", "with", "d", "arguments", "against", "the", "jvm"], "project": "flink"}
{"id": 9421, "code": "public void free(boolean reservedRecordMemory) {\n    recordArea.release();\n    destructiveIterator = null;\n    super.free(reservedRecordMemory);\n}", "summary_tokens": ["reserved", "record", "memory", "reserved", "fixed", "memory", "or", "not"], "project": "flink"}
{"id": 5280, "code": "static void enrichNetworkMemory(\n        SlotSharingGroup ssg,\n        Function<JobVertexID, ExecutionJobVertex> ejvs,\n        ShuffleMaster<?> shuffleMaster) {\n\n    ResourceProfile original = ssg.getResourceProfile();\n\n        \n        \n    if (original.equals(ResourceProfile.UNKNOWN)\n            || !original.getNetworkMemory().equals(MemorySize.ZERO)) {\n        return;\n    }\n\n    MemorySize networkMemory = MemorySize.ZERO;\n    for (JobVertexID jvId : ssg.getJobVertexIds()) {\n        ExecutionJobVertex ejv = ejvs.apply(jvId);\n        TaskInputsOutputsDescriptor desc = buildTaskInputsOutputsDescriptor(ejv, ejvs);\n        MemorySize requiredNetworkMemory = shuffleMaster.computeShuffleMemorySizeForTask(desc);\n        networkMemory = networkMemory.add(requiredNetworkMemory);\n    }\n\n    ResourceProfile enriched =\n            ResourceProfile.newBuilder()\n                    .setCpuCores(original.getCpuCores())\n                    .setTaskHeapMemory(original.getTaskHeapMemory())\n                    .setTaskOffHeapMemory(original.getTaskOffHeapMemory())\n                    .setManagedMemory(original.getManagedMemory())\n                    .setNetworkMemory(networkMemory)\n                    .setExtendedResources(original.getExtendedResources().values())\n                    .build();\n    ssg.setResourceProfile(enriched);\n}", "summary_tokens": ["calculates", "network", "memory", "requirement", "of", "execution", "job", "vertex", "and", "update", "resource", "profile", "of", "corresponding", "slot", "sharing", "group"], "project": "flink"}
{"id": 1483, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple15)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple15 tuple = (Tuple15) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    if (f5 != null ? !f5.equals(tuple.f5) : tuple.f5 != null) {\n        return false;\n    }\n    if (f6 != null ? !f6.equals(tuple.f6) : tuple.f6 != null) {\n        return false;\n    }\n    if (f7 != null ? !f7.equals(tuple.f7) : tuple.f7 != null) {\n        return false;\n    }\n    if (f8 != null ? !f8.equals(tuple.f8) : tuple.f8 != null) {\n        return false;\n    }\n    if (f9 != null ? !f9.equals(tuple.f9) : tuple.f9 != null) {\n        return false;\n    }\n    if (f10 != null ? !f10.equals(tuple.f10) : tuple.f10 != null) {\n        return false;\n    }\n    if (f11 != null ? !f11.equals(tuple.f11) : tuple.f11 != null) {\n        return false;\n    }\n    if (f12 != null ? !f12.equals(tuple.f12) : tuple.f12 != null) {\n        return false;\n    }\n    if (f13 != null ? !f13.equals(tuple.f13) : tuple.f13 != null) {\n        return false;\n    }\n    if (f14 != null ? !f14.equals(tuple.f14) : tuple.f14 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 684, "code": "public void runCommitOffsetsToKafka() throws Exception {\n        \n        \n    final int parallelism = 3;\n    final int recordsInEachPartition = 50;\n\n    final String topicName =\n            writeSequence(\n                    \"testCommitOffsetsToKafkaTopic\", recordsInEachPartition, parallelism, 1);\n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.getConfig().setRestartStrategy(RestartStrategies.noRestart());\n    env.setParallelism(parallelism);\n    env.enableCheckpointing(200);\n\n    DataStream<String> stream =\n            getStream(env, topicName, new SimpleStringSchema(), standardProps);\n    stream.addSink(new DiscardingSink<String>());\n\n    final AtomicReference<Throwable> errorRef = new AtomicReference<>();\n    final Thread runner =\n            new Thread(\"runner\") {\n                @Override\n                public void run() {\n                    try {\n                        env.execute();\n                    } catch (Throwable t) {\n                        if (!(t instanceof JobCancellationException)) {\n                            errorRef.set(t);\n                        }\n                    }\n                }\n            };\n    runner.start();\n\n    final Long l50 = 50L; \n    final long deadline = 30_000_000_000L + System.nanoTime();\n\n    KafkaTestEnvironment.KafkaOffsetHandler kafkaOffsetHandler =\n            kafkaServer.createOffsetHandler();\n\n    do {\n        Long o1 = kafkaOffsetHandler.getCommittedOffset(topicName, 0);\n        Long o2 = kafkaOffsetHandler.getCommittedOffset(topicName, 1);\n        Long o3 = kafkaOffsetHandler.getCommittedOffset(topicName, 2);\n\n        if (l50.equals(o1) && l50.equals(o2) && l50.equals(o3)) {\n            break;\n        }\n\n        Thread.sleep(100);\n    } while (System.nanoTime() < deadline);\n\n        \n    client.cancel(Iterables.getOnlyElement(getRunningJobs(client))).get();\n    runner.join();\n\n    final Throwable t = errorRef.get();\n    if (t != null) {\n        throw new RuntimeException(\"Job failed with an exception\", t);\n    }\n\n        \n    Long o1 = kafkaOffsetHandler.getCommittedOffset(topicName, 0);\n    Long o2 = kafkaOffsetHandler.getCommittedOffset(topicName, 1);\n    Long o3 = kafkaOffsetHandler.getCommittedOffset(topicName, 2);\n    Assert.assertEquals(Long.valueOf(50L), o1);\n    Assert.assertEquals(Long.valueOf(50L), o2);\n    Assert.assertEquals(Long.valueOf(50L), o3);\n\n    kafkaOffsetHandler.close();\n    deleteTestTopic(topicName);\n}", "summary_tokens": ["ensures", "that", "the", "committed", "offsets", "to", "kafka", "are", "the", "offsets", "of", "the", "next", "record", "to", "process"], "project": "flink"}
{"id": 1424, "code": "public int getId() {\n    return id;\n}", "summary_tokens": ["returns", "the", "unique", "id", "of", "this", "transformation"], "project": "flink"}
{"id": 1252, "code": "public UserCodeWrapper<?> getUserCodeWrapper() {\n    return null;\n}", "summary_tokens": ["gets", "the", "user", "code", "wrapper"], "project": "flink"}
{"id": 6492, "code": "public void testFileCacheExpiration() throws Exception {\n    final Time cacheEntryDuration = Time.milliseconds(5L);\n\n    final File outputFile = runFileCachingTest(cacheEntryDuration, cacheEntryDuration);\n\n    assertThat(outputFile.length(), is(greaterThan(0L)));\n    assertThat(FileUtils.readFileUtf8(outputFile), is(equalTo(fileContent2)));\n}", "summary_tokens": ["tests", "that", "file", "cache", "entries", "expire"], "project": "flink"}
{"id": 9504, "code": "public static <T, E extends Throwable> FutureFailedMatcher<T> futureFailedWith(\n        Class<E> exceptionType) {\n    Objects.requireNonNull(exceptionType, \"exceptionType should not be null\");\n    return new FutureFailedMatcher<>(exceptionType);\n}", "summary_tokens": ["checks", "whether", "completable", "future", "completed", "already", "exceptionally", "with", "a", "specific", "exception", "type"], "project": "flink"}
{"id": 6089, "code": "public void testHeartbeatCluster() throws Exception {\n    ResourceID resourceIdTarget = new ResourceID(\"foobar\");\n    ResourceID resourceIDSender = new ResourceID(\"barfoo\");\n    final int targetPayload = 42;\n    final AtomicInteger numReportPayloadCallsTarget = new AtomicInteger(0);\n    final TestingHeartbeatListener<String, Integer> heartbeatListenerTarget =\n            new TestingHeartbeatListenerBuilder<String, Integer>()\n                    .setRetrievePayloadFunction(ignored -> targetPayload)\n                    .setReportPayloadConsumer(\n                            (ignoredA, ignoredB) ->\n                                    numReportPayloadCallsTarget.incrementAndGet())\n                    .createNewTestingHeartbeatListener();\n\n    final String senderPayload = \"1337\";\n    final CompletableFuture<ResourceID> targetHeartbeatTimeoutFuture =\n            new CompletableFuture<>();\n    final AtomicInteger numReportPayloadCallsSender = new AtomicInteger(0);\n    final TestingHeartbeatListener<Integer, String> heartbeatListenerSender =\n            new TestingHeartbeatListenerBuilder<Integer, String>()\n                    .setRetrievePayloadFunction(ignored -> senderPayload)\n                    .setNotifyHeartbeatTimeoutConsumer(targetHeartbeatTimeoutFuture::complete)\n                    .setReportPayloadConsumer(\n                            (ignoredA, ignoredB) ->\n                                    numReportPayloadCallsSender.incrementAndGet())\n                    .createNewTestingHeartbeatListener();\n\n    HeartbeatManagerImpl<String, Integer> heartbeatManagerTarget =\n            new HeartbeatManagerImpl<>(\n                    HEARTBEAT_TIMEOUT,\n                    FAILED_RPC_THRESHOLD,\n                    resourceIdTarget,\n                    heartbeatListenerTarget,\n                    TestingUtils.defaultScheduledExecutor(),\n                    LOG);\n\n    HeartbeatManagerSenderImpl<Integer, String> heartbeatManagerSender =\n            new HeartbeatManagerSenderImpl<>(\n                    HEARTBEAT_INTERVAL,\n                    HEARTBEAT_TIMEOUT,\n                    FAILED_RPC_THRESHOLD,\n                    resourceIDSender,\n                    heartbeatListenerSender,\n                    TestingUtils.defaultScheduledExecutor(),\n                    LOG);\n\n    heartbeatManagerTarget.monitorTarget(resourceIDSender, heartbeatManagerSender);\n    heartbeatManagerSender.monitorTarget(resourceIdTarget, heartbeatManagerTarget);\n\n    Thread.sleep(2 * HEARTBEAT_TIMEOUT);\n\n    assertFalse(targetHeartbeatTimeoutFuture.isDone());\n\n    heartbeatManagerTarget.stop();\n\n    ResourceID timeoutResourceID =\n            targetHeartbeatTimeoutFuture.get(2 * HEARTBEAT_TIMEOUT, TimeUnit.MILLISECONDS);\n\n    assertThat(timeoutResourceID, is(resourceIdTarget));\n\n    int numberHeartbeats = (int) (2 * HEARTBEAT_TIMEOUT / HEARTBEAT_INTERVAL);\n\n    final Matcher<Integer> numberHeartbeatsMatcher = greaterThanOrEqualTo(numberHeartbeats / 2);\n    assertThat(numReportPayloadCallsTarget.get(), is(numberHeartbeatsMatcher));\n    assertThat(numReportPayloadCallsSender.get(), is(numberHeartbeatsMatcher));\n}", "summary_tokens": ["tests", "the", "heartbeat", "interplay", "between", "the", "heartbeat", "manager", "impl", "and", "the", "heartbeat", "manager", "sender", "impl"], "project": "flink"}
{"id": 7854, "code": "public void testEarlyCanceling() throws Exception {\n    final StreamConfig cfg = new StreamConfig(new Configuration());\n    cfg.setOperatorID(new OperatorID(4711L, 42L));\n    cfg.setStreamOperator(new SlowlyDeserializingOperator());\n    cfg.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);\n\n    final TaskManagerActions taskManagerActions = spy(new NoOpTaskManagerActions());\n    try (NettyShuffleEnvironment shuffleEnvironment =\n            new NettyShuffleEnvironmentBuilder().build()) {\n        final Task task =\n                new TestTaskBuilder(shuffleEnvironment)\n                        .setInvokable(SourceStreamTask.class)\n                        .setTaskConfig(cfg.getConfiguration())\n                        .setTaskManagerActions(taskManagerActions)\n                        .build();\n\n        final TaskExecutionState state =\n                new TaskExecutionState(task.getExecutionId(), ExecutionState.RUNNING);\n\n        task.startTaskThread();\n\n        verify(taskManagerActions, timeout(2000L)).updateTaskExecutionState(eq(state));\n\n            \n            \n        task.cancelExecution();\n\n        task.getExecutingThread().join();\n\n        assertFalse(\"Task did not cancel\", task.getExecutingThread().isAlive());\n        assertEquals(ExecutionState.CANCELED, task.getExecutionState());\n    }\n}", "summary_tokens": ["this", "test", "checks", "that", "cancel", "calls", "that", "are", "issued", "before", "the", "operator", "is", "instantiated", "still", "lead", "to", "proper", "canceling"], "project": "flink"}
{"id": 1887, "code": "static int deepHashCodeRow(\n        RowKind kind,\n        @Nullable Object[] fieldByPosition,\n        @Nullable Map<String, Object> fieldByName) {\n    int result = kind.toByteValue(); \n    if (fieldByPosition != null) {\n            \n        result = 31 * result + deepHashCodeInternal(fieldByPosition);\n    } else {\n        result = 31 * result + deepHashCodeInternal(fieldByName);\n    }\n    return result;\n}", "summary_tokens": ["hashes", "two", "objects", "with", "proper", "nested", "equality", "semantics"], "project": "flink"}
{"id": 6113, "code": "public void channelSelect() {\n    final StringValue dummyRecord = new StringValue(\"abc\");\n    final RoundRobinChannelSelector<StringValue> selector = new RoundRobinChannelSelector<>();\n    selector.setup(2);\n\n    assertSelectedChannel(selector, dummyRecord, 0);\n    assertSelectedChannel(selector, dummyRecord, 1);\n}", "summary_tokens": ["this", "test", "checks", "the", "channel", "selection"], "project": "flink"}
{"id": 9365, "code": "public Comparator<K> getComparator() {\n    return comparator;\n}", "summary_tokens": ["returns", "the", "comparator", "for", "the", "keys", "in", "the", "map"], "project": "flink"}
{"id": 4869, "code": "void reserveMemory(long size) throws MemoryReservationException {\n    long availableOrReserved = tryReserveMemory(size);\n        \n    if (availableOrReserved >= size) {\n        return;\n    }\n        \n    throw new MemoryReservationException(\n            String.format(\n                    \"Could not allocate %d bytes, only %d bytes are remaining. This usually indicates \"\n                            + \"that you are requesting more memory than you have reserved. \"\n                            + \"However, when running an old JVM version it can also be caused by slow garbage collection. \"\n                            + \"Try to upgrade to Java 8u72 or higher if running on an old Java version.\",\n                    size, availableOrReserved));\n}", "summary_tokens": ["reserve", "memory", "of", "certain", "size", "if", "it", "is", "available"], "project": "flink"}
{"id": 4229, "code": "private boolean hasActiveUpstreamVertex(\n        DistributionPattern distribution, BitSet upstreamRunningTasks) {\n    return (distribution == DistributionPattern.ALL_TO_ALL\n                    && upstreamRunningTasks.cardinality() > 0)\n            || (distribution == DistributionPattern.POINTWISE\n                    && upstreamRunningTasks.cardinality() == upstreamRunningTasks.size());\n}", "summary_tokens": ["every", "task", "must", "have", "active", "upstream", "tasks", "if"], "project": "flink"}
{"id": 2554, "code": "private Map<String, String> getModifyOptions(Consumer<Map<String, String>> optionModifier) {\n    Map<String, String> options = getAllOptions();\n    optionModifier.accept(options);\n    return options;\n}", "summary_tokens": ["returns", "the", "full", "options", "modified", "by", "the", "given", "consumer", "option", "modifier"], "project": "flink"}
{"id": 4861, "code": "public long availableMemory() {\n    return memoryBudget.getAvailableMemorySize();\n}", "summary_tokens": ["returns", "the", "available", "amount", "of", "memory", "handled", "by", "this", "memory", "manager"], "project": "flink"}
{"id": 9592, "code": "public void testLocalEnvironmentWithConfig() throws Exception {\n    Configuration conf = new Configuration();\n    conf.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, PARALLELISM);\n\n    final ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment(conf);\n\n    DataSet<Integer> result =\n            env.createInput(new ParallelismDependentInputFormat())\n                    .rebalance()\n                    .mapPartition(\n                            new RichMapPartitionFunction<Integer, Integer>() {\n                                @Override\n                                public void mapPartition(\n                                        Iterable<Integer> values, Collector<Integer> out)\n                                        throws Exception {\n                                    out.collect(getRuntimeContext().getIndexOfThisSubtask());\n                                }\n                            });\n    List<Integer> resultCollection = result.collect();\n    assertEquals(PARALLELISM, resultCollection.size());\n}", "summary_tokens": ["ensure", "that", "the", "user", "can", "pass", "a", "custom", "configuration", "object", "to", "the", "local", "environment"], "project": "flink"}
{"id": 1408, "code": "public static <T> void writeSerializerSnapshot(\n        DataOutputView out,\n        TypeSerializerSnapshot<T> serializerSnapshot,\n        TypeSerializer<T> serializer)\n        throws IOException {\n\n    new TypeSerializerSnapshotSerializationProxy<>(serializerSnapshot, serializer).write(out);\n}", "summary_tokens": ["writes", "a", "type", "serializer", "snapshot", "to", "the", "provided", "data", "output", "view"], "project": "flink"}
{"id": 3296, "code": "public void setInput(DataSet<Vertex<K, VV>> dataSet) {\n    this.vertexDataSet = dataSet;\n}", "summary_tokens": ["sets", "the", "input", "data", "set", "for", "this", "operator"], "project": "flink"}
{"id": 773, "code": "private boolean isRunning() {\n    return !Thread.interrupted() && fetcherRef.isRunning();\n}", "summary_tokens": ["the", "loop", "in", "run", "checks", "this", "before", "fetching", "next", "batch", "of", "records"], "project": "flink"}
{"id": 6071, "code": "public void testRegionFailoverForDataConsumptionErrors() throws Exception {\n    TestingSchedulingTopology topology = new TestingSchedulingTopology();\n\n    TestingSchedulingExecutionVertex v1 = topology.newExecutionVertex(ExecutionState.FINISHED);\n    TestingSchedulingExecutionVertex v2 = topology.newExecutionVertex(ExecutionState.FINISHED);\n    TestingSchedulingExecutionVertex v3 = topology.newExecutionVertex(ExecutionState.FINISHED);\n    TestingSchedulingExecutionVertex v4 = topology.newExecutionVertex(ExecutionState.RUNNING);\n    TestingSchedulingExecutionVertex v5 = topology.newExecutionVertex(ExecutionState.RUNNING);\n    TestingSchedulingExecutionVertex v6 = topology.newExecutionVertex(ExecutionState.RUNNING);\n\n    topology.connect(v1, v4, ResultPartitionType.BLOCKING);\n    topology.connect(v1, v5, ResultPartitionType.BLOCKING);\n    topology.connect(v2, v4, ResultPartitionType.BLOCKING);\n    topology.connect(v2, v5, ResultPartitionType.BLOCKING);\n    topology.connect(v3, v6, ResultPartitionType.BLOCKING);\n\n    RestartPipelinedRegionFailoverStrategy strategy =\n            new RestartPipelinedRegionFailoverStrategy(topology);\n\n    Iterator<TestingSchedulingResultPartition> v4InputEdgeIterator =\n            v4.getConsumedResults().iterator();\n    TestingSchedulingResultPartition v1out = v4InputEdgeIterator.next();\n    verifyThatFailedExecution(strategy, v4)\n            .partitionConnectionCause(v1out)\n            .restarts(v1, v4, v5);\n    TestingSchedulingResultPartition v2out = v4InputEdgeIterator.next();\n    verifyThatFailedExecution(strategy, v4)\n            .partitionConnectionCause(v2out)\n            .restarts(v2, v4, v5);\n\n    Iterator<TestingSchedulingResultPartition> v5InputEdgeIterator =\n            v5.getConsumedResults().iterator();\n    v1out = v5InputEdgeIterator.next();\n    verifyThatFailedExecution(strategy, v5)\n            .partitionConnectionCause(v1out)\n            .restarts(v1, v4, v5);\n    v2out = v5InputEdgeIterator.next();\n    verifyThatFailedExecution(strategy, v5)\n            .partitionConnectionCause(v2out)\n            .restarts(v2, v4, v5);\n\n    TestingSchedulingResultPartition v3out = v6.getConsumedResults().iterator().next();\n    verifyThatFailedExecution(strategy, v6).partitionConnectionCause(v3out).restarts(v3, v6);\n}", "summary_tokens": ["tests", "for", "scenes", "that", "a", "task", "fails", "for", "data", "consumption", "error", "in", "which", "case", "the", "region", "containing", "the", "failed", "task", "the", "region", "containing", "the", "unavailable", "result", "partition", "and", "all", "their", "consumer", "regions", "should", "be", "restarted"], "project": "flink"}
{"id": 1651, "code": "public void addAll(Configuration other, String prefix) {\n    final StringBuilder bld = new StringBuilder();\n    bld.append(prefix);\n    final int pl = bld.length();\n\n    synchronized (this.confData) {\n        synchronized (other.confData) {\n            for (Map.Entry<String, Object> entry : other.confData.entrySet()) {\n                bld.setLength(pl);\n                bld.append(entry.getKey());\n                this.confData.put(bld.toString(), entry.getValue());\n            }\n        }\n    }\n}", "summary_tokens": ["adds", "all", "entries", "from", "the", "given", "configuration", "into", "this", "configuration"], "project": "flink"}
{"id": 7519, "code": "int getLongestChainLength() {\n    int maxLen = 0;\n\n    for (Entry<?, ?> entry : table) {\n        int thisLen = 0;\n        while (entry != null) {\n            thisLen++;\n            entry = entry.next;\n        }\n        maxLen = Math.max(maxLen, thisLen);\n    }\n\n    return maxLen;\n}", "summary_tokens": ["for", "testing", "only", "gets", "the", "length", "of", "the", "longest", "overflow", "chain"], "project": "flink"}
{"id": 494, "code": "public <T extends IN> KafkaRecordSerializationSchemaBuilder<T> setTopicSelector(\n        TopicSelector<? super T> topicSelector) {\n    checkState(this.topicSelector == null, \"Topic selector already set.\");\n    KafkaRecordSerializationSchemaBuilder<T> self = self();\n    self.topicSelector = new CachingTopicSelector<>(checkNotNull(topicSelector));\n    return self;\n}", "summary_tokens": ["sets", "a", "topic", "selector", "which", "computes", "the", "target", "topic", "for", "every", "incoming", "record"], "project": "flink"}
{"id": 4871, "code": "public static Optional<ThreadInfoSample> from(@Nullable ThreadInfo threadInfo) {\n    if (threadInfo != null) {\n        return Optional.of(\n                new ThreadInfoSample(threadInfo.getThreadState(), threadInfo.getStackTrace()));\n    } else {\n        return Optional.empty();\n    }\n}", "summary_tokens": ["constructs", "a", "thread", "info", "sample", "from", "thread", "info"], "project": "flink"}
{"id": 8550, "code": "public static Class<?> wrapperToPrimitive(final Class<?> cls) {\n    return wrapperPrimitiveMap.get(cls);\n}", "summary_tokens": ["converts", "the", "specified", "wrapper", "class", "to", "its", "corresponding", "primitive", "class"], "project": "flink"}
{"id": 1756, "code": "public byte[] getSharedBuffer() {\n    return buffer;\n}", "summary_tokens": ["gets", "a", "reference", "to", "the", "internal", "byte", "buffer"], "project": "flink"}
{"id": 5528, "code": "public int numProxyQueryThreads() {\n    return numPQueryThreads;\n}", "summary_tokens": ["returns", "the", "number", "of", "query", "threads", "for", "the", "queryable", "state", "client", "proxy"], "project": "flink"}
{"id": 4162, "code": "public long getTriggerTimestamp() {\n    return triggerTimestamp;\n}", "summary_tokens": ["returns", "the", "timestamp", "when", "the", "checkpoint", "was", "triggered"], "project": "flink"}
{"id": 1635, "code": "public int getInteger(ConfigOption<Integer> configOption, int overrideDefault) {\n    return getOptional(configOption).orElse(overrideDefault);\n}", "summary_tokens": ["returns", "the", "value", "associated", "with", "the", "given", "config", "option", "as", "an", "integer"], "project": "flink"}
{"id": 4776, "code": "public int getNumberOfProducedIntermediateDataSets() {\n    return this.results.size();\n}", "summary_tokens": ["returns", "the", "number", "of", "produced", "intermediate", "data", "sets"], "project": "flink"}
{"id": 3788, "code": "public static <T> T release(final Resource<T> resource, final T instance) {\n    return holder.releaseInternal(resource, instance);\n}", "summary_tokens": ["releases", "an", "instance", "of", "the", "given", "resource"], "project": "flink"}
{"id": 636, "code": "public static int[] createValueFormatProjection(\n        ReadableConfig options, DataType physicalDataType) {\n    final LogicalType physicalType = physicalDataType.getLogicalType();\n    Preconditions.checkArgument(\n            physicalType.is(LogicalTypeRoot.ROW), \"Row data type expected.\");\n    final int physicalFieldCount = LogicalTypeChecks.getFieldCount(physicalType);\n    final IntStream physicalFields = IntStream.range(0, physicalFieldCount);\n\n    final String keyPrefix = options.getOptional(KEY_FIELDS_PREFIX).orElse(\"\");\n\n    final ValueFieldsStrategy strategy = options.get(VALUE_FIELDS_INCLUDE);\n    if (strategy == ValueFieldsStrategy.ALL) {\n        if (keyPrefix.length() > 0) {\n            throw new ValidationException(\n                    String.format(\n                            \"A key prefix is not allowed when option '%s' is set to '%s'. \"\n                                    + \"Set it to '%s' instead to avoid field overlaps.\",\n                            VALUE_FIELDS_INCLUDE.key(),\n                            ValueFieldsStrategy.ALL,\n                            ValueFieldsStrategy.EXCEPT_KEY));\n        }\n        return physicalFields.toArray();\n    } else if (strategy == ValueFieldsStrategy.EXCEPT_KEY) {\n        final int[] keyProjection = createKeyFormatProjection(options, physicalDataType);\n        return physicalFields\n                .filter(pos -> IntStream.of(keyProjection).noneMatch(k -> k == pos))\n                .toArray();\n    }\n    throw new TableException(\"Unknown value fields strategy:\" + strategy);\n}", "summary_tokens": ["creates", "an", "array", "of", "indices", "that", "determine", "which", "physical", "fields", "of", "the", "table", "schema", "to", "include", "in", "the", "value", "format"], "project": "flink"}
{"id": 1718, "code": "public int getMaxNumOpenOutputStreams() {\n    return maxNumOpenOutputStreams;\n}", "summary_tokens": ["gets", "the", "maximum", "number", "of", "concurrently", "open", "output", "streams"], "project": "flink"}
{"id": 1974, "code": "public static void cleanup(final Logger log, final AutoCloseable... closeables) {\n    for (AutoCloseable c : closeables) {\n        if (c != null) {\n            try {\n                c.close();\n            } catch (Exception e) {\n                if (log != null && log.isDebugEnabled()) {\n                    log.debug(\"Exception in closing \" + c, e);\n                }\n            }\n        }\n    }\n}", "summary_tokens": ["close", "the", "auto", "closeable", "objects", "and", "b", "ignore", "b", "any", "exception", "or", "null", "pointers"], "project": "flink"}
{"id": 9705, "code": "public void testQueryCluster() throws Exception {\n    runTest(\n            () -> {\n                LOG.info(\"Starting testQueryCluster()\");\n                runWithArgs(\n                        new String[] {\"-q\"},\n                        \"Summary: totalMemory 8192 totalCores 1332\",\n                        null,\n                        RunTypes.YARN_SESSION,\n                        0); \n                LOG.info(\"Finished testQueryCluster()\");\n            });\n}", "summary_tokens": ["test", "querying", "the", "yarn", "cluster"], "project": "flink"}
{"id": 1848, "code": "public void setValue(final long value) {\n    this.value = value;\n}", "summary_tokens": ["sets", "the", "value", "of", "the", "encapsulated", "long", "to", "the", "specified", "value"], "project": "flink"}
{"id": 884, "code": "public static boolean haveProtobuf() {\n    return PROTOBUF_MESSAGE_CLASS != null;\n}", "summary_tokens": ["a", "boolean", "value", "for", "determine", "if", "user", "have", "protobuf", "java", "in", "his", "class", "path"], "project": "flink"}
{"id": 5783, "code": "public static void testBlobCacheRecovery(final Configuration config, final BlobStore blobStore)\n        throws IOException {\n\n    final String clusterId = config.getString(HighAvailabilityOptions.HA_CLUSTER_ID);\n    String storagePath =\n            config.getString(HighAvailabilityOptions.HA_STORAGE_PATH) + \"/\" + clusterId;\n    Random rand = new Random();\n\n    try (BlobServer server0 = new BlobServer(config, blobStore);\n            BlobServer server1 = new BlobServer(config, blobStore);\n                \n            BlobCacheService cache0 =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server0.getPort()));\n            BlobCacheService cache1 =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server1.getPort()))) {\n\n        server0.start();\n        server1.start();\n\n            \n        byte[] expected = new byte[1024];\n        rand.nextBytes(expected);\n        byte[] expected2 = Arrays.copyOfRange(expected, 32, 288);\n\n        BlobKey[] keys = new BlobKey[2];\n        BlobKey nonHAKey;\n\n            \n        JobID[] jobId = new JobID[] {new JobID(), new JobID()};\n        keys[0] = put(cache0, jobId[0], expected, PERMANENT_BLOB); \n        keys[1] = put(cache0, jobId[1], expected2, PERMANENT_BLOB); \n\n            \n        nonHAKey = put(cache0, jobId[0], expected2, TRANSIENT_BLOB);\n        verifyKeyDifferentHashDifferent(keys[0], nonHAKey);\n        verifyKeyDifferentHashEquals(keys[1], nonHAKey);\n\n            \n        final Path blobServerPath = new Path(storagePath, \"blob\");\n        FileSystem fs = blobServerPath.getFileSystem();\n        assertTrue(\"Unknown storage dir: \" + blobServerPath, fs.exists(blobServerPath));\n\n            \n            \n        verifyContents(cache1, jobId[0], keys[0], expected);\n        verifyContents(cache1, jobId[1], keys[1], expected2);\n\n            \n        verifyDeleted(cache1, jobId[0], nonHAKey);\n    }\n}", "summary_tokens": ["helper", "to", "test", "that", "the", "blob", "server", "recovery", "from", "its", "ha", "store", "works"], "project": "flink"}
{"id": 8033, "code": "public TumbleWithSizeOnTimeWithAlias as(String alias) {\n    return as(ExpressionParser.INSTANCE.parseExpression(alias));\n}", "summary_tokens": ["assigns", "an", "alias", "for", "this", "window", "that", "the", "following", "group", "by", "and", "select", "clause", "can", "refer", "to"], "project": "flink"}
{"id": 327, "code": "private static CatalogPartitionSpec createPartitionSpec(String hivePartitionName) {\n    String[] partKeyVals = hivePartitionName.split(\"/\");\n    Map<String, String> spec = new HashMap<>(partKeyVals.length);\n    for (String keyVal : partKeyVals) {\n        String[] kv = keyVal.split(\"=\");\n        spec.put(unescapePathName(kv[0]), unescapePathName(kv[1]));\n    }\n    return new CatalogPartitionSpec(spec);\n}", "summary_tokens": ["creates", "a", "catalog", "partition", "spec", "from", "a", "hive", "partition", "name", "string"], "project": "flink"}
{"id": 3250, "code": "public static <OLD, NEW, VV> DataSet<Vertex<NEW, VV>> translateVertexIds(\n        DataSet<Vertex<OLD, VV>> vertices,\n        TranslateFunction<OLD, NEW> translator,\n        int parallelism) {\n    Preconditions.checkNotNull(vertices);\n    Preconditions.checkNotNull(translator);\n\n    Class<Vertex<NEW, VV>> vertexClass =\n            (Class<Vertex<NEW, VV>>) (Class<? extends Vertex>) Vertex.class;\n    TypeInformation<OLD> oldType =\n            ((TupleTypeInfo<Vertex<OLD, VV>>) vertices.getType()).getTypeAt(0);\n    TypeInformation<NEW> newType =\n            TypeExtractor.getUnaryOperatorReturnType(\n                    translator,\n                    TranslateFunction.class,\n                    0,\n                    1,\n                    new int[] {1},\n                    oldType,\n                    null,\n                    false);\n    TypeInformation<VV> vertexValueType =\n            ((TupleTypeInfo<Vertex<OLD, VV>>) vertices.getType()).getTypeAt(1);\n\n    TupleTypeInfo<Vertex<NEW, VV>> returnType =\n            new TupleTypeInfo<>(vertexClass, newType, vertexValueType);\n\n    return vertices.map(new TranslateVertexId<>(translator))\n            .returns(returnType)\n            .setParallelism(parallelism)\n            .name(\"Translate vertex IDs\");\n}", "summary_tokens": ["translate", "vertex", "ids", "using", "the", "given", "translate", "function"], "project": "flink"}
{"id": 1707, "code": "public static FileSystem get(URI uri) throws IOException {\n    return FileSystemSafetyNet.wrapWithSafetyNetWhenActivated(getUnguardedFileSystem(uri));\n}", "summary_tokens": ["returns", "a", "reference", "to", "the", "file", "system", "instance", "for", "accessing", "the", "file", "system", "identified", "by", "the", "given", "uri"], "project": "flink"}
{"id": 76, "code": "public void testWaitUntilJobInitializationFinished_doesNotThrowRuntimeException()\n        throws Exception {\n    Iterator<JobStatus> statusSequenceIterator =\n            Arrays.asList(JobStatus.INITIALIZING, JobStatus.INITIALIZING, JobStatus.FAILED)\n                    .iterator();\n    ClientUtils.waitUntilJobInitializationFinished(\n            statusSequenceIterator::next,\n            () -> buildJobResult(new RuntimeException(\"Err\")),\n            ClassLoader.getSystemClassLoader());\n}", "summary_tokens": ["ensure", "that", "wait", "until", "job", "initialization", "finished", "does", "not", "throw", "non", "initialization", "exceptions"], "project": "flink"}
{"id": 7865, "code": "public LinkedBlockingQueue<Object> getOutput() {\n    return outputList;\n}", "summary_tokens": ["get", "all", "the", "output", "from", "the", "task"], "project": "flink"}
{"id": 2322, "code": "public void setDeprecatedProperties() {\n    DeprecationContext deprecations = deprecationContext.get();\n    Properties props = getProps();\n    Properties overlay = getOverlay();\n    for (Map.Entry<String, DeprecatedKeyInfo> entry :\n            deprecations.getDeprecatedKeyMap().entrySet()) {\n        String depKey = entry.getKey();\n        if (!overlay.contains(depKey)) {\n            for (String newKey : entry.getValue().newKeys) {\n                String val = overlay.getProperty(newKey);\n                if (val != null) {\n                    props.setProperty(depKey, val);\n                    overlay.setProperty(depKey, val);\n                    break;\n                }\n            }\n        }\n    }\n}", "summary_tokens": ["sets", "all", "deprecated", "properties", "that", "are", "not", "currently", "set", "but", "have", "a", "corresponding", "new", "property", "that", "is", "set"], "project": "flink"}
{"id": 5923, "code": "public void testQuantiles() {\n    int stateSize = 100;\n    int processedData = 200;\n    int persistedData = 300;\n    long triggerTimestamp = 1234;\n    long lastAck = triggerTimestamp + 123;\n\n    CompletedCheckpointStatsSummary summary = new CompletedCheckpointStatsSummary();\n    summary.updateSummary(\n            new CompletedCheckpointStats(\n                    1L,\n                    triggerTimestamp,\n                    CheckpointProperties.forSavepoint(false),\n                    1,\n                    singletonMap(new JobVertexID(), new TaskStateStats(new JobVertexID(), 1)),\n                    1,\n                    stateSize,\n                    processedData,\n                    persistedData,\n                    new SubtaskStateStats(0, lastAck),\n                    \"\"));\n    CompletedCheckpointStatsSummarySnapshot snapshot = summary.createSnapshot();\n    assertEquals(stateSize, snapshot.getStateSizeStats().getQuantile(1), 0);\n    assertEquals(processedData, snapshot.getProcessedDataStats().getQuantile(1), 0);\n    assertEquals(persistedData, snapshot.getPersistedDataStats().getQuantile(1), 0);\n    assertEquals(\n            lastAck - triggerTimestamp, snapshot.getEndToEndDurationStats().getQuantile(1), 0);\n}", "summary_tokens": ["simply", "test", "that", "quantiles", "can", "be", "computed", "and", "fields", "are", "not", "permuted"], "project": "flink"}
{"id": 433, "code": "private Operation convertAlterTableAddParts(String[] qualified, CommonTree ast) {\n        \n        \n    boolean ifNotExists = ast.getChild(0).getType() == HiveASTParser.TOK_IFNOTEXISTS;\n\n    Table tab = getTable(new ObjectPath(qualified[0], qualified[1]));\n    boolean isView = tab.isView();\n    validateAlterTableType(tab);\n\n    int numCh = ast.getChildCount();\n    int start = ifNotExists ? 1 : 0;\n\n    String currentLocation = null;\n    Map<String, String> currentPartSpec = null;\n        \n        \n    List<CatalogPartitionSpec> specs = new ArrayList<>();\n    List<CatalogPartition> partitions = new ArrayList<>();\n    for (int num = start; num < numCh; num++) {\n        HiveParserASTNode child = (HiveParserASTNode) ast.getChild(num);\n        switch (child.getToken().getType()) {\n            case HiveASTParser.TOK_PARTSPEC:\n                if (currentPartSpec != null) {\n                    specs.add(new CatalogPartitionSpec(currentPartSpec));\n                    Map<String, String> props = new HashMap<>();\n                    if (currentLocation != null) {\n                        props.put(TABLE_LOCATION_URI, currentLocation);\n                    }\n                    partitions.add(new CatalogPartitionImpl(props, null));\n                    currentLocation = null;\n                }\n                currentPartSpec = getPartSpec(child);\n                validatePartitionValues(currentPartSpec); \n                break;\n            case HiveASTParser.TOK_PARTITIONLOCATION:\n                    \n                if (isView) {\n                    throw new ValidationException(\"LOCATION clause illegal for view partition\");\n                }\n                currentLocation =\n                        HiveParserBaseSemanticAnalyzer.unescapeSQLString(\n                                child.getChild(0).getText());\n                break;\n            default:\n                throw new ValidationException(\"Unknown child: \" + child);\n        }\n    }\n\n        \n    if (currentPartSpec != null) {\n        specs.add(new CatalogPartitionSpec(currentPartSpec));\n        Map<String, String> props = new HashMap<>();\n        if (currentLocation != null) {\n            props.put(TABLE_LOCATION_URI, currentLocation);\n        }\n        partitions.add(new CatalogPartitionImpl(props, null));\n    }\n\n    ObjectIdentifier tableIdentifier =\n            tab.getDbName() == null\n                    ? parseObjectIdentifier(tab.getTableName())\n                    : catalogManager.qualifyIdentifier(\n                            UnresolvedIdentifier.of(tab.getDbName(), tab.getTableName()));\n    return new AddPartitionsOperation(tableIdentifier, ifNotExists, specs, partitions);\n}", "summary_tokens": ["add", "one", "or", "more", "partitions", "to", "a", "table"], "project": "flink"}
{"id": 4857, "code": "public <T extends AutoCloseable>\n        OpaqueMemoryResource<T> getSharedMemoryResourceForManagedMemory(\n                String type,\n                LongFunctionWithException<T, Exception> initializer,\n                double fractionToInitializeWith)\n                throws Exception {\n\n        \n        \n    final long numBytes = computeMemorySize(fractionToInitializeWith);\n\n        \n        \n        \n    final LongFunctionWithException<T, Exception> reserveAndInitialize =\n            (size) -> {\n                try {\n                    reserveMemory(type, size);\n                } catch (MemoryReservationException e) {\n                    throw new MemoryAllocationException(\n                            \"Could not created the shared memory resource of size \"\n                                    + size\n                                    + \". Not enough memory left to reserve from the slot's managed memory.\",\n                            e);\n                }\n\n                try {\n                    return initializer.apply(size);\n                } catch (Throwable t) {\n                    releaseMemory(type, size);\n                    throw t;\n                }\n            };\n\n    final LongConsumer releaser = (size) -> releaseMemory(type, size);\n\n        \n        \n        \n        \n    final Object leaseHolder = new Object();\n\n    final SharedResources.ResourceAndSize<T> resource =\n            sharedResources.getOrAllocateSharedResource(\n                    type, leaseHolder, reserveAndInitialize, numBytes);\n\n        \n        \n        \n        \n    final long size = resource.size();\n\n    final ThrowingRunnable<Exception> disposer =\n            () -> sharedResources.release(type, leaseHolder, releaser);\n\n    return new OpaqueMemoryResource<>(resource.resourceHandle(), size, disposer);\n}", "summary_tokens": ["acquires", "a", "shared", "memory", "resource", "identified", "by", "a", "type", "string"], "project": "flink"}
{"id": 422, "code": "public void setUnparseTranslator(HiveParserUnparseTranslator unparseTranslator) {\n    this.unparseTranslator = unparseTranslator;\n}", "summary_tokens": ["unparse", "translator", "the", "unparse", "translator", "to", "set"], "project": "flink"}
{"id": 8192, "code": "public void addAll(List<T> list) throws Exception {\n    this.list.addAll(list);\n}", "summary_tokens": ["adds", "all", "of", "the", "elements", "of", "the", "specified", "list", "to", "this", "list", "view"], "project": "flink"}
{"id": 7700, "code": "public void testEventTimeTimerWithState() throws Exception {\n\n    LegacyKeyedCoProcessOperator<String, Integer, String, String> operator =\n            new LegacyKeyedCoProcessOperator<>(\n                    new EventTimeTriggeringStatefulProcessFunction());\n\n    TwoInputStreamOperatorTestHarness<Integer, String, String> testHarness =\n            new KeyedTwoInputStreamOperatorTestHarness<>(\n                    operator,\n                    new IntToStringKeySelector<>(),\n                    new IdentityKeySelector<String>(),\n                    BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.processWatermark1(new Watermark(1));\n    testHarness.processWatermark2(new Watermark(1));\n    testHarness.processElement1(new StreamRecord<>(17, 0L)); \n    testHarness.processElement1(new StreamRecord<>(13, 0L)); \n\n    testHarness.processWatermark1(new Watermark(2));\n    testHarness.processWatermark2(new Watermark(2));\n    testHarness.processElement1(new StreamRecord<>(13, 1L)); \n    testHarness.processElement2(new StreamRecord<>(\"42\", 1L)); \n\n    testHarness.processWatermark1(new Watermark(6));\n    testHarness.processWatermark2(new Watermark(6));\n\n    testHarness.processWatermark1(new Watermark(7));\n    testHarness.processWatermark2(new Watermark(7));\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    expectedOutput.add(new Watermark(1L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT1:17\", 0L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT1:13\", 0L));\n    expectedOutput.add(new Watermark(2L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT2:42\", 1L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:17\", 6L));\n    expectedOutput.add(new Watermark(6L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:42\", 7L));\n    expectedOutput.add(new Watermark(7L));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.close();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "leakage", "between", "different", "keys"], "project": "flink"}
{"id": 5219, "code": "public synchronized ComponentMetricStore getSubtaskMetricStore(\n        String jobID, String taskID, int subtaskIndex) {\n    JobMetricStore job = jobID == null ? null : jobs.get(jobID);\n    if (job == null) {\n        return null;\n    }\n    TaskMetricStore task = job.getTaskMetricStore(taskID);\n    if (task == null) {\n        return null;\n    }\n    return ComponentMetricStore.unmodifiable(task.getSubtaskMetricStore(subtaskIndex));\n}", "summary_tokens": ["returns", "the", "component", "metric", "store", "for", "the", "given", "job", "task", "id", "and", "subtask", "index"], "project": "flink"}
{"id": 7524, "code": "public W addWindow(W newWindow, MergeFunction<W> mergeFunction) throws Exception {\n\n    List<W> windows = new ArrayList<>();\n\n    windows.addAll(this.mapping.keySet());\n    windows.add(newWindow);\n\n    final Map<W, Collection<W>> mergeResults = new HashMap<>();\n    windowAssigner.mergeWindows(\n            windows,\n            new MergingWindowAssigner.MergeCallback<W>() {\n                @Override\n                public void merge(Collection<W> toBeMerged, W mergeResult) {\n                    if (LOG.isDebugEnabled()) {\n                        LOG.debug(\"Merging {} into {}\", toBeMerged, mergeResult);\n                    }\n                    mergeResults.put(mergeResult, toBeMerged);\n                }\n            });\n\n    W resultWindow = newWindow;\n    boolean mergedNewWindow = false;\n\n        \n    for (Map.Entry<W, Collection<W>> c : mergeResults.entrySet()) {\n        W mergeResult = c.getKey();\n        Collection<W> mergedWindows = c.getValue();\n\n            \n            \n        if (mergedWindows.remove(newWindow)) {\n            mergedNewWindow = true;\n            resultWindow = mergeResult;\n        }\n\n            \n            \n        W mergedStateWindow = this.mapping.get(mergedWindows.iterator().next());\n\n            \n        List<W> mergedStateWindows = new ArrayList<>();\n        for (W mergedWindow : mergedWindows) {\n            W res = this.mapping.remove(mergedWindow);\n            if (res != null) {\n                mergedStateWindows.add(res);\n            }\n        }\n\n        this.mapping.put(mergeResult, mergedStateWindow);\n\n            \n        mergedStateWindows.remove(mergedStateWindow);\n\n            \n            \n            \n        if (!(mergedWindows.contains(mergeResult) && mergedWindows.size() == 1)) {\n            mergeFunction.merge(\n                    mergeResult,\n                    mergedWindows,\n                    this.mapping.get(mergeResult),\n                    mergedStateWindows);\n        }\n    }\n\n        \n    if (mergeResults.isEmpty() || (resultWindow.equals(newWindow) && !mergedNewWindow)) {\n        this.mapping.put(resultWindow, resultWindow);\n    }\n\n    return resultWindow;\n}", "summary_tokens": ["adds", "a", "new", "window", "to", "the", "set", "of", "in", "flight", "windows"], "project": "flink"}
{"id": 5521, "code": "public static JobManagerCheckpointStorage createFromConfig(\n        ReadableConfig config, ClassLoader classLoader) throws IllegalConfigurationException {\n    try {\n        return new JobManagerCheckpointStorage().configure(config, classLoader);\n    } catch (IllegalArgumentException e) {\n        throw new IllegalConfigurationException(\n                \"Invalid configuration for the state backend\", e);\n    }\n}", "summary_tokens": ["creates", "a", "new", "job", "manager", "checkpoint", "storage", "using", "the", "given", "configuration"], "project": "flink"}
{"id": 4697, "code": "public int getNumberOfQueuedBuffers() {\n    synchronized (receivedBuffers) {\n        return receivedBuffers.size();\n    }\n}", "summary_tokens": ["gets", "the", "current", "number", "of", "received", "buffers", "which", "have", "not", "been", "processed", "yet"], "project": "flink"}
{"id": 2351, "code": "public void setBooleanIfUnset(String name, boolean value) {\n    setIfUnset(name, Boolean.toString(value));\n}", "summary_tokens": ["set", "the", "given", "property", "if", "it", "is", "currently", "unset"], "project": "flink"}
{"id": 3544, "code": "private List<String> getTagsFromMetricGroup(MetricGroup metricGroup) {\n    List<String> tags = new ArrayList<>();\n\n    for (Map.Entry<String, String> entry : metricGroup.getAllVariables().entrySet()) {\n        if (!entry.getKey().equals(HOST_VARIABLE)) {\n            tags.add(getVariableName(entry.getKey()) + \":\" + entry.getValue());\n        }\n    }\n\n    return tags;\n}", "summary_tokens": ["get", "tags", "from", "metric", "group", "get", "all", "variables", "excluding", "host"], "project": "flink"}
{"id": 7827, "code": "public void testCheckpointBarriers() throws Exception {\n    try (StreamTaskMailboxTestHarness<String> testHarness =\n            new StreamTaskMailboxTestHarnessBuilder<>(\n                            MultipleInputStreamTask::new, BasicTypeInfo.STRING_TYPE_INFO)\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO, 2)\n                    .addInput(BasicTypeInfo.INT_TYPE_INFO, 2)\n                    .addInput(BasicTypeInfo.DOUBLE_TYPE_INFO, 2)\n                    .setupOutputForSingletonOperatorChain(\n                            new MapToStringMultipleInputOperatorFactory(3))\n                    .build()) {\n        ArrayDeque<Object> expectedOutput = new ArrayDeque<>();\n        long initialTime = 0L;\n\n        testHarness.processEvent(\n                new CheckpointBarrier(\n                        0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n                0,\n                0);\n\n            \n        testHarness.processElement(new StreamRecord<>(\"Ciao-0-0\", initialTime), 0, 1);\n        expectedOutput.add(new StreamRecord<>(\"Ciao-0-0\", initialTime));\n\n            \n            \n            \n        testHarness.processElement(new StreamRecord<>(11, initialTime), 1, 1);\n        testHarness.processElement(new StreamRecord<>(1.0d, initialTime), 2, 0);\n        expectedOutput.add(new StreamRecord<>(\"11\", initialTime));\n        expectedOutput.add(new StreamRecord<>(\"1.0\", initialTime));\n\n        assertThat(testHarness.getOutput(), contains(expectedOutput.toArray()));\n\n        testHarness.processEvent(\n                new CheckpointBarrier(\n                        0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n                0,\n                1);\n        testHarness.processEvent(\n                new CheckpointBarrier(\n                        0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n                1,\n                0);\n        testHarness.processEvent(\n                new CheckpointBarrier(\n                        0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n                1,\n                1);\n        testHarness.processEvent(\n                new CheckpointBarrier(\n                        0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n                2,\n                0);\n        testHarness.processEvent(\n                new CheckpointBarrier(\n                        0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n                2,\n                1);\n\n            \n        expectedOutput.add(\n                new CheckpointBarrier(\n                        0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()));\n\n        assertThat(testHarness.getOutput(), contains(expectedOutput.toArray()));\n    }\n}", "summary_tokens": ["this", "test", "verifies", "that", "checkpoint", "barriers", "are", "correctly", "forwarded"], "project": "flink"}
{"id": 1865, "code": "public void copyFrom(\n        final Record source, final int[] sourcePositions, final int[] targetPositions) {\n\n    final int[] sourceOffsets = source.offsets;\n    final int[] sourceLengths = source.lengths;\n    final byte[] sourceBuffer = source.binaryData;\n    final Value[] sourceFields = source.writeFields;\n\n    boolean anyFieldIsBinary = false;\n    int maxFieldNum = 0;\n\n    for (int i = 0; i < sourcePositions.length; i++) {\n\n        final int sourceFieldNum = sourcePositions[i];\n        final int sourceOffset = sourceOffsets[sourceFieldNum];\n        final int targetFieldNum = targetPositions[i];\n\n        maxFieldNum = Math.max(targetFieldNum, maxFieldNum);\n\n        if (sourceOffset == NULL_INDICATOR_OFFSET) {\n                \n            if (targetFieldNum < numFields) {\n                internallySetField(targetFieldNum, null);\n            }\n        } else if (sourceOffset != MODIFIED_INDICATOR_OFFSET) {\n            anyFieldIsBinary = true;\n        }\n    }\n\n    if (numFields < maxFieldNum + 1) {\n        setNumFields(maxFieldNum + 1);\n    }\n\n    final int[] targetLengths = this.lengths;\n    final int[] targetOffsets = this.offsets;\n\n        \n    if (anyFieldIsBinary) {\n\n        for (int i = 0; i < sourcePositions.length; i++) {\n            final int sourceFieldNum = sourcePositions[i];\n            final int sourceOffset = sourceOffsets[sourceFieldNum];\n\n            if (sourceOffset != MODIFIED_INDICATOR_OFFSET\n                    && sourceOffset != NULL_INDICATOR_OFFSET) {\n                final int targetFieldNum = targetPositions[i];\n                targetLengths[targetFieldNum] = sourceLengths[sourceFieldNum];\n                internallySetField(targetFieldNum, RESERVE_SPACE);\n            }\n        }\n\n        updateBinaryRepresenation();\n    }\n\n    final byte[] targetBuffer = this.binaryData;\n\n    for (int i = 0; i < sourcePositions.length; i++) {\n        final int sourceFieldNum = sourcePositions[i];\n        final int sourceOffset = sourceOffsets[sourceFieldNum];\n        final int targetFieldNum = targetPositions[i];\n\n        if (sourceOffset == MODIFIED_INDICATOR_OFFSET) {\n            internallySetField(targetFieldNum, sourceFields[sourceFieldNum]);\n        } else if (sourceOffset != NULL_INDICATOR_OFFSET) {\n                \n            final int targetOffset = targetOffsets[targetFieldNum];\n            final int length = targetLengths[targetFieldNum];\n            System.arraycopy(sourceBuffer, sourceOffset, targetBuffer, targetOffset, length);\n        }\n    }\n}", "summary_tokens": ["bin", "copies", "fields", "from", "a", "source", "record", "to", "this", "record"], "project": "flink"}
{"id": 9024, "code": "public static FlinkJoinType getFlinkJoinType(JoinRelType joinRelType) {\n    switch (joinRelType) {\n        case INNER:\n            return FlinkJoinType.INNER;\n        case LEFT:\n            return FlinkJoinType.LEFT;\n        case RIGHT:\n            return FlinkJoinType.RIGHT;\n        case FULL:\n            return FlinkJoinType.FULL;\n        case SEMI:\n            return FlinkJoinType.SEMI;\n        case ANTI:\n            return FlinkJoinType.ANTI;\n        default:\n            throw new IllegalArgumentException(\"invalid: \" + joinRelType);\n    }\n}", "summary_tokens": ["converts", "join", "rel", "type", "to", "flink", "join", "type"], "project": "flink"}
{"id": 7811, "code": "public void writeApplyEventTimeWindowsSnapshot() throws Exception {\n    final int windowSize = 3;\n\n    ListStateDescriptor<Tuple2<String, Integer>> stateDesc =\n            new ListStateDescriptor<>(\n                    \"window-contents\",\n                    STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n    WindowOperator<\n                    String,\n                    Tuple2<String, Integer>,\n                    Iterable<Tuple2<String, Integer>>,\n                    Tuple2<String, Integer>,\n                    TimeWindow>\n            operator =\n                    new WindowOperator<>(\n                            TumblingEventTimeWindows.of(Time.of(windowSize, TimeUnit.SECONDS)),\n                            new TimeWindow.Serializer(),\n                            new TupleKeySelector<>(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()),\n                            stateDesc,\n                            new InternalIterableWindowFunction<>(\n                                    new RichSumReducer<TimeWindow>()),\n                            EventTimeTrigger.create(),\n                            0,\n                            null );\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>>\n            testHarness =\n                    new KeyedOneInputStreamOperatorTestHarness<>(\n                            operator, new TupleKeySelector<>(), BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n        \n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 3999));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 3000));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 20));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 0));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 999));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 1998));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 1999));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 1000));\n\n    testHarness.processWatermark(new Watermark(999));\n    expectedOutput.add(new Watermark(999));\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new Tuple2ResultSortComparator<>());\n\n    testHarness.processWatermark(new Watermark(1999));\n    expectedOutput.add(new Watermark(1999));\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new Tuple2ResultSortComparator<>());\n\n        \n    OperatorSubtaskState snapshot = testHarness.snapshot(0, 0);\n    OperatorSnapshotUtil.writeStateHandle(\n            snapshot,\n            \"src/test/resources/win-op-migration-test-apply-event-time-flink\"\n                    + flinkGenerateSavepointVersion\n                    + \"-snapshot\");\n\n    testHarness.close();\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 9075, "code": "public static File createJarFile(File tmpDir, String jarName, String className, String javaCode)\n        throws IOException {\n        \n    File javaFile = Paths.get(tmpDir.toString(), className + \".java\").toFile();\n        \n    javaFile.createNewFile();\n    FileUtils.writeFileUtf8(javaFile, javaCode);\n\n        \n    DiagnosticCollector<JavaFileObject> diagnostics = new DiagnosticCollector<>();\n    JavaCompiler compiler = ToolProvider.getSystemJavaCompiler();\n    StandardJavaFileManager fileManager =\n            compiler.getStandardFileManager(diagnostics, null, null);\n    Iterable<? extends JavaFileObject> compilationUnit =\n            fileManager.getJavaFileObjectsFromFiles(Collections.singletonList(javaFile));\n    JavaCompiler.CompilationTask task =\n            compiler.getTask(\n                    null,\n                    fileManager,\n                    diagnostics,\n                    Collections.emptyList(),\n                    null,\n                    compilationUnit);\n    task.call();\n\n        \n    File classFile = Paths.get(tmpDir.toString(), className + \".class\").toFile();\n    File jarFile = Paths.get(tmpDir.toString(), jarName).toFile();\n    JarOutputStream jos = new JarOutputStream(new FileOutputStream(jarFile));\n    JarEntry jarEntry = new JarEntry(className + \".class\");\n    jos.putNextEntry(jarEntry);\n    byte[] classBytes = FileUtils.readAllBytes(classFile.toPath());\n    jos.write(classBytes);\n    jos.closeEntry();\n    jos.close();\n\n    return jarFile;\n}", "summary_tokens": ["pack", "the", "generated", "udf", "class", "into", "a", "jar", "and", "return", "the", "path", "of", "the", "jar"], "project": "flink"}
{"id": 4782, "code": "public void setParallelism(int parallelism) {\n    if (parallelism < 1) {\n        throw new IllegalArgumentException(\"The parallelism must be at least one.\");\n    }\n    this.parallelism = parallelism;\n}", "summary_tokens": ["sets", "the", "parallelism", "for", "the", "task"], "project": "flink"}
{"id": 8819, "code": "private static void prepareDynamicSink(\n        ObjectIdentifier sinkIdentifier,\n        Map<String, String> staticPartitions,\n        boolean isOverwrite,\n        DynamicTableSink sink,\n        ResolvedCatalogTable table,\n        List<SinkAbilitySpec> sinkAbilitySpecs) {\n    validatePartitioning(sinkIdentifier, staticPartitions, sink, table.getPartitionKeys());\n\n    validateAndApplyOverwrite(sinkIdentifier, isOverwrite, sink, sinkAbilitySpecs);\n\n    validateAndApplyMetadata(sinkIdentifier, sink, table.getResolvedSchema(), sinkAbilitySpecs);\n}", "summary_tokens": ["prepares", "the", "given", "dynamic", "table", "sink"], "project": "flink"}
{"id": 3931, "code": "public void testDeserializeValueTooShort() throws Exception {\n        \n    KvStateSerializer.deserializeValue(new byte[] {1}, LongSerializer.INSTANCE);\n}", "summary_tokens": ["tests", "value", "deserialization", "with", "too", "few", "bytes"], "project": "flink"}
{"id": 1755, "code": "public byte[] getByteArray() {\n    return getSharedBuffer();\n}", "summary_tokens": ["replaced", "by", "get", "shared", "buffer", "for", "a", "better", "safer", "name"], "project": "flink"}
{"id": 7267, "code": "public void clearJobListeners() {\n    this.jobListeners.clear();\n}", "summary_tokens": ["clear", "all", "registered", "job", "listener", "s"], "project": "flink"}
{"id": 4594, "code": "public ChannelHandler[] getClientChannelHandlers() {\n    NetworkClientHandler networkClientHandler = new CreditBasedPartitionRequestClientHandler();\n\n    return new ChannelHandler[] {\n        messageEncoder,\n        new NettyMessageClientDecoderDelegate(networkClientHandler),\n        networkClientHandler\n    };\n}", "summary_tokens": ["returns", "the", "client", "channel", "handlers"], "project": "flink"}
{"id": 6273, "code": "public void testCoLocationConstraintJobExecution() throws Exception {\n    final int numSlotsPerTaskExecutor = 1;\n    final int numTaskExecutors = 3;\n    final int parallelism = numTaskExecutors * numSlotsPerTaskExecutor;\n    final JobGraph jobGraph = createJobGraph(parallelism);\n\n    final TestingMiniClusterConfiguration miniClusterConfiguration =\n            TestingMiniClusterConfiguration.newBuilder()\n                    .setNumSlotsPerTaskManager(numSlotsPerTaskExecutor)\n                    .setNumTaskManagers(numTaskExecutors)\n                    .setLocalCommunication(true)\n                    .build();\n\n    try (TestingMiniCluster miniCluster = new TestingMiniCluster(miniClusterConfiguration)) {\n        miniCluster.start();\n\n        miniCluster.submitJob(jobGraph).get();\n\n        final CompletableFuture<JobResult> jobResultFuture =\n                miniCluster.requestJobResult(jobGraph.getJobID());\n\n        assertThat(jobResultFuture.get().isSuccess(), is(true));\n    }\n}", "summary_tokens": ["tests", "that", "tasks", "with", "a", "co", "location", "constraint", "are", "scheduled", "in", "the", "same", "slots"], "project": "flink"}
{"id": 8046, "code": "public void registerCatalog(String catalogName, Catalog catalog) {\n    checkArgument(\n            !StringUtils.isNullOrWhitespaceOnly(catalogName),\n            \"Catalog name cannot be null or empty.\");\n    checkNotNull(catalog, \"Catalog cannot be null\");\n\n    if (catalogs.containsKey(catalogName)) {\n        throw new CatalogException(format(\"Catalog %s already exists.\", catalogName));\n    }\n\n    catalog.open();\n    catalogs.put(catalogName, catalog);\n}", "summary_tokens": ["registers", "a", "catalog", "under", "the", "given", "name"], "project": "flink"}
{"id": 7512, "code": "public V get(K key) {\n    final int hash = hash(key);\n    final int slot = indexOf(hash);\n\n        \n    for (Entry<K, V> entry = table[slot]; entry != null; entry = entry.next) {\n        if (entry.hashCode == hash && entry.key.equals(key)) {\n            return entry.value;\n        }\n    }\n\n        \n    return null;\n}", "summary_tokens": ["looks", "up", "the", "value", "mapped", "under", "the", "given", "key"], "project": "flink"}
{"id": 1116, "code": "public int getAttemptNumber() {\n    return this.attemptNumber;\n}", "summary_tokens": ["gets", "the", "attempt", "number", "of", "this", "parallel", "subtask"], "project": "flink"}
{"id": 6144, "code": "public void testRequestMemorySegmentsWithInvalidArgument() throws IOException {\n    NetworkBufferPool globalPool = new NetworkBufferPool(10, 128);\n        \n    globalPool.requestMemorySegments(-1);\n    globalPool.destroy();\n    fail(\"Should throw an IllegalArgumentException\");\n}", "summary_tokens": ["tests", "network", "buffer", "pool", "request", "memory", "segments", "int", "with", "the", "invalid", "argument", "to", "cause", "exception"], "project": "flink"}
{"id": 8452, "code": "public TypeInformation<ACC> getAccumulatorType() {\n    return null;\n}", "summary_tokens": ["returns", "the", "type", "information", "of", "the", "imperative", "aggregate", "function", "s", "accumulator"], "project": "flink"}
{"id": 7390, "code": "public static <OUT> SourceFunction.SourceContext<OUT> getSourceContext(\n        TimeCharacteristic timeCharacteristic,\n        ProcessingTimeService processingTimeService,\n        Object checkpointLock,\n        Output<StreamRecord<OUT>> output,\n        long watermarkInterval,\n        long idleTimeout,\n        boolean emitProgressiveWatermarks) {\n\n    final SourceFunction.SourceContext<OUT> ctx;\n    switch (timeCharacteristic) {\n        case EventTime:\n            ctx =\n                    new ManualWatermarkContext<>(\n                            output,\n                            processingTimeService,\n                            checkpointLock,\n                            idleTimeout,\n                            emitProgressiveWatermarks);\n\n            break;\n        case IngestionTime:\n            Preconditions.checkState(\n                    emitProgressiveWatermarks,\n                    \"Ingestion time is not available when emitting progressive watermarks \"\n                            + \"is disabled.\");\n            ctx =\n                    new AutomaticWatermarkContext<>(\n                            output,\n                            watermarkInterval,\n                            processingTimeService,\n                            checkpointLock,\n                            idleTimeout);\n            break;\n        case ProcessingTime:\n            ctx = new NonTimestampContext<>(checkpointLock, output);\n            break;\n        default:\n            throw new IllegalArgumentException(String.valueOf(timeCharacteristic));\n    }\n    return new SwitchingOnClose<>(ctx);\n}", "summary_tokens": ["depending", "on", "the", "time", "characteristic", "this", "method", "will", "return", "the", "adequate", "org"], "project": "flink"}
{"id": 3413, "code": "public boolean conflictsWith(OptionalBoolean other) {\n    return state == State.CONFLICTING\n            || other.state == State.CONFLICTING\n            || (state == State.TRUE && other.state == State.FALSE)\n            || (state == State.FALSE && other.state == State.TRUE);\n}", "summary_tokens": ["the", "conflicting", "states", "are", "true", "with", "false", "and", "false", "with", "true"], "project": "flink"}
{"id": 8827, "code": "public static boolean isUpsertSource(\n        ResolvedCatalogTable catalogTable, DynamicTableSource tableSource) {\n    if (!(tableSource instanceof ScanTableSource)) {\n        return false;\n    }\n    ChangelogMode mode = ((ScanTableSource) tableSource).getChangelogMode();\n    boolean isUpsertMode =\n            mode.contains(RowKind.UPDATE_AFTER) && !mode.contains(RowKind.UPDATE_BEFORE);\n    boolean hasPrimaryKey = catalogTable.getResolvedSchema().getPrimaryKey().isPresent();\n    return isUpsertMode && hasPrimaryKey;\n}", "summary_tokens": ["returns", "true", "if", "the", "table", "is", "an", "upsert", "source"], "project": "flink"}
{"id": 1557, "code": "public static <T0, T1, T2, T3, T4, T5, T6, T7, T8>\n        Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8> of(\n                T0 f0, T1 f1, T2 f2, T3 f3, T4 f4, T5 f5, T6 f6, T7 f7, T8 f8) {\n    return new Tuple9<>(f0, f1, f2, f3, f4, f5, f6, f7, f8);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 5776, "code": "private void testPutStreamTransientSuccessfulGet(@Nullable JobID jobId1, @Nullable JobID jobId2)\n        throws IOException, InterruptedException {\n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n        byte[] data2 = Arrays.copyOfRange(data, 10, 54);\n\n            \n        TransientBlobKey key1a =\n                (TransientBlobKey)\n                        put(cache, jobId1, new ByteArrayInputStream(data), TRANSIENT_BLOB);\n        assertNotNull(key1a);\n            \n        BlobKey key1a2 = put(cache, jobId1, new ByteArrayInputStream(data), TRANSIENT_BLOB);\n        assertNotNull(key1a2);\n        verifyKeyDifferentHashEquals(key1a, key1a2);\n\n        TransientBlobKey key1b =\n                (TransientBlobKey)\n                        put(cache, jobId1, new ByteArrayInputStream(data2), TRANSIENT_BLOB);\n        assertNotNull(key1b);\n\n            \n        verifyContents(server, jobId1, key1a, data);\n        verifyContents(server, jobId1, key1a2, data);\n        verifyContents(server, jobId1, key1b, data2);\n\n            \n        TransientBlobKey key2a =\n                (TransientBlobKey)\n                        put(cache, jobId2, new ByteArrayInputStream(data), TRANSIENT_BLOB);\n        assertNotNull(key2a);\n        verifyKeyDifferentHashEquals(key1a, key2a);\n\n        TransientBlobKey key2b =\n                (TransientBlobKey)\n                        put(cache, jobId2, new ByteArrayInputStream(data2), TRANSIENT_BLOB);\n        assertNotNull(key2b);\n        verifyKeyDifferentHashEquals(key1b, key2b);\n\n            \n        verifyContents(server, jobId1, key1a, data);\n        verifyContents(server, jobId1, key1a2, data);\n        verifyContents(server, jobId1, key1b, data2);\n        verifyContents(server, jobId2, key2a, data);\n        verifyContents(server, jobId2, key2b, data2);\n\n            \n        verifyContents(cache, jobId1, key1a, data);\n        verifyContents(cache, jobId1, key1b, data2);\n        verifyContents(cache, jobId2, key2a, data);\n        verifyContents(cache, jobId2, key2b, data2);\n\n            \n        verifyDeletedEventually(server, jobId1, key1a);\n        verifyDeletedEventually(server, jobId1, key1b);\n        verifyDeletedEventually(server, jobId2, key2a);\n        verifyDeletedEventually(server, jobId2, key2b);\n\n            \n        verifyContents(cache, jobId1, key1a, data);\n        verifyContents(cache, jobId1, key1b, data2);\n        verifyContents(cache, jobId2, key2a, data);\n        verifyContents(cache, jobId2, key2b, data2);\n    }\n}", "summary_tokens": ["uploads", "two", "file", "streams", "for", "different", "jobs", "into", "the", "server", "via", "the", "blob", "cache", "service"], "project": "flink"}
{"id": 8304, "code": "public static TimestampData fromLocalDateTime(LocalDateTime dateTime) {\n    long epochDay = dateTime.toLocalDate().toEpochDay();\n    long nanoOfDay = dateTime.toLocalTime().toNanoOfDay();\n\n    long millisecond = epochDay * MILLIS_PER_DAY + nanoOfDay / 1_000_000;\n    int nanoOfMillisecond = (int) (nanoOfDay % 1_000_000);\n\n    return new TimestampData(millisecond, nanoOfMillisecond);\n}", "summary_tokens": ["creates", "an", "instance", "of", "timestamp", "data", "from", "an", "instance", "of", "local", "date", "time"], "project": "flink"}
{"id": 3721, "code": "public void setCosts(Costs nodeCosts) {\n        \n    this.nodeCosts = nodeCosts;\n\n        \n    this.cumulativeCosts = nodeCosts.clone();\n\n        \n    for (PlanNode pred : getPredecessors()) {\n\n        Costs parentCosts = pred.getCumulativeCostsShare();\n        if (parentCosts != null) {\n            this.cumulativeCosts.addCosts(parentCosts);\n        } else {\n            throw new CompilerException(\n                    \"Trying to set the costs of an operator before the predecessor costs are computed.\");\n        }\n    }\n\n        \n    if (this.broadcastInputs != null) {\n        for (NamedChannel nc : this.broadcastInputs) {\n            Costs bcInputCost = nc.getSource().getCumulativeCostsShare();\n            if (bcInputCost != null) {\n                this.cumulativeCosts.addCosts(bcInputCost);\n            } else {\n                throw new CompilerException(\n                        \"Trying to set the costs of an operator before the broadcast input costs are computed.\");\n            }\n        }\n    }\n}", "summary_tokens": ["sets", "the", "basic", "cost", "for", "this", "node", "to", "the", "given", "value", "and", "sets", "the", "cumulative", "costs", "to", "those", "costs", "plus", "the", "cost", "shares", "of", "all", "inputs", "regular", "and", "broadcast"], "project": "flink"}
{"id": 5395, "code": "public boolean isKeyGroupAlreadyStarted(int keyGroupId) {\n    return NO_OFFSET_SET != keyGroupRangeOffsets.getKeyGroupOffset(keyGroupId);\n}", "summary_tokens": ["returns", "true", "if", "the", "key", "group", "with", "the", "given", "id", "was", "already", "started"], "project": "flink"}
{"id": 3087, "code": "public Pattern<T, F> timesOrMore(int times) {\n    checkIfNoNotPattern();\n    checkIfQuantifierApplied();\n    this.quantifier = Quantifier.looping(quantifier.getConsumingStrategy());\n    this.times = Times.of(times);\n    return this;\n}", "summary_tokens": ["specifies", "that", "this", "pattern", "can", "occur", "the", "specified", "times", "at", "least"], "project": "flink"}
{"id": 1814, "code": "public static MemorySegment allocateUnpooledSegment(int size, Object owner) {\n    return new MemorySegment(new byte[size], owner);\n}", "summary_tokens": ["allocates", "some", "unpooled", "memory", "and", "creates", "a", "new", "memory", "segment", "that", "represents", "that", "memory"], "project": "flink"}
{"id": 6295, "code": "public void testConcurrentReleaseOperations() throws Exception {\n    final CountingSlotOwner countingSlotOwner = new CountingSlotOwner();\n    final CountingFailPayload countingFailPayload = new CountingFailPayload();\n    final SingleLogicalSlot singleLogicalSlot = createSingleLogicalSlot(countingSlotOwner);\n\n    singleLogicalSlot.tryAssignPayload(countingFailPayload);\n\n    final ExecutorService executorService = Executors.newFixedThreadPool(4);\n\n    try {\n        final int numberConcurrentOperations = 10;\n        final Collection<CompletableFuture<?>> releaseOperationFutures =\n                new ArrayList<>(numberConcurrentOperations);\n\n        for (int i = 0; i < numberConcurrentOperations; i++) {\n            final CompletableFuture<Void> releaseOperationFuture =\n                    CompletableFuture.runAsync(\n                            () -> {\n                                try {\n                                    singleLogicalSlot\n                                            .releaseSlot(new FlinkException(\"Test exception\"))\n                                            .get();\n                                } catch (InterruptedException | ExecutionException e) {\n                                    ExceptionUtils.checkInterrupted(e);\n                                    throw new CompletionException(e);\n                                }\n                            });\n\n            releaseOperationFutures.add(releaseOperationFuture);\n        }\n\n        final FutureUtils.ConjunctFuture<Void> releaseOperationsFuture =\n                FutureUtils.waitForAll(releaseOperationFutures);\n\n        releaseOperationsFuture.get();\n\n        assertThat(countingSlotOwner.getReleaseCount(), is(1));\n        assertThat(countingFailPayload.getFailCount(), is(1));\n    } finally {\n        executorService.shutdownNow();\n    }\n}", "summary_tokens": ["tests", "that", "concurrent", "release", "operations", "only", "trigger", "the", "failing", "of", "the", "payload", "and", "the", "return", "of", "the", "slot", "once"], "project": "flink"}
{"id": 4438, "code": "public boolean isGlobalFailure() {\n    return globalFailure;\n}", "summary_tokens": ["checks", "if", "this", "failure", "was", "a", "global", "failure", "i"], "project": "flink"}
{"id": 8619, "code": "public static StructuredType.Builder newBuilder(Class<?> implementationClass) {\n    return new StructuredType.Builder(implementationClass);\n}", "summary_tokens": ["creates", "a", "builder", "for", "a", "structured", "type", "that", "is", "not", "stored", "in", "a", "catalog", "and", "is", "identified", "by", "an", "implementation", "class"], "project": "flink"}
{"id": 6124, "code": "public void testBroadcastEventNoRecords() throws Exception {\n    int numberOfChannels = 4;\n    int bufferSize = 32;\n\n    ResultPartition partition = createResultPartition(bufferSize, numberOfChannels);\n    RecordWriter<ByteArrayIO> writer = createRecordWriter(partition);\n    CheckpointBarrier barrier =\n            new CheckpointBarrier(\n                    Integer.MAX_VALUE + 919192L,\n                    Integer.MAX_VALUE + 18828228L,\n                    CheckpointOptions.forCheckpointWithDefaultLocation());\n\n        \n    writer.broadcastEvent(barrier);\n\n    assertEquals(0, partition.getBufferPool().bestEffortGetNumOfUsedBuffers());\n\n    for (int i = 0; i < numberOfChannels; i++) {\n        assertEquals(1, partition.getNumberOfQueuedBuffers(i));\n        ResultSubpartitionView view =\n                partition.createSubpartitionView(i, new NoOpBufferAvailablityListener());\n        BufferOrEvent boe = parseBuffer(view.getNextBuffer().buffer(), i);\n        assertTrue(boe.isEvent());\n        assertEquals(barrier, boe.getEvent());\n        assertFalse(view.getAvailabilityAndBacklog(Integer.MAX_VALUE).isAvailable());\n    }\n}", "summary_tokens": ["tests", "broadcasting", "events", "when", "no", "records", "have", "been", "emitted", "yet"], "project": "flink"}
{"id": 970, "code": "public Integer getRequestedFrameMax() {\n    return requestedFrameMax;\n}", "summary_tokens": ["retrieve", "the", "requested", "maximum", "frame", "size"], "project": "flink"}
{"id": 9131, "code": "public static double log(double base, double x) {\n    return Math.log(x) / Math.log(base);\n}", "summary_tokens": ["returns", "the", "logarithm", "of", "x", "with", "base", "base"], "project": "flink"}
{"id": 5350, "code": "public AsyncSnapshotTask toAsyncSnapshotFutureTask(@Nonnull CloseableRegistry taskRegistry)\n        throws IOException {\n    return new AsyncSnapshotTask(taskRegistry);\n}", "summary_tokens": ["creates", "a", "future", "task", "from", "this", "and", "registers", "it", "with", "the", "given", "closeable", "registry"], "project": "flink"}
{"id": 711, "code": "protected void testExactlyOnce(boolean regularSink, int sinksCount) throws Exception {\n    final String topic =\n            (regularSink ? \"exactlyOnceTopicRegularSink\" : \"exactlyTopicCustomOperator\")\n                    + sinksCount;\n    final int partition = 0;\n    final int numElements = 1000;\n    final int failAfterElements = 333;\n\n    for (int i = 0; i < sinksCount; i++) {\n        createTestTopic(topic + i, 1, 1);\n    }\n\n    TypeInformationSerializationSchema<Integer> schema =\n            new TypeInformationSerializationSchema<>(\n                    BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.enableCheckpointing(500);\n    env.setParallelism(1);\n    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\n    Properties properties = new Properties();\n    properties.putAll(standardProps);\n    properties.putAll(secureProps);\n\n        \n        \n    List<Integer> expectedElements = getIntegersSequence(numElements);\n\n    DataStream<Integer> inputStream =\n            env.addSource(new IntegerSource(numElements))\n                    .map(new FailingIdentityMapper<Integer>(failAfterElements));\n\n    for (int i = 0; i < sinksCount; i++) {\n        FlinkKafkaPartitioner<Integer> partitioner =\n                new FlinkKafkaPartitioner<Integer>() {\n                    @Override\n                    public int partition(\n                            Integer record,\n                            byte[] key,\n                            byte[] value,\n                            String targetTopic,\n                            int[] partitions) {\n                        return partition;\n                    }\n                };\n\n        if (regularSink) {\n            StreamSink<Integer> kafkaSink =\n                    kafkaServer.getProducerSink(topic + i, schema, properties, partitioner);\n            inputStream.addSink(kafkaSink.getUserFunction());\n        } else {\n            kafkaServer.produceIntoKafka(\n                    inputStream, topic + i, schema, properties, partitioner);\n        }\n    }\n\n    FailingIdentityMapper.failedBefore = false;\n    TestUtils.tryExecute(env, \"Exactly once test\");\n\n    for (int i = 0; i < sinksCount; i++) {\n            \n        assertExactlyOnceForTopic(properties, topic + i, expectedElements);\n        deleteTestTopic(topic + i);\n    }\n}", "summary_tokens": ["this", "test", "sets", "kafka", "producer", "so", "that", "it", "will", "automatically", "flush", "the", "data", "and", "and", "fails", "the", "broker", "to", "check", "whether", "flushed", "records", "since", "last", "checkpoint", "were", "not", "duplicated"], "project": "flink"}
{"id": 1681, "code": "public int getMebiBytes() {\n    return (int) (bytes >> 20);\n}", "summary_tokens": ["gets", "the", "memory", "size", "in", "mebibytes", "0", "kibibytes"], "project": "flink"}
{"id": 5257, "code": "public final void resolveFromString(String value) throws ConversionException {\n    resolve(convertFromString(value));\n}", "summary_tokens": ["resolves", "this", "parameter", "for", "the", "given", "string", "value", "representation"], "project": "flink"}
{"id": 2317, "code": "public TypeInference getTypeInference(DataTypeFactory typeFactory) {\n    return TypeInference.newBuilder()\n                \n                \n                \n                \n            .inputTypeStrategy(\n                    InputTypeStrategies.sequence(\n                            InputTypeStrategies.ANY,\n                            InputTypeStrategies.explicit(DataTypes.DATE())))\n                \n            .accumulatorTypeStrategy(\n                    callContext -> {\n                        final DataType argDataType = callContext.getArgumentDataTypes().get(0);\n                        final DataType accDataType =\n                                DataTypes.STRUCTURED(\n                                        Accumulator.class,\n                                        DataTypes.FIELD(\"value\", argDataType),\n                                        DataTypes.FIELD(\"date\", DataTypes.DATE()));\n                        return Optional.of(accDataType);\n                    })\n                \n            .outputTypeStrategy(\n                    callContext -> {\n                        final DataType argDataType = callContext.getArgumentDataTypes().get(0);\n                        final DataType outputDataType =\n                                DataTypes.ROW(\n                                        DataTypes.FIELD(\"value\", argDataType),\n                                        DataTypes.FIELD(\"date\", DataTypes.DATE()));\n                        return Optional.of(outputDataType);\n                    })\n            .build();\n}", "summary_tokens": ["declares", "the", "type", "inference", "of", "this", "function"], "project": "flink"}
{"id": 8914, "code": "private static FlinkPreparingTableBase toPreparingTable(\n        RelOptSchema relOptSchema,\n        List<String> names,\n        RelDataType rowType,\n        CatalogSchemaTable schemaTable) {\n    final ResolvedCatalogBaseTable<?> resolvedBaseTable = schemaTable.getResolvedCatalogTable();\n    final CatalogBaseTable originTable = resolvedBaseTable.getOrigin();\n    if (originTable instanceof QueryOperationCatalogView) {\n        return convertQueryOperationView(\n                relOptSchema, names, rowType, (QueryOperationCatalogView) originTable);\n    } else if (originTable instanceof ConnectorCatalogTable) {\n        ConnectorCatalogTable<?, ?> connectorTable = (ConnectorCatalogTable<?, ?>) originTable;\n        if ((connectorTable).getTableSource().isPresent()) {\n            return convertSourceTable(\n                    relOptSchema,\n                    rowType,\n                    schemaTable.getTableIdentifier(),\n                    connectorTable,\n                    schemaTable.getStatistic(),\n                    schemaTable.isStreamingMode());\n        } else {\n            throw new ValidationException(\n                    \"Cannot convert a connector table \" + \"without source.\");\n        }\n    } else if (originTable instanceof CatalogView) {\n        return convertCatalogView(\n                relOptSchema,\n                names,\n                rowType,\n                schemaTable.getStatistic(),\n                (CatalogView) originTable);\n    } else if (originTable instanceof CatalogTable) {\n        return convertCatalogTable(\n                relOptSchema,\n                names,\n                rowType,\n                (ResolvedCatalogTable) resolvedBaseTable,\n                schemaTable);\n    } else {\n        throw new ValidationException(\"Unsupported table type: \" + originTable);\n    }\n}", "summary_tokens": ["translate", "this", "catalog", "schema", "table", "into", "flink", "source", "table"], "project": "flink"}
{"id": 9141, "code": "public static String hash(String algorithm, String str, String charsetName) {\n    try {\n        byte[] digest =\n                MessageDigest.getInstance(algorithm)\n                        .digest(strToBytesWithCharset(str, charsetName));\n        return EncodingUtils.hex(digest);\n    } catch (NoSuchAlgorithmException e) {\n        throw new IllegalArgumentException(\"Unsupported algorithm: \" + algorithm, e);\n    }\n}", "summary_tokens": ["calculate", "the", "hash", "value", "of", "a", "given", "string"], "project": "flink"}
{"id": 9664, "code": "public void testChangedFieldTypesWithOperatorState() throws Exception {\n    try {\n        testPojoSerializerUpgrade(SOURCE_A, SOURCE_C, true, false);\n        fail(\"Expected a state migration exception.\");\n    } catch (Exception e) {\n        if (CommonTestUtils.containsCause(e, StateMigrationException.class)) {\n                \n        } else {\n            throw e;\n        }\n    }\n}", "summary_tokens": ["changing", "field", "types", "of", "a", "pojo", "as", "operator", "state", "should", "require", "a", "state", "migration"], "project": "flink"}
{"id": 4615, "code": "default void stopTrackingAndReleasePartitions(\n        Collection<ResultPartitionID> resultPartitionIds) {\n    stopTrackingAndReleasePartitions(resultPartitionIds, true);\n}", "summary_tokens": ["releases", "the", "given", "partitions", "and", "stop", "the", "tracking", "of", "partitions", "that", "were", "released"], "project": "flink"}
{"id": 7485, "code": "public void open(Configuration parameters) throws Exception {\n    try {\n        client = new Socket(hostIp, port);\n        outputStream = client.getOutputStream();\n        streamWriter = new DataOutputViewStreamWrapper(outputStream);\n    } catch (IOException e) {\n        throw new IOException(\n                \"Cannot get back the stream while opening connection to client at \"\n                        + hostIp.toString()\n                        + \":\"\n                        + port,\n                e);\n    }\n}", "summary_tokens": ["initialize", "the", "connection", "with", "the", "socket", "in", "the", "server"], "project": "flink"}
{"id": 5719, "code": "public int getRequestId() {\n    return requestId;\n}", "summary_tokens": ["returns", "the", "id", "of", "the", "sample"], "project": "flink"}
{"id": 9305, "code": "public TimeWindow getTriggerWindow() {\n    return currentWindow;\n}", "summary_tokens": ["the", "last", "triggered", "window"], "project": "flink"}
{"id": 5839, "code": "private void testDeleteBlobFails(@Nullable final JobID jobId, BlobKey.BlobType blobType)\n        throws IOException {\n    assumeTrue(!OperatingSystem.isWindows()); \n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    File blobFile = null;\n    File directory = null;\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore())) {\n\n        server.start();\n\n        try {\n            byte[] data = new byte[2000000];\n            rnd.nextBytes(data);\n\n                \n            BlobKey key = put(server, jobId, data, blobType);\n            assertNotNull(key);\n\n            blobFile = server.getStorageLocation(jobId, key);\n            directory = blobFile.getParentFile();\n\n            assertTrue(blobFile.setWritable(false, false));\n            assertTrue(directory.setWritable(false, false));\n\n                \n            assertFalse(delete(server, jobId, key, blobType));\n\n                \n            verifyContents(server, jobId, key, data);\n        } finally {\n            if (blobFile != null && directory != null) {\n                    \n                blobFile.setWritable(true, false);\n                    \n                directory.setWritable(true, false);\n            }\n        }\n    }\n}", "summary_tokens": ["uploads", "a", "byte", "array", "for", "the", "given", "job", "and", "verifies", "that", "a", "delete", "operation", "via", "the", "blob", "server", "does", "not", "fail", "even", "if", "the", "file", "is", "not", "deletable", "e"], "project": "flink"}
{"id": 3818, "code": "public void setConfiguration(Configuration config) {\n    this.config = config;\n}", "summary_tokens": ["reset", "the", "configuration", "if", "needed"], "project": "flink"}
{"id": 67, "code": "public List<URL> getClasspaths() {\n    return this.classpaths;\n}", "summary_tokens": ["returns", "the", "classpaths", "that", "are", "required", "by", "the", "program"], "project": "flink"}
{"id": 7606, "code": "public TypeInformation<F> getFieldType() {\n    return fieldType;\n}", "summary_tokens": ["gets", "the", "type", "information", "for", "the", "type", "of", "the", "field"], "project": "flink"}
{"id": 9068, "code": "private static void write(Document doc, Writer w, int indent) {\n    final XmlOutput out = new XmlOutput(w);\n    out.setGlob(true);\n    out.setIndentString(Spaces.of(indent));\n    writeNode(doc, out);\n}", "summary_tokens": ["serializes", "an", "xml", "document", "as", "text"], "project": "flink"}
{"id": 672, "code": "public void testAsyncErrorRethrownOnCheckpoint() throws Throwable {\n    final DummyFlinkKafkaProducer<String> producer =\n            new DummyFlinkKafkaProducer<>(\n                    FakeStandardProducerConfig.get(),\n                    new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()),\n                    null);\n\n    OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer));\n\n    testHarness.open();\n\n    testHarness.processElement(new StreamRecord<>(\"msg-1\"));\n\n        \n    producer.getPendingCallbacks()\n            .get(0)\n            .onCompletion(null, new Exception(\"artificial async exception\"));\n\n    try {\n        testHarness.snapshot(123L, 123L);\n    } catch (Exception e) {\n            \n        Assert.assertTrue(e.getCause().getMessage().contains(\"artificial async exception\"));\n\n            \n        return;\n    }\n\n    Assert.fail();\n}", "summary_tokens": ["test", "ensuring", "that", "if", "a", "snapshot", "call", "happens", "right", "after", "an", "async", "exception", "is", "caught", "it", "should", "be", "rethrown"], "project": "flink"}
{"id": 4849, "code": "public boolean isShutdown() {\n    return isShutDown;\n}", "summary_tokens": ["checks", "whether", "the", "memory", "manager", "has", "been", "shut", "down"], "project": "flink"}
{"id": 6728, "code": "public void setCharsetName(String charsetName) {\n    this.charsetName = charsetName;\n}", "summary_tokens": ["sets", "the", "charset", "with", "which", "the", "csv", "strings", "are", "written", "to", "the", "file"], "project": "flink"}
{"id": 737, "code": "private static Map<String, String> getModifiedOptions(\n        Map<String, String> options, Consumer<Map<String, String>> optionModifier) {\n    optionModifier.accept(options);\n    return options;\n}", "summary_tokens": ["returns", "the", "full", "options", "modified", "by", "the", "given", "consumer", "option", "modifier"], "project": "flink"}
{"id": 3695, "code": "public TypeSerializerFactory<?> getSerializer() {\n    return serializer;\n}", "summary_tokens": ["gets", "the", "serializer", "from", "this", "channel"], "project": "flink"}
{"id": 3777, "code": "public void testConsecutiveUnionsWithBroadcast() throws Exception {\n\n        \n        \n        \n\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    DataSet<Tuple2<Long, Long>> src1 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src2 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src3 = env.fromElements(new Tuple2<>(0L, 0L));\n    DataSet<Tuple2<Long, Long>> src4 = env.fromElements(new Tuple2<>(0L, 0L));\n\n    DataSet<Tuple2<Long, Long>> union12 = src1.union(src2);\n    DataSet<Tuple2<Long, Long>> union123 = union12.union(src3);\n    union123.join(src4, JoinOperatorBase.JoinHint.BROADCAST_HASH_FIRST)\n            .where(0)\n            .equalTo(0)\n            .name(\"join\")\n            .output(\n                    new DiscardingOutputFormat<\n                            Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>())\n            .name(\"out\");\n\n        \n        \n        \n\n    OptimizedPlan optimizedPlan = compileNoStats(env.createProgramPlan());\n\n    OptimizerPlanNodeResolver resolver = getOptimizerPlanNodeResolver(optimizedPlan);\n\n    DualInputPlanNode join = resolver.getNode(\"join\");\n\n        \n    assertEquals(\n            \"First join input should be fully replicated.\",\n            PartitioningProperty.FULL_REPLICATION,\n            join.getInput1().getGlobalProperties().getPartitioning());\n\n    NAryUnionPlanNode union = (NAryUnionPlanNode) join.getInput1().getSource();\n        \n    for (Channel c : union.getInputs()) {\n        assertEquals(\n                \"Union input should be fully replicated\",\n                PartitioningProperty.FULL_REPLICATION,\n                c.getGlobalProperties().getPartitioning());\n        assertEquals(\n                \"Union input channel should be broadcasting\",\n                ShipStrategyType.BROADCAST,\n                c.getShipStrategy());\n    }\n}", "summary_tokens": ["checks", "that", "a", "plan", "with", "consecutive", "unions", "followed", "by", "broadcast", "fwd", "join", "is", "correctly", "translated"], "project": "flink"}
{"id": 3336, "code": "public void setInput(DataSet<Vertex<K, VV>> inputData) {\n    this.initialVertices = inputData;\n}", "summary_tokens": ["sets", "the", "input", "data", "set", "for", "this", "operator"], "project": "flink"}
{"id": 8720, "code": "private RexSimplify withPredicateElimination(boolean predicateElimination) {\n    return predicateElimination == this.predicateElimination\n            ? this\n            : new RexSimplify(\n                    rexBuilder,\n                    predicates,\n                    defaultUnknownAs,\n                    predicateElimination,\n                    paranoid,\n                    executor);\n}", "summary_tokens": ["returns", "a", "rex", "simplify", "the", "same", "as", "this", "but", "with", "a", "specified", "predicate", "elimination", "value"], "project": "flink"}
{"id": 1657, "code": "public static String[] parseLocalStateDirectories(Configuration configuration) {\n    String configValue =\n            configuration.getString(\n                    CheckpointingOptions.LOCAL_RECOVERY_TASK_MANAGER_STATE_ROOT_DIRS, \"\");\n    return splitPaths(configValue);\n}", "summary_tokens": ["extracts", "the", "local", "state", "directories", "as", "defined", "by", "checkpointing", "options", "local", "recovery", "task", "manager", "state", "root", "dirs"], "project": "flink"}
{"id": 2319, "code": "public static void addDeprecations(DeprecationDelta[] deltas) {\n    DeprecationContext prev, next;\n    do {\n        prev = deprecationContext.get();\n        next = new DeprecationContext(prev, deltas);\n    } while (!deprecationContext.compareAndSet(prev, next));\n}", "summary_tokens": ["adds", "a", "set", "of", "deprecated", "keys", "to", "the", "global", "deprecations"], "project": "flink"}
{"id": 5239, "code": "public Router<T> notFound(T target) {\n    this.notFound = target;\n    return this;\n}", "summary_tokens": ["sets", "the", "fallback", "target", "for", "use", "when", "there", "s", "no", "match", "at", "route", "http", "method", "string"], "project": "flink"}
{"id": 7890, "code": "public void testMultipleInputYieldsWatermarkOnlyWhenAllChannelsReceivesWatermarks()\n        throws Exception {\n    StatusWatermarkOutput valveOutput = new StatusWatermarkOutput();\n    StatusWatermarkValve valve = new StatusWatermarkValve(3);\n\n    valve.inputWatermark(new Watermark(0), 0, valveOutput);\n    valve.inputWatermark(new Watermark(0), 1, valveOutput);\n    assertEquals(null, valveOutput.popLastSeenOutput());\n\n        \n    valve.inputWatermark(new Watermark(0), 2, valveOutput);\n    assertEquals(new Watermark(0), valveOutput.popLastSeenOutput());\n    assertEquals(null, valveOutput.popLastSeenOutput());\n}", "summary_tokens": ["tests", "that", "the", "valve", "yields", "a", "watermark", "only", "when", "all", "inputs", "have", "received", "a", "watermark"], "project": "flink"}
{"id": 8848, "code": "public final UnresolvedReferenceExpression[] operands() {\n    int operandCount = operandCount();\n    Preconditions.checkState(\n            operandCount >= 0, \"inputCount must be greater than or equal to 0.\");\n    UnresolvedReferenceExpression[] ret = new UnresolvedReferenceExpression[operandCount];\n    for (int i = 0; i < operandCount; i++) {\n        String name = String.valueOf(i);\n        validateOperandName(name);\n        ret[i] = unresolvedRef(name);\n    }\n    return ret;\n}", "summary_tokens": ["args", "of", "accumulate", "and", "retract", "the", "input", "value", "usually", "obtained", "from", "a", "new", "arrived", "data"], "project": "flink"}
{"id": 123, "code": "public List<Collection<RequestEntryT>> snapshotState() {\n    return Arrays.asList(\n            bufferedRequestEntries.stream()\n                    .map(RequestEntryWrapper::getRequestEntry)\n                    .collect(Collectors.toList()));\n}", "summary_tokens": ["all", "in", "flight", "requests", "that", "are", "relevant", "for", "the", "snapshot", "have", "been", "completed", "but", "there", "may", "still", "be", "request", "entries", "in", "the", "internal", "buffers", "that", "are", "yet", "to", "be", "sent", "to", "the", "endpoint"], "project": "flink"}
{"id": 3691, "code": "public double getRelativeTempMemory() {\n    return this.relativeTempMemory;\n}", "summary_tokens": ["gets", "the", "memory", "for", "materializing", "the", "channel", "s", "result", "from", "this", "channel"], "project": "flink"}
{"id": 3553, "code": "public void testJMXAvailability() throws Exception {\n    final JMXReporter rep1 = new JMXReporter(\"9040-9055\");\n    final JMXReporter rep2 = new JMXReporter(\"9040-9055\");\n\n    Gauge<Integer> g1 = () -> 1;\n    Gauge<Integer> g2 = () -> 2;\n\n    rep1.notifyOfAddedMetric(g1, \"rep1\", metricGroup);\n    rep2.notifyOfAddedMetric(g2, \"rep2\", metricGroup);\n\n    ObjectName objectName1 =\n            new ObjectName(\n                    JMX_DOMAIN_PREFIX + \"taskmanager.rep1\",\n                    JMXReporter.generateJmxTable(metricGroup.getAllVariables()));\n    ObjectName objectName2 =\n            new ObjectName(\n                    JMX_DOMAIN_PREFIX + \"taskmanager.rep2\",\n                    JMXReporter.generateJmxTable(metricGroup.getAllVariables()));\n\n    JMXServiceURL url1 =\n            new JMXServiceURL(\n                    \"service:jmx:rmi://localhost:\"\n                            + rep1.getPort().get()\n                            + \"/jndi/rmi://localhost:\"\n                            + rep1.getPort().get()\n                            + \"/jmxrmi\");\n    JMXConnector jmxCon1 = JMXConnectorFactory.connect(url1);\n    MBeanServerConnection mCon1 = jmxCon1.getMBeanServerConnection();\n\n    assertEquals(1, mCon1.getAttribute(objectName1, \"Value\"));\n    assertEquals(2, mCon1.getAttribute(objectName2, \"Value\"));\n\n    jmxCon1.close();\n\n    JMXServiceURL url2 =\n            new JMXServiceURL(\n                    \"service:jmx:rmi://localhost:\"\n                            + rep2.getPort().get()\n                            + \"/jndi/rmi://localhost:\"\n                            + rep2.getPort().get()\n                            + \"/jmxrmi\");\n    JMXConnector jmxCon2 = JMXConnectorFactory.connect(url2);\n    MBeanServerConnection mCon2 = jmxCon2.getMBeanServerConnection();\n\n    assertEquals(1, mCon2.getAttribute(objectName1, \"Value\"));\n    assertEquals(2, mCon2.getAttribute(objectName2, \"Value\"));\n\n        \n    assertEquals(url1, url2);\n\n    rep1.notifyOfRemovedMetric(g1, \"rep1\", null);\n    rep1.notifyOfRemovedMetric(g2, \"rep2\", null);\n\n    jmxCon2.close();\n\n    rep1.close();\n    rep2.close();\n}", "summary_tokens": ["verifies", "that", "we", "can", "connect", "to", "multiple", "jmxreporters", "running", "on", "the", "same", "machine"], "project": "flink"}
{"id": 6417, "code": "public void testRecoverWorkerFromPreviousAttempt() throws Exception {\n    new Context() {\n        {\n            final ResourceID tmResourceId = ResourceID.generate();\n\n            runTest(\n                    () -> {\n                        runInMainThread(\n                                () ->\n                                        getResourceManager()\n                                                .onPreviousAttemptWorkersRecovered(\n                                                        Collections.singleton(tmResourceId)));\n                        CompletableFuture<RegistrationResponse> registerTaskExecutorFuture =\n                                registerTaskExecutor(tmResourceId);\n                        assertThat(\n                                registerTaskExecutorFuture.get(TIMEOUT_SEC, TimeUnit.SECONDS),\n                                instanceOf(RegistrationResponse.Success.class));\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "workers", "from", "previous", "attempt", "successfully", "recovered", "and", "registered"], "project": "flink"}
{"id": 6959, "code": "ColumnFamilyOptions createBaseCommonColumnOptions() {\n    return new ColumnFamilyOptions();\n}", "summary_tokens": ["create", "a", "column", "family", "options", "for", "rocks", "db", "including", "some", "common", "settings"], "project": "flink"}
{"id": 8406, "code": "public static DynamicTableSource createTableSource(\n        @Nullable Catalog catalog,\n        ObjectIdentifier objectIdentifier,\n        ResolvedCatalogTable catalogTable,\n        ReadableConfig configuration,\n        ClassLoader classLoader,\n        boolean isTemporary) {\n    final DefaultDynamicTableContext context =\n            new DefaultDynamicTableContext(\n                    objectIdentifier, catalogTable, configuration, classLoader, isTemporary);\n\n    return createDynamicTableSource(\n            getDynamicTableFactory(DynamicTableSourceFactory.class, catalog, context),\n            objectIdentifier,\n            catalogTable,\n            configuration,\n            classLoader,\n            isTemporary);\n}", "summary_tokens": ["creates", "a", "dynamic", "table", "source", "from", "a", "catalog", "table"], "project": "flink"}
{"id": 2063, "code": "public static String generateRandomAlphanumericString(Random rnd, int length) {\n    checkNotNull(rnd);\n    checkArgument(length >= 0);\n\n    StringBuilder buffer = new StringBuilder(length);\n    for (int i = 0; i < length; i++) {\n        buffer.append(nextAlphanumericChar(rnd));\n    }\n    return buffer.toString();\n}", "summary_tokens": ["creates", "a", "random", "alphanumeric", "string", "of", "given", "length"], "project": "flink"}
{"id": 405, "code": "private HiveConf createConf(HiveConf conf, Map<String, String> confOverlay, boolean runAsync) {\n\n    if (confOverlay != null && !confOverlay.isEmpty()) {\n        conf = (conf == null ? new HiveConf() : new HiveConf(conf));\n\n            \n        for (Map.Entry<String, String> confEntry : confOverlay.entrySet()) {\n            try {\n                conf.verifyAndSet(confEntry.getKey(), confEntry.getValue());\n            } catch (IllegalArgumentException e) {\n                throw new RuntimeException(\"Error applying statement specific settings\", e);\n            }\n        }\n    } else if (runAsync) {\n        conf = (conf == null ? new HiveConf() : new HiveConf(conf));\n    }\n\n    if (conf == null) {\n        conf = new HiveConf();\n    }\n\n    conf.setVar(HiveConf.ConfVars.HIVEQUERYID, QueryPlan.makeQueryId());\n    return conf;\n}", "summary_tokens": ["if", "there", "are", "query", "specific", "settings", "to", "overlay", "then", "create", "a", "copy", "of", "config", "there", "are", "two", "cases", "we", "need", "to", "clone", "the", "session", "config", "that", "s", "being", "passed", "to", "hive", "driver", "0"], "project": "flink"}
{"id": 2914, "code": "public void testMaxByComparisonSpecialCase1() {\n    SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>> maxByTuple =\n            new SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>>(\n                    tupleTypeInfo, new int[] {0, 3});\n\n    try {\n        Assert.assertSame(\n                \"SelectByMax must return the first given tuple\",\n                specialCaseBigger,\n                maxByTuple.reduce(specialCaseBigger, bigger));\n        Assert.assertSame(\n                \"SelectByMax must return the first given tuple\",\n                bigger,\n                maxByTuple.reduce(bigger, specialCaseBigger));\n    } catch (Exception e) {\n        Assert.fail(\"No exception should be thrown while comparing both tuples\");\n    }\n}", "summary_tokens": ["this", "test", "cases", "checks", "when", "two", "tuples", "only", "differ", "in", "one", "value", "but", "this", "value", "is", "not", "in", "the", "fields", "list"], "project": "flink"}
{"id": 2133, "code": "static <A, B, C, D> TriFunction<A, B, C, D> unchecked(\n        TriFunctionWithException<A, B, C, D, ?> triFunctionWithException) {\n    return (A a, B b, C c) -> {\n        try {\n            return triFunctionWithException.apply(a, b, c);\n        } catch (Throwable t) {\n            ExceptionUtils.rethrow(t);\n                \n            return null;\n        }\n    };\n}", "summary_tokens": ["convert", "at", "tri", "function", "with", "exception", "into", "a", "tri", "function"], "project": "flink"}
{"id": 5330, "code": "public void close() throws InterruptedException {\n    if (!closed.compareAndSet(false, true)) {\n        LOG.debug(\"The executor notifier has been closed.\");\n        return;\n    }\n        \n    workerExecutor.shutdownNow();\n    workerExecutor.awaitTermination(Long.MAX_VALUE, TimeUnit.SECONDS);\n}", "summary_tokens": ["close", "the", "executor", "notifier"], "project": "flink"}
{"id": 9231, "code": "public void cleanupState(long time) {\n    rightState.clear();\n}", "summary_tokens": ["the", "method", "to", "be", "called", "when", "a", "cleanup", "timer", "fires"], "project": "flink"}
{"id": 4775, "code": "public void setName(String name) {\n    this.name = name == null ? DEFAULT_NAME : name;\n}", "summary_tokens": ["sets", "the", "name", "of", "the", "vertex"], "project": "flink"}
{"id": 7182, "code": "public void setCheckpointInterval(long checkpointInterval) {\n    if (checkpointInterval < MINIMAL_CHECKPOINT_TIME) {\n        throw new IllegalArgumentException(\n                String.format(\n                        \"Checkpoint interval must be larger than or equal to %s ms\",\n                        MINIMAL_CHECKPOINT_TIME));\n    }\n    this.checkpointInterval = checkpointInterval;\n}", "summary_tokens": ["sets", "the", "interval", "in", "which", "checkpoints", "are", "periodically", "scheduled"], "project": "flink"}
{"id": 3867, "code": "public void invoke(IN value, Context context) throws Exception {\n\n    synchronized (collectedResult) {\n        collectedResult.add(value);\n    }\n}", "summary_tokens": ["collect", "the", "sink", "value", "into", "a", "static", "list", "so", "that", "the", "client", "side", "can", "fetch", "the", "result", "of", "flink", "job", "in", "test", "cases"], "project": "flink"}
{"id": 5556, "code": "public void shutDown() throws FlinkException {\n\n    Exception exception = null;\n\n    try {\n        taskManagerStateStore.shutdown();\n    } catch (Exception e) {\n        exception = e;\n    }\n\n    try {\n        ioManager.close();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    try {\n        shuffleEnvironment.close();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    try {\n        kvStateService.shutdown();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    try {\n        taskSlotTable.close();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    try {\n        jobLeaderService.stop();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    try {\n        ioExecutor.shutdown();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    try {\n        jobTable.close();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    try {\n        libraryCacheManager.shutdown();\n    } catch (Exception e) {\n        exception = ExceptionUtils.firstOrSuppressed(e, exception);\n    }\n\n    taskEventDispatcher.clearAll();\n\n    if (exception != null) {\n        throw new FlinkException(\n                \"Could not properly shut down the TaskManager services.\", exception);\n    }\n}", "summary_tokens": ["shuts", "the", "task", "executor", "services", "down"], "project": "flink"}
{"id": 1795, "code": "public float getFloatLittleEndian(int index) {\n    return Float.intBitsToFloat(getIntLittleEndian(index));\n}", "summary_tokens": ["reads", "a", "single", "precision", "floating", "point", "value", "0", "bit", "0", "bytes", "from", "the", "given", "position", "in", "little", "endian", "byte", "order"], "project": "flink"}
{"id": 4272, "code": "public static List<KeyedStateHandle> getManagedKeyedStateHandles(\n        OperatorState operatorState, KeyGroupRange subtaskKeyGroupRange) {\n\n    final int parallelism = operatorState.getParallelism();\n\n    List<KeyedStateHandle> subtaskKeyedStateHandles = null;\n\n    for (int i = 0; i < parallelism; i++) {\n        if (operatorState.getState(i) != null) {\n\n            Collection<KeyedStateHandle> keyedStateHandles =\n                    operatorState.getState(i).getManagedKeyedState();\n\n            if (subtaskKeyedStateHandles == null) {\n                subtaskKeyedStateHandles =\n                        new ArrayList<>(parallelism * keyedStateHandles.size());\n            }\n\n            extractIntersectingState(\n                    keyedStateHandles, subtaskKeyGroupRange, subtaskKeyedStateHandles);\n        }\n    }\n\n    return subtaskKeyedStateHandles != null ? subtaskKeyedStateHandles : emptyList();\n}", "summary_tokens": ["collect", "key", "groups", "state", "handle", "managed", "keyed", "state", "handles", "which", "have", "intersection", "with", "given", "key", "group", "range", "from", "task", "state", "operator", "state"], "project": "flink"}
{"id": 1712, "code": "public boolean initOutPathLocalFS(Path outPath, WriteMode writeMode, boolean createDirectory)\n        throws IOException {\n    if (isDistributedFS()) {\n        return false;\n    }\n\n        \n        \n        \n        \n        \n\n        \n        \n    try {\n        OUTPUT_DIRECTORY_INIT_LOCK.lockInterruptibly();\n    } catch (InterruptedException e) {\n            \n        Thread.currentThread().interrupt();\n\n            \n        throw new IOException(\n                \"The thread was interrupted while trying to initialize the output directory\");\n    }\n\n    try {\n        FileStatus status;\n        try {\n            status = getFileStatus(outPath);\n        } catch (FileNotFoundException e) {\n                \n            status = null;\n        }\n\n            \n        if (status != null) {\n                \n            switch (writeMode) {\n                case NO_OVERWRITE:\n                    if (status.isDir() && createDirectory) {\n                        return true;\n                    } else {\n                            \n                        throw new IOException(\n                                \"File or directory \"\n                                        + outPath\n                                        + \" already exists. Existing files and directories \"\n                                        + \"are not overwritten in \"\n                                        + WriteMode.NO_OVERWRITE.name()\n                                        + \" mode. Use \"\n                                        + WriteMode.OVERWRITE.name()\n                                        + \" mode to overwrite existing files and directories.\");\n                    }\n\n                case OVERWRITE:\n                    if (status.isDir()) {\n                        if (createDirectory) {\n                                \n                            return true;\n                        } else {\n                                \n                            try {\n                                delete(outPath, true);\n                            } catch (IOException e) {\n                                throw new IOException(\n                                        \"Could not remove existing directory '\"\n                                                + outPath\n                                                + \"' to allow overwrite by result file\",\n                                        e);\n                            }\n                        }\n                    } else {\n                            \n                        try {\n                            delete(outPath, false);\n                        } catch (IOException e) {\n                            throw new IOException(\n                                    \"Could not remove existing file '\"\n                                            + outPath\n                                            + \"' to allow overwrite by result file/directory\",\n                                    e);\n                        }\n                    }\n                    break;\n\n                default:\n                    throw new IllegalArgumentException(\"Invalid write mode: \" + writeMode);\n            }\n        }\n\n        if (createDirectory) {\n                \n            if (!exists(outPath)) {\n                mkdirs(outPath);\n            }\n\n                \n            try {\n                return getFileStatus(outPath).isDir();\n            } catch (FileNotFoundException e) {\n                return false;\n            }\n        } else {\n                \n                \n            return !exists(outPath);\n        }\n    } finally {\n        OUTPUT_DIRECTORY_INIT_LOCK.unlock();\n    }\n}", "summary_tokens": ["initializes", "output", "directories", "on", "local", "file", "systems", "according", "to", "the", "given", "write", "mode"], "project": "flink"}
{"id": 1530, "code": "public void setFields(T0 f0, T1 f1, T2 f2) {\n    this.f0 = f0;\n    this.f1 = f1;\n    this.f2 = f2;\n}", "summary_tokens": ["sets", "new", "values", "to", "all", "fields", "of", "the", "tuple"], "project": "flink"}
{"id": 3402, "code": "public static <T> DataSet<LongValue> count(DataSet<T> input) {\n    return input.map(new MapTo<>(new LongValue(1)))\n            .returns(LONG_VALUE_TYPE_INFO)\n            .name(\"Emit 1\")\n            .reduce(new AddLongValue())\n            .name(\"Sum\");\n}", "summary_tokens": ["count", "the", "number", "of", "elements", "in", "a", "data", "set"], "project": "flink"}
{"id": 2736, "code": "public String getCharset() {\n    return this.charset;\n}", "summary_tokens": ["gets", "the", "character", "set", "for", "the", "reader"], "project": "flink"}
{"id": 7170, "code": "public <ACC, V, R> SingleOutputStreamOperator<R> aggregate(\n        AggregateFunction<T, ACC, V> aggregateFunction,\n        ProcessWindowFunction<V, R, K, W> windowFunction,\n        TypeInformation<ACC> accumulatorType,\n        TypeInformation<V> aggregateResultType,\n        TypeInformation<R> resultType) {\n\n    checkNotNull(aggregateFunction, \"aggregateFunction\");\n    checkNotNull(windowFunction, \"windowFunction\");\n    checkNotNull(accumulatorType, \"accumulatorType\");\n    checkNotNull(aggregateResultType, \"aggregateResultType\");\n    checkNotNull(resultType, \"resultType\");\n\n    if (aggregateFunction instanceof RichFunction) {\n        throw new UnsupportedOperationException(\n                \"This aggregate function cannot be a RichFunction.\");\n    }\n\n        \n    windowFunction = input.getExecutionEnvironment().clean(windowFunction);\n    aggregateFunction = input.getExecutionEnvironment().clean(aggregateFunction);\n\n    final String opName = builder.generateOperatorName(aggregateFunction, windowFunction);\n\n    OneInputStreamOperator<T, R> operator =\n            builder.aggregate(aggregateFunction, windowFunction, accumulatorType);\n\n    return input.transform(opName, resultType, operator);\n}", "summary_tokens": ["applies", "the", "given", "window", "function", "to", "each", "window"], "project": "flink"}
{"id": 5085, "code": "public void run() {\n    try {\n        go();\n    } catch (Throwable t) {\n        internalHandleException(\n                new IOException(\n                        \"Thread '\"\n                                + getName()\n                                + \"' terminated due to an exception: \"\n                                + t.getMessage(),\n                        t));\n    }\n}", "summary_tokens": ["implements", "exception", "handling", "and", "delegates", "to", "go"], "project": "flink"}
{"id": 6993, "code": "private KeyedBackendSerializationProxy<K> readMetaData(StreamStateHandle metaStateHandle)\n        throws Exception {\n\n    InputStream inputStream = null;\n\n    try {\n        inputStream = metaStateHandle.openInputStream();\n        cancelStreamRegistry.registerCloseable(inputStream);\n        DataInputView in = new DataInputViewStreamWrapper(inputStream);\n        return readMetaData(in);\n    } finally {\n        if (cancelStreamRegistry.unregisterCloseable(inputStream)) {\n            inputStream.close();\n        }\n    }\n}", "summary_tokens": ["reads", "flink", "s", "state", "meta", "data", "file", "from", "the", "state", "handle"], "project": "flink"}
{"id": 4348, "code": "public ResourceProfile getTaskResourceProfile() {\n    return taskResourceProfile;\n}", "summary_tokens": ["returns", "the", "desired", "resource", "profile", "for", "the", "task", "slot"], "project": "flink"}
{"id": 6255, "code": "public void testPartitionNotFoundExceptionWhileGetNextBuffer() throws Exception {\n    final SingleInputGate inputGate = createSingleInputGate(1);\n    final LocalInputChannel localChannel =\n            createLocalInputChannel(inputGate, new ResultPartitionManager());\n    final ResultPartitionID partitionId = localChannel.getPartitionId();\n\n    inputGate.setInputChannels(localChannel);\n    localChannel.setError(new PartitionNotFoundException(partitionId));\n    try {\n        inputGate.getNext();\n\n        fail(\"Should throw a PartitionNotFoundException.\");\n    } catch (PartitionNotFoundException notFound) {\n        assertThat(partitionId, is(notFound.getPartitionId()));\n    }\n}", "summary_tokens": ["tests", "that", "if", "the", "partition", "not", "found", "exception", "is", "set", "onto", "one", "input", "channel", "then", "it", "would", "be", "thrown", "directly", "via", "single", "input", "gate", "get", "next"], "project": "flink"}
{"id": 3460, "code": "public <K, OUT> DataSource<OUT> readKeyedState(\n        String uid,\n        KeyedStateReaderFunction<K, OUT> function,\n        TypeInformation<K> keyTypeInfo,\n        TypeInformation<OUT> outTypeInfo)\n        throws IOException {\n\n    OperatorState operatorState = metadata.getOperatorState(uid);\n    KeyedStateInputFormat<K, VoidNamespace, OUT> inputFormat =\n            new KeyedStateInputFormat<>(\n                    operatorState,\n                    stateBackend,\n                    env.getConfiguration(),\n                    new KeyedStateReaderOperator<>(function, keyTypeInfo));\n\n    return env.createInput(inputFormat, outTypeInfo);\n}", "summary_tokens": ["read", "keyed", "state", "from", "an", "operator", "in", "a", "savepoint"], "project": "flink"}
{"id": 4549, "code": "public Buffer compressToOriginalBuffer(Buffer buffer) {\n    int compressedLen;\n    if ((compressedLen = compress(buffer)) == 0) {\n        return buffer;\n    }\n\n        \n    int memorySegmentOffset = buffer.getMemorySegmentOffset();\n    MemorySegment segment = buffer.getMemorySegment();\n    segment.put(memorySegmentOffset, internalBuffer.array(), 0, compressedLen);\n\n    return new ReadOnlySlicedNetworkBuffer(\n            buffer.asByteBuf(), 0, compressedLen, memorySegmentOffset, true);\n}", "summary_tokens": ["the", "difference", "between", "this", "method", "and", "compress", "to", "intermediate", "buffer", "buffer", "is", "that", "this", "method", "will", "copy", "the", "compressed", "data", "back", "to", "the", "input", "buffer", "starting", "from", "offset", "0"], "project": "flink"}
{"id": 8320, "code": "public static int hashByWords(MemorySegment[] segments, int offset, int numBytes) {\n    if (inFirstSegment(segments, offset, numBytes)) {\n        return MurmurHashUtils.hashBytesByWords(segments[0], offset, numBytes);\n    } else {\n        return hashMultiSegByWords(segments, offset, numBytes);\n    }\n}", "summary_tokens": ["hash", "segments", "to", "int", "num", "bytes", "must", "be", "aligned", "to", "0", "bytes"], "project": "flink"}
{"id": 6148, "code": "public void testRequestMemorySegmentsTimeout() throws Exception {\n    final int numBuffers = 10;\n    final int numberOfSegmentsToRequest = 2;\n    final Duration requestSegmentsTimeout = Duration.ofMillis(50L);\n\n    NetworkBufferPool globalPool =\n            new NetworkBufferPool(numBuffers, 128, requestSegmentsTimeout);\n\n    BufferPool localBufferPool = globalPool.createBufferPool(1, numBuffers);\n    for (int i = 0; i < numBuffers; ++i) {\n        localBufferPool.requestBuffer();\n    }\n\n    assertEquals(0, globalPool.getNumberOfAvailableMemorySegments());\n\n    CheckedThread asyncRequest =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                    globalPool.requestMemorySegments(numberOfSegmentsToRequest);\n                }\n            };\n\n    asyncRequest.start();\n\n    expectedException.expect(IOException.class);\n    expectedException.expectMessage(\"Timeout\");\n\n    try {\n        asyncRequest.sync();\n    } finally {\n        globalPool.destroy();\n    }\n}", "summary_tokens": ["tests", "network", "buffer", "pool", "request", "memory", "segments", "int", "and", "verifies", "it", "will", "end", "exceptionally", "when", "failing", "to", "acquire", "all", "the", "segments", "in", "the", "specific", "timeout"], "project": "flink"}
{"id": 2733, "code": "public CsvReader fieldDelimiter(String delimiter) {\n    this.fieldDelimiter = delimiter;\n    return this;\n}", "summary_tokens": ["configures", "the", "delimiter", "that", "separates", "the", "fields", "within", "a", "row"], "project": "flink"}
{"id": 2811, "code": "public <R> GroupCombineOperator<T, R> combineGroup(GroupCombineFunction<T, R> combiner) {\n    if (combiner == null) {\n        throw new NullPointerException(\"GroupCombine function must not be null.\");\n    }\n    TypeInformation<R> resultType =\n            TypeExtractor.getGroupCombineReturnTypes(\n                    combiner,\n                    this.getInputDataSet().getType(),\n                    Utils.getCallLocationName(),\n                    true);\n\n    return new GroupCombineOperator<>(\n            this, resultType, inputDataSet.clean(combiner), Utils.getCallLocationName());\n}", "summary_tokens": ["applies", "a", "group", "combine", "function", "on", "a", "grouped", "data", "set"], "project": "flink"}
{"id": 2874, "code": "public static <T> Utils.ChecksumHashCode checksumHashCode(DataSet<T> input) throws Exception {\n    final String id = new AbstractID().toString();\n\n    input.output(new Utils.ChecksumHashCodeHelper<T>(id)).name(\"ChecksumHashCode\");\n\n    JobExecutionResult res = input.getExecutionEnvironment().execute();\n    return res.<Utils.ChecksumHashCode>getAccumulatorResult(id);\n}", "summary_tokens": ["convenience", "method", "to", "get", "the", "count", "number", "of", "elements", "of", "a", "data", "set", "as", "well", "as", "the", "checksum", "sum", "over", "element", "hashes"], "project": "flink"}
{"id": 7625, "code": "public void testFromSequence() {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStreamSource<Long> src = env.fromSequence(0, 2);\n\n    assertEquals(BasicTypeInfo.LONG_TYPE_INFO, src.getType());\n}", "summary_tokens": ["verifies", "that", "the", "api", "method", "doesn", "t", "throw", "and", "creates", "a", "source", "of", "the", "expected", "type"], "project": "flink"}
{"id": 1902, "code": "private static boolean byteArrayEquals(byte[] source, int start, int length, byte[] other) {\n    if (length != other.length) {\n        return false;\n    }\n    for (int i = 0; i < other.length; i++) {\n        if (Character.toLowerCase(source[i + start]) != other[i]) {\n            return false;\n        }\n    }\n    return true;\n}", "summary_tokens": ["checks", "if", "a", "part", "of", "a", "byte", "array", "matches", "another", "byte", "array", "with", "chars", "case", "insensitive"], "project": "flink"}
{"id": 6714, "code": "public void testAddAndLockRetrySuccessfulTransaction() throws Exception {\n    final TestingLongStateHandleHelper stateHandleProvider = new TestingLongStateHandleHelper();\n    final CuratorFramework client = ZOOKEEPER.getClient();\n    final ZooKeeperStateHandleStore<TestingLongStateHandleHelper.LongStateHandle> store =\n            new ZooKeeperStateHandleStore<TestingLongStateHandleHelper.LongStateHandle>(\n                    client, stateHandleProvider) {\n\n                @Override\n                protected void writeStoreHandleTransactionally(\n                        String path, byte[] serializedStoreHandle) throws Exception {\n                    super.writeStoreHandleTransactionally(path, serializedStoreHandle);\n                    throw new KeeperException.NodeExistsException(\n                            \"Committed transaction has been retried.\");\n                }\n            };\n    final String path = \"/test\";\n    final long firstState = 1337L;\n    store.addAndLock(path, new TestingLongStateHandleHelper.LongStateHandle(firstState));\n        \n    assertEquals(1, TestingLongStateHandleHelper.getGlobalStorageSize());\n    assertEquals(firstState, TestingLongStateHandleHelper.getStateHandleValueByIndex(0));\n        \n    assertEquals(0, TestingLongStateHandleHelper.getDiscardCallCountForStateHandleByIndex(0));\n        \n    assertEquals(firstState, store.getAndLock(path).retrieveState().getValue());\n}", "summary_tokens": ["transactions", "are", "not", "idempotent", "in", "the", "curator", "version", "we", "re", "currently", "using", "therefore", "we", "may", "end", "up", "retrying", "the", "transaction", "that", "has", "already", "eg"], "project": "flink"}
{"id": 2043, "code": "public static boolean getBoolean(Properties config, String key, boolean defaultValue) {\n    String val = config.getProperty(key);\n    if (val == null) {\n        return defaultValue;\n    } else {\n        return Boolean.parseBoolean(val);\n    }\n}", "summary_tokens": ["get", "boolean", "from", "properties"], "project": "flink"}
{"id": 2500, "code": "static <T> TypeSerializerSchemaCompatibility<T> resolveSchemaCompatibility(\n        Schema writerSchema, Schema readerSchema) {\n\n    if (Objects.equals(writerSchema, readerSchema)) {\n        return TypeSerializerSchemaCompatibility.compatibleAsIs();\n    }\n\n    final SchemaPairCompatibility compatibility =\n            SchemaCompatibility.checkReaderWriterCompatibility(readerSchema, writerSchema);\n\n    return avroCompatibilityToFlinkCompatibility(compatibility);\n}", "summary_tokens": ["resolves", "writer", "reader", "schema", "compatibly"], "project": "flink"}
{"id": 7462, "code": "public static Time of(long size, TimeUnit unit) {\n    return new Time(size, unit);\n}", "summary_tokens": ["creates", "a", "new", "time", "of", "the", "given", "duration", "and", "time", "unit"], "project": "flink"}
{"id": 4183, "code": "public boolean isSynchronous() {\n    return checkpointType.isSynchronous();\n}", "summary_tokens": ["returns", "whether", "the", "checkpoint", "properties", "describe", "a", "synchronous", "savepoint", "checkpoint"], "project": "flink"}
{"id": 2512, "code": "public void testDataTypeToSchemaToDataTypeNonNullable() {\n    DataType dataType =\n            DataTypes.ROW(\n                            DataTypes.FIELD(\"f_boolean\", DataTypes.BOOLEAN().notNull()),\n                                \n                            DataTypes.FIELD(\"f_int\", DataTypes.INT().notNull()),\n                            DataTypes.FIELD(\"f_bigint\", DataTypes.BIGINT().notNull()),\n                            DataTypes.FIELD(\"f_float\", DataTypes.FLOAT().notNull()),\n                            DataTypes.FIELD(\"f_double\", DataTypes.DOUBLE().notNull()),\n                                \n                            DataTypes.FIELD(\"f_string\", DataTypes.STRING().notNull()),\n                                \n                            DataTypes.FIELD(\"f_varbinary\", DataTypes.BYTES().notNull()),\n                            DataTypes.FIELD(\"f_timestamp\", DataTypes.TIMESTAMP(3).notNull()),\n                            DataTypes.FIELD(\"f_date\", DataTypes.DATE().notNull()),\n                            DataTypes.FIELD(\"f_time\", DataTypes.TIME(3).notNull()),\n                            DataTypes.FIELD(\"f_decimal\", DataTypes.DECIMAL(10, 0).notNull()),\n                            DataTypes.FIELD(\n                                    \"f_row\",\n                                    DataTypes.ROW(\n                                                    DataTypes.FIELD(\n                                                            \"f0\", DataTypes.INT().notNull()),\n                                                    DataTypes.FIELD(\n                                                            \"f1\",\n                                                            DataTypes.TIMESTAMP(3).notNull()))\n                                            .notNull()),\n                                \n                                \n                            DataTypes.FIELD(\n                                    \"f_map\",\n                                    DataTypes.MAP(\n                                                    DataTypes.STRING().notNull(),\n                                                    DataTypes.INT().notNull())\n                                            .notNull()),\n                            DataTypes.FIELD(\n                                    \"f_array\",\n                                    DataTypes.ARRAY(DataTypes.INT().notNull()).notNull()))\n                    .notNull();\n    Schema schema = AvroSchemaConverter.convertToSchema(dataType.getLogicalType());\n    DataType converted = AvroSchemaConverter.convertToDataType(schema.toString());\n    assertEquals(dataType, converted);\n}", "summary_tokens": ["test", "convert", "non", "nullable", "data", "type", "to", "avro", "schema", "then", "converts", "back"], "project": "flink"}
{"id": 1535, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 8665, "code": "public static int timestampMillisToTime(long ts) {\n    return (int) (ts % MILLIS_PER_DAY);\n}", "summary_tokens": ["get", "time", "from", "a", "timestamp"], "project": "flink"}
{"id": 8539, "code": "static List<Field> collectStructuredFields(Class<?> clazz) {\n    final List<Field> fields = new ArrayList<>();\n    while (clazz != Object.class) {\n        final Field[] declaredFields = clazz.getDeclaredFields();\n        Stream.of(declaredFields)\n                .filter(\n                        field -> {\n                            final int m = field.getModifiers();\n                            return !Modifier.isStatic(m) && !Modifier.isTransient(m);\n                        })\n                .forEach(fields::add);\n        clazz = clazz.getSuperclass();\n    }\n    return fields;\n}", "summary_tokens": ["returns", "the", "fields", "of", "a", "class", "for", "a", "structured", "type"], "project": "flink"}
{"id": 641, "code": "public static KafkaContainer createKafkaContainer(String dockerImageVersion, Logger logger) {\n    String logLevel;\n    if (logger.isTraceEnabled()) {\n        logLevel = \"TRACE\";\n    } else if (logger.isDebugEnabled()) {\n        logLevel = \"DEBUG\";\n    } else if (logger.isInfoEnabled()) {\n        logLevel = \"INFO\";\n    } else if (logger.isWarnEnabled()) {\n        logLevel = \"WARN\";\n    } else if (logger.isErrorEnabled()) {\n        logLevel = \"ERROR\";\n    } else {\n        logLevel = \"OFF\";\n    }\n\n    return new KafkaContainer(DockerImageName.parse(dockerImageVersion))\n            .withEnv(\"KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR\", \"1\")\n            .withEnv(\"KAFKA_TRANSACTION_STATE_LOG_MIN_ISR\", \"1\")\n            .withEnv(\"KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE\", \"false\")\n            .withEnv(\"KAFKA_LOG4J_ROOT_LOGLEVEL\", logLevel)\n            .withEnv(\"KAFKA_LOG4J_LOGGERS\", \"state.change.logger=\" + logLevel)\n            .withEnv(\"KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR\", \"1\")\n            .withEnv(\"KAFKA_TRANSACTION_STATE_LOG_MIN_ISR\", \"1\")\n            .withEnv(\"KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE\", \"false\")\n            .withEnv(\n                    \"KAFKA_TRANSACTION_MAX_TIMEOUT_MS\",\n                    String.valueOf(Duration.ofHours(2).toMillis()))\n            .withEnv(\"KAFKA_LOG4J_TOOLS_ROOT_LOGLEVEL\", logLevel)\n            .withLogConsumer(new Slf4jLogConsumer(logger));\n}", "summary_tokens": ["this", "method", "helps", "to", "set", "commonly", "used", "kafka", "configurations", "and", "aligns", "the", "internal", "kafka", "log", "levels", "with", "the", "ones", "used", "by", "the", "capturing", "logger"], "project": "flink"}
{"id": 4739, "code": "public void setDownstreamSubtaskStateMapper(SubtaskStateMapper downstreamSubtaskStateMapper) {\n    this.downstreamSubtaskStateMapper = checkNotNull(downstreamSubtaskStateMapper);\n}", "summary_tokens": ["sets", "the", "channel", "state", "rescaler", "used", "for", "rescaling", "persisted", "data", "on", "downstream", "side", "of", "this", "job", "edge"], "project": "flink"}
{"id": 2954, "code": "protected NumericColumnSummary<Double> summarize(Double... values) {\n    return new AggregateCombineHarness<\n            Double, NumericColumnSummary<Double>, DoubleSummaryAggregator>() {\n\n        @Override\n        protected void compareResults(\n                NumericColumnSummary<Double> result1, NumericColumnSummary<Double> result2) {\n            Assert.assertEquals(result1.getMin(), result2.getMin(), 0.0);\n            Assert.assertEquals(result1.getMax(), result2.getMax(), 0.0);\n            Assert.assertEquals(result1.getMean(), result2.getMean(), 1e-12d);\n            Assert.assertEquals(result1.getVariance(), result2.getVariance(), 1e-9d);\n            Assert.assertEquals(\n                    result1.getStandardDeviation(), result2.getStandardDeviation(), 1e-12d);\n        }\n    }.summarize(values);\n}", "summary_tokens": ["helper", "method", "for", "summarizing", "a", "list", "of", "values"], "project": "flink"}
{"id": 4846, "code": "protected void seekOutput(MemorySegment seg, int position) {\n    this.currentSegment = seg;\n    this.positionInSegment = position;\n}", "summary_tokens": ["sets", "the", "internal", "state", "to", "the", "given", "memory", "segment", "and", "the", "given", "position", "within", "the", "segment"], "project": "flink"}
{"id": 9034, "code": "public Expanded expanded(String ori) {\n    final Map<SqlParserPos, SqlIdentifier> identifiers = new HashMap<>();\n    final Map<String, SqlIdentifier> funcNameToId = new HashMap<>();\n    final SqlNode oriNode = planner.parser().parse(ori);\n        \n        \n    final SqlNode validated = planner.validate(planner.parser().parse(ori));\n    validated.accept(\n            new SqlBasicVisitor<Void>() {\n                @Override\n                public Void visit(SqlCall call) {\n                    SqlOperator operator = call.getOperator();\n                    if (operator instanceof BridgingSqlFunction) {\n                        final SqlIdentifier functionID =\n                                ((BridgingSqlFunction) operator).getSqlIdentifier();\n                        if (!functionID.isSimple()) {\n                            funcNameToId.put(Util.last(functionID.names), functionID);\n                        }\n                    }\n                    return super.visit(call);\n                }\n\n                @Override\n                public Void visit(SqlIdentifier identifier) {\n                        \n                        \n                        \n                    if (!identifier.names.get(0).startsWith(\"EXPR$\")) {\n                        identifiers.putIfAbsent(identifier.getParserPosition(), identifier);\n                    }\n                    return null;\n                }\n            });\n    return new Expanded(oriNode, identifiers, funcNameToId);\n}", "summary_tokens": ["expands", "identifiers", "in", "a", "given", "sql", "string", "returning", "a", "expanded"], "project": "flink"}
{"id": 656, "code": "public void testRestore() throws Exception {\n    final List<KafkaTopicPartition> partitions = new ArrayList<>(PARTITION_STATE.keySet());\n\n    final DummyFlinkKafkaConsumer<String> consumerFunction =\n            new DummyFlinkKafkaConsumer<>(\n                    TOPICS, partitions, FlinkKafkaConsumerBase.PARTITION_DISCOVERY_DISABLED);\n\n    StreamSource<String, DummyFlinkKafkaConsumer<String>> consumerOperator =\n            new StreamSource<>(consumerFunction);\n\n    final AbstractStreamOperatorTestHarness<String> testHarness =\n            new AbstractStreamOperatorTestHarness<>(consumerOperator, 1, 1, 0);\n\n    testHarness.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);\n\n    testHarness.setup();\n\n        \n    testHarness.initializeState(\n            OperatorSnapshotUtil.getResourceFilename(\n                    \"kafka-consumer-migration-test-flink\" + testMigrateVersion + \"-snapshot\"));\n\n    testHarness.open();\n\n        \n    assertTrue(consumerFunction.getSubscribedPartitionsToStartOffsets() != null);\n    assertTrue(!consumerFunction.getSubscribedPartitionsToStartOffsets().isEmpty());\n\n        \n    assertEquals(PARTITION_STATE, consumerFunction.getSubscribedPartitionsToStartOffsets());\n\n        \n    assertTrue(consumerFunction.getRestoredState() != null);\n    assertEquals(PARTITION_STATE, consumerFunction.getRestoredState());\n\n    consumerOperator.close();\n    consumerOperator.cancel();\n}", "summary_tokens": ["test", "restoring", "from", "a", "non", "empty", "state", "taken", "using", "a", "previous", "flink", "version", "when", "some", "partitions", "could", "be", "found", "for", "topics"], "project": "flink"}
{"id": 1517, "code": "public static <\n                T0,\n                T1,\n                T2,\n                T3,\n                T4,\n                T5,\n                T6,\n                T7,\n                T8,\n                T9,\n                T10,\n                T11,\n                T12,\n                T13,\n                T14,\n                T15,\n                T16,\n                T17,\n                T18,\n                T19,\n                T20,\n                T21>\n        Tuple22<\n                        T0,\n                        T1,\n                        T2,\n                        T3,\n                        T4,\n                        T5,\n                        T6,\n                        T7,\n                        T8,\n                        T9,\n                        T10,\n                        T11,\n                        T12,\n                        T13,\n                        T14,\n                        T15,\n                        T16,\n                        T17,\n                        T18,\n                        T19,\n                        T20,\n                        T21>\n                of(\n                        T0 f0,\n                        T1 f1,\n                        T2 f2,\n                        T3 f3,\n                        T4 f4,\n                        T5 f5,\n                        T6 f6,\n                        T7 f7,\n                        T8 f8,\n                        T9 f9,\n                        T10 f10,\n                        T11 f11,\n                        T12 f12,\n                        T13 f13,\n                        T14 f14,\n                        T15 f15,\n                        T16 f16,\n                        T17 f17,\n                        T18 f18,\n                        T19 f19,\n                        T20 f20,\n                        T21 f21) {\n    return new Tuple22<>(\n            f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17, f18,\n            f19, f20, f21);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 2724, "code": "public T reduce(T value1, T value2) throws Exception {\n\n    for (int index = 0; index < fields.length; index++) {\n            \n        int position = this.fields[index];\n\n            \n        Comparable comparable1 = value1.getFieldNotNull(position);\n        Comparable comparable2 = value2.getFieldNotNull(position);\n\n            \n        int comp = comparable1.compareTo(comparable2);\n            \n            \n        if (comp > 0) {\n            return value1;\n        } else if (comp < 0) {\n            return value2;\n        }\n    }\n    return value1;\n}", "summary_tokens": ["reduce", "implementation", "returns", "bigger", "tuple", "or", "value", "0", "if", "both", "tuples", "are", "equal"], "project": "flink"}
{"id": 6806, "code": "public static void putValueData(MemorySegment memorySegment, int offset, byte[] value) {\n    MemorySegment valueSegment = MemorySegmentFactory.wrap(value);\n    valueSegment.copyTo(0, memorySegment, offset + getValueMetaLen(), value.length);\n}", "summary_tokens": ["puts", "the", "value", "data", "into", "value", "space"], "project": "flink"}
{"id": 4800, "code": "public int getIndexInSubtaskGroup() {\n    return this.environment.getTaskInfo().getIndexOfThisSubtask();\n}", "summary_tokens": ["returns", "the", "index", "of", "this", "subtask", "in", "the", "subtask", "group"], "project": "flink"}
{"id": 2284, "code": "public FlinkImageBuilder setImageName(String imageName) {\n    this.imageName = imageName;\n    return this;\n}", "summary_tokens": ["sets", "the", "name", "of", "building", "image"], "project": "flink"}
{"id": 6868, "code": "private void setInternal(String key, String value) {\n    Preconditions.checkArgument(\n            value != null && !value.isEmpty(), \"The configuration value must not be empty.\");\n\n    configuredOptions.put(key, value);\n}", "summary_tokens": ["sets", "the", "configuration", "with", "key", "value", "if", "the", "key", "is", "predefined", "otherwise", "throws", "illegal", "argument", "exception"], "project": "flink"}
{"id": 5648, "code": "public static String getTemporaryFileDirectory() {\n    return System.getProperty(\"java.io.tmpdir\");\n}", "summary_tokens": ["gets", "the", "directory", "for", "temporary", "files", "as", "returned", "by", "the", "jvm", "system", "property", "java"], "project": "flink"}
{"id": 8813, "code": "public static RelNode convertCollectToRel(\n        FlinkRelBuilder relBuilder,\n        RelNode input,\n        CollectModifyOperation collectModifyOperation,\n        ReadableConfig configuration,\n        ClassLoader classLoader) {\n    final DataTypeFactory dataTypeFactory =\n            unwrapContext(relBuilder).getCatalogManager().getDataTypeFactory();\n    final ResolvedSchema childSchema = collectModifyOperation.getChild().getResolvedSchema();\n    final ResolvedSchema schema =\n            ResolvedSchema.physical(\n                    childSchema.getColumnNames(), childSchema.getColumnDataTypes());\n    final CatalogTable unresolvedTable = new InlineCatalogTable(schema);\n    final ResolvedCatalogTable catalogTable = new ResolvedCatalogTable(unresolvedTable, schema);\n\n    final DataType consumedDataType = fixCollectDataType(dataTypeFactory, schema);\n\n    final String zone = configuration.get(TableConfigOptions.LOCAL_TIME_ZONE);\n    final ZoneId zoneId =\n            TableConfigOptions.LOCAL_TIME_ZONE.defaultValue().equals(zone)\n                    ? ZoneId.systemDefault()\n                    : ZoneId.of(zone);\n\n    final CollectDynamicSink tableSink =\n            new CollectDynamicSink(\n                    collectModifyOperation.getTableIdentifier(),\n                    consumedDataType,\n                    configuration.get(CollectSinkOperatorFactory.MAX_BATCH_SIZE),\n                    configuration.get(CollectSinkOperatorFactory.SOCKET_TIMEOUT),\n                    classLoader,\n                    zoneId,\n                    configuration\n                            .get(ExecutionConfigOptions.TABLE_EXEC_LEGACY_CAST_BEHAVIOUR)\n                            .isEnabled());\n    collectModifyOperation.setSelectResultProvider(tableSink.getSelectResultProvider());\n    collectModifyOperation.setConsumedDataType(consumedDataType);\n    return convertSinkToRel(\n            relBuilder,\n            input,\n            Collections.emptyMap(), \n            collectModifyOperation.getTableIdentifier(),\n            Collections.emptyMap(), \n            false,\n            tableSink,\n            catalogTable);\n}", "summary_tokens": ["converts", "an", "table", "result", "collect", "sink", "to", "a", "rel", "node"], "project": "flink"}
{"id": 4859, "code": "public int getPageSize() {\n    return (int) pageSize;\n}", "summary_tokens": ["gets", "the", "size", "of", "the", "pages", "handled", "by", "the", "memory", "manager"], "project": "flink"}
{"id": 3357, "code": "public void sendMessageToAllNeighbors(Message m) {\n    if (edgesUsed) {\n        throw new IllegalStateException(\n                \"Can use either 'getEdges()' or 'sendMessageToAllNeighbors()'\"\n                        + \"exactly once.\");\n    }\n\n    edgesUsed = true;\n    outValue.f1 = m;\n\n    while (edges.hasNext()) {\n        Tuple next = (Tuple) edges.next();\n\n            \n        if (getDirection().equals(EdgeDirection.OUT)) {\n            outValue.f0 = next.getField(1);\n        }\n            \n        else if (getDirection().equals(EdgeDirection.IN)) {\n            outValue.f0 = next.getField(0);\n        }\n            \n        if (getDirection().equals(EdgeDirection.ALL)) {\n            if (next.getField(0).equals(vertexId)) {\n                    \n                outValue.f0 = next.getField(1);\n            } else {\n                    \n                outValue.f0 = next.getField(0);\n            }\n        }\n        out.collect(outValue);\n    }\n}", "summary_tokens": ["sends", "the", "given", "message", "to", "all", "vertices", "that", "are", "targets", "of", "an", "edge", "of", "the", "changed", "vertex"], "project": "flink"}
{"id": 5487, "code": "public boolean remove(@Nonnull T toRemove) {\n    T storedElement = getDedupMapForElement(toRemove).remove(toRemove);\n    return storedElement != null && super.remove(storedElement);\n}", "summary_tokens": ["in", "contrast", "to", "the", "superclass", "and", "to", "maintain", "set", "semantics", "removal", "here", "is", "based", "on", "comparing", "the", "given", "element", "via", "equals", "object"], "project": "flink"}
{"id": 103, "code": "public KinesisDataStreamsSinkBuilder<InputT> setStreamName(String streamName) {\n    this.streamName = streamName;\n    return this;\n}", "summary_tokens": ["sets", "the", "name", "of", "the", "kds", "stream", "that", "the", "sink", "will", "connect", "to"], "project": "flink"}
{"id": 7723, "code": "public void testManualHashAssignmentForStartNodeInInChain() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(4);\n\n    env.addSource(new NoOpSourceFunction())\n            .uid(\"source\")\n            .map(new NoOpMapFunction())\n            .addSink(new DiscardingSink<>());\n\n    env.getStreamGraph().getJobGraph();\n}", "summary_tokens": ["tests", "that", "a", "manual", "hash", "at", "the", "beginning", "of", "a", "chain", "is", "accepted"], "project": "flink"}
{"id": 9464, "code": "protected long utcMills(String timestampStr) {\n    LocalDateTime localDateTime = LocalDateTime.parse(timestampStr);\n    return localDateTime.atZone(UTC_ZONE_ID).toInstant().toEpochMilli();\n}", "summary_tokens": ["get", "utc", "mills", "from", "a", "timestamp", "string", "and", "the", "parameterized", "time", "zone"], "project": "flink"}
{"id": 7276, "code": "public static LocalStreamEnvironment createLocalEnvironment(Configuration configuration) {\n    if (configuration.getOptional(CoreOptions.DEFAULT_PARALLELISM).isPresent()) {\n        return new LocalStreamEnvironment(configuration);\n    } else {\n        Configuration copyOfConfiguration = new Configuration();\n        copyOfConfiguration.addAll(configuration);\n        copyOfConfiguration.set(CoreOptions.DEFAULT_PARALLELISM, defaultLocalParallelism);\n        return new LocalStreamEnvironment(copyOfConfiguration);\n    }\n}", "summary_tokens": ["creates", "a", "local", "stream", "environment"], "project": "flink"}
{"id": 8611, "code": "public boolean isNullable() {\n    return isNullable;\n}", "summary_tokens": ["returns", "whether", "a", "value", "of", "this", "type", "can", "be", "null"], "project": "flink"}
{"id": 1747, "code": "public String[] getHostnames() {\n    return this.hostnames;\n}", "summary_tokens": ["returns", "the", "names", "of", "the", "hosts", "storing", "the", "data", "this", "input", "split", "refers", "to"], "project": "flink"}
{"id": 4566, "code": "public void destroyAllBufferPools() {\n    synchronized (factoryLock) {\n            \n        LocalBufferPool[] poolsCopy =\n                allBufferPools.toArray(new LocalBufferPool[allBufferPools.size()]);\n\n        for (LocalBufferPool pool : poolsCopy) {\n            pool.lazyDestroy();\n        }\n\n            \n        if (allBufferPools.size() > 0 || numTotalRequiredBuffers > 0) {\n            throw new IllegalStateException(\n                    \"NetworkBufferPool is not empty after destroying all LocalBufferPools\");\n        }\n    }\n}", "summary_tokens": ["destroys", "all", "buffer", "pools", "that", "allocate", "their", "buffers", "from", "this", "buffer", "pool", "created", "via", "create", "buffer", "pool", "int", "int"], "project": "flink"}
{"id": 6641, "code": "public void testReleaseForSuccessfulSnapshot() throws IOException {\n    int numberOfKeyGroups = 10;\n    CopyOnWriteStateTable<Integer, Integer, Float> table =\n            createStateTableForSnapshotRelease(numberOfKeyGroups);\n\n    ByteArrayOutputStreamWithPos byteArrayOutputStreamWithPos =\n            new ByteArrayOutputStreamWithPos();\n    DataOutputView dataOutputView =\n            new DataOutputViewStreamWrapper(byteArrayOutputStreamWithPos);\n\n    CopyOnWriteStateTableSnapshot<Integer, Integer, Float> snapshot = table.stateSnapshot();\n    for (int group = 0; group < numberOfKeyGroups; group++) {\n        snapshot.writeStateInKeyGroup(dataOutputView, group);\n            \n        Assert.assertTrue(isResourceReleasedForKeyGroup(table, group));\n    }\n    snapshot.release();\n    verifyResourceIsReleasedForAllKeyGroup(table, 1);\n}", "summary_tokens": ["this", "tests", "that", "resource", "can", "be", "released", "for", "a", "successful", "snapshot"], "project": "flink"}
{"id": 6023, "code": "protected void checkJobOffloaded(DefaultExecutionGraph eg) throws Exception {\n    assertTrue(eg.getJobInformationOrBlobKey().isLeft());\n}", "summary_tokens": ["checks", "that", "the", "job", "information", "for", "the", "given", "id", "has", "been", "offloaded", "successfully", "if", "offloading", "is", "used"], "project": "flink"}
{"id": 6598, "code": "public void testKeyGroupsSnapshotRestoreScaleUpUnEvenDistribute() throws Exception {\n    testKeyGroupSnapshotRestore(15, 77, 128);\n}", "summary_tokens": ["similar", "with", "test", "key", "group", "snapshot", "restore", "scale", "up", "but", "the", "key", "groups", "were", "distributed", "unevenly"], "project": "flink"}
{"id": 6982, "code": "private void downloadDataForStateHandle(\n        Path restoreFilePath,\n        StreamStateHandle remoteFileHandle,\n        CloseableRegistry closeableRegistry)\n        throws IOException {\n\n    FSDataInputStream inputStream = null;\n    OutputStream outputStream = null;\n\n    try {\n        inputStream = remoteFileHandle.openInputStream();\n        closeableRegistry.registerCloseable(inputStream);\n\n        Files.createDirectories(restoreFilePath.getParent());\n        outputStream = Files.newOutputStream(restoreFilePath);\n        closeableRegistry.registerCloseable(outputStream);\n\n        byte[] buffer = new byte[8 * 1024];\n        while (true) {\n            int numBytes = inputStream.read(buffer);\n            if (numBytes == -1) {\n                break;\n            }\n\n            outputStream.write(buffer, 0, numBytes);\n        }\n    } finally {\n        if (closeableRegistry.unregisterCloseable(inputStream)) {\n            inputStream.close();\n        }\n\n        if (closeableRegistry.unregisterCloseable(outputStream)) {\n            outputStream.close();\n        }\n    }\n}", "summary_tokens": ["copies", "the", "file", "from", "a", "single", "state", "handle", "to", "the", "given", "path"], "project": "flink"}
{"id": 3135, "code": "public DoubleParameter setMaximumValue(double maximumValue, boolean inclusive) {\n    if (hasDefaultValue) {\n        if (inclusive) {\n            Util.checkParameter(\n                    maximumValue >= defaultValue,\n                    \"Maximum value (\"\n                            + maximumValue\n                            + \") must be greater than or equal to default (\"\n                            + defaultValue\n                            + \")\");\n        } else {\n            Util.checkParameter(\n                    maximumValue > defaultValue,\n                    \"Maximum value (\"\n                            + maximumValue\n                            + \") must be greater than default (\"\n                            + defaultValue\n                            + \")\");\n        }\n    } else if (hasMinimumValue) {\n        if (inclusive && minimumValueInclusive) {\n            Util.checkParameter(\n                    maximumValue >= minimumValue,\n                    \"Maximum value (\"\n                            + maximumValue\n                            + \") must be greater than or equal to minimum (\"\n                            + minimumValue\n                            + \")\");\n        } else {\n            Util.checkParameter(\n                    maximumValue > minimumValue,\n                    \"Maximum value (\"\n                            + maximumValue\n                            + \") must be greater than minimum (\"\n                            + minimumValue\n                            + \")\");\n        }\n    }\n\n    this.hasMaximumValue = true;\n    this.maximumValue = maximumValue;\n    this.maximumValueInclusive = inclusive;\n\n    return this;\n}", "summary_tokens": ["set", "the", "maximum", "value"], "project": "flink"}
{"id": 634, "code": "private static <T> FlinkKafkaPartitioner<T> initializePartitioner(\n        String name, ClassLoader classLoader) {\n    try {\n        Class<?> clazz = Class.forName(name, true, classLoader);\n        if (!FlinkKafkaPartitioner.class.isAssignableFrom(clazz)) {\n            throw new ValidationException(\n                    String.format(\n                            \"Sink partitioner class '%s' should extend from the required class %s\",\n                            name, FlinkKafkaPartitioner.class.getName()));\n        }\n        @SuppressWarnings(\"unchecked\")\n        final FlinkKafkaPartitioner<T> kafkaPartitioner =\n                InstantiationUtil.instantiate(name, FlinkKafkaPartitioner.class, classLoader);\n\n        return kafkaPartitioner;\n    } catch (ClassNotFoundException | FlinkException e) {\n        throw new ValidationException(\n                String.format(\"Could not find and instantiate partitioner class '%s'\", name),\n                e);\n    }\n}", "summary_tokens": ["returns", "a", "class", "value", "with", "the", "given", "class", "name"], "project": "flink"}
{"id": 2242, "code": "public void triggerAll() {\n    execService.triggerAll();\n}", "summary_tokens": ["triggers", "all", "queued", "runnables"], "project": "flink"}
{"id": 6869, "code": "private String getInternal(String key) {\n    Preconditions.checkArgument(\n            configuredOptions.containsKey(key),\n            \"The configuration \" + key + \" has not been configured.\");\n\n    return configuredOptions.get(key);\n}", "summary_tokens": ["returns", "the", "value", "in", "string", "format", "with", "the", "given", "key"], "project": "flink"}
{"id": 2119, "code": "public static <T> void forwardAsync(\n        CompletableFuture<T> source, CompletableFuture<T> target, Executor executor) {\n    source.whenCompleteAsync(forwardTo(target), executor);\n}", "summary_tokens": ["forwards", "the", "value", "from", "the", "source", "future", "to", "the", "target", "future", "using", "the", "provided", "executor"], "project": "flink"}
{"id": 9680, "code": "private void initParallelSessionGenerators(int parallelSessions) {\n    for (int i = 0;\n            i < parallelSessions\n                    && generatorFactory.getProducedGeneratorsCount() < sessionCountLimit;\n            ++i) {\n        subGeneratorLists.add(\n                generatorFactory.newSessionGeneratorForKey(\n                        randomGenerator.chooseRandomElement(sessionKeys), 0L));\n    }\n}", "summary_tokens": ["parallel", "sessions", "the", "number", "of", "parallel", "sessions", "to", "initialize"], "project": "flink"}
{"id": 7333, "code": "private String determineSlotSharingGroup(String specifiedGroup, Collection<Integer> inputIds) {\n    if (specifiedGroup != null) {\n        return specifiedGroup;\n    } else {\n        String inputGroup = null;\n        for (int id : inputIds) {\n            String inputGroupCandidate = streamGraph.getSlotSharingGroup(id);\n            if (inputGroup == null) {\n                inputGroup = inputGroupCandidate;\n            } else if (!inputGroup.equals(inputGroupCandidate)) {\n                return DEFAULT_SLOT_SHARING_GROUP;\n            }\n        }\n        return inputGroup == null ? DEFAULT_SLOT_SHARING_GROUP : inputGroup;\n    }\n}", "summary_tokens": ["determines", "the", "slot", "sharing", "group", "for", "an", "operation", "based", "on", "the", "slot", "sharing", "group", "set", "by", "the", "user", "and", "the", "slot", "sharing", "groups", "of", "the", "inputs"], "project": "flink"}
{"id": 8500, "code": "public WatermarkStrategy getWatermarkStrategy() {\n    return watermarkStrategy;\n}", "summary_tokens": ["returns", "the", "watermark", "strategy", "for", "the", "attribute"], "project": "flink"}
{"id": 8119, "code": "public static boolean similar(String s, String pattern, String escape) {\n    final String regex = sqlToRegexSimilar(pattern, escape);\n    return Pattern.matches(regex, s);\n}", "summary_tokens": ["sql", "similar", "function", "with", "escape"], "project": "flink"}
{"id": 9121, "code": "public Object getInput() {\n    return input;\n}", "summary_tokens": ["gets", "the", "input", "value", "from", "left", "table", "which", "will", "be", "used", "to", "cross", "join", "with", "the", "result", "of", "right", "table"], "project": "flink"}
{"id": 1160, "code": "public void setAccumulatedRecordCount(long accumulatedRecordCount) {\n    this.accumulatedRecordCount = accumulatedRecordCount;\n}", "summary_tokens": ["sets", "the", "accumulated", "record", "count", "to", "the", "specified", "value"], "project": "flink"}
{"id": 6136, "code": "public void testUniformDistributionAllBuffers() throws IOException {\n    BufferPool first =\n            networkBufferPool.createBufferPool(\n                    networkBufferPool.getTotalNumberOfMemorySegments() / 2, Integer.MAX_VALUE);\n    assertEquals(networkBufferPool.getTotalNumberOfMemorySegments(), first.getNumBuffers());\n\n    BufferPool second =\n            networkBufferPool.createBufferPool(\n                    networkBufferPool.getTotalNumberOfMemorySegments() / 2, Integer.MAX_VALUE);\n    assertEquals(networkBufferPool.getTotalNumberOfMemorySegments() / 2, first.getNumBuffers());\n    assertEquals(\n            networkBufferPool.getTotalNumberOfMemorySegments() / 2, second.getNumBuffers());\n\n    first.lazyDestroy();\n    second.lazyDestroy();\n}", "summary_tokens": ["tests", "that", "buffers", "once", "given", "to", "an", "initial", "buffer", "pool", "get", "re", "distributed", "to", "a", "second", "one", "in", "case", "both", "buffer", "pools", "request", "half", "of", "the", "available", "buffer", "count"], "project": "flink"}
{"id": 5863, "code": "public void testPortUnavailable() throws IOException {\n        \n    ServerSocket socket = null;\n    try {\n        socket = new ServerSocket(0);\n    } catch (IOException e) {\n        e.printStackTrace();\n        Assert.fail(\"An exception was thrown while preparing the test \" + e.getMessage());\n    }\n\n    Configuration conf = new Configuration();\n    conf.setString(BlobServerOptions.PORT, String.valueOf(socket.getLocalPort()));\n    conf.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n        \n    try {\n        BlobServer server = new BlobServer(conf, new VoidBlobStore());\n        server.start();\n    } finally {\n        socket.close();\n    }\n}", "summary_tokens": ["try", "allocating", "on", "an", "unavailable", "port"], "project": "flink"}
{"id": 6374, "code": "public void testDoubleProbeInMemory() {\n\n    int buildSize = 1000;\n    int probeSize = 1000;\n    try {\n        TupleGenerator bgen =\n                new TupleGenerator(SEED1, 0, 28, KeyMode.SORTED, ValueMode.FIX_LENGTH);\n        TupleGenerator pgen =\n                new TupleGenerator(SEED2, 0, 28, KeyMode.SORTED, ValueMode.FIX_LENGTH);\n\n        final TupleGeneratorIterator buildInput = new TupleGeneratorIterator(bgen, buildSize);\n        final TupleGeneratorIterator probeInput = new TupleGeneratorIterator(pgen, probeSize);\n\n        doTest(buildInput, probeInput, bgen, pgen);\n    } catch (Exception e) {\n        e.printStackTrace();\n        Assert.fail(\"An exception occurred during the test: \" + e.getMessage());\n    }\n}", "summary_tokens": ["this", "test", "case", "verifies", "that", "hybrid", "hash", "join", "is", "able", "to", "handle", "multiple", "probe", "phases", "when", "the", "build", "side", "fits", "completely", "into", "memory"], "project": "flink"}
{"id": 1349, "code": "public long toMilliseconds() {\n    return unit.toMillis(size);\n}", "summary_tokens": ["converts", "the", "time", "interval", "to", "milliseconds"], "project": "flink"}
{"id": 8378, "code": "public JoinedRowData replace(RowData row1, RowData row2) {\n    this.row1 = row1;\n    this.row2 = row2;\n    return this;\n}", "summary_tokens": ["replaces", "the", "row", "data", "backing", "this", "joined", "row", "data"], "project": "flink"}
{"id": 4442, "code": "public static RestartBackoffTimeStrategy.Factory createRestartBackoffTimeStrategyFactory(\n        final RestartStrategies.RestartStrategyConfiguration jobRestartStrategyConfiguration,\n        final Configuration clusterConfiguration,\n        final boolean isCheckpointingEnabled) {\n\n    checkNotNull(jobRestartStrategyConfiguration);\n    checkNotNull(clusterConfiguration);\n\n    return getJobRestartStrategyFactory(jobRestartStrategyConfiguration)\n            .orElse(\n                    getClusterRestartStrategyFactory(clusterConfiguration)\n                            .orElse(getDefaultRestartStrategyFactory(isCheckpointingEnabled)));\n}", "summary_tokens": ["creates", "restart", "backoff", "time", "strategy"], "project": "flink"}
{"id": 6088, "code": "public void testHeartbeatTimeout() throws Exception {\n    int numHeartbeats = 6;\n    final int payload = 42;\n\n    ResourceID ownResourceID = new ResourceID(\"foobar\");\n    ResourceID targetResourceID = new ResourceID(\"barfoo\");\n\n    final CompletableFuture<ResourceID> timeoutFuture = new CompletableFuture<>();\n    final TestingHeartbeatListener<Integer, Integer> heartbeatListener =\n            new TestingHeartbeatListenerBuilder<Integer, Integer>()\n                    .setRetrievePayloadFunction(ignored -> payload)\n                    .setNotifyHeartbeatTimeoutConsumer(timeoutFuture::complete)\n                    .createNewTestingHeartbeatListener();\n\n    HeartbeatManagerImpl<Integer, Integer> heartbeatManager =\n            new HeartbeatManagerImpl<>(\n                    HEARTBEAT_TIMEOUT,\n                    FAILED_RPC_THRESHOLD,\n                    ownResourceID,\n                    heartbeatListener,\n                    TestingUtils.defaultScheduledExecutor(),\n                    LOG);\n\n    final HeartbeatTarget<Integer> heartbeatTarget =\n            new TestingHeartbeatTargetBuilder<Integer>().createTestingHeartbeatTarget();\n\n    heartbeatManager.monitorTarget(targetResourceID, heartbeatTarget);\n\n    for (int i = 0; i < numHeartbeats; i++) {\n        heartbeatManager.receiveHeartbeat(targetResourceID, payload);\n        Thread.sleep(HEARTBEAT_INTERVAL);\n    }\n\n    assertFalse(timeoutFuture.isDone());\n\n    ResourceID timeoutResourceID =\n            timeoutFuture.get(2 * HEARTBEAT_TIMEOUT, TimeUnit.MILLISECONDS);\n\n    assertEquals(targetResourceID, timeoutResourceID);\n}", "summary_tokens": ["tests", "that", "a", "heartbeat", "timeout", "is", "signaled", "if", "the", "heartbeat", "is", "not", "reported", "in", "time"], "project": "flink"}
{"id": 5799, "code": "public void testBlobForJobCacheHa() throws IOException {\n    Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n    config.setString(HighAvailabilityOptions.HA_MODE, \"ZOOKEEPER\");\n    config.setString(\n            HighAvailabilityOptions.HA_STORAGE_PATH, temporaryFolder.newFolder().getPath());\n\n    uploadFileGetTest(config, new JobID(), true, true, PERMANENT_BLOB);\n}", "summary_tokens": ["blob", "cache", "is", "configured", "in", "ha", "mode", "and", "the", "cache", "can", "download", "files", "from", "the", "file", "system", "directly", "and", "does", "not", "need", "to", "download", "blobs", "from", "the", "blob", "server", "which", "remains", "active", "after", "the", "blob", "upload"], "project": "flink"}
{"id": 4007, "code": "public void testOnStopExceptionPropagation() throws Exception {\n    FailingOnStopEndpoint rpcEndpoint =\n            new FailingOnStopEndpoint(akkaRpcService, \"FailingOnStopEndpoint\");\n    rpcEndpoint.start();\n\n    CompletableFuture<Void> terminationFuture = rpcEndpoint.closeAsync();\n\n    try {\n        terminationFuture.get();\n    } catch (ExecutionException e) {\n        assertTrue(e.getCause() instanceof FailingOnStopEndpoint.OnStopException);\n    }\n}", "summary_tokens": ["tests", "that", "exception", "thrown", "in", "the", "on", "stop", "method", "are", "returned", "by", "the", "termination", "future"], "project": "flink"}
{"id": 4135, "code": "private static void writeErrorToStream(OutputStream out, Throwable t) throws IOException {\n    byte[] bytes = InstantiationUtil.serializeObject(t);\n    out.write(RETURN_ERROR);\n    writeLength(bytes.length, out);\n    out.write(bytes);\n}", "summary_tokens": ["writes", "to", "the", "output", "stream", "the", "error", "return", "code", "and", "the", "given", "exception", "in", "serialized", "form"], "project": "flink"}
{"id": 9187, "code": "static int getNumWriteBehindBuffers(int numBuffers) {\n    int numIOBufs = (int) (Math.log(numBuffers) / Math.log(4) - 1.5);\n    return numIOBufs > 6 ? 6 : numIOBufs;\n}", "summary_tokens": ["determines", "the", "number", "of", "buffers", "to", "be", "used", "for", "asynchronous", "write", "behind"], "project": "flink"}
{"id": 3198, "code": "public Graph<K, VV, EV> removeEdges(List<Edge<K, EV>> edgesToBeRemoved) {\n\n    DataSet<Edge<K, EV>> newEdges =\n            getEdges()\n                    .coGroup(this.context.fromCollection(edgesToBeRemoved))\n                    .where(0, 1)\n                    .equalTo(0, 1)\n                    .with(new EdgeRemovalCoGroup<>())\n                    .name(\"Remove edges\");\n\n    return new Graph<>(this.vertices, newEdges, context);\n}", "summary_tokens": ["removes", "all", "the", "edges", "that", "match", "the", "edges", "in", "the", "given", "data", "set", "from", "the", "graph"], "project": "flink"}
{"id": 3173, "code": "public <NEW> Graph<K, VV, NEW> translateEdgeValues(TranslateFunction<EV, NEW> translator)\n        throws Exception {\n    return run(new TranslateEdgeValues<>(translator));\n}", "summary_tokens": ["translate", "edge", "values", "using", "the", "given", "map", "function"], "project": "flink"}
{"id": 4539, "code": "public void randomEmit(T record) throws IOException {\n    checkErroneous();\n\n    int targetSubpartition = rng.nextInt(numberOfChannels);\n    emit(record, targetSubpartition);\n}", "summary_tokens": ["this", "is", "used", "to", "send", "latency", "marks", "to", "a", "random", "target", "channel"], "project": "flink"}
{"id": 3802, "code": "static List<String> parseYarn(String[] args) {\n    String[] params = new String[args.length - 1];\n    System.arraycopy(args, 1, params, 0, params.length);\n    CommandLine commandLine = parse(YARN_OPTIONS, params);\n    if (commandLine.hasOption(OPTION_HELP.getOpt())) {\n        printYarnHelp();\n        System.exit(0);\n    }\n    List<String> options = new ArrayList<>();\n    options.add(args[0]);\n    options.add(\"-m\");\n    options.add(\"yarn-cluster\");\n    constructYarnOption(options, OPTION_JM_MEMORY, commandLine);\n    constructYarnOption(options, OPTION_NAME, commandLine);\n    constructYarnOption(options, OPTION_QUEUE, commandLine);\n    constructYarnOption(options, OPTION_SLOTS, commandLine);\n    constructYarnOption(options, OPTION_TM_MEMORY, commandLine);\n    return options;\n}", "summary_tokens": ["parses", "python", "shell", "yarn", "options", "and", "transfer", "to", "yarn", "options", "which", "will", "be", "used", "in", "flink", "run", "to", "submit", "flink", "job"], "project": "flink"}
{"id": 4975, "code": "private static int getInitialTableSize(\n        int numBuffers, int bufferSize, int numPartitions, int recordLenBytes) {\n    final long totalSize = ((long) bufferSize) * numBuffers;\n    final long numRecordsStorable = totalSize / (recordLenBytes + RECORD_OVERHEAD_BYTES);\n    final long bucketBytes = numRecordsStorable * RECORD_OVERHEAD_BYTES;\n    long numBuckets = bucketBytes / (2 * HASH_BUCKET_SIZE) + 1;\n    numBuckets += numPartitions - numBuckets % numPartitions;\n    return numBuckets > Integer.MAX_VALUE ? Integer.MAX_VALUE : (int) numBuckets;\n}", "summary_tokens": ["tries", "to", "find", "a", "good", "value", "for", "the", "number", "of", "buckets", "will", "ensure", "that", "the", "number", "of", "buckets", "is", "a", "multiple", "of", "num", "partitions"], "project": "flink"}
{"id": 7280, "code": "public static void setDefaultLocalParallelism(int parallelism) {\n    defaultLocalParallelism = parallelism;\n}", "summary_tokens": ["sets", "the", "default", "parallelism", "that", "will", "be", "used", "for", "the", "local", "execution", "environment", "created", "by", "create", "local", "environment"], "project": "flink"}
{"id": 8301, "code": "public LocalDateTime toLocalDateTime() {\n    int date = (int) (millisecond / MILLIS_PER_DAY);\n    int time = (int) (millisecond % MILLIS_PER_DAY);\n    if (time < 0) {\n        --date;\n        time += MILLIS_PER_DAY;\n    }\n    long nanoOfDay = time * 1_000_000L + nanoOfMillisecond;\n    LocalDate localDate = LocalDate.ofEpochDay(date);\n    LocalTime localTime = LocalTime.ofNanoOfDay(nanoOfDay);\n    return LocalDateTime.of(localDate, localTime);\n}", "summary_tokens": ["converts", "this", "timestamp", "data", "object", "to", "a", "local", "date", "time"], "project": "flink"}
{"id": 4258, "code": "public StateObjectCollection<KeyedStateHandle> getJobManagerRawKeyedState() {\n    return lastElement(prioritizedRawKeyedState);\n}", "summary_tokens": ["returns", "the", "raw", "keyed", "state", "from", "the", "job", "manager", "which", "represents", "the", "ground", "truth", "about", "what", "this", "state", "should", "represent"], "project": "flink"}
{"id": 7877, "code": "public void testConcurrentPutTakeBlocking() throws Exception {\n    testPutTake(mailbox -> mailbox.take(DEFAULT_PRIORITY));\n}", "summary_tokens": ["test", "the", "producer", "consumer", "pattern", "using", "the", "blocking", "methods", "on", "the", "mailbox"], "project": "flink"}
{"id": 987, "code": "public long getMaxPartSize() {\n    return partSize;\n}", "summary_tokens": ["returns", "the", "maximum", "part", "file", "size", "before", "rolling"], "project": "flink"}
{"id": 719, "code": "public void testAssignedToPartitionFailureRecoveryIngestionTime() throws Exception {\n    testAssignedToPartitionFailureRecovery(500, IngestionTime);\n}", "summary_tokens": ["failure", "recovery", "after", "data", "is", "repartitioned", "with", "time", "characteristic", "ingestion", "time"], "project": "flink"}
{"id": 1964, "code": "public static Throwable stripException(\n        Throwable throwableToStrip, Class<? extends Throwable> typeToStrip) {\n    while (typeToStrip.isAssignableFrom(throwableToStrip.getClass())\n            && throwableToStrip.getCause() != null) {\n        throwableToStrip = throwableToStrip.getCause();\n    }\n\n    return throwableToStrip;\n}", "summary_tokens": ["unpacks", "an", "specified", "exception", "and", "returns", "its", "cause"], "project": "flink"}
{"id": 2856, "code": "public static <T, R> Aggregator<T, R> create(Class<T> type) {\n    if (type == Long.class) {\n        return (Aggregator<T, R>) new LongSummaryAggregator();\n    } else if (type == LongValue.class) {\n        return (Aggregator<T, R>) new ValueSummaryAggregator.LongValueSummaryAggregator();\n    } else if (type == Integer.class) {\n        return (Aggregator<T, R>) new IntegerSummaryAggregator();\n    } else if (type == IntValue.class) {\n        return (Aggregator<T, R>) new ValueSummaryAggregator.IntegerValueSummaryAggregator();\n    } else if (type == Double.class) {\n        return (Aggregator<T, R>) new DoubleSummaryAggregator();\n    } else if (type == DoubleValue.class) {\n        return (Aggregator<T, R>) new ValueSummaryAggregator.DoubleValueSummaryAggregator();\n    } else if (type == Float.class) {\n        return (Aggregator<T, R>) new FloatSummaryAggregator();\n    } else if (type == FloatValue.class) {\n        return (Aggregator<T, R>) new ValueSummaryAggregator.FloatValueSummaryAggregator();\n    } else if (type == Short.class) {\n        return (Aggregator<T, R>) new ShortSummaryAggregator();\n    } else if (type == ShortValue.class) {\n        return (Aggregator<T, R>) new ValueSummaryAggregator.ShortValueSummaryAggregator();\n    } else if (type == Boolean.class) {\n        return (Aggregator<T, R>) new BooleanSummaryAggregator();\n    } else if (type == BooleanValue.class) {\n        return (Aggregator<T, R>) new ValueSummaryAggregator.BooleanValueSummaryAggregator();\n    } else if (type == String.class) {\n        return (Aggregator<T, R>) new StringSummaryAggregator();\n    } else if (type == StringValue.class) {\n        return (Aggregator<T, R>) new ValueSummaryAggregator.StringValueSummaryAggregator();\n    } else {\n            \n        return (Aggregator<T, R>) new ObjectSummaryAggregator();\n    }\n}", "summary_tokens": ["create", "a", "summary", "aggregator", "for", "the", "supplied", "type"], "project": "flink"}
{"id": 475, "code": "Collection<Xid> getHanging() {\n    return hanging;\n}", "summary_tokens": ["immutable", "collection", "of", "xa", "transactions", "to", "javax"], "project": "flink"}
{"id": 3834, "code": "public ColumnVector[] getColumnVectors() {\n    return columnVectors;\n}", "summary_tokens": ["gets", "the", "column", "vectors"], "project": "flink"}
{"id": 7517, "code": "public int getLog2TableCapacity() {\n    return log2size;\n}", "summary_tokens": ["gets", "the", "base", "0", "logarithm", "of", "the", "hash", "table", "capacity", "as", "returned", "by", "get", "current", "table", "capacity"], "project": "flink"}
{"id": 1697, "code": "protected void doClose(List<AutoCloseable> toClose) throws Exception {\n    IOUtils.closeAll(reverse(toClose), Throwable.class);\n}", "summary_tokens": ["this", "implementation", "implies", "that", "any", "exception", "is", "possible", "during", "closing"], "project": "flink"}
{"id": 9074, "code": "public static Matcher<CreateTableOperation> withSchema(Schema schema) {\n    return new FeatureMatcher<CreateTableOperation, Schema>(\n            equalTo(schema), \"schema of the derived table\", \"schema\") {\n        @Override\n        protected Schema featureValueOf(CreateTableOperation actual) {\n            return actual.getCatalogTable().getUnresolvedSchema();\n        }\n    };\n}", "summary_tokens": ["checks", "that", "the", "schema", "of", "create", "table", "operation", "is", "equal", "to", "the", "given", "schema"], "project": "flink"}
{"id": 3668, "code": "public Ordering getOrdering() {\n    return this.ordering;\n}", "summary_tokens": ["gets", "the", "key", "order"], "project": "flink"}
{"id": 239, "code": "public static Collection<String> getCommonSuffixes() {\n    return COMMON_SUFFIXES;\n}", "summary_tokens": ["gets", "all", "common", "file", "extensions", "of", "supported", "file", "compression", "formats"], "project": "flink"}
{"id": 6612, "code": "public void testCreationFromConfigDefault() throws Exception {\n\n    final Configuration config = new Configuration();\n\n    TaskManagerServicesConfiguration taskManagerServicesConfiguration =\n            createTaskManagerServiceConfiguration(config);\n\n    TaskManagerServices taskManagerServices =\n            createTaskManagerServices(taskManagerServicesConfiguration);\n\n    try {\n        TaskExecutorLocalStateStoresManager taskStateManager =\n                taskManagerServices.getTaskManagerStateStore();\n\n        String[] tmpDirPaths = taskManagerServicesConfiguration.getTmpDirPaths();\n        File[] localStateRootDirectories = taskStateManager.getLocalStateRootDirectories();\n\n        for (int i = 0; i < tmpDirPaths.length; ++i) {\n            Assert.assertEquals(\n                    new File(\n                            tmpDirPaths[i], TaskManagerServices.LOCAL_STATE_SUB_DIRECTORY_ROOT),\n                    localStateRootDirectories[i]);\n        }\n\n        Assert.assertFalse(taskStateManager.isLocalRecoveryEnabled());\n    } finally {\n        taskManagerServices.shutDown();\n    }\n}", "summary_tokens": ["this", "tests", "that", "the", "creation", "of", "task", "manager", "services", "correctly", "falls", "back", "to", "the", "first", "tmp", "directory", "of", "the", "iomanager", "as", "default", "for", "the", "local", "state", "root", "directory"], "project": "flink"}
{"id": 5459, "code": "public Path getBasePath() {\n    return getCheckpointPath();\n}", "summary_tokens": ["gets", "the", "base", "directory", "where", "all", "the", "checkpoints", "are", "stored"], "project": "flink"}
{"id": 505, "code": "public KafkaSinkBuilder<IN> setBootstrapServers(String bootstrapServers) {\n    this.bootstrapServers = checkNotNull(bootstrapServers);\n    return this;\n}", "summary_tokens": ["sets", "the", "kafka", "bootstrap", "servers"], "project": "flink"}
{"id": 1579, "code": "public static Class<?> getRawClass(Type t) {\n    if (isClassType(t)) {\n        return typeToClass(t);\n    } else if (t instanceof GenericArrayType) {\n        Type component = ((GenericArrayType) t).getGenericComponentType();\n        return Array.newInstance(getRawClass(component), 0).getClass();\n    }\n    return Object.class;\n}", "summary_tokens": ["returns", "the", "raw", "class", "of", "both", "parameterized", "types", "and", "generic", "arrays"], "project": "flink"}
{"id": 7080, "code": "public DataStreamSink<T> writeUsingOutputFormat(OutputFormat<T> format) {\n    return addSink(new OutputFormatSinkFunction<>(format));\n}", "summary_tokens": ["writes", "the", "data", "stream", "into", "an", "output", "described", "by", "an", "output", "format"], "project": "flink"}
{"id": 7542, "code": "public long getMarkedTime() {\n    return markedTime;\n}", "summary_tokens": ["returns", "the", "timestamp", "marked", "by", "the", "latency", "marker"], "project": "flink"}
{"id": 9590, "code": "public void testPartitionWithDistribution1() throws Exception {\n    final TestDataDist1 dist = new TestDataDist1();\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(dist.getParallelism());\n\n    DataSet<Tuple3<Integer, Long, String>> input = CollectionDataSets.get3TupleDataSet(env);\n\n    DataSet<Boolean> result =\n            DataSetUtils.partitionByRange(input, dist, 0)\n                    .mapPartition(\n                            new RichMapPartitionFunction<\n                                    Tuple3<Integer, Long, String>, Boolean>() {\n\n                                @Override\n                                public void mapPartition(\n                                        Iterable<Tuple3<Integer, Long, String>> values,\n                                        Collector<Boolean> out)\n                                        throws Exception {\n                                    int pIdx = getRuntimeContext().getIndexOfThisSubtask();\n\n                                    for (Tuple3<Integer, Long, String> s : values) {\n                                        boolean correctlyPartitioned = true;\n                                        if (pIdx == 0) {\n                                            Integer[] upper = dist.boundaries[0];\n                                            if (s.f0.compareTo(upper[0]) > 0) {\n                                                correctlyPartitioned = false;\n                                            }\n                                        } else if (pIdx > 0\n                                                && pIdx < dist.getParallelism() - 1) {\n                                            Integer[] lower = dist.boundaries[pIdx - 1];\n                                            Integer[] upper = dist.boundaries[pIdx];\n                                            if (s.f0.compareTo(upper[0]) > 0\n                                                    || (s.f0.compareTo(lower[0]) <= 0)) {\n                                                correctlyPartitioned = false;\n                                            }\n                                        } else {\n                                            Integer[] lower = dist.boundaries[pIdx - 1];\n                                            if ((s.f0.compareTo(lower[0]) <= 0)) {\n                                                correctlyPartitioned = false;\n                                            }\n                                        }\n\n                                        if (!correctlyPartitioned) {\n                                            fail(\n                                                    \"Record was not correctly partitioned: \"\n                                                            + s.toString());\n                                        }\n                                    }\n                                }\n                            });\n\n    result.output(new DiscardingOutputFormat<Boolean>());\n    env.execute();\n}", "summary_tokens": ["test", "the", "record", "partitioned", "rightly", "with", "one", "field", "according", "to", "the", "customized", "data", "distribution"], "project": "flink"}
{"id": 3525, "code": "public List<StateBootstrapTransformationWithID<?>> getNewOperators() {\n    return operatorStateIndex.values().stream()\n            .filter(OperatorStateSpecV2::isNewStateTransformation)\n            .map(OperatorStateSpecV2::asNewStateTransformation)\n            .collect(Collectors.toList());\n}", "summary_tokens": ["list", "of", "new", "operator", "states", "for", "the", "savepoint", "represented", "by", "their", "target", "operator", "id", "and", "state", "bootstrap", "transformation"], "project": "flink"}
{"id": 7192, "code": "public void setForceUnalignedCheckpoints(boolean forceUnalignedCheckpoints) {\n    this.forceUnalignedCheckpoints = forceUnalignedCheckpoints;\n}", "summary_tokens": ["checks", "whether", "unaligned", "checkpoints", "are", "forced", "despite", "currently", "non", "checkpointable", "iteration", "feedback", "or", "custom", "partitioners"], "project": "flink"}
{"id": 6186, "code": "public void testMatchingNumberOfArenasAndThreadsAsDefault() throws Exception {\n        \n    int numberOfSlots = 2;\n\n    NettyConfig config =\n            new NettyConfig(\n                    InetAddress.getLocalHost(),\n                    NetUtils.getAvailablePort(),\n                    1024,\n                    numberOfSlots,\n                    new Configuration());\n\n    NettyConnectionManager connectionManager = createNettyConnectionManager(config);\n    connectionManager.start();\n\n    assertEquals(numberOfSlots, connectionManager.getBufferPool().getNumberOfArenas());\n\n    {\n            \n        Bootstrap boostrap = connectionManager.getClient().getBootstrap();\n        EventLoopGroup group = boostrap.group();\n\n        Field f = group.getClass().getSuperclass().getSuperclass().getDeclaredField(\"children\");\n        f.setAccessible(true);\n        Object[] eventExecutors = (Object[]) f.get(group);\n\n        assertEquals(numberOfSlots, eventExecutors.length);\n    }\n\n    {\n            \n        ServerBootstrap bootstrap = connectionManager.getServer().getBootstrap();\n        EventLoopGroup group = bootstrap.group();\n\n        Field f = group.getClass().getSuperclass().getSuperclass().getDeclaredField(\"children\");\n        f.setAccessible(true);\n        Object[] eventExecutors = (Object[]) f.get(group);\n\n        assertEquals(numberOfSlots, eventExecutors.length);\n    }\n\n    {\n            \n        ServerBootstrap bootstrap = connectionManager.getServer().getBootstrap();\n        EventLoopGroup group = bootstrap.childGroup();\n\n        Field f = group.getClass().getSuperclass().getSuperclass().getDeclaredField(\"children\");\n        f.setAccessible(true);\n        Object[] eventExecutors = (Object[]) f.get(group);\n\n        assertEquals(numberOfSlots, eventExecutors.length);\n    }\n}", "summary_tokens": ["tests", "that", "the", "number", "of", "arenas", "and", "number", "of", "threads", "of", "the", "client", "and", "server", "are", "set", "to", "the", "same", "number", "that", "is", "the", "number", "of", "configured", "task", "slots"], "project": "flink"}
{"id": 1256, "code": "public Ordering createNewOrderingUpToIndex(int exclusiveIndex) {\n    if (exclusiveIndex == 0) {\n        return null;\n    }\n    final Ordering newOrdering = new Ordering();\n    for (int i = 0; i < exclusiveIndex; i++) {\n        newOrdering.appendOrdering(this.indexes.get(i), this.types.get(i), this.orders.get(i));\n    }\n    return newOrdering;\n}", "summary_tokens": ["creates", "a", "new", "ordering", "the", "represents", "an", "ordering", "on", "a", "prefix", "of", "the", "fields"], "project": "flink"}
{"id": 7971, "code": "default StreamTableSource<T> createStreamTableSource(Map<String, String> properties) {\n    return null;\n}", "summary_tokens": ["creates", "and", "configures", "a", "stream", "table", "source", "using", "the", "given", "properties"], "project": "flink"}
{"id": 9114, "code": "public void setInput(Object input) {\n    this.input = input;\n}", "summary_tokens": ["sets", "the", "input", "row", "from", "left", "table", "which", "will", "be", "used", "to", "cross", "join", "with", "the", "result", "of", "table", "function"], "project": "flink"}
{"id": 8376, "code": "public HeapIntVector getDictionaryIds() {\n    return dictionaryIds;\n}", "summary_tokens": ["returns", "the", "underlying", "integer", "column", "for", "ids", "of", "dictionary"], "project": "flink"}
{"id": 6125, "code": "public void testBroadcastEventMixedRecords() throws Exception {\n    Random rand = new XORShiftRandom();\n    int numberOfChannels = 4;\n    int bufferSize = 32;\n    int lenBytes = 4; \n\n    ResultPartition partition = createResultPartition(bufferSize, numberOfChannels);\n    RecordWriter<ByteArrayIO> writer = createRecordWriter(partition);\n    CheckpointBarrier barrier =\n            new CheckpointBarrier(\n                    Integer.MAX_VALUE + 1292L,\n                    Integer.MAX_VALUE + 199L,\n                    CheckpointOptions.forCheckpointWithDefaultLocation());\n\n        \n        \n        \n\n        \n    byte[] bytes = new byte[bufferSize / 2];\n    rand.nextBytes(bytes);\n\n    writer.emit(new ByteArrayIO(bytes));\n\n        \n    bytes = new byte[bufferSize + 1];\n    rand.nextBytes(bytes);\n\n    writer.emit(new ByteArrayIO(bytes));\n\n        \n    bytes = new byte[bufferSize - lenBytes];\n    rand.nextBytes(bytes);\n\n    writer.emit(new ByteArrayIO(bytes));\n\n        \n    writer.broadcastEvent(barrier);\n\n    if (isBroadcastWriter) {\n        assertEquals(3, partition.getBufferPool().bestEffortGetNumOfUsedBuffers());\n\n        for (int i = 0; i < numberOfChannels; i++) {\n            assertEquals(4, partition.getNumberOfQueuedBuffers(i)); \n\n            ResultSubpartitionView view =\n                    partition.createSubpartitionView(i, new NoOpBufferAvailablityListener());\n            for (int j = 0; j < 3; j++) {\n                assertTrue(parseBuffer(view.getNextBuffer().buffer(), 0).isBuffer());\n            }\n\n            BufferOrEvent boe = parseBuffer(view.getNextBuffer().buffer(), i);\n            assertTrue(boe.isEvent());\n            assertEquals(barrier, boe.getEvent());\n        }\n    } else {\n        assertEquals(4, partition.getBufferPool().bestEffortGetNumOfUsedBuffers());\n        ResultSubpartitionView[] views = new ResultSubpartitionView[4];\n\n        assertEquals(2, partition.getNumberOfQueuedBuffers(0)); \n        views[0] = partition.createSubpartitionView(0, new NoOpBufferAvailablityListener());\n        assertTrue(parseBuffer(views[0].getNextBuffer().buffer(), 0).isBuffer());\n\n        assertEquals(3, partition.getNumberOfQueuedBuffers(1)); \n        views[1] = partition.createSubpartitionView(1, new NoOpBufferAvailablityListener());\n        assertTrue(parseBuffer(views[1].getNextBuffer().buffer(), 1).isBuffer());\n        assertTrue(parseBuffer(views[1].getNextBuffer().buffer(), 1).isBuffer());\n\n        assertEquals(2, partition.getNumberOfQueuedBuffers(2)); \n        views[2] = partition.createSubpartitionView(2, new NoOpBufferAvailablityListener());\n        assertTrue(parseBuffer(views[2].getNextBuffer().buffer(), 2).isBuffer());\n\n        views[3] = partition.createSubpartitionView(3, new NoOpBufferAvailablityListener());\n        assertEquals(1, partition.getNumberOfQueuedBuffers(3)); \n\n            \n        for (int i = 0; i < numberOfChannels; i++) {\n            BufferOrEvent boe = parseBuffer(views[i].getNextBuffer().buffer(), i);\n            assertTrue(boe.isEvent());\n            assertEquals(barrier, boe.getEvent());\n        }\n    }\n}", "summary_tokens": ["tests", "broadcasting", "events", "when", "records", "have", "been", "emitted"], "project": "flink"}
{"id": 2556, "code": "public void testTypeInfoDeserialization() throws Exception {\n    long id = 1238123899121L;\n    String name = \"asdlkjasjkdla998y1122\";\n    byte[] bytes = new byte[1024];\n    ThreadLocalRandom.current().nextBytes(bytes);\n    Timestamp timestamp = Timestamp.valueOf(\"1990-10-14 12:12:43\");\n    Date date = Date.valueOf(\"1990-10-14\");\n    Time time = Time.valueOf(\"12:12:43\");\n\n    Map<String, Long> map = new HashMap<>();\n    map.put(\"flink\", 123L);\n\n    Map<String, Map<String, Integer>> nestedMap = new HashMap<>();\n    Map<String, Integer> innerMap = new HashMap<>();\n    innerMap.put(\"key\", 234);\n    nestedMap.put(\"inner_map\", innerMap);\n\n    ObjectMapper objectMapper = new ObjectMapper();\n\n        \n    ObjectNode root = objectMapper.createObjectNode();\n    root.put(\"id\", id);\n    root.put(\"name\", name);\n    root.put(\"bytes\", bytes);\n    root.put(\"date1\", \"1990-10-14\");\n    root.put(\"date2\", \"1990-10-14\");\n    root.put(\"time1\", \"12:12:43Z\");\n    root.put(\"time2\", \"12:12:43Z\");\n    root.put(\"timestamp1\", \"1990-10-14T12:12:43Z\");\n    root.put(\"timestamp2\", \"1990-10-14T12:12:43Z\");\n    root.putObject(\"map\").put(\"flink\", 123);\n    root.putObject(\"map2map\").putObject(\"inner_map\").put(\"key\", 234);\n\n    byte[] serializedJson = objectMapper.writeValueAsBytes(root);\n\n    JsonRowDeserializationSchema deserializationSchema =\n            new JsonRowDeserializationSchema.Builder(\n                            Types.ROW_NAMED(\n                                    new String[] {\n                                        \"id\",\n                                        \"name\",\n                                        \"bytes\",\n                                        \"date1\",\n                                        \"date2\",\n                                        \"time1\",\n                                        \"time2\",\n                                        \"timestamp1\",\n                                        \"timestamp2\",\n                                        \"map\",\n                                        \"map2map\"\n                                    },\n                                    Types.LONG,\n                                    Types.STRING,\n                                    Types.PRIMITIVE_ARRAY(Types.BYTE),\n                                    Types.SQL_DATE,\n                                    Types.LOCAL_DATE,\n                                    Types.SQL_TIME,\n                                    Types.LOCAL_TIME,\n                                    Types.SQL_TIMESTAMP,\n                                    Types.LOCAL_DATE_TIME,\n                                    Types.MAP(Types.STRING, Types.LONG),\n                                    Types.MAP(\n                                            Types.STRING, Types.MAP(Types.STRING, Types.INT))))\n                    .build();\n\n    Row row = new Row(11);\n    row.setField(0, id);\n    row.setField(1, name);\n    row.setField(2, bytes);\n    row.setField(3, date);\n    row.setField(4, date.toLocalDate());\n    row.setField(5, time);\n    row.setField(6, time.toLocalTime());\n    row.setField(7, timestamp);\n    row.setField(8, timestamp.toLocalDateTime());\n    row.setField(9, map);\n    row.setField(10, nestedMap);\n\n    assertThat(serializedJson, whenDeserializedWith(deserializationSchema).equalsTo(row));\n}", "summary_tokens": ["tests", "simple", "deserialization", "using", "type", "information"], "project": "flink"}
{"id": 1167, "code": "public boolean reachedEnd() {\n    return this.end;\n}", "summary_tokens": ["checks", "whether", "the", "current", "split", "is", "at", "its", "end"], "project": "flink"}
{"id": 6592, "code": "public void testReducingStateDefaultValue() throws Exception {\n    ReducingStateDescriptor<String> kvId =\n            new ReducingStateDescriptor<>(\"id\", new AppendingReduce(), String.class);\n\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n    try {\n        ReducingState<String> state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n        backend.setCurrentKey(1);\n        assertNull(state.get());\n\n        state.add(\"Ciao\");\n        assertEquals(\"Ciao\", state.get());\n\n        state.clear();\n        assertNull(state.get());\n    } finally {\n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["verify", "that", "an", "empty", "reduce", "state", "yields", "null"], "project": "flink"}
{"id": 7649, "code": "public void testEventTimeTimersDontInterfere() throws Exception {\n    try (KeyedOneInputStreamOperatorTestHarness<Integer, Tuple2<Integer, String>, String>\n            testHarness = createTestHarness()) {\n        testHarness.open();\n\n        testHarness.processWatermark(0L);\n\n        testHarness.processElement(new Tuple2<>(1, \"SET_EVENT_TIME_TIMER:20\"), 0);\n\n        testHarness.processElement(new Tuple2<>(0, \"SET_STATE:HELLO\"), 0);\n        testHarness.processElement(new Tuple2<>(1, \"SET_STATE:CIAO\"), 0);\n\n        testHarness.processElement(new Tuple2<>(0, \"SET_EVENT_TIME_TIMER:10\"), 0);\n\n        testHarness.processWatermark(10L);\n\n        assertThat(extractResult(testHarness), contains(\"ON_EVENT_TIME:HELLO\"));\n\n        testHarness.processWatermark(20L);\n\n        assertThat(extractResult(testHarness), contains(\"ON_EVENT_TIME:CIAO\"));\n    }\n}", "summary_tokens": ["verify", "that", "firing", "event", "time", "timers", "see", "the", "state", "of", "the", "key", "that", "was", "active", "when", "the", "timer", "was", "set"], "project": "flink"}
{"id": 7836, "code": "public void testOvertakingCheckpointBarriers() throws Exception {\n    final OneInputStreamTaskTestHarness<String, String> testHarness =\n            new OneInputStreamTaskTestHarness<>(\n                    OneInputStreamTask::new,\n                    2,\n                    2,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setupOutputForSingletonOperatorChain();\n\n    StreamConfig streamConfig = testHarness.getStreamConfig();\n    StreamMap<String, String> mapOperator = new StreamMap<>(new IdentityMap());\n    streamConfig.setStreamOperator(mapOperator);\n    streamConfig.setOperatorID(new OperatorID());\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n    long initialTime = 0L;\n\n    testHarness.invoke();\n    testHarness.waitForTaskRunning();\n\n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            0,\n            0);\n\n        \n        \n        \n    testHarness.processElement(new StreamRecord<>(\"Hello-1-1\", initialTime), 1, 1);\n    testHarness.processElement(new StreamRecord<>(\"Ciao-1-1\", initialTime), 1, 1);\n    expectedOutput.add(new StreamRecord<>(\"Hello-1-1\", initialTime));\n    expectedOutput.add(new StreamRecord<>(\"Ciao-1-1\", initialTime));\n\n    testHarness.waitForInputProcessing();\n        \n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n        \n    testHarness.processEvent(\n            new CheckpointBarrier(1, 1, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            0,\n            1);\n    testHarness.processEvent(\n            new CheckpointBarrier(1, 1, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            0,\n            0);\n    testHarness.processEvent(\n            new CheckpointBarrier(1, 1, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            1,\n            0);\n    testHarness.processEvent(\n            new CheckpointBarrier(1, 1, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            1,\n            1);\n\n    expectedOutput.add(new CancelCheckpointMarker(0));\n    expectedOutput.add(\n            new CheckpointBarrier(1, 1, CheckpointOptions.forCheckpointWithDefaultLocation()));\n\n    testHarness.waitForInputProcessing();\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n        \n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            0,\n            1);\n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            1,\n            0);\n    testHarness.processEvent(\n            new CheckpointBarrier(0, 0, CheckpointOptions.forCheckpointWithDefaultLocation()),\n            1,\n            1);\n\n    testHarness.waitForInputProcessing();\n\n    testHarness.endInput();\n\n    testHarness.waitForTaskCompletion();\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n}", "summary_tokens": ["this", "test", "verifies", "that", "checkpoint", "barriers", "and", "barrier", "buffers", "work", "correctly", "with", "concurrent", "checkpoint", "barriers", "where", "one", "checkpoint", "is", "overtaking", "another", "checkpoint", "i"], "project": "flink"}
{"id": 3898, "code": "public static ByteBuf serializeServerFailure(\n        final ByteBufAllocator alloc, final Throwable cause) throws IOException {\n\n    final ByteBuf buf = alloc.ioBuffer();\n\n        \n    buf.writeInt(0);\n    writeHeader(buf, MessageType.SERVER_FAILURE);\n\n    try (ByteBufOutputStream bbos = new ByteBufOutputStream(buf);\n            ObjectOutput out = new ObjectOutputStream(bbos)) {\n        out.writeObject(cause);\n    }\n\n        \n    int frameLength = buf.readableBytes() - Integer.BYTES;\n    buf.setInt(0, frameLength);\n    return buf;\n}", "summary_tokens": ["serializes", "the", "failure", "message", "sent", "to", "the", "org"], "project": "flink"}
{"id": 7205, "code": "public void setAlignedCheckpointTimeout(Duration alignedCheckpointTimeout) {\n    this.alignedCheckpointTimeout = alignedCheckpointTimeout;\n}", "summary_tokens": ["only", "relevant", "if", "unaligned", "checkpoints", "enabled", "is", "enabled"], "project": "flink"}
{"id": 6653, "code": "public void testTaskSubmission() throws Exception {\n    final ExecutionAttemptID eid = new ExecutionAttemptID();\n\n    final TaskDeploymentDescriptor tdd =\n            createTestTaskDeploymentDescriptor(\n                    \"test task\", eid, FutureCompletingInvokable.class);\n\n    final CompletableFuture<Void> taskRunningFuture = new CompletableFuture<>();\n\n    try (TaskSubmissionTestEnvironment env =\n            new TaskSubmissionTestEnvironment.Builder(jobId)\n                    .setSlotSize(1)\n                    .addTaskManagerActionListener(\n                            eid, ExecutionState.RUNNING, taskRunningFuture)\n                    .build()) {\n        TaskExecutorGateway tmGateway = env.getTaskExecutorGateway();\n        TaskSlotTable taskSlotTable = env.getTaskSlotTable();\n\n        taskSlotTable.allocateSlot(0, jobId, tdd.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd, env.getJobMasterId(), timeout).get();\n\n        taskRunningFuture.get();\n    }\n}", "summary_tokens": ["tests", "that", "we", "can", "submit", "a", "task", "to", "the", "task", "manager", "given", "that", "we", "ve", "allocated", "a", "slot", "there"], "project": "flink"}
{"id": 3892, "code": "private boolean attemptToBind(final int port) throws Throwable {\n    log.debug(\"Attempting to start {} on port {}.\", serverName, port);\n\n    this.queryExecutor = createQueryExecutor();\n    this.handler = initializeHandler();\n\n    final NettyBufferPool bufferPool = new NettyBufferPool(numEventLoopThreads);\n\n    final ThreadFactory threadFactory =\n            new ThreadFactoryBuilder()\n                    .setDaemon(true)\n                    .setNameFormat(\"Flink \" + serverName + \" EventLoop Thread %d\")\n                    .build();\n\n    final NioEventLoopGroup nioGroup =\n            new NioEventLoopGroup(numEventLoopThreads, threadFactory);\n\n    this.bootstrap =\n            new ServerBootstrap()\n                    .localAddress(bindAddress, port)\n                    .group(nioGroup)\n                    .channel(NioServerSocketChannel.class)\n                    .option(ChannelOption.ALLOCATOR, bufferPool)\n                    .childOption(ChannelOption.ALLOCATOR, bufferPool)\n                    .childHandler(new ServerChannelInitializer<>(handler));\n\n    final int defaultHighWaterMark = 64 * 1024; \n        \n        \n    if (LOW_WATER_MARK > defaultHighWaterMark) {\n        bootstrap.childOption(ChannelOption.WRITE_BUFFER_HIGH_WATER_MARK, HIGH_WATER_MARK);\n        bootstrap.childOption(ChannelOption.WRITE_BUFFER_LOW_WATER_MARK, LOW_WATER_MARK);\n    } else { \n        bootstrap.childOption(ChannelOption.WRITE_BUFFER_LOW_WATER_MARK, LOW_WATER_MARK);\n        bootstrap.childOption(ChannelOption.WRITE_BUFFER_HIGH_WATER_MARK, HIGH_WATER_MARK);\n    }\n\n    try {\n        final ChannelFuture future = bootstrap.bind().sync();\n        if (future.isSuccess()) {\n            final InetSocketAddress localAddress =\n                    (InetSocketAddress) future.channel().localAddress();\n            serverAddress =\n                    new InetSocketAddress(localAddress.getAddress(), localAddress.getPort());\n            return true;\n        }\n\n            \n            \n            \n\n        throw future.cause();\n    } catch (BindException e) {\n        log.debug(\"Failed to start {} on port {}: {}.\", serverName, port, e.getMessage());\n        try {\n                \n                \n                \n\n            shutdownServer()\n                    .whenComplete((ignoredV, ignoredT) -> serverShutdownFuture.getAndSet(null))\n                    .get();\n        } catch (Exception r) {\n\n                \n                \n                \n\n            log.warn(\"Problem while shutting down {}: {}\", serverName, r.getMessage());\n        }\n    }\n        \n    return false;\n}", "summary_tokens": ["tries", "to", "start", "the", "server", "at", "the", "provided", "port"], "project": "flink"}
{"id": 6737, "code": "int totalSize() {\n    return totalSize;\n}", "summary_tokens": ["returns", "total", "size", "of", "this", "map", "including", "logically", "removed", "state"], "project": "flink"}
{"id": 7679, "code": "public void testTimeQuerying() throws Exception {\n\n    BufferingQueryingSink<String> bufferingSink = new BufferingQueryingSink<>();\n\n    StreamSink<String> operator = new StreamSink<>(bufferingSink);\n\n    OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(operator);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.processWatermark(new Watermark(17));\n    testHarness.setProcessingTime(12);\n    testHarness.processElement(new StreamRecord<>(\"Hello\", 12L));\n\n    testHarness.processWatermark(new Watermark(42));\n    testHarness.setProcessingTime(15);\n    testHarness.processElement(new StreamRecord<>(\"Ciao\", 13L));\n\n    testHarness.processWatermark(new Watermark(42));\n    testHarness.setProcessingTime(15);\n    testHarness.processElement(new StreamRecord<>(\"Ciao\"));\n\n    assertThat(bufferingSink.data.size(), is(3));\n\n    assertThat(\n            bufferingSink.data,\n            contains(\n                    new Tuple4<>(17L, 12L, 12L, \"Hello\"),\n                    new Tuple4<>(42L, 15L, 13L, \"Ciao\"),\n                    new Tuple4<>(42L, 15L, null, \"Ciao\")));\n\n    assertThat(bufferingSink.watermarks.size(), is(3));\n\n    assertThat(\n            bufferingSink.watermarks,\n            contains(\n                    new org.apache.flink.api.common.eventtime.Watermark(17L),\n                    new org.apache.flink.api.common.eventtime.Watermark(42L),\n                    new org.apache.flink.api.common.eventtime.Watermark(42L)));\n\n    testHarness.close();\n}", "summary_tokens": ["verify", "that", "we", "can", "correctly", "query", "watermark", "processing", "time", "and", "the", "timestamp", "from", "the", "context"], "project": "flink"}
{"id": 5251, "code": "public static String getMimeTypeForFileName(String fileName) {\n    int extensionPos = fileName.lastIndexOf('.');\n    if (extensionPos >= 1 && extensionPos < fileName.length() - 1) {\n        String extension = fileName.substring(extensionPos + 1);\n        return getMimeTypeForExtension(extension);\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["gets", "the", "mime", "type", "for", "the", "file", "with", "the", "given", "name", "by", "extension"], "project": "flink"}
{"id": 7090, "code": "public DataStreamSink<T> setUidHash(String uidHash) {\n    transformation.setUidHash(uidHash);\n    return this;\n}", "summary_tokens": ["sets", "an", "user", "provided", "hash", "for", "this", "operator"], "project": "flink"}
{"id": 6327, "code": "public void testMultipleReporterInstantiation() throws Exception {\n    Configuration config = new Configuration();\n\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test1.\"\n                    + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,\n            TestReporter11.class.getName());\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test2.\"\n                    + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,\n            TestReporter12.class.getName());\n    config.setString(\n            ConfigConstants.METRICS_REPORTER_PREFIX\n                    + \"test3.\"\n                    + ConfigConstants.METRICS_REPORTER_CLASS_SUFFIX,\n            TestReporter13.class.getName());\n\n    List<ReporterSetup> reporterSetups = ReporterSetup.fromConfiguration(config, null);\n\n    assertEquals(3, reporterSetups.size());\n\n    Assert.assertTrue(TestReporter11.wasOpened);\n    Assert.assertTrue(TestReporter12.wasOpened);\n    Assert.assertTrue(TestReporter13.wasOpened);\n}", "summary_tokens": ["verifies", "that", "multiple", "reporters", "are", "instantiated", "correctly"], "project": "flink"}
{"id": 1895, "code": "public void setValueAscii(byte[] bytes, int offset, int len) {\n    if (bytes == null) {\n        throw new NullPointerException(\"Bytes must not be null\");\n    }\n    if (len < 0 || offset < 0 || offset > bytes.length - len) {\n        throw new IndexOutOfBoundsException();\n    }\n\n    ensureSize(len);\n    this.len = len;\n    this.hashCode = 0;\n\n    final char[] chars = this.value;\n\n    for (int i = 0, limit = offset + len; offset < limit; offset++, i++) {\n        chars[i] = (char) (bytes[offset] & 0xff);\n    }\n}", "summary_tokens": ["sets", "the", "value", "of", "this", "code", "string", "value", "code", "assuming", "that", "the", "binary", "data", "is", "ascii", "coded"], "project": "flink"}
{"id": 4698, "code": "public Buffer requestBuffer() {\n    return bufferManager.requestBuffer();\n}", "summary_tokens": ["requests", "buffer", "from", "input", "channel", "directly", "for", "receiving", "network", "data"], "project": "flink"}
{"id": 3204, "code": "public <M> Graph<K, VV, EV> runScatterGatherIteration(\n        ScatterFunction<K, VV, M, EV> scatterFunction,\n        org.apache.flink.graph.spargel.GatherFunction<K, VV, M> gatherFunction,\n        int maximumNumberOfIterations,\n        ScatterGatherConfiguration parameters) {\n\n    ScatterGatherIteration<K, VV, M, EV> iteration =\n            ScatterGatherIteration.withEdges(\n                    edges, scatterFunction, gatherFunction, maximumNumberOfIterations);\n\n    iteration.configure(parameters);\n\n    DataSet<Vertex<K, VV>> newVertices = this.getVertices().runOperation(iteration);\n\n    return new Graph<>(newVertices, this.edges, this.context);\n}", "summary_tokens": ["runs", "a", "scatter", "gather", "iteration", "on", "the", "graph", "with", "configuration", "options"], "project": "flink"}
{"id": 5995, "code": "public void testJobSubmission() throws Exception {\n    dispatcher =\n            createAndStartDispatcher(\n                    heartbeatServices,\n                    haServices,\n                    new ExpectedJobIdJobManagerRunnerFactory(\n                            jobId, createdJobManagerRunnerLatch));\n    DispatcherGateway dispatcherGateway = dispatcher.getSelfGateway(DispatcherGateway.class);\n\n    dispatcherGateway.submitJob(jobGraph, TIMEOUT).get();\n\n    jobMasterLeaderElectionService.getStartFuture().get();\n\n    assertTrue(\n            \"jobManagerRunner was not started\",\n            jobMasterLeaderElectionService.getStartFuture().isDone());\n}", "summary_tokens": ["tests", "that", "we", "can", "submit", "a", "job", "to", "the", "dispatcher", "which", "then", "spawns", "a", "new", "job", "manager", "runner"], "project": "flink"}
{"id": 9554, "code": "public void batchFailoverWithKeyByBarrier() throws Exception {\n\n    final StreamExecutionEnvironment env = getExecutionEnvironment();\n\n    DataStreamSource<String> source = env.fromElements(\"foo\", \"bar\");\n\n    SingleOutputStreamOperator<String> mapped =\n            source.map(new SuffixAttemptId(\"a\"))\n                    .map(new SuffixAttemptId(\"b\"))\n                    .keyBy(in -> in)\n                    .map(new SuffixAttemptId(\"c\"))\n                    .map(new OnceFailingMapper(\"d\"));\n\n    try (CloseableIterator<String> result = mapped.executeAndCollect()) {\n\n            \n            \n        assertThat(\n                iteratorToList(result),\n                containsInAnyOrder(\"foo-a0-b0-c1-d1\", \"bar-a0-b0-c1-d1\"));\n    }\n}", "summary_tokens": ["we", "induce", "a", "failure", "in", "the", "last", "mapper"], "project": "flink"}
{"id": 7286, "code": "public void onTimer(final long timestamp, final OnTimerContext ctx, final Collector<OUT> out)", "summary_tokens": ["called", "when", "a", "timer", "set", "using", "timer", "service", "fires"], "project": "flink"}
{"id": 8924, "code": "public static List<RelCollation> limit(RelMetadataQuery mq, RelNode input) {\n    return mq.collations(input);\n}", "summary_tokens": ["helper", "method", "to", "determine", "a", "limit", "s", "collation"], "project": "flink"}
{"id": 1405, "code": "public static List<Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>>\n        readSerializersAndConfigsWithResilience(\n                DataInputView in, ClassLoader userCodeClassLoader) throws IOException {\n\n    int numSerializersAndConfigSnapshots = in.readInt();\n\n    int[] offsets = new int[numSerializersAndConfigSnapshots * 2];\n\n    for (int i = 0; i < numSerializersAndConfigSnapshots; i++) {\n        offsets[i * 2] = in.readInt();\n        offsets[i * 2 + 1] = in.readInt();\n    }\n\n    int totalBytes = in.readInt();\n    byte[] buffer = new byte[totalBytes];\n    in.readFully(buffer);\n\n    List<Tuple2<TypeSerializer<?>, TypeSerializerSnapshot<?>>> serializersAndConfigSnapshots =\n            new ArrayList<>(numSerializersAndConfigSnapshots);\n\n    TypeSerializer<?> serializer;\n    TypeSerializerSnapshot<?> configSnapshot;\n    try (ByteArrayInputStreamWithPos bufferWithPos = new ByteArrayInputStreamWithPos(buffer);\n            DataInputViewStreamWrapper bufferWrapper =\n                    new DataInputViewStreamWrapper(bufferWithPos)) {\n\n        for (int i = 0; i < numSerializersAndConfigSnapshots; i++) {\n\n            bufferWithPos.setPosition(offsets[i * 2]);\n            serializer = tryReadSerializer(bufferWrapper, userCodeClassLoader, true);\n\n            bufferWithPos.setPosition(offsets[i * 2 + 1]);\n\n            configSnapshot =\n                    TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(\n                            bufferWrapper, userCodeClassLoader, serializer);\n\n            if (serializer instanceof LegacySerializerSnapshotTransformer) {\n                configSnapshot = transformLegacySnapshot(serializer, configSnapshot);\n            }\n\n            serializersAndConfigSnapshots.add(new Tuple2<>(serializer, configSnapshot));\n        }\n    }\n\n    return serializersAndConfigSnapshots;\n}", "summary_tokens": ["reads", "from", "a", "data", "input", "view", "a", "list", "of", "serializers", "and", "their", "corresponding", "config", "snapshots", "written", "using", "write", "serializers", "and", "configs", "with", "resilience", "data", "output", "view", "list"], "project": "flink"}
{"id": 7427, "code": "public TypeInformation<IN> getInputType() {\n    return input.getOutputType();\n}", "summary_tokens": ["returns", "the", "type", "information", "for", "the", "elements", "of", "the", "input"], "project": "flink"}
{"id": 4225, "code": "private void checkAllTasksInitiated() throws CheckpointException {\n    for (ExecutionVertex task : allTasks) {\n        if (task.getCurrentExecutionAttempt() == null) {\n            throw new CheckpointException(\n                    String.format(\n                            \"task %s of job %s is not being executed at the moment. Aborting checkpoint.\",\n                            task.getTaskNameWithSubtaskIndex(), jobId),\n                    CheckpointFailureReason.NOT_ALL_REQUIRED_TASKS_RUNNING);\n        }\n    }\n}", "summary_tokens": ["checks", "if", "all", "tasks", "are", "attached", "with", "the", "current", "execution", "already"], "project": "flink"}
{"id": 2035, "code": "public static <T> T checkNotNull(\n        T reference,\n        @Nullable String errorMessageTemplate,\n        @Nullable Object... errorMessageArgs) {\n\n    if (reference == null) {\n        throw new NullPointerException(format(errorMessageTemplate, errorMessageArgs));\n    }\n    return reference;\n}", "summary_tokens": ["ensures", "that", "the", "given", "object", "reference", "is", "not", "null"], "project": "flink"}
{"id": 7050, "code": "public ResourceSpec getPreferredResources() {\n    return transformation.getPreferredResources();\n}", "summary_tokens": ["gets", "the", "preferred", "resources", "for", "this", "operator"], "project": "flink"}
{"id": 6478, "code": "public void testOperationFailure() throws Exception {\n    final FlinkException testException = new FlinkException(\"Test exception\");\n    testingTriggerHandler.setGatewayCallback(\n            (request, gateway) -> FutureUtils.completedExceptionally(testException));\n\n        \n    final TriggerId triggerId =\n            testingTriggerHandler\n                    .handleRequest(triggerOperationRequest(), DUMMY_GATEWAY)\n                    .get()\n                    .getTriggerId();\n\n    AsynchronousOperationResult<OperationResult> operationResult =\n            testingStatusHandler\n                    .handleRequest(statusOperationRequest(triggerId), DUMMY_GATEWAY)\n                    .get();\n\n    assertThat(operationResult.queueStatus().getId(), is(QueueStatus.completed().getId()));\n\n    final OperationResult resource = operationResult.resource();\n    assertThat(resource.throwable, is(testException));\n}", "summary_tokens": ["tests", "the", "triggering", "and", "exceptional", "completion", "of", "an", "asynchronous", "operation"], "project": "flink"}
{"id": 8634, "code": "public static List<LogicalType> getFieldTypes(LogicalType logicalType) {\n    if (logicalType instanceof DistinctType) {\n        return getFieldTypes(((DistinctType) logicalType).getSourceType());\n    }\n    return logicalType.getChildren();\n}", "summary_tokens": ["returns", "the", "field", "types", "of", "row", "and", "structured", "types"], "project": "flink"}
{"id": 6264, "code": "public void testBlobServerCleanupFailedJob() throws Exception {\n    testBlobServerCleanup(TestCase.JOB_FAILS);\n}", "summary_tokens": ["test", "cleanup", "for", "a", "job", "that", "fails", "first", "a", "task", "fails", "then", "the", "job", "recovers", "then", "the", "whole", "job", "fails", "due", "to", "a", "limited", "restart", "policy"], "project": "flink"}
{"id": 219, "code": "public void runInvalidElasticsearchClusterTest() throws Exception {\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStreamSource<Tuple2<Integer, String>> source =\n            env.addSource(new SourceSinkDataTestKit.TestDataSourceFunction());\n\n    source.addSink(\n            createElasticsearchSinkForNode(\n                    1,\n                    \"invalid-cluster-name\",\n                    SourceSinkDataTestKit.getJsonSinkFunction(\"test\"),\n                    \"123.123.123.123\")); \n\n    try {\n        env.execute(\"Elasticsearch Sink Test\");\n    } catch (JobExecutionException expectedException) {\n            \n            \n            \n        return;\n    }\n\n    fail();\n}", "summary_tokens": ["tests", "whether", "the", "elasticsearch", "sink", "fails", "when", "there", "is", "no", "cluster", "to", "connect", "to"], "project": "flink"}
{"id": 1012, "code": "public ZoneId getLocalTimeZone() {\n  String timeZoneStr = getVar(ConfVars.HIVE_LOCAL_TIME_ZONE);\n  return TimestampTZUtil.parseTimeZone(timeZoneStr);\n}", "summary_tokens": ["obtains", "the", "local", "time", "zone", "id"], "project": "flink"}
{"id": 536, "code": "static OffsetsInitializer offsets(\n        Map<TopicPartition, Long> offsets, OffsetResetStrategy offsetResetStrategy) {\n    return new SpecifiedOffsetsInitializer(offsets, offsetResetStrategy);\n}", "summary_tokens": ["get", "an", "offsets", "initializer", "which", "initializes", "the", "offsets", "to", "the", "specified", "offsets"], "project": "flink"}
{"id": 7634, "code": "public void testAutoMaxParallelism() {\n    int globalParallelism = 42;\n    int mapParallelism = 17;\n    int maxParallelism = 21;\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(globalParallelism);\n\n    DataStream<Integer> source = env.fromElements(1, 2, 3);\n\n    DataStream<Integer> keyedResult1 = source.keyBy(value -> value).map(new NoOpIntMap());\n\n    DataStream<Integer> keyedResult2 =\n            keyedResult1\n                    .keyBy(value -> value)\n                    .map(new NoOpIntMap())\n                    .setParallelism(mapParallelism);\n\n    DataStream<Integer> keyedResult3 =\n            keyedResult2\n                    .keyBy(value -> value)\n                    .map(new NoOpIntMap())\n                    .setMaxParallelism(maxParallelism);\n\n    DataStream<Integer> keyedResult4 =\n            keyedResult3\n                    .keyBy(value -> value)\n                    .map(new NoOpIntMap())\n                    .setMaxParallelism(maxParallelism)\n                    .setParallelism(mapParallelism);\n\n    keyedResult4.addSink(new DiscardingSink<>());\n\n    StreamGraph graph = env.getStreamGraph();\n\n    StreamNode keyedResult3Node = graph.getStreamNode(keyedResult3.getId());\n    StreamNode keyedResult4Node = graph.getStreamNode(keyedResult4.getId());\n\n    assertEquals(maxParallelism, keyedResult3Node.getMaxParallelism());\n    assertEquals(maxParallelism, keyedResult4Node.getMaxParallelism());\n}", "summary_tokens": ["tests", "that", "the", "max", "parallelism", "is", "automatically", "set", "to", "the", "parallelism", "if", "it", "has", "not", "been", "specified"], "project": "flink"}
{"id": 4944, "code": "public static void openUserCode(Function stub, Configuration parameters) throws Exception {\n    try {\n        FunctionUtils.openFunction(stub, parameters);\n    } catch (Throwable t) {\n        throw new Exception(\n                \"The user defined 'open(Configuration)' method in \"\n                        + stub.getClass().toString()\n                        + \" caused an exception: \"\n                        + t.getMessage(),\n                t);\n    }\n}", "summary_tokens": ["opens", "the", "given", "stub", "using", "its", "org"], "project": "flink"}
{"id": 2012, "code": "public static String getHostnameFromFQDN(String fqdn) {\n    if (fqdn == null) {\n        throw new IllegalArgumentException(\"fqdn is null\");\n    }\n    int dotPos = fqdn.indexOf('.');\n    if (dotPos == -1) {\n        return fqdn;\n    } else {\n        return fqdn.substring(0, dotPos);\n    }\n}", "summary_tokens": ["turn", "a", "fully", "qualified", "domain", "name", "fqdn", "into", "a", "hostname"], "project": "flink"}
{"id": 7934, "code": "private boolean executeFile(String content, ExecutionMode mode) {\n    terminal.writer().println(CliStrings.messageInfo(CliStrings.MESSAGE_EXECUTE_FILE).toAnsi());\n\n    for (String statement : CliStatementSplitter.splitContent(content)) {\n        terminal.writer()\n                .println(new AttributedString(String.format(\"%s%s\", prompt, statement)));\n        terminal.flush();\n\n        if (!executeStatement(statement, mode)) {\n                \n            return false;\n        }\n    }\n    return true;\n}", "summary_tokens": ["execute", "content", "from", "sql", "file", "and", "prints", "status", "information", "and", "or", "errors", "on", "the", "terminal"], "project": "flink"}
{"id": 6678, "code": "public void testWatchDogInterruptsTask() throws Exception {\n    final TaskManagerActions taskManagerActions = new ProhibitFatalErrorTaskManagerActions();\n\n    final Configuration config = new Configuration();\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_INTERVAL.key(), 5);\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT.key(), 60 * 1000);\n\n    final Task task =\n            createTaskBuilder()\n                    .setInvokable(InvokableBlockingInCancel.class)\n                    .setTaskManagerConfig(config)\n                    .setTaskManagerActions(taskManagerActions)\n                    .build();\n\n    task.startTaskThread();\n\n    awaitLatch.await();\n\n    task.cancelExecution();\n    task.getExecutingThread().join();\n}", "summary_tokens": ["tests", "that", "interrupt", "happens", "via", "watch", "dog", "if", "canceller", "is", "stuck", "in", "cancel"], "project": "flink"}
{"id": 3323, "code": "public JaccardIndex<K, VV, EV> setMirrorResults(boolean mirrorResults) {\n    this.mirrorResults = mirrorResults;\n\n    return this;\n}", "summary_tokens": ["by", "default", "only", "one", "result", "is", "output", "for", "each", "pair", "of", "vertices"], "project": "flink"}
{"id": 4199, "code": "CheckpointStatsHistory createSnapshot() {\n    if (readOnly) {\n        throw new UnsupportedOperationException(\n                \"Can't create a snapshot of a read-only history.\");\n    }\n\n    List<AbstractCheckpointStats> checkpointsHistory;\n    Map<Long, AbstractCheckpointStats> checkpointsById;\n\n    checkpointsById = new HashMap<>(checkpointsArray.length);\n\n    if (maxSize == 0) {\n        checkpointsHistory = Collections.emptyList();\n    } else {\n        AbstractCheckpointStats[] newCheckpointsArray =\n                new AbstractCheckpointStats[checkpointsArray.length];\n\n        System.arraycopy(\n                checkpointsArray,\n                nextPos,\n                newCheckpointsArray,\n                0,\n                checkpointsArray.length - nextPos);\n        System.arraycopy(\n                checkpointsArray,\n                0,\n                newCheckpointsArray,\n                checkpointsArray.length - nextPos,\n                nextPos);\n\n        checkpointsHistory = Arrays.asList(newCheckpointsArray);\n\n            \n        Collections.reverse(checkpointsHistory);\n\n        for (AbstractCheckpointStats checkpoint : checkpointsHistory) {\n            checkpointsById.put(checkpoint.getCheckpointId(), checkpoint);\n        }\n    }\n\n    if (latestCompletedCheckpoint != null) {\n        checkpointsById.put(\n                latestCompletedCheckpoint.getCheckpointId(), latestCompletedCheckpoint);\n    }\n\n    if (latestFailedCheckpoint != null) {\n        checkpointsById.put(latestFailedCheckpoint.getCheckpointId(), latestFailedCheckpoint);\n    }\n\n    if (latestSavepoint != null) {\n        checkpointsById.put(latestSavepoint.getCheckpointId(), latestSavepoint);\n    }\n\n    return new CheckpointStatsHistory(\n            true,\n            maxSize,\n            null,\n            checkpointsHistory,\n            checkpointsById,\n            latestCompletedCheckpoint,\n            latestFailedCheckpoint,\n            latestSavepoint);\n}", "summary_tokens": ["creates", "a", "snapshot", "of", "the", "current", "state"], "project": "flink"}
{"id": 9473, "code": "public static StreamRecord<RowData> updateAfterRecord(Object... fields) {\n    RowData row = row(fields);\n    row.setRowKind(RowKind.UPDATE_AFTER);\n    return new StreamRecord<>(row);\n}", "summary_tokens": ["creates", "n", "new", "stream", "record", "of", "row", "data", "based", "on", "the", "given", "fields", "array", "and", "a", "default", "update", "after", "row", "kind"], "project": "flink"}
{"id": 7334, "code": "public Map<Integer, byte[]> traverseStreamGraphAndGenerateHashes(StreamGraph streamGraph) {\n        \n    final HashFunction hashFunction = Hashing.murmur3_128(0);\n    final Map<Integer, byte[]> hashes = new HashMap<>();\n\n    Set<Integer> visited = new HashSet<>();\n    Queue<StreamNode> remaining = new ArrayDeque<>();\n\n        \n        \n        \n        \n    List<Integer> sources = new ArrayList<>();\n    for (Integer sourceNodeId : streamGraph.getSourceIDs()) {\n        sources.add(sourceNodeId);\n    }\n    Collections.sort(sources);\n\n        \n        \n        \n        \n\n        \n    for (Integer sourceNodeId : sources) {\n        remaining.add(streamGraph.getStreamNode(sourceNodeId));\n        visited.add(sourceNodeId);\n    }\n\n    StreamNode currentNode;\n    while ((currentNode = remaining.poll()) != null) {\n            \n            \n            \n        if (generateNodeHash(\n                currentNode,\n                hashFunction,\n                hashes,\n                streamGraph.isChainingEnabled(),\n                streamGraph)) {\n                \n            for (StreamEdge outEdge : currentNode.getOutEdges()) {\n                StreamNode child = streamGraph.getTargetVertex(outEdge);\n\n                if (!visited.contains(child.getId())) {\n                    remaining.add(child);\n                    visited.add(child.getId());\n                }\n            }\n        } else {\n                \n            visited.remove(currentNode.getId());\n        }\n    }\n\n    return hashes;\n}", "summary_tokens": ["returns", "a", "map", "with", "a", "hash", "for", "each", "stream", "node", "of", "the", "stream", "graph"], "project": "flink"}
{"id": 9013, "code": "public List<RelReferentialConstraint> getReferentialConstraints() {\n    return ImmutableList.of();\n}", "summary_tokens": ["returns", "the", "referential", "constraints", "existing", "for", "this", "table"], "project": "flink"}
{"id": 9078, "code": "private static void checkFieldType(LogicalType fieldType) {\n    if (!supportedTypes.contains(fieldType.getTypeRoot())) {\n        throw new ValidationException(\n                String.format(\n                        \"The 'raw' format doesn't supports '%s' as column type.\",\n                        fieldType.asSummaryString()));\n    }\n}", "summary_tokens": ["checks", "the", "given", "field", "type", "is", "supported"], "project": "flink"}
{"id": 8642, "code": "public static LogicalType findAvgAggType(LogicalType argType) {\n    final LogicalType resultType;\n    if (argType.is(DECIMAL)) {\n            \n        if (argType instanceof LegacyTypeInformationType) {\n            return argType;\n        }\n            \n            \n            \n            \n        resultType = LogicalTypeMerging.findDivisionDecimalType(38, getScale(argType), 20, 0);\n    } else {\n        resultType = argType;\n    }\n    return resultType.copy(argType.isNullable());\n}", "summary_tokens": ["finds", "the", "result", "type", "of", "a", "decimal", "average", "aggregation"], "project": "flink"}
{"id": 9304, "code": "public RowIterator<BinaryRowData> buildTriggerWindowElementsIterator() {\n    currentWindow = nextWindow;\n        \n    Preconditions.checkState(\n            watermark == Long.MIN_VALUE || nextWindow != null,\n            \"next trigger window cannot be null.\");\n    if (nextWindow.getEnd() > watermark) {\n        throw new IllegalStateException(\"invalid window triggered \" + currentWindow);\n    }\n\n        \n    nextWindow =\n            TimeWindow.of(\n                    currentWindow.getStart() + slideSize,\n                    currentWindow.getStart() + slideSize + windowSize);\n        \n    emptyWindowTriggered = true;\n    onBufferEvict(triggerWindowStartIndex);\n    return new WindowsElementsIterator(newBufferIterator(triggerWindowStartIndex));\n}", "summary_tokens": ["the", "iterator", "of", "the", "next", "triggerable", "window", "s", "elements"], "project": "flink"}
{"id": 815, "code": "private GetRecordsResult getRecords(String shardItr, int maxNumberOfRecords)\n        throws InterruptedException {\n    GetRecordsResult getRecordsResult = null;\n    while (getRecordsResult == null) {\n        try {\n            getRecordsResult = kinesisProxy.getRecords(shardItr, maxNumberOfRecords);\n        } catch (ExpiredIteratorException | InterruptedException eiEx) {\n            LOG.warn(\n                    \"Encountered an unexpected expired iterator {} for shard {};\"\n                            + \" refreshing the iterator ...\",\n                    shardItr,\n                    subscribedShard);\n\n            shardItr = getShardIterator();\n\n                \n                \n            if (fetchIntervalMillis != 0) {\n                Thread.sleep(fetchIntervalMillis);\n            }\n        }\n    }\n    return getRecordsResult;\n}", "summary_tokens": ["calls", "kinesis", "proxy", "interface", "get", "records", "string", "int", "while", "also", "handling", "unexpected", "aws", "expired", "iterator", "exception", "s", "to", "assure", "that", "we", "get", "results", "and", "don", "t", "just", "fail", "on", "such", "occasions"], "project": "flink"}
{"id": 7317, "code": "public static <T> ArrayDeque<Tuple2<Long, Set<T>>> toDeque(\n        SerializedCheckpointData[] data, TypeSerializer<T> serializer) throws IOException {\n\n    ArrayDeque<Tuple2<Long, Set<T>>> deque = new ArrayDeque<>(data.length);\n    DataInputDeserializer deser = null;\n\n    for (SerializedCheckpointData checkpoint : data) {\n        byte[] serializedData = checkpoint.getSerializedData();\n        if (deser == null) {\n            deser = new DataInputDeserializer(serializedData, 0, serializedData.length);\n        } else {\n            deser.setBuffer(serializedData);\n        }\n\n        final Set<T> ids = new HashSet<>(checkpoint.getNumIds());\n        final int numIds = checkpoint.getNumIds();\n\n        for (int i = 0; i < numIds; i++) {\n            ids.add(serializer.deserialize(deser));\n        }\n\n        deque.addLast(new Tuple2<Long, Set<T>>(checkpoint.checkpointId, ids));\n    }\n\n    return deque;\n}", "summary_tokens": ["de", "serializes", "an", "array", "of", "serialized", "checkpoint", "data", "back", "into", "an", "array", "deque", "of", "element", "checkpoints"], "project": "flink"}
{"id": 149, "code": "public void wakeUpPuttingThread(int threadIndex) {\n    lock.lock();\n    try {\n        maybeCreateCondition(threadIndex);\n        ConditionAndFlag caf = putConditionAndFlags[threadIndex];\n        if (caf != null) {\n            caf.setWakeUp(true);\n            caf.condition().signal();\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["gracefully", "wakes", "up", "the", "thread", "with", "the", "given", "thread", "index", "if", "it", "is", "blocked", "in", "adding", "an", "element"], "project": "flink"}
{"id": 2613, "code": "void readNextGroup() {\n    try {\n        int header = readUnsignedVarInt();\n        this.mode = (header & 1) == 0 ? MODE.RLE : MODE.PACKED;\n        switch (mode) {\n            case RLE:\n                this.currentCount = header >>> 1;\n                this.currentValue = readIntLittleEndianPaddedOnBitWidth();\n                return;\n            case PACKED:\n                int numGroups = header >>> 1;\n                this.currentCount = numGroups * 8;\n\n                if (this.currentBuffer.length < this.currentCount) {\n                    this.currentBuffer = new int[this.currentCount];\n                }\n                currentBufferIdx = 0;\n                int valueIndex = 0;\n                while (valueIndex < this.currentCount) {\n                        \n                    ByteBuffer buffer = in.slice(bitWidth);\n                    this.packer.unpack8Values(\n                            buffer, buffer.position(), this.currentBuffer, valueIndex);\n                    valueIndex += 8;\n                }\n                return;\n            default:\n                throw new ParquetDecodingException(\"not a valid mode \" + this.mode);\n        }\n    } catch (IOException e) {\n        throw new ParquetDecodingException(\"Failed to read from input stream\", e);\n    }\n}", "summary_tokens": ["reads", "the", "next", "group"], "project": "flink"}
{"id": 2281, "code": "public FlinkContainersBuilder setLogProperties(Properties logProperties) {\n    this.logProperties.putAll(logProperties);\n    return this;\n}", "summary_tokens": ["sets", "log", "0", "j", "properties"], "project": "flink"}
{"id": 9570, "code": "private static JobGraph getJobGraph(Plan plan) {\n    Optimizer pc = new Optimizer(new DataStatistics(), new Configuration());\n    JobGraphGenerator jgg = new JobGraphGenerator();\n    OptimizedPlan op = pc.compile(plan);\n    return jgg.compileJobGraph(op);\n}", "summary_tokens": ["helpers", "to", "generate", "the", "job", "graph"], "project": "flink"}
{"id": 1797, "code": "public void putFloat(int index, float value) {\n    putInt(index, Float.floatToRawIntBits(value));\n}", "summary_tokens": ["writes", "the", "given", "single", "precision", "float", "value", "0", "bit", "0", "bytes", "to", "the", "given", "position", "in", "the", "system", "s", "native", "byte", "order"], "project": "flink"}
{"id": 1605, "code": "private static LinkedHashMap<Class<?>, Integer> createRegisteredSubclassTags(\n        LinkedHashSet<Class<?>> registeredSubclasses) {\n    final LinkedHashMap<Class<?>, Integer> classToTag = new LinkedHashMap<>();\n\n    int id = 0;\n    for (Class<?> registeredClass : registeredSubclasses) {\n        classToTag.put(registeredClass, id);\n        id++;\n    }\n\n    return classToTag;\n}", "summary_tokens": ["builds", "map", "of", "registered", "subclasses", "to", "their", "class", "tags"], "project": "flink"}
{"id": 1233, "code": "public String getStatisticsKey() {\n    return this.statisticsKey;\n}", "summary_tokens": ["gets", "the", "key", "under", "which", "statistics", "about", "this", "data", "source", "may", "be", "obtained", "from", "the", "statistics", "cache"], "project": "flink"}
{"id": 2667, "code": "public PartitionOperator<T> rebalance() {\n    return new PartitionOperator<>(\n            this, PartitionMethod.REBALANCE, Utils.getCallLocationName());\n}", "summary_tokens": ["enforces", "a", "re", "balancing", "of", "the", "data", "set", "i"], "project": "flink"}
{"id": 1715, "code": "private static FileSystemFactory loadHadoopFsFactory() {\n    final ClassLoader cl = FileSystem.class.getClassLoader();\n\n        \n    final Class<? extends FileSystemFactory> factoryClass;\n    try {\n        factoryClass =\n                Class.forName(\"org.apache.flink.runtime.fs.hdfs.HadoopFsFactory\", false, cl)\n                        .asSubclass(FileSystemFactory.class);\n    } catch (ClassNotFoundException e) {\n        LOG.info(\n                \"No Flink runtime dependency present. \"\n                        + \"The extended set of supported File Systems via Hadoop is not available.\");\n        return new UnsupportedSchemeFactory(\n                \"Flink runtime classes missing in classpath/dependencies.\");\n    } catch (Exception | LinkageError e) {\n        LOG.warn(\"Flink's Hadoop file system factory could not be loaded\", e);\n        return new UnsupportedSchemeFactory(\n                \"Flink's Hadoop file system factory could not be loaded\", e);\n    }\n\n        \n    try {\n        Class.forName(\"org.apache.hadoop.conf.Configuration\", false, cl);\n        Class.forName(\"org.apache.hadoop.fs.FileSystem\", false, cl);\n    } catch (ClassNotFoundException e) {\n        LOG.info(\n                \"Hadoop is not in the classpath/dependencies. \"\n                        + \"The extended set of supported File Systems via Hadoop is not available.\");\n        return new UnsupportedSchemeFactory(\"Hadoop is not in the classpath/dependencies.\");\n    }\n\n        \n    try {\n        return factoryClass.newInstance();\n    } catch (Exception | LinkageError e) {\n        LOG.warn(\"Flink's Hadoop file system factory could not be created\", e);\n        return new UnsupportedSchemeFactory(\n                \"Flink's Hadoop file system factory could not be created\", e);\n    }\n}", "summary_tokens": ["utility", "loader", "for", "the", "hadoop", "file", "system", "factory"], "project": "flink"}
{"id": 5364, "code": "public SharedStateRegistryKey createSharedStateRegistryKeyFromFileName(StateHandleID shId) {\n    return new SharedStateRegistryKey(\n            String.valueOf(backendIdentifier) + '-' + keyGroupRange, shId);\n}", "summary_tokens": ["create", "a", "unique", "key", "to", "register", "one", "of", "our", "shared", "state", "handles"], "project": "flink"}
{"id": 1112, "code": "public String getTaskName() {\n    return this.taskName;\n}", "summary_tokens": ["returns", "the", "name", "of", "the", "task"], "project": "flink"}
{"id": 6061, "code": "public void testNonRecoverableFailureHandlingResult() {\n        \n    final Throwable error =\n            new Exception(new SuppressRestartsException(new Exception(\"test failure\")));\n    final long timestamp = System.currentTimeMillis();\n    final FailureHandlingResult result =\n            executionFailureHandler.getFailureHandlingResult(\n                    new ExecutionVertexID(new JobVertexID(), 0), error, timestamp);\n\n        \n    assertFalse(result.canRestart());\n    assertNotNull(result.getError());\n    assertTrue(ExecutionFailureHandler.isUnrecoverableError(result.getError()));\n    assertThat(result.getTimestamp(), is(timestamp));\n    try {\n        result.getVerticesToRestart();\n        fail(\"get tasks to restart is not allowed when restarting is suppressed\");\n    } catch (IllegalStateException ex) {\n            \n    }\n    try {\n        result.getRestartDelayMS();\n        fail(\"get restart delay is not allowed when restarting is suppressed\");\n    } catch (IllegalStateException ex) {\n            \n    }\n    assertEquals(0, executionFailureHandler.getNumberOfRestarts());\n}", "summary_tokens": ["tests", "the", "case", "that", "the", "failure", "is", "non", "recoverable", "type"], "project": "flink"}
{"id": 9513, "code": "public void triggerScheduledTasks() {\n    triggerPeriodicScheduledTasks();\n    triggerNonPeriodicScheduledTasks();\n}", "summary_tokens": ["triggers", "all", "registered", "tasks"], "project": "flink"}
{"id": 7655, "code": "public void testRestoreProcedureOrderAndFailure() throws Exception {\n\n    CloseableRegistry closeableRegistry = new CloseableRegistry();\n    CheckpointStreamFactory checkpointStreamFactory = new MemCheckpointStreamFactory(1024);\n\n    ListStateDescriptor<Integer> stateDescriptor =\n            new ListStateDescriptor<>(\"test-state\", Integer.class);\n    OperatorStateBackend originalBackend = backendSupplier.apply(Collections.emptyList());\n    SnapshotResult<OperatorStateHandle> snapshotResult;\n\n    try {\n        ListState<Integer> listState = originalBackend.getListState(stateDescriptor);\n\n        listState.add(0);\n        listState.add(1);\n        listState.add(2);\n        listState.add(3);\n\n        RunnableFuture<SnapshotResult<OperatorStateHandle>> snapshot =\n                originalBackend.snapshot(\n                        0L,\n                        0L,\n                        checkpointStreamFactory,\n                        CheckpointOptions.forCheckpointWithDefaultLocation());\n\n        snapshot.run();\n        snapshotResult = snapshot.get();\n\n    } finally {\n        originalBackend.close();\n        originalBackend.dispose();\n    }\n\n    OperatorStateHandle firstFailHandle = mock(OperatorStateHandle.class);\n    OperatorStateHandle secondSuccessHandle = spy(snapshotResult.getJobManagerOwnedSnapshot());\n    OperatorStateHandle thirdNotUsedHandle = mock(OperatorStateHandle.class);\n\n    List<StateObjectCollection<OperatorStateHandle>> sortedRestoreOptions =\n            Arrays.asList(\n                    new StateObjectCollection<>(Collections.singletonList(firstFailHandle)),\n                    new StateObjectCollection<>(Collections.singletonList(secondSuccessHandle)),\n                    new StateObjectCollection<>(Collections.singletonList(thirdNotUsedHandle)));\n\n    BackendRestorerProcedure<OperatorStateBackend, OperatorStateHandle> restorerProcedure =\n            new BackendRestorerProcedure<>(\n                    backendSupplier, closeableRegistry, \"test op state backend\");\n\n    OperatorStateBackend restoredBackend =\n            restorerProcedure.createAndRestore(sortedRestoreOptions);\n    Assert.assertNotNull(restoredBackend);\n\n    try {\n        verify(firstFailHandle).openInputStream();\n        verify(secondSuccessHandle).openInputStream();\n        verifyZeroInteractions(thirdNotUsedHandle);\n\n        ListState<Integer> listState = restoredBackend.getListState(stateDescriptor);\n\n        Iterator<Integer> stateIterator = listState.get().iterator();\n        Assert.assertEquals(0, (int) stateIterator.next());\n        Assert.assertEquals(1, (int) stateIterator.next());\n        Assert.assertEquals(2, (int) stateIterator.next());\n        Assert.assertEquals(3, (int) stateIterator.next());\n        Assert.assertFalse(stateIterator.hasNext());\n\n    } finally {\n        restoredBackend.close();\n        restoredBackend.dispose();\n    }\n}", "summary_tokens": ["tests", "that", "the", "restore", "procedure", "follows", "the", "order", "of", "the", "iterator", "and", "will", "retries", "failed", "attempts", "if", "there", "are", "more", "options"], "project": "flink"}
{"id": 1665, "code": "public static boolean filterPrefixMapKey(String key, String candidate) {\n    final String prefixKey = key + \".\";\n    return candidate.startsWith(prefixKey);\n}", "summary_tokens": ["filter", "condition", "for", "prefix", "map", "keys"], "project": "flink"}
{"id": 4, "code": "public static ArchCondition<JavaMethod> haveLeafArgumentTypes(\n        DescribedPredicate<JavaClass> typePredicate) {\n    return new ArchCondition<JavaMethod>(\n            \"have leaf argument types\" + typePredicate.getDescription()) {\n        @Override\n        public void check(JavaMethod method, ConditionEvents events) {\n            final List<JavaClass> leafArgumentTypes =\n                    method.getParameterTypes().stream()\n                            .flatMap(argumentType -> getLeafTypes(argumentType).stream())\n                            .collect(Collectors.toList());\n\n            for (JavaClass leafType : leafArgumentTypes) {\n                if (!isJavaClass(leafType)) {\n                    continue;\n                }\n\n                if (!typePredicate.apply(leafType)) {\n                    final String message =\n                            String.format(\n                                    \"%s: Argument leaf type %s does not satisfy: %s\",\n                                    method.getFullName(),\n                                    leafType.getName(),\n                                    typePredicate.getDescription());\n\n                    events.add(SimpleConditionEvent.violated(method, message));\n                }\n            }\n        }\n    };\n}", "summary_tokens": ["tests", "leaf", "argument", "types", "of", "a", "method", "against", "the", "given", "predicate"], "project": "flink"}
{"id": 9371, "code": "public static byte[] allocateReuseBytes(int length) {\n    byte[] bytes = BYTES_LOCAL.get();\n\n    if (bytes == null) {\n        if (length <= MAX_BYTES_LENGTH) {\n            bytes = new byte[MAX_BYTES_LENGTH];\n            BYTES_LOCAL.set(bytes);\n        } else {\n            bytes = new byte[length];\n        }\n    } else if (bytes.length < length) {\n        bytes = new byte[length];\n    }\n\n    return bytes;\n}", "summary_tokens": ["allocate", "bytes", "that", "is", "only", "for", "temporary", "usage", "it", "should", "not", "be", "stored", "in", "somewhere", "else"], "project": "flink"}
{"id": 8573, "code": "public static InputTypeStrategy comparable(\n        ConstantArgumentCount argumentCount, StructuredComparison requiredComparison) {\n    return new ComparableTypeStrategy(argumentCount, requiredComparison);\n}", "summary_tokens": ["strategy", "that", "checks", "all", "types", "are", "comparable", "with", "each", "other"], "project": "flink"}
{"id": 3772, "code": "public void checkJoinWithReplicatedSourceInputBehindRebalance() {\n    ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    TupleTypeInfo<Tuple1<String>> typeInfo = TupleTypeInfo.getBasicTupleTypeInfo(String.class);\n    ReplicatingInputFormat<Tuple1<String>, FileInputSplit> rif =\n            new ReplicatingInputFormat<Tuple1<String>, FileInputSplit>(\n                    new TupleCsvInputFormat<Tuple1<String>>(new Path(\"/some/path\"), typeInfo));\n\n    DataSet<Tuple1<String>> source1 =\n            env.createInput(\n                    rif, new TupleTypeInfo<Tuple1<String>>(BasicTypeInfo.STRING_TYPE_INFO));\n    DataSet<Tuple1<String>> source2 = env.readCsvFile(\"/some/otherpath\").types(String.class);\n\n    DataSink<Tuple2<Tuple1<String>, Tuple1<String>>> out =\n            source1.rebalance()\n                    .join(source2)\n                    .where(\"*\")\n                    .equalTo(\"*\")\n                    .writeAsText(\"/some/newpath\");\n\n    Plan plan = env.createProgramPlan();\n\n        \n    OptimizedPlan oPlan = compileNoStats(plan);\n}", "summary_tokens": ["tests", "compiler", "fail", "for", "join", "program", "with", "replicated", "data", "source", "behind", "rebalance"], "project": "flink"}
{"id": 3167, "code": "public DataSet<Tuple3<K, K, EV>> getEdgesAsTuple3() {\n    return edges.map(new EdgeToTuple3Map<>());\n}", "summary_tokens": ["the", "edge", "data", "set", "as", "tuple", "0"], "project": "flink"}
{"id": 4378, "code": "public CompletableFuture<Void> stopApplication(\n        final ApplicationStatus applicationStatus, final @Nullable String diagnostics) {\n    return internalShutdown(\n            () -> resourceManagerService.deregisterApplication(applicationStatus, diagnostics));\n}", "summary_tokens": ["deregister", "the", "flink", "application", "from", "the", "resource", "management", "system", "by", "signalling", "the", "resource", "manager", "and", "also", "stop", "the", "process"], "project": "flink"}
{"id": 7699, "code": "public void testProcessingTimeTimerWithState() throws Exception {\n\n    KeyedCoProcessOperator<String, Integer, String, String> operator =\n            new KeyedCoProcessOperator<>(new ProcessingTimeTriggeringStatefulProcessFunction());\n\n    TwoInputStreamOperatorTestHarness<Integer, String, String> testHarness =\n            new KeyedTwoInputStreamOperatorTestHarness<>(\n                    operator,\n                    new IntToStringKeySelector<>(),\n                    new IdentityKeySelector<String>(),\n                    BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.setProcessingTime(1);\n    testHarness.processElement1(new StreamRecord<>(17)); \n    testHarness.processElement1(new StreamRecord<>(13)); \n\n    testHarness.setProcessingTime(2);\n    testHarness.processElement1(new StreamRecord<>(13)); \n    testHarness.processElement2(new StreamRecord<>(\"42\")); \n\n    testHarness.setProcessingTime(6);\n    testHarness.setProcessingTime(7);\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    expectedOutput.add(new StreamRecord<>(\"INPUT1:17\"));\n    expectedOutput.add(new StreamRecord<>(\"INPUT1:13\"));\n    expectedOutput.add(new StreamRecord<>(\"INPUT2:42\"));\n    expectedOutput.add(new StreamRecord<>(\"STATE:17\"));\n    expectedOutput.add(new StreamRecord<>(\"STATE:42\"));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.close();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "leakage", "between", "different", "keys"], "project": "flink"}
{"id": 2173, "code": "public void addRecord(int record) {\n    if (!records.offer(record)) {\n        throw new IllegalStateException(\"Failed to add record to split.\");\n    }\n}", "summary_tokens": ["add", "a", "record", "to", "this", "split"], "project": "flink"}
{"id": 7866, "code": "public void processElement(Object element, int inputGate, int channel) {\n    inputGates[inputGate].sendElement(element, channel);\n}", "summary_tokens": ["sends", "the", "element", "to", "the", "specified", "channel", "on", "the", "specified", "input", "gate"], "project": "flink"}
{"id": 1194, "code": "", "summary_tokens": ["closes", "this", "input", "format", "instance"], "project": "flink"}
{"id": 135, "code": "public boolean maybeShutdownFinishedFetchers() {\n    Iterator<Map.Entry<Integer, SplitFetcher<E, SplitT>>> iter = fetchers.entrySet().iterator();\n    while (iter.hasNext()) {\n        Map.Entry<Integer, SplitFetcher<E, SplitT>> entry = iter.next();\n        SplitFetcher<E, SplitT> fetcher = entry.getValue();\n        if (fetcher.isIdle()) {\n            LOG.info(\"Closing splitFetcher {} because it is idle.\", entry.getKey());\n            fetcher.shutdown();\n            iter.remove();\n        }\n    }\n    return fetchers.isEmpty();\n}", "summary_tokens": ["check", "and", "shutdown", "the", "fetchers", "that", "have", "completed", "their", "work"], "project": "flink"}
{"id": 4937, "code": "protected void initInputsSerializersAndComparators(int numInputs, int numComparators) {\n    this.inputSerializers = new TypeSerializerFactory<?>[numInputs];\n    this.inputComparators = numComparators > 0 ? new TypeComparator<?>[numComparators] : null;\n    this.inputIterators = new MutableObjectIterator<?>[numInputs];\n\n    ClassLoader userCodeClassLoader = getUserCodeClassLoader();\n\n    for (int i = 0; i < numInputs; i++) {\n\n        final TypeSerializerFactory<?> serializerFactory =\n                this.config.getInputSerializer(i, userCodeClassLoader);\n        this.inputSerializers[i] = serializerFactory;\n\n        this.inputIterators[i] =\n                createInputIterator(this.inputReaders[i], this.inputSerializers[i]);\n    }\n\n        \n    for (int i = 0; i < numComparators; i++) {\n\n        if (this.inputComparators != null) {\n            final TypeComparatorFactory<?> comparatorFactory =\n                    this.config.getDriverComparator(i, userCodeClassLoader);\n            this.inputComparators[i] = comparatorFactory.createComparator();\n        }\n    }\n}", "summary_tokens": ["creates", "all", "the", "serializers", "and", "comparators"], "project": "flink"}
{"id": 5793, "code": "public void testUntrackNonExistingBlob() {\n    tracker.untrack(Tuple2.of(jobId, BlobKey.createKey(BlobType.PERMANENT_BLOB)));\n    assertEquals(1, tracker.getBlobKeysByJobId(jobId).size());\n}", "summary_tokens": ["untracking", "a", "non", "existing", "blob", "shouldn", "t", "change", "anything", "or", "throw", "any", "exceptions"], "project": "flink"}
{"id": 5806, "code": "public void testSSLClientFailure() throws Exception {\n        \n    uploadJarFile(blobServer, sslClientConfig);\n}", "summary_tokens": ["verify", "ssl", "client", "to", "non", "ssl", "server", "failure"], "project": "flink"}
{"id": 6687, "code": "public CompletableFuture<Integer> getSystemExitFuture() {\n    return systemExitFuture;\n}", "summary_tokens": ["returns", "a", "completable", "future", "that", "is", "completed", "with", "the", "exit", "code", "when", "system", "exit", "int", "is", "called"], "project": "flink"}
{"id": 5567, "code": "public void clear() {\n    tasks.clear();\n}", "summary_tokens": ["removes", "all", "tasks", "from", "this", "task", "slot"], "project": "flink"}
{"id": 320, "code": "public static HiveConf create(Configuration conf) {\n    HiveConf hiveConf = new HiveConf(conf, HiveConf.class);\n        \n    hiveConf.addResource(conf);\n    return hiveConf;\n}", "summary_tokens": ["create", "hive", "conf", "instance", "via", "hadoop", "configuration"], "project": "flink"}
{"id": 3019, "code": "public <L, R> SingleOutputStreamOperator<Either<L, R>> select(\n        final PatternTimeoutFunction<T, L> patternTimeoutFunction,\n        final PatternSelectFunction<T, R> patternSelectFunction) {\n\n    final TypeInformation<R> mainTypeInfo =\n            TypeExtractor.getUnaryOperatorReturnType(\n                    patternSelectFunction,\n                    PatternSelectFunction.class,\n                    0,\n                    1,\n                    TypeExtractor.NO_INDEX,\n                    builder.getInputType(),\n                    null,\n                    false);\n\n    final TypeInformation<L> timeoutTypeInfo =\n            TypeExtractor.getUnaryOperatorReturnType(\n                    patternTimeoutFunction,\n                    PatternTimeoutFunction.class,\n                    0,\n                    1,\n                    TypeExtractor.NO_INDEX,\n                    builder.getInputType(),\n                    null,\n                    false);\n\n    final TypeInformation<Either<L, R>> outTypeInfo =\n            new EitherTypeInfo<>(timeoutTypeInfo, mainTypeInfo);\n\n    final OutputTag<L> outputTag =\n            new OutputTag<>(UUID.randomUUID().toString(), timeoutTypeInfo);\n\n    final PatternProcessFunction<T, R> processFunction =\n            fromSelect(builder.clean(patternSelectFunction))\n                    .withTimeoutHandler(outputTag, builder.clean(patternTimeoutFunction))\n                    .build();\n\n    final SingleOutputStreamOperator<R> mainStream = process(processFunction, mainTypeInfo);\n    final DataStream<L> timedOutStream = mainStream.getSideOutput(outputTag);\n\n    return mainStream.connect(timedOutStream).map(new CoMapTimeout<>()).returns(outTypeInfo);\n}", "summary_tokens": ["applies", "a", "select", "function", "to", "the", "detected", "pattern", "sequence"], "project": "flink"}
{"id": 7770, "code": "public void testClear() throws Exception {\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(\n                    CountTrigger.<TimeWindow>of(3), new TimeWindow.Serializer());\n\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n        \n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers());\n\n    assertEquals(2, testHarness.numStateEntries());\n    assertEquals(1, testHarness.numStateEntries(new TimeWindow(0, 2)));\n    assertEquals(1, testHarness.numStateEntries(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(2, 4));\n\n    assertEquals(1, testHarness.numStateEntries());\n    assertEquals(1, testHarness.numStateEntries(new TimeWindow(0, 2)));\n    assertEquals(0, testHarness.numStateEntries(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(0, 2));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numStateEntries(new TimeWindow(0, 2)));\n    assertEquals(0, testHarness.numStateEntries(new TimeWindow(2, 4)));\n}", "summary_tokens": ["verify", "that", "clear", "does", "not", "leak", "across", "windows"], "project": "flink"}
{"id": 2362, "code": "public synchronized String[] getPropertySources(String name) {\n    if (properties == null) {\n            \n            \n            \n        getProps();\n    }\n        \n        \n    if (properties == null || updatingResource == null) {\n        return null;\n    } else {\n        String[] source = updatingResource.get(name);\n        if (source == null) {\n            return null;\n        } else {\n            return Arrays.copyOf(source, source.length);\n        }\n    }\n}", "summary_tokens": ["gets", "information", "about", "why", "a", "property", "was", "set"], "project": "flink"}
{"id": 2406, "code": "public void skipFully(long bytes) throws IOException {\n    while (bytes > 0) {\n        bytes -= fsDataInputStream.skip(bytes);\n    }\n}", "summary_tokens": ["skips", "over", "a", "given", "amount", "of", "bytes", "in", "the", "stream"], "project": "flink"}
{"id": 5870, "code": "public void testTaskManagerFallbackBlobStorageDirectory2b() throws IOException {\n    Configuration config = new Configuration();\n    String blobStorageDirs =\n            temporaryFolder.newFolder().getAbsolutePath()\n                    + File.pathSeparator\n                    + temporaryFolder.newFolder().getAbsolutePath();\n    config.setString(CoreOptions.TMP_DIRS, blobStorageDirs);\n\n    File dir = BlobUtils.initLocalStorageDirectory(config);\n    assertThat(dir.getAbsolutePath(), startsWith(temporaryFolder.getRoot().getAbsolutePath()));\n}", "summary_tokens": ["tests", "blob", "utils", "init", "local", "storage", "directory", "s", "fallback", "to", "core", "options", "tmp", "dirs", "having", "multiple", "temp", "directories"], "project": "flink"}
{"id": 2457, "code": "public void testWriteSchema_withoutAutoRegistration_throwsException() throws IOException {\n    configs.put(AWSSchemaRegistryConstants.SCHEMA_AUTO_REGISTRATION_SETTING, false);\n    mockClient = new MockAWSSchemaRegistryClient();\n\n    GlueSchemaRegistrySerializationFacade glueSchemaRegistrySerializationFacade =\n            GlueSchemaRegistrySerializationFacade.builder()\n                    .schemaRegistryClient(mockClient)\n                    .credentialProvider(credentialsProvider)\n                    .glueSchemaRegistryConfiguration(\n                            new GlueSchemaRegistryConfiguration(configs))\n                    .build();\n\n    GlueSchemaRegistryOutputStreamSerializer glueSchemaRegistryOutputStreamSerializer =\n            new GlueSchemaRegistryOutputStreamSerializer(\n                    testTopic, configs, glueSchemaRegistrySerializationFacade);\n    GlueSchemaRegistryAvroSchemaCoder glueSchemaRegistryAvroSchemaCoder =\n            new GlueSchemaRegistryAvroSchemaCoder(glueSchemaRegistryOutputStreamSerializer);\n\n    thrown.expect(AWSSchemaRegistryException.class);\n    thrown.expectMessage(AWSSchemaRegistryConstants.AUTO_REGISTRATION_IS_DISABLED_MSG);\n    glueSchemaRegistryAvroSchemaCoder.writeSchema(userSchema, new ByteArrayOutputStream());\n}", "summary_tokens": ["test", "whether", "write", "schema", "method", "throws", "exception", "if", "auto", "registration", "un", "enabled"], "project": "flink"}
{"id": 8638, "code": "public static DecimalType findModuloDecimalType(\n        int precision1, int scale1, int precision2, int scale2) {\n    final int scale = Math.max(scale1, scale2);\n    int precision = Math.min(precision1 - scale1, precision2 - scale2) + scale;\n    return adjustPrecisionScale(precision, scale);\n}", "summary_tokens": ["finds", "the", "result", "type", "of", "a", "decimal", "modulo", "operation"], "project": "flink"}
{"id": 9236, "code": "private Optional<RowData> latestRightRowToJoin(List<RowData> rightRowsSorted, long leftTime) {\n    return latestRightRowToJoin(rightRowsSorted, 0, rightRowsSorted.size() - 1, leftTime);\n}", "summary_tokens": ["binary", "search", "right", "rows", "sorted", "to", "find", "the", "latest", "right", "row", "to", "join", "with", "left", "time"], "project": "flink"}
{"id": 6925, "code": "public void enableNumEntriesImmMemTables() {\n    this.properties.add(RocksDBProperty.NumEntriesImmMemTables.getRocksDBProperty());\n}", "summary_tokens": ["returns", "total", "number", "of", "entries", "in", "the", "unflushed", "immutable", "memtables"], "project": "flink"}
{"id": 6346, "code": "public void testHeapMetricUsageNotStatic() throws Exception {\n    final InterceptingOperatorMetricGroup heapMetrics = new InterceptingOperatorMetricGroup();\n\n    MetricUtils.instantiateHeapMemoryMetrics(heapMetrics);\n\n    @SuppressWarnings(\"unchecked\")\n    final Gauge<Long> used = (Gauge<Long>) heapMetrics.get(MetricNames.MEMORY_USED);\n\n    runUntilMetricChanged(\"Heap\", 10, () -> new byte[1024 * 1024 * 8], used);\n}", "summary_tokens": ["tests", "that", "heap", "non", "heap", "metrics", "do", "not", "rely", "on", "a", "static", "memory", "usage", "instance"], "project": "flink"}
{"id": 3905, "code": "public static RequestFailure deserializeRequestFailure(final ByteBuf buf)\n        throws IOException, ClassNotFoundException {\n    long requestId = buf.readLong();\n\n    Throwable cause;\n    try (ByteBufInputStream bis = new ByteBufInputStream(buf);\n            ObjectInputStream in = new ObjectInputStream(bis)) {\n        cause = (Throwable) in.readObject();\n    }\n    return new RequestFailure(requestId, cause);\n}", "summary_tokens": ["de", "serializes", "the", "request", "failure", "sent", "to", "the", "org"], "project": "flink"}
{"id": 2924, "code": "public void testMaxByKeyFieldsDataset() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    DataSet<Tuple5<Integer, Long, String, Long, Integer>> tupleDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo);\n\n        \n    try {\n        tupleDs.maxBy(4, 0, 1, 2, 3);\n    } catch (Exception e) {\n        Assert.fail();\n    }\n}", "summary_tokens": ["this", "test", "validates", "that", "no", "exceptions", "is", "thrown", "when", "an", "empty", "dataset", "calls", "max", "by"], "project": "flink"}
{"id": 2205, "code": "public void testSetPosition() throws Exception {\n    Assert.assertEquals(data.length, stream.available());\n    Assert.assertEquals('0', stream.read());\n\n    stream.setPosition(1);\n    Assert.assertEquals(data.length - 1, stream.available());\n    Assert.assertEquals('1', stream.read());\n\n    stream.setPosition(3);\n    Assert.assertEquals(data.length - 3, stream.available());\n    Assert.assertEquals('3', stream.read());\n\n    stream.setPosition(data.length);\n    Assert.assertEquals(0, stream.available());\n    Assert.assertEquals(-1, stream.read());\n}", "summary_tokens": ["test", "setting", "position", "on", "a", "byte", "array", "input", "stream", "with", "pos"], "project": "flink"}
{"id": 9044, "code": "public static String registerRowData(Seq<RowData> data) {\n    return registerRowData(JavaScalaConversionUtil.toJava(data));\n}", "summary_tokens": ["register", "the", "given", "internal", "row", "data", "into", "the", "data", "factory", "context", "and", "return", "the", "data", "id"], "project": "flink"}
{"id": 6582, "code": "public void testValueStateRace() throws Exception {\n    final Integer namespace = 1;\n\n    final ValueStateDescriptor<String> kvId = new ValueStateDescriptor<>(\"id\", String.class);\n\n    final TypeSerializer<Integer> keySerializer = IntSerializer.INSTANCE;\n    final TypeSerializer<Integer> namespaceSerializer = IntSerializer.INSTANCE;\n\n    final CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n    try {\n        final ValueState<String> state =\n                backend.getPartitionedState(namespace, IntSerializer.INSTANCE, kvId);\n\n            \n        final TypeSerializer<String> valueSerializer = kvId.getSerializer();\n\n        @SuppressWarnings(\"unchecked\")\n        final InternalKvState<Integer, Integer, String> kvState =\n                (InternalKvState<Integer, Integer, String>) state;\n\n            \n\n            \n        final int key1 = 1;\n        backend.setCurrentKey(key1);\n        kvState.setCurrentNamespace(2);\n        state.update(\"2\");\n        assertEquals(\"2\", state.value());\n\n            \n        assertNull(\n                getSerializedValue(\n                        kvState,\n                        3,\n                        keySerializer,\n                        namespace,\n                        IntSerializer.INSTANCE,\n                        valueSerializer));\n\n            \n        assertEquals(\"2\", state.value());\n\n            \n        kvState.setCurrentNamespace(namespace);\n\n            \n\n            \n        final int key2 = 10;\n        backend.setCurrentKey(key2);\n        assertNull(state.value());\n        assertNull(\n                getSerializedValue(\n                        kvState,\n                        key2,\n                        keySerializer,\n                        namespace,\n                        namespaceSerializer,\n                        valueSerializer));\n        state.update(\"1\");\n\n        final CheckedThread getter =\n                new CheckedThread(\"State getter\") {\n                    @Override\n                    public void go() throws Exception {\n                        while (!isInterrupted()) {\n                            assertEquals(\"1\", state.value());\n                        }\n                    }\n                };\n\n        final CheckedThread serializedGetter =\n                new CheckedThread(\"Serialized state getter\") {\n                    @Override\n                    public void go() throws Exception {\n                        while (!isInterrupted() && getter.isAlive()) {\n                            final String serializedValue =\n                                    getSerializedValue(\n                                            kvState,\n                                            key2,\n                                            keySerializer,\n                                            namespace,\n                                            namespaceSerializer,\n                                            valueSerializer);\n                            assertEquals(\"1\", serializedValue);\n                        }\n                    }\n                };\n\n        getter.start();\n        serializedGetter.start();\n\n            \n        Timer t = new Timer(\"stopper\");\n        t.schedule(\n                new TimerTask() {\n                    @Override\n                    public void run() {\n                        getter.interrupt();\n                        serializedGetter.interrupt();\n                        this.cancel();\n                    }\n                },\n                100);\n\n            \n            \n            \n        serializedGetter.sync();\n            \n        getter.interrupt();\n        getter.sync();\n        t.cancel(); \n    } finally {\n            \n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["tests", "value", "state", "value", "and", "internal", "kv", "state", "get", "serialized", "value", "byte", "type", "serializer", "type", "serializer", "type", "serializer", "accessing", "the", "state", "concurrently"], "project": "flink"}
{"id": 919, "code": "static StartCursor fromMessageId(MessageId messageId, boolean inclusive) {\n    return new MessageIdStartCursor(messageId, inclusive);\n}", "summary_tokens": ["message", "id", "find", "the", "available", "message", "id", "and", "start", "consuming", "from", "it"], "project": "flink"}
{"id": 1201, "code": "protected static <U> Class<U>[] asArray(Class<U> clazz) {\n    @SuppressWarnings(\"unchecked\")\n    Class<U>[] array = new Class[] {clazz};\n    return array;\n}", "summary_tokens": ["generic", "utility", "function", "that", "wraps", "a", "single", "class", "object", "into", "an", "array", "of", "that", "class", "type"], "project": "flink"}
{"id": 6450, "code": "public void testTaskManagerRegistrationDeductPendingTaskManager() throws Exception {\n    final TaskExecutorConnection taskExecutionConnection1 = createTaskExecutorConnection();\n    final TaskExecutorConnection taskExecutionConnection2 = createTaskExecutorConnection();\n    final TaskExecutorConnection taskExecutionConnection3 = createTaskExecutorConnection();\n    final SlotReport slotReportWithAllocatedSlot =\n            new SlotReport(\n                    createAllocatedSlotStatus(\n                            new AllocationID(), DEFAULT_SLOT_RESOURCE_PROFILE));\n    new Context() {\n        {\n            runTest(\n                    () -> {\n                        final CompletableFuture<Boolean> registerTaskManagerFuture1 =\n                                new CompletableFuture<>();\n                        final CompletableFuture<Boolean> registerTaskManagerFuture2 =\n                                new CompletableFuture<>();\n                        final CompletableFuture<Boolean> registerTaskManagerFuture3 =\n                                new CompletableFuture<>();\n                        runInMainThread(\n                                () -> {\n                                    getTaskManagerTracker()\n                                            .addPendingTaskManager(\n                                                    new PendingTaskManager(\n                                                            DEFAULT_TOTAL_RESOURCE_PROFILE,\n                                                            DEFAULT_NUM_SLOTS_PER_WORKER));\n                                        \n                                        \n                                    registerTaskManagerFuture1.complete(\n                                            getSlotManager()\n                                                    .registerTaskManager(\n                                                            taskExecutionConnection1,\n                                                            slotReportWithAllocatedSlot,\n                                                            DEFAULT_TOTAL_RESOURCE_PROFILE,\n                                                            DEFAULT_SLOT_RESOURCE_PROFILE));\n                                });\n\n                        assertThat(\n                                assertFutureCompleteAndReturn(registerTaskManagerFuture1),\n                                is(true));\n                        assertThat(\n                                getTaskManagerTracker().getPendingTaskManagers().size(), is(1));\n\n                            \n                            \n                        runInMainThread(\n                                () ->\n                                        registerTaskManagerFuture2.complete(\n                                                getSlotManager()\n                                                        .registerTaskManager(\n                                                                taskExecutionConnection2,\n                                                                new SlotReport(),\n                                                                LARGE_TOTAL_RESOURCE_PROFILE,\n                                                                LARGE_SLOT_RESOURCE_PROFILE)));\n\n                        assertThat(\n                                assertFutureCompleteAndReturn(registerTaskManagerFuture2),\n                                is(true));\n                        assertThat(\n                                getTaskManagerTracker().getPendingTaskManagers().size(), is(1));\n\n                        runInMainThread(\n                                () ->\n                                        registerTaskManagerFuture3.complete(\n                                                getSlotManager()\n                                                        .registerTaskManager(\n                                                                taskExecutionConnection3,\n                                                                new SlotReport(),\n                                                                DEFAULT_TOTAL_RESOURCE_PROFILE,\n                                                                DEFAULT_SLOT_RESOURCE_PROFILE)));\n                        assertThat(\n                                assertFutureCompleteAndReturn(registerTaskManagerFuture3),\n                                is(true));\n                        assertThat(\n                                getTaskManagerTracker().getPendingTaskManagers().size(), is(0));\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "that", "we", "can", "matched", "task", "manager", "will", "deduct", "pending", "task", "manager"], "project": "flink"}
{"id": 1992, "code": "public static <T> void applyToAllWhileSuppressingExceptions(\n        Iterable<T> inputs, ThrowingConsumer<T, ? extends Exception> throwingConsumer)\n        throws Exception {\n\n    if (inputs != null && throwingConsumer != null) {\n        Exception exception = null;\n\n        for (T input : inputs) {\n\n            if (input != null) {\n                try {\n                    throwingConsumer.accept(input);\n                } catch (Exception ex) {\n                    exception = ExceptionUtils.firstOrSuppressed(ex, exception);\n                }\n            }\n        }\n\n        if (exception != null) {\n            throw exception;\n        }\n    }\n}", "summary_tokens": ["this", "method", "supplies", "all", "elements", "from", "the", "input", "to", "the", "consumer"], "project": "flink"}
{"id": 4873, "code": "public JobsOverview combine(JobsOverview jobsOverview) {\n    return new JobsOverview(this, jobsOverview);\n}", "summary_tokens": ["combines", "the", "given", "jobs", "overview", "with", "this"], "project": "flink"}
{"id": 6107, "code": "public void testSimpleClose() throws Exception {\n    final String rootPath = \"/foo/bar/flink\";\n    final Configuration configuration = createConfiguration(rootPath);\n\n    final TestingBlobStoreService blobStoreService = new TestingBlobStoreService();\n\n    runCleanupTest(configuration, blobStoreService, ZooKeeperHaServices::close);\n\n    assertThat(blobStoreService.isClosed(), is(true));\n    assertThat(blobStoreService.isClosedAndCleanedUpAllData(), is(false));\n\n    final List<String> children = client.getChildren().forPath(rootPath);\n    assertThat(children, is(not(empty())));\n}", "summary_tokens": ["tests", "that", "a", "simple", "zoo", "keeper", "ha", "services", "close", "does", "not", "delete", "zoo", "keeper", "paths"], "project": "flink"}
{"id": 4495, "code": "public MemorySegment getNextReturnedBlock() throws IOException {\n    try {\n        while (true) {\n            final MemorySegment next = this.returnSegments.poll(1000, TimeUnit.MILLISECONDS);\n            if (next != null) {\n                return next;\n            } else {\n                if (this.closed) {\n                    throw new IOException(\"The reader has been asynchronously closed.\");\n                }\n                checkErroneous();\n            }\n        }\n    } catch (InterruptedException iex) {\n        throw new IOException(\n                \"Reader was interrupted while waiting for the next returning segment.\");\n    }\n}", "summary_tokens": ["gets", "the", "next", "memory", "segment", "that", "has", "been", "filled", "with", "data", "by", "the", "reader"], "project": "flink"}
{"id": 7669, "code": "public void testProcessingTimeTimerWithState() throws Exception {\n\n    KeyedProcessOperator<Integer, Integer, String> operator =\n            new KeyedProcessOperator<>(\n                    new TriggeringStatefulFlatMapFunction(TimeDomain.PROCESSING_TIME));\n\n    OneInputStreamOperatorTestHarness<Integer, String> testHarness =\n            new KeyedOneInputStreamOperatorTestHarness<>(\n                    operator, new IdentityKeySelector<Integer>(), BasicTypeInfo.INT_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.setProcessingTime(1);\n    testHarness.processElement(new StreamRecord<>(17)); \n    testHarness.processElement(new StreamRecord<>(13)); \n\n    testHarness.setProcessingTime(2);\n    testHarness.processElement(new StreamRecord<>(13)); \n    testHarness.processElement(new StreamRecord<>(42)); \n\n    testHarness.setProcessingTime(6);\n    testHarness.setProcessingTime(7);\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    expectedOutput.add(new StreamRecord<>(\"INPUT:17\"));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:13\"));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:42\"));\n    expectedOutput.add(new StreamRecord<>(\"STATE:17\"));\n    expectedOutput.add(new StreamRecord<>(\"STATE:42\"));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.close();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "leakage", "between", "different", "keys"], "project": "flink"}
{"id": 6774, "code": "static int compareNamespaceAndNode(\n        MemorySegment namespaceSegment,\n        int namespaceOffset,\n        int namespaceLen,\n        MemorySegment nodeSegment,\n        int nodeKeyOffset) {\n\n    int nodeNamespaceLen = nodeSegment.getInt(nodeKeyOffset);\n    return namespaceSegment.compare(\n            nodeSegment,\n            namespaceOffset,\n            nodeKeyOffset + Integer.BYTES,\n            namespaceLen,\n            nodeNamespaceLen);\n}", "summary_tokens": ["compares", "the", "namespace", "in", "the", "memory", "segment", "with", "the", "namespace", "in", "the", "node"], "project": "flink"}
{"id": 2563, "code": "public static org.apache.flink.table.data.columnar.vector.ColumnVector\n        createFlinkVectorFromConstant(LogicalType type, Object value, int batchSize) {\n    return createFlinkVector(createHiveVectorFromConstant(type, value, batchSize));\n}", "summary_tokens": ["create", "flink", "vector", "by", "hive", "vector", "from", "constant"], "project": "flink"}
{"id": 8861, "code": "public static HintStrategyTable createHintStrategyTable() {\n    return HintStrategyTable.builder()\n                \n                \n            .errorHandler(Litmus.THROW)\n            .hintStrategy(\n                    FlinkHints.HINT_NAME_OPTIONS,\n                    HintStrategy.builder(HintPredicates.TABLE_SCAN)\n                            .optionChecker(\n                                    (hint, errorHandler) ->\n                                            errorHandler.check(\n                                                    hint.kvOptions.size() > 0,\n                                                    \"Hint [{}] only support non empty key value options\",\n                                                    hint.hintName))\n                            .build())\n            .hintStrategy(\n                    FlinkHints.HINT_NAME_JSON_AGGREGATE_WRAPPED,\n                    HintStrategy.builder(HintPredicates.AGGREGATE)\n                            .excludedRules(WrapJsonAggFunctionArgumentsRule.INSTANCE)\n                            .build())\n            .build();\n}", "summary_tokens": ["customize", "the", "hint", "strategy", "table", "which", "contains", "hint", "strategies", "supported", "by", "flink"], "project": "flink"}
{"id": 2303, "code": "private static void genRanks(int noDocs, String path) {\n\n    Random rand = new Random(Calendar.getInstance().getTimeInMillis());\n\n    try (BufferedWriter fw = new BufferedWriter(new FileWriter(path))) {\n        for (int i = 0; i < noDocs; i++) {\n                \n            StringBuilder rank = new StringBuilder(rand.nextInt(100) + \"|\");\n                \n            rank.append(\"url_\" + i + \"|\");\n                \n            rank.append(rand.nextInt(10) + rand.nextInt(50) + \"|\\n\");\n\n            fw.write(rank.toString());\n        }\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n}", "summary_tokens": ["generates", "the", "files", "for", "the", "ranks", "relation"], "project": "flink"}
{"id": 5820, "code": "private void testContentAddressableStream(BlobKey.BlobType blobType)\n        throws IOException, InterruptedException {\n\n    File testFile = temporaryFolder.newFile();\n    byte[] digest = prepareTestFile(testFile);\n\n    InputStream is = null;\n\n    try (BlobClient client =\n            new BlobClient(\n                    new InetSocketAddress(\"localhost\", getBlobServer().getPort()),\n                    getBlobClientConfig())) {\n\n        JobID jobId = new JobID();\n        BlobKey receivedKey1 = null;\n\n            \n        if (blobType == TRANSIENT_BLOB) {\n            is = new FileInputStream(testFile);\n            receivedKey1 = client.putInputStream(null, is, blobType);\n            assertArrayEquals(digest, receivedKey1.getHash());\n        }\n\n            \n        is = new FileInputStream(testFile);\n        BlobKey receivedKey2 = client.putInputStream(jobId, is, blobType);\n\n        is.close();\n        is = null;\n\n            \n        if (blobType == TRANSIENT_BLOB) {\n            verifyKeyDifferentHashEquals(receivedKey1, receivedKey2);\n\n            validateGetAndClose(client.getInternal(null, receivedKey1), testFile);\n                \n            verifyDeletedEventually(getBlobServer(), null, receivedKey1);\n        }\n            \n        validateGetAndClose(client.getInternal(jobId, receivedKey2), testFile);\n        if (blobType == TRANSIENT_BLOB) {\n                \n            verifyDeletedEventually(getBlobServer(), jobId, receivedKey2);\n        }\n    } finally {\n        if (is != null) {\n            try {\n                is.close();\n            } catch (Throwable ignored) {\n            }\n        }\n    }\n}", "summary_tokens": ["tests", "the", "put", "get", "operations", "for", "content", "addressable", "streams"], "project": "flink"}
{"id": 9538, "code": "public MetricGroup getMetricGroup() {\n    return this.rootMetricGroup;\n}", "summary_tokens": ["get", "the", "root", "metric", "group", "of", "this", "listener"], "project": "flink"}
{"id": 2326, "code": "public void addResource(Configuration conf) {\n    addResourceObject(new Resource(conf.getProps(), conf.restrictSystemProps));\n}", "summary_tokens": ["add", "a", "configuration", "resource"], "project": "flink"}
{"id": 5660, "code": "public static LeaderConnectionInfo retrieveLeaderConnectionInfo(\n        LeaderRetrievalService leaderRetrievalService, Duration timeout)\n        throws LeaderRetrievalException {\n\n    LeaderConnectionInfoListener listener = new LeaderConnectionInfoListener();\n\n    try {\n        leaderRetrievalService.start(listener);\n\n        return listener.getLeaderConnectionInfoFuture()\n                .get(timeout.toMillis(), TimeUnit.MILLISECONDS);\n    } catch (Exception e) {\n        throw new LeaderRetrievalException(\n                \"Could not retrieve the leader address and leader \" + \"session ID.\", e);\n    } finally {\n        try {\n            leaderRetrievalService.stop();\n        } catch (Exception fe) {\n            LOG.warn(\"Could not stop the leader retrieval service.\", fe);\n        }\n    }\n}", "summary_tokens": ["retrieves", "the", "leader", "akka", "url", "and", "the", "current", "leader", "session", "id"], "project": "flink"}
{"id": 7199, "code": "public boolean isExternalizedCheckpointsEnabled() {\n    return externalizedCheckpointCleanup\n            != ExternalizedCheckpointCleanup.NO_EXTERNALIZED_CHECKPOINTS;\n}", "summary_tokens": ["returns", "whether", "checkpoints", "should", "be", "persisted", "externally"], "project": "flink"}
{"id": 3919, "code": "public void testServerClosesChannel() throws Exception {\n    AtomicKvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n    final MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    Client<KvStateInternalRequest, KvStateResponse> client = null;\n    Channel serverChannel = null;\n\n    try {\n        client = new Client<>(\"Test Client\", 1, serializer, stats);\n\n        final LinkedBlockingQueue<ByteBuf> received = new LinkedBlockingQueue<>();\n        final AtomicReference<Channel> channel = new AtomicReference<>();\n\n        serverChannel =\n                createServerChannel(new ChannelDataCollectingHandler(channel, received));\n\n        InetSocketAddress serverAddress = getKvStateServerAddress(serverChannel);\n\n            \n        KvStateInternalRequest request =\n                new KvStateInternalRequest(new KvStateID(), new byte[0]);\n        Future<KvStateResponse> future = client.sendRequest(serverAddress, request);\n\n        received.take();\n\n        assertEquals(1, stats.getNumConnections());\n\n        channel.get().close().await();\n\n        try {\n            future.get();\n            fail(\"Did not throw expected server failure\");\n        } catch (ExecutionException e) {\n            if (!(e.getCause() instanceof ClosedChannelException)) {\n                fail(\"Did not throw expected Exception\");\n            }\n                \n        }\n\n        assertEquals(0L, stats.getNumConnections());\n\n            \n        while (stats.getNumSuccessful() != 0L || stats.getNumFailed() != 1L) {\n            Thread.sleep(100L);\n        }\n\n        assertEquals(1L, stats.getNumRequests());\n        assertEquals(0L, stats.getNumSuccessful());\n        assertEquals(1L, stats.getNumFailed());\n    } finally {\n        if (client != null) {\n            try {\n                client.shutdown().get();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            Assert.assertTrue(client.isEventGroupShutdown());\n        }\n\n        if (serverChannel != null) {\n            serverChannel.close();\n        }\n\n        assertEquals(\"Channel leak\", 0L, stats.getNumConnections());\n    }\n}", "summary_tokens": ["tests", "that", "a", "server", "channel", "close", "closes", "the", "connection", "and", "removes", "it", "from", "the", "established", "connections"], "project": "flink"}
{"id": 7615, "code": "public void testKeyedStreamProcessTranslation() {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    DataStreamSource<Long> src = env.generateSequence(0, 0);\n\n    ProcessFunction<Long, Integer> processFunction =\n            new ProcessFunction<Long, Integer>() {\n                private static final long serialVersionUID = 1L;\n\n                @Override\n                public void processElement(Long value, Context ctx, Collector<Integer> out)\n                        throws Exception {\n                        \n                }\n\n                @Override\n                public void onTimer(long timestamp, OnTimerContext ctx, Collector<Integer> out)\n                        throws Exception {\n                        \n                }\n            };\n\n    DataStream<Integer> processed =\n            src.keyBy(new IdentityKeySelector<Long>()).process(processFunction);\n\n    processed.addSink(new DiscardingSink<Integer>());\n\n    assertEquals(processFunction, getFunctionForDataStream(processed));\n    assertTrue(getOperatorForDataStream(processed) instanceof LegacyKeyedProcessOperator);\n}", "summary_tokens": ["verify", "that", "a", "keyed", "stream", "process", "process", "function", "call", "is", "correctly", "translated", "to", "an", "operator"], "project": "flink"}
{"id": 1493, "code": "public void setFields(\n        T0 f0,\n        T1 f1,\n        T2 f2,\n        T3 f3,\n        T4 f4,\n        T5 f5,\n        T6 f6,\n        T7 f7,\n        T8 f8,\n        T9 f9,\n        T10 f10,\n        T11 f11,\n        T12 f12,\n        T13 f13,\n        T14 f14,\n        T15 f15,\n        T16 f16,\n        T17 f17) {\n    this.f0 = f0;\n    this.f1 = f1;\n    this.f2 = f2;\n    this.f3 = f3;\n    this.f4 = f4;\n    this.f5 = f5;\n    this.f6 = f6;\n    this.f7 = f7;\n    this.f8 = f8;\n    this.f9 = f9;\n    this.f10 = f10;\n    this.f11 = f11;\n    this.f12 = f12;\n    this.f13 = f13;\n    this.f14 = f14;\n    this.f15 = f15;\n    this.f16 = f16;\n    this.f17 = f17;\n}", "summary_tokens": ["sets", "new", "values", "to", "all", "fields", "of", "the", "tuple"], "project": "flink"}
{"id": 3343, "code": "public void preSuperstep() throws Exception {}", "summary_tokens": ["this", "method", "is", "executed", "once", "per", "superstep", "before", "the", "gather", "function", "is", "invoked", "for", "each", "vertex"], "project": "flink"}
{"id": 4226, "code": "private void checkTasksStarted(List<Execution> toTrigger) throws CheckpointException {\n    for (Execution execution : toTrigger) {\n        if (execution.getState() != ExecutionState.RUNNING) {\n            throw new CheckpointException(\n                    String.format(\n                            \"Checkpoint triggering task %s of job %s is not being executed at the moment. \"\n                                    + \"Aborting checkpoint.\",\n                            execution.getVertex().getTaskNameWithSubtaskIndex(), jobId),\n                    CheckpointFailureReason.NOT_ALL_REQUIRED_TASKS_RUNNING);\n        }\n    }\n}", "summary_tokens": ["checks", "if", "all", "tasks", "to", "trigger", "have", "already", "been", "in", "running", "state"], "project": "flink"}
{"id": 3364, "code": "public long getOutDegree() {\n    return outDegree;\n}", "summary_tokens": ["retrieve", "the", "vertex", "out", "degree", "number", "of", "out", "going", "edges"], "project": "flink"}
{"id": 5913, "code": "public void testModifySnapshot() throws Exception {\n    CheckpointStatsHistory history = new CheckpointStatsHistory(3);\n\n    history.addInProgressCheckpoint(createPendingCheckpointStats(0));\n    history.addInProgressCheckpoint(createPendingCheckpointStats(1));\n    history.addInProgressCheckpoint(createPendingCheckpointStats(2));\n\n    CheckpointStatsHistory snapshot = history.createSnapshot();\n\n    try {\n        snapshot.addInProgressCheckpoint(createPendingCheckpointStats(4));\n        fail(\"Did not throw expected Exception\");\n    } catch (UnsupportedOperationException ignored) {\n    }\n\n    try {\n        snapshot.replacePendingCheckpointById(createCompletedCheckpointStats(2));\n        fail(\"Did not throw expected Exception\");\n    } catch (UnsupportedOperationException ignored) {\n    }\n\n    try {\n        snapshot.createSnapshot();\n        fail(\"Did not throw expected Exception\");\n    } catch (UnsupportedOperationException ignored) {\n    }\n}", "summary_tokens": ["tests", "that", "a", "snapshot", "cannot", "be", "modified", "or", "copied"], "project": "flink"}
{"id": 7932, "code": "public void executeInInteractiveMode() {\n    try {\n        terminal = terminalFactory.get();\n        executeInteractive();\n    } finally {\n        closeTerminal();\n    }\n}", "summary_tokens": ["opens", "the", "interactive", "cli", "shell"], "project": "flink"}
{"id": 5850, "code": "public void testServerContentAddressableGetStorageLocationConcurrentNoJob() throws Exception {\n    testServerContentAddressableGetStorageLocationConcurrent(null);\n}", "summary_tokens": ["tests", "concurrent", "calls", "to", "blob", "server", "get", "storage", "location", "job", "id", "blob", "key"], "project": "flink"}
{"id": 6513, "code": "public void testNotRunningState()\n        throws InterruptedException, ExecutionException, TimeoutException {\n    CompletableFuture<Void> stopFuture = new CompletableFuture<>();\n    RunningStateTestingEndpoint endpoint =\n            new RunningStateTestingEndpoint(rpcService, stopFuture);\n    RunningStateTestingEndpointGateway gateway =\n            endpoint.getSelfGateway(RunningStateTestingEndpointGateway.class);\n\n    endpoint.start();\n    CompletableFuture<Void> terminationFuture = endpoint.closeAndWaitUntilOnStopCalled();\n\n    assertThat(gateway.queryIsRunningFlag().get(), is(false));\n\n    stopFuture.complete(null);\n    terminationFuture.get(TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["tests", "that", "the", "rpc", "is", "not", "running", "if", "it", "is", "being", "stopped"], "project": "flink"}
{"id": 2934, "code": "public void testMaxByRowTypeInfoKeyFieldsDataset() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    TypeInformation[] types = new TypeInformation[] {Types.INT, Types.INT};\n\n    String[] fieldNames = new String[] {\"id\", \"value\"};\n    RowTypeInfo rowTypeInfo = new RowTypeInfo(types, fieldNames);\n    DataSet tupleDs = env.fromCollection(Collections.singleton(new Row(2)), rowTypeInfo);\n\n    tupleDs.maxBy(0);\n}", "summary_tokens": ["validates", "that", "no", "class", "cast", "exception", "happens", "should", "not", "fail", "e"], "project": "flink"}
{"id": 2230, "code": "public void testRetryFailureFixedRetries() throws Throwable {\n    final int retries = 3;\n\n    CompletableFuture<?> retryFuture =\n            FutureUtils.retry(\n                    () ->\n                            FutureUtils.completedExceptionally(\n                                    new FlinkException(\"Test exception\")),\n                    retries,\n                    TestingUtils.defaultExecutor());\n\n    try {\n        retryFuture.get();\n    } catch (ExecutionException ee) {\n        throw ExceptionUtils.stripExecutionException(ee);\n    }\n}", "summary_tokens": ["tests", "that", "a", "retry", "future", "is", "failed", "after", "all", "retries", "have", "been", "consumed"], "project": "flink"}
{"id": 5314, "code": "public static SecurityContextFactory findContextFactory(String securityContextFactoryClass)\n        throws NoMatchSecurityFactoryException {\n    return findFactoryInternal(\n            securityContextFactoryClass,\n            SecurityContextFactory.class,\n            SecurityContextFactory.class.getClassLoader());\n}", "summary_tokens": ["find", "a", "suitable", "security", "context", "factory", "based", "on", "canonical", "name"], "project": "flink"}
{"id": 7108, "code": "public <R> SingleOutputStreamOperator<R> process(\n        KeyedProcessFunction<KEY, T, R> keyedProcessFunction, TypeInformation<R> outputType) {\n\n    KeyedProcessOperator<KEY, T, R> operator =\n            new KeyedProcessOperator<>(clean(keyedProcessFunction));\n    return transform(\"KeyedProcess\", outputType, operator);\n}", "summary_tokens": ["applies", "the", "given", "keyed", "process", "function", "on", "the", "input", "stream", "thereby", "creating", "a", "transformed", "output", "stream"], "project": "flink"}
{"id": 3578, "code": "public void addHeuristicNetworkCost(double cost) {\n    if (cost <= 0) {\n        throw new IllegalArgumentException(\"Heuristic costs must be positive.\");\n    }\n    this.heuristicNetworkCost += cost;\n        \n    if (this.heuristicNetworkCost < 0) {\n        this.heuristicNetworkCost = Double.MAX_VALUE;\n    }\n}", "summary_tokens": ["adds", "the", "heuristic", "costs", "for", "network", "to", "the", "current", "heuristic", "network", "costs", "for", "this", "costs", "object"], "project": "flink"}
{"id": 9766, "code": "public void testRestPortSpecified() throws IOException {\n    final Configuration initialConfiguration = new Configuration();\n    final int port = 1337;\n    initialConfiguration.setInteger(RestOptions.PORT, port);\n\n    final Configuration configuration = loadConfiguration(initialConfiguration);\n\n        \n    assertThat(\n            configuration.getString(RestOptions.BIND_PORT), is(equalTo(String.valueOf(port))));\n}", "summary_tokens": ["tests", "that", "the", "binding", "rest", "port", "is", "set", "to", "the", "rest", "port", "if", "set"], "project": "flink"}
{"id": 7809, "code": "public void testRestoreSessionWindowsWithCountTriggerInMintCondition() throws Exception {\n\n    final int sessionSize = 3;\n\n    ListStateDescriptor<Tuple2<String, Integer>> stateDesc =\n            new ListStateDescriptor<>(\n                    \"window-contents\",\n                    STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n    WindowOperator<\n                    String,\n                    Tuple2<String, Integer>,\n                    Iterable<Tuple2<String, Integer>>,\n                    Tuple3<String, Long, Long>,\n                    TimeWindow>\n            operator =\n                    new WindowOperator<>(\n                            EventTimeSessionWindows.withGap(Time.seconds(sessionSize)),\n                            new TimeWindow.Serializer(),\n                            new TupleKeySelector<String>(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()),\n                            stateDesc,\n                            new InternalIterableWindowFunction<>(new SessionWindowFunction()),\n                            PurgingTrigger.of(CountTrigger.of(4)),\n                            0,\n                            null );\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple3<String, Long, Long>>\n            testHarness =\n                    new KeyedOneInputStreamOperatorTestHarness<>(\n                            operator, new TupleKeySelector<>(), BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n\n    testHarness.initializeState(\n            OperatorSnapshotUtil.getResourceFilename(\n                    \"win-op-migration-test-session-with-stateful-trigger-mint-flink\"\n                            + testMigrateVersion\n                            + \"-snapshot\"));\n\n    testHarness.open();\n\n        \n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 0));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 2), 1000));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 3), 2500));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 4), 3500));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 10));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 2), 1000));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 3), 2500));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 6000));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 2), 6500));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 3), 7000));\n\n    expectedOutput.add(new StreamRecord<>(new Tuple3<>(\"key2-10\", 0L, 6500L), 6499));\n\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new Tuple3ResultSortComparator());\n\n        \n        \n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 10), 4500));\n\n    expectedOutput.add(new StreamRecord<>(new Tuple3<>(\"key1-22\", 10L, 10000L), 9999L));\n\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new Tuple3ResultSortComparator());\n\n    testHarness.close();\n}", "summary_tokens": ["this", "checks", "that", "we", "can", "restore", "from", "a", "virgin", "window", "operator", "that", "has", "never", "seen", "any", "elements"], "project": "flink"}
{"id": 685, "code": "public void runAutoOffsetRetrievalAndCommitToKafka() throws Exception {\n        \n        \n    final int parallelism = 3;\n    final int recordsInEachPartition = 50;\n\n    final String topicName =\n            writeSequence(\n                    \"testAutoOffsetRetrievalAndCommitToKafkaTopic\",\n                    recordsInEachPartition,\n                    parallelism,\n                    1);\n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.getConfig().setRestartStrategy(RestartStrategies.noRestart());\n    env.setParallelism(parallelism);\n    env.enableCheckpointing(200);\n\n    Properties readProps = new Properties();\n    readProps.putAll(standardProps);\n    readProps.setProperty(\n            \"auto.offset.reset\",\n            \"latest\"); \n\n    DataStream<String> stream = getStream(env, topicName, new SimpleStringSchema(), readProps);\n    stream.addSink(new DiscardingSink<String>());\n\n    final AtomicReference<Throwable> errorRef = new AtomicReference<>();\n    final Thread runner =\n            new Thread(\"runner\") {\n                @Override\n                public void run() {\n                    try {\n                        env.execute();\n                    } catch (Throwable t) {\n                        if (!(t instanceof JobCancellationException)) {\n                            errorRef.set(t);\n                        }\n                    }\n                }\n            };\n    runner.start();\n\n    KafkaTestEnvironment.KafkaOffsetHandler kafkaOffsetHandler =\n            kafkaServer.createOffsetHandler();\n\n    final Long l50 = 50L; \n    final long deadline = 30_000_000_000L + System.nanoTime();\n    do {\n        Long o1 = kafkaOffsetHandler.getCommittedOffset(topicName, 0);\n        Long o2 = kafkaOffsetHandler.getCommittedOffset(topicName, 1);\n        Long o3 = kafkaOffsetHandler.getCommittedOffset(topicName, 2);\n\n        if (l50.equals(o1) && l50.equals(o2) && l50.equals(o3)) {\n            break;\n        }\n\n        Thread.sleep(100);\n    } while (System.nanoTime() < deadline);\n\n        \n    client.cancel(Iterables.getOnlyElement(getRunningJobs(client))).get();\n    runner.join();\n\n    final Throwable t = errorRef.get();\n    if (t != null) {\n        throw new RuntimeException(\"Job failed with an exception\", t);\n    }\n\n        \n    Long o1 = kafkaOffsetHandler.getCommittedOffset(topicName, 0);\n    Long o2 = kafkaOffsetHandler.getCommittedOffset(topicName, 1);\n    Long o3 = kafkaOffsetHandler.getCommittedOffset(topicName, 2);\n    Assert.assertEquals(Long.valueOf(50L), o1);\n    Assert.assertEquals(Long.valueOf(50L), o2);\n    Assert.assertEquals(Long.valueOf(50L), o3);\n\n    kafkaOffsetHandler.close();\n    deleteTestTopic(topicName);\n}", "summary_tokens": ["this", "test", "ensures", "that", "when", "the", "consumers", "retrieve", "some", "start", "offset", "from", "kafka", "earliest", "latest", "that", "this", "offset", "is", "committed", "to", "kafka", "even", "if", "some", "partitions", "are", "not", "read"], "project": "flink"}
{"id": 3785, "code": "public void testResourcesForDeltaIteration() throws Exception {\n    ResourceSpec resource1 = ResourceSpec.newBuilder(0.1, 100).build();\n    ResourceSpec resource2 = ResourceSpec.newBuilder(0.2, 200).build();\n    ResourceSpec resource3 = ResourceSpec.newBuilder(0.3, 300).build();\n    ResourceSpec resource4 = ResourceSpec.newBuilder(0.4, 400).build();\n    ResourceSpec resource5 = ResourceSpec.newBuilder(0.5, 500).build();\n    ResourceSpec resource6 = ResourceSpec.newBuilder(0.6, 600).build();\n\n    Method opMethod = Operator.class.getDeclaredMethod(\"setResources\", ResourceSpec.class);\n    opMethod.setAccessible(true);\n\n    Method deltaMethod =\n            DeltaIteration.class.getDeclaredMethod(\"setResources\", ResourceSpec.class);\n    deltaMethod.setAccessible(true);\n\n    Method sinkMethod = DataSink.class.getDeclaredMethod(\"setResources\", ResourceSpec.class);\n    sinkMethod.setAccessible(true);\n\n    MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>> mapFunction =\n            new MapFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>() {\n                @Override\n                public Tuple2<Long, Long> map(Tuple2<Long, Long> value) throws Exception {\n                    return value;\n                }\n            };\n\n    FilterFunction<Tuple2<Long, Long>> filterFunction =\n            new FilterFunction<Tuple2<Long, Long>>() {\n                @Override\n                public boolean filter(Tuple2<Long, Long> value) throws Exception {\n                    return false;\n                }\n            };\n\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n    DataSet<Tuple2<Long, Long>> input = env.fromElements(new Tuple2<>(1L, 2L));\n    opMethod.invoke(input, resource1);\n\n        \n    DataSet<Tuple2<Long, Long>> map = input.map(mapFunction);\n    opMethod.invoke(map, resource2);\n\n    DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> iteration =\n            map.iterateDelta(map, 100, 0).registerAggregator(\"test\", new LongSumAggregator());\n    deltaMethod.invoke(iteration, resource3);\n\n    DataSet<Tuple2<Long, Long>> delta = iteration.getWorkset().map(mapFunction);\n    opMethod.invoke(delta, resource4);\n\n    DataSet<Tuple2<Long, Long>> feedback = delta.filter(filterFunction);\n    opMethod.invoke(feedback, resource5);\n\n    DataSink<Tuple2<Long, Long>> sink =\n            iteration\n                    .closeWith(delta, feedback)\n                    .output(new DiscardingOutputFormat<Tuple2<Long, Long>>());\n    sinkMethod.invoke(sink, resource6);\n\n    JobGraph jobGraph = compileJob(env);\n\n    JobVertex sourceMapVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(0);\n    JobVertex iterationHeadVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(1);\n    JobVertex deltaVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(2);\n    JobVertex iterationTailVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(3);\n    JobVertex feedbackVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(4);\n    JobVertex sinkVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(5);\n    JobVertex iterationSyncVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(6);\n\n    assertTrue(sourceMapVertex.getMinResources().equals(resource1.merge(resource2)));\n    assertTrue(iterationHeadVertex.getPreferredResources().equals(resource3));\n    assertTrue(deltaVertex.getMinResources().equals(resource4));\n        \n        \n    assertTrue(iterationTailVertex.getPreferredResources().equals(ResourceSpec.DEFAULT));\n    assertTrue(feedbackVertex.getMinResources().equals(resource5));\n    assertTrue(sinkVertex.getPreferredResources().equals(resource6));\n    assertTrue(iterationSyncVertex.getMinResources().equals(resource3));\n}", "summary_tokens": ["verifies", "that", "the", "resources", "are", "set", "onto", "each", "job", "vertex", "correctly", "when", "generating", "job", "graph", "which", "covers", "the", "delta", "iteration", "case"], "project": "flink"}
{"id": 1533, "code": "public static <T0, T1, T2> Tuple3<T0, T1, T2> of(T0 f0, T1 f1, T2 f2) {\n    return new Tuple3<>(f0, f1, f2);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 4717, "code": "public V getAndRemove(String key) {\n    try {\n        V objToShare = retrieveSharedQueue(key).take();\n        mediations.remove(key);\n        return objToShare;\n    } catch (InterruptedException e) {\n        throw new RuntimeException(e);\n    }\n}", "summary_tokens": ["blocking", "retrieval", "and", "removal", "of", "the", "object", "to", "share"], "project": "flink"}
{"id": 3908, "code": "public Throwable getCause() {\n    return cause;\n}", "summary_tokens": ["returns", "the", "failure", "cause"], "project": "flink"}
{"id": 9171, "code": "static int partitionLevelHash(int hash) {\n    return hash ^ (hash >>> 16);\n}", "summary_tokens": ["partition", "level", "hash", "again", "for", "avoid", "two", "layer", "hash", "conflict"], "project": "flink"}
{"id": 7203, "code": "public Duration getAlignmentTimeout() {\n    return alignedCheckpointTimeout;\n}", "summary_tokens": ["value", "of", "alignment", "timeout", "as", "configured", "via", "set", "alignment", "timeout", "duration", "or", "execution", "checkpointing", "options", "alignment", "timeout"], "project": "flink"}
{"id": 1878, "code": "public void clear() {\n    if (fieldByPosition != null) {\n        Arrays.fill(fieldByPosition, null);\n    } else {\n        assert fieldByName != null;\n        fieldByName.clear();\n    }\n}", "summary_tokens": ["clears", "all", "fields", "of", "this", "row"], "project": "flink"}
{"id": 8340, "code": "public static void setDouble(MemorySegment[] segments, int offset, double value) {\n    if (inFirstSegment(segments, offset, 8)) {\n        segments[0].putDouble(offset, value);\n    } else {\n        setDoubleMultiSegments(segments, offset, value);\n    }\n}", "summary_tokens": ["set", "double", "from", "segments"], "project": "flink"}
{"id": 4301, "code": "public boolean isTaskDeployedAsFinished() {\n    return isTaskDeployedAsFinished;\n}", "summary_tokens": ["returns", "whether", "all", "the", "operators", "of", "the", "task", "are", "already", "finished", "on", "restoring"], "project": "flink"}
{"id": 7925, "code": "public static void assertOutputEqualsSorted(\n        String message,\n        Iterable<Object> expected,\n        Iterable<Object> actual,\n        Comparator<Object> comparator) {\n    assertEquals(Iterables.size(expected), Iterables.size(actual));\n\n        \n    Iterator<Object> exIt = expected.iterator();\n    Iterator<Object> actIt = actual.iterator();\n    while (exIt.hasNext()) {\n        Object nextEx = exIt.next();\n        Object nextAct = actIt.next();\n        if (nextEx instanceof Watermark) {\n            assertEquals(nextEx, nextAct);\n        }\n    }\n\n    List<Object> expectedRecords = new ArrayList<>();\n    List<Object> actualRecords = new ArrayList<>();\n\n    for (Object ex : expected) {\n        if (ex instanceof StreamRecord) {\n            expectedRecords.add(ex);\n        }\n    }\n\n    for (Object act : actual) {\n        if (act instanceof StreamRecord) {\n            actualRecords.add(act);\n        }\n    }\n\n    Object[] sortedExpected = expectedRecords.toArray();\n    Object[] sortedActual = actualRecords.toArray();\n\n    Arrays.sort(sortedExpected, comparator);\n    Arrays.sort(sortedActual, comparator);\n\n    Assert.assertArrayEquals(message, sortedExpected, sortedActual);\n}", "summary_tokens": ["compare", "the", "two", "queues", "containing", "operator", "task", "output", "by", "converting", "them", "to", "an", "array", "first"], "project": "flink"}
{"id": 1437, "code": "public void declareManagedMemoryUseCaseAtSlotScope(ManagedMemoryUseCase managedMemoryUseCase) {\n    Preconditions.checkNotNull(managedMemoryUseCase);\n    Preconditions.checkArgument(managedMemoryUseCase.scope == ManagedMemoryUseCase.Scope.SLOT);\n\n    managedMemorySlotScopeUseCases.add(managedMemoryUseCase);\n}", "summary_tokens": ["declares", "that", "this", "transformation", "contains", "certain", "slot", "scope", "managed", "memory", "use", "case"], "project": "flink"}
{"id": 654, "code": "public void testRestoreFromEmptyStateNoPartitions() throws Exception {\n    final DummyFlinkKafkaConsumer<String> consumerFunction =\n            new DummyFlinkKafkaConsumer<>(\n                    Collections.singletonList(\"dummy-topic\"),\n                    Collections.<KafkaTopicPartition>emptyList(),\n                    FlinkKafkaConsumerBase.PARTITION_DISCOVERY_DISABLED);\n\n    StreamSource<String, DummyFlinkKafkaConsumer<String>> consumerOperator =\n            new StreamSource<>(consumerFunction);\n\n    final AbstractStreamOperatorTestHarness<String> testHarness =\n            new AbstractStreamOperatorTestHarness<>(consumerOperator, 1, 1, 0);\n\n    testHarness.setTimeCharacteristic(TimeCharacteristic.ProcessingTime);\n\n    testHarness.setup();\n\n        \n    testHarness.initializeState(\n            OperatorSnapshotUtil.getResourceFilename(\n                    \"kafka-consumer-migration-test-flink\"\n                            + testMigrateVersion\n                            + \"-empty-state-snapshot\"));\n\n    testHarness.open();\n\n        \n    assertTrue(consumerFunction.getSubscribedPartitionsToStartOffsets() != null);\n    assertTrue(consumerFunction.getSubscribedPartitionsToStartOffsets().isEmpty());\n\n        \n    assertTrue(consumerFunction.getRestoredState().isEmpty());\n\n    consumerOperator.close();\n    consumerOperator.cancel();\n}", "summary_tokens": ["test", "restoring", "from", "an", "legacy", "empty", "state", "when", "no", "partitions", "could", "be", "found", "for", "topics"], "project": "flink"}
{"id": 4084, "code": "protected File getFileInternal(@Nullable JobID jobId, BlobKey blobKey) throws IOException {\n    checkArgument(blobKey != null, \"BLOB key cannot be null.\");\n\n    final File localFile = BlobUtils.getStorageLocation(storageDir, jobId, blobKey);\n    readWriteLock.readLock().lock();\n\n    try {\n        if (localFile.exists()) {\n            return localFile;\n        }\n    } finally {\n        readWriteLock.readLock().unlock();\n    }\n\n        \n        \n    File incomingFile = createTemporaryFilename();\n    try {\n        try {\n            if (blobView.get(jobId, blobKey, incomingFile)) {\n                    \n                readWriteLock.writeLock().lock();\n                try {\n                    BlobUtils.moveTempFileToStore(\n                            incomingFile, jobId, blobKey, localFile, log, null);\n                } finally {\n                    readWriteLock.writeLock().unlock();\n                }\n\n                return localFile;\n            }\n        } catch (Exception e) {\n            log.info(\n                    \"Failed to copy from blob store. Downloading from BLOB server instead.\", e);\n        }\n\n        final InetSocketAddress currentServerAddress = serverAddress;\n\n        if (currentServerAddress != null) {\n                \n            BlobClient.downloadFromBlobServer(\n                    jobId,\n                    blobKey,\n                    incomingFile,\n                    currentServerAddress,\n                    blobClientConfig,\n                    numFetchRetries);\n\n            readWriteLock.writeLock().lock();\n            try {\n                BlobUtils.moveTempFileToStore(\n                        incomingFile, jobId, blobKey, localFile, log, null);\n            } finally {\n                readWriteLock.writeLock().unlock();\n            }\n        } else {\n            throw new IOException(\n                    \"Cannot download from BlobServer, because the server address is unknown.\");\n        }\n\n        return localFile;\n    } finally {\n            \n        if (!incomingFile.delete() && incomingFile.exists()) {\n            log.warn(\n                    \"Could not delete the staging file {} for blob key {} and job {}.\",\n                    incomingFile,\n                    blobKey,\n                    jobId);\n        }\n    }\n}", "summary_tokens": ["returns", "local", "copy", "of", "the", "file", "for", "the", "blob", "with", "the", "given", "key"], "project": "flink"}
{"id": 3911, "code": "public void testKvStateLocationOracle() {\n    final JobID jobId1 = new JobID();\n    final TestingKvStateLocationOracle kvStateLocationOracle1 =\n            new TestingKvStateLocationOracle();\n    kvStateClientProxy.updateKvStateLocationOracle(jobId1, kvStateLocationOracle1);\n    final JobID jobId2 = new JobID();\n    final TestingKvStateLocationOracle kvStateLocationOracle2 =\n            new TestingKvStateLocationOracle();\n    kvStateClientProxy.updateKvStateLocationOracle(jobId2, kvStateLocationOracle2);\n\n    assertThat(kvStateClientProxy.getKvStateLocationOracle(new JobID()), nullValue());\n\n    assertThat(\n            kvStateClientProxy.getKvStateLocationOracle(jobId1),\n            equalTo(kvStateLocationOracle1));\n    assertThat(\n            kvStateClientProxy.getKvStateLocationOracle(jobId2),\n            equalTo(kvStateLocationOracle2));\n\n    kvStateClientProxy.updateKvStateLocationOracle(jobId1, null);\n    assertThat(kvStateClientProxy.getKvStateLocationOracle(jobId1), nullValue());\n}", "summary_tokens": ["tests", "that", "we", "can", "set", "and", "retrieve", "the", "kv", "state", "location", "oracle"], "project": "flink"}
{"id": 7987, "code": "public static OverWindowPartitioned partitionBy(Expression... partitionBy) {\n    return new OverWindowPartitioned(Arrays.asList(partitionBy));\n}", "summary_tokens": ["partitions", "the", "elements", "on", "some", "partition", "keys"], "project": "flink"}
{"id": 2166, "code": "private Path getGenerateDataFilePath() {\n    return Paths.get(getGenerateResourceDirectory() + \"/test-data\");\n}", "summary_tokens": ["paths", "to", "use", "during", "snapshot", "generation", "which", "should", "only", "use", "the", "current", "version"], "project": "flink"}
{"id": 2806, "code": "public void setSemanticProperties(SingleInputSemanticProperties properties) {\n    this.udfSemantics = properties;\n    this.analyzedUdfSemantics = false;\n}", "summary_tokens": ["sets", "the", "semantic", "properties", "for", "the", "user", "defined", "function", "udf"], "project": "flink"}
{"id": 7019, "code": "public AllWindowedStream<T, W> sideOutputLateData(OutputTag<T> outputTag) {\n    Preconditions.checkNotNull(outputTag, \"Side output tag must not be null.\");\n    this.lateDataOutputTag = input.getExecutionEnvironment().clean(outputTag);\n    return this;\n}", "summary_tokens": ["send", "late", "arriving", "data", "to", "the", "side", "output", "identified", "by", "the", "given", "output", "tag"], "project": "flink"}
{"id": 9763, "code": "public void testDeleteApplicationFiles() throws Exception {\n    new Context() {\n        {\n            final File applicationDir = folder.newFolder(\".flink\");\n            env.put(FLINK_YARN_FILES, applicationDir.getCanonicalPath());\n\n            runTest(\n                    () -> {\n                        getDriver().deregisterApplication(ApplicationStatus.SUCCEEDED, null);\n                        assertFalse(\n                                \"YARN application directory was not removed\",\n                                Files.exists(applicationDir.toPath()));\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "that", "application", "files", "are", "deleted", "when", "the", "yarn", "application", "master", "is", "de", "registered"], "project": "flink"}
{"id": 9738, "code": "private FinalApplicationStatus getYarnStatus(ApplicationStatus status) {\n    if (status == null) {\n        return FinalApplicationStatus.UNDEFINED;\n    } else {\n        switch (status) {\n            case SUCCEEDED:\n                return FinalApplicationStatus.SUCCEEDED;\n            case FAILED:\n                return FinalApplicationStatus.FAILED;\n            case CANCELED:\n                return FinalApplicationStatus.KILLED;\n            default:\n                return FinalApplicationStatus.UNDEFINED;\n        }\n    }\n}", "summary_tokens": ["converts", "a", "flink", "application", "status", "enum", "to", "a", "yarn", "application", "status", "enum"], "project": "flink"}
{"id": 2463, "code": "public void testConstructor_withConfigs_succeeds() {\n    GlueSchemaRegistryInputStreamDeserializer glueSchemaRegistryInputStreamDeserializer =\n            new GlueSchemaRegistryInputStreamDeserializer(configs);\n    assertThat(\n            glueSchemaRegistryInputStreamDeserializer,\n            instanceOf(GlueSchemaRegistryInputStreamDeserializer.class));\n}", "summary_tokens": ["test", "whether", "constructor", "works", "with", "configuration", "map"], "project": "flink"}
{"id": 4731, "code": "private BlockingBackChannel initBackChannel() throws Exception {\n\n        \n    int backChannelMemoryPages =\n            getMemoryManager().computeNumberOfPages(this.config.getRelativeBackChannelMemory());\n\n        \n    List<MemorySegment> segments = new ArrayList<MemorySegment>();\n    int segmentSize = getMemoryManager().getPageSize();\n    getMemoryManager().allocatePages(this, segments, backChannelMemoryPages);\n\n        \n    BlockingBackChannel backChannel =\n            new BlockingBackChannel(\n                    new SerializedUpdateBuffer(segments, segmentSize, getIOManager()));\n\n        \n    Broker<BlockingBackChannel> broker = BlockingBackChannelBroker.instance();\n    broker.handIn(brokerKey(), backChannel);\n\n    return backChannel;\n}", "summary_tokens": ["the", "iteration", "head", "prepares", "the", "backchannel", "it", "allocates", "memory", "instantiates", "a", "blocking", "back", "channel", "and", "hands", "it", "to", "the", "iteration", "tail", "via", "a", "broker", "singleton"], "project": "flink"}
{"id": 5790, "code": "private static void testBlobFetchWithTooManyFailures(\n        final Configuration config,\n        final BlobStore blobStore,\n        @Nullable final JobID jobId,\n        BlobKey.BlobType blobType)\n        throws IOException {\n\n    final byte[] data = new byte[] {1, 2, 3, 4, 5, 6, 7, 8, 9, 0};\n\n    try (BlobServer server = new TestingFailingBlobServer(config, blobStore, 0, 10);\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n            \n        final BlobKey key = put(server, jobId, data, blobType);\n\n            \n        try {\n            verifyContents(cache, jobId, key, data);\n            fail(\"This should fail\");\n        } catch (IOException e) {\n                \n        }\n    }\n}", "summary_tokens": ["a", "test", "where", "the", "blob", "cache", "must", "use", "the", "blob", "server", "and", "the", "connection", "fails", "too", "often", "which", "eventually", "fails", "the", "get", "request"], "project": "flink"}
{"id": 4927, "code": "public static SSLHandlerFactory createRestClientSSLEngineFactory(final Configuration config)\n        throws Exception {\n    ClientAuth clientAuth =\n            SecurityOptions.isRestSSLAuthenticationEnabled(config)\n                    ? ClientAuth.REQUIRE\n                    : ClientAuth.NONE;\n    SslContext sslContext = createRestNettySSLContext(config, true, clientAuth);\n    if (sslContext == null) {\n        throw new IllegalConfigurationException(\"SSL is not enabled for REST endpoints.\");\n    }\n\n    return new SSLHandlerFactory(sslContext, -1, -1);\n}", "summary_tokens": ["creates", "a", "sslhandler", "factory", "to", "be", "used", "by", "the", "rest", "clients"], "project": "flink"}
{"id": 6999, "code": "public void testSharedResourcesAfterClose() throws Exception {\n    OpaqueMemoryResource<RocksDBSharedResources> sharedResources = getSharedResources();\n    RocksDBResourceContainer container =\n            new RocksDBResourceContainer(PredefinedOptions.DEFAULT, null, sharedResources);\n    container.close();\n    RocksDBSharedResources rocksDBSharedResources = sharedResources.getResourceHandle();\n    assertThat(rocksDBSharedResources.getCache().isOwningHandle(), is(false));\n    assertThat(rocksDBSharedResources.getWriteBufferManager().isOwningHandle(), is(false));\n}", "summary_tokens": ["guard", "the", "shared", "resources", "will", "be", "released", "after", "rocks", "dbresource", "container", "close", "when", "the", "rocks", "dbresource", "container", "instance", "is", "initiated", "with", "opaque", "memory", "resource"], "project": "flink"}
{"id": 2488, "code": "public static AvroSerializationSchema<GenericRecord> forGeneric(Schema schema) {\n    return new AvroSerializationSchema<>(GenericRecord.class, schema);\n}", "summary_tokens": ["creates", "avro", "serialization", "schema", "that", "serializes", "generic", "record", "using", "provided", "schema"], "project": "flink"}
{"id": 4220, "code": "public StatsSummary getEndToEndDurationStats() {\n    return duration;\n}", "summary_tokens": ["returns", "the", "summary", "stats", "for", "the", "duration", "of", "completed", "checkpoints"], "project": "flink"}
{"id": 9483, "code": "public void testSourceSingleSplit(TestEnvironment testEnv, ExternalContext<T> externalContext)\n        throws Exception {\n\n        \n    LOG.info(\"Writing test data to split 0\");\n    final List<T> testRecords = generateAndWriteTestData(0, externalContext);\n\n        \n    StreamExecutionEnvironment execEnv = testEnv.createExecutionEnvironment();\n\n    LOG.info(\"Submitting Flink job to test environment\");\n    try (CloseableIterator<T> resultIterator =\n            execEnv.fromSource(\n                            externalContext.createSource(Boundedness.BOUNDED),\n                            WatermarkStrategy.noWatermarks(),\n                            \"Tested Source\")\n                    .setParallelism(1)\n                    .executeAndCollect(\"Source Single Split Test\")) {\n            \n        LOG.info(\"Checking test results\");\n        assertThat(resultIterator, matchesSplitTestData(testRecords));\n    }\n}", "summary_tokens": ["test", "connector", "source", "with", "only", "one", "split", "in", "the", "external", "system"], "project": "flink"}
{"id": 4740, "code": "public SubtaskStateMapper getUpstreamSubtaskStateMapper() {\n    return upstreamSubtaskStateMapper;\n}", "summary_tokens": ["gets", "the", "channel", "state", "rescaler", "used", "for", "rescaling", "persisted", "data", "on", "upstream", "side", "of", "this", "job", "edge"], "project": "flink"}
{"id": 6102, "code": "public void testConcurrentGrantLeadershipAndShutdown() throws Exception {\n    final EmbeddedLeaderService embeddedLeaderService =\n            new EmbeddedLeaderService(TestingUtils.defaultExecutor());\n\n    try {\n        final LeaderElectionService leaderElectionService =\n                embeddedLeaderService.createLeaderElectionService();\n\n        final TestingLeaderContender contender = new TestingLeaderContender();\n\n        leaderElectionService.start(contender);\n        leaderElectionService.stop();\n\n        try {\n                \n            contender.getLeaderSessionFuture().get(10L, TimeUnit.MILLISECONDS);\n        } catch (TimeoutException ignored) {\n                \n        }\n\n            \n        Assert.assertThat(embeddedLeaderService.isShutdown(), is(false));\n    } finally {\n        embeddedLeaderService.shutdown();\n    }\n}", "summary_tokens": ["tests", "that", "the", "embedded", "leader", "service", "can", "handle", "a", "concurrent", "grant", "leadership", "call", "and", "a", "shutdown"], "project": "flink"}
{"id": 602, "code": "public E getElementBlocking(long timeoutMillis) throws InterruptedException {\n    if (timeoutMillis == 0L) {\n            \n        return getElementBlocking();\n    } else if (timeoutMillis < 0L) {\n        throw new IllegalArgumentException(\"invalid timeout\");\n    }\n\n    final long deadline = System.nanoTime() + timeoutMillis * 1_000_000L;\n\n    lock.lock();\n    try {\n        while (open && elements.isEmpty() && timeoutMillis > 0) {\n            nonEmpty.await(timeoutMillis, TimeUnit.MILLISECONDS);\n            timeoutMillis = (deadline - System.nanoTime()) / 1_000_000L;\n        }\n\n        if (!open) {\n            throw new IllegalStateException(\"queue is closed\");\n        } else if (elements.isEmpty()) {\n            return null;\n        } else {\n            return elements.removeFirst();\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["returns", "the", "next", "element", "in", "the", "queue"], "project": "flink"}
{"id": 5391, "code": "public KeyGroupsStateHandle getIntersection(KeyGroupRange keyGroupRange) {\n    KeyGroupRangeOffsets offsets = groupRangeOffsets.getIntersection(keyGroupRange);\n    if (offsets.getKeyGroupRange().getNumberOfKeyGroups() <= 0) {\n        return null;\n    }\n    return new KeyGroupsStateHandle(offsets, stateHandle);\n}", "summary_tokens": ["key", "group", "range", "a", "key", "group", "range", "to", "intersect"], "project": "flink"}
{"id": 2848, "code": "public Double getMean() {\n    return mean;\n}", "summary_tokens": ["null", "na", "n", "and", "infinite", "values", "are", "ignored", "in", "this", "calculation"], "project": "flink"}
{"id": 1327, "code": "public TypeSerializer<T> getElementSerializer() {\n        \n    final TypeSerializer<List<T>> rawSerializer = getSerializer();\n    if (!(rawSerializer instanceof ListSerializer)) {\n        throw new IllegalStateException();\n    }\n\n    return ((ListSerializer<T>) rawSerializer).getElementSerializer();\n}", "summary_tokens": ["gets", "the", "serializer", "for", "the", "elements", "contained", "in", "the", "list"], "project": "flink"}
{"id": 8908, "code": "public SqlNode parse(String sql) {\n    try {\n        SqlParser parser = SqlParser.create(sql, config);\n        return parser.parseStmt();\n    } catch (SqlParseException e) {\n        throw new SqlParserException(\"SQL parse failed. \" + e.getMessage(), e);\n    }\n}", "summary_tokens": ["parses", "a", "sql", "statement", "into", "a", "sql", "node"], "project": "flink"}
{"id": 6249, "code": "public void testUpdateChannelBeforeRequest() throws Exception {\n    SingleInputGate inputGate = createInputGate(1);\n\n    TestingResultPartitionManager partitionManager =\n            new TestingResultPartitionManager(new NoOpResultSubpartitionView());\n\n    InputChannel unknown =\n            InputChannelBuilder.newBuilder()\n                    .setPartitionManager(partitionManager)\n                    .buildUnknownChannel(inputGate);\n    inputGate.setInputChannels(unknown);\n\n        \n    ResultPartitionID resultPartitionID = unknown.getPartitionId();\n    ResourceID location = ResourceID.generate();\n    inputGate.updateInputChannel(\n            location,\n            createRemoteWithIdAndLocation(resultPartitionID.getPartitionId(), location));\n\n    assertEquals(0, partitionManager.counter);\n}", "summary_tokens": ["tests", "that", "an", "update", "channel", "does", "not", "trigger", "a", "partition", "request", "before", "the", "udf", "has", "requested", "any", "partitions"], "project": "flink"}
{"id": 6659, "code": "public void testUpdateTaskInputPartitionsFailure() throws Exception {\n    final ExecutionAttemptID eid = new ExecutionAttemptID();\n\n    final TaskDeploymentDescriptor tdd =\n            createTestTaskDeploymentDescriptor(\"test task\", eid, BlockingNoOpInvokable.class);\n\n    final CompletableFuture<Void> taskRunningFuture = new CompletableFuture<>();\n    final CompletableFuture<Void> taskFailedFuture = new CompletableFuture<>();\n    final ShuffleEnvironment<?, ?> shuffleEnvironment =\n            mock(ShuffleEnvironment.class, Mockito.RETURNS_MOCKS);\n\n    try (TaskSubmissionTestEnvironment env =\n            new TaskSubmissionTestEnvironment.Builder(jobId)\n                    .setShuffleEnvironment(shuffleEnvironment)\n                    .setSlotSize(1)\n                    .addTaskManagerActionListener(\n                            eid, ExecutionState.RUNNING, taskRunningFuture)\n                    .addTaskManagerActionListener(eid, ExecutionState.FAILED, taskFailedFuture)\n                    .build()) {\n        TaskExecutorGateway tmGateway = env.getTaskExecutorGateway();\n        TaskSlotTable<Task> taskSlotTable = env.getTaskSlotTable();\n\n        taskSlotTable.allocateSlot(0, jobId, tdd.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd, env.getJobMasterId(), timeout).get();\n        taskRunningFuture.get();\n\n        final ResourceID producerLocation = env.getTaskExecutor().getResourceID();\n        NettyShuffleDescriptor shuffleDescriptor =\n                createRemoteWithIdAndLocation(\n                        new IntermediateResultPartitionID(), producerLocation);\n        final PartitionInfo partitionUpdate =\n                new PartitionInfo(new IntermediateDataSetID(), shuffleDescriptor);\n        doThrow(new IOException())\n                .when(shuffleEnvironment)\n                .updatePartitionInfo(eid, partitionUpdate);\n\n        final CompletableFuture<Acknowledge> updateFuture =\n                tmGateway.updatePartitions(\n                        eid, Collections.singletonList(partitionUpdate), timeout);\n\n        updateFuture.get();\n        taskFailedFuture.get();\n        Task task = taskSlotTable.getTask(tdd.getExecutionAttemptId());\n        assertThat(task.getExecutionState(), is(ExecutionState.FAILED));\n        assertThat(task.getFailureCause(), instanceOf(IOException.class));\n    }\n}", "summary_tokens": ["tests", "that", "the", "task", "manager", "fails", "the", "task", "if", "the", "partition", "update", "fails"], "project": "flink"}
{"id": 6842, "code": "public void testPutAndPutWithSnapshot() {\n    CopyOnWriteSkipListStateMapSnapshot<Integer, Long, String> snapshot =\n            stateMapWithStates.stateSnapshot();\n    TestExecutionResult result = testPutAndPut();\n    snapshot.release();\n    verify(result);\n}", "summary_tokens": ["test", "put", "put", "during", "snapshot", "the", "first", "put", "should", "trigger", "copy", "on", "write", "and", "the", "second", "shouldn", "t"], "project": "flink"}
{"id": 2320, "code": "public static void addDeprecation(String key, String newKey) {\n    addDeprecation(key, new String[] {newKey}, null);\n}", "summary_tokens": ["adds", "the", "deprecated", "key", "to", "the", "global", "deprecation", "map", "when", "no", "custom", "message", "is", "provided"], "project": "flink"}
{"id": 899, "code": "public PulsarSourceBuilder<OUT> setUnboundedStopCursor(StopCursor stopCursor) {\n    this.boundedness = Boundedness.CONTINUOUS_UNBOUNDED;\n    this.stopCursor = checkNotNull(stopCursor);\n    return this;\n}", "summary_tokens": ["by", "default", "the", "pulsar", "source", "is", "set", "to", "run", "in", "boundedness", "continuous", "unbounded", "manner", "and", "thus", "never", "stops", "until", "the", "flink", "job", "fails", "or", "is", "canceled"], "project": "flink"}
{"id": 8167, "code": "public static TypeInformation<Double> DOUBLE() {\n    return org.apache.flink.api.common.typeinfo.Types.DOUBLE;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "integer", "or", "sql", "double", "type"], "project": "flink"}
{"id": 4180, "code": "boolean discardOnJobSuspended() {\n    return discardSuspended;\n}", "summary_tokens": ["returns", "whether", "the", "checkpoint", "should", "be", "discarded", "when", "the", "owning", "job", "reaches", "the", "job", "status", "suspended", "state"], "project": "flink"}
{"id": 9671, "code": "public double computeEuclideanDistance(CoordVector cv) {\n        \n    if (cv.coordinates.length != this.coordinates.length) {\n        return -1.0;\n    }\n\n    double quadSum = 0.0;\n    for (int i = 0; i < this.coordinates.length; i++) {\n        double diff = this.coordinates[i] - cv.coordinates[i];\n        quadSum += diff * diff;\n    }\n    return Math.sqrt(quadSum);\n}", "summary_tokens": ["computes", "the", "euclidean", "distance", "between", "this", "coordinate", "vector", "and", "a", "second", "coordinate", "vector"], "project": "flink"}
{"id": 8518, "code": "DataTypeTemplate mergeWithInnerAnnotation(DataTypeFactory typeFactory, DataTypeHint hint) {\n    final DataTypeTemplate otherTemplate = fromAnnotation(typeFactory, hint);\n    return new DataTypeTemplate(\n            otherTemplate.dataType,\n            rightValueIfNotNull(rawSerializer, otherTemplate.rawSerializer),\n            rightValueIfNotNull(inputGroup, otherTemplate.inputGroup),\n            rightValueIfNotNull(version, otherTemplate.version),\n            rightValueIfNotNull(allowRawGlobally, otherTemplate.allowRawGlobally),\n            rightValueIfNotNull(allowRawPattern, otherTemplate.allowRawPattern),\n            rightValueIfNotNull(forceRawPattern, otherTemplate.forceRawPattern),\n            rightValueIfNotNull(defaultDecimalPrecision, otherTemplate.defaultDecimalPrecision),\n            rightValueIfNotNull(defaultDecimalScale, otherTemplate.defaultDecimalScale),\n            rightValueIfNotNull(defaultYearPrecision, otherTemplate.defaultYearPrecision),\n            rightValueIfNotNull(defaultSecondPrecision, otherTemplate.defaultSecondPrecision));\n}", "summary_tokens": ["merges", "this", "template", "with", "an", "inner", "annotation"], "project": "flink"}
{"id": 9466, "code": "public static <T> TypeSerializer<T> snapshotAndReconfigure(\n        TypeSerializer<T> serializer, SerializerGetter<T> serializerGetter) throws IOException {\n    TypeSerializerSnapshot<T> configSnapshot = serializer.snapshotConfiguration();\n\n    byte[] serializedConfig;\n    try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n        TypeSerializerSnapshotSerializationUtil.writeSerializerSnapshot(\n                new DataOutputViewStreamWrapper(out), configSnapshot, serializer);\n        serializedConfig = out.toByteArray();\n    }\n\n    TypeSerializerSnapshot<T> restoredConfig;\n    try (ByteArrayInputStream in = new ByteArrayInputStream(serializedConfig)) {\n        restoredConfig =\n                TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(\n                        new DataInputViewStreamWrapper(in),\n                        Thread.currentThread().getContextClassLoader(),\n                        serializerGetter.getSerializer());\n    }\n\n    TypeSerializerSchemaCompatibility<T> strategy =\n            restoredConfig.resolveSchemaCompatibility(serializerGetter.getSerializer());\n    final TypeSerializer<T> restoredSerializer;\n    if (strategy.isCompatibleAsIs()) {\n        restoredSerializer = restoredConfig.restoreSerializer();\n    } else if (strategy.isCompatibleWithReconfiguredSerializer()) {\n        restoredSerializer = strategy.getReconfiguredSerializer();\n    } else {\n        throw new AssertionError(\"Unable to restore serializer with \" + strategy);\n    }\n    assertEquals(serializer.getClass(), restoredSerializer.getClass());\n\n    return restoredSerializer;\n}", "summary_tokens": ["snapshot", "and", "restore", "the", "given", "serializer"], "project": "flink"}
{"id": 5779, "code": "private void testPutBufferFailsIncoming(@Nullable final JobID jobId, BlobKey.BlobType blobType)\n        throws IOException {\n    assumeTrue(!OperatingSystem.isWindows()); \n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    File tempFileDir = null;\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n            \n        tempFileDir = server.createTemporaryFilename().getParentFile();\n        assertTrue(tempFileDir.setExecutable(true, false));\n        assertTrue(tempFileDir.setReadable(true, false));\n        assertTrue(tempFileDir.setWritable(false, false));\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n\n            \n        exception.expect(IOException.class);\n        exception.expectMessage(\"PUT operation failed: \");\n\n        try {\n            put(cache, jobId, data, blobType);\n        } finally {\n            File storageDir = tempFileDir.getParentFile();\n                \n            assertArrayEquals(new String[] {\"incoming\"}, storageDir.list());\n        }\n    } finally {\n            \n        if (tempFileDir != null) {\n                \n            tempFileDir.setWritable(true, false);\n        }\n    }\n}", "summary_tokens": ["uploads", "a", "byte", "array", "to", "a", "server", "which", "cannot", "create", "incoming", "files", "via", "the", "blob", "cache", "service"], "project": "flink"}
{"id": 6152, "code": "private static NetworkBuffer newBuffer(\n        int length, int maxCapacity, boolean isBuffer, BufferRecycler recycler) {\n    final MemorySegment segment =\n            MemorySegmentFactory.allocateUnpooledSegment(\n                    Math.min(maxCapacity, MAX_CAPACITY_UPPER_BOUND));\n\n    Buffer.DataType dataType =\n            isBuffer ? Buffer.DataType.DATA_BUFFER : Buffer.DataType.EVENT_BUFFER;\n    NetworkBuffer buffer = new NetworkBuffer(segment, recycler, dataType);\n    buffer.capacity(length);\n    buffer.setAllocator(NETTY_BUFFER_POOL);\n\n    assertSame(ByteOrder.BIG_ENDIAN, buffer.order());\n    assertEquals(0, buffer.readerIndex());\n    assertEquals(0, buffer.writerIndex());\n    return buffer;\n}", "summary_tokens": ["creates", "a", "new", "buffer", "for", "testing"], "project": "flink"}
{"id": 6493, "code": "public void testNullFieldsNotSet() throws JsonProcessingException {\n    ObjectMapper objMapper = RestMapperUtils.getStrictObjectMapper();\n    String json =\n            objMapper.writeValueAsString(\n                    new JobExceptionsInfoWithHistory.ExceptionInfo(\n                            \"exception name\", \"stacktrace\", 0L));\n\n    assertThat(json, not(CoreMatchers.containsString(\"taskName\")));\n    assertThat(json, not(CoreMatchers.containsString(\"location\")));\n}", "summary_tokens": ["task", "name", "and", "location", "should", "not", "be", "exposed", "if", "not", "set"], "project": "flink"}
{"id": 4269, "code": "private List<Map<StreamStateHandle, OperatorStateHandle>> repartition(\n        GroupByStateNameResults nameToStateByMode, int newParallelism) {\n\n        \n        \n    List<Map<StreamStateHandle, OperatorStateHandle>> mergeMapList =\n            new ArrayList<>(newParallelism);\n\n        \n    for (int i = 0; i < newParallelism; ++i) {\n        mergeMapList.add(new HashMap<>());\n    }\n\n        \n    Map<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>>\n            nameToDistributeState =\n                    nameToStateByMode.getByMode(OperatorStateHandle.Mode.SPLIT_DISTRIBUTE);\n\n    repartitionSplitState(nameToDistributeState, newParallelism, mergeMapList);\n\n        \n    Map<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>>\n            nameToUnionState = nameToStateByMode.getByMode(OperatorStateHandle.Mode.UNION);\n\n    repartitionUnionState(nameToUnionState, mergeMapList);\n\n        \n    Map<String, List<Tuple2<StreamStateHandle, OperatorStateHandle.StateMetaInfo>>>\n            nameToBroadcastState =\n                    nameToStateByMode.getByMode(OperatorStateHandle.Mode.BROADCAST);\n\n    repartitionBroadcastState(nameToBroadcastState, mergeMapList);\n\n    return mergeMapList;\n}", "summary_tokens": ["repartition", "all", "named", "states"], "project": "flink"}
{"id": 6370, "code": "public void testHashTableGrowthWithInsertOrReplace() {\n    try {\n        final int numElements = 1000000;\n\n        List<MemorySegment> memory = getMemory(1000, 32 * 1024);\n\n        InPlaceMutableHashTable<Tuple2<Long, String>> table =\n                new InPlaceMutableHashTable<Tuple2<Long, String>>(\n                        serializer, comparator, memory);\n        table.open();\n\n        for (long i = 0; i < numElements; i++) {\n            table.insertOrReplaceRecord(Tuple2.of(i, String.valueOf(i)));\n        }\n\n            \n        {\n            BitSet bitSet = new BitSet(numElements);\n            MutableObjectIterator<Tuple2<Long, String>> iter = table.getEntryIterator();\n            Tuple2<Long, String> next;\n            while ((next = iter.next()) != null) {\n                assertNotNull(next.f0);\n                assertNotNull(next.f1);\n                assertEquals(next.f0.longValue(), Long.parseLong(next.f1));\n\n                bitSet.set(next.f0.intValue());\n            }\n\n            assertEquals(numElements, bitSet.cardinality());\n        }\n\n            \n        {\n            InPlaceMutableHashTable<Tuple2<Long, String>>.HashTableProber<Long> proper =\n                    table.getProber(probeComparator, pairComparator);\n\n            Tuple2<Long, String> reuse = new Tuple2<>();\n\n            for (long i = 0; i < numElements; i++) {\n                assertNotNull(proper.getMatchFor(i, reuse));\n                assertNull(proper.getMatchFor(i + numElements, reuse));\n            }\n        }\n\n        table.close();\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["this", "test", "validates", "that", "records", "are", "not", "lost", "via", "insert", "or", "replace", "as", "in", "bug", "flink", "0"], "project": "flink"}
{"id": 8901, "code": "private Operation convertDescribeTable(SqlRichDescribeTable sqlRichDescribeTable) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlRichDescribeTable.fullTableName());\n    ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n\n    return new DescribeTableOperation(identifier, sqlRichDescribeTable.isExtended());\n}", "summary_tokens": ["convert", "describe", "extended", "catalog", "name"], "project": "flink"}
{"id": 888, "code": "private static <T, R extends Exception> T sneaky(SupplierWithException<T, R> supplier) {\n    try {\n        return supplier.get();\n    } catch (Exception r) {\n        sneakyThrow(r);\n    }\n\n        \n    throw new RuntimeException(\"Never throw here.\");\n}", "summary_tokens": ["catch", "the", "throwable", "exception", "and", "rethrow", "it", "without", "try", "catch"], "project": "flink"}
{"id": 6198, "code": "public void testEnqueueReaderByResumingConsumption() throws Exception {\n    PipelinedSubpartition subpartition =\n            PipelinedSubpartitionTest.createPipelinedSubpartition();\n    Buffer.DataType dataType1 = Buffer.DataType.ALIGNED_CHECKPOINT_BARRIER;\n    Buffer.DataType dataType2 = Buffer.DataType.DATA_BUFFER;\n    subpartition.add(createEventBufferConsumer(4096, dataType1));\n    subpartition.add(createEventBufferConsumer(4096, dataType2));\n\n    BufferAvailabilityListener bufferAvailabilityListener = new NoOpBufferAvailablityListener();\n    PipelinedSubpartitionView view = subpartition.createReadView(bufferAvailabilityListener);\n    ResultPartitionProvider partitionProvider =\n            (partitionId, index, availabilityListener) -> view;\n\n    InputChannelID receiverId = new InputChannelID();\n    PartitionRequestQueue queue = new PartitionRequestQueue();\n    CreditBasedSequenceNumberingViewReader reader =\n            new CreditBasedSequenceNumberingViewReader(receiverId, 2, queue);\n    EmbeddedChannel channel = new EmbeddedChannel(queue);\n\n    reader.requestSubpartitionView(partitionProvider, new ResultPartitionID(), 0);\n    queue.notifyReaderCreated(reader);\n    assertTrue(reader.getAvailabilityAndBacklog().isAvailable());\n\n    reader.notifyDataAvailable();\n    channel.runPendingTasks();\n    assertFalse(reader.getAvailabilityAndBacklog().isAvailable());\n    assertEquals(1, subpartition.unsynchronizedGetNumberOfQueuedBuffers());\n\n    queue.addCreditOrResumeConsumption(\n            receiverId, NetworkSequenceViewReader::resumeConsumption);\n    assertFalse(reader.getAvailabilityAndBacklog().isAvailable());\n    assertEquals(0, subpartition.unsynchronizedGetNumberOfQueuedBuffers());\n\n    Object data1 = channel.readOutbound();\n    assertEquals(dataType1, ((NettyMessage.BufferResponse) data1).buffer.getDataType());\n    Object data2 = channel.readOutbound();\n    assertEquals(dataType2, ((NettyMessage.BufferResponse) data2).buffer.getDataType());\n}", "summary_tokens": ["tests", "partition", "request", "queue", "enqueue", "available", "reader", "network", "sequence", "view", "reader", "verifying", "the", "reader", "would", "be", "enqueued", "in", "the", "pipeline", "after", "resuming", "data", "consumption", "if", "there", "are", "credit", "and", "data", "available"], "project": "flink"}
{"id": 631, "code": "public static Optional<FlinkKafkaPartitioner<RowData>> getFlinkKafkaPartitioner(\n        ReadableConfig tableOptions, ClassLoader classLoader) {\n    return tableOptions\n            .getOptional(SINK_PARTITIONER)\n            .flatMap(\n                    (String partitioner) -> {\n                        switch (partitioner) {\n                            case SINK_PARTITIONER_VALUE_FIXED:\n                                return Optional.of(new FlinkFixedPartitioner<>());\n                            case SINK_PARTITIONER_VALUE_DEFAULT:\n                            case SINK_PARTITIONER_VALUE_ROUND_ROBIN:\n                                return Optional.empty();\n                                    \n                            default:\n                                return Optional.of(\n                                        initializePartitioner(partitioner, classLoader));\n                        }\n                    });\n}", "summary_tokens": ["the", "partitioner", "can", "be", "either", "fixed", "round", "robin", "or", "a", "customized", "partitioner", "full", "class", "name"], "project": "flink"}
{"id": 3982, "code": "public static String getRpcUrl(\n        String hostname,\n        int port,\n        String endpointName,\n        AddressResolution addressResolution,\n        AkkaProtocol akkaProtocol)\n        throws UnknownHostException {\n\n    checkNotNull(hostname, \"hostname is null\");\n    checkNotNull(endpointName, \"endpointName is null\");\n    checkArgument(isValidClientPort(port), \"port must be in [1, 65535]\");\n\n    if (addressResolution == AddressResolution.TRY_ADDRESS_RESOLUTION) {\n            \n            \n        InetAddress.getByName(hostname);\n    }\n\n    final String hostPort = NetUtils.unresolvedHostAndPortToNormalizedString(hostname, port);\n\n    return internalRpcUrl(\n            endpointName, Optional.of(new RemoteAddressInformation(hostPort, akkaProtocol)));\n}", "summary_tokens": ["hostname", "the", "hostname", "or", "address", "where", "the", "target", "rpc", "service", "is", "listening"], "project": "flink"}
{"id": 7954, "code": "public boolean isOverwrite() {\n    return getModifierNode(RichSqlInsertKeyword.OVERWRITE) != null;\n}", "summary_tokens": ["returns", "whether", "the", "insert", "mode", "is", "overwrite", "for", "whole", "table", "or", "for", "specific", "partitions"], "project": "flink"}
{"id": 2391, "code": "public Map<String, String> getPropsWithPrefix(String confPrefix) {\n    Properties props = getProps();\n    Enumeration e = props.propertyNames();\n    Map<String, String> configMap = new HashMap<>();\n    String name = null;\n    while (e.hasMoreElements()) {\n        name = (String) e.nextElement();\n        if (name.startsWith(confPrefix)) {\n            String value = props.getProperty(name);\n            name = name.substring(confPrefix.length());\n            configMap.put(name, value);\n        }\n    }\n    return configMap;\n}", "summary_tokens": ["constructs", "a", "mapping", "of", "configuration", "and", "includes", "all", "properties", "that", "start", "with", "the", "specified", "configuration", "prefix"], "project": "flink"}
{"id": 8295, "code": "static FieldGetter createFieldGetter(LogicalType fieldType, int fieldPos) {\n    final FieldGetter fieldGetter;\n        \n    switch (fieldType.getTypeRoot()) {\n        case CHAR:\n        case VARCHAR:\n            fieldGetter = row -> row.getString(fieldPos);\n            break;\n        case BOOLEAN:\n            fieldGetter = row -> row.getBoolean(fieldPos);\n            break;\n        case BINARY:\n        case VARBINARY:\n            fieldGetter = row -> row.getBinary(fieldPos);\n            break;\n        case DECIMAL:\n            final int decimalPrecision = getPrecision(fieldType);\n            final int decimalScale = getScale(fieldType);\n            fieldGetter = row -> row.getDecimal(fieldPos, decimalPrecision, decimalScale);\n            break;\n        case TINYINT:\n            fieldGetter = row -> row.getByte(fieldPos);\n            break;\n        case SMALLINT:\n            fieldGetter = row -> row.getShort(fieldPos);\n            break;\n        case INTEGER:\n        case DATE:\n        case TIME_WITHOUT_TIME_ZONE:\n        case INTERVAL_YEAR_MONTH:\n            fieldGetter = row -> row.getInt(fieldPos);\n            break;\n        case BIGINT:\n        case INTERVAL_DAY_TIME:\n            fieldGetter = row -> row.getLong(fieldPos);\n            break;\n        case FLOAT:\n            fieldGetter = row -> row.getFloat(fieldPos);\n            break;\n        case DOUBLE:\n            fieldGetter = row -> row.getDouble(fieldPos);\n            break;\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            final int timestampPrecision = getPrecision(fieldType);\n            fieldGetter = row -> row.getTimestamp(fieldPos, timestampPrecision);\n            break;\n        case TIMESTAMP_WITH_TIME_ZONE:\n            throw new UnsupportedOperationException();\n        case ARRAY:\n            fieldGetter = row -> row.getArray(fieldPos);\n            break;\n        case MULTISET:\n        case MAP:\n            fieldGetter = row -> row.getMap(fieldPos);\n            break;\n        case ROW:\n        case STRUCTURED_TYPE:\n            final int rowFieldCount = getFieldCount(fieldType);\n            fieldGetter = row -> row.getRow(fieldPos, rowFieldCount);\n            break;\n        case DISTINCT_TYPE:\n            fieldGetter =\n                    createFieldGetter(((DistinctType) fieldType).getSourceType(), fieldPos);\n            break;\n        case RAW:\n            fieldGetter = row -> row.getRawValue(fieldPos);\n            break;\n        case NULL:\n        case SYMBOL:\n        case UNRESOLVED:\n        default:\n            throw new IllegalArgumentException();\n    }\n    if (!fieldType.isNullable()) {\n        return fieldGetter;\n    }\n    return row -> {\n        if (row.isNullAt(fieldPos)) {\n            return null;\n        }\n        return fieldGetter.getFieldOrNull(row);\n    };\n}", "summary_tokens": ["creates", "an", "accessor", "for", "getting", "elements", "in", "an", "internal", "row", "data", "structure", "at", "the", "given", "position"], "project": "flink"}
{"id": 2739, "code": "public CsvReader ignoreFirstLine() {\n    skipFirstLineAsHeader = true;\n    return this;\n}", "summary_tokens": ["sets", "the", "csv", "reader", "to", "ignore", "the", "first", "line"], "project": "flink"}
{"id": 3372, "code": "public void setDirection(EdgeDirection direction) {\n    this.direction = direction;\n}", "summary_tokens": ["sets", "the", "direction", "in", "which", "messages", "are", "sent", "in", "the", "scatter", "function"], "project": "flink"}
{"id": 5893, "code": "public void testCounterIsNeverNegative() throws Exception {\n    final CheckpointIDCounter counter = createCheckpointIdCounter();\n\n    try {\n        counter.start();\n        assertThat(counter.get(), greaterThanOrEqualTo(0L));\n    } finally {\n        counter.shutdown(JobStatus.FINISHED);\n    }\n}", "summary_tokens": ["this", "test", "guards", "an", "assumption", "made", "in", "the", "notifications", "in", "the", "org"], "project": "flink"}
{"id": 9116, "code": "public void setCollector(Collector<?> collector) {\n    this.collector = collector;\n}", "summary_tokens": ["sets", "the", "current", "collector", "which", "used", "to", "emit", "the", "final", "row"], "project": "flink"}
{"id": 3757, "code": "public void checkPropertyHandlingWithIncreasingGlobalParallelism2() {\n    final int p = DEFAULT_PARALLELISM;\n\n        \n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(p);\n    DataSet<Long> set1 = env.generateSequence(0, 1).setParallelism(p);\n\n    set1.map(new IdentityMapper<Long>())\n            .withForwardedFields(\"*\")\n            .setParallelism(p)\n            .name(\"Map1\")\n            .groupBy(\"*\")\n            .reduceGroup(new IdentityGroupReducer<Long>())\n            .withForwardedFields(\"*\")\n            .setParallelism(p)\n            .name(\"Reduce1\")\n            .map(new IdentityMapper<Long>())\n            .withForwardedFields(\"*\")\n            .setParallelism(p)\n            .name(\"Map2\")\n            .groupBy(\"*\")\n            .reduceGroup(new IdentityGroupReducer<Long>())\n            .withForwardedFields(\"*\")\n            .setParallelism(p * 2)\n            .name(\"Reduce2\")\n            .output(new DiscardingOutputFormat<Long>())\n            .setParallelism(p * 2)\n            .name(\"Sink\");\n\n    Plan plan = env.createProgramPlan();\n\n        \n    OptimizedPlan oPlan = compileNoStats(plan);\n\n        \n        \n        \n        \n        \n        \n    SinkPlanNode sinkNode = oPlan.getDataSinks().iterator().next();\n    SingleInputPlanNode red2Node = (SingleInputPlanNode) sinkNode.getPredecessor();\n    SingleInputPlanNode map2Node = (SingleInputPlanNode) red2Node.getPredecessor();\n\n    ShipStrategyType mapIn = map2Node.getInput().getShipStrategy();\n    ShipStrategyType reduceIn = red2Node.getInput().getShipStrategy();\n\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\", ShipStrategyType.FORWARD, mapIn);\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\",\n            ShipStrategyType.PARTITION_HASH,\n            reduceIn);\n}", "summary_tokens": ["simple", "job", "map", "reduce", "map", "reduce"], "project": "flink"}
{"id": 5304, "code": "public static RootExceptionHistoryEntry fromFailureHandlingResultSnapshot(\n        FailureHandlingResultSnapshot snapshot) {\n    String failingTaskName = null;\n    TaskManagerLocation taskManagerLocation = null;\n    if (snapshot.getRootCauseExecution().isPresent()) {\n        final Execution rootCauseExecution = snapshot.getRootCauseExecution().get();\n        failingTaskName = rootCauseExecution.getVertexWithAttempt();\n        taskManagerLocation = rootCauseExecution.getAssignedResourceLocation();\n    }\n\n    return createRootExceptionHistoryEntry(\n            snapshot.getRootCause(),\n            snapshot.getTimestamp(),\n            failingTaskName,\n            taskManagerLocation,\n            snapshot.getConcurrentlyFailedExecution());\n}", "summary_tokens": ["creates", "a", "root", "exception", "history", "entry", "based", "on", "the", "passed", "failure", "handling", "result", "snapshot"], "project": "flink"}
{"id": 4357, "code": "public JobID getJobId() {\n    return jobId;\n}", "summary_tokens": ["returns", "the", "task", "s", "job", "id"], "project": "flink"}
{"id": 3559, "code": "public void testStatsDHistogramReporting() throws Exception {\n    Set<String> expectedLines = new HashSet<>(6);\n    expectedLines.add(\"metric.count:1|g\");\n    expectedLines.add(\"metric.mean:4.0|g\");\n    expectedLines.add(\"metric.min:7|g\");\n    expectedLines.add(\"metric.max:6|g\");\n    expectedLines.add(\"metric.stddev:5.0|g\");\n    expectedLines.add(\"metric.p75:0.75|g\");\n    expectedLines.add(\"metric.p98:0.98|g\");\n    expectedLines.add(\"metric.p99:0.99|g\");\n    expectedLines.add(\"metric.p999:0.999|g\");\n    expectedLines.add(\"metric.p95:0.95|g\");\n    expectedLines.add(\"metric.p50:0.5|g\");\n\n    testMetricAndAssert(new TestHistogram(), \"metric\", expectedLines);\n}", "summary_tokens": ["tests", "that", "histograms", "are", "properly", "reported", "via", "the", "stats", "d", "reporter"], "project": "flink"}
{"id": 2972, "code": "public RetrievableStateHandle<T> addAndLock(String key, T state)\n        throws PossibleInconsistentStateException, Exception {\n    checkNotNull(key, \"Key in ConfigMap.\");\n    checkNotNull(state, \"State.\");\n\n    final RetrievableStateHandle<T> storeHandle = storage.store(state);\n\n    final byte[] serializedStoreHandle = serializeOrDiscard(storeHandle);\n\n        \n    boolean discardState = true;\n    try {\n            \n        discardState =\n                !kubeClient\n                        .checkAndUpdateConfigMap(\n                                configMapName,\n                                c -> {\n                                    if (KubernetesLeaderElector.hasLeadership(\n                                            c, lockIdentity)) {\n                                        if (!c.getData().containsKey(key)) {\n                                            c.getData()\n                                                    .put(\n                                                            key,\n                                                            encodeStateHandle(\n                                                                    serializedStoreHandle));\n                                            return Optional.of(c);\n                                        } else {\n                                            throw new CompletionException(\n                                                    getKeyAlreadyExistException(key));\n                                        }\n                                    }\n                                    return Optional.empty();\n                                })\n                        .get();\n        return storeHandle;\n    } catch (Exception ex) {\n        final Optional<PossibleInconsistentStateException> possibleInconsistentStateException =\n                ExceptionUtils.findThrowable(ex, PossibleInconsistentStateException.class);\n        if (possibleInconsistentStateException.isPresent()) {\n                \n                \n            discardState = false;\n            throw possibleInconsistentStateException.get();\n        }\n\n        throw ExceptionUtils.findThrowable(ex, AlreadyExistException.class)\n                .orElseThrow(() -> ex);\n    } finally {\n        if (discardState) {\n            storeHandle.discardState();\n        }\n    }\n}", "summary_tokens": ["creates", "a", "state", "handle", "stores", "it", "in", "config", "map"], "project": "flink"}
{"id": 66, "code": "public void invokeInteractiveModeForExecution() throws ProgramInvocationException {\n    FlinkSecurityManager.monitorUserSystemExitForCurrentThread();\n    try {\n        callMainMethod(mainClass, args);\n    } finally {\n        FlinkSecurityManager.unmonitorUserSystemExitForCurrentThread();\n    }\n}", "summary_tokens": ["this", "method", "assumes", "that", "the", "context", "environment", "is", "prepared", "or", "the", "execution", "will", "be", "a", "local", "execution", "by", "default"], "project": "flink"}
{"id": 9442, "code": "private long localMills(long epochMills) {\n    return toUtcTimestampMills(epochMills, shiftTimeZone);\n}", "summary_tokens": ["get", "the", "timestamp", "in", "mills", "by", "given", "epoch", "mills", "and", "timezone"], "project": "flink"}
{"id": 3600, "code": "public void setShipStrategy(ShipStrategyType strategy) {\n    this.shipStrategy = strategy;\n}", "summary_tokens": ["sets", "the", "shipping", "strategy", "for", "this", "connection"], "project": "flink"}
{"id": 9348, "code": "public static LogicalType fromDataTypeToLogicalType(DataType dataType) {\n    return PlannerTypeUtils.removeLegacyTypes(dataType.getLogicalType());\n}", "summary_tokens": ["it", "convert", "legacy", "type", "information", "type", "to", "planner", "types"], "project": "flink"}
{"id": 6418, "code": "public void testRegisterUnknownWorker() throws Exception {\n    new Context() {\n        {\n            runTest(\n                    () -> {\n                        CompletableFuture<RegistrationResponse> registerTaskExecutorFuture =\n                                registerTaskExecutor(ResourceID.generate());\n                        assertThat(\n                                registerTaskExecutorFuture.get(TIMEOUT_SEC, TimeUnit.SECONDS),\n                                instanceOf(RegistrationResponse.Rejection.class));\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "decline", "unknown", "worker", "registration"], "project": "flink"}
{"id": 8913, "code": "public String[] getCompletionHints(String statement, int cursor) {\n    String normalizedStatement = statement.trim().toUpperCase();\n    List<String> hints = new ArrayList<>();\n    for (ExtendedParseStrategy strategy : PARSE_STRATEGIES) {\n        for (String hint : strategy.getHints()) {\n            if (hint.startsWith(normalizedStatement) && cursor < hint.length()) {\n                hints.add(getCompletionHint(normalizedStatement, hint));\n            }\n        }\n    }\n\n    return hints.toArray(new String[0]);\n}", "summary_tokens": ["returns", "completion", "hints", "for", "the", "given", "statement", "at", "the", "given", "cursor", "position"], "project": "flink"}
{"id": 9752, "code": "public EnumSet getSchedulerResourceTypes() {\n    return EnumSet.copyOf(Collections.<Enum>emptySet());\n}", "summary_tokens": ["the", "annotation", "is", "intentionally", "removed", "for", "this", "method", "to", "align", "with", "the", "production", "codes", "assumption", "that", "this", "interface", "may", "not", "be", "available", "for", "the", "given", "hadoop", "version"], "project": "flink"}
{"id": 1078, "code": "public void registerKryoType(Class<?> type) {\n    if (type == null) {\n        throw new NullPointerException(\"Cannot register null type class.\");\n    }\n    registeredKryoTypes.add(type);\n}", "summary_tokens": ["registers", "the", "given", "type", "with", "the", "serialization", "stack"], "project": "flink"}
{"id": 7556, "code": "public void copyTo(T valueCopy, StreamRecord<T> target) {\n    target.value = valueCopy;\n    target.timestamp = this.timestamp;\n    target.hasTimestamp = this.hasTimestamp;\n}", "summary_tokens": ["copies", "this", "record", "into", "the", "new", "stream", "record"], "project": "flink"}
{"id": 3534, "code": "default <T, G extends Gauge<T>> G gauge(int name, G gauge) {\n    return gauge(String.valueOf(name), gauge);\n}", "summary_tokens": ["registers", "a", "new", "org"], "project": "flink"}
{"id": 8553, "code": "static Set<FunctionTemplate> extractGlobalFunctionTemplates(\n        DataTypeFactory typeFactory, Class<? extends UserDefinedFunction> function) {\n    return asFunctionTemplates(\n            typeFactory, collectAnnotationsOfClass(FunctionHint.class, function));\n}", "summary_tokens": ["retrieve", "global", "templates", "from", "function", "class"], "project": "flink"}
{"id": 9660, "code": "public int createList() {\n    lists.add(new ArrayList<Comparable>());\n    return lists.size() - 1;\n}", "summary_tokens": ["creates", "and", "stores", "a", "list", "returns", "with", "the", "id"], "project": "flink"}
{"id": 5766, "code": "private void testGetFailsIncoming(@Nullable final JobID jobId, BlobKey.BlobType blobType)\n        throws IOException {\n    assumeTrue(!OperatingSystem.isWindows()); \n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    File tempFileDir = null;\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n            \n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n        BlobKey blobKey = put(server, jobId, data, blobType);\n        verifyType(blobType, blobKey);\n\n            \n        if (blobType == PERMANENT_BLOB) {\n            tempFileDir =\n                    cache.getPermanentBlobService().createTemporaryFilename().getParentFile();\n        } else {\n            tempFileDir =\n                    cache.getTransientBlobService().createTemporaryFilename().getParentFile();\n        }\n        assertTrue(tempFileDir.setExecutable(true, false));\n        assertTrue(tempFileDir.setReadable(true, false));\n        assertTrue(tempFileDir.setWritable(false, false));\n\n            \n        exception.expect(IOException.class);\n        exception.expectMessage(\"Failed to fetch BLOB \");\n\n        try {\n            get(cache, jobId, blobKey);\n        } finally {\n            HashSet<String> expectedDirs = new HashSet<>();\n            expectedDirs.add(\"incoming\");\n            if (jobId != null) {\n                    \n                expectedDirs.add(JOB_DIR_PREFIX + jobId);\n                File storageDir = tempFileDir.getParentFile();\n                String[] actualDirs = storageDir.list();\n                assertNotNull(actualDirs);\n                assertEquals(expectedDirs, new HashSet<>(Arrays.asList(actualDirs)));\n\n                    \n                File jobDir = new File(tempFileDir.getParentFile(), JOB_DIR_PREFIX + jobId);\n                assertArrayEquals(new String[] {}, jobDir.list());\n            } else {\n                    \n                expectedDirs.add(NO_JOB_DIR_PREFIX);\n                File storageDir = tempFileDir.getParentFile();\n                String[] actualDirs = storageDir.list();\n                assertNotNull(actualDirs);\n                assertEquals(expectedDirs, new HashSet<>(Arrays.asList(actualDirs)));\n\n                    \n                File noJobDir = new File(tempFileDir.getParentFile(), NO_JOB_DIR_PREFIX);\n                assertArrayEquals(new String[] {}, noJobDir.list());\n            }\n\n                \n            assertTrue(server.getStorageLocation(jobId, blobKey).exists());\n        }\n    } finally {\n            \n        if (tempFileDir != null) {\n                \n            tempFileDir.setWritable(true, false);\n        }\n    }\n}", "summary_tokens": ["retrieves", "a", "blob", "via", "a", "blob", "cache", "service", "which", "cannot", "create", "incoming", "files"], "project": "flink"}
{"id": 4416, "code": "public void cancel() {\n    for (ExecutionVertex ev : getTaskVertices()) {\n        ev.cancel();\n    }\n}", "summary_tokens": ["cancels", "all", "currently", "running", "vertex", "executions"], "project": "flink"}
{"id": 4497, "code": "public MemorySegment getNextReturnedBlock() throws IOException {\n    try {\n        while (true) {\n            final MemorySegment next = returnSegments.poll(1000, TimeUnit.MILLISECONDS);\n            if (next != null) {\n                return next;\n            } else {\n                if (this.closed) {\n                    throw new IOException(\"The writer has been closed.\");\n                }\n                checkErroneous();\n            }\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(\n                \"Writer was interrupted while waiting for the next returning segment.\");\n    }\n}", "summary_tokens": ["gets", "the", "next", "memory", "segment", "that", "has", "been", "written", "and", "is", "available", "again"], "project": "flink"}
{"id": 3175, "code": "public <T> Graph<K, VV, EV> joinWithEdges(\n        DataSet<Tuple3<K, K, T>> inputDataSet, final EdgeJoinFunction<EV, T> edgeJoinFunction) {\n\n    DataSet<Edge<K, EV>> resultedEdges =\n            this.getEdges()\n                    .coGroup(inputDataSet)\n                    .where(0, 1)\n                    .equalTo(0, 1)\n                    .with(new ApplyCoGroupToEdgeValues<>(edgeJoinFunction))\n                    .name(\"Join with edges\");\n    return new Graph<>(this.vertices, resultedEdges, this.context);\n}", "summary_tokens": ["joins", "the", "edge", "data", "set", "with", "an", "input", "data", "set", "on", "the", "composite", "key", "of", "both", "source", "and", "target", "ids", "and", "applies", "a", "user", "defined", "transformation", "on", "the", "values", "of", "the", "matched", "records"], "project": "flink"}
{"id": 1086, "code": "public void configure(ReadableConfig configuration, ClassLoader classLoader) {\n    configuration\n            .getOptional(PipelineOptions.AUTO_TYPE_REGISTRATION)\n            .ifPresent(b -> this.autoTypeRegistrationEnabled = b);\n    configuration\n            .getOptional(PipelineOptions.AUTO_GENERATE_UIDS)\n            .ifPresent(b -> this.enableAutoGeneratedUids = b);\n    configuration\n            .getOptional(PipelineOptions.AUTO_WATERMARK_INTERVAL)\n            .ifPresent(i -> this.setAutoWatermarkInterval(i.toMillis()));\n    configuration\n            .getOptional(PipelineOptions.CLOSURE_CLEANER_LEVEL)\n            .ifPresent(this::setClosureCleanerLevel);\n    configuration.getOptional(PipelineOptions.FORCE_AVRO).ifPresent(b -> this.forceAvro = b);\n    configuration\n            .getOptional(PipelineOptions.GENERIC_TYPES)\n            .ifPresent(b -> this.disableGenericTypes = !b);\n    configuration.getOptional(PipelineOptions.FORCE_KRYO).ifPresent(b -> this.forceKryo = b);\n    configuration\n            .getOptional(PipelineOptions.GLOBAL_JOB_PARAMETERS)\n            .<GlobalJobParameters>map(MapBasedJobParameters::new)\n            .ifPresent(this::setGlobalJobParameters);\n\n    configuration\n            .getOptional(MetricOptions.LATENCY_INTERVAL)\n            .ifPresent(this::setLatencyTrackingInterval);\n\n    configuration\n            .getOptional(StateChangelogOptions.PERIODIC_MATERIALIZATION_INTERVAL)\n            .ifPresent(this::setPeriodicMaterializeIntervalMillis);\n    configuration\n            .getOptional(StateChangelogOptions.MATERIALIZATION_MAX_FAILURES_ALLOWED)\n            .ifPresent(this::setMaterializationMaxAllowedFailures);\n\n    configuration\n            .getOptional(PipelineOptions.MAX_PARALLELISM)\n            .ifPresent(this::setMaxParallelism);\n    configuration.getOptional(CoreOptions.DEFAULT_PARALLELISM).ifPresent(this::setParallelism);\n    configuration\n            .getOptional(PipelineOptions.OBJECT_REUSE)\n            .ifPresent(o -> this.objectReuse = o);\n    configuration\n            .getOptional(TaskManagerOptions.TASK_CANCELLATION_INTERVAL)\n            .ifPresent(this::setTaskCancellationInterval);\n    configuration\n            .getOptional(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT)\n            .ifPresent(this::setTaskCancellationTimeout);\n    configuration\n            .getOptional(ExecutionOptions.SNAPSHOT_COMPRESSION)\n            .ifPresent(this::setUseSnapshotCompression);\n    RestartStrategies.fromConfiguration(configuration).ifPresent(this::setRestartStrategy);\n    configuration\n            .getOptional(PipelineOptions.KRYO_DEFAULT_SERIALIZERS)\n            .map(s -> parseKryoSerializersWithExceptionHandling(classLoader, s))\n            .ifPresent(s -> this.defaultKryoSerializerClasses = s);\n\n    configuration\n            .getOptional(PipelineOptions.POJO_REGISTERED_CLASSES)\n            .map(c -> loadClasses(c, classLoader, \"Could not load pojo type to be registered.\"))\n            .ifPresent(c -> this.registeredPojoTypes = c);\n\n    configuration\n            .getOptional(PipelineOptions.KRYO_REGISTERED_CLASSES)\n            .map(c -> loadClasses(c, classLoader, \"Could not load kryo type to be registered.\"))\n            .ifPresent(c -> this.registeredKryoTypes = c);\n}", "summary_tokens": ["sets", "all", "relevant", "options", "contained", "in", "the", "readable", "config", "such", "as", "e"], "project": "flink"}
{"id": 4060, "code": "public static void terminateRpcEndpoint(RpcEndpoint rpcEndpoint, Time timeout)\n        throws ExecutionException, InterruptedException, TimeoutException {\n    rpcEndpoint.closeAsync().get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["shuts", "the", "given", "rpc", "endpoint", "down", "and", "awaits", "its", "termination"], "project": "flink"}
{"id": 2111, "code": "public static boolean isCompletedNormally(CompletableFuture<?> future) {\n    return future.isDone() && !future.isCompletedExceptionally();\n}", "summary_tokens": ["true", "if", "future", "has", "completed", "normally", "false", "otherwise"], "project": "flink"}
{"id": 5543, "code": "public Long getFrameworkOffHeap() {\n    return frameworkOffHeap;\n}", "summary_tokens": ["returns", "the", "configured", "off", "heap", "size", "used", "by", "the", "framework"], "project": "flink"}
{"id": 1998, "code": "public LinkedHashMap<K, V> unwrapOptionals() {\n    final LinkedHashMap<K, V> unwrapped = new LinkedHashMap<>(underlyingMap.size());\n\n    for (Entry<String, KeyValue<K, V>> entry : underlyingMap.entrySet()) {\n        String namedKey = entry.getKey();\n        KeyValue<K, V> kv = entry.getValue();\n        if (kv.key == null) {\n            throw new IllegalStateException(\"Missing key '\" + namedKey + \"'\");\n        }\n        if (kv.value == null) {\n            throw new IllegalStateException(\"Missing value for the key '\" + namedKey + \"'\");\n        }\n        unwrapped.put(kv.key, kv.value);\n    }\n    return unwrapped;\n}", "summary_tokens": ["assuming", "all", "the", "entries", "of", "this", "map", "are", "present", "keys", "and", "values", "this", "method", "would", "return", "a", "map", "with", "these", "key", "and", "values", "stripped", "from", "their", "optional", "wrappers"], "project": "flink"}
{"id": 2663, "code": "public UnionOperator<T> union(DataSet<T> other) {\n    return new UnionOperator<>(this, other, Utils.getCallLocationName());\n}", "summary_tokens": ["creates", "a", "union", "of", "this", "data", "set", "with", "an", "other", "data", "set"], "project": "flink"}
{"id": 4247, "code": "private void reportFailedCheckpoint(Exception cause, PendingCheckpointStats statsCallback) {\n        \n    if (statsCallback != null) {\n        long failureTimestamp = System.currentTimeMillis();\n        statsCallback.reportFailedCheckpoint(failureTimestamp, cause);\n    }\n}", "summary_tokens": ["reports", "a", "failed", "checkpoint", "with", "the", "given", "optional", "cause"], "project": "flink"}
{"id": 9255, "code": "public Set<Map.Entry<RowData, Collection<RowData>>> entrySet() {\n    return treeMap.entrySet();\n}", "summary_tokens": ["returns", "a", "set", "view", "of", "the", "mappings", "contained", "in", "the", "buffer"], "project": "flink"}
{"id": 4856, "code": "public void releaseAllMemory(Object owner) {\n    checkMemoryReservationPreconditions(owner, 0L);\n    Long memoryReservedForOwner = reservedMemory.remove(owner);\n    if (memoryReservedForOwner != null) {\n        memoryBudget.releaseMemory(memoryReservedForOwner);\n    }\n}", "summary_tokens": ["releases", "all", "reserved", "memory", "chunks", "from", "an", "owner", "to", "this", "memory", "manager"], "project": "flink"}
{"id": 2780, "code": "public Partitioner<?> getCustomPartitioner() {\n    return this.customPartitioner;\n}", "summary_tokens": ["gets", "the", "custom", "partitioner", "to", "be", "used", "for", "this", "grouping", "or", "null", "if", "none", "was", "defined"], "project": "flink"}
{"id": 7473, "code": "public static ProcessingTimeTrigger create() {\n    return new ProcessingTimeTrigger();\n}", "summary_tokens": ["creates", "a", "new", "trigger", "that", "fires", "once", "system", "time", "passes", "the", "end", "of", "the", "window"], "project": "flink"}
{"id": 2383, "code": "public File getFile(String dirsProp, String path) throws IOException {\n    String[] dirs = getTrimmedStrings(dirsProp);\n    int hashCode = path.hashCode();\n    for (int i = 0; i < dirs.length; i++) { \n        int index = (hashCode + i & Integer.MAX_VALUE) % dirs.length;\n        File file = new File(dirs[index], path);\n        File dir = file.getParentFile();\n        if (dir.exists() || dir.mkdirs()) {\n            return file;\n        }\n    }\n    throw new IOException(\"No valid local directories in property: \" + dirsProp);\n}", "summary_tokens": ["get", "a", "local", "file", "name", "under", "a", "directory", "named", "in", "i", "dirs", "prop", "i", "with", "the", "given", "i", "path", "i"], "project": "flink"}
{"id": 3623, "code": "public void initId(int id) {\n    if (id <= 0) {\n        throw new IllegalArgumentException();\n    }\n\n    if (this.id == -1) {\n        this.id = id;\n    } else {\n        throw new IllegalStateException(\"Id has already been initialized.\");\n    }\n}", "summary_tokens": ["sets", "the", "id", "of", "this", "node"], "project": "flink"}
{"id": 5221, "code": "public Map<PathPattern, T> routes() {\n    return Collections.unmodifiableMap(routes);\n}", "summary_tokens": ["returns", "all", "routes", "in", "this", "router", "an", "unmodifiable", "map", "of", "path", "pattern", "target"], "project": "flink"}
{"id": 5770, "code": "private void testConcurrentGetOperations(\n        final JobID jobId, final BlobKey.BlobType blobType, final boolean cacheAccessesHAStore)\n        throws IOException, InterruptedException, ExecutionException {\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    final BlobStore blobStoreServer = mock(BlobStore.class);\n    final BlobStore blobStoreCache = mock(BlobStore.class);\n\n    final int numberConcurrentGetOperations = 3;\n    final List<CompletableFuture<File>> getOperations =\n            new ArrayList<>(numberConcurrentGetOperations);\n\n    final byte[] data = {1, 2, 3, 4, 99, 42};\n\n    final ExecutorService executor =\n            Executors.newFixedThreadPool(numberConcurrentGetOperations);\n\n    try (final BlobServer server = new BlobServer(config, blobStoreServer);\n            final BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            cacheAccessesHAStore ? blobStoreServer : blobStoreCache,\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n            \n        final BlobKey blobKey = put(server, jobId, data, blobType);\n\n            \n            \n        for (int i = 0; i < numberConcurrentGetOperations; i++) {\n            CompletableFuture<File> getOperation =\n                    CompletableFuture.supplyAsync(\n                            () -> {\n                                try {\n                                    File file = get(cache, jobId, blobKey);\n                                        \n                                    validateGetAndClose(new FileInputStream(file), data);\n                                    return file;\n                                } catch (IOException e) {\n                                    throw new CompletionException(\n                                            new FlinkException(\n                                                    \"Could not read blob for key \"\n                                                            + blobKey\n                                                            + '.',\n                                                    e));\n                                }\n                            },\n                            executor);\n\n            getOperations.add(getOperation);\n        }\n\n        FutureUtils.ConjunctFuture<Collection<File>> filesFuture =\n                FutureUtils.combineAll(getOperations);\n\n        if (blobType == PERMANENT_BLOB) {\n                \n            filesFuture.get();\n        } else {\n                \n                \n            int completedSuccessfully = 0;\n            for (CompletableFuture<File> op : getOperations) {\n                try {\n                    op.get();\n                    ++completedSuccessfully;\n                } catch (Throwable t) {\n                        \n                        \n                        \n                    if (!(ExceptionUtils.getRootCause(t) instanceof FileNotFoundException)) {\n                            \n                        org.apache.flink.util.ExceptionUtils.rethrowIOException(t);\n                    }\n                }\n            }\n                \n                \n            assertThat(completedSuccessfully, greaterThanOrEqualTo(1));\n        }\n    } finally {\n        executor.shutdownNow();\n    }\n}", "summary_tokens": ["flink", "0", "tests", "that", "concurrent", "get", "operations", "don", "t", "concurrently", "access", "the", "blob", "store", "to", "download", "a", "blob"], "project": "flink"}
{"id": 1027, "code": "public List<Partition> exchange_partitions(Map<String, String> partitionSpecs,\n    String sourceDb, String sourceTable, String destDb,\n    String destinationTableName) throws TException {\n  return exchange_partitions(partitionSpecs, getDefaultCatalog(conf), sourceDb, sourceTable,\n      getDefaultCatalog(conf), destDb, destinationTableName);\n}", "summary_tokens": ["exchange", "the", "partitions", "between", "two", "tables", "partition", "specs", "partitions", "specs", "of", "the", "parent", "partition", "to", "be", "exchanged", "dest", "db", "the", "db", "of", "the", "destination", "table", "destination", "table", "name", "the", "destination", "table", "name", "new", "partitions", "after", "exchanging"], "project": "flink"}
{"id": 9219, "code": "public void processElement2(StreamRecord<RowData> element) throws Exception {\n    RowData input = element.getValue();\n    boolean isAccumulateMsg = RowDataUtil.isAccumulateMsg(input);\n    RowKind inputRowKind = input.getRowKind();\n    input.setRowKind(RowKind.INSERT); \n\n    AssociatedRecords associatedRecords =\n            AssociatedRecords.of(input, false, leftRecordStateView, joinCondition);\n    if (isAccumulateMsg) { \n        rightRecordStateView.addRecord(input);\n        if (!associatedRecords.isEmpty()) {\n                \n            for (OuterRecord outerRecord : associatedRecords.getOuterRecords()) {\n                RowData other = outerRecord.record;\n                if (outerRecord.numOfAssociations == 0) {\n                    if (isAntiJoin) {\n                            \n                        other.setRowKind(RowKind.DELETE);\n                    } else {\n                            \n                        other.setRowKind(inputRowKind);\n                    }\n                    collector.collect(other);\n                        \n                    other.setRowKind(RowKind.INSERT);\n                } \n                leftRecordStateView.updateNumOfAssociations(\n                        other, outerRecord.numOfAssociations + 1);\n            }\n        } \n    } else { \n        rightRecordStateView.retractRecord(input);\n        if (!associatedRecords.isEmpty()) {\n                \n            for (OuterRecord outerRecord : associatedRecords.getOuterRecords()) {\n                RowData other = outerRecord.record;\n                if (outerRecord.numOfAssociations == 1) {\n                    if (!isAntiJoin) {\n                            \n                        other.setRowKind(inputRowKind);\n                    } else {\n                            \n                        other.setRowKind(RowKind.INSERT);\n                    }\n                    collector.collect(other);\n                        \n                    other.setRowKind(RowKind.INSERT);\n                } \n                leftRecordStateView.updateNumOfAssociations(\n                        other, outerRecord.numOfAssociations - 1);\n            }\n        } \n    }\n}", "summary_tokens": ["process", "an", "input", "element", "and", "output", "incremental", "joined", "records", "retraction", "messages", "will", "be", "sent", "in", "some", "scenarios"], "project": "flink"}
{"id": 7298, "code": "static <IN, BucketID> Bucket<IN, BucketID> getNew(\n        final int subtaskIndex,\n        final BucketID bucketId,\n        final Path bucketPath,\n        final long initialPartCounter,\n        final BucketWriter<IN, BucketID> bucketWriter,\n        final RollingPolicy<IN, BucketID> rollingPolicy,\n        @Nullable final FileLifeCycleListener<BucketID> fileListener,\n        final OutputFileConfig outputFileConfig) {\n    return new Bucket<>(\n            subtaskIndex,\n            bucketId,\n            bucketPath,\n            initialPartCounter,\n            bucketWriter,\n            rollingPolicy,\n            fileListener,\n            outputFileConfig);\n}", "summary_tokens": ["creates", "a", "new", "empty", "bucket"], "project": "flink"}
{"id": 3480, "code": "public <K, OUT> DataStream<OUT> readKeyedState(\n        String uid,\n        KeyedStateReaderFunction<K, OUT> function,\n        TypeInformation<K> keyTypeInfo,\n        TypeInformation<OUT> outTypeInfo)\n        throws IOException {\n\n    OperatorState operatorState = metadata.getOperatorState(uid);\n    KeyedStateInputFormat<K, VoidNamespace, OUT> inputFormat =\n            new KeyedStateInputFormat<>(\n                    operatorState,\n                    stateBackend,\n                    MutableConfig.of(env.getConfiguration()),\n                    new KeyedStateReaderOperator<>(function, keyTypeInfo));\n\n    return SourceBuilder.fromFormat(env, inputFormat, outTypeInfo);\n}", "summary_tokens": ["read", "keyed", "state", "from", "an", "operator", "in", "a", "savepoint"], "project": "flink"}
{"id": 1138, "code": "public boolean isConverged(int iteration, LongValue value) {\n    return value.getValue() == 0;\n}", "summary_tokens": ["returns", "true", "if", "the", "aggregator", "value", "is", "zero", "false", "otherwise"], "project": "flink"}
{"id": 5225, "code": "public boolean anyMatched(String[] requestPathTokens) {\n    Map<String, String> pathParams = new HashMap<>();\n    for (PathPattern pattern : routes.keySet()) {\n        if (pattern.match(requestPathTokens, pathParams)) {\n            return true;\n        }\n\n            \n        pathParams.clear();\n    }\n\n    return false;\n}", "summary_tokens": ["checks", "if", "there", "s", "any", "matching", "route"], "project": "flink"}
{"id": 6623, "code": "public void testWriteAndRead() throws Exception {\n    final FileSystem fs = FileSystem.getLocalFileSystem();\n    final Path folder = baseFolder();\n    final String fileName = \"fooBarName\";\n\n    final Random rnd = new Random();\n    final byte[] data = new byte[1694523];\n\n        \n    final FileStateHandle handle;\n    try (FSDataOutputStream stream = createTestStream(fs, folder, fileName)) {\n        for (int i = 0; i < data.length; ) {\n            if (rnd.nextBoolean()) {\n                stream.write(data[i++]);\n            } else {\n                int len = rnd.nextInt(Math.min(data.length - i, 32));\n                stream.write(data, i, len);\n                i += len;\n            }\n        }\n        handle = closeAndGetResult(stream);\n    }\n\n        \n    try (FSDataInputStream in = handle.openInputStream()) {\n        byte[] buffer = new byte[data.length];\n        readFully(in, buffer);\n        assertArrayEquals(data, buffer);\n    }\n\n        \n    try (FSDataInputStream in = fs.open(handle.getFilePath())) {\n        byte[] buffer = new byte[data.length];\n        readFully(in, buffer);\n        assertArrayEquals(data, buffer);\n    }\n}", "summary_tokens": ["simple", "write", "and", "read", "test"], "project": "flink"}
{"id": 7259, "code": "public <OUT> DataStreamSource<OUT> readFile(\n        FileInputFormat<OUT> inputFormat,\n        String filePath,\n        FileProcessingMode watchType,\n        long interval,\n        TypeInformation<OUT> typeInformation) {\n\n    Preconditions.checkNotNull(inputFormat, \"InputFormat must not be null.\");\n    Preconditions.checkArgument(\n            !StringUtils.isNullOrWhitespaceOnly(filePath),\n            \"The file path must not be null or blank.\");\n\n    inputFormat.setFilePath(filePath);\n    return createFileInput(\n            inputFormat, typeInformation, \"Custom File Source\", watchType, interval);\n}", "summary_tokens": ["reads", "the", "contents", "of", "the", "user", "specified", "file", "path", "based", "on", "the", "given", "file", "input", "format"], "project": "flink"}
{"id": 1647, "code": "public String getValue(ConfigOption<?> configOption) {\n    return Optional.ofNullable(\n                    getRawValueFromOption(configOption).orElseGet(configOption::defaultValue))\n            .map(String::valueOf)\n            .orElse(null);\n}", "summary_tokens": ["returns", "the", "value", "associated", "with", "the", "given", "config", "option", "as", "a", "string"], "project": "flink"}
{"id": 1248, "code": "public void setParallelism(int parallelism) {\n    this.parallelism = parallelism;\n}", "summary_tokens": ["sets", "the", "parallelism", "for", "this", "contract", "instance"], "project": "flink"}
{"id": 8150, "code": "public static Schema.Builder newBuilder() {\n    return new Builder();\n}", "summary_tokens": ["builder", "for", "configuring", "and", "creating", "instances", "of", "schema"], "project": "flink"}
{"id": 6297, "code": "public void testPendingBatchSlotRequestDoesNotTimeoutIfFulfillingSlotExists() throws Exception {\n    final Time batchSlotTimeout = Time.milliseconds(2L);\n    final ManualClock clock = new ManualClock();\n\n    try (final DeclarativeSlotPoolBridge slotPool =\n            createAndSetUpSlotPool(mainThreadExecutor, null, batchSlotTimeout, clock)) {\n\n        SlotPoolUtils.requestNewAllocatedBatchSlot(\n                slotPool, mainThreadExecutor, resourceProfile);\n\n        SlotPoolUtils.offerSlots(slotPool, mainThreadExecutor, Arrays.asList(resourceProfile));\n\n        final CompletableFuture<PhysicalSlot> firstPendingSlotFuture =\n                SlotPoolUtils.requestNewAllocatedBatchSlot(\n                        slotPool, mainThreadExecutor, ResourceProfile.UNKNOWN);\n        final CompletableFuture<PhysicalSlot> secondPendingSlotFuture =\n                SlotPoolUtils.requestNewAllocatedBatchSlot(\n                        slotPool, mainThreadExecutor, resourceProfile);\n\n        final List<CompletableFuture<PhysicalSlot>> slotFutures =\n                Arrays.asList(firstPendingSlotFuture, secondPendingSlotFuture);\n\n        advanceTimeAndTriggerCheckBatchSlotTimeout(\n                slotPool, mainThreadExecutor, clock, batchSlotTimeout);\n\n        for (CompletableFuture<PhysicalSlot> slotFuture : slotFutures) {\n            assertThat(slotFuture.isDone(), is(false));\n        }\n    }\n}", "summary_tokens": ["tests", "that", "a", "batch", "slot", "request", "won", "t", "time", "out", "if", "there", "exists", "a", "slot", "in", "the", "slot", "pool", "which", "fulfills", "the", "requested", "resource", "profile"], "project": "flink"}
{"id": 7526, "code": "public long getTimestamp() {\n    if (hasTimestamp) {\n        return timestamp;\n    } else {\n        throw new IllegalStateException(\n                \"Record has no timestamp. Is the time characteristic set to 'ProcessingTime', or \"\n                        + \"did you forget to call 'DataStream.assignTimestampsAndWatermarks(...)'?\");\n    }\n}", "summary_tokens": ["the", "timestamp", "associated", "with", "this", "stream", "value", "in", "milliseconds"], "project": "flink"}
{"id": 4737, "code": "public void setShipStrategyName(String shipStrategyName) {\n    this.shipStrategyName = shipStrategyName;\n}", "summary_tokens": ["sets", "the", "name", "of", "the", "ship", "strategy", "for", "the", "represented", "input"], "project": "flink"}
{"id": 2948, "code": "public final R summarize(T... values) {\n    if (values.length == 0) {\n            \n            \n        A agg1 = initAggregator();\n        agg1.combine(initAggregator());\n        return agg1.result();\n    } else {\n        R previousResult = null;\n        R result = null;\n\n            \n            \n        List<T> list = Arrays.asList(values);\n        Collections.shuffle(list);\n\n        for (int i = 0; i < values.length; i++) {\n\n                \n                \n                \n                \n                \n\n            A aggregator1 = initAggregator();\n            A aggregator2 = initAggregator();\n\n            for (int j = 0; j < i; j++) {\n                aggregator1.aggregate(list.get(j));\n            }\n            for (int j = i; j < values.length; j++) {\n                aggregator2.aggregate(list.get(j));\n            }\n\n            aggregator1.combine(aggregator2);\n\n            previousResult = result;\n            result = aggregator1.result();\n\n            if (previousResult != null) {\n                    \n                    \n                compareResults(result, previousResult);\n            }\n        }\n        return result;\n    }\n}", "summary_tokens": ["variously", "aggregate", "and", "combine", "against", "a", "list", "of", "values", "comparing", "results", "each", "time"], "project": "flink"}
{"id": 3121, "code": "public static <T> NFA<T> compile(Pattern<T, ?> pattern, boolean timeoutHandling) {\n    NFACompiler.NFAFactory<T> factory = compileFactory(pattern, timeoutHandling);\n    return factory.createNFA();\n}", "summary_tokens": ["compiles", "the", "given", "pattern", "into", "a", "nfa"], "project": "flink"}
{"id": 3320, "code": "public JaccardIndex<K, VV, EV> setGroupSize(int groupSize) {\n    Preconditions.checkArgument(groupSize > 0, \"Group size must be greater than zero\");\n\n    this.groupSize = groupSize;\n\n    return this;\n}", "summary_tokens": ["override", "the", "default", "group", "size", "for", "the", "quadratic", "expansion", "of", "neighbor", "pairs"], "project": "flink"}
{"id": 1094, "code": "public static JobID fromHexString(String hexString) {\n    try {\n        return new JobID(StringUtils.hexStringToByte(hexString));\n    } catch (Exception e) {\n        throw new IllegalArgumentException(\n                \"Cannot parse JobID from \\\"\"\n                        + hexString\n                        + \"\\\". The expected format is \"\n                        + \"[0-9a-fA-F]{32}, e.g. fd72014d4c864993a2e5a9287b4a9c5d.\",\n                e);\n    }\n}", "summary_tokens": ["parses", "a", "job", "id", "from", "the", "given", "string"], "project": "flink"}
{"id": 7401, "code": "public void processElement2(StreamRecord<T2> record) throws Exception {\n    processElement(record, rightBuffer, leftBuffer, -upperBound, -lowerBound, false);\n}", "summary_tokens": ["process", "a", "stream", "record", "from", "the", "right", "stream"], "project": "flink"}
{"id": 2143, "code": "public void testOneNestedDirectoryFalse() {\n    try {\n        String firstLevelDir = TestFileUtils.randomFileName();\n        String secondLevelDir = TestFileUtils.randomFileName();\n\n        File insideNestedDir = tempFolder.newFolder(firstLevelDir, secondLevelDir);\n        File nestedDir = insideNestedDir.getParentFile();\n\n            \n        TestFileUtils.createTempFileInDirectory(nestedDir.getAbsolutePath(), \"paella\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"kalamari\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"fideua\");\n\n        this.format.setFilePath(new Path(nestedDir.toURI().toString()));\n        this.config.setBoolean(\"recursive.file.enumeration\", false);\n        format.configure(this.config);\n\n        FileInputSplit[] splits = format.createInputSplits(1);\n        Assert.assertEquals(1, splits.length);\n    } catch (Exception ex) {\n        ex.printStackTrace();\n        Assert.fail(ex.getMessage());\n    }\n}", "summary_tokens": ["test", "with", "one", "nested", "directory", "and", "recursive"], "project": "flink"}
{"id": 5162, "code": "private void checkResourceRequirements() {\n    if (!started) {\n        return;\n    }\n    Map<JobID, Collection<ResourceRequirement>> missingResources =\n            resourceTracker.getMissingResources();\n    if (missingResources.isEmpty()) {\n        return;\n    }\n\n    LOG.info(\"Matching resource requirements against available resources.\");\n    missingResources =\n            missingResources.entrySet().stream()\n                    .collect(\n                            Collectors.toMap(\n                                    Map.Entry::getKey, e -> new ArrayList<>(e.getValue())));\n\n    final ResourceAllocationResult result =\n            resourceAllocationStrategy.tryFulfillRequirements(\n                    missingResources, taskManagerTracker);\n\n        \n    allocateSlotsAccordingTo(result.getAllocationsOnRegisteredResources());\n\n        \n    final Set<PendingTaskManagerId> failAllocations =\n            allocateTaskManagersAccordingTo(result.getPendingTaskManagersToAllocate());\n\n        \n    final Map<PendingTaskManagerId, Map<JobID, ResourceCounter>>\n            pendingResourceAllocationResult =\n                    new HashMap<>(result.getAllocationsOnPendingResources());\n    pendingResourceAllocationResult.keySet().removeAll(failAllocations);\n    taskManagerTracker.replaceAllPendingAllocations(pendingResourceAllocationResult);\n\n    unfulfillableJobs.clear();\n    unfulfillableJobs.addAll(result.getUnfulfillableJobs());\n    for (PendingTaskManagerId pendingTaskManagerId : failAllocations) {\n        unfulfillableJobs.addAll(\n                result.getAllocationsOnPendingResources().get(pendingTaskManagerId).keySet());\n    }\n        \n    if (sendNotEnoughResourceNotifications) {\n        for (JobID jobId : unfulfillableJobs) {\n            LOG.warn(\"Could not fulfill resource requirements of job {}.\", jobId);\n            resourceActions.notifyNotEnoughResourcesAvailable(\n                    jobId, resourceTracker.getAcquiredResources(jobId));\n        }\n    }\n}", "summary_tokens": ["do", "not", "call", "this", "method", "directly"], "project": "flink"}
{"id": 6547, "code": "public void testConfigureJobManagerStorageWithParameters() throws Exception {\n    final String savepointDirConfig = new Path(tmp.newFolder().toURI()).toString();\n    final Path savepointDirJob = new Path(tmp.newFolder().toURI());\n\n    final Configuration config = new Configuration();\n    config.set(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDirConfig);\n\n    CheckpointStorage storage =\n            CheckpointStorageLoader.load(\n                    new JobManagerCheckpointStorage(),\n                    savepointDirJob,\n                    new ModernStateBackend(),\n                    config,\n                    cl,\n                    log);\n\n    Assert.assertThat(storage, Matchers.instanceOf(JobManagerCheckpointStorage.class));\n    JobManagerCheckpointStorage jmStorage = (JobManagerCheckpointStorage) storage;\n    Assert.assertThat(jmStorage.getSavepointPath(), normalizedPath(savepointDirJob));\n}", "summary_tokens": ["tests", "that", "job", "parameters", "take", "precedence", "over", "cluster", "configurations"], "project": "flink"}
{"id": 9052, "code": "public void testLookupJoin() {\n    createSourceWithTimeAttribute();\n    String srcTableB =\n            \"CREATE TABLE LookupTable (\\n\"\n                    + \"  id int,\\n\"\n                    + \"  name varchar,\\n\"\n                    + \"  age int \\n\"\n                    + \") with (\\n\"\n                    + \"  'connector' = 'values',\\n\"\n                    + \"  'bounded' = 'true')\";\n    tEnv.executeSql(srcTableB);\n    verifyQuery(\n            \"SELECT * FROM MyTable AS T JOIN LookupTable \"\n                    + \"FOR SYSTEM_TIME AS OF T.proctime AS D ON T.b = D.id\");\n}", "summary_tokens": ["verify", "look", "up", "join"], "project": "flink"}
{"id": 1182, "code": "public FileInputSplit[] createInputSplits(int minNumSplits) throws IOException {\n    if (minNumSplits < 1) {\n        throw new IllegalArgumentException(\"Number of input splits has to be at least 1.\");\n    }\n\n        \n    minNumSplits = Math.max(minNumSplits, this.numSplits);\n\n    final List<FileInputSplit> inputSplits = new ArrayList<FileInputSplit>(minNumSplits);\n\n        \n    List<FileStatus> files = new ArrayList<>();\n    long totalLength = 0;\n\n    for (Path path : getFilePaths()) {\n        final FileSystem fs = path.getFileSystem();\n        final FileStatus pathFile = fs.getFileStatus(path);\n\n        if (pathFile.isDir()) {\n            totalLength += addFilesInDir(path, files, true);\n        } else {\n            testForUnsplittable(pathFile);\n\n            files.add(pathFile);\n            totalLength += pathFile.getLen();\n        }\n    }\n\n        \n    if (unsplittable) {\n        int splitNum = 0;\n        for (final FileStatus file : files) {\n            final FileSystem fs = file.getPath().getFileSystem();\n            final BlockLocation[] blocks = fs.getFileBlockLocations(file, 0, file.getLen());\n            Set<String> hosts = new HashSet<String>();\n            for (BlockLocation block : blocks) {\n                hosts.addAll(Arrays.asList(block.getHosts()));\n            }\n            long len = file.getLen();\n            if (testForUnsplittable(file)) {\n                len = READ_WHOLE_SPLIT_FLAG;\n            }\n            FileInputSplit fis =\n                    new FileInputSplit(\n                            splitNum++,\n                            file.getPath(),\n                            0,\n                            len,\n                            hosts.toArray(new String[hosts.size()]));\n            inputSplits.add(fis);\n        }\n        return inputSplits.toArray(new FileInputSplit[inputSplits.size()]);\n    }\n\n    final long maxSplitSize =\n            totalLength / minNumSplits + (totalLength % minNumSplits == 0 ? 0 : 1);\n\n        \n    int splitNum = 0;\n    for (final FileStatus file : files) {\n\n        final FileSystem fs = file.getPath().getFileSystem();\n        final long len = file.getLen();\n        final long blockSize = file.getBlockSize();\n\n        final long minSplitSize;\n        if (this.minSplitSize <= blockSize) {\n            minSplitSize = this.minSplitSize;\n        } else {\n            if (LOG.isWarnEnabled()) {\n                LOG.warn(\n                        \"Minimal split size of \"\n                                + this.minSplitSize\n                                + \" is larger than the block size of \"\n                                + blockSize\n                                + \". Decreasing minimal split size to block size.\");\n            }\n            minSplitSize = blockSize;\n        }\n\n        final long splitSize = Math.max(minSplitSize, Math.min(maxSplitSize, blockSize));\n        final long halfSplit = splitSize >>> 1;\n\n        final long maxBytesForLastSplit = (long) (splitSize * MAX_SPLIT_SIZE_DISCREPANCY);\n\n        if (len > 0) {\n\n                \n                \n            final BlockLocation[] blocks = fs.getFileBlockLocations(file, 0, len);\n            Arrays.sort(blocks);\n\n            long bytesUnassigned = len;\n            long position = 0;\n\n            int blockIndex = 0;\n\n            while (bytesUnassigned > maxBytesForLastSplit) {\n                    \n                blockIndex = getBlockIndexForPosition(blocks, position, halfSplit, blockIndex);\n                    \n                FileInputSplit fis =\n                        new FileInputSplit(\n                                splitNum++,\n                                file.getPath(),\n                                position,\n                                splitSize,\n                                blocks[blockIndex].getHosts());\n                inputSplits.add(fis);\n\n                    \n                position += splitSize;\n                bytesUnassigned -= splitSize;\n            }\n\n                \n            if (bytesUnassigned > 0) {\n                blockIndex = getBlockIndexForPosition(blocks, position, halfSplit, blockIndex);\n                final FileInputSplit fis =\n                        new FileInputSplit(\n                                splitNum++,\n                                file.getPath(),\n                                position,\n                                bytesUnassigned,\n                                blocks[blockIndex].getHosts());\n                inputSplits.add(fis);\n            }\n        } else {\n                \n            final BlockLocation[] blocks = fs.getFileBlockLocations(file, 0, 0);\n            String[] hosts;\n            if (blocks.length > 0) {\n                hosts = blocks[0].getHosts();\n            } else {\n                hosts = new String[0];\n            }\n            final FileInputSplit fis =\n                    new FileInputSplit(splitNum++, file.getPath(), 0, 0, hosts);\n            inputSplits.add(fis);\n        }\n    }\n\n    return inputSplits.toArray(new FileInputSplit[inputSplits.size()]);\n}", "summary_tokens": ["computes", "the", "input", "splits", "for", "the", "file"], "project": "flink"}
{"id": 2069, "code": "public static String concatenateWithAnd(@Nullable String s1, @Nullable String s2) {\n    if (s1 != null) {\n        return s2 == null ? s1 : s1 + \" and \" + s2;\n    } else {\n        return s2;\n    }\n}", "summary_tokens": ["if", "both", "string", "arguments", "are", "non", "null", "this", "method", "concatenates", "them", "with", "and"], "project": "flink"}
{"id": 7148, "code": "public <T0, T1, T2, T3, T4, T5, T6, T7, T8>\n        SingleOutputStreamOperator<Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>> projectTuple9() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>> tType =\n            new TupleTypeInfo<Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>>(fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<IN, Tuple9<T0, T1, T2, T3, T4, T5, T6, T7, T8>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 3941, "code": "public void testDeserializeMapTooShort2() throws Exception {\n        \n    KvStateSerializer.deserializeMap(\n            new byte[] {1, 1, 1, 1, 1, 1, 1, 1, 0},\n            LongSerializer.INSTANCE,\n            LongSerializer.INSTANCE);\n}", "summary_tokens": ["tests", "map", "deserialization", "with", "too", "few", "bytes"], "project": "flink"}
{"id": 7145, "code": "public <T0, T1, T2, T3, T4, T5>\n        SingleOutputStreamOperator<Tuple6<T0, T1, T2, T3, T4, T5>> projectTuple6() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<Tuple6<T0, T1, T2, T3, T4, T5>> tType =\n            new TupleTypeInfo<Tuple6<T0, T1, T2, T3, T4, T5>>(fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<IN, Tuple6<T0, T1, T2, T3, T4, T5>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 7397, "code": "void removedFromTimerQueue() {\n    setInternalIndex(NOT_CONTAINED);\n}", "summary_tokens": ["this", "method", "can", "be", "called", "to", "indicate", "that", "the", "timer", "is", "no", "longer", "managed", "be", "a", "timer", "heap", "e"], "project": "flink"}
{"id": 6069, "code": "public void testDiamondWithMixedPipelinedAndBlockingEdges() {\n    JobVertex v1 = new JobVertex(\"v1\");\n    JobVertex v2 = new JobVertex(\"v2\");\n    JobVertex v3 = new JobVertex(\"v3\");\n    JobVertex v4 = new JobVertex(\"v4\");\n\n    v2.connectNewDataSetAsInput(\n            v1, DistributionPattern.POINTWISE, ResultPartitionType.BLOCKING);\n    v4.connectNewDataSetAsInput(\n            v2, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);\n    v3.connectNewDataSetAsInput(\n            v1, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);\n    v4.connectNewDataSetAsInput(\n            v3, DistributionPattern.POINTWISE, ResultPartitionType.PIPELINED);\n\n    Set<Set<LogicalVertex>> regions = computePipelinedRegions(v1, v2, v3, v4);\n\n    checkRegionSize(regions, 1, 4);\n}", "summary_tokens": ["tests", "that", "the", "computation", "of", "vertices", "connected", "like", "a", "diamond", "with", "both", "pipelined", "and", "blocking", "edges", "works", "correctly"], "project": "flink"}
{"id": 9481, "code": "public void testRead() throws Exception {\n    try (SourceReader<Integer, SplitT> reader = createReader()) {\n        reader.addSplits(getSplits(numSplits, NUM_RECORDS_PER_SPLIT, Boundedness.BOUNDED));\n        ValidatingSourceOutput output = new ValidatingSourceOutput();\n        while (output.count < totalNumRecords) {\n            reader.pollNext(output);\n        }\n        output.validate();\n    }\n}", "summary_tokens": ["simply", "test", "the", "reader", "reads", "all", "the", "splits", "fine"], "project": "flink"}
{"id": 9533, "code": "public static String getS3AccessKey() {\n    if (S3_TEST_ACCESS_KEY != null) {\n        return S3_TEST_ACCESS_KEY;\n    } else {\n        throw new IllegalStateException(\"S3 test access key not available\");\n    }\n}", "summary_tokens": ["gets", "the", "s", "0", "access", "key"], "project": "flink"}
{"id": 8250, "code": "public String getRowtimeAttribute() {\n    return rowtimeAttribute;\n}", "summary_tokens": ["returns", "the", "name", "of", "a", "rowtime", "attribute"], "project": "flink"}
{"id": 1585, "code": "private <IN1, IN2> TypeInformation<?>[] createSubTypesInfo(\n        Type originalType,\n        ParameterizedType definingType,\n        List<Type> typeHierarchy,\n        TypeInformation<IN1> in1Type,\n        TypeInformation<IN2> in2Type,\n        boolean lenient) {\n    Type[] subtypes = new Type[definingType.getActualTypeArguments().length];\n\n        \n    for (int i = 0; i < subtypes.length; i++) {\n        final Type actualTypeArg = definingType.getActualTypeArguments()[i];\n            \n        if (actualTypeArg instanceof TypeVariable<?>) {\n            subtypes[i] =\n                    materializeTypeVariable(typeHierarchy, (TypeVariable<?>) actualTypeArg);\n        }\n            \n        else {\n            subtypes[i] = actualTypeArg;\n        }\n    }\n\n    TypeInformation<?>[] subTypesInfo = new TypeInformation<?>[subtypes.length];\n    for (int i = 0; i < subtypes.length; i++) {\n        final List<Type> subTypeHierarchy = new ArrayList<>(typeHierarchy);\n        subTypeHierarchy.add(subtypes[i]);\n            \n            \n            \n        if (subtypes[i] instanceof TypeVariable<?>) {\n            subTypesInfo[i] =\n                    createTypeInfoFromInputs(\n                            (TypeVariable<?>) subtypes[i], subTypeHierarchy, in1Type, in2Type);\n\n                \n            if (subTypesInfo[i] == null && !lenient) {\n                throw new InvalidTypesException(\n                        \"Type of TypeVariable '\"\n                                + ((TypeVariable<?>) subtypes[i]).getName()\n                                + \"' in '\"\n                                + ((TypeVariable<?>) subtypes[i]).getGenericDeclaration()\n                                + \"' could not be determined. This is most likely a type erasure problem. \"\n                                + \"The type extraction currently supports types with generic variables only in cases where \"\n                                + \"all variables in the return type can be deduced from the input type(s). \"\n                                + \"Otherwise the type has to be specified explicitly using type information.\");\n            }\n        } else {\n                \n            try {\n                subTypesInfo[i] =\n                        createTypeInfoWithTypeHierarchy(\n                                subTypeHierarchy, subtypes[i], in1Type, in2Type);\n            } catch (InvalidTypesException e) {\n                if (lenient) {\n                    subTypesInfo[i] = null;\n                } else {\n                    throw e;\n                }\n            }\n        }\n    }\n\n        \n    if (!lenient) {\n        Class<?> originalTypeAsClass = null;\n        if (isClassType(originalType)) {\n            originalTypeAsClass = typeToClass(originalType);\n        }\n        checkNotNull(originalTypeAsClass, \"originalType has an unexpected type\");\n            \n            \n            \n            \n        int fieldCount = countFieldsInClass(originalTypeAsClass);\n        if (fieldCount > subTypesInfo.length) {\n            return null;\n        }\n    }\n\n    return subTypesInfo;\n}", "summary_tokens": ["creates", "the", "type", "information", "for", "all", "elements", "of", "a", "type", "that", "expects", "a", "certain", "number", "of", "subtypes", "e"], "project": "flink"}
{"id": 4646, "code": "public boolean containsPriorityElement(T element) {\n    if (numPriorityElements == 0) {\n        return false;\n    }\n    final Iterator<T> iterator = deque.iterator();\n    for (int i = 0; i < numPriorityElements && iterator.hasNext(); i++) {\n        if (iterator.next() == element) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["returns", "whether", "the", "given", "element", "is", "a", "known", "priority", "element"], "project": "flink"}
{"id": 5163, "code": "private Set<PendingTaskManagerId> allocateTaskManagersAccordingTo(\n        List<PendingTaskManager> pendingTaskManagers) {\n    final Set<PendingTaskManagerId> failedAllocations = new HashSet<>();\n    for (PendingTaskManager pendingTaskManager : pendingTaskManagers) {\n        if (!allocateResource(pendingTaskManager)) {\n            failedAllocations.add(pendingTaskManager.getPendingTaskManagerId());\n        }\n    }\n    return failedAllocations;\n}", "summary_tokens": ["allocate", "pending", "task", "managers", "returns", "the", "ids", "of", "pending", "task", "managers", "that", "can", "not", "be", "allocated"], "project": "flink"}
{"id": 4485, "code": "public void recycle(Collection<MemorySegment> segments) {\n    checkArgument(segments != null, \"Buffer list must be not null.\");\n\n    if (segments.isEmpty()) {\n        return;\n    }\n\n    synchronized (buffers) {\n        checkState(initialized, \"Recycling a buffer before initialization.\");\n\n        if (destroyed) {\n            segments.forEach(MemorySegment::free);\n            return;\n        }\n\n        buffers.addAll(segments);\n        if (buffers.size() >= numBuffersPerRequest) {\n            buffers.notifyAll();\n        }\n    }\n}", "summary_tokens": ["recycles", "a", "collection", "of", "buffers", "to", "this", "buffer", "pool"], "project": "flink"}
{"id": 223, "code": "public void initializeState(List<FileWriterBucketState> bucketStates) throws IOException {\n    checkNotNull(bucketStates, \"The retrieved state was null.\");\n\n    for (FileWriterBucketState state : bucketStates) {\n        String bucketId = state.getBucketId();\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Restoring: {}\", state);\n        }\n\n        FileWriterBucket<IN> restoredBucket =\n                bucketFactory.restoreBucket(\n                        bucketWriter, rollingPolicy, state, outputFileConfig);\n\n        updateActiveBucketId(bucketId, restoredBucket);\n    }\n\n    registerNextBucketInspectionTimer();\n}", "summary_tokens": ["initializes", "the", "state", "after", "recovery", "from", "a", "failure"], "project": "flink"}
{"id": 7595, "code": "private void sendControlMail(\n        RunnableWithException mail, String descriptionFormat, Object... descriptionArgs) {\n    mailbox.putFirst(\n            new Mail(\n                    mail,\n                    Integer.MAX_VALUE ,\n                    descriptionFormat,\n                    descriptionArgs));\n}", "summary_tokens": ["sends", "the", "given", "code", "mail", "code", "using", "task", "mailbox", "put", "first", "mail"], "project": "flink"}
{"id": 1077, "code": "public void registerPojoType(Class<?> type) {\n    if (type == null) {\n        throw new NullPointerException(\"Cannot register null type class.\");\n    }\n    if (!registeredPojoTypes.contains(type)) {\n        registeredPojoTypes.add(type);\n    }\n}", "summary_tokens": ["registers", "the", "given", "type", "with", "the", "serialization", "stack"], "project": "flink"}
{"id": 1997, "code": "public boolean hasAbsentKeysOrValues() {\n    for (Entry<String, KeyValue<K, V>> entry : underlyingMap.entrySet()) {\n        if (keyOrValueIsAbsent(entry)) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["checks", "whether", "there", "are", "entries", "with", "absent", "keys", "or", "values"], "project": "flink"}
{"id": 4813, "code": "public Optional<SerializedThrowable> getSerializedThrowable() {\n    return Optional.ofNullable(serializedThrowable);\n}", "summary_tokens": ["returns", "an", "empty", "optional", "if", "the", "job", "finished", "successfully", "otherwise", "the", "optional", "will", "carry", "the", "failure", "cause"], "project": "flink"}
{"id": 489, "code": "private FlinkKafkaInternalProducer<?, ?> getRecoveryProducer(KafkaCommittable committable) {\n    if (recoveryProducer == null) {\n        recoveryProducer =\n                new FlinkKafkaInternalProducer<>(\n                        kafkaProducerConfig, committable.getTransactionalId());\n    } else {\n        recoveryProducer.setTransactionId(committable.getTransactionalId());\n    }\n    recoveryProducer.resumeTransaction(committable.getProducerId(), committable.getEpoch());\n    return recoveryProducer;\n}", "summary_tokens": ["creates", "a", "producer", "that", "can", "commit", "into", "the", "same", "transaction", "as", "the", "upstream", "producer", "that", "was", "serialized", "into", "kafka", "committable"], "project": "flink"}
{"id": 2372, "code": "protected char[] getPasswordFromConfig(String name) {\n    char[] pass = null;\n    if (getBoolean(\n            CredentialProvider.CLEAR_TEXT_FALLBACK,\n            CommonConfigurationKeysPublic\n                    .HADOOP_SECURITY_CREDENTIAL_CLEAR_TEXT_FALLBACK_DEFAULT)) {\n        String passStr = get(name);\n        if (passStr != null) {\n            pass = passStr.toCharArray();\n        }\n    }\n    return pass;\n}", "summary_tokens": ["fallback", "to", "clear", "text", "passwords", "in", "configuration"], "project": "flink"}
{"id": 8576, "code": "public static ConstraintArgumentTypeStrategy constraint(\n        String constraintMessage, Function<List<DataType>, Boolean> evaluator) {\n    return new ConstraintArgumentTypeStrategy(constraintMessage, evaluator);\n}", "summary_tokens": ["strategy", "for", "an", "argument", "that", "must", "fulfill", "a", "given", "constraint"], "project": "flink"}
{"id": 9246, "code": "private boolean retractRecordWithRowNumber(\n        SortedMap<RowData, Long> sortedMap,\n        RowData sortKey,\n        RowData inputRow,\n        Collector<RowData> out)\n        throws Exception {\n    Iterator<Map.Entry<RowData, Long>> iterator = sortedMap.entrySet().iterator();\n    long currentRank = 0L;\n    RowData prevRow = null;\n    boolean findsSortKey = false;\n    while (iterator.hasNext() && isInRankEnd(currentRank)) {\n        Map.Entry<RowData, Long> entry = iterator.next();\n        RowData key = entry.getKey();\n        if (!findsSortKey && key.equals(sortKey)) {\n            List<RowData> inputs = dataState.get(key);\n            if (inputs == null) {\n                processStateStaled(iterator);\n            } else {\n                Iterator<RowData> inputIter = inputs.iterator();\n                while (inputIter.hasNext() && isInRankEnd(currentRank)) {\n                    RowData currentRow = inputIter.next();\n                    if (!findsSortKey && equaliser.equals(currentRow, inputRow)) {\n                        prevRow = currentRow;\n                        findsSortKey = true;\n                        inputIter.remove();\n                    } else if (findsSortKey) {\n                        collectUpdateBefore(out, prevRow, currentRank);\n                        collectUpdateAfter(out, currentRow, currentRank);\n                        prevRow = currentRow;\n                    }\n                    currentRank += 1;\n                }\n                if (inputs.isEmpty()) {\n                    dataState.remove(key);\n                } else {\n                    dataState.put(key, inputs);\n                }\n            }\n        } else if (findsSortKey) {\n            List<RowData> inputs = dataState.get(key);\n            if (inputs == null) {\n                processStateStaled(iterator);\n            } else {\n                int i = 0;\n                while (i < inputs.size() && isInRankEnd(currentRank)) {\n                    RowData currentRow = inputs.get(i);\n                    collectUpdateBefore(out, prevRow, currentRank);\n                    collectUpdateAfter(out, currentRow, currentRank);\n                    prevRow = currentRow;\n                    currentRank += 1;\n                    i++;\n                }\n            }\n        } else {\n            currentRank += entry.getValue();\n        }\n    }\n    if (isInRankEnd(currentRank)) {\n            \n        collectDelete(out, prevRow, currentRank);\n    }\n\n    return findsSortKey;\n}", "summary_tokens": ["retract", "the", "input", "record", "and", "emit", "updated", "records"], "project": "flink"}
{"id": 8218, "code": "static CatalogTable fromProperties(Map<String, String> properties) {\n    return CatalogPropertiesUtil.deserializeCatalogTable(properties);\n}", "summary_tokens": ["creates", "an", "instance", "of", "catalog", "table", "from", "a", "map", "of", "string", "properties", "that", "were", "previously", "created", "with", "resolved", "catalog", "table", "to", "properties"], "project": "flink"}
{"id": 9717, "code": "void setResourceInformationUnSafe(Object resource, String resourceName, long amount) {\n    if (!isYarnResourceTypesAvailable) {\n        LOG.info(\n                \"Will not request extended resource {} because the used YARN version does not support it.\",\n                resourceName);\n        return;\n    }\n    try {\n        resourceSetResourceInformationMethod.invoke(\n                resource,\n                resourceName,\n                resourceInformationNewInstanceMethod.invoke(null, resourceName, amount));\n    } catch (Exception e) {\n        LOG.warn(\n                \"Error in setting the external resource {}. Will not request this resource from YARN.\",\n                resourceName,\n                e);\n    }\n}", "summary_tokens": ["same", "as", "set", "resource", "information", "resource", "string", "long", "but", "allows", "to", "pass", "objects", "that", "are", "not", "of", "type", "resource"], "project": "flink"}
{"id": 761, "code": "protected boolean shouldAdvanceLastDiscoveredShardId(\n        String shardId, String lastSeenShardIdOfStream) {\n    return (StreamShardHandle.compareShardIds(shardId, lastSeenShardIdOfStream) > 0);\n}", "summary_tokens": ["given", "last", "seen", "shard", "id", "check", "if", "last", "discovered", "shard", "id", "should", "be", "advanced"], "project": "flink"}
{"id": 4395, "code": "public String getExceptionAsString() {\n    return exception.getFullStringifiedStackTrace();\n}", "summary_tokens": ["returns", "the", "contained", "exception", "as", "a", "string"], "project": "flink"}
{"id": 1692, "code": "public static LinkElement link(String link) {\n    return new LinkElement(link, link);\n}", "summary_tokens": ["creates", "a", "link", "with", "a", "given", "url"], "project": "flink"}
{"id": 1640, "code": "public void setBoolean(ConfigOption<Boolean> key, boolean value) {\n    setValueInternal(key.key(), value);\n}", "summary_tokens": ["adds", "the", "given", "value", "to", "the", "configuration", "object"], "project": "flink"}
{"id": 7069, "code": "public <T2> CoGroupedStreams<T, T2> coGroup(DataStream<T2> otherStream) {\n    return new CoGroupedStreams<>(this, otherStream);\n}", "summary_tokens": ["creates", "a", "join", "operation"], "project": "flink"}
{"id": 6269, "code": "public void testNoOps() {\n    StandaloneJobGraphStore jobGraphs = new StandaloneJobGraphStore();\n\n    JobGraph jobGraph = JobGraphTestUtils.emptyJobGraph();\n\n    assertEquals(0, jobGraphs.getJobIds().size());\n\n    jobGraphs.putJobGraph(jobGraph);\n    assertEquals(0, jobGraphs.getJobIds().size());\n\n    jobGraphs.removeJobGraph(jobGraph.getJobID());\n    assertEquals(0, jobGraphs.getJobIds().size());\n\n    assertNull(jobGraphs.recoverJobGraph(new JobID()));\n}", "summary_tokens": ["tests", "that", "all", "operations", "work", "and", "don", "t", "change", "the", "state"], "project": "flink"}
{"id": 55, "code": "public static FromJarEntryClassInformationProvider createFromPythonJar() {\n    return new FromJarEntryClassInformationProvider(\n            new File(PackagedProgramUtils.getPythonJar().getPath()),\n            PackagedProgramUtils.getPythonDriverClassName());\n}", "summary_tokens": ["creates", "a", "from", "jar", "entry", "class", "information", "provider", "for", "a", "job", "implemented", "in", "python"], "project": "flink"}
{"id": 5656, "code": "private static long getSizeOfPhysicalMemoryForWindows() {\n    BufferedReader bi = null;\n    try {\n        Process proc = Runtime.getRuntime().exec(\"wmic memorychip get capacity\");\n\n        bi =\n                new BufferedReader(\n                        new InputStreamReader(proc.getInputStream(), StandardCharsets.UTF_8));\n\n        String line = bi.readLine();\n        if (line == null) {\n            return -1L;\n        }\n\n        if (!line.startsWith(\"Capacity\")) {\n            return -1L;\n        }\n\n        long sizeOfPhyiscalMemory = 0L;\n        while ((line = bi.readLine()) != null) {\n            if (line.isEmpty()) {\n                continue;\n            }\n\n            line = line.replaceAll(\" \", \"\");\n            sizeOfPhyiscalMemory += Long.parseLong(line);\n        }\n        return sizeOfPhyiscalMemory;\n    } catch (Throwable t) {\n        LOG.error(\n                \"Cannot determine the size of the physical memory for Windows host \"\n                        + \"(using 'wmic memorychip')\",\n                t);\n        return -1L;\n    } finally {\n        if (bi != null) {\n            try {\n                bi.close();\n            } catch (Throwable ignored) {\n            }\n        }\n    }\n}", "summary_tokens": ["returns", "the", "size", "of", "the", "physical", "memory", "in", "bytes", "on", "windows"], "project": "flink"}
{"id": 6459, "code": "public void testTimeoutForUnusedTaskManager() throws Exception {\n    WorkerResourceSpec workerResourceSpec =\n            new WorkerResourceSpec.Builder().setCpuCores(1).build();\n    final ResourceProfile resourceProfile = ResourceProfile.newBuilder().setCpuCores(1).build();\n    final Time taskManagerTimeout = Time.milliseconds(50L);\n\n    final CompletableFuture<InstanceID> releaseResourceFuture = new CompletableFuture<>();\n    final ResourceActions resourceManagerActions =\n            new TestingResourceActionsBuilder()\n                    .setReleaseResourceConsumer(\n                            (instanceID, e) -> releaseResourceFuture.complete(instanceID))\n                    .build();\n\n    final Executor mainThreadExecutor = TestingUtils.defaultExecutor();\n\n    try (final TaskExecutorManager taskExecutorManager =\n            createTaskExecutorManagerBuilder()\n                    .setTaskManagerTimeout(taskManagerTimeout)\n                    .setDefaultWorkerResourceSpec(workerResourceSpec)\n                    .setResourceActions(resourceManagerActions)\n                    .setMainThreadExecutor(mainThreadExecutor)\n                    .createTaskExecutorManager()) {\n\n        CompletableFuture.supplyAsync(\n                        () -> {\n                            taskExecutorManager.allocateWorker(resourceProfile);\n                            InstanceID taskExecutorId =\n                                    createAndRegisterTaskExecutor(\n                                            taskExecutorManager, 1, resourceProfile);\n\n                            taskExecutorManager.occupySlot(taskExecutorId);\n                            taskExecutorManager.freeSlot(taskExecutorId);\n\n                            return taskExecutorId;\n                        },\n                        mainThreadExecutor)\n                    \n                .thenAcceptBoth(\n                        releaseResourceFuture,\n                        (registeredInstance, releasedInstance) ->\n                                assertThat(registeredInstance, is(releasedInstance)))\n                .get();\n    }\n}", "summary_tokens": ["tests", "that", "formerly", "used", "task", "managers", "can", "timeout", "after", "all", "of", "their", "slots", "have", "been", "freed"], "project": "flink"}
{"id": 598, "code": "public void add(E element) throws IllegalStateException {\n    requireNonNull(element);\n\n    lock.lock();\n    try {\n        if (open) {\n            elements.addLast(element);\n            if (elements.size() == 1) {\n                nonEmpty.signalAll();\n            }\n        } else {\n            throw new IllegalStateException(\"queue is closed\");\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["adds", "the", "element", "to", "the", "queue", "or", "fails", "with", "an", "exception", "if", "the", "queue", "is", "closed"], "project": "flink"}
{"id": 5984, "code": "public static SlotProfile noLocality(ResourceProfile resourceProfile) {\n    return preferredLocality(resourceProfile, Collections.emptyList());\n}", "summary_tokens": ["returns", "a", "slot", "profile", "for", "the", "given", "resource", "profile", "without", "any", "locality", "requirements"], "project": "flink"}
{"id": 4370, "code": "public static void tryEnrichClusterEntryPointError(@Nullable Throwable root) {\n    tryEnrichOutOfMemoryError(\n            root,\n            JM_METASPACE_OOM_ERROR_MESSAGE,\n            JM_DIRECT_OOM_ERROR_MESSAGE,\n            JM_HEAP_SPACE_OOM_ERROR_MESSAGE);\n}", "summary_tokens": ["tries", "to", "enrich", "the", "passed", "exception", "or", "its", "causes", "with", "additional", "information"], "project": "flink"}
{"id": 3986, "code": "public static ActorSystem createActorSystem(String actorSystemName, Config akkaConfig) {\n        \n    InternalLoggerFactory.setDefaultFactory(new Slf4JLoggerFactory());\n    return RobustActorSystem.create(actorSystemName, akkaConfig);\n}", "summary_tokens": ["creates", "an", "actor", "system", "with", "the", "given", "akka", "config"], "project": "flink"}
{"id": 6165, "code": "public void testCancelPartitionRequest() throws Exception {\n\n    NettyServerAndClient serverAndClient = null;\n\n    try {\n        TestPooledBufferProvider outboundBuffers = new TestPooledBufferProvider(16);\n\n        ResultPartitionManager partitions = mock(ResultPartitionManager.class);\n\n        ResultPartitionID pid = new ResultPartitionID();\n\n        CountDownLatch sync = new CountDownLatch(1);\n\n        final ResultSubpartitionView view =\n                spy(new InfiniteSubpartitionView(outboundBuffers, sync));\n\n            \n        when(partitions.createSubpartitionView(\n                        eq(pid), eq(0), any(BufferAvailabilityListener.class)))\n                .thenAnswer(\n                        new Answer<ResultSubpartitionView>() {\n                            @Override\n                            public ResultSubpartitionView answer(\n                                    InvocationOnMock invocationOnMock) throws Throwable {\n                                BufferAvailabilityListener listener =\n                                        (BufferAvailabilityListener)\n                                                invocationOnMock.getArguments()[2];\n                                listener.notifyDataAvailable();\n                                return view;\n                            }\n                        });\n\n        NettyProtocol protocol = new NettyProtocol(partitions, mock(TaskEventDispatcher.class));\n\n        serverAndClient = initServerAndClient(protocol);\n\n        Channel ch = connect(serverAndClient);\n\n            \n        ch.writeAndFlush(new PartitionRequest(pid, 0, new InputChannelID(), Integer.MAX_VALUE))\n                .await();\n\n            \n        if (!sync.await(TestingUtils.TESTING_DURATION.toMillis(), TimeUnit.MILLISECONDS)) {\n            fail(\n                    \"Timed out after waiting for \"\n                            + TestingUtils.TESTING_DURATION.toMillis()\n                            + \" ms to be notified about cancelled partition.\");\n        }\n\n        verify(view, times(1)).releaseAllResources();\n    } finally {\n        shutdown(serverAndClient);\n    }\n}", "summary_tokens": ["verifies", "that", "requests", "for", "non", "existing", "failed", "cancelled", "input", "channels", "are", "properly", "cancelled"], "project": "flink"}
{"id": 4039, "code": "public final void internalCallOnStart() throws Exception {\n    validateRunsInMainThread();\n    isRunning = true;\n    onStart();\n}", "summary_tokens": ["internal", "method", "which", "is", "called", "by", "the", "rpc", "service", "implementation", "to", "start", "the", "rpc", "endpoint"], "project": "flink"}
{"id": 3672, "code": "public void reset() {\n    this.partitioning = PartitioningProperty.RANDOM_PARTITIONED;\n    this.ordering = null;\n    this.partitioningFields = null;\n    this.dataDistribution = null;\n    this.customPartitioner = null;\n}", "summary_tokens": ["this", "method", "resets", "the", "properties", "to", "a", "state", "where", "no", "properties", "are", "given"], "project": "flink"}
{"id": 7331, "code": "private <F> Collection<Integer> transformCoFeedback(CoFeedbackTransformation<F> coIterate) {\n\n    if (shouldExecuteInBatchMode) {\n        throw new UnsupportedOperationException(\n                \"Iterations are not supported in BATCH\"\n                        + \" execution mode. If you want to execute such a pipeline, please set the \"\n                        + \"'\"\n                        + ExecutionOptions.RUNTIME_MODE.key()\n                        + \"'=\"\n                        + RuntimeExecutionMode.STREAMING.name());\n    }\n\n        \n        \n        \n        \n\n        \n    Tuple2<StreamNode, StreamNode> itSourceAndSink =\n            streamGraph.createIterationSourceAndSink(\n                    coIterate.getId(),\n                    getNewIterationNodeId(),\n                    getNewIterationNodeId(),\n                    coIterate.getWaitTime(),\n                    coIterate.getParallelism(),\n                    coIterate.getMaxParallelism(),\n                    coIterate.getMinResources(),\n                    coIterate.getPreferredResources());\n\n    StreamNode itSource = itSourceAndSink.f0;\n    StreamNode itSink = itSourceAndSink.f1;\n\n        \n    streamGraph.setSerializers(\n            itSource.getId(),\n            null,\n            null,\n            coIterate.getOutputType().createSerializer(executionConfig));\n    streamGraph.setSerializers(\n            itSink.getId(),\n            coIterate.getOutputType().createSerializer(executionConfig),\n            null,\n            null);\n\n    Collection<Integer> resultIds = Collections.singleton(itSource.getId());\n\n        \n        \n    alreadyTransformed.put(coIterate, resultIds);\n\n        \n    List<Integer> allFeedbackIds = new ArrayList<>();\n\n    for (Transformation<F> feedbackEdge : coIterate.getFeedbackEdges()) {\n        Collection<Integer> feedbackIds = transform(feedbackEdge);\n        allFeedbackIds.addAll(feedbackIds);\n        for (Integer feedbackId : feedbackIds) {\n            streamGraph.addEdge(feedbackId, itSink.getId(), 0);\n        }\n    }\n\n    String slotSharingGroup = determineSlotSharingGroup(null, allFeedbackIds);\n\n    itSink.setSlotSharingGroup(slotSharingGroup);\n    itSource.setSlotSharingGroup(slotSharingGroup);\n\n    return Collections.singleton(itSource.getId());\n}", "summary_tokens": ["transforms", "a", "co", "feedback", "transformation"], "project": "flink"}
{"id": 4283, "code": "public long getMaximum() {\n    return max;\n}", "summary_tokens": ["returns", "the", "maximum", "seen", "value"], "project": "flink"}
{"id": 2690, "code": "public DataSource<StringValue> readTextFileWithValue(\n        String filePath, String charsetName, boolean skipInvalidLines) {\n    Preconditions.checkNotNull(filePath, \"The file path may not be null.\");\n\n    TextValueInputFormat format = new TextValueInputFormat(new Path(filePath));\n    format.setCharsetName(charsetName);\n    format.setSkipInvalidLines(skipInvalidLines);\n    return new DataSource<>(\n            this, format, new ValueTypeInfo<>(StringValue.class), Utils.getCallLocationName());\n}", "summary_tokens": ["creates", "a", "data", "set", "that", "represents", "the", "strings", "produced", "by", "reading", "the", "given", "file", "line", "wise"], "project": "flink"}
{"id": 7843, "code": "public void testDeclineCallOnCancelBarrierOneInput() throws Exception {\n\n    OneInputStreamTaskTestHarness<String, String> testHarness =\n            new OneInputStreamTaskTestHarness<>(\n                    OneInputStreamTask::new,\n                    1,\n                    2,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n    testHarness.setupOutputForSingletonOperatorChain();\n\n    StreamConfig streamConfig = testHarness.getStreamConfig();\n    StreamMap<String, String> mapOperator = new StreamMap<>(new IdentityMap());\n    streamConfig.setStreamOperator(mapOperator);\n    streamConfig.setOperatorID(new OperatorID());\n\n    StreamMockEnvironment environment = spy(testHarness.createEnvironment());\n\n        \n    testHarness.invoke(environment);\n    testHarness.waitForTaskRunning();\n\n        \n    testHarness.processEvent(new CancelCheckpointMarker(2L), 0, 1);\n    testHarness.processEvent(new CancelCheckpointMarker(2L), 0, 0);\n    testHarness.waitForInputProcessing();\n\n        \n    verify(environment, times(1))\n            .declineCheckpoint(\n                    eq(2L),\n                    argThat(\n                            new CheckpointExceptionMatcher(\n                                    CheckpointFailureReason\n                                            .CHECKPOINT_DECLINED_ON_CANCELLATION_BARRIER)));\n\n        \n    Object result = testHarness.getOutput().poll();\n    assertNotNull(\"nothing emitted\", result);\n    assertTrue(\"wrong type emitted\", result instanceof CancelCheckpointMarker);\n    assertEquals(\n            \"wrong checkpoint id\", 2L, ((CancelCheckpointMarker) result).getCheckpointId());\n\n        \n    testHarness.endInput();\n    testHarness.waitForTaskCompletion();\n}", "summary_tokens": ["this", "test", "verifies", "for", "onw", "input", "tasks", "that", "the", "stream", "tasks", "react", "the", "following", "way", "to", "receiving", "a", "checkpoint", "cancellation", "barrier", "send", "a", "decline", "checkpoint", "notification", "out", "to", "the", "job", "manager", "emit", "a", "cancellation", "barrier", "downstream"], "project": "flink"}
{"id": 5275, "code": "void cancelLogicalSlotRequest(ExecutionVertexID executionVertexID, @Nullable Throwable cause) {\n    Preconditions.checkState(\n            state == State.ALLOCATED,\n            \"SharedSlot (physical request %s) has been released\",\n            physicalSlotRequestId);\n    CompletableFuture<SingleLogicalSlot> logicalSlotFuture =\n            requestedLogicalSlots.getValueByKeyA(executionVertexID);\n    SlotRequestId logicalSlotRequestId = requestedLogicalSlots.getKeyBByKeyA(executionVertexID);\n    if (logicalSlotFuture != null) {\n        LOG.debug(\n                \"Cancel {} from {}\",\n                getLogicalSlotString(logicalSlotRequestId),\n                executionVertexID);\n            \n            \n        if (cause == null) {\n            logicalSlotFuture.cancel(false);\n        } else {\n            logicalSlotFuture.completeExceptionally(cause);\n        }\n    } else {\n        LOG.debug(\n                \"No SlotExecutionVertexAssignment for logical {} from physical {}}\",\n                logicalSlotRequestId,\n                physicalSlotRequestId);\n    }", "summary_tokens": ["cancels", "a", "logical", "slot", "request"], "project": "flink"}
{"id": 9276, "code": "public final MutableObjectIterator<Tuple2<BinaryRowData, BinaryRowData>> getIterator() {\n    return new MutableObjectIterator<Tuple2<BinaryRowData, BinaryRowData>>() {\n        private final int size = size();\n        private int current = 0;\n\n        private int currentSegment = 0;\n        private int currentOffset = 0;\n\n        private MemorySegment currentIndexSegment = sortIndex.get(0);\n\n        @Override\n        public Tuple2<BinaryRowData, BinaryRowData> next(\n                Tuple2<BinaryRowData, BinaryRowData> kv) {\n            if (this.current < this.size) {\n                this.current++;\n                if (this.currentOffset > lastIndexEntryOffset) {\n                    this.currentOffset = 0;\n                    this.currentIndexSegment = sortIndex.get(++this.currentSegment);\n                }\n\n                long pointer = this.currentIndexSegment.getLong(this.currentOffset);\n                this.currentOffset += indexEntrySize;\n\n                try {\n                    return getRecordFromBuffer(kv.f0, kv.f1, pointer);\n                } catch (IOException ioe) {\n                    throw new RuntimeException(ioe);\n                }\n            } else {\n                return null;\n            }\n        }\n\n        @Override\n        public Tuple2<BinaryRowData, BinaryRowData> next() {\n            throw new RuntimeException(\"Not support!\");\n        }\n    };\n}", "summary_tokens": ["gets", "an", "iterator", "over", "all", "kv", "records", "in", "this", "buffer", "in", "their", "logical", "order"], "project": "flink"}
{"id": 9245, "code": "public void setKeyContext(KeyContext keyContext) {\n    this.keyContext = keyContext;\n}", "summary_tokens": ["sets", "key", "context", "to", "rank", "function"], "project": "flink"}
{"id": 7387, "code": "protected <S extends State, N> S getPartitionedState(\n        N namespace,\n        TypeSerializer<N> namespaceSerializer,\n        StateDescriptor<S, ?> stateDescriptor)\n        throws Exception {\n\n        \n\n    if (keyedStateBackend != null) {\n        return keyedStateBackend.getPartitionedState(\n                namespace, namespaceSerializer, stateDescriptor);\n    } else {\n        throw new RuntimeException(\n                \"Cannot create partitioned state. The keyed state \"\n                        + \"backend has not been set. This indicates that the operator is not \"\n                        + \"partitioned/keyed.\");\n    }\n}", "summary_tokens": ["creates", "a", "partitioned", "state", "handle", "using", "the", "state", "backend", "configured", "for", "this", "task"], "project": "flink"}
{"id": 4733, "code": "public JobVertex getTarget() {\n    return target;\n}", "summary_tokens": ["returns", "the", "vertex", "connected", "to", "this", "edge"], "project": "flink"}
{"id": 3070, "code": "private void processEvent(NFAState nfaState, IN event, long timestamp) throws Exception {\n    try (SharedBufferAccessor<IN> sharedBufferAccessor = partialMatches.getAccessor()) {\n        Collection<Map<String, List<IN>>> patterns =\n                nfa.process(\n                        sharedBufferAccessor,\n                        nfaState,\n                        event,\n                        timestamp,\n                        afterMatchSkipStrategy,\n                        cepTimerService);\n        processMatchedSequences(patterns, timestamp);\n    }\n}", "summary_tokens": ["process", "the", "given", "event", "by", "giving", "it", "to", "the", "nfa", "and", "outputting", "the", "produced", "set", "of", "matched", "event", "sequences"], "project": "flink"}
{"id": 6690, "code": "public long getProcessId() {\n    checkState(process != null, \"process not started\");\n\n    try {\n        Class<? extends Process> clazz = process.getClass();\n        if (clazz.getName().equals(\"java.lang.UNIXProcess\")) {\n            Field pidField = clazz.getDeclaredField(\"pid\");\n            pidField.setAccessible(true);\n            return pidField.getLong(process);\n        } else if (clazz.getName().equals(\"java.lang.ProcessImpl\")) {\n            Method pid = clazz.getDeclaredMethod(\"pid\");\n            pid.setAccessible(true);\n            return (long) pid.invoke(process);\n        } else {\n            return -1;\n        }\n    } catch (Throwable ignored) {\n        return -1;\n    }\n}", "summary_tokens": ["gets", "the", "process", "id", "if", "possible"], "project": "flink"}
{"id": 1802, "code": "public double getDoubleBigEndian(int index) {\n    return Double.longBitsToDouble(getLongBigEndian(index));\n}", "summary_tokens": ["reads", "a", "double", "precision", "floating", "point", "value", "0", "bit", "0", "bytes", "from", "the", "given", "position", "in", "big", "endian", "byte", "order"], "project": "flink"}
{"id": 1154, "code": "static <T> WatermarkStrategy<T> noWatermarks() {\n    return (ctx) -> new NoWatermarksGenerator<>();\n}", "summary_tokens": ["creates", "a", "watermark", "strategy", "that", "generates", "no", "watermarks", "at", "all"], "project": "flink"}
{"id": 6489, "code": "public void testConcurrentAccess() throws Exception {\n    final Time timeout = Time.milliseconds(100L);\n    final Time timeToLive = Time.hours(1L);\n\n    final CountingRestfulGateway restfulGateway =\n            createCountingRestfulGateway(\n                    expectedJobId,\n                    CompletableFuture.completedFuture(expectedExecutionGraphInfo));\n\n    final int numConcurrentAccesses = 10;\n\n    final ArrayList<CompletableFuture<ExecutionGraphInfo>> executionGraphFutures =\n            new ArrayList<>(numConcurrentAccesses);\n\n    final ExecutorService executor =\n            java.util.concurrent.Executors.newFixedThreadPool(numConcurrentAccesses);\n\n    try (ExecutionGraphCache executionGraphCache =\n            new DefaultExecutionGraphCache(timeout, timeToLive)) {\n        for (int i = 0; i < numConcurrentAccesses; i++) {\n            CompletableFuture<ExecutionGraphInfo> executionGraphFuture =\n                    CompletableFuture.supplyAsync(\n                                    () ->\n                                            executionGraphCache.getExecutionGraphInfo(\n                                                    expectedJobId, restfulGateway),\n                                    executor)\n                            .thenCompose(Function.identity());\n\n            executionGraphFutures.add(executionGraphFuture);\n        }\n\n        final CompletableFuture<Collection<ExecutionGraphInfo>> allExecutionGraphFutures =\n                FutureUtils.combineAll(executionGraphFutures);\n\n        Collection<ExecutionGraphInfo> allExecutionGraphs = allExecutionGraphFutures.get();\n\n        for (ExecutionGraphInfo executionGraph : allExecutionGraphs) {\n            assertEquals(expectedExecutionGraphInfo, executionGraph);\n        }\n\n        assertThat(restfulGateway.getNumRequestJobCalls(), Matchers.equalTo(1));\n    } finally {\n        ExecutorUtils.gracefulShutdown(5000L, TimeUnit.MILLISECONDS, executor);\n    }\n}", "summary_tokens": ["tests", "that", "concurrent", "accesses", "only", "trigger", "a", "single", "access", "execution", "graph", "request"], "project": "flink"}
{"id": 4830, "code": "default <T> Optional<T> castInto(Class<T> clazz) {\n    if (clazz.isAssignableFrom(this.getClass())) {\n        return Optional.of(clazz.cast(this));\n    } else {\n        return Optional.empty();\n    }\n}", "summary_tokens": ["tries", "to", "cast", "this", "slot", "pool", "service", "into", "the", "given", "clazz"], "project": "flink"}
{"id": 9528, "code": "public static String getOSSAccessKey() {\n    if (ACCESS_KEY != null) {\n        return ACCESS_KEY;\n    } else {\n        throw new IllegalStateException(\"OSS access key is not available\");\n    }\n}", "summary_tokens": ["get", "oss", "access", "key"], "project": "flink"}
{"id": 8164, "code": "public static TypeInformation<Integer> INT() {\n    return org.apache.flink.api.common.typeinfo.Types.INT;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "integer", "or", "sql", "int", "integer", "type"], "project": "flink"}
{"id": 5989, "code": "public void testMixedLocalRemoteUnknownDeployment() throws Exception {\n    ResourceID consumerResourceID = ResourceID.generate();\n    JobID jobID = new JobID();\n\n        \n        \n    for (ExecutionState state : ExecutionState.values()) {\n        ResultPartitionID localPartitionId = new ResultPartitionID();\n        ResultPartitionDeploymentDescriptor localPartition =\n                createResultPartitionDeploymentDescriptor(\n                        jobID, localPartitionId, consumerResourceID);\n\n        ResultPartitionID remotePartitionId = new ResultPartitionID();\n        ResultPartitionDeploymentDescriptor remotePartition =\n                createResultPartitionDeploymentDescriptor(\n                        jobID, remotePartitionId, ResourceID.generate());\n\n        ResultPartitionID unknownPartitionId = new ResultPartitionID();\n\n        ShuffleDescriptor localShuffleDescriptor =\n                getConsumedPartitionShuffleDescriptor(\n                        localPartitionId,\n                        state,\n                        localPartition,\n                        TaskDeploymentDescriptorFactory.PartitionLocationConstraint\n                                .CAN_BE_UNKNOWN);\n        ShuffleDescriptor remoteShuffleDescriptor =\n                getConsumedPartitionShuffleDescriptor(\n                        remotePartitionId,\n                        state,\n                        remotePartition,\n                        TaskDeploymentDescriptorFactory.PartitionLocationConstraint\n                                .CAN_BE_UNKNOWN);\n        ShuffleDescriptor unknownShuffleDescriptor =\n                getConsumedPartitionShuffleDescriptor(\n                        unknownPartitionId,\n                        state,\n                        null,\n                        TaskDeploymentDescriptorFactory.PartitionLocationConstraint\n                                .CAN_BE_UNKNOWN);\n\n            \n        if (state == ExecutionState.RUNNING\n                || state == ExecutionState.INITIALIZING\n                || state == ExecutionState.FINISHED\n                || state == ExecutionState.SCHEDULED\n                || state == ExecutionState.DEPLOYING) {\n            NettyShuffleDescriptor nettyShuffleDescriptor;\n\n                \n            verifyShuffleDescriptor(\n                    localShuffleDescriptor,\n                    NettyShuffleDescriptor.class,\n                    false,\n                    localPartitionId);\n            nettyShuffleDescriptor = (NettyShuffleDescriptor) localShuffleDescriptor;\n            assertThat(nettyShuffleDescriptor.isLocalTo(consumerResourceID), is(true));\n\n            verifyShuffleDescriptor(\n                    remoteShuffleDescriptor,\n                    NettyShuffleDescriptor.class,\n                    false,\n                    remotePartitionId);\n            nettyShuffleDescriptor = (NettyShuffleDescriptor) remoteShuffleDescriptor;\n            assertThat(nettyShuffleDescriptor.isLocalTo(consumerResourceID), is(false));\n            assertThat(nettyShuffleDescriptor.getConnectionId(), is(STUB_CONNECTION_ID));\n        } else {\n                \n            verifyShuffleDescriptor(\n                    localShuffleDescriptor,\n                    UnknownShuffleDescriptor.class,\n                    true,\n                    localPartitionId);\n            verifyShuffleDescriptor(\n                    remoteShuffleDescriptor,\n                    UnknownShuffleDescriptor.class,\n                    true,\n                    remotePartitionId);\n        }\n\n        verifyShuffleDescriptor(\n                unknownShuffleDescriptor,\n                UnknownShuffleDescriptor.class,\n                true,\n                unknownPartitionId);\n    }\n}", "summary_tokens": ["tests", "the", "deployment", "descriptors", "for", "local", "remote", "and", "unknown", "partition", "locations", "with", "lazy", "deployment", "allowed", "and", "all", "execution", "states", "for", "the", "producers"], "project": "flink"}
{"id": 7657, "code": "public void testCanBeCanceledViaRegistry() throws Exception {\n    CloseableRegistry closeableRegistry = new CloseableRegistry();\n    OneShotLatch waitForBlock = new OneShotLatch();\n    OneShotLatch unblock = new OneShotLatch();\n    OperatorStateHandle blockingRestoreHandle = mock(OperatorStateHandle.class);\n    when(blockingRestoreHandle.openInputStream())\n            .thenReturn(new BlockingFSDataInputStream(waitForBlock, unblock));\n\n    List<StateObjectCollection<OperatorStateHandle>> sortedRestoreOptions =\n            Collections.singletonList(\n                    new StateObjectCollection<>(\n                            Collections.singletonList(blockingRestoreHandle)));\n\n    BackendRestorerProcedure<OperatorStateBackend, OperatorStateHandle> restorerProcedure =\n            new BackendRestorerProcedure<>(\n                    backendSupplier, closeableRegistry, \"test op state backend\");\n\n    AtomicReference<Exception> exceptionReference = new AtomicReference<>(null);\n    Thread restoreThread =\n            new Thread(\n                    () -> {\n                        try {\n                            restorerProcedure.createAndRestore(sortedRestoreOptions);\n                        } catch (Exception e) {\n                            exceptionReference.set(e);\n                        }\n                    });\n\n    restoreThread.start();\n    waitForBlock.await();\n    closeableRegistry.close();\n    unblock.trigger();\n    restoreThread.join();\n\n    Exception exception = exceptionReference.get();\n    Assert.assertTrue(exception instanceof FlinkException);\n}", "summary_tokens": ["test", "that", "the", "restore", "can", "be", "stopped", "via", "the", "provided", "closeable", "registry"], "project": "flink"}
{"id": 5177, "code": "public String getRestBindAddress() {\n    return restBindAddress;\n}", "summary_tokens": ["returns", "the", "address", "that", "the", "rest", "server", "endpoint", "should", "bind", "itself", "to"], "project": "flink"}
{"id": 8243, "code": "public DataType toPhysicalRowDataType() {\n    return toRowDataType(Column::isPhysical);\n}", "summary_tokens": ["converts", "all", "physical", "columns", "of", "this", "schema", "into", "a", "possibly", "nested", "row", "data", "type"], "project": "flink"}
{"id": 6022, "code": "public void testCreateSimpleGraphBipartite() throws Exception {\n    JobVertex v1 = new JobVertex(\"vertex1\");\n    JobVertex v2 = new JobVertex(\"vertex2\");\n    JobVertex v3 = new JobVertex(\"vertex3\");\n    JobVertex v4 = new JobVertex(\"vertex4\");\n    JobVertex v5 = new JobVertex(\"vertex5\");\n\n    v1.setParallelism(5);\n    v2.setParallelism(7);\n    v3.setParallelism(2);\n    v4.setParallelism(11);\n    v5.setParallelism(4);\n\n    v1.setInvokableClass(AbstractInvokable.class);\n    v2.setInvokableClass(AbstractInvokable.class);\n    v3.setInvokableClass(AbstractInvokable.class);\n    v4.setInvokableClass(AbstractInvokable.class);\n    v5.setInvokableClass(AbstractInvokable.class);\n\n    v2.connectNewDataSetAsInput(\n            v1, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);\n    v4.connectNewDataSetAsInput(\n            v2, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);\n    v4.connectNewDataSetAsInput(\n            v3, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);\n    v5.connectNewDataSetAsInput(\n            v4, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);\n    v5.connectNewDataSetAsInput(\n            v3, DistributionPattern.ALL_TO_ALL, ResultPartitionType.PIPELINED);\n\n    List<JobVertex> ordered = new ArrayList<JobVertex>(Arrays.asList(v1, v2, v3, v4, v5));\n\n    ExecutionGraph eg = createDefaultExecutionGraph(ordered);\n    try {\n        eg.attachJobGraph(ordered);\n    } catch (JobException e) {\n        e.printStackTrace();\n        fail(\"Job failed with exception: \" + e.getMessage());\n    }\n\n    verifyTestGraph(eg, v1, v2, v3, v4, v5);\n}", "summary_tokens": ["creates", "a", "job", "graph", "of", "the", "following", "form"], "project": "flink"}
{"id": 4142, "code": "static void writeLength(int length, OutputStream outputStream) throws IOException {\n    byte[] buf = new byte[4];\n    buf[0] = (byte) (length & 0xff);\n    buf[1] = (byte) ((length >> 8) & 0xff);\n    buf[2] = (byte) ((length >> 16) & 0xff);\n    buf[3] = (byte) ((length >> 24) & 0xff);\n    outputStream.write(buf, 0, 4);\n}", "summary_tokens": ["auxiliary", "method", "to", "write", "the", "length", "of", "an", "upcoming", "data", "chunk", "to", "an", "output", "stream"], "project": "flink"}
{"id": 190, "code": "public B setConnectionPathPrefix(String prefix) {\n    checkNotNull(prefix);\n    this.connectionPathPrefix = prefix;\n    return self();\n}", "summary_tokens": ["sets", "a", "prefix", "which", "used", "for", "every", "rest", "communication", "to", "the", "elasticsearch", "cluster"], "project": "flink"}
{"id": 3196, "code": "private Graph<K, VV, EV> removeVertices(DataSet<Vertex<K, VV>> verticesToBeRemoved) {\n\n    DataSet<Vertex<K, VV>> newVertices =\n            getVertices()\n                    .coGroup(verticesToBeRemoved)\n                    .where(0)\n                    .equalTo(0)\n                    .with(new VerticesRemovalCoGroup<>())\n                    .name(\"Remove vertices\");\n\n    DataSet<Edge<K, EV>> newEdges =\n            newVertices\n                    .join(getEdges())\n                    .where(0)\n                    .equalTo(0)\n                        \n                    .with(new ProjectEdgeToBeRemoved<>())\n                    .name(\"Edges to be removed\")\n                        \n                    .join(newVertices)\n                    .where(1)\n                    .equalTo(0)\n                    .with(new ProjectEdge<>())\n                    .name(\"Remove edges\");\n\n    return new Graph<>(newVertices, newEdges, context);\n}", "summary_tokens": ["removes", "the", "given", "list", "of", "vertices", "and", "its", "edges", "from", "the", "graph"], "project": "flink"}
{"id": 8656, "code": "public static long toInternal(java.sql.Timestamp ts) {\n    long time = ts.getTime();\n    return time + LOCAL_TZ.getOffset(time);\n}", "summary_tokens": ["converts", "the", "java", "type", "used", "for", "udf", "parameters", "of", "sql", "timestamp", "type", "java"], "project": "flink"}
{"id": 9102, "code": "default boolean isIdentityConversion() {\n    return false;\n}", "summary_tokens": ["returns", "whether", "this", "conversion", "is", "a", "no", "op"], "project": "flink"}
{"id": 3129, "code": "private static void writeJobDetails(ExecutionEnvironment env, String jobDetailsPath)\n        throws IOException {\n    JobExecutionResult result = env.getLastJobExecutionResult();\n\n    File jsonFile = new File(jobDetailsPath);\n\n    try (JsonGenerator json = new JsonFactory().createGenerator(jsonFile, JsonEncoding.UTF8)) {\n        json.writeStartObject();\n\n        json.writeObjectFieldStart(\"Apache Flink\");\n        json.writeStringField(\"version\", EnvironmentInformation.getVersion());\n        json.writeStringField(\n                \"commit ID\", EnvironmentInformation.getRevisionInformation().commitId);\n        json.writeStringField(\n                \"commit date\", EnvironmentInformation.getRevisionInformation().commitDate);\n        json.writeEndObject();\n\n        json.writeStringField(\"job_id\", result.getJobID().toString());\n        json.writeNumberField(\"runtime_ms\", result.getNetRuntime());\n\n        json.writeObjectFieldStart(\"parameters\");\n        for (Map.Entry<String, String> entry :\n                env.getConfig().getGlobalJobParameters().toMap().entrySet()) {\n            json.writeStringField(entry.getKey(), entry.getValue());\n        }\n        json.writeEndObject();\n\n        json.writeObjectFieldStart(\"accumulators\");\n        for (Map.Entry<String, Object> entry : result.getAllAccumulatorResults().entrySet()) {\n            json.writeStringField(entry.getKey(), entry.getValue().toString());\n        }\n        json.writeEndObject();\n\n        json.writeEndObject();\n    }\n}", "summary_tokens": ["write", "the", "following", "job", "details", "as", "a", "json", "encoded", "file", "runtime", "environment", "job", "id", "runtime", "parameters", "and", "accumulators"], "project": "flink"}
{"id": 6879, "code": "public PredefinedOptions getPredefinedOptions() {\n    if (predefinedOptions == null) {\n        predefinedOptions = PredefinedOptions.DEFAULT;\n    }\n    return predefinedOptions;\n}", "summary_tokens": ["gets", "the", "currently", "set", "predefined", "options", "for", "rocks", "db"], "project": "flink"}
{"id": 1937, "code": "public T deserializeValue(ClassLoader loader) throws IOException, ClassNotFoundException {\n    Preconditions.checkNotNull(loader, \"No classloader has been passed\");\n    return InstantiationUtil.decompressAndDeserializeObject(getByteArray(), loader);\n}", "summary_tokens": ["decompress", "and", "deserialize", "the", "data", "to", "get", "the", "original", "object"], "project": "flink"}
{"id": 3608, "code": "public GenericDataSinkBase<?> getOperator() {\n    return (GenericDataSinkBase<?>) super.getOperator();\n}", "summary_tokens": ["gets", "the", "operator", "for", "which", "this", "optimizer", "sink", "node", "was", "created"], "project": "flink"}
{"id": 4724, "code": "public void setup() {\n    latch = new CountDownLatch(1);\n}", "summary_tokens": ["setup", "the", "barrier", "has", "to", "be", "called", "at", "the", "beginning", "of", "each", "superstep"], "project": "flink"}
{"id": 5425, "code": "public static <T> StateSerializerProvider<T> fromNewRegisteredSerializer(\n        TypeSerializer<T> registeredStateSerializer) {\n    return new EagerlyRegisteredStateSerializerProvider<>(registeredStateSerializer);\n}", "summary_tokens": ["creates", "a", "state", "serializer", "provider", "from", "the", "registered", "state", "serializer"], "project": "flink"}
{"id": 2508, "code": "public void testDeserializationGenericRecord() throws IOException {\n    Configuration parameters = new Configuration();\n\n    AvroInputFormat<GenericRecord> format =\n            new AvroInputFormat<>(new Path(testFile.getAbsolutePath()), GenericRecord.class);\n\n    doTestDeserializationGenericRecord(format, parameters);\n}", "summary_tokens": ["test", "if", "the", "avro", "input", "format", "is", "able", "to", "properly", "read", "data", "from", "an", "avro", "file", "as", "a", "generic", "record"], "project": "flink"}
{"id": 6112, "code": "public void parallelChannelsTest() throws Exception {\n    final Random rnd = new Random(SEED);\n    final AbstractInvokable memOwner = new DummyInvokable();\n\n    FileIOChannel.ID[] ids = new FileIOChannel.ID[NUM_CHANNELS];\n    BlockChannelWriter<MemorySegment>[] writers = new BlockChannelWriter[NUM_CHANNELS];\n    BlockChannelReader<MemorySegment>[] readers = new BlockChannelReader[NUM_CHANNELS];\n    ChannelWriterOutputView[] outs = new ChannelWriterOutputView[NUM_CHANNELS];\n    ChannelReaderInputView[] ins = new ChannelReaderInputView[NUM_CHANNELS];\n\n    int[] writingCounters = new int[NUM_CHANNELS];\n    int[] readingCounters = new int[NUM_CHANNELS];\n\n        \n    for (int i = 0; i < NUM_CHANNELS; i++) {\n        ids[i] = this.ioManager.createChannel();\n        writers[i] = this.ioManager.createBlockChannelWriter(ids[i]);\n\n        List<MemorySegment> memSegs =\n                this.memoryManager.allocatePages(\n                        memOwner, rnd.nextInt(MAXIMUM_NUMBER_OF_SEGMENTS_PER_CHANNEL - 1) + 1);\n        outs[i] =\n                new ChannelWriterOutputView(\n                        writers[i], memSegs, this.memoryManager.getPageSize());\n    }\n\n    Value val = new Value();\n\n        \n\n    for (int i = 0; i < NUMBERS_TO_BE_WRITTEN; i++) {\n        int channel = skewedSample(rnd, NUM_CHANNELS - 1);\n\n        val.value = String.valueOf(writingCounters[channel]++);\n        val.write(outs[channel]);\n    }\n\n        \n    for (int i = 0; i < NUM_CHANNELS; i++) {\n        this.memoryManager.release(outs[i].close());\n    }\n    outs = null;\n    writers = null;\n\n        \n    for (int i = 0; i < NUM_CHANNELS; i++) {\n\n        List<MemorySegment> memSegs =\n                this.memoryManager.allocatePages(\n                        memOwner, rnd.nextInt(MAXIMUM_NUMBER_OF_SEGMENTS_PER_CHANNEL - 1) + 1);\n\n        final BlockChannelReader<MemorySegment> reader =\n                this.ioManager.createBlockChannelReader(ids[i]);\n        final ChannelReaderInputView in = new ChannelReaderInputView(reader, memSegs, false);\n        int nextVal = 0;\n\n        try {\n            while (true) {\n                val.read(in);\n                int intValue = 0;\n                try {\n                    intValue = Integer.parseInt(val.value);\n                } catch (NumberFormatException nfex) {\n                    Assert.fail(\n                            \"Invalid value read from reader. Valid decimal number expected.\");\n                }\n                Assert.assertEquals(\n                        \"Written and read values do not match during sequential read.\",\n                        nextVal,\n                        intValue);\n                nextVal++;\n            }\n        } catch (EOFException eofex) {\n                \n        }\n\n        Assert.assertEquals(\n                \"NUmber of written numbers differs from number of read numbers.\",\n                writingCounters[i],\n                nextVal);\n\n        this.memoryManager.release(in.close());\n    }\n\n        \n    for (int i = 0; i < NUM_CHANNELS; i++) {\n\n        List<MemorySegment> memSegs =\n                this.memoryManager.allocatePages(\n                        memOwner, rnd.nextInt(MAXIMUM_NUMBER_OF_SEGMENTS_PER_CHANNEL - 1) + 1);\n\n        readers[i] = this.ioManager.createBlockChannelReader(ids[i]);\n        ins[i] = new ChannelReaderInputView(readers[i], memSegs, false);\n    }\n\n        \n    for (int i = 0; i < NUMBERS_TO_BE_WRITTEN; i++) {\n\n        while (true) {\n            final int channel = skewedSample(rnd, NUM_CHANNELS - 1);\n            if (ins[channel] != null) {\n                try {\n                    val.read(ins[channel]);\n                    int intValue;\n                    try {\n                        intValue = Integer.parseInt(val.value);\n                    } catch (NumberFormatException nfex) {\n                        Assert.fail(\n                                \"Invalid value read from reader. Valid decimal number expected.\");\n                        return;\n                    }\n\n                    Assert.assertEquals(\n                            \"Written and read values do not match.\",\n                            readingCounters[channel]++,\n                            intValue);\n\n                    break;\n                } catch (EOFException eofex) {\n                    this.memoryManager.release(ins[channel].close());\n                    ins[channel] = null;\n                }\n            }\n        }\n    }\n\n        \n    for (int i = 0; i < NUM_CHANNELS; i++) {\n        if (ins[i] != null) {\n            this.memoryManager.release(ins[i].close());\n        }\n        readers[i].closeAndDelete();\n    }\n\n    ins = null;\n    readers = null;\n\n        \n    for (int i = 0; i < NUM_CHANNELS; i++) {\n        File f = new File(ids[i].getPath());\n        Assert.assertFalse(\"Channel file has not been deleted.\", f.exists());\n    }\n}", "summary_tokens": ["this", "test", "instantiates", "multiple", "channels", "and", "writes", "to", "them", "in", "parallel", "and", "re", "reads", "the", "data", "in", "parallel"], "project": "flink"}
{"id": 6953, "code": "public Long getWriteBufferManagerCapacity() {\n    if (sharedResources == null) {\n        return null;\n    }\n\n    return sharedResources.getResourceHandle().getWriteBufferManagerCapacity();\n}", "summary_tokens": ["gets", "write", "buffer", "manager", "capacity"], "project": "flink"}
{"id": 1162, "code": "protected static void loadGlobalConfigParams() {\n    loadConfigParameters(GlobalConfiguration.loadConfiguration());\n}", "summary_tokens": ["please", "use", "load", "config", "parameters", "configuration", "config"], "project": "flink"}
{"id": 8210, "code": "default Optional<Factory> getFactory() {\n    return Optional.empty();\n}", "summary_tokens": ["returns", "a", "factory", "for", "creating", "instances", "from", "catalog", "objects"], "project": "flink"}
{"id": 6964, "code": "public StateBackend getCheckpointBackend() {\n    return checkpointStreamBackend;\n}", "summary_tokens": ["gets", "the", "state", "backend", "that", "this", "rocks", "db", "state", "backend", "uses", "to", "persist", "its", "bytes", "to"], "project": "flink"}
{"id": 7490, "code": "public static <T> StreamTaskInput<T> create(\n        CheckpointedInputGate checkpointedInputGate,\n        TypeSerializer<T> inputSerializer,\n        IOManager ioManager,\n        StatusWatermarkValve statusWatermarkValve,\n        int inputIndex,\n        InflightDataRescalingDescriptor rescalingDescriptorinflightDataRescalingDescriptor,\n        Function<Integer, StreamPartitioner<?>> gatePartitioners,\n        TaskInfo taskInfo) {\n    return rescalingDescriptorinflightDataRescalingDescriptor.equals(\n                    InflightDataRescalingDescriptor.NO_RESCALE)\n            ? new StreamTaskNetworkInput<>(\n                    checkpointedInputGate,\n                    inputSerializer,\n                    ioManager,\n                    statusWatermarkValve,\n                    inputIndex)\n            : new RescalingStreamTaskNetworkInput<>(\n                    checkpointedInputGate,\n                    inputSerializer,\n                    ioManager,\n                    statusWatermarkValve,\n                    inputIndex,\n                    rescalingDescriptorinflightDataRescalingDescriptor,\n                    gatePartitioners,\n                    taskInfo);\n}", "summary_tokens": ["factory", "method", "for", "stream", "task", "network", "input", "or", "rescaling", "stream", "task", "network", "input", "depending", "on", "inflight", "data", "rescaling", "descriptor"], "project": "flink"}
{"id": 6316, "code": "public void testTimeoutOfFindConnectingAddress() throws Exception {\n    Duration timeout = Duration.ofSeconds(1L);\n\n    LeaderRetrievalService leaderRetrievalService =\n            highAvailabilityServices.getJobManagerLeaderRetriever(\n                    HighAvailabilityServices.DEFAULT_JOB_ID);\n    InetAddress result =\n            LeaderRetrievalUtils.findConnectingAddress(\n                    leaderRetrievalService, timeout, RPC_SYSTEM);\n\n    assertEquals(InetAddress.getLocalHost(), result);\n}", "summary_tokens": ["tests", "that", "the", "leader", "retrieval", "utils"], "project": "flink"}
{"id": 6802, "code": "public static void putNextValuePointer(\n        MemorySegment memorySegment, int offset, long nextValuePointer) {\n    memorySegment.putLong(offset + NEXT_VALUE_POINTER_OFFSET, nextValuePointer);\n}", "summary_tokens": ["puts", "the", "pointer", "of", "next", "value", "space"], "project": "flink"}
{"id": 760, "code": "public String getAnyMethodParameter(String key) {\n    String suffix = \".\" + key;\n    String protocolServiceKey = getProtocolServiceKey();\n    if (StringUtils.isNotEmpty(protocolServiceKey)) {\n        MetadataInfo.ServiceInfo serviceInfo = getServiceInfo(protocolServiceKey);\n        if (null == serviceInfo) {\n            return null;\n        }\n\n        for (String fullKey : serviceInfo.getAllParams().keySet()) {\n            if (fullKey.endsWith(suffix)) {\n                return getParameter(fullKey);\n            }\n        }\n    }\n    return null;\n}", "summary_tokens": ["gets", "method", "level", "value", "of", "the", "specified", "key"], "project": "dubbo"}
{"id": 516, "code": "private void createInvokerForLocal(Map<String, String> referenceParameters) {\n    URL url = new ServiceConfigURL(LOCAL_PROTOCOL, LOCALHOST_VALUE, 0, interfaceClass.getName(), referenceParameters);\n    url = url.setScopeModel(getScopeModel());\n    url = url.setServiceModel(consumerModel);\n    Invoker<?> withFilter = protocolSPI.refer(interfaceClass, url);\n        \n    List<Invoker<?>> invokers = new ArrayList<>();\n    invokers.add(withFilter);\n    invoker = Cluster.getCluster(url.getScopeModel(), Cluster.DEFAULT).join(new StaticDirectory(url, invokers), true);\n\n    if (logger.isInfoEnabled()) {\n        logger.info(\"Using in jvm service \" + interfaceClass.getName());\n    }\n}", "summary_tokens": ["make", "a", "local", "reference", "create", "a", "local", "invoker"], "project": "dubbo"}
{"id": 1068, "code": "private void unpack(ZookeeperContext context, int clientPort) throws DubboTestException {\n    File sourceFile = context.getSourceFile().toFile();\n    Path targetPath = Paths.get(context.getSourceFile().getParent().toString(),\n        String.valueOf(clientPort));\n        \n    if (targetPath.toFile() != null && targetPath.toFile().isDirectory()) {\n        logger.info(String.format(\"The file has been unpacked, target path:%s\", targetPath.toString()));\n        return;\n    }\n    try (FileInputStream fileInputStream = new FileInputStream(sourceFile);\n         GzipCompressorInputStream gzipCompressorInputStream = new GzipCompressorInputStream(fileInputStream);\n         TarArchiveInputStream tarArchiveInputStream = new TarArchiveInputStream(gzipCompressorInputStream, \"UTF-8\")) {\n        File targetFile = targetPath.toFile();\n        TarArchiveEntry entry;\n        while ((entry = tarArchiveInputStream.getNextTarEntry()) != null) {\n            if (entry.isDirectory()) {\n                continue;\n            }\n            File curFile = new File(targetFile, entry.getName());\n            File parent = curFile.getParentFile();\n            if (!parent.exists()) {\n                parent.mkdirs();\n            }\n            try (FileOutputStream outputStream = new FileOutputStream(curFile)) {\n                IOUtils.copy(tarArchiveInputStream, outputStream);\n            }\n        }\n    } catch (IOException e) {\n        throw new DubboTestException(String.format(\"Failed to unpack the zookeeper binary file\"), e);\n    }\n}", "summary_tokens": ["unpack", "the", "zookeeper", "binary", "file"], "project": "dubbo"}
{"id": 599, "code": "public boolean hasCalled() {\n    return called;\n}", "summary_tokens": ["returns", "if", "the", "filter", "has", "called"], "project": "dubbo"}
{"id": 969, "code": "private void batchClientRefIncr(List<ReferenceCountExchangeClient> referenceCountExchangeClients) {\n    if (CollectionUtils.isEmpty(referenceCountExchangeClients)) {\n        return;\n    }\n    referenceCountExchangeClients.stream()\n        .filter(Objects::nonNull)\n        .forEach(ReferenceCountExchangeClient::incrementAndGetCount);\n}", "summary_tokens": ["increase", "the", "reference", "count", "if", "we", "create", "new", "invoker", "shares", "same", "connection", "the", "connection", "will", "be", "closed", "without", "any", "reference"], "project": "dubbo"}
{"id": 1056, "code": "public int[] getClientPorts() {\n    return config.getClientPorts();\n}", "summary_tokens": ["returns", "the", "client", "ports", "of", "zookeeper"], "project": "dubbo"}
{"id": 306, "code": "public static List<String> mergeValues(ExtensionDirector extensionDirector, Class<?> type, String cfg, List<String> def) {\n    List<String> defaults = new ArrayList<String>();\n    if (def != null) {\n        for (String name : def) {\n            if (extensionDirector.getExtensionLoader(type).hasExtension(name)) {\n                defaults.add(name);\n            }\n        }\n    }\n\n    List<String> names = new ArrayList<String>();\n\n        \n    String[] configs = (cfg == null || cfg.trim().length() == 0) ? new String[0] : COMMA_SPLIT_PATTERN.split(cfg);\n    for (String config : configs) {\n        if (config != null && config.trim().length() > 0) {\n            names.add(config);\n        }\n    }\n\n        \n    if (!names.contains(REMOVE_VALUE_PREFIX + DEFAULT_KEY)) {\n            \n        int i = names.indexOf(DEFAULT_KEY);\n        if (i > 0) {\n            names.addAll(i, defaults);\n        } else {\n            names.addAll(0, defaults);\n        }\n        names.remove(DEFAULT_KEY);\n    } else {\n        names.remove(DEFAULT_KEY);\n    }\n\n        \n    for (String name : new ArrayList<String>(names)) {\n        if (name.startsWith(REMOVE_VALUE_PREFIX)) {\n            names.remove(name);\n            names.remove(name.substring(1));\n        }\n    }\n    return names;\n}", "summary_tokens": ["insert", "default", "extension", "into", "extension", "list"], "project": "dubbo"}
{"id": 861, "code": "private void fetchLatestAddresses() {\n        \n    Map<URL, Set<NotifyListener>> recoverSubscribed = new HashMap<>(getSubscribed());\n    if (!recoverSubscribed.isEmpty()) {\n        if (logger.isInfoEnabled()) {\n            logger.info(\"Fetching the latest urls of \" + recoverSubscribed.keySet());\n        }\n        for (Map.Entry<URL, Set<NotifyListener>> entry : recoverSubscribed.entrySet()) {\n            URL url = entry.getKey();\n            for (NotifyListener listener : entry.getValue()) {\n                removeFailedSubscribed(url, listener);\n                addFailedSubscribed(url, listener);\n            }\n        }\n    }\n}", "summary_tokens": ["when", "zookeeper", "connection", "recovered", "from", "a", "connection", "loss", "it", "needs", "to", "fetch", "the", "latest", "provider", "list"], "project": "dubbo"}
{"id": 144, "code": "public Converter<?, ?> getConverter(Class<?> sourceType, Class<?> targetType) {\n    Map<Class<?>, List<Converter>> toTargetMap = converterCache.computeIfAbsent(sourceType, (k) -> new ConcurrentHashMap<>());\n    List<Converter> converters = toTargetMap.computeIfAbsent(targetType, (k) -> frameworkModel.getExtensionLoader(Converter.class)\n        .getSupportedExtensionInstances()\n        .stream()\n        .filter(converter -> converter.accept(sourceType, targetType))\n        .collect(Collectors.toList()));\n\n    return converters.size() > 0 ? converters.get(0) : null;\n}", "summary_tokens": ["get", "the", "converter", "instance", "from", "extension", "loader", "with", "the", "specified", "source", "and", "target", "type"], "project": "dubbo"}
{"id": 177, "code": "public String getString(Map<String, ?> obj, String key) {\n    assert obj != null;\n    assert key != null;\n    if (!obj.containsKey(key)) {\n        return null;\n    }\n    Object value = obj.get(key);\n    if (!(value instanceof String)) {\n        throw new ClassCastException(\n            String.format(\"value '%s' for key '%s' in '%s' is not String\", value, key, obj));\n    }\n    return (String) value;\n}", "summary_tokens": ["gets", "a", "string", "from", "an", "object", "for", "the", "given", "key"], "project": "dubbo"}
{"id": 773, "code": "public void onEvent(ServiceInstancesChangedEvent event) {\n    if (destroyed.get() || !accept(event) || isRetryAndExpired(event)) {\n        return;\n    }\n    doOnEvent(event);\n}", "summary_tokens": ["on", "service", "instances", "changed", "event", "the", "service", "instances", "change", "event"], "project": "dubbo"}
{"id": 932, "code": "public Invoker<?> getInvoker() {\n    return invoker;\n}", "summary_tokens": ["replace", "to", "get", "url"], "project": "dubbo"}
{"id": 870, "code": "public static byte[] getNullBytesOf(Serialization s) {\n    return ID_NULLBYTES_MAP.computeIfAbsent(s.getContentTypeId(), k -> {\n            \n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        byte[] nullBytes = new byte[0];\n        try {\n            ObjectOutput out = s.serialize(null, baos);\n            out.writeObject(null);\n            out.flushBuffer();\n            nullBytes = baos.toByteArray();\n            baos.close();\n        } catch (Exception e) {\n            logger.warn(\"Serialization extension \" + s.getClass().getName() + \" not support serializing null object, return an empty bytes instead.\");\n        }\n        return nullBytes;\n    });\n}", "summary_tokens": ["get", "the", "null", "object", "serialize", "result", "byte", "of", "serialization", "from", "the", "cache", "if", "not", "generate", "it", "first"], "project": "dubbo"}
{"id": 175, "code": "public Integer getNumberAsInteger(Map<String, ?> obj, String key) {\n    assert obj != null;\n    assert key != null;\n    if (!obj.containsKey(key)) {\n        return null;\n    }\n    Object value = obj.get(key);\n    if (value instanceof Double) {\n        Double d = (Double) value;\n        int i = d.intValue();\n        if (i != d) {\n            throw new ClassCastException(\"Number expected to be integer: \" + d);\n        }\n        return i;\n    }\n    if (value instanceof String) {\n        try {\n            return Integer.parseInt((String) value);\n        } catch (NumberFormatException e) {\n            throw new IllegalArgumentException(\n                String.format(\"value '%s' for key '%s' is not an integer\", value, key));\n        }\n    }\n    throw new IllegalArgumentException(\n        String.format(\"value '%s' for key '%s' is not an integer\", value, key));\n}", "summary_tokens": ["gets", "a", "number", "from", "an", "object", "for", "the", "given", "key", "casted", "to", "an", "integer"], "project": "dubbo"}
{"id": 253, "code": "static <A extends Annotation> A getAnnotation(AnnotatedElement annotatedElement, String annotationClassName)\n        throws ClassCastException {\n    Class<? extends Annotation> annotationType = resolveAnnotationType(annotatedElement, annotationClassName);\n    if (annotationType == null) {\n        return null;\n    }\n    return (A) annotatedElement.getAnnotation(annotationType);\n}", "summary_tokens": ["get", "the", "annotation", "from", "the", "specified", "annotated", "element", "the", "annotated", "element", "and", "annotation", "annotation", "class", "name"], "project": "dubbo"}
{"id": 87, "code": "static Map<String, FileCacheStore> getCacheMap() {\n    return cacheMap;\n}", "summary_tokens": ["for", "unit", "test", "only"], "project": "dubbo"}
{"id": 795, "code": "public Map<URL, Invoker<T>> getUrlInvokerMap() {\n    return urlInvokerMap;\n}", "summary_tokens": ["haomin", "added", "for", "test", "purpose"], "project": "dubbo"}
{"id": 975, "code": "private void replaceWithLazyClient() {\n        \n    if (disconnectCount.getAndIncrement() % warningPeriod == 1) {\n        logger.warn(url.getAddress() + \" \" + url.getServiceKey() + \" safe guard client , should not be called ,must have a bug.\");\n    }\n\n        \n    if (!(client instanceof LazyConnectExchangeClient)) {\n        client = new LazyConnectExchangeClient(url, client.getExchangeHandler());\n    }\n}", "summary_tokens": ["when", "closing", "the", "client", "the", "client", "needs", "to", "be", "set", "to", "lazy", "connect", "exchange", "client", "and", "if", "a", "new", "call", "is", "made", "the", "client", "will", "resurrect"], "project": "dubbo"}
{"id": 29, "code": "private String getRule(URL url) {\n    String vRule = url.getParameterAndDecoded(RULE_KEY);\n    if (StringUtils.isEmpty(vRule)) {\n        throw new IllegalStateException(\"route rule can not be empty.\");\n    }\n    return vRule;\n}", "summary_tokens": ["get", "rule", "from", "url", "parameters"], "project": "dubbo"}
{"id": 204, "code": "public static long defaultLimit() {\n    checkAndScheduleRefresh();\n    return (long) (maxAvailable() * 0.8);\n}", "summary_tokens": ["by", "default", "it", "takes", "0", "of", "the", "maximum", "available", "memory", "of", "the", "current", "jvm"], "project": "dubbo"}
{"id": 27, "code": "protected DubboRoute getDubboRoute(VirtualServiceRule virtualServiceRule, Invocation invocation) {\n    String serviceName = invocation.getServiceName();\n\n    VirtualServiceSpec spec = virtualServiceRule.getSpec();\n    List<DubboRoute> dubboRouteList = spec.getDubbo();\n    if (CollectionUtils.isNotEmpty(dubboRouteList)) {\n        for (DubboRoute dubboRoute : dubboRouteList) {\n            List<StringMatch> stringMatchList = dubboRoute.getServices();\n            if (CollectionUtils.isEmpty(stringMatchList)) {\n                return dubboRoute;\n            }\n            for (StringMatch stringMatch : stringMatchList) {\n                if (stringMatch.isMatch(serviceName)) {\n                    return dubboRoute;\n                }\n            }\n        }\n    }\n    return null;\n}", "summary_tokens": ["match", "virtual", "service", "by", "service", "name"], "project": "dubbo"}
{"id": 843, "code": "void testSubscribe() {\n        \n    final URL[] notifyUrl = new URL[1];\n    for (int i = 0; i < 10; i++) {\n        registry.register(serviceUrl);\n        registry.subscribe(consumerUrl, urls -> {\n            notifyUrl[0] = urls.get(0);\n\n            Map<URL, Set<NotifyListener>> subscribed = registry.getSubscribed();\n            assertEquals(consumerUrl, subscribed.keySet().iterator().next());\n        });\n        if (!EMPTY_PROTOCOL.equalsIgnoreCase(notifyUrl[0].getProtocol())) {\n            break;\n        }\n    }\n    assertEquals(serviceUrl.toFullString(), notifyUrl[0].toFullString());\n}", "summary_tokens": ["test", "method", "for", "org"], "project": "dubbo"}
{"id": 900, "code": "public void setValue(Object value) {\n    try {\n        if (responseFuture.isDone()) {\n            responseFuture.get().setValue(value);\n        } else {\n            AppResponse appResponse = new AppResponse(invocation);\n            appResponse.setValue(value);\n            responseFuture.complete(appResponse);\n        }\n    } catch (Exception e) {\n            \n        logger.error(\"Got exception when trying to fetch the underlying result from AsyncRpcResult.\");\n        throw new RpcException(e);\n    }\n}", "summary_tokens": ["completable", "future", "can", "only", "be", "completed", "once", "so", "try", "to", "update", "the", "result", "of", "one", "completed", "completable", "future", "will", "have", "no", "effect"], "project": "dubbo"}
{"id": 997, "code": "default void disableAutoRequest() {\n    disableAutoFlowControl();\n}", "summary_tokens": ["swaps", "to", "manual", "flow", "control", "where", "no", "message", "will", "be", "delivered", "to", "stream", "observer", "on", "next", "object", "unless", "it", "is", "request", "request", "ed"], "project": "dubbo"}
{"id": 491, "code": "public void testCompileJavaClass0() throws Exception {\n    boolean ignoreWithoutPackage = shouldIgnoreWithoutPackage();\n    JavassistCompiler compiler = new JavassistCompiler();\n\n    if (ignoreWithoutPackage) {\n        Assertions.assertThrows(RuntimeException.class, () -> compiler.compile(null, getSimpleCodeWithoutPackage(), JavassistCompiler.class.getClassLoader()));\n    } else {\n        Class<?> clazz = compiler.compile(null, getSimpleCodeWithoutPackage(), JavassistCompiler.class.getClassLoader());\n        Object instance = clazz.newInstance();\n        Method sayHello = instance.getClass().getMethod(\"sayHello\");\n        Assertions.assertEquals(\"Hello world!\", sayHello.invoke(instance));\n    }\n}", "summary_tokens": ["javassist", "compile", "will", "find", "hello", "service", "in", "classpath"], "project": "dubbo"}
{"id": 327, "code": "static Predicate<Method> excludedDeclaredClass(Class<?> declaredClass) {\n    return method -> !Objects.equals(declaredClass, method.getDeclaringClass());\n}", "summary_tokens": ["create", "an", "instance", "of", "predicate", "for", "method", "to", "exclude", "the", "specified", "declared", "class"], "project": "dubbo"}
{"id": 80, "code": "private static Set<String> getResources(String path) throws IOException {\n    Enumeration<URL> urls = ClassUtils.getCallerClassLoader(Version.class).getResources(path);\n    Set<String> files = new HashSet<String>();\n    while (urls.hasMoreElements()) {\n        URL url = urls.nextElement();\n        if (url != null) {\n            String file = url.getFile();\n            if (StringUtils.isNotEmpty(file)) {\n                files.add(file);\n            }\n        }\n    }\n    return files;\n}", "summary_tokens": ["search", "resources", "in", "caller", "s", "classloader"], "project": "dubbo"}
{"id": 445, "code": "public MethodDefinition build(Method method) {\n\n    MethodDefinition md = new MethodDefinition();\n    md.setName(method.getName());\n\n        \n    Class<?>[] paramTypes = method.getParameterTypes();\n    Type[] genericParamTypes = method.getGenericParameterTypes();\n\n    int paramSize = paramTypes.length;\n    String[] parameterTypes = new String[paramSize];\n    List<TypeDefinition> parameters = new ArrayList<>(paramSize);\n    for (int i = 0; i < paramSize; i++) {\n        TypeDefinition parameter = builder.build(genericParamTypes[i], paramTypes[i]);\n        parameterTypes[i] = parameter.getType();\n        parameters.add(parameter);\n    }\n\n    md.setParameterTypes(parameterTypes);\n    md.setParameters(parameters);\n\n        \n    TypeDefinition td = builder.build(method.getGenericReturnType(), method.getReturnType());\n    md.setReturnType(td.getType());\n\n    return md;\n}", "summary_tokens": ["build", "the", "instance", "of", "method", "definition"], "project": "dubbo"}
{"id": 545, "code": "private boolean supportsExtension(Class<?> extensionClass, String name) {\n    if (isNotEmpty(name)) {\n        ExtensionLoader extensionLoader = getExtensionLoader(extensionClass);\n        return extensionLoader.hasExtension(name);\n    }\n    return false;\n}", "summary_tokens": ["supports", "the", "extension", "with", "the", "specified", "class", "and", "name"], "project": "dubbo"}
{"id": 174, "code": "public Double getNumberAsDouble(Map<String, ?> obj, String key) {\n    assert obj != null;\n    assert key != null;\n    if (!obj.containsKey(key)) {\n        return null;\n    }\n    Object value = obj.get(key);\n    if (value instanceof Double) {\n        return (Double) value;\n    }\n    if (value instanceof String) {\n        try {\n            return Double.parseDouble((String) value);\n        } catch (NumberFormatException e) {\n            throw new IllegalArgumentException(\n                String.format(\"value '%s' for key '%s' is not a double\", value, key));\n        }\n    }\n    throw new IllegalArgumentException(\n        String.format(\"value '%s' for key '%s' in '%s' is not a number\", value, key, obj));\n}", "summary_tokens": ["gets", "a", "number", "from", "an", "object", "for", "the", "given", "key"], "project": "dubbo"}
{"id": 146, "code": "default Class<S> getSourceType() {\n    return findActualTypeArgument(getClass(), MultiValueConverter.class, 0);\n}", "summary_tokens": ["get", "the", "source", "type"], "project": "dubbo"}
{"id": 712, "code": "default String[] serviceParamsIncluded() {\n    return new String[0];\n}", "summary_tokens": ["params", "that", "need", "to", "be", "sent", "to", "metadata", "center"], "project": "dubbo"}
{"id": 289, "code": "public static <K, V> Map<V, K> flip(Map<K, V> map) {\n    if (isEmptyMap(map)) {\n        return (Map<V, K>) map;\n    }\n    Set<V> set = map.values().stream().collect(Collectors.toSet());\n    if (set.size() != map.size()) {\n        throw new IllegalArgumentException(\"The map value must be unique.\");\n    }\n    return map.entrySet()\n            .stream()\n            .collect(Collectors.toMap(Map.Entry::getValue, Map.Entry::getKey));\n}", "summary_tokens": ["flip", "the", "specified", "map"], "project": "dubbo"}
{"id": 382, "code": "public static boolean isEquals(String s1, String s2) {\n    if (s1 == null && s2 == null) {\n        return true;\n    }\n    if (s1 == null || s2 == null) {\n        return false;\n    }\n    return s1.equals(s2);\n}", "summary_tokens": ["if", "s", "0", "is", "null", "and", "s", "0", "is", "null", "then", "return", "true"], "project": "dubbo"}
{"id": 561, "code": "public void testMultipleRegistryForRemoteRefer() {\n    ReferenceConfig<DemoService> referenceConfig = new ReferenceConfig<>();\n    referenceConfig.setGeneric(Boolean.FALSE.toString());\n    referenceConfig.setProtocol(\"dubbo\");\n    referenceConfig.setInit(true);\n    referenceConfig.setLazy(false);\n    referenceConfig.setInjvm(false);\n\n    DubboBootstrap dubboBootstrap = DubboBootstrap.newInstance(FrameworkModel.defaultModel());\n\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"application1\");\n    Map<String, String> parameters = new HashMap<>();\n    parameters.put(\"key1\", \"value1\");\n    parameters.put(\"key2\", \"value2\");\n    applicationConfig.setParameters(parameters);\n\n    referenceConfig.refreshed.set(true);\n    referenceConfig.setInterface(DemoService.class);\n    referenceConfig.getInterfaceClass();\n    referenceConfig.setCheck(false);\n    RegistryConfig registry1 = new RegistryConfig();\n    registry1.setAddress(zkUrl1);\n    registry1.setId(\"zk1\");\n\n    RegistryConfig registry2 = new RegistryConfig();\n    registry2.setAddress(zkUrl2);\n    registry2.setId(\"zk2\");\n\n    List<RegistryConfig> registryConfigs = new ArrayList<>();\n    registryConfigs.add(registry1);\n    registryConfigs.add(registry2);\n    applicationConfig.setRegistries(registryConfigs);\n    applicationConfig.setRegistryIds(\"zk1,zk2\");\n\n    referenceConfig.setRegistries(registryConfigs);\n\n    dubboBootstrap\n        .application(applicationConfig)\n        .reference(referenceConfig)\n        .initialize();\n\n    referenceConfig.init();\n    Assertions.assertTrue(referenceConfig.getInvoker() instanceof ZoneAwareClusterInvoker);\n\n    dubboBootstrap.destroy();\n}", "summary_tokens": ["verify", "the", "service", "reference", "of", "multiple", "registries"], "project": "dubbo"}
{"id": 44, "code": "private List<Invoker<T>> selectMockInvoker(Invocation invocation) {\n    List<Invoker<T>> invokers = null;\n        \n    if (invocation instanceof RpcInvocation) {\n            \n        invocation.setAttachment(INVOCATION_NEED_MOCK, Boolean.TRUE.toString());\n            \n        try {\n            RpcContext.getServiceContext().setConsumerUrl(getUrl());\n            invokers = directory.list(invocation);\n        } catch (RpcException e) {\n            if (logger.isInfoEnabled()) {\n                logger.info(\"Exception when try to invoke mock. Get mock invokers error for service:\"\n                        + getUrl().getServiceInterface() + \", method:\" + invocation.getMethodName()\n                        + \", will construct a new mock with 'new MockInvoker()'.\", e);\n            }\n        }\n    }\n    return invokers;\n}", "summary_tokens": ["return", "mock", "invoker", "contract", "directory"], "project": "dubbo"}
{"id": 236, "code": "public URLParam addParameter(String key, String value) {\n    if (StringUtils.isEmpty(key) || StringUtils.isEmpty(value)) {\n        return this;\n    }\n    return addParameters(Collections.singletonMap(key, value));\n}", "summary_tokens": ["add", "parameters", "to", "a", "new", "urlparam"], "project": "dubbo"}
{"id": 610, "code": "private void afterInvoke() {\n        \n    Assertions.assertTrue(filter.hasCalled());\n        \n    Assertions.assertFalse(filter.hasError());\n        \n    Assertions.assertEquals(\"Hello Dubbo\", filter.getResponse());\n}", "summary_tokens": ["there", "are", "some", "checkpoints", "need", "to", "check", "after", "invoked", "as", "follow", "ul", "li", "the", "single", "registry", "center", "injvm", "filter", "has", "called", "or", "not", "li", "li", "the", "single", "registry", "center", "injvm", "filter", "exists", "error", "after", "invoked", "li", "li", "the", "single", "registry", "center", "injvm", "filter", "s", "response", "is", "right", "or", "not", "li", "ul"], "project": "dubbo"}
{"id": 805, "code": "public void testSubscribeMultipleProtocols() {\n    Set<String> serviceNames = new HashSet<>();\n    serviceNames.add(\"app1\");\n    listener = new ServiceInstancesChangedListener(serviceNames, serviceDiscovery);\n        \n    NotifyListener demoServiceListener1 = Mockito.mock(NotifyListener.class);\n    when(demoServiceListener1.getConsumerUrl()).thenReturn(noProtocolConsumerURL);\n    listener.addListenerAndNotify(noProtocolConsumerURL, demoServiceListener1);\n        \n    NotifyListener demoServiceListener2 = Mockito.mock(NotifyListener.class);\n    when(demoServiceListener2.getConsumerUrl()).thenReturn(multipleProtocolsConsumerURL);\n    listener.addListenerAndNotify(multipleProtocolsConsumerURL, demoServiceListener2);\n        \n    NotifyListener demoServiceListener3 = Mockito.mock(NotifyListener.class);\n    when(demoServiceListener3.getConsumerUrl()).thenReturn(singleProtocolsConsumerURL);\n    listener.addListenerAndNotify(singleProtocolsConsumerURL, demoServiceListener3);\n\n        \n    ServiceInstancesChangedEvent app1_event = new ServiceInstancesChangedEvent(\"app1\", app1InstancesMultipleProtocols);\n    listener.onEvent(app1_event);\n\n        \n    ArgumentCaptor<List<URL>> default_protocol_captor = ArgumentCaptor.forClass(List.class);\n    Mockito.verify(demoServiceListener1, Mockito.times(1)).notify(default_protocol_captor.capture());\n    List<URL> default_protocol_notifiedUrls = default_protocol_captor.getValue();\n    Assertions.assertEquals(4, default_protocol_notifiedUrls.size());\n        \n    ArgumentCaptor<List<URL>> multi_protocols_captor = ArgumentCaptor.forClass(List.class);\n    Mockito.verify(demoServiceListener2, Mockito.times(1)).notify(multi_protocols_captor.capture());\n    List<URL> multi_protocol_notifiedUrls = multi_protocols_captor.getValue();\n    Assertions.assertEquals(4, multi_protocol_notifiedUrls.size());\n        \n    ArgumentCaptor<List<URL>> single_protocols_captor = ArgumentCaptor.forClass(List.class);\n    Mockito.verify(demoServiceListener3, Mockito.times(1)).notify(single_protocols_captor.capture());\n    List<URL> single_protocol_notifiedUrls = single_protocols_captor.getValue();\n    Assertions.assertEquals(1, single_protocol_notifiedUrls.size());\n}", "summary_tokens": ["test", "subscribe", "multiple", "protocols"], "project": "dubbo"}
{"id": 224, "code": "public void dispatchThreadPoolExhaustedEvent(String msg) {\n    listeners.forEach(listener -> listener.onEvent(new ThreadPoolExhaustedEvent(msg)));\n}", "summary_tokens": ["dispatch", "thread", "pool", "exhausted", "event", "msg"], "project": "dubbo"}
{"id": 553, "code": "public static SimpleReferenceCache getCache(String name, KeyGenerator keyGenerator) {\n    return CACHE_HOLDER.computeIfAbsent(name, k -> new SimpleReferenceCache(k, keyGenerator));\n}", "summary_tokens": ["get", "the", "cache", "use", "specified", "key", "generator"], "project": "dubbo"}
{"id": 285, "code": "public static Class<?> resolveClass(String className, ClassLoader classLoader) {\n    Class<?> targetClass = null;\n    try {\n        targetClass = forName(className, classLoader);\n    } catch (Throwable ignored) { \n    }\n    return targetClass;\n}", "summary_tokens": ["resolve", "the", "class", "by", "the", "specified", "name", "and", "class", "loader"], "project": "dubbo"}
{"id": 2, "code": "default int compareTo(Configurator o) {\n    if (o == null) {\n        return -1;\n    }\n\n    int ipCompare = getUrl().getHost().compareTo(o.getUrl().getHost());\n        \n    if (ipCompare == 0) {\n        int i = getUrl().getParameter(PRIORITY_KEY, 0);\n        int j = o.getUrl().getParameter(PRIORITY_KEY, 0);\n        return Integer.compare(i, j);\n    } else {\n        return ipCompare;\n    }\n}", "summary_tokens": ["sort", "by", "host", "then", "by", "priority", "0"], "project": "dubbo"}
{"id": 806, "code": "public void testSubscribeMultipleGroups() {\n    Set<String> serviceNames = new HashSet<>();\n    serviceNames.add(\"app1\");\n    listener = new ServiceInstancesChangedListener(serviceNames, serviceDiscovery);\n\n        \n    ServiceInstancesChangedEvent event = new ServiceInstancesChangedEvent(\"app1\", app1Instances);\n    listener.onEvent(event);\n\n    Map<String, List<ServiceInstance>> allInstances = listener.getAllInstances();\n    Assertions.assertEquals(1, allInstances.size());\n    Assertions.assertEquals(3, allInstances.get(\"app1\").size());\n\n    ProtocolServiceKey protocolServiceKey = new ProtocolServiceKey(service1, null, null, \"dubbo\");\n    List<URL> serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, null, \"\", \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, null, \",group1\", \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, null, \"group1,\", \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, null, \"*\", \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, null, \"group1\", \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(0, serviceUrls.size());\n\n    protocolServiceKey = new ProtocolServiceKey(service1, null, \"group1,group2\", \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(0, serviceUrls.size());\n\n    protocolServiceKey = new ProtocolServiceKey(service1, null, \"group1,,group2\", \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n}", "summary_tokens": ["test", "subscribe", "multiple", "groups"], "project": "dubbo"}
{"id": 908, "code": "public static RpcServiceContext getServiceContext() {\n    return SERVICE_CONTEXT.get();\n}", "summary_tokens": ["using", "to", "pass", "environment", "parameters", "in", "the", "whole", "invocation"], "project": "dubbo"}
{"id": 192, "code": "public final InternalThreadLocalMap threadLocalMap() {\n    return threadLocalMap;\n}", "summary_tokens": ["returns", "the", "internal", "data", "structure", "that", "keeps", "the", "thread", "local", "variables", "bound", "to", "this", "thread"], "project": "dubbo"}
{"id": 352, "code": "public static boolean isMulticastAddress(String host) {\n    int i = host.indexOf('.');\n    if (i > 0) {\n        String prefix = host.substring(0, i);\n        if (StringUtils.isNumber(prefix)) {\n            int p = Integer.parseInt(prefix);\n            return p >= 224 && p <= 239;\n        }\n    }\n    return false;\n}", "summary_tokens": ["is", "multicast", "address", "or", "not"], "project": "dubbo"}
{"id": 854, "code": "private List<String> getCategories(URL url) {\n    return ANY_VALUE.equals(url.getServiceInterface()) ?\n        ALL_SUPPORTED_CATEGORIES : Arrays.asList(DEFAULT_CATEGORY);\n}", "summary_tokens": ["get", "the", "categories", "from", "url"], "project": "dubbo"}
{"id": 759, "code": "public Map<String, String> getServiceParameters(String protocolServiceKey) {\n    Map<String, String> instanceParams = getInstance().getAllParams();\n    Map<String, String> metadataParams = (metadataInfo == null ? new HashMap<>() : metadataInfo.getParameters(protocolServiceKey));\n    int i = instanceParams == null ? 0 : instanceParams.size();\n    int j = metadataParams == null ? 0 : metadataParams.size();\n    Map<String, String> params = new HashMap<>((int) ((i + j) / 0.75) + 1);\n    if (instanceParams != null) {\n        params.putAll(instanceParams);\n    }\n    if (metadataParams != null) {\n        params.putAll(metadataParams);\n    }\n\n    URL consumerUrl = RpcContext.getServiceContext().getConsumerUrl();\n    if (consumerUrl != null) {\n        Map<String, String> consumerParams = new HashMap<>(consumerUrl.getParameters());\n        if (CollectionUtils.isNotEmpty(providerFirstParams)) {\n            providerFirstParams.forEach(consumerParams::remove);\n        }\n        params.putAll(consumerParams);\n    }\n    return params;\n}", "summary_tokens": ["avoid", "calling", "this", "method", "in", "rpc", "call"], "project": "dubbo"}
{"id": 964, "code": "private String exportOrUnexportCallbackService(Channel channel, RpcInvocation inv, URL url, Class clazz, Object inst, Boolean export) throws IOException {\n    int instid = System.identityHashCode(inst);\n\n    Map<String, String> params = new HashMap<>(3);\n        \n    params.put(IS_SERVER_KEY, Boolean.FALSE.toString());\n        \n    params.put(IS_CALLBACK_SERVICE, Boolean.TRUE.toString());\n    String group = (inv == null ? null : (String) inv.getObjectAttachmentWithoutConvert(GROUP_KEY));\n    if (group != null && group.length() > 0) {\n        params.put(GROUP_KEY, group);\n    }\n        \n    params.put(METHODS_KEY, StringUtils.join(ClassUtils.getDeclaredMethodNames(clazz), \",\"));\n\n    Map<String, String> tmpMap = new HashMap<>();\n    if (url != null) {\n        Map<String, String> parameters = url.getParameters();\n        if (parameters != null && !parameters.isEmpty()) {\n            tmpMap.putAll(parameters);\n        }\n    }\n    tmpMap.putAll(params);\n\n    tmpMap.remove(VERSION_KEY);\n    tmpMap.remove(Constants.BIND_PORT_KEY); \n    tmpMap.put(INTERFACE_KEY, clazz.getName());\n    URL exportUrl = new ServiceConfigURL(DubboProtocol.NAME, channel.getLocalAddress().getAddress().getHostAddress(),\n        channel.getLocalAddress().getPort(), clazz.getName() + \".\" + instid, tmpMap);\n\n        \n    String cacheKey = getClientSideCallbackServiceCacheKey(instid);\n    String countKey = getClientSideCountKey(clazz.getName());\n    if (export) {\n            \n        if (!channel.hasAttribute(cacheKey)) {\n            if (!isInstancesOverLimit(channel, url, clazz.getName(), instid, false)) {\n                ModuleModel moduleModel;\n                if (inv.getServiceModel() == null) {\n                        \n                    moduleModel = ApplicationModel.defaultModel().getDefaultModule();\n                    logger.error(\"Unable to get Service Model from Invocation. Please check if your invocation failed! \" +\n                        \"This error only happen in UT cases! Invocation:\" + inv);\n                } else {\n                    moduleModel = inv.getServiceModel().getModuleModel();\n                }\n\n                ServiceDescriptor serviceDescriptor = moduleModel.getServiceRepository().registerService(clazz);\n                ServiceMetadata serviceMetadata = new ServiceMetadata(clazz.getName() + \".\" + instid, exportUrl.getGroup(), exportUrl.getVersion(), clazz);\n                String serviceKey = BaseServiceMetadata.buildServiceKey(exportUrl.getPath(), group, exportUrl.getVersion());\n                ProviderModel providerModel = new ProviderModel(serviceKey, inst, serviceDescriptor, moduleModel, serviceMetadata, ClassUtils.getClassLoader(clazz));\n                moduleModel.getServiceRepository().registerProvider(providerModel);\n\n                exportUrl = exportUrl.setScopeModel(moduleModel);\n                exportUrl = exportUrl.setServiceModel(providerModel);\n                Invoker<?> invoker = proxyFactory.getInvoker(inst, clazz, exportUrl);\n                    \n                Exporter<?> exporter = protocolSPI.export(invoker);\n                    \n                channel.setAttribute(cacheKey, exporter);\n                logger.info(\"Export a callback service :\" + exportUrl + \", on \" + channel + \", url is: \" + url);\n                increaseInstanceCount(channel, countKey);\n            }\n        }\n    } else {\n        if (channel.hasAttribute(cacheKey)) {\n            Exporter<?> exporter = (Exporter<?>) channel.getAttribute(cacheKey);\n            exporter.unexport();\n            channel.removeAttribute(cacheKey);\n            decreaseInstanceCount(channel, countKey);\n        }\n    }\n    return String.valueOf(instid);\n}", "summary_tokens": ["export", "or", "unexport", "callback", "service", "on", "client", "side"], "project": "dubbo"}
{"id": 498, "code": "public void testPerformance() {\n    final InternalThreadLocal<String>[] caches = new InternalThreadLocal[PERFORMANCE_THREAD_COUNT];\n    final Thread mainThread = Thread.currentThread();\n    for (int i = 0; i < PERFORMANCE_THREAD_COUNT; i++) {\n        caches[i] = new InternalThreadLocal<String>();\n    }\n    Thread t = new InternalThread(new Runnable() {\n        @Override\n        public void run() {\n            for (int i = 0; i < PERFORMANCE_THREAD_COUNT; i++) {\n                caches[i].set(\"float.lu\");\n            }\n            long start = System.nanoTime();\n            for (int i = 0; i < PERFORMANCE_THREAD_COUNT; i++) {\n                for (int j = 0; j < GET_COUNT; j++) {\n                    caches[i].get();\n                }\n            }\n            long end = System.nanoTime();\n            System.out.println(\"take[\" + TimeUnit.NANOSECONDS.toMillis(end - start) +\n                    \"]ms\");\n            LockSupport.unpark(mainThread);\n        }\n    });\n    t.start();\n    LockSupport.park(mainThread);\n}", "summary_tokens": ["print", "take", "0", "ms", "p", "p", "this", "test", "is", "based", "on", "a", "machine", "with", "0", "core", "and", "0", "g", "memory"], "project": "dubbo"}
{"id": 168, "code": "static <T> Predicate<T> or(Predicate<T>... predicates) {\n    return of(predicates).reduce((a, b) -> a.or(b)).orElse(e -> true);\n}", "summary_tokens": ["a", "composed", "predicate", "that", "represents", "a", "short", "circuiting", "logical", "or", "of", "predicate", "predicates"], "project": "dubbo"}
{"id": 789, "code": "public URL getOriginalConsumerUrl() {\n    return this.consumerUrl;\n}", "summary_tokens": ["the", "original", "consumer", "url"], "project": "dubbo"}
{"id": 415, "code": "protected List<Method> computeAttributedMethods() {\n    Class<? extends AbstractConfig> cls = this.getClass();\n    BeanInfo beanInfo = getBeanInfo(cls);\n    List<Method> methods = new ArrayList<>(beanInfo.getMethodDescriptors().length);\n    for (MethodDescriptor methodDescriptor : beanInfo.getMethodDescriptors()) {\n        Method method = methodDescriptor.getMethod();\n        if (MethodUtils.isGetter(method) || isParametersGetter(method)) {\n                \n            Parameter parameter = method.getAnnotation(Parameter.class);\n            if (parameter != null && !parameter.attribute()) {\n                continue;\n            }\n            String propertyName = calculateAttributeFromGetter(method.getName());\n                \n            if (!isWritableProperty(beanInfo, propertyName)) {\n                continue;\n            }\n            methods.add(method);\n        }\n    }\n    return methods;\n}", "summary_tokens": ["compute", "attributed", "getter", "methods", "subclass", "can", "override", "this", "method", "to", "add", "remove", "attributed", "methods"], "project": "dubbo"}
{"id": 864, "code": "private static void timeoutCheck(DefaultFuture future) {\n    TimeoutCheckTask task = new TimeoutCheckTask(future.getId());\n    future.timeoutCheckTask = TIME_OUT_TIMER.get().newTimeout(task, future.getTimeout(), TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["check", "time", "out", "of", "the", "future"], "project": "dubbo"}
{"id": 64, "code": "public static URL valueOf(String url, boolean encoded) {\n    if (encoded) {\n        return URLStrParser.parseEncodedStr(url);\n    }\n    return URLStrParser.parseDecodedStr(url);\n}", "summary_tokens": ["parse", "normal", "or", "encoded", "url", "string", "into", "strutted", "url", "dubbo", "host", "port", "path", "param", "value", "url"], "project": "dubbo"}
{"id": 544, "code": "private boolean isUsedRegistryAsCenter(RegistryConfig registryConfig, Supplier<Boolean> usedRegistryAsCenter,\n                                       String centerType,\n                                       Class<?> extensionClass) {\n    final boolean supported;\n\n    Boolean configuredValue = usedRegistryAsCenter.get();\n    if (configuredValue != null) { \n        supported = configuredValue.booleanValue();\n    } else {                       \n        String protocol = registryConfig.getProtocol();\n        supported = supportsExtension(extensionClass, protocol);\n        if (logger.isInfoEnabled()) {\n            logger.info(format(\"No value is configured in the registry, the %s extension[name : %s] %s as the %s center\"\n                , extensionClass.getSimpleName(), protocol, supported ? \"supports\" : \"does not support\", centerType));\n        }\n    }\n\n    if (logger.isInfoEnabled()) {\n        logger.info(format(\"The registry[%s] will be %s as the %s center\", registryConfig,\n            supported ? \"used\" : \"not used\", centerType));\n    }\n    return supported;\n}", "summary_tokens": ["is", "used", "the", "specified", "registry", "as", "a", "center", "infrastructure"], "project": "dubbo"}
{"id": 565, "code": "private Filter getFilter(FilterChainBuilder.CopyOfFilterChainNode filterChainNode) {\n    if (filterChainNode != null) {\n        Field field = null;\n        try {\n            field = filterChainNode.getClass().getDeclaredField(\"filter\");\n            field.setAccessible(true);\n            return (Filter) field.get(filterChainNode);\n        } catch (NoSuchFieldException | IllegalAccessException e) {\n                \n        }\n    }\n    return null;\n}", "summary_tokens": ["use", "reflection", "to", "obtain", "filter"], "project": "dubbo"}
{"id": 724, "code": "protected void processServiceRestMetadata(ServiceRestMetadata serviceRestMetadata, Class<?> serviceType) {\n    ServiceAnnotationResolver resolver = new ServiceAnnotationResolver(serviceType);\n    serviceRestMetadata.setServiceInterface(resolver.resolveInterfaceClassName());\n    serviceRestMetadata.setVersion(resolver.resolveVersion());\n    serviceRestMetadata.setGroup(resolver.resolveGroup());\n}", "summary_tokens": ["process", "the", "service", "type", "including", "the", "sub", "routines", "ul", "li", "service", "rest", "metadata", "set", "service", "interface", "string", "li", "li", "service", "rest", "metadata", "set", "version", "string", "li", "li", "service", "rest", "metadata", "set", "group", "string", "li", "ul"], "project": "dubbo"}
{"id": 267, "code": "public static boolean isEmpty(final Object[] array) {\n    return array == null || array.length == 0;\n}", "summary_tokens": ["p", "checks", "if", "the", "array", "is", "null", "or", "empty"], "project": "dubbo"}
{"id": 957, "code": "public void testAppResponseWithEmptyStackTraceException() {\n    Throwable throwable = buildEmptyStackTraceException();\n    assumeFalse(throwable == null);\n    AppResponse appResponse = new AppResponse(throwable);\n\n    StackTraceElement[] stackTrace = appResponse.getException().getStackTrace();\n    Assertions.assertNotNull(stackTrace);\n    Assertions.assertEquals(0,stackTrace.length);\n}", "summary_tokens": ["please", "run", "this", "test", "in", "run", "mode"], "project": "dubbo"}
{"id": 251, "code": "static <T> T getAttribute(Annotation annotation, String attributeName) throws IllegalArgumentException {\n    return annotation == null ? null : invokeMethod(annotation, attributeName);\n}", "summary_tokens": ["get", "the", "attribute", "from", "the", "specified", "annotation", "annotation"], "project": "dubbo"}
{"id": 871, "code": "public static byte[] getPayload(InputStream is) throws IOException {\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    byte[] buffer = getBuffer(is.available());\n    int len;\n    while ((len = is.read(buffer)) > -1) {\n        baos.write(buffer, 0, len);\n    }\n    baos.flush();\n    return baos.toByteArray();\n}", "summary_tokens": ["read", "all", "payload", "to", "byte"], "project": "dubbo"}
{"id": 214, "code": "public synchronized ExecutorService createExecutorIfAbsent(URL url) {\n    Map<Integer, ExecutorService> executors = data.computeIfAbsent(getExecutorKey(url), k -> new ConcurrentHashMap<>());\n        \n    Integer portKey = CONSUMER_SIDE.equalsIgnoreCase(url.getParameter(SIDE_KEY)) ? Integer.MAX_VALUE : url.getPort();\n\n    String protocol = url.getProtocol();\n    if (StringUtils.isEmpty(protocol)) {\n        protocol = DEFAULT_PROTOCOL;\n    }\n\n    if (url.getParameter(THREAD_NAME_KEY) == null) {\n        url = url.putAttribute(THREAD_NAME_KEY, protocol + \"-protocol-\" + portKey);\n    }\n    URL finalUrl = url;\n    ExecutorService executor = executors.computeIfAbsent(portKey, k -> createExecutor(finalUrl));\n        \n    if (executor.isShutdown() || executor.isTerminated()) {\n        executors.remove(portKey);\n        executor = createExecutor(url);\n        executors.put(portKey, executor);\n    }\n    return executor;\n}", "summary_tokens": ["get", "called", "when", "the", "server", "or", "client", "instance", "initiating"], "project": "dubbo"}
{"id": 32, "code": "private Bindings createBindings(List<Invoker<T>> invokers, Invocation invocation) {\n    Bindings bindings = engine.createBindings();\n        \n    bindings.put(\"invokers\", new ArrayList<>(invokers));\n    bindings.put(\"invocation\", invocation);\n    bindings.put(\"context\", RpcContext.getClientAttachment());\n    return bindings;\n}", "summary_tokens": ["create", "bindings", "for", "script", "engine"], "project": "dubbo"}
{"id": 926, "code": "public String getLocalHostName() {\n    String host = localAddress == null ? null : localAddress.getHostName();\n    if (StringUtils.isEmpty(host)) {\n        return getLocalHost();\n    }\n    return host;\n}", "summary_tokens": ["get", "local", "host", "name"], "project": "dubbo"}
{"id": 836, "code": "private void clean() {\n    if (admin) {\n        for (Set<URL> providers : new HashSet<Set<URL>>(received.values())) {\n            for (URL url : new HashSet<URL>(providers)) {\n                if (isExpired(url)) {\n                    if (logger.isWarnEnabled()) {\n                        logger.warn(\"Clean expired provider \" + url);\n                    }\n                    doUnregister(url);\n                }\n            }\n        }\n    }\n}", "summary_tokens": ["remove", "the", "expired", "providers", "only", "when", "clean", "parameter", "is", "true"], "project": "dubbo"}
{"id": 568, "code": "private String generateKey(String host, int port) {\n    return String.format(\"%s:%d\", host, port);\n}", "summary_tokens": ["generate", "the", "key", "for", "storage"], "project": "dubbo"}
{"id": 566, "code": "private FilterChainBuilder.CopyOfFilterChainNode getNextNode(FilterChainBuilder.CopyOfFilterChainNode filterChainNode) {\n    if (filterChainNode != null) {\n        Field field = null;\n        try {\n            field = filterChainNode.getClass().getDeclaredField(\"nextNode\");\n            field.setAccessible(true);\n            Object object = field.get(filterChainNode);\n            if (object instanceof FilterChainBuilder.CopyOfFilterChainNode) {\n                return (FilterChainBuilder.CopyOfFilterChainNode) object;\n            }\n        } catch (NoSuchFieldException | IllegalAccessException e) {\n                \n        }\n    }\n    return null;\n}", "summary_tokens": ["use", "reflection", "to", "obtain", "filter", "chain", "builder"], "project": "dubbo"}
{"id": 986, "code": "private int getErrorCode(Throwable e) {\n    if (e instanceof StatusException) {\n        StatusException statusException = (StatusException) e;\n        Status status = statusException.getStatus();\n        if (status.getCode() == Status.Code.DEADLINE_EXCEEDED) {\n            return RpcException.TIMEOUT_EXCEPTION;\n        }\n    }\n    return RpcException.UNKNOWN_EXCEPTION;\n}", "summary_tokens": ["fixme", "convert", "g", "rpc", "exceptions", "to", "equivalent", "dubbo", "exceptions"], "project": "dubbo"}
{"id": 815, "code": "public void test() throws InterruptedException {\n    DynamicConfiguration dynamicConfiguration = Mockito.mock(DynamicConfiguration.class);\n\n    ApplicationModel.reset();\n    ApplicationModel.defaultModel().getDefaultModule().getModelEnvironment().setDynamicConfiguration(dynamicConfiguration);\n    ApplicationModel.defaultModel().getDefaultModule().getModelEnvironment().setLocalMigrationRule(localRule);\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"demo-consumer\");\n    ApplicationModel.defaultModel().getApplicationConfigManager().setApplication(applicationConfig);\n\n    URL consumerURL = Mockito.mock(URL.class);\n    Mockito.when(consumerURL.getServiceKey()).thenReturn(\"Test\");\n    Mockito.when(consumerURL.getParameter(\"timestamp\")).thenReturn(\"1\");\n\n    System.setProperty(\"dubbo.application.migration.delay\", \"1000\");\n    MigrationRuleHandler<?> handler = Mockito.mock(MigrationRuleHandler.class, Mockito.withSettings().verboseLogging());\n\n    MigrationRuleListener migrationRuleListener = new MigrationRuleListener(ApplicationModel.defaultModel().getDefaultModule());\n\n    MigrationInvoker<?> migrationInvoker = Mockito.mock(MigrationInvoker.class);\n    migrationRuleListener.getHandlers().put(migrationInvoker, handler);\n\n    Thread.sleep(2000);\n    Mockito.verify(handler, Mockito.timeout(5000)).doMigrate(Mockito.any());\n\n    migrationRuleListener.onRefer(null, migrationInvoker, consumerURL, null);\n    Mockito.verify(handler, Mockito.times(2)).doMigrate(Mockito.any());\n\n    ApplicationModel.reset();\n}", "summary_tokens": ["listener", "started", "with", "config", "center", "and", "local", "rule", "no", "initial", "remote", "rule"], "project": "dubbo"}
{"id": 532, "code": "public boolean isStarting() {\n    return applicationDeployer.isStarting();\n}", "summary_tokens": ["true", "if", "the", "dubbo", "application", "is", "starting"], "project": "dubbo"}
{"id": 239, "code": "public URLParam addParametersIfAbsent(Map<String, String> parameters) {\n    if (CollectionUtils.isEmptyMap(parameters)) {\n        return this;\n    }\n\n    return doAddParameters(parameters, true);\n}", "summary_tokens": ["add", "absent", "parameters", "to", "a", "new", "urlparam"], "project": "dubbo"}
{"id": 708, "code": "public void init() {\n    if (!initiated.compareAndSet(false, true)) {\n        return;\n    }\n    if (CollectionUtils.isNotEmptyMap(services)) {\n        services.forEach((_k, serviceInfo) -> {\n            serviceInfo.init();\n                \n            if (subscribedServices == null) {\n                subscribedServices = new HashMap<>();\n            }\n            Set<ServiceInfo> serviceInfos = subscribedServices.computeIfAbsent(serviceInfo.getServiceKey(), _key -> new HashSet<>());\n            serviceInfos.add(serviceInfo);\n        });\n    }\n}", "summary_tokens": ["initialize", "is", "needed", "when", "metadata", "info", "is", "created", "from", "deserialization", "on", "the", "consumer", "side", "before", "being", "used", "for", "rpc", "call"], "project": "dubbo"}
{"id": 503, "code": "public void testToCommaDelimitedString() {\n    String value = toCommaDelimitedString(null);\n    assertNull(value);\n\n    value = toCommaDelimitedString(null, null);\n    assertNull(value);\n\n    value = toCommaDelimitedString(\"\");\n    assertEquals(\"\", value);\n\n    value = toCommaDelimitedString(\"one\");\n    assertEquals(\"one\", value);\n\n    value = toCommaDelimitedString(\"one\", \"two\");\n    assertEquals(\"one,two\", value);\n\n    value = toCommaDelimitedString(\"one\", \"two\", \"three\");\n    assertEquals(\"one,two,three\", value);\n}", "summary_tokens": ["test", "string", "utils", "to", "comma", "delimited", "string", "string", "string"], "project": "dubbo"}
{"id": 644, "code": "public ServiceBean getServiceBean() {\n    return (ServiceBean) super.getSource();\n}", "summary_tokens": ["get", "service", "bean", "instance"], "project": "dubbo"}
{"id": 928, "code": "public String getRemoteHostName() {\n    return remoteAddress == null ? null : remoteAddress.getHostName();\n}", "summary_tokens": ["get", "remote", "host", "name"], "project": "dubbo"}
{"id": 904, "code": "public static RpcContextAttachment getServerContext() {\n    return SERVER_LOCAL.get();\n}", "summary_tokens": ["get", "server", "side", "context"], "project": "dubbo"}
{"id": 851, "code": "private String getLegacySubscribedServiceName(URL url) {\n    StringBuilder serviceNameBuilder = new StringBuilder(DEFAULT_CATEGORY);\n    appendIfPresent(serviceNameBuilder, url, INTERFACE_KEY);\n    appendIfPresent(serviceNameBuilder, url, VERSION_KEY);\n    appendIfPresent(serviceNameBuilder, url, GROUP_KEY);\n    return serviceNameBuilder.toString();\n}", "summary_tokens": ["get", "the", "legacy", "subscribed", "service", "name", "for", "compatible", "with", "dubbo", "0"], "project": "dubbo"}
{"id": 699, "code": "protected Cache createCache(URL url) {\n    return new ThreadLocalCache(url);\n}", "summary_tokens": ["takes", "url", "as", "an", "method", "argument", "and", "return", "new", "instance", "of", "cache", "store", "implemented", "by", "thread", "local", "cache"], "project": "dubbo"}
{"id": 35, "code": "public final void setNextRouter(StateRouter<T> nextRouter) {\n    this.nextRouter = nextRouter;\n}", "summary_tokens": ["next", "router", "node", "state", "is", "maintained", "by", "abstract", "state", "router", "and", "this", "method", "is", "not", "allow", "to", "override"], "project": "dubbo"}
{"id": 349, "code": "public static NetworkInterface findNetworkInterface() {\n\n    List<NetworkInterface> validNetworkInterfaces = emptyList();\n    try {\n        validNetworkInterfaces = getValidNetworkInterfaces();\n    } catch (Throwable e) {\n        logger.warn(e);\n    }\n\n    NetworkInterface result = null;\n\n        \n    for (NetworkInterface networkInterface : validNetworkInterfaces) {\n        if (isPreferredNetworkInterface(networkInterface)) {\n            result = networkInterface;\n            break;\n        }\n    }\n\n    if (result == null) { \n        for (NetworkInterface networkInterface : validNetworkInterfaces) {\n            Enumeration<InetAddress> addresses = networkInterface.getInetAddresses();\n            while (addresses.hasMoreElements()) {\n                Optional<InetAddress> addressOp = toValidAddress(addresses.nextElement());\n                if (addressOp.isPresent()) {\n                    try {\n                        if (addressOp.get().isReachable(100)) {\n                            return networkInterface;\n                        }\n                    } catch (IOException e) {\n                            \n                    }\n                }\n            }\n        }\n    }\n\n    if (result == null) {\n        result = first(validNetworkInterfaces);\n    }\n\n    return result;\n}", "summary_tokens": ["get", "the", "suitable", "network", "interface"], "project": "dubbo"}
{"id": 462, "code": "public static ExecutorRepository getExecutorRepository() {\n    return defaultModel().getApplicationExecutorRepository();\n}", "summary_tokens": ["replace", "to", "application", "model", "get", "application", "executor", "repository"], "project": "dubbo"}
{"id": 564, "code": "private FilterChainBuilder.CopyOfFilterChainNode getFilterChainNode(FilterChainBuilder.CallbackRegistrationInvoker callbackRegistrationInvoker) {\n    if (callbackRegistrationInvoker != null) {\n        Field field = null;\n        try {\n            field = callbackRegistrationInvoker.getClass().getDeclaredField(\"filterInvoker\");\n            field.setAccessible(true);\n            return (FilterChainBuilder.CopyOfFilterChainNode) field.get(callbackRegistrationInvoker);\n        } catch (NoSuchFieldException | IllegalAccessException e) {\n                \n        }\n    }\n    return null;\n}", "summary_tokens": ["use", "reflection", "to", "obtain", "filter"], "project": "dubbo"}
{"id": 603, "code": "private void afterInvoke() {\n        \n    Assertions.assertTrue(filter.hasCalled());\n        \n    Assertions.assertFalse(filter.hasError());\n        \n    Assertions.assertEquals(\"Hello \" + PROVIDER_APPLICATION_NAME, filter.getResponse());\n}", "summary_tokens": ["there", "are", "some", "checkpoints", "need", "to", "check", "after", "invoked", "as", "follow", "ul", "li", "the", "single", "registry", "center", "export", "provider", "filter", "has", "called", "or", "not", "li", "li", "the", "single", "registry", "center", "export", "provider", "filter", "exists", "error", "after", "invoked", "li", "li", "the", "single", "registry", "center", "export", "provider", "filter", "s", "response", "is", "right", "or", "not", "li", "ul"], "project": "dubbo"}
{"id": 725, "code": "protected void processAllRestMethodMetadata(ServiceRestMetadata serviceRestMetadata, Class<?> serviceType) {\n    Class<?> serviceInterfaceClass = resolveServiceInterfaceClass(serviceRestMetadata, serviceType);\n    Map<Method, Method> serviceMethodsMap = resolveServiceMethodsMap(serviceType, serviceInterfaceClass);\n    for (Map.Entry<Method, Method> entry : serviceMethodsMap.entrySet()) {\n            \n        Method serviceMethod = entry.getKey();\n            \n        if (!processRestMethodMetadata(serviceMethod, serviceType, serviceInterfaceClass, serviceRestMetadata.getMeta()::add)) {\n            Method declaredServiceMethod = entry.getValue();\n            processRestMethodMetadata(declaredServiceMethod, serviceType, serviceInterfaceClass,\n                    serviceRestMetadata.getMeta()::add);\n        }\n    }\n}", "summary_tokens": ["process", "all", "rest", "method", "metadata"], "project": "dubbo"}
{"id": 798, "code": "protected ServiceAddressURL createURL(String rawProvider, URL consumerURL, Map<String, String> extraParameters) {\n\n    boolean encoded = true;\n\n        \n    int paramStartIdx = rawProvider.indexOf(ENCODED_QUESTION_MARK);\n\n    if (paramStartIdx == -1) {\n            \n        encoded = false;\n    }\n\n        \n        \n        \n    String[] parts = URLStrParser.parseRawURLToArrays(rawProvider, paramStartIdx);\n\n    if (parts.length <= 1) {\n            \n        logger.warn(\"1-5\", \"\", \"\",\n            \"Received url without any parameters \" + rawProvider);\n\n        return DubboServiceAddressURL.valueOf(rawProvider, consumerURL);\n    }\n\n    String rawAddress = parts[0];\n    String rawParams = parts[1];\n\n        \n    boolean isEncoded = encoded;\n\n        \n    URLAddress address = stringAddress.computeIfAbsent(rawAddress, k -> URLAddress.parse(k, getDefaultURLProtocol(), isEncoded));\n    address.setTimestamp(System.currentTimeMillis());\n\n    URLParam param = stringParam.computeIfAbsent(rawParams, k -> URLParam.parse(k, isEncoded, extraParameters));\n    param.setTimestamp(System.currentTimeMillis());\n\n        \n    ServiceAddressURL cachedServiceAddressURL = createServiceURL(address, param, consumerURL);\n\n    if (isMatch(consumerURL, cachedServiceAddressURL)) {\n        return cachedServiceAddressURL;\n    }\n\n    return null;\n}", "summary_tokens": ["create", "dubbo", "service", "address", "object", "using", "provider", "url", "consumer", "url", "and", "extra", "parameters"], "project": "dubbo"}
{"id": 186, "code": "public final boolean release() {\n    long remainingCount = COUNTER_UPDATER.decrementAndGet(this);\n\n    if (remainingCount == 0) {\n        destroy();\n        return true;\n    } else if (remainingCount <= -1) {\n        logger.warn(\"This instance has been destroyed\");\n        return false;\n    } else {\n        return false;\n    }\n}", "summary_tokens": ["decreases", "the", "reference", "count", "by", "0", "and", "calls", "this", "destroy", "if", "the", "reference", "count", "reaches", "0"], "project": "dubbo"}
{"id": 510, "code": "public Set<String> getSubscribedServices() {\n    return splitToSet(getServices(), COMMA_SEPARATOR_CHAR);\n}", "summary_tokens": ["it", "s", "an", "alias", "method", "for", "get", "services", "but", "the", "more", "convenient"], "project": "dubbo"}
{"id": 203, "code": "public static long calculate(final float percentage) {\n    if (percentage <= 0 || percentage > 1) {\n        throw new IllegalArgumentException();\n    }\n    checkAndScheduleRefresh();\n    return (long) (maxAvailable() * percentage);\n}", "summary_tokens": ["take", "the", "current", "jvm", "s", "maximum", "available", "memory", "as", "a", "percentage", "of", "the", "result", "as", "the", "limit"], "project": "dubbo"}
{"id": 739, "code": "boolean isListPropertyGettingMethod(Method method) {\n    String methodName = method.getName();\n    Class<?> type = method.getReturnType();\n\n\n    if (!methodName.startsWith(\"get\") || !methodName.endsWith(\"List\")) {\n        return false;\n    }\n\n        \n    if (methodName.endsWith(\"BuilderList\")) {\n        return false;\n    }\n\n        \n    if (!List.class.isAssignableFrom(type)) {\n        return false;\n    }\n\n    return true;\n}", "summary_tokens": ["judge", "list", "property", "br", "proto", "0", "grammar", "ex", "repeated", "string", "names", "br", "generated", "getting", "method", "list", "string", "get", "names", "list"], "project": "dubbo"}
{"id": 886, "code": "public void testToList() {\n    List<List<String>> table = new LinkedList<>();\n    table.add(Arrays.asList(\"abc\",\"abc\",\"abc\"));\n    table.add(Arrays.asList(\"1\",\"2\",\"3\"));\n    table.add(Arrays.asList(\"x\",\"y\",\"z\"));\n\n    String toList = TelnetUtils.toList(table);\n\n    Assertions.assertTrue(toList.contains(\"abc - abc - abc\"));\n    Assertions.assertTrue(toList.contains(\"1   - 2   - 3\"));\n    Assertions.assertTrue(toList.contains(\"x   - y   - z\"));\n}", "summary_tokens": ["abc", "abc", "abc", "0", "0", "0", "x", "y", "z"], "project": "dubbo"}
{"id": 533, "code": "public boolean isStarted() {\n    return applicationDeployer.isStarted();\n}", "summary_tokens": ["true", "if", "the", "dubbo", "application", "has", "been", "started"], "project": "dubbo"}
{"id": 941, "code": "public long getAverageTps() {\n    if (getTotalElapsed() >= 1000L) {\n        return getTotal() / (getTotalElapsed() / 1000L);\n    }\n    return getTotal();\n}", "summary_tokens": ["calculate", "average", "tps", "transaction", "per", "second"], "project": "dubbo"}
{"id": 447, "code": "public static String schema(final Class<?> clazz) {\n    ServiceDefinition sd = build(clazz);\n    return JsonUtils.getJson().toJson(sd);\n}", "summary_tokens": ["describe", "a", "java", "interface", "in", "json", "schema"], "project": "dubbo"}
{"id": 51, "code": "public void testMockInvokerInvoke_failmock() {\n    URL url = URL.valueOf(\"remote://1.2.3.4/\" + IHelloService.class.getName())\n            .addParameter(REFER_KEY,\n                    URL.encode(PATH_KEY + \"=\" + IHelloService.class.getName()\n                            + \"&\" + \"mock=fail:return null\"))\n            .addParameter(\"invoke_return_error\", \"true\");\n    URL mockUrl = URL.valueOf(\"mock://localhost/\" + IHelloService.class.getName())\n            .addParameter(\"mock\",\"fail:return null\")\n            .addParameter(\"getSomething.mock\",\"return aa\")\n            .addParameter(REFER_KEY, URL.encode(PATH_KEY + \"=\" + IHelloService.class.getName()))\n            .addParameter(\"invoke_return_error\", \"true\");\n\n    Protocol protocol = new MockProtocol();\n    Invoker<IHelloService> mInvoker1 = protocol.refer(IHelloService.class, mockUrl);\n    Invoker<IHelloService> cluster = getClusterInvokerMock(url, mInvoker1);\n\n        \n    RpcInvocation invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething\");\n    Result ret = cluster.invoke(invocation);\n    Assertions.assertEquals(\"aa\", ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething2\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertNull(ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"sayHello\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertNull(ret.getValue());\n}", "summary_tokens": ["test", "if", "mock", "policy", "works", "fine", "fail", "mock"], "project": "dubbo"}
{"id": 181, "code": "public static void setLevel(Level level) {\n    LOGGER_ADAPTER.setLevel(level);\n}", "summary_tokens": ["set", "the", "current", "logging", "level"], "project": "dubbo"}
{"id": 781, "code": "public static String getExportedServicesRevision(ServiceInstance serviceInstance) {\n    return Optional.ofNullable(serviceInstance.getServiceMetadata())\n        .map(MetadataInfo::getRevision)\n        .filter(StringUtils::isNotEmpty)\n        .orElse(serviceInstance.getMetadata(EXPORTED_SERVICES_REVISION_PROPERTY_NAME));\n}", "summary_tokens": ["the", "revision", "for", "all", "exported", "dubbo", "services", "from", "the", "specified", "service", "instance"], "project": "dubbo"}
{"id": 670, "code": "public RegistryConfig registryConfig() {\n    RegistryConfig registryConfig = new RegistryConfig();\n    registryConfig.setAddress(\"N/A\");\n    return registryConfig;\n}", "summary_tokens": ["current", "registry", "center", "configuration", "to", "replace", "xml", "config", "prev", "lt", "dubbo", "registry", "address", "n", "a", "gt", "prev"], "project": "dubbo"}
{"id": 12, "code": "public <T> ClusterInvoker<T> buildClusterInvokerChain(final ClusterInvoker<T> originalInvoker, String key, String group) {\n    ClusterInvoker<T> last = originalInvoker;\n    URL url = originalInvoker.getUrl();\n    List<ModuleModel> moduleModels = getModuleModelsFromUrl(url);\n    List<ClusterFilter> filters;\n    if (moduleModels != null && moduleModels.size() == 1) {\n        filters = ScopeModelUtil.getExtensionLoader(ClusterFilter.class, moduleModels.get(0)).getActivateExtension(url, key, group);\n    } else if (moduleModels != null && moduleModels.size() > 1) {\n        filters = new ArrayList<>();\n        List<ExtensionDirector> directors = new ArrayList<>();\n        for (ModuleModel moduleModel : moduleModels) {\n            List<ClusterFilter> tempFilters = ScopeModelUtil.getExtensionLoader(ClusterFilter.class, moduleModel).getActivateExtension(url, key, group);\n            filters.addAll(tempFilters);\n            directors.add(moduleModel.getExtensionDirector());\n        }\n        filters = sortingAndDeduplication(filters, directors);\n\n    } else {\n        filters = ScopeModelUtil.getExtensionLoader(ClusterFilter.class, null).getActivateExtension(url, key, group);\n    }\n\n    if (!CollectionUtils.isEmpty(filters)) {\n        for (int i = filters.size() - 1; i >= 0; i--) {\n            final ClusterFilter filter = filters.get(i);\n            final Invoker<T> next = last;\n            last = new CopyOfClusterFilterChainNode<>(originalInvoker, next, filter);\n        }\n        return new ClusterCallbackRegistrationInvoker<>(originalInvoker, last, filters);\n    }\n\n    return last;\n}", "summary_tokens": ["build", "consumer", "cluster", "filter", "chain"], "project": "dubbo"}
{"id": 5, "code": "public void initWithRouters(List<Router> builtinRouters) {\n    this.builtinRouters = builtinRouters;\n    this.routers = new LinkedList<>(builtinRouters);\n}", "summary_tokens": ["the", "resident", "routers", "must", "being", "initialized", "before", "address", "notification"], "project": "dubbo"}
{"id": 229, "code": "public String getIp() {\n    if (ip == null) {\n        ip = NetUtils.getIpByHost(getHost());\n    }\n    return ip;\n}", "summary_tokens": ["fetch", "ip", "address", "for", "this", "url"], "project": "dubbo"}
{"id": 992, "code": "public String getMessage() {\n    Object ref = message_;\n    if (ref instanceof String) {\n        return (String) ref;\n    } else {\n        com.google.protobuf.ByteString bs =\n            (com.google.protobuf.ByteString) ref;\n        String s = bs.toStringUtf8();\n        message_ = s;\n        return s;\n    }\n}", "summary_tokens": ["code", "string", "message", "0", "code"], "project": "dubbo"}
{"id": 260, "code": "static <A extends Annotation> A findMetaAnnotation(AnnotatedElement annotatedElement, Class<A> metaAnnotationType) {\n    return first(findMetaAnnotations(annotatedElement, metaAnnotationType));\n}", "summary_tokens": ["find", "the", "meta", "annotation", "from", "the", "annotated", "element", "by", "meta", "annotation", "type"], "project": "dubbo"}
{"id": 250, "code": "static Predicate<Annotation> excludedType(Class<? extends Annotation> excludedAnnotationType) {\n    return annotation -> !isSameType(annotation, excludedAnnotationType);\n}", "summary_tokens": ["build", "an", "instance", "of", "predicate", "to", "excluded", "annotation", "type"], "project": "dubbo"}
{"id": 400, "code": "static List<ParameterizedType> getAllGenericTypes(Type type, Predicate<ParameterizedType>... typeFilters) {\n    List<ParameterizedType> allGenericTypes = new LinkedList<>();\n        \n    allGenericTypes.addAll(getAllGenericSuperClasses(type, typeFilters));\n        \n    allGenericTypes.addAll(getAllGenericInterfaces(type, typeFilters));\n        \n    return unmodifiableList(allGenericTypes);\n}", "summary_tokens": ["get", "all", "generic", "types", "including", "super", "classes", "and", "interfaces", "that", "are", "assignable", "from", "parameterized", "type", "interface"], "project": "dubbo"}
{"id": 291, "code": "public static boolean isNotEmpty(Collection<?> collection) {\n    return !isEmpty(collection);\n}", "summary_tokens": ["return", "true", "if", "the", "supplied", "collection", "is", "not", "null", "or", "not", "empty"], "project": "dubbo"}
{"id": 455, "code": "public static Collection<ConsumerModel> allConsumerModels() {\n    return defaultModel().getApplicationServiceRepository().allConsumerModels();\n}", "summary_tokens": ["use", "service", "repository", "all", "consumer", "models"], "project": "dubbo"}
{"id": 440, "code": "protected <T extends AbstractConfig> boolean isRequired(Class<T> clazz) {\n    if (clazz == RegistryConfig.class ||\n        clazz == MetadataReportConfig.class ||\n        clazz == MonitorConfig.class ||\n        clazz == MetricsConfig.class) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["the", "configuration", "that", "does", "not", "affect", "the", "main", "process", "is", "not", "necessary"], "project": "dubbo"}
{"id": 110, "code": "public void updateAppConfigMap(Map<String, String> map) {\n    this.appConfiguration.addProperties(map);\n}", "summary_tokens": ["merge", "target", "map", "properties", "into", "app", "configuration", "map"], "project": "dubbo"}
{"id": 429, "code": "public void setDispather(String dispather) {\n    setDispatcher(dispather);\n}", "summary_tokens": ["typo", "switch", "to", "use", "get", "dispatcher"], "project": "dubbo"}
{"id": 472, "code": "void tryDestroyProtocols() {\n    synchronized (instLock) {\n        if (pubApplicationModels.size() == 0) {\n            notifyProtocolDestroy();\n        }\n    }\n}", "summary_tokens": ["protocols", "are", "special", "resources", "that", "need", "to", "be", "destroyed", "as", "soon", "as", "possible"], "project": "dubbo"}
{"id": 316, "code": "public static URL getURL(String resourceLocation) throws FileNotFoundException {\n    Assert.notNull(resourceLocation, \"Resource location must not be null\");\n    if (resourceLocation.startsWith(CommonConstants.CLASSPATH_URL_PREFIX)) {\n        String path = resourceLocation.substring(CommonConstants.CLASSPATH_URL_PREFIX.length());\n        ClassLoader cl = ClassUtils.getClassLoader();\n        URL url = (cl != null ? cl.getResource(path) : ClassLoader.getSystemResource(path));\n        if (url == null) {\n            String description = \"class path resource [\" + path + \"]\";\n            throw new FileNotFoundException(description +\n                \" cannot be resolved to URL because it does not exist\");\n        }\n        return url;\n    }\n    try {\n            \n        return new URL(resourceLocation);\n    } catch (MalformedURLException ex) {\n            \n        try {\n            return new File(resourceLocation).toURI().toURL();\n        } catch (MalformedURLException ex2) {\n            throw new FileNotFoundException(\"Resource location [\" + resourceLocation +\n                \"] is neither a URL not a well-formed file path\");\n        }\n    }\n}", "summary_tokens": ["use", "like", "spring", "code"], "project": "dubbo"}
{"id": 119, "code": "protected static String getGroup(URL url) {\n    String group = getParameter(url, GROUP_PARAM_NAME, null);\n    return StringUtils.isBlank(group) ? getParameter(url, GROUP_KEY, DEFAULT_GROUP) : group;\n}", "summary_tokens": ["get", "the", "group", "from", "url", "the", "specified", "connection", "url"], "project": "dubbo"}
{"id": 542, "code": "private boolean isRegisterConsumerInstance() {\n    Boolean registerConsumer = getApplication().getRegisterConsumer();\n    if (registerConsumer == null) {\n        return true;\n    }\n    return Boolean.TRUE.equals(registerConsumer);\n}", "summary_tokens": ["close", "registration", "of", "instance", "for", "pure", "consumer", "process", "by", "setting", "register", "consumer", "to", "false", "by", "default", "is", "true"], "project": "dubbo"}
{"id": 70, "code": "public String getServiceKey() {\n    if (serviceKey != null) {\n        return serviceKey;\n    }\n    String inf = getServiceInterface();\n    if (inf == null) {\n        return null;\n    }\n    serviceKey = buildKey(inf, getGroup(), getVersion());\n    return serviceKey;\n}", "summary_tokens": ["the", "format", "of", "return", "value", "is", "group", "interface", "name", "version"], "project": "dubbo"}
{"id": 690, "code": "protected Cache createCache(URL url) {\n    return new JCache(url);\n}", "summary_tokens": ["takes", "url", "as", "an", "method", "argument", "and", "return", "new", "instance", "of", "cache", "store", "implemented", "by", "jcache"], "project": "dubbo"}
{"id": 802, "code": "public void testDoSubscribe() {\n    ApplicationModel applicationModel = spy(ApplicationModel.defaultModel());\n    when(applicationModel.getDefaultExtension(ServiceNameMapping.class)).thenReturn(mapping);\n        \n    when(mapping.getAndListen(any(), any(), any())).thenReturn(Collections.emptySet());\n        \n    try {\n        registryURL = registryURL.setScopeModel(applicationModel);\n        serviceDiscoveryRegistry = new ServiceDiscoveryRegistry(registryURL, serviceDiscovery, mapping);\n        serviceDiscoveryRegistry.doSubscribe(url, testServiceListener);\n    } finally {\n        registryURL = registryURL.setScopeModel(null);\n        serviceDiscoveryRegistry.unsubscribe(url, testServiceListener);\n    }\n\n    URL checkURL = url.addParameter(CHECK_KEY, true);\n\n\n\n\n\n\n\n\n\n\n\n\n        \n    Set<String> singleApp = new HashSet<>();\n    singleApp.add(APP_NAME1);\n    when(mapping.getAndListen(any(), any(), any())).thenReturn(singleApp);\n    try {\n        serviceDiscoveryRegistry.doSubscribe(checkURL, testServiceListener);\n    } finally {\n        serviceDiscoveryRegistry.unsubscribe(checkURL, testServiceListener);\n    }\n}", "summary_tokens": ["test", "subscribe", "normal", "case", "exceptional", "case", "check", "true", "check", "false"], "project": "dubbo"}
{"id": 537, "code": "public DubboBootstrap application(ApplicationConfig applicationConfig) {\n    applicationConfig.setScopeModel(applicationModel);\n    configManager.setApplication(applicationConfig);\n    return this;\n}", "summary_tokens": ["set", "the", "application", "config"], "project": "dubbo"}
{"id": 438, "code": "private Set<String> getConfigIdsFromProps(Class<? extends AbstractConfig> clazz) {\n    String prefix = CommonConstants.DUBBO + \".\" + AbstractConfig.getPluralTagName(clazz) + \".\";\n    return ConfigurationUtils.getSubIds(environment.getConfigurationMaps(), prefix);\n}", "summary_tokens": ["search", "props", "and", "extract", "config", "ids", "of", "specify", "type"], "project": "dubbo"}
{"id": 1039, "code": "private static OS getOS() {\n    String osName = System.getProperty(\"os.name\").toLowerCase();\n    OS os = OS.Unix;\n    if (osName.contains(\"windows\")) {\n        os = OS.Windows;\n    }\n    return os;\n}", "summary_tokens": ["returns", "the", "operating", "system"], "project": "dubbo"}
{"id": 113, "code": "public List<Map<String, String>> getConfigurationMaps() {\n    if (globalConfigurationMaps == null) {\n        globalConfigurationMaps = getConfigurationMaps(null, null);\n    }\n    return globalConfigurationMaps;\n}", "summary_tokens": ["get", "global", "configuration", "as", "map", "list"], "project": "dubbo"}
{"id": 591, "code": "private void afterExport() {\n        \n    Assertions.assertTrue(DubboBootstrap.getInstance().isInitialized());\n        \n    Assertions.assertFalse(DubboBootstrap.getInstance().isPending());\n        \n    Assertions.assertTrue(DubboBootstrap.getInstance().isStarted());\n        \n    Assertions.assertFalse(DubboBootstrap.getInstance().isStopped());\n        \n    Assertions.assertTrue(this.serviceConfig.isExported());\n        \n    Assertions.assertEquals(this.serviceConfig.getExportedUrls().size(), 1);\n    URL exportedUrl = this.serviceConfig.getExportedUrls().get(0);\n        \n    Assertions.assertEquals(exportedUrl.getProtocol(), PROTOCOL_NAME);\n        \n    Assertions.assertEquals(exportedUrl.getPort(), PROTOCOL_PORT);\n        \n    Assertions.assertEquals(exportedUrl.getApplication(), PROVIDER_APPLICATION_NAME);\n\n        \n    ServiceDiscoveryRegistry serviceDiscoveryRegistry = this.getServiceDiscoveryRegistry();\n        \n    Assertions.assertNotNull(serviceDiscoveryRegistry);\n        \n    Assertions.assertTrue(serviceDiscoveryRegistry.getServiceDiscovery() instanceof ZookeeperServiceDiscovery);\n        \n    ZookeeperServiceDiscovery zookeeperServiceDiscovery = (ZookeeperServiceDiscovery) serviceDiscoveryRegistry.getServiceDiscovery();\n        \n    Set<String> services = zookeeperServiceDiscovery.getServices();\n        \n    Assertions.assertTrue(!services.isEmpty());\n        \n    Assertions.assertTrue(services.contains(PROVIDER_APPLICATION_NAME));\n\n        \n    MetadataServiceDelegation inMemoryWritableMetadataService = (MetadataServiceDelegation) serviceConfig.getScopeModel().getBeanFactory().getBean(MetadataService.class);\n        \n    Assertions.assertEquals(inMemoryWritableMetadataService.getExportedURLs().size(), 1);\n        \n    Assertions.assertFalse(inMemoryWritableMetadataService.getMetadataInfos().isEmpty());\n        \n    Assertions.assertFalse(inMemoryWritableMetadataService.getMetadataInfos().get(0).getServices().isEmpty());\n        \n    Assertions.assertEquals(inMemoryWritableMetadataService.getMetadataInfos().get(0).getServices().size(), 1);\n        \n    String key = SingleRegistryCenterIntegrationService.class.getName() + \":\" + PROTOCOL_NAME;\n    MetadataInfo.ServiceInfo serviceInfo = inMemoryWritableMetadataService.getMetadataInfos().get(0).getServices().get(key);\n        \n    Assertions.assertNotNull(serviceInfo);\n        \n    Assertions.assertEquals(serviceInfo.getName(), SingleRegistryCenterIntegrationService.class.getName());\n        \n    Assertions.assertNull(serviceInfo.getGroup());\n        \n    Assertions.assertNull(serviceInfo.getVersion());\n        \n    Assertions.assertEquals(serviceInfo.getProtocol(), PROTOCOL_NAME);\n        \n    Assertions.assertEquals(serviceInfo.getServiceKey(), SingleRegistryCenterIntegrationService.class.getName());\n        \n    Assertions.assertEquals(serviceInfo.getMatchKey(), key);\n        \n        \n        \n        \n    singleRegistryCenterExportedServiceListener = (SingleRegistryCenterExportedServiceListener) ExtensionLoader.getExtensionLoader(ServiceListener.class).getExtension(\"exported\");\n    Assertions.assertNotNull(singleRegistryCenterExportedServiceListener);\n    Assertions.assertEquals(singleRegistryCenterExportedServiceListener.getExportedServices().size(), 1);\n    Assertions.assertEquals(SingleRegistryCenterIntegrationService.class,\n        singleRegistryCenterExportedServiceListener.getExportedServices().get(0).getInterfaceClass());\n    ServiceConfig singleRegistryCenterServiceConfig = singleRegistryCenterExportedServiceListener.getExportedServices().get(0);\n    Assertions.assertNotNull(singleRegistryCenterServiceConfig);\n    Assertions.assertTrue(singleRegistryCenterServiceConfig.isExported());\n}", "summary_tokens": ["there", "are", "some", "checkpoints", "needed", "to", "check", "as", "follow", "ul", "li", "dubbo", "bootstrap", "is", "initialized", "or", "not", "li", "li", "dubbo", "bootstrap", "is", "started", "or", "not", "li", "li", "dubbo", "bootstrap", "is", "shutdown", "or", "not", "li", "li", "service", "has", "been", "exported", "or", "not", "li", "li", "there", "is", "exported", "urls", "or", "not", "li", "li", "protocol", "name", "is", "right", "or", "not", "li", "li", "protocol", "port", "is", "right", "or", "not", "li", "li", "service", "discovery", "registry", "s", "protocol", "is", "right", "or", "not", "li", "li", "registered", "service", "in", "registry", "center", "is", "right", "or", "not", "li", "li", "metadata", "info", "has", "reported", "or", "not", "li", "li", "metadata", "info", "has", "reported", "or", "not", "has", "service", "or", "not", "li", "li", "metadata", "info", "s", "application", "name", "is", "right", "or", "not", "li", "li", "metadata", "info", "s", "service", "exists", "or", "not", "li", "li", "the", "name", "of", "metadata", "info", "s", "service", "is", "right", "or", "not", "li", "li", "the", "group", "of", "metadata", "info", "s", "service", "is", "right", "or", "not", "li", "li", "the", "version", "of", "metadata", "info", "s", "service", "is", "right", "or", "not", "li", "li", "the", "protocol", "of", "metadata", "info", "s", "service", "is", "right", "or", "not", "li", "li", "the", "service", "key", "of", "metadata", "info", "s", "service", "is", "right", "or", "not", "li", "li", "the", "match", "key", "of", "metadata", "info", "s", "service", "is", "right", "or", "not", "li", "li", "the", "exported", "service", "are", "right", "or", "not", "li", "ul"], "project": "dubbo"}
{"id": 71, "code": "public String getPathKey() {\n    String inf = StringUtils.isNotEmpty(getPath()) ? getPath() : getServiceInterface();\n    if (inf == null) {\n        return null;\n    }\n    return buildKey(inf, getGroup(), getVersion());\n}", "summary_tokens": ["the", "format", "of", "return", "value", "is", "group", "path", "interface", "name", "version"], "project": "dubbo"}
{"id": 205, "code": "private void fullyLock() {\n    acquireLock.lock();\n    releaseLock.lock();\n}", "summary_tokens": ["locks", "to", "prevent", "both", "acquires", "and", "releases"], "project": "dubbo"}
{"id": 547, "code": "public void prepare() {\n    applicationDeployer.initialize();\n    this.initialize();\n}", "summary_tokens": ["prepare", "for", "export", "refer", "service", "trigger", "initializing", "application", "and", "module"], "project": "dubbo"}
{"id": 488, "code": "public Set<MethodDescriptor> getAllMethods() {\n    return serviceModel.getAllMethods();\n}", "summary_tokens": ["return", "all", "method", "models", "for", "the", "current", "service"], "project": "dubbo"}
{"id": 268, "code": "public static boolean isNotEmpty(final Object[] array) {\n    return !isEmpty(array);\n}", "summary_tokens": ["p", "checks", "if", "the", "array", "is", "not", "null", "or", "empty"], "project": "dubbo"}
{"id": 281, "code": "public static Set<Class<?>> getAllInterfaces(Class<?> type, Predicate<Class<?>>... interfaceFilters) {\n    if (type == null || type.isPrimitive()) {\n        return emptySet();\n    }\n\n    Set<Class<?>> allInterfaces = new LinkedHashSet<>();\n    Set<Class<?>> resolved = new LinkedHashSet<>();\n    Queue<Class<?>> waitResolve = new LinkedList<>();\n\n    resolved.add(type);\n    Class<?> clazz = type;\n    while (clazz != null) {\n\n        Class<?>[] interfaces = clazz.getInterfaces();\n\n        if (isNotEmpty(interfaces)) {\n                \n            Arrays.stream(interfaces)\n                    .filter(resolved::add)\n                    .forEach(cls -> {\n                        allInterfaces.add(cls);\n                        waitResolve.add(cls);\n                    });\n        }\n\n            \n        getAllSuperClasses(clazz)\n                .stream()\n                .filter(resolved::add)\n                .forEach(waitResolve::add);\n\n        clazz = waitResolve.poll();\n    }\n\n    return filterAll(allInterfaces, interfaceFilters);\n}", "summary_tokens": ["get", "all", "interfaces", "from", "the", "specified", "type"], "project": "dubbo"}
{"id": 383, "code": "public static boolean isNumber(String str) {\n    return isNotEmpty(str) && NUM_PATTERN.matcher(str).matches();\n}", "summary_tokens": ["is", "positive", "integer", "or", "zero", "string"], "project": "dubbo"}
{"id": 1061, "code": "public ExecutorService getExecutorService() {\n    return DEFAULT_EXECUTOR_SERVICE;\n}", "summary_tokens": ["returns", "the", "default", "executor", "service", "to", "manage", "the", "lifecycle", "of", "zookeeper"], "project": "dubbo"}
{"id": 694, "code": "public void put(Object key, Object value) {\n    store.put(key, value);\n}", "summary_tokens": ["api", "to", "store", "value", "against", "a", "key", "in", "the", "calling", "thread", "scope"], "project": "dubbo"}
{"id": 209, "code": "public boolean hasRemainedMemory() {\n    return MemoryLimitCalculator.maxAvailable() > maxFreeMemory;\n}", "summary_tokens": ["determine", "if", "there", "is", "any", "remaining", "free", "memory"], "project": "dubbo"}
{"id": 839, "code": "void testAnyHost() {\n    Assertions.assertThrows(IllegalStateException.class, () -> {\n        URL errorUrl = URL.valueOf(\"multicast://0.0.0.0/\");\n        new MulticastRegistry(errorUrl);\n    });\n}", "summary_tokens": ["test", "method", "for", "org"], "project": "dubbo"}
{"id": 1, "code": "static Optional<List<Configurator>> toConfigurators(List<URL> urls) {\n    if (CollectionUtils.isEmpty(urls)) {\n        return Optional.empty();\n    }\n\n    ConfiguratorFactory configuratorFactory = urls.get(0).getOrDefaultApplicationModel().getExtensionLoader(ConfiguratorFactory.class)\n            .getAdaptiveExtension();\n\n    List<Configurator> configurators = new ArrayList<>(urls.size());\n    for (URL url : urls) {\n        if (EMPTY_PROTOCOL.equals(url.getProtocol())) {\n            configurators.clear();\n            break;\n        }\n        Map<String, String> override = new HashMap<>(url.getParameters());\n            \n        override.remove(ANYHOST_KEY);\n        if (CollectionUtils.isEmptyMap(override)) {\n            continue;\n        }\n        configurators.add(configuratorFactory.getConfigurator(url));\n    }\n    Collections.sort(configurators);\n    return Optional.of(configurators);\n}", "summary_tokens": ["convert", "override", "urls", "to", "map", "for", "use", "when", "re", "refer"], "project": "dubbo"}
{"id": 538, "code": "public DubboBootstrap registry(RegistryConfig registryConfig) {\n    registryConfig.setScopeModel(applicationModel);\n    configManager.addRegistry(registryConfig);\n    return this;\n}", "summary_tokens": ["add", "an", "instance", "of", "registry", "config"], "project": "dubbo"}
{"id": 1010, "code": "public static <T, R> StreamObserver<T> manyToOne(StreamObserver<R> responseObserver,\n                                                  Function<Flux<T>, Mono<R>> func) {\n    ServerTripleReactorPublisher<T> serverPublisher = new ServerTripleReactorPublisher<T>((CallStreamObserver<R>) responseObserver);\n    try {\n        Mono<R> responseMono = func.apply(Flux.from(serverPublisher));\n        responseMono.subscribe(value -> {\n                    \n                if (!serverPublisher.isCancelled()) {\n                    responseObserver.onNext(value);\n                }\n            },\n            throwable -> {\n                    \n                if (!serverPublisher.isCancelled()) {\n                    responseObserver.onError(throwable);\n                }\n            },\n            responseObserver::onCompleted\n        );\n        serverPublisher.startRequest();\n    } catch (Throwable throwable) {\n        responseObserver.onError(throwable);\n    }\n    return serverPublisher;\n}", "summary_tokens": ["implements", "a", "stream", "unary", "call", "as", "flux", "mono"], "project": "dubbo"}
{"id": 220, "code": "public ScheduledExecutorService getConnectivityScheduledExecutor() {\n    return connectivityScheduledExecutor;\n}", "summary_tokens": ["scheduled", "executor", "handle", "connectivity", "check", "task"], "project": "dubbo"}
{"id": 208, "code": "public int getMaxFreeMemory() {\n    return maxFreeMemory;\n}", "summary_tokens": ["get", "the", "max", "free", "memory"], "project": "dubbo"}
{"id": 558, "code": "public void testCreateInvokerForRemoteRefer() {\n\n    ReferenceConfig<DemoService> referenceConfig = new ReferenceConfig<>();\n    referenceConfig.setGeneric(Boolean.FALSE.toString());\n    referenceConfig.setProtocol(\"dubbo\");\n    referenceConfig.setInit(true);\n    referenceConfig.setLazy(false);\n    referenceConfig.setInjvm(false);\n\n    DubboBootstrap dubboBootstrap = DubboBootstrap.newInstance(FrameworkModel.defaultModel());\n\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"application1\");\n    Map<String, String> parameters = new HashMap<>();\n    parameters.put(\"key1\", \"value1\");\n    parameters.put(\"key2\", \"value2\");\n    applicationConfig.setParameters(parameters);\n\n    referenceConfig.refreshed.set(true);\n    referenceConfig.setInterface(DemoService.class);\n    referenceConfig.getInterfaceClass();\n    referenceConfig.setCheck(false);\n    RegistryConfig registry = new RegistryConfig();\n    registry.setAddress(zkUrl1);\n    applicationConfig.setRegistries(Collections.singletonList(registry));\n    applicationConfig.setRegistryIds(registry.getId());\n\n    referenceConfig.setRegistry(registry);\n\n    dubboBootstrap\n        .application(applicationConfig)\n        .reference(referenceConfig)\n        .initialize();\n\n    referenceConfig.init();\n    Assertions.assertTrue(referenceConfig.getInvoker() instanceof MigrationInvoker);\n\n    dubboBootstrap.destroy();\n}", "summary_tokens": ["verify", "the", "configuration", "of", "the", "registry", "protocol", "for", "remote", "reference"], "project": "dubbo"}
{"id": 249, "code": "static boolean isSameType(Annotation annotation, Class<? extends Annotation> annotationType) {\n    if (annotation == null || annotationType == null) {\n        return false;\n    }\n    return Objects.equals(annotation.annotationType(), annotationType);\n}", "summary_tokens": ["is", "the", "type", "of", "specified", "annotation", "same", "to", "the", "expected", "type"], "project": "dubbo"}
{"id": 1041, "code": "private Processor get(OS os, Command command) {\n    Map<Command, Processor> commandProcessorMap = this.processors.get(os);\n    Objects.requireNonNull(commandProcessorMap, \"The command with the OS cannot be null\");\n    Processor processor = commandProcessorMap.get(command);\n    Objects.requireNonNull(processor, \"The processor cannot be null\");\n    return processor;\n}", "summary_tokens": ["gets", "the", "processor", "with", "the", "given", "os", "type", "and", "command"], "project": "dubbo"}
{"id": 340, "code": "public static boolean isPortInUsed(int port) {\n    try (ServerSocket ignored = new ServerSocket(port)) {\n        return false;\n    } catch (IOException e) {\n            \n    }\n    return true;\n}", "summary_tokens": ["check", "the", "port", "whether", "is", "in", "use", "in", "os", "port", "port", "to", "check", "true", "if", "it", "s", "occupied"], "project": "dubbo"}
{"id": 775, "code": "private boolean accept(ServiceInstancesChangedEvent event) {\n    return serviceNames.contains(event.getServiceName());\n}", "summary_tokens": ["event", "service", "instances", "changed", "event", "event", "if", "service", "name", "matches", "return", "code", "true", "code", "or", "code", "false", "code"], "project": "dubbo"}
{"id": 952, "code": "public void setTypes(Class[] types) {\n    set(TYPES, types != null ? Arrays.copyOf(types, types.length) : null);\n}", "summary_tokens": ["set", "invocation", "s", "method", "s", "input", "parameter", "s", "types"], "project": "dubbo"}
{"id": 395, "code": "public static String encodeParameters(Map<String, String> params) {\n    if (params == null || params.isEmpty()) {\n        return null;\n    }\n\n    StringBuilder sb = new StringBuilder();\n    sb.append('[');\n    params.forEach((key, value) -> {\n            \n        if (hasText(value)) {\n            sb.append('{').append(key).append(':').append(value).append(\"},\");\n        }\n    });\n        \n    if (sb.charAt(sb.length() - 1) == ',') {\n        sb.deleteCharAt(sb.length() - 1);\n    }\n    sb.append(']');\n    return sb.toString();\n}", "summary_tokens": ["encode", "parameters", "map", "to", "string", "like", "a", "b", "c", "d"], "project": "dubbo"}
{"id": 894, "code": "static FormattingTuple format(final String messagePattern,\n                              Object argA, Object argB) {\n    return arrayFormat(messagePattern, new Object[]{argA, argB});\n}", "summary_tokens": ["performs", "a", "two", "argument", "substitution", "for", "the", "message", "pattern", "passed", "as", "parameter"], "project": "dubbo"}
{"id": 434, "code": "public final <T extends AbstractConfig> T addConfig(AbstractConfig config) {\n    if (config == null) {\n        return null;\n    }\n        \n    if (!isSupportConfigType(config.getClass())) {\n        throw new IllegalArgumentException(\"Unsupported config type: \" + config);\n    }\n\n    if (config.getScopeModel() != scopeModel) {\n        config.setScopeModel(scopeModel);\n    }\n\n    Map<String, AbstractConfig> configsMap = configsCache.computeIfAbsent(getTagName(config.getClass()), type -> new ConcurrentHashMap<>());\n\n        \n    if (!(config instanceof ReferenceConfigBase || config instanceof ServiceConfigBase)) {\n        for (AbstractConfig value : configsMap.values()) {\n            if (value.equals(config)) {\n                return (T) value;\n            }\n        }\n    }\n\n        \n    synchronized (configsMap) {\n        return (T) addIfAbsent(config, configsMap);\n    }\n}", "summary_tokens": ["add", "the", "dubbo", "abstract", "config", "config"], "project": "dubbo"}
{"id": 233, "code": "public String getMethodParameterStrict(String method, String key) {\n    String methodsString = getParameter(METHODS_KEY);\n    if (StringUtils.isNotEmpty(methodsString)) {\n        if (!methodsString.contains(method)) {\n            return null;\n        }\n    }\n\n    Map<String, String> methodMap = METHOD_PARAMETERS.get(key);\n    if (CollectionUtils.isNotEmptyMap(methodMap)) {\n        return methodMap.get(method);\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["get", "method", "related", "parameter"], "project": "dubbo"}
{"id": 1052, "code": "public Path getSourceFile() {\n    return this.sourceFile;\n}", "summary_tokens": ["returns", "the", "source", "file", "path", "of", "downloaded", "zookeeper", "binary", "archive"], "project": "dubbo"}
{"id": 221, "code": "public ScheduledExecutorService getCacheRefreshingScheduledExecutor() {\n    return cacheRefreshingScheduledExecutor;\n}", "summary_tokens": ["scheduler", "used", "to", "refresh", "file", "based", "caches", "from", "memory", "to", "disk"], "project": "dubbo"}
{"id": 97, "code": "public static Configuration getSystemConfiguration() {\n    return ApplicationModel.defaultModel().getModelEnvironment().getSystemConfiguration();\n}", "summary_tokens": ["for", "compact", "single", "instance", "replaced", "to", "configuration", "utils", "get", "system", "configuration", "scope", "model"], "project": "dubbo"}
{"id": 406, "code": "public static URL valueOf(String url) {\n    if (url == null || (url = url.trim()).length() == 0) {\n        throw new IllegalArgumentException(\"url == null\");\n    }\n    String protocol = null;\n    String username = null;\n    String password = null;\n    String host = null;\n    int port = 0;\n    String path = null;\n    Map<String, String> parameters = null;\n    int i = url.indexOf('?'); \n    if (i >= 0) {\n        String[] parts = url.substring(i + 1).split(\"&\");\n        parameters = new HashMap<>();\n        for (String part : parts) {\n            part = part.trim();\n            if (part.length() > 0) {\n                int j = part.indexOf('=');\n                if (j >= 0) {\n                    String key = part.substring(0, j);\n                    String value = part.substring(j + 1);\n                    parameters.put(key, value);\n                        \n                    if (key.startsWith(DEFAULT_KEY_PREFIX)) {\n                        parameters.putIfAbsent(key.substring(DEFAULT_KEY_PREFIX.length()), value);\n                    }\n                } else {\n                    parameters.put(part, part);\n                }\n            }\n        }\n        url = url.substring(0, i);\n    }\n    i = url.indexOf(\"://\");\n    if (i >= 0) {\n        if (i == 0) {\n            throw new IllegalStateException(\"url missing protocol: \\\"\" + url + \"\\\"\");\n        }\n        protocol = url.substring(0, i);\n        url = url.substring(i + 3);\n    } else {\n            \n        i = url.indexOf(\":/\");\n        if (i >= 0) {\n            if (i == 0) {\n                throw new IllegalStateException(\"url missing protocol: \\\"\" + url + \"\\\"\");\n            }\n            protocol = url.substring(0, i);\n            url = url.substring(i + 1);\n        }\n    }\n\n    i = url.indexOf('/');\n    if (i >= 0) {\n        path = url.substring(i + 1);\n        url = url.substring(0, i);\n    }\n    i = url.lastIndexOf('@');\n    if (i >= 0) {\n        username = url.substring(0, i);\n        int j = username.indexOf(':');\n        if (j >= 0) {\n            password = username.substring(j + 1);\n            username = username.substring(0, j);\n        }\n        url = url.substring(i + 1);\n    }\n    i = url.lastIndexOf(':');\n    if (i >= 0 && i < url.length() - 1) {\n        if (url.lastIndexOf('%') > i) {\n                \n                \n                \n                \n        } else {\n            port = Integer.parseInt(url.substring(i + 1));\n            url = url.substring(0, i);\n        }\n    }\n    if (url.length() > 0) {\n        host = url;\n    }\n\n    return new ServiceConfigURL(protocol, username, password, host, port, path, parameters);\n}", "summary_tokens": ["notice", "this", "method", "allocate", "too", "much", "objects", "we", "can", "use", "urlstr", "parser", "parse", "decoded", "str", "string", "instead"], "project": "dubbo"}
{"id": 83, "code": "public Object newInstance(InvocationHandler handler) {\n    Constructor<?> constructor;\n    try {\n        constructor = classToCreate.getDeclaredConstructor(InvocationHandler.class);\n        return constructor.newInstance(handler);\n    } catch (ReflectiveOperationException e) {\n        throw new RuntimeException(e);\n    }\n}", "summary_tokens": ["get", "instance", "with", "special", "handler"], "project": "dubbo"}
{"id": 160, "code": "private String generateGetUrlNullCheck(int index, Class<?> type, String method) {\n        \n    StringBuilder code = new StringBuilder();\n    code.append(String.format(\"if (arg%d == null) throw new IllegalArgumentException(\\\"%s argument == null\\\");\\n\",\n            index, type.getName()));\n    code.append(String.format(\"if (arg%d.%s() == null) throw new IllegalArgumentException(\\\"%s argument %s() == null\\\");\\n\",\n            index, method, type.getName(), method));\n\n    code.append(String.format(\"%s url = arg%d.%s();\\n\", URL.class.getName(), index, method));\n    return code.toString();\n}", "summary_tokens": ["0", "test", "if", "argi", "is", "null", "0", "test", "if", "argi"], "project": "dubbo"}
{"id": 123, "code": "default String getConfig(String key, String group) {\n    return getConfig(key, group, getDefaultTimeout());\n}", "summary_tokens": ["get", "the", "configuration", "mapped", "to", "the", "given", "key", "and", "the", "given", "group", "with", "get", "default", "timeout", "the", "default", "timeout"], "project": "dubbo"}
{"id": 500, "code": "public void testMergeValuesDelete() {\n    List<String> merged = ConfigUtils.mergeValues(ApplicationModel.defaultModel().getExtensionDirector(), ThreadPool.class, \"-fixed,aaa\", asList(\"fixed\", \"default.limited\", \"cached\"));\n    assertEquals(asList(\"cached\", \"aaa\"), merged);\n}", "summary_tokens": ["the", "user", "configures", "default", "which", "will", "delete", "all", "the", "default", "parameters"], "project": "dubbo"}
{"id": 945, "code": "public static AccessLogData newLogData() {\n    return new AccessLogData();\n}", "summary_tokens": ["get", "new", "instance", "of", "log", "data"], "project": "dubbo"}
{"id": 305, "code": "public void clear() {\n    map.clear();\n}", "summary_tokens": ["removes", "all", "of", "the", "elements", "from", "this", "set"], "project": "dubbo"}
{"id": 55, "code": "public void testMockInvokerFromOverride_Invoke_Fock_WithDefault() {\n    URL url = URL.valueOf(\"remote://1.2.3.4/\" + IHelloService.class.getName())\n            .addParameter(REFER_KEY,\n                    URL.encode(PATH_KEY + \"=\" + IHelloService.class.getName()\n                            + \"&\" + \"mock\" + \"=\" + \"fail:return null\"\n                            + \"&\" + \"getSomething.mock\" + \"=\" + \"fail:return x\"\n                            + \"&\" + \"getSomething2.mock\" + \"=\" + \"fail:return y\"))\n            .addParameter(\"invoke_return_error\", \"true\");\n    Invoker<IHelloService> cluster = getClusterInvoker(url);\n        \n    RpcInvocation invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething\");\n    Result ret = cluster.invoke(invocation);\n    Assertions.assertEquals(\"x\", ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething2\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertEquals(\"y\", ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething3\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertNull(ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"sayHello\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertNull(ret.getValue());\n}", "summary_tokens": ["test", "if", "mock", "policy", "works", "fine", "fail", "mock"], "project": "dubbo"}
{"id": 1050, "code": "public static String getConnectionAddressKey2() {\n    return CONFIG.getConnectionAddressKey2();\n}", "summary_tokens": ["returns", "the", "second", "connection", "address", "key", "in", "multiple", "registry", "center"], "project": "dubbo"}
{"id": 366, "code": "public static <T> T getProperty(Object bean, String methodName) {\n    Class<?> beanClass = bean.getClass();\n    BeanInfo beanInfo = null;\n    T propertyValue = null;\n\n    try {\n        beanInfo = Introspector.getBeanInfo(beanClass);\n        propertyValue = (T) Stream.of(beanInfo.getMethodDescriptors())\n                .filter(methodDescriptor -> methodName.equals(methodDescriptor.getName()))\n                .findFirst()\n                .map(method -> {\n                    try {\n                        return method.getMethod().invoke(bean);\n                    } catch (Exception e) {\n                            \n                    }\n                    return null;\n                }).get();\n    } catch (Exception e) {\n\n    }\n    return propertyValue;\n}", "summary_tokens": ["get", "the", "value", "from", "the", "specified", "bean", "and", "its", "getter", "method"], "project": "dubbo"}
{"id": 344, "code": "static InetAddress normalizeV6Address(Inet6Address address) {\n    String addr = address.getHostAddress();\n    int i = addr.lastIndexOf('%');\n    if (i > 0) {\n        try {\n            return InetAddress.getByName(addr.substring(0, i) + '%' + address.getScopeId());\n        } catch (UnknownHostException e) {\n                \n            logger.debug(\"Unknown IPV6 address: \", e);\n        }\n    }\n    return address;\n}", "summary_tokens": ["normalize", "the", "ipv", "0", "address", "convert", "scope", "name", "to", "scope", "id"], "project": "dubbo"}
{"id": 345, "code": "public static InetAddress getLocalAddress() {\n    if (LOCAL_ADDRESS != null) {\n        return LOCAL_ADDRESS;\n    }\n    InetAddress localAddress = getLocalAddress0();\n    LOCAL_ADDRESS = localAddress;\n    return localAddress;\n}", "summary_tokens": ["find", "first", "valid", "ip", "from", "local", "network", "card"], "project": "dubbo"}
{"id": 996, "code": "protected String getContextPath(URL url) {\n    String contextPath = url.getPath();\n    if (contextPath != null) {\n        if (contextPath.equalsIgnoreCase(url.getParameter(INTERFACE_KEY))) {\n            return \"\";\n        }\n        if (contextPath.endsWith(url.getParameter(INTERFACE_KEY))) {\n            contextPath = contextPath.substring(0, contextPath.lastIndexOf(url.getParameter(INTERFACE_KEY)));\n        }\n        return contextPath.endsWith(\"/\") ? contextPath.substring(0, contextPath.length() - 1) : contextPath;\n    } else {\n        return \"\";\n    }\n}", "summary_tokens": ["get", "path", "will", "return", "contextpath", "path", "0"], "project": "dubbo"}
{"id": 474, "code": "public List<ApplicationModel> getAllApplicationModels() {\n    return Collections.unmodifiableList(applicationModels);\n}", "summary_tokens": ["get", "all", "application", "models", "including", "the", "internal", "application", "model"], "project": "dubbo"}
{"id": 18, "code": "static int calculateWarmupWeight(int uptime, int warmup, int weight) {\n    int ww = (int) ( uptime / ((float) warmup / weight));\n    return ww < 1 ? 1 : (Math.min(ww, weight));\n}", "summary_tokens": ["calculate", "the", "weight", "according", "to", "the", "uptime", "proportion", "of", "warmup", "time", "the", "new", "weight", "will", "be", "within", "0", "inclusive", "to", "weight", "inclusive"], "project": "dubbo"}
{"id": 72, "code": "public static URL parseDecodedStr(String decodedURLStr) {\n    Map<String, String> parameters = null;\n    int pathEndIdx = decodedURLStr.indexOf('?');\n    if (pathEndIdx >= 0) {\n        parameters = parseDecodedParams(decodedURLStr, pathEndIdx + 1);\n    } else {\n        pathEndIdx = decodedURLStr.length();\n    }\n\n    String decodedBody = decodedURLStr.substring(0, pathEndIdx);\n    return parseURLBody(decodedURLStr, decodedBody, parameters);\n}", "summary_tokens": ["decoded", "urlstr", "after", "url", "decode", "string", "decoded", "urlstr", "format", "protocol", "username", "password", "port", "path", "k", "0", "v", "0", "k", "0", "v", "0", "protocol", "username", "password", "host", "port", "path", "k", "0", "v", "0", "k", "0", "v", "0"], "project": "dubbo"}
{"id": 711, "code": "public ServiceInfo getNoProtocolServiceInfo(String serviceKeyWithoutProtocol) {\n    if (CollectionUtils.isEmptyMap(subscribedServices)) {\n        return null;\n    }\n    Set<ServiceInfo> subServices = subscribedServices.get(serviceKeyWithoutProtocol);\n    if (CollectionUtils.isNotEmpty(subServices)) {\n       return subServices.iterator().next();\n    }\n    return null;\n}", "summary_tokens": ["get", "service", "infos", "of", "an", "interface", "with", "specified", "group", "version"], "project": "dubbo"}
{"id": 750, "code": "private int indexLastCol(final int[] widthCacheArray) {\n    for (int colIndex = widthCacheArray.length - 1; colIndex >= 0; colIndex--) {\n        final int width = widthCacheArray[colIndex];\n        if (width <= 0) {\n            continue;\n        }\n        return colIndex;\n    }\n    return 0;\n}", "summary_tokens": ["position", "to", "last", "column"], "project": "dubbo"}
{"id": 1015, "code": "public static void convertAttachment(DefaultHttp2Headers headers,\n    Map<String, Object> attachments) {\n    if (attachments == null) {\n        return;\n    }\n    for (Map.Entry<String, Object> entry : attachments.entrySet()) {\n        final String key = entry.getKey().toLowerCase(Locale.ROOT);\n        if (Http2Headers.PseudoHeaderName.isPseudoHeader(key)) {\n            continue;\n        }\n        if (TripleHeaderEnum.containsExcludeAttachments(key)) {\n            continue;\n        }\n        final Object v = entry.getValue();\n        convertSingleAttachment(headers, key, v);\n    }\n}", "summary_tokens": ["parse", "and", "put", "the", "kv", "pairs", "into", "metadata"], "project": "dubbo"}
{"id": 390, "code": "private static Map<String, String> parseKeyValuePair(String str, String itemSeparator) {\n    String[] tmp = str.split(itemSeparator);\n    Map<String, String> map = new HashMap<String, String>(tmp.length);\n    for (int i = 0; i < tmp.length; i++) {\n        Matcher matcher = KVP_PATTERN.matcher(tmp[i]);\n        if (!matcher.matches()) {\n            continue;\n        }\n        map.put(matcher.group(1), matcher.group(2));\n    }\n    return map;\n}", "summary_tokens": ["parse", "key", "value", "pair"], "project": "dubbo"}
{"id": 820, "code": "public void testConsumerUrlWithProtocol() {\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"application1\");\n\n    ConfigManager configManager = mock(ConfigManager.class);\n    when(configManager.getApplicationOrElseThrow()).thenReturn(applicationConfig);\n\n    CompositeConfiguration compositeConfiguration = mock(CompositeConfiguration.class);\n    when(compositeConfiguration.convert(Boolean.class, ENABLE_CONFIGURATION_LISTEN, true))\n        .thenReturn(true);\n\n    Map<String, String> parameters = new HashMap<>();\n    parameters.put(INTERFACE_KEY, DemoService.class.getName());\n    parameters.put(\"registry\", \"zookeeper\");\n    parameters.put(\"register\", \"false\");\n    parameters.put(REGISTER_IP_KEY, \"172.23.236.180\");\n    parameters.put(PROTOCOL_KEY, \"tri\");\n    Map<String, Object> attributes = new HashMap<>();\n    ServiceConfigURL serviceConfigURL = new ServiceConfigURL(\"registry\",\n        \"127.0.0.1\",\n        2181,\n        \"org.apache.dubbo.registry.RegistryService\",\n        parameters);\n    Map<String, String> refer = new HashMap<>();\n    attributes.put(REFER_KEY, refer);\n    attributes.put(\"key1\", \"value1\");\n    URL url = serviceConfigURL.addAttributes(attributes);\n\n    RegistryFactory registryFactory = mock(RegistryFactory.class);\n\n    RegistryProtocol registryProtocol = new RegistryProtocol();\n    Registry registry = mock(Registry.class);\n\n    MigrationRuleListener migrationRuleListener = mock(MigrationRuleListener.class);\n    List<RegistryProtocolListener> registryProtocolListeners = new ArrayList<>();\n    registryProtocolListeners.add(migrationRuleListener);\n\n    ModuleModel moduleModel = Mockito.spy(ApplicationModel.defaultModel().getDefaultModule());\n    moduleModel.getApplicationModel().getApplicationConfigManager().setApplication(new ApplicationConfig(\"application1\"));\n    ExtensionLoader<RegistryProtocolListener> extensionLoaderMock = mock(ExtensionLoader.class);\n    Mockito.when(moduleModel.getExtensionLoader(RegistryProtocolListener.class)).thenReturn(extensionLoaderMock);\n    Mockito.when(extensionLoaderMock.getActivateExtension(url, REGISTRY_PROTOCOL_LISTENER_KEY))\n        .thenReturn(registryProtocolListeners);\n    url = url.setScopeModel(moduleModel);\n\n    when(registryFactory.getRegistry(registryProtocol.getRegistryUrl(url))).thenReturn(registry);\n\n    Cluster cluster = mock(Cluster.class);\n\n    Invoker<?> invoker = registryProtocol.doRefer(cluster, registry, DemoService.class, url, parameters);\n\n    Assertions.assertTrue(invoker instanceof MigrationInvoker);\n\n    URL consumerUrl = ((MigrationInvoker<?>) invoker).getConsumerUrl();\n    Assertions.assertTrue((consumerUrl != null));\n\n        \n    Assertions.assertEquals(\"tri\", consumerUrl.getProtocol());\n    Assertions.assertEquals(parameters.get(REGISTER_IP_KEY), consumerUrl.getHost());\n    Assertions.assertFalse(consumerUrl.getAttributes().containsKey(REFER_KEY));\n    Assertions.assertEquals(\"value1\", consumerUrl.getAttribute(\"key1\"));\n\n}", "summary_tokens": ["verify", "that", "when", "the", "protocol", "is", "configured", "the", "protocol", "of", "consumer", "url", "is", "the", "configured", "protocol"], "project": "dubbo"}
{"id": 230, "code": "public boolean equals(Object obj) {\n    if (this == obj) {\n        return true;\n    }\n    if (obj == null) {\n        return false;\n    }\n    if (!(obj instanceof ServiceAddressURL)) {\n        return false;\n    }\n    return super.equals(obj);\n}", "summary_tokens": ["ignore", "consumer", "url", "compare"], "project": "dubbo"}
{"id": 309, "code": "private static boolean checkFileNameExist(String fileName) {\n    File file = new File(fileName);\n    return file.exists();\n}", "summary_tokens": ["check", "if", "the", "file", "name", "can", "be", "found", "in", "filesystem"], "project": "dubbo"}
{"id": 319, "code": "public String getMd5(String input) {\n    byte[] md5;\n        \n    synchronized (mdInst) {\n        mdInst.update(input.getBytes(UTF_8));\n        md5 = mdInst.digest();\n    }\n\n    int j = md5.length;\n    char str[] = new char[j * 2];\n    int k = 0;\n    for (int i = 0; i < j; i++) {\n        byte byte0 = md5[i];\n        str[k++] = hexDigits[byte0 >>> 4 & 0xf];\n        str[k++] = hexDigits[byte0 & 0xf];\n    }\n    return new String(str);\n}", "summary_tokens": ["calculation", "md", "0", "value", "of", "specify", "string", "input"], "project": "dubbo"}
{"id": 754, "code": "public TTree end() {\n    if (current.isRoot()) {\n        throw new IllegalStateException(\"current node is root.\");\n    }\n    current.markEnd();\n    current = current.parent;\n    return this;\n}", "summary_tokens": ["end", "a", "branch", "node"], "project": "dubbo"}
{"id": 573, "code": "public boolean hasCalled() {\n    return called;\n}", "summary_tokens": ["returns", "if", "the", "filter", "has", "called"], "project": "dubbo"}
{"id": 442, "code": "public Optional<ProviderConfig> getDefaultProvider() {\n    List<ProviderConfig> providerConfigs = getDefaultConfigs(getConfigsMap(getTagName(ProviderConfig.class)));\n    if (CollectionUtils.isNotEmpty(providerConfigs)) {\n        return Optional.of(providerConfigs.get(0));\n    }\n    return Optional.empty();\n}", "summary_tokens": ["only", "allows", "one", "default", "provider", "config"], "project": "dubbo"}
{"id": 829, "code": "public void testSubscribeAndUnsubscribe() {\n        \n    final AtomicReference<Boolean> notified = new AtomicReference<Boolean>(false);\n    NotifyListener listener = urls -> notified.set(Boolean.TRUE);\n    URL url = new ServiceConfigURL(\"dubbo\", \"192.168.0.1\", 2200);\n    abstractRegistry.subscribe(url, listener);\n    Set<NotifyListener> subscribeListeners = abstractRegistry.getSubscribed().get(url);\n    MatcherAssert.assertThat(true, Matchers.equalTo(subscribeListeners.contains(listener)));\n        \n    abstractRegistry.unsubscribe(url, listener);\n    Set<NotifyListener> unsubscribeListeners = abstractRegistry.getSubscribed().get(url);\n    MatcherAssert.assertThat(false, Matchers.equalTo(unsubscribeListeners.contains(listener)));\n}", "summary_tokens": ["test", "subscribe", "and", "unsubscribe"], "project": "dubbo"}
{"id": 911, "code": "public <T> T getResponse(Class<T> clazz) {\n    return SERVICE_CONTEXT.get().getResponse(clazz);\n}", "summary_tokens": ["get", "the", "response", "object", "of", "the", "underlying", "rpc", "protocol", "e"], "project": "dubbo"}
{"id": 147, "code": "static MultiValueConverter<?> find(Class<?> sourceType, Class<?> targetType) {\n    return getExtensionLoader(MultiValueConverter.class)\n            .getSupportedExtensionInstances()\n            .stream()\n            .filter(converter -> converter.accept(sourceType, targetType))\n            .findFirst()\n            .orElse(null);\n}", "summary_tokens": ["find", "the", "multi", "value", "converter", "instance", "from", "extension", "loader", "with", "the", "specified", "source", "and", "target", "type"], "project": "dubbo"}
{"id": 648, "code": "private synchronized void initReferenceBean(ReferenceBean referenceBean) throws Exception {\n\n    if (referenceBean.getReferenceConfig() != null) {\n        return;\n    }\n\n        \n\n        \n    String referenceKey = getReferenceKeyByBeanName(referenceBean.getId());\n    if (StringUtils.isEmpty(referenceKey)) {\n        referenceKey = ReferenceBeanSupport.generateReferenceKey(referenceBean, applicationContext);\n    }\n\n    ReferenceConfig referenceConfig = referenceConfigMap.get(referenceKey);\n    if (referenceConfig == null) {\n            \n        Map<String, Object> referenceAttributes = ReferenceBeanSupport.getReferenceAttributes(referenceBean);\n        referenceConfig = ReferenceCreator.create(referenceAttributes, applicationContext)\n                .defaultInterfaceClass(referenceBean.getObjectType())\n                .build();\n\n            \n        if (referenceBean.getId() != null && !referenceBean.getId().contains(\"#\")) {\n            referenceConfig.setId(referenceBean.getId());\n        }\n\n            \n        referenceConfigMap.put(referenceKey, referenceConfig);\n\n            \n        moduleModel.getConfigManager().addReference(referenceConfig);\n    }\n\n        \n    referenceBean.setKeyAndReferenceConfig(referenceKey, referenceConfig);\n}", "summary_tokens": ["note", "this", "method", "should", "only", "call", "after", "all", "dubbo", "config", "beans", "and", "all", "property", "resolvers", "is", "loaded"], "project": "dubbo"}
{"id": 744, "code": "static String buildDefaultValue(int parameterIndex) {\n    return \"{\" + parameterIndex + \"}\";\n}", "summary_tokens": ["build", "the", "default", "value"], "project": "dubbo"}
{"id": 436, "code": "public <T extends AbstractConfig> Optional<T> getConfig(Class<T> cls, String idOrName) {\n    T config = getConfigById(getTagName(cls), idOrName);\n    if (config == null) {\n        config = getConfigByName(cls, idOrName);\n    }\n    return ofNullable(config);\n}", "summary_tokens": ["get", "config", "instance", "by", "id", "or", "by", "name"], "project": "dubbo"}
{"id": 193, "code": "public final void setThreadLocalMap(InternalThreadLocalMap threadLocalMap) {\n    this.threadLocalMap = threadLocalMap;\n}", "summary_tokens": ["sets", "the", "internal", "data", "structure", "that", "keeps", "the", "thread", "local", "variables", "bound", "to", "this", "thread"], "project": "dubbo"}
{"id": 1016, "code": "private static void convertSingleAttachment(DefaultHttp2Headers headers, String key, Object v) {\n    try {\n        if (v instanceof String || v instanceof Number || v instanceof Boolean) {\n            String str = v.toString();\n            headers.set(key, str);\n        } else if (v instanceof byte[]) {\n            String str = encodeBase64ASCII((byte[]) v);\n            headers.set(key + TripleConstant.HEADER_BIN_SUFFIX, str);\n        }\n    } catch (Throwable t) {\n        LOGGER.warn(\"Meet exception when convert single attachment key:\" + key + \" value=\" + v,\n            t);\n    }\n}", "summary_tokens": ["convert", "each", "user", "s", "attach", "value", "to", "metadata"], "project": "dubbo"}
{"id": 1008, "code": "public static <T, R> void oneToOne(T request,\n                                   StreamObserver<R> responseObserver,\n                                   Function<Mono<T>, Mono<R>> func) {\n    func.apply(Mono.just(request)).subscribe(res -> {\n        CompletableFuture.completedFuture(res)\n            .whenComplete((r, t) -> {\n                if (t != null) {\n                    responseObserver.onError(t);\n                } else {\n                    responseObserver.onNext(r);\n                    responseObserver.onCompleted();\n                }\n            });\n    });\n}", "summary_tokens": ["implements", "a", "unary", "unary", "call", "as", "mono", "mono"], "project": "dubbo"}
{"id": 402, "code": "static List<ParameterizedType> getAllGenericInterfaces(Type type, Predicate<ParameterizedType>... typeFilters) {\n\n    Class<?> rawClass = getRawClass(type);\n\n    if (rawClass == null) {\n        return emptyList();\n    }\n\n    List<Class<?>> allTypes = new LinkedList<>();\n        \n    allTypes.add(rawClass);\n        \n    allTypes.addAll(getAllSuperClasses(rawClass, NON_OBJECT_TYPE_FILTER));\n        \n    allTypes.addAll(getAllInterfaces(rawClass));\n\n    List<ParameterizedType> allGenericInterfaces = allTypes\n            .stream()\n            .map(Class::getGenericInterfaces)\n            .map(Arrays::asList)\n            .flatMap(Collection::stream)\n            .filter(TypeUtils::isParameterizedType)\n            .map(ParameterizedType.class::cast)\n            .collect(toList());\n\n    return unmodifiableList(filterAll(allGenericInterfaces, typeFilters));\n}", "summary_tokens": ["get", "all", "generic", "interfaces", "that", "are", "assignable", "from", "parameterized", "type", "interface"], "project": "dubbo"}
{"id": 625, "code": "public Map<InjectionMetadata.InjectedElement, ReferenceBean<?>> getInjectedMethodReferenceBeanMap() {\n    Map<InjectionMetadata.InjectedElement, ReferenceBean<?>> map = new HashMap<>();\n    for (Map.Entry<InjectionMetadata.InjectedElement, String> entry : injectedMethodReferenceBeanCache.entrySet()) {\n        map.put(entry.getKey(), referenceBeanManager.getById(entry.getValue()));\n    }\n    return Collections.unmodifiableMap(map);\n}", "summary_tokens": ["get", "reference", "bean", "map", "in", "injected", "method"], "project": "dubbo"}
{"id": 569, "code": "protected Class<?> getInterface() {\n    return MetadataService.class;\n}", "summary_tokens": ["returns", "the", "interface", "of", "exported", "service"], "project": "dubbo"}
{"id": 337, "code": "static String extractFieldName(Method method) {\n    List<String> emptyFieldMethod = Arrays.asList(\"is\", \"get\", \"getObject\", \"getClass\");\n    String methodName = method.getName();\n    String fieldName = \"\";\n\n    if (emptyFieldMethod.contains(methodName)) {\n        return fieldName;\n    } else if (methodName.startsWith(\"get\")) {\n        fieldName = methodName.substring(\"get\".length());\n    } else if (methodName.startsWith(\"set\")) {\n        fieldName = methodName.substring(\"set\".length());\n    } else if (methodName.startsWith(\"is\")) {\n        fieldName = methodName.substring(\"is\".length());\n    } else {\n        return fieldName;\n    }\n\n    if (StringUtils.isNotEmpty(fieldName)) {\n        fieldName = fieldName.substring(0, 1).toLowerCase() + fieldName.substring(1);\n    }\n\n    return fieldName;\n}", "summary_tokens": ["extract", "field", "name", "from", "set", "get", "is", "method"], "project": "dubbo"}
{"id": 6, "code": "public void addRouters(List<Router> routers) {\n    List<Router> newRouters = new LinkedList<>();\n    newRouters.addAll(builtinRouters);\n    newRouters.addAll(routers);\n    CollectionUtils.sort(newRouters);\n    this.routers = newRouters;\n}", "summary_tokens": ["if", "we", "use", "route", "protocol", "in", "version", "before", "0"], "project": "dubbo"}
{"id": 387, "code": "public static List<String> splitToList(String str, char ch) {\n    if (isEmpty(str)) {\n        return Collections.emptyList();\n    }\n    return splitToList0(str, ch);\n}", "summary_tokens": ["splits", "string", "around", "matches", "of", "the", "given", "character"], "project": "dubbo"}
{"id": 887, "code": "public void testToTable() {\n    List<List<String>> table = new LinkedList<>();\n    table.add(Arrays.asList(\"abc\",\"abc\",\"abc\"));\n    table.add(Arrays.asList(\"1\",\"2\",\"3\"));\n    table.add(Arrays.asList(\"x\",\"y\",\"z\"));\n\n    String toTable = TelnetUtils.toTable(new String[]{\"A\",\"B\",\"C\"},table);\n\n    Assertions.assertTrue(toTable.contains(\"| A   | B   | C   |\"));\n    Assertions.assertTrue(toTable.contains(\"| abc | abc | abc |\"));\n    Assertions.assertTrue(toTable.contains(\"| 1   | 2   | 3   |\"));\n    Assertions.assertTrue(toTable.contains(\"| x   | y   | z   |\"));\n}", "summary_tokens": ["a", "b", "c", "abc", "abc", "abc", "0", "0", "0", "x", "y", "z"], "project": "dubbo"}
{"id": 680, "code": "private Map<String, String> mergeOverriddenProperties(String namespace, Map<String, String> configurations) {\n    if (addedOrModifiedPropertiesOfNamespace.containsKey(namespace)) {\n        configurations.putAll(addedOrModifiedPropertiesOfNamespace.get(namespace));\n    }\n    if (deletedKeysOfNamespace.containsKey(namespace)) {\n        for (String k : deletedKeysOfNamespace.get(namespace)) {\n            configurations.remove(k);\n        }\n    }\n    return configurations;\n}", "summary_tokens": ["incorporate", "user", "modifications", "to", "namespace"], "project": "dubbo"}
{"id": 492, "code": "void testGetMemProperty() {\n    Assertions.assertNull(memConfig.getInternalProperty(MOCK_KEY));\n    Assertions.assertFalse(memConfig.containsKey(MOCK_KEY));\n    Assertions.assertNull(memConfig.getString(MOCK_KEY));\n    Assertions.assertNull(memConfig.getProperty(MOCK_KEY));\n    memConfig.addProperty(MOCK_KEY, MOCK_VALUE);\n    Assertions.assertTrue(memConfig.containsKey(MOCK_KEY));\n    Assertions.assertEquals(MOCK_VALUE, memConfig.getInternalProperty(MOCK_KEY));\n    Assertions.assertEquals(MOCK_VALUE, memConfig.getString(MOCK_KEY, MOCK_VALUE));\n    Assertions.assertEquals(MOCK_VALUE, memConfig.getProperty(MOCK_KEY, MOCK_VALUE));\n}", "summary_tokens": ["test", "get", "mem", "property"], "project": "dubbo"}
{"id": 736, "code": "private String generateMapFieldName(String methodName) {\n    return toCamelCase(methodName.substring(6));\n}", "summary_tokens": ["get", "map", "property", "name", "from", "setting", "method"], "project": "dubbo"}
{"id": 807, "code": "public void testSubscribeMultipleVersions() {\n    Set<String> serviceNames = new HashSet<>();\n    serviceNames.add(\"app1\");\n    listener = new ServiceInstancesChangedListener(serviceNames, serviceDiscovery);\n\n        \n    ServiceInstancesChangedEvent event = new ServiceInstancesChangedEvent(\"app1\", app1Instances);\n    listener.onEvent(event);\n\n    Map<String, List<ServiceInstance>> allInstances = listener.getAllInstances();\n    Assertions.assertEquals(1, allInstances.size());\n    Assertions.assertEquals(3, allInstances.get(\"app1\").size());\n\n    ProtocolServiceKey protocolServiceKey = new ProtocolServiceKey(service1, null, null, \"dubbo\");\n    List<URL> serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, \"\", null, \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, \"*\", null, \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, \",1.0.0\", null, \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, \"1.0.0,\", null, \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, \"1.0.0,,1.0.1\", null, \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(3, serviceUrls.size());\n    assertTrue(serviceUrls.get(0) instanceof InstanceAddressURL);\n\n    protocolServiceKey = new ProtocolServiceKey(service1, \"1.0.1,1.0.0\", null, \"dubbo\");\n    serviceUrls = listener.getAddresses(protocolServiceKey, consumerURL);\n    Assertions.assertEquals(0, serviceUrls.size());\n}", "summary_tokens": ["test", "subscribe", "multiple", "versions"], "project": "dubbo"}
{"id": 308, "code": "public static Properties loadProperties(Set<ClassLoader> classLoaders, String fileName, boolean allowMultiFile, boolean optional) {\n    Properties properties = new Properties();\n        \n    if (checkFileNameExist(fileName)) {\n        try {\n            FileInputStream input = new FileInputStream(fileName);\n            try {\n                properties.load(input);\n            } finally {\n                input.close();\n            }\n        } catch (Throwable e) {\n            logger.warn(\"Failed to load \" + fileName + \" file from \" + fileName + \"(ignore this file): \" + e.getMessage(), e);\n        }\n        return properties;\n    }\n\n    Set<java.net.URL> set = null;\n    try {\n        List<ClassLoader> classLoadersToLoad = new LinkedList<>();\n        classLoadersToLoad.add(ClassUtils.getClassLoader());\n        classLoadersToLoad.addAll(classLoaders);\n        set = ClassLoaderResourceLoader.loadResources(fileName, classLoadersToLoad).values().stream().reduce(new LinkedHashSet<>(), (a, i) -> {\n            a.addAll(i);\n            return a;\n        });\n    } catch (Throwable t) {\n        logger.warn(\"Fail to load \" + fileName + \" file: \" + t.getMessage(), t);\n    }\n\n    if (CollectionUtils.isEmpty(set)) {\n        if (!optional) {\n            logger.warn(\"No \" + fileName + \" found on the class path.\");\n        }\n        return properties;\n    }\n\n    if (!allowMultiFile) {\n        if (set.size() > 1) {\n            String errMsg = String.format(\"only 1 %s file is expected, but %d dubbo.properties files found on class path: %s\",\n                fileName, set.size(), set);\n            logger.warn(errMsg);\n        }\n\n            \n        try {\n            properties.load(ClassUtils.getClassLoader().getResourceAsStream(fileName));\n        } catch (Throwable e) {\n            logger.warn(\"Failed to load \" + fileName + \" file from \" + fileName + \"(ignore this file): \" + e.getMessage(), e);\n        }\n        return properties;\n    }\n\n    logger.info(\"load \" + fileName + \" properties file from \" + set);\n\n    for (java.net.URL url : set) {\n        try {\n            Properties p = new Properties();\n            InputStream input = url.openStream();\n            if (input != null) {\n                try {\n                    p.load(input);\n                    properties.putAll(p);\n                } finally {\n                    try {\n                        input.close();\n                    } catch (Throwable t) {\n                    }\n                }\n            }\n        } catch (Throwable e) {\n            logger.warn(\"Fail to load \" + fileName + \" file from \" + url + \"(ignore this file): \" + e.getMessage(), e);\n        }\n    }\n\n    return properties;\n}", "summary_tokens": ["load", "properties", "file", "to", "properties", "from", "class", "path"], "project": "dubbo"}
{"id": 681, "code": "public void addOrModifyProperty(String namespace, String someKey, String someValue) {\n    if (addedOrModifiedPropertiesOfNamespace.containsKey(namespace)) {\n        addedOrModifiedPropertiesOfNamespace.get(namespace).put(someKey, someValue);\n    } else {\n        Map<String, String> m = Maps.newConcurrentMap();\n        m.put(someKey, someValue);\n        addedOrModifiedPropertiesOfNamespace.put(namespace, m);\n    }\n}", "summary_tokens": ["add", "new", "property", "or", "update", "existed", "property"], "project": "dubbo"}
{"id": 737, "code": "private String generateListFieldName(String methodName) {\n    return toCamelCase(methodName.substring(3, methodName.length() - 4));\n}", "summary_tokens": ["get", "list", "property", "name", "from", "setting", "method"], "project": "dubbo"}
{"id": 53, "code": "public void testMockInvokerFromOverride_Invoke_Fock_someMethods() {\n    URL url = URL.valueOf(\"remote://1.2.3.4/\" + IHelloService.class.getName())\n            .addParameter(REFER_KEY,\n                    URL.encode(PATH_KEY + \"=\" + IHelloService.class.getName()\n                            + \"&\" + \"getSomething.mock=fail:return x\"\n                            + \"&\" + \"getSomething2.mock=force:return y\"));\n    Invoker<IHelloService> cluster = getClusterInvoker(url);\n        \n    RpcInvocation invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething\");\n    Result ret = cluster.invoke(invocation);\n    Assertions.assertEquals(\"something\", ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething2\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertEquals(\"y\", ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething3\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertEquals(\"something3\", ret.getValue());\n\n        \n    invocation = new RpcInvocation();\n    invocation.setMethodName(\"sayHello\");\n    ret = cluster.invoke(invocation);\n    Assertions.assertNull(ret.getValue());\n}", "summary_tokens": ["test", "if", "mock", "policy", "works", "fine", "fail", "mock"], "project": "dubbo"}
{"id": 443, "code": "public Optional<ConsumerConfig> getDefaultConsumer() {\n    List<ConsumerConfig> consumerConfigs = getDefaultConfigs(getConfigsMap(getTagName(ConsumerConfig.class)));\n    if (CollectionUtils.isNotEmpty(consumerConfigs)) {\n        return Optional.of(consumerConfigs.get(0));\n    }\n    return Optional.empty();\n}", "summary_tokens": ["only", "allows", "one", "default", "consumer", "config"], "project": "dubbo"}
{"id": 682, "code": "private NacosConfigListener createTargetListener(String key, String group) {\n    NacosConfigListener configListener = new NacosConfigListener();\n    configListener.fillContext(key, group);\n    return configListener;\n}", "summary_tokens": ["ignores", "the", "group", "parameter"], "project": "dubbo"}
{"id": 890, "code": "static void removeChannelIfDisconnected(Channel ch) {\n    if (ch != null && !ch.isActive()) {\n        NettyChannel nettyChannel = CHANNEL_MAP.remove(ch);\n        if (nettyChannel != null) {\n            nettyChannel.markActive(false);\n        }\n    }\n}", "summary_tokens": ["remove", "the", "inactive", "channel"], "project": "dubbo"}
{"id": 422, "code": "public void setReferBackground(Boolean referBackground) {\n    this.referBackground = referBackground;\n}", "summary_tokens": ["whether", "refer", "should", "run", "in", "background", "or", "not"], "project": "dubbo"}
{"id": 311, "code": "public static URL setThreadName(URL url, String defaultName) {\n    String name = url.getParameter(THREAD_NAME_KEY, defaultName);\n    name = name + \"-\" + url.getAddress();\n    url = url.addParameter(THREAD_NAME_KEY, name);\n    return url;\n}", "summary_tokens": ["append", "thread", "name", "with", "url", "address"], "project": "dubbo"}
{"id": 594, "code": "private void afterRefer() {\n        \n    Assertions.assertNotNull(singleRegistryCenterIntegrationService);\n        \n    Assertions.assertNotNull(referenceConfig.getInvoker());\n    Assertions.assertTrue(referenceConfig.getInvoker() instanceof MigrationInvoker);\n        \n    Assertions.assertEquals(\"Hello Reference\",\n        singleRegistryCenterIntegrationService.hello(\"Reference\"));\n        \n    Directory directory = ((MigrationInvoker) referenceConfig.getInvoker()).getDirectory();\n        \n    Assertions.assertNotNull(directory);\n        \n    Assertions.assertTrue(directory instanceof ServiceDiscoveryRegistryDirectory);\n        \n    Assertions.assertEquals(directory.getInterface(), SingleRegistryCenterIntegrationService.class);\n        \n    Assertions.assertTrue(directory.isAvailable());\n        \n    Assertions.assertFalse(directory.isDestroyed());\n        \n    Assertions.assertTrue(directory.isNotificationReceived());\n    ServiceDiscoveryRegistryDirectory serviceDiscoveryRegistryDirectory = (ServiceDiscoveryRegistryDirectory) directory;\n        \n    Assertions.assertTrue(serviceDiscoveryRegistryDirectory.isShouldRegister());\n        \n    Assertions.assertEquals(serviceDiscoveryRegistryDirectory.getRegisteredConsumerUrl().getCategory(), CONSUMERS_CATEGORY);\n        \n    Assertions.assertTrue(serviceDiscoveryRegistryDirectory.getRegistry() instanceof ListenerRegistryWrapper);\n        \n    Assertions.assertEquals(serviceDiscoveryRegistryDirectory.getAllInvokers().size(), 1);\n    Assertions.assertEquals(serviceDiscoveryRegistryDirectory.getInvokers(), serviceDiscoveryRegistryDirectory.getAllInvokers());\n}", "summary_tokens": ["there", "are", "some", "checkpoints", "needed", "to", "check", "after", "referred", "as", "follow", "ul", "li", "single", "registry", "center", "integration", "service", "instance", "can", "t", "be", "null", "li", "li", "rpc", "works", "well", "or", "not", "li", "li", "invoker", "is", "right", "or", "not", "li", "li", "directory", "is", "null", "or", "not", "li", "li", "registered", "interface", "is", "right", "or", "not", "li", "li", "directory", "is", "available", "or", "not", "li", "li", "directory", "is", "destroyed", "or", "not", "li", "li", "directory", "has", "received", "notification", "or", "not", "li", "li", "service", "discovery", "registry", "directory", "should", "register", "or", "not", "li", "li", "service", "discovery", "registry", "directory", "s", "registered", "consumer", "url", "is", "right", "or", "not", "li", "li", "service", "discovery", "registry", "directory", "s", "registry", "is", "right", "or", "not", "li", "li", "directory", "s", "invokers", "are", "right", "or", "not", "li", "ul"], "project": "dubbo"}
{"id": 645, "code": "protected Iterable<PropertySource<?>> getPropertySources() {\n    return propertySources;\n}", "summary_tokens": ["get", "multiple", "property", "source", "property", "sources"], "project": "dubbo"}
{"id": 157, "code": "private String generateInvocationArgumentNullCheck(Method method) {\n    Class<?>[] pts = method.getParameterTypes();\n    return IntStream.range(0, pts.length).filter(i -> CLASS_NAME_INVOCATION.equals(pts[i].getName()))\n                    .mapToObj(i -> String.format(CODE_INVOCATION_ARGUMENT_NULL_CHECK, i, i))\n                    .findFirst().orElse(\"\");\n}", "summary_tokens": ["generate", "code", "to", "test", "argument", "of", "type", "code", "invocation", "code", "is", "null"], "project": "dubbo"}
{"id": 800, "code": "public void destroyAll() {\n    if (!destroyed.compareAndSet(false, true)) {\n        return;\n    }\n\n    if (LOGGER.isInfoEnabled()) {\n        LOGGER.info(\"Close all registries \" + getRegistries());\n    }\n        \n    lock.lock();\n    try {\n        for (Registry registry : getRegistries()) {\n            try {\n                registry.destroy();\n            } catch (Throwable e) {\n                LOGGER.warn(e.getMessage(), e);\n            }\n        }\n        registries.clear();\n    } finally {\n            \n        lock.unlock();\n    }\n}", "summary_tokens": ["close", "all", "created", "registries"], "project": "dubbo"}
{"id": 130, "code": "static String getRuleKey(URL url) {\n    return url.getColonSeparatedKey();\n}", "summary_tokens": ["the", "format", "is", "interface", "name", "version", "group"], "project": "dubbo"}
{"id": 925, "code": "public <T> T getResponse(Class<T> clazz) {\n    return (response != null && clazz.isAssignableFrom(response.getClass())) ? (T) response : null;\n}", "summary_tokens": ["get", "the", "response", "object", "of", "the", "underlying", "rpc", "protocol", "e"], "project": "dubbo"}
