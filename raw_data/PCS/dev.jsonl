{"id": 767, "code": "\tprivate void skipToEndOfLine() {\n\t\tfor (; this.pos < this.in.length(); this.pos++) {\n\t\t\tchar c = this.in.charAt(this.pos);\n\t\t\tif (c == '\\r' || c == '\\n') {\n\t\t\t\tthis.pos++;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["advances", "the", "position", "until", "after", "the", "next", "newline", "character"], "project": "spring-boot"}
{"id": 214, "code": "\tpublic JmsPoolConnectionFactory createPooledConnectionFactory(ConnectionFactory connectionFactory) {\n\t\tJmsPoolConnectionFactory pooledConnectionFactory = new JmsPoolConnectionFactory();\n\t\tpooledConnectionFactory.setConnectionFactory(connectionFactory);\n\n\t\tpooledConnectionFactory.setBlockIfSessionPoolIsFull(this.properties.isBlockIfFull());\n\t\tif (this.properties.getBlockIfFullTimeout() != null) {\n\t\t\tpooledConnectionFactory\n\t\t\t\t\t.setBlockIfSessionPoolIsFullTimeout(this.properties.getBlockIfFullTimeout().toMillis());\n\t\t}\n\t\tif (this.properties.getIdleTimeout() != null) {\n\t\t\tpooledConnectionFactory.setConnectionIdleTimeout((int) this.properties.getIdleTimeout().toMillis());\n\t\t}\n\t\tpooledConnectionFactory.setMaxConnections(this.properties.getMaxConnections());\n\t\tpooledConnectionFactory.setMaxSessionsPerConnection(this.properties.getMaxSessionsPerConnection());\n\t\tif (this.properties.getTimeBetweenExpirationCheck() != null) {\n\t\t\tpooledConnectionFactory\n\t\t\t\t\t.setConnectionCheckInterval(this.properties.getTimeBetweenExpirationCheck().toMillis());\n\t\t}\n\t\tpooledConnectionFactory.setUseAnonymousProducers(this.properties.isUseAnonymousProducers());\n\t\treturn pooledConnectionFactory;\n\t}", "summary_tokens": ["create", "a", "jms", "pool", "connection", "factory", "based", "on", "the", "specified", "connection", "factory"], "project": "spring-boot"}
{"id": 609, "code": "\tpublic static ContainerStatus of(int statusCode, String errorMessage) {\n\t\treturn new ContainerStatus(statusCode, errorMessage);\n\t}", "summary_tokens": ["create", "a", "new", "container", "status", "instance", "with", "the", "specified", "values"], "project": "spring-boot"}
{"id": 560, "code": "\tint getPatch() {\n\t\treturn this.patch;\n\t}", "summary_tokens": ["return", "the", "patch", "version", "number"], "project": "spring-boot"}
{"id": 127, "code": "\tpublic static Tag outcome(ServerWebExchange exchange, Throwable exception) {\n\t\tif (exception != null) {\n\t\t\tif (exception instanceof CancelledServerWebExchangeException\n\t\t\t\t\t|| DISCONNECTED_CLIENT_EXCEPTIONS.contains(exception.getClass().getSimpleName())) {\n\t\t\t\treturn Outcome.UNKNOWN.asTag();\n\t\t\t}\n\t\t}\n\t\tHttpStatusCode statusCode = exchange.getResponse().getStatusCode();\n\t\tOutcome outcome = (statusCode != null) ? Outcome.forStatus(statusCode.value()) : Outcome.SUCCESS;\n\t\treturn outcome.asTag();\n\t}", "summary_tokens": ["creates", "an", "outcome", "tag", "based", "on", "the", "response", "status", "of", "the", "given", "exchange", "and", "the", "exception", "thrown", "during", "request", "processing"], "project": "spring-boot"}
{"id": 1544, "code": "\tpublic void setScopeMetadataResolver(ScopeMetadataResolver scopeMetadataResolver) {\n\t\tthis.reader.setScopeMetadataResolver(scopeMetadataResolver);\n\t\tthis.scanner.setScopeMetadataResolver(scopeMetadataResolver);\n\t}", "summary_tokens": ["set", "the", "scope", "metadata", "resolver", "to", "use", "for", "detected", "bean", "classes"], "project": "spring-boot"}
{"id": 287, "code": "\tprotected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status,\n\t\t\tMap<String, Object> model) {\n\t\tfor (ErrorViewResolver resolver : this.errorViewResolvers) {\n\t\t\tModelAndView modelAndView = resolver.resolveErrorView(request, status, model);\n\t\t\tif (modelAndView != null) {\n\t\t\t\treturn modelAndView;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["resolve", "any", "specific", "error", "views"], "project": "spring-boot"}
{"id": 270, "code": "\tprotected Throwable getError(ServerRequest request) {\n\t\treturn this.errorAttributes.getError(request);\n\t}", "summary_tokens": ["extract", "the", "original", "error", "from", "the", "current", "request"], "project": "spring-boot"}
{"id": 965, "code": "\tprotected LayoutFactory getLayoutFactory() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "layout", "factory", "that", "will", "be", "used", "to", "determine", "the", "layout", "type", "if", "no", "explicit", "layout", "is", "set"], "project": "spring-boot"}
{"id": 944, "code": "\tprotected boolean isSearchCandidate(Archive.Entry entry) {\n\t\tif (getArchiveEntryPathPrefix() == null) {\n\t\t\treturn true;\n\t\t}\n\t\treturn entry.getName().startsWith(getArchiveEntryPathPrefix());\n\t}", "summary_tokens": ["determine", "if", "the", "specified", "entry", "is", "a", "candidate", "for", "further", "searching"], "project": "spring-boot"}
{"id": 242, "code": "\tpublic static DatabaseInitializationSettings getSettings(DataSource dataSource, QuartzProperties properties) {\n\t\tDatabaseInitializationSettings settings = new DatabaseInitializationSettings();\n\t\tsettings.setSchemaLocations(resolveSchemaLocations(dataSource, properties.getJdbc()));\n\t\tsettings.setMode(properties.getJdbc().getInitializeSchema());\n\t\tsettings.setContinueOnError(true);\n\t\treturn settings;\n\t}", "summary_tokens": ["adapts", "quartz", "properties", "quartz", "properties", "to", "database", "initialization", "settings", "replacing", "any", "placeholders"], "project": "spring-boot"}
{"id": 1167, "code": "\tpublic List<TimelineEvent> getEvents() {\n\t\treturn this.events;\n\t}", "summary_tokens": ["return", "the", "recorded", "events"], "project": "spring-boot"}
{"id": 654, "code": "\tprotected final JsonNode getNode() {\n\t\treturn this.node;\n\t}", "summary_tokens": ["return", "the", "source", "node", "of", "the", "mapped", "object"], "project": "spring-boot"}
{"id": 1470, "code": "\tpublic static void ifPortBindingException(Exception ex, Consumer<BindException> action) {\n\t\tifCausedBy(ex, BindException.class, (bindException) -> {\n\t\t\t\n\t\t\tif (bindException.getMessage().toLowerCase().contains(\"in use\")) {\n\t\t\t\taction.accept(bindException);\n\t\t\t}\n\t\t});\n\t}", "summary_tokens": ["perform", "an", "action", "if", "the", "given", "exception", "was", "caused", "by", "a", "port", "in", "use", "bind", "exception"], "project": "spring-boot"}
{"id": 755, "code": "\tpublic JSONStringer object() throws JSONException {\n\t\treturn open(Scope.EMPTY_OBJECT, \"{\");\n\t}\n\n\t\n\tpublic JSONStringer endObject() throws JSONException {\n\t\treturn close(Scope.EMPTY_OBJECT, Scope.NONEMPTY_OBJECT, \"}\");\n\t}", "summary_tokens": ["begins", "encoding", "a", "new", "object"], "project": "spring-boot"}
{"id": 779, "code": "\tStream<PropertyDescriptor<?>> resolve(TypeElement type, ExecutableElement factoryMethod) {\n\t\tTypeElementMembers members = new TypeElementMembers(this.environment, type);\n\t\tif (factoryMethod != null) {\n\t\t\treturn resolveJavaBeanProperties(type, factoryMethod, members);\n\t\t}\n\t\treturn resolve(ConfigurationPropertiesTypeElement.of(type, this.environment), factoryMethod, members);\n\t}", "summary_tokens": ["return", "the", "property", "descriptor", "instances", "that", "are", "valid", "candidates", "for", "the", "specified", "type", "element", "type", "based", "on", "the", "specified", "executable", "element", "factory", "method", "if", "any"], "project": "spring-boot"}
{"id": 1244, "code": "\tpublic Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "invalid", "value", "can", "be", "null"], "project": "spring-boot"}
{"id": 1269, "code": "\tprivate static String coerceToEpoch(String s) {\n\t\tLong epoch = parseEpochSecond(s);\n\t\tif (epoch != null) {\n\t\t\treturn String.valueOf(epoch);\n\t\t}\n\t\tDateTimeFormatter format = DateTimeFormatter.ofPattern(\"yyyy-MM-dd'T'HH:mm:ssZ\");\n\t\ttry {\n\t\t\treturn String.valueOf(format.parse(s, Instant::from).toEpochMilli());\n\t\t}\n\t\tcatch (DateTimeParseException ex) {\n\t\t\treturn s;\n\t\t}\n\t}", "summary_tokens": ["attempt", "to", "convert", "the", "specified", "value", "to", "epoch", "time"], "project": "spring-boot"}
{"id": 192, "code": "\tpublic static void register(BeanDefinitionRegistry registry, Collection<String> packageNames) {\n\t\tAssert.notNull(registry, \"Registry must not be null\");\n\t\tAssert.notNull(packageNames, \"PackageNames must not be null\");\n\t\tif (registry.containsBeanDefinition(BEAN)) {\n\t\t\tEntityScanPackagesBeanDefinition beanDefinition = (EntityScanPackagesBeanDefinition) registry\n\t\t\t\t\t.getBeanDefinition(BEAN);\n\t\t\tbeanDefinition.addPackageNames(packageNames);\n\t\t}\n\t\telse {\n\t\t\tregistry.registerBeanDefinition(BEAN, new EntityScanPackagesBeanDefinition(packageNames));\n\t\t}\n\t}", "summary_tokens": ["register", "the", "specified", "entity", "scan", "packages", "with", "the", "system"], "project": "spring-boot"}
{"id": 265, "code": "\tdefault RequestMappingHandlerAdapter getRequestMappingHandlerAdapter() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "custom", "request", "mapping", "handler", "adapter", "that", "should", "be", "used", "and", "processed", "by", "the", "web", "flux", "configuration"], "project": "spring-boot"}
{"id": 1392, "code": "\tpublic RestTemplateBuilder requestCustomizers(\n\t\t\tCollection<? extends RestTemplateRequestCustomizer<?>> requestCustomizers) {\n\t\tAssert.notNull(requestCustomizers, \"RequestCustomizers must not be null\");\n\t\treturn new RestTemplateBuilder(this.requestFactoryCustomizer, this.detectRequestFactory, this.rootUri,\n\t\t\t\tthis.messageConverters, this.interceptors, this.requestFactory, this.uriTemplateHandler,\n\t\t\t\tthis.errorHandler, this.basicAuthentication, this.defaultHeaders, this.customizers,\n\t\t\t\tcopiedSetOf(requestCustomizers));\n\t}", "summary_tokens": ["set", "the", "rest", "template", "request", "customizer", "rest", "template", "request", "customizers", "that", "should", "be", "applied", "to", "the", "client", "http", "request"], "project": "spring-boot"}
{"id": 472, "code": "\tpublic static TestPropertyValues empty() {\n\t\treturn EMPTY;\n\t}", "summary_tokens": ["return", "an", "empty", "test", "property", "values", "instance"], "project": "spring-boot"}
{"id": 997, "code": "\tprotected LayoutType getLayout() {\n\t\treturn this.layout;\n\t}", "summary_tokens": ["return", "the", "type", "of", "archive", "that", "should", "be", "packaged", "by", "this", "mojo"], "project": "spring-boot"}
{"id": 737, "code": "\tpublic int optInt(String name, int fallback) {\n\t\tObject object = opt(name);\n\t\tInteger result = JSON.toInteger(object);\n\t\treturn result != null ? result : fallback;\n\t}", "summary_tokens": ["returns", "the", "value", "mapped", "by", "name", "if", "it", "exists", "and", "is", "an", "int", "or", "can", "be", "coerced", "to", "an", "int"], "project": "spring-boot"}
{"id": 1522, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "of", "the", "registration", "bean"], "project": "spring-boot"}
{"id": 828, "code": "\tpublic boolean isVerboseLogging() {\n\t\treturn this.verboseLogging;\n\t}", "summary_tokens": ["whether", "verbose", "logging", "should", "be", "enabled", "while", "building", "the", "image"], "project": "spring-boot"}
{"id": 1017, "code": "\tpublic ConfigurableApplicationContext getApplicationContext() {\n\t\treturn this.applicationContext;\n\t}", "summary_tokens": ["return", "the", "prepared", "application", "context"], "project": "spring-boot"}
{"id": 649, "code": "\tdefault void file(String name, Owner owner, Content content) throws IOException {\n\t\tfile(name, owner, 0644, content);\n\t}", "summary_tokens": ["write", "a", "file", "to", "the", "content"], "project": "spring-boot"}
{"id": 1086, "code": "\tProfiles getProfiles() {\n\t\treturn this.profiles;\n\t}", "summary_tokens": ["return", "profile", "information", "if", "it", "is", "available"], "project": "spring-boot"}
{"id": 1457, "code": "\tpublic Shutdown getShutdown() {\n\t\treturn this.shutdown;\n\t}", "summary_tokens": ["returns", "the", "shutdown", "configuration", "that", "will", "be", "applied", "to", "the", "server"], "project": "spring-boot"}
{"id": 1228, "code": "\tpublic ConfigurationPropertyName getParent() {\n\t\tint numberOfElements = getNumberOfElements();\n\t\treturn (numberOfElements <= 1) ? EMPTY : chop(numberOfElements - 1);\n\t}", "summary_tokens": ["return", "the", "parent", "of", "this", "configuration", "property", "name", "or", "configuration", "property", "name", "empty", "if", "there", "is", "no", "parent"], "project": "spring-boot"}
{"id": 274, "code": "\tprotected Mono<ServerResponse> renderErrorView(String viewName, ServerResponse.BodyBuilder responseBody,\n\t\t\tMap<String, Object> error) {\n\t\tif (isTemplateAvailable(viewName)) {\n\t\t\treturn responseBody.render(viewName, error);\n\t\t}\n\t\tResource resource = resolveResource(viewName);\n\t\tif (resource != null) {\n\t\t\treturn responseBody.body(BodyInserters.fromResource(resource));\n\t\t}\n\t\treturn Mono.empty();\n\t}", "summary_tokens": ["render", "the", "given", "error", "data", "as", "a", "view", "using", "a", "template", "view", "if", "available", "or", "a", "static", "html", "file", "if", "available", "otherwise"], "project": "spring-boot"}
{"id": 348, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "repository"], "project": "spring-boot"}
{"id": 620, "code": "\tpublic Map<String, String> getEnv() {\n\t\treturn this.configEnv;\n\t}", "summary_tokens": ["return", "the", "image", "environment", "variables"], "project": "spring-boot"}
{"id": 312, "code": "\tString getLanguage() {\n\t\treturn this.language;\n\t}", "summary_tokens": ["the", "programming", "language", "to", "use", "or", "null", "if", "it", "should", "not", "be", "customized"], "project": "spring-boot"}
{"id": 1218, "code": "\tstatic ConfigurationPropertyCaching get(Iterable<ConfigurationPropertySource> sources, Object underlyingSource) {\n\t\tAssert.notNull(sources, \"Sources must not be null\");\n\t\tif (underlyingSource == null) {\n\t\t\treturn new ConfigurationPropertySourcesCaching(sources);\n\t\t}\n\t\tfor (ConfigurationPropertySource source : sources) {\n\t\t\tif (source.getUnderlyingSource() == underlyingSource) {\n\t\t\t\tConfigurationPropertyCaching caching = CachingConfigurationPropertySource.find(source);\n\t\t\t\tif (caching != null) {\n\t\t\t\t\treturn caching;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tthrow new IllegalStateException(\"Unable to find cache from configuration property sources\");\n\t}", "summary_tokens": ["get", "for", "a", "specific", "configuration", "property", "source", "in", "the", "specified", "configuration", "property", "sources"], "project": "spring-boot"}
{"id": 701, "code": "\tpublic JSONArray put(int index, Object value) throws JSONException {\n\t\tif (value instanceof Number) {\n\t\t\t\n\t\t\t\n\t\t\tJSON.checkDouble(((Number) value).doubleValue());\n\t\t}\n\t\twhile (this.values.size() <= index) {\n\t\t\tthis.values.add(null);\n\t\t}\n\t\tthis.values.set(index, value);\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "value", "at", "index", "to", "value", "null", "padding", "this", "array", "to", "the", "required", "length", "if", "necessary"], "project": "spring-boot"}
{"id": 902, "code": "\tstatic Command find(Collection<? extends Command> commands, String name) {\n\t\tfor (Command command : commands) {\n\t\t\tif (command.getName().equals(name)) {\n\t\t\t\treturn command;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["static", "method", "that", "can", "be", "used", "to", "find", "a", "single", "command", "from", "a", "collection"], "project": "spring-boot"}
{"id": 831, "code": "\tpublic void setPullPolicy(PullPolicy pullPolicy) {\n\t\tthis.pullPolicy = pullPolicy;\n\t}", "summary_tokens": ["sets", "image", "pull", "policy", "that", "will", "be", "used", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 161, "code": "\tpublic void configure(RabbitStreamTemplate template) {\n\t\tif (this.messageConverter != null) {\n\t\t\ttemplate.setMessageConverter(this.messageConverter);\n\t\t}\n\t\tif (this.streamMessageConverter != null) {\n\t\t\ttemplate.setStreamConverter(this.streamMessageConverter);\n\t\t}\n\t\tif (this.producerCustomizer != null) {\n\t\t\ttemplate.setProducerCustomizer(this.producerCustomizer);\n\t\t}\n\t}", "summary_tokens": ["configure", "the", "specified", "rabbit", "stream", "template"], "project": "spring-boot"}
{"id": 1256, "code": "\tpublic String getAction() {\n\t\treturn this.action;\n\t}", "summary_tokens": ["returns", "the", "action", "if", "any", "to", "be", "taken", "to", "address", "the", "failure"], "project": "spring-boot"}
{"id": 1400, "code": "\tpublic WebServer getWebServer() {\n\t\treturn getSource();\n\t}", "summary_tokens": ["access", "the", "web", "server"], "project": "spring-boot"}
{"id": 470, "code": "\tpublic <T> T applyToSystemProperties(Callable<T> call) {\n\t\ttry (SystemPropertiesHandler handler = new SystemPropertiesHandler()) {\n\t\t\treturn call.call();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\trethrow(ex);\n\t\t\tthrow new IllegalStateException(\"Original cause not rethrown\", ex);\n\t\t}\n\t}", "summary_tokens": ["add", "the", "properties", "to", "the", "system", "get", "properties", "system", "properties", "for", "the", "duration", "of", "the", "call", "restoring", "previous", "values", "when", "it", "completes"], "project": "spring-boot"}
{"id": 1550, "code": "\tprotected Collection<ServletContextInitializer> getServletContextInitializerBeans() {\n\t\treturn new ServletContextInitializerBeans(getBeanFactory());\n\t}", "summary_tokens": ["returns", "servlet", "context", "initializer", "s", "that", "should", "be", "used", "with", "the", "embedded", "web", "server"], "project": "spring-boot"}
{"id": 1607, "code": "\tprivate void removeSystemProperties() {\n\t\tMutablePropertySources sources = this.context.getEnvironment().getPropertySources();\n\t\tsources.remove(\"systemProperties\");\n\t\tsources.remove(\"systemEnvironment\");\n\t}", "summary_tokens": ["strict", "tests", "need", "a", "known", "set", "of", "properties", "so", "we", "remove", "system", "items", "which", "may", "be", "environment", "specific"], "project": "spring-boot"}
{"id": 1, "code": "\tprivate void addMavenOptionalFeature(Project project) {\n\t\tJavaPluginExtension extension = project.getExtensions().getByType(JavaPluginExtension.class);\n\t\textension.registerFeature(\"mavenOptional\",\n\t\t\t\t(feature) -> feature.usingSourceSet(extension.getSourceSets().getByName(\"main\")));\n\t\tAdhocComponentWithVariants javaComponent = (AdhocComponentWithVariants) project.getComponents()\n\t\t\t\t.findByName(\"java\");\n\t\tjavaComponent.addVariantsFromConfiguration(\n\t\t\t\tproject.getConfigurations().findByName(\"mavenOptionalRuntimeElements\"),\n\t\t\t\tConfigurationVariantDetails::mapToOptional);\n\t}", "summary_tokens": ["add", "a", "feature", "that", "allows", "maven", "plugins", "to", "declare", "optional", "dependencies", "that", "appear", "in", "the", "pom"], "project": "spring-boot"}
{"id": 1490, "code": "\tpublic String getTrustCertificatePrivateKey() {\n\t\treturn this.trustCertificatePrivateKey;\n\t}", "summary_tokens": ["return", "the", "location", "of", "the", "private", "key", "for", "the", "trust", "certificate", "in", "pem", "format"], "project": "spring-boot"}
{"id": 1261, "code": "\tpublic String getArtifact() {\n\t\treturn get(\"artifact\");\n\t}", "summary_tokens": ["return", "the", "artifact", "id", "of", "the", "project", "or", "null"], "project": "spring-boot"}
{"id": 267, "code": "\tpublic void setMessageReaders(List<HttpMessageReader<?>> messageReaders) {\n\t\tAssert.notNull(messageReaders, \"'messageReaders' must not be null\");\n\t\tthis.messageReaders = messageReaders;\n\t}", "summary_tokens": ["configure", "http", "message", "readers", "to", "deserialize", "the", "request", "body", "with"], "project": "spring-boot"}
{"id": 1268, "code": "\tpublic Instant getCommitTime() {\n\t\treturn getInstant(\"commit.time\");\n\t}", "summary_tokens": ["return", "the", "timestamp", "of", "the", "commit", "or", "null"], "project": "spring-boot"}
{"id": 402, "code": "\tpublic String toHexString() {\n\t\tbyte[] bytes = this.data.array();\n\t\treturn HEX_FORMAT.formatHex(bytes);\n\t}", "summary_tokens": ["return", "the", "payload", "as", "a", "hexadecimal", "string"], "project": "spring-boot"}
{"id": 201, "code": "\tpublic String determineUrl() {\n\t\tif (StringUtils.hasText(this.url)) {\n\t\t\treturn this.url;\n\t\t}\n\t\tString databaseName = determineDatabaseName();\n\t\tString url = (databaseName != null) ? this.embeddedDatabaseConnection.getUrl(databaseName) : null;\n\t\tif (!StringUtils.hasText(url)) {\n\t\t\tthrow new DataSourceBeanCreationException(\"Failed to determine suitable jdbc url\", this,\n\t\t\t\t\tthis.embeddedDatabaseConnection);\n\t\t}\n\t\treturn url;\n\t}", "summary_tokens": ["determine", "the", "url", "to", "use", "based", "on", "this", "configuration", "and", "the", "environment"], "project": "spring-boot"}
{"id": 231, "code": "\tpublic Map<String, Object> buildProducerProperties() {\n\t\tMap<String, Object> properties = buildCommonProperties();\n\t\tproperties.putAll(this.producer.buildProperties());\n\t\treturn properties;\n\t}", "summary_tokens": ["create", "an", "initial", "map", "of", "producer", "properties", "from", "the", "state", "of", "this", "instance"], "project": "spring-boot"}
{"id": 247, "code": "\tpublic StaticResourceServerWebExchange at(Set<StaticResourceLocation> locations) {\n\t\tAssert.notNull(locations, \"Locations must not be null\");\n\t\treturn new StaticResourceServerWebExchange(new LinkedHashSet<>(locations));\n\t}", "summary_tokens": ["returns", "a", "matcher", "that", "includes", "the", "specified", "static", "resource", "location", "locations"], "project": "spring-boot"}
{"id": 1060, "code": "\tpublic SpringApplicationBuilder banner(Banner banner) {\n\t\tthis.application.setBanner(banner);\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "banner", "instance", "which", "will", "be", "used", "to", "print", "the", "banner", "when", "no", "static", "banner", "file", "is", "provided"], "project": "spring-boot"}
{"id": 1510, "code": "\tpublic Map<String, String> getInitParameters() {\n\t\treturn this.initParameters;\n\t}", "summary_tokens": ["returns", "a", "mutable", "map", "of", "the", "registration", "init", "parameters"], "project": "spring-boot"}
{"id": 725, "code": "\tpublic JSONObject putOpt(String name, Object value) throws JSONException {\n\t\tif (name == null || value == null) {\n\t\t\treturn this;\n\t\t}\n\t\treturn put(name, value);\n\t}", "summary_tokens": ["equivalent", "to", "put", "name", "value", "when", "both", "parameters", "are", "non", "null", "does", "nothing", "otherwise"], "project": "spring-boot"}
{"id": 676, "code": "\tpublic ConfigurationMetadataRepository build() {\n\t\tSimpleConfigurationMetadataRepository result = new SimpleConfigurationMetadataRepository();\n\t\tfor (SimpleConfigurationMetadataRepository repository : this.repositories) {\n\t\t\tresult.include(repository);\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["build", "a", "configuration", "metadata", "repository", "with", "the", "current", "state", "of", "this", "builder"], "project": "spring-boot"}
{"id": 673, "code": "\tpublic Deprecation getDeprecation() {\n\t\treturn this.deprecation;\n\t}", "summary_tokens": ["the", "deprecation", "for", "this", "property", "if", "any"], "project": "spring-boot"}
{"id": 1281, "code": "\tpublic static Class<? extends DataSource> findType(ClassLoader classLoader) {\n\t\tMappedDataSourceProperties<?> mappings = MappedDataSourceProperties.forType(classLoader, null);\n\t\treturn (mappings != null) ? mappings.getDataSourceInstanceType() : null;\n\t}", "summary_tokens": ["find", "the", "data", "source", "type", "preferred", "for", "the", "given", "classloader"], "project": "spring-boot"}
{"id": 63, "code": "\tpublic String getPath() {\n\t\treturn this.path;\n\t}", "summary_tokens": ["returns", "the", "path", "to", "which", "endpoints", "should", "be", "mapped"], "project": "spring-boot"}
{"id": 1323, "code": "\tpublic void setResourceFactory(ReactorResourceFactory resourceFactory) {\n\t\tthis.resourceFactory = resourceFactory;\n\t}", "summary_tokens": ["set", "the", "reactor", "resource", "factory", "to", "get", "the", "shared", "resources", "from"], "project": "spring-boot"}
{"id": 722, "code": "\tpublic String toString(int indentSpaces) throws JSONException {\n\t\tJSONStringer stringer = new JSONStringer(indentSpaces);\n\t\twriteTo(stringer);\n\t\treturn stringer.toString();\n\t}", "summary_tokens": ["encodes", "this", "array", "as", "a", "human", "readable", "json", "string", "for", "debugging", "such", "as", "pre", "0", "0", "pre", "indent", "spaces", "the", "number", "of", "spaces", "to", "indent", "for", "each", "level", "of", "nesting"], "project": "spring-boot"}
{"id": 731, "code": "\tpublic Object opt(String name) {\n\t\treturn this.nameValuePairs.get(name);\n\t}", "summary_tokens": ["returns", "the", "value", "mapped", "by", "name", "or", "null", "if", "no", "such", "mapping", "exists"], "project": "spring-boot"}
{"id": 307, "code": "\tString getPackaging() {\n\t\treturn this.packaging;\n\t}", "summary_tokens": ["the", "packaging", "type", "or", "null", "if", "it", "should", "not", "be", "customized"], "project": "spring-boot"}
{"id": 397, "code": "\tpublic void writeTo(WritableByteChannel channel) throws IOException {\n\t\tAssert.notNull(channel, \"Channel must not be null\");\n\t\twhile (this.data.hasRemaining()) {\n\t\t\tchannel.write(this.data);\n\t\t}\n\t}", "summary_tokens": ["write", "the", "content", "of", "this", "payload", "to", "the", "given", "target", "channel"], "project": "spring-boot"}
{"id": 315, "code": "\tURI generateUrl(InitializrServiceMetadata metadata) {\n\t\ttry {\n\t\t\tURIBuilder builder = new URIBuilder(this.serviceUrl);\n\t\t\tStringBuilder sb = new StringBuilder();\n\t\t\tif (builder.getPath() != null) {\n\t\t\t\tsb.append(builder.getPath());\n\t\t\t}\n\n\t\t\tProjectType projectType = determineProjectType(metadata);\n\t\t\tthis.type = projectType.getId();\n\t\t\tsb.append(projectType.getAction());\n\t\t\tbuilder.setPath(sb.toString());\n\n\t\t\tif (!this.dependencies.isEmpty()) {\n\t\t\t\tbuilder.setParameter(\"dependencies\", StringUtils.collectionToCommaDelimitedString(this.dependencies));\n\t\t\t}\n\n\t\t\tif (this.groupId != null) {\n\t\t\t\tbuilder.setParameter(\"groupId\", this.groupId);\n\t\t\t}\n\t\t\tString resolvedArtifactId = resolveArtifactId();\n\t\t\tif (resolvedArtifactId != null) {\n\t\t\t\tbuilder.setParameter(\"artifactId\", resolvedArtifactId);\n\t\t\t}\n\t\t\tif (this.version != null) {\n\t\t\t\tbuilder.setParameter(\"version\", this.version);\n\t\t\t}\n\t\t\tif (this.name != null) {\n\t\t\t\tbuilder.setParameter(\"name\", this.name);\n\t\t\t}\n\t\t\tif (this.description != null) {\n\t\t\t\tbuilder.setParameter(\"description\", this.description);\n\t\t\t}\n\t\t\tif (this.packageName != null) {\n\t\t\t\tbuilder.setParameter(\"packageName\", this.packageName);\n\t\t\t}\n\t\t\tif (this.type != null) {\n\t\t\t\tbuilder.setParameter(\"type\", projectType.getId());\n\t\t\t}\n\t\t\tif (this.packaging != null) {\n\t\t\t\tbuilder.setParameter(\"packaging\", this.packaging);\n\t\t\t}\n\t\t\tif (this.javaVersion != null) {\n\t\t\t\tbuilder.setParameter(\"javaVersion\", this.javaVersion);\n\t\t\t}\n\t\t\tif (this.language != null) {\n\t\t\t\tbuilder.setParameter(\"language\", this.language);\n\t\t\t}\n\t\t\tif (this.bootVersion != null) {\n\t\t\t\tbuilder.setParameter(\"bootVersion\", this.bootVersion);\n\t\t\t}\n\n\t\t\treturn builder.build();\n\t\t}\n\t\tcatch (URISyntaxException ex) {\n\t\t\tthrow new ReportableException(\"Invalid service URL (\" + ex.getMessage() + \")\");\n\t\t}\n\t}", "summary_tokens": ["generates", "the", "uri", "to", "use", "to", "generate", "a", "project", "represented", "by", "this", "request"], "project": "spring-boot"}
{"id": 814, "code": "\tpublic void setAdditional(Map<String, Object> additionalProperties) {\n\t\tthis.additionalProperties = additionalProperties;\n\t}", "summary_tokens": ["sets", "the", "additional", "properties", "that", "will", "be", "included"], "project": "spring-boot"}
{"id": 1310, "code": "\tpublic static ExtendedWhitespaceThrowablePatternConverter newInstance(Configuration configuration,\n\t\t\tString[] options) {\n\t\treturn new ExtendedWhitespaceThrowablePatternConverter(configuration, options);\n\t}", "summary_tokens": ["creates", "a", "new", "instance", "of", "the", "class"], "project": "spring-boot"}
{"id": 75, "code": "\tpublic WebEndpointHttpMethod getHttpMethod() {\n\t\treturn this.httpMethod;\n\t}", "summary_tokens": ["returns", "the", "http", "method", "for", "the", "operation"], "project": "spring-boot"}
{"id": 1137, "code": "\tpublic String getPropertyName() {\n\t\treturn this.propertyName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "property"], "project": "spring-boot"}
{"id": 1249, "code": "\tpublic Set<String> getConfiguredNames() {\n\t\treturn this.configuredNames;\n\t}", "summary_tokens": ["return", "the", "names", "of", "the", "properties", "that", "have", "been", "configured"], "project": "spring-boot"}
{"id": 1428, "code": "\tpublic void setUriEncoding(Charset uriEncoding) {\n\t\tthis.uriEncoding = uriEncoding;\n\t}", "summary_tokens": ["set", "the", "character", "encoding", "to", "use", "for", "url", "decoding"], "project": "spring-boot"}
{"id": 846, "code": "\tpublic String getNetwork() {\n\t\treturn this.network;\n\t}", "summary_tokens": ["returns", "the", "network", "the", "build", "container", "will", "connect", "to"], "project": "spring-boot"}
{"id": 750, "code": "\tpublic static String numberToString(Number number) throws JSONException {\n\t\tif (number == null) {\n\t\t\tthrow new JSONException(\"Number must be non-null\");\n\t\t}\n\n\t\tdouble doubleValue = number.doubleValue();\n\t\tJSON.checkDouble(doubleValue);\n\n\t\t\n\t\tif (number.equals(NEGATIVE_ZERO)) {\n\t\t\treturn \"-0\";\n\t\t}\n\n\t\tlong longValue = number.longValue();\n\t\tif (doubleValue == longValue) {\n\t\t\treturn Long.toString(longValue);\n\t\t}\n\n\t\treturn number.toString();\n\t}", "summary_tokens": ["encodes", "the", "number", "as", "a", "json", "string"], "project": "spring-boot"}
{"id": 1436, "code": "\tpublic Collection<UndertowBuilderCustomizer> getBuilderCustomizers() {\n\t\treturn this.delegate.getBuilderCustomizers();\n\t}", "summary_tokens": ["returns", "a", "mutable", "collection", "of", "the", "undertow", "builder", "customizer", "s", "that", "will", "be", "applied", "to", "the", "undertow", "io"], "project": "spring-boot"}
{"id": 710, "code": "\tpublic int getInt(int index) throws JSONException {\n\t\tObject object = get(index);\n\t\tInteger result = JSON.toInteger(object);\n\t\tif (result == null) {\n\t\t\tthrow JSON.typeMismatch(index, object, \"int\");\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index", "if", "it", "exists", "and", "is", "an", "int", "or", "can", "be", "coerced", "to", "an", "int"], "project": "spring-boot"}
{"id": 1422, "code": "\tpublic void setTomcatProtocolHandlerCustomizers(\n\t\t\tCollection<? extends TomcatProtocolHandlerCustomizer<?>> tomcatProtocolHandlerCustomizers) {\n\t\tAssert.notNull(tomcatProtocolHandlerCustomizers, \"TomcatProtocolHandlerCustomizers must not be null\");\n\t\tthis.tomcatProtocolHandlerCustomizers = new LinkedHashSet<>(tomcatProtocolHandlerCustomizers);\n\t}", "summary_tokens": ["set", "tomcat", "protocol", "handler", "customizer", "s", "that", "should", "be", "applied", "to", "the", "tomcat", "connector"], "project": "spring-boot"}
{"id": 532, "code": "\tstatic BuildpackCoordinates of(String id, String version) {\n\t\treturn new BuildpackCoordinates(id, version);\n\t}", "summary_tokens": ["create", "buildpack", "coordinates", "from", "an", "id", "and", "version"], "project": "spring-boot"}
{"id": 1512, "code": "\tprotected final String getOrDeduceName(Object value) {\n\t\treturn (this.name != null) ? this.name : Conventions.getVariableName(value);\n\t}", "summary_tokens": ["deduces", "the", "name", "for", "this", "registration"], "project": "spring-boot"}
{"id": 273, "code": "\tprotected boolean isBindingErrorsEnabled(ServerRequest request) {\n\t\treturn getBooleanParameter(request, \"errors\");\n\t}", "summary_tokens": ["check", "whether", "the", "errors", "attribute", "has", "been", "set", "on", "the", "given", "request"], "project": "spring-boot"}
{"id": 1015, "code": "\tstatic ApplicationContextFactory of(Supplier<ConfigurableApplicationContext> supplier) {\n\t\treturn (webApplicationType) -> supplier.get();\n\t}", "summary_tokens": ["creates", "an", "application", "context", "factory", "that", "will", "create", "contexts", "by", "calling", "the", "given", "supplier"], "project": "spring-boot"}
{"id": 607, "code": "\tpublic int getStatusCode() {\n\t\treturn this.statusCode;\n\t}", "summary_tokens": ["return", "the", "container", "exit", "status", "code"], "project": "spring-boot"}
{"id": 716, "code": "\tpublic JSONArray getJSONArray(int index) throws JSONException {\n\t\tObject object = get(index);\n\t\tif (object instanceof JSONArray) {\n\t\t\treturn (JSONArray) object;\n\t\t}\n\t\telse {\n\t\t\tthrow JSON.typeMismatch(index, object, \"JSONArray\");\n\t\t}\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index", "if", "it", "exists", "and", "is", "a", "jsonarray"], "project": "spring-boot"}
{"id": 1242, "code": "\tstatic ConfigurationPropertySource from(PropertySource<?> source) {\n\t\tif (source instanceof ConfigurationPropertySourcesPropertySource) {\n\t\t\treturn null;\n\t\t}\n\t\treturn SpringConfigurationPropertySource.from(source);\n\t}", "summary_tokens": ["return", "a", "single", "new", "configuration", "property", "source", "adapted", "from", "the", "given", "spring", "property", "source", "or", "null", "if", "the", "source", "cannot", "be", "adapted"], "project": "spring-boot"}
{"id": 1577, "code": "\tpublic String getClassName() {\n\t\treturn this.className;\n\t}", "summary_tokens": ["return", "the", "class", "name", "of", "the", "servlet", "to", "use", "for", "jsps"], "project": "spring-boot"}
{"id": 90, "code": "\tdefault HealthEndpointGroup get(AdditionalHealthEndpointPath path) {\n\t\tAssert.notNull(path, \"Path must not be null\");\n\t\tfor (String name : getNames()) {\n\t\t\tHealthEndpointGroup group = get(name);\n\t\t\tif (path.equals(group.getAdditionalPath())) {\n\t\t\t\treturn group;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "group", "with", "the", "specified", "additional", "path", "or", "null", "if", "no", "group", "with", "that", "path", "is", "found"], "project": "spring-boot"}
{"id": 336, "code": "\tpublic DependencyCustomizer ifAnyMissingClasses(String... classNames) {\n\t\treturn new DependencyCustomizer(this) {\n\t\t\t@Override\n\t\t\tprotected boolean canAdd() {\n\t\t\t\tfor (String className : classNames) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tClass.forName(className, false, DependencyCustomizer.this.loader);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\t\treturn true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn false;\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["create", "a", "nested", "dependency", "customizer", "that", "only", "applies", "if", "any", "of", "the", "specified", "class", "names", "are", "not", "on", "the", "class", "path"], "project": "spring-boot"}
{"id": 384, "code": "\tpublic long getLastModified() {\n\t\treturn this.lastModified;\n\t}", "summary_tokens": ["return", "the", "time", "that", "the", "file", "was", "last", "modified"], "project": "spring-boot"}
{"id": 297, "code": "\tString getServiceUrl() {\n\t\treturn this.serviceUrl;\n\t}", "summary_tokens": ["the", "url", "of", "the", "service", "to", "use"], "project": "spring-boot"}
{"id": 14, "code": "\tpublic final boolean match(EndpointId endpointId) {\n\t\treturn isIncluded(endpointId) && !isExcluded(endpointId);\n\t}", "summary_tokens": ["return", "true", "if", "the", "filter", "matches"], "project": "spring-boot"}
{"id": 1583, "code": "\tpublic void setCompiler(Compiler compiler) {\n\t\tthis.compiler = compiler;\n\t}", "summary_tokens": ["set", "the", "mustache", "compiler", "to", "be", "used", "by", "this", "view"], "project": "spring-boot"}
{"id": 1464, "code": "\tpublic String[] getMimeTypes() {\n\t\treturn this.mimeTypes;\n\t}", "summary_tokens": ["return", "the", "mime", "types", "that", "should", "be", "compressed"], "project": "spring-boot"}
{"id": 1306, "code": "\tpublic LoggerConfiguration getLoggerConfiguration(String loggerName) {\n\t\tthrow new UnsupportedOperationException(\"Unable to get logger configuration\");\n\t}", "summary_tokens": ["returns", "the", "current", "configuration", "for", "a", "logging", "system", "s", "logger"], "project": "spring-boot"}
{"id": 988, "code": "\tpublic Map<String, String> getEnv() {\n\t\treturn this.env;\n\t}", "summary_tokens": ["environment", "properties", "that", "should", "be", "passed", "to", "the", "builder"], "project": "spring-boot"}
{"id": 94, "code": "\tdefault Stream<NamedContributor<C>> stream() {\n\t\treturn StreamSupport.stream(spliterator(), false);\n\t}", "summary_tokens": ["return", "a", "stream", "of", "the", "named", "contributor", "named", "contributors"], "project": "spring-boot"}
{"id": 1423, "code": "\tpublic void addProtocolHandlerCustomizers(TomcatProtocolHandlerCustomizer<?>... tomcatProtocolHandlerCustomizers) {\n\t\tAssert.notNull(tomcatProtocolHandlerCustomizers, \"TomcatProtocolHandlerCustomizers must not be null\");\n\t\tthis.tomcatProtocolHandlerCustomizers.addAll(Arrays.asList(tomcatProtocolHandlerCustomizers));\n\t}", "summary_tokens": ["add", "tomcat", "protocol", "handler", "customizer", "s", "that", "should", "be", "added", "to", "the", "tomcat", "connector"], "project": "spring-boot"}
{"id": 1181, "code": "\tprotected final Context getContext() {\n\t\treturn this.context;\n\t}", "summary_tokens": ["return", "the", "context", "being", "used", "by", "this", "binder"], "project": "spring-boot"}
{"id": 1504, "code": "\tpublic void setMatchAfter(boolean matchAfter) {\n\t\tthis.matchAfter = matchAfter;\n\t}", "summary_tokens": ["set", "if", "the", "filter", "mappings", "should", "be", "matched", "after", "any", "declared", "filter", "mappings", "of", "the", "servlet", "context"], "project": "spring-boot"}
{"id": 1498, "code": "\tpublic Collection<String> getServletNames() {\n\t\treturn this.servletNames;\n\t}", "summary_tokens": ["return", "a", "mutable", "collection", "of", "servlet", "names", "that", "the", "filter", "will", "be", "registered", "against"], "project": "spring-boot"}
{"id": 1362, "code": "\tpublic TaskSchedulerBuilder threadNamePrefix(String threadNamePrefix) {\n\t\treturn new TaskSchedulerBuilder(this.poolSize, this.awaitTermination, this.awaitTerminationPeriod,\n\t\t\t\tthreadNamePrefix, this.customizers);\n\t}", "summary_tokens": ["set", "the", "prefix", "to", "use", "for", "the", "names", "of", "newly", "created", "threads"], "project": "spring-boot"}
{"id": 1007, "code": "\tpublic static DockerImageName couchbase() {\n\t\treturn DockerImageName.parse(\"couchbase/server\").withTag(COUCHBASE_VERSION);\n\t}", "summary_tokens": ["return", "a", "docker", "image", "name", "suitable", "for", "running", "couchbase"], "project": "spring-boot"}
{"id": 387, "code": "\tpublic void addFile(String sourceDirectory, String name, ClassLoaderFile file) {\n\t\tAssert.notNull(sourceDirectory, \"SourceDirectory must not be null\");\n\t\tAssert.notNull(name, \"Name must not be null\");\n\t\tAssert.notNull(file, \"File must not be null\");\n\t\tremoveAll(name);\n\t\tgetOrCreateSourceDirectory(sourceDirectory).add(name, file);\n\t}", "summary_tokens": ["add", "a", "single", "class", "loader", "file", "to", "the", "collection"], "project": "spring-boot"}
{"id": 644, "code": "\tpublic static VolumeName of(String value) {\n\t\tAssert.notNull(value, \"Value must not be null\");\n\t\treturn new VolumeName(value);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "volume", "name", "with", "a", "specific", "value"], "project": "spring-boot"}
{"id": 712, "code": "\tpublic long getLong(int index) throws JSONException {\n\t\tObject object = get(index);\n\t\tLong result = JSON.toLong(object);\n\t\tif (result == null) {\n\t\t\tthrow JSON.typeMismatch(index, object, \"long\");\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index", "if", "it", "exists", "and", "is", "a", "long", "or", "can", "be", "coerced", "to", "a", "long"], "project": "spring-boot"}
{"id": 978, "code": "\tpublic String getCertPath() {\n\t\treturn this.certPath;\n\t}", "summary_tokens": ["the", "path", "to", "tls", "certificate", "and", "key", "files", "required", "for", "tls", "communication", "with", "the", "docker", "daemon"], "project": "spring-boot"}
{"id": 1050, "code": "\tpublic SpringApplication application() {\n\t\treturn this.application;\n\t}", "summary_tokens": ["accessor", "for", "the", "current", "application"], "project": "spring-boot"}
{"id": 309, "code": "\tString getFormat() {\n\t\treturn this.format;\n\t}", "summary_tokens": ["the", "project", "format", "to", "use"], "project": "spring-boot"}
{"id": 360, "code": "\tpublic void addSourceDirectory(File directory) {\n\t\tAssert.notNull(directory, \"Directory must not be null\");\n\t\tAssert.isTrue(!directory.isFile(), () -> \"Directory '\" + directory + \"' must not be a file\");\n\t\tsynchronized (this.monitor) {\n\t\t\tcheckNotStarted();\n\t\t\tthis.directories.put(directory, null);\n\t\t}\n\t}", "summary_tokens": ["add", "a", "source", "directory", "to", "monitor"], "project": "spring-boot"}
{"id": 279, "code": "\tdefault String getServletUrlMapping() {\n\t\tif (getPath().equals(\"\") || getPath().equals(\"/\")) {\n\t\t\treturn \"/\";\n\t\t}\n\t\tif (getPath().contains(\"*\")) {\n\t\t\treturn getPath();\n\t\t}\n\t\tif (getPath().endsWith(\"/\")) {\n\t\t\treturn getPath() + \"*\";\n\t\t}\n\t\treturn getPath() + \"/*\";\n\t}", "summary_tokens": ["return", "a", "url", "mapping", "pattern", "that", "can", "be", "used", "with", "a", "servlet", "registration", "bean", "to", "map", "the", "dispatcher", "servlet"], "project": "spring-boot"}
{"id": 1410, "code": "\tpublic void addRouteProviders(NettyRouteProvider... routeProviders) {\n\t\tAssert.notNull(routeProviders, \"NettyRouteProvider must not be null\");\n\t\tthis.routeProviders.addAll(Arrays.asList(routeProviders));\n\t}", "summary_tokens": ["add", "netty", "route", "provider", "s", "that", "should", "be", "applied", "in", "order", "before", "the", "handler", "for", "the", "spring", "application"], "project": "spring-boot"}
{"id": 1580, "code": "\tpublic Set<Session.SessionTrackingMode> getTrackingModes() {\n\t\treturn this.trackingModes;\n\t}", "summary_tokens": ["return", "the", "session", "tracking", "mode", "session", "tracking", "modes"], "project": "spring-boot"}
{"id": 1377, "code": "\tpublic RestTemplateBuilder messageConverters(Collection<? extends HttpMessageConverter<?>> messageConverters) {\n\t\tAssert.notNull(messageConverters, \"MessageConverters must not be null\");\n\t\treturn new RestTemplateBuilder(this.requestFactoryCustomizer, this.detectRequestFactory, this.rootUri,\n\t\t\t\tcopiedSetOf(messageConverters), this.interceptors, this.requestFactory, this.uriTemplateHandler,\n\t\t\t\tthis.errorHandler, this.basicAuthentication, this.defaultHeaders, this.customizers,\n\t\t\t\tthis.requestCustomizers);\n\t}", "summary_tokens": ["set", "the", "http", "message", "converter", "http", "message", "converters", "that", "should", "be", "used", "with", "the", "rest", "template"], "project": "spring-boot"}
{"id": 1379, "code": "\tpublic RestTemplateBuilder defaultMessageConverters() {\n\t\treturn new RestTemplateBuilder(this.requestFactoryCustomizer, this.detectRequestFactory, this.rootUri,\n\t\t\t\tcopiedSetOf(new RestTemplate().getMessageConverters()), this.interceptors, this.requestFactory,\n\t\t\t\tthis.uriTemplateHandler, this.errorHandler, this.basicAuthentication, this.defaultHeaders,\n\t\t\t\tthis.customizers, this.requestCustomizers);\n\t}", "summary_tokens": ["set", "the", "http", "message", "converter", "http", "message", "converters", "that", "should", "be", "used", "with", "the", "rest", "template", "to", "the", "default", "set"], "project": "spring-boot"}
{"id": 310, "code": "\tboolean isDetectType() {\n\t\treturn this.detectType;\n\t}", "summary_tokens": ["whether", "the", "type", "should", "be", "detected", "based", "on", "the", "build", "and", "format", "value"], "project": "spring-boot"}
{"id": 1235, "code": "\tpublic static ConfigurationPropertyName ofIfValid(CharSequence name) {\n\t\treturn of(name, true);\n\t}", "summary_tokens": ["return", "a", "configuration", "property", "name", "for", "the", "specified", "string", "or", "null", "if", "the", "name", "is", "not", "valid"], "project": "spring-boot"}
{"id": 264, "code": "\tdefault RequestMappingHandlerMapping getRequestMappingHandlerMapping() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "custom", "request", "mapping", "handler", "mapping", "that", "should", "be", "used", "and", "processed", "by", "the", "web", "flux", "configuration"], "project": "spring-boot"}
{"id": 1073, "code": "\tpublic SpringApplicationBuilder resourceLoader(ResourceLoader resourceLoader) {\n\t\tthis.application.setResourceLoader(resourceLoader);\n\t\treturn this;\n\t}", "summary_tokens": ["resource", "loader", "for", "the", "application", "context"], "project": "spring-boot"}
{"id": 1024, "code": "\tpublic int getExitCode() {\n\t\treturn this.exitCode;\n\t}", "summary_tokens": ["return", "the", "exit", "code", "that", "will", "be", "used", "to", "exit", "the", "jvm"], "project": "spring-boot"}
{"id": 1237, "code": "\tdefault ConfigurationPropertyState containsDescendantOf(ConfigurationPropertyName name) {\n\t\treturn ConfigurationPropertyState.UNKNOWN;\n\t}", "summary_tokens": ["returns", "if", "the", "source", "contains", "any", "descendants", "of", "the", "specified", "name"], "project": "spring-boot"}
{"id": 433, "code": "\tstatic <T extends ApplicationContextAssertProvider<C>, C extends ApplicationContext> T get(Class<T> type,\n\t\t\tClass<? extends C> contextType, Supplier<? extends C> contextSupplier) {\n\t\tAssert.notNull(type, \"Type must not be null\");\n\t\tAssert.isTrue(type.isInterface(), \"Type must be an interface\");\n\t\tAssert.notNull(contextType, \"ContextType must not be null\");\n\t\tAssert.isTrue(contextType.isInterface(), \"ContextType must be an interface\");\n\t\tClass<?>[] interfaces = { type, contextType };\n\t\treturn (T) Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), interfaces,\n\t\t\t\tnew AssertProviderApplicationContextInvocationHandler(contextType, contextSupplier));\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "new", "application", "context", "assert", "provider", "instance"], "project": "spring-boot"}
{"id": 1102, "code": "\tstatic ConfigDataEnvironmentContributor of(List<ConfigDataEnvironmentContributor> contributors) {\n\t\tMap<ImportPhase, List<ConfigDataEnvironmentContributor>> children = new LinkedHashMap<>();\n\t\tchildren.put(ImportPhase.BEFORE_PROFILE_ACTIVATION, Collections.unmodifiableList(contributors));\n\t\treturn new ConfigDataEnvironmentContributor(Kind.ROOT, null, null, false, null, null, null, null, children);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "kind", "root", "root", "contributor"], "project": "spring-boot"}
{"id": 1321, "code": "\tpublic RSocketServer getServer() {\n\t\treturn getSource();\n\t}", "summary_tokens": ["access", "the", "rsocket", "server"], "project": "spring-boot"}
{"id": 489, "code": "\tpublic BuildRequest withCreator(Creator creator) {\n\t\tAssert.notNull(creator, \"Creator must not be null\");\n\t\treturn new BuildRequest(this.name, this.applicationContent, this.builder, this.runImage, creator, this.env,\n\t\t\t\tthis.cleanCache, this.verboseLogging, this.pullPolicy, this.publish, this.buildpacks, this.bindings,\n\t\t\t\tthis.network, this.tags, this.buildCache, this.launchCache);\n\t}", "summary_tokens": ["return", "a", "new", "build", "request", "with", "an", "updated", "creator"], "project": "spring-boot"}
{"id": 743, "code": "\tpublic JSONArray optJSONArray(String name) {\n\t\tObject object = opt(name);\n\t\treturn object instanceof JSONArray ? (JSONArray) object : null;\n\t}", "summary_tokens": ["returns", "the", "value", "mapped", "by", "name", "if", "it", "exists", "and", "is", "a", "jsonarray"], "project": "spring-boot"}
{"id": 97, "code": "\tdefault Status getAggregateStatus(Status... statuses) {\n\t\treturn getAggregateStatus(new LinkedHashSet<>(Arrays.asList(statuses)));\n\t}", "summary_tokens": ["return", "the", "aggregate", "status", "for", "the", "given", "set", "of", "statuses"], "project": "spring-boot"}
{"id": 856, "code": "\tpublic CopySpec getBootInf() {\n\t\tCopySpec child = getProject().copySpec();\n\t\tthis.bootInfSpec.with(child);\n\t\treturn child;\n\t}", "summary_tokens": ["returns", "a", "copy", "spec", "that", "can", "be", "used", "to", "add", "content", "to", "the", "boot", "inf", "directory", "of", "the", "jar"], "project": "spring-boot"}
{"id": 1465, "code": "\tpublic DataSize getMinResponseSize() {\n\t\treturn this.minResponseSize;\n\t}", "summary_tokens": ["return", "the", "minimum", "content", "length", "value", "that", "is", "required", "for", "compression", "to", "be", "performed"], "project": "spring-boot"}
{"id": 1013, "code": "\tpublic static DockerImageName registry() {\n\t\treturn DockerImageName.parse(\"registry\").withTag(REGISTRY_VERSION);\n\t}", "summary_tokens": ["return", "a", "docker", "image", "name", "suitable", "for", "running", "a", "docker", "registry"], "project": "spring-boot"}
{"id": 400, "code": "\tpublic void logIncoming() {\n\t\tlog(\"< \");\n\t}", "summary_tokens": ["log", "incoming", "payload", "information", "at", "trace", "level", "to", "aid", "diagnostics"], "project": "spring-boot"}
{"id": 358, "code": "\tpublic void addListener(FileChangeListener fileChangeListener) {\n\t\tAssert.notNull(fileChangeListener, \"FileChangeListener must not be null\");\n\t\tsynchronized (this.monitor) {\n\t\t\tcheckNotStarted();\n\t\t\tthis.listeners.add(fileChangeListener);\n\t\t}\n\t}", "summary_tokens": ["add", "listener", "for", "file", "change", "events"], "project": "spring-boot"}
{"id": 193, "code": "\tpublic final Set<Class<?>> scan(Class<? extends Annotation>... annotationTypes) throws ClassNotFoundException {\n\t\tList<String> packages = getPackages();\n\t\tif (packages.isEmpty()) {\n\t\t\treturn Collections.emptySet();\n\t\t}\n\t\tClassPathScanningCandidateComponentProvider scanner = createClassPathScanningCandidateComponentProvider(\n\t\t\t\tthis.context);\n\t\tfor (Class<? extends Annotation> annotationType : annotationTypes) {\n\t\t\tscanner.addIncludeFilter(new AnnotationTypeFilter(annotationType));\n\t\t}\n\t\tSet<Class<?>> entitySet = new HashSet<>();\n\t\tfor (String basePackage : packages) {\n\t\t\tif (StringUtils.hasText(basePackage)) {\n\t\t\t\tfor (BeanDefinition candidate : scanner.findCandidateComponents(basePackage)) {\n\t\t\t\t\tentitySet.add(ClassUtils.forName(candidate.getBeanClassName(), this.context.getClassLoader()));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn entitySet;\n\t}", "summary_tokens": ["scan", "for", "entities", "with", "the", "specified", "annotations"], "project": "spring-boot"}
{"id": 859, "code": "\tprotected boolean isLibrary(FileCopyDetails details) {\n\t\tString path = details.getRelativePath().getPathString();\n\t\treturn path.startsWith(LIB_DIRECTORY);\n\t}", "summary_tokens": ["return", "if", "the", "file", "copy", "details", "are", "for", "a", "library"], "project": "spring-boot"}
{"id": 59, "code": "\tpublic Method getMethod() {\n\t\treturn this.method;\n\t}", "summary_tokens": ["return", "the", "source", "java", "method"], "project": "spring-boot"}
{"id": 934, "code": "\tstatic LibraryCoordinates of(String groupId, String artifactId, String version) {\n\t\treturn new DefaultLibraryCoordinates(groupId, artifactId, version);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "library", "coordinates", "with", "the", "specified", "values"], "project": "spring-boot"}
{"id": 306, "code": "\tString getType() {\n\t\treturn this.type;\n\t}", "summary_tokens": ["the", "type", "of", "project", "to", "generate"], "project": "spring-boot"}
{"id": 413, "code": "\tpublic <E> E persist(E entity) {\n\t\tgetEntityManager().persist(entity);\n\t\treturn entity;\n\t}", "summary_tokens": ["make", "an", "instance", "managed", "and", "persistent"], "project": "spring-boot"}
{"id": 929, "code": "\tpublic LibraryScope getScope() {\n\t\treturn this.scope;\n\t}", "summary_tokens": ["return", "the", "scope", "of", "the", "library"], "project": "spring-boot"}
{"id": 669, "code": "\tpublic String getDescription() {\n\t\treturn this.description;\n\t}", "summary_tokens": ["a", "description", "of", "the", "property", "if", "any"], "project": "spring-boot"}
{"id": 631, "code": "\tpublic ImageReference inTaggedOrDigestForm() {\n\t\tif (this.digest != null) {\n\t\t\treturn this;\n\t\t}\n\t\treturn inTaggedForm();\n\t}", "summary_tokens": ["return", "an", "image", "reference", "containing", "either", "a", "tag", "or", "a", "digest"], "project": "spring-boot"}
{"id": 656, "code": "\tprotected static <T extends MappedObject, C> T of(C content, ContentReader<C> reader, Function<JsonNode, T> factory)\n\t\t\tthrows IOException {\n\t\tObjectMapper objectMapper = SharedObjectMapper.get();\n\t\tJsonNode node = reader.read(objectMapper, content);\n\t\treturn factory.apply(node);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "new", "mapped", "object", "instance"], "project": "spring-boot"}
{"id": 580, "code": "\tpublic ProgressDetail getProgressDetail() {\n\t\treturn this.progressDetail;\n\t}", "summary_tokens": ["return", "progress", "details", "if", "available"], "project": "spring-boot"}
{"id": 70, "code": "\tpublic MimeType getContentType() {\n\t\treturn this.contentType;\n\t}", "summary_tokens": ["returns", "the", "content", "type", "of", "the", "response"], "project": "spring-boot"}
{"id": 657, "code": "\tpublic static DomainSocket get(String path) throws IOException {\n\t\tif (Platform.isMac() || isBsdPlatform()) {\n\t\t\treturn new BsdDomainSocket(path);\n\t\t}\n\t\treturn new LinuxDomainSocket(path);\n\t}", "summary_tokens": ["return", "a", "new", "domain", "socket", "for", "the", "given", "path"], "project": "spring-boot"}
{"id": 1069, "code": "\tpublic SpringApplicationBuilder profiles(String... profiles) {\n\t\tthis.additionalProfiles.addAll(Arrays.asList(profiles));\n\t\tthis.application.setAdditionalProfiles(StringUtils.toStringArray(this.additionalProfiles));\n\t\treturn this;\n\t}", "summary_tokens": ["add", "to", "the", "active", "spring", "profiles", "for", "this", "app", "and", "its", "parent", "and", "children"], "project": "spring-boot"}
{"id": 1131, "code": "\tpublic ConfigDataResource getResource() {\n\t\treturn this.resource;\n\t}", "summary_tokens": ["return", "the", "resource", "that", "could", "not", "be", "found"], "project": "spring-boot"}
{"id": 1359, "code": "\tpublic TaskSchedulerBuilder poolSize(int poolSize) {\n\t\treturn new TaskSchedulerBuilder(poolSize, this.awaitTermination, this.awaitTerminationPeriod,\n\t\t\t\tthis.threadNamePrefix, this.customizers);\n\t}", "summary_tokens": ["set", "the", "maximum", "allowed", "number", "of", "threads"], "project": "spring-boot"}
{"id": 234, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "value", "of", "this", "object"], "project": "spring-boot"}
{"id": 1053, "code": "\tpublic SpringApplicationBuilder child(Class<?>... sources) {\n\t\tSpringApplicationBuilder child = new SpringApplicationBuilder();\n\t\tchild.sources(sources);\n\n\t\t\n\t\tchild.properties(this.defaultProperties).environment(this.environment)\n\t\t\t\t.additionalProfiles(this.additionalProfiles);\n\t\tchild.parent = this;\n\n\t\t\n\t\t\n\t\t\n\t\tweb(WebApplicationType.NONE);\n\n\t\t\n\t\tbannerMode(Banner.Mode.OFF);\n\n\t\t\n\t\tthis.application.addPrimarySources(this.sources);\n\n\t\treturn child;\n\t}", "summary_tokens": ["create", "a", "child", "application", "with", "the", "provided", "sources"], "project": "spring-boot"}
{"id": 863, "code": "\tpublic void providedClasspath(Object... classpath) {\n\t\tFileCollection existingClasspath = this.providedClasspath;\n\t\tthis.providedClasspath = getProject()\n\t\t\t\t.files((existingClasspath != null) ? existingClasspath : Collections.emptyList(), classpath);\n\t}", "summary_tokens": ["adds", "files", "to", "the", "provided", "classpath", "to", "include", "in", "the", "web", "inf", "lib", "provided", "directory", "of", "the", "war"], "project": "spring-boot"}
{"id": 1206, "code": "\tpublic Bindable<T> withSuppliedValue(Supplier<T> suppliedValue) {\n\t\treturn new Bindable<>(this.type, this.boxedType, suppliedValue, this.annotations, this.bindRestrictions);\n\t}", "summary_tokens": ["create", "an", "updated", "bindable", "instance", "with", "a", "value", "supplier"], "project": "spring-boot"}
{"id": 353, "code": "\tpublic void triggerReload() {\n\t\tif (this.server != null) {\n\t\t\tthis.server.triggerReload();\n\t\t}\n\t}", "summary_tokens": ["trigger", "live", "reload", "if", "the", "server", "is", "up", "and", "running"], "project": "spring-boot"}
{"id": 392, "code": "\tpublic static boolean shouldEnable(Thread thread) {\n\t\tfor (StackTraceElement element : thread.getStackTrace()) {\n\t\t\tif (isSkippedStackElement(element)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["checks", "if", "a", "specific", "stack", "trace", "element", "in", "the", "current", "thread", "s", "stacktrace", "should", "cause", "devtools", "to", "be", "disabled"], "project": "spring-boot"}
{"id": 108, "code": "\tpublic void setDataSource(DataSource dataSource) {\n\t\tthis.dataSource = dataSource;\n\t\tthis.jdbcTemplate = new JdbcTemplate(dataSource);\n\t}", "summary_tokens": ["set", "the", "data", "source", "to", "use"], "project": "spring-boot"}
{"id": 962, "code": "\tpublic static String getProperty(String key, String defaultValue, String text) {\n\t\ttry {\n\t\t\tString propVal = System.getProperty(key);\n\t\t\tif (propVal == null) {\n\t\t\t\t\n\t\t\t\tpropVal = System.getenv(key);\n\t\t\t}\n\t\t\tif (propVal == null) {\n\t\t\t\t\n\t\t\t\tString name = key.replace('.', '_');\n\t\t\t\tpropVal = System.getenv(name);\n\t\t\t}\n\t\t\tif (propVal == null) {\n\t\t\t\t\n\t\t\t\tString name = key.toUpperCase(Locale.ENGLISH).replace('.', '_');\n\t\t\t\tpropVal = System.getenv(name);\n\t\t\t}\n\t\t\tif (propVal != null) {\n\t\t\t\treturn propVal;\n\t\t\t}\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tSystem.err.println(\"Could not resolve key '\" + key + \"' in '\" + text\n\t\t\t\t\t+ \"' as system property or in environment: \" + ex);\n\t\t}\n\t\treturn defaultValue;\n\t}", "summary_tokens": ["search", "the", "system", "properties", "and", "environment", "variables", "for", "a", "value", "with", "the", "provided", "key"], "project": "spring-boot"}
{"id": 1320, "code": "\tpublic static OptionsCapableConnectionFactory unwrapFrom(ConnectionFactory connectionFactory) {\n\t\tif (connectionFactory instanceof OptionsCapableConnectionFactory) {\n\t\t\treturn (OptionsCapableConnectionFactory) connectionFactory;\n\t\t}\n\t\tif (connectionFactory instanceof Wrapped) {\n\t\t\tObject unwrapped = ((Wrapped<?>) connectionFactory).unwrap();\n\t\t\tif (unwrapped instanceof ConnectionFactory) {\n\t\t\t\treturn unwrapFrom((ConnectionFactory) unwrapped);\n\t\t\t}\n\t\t}\n\t\treturn null;\n\n\t}", "summary_tokens": ["returns", "if", "possible", "an", "options", "capable", "connection", "factory", "by", "unwrapping", "the", "given", "connection", "factory", "as", "necessary"], "project": "spring-boot"}
{"id": 74, "code": "\tpublic String getMatchAllRemainingPathSegmentsVariable() {\n\t\treturn this.matchAllRemainingPathSegmentsVariable;\n\t}", "summary_tokens": ["returns", "the", "name", "of", "the", "variable", "used", "to", "catch", "all", "remaining", "path", "segments", "null"], "project": "spring-boot"}
{"id": 423, "code": "\tpublic <T> T getId(Object entity, Class<T> idType) {\n\t\tObject id = getId(entity);\n\t\tAssert.isInstanceOf(idType, id, \"ID mismatch:\");\n\t\treturn (T) id;\n\t}", "summary_tokens": ["return", "the", "id", "of", "the", "given", "entity", "cast", "to", "a", "specific", "type"], "project": "spring-boot"}
{"id": 1032, "code": "\tdefault void started(ConfigurableApplicationContext context, Duration timeTaken) {\n\t}", "summary_tokens": ["the", "context", "has", "been", "refreshed", "and", "the", "application", "has", "started", "but", "command", "line", "runner", "command", "line", "runners", "and", "application", "runner", "application", "runners", "have", "not", "been", "called"], "project": "spring-boot"}
{"id": 1540, "code": "\tpublic final void register(Class<?>... annotatedClasses) {\n\t\tAssert.notEmpty(annotatedClasses, \"At least one annotated class must be specified\");\n\t\tthis.annotatedClasses.addAll(Arrays.asList(annotatedClasses));\n\t}", "summary_tokens": ["register", "one", "or", "more", "annotated", "classes", "to", "be", "processed"], "project": "spring-boot"}
{"id": 1192, "code": "\tpublic boolean isBound() {\n\t\treturn (this.value != null);\n\t}", "summary_tokens": ["returns", "true", "if", "a", "result", "was", "bound"], "project": "spring-boot"}
{"id": 464, "code": "\tSet<Class<?>> getExtraInterfaces() {\n\t\treturn this.extraInterfaces;\n\t}", "summary_tokens": ["return", "the", "extra", "interfaces"], "project": "spring-boot"}
{"id": 576, "code": "\tpublic ContainerApi container() {\n\t\treturn this.container;\n\t}", "summary_tokens": ["return", "the", "docker", "api", "for", "container", "operations"], "project": "spring-boot"}
{"id": 209, "code": "\tvoid setMessageConverter(MessageConverter messageConverter) {\n\t\tthis.messageConverter = messageConverter;\n\t}", "summary_tokens": ["set", "the", "message", "converter", "to", "use", "or", "null", "if", "the", "out", "of", "the", "box", "converter", "should", "be", "used"], "project": "spring-boot"}
{"id": 1135, "code": "\tpublic PropertySource<?> getPropertySource() {\n\t\treturn this.propertySource;\n\t}", "summary_tokens": ["return", "the", "inactive", "property", "source", "that", "contained", "the", "property"], "project": "spring-boot"}
{"id": 143, "code": "\tprotected final T getRegistration() {\n\t\treturn this.registration;\n\t}", "summary_tokens": ["returns", "the", "registration", "that", "is", "being", "described"], "project": "spring-boot"}
{"id": 711, "code": "\tpublic int optInt(int index, int fallback) {\n\t\tObject object = opt(index);\n\t\tInteger result = JSON.toInteger(object);\n\t\treturn result != null ? result : fallback;\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index", "if", "it", "exists", "and", "is", "an", "int", "or", "can", "be", "coerced", "to", "an", "int"], "project": "spring-boot"}
{"id": 1447, "code": "\tpublic final void scan(String... basePackages) {\n\t\tAssert.notEmpty(basePackages, \"At least one base package must be specified\");\n\t\tthis.basePackages = basePackages;\n\t}", "summary_tokens": ["perform", "a", "scan", "within", "the", "specified", "base", "packages"], "project": "spring-boot"}
{"id": 277, "code": "\tdefault String getRelativePath(String path) {\n\t\tString prefix = getPrefix();\n\t\tif (!path.startsWith(\"/\")) {\n\t\t\tpath = \"/\" + path;\n\t\t}\n\t\treturn prefix + path;\n\t}", "summary_tokens": ["return", "a", "form", "of", "the", "given", "path", "that", "s", "relative", "to", "the", "dispatcher", "servlet", "path"], "project": "spring-boot"}
{"id": 666, "code": "\tpublic String getId() {\n\t\treturn this.id;\n\t}", "summary_tokens": ["the", "full", "identifier", "of", "the", "property", "in", "lowercase", "dashed", "form", "e"], "project": "spring-boot"}
{"id": 975, "code": "\tprotected final boolean equals(Artifact artifact, FilterableDependency dependency) {\n\t\tif (!dependency.getGroupId().equals(artifact.getGroupId())) {\n\t\t\treturn false;\n\t\t}\n\t\tif (!dependency.getArtifactId().equals(artifact.getArtifactId())) {\n\t\t\treturn false;\n\t\t}\n\t\treturn (dependency.getClassifier() == null\n\t\t\t\t|| artifact.getClassifier() != null && dependency.getClassifier().equals(artifact.getClassifier()));\n\t}", "summary_tokens": ["check", "if", "the", "specified", "org"], "project": "spring-boot"}
{"id": 764, "code": "\tprivate void beforeValue() throws JSONException {\n\t\tif (this.stack.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\n\t\tScope context = peek();\n\t\tif (context == Scope.EMPTY_ARRAY) { \n\t\t\treplaceTop(Scope.NONEMPTY_ARRAY);\n\t\t\tnewline();\n\t\t}\n\t\telse if (context == Scope.NONEMPTY_ARRAY) { \n\t\t\tthis.out.append(',');\n\t\t\tnewline();\n\t\t}\n\t\telse if (context == Scope.DANGLING_KEY) { \n\t\t\tthis.out.append(this.indent == null ? \":\" : \": \");\n\t\t\treplaceTop(Scope.NONEMPTY_OBJECT);\n\t\t}\n\t\telse if (context != Scope.NULL) {\n\t\t\tthrow new JSONException(\"Nesting problem\");\n\t\t}\n\t}", "summary_tokens": ["inserts", "any", "necessary", "separators", "and", "whitespace", "before", "a", "literal", "value", "inline", "array", "or", "inline", "object"], "project": "spring-boot"}
{"id": 1543, "code": "\tpublic void setBeanNameGenerator(BeanNameGenerator beanNameGenerator) {\n\t\tthis.reader.setBeanNameGenerator(beanNameGenerator);\n\t\tthis.scanner.setBeanNameGenerator(beanNameGenerator);\n\t\tgetBeanFactory().registerSingleton(AnnotationConfigUtils.CONFIGURATION_BEAN_NAME_GENERATOR, beanNameGenerator);\n\t}", "summary_tokens": ["provide", "a", "custom", "bean", "name", "generator", "for", "use", "with", "annotated", "bean", "definition", "reader", "and", "or", "class", "path", "bean", "definition", "scanner", "if", "any"], "project": "spring-boot"}
{"id": 299, "code": "\tboolean isExtract() {\n\t\treturn this.extract;\n\t}", "summary_tokens": ["whether", "the", "project", "archive", "should", "be", "extracted", "in", "the", "output", "location"], "project": "spring-boot"}
{"id": 1368, "code": "\tpublic void clearCache() {\n\t\tthis.cache.clear();\n\t}", "summary_tokens": ["clear", "the", "entire", "metadata", "reader", "cache", "removing", "all", "cached", "class", "metadata"], "project": "spring-boot"}
{"id": 699, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "provider"], "project": "spring-boot"}
{"id": 780, "code": "\tpublic void add(ItemMetadata itemMetadata) {\n\t\tadd(this.items, itemMetadata.getName(), itemMetadata, false);\n\t}", "summary_tokens": ["add", "item", "meta", "data"], "project": "spring-boot"}
{"id": 778, "code": "\tList<Element> getElementsAnnotatedOrMetaAnnotatedWith(Element element, TypeElement annotationType) {\n\t\tLinkedList<Element> stack = new LinkedList<>();\n\t\tstack.push(element);\n\t\tcollectElementsAnnotatedOrMetaAnnotatedWith(annotationType, stack);\n\t\tstack.removeFirst();\n\t\treturn Collections.unmodifiableList(stack);\n\t}", "summary_tokens": ["collect", "the", "annotations", "that", "are", "annotated", "or", "meta", "annotated", "with", "the", "specified", "type", "element", "annotation"], "project": "spring-boot"}
{"id": 971, "code": "\tprotected RunArguments resolveJvmArguments() {\n\t\tStringBuilder stringBuilder = new StringBuilder();\n\t\tif (this.systemPropertyVariables != null) {\n\t\t\tstringBuilder.append(this.systemPropertyVariables.entrySet().stream()\n\t\t\t\t\t.map((e) -> SystemPropertyFormatter.format(e.getKey(), e.getValue()))\n\t\t\t\t\t.collect(Collectors.joining(\" \")));\n\t\t}\n\t\tif (this.jvmArguments != null) {\n\t\t\tstringBuilder.append(\" \").append(this.jvmArguments);\n\t\t}\n\t\treturn new RunArguments(stringBuilder.toString());\n\t}", "summary_tokens": ["resolve", "the", "jvm", "arguments", "to", "use"], "project": "spring-boot"}
{"id": 1194, "code": "\tpublic <U> BindResult<U> map(Function<? super T, ? extends U> mapper) {\n\t\tAssert.notNull(mapper, \"Mapper must not be null\");\n\t\treturn of((this.value != null) ? mapper.apply(this.value) : null);\n\t}", "summary_tokens": ["apply", "the", "provided", "mapping", "function", "to", "the", "bound", "value", "or", "return", "an", "updated", "unbound", "result", "if", "no", "value", "has", "been", "bound"], "project": "spring-boot"}
{"id": 1266, "code": "\tpublic String getCommitId() {\n\t\treturn get(\"commit.id\");\n\t}", "summary_tokens": ["return", "the", "full", "id", "of", "the", "commit", "or", "null"], "project": "spring-boot"}
{"id": 188, "code": "\tprotected BootstrapMode getBootstrapMode() {\n\t\treturn BootstrapMode.DEFAULT;\n\t}", "summary_tokens": ["the", "bootstrap", "mode", "for", "the", "particular", "repository", "support"], "project": "spring-boot"}
{"id": 728, "code": "\tpublic boolean isNull(String name) {\n\t\tObject value = this.nameValuePairs.get(name);\n\t\treturn value == null || value == NULL;\n\t}", "summary_tokens": ["returns", "true", "if", "this", "object", "has", "no", "mapping", "for", "name", "or", "if", "it", "has", "a", "mapping", "whose", "value", "is", "null"], "project": "spring-boot"}
{"id": 117, "code": "\tpublic static Tag status(ClientHttpResponse response) {\n\t\treturn Tag.of(\"status\", getStatusMessage(response));\n\t}", "summary_tokens": ["creates", "a", "status", "tag", "derived", "from", "the", "client", "http", "response", "get", "status", "code", "status", "of", "the", "given", "response"], "project": "spring-boot"}
{"id": 1217, "code": "\tpublic Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "configuration", "property"], "project": "spring-boot"}
{"id": 1598, "code": "\tpublic WebServiceTemplateBuilder setUnmarshaller(Unmarshaller unmarshaller) {\n\t\treturn new WebServiceTemplateBuilder(this.detectHttpMessageSender, this.interceptors, this.internalCustomizers,\n\t\t\t\tthis.customizers, this.messageSenders, this.marshaller, unmarshaller, this.destinationProvider,\n\t\t\t\tthis.transformerFactoryClass, this.messageFactory);\n\t}", "summary_tokens": ["set", "the", "unmarshaller", "to", "use", "to", "deserialize", "messages"], "project": "spring-boot"}
{"id": 585, "code": "\tdefault void onFinish() {\n\t}", "summary_tokens": ["called", "when", "the", "operation", "finishes", "with", "or", "without", "error"], "project": "spring-boot"}
{"id": 1110, "code": "\tpublic static void applyTo(ConfigurableEnvironment environment, ResourceLoader resourceLoader,\n\t\t\tConfigurableBootstrapContext bootstrapContext, Collection<String> additionalProfiles,\n\t\t\tConfigDataEnvironmentUpdateListener environmentUpdateListener) {\n\t\tDeferredLogFactory logFactory = Supplier::get;\n\t\tbootstrapContext = (bootstrapContext != null) ? bootstrapContext : new DefaultBootstrapContext();\n\t\tConfigDataEnvironmentPostProcessor postProcessor = new ConfigDataEnvironmentPostProcessor(logFactory,\n\t\t\t\tbootstrapContext, environmentUpdateListener);\n\t\tpostProcessor.postProcessEnvironment(environment, resourceLoader, additionalProfiles);\n\t}", "summary_tokens": ["apply", "config", "data", "post", "processing", "to", "an", "existing", "environment"], "project": "spring-boot"}
{"id": 768, "code": "\tpublic String nextString(char quote) throws JSONException {\n\t\t\n\t\tStringBuilder builder = null;\n\n\t\t\n\t\tint start = this.pos;\n\n\t\twhile (this.pos < this.in.length()) {\n\t\t\tint c = this.in.charAt(this.pos++);\n\t\t\tif (c == quote) {\n\t\t\t\tif (builder == null) {\n\t\t\t\t\t\n\t\t\t\t\treturn new String(this.in.substring(start, this.pos - 1));\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbuilder.append(this.in, start, this.pos - 1);\n\t\t\t\t\treturn builder.toString();\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (c == '\\\\') {\n\t\t\t\tif (this.pos == this.in.length()) {\n\t\t\t\t\tthrow syntaxError(\"Unterminated escape sequence\");\n\t\t\t\t}\n\t\t\t\tif (builder == null) {\n\t\t\t\t\tbuilder = new StringBuilder();\n\t\t\t\t}\n\t\t\t\tbuilder.append(this.in, start, this.pos - 1);\n\t\t\t\tbuilder.append(readEscapeCharacter());\n\t\t\t\tstart = this.pos;\n\t\t\t}\n\t\t}\n\n\t\tthrow syntaxError(\"Unterminated string\");\n\t}", "summary_tokens": ["returns", "the", "string", "up", "to", "but", "not", "including", "quote", "unescaping", "any", "character", "escape", "sequences", "encountered", "along", "the", "way"], "project": "spring-boot"}
{"id": 372, "code": "\tpublic void stop() throws IOException {\n\t\tsynchronized (this.monitor) {\n\t\t\tif (this.listenThread != null) {\n\t\t\t\tcloseAllConnections();\n\t\t\t\ttry {\n\t\t\t\t\tthis.executor.shutdown();\n\t\t\t\t\tthis.executor.awaitTermination(1, TimeUnit.MINUTES);\n\t\t\t\t}\n\t\t\t\tcatch (InterruptedException ex) {\n\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t}\n\t\t\t\tthis.serverSocket.close();\n\t\t\t\ttry {\n\t\t\t\t\tthis.listenThread.join();\n\t\t\t\t}\n\t\t\t\tcatch (InterruptedException ex) {\n\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t}\n\t\t\t\tthis.listenThread = null;\n\t\t\t\tthis.serverSocket = null;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["gracefully", "stop", "the", "livereload", "server"], "project": "spring-boot"}
{"id": 1302, "code": "\tpublic Runnable getShutdownHandler() {\n\t\treturn null;\n\t}", "summary_tokens": ["returns", "a", "runnable", "that", "can", "handle", "shutdown", "of", "this", "logging", "system", "when", "the", "jvm", "exits"], "project": "spring-boot"}
{"id": 847, "code": "\tpublic void setNetwork(String network) {\n\t\tthis.network = network;\n\t}", "summary_tokens": ["sets", "the", "network", "the", "build", "container", "will", "connect", "to"], "project": "spring-boot"}
{"id": 1535, "code": "\tpublic MultipartConfigElement getMultipartConfig() {\n\t\treturn this.multipartConfig;\n\t}", "summary_tokens": ["returns", "the", "multipart", "config", "element", "multi", "part", "configuration", "to", "be", "applied", "or", "null"], "project": "spring-boot"}
{"id": 1558, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "for", "this", "filter"], "project": "spring-boot"}
{"id": 259, "code": "\tpublic boolean exists(ResourcePatternResolver resolver) {\n\t\tAssert.notNull(resolver, \"Resolver must not be null\");\n\t\tif (resolver.getResource(this.path).exists()) {\n\t\t\treturn true;\n\t\t}\n\t\ttry {\n\t\t\treturn anyExists(resolver);\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["determine", "if", "this", "template", "location", "exists", "using", "the", "specified", "resource", "pattern", "resolver"], "project": "spring-boot"}
{"id": 681, "code": "\tpublic String getShortDescription() {\n\t\treturn this.shortDescription;\n\t}", "summary_tokens": ["a", "single", "line", "single", "sentence", "description", "of", "this", "source", "if", "any"], "project": "spring-boot"}
{"id": 1491, "code": "\tpublic String getProtocol() {\n\t\treturn this.protocol;\n\t}", "summary_tokens": ["return", "the", "ssl", "protocol", "to", "use"], "project": "spring-boot"}
{"id": 860, "code": "\tprivate static <T> Action<CopySpec> fromCallTo(Callable<T> callable) {\n\t\treturn (spec) -> spec.from(callTo(callable));\n\t}", "summary_tokens": ["syntactic", "sugar", "that", "makes", "copy", "spec", "into", "calls", "a", "little", "easier", "to", "read"], "project": "spring-boot"}
{"id": 316, "code": "\tprotected String resolveArtifactId() {\n\t\tif (this.artifactId != null) {\n\t\t\treturn this.artifactId;\n\t\t}\n\t\tif (this.output != null) {\n\t\t\tint i = this.output.lastIndexOf('.');\n\t\t\treturn (i != -1) ? this.output.substring(0, i) : this.output;\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["resolve", "the", "artifact", "id", "to", "use", "or", "null", "if", "it", "should", "not", "be", "customized"], "project": "spring-boot"}
{"id": 485, "code": "\tstatic BuildOwner fromEnv(Map<String, String> env) {\n\t\tAssert.notNull(env, \"Env must not be null\");\n\t\treturn new BuildOwner(env);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "the", "build", "owner", "by", "inspecting", "the", "image", "env", "for", "cnb", "user", "id", "cnb", "group", "id", "variables"], "project": "spring-boot"}
{"id": 1467, "code": "\tpublic boolean isEnabled() {\n\t\treturn this.enabled;\n\t}", "summary_tokens": ["return", "whether", "to", "enable", "http", "0", "support", "if", "the", "current", "environment", "supports", "it"], "project": "spring-boot"}
{"id": 970, "code": "\tprotected EnvVariables resolveEnvVariables() {\n\t\treturn new EnvVariables(this.environmentVariables);\n\t}", "summary_tokens": ["resolve", "the", "environment", "variables", "to", "use"], "project": "spring-boot"}
{"id": 1211, "code": "\tpublic static <E> Bindable<Set<E>> setOf(Class<E> elementType) {\n\t\treturn of(ResolvableType.forClassWithGenerics(Set.class, elementType));\n\t}", "summary_tokens": ["create", "a", "new", "bindable", "set", "of", "the", "specified", "element", "type"], "project": "spring-boot"}
{"id": 471, "code": "\tpublic static <T> TestPropertyValues of(Stream<T> stream, Function<T, Pair> mapper) {\n\t\treturn (stream != null) ? empty().and(stream, mapper) : empty();\n\t}", "summary_tokens": ["return", "a", "new", "test", "property", "values", "with", "the", "underlying", "map", "populated", "with", "the", "given", "stream"], "project": "spring-boot"}
{"id": 864, "code": "\tpublic void setProvidedClasspath(Object classpath) {\n\t\tthis.providedClasspath = getProject().files(classpath);\n\t}", "summary_tokens": ["sets", "the", "provided", "classpath", "to", "include", "in", "the", "web", "inf", "lib", "provided", "directory", "of", "the", "war"], "project": "spring-boot"}
{"id": 5, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["returns", "the", "name", "of", "the", "milestone"], "project": "spring-boot"}
{"id": 581, "code": "\tpublic String getProgress() {\n\t\treturn this.progress;\n\t}", "summary_tokens": ["return", "a", "text", "based", "progress", "bar", "if", "progress", "information", "is", "available"], "project": "spring-boot"}
{"id": 129, "code": "\tpublic static Tag status(HttpServletResponse response) {\n\t\treturn (response != null) ? Tag.of(\"status\", Integer.toString(response.getStatus())) : STATUS_UNKNOWN;\n\t}", "summary_tokens": ["creates", "a", "status", "tag", "based", "on", "the", "status", "of", "the", "given", "response"], "project": "spring-boot"}
{"id": 1048, "code": "\tprotected SpringApplication createSpringApplication(ResourceLoader resourceLoader, Class<?>... sources) {\n\t\treturn new SpringApplication(resourceLoader, sources);\n\t}", "summary_tokens": ["creates", "a", "new", "spring", "application", "instance", "from", "the", "given", "sources", "using", "the", "given", "resource", "loader"], "project": "spring-boot"}
{"id": 291, "code": "\tpublic Set<Option> getOptions() {\n\t\treturn Collections.unmodifiableSet(this.options);\n\t}", "summary_tokens": ["returns", "a", "set", "of", "options", "that", "are", "understood", "by", "the", "command", "runner"], "project": "spring-boot"}
{"id": 153, "code": "\tpublic int determinePort() {\n\t\tif (CollectionUtils.isEmpty(this.parsedAddresses)) {\n\t\t\tInteger port = getPort();\n\t\t\tif (port != null) {\n\t\t\t\treturn port;\n\t\t\t}\n\t\t\treturn (Optional.ofNullable(getSsl().getEnabled()).orElse(false)) ? DEFAULT_PORT_SECURE : DEFAULT_PORT;\n\t\t}\n\t\treturn this.parsedAddresses.get(0).port;\n\t}", "summary_tokens": ["returns", "the", "port", "from", "the", "first", "address", "or", "the", "configured", "port", "if", "no", "addresses", "have", "been", "set"], "project": "spring-boot"}
{"id": 834, "code": "\tpublic List<String> getBuildpacks() {\n\t\treturn this.buildpacks.getOrNull();\n\t}", "summary_tokens": ["returns", "the", "buildpacks", "that", "will", "be", "used", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 918, "code": "\tpublic void packageImage(Libraries libraries, BiConsumer<ZipEntry, EntryWriter> exporter) throws IOException {\n\t\tpackageImage(libraries, new DelegatingJarWriter(exporter));\n\t}", "summary_tokens": ["create", "a", "packaged", "image"], "project": "spring-boot"}
{"id": 527, "code": "\tstatic BuilderMetadata fromImageConfig(ImageConfig imageConfig) throws IOException {\n\t\tAssert.notNull(imageConfig, \"ImageConfig must not be null\");\n\t\tString json = imageConfig.getLabels().get(LABEL_NAME);\n\t\tAssert.notNull(json, () -> \"No '\" + LABEL_NAME + \"' label found in image config labels '\"\n\t\t\t\t+ StringUtils.collectionToCommaDelimitedString(imageConfig.getLabels().keySet()) + \"'\");\n\t\treturn fromJson(json);\n\t}", "summary_tokens": ["factory", "method", "to", "extract", "builder", "metadata", "from", "image", "config"], "project": "spring-boot"}
{"id": 999, "code": "\tboolean isReady() throws MojoExecutionException {\n\t\ttry {\n\t\t\treturn (Boolean) this.connection.getAttribute(this.objectName, \"Ready\");\n\t\t}\n\t\tcatch (InstanceNotFoundException ex) {\n\t\t\treturn false; \n\t\t}\n\t\tcatch (AttributeNotFoundException ex) {\n\t\t\tthrow new IllegalStateException(\"Unexpected: attribute 'Ready' not available\", ex);\n\t\t}\n\t\tcatch (ReflectionException ex) {\n\t\t\tthrow new MojoExecutionException(\"Failed to retrieve Ready attribute\", ex.getCause());\n\t\t}\n\t\tcatch (MBeanException | IOException ex) {\n\t\t\tthrow new MojoExecutionException(ex.getMessage(), ex);\n\t\t}\n\t}", "summary_tokens": ["check", "if", "the", "spring", "application", "managed", "by", "this", "instance", "is", "ready"], "project": "spring-boot"}
{"id": 526, "code": "\tstatic BuilderMetadata fromImage(Image image) throws IOException {\n\t\tAssert.notNull(image, \"Image must not be null\");\n\t\treturn fromImageConfig(image.getConfig());\n\t}", "summary_tokens": ["factory", "method", "to", "extract", "builder", "metadata", "from", "an", "image"], "project": "spring-boot"}
{"id": 936, "code": "\tpublic static String findMainClass(JarFile jarFile, String classesLocation) throws IOException {\n\t\treturn doWithMainClasses(jarFile, classesLocation, MainClass::getName);\n\t}", "summary_tokens": ["find", "the", "main", "class", "in", "a", "given", "jar", "file"], "project": "spring-boot"}
{"id": 844, "code": "\tpublic void tag(String tag) {\n\t\tthis.tags.add(tag);\n\t}", "summary_tokens": ["add", "an", "entry", "to", "the", "tags", "that", "will", "be", "created", "for", "the", "built", "image"], "project": "spring-boot"}
{"id": 254, "code": "\tpublic static DatabaseInitializationSettings getSettings(SqlInitializationProperties properties) {\n\t\treturn SettingsCreator.createFrom(properties);\n\t}", "summary_tokens": ["adapts", "sql", "initialization", "properties", "sql", "initialization", "properties", "to", "database", "initialization", "settings"], "project": "spring-boot"}
{"id": 1417, "code": "\tpublic Collection<TomcatContextCustomizer> getTomcatContextCustomizers() {\n\t\treturn this.tomcatContextCustomizers;\n\t}", "summary_tokens": ["returns", "a", "mutable", "collection", "of", "the", "tomcat", "context", "customizer", "s", "that", "will", "be", "applied", "to", "the", "tomcat", "context"], "project": "spring-boot"}
{"id": 386, "code": "\tpublic void addAll(ClassLoaderFiles files) {\n\t\tAssert.notNull(files, \"Files must not be null\");\n\t\tfor (SourceDirectory directory : files.getSourceDirectories()) {\n\t\t\tfor (Map.Entry<String, ClassLoaderFile> entry : directory.getFilesEntrySet()) {\n\t\t\t\taddFile(directory.getName(), entry.getKey(), entry.getValue());\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["add", "all", "elements", "items", "from", "the", "specified", "class", "loader", "files", "to", "this", "instance"], "project": "spring-boot"}
{"id": 665, "code": "\tString getSourceMethod() {\n\t\treturn this.sourceMethod;\n\t}", "summary_tokens": ["the", "full", "name", "of", "the", "method", "including", "parenthesis", "and", "argument", "types", "that", "contributed", "this", "property"], "project": "spring-boot"}
{"id": 337, "code": "\tpublic DependencyCustomizer ifAllMissingClasses(String... classNames) {\n\t\treturn new DependencyCustomizer(this) {\n\t\t\t@Override\n\t\t\tprotected boolean canAdd() {\n\t\t\t\tfor (String className : classNames) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tClass.forName(className, false, DependencyCustomizer.this.loader);\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn DependencyCustomizer.this.canAdd();\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["create", "a", "nested", "dependency", "customizer", "that", "only", "applies", "if", "all", "the", "specified", "class", "names", "are", "not", "on", "the", "class", "path"], "project": "spring-boot"}
{"id": 1006, "code": "\tpublic static DockerImageName cassandra() {\n\t\treturn DockerImageName.parse(\"cassandra\").withTag(CASSANDRA_VERSION);\n\t}", "summary_tokens": ["return", "a", "docker", "image", "name", "suitable", "for", "running", "cassandra"], "project": "spring-boot"}
{"id": 648, "code": "\tdefault void directory(String name, Owner owner) throws IOException {\n\t\tdirectory(name, owner, 0755);\n\t}", "summary_tokens": ["add", "a", "directory", "to", "the", "content"], "project": "spring-boot"}
{"id": 64, "code": "\tpublic List<String> getProduced() {\n\t\treturn this.produced;\n\t}", "summary_tokens": ["returns", "the", "media", "types", "produced", "by", "an", "endpoint"], "project": "spring-boot"}
{"id": 1532, "code": "\tpublic void addUrlMappings(String... urlMappings) {\n\t\tAssert.notNull(urlMappings, \"UrlMappings must not be null\");\n\t\tthis.urlMappings.addAll(Arrays.asList(urlMappings));\n\t}", "summary_tokens": ["add", "url", "mappings", "as", "defined", "in", "the", "servlet", "specification", "for", "the", "servlet"], "project": "spring-boot"}
{"id": 556, "code": "\tvoid execute() throws IOException {\n\t\tAssert.state(!this.executed, \"Lifecycle has already been executed\");\n\t\tthis.executed = true;\n\t\tthis.log.executingLifecycle(this.request, this.lifecycleVersion, this.buildCacheVolume);\n\t\tif (this.request.isCleanCache()) {\n\t\t\tdeleteVolume(this.buildCacheVolume);\n\t\t}\n\t\trun(createPhase());\n\t\tthis.log.executedLifecycle(this.request);\n\t}", "summary_tokens": ["execute", "this", "lifecycle", "by", "running", "each", "phase", "in", "turn"], "project": "spring-boot"}
{"id": 269, "code": "\tprotected Map<String, Object> getErrorAttributes(ServerRequest request, ErrorAttributeOptions options) {\n\t\treturn this.errorAttributes.getErrorAttributes(request, options);\n\t}", "summary_tokens": ["extract", "the", "error", "attributes", "from", "the", "current", "request", "to", "be", "used", "to", "populate", "error", "views", "or", "json", "payloads"], "project": "spring-boot"}
{"id": 811, "code": "\tpublic Instant getTime() {\n\t\tLong epochMillis = this.time.getOrNull();\n\t\tif (epochMillis != null) {\n\t\t\treturn Instant.ofEpochMilli(epochMillis);\n\t\t}\n\t\tif (this.timeConfigured) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.creationTime;\n\t}", "summary_tokens": ["returns", "the", "value", "used", "for", "the", "build"], "project": "spring-boot"}
{"id": 327, "code": "\tpublic int getCode() {\n\t\treturn this.code;\n\t}", "summary_tokens": ["an", "exit", "code", "appropriate", "for", "use", "in", "system"], "project": "spring-boot"}
{"id": 1303, "code": "\tpublic Set<LogLevel> getSupportedLogLevels() {\n\t\treturn EnumSet.allOf(LogLevel.class);\n\t}", "summary_tokens": ["returns", "a", "set", "of", "the", "log", "level", "log", "levels", "that", "are", "actually", "supported", "by", "the", "logging", "system"], "project": "spring-boot"}
{"id": 1485, "code": "\tpublic String getTrustStoreType() {\n\t\treturn this.trustStoreType;\n\t}", "summary_tokens": ["return", "the", "type", "of", "the", "trust", "store"], "project": "spring-boot"}
{"id": 1413, "code": "\tpublic void setResourceFactory(ReactorResourceFactory resourceFactory) {\n\t\tthis.resourceFactory = resourceFactory;\n\t}", "summary_tokens": ["set", "the", "reactor", "resource", "factory", "to", "get", "the", "shared", "resources", "from"], "project": "spring-boot"}
{"id": 888, "code": "\tpublic DependenciesSpec getDependencies() {\n\t\treturn this.dependencies;\n\t}", "summary_tokens": ["returns", "the", "dependencies", "spec", "that", "controls", "the", "layers", "to", "which", "dependencies", "belong"], "project": "spring-boot"}
{"id": 1396, "code": "\tpublic ClientHttpRequestFactory buildRequestFactory() {\n\t\tClientHttpRequestFactory requestFactory = null;\n\t\tif (this.requestFactory != null) {\n\t\t\trequestFactory = this.requestFactory.get();\n\t\t}\n\t\telse if (this.detectRequestFactory) {\n\t\t\trequestFactory = new ClientHttpRequestFactorySupplier().get();\n\t\t}\n\t\tif (requestFactory != null) {\n\t\t\tif (this.requestFactoryCustomizer != null) {\n\t\t\t\tthis.requestFactoryCustomizer.accept(requestFactory);\n\t\t\t}\n\t\t}\n\t\treturn requestFactory;\n\t}", "summary_tokens": ["build", "a", "new", "client", "http", "request", "factory", "instance", "using", "the", "settings", "of", "this", "builder"], "project": "spring-boot"}
{"id": 990, "code": "\tpublic boolean isVerboseLogging() {\n\t\treturn this.verboseLogging;\n\t}", "summary_tokens": ["if", "verbose", "logging", "is", "required"], "project": "spring-boot"}
{"id": 487, "code": "\tpublic BuildRequest withBuilder(ImageReference builder) {\n\t\tAssert.notNull(builder, \"Builder must not be null\");\n\t\treturn new BuildRequest(this.name, this.applicationContent, builder.inTaggedOrDigestForm(), this.runImage,\n\t\t\t\tthis.creator, this.env, this.cleanCache, this.verboseLogging, this.pullPolicy, this.publish,\n\t\t\t\tthis.buildpacks, this.bindings, this.network, this.tags, this.buildCache, this.launchCache);\n\t}", "summary_tokens": ["return", "a", "new", "build", "request", "with", "an", "updated", "builder"], "project": "spring-boot"}
{"id": 43, "code": "\tpublic <T> T resolveArgument(Class<T> argumentType) {\n\t\tfor (OperationArgumentResolver argumentResolver : this.argumentResolvers) {\n\t\t\tif (argumentResolver.canResolve(argumentType)) {\n\t\t\t\tT result = argumentResolver.resolve(argumentType);\n\t\t\t\tif (result != null) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["resolves", "an", "argument", "with", "the", "given", "argument", "type"], "project": "spring-boot"}
{"id": 608, "code": "\tpublic String getWaitingErrorMessage() {\n\t\treturn this.waitingErrorMessage;\n\t}", "summary_tokens": ["return", "a", "message", "indicating", "an", "error", "waiting", "for", "a", "container", "to", "stop"], "project": "spring-boot"}
{"id": 424, "code": "\tpublic final EntityManager getEntityManager() {\n\t\tEntityManager manager = EntityManagerFactoryUtils.getTransactionalEntityManager(this.entityManagerFactory);\n\t\tAssert.state(manager != null, \"No transactional EntityManager found, is your test running in a transaction?\");\n\t\treturn manager;\n\t}", "summary_tokens": ["return", "the", "underlying", "entity", "manager", "that", "s", "actually", "used", "to", "perform", "all", "operations"], "project": "spring-boot"}
{"id": 1259, "code": "\tstatic EnvironmentPostProcessorsFactory of(ClassLoader classLoader, String... classNames) {\n\t\treturn new ReflectionEnvironmentPostProcessorsFactory(classLoader, classNames);\n\t}", "summary_tokens": ["return", "a", "environment", "post", "processors", "factory", "that", "reflectively", "creates", "post", "processors", "from", "the", "given", "class", "names"], "project": "spring-boot"}
{"id": 909, "code": "\tprivate void writeEntry(JarArchiveEntry entry, Library library, EntryWriter entryWriter,\n\t\t\tUnpackHandler unpackHandler) throws IOException {\n\t\tString name = entry.getName();\n\t\tif (this.writtenEntries.add(name)) {\n\t\t\twriteParentDirectoryEntries(name);\n\t\t\tentry.setUnixMode(name.endsWith(\"/\") ? UNIX_DIR_MODE : UNIX_FILE_MODE);\n\t\t\tentry.getGeneralPurposeBit().useUTF8ForNames(true);\n\t\t\tif (!entry.isDirectory() && entry.getSize() == -1) {\n\t\t\t\tentryWriter = SizeCalculatingEntryWriter.get(entryWriter);\n\t\t\t\tentry.setSize(entryWriter.size());\n\t\t\t}\n\t\t\tentryWriter = addUnpackCommentIfNecessary(entry, entryWriter, unpackHandler);\n\t\t\tupdateLayerIndex(entry, library);\n\t\t\twriteToArchive(entry, entryWriter);\n\t\t}\n\t}", "summary_tokens": ["perform", "the", "actual", "write", "of", "a", "jar", "entry"], "project": "spring-boot"}
{"id": 850, "code": "\tpublic CacheSpec getLaunchCache() {\n\t\treturn this.launchCache;\n\t}", "summary_tokens": ["returns", "the", "launch", "cache", "that", "will", "be", "used", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 71, "code": "\tpublic T getBody() {\n\t\treturn this.body;\n\t}", "summary_tokens": ["returns", "the", "body", "for", "the", "response"], "project": "spring-boot"}
{"id": 354, "code": "\tpublic Set<ChangedFiles> getChangeSet() {\n\t\treturn this.changeSet;\n\t}", "summary_tokens": ["return", "details", "of", "the", "files", "that", "changed"], "project": "spring-boot"}
{"id": 546, "code": "\tpublic static Cache volume(String name) {\n\t\tAssert.notNull(name, \"Name must not be null\");\n\t\treturn new Volume(name);\n\t}", "summary_tokens": ["create", "a", "new", "cache", "that", "uses", "a", "volume", "with", "the", "provided", "name"], "project": "spring-boot"}
{"id": 708, "code": "\tpublic double getDouble(int index) throws JSONException {\n\t\tObject object = get(index);\n\t\tDouble result = JSON.toDouble(object);\n\t\tif (result == null) {\n\t\t\tthrow JSON.typeMismatch(index, object, \"double\");\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index", "if", "it", "exists", "and", "is", "a", "double", "or", "can", "be", "coerced", "to", "a", "double"], "project": "spring-boot"}
{"id": 908, "code": "\tpublic void writeLoaderClasses(String loaderJarResourceName) throws IOException {\n\t\tURL loaderJar = getClass().getClassLoader().getResource(loaderJarResourceName);\n\t\ttry (JarInputStream inputStream = new JarInputStream(new BufferedInputStream(loaderJar.openStream()))) {\n\t\t\tJarEntry entry;\n\t\t\twhile ((entry = inputStream.getNextJarEntry()) != null) {\n\t\t\t\tif (isDirectoryEntry(entry) || isClassEntry(entry)) {\n\t\t\t\t\twriteEntry(new JarArchiveEntry(entry), new InputStreamEntryWriter(inputStream));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["write", "the", "required", "spring", "boot", "loader", "classes", "to", "the", "jar"], "project": "spring-boot"}
{"id": 1475, "code": "\tpublic String[] getCiphers() {\n\t\treturn this.ciphers;\n\t}", "summary_tokens": ["return", "the", "supported", "ssl", "ciphers"], "project": "spring-boot"}
{"id": 940, "code": "\tpublic void repackage(File destination, Libraries libraries, LaunchScript launchScript, FileTime lastModifiedTime)\n\t\t\tthrows IOException {\n\t\tAssert.isTrue(destination != null && !destination.isDirectory(), \"Invalid destination\");\n\t\tgetLayout(); \n\t\tdestination = destination.getAbsoluteFile();\n\t\tFile source = getSource();\n\t\tif (isAlreadyPackaged() && source.equals(destination)) {\n\t\t\treturn;\n\t\t}\n\t\tFile workingSource = source;\n\t\tif (source.equals(destination)) {\n\t\t\tworkingSource = getBackupFile();\n\t\t\tworkingSource.delete();\n\t\t\trenameFile(source, workingSource);\n\t\t}\n\t\tdestination.delete();\n\t\ttry {\n\t\t\ttry (JarFile sourceJar = new JarFile(workingSource)) {\n\t\t\t\trepackage(sourceJar, destination, libraries, launchScript, lastModifiedTime);\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tif (!this.backupSource && !source.equals(workingSource)) {\n\t\t\t\tdeleteFile(workingSource);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["repackage", "to", "the", "given", "destination", "so", "that", "it", "can", "be", "launched", "using", "java", "jar"], "project": "spring-boot"}
{"id": 691, "code": "\tpublic List<ValueHint> getValueHints() {\n\t\treturn this.valueHints;\n\t}", "summary_tokens": ["the", "list", "of", "well", "defined", "values", "if", "any"], "project": "spring-boot"}
{"id": 17, "code": "\tprivate String getCacheManagerName(String beanName) {\n\t\tif (beanName.length() > CACHE_MANAGER_SUFFIX.length()\n\t\t\t\t&& StringUtils.endsWithIgnoreCase(beanName, CACHE_MANAGER_SUFFIX)) {\n\t\t\treturn beanName.substring(0, beanName.length() - CACHE_MANAGER_SUFFIX.length());\n\t\t}\n\t\treturn beanName;\n\t}", "summary_tokens": ["get", "the", "name", "of", "a", "cache", "manager", "based", "on", "its", "bean", "name"], "project": "spring-boot"}
{"id": 191, "code": "\tpublic static EntityScanPackages get(BeanFactory beanFactory) {\n\t\t\n\t\t\n\t\ttry {\n\t\t\treturn beanFactory.getBean(BEAN, EntityScanPackages.class);\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\treturn NONE;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "entity", "scan", "packages", "for", "the", "given", "bean", "factory"], "project": "spring-boot"}
{"id": 1328, "code": "\tprotected void initialized(Supplier<C> context) {\n\t}", "summary_tokens": ["called", "once", "the", "context", "has", "been", "initialized"], "project": "spring-boot"}
{"id": 109, "code": "\tpublic void setQuery(String query) {\n\t\tthis.query = query;\n\t}", "summary_tokens": ["set", "a", "specific", "validation", "query", "to", "use", "to", "validate", "a", "connection"], "project": "spring-boot"}
{"id": 869, "code": "\tprivate static <T> Action<CopySpec> fromCallTo(Callable<T> callable) {\n\t\treturn (spec) -> spec.from(callTo(callable));\n\t}", "summary_tokens": ["syntactic", "sugar", "that", "makes", "copy", "spec", "into", "calls", "a", "little", "easier", "to", "read"], "project": "spring-boot"}
{"id": 448, "code": "\tprotected final void initialize(Class<?> resourceLoadClass, Charset charset) {\n\t\tif (this.loader == null) {\n\t\t\tthis.loader = new JsonLoader(resourceLoadClass, charset);\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "marshal", "tester", "for", "use"], "project": "spring-boot"}
{"id": 1089, "code": "\tConfigDataResource getResource() {\n\t\treturn this.resource;\n\t}", "summary_tokens": ["return", "the", "resource", "that", "contributed", "this", "instance"], "project": "spring-boot"}
{"id": 794, "code": "\tpublic FileCollection getClasspath() {\n\t\treturn this.classpath;\n\t}", "summary_tokens": ["returns", "the", "classpath", "that", "the", "task", "will", "examine", "when", "resolving", "the", "main", "class", "name"], "project": "spring-boot"}
{"id": 219, "code": "\tstatic SQLDialect getDialect(DataSource dataSource) {\n\t\tif (dataSource == null) {\n\t\t\treturn SQLDialect.DEFAULT;\n\t\t}\n\t\ttry {\n\t\t\tString url = JdbcUtils.extractDatabaseMetaData(dataSource, DatabaseMetaData::getURL);\n\t\t\tSQLDialect sqlDialect = JDBCUtils.dialect(url);\n\t\t\tif (sqlDialect != null) {\n\t\t\t\treturn sqlDialect;\n\t\t\t}\n\t\t}\n\t\tcatch (MetaDataAccessException ex) {\n\t\t\tlogger.warn(\"Unable to determine jdbc url from datasource\", ex);\n\t\t}\n\t\treturn SQLDialect.DEFAULT;\n\t}", "summary_tokens": ["return", "the", "most", "suitable", "sqldialect", "for", "the", "given", "data", "source"], "project": "spring-boot"}
{"id": 878, "code": "\tpublic void properties(Map<String, String> properties) {\n\t\tthis.properties.putAll(properties);\n\t}", "summary_tokens": ["sets", "the", "properties", "that", "are", "applied", "to", "the", "launch", "script", "when", "it", "s", "being", "including", "in", "the", "executable", "archive"], "project": "spring-boot"}
{"id": 1183, "code": "\tpublic ConfigurationPropertyName getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "configuration", "property", "being", "bound"], "project": "spring-boot"}
{"id": 246, "code": "\tpublic StaticResourceServerWebExchange atCommonLocations() {\n\t\treturn at(EnumSet.allOf(StaticResourceLocation.class));\n\t}", "summary_tokens": ["returns", "a", "matcher", "that", "includes", "all", "commonly", "used", "static", "resource", "location", "locations"], "project": "spring-boot"}
{"id": 841, "code": "\tpublic void bindings(List<String> bindings) {\n\t\tthis.bindings.addAll(bindings);\n\t}", "summary_tokens": ["add", "entries", "to", "the", "volume", "bindings", "that", "will", "be", "mounted", "to", "the", "container", "when", "building", "the", "image"], "project": "spring-boot"}
{"id": 1440, "code": "\tpublic ErrorAttributeOptions excluding(Include... excludes) {\n\t\tEnumSet<Include> updated = copyIncludes();\n\t\tupdated.removeAll(Arrays.asList(excludes));\n\t\treturn new ErrorAttributeOptions(Collections.unmodifiableSet(updated));\n\t}", "summary_tokens": ["return", "an", "error", "attribute", "options", "that", "excludes", "the", "specified", "attribute", "include", "options"], "project": "spring-boot"}
{"id": 1197, "code": "\tpublic <X extends Throwable> T orElseThrow(Supplier<? extends X> exceptionSupplier) throws X {\n\t\tif (this.value == null) {\n\t\t\tthrow exceptionSupplier.get();\n\t\t}\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "object", "that", "was", "bound", "or", "throw", "an", "exception", "to", "be", "created", "by", "the", "provided", "supplier", "if", "no", "value", "has", "been", "bound"], "project": "spring-boot"}
{"id": 1578, "code": "\tpublic Map<String, String> getInitParameters() {\n\t\treturn this.initParameters;\n\t}", "summary_tokens": ["return", "the", "init", "parameters", "used", "to", "configure", "the", "jsp", "servlet"], "project": "spring-boot"}
{"id": 245, "code": "\tpublic static StaticResourceRequest toStaticResources() {\n\t\treturn StaticResourceRequest.INSTANCE;\n\t}", "summary_tokens": ["returns", "a", "static", "resource", "request", "that", "can", "be", "used", "to", "create", "a", "matcher", "for", "static", "resource", "location", "locations"], "project": "spring-boot"}
{"id": 714, "code": "\tpublic String getString(int index) throws JSONException {\n\t\tObject object = get(index);\n\t\tString result = JSON.toString(object);\n\t\tif (result == null) {\n\t\t\tthrow JSON.typeMismatch(index, object, \"String\");\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["returns", "the", "value", "at", "index", "if", "it", "exists", "coercing", "it", "if", "necessary"], "project": "spring-boot"}
{"id": 1064, "code": "\tpublic SpringApplicationBuilder addCommandLineProperties(boolean addCommandLineProperties) {\n\t\tthis.application.setAddCommandLineProperties(addCommandLineProperties);\n\t\treturn this;\n\t}", "summary_tokens": ["flag", "to", "indicate", "that", "command", "line", "arguments", "should", "be", "added", "to", "the", "environment"], "project": "spring-boot"}
{"id": 954, "code": "", "summary_tokens": ["closes", "the", "archive", "releasing", "any", "open", "resources"], "project": "spring-boot"}
{"id": 652, "code": "\tstatic TarArchive fromZip(File zip, Owner owner) {\n\t\treturn new ZipFileTarArchive(zip, owner);\n\t}", "summary_tokens": ["factory", "method", "to", "adapt", "a", "zip", "file", "to", "tar", "archive"], "project": "spring-boot"}
{"id": 314, "code": "\tList<String> getDependencies() {\n\t\treturn this.dependencies;\n\t}", "summary_tokens": ["the", "identifiers", "of", "the", "dependencies", "to", "include", "in", "the", "project"], "project": "spring-boot"}
{"id": 206, "code": "\tpublic String determinePassword() {\n\t\tif (StringUtils.hasText(this.password)) {\n\t\t\treturn this.password;\n\t\t}\n\t\tif (EmbeddedDatabaseConnection.isEmbedded(determineDriverClassName(), determineUrl())) {\n\t\t\treturn \"\";\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["determine", "the", "password", "to", "use", "based", "on", "this", "configuration", "and", "the", "environment"], "project": "spring-boot"}
{"id": 1123, "code": "\tdefault List<R> resolveProfileSpecific(ConfigDataLocationResolverContext context, ConfigDataLocation location,\n\t\t\tProfiles profiles) throws ConfigDataLocationNotFoundException {\n\t\treturn Collections.emptyList();\n\t}", "summary_tokens": ["resolve", "a", "config", "data", "location", "into", "one", "or", "more", "config", "data", "resource", "instances", "based", "on", "available", "profiles"], "project": "spring-boot"}
{"id": 640, "code": "\tpublic static LayerId of(String value) {\n\t\tAssert.hasText(value, \"Value must not be empty\");\n\t\tint i = value.indexOf(':');\n\t\tAssert.isTrue(i >= 0, () -> \"Invalid layer ID '\" + value + \"'\");\n\t\treturn new LayerId(value, value.substring(0, i), value.substring(i + 1));\n\t}", "summary_tokens": ["create", "a", "new", "layer", "id", "with", "the", "specified", "value"], "project": "spring-boot"}
{"id": 281, "code": "\tdefault String getPrefix() {\n\t\tString result = getPath();\n\t\tint index = result.indexOf('*');\n\t\tif (index != -1) {\n\t\t\tresult = result.substring(0, index);\n\t\t}\n\t\tif (result.endsWith(\"/\")) {\n\t\t\tresult = result.substring(0, result.length() - 1);\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["return", "a", "cleaned", "up", "version", "of", "the", "path", "that", "can", "be", "used", "as", "a", "prefix", "for", "urls"], "project": "spring-boot"}
{"id": 222, "code": "\tvoid setRecordFilterStrategy(RecordFilterStrategy<Object, Object> recordFilterStrategy) {\n\t\tthis.recordFilterStrategy = recordFilterStrategy;\n\t}", "summary_tokens": ["set", "the", "record", "filter", "strategy", "to", "use", "to", "filter", "incoming", "records"], "project": "spring-boot"}
{"id": 1298, "code": "\tpublic Environment getEnvironment() {\n\t\treturn this.environment;\n\t}", "summary_tokens": ["return", "the", "spring", "environment", "if", "available"], "project": "spring-boot"}
{"id": 1448, "code": "\tprotected HttpHandler getHttpHandler() {\n\t\t\n\t\tString[] beanNames = getBeanFactory().getBeanNamesForType(HttpHandler.class);\n\t\tif (beanNames.length == 0) {\n\t\t\tthrow new ApplicationContextException(\n\t\t\t\t\t\"Unable to start ReactiveWebApplicationContext due to missing HttpHandler bean.\");\n\t\t}\n\t\tif (beanNames.length > 1) {\n\t\t\tthrow new ApplicationContextException(\n\t\t\t\t\t\"Unable to start ReactiveWebApplicationContext due to multiple HttpHandler beans : \"\n\t\t\t\t\t\t\t+ StringUtils.arrayToCommaDelimitedString(beanNames));\n\t\t}\n\t\treturn getBeanFactory().getBean(beanNames[0], HttpHandler.class);\n\t}", "summary_tokens": ["return", "the", "http", "handler", "that", "should", "be", "used", "to", "process", "the", "reactive", "web", "server"], "project": "spring-boot"}
{"id": 434, "code": "\tstatic AssertableApplicationContext get(Supplier<? extends ConfigurableApplicationContext> contextSupplier) {\n\t\treturn ApplicationContextAssertProvider.get(AssertableApplicationContext.class,\n\t\t\t\tConfigurableApplicationContext.class, contextSupplier);\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "new", "assertable", "application", "context", "instance"], "project": "spring-boot"}
{"id": 134, "code": "\tpublic final HttpTrace receivedRequest(TraceableRequest request) {\n\t\treturn new HttpTrace(new FilteredTraceableRequest(request));\n\t}", "summary_tokens": ["begins", "the", "tracing", "of", "the", "exchange", "that", "was", "initiated", "by", "the", "given", "request", "being", "received"], "project": "spring-boot"}
{"id": 1112, "code": "\tdefault void onSetProfiles(Profiles profiles) {\n\t}", "summary_tokens": ["called", "when", "environment", "profiles", "are", "set"], "project": "spring-boot"}
{"id": 753, "code": "\tpublic JSONStringer array() throws JSONException {\n\t\treturn open(Scope.EMPTY_ARRAY, \"[\");\n\t}", "summary_tokens": ["begins", "encoding", "a", "new", "array"], "project": "spring-boot"}
{"id": 141, "code": "\tpublic String getName() {\n\t\treturn this.registration.getName();\n\t}", "summary_tokens": ["returns", "the", "name", "of", "the", "registered", "filter", "or", "servlet"], "project": "spring-boot"}
{"id": 826, "code": "\tpublic boolean isCleanCache() {\n\t\treturn this.cleanCache;\n\t}", "summary_tokens": ["returns", "whether", "caches", "should", "be", "cleaned", "before", "packaging"], "project": "spring-boot"}
{"id": 1557, "code": "\tdefault Map<String, Object> getErrorAttributes(WebRequest webRequest, ErrorAttributeOptions options) {\n\t\treturn Collections.emptyMap();\n\t}", "summary_tokens": ["returns", "a", "map", "of", "the", "error", "attributes"], "project": "spring-boot"}
{"id": 1516, "code": "\tpublic void setMaxRequestSize(DataSize maxRequestSize) {\n\t\tthis.maxRequestSize = maxRequestSize;\n\t}", "summary_tokens": ["sets", "the", "maximum", "data", "size", "allowed", "for", "multipart", "form", "data", "requests"], "project": "spring-boot"}
{"id": 26, "code": "\tpublic static <T extends AbstractApplicationContextRunner<?, ?, ?>> Function<T, T> limitedTo(\n\t\t\tClass<?>... exportAutoConfigurations) {\n\t\treturn (contextRunner) -> apply(contextRunner, exportAutoConfigurations);\n\t}", "summary_tokens": ["return", "a", "function", "that", "configures", "the", "run", "to", "be", "limited", "to", "the", "specified", "implementations"], "project": "spring-boot"}
{"id": 1478, "code": "\tpublic String getKeyPassword() {\n\t\treturn this.keyPassword;\n\t}", "summary_tokens": ["return", "the", "password", "used", "to", "access", "the", "key", "in", "the", "key", "store"], "project": "spring-boot"}
{"id": 169, "code": "\tpublic void recordConditionEvaluation(String source, Condition condition, ConditionOutcome outcome) {\n\t\tAssert.notNull(source, \"Source must not be null\");\n\t\tAssert.notNull(condition, \"Condition must not be null\");\n\t\tAssert.notNull(outcome, \"Outcome must not be null\");\n\t\tthis.unconditionalClasses.remove(source);\n\t\tif (!this.outcomes.containsKey(source)) {\n\t\t\tthis.outcomes.put(source, new ConditionAndOutcomes());\n\t\t}\n\t\tthis.outcomes.get(source).add(condition, outcome);\n\t\tthis.addedAncestorOutcomes = false;\n\t}", "summary_tokens": ["record", "the", "occurrence", "of", "condition", "evaluation"], "project": "spring-boot"}
{"id": 1099, "code": "\tConfigDataEnvironmentContributor withBoundProperties(Iterable<ConfigDataEnvironmentContributor> contributors,\n\t\t\tConfigDataActivationContext activationContext) {\n\t\tIterable<ConfigurationPropertySource> sources = Collections.singleton(getConfigurationPropertySource());\n\t\tPlaceholdersResolver placeholdersResolver = new ConfigDataEnvironmentContributorPlaceholdersResolver(\n\t\t\t\tcontributors, activationContext, this, true);\n\t\tBinder binder = new Binder(sources, placeholdersResolver, null, null, null);\n\t\tConfigDataProperties properties = ConfigDataProperties.get(binder);\n\t\tif (properties != null && this.configDataOptions.contains(ConfigData.Option.IGNORE_IMPORTS)) {\n\t\t\tproperties = properties.withoutImports();\n\t\t}\n\t\treturn new ConfigDataEnvironmentContributor(Kind.BOUND_IMPORT, this.location, this.resource,\n\t\t\t\tthis.fromProfileSpecificImport, this.propertySource, this.configurationPropertySource, properties,\n\t\t\t\tthis.configDataOptions, null);\n\t}", "summary_tokens": ["create", "a", "new", "config", "data", "environment", "contributor", "with", "bound", "config", "data", "properties"], "project": "spring-boot"}
{"id": 843, "code": "\tpublic void setTags(List<String> tags) {\n\t\tthis.tags.set(tags);\n\t}", "summary_tokens": ["sets", "the", "tags", "that", "will", "be", "created", "for", "the", "built", "image"], "project": "spring-boot"}
{"id": 230, "code": "\tpublic Map<String, Object> buildConsumerProperties() {\n\t\tMap<String, Object> properties = buildCommonProperties();\n\t\tproperties.putAll(this.consumer.buildProperties());\n\t\treturn properties;\n\t}", "summary_tokens": ["create", "an", "initial", "map", "of", "consumer", "properties", "from", "the", "state", "of", "this", "instance"], "project": "spring-boot"}
{"id": 349, "code": "\tpublic URI getUri() {\n\t\treturn this.uri;\n\t}", "summary_tokens": ["return", "the", "uri", "of", "the", "repository"], "project": "spring-boot"}
{"id": 39, "code": "\tpublic static EndpointId of(Environment environment, String value) {\n\t\tAssert.notNull(environment, \"Environment must not be null\");\n\t\treturn new EndpointId(migrateLegacyId(environment, value));\n\t}", "summary_tokens": ["factory", "method", "to", "create", "a", "new", "endpoint", "id", "of", "the", "specified", "value"], "project": "spring-boot"}
{"id": 1231, "code": "\tpublic boolean isParentOf(ConfigurationPropertyName name) {\n\t\tAssert.notNull(name, \"Name must not be null\");\n\t\tif (getNumberOfElements() != name.getNumberOfElements() - 1) {\n\t\t\treturn false;\n\t\t}\n\t\treturn isAncestorOf(name);\n\t}", "summary_tokens": ["returns", "true", "if", "this", "element", "is", "an", "immediate", "parent", "of", "the", "specified", "name"], "project": "spring-boot"}
{"id": 745, "code": "\tpublic JSONObject optJSONObject(String name) {\n\t\tObject object = opt(name);\n\t\treturn object instanceof JSONObject ? (JSONObject) object : null;\n\t}", "summary_tokens": ["returns", "the", "value", "mapped", "by", "name", "if", "it", "exists", "and", "is", "a", "jsonobject"], "project": "spring-boot"}
{"id": 301, "code": "\tString getArtifactId() {\n\t\treturn this.artifactId;\n\t}", "summary_tokens": ["the", "artifact", "id", "to", "use", "or", "null", "if", "it", "should", "not", "be", "customized"], "project": "spring-boot"}
{"id": 283, "code": "\tpublic MultipartConfigElement createMultipartConfig() {\n\t\tMultipartConfigFactory factory = new MultipartConfigFactory();\n\t\tPropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull();\n\t\tmap.from(this.fileSizeThreshold).to(factory::setFileSizeThreshold);\n\t\tmap.from(this.location).whenHasText().to(factory::setLocation);\n\t\tmap.from(this.maxRequestSize).to(factory::setMaxRequestSize);\n\t\tmap.from(this.maxFileSize).to(factory::setMaxFileSize);\n\t\treturn factory.createMultipartConfig();\n\t}", "summary_tokens": ["create", "a", "new", "multipart", "config", "element", "using", "the", "properties"], "project": "spring-boot"}
{"id": 19, "code": "\tprotected final <V> V get(Function<T, V> getter, Supplier<V> fallback) {\n\t\tV value = getter.apply(this.properties);\n\t\treturn (value != null) ? value : fallback.get();\n\t}", "summary_tokens": ["get", "the", "value", "from", "the", "properties", "or", "use", "a", "fallback", "from", "the", "defaults"], "project": "spring-boot"}
{"id": 749, "code": "\tpublic String toString(int indentSpaces) throws JSONException {\n\t\tJSONStringer stringer = new JSONStringer(indentSpaces);\n\t\twriteTo(stringer);\n\t\treturn stringer.toString();\n\t}", "summary_tokens": ["encodes", "this", "object", "as", "a", "human", "readable", "json", "string", "for", "debugging", "such", "as", "pre", "query", "pizza", "locations", "0", "0", "pre", "indent", "spaces", "the", "number", "of", "spaces", "to", "indent", "for", "each", "level", "of", "nesting"], "project": "spring-boot"}
{"id": 382, "code": "\tString getDeclaringClassName() {\n\t\treturn this.method.getDeclaringClass().getName();\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "declaring", "class"], "project": "spring-boot"}
{"id": 1182, "code": "\tdefault Object bind(ConfigurationPropertyName name, Bindable<?> target) {\n\t\treturn bind(name, target, null);\n\t}", "summary_tokens": ["bind", "the", "given", "name", "to", "a", "target", "bindable"], "project": "spring-boot"}
{"id": 148, "code": "\tprotected void setMessageConverter(MessageConverter messageConverter) {\n\t\tthis.messageConverter = messageConverter;\n\t}", "summary_tokens": ["set", "the", "message", "converter", "to", "use", "or", "null", "if", "the", "out", "of", "the", "box", "converter", "should", "be", "used"], "project": "spring-boot"}
{"id": 602, "code": "\tpublic String getMessage() {\n\t\treturn this.message;\n\t}", "summary_tokens": ["return", "the", "message", "contained", "in", "the", "response"], "project": "spring-boot"}
{"id": 1021, "code": "\tpublic static void addOrMerge(Map<String, Object> source, MutablePropertySources sources) {\n\t\tif (!CollectionUtils.isEmpty(source)) {\n\t\t\tMap<String, Object> resultingSource = new HashMap<>();\n\t\t\tDefaultPropertiesPropertySource propertySource = new DefaultPropertiesPropertySource(resultingSource);\n\t\t\tif (sources.contains(NAME)) {\n\t\t\t\tmergeIfPossible(source, sources, resultingSource);\n\t\t\t\tsources.replace(NAME, propertySource);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tresultingSource.putAll(source);\n\t\t\t\tsources.addLast(propertySource);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["add", "a", "new", "default", "properties", "property", "source", "or", "merge", "with", "an", "existing", "one"], "project": "spring-boot"}
{"id": 1314, "code": "\tstatic <K> Origin getOrigin(Object source, K key) {\n\t\tif (!(source instanceof OriginLookup)) {\n\t\t\treturn null;\n\t\t}\n\t\ttry {\n\t\t\treturn ((OriginLookup<K>) source).getOrigin(key);\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["attempt", "to", "look", "up", "the", "origin", "from", "the", "given", "source"], "project": "spring-boot"}
{"id": 1343, "code": "\tpublic DatabaseInitializationMode getMode() {\n\t\treturn this.mode;\n\t}", "summary_tokens": ["gets", "the", "mode", "to", "use", "when", "determining", "whether", "database", "initialization", "should", "be", "performed"], "project": "spring-boot"}
{"id": 1519, "code": "\tprivate long convertToBytes(DataSize size, int defaultValue) {\n\t\tif (size != null && !size.isNegative()) {\n\t\t\treturn size.toBytes();\n\t\t}\n\t\treturn defaultValue;\n\t}", "summary_tokens": ["return", "the", "amount", "of", "bytes", "from", "the", "specified", "data", "size", "size"], "project": "spring-boot"}
{"id": 924, "code": "\tdefault String getLayersIndexFileLocation() {\n\t\treturn null;\n\t}", "summary_tokens": ["returns", "the", "location", "of", "the", "layer", "index", "file", "that", "should", "be", "written", "or", "null", "if", "not", "index", "is", "required"], "project": "spring-boot"}
{"id": 655, "code": "\tprotected <T> T valueAt(String expression, Class<T> type) {\n\t\treturn valueAt(this, this.node, this.lookup, expression, type);\n\t}", "summary_tokens": ["get", "the", "value", "at", "the", "given", "json", "path", "expression", "as", "a", "specific", "type"], "project": "spring-boot"}
{"id": 331, "code": "\tpublic boolean matches(ClassNode classNode) {\n\t\treturn true;\n\t}", "summary_tokens": ["strategy", "method", "used", "to", "determine", "when", "compiler", "auto", "configuration", "should", "be", "applied"], "project": "spring-boot"}
{"id": 1275, "code": "\tpublic DataSourceBuilder<T> driverClassName(String driverClassName) {\n\t\tset(DataSourceProperty.DRIVER_CLASS_NAME, driverClassName);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "driver", "class", "name", "that", "should", "be", "used", "when", "building", "the", "datasource"], "project": "spring-boot"}
{"id": 1317, "code": "\tpublic static Origin get(PropertySource<?> propertySource, String name) {\n\t\tOrigin origin = OriginLookup.getOrigin(propertySource, name);\n\t\treturn (origin != null) ? origin : new PropertySourceOrigin(propertySource, name);\n\t}", "summary_tokens": ["get", "an", "origin", "for", "the", "given", "property", "source", "and", "property", "name"], "project": "spring-boot"}
{"id": 561, "code": "\tstatic LifecycleVersion parse(String value) {\n\t\tAssert.hasText(value, \"Value must not be empty\");\n\t\tif (value.startsWith(\"v\") || value.startsWith(\"V\")) {\n\t\t\tvalue = value.substring(1);\n\t\t}\n\t\tString[] components = value.split(\"\\\\.\");\n\t\tAssert.isTrue(components.length <= 3, \"Malformed version number '\" + value + \"'\");\n\t\tint[] versions = new int[3];\n\t\tfor (int i = 0; i < components.length; i++) {\n\t\t\ttry {\n\t\t\t\tversions[i] = Integer.parseInt(components[i]);\n\t\t\t}\n\t\t\tcatch (NumberFormatException ex) {\n\t\t\t\tthrow new IllegalArgumentException(\"Malformed version number '\" + value + \"'\", ex);\n\t\t\t}\n\t\t}\n\t\treturn new LifecycleVersion(versions[0], versions[1], versions[2]);\n\t}", "summary_tokens": ["factory", "method", "to", "parse", "a", "string", "into", "a", "lifecycle", "version", "instance"], "project": "spring-boot"}
{"id": 522, "code": "\tCreatedBy getCreatedBy() {\n\t\treturn this.createdBy;\n\t}", "summary_tokens": ["return", "information", "about", "who", "created", "the", "builder"], "project": "spring-boot"}
{"id": 998, "code": "\tprotected LayoutFactory getLayoutFactory() {\n\t\treturn this.layoutFactory;\n\t}", "summary_tokens": ["return", "the", "layout", "factory", "that", "will", "be", "used", "to", "determine", "the", "abstract", "packager", "mojo"], "project": "spring-boot"}
{"id": 694, "code": "\tpublic void add(ConfigurationMetadataProperty property, ConfigurationMetadataSource source) {\n\t\tif (source != null) {\n\t\t\tputIfAbsent(source.getProperties(), property.getId(), property);\n\t\t}\n\t\tputIfAbsent(getGroup(source).getProperties(), property.getId(), property);\n\t}", "summary_tokens": ["add", "a", "configuration", "metadata", "property", "with", "the", "configuration", "metadata", "source", "source", "that", "defines", "it", "if", "any"], "project": "spring-boot"}
{"id": 985, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["the", "name", "of", "the", "created", "image"], "project": "spring-boot"}
{"id": 806, "code": "public static <K, V> Builder<K, V> builderWithExpectedSize(int expectedSize) {\n  checkNonnegative(expectedSize, \"expectedSize\");\n  return new Builder<>(expectedSize);\n}", "summary_tokens": ["returns", "a", "new", "builder", "expecting", "the", "specified", "number", "of", "entries", "to", "be", "added"], "project": "guava"}
{"id": 1580, "code": "public long[] toArray() {\n  return Arrays.copyOfRange(array, start, end);\n}", "summary_tokens": ["returns", "a", "new", "mutable", "copy", "of", "this", "array", "s", "values", "as", "a", "primitive", "long"], "project": "guava"}
{"id": 294, "code": "public void testGetRandomAccess() {\n  Multimap<String, Integer> multimap = create();\n  multimap.put(\"foo\", 1);\n  multimap.put(\"foo\", 3);\n  assertTrue(multimap.get(\"foo\") instanceof RandomAccess);\n  assertTrue(multimap.get(\"bar\") instanceof RandomAccess);\n}", "summary_tokens": ["confirm", "that", "get", "returns", "a", "list", "implementing", "random", "access"], "project": "guava"}
{"id": 1608, "code": "public static List<Integer> asList(int... backingArray) {\n  if (backingArray.length == 0) {\n    return Collections.emptyList();\n  }\n  return new IntArrayAsList(backingArray);\n}", "summary_tokens": ["returns", "a", "fixed", "size", "list", "backed", "by", "the", "specified", "array", "similar", "to", "arrays", "as", "list", "object"], "project": "guava"}
{"id": 1723, "code": "public static long max(long... array) {\n  checkArgument(array.length > 0);\n  long max = flip(array[0]);\n  for (int i = 1; i < array.length; i++) {\n    long next = flip(array[i]);\n    if (next > max) {\n      max = next;\n    }\n  }\n  return flip(max);\n}", "summary_tokens": ["returns", "the", "greatest", "value", "present", "in", "array", "treating", "values", "as", "unsigned"], "project": "guava"}
{"id": 1893, "code": "public int getWaitQueueLength(Guard guard) {\n  if (guard.monitor != this) {\n    throw new IllegalMonitorStateException();\n  }\n  lock.lock();\n  try {\n    return guard.waiterCount;\n  } finally {\n    lock.unlock();\n  }\n}", "summary_tokens": ["returns", "an", "estimate", "of", "the", "number", "of", "threads", "waiting", "for", "the", "given", "guard", "to", "become", "satisfied"], "project": "guava"}
{"id": 1586, "code": "public ImmutableLongArray trimmed() {\n  return isPartialView() ? new ImmutableLongArray(toArray()) : this;\n}", "summary_tokens": ["returns", "an", "immutable", "array", "containing", "the", "same", "values", "as", "this", "array"], "project": "guava"}
{"id": 961, "code": "public boolean hasUpperBound() {\n  return upperBound != Cut.aboveAll();\n}", "summary_tokens": ["returns", "true", "if", "this", "range", "has", "an", "upper", "endpoint"], "project": "guava"}
{"id": 500, "code": "public void testSuccessfulAsList_logging_exception() throws Exception {\n  assertEquals(\n      newArrayList((Object) null),\n      getDone(successfulAsList(immediateFailedFuture(new MyException()))));\n  assertWithMessage(\"Nothing should be logged\")\n      .that(aggregateFutureLogHandler.getStoredLogRecords())\n      .isEmpty();\n\n    \n  assertEquals(\n      newArrayList(null, null, null),\n      getDone(\n          successfulAsList(\n              immediateFailedFuture(new MyException()),\n              immediateFailedFuture(new MyException()),\n              immediateFailedFuture(new MyException()))));\n  assertWithMessage(\"Nothing should be logged\")\n      .that(aggregateFutureLogHandler.getStoredLogRecords())\n      .isEmpty();\n}", "summary_tokens": ["non", "error", "exceptions", "are", "never", "logged"], "project": "guava"}
{"id": 479, "code": "public void testDoubleValue() {\n  AtomicDouble at = new AtomicDouble();\n  assertEquals(0.0d, at.doubleValue());\n  for (double x : VALUES) {\n    at.set(x);\n    assertBitEquals(x, at.doubleValue());\n  }\n}", "summary_tokens": ["double", "value", "returns", "current", "value"], "project": "guava"}
{"id": 1576, "code": "public long get(int index) {\n  Preconditions.checkElementIndex(index, length());\n  return array[start + index];\n}", "summary_tokens": ["returns", "the", "long", "value", "present", "at", "the", "given", "index"], "project": "guava"}
{"id": 978, "code": "static <R, C, V> RegularImmutableTable<R, C, V> forOrderedComponents(\n    ImmutableList<Cell<R, C, V>> cellList,\n    ImmutableSet<R> rowSpace,\n    ImmutableSet<C> columnSpace) {\n    \n    \n  return (cellList.size() > (((long) rowSpace.size() * columnSpace.size()) / 2))\n      ? new DenseImmutableTable<R, C, V>(cellList, rowSpace, columnSpace)\n      : new SparseImmutableTable<R, C, V>(cellList, rowSpace, columnSpace);\n}", "summary_tokens": ["a", "factory", "that", "chooses", "the", "most", "space", "efficient", "representation", "of", "the", "table"], "project": "guava"}
{"id": 1933, "code": "protected Entry<E> standardPollLastEntry() {\n  Iterator<Entry<E>> entryIterator = descendingMultiset().entrySet().iterator();\n  if (!entryIterator.hasNext()) {\n    return null;\n  }\n  Entry<E> entry = entryIterator.next();\n  entry = Multisets.immutableEntry(entry.getElement(), entry.getCount());\n  entryIterator.remove();\n  return entry;\n}", "summary_tokens": ["a", "sensible", "definition", "of", "poll", "last", "entry", "in", "terms", "of", "descending", "multiset"], "project": "guava"}
{"id": 1354, "code": "public double max() {\n  checkState(count != 0);\n  return max;\n}", "summary_tokens": ["returns", "the", "highest", "value", "in", "the", "dataset"], "project": "guava"}
{"id": 128, "code": "<T> T instantiate(Class<T> cls)\n    throws ParameterNotInstantiableException, IllegalAccessException, InvocationTargetException,\n        FactoryMethodReturnsNullException {\n  if (cls.isEnum()) {\n    T[] constants = cls.getEnumConstants();\n    if (constants.length > 0) {\n      return constants[0];\n    } else {\n      return null;\n    }\n  }\n  TypeToken<T> type = TypeToken.of(cls);\n  List<ParameterNotInstantiableException> paramErrors = Lists.newArrayList();\n  List<InvocationTargetException> instantiationExceptions = Lists.newArrayList();\n  List<FactoryMethodReturnsNullException> nullErrors = Lists.newArrayList();\n  for (Invokable<?, ? extends T> factory : getFactories(type)) {\n    T instance;\n    try {\n      instance = instantiate(factory);\n    } catch (ParameterNotInstantiableException e) {\n      paramErrors.add(e);\n      continue;\n    } catch (InvocationTargetException e) {\n      instantiationExceptions.add(e);\n      continue;\n    }\n    if (instance == null) {\n      nullErrors.add(new FactoryMethodReturnsNullException(factory));\n    } else {\n      return instance;\n    }\n  }\n  throwFirst(paramErrors);\n  throwFirst(instantiationExceptions);\n  throwFirst(nullErrors);\n  return null;\n}", "summary_tokens": ["instantiates", "cls", "by", "invoking", "one", "of", "its", "non", "private", "constructors", "or", "non", "private", "static", "factory", "methods", "with", "the", "parameters", "automatically", "provided", "using", "dummy", "values"], "project": "guava"}
{"id": 1684, "code": "public UnsignedInteger mod(UnsignedInteger val) {\n  return fromIntBits(UnsignedInts.remainder(value, checkNotNull(val).value));\n}", "summary_tokens": ["returns", "this", "mod", "val"], "project": "guava"}
{"id": 575, "code": "public static boolean isLowerCase(char c) {\n    \n    \n  return (c >= 'a') && (c <= 'z');\n}", "summary_tokens": ["indicates", "whether", "c", "is", "one", "of", "the", "twenty", "six", "lowercase", "ascii", "alphabetic", "characters", "between", "a", "and", "z", "inclusive"], "project": "guava"}
{"id": 1348, "code": "public final double sum() {\n  return mean * count;\n}", "summary_tokens": ["returns", "the", "sum", "of", "the", "values"], "project": "guava"}
{"id": 931, "code": "public E pollFirst() {\n  return poll();\n}", "summary_tokens": ["removes", "and", "returns", "the", "least", "element", "of", "this", "queue", "or", "returns", "null", "if", "the", "queue", "is", "empty"], "project": "guava"}
{"id": 1746, "code": "public static <B> Builder<B> builder() {\n  return new Builder<>();\n}", "summary_tokens": ["returns", "a", "new", "builder"], "project": "guava"}
{"id": 1503, "code": "public static boolean isFinite(double value) {\n  return NEGATIVE_INFINITY < value && value < POSITIVE_INFINITY;\n}", "summary_tokens": ["returns", "true", "if", "value", "represents", "a", "real", "number"], "project": "guava"}
{"id": 1351, "code": "public final double sampleVariance() {\n  checkState(count > 1);\n  if (isNaN(sumOfSquaresOfDeltas)) {\n    return NaN;\n  }\n  return ensureNonNegative(sumOfSquaresOfDeltas) / (count - 1);\n}", "summary_tokens": ["returns", "the", "a", "href", "http", "en"], "project": "guava"}
{"id": 1143, "code": "public static HashFunction concatenating(Iterable<HashFunction> hashFunctions) {\n  checkNotNull(hashFunctions);\n    \n  List<HashFunction> list = new ArrayList<>();\n  for (HashFunction hashFunction : hashFunctions) {\n    list.add(hashFunction);\n  }\n  checkArgument(list.size() > 0, \"number of hash functions (%s) must be > 0\", list.size());\n  return new ConcatenatedHashFunction(list.toArray(new HashFunction[0]));\n}", "summary_tokens": ["returns", "a", "hash", "function", "which", "computes", "its", "hash", "code", "by", "concatenating", "the", "hash", "codes", "of", "the", "underlying", "hash", "functions", "together"], "project": "guava"}
{"id": 1389, "code": "public static TeredoInfo getTeredoInfo(Inet6Address ip) {\n  checkArgument(isTeredoAddress(ip), \"Address '%s' is not a Teredo address.\", toAddrString(ip));\n\n  byte[] bytes = ip.getAddress();\n  Inet4Address server = getInet4Address(Arrays.copyOfRange(bytes, 4, 8));\n\n  int flags = ByteStreams.newDataInput(bytes, 8).readShort() & 0xffff;\n\n    \n  int port = ~ByteStreams.newDataInput(bytes, 10).readShort() & 0xffff;\n\n  byte[] clientBytes = Arrays.copyOfRange(bytes, 12, 16);\n  for (int i = 0; i < clientBytes.length; i++) {\n      \n    clientBytes[i] = (byte) ~clientBytes[i];\n  }\n  Inet4Address client = getInet4Address(clientBytes);\n\n  return new TeredoInfo(server, client, port, flags);\n}", "summary_tokens": ["returns", "the", "teredo", "information", "embedded", "in", "a", "teredo", "address"], "project": "guava"}
{"id": 1834, "code": "public final double getAndSet(int i, double newValue) {\n  long next = doubleToRawLongBits(newValue);\n  return longBitsToDouble(longs.getAndSet(i, next));\n}", "summary_tokens": ["atomically", "sets", "the", "element", "at", "position", "i", "to", "the", "given", "value", "and", "returns", "the", "old", "value"], "project": "guava"}
{"id": 1696, "code": "public static int min(int... array) {\n  checkArgument(array.length > 0);\n  int min = flip(array[0]);\n  for (int i = 1; i < array.length; i++) {\n    int next = flip(array[i]);\n    if (next < min) {\n      min = next;\n    }\n  }\n  return flip(min);\n}", "summary_tokens": ["returns", "the", "least", "value", "present", "in", "array", "treating", "values", "as", "unsigned"], "project": "guava"}
{"id": 490, "code": "public void testAllAsList_doneFutures() throws Exception {\n    \n  SettableFuture<String> future1 = SettableFuture.create();\n  SettableFuture<String> future2 = SettableFuture.create();\n  SettableFuture<String> future3 = SettableFuture.create();\n\n    \n  future1.set(DATA1);\n  future2.set(DATA2);\n  future3.set(DATA3);\n\n  @SuppressWarnings(\"unchecked\") \n  ListenableFuture<List<String>> compound = allAsList(future1, future2, future3);\n\n    \n  SingleCallListener listener = new SingleCallListener();\n  listener.expectCall();\n  compound.addListener(listener, directExecutor());\n\n  assertTrue(listener.wasCalled());\n\n  List<String> results = getDone(compound);\n  assertThat(results).containsExactly(DATA1, DATA2, DATA3).inOrder();\n}", "summary_tokens": ["test", "the", "case", "where", "the", "futures", "are", "fulfilled", "prior", "to", "constructing", "the", "list", "future"], "project": "guava"}
{"id": 1942, "code": "public static Method getMergeNullValueMethod() {\n  return Helpers.getMethod(MapMergeTester.class, \"testMergeNullValue\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "merge", "null", "value", "so", "that", "tests", "of", "hashtable", "can", "suppress", "it", "with", "feature", "specific", "test", "suite", "builder"], "project": "guava"}
{"id": 1212, "code": "public void writeFloat(float v) throws IOException {\n  writeInt(Float.floatToIntBits(v));\n}", "summary_tokens": ["writes", "a", "float", "as", "specified", "by", "data", "output", "stream", "write", "float", "float", "except", "using", "little", "endian", "byte", "order"], "project": "guava"}
{"id": 1700, "code": "public static void sort(int[] array, int fromIndex, int toIndex) {\n  checkNotNull(array);\n  checkPositionIndexes(fromIndex, toIndex, array.length);\n  for (int i = fromIndex; i < toIndex; i++) {\n    array[i] = flip(array[i]);\n  }\n  Arrays.sort(array, fromIndex, toIndex);\n  for (int i = fromIndex; i < toIndex; i++) {\n    array[i] = flip(array[i]);\n  }\n}", "summary_tokens": ["sorts", "the", "array", "between", "from", "index", "inclusive", "and", "to", "index", "exclusive", "treating", "its", "elements", "as", "unsigned", "0", "bit", "integers"], "project": "guava"}
{"id": 1199, "code": "public String readLine() {\n  throw new UnsupportedOperationException(\"readLine is not supported\");\n}", "summary_tokens": ["this", "method", "will", "throw", "an", "unsupported", "operation", "exception"], "project": "guava"}
{"id": 1572, "code": "public static ImmutableLongArray copyOf(LongStream stream) {\n    \n  long[] array = stream.toArray();\n  return (array.length == 0) ? EMPTY : new ImmutableLongArray(array);\n}", "summary_tokens": ["returns", "an", "immutable", "array", "containing", "all", "the", "values", "from", "stream", "in", "order"], "project": "guava"}
{"id": 581, "code": "public static CharMatcher breakingWhitespace() {\n  return BreakingWhitespace.INSTANCE;\n}", "summary_tokens": ["determines", "whether", "a", "character", "is", "a", "breaking", "whitespace", "that", "is", "a", "whitespace", "which", "can", "be", "interpreted", "as", "a", "break", "between", "words", "for", "formatting", "purposes"], "project": "guava"}
{"id": 309, "code": "public void testNewHashMapWithExpectedSize_wontGrow() throws Exception {\n    \n    \n  assertTrue(bucketsOf(Maps.newHashMapWithExpectedSize(0)) <= 1);\n\n  for (int size = 1; size < 200; size++) {\n    assertWontGrow(\n        size, Maps.newHashMapWithExpectedSize(size), Maps.newHashMapWithExpectedSize(size));\n  }\n}", "summary_tokens": ["tests", "that", "n", "hmwes", "makes", "hash", "maps", "large", "enough", "that", "adding", "the", "expected", "number", "of", "elements", "won", "t", "cause", "a", "rehash"], "project": "guava"}
{"id": 256, "code": "private static void testConcurrentLoadingDefault(CacheBuilder<Object, Object> builder)\n    throws InterruptedException {\n\n  int count = 10;\n  final AtomicInteger callCount = new AtomicInteger();\n  final CountDownLatch startSignal = new CountDownLatch(count + 1);\n  final Object result = new Object();\n\n  LoadingCache<String, Object> cache =\n      builder.build(\n          new CacheLoader<String, Object>() {\n            @Override\n            public Object load(String key) throws InterruptedException {\n              callCount.incrementAndGet();\n              startSignal.await();\n              return result;\n            }\n          });\n\n  List<Object> resultArray = doConcurrentGet(cache, \"bar\", count, startSignal);\n\n  assertEquals(1, callCount.get());\n  for (int i = 0; i < count; i++) {\n    assertSame(\"result(\" + i + \") didn't match expected\", result, resultArray.get(i));\n  }\n}", "summary_tokens": ["on", "a", "successful", "concurrent", "computation", "only", "one", "thread", "does", "the", "work", "but", "all", "the", "threads", "get", "the", "same", "result"], "project": "guava"}
{"id": 291, "code": "void verifyThreadSafe() {\n  List<String> sample = Lists.newArrayList(\"a\", \"b\", \"c\");\n  for (int delta : new int[] {-1, 0, 1}) {\n    for (int i = 0; i < sample.size(); i++) {\n      Collection<String> misleading = Helpers.misleadingSizeCollection(delta);\n      List<String> expected = sample.subList(0, i);\n      misleading.addAll(expected);\n      assertEquals(\n          \"delta: \" + delta + \" sample size: \" + i,\n          Sets.newHashSet(expected),\n          copyOf(misleading));\n    }\n  }\n}", "summary_tokens": ["verify", "thread", "safety", "by", "using", "a", "collection", "whose", "size", "may", "be", "inconsistent", "with", "the", "actual", "number", "of", "elements"], "project": "guava"}
{"id": 483, "code": "protected void assertFinalStepThrowsIllegalStateException(ClosingFuture<?> closingFuture) {\n  try {\n    closingFuture.finishToFuture();\n    fail();\n  } catch (IllegalStateException expected) {\n  }\n  try {\n    closingFuture.finishToValueAndCloser(new NoOpValueAndCloserConsumer<>(), executor);\n    fail();\n  } catch (IllegalStateException expected) {\n  }\n}", "summary_tokens": ["asserts", "that", "marking", "this", "step", "a", "final", "step", "throws", "illegal", "state", "exception"], "project": "guava"}
{"id": 1634, "code": "public static <T> Class<T> wrap(Class<T> type) {\n  checkNotNull(type);\n\n    \n  @SuppressWarnings(\"unchecked\")\n  Class<T> wrapped = (Class<T>) PRIMITIVE_TO_WRAPPER_TYPE.get(type);\n  return (wrapped == null) ? type : wrapped;\n}", "summary_tokens": ["returns", "the", "corresponding", "wrapper", "type", "of", "type", "if", "it", "is", "a", "primitive", "type", "otherwise", "returns", "type", "itself"], "project": "guava"}
{"id": 1801, "code": "static <T> TypeToken<? extends T> toGenericType(Class<T> cls) {\n  if (cls.isArray()) {\n    Type arrayOfGenericType =\n        Types.newArrayType(\n              \n            toGenericType(cls.getComponentType()).runtimeType);\n    @SuppressWarnings(\"unchecked\") \n    TypeToken<? extends T> result = (TypeToken<? extends T>) of(arrayOfGenericType);\n    return result;\n  }\n  TypeVariable<Class<T>>[] typeParams = cls.getTypeParameters();\n  Type ownerType =\n      cls.isMemberClass() && !Modifier.isStatic(cls.getModifiers())\n          ? toGenericType(cls.getEnclosingClass()).runtimeType\n          : null;\n\n  if ((typeParams.length > 0) || ((ownerType != null) && ownerType != cls.getEnclosingClass())) {\n    @SuppressWarnings(\"unchecked\") \n    TypeToken<? extends T> type =\n        (TypeToken<? extends T>)\n            of(Types.newParameterizedTypeWithOwner(ownerType, cls, typeParams));\n    return type;\n  } else {\n    return of(cls);\n  }\n}", "summary_tokens": ["returns", "the", "type", "token", "representing", "the", "generic", "type", "declaration", "of", "cls"], "project": "guava"}
{"id": 1158, "code": "public void decrement() {\n  add(-1L);\n}", "summary_tokens": ["equivalent", "to", "add", "0"], "project": "guava"}
{"id": 969, "code": "public boolean isConnected(Range<C> other) {\n  return lowerBound.compareTo(other.upperBound) <= 0\n      && other.lowerBound.compareTo(upperBound) <= 0;\n}", "summary_tokens": ["returns", "true", "if", "there", "exists", "a", "possibly", "empty", "range", "which", "is", "encloses", "enclosed", "by", "both", "this", "range", "and", "other"], "project": "guava"}
{"id": 409, "code": "static void assertHorizontalLinearTransformation(LinearTransformation transformation, double y) {\n  assertThat(transformation.isHorizontal()).isTrue();\n  assertThat(transformation.isVertical()).isFalse();\n  assertThat(transformation.inverse().isHorizontal()).isFalse();\n  assertThat(transformation.inverse().isVertical()).isTrue();\n  assertThat(transformation.transform(-1.0)).isWithin(ALLOWED_ERROR).of(y);\n  assertThat(transformation.transform(1.0)).isWithin(ALLOWED_ERROR).of(y);\n  try {\n    transformation.inverse().transform(0.0);\n    fail(\"Expected IllegalStateException\");\n  } catch (IllegalStateException expected) {\n  }\n  assertThat(transformation.slope()).isWithin(ALLOWED_ERROR).of(0.0);\n  try {\n    transformation.inverse().slope();\n    fail(\"Expected IllegalStateException\");\n  } catch (IllegalStateException expected) {\n  }\n  assertThat(transformation.inverse()).isSameInstanceAs(transformation.inverse());\n  assertThat(transformation.inverse().inverse()).isSameInstanceAs(transformation);\n}", "summary_tokens": ["asserts", "that", "transformation", "is", "horizontal", "with", "the", "given", "value", "of", "y"], "project": "guava"}
{"id": 1447, "code": "static MediaType createTextType(String subtype) {\n  return create(TEXT_TYPE, subtype);\n}", "summary_tokens": ["creates", "a", "media", "type", "with", "the", "text", "type", "and", "the", "given", "subtype"], "project": "guava"}
{"id": 2006, "code": "public void forEach(DoubleConsumer consumer) {\n  checkNotNull(consumer);\n  for (int i = start; i < end; i++) {\n    consumer.accept(array[i]);\n  }\n}", "summary_tokens": ["invokes", "consumer", "for", "each", "value", "contained", "in", "this", "array", "in", "order"], "project": "guava"}
{"id": 1198, "code": "public String readLine() throws IOException {\n  while (lines.peek() == null) {\n    Java8Compatibility.clear(cbuf);\n      \n      \n    int read = (reader != null) ? reader.read(buf, 0, buf.length) : readable.read(cbuf);\n    if (read == -1) {\n      lineBuf.finish();\n      break;\n    }\n    lineBuf.add(buf, 0, read);\n  }\n  return lines.poll();\n}", "summary_tokens": ["reads", "a", "line", "of", "text"], "project": "guava"}
{"id": 1411, "code": "public boolean isPublicSuffix() {\n  return publicSuffixIndex == 0;\n}", "summary_tokens": ["indicates", "whether", "this", "domain", "name", "represents", "a", "i", "public", "suffix", "i", "as", "defined", "by", "the", "mozilla", "foundation", "s", "a", "href", "http", "publicsuffix"], "project": "guava"}
{"id": 819, "code": "public ImmutableList<E> subList(int fromIndex, int toIndex) {\n  checkPositionIndexes(fromIndex, toIndex, size());\n  int length = toIndex - fromIndex;\n  if (length == size()) {\n    return this;\n  } else if (length == 0) {\n    return of();\n  } else {\n    return subListUnchecked(fromIndex, toIndex);\n  }\n}", "summary_tokens": ["returns", "an", "immutable", "list", "of", "the", "elements", "between", "the", "specified", "from", "index", "inclusive", "and", "to", "index", "exclusive"], "project": "guava"}
{"id": 715, "code": "public CacheBuilder<K, V> expireAfterWrite(long duration, TimeUnit unit) {\n  checkState(\n      expireAfterWriteNanos == UNSET_INT,\n      \"expireAfterWrite was already set to %s ns\",\n      expireAfterWriteNanos);\n  checkArgument(duration >= 0, \"duration cannot be negative: %s %s\", duration, unit);\n  this.expireAfterWriteNanos = unit.toNanos(duration);\n  return this;\n}", "summary_tokens": ["specifies", "that", "each", "entry", "should", "be", "automatically", "removed", "from", "the", "cache", "once", "a", "fixed", "duration", "has", "elapsed", "after", "the", "entry", "s", "creation", "or", "the", "most", "recent", "replacement", "of", "its", "value"], "project": "guava"}
{"id": 206, "code": "private E extract() {\n  final E[] items = this.items;\n  E x = items[takeIndex];\n  items[takeIndex] = null;\n  takeIndex = inc(takeIndex);\n  --count;\n  return x;\n}", "summary_tokens": ["extracts", "element", "at", "current", "take", "position", "advances", "and", "signals"], "project": "guava"}
{"id": 981, "code": "public Comparator<? super R> rowComparator() {\n    \n  return requireNonNull(rowKeySet().comparator());\n}", "summary_tokens": ["returns", "the", "comparator", "that", "orders", "the", "rows"], "project": "guava"}
{"id": 1928, "code": "private static int doParseTrieToBuilder(\n    Deque<CharSequence> stack,\n    CharSequence encoded,\n    int start,\n    ImmutableMap.Builder<String, PublicSuffixType> builder) {\n\n  int encodedLen = encoded.length();\n  int idx = start;\n  char c = '\\0';\n\n    \n  for (; idx < encodedLen; idx++) {\n    c = encoded.charAt(idx);\n    if (c == '&' || c == '?' || c == '!' || c == ':' || c == ',') {\n      break;\n    }\n  }\n\n  stack.push(reverse(encoded.subSequence(start, idx)));\n\n  if (c == '!' || c == '?' || c == ':' || c == ',') {\n      \n      \n      \n      \n    String domain = PREFIX_JOINER.join(stack);\n    if (domain.length() > 0) {\n      builder.put(domain, PublicSuffixType.fromCode(c));\n    }\n  }\n  idx++;\n\n  if (c != '?' && c != ',') {\n    while (idx < encodedLen) {\n        \n      idx += doParseTrieToBuilder(stack, encoded, idx, builder);\n      if (encoded.charAt(idx) == '?' || encoded.charAt(idx) == ',') {\n          \n        idx++;\n        break;\n      }\n    }\n  }\n  stack.pop();\n  return idx - start;\n}", "summary_tokens": ["parses", "a", "trie", "node", "and", "returns", "the", "number", "of", "characters", "consumed"], "project": "guava"}
{"id": 1231, "code": "public static BigInteger divide(BigInteger p, BigInteger q, RoundingMode mode) {\n  BigDecimal pDec = new BigDecimal(p);\n  BigDecimal qDec = new BigDecimal(q);\n  return pDec.divide(qDec, 0, mode).toBigIntegerExact();\n}", "summary_tokens": ["returns", "the", "result", "of", "dividing", "p", "by", "q", "rounding", "using", "the", "specified", "rounding", "mode"], "project": "guava"}
{"id": 1891, "code": "public boolean hasQueuedThread(Thread thread) {\n  return lock.hasQueuedThread(thread);\n}", "summary_tokens": ["queries", "whether", "the", "given", "thread", "is", "waiting", "to", "enter", "this", "monitor"], "project": "guava"}
{"id": 142, "code": "private static Method[] getMostConcreteMethods(Class<?> type) {\n  Method[] methods = type.getMethods();\n  for (int i = 0; i < methods.length; i++) {\n    try {\n      methods[i] = type.getMethod(methods[i].getName(), methods[i].getParameterTypes());\n    } catch (Exception e) {\n      throwIfUnchecked(e);\n      throw new RuntimeException(e);\n    }\n  }\n  return methods;\n}", "summary_tokens": ["returns", "the", "most", "concrete", "public", "methods", "from", "type"], "project": "guava"}
{"id": 201, "code": "int assignDelimiter(int reps) {\n  int dummy = 0;\n  for (int i = 0; i < reps; i++) {\n    StringBuilder sb = new StringBuilder();\n    String delim = \"\";\n    for (String comp : components) {\n      sb.append(delim);\n      sb.append(comp);\n      delim = DELIMITER_STRING;\n    }\n    dummy ^= sb.toString().length();\n  }\n  return dummy;\n}", "summary_tokens": ["starts", "with", "an", "empty", "delimiter", "and", "changes", "to", "the", "desired", "value", "at", "the", "end", "of", "the", "iteration"], "project": "guava"}
{"id": 805, "code": "public static <K, V> Builder<K, V> builder() {\n  return new Builder<>();\n}", "summary_tokens": ["returns", "a", "new", "builder"], "project": "guava"}
{"id": 1679, "code": "public static UnsignedInteger valueOf(String string, int radix) {\n  return fromIntBits(UnsignedInts.parseUnsignedInt(string, radix));\n}", "summary_tokens": ["returns", "an", "unsigned", "integer", "holding", "the", "value", "of", "the", "specified", "string", "parsed", "as", "an", "unsigned", "int", "value", "in", "the", "specified", "radix"], "project": "guava"}
{"id": 165, "code": "private static boolean isEquals(Member member) {\n  if (!(member instanceof Method)) {\n    return false;\n  }\n  Method method = (Method) member;\n  if (!method.getName().contentEquals(\"equals\")) {\n    return false;\n  }\n  Class<?>[] parameters = method.getParameterTypes();\n  if (parameters.length != 1) {\n    return false;\n  }\n  if (!parameters[0].equals(Object.class)) {\n    return false;\n  }\n  return true;\n}", "summary_tokens": ["returns", "true", "if", "the", "given", "member", "is", "a", "method", "that", "overrides", "object", "equals", "object"], "project": "guava"}
{"id": 695, "code": "public static int encodedLength(CharSequence sequence) {\n    \n  int utf16Length = sequence.length();\n  int utf8Length = utf16Length;\n  int i = 0;\n\n    \n  while (i < utf16Length && sequence.charAt(i) < 0x80) {\n    i++;\n  }\n\n    \n  for (; i < utf16Length; i++) {\n    char c = sequence.charAt(i);\n    if (c < 0x800) {\n      utf8Length += ((0x7f - c) >>> 31); \n    } else {\n      utf8Length += encodedLengthGeneral(sequence, i);\n      break;\n    }\n  }\n\n  if (utf8Length < utf16Length) {\n      \n    throw new IllegalArgumentException(\n        \"UTF-8 length does not fit in int: \" + (utf8Length + (1L << 32)));\n  }\n  return utf8Length;\n}", "summary_tokens": ["returns", "the", "number", "of", "bytes", "in", "the", "utf", "0", "encoded", "form", "of", "sequence"], "project": "guava"}
{"id": 563, "code": "public void callAndAssertReturns(int expected, String methodName, Object... arguments)\n    throws Exception {\n  checkNotNull(methodName);\n  checkNotNull(arguments);\n  sendRequest(methodName, arguments);\n  assertEquals(expected, getResponse(methodName).getResult());\n}", "summary_tokens": ["causes", "this", "thread", "to", "call", "the", "named", "method", "and", "asserts", "that", "the", "call", "returns", "the", "expected", "int", "value"], "project": "guava"}
{"id": 20, "code": "public TestSuite createTestSuite() {\n  checkCanCreate();\n\n  logger.fine(\" Testing: \" + name);\n  logger.fine(\"Features: \" + formatFeatureSet(features));\n\n  FeatureUtil.addImpliedFeatures(features);\n\n  logger.fine(\"Expanded: \" + formatFeatureSet(features));\n\n    \n  List<Class<? extends AbstractTester>> testers = getTesters();\n\n  TestSuite suite = new TestSuite(name);\n  for (Class<? extends AbstractTester> testerClass : testers) {\n    TestSuite testerSuite =\n        makeSuiteForTesterClass((Class<? extends AbstractTester<?>>) testerClass);\n    if (testerSuite.countTestCases() > 0) {\n      suite.addTest(testerSuite);\n    }\n  }\n  return suite;\n}", "summary_tokens": ["creates", "a", "runnable", "junit", "test", "suite", "based", "on", "the", "criteria", "already", "given"], "project": "guava"}
{"id": 1043, "code": "public static <S> ElementOrder<S> insertion() {\n  return new ElementOrder<>(Type.INSERTION, null);\n}", "summary_tokens": ["returns", "an", "instance", "which", "specifies", "that", "insertion", "ordering", "is", "guaranteed"], "project": "guava"}
{"id": 1899, "code": "private boolean awaitNanos(Guard guard, long nanos, boolean signalBeforeWaiting)\n    throws InterruptedException {\n  boolean firstTime = true;\n  try {\n    do {\n      if (nanos <= 0L) {\n        return false;\n      }\n      if (firstTime) {\n        if (signalBeforeWaiting) {\n          signalNextWaiter();\n        }\n        beginWaitingFor(guard);\n        firstTime = false;\n      }\n      nanos = guard.condition.awaitNanos(nanos);\n    } while (!guard.isSatisfied());\n    return true;\n  } finally {\n    if (!firstTime) {\n      endWaitingFor(guard);\n    }\n  }\n}", "summary_tokens": ["caller", "should", "check", "before", "calling", "that", "guard", "is", "not", "satisfied"], "project": "guava"}
{"id": 1317, "code": "public static Scale quartiles() {\n  return scale(4);\n}", "summary_tokens": ["specifies", "the", "computation", "of", "quartiles", "i"], "project": "guava"}
{"id": 1388, "code": "public static boolean isTeredoAddress(Inet6Address ip) {\n  byte[] bytes = ip.getAddress();\n  return (bytes[0] == (byte) 0x20)\n      && (bytes[1] == (byte) 0x01)\n      && (bytes[2] == 0)\n      && (bytes[3] == 0);\n}", "summary_tokens": ["evaluates", "whether", "the", "argument", "is", "a", "teredo", "address"], "project": "guava"}
{"id": 412, "code": "static PairedStats createPairedStatsOf(List<Double> xValues, List<Double> yValues) {\n  return createFilledPairedStatsAccumulator(xValues, yValues).snapshot();\n}", "summary_tokens": ["creates", "a", "paired", "stats", "from", "with", "the", "given", "lists", "of", "x", "and", "y", "values", "which", "must", "be", "of", "the", "same", "size"], "project": "guava"}
{"id": 1523, "code": "public static boolean contains(float[] array, float target) {\n  for (float value : array) {\n    if (value == target) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "true", "if", "target", "is", "present", "as", "an", "element", "anywhere", "in", "array"], "project": "guava"}
{"id": 1579, "code": "public boolean contains(long target) {\n  return indexOf(target) >= 0;\n}", "summary_tokens": ["returns", "true", "if", "target", "is", "present", "at", "any", "index", "in", "this", "array"], "project": "guava"}
{"id": 395, "code": "protected final File getTempDir() throws IOException {\n  if (tempDir == null) {\n    tempDir = createTempDir();\n  }\n\n  return tempDir;\n}", "summary_tokens": ["gets", "a", "temp", "dir", "for", "testing"], "project": "guava"}
{"id": 1552, "code": "public int hashCode() {\n  int hash = 1;\n  for (int i = start; i < end; i++) {\n    hash *= 31;\n    hash += Doubles.hashCode(array[i]);\n  }\n  return hash;\n}", "summary_tokens": ["returns", "an", "unspecified", "hash", "code", "for", "the", "contents", "of", "this", "immutable", "array"], "project": "guava"}
{"id": 1709, "code": "public UnsignedLong plus(UnsignedLong val) {\n  return fromLongBits(this.value + checkNotNull(val).value);\n}", "summary_tokens": ["returns", "the", "result", "of", "adding", "this", "and", "val"], "project": "guava"}
{"id": 1182, "code": "public void write(CharSequence charSequence) throws IOException {\n  checkNotNull(charSequence);\n\n  Closer closer = Closer.create();\n  try {\n    Writer out = closer.register(openStream());\n    out.append(charSequence);\n    out.flush(); \n  } catch (Throwable e) {\n    throw closer.rethrow(e);\n  } finally {\n    closer.close();\n  }\n}", "summary_tokens": ["writes", "the", "given", "character", "sequence", "to", "this", "sink"], "project": "guava"}
{"id": 1760, "code": "final boolean isVolatile() {\n  return Modifier.isVolatile(getModifiers());\n}", "summary_tokens": ["returns", "true", "if", "the", "field", "is", "volatile"], "project": "guava"}
{"id": 708, "code": "public CacheBuilder<K, V> concurrencyLevel(int concurrencyLevel) {\n  checkState(\n      this.concurrencyLevel == UNSET_INT,\n      \"concurrency level was already set to %s\",\n      this.concurrencyLevel);\n  checkArgument(concurrencyLevel > 0);\n  this.concurrencyLevel = concurrencyLevel;\n  return this;\n}", "summary_tokens": ["guides", "the", "allowed", "concurrency", "among", "update", "operations"], "project": "guava"}
{"id": 1704, "code": "public static int decode(String stringValue) {\n  ParseRequest request = ParseRequest.fromString(stringValue);\n\n  try {\n    return parseUnsignedInt(request.rawValue, request.radix);\n  } catch (NumberFormatException e) {\n    NumberFormatException decodeException =\n        new NumberFormatException(\"Error parsing value: \" + stringValue);\n    decodeException.initCause(e);\n    throw decodeException;\n  }\n}", "summary_tokens": ["returns", "the", "unsigned", "int", "value", "represented", "by", "the", "given", "string"], "project": "guava"}
{"id": 617, "code": "public String collapseFrom(CharSequence sequence, char replacement) {\n    \n  int len = sequence.length();\n  for (int i = 0; i < len; i++) {\n    char c = sequence.charAt(i);\n    if (matches(c)) {\n      if (c == replacement && (i == len - 1 || !matches(sequence.charAt(i + 1)))) {\n          \n        i++;\n      } else {\n        StringBuilder builder = new StringBuilder(len).append(sequence, 0, i).append(replacement);\n        return finishCollapseFrom(sequence, i + 1, len, replacement, builder, true);\n      }\n    }\n  }\n    \n  return sequence.toString();\n}", "summary_tokens": ["returns", "a", "string", "copy", "of", "the", "input", "character", "sequence", "with", "each", "group", "of", "consecutive", "matching", "bmp", "characters", "replaced", "by", "a", "single", "replacement", "character"], "project": "guava"}
{"id": 730, "code": "public Map<K, V> loadAll(Iterable<? extends K> keys) throws Exception {\n    \n    \n  throw new UnsupportedLoadingOperationException();\n}", "summary_tokens": ["computes", "or", "retrieves", "the", "values", "corresponding", "to", "keys"], "project": "guava"}
{"id": 74, "code": "public Iterable<Entry<String, String>> order(List<Entry<String, String>> insertionOrder) {\n  return insertionOrder;\n}", "summary_tokens": ["returns", "the", "original", "element", "list", "unchanged"], "project": "guava"}
{"id": 1794, "code": "public final TypeToken<?> getComponentType() {\n  Type componentType = Types.getComponentType(runtimeType);\n  if (componentType == null) {\n    return null;\n  }\n  return of(componentType);\n}", "summary_tokens": ["returns", "the", "array", "component", "type", "if", "this", "type", "represents", "an", "array", "int", "t", "extends", "map", "string", "integer", "etc"], "project": "guava"}
{"id": 946, "code": "public static <C extends Comparable<?>> Range<C> closedOpen(C lower, C upper) {\n  return create(Cut.belowValue(lower), Cut.belowValue(upper));\n}", "summary_tokens": ["returns", "a", "range", "that", "contains", "all", "values", "greater", "than", "or", "equal", "to", "lower", "and", "strictly", "less", "than", "upper"], "project": "guava"}
{"id": 234, "code": "public void testUnloadableWithSecurityManager() throws Exception {\n  if (isJdk9OrHigher()) {\n    return;\n  }\n  Policy oldPolicy = Policy.getPolicy();\n  SecurityManager oldSecurityManager = System.getSecurityManager();\n  try {\n    Policy.setPolicy(new PermissivePolicy());\n    System.setSecurityManager(new SecurityManager());\n    doTestUnloadable();\n  } finally {\n    System.setSecurityManager(oldSecurityManager);\n    Policy.setPolicy(oldPolicy);\n  }\n}", "summary_tokens": ["tests", "that", "the", "use", "of", "a", "finalizable", "reference", "queue", "does", "not", "subsequently", "prevent", "the", "loader", "of", "that", "class", "from", "being", "garbage", "collected", "even", "if", "there", "is", "a", "security", "manager"], "project": "guava"}
{"id": 496, "code": "public void testAllAsList_logging_same_cause() throws Exception {\n  try {\n    MyException exception1 = new MyException();\n    MyException exception2 = new MyException();\n    MyException exception3 = new MyException();\n\n    MyException sameInstance = new MyException();\n    exception1.initCause(sameInstance);\n    exception2.initCause(sameInstance);\n    exception3.initCause(exception2);\n    getDone(allAsList(immediateFailedFuture(exception1), immediateFailedFuture(exception3)));\n    fail();\n  } catch (ExecutionException expected) {\n    assertThat(expected.getCause()).isInstanceOf(MyException.class);\n    assertEquals(\n        \"Nothing should be logged\", 0, aggregateFutureLogHandler.getStoredLogRecords().size());\n  }\n}", "summary_tokens": ["different", "exceptions", "happening", "on", "multiple", "futures", "with", "the", "same", "cause", "should", "not", "be", "logged"], "project": "guava"}
{"id": 906, "code": "public static <E> Interner<E> newStrongInterner() {\n  return newBuilder().strong().build();\n}", "summary_tokens": ["returns", "a", "new", "thread", "safe", "interner", "which", "retains", "a", "strong", "reference", "to", "each", "instance", "it", "has", "interned", "thus", "preventing", "these", "instances", "from", "being", "garbage", "collected"], "project": "guava"}
{"id": 758, "code": "Map<K, V> loadAll(Set<? extends K> keys, CacheLoader<? super K, V> loader)\n    throws ExecutionException {\n  checkNotNull(loader);\n  checkNotNull(keys);\n  Stopwatch stopwatch = Stopwatch.createStarted();\n  Map<K, V> result;\n  boolean success = false;\n  try {\n    @SuppressWarnings(\"unchecked\") \n    Map<K, V> map = (Map<K, V>) loader.loadAll(keys);\n    result = map;\n    success = true;\n  } catch (UnsupportedLoadingOperationException e) {\n    success = true;\n    throw e;\n  } catch (InterruptedException e) {\n    Thread.currentThread().interrupt();\n    throw new ExecutionException(e);\n  } catch (RuntimeException e) {\n    throw new UncheckedExecutionException(e);\n  } catch (Exception e) {\n    throw new ExecutionException(e);\n  } catch (Error e) {\n    throw new ExecutionError(e);\n  } finally {\n    if (!success) {\n      globalStatsCounter.recordLoadException(stopwatch.elapsed(NANOSECONDS));\n    }\n  }\n\n  if (result == null) {\n    globalStatsCounter.recordLoadException(stopwatch.elapsed(NANOSECONDS));\n    throw new InvalidCacheLoadException(loader + \" returned null map from loadAll\");\n  }\n\n  stopwatch.stop();\n    \n  boolean nullsPresent = false;\n  for (Entry<K, V> entry : result.entrySet()) {\n    K key = entry.getKey();\n    V value = entry.getValue();\n    if (key == null || value == null) {\n        \n      nullsPresent = true;\n    } else {\n      put(key, value);\n    }\n  }\n\n  if (nullsPresent) {\n    globalStatsCounter.recordLoadException(stopwatch.elapsed(NANOSECONDS));\n    throw new InvalidCacheLoadException(loader + \" returned null keys or values from loadAll\");\n  }\n\n    \n  globalStatsCounter.recordLoadSuccess(stopwatch.elapsed(NANOSECONDS));\n  return result;\n}", "summary_tokens": ["returns", "the", "result", "of", "calling", "cache", "loader", "load", "all", "or", "null", "if", "loader", "doesn", "t", "implement", "load", "all"], "project": "guava"}
{"id": 901, "code": "public final void clear() {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "table", "unmodified"], "project": "guava"}
{"id": 1074, "code": "public static <N, E> MutableNetwork<N, E> copyOf(Network<N, E> network) {\n  MutableNetwork<N, E> copy =\n      NetworkBuilder.from(network)\n          .expectedNodeCount(network.nodes().size())\n          .expectedEdgeCount(network.edges().size())\n          .build();\n  for (N node : network.nodes()) {\n    copy.addNode(node);\n  }\n  for (E edge : network.edges()) {\n    EndpointPair<N> endpointPair = network.incidentNodes(edge);\n    copy.addEdge(endpointPair.nodeU(), endpointPair.nodeV(), edge);\n  }\n  return copy;\n}", "summary_tokens": ["creates", "a", "mutable", "copy", "of", "network", "with", "the", "same", "nodes", "and", "edges"], "project": "guava"}
{"id": 1096, "code": "public static ValueGraphBuilder<Object, Object> directed() {\n  return new ValueGraphBuilder<>(true);\n}", "summary_tokens": ["returns", "a", "value", "graph", "builder", "for", "building", "directed", "graphs"], "project": "guava"}
{"id": 595, "code": "public static CharMatcher noneOf(CharSequence sequence) {\n  return anyOf(sequence).negate();\n}", "summary_tokens": ["returns", "a", "char", "matcher", "that", "matches", "any", "bmp", "character", "not", "present", "in", "the", "given", "character", "sequence"], "project": "guava"}
{"id": 375, "code": "static void check2BitAvalanche(HashFunction function, int trials, double epsilon) {\n  Random rand = new Random(0);\n  int keyBits = 32;\n  int hashBits = function.bits();\n  for (int bit1 = 0; bit1 < keyBits; bit1++) {\n    for (int bit2 = 0; bit2 < keyBits; bit2++) {\n      if (bit2 <= bit1) continue;\n      int delta = (1 << bit1) | (1 << bit2);\n      int[] same = new int[hashBits];\n      int[] diff = new int[hashBits];\n        \n      for (int j = 0; j < trials; j++) {\n        int key1 = rand.nextInt();\n          \n        int key2 = key1 ^ delta;\n          \n        int hash1 = function.hashInt(key1).asInt();\n        int hash2 = function.hashInt(key2).asInt();\n        for (int k = 0; k < hashBits; k++) {\n          if ((hash1 & (1 << k)) == (hash2 & (1 << k))) {\n            same[k] += 1;\n          } else {\n            diff[k] += 1;\n          }\n        }\n      }\n        \n      for (int j = 0; j < hashBits; j++) {\n        double prob = (double) diff[j] / (double) (diff[j] + same[j]);\n        Assert.assertEquals(0.50d, prob, epsilon);\n      }\n    }\n  }\n}", "summary_tokens": ["test", "for", "avalanche", "with", "0", "bit", "deltas"], "project": "guava"}
{"id": 171, "code": "public synchronized List<LogRecord> getStoredLogRecords() {\n  List<LogRecord> result = new ArrayList<>(list);\n  return Collections.unmodifiableList(result);\n}", "summary_tokens": ["returns", "a", "snapshot", "of", "the", "logged", "records"], "project": "guava"}
{"id": 129, "code": "public FactoryMethodReturnValueTester forAllPublicStaticMethods(Class<?> cls) {\n  ImmutableList.Builder<Invokable<?, ?>> builder = ImmutableList.builder();\n  for (Method method : cls.getDeclaredMethods()) {\n    Invokable<?, ?> invokable = Invokable.from(method);\n    invokable.setAccessible(true);\n    if (invokable.isPublic() && invokable.isStatic() && !invokable.isSynthetic()) {\n      builder.add(invokable);\n    }\n  }\n  return new FactoryMethodReturnValueTester(cls, builder.build(), \"public static methods\");\n}", "summary_tokens": ["returns", "an", "object", "responsible", "for", "performing", "sanity", "tests", "against", "the", "return", "values", "of", "all", "public", "static", "methods", "declared", "by", "cls", "excluding", "superclasses"], "project": "guava"}
{"id": 1614, "code": "public static int lastIndexOf(long[] array, long target) {\n  return lastIndexOf(array, target, 0, array.length);\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "last", "appearance", "of", "the", "value", "target", "in", "array"], "project": "guava"}
{"id": 460, "code": "public void testSerialization() throws Exception {\n  AtomicDoubleArray x = new AtomicDoubleArray(SIZE);\n  for (int i = 0; i < SIZE; i++) {\n    x.set(i, (double) -i);\n  }\n  AtomicDoubleArray y = serialClone(x);\n  assertTrue(x != y);\n  assertEquals(x.length(), y.length());\n  for (int i = 0; i < SIZE; i++) {\n    assertBitEquals(x.get(i), y.get(i));\n  }\n\n  AtomicDoubleArray a = new AtomicDoubleArray(VALUES);\n  AtomicDoubleArray b = serialClone(a);\n  assertFalse(a.equals(b));\n  assertFalse(b.equals(a));\n  assertEquals(a.length(), b.length());\n  for (int i = 0; i < VALUES.length; i++) {\n    assertBitEquals(a.get(i), b.get(i));\n  }\n}", "summary_tokens": ["a", "deserialized", "serialized", "array", "holds", "same", "values"], "project": "guava"}
{"id": 601, "code": "public CharMatcher precomputed() {\n  return Platform.precomputeCharMatcher(this);\n}", "summary_tokens": ["returns", "a", "char", "matcher", "functionally", "equivalent", "to", "this", "one", "but", "which", "may", "be", "faster", "to", "query", "than", "the", "original", "your", "mileage", "may", "vary"], "project": "guava"}
{"id": 421, "code": "public void testBadArguments_badchars() {\n  String msg =\n      \"Alphanumeric characters are always 'safe' \" + \"and should not be explicitly specified\";\n  try {\n    new PercentEscaper(\"-+#abc.!\", false);\n    fail(msg);\n  } catch (IllegalArgumentException expected) {\n    assertThat(expected).hasMessageThat().isEqualTo(msg);\n  }\n}", "summary_tokens": ["tests", "that", "specifying", "any", "alphanumeric", "characters", "as", "safe", "causes", "an", "illegal", "argument", "exception"], "project": "guava"}
{"id": 1038, "code": "protected final void validateEndpoints(EndpointPair<?> endpoints) {\n  checkNotNull(endpoints);\n  checkArgument(isOrderingCompatible(endpoints), ENDPOINTS_MISMATCH);\n}", "summary_tokens": ["throws", "an", "illegal", "argument", "exception", "if", "the", "ordering", "of", "endpoints", "is", "not", "compatible", "with", "the", "directionality", "of", "this", "graph"], "project": "guava"}
{"id": 25, "code": "public TestSuite createTestSuite() {\n  withFeatures(KNOWN_ORDER);\n  return super.createTestSuite();\n}", "summary_tokens": ["specifies", "collection", "feature", "known", "order", "for", "all", "list", "tests", "since", "lists", "have", "an", "iteration", "ordering", "corresponding", "to", "the", "insertion", "order"], "project": "guava"}
{"id": 1207, "code": "private byte readAndCheckByte() throws IOException, EOFException {\n  int b1 = in.read();\n\n  if (-1 == b1) {\n    throw new EOFException();\n  }\n\n  return (byte) b1;\n}", "summary_tokens": ["reads", "a", "byte", "from", "the", "input", "stream", "checking", "that", "the", "end", "of", "file", "eof", "has", "not", "been", "encountered"], "project": "guava"}
{"id": 619, "code": "public boolean apply(Character character) {\n  return matches(character);\n}", "summary_tokens": ["provided", "only", "to", "satisfy", "the", "predicate", "interface", "use", "matches", "instead"], "project": "guava"}
{"id": 1538, "code": "public static Float tryParse(String string) {\n  if (Doubles.FLOATING_POINT_PATTERN.matcher(string).matches()) {\n      \n      \n    try {\n      return Float.parseFloat(string);\n    } catch (NumberFormatException e) {\n        \n        \n    }\n  }\n  return null;\n}", "summary_tokens": ["parses", "the", "specified", "string", "as", "a", "single", "precision", "floating", "point", "value"], "project": "guava"}
{"id": 156, "code": "public void testStaticMethods(Class<?> c, Visibility minimalVisibility) {\n  for (Method method : minimalVisibility.getStaticMethods(c)) {\n    if (!isIgnored(method)) {\n      testMethod(null, method);\n    }\n  }\n}", "summary_tokens": ["runs", "test", "method", "on", "every", "static", "method", "of", "class", "c", "that", "has", "at", "least", "minimal", "visibility", "including", "those", "inherited", "from", "superclasses", "of", "the", "same", "package"], "project": "guava"}
{"id": 614, "code": "public String trimFrom(CharSequence sequence) {\n  int len = sequence.length();\n  int first;\n  int last;\n\n  for (first = 0; first < len; first++) {\n    if (!matches(sequence.charAt(first))) {\n      break;\n    }\n  }\n  for (last = len - 1; last > first; last--) {\n    if (!matches(sequence.charAt(last))) {\n      break;\n    }\n  }\n\n  return sequence.subSequence(first, last + 1).toString();\n}", "summary_tokens": ["returns", "a", "substring", "of", "the", "input", "character", "sequence", "that", "omits", "all", "matching", "bmp", "characters", "from", "the", "beginning", "and", "from", "the", "end", "of", "the", "string"], "project": "guava"}
{"id": 1812, "code": "protected final void notifyStopped() {\n  monitor.enter();\n  try {\n    State previous = state();\n    switch (previous) {\n      case NEW:\n      case TERMINATED:\n      case FAILED:\n        throw new IllegalStateException(\"Cannot notifyStopped() when the service is \" + previous);\n      case RUNNING:\n      case STARTING:\n      case STOPPING:\n        snapshot = new StateSnapshot(TERMINATED);\n        enqueueTerminatedEvent(previous);\n        break;\n    }\n  } finally {\n    monitor.leave();\n    dispatchListenerEvents();\n  }\n}", "summary_tokens": ["implementing", "classes", "should", "invoke", "this", "method", "once", "their", "service", "has", "stopped"], "project": "guava"}
{"id": 729, "code": "public ListenableFuture<V> reload(K key, V oldValue) throws Exception {\n  checkNotNull(key);\n  checkNotNull(oldValue);\n  return Futures.immediateFuture(load(key));\n}", "summary_tokens": ["computes", "or", "retrieves", "a", "replacement", "value", "corresponding", "to", "an", "already", "cached", "key"], "project": "guava"}
{"id": 1264, "code": "public static int factorial(int n) {\n  checkNonNegative(\"n\", n);\n  return (n < factorials.length) ? factorials[n] : Integer.MAX_VALUE;\n}", "summary_tokens": ["returns", "n", "that", "is", "the", "product", "of", "the", "first", "n", "positive", "integers", "0", "if", "n", "0", "or", "integer", "max", "value", "if", "the", "result", "does", "not", "fit", "in", "a", "int"], "project": "guava"}
{"id": 1903, "code": "public double acquire(int permits) {\n  long microsToWait = reserve(permits);\n  stopwatch.sleepMicrosUninterruptibly(microsToWait);\n  return 1.0 * microsToWait / SECONDS.toMicros(1L);\n}", "summary_tokens": ["acquires", "the", "given", "number", "of", "permits", "from", "this", "rate", "limiter", "blocking", "until", "the", "request", "can", "be", "granted"], "project": "guava"}
{"id": 1424, "code": "public InternetDomainName parent() {\n  checkState(hasParent(), \"Domain '%s' has no parent\", name);\n  return ancestor(1);\n}", "summary_tokens": ["returns", "an", "internet", "domain", "name", "that", "is", "the", "immediate", "ancestor", "of", "this", "one", "that", "is", "the", "current", "domain", "with", "the", "leftmost", "part", "removed"], "project": "guava"}
{"id": 714, "code": "public CacheBuilder<K, V> softValues() {\n  return setValueStrength(Strength.SOFT);\n}", "summary_tokens": ["specifies", "that", "each", "value", "not", "key", "stored", "in", "the", "cache", "should", "be", "wrapped", "in", "a", "soft", "reference", "by", "default", "strong", "references", "are", "used"], "project": "guava"}
{"id": 1741, "code": "static ImmutableSet<LocationInfo> locationsFrom(ClassLoader classloader) {\n  ImmutableSet.Builder<LocationInfo> builder = ImmutableSet.builder();\n  for (Map.Entry<File, ClassLoader> entry : getClassPathEntries(classloader).entrySet()) {\n    builder.add(new LocationInfo(entry.getKey(), entry.getValue()));\n  }\n  return builder.build();\n}", "summary_tokens": ["returns", "all", "locations", "that", "classloader", "and", "parent", "loaders", "load", "classes", "and", "resources", "from"], "project": "guava"}
{"id": 1244, "code": "static double ensureNonNegative(double value) {\n  checkArgument(!isNaN(value));\n  return Math.max(value, 0.0);\n}", "summary_tokens": ["returns", "its", "argument", "if", "it", "is", "non", "negative", "zero", "if", "it", "is", "negative"], "project": "guava"}
{"id": 1654, "code": "public static void sortDescending(short[] array, int fromIndex, int toIndex) {\n  checkNotNull(array);\n  checkPositionIndexes(fromIndex, toIndex, array.length);\n  Arrays.sort(array, fromIndex, toIndex);\n  reverse(array, fromIndex, toIndex);\n}", "summary_tokens": ["sorts", "the", "elements", "of", "array", "between", "from", "index", "inclusive", "and", "to", "index", "exclusive", "in", "descending", "order"], "project": "guava"}
{"id": 1697, "code": "public static int max(int... array) {\n  checkArgument(array.length > 0);\n  int max = flip(array[0]);\n  for (int i = 1; i < array.length; i++) {\n    int next = flip(array[i]);\n    if (next > max) {\n      max = next;\n    }\n  }\n  return flip(max);\n}", "summary_tokens": ["returns", "the", "greatest", "value", "present", "in", "array", "treating", "values", "as", "unsigned"], "project": "guava"}
{"id": 1240, "code": "public static double factorial(int n) {\n  checkNonNegative(\"n\", n);\n  if (n > MAX_FACTORIAL) {\n    return Double.POSITIVE_INFINITY;\n  } else {\n      \n      \n    double accum = 1.0;\n    for (int i = 1 + (n & ~0xf); i <= n; i++) {\n      accum *= i;\n    }\n    return accum * everySixteenthFactorial[n >> 4];\n  }\n}", "summary_tokens": ["returns", "n", "that", "is", "the", "product", "of", "the", "first", "n", "positive", "integers", "0", "if", "n", "0", "or", "n", "or", "double", "positive", "infinity", "if", "n", "double"], "project": "guava"}
{"id": 1930, "code": "protected Entry<E> standardFirstEntry() {\n  Iterator<Entry<E>> entryIterator = entrySet().iterator();\n  if (!entryIterator.hasNext()) {\n    return null;\n  }\n  Entry<E> entry = entryIterator.next();\n  return Multisets.immutableEntry(entry.getElement(), entry.getCount());\n}", "summary_tokens": ["a", "sensible", "definition", "of", "first", "entry", "in", "terms", "of", "entry", "set"], "project": "guava"}
{"id": 1281, "code": "public static long mod(long x, long m) {\n  if (m <= 0) {\n    throw new ArithmeticException(\"Modulus must be positive\");\n  }\n  long result = x % m;\n  return (result >= 0) ? result : result + m;\n}", "summary_tokens": ["returns", "x", "mod", "m", "a", "non", "negative", "value", "less", "than", "m"], "project": "guava"}
{"id": 318, "code": "public void testInvalidatingRemove() {\n  MinMaxPriorityQueue<Integer> mmHeap = MinMaxPriorityQueue.create();\n  mmHeap.addAll(\n      Lists.newArrayList(1, 20, 1000, 2, 3, 30, 40, 10, 11, 12, 13, 300, 400, 500, 600));\n  assertEquals(15, mmHeap.size());\n  assertTrue(\"Heap is not intact initially\", mmHeap.isIntact());\n  mmHeap.remove(12);\n  assertEquals(14, mmHeap.size());\n  assertTrue(\"Heap is not intact after remove()\", mmHeap.isIntact());\n}", "summary_tokens": ["this", "tests", "a", "special", "case", "of", "the", "remove", "at", "call"], "project": "guava"}
{"id": 1081, "code": "public <N1 extends N, E1 extends E> ImmutableNetwork.Builder<N1, E1> immutable() {\n  NetworkBuilder<N1, E1> castBuilder = cast();\n  return new ImmutableNetwork.Builder<>(castBuilder);\n}", "summary_tokens": ["returns", "an", "immutable", "network"], "project": "guava"}
{"id": 1022, "code": "void invokeSubscriberMethod(Object event) throws InvocationTargetException {\n  try {\n    method.invoke(target, checkNotNull(event));\n  } catch (IllegalArgumentException e) {\n    throw new Error(\"Method rejected target/argument: \" + event, e);\n  } catch (IllegalAccessException e) {\n    throw new Error(\"Method became inaccessible: \" + event, e);\n  } catch (InvocationTargetException e) {\n    if (e.getCause() instanceof Error) {\n      throw (Error) e.getCause();\n    }\n    throw e;\n  }\n}", "summary_tokens": ["invokes", "the", "subscriber", "method"], "project": "guava"}
{"id": 1725, "code": "public static Comparator<long[]> lexicographicalComparator() {\n  return LexicographicalComparator.INSTANCE;\n}", "summary_tokens": ["returns", "a", "comparator", "that", "compares", "two", "arrays", "of", "unsigned", "long", "values", "a", "href", "http", "en"], "project": "guava"}
{"id": 1584, "code": "public int hashCode() {\n  int hash = 1;\n  for (int i = start; i < end; i++) {\n    hash *= 31;\n    hash += Longs.hashCode(array[i]);\n  }\n  return hash;\n}", "summary_tokens": ["returns", "an", "unspecified", "hash", "code", "for", "the", "contents", "of", "this", "immutable", "array"], "project": "guava"}
{"id": 2005, "code": "public static Collector<Number, StatsAccumulator, Stats> toStats() {\n  return Collector.of(\n      StatsAccumulator::new,\n      (a, x) -> a.add(x.doubleValue()),\n      (l, r) -> {\n        l.addAll(r);\n        return l;\n      },\n      StatsAccumulator::snapshot,\n      Collector.Characteristics.UNORDERED);\n}", "summary_tokens": ["returns", "a", "collector", "which", "accumulates", "statistics", "from", "a", "java"], "project": "guava"}
{"id": 197, "code": "int joinerWithCharacterDelimiter(int reps) {\n  int dummy = 0;\n  for (int i = 0; i < reps; i++) {\n    dummy ^= JOINER_ON_CHARACTER.join(components).length();\n  }\n  return dummy;\n}", "summary_tokens": ["joiner", "with", "a", "character", "delimiter"], "project": "guava"}
{"id": 1622, "code": "public static Long tryParse(String string, int radix) {\n  if (checkNotNull(string).isEmpty()) {\n    return null;\n  }\n  if (radix < Character.MIN_RADIX || radix > Character.MAX_RADIX) {\n    throw new IllegalArgumentException(\n        \"radix must be between MIN_RADIX and MAX_RADIX but was \" + radix);\n  }\n  boolean negative = string.charAt(0) == '-';\n  int index = negative ? 1 : 0;\n  if (index == string.length()) {\n    return null;\n  }\n  int digit = AsciiDigits.digit(string.charAt(index++));\n  if (digit < 0 || digit >= radix) {\n    return null;\n  }\n  long accum = -digit;\n\n  long cap = Long.MIN_VALUE / radix;\n\n  while (index < string.length()) {\n    digit = AsciiDigits.digit(string.charAt(index++));\n    if (digit < 0 || digit >= radix || accum < cap) {\n      return null;\n    }\n    accum *= radix;\n    if (accum < Long.MIN_VALUE + digit) {\n      return null;\n    }\n    accum -= digit;\n  }\n\n  if (negative) {\n    return accum;\n  } else if (accum == Long.MIN_VALUE) {\n    return null;\n  } else {\n    return -accum;\n  }\n}", "summary_tokens": ["parses", "the", "specified", "string", "as", "a", "signed", "long", "value", "using", "the", "specified", "radix"], "project": "guava"}
{"id": 1730, "code": "public static long parseUnsignedLong(String string, int radix) {\n  checkNotNull(string);\n  if (string.length() == 0) {\n    throw new NumberFormatException(\"empty string\");\n  }\n  if (radix < Character.MIN_RADIX || radix > Character.MAX_RADIX) {\n    throw new NumberFormatException(\"illegal radix: \" + radix);\n  }\n\n  int maxSafePos = ParseOverflowDetection.maxSafeDigits[radix] - 1;\n  long value = 0;\n  for (int pos = 0; pos < string.length(); pos++) {\n    int digit = Character.digit(string.charAt(pos), radix);\n    if (digit == -1) {\n      throw new NumberFormatException(string);\n    }\n    if (pos > maxSafePos && ParseOverflowDetection.overflowInParse(value, digit, radix)) {\n      throw new NumberFormatException(\"Too large for unsigned long: \" + string);\n    }\n    value = (value * radix) + digit;\n  }\n\n  return value;\n}", "summary_tokens": ["returns", "the", "unsigned", "long", "value", "represented", "by", "a", "string", "with", "the", "given", "radix"], "project": "guava"}
{"id": 236, "code": "private static boolean isJdk9OrHigher() {\n  return JAVA_SPECIFICATION_VERSION.value().startsWith(\"9\")\n      || JAVA_SPECIFICATION_VERSION.value().startsWith(\"10\");\n}", "summary_tokens": ["these", "tests", "fail", "in", "jdk", "0", "and", "jdk", "0", "for", "an", "unknown", "reason"], "project": "guava"}
{"id": 1414, "code": "public boolean isUnderPublicSuffix() {\n  return publicSuffixIndex > 0;\n}", "summary_tokens": ["indicates", "whether", "this", "domain", "name", "ends", "in", "a", "is", "public", "suffix", "public", "suffix", "while", "not", "being", "a", "public", "suffix", "itself"], "project": "guava"}
{"id": 551, "code": "public void testTimeToWarmUpIsHonouredEvenWithWeights() {\n  Random random = new Random();\n  int warmupPermits = 10;\n  double[] coldFactorsToTest = {2.0, 3.0, 10.0};\n  double[] qpsToTest = {4.0, 2.0, 1.0, 0.5, 0.1};\n  for (int trial = 0; trial < 100; trial++) {\n    for (double coldFactor : coldFactorsToTest) {\n      for (double qps : qpsToTest) {\n          \n          \n        long warmupMillis = (long) ((1 + coldFactor) * warmupPermits / (2.0 * qps) * 1000.0);\n        RateLimiter rateLimiter =\n            RateLimiter.create(qps, warmupMillis, MILLISECONDS, coldFactor, stopwatch);\n        assertEquals(warmupMillis, measureTotalTimeMillis(rateLimiter, warmupPermits, random));\n      }\n    }\n  }\n}", "summary_tokens": ["this", "neat", "test", "shows", "that", "no", "matter", "what", "weights", "we", "use", "in", "our", "requests", "if", "we", "push", "x", "amount", "of", "permits", "in", "a", "cool", "state", "where", "x", "rate", "time", "to", "cool", "down", "and", "we", "have", "specified", "a", "time", "to", "warm", "up", "period", "it", "will", "cost", "as", "the", "prescribed", "amount", "of", "time"], "project": "guava"}
{"id": 1026, "code": "public Object getEvent() {\n  return event;\n}", "summary_tokens": ["the", "event", "object", "that", "caused", "the", "subscriber", "to", "throw"], "project": "guava"}
{"id": 1183, "code": "public void writeLines(Stream<? extends CharSequence> lines, String lineSeparator)\n    throws IOException {\n  writeLines(lines.iterator(), lineSeparator);\n}", "summary_tokens": ["writes", "the", "given", "lines", "of", "text", "to", "this", "sink", "with", "each", "line", "including", "the", "last", "terminated", "with", "the", "given", "line", "separator"], "project": "guava"}
{"id": 845, "code": "public final boolean remove(@CheckForNull Object key, @CheckForNull Object value) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "multimap", "unmodified"], "project": "guava"}
{"id": 424, "code": "static void assertBasicUrlEscaperExceptPercent(UnicodeEscaper e) {\n    \n  try {\n    e.escape((String) null);\n    fail(\"Escaping null string should throw exception\");\n  } catch (NullPointerException x) {\n      \n  }\n\n    \n  assertUnescaped(e, 'a');\n  assertUnescaped(e, 'z');\n  assertUnescaped(e, 'A');\n  assertUnescaped(e, 'Z');\n  assertUnescaped(e, '0');\n  assertUnescaped(e, '9');\n\n    \n  assertUnescaped(e, '-');\n  assertUnescaped(e, '_');\n  assertUnescaped(e, '.');\n  assertUnescaped(e, '*');\n\n  assertEscaping(e, \"%00\", '\\u0000'); \n  assertEscaping(e, \"%7F\", '\\u007f'); \n  assertEscaping(e, \"%C2%80\", '\\u0080'); \n  assertEscaping(e, \"%DF%BF\", '\\u07ff'); \n  assertEscaping(e, \"%E0%A0%80\", '\\u0800'); \n  assertEscaping(e, \"%EF%BF%BF\", '\\uffff'); \n  assertUnicodeEscaping(e, \"%F0%90%80%80\", '\\uD800', '\\uDC00');\n  assertUnicodeEscaping(e, \"%F4%8F%BF%BF\", '\\uDBFF', '\\uDFFF');\n\n  assertEquals(\"\", e.escape(\"\"));\n  assertEquals(\"safestring\", e.escape(\"safestring\"));\n  assertEquals(\"embedded%00null\", e.escape(\"embedded\\0null\"));\n  assertEquals(\"max%EF%BF%BFchar\", e.escape(\"max\\uffffchar\"));\n}", "summary_tokens": ["helper", "to", "assert", "common", "expected", "behaviour", "of", "uri", "escapers"], "project": "guava"}
{"id": 791, "code": "public static <K extends Enum<K>, V extends Enum<V>> EnumBiMap<K, V> create(Map<K, V> map) {\n  EnumBiMap<K, V> bimap = create(inferKeyType(map), inferValueType(map));\n  bimap.putAll(map);\n  return bimap;\n}", "summary_tokens": ["returns", "a", "new", "bimap", "with", "the", "same", "mappings", "as", "the", "specified", "map"], "project": "guava"}
{"id": 1650, "code": "public static Converter<String, Short> stringConverter() {\n  return ShortConverter.INSTANCE;\n}", "summary_tokens": ["returns", "a", "serializable", "converter", "object", "that", "converts", "between", "strings", "and", "shorts", "using", "short", "decode", "and", "short", "to", "string"], "project": "guava"}
{"id": 1818, "code": "public final double getAndSet(double newValue) {\n  long next = doubleToRawLongBits(newValue);\n  return longBitsToDouble(updater.getAndSet(this, next));\n}", "summary_tokens": ["atomically", "sets", "to", "the", "given", "value", "and", "returns", "the", "old", "value"], "project": "guava"}
{"id": 1530, "code": "public static Converter<String, Float> stringConverter() {\n  return FloatConverter.INSTANCE;\n}", "summary_tokens": ["returns", "a", "serializable", "converter", "object", "that", "converts", "between", "strings", "and", "floats", "using", "float", "value", "of", "and", "float", "to", "string"], "project": "guava"}
{"id": 915, "code": "public String toString() {\n  MoreObjects.ToStringHelper s = MoreObjects.toStringHelper(this);\n  if (initialCapacity != UNSET_INT) {\n    s.add(\"initialCapacity\", initialCapacity);\n  }\n  if (concurrencyLevel != UNSET_INT) {\n    s.add(\"concurrencyLevel\", concurrencyLevel);\n  }\n  if (keyStrength != null) {\n    s.add(\"keyStrength\", Ascii.toLowerCase(keyStrength.toString()));\n  }\n  if (valueStrength != null) {\n    s.add(\"valueStrength\", Ascii.toLowerCase(valueStrength.toString()));\n  }\n  if (keyEquivalence != null) {\n    s.addValue(\"keyEquivalence\");\n  }\n  return s.toString();\n}", "summary_tokens": ["returns", "a", "string", "representation", "for", "this", "map", "maker", "instance"], "project": "guava"}
{"id": 520, "code": "Date delayedDate(long delayMillis) {\n  return new Date(System.currentTimeMillis() + delayMillis);\n}", "summary_tokens": ["returns", "a", "new", "date", "instance", "representing", "a", "time", "delay", "millis", "milliseconds", "in", "the", "future"], "project": "guava"}
{"id": 1220, "code": "private static int availableCapacity(Buffer buffer) {\n  return buffer.capacity() - buffer.limit();\n}", "summary_tokens": ["returns", "the", "number", "of", "elements", "between", "the", "limit", "and", "capacity"], "project": "guava"}
{"id": 1306, "code": "public void add(double x, double y) {\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  xStats.add(x);\n  if (isFinite(x) && isFinite(y)) {\n    if (xStats.count() > 1) {\n      sumOfProductsOfDeltas += (x - xStats.mean()) * (y - yStats.mean());\n    }\n  } else {\n    sumOfProductsOfDeltas = NaN;\n  }\n  yStats.add(y);\n}", "summary_tokens": ["adds", "the", "given", "pair", "of", "values", "to", "the", "dataset"], "project": "guava"}
{"id": 711, "code": "public <K1 extends K, V1 extends V> CacheBuilder<K1, V1> weigher(\n    Weigher<? super K1, ? super V1> weigher) {\n  checkState(this.weigher == null);\n  if (strictParsing) {\n    checkState(\n        this.maximumSize == UNSET_INT,\n        \"weigher can not be combined with maximum size\",\n        this.maximumSize);\n  }\n\n    \n  @SuppressWarnings(\"unchecked\")\n  CacheBuilder<K1, V1> me = (CacheBuilder<K1, V1>) this;\n  me.weigher = checkNotNull(weigher);\n  return me;\n}", "summary_tokens": ["specifies", "the", "weigher", "to", "use", "in", "determining", "the", "weight", "of", "entries"], "project": "guava"}
{"id": 1200, "code": "public int readUnsignedShort() throws IOException {\n  byte b1 = readAndCheckByte();\n  byte b2 = readAndCheckByte();\n\n  return Ints.fromBytes((byte) 0, (byte) 0, b2, b1);\n}", "summary_tokens": ["reads", "an", "unsigned", "short", "as", "specified", "by", "data", "input", "stream", "read", "unsigned", "short", "except", "using", "little", "endian", "byte", "order"], "project": "guava"}
{"id": 192, "code": "public void testOf_NullPointerException() {\n  try {\n    EquivalenceTester.of(null);\n    fail(\"Should fail on null reference\");\n  } catch (NullPointerException expected) {\n  }\n}", "summary_tokens": ["test", "null", "reference", "yields", "error"], "project": "guava"}
{"id": 1736, "code": "public static ClassPath from(ClassLoader classloader) throws IOException {\n  ImmutableSet<LocationInfo> locations = locationsFrom(classloader);\n\n    \n    \n  Set<File> scanned = new HashSet<>();\n  for (LocationInfo location : locations) {\n    scanned.add(location.file());\n  }\n\n    \n  ImmutableSet.Builder<ResourceInfo> builder = ImmutableSet.builder();\n  for (LocationInfo location : locations) {\n    builder.addAll(location.scanResources(scanned));\n  }\n  return new ClassPath(builder.build());\n}", "summary_tokens": ["returns", "a", "class", "path", "representing", "all", "classes", "and", "resources", "loadable", "from", "classloader", "and", "its", "ancestor", "class", "loaders"], "project": "guava"}
{"id": 986, "code": "public static <C extends Comparable<?>> TreeRangeSet<C> create(Iterable<Range<C>> ranges) {\n  TreeRangeSet<C> result = create();\n  result.addAll(ranges);\n  return result;\n}", "summary_tokens": ["returns", "a", "tree", "range", "set", "representing", "the", "union", "of", "the", "specified", "ranges"], "project": "guava"}
{"id": 1418, "code": "public boolean hasRegistrySuffix() {\n  return registrySuffixIndex != NO_SUFFIX_FOUND;\n}", "summary_tokens": ["indicates", "whether", "this", "domain", "name", "ends", "in", "a", "is", "registry", "suffix", "registry", "suffix", "including", "if", "it", "is", "a", "registry", "suffix", "itself"], "project": "guava"}
{"id": 2004, "code": "private static void throwDeleteFailed(Path path, Collection<IOException> exceptions)\n    throws FileSystemException {\n  NoSuchFileException pathNotFound = pathNotFound(path, exceptions);\n  if (pathNotFound != null) {\n    throw pathNotFound;\n  }\n    \n    \n    \n  FileSystemException deleteFailed =\n      new FileSystemException(\n          path.toString(),\n          null,\n          \"failed to delete one or more files; see suppressed exceptions for details\");\n  for (IOException e : exceptions) {\n    deleteFailed.addSuppressed(e);\n  }\n  throw deleteFailed;\n}", "summary_tokens": ["throws", "an", "exception", "indicating", "that", "one", "or", "more", "files", "couldn", "t", "be", "deleted", "when", "deleting", "path", "or", "its", "contents"], "project": "guava"}
{"id": 860, "code": "public final void put(Range<K> range, V value) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "range", "map", "unmodified"], "project": "guava"}
{"id": 2012, "code": "public final double getAndAccumulate(double x, DoubleBinaryOperator accumulatorFunction) {\n  checkNotNull(accumulatorFunction);\n  return getAndUpdate(oldValue -> accumulatorFunction.applyAsDouble(oldValue, x));\n}", "summary_tokens": ["atomically", "updates", "the", "current", "value", "with", "the", "results", "of", "applying", "the", "given", "function", "to", "the", "current", "and", "given", "values"], "project": "guava"}
{"id": 78, "code": "public static <E> void assertSetIsUnmodifiable(Set<E> set, E sampleElement) {\n  assertCollectionIsUnmodifiable(set, sampleElement);\n}", "summary_tokens": ["verifies", "that", "a", "set", "is", "immutable"], "project": "guava"}
{"id": 584, "code": "public static CharMatcher javaDigit() {\n  return JavaDigit.INSTANCE;\n}", "summary_tokens": ["determines", "whether", "a", "character", "is", "a", "bmp", "digit", "according", "to", "character", "is", "digit", "char", "java", "s", "definition"], "project": "guava"}
{"id": 252, "code": "public void testRemovalNotification_get_basher() throws InterruptedException {\n  int nTasks = 1000;\n  int nThreads = 100;\n  final int getsPerTask = 1000;\n  final int nUniqueKeys = 10000;\n  final Random random = new Random(); \n\n  QueuingRemovalListener<String, String> removalListener = queuingRemovalListener();\n  final AtomicInteger computeCount = new AtomicInteger();\n  final AtomicInteger exceptionCount = new AtomicInteger();\n  final AtomicInteger computeNullCount = new AtomicInteger();\n  CacheLoader<String, String> countingIdentityLoader =\n      new CacheLoader<String, String>() {\n        @Override\n        public String load(String key) throws InterruptedException {\n          int behavior = random.nextInt(4);\n          if (behavior == 0) { \n            exceptionCount.incrementAndGet();\n            throw new RuntimeException(\"fake exception for test\");\n          } else if (behavior == 1) { \n            computeNullCount.incrementAndGet();\n            return null;\n          } else if (behavior == 2) { \n            Thread.sleep(5);\n            computeCount.incrementAndGet();\n            return key;\n          } else {\n            computeCount.incrementAndGet();\n            return key;\n          }\n        }\n      };\n  final LoadingCache<String, String> cache =\n      CacheBuilder.newBuilder()\n          .recordStats()\n          .concurrencyLevel(2)\n          .expireAfterWrite(100, MILLISECONDS)\n          .removalListener(removalListener)\n          .maximumSize(5000)\n          .build(countingIdentityLoader);\n\n  ExecutorService threadPool = Executors.newFixedThreadPool(nThreads);\n  for (int i = 0; i < nTasks; i++) {\n    @SuppressWarnings(\"unused\") \n    Future<?> possiblyIgnoredError =\n        threadPool.submit(\n            new Runnable() {\n              @Override\n              public void run() {\n                for (int j = 0; j < getsPerTask; j++) {\n                  try {\n                    cache.getUnchecked(\"key\" + random.nextInt(nUniqueKeys));\n                  } catch (RuntimeException e) {\n                  }\n                }\n              }\n            });\n  }\n\n  threadPool.shutdown();\n  threadPool.awaitTermination(300, SECONDS);\n\n    \n    \n\n    \n  for (RemovalNotification<String, String> notification : removalListener) {\n    assertEquals(\"Invalid removal notification\", notification.getKey(), notification.getValue());\n  }\n\n  CacheStats stats = cache.stats();\n  assertEquals(removalListener.size(), stats.evictionCount());\n  assertEquals(computeCount.get(), stats.loadSuccessCount());\n  assertEquals(exceptionCount.get() + computeNullCount.get(), stats.loadExceptionCount());\n    \n  assertEquals(computeCount.get(), cache.size() + removalListener.size());\n}", "summary_tokens": ["calls", "get", "repeatedly", "from", "many", "different", "threads", "and", "tests", "that", "all", "of", "the", "removed", "entries", "removed", "because", "of", "size", "limits", "or", "expiration", "trigger", "appropriate", "removal", "notifications"], "project": "guava"}
{"id": 379, "code": "public void testGoodFastHashEquals() throws Exception {\n  HashFunction hashFunction1a = Hashing.goodFastHash(1);\n  HashFunction hashFunction1b = Hashing.goodFastHash(32);\n  HashFunction hashFunction2a = Hashing.goodFastHash(33);\n  HashFunction hashFunction2b = Hashing.goodFastHash(128);\n  HashFunction hashFunction3a = Hashing.goodFastHash(129);\n  HashFunction hashFunction3b = Hashing.goodFastHash(256);\n  HashFunction hashFunction4a = Hashing.goodFastHash(257);\n  HashFunction hashFunction4b = Hashing.goodFastHash(384);\n\n  new EqualsTester()\n      .addEqualityGroup(hashFunction1a, hashFunction1b)\n      .addEqualityGroup(hashFunction2a, hashFunction2b)\n      .addEqualityGroup(hashFunction3a, hashFunction3b)\n      .addEqualityGroup(hashFunction4a, hashFunction4b)\n      .testEquals();\n\n  assertEquals(hashFunction1a.toString(), hashFunction1b.toString());\n  assertEquals(hashFunction2a.toString(), hashFunction2b.toString());\n  assertEquals(hashFunction3a.toString(), hashFunction3b.toString());\n  assertEquals(hashFunction4a.toString(), hashFunction4b.toString());\n}", "summary_tokens": ["tests", "equality", "of", "hashing", "good", "fast", "hash", "instances"], "project": "guava"}
{"id": 223, "code": "public boolean remove(@Nullable Object o) {\n  final Monitor monitor = this.monitor;\n  monitor.enter();\n  try {\n    return q.remove(o);\n  } finally {\n    monitor.leave();\n  }\n}", "summary_tokens": ["removes", "a", "single", "instance", "of", "the", "specified", "element", "from", "this", "queue", "if", "it", "is", "present"], "project": "guava"}
{"id": 1421, "code": "public boolean isTopDomainUnderRegistrySuffix() {\n  return registrySuffixIndex == 1;\n}", "summary_tokens": ["indicates", "whether", "this", "domain", "name", "is", "composed", "of", "exactly", "one", "subdomain", "component", "followed", "by", "a", "is", "registry", "suffix", "registry", "suffix"], "project": "guava"}
{"id": 149, "code": "private static void createUnreachableLatchFinalizer(CountDownLatch latch) {\n  new Object() {\n    @Override\n    protected void finalize() {\n      latch.countDown();\n    }\n  };\n}", "summary_tokens": ["creates", "a", "garbage", "object", "that", "counts", "down", "the", "latch", "in", "its", "finalizer"], "project": "guava"}
{"id": 1221, "code": "private void startDraining(boolean overflow) {\n  Java8Compatibility.flip(byteBuffer);\n  if (overflow && byteBuffer.remaining() == 0) {\n    byteBuffer = ByteBuffer.allocate(byteBuffer.capacity() * 2);\n  } else {\n    draining = true;\n  }\n}", "summary_tokens": ["flips", "the", "buffer", "output", "buffer", "so", "we", "can", "start", "reading", "bytes", "from", "it"], "project": "guava"}
{"id": 334, "code": "private static <E> void verifyLinkedHashSetContents(\n    LinkedHashSet<E> set, Collection<E> contents) {\n  assertEquals(\n      \"LinkedHashSet should have preserved order for iteration\",\n      new ArrayList<E>(set),\n      new ArrayList<E>(contents));\n  verifySetContents(set, contents);\n}", "summary_tokens": ["utility", "method", "to", "verify", "that", "the", "given", "linked", "hash", "set", "is", "equal", "to", "and", "hashes", "identically", "to", "a", "set", "constructed", "with", "the", "elements", "in", "the", "given", "collection"], "project": "guava"}
{"id": 1324, "code": "private static void movePivotToStartOfSlice(double[] array, int from, int to) {\n  int mid = (from + to) >>> 1;\n    \n    \n    \n    \n  boolean toLessThanMid = (array[to] < array[mid]);\n  boolean midLessThanFrom = (array[mid] < array[from]);\n  boolean toLessThanFrom = (array[to] < array[from]);\n  if (toLessThanMid == midLessThanFrom) {\n      \n    swap(array, mid, from);\n  } else if (toLessThanMid != toLessThanFrom) {\n      \n    swap(array, from, to);\n  }\n    \n}", "summary_tokens": ["selects", "the", "pivot", "to", "use", "namely", "the", "median", "of", "the", "values", "at", "from", "to", "and", "halfway", "between", "the", "two", "rounded", "down", "from", "array", "and", "ensure", "by", "swapping", "elements", "if", "necessary", "that", "that", "pivot", "value", "appears", "at", "the", "start", "of", "the", "slice", "i"], "project": "guava"}
{"id": 828, "code": "public static <E> Builder<E> builderWithExpectedSize(int expectedSize) {\n  checkNonnegative(expectedSize, \"expectedSize\");\n  return new ImmutableList.Builder<E>(expectedSize);\n}", "summary_tokens": ["returns", "a", "new", "builder", "expecting", "the", "specified", "number", "of", "elements", "to", "be", "added"], "project": "guava"}
{"id": 1920, "code": "public ThreadFactoryBuilder setPriority(int priority) {\n    \n    \n  checkArgument(\n      priority >= Thread.MIN_PRIORITY,\n      \"Thread priority (%s) must be >= %s\",\n      priority,\n      Thread.MIN_PRIORITY);\n  checkArgument(\n      priority <= Thread.MAX_PRIORITY,\n      \"Thread priority (%s) must be <= %s\",\n      priority,\n      Thread.MAX_PRIORITY);\n  this.priority = priority;\n  return this;\n}", "summary_tokens": ["sets", "the", "priority", "for", "new", "threads", "created", "with", "this", "thread", "factory"], "project": "guava"}
{"id": 244, "code": "public void testMapSplitter_extraValueDelimiter() {\n  try {\n    COMMA_SPLITTER.withKeyValueSeparator(\"=\").split(\"a=1,c=2=\");\n    fail();\n  } catch (IllegalArgumentException expected) {\n  }\n}", "summary_tokens": ["testing", "the", "behavior", "in", "https", "github"], "project": "guava"}
{"id": 33, "code": "public TestSuite createTestSuite() {\n  checkCanCreate();\n\n  String name = getName();\n    \n  Set<Feature<?>> features = Helpers.copyToSet(getFeatures());\n  List<Class<? extends AbstractTester>> testers = getTesters();\n\n  logger.fine(\" Testing: \" + name);\n\n    \n  Set<Feature<?>> sizesToTest = Helpers.<Feature<?>>copyToSet(CollectionSize.values());\n  sizesToTest.retainAll(features);\n  features.removeAll(sizesToTest);\n\n  FeatureUtil.addImpliedFeatures(sizesToTest);\n  sizesToTest.retainAll(\n      Arrays.asList(CollectionSize.ZERO, CollectionSize.ONE, CollectionSize.SEVERAL));\n\n  logger.fine(\"   Sizes: \" + formatFeatureSet(sizesToTest));\n\n  if (sizesToTest.isEmpty()) {\n    throw new IllegalStateException(\n        name\n            + \": no CollectionSizes specified (check the argument to \"\n            + \"FeatureSpecificTestSuiteBuilder.withFeatures().)\");\n  }\n\n  TestSuite suite = new TestSuite(name);\n  for (Feature<?> collectionSize : sizesToTest) {\n    String oneSizeName =\n        Platform.format(\n            \"%s [collection size: %s]\", name, collectionSize.toString().toLowerCase());\n    OneSizeGenerator<T, E> oneSizeGenerator =\n        new OneSizeGenerator<>(getSubjectGenerator(), (CollectionSize) collectionSize);\n    Set<Feature<?>> oneSizeFeatures = Helpers.copyToSet(features);\n    oneSizeFeatures.add(collectionSize);\n    Set<Method> oneSizeSuppressedTests = getSuppressedTests();\n\n    OneSizeTestSuiteBuilder<T, E> oneSizeBuilder =\n        new OneSizeTestSuiteBuilder<T, E>(testers)\n            .named(oneSizeName)\n            .usingGenerator(oneSizeGenerator)\n            .withFeatures(oneSizeFeatures)\n            .withSetUp(getSetUp())\n            .withTearDown(getTearDown())\n            .suppressing(oneSizeSuppressedTests);\n    TestSuite oneSizeSuite = oneSizeBuilder.createTestSuite();\n    suite.addTest(oneSizeSuite);\n\n    for (TestSuite derivedSuite : createDerivedSuites(oneSizeBuilder)) {\n      oneSizeSuite.addTest(derivedSuite);\n    }\n  }\n  return suite;\n}", "summary_tokens": ["creates", "a", "runnable", "junit", "test", "suite", "based", "on", "the", "criteria", "already", "given"], "project": "guava"}
{"id": 1705, "code": "public static int parseUnsignedInt(String string, int radix) {\n  checkNotNull(string);\n  long result = Long.parseLong(string, radix);\n  if ((result & INT_MASK) != result) {\n    throw new NumberFormatException(\n        \"Input \" + string + \" in base \" + radix + \" is not in the range of an unsigned integer\");\n  }\n  return (int) result;\n}", "summary_tokens": ["returns", "the", "unsigned", "int", "value", "represented", "by", "a", "string", "with", "the", "given", "radix"], "project": "guava"}
{"id": 227, "code": "public void clear() {\n  final Monitor monitor = this.monitor;\n  monitor.enter();\n  try {\n    q.clear();\n  } finally {\n    monitor.leave();\n  }\n}", "summary_tokens": ["atomically", "removes", "all", "of", "the", "elements", "from", "this", "queue"], "project": "guava"}
{"id": 886, "code": "public final ImmutableSet<V> removeAll(@CheckForNull Object key) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "multimap", "unmodified"], "project": "guava"}
{"id": 1638, "code": "public static short saturatedCast(long value) {\n  if (value > Short.MAX_VALUE) {\n    return Short.MAX_VALUE;\n  }\n  if (value < Short.MIN_VALUE) {\n    return Short.MIN_VALUE;\n  }\n  return (short) value;\n}", "summary_tokens": ["returns", "the", "short", "nearest", "in", "value", "to", "value"], "project": "guava"}
{"id": 1897, "code": "private void beginWaitingFor(Guard guard) {\n  int waiters = guard.waiterCount++;\n  if (waiters == 0) {\n      \n    guard.next = activeGuards;\n    activeGuards = guard;\n  }\n}", "summary_tokens": ["records", "that", "the", "current", "thread", "is", "about", "to", "wait", "on", "the", "specified", "guard"], "project": "guava"}
{"id": 502, "code": "private static boolean isAnyEnter(Method method) {\n  return method.getName().startsWith(\"enter\") || method.getName().startsWith(\"tryEnter\");\n}", "summary_tokens": ["identifies", "all", "enter", "xxx", "and", "try", "enter", "xxx", "methods"], "project": "guava"}
{"id": 96, "code": "public static Method getSubListOriginalListSetAffectsSubListMethod() {\n  return getMethod(ListSubListTester.class, \"testSubList_originalListSetAffectsSubList\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "sub", "list", "original", "list", "set", "affects", "sub", "list", "so", "that", "tests", "of", "copy", "on", "write", "array", "list", "can", "suppress", "them", "with", "feature", "specific", "test", "suite", "builder"], "project": "guava"}
{"id": 834, "code": "public final ImmutableList<V> removeAll(@CheckForNull Object key) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "multimap", "unmodified"], "project": "guava"}
{"id": 833, "code": "public ImmutableList<V> get(K key) {\n    \n  ImmutableList<V> list = (ImmutableList<V>) map.get(key);\n  return (list == null) ? ImmutableList.<V>of() : list;\n}", "summary_tokens": ["returns", "an", "immutable", "list", "of", "the", "values", "for", "the", "given", "key"], "project": "guava"}
{"id": 1166, "code": "public static Escaper htmlEscaper() {\n  return HTML_ESCAPER;\n}", "summary_tokens": ["returns", "an", "escaper", "instance", "that", "escapes", "html", "metacharacters", "as", "specified", "by", "a", "href", "http", "www"], "project": "guava"}
{"id": 995, "code": "protected final String escapeSlow(String s, int index) {\n  int slen = s.length();\n\n    \n  char[] dest = Platform.charBufferFromThreadLocal();\n  int destSize = dest.length;\n  int destIndex = 0;\n  int lastEscape = 0;\n\n    \n    \n  for (; index < slen; index++) {\n\n      \n    char[] r = escape(s.charAt(index));\n\n      \n    if (r == null) {\n      continue;\n    }\n\n    int rlen = r.length;\n    int charsSkipped = index - lastEscape;\n\n      \n      \n      \n    int sizeNeeded = destIndex + charsSkipped + rlen;\n    if (destSize < sizeNeeded) {\n      destSize = sizeNeeded + DEST_PAD_MULTIPLIER * (slen - index);\n      dest = growBuffer(dest, destIndex, destSize);\n    }\n\n      \n    if (charsSkipped > 0) {\n      s.getChars(lastEscape, index, dest, destIndex);\n      destIndex += charsSkipped;\n    }\n\n      \n    if (rlen > 0) {\n      System.arraycopy(r, 0, dest, destIndex, rlen);\n      destIndex += rlen;\n    }\n    lastEscape = index + 1;\n  }\n\n    \n  int charsLeft = slen - lastEscape;\n  if (charsLeft > 0) {\n    int sizeNeeded = destIndex + charsLeft;\n    if (destSize < sizeNeeded) {\n\n        \n      dest = growBuffer(dest, destIndex, sizeNeeded);\n    }\n    s.getChars(lastEscape, slen, dest, destIndex);\n    destIndex = sizeNeeded;\n  }\n  return new String(dest, 0, destIndex);\n}", "summary_tokens": ["returns", "the", "escaped", "form", "of", "a", "given", "literal", "string", "starting", "at", "the", "given", "index"], "project": "guava"}
{"id": 437, "code": "final <T> T isSubtype(T sub) {\n  Type returnType = method.getGenericReturnType();\n  Type paramType = getOnlyParameterType();\n  TestSubtype spec = method.getAnnotation(TestSubtype.class);\n  assertWithMessage(\"%s is subtype of %s\", paramType, returnType)\n      .that(TypeToken.of(paramType).isSubtypeOf(returnType))\n      .isTrue();\n  assertWithMessage(\"%s is supertype of %s\", returnType, paramType)\n      .that(TypeToken.of(returnType).isSupertypeOf(paramType))\n      .isTrue();\n  if (!spec.suppressGetSubtype()) {\n    assertThat(getSubtype(returnType, TypeToken.of(paramType).getRawType())).isEqualTo(paramType);\n  }\n  if (!spec.suppressGetSupertype()) {\n    assertThat(getSupertype(paramType, TypeToken.of(returnType).getRawType()))\n        .isEqualTo(returnType);\n  }\n  return sub;\n}", "summary_tokens": ["call", "this", "in", "a", "test", "subtype", "public", "method", "asserting", "subtype", "relationship"], "project": "guava"}
{"id": 869, "code": "public void add(Range<C> range) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "range", "set", "unmodified"], "project": "guava"}
{"id": 1922, "code": "public ThreadFactoryBuilder setThreadFactory(ThreadFactory backingThreadFactory) {\n  this.backingThreadFactory = checkNotNull(backingThreadFactory);\n  return this;\n}", "summary_tokens": ["sets", "the", "backing", "thread", "factory", "for", "new", "threads", "created", "with", "this", "thread", "factory"], "project": "guava"}
{"id": 874, "code": "public ImmutableRangeSet<C> intersection(RangeSet<C> other) {\n  RangeSet<C> copy = TreeRangeSet.create(this);\n  copy.removeAll(other.complement());\n  return copyOf(copy);\n}", "summary_tokens": ["returns", "a", "new", "range", "set", "consisting", "of", "the", "intersection", "of", "this", "range", "set", "and", "other"], "project": "guava"}
{"id": 1468, "code": "public static List<Boolean> asList(boolean... backingArray) {\n  if (backingArray.length == 0) {\n    return Collections.emptyList();\n  }\n  return new BooleanArrayAsList(backingArray);\n}", "summary_tokens": ["returns", "a", "fixed", "size", "list", "backed", "by", "the", "specified", "array", "similar", "to", "arrays", "as", "list", "object"], "project": "guava"}
{"id": 1752, "code": "public final boolean isProtected() {\n  return Modifier.isProtected(getModifiers());\n}", "summary_tokens": ["returns", "true", "if", "the", "element", "is", "protected"], "project": "guava"}
{"id": 1488, "code": "public static char max(char... array) {\n  checkArgument(array.length > 0);\n  char max = array[0];\n  for (int i = 1; i < array.length; i++) {\n    if (array[i] > max) {\n      max = array[i];\n    }\n  }\n  return max;\n}", "summary_tokens": ["returns", "the", "greatest", "value", "present", "in", "array"], "project": "guava"}
{"id": 1806, "code": "protected String serviceName() {\n  return getClass().getSimpleName();\n}", "summary_tokens": ["returns", "the", "name", "of", "this", "service"], "project": "guava"}
{"id": 771, "code": "public static <K, V> RemovalListener<K, V> asynchronous(\n    RemovalListener<K, V> listener, Executor executor) {\n  checkNotNull(listener);\n  checkNotNull(executor);\n  return (RemovalNotification<K, V> notification) ->\n      executor.execute(() -> listener.onRemoval(notification));\n}", "summary_tokens": ["returns", "a", "removal", "listener", "which", "processes", "all", "eviction", "notifications", "using", "executor"], "project": "guava"}
{"id": 635, "code": "void cleanUp() {\n  if (threadStarted) {\n    return;\n  }\n\n  Reference<?> reference;\n  while ((reference = queue.poll()) != null) {\n      \n    reference.clear();\n    try {\n      ((FinalizableReference) reference).finalizeReferent();\n    } catch (Throwable t) {\n      logger.log(Level.SEVERE, \"Error cleaning up after reference.\", t);\n    }\n  }\n}", "summary_tokens": ["repeatedly", "dequeues", "references", "from", "the", "queue", "and", "invokes", "finalizable", "reference", "finalize", "referent", "on", "them", "until", "the", "queue", "is", "empty"], "project": "guava"}
{"id": 1521, "code": "public static int compare(float a, float b) {\n  return Float.compare(a, b);\n}", "summary_tokens": ["compares", "the", "two", "specified", "float", "values", "using", "float", "compare", "float", "float"], "project": "guava"}
{"id": 897, "code": "public static <R, C, V> ImmutableTable<R, C, V> of(R rowKey, C columnKey, V value) {\n  return new SingletonImmutableTable<>(rowKey, columnKey, value);\n}", "summary_tokens": ["returns", "an", "immutable", "table", "containing", "a", "single", "cell"], "project": "guava"}
{"id": 1980, "code": "private static void checkNoConflictInValueBucket(\n    Object value, Entry<?, ?> entry, @CheckForNull ImmutableMapEntry<?, ?> valueBucketHead)\n    throws BucketOverflowException {\n  int bucketSize = 0;\n  for (; valueBucketHead != null; valueBucketHead = valueBucketHead.getNextInValueBucket()) {\n    checkNoConflict(!value.equals(valueBucketHead.getValue()), \"value\", entry, valueBucketHead);\n    if (++bucketSize > MAX_HASH_BUCKET_LENGTH) {\n      throw new BucketOverflowException();\n    }\n  }\n}", "summary_tokens": ["illegal", "argument", "exception", "if", "another", "entry", "in", "the", "bucket", "has", "the", "same", "key", "bucket", "overflow", "exception", "if", "this", "bucket", "has", "too", "many", "entries", "which", "may", "indicate", "a", "hash", "flooding", "attack"], "project": "guava"}
{"id": 1557, "code": "public static Builder builder() {\n  return new Builder(10);\n}", "summary_tokens": ["returns", "a", "new", "empty", "builder", "for", "immutable", "int", "array", "instances", "with", "a", "default", "initial", "capacity"], "project": "guava"}
{"id": 1936, "code": "static <E> Set<E> preservesInsertionOrderOnAddsSet() {\n  return Sets.newLinkedHashSet();\n}", "summary_tokens": ["returns", "the", "platform", "preferred", "set", "implementation", "that", "preserves", "insertion", "order", "when", "used", "only", "for", "insertions"], "project": "guava"}
{"id": 1078, "code": "public static NetworkBuilder<Object, Object> directed() {\n  return new NetworkBuilder<>(true);\n}", "summary_tokens": ["returns", "a", "network", "builder", "for", "building", "directed", "networks"], "project": "guava"}
{"id": 1423, "code": "public boolean hasParent() {\n  return parts.size() > 1;\n}", "summary_tokens": ["indicates", "whether", "this", "domain", "is", "composed", "of", "two", "or", "more", "parts"], "project": "guava"}
{"id": 1898, "code": "private void endWaitingFor(Guard guard) {\n  int waiters = --guard.waiterCount;\n  if (waiters == 0) {\n      \n    for (Guard p = activeGuards, pred = null; ; pred = p, p = p.next) {\n      if (p == guard) {\n        if (pred == null) {\n          activeGuards = p.next;\n        } else {\n          pred.next = p.next;\n        }\n        p.next = null; \n        break;\n      }\n    }\n  }\n}", "summary_tokens": ["records", "that", "the", "current", "thread", "is", "no", "longer", "waiting", "on", "the", "specified", "guard"], "project": "guava"}
{"id": 1162, "code": "public String toString() {\n  return Long.toString(sum());\n}", "summary_tokens": ["returns", "the", "string", "representation", "of", "the", "sum"], "project": "guava"}
{"id": 1251, "code": "public static int pow(int b, int k) {\n  checkNonNegative(\"exponent\", k);\n  switch (b) {\n    case 0:\n      return (k == 0) ? 1 : 0;\n    case 1:\n      return 1;\n    case (-1):\n      return ((k & 1) == 0) ? 1 : -1;\n    case 2:\n      return (k < Integer.SIZE) ? (1 << k) : 0;\n    case (-2):\n      if (k < Integer.SIZE) {\n        return ((k & 1) == 0) ? (1 << k) : -(1 << k);\n      } else {\n        return 0;\n      }\n    default:\n        \n  }\n  for (int accum = 1; ; k >>= 1) {\n    switch (k) {\n      case 0:\n        return accum;\n      case 1:\n        return b * accum;\n      default:\n        accum *= ((k & 1) == 0) ? 1 : b;\n        b *= b;\n    }\n  }\n}", "summary_tokens": ["returns", "b", "to", "the", "k", "th", "power"], "project": "guava"}
{"id": 2003, "code": "private static Collection<IOException> concat(\n    @CheckForNull Collection<IOException> exceptions,\n    @CheckForNull Collection<IOException> other) {\n  if (exceptions == null) {\n    return other;\n  } else if (other != null) {\n    exceptions.addAll(other);\n  }\n  return exceptions;\n}", "summary_tokens": ["concatenates", "the", "contents", "of", "the", "two", "given", "collections", "of", "exceptions"], "project": "guava"}
{"id": 1010, "code": "public Object getEvent() {\n  return event;\n}", "summary_tokens": ["returns", "the", "wrapped", "dead", "event", "which", "the", "system", "was", "unable", "to", "deliver", "to", "any", "registered", "subscriber"], "project": "guava"}
{"id": 1610, "code": "public static int hashCode(long value) {\n  return (int) (value ^ (value >>> 32));\n}", "summary_tokens": ["returns", "a", "hash", "code", "for", "value", "equal", "to", "the", "result", "of", "invoking", "long", "value"], "project": "guava"}
{"id": 1029, "code": "void register(Object listener) {\n  Multimap<Class<?>, Subscriber> listenerMethods = findAllSubscribers(listener);\n\n  for (Entry<Class<?>, Collection<Subscriber>> entry : listenerMethods.asMap().entrySet()) {\n    Class<?> eventType = entry.getKey();\n    Collection<Subscriber> eventMethodsInListener = entry.getValue();\n\n    CopyOnWriteArraySet<Subscriber> eventSubscribers = subscribers.get(eventType);\n\n    if (eventSubscribers == null) {\n      CopyOnWriteArraySet<Subscriber> newSet = new CopyOnWriteArraySet<>();\n      eventSubscribers =\n          MoreObjects.firstNonNull(subscribers.putIfAbsent(eventType, newSet), newSet);\n    }\n\n    eventSubscribers.addAll(eventMethodsInListener);\n  }\n}", "summary_tokens": ["registers", "all", "subscriber", "methods", "on", "the", "given", "listener", "object"], "project": "guava"}
{"id": 1012, "code": "static Dispatcher legacyAsync() {\n  return new LegacyAsyncDispatcher();\n}", "summary_tokens": ["returns", "a", "dispatcher", "that", "queues", "events", "that", "are", "posted", "in", "a", "single", "global", "queue"], "project": "guava"}
{"id": 926, "code": "public static Builder<Comparable> expectedSize(int expectedSize) {\n  return new Builder<Comparable>(Ordering.natural()).expectedSize(expectedSize);\n}", "summary_tokens": ["creates", "and", "returns", "a", "new", "builder", "configured", "to", "build", "min", "max", "priority", "queue", "instances", "sized", "appropriately", "to", "hold", "expected", "size", "elements"], "project": "guava"}
{"id": 1698, "code": "public static String join(String separator, int... array) {\n  checkNotNull(separator);\n  if (array.length == 0) {\n    return \"\";\n  }\n\n    \n  StringBuilder builder = new StringBuilder(array.length * 5);\n  builder.append(toString(array[0]));\n  for (int i = 1; i < array.length; i++) {\n    builder.append(separator).append(toString(array[i]));\n  }\n  return builder.toString();\n}", "summary_tokens": ["returns", "a", "string", "containing", "the", "supplied", "unsigned", "int", "values", "separated", "by", "separator"], "project": "guava"}
{"id": 706, "code": "CacheBuilder<K, V> valueEquivalence(Equivalence<Object> equivalence) {\n  checkState(\n      valueEquivalence == null, \"value equivalence was already set to %s\", valueEquivalence);\n  this.valueEquivalence = checkNotNull(equivalence);\n  return this;\n}", "summary_tokens": ["sets", "a", "custom", "equivalence", "strategy", "for", "comparing", "values"], "project": "guava"}
{"id": 103, "code": "protected void resetWithHole() {\n  super.resetContainer(getSubjectGenerator().create(a, c));\n  navigableSet = (NavigableSet<E>) getSet();\n}", "summary_tokens": ["resets", "the", "contents", "of", "navigable", "set", "to", "have", "elements", "a", "c", "for", "the", "navigation", "tests"], "project": "guava"}
{"id": 1734, "code": "public int hashCode() {\n  return super.hashCode();\n}", "summary_tokens": ["by", "default", "delegates", "to", "object", "hash", "code"], "project": "guava"}
{"id": 225, "code": "public <T> T[] toArray(T[] a) {\n  final Monitor monitor = this.monitor;\n  monitor.enter();\n  try {\n    return q.toArray(a);\n  } finally {\n    monitor.leave();\n  }\n}", "summary_tokens": ["returns", "an", "array", "containing", "all", "of", "the", "elements", "in", "this", "queue", "the", "runtime", "type", "of", "the", "returned", "array", "is", "that", "of", "the", "specified", "array"], "project": "guava"}
{"id": 1443, "code": "static MediaType createApplicationType(String subtype) {\n  return create(APPLICATION_TYPE, subtype);\n}", "summary_tokens": ["creates", "a", "media", "type", "with", "the", "application", "type", "and", "the", "given", "subtype"], "project": "guava"}
{"id": 1889, "code": "public int getQueueLength() {\n  return lock.getQueueLength();\n}", "summary_tokens": ["returns", "an", "estimate", "of", "the", "number", "of", "threads", "waiting", "to", "enter", "this", "monitor"], "project": "guava"}
{"id": 1657, "code": "public static List<Short> asList(short... backingArray) {\n  if (backingArray.length == 0) {\n    return Collections.emptyList();\n  }\n  return new ShortArrayAsList(backingArray);\n}", "summary_tokens": ["returns", "a", "fixed", "size", "list", "backed", "by", "the", "specified", "array", "similar", "to", "arrays", "as", "list", "object"], "project": "guava"}
{"id": 1750, "code": "public static <T> Invokable<T, T> from(Constructor<T> constructor) {\n  return new ConstructorInvokable<T>(constructor);\n}", "summary_tokens": ["returns", "invokable", "of", "constructor"], "project": "guava"}
{"id": 888, "code": "public ImmutableSet<Entry<K, V>> entries() {\n  ImmutableSet<Entry<K, V>> result = entries;\n  return result == null ? (entries = new EntrySet<>(this)) : result;\n}", "summary_tokens": ["returns", "an", "immutable", "collection", "of", "all", "key", "value", "pairs", "in", "the", "multimap"], "project": "guava"}
{"id": 761, "code": "public void add(long x) {\n  Cell[] as;\n  long b, v;\n  int[] hc;\n  Cell a;\n  int n;\n  if ((as = cells) != null || !casBase(b = base, b + x)) {\n    boolean uncontended = true;\n    if ((hc = threadHashCode.get()) == null\n        || as == null\n        || (n = as.length) < 1\n        || (a = as[(n - 1) & hc[0]]) == null\n        || !(uncontended = a.cas(v = a.value, v + x))) retryUpdate(x, hc, uncontended);\n  }\n}", "summary_tokens": ["adds", "the", "given", "value"], "project": "guava"}
{"id": 1911, "code": "public void awaitHealthy(long timeout, TimeUnit unit) throws TimeoutException {\n  state.awaitHealthy(timeout, unit);\n}", "summary_tokens": ["waits", "for", "the", "service", "manager", "to", "become", "is", "healthy", "healthy", "for", "no", "more", "than", "the", "given", "time"], "project": "guava"}
{"id": 634, "code": "public static <T extends Enum<T>> Converter<String, T> stringConverter(Class<T> enumClass) {\n  return new StringConverter<>(enumClass);\n}", "summary_tokens": ["returns", "a", "converter", "that", "converts", "between", "strings", "and", "enum", "values", "of", "type", "enum", "class", "using", "enum", "value", "of", "class", "string", "and", "enum", "name"], "project": "guava"}
{"id": 1313, "code": "public final double sampleCovariance() {\n  checkState(count() > 1);\n  return sumOfProductsOfDeltas / (count() - 1);\n}", "summary_tokens": ["returns", "the", "sample", "covariance", "of", "the", "values"], "project": "guava"}
{"id": 1255, "code": "public static int gcd(int a, int b) {\n    \n  checkNonNegative(\"a\", a);\n  checkNonNegative(\"b\", b);\n  if (a == 0) {\n      \n      \n    return b;\n  } else if (b == 0) {\n    return a; \n  }\n    \n  int aTwos = Integer.numberOfTrailingZeros(a);\n  a >>= aTwos; \n  int bTwos = Integer.numberOfTrailingZeros(b);\n  b >>= bTwos; \n  while (a != b) { \n      \n      \n      \n\n      \n      \n\n    int delta = a - b; \n\n    int minDeltaOrZero = delta & (delta >> (Integer.SIZE - 1));\n      \n\n    a = delta - minDeltaOrZero - minDeltaOrZero; \n      \n\n    b += minDeltaOrZero; \n    a >>= Integer.numberOfTrailingZeros(a); \n  }\n  return a << min(aTwos, bTwos);\n}", "summary_tokens": ["returns", "the", "greatest", "common", "divisor", "of", "a", "b"], "project": "guava"}
{"id": 699, "code": "public static void startFinalizer(\n    Class<?> finalizableReferenceClass,\n    ReferenceQueue<Object> queue,\n    PhantomReference<Object> frqReference) {\n    \n  if (!finalizableReferenceClass.getName().equals(FINALIZABLE_REFERENCE)) {\n    throw new IllegalArgumentException(\"Expected \" + FINALIZABLE_REFERENCE + \".\");\n  }\n\n  Finalizer finalizer = new Finalizer(finalizableReferenceClass, queue, frqReference);\n  String threadName = Finalizer.class.getName();\n  Thread thread = null;\n  if (bigThreadConstructor != null) {\n    try {\n      boolean inheritThreadLocals = false;\n      long defaultStackSize = 0;\n      thread =\n          bigThreadConstructor.newInstance(\n              (ThreadGroup) null, finalizer, threadName, defaultStackSize, inheritThreadLocals);\n    } catch (Throwable t) {\n      logger.log(\n          Level.INFO, \"Failed to create a thread without inherited thread-local values\", t);\n    }\n  }\n  if (thread == null) {\n    thread = new Thread((ThreadGroup) null, finalizer, threadName);\n  }\n  thread.setDaemon(true);\n\n  try {\n    if (inheritableThreadLocals != null) {\n      inheritableThreadLocals.set(thread, null);\n    }\n  } catch (Throwable t) {\n    logger.log(\n        Level.INFO,\n        \"Failed to clear thread local values inherited by reference finalizer thread.\",\n        t);\n  }\n\n  thread.start();\n}", "summary_tokens": ["starts", "the", "finalizer", "thread"], "project": "guava"}
{"id": 353, "code": "public void immutableNetworkBuilder_copiesNetworkBuilder() {\n  NetworkBuilder<String, Object> networkBuilder =\n      NetworkBuilder.directed()\n          .allowsSelfLoops(true)\n          .<String>nodeOrder(ElementOrder.<String>natural());\n  ImmutableNetwork.Builder<String, Integer> immutableNetworkBuilder =\n      networkBuilder.<String, Integer>immutable();\n\n    \n  networkBuilder.allowsSelfLoops(false).nodeOrder(ElementOrder.<String>unordered());\n\n  ImmutableNetwork<String, Integer> emptyNetwork = immutableNetworkBuilder.build();\n\n  assertThat(emptyNetwork.isDirected()).isTrue();\n  assertThat(emptyNetwork.allowsSelfLoops()).isTrue();\n  assertThat(emptyNetwork.nodeOrder()).isEqualTo(ElementOrder.<String>natural());\n}", "summary_tokens": ["tests", "that", "the", "immutable", "network"], "project": "guava"}
{"id": 776, "code": "static void tableSet(Object table, int index, int entry) {\n  if (table instanceof byte[]) {\n    ((byte[]) table)[index] = (byte) entry; \n  } else if (table instanceof short[]) {\n    ((short[]) table)[index] = (short) entry; \n  } else {\n    ((int[]) table)[index] = entry;\n  }\n}", "summary_tokens": ["sets", "table", "index", "to", "entry", "where", "table", "is", "actually", "a", "byte", "short", "or", "int"], "project": "guava"}
{"id": 677, "code": "public static String commonSuffix(CharSequence a, CharSequence b) {\n  checkNotNull(a);\n  checkNotNull(b);\n\n  int maxSuffixLength = Math.min(a.length(), b.length());\n  int s = 0;\n  while (s < maxSuffixLength && a.charAt(a.length() - s - 1) == b.charAt(b.length() - s - 1)) {\n    s++;\n  }\n  if (validSurrogatePairAt(a, a.length() - s - 1)\n      || validSurrogatePairAt(b, b.length() - s - 1)) {\n    s--;\n  }\n  return a.subSequence(a.length() - s, a.length()).toString();\n}", "summary_tokens": ["returns", "the", "longest", "string", "suffix", "such", "that", "a"], "project": "guava"}
{"id": 1888, "code": "public int getOccupiedDepth() {\n  return lock.getHoldCount();\n}", "summary_tokens": ["returns", "the", "number", "of", "times", "the", "current", "thread", "has", "entered", "this", "monitor", "in", "excess", "of", "the", "number", "of", "times", "it", "has", "left"], "project": "guava"}
{"id": 1970, "code": "public static <T> Optional<T> fromJavaUtil(@CheckForNull java.util.Optional<T> javaUtilOptional) {\n  return (javaUtilOptional == null) ? null : fromNullable(javaUtilOptional.orElse(null));\n}", "summary_tokens": ["returns", "the", "equivalent", "com"], "project": "guava"}
{"id": 470, "code": "public void testWeakCompareAndSet() {\n  double prev = Math.E;\n  double unused = Math.E + Math.PI;\n  AtomicDouble at = new AtomicDouble(prev);\n  for (double x : VALUES) {\n    assertBitEquals(prev, at.get());\n    assertFalse(at.weakCompareAndSet(unused, x));\n    assertBitEquals(prev, at.get());\n    while (!at.weakCompareAndSet(prev, x)) {\n      ;\n    }\n    assertBitEquals(x, at.get());\n    prev = x;\n  }\n}", "summary_tokens": ["repeated", "weak", "compare", "and", "set", "succeeds", "in", "changing", "value", "when", "equal", "to", "expected"], "project": "guava"}
{"id": 1053, "code": "public final N nodeV() {\n  return nodeV;\n}", "summary_tokens": ["returns", "the", "node", "adjacent", "node", "object", "adjacent", "to", "node", "u", "along", "the", "origin", "edge"], "project": "guava"}
{"id": 867, "code": "public static <C extends Comparable<?>> ImmutableRangeSet<C> copyOf(Iterable<Range<C>> ranges) {\n  return new ImmutableRangeSet.Builder<C>().addAll(ranges).build();\n}", "summary_tokens": ["returns", "an", "immutable", "range", "set", "containing", "each", "of", "the", "specified", "disjoint", "ranges"], "project": "guava"}
{"id": 137, "code": "public EquivalenceTester<T> test() {\n  for (int run = 0; run < REPETITIONS; run++) {\n    testItems();\n    delegate.test();\n  }\n  return this;\n}", "summary_tokens": ["run", "tests", "on", "equivalence", "methods", "throwing", "a", "failure", "on", "an", "invalid", "test"], "project": "guava"}
{"id": 1675, "code": "public static Comparator<byte[]> lexicographicalComparator() {\n  return LexicographicalComparatorHolder.BEST_COMPARATOR;\n}", "summary_tokens": ["returns", "a", "comparator", "that", "compares", "two", "byte", "arrays", "a", "href", "http", "en"], "project": "guava"}
{"id": 1803, "code": "public final void visit(@Nullable Type... types) {\n  for (Type type : types) {\n    if (type == null || !visited.add(type)) {\n        \n      continue;\n    }\n    boolean succeeded = false;\n    try {\n      if (type instanceof TypeVariable) {\n        visitTypeVariable((TypeVariable<?>) type);\n      } else if (type instanceof WildcardType) {\n        visitWildcardType((WildcardType) type);\n      } else if (type instanceof ParameterizedType) {\n        visitParameterizedType((ParameterizedType) type);\n      } else if (type instanceof Class) {\n        visitClass((Class<?>) type);\n      } else if (type instanceof GenericArrayType) {\n        visitGenericArrayType((GenericArrayType) type);\n      } else {\n        throw new AssertionError(\"Unknown type: \" + type);\n      }\n      succeeded = true;\n    } finally {\n      if (!succeeded) { \n        visited.remove(type);\n      }\n    }\n  }\n}", "summary_tokens": ["visits", "the", "given", "types"], "project": "guava"}
{"id": 1234, "code": "public static int roundToInt(double x, RoundingMode mode) {\n  double z = roundIntermediate(x, mode);\n  checkInRangeForRoundingInputs(\n      z > MIN_INT_AS_DOUBLE - 1.0 & z < MAX_INT_AS_DOUBLE + 1.0, x, mode);\n  return (int) z;\n}", "summary_tokens": ["returns", "the", "int", "value", "that", "is", "equal", "to", "x", "rounded", "with", "the", "specified", "rounding", "mode", "if", "possible"], "project": "guava"}
{"id": 1222, "code": "private int drain(byte[] b, int off, int len) {\n  int remaining = Math.min(len, byteBuffer.remaining());\n  byteBuffer.get(b, off, remaining);\n  return remaining;\n}", "summary_tokens": ["copy", "as", "much", "of", "the", "byte", "buffer", "into", "the", "output", "array", "as", "possible", "returning", "the", "positive", "number", "of", "characters", "copied"], "project": "guava"}
{"id": 655, "code": "public static Splitter on(Pattern separatorPattern) {\n  return on(new JdkPattern(separatorPattern));\n}", "summary_tokens": ["returns", "a", "splitter", "that", "considers", "any", "subsequence", "matching", "pattern", "to", "be", "a", "separator"], "project": "guava"}
{"id": 125, "code": "public <T> ClassSanityTester setDistinctValues(Class<T> type, T value1, T value2) {\n  checkNotNull(type);\n  checkNotNull(value1);\n  checkNotNull(value2);\n  checkArgument(!Objects.equal(value1, value2), \"Duplicate value provided.\");\n  distinctValues.replaceValues(type, ImmutableList.of(value1, value2));\n  setDefault(type, value1);\n  return this;\n}", "summary_tokens": ["sets", "distinct", "values", "for", "type", "so", "that", "when", "a", "class", "foo", "is", "tested", "for", "object", "equals", "and", "object", "hash", "code", "and", "its", "construction", "requires", "a", "parameter", "of", "type", "the", "distinct", "values", "of", "type", "can", "be", "passed", "as", "parameters", "to", "create", "foo", "instances", "that", "are", "unequal"], "project": "guava"}
{"id": 195, "code": "private TearDownStack buildTearDownStack() {\n  final TearDownStack result = new TearDownStack();\n  tearDownStack.addTearDown(\n      new TearDown() {\n\n        @Override\n        public void tearDown() throws Exception {\n          synchronized (result.stack) {\n            assertEquals(\n                \"The test should have cleared the stack (say, by virtue of running runTearDown)\",\n                0,\n                result.stack.size());\n          }\n        }\n      });\n  return result;\n}", "summary_tokens": ["builds", "a", "tear", "down", "stack", "that", "makes", "sure", "it", "s", "clear", "by", "the", "end", "of", "this", "test"], "project": "guava"}
{"id": 652, "code": "public static int checkPositionIndex(int index, int size, String desc) {\n    \n  if (index < 0 || index > size) {\n    throw new IndexOutOfBoundsException(badPositionIndex(index, size, desc));\n  }\n  return index;\n}", "summary_tokens": ["ensures", "that", "index", "specifies", "a", "valid", "i", "position", "i", "in", "an", "array", "list", "or", "string", "of", "size", "size"], "project": "guava"}
{"id": 1364, "code": "private static String[] getHostAndPortFromBracketedHost(String hostPortString) {\n  checkArgument(\n      hostPortString.charAt(0) == '[',\n      \"Bracketed host-port string must start with a bracket: %s\",\n      hostPortString);\n  int colonIndex = hostPortString.indexOf(':');\n  int closeBracketIndex = hostPortString.lastIndexOf(']');\n  checkArgument(\n      colonIndex > -1 && closeBracketIndex > colonIndex,\n      \"Invalid bracketed host/port: %s\",\n      hostPortString);\n\n  String host = hostPortString.substring(1, closeBracketIndex);\n  if (closeBracketIndex + 1 == hostPortString.length()) {\n    return new String[] {host, \"\"};\n  } else {\n    checkArgument(\n        hostPortString.charAt(closeBracketIndex + 1) == ':',\n        \"Only a colon may follow a close bracket: %s\",\n        hostPortString);\n    for (int i = closeBracketIndex + 2; i < hostPortString.length(); ++i) {\n      checkArgument(\n          Character.isDigit(hostPortString.charAt(i)),\n          \"Port must be numeric: %s\",\n          hostPortString);\n    }\n    return new String[] {host, hostPortString.substring(closeBracketIndex + 2)};\n  }\n}", "summary_tokens": ["parses", "a", "bracketed", "host", "port", "string", "throwing", "illegal", "argument", "exception", "if", "parsing", "fails"], "project": "guava"}
{"id": 1671, "code": "public static byte max(byte... array) {\n  checkArgument(array.length > 0);\n  int max = toInt(array[0]);\n  for (int i = 1; i < array.length; i++) {\n    int next = toInt(array[i]);\n    if (next > max) {\n      max = next;\n    }\n  }\n  return (byte) max;\n}", "summary_tokens": ["returns", "the", "greatest", "value", "present", "in", "array", "treating", "values", "as", "unsigned"], "project": "guava"}
{"id": 793, "code": "public Class<V> valueType() {\n  return valueType;\n}", "summary_tokens": ["returns", "the", "associated", "value", "type"], "project": "guava"}
{"id": 1003, "code": "static char[] charBufferFromThreadLocal() {\n  return DEST_TL.get();\n}", "summary_tokens": ["returns", "a", "thread", "local", "0", "char", "array"], "project": "guava"}
{"id": 1072, "code": "public static <N, E> Network<N, E> transpose(Network<N, E> network) {\n  if (!network.isDirected()) {\n    return network; \n  }\n\n  if (network instanceof TransposedNetwork) {\n    return ((TransposedNetwork<N, E>) network).network;\n  }\n\n  return new TransposedNetwork<>(network);\n}", "summary_tokens": ["returns", "a", "view", "of", "network", "with", "the", "direction", "if", "any", "of", "every", "edge", "reversed"], "project": "guava"}
{"id": 217, "code": "public int drainTo(Collection<? super E> c, int maxElements) {\n  if (c == null) throw new NullPointerException();\n  if (c == this) throw new IllegalArgumentException();\n  if (maxElements <= 0) return 0;\n  final E[] items = this.items;\n  final Monitor monitor = this.monitor;\n  monitor.enter();\n  try {\n    int i = takeIndex;\n    int n = 0;\n    int max = (maxElements < count) ? maxElements : count;\n    while (n < max) {\n      c.add(items[i]);\n      items[i] = null;\n      i = inc(i);\n      ++n;\n    }\n    if (n > 0) {\n      count -= n;\n      takeIndex = i;\n    }\n    return n;\n  } finally {\n    monitor.leave();\n  }\n}", "summary_tokens": ["unsupported", "operation", "exception", "class", "cast", "exception", "null", "pointer", "exception", "illegal", "argument", "exception"], "project": "guava"}
{"id": 921, "code": "Segment<K, V, E, S> segmentFor(int hash) {\n    \n  return segments[(hash >>> segmentShift) & segmentMask];\n}", "summary_tokens": ["returns", "the", "segment", "that", "should", "be", "used", "for", "a", "key", "with", "the", "given", "hash"], "project": "guava"}
{"id": 1087, "code": "public <E1 extends E> NetworkBuilder<N, E1> edgeOrder(ElementOrder<E1> edgeOrder) {\n  NetworkBuilder<N, E1> newBuilder = cast();\n  newBuilder.edgeOrder = checkNotNull(edgeOrder);\n  return newBuilder;\n}", "summary_tokens": ["specifies", "the", "order", "of", "iteration", "for", "the", "elements", "of", "network", "edges"], "project": "guava"}
{"id": 1154, "code": "static boolean usingUnsafe() {\n  return (byteArray instanceof UnsafeByteArray);\n}", "summary_tokens": ["indicates", "that", "the", "loading", "of", "unsafe", "was", "successful", "and", "the", "load", "and", "store", "operations", "will", "be", "very", "efficient"], "project": "guava"}
{"id": 473, "code": "public void testAddAndGet() {\n  for (double x : VALUES) {\n    for (double y : VALUES) {\n      AtomicDouble a = new AtomicDouble(x);\n      double z = a.addAndGet(y);\n      assertBitEquals(x + y, z);\n      assertBitEquals(x + y, a.get());\n    }\n  }\n}", "summary_tokens": ["add", "and", "get", "adds", "given", "value", "to", "current", "and", "returns", "current", "value"], "project": "guava"}
{"id": 1662, "code": "public static byte max(byte... array) {\n  checkArgument(array.length > 0);\n  byte max = array[0];\n  for (int i = 1; i < array.length; i++) {\n    if (array[i] > max) {\n      max = array[i];\n    }\n  }\n  return max;\n}", "summary_tokens": ["returns", "the", "greatest", "value", "present", "in", "array"], "project": "guava"}
{"id": 856, "code": "public final boolean setCount(E element, int oldCount, int newCount) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "collection", "unmodified"], "project": "guava"}
{"id": 1084, "code": "public NetworkBuilder<N, E> expectedNodeCount(int expectedNodeCount) {\n  this.expectedNodeCount = Optional.of(checkNonNegative(expectedNodeCount));\n  return this;\n}", "summary_tokens": ["specifies", "the", "expected", "number", "of", "nodes", "in", "the", "network"], "project": "guava"}
{"id": 1991, "code": "public static void createParentDirectories(Path path, FileAttribute<?>... attrs)\n    throws IOException {\n    \n    \n    \n    \n  Path normalizedAbsolutePath = path.toAbsolutePath().normalize();\n  Path parent = normalizedAbsolutePath.getParent();\n  if (parent == null) {\n      \n      \n      \n      \n    return;\n  }\n\n    \n    \n    \n    \n  if (!Files.isDirectory(parent)) {\n    Files.createDirectories(parent, attrs);\n    if (!Files.isDirectory(parent)) {\n      throw new IOException(\"Unable to create parent directories of \" + path);\n    }\n  }\n}", "summary_tokens": ["creates", "any", "necessary", "but", "nonexistent", "parent", "directories", "of", "the", "specified", "path"], "project": "guava"}
{"id": 1377, "code": "private static InetAddress bytesToInetAddress(byte[] addr) {\n  try {\n    return InetAddress.getByAddress(addr);\n  } catch (UnknownHostException e) {\n    throw new AssertionError(e);\n  }\n}", "summary_tokens": ["convert", "a", "byte", "array", "into", "an", "inet", "address"], "project": "guava"}
{"id": 1113, "code": "public static HashCode fromLong(long hash) {\n  return new LongHashCode(hash);\n}", "summary_tokens": ["creates", "a", "0", "bit", "hash", "code", "representation", "of", "the", "given", "long", "value"], "project": "guava"}
{"id": 794, "code": "private void writeObject(ObjectOutputStream stream) throws IOException {\n  stream.defaultWriteObject();\n  stream.writeObject(keyType);\n  stream.writeObject(valueType);\n  Serialization.writeMap(this, stream);\n}", "summary_tokens": ["the", "key", "class", "value", "class", "number", "of", "entries", "first", "key", "first", "value", "second", "key", "second", "value", "and", "so", "on"], "project": "guava"}
{"id": 2019, "code": "public final double updateAndGet(int i, DoubleUnaryOperator updaterFunction) {\n  while (true) {\n    long current = longs.get(i);\n    double currentVal = longBitsToDouble(current);\n    double nextVal = updaterFunction.applyAsDouble(currentVal);\n    long next = doubleToRawLongBits(nextVal);\n    if (longs.compareAndSet(i, current, next)) {\n      return nextVal;\n    }\n  }\n}", "summary_tokens": ["atomically", "updates", "the", "element", "at", "index", "i", "with", "the", "results", "of", "applying", "the", "given", "function", "to", "the", "curernt", "value"], "project": "guava"}
{"id": 577, "code": "public static String truncate(CharSequence seq, int maxLength, String truncationIndicator) {\n  checkNotNull(seq);\n\n    \n  int truncationLength = maxLength - truncationIndicator.length();\n\n    \n    \n  checkArgument(\n      truncationLength >= 0,\n      \"maxLength (%s) must be >= length of the truncation indicator (%s)\",\n      maxLength,\n      truncationIndicator.length());\n\n  if (seq.length() <= maxLength) {\n    String string = seq.toString();\n    if (string.length() <= maxLength) {\n      return string;\n    }\n      \n    seq = string;\n  }\n\n  return new StringBuilder(maxLength)\n      .append(seq, 0, truncationLength)\n      .append(truncationIndicator)\n      .toString();\n}", "summary_tokens": ["truncates", "the", "given", "character", "sequence", "to", "the", "given", "maximum", "length"], "project": "guava"}
{"id": 1878, "code": "public boolean enterWhen(Guard guard, long time, TimeUnit unit) throws InterruptedException {\n  final long timeoutNanos = toSafeNanos(time, unit);\n  if (guard.monitor != this) {\n    throw new IllegalMonitorStateException();\n  }\n  final ReentrantLock lock = this.lock;\n  boolean reentrant = lock.isHeldByCurrentThread();\n  long startTime = 0L;\n\n  locked:\n  {\n    if (!fair) {\n        \n      if (Thread.interrupted()) {\n        throw new InterruptedException();\n      }\n      if (lock.tryLock()) {\n        break locked;\n      }\n    }\n    startTime = initNanoTime(timeoutNanos);\n    if (!lock.tryLock(time, unit)) {\n      return false;\n    }\n  }\n\n  boolean satisfied = false;\n  boolean threw = true;\n  try {\n    satisfied =\n        guard.isSatisfied()\n            || awaitNanos(\n                guard,\n                (startTime == 0L) ? timeoutNanos : remainingNanos(startTime, timeoutNanos),\n                reentrant);\n    threw = false;\n    return satisfied;\n  } finally {\n    if (!satisfied) {\n      try {\n          \n        if (threw && !reentrant) {\n          signalNextWaiter();\n        }\n      } finally {\n        lock.unlock();\n      }\n    }\n  }\n}", "summary_tokens": ["enters", "this", "monitor", "when", "the", "guard", "is", "satisfied"], "project": "guava"}
{"id": 438, "code": "final <X> X notSubtype(@SuppressWarnings(\"unused\") Object sub) {\n  Type returnType = method.getGenericReturnType();\n  Type paramType = getOnlyParameterType();\n  TestSubtype spec = method.getAnnotation(TestSubtype.class);\n  assertWithMessage(\"%s is subtype of %s\", paramType, returnType)\n      .that(TypeToken.of(paramType).isSubtypeOf(returnType))\n      .isFalse();\n  assertWithMessage(\"%s is supertype of %s\", returnType, paramType)\n      .that(TypeToken.of(returnType).isSupertypeOf(paramType))\n      .isFalse();\n  if (!spec.suppressGetSubtype()) {\n    try {\n      assertThat(getSubtype(returnType, TypeToken.of(paramType).getRawType()))\n          .isNotEqualTo(paramType);\n    } catch (IllegalArgumentException notSubtype1) {\n        \n    }\n  }\n  if (!spec.suppressGetSupertype()) {\n    try {\n      assertThat(getSupertype(paramType, TypeToken.of(returnType).getRawType()))\n          .isNotEqualTo(returnType);\n    } catch (IllegalArgumentException notSubtype2) {\n        \n    }\n  }\n  return null;\n}", "summary_tokens": ["call", "this", "in", "a", "test", "subtype", "public", "method", "asserting", "that", "subtype", "relationship", "does", "not", "hold"], "project": "guava"}
{"id": 773, "code": "static int tableSize(int expectedSize) {\n    \n  return Math.max(MIN_HASH_TABLE_SIZE, Hashing.closedTableSize(expectedSize + 1, 1.0f));\n}", "summary_tokens": ["returns", "the", "power", "of", "0", "hashtable", "size", "required", "to", "hold", "the", "expected", "number", "of", "items", "or", "the", "minimum", "hashtable", "size", "whichever", "is", "greater"], "project": "guava"}
{"id": 612, "code": "public String retainFrom(CharSequence sequence) {\n  return negate().removeFrom(sequence);\n}", "summary_tokens": ["returns", "a", "string", "containing", "all", "matching", "bmp", "characters", "of", "a", "character", "sequence", "in", "order"], "project": "guava"}
{"id": 1686, "code": "public long longValue() {\n  return toLong(value);\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "unsigned", "integer", "as", "a", "long"], "project": "guava"}
{"id": 1590, "code": "public static int compare(int a, int b) {\n  return (a < b) ? -1 : ((a > b) ? 1 : 0);\n}", "summary_tokens": ["compares", "the", "two", "specified", "int", "values"], "project": "guava"}
{"id": 1291, "code": "public static long factorial(int n) {\n  checkNonNegative(\"n\", n);\n  return (n < factorials.length) ? factorials[n] : Long.MAX_VALUE;\n}", "summary_tokens": ["returns", "n", "that", "is", "the", "product", "of", "the", "first", "n", "positive", "integers", "0", "if", "n", "0", "or", "long", "max", "value", "if", "the", "result", "does", "not", "fit", "in", "a", "long"], "project": "guava"}
{"id": 1045, "code": "public static <S> ElementOrder<S> sorted(Comparator<S> comparator) {\n  return new ElementOrder<>(Type.SORTED, checkNotNull(comparator));\n}", "summary_tokens": ["returns", "an", "instance", "which", "specifies", "that", "the", "ordering", "of", "the", "elements", "is", "guaranteed", "to", "be", "determined", "by", "comparator"], "project": "guava"}
{"id": 1375, "code": "public static boolean isInetAddress(String ipString) {\n  return ipStringToBytes(ipString) != null;\n}", "summary_tokens": ["returns", "true", "if", "the", "supplied", "string", "is", "a", "valid", "ip", "string", "literal", "false", "otherwise"], "project": "guava"}
{"id": 935, "code": "public E removeLast() {\n  if (isEmpty()) {\n    throw new NoSuchElementException();\n  }\n  return removeAndGet(getMaxElementIndex());\n}", "summary_tokens": ["removes", "and", "returns", "the", "greatest", "element", "of", "this", "queue"], "project": "guava"}
{"id": 261, "code": "static <K, V> void simulateValueReclamation(Cache<K, V> cache, K key) {\n  ReferenceEntry<K, V> entry = getReferenceEntry(cache, key);\n  if (entry != null) {\n    ValueReference<K, V> valueRef = entry.getValueReference();\n      \n    Preconditions.checkState(valueRef instanceof Reference);\n    Reference<V> ref = (Reference<V>) valueRef;\n    if (ref != null) {\n      ref.clear();\n    }\n  }\n}", "summary_tokens": ["poke", "into", "the", "cache", "internals", "to", "simulate", "garbage", "collection", "of", "the", "value", "associated", "with", "the", "given", "key"], "project": "guava"}
{"id": 119, "code": "protected final <T> void setDistinctValues(Class<T> type, T value1, T value2) {\n  tester.setDistinctValues(type, value1, value2);\n}", "summary_tokens": ["sets", "two", "distinct", "values", "for", "type"], "project": "guava"}
{"id": 193, "code": "private void runConcurrentTest(int numberOfThreads, final Callable<Void> callable)\n    throws Exception {\n  ExecutorService executorService = Executors.newFixedThreadPool(numberOfThreads);\n  final CountDownLatch startLatch = new CountDownLatch(numberOfThreads);\n  final CountDownLatch doneLatch = new CountDownLatch(numberOfThreads);\n  for (int i = numberOfThreads; i > 0; i--) {\n    @SuppressWarnings(\"unused\") \n    Future<?> possiblyIgnoredError =\n        executorService.submit(\n            new Callable<Void>() {\n              @Override\n              public Void call() throws Exception {\n                startLatch.countDown();\n                startLatch.await();\n                callable.call();\n                doneLatch.countDown();\n                return null;\n              }\n            });\n  }\n  doneLatch.await();\n}", "summary_tokens": ["runs", "callable", "concurrently", "number", "of", "threads", "times"], "project": "guava"}
{"id": 639, "code": "public static boolean equal(@CheckForNull Object a, @CheckForNull Object b) {\n  return a == b || (a != null && a.equals(b));\n}", "summary_tokens": ["determines", "whether", "two", "possibly", "null", "objects", "are", "equal"], "project": "guava"}
{"id": 1445, "code": "static MediaType createFontType(String subtype) {\n  return create(FONT_TYPE, subtype);\n}", "summary_tokens": ["creates", "a", "media", "type", "with", "the", "font", "type", "and", "the", "given", "subtype"], "project": "guava"}
{"id": 1358, "code": "public boolean hasPort() {\n  return port >= 0;\n}", "summary_tokens": ["return", "true", "if", "this", "instance", "has", "a", "defined", "port"], "project": "guava"}
{"id": 1763, "code": "public final TypeToken<? extends R> getReturnType() {\n  return (TypeToken<? extends R>) TypeToken.of(getGenericReturnType());\n}", "summary_tokens": ["returns", "the", "return", "type", "of", "this", "invokable"], "project": "guava"}
{"id": 982, "code": "public Comparator<? super C> columnComparator() {\n  return columnComparator;\n}", "summary_tokens": ["returns", "the", "comparator", "that", "orders", "the", "columns"], "project": "guava"}
{"id": 1916, "code": "public ImmutableMap<Service, Long> startupTimes() {\n  return state.startupTimes();\n}", "summary_tokens": ["returns", "the", "service", "load", "times"], "project": "guava"}
{"id": 1497, "code": "public static char[] toArray(Collection<Character> collection) {\n  if (collection instanceof CharArrayAsList) {\n    return ((CharArrayAsList) collection).toCharArray();\n  }\n\n  Object[] boxedArray = collection.toArray();\n  int len = boxedArray.length;\n  char[] array = new char[len];\n  for (int i = 0; i < len; i++) {\n      \n    array[i] = (Character) checkNotNull(boxedArray[i]);\n  }\n  return array;\n}", "summary_tokens": ["copies", "a", "collection", "of", "character", "instances", "into", "a", "new", "array", "of", "primitive", "char", "values"], "project": "guava"}
{"id": 1007, "code": "protected static int codePointAt(CharSequence seq, int index, int end) {\n  checkNotNull(seq);\n  if (index < end) {\n    char c1 = seq.charAt(index++);\n    if (c1 < Character.MIN_HIGH_SURROGATE || c1 > Character.MAX_LOW_SURROGATE) {\n        \n      return c1;\n    } else if (c1 <= Character.MAX_HIGH_SURROGATE) {\n        \n      if (index == end) {\n        return -c1;\n      }\n        \n      char c2 = seq.charAt(index);\n      if (Character.isLowSurrogate(c2)) {\n        return Character.toCodePoint(c1, c2);\n      }\n      throw new IllegalArgumentException(\n          \"Expected low surrogate but got char '\"\n              + c2\n              + \"' with value \"\n              + (int) c2\n              + \" at index \"\n              + index\n              + \" in '\"\n              + seq\n              + \"'\");\n    } else {\n      throw new IllegalArgumentException(\n          \"Unexpected low surrogate character '\"\n              + c1\n              + \"' with value \"\n              + (int) c1\n              + \" at index \"\n              + (index - 1)\n              + \" in '\"\n              + seq\n              + \"'\");\n    }\n  }\n  throw new IndexOutOfBoundsException(\"Index exceeds specified range\");\n}", "summary_tokens": ["returns", "the", "unicode", "code", "point", "of", "the", "character", "at", "the", "given", "index"], "project": "guava"}
{"id": 585, "code": "public static CharMatcher javaLetter() {\n  return JavaLetter.INSTANCE;\n}", "summary_tokens": ["determines", "whether", "a", "character", "is", "a", "bmp", "letter", "according", "to", "character", "is", "letter", "char", "java", "s", "definition"], "project": "guava"}
{"id": 1047, "code": "public Comparator<T> comparator() {\n  if (comparator != null) {\n    return comparator;\n  }\n  throw new UnsupportedOperationException(\"This ordering does not define a comparator.\");\n}", "summary_tokens": ["returns", "the", "comparator", "used"], "project": "guava"}
{"id": 1792, "code": "public final TypeToken<T> wrap() {\n  if (isPrimitive()) {\n    @SuppressWarnings(\"unchecked\") \n    Class<T> type = (Class<T>) runtimeType;\n    return of(Primitives.wrap(type));\n  }\n  return this;\n}", "summary_tokens": ["returns", "the", "corresponding", "wrapper", "type", "if", "this", "is", "a", "primitive", "type", "otherwise", "returns", "this", "itself"], "project": "guava"}
{"id": 459, "code": "public void testCountingInMultipleThreads() throws InterruptedException {\n  final AtomicDoubleArray aa = new AtomicDoubleArray(SIZE);\n  for (int i = 0; i < SIZE; i++) {\n    aa.set(i, (double) COUNTDOWN);\n  }\n  Counter c1 = new Counter(aa);\n  Counter c2 = new Counter(aa);\n  Thread t1 = newStartedThread(c1);\n  Thread t2 = newStartedThread(c2);\n  awaitTermination(t1);\n  awaitTermination(t2);\n  assertEquals(SIZE * COUNTDOWN, c1.counts + c2.counts);\n}", "summary_tokens": ["multiple", "threads", "using", "same", "array", "of", "counters", "successfully", "update", "a", "number", "of", "times", "equal", "to", "total", "count"], "project": "guava"}
{"id": 1959, "code": "public void testUpdateAndGetWithSubtract() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(SIZE);\n  for (int i : new int[] {0, SIZE - 1}) {\n    for (double x : VALUES) {\n      for (double y : VALUES) {\n        aa.set(i, x);\n        double z = aa.updateAndGet(i, value -> value - y);\n        assertBitEquals(x - y, z);\n        assertBitEquals(x - y, aa.get(i));\n      }\n    }\n  }\n}", "summary_tokens": ["update", "and", "get", "subtracts", "given", "value", "to", "current", "and", "returns", "current", "value"], "project": "guava"}
{"id": 287, "code": "static <K, V> CountingRemovalListener<K, V> countingRemovalListener() {\n  return new CountingRemovalListener<>();\n}", "summary_tokens": ["type", "inferring", "factory", "method", "for", "creating", "a", "counting", "removal", "listener"], "project": "guava"}
{"id": 11, "code": "protected Entry<K, V>[] createArrayWithNullKey() {\n  Entry<K, V>[] array = createSamplesArray();\n  int nullKeyLocation = getNullLocation();\n  Entry<K, V> oldEntry = array[nullKeyLocation];\n  array[nullKeyLocation] = entry(null, oldEntry.getValue());\n  return array;\n}", "summary_tokens": ["an", "array", "of", "the", "proper", "size", "with", "null", "as", "the", "key", "of", "the", "middle", "element"], "project": "guava"}
{"id": 548, "code": "public void testInvokeAnyImpl_noTaskCompletes() throws Exception {\n  ListeningExecutorService e = newDirectExecutorService();\n  List<Callable<String>> l = new ArrayList<>();\n  l.add(new NPETask());\n  try {\n    invokeAnyImpl(e, l, false, 0, TimeUnit.NANOSECONDS);\n    fail();\n  } catch (ExecutionException success) {\n    assertThat(success).hasCauseThat().isInstanceOf(NullPointerException.class);\n  } finally {\n    joinPool(e);\n  }\n}", "summary_tokens": ["invoke", "any", "c", "throws", "execution", "exception", "if", "no", "task", "in", "c", "completes"], "project": "guava"}
{"id": 746, "code": "public CacheStats plus(CacheStats other) {\n  return new CacheStats(\n      saturatedAdd(hitCount, other.hitCount),\n      saturatedAdd(missCount, other.missCount),\n      saturatedAdd(loadSuccessCount, other.loadSuccessCount),\n      saturatedAdd(loadExceptionCount, other.loadExceptionCount),\n      saturatedAdd(totalLoadTime, other.totalLoadTime),\n      saturatedAdd(evictionCount, other.evictionCount));\n}", "summary_tokens": ["returns", "a", "new", "cache", "stats", "representing", "the", "sum", "of", "this", "cache", "stats", "and", "other"], "project": "guava"}
{"id": 1434, "code": "public ImmutableListMultimap<String, String> parameters() {\n  return parameters;\n}", "summary_tokens": ["returns", "a", "multimap", "containing", "the", "parameters", "of", "this", "media", "type"], "project": "guava"}
{"id": 1398, "code": "public static Inet4Address fromInteger(int address) {\n  return getInet4Address(Ints.toByteArray(address));\n}", "summary_tokens": ["returns", "an", "inet", "0", "address", "having", "the", "integer", "value", "specified", "by", "the", "argument"], "project": "guava"}
{"id": 4, "code": "protected void expectContents(Collection<E> expected) {\n  Helpers.assertEqualIgnoringOrder(expected, actualContents());\n}", "summary_tokens": ["asserts", "that", "the", "collection", "under", "test", "contains", "exactly", "the", "given", "elements", "respecting", "cardinality", "but", "not", "order"], "project": "guava"}
{"id": 1600, "code": "public static int fromBytes(byte b1, byte b2, byte b3, byte b4) {\n  return b1 << 24 | (b2 & 0xFF) << 16 | (b3 & 0xFF) << 8 | (b4 & 0xFF);\n}", "summary_tokens": ["returns", "the", "int", "value", "whose", "byte", "representation", "is", "the", "given", "0", "bytes", "in", "big", "endian", "order", "equivalent", "to", "ints"], "project": "guava"}
{"id": 627, "code": "public final B apply(@CheckForNull A a) {\n  return convert(a);\n}", "summary_tokens": ["provided", "to", "satisfy", "the", "function", "interface", "use", "convert", "instead"], "project": "guava"}
{"id": 541, "code": "Thread newStartedThread(Runnable runnable) {\n  Thread t = new Thread(runnable);\n  t.setDaemon(true);\n  t.start();\n  return t;\n}", "summary_tokens": ["returns", "a", "new", "started", "daemon", "thread", "running", "the", "given", "runnable"], "project": "guava"}
{"id": 166, "code": "static <T> T reserialize(T object) {\n  checkNotNull(object);\n  ByteArrayOutputStream bytes = new ByteArrayOutputStream();\n  try {\n    ObjectOutputStream out = new ObjectOutputStream(bytes);\n    out.writeObject(object);\n    ObjectInputStream in = new ObjectInputStream(new ByteArrayInputStream(bytes.toByteArray()));\n    return (T) in.readObject();\n  } catch (IOException | ClassNotFoundException e) {\n    throw new RuntimeException(e);\n  }\n}", "summary_tokens": ["serializes", "and", "deserializes", "the", "specified", "object"], "project": "guava"}
{"id": 1363, "code": "public static HostAndPort fromString(String hostPortString) {\n  checkNotNull(hostPortString);\n  String host;\n  String portString = null;\n  boolean hasBracketlessColons = false;\n\n  if (hostPortString.startsWith(\"[\")) {\n    String[] hostAndPort = getHostAndPortFromBracketedHost(hostPortString);\n    host = hostAndPort[0];\n    portString = hostAndPort[1];\n  } else {\n    int colonPos = hostPortString.indexOf(':');\n    if (colonPos >= 0 && hostPortString.indexOf(':', colonPos + 1) == -1) {\n        \n      host = hostPortString.substring(0, colonPos);\n      portString = hostPortString.substring(colonPos + 1);\n    } else {\n        \n      host = hostPortString;\n      hasBracketlessColons = (colonPos >= 0);\n    }\n  }\n\n  int port = NO_PORT;\n  if (!Strings.isNullOrEmpty(portString)) {\n      \n      \n    checkArgument(\n        !portString.startsWith(\"+\") && CharMatcher.ascii().matchesAllOf(portString),\n        \"Unparseable port number: %s\",\n        hostPortString);\n    try {\n      port = Integer.parseInt(portString);\n    } catch (NumberFormatException e) {\n      throw new IllegalArgumentException(\"Unparseable port number: \" + hostPortString);\n    }\n    checkArgument(isValidPort(port), \"Port number out of range: %s\", hostPortString);\n  }\n\n  return new HostAndPort(host, port, hasBracketlessColons);\n}", "summary_tokens": ["split", "a", "freeform", "string", "into", "a", "host", "and", "port", "without", "strict", "validation"], "project": "guava"}
{"id": 1969, "code": "private static boolean isDurationBased(Method method) {\n  Class<?>[] parameterTypes = method.getParameterTypes();\n  return parameterTypes.length >= 1\n      && parameterTypes[parameterTypes.length - 1] == Duration.class;\n}", "summary_tokens": ["determines", "whether", "the", "given", "method", "takes", "a", "duration", "as", "its", "last", "parameter"], "project": "guava"}
{"id": 1937, "code": "String pendingToString() {\n  if (state == State.DELEGATED) {\n    return \"setFuture=[\" + delegate + \"]\";\n  }\n  return null;\n}", "summary_tokens": ["provide", "a", "human", "readable", "explanation", "of", "why", "this", "future", "has", "not", "yet", "completed"], "project": "guava"}
{"id": 1165, "code": "public double doubleValue() {\n  return (double) sum();\n}", "summary_tokens": ["returns", "the", "sum", "as", "a", "double", "after", "a", "widening", "primitive", "conversion"], "project": "guava"}
{"id": 99, "code": "public static Method getCreateWithNullKeyUnsupportedMethod() {\n  return Helpers.getMethod(MapCreationTester.class, \"testCreateWithNullKeyUnsupported\");\n}", "summary_tokens": ["returns", "the", "method", "instance", "for", "test", "create", "with", "null", "key", "unsupported", "so", "that", "tests", "can", "suppress", "it", "with", "feature", "specific", "test", "suite", "builder"], "project": "guava"}
{"id": 524, "code": "public void threadAssertTrue(boolean b) {\n  try {\n    assertTrue(b);\n  } catch (AssertionFailedError t) {\n    threadRecordFailure(t);\n    throw t;\n  }\n}", "summary_tokens": ["just", "like", "assert", "true", "b", "but", "additionally", "recording", "using", "thread", "record", "failure", "any", "assertion", "failed", "error", "thrown", "so", "that", "the", "current", "testcase", "will", "fail"], "project": "guava"}
{"id": 1448, "code": "static MediaType createVideoType(String subtype) {\n  return create(VIDEO_TYPE, subtype);\n}", "summary_tokens": ["creates", "a", "media", "type", "with", "the", "video", "type", "and", "the", "given", "subtype"], "project": "guava"}
{"id": 312, "code": "public void testUniqueIndexNullValue() {\n  List<String> listWithNull = Lists.newArrayList((String) null);\n  try {\n    Maps.uniqueIndex(listWithNull, Functions.constant(1));\n    fail();\n  } catch (NullPointerException expected) {\n  }\n}", "summary_tokens": ["null", "values", "are", "not", "allowed"], "project": "guava"}
{"id": 751, "code": "ReferenceEntry<K, V> copyEntry(ReferenceEntry<K, V> original, ReferenceEntry<K, V> newNext) {\n  int hash = original.getHash();\n  return segmentFor(hash).copyEntry(original, newNext);\n}", "summary_tokens": ["this", "method", "is", "a", "convenience", "for", "testing"], "project": "guava"}
{"id": 987, "code": "public static <T> TreeTraverser<T> using(\n    final Function<T, ? extends Iterable<T>> nodeToChildrenFunction) {\n  checkNotNull(nodeToChildrenFunction);\n  return new TreeTraverser<T>() {\n    @Override\n    public Iterable<T> children(T root) {\n      return nodeToChildrenFunction.apply(root);\n    }\n  };\n}", "summary_tokens": ["returns", "a", "tree", "traverser", "that", "uses", "the", "given", "function", "to", "navigate", "from", "a", "node", "to", "its", "children"], "project": "guava"}
{"id": 329, "code": "private void assertDrained(BlockingQueue<Object> q) {\n  assertNull(q.peek());\n  assertInterruptibleDrained(q);\n  assertUninterruptibleDrained(q);\n}", "summary_tokens": ["checks", "that", "drain", "invocations", "behave", "correctly", "for", "a", "drained", "empty", "queue"], "project": "guava"}
{"id": 858, "code": "public static <K extends Comparable<?>, V> ImmutableRangeMap<K, V> of(Range<K> range, V value) {\n  return new ImmutableRangeMap<>(ImmutableList.of(range), ImmutableList.of(value));\n}", "summary_tokens": ["returns", "an", "immutable", "range", "map", "mapping", "a", "single", "range", "to", "a", "single", "value"], "project": "guava"}
{"id": 77, "code": "public static <E> void assertCollectionIsUnmodifiable(Collection<E> collection, E sampleElement) {\n  Collection<E> siblingCollection = new ArrayList<>();\n  siblingCollection.add(sampleElement);\n\n  Collection<E> copy = new ArrayList<>();\n    \n    \n  Iterators.addAll(copy, collection.iterator());\n\n  try {\n    collection.add(sampleElement);\n    fail(\"add succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n\n  assertCollectionsAreEquivalent(copy, collection);\n\n  try {\n    collection.addAll(siblingCollection);\n    fail(\"addAll succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertCollectionsAreEquivalent(copy, collection);\n\n  try {\n    collection.clear();\n    fail(\"clear succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertCollectionsAreEquivalent(copy, collection);\n\n  assertIteratorIsUnmodifiable(collection.iterator());\n  assertCollectionsAreEquivalent(copy, collection);\n\n  try {\n    collection.remove(sampleElement);\n    fail(\"remove succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertCollectionsAreEquivalent(copy, collection);\n\n  try {\n    collection.removeAll(siblingCollection);\n    fail(\"removeAll succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertCollectionsAreEquivalent(copy, collection);\n\n  try {\n    collection.retainAll(siblingCollection);\n    fail(\"retainAll succeeded on unmodifiable collection\");\n  } catch (UnsupportedOperationException expected) {\n  }\n  assertCollectionsAreEquivalent(copy, collection);\n}", "summary_tokens": ["verifies", "that", "a", "collection", "is", "immutable"], "project": "guava"}
{"id": 1641, "code": "public static int indexOf(short[] array, short[] target) {\n  checkNotNull(array, \"array\");\n  checkNotNull(target, \"target\");\n  if (target.length == 0) {\n    return 0;\n  }\n\n  outer:\n  for (int i = 0; i < array.length - target.length + 1; i++) {\n    for (int j = 0; j < target.length; j++) {\n      if (array[i + j] != target[j]) {\n        continue outer;\n      }\n    }\n    return i;\n  }\n  return -1;\n}", "summary_tokens": ["returns", "the", "start", "position", "of", "the", "first", "occurrence", "of", "the", "specified", "target", "within", "array", "or", "0", "if", "there", "is", "no", "such", "occurrence"], "project": "guava"}
{"id": 319, "code": "public void testInvalidatingRemove2() {\n  MinMaxPriorityQueue<Integer> mmHeap = MinMaxPriorityQueue.create();\n  List<Integer> values =\n      Lists.newArrayList(\n          1, 20, 1000, 2, 3, 30, 40, 10, 11, 12, 13, 300, 400, 500, 600, 4, 5, 6, 7, 8, 9, 4, 5,\n          200, 250);\n  mmHeap.addAll(values);\n  assertEquals(25, mmHeap.size());\n  assertTrue(\"Heap is not intact initially\", mmHeap.isIntact());\n  mmHeap.remove(2);\n  assertEquals(24, mmHeap.size());\n  assertTrue(\"Heap is not intact after remove()\", mmHeap.isIntact());\n  values.removeAll(Lists.newArrayList(2));\n  assertEquals(values.size(), mmHeap.size());\n  assertTrue(values.containsAll(mmHeap));\n  assertTrue(mmHeap.containsAll(values));\n}", "summary_tokens": ["this", "tests", "a", "more", "obscure", "special", "case", "but", "otherwise", "similar", "to", "above"], "project": "guava"}
{"id": 150, "code": "public static void awaitClear(WeakReference<?> ref) {\n  awaitDone(\n      new FinalizationPredicate() {\n        @Override\n        public boolean isDone() {\n          return ref.get() == null;\n        }\n      });\n}", "summary_tokens": ["waits", "until", "the", "given", "weak", "reference", "is", "cleared", "invoking", "the", "garbage", "collector", "as", "necessary", "to", "try", "to", "ensure", "that", "this", "will", "happen"], "project": "guava"}
{"id": 739, "code": "public long loadSuccessCount() {\n  return loadSuccessCount;\n}", "summary_tokens": ["returns", "the", "number", "of", "times", "cache", "lookup", "methods", "have", "successfully", "loaded", "a", "new", "value"], "project": "guava"}
{"id": 15, "code": "protected V get(K key) {\n  return getMap().get(key);\n}", "summary_tokens": ["wrapper", "for", "map", "get", "object", "that", "forces", "the", "caller", "to", "pass", "in", "a", "key", "of", "the", "same", "type", "as", "the", "map"], "project": "guava"}
{"id": 1759, "code": "public final boolean isSynchronized() {\n  return Modifier.isSynchronized(getModifiers());\n}", "summary_tokens": ["returns", "true", "if", "the", "method", "is", "synchronized"], "project": "guava"}
{"id": 1766, "code": "public final <R1 extends R> Invokable<T, R1> returning(TypeToken<R1> returnType) {\n  if (!returnType.isSupertypeOf(getReturnType())) {\n    throw new IllegalArgumentException(\n        \"Invokable is known to return \" + getReturnType() + \", not \" + returnType);\n  }\n  @SuppressWarnings(\"unchecked\") \n  Invokable<T, R1> specialized = (Invokable<T, R1>) this;\n  return specialized;\n}", "summary_tokens": ["explicitly", "specifies", "the", "return", "type", "of", "this", "invokable"], "project": "guava"}
{"id": 940, "code": "public Iterator<E> iterator() {\n  return new QueueIterator();\n}", "summary_tokens": ["returns", "an", "iterator", "over", "the", "elements", "contained", "in", "this", "collection", "i", "in", "no", "particular", "order", "i"], "project": "guava"}
{"id": 18, "code": "public B named(String name) {\n  if (name.contains(\"(\")) {\n    throw new IllegalArgumentException(\n        \"Eclipse hides all characters after \"\n            + \"'('; please use '[]' or other characters instead of parentheses\");\n  }\n  this.name = name;\n  return self();\n}", "summary_tokens": ["configures", "this", "builder", "produce", "a", "test", "suite", "with", "the", "given", "name"], "project": "guava"}
{"id": 376, "code": "static void assertInvariants(HashFunction hashFunction) {\n  int objects = 100;\n  Set<HashCode> hashcodes = Sets.newHashSetWithExpectedSize(objects);\n  Random random = new Random(314159);\n  for (int i = 0; i < objects; i++) {\n    int value = random.nextInt();\n    HashCode hashcode1 = hashFunction.hashInt(value);\n    HashCode hashcode2 = hashFunction.hashInt(value);\n    Assert.assertEquals(hashcode1, hashcode2); \n    Assert.assertEquals(hashFunction.bits(), hashcode1.bits());\n    Assert.assertEquals(hashFunction.bits(), hashcode1.asBytes().length * 8);\n    hashcodes.add(hashcode1);\n  }\n  Assert.assertTrue(hashcodes.size() > objects * 0.95); \n\n  assertHashBytesThrowsCorrectExceptions(hashFunction);\n  assertIndependentHashers(hashFunction);\n  assertShortcutsAreEquivalent(hashFunction, 512);\n}", "summary_tokens": ["checks", "that", "a", "hasher", "returns", "the", "same", "hash", "code", "when", "given", "the", "same", "input", "and", "also", "that", "the", "collision", "rate", "looks", "sane"], "project": "guava"}
{"id": 214, "code": "public boolean contains(@Nullable Object o) {\n  if (o == null) return false;\n  final E[] items = this.items;\n  final Monitor monitor = this.monitor;\n  monitor.enter();\n  try {\n    int i = takeIndex;\n    int k = 0;\n    while (k++ < count) {\n      if (o.equals(items[i])) return true;\n      i = inc(i);\n    }\n    return false;\n  } finally {\n    monitor.leave();\n  }\n}", "summary_tokens": ["returns", "true", "if", "this", "queue", "contains", "the", "specified", "element"], "project": "guava"}
{"id": 560, "code": "public void testCreate() throws Exception {\n  SettableFuture<Integer> future = SettableFuture.create();\n  assertFalse(future.isDone());\n  assertFalse(future.isCancelled());\n}", "summary_tokens": ["tests", "the", "initial", "state", "of", "the", "future"], "project": "guava"}
{"id": 27, "code": "protected final void assertInvariants(Map<K, V> map) {\n  Set<K> keySet = map.keySet();\n  Collection<V> valueCollection = map.values();\n  Set<Entry<K, V>> entrySet = map.entrySet();\n\n  assertEquals(map.size() == 0, map.isEmpty());\n  assertEquals(map.size(), keySet.size());\n  assertEquals(keySet.size() == 0, keySet.isEmpty());\n  assertEquals(!keySet.isEmpty(), keySet.iterator().hasNext());\n\n  int expectedKeySetHash = 0;\n  for (K key : keySet) {\n    V value = map.get(key);\n    expectedKeySetHash += key != null ? key.hashCode() : 0;\n    assertTrue(map.containsKey(key));\n    assertTrue(map.containsValue(value));\n    assertTrue(valueCollection.contains(value));\n    assertTrue(valueCollection.containsAll(Collections.singleton(value)));\n    assertTrue(entrySet.contains(mapEntry(key, value)));\n    assertTrue(allowsNullKeys || (key != null));\n  }\n  assertEquals(expectedKeySetHash, keySet.hashCode());\n\n  assertEquals(map.size(), valueCollection.size());\n  assertEquals(valueCollection.size() == 0, valueCollection.isEmpty());\n  assertEquals(!valueCollection.isEmpty(), valueCollection.iterator().hasNext());\n  for (V value : valueCollection) {\n    assertTrue(map.containsValue(value));\n    assertTrue(allowsNullValues || (value != null));\n  }\n\n  assertEquals(map.size(), entrySet.size());\n  assertEquals(entrySet.size() == 0, entrySet.isEmpty());\n  assertEquals(!entrySet.isEmpty(), entrySet.iterator().hasNext());\n  assertEntrySetNotContainsString(entrySet);\n\n  boolean supportsValuesHashCode = supportsValuesHashCode(map);\n  if (supportsValuesHashCode) {\n    int expectedEntrySetHash = 0;\n    for (Entry<K, V> entry : entrySet) {\n      assertTrue(map.containsKey(entry.getKey()));\n      assertTrue(map.containsValue(entry.getValue()));\n      int expectedHash =\n          (entry.getKey() == null ? 0 : entry.getKey().hashCode())\n              ^ (entry.getValue() == null ? 0 : entry.getValue().hashCode());\n      assertEquals(expectedHash, entry.hashCode());\n      expectedEntrySetHash += expectedHash;\n    }\n    assertEquals(expectedEntrySetHash, entrySet.hashCode());\n    assertTrue(entrySet.containsAll(new HashSet<Entry<K, V>>(entrySet)));\n    assertTrue(entrySet.equals(new HashSet<Entry<K, V>>(entrySet)));\n  }\n\n  Object[] entrySetToArray1 = entrySet.toArray();\n  assertEquals(map.size(), entrySetToArray1.length);\n  assertTrue(Arrays.asList(entrySetToArray1).containsAll(entrySet));\n\n  Entry<?, ?>[] entrySetToArray2 = new Entry<?, ?>[map.size() + 2];\n  entrySetToArray2[map.size()] = mapEntry(\"foo\", 1);\n  assertSame(entrySetToArray2, entrySet.toArray(entrySetToArray2));\n  assertNull(entrySetToArray2[map.size()]);\n  assertTrue(Arrays.asList(entrySetToArray2).containsAll(entrySet));\n\n  Object[] valuesToArray1 = valueCollection.toArray();\n  assertEquals(map.size(), valuesToArray1.length);\n  assertTrue(Arrays.asList(valuesToArray1).containsAll(valueCollection));\n\n  Object[] valuesToArray2 = new Object[map.size() + 2];\n  valuesToArray2[map.size()] = \"foo\";\n  assertSame(valuesToArray2, valueCollection.toArray(valuesToArray2));\n  assertNull(valuesToArray2[map.size()]);\n  assertTrue(Arrays.asList(valuesToArray2).containsAll(valueCollection));\n\n  if (supportsValuesHashCode) {\n    int expectedHash = 0;\n    for (Entry<K, V> entry : entrySet) {\n      expectedHash += entry.hashCode();\n    }\n    assertEquals(expectedHash, map.hashCode());\n  }\n\n  assertMoreInvariants(map);\n}", "summary_tokens": ["checks", "all", "the", "properties", "that", "should", "always", "hold", "of", "a", "map"], "project": "guava"}
{"id": 202, "code": "int alwaysAppendThenBackUp(int reps) {\n  int dummy = 0;\n  for (int i = 0; i < reps; i++) {\n    StringBuilder sb = new StringBuilder();\n    for (String comp : components) {\n      sb.append(comp);\n      sb.append(DELIMITER_STRING);\n    }\n    if (sb.length() > 0) {\n      sb.setLength(sb.length() - DELIMITER_STRING.length());\n    }\n    dummy ^= sb.toString().length();\n  }\n  return dummy;\n}", "summary_tokens": ["always", "append", "the", "delimiter", "after", "the", "component", "and", "in", "the", "very", "end", "shortens", "the", "buffer", "to", "get", "rid", "of", "the", "extra", "trailing", "delimiter"], "project": "guava"}
{"id": 778, "code": "static int getHashPrefix(int value, int mask) {\n  return value & ~mask;\n}", "summary_tokens": ["returns", "the", "hash", "prefix", "given", "the", "current", "mask"], "project": "guava"}
{"id": 1768, "code": "public TypeToken<?> getType() {\n  return type;\n}", "summary_tokens": ["returns", "the", "type", "of", "the", "parameter"], "project": "guava"}
{"id": 1394, "code": "public static boolean isMappedIPv4Address(String ipString) {\n  byte[] bytes = ipStringToBytes(ipString);\n  if (bytes != null && bytes.length == 16) {\n    for (int i = 0; i < 10; i++) {\n      if (bytes[i] != 0) {\n        return false;\n      }\n    }\n    for (int i = 10; i < 12; i++) {\n      if (bytes[i] != (byte) 0xff) {\n        return false;\n      }\n    }\n    return true;\n  }\n  return false;\n}", "summary_tokens": ["evaluates", "whether", "the", "argument", "is", "an", "ipv", "0", "mapped", "ipv", "0", "address"], "project": "guava"}
{"id": 1016, "code": "void handleSubscriberException(Throwable e, SubscriberExceptionContext context) {\n  checkNotNull(e);\n  checkNotNull(context);\n  try {\n    exceptionHandler.handleException(e, context);\n  } catch (Throwable e2) {\n      \n    logger.log(\n        Level.SEVERE,\n        String.format(Locale.ROOT, \"Exception %s thrown while handling exception: %s\", e2, e),\n        e2);\n  }\n}", "summary_tokens": ["handles", "the", "given", "exception", "thrown", "by", "a", "subscriber", "with", "the", "given", "context"], "project": "guava"}
{"id": 755, "code": "V getLiveValue(ReferenceEntry<K, V> entry, long now) {\n  if (entry.getKey() == null) {\n    return null;\n  }\n  V value = entry.getValueReference().get();\n  if (value == null) {\n    return null;\n  }\n\n  if (isExpired(entry, now)) {\n    return null;\n  }\n  return value;\n}", "summary_tokens": ["gets", "the", "value", "from", "an", "entry"], "project": "guava"}
{"id": 1542, "code": "public int length() {\n  return end - start;\n}", "summary_tokens": ["returns", "the", "number", "of", "values", "in", "this", "array"], "project": "guava"}
{"id": 1338, "code": "public static double meanOf(long... values) {\n  checkArgument(values.length > 0);\n  double mean = values[0];\n  for (int index = 1; index < values.length; index++) {\n    double value = values[index];\n    if (isFinite(value) && isFinite(mean)) {\n        \n      mean += (value - mean) / (index + 1);\n    } else {\n      mean = calculateNewMeanNonFinite(mean, value);\n    }\n  }\n  return mean;\n}", "summary_tokens": ["returns", "the", "a", "href", "http", "en"], "project": "guava"}
{"id": 397, "code": "static byte[] newPreFilledByteArray(int offset, int size) {\n  byte[] array = new byte[size];\n  for (int i = 0; i < size; i++) {\n    array[i] = (byte) (offset + i);\n  }\n  return array;\n}", "summary_tokens": ["returns", "a", "byte", "array", "of", "length", "size", "that", "has", "values", "offset"], "project": "guava"}
{"id": 1581, "code": "public ImmutableLongArray subArray(int startIndex, int endIndex) {\n  Preconditions.checkPositionIndexes(startIndex, endIndex, length());\n  return startIndex == endIndex\n      ? EMPTY\n      : new ImmutableLongArray(array, start + startIndex, start + endIndex);\n}", "summary_tokens": ["returns", "a", "new", "immutable", "array", "containing", "the", "values", "in", "the", "specified", "range"], "project": "guava"}
{"id": 383, "code": "private static int runSuppressionFailureTest(ByteSource in, ByteSink out) {\n  try {\n    in.copyTo(out);\n    fail();\n  } catch (IOException expected) {\n    return CloserTest.getSuppressed(expected).length;\n  }\n  throw new AssertionError(); \n}", "summary_tokens": ["the", "number", "of", "exceptions", "that", "were", "suppressed", "on", "the", "expected", "thrown", "exception"], "project": "guava"}
{"id": 232, "code": "private static ImmutableList<URL> parseJavaClassPath() {\n  ImmutableList.Builder<URL> urls = ImmutableList.builder();\n  for (String entry : Splitter.on(PATH_SEPARATOR.value()).split(JAVA_CLASS_PATH.value())) {\n    try {\n      try {\n        urls.add(new File(entry).toURI().toURL());\n      } catch (SecurityException e) { \n        urls.add(new URL(\"file\", null, new File(entry).getAbsolutePath()));\n      }\n    } catch (MalformedURLException e) {\n      AssertionError error = new AssertionError(\"malformed class path entry: \" + entry);\n      error.initCause(e);\n      throw error;\n    }\n  }\n  return urls.build();\n}", "summary_tokens": ["returns", "the", "urls", "in", "the", "class", "path", "specified", "by", "the", "java"], "project": "guava"}
{"id": 1604, "code": "public static Comparator<int[]> lexicographicalComparator() {\n  return LexicographicalComparator.INSTANCE;\n}", "summary_tokens": ["returns", "a", "comparator", "that", "compares", "two", "int", "arrays", "a", "href", "http", "en"], "project": "guava"}
{"id": 977, "code": "private static Object createHashTable(\n    @Nullable Object[] alternatingKeysAndValues, int n, int tableSize, int keyOffset) {\n  if (n == 1) {\n      \n      \n    checkEntryNotNull(\n        requireNonNull(alternatingKeysAndValues[keyOffset]),\n        requireNonNull(alternatingKeysAndValues[keyOffset ^ 1]));\n    return null;\n  }\n  int mask = tableSize - 1;\n  Builder.DuplicateKey duplicateKey = null;\n  if (tableSize <= BYTE_MAX_SIZE) {\n      \n    byte[] hashTable = new byte[tableSize];\n    Arrays.fill(hashTable, ABSENT);\n\n    int outI = 0;\n    entries:\n    for (int i = 0; i < n; i++) {\n      int keyIndex = 2 * i + keyOffset;\n      int outKeyIndex = 2 * outI + keyOffset;\n        \n      Object key = requireNonNull(alternatingKeysAndValues[keyIndex]);\n      Object value = requireNonNull(alternatingKeysAndValues[keyIndex ^ 1]);\n      checkEntryNotNull(key, value);\n      for (int h = Hashing.smear(key.hashCode()); ; h++) {\n        h &= mask;\n        int previousKeyIndex = hashTable[h] & BYTE_MASK; \n        if (previousKeyIndex == BYTE_MASK) { \n          hashTable[h] = (byte) outKeyIndex;\n          break;\n        } else if (key.equals(alternatingKeysAndValues[previousKeyIndex])) {\n          duplicateKey =\n              new Builder.DuplicateKey(\n                  key, value, requireNonNull(alternatingKeysAndValues[previousKeyIndex ^ 1]));\n          alternatingKeysAndValues[previousKeyIndex ^ 1] = value;\n          continue entries;\n        }\n      }\n      if (outI < i) { \n        alternatingKeysAndValues[outKeyIndex] = key;\n        alternatingKeysAndValues[outKeyIndex ^ 1] = value;\n      }\n      outI++;\n    }\n    return outI == n ? hashTable : new Object[] {hashTable, outI, duplicateKey};\n  } else if (tableSize <= SHORT_MAX_SIZE) {\n      \n    short[] hashTable = new short[tableSize];\n    Arrays.fill(hashTable, ABSENT);\n\n    int outI = 0;\n    entries:\n    for (int i = 0; i < n; i++) {\n      int keyIndex = 2 * i + keyOffset;\n      int outKeyIndex = 2 * outI + keyOffset;\n        \n      Object key = requireNonNull(alternatingKeysAndValues[keyIndex]);\n      Object value = requireNonNull(alternatingKeysAndValues[keyIndex ^ 1]);\n      checkEntryNotNull(key, value);\n      for (int h = Hashing.smear(key.hashCode()); ; h++) {\n        h &= mask;\n        int previousKeyIndex = hashTable[h] & SHORT_MASK; \n        if (previousKeyIndex == SHORT_MASK) { \n          hashTable[h] = (short) outKeyIndex;\n          break;\n        } else if (key.equals(alternatingKeysAndValues[previousKeyIndex])) {\n          duplicateKey =\n              new Builder.DuplicateKey(\n                  key, value, requireNonNull(alternatingKeysAndValues[previousKeyIndex ^ 1]));\n          alternatingKeysAndValues[previousKeyIndex ^ 1] = value;\n          continue entries;\n        }\n      }\n      if (outI < i) { \n        alternatingKeysAndValues[outKeyIndex] = key;\n        alternatingKeysAndValues[outKeyIndex ^ 1] = value;\n      }\n      outI++;\n    }\n    return outI == n ? hashTable : new Object[] {hashTable, outI, duplicateKey};\n  } else {\n      \n    int[] hashTable = new int[tableSize];\n    Arrays.fill(hashTable, ABSENT);\n\n    int outI = 0;\n    entries:\n    for (int i = 0; i < n; i++) {\n      int keyIndex = 2 * i + keyOffset;\n      int outKeyIndex = 2 * outI + keyOffset;\n        \n      Object key = requireNonNull(alternatingKeysAndValues[keyIndex]);\n      Object value = requireNonNull(alternatingKeysAndValues[keyIndex ^ 1]);\n      checkEntryNotNull(key, value);\n      for (int h = Hashing.smear(key.hashCode()); ; h++) {\n        h &= mask;\n        int previousKeyIndex = hashTable[h];\n        if (previousKeyIndex == ABSENT) {\n          hashTable[h] = outKeyIndex;\n          break;\n        } else if (key.equals(alternatingKeysAndValues[previousKeyIndex])) {\n          duplicateKey =\n              new Builder.DuplicateKey(\n                  key, value, requireNonNull(alternatingKeysAndValues[previousKeyIndex ^ 1]));\n          alternatingKeysAndValues[previousKeyIndex ^ 1] = value;\n          continue entries;\n        }\n      }\n      if (outI < i) { \n        alternatingKeysAndValues[outKeyIndex] = key;\n        alternatingKeysAndValues[outKeyIndex ^ 1] = value;\n      }\n      outI++;\n    }\n    return outI == n ? hashTable : new Object[] {hashTable, outI, duplicateKey};\n  }\n}", "summary_tokens": ["returns", "a", "hash", "table", "for", "the", "specified", "keys", "and", "values", "and", "ensures", "that", "neither", "keys", "nor", "values", "are", "null"], "project": "guava"}
{"id": 341, "code": "public void testCreateFromHashMultimap() {\n  Multimap<Double, Double> hash = HashMultimap.create();\n  hash.put(1.0, 2.0);\n  hash.put(2.0, 3.0);\n  hash.put(3.0, 4.0);\n  hash.put(4.0, 5.0);\n\n  TreeMultimap<Double, Double> copyFromHash = TreeMultimap.create(hash);\n  assertEquals(hash, copyFromHash);\n  assertEquals(Ordering.natural(), copyFromHash.keyComparator());\n  assertEquals(Ordering.natural(), copyFromHash.valueComparator());\n}", "summary_tokens": ["test", "that", "creating", "one", "tree", "multimap", "from", "a", "non", "tree", "multimap", "results", "in", "natural", "ordering"], "project": "guava"}
{"id": 996, "code": "private static char[] growBuffer(char[] dest, int index, int size) {\n  if (size < 0) { \n    throw new AssertionError(\"Cannot increase internal buffer any further\");\n  }\n  char[] copy = new char[size];\n  if (index > 0) {\n    System.arraycopy(dest, 0, copy, 0, index);\n  }\n  return copy;\n}", "summary_tokens": ["helper", "method", "to", "grow", "the", "character", "buffer", "as", "needed", "this", "only", "happens", "once", "in", "a", "while", "so", "it", "s", "ok", "if", "it", "s", "in", "a", "method", "call"], "project": "guava"}
{"id": 254, "code": "public void testEviction_maxWeight_entryTooBig() {\n  CountingRemovalListener<Integer, Integer> removalListener = countingRemovalListener();\n  IdentityLoader<Integer> loader = identityLoader();\n\n  LoadingCache<Integer, Integer> cache =\n      CacheBuilder.newBuilder()\n          .concurrencyLevel(1)\n          .maximumWeight(4)\n          .weigher(intValueWeigher())\n          .removalListener(removalListener)\n          .build(loader);\n\n    \n  assertThat(cache.getUnchecked(2)).isEqualTo(2);\n  assertThat(cache.asMap().keySet()).containsExactly(2);\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(0);\n\n    \n  assertThat(cache.getUnchecked(3)).isEqualTo(3);\n  assertThat(cache.asMap().keySet()).containsExactly(3);\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(1);\n\n    \n  assertThat(cache.getUnchecked(5)).isEqualTo(5);\n  assertThat(cache.asMap().keySet()).containsExactly(3);\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(2);\n\n    \n  assertThat(cache.getUnchecked(1)).isEqualTo(1);\n  assertThat(cache.asMap().keySet()).containsExactly(3, 1);\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(2);\n\n    \n  assertThat(cache.getUnchecked(4)).isEqualTo(4);\n  assertThat(cache.asMap().keySet()).containsExactly(4);\n\n  CacheTesting.processPendingNotifications(cache);\n  assertThat(removalListener.getCount()).isEqualTo(4);\n\n    \n  CacheTesting.checkValidState(cache);\n}", "summary_tokens": ["tests", "that", "when", "a", "single", "entry", "exceeds", "the", "segment", "s", "max", "weight", "the", "new", "entry", "is", "immediately", "evicted", "and", "nothing", "else"], "project": "guava"}
{"id": 182, "code": "public void testAddTwoEqualObjectsAtOnceWithNull() {\n  try {\n    equalsTester.addEqualityGroup(reference, equalObject1, null);\n    fail(\"Should fail on null equal object\");\n  } catch (NullPointerException e) {\n  }\n}", "summary_tokens": ["test", "equal", "objects", "after", "adding", "multiple", "instances", "at", "once", "with", "a", "null"], "project": "guava"}
{"id": 1767, "code": "public TypeToken<T> getOwnerType() {\n  return (TypeToken<T>) TypeToken.of(getDeclaringClass());\n}", "summary_tokens": ["returns", "the", "type", "of", "t"], "project": "guava"}
{"id": 215, "code": "public <T> T[] toArray(T[] a) {\n  final E[] items = this.items;\n  final Monitor monitor = this.monitor;\n  monitor.enter();\n  try {\n    if (a.length < count) a = ObjectArrays.newArray(a, count);\n\n    int k = 0;\n    int i = takeIndex;\n    while (k < count) {\n        \n        \n        \n        \n      @SuppressWarnings(\"unchecked\")\n      T t = (T) items[i];\n      a[k++] = t;\n      i = inc(i);\n    }\n    if (a.length > count) a[count] = null;\n    return a;\n  } finally {\n    monitor.leave();\n  }\n}", "summary_tokens": ["returns", "an", "array", "containing", "all", "of", "the", "elements", "in", "this", "queue", "in", "proper", "sequence", "the", "runtime", "type", "of", "the", "returned", "array", "is", "that", "of", "the", "specified", "array"], "project": "guava"}
{"id": 2010, "code": "public void forEach(LongConsumer consumer) {\n  checkNotNull(consumer);\n  for (int i = start; i < end; i++) {\n    consumer.accept(array[i]);\n  }\n}", "summary_tokens": ["invokes", "consumer", "for", "each", "value", "contained", "in", "this", "array", "in", "order"], "project": "guava"}
{"id": 766, "code": "public long sumThenReset() {\n  long sum = base;\n  Cell[] as = cells;\n  base = 0L;\n  if (as != null) {\n    int n = as.length;\n    for (int i = 0; i < n; ++i) {\n      Cell a = as[i];\n      if (a != null) {\n        sum += a.value;\n        a.value = 0L;\n      }\n    }\n  }\n  return sum;\n}", "summary_tokens": ["equivalent", "in", "effect", "to", "sum", "followed", "by", "reset"], "project": "guava"}
{"id": 1819, "code": "public final boolean compareAndSet(double expect, double update) {\n  return updater.compareAndSet(this, doubleToRawLongBits(expect), doubleToRawLongBits(update));\n}", "summary_tokens": ["atomically", "sets", "the", "value", "to", "the", "given", "updated", "value", "if", "the", "current", "value", "is", "a", "href", "bit", "equals", "bitwise", "equal", "a", "to", "the", "expected", "value"], "project": "guava"}
{"id": 1309, "code": "public long count() {\n  return xStats.count();\n}", "summary_tokens": ["returns", "the", "number", "of", "pairs", "in", "the", "dataset"], "project": "guava"}
{"id": 994, "code": "public String escape(String string) {\n  checkNotNull(string); \n    \n  int length = string.length();\n  for (int index = 0; index < length; index++) {\n    if (escape(string.charAt(index)) != null) {\n      return escapeSlow(string, index);\n    }\n  }\n  return string;\n}", "summary_tokens": ["returns", "the", "escaped", "form", "of", "a", "given", "literal", "string"], "project": "guava"}
{"id": 1144, "code": "public int read(byte[] bytes, int off, int len) throws IOException {\n  int numOfBytesRead = in.read(bytes, off, len);\n  if (numOfBytesRead != -1) {\n    hasher.putBytes(bytes, off, numOfBytesRead);\n  }\n  return numOfBytesRead;\n}", "summary_tokens": ["reads", "the", "specified", "bytes", "of", "data", "from", "the", "underlying", "input", "stream", "and", "updates", "the", "hasher", "with", "the", "bytes", "read"], "project": "guava"}
{"id": 420, "code": "public void testBadArguments_null() {\n  try {\n    new PercentEscaper(null, false);\n    fail(\"Expected null pointer exception for null parameter\");\n  } catch (NullPointerException expected) {\n      \n  }\n}", "summary_tokens": ["test", "that", "giving", "a", "null", "safe", "chars", "string", "causes", "a", "null", "pointer", "exception"], "project": "guava"}
{"id": 143, "code": "final Object generateFresh(TypeToken<?> type) {\n  Object generated = generate(type);\n  if (generated != null) {\n    freshness.incrementAndGet();\n  }\n  return generated;\n}", "summary_tokens": ["returns", "a", "fresh", "instance", "for", "type", "if", "possible"], "project": "guava"}
{"id": 628, "code": "public boolean equals(@CheckForNull Object object) {\n  return super.equals(object);\n}", "summary_tokens": ["indicates", "whether", "another", "object", "is", "equal", "to", "this", "converter"], "project": "guava"}
{"id": 430, "code": "public void testTrimmed() {\n  ImmutableIntArray iia = ImmutableIntArray.of(0, 1, 3);\n  assertDoesntActuallyTrim(iia);\n  assertDoesntActuallyTrim(iia.subArray(0, 3));\n  assertActuallyTrims(iia.subArray(0, 2));\n  assertActuallyTrims(iia.subArray(1, 3));\n\n  ImmutableIntArray rightSized = ImmutableIntArray.builder(3).add(0).add(1).add(3).build();\n  assertDoesntActuallyTrim(rightSized);\n\n  ImmutableIntArray overSized = ImmutableIntArray.builder(3).add(0).add(1).build();\n  assertActuallyTrims(overSized);\n\n  ImmutableIntArray underSized = ImmutableIntArray.builder(2).add(0).add(1).add(3).build();\n  assertActuallyTrims(underSized);\n}", "summary_tokens": ["this", "is", "probably", "a", "weird", "and", "hacky", "way", "to", "test", "what", "we", "re", "really", "trying", "to", "test", "but", "hey", "it", "caught", "a", "bug"], "project": "guava"}
{"id": 546, "code": "public void testInvokeAnyImpl_emptyTasks() throws Exception {\n  ListeningExecutorService e = newDirectExecutorService();\n  try {\n    invokeAnyImpl(e, new ArrayList<Callable<String>>(), false, 0, TimeUnit.NANOSECONDS);\n    fail();\n  } catch (IllegalArgumentException success) {\n  } finally {\n    joinPool(e);\n  }\n}", "summary_tokens": ["invoke", "any", "empty", "collection", "throws", "iae"], "project": "guava"}
{"id": 943, "code": "private static int capAtMaximumSize(int queueSize, int maximumSize) {\n  return Math.min(queueSize - 1, maximumSize) + 1; \n}", "summary_tokens": ["there", "s", "no", "reason", "for", "the", "queue", "size", "to", "ever", "be", "more", "than", "max", "size", "0"], "project": "guava"}
{"id": 1284, "code": "public static long checkedSubtract(long a, long b) {\n  long result = a - b;\n  checkNoOverflow((a ^ b) >= 0 | (a ^ result) >= 0, \"checkedSubtract\", a, b);\n  return result;\n}", "summary_tokens": ["returns", "the", "difference", "of", "a", "and", "b", "provided", "it", "does", "not", "overflow"], "project": "guava"}
{"id": 513, "code": "private static TestCase generateGuardWithWrongMonitorTestCase(\n    final Method method, final boolean fair1, final boolean fair2) {\n  final boolean timed = isTimed(method); \n  return new TestCase(method.getName() + (timed ? \"(0ms)\" : \"()\") + \"/WrongMonitor->IMSE\") {\n    @Override\n    protected void runTest() throws Throwable {\n      Monitor monitor1 = new Monitor(fair1);\n      Monitor monitor2 = new Monitor(fair2);\n      FlagGuard guard = new FlagGuard(monitor2);\n      List<Object> arguments = new ArrayList<>();\n      arguments.add(guard);\n      if (isDurationBased(method)) {\n        arguments.add(Duration.ZERO);\n      }\n      if (isLongTimeUnitBased(method)) {\n        arguments.add(0L);\n        arguments.add(TimeUnit.MILLISECONDS);\n      }\n      boolean occupyMonitor = isWaitFor(method);\n      if (occupyMonitor) {\n          \n          \n        monitor1.enter();\n      }\n      try {\n        method.invoke(monitor1, arguments.toArray());\n        fail(\"expected IllegalMonitorStateException\");\n      } catch (InvocationTargetException e) {\n        assertEquals(IllegalMonitorStateException.class, e.getTargetException().getClass());\n      } finally {\n        if (occupyMonitor) {\n          monitor1.leave();\n        }\n      }\n    }\n  };\n}", "summary_tokens": ["generates", "a", "test", "case", "verifying", "that", "calling", "any", "enter", "xxx", "try", "enter", "xxx", "or", "wait", "for", "xxx", "method", "with", "a", "guard", "that", "doesn", "t", "match", "the", "monitor", "produces", "an", "illegal", "monitor", "state", "exception"], "project": "guava"}
{"id": 1593, "code": "public static int lastIndexOf(int[] array, int target) {\n  return lastIndexOf(array, target, 0, array.length);\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "last", "appearance", "of", "the", "value", "target", "in", "array"], "project": "guava"}
{"id": 59, "code": "protected Entry<K, V>[] createArrayWithNullValue() {\n  Entry<K, V>[] array = createSamplesArray();\n  int nullValueLocation = getNullLocation();\n  Entry<K, V> oldEntry = array[nullValueLocation];\n  array[nullValueLocation] = Helpers.mapEntry(oldEntry.getKey(), null);\n  return array;\n}", "summary_tokens": ["an", "array", "of", "the", "proper", "size", "with", "null", "as", "the", "value", "of", "the", "middle", "element"], "project": "guava"}
{"id": 2026, "code": "default void awaitRunning(Duration timeout) throws TimeoutException {\n  awaitRunning(toNanosSaturated(timeout), TimeUnit.NANOSECONDS);\n}", "summary_tokens": ["waits", "for", "the", "service", "to", "reach", "the", "state", "running", "running", "state", "for", "no", "more", "than", "the", "given", "time"], "project": "guava"}
{"id": 1270, "code": "public static LinearTransformation horizontal(double y) {\n  checkArgument(isFinite(y));\n  double slope = 0.0;\n  return new RegularLinearTransformation(slope, y);\n}", "summary_tokens": ["builds", "an", "instance", "representing", "a", "horizontal", "transformation", "with", "a", "constant", "value", "of", "y"], "project": "guava"}
{"id": 993, "code": "protected final char[] escape(int cp) {\n  if (cp < replacementsLength) {\n    char[] chars = replacements[cp];\n    if (chars != null) {\n      return chars;\n    }\n  }\n  if (cp >= safeMin && cp <= safeMax) {\n    return null;\n  }\n  return escapeUnsafe(cp);\n}", "summary_tokens": ["escapes", "a", "single", "unicode", "code", "point", "using", "the", "replacement", "array", "and", "safe", "range", "values"], "project": "guava"}
{"id": 1528, "code": "public static float constrainToRange(float value, float min, float max) {\n    \n    \n  if (min <= max) {\n    return Math.min(Math.max(value, min), max);\n  }\n  throw new IllegalArgumentException(\n      lenientFormat(\"min (%s) must be less than or equal to max (%s)\", min, max));\n}", "summary_tokens": ["returns", "the", "value", "nearest", "to", "value", "which", "is", "within", "the", "closed", "range", "min"], "project": "guava"}
{"id": 123, "code": "public static <T> T get(Class<T> type) {\n  T defaultValue = DEFAULTS.getInstance(type);\n  if (defaultValue != null) {\n    return defaultValue;\n  }\n  Class<? extends T> implementation = getImplementation(type);\n  if (implementation != null) {\n    return get(implementation);\n  }\n  if (type.isEnum()) {\n    T[] enumConstants = type.getEnumConstants();\n    return (enumConstants.length == 0) ? null : enumConstants[0];\n  }\n  if (type.isArray()) {\n    return createEmptyArray(type);\n  }\n  T jvmDefault = Defaults.defaultValue(Primitives.unwrap(type));\n  if (jvmDefault != null) {\n    return jvmDefault;\n  }\n  if (Modifier.isAbstract(type.getModifiers()) || !Modifier.isPublic(type.getModifiers())) {\n    return arbitraryConstantInstanceOrNull(type);\n  }\n  final Constructor<T> constructor;\n  try {\n    constructor = type.getConstructor();\n  } catch (NoSuchMethodException e) {\n    return arbitraryConstantInstanceOrNull(type);\n  }\n  constructor.setAccessible(true); \n  try {\n    return constructor.newInstance();\n      \n  } catch (InstantiationException impossible) {\n    throw new AssertionError(impossible);\n  } catch (IllegalAccessException impossible) {\n    throw new AssertionError(impossible);\n  } catch (InvocationTargetException e) {\n    logger.log(Level.WARNING, \"Exception while invoking default constructor.\", e.getCause());\n    return arbitraryConstantInstanceOrNull(type);\n  }\n}", "summary_tokens": ["returns", "an", "arbitrary", "instance", "for", "type", "or", "null", "if", "no", "arbitrary", "instance", "can", "be", "determined"], "project": "guava"}
{"id": 1522, "code": "public static boolean isFinite(float value) {\n  return NEGATIVE_INFINITY < value && value < POSITIVE_INFINITY;\n}", "summary_tokens": ["returns", "true", "if", "value", "represents", "a", "real", "number"], "project": "guava"}
{"id": 349, "code": "public void addEdge_nodesNotInGraph() {\n  assume().that(graphIsMutable()).isTrue();\n\n  networkAsMutableNetwork.addNode(N1);\n  assertTrue(networkAsMutableNetwork.addEdge(N1, N5, E15));\n  assertTrue(networkAsMutableNetwork.addEdge(N4, N1, E41));\n  assertTrue(networkAsMutableNetwork.addEdge(N2, N3, E23));\n  assertThat(network.nodes()).containsExactly(N1, N5, N4, N2, N3);\n  assertThat(network.edges()).containsExactly(E15, E41, E23);\n  assertThat(network.edgesConnecting(N1, N5)).containsExactly(E15);\n  assertThat(network.edgesConnecting(N4, N1)).containsExactly(E41);\n  assertThat(network.edgesConnecting(N2, N3)).containsExactly(E23);\n    \n  assertThat(network.edgesConnecting(N3, N2)).isEmpty();\n}", "summary_tokens": ["this", "test", "checks", "an", "implementation", "dependent", "feature"], "project": "guava"}
{"id": 493, "code": "public void testAllAsList_logging_multipleExceptions_alreadyDone() throws Exception {\n  try {\n    getDone(\n        allAsList(\n            immediateFailedFuture(new MyException()), immediateFailedFuture(new MyException())));\n    fail();\n  } catch (ExecutionException expected) {\n    assertThat(expected.getCause()).isInstanceOf(MyException.class);\n    List<LogRecord> logged = aggregateFutureLogHandler.getStoredLogRecords();\n    assertThat(logged).hasSize(1); \n    assertThat(logged.get(0).getThrown()).isInstanceOf(MyException.class);\n  }\n}", "summary_tokens": ["all", "as", "list", "will", "log", "extra", "exceptions", "that", "have", "already", "occurred"], "project": "guava"}
{"id": 686, "code": "public static List<Throwable> getCausalChain(Throwable throwable) {\n  checkNotNull(throwable);\n  List<Throwable> causes = new ArrayList<>(4);\n  causes.add(throwable);\n\n    \n    \n  Throwable slowPointer = throwable;\n  boolean advanceSlowPointer = false;\n\n  Throwable cause;\n  while ((cause = throwable.getCause()) != null) {\n    throwable = cause;\n    causes.add(throwable);\n\n    if (throwable == slowPointer) {\n      throw new IllegalArgumentException(\"Loop in causal chain detected.\", throwable);\n    }\n    if (advanceSlowPointer) {\n      slowPointer = slowPointer.getCause();\n    }\n    advanceSlowPointer = !advanceSlowPointer; \n  }\n  return Collections.unmodifiableList(causes);\n}", "summary_tokens": ["gets", "a", "throwable", "cause", "chain", "as", "a", "list"], "project": "guava"}
{"id": 124, "code": "public <T> ClassSanityTester setDefault(Class<T> type, T value) {\n  nullPointerTester.setDefault(type, value);\n  defaultValues.putInstance(type, value);\n  return this;\n}", "summary_tokens": ["sets", "the", "default", "value", "for", "type"], "project": "guava"}
{"id": 693, "code": "private static Method getSizeMethod(Object jla) {\n  try {\n    Method getStackTraceDepth = getJlaMethod(\"getStackTraceDepth\", Throwable.class);\n    if (getStackTraceDepth == null) {\n      return null;\n    }\n    getStackTraceDepth.invoke(jla, new Throwable());\n    return getStackTraceDepth;\n  } catch (UnsupportedOperationException | IllegalAccessException | InvocationTargetException e) {\n    return null;\n  }\n}", "summary_tokens": ["returns", "the", "method", "that", "can", "be", "used", "to", "return", "the", "size", "of", "a", "stack", "or", "null", "if", "that", "method", "cannot", "be", "found", "it", "is", "only", "to", "be", "found", "in", "fairly", "recent", "jdks"], "project": "guava"}
{"id": 1852, "code": "boolean remove(K key, long value) {\n  return map.remove(key, value);\n}", "summary_tokens": ["if", "key", "value", "is", "currently", "in", "the", "map", "this", "method", "removes", "it", "and", "returns", "true", "otherwise", "this", "method", "returns", "false"], "project": "guava"}
{"id": 53, "code": "private static TesterRequirements buildTesterRequirements(Annotation testerAnnotation)\n    throws ConflictingRequirementsException {\n  Class<? extends Annotation> annotationClass = testerAnnotation.annotationType();\n  Feature<?>[] presentFeatures;\n  Feature<?>[] absentFeatures;\n  try {\n    presentFeatures = (Feature[]) annotationClass.getMethod(\"value\").invoke(testerAnnotation);\n    absentFeatures = (Feature[]) annotationClass.getMethod(\"absent\").invoke(testerAnnotation);\n  } catch (Exception e) {\n    throw new IllegalArgumentException(\"Error extracting features from tester annotation.\", e);\n  }\n  Set<Feature<?>> allPresentFeatures =\n      addImpliedFeatures(Helpers.<Feature<?>>copyToSet(presentFeatures));\n  Set<Feature<?>> allAbsentFeatures =\n      addImpliedFeatures(Helpers.<Feature<?>>copyToSet(absentFeatures));\n  if (!Collections.disjoint(allPresentFeatures, allAbsentFeatures)) {\n    throw new ConflictingRequirementsException(\n        \"Annotation explicitly or \"\n            + \"implicitly requires one or more features to be both present \"\n            + \"and absent.\",\n        intersection(allPresentFeatures, allAbsentFeatures),\n        testerAnnotation);\n  }\n  return new TesterRequirements(allPresentFeatures, allAbsentFeatures);\n}", "summary_tokens": ["find", "all", "the", "constraints", "explicitly", "or", "implicitly", "specified", "by", "a", "single", "tester", "annotation"], "project": "guava"}
{"id": 1742, "code": "static ImmutableSet<File> getClassPathFromManifest(\n    File jarFile, @CheckForNull Manifest manifest) {\n  if (manifest == null) {\n    return ImmutableSet.of();\n  }\n  ImmutableSet.Builder<File> builder = ImmutableSet.builder();\n  String classpathAttribute =\n      manifest.getMainAttributes().getValue(Attributes.Name.CLASS_PATH.toString());\n  if (classpathAttribute != null) {\n    for (String path : CLASS_PATH_ATTRIBUTE_SEPARATOR.split(classpathAttribute)) {\n      URL url;\n      try {\n        url = getClassPathEntry(jarFile, path);\n      } catch (MalformedURLException e) {\n          \n        logger.warning(\"Invalid Class-Path entry: \" + path);\n        continue;\n      }\n      if (url.getProtocol().equals(\"file\")) {\n        builder.add(toFile(url));\n      }\n    }\n  }\n  return builder.build();\n}", "summary_tokens": ["returns", "the", "class", "path", "uris", "specified", "by", "the", "class", "path", "manifest", "attribute", "according", "to", "a", "href", "http", "docs"], "project": "guava"}
{"id": 1713, "code": "public UnsignedLong mod(UnsignedLong val) {\n  return fromLongBits(UnsignedLongs.remainder(value, checkNotNull(val).value));\n}", "summary_tokens": ["returns", "this", "modulo", "val"], "project": "guava"}
{"id": 451, "code": "public void testGetSet() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(VALUES.length);\n  for (int i = 0; i < VALUES.length; i++) {\n    assertBitEquals(0.0, aa.get(i));\n    aa.set(i, VALUES[i]);\n    assertBitEquals(VALUES[i], aa.get(i));\n    aa.set(i, -3.0);\n    assertBitEquals(-3.0, aa.get(i));\n  }\n}", "summary_tokens": ["get", "returns", "the", "last", "value", "set", "at", "index"], "project": "guava"}
{"id": 1071, "code": "public static <N> Set<N> reachableNodes(Graph<N> graph, N node) {\n  checkArgument(graph.nodes().contains(node), NODE_NOT_IN_GRAPH, node);\n  return ImmutableSet.copyOf(Traverser.forGraph(graph).breadthFirst(node));\n}", "summary_tokens": ["returns", "the", "set", "of", "nodes", "that", "are", "reachable", "from", "node"], "project": "guava"}
{"id": 821, "code": "public final boolean addAll(int index, Collection<? extends E> newElements) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["guaranteed", "to", "throw", "an", "exception", "and", "leave", "the", "list", "unmodified"], "project": "guava"}
{"id": 753, "code": "boolean isLive(ReferenceEntry<K, V> entry, long now) {\n  return segmentFor(entry.getHash()).getLiveValue(entry, now) != null;\n}", "summary_tokens": ["this", "method", "is", "a", "convenience", "for", "testing"], "project": "guava"}
{"id": 1573, "code": "public static Builder builder() {\n  return new Builder(10);\n}", "summary_tokens": ["returns", "a", "new", "empty", "builder", "for", "immutable", "long", "array", "instances", "with", "a", "default", "initial", "capacity"], "project": "guava"}
{"id": 1918, "code": "public ThreadFactoryBuilder setNameFormat(String nameFormat) {\n  String unused = format(nameFormat, 0); \n  this.nameFormat = nameFormat;\n  return this;\n}", "summary_tokens": ["sets", "the", "naming", "format", "to", "use", "when", "naming", "threads", "thread", "set", "name", "which", "are", "created", "with", "this", "thread", "factory"], "project": "guava"}
{"id": 768, "code": "public int intValue() {\n  return (int) sum();\n}", "summary_tokens": ["returns", "the", "sum", "as", "an", "int", "after", "a", "narrowing", "primitive", "conversion"], "project": "guava"}
{"id": 2025, "code": "public Guard newGuard(final BooleanSupplier isSatisfied) {\n  checkNotNull(isSatisfied, \"isSatisfied\");\n  return new Guard(this) {\n    @Override\n    public boolean isSatisfied() {\n      return isSatisfied.getAsBoolean();\n    }\n  };\n}", "summary_tokens": ["creates", "a", "new", "guard", "guard", "for", "this", "monitor"], "project": "guava"}
{"id": 1344, "code": "public void addAll(StatsAccumulator values) {\n  if (values.count() == 0) {\n    return;\n  }\n  merge(values.count(), values.mean(), values.sumOfSquaresOfDeltas(), values.min(), values.max());\n}", "summary_tokens": ["adds", "the", "given", "statistics", "to", "the", "dataset", "as", "if", "the", "individual", "values", "used", "to", "compute", "the", "statistics", "had", "been", "added", "directly"], "project": "guava"}
{"id": 1249, "code": "public static int log2(int x, RoundingMode mode) {\n  checkPositive(\"x\", x);\n  switch (mode) {\n    case UNNECESSARY:\n      checkRoundingUnnecessary(isPowerOfTwo(x));\n        \n    case DOWN:\n    case FLOOR:\n      return (Integer.SIZE - 1) - Integer.numberOfLeadingZeros(x);\n\n    case UP:\n    case CEILING:\n      return Integer.SIZE - Integer.numberOfLeadingZeros(x - 1);\n\n    case HALF_DOWN:\n    case HALF_UP:\n    case HALF_EVEN:\n        \n      int leadingZeros = Integer.numberOfLeadingZeros(x);\n      int cmp = MAX_POWER_OF_SQRT2_UNSIGNED >>> leadingZeros;\n        \n      int logFloor = (Integer.SIZE - 1) - leadingZeros;\n      return logFloor + lessThanBranchFree(cmp, x);\n\n    default:\n      throw new AssertionError();\n  }\n}", "summary_tokens": ["returns", "the", "base", "0", "logarithm", "of", "x", "rounded", "according", "to", "the", "specified", "rounding", "mode"], "project": "guava"}
{"id": 698, "code": "public static <T> T verifyNotNull(\n    @CheckForNull T reference,\n    String errorMessageTemplate,\n    @CheckForNull @Nullable Object... errorMessageArgs) {\n  if (reference == null) {\n    throw new VerifyException(lenientFormat(errorMessageTemplate, errorMessageArgs));\n  }\n  return reference;\n}", "summary_tokens": ["ensures", "that", "reference", "is", "non", "null", "throwing", "a", "verify", "exception", "with", "a", "custom", "message", "otherwise"], "project": "guava"}
{"id": 1197, "code": "protected void finish() throws IOException {\n  if (sawReturn || line.length() > 0) {\n    finishLine(false);\n  }\n}", "summary_tokens": ["subclasses", "must", "call", "this", "method", "after", "finishing", "character", "processing", "in", "order", "to", "ensure", "that", "any", "unterminated", "line", "in", "the", "buffer", "is", "passed", "to", "handle", "line"], "project": "guava"}
{"id": 907, "code": "public static <E> Interner<E> newWeakInterner() {\n  return newBuilder().weak().build();\n}", "summary_tokens": ["returns", "a", "new", "thread", "safe", "interner", "which", "retains", "a", "weak", "reference", "to", "each", "instance", "it", "has", "interned", "and", "so", "does", "not", "prevent", "these", "instances", "from", "being", "garbage", "collected"], "project": "guava"}
{"id": 1618, "code": "public static long[] concat(long[]... arrays) {\n  int length = 0;\n  for (long[] array : arrays) {\n    length += array.length;\n  }\n  long[] result = new long[length];\n  int pos = 0;\n  for (long[] array : arrays) {\n    System.arraycopy(array, 0, result, pos, array.length);\n    pos += array.length;\n  }\n  return result;\n}", "summary_tokens": ["returns", "the", "values", "from", "each", "provided", "array", "combined", "into", "a", "single", "array"], "project": "guava"}
{"id": 1926, "code": "public static Escaper xmlAttributeEscaper() {\n  return XML_ATTRIBUTE_ESCAPER;\n}", "summary_tokens": ["returns", "an", "escaper", "instance", "that", "escapes", "special", "characters", "in", "a", "string", "so", "it", "can", "safely", "be", "included", "in", "xml", "document", "as", "an", "attribute", "value"], "project": "guava"}
{"id": 481, "code": "static URL[] parseJavaClassPath() {\n  ImmutableList.Builder<URL> urls = ImmutableList.builder();\n  for (String entry : Splitter.on(PATH_SEPARATOR.value()).split(JAVA_CLASS_PATH.value())) {\n    try {\n      try {\n        urls.add(new File(entry).toURI().toURL());\n      } catch (SecurityException e) { \n        urls.add(new URL(\"file\", null, new File(entry).getAbsolutePath()));\n      }\n    } catch (MalformedURLException e) {\n      AssertionError error = new AssertionError(\"malformed class path entry: \" + entry);\n      error.initCause(e);\n      throw error;\n    }\n  }\n  return urls.build().toArray(new URL[0]);\n}", "summary_tokens": ["returns", "the", "urls", "in", "the", "class", "path", "specified", "by", "the", "java"], "project": "guava"}
{"id": 1782, "code": "public final TypeToken<?> resolveType(Type type) {\n  checkNotNull(type);\n    \n    \n  return of(getInvariantTypeResolver().resolveType(type));\n}", "summary_tokens": ["resolves", "the", "given", "type", "against", "the", "type", "context", "represented", "by", "this", "type"], "project": "guava"}
{"id": 299, "code": "public void testNoop() {}", "summary_tokens": ["no", "op", "test", "so", "that", "the", "class", "has", "at", "least", "one", "method", "making", "maven", "s", "test", "runner", "happy"], "project": "guava"}
{"id": 332, "code": "public void testCartesianProduct_unary() {\n  assertThat(Sets.cartesianProduct(set(1, 2))).containsExactly(list(1), list(2));\n}", "summary_tokens": ["a", "unary", "cartesian", "product", "is", "one", "list", "of", "size", "0", "for", "each", "element", "in", "the", "input", "set"], "project": "guava"}
{"id": 1098, "code": "public static <N, V> ValueGraphBuilder<N, V> from(ValueGraph<N, V> graph) {\n  return new ValueGraphBuilder<N, V>(graph.isDirected())\n      .allowsSelfLoops(graph.allowsSelfLoops())\n      .nodeOrder(graph.nodeOrder())\n      .incidentEdgeOrder(graph.incidentEdgeOrder());\n}", "summary_tokens": ["returns", "a", "value", "graph", "builder", "initialized", "with", "all", "properties", "queryable", "from", "graph"], "project": "guava"}
{"id": 1636, "code": "public static int hashCode(short value) {\n  return value;\n}", "summary_tokens": ["returns", "a", "hash", "code", "for", "value", "equal", "to", "the", "result", "of", "invoking", "short", "value"], "project": "guava"}
{"id": 433, "code": "private static void tryParseAndAssertEquals(Integer expected, String value) {\n  assertEquals(expected, Ints.tryParse(value));\n}", "summary_tokens": ["applies", "ints", "try", "parse", "string", "to", "the", "given", "string", "and", "asserts", "that", "the", "result", "is", "as", "expected"], "project": "guava"}
{"id": 1422, "code": "public InternetDomainName topDomainUnderRegistrySuffix() {\n  if (isTopDomainUnderRegistrySuffix()) {\n    return this;\n  }\n  checkState(isUnderRegistrySuffix(), \"Not under a registry suffix: %s\", name);\n  return ancestor(registrySuffixIndex - 1);\n}", "summary_tokens": ["returns", "the", "portion", "of", "this", "domain", "name", "that", "is", "one", "level", "beneath", "the", "is", "registry", "suffix", "registry", "suffix"], "project": "guava"}
{"id": 1781, "code": "public final <X> TypeToken<T> where(TypeParameter<X> typeParam, Class<X> typeArg) {\n  return where(typeParam, of(typeArg));\n}", "summary_tokens": ["returns", "a", "new", "type", "token", "where", "type", "variables", "represented", "by", "type", "param", "are", "substituted", "by", "type", "arg"], "project": "guava"}
{"id": 67, "code": "private void resetWithHole() {\n  List<E> container = new ArrayList<>();\n  container.addAll(Collections.nCopies(a.getCount(), a.getElement()));\n  container.addAll(Collections.nCopies(c.getCount(), c.getElement()));\n  super.resetContainer(getSubjectGenerator().create(container.toArray()));\n  sortedMultiset = (SortedMultiset<E>) getMultiset();\n}", "summary_tokens": ["resets", "the", "contents", "of", "sorted", "multiset", "to", "have", "entries", "a", "c", "for", "the", "navigation", "tests"], "project": "guava"}
{"id": 135, "code": "public EqualsTester testEquals() {\n  RelationshipTester<Object> delegate =\n      new RelationshipTester<>(\n          Equivalence.equals(), \"Object#equals\", \"Object#hashCode\", itemReporter);\n  for (List<Object> group : equalityGroups) {\n    delegate.addRelatedGroup(group);\n  }\n  for (int run = 0; run < REPETITIONS; run++) {\n    testItems();\n    delegate.test();\n  }\n  return this;\n}", "summary_tokens": ["run", "tests", "on", "equals", "method", "throwing", "a", "failure", "on", "an", "invalid", "test"], "project": "guava"}
{"id": 1764, "code": "public final ImmutableList<Parameter> getParameters() {\n  Type[] parameterTypes = getGenericParameterTypes();\n  Annotation[][] annotations = getParameterAnnotations();\n  AnnotatedType[] annotatedTypes = getAnnotatedParameterTypes();\n  ImmutableList.Builder<Parameter> builder = ImmutableList.builder();\n  for (int i = 0; i < parameterTypes.length; i++) {\n    builder.add(\n        new Parameter(\n            this, i, TypeToken.of(parameterTypes[i]), annotations[i], annotatedTypes[i]));\n  }\n  return builder.build();\n}", "summary_tokens": ["returns", "all", "declared", "parameters", "of", "this", "invokable"], "project": "guava"}
{"id": 1256, "code": "public static int checkedAdd(int a, int b) {\n  long result = (long) a + b;\n  checkNoOverflow(result == (int) result, \"checkedAdd\", a, b);\n  return (int) result;\n}", "summary_tokens": ["returns", "the", "sum", "of", "a", "and", "b", "provided", "it", "does", "not", "overflow"], "project": "guava"}
{"id": 1145, "code": "public boolean markSupported() {\n  return false;\n}", "summary_tokens": ["mark", "is", "not", "supported", "for", "hashing", "input", "stream"], "project": "guava"}
{"id": 1678, "code": "public static UnsignedInteger fromIntBits(int bits) {\n  return new UnsignedInteger(bits);\n}", "summary_tokens": ["returns", "an", "unsigned", "integer", "corresponding", "to", "a", "given", "bit", "representation"], "project": "guava"}
{"id": 1876, "code": "public void dispatch() {\n    \n  for (int i = 0; i < listeners.size(); i++) {\n    listeners.get(i).dispatch();\n  }\n}", "summary_tokens": ["dispatches", "all", "events", "enqueued", "prior", "to", "this", "call", "serially", "and", "in", "order", "for", "every", "listener"], "project": "guava"}
{"id": 1236, "code": "public static BigInteger roundToBigInteger(double x, RoundingMode mode) {\n  x = roundIntermediate(x, mode);\n  if (MIN_LONG_AS_DOUBLE - x < 1.0 & x < MAX_LONG_AS_DOUBLE_PLUS_ONE) {\n    return BigInteger.valueOf((long) x);\n  }\n  int exponent = getExponent(x);\n  long significand = getSignificand(x);\n  BigInteger result = BigInteger.valueOf(significand).shiftLeft(exponent - SIGNIFICAND_BITS);\n  return (x < 0) ? result.negate() : result;\n}", "summary_tokens": ["returns", "the", "big", "integer", "value", "that", "is", "equal", "to", "x", "rounded", "with", "the", "specified", "rounding", "mode", "if", "possible"], "project": "guava"}
{"id": 1953, "code": "public void testGetAndAccumulateWithMax() {\n  AtomicDoubleArray aa = new AtomicDoubleArray(SIZE);\n  for (int i : new int[] {0, SIZE - 1}) {\n    for (double x : VALUES) {\n      for (double y : VALUES) {\n        aa.set(i, x);\n        double z = aa.getAndAccumulate(i, y, Double::max);\n        double expectedMax = max(x, y);\n        assertBitEquals(x, z);\n        assertBitEquals(expectedMax, aa.get(i));\n      }\n    }\n  }\n}", "summary_tokens": ["get", "and", "accumulate", "with", "max", "stores", "max", "of", "given", "value", "to", "current", "and", "returns", "previous", "value"], "project": "guava"}
{"id": 1062, "code": "public GraphBuilder<N> allowsSelfLoops(boolean allowsSelfLoops) {\n  this.allowsSelfLoops = allowsSelfLoops;\n  return this;\n}", "summary_tokens": ["specifies", "whether", "the", "graph", "will", "allow", "self", "loops", "edges", "that", "connect", "a", "node", "to", "itself"], "project": "guava"}
{"id": 337, "code": "private TreeMultimap<String, Integer> createPopulate() {\n  TreeMultimap<String, Integer> multimap =\n      TreeMultimap.create(StringLength.COMPARATOR, DECREASING_INT_COMPARATOR);\n  multimap.put(\"google\", 2);\n  multimap.put(\"google\", 6);\n  multimap.put(null, 3);\n  multimap.put(null, 1);\n  multimap.put(null, 7);\n  multimap.put(\"tree\", 0);\n  multimap.put(\"tree\", null);\n  return multimap;\n}", "summary_tokens": ["create", "and", "populate", "a", "tree", "multimap", "with", "explicit", "comparators"], "project": "guava"}
{"id": 1566, "code": "public List<Integer> asList() {\n    \n  return new AsList(this);\n}", "summary_tokens": ["returns", "an", "immutable", "i", "view", "i", "of", "this", "array", "s", "values", "as", "a", "list", "note", "that", "int", "values", "are", "boxed", "into", "integer", "instances", "on", "demand", "which", "can", "be", "very", "expensive"], "project": "guava"}
{"id": 498, "code": "private static void runExtensiveMergerTest(Merger merger) throws InterruptedException {\n  int inputCount = new TestFutureBatch().allFutures.size();\n\n  for (int i = 0; i < inputCount; i++) {\n    for (int j = 0; j < inputCount; j++) {\n      for (boolean iBeforeJ : new boolean[] {true, false}) {\n        TestFutureBatch inputs = new TestFutureBatch();\n        ListenableFuture<String> iFuture = inputs.allFutures.get(i).future;\n        ListenableFuture<String> jFuture = inputs.allFutures.get(j).future;\n        ListenableFuture<List<String>> future = merger.merged(iFuture, jFuture);\n\n          \n        try {\n          List<String> result = future.get(0, MILLISECONDS);\n          assertTrue(\"Got \" + result, asList(\"a\", null).containsAll(result));\n        } catch (CancellationException e) {\n          assertTrue(merger == Merger.allMerger);\n          inputs.assertHasImmediateCancel(iFuture, jFuture, e);\n        } catch (ExecutionException e) {\n          assertTrue(merger == Merger.allMerger);\n          inputs.assertHasImmediateFailure(iFuture, jFuture, e);\n        } catch (TimeoutException e) {\n          inputs.assertHasDelayed(iFuture, jFuture, e);\n        }\n\n          \n        try {\n          List<String> result =\n              conditionalPseudoTimedGetUninterruptibly(\n                  inputs, iFuture, jFuture, future, 20, MILLISECONDS);\n          assertTrue(\"Got \" + result, asList(\"a\", null).containsAll(result));\n        } catch (CancellationException e) {\n          assertTrue(merger == Merger.allMerger);\n          inputs.assertHasImmediateCancel(iFuture, jFuture, e);\n        } catch (ExecutionException e) {\n          assertTrue(merger == Merger.allMerger);\n          inputs.assertHasImmediateFailure(iFuture, jFuture, e);\n        } catch (TimeoutException e) {\n          inputs.assertHasDelayed(iFuture, jFuture, e);\n        }\n\n          \n        inputs.allFutures.get(iBeforeJ ? i : j).finisher.run();\n        inputs.allFutures.get(iBeforeJ ? j : i).finisher.run();\n\n          \n        try {\n          List<String> result = getDone(future);\n          assertTrue(\"Got \" + result, asList(\"a\", \"b\", null).containsAll(result));\n        } catch (CancellationException e) {\n          assertTrue(merger == Merger.allMerger);\n          inputs.assertHasCancel(iFuture, jFuture, e);\n        } catch (ExecutionException e) {\n          assertTrue(merger == Merger.allMerger);\n          inputs.assertHasFailure(iFuture, jFuture, e);\n        }\n      }\n    }\n  }\n}", "summary_tokens": ["for", "each", "possible", "pair", "of", "futures", "from", "test", "future", "batch", "for", "each", "possible", "completion", "order", "of", "those", "futures", "test", "that", "various", "get", "calls", "timed", "before", "future", "completion", "untimed", "before", "future", "completion", "and", "untimed", "after", "future", "completion", "return", "or", "throw", "the", "proper", "values"], "project": "guava"}
{"id": 1835, "code": "public final boolean compareAndSet(int i, double expect, double update) {\n  return longs.compareAndSet(i, doubleToRawLongBits(expect), doubleToRawLongBits(update));\n}", "summary_tokens": ["atomically", "sets", "the", "element", "at", "position", "i", "to", "the", "given", "updated", "value", "if", "the", "current", "value", "is", "a", "href", "bit", "equals", "bitwise", "equal", "a", "to", "the", "expected", "value"], "project": "guava"}
{"id": 1921, "code": "public ThreadFactoryBuilder setUncaughtExceptionHandler(\n    UncaughtExceptionHandler uncaughtExceptionHandler) {\n  this.uncaughtExceptionHandler = checkNotNull(uncaughtExceptionHandler);\n  return this;\n}", "summary_tokens": ["sets", "the", "uncaught", "exception", "handler", "for", "new", "threads", "created", "with", "this", "thread", "factory"], "project": "guava"}
{"id": 385, "code": "private static int runSuppressionFailureTest(CharSource in, CharSink out) {\n  try {\n    in.copyTo(out);\n    fail();\n  } catch (IOException expected) {\n    return CloserTest.getSuppressed(expected).length;\n  }\n  throw new AssertionError(); \n}", "summary_tokens": ["the", "number", "of", "exceptions", "that", "were", "suppressed", "on", "the", "expected", "thrown", "exception"], "project": "guava"}
{"id": 4467, "code": "\tpublic void setIdleTaskExecutionLimit(int idleTaskExecutionLimit) {\n\t\tAssert.isTrue(idleTaskExecutionLimit > 0, \"'idleTaskExecutionLimit' must be 1 or higher\");\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tthis.idleTaskExecutionLimit = idleTaskExecutionLimit;\n\t\t}\n\t}", "summary_tokens": ["specify", "the", "limit", "for", "idle", "executions", "of", "a", "consumer", "task", "not", "having", "received", "any", "message", "within", "its", "execution"], "project": "spring-framework"}
{"id": 1024, "code": "\tpublic void setHost(@Nullable String host) {\n\t\tthis.host = host;\n\t}", "summary_tokens": ["set", "the", "mail", "server", "host", "typically", "an", "smtp", "host"], "project": "spring-framework"}
{"id": 3120, "code": "\tpublic static ClassLoader overrideThreadContextClassLoader(@Nullable ClassLoader classLoaderToUse) {\n\t\tThread currentThread = Thread.currentThread();\n\t\tClassLoader threadContextClassLoader = currentThread.getContextClassLoader();\n\t\tif (classLoaderToUse != null && !classLoaderToUse.equals(threadContextClassLoader)) {\n\t\t\tcurrentThread.setContextClassLoader(classLoaderToUse);\n\t\t\treturn threadContextClassLoader;\n\t\t}\n\t\telse {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["override", "the", "thread", "context", "class", "loader", "with", "the", "environment", "s", "bean", "class", "loader", "if", "necessary", "i"], "project": "spring-framework"}
{"id": 9241, "code": "\tpublic void setScope(String scope) {\n\t\tthis.scope = TagUtils.getScope(scope);\n\t}", "summary_tokens": ["set", "the", "scope", "to", "export", "the", "url", "variable", "to"], "project": "spring-framework"}
{"id": 8699, "code": "\tprotected void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n\t}", "summary_tokens": ["override", "this", "method", "to", "add", "custom", "http", "message", "converter", "http", "message", "converters", "to", "use", "with", "the", "request", "mapping", "handler", "adapter", "and", "the", "exception", "handler", "exception", "resolver"], "project": "spring-framework"}
{"id": 4487, "code": "\tprotected void establishSharedConnection() {\n\t\ttry {\n\t\t\tsuper.establishSharedConnection();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tif (ex instanceof JMSException) {\n\t\t\t\tinvokeExceptionListener((JMSException) ex);\n\t\t\t}\n\t\t\tlogger.debug(\"Could not establish shared JMS Connection - \" +\n\t\t\t\t\t\"leaving it up to asynchronous invokers to establish a Connection as soon as possible\", ex);\n\t\t}\n\t}", "summary_tokens": ["overridden", "to", "accept", "a", "failure", "in", "the", "initial", "setup", "leaving", "it", "up", "to", "the", "asynchronous", "invokers", "to", "establish", "the", "shared", "connection", "on", "first", "access"], "project": "spring-framework"}
{"id": 4831, "code": "\tpublic Map<String, Object> getSessionAttributes() {\n\t\treturn (Map<String, Object>) getHeader(SESSION_ATTRIBUTES);\n\t}", "summary_tokens": ["return", "the", "attributes", "associated", "with", "the", "current", "session"], "project": "spring-framework"}
{"id": 9326, "code": "\tprotected String getOnchange() {\n\t\treturn this.onchange;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onchange", "attribute"], "project": "spring-framework"}
{"id": 1359, "code": "\tprotected DefaultListableBeanFactory createBeanFactory() {\n\t\treturn new DefaultListableBeanFactory(getInternalParentBeanFactory());\n\t}", "summary_tokens": ["create", "an", "internal", "bean", "factory", "for", "this", "context"], "project": "spring-framework"}
{"id": 8864, "code": "\tpublic void destroy() {\n\t\tif (this.servletInstance != null) {\n\t\t\tthis.servletInstance.destroy();\n\t\t}\n\t}", "summary_tokens": ["destroy", "the", "wrapped", "servlet", "instance"], "project": "spring-framework"}
{"id": 9218, "code": "\tprotected Object[] resolveArguments(@Nullable Object arguments) throws JspException {\n\t\tif (arguments instanceof String) {\n\t\t\treturn StringUtils.delimitedListToStringArray((String) arguments, this.argumentSeparator);\n\t\t}\n\t\telse if (arguments instanceof Object[]) {\n\t\t\treturn (Object[]) arguments;\n\t\t}\n\t\telse if (arguments instanceof Collection) {\n\t\t\treturn ((Collection<?>) arguments).toArray();\n\t\t}\n\t\telse if (arguments != null) {\n\t\t\t\n\t\t\treturn new Object[] {arguments};\n\t\t}\n\t\telse {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["resolve", "the", "given", "arguments", "object", "into", "an", "arguments", "array"], "project": "spring-framework"}
{"id": 6675, "code": "\tpublic void setIfModifiedSince(long ifModifiedSince) {\n\t\tsetDate(IF_MODIFIED_SINCE, ifModifiedSince);\n\t}", "summary_tokens": ["set", "the", "new", "value", "of", "the", "if", "modified", "since", "header"], "project": "spring-framework"}
{"id": 8550, "code": "\tpublic ModelAndView addAllObjects(@Nullable Map<String, ?> modelMap) {\n\t\tgetModelMap().addAllAttributes(modelMap);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "all", "attributes", "contained", "in", "the", "provided", "map", "to", "the", "model"], "project": "spring-framework"}
{"id": 2239, "code": "\tvoid doWithMethodSpecs(Consumer<MethodSpec> action) {\n\t\tstream().map(GeneratedMethod::getMethodSpec).forEach(action);\n\t}", "summary_tokens": ["call", "the", "given", "action", "with", "each", "of", "the", "method", "spec", "method", "specs", "that", "have", "been", "added", "to", "this", "collection"], "project": "spring-framework"}
{"id": 7893, "code": "\tpublic String toDetailedString() {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tsb.append(this.pattern).append('\\n');\n\t\tfor (int i = 0; i < this.position; i++) {\n\t\t\tsb.append(' ');\n\t\t}\n\t\tsb.append(\"^\\n\");\n\t\tsb.append(getMessage());\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["return", "a", "detailed", "message", "that", "includes", "the", "original", "pattern", "text", "with", "a", "pointer", "to", "the", "error", "position", "as", "well", "as", "the", "error", "message"], "project": "spring-framework"}
{"id": 2392, "code": "public MethodVisitor visitMethod(\n    final int access,\n    final String name,\n    final String descriptor,\n    final String signature,\n    final String[] exceptions) {\n  if (cv != null) {\n    return cv.visitMethod(access, name, descriptor, signature, exceptions);\n  }\n  return null;\n}", "summary_tokens": ["visits", "a", "method", "of", "the", "class"], "project": "spring-framework"}
{"id": 4267, "code": "\tpublic void setShouldStopConnections(boolean shouldStopConnections) {\n\t\tthis.shouldStopConnections = shouldStopConnections;\n\t}", "summary_tokens": ["indicate", "whether", "connections", "obtained", "from", "the", "target", "factory", "are", "supposed", "to", "be", "stopped", "before", "closed", "true", "or", "simply", "closed", "false"], "project": "spring-framework"}
{"id": 7092, "code": "\tpublic void publishComplete() {\n\t\tState state = this.state.get();\n\t\tif (rsWriteResultLogger.isTraceEnabled()) {\n\t\t\trsWriteResultLogger.trace(this.logPrefix + \"completed [\" + state + \"]\");\n\t\t}\n\t\tstate.publishComplete(this);\n\t}", "summary_tokens": ["invoke", "this", "to", "delegate", "a", "completion", "signal", "to", "the", "subscriber"], "project": "spring-framework"}
{"id": 7667, "code": "\tpublic String getReason() {\n\t\treturn this.reason;\n\t}", "summary_tokens": ["the", "reason", "explaining", "the", "exception", "potentially", "null", "or", "empty"], "project": "spring-framework"}
{"id": 1865, "code": "\tpublic void setTaskDecorator(TaskDecorator taskDecorator) {\n\t\tthis.taskDecorator = taskDecorator;\n\t}", "summary_tokens": ["specify", "a", "custom", "task", "decorator", "to", "be", "applied", "to", "any", "runnable", "about", "to", "be", "executed"], "project": "spring-framework"}
{"id": 3948, "code": "\tpublic void setDriverClassName(String driverClassName) {\n\t\tAssert.hasText(driverClassName, \"Property 'driverClassName' must not be empty\");\n\t\tString driverClassNameToUse = driverClassName.trim();\n\t\ttry {\n\t\t\tClass.forName(driverClassNameToUse, true, ClassUtils.getDefaultClassLoader());\n\t\t}\n\t\tcatch (ClassNotFoundException ex) {\n\t\t\tthrow new IllegalStateException(\"Could not load JDBC driver class [\" + driverClassNameToUse + \"]\", ex);\n\t\t}\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Loaded JDBC driver: \" + driverClassNameToUse);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "jdbc", "driver", "class", "name"], "project": "spring-framework"}
{"id": 2488, "code": "public void visitMultiANewArrayInsn(final String descriptor, final int numDimensions) {\n  if (mv != null) {\n    mv.visitMultiANewArrayInsn(descriptor, numDimensions);\n  }\n}", "summary_tokens": ["visits", "a", "multianewarray", "instruction"], "project": "spring-framework"}
{"id": 6265, "code": "\tpublic void setTransactionManagerBeanName(@Nullable String transactionManagerBeanName) {\n\t\tthis.transactionManagerBeanName = transactionManagerBeanName;\n\t}", "summary_tokens": ["specify", "the", "name", "of", "the", "default", "transaction", "manager", "bean"], "project": "spring-framework"}
{"id": 2511, "code": "public void visitPackage(final String packaze) {\n  if (mv != null) {\n    mv.visitPackage(packaze);\n  }\n}", "summary_tokens": ["visit", "a", "package", "of", "the", "current", "module"], "project": "spring-framework"}
{"id": 3679, "code": "\tpublic void setResultSetType(int resultSetType) {\n\t\tthis.resultSetType = resultSetType;\n\t}", "summary_tokens": ["set", "whether", "to", "use", "prepared", "statements", "that", "return", "a", "specific", "type", "of", "result", "set"], "project": "spring-framework"}
{"id": 2582, "code": "public int getSize() {\n  switch (sort) {\n    case VOID:\n      return 0;\n    case BOOLEAN:\n    case CHAR:\n    case BYTE:\n    case SHORT:\n    case INT:\n    case FLOAT:\n    case ARRAY:\n    case OBJECT:\n    case INTERNAL:\n      return 1;\n    case LONG:\n    case DOUBLE:\n      return 2;\n    default:\n      throw new AssertionError();\n  }\n}", "summary_tokens": ["returns", "the", "size", "of", "values", "of", "this", "type"], "project": "spring-framework"}
{"id": 891, "code": "\tpublic void previousPage() {\n\t\tif (!isFirstPage()) {\n\t\t\tthis.page--;\n\t\t}\n\t}", "summary_tokens": ["switch", "to", "previous", "page"], "project": "spring-framework"}
{"id": 5827, "code": "\tpublic RequestMatcher isNotEmpty() {\n\t\treturn new AbstractJsonPathRequestMatcher() {\n\t\t\t@Override\n\t\t\tpublic void matchInternal(MockClientHttpRequest request) throws IOException, ParseException {\n\t\t\t\tJsonPathRequestMatchers.this.jsonPathHelper.assertValueIsNotEmpty(request.getBodyAsString());\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "json", "path", "expression", "against", "the", "request", "content", "and", "assert", "that", "a", "non", "empty", "value", "exists", "at", "the", "given", "path"], "project": "spring-framework"}
{"id": 1259, "code": "\tpublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {\n\t\tboolean candidateFound = false;\n\t\tSet<String> annTypes = importingClassMetadata.getAnnotationTypes();\n\t\tfor (String annType : annTypes) {\n\t\t\tAnnotationAttributes candidate = AnnotationConfigUtils.attributesFor(importingClassMetadata, annType);\n\t\t\tif (candidate == null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tObject mode = candidate.get(\"mode\");\n\t\t\tObject proxyTargetClass = candidate.get(\"proxyTargetClass\");\n\t\t\tif (mode != null && proxyTargetClass != null && AdviceMode.class == mode.getClass() &&\n\t\t\t\t\tBoolean.class == proxyTargetClass.getClass()) {\n\t\t\t\tcandidateFound = true;\n\t\t\t\tif (mode == AdviceMode.PROXY) {\n\t\t\t\t\tAopConfigUtils.registerAutoProxyCreatorIfNecessary(registry);\n\t\t\t\t\tif ((Boolean) proxyTargetClass) {\n\t\t\t\t\t\tAopConfigUtils.forceAutoProxyCreatorToUseClassProxying(registry);\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (!candidateFound && logger.isInfoEnabled()) {\n\t\t\tString name = getClass().getSimpleName();\n\t\t\tlogger.info(String.format(\"%s was imported but no annotations were found \" +\n\t\t\t\t\t\"having both 'mode' and 'proxyTargetClass' attributes of type \" +\n\t\t\t\t\t\"AdviceMode and boolean respectively. This means that auto proxy \" +\n\t\t\t\t\t\"creator registration and configuration may not have occurred as \" +\n\t\t\t\t\t\"intended, and components may not be proxied as expected. Check to \" +\n\t\t\t\t\t\"ensure that %s has been @Import'ed on the same class where these \" +\n\t\t\t\t\t\"annotations are declared; otherwise remove the import of %s \" +\n\t\t\t\t\t\"altogether.\", name, name, name));\n\t\t}\n\t}", "summary_tokens": ["register", "escalate", "and", "configure", "the", "standard", "auto", "proxy", "creator", "apc", "against", "the", "given", "registry"], "project": "spring-framework"}
{"id": 9300, "code": "\tpublic void setOnmousedown(String onmousedown) {\n\t\tthis.onmousedown = onmousedown;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "onmousedown", "attribute"], "project": "spring-framework"}
{"id": 6647, "code": "\tpublic List<Charset> getAcceptCharset() {\n\t\tString value = getFirst(ACCEPT_CHARSET);\n\t\tif (value != null) {\n\t\t\tString[] tokens = StringUtils.tokenizeToStringArray(value, \",\");\n\t\t\tList<Charset> result = new ArrayList<>(tokens.length);\n\t\t\tfor (String token : tokens) {\n\t\t\t\tint paramIdx = token.indexOf(';');\n\t\t\t\tString charsetName;\n\t\t\t\tif (paramIdx == -1) {\n\t\t\t\t\tcharsetName = token;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tcharsetName = token.substring(0, paramIdx);\n\t\t\t\t}\n\t\t\t\tif (!charsetName.equals(\"*\")) {\n\t\t\t\t\tresult.add(Charset.forName(charsetName));\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\telse {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t}", "summary_tokens": ["return", "the", "list", "of", "acceptable", "charset", "charsets", "as", "specified", "by", "the", "accept", "charset", "header"], "project": "spring-framework"}
{"id": 7722, "code": "\tpublic List<WebFilter> getFilters() {\n\t\treturn this.chain.getFilters();\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "of", "the", "configured", "filters"], "project": "spring-framework"}
{"id": 9883, "code": "\tpublic Collection<String> getAllowedOriginPatterns() {\n\t\tList<String> allowedOriginPatterns = this.corsConfiguration.getAllowedOriginPatterns();\n\t\treturn (CollectionUtils.isEmpty(allowedOriginPatterns) ? Collections.emptySet() :\n\t\t\t\tCollections.unmodifiableSet(new LinkedHashSet<>(allowedOriginPatterns)));\n\t}", "summary_tokens": ["return", "the", "set", "allowed", "origin", "patterns", "collection", "configured", "allowed", "origin", "patterns"], "project": "spring-framework"}
{"id": 5312, "code": "\tprotected XMLReader createXmlReader() throws SAXException, ParserConfigurationException {\n\t\tSAXParserFactory saxParserFactory = SAXParserFactory.newInstance();\n\t\tsaxParserFactory.setNamespaceAware(true);\n\t\tsaxParserFactory.setFeature(\"http://apache.org/xml/features/disallow-doctype-decl\", !isSupportDtd());\n\t\tsaxParserFactory.setFeature(\"http://xml.org/sax/features/external-general-entities\", isProcessExternalEntities());\n\t\tSAXParser saxParser = saxParserFactory.newSAXParser();\n\t\tXMLReader xmlReader = saxParser.getXMLReader();\n\t\tif (!isProcessExternalEntities()) {\n\t\t\txmlReader.setEntityResolver(NO_OP_ENTITY_RESOLVER);\n\t\t}\n\t\treturn xmlReader;\n\t}", "summary_tokens": ["create", "an", "xmlreader", "that", "this", "marshaller", "will", "when", "passed", "an", "empty", "saxsource"], "project": "spring-framework"}
{"id": 9051, "code": "\tprotected ModelAndView handleConversionNotSupported(ConversionNotSupportedException ex,\n\t\t\tHttpServletRequest request, HttpServletResponse response, @Nullable Object handler) throws IOException {\n\n\t\tsendServerError(ex, request, response);\n\t\treturn new ModelAndView();\n\t}", "summary_tokens": ["handle", "the", "case", "when", "a", "org"], "project": "spring-framework"}
{"id": 2384, "code": "public AnnotationVisitor visitAnnotation(final String descriptor, final boolean visible) {\n  if (cv != null) {\n    return cv.visitAnnotation(descriptor, visible);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "annotation", "of", "the", "class"], "project": "spring-framework"}
{"id": 6143, "code": "\tvoid autowiredParameterWithImplicitQualifierBasedOnParameterName(@Autowired Person wally) {\n\t\tassertThat(wally).as(\"Wally should have been @Autowired by Spring\").isNotNull();\n\t\tassertThat(wally.getName()).as(\"Person's name\").isEqualTo(\"Wally\");\n\t}", "summary_tokens": ["note", "test", "code", "must", "be", "compiled", "with", "g", "debug", "symbols", "or", "parameters", "in", "order", "for", "the", "parameter", "name", "to", "be", "used", "as", "the", "qualifier", "otherwise", "use", "wally"], "project": "spring-framework"}
{"id": 615, "code": "\tpublic int loadBeanDefinitions(String location, @Nullable Set<Resource> actualResources) throws BeanDefinitionStoreException {\n\t\tResourceLoader resourceLoader = getResourceLoader();\n\t\tif (resourceLoader == null) {\n\t\t\tthrow new BeanDefinitionStoreException(\n\t\t\t\t\t\"Cannot load bean definitions from location [\" + location + \"]: no ResourceLoader available\");\n\t\t}\n\n\t\tif (resourceLoader instanceof ResourcePatternResolver) {\n\t\t\t\n\t\t\ttry {\n\t\t\t\tResource[] resources = ((ResourcePatternResolver) resourceLoader).getResources(location);\n\t\t\t\tint count = loadBeanDefinitions(resources);\n\t\t\t\tif (actualResources != null) {\n\t\t\t\t\tCollections.addAll(actualResources, resources);\n\t\t\t\t}\n\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\tlogger.trace(\"Loaded \" + count + \" bean definitions from location pattern [\" + location + \"]\");\n\t\t\t\t}\n\t\t\t\treturn count;\n\t\t\t}\n\t\t\tcatch (IOException ex) {\n\t\t\t\tthrow new BeanDefinitionStoreException(\n\t\t\t\t\t\t\"Could not resolve bean definition resource pattern [\" + location + \"]\", ex);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tResource resource = resourceLoader.getResource(location);\n\t\t\tint count = loadBeanDefinitions(resource);\n\t\t\tif (actualResources != null) {\n\t\t\t\tactualResources.add(resource);\n\t\t\t}\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Loaded \" + count + \" bean definitions from location [\" + location + \"]\");\n\t\t\t}\n\t\t\treturn count;\n\t\t}\n\t}", "summary_tokens": ["load", "bean", "definitions", "from", "the", "specified", "resource", "location"], "project": "spring-framework"}
{"id": 8395, "code": "\tprivate String getDefaultViewName(ServerWebExchange exchange) {\n\t\tString path = exchange.getRequest().getPath().pathWithinApplication().value();\n\t\tif (path.startsWith(\"/\")) {\n\t\t\tpath = path.substring(1);\n\t\t}\n\t\tif (path.endsWith(\"/\")) {\n\t\t\tpath = path.substring(0, path.length() - 1);\n\t\t}\n\t\treturn StringUtils.stripFilenameExtension(path);\n\t}", "summary_tokens": ["select", "a", "default", "view", "name", "when", "a", "controller", "did", "not", "specify", "it"], "project": "spring-framework"}
{"id": 4646, "code": "\tpublic void setUnmarshaller(@Nullable Unmarshaller unmarshaller) {\n\t\tthis.unmarshaller = unmarshaller;\n\t}", "summary_tokens": ["set", "the", "unmarshaller", "to", "be", "used", "by", "this", "message", "converter"], "project": "spring-framework"}
{"id": 5032, "code": "\tpublic void setUserDestinationPrefix(String prefix) {\n\t\tAssert.hasText(prefix, \"Prefix must not be empty\");\n\t\tthis.prefix = (prefix.endsWith(\"/\") ? prefix : prefix + \"/\");\n\t}", "summary_tokens": ["the", "prefix", "used", "to", "identify", "user", "destinations"], "project": "spring-framework"}
{"id": 7694, "code": "\tpublic ServerCodecConfigurer getCodecConfigurer() {\n\t\tif (this.codecConfigurer == null) {\n\t\t\tsetCodecConfigurer(ServerCodecConfigurer.create());\n\t\t}\n\t\treturn this.codecConfigurer;\n\t}", "summary_tokens": ["return", "the", "configured", "server", "codec", "configurer"], "project": "spring-framework"}
{"id": 6666, "code": "\tpublic long getDate() {\n\t\treturn getFirstDate(DATE);\n\t}", "summary_tokens": ["return", "the", "date", "and", "time", "at", "which", "the", "message", "was", "created", "as", "specified", "by", "the", "date", "header"], "project": "spring-framework"}
{"id": 2389, "code": "public void visitInnerClass(\n    final String name, final String outerName, final String innerName, final int access) {\n  if (cv != null) {\n    cv.visitInnerClass(name, outerName, innerName, access);\n  }\n}", "summary_tokens": ["visits", "information", "about", "an", "inner", "class"], "project": "spring-framework"}
{"id": 2915, "code": "\tpublic Resource createRelative(String relativePath) throws IOException {\n\t\tthrow new FileNotFoundException(\"Cannot create a relative resource for \" + getDescription());\n\t}", "summary_tokens": ["this", "implementation", "throws", "a", "file", "not", "found", "exception", "assuming", "that", "relative", "resources", "cannot", "be", "created", "for", "this", "resource"], "project": "spring-framework"}
{"id": 3774, "code": "\tpublic void setAccessTableColumnMetaData(boolean accessTableColumnMetaData) {\n\t\tthis.accessTableColumnMetaData = accessTableColumnMetaData;\n\t}", "summary_tokens": ["specify", "whether", "we", "should", "access", "table", "column", "meta", "data"], "project": "spring-framework"}
{"id": 3684, "code": "\tprotected Object getColumnValue(ResultSet rs, int index) throws SQLException {\n\t\treturn JdbcUtils.getResultSetValue(rs, index);\n\t}", "summary_tokens": ["retrieve", "a", "jdbc", "object", "value", "for", "the", "specified", "column"], "project": "spring-framework"}
{"id": 2909, "code": "\tpublic URI getURI() throws IOException {\n\t\tURL url = getURL();\n\t\ttry {\n\t\t\treturn ResourceUtils.toURI(url);\n\t\t}\n\t\tcatch (URISyntaxException ex) {\n\t\t\tthrow new IOException(\"Invalid URI [\" + url + \"]\", ex);\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "builds", "a", "uri", "based", "on", "the", "url", "returned", "by", "get", "url"], "project": "spring-framework"}
{"id": 4493, "code": "\tprotected void refreshDestination() {\n\t\tString destName = getDestinationName();\n\t\tif (destName != null) {\n\t\t\tDestinationResolver destResolver = getDestinationResolver();\n\t\t\tif (destResolver instanceof CachingDestinationResolver) {\n\t\t\t\t((CachingDestinationResolver) destResolver).removeFromCache(destName);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["refresh", "the", "jms", "destination", "that", "this", "listener", "container", "operates", "on"], "project": "spring-framework"}
{"id": 1420, "code": "\tpublic void setEnvironment(ConfigurableEnvironment environment) {\n\t\tsuper.setEnvironment(environment);\n\t\tthis.reader.setEnvironment(getEnvironment());\n\t}", "summary_tokens": ["delegates", "the", "given", "environment", "to", "underlying", "xml", "bean", "definition", "reader"], "project": "spring-framework"}
{"id": 2149, "code": "\tpublic static ClassLoader index(ClassLoader classLoader, Resource... resources) {\n\t\treturn new CandidateComponentsTestClassLoader(classLoader,\n\t\t\t\tCollections.enumeration(Stream.of(resources).map(r -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn r.getURL();\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\t\tthrow new IllegalArgumentException(\"Invalid resource \" + r, ex);\n\t\t\t\t\t}\n\t\t\t\t}).collect(Collectors.toList())));\n\t}", "summary_tokens": ["create", "a", "test", "class", "loader", "that", "creates", "an", "index", "with", "the", "specified", "resource", "instances", "class", "loader", "the", "classloader", "to", "use", "for", "all", "other", "operations", "a", "test", "class", "loader", "with", "an", "index", "built", "based", "on", "the", "specified", "resources"], "project": "spring-framework"}
{"id": 8409, "code": "\tprotected String getEncoding() {\n\t\treturn this.encoding;\n\t}", "summary_tokens": ["get", "the", "encoding", "for", "the", "free", "marker", "template"], "project": "spring-framework"}
{"id": 9499, "code": "\tpublic int getCacheLimit() {\n\t\treturn this.cacheLimit;\n\t}", "summary_tokens": ["return", "the", "maximum", "number", "of", "entries", "for", "the", "view", "cache"], "project": "spring-framework"}
{"id": 6341, "code": "\tpublic final TransactionManager getTransactionManager() {\n\t\treturn this.transactionManager;\n\t}", "summary_tokens": ["return", "the", "jta", "transaction", "manager", "that", "this", "adapter", "delegates", "to"], "project": "spring-framework"}
{"id": 5355, "code": "\tprotected Boolean getAutoCommitValue() {\n\t\treturn this.autoCommit;\n\t}", "summary_tokens": ["return", "whether", "the", "returned", "connection", "s", "auto", "commit", "setting", "should", "be", "overridden"], "project": "spring-framework"}
{"id": 735, "code": "\tpublic static RegisteredBean ofInnerBean(RegisteredBean parent,\n\t\t\t@Nullable String innerBeanName, BeanDefinition innerBeanDefinition) {\n\n\t\tAssert.notNull(parent, \"'parent' must not be null\");\n\t\tAssert.notNull(innerBeanDefinition, \"'innerBeanDefinition' must not be null\");\n\t\tInnerBeanResolver resolver = new InnerBeanResolver(parent, innerBeanName,\n\t\t\t\tinnerBeanDefinition);\n\t\tSupplier<String> beanName = StringUtils.hasLength(innerBeanName)\n\t\t\t\t? () -> innerBeanName : resolver::resolveBeanName;\n\t\treturn new RegisteredBean(parent.getBeanFactory(), beanName,\n\t\t\t\tinnerBeanName == null, resolver::resolveMergedBeanDefinition, parent);\n\t}", "summary_tokens": ["create", "a", "new", "registered", "bean", "instance", "for", "an", "inner", "bean"], "project": "spring-framework"}
{"id": 6685, "code": "\tpublic void setOrigin(@Nullable String origin) {\n\t\tsetOrRemove(ORIGIN, origin);\n\t}", "summary_tokens": ["set", "the", "new", "value", "of", "the", "origin", "header"], "project": "spring-framework"}
{"id": 9365, "code": "\tprotected boolean shouldRender() throws JspException {\n\t\ttry {\n\t\t\treturn getBindStatus().isError();\n\t\t}\n\t\tcatch (IllegalStateException ex) {\n\t\t\t\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["should", "rendering", "of", "this", "tag", "proceed", "at", "all", "p", "only", "renders", "output", "when", "there", "are", "errors", "for", "the", "configured", "set", "path", "path"], "project": "spring-framework"}
{"id": 2591, "code": "public static TypePath fromString(final String typePath) {\n  if (typePath == null || typePath.length() == 0) {\n    return null;\n  }\n  int typePathLength = typePath.length();\n  ByteVector output = new ByteVector(typePathLength);\n  output.putByte(0);\n  int typePathIndex = 0;\n  while (typePathIndex < typePathLength) {\n    char c = typePath.charAt(typePathIndex++);\n    if (c == '[') {\n      output.put11(ARRAY_ELEMENT, 0);\n    } else if (c == '.') {\n      output.put11(INNER_TYPE, 0);\n    } else if (c == '*') {\n      output.put11(WILDCARD_BOUND, 0);\n    } else if (c >= '0' && c <= '9') {\n      int typeArg = c - '0';\n      while (typePathIndex < typePathLength) {\n        c = typePath.charAt(typePathIndex++);\n        if (c >= '0' && c <= '9') {\n          typeArg = typeArg * 10 + c - '0';\n        } else if (c == ';') {\n          break;\n        } else {\n          throw new IllegalArgumentException();\n        }\n      }\n      output.put11(TYPE_ARGUMENT, typeArg);\n    } else {\n      throw new IllegalArgumentException();\n    }\n  }\n  output.data[0] = (byte) (output.length / 2);\n  return new TypePath(output.data, 0);\n}", "summary_tokens": ["converts", "a", "type", "path", "in", "string", "form", "in", "the", "format", "used", "by", "to", "string", "into", "a", "type", "path", "object"], "project": "spring-framework"}
{"id": 6251, "code": "\tpublic String getDescriptor() {\n\t\treturn this.descriptor;\n\t}", "summary_tokens": ["return", "a", "descriptor", "for", "this", "transaction", "attribute", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 260, "code": "\tpublic long getMaxWait() {\n\t\treturn this.maxWait;\n\t}", "summary_tokens": ["return", "the", "maximum", "waiting", "time", "for", "fetching", "an", "object", "from", "the", "pool"], "project": "spring-framework"}
{"id": 3811, "code": "\tString getOriginalSql() {\n\t\treturn this.originalSql;\n\t}", "summary_tokens": ["return", "the", "sql", "statement", "that", "is", "being", "parsed"], "project": "spring-framework"}
{"id": 2760, "code": "\tpublic static void setProperty(String key, @Nullable String value) {\n\t\tif (value != null) {\n\t\t\tlocalProperties.setProperty(key, value);\n\t\t}\n\t\telse {\n\t\t\tlocalProperties.remove(key);\n\t\t}\n\t}", "summary_tokens": ["programmatically", "set", "a", "local", "property", "overriding", "an", "entry", "in", "the", "spring"], "project": "spring-framework"}
{"id": 181, "code": "\tprotected String getExecutorQualifier(Method method) {\n\t\treturn null;\n\t}", "summary_tokens": ["this", "implementation", "is", "a", "no", "op", "for", "compatibility", "in", "spring", "0"], "project": "spring-framework"}
{"id": 4698, "code": "\tprivate Method getMappedMethod(Class<? extends Throwable> exceptionType) {\n\t\tList<Class<? extends Throwable>> matches = new ArrayList<>();\n\t\tfor (Class<? extends Throwable> mappedException : this.mappedMethods.keySet()) {\n\t\t\tif (mappedException.isAssignableFrom(exceptionType)) {\n\t\t\t\tmatches.add(mappedException);\n\t\t\t}\n\t\t}\n\t\tif (!matches.isEmpty()) {\n\t\t\tif (matches.size() > 1) {\n\t\t\t\tmatches.sort(new ExceptionDepthComparator(exceptionType));\n\t\t\t}\n\t\t\treturn this.mappedMethods.get(matches.get(0));\n\t\t}\n\t\telse {\n\t\t\treturn NO_MATCHING_EXCEPTION_HANDLER_METHOD;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "method", "mapped", "to", "the", "given", "exception", "type", "or", "no", "matching", "exception", "handler", "method", "if", "none"], "project": "spring-framework"}
{"id": 9353, "code": "\tpublic void setDisabled(boolean disabled) {\n\t\tthis.disabled = disabled;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "disabled", "attribute"], "project": "spring-framework"}
{"id": 4933, "code": "\tpublic long getReceiptTimeLimit() {\n\t\treturn this.receiptTimeLimit;\n\t}", "summary_tokens": ["return", "the", "configured", "time", "limit", "before", "a", "receipt", "expires"], "project": "spring-framework"}
{"id": 9060, "code": "\tpublic RedirectAttributesModelMap mergeAttributes(@Nullable Map<String, ?> attributes) {\n\t\tif (attributes != null) {\n\t\t\tattributes.forEach((key, attribute) -> {\n\t\t\t\tif (!containsKey(key)) {\n\t\t\t\t\taddAttribute(key, attribute);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["p", "each", "attribute", "value", "is", "formatted", "as", "a", "string", "before", "being", "merged"], "project": "spring-framework"}
{"id": 186, "code": "\tprotected Object invokeUnderTrace(MethodInvocation invocation, Log logger) throws Throwable {\n\t\tString name = ClassUtils.getQualifiedMethodName(invocation.getMethod());\n\t\tStopWatch stopWatch = new StopWatch(name);\n\t\tObject returnValue = null;\n\t\tboolean exitThroughException = false;\n\t\ttry {\n\t\t\tstopWatch.start(name);\n\t\t\twriteToLog(logger,\n\t\t\t\t\treplacePlaceholders(this.enterMessage, invocation, null, null, -1));\n\t\t\treturnValue = invocation.proceed();\n\t\t\treturn returnValue;\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tif (stopWatch.isRunning()) {\n\t\t\t\tstopWatch.stop();\n\t\t\t}\n\t\t\texitThroughException = true;\n\t\t\twriteToLog(logger, replacePlaceholders(\n\t\t\t\t\tthis.exceptionMessage, invocation, null, ex, stopWatch.getTotalTimeMillis()), ex);\n\t\t\tthrow ex;\n\t\t}\n\t\tfinally {\n\t\t\tif (!exitThroughException) {\n\t\t\t\tif (stopWatch.isRunning()) {\n\t\t\t\t\tstopWatch.stop();\n\t\t\t\t}\n\t\t\t\twriteToLog(logger, replacePlaceholders(\n\t\t\t\t\t\tthis.exitMessage, invocation, returnValue, null, stopWatch.getTotalTimeMillis()));\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["writes", "a", "log", "message", "before", "the", "invocation", "based", "on", "the", "value", "of", "enter", "message"], "project": "spring-framework"}
{"id": 1974, "code": "\tpublic void setAutoGrowNestedPaths(boolean autoGrowNestedPaths) {\n\t\tAssert.state(this.bindingResult == null,\n\t\t\t\t\"DataBinder is already initialized - call setAutoGrowNestedPaths before other configuration methods\");\n\t\tthis.autoGrowNestedPaths = autoGrowNestedPaths;\n\t}", "summary_tokens": ["set", "whether", "this", "binder", "should", "attempt", "to", "auto", "grow", "a", "nested", "path", "that", "contains", "a", "null", "value"], "project": "spring-framework"}
{"id": 4399, "code": "\tprotected void checkMessageListener(@Nullable Object messageListener) {\n\t\tif (messageListener != null && !(messageListener instanceof MessageListener ||\n\t\t\t\tmessageListener instanceof SessionAwareMessageListener)) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Message listener needs to be of type [\" + MessageListener.class.getName() +\n\t\t\t\t\t\"] or [\" + SessionAwareMessageListener.class.getName() + \"]\");\n\t\t}\n\t}", "summary_tokens": ["check", "the", "given", "message", "listener", "throwing", "an", "exception", "if", "it", "does", "not", "correspond", "to", "a", "supported", "listener", "type"], "project": "spring-framework"}
{"id": 8728, "code": "\tdefault void configureMessageConverters(List<HttpMessageConverter<?>> converters) {\n\t}", "summary_tokens": ["configure", "the", "http", "message", "converter", "http", "message", "converter", "s", "for", "reading", "from", "the", "request", "body", "and", "for", "writing", "to", "the", "response", "body"], "project": "spring-framework"}
{"id": 8452, "code": "\tpublic static WebSocketHandler decorate(WebSocketHandler handler, ContextView contextView) {\n\t\treturn (!contextView.isEmpty() ? new ContextWebSocketHandler(handler, contextView) : handler);\n\t}", "summary_tokens": ["return", "the", "given", "handler", "decorated", "to", "insert", "the", "given", "context", "or", "the", "same", "handler", "instance", "when", "the", "context", "is", "empty"], "project": "spring-framework"}
{"id": 8827, "code": "\tprotected ModelAndView getModelAndView(String viewName, Exception ex) {\n\t\tModelAndView mv = new ModelAndView(viewName);\n\t\tif (this.exceptionAttribute != null) {\n\t\t\tmv.addObject(this.exceptionAttribute, ex);\n\t\t}\n\t\treturn mv;\n\t}", "summary_tokens": ["return", "a", "model", "and", "view", "for", "the", "given", "view", "name", "and", "exception"], "project": "spring-framework"}
{"id": 1514, "code": "\tpublic ClassLoader getThrowawayClassLoader() {\n\t\treturn new SimpleThrowawayClassLoader(getInstrumentableClassLoader());\n\t}", "summary_tokens": ["this", "implementation", "builds", "a", "simple", "throwaway", "class", "loader"], "project": "spring-framework"}
{"id": 1596, "code": "\tprotected MBeanParameterInfo[] getOperationParameters(Method method, String beanKey) {\n\t\tParameterNameDiscoverer paramNameDiscoverer = getParameterNameDiscoverer();\n\t\tString[] paramNames = (paramNameDiscoverer != null ? paramNameDiscoverer.getParameterNames(method) : null);\n\t\tif (paramNames == null) {\n\t\t\treturn new MBeanParameterInfo[0];\n\t\t}\n\n\t\tMBeanParameterInfo[] info = new MBeanParameterInfo[paramNames.length];\n\t\tClass<?>[] typeParameters = method.getParameterTypes();\n\t\tfor (int i = 0; i < info.length; i++) {\n\t\t\tinfo[i] = new MBeanParameterInfo(paramNames[i], typeParameters[i].getName(), paramNames[i]);\n\t\t}\n\n\t\treturn info;\n\t}", "summary_tokens": ["create", "parameter", "info", "for", "the", "given", "method"], "project": "spring-framework"}
{"id": 1772, "code": "\tdefault Date nextExecutionTime(TriggerContext triggerContext) {\n\t\tInstant instant = nextExecution(triggerContext);\n\t\treturn instant != null ? Date.from(instant) : null;\n\t}", "summary_tokens": ["determine", "the", "next", "execution", "time", "according", "to", "the", "given", "trigger", "context"], "project": "spring-framework"}
{"id": 1494, "code": "\tprotected MonetaryAmountFormat getMonetaryAmountFormat(Locale locale) {\n\t\tif (this.formatName != null) {\n\t\t\treturn MonetaryFormats.getAmountFormat(this.formatName);\n\t\t}\n\t\telse {\n\t\t\treturn MonetaryFormats.getAmountFormat(locale);\n\t\t}\n\t}", "summary_tokens": ["obtain", "a", "monetary", "amount", "format", "for", "the", "given", "locale"], "project": "spring-framework"}
{"id": 7701, "code": "\tpublic void afterPropertiesSet() {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tString value = this.enableLoggingRequestDetails ?\n\t\t\t\t\t\"shown which may lead to unsafe logging of potentially sensitive data\" :\n\t\t\t\t\t\"masked to prevent unsafe logging of potentially sensitive data\";\n\t\t\tlogger.debug(\"enableLoggingRequestDetails='\" + this.enableLoggingRequestDetails +\n\t\t\t\t\t\"': form data and headers will be \" + value);\n\t\t}\n\t}", "summary_tokens": ["this", "method", "must", "be", "invoked", "after", "all", "properties", "have", "been", "set", "to", "complete", "initialization"], "project": "spring-framework"}
{"id": 2853, "code": "\tprotected String doGetActiveProfilesProperty() {\n\t\treturn getProperty(ACTIVE_PROFILES_PROPERTY_NAME);\n\t}", "summary_tokens": ["return", "the", "property", "value", "for", "the", "active", "profiles"], "project": "spring-framework"}
{"id": 6772, "code": "\tprotected void prepareConnection(HttpURLConnection connection, String httpMethod) throws IOException {\n\t\tif (this.connectTimeout >= 0) {\n\t\t\tconnection.setConnectTimeout(this.connectTimeout);\n\t\t}\n\t\tif (this.readTimeout >= 0) {\n\t\t\tconnection.setReadTimeout(this.readTimeout);\n\t\t}\n\n\t\tboolean mayWrite =\n\t\t\t\t(\"POST\".equals(httpMethod) || \"PUT\".equals(httpMethod) ||\n\t\t\t\t\t\t\"PATCH\".equals(httpMethod) || \"DELETE\".equals(httpMethod));\n\n\t\tconnection.setDoInput(true);\n\t\tconnection.setInstanceFollowRedirects(\"GET\".equals(httpMethod));\n\t\tconnection.setDoOutput(mayWrite);\n\t\tconnection.setRequestMethod(httpMethod);\n\t}", "summary_tokens": ["template", "method", "for", "preparing", "the", "given", "http", "urlconnection"], "project": "spring-framework"}
{"id": 3966, "code": "\tpublic void rollbackToSavepoint(Object savepoint) throws TransactionException {\n\t\tConnectionHolder conHolder = getConnectionHolderForSavepoint();\n\t\ttry {\n\t\t\tconHolder.getConnection().rollback((Savepoint) savepoint);\n\t\t\tconHolder.resetRollbackOnly();\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tthrow new TransactionSystemException(\"Could not roll back to JDBC savepoint\", ex);\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "rolls", "back", "to", "the", "given", "jdbc", "0"], "project": "spring-framework"}
{"id": 5234, "code": "\tprotected EntityManagerFactory createNativeEntityManagerFactory() throws PersistenceException {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Building JPA EntityManagerFactory for persistence unit '\" + getPersistenceUnitName() + \"'\");\n\t\t}\n\t\tPersistenceProvider provider = getPersistenceProvider();\n\t\tif (provider != null) {\n\t\t\t\n\t\t\tEntityManagerFactory emf = provider.createEntityManagerFactory(getPersistenceUnitName(), getJpaPropertyMap());\n\t\t\tif (emf == null) {\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\"PersistenceProvider [\" + provider + \"] did not return an EntityManagerFactory for name '\" +\n\t\t\t\t\t\tgetPersistenceUnitName() + \"'\");\n\t\t\t}\n\t\t\treturn emf;\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\treturn Persistence.createEntityManagerFactory(getPersistenceUnitName(), getJpaPropertyMap());\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "entity", "manager", "factory", "for", "the", "given", "configuration"], "project": "spring-framework"}
{"id": 5447, "code": "\tpublic void setWriteHandler(Function<Flux<DataBuffer>, Mono<Void>> writeHandler) {\n\t\tAssert.notNull(writeHandler, \"'writeHandler' is required\");\n\t\tthis.body = Flux.error(new IllegalStateException(\"Not available with custom write handler.\"));\n\t\tthis.writeHandler = writeHandler;\n\t}", "summary_tokens": ["configure", "a", "custom", "handler", "to", "consume", "the", "response", "body"], "project": "spring-framework"}
{"id": 669, "code": "\tpublic final BeanDefinition getBeanDefinition() {\n\t\treturn this.beanDefinition;\n\t}", "summary_tokens": ["return", "the", "wrapped", "bean", "definition", "object"], "project": "spring-framework"}
{"id": 2069, "code": "\tprotected boolean requiresTarget() {\n\t\treturn false;\n\t}", "summary_tokens": ["is", "a", "target", "always", "required"], "project": "spring-framework"}
{"id": 4450, "code": "\tprotected Connection getConnection(JmsResourceHolder holder) {\n\t\treturn holder.getConnection();\n\t}", "summary_tokens": ["fetch", "an", "appropriate", "connection", "from", "the", "given", "jms", "resource", "holder"], "project": "spring-framework"}
{"id": 5242, "code": "\tpublic void setSharedCacheMode(SharedCacheMode sharedCacheMode) {\n\t\tthis.sharedCacheMode = sharedCacheMode;\n\t}", "summary_tokens": ["specify", "the", "jpa", "0"], "project": "spring-framework"}
{"id": 5388, "code": "\tpublic void setTargetConnectionFactories(Map<?, ?> targetConnectionFactories) {\n\t\tthis.targetConnectionFactories = targetConnectionFactories;\n\t}", "summary_tokens": ["specify", "the", "map", "of", "target", "connection", "factory", "connection", "factories", "with", "the", "lookup", "key", "as", "key"], "project": "spring-framework"}
{"id": 4636, "code": "\tpublic List<MessageConverter> getConverters() {\n\t\treturn this.converters;\n\t}", "summary_tokens": ["return", "the", "underlying", "list", "of", "delegate", "converters"], "project": "spring-framework"}
{"id": 8961, "code": "\tpublic void setCustomReturnValueHandlers(@Nullable List<HandlerMethodReturnValueHandler> returnValueHandlers) {\n\t\tthis.customReturnValueHandlers = returnValueHandlers;\n\t}", "summary_tokens": ["provide", "handlers", "for", "custom", "return", "value", "types"], "project": "spring-framework"}
{"id": 9452, "code": "\tpublic void setDisabled(boolean disabled) {\n\t\tthis.disabled = disabled;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "disabled", "attribute"], "project": "spring-framework"}
{"id": 3556, "code": "\tpublic boolean isCompilable() {\n\t\treturn false;\n\t}", "summary_tokens": ["check", "whether", "a", "node", "can", "be", "compiled", "to", "bytecode"], "project": "spring-framework"}
{"id": 1542, "code": "\tpublic void afterSingletonsInstantiated() {\n\t\ttry {\n\t\t\tlogger.debug(\"Registering beans for JMX exposure on startup\");\n\t\t\tregisterBeans();\n\t\t\tregisterNotificationListeners();\n\t\t}\n\t\tcatch (RuntimeException ex) {\n\t\t\t\n\t\t\tunregisterNotificationListeners();\n\t\t\tunregisterBeans();\n\t\t\tthrow ex;\n\t\t}\n\t}", "summary_tokens": ["kick", "off", "bean", "registration", "automatically", "after", "the", "regular", "singleton", "instantiation", "phase"], "project": "spring-framework"}
{"id": 4595, "code": "\tprotected ObjectMessage createMessageForSerializable(Serializable object, Session session) throws JMSException {\n\t\treturn session.createObjectMessage(object);\n\t}", "summary_tokens": ["create", "a", "jms", "object", "message", "for", "the", "given", "serializable", "object"], "project": "spring-framework"}
{"id": 1282, "code": "\tpublic void setResourceLoader(@Nullable ResourceLoader resourceLoader) {\n\t\tthis.resourcePatternResolver = ResourcePatternUtils.getResourcePatternResolver(resourceLoader);\n\t\tthis.metadataReaderFactory = new CachingMetadataReaderFactory(resourceLoader);\n\t\tthis.componentsIndex = CandidateComponentsIndexLoader.loadIndex(this.resourcePatternResolver.getClassLoader());\n\t}", "summary_tokens": ["set", "the", "resource", "loader", "to", "use", "for", "resource", "locations"], "project": "spring-framework"}
{"id": 7061, "code": "\tpublic final void onComplete() {\n\t\tState state = this.state.get();\n\t\tif (rsWriteLogger.isTraceEnabled()) {\n\t\t\trsWriteLogger.trace(getLogPrefix() + \"onComplete [\" + state + \"]\");\n\t\t}\n\t\tstate.onComplete(this);\n\t}", "summary_tokens": ["completion", "signal", "from", "the", "upstream", "write", "publisher"], "project": "spring-framework"}
{"id": 5083, "code": "\tprotected Map<String, List<String>> getNativeHeaders() {\n\t\treturn (Map<String, List<String>>) getHeader(NATIVE_HEADERS);\n\t}", "summary_tokens": ["subclasses", "can", "use", "this", "method", "to", "access", "the", "native", "headers", "sub", "map"], "project": "spring-framework"}
{"id": 2484, "code": "public void visitLdcInsn(final Object value) {\n  if (api < Opcodes.ASM5\n      && (value instanceof Handle\n          || (value instanceof Type && ((Type) value).getSort() == Type.METHOD))) {\n    throw new UnsupportedOperationException(REQUIRES_ASM5);\n  }\n  if (api < Opcodes.ASM7 && value instanceof ConstantDynamic) {\n    throw new UnsupportedOperationException(\"This feature requires ASM7\");\n  }\n  if (mv != null) {\n    mv.visitLdcInsn(value);\n  }\n}", "summary_tokens": ["visits", "a", "ldc", "instruction"], "project": "spring-framework"}
{"id": 3801, "code": "\tpublic Map<String, Object> getValues() {\n\t\treturn Collections.unmodifiableMap(this.values);\n\t}", "summary_tokens": ["expose", "the", "current", "parameter", "values", "as", "read", "only", "map"], "project": "spring-framework"}
{"id": 5144, "code": "\tprotected void applyNamedParameterToQuery(Query<?> queryObject, String paramName, Object value)\n\t\t\tthrows HibernateException {\n\n\t\tif (value instanceof Collection) {\n\t\t\tqueryObject.setParameterList(paramName, (Collection<?>) value);\n\t\t}\n\t\telse if (value instanceof Object[]) {\n\t\t\tqueryObject.setParameterList(paramName, (Object[]) value);\n\t\t}\n\t\telse {\n\t\t\tqueryObject.setParameter(paramName, value);\n\t\t}\n\t}", "summary_tokens": ["apply", "the", "given", "name", "parameter", "to", "the", "given", "query", "object"], "project": "spring-framework"}
{"id": 9189, "code": "\tpublic String getPath() {\n\t\treturn this.path;\n\t}", "summary_tokens": ["return", "the", "path", "that", "this", "tag", "applies", "to"], "project": "spring-framework"}
{"id": 2141, "code": "\tpublic static synchronized void resetMBeanServers() throws Exception {\n\t\tfor (MBeanServer server : MBeanServerFactory.findMBeanServer(null)) {\n\t\t\ttry {\n\t\t\t\tMBeanServerFactory.releaseMBeanServer(server);\n\t\t\t}\n\t\t\tcatch (IllegalArgumentException ex) {\n\t\t\t\tif (!ex.getMessage().contains(\"not in list\")) {\n\t\t\t\t\tthrow ex;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["resets", "mbean", "server", "factory", "and", "management", "factory", "to", "a", "known", "consistent", "state"], "project": "spring-framework"}
{"id": 9729, "code": "\tvoid contextLoaderListenerWithCustomizedContextLoader() {\n\t\tfinal StringBuilder builder = new StringBuilder();\n\t\tfinal String expectedContents = \"customizeContext() was called\";\n\t\tfinal MockServletContext sc = new MockServletContext(\"\");\n\t\tsc.addInitParameter(ContextLoader.CONFIG_LOCATION_PARAM,\n\t\t\t\t\"/org/springframework/web/context/WEB-INF/applicationContext.xml\");\n\t\tServletContextListener listener = new ContextLoaderListener() {\n\t\t\t@Override\n\t\t\tprotected void customizeContext(ServletContext sc, ConfigurableWebApplicationContext wac) {\n\t\t\t\tassertThat(sc).as(\"The ServletContext should not be null.\").isNotNull();\n\t\t\t\tassertThat(sc).as(\"Verifying that we received the expected ServletContext.\").isEqualTo(sc);\n\t\t\t\tassertThat(wac.isActive()).as(\"The ApplicationContext should not yet have been refreshed.\").isFalse();\n\t\t\t\tbuilder.append(expectedContents);\n\t\t\t}\n\t\t};\n\t\tlistener.contextInitialized(new ServletContextEvent(sc));\n\t\tassertThat(builder.toString()).as(\"customizeContext() should have been called.\").isEqualTo(expectedContents);\n\t}", "summary_tokens": ["addresses", "the", "issues", "raised", "in", "a", "href", "https", "opensource"], "project": "spring-framework"}
{"id": 788, "code": "\tprotected boolean shouldGenerateIdAsFallback() {\n\t\treturn false;\n\t}", "summary_tokens": ["should", "an", "id", "be", "generated", "instead", "if", "the", "passed", "in", "element", "does", "not", "specify", "an", "id", "attribute", "explicitly", "p", "disabled", "by", "default", "subclasses", "can", "override", "this", "to", "enable", "id", "generation", "as", "fallback", "the", "parser", "will", "first", "check", "for", "an", "id", "attribute", "in", "this", "case", "only", "falling", "back", "to", "a", "generated", "id", "if", "no", "value", "was", "specified"], "project": "spring-framework"}
{"id": 1077, "code": "\tpublic void setTargetBeanName(String targetBeanName) {\n\t\tthis.targetBeanName = targetBeanName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "target", "bean", "in", "the", "spring", "bean", "factory"], "project": "spring-framework"}
{"id": 1575, "code": "\tprotected Class<?> getTargetClass(Object managedBean) {\n\t\treturn AopUtils.getTargetClass(managedBean);\n\t}", "summary_tokens": ["return", "the", "actual", "bean", "class", "of", "the", "given", "bean", "instance"], "project": "spring-framework"}
{"id": 5090, "code": "\tpublic void addNativeHeader(String name, @Nullable String value) {\n\t\tAssert.state(isMutable(), \"Already immutable\");\n\t\tif (value == null) {\n\t\t\treturn;\n\t\t}\n\t\tMap<String, List<String>> nativeHeaders = getNativeHeaders();\n\t\tif (nativeHeaders == null) {\n\t\t\tnativeHeaders = new LinkedMultiValueMap<>(3);\n\t\t\tsetHeader(NATIVE_HEADERS, nativeHeaders);\n\t\t}\n\t\tList<String> values = nativeHeaders.computeIfAbsent(name, k -> new ArrayList<>(1));\n\t\tvalues.add(value);\n\t\tsetModified(true);\n\t}", "summary_tokens": ["add", "the", "specified", "native", "header", "value", "to", "existing", "values"], "project": "spring-framework"}
{"id": 3191, "code": "\tpublic static <K, V> MultiValueMap<K, V> unmodifiableMultiValueMap(\n\t\t\tMultiValueMap<? extends K, ? extends V> targetMap) {\n\n\t\tAssert.notNull(targetMap, \"'targetMap' must not be null\");\n\t\tif (targetMap instanceof UnmodifiableMultiValueMap) {\n\t\t\treturn (MultiValueMap<K, V>) targetMap;\n\t\t}\n\t\treturn new UnmodifiableMultiValueMap<>(targetMap);\n\t}", "summary_tokens": ["return", "an", "unmodifiable", "view", "of", "the", "specified", "multi", "value", "map"], "project": "spring-framework"}
{"id": 1852, "code": "\tpublic void setExposeUnconfigurableExecutor(boolean exposeUnconfigurableExecutor) {\n\t\tthis.exposeUnconfigurableExecutor = exposeUnconfigurableExecutor;\n\t}", "summary_tokens": ["specify", "whether", "this", "factory", "bean", "should", "expose", "an", "unconfigurable", "decorator", "for", "the", "created", "executor"], "project": "spring-framework"}
{"id": 6650, "code": "\tpublic void setBasicAuth(String encodedCredentials) {\n\t\tAssert.hasText(encodedCredentials, \"'encodedCredentials' must not be null or blank\");\n\t\tset(AUTHORIZATION, \"Basic \" + encodedCredentials);\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "authorization", "authorization", "header", "to", "basic", "authentication", "based", "on", "the", "given", "encode", "basic", "auth", "encoded", "credentials"], "project": "spring-framework"}
{"id": 9445, "code": "\tprivate boolean isOptionSelected(@Nullable Object resolvedValue) {\n\t\treturn SelectedValueComparator.isSelected(this.bindStatus, resolvedValue);\n\t}", "summary_tokens": ["determine", "whether", "the", "supplied", "values", "matched", "the", "selected", "value"], "project": "spring-framework"}
{"id": 4156, "code": "\tpublic boolean isLazyInit() {\n\t\treturn this.lazyInit;\n\t}", "summary_tokens": ["return", "whether", "to", "lazily", "initialize", "the", "sqlexception", "translator", "for", "this", "transaction", "manager"], "project": "spring-framework"}
{"id": 8822, "code": "\tprotected String determineViewName(Exception ex, HttpServletRequest request) {\n\t\tString viewName = null;\n\t\tif (this.excludedExceptions != null) {\n\t\t\tfor (Class<?> excludedEx : this.excludedExceptions) {\n\t\t\t\tif (excludedEx.equals(ex.getClass())) {\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (this.exceptionMappings != null) {\n\t\t\tviewName = findMatchingViewName(this.exceptionMappings, ex);\n\t\t}\n\t\t\n\t\tif (viewName == null && this.defaultErrorView != null) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Resolving to default view '\" + this.defaultErrorView + \"'\");\n\t\t\t}\n\t\t\tviewName = this.defaultErrorView;\n\t\t}\n\t\treturn viewName;\n\t}", "summary_tokens": ["determine", "the", "view", "name", "for", "the", "given", "exception", "first", "checking", "against", "the", "set", "excluded", "exceptions", "class", "excluded", "execptions", "then", "searching", "the", "set", "exception", "mappings", "exception", "mappings", "and", "finally", "using", "the", "set", "default", "error", "view", "default", "error", "view", "as", "a", "fallback"], "project": "spring-framework"}
{"id": 1126, "code": "\tpublic void setGroup(String group) {\n\t\tthis.group = group;\n\t}", "summary_tokens": ["specify", "the", "trigger", "s", "group"], "project": "spring-framework"}
{"id": 5392, "code": "\tprotected Object resolveSpecifiedLookupKey(Object lookupKey) {\n\t\treturn lookupKey;\n\t}", "summary_tokens": ["resolve", "the", "given", "lookup", "key", "object", "as", "specified", "in", "the", "set", "target", "connection", "factories", "target", "connection", "factories", "map", "into", "the", "actual", "lookup", "key", "to", "be", "used", "for", "matching", "with", "the", "determine", "current", "lookup", "key", "current", "lookup", "key"], "project": "spring-framework"}
{"id": 1868, "code": "\tpublic ThreadPoolExecutor getThreadPoolExecutor() throws IllegalStateException {\n\t\tAssert.state(this.threadPoolExecutor != null, \"ThreadPoolTaskExecutor not initialized\");\n\t\treturn this.threadPoolExecutor;\n\t}", "summary_tokens": ["return", "the", "underlying", "thread", "pool", "executor", "for", "native", "access"], "project": "spring-framework"}
{"id": 4100, "code": "\tprotected void onCompileInternal() {\n\t}", "summary_tokens": ["hook", "method", "that", "subclasses", "may", "override", "to", "react", "to", "compilation"], "project": "spring-framework"}
{"id": 7341, "code": "\tpublic void scan(String... basePackages) {\n\t\tAssert.notEmpty(basePackages, \"At least one base package must be specified\");\n\t\tCollections.addAll(this.basePackages, basePackages);\n\t}", "summary_tokens": ["perform", "a", "scan", "within", "the", "specified", "base", "packages"], "project": "spring-framework"}
{"id": 7133, "code": "\tpublic List<MediaType> getContentTypes() {\n\t\treturn this.contentTypes;\n\t}", "summary_tokens": ["return", "the", "configured", "list", "of", "media", "types"], "project": "spring-framework"}
{"id": 3600, "code": "\tpublic TypeConverter getTypeConverter() {\n\t\treturn this.typeConverter;\n\t}", "summary_tokens": ["the", "configured", "type", "converter"], "project": "spring-framework"}
{"id": 9903, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "unique", "name", "associated", "with", "this", "service"], "project": "spring-framework"}
{"id": 9033, "code": "\tprotected void bindRequestParameters(WebDataBinder binder, NativeWebRequest request) {\n\t\tServletRequest servletRequest = request.getNativeRequest(ServletRequest.class);\n\t\tAssert.state(servletRequest != null, \"No ServletRequest\");\n\t\tServletRequestDataBinder servletBinder = (ServletRequestDataBinder) binder;\n\t\tservletBinder.bind(servletRequest);\n\t}", "summary_tokens": ["this", "implementation", "downcasts", "web", "data", "binder", "to", "servlet", "request", "data", "binder", "before", "binding"], "project": "spring-framework"}
{"id": 3759, "code": "\tprotected void setStoresUpperCaseIdentifiers(boolean storesUpperCaseIdentifiers) {\n\t\tthis.storesUpperCaseIdentifiers = storesUpperCaseIdentifiers;\n\t}", "summary_tokens": ["specify", "whether", "the", "database", "uses", "upper", "case", "for", "identifiers"], "project": "spring-framework"}
{"id": 6541, "code": "\tpublic static boolean hasResource(Object key) {\n\t\tObject actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key);\n\t\tObject value = doGetResource(actualKey);\n\t\treturn (value != null);\n\t}", "summary_tokens": ["check", "if", "there", "is", "a", "resource", "for", "the", "given", "key", "bound", "to", "the", "current", "thread"], "project": "spring-framework"}
{"id": 1691, "code": "\tpublic static Class<?>[] parameterInfoToTypes(\n\t\t\t@Nullable MBeanParameterInfo[] paramInfo, @Nullable ClassLoader classLoader)\n\t\t\tthrows ClassNotFoundException {\n\n\t\tClass<?>[] types = null;\n\t\tif (paramInfo != null && paramInfo.length > 0) {\n\t\t\ttypes = new Class<?>[paramInfo.length];\n\t\t\tfor (int x = 0; x < paramInfo.length; x++) {\n\t\t\t\ttypes[x] = ClassUtils.forName(paramInfo[x].getType(), classLoader);\n\t\t\t}\n\t\t}\n\t\treturn types;\n\t}", "summary_tokens": ["convert", "an", "array", "of", "mbean", "parameter", "info", "into", "an", "array", "of", "class", "instances", "corresponding", "to", "the", "parameters"], "project": "spring-framework"}
{"id": 6043, "code": "\tpublic ResultMatcher sessionAttributeDoesNotExist(String... names) {\n\t\treturn result -> {\n\t\t\tHttpSession session = result.getRequest().getSession();\n\t\t\tAssert.state(session != null, \"No HttpSession\");\n\t\t\tfor (String name : names) {\n\t\t\t\tassertNull(\"Session attribute '\" + name + \"' exists\", session.getAttribute(name));\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "given", "session", "attributes", "do", "not", "exist"], "project": "spring-framework"}
{"id": 7747, "code": "\tpublic String getUriTemplate() {\n\t\treturn this.uriTemplate;\n\t}", "summary_tokens": ["return", "the", "url", "template", "for", "the", "request", "if", "set"], "project": "spring-framework"}
{"id": 2235, "code": "\tdefault void addFile(Kind kind, String path, ThrowingConsumer<Appendable> content) {\n\t\tAssert.notNull(content, \"'content' must not be null\");\n\t\taddFile(kind, path, new AppendableConsumerInputStreamSource(content));\n\t}", "summary_tokens": ["add", "a", "generated", "file", "of", "the", "specified", "kind", "with", "content", "written", "to", "an", "appendable", "passed", "to", "the", "given", "throwing", "consumer"], "project": "spring-framework"}
{"id": 7969, "code": "\tpublic ResolvableType getReturnType() {\n\t\treturn this.returnType;\n\t}", "summary_tokens": ["return", "the", "type", "of", "the", "value", "returned", "from", "the", "handler", "e"], "project": "spring-framework"}
{"id": 4840, "code": "\tpublic long getSendTimeout() {\n\t\treturn this.sendTimeout;\n\t}", "summary_tokens": ["return", "the", "configured", "send", "timeout", "in", "milliseconds"], "project": "spring-framework"}
{"id": 1694, "code": "\tpublic static ObjectName appendIdentityToObjectName(ObjectName objectName, Object managedResource)\n\t\t\tthrows MalformedObjectNameException {\n\n\t\tHashtable<String, String> keyProperties = objectName.getKeyPropertyList();\n\t\tkeyProperties.put(IDENTITY_OBJECT_NAME_KEY, ObjectUtils.getIdentityHexString(managedResource));\n\t\treturn ObjectNameManager.getInstance(objectName.getDomain(), keyProperties);\n\t}", "summary_tokens": ["append", "an", "additional", "key", "value", "pair", "to", "an", "existing", "object", "name", "with", "the", "key", "being", "the", "static", "value", "identity", "and", "the", "value", "being", "the", "identity", "hash", "code", "of", "the", "managed", "resource", "being", "exposed", "on", "the", "supplied", "object", "name"], "project": "spring-framework"}
{"id": 2862, "code": "\tpublic void setValueSeparator(@Nullable String valueSeparator) {\n\t\tthis.valueSeparator = valueSeparator;\n\t}", "summary_tokens": ["specify", "the", "separating", "character", "between", "the", "placeholders", "replaced", "by", "this", "resolver", "and", "their", "associated", "default", "value", "or", "null", "if", "no", "such", "special", "character", "should", "be", "processed", "as", "a", "value", "separator"], "project": "spring-framework"}
{"id": 1771, "code": "\tdefault ScheduledFuture<?> scheduleWithFixedDelay(Runnable task, long delay) {\n\t\treturn scheduleWithFixedDelay(task, Duration.ofMillis(delay));\n\t}", "summary_tokens": ["schedule", "the", "given", "runnable", "starting", "as", "soon", "as", "possible", "and", "invoking", "it", "with", "the", "given", "delay", "between", "the", "completion", "of", "one", "execution", "and", "the", "start", "of", "the", "next"], "project": "spring-framework"}
{"id": 650, "code": "\tpublic boolean isLazyInit() {\n\t\treturn (this.lazyInit != null && this.lazyInit.booleanValue());\n\t}", "summary_tokens": ["return", "whether", "beans", "should", "be", "lazily", "initialized", "by", "default", "i"], "project": "spring-framework"}
{"id": 1349, "code": "\tprotected String getMessageInternal(@Nullable String code, @Nullable Object[] args, @Nullable Locale locale) {\n\t\tif (code == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (locale == null) {\n\t\t\tlocale = Locale.getDefault();\n\t\t}\n\t\tObject[] argsToUse = args;\n\n\t\tif (!isAlwaysUseMessageFormat() && ObjectUtils.isEmpty(args)) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tString message = resolveCodeWithoutArguments(code, locale);\n\t\t\tif (message != null) {\n\t\t\t\treturn message;\n\t\t\t}\n\t\t}\n\n\t\telse {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\targsToUse = resolveArguments(args, locale);\n\n\t\t\tMessageFormat messageFormat = resolveCode(code, locale);\n\t\t\tif (messageFormat != null) {\n\t\t\t\tsynchronized (messageFormat) {\n\t\t\t\t\treturn messageFormat.format(argsToUse);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tProperties commonMessages = getCommonMessages();\n\t\tif (commonMessages != null) {\n\t\t\tString commonMessage = commonMessages.getProperty(code);\n\t\t\tif (commonMessage != null) {\n\t\t\t\treturn formatMessage(commonMessage, args, locale);\n\t\t\t}\n\t\t}\n\n\t\t\n\t\treturn getMessageFromParent(code, argsToUse, locale);\n\t}", "summary_tokens": ["resolve", "the", "given", "code", "and", "arguments", "as", "message", "in", "the", "given", "locale", "returning", "null", "if", "not", "found"], "project": "spring-framework"}
{"id": 8494, "code": "\tprivate void initMultipartResolver(ApplicationContext context) {\n\t\ttry {\n\t\t\tthis.multipartResolver = context.getBean(MULTIPART_RESOLVER_BEAN_NAME, MultipartResolver.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Detected \" + this.multipartResolver);\n\t\t\t}\n\t\t\telse if (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Detected \" + this.multipartResolver.getClass().getSimpleName());\n\t\t\t}\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\n\t\t\tthis.multipartResolver = null;\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"No MultipartResolver '\" + MULTIPART_RESOLVER_BEAN_NAME + \"' declared\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "multipart", "resolver", "used", "by", "this", "class"], "project": "spring-framework"}
{"id": 5317, "code": "\tprotected void marshalSaxResult(Object graph, SAXResult saxResult) throws XmlMappingException {\n\t\tContentHandler contentHandler = saxResult.getHandler();\n\t\tAssert.notNull(contentHandler, \"ContentHandler not set on SAXResult\");\n\t\tLexicalHandler lexicalHandler = saxResult.getLexicalHandler();\n\t\tmarshalSaxHandlers(graph, contentHandler, lexicalHandler);\n\t}", "summary_tokens": ["template", "method", "for", "handling", "saxresult", "s"], "project": "spring-framework"}
{"id": 3317, "code": "\tpublic static String quote(@Nullable String str) {\n\t\treturn (str != null ? \"'\" + str + \"'\" : null);\n\t}", "summary_tokens": ["quote", "the", "given", "string", "with", "single", "quotes"], "project": "spring-framework"}
{"id": 6243, "code": "\tpublic void setTransactionPhase(TransactionPhase transactionPhase) {\n\t\tthis.transactionPhase = transactionPhase;\n\t}", "summary_tokens": ["specify", "the", "transaction", "phase", "to", "invoke", "the", "listener", "in"], "project": "spring-framework"}
{"id": 4090, "code": "\tprotected void validateParameters(@Nullable Object[] parameters) throws InvalidDataAccessApiUsageException {\n\t\tcheckCompiled();\n\t\tint declaredInParameters = 0;\n\t\tfor (SqlParameter param : this.declaredParameters) {\n\t\t\tif (param.isInputValueProvided()) {\n\t\t\t\tif (!supportsLobParameters() &&\n\t\t\t\t\t\t(param.getSqlType() == Types.BLOB || param.getSqlType() == Types.CLOB)) {\n\t\t\t\t\tthrow new InvalidDataAccessApiUsageException(\n\t\t\t\t\t\t\t\"BLOB or CLOB parameters are not allowed for this kind of operation\");\n\t\t\t\t}\n\t\t\t\tdeclaredInParameters++;\n\t\t\t}\n\t\t}\n\t\tvalidateParameterCount((parameters != null ? parameters.length : 0), declaredInParameters);\n\t}", "summary_tokens": ["validate", "the", "parameters", "passed", "to", "an", "execute", "method", "based", "on", "declared", "parameters"], "project": "spring-framework"}
{"id": 5038, "code": "\tpublic void setBroadcastDestination(@Nullable String destination) {\n\t\tthis.broadcastHandler = (StringUtils.hasText(destination) ?\n\t\t\t\tnew BroadcastHandler(this.messagingTemplate, destination) : null);\n\t}", "summary_tokens": ["set", "a", "destination", "to", "broadcast", "messages", "to", "that", "remain", "unresolved", "because", "the", "user", "is", "not", "connected"], "project": "spring-framework"}
{"id": 736, "code": "\tpublic String getBeanName() {\n\t\treturn this.beanName.get();\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "bean"], "project": "spring-framework"}
{"id": 3083, "code": "\tpublic final Class<?> getTargetType() {\n\t\treturn this.targetType;\n\t}", "summary_tokens": ["return", "the", "type", "that", "this", "instance", "is", "using", "to", "filter", "candidates"], "project": "spring-framework"}
{"id": 9925, "code": "\tprivate boolean validatePath(ServerHttpRequest request) {\n\t\tString path = request.getURI().getPath();\n\t\tint index = path.lastIndexOf('/') + 1;\n\t\treturn (path.indexOf(';', index) == -1);\n\t}", "summary_tokens": ["ensure", "the", "path", "does", "not", "contain", "a", "file", "extension", "either", "in", "the", "filename", "e"], "project": "spring-framework"}
{"id": 8672, "code": "\tpublic UrlPathHelper mvcUrlPathHelper() {\n\t\treturn getPathMatchConfigurer().getUrlPathHelperOrDefault();\n\t}", "summary_tokens": ["return", "a", "global", "url", "path", "helper", "instance", "which", "is", "used", "to", "resolve", "the", "request", "mapping", "path", "for", "an", "application"], "project": "spring-framework"}
{"id": 8737, "code": "\tstatic <T extends ServerResponse> HandlerFilterFunction<T, T>\n\tofRequestProcessor(Function<ServerRequest, ServerRequest> requestProcessor) {\n\n\t\tAssert.notNull(requestProcessor, \"Function must not be null\");\n\t\treturn (request, next) -> next.handle(requestProcessor.apply(request));\n\t}", "summary_tokens": ["adapt", "the", "given", "request", "processor", "function", "to", "a", "filter", "function", "that", "only", "operates", "on", "the", "server", "request"], "project": "spring-framework"}
{"id": 3768, "code": "\tpublic void setTableName(@Nullable String tableName) {\n\t\tthis.tableName = tableName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "table", "for", "this", "context"], "project": "spring-framework"}
{"id": 5451, "code": "\tpublic final OutputStream getTargetStream() {\n\t\treturn this.targetStream;\n\t}", "summary_tokens": ["return", "the", "underlying", "target", "stream", "never", "null"], "project": "spring-framework"}
{"id": 8459, "code": "\tpublic void setHandlePing(boolean handlePing) {\n\t\tthis.handlePing = handlePing;\n\t}", "summary_tokens": ["configure", "whether", "to", "let", "ping", "frames", "through", "to", "be", "handled", "by", "the", "web", "socket", "handler", "given", "to", "the", "execute", "method"], "project": "spring-framework"}
{"id": 1355, "code": "\tpublic void setAllowCircularReferences(boolean allowCircularReferences) {\n\t\tthis.allowCircularReferences = allowCircularReferences;\n\t}", "summary_tokens": ["set", "whether", "to", "allow", "circular", "references", "between", "beans", "and", "automatically", "try", "to", "resolve", "them"], "project": "spring-framework"}
{"id": 512, "code": "\tpublic void setTrimValues(boolean trimValues) {\n\t\tthis.trimValues = trimValues;\n\t}", "summary_tokens": ["specify", "whether", "to", "trim", "resolved", "values", "before", "applying", "them", "removing", "superfluous", "whitespace", "from", "the", "beginning", "and", "end"], "project": "spring-framework"}
{"id": 7690, "code": "\tprotected boolean hasForwardedHeaders(ServerHttpRequest request) {\n\t\tHttpHeaders headers = request.getHeaders();\n\t\tfor (String headerName : FORWARDED_HEADER_NAMES) {\n\t\t\tif (headers.containsKey(headerName)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["whether", "the", "request", "has", "any", "forwarded", "headers"], "project": "spring-framework"}
{"id": 7933, "code": "\tpublic void setExpires(@Nullable ZonedDateTime expires) {\n\t\tthis.expires = expires;\n\t}", "summary_tokens": ["set", "the", "expires", "attribute", "for", "this", "cookie"], "project": "spring-framework"}
{"id": 8549, "code": "\tpublic ModelAndView addObject(Object attributeValue) {\n\t\tgetModelMap().addAttribute(attributeValue);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "an", "attribute", "to", "the", "model", "using", "parameter", "name", "generation"], "project": "spring-framework"}
{"id": 5021, "code": "\tpublic String getReceiptId() {\n\t\treturn getFirst(RECEIPT_ID);\n\t}", "summary_tokens": ["get", "the", "receipt", "header"], "project": "spring-framework"}
{"id": 6452, "code": "\tprivate void doResumeSynchronization(List<TransactionSynchronization> suspendedSynchronizations) {\n\t\tTransactionSynchronizationManager.initSynchronization();\n\t\tfor (TransactionSynchronization synchronization : suspendedSynchronizations) {\n\t\t\tsynchronization.resume();\n\t\t\tTransactionSynchronizationManager.registerSynchronization(synchronization);\n\t\t}\n\t}", "summary_tokens": ["reactivate", "transaction", "synchronization", "for", "the", "current", "thread", "and", "resume", "all", "given", "synchronizations"], "project": "spring-framework"}
{"id": 3026, "code": "\tpublic boolean isErrorEnabled() {\n\t\treturn this.log.isErrorEnabled();\n\t}", "summary_tokens": ["is", "error", "logging", "currently", "enabled"], "project": "spring-framework"}
{"id": 41, "code": "\tprotected boolean isEligibleAspectBean(String beanName) {\n\t\tif (this.includePatterns == null) {\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\tfor (Pattern pattern : this.includePatterns) {\n\t\t\t\tif (pattern.matcher(beanName).matches()) {\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["check", "whether", "the", "given", "aspect", "bean", "is", "eligible", "for", "auto", "proxying"], "project": "spring-framework"}
{"id": 8231, "code": "\tpublic ParamsRequestCondition combine(ParamsRequestCondition other) {\n\t\tif (isEmpty() && other.isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\telse if (other.isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\telse if (isEmpty()) {\n\t\t\treturn other;\n\t\t}\n\t\tSet<ParamExpression> set = new LinkedHashSet<>(this.expressions);\n\t\tset.addAll(other.expressions);\n\t\treturn new ParamsRequestCondition(set);\n\t}", "summary_tokens": ["returns", "a", "new", "instance", "with", "the", "union", "of", "the", "param", "expressions", "from", "this", "and", "the", "other", "instance"], "project": "spring-framework"}
{"id": 2952, "code": "\tpublic String getDescription() {\n\t\treturn \"file [\" + (this.file != null ? this.file.getAbsolutePath() : this.filePath.toAbsolutePath()) + \"]\";\n\t}", "summary_tokens": ["this", "implementation", "returns", "a", "description", "that", "includes", "the", "absolute", "path", "of", "the", "file"], "project": "spring-framework"}
{"id": 819, "code": "\tpublic BeanDefinition parse(Element element, ParserContext parserContext) {\n\t\tBeanDefinitionParser parser = findParserForElement(element, parserContext);\n\t\treturn (parser != null ? parser.parse(element, parserContext) : null);\n\t}", "summary_tokens": ["parses", "the", "supplied", "element", "by", "delegating", "to", "the", "bean", "definition", "parser", "that", "is", "registered", "for", "that", "element"], "project": "spring-framework"}
{"id": 2977, "code": "\tpublic String getFilename() {\n\t\treturn this.path.getFileName().toString();\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "name", "of", "the", "file"], "project": "spring-framework"}
{"id": 2631, "code": "public void zero_or_null(Type type) {\n    if (TypeUtils.isPrimitive(type)) {\n        switch (type.getSort()) {\n        case Type.DOUBLE:\n            push(0d);\n            break;\n        case Type.LONG:\n            push(0L);\n            break;\n        case Type.FLOAT:\n            push(0f);\n            break;\n        case Type.VOID:\n            aconst_null();\n        default:\n            push(0);\n        }\n    } else {\n        aconst_null();\n    }\n}", "summary_tokens": ["pushes", "a", "zero", "onto", "the", "stack", "if", "the", "argument", "is", "a", "primitive", "class", "or", "a", "null", "otherwise"], "project": "spring-framework"}
{"id": 2718, "code": "\tpublic static Throwable getMostSpecificCause(Throwable original) {\n\t\tThrowable rootCause = getRootCause(original);\n\t\treturn (rootCause != null ? rootCause : original);\n\t}", "summary_tokens": ["retrieve", "the", "most", "specific", "cause", "of", "the", "given", "exception", "that", "is", "either", "the", "innermost", "cause", "root", "cause", "or", "the", "exception", "itself"], "project": "spring-framework"}
{"id": 2710, "code": "\tpublic static boolean isKotlinType(Class<?> clazz) {\n\t\treturn (kotlinMetadata != null && clazz.getDeclaredAnnotation(kotlinMetadata) != null);\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "class", "is", "a", "kotlin", "type", "with", "kotlin", "metadata", "present", "on", "it"], "project": "spring-framework"}
{"id": 4071, "code": "\tpublic void setQueryTimeout(int queryTimeout) {\n\t\tthis.jdbcTemplate.setQueryTimeout(queryTimeout);\n\t}", "summary_tokens": ["set", "the", "query", "timeout", "for", "statements", "that", "this", "rdbms", "operation", "executes"], "project": "spring-framework"}
{"id": 7014, "code": "\tpublic void setApplicationContext(ApplicationContext applicationContext) {\n\t\tthis.builder.applicationContext(applicationContext);\n\t}", "summary_tokens": ["set", "the", "builder", "application", "context", "in", "order", "to", "autowire", "jackson", "handlers", "json", "serializer", "json", "deserializer", "key", "deserializer", "type", "resolver", "builder", "and", "type", "id", "resolver"], "project": "spring-framework"}
{"id": 4807, "code": "\tpublic void setDefaultDataMimeType(@Nullable MimeType mimeType) {\n\t\tthis.defaultDataMimeType = mimeType;\n\t}", "summary_tokens": ["configure", "the", "default", "content", "type", "to", "use", "for", "data", "payloads", "if", "the", "setup", "frame", "did", "not", "specify", "one"], "project": "spring-framework"}
{"id": 3080, "code": "\tprotected Boolean matchSuperClass(String superClassName) {\n\t\treturn null;\n\t}", "summary_tokens": ["override", "this", "to", "match", "on", "supertype", "name"], "project": "spring-framework"}
{"id": 3044, "code": "\tpublic Object deserialize(InputStream inputStream) throws IOException {\n\t\tObjectInputStream objectInputStream = new ConfigurableObjectInputStream(inputStream, this.classLoader);\n\t\ttry {\n\t\t\treturn objectInputStream.readObject();\n\t\t}\n\t\tcatch (ClassNotFoundException ex) {\n\t\t\tthrow new IOException(\"Failed to deserialize object type\", ex);\n\t\t}\n\t}", "summary_tokens": ["read", "from", "the", "supplied", "input", "stream", "and", "deserialize", "the", "contents", "into", "an", "object"], "project": "spring-framework"}
{"id": 3193, "code": "\tpublic void setConcurrencyLimit(int concurrencyLimit) {\n\t\tthis.concurrencyLimit = concurrencyLimit;\n\t}", "summary_tokens": ["set", "the", "maximum", "number", "of", "concurrent", "access", "attempts", "allowed"], "project": "spring-framework"}
{"id": 5225, "code": "\tpublic void setMappingResources(String... mappingResources) {\n\t\tthis.internalPersistenceUnitManager.setMappingResources(mappingResources);\n\t}", "summary_tokens": ["specify", "one", "or", "more", "mapping", "resources", "equivalent", "to", "mapping", "file", "entries", "in", "persistence"], "project": "spring-framework"}
{"id": 807, "code": "\tpublic String getLazyInit() {\n\t\treturn this.lazyInit;\n\t}", "summary_tokens": ["return", "the", "default", "lazy", "init", "flag", "for", "the", "document", "that", "s", "currently", "parsed"], "project": "spring-framework"}
{"id": 866, "code": "\tpublic String getAsText() {\n\t\treturn null;\n\t}", "summary_tokens": ["this", "implementation", "returns", "null", "to", "indicate", "that", "there", "is", "no", "appropriate", "text", "representation"], "project": "spring-framework"}
{"id": 3647, "code": "\tpublic static LogFactory getFactory() {\n\t\treturn new LogFactory() {};\n\t}", "summary_tokens": ["this", "method", "only", "exists", "for", "compatibility", "with", "unusual", "commons", "logging", "api", "usage", "like", "e"], "project": "spring-framework"}
{"id": 2649, "code": "\tpublic void setInterceptDuringConstruction(boolean interceptDuringConstruction) {\n\t\tthis.interceptDuringConstruction = interceptDuringConstruction;\n\t}", "summary_tokens": ["set", "whether", "methods", "called", "from", "within", "the", "proxy", "s", "constructer", "will", "be", "intercepted"], "project": "spring-framework"}
{"id": 451, "code": "\tprotected BeanFactory getBeanFactory() {\n\t\treturn this.beanFactory;\n\t}", "summary_tokens": ["return", "the", "bean", "factory", "that", "this", "bean", "runs", "in"], "project": "spring-framework"}
{"id": 2112, "code": "\tvoid postProcessorIntrospectsInheritedDefinitionsCorrectly() {\n\t\tbeanFactory.registerBeanDefinition(\"config\", new RootBeanDefinition(SingletonBeanConfig.class));\n\t\tbeanFactory.registerBeanDefinition(\"parent\", new RootBeanDefinition(TestBean.class));\n\t\tbeanFactory.registerBeanDefinition(\"child\", new ChildBeanDefinition(\"parent\"));\n\t\tConfigurationClassPostProcessor pp = new ConfigurationClassPostProcessor();\n\t\tpp.postProcessBeanFactory(beanFactory);\n\t\tFoo foo = beanFactory.getBean(\"foo\", Foo.class);\n\t\tBar bar = beanFactory.getBean(\"bar\", Bar.class);\n\t\tassertThat(bar.foo).isSameAs(foo);\n\t}", "summary_tokens": ["tests", "whether", "a", "bean", "definition", "without", "a", "specified", "bean", "class", "is", "handled", "correctly"], "project": "spring-framework"}
{"id": 6871, "code": "\tdefault Mono<Void> transferTo(File dest) {\n\t\treturn transferTo(dest.toPath());\n\t}", "summary_tokens": ["convenience", "method", "to", "copy", "the", "content", "of", "the", "file", "in", "this", "part", "to", "the", "given", "destination", "file"], "project": "spring-framework"}
{"id": 1958, "code": "\tpublic Class<?> getFieldType(@Nullable String field) {\n\t\treturn (getTarget() != null ? getPropertyAccessor().getPropertyType(fixedField(field)) :\n\t\t\t\tsuper.getFieldType(field));\n\t}", "summary_tokens": ["determines", "the", "field", "type", "from", "the", "property", "type"], "project": "spring-framework"}
{"id": 5617, "code": "\tprotected Statement withPotentialTimeout(FrameworkMethod frameworkMethod, Object testInstance, Statement next) {\n\t\tStatement statement = null;\n\t\tlong springTimeout = getSpringTimeout(frameworkMethod);\n\t\tlong junitTimeout = getJUnitTimeout(frameworkMethod);\n\t\tif (springTimeout > 0 && junitTimeout > 0) {\n\t\t\tString msg = String.format(\"Test method [%s] has been configured with Spring's @Timed(millis=%s) and \" +\n\t\t\t\t\t\t\t\"JUnit's @Test(timeout=%s) annotations, but only one declaration of a 'timeout' is \" +\n\t\t\t\t\t\t\t\"permitted per test method.\", frameworkMethod.getMethod(), springTimeout, junitTimeout);\n\t\t\tlogger.error(msg);\n\t\t\tthrow new IllegalStateException(msg);\n\t\t}\n\t\telse if (springTimeout > 0) {\n\t\t\tstatement = new SpringFailOnTimeout(next, springTimeout);\n\t\t}\n\t\telse if (junitTimeout > 0) {\n\t\t\tstatement = FailOnTimeout.builder().withTimeout(junitTimeout, TimeUnit.MILLISECONDS).build(next);\n\t\t}\n\t\telse {\n\t\t\tstatement = next;\n\t\t}\n\n\t\treturn statement;\n\t}", "summary_tokens": ["perform", "the", "same", "logic", "as", "block", "junit", "0", "class", "runner", "with", "potential", "timeout", "framework", "method", "object", "statement", "but", "with", "additional", "support", "for", "spring", "s", "annotation"], "project": "spring-framework"}
{"id": 5622, "code": "\tprotected Statement withBefores(FrameworkMethod frameworkMethod, Object testInstance, Statement statement) {\n\t\tStatement junitBefores = super.withBefores(frameworkMethod, testInstance, statement);\n\t\treturn new RunBeforeTestMethodCallbacks(junitBefores, testInstance, frameworkMethod.getMethod(), getTestContextManager());\n\t}", "summary_tokens": ["wrap", "the", "statement", "returned", "by", "the", "parent", "implementation", "with", "a", "run", "before", "test", "method", "callbacks", "statement", "thus", "preserving", "the", "default", "functionality", "while", "adding", "support", "for", "the", "spring", "test", "context", "framework"], "project": "spring-framework"}
{"id": 1085, "code": "\tpublic void setJobDetails(JobDetail... jobDetails) {\n\t\t\n\t\t\n\t\tthis.jobDetails = new ArrayList<>(Arrays.asList(jobDetails));\n\t}", "summary_tokens": ["register", "a", "list", "of", "job", "detail", "objects", "with", "the", "scheduler", "that", "this", "factory", "bean", "creates", "to", "be", "referenced", "by", "triggers"], "project": "spring-framework"}
{"id": 5085, "code": "\tpublic boolean containsNativeHeader(String headerName) {\n\t\tMap<String, List<String>> map = getNativeHeaders();\n\t\treturn (map != null && map.containsKey(headerName));\n\t}", "summary_tokens": ["whether", "the", "native", "header", "map", "contains", "the", "give", "header", "name"], "project": "spring-framework"}
{"id": 106, "code": "\tpublic void setProxyClassLoader(@Nullable ClassLoader classLoader) {\n\t\tthis.proxyClassLoader = classLoader;\n\t\tthis.classLoaderConfigured = (classLoader != null);\n\t}", "summary_tokens": ["set", "the", "class", "loader", "to", "generate", "the", "proxy", "class", "in"], "project": "spring-framework"}
{"id": 1350, "code": "\tprotected String getMessageFromParent(String code, @Nullable Object[] args, Locale locale) {\n\t\tMessageSource parent = getParentMessageSource();\n\t\tif (parent != null) {\n\t\t\tif (parent instanceof AbstractMessageSource) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\treturn ((AbstractMessageSource) parent).getMessageInternal(code, args, locale);\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\treturn parent.getMessage(code, args, null, locale);\n\t\t\t}\n\t\t}\n\t\t\n\t\treturn null;\n\t}", "summary_tokens": ["try", "to", "retrieve", "the", "given", "message", "from", "the", "parent", "message", "source", "if", "any"], "project": "spring-framework"}
{"id": 1288, "code": "\tprivate boolean indexSupportsIncludeFilter(TypeFilter filter) {\n\t\tif (filter instanceof AnnotationTypeFilter) {\n\t\t\tClass<? extends Annotation> annotation = ((AnnotationTypeFilter) filter).getAnnotationType();\n\t\t\treturn (AnnotationUtils.isAnnotationDeclaredLocally(Indexed.class, annotation) ||\n\t\t\t\t\tannotation.getName().startsWith(\"javax.\"));\n\t\t}\n\t\tif (filter instanceof AssignableTypeFilter) {\n\t\t\tClass<?> target = ((AssignableTypeFilter) filter).getTargetType();\n\t\t\treturn AnnotationUtils.isAnnotationDeclaredLocally(Indexed.class, target);\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "if", "the", "specified", "include", "type", "filter", "is", "supported", "by", "the", "index"], "project": "spring-framework"}
{"id": 9415, "code": "\tprotected String getAutocomplete() {\n\t\treturn this.autocomplete;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "autocomplete", "attribute"], "project": "spring-framework"}
{"id": 5748, "code": "\tpublic String toString() {\n\t\treturn new ToStringCreator(this)\n\t\t\t\t.append(\"testClass\", getTestClass())\n\t\t\t\t.append(\"locations\", ObjectUtils.nullSafeToString(getLocations()))\n\t\t\t\t.append(\"classes\", ObjectUtils.nullSafeToString(getClasses()))\n\t\t\t\t.append(\"contextInitializerClasses\", ObjectUtils.nullSafeToString(getContextInitializerClasses()))\n\t\t\t\t.append(\"activeProfiles\", ObjectUtils.nullSafeToString(getActiveProfiles()))\n\t\t\t\t.append(\"propertySourceLocations\", ObjectUtils.nullSafeToString(getPropertySourceLocations()))\n\t\t\t\t.append(\"propertySourceProperties\", ObjectUtils.nullSafeToString(getPropertySourceProperties()))\n\t\t\t\t.append(\"contextCustomizers\", getContextCustomizers())\n\t\t\t\t.append(\"resourceBasePath\", getResourceBasePath())\n\t\t\t\t.append(\"contextLoader\", nullSafeClassName(getContextLoader()))\n\t\t\t\t.append(\"parent\", getParent())\n\t\t\t\t.toString();\n\t}", "summary_tokens": ["provide", "a", "string", "representation", "of", "the", "get", "test", "class", "test", "class", "get", "locations", "locations", "get", "classes", "annotated", "classes", "get", "context", "initializer", "classes", "context", "initializer", "classes", "get", "active", "profiles", "active", "profiles", "get", "property", "source", "locations", "property", "source", "locations", "get", "property", "source", "properties", "property", "source", "properties", "get", "context", "customizers", "context", "customizers", "get", "resource", "base", "path", "resource", "base", "path", "the", "name", "of", "the", "get", "context", "loader", "context", "loader", "and", "the", "get", "parent", "parent", "configuration"], "project": "spring-framework"}
{"id": 6102, "code": "\tpublic ResultMatcher isUpgradeRequired() {\n\t\treturn matcher(HttpStatus.UPGRADE_REQUIRED);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 4230, "code": "\tprotected StringBuilder getEndpointDescription() {\n\t\tStringBuilder result = new StringBuilder();\n\t\treturn result.append(getClass().getSimpleName()).append('[').append(this.id).append(\"] destination=\").\n\t\t\t\tappend(this.destination).append(\"' | subscription='\").append(this.subscription).\n\t\t\t\tappend(\" | selector='\").append(this.selector).append('\\'');\n\t}", "summary_tokens": ["return", "a", "description", "for", "this", "endpoint"], "project": "spring-framework"}
{"id": 6487, "code": "\tpublic final void setPropagationBehaviorName(String constantName) throws IllegalArgumentException {\n\t\tif (!constantName.startsWith(PREFIX_PROPAGATION)) {\n\t\t\tthrow new IllegalArgumentException(\"Only propagation constants allowed\");\n\t\t}\n\t\tsetPropagationBehavior(constants.asNumber(constantName).intValue());\n\t}", "summary_tokens": ["set", "the", "propagation", "behavior", "by", "the", "name", "of", "the", "corresponding", "constant", "in", "transaction", "definition", "e"], "project": "spring-framework"}
{"id": 2260, "code": "\tpublic ProxyHints registerJdkProxy(Class<?>... proxiedInterfaces) {\n\t\treturn registerJdkProxy(jdkProxyHint ->\n\t\t\t\tjdkProxyHint.proxiedInterfaces(proxiedInterfaces));\n\t}", "summary_tokens": ["register", "that", "a", "jdk", "proxy", "implementing", "the", "specified", "interfaces", "is", "required"], "project": "spring-framework"}
{"id": 2388, "code": "public void visitPermittedSubclass(final String permittedSubclass) {\n  if (api < Opcodes.ASM9) {\n    throw new UnsupportedOperationException(\"PermittedSubclasses requires ASM9\");\n  }\n  if (cv != null) {\n    cv.visitPermittedSubclass(permittedSubclass);\n  }\n}", "summary_tokens": ["visits", "a", "permitted", "subclasses"], "project": "spring-framework"}
{"id": 4685, "code": "\tprivate Object handleNullValue(String name, @Nullable Object value, Class<?> paramType) {\n\t\tif (value == null) {\n\t\t\tif (Boolean.TYPE.equals(paramType)) {\n\t\t\t\treturn Boolean.FALSE;\n\t\t\t}\n\t\t\telse if (paramType.isPrimitive()) {\n\t\t\t\tthrow new IllegalStateException(\"Optional \" + paramType + \" parameter '\" + name +\n\t\t\t\t\t\t\"' is present but cannot be translated into a null value due to being \" +\n\t\t\t\t\t\t\"declared as a primitive type. Consider declaring it as object wrapper \" +\n\t\t\t\t\t\t\"for the corresponding primitive type.\");\n\t\t\t}\n\t\t}\n\t\treturn value;\n\t}", "summary_tokens": ["one", "last", "chance", "to", "handle", "a", "possible", "null", "value"], "project": "spring-framework"}
{"id": 547, "code": "\tpublic void setServiceLocatorExceptionClass(Class<? extends Exception> serviceLocatorExceptionClass) {\n\t\tthis.serviceLocatorExceptionConstructor =\n\t\t\t\tdetermineServiceLocatorExceptionConstructor(serviceLocatorExceptionClass);\n\t}", "summary_tokens": ["set", "the", "exception", "class", "that", "the", "service", "locator", "should", "throw", "if", "service", "lookup", "failed"], "project": "spring-framework"}
{"id": 4893, "code": "\tpublic StompBrokerRelayRegistration enableStompBrokerRelay(String... destinationPrefixes) {\n\t\tthis.brokerRelayRegistration = new StompBrokerRelayRegistration(\n\t\t\t\tthis.clientInboundChannel, this.clientOutboundChannel, destinationPrefixes);\n\t\treturn this.brokerRelayRegistration;\n\t}", "summary_tokens": ["enable", "a", "stomp", "broker", "relay", "and", "configure", "the", "destination", "prefixes", "supported", "by", "the", "message", "broker"], "project": "spring-framework"}
{"id": 9431, "code": "\tprotected boolean isDisabled() {\n\t\treturn this.disabled;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "disabled", "attribute"], "project": "spring-framework"}
{"id": 8736, "code": "\tdefault HandlerFunction<R> apply(HandlerFunction<T> handler) {\n\t\tAssert.notNull(handler, \"HandlerFunction must not be null\");\n\t\treturn request -> this.filter(request, handler);\n\t}", "summary_tokens": ["apply", "this", "filter", "to", "the", "given", "handler", "function", "resulting", "in", "a", "filtered", "handler", "function"], "project": "spring-framework"}
{"id": 6539, "code": "\tdefault void afterCompletion(int status) {\n\t}", "summary_tokens": ["invoked", "after", "transaction", "commit", "rollback"], "project": "spring-framework"}
{"id": 8301, "code": "\tpublic Mono<Map<String, Object>> getValuesToBind(WebExchangeDataBinder binder, ServerWebExchange exchange) {\n\t\treturn binder.getValuesToBind(exchange);\n\t}", "summary_tokens": ["protected", "method", "to", "obtain", "the", "values", "for", "data", "binding"], "project": "spring-framework"}
{"id": 7937, "code": "\tpublic static MockCookie parse(String setCookieHeader) {\n\t\tAssert.notNull(setCookieHeader, \"Set-Cookie header must not be null\");\n\t\tString[] cookieParts = setCookieHeader.split(\"\\\\s*=\\\\s*\", 2);\n\t\tAssert.isTrue(cookieParts.length == 2, () -> \"Invalid Set-Cookie header '\" + setCookieHeader + \"'\");\n\n\t\tString name = cookieParts[0];\n\t\tString[] valueAndAttributes = cookieParts[1].split(\"\\\\s*;\\\\s*\", 2);\n\t\tString value = valueAndAttributes[0];\n\t\tString[] attributes =\n\t\t\t\t(valueAndAttributes.length > 1 ? valueAndAttributes[1].split(\"\\\\s*;\\\\s*\") : new String[0]);\n\n\t\tMockCookie cookie = new MockCookie(name, value);\n\t\tfor (String attribute : attributes) {\n\t\t\tif (StringUtils.startsWithIgnoreCase(attribute, \"Domain\")) {\n\t\t\t\tcookie.setDomain(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Max-Age\")) {\n\t\t\t\tcookie.setMaxAge(Integer.parseInt(extractAttributeValue(attribute, setCookieHeader)));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Expires\")) {\n\t\t\t\ttry {\n\t\t\t\t\tcookie.setExpires(ZonedDateTime.parse(extractAttributeValue(attribute, setCookieHeader),\n\t\t\t\t\t\t\tDateTimeFormatter.RFC_1123_DATE_TIME));\n\t\t\t\t}\n\t\t\t\tcatch (DateTimeException ex) {\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Path\")) {\n\t\t\t\tcookie.setPath(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Secure\")) {\n\t\t\t\tcookie.setSecure(true);\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"HttpOnly\")) {\n\t\t\t\tcookie.setHttpOnly(true);\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"SameSite\")) {\n\t\t\t\tcookie.setSameSite(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t\telse if (StringUtils.startsWithIgnoreCase(attribute, \"Comment\")) {\n\t\t\t\tcookie.setComment(extractAttributeValue(attribute, setCookieHeader));\n\t\t\t}\n\t\t}\n\t\treturn cookie;\n\t}", "summary_tokens": ["factory", "method", "that", "parses", "the", "value", "of", "the", "supplied", "set", "cookie", "header"], "project": "spring-framework"}
{"id": 6017, "code": "\tpublic static ResultMatcher redirectedUrl(String expectedUrl) {\n\t\treturn result -> assertEquals(\"Redirected URL\", expectedUrl, result.getResponse().getRedirectedUrl());\n\t}", "summary_tokens": ["asserts", "the", "request", "was", "redirected", "to", "the", "given", "url"], "project": "spring-framework"}
{"id": 6751, "code": "\tpublic void setReadTimeout(int timeout) {\n\t\tAssert.isTrue(timeout >= 0, \"Timeout must be a non-negative value\");\n\t\tthis.requestConfig = requestConfigBuilder().setSocketTimeout(timeout).build();\n\t}", "summary_tokens": ["set", "the", "socket", "read", "timeout", "for", "the", "underlying", "request", "config"], "project": "spring-framework"}
{"id": 2709, "code": "\tpublic static boolean isKotlinReflectPresent() {\n\t\treturn kotlinReflectPresent;\n\t}", "summary_tokens": ["determine", "whether", "kotlin", "reflection", "is", "present"], "project": "spring-framework"}
{"id": 3778, "code": "\tpublic List<String> getTableColumns() {\n\t\treturn this.tableColumns;\n\t}", "summary_tokens": ["get", "a", "list", "of", "the", "table", "column", "names"], "project": "spring-framework"}
{"id": 1656, "code": "\tpublic void setNotificationTypes(@Nullable String... notificationTypes) {\n\t\tthis.notificationTypes = notificationTypes;\n\t}", "summary_tokens": ["set", "a", "list", "of", "notification", "types"], "project": "spring-framework"}
{"id": 8196, "code": "\tpublic List<String> getContentCodings() {\n\t\treturn Collections.unmodifiableList(this.contentCodings);\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "with", "the", "supported", "content", "codings"], "project": "spring-framework"}
{"id": 1942, "code": "\tpublic ModelMap addAllAttributes(@Nullable Map<String, ?> attributes) {\n\t\tif (attributes != null) {\n\t\t\tputAll(attributes);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["copy", "all", "attributes", "in", "the", "supplied", "map", "into", "this", "map"], "project": "spring-framework"}
{"id": 3181, "code": "\tpublic static boolean containsAny(Collection<?> source, Collection<?> candidates) {\n\t\treturn findFirstMatch(source, candidates) != null;\n\t}", "summary_tokens": ["return", "true", "if", "any", "element", "in", "candidates", "is", "contained", "in", "source", "otherwise", "returns", "false"], "project": "spring-framework"}
{"id": 4531, "code": "\tpublic void setMessageConverter(@Nullable MessageConverter messageConverter) {\n\t\tthis.messageConverter = messageConverter;\n\t}", "summary_tokens": ["set", "the", "message", "converter", "strategy", "for", "converting", "jms", "messages"], "project": "spring-framework"}
{"id": 2136, "code": "\tpublic void testWithOnlyGetter() throws Exception {\n\t\tModelMBeanInfo info = getMBeanInfoFromAssembler();\n\t\tModelMBeanAttributeInfo attr = info.getAttribute(\"Superman\");\n\t\tassertThat(attr).as(\"Attribute should not be null\").isNotNull();\n\t}", "summary_tokens": ["tests", "the", "situation", "where", "the", "property", "only", "has", "a", "setter"], "project": "spring-framework"}
{"id": 9369, "code": "\tprotected String getModelAttribute() {\n\t\treturn this.modelAttribute;\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "form", "attribute", "in", "the", "model"], "project": "spring-framework"}
{"id": 1021, "code": "\tpublic synchronized Session getSession() {\n\t\tif (this.session == null) {\n\t\t\tthis.session = Session.getInstance(this.javaMailProperties);\n\t\t}\n\t\treturn this.session;\n\t}", "summary_tokens": ["return", "the", "java", "mail", "session", "lazily", "initializing", "it", "if", "it", "hasn", "t", "been", "specified", "explicitly"], "project": "spring-framework"}
{"id": 4344, "code": "\tpublic <T> T execute(SessionCallback<T> action, boolean startConnection) throws JmsException {\n\t\tAssert.notNull(action, \"Callback object must not be null\");\n\t\tConnection conToClose = null;\n\t\tSession sessionToClose = null;\n\t\ttry {\n\t\t\tSession sessionToUse = ConnectionFactoryUtils.doGetTransactionalSession(\n\t\t\t\t\tobtainConnectionFactory(), this.transactionalResourceFactory, startConnection);\n\t\t\tif (sessionToUse == null) {\n\t\t\t\tconToClose = createConnection();\n\t\t\t\tsessionToClose = createSession(conToClose);\n\t\t\t\tif (startConnection) {\n\t\t\t\t\tconToClose.start();\n\t\t\t\t}\n\t\t\t\tsessionToUse = sessionToClose;\n\t\t\t}\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Executing callback on JMS Session: \" + sessionToUse);\n\t\t\t}\n\t\t\treturn action.doInJms(sessionToUse);\n\t\t}\n\t\tcatch (JMSException ex) {\n\t\t\tthrow convertJmsAccessException(ex);\n\t\t}\n\t\tfinally {\n\t\t\tJmsUtils.closeSession(sessionToClose);\n\t\t\tConnectionFactoryUtils.releaseConnection(conToClose, getConnectionFactory(), startConnection);\n\t\t}\n\t}", "summary_tokens": ["execute", "the", "action", "specified", "by", "the", "given", "action", "object", "within", "a", "jms", "session"], "project": "spring-framework"}
{"id": 6572, "code": "\tpublic PlatformTransactionManager getTransactionManager() {\n\t\treturn this.transactionManager;\n\t}", "summary_tokens": ["return", "the", "transaction", "management", "strategy", "to", "be", "used"], "project": "spring-framework"}
{"id": 134, "code": "\tprotected TargetSource getCustomTargetSource(Class<?> beanClass, String beanName) {\n\t\t\n\t\tif (this.customTargetSourceCreators != null &&\n\t\t\t\tthis.beanFactory != null && this.beanFactory.containsBean(beanName)) {\n\t\t\tfor (TargetSourceCreator tsc : this.customTargetSourceCreators) {\n\t\t\t\tTargetSource ts = tsc.getTargetSource(beanClass, beanName);\n\t\t\t\tif (ts != null) {\n\t\t\t\t\t\n\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\tlogger.trace(\"TargetSourceCreator [\" + tsc +\n\t\t\t\t\t\t\t\t\"] found custom TargetSource for bean with name '\" + beanName + \"'\");\n\t\t\t\t\t}\n\t\t\t\t\treturn ts;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t\n\t\treturn null;\n\t}", "summary_tokens": ["create", "a", "target", "source", "for", "bean", "instances"], "project": "spring-framework"}
{"id": 140, "code": "\tprotected void customizeProxyFactory(ProxyFactory proxyFactory) {\n\t}", "summary_tokens": ["subclasses", "may", "choose", "to", "implement", "this", "for", "example", "to", "change", "the", "interfaces", "exposed"], "project": "spring-framework"}
{"id": 3108, "code": "\tpublic static void isAssignable(Class<?> superType, Class<?> subType) {\n\t\tisAssignable(superType, subType, \"\");\n\t}", "summary_tokens": ["assert", "that", "super", "type"], "project": "spring-framework"}
{"id": 5344, "code": "\tprivate static int getConnectionSynchronizationOrder(ConnectionFactory connectionFactory) {\n\t\tint order = CONNECTION_SYNCHRONIZATION_ORDER;\n\t\tConnectionFactory current = connectionFactory;\n\t\twhile (current instanceof DelegatingConnectionFactory) {\n\t\t\torder--;\n\t\t\tcurrent = ((DelegatingConnectionFactory) current).getTargetConnectionFactory();\n\t\t}\n\t\treturn order;\n\t}", "summary_tokens": ["determine", "the", "connection", "synchronization", "order", "to", "use", "for", "the", "given", "connection", "factory"], "project": "spring-framework"}
{"id": 2241, "code": "\tpublic String getGeneratedFileContent(Kind kind, String path) throws IOException {\n\t\tInputStreamSource source = getGeneratedFile(kind, path);\n\t\tif (source != null) {\n\t\t\treturn new String(source.getInputStream().readAllBytes(), StandardCharsets.UTF_8);\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "content", "of", "the", "specified", "file"], "project": "spring-framework"}
{"id": 7595, "code": "\tprivate HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) {\n\t\tHandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter);\n\t\tif (result == null) {\n\t\t\tfor (HandlerMethodArgumentResolver resolver : this.argumentResolvers) {\n\t\t\t\tif (resolver.supportsParameter(parameter)) {\n\t\t\t\t\tresult = resolver;\n\t\t\t\t\tthis.argumentResolverCache.put(parameter, result);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["find", "a", "registered", "handler", "method", "argument", "resolver", "that", "supports", "the", "given", "method", "parameter"], "project": "spring-framework"}
{"id": 1620, "code": "\tprotected String getDescription(Object managedBean, String beanKey) {\n\t\tManagedResource mr = obtainAttributeSource().getManagedResource(getClassToExpose(managedBean));\n\t\treturn (mr != null ? mr.getDescription() : \"\");\n\t}", "summary_tokens": ["reads", "managed", "resource", "description", "from", "the", "source", "level", "metadata"], "project": "spring-framework"}
{"id": 9252, "code": "\tprotected final String getPath() throws JspException {\n\t\tString resolvedPath = (String) evaluate(\"path\", this.path);\n\t\treturn (resolvedPath != null ? resolvedPath : \"\");\n\t}", "summary_tokens": ["get", "the", "evaluate", "resolved", "property", "path", "for", "the", "form", "tag", "set", "model", "attribute", "form", "object"], "project": "spring-framework"}
{"id": 5911, "code": "\tpublic WebTestClient.BodyContentSpec isEqualTo(boolean expectedValue) {\n\t\treturn assertWith(() -> this.xpathHelper.assertBoolean(getContent(), getCharset(), expectedValue));\n\t}", "summary_tokens": ["delegates", "to", "xpath", "expectations", "helper", "assert", "boolean", "byte", "string", "boolean"], "project": "spring-framework"}
{"id": 4377, "code": "\tprotected boolean runningAllowed() {\n\t\treturn true;\n\t}", "summary_tokens": ["check", "whether", "this", "container", "s", "listeners", "are", "generally", "allowed", "to", "run"], "project": "spring-framework"}
{"id": 5385, "code": "\tprivate static String readScript(LineNumberReader lineNumberReader, @Nullable String separator) throws IOException {\n\t\tStringBuilder scriptBuilder = new StringBuilder();\n\t\tString currentLine = lineNumberReader.readLine();\n\t\twhile (currentLine != null) {\n\t\t\tif (scriptBuilder.length() > 0) {\n\t\t\t\tscriptBuilder.append('\\n');\n\t\t\t}\n\t\t\tscriptBuilder.append(currentLine);\n\t\t\tcurrentLine = lineNumberReader.readLine();\n\t\t}\n\t\tappendSeparatorToScriptIfNecessary(scriptBuilder, separator);\n\t\treturn scriptBuilder.toString();\n\t}", "summary_tokens": ["read", "a", "script", "from", "the", "provided", "line", "number", "reader", "and", "build", "a", "string", "containing", "the", "lines"], "project": "spring-framework"}
{"id": 3891, "code": "\tpublic final boolean isBatchExhausted(int i) {\n\t\treturn this.exhausted;\n\t}", "summary_tokens": ["this", "implementation", "return", "this", "instance", "s", "current", "exhaustion", "flag"], "project": "spring-framework"}
{"id": 381, "code": "\tpublic Class<?> getActualType() {\n\t\treturn this.actualType;\n\t}", "summary_tokens": ["return", "the", "actual", "type", "of", "the", "instance", "found"], "project": "spring-framework"}
{"id": 8993, "code": "\tpublic boolean isReactiveType(Class<?> type) {\n\t\treturn (this.adapterRegistry.getAdapter(type) != null);\n\t}", "summary_tokens": ["whether", "the", "type", "can", "be", "adapted", "to", "a", "reactive", "streams", "publisher"], "project": "spring-framework"}
{"id": 9663, "code": "\tprotected final void buildFeedEntries(Map<String, Object> model, Feed feed,\n\t\t\tHttpServletRequest request, HttpServletResponse response) throws Exception {\n\n\t\tList<Entry> entries = buildFeedEntries(model, request, response);\n\t\tfeed.setEntries(entries);\n\t}", "summary_tokens": ["invokes", "build", "feed", "entries", "map", "http", "servlet", "request", "http", "servlet", "response", "to", "get", "a", "list", "of", "feed", "entries"], "project": "spring-framework"}
{"id": 2707, "code": "\tpublic static Class<? extends Throwable> findClosestMatch(\n\t\t\tCollection<Class<? extends Throwable>> exceptionTypes, Throwable targetException) {\n\n\t\tAssert.notEmpty(exceptionTypes, \"Exception types must not be empty\");\n\t\tif (exceptionTypes.size() == 1) {\n\t\t\treturn exceptionTypes.iterator().next();\n\t\t}\n\t\tList<Class<? extends Throwable>> handledExceptions = new ArrayList<>(exceptionTypes);\n\t\thandledExceptions.sort(new ExceptionDepthComparator(targetException));\n\t\treturn handledExceptions.get(0);\n\t}", "summary_tokens": ["obtain", "the", "closest", "match", "from", "the", "given", "exception", "types", "for", "the", "given", "target", "exception"], "project": "spring-framework"}
{"id": 8834, "code": "\tpublic final void setAuthorizedRoles(String... authorizedRoles) {\n\t\tthis.authorizedRoles = authorizedRoles;\n\t}", "summary_tokens": ["set", "the", "roles", "that", "this", "interceptor", "should", "treat", "as", "authorized"], "project": "spring-framework"}
{"id": 4547, "code": "\tpublic DestinationResolver getDestinationResolver() {\n\t\treturn this.destinationResolver;\n\t}", "summary_tokens": ["return", "the", "destination", "resolver", "to", "use", "for", "resolving", "destinations", "names"], "project": "spring-framework"}
{"id": 6063, "code": "\tpublic ResultMatcher isAlreadyReported() {\n\t\treturn matcher(HttpStatus.ALREADY_REPORTED);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2815, "code": "\tpublic void setLogger(Log logger) {\n\t\tthis.logger = logger;\n\t}", "summary_tokens": ["set", "an", "alternative", "logger", "to", "use", "than", "the", "one", "based", "on", "the", "class", "name"], "project": "spring-framework"}
{"id": 9784, "code": "\tprotected SockJsServiceRegistration getSockJsServiceRegistration() {\n\t\treturn this.sockJsServiceRegistration;\n\t}", "summary_tokens": ["expose", "the", "sock", "js", "service", "registration", "if", "sock", "js", "is", "enabled", "or", "null", "otherwise", "so", "that", "it", "can", "be", "configured", "with", "a", "task", "scheduler", "if", "the", "application", "did", "not", "provide", "one"], "project": "spring-framework"}
{"id": 2293, "code": "\tpublic MethodHintPredicate onMethod(Class<?> type, String methodName) {\n\t\tAssert.notNull(type, \"'type' should not be null\");\n\t\tAssert.hasText(methodName, \"'methodName' should not be null\");\n\t\treturn new MethodHintPredicate(getMethod(type, methodName));\n\t}", "summary_tokens": ["return", "a", "predicate", "that", "checks", "whether", "a", "reflection", "hint", "is", "registered", "for", "the", "method", "that", "matches", "the", "given", "selector"], "project": "spring-framework"}
{"id": 3299, "code": "\tpublic static boolean isEmpty(@Nullable Object str) {\n\t\treturn (str == null || \"\".equals(str));\n\t}", "summary_tokens": ["check", "whether", "the", "given", "object", "possibly", "a", "string", "is", "empty"], "project": "spring-framework"}
{"id": 5704, "code": "\tboolean isInheritLocations() {\n\t\treturn this.inheritLocations;\n\t}", "summary_tokens": ["get", "the", "inherit", "locations", "flag", "that", "was", "declared", "via"], "project": "spring-framework"}
{"id": 8212, "code": "\tpublic boolean isEmpty() {\n\t\treturn getContent().isEmpty();\n\t}", "summary_tokens": ["indicates", "whether", "this", "condition", "is", "empty", "i"], "project": "spring-framework"}
{"id": 5502, "code": "\tpublic String[] getPropertySourceLocations() {\n\t\treturn this.propertySourceLocations;\n\t}", "summary_tokens": ["get", "the", "merged", "resource", "locations", "for", "test", "property", "sources", "for", "the", "get", "test", "class", "test", "class"], "project": "spring-framework"}
{"id": 7805, "code": "\tprivate static String sanitizeSource(String source) {\n\t\tint level = 0;\n\t\tint lastCharIndex = 0;\n\t\tchar[] chars = new char[source.length()];\n\t\tfor (int i = 0; i < source.length(); i++) {\n\t\t\tchar c = source.charAt(i);\n\t\t\tif (c == '{') {\n\t\t\t\tlevel++;\n\t\t\t}\n\t\t\tif (c == '}') {\n\t\t\t\tlevel--;\n\t\t\t}\n\t\t\tif (level > 1 || (level == 1 && c == '}')) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tchars[lastCharIndex++] = c;\n\t\t}\n\t\treturn new String(chars, 0, lastCharIndex);", "summary_tokens": ["remove", "nested", "such", "as", "in", "uri", "vars", "with", "regular", "expressions"], "project": "spring-framework"}
{"id": 9615, "code": "\tpublic void setRedirectContextRelative(boolean redirectContextRelative) {\n\t\tthis.redirectContextRelative = redirectContextRelative;\n\t}", "summary_tokens": ["set", "whether", "to", "interpret", "a", "given", "redirect", "url", "that", "starts", "with", "a", "slash", "as", "relative", "to", "the", "current", "servlet", "context", "i"], "project": "spring-framework"}
{"id": 7745, "code": "\tpublic HttpMethod getHttpMethod() {\n\t\treturn this.httpMethod;\n\t}", "summary_tokens": ["return", "the", "http", "method", "to", "use", "for", "the", "request"], "project": "spring-framework"}
{"id": 321, "code": "\tprivate boolean supports(Class<?> beanClass) {\n\t\tfor (Method method : beanClass.getMethods()) {\n\t\t\tif (ExtendedBeanInfo.isCandidateWriteMethod(method)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["return", "whether", "the", "given", "bean", "class", "declares", "or", "inherits", "any", "non", "void", "returning", "bean", "property", "or", "indexed", "property", "setter", "methods"], "project": "spring-framework"}
{"id": 9476, "code": "\tpublic static String nextId(String name, PageContext pageContext) {\n\t\tString attributeName = PAGE_CONTEXT_ATTRIBUTE_PREFIX + name;\n\t\tInteger currentCount = (Integer) pageContext.getAttribute(attributeName);\n\t\tcurrentCount = (currentCount != null ? currentCount + 1 : 1);\n\t\tpageContext.setAttribute(attributeName, currentCount);\n\t\treturn (name + currentCount);\n\t}", "summary_tokens": ["get", "the", "next", "unique", "id", "within", "the", "given", "page", "context", "for", "the", "supplied", "name"], "project": "spring-framework"}
{"id": 1776, "code": "\tdefault Date lastCompletionTime() {\n\t\tInstant instant = lastCompletion();\n\t\treturn instant != null ? Date.from(instant) : null;\n\t}", "summary_tokens": ["return", "the", "last", "completion", "time", "of", "the", "task", "or", "null", "if", "not", "scheduled", "before"], "project": "spring-framework"}
{"id": 3253, "code": "\tpublic static String generateMultipartBoundaryString() {\n\t\treturn new String(generateMultipartBoundary(), StandardCharsets.US_ASCII);\n\t}", "summary_tokens": ["generate", "a", "random", "mime", "boundary", "as", "string", "often", "used", "in", "multipart", "mime", "types"], "project": "spring-framework"}
{"id": 7750, "code": "\tpublic MultiValueMap<String, String> getCookies() {\n\t\treturn this.cookies;\n\t}", "summary_tokens": ["return", "the", "cookies", "for", "the", "request", "or", "an", "empty", "map"], "project": "spring-framework"}
{"id": 2153, "code": "\tpublic void bind(String name, Object obj) {\n\t\tif (logger.isInfoEnabled()) {\n\t\t\tlogger.info(\"Static JNDI binding: [\" + this.root + name + \"] = [\" + obj + \"]\");\n\t\t}\n\t\tthis.boundObjects.put(this.root + name, obj);\n\t}", "summary_tokens": ["bind", "the", "given", "object", "to", "the", "given", "name"], "project": "spring-framework"}
{"id": 7602, "code": "\tpublic void setParameterNameDiscoverer(ParameterNameDiscoverer parameterNameDiscoverer) {\n\t\tthis.parameterNameDiscoverer = parameterNameDiscoverer;\n\t}", "summary_tokens": ["set", "the", "parameter", "name", "discoverer", "for", "resolving", "parameter", "names", "when", "needed", "e"], "project": "spring-framework"}
{"id": 407, "code": "\tdefault boolean isPrototype() {\n\t\treturn false;\n\t}", "summary_tokens": ["is", "the", "object", "managed", "by", "this", "factory", "a", "prototype", "that", "is", "will", "get", "object", "always", "return", "an", "independent", "instance", "p", "the", "prototype", "status", "of", "the", "factory", "bean", "itself", "will", "generally", "be", "provided", "by", "the", "owning", "bean", "factory", "usually", "it", "has", "to", "be", "defined", "as", "singleton", "there"], "project": "spring-framework"}
{"id": 3273, "code": "\tpublic PathMatcher getPathMatcher() {\n\t\treturn this.pathMatcher;\n\t}", "summary_tokens": ["return", "the", "underlying", "path", "matcher", "delegate"], "project": "spring-framework"}
{"id": 7507, "code": "\tpublic void setMethodParam(String methodParam) {\n\t\tAssert.hasText(methodParam, \"'methodParam' must not be empty\");\n\t\tthis.methodParam = methodParam;\n\t}", "summary_tokens": ["set", "the", "parameter", "name", "to", "look", "for", "http", "methods"], "project": "spring-framework"}
{"id": 6701, "code": "\tprotected List<String> getETagValuesAsList(String headerName) {\n\t\tList<String> values = get(headerName);\n\t\tif (values != null) {\n\t\t\tList<String> result = new ArrayList<>();\n\t\t\tfor (String value : values) {\n\t\t\t\tif (value != null) {\n\t\t\t\t\tMatcher matcher = ETAG_HEADER_VALUE_PATTERN.matcher(value);\n\t\t\t\t\twhile (matcher.find()) {\n\t\t\t\t\t\tif (\"*\".equals(matcher.group())) {\n\t\t\t\t\t\t\tresult.add(matcher.group());\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tresult.add(matcher.group(1));\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (result.isEmpty()) {\n\t\t\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\t\t\"Could not parse header '\" + headerName + \"' with value '\" + value + \"'\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\treturn Collections.emptyList();\n\t}", "summary_tokens": ["retrieve", "a", "combined", "result", "from", "the", "field", "values", "of", "the", "etag", "header"], "project": "spring-framework"}
{"id": 7518, "code": "\tprotected boolean isEligibleForEtag(HttpServletRequest request, HttpServletResponse response,\n\t\t\tint responseStatusCode, InputStream inputStream) {\n\n\t\tif (!response.isCommitted() &&\n\t\t\t\tresponseStatusCode >= 200 && responseStatusCode < 300 &&\n\t\t\t\tHttpMethod.GET.matches(request.getMethod())) {\n\n\t\t\tString cacheControl = response.getHeader(HttpHeaders.CACHE_CONTROL);\n\t\t\treturn (cacheControl == null || !cacheControl.contains(DIRECTIVE_NO_STORE));\n\t\t}\n\n\t\treturn false;\n\t}", "summary_tokens": ["whether", "an", "etag", "should", "be", "calculated", "for", "the", "given", "request", "and", "response", "exchange"], "project": "spring-framework"}
{"id": 6614, "code": "\tpublic CacheControl staleWhileRevalidate(Duration staleWhileRevalidate) {\n\t\tthis.staleWhileRevalidate = staleWhileRevalidate;\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "stale", "while", "revalidate", "directive"], "project": "spring-framework"}
{"id": 4141, "code": "\tpublic void setTimeout(int timeout) {\n\t\tthis.timeout = timeout;\n\t}", "summary_tokens": ["set", "the", "timeout", "in", "seconds", "after", "which", "a", "fatal", "exception", "will", "be", "thrown"], "project": "spring-framework"}
{"id": 3704, "code": "\tpublic boolean isReturnTypeSupported() {\n\t\treturn (this.sqlReturnType != null);\n\t}", "summary_tokens": ["return", "whether", "this", "parameter", "holds", "a", "custom", "return", "type"], "project": "spring-framework"}
{"id": 1295, "code": "\tpublic boolean isImported() {\n\t\treturn !this.importedBy.isEmpty();\n\t}", "summary_tokens": ["return", "whether", "this", "configuration", "class", "was", "registered", "via", "import", "or", "automatically", "registered", "due", "to", "being", "nested", "within", "another", "configuration", "class"], "project": "spring-framework"}
{"id": 8893, "code": "\tpublic HeadersRequestCondition getMatchingCondition(HttpServletRequest request) {\n\t\tif (CorsUtils.isPreFlightRequest(request)) {\n\t\t\treturn PRE_FLIGHT_MATCH;\n\t\t}\n\t\tfor (HeaderExpression expression : this.expressions) {\n\t\t\tif (!expression.match(request)) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["returns", "this", "instance", "if", "the", "request", "matches", "all", "expressions", "or", "null", "otherwise"], "project": "spring-framework"}
{"id": 5128, "code": "\tpublic void setCacheQueries(boolean cacheQueries) {\n\t\tthis.cacheQueries = cacheQueries;\n\t}", "summary_tokens": ["set", "whether", "to", "cache", "all", "queries", "executed", "by", "this", "template"], "project": "spring-framework"}
{"id": 7378, "code": "\tpublic void setConfigLocation(String configLocation) {\n\t\tthrow new UnsupportedOperationException(\"StaticWebApplicationContext does not support config locations\");\n\t}", "summary_tokens": ["the", "static", "web", "application", "context", "class", "does", "not", "support", "this", "method"], "project": "spring-framework"}
{"id": 3031, "code": "\tpublic void fatal(Throwable cause, Supplier<? extends CharSequence> messageSupplier) {\n\t\tif (this.log.isFatalEnabled()) {\n\t\t\tthis.log.fatal(LogMessage.of(messageSupplier), cause);\n\t\t}\n\t}", "summary_tokens": ["log", "an", "error", "with", "fatal", "log", "level"], "project": "spring-framework"}
{"id": 7980, "code": "\tpublic void fixedResolver(MediaType... mediaTypes) {\n\t\tthis.candidates.add(() -> new FixedContentTypeResolver(Arrays.asList(mediaTypes)));\n\t}", "summary_tokens": ["add", "resolver", "that", "returns", "a", "fixed", "set", "of", "media", "types"], "project": "spring-framework"}
{"id": 2626, "code": "public void load_arg(int index) {\n    load_local(state.argumentTypes[index],\n               state.localOffset + skipArgs(index));\n}", "summary_tokens": ["pushes", "the", "specified", "argument", "of", "the", "current", "method", "onto", "the", "stack"], "project": "spring-framework"}
{"id": 1207, "code": "\tpublic void setKeyGenerator(KeyGenerator keyGenerator) {\n\t\tthis.cacheInterceptor.setKeyGenerator(keyGenerator);\n\t}", "summary_tokens": ["set", "the", "default", "key", "generator", "that", "this", "cache", "aspect", "should", "delegate", "to", "if", "no", "specific", "key", "generator", "has", "been", "set", "for", "the", "operation"], "project": "spring-framework"}
{"id": 189, "code": "\tprivate void appendArgumentTypes(MethodInvocation methodInvocation, Matcher matcher, StringBuilder output) {\n\t\tClass<?>[] argumentTypes = methodInvocation.getMethod().getParameterTypes();\n\t\tString[] argumentTypeShortNames = new String[argumentTypes.length];\n\t\tfor (int i = 0; i < argumentTypeShortNames.length; i++) {\n\t\t\targumentTypeShortNames[i] = ClassUtils.getShortName(argumentTypes[i]);\n\t\t}\n\t\tmatcher.appendReplacement(output,\n\t\t\t\tMatcher.quoteReplacement(StringUtils.arrayToCommaDelimitedString(argumentTypeShortNames)));\n\t}", "summary_tokens": ["adds", "a", "comma", "separated", "list", "of", "the", "short", "class", "names", "of", "the", "method", "argument", "types", "to", "the", "output"], "project": "spring-framework"}
{"id": 7561, "code": "\tpublic MethodParameter getParameter() {\n\t\treturn this.parameter;\n\t}", "summary_tokens": ["return", "the", "target", "method", "parameter"], "project": "spring-framework"}
{"id": 8118, "code": "\tdefault Optional<ServerRequest> nest(ServerRequest request) {\n\t\treturn (test(request) ? Optional.of(request) : Optional.empty());\n\t}", "summary_tokens": ["transform", "the", "given", "request", "into", "a", "request", "used", "for", "a", "nested", "route"], "project": "spring-framework"}
{"id": 7719, "code": "\tpublic HttpHandler build() {\n\t\tWebHandler decorated = new FilteringWebHandler(this.webHandler, this.filters);\n\t\tdecorated = new ExceptionHandlingWebHandler(decorated,  this.exceptionHandlers);\n\n\t\tHttpWebHandlerAdapter adapted = new HttpWebHandlerAdapter(decorated);\n\t\tif (this.sessionManager != null) {\n\t\t\tadapted.setSessionManager(this.sessionManager);\n\t\t}\n\t\tif (this.codecConfigurer != null) {\n\t\t\tadapted.setCodecConfigurer(this.codecConfigurer);\n\t\t}\n\t\tif (this.localeContextResolver != null) {\n\t\t\tadapted.setLocaleContextResolver(this.localeContextResolver);\n\t\t}\n\t\tif (this.forwardedHeaderTransformer != null) {\n\t\t\tadapted.setForwardedHeaderTransformer(this.forwardedHeaderTransformer);\n\t\t}\n\t\tif (this.applicationContext != null) {\n\t\t\tadapted.setApplicationContext(this.applicationContext);\n\t\t}\n\t\tadapted.afterPropertiesSet();\n\n\t\treturn (this.httpHandlerDecorator != null ? this.httpHandlerDecorator.apply(adapted) : adapted);\n\t}", "summary_tokens": ["build", "the", "http", "handler"], "project": "spring-framework"}
{"id": 3084, "code": "\tpublic boolean isWorthTrying() {\n\t\treturn (this.worthTrying != Boolean.FALSE);\n\t}", "summary_tokens": ["return", "whether", "this", "objenesis", "instance", "is", "worth", "trying", "for", "instance", "creation", "i"], "project": "spring-framework"}
{"id": 5978, "code": "\tpublic ResultMatcher version(String name, int version) {\n\t\treturn result -> {\n\t\t\tCookie cookie = getCookie(result, name);\n\t\t\tassertEquals(\"Response cookie '\" + name + \"' version\", version, cookie.getVersion());\n\t\t};\n\t}", "summary_tokens": ["assert", "a", "cookie", "s", "version"], "project": "spring-framework"}
{"id": 7205, "code": "\tpublic final void setValidator(@Nullable Validator validator) {\n\t\tthis.validator = validator;\n\t}", "summary_tokens": ["set", "the", "validator", "to", "apply", "after", "each", "binding", "step"], "project": "spring-framework"}
{"id": 6, "code": "\tprivate Object readResolve() {\n\t\treturn INSTANCE;\n\t}", "summary_tokens": ["required", "to", "support", "serialization"], "project": "spring-framework"}
{"id": 8344, "code": "\tpublic String getErrorCode() {\n\t\treturn (!ObjectUtils.isEmpty(this.errorCodes) ? this.errorCodes[0] : \"\");\n\t}", "summary_tokens": ["return", "the", "first", "error", "codes", "for", "the", "field", "or", "object", "if", "any"], "project": "spring-framework"}
{"id": 2684, "code": "\tprivate static Method searchForMatch(Class<?> type, Method bridgeMethod) {\n\t\ttry {\n\t\t\treturn type.getDeclaredMethod(bridgeMethod.getName(), bridgeMethod.getParameterTypes());\n\t\t}\n\t\tcatch (NoSuchMethodException ex) {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["if", "the", "supplied", "class", "has", "a", "declared", "method", "whose", "signature", "matches", "that", "of", "the", "supplied", "method", "then", "this", "matching", "method", "is", "returned", "otherwise", "null", "is", "returned"], "project": "spring-framework"}
{"id": 3991, "code": "\tpublic void setReobtainTransactionalConnections(boolean reobtainTransactionalConnections) {\n\t\tthis.reobtainTransactionalConnections = reobtainTransactionalConnections;\n\t}", "summary_tokens": ["specify", "whether", "to", "reobtain", "the", "target", "connection", "for", "each", "operation", "performed", "within", "a", "transaction"], "project": "spring-framework"}
{"id": 8431, "code": "\tpublic void setEngine(ScriptEngine engine) {\n\t\tthis.engine = engine;\n\t}", "summary_tokens": ["see", "script", "template", "configurer", "set", "engine", "script", "engine", "documentation"], "project": "spring-framework"}
{"id": 2936, "code": "\tpublic final String getPath() {\n\t\treturn this.path;\n\t}", "summary_tokens": ["return", "the", "file", "path", "for", "this", "resource"], "project": "spring-framework"}
{"id": 7227, "code": "\tprivate String getErrorMessage(\n\t\t\tint rawStatusCode, String statusText, @Nullable byte[] responseBody, @Nullable Charset charset) {\n\n\t\tString preface = rawStatusCode + \" \" + statusText + \": \";\n\n\t\tif (ObjectUtils.isEmpty(responseBody)) {\n\t\t\treturn preface + \"[no body]\";\n\t\t}\n\n\t\tcharset = (charset != null ? charset : StandardCharsets.UTF_8);\n\n\t\tString bodyText = new String(responseBody, charset);\n\t\tbodyText = LogFormatUtils.formatValue(bodyText, -1, true);\n\n\t\treturn preface + bodyText;\n\t}", "summary_tokens": ["return", "error", "message", "with", "details", "from", "the", "response", "body"], "project": "spring-framework"}
{"id": 4649, "code": "\tpublic void setDestinationResolver(@Nullable DestinationResolver<D> destinationResolver) {\n\t\tthis.destinationResolver = destinationResolver;\n\t}", "summary_tokens": ["configure", "the", "destination", "resolver", "to", "use", "to", "resolve", "string", "destination", "names", "into", "actual", "destinations", "of", "type", "d"], "project": "spring-framework"}
{"id": 8769, "code": "\tstatic BodyBuilder from(ServerResponse other) {\n\t\treturn new DefaultServerResponseBuilder(other);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "the", "status", "code", "and", "headers", "of", "the", "given", "response"], "project": "spring-framework"}
{"id": 486, "code": "\tpublic void setTargetClass(@Nullable Class<?> targetClass) {\n\t\tthis.targetClass = targetClass;\n\t}", "summary_tokens": ["set", "the", "target", "class", "on", "which", "the", "field", "is", "defined"], "project": "spring-framework"}
{"id": 7593, "code": "\tpublic boolean supportsParameter(MethodParameter parameter) {\n\t\treturn getArgumentResolver(parameter) != null;\n\t}", "summary_tokens": ["whether", "the", "given", "method", "parameter", "method", "parameter", "is", "supported", "by", "any", "registered", "handler", "method", "argument", "resolver"], "project": "spring-framework"}
{"id": 1911, "code": "\tpublic Class<?>[] getScriptInterfaces() {\n\t\treturn null;\n\t}", "summary_tokens": ["groovy", "scripts", "determine", "their", "interfaces", "themselves", "hence", "we", "don", "t", "need", "to", "explicitly", "expose", "interfaces", "here"], "project": "spring-framework"}
{"id": 4732, "code": "\tpublic HandlerMethodReturnValueHandlerComposite addHandlers(\n\t\t\t@Nullable List<? extends HandlerMethodReturnValueHandler> handlers) {\n\n\t\tif (handlers != null) {\n\t\t\tthis.returnValueHandlers.addAll(handlers);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "given", "handler", "method", "return", "value", "handler", "handler", "method", "return", "value", "handlers"], "project": "spring-framework"}
{"id": 584, "code": "\tpublic final String getImportedResource() {\n\t\treturn this.importedResource;\n\t}", "summary_tokens": ["return", "the", "location", "of", "the", "imported", "resource"], "project": "spring-framework"}
{"id": 4225, "code": "\tpublic String getSubscription() {\n\t\treturn this.subscription;\n\t}", "summary_tokens": ["return", "the", "name", "for", "the", "durable", "subscription", "if", "any"], "project": "spring-framework"}
{"id": 6228, "code": "\tdefault boolean isReadOnly() {\n\t\treturn false;\n\t}", "summary_tokens": ["return", "whether", "to", "optimize", "as", "a", "read", "only", "transaction"], "project": "spring-framework"}
{"id": 9413, "code": "\tprotected String getOnselect() {\n\t\treturn this.onselect;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onselect", "attribute"], "project": "spring-framework"}
{"id": 2799, "code": "\tstatic <A extends Annotation> MergedAnnotation<A> of(\n\t\t\t@Nullable ClassLoader classLoader, @Nullable Object source,\n\t\t\tClass<A> annotationType, @Nullable Map<String, ?> attributes) {\n\n\t\treturn TypeMappedAnnotation.of(classLoader, source, annotationType, attributes);\n\t}", "summary_tokens": ["create", "a", "new", "merged", "annotation", "instance", "of", "the", "specified", "annotation", "type", "with", "attribute", "values", "supplied", "by", "a", "map"], "project": "spring-framework"}
{"id": 346, "code": "\tpublic void overrideDefaultEditor(Class<?> requiredType, PropertyEditor propertyEditor) {\n\t\tif (this.overriddenDefaultEditors == null) {\n\t\t\tthis.overriddenDefaultEditors = new HashMap<>();\n\t\t}\n\t\tthis.overriddenDefaultEditors.put(requiredType, propertyEditor);\n\t}", "summary_tokens": ["override", "the", "default", "editor", "for", "the", "specified", "type", "with", "the", "given", "property", "editor"], "project": "spring-framework"}
{"id": 674, "code": "\tprivate Method[] getCandidateMethods(Class<?> factoryClass, RootBeanDefinition mbd) {\n\t\treturn (mbd.isNonPublicAccessAllowed() ?\n\t\t\t\tReflectionUtils.getAllDeclaredMethods(factoryClass) : factoryClass.getMethods());\n\t}", "summary_tokens": ["retrieve", "all", "candidate", "methods", "for", "the", "given", "class", "considering", "the", "root", "bean", "definition", "is", "non", "public", "access", "allowed", "flag"], "project": "spring-framework"}
{"id": 9394, "code": "\tprotected String autogenerateId() throws JspException {\n\t\treturn resolveModelAttribute();\n\t}", "summary_tokens": ["autogenerated", "ids", "correspond", "to", "the", "form", "object", "name"], "project": "spring-framework"}
{"id": 355, "code": "\tprivate void addStrippedPropertyPaths(List<String> strippedPaths, String nestedPath, String propertyPath) {\n\t\tint startIndex = propertyPath.indexOf(PropertyAccessor.PROPERTY_KEY_PREFIX_CHAR);\n\t\tif (startIndex != -1) {\n\t\t\tint endIndex = propertyPath.indexOf(PropertyAccessor.PROPERTY_KEY_SUFFIX_CHAR);\n\t\t\tif (endIndex != -1) {\n\t\t\t\tString prefix = propertyPath.substring(0, startIndex);\n\t\t\t\tString key = propertyPath.substring(startIndex, endIndex + 1);\n\t\t\t\tString suffix = propertyPath.substring(endIndex + 1);\n\t\t\t\t\n\t\t\t\tstrippedPaths.add(nestedPath + prefix + suffix);\n\t\t\t\t\n\t\t\t\taddStrippedPropertyPaths(strippedPaths, nestedPath + prefix, suffix);\n\t\t\t\t\n\t\t\t\taddStrippedPropertyPaths(strippedPaths, nestedPath + prefix + key, suffix);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["add", "property", "paths", "with", "all", "variations", "of", "stripped", "keys", "and", "or", "indexes"], "project": "spring-framework"}
{"id": 4506, "code": "\tprotected void initializeConsumers() throws JMSException {\n\t\t\n\t\tsynchronized (this.consumersMonitor) {\n\t\t\tif (this.consumers == null) {\n\t\t\t\tthis.sessions = new HashSet<>(this.concurrentConsumers);\n\t\t\t\tthis.consumers = new HashSet<>(this.concurrentConsumers);\n\t\t\t\tConnection con = getSharedConnection();\n\t\t\t\tfor (int i = 0; i < this.concurrentConsumers; i++) {\n\t\t\t\t\tSession session = createSession(con);\n\t\t\t\t\tMessageConsumer consumer = createListenerConsumer(session);\n\t\t\t\t\tthis.sessions.add(session);\n\t\t\t\t\tthis.consumers.add(consumer);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "jms", "sessions", "and", "message", "consumers", "for", "this", "container"], "project": "spring-framework"}
{"id": 7121, "code": "\tpublic void setMediaTypes(Properties mediaTypes) {\n\t\tif (!CollectionUtils.isEmpty(mediaTypes)) {\n\t\t\tmediaTypes.forEach((key, value) ->\n\t\t\t\t\taddMediaType((String) key, MediaType.valueOf((String) value)));\n\t\t}\n\t}", "summary_tokens": ["add", "a", "mapping", "from", "a", "key", "to", "a", "media", "type", "where", "the", "key", "are", "normalized", "to", "lowercase", "and", "may", "have", "been", "extracted", "from", "a", "path", "extension", "a", "filename", "extension", "or", "passed", "as", "a", "query", "parameter"], "project": "spring-framework"}
{"id": 791, "code": "\tprotected void postProcessComponentDefinition(BeanComponentDefinition componentDefinition) {\n\t}", "summary_tokens": ["hook", "method", "called", "after", "the", "primary", "parsing", "of", "a", "bean", "component", "definition", "but", "before", "the", "bean", "component", "definition", "has", "been", "registered", "with", "a", "org"], "project": "spring-framework"}
{"id": 3227, "code": "\tpublic String getMimeType() {\n\t\treturn this.mimeType;\n\t}", "summary_tokens": ["return", "the", "offending", "content", "type"], "project": "spring-framework"}
{"id": 6082, "code": "\tpublic ResultMatcher isRequestTimeout() {\n\t\treturn matcher(HttpStatus.REQUEST_TIMEOUT);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 9536, "code": "\tpublic boolean isExposePathVariables() {\n\t\treturn this.exposePathVariables;\n\t}", "summary_tokens": ["return", "whether", "to", "add", "path", "variables", "to", "the", "model", "or", "not"], "project": "spring-framework"}
{"id": 4018, "code": "\tpublic EmbeddedDatabaseBuilder ignoreFailedDrops(boolean flag) {\n\t\tthis.databasePopulator.setIgnoreFailedDrops(flag);\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "that", "a", "failed", "sql", "drop", "statement", "within", "an", "executed", "script", "can", "be", "ignored"], "project": "spring-framework"}
{"id": 3869, "code": "\tpublic void setAccessTableColumnMetaData(boolean accessTableColumnMetaData) {\n\t\tthis.tableMetaDataContext.setAccessTableColumnMetaData(accessTableColumnMetaData);\n\t}", "summary_tokens": ["specify", "whether", "the", "parameter", "meta", "data", "for", "the", "call", "should", "be", "used"], "project": "spring-framework"}
{"id": 1343, "code": "\tpublic Set<String> getCandidateTypes(String basePackage, String stereotype) {\n\t\tList<Entry> candidates = this.index.get(stereotype);\n\t\tif (candidates != null) {\n\t\t\treturn candidates.parallelStream()\n\t\t\t\t\t.filter(t -> t.match(basePackage))\n\t\t\t\t\t.map(t -> t.type)\n\t\t\t\t\t.collect(Collectors.toSet());\n\t\t}\n\t\treturn Collections.emptySet();\n\t}", "summary_tokens": ["return", "the", "candidate", "types", "that", "are", "associated", "with", "the", "specified", "stereotype"], "project": "spring-framework"}
{"id": 4987, "code": "\tpublic static StompHeaderAccessor createForHeartbeat() {\n\t\treturn new StompHeaderAccessor();\n\t}", "summary_tokens": ["create", "headers", "for", "a", "heartbeat"], "project": "spring-framework"}
{"id": 2576, "code": "public static String getDescriptor(final Class<?> clazz) {\n  StringBuilder stringBuilder = new StringBuilder();\n  appendDescriptor(clazz, stringBuilder);\n  return stringBuilder.toString();\n}", "summary_tokens": ["returns", "the", "descriptor", "corresponding", "to", "the", "given", "class"], "project": "spring-framework"}
{"id": 6953, "code": "\tpublic Jackson2ObjectMapperBuilder timeZone(String timeZoneString) {\n\t\tthis.timeZone = StringUtils.parseTimeZoneString(timeZoneString);\n\t\treturn this;\n\t}", "summary_tokens": ["override", "the", "default", "time", "zone", "to", "use", "for", "formatting"], "project": "spring-framework"}
{"id": 2673, "code": "public void quickSort(int index, int lo, int hi, Comparator cmp) {\n    chooseComparer(index, cmp);\n    super.quickSort(lo, hi - 1);\n}", "summary_tokens": ["sort", "the", "arrays", "using", "the", "quicksort", "algorithm"], "project": "spring-framework"}
{"id": 9723, "code": "\tpublic void setIndent(boolean indent) {\n\t\tthis.indent = indent;\n\t}", "summary_tokens": ["set", "whether", "the", "xslt", "transformer", "may", "add", "additional", "whitespace", "when", "outputting", "the", "result", "tree"], "project": "spring-framework"}
{"id": 6232, "code": "\tpublic final Throwable getApplicationException() {\n\t\treturn this.applicationException;\n\t}", "summary_tokens": ["return", "the", "application", "exception", "that", "was", "thrown", "before", "this", "transaction", "exception", "if", "any"], "project": "spring-framework"}
{"id": 6723, "code": "\tpublic URI getType() {\n\t\treturn this.type;\n\t}", "summary_tokens": ["return", "the", "configured", "set", "type", "uri", "problem", "type"], "project": "spring-framework"}
{"id": 7539, "code": "\tpublic static HandlerTypePredicate forAssignableType(Class<?>... types) {\n\t\treturn new Builder().assignableType(types).build();\n\t}", "summary_tokens": ["match", "handlers", "that", "are", "assignable", "to", "a", "given", "type"], "project": "spring-framework"}
{"id": 5024, "code": "\tpublic void set(String headerName, @Nullable String headerValue) {\n\t\tList<String> headerValues = new ArrayList<>(1);\n\t\theaderValues.add(headerValue);\n\t\tthis.headers.put(headerName, headerValues);\n\t}", "summary_tokens": ["set", "the", "given", "single", "header", "value", "under", "the", "given", "name"], "project": "spring-framework"}
{"id": 1079, "code": "\tpublic Class<?> getTargetClass() {\n\t\tClass<?> targetClass = super.getTargetClass();\n\t\tif (targetClass == null && this.targetBeanName != null) {\n\t\t\tAssert.state(this.beanFactory != null, \"BeanFactory must be set when using 'targetBeanName'\");\n\t\t\ttargetClass = this.beanFactory.getType(this.targetBeanName);\n\t\t}\n\t\treturn targetClass;\n\t}", "summary_tokens": ["overridden", "to", "support", "the", "set", "target", "bean", "name", "target", "bean", "name", "feature"], "project": "spring-framework"}
{"id": 3604, "code": "\tpublic static Builder forReadOnlyDataBinding() {\n\t\treturn new Builder(DataBindingPropertyAccessor.forReadOnlyAccess());\n\t}", "summary_tokens": ["create", "a", "simple", "evaluation", "context", "for", "read", "only", "access", "to", "public", "properties", "via", "data", "binding", "property", "accessor"], "project": "spring-framework"}
{"id": 7365, "code": "\tprotected ServletConfig getServletConfig() {\n\t\treturn this.servletConfig;\n\t}", "summary_tokens": ["returns", "the", "servlet", "config", "to", "be", "injected", "or", "null"], "project": "spring-framework"}
{"id": 790, "code": "\tprotected boolean shouldFireEvents() {\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "whether", "this", "parser", "is", "supposed", "to", "fire", "a", "org"], "project": "spring-framework"}
{"id": 6187, "code": "\tpublic void setTransactionManager(Object transactionManager) {\n\t\tif (transactionManager instanceof TransactionFactory) {\n\t\t\tthis.transactionFactory = (TransactionFactory) transactionManager;\n\t\t}\n\t\telse if (transactionManager instanceof TransactionManager) {\n\t\t\tthis.transactionFactory = new SimpleTransactionFactory((TransactionManager) transactionManager);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"Transaction manager [\" + transactionManager +\n\t\t\t\t\t\"] is neither a [org.springframework.transaction.jta.TransactionFactory} nor a \" +\n\t\t\t\t\t\"[jakarta.transaction.TransactionManager]\");\n\t\t}", "summary_tokens": ["set", "the", "xa", "transaction", "manager", "to", "use", "for", "wrapping", "endpoint", "invocations", "enlisting", "the", "endpoint", "resource", "in", "each", "such", "transaction"], "project": "spring-framework"}
{"id": 5835, "code": "\tpublic static RequestMatcher requestTo(URI uri) {\n\t\tAssert.notNull(uri, \"'uri' must not be null\");\n\t\treturn request -> assertEquals(\"Unexpected request\", uri, request.getURI());\n\t}", "summary_tokens": ["expect", "a", "request", "to", "the", "given", "uri"], "project": "spring-framework"}
{"id": 2833, "code": "\tpublic static StringDecoder textPlainOnly(List<String> delimiters, boolean stripDelimiter) {\n\t\treturn new StringDecoder(delimiters, stripDelimiter, new MimeType(\"text\", \"plain\", DEFAULT_CHARSET));\n\t}", "summary_tokens": ["create", "a", "string", "decoder", "for", "text", "plain"], "project": "spring-framework"}
{"id": 2912, "code": "\tpublic long contentLength() throws IOException {\n\t\tInputStream is = getInputStream();\n\t\ttry {\n\t\t\tlong size = 0;\n\t\t\tbyte[] buf = new byte[256];\n\t\t\tint read;\n\t\t\twhile ((read = is.read(buf)) != -1) {\n\t\t\t\tsize += read;\n\t\t\t}\n\t\t\treturn size;\n\t\t}\n\t\tfinally {\n\t\t\ttry {\n\t\t\t\tis.close();\n\t\t\t}\n\t\t\tcatch (IOException ex) {\n\t\t\t\tdebug(() -> \"Could not close content-length InputStream for \" + getDescription(), ex);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["this", "method", "reads", "the", "entire", "input", "stream", "to", "determine", "the", "content", "length"], "project": "spring-framework"}
{"id": 7010, "code": "\tpublic void setModules(List<Module> modules) {\n\t\tthis.builder.modules(modules);\n\t}", "summary_tokens": ["set", "a", "complete", "list", "of", "modules", "to", "be", "registered", "with", "the", "object", "mapper"], "project": "spring-framework"}
{"id": 5403, "code": "\tMapBindParameterSource addValue(String paramName, Object value) {\n\t\tAssert.notNull(paramName, \"Parameter name must not be null\");\n\t\tAssert.notNull(value, \"Value must not be null\");\n\t\tthis.values.put(paramName, Parameters.in(value));\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "key", "value", "pair", "to", "the", "map", "bind", "parameter", "source"], "project": "spring-framework"}
{"id": 8484, "code": "public int getBlah() {\n  return blah_;\n}", "summary_tokens": ["code", "optional", "int", "0", "blah", "0", "code"], "project": "spring-framework"}
{"id": 2169, "code": "\tpublic boolean isStatic() {\n\t\treturn this.instance == null;\n\t}", "summary_tokens": ["return", "whether", "the", "current", "invocation", "is", "static"], "project": "spring-framework"}
{"id": 3689, "code": "\tpublic RowMapper<?> getRowMapper() {\n\t\treturn this.rowMapper;\n\t}", "summary_tokens": ["return", "the", "row", "mapper", "held", "by", "this", "parameter", "if", "any"], "project": "spring-framework"}
{"id": 8175, "code": "\tprotected void initRouterFunctions() {\n\t\tList<RouterFunction<?>> routerFunctions = routerFunctions();\n\t\tthis.routerFunction = routerFunctions.stream().reduce(RouterFunction::andOther).orElse(null);\n\t\tlogRouterFunctions(routerFunctions);\n\t}", "summary_tokens": ["initialized", "the", "router", "functions", "by", "detecting", "them", "in", "the", "application", "context"], "project": "spring-framework"}
{"id": 5487, "code": "\tpublic static final SystemProfileValueSource getInstance() {\n\t\treturn INSTANCE;\n\t}", "summary_tokens": ["obtain", "the", "canonical", "instance", "of", "this", "profile", "value", "source"], "project": "spring-framework"}
{"id": 9833, "code": "\tpublic MessageHeaderInitializer getHeaderInitializer() {\n\t\treturn this.headerInitializer;\n\t}", "summary_tokens": ["return", "the", "configured", "header", "initializer"], "project": "spring-framework"}
{"id": 5045, "code": "\tpublic String getSubscribeDestination() {\n\t\treturn this.subscribeDestination;\n\t}", "summary_tokens": ["the", "user", "destination", "in", "the", "form", "expected", "when", "a", "client", "subscribes", "e"], "project": "spring-framework"}
{"id": 849, "code": "\tpublic NamespaceHandlerResolver getNamespaceHandlerResolver() {\n\t\tif (this.namespaceHandlerResolver == null) {\n\t\t\tthis.namespaceHandlerResolver = createDefaultNamespaceHandlerResolver();\n\t\t}\n\t\treturn this.namespaceHandlerResolver;\n\t}", "summary_tokens": ["lazily", "create", "a", "default", "namespace", "handler", "resolver", "if", "not", "set", "before"], "project": "spring-framework"}
{"id": 161, "code": "\tprotected DefaultListableBeanFactory buildInternalBeanFactory(ConfigurableBeanFactory containingFactory) {\n\t\t\n\t\tDefaultListableBeanFactory internalBeanFactory = new DefaultListableBeanFactory(containingFactory);\n\n\t\t\n\t\tinternalBeanFactory.copyConfigurationFrom(containingFactory);\n\n\t\t\n\t\t\n\t\tinternalBeanFactory.getBeanPostProcessors().removeIf(beanPostProcessor ->\n\t\t\t\tbeanPostProcessor instanceof AopInfrastructureBean);\n\n\t\treturn internalBeanFactory;\n\t}", "summary_tokens": ["build", "an", "internal", "bean", "factory", "for", "resolving", "target", "beans"], "project": "spring-framework"}
{"id": 1059, "code": "\tpublic void setMisfireInstruction(int misfireInstruction) {\n\t\tthis.misfireInstruction = misfireInstruction;\n\t}", "summary_tokens": ["specify", "a", "misfire", "instruction", "for", "this", "trigger"], "project": "spring-framework"}
{"id": 6288, "code": "\tpublic void setClassFilter(ClassFilter classFilter) {\n\t\tthis.pointcut.setClassFilter(classFilter);\n\t}", "summary_tokens": ["set", "the", "class", "filter", "to", "use", "for", "this", "pointcut"], "project": "spring-framework"}
{"id": 1728, "code": "\tpublic Properties getJndiEnvironment() {\n\t\treturn this.jndiTemplate.getEnvironment();\n\t}", "summary_tokens": ["return", "the", "jndi", "environment", "to", "use", "for", "jndi", "lookups"], "project": "spring-framework"}
{"id": 724, "code": "\tpublic String getValueTypeName() {\n\t\treturn this.valueTypeName;\n\t}", "summary_tokens": ["return", "the", "default", "value", "type", "name", "class", "name", "to", "be", "used", "for", "this", "map"], "project": "spring-framework"}
{"id": 7515, "code": "\tpublic void setWriteWeakETag(boolean writeWeakETag) {\n\t\tthis.writeWeakETag = writeWeakETag;\n\t}", "summary_tokens": ["set", "whether", "the", "etag", "value", "written", "to", "the", "response", "should", "be", "weak", "as", "per", "rfc", "0"], "project": "spring-framework"}
{"id": 4166, "code": "\tpublic SQLErrorCodes registerDatabase(DataSource dataSource, String databaseName) {\n\t\tSQLErrorCodes sec = getErrorCodes(databaseName);\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Caching SQL error codes for DataSource [\" + identify(dataSource) +\n\t\t\t\t\t\"]: database product name is '\" + databaseName + \"'\");\n\t\t}\n\t\tthis.dataSourceCache.put(dataSource, sec);\n\t\treturn sec;\n\t}", "summary_tokens": ["associate", "the", "specified", "database", "name", "with", "the", "given", "data", "source"], "project": "spring-framework"}
{"id": 1806, "code": "\tpublic void setJndiName(String jndiName) {\n\t\tthis.jndiName = jndiName;\n\t}", "summary_tokens": ["specify", "a", "jndi", "name", "of", "the", "java"], "project": "spring-framework"}
{"id": 6128, "code": "\tpublic ResultMatcher number(Double expectedValue) {\n\t\treturn result -> {\n\t\t\tMockHttpServletResponse response = result.getResponse();\n\t\t\tthis.xpathHelper.assertNumber(response.getContentAsByteArray(), getDefinedEncoding(response), expectedValue);\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "xpath", "and", "assert", "the", "double", "value", "found"], "project": "spring-framework"}
{"id": 8624, "code": "\tpublic RedirectViewControllerRegistration setContextRelative(boolean contextRelative) {\n\t\tthis.redirectView.setContextRelative(contextRelative);\n\t\treturn this;\n\t}", "summary_tokens": ["whether", "to", "interpret", "a", "given", "redirect", "url", "that", "starts", "with", "a", "slash", "as", "relative", "to", "the", "current", "servlet", "context", "i"], "project": "spring-framework"}
{"id": 2476, "code": "public void visitInsn(final int opcode) {\n  if (mv != null) {\n    mv.visitInsn(opcode);\n  }\n}", "summary_tokens": ["visits", "a", "zero", "operand", "instruction"], "project": "spring-framework"}
{"id": 7172, "code": "\tpublic static double getRequiredDoubleParameter(ServletRequest request, String name)\n\t\t\tthrows ServletRequestBindingException {\n\n\t\treturn DOUBLE_PARSER.parseDouble(name, request.getParameter(name));\n\t}", "summary_tokens": ["get", "a", "double", "parameter", "throwing", "an", "exception", "if", "it", "isn", "t", "found", "or", "isn", "t", "a", "number"], "project": "spring-framework"}
{"id": 4161, "code": "\tpublic void setUseSqlStateForTranslation(boolean useStateCodeForTranslation) {\n\t\tthis.useSqlStateForTranslation = useStateCodeForTranslation;\n\t}", "summary_tokens": ["set", "this", "property", "to", "true", "for", "databases", "that", "do", "not", "provide", "an", "error", "code", "but", "that", "do", "provide", "sql", "state", "this", "includes", "postgre", "sql"], "project": "spring-framework"}
{"id": 2170, "code": "\tpublic List<Object> getArguments() {\n\t\treturn Arrays.asList(this.arguments);\n\t}", "summary_tokens": ["return", "the", "argument", "values", "used", "for", "the", "current", "reflection", "invocation"], "project": "spring-framework"}
{"id": 1180, "code": "\tpublic boolean isAllowNullValues() {\n\t\treturn this.allowNullValues;\n\t}", "summary_tokens": ["return", "whether", "this", "cache", "manager", "accepts", "and", "converts", "null", "values", "for", "all", "of", "its", "caches"], "project": "spring-framework"}
{"id": 4121, "code": "\tpublic int update(String p1, String p2) throws DataAccessException {\n\t\treturn update(new Object[] {p1, p2});\n\t}", "summary_tokens": ["convenient", "method", "to", "execute", "an", "update", "given", "two", "string", "args"], "project": "spring-framework"}
{"id": 3316, "code": "\tpublic static String deleteAny(String inString, @Nullable String charsToDelete) {\n\t\tif (!hasLength(inString) || !hasLength(charsToDelete)) {\n\t\t\treturn inString;\n\t\t}\n\n\t\tint lastCharIndex = 0;\n\t\tchar[] result = new char[inString.length()];\n\t\tfor (int i = 0; i < inString.length(); i++) {\n\t\t\tchar c = inString.charAt(i);\n\t\t\tif (charsToDelete.indexOf(c) == -1) {\n\t\t\t\tresult[lastCharIndex++] = c;\n\t\t\t}\n\t\t}\n\t\tif (lastCharIndex == inString.length()) {\n\t\t\treturn inString;\n\t\t}\n\t\treturn new String(result, 0, lastCharIndex);\n\t}", "summary_tokens": ["delete", "any", "character", "in", "a", "given", "string"], "project": "spring-framework"}
{"id": 6332, "code": "\tprotected void applyTimeout(JtaTransactionObject txObject, int timeout) throws SystemException {\n\t\tif (timeout > TransactionDefinition.TIMEOUT_DEFAULT) {\n\t\t\ttxObject.getUserTransaction().setTransactionTimeout(timeout);\n\t\t\tif (timeout > 0) {\n\t\t\t\ttxObject.resetTransactionTimeout = true;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["apply", "the", "given", "transaction", "timeout"], "project": "spring-framework"}
{"id": 9559, "code": "\tprotected String transformPath(String lookupPath) {\n\t\tString path = lookupPath;\n\t\tif (this.stripLeadingSlash && path.startsWith(SLASH)) {\n\t\t\tpath = path.substring(1);\n\t\t}\n\t\tif (this.stripTrailingSlash && path.endsWith(SLASH)) {\n\t\t\tpath = path.substring(0, path.length() - 1);\n\t\t}\n\t\tif (this.stripExtension) {\n\t\t\tpath = StringUtils.stripFilenameExtension(path);\n\t\t}\n\t\tif (!SLASH.equals(this.separator)) {\n\t\t\tpath = StringUtils.replace(path, SLASH, this.separator);\n\t\t}\n\t\treturn path;\n\t}", "summary_tokens": ["transform", "the", "request", "uri", "in", "the", "context", "of", "the", "webapp", "stripping", "slashes", "and", "extensions", "and", "replacing", "the", "separator", "as", "required"], "project": "spring-framework"}
{"id": 1166, "code": "\tdefault boolean invalidate() {\n\t\tclear();\n\t\treturn false;\n\t}", "summary_tokens": ["invalidate", "the", "cache", "through", "removing", "all", "mappings", "expecting", "all", "entries", "to", "be", "immediately", "invisible", "for", "subsequent", "lookups"], "project": "spring-framework"}
{"id": 6848, "code": "\tpublic void setObjectMapper(ObjectMapper objectMapper) {\n\t\tAssert.notNull(objectMapper, \"ObjectMapper must not be null\");\n\t\tthis.defaultObjectMapper = objectMapper;\n\t}", "summary_tokens": ["configure", "the", "default", "object", "mapper", "instance", "to", "use"], "project": "spring-framework"}
{"id": 2283, "code": "\tpublic Stream<FieldHint> fields() {\n\t\treturn this.fields.stream();\n\t}", "summary_tokens": ["return", "the", "fields", "that", "require", "reflection"], "project": "spring-framework"}
{"id": 1492, "code": "\tpublic void setPattern(String pattern) {\n\t\tthis.pattern = pattern;\n\t}", "summary_tokens": ["specify", "the", "pattern", "to", "use", "to", "format", "number", "values"], "project": "spring-framework"}
{"id": 805, "code": "\tprivate Map<String, Object> getHandlerMappings() {\n\t\tMap<String, Object> handlerMappings = this.handlerMappings;\n\t\tif (handlerMappings == null) {\n\t\t\tsynchronized (this) {\n\t\t\t\thandlerMappings = this.handlerMappings;\n\t\t\t\tif (handlerMappings == null) {\n\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\tlogger.trace(\"Loading NamespaceHandler mappings from [\" + this.handlerMappingsLocation + \"]\");\n\t\t\t\t\t}\n\t\t\t\t\ttry {\n\t\t\t\t\t\tProperties mappings =\n\t\t\t\t\t\t\t\tPropertiesLoaderUtils.loadAllProperties(this.handlerMappingsLocation, this.classLoader);\n\t\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\t\tlogger.trace(\"Loaded NamespaceHandler mappings: \" + mappings);\n\t\t\t\t\t\t}\n\t\t\t\t\t\thandlerMappings = new ConcurrentHashMap<>(mappings.size());\n\t\t\t\t\t\tCollectionUtils.mergePropertiesIntoMap(mappings, handlerMappings);\n\t\t\t\t\t\tthis.handlerMappings = handlerMappings;\n\t\t\t\t\t}\n\t\t\t\t\tcatch (IOException ex) {\n\t\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\t\"Unable to load NamespaceHandler mappings from location [\" + this.handlerMappingsLocation + \"]\", ex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn handlerMappings;\n\t}", "summary_tokens": ["load", "the", "specified", "namespace", "handler", "mappings", "lazily"], "project": "spring-framework"}
{"id": 2584, "code": "public int getOpcode(final int opcode) {\n  if (opcode == Opcodes.IALOAD || opcode == Opcodes.IASTORE) {\n    switch (sort) {\n      case BOOLEAN:\n      case BYTE:\n        return opcode + (Opcodes.BALOAD - Opcodes.IALOAD);\n      case CHAR:\n        return opcode + (Opcodes.CALOAD - Opcodes.IALOAD);\n      case SHORT:\n        return opcode + (Opcodes.SALOAD - Opcodes.IALOAD);\n      case INT:\n        return opcode;\n      case FLOAT:\n        return opcode + (Opcodes.FALOAD - Opcodes.IALOAD);\n      case LONG:\n        return opcode + (Opcodes.LALOAD - Opcodes.IALOAD);\n      case DOUBLE:\n        return opcode + (Opcodes.DALOAD - Opcodes.IALOAD);\n      case ARRAY:\n      case OBJECT:\n      case INTERNAL:\n        return opcode + (Opcodes.AALOAD - Opcodes.IALOAD);\n      case METHOD:\n      case VOID:\n        throw new UnsupportedOperationException();\n      default:\n        throw new AssertionError();\n    }\n  } else {\n    switch (sort) {\n      case VOID:\n        if (opcode != Opcodes.IRETURN) {\n          throw new UnsupportedOperationException();\n        }\n        return Opcodes.RETURN;\n      case BOOLEAN:\n      case BYTE:\n      case CHAR:\n      case SHORT:\n      case INT:\n        return opcode;\n      case FLOAT:\n        return opcode + (Opcodes.FRETURN - Opcodes.IRETURN);\n      case LONG:\n        return opcode + (Opcodes.LRETURN - Opcodes.IRETURN);\n      case DOUBLE:\n        return opcode + (Opcodes.DRETURN - Opcodes.IRETURN);\n      case ARRAY:\n      case OBJECT:\n      case INTERNAL:\n        if (opcode != Opcodes.ILOAD && opcode != Opcodes.ISTORE && opcode != Opcodes.IRETURN) {\n          throw new UnsupportedOperationException();\n        }\n        return opcode + (Opcodes.ARETURN - Opcodes.IRETURN);\n      case METHOD:\n        throw new UnsupportedOperationException();\n      default:\n        throw new AssertionError();\n    }\n  }\n}", "summary_tokens": ["returns", "a", "jvm", "instruction", "opcode", "adapted", "to", "this", "type"], "project": "spring-framework"}
{"id": 1946, "code": "\tpublic void setBasenamePrefix(@Nullable String basenamePrefix) {\n\t\tthis.basenamePrefix = (basenamePrefix != null ? basenamePrefix : \"\");\n\t}", "summary_tokens": ["set", "the", "prefix", "that", "gets", "applied", "to", "the", "resource", "bundle", "basenames", "i"], "project": "spring-framework"}
{"id": 4826, "code": "\tpublic static SimpAttributes currentAttributes() throws IllegalStateException {\n\t\tSimpAttributes attributes = getAttributes();\n\t\tif (attributes == null) {\n\t\t\tthrow new IllegalStateException(\"No thread-bound SimpAttributes found. \" +\n\t\t\t\t\t\"Your code is probably not processing a client message and executing in \" +\n\t\t\t\t\t\"message-handling methods invoked by the SimpAnnotationMethodMessageHandler?\");\n\t\t}\n\t\treturn attributes;\n\t}", "summary_tokens": ["return", "the", "simp", "attributes", "currently", "bound", "to", "the", "thread", "or", "raise", "an", "java"], "project": "spring-framework"}
{"id": 7431, "code": "\tprotected List<HttpMethod> checkMethods(CorsConfiguration config, @Nullable HttpMethod requestMethod) {\n\t\treturn config.checkHttpMethod(requestMethod);\n\t}", "summary_tokens": ["check", "the", "http", "method", "and", "determine", "the", "methods", "for", "the", "response", "of", "a", "pre", "flight", "request"], "project": "spring-framework"}
{"id": 2469, "code": "public AnnotationVisitor visitAnnotation(final String descriptor, final boolean visible) {\n  if (mv != null) {\n    return mv.visitAnnotation(descriptor, visible);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "annotation", "of", "this", "method"], "project": "spring-framework"}
{"id": 6339, "code": "\tpublic void flush() {\n\t\tTransactionSynchronizationUtils.triggerFlush();\n\t}", "summary_tokens": ["this", "implementation", "triggers", "flush", "callbacks", "assuming", "that", "they", "will", "flush", "all", "affected", "orm", "sessions"], "project": "spring-framework"}
{"id": 8727, "code": "\tdefault void addReturnValueHandlers(List<HandlerMethodReturnValueHandler> handlers) {\n\t}", "summary_tokens": ["add", "handlers", "to", "support", "custom", "controller", "method", "return", "value", "types"], "project": "spring-framework"}
{"id": 209, "code": "\tprotected Object doProceed(MethodInvocation mi) throws Throwable {\n\t\t\n\t\treturn mi.proceed();\n\t}", "summary_tokens": ["proceed", "with", "the", "supplied", "org"], "project": "spring-framework"}
{"id": 7304, "code": "\tpublic void setTimeout(Long timeout) {\n\t\tAssert.state(!isAsyncStarted(), \"Cannot change the timeout with concurrent handling in progress\");\n\t\tthis.timeout = timeout;\n\t}", "summary_tokens": ["in", "servlet", "0", "async", "processing", "the", "timeout", "period", "begins", "after", "the", "container", "processing", "thread", "has", "exited"], "project": "spring-framework"}
{"id": 37, "code": "\tpublic String getTypePattern() {\n\t\treturn this.typePattern;\n\t}", "summary_tokens": ["return", "the", "aspect", "j", "type", "pattern", "to", "match"], "project": "spring-framework"}
{"id": 6724, "code": "\tpublic String getTitle() {\n\t\tif (this.title == null) {\n\t\t\tHttpStatus httpStatus = HttpStatus.resolve(this.status);\n\t\t\tif (httpStatus != null) {\n\t\t\t\treturn httpStatus.getReasonPhrase();\n\t\t\t}\n\t\t}\n\t\treturn this.title;\n\t}", "summary_tokens": ["return", "the", "configured", "set", "title", "string", "problem", "title"], "project": "spring-framework"}
{"id": 319, "code": "\tprivate static BeanInfo getBeanInfo(Class<?> beanClass) throws IntrospectionException {\n\t\tfor (BeanInfoFactory beanInfoFactory : beanInfoFactories) {\n\t\t\tBeanInfo beanInfo = beanInfoFactory.getBeanInfo(beanClass);\n\t\t\tif (beanInfo != null) {\n\t\t\t\treturn beanInfo;\n\t\t\t}\n\t\t}\n\t\treturn (shouldIntrospectorIgnoreBeaninfoClasses ?\n\t\t\t\tIntrospector.getBeanInfo(beanClass, Introspector.IGNORE_ALL_BEANINFO) :\n\t\t\t\tIntrospector.getBeanInfo(beanClass));\n\t}", "summary_tokens": ["retrieve", "a", "bean", "info", "descriptor", "for", "the", "given", "target", "class"], "project": "spring-framework"}
{"id": 1981, "code": "\tprotected AbstractPropertyBindingResult createDirectFieldBindingResult() {\n\t\tDirectFieldBindingResult result = new DirectFieldBindingResult(getTarget(),\n\t\t\t\tgetObjectName(), isAutoGrowNestedPaths());\n\n\t\tif (this.conversionService != null) {\n\t\t\tresult.initConversion(this.conversionService);\n\t\t}\n\t\tif (this.messageCodesResolver != null) {\n\t\t\tresult.setMessageCodesResolver(this.messageCodesResolver);\n\t\t}\n\n\t\treturn result;\n\t}", "summary_tokens": ["create", "the", "abstract", "property", "binding", "result", "instance", "using", "direct", "field", "access"], "project": "spring-framework"}
{"id": 8812, "code": "\tpublic Map<String, String> extractUriTemplateVariables() {\n\t\treturn (this.pathPattern != null ?\n\t\t\t\tthis.pathPattern.matchAndExtract(this.lookupPathContainer).getUriVariables() :\n\t\t\t\tthis.pathMatcher.extractUriTemplateVariables(this.pattern, this.lookupPath));\n\t}", "summary_tokens": ["extract", "uri", "template", "variables", "from", "the", "matching", "pattern", "as", "defined", "in", "path", "matcher", "extract", "uri", "template", "variables"], "project": "spring-framework"}
{"id": 5531, "code": "\tpublic void afterTestClass() throws Exception {\n\t\tClass<?> testClass = getTestContext().getTestClass();\n\t\tif (logger.isTraceEnabled()) {\n\t\t\tlogger.trace(\"afterTestClass(): class [\" + testClass.getName() + \"]\");\n\t\t}\n\t\tgetTestContext().updateState(null, null, null);\n\n\t\tThrowable afterTestClassException = null;\n\t\t\n\t\t\n\t\tfor (TestExecutionListener testExecutionListener : getReversedTestExecutionListeners()) {\n\t\t\ttry {\n\t\t\t\ttestExecutionListener.afterTestClass(getTestContext());\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tlogException(ex, \"afterTestClass\", testExecutionListener, testClass);\n\t\t\t\tif (afterTestClassException == null) {\n\t\t\t\t\tafterTestClassException = ex;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tafterTestClassException.addSuppressed(ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tthis.testContextHolder.remove();\n\n\t\tif (afterTestClassException != null) {\n\t\t\tReflectionUtils.rethrowException(afterTestClassException);\n\t\t}\n\t}", "summary_tokens": ["hook", "for", "post", "processing", "a", "test", "class", "em", "after", "em", "execution", "of", "all", "tests", "within", "the", "class"], "project": "spring-framework"}
{"id": 8057, "code": "\tpublic static BodyExtractor<Mono<MultiValueMap<String, String>>, ReactiveHttpInputMessage> toFormData() {\n\t\treturn (message, context) -> {\n\t\t\tResolvableType elementType = FORM_DATA_TYPE;\n\t\t\tMediaType mediaType = MediaType.APPLICATION_FORM_URLENCODED;\n\t\t\tHttpMessageReader<MultiValueMap<String, String>> reader = findReader(elementType, mediaType, context);\n\t\t\treturn readToMono(message, context, elementType, reader);\n\t\t};\n\t}", "summary_tokens": ["extractor", "to", "read", "form", "data", "into", "multi", "value", "map", "string", "string"], "project": "spring-framework"}
{"id": 97, "code": "\tpublic void addListener(AdvisedSupportListener listener) {\n\t\tAssert.notNull(listener, \"AdvisedSupportListener must not be null\");\n\t\tthis.listeners.add(listener);\n\t}", "summary_tokens": ["add", "the", "given", "advised", "support", "listener", "to", "this", "proxy", "configuration"], "project": "spring-framework"}
{"id": 7270, "code": "\tpublic static void setRequestAttributes(@Nullable RequestAttributes attributes, boolean inheritable) {\n\t\tif (attributes == null) {\n\t\t\tresetRequestAttributes();\n\t\t}\n\t\telse {\n\t\t\tif (inheritable) {\n\t\t\t\tinheritableRequestAttributesHolder.set(attributes);\n\t\t\t\trequestAttributesHolder.remove();\n\t\t\t}\n\t\t\telse {\n\t\t\t\trequestAttributesHolder.set(attributes);\n\t\t\t\tinheritableRequestAttributesHolder.remove();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["bind", "the", "given", "request", "attributes", "to", "the", "current", "thread"], "project": "spring-framework"}
{"id": 8192, "code": "\tpublic void initApplicationContext() throws BeansException {\n\t\tsuper.initApplicationContext();\n\t\tregisterHandlers(this.urlMap);\n\t}", "summary_tokens": ["calls", "the", "register", "handlers", "method", "in", "addition", "to", "the", "superclass", "s", "initialization"], "project": "spring-framework"}
{"id": 3132, "code": "\tpublic static boolean isAssignable(Class<?> lhsType, Class<?> rhsType) {\n\t\tAssert.notNull(lhsType, \"Left-hand side type must not be null\");\n\t\tAssert.notNull(rhsType, \"Right-hand side type must not be null\");\n\t\tif (lhsType.isAssignableFrom(rhsType)) {\n\t\t\treturn true;\n\t\t}\n\t\tif (lhsType.isPrimitive()) {\n\t\t\tClass<?> resolvedPrimitive = primitiveWrapperTypeMap.get(rhsType);\n\t\t\treturn (lhsType == resolvedPrimitive);\n\t\t}\n\t\telse {\n\t\t\tClass<?> resolvedWrapper = primitiveTypeToWrapperMap.get(rhsType);\n\t\t\treturn (resolvedWrapper != null && lhsType.isAssignableFrom(resolvedWrapper));\n\t\t}\n\t}", "summary_tokens": ["check", "if", "the", "right", "hand", "side", "type", "may", "be", "assigned", "to", "the", "left", "hand", "side", "type", "assuming", "setting", "by", "reflection"], "project": "spring-framework"}
{"id": 2081, "code": "\tpublic void testProxyConfigString() {\n\t\tTestBean target = new TestBean();\n\t\tProxyFactory pc = new ProxyFactory(target);\n\t\tpc.setInterfaces(ITestBean.class);\n\t\tpc.addAdvice(new NopInterceptor());\n\t\tMethodBeforeAdvice mba = new CountingBeforeAdvice();\n\t\tAdvisor advisor = new DefaultPointcutAdvisor(new NameMatchMethodPointcut(), mba);\n\t\tpc.addAdvisor(advisor);\n\t\tITestBean proxied = (ITestBean) createProxy(pc);\n\n\t\tString proxyConfigString = ((Advised) proxied).toProxyConfigString();\n\t\tassertThat(proxyConfigString.contains(advisor.toString())).isTrue();\n\t\tassertThat(proxyConfigString.contains(\"1 interface\")).isTrue();\n\t}", "summary_tokens": ["check", "that", "the", "string", "is", "informative"], "project": "spring-framework"}
{"id": 3100, "code": "\tpublic static void isNull(@Nullable Object object) {\n\t\tisNull(object, \"[Assertion failed] - the object argument must be null\");\n\t}", "summary_tokens": ["assert", "that", "an", "object", "is", "null"], "project": "spring-framework"}
{"id": 9288, "code": "\tpublic void setLang(String lang) {\n\t\tthis.lang = lang;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "lang", "attribute"], "project": "spring-framework"}
{"id": 3082, "code": "\tpublic final Class<? extends Annotation> getAnnotationType() {\n\t\treturn this.annotationType;\n\t}", "summary_tokens": ["return", "the", "annotation", "that", "this", "instance", "is", "using", "to", "filter", "candidates"], "project": "spring-framework"}
{"id": 187, "code": "\tprotected String replacePlaceholders(String message, MethodInvocation methodInvocation,\n\t\t\t@Nullable Object returnValue, @Nullable Throwable throwable, long invocationTime) {\n\n\t\tMatcher matcher = PATTERN.matcher(message);\n\t\tObject target = methodInvocation.getThis();\n\t\tAssert.state(target != null, \"Target must not be null\");\n\n\t\tStringBuilder output = new StringBuilder();\n\t\twhile (matcher.find()) {\n\t\t\tString match = matcher.group();\n\t\t\tif (PLACEHOLDER_METHOD_NAME.equals(match)) {\n\t\t\t\tmatcher.appendReplacement(output, Matcher.quoteReplacement(methodInvocation.getMethod().getName()));\n\t\t\t}\n\t\t\telse if (PLACEHOLDER_TARGET_CLASS_NAME.equals(match)) {\n\t\t\t\tString className = getClassForLogging(target).getName();\n\t\t\t\tmatcher.appendReplacement(output, Matcher.quoteReplacement(className));\n\t\t\t}\n\t\t\telse if (PLACEHOLDER_TARGET_CLASS_SHORT_NAME.equals(match)) {\n\t\t\t\tString shortName = ClassUtils.getShortName(getClassForLogging(target));\n\t\t\t\tmatcher.appendReplacement(output, Matcher.quoteReplacement(shortName));\n\t\t\t}\n\t\t\telse if (PLACEHOLDER_ARGUMENTS.equals(match)) {\n\t\t\t\tmatcher.appendReplacement(output,\n\t\t\t\t\t\tMatcher.quoteReplacement(StringUtils.arrayToCommaDelimitedString(methodInvocation.getArguments())));\n\t\t\t}\n\t\t\telse if (PLACEHOLDER_ARGUMENT_TYPES.equals(match)) {\n\t\t\t\tappendArgumentTypes(methodInvocation, matcher, output);\n\t\t\t}\n\t\t\telse if (PLACEHOLDER_RETURN_VALUE.equals(match)) {\n\t\t\t\tappendReturnValue(methodInvocation, matcher, output, returnValue);\n\t\t\t}\n\t\t\telse if (throwable != null && PLACEHOLDER_EXCEPTION.equals(match)) {\n\t\t\t\tmatcher.appendReplacement(output, Matcher.quoteReplacement(throwable.toString()));\n\t\t\t}\n\t\t\telse if (PLACEHOLDER_INVOCATION_TIME.equals(match)) {\n\t\t\t\tmatcher.appendReplacement(output, Long.toString(invocationTime));\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\tthrow new IllegalArgumentException(\"Unknown placeholder [\" + match + \"]\");\n\t\t\t}\n\t\t}\n\t\tmatcher.appendTail(output);\n\n\t\treturn output.toString();\n\t}", "summary_tokens": ["replace", "the", "placeholders", "in", "the", "given", "message", "with", "the", "supplied", "values", "or", "values", "derived", "from", "those", "supplied"], "project": "spring-framework"}
{"id": 2561, "code": "Symbol getType(final int typeIndex) {\n  return typeTable[typeIndex];\n}", "summary_tokens": ["returns", "the", "type", "table", "element", "whose", "index", "is", "given"], "project": "spring-framework"}
{"id": 250, "code": "\tpublic int getMaxSize() {\n\t\treturn this.maxSize;\n\t}", "summary_tokens": ["return", "the", "maximum", "size", "of", "the", "pool"], "project": "spring-framework"}
{"id": 5308, "code": "\tpublic boolean isProcessExternalEntities() {\n\t\treturn this.processExternalEntities;\n\t}", "summary_tokens": ["return", "whether", "xml", "external", "entities", "are", "allowed"], "project": "spring-framework"}
{"id": 9683, "code": "\tprotected Template getTemplate(String name, Locale locale) throws IOException {\n\t\treturn (getEncoding() != null ?\n\t\t\t\tobtainConfiguration().getTemplate(name, locale, getEncoding()) :\n\t\t\t\tobtainConfiguration().getTemplate(name, locale));\n\t}", "summary_tokens": ["retrieve", "the", "free", "marker", "template", "specified", "by", "the", "given", "name", "using", "the", "encoding", "specified", "by", "the", "encoding", "bean", "property"], "project": "spring-framework"}
{"id": 5881, "code": "\tpublic WebTestClient.ResponseSpec values(String name, Consumer<List<String>> consumer) {\n\t\tList<String> values = getRequiredValues(name);\n\t\tthis.exchangeResult.assertWithDiagnostics(() -> consumer.accept(values));\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["consume", "all", "values", "of", "the", "named", "response", "header"], "project": "spring-framework"}
{"id": 854, "code": "\tpublic final ResourceLoader getResourceLoader() {\n\t\treturn this.reader.getResourceLoader();\n\t}", "summary_tokens": ["return", "the", "resource", "loader", "to", "use", "if", "any"], "project": "spring-framework"}
{"id": 1902, "code": "\tpublic static BeanDefinition registerScriptFactoryPostProcessorIfNecessary(BeanDefinitionRegistry registry) {\n\t\tBeanDefinition beanDefinition;\n\t\tif (registry.containsBeanDefinition(SCRIPT_FACTORY_POST_PROCESSOR_BEAN_NAME)) {\n\t\t\tbeanDefinition = registry.getBeanDefinition(SCRIPT_FACTORY_POST_PROCESSOR_BEAN_NAME);\n\t\t}\n\t\telse {\n\t\t\tbeanDefinition = new RootBeanDefinition(ScriptFactoryPostProcessor.class);\n\t\t\tregistry.registerBeanDefinition(SCRIPT_FACTORY_POST_PROCESSOR_BEAN_NAME, beanDefinition);\n\t\t}\n\t\treturn beanDefinition;\n\t}", "summary_tokens": ["register", "a", "script", "factory", "post", "processor", "bean", "definition", "in", "the", "supplied", "bean", "definition", "registry", "if", "the", "script", "factory", "post", "processor", "hasn", "t", "already", "been", "registered"], "project": "spring-framework"}
{"id": 9320, "code": "\tprotected String resolveCssClass() throws JspException {\n\t\tif (getBindStatus().isError() && StringUtils.hasText(getCssErrorClass())) {\n\t\t\treturn ObjectUtils.getDisplayString(evaluate(\"cssErrorClass\", getCssErrorClass()));\n\t\t}\n\t\telse {\n\t\t\treturn ObjectUtils.getDisplayString(evaluate(\"cssClass\", getCssClass()));\n\t\t}\n\t}", "summary_tokens": ["gets", "the", "appropriate", "css", "class", "to", "use", "based", "on", "the", "state", "of", "the", "current", "org"], "project": "spring-framework"}
{"id": 8143, "code": "\tdefault RouterFunction<T> withAttribute(String name, Object value) {\n\t\tAssert.hasLength(name, \"Name must not be empty\");\n\t\tAssert.notNull(value, \"Value must not be null\");\n\n\t\tMap<String, Object> attributes = new LinkedHashMap<>();\n\t\tattributes.put(name, value);\n\t\treturn new RouterFunctions.AttributesRouterFunction<>(this, attributes);\n\t}", "summary_tokens": ["return", "a", "new", "routing", "function", "with", "the", "given", "attribute"], "project": "spring-framework"}
{"id": 7675, "code": "\tdefault Builder mutate() {\n\t\treturn new DefaultServerWebExchangeBuilder(this);\n\t}", "summary_tokens": ["return", "a", "builder", "to", "mutate", "properties", "of", "this", "exchange", "by", "wrapping", "it", "with", "server", "web", "exchange", "decorator", "and", "returning", "either", "mutated", "values", "or", "delegating", "back", "to", "this", "instance"], "project": "spring-framework"}
{"id": 3231, "code": "\tpublic Class<?> getTargetClass() {\n\t\treturn this.targetClass;\n\t}", "summary_tokens": ["return", "the", "target", "class", "on", "which", "to", "call", "the", "target", "method"], "project": "spring-framework"}
{"id": 7547, "code": "\tprivate Object handleNullValue(String name, @Nullable Object value, Class<?> paramType) {\n\t\tif (value == null) {\n\t\t\tif (Boolean.TYPE.equals(paramType)) {\n\t\t\t\treturn Boolean.FALSE;\n\t\t\t}\n\t\t\telse if (paramType.isPrimitive()) {\n\t\t\t\tthrow new IllegalStateException(\"Optional \" + paramType.getSimpleName() + \" parameter '\" + name +\n\t\t\t\t\t\t\"' is present but cannot be translated into a null value due to being declared as a \" +\n\t\t\t\t\t\t\"primitive type. Consider declaring it as object wrapper for the corresponding primitive type.\");\n\t\t\t}\n\t\t}\n\t\treturn value;\n\t}", "summary_tokens": ["a", "null", "results", "in", "a", "false", "value", "for", "boolean", "s", "or", "an", "exception", "for", "other", "primitives"], "project": "spring-framework"}
{"id": 8601, "code": "\tpublic InterceptorRegistration excludePathPatterns(List<String> patterns) {\n\t\tthis.excludePatterns = (this.excludePatterns != null ?\n\t\t\t\tthis.excludePatterns : new ArrayList<>(patterns.size()));\n\t\tthis.excludePatterns.addAll(patterns);\n\t\treturn this;\n\t}", "summary_tokens": ["list", "based", "variant", "of", "exclude", "path", "patterns", "string"], "project": "spring-framework"}
{"id": 6381, "code": "\tprotected Mono<Void> processResourceAfterCommit(O resourceHolder) {\n\t\treturn Mono.empty();\n\t}", "summary_tokens": ["after", "commit", "callback", "for", "the", "given", "resource", "holder"], "project": "spring-framework"}
{"id": 3529, "code": "\tpublic static boolean isReferenceTypeArray(String arraytype) {\n\t\tint length = arraytype.length();\n\t\tfor (int i = 0; i < length; i++) {\n\t\t\tchar ch = arraytype.charAt(i);\n\t\t\tif (ch == '[') {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\treturn (ch == 'L');\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["return", "if", "the", "supplied", "array", "type", "has", "a", "core", "component", "reference", "type"], "project": "spring-framework"}
{"id": 29, "code": "\tpublic Object getTarget() {\n\t\treturn this.methodInvocation.getThis();\n\t}", "summary_tokens": ["returns", "the", "spring", "aop", "target"], "project": "spring-framework"}
{"id": 953, "code": "\tpublic Set<Object> keySet() {\n\t\tSet<Object> sortedKeys = new TreeSet<>(keyComparator);\n\t\tsortedKeys.addAll(super.keySet());\n\t\treturn Collections.synchronizedSet(sortedKeys);\n\t}", "summary_tokens": ["return", "a", "sorted", "set", "of", "the", "keys", "in", "this", "properties", "object"], "project": "spring-framework"}
{"id": 2024, "code": "\tpublic final ConfigurablePropertyAccessor getPropertyAccessor() {\n\t\tif (this.directFieldAccessor == null) {\n\t\t\tthis.directFieldAccessor = createDirectFieldAccessor();\n\t\t\tthis.directFieldAccessor.setExtractOldValueForEditor(true);\n\t\t\tthis.directFieldAccessor.setAutoGrowNestedPaths(this.autoGrowNestedPaths);\n\t\t}\n\t\treturn this.directFieldAccessor;\n\t}", "summary_tokens": ["returns", "the", "direct", "field", "accessor", "that", "this", "instance", "uses"], "project": "spring-framework"}
{"id": 1158, "code": "\tprotected TemplateLoader getAggregateTemplateLoader(List<TemplateLoader> templateLoaders) {\n\t\tswitch (templateLoaders.size()) {\n\t\t\tcase 0:\n\t\t\t\tlogger.debug(\"No FreeMarker TemplateLoaders specified\");\n\t\t\t\treturn null;\n\t\t\tcase 1:\n\t\t\t\treturn templateLoaders.get(0);\n\t\t\tdefault:\n\t\t\t\tTemplateLoader[] loaders = templateLoaders.toArray(new TemplateLoader[0]);\n\t\t\t\treturn new MultiTemplateLoader(loaders);\n\t\t}\n\t}", "summary_tokens": ["return", "a", "template", "loader", "based", "on", "the", "given", "template", "loader", "list"], "project": "spring-framework"}
{"id": 420, "code": "\tprotected boolean checkQualifier(\n\t\t\tBeanDefinitionHolder bdHolder, Annotation annotation, TypeConverter typeConverter) {\n\n\t\tClass<? extends Annotation> type = annotation.annotationType();\n\t\tRootBeanDefinition bd = (RootBeanDefinition) bdHolder.getBeanDefinition();\n\n\t\tAutowireCandidateQualifier qualifier = bd.getQualifier(type.getName());\n\t\tif (qualifier == null) {\n\t\t\tqualifier = bd.getQualifier(ClassUtils.getShortName(type));\n\t\t}\n\t\tif (qualifier == null) {\n\t\t\t\n\t\t\tAnnotation targetAnnotation = getQualifiedElementAnnotation(bd, type);\n\t\t\t\n\t\t\tif (targetAnnotation == null) {\n\t\t\t\ttargetAnnotation = getFactoryMethodAnnotation(bd, type);\n\t\t\t}\n\t\t\tif (targetAnnotation == null) {\n\t\t\t\tRootBeanDefinition dbd = getResolvedDecoratedDefinition(bd);\n\t\t\t\tif (dbd != null) {\n\t\t\t\t\ttargetAnnotation = getFactoryMethodAnnotation(dbd, type);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (targetAnnotation == null) {\n\t\t\t\t\n\t\t\t\tif (getBeanFactory() != null) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tClass<?> beanType = getBeanFactory().getType(bdHolder.getBeanName());\n\t\t\t\t\t\tif (beanType != null) {\n\t\t\t\t\t\t\ttargetAnnotation = AnnotationUtils.getAnnotation(ClassUtils.getUserClass(beanType), type);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (targetAnnotation == null && bd.hasBeanClass()) {\n\t\t\t\t\ttargetAnnotation = AnnotationUtils.getAnnotation(ClassUtils.getUserClass(bd.getBeanClass()), type);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (targetAnnotation != null && targetAnnotation.equals(annotation)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\tMap<String, Object> attributes = AnnotationUtils.getAnnotationAttributes(annotation);\n\t\tif (attributes.isEmpty() && qualifier == null) {\n\t\t\t\n\t\t\treturn false;\n\t\t}\n\t\tfor (Map.Entry<String, Object> entry : attributes.entrySet()) {\n\t\t\tString attributeName = entry.getKey();\n\t\t\tObject expectedValue = entry.getValue();\n\t\t\tObject actualValue = null;\n\t\t\t\n\t\t\tif (qualifier != null) {\n\t\t\t\tactualValue = qualifier.getAttribute(attributeName);\n\t\t\t}\n\t\t\tif (actualValue == null) {\n\t\t\t\t\n\t\t\t\tactualValue = bd.getAttribute(attributeName);\n\t\t\t}\n\t\t\tif (actualValue == null && attributeName.equals(AutowireCandidateQualifier.VALUE_KEY) &&\n\t\t\t\t\texpectedValue instanceof String && bdHolder.matchesName((String) expectedValue)) {\n\t\t\t\t\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (actualValue == null && qualifier != null) {\n\t\t\t\t\n\t\t\t\tactualValue = AnnotationUtils.getDefaultValue(annotation, attributeName);\n\t\t\t}\n\t\t\tif (actualValue != null) {\n\t\t\t\tactualValue = typeConverter.convertIfNecessary(actualValue, expectedValue.getClass());\n\t\t\t}\n\t\t\tif (!expectedValue.equals(actualValue)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["match", "the", "given", "qualifier", "annotation", "against", "the", "candidate", "bean", "definition"], "project": "spring-framework"}
{"id": 1353, "code": "\tprotected String resolveCodeWithoutArguments(String code, Locale locale) {\n\t\tMessageFormat messageFormat = resolveCode(code, locale);\n\t\tif (messageFormat != null) {\n\t\t\tsynchronized (messageFormat) {\n\t\t\t\treturn messageFormat.format(new Object[0]);\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["subclasses", "can", "override", "this", "method", "to", "resolve", "a", "message", "without", "arguments", "in", "an", "optimized", "fashion", "i"], "project": "spring-framework"}
{"id": 8342, "code": "\tpublic boolean isError() {\n\t\treturn (this.errorCodes.length > 0);\n\t}", "summary_tokens": ["return", "if", "this", "status", "represents", "a", "field", "or", "object", "error"], "project": "spring-framework"}
{"id": 7989, "code": "\tpublic CorsRegistration maxAge(long maxAge) {\n\t\tthis.config.setMaxAge(maxAge);\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "how", "long", "in", "seconds", "the", "response", "from", "a", "pre", "flight", "request", "can", "be", "cached", "by", "clients"], "project": "spring-framework"}
{"id": 5091, "code": "\tpublic void addNativeHeaders(@Nullable MultiValueMap<String, String> headers) {\n\t\tif (headers == null) {\n\t\t\treturn;\n\t\t}\n\t\theaders.forEach((key, values) -> values.forEach(value -> addNativeHeader(key, value)));\n\t}", "summary_tokens": ["add", "the", "specified", "native", "headers", "to", "existing", "values"], "project": "spring-framework"}
{"id": 2150, "code": "\tpublic void addObject(String name, Object object) {\n\t\tthis.jndiObjects.put(name, object);\n\t}", "summary_tokens": ["add", "the", "given", "object", "to", "the", "list", "of", "jndi", "objects", "that", "this", "template", "will", "expose"], "project": "spring-framework"}
{"id": 879, "code": "\tpublic Date getRefreshDate() {\n\t\treturn this.refreshDate;\n\t}", "summary_tokens": ["return", "the", "last", "time", "the", "list", "has", "been", "fetched", "from", "the", "source", "provider"], "project": "spring-framework"}
{"id": 4178, "code": "\tpublic String getIncrementerName() {\n\t\treturn this.incrementerName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "sequence", "table"], "project": "spring-framework"}
{"id": 6062, "code": "\tpublic ResultMatcher isMultiStatus() {\n\t\treturn matcher(HttpStatus.MULTI_STATUS);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 1409, "code": "\tprotected final void closeBeanFactory() {\n\t\tthis.beanFactory.setSerializationId(null);\n\t}", "summary_tokens": ["not", "much", "to", "do", "we", "hold", "a", "single", "internal", "bean", "factory", "that", "will", "never", "get", "released"], "project": "spring-framework"}
{"id": 3824, "code": "\tdefault String[] getParameterNames() {\n\t\treturn null;\n\t}", "summary_tokens": ["enumerate", "all", "available", "parameter", "names", "if", "possible"], "project": "spring-framework"}
{"id": 2143, "code": "\tpublic Object invoke(MethodInvocation invocation) throws Throwable {\n\t\tif (locked() && invocation.getMethod().getName().indexOf(\"set\") == 0) {\n\t\t\tthrow new LockedException();\n\t\t}\n\t\treturn super.invoke(invocation);\n\t}", "summary_tokens": ["note", "that", "we", "need", "to", "override", "around", "advice"], "project": "spring-framework"}
{"id": 8436, "code": "\tpublic void setRenderObject(String renderObject) {\n\t\tthis.renderObject = renderObject;\n\t}", "summary_tokens": ["see", "script", "template", "configurer", "set", "render", "object", "string", "documentation"], "project": "spring-framework"}
{"id": 8626, "code": "\tpublic ResourceChainRegistration addResolver(ResourceResolver resolver) {\n\t\tAssert.notNull(resolver, \"The provided ResourceResolver should not be null\");\n\t\tthis.resolvers.add(resolver);\n\t\tif (resolver instanceof VersionResourceResolver) {\n\t\t\tthis.hasVersionResolver = true;\n\t\t}\n\t\telse if (resolver instanceof PathResourceResolver) {\n\t\t\tthis.hasPathResolver = true;\n\t\t}\n\t\telse if (resolver instanceof WebJarsResourceResolver) {\n\t\t\tthis.hasWebjarsResolver = true;\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "resource", "resolver", "to", "the", "chain"], "project": "spring-framework"}
{"id": 2706, "code": "\tprotected boolean isExcluded(String className) {\n\t\tif (this.excludedClasses.contains(className)) {\n\t\t\treturn true;\n\t\t}\n\t\tfor (String packageName : this.excludedPackages) {\n\t\t\tif (className.startsWith(packageName)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "whether", "the", "specified", "class", "is", "excluded", "from", "decoration", "by", "this", "class", "loader"], "project": "spring-framework"}
{"id": 6826, "code": "\tdefault List<MediaType> getReadableMediaTypes(ResolvableType elementType) {\n\t\treturn (canRead(elementType, null) ? getReadableMediaTypes() : Collections.emptyList());\n\t}", "summary_tokens": ["return", "the", "list", "of", "media", "types", "supported", "by", "this", "reader", "for", "the", "given", "type", "of", "element"], "project": "spring-framework"}
{"id": 7528, "code": "\tprotected WebApplicationContext getWebApplicationContext(FacesContext facesContext) {\n\t\treturn FacesContextUtils.getRequiredWebApplicationContext(facesContext);\n\t}", "summary_tokens": ["retrieve", "the", "web", "application", "context", "to", "delegate", "bean", "name", "resolution", "to"], "project": "spring-framework"}
{"id": 7170, "code": "\tpublic static double getDoubleParameter(ServletRequest request, String name, double defaultVal) {\n\t\tif (request.getParameter(name) == null) {\n\t\t\treturn defaultVal;\n\t\t}\n\t\ttry {\n\t\t\treturn getRequiredDoubleParameter(request, name);\n\t\t}\n\t\tcatch (ServletRequestBindingException ex) {\n\t\t\treturn defaultVal;\n\t\t}\n\t}", "summary_tokens": ["get", "a", "double", "parameter", "with", "a", "fallback", "value"], "project": "spring-framework"}
{"id": 18, "code": "\tprivate void maybeBindThisOrTargetOrArgsFromPointcutExpression() {\n\t\tif (this.numberOfRemainingUnboundArguments > 1) {\n\t\t\tthrow new AmbiguousBindingException(\"Still \" + this.numberOfRemainingUnboundArguments\n\t\t\t\t\t+ \" unbound args at this(),target(),args() binding stage, with no way to determine between them\");\n\t\t}\n\n\t\tList<String> varNames = new ArrayList<>();\n\t\tString[] tokens = StringUtils.tokenizeToStringArray(this.pointcutExpression, \" \");\n\t\tfor (int i = 0; i < tokens.length; i++) {\n\t\t\tif (tokens[i].equals(\"this\") ||\n\t\t\t\t\ttokens[i].startsWith(\"this(\") ||\n\t\t\t\t\ttokens[i].equals(\"target\") ||\n\t\t\t\t\ttokens[i].startsWith(\"target(\")) {\n\t\t\t\tPointcutBody body = getPointcutBody(tokens, i);\n\t\t\t\ti += body.numTokensConsumed;\n\t\t\t\tString varName = maybeExtractVariableName(body.text);\n\t\t\t\tif (varName != null) {\n\t\t\t\t\tvarNames.add(varName);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (tokens[i].equals(\"args\") || tokens[i].startsWith(\"args(\")) {\n\t\t\t\tPointcutBody body = getPointcutBody(tokens, i);\n\t\t\t\ti += body.numTokensConsumed;\n\t\t\t\tList<String> candidateVarNames = new ArrayList<>();\n\t\t\t\tmaybeExtractVariableNamesFromArgs(body.text, candidateVarNames);\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tfor (String varName : candidateVarNames) {\n\t\t\t\t\tif (!alreadyBound(varName)) {\n\t\t\t\t\t\tvarNames.add(varName);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\n\t\tif (varNames.size() > 1) {\n\t\t\tthrow new AmbiguousBindingException(\"Found \" + varNames.size() +\n\t\t\t\t\t\" candidate this(), target() or args() variables but only one unbound argument slot\");\n\t\t}\n\t\telse if (varNames.size() == 1) {\n\t\t\tfor (int j = 0; j < this.parameterNameBindings.length; j++) {\n\t\t\t\tif (isUnbound(j)) {\n\t\t\t\t\tbindParameterName(j, varNames.get(0));\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t}", "summary_tokens": ["parse", "the", "string", "pointcut", "expression", "looking", "for", "this", "target", "and", "args", "expressions"], "project": "spring-framework"}
{"id": 6815, "code": "\tprotected MediaType getContentType(HttpMessage inputMessage) {\n\t\tMediaType contentType = inputMessage.getHeaders().getContentType();\n\t\treturn (contentType != null ? contentType : MediaType.APPLICATION_OCTET_STREAM);\n\t}", "summary_tokens": ["determine", "the", "content", "type", "of", "the", "http", "message", "based", "on", "the", "content", "type", "header", "or", "otherwise", "default", "to", "media", "type", "application", "octet", "stream"], "project": "spring-framework"}
{"id": 2447, "code": "public String toString() {\n  return owner + '.' + name + descriptor + \" (\" + tag + (isInterface ? \" itf\" : \"\") + ')';\n}", "summary_tokens": ["returns", "the", "textual", "representation", "of", "this", "handle"], "project": "spring-framework"}
{"id": 5975, "code": "\tpublic ResultMatcher path(String name, String path) {\n\t\treturn result -> {\n\t\t\tCookie cookie = getCookie(result, name);\n\t\t\tassertEquals(\"Response cookie '\" + name + \"' path\", path, cookie.getPath());\n\t\t};\n\t}", "summary_tokens": ["assert", "a", "cookie", "s", "path"], "project": "spring-framework"}
{"id": 1920, "code": "\tpublic void setDefaultProxyTargetClass(boolean defaultProxyTargetClass) {\n\t\tthis.defaultProxyTargetClass = defaultProxyTargetClass;\n\t}", "summary_tokens": ["flag", "to", "signal", "that", "refreshable", "proxies", "should", "be", "created", "to", "proxy", "the", "target", "class", "not", "its", "interfaces"], "project": "spring-framework"}
{"id": 9745, "code": "\tpublic static List<WebSocketExtension> parseExtensions(String extensions) {\n\t\tif (StringUtils.hasText(extensions)) {\n\t\t\tString[] tokens = StringUtils.tokenizeToStringArray(extensions, \",\");\n\t\t\tList<WebSocketExtension> result = new ArrayList<>(tokens.length);\n\t\t\tfor (String token : tokens) {\n\t\t\t\tresult.add(parseExtension(token));\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t\telse {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t}", "summary_tokens": ["parse", "the", "given", "comma", "separated", "string", "into", "a", "list", "of", "web", "socket", "extension", "objects"], "project": "spring-framework"}
{"id": 2005, "code": "\tpublic List<Validator> getValidators() {\n\t\treturn Collections.unmodifiableList(this.validators);\n\t}", "summary_tokens": ["return", "the", "validators", "to", "apply", "after", "data", "binding"], "project": "spring-framework"}
{"id": 1017, "code": "\tpublic String getContentType(String fileName) {\n\t\treturn getFileTypeMap().getContentType(fileName);\n\t}", "summary_tokens": ["delegates", "to", "the", "underlying", "file", "type", "map"], "project": "spring-framework"}
{"id": 1276, "code": "\tpublic void addIncludeFilter(TypeFilter includeFilter) {\n\t\tthis.includeFilters.add(includeFilter);\n\t}", "summary_tokens": ["add", "an", "include", "type", "filter", "to", "the", "i", "end", "i", "of", "the", "inclusion", "list"], "project": "spring-framework"}
{"id": 406, "code": "\tdefault Stream<T> orderedStream() {\n\t\tthrow new UnsupportedOperationException(\"Ordered element access not supported\");\n\t}", "summary_tokens": ["return", "a", "sequential", "stream", "over", "all", "matching", "object", "instances", "pre", "ordered", "according", "to", "the", "factory", "s", "common", "order", "comparator"], "project": "spring-framework"}
{"id": 6986, "code": "\tpublic static Jackson2ObjectMapperBuilder cbor() {\n\t\treturn new Jackson2ObjectMapperBuilder().factory(new CborFactoryInitializer().create());\n\t}", "summary_tokens": ["obtain", "a", "jackson", "0", "object", "mapper", "builder", "instance", "in", "order", "to", "build", "a", "cbor", "data", "format", "object", "mapper", "instance"], "project": "spring-framework"}
{"id": 8262, "code": "\tprivate HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) {\n\t\tHandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter);\n\t\tif (result == null) {\n\t\t\tfor (HandlerMethodArgumentResolver methodArgumentResolver : this.argumentResolvers) {\n\t\t\t\tif (methodArgumentResolver.supportsParameter(parameter)) {\n\t\t\t\t\tresult = methodArgumentResolver;\n\t\t\t\t\tthis.argumentResolverCache.put(parameter, result);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["find", "a", "registered", "handler", "method", "argument", "resolver", "that", "supports", "the", "given", "method", "parameter"], "project": "spring-framework"}
{"id": 5470, "code": "\tpublic final HttpHeaders getHeaders() {\n\t\treturn this.headers;\n\t}", "summary_tokens": ["return", "the", "http", "headers", "backing", "header", "related", "accessor", "methods", "allowing", "for", "populating", "selected", "header", "entries"], "project": "spring-framework"}
{"id": 843, "code": "\tprotected Document doLoadDocument(InputSource inputSource, Resource resource) throws Exception {\n\t\treturn this.documentLoader.loadDocument(inputSource, getEntityResolver(), this.errorHandler,\n\t\t\t\tgetValidationModeForResource(resource), isNamespaceAware());\n\t}", "summary_tokens": ["actually", "load", "the", "specified", "document", "using", "the", "configured", "document", "loader"], "project": "spring-framework"}
{"id": 6021, "code": "\tpublic static HeaderResultMatchers header() {\n\t\treturn new HeaderResultMatchers();\n\t}", "summary_tokens": ["access", "to", "response", "header", "assertions"], "project": "spring-framework"}
{"id": 8844, "code": "\tpublic void setHttpMethods(@Nullable String... httpMethods) {\n\t\tthis.httpMethods = httpMethods;\n\t}", "summary_tokens": ["configure", "the", "http", "method", "s", "over", "which", "the", "locale", "can", "be", "changed"], "project": "spring-framework"}
{"id": 9280, "code": "\tprotected void removeAttributes() {\n\t}", "summary_tokens": ["called", "by", "do", "finally", "allowing", "subclasses", "to", "remove", "any", "attributes", "from", "the", "jakarta"], "project": "spring-framework"}
{"id": 2716, "code": "\tpublic static String buildMessage(@Nullable String message, @Nullable Throwable cause) {\n\t\tif (cause == null) {\n\t\t\treturn message;\n\t\t}\n\t\tStringBuilder sb = new StringBuilder(64);\n\t\tif (message != null) {\n\t\t\tsb.append(message).append(\"; \");\n\t\t}\n\t\tsb.append(\"nested exception is \").append(cause);\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["build", "a", "message", "for", "the", "given", "base", "message", "and", "root", "cause"], "project": "spring-framework"}
{"id": 1779, "code": "\tpublic void setAsyncAnnotationType(Class<? extends Annotation> asyncAnnotationType) {\n\t\tAssert.notNull(asyncAnnotationType, \"'asyncAnnotationType' must not be null\");\n\t\tSet<Class<? extends Annotation>> asyncAnnotationTypes = new HashSet<>();\n\t\tasyncAnnotationTypes.add(asyncAnnotationType);\n\t\tthis.pointcut = buildPointcut(asyncAnnotationTypes);\n\t}", "summary_tokens": ["set", "the", "async", "annotation", "type"], "project": "spring-framework"}
{"id": 4080, "code": "\tpublic void setSql(@Nullable String sql) {\n\t\tthis.sql = sql;\n\t}", "summary_tokens": ["set", "the", "sql", "executed", "by", "this", "operation"], "project": "spring-framework"}
{"id": 7320, "code": "\tpublic void startDeferredResultProcessing(\n\t\t\tfinal DeferredResult<?> deferredResult, Object... processingContext) throws Exception {\n\n\t\tAssert.notNull(deferredResult, \"DeferredResult must not be null\");\n\t\tAssert.state(this.asyncWebRequest != null, \"AsyncWebRequest must not be null\");\n\n\t\tLong timeout = deferredResult.getTimeoutValue();\n\t\tif (timeout != null) {\n\t\t\tthis.asyncWebRequest.setTimeout(timeout);\n\t\t}\n\n\t\tList<DeferredResultProcessingInterceptor> interceptors = new ArrayList<>();\n\t\tinterceptors.add(deferredResult.getInterceptor());\n\t\tinterceptors.addAll(this.deferredResultInterceptors.values());\n\t\tinterceptors.add(timeoutDeferredResultInterceptor);\n\n\t\tfinal DeferredResultInterceptorChain interceptorChain = new DeferredResultInterceptorChain(interceptors);\n\n\t\tthis.asyncWebRequest.addTimeoutHandler(() -> {\n\t\t\ttry {\n\t\t\t\tinterceptorChain.triggerAfterTimeout(this.asyncWebRequest, deferredResult);\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tsetConcurrentResultAndDispatch(ex);\n\t\t\t}\n\t\t});\n\n\t\tthis.asyncWebRequest.addErrorHandler(ex -> {\n\t\t\tif (!this.errorHandlingInProgress) {\n\t\t\t\ttry {\n\t\t\t\t\tif (!interceptorChain.triggerAfterError(this.asyncWebRequest, deferredResult, ex)) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tdeferredResult.setErrorResult(ex);\n\t\t\t\t}\n\t\t\t\tcatch (Throwable interceptorEx) {\n\t\t\t\t\tsetConcurrentResultAndDispatch(interceptorEx);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\n\t\tthis.asyncWebRequest.addCompletionHandler(()\n\t\t\t\t-> interceptorChain.triggerAfterCompletion(this.asyncWebRequest, deferredResult));\n\n\t\tinterceptorChain.applyBeforeConcurrentHandling(this.asyncWebRequest, deferredResult);\n\t\tstartAsyncProcessing(processingContext);\n\n\t\ttry {\n\t\t\tinterceptorChain.applyPreProcess(this.asyncWebRequest, deferredResult);\n\t\t\tdeferredResult.setResultHandler(result -> {\n\t\t\t\tresult = interceptorChain.applyPostProcess(this.asyncWebRequest, deferredResult, result);\n\t\t\t\tsetConcurrentResultAndDispatch(result);\n\t\t\t});\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tsetConcurrentResultAndDispatch(ex);\n\t\t}\n\t}", "summary_tokens": ["start", "concurrent", "request", "processing", "and", "initialize", "the", "given", "deferred", "result", "with", "a", "deferred", "result", "handler", "that", "saves", "the", "result", "and", "dispatches", "the", "request", "to", "resume", "processing", "of", "that", "result"], "project": "spring-framework"}
{"id": 7254, "code": "\tpublic void setRestTemplate(RestTemplate restTemplate) {\n\t\tAssert.notNull(restTemplate, \"'restTemplate' must not be null\");\n\t\tthis.restTemplate = restTemplate;\n\t}", "summary_tokens": ["sets", "the", "rest", "template", "for", "the", "gateway"], "project": "spring-framework"}
{"id": 5202, "code": "\tprotected Session openSession() throws DataAccessResourceFailureException {\n\t\ttry {\n\t\t\tSession session = obtainSessionFactory().openSession();\n\t\t\tsession.setHibernateFlushMode(FlushMode.MANUAL);\n\t\t\treturn session;\n\t\t}\n\t\tcatch (HibernateException ex) {\n\t\t\tthrow new DataAccessResourceFailureException(\"Could not open Hibernate Session\", ex);\n\t\t}\n\t}", "summary_tokens": ["open", "a", "session", "for", "the", "session", "factory", "that", "this", "interceptor", "uses"], "project": "spring-framework"}
{"id": 6287, "code": "\tpublic void setTransactionInterceptor(TransactionInterceptor interceptor) {\n\t\tthis.transactionInterceptor = interceptor;\n\t}", "summary_tokens": ["set", "the", "transaction", "interceptor", "to", "use", "for", "this", "advisor"], "project": "spring-framework"}
{"id": 7886, "code": "\tpublic boolean isMatchOptionalTrailingSeparator() {\n\t\treturn this.matchOptionalTrailingSeparator;\n\t}", "summary_tokens": ["whether", "optional", "trailing", "slashing", "match", "is", "enabled"], "project": "spring-framework"}
{"id": 2939, "code": "\tpublic InputStream getInputStream() throws IOException {\n\t\ttry {\n\t\t\treturn Files.newInputStream(this.filePath);\n\t\t}\n\t\tcatch (NoSuchFileException ex) {\n\t\t\tthrow new FileNotFoundException(ex.getMessage());\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "opens", "a", "nio", "file", "stream", "for", "the", "underlying", "file"], "project": "spring-framework"}
{"id": 7673, "code": "\tdefault <T> T getRequiredAttribute(String name) {\n\t\tT value = getAttribute(name);\n\t\tAssert.notNull(value, () -> \"Required attribute '\" + name + \"' is missing\");\n\t\treturn value;\n\t}", "summary_tokens": ["return", "the", "request", "attribute", "value", "or", "if", "not", "present", "raise", "an", "illegal", "argument", "exception"], "project": "spring-framework"}
{"id": 4033, "code": "\tpublic void addScripts(Resource... scripts) {\n\t\tassertContentsOfScriptArray(scripts);\n\t\tthis.scripts.addAll(Arrays.asList(scripts));\n\t}", "summary_tokens": ["add", "multiple", "scripts", "to", "execute", "to", "initialize", "or", "clean", "up", "the", "database"], "project": "spring-framework"}
{"id": 4734, "code": "\tpublic void setParameterNameDiscoverer(ParameterNameDiscoverer parameterNameDiscoverer) {\n\t\tthis.parameterNameDiscoverer = parameterNameDiscoverer;\n\t}", "summary_tokens": ["set", "the", "parameter", "name", "discoverer", "for", "resolving", "parameter", "names", "when", "needed", "e"], "project": "spring-framework"}
{"id": 7477, "code": "\tpublic String getEncoding() {\n\t\treturn this.encoding;\n\t}", "summary_tokens": ["return", "the", "configured", "encoding", "for", "requests", "and", "or", "responses"], "project": "spring-framework"}
{"id": 1502, "code": "\tpublic ClassLoader getThrowawayClassLoader() {\n\t\treturn new SimpleThrowawayClassLoader(getInstrumentableClassLoader());\n\t}", "summary_tokens": ["this", "implementation", "always", "returns", "a", "simple", "throwaway", "class", "loader"], "project": "spring-framework"}
{"id": 7564, "code": "\tpublic boolean supportsParameter(MethodParameter parameter) {\n\t\treturn (parameter.hasParameterAnnotation(ModelAttribute.class) ||\n\t\t\t\t(this.annotationNotRequired && !BeanUtils.isSimpleProperty(parameter.getParameterType())));\n\t}", "summary_tokens": ["returns", "true", "if", "the", "parameter", "is", "annotated", "with", "model", "attribute", "or", "if", "in", "default", "resolution", "mode", "for", "any", "method", "parameter", "that", "is", "not", "a", "simple", "type"], "project": "spring-framework"}
{"id": 7295, "code": "\tpublic boolean setResult(T result) {\n\t\treturn setResultInternal(result);\n\t}", "summary_tokens": ["set", "the", "value", "for", "the", "deferred", "result", "and", "handle", "it"], "project": "spring-framework"}
{"id": 2166, "code": "\tpublic Stream<StackWalker.StackFrame> getStackFrames() {\n\t\treturn this.stackFrames.stream();\n\t}", "summary_tokens": ["return", "the", "stack", "trace", "of", "the", "current", "invocation"], "project": "spring-framework"}
{"id": 9710, "code": "\tpublic void setRenderObject(@Nullable String renderObject) {\n\t\tthis.renderObject = renderObject;\n\t}", "summary_tokens": ["set", "the", "object", "where", "the", "render", "function", "belongs", "optional"], "project": "spring-framework"}
{"id": 8277, "code": "\tpublic List<HttpMessageReader<?>> getMessageReaders() {\n\t\treturn this.messageReaders;\n\t}", "summary_tokens": ["return", "the", "configured", "message", "converters"], "project": "spring-framework"}
{"id": 5262, "code": "\tprotected boolean isPersistenceUnitOverrideAllowed() {\n\t\treturn false;\n\t}", "summary_tokens": ["return", "whether", "an", "override", "of", "a", "same", "named", "persistence", "unit", "is", "allowed"], "project": "spring-framework"}
{"id": 4437, "code": "\tpublic void setTransactionName(String transactionName) {\n\t\tthis.transactionDefinition.setName(transactionName);\n\t}", "summary_tokens": ["specify", "the", "transaction", "name", "to", "use", "for", "transactional", "wrapping"], "project": "spring-framework"}
{"id": 9110, "code": "\tpublic Errors getErrors() {\n\t\treturn this.errors;\n\t}", "summary_tokens": ["return", "the", "errors", "instance", "typically", "a", "binding", "result", "that", "this", "bind", "status", "is", "currently", "associated", "with"], "project": "spring-framework"}
{"id": 3208, "code": "\tprotected String nextThreadName() {\n\t\treturn getThreadNamePrefix() + this.threadCount.incrementAndGet();\n\t}", "summary_tokens": ["return", "the", "thread", "name", "to", "use", "for", "a", "newly", "created", "thread"], "project": "spring-framework"}
{"id": 6429, "code": "\tpublic final void setDefaultTimeout(int defaultTimeout) {\n\t\tif (defaultTimeout < TransactionDefinition.TIMEOUT_DEFAULT) {\n\t\t\tthrow new InvalidTimeoutException(\"Invalid default timeout\", defaultTimeout);\n\t\t}\n\t\tthis.defaultTimeout = defaultTimeout;\n\t}", "summary_tokens": ["specify", "the", "default", "timeout", "that", "this", "transaction", "manager", "should", "apply", "if", "there", "is", "no", "timeout", "specified", "at", "the", "transaction", "level", "in", "seconds"], "project": "spring-framework"}
{"id": 6732, "code": "\tpublic HttpMethod getMethod() {\n\t\treturn this.method;\n\t}", "summary_tokens": ["return", "the", "http", "method", "of", "the", "request"], "project": "spring-framework"}
{"id": 3421, "code": "\tpublic void setLexicalHandler(LexicalHandler handler) {\n\t\tthrow new UnsupportedOperationException(\"setLexicalHandler is not supported\");\n\t}", "summary_tokens": ["throws", "an", "unsupported", "operation", "exception"], "project": "spring-framework"}
{"id": 2522, "code": "public void visitEnd() {\n  if (delegate != null) {\n    delegate.visitEnd();\n  }\n}", "summary_tokens": ["visits", "the", "end", "of", "the", "record", "component"], "project": "spring-framework"}
{"id": 4021, "code": "\tpublic static synchronized H2EmbeddedDatabaseConfigurer getInstance() throws ClassNotFoundException {\n\t\tif (instance == null) {\n\t\t\tinstance = new H2EmbeddedDatabaseConfigurer( (Class<? extends Driver>)\n\t\t\t\t\tClassUtils.forName(\"org.h2.Driver\", H2EmbeddedDatabaseConfigurer.class.getClassLoader()));\n\t\t}\n\t\treturn instance;\n\t}", "summary_tokens": ["get", "the", "singleton", "h", "0", "embedded", "database", "configurer", "instance"], "project": "spring-framework"}
{"id": 5436, "code": "\tpublic MockPropertySource withProperty(String name, Object value) {\n\t\tthis.setProperty(name, value);\n\t\treturn this;\n\t}", "summary_tokens": ["convenient", "synonym", "for", "set", "property", "that", "returns", "the", "current", "instance"], "project": "spring-framework"}
{"id": 5456, "code": "\tpublic String getSameSite() {\n\t\treturn this.sameSite;\n\t}", "summary_tokens": ["get", "the", "same", "site", "attribute", "for", "this", "cookie"], "project": "spring-framework"}
{"id": 2512, "code": "public void visitRequire(final String module, final int access, final String version) {\n  if (mv != null) {\n    mv.visitRequire(module, access, version);\n  }\n}", "summary_tokens": ["visits", "a", "dependence", "of", "the", "current", "module"], "project": "spring-framework"}
{"id": 1736, "code": "\tpublic void setProxyInterfaces(Class<?>... proxyInterfaces) {\n\t\tthis.proxyInterfaces = proxyInterfaces;\n\t}", "summary_tokens": ["specify", "multiple", "proxy", "interfaces", "to", "use", "for", "the", "jndi", "object"], "project": "spring-framework"}
{"id": 4913, "code": "\tpublic StompBrokerRelayRegistration setTaskScheduler(@Nullable TaskScheduler taskScheduler) {\n\t\tthis.taskScheduler = taskScheduler;\n\t\treturn this;\n\t}", "summary_tokens": ["some", "stomp", "clients", "e"], "project": "spring-framework"}
{"id": 6281, "code": "\tprotected TransactionInfo prepareTransactionInfo(@Nullable PlatformTransactionManager tm,\n\t\t\t@Nullable TransactionAttribute txAttr, String joinpointIdentification,\n\t\t\t@Nullable TransactionStatus status) {\n\n\t\tTransactionInfo txInfo = new TransactionInfo(tm, txAttr, joinpointIdentification);\n\t\tif (txAttr != null) {\n\t\t\t\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Getting transaction for [\" + txInfo.getJoinpointIdentification() + \"]\");\n\t\t\t}\n\t\t\t\n\t\t\ttxInfo.newTransactionStatus(status);\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\t\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"No need to create transaction for [\" + joinpointIdentification +\n\t\t\t\t\t\t\"]: This method is not transactional.\");\n\t\t\t}\n\t\t}\n\n\t\t\n\t\t\n\t\t\n\t\ttxInfo.bindToThread();\n\t\treturn txInfo;\n\t}", "summary_tokens": ["prepare", "a", "transaction", "info", "for", "the", "given", "attribute", "and", "status", "object"], "project": "spring-framework"}
{"id": 4680, "code": "\tpublic final Mono<Object> resolveArgument(MethodParameter parameter, Message<?> message) {\n\n\t\tPayload ann = parameter.getParameterAnnotation(Payload.class);\n\t\tif (ann != null && StringUtils.hasText(ann.expression())) {\n\t\t\tthrow new IllegalStateException(\"@Payload SpEL expressions not supported by this resolver\");\n\t\t}\n\n\t\tMimeType mimeType = getMimeType(message);\n\t\tmimeType = mimeType != null ? mimeType : MimeTypeUtils.APPLICATION_OCTET_STREAM;\n\n\t\tFlux<DataBuffer> content = extractContent(parameter, message);\n\t\treturn decodeContent(parameter, message, ann == null || ann.required(), content, mimeType);\n\t}", "summary_tokens": ["decode", "the", "content", "of", "the", "given", "message", "payload", "through", "a", "compatible", "decoder"], "project": "spring-framework"}
{"id": 8090, "code": "\tstatic Builder builder() {\n\t\tDefaultExchangeStrategiesBuilder builder = new DefaultExchangeStrategiesBuilder();\n\t\tbuilder.defaultConfiguration();\n\t\treturn builder;\n\t}", "summary_tokens": ["return", "a", "builder", "pre", "configured", "with", "default", "configuration", "to", "start"], "project": "spring-framework"}
{"id": 415, "code": "\tpublic void addQualifierType(Class<? extends Annotation> qualifierType) {\n\t\tthis.qualifierTypes.add(qualifierType);\n\t}", "summary_tokens": ["register", "the", "given", "type", "to", "be", "used", "as", "a", "qualifier", "when", "autowiring"], "project": "spring-framework"}
{"id": 9776, "code": "\tpublic void setLoggingPeriod(long period) {\n\t\tif (this.loggingTask != null) {\n\t\t\tthis.loggingTask.cancel(true);\n\t\t}\n\t\tthis.loggingPeriod = period;\n\t\tthis.loggingTask = initLoggingTask(0);\n\t}", "summary_tokens": ["set", "the", "frequency", "for", "logging", "information", "at", "info", "level", "in", "milliseconds"], "project": "spring-framework"}
{"id": 6796, "code": "\tpublic void setShutdownTimeout(Duration shutdownTimeout) {\n\t\tAssert.notNull(shutdownTimeout, \"shutdownTimeout should not be null\");\n\t\tthis.shutdownTimeout = shutdownTimeout;\n\t}", "summary_tokens": ["configure", "the", "maximum", "amount", "of", "time", "to", "wait", "until", "the", "disposal", "of", "the", "underlying", "resources", "regardless", "if", "a", "task", "was", "submitted", "during", "the", "shutdown", "quiet", "period"], "project": "spring-framework"}
{"id": 7494, "code": "\tpublic void setEnvironment(Environment environment) {\n\t\tthis.environment = environment;\n\t}", "summary_tokens": ["set", "the", "environment", "that", "this", "filter", "runs", "in"], "project": "spring-framework"}
{"id": 5287, "code": "\tprotected String getPersistenceUnitName() {\n\t\treturn this.persistenceUnitName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "persistence", "unit", "to", "access", "the", "entity", "manager", "factory", "for", "if", "any"], "project": "spring-framework"}
{"id": 1376, "code": "\tpublic void setDefaultLocale(@Nullable Locale defaultLocale) {\n\t\tthis.defaultLocale = defaultLocale;\n\t}", "summary_tokens": ["specify", "a", "default", "locale", "to", "fall", "back", "to", "as", "an", "alternative", "to", "falling", "back", "to", "the", "system", "locale"], "project": "spring-framework"}
{"id": 6920, "code": "\tpublic void setUnmarshallerProcessor(Function<Unmarshaller, Unmarshaller> processor) {\n\t\tthis.unmarshallerProcessor = this.unmarshallerProcessor.andThen(processor);\n\t}", "summary_tokens": ["configure", "a", "processor", "function", "to", "customize", "unmarshaller", "instances"], "project": "spring-framework"}
{"id": 8391, "code": "\tdefault boolean isRedirectView() {\n\t\treturn false;\n\t}", "summary_tokens": ["whether", "this", "view", "does", "render", "by", "performing", "a", "redirect"], "project": "spring-framework"}
{"id": 70, "code": "\tpublic void setPreInterceptors(Object[] preInterceptors) {\n\t\tthis.preInterceptors = preInterceptors;\n\t}", "summary_tokens": ["set", "additional", "interceptors", "or", "advisors", "to", "be", "applied", "before", "the", "implicit", "transaction", "interceptor", "e"], "project": "spring-framework"}
{"id": 9077, "code": "\tprotected String toAbsolutePath(String path, HttpServletRequest request) {\n\t\tString absolutePath = path;\n\t\tif (!path.startsWith(\"/\")) {\n\t\t\tResourceUrlProvider urlProvider = findResourceUrlProvider(request);\n\t\t\tAssert.state(urlProvider != null, \"No ResourceUrlProvider\");\n\t\t\tString requestPath = urlProvider.getUrlPathHelper().getRequestUri(request);\n\t\t\tabsolutePath = StringUtils.applyRelativePath(requestPath, path);\n\t\t}\n\t\treturn StringUtils.cleanPath(absolutePath);\n\t}", "summary_tokens": ["transform", "the", "given", "relative", "request", "path", "to", "an", "absolute", "path", "taking", "the", "path", "of", "the", "given", "request", "as", "a", "point", "of", "reference"], "project": "spring-framework"}
{"id": 3220, "code": "\tpublic static void copy(String in, Writer out) throws IOException {\n\t\tAssert.notNull(in, \"No input String specified\");\n\t\tAssert.notNull(out, \"No Writer specified\");\n\n\t\ttry {\n\t\t\tout.write(in);\n\t\t}\n\t\tfinally {\n\t\t\tclose(out);\n\t\t}\n\t}", "summary_tokens": ["copy", "the", "contents", "of", "the", "given", "string", "to", "the", "given", "writer"], "project": "spring-framework"}
{"id": 760, "code": "\tpublic Set<Member> getExternallyManagedConfigMembers() {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\treturn (this.externallyManagedConfigMembers != null ?\n\t\t\t\t\tCollections.unmodifiableSet(new LinkedHashSet<>(this.externallyManagedConfigMembers)) :\n\t\t\t\t\tCollections.emptySet());\n\t\t}\n\t}", "summary_tokens": ["get", "all", "externally", "managed", "configuration", "methods", "and", "fields", "as", "an", "immutable", "set"], "project": "spring-framework"}
{"id": 549, "code": "\tprotected Constructor<Exception> determineServiceLocatorExceptionConstructor(Class<? extends Exception> exceptionClass) {\n\t\ttry {\n\t\t\treturn (Constructor<Exception>) exceptionClass.getConstructor(String.class, Throwable.class);\n\t\t}\n\t\tcatch (NoSuchMethodException ex) {\n\t\t\ttry {\n\t\t\t\treturn (Constructor<Exception>) exceptionClass.getConstructor(Throwable.class);\n\t\t\t}\n\t\t\tcatch (NoSuchMethodException ex2) {\n\t\t\t\ttry {\n\t\t\t\t\treturn (Constructor<Exception>) exceptionClass.getConstructor(String.class);\n\t\t\t\t}\n\t\t\t\tcatch (NoSuchMethodException ex3) {\n\t\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\t\"Service locator exception [\" + exceptionClass.getName() +\n\t\t\t\t\t\t\t\"] neither has a (String, Throwable) constructor nor a (String) constructor\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["determine", "the", "constructor", "to", "use", "for", "the", "given", "service", "locator", "exception", "class"], "project": "spring-framework"}
{"id": 1566, "code": "\tpublic void setManagedResource(Object managedResource, String managedResourceType)\n\t\t\tthrows MBeanException, InstanceNotFoundException, InvalidTargetObjectTypeException {\n\n\t\tthis.managedResourceClassLoader = managedResource.getClass().getClassLoader();\n\t\tsuper.setManagedResource(managedResource, managedResourceType);\n\t}", "summary_tokens": ["sets", "managed", "resource", "to", "expose", "and", "stores", "its", "class", "loader"], "project": "spring-framework"}
{"id": 1646, "code": "\tpublic String getDisplayName() {\n\t\treturn this.displayName;\n\t}", "summary_tokens": ["a", "display", "name", "for", "this", "metric"], "project": "spring-framework"}
{"id": 6349, "code": "\tprivate Mono<Void> resumeAfterBeginException(TransactionSynchronizationManager synchronizationManager,\n\t\t\tObject transaction, @Nullable SuspendedResourcesHolder suspendedResources, Throwable beginEx) {\n\n\t\tString exMessage = \"Inner transaction begin exception overridden by outer transaction resume exception\";\n\t\treturn resume(synchronizationManager, transaction, suspendedResources).doOnError(ErrorPredicates.RUNTIME_OR_ERROR,\n\t\t\t\tex -> logger.error(exMessage, beginEx));\n\t}", "summary_tokens": ["resume", "outer", "transaction", "after", "inner", "transaction", "begin", "failed"], "project": "spring-framework"}
{"id": 5153, "code": "\tpublic void setEntityInterceptor(Interceptor entityInterceptor) {\n\t\tthis.entityInterceptor = entityInterceptor;\n\t}", "summary_tokens": ["set", "a", "hibernate", "entity", "interceptor", "that", "allows", "to", "inspect", "and", "change", "property", "values", "before", "writing", "to", "and", "reading", "from", "the", "database"], "project": "spring-framework"}
{"id": 4181, "code": "\tpublic void setDeleteSpecificValues(boolean deleteSpecificValues) {\n\t\tthis.deleteSpecificValues = deleteSpecificValues;\n\t}", "summary_tokens": ["specify", "whether", "to", "delete", "the", "entire", "range", "below", "the", "current", "maximum", "key", "value", "false", "the", "default", "or", "the", "specifically", "generated", "values", "true"], "project": "spring-framework"}
{"id": 7936, "code": "\tpublic String getSameSite() {\n\t\treturn this.sameSite;\n\t}", "summary_tokens": ["get", "the", "same", "site", "attribute", "for", "this", "cookie"], "project": "spring-framework"}
{"id": 4624, "code": "\tvoid testSendDestinationWithQOS() throws Exception {\n\t\tdoTestSendDestination(true, false, false, true);\n\t}", "summary_tokens": ["test", "sending", "to", "a", "destination", "using", "the", "method", "send", "destination", "d", "message", "creator", "message", "creator", "using", "qos", "parameters"], "project": "spring-framework"}
{"id": 426, "code": "\tdefault <T> T get(int index) {\n\t\treturn (T) getObject(index);\n\t}", "summary_tokens": ["return", "the", "resolved", "argument", "at", "the", "specified", "index"], "project": "spring-framework"}
{"id": 5633, "code": "\tprivate Statement withAfterTestMethodCallbacks(Statement next, Method testMethod,\n\t\t\tObject testInstance, TestContextManager testContextManager) {\n\n\t\treturn new RunAfterTestMethodCallbacks(\n\t\t\t\tnext, testInstance, testMethod, testContextManager);\n\t}", "summary_tokens": ["wrap", "the", "supplied", "statement", "with", "a", "run", "after", "test", "method", "callbacks", "statement"], "project": "spring-framework"}
{"id": 977, "code": "\tpublic KeyGenerator getKeyGenerator() {\n\t\treturn this.keyGenerator;\n\t}", "summary_tokens": ["return", "the", "key", "generator", "to", "use", "to", "compute", "cache", "keys"], "project": "spring-framework"}
{"id": 261, "code": "\tpublic void setTimeBetweenEvictionRunsMillis(long timeBetweenEvictionRunsMillis) {\n\t\tthis.timeBetweenEvictionRunsMillis = timeBetweenEvictionRunsMillis;\n\t}", "summary_tokens": ["set", "the", "time", "between", "eviction", "runs", "that", "check", "idle", "objects", "whether", "they", "have", "been", "idle", "for", "too", "long", "or", "have", "become", "invalid"], "project": "spring-framework"}
{"id": 8757, "code": "\tpublic static RouterFunction<ServerResponse> resources(Function<ServerRequest, Optional<Resource>> lookupFunction) {\n\t\treturn new ResourcesRouterFunction(lookupFunction);\n\t}", "summary_tokens": ["route", "to", "resources", "using", "the", "provided", "lookup", "function"], "project": "spring-framework"}
{"id": 8282, "code": "\tprivate NamedValueInfo getNamedValueInfo(MethodParameter parameter) {\n\t\tNamedValueInfo namedValueInfo = this.namedValueInfoCache.get(parameter);\n\t\tif (namedValueInfo == null) {\n\t\t\tnamedValueInfo = createNamedValueInfo(parameter);\n\t\t\tnamedValueInfo = updateNamedValueInfo(parameter, namedValueInfo);\n\t\t\tthis.namedValueInfoCache.put(parameter, namedValueInfo);\n\t\t}\n\t\treturn namedValueInfo;\n\t}", "summary_tokens": ["obtain", "the", "named", "value", "for", "the", "given", "method", "parameter"], "project": "spring-framework"}
{"id": 5674, "code": "\tpublic void afterTestMethod(TestContext testContext) throws Exception {\n\t\t\n\t}", "summary_tokens": ["the", "default", "implementation", "is", "em", "empty", "em"], "project": "spring-framework"}
{"id": 7497, "code": "\tpublic void setServletContext(ServletContext servletContext) {\n\t\tthis.servletContext = servletContext;\n\t}", "summary_tokens": ["stores", "the", "servlet", "context", "that", "the", "bean", "factory", "runs", "in"], "project": "spring-framework"}
{"id": 7029, "code": "\tpublic void setObjectMapper(ObjectMapper objectMapper) {\n\t\tAssert.isInstanceOf(SmileFactory.class, objectMapper.getFactory(), \"SmileFactory required\");\n\t\tsuper.setObjectMapper(objectMapper);\n\t}", "summary_tokens": ["the", "object", "mapper", "must", "be", "configured", "with", "a", "smile", "factory", "instance"], "project": "spring-framework"}
{"id": 5594, "code": "\tstatic TestContextManager getTestContextManager(ExtensionContext context) {\n\t\tAssert.notNull(context, \"ExtensionContext must not be null\");\n\t\tClass<?> testClass = context.getRequiredTestClass();\n\t\tStore store = getStore(context);\n\t\treturn store.getOrComputeIfAbsent(testClass, TestContextManager::new, TestContextManager.class);\n\t}", "summary_tokens": ["get", "the", "test", "context", "manager", "associated", "with", "the", "supplied", "extension", "context"], "project": "spring-framework"}
{"id": 9468, "code": "\tpublic void setMultiple(Object multiple) {\n\t\tthis.multiple = multiple;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "html", "multiple", "attribute", "rendered", "on", "the", "final", "select", "element"], "project": "spring-framework"}
{"id": 7372, "code": "\tpublic String getServletName() {\n\t\treturn this.servletName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "servlet", "that", "handled", "the", "request"], "project": "spring-framework"}
{"id": 2057, "code": "\tpublic void setConfigurationInitializer(Consumer<Configuration<?>> configurationInitializer) {\n\t\tthis.configurationInitializer = configurationInitializer;\n\t}", "summary_tokens": ["specify", "a", "callback", "for", "customizing", "the", "bean", "validation", "configuration", "instance", "as", "an", "alternative", "to", "overriding", "the", "post", "process", "configuration", "configuration", "method", "in", "custom", "local", "validator", "factory", "bean", "subclasses"], "project": "spring-framework"}
{"id": 663, "code": "\tpublic BeanDefinition getExistingDefinition() {\n\t\treturn this.existingDefinition;\n\t}", "summary_tokens": ["return", "the", "existing", "bean", "definition", "for", "the", "same", "name"], "project": "spring-framework"}
{"id": 6995, "code": "\tpublic void setDefaultTyping(TypeResolverBuilder<?> typeResolverBuilder) {\n\t\tthis.builder.defaultTyping(typeResolverBuilder);\n\t}", "summary_tokens": ["specify", "a", "type", "resolver", "builder", "to", "use", "for", "jackson", "s", "default", "typing"], "project": "spring-framework"}
{"id": 2396, "code": "private byte[] replaceAsmInstructions(final byte[] classFile, final boolean hasFrames) {\n  final Attribute[] attributes = getAttributePrototypes();\n  firstField = null;\n  lastField = null;\n  firstMethod = null;\n  lastMethod = null;\n  lastRuntimeVisibleAnnotation = null;\n  lastRuntimeInvisibleAnnotation = null;\n  lastRuntimeVisibleTypeAnnotation = null;\n  lastRuntimeInvisibleTypeAnnotation = null;\n  moduleWriter = null;\n  nestHostClassIndex = 0;\n  numberOfNestMemberClasses = 0;\n  nestMemberClasses = null;\n  numberOfPermittedSubclasses = 0;\n  permittedSubclasses = null;\n  firstRecordComponent = null;\n  lastRecordComponent = null;\n  firstAttribute = null;\n  compute = hasFrames ? MethodWriter.COMPUTE_INSERTED_FRAMES : MethodWriter.COMPUTE_NOTHING;\n  new ClassReader(classFile, 0,  false)\n      .accept(\n          this,\n          attributes,\n          (hasFrames ? ClassReader.EXPAND_FRAMES : 0) | ClassReader.EXPAND_ASM_INSNS);\n  return toByteArray();\n}", "summary_tokens": ["returns", "the", "equivalent", "of", "the", "given", "class", "file", "with", "the", "asm", "specific", "instructions", "replaced", "with", "standard", "ones"], "project": "spring-framework"}
{"id": 7968, "code": "\tpublic Object getReturnValue() {\n\t\treturn this.returnValue;\n\t}", "summary_tokens": ["return", "the", "value", "returned", "from", "the", "handler", "if", "any"], "project": "spring-framework"}
{"id": 5880, "code": "\tpublic WebTestClient.ResponseSpec value(String name, Consumer<String> consumer) {\n\t\tString value = getRequiredValue(name);\n\t\tthis.exchangeResult.assertWithDiagnostics(() -> consumer.accept(value));\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["consume", "the", "first", "value", "of", "the", "named", "response", "header"], "project": "spring-framework"}
{"id": 3627, "code": "\tpublic void compilingMathematicalExpressionsWithDifferentOperandTypes() throws Exception {\n\t\tNumberHolder nh = new NumberHolder();\n\t\texpression = parser.parseExpression(\"(T(Integer).valueOf(payload).doubleValue())/18D\");\n\t\tObject o = expression.getValue(nh);\n\t\tassertThat(o).isEqualTo(2d);\n\t\tSystem.out.println(\"Performance check for SpEL expression: '(T(Integer).valueOf(payload).doubleValue())/18D'\");\n\t\tlong stime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tcompile(expression);\n\t\tSystem.out.println(\"Now compiled:\");\n\t\to = expression.getValue(nh);\n\t\tassertThat(o).isEqualTo(2d);\n\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\n\t\texpression = parser.parseExpression(\"payload/18D\");\n\t\to = expression.getValue(nh);\n\t\tassertThat(o).isEqualTo(2d);\n\t\tSystem.out.println(\"Performance check for SpEL expression: 'payload/18D'\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tcompile(expression);\n\t\tSystem.out.println(\"Now compiled:\");\n\t\to = expression.getValue(nh);\n\t\tassertThat(o).isEqualTo(2d);\n\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t\tstime = System.currentTimeMillis();\n\t\tfor (int i = 0; i < 1000000; i++) {\n\t\t\to = expression.getValue(nh);\n\t\t}\n\t\tSystem.out.println(\"One million iterations: \" + (System.currentTimeMillis()-stime) + \"ms\");\n\t}", "summary_tokens": ["this", "test", "verifies", "the", "new", "support", "for", "compiling", "mathematical", "expressions", "with", "different", "operand", "types"], "project": "spring-framework"}
{"id": 9130, "code": "\tpublic Boolean getDefaultHtmlEscape() {\n\t\treturn this.defaultHtmlEscape;\n\t}", "summary_tokens": ["return", "the", "default", "html", "escape", "setting", "differentiating", "between", "no", "default", "specified", "and", "an", "explicit", "value"], "project": "spring-framework"}
{"id": 2808, "code": "\tpublic static RepeatableContainers of(\n\t\t\tClass<? extends Annotation> repeatable, @Nullable Class<? extends Annotation> container) {\n\n\t\treturn new ExplicitRepeatableContainer(null, repeatable, container);\n\t}", "summary_tokens": ["create", "a", "repeatable", "containers", "instance", "that", "uses", "a", "defined", "container", "and", "repeatable", "type"], "project": "spring-framework"}
{"id": 8408, "code": "\tpublic void setEncoding(@Nullable String encoding) {\n\t\tthis.encoding = encoding;\n\t}", "summary_tokens": ["set", "the", "encoding", "of", "the", "free", "marker", "template", "file"], "project": "spring-framework"}
{"id": 8881, "code": "\tpublic CompositeRequestCondition getMatchingCondition(HttpServletRequest request) {\n\t\tif (isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\tRequestConditionHolder[] matchingConditions = new RequestConditionHolder[getLength()];\n\t\tfor (int i = 0; i < getLength(); i++) {\n\t\t\tmatchingConditions[i] = this.requestConditions[i].getMatchingCondition(request);\n\t\t\tif (matchingConditions[i] == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\treturn new CompositeRequestCondition(matchingConditions);\n\t}", "summary_tokens": ["delegate", "to", "em", "all", "em", "contained", "conditions", "to", "match", "the", "request", "and", "return", "the", "resulting", "matching", "condition", "instances"], "project": "spring-framework"}
{"id": 217, "code": "\tprotected final boolean isMethodOnIntroducedInterface(MethodInvocation mi) {\n\t\tBoolean rememberedResult = this.rememberedMethods.get(mi.getMethod());\n\t\tif (rememberedResult != null) {\n\t\t\treturn rememberedResult;\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tboolean result = implementsInterface(mi.getMethod().getDeclaringClass());\n\t\t\tthis.rememberedMethods.put(mi.getMethod(), result);\n\t\t\treturn result;\n\t\t}\n\t}", "summary_tokens": ["is", "this", "method", "on", "an", "introduced", "interface", "mi", "the", "method", "invocation", "whether", "the", "invoked", "method", "is", "on", "an", "introduced", "interface"], "project": "spring-framework"}
{"id": 1265, "code": "\tpublic void setScopeMetadataResolver(@Nullable ScopeMetadataResolver scopeMetadataResolver) {\n\t\tthis.scopeMetadataResolver =\n\t\t\t\t(scopeMetadataResolver != null ? scopeMetadataResolver : new AnnotationScopeMetadataResolver());\n\t}", "summary_tokens": ["set", "the", "scope", "metadata", "resolver", "to", "use", "for", "detected", "bean", "classes"], "project": "spring-framework"}
{"id": 8667, "code": "\tprotected final Object[] getInterceptors(\n\t\t\tFormattingConversionService mvcConversionService,\n\t\t\tResourceUrlProvider mvcResourceUrlProvider) {\n\n\t\tif (this.interceptors == null) {\n\t\t\tInterceptorRegistry registry = new InterceptorRegistry();\n\t\t\taddInterceptors(registry);\n\t\t\tregistry.addInterceptor(new ConversionServiceExposingInterceptor(mvcConversionService));\n\t\t\tregistry.addInterceptor(new ResourceUrlProviderExposingInterceptor(mvcResourceUrlProvider));\n\t\t\tthis.interceptors = registry.getInterceptors();\n\t\t}\n\t\treturn this.interceptors.toArray();\n\t}", "summary_tokens": ["provide", "access", "to", "the", "shared", "handler", "interceptors", "used", "to", "configure", "handler", "mapping", "instances", "with"], "project": "spring-framework"}
{"id": 9063, "code": "\tpublic Cache getCache() {\n\t\treturn this.cache;\n\t}", "summary_tokens": ["return", "the", "configured", "cache"], "project": "spring-framework"}
{"id": 5613, "code": "\tprivate Statement withRulesReflectively(FrameworkMethod frameworkMethod, Object testInstance, Statement statement) {\n\t\tObject result = ReflectionUtils.invokeMethod(withRulesMethod, this, frameworkMethod, testInstance, statement);\n\t\tAssert.state(result instanceof Statement, \"withRules mismatch\");\n\t\treturn (Statement) result;\n\t}", "summary_tokens": ["invoke", "junit", "s", "private", "with", "rules", "method", "using", "reflection"], "project": "spring-framework"}
{"id": 4, "code": "\tvoid testRollbackRulesOnMethodCauseRollback() throws Exception {\n\t\tBeanFactory bf = getBeanFactory();\n\t\tRollback rb = (Rollback) bf.getBean(\"rollback\");\n\n\t\tCallCountingTransactionManager txMan = (CallCountingTransactionManager) bf.getBean(TXMANAGER_BEAN_NAME);\n\t\tOrderedTxCheckAdvisor txc = (OrderedTxCheckAdvisor) bf.getBean(\"orderedBeforeTransaction\");\n\t\tassertThat(txc.getCountingBeforeAdvice().getCalls()).isEqualTo(0);\n\n\t\tassertThat(txMan.commits).isEqualTo(0);\n\t\trb.echoException(null);\n\t\t\n\t\tassertThat(txc.getCountingBeforeAdvice().getCalls()).isEqualTo(0);\n\t\tassertThat(txMan.commits).as(\"Transaction counts match\").isEqualTo(1);\n\n\t\tassertThat(txMan.rollbacks).isEqualTo(0);\n\t\tException ex = new Exception();\n\t\ttry {\n\t\t\trb.echoException(ex);\n\t\t}\n\t\tcatch (Exception actual) {\n\t\t\tassertThat(actual).isEqualTo(ex);\n\t\t}\n\t\tassertThat(txMan.rollbacks).as(\"Transaction counts match\").isEqualTo(1);\n\t}", "summary_tokens": ["should", "not", "roll", "back", "on", "servlet", "exception"], "project": "spring-framework"}
{"id": 1896, "code": "\tpublic ScriptSource getScriptSource() {\n\t\treturn this.scriptSource;\n\t}", "summary_tokens": ["return", "the", "source", "for", "the", "offending", "script"], "project": "spring-framework"}
{"id": 2371, "code": "private String readStringish(final int offset, final char[] charBuffer) {\n    \n    \n  return readUTF8(cpInfoOffsets[readUnsignedShort(offset)], charBuffer);\n}", "summary_tokens": ["reads", "a", "constant", "class", "constant", "string", "constant", "method", "type", "constant", "module", "or", "constant", "package", "constant", "pool", "entry", "in", "class", "file", "buffer"], "project": "spring-framework"}
{"id": 5406, "code": "\tpublic List<String> getParameterNames(String sql) {\n\t\treturn getParsedSql(sql).getParameterNames();\n\t}", "summary_tokens": ["parse", "the", "sql", "statement", "and", "locate", "any", "placeholders", "or", "named", "parameters"], "project": "spring-framework"}
{"id": 6057, "code": "\tpublic ResultMatcher isAccepted() {\n\t\treturn matcher(HttpStatus.ACCEPTED);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 638, "code": "\tpublic BeanDefinitionBuilder setDestroyMethodName(@Nullable String methodName) {\n\t\tthis.beanDefinition.setDestroyMethodName(methodName);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "destroy", "method", "for", "this", "definition"], "project": "spring-framework"}
{"id": 2445, "code": "public String getDesc() {\n  return descriptor;\n}", "summary_tokens": ["returns", "the", "descriptor", "of", "the", "field", "or", "method", "designated", "by", "this", "handle"], "project": "spring-framework"}
{"id": 7724, "code": "\tpublic void setSupportedLocales(List<Locale> locales) {\n\t\tthis.supportedLocales.clear();\n\t\tthis.supportedLocales.addAll(locales);\n\t}", "summary_tokens": ["configure", "supported", "locales", "to", "check", "against", "the", "requested", "locales", "determined", "via", "http", "headers", "get", "accept", "language", "as", "locales"], "project": "spring-framework"}
{"id": 8595, "code": "\tpublic CorsRegistration combine(CorsConfiguration other) {\n\t\tthis.config = this.config.combine(other);\n\t\treturn this;\n\t}", "summary_tokens": ["apply", "the", "given", "cors", "configuration", "to", "the", "one", "being", "configured", "via", "cors", "configuration", "combine", "cors", "configuration", "which", "in", "turn", "has", "been", "initialized", "with", "cors", "configuration", "apply", "permit", "default", "values"], "project": "spring-framework"}
{"id": 6034, "code": "\tpublic ResultMatcher errorCount(int expectedCount) {\n\t\treturn result -> {\n\t\t\tint actualCount = getErrorCount(getModelAndView(result).getModelMap());\n\t\t\tassertEquals(\"Binding/validation error count\", expectedCount, actualCount);\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "total", "number", "of", "errors", "in", "the", "model"], "project": "spring-framework"}
{"id": 430, "code": "\tpublic static AutowiredFieldValueResolver forRequiredField(String fieldName) {\n\t\treturn new AutowiredFieldValueResolver(fieldName, true, null);\n\t}", "summary_tokens": ["create", "a", "new", "autowired", "field", "value", "resolver", "for", "the", "specified", "field", "where", "injection", "is", "required"], "project": "spring-framework"}
{"id": 838, "code": "\tprotected EntityResolver getEntityResolver() {\n\t\tif (this.entityResolver == null) {\n\t\t\t\n\t\t\tResourceLoader resourceLoader = getResourceLoader();\n\t\t\tif (resourceLoader != null) {\n\t\t\t\tthis.entityResolver = new ResourceEntityResolver(resourceLoader);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.entityResolver = new DelegatingEntityResolver(getBeanClassLoader());\n\t\t\t}\n\t\t}\n\t\treturn this.entityResolver;\n\t}", "summary_tokens": ["return", "the", "entity", "resolver", "to", "use", "building", "a", "default", "resolver", "if", "none", "specified"], "project": "spring-framework"}
{"id": 575, "code": "\tpublic final String getAlias() {\n\t\treturn this.alias;\n\t}", "summary_tokens": ["return", "the", "alias", "registered", "for", "the", "bean"], "project": "spring-framework"}
{"id": 8619, "code": "\tpublic Boolean isUseSuffixPatternMatch() {\n\t\treturn this.suffixPatternMatch;\n\t}", "summary_tokens": ["whether", "to", "use", "registered", "suffixes", "for", "pattern", "matching"], "project": "spring-framework"}
{"id": 3797, "code": "\tpublic int getSqlType(String paramName) {\n\t\tint sqlType = super.getSqlType(paramName);\n\t\tif (sqlType != TYPE_UNKNOWN) {\n\t\t\treturn sqlType;\n\t\t}\n\t\tClass<?> propType = this.beanWrapper.getPropertyType(paramName);\n\t\treturn StatementCreatorUtils.javaTypeToSqlParameterType(propType);\n\t}", "summary_tokens": ["derives", "a", "default", "sql", "type", "from", "the", "corresponding", "property", "type"], "project": "spring-framework"}
{"id": 7571, "code": "\tprotected boolean isBindExceptionRequired(MethodParameter parameter) {\n\t\tint i = parameter.getParameterIndex();\n\t\tClass<?>[] paramTypes = parameter.getExecutable().getParameterTypes();\n\t\tboolean hasBindingResult = (paramTypes.length > (i + 1) && Errors.class.isAssignableFrom(paramTypes[i + 1]));\n\t\treturn !hasBindingResult;\n\t}", "summary_tokens": ["whether", "to", "raise", "a", "fatal", "bind", "exception", "on", "validation", "errors"], "project": "spring-framework"}
{"id": 1214, "code": "\tprotected void logCacheError(Supplier<String> messageSupplier, RuntimeException exception) {\n\t\tif (getLogger().isWarnEnabled()) {\n\t\t\tif (isLogStackTraces()) {\n\t\t\t\tgetLogger().warn(messageSupplier.get(), exception);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tgetLogger().warn(messageSupplier.get());\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["log", "the", "cache", "error", "message", "in", "the", "given", "supplier"], "project": "spring-framework"}
{"id": 6570, "code": "\tpublic static void invokeAfterCompletion(@Nullable List<TransactionSynchronization> synchronizations,\n\t\t\tint completionStatus) {\n\n\t\tif (synchronizations != null) {\n\t\t\tfor (TransactionSynchronization synchronization : synchronizations) {\n\t\t\t\ttry {\n\t\t\t\t\tsynchronization.afterCompletion(completionStatus);\n\t\t\t\t}\n\t\t\t\tcatch (Throwable ex) {\n\t\t\t\t\tlogger.debug(\"TransactionSynchronization.afterCompletion threw exception\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["actually", "invoke", "the", "after", "completion", "methods", "of", "the", "given", "spring", "transaction", "synchronization", "objects"], "project": "spring-framework"}
{"id": 7541, "code": "\tpublic static Builder builder() {\n\t\treturn new Builder();\n\t}", "summary_tokens": ["return", "a", "builder", "for", "a", "handler", "type", "predicate"], "project": "spring-framework"}
{"id": 8890, "code": "\tpublic int compareTo(ConsumesRequestCondition other, HttpServletRequest request) {\n\t\tif (this.expressions.isEmpty() && other.expressions.isEmpty()) {\n\t\t\treturn 0;\n\t\t}\n\t\telse if (this.expressions.isEmpty()) {\n\t\t\treturn 1;\n\t\t}\n\t\telse if (other.expressions.isEmpty()) {\n\t\t\treturn -1;\n\t\t}\n\t\telse {\n\t\t\treturn this.expressions.get(0).compareTo(other.expressions.get(0));\n\t\t}\n\t}", "summary_tokens": ["returns", "ul", "li", "0", "if", "the", "two", "conditions", "have", "the", "same", "number", "of", "expressions", "li", "less", "than", "0", "if", "this", "has", "more", "or", "more", "specific", "media", "type", "expressions", "li", "greater", "than", "0", "if", "other", "has", "more", "or", "more", "specific", "media", "type", "expressions", "ul", "p", "it", "is", "assumed", "that", "both", "instances", "have", "been", "obtained", "via", "get", "matching", "condition", "http", "servlet", "request", "and", "each", "instance", "contains", "the", "matching", "consumable", "media", "type", "expression", "only", "or", "is", "otherwise", "empty"], "project": "spring-framework"}
{"id": 3455, "code": "\tprotected void testDecodeError(Publisher<DataBuffer> input, ResolvableType outputType,\n\t\t\t@Nullable MimeType mimeType, @Nullable Map<String, Object> hints) {\n\n\t\tFlux<DataBuffer> buffer = Mono.from(input).concatWith(Flux.error(new InputException()));\n\t\tassertThatExceptionOfType(InputException.class).isThrownBy(() ->\n\t\t\t\tthis.decoder.decode(buffer, outputType, mimeType, hints).blockLast(Duration.ofSeconds(5)));\n\t}", "summary_tokens": ["test", "a", "decoder", "decode", "decode", "scenario", "where", "the", "input", "stream", "contains", "an", "error"], "project": "spring-framework"}
{"id": 5237, "code": "\tpublic void setDefaultPersistenceUnitRootLocation(String defaultPersistenceUnitRootLocation) {\n\t\tthis.defaultPersistenceUnitRootLocation = defaultPersistenceUnitRootLocation;\n\t}", "summary_tokens": ["set", "the", "default", "persistence", "unit", "root", "location", "to", "be", "applied", "if", "no", "unit", "specific", "persistence", "unit", "root", "could", "be", "determined"], "project": "spring-framework"}
{"id": 6338, "code": "\tpublic boolean isRollbackOnly() {\n\t\ttry {\n\t\t\tint jtaStatus = this.userTransaction.getStatus();\n\t\t\treturn (jtaStatus == Status.STATUS_MARKED_ROLLBACK || jtaStatus == Status.STATUS_ROLLEDBACK);\n\t\t}\n\t\tcatch (SystemException ex) {\n\t\t\tthrow new TransactionSystemException(\"JTA failure on getStatus\", ex);\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "checks", "the", "user", "transaction", "s", "rollback", "only", "flag"], "project": "spring-framework"}
{"id": 9321, "code": "\tpublic void setOnfocus(String onfocus) {\n\t\tthis.onfocus = onfocus;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "onfocus", "attribute"], "project": "spring-framework"}
{"id": 878, "code": "\tpublic List<E> getSource() {\n\t\treturn this.source;\n\t}", "summary_tokens": ["return", "the", "source", "list", "for", "this", "holder"], "project": "spring-framework"}
{"id": 725, "code": "\tpublic void setMergeEnabled(boolean mergeEnabled) {\n\t\tthis.mergeEnabled = mergeEnabled;\n\t}", "summary_tokens": ["set", "whether", "merging", "should", "be", "enabled", "for", "this", "collection", "in", "case", "of", "a", "parent", "collection", "value", "being", "present"], "project": "spring-framework"}
{"id": 230, "code": "\tpublic void setMappedNames(String... mappedNames) {\n\t\tthis.pointcut.setMappedNames(mappedNames);\n\t}", "summary_tokens": ["set", "the", "method", "names", "defining", "methods", "to", "match"], "project": "spring-framework"}
{"id": 9329, "code": "\tpublic void setDisabled(boolean disabled) {\n\t\tthis.disabled = disabled;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "disabled", "attribute"], "project": "spring-framework"}
{"id": 5187, "code": "\tprotected HibernateTemplate createHibernateTemplate(SessionFactory sessionFactory) {\n\t\treturn new HibernateTemplate(sessionFactory);\n\t}", "summary_tokens": ["create", "a", "hibernate", "template", "for", "the", "given", "session", "factory"], "project": "spring-framework"}
{"id": 6065, "code": "\tpublic ResultMatcher isMultipleChoices() {\n\t\treturn matcher(HttpStatus.MULTIPLE_CHOICES);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 7472, "code": "\tprivate String getAfterMessage(HttpServletRequest request) {\n\t\treturn createMessage(request, this.afterMessagePrefix, this.afterMessageSuffix);\n\t}", "summary_tokens": ["get", "the", "message", "to", "write", "to", "the", "log", "after", "the", "request"], "project": "spring-framework"}
{"id": 915, "code": "\tvoid copyPropertiesDoesNotHonorGenericTypeMismatches() {\n\t\tIntegerListHolder1 integerListHolder = new IntegerListHolder1();\n\t\tintegerListHolder.getList().add(42);\n\t\tLongListHolder longListHolder = new LongListHolder();\n\n\t\tBeanUtils.copyProperties(integerListHolder, longListHolder);\n\t\tassertThat(integerListHolder.getList()).containsOnly(42);\n\t\tassertThat(longListHolder.getList()).isEmpty();\n\t}", "summary_tokens": ["list", "integer", "can", "not", "be", "copied", "to", "list", "long"], "project": "spring-framework"}
{"id": 1740, "code": "\tpublic void setDefaultObject(Object defaultObject) {\n\t\tthis.defaultObject = defaultObject;\n\t}", "summary_tokens": ["specify", "a", "default", "object", "to", "fall", "back", "to", "if", "the", "jndi", "lookup", "fails"], "project": "spring-framework"}
{"id": 6820, "code": "\tpublic Charset getDefaultCharset() {\n\t\treturn this.defaultCharset;\n\t}", "summary_tokens": ["return", "the", "configured", "default", "charset"], "project": "spring-framework"}
{"id": 709, "code": "\tprotected Object postProcessObjectFromFactoryBean(Object object, String beanName) throws BeansException {\n\t\treturn object;\n\t}", "summary_tokens": ["post", "process", "the", "given", "object", "that", "has", "been", "obtained", "from", "the", "factory", "bean"], "project": "spring-framework"}
{"id": 6212, "code": "\tpublic void stop() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tif (this.running) {\n\t\t\t\tResourceAdapter resourceAdapter = getResourceAdapter();\n\t\t\t\tAssert.state(resourceAdapter != null, \"No ResourceAdapter set\");\n\t\t\t\tresourceAdapter.endpointDeactivation(getMessageEndpointFactory(), getActivationSpec());\n\t\t\t\tthis.running = false;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["deactivates", "the", "configured", "message", "endpoint"], "project": "spring-framework"}
{"id": 3558, "code": "\tprotected static void generateCodeForArguments(MethodVisitor mv, CodeFlow cf, Member member, SpelNodeImpl[] arguments) {\n\t\tString[] paramDescriptors = null;\n\t\tboolean isVarargs = false;\n\t\tif (member instanceof Constructor) {\n\t\t\tConstructor<?> ctor = (Constructor<?>) member;\n\t\t\tparamDescriptors = CodeFlow.toDescriptors(ctor.getParameterTypes());\n\t\t\tisVarargs = ctor.isVarArgs();\n\t\t}\n\t\telse { \n\t\t\tMethod method = (Method)member;\n\t\t\tparamDescriptors = CodeFlow.toDescriptors(method.getParameterTypes());\n\t\t\tisVarargs = method.isVarArgs();\n\t\t}\n\t\tif (isVarargs) {\n\t\t\t\n\t\t\t\n\t\t\tint p = 0; \n\t\t\tint childCount = arguments.length;\n\n\t\t\t\n\t\t\tfor (p = 0; p < paramDescriptors.length - 1; p++) {\n\t\t\t\tgenerateCodeForArgument(mv, cf, arguments[p], paramDescriptors[p]);\n\t\t\t}\n\n\t\t\tSpelNodeImpl lastChild = (childCount == 0 ? null : arguments[childCount - 1]);\n\t\t\tString arrayType = paramDescriptors[paramDescriptors.length - 1];\n\t\t\t\n\t\t\t\n\t\t\tif (lastChild != null && arrayType.equals(lastChild.getExitDescriptor())) {\n\t\t\t\tgenerateCodeForArgument(mv, cf, lastChild, paramDescriptors[p]);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tarrayType = arrayType.substring(1); \n\t\t\t\t\n\t\t\t\tCodeFlow.insertNewArrayCode(mv, childCount - p, arrayType);\n\t\t\t\t\n\t\t\t\tint arrayindex = 0;\n\t\t\t\twhile (p < childCount) {\n\t\t\t\t\tSpelNodeImpl child = arguments[p];\n\t\t\t\t\tmv.visitInsn(DUP);\n\t\t\t\t\tCodeFlow.insertOptimalLoad(mv, arrayindex++);\n\t\t\t\t\tgenerateCodeForArgument(mv, cf, child, arrayType);\n\t\t\t\t\tCodeFlow.insertArrayStore(mv, arrayType);\n\t\t\t\t\tp++;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tfor (int i = 0; i < paramDescriptors.length;i++) {\n\t\t\t\tgenerateCodeForArgument(mv, cf, arguments[i], paramDescriptors[i]);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["generate", "code", "that", "handles", "building", "the", "argument", "values", "for", "the", "specified", "method"], "project": "spring-framework"}
{"id": 9505, "code": "\tpublic CacheFilter getCacheFilter() {\n\t\treturn this.cacheFilter;\n\t}", "summary_tokens": ["return", "filter", "function", "that", "determines", "if", "view", "should", "be", "cached"], "project": "spring-framework"}
{"id": 4002, "code": "\tprotected Connection doGetConnection(@Nullable String username, @Nullable String password) throws SQLException {\n\t\tAssert.state(getTargetDataSource() != null, \"'targetDataSource' is required\");\n\t\tif (StringUtils.hasLength(username)) {\n\t\t\treturn getTargetDataSource().getConnection(username, password);\n\t\t}\n\t\telse {\n\t\t\treturn getTargetDataSource().getConnection();\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "delegates", "to", "the", "get", "connection", "username", "password", "method", "of", "the", "target", "data", "source", "passing", "in", "the", "specified", "user", "credentials"], "project": "spring-framework"}
{"id": 1462, "code": "\tpublic void registerPrototype(String name, Class<?> clazz, MutablePropertyValues pvs) throws BeansException {\n\t\tGenericBeanDefinition bd = new GenericBeanDefinition();\n\t\tbd.setScope(BeanDefinition.SCOPE_PROTOTYPE);\n\t\tbd.setBeanClass(clazz);\n\t\tbd.setPropertyValues(pvs);\n\t\tgetDefaultListableBeanFactory().registerBeanDefinition(name, bd);\n\t}", "summary_tokens": ["register", "a", "prototype", "bean", "with", "the", "underlying", "bean", "factory"], "project": "spring-framework"}
{"id": 3745, "code": "\tpublic String createCallString() {\n\t\tAssert.state(this.metaDataProvider != null, \"No CallMetaDataProvider available\");\n\n\t\tStringBuilder callString;\n\t\tint parameterCount = 0;\n\t\tString catalogNameToUse;\n\t\tString schemaNameToUse;\n\n\t\t\n\t\t\n\t\tif (this.metaDataProvider.isSupportsSchemasInProcedureCalls() &&\n\t\t\t\t!this.metaDataProvider.isSupportsCatalogsInProcedureCalls()) {\n\t\t\tschemaNameToUse = this.metaDataProvider.catalogNameToUse(getCatalogName());\n\t\t\tcatalogNameToUse = this.metaDataProvider.schemaNameToUse(getSchemaName());\n\t\t}\n\t\telse {\n\t\t\tcatalogNameToUse = this.metaDataProvider.catalogNameToUse(getCatalogName());\n\t\t\tschemaNameToUse = this.metaDataProvider.schemaNameToUse(getSchemaName());\n\t\t}\n\n\t\tif (isFunction() || isReturnValueRequired()) {\n\t\t\tcallString = new StringBuilder(\"{? = call \");\n\t\t\tparameterCount = -1;\n\t\t}\n\t\telse {\n\t\t\tcallString = new StringBuilder(\"{call \");\n\t\t}\n\n\t\tif (StringUtils.hasLength(catalogNameToUse)) {\n\t\t\tcallString.append(catalogNameToUse).append('.');\n\t\t}\n\t\tif (StringUtils.hasLength(schemaNameToUse)) {\n\t\t\tcallString.append(schemaNameToUse).append('.');\n\t\t}\n\t\tcallString.append(this.metaDataProvider.procedureNameToUse(getProcedureName()));\n\t\tcallString.append('(');\n\n\t\tfor (SqlParameter parameter : this.callParameters) {\n\t\t\tif (!parameter.isResultsParameter()) {\n\t\t\t\tif (parameterCount > 0) {\n\t\t\t\t\tcallString.append(\", \");\n\t\t\t\t}\n\t\t\t\tif (parameterCount >= 0) {\n\t\t\t\t\tcallString.append(createParameterBinding(parameter));\n\t\t\t\t}\n\t\t\t\tparameterCount++;\n\t\t\t}\n\t\t}\n\t\tcallString.append(\")}\");\n\n\t\treturn callString.toString();\n\t}\n\n\t\n\tprotected String createParameterBinding(SqlParameter parameter) {\n\t\treturn (isNamedBinding() ? parameter.getName() + \" => ?\" : \"?\");\n\t}\n\n\tprivate static String lowerCase(@Nullable String paramName) {\n\t\treturn (paramName != null ? paramName.toLowerCase() : \"\");\n\t}\n\n}", "summary_tokens": ["build", "the", "call", "string", "based", "on", "configuration", "and", "meta", "data", "information"], "project": "spring-framework"}
{"id": 9811, "code": "\tdefault void configureMessageBroker(MessageBrokerRegistry registry) {\n\t}", "summary_tokens": ["configure", "message", "broker", "options"], "project": "spring-framework"}
{"id": 6141, "code": "\tpublic void beforeTestMethodAnnotationWithFailingAsyncEventListener() throws Exception {\n\t\tTrackingAsyncUncaughtExceptionHandler.asyncException = null;\n\n\t\tString methodName = \"testWithFailingAsyncEventListener\";\n\t\tMethod method = ReflectionUtils.findMethod(ExampleTestCase.class, methodName);\n\n\t\ttestContextManager.beforeTestMethod(testInstance, method);\n\n\t\tassertThat(countDownLatch.await(2, TimeUnit.SECONDS)).isTrue();\n\n\t\tverify(listener, only()).beforeTestMethod(testContext);\n\t\tassertThat(TrackingAsyncUncaughtExceptionHandler.asyncException.getMessage())\n\t\t\t\t.startsWith(\"Asynchronous exception for test method [\" + methodName + \"] in thread [\" + THREAD_NAME_PREFIX);\n\t}", "summary_tokens": ["an", "exception", "thrown", "from", "an", "event", "listener", "that", "is", "executed", "asynchronously", "should", "not", "fail", "the", "test", "method"], "project": "spring-framework"}
{"id": 9720, "code": "\tpublic void setSourceKey(String sourceKey) {\n\t\tthis.sourceKey = sourceKey;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "model", "attribute", "that", "represents", "the", "xslt", "source"], "project": "spring-framework"}
{"id": 3502, "code": "\tpublic String lastDescriptor() {\n\t\treturn CollectionUtils.lastElement(this.compilationScopes.peek());\n\t}", "summary_tokens": ["return", "the", "descriptor", "for", "the", "item", "currently", "on", "top", "of", "the", "stack", "in", "the", "current", "scope"], "project": "spring-framework"}
{"id": 8303, "code": "\tpublic static String getNameForParameter(MethodParameter parameter) {\n\t\tModelAttribute ann = parameter.getParameterAnnotation(ModelAttribute.class);\n\t\tString name = (ann != null ? ann.value() : null);\n\t\treturn (StringUtils.hasText(name) ? name : Conventions.getVariableNameForParameter(parameter));\n\t}", "summary_tokens": ["derive", "the", "model", "attribute", "name", "for", "the", "given", "method", "parameter", "based", "on", "a", "parameter", "annotation", "if", "present", "or", "falling", "back", "on", "parameter", "type", "based", "conventions"], "project": "spring-framework"}
{"id": 4091, "code": "\tprotected void validateNamedParameters(@Nullable Map<String, ?> parameters) throws InvalidDataAccessApiUsageException {\n\t\tcheckCompiled();\n\t\tMap<String, ?> paramsToUse = (parameters != null ? parameters : Collections.<String, Object> emptyMap());\n\t\tint declaredInParameters = 0;\n\t\tfor (SqlParameter param : this.declaredParameters) {\n\t\t\tif (param.isInputValueProvided()) {\n\t\t\t\tif (!supportsLobParameters() &&\n\t\t\t\t\t\t(param.getSqlType() == Types.BLOB || param.getSqlType() == Types.CLOB)) {\n\t\t\t\t\tthrow new InvalidDataAccessApiUsageException(\n\t\t\t\t\t\t\t\"BLOB or CLOB parameters are not allowed for this kind of operation\");\n\t\t\t\t}\n\t\t\t\tif (param.getName() != null && !paramsToUse.containsKey(param.getName())) {\n\t\t\t\t\tthrow new InvalidDataAccessApiUsageException(\"The parameter named '\" + param.getName() +\n\t\t\t\t\t\t\t\"' was not among the parameters supplied: \" + paramsToUse.keySet());\n\t\t\t\t}\n\t\t\t\tdeclaredInParameters++;\n\t\t\t}\n\t\t}\n\t\tvalidateParameterCount(paramsToUse.size(), declaredInParameters);\n\t}", "summary_tokens": ["validate", "the", "named", "parameters", "passed", "to", "an", "execute", "method", "based", "on", "declared", "parameters"], "project": "spring-framework"}
{"id": 636, "code": "\tpublic BeanDefinitionBuilder addAutowiredProperty(String name) {\n\t\tthis.beanDefinition.getPropertyValues().add(name, AutowiredPropertyMarker.INSTANCE);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "an", "autowired", "marker", "for", "the", "specified", "property", "on", "the", "specified", "bean"], "project": "spring-framework"}
{"id": 8926, "code": "\tpublic Set<RequestMethod> getMethods() {\n\t\treturn this.methods;\n\t}", "summary_tokens": ["returns", "all", "request", "method", "request", "methods", "contained", "in", "this", "condition"], "project": "spring-framework"}
{"id": 7184, "code": "\tpublic final Map<String, String[]> getActualParams() {\n\t\treturn this.actualParams;\n\t}", "summary_tokens": ["return", "the", "actual", "parameter", "map", "associated", "with", "the", "servlet", "request"], "project": "spring-framework"}
{"id": 7986, "code": "\tpublic CorsRegistration allowedHeaders(String... headers) {\n\t\tthis.config.setAllowedHeaders(Arrays.asList(headers));\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "list", "of", "headers", "that", "a", "pre", "flight", "request", "can", "list", "as", "allowed", "for", "use", "during", "an", "actual", "request"], "project": "spring-framework"}
{"id": 7897, "code": "\tpublic HttpHeaders getWrittenHeaders() {\n\t\treturn writtenHeaders;\n\t}", "summary_tokens": ["return", "a", "copy", "of", "the", "actual", "headers", "written", "at", "the", "time", "of", "the", "call", "to", "get", "response", "body", "i"], "project": "spring-framework"}
{"id": 6783, "code": "\tpublic Executor getExecutor() {\n\t\treturn this.executor;\n\t}", "summary_tokens": ["return", "the", "configured", "executor"], "project": "spring-framework"}
{"id": 700, "code": "\tprotected Object writeReplace() {\n\t\tList<DestructionAwareBeanPostProcessor> serializablePostProcessors = null;\n\t\tif (this.beanPostProcessors != null) {\n\t\t\tserializablePostProcessors = new ArrayList<>();\n\t\t\tfor (DestructionAwareBeanPostProcessor postProcessor : this.beanPostProcessors) {\n\t\t\t\tif (postProcessor instanceof Serializable) {\n\t\t\t\t\tserializablePostProcessors.add(postProcessor);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn new DisposableBeanAdapter(\n\t\t\t\tthis.bean, this.beanName, this.nonPublicAccessAllowed, this.invokeDisposableBean,\n\t\t\t\tthis.invokeAutoCloseable, this.destroyMethodNames, serializablePostProcessors);\n\t}", "summary_tokens": ["serializes", "a", "copy", "of", "the", "state", "of", "this", "class", "filtering", "out", "non", "serializable", "bean", "post", "processors"], "project": "spring-framework"}
{"id": 92, "code": "\tpublic void setFrozen(boolean frozen) {\n\t\tthis.frozen = frozen;\n\t}", "summary_tokens": ["set", "whether", "this", "config", "should", "be", "frozen"], "project": "spring-framework"}
{"id": 4608, "code": "\tprotected Message receiveFromConsumer(MessageConsumer consumer, long timeout) throws JMSException {\n\t\tif (timeout > 0) {\n\t\t\treturn consumer.receive(timeout);\n\t\t}\n\t\telse if (timeout < 0) {\n\t\t\treturn consumer.receiveNoWait();\n\t\t}\n\t\telse {\n\t\t\treturn consumer.receive();\n\t\t}\n\t}", "summary_tokens": ["actually", "receive", "a", "message", "from", "the", "given", "consumer"], "project": "spring-framework"}
{"id": 4122, "code": "\tpublic int updateByNamedParam(Map<String, ?> paramMap, KeyHolder generatedKeyHolder) throws DataAccessException {\n\t\tvalidateNamedParameters(paramMap);\n\t\tParsedSql parsedSql = getParsedSql();\n\t\tMapSqlParameterSource paramSource = new MapSqlParameterSource(paramMap);\n\t\tString sqlToUse = NamedParameterUtils.substituteNamedParameters(parsedSql, paramSource);\n\t\tObject[] params = NamedParameterUtils.buildValueArray(parsedSql, paramSource, getDeclaredParameters());\n\t\tint rowsAffected = getJdbcTemplate().update(newPreparedStatementCreator(sqlToUse, params), generatedKeyHolder);\n\t\tcheckRowsAffected(rowsAffected);\n\t\treturn rowsAffected;\n\t}", "summary_tokens": ["method", "to", "execute", "the", "update", "given", "arguments", "and", "retrieve", "the", "generated", "keys", "using", "a", "key", "holder"], "project": "spring-framework"}
{"id": 1538, "code": "\tpublic void setListeners(MBeanExporterListener... listeners) {\n\t\tthis.listeners = listeners;\n\t}", "summary_tokens": ["set", "the", "mbean", "exporter", "listener", "s", "that", "should", "be", "notified", "of", "mbean", "registration", "and", "unregistration", "events"], "project": "spring-framework"}
{"id": 8536, "code": "\tdefault Locale resolveLocale(HttpServletRequest request) {\n\t\tLocale locale = resolveLocaleContext(request).getLocale();\n\t\treturn (locale != null ? locale : request.getLocale());\n\t}", "summary_tokens": ["default", "implementation", "of", "locale", "resolver", "resolve", "locale", "http", "servlet", "request", "that", "delegates", "to", "resolve", "locale", "context", "http", "servlet", "request", "falling", "back", "to", "http", "servlet", "request", "get", "locale", "if", "necessary"], "project": "spring-framework"}
{"id": 9106, "code": "\tpublic String[] getErrorMessages() {\n\t\treturn initErrorMessages();\n\t}", "summary_tokens": ["return", "the", "resolved", "error", "messages", "for", "the", "field", "or", "object", "if", "any"], "project": "spring-framework"}
{"id": 6106, "code": "\tpublic ResultMatcher isUnavailableForLegalReasons() {\n\t\treturn matcher(HttpStatus.valueOf(451));\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 6326, "code": "\tprotected TransactionSynchronizationRegistry findTransactionSynchronizationRegistry(\n\t\t\t@Nullable UserTransaction ut, @Nullable TransactionManager tm) throws TransactionSystemException {\n\n\t\tif (this.userTransactionObtainedFromJndi) {\n\t\t\t\n\t\t\t\n\t\t\tString jndiName = DEFAULT_TRANSACTION_SYNCHRONIZATION_REGISTRY_NAME;\n\t\t\ttry {\n\t\t\t\tTransactionSynchronizationRegistry tsr = getJndiTemplate().lookup(jndiName, TransactionSynchronizationRegistry.class);\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"JTA TransactionSynchronizationRegistry found at default JNDI location [\" + jndiName + \"]\");\n\t\t\t\t}\n\t\t\t\treturn tsr;\n\t\t\t}\n\t\t\tcatch (NamingException ex) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"No JTA TransactionSynchronizationRegistry found at default JNDI location [\" + jndiName + \"]\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\tif (ut instanceof TransactionSynchronizationRegistry) {\n\t\t\treturn (TransactionSynchronizationRegistry) ut;\n\t\t}\n\t\tif (tm instanceof TransactionSynchronizationRegistry) {\n\t\t\treturn (TransactionSynchronizationRegistry) tm;\n\t\t}\n\t\t\n\t\treturn null;\n\t}", "summary_tokens": ["find", "the", "jta", "0"], "project": "spring-framework"}
{"id": 4783, "code": "\tpublic MetadataEncoder metadataAndOrRoute(@Nullable Map<Object, MimeType> metadata,\n\t\t\t@Nullable String route, @Nullable Object[] vars) {\n\n\t\tif (route != null) {\n\t\t\tthis.route = expand(route, vars != null ? vars : new Object[0]);\n\t\t}\n\t\tif (!CollectionUtils.isEmpty(metadata)) {\n\t\t\tfor (Map.Entry<Object, MimeType> entry : metadata.entrySet()) {\n\t\t\t\tmetadata(entry.getKey(), entry.getValue());\n\t\t\t}\n\t\t}\n\t\tassertMetadataEntryCount();\n\t\treturn this;\n\t}", "summary_tokens": ["add", "route", "and", "or", "metadata", "both", "optional"], "project": "spring-framework"}
{"id": 9022, "code": "\tpublic synchronized void completeWithError(Throwable ex) {\n\t\t\n\t\tif (this.sendFailed) {\n\t\t\treturn;\n\t\t}\n\t\tthis.complete = true;\n\t\tthis.failure = ex;\n\t\tif (this.handler != null) {\n\t\t\tthis.handler.completeWithError(ex);\n\t\t}\n\t}", "summary_tokens": ["complete", "request", "processing", "with", "an", "error"], "project": "spring-framework"}
{"id": 917, "code": "\tvoid readMethodReturnsSupertypeOfWriteMethodParameter() throws Exception {\n\t\t@SuppressWarnings(\"unused\") class C {\n\t\t\tpublic Number getFoo() { return null; }\n\t\t\tpublic void setFoo(Integer foo) { }\n\t\t}\n\n\t\tBeanInfo bi = Introspector.getBeanInfo(C.class);\n\t\tBeanInfo ebi = new ExtendedBeanInfo(bi);\n\n\t\tassertThat(hasReadMethodForProperty(bi, \"foo\")).isTrue();\n\t\tassertThat(hasReadMethodForProperty(ebi, \"foo\")).isTrue();\n\t\tassertThat(hasWriteMethodForProperty(ebi, \"foo\")).isEqualTo(hasWriteMethodForProperty(bi, \"foo\"));\n\t}", "summary_tokens": ["extended", "bean", "info", "should", "behave", "exactly", "like", "bean", "info", "in", "strange", "edge", "cases"], "project": "spring-framework"}
{"id": 8025, "code": "\tprotected final PathMatchConfigurer getPathMatchConfigurer() {\n\t\tif (this.pathMatchConfigurer == null) {\n\t\t\tthis.pathMatchConfigurer = new PathMatchConfigurer();\n\t\t\tconfigurePathMatching(this.pathMatchConfigurer);\n\t\t}\n\t\treturn this.pathMatchConfigurer;\n\t}", "summary_tokens": ["callback", "for", "building", "the", "path", "match", "configurer"], "project": "spring-framework"}
{"id": 8085, "code": "\tstatic ExchangeFilterFunction ofResponseProcessor(Function<ClientResponse, Mono<ClientResponse>> processor) {\n\t\tAssert.notNull(processor, \"ClientResponse Function must not be null\");\n\t\treturn (request, next) -> next.exchange(request).flatMap(processor);\n\t}", "summary_tokens": ["adapt", "the", "given", "response", "processor", "function", "to", "a", "filter", "function", "that", "only", "operates", "on", "the", "client", "response"], "project": "spring-framework"}
{"id": 3052, "code": "\tpublic String toString() {\n\t\tthis.styler.styleEnd(this.buffer, this.object);\n\t\treturn this.buffer.toString();\n\t}", "summary_tokens": ["return", "the", "string", "representation", "that", "this", "to", "string", "creator", "built"], "project": "spring-framework"}
{"id": 8647, "code": "\tpublic void setViewName(String viewName) {\n\t\tthis.controller.setViewName(viewName);\n\t}", "summary_tokens": ["set", "the", "view", "name", "to", "return"], "project": "spring-framework"}
{"id": 5221, "code": "\tpublic void setPersistenceUnitName(@Nullable String persistenceUnitName) {\n\t\tsuper.setPersistenceUnitName(persistenceUnitName);\n\t\tif (persistenceUnitName != null) {\n\t\t\tthis.internalPersistenceUnitManager.setDefaultPersistenceUnitName(persistenceUnitName);\n\t\t}\n\t}", "summary_tokens": ["uses", "the", "specified", "persistence", "unit", "name", "as", "the", "name", "of", "the", "default", "persistence", "unit", "if", "applicable"], "project": "spring-framework"}
{"id": 8029, "code": "\tprotected void addResourceHandlers(ResourceHandlerRegistry registry) {\n\t}", "summary_tokens": ["override", "this", "method", "to", "add", "resource", "handlers", "for", "serving", "static", "resources"], "project": "spring-framework"}
{"id": 6540, "code": "\tpublic static Map<Object, Object> getResourceMap() {\n\t\tMap<Object, Object> map = resources.get();\n\t\treturn (map != null ? Collections.unmodifiableMap(map) : Collections.emptyMap());\n\t}", "summary_tokens": ["return", "all", "resources", "that", "are", "bound", "to", "the", "current", "thread"], "project": "spring-framework"}
{"id": 5299, "code": "\tpublic void setShowSql(boolean showSql) {\n\t\tthis.showSql = showSql;\n\t}", "summary_tokens": ["set", "whether", "to", "show", "sql", "in", "the", "log", "or", "in", "the", "console"], "project": "spring-framework"}
{"id": 922, "code": "\tvoid propertyDescriptorOrderIsEqual() throws Exception {\n\t\tBeanInfo bi = Introspector.getBeanInfo(TestBean.class);\n\t\tBeanInfo ebi = new ExtendedBeanInfo(bi);\n\n\t\tfor (int i = 0; i < bi.getPropertyDescriptors().length; i++) {\n\t\t\tassertThat(ebi.getPropertyDescriptors()[i].getName()).isEqualTo(bi.getPropertyDescriptors()[i].getName());\n\t\t}\n\t}", "summary_tokens": ["bean", "info", "get", "property", "descriptors", "returns", "alphanumerically", "sorted"], "project": "spring-framework"}
{"id": 6348, "code": "\tprivate Mono<Void> resume(TransactionSynchronizationManager synchronizationManager,\n\t\t\t@Nullable Object transaction, @Nullable SuspendedResourcesHolder resourcesHolder)\n\t\t\tthrows TransactionException {\n\n\t\tMono<Void> resume = Mono.empty();\n\n\t\tif (resourcesHolder != null) {\n\t\t\tObject suspendedResources = resourcesHolder.suspendedResources;\n\t\t\tif (suspendedResources != null) {\n\t\t\t\tresume =  doResume(synchronizationManager, transaction, suspendedResources);\n\t\t\t}\n\t\t\tList<TransactionSynchronization> suspendedSynchronizations = resourcesHolder.suspendedSynchronizations;\n\t\t\tif (suspendedSynchronizations != null) {\n\t\t\t\tsynchronizationManager.setActualTransactionActive(resourcesHolder.wasActive);\n\t\t\t\tsynchronizationManager.setCurrentTransactionIsolationLevel(resourcesHolder.isolationLevel);\n\t\t\t\tsynchronizationManager.setCurrentTransactionReadOnly(resourcesHolder.readOnly);\n\t\t\t\tsynchronizationManager.setCurrentTransactionName(resourcesHolder.name);\n\t\t\t\treturn resume.then(doResumeSynchronization(synchronizationManager, suspendedSynchronizations));\n\t\t\t}\n\t\t}\n\n\t\treturn resume;\n\t}", "summary_tokens": ["resume", "the", "given", "transaction"], "project": "spring-framework"}
{"id": 5639, "code": "\tpublic void evaluate() throws Throwable {\n\t\tList<Throwable> errors = new ArrayList<>();\n\t\ttry {\n\t\t\tthis.next.evaluate();\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\terrors.add(ex);\n\t\t}\n\n\t\ttry {\n\t\t\tthis.testContextManager.afterTestClass();\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\terrors.add(ex);\n\t\t}\n\n\t\tMultipleFailureException.assertEmpty(errors);\n\t}", "summary_tokens": ["evaluate", "the", "next", "statement", "in", "the", "execution", "chain", "typically", "an", "instance", "of", "org"], "project": "spring-framework"}
{"id": 4163, "code": "\tprotected Resource loadResource(String path) {\n\t\treturn new ClassPathResource(path, getClass().getClassLoader());\n\t}", "summary_tokens": ["load", "the", "given", "resource", "from", "the", "class", "path"], "project": "spring-framework"}
{"id": 8676, "code": "\tpublic HandlerMapping viewControllerHandlerMapping(\n\t\t\t@Qualifier(\"mvcConversionService\") FormattingConversionService conversionService,\n\t\t\t@Qualifier(\"mvcResourceUrlProvider\") ResourceUrlProvider resourceUrlProvider) {\n\n\t\tViewControllerRegistry registry = new ViewControllerRegistry(this.applicationContext);\n\t\taddViewControllers(registry);\n\n\t\tAbstractHandlerMapping mapping = registry.buildHandlerMapping();\n\t\tinitHandlerMapping(mapping, conversionService, resourceUrlProvider);\n\t\treturn mapping;\n\t}", "summary_tokens": ["return", "a", "handler", "mapping", "ordered", "at", "0", "to", "map", "url", "paths", "directly", "to", "view", "names"], "project": "spring-framework"}
{"id": 912, "code": "\tvoid copyPropertiesHonorsGenericTypeMatchesFromIntegerToWildcard() {\n\t\tIntegerListHolder1 integerListHolder1 = new IntegerListHolder1();\n\t\tintegerListHolder1.getList().add(42);\n\t\tWildcardListHolder2 wildcardListHolder2 = new WildcardListHolder2();\n\n\t\tBeanUtils.copyProperties(integerListHolder1, wildcardListHolder2);\n\t\tassertThat(integerListHolder1.getList()).containsOnly(42);\n\t\tassertThat(wildcardListHolder2.getList()).isEqualTo(Arrays.asList(42));\n\t}", "summary_tokens": ["list", "integer", "can", "be", "copied", "to", "list"], "project": "spring-framework"}
{"id": 6107, "code": "\tpublic ResultMatcher isInternalServerError() {\n\t\treturn matcher(HttpStatus.INTERNAL_SERVER_ERROR);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 394, "code": "\tpublic String getBeanName() {\n\t\treturn this.beanName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "missing", "bean", "if", "it", "was", "a", "lookup", "em", "by", "name", "em", "that", "failed"], "project": "spring-framework"}
{"id": 3754, "code": "\tpublic boolean isNullable() {\n\t\treturn this.nullable;\n\t}", "summary_tokens": ["return", "whether", "the", "parameter", "is", "nullable"], "project": "spring-framework"}
{"id": 7903, "code": "\tprotected void doTestTony(PropertyValues pvs) throws Exception {\n\t\tassertThat(pvs.getPropertyValues().length == 3).as(\"Contains 3\").isTrue();\n\t\tassertThat(pvs.contains(\"forname\")).as(\"Contains forname\").isTrue();\n\t\tassertThat(pvs.contains(\"surname\")).as(\"Contains surname\").isTrue();\n\t\tassertThat(pvs.contains(\"age\")).as(\"Contains age\").isTrue();\n\t\tboolean condition1 = !pvs.contains(\"tory\");\n\t\tassertThat(condition1).as(\"Doesn't contain tory\").isTrue();\n\n\t\tPropertyValue[] ps = pvs.getPropertyValues();\n\t\tMap<String, String> m = new HashMap<>();\n\t\tm.put(\"forname\", \"Tony\");\n\t\tm.put(\"surname\", \"Blair\");\n\t\tm.put(\"age\", \"50\");\n\t\tfor (PropertyValue element : ps) {\n\t\t\tObject val = m.get(element.getName());\n\t\t\tassertThat(val != null).as(\"Can't have unexpected value\").isTrue();\n\t\t\tboolean condition = val instanceof String;\n\t\t\tassertThat(condition).as(\"Val i string\").isTrue();\n\t\t\tassertThat(val.equals(element.getValue())).as(\"val matches expected\").isTrue();\n\t\t\tm.remove(element.getName());\n\t\t}\n\t\tassertThat(m.size() == 0).as(\"Map size is 0\").isTrue();\n\t}", "summary_tokens": ["must", "contain", "forname", "tony", "surname", "blair", "age", "0"], "project": "spring-framework"}
{"id": 6486, "code": "", "summary_tokens": ["this", "implementation", "is", "empty", "considering", "flush", "as", "a", "no", "op"], "project": "spring-framework"}
{"id": 4694, "code": "\tprotected static List<Class<? extends Throwable>> getExceptionsFromMethodSignature(Method method) {\n\t\tList<Class<? extends Throwable>> result = new ArrayList<>();\n\t\tfor (Class<?> paramType : method.getParameterTypes()) {\n\t\t\tif (Throwable.class.isAssignableFrom(paramType)) {\n\t\t\t\tresult.add((Class<? extends Throwable>) paramType);\n\t\t\t}\n\t\t}\n\t\tif (result.isEmpty()) {\n\t\t\tthrow new IllegalStateException(\"No exception types mapped to \" + method);\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["extract", "the", "exceptions", "this", "method", "handles"], "project": "spring-framework"}
{"id": 2749, "code": "\tpublic boolean hasAlias(String name, String alias) {\n\t\tString registeredName = this.aliasMap.get(alias);\n\t\treturn ObjectUtils.nullSafeEquals(registeredName, name) ||\n\t\t\t\t(registeredName != null && hasAlias(name, registeredName));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "name", "has", "the", "given", "alias", "registered"], "project": "spring-framework"}
{"id": 7318, "code": "\tpublic void clearConcurrentResult() {\n\t\tsynchronized (WebAsyncManager.this) {\n\t\t\tthis.concurrentResult = RESULT_NONE;\n\t\t\tthis.concurrentResultContext = null;\n\t\t}\n\t}", "summary_tokens": ["clear", "get", "concurrent", "result", "concurrent", "result", "and", "get", "concurrent", "result", "context", "concurrent", "result", "context"], "project": "spring-framework"}
{"id": 9521, "code": "\tpublic void setUrl(@Nullable String url) {\n\t\tthis.url = url;\n\t}", "summary_tokens": ["set", "the", "url", "of", "the", "resource", "that", "this", "view", "wraps"], "project": "spring-framework"}
{"id": 3753, "code": "\tpublic String getTypeName() {\n\t\treturn this.typeName;\n\t}", "summary_tokens": ["return", "the", "parameter", "type", "name"], "project": "spring-framework"}
{"id": 536, "code": "\tpublic void setSearchSystemEnvironment(boolean searchSystemEnvironment) {\n\t\tthis.searchSystemEnvironment = searchSystemEnvironment;\n\t}", "summary_tokens": ["set", "whether", "to", "search", "for", "a", "matching", "system", "environment", "variable", "if", "no", "matching", "system", "property", "has", "been", "found"], "project": "spring-framework"}
{"id": 8338, "code": "\tpublic Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "current", "value", "of", "the", "field", "i"], "project": "spring-framework"}
{"id": 597, "code": "\tpublic ParseState getParseState() {\n\t\treturn this.parseState;\n\t}", "summary_tokens": ["get", "the", "parse", "state", "at", "the", "time", "of", "the", "error", "may", "be", "null"], "project": "spring-framework"}
{"id": 7889, "code": "\tpublic void setPathOptions(PathContainer.Options pathOptions) {\n\t\tthis.pathOptions = pathOptions;\n\t}", "summary_tokens": ["set", "options", "for", "parsing", "patterns"], "project": "spring-framework"}
{"id": 7848, "code": "\tpublic boolean shouldRemoveSemicolonContent() {\n\t\treturn this.removeSemicolonContent;\n\t}", "summary_tokens": ["whether", "configured", "to", "remove", "semicolon", "content", "from", "the", "request", "uri"], "project": "spring-framework"}
{"id": 3453, "code": "\tprotected <T> void testDecodeAll(Publisher<DataBuffer> input, ResolvableType outputType,\n\t\t\tConsumer<StepVerifier.FirstStep<T>> stepConsumer,\n\t\t\t@Nullable MimeType mimeType, @Nullable Map<String, Object> hints) {\n\n\t\ttestDecode(input, outputType, stepConsumer, mimeType, hints);\n\t\ttestDecodeError(input, outputType, mimeType, hints);\n\t\ttestDecodeCancel(input, outputType, mimeType, hints);\n\t\ttestDecodeEmpty(outputType, mimeType, hints);\n\t}", "summary_tokens": ["helper", "method", "that", "tests", "for", "a", "variety", "of", "flux", "decoding", "scenarios"], "project": "spring-framework"}
{"id": 9818, "code": "\tpublic WebSocketTransportRegistration setTimeToFirstMessage(int timeToFirstMessage) {\n\t\tthis.timeToFirstMessage = timeToFirstMessage;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "maximum", "time", "allowed", "in", "milliseconds", "after", "the", "web", "socket", "connection", "is", "established", "and", "before", "the", "first", "sub", "protocol", "message", "is", "received"], "project": "spring-framework"}
{"id": 6623, "code": "\tpublic List<MediaType> getAccept() {\n\t\treturn MediaType.parseMediaTypes(get(ACCEPT));\n\t}", "summary_tokens": ["return", "the", "list", "of", "acceptable", "media", "type", "media", "types", "as", "specified", "by", "the", "accept", "header"], "project": "spring-framework"}
{"id": 5741, "code": "\tprotected final boolean isRollback(TestContext testContext) throws Exception {\n\t\tboolean rollback = isDefaultRollback(testContext);\n\t\tRollback rollbackAnnotation =\n\t\t\t\tAnnotatedElementUtils.findMergedAnnotation(testContext.getTestMethod(), Rollback.class);\n\t\tif (rollbackAnnotation != null) {\n\t\t\tboolean rollbackOverride = rollbackAnnotation.value();\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(String.format(\n\t\t\t\t\t\t\"Method-level @Rollback(%s) overrides default rollback [%s] for test context %s.\",\n\t\t\t\t\t\trollbackOverride, rollback, testContext));\n\t\t\t}\n\t\t\trollback = rollbackOverride;\n\t\t}\n\t\telse {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(String.format(\n\t\t\t\t\t\t\"No method-level @Rollback override: using default rollback [%s] for test context %s.\",\n\t\t\t\t\t\trollback, testContext));\n\t\t\t}\n\t\t}\n\t\treturn rollback;\n\t}", "summary_tokens": ["determine", "whether", "to", "rollback", "transactions", "for", "the", "supplied", "test", "context", "test", "context", "by", "taking", "into", "consideration", "the", "is", "default", "rollback", "test", "context", "default", "rollback", "flag", "and", "a", "possible", "method", "level", "override", "via", "the", "rollback", "annotation"], "project": "spring-framework"}
{"id": 4320, "code": "\tpublic void setDefaultDestinationName(@Nullable String destinationName) {\n\t\tthis.defaultDestination = destinationName;\n\t}", "summary_tokens": ["set", "the", "destination", "name", "to", "be", "used", "on", "send", "receive", "operations", "that", "do", "not", "have", "a", "destination", "parameter"], "project": "spring-framework"}
{"id": 4466, "code": "\tpublic final int getIdleConsumerLimit() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\treturn this.idleConsumerLimit;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "limit", "for", "the", "number", "of", "idle", "consumers"], "project": "spring-framework"}
{"id": 3770, "code": "\tpublic void setCatalogName(@Nullable String catalogName) {\n\t\tthis.catalogName = catalogName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "catalog", "for", "this", "context"], "project": "spring-framework"}
{"id": 5910, "code": "\tExchangeResult getExchangeResult(String requestId, @Nullable String uriTemplate, Duration timeout) {\n\t\tClientExchangeInfo clientInfo = this.exchanges.remove(requestId);\n\t\tAssert.state(clientInfo != null, () -> {\n\t\t\tString header = WebTestClient.WEBTESTCLIENT_REQUEST_ID;\n\t\t\treturn \"No match for \" + header + \"=\" + requestId;\n\t\t});\n\t\treturn new ExchangeResult(clientInfo.getRequest(), clientInfo.getResponse(),\n\t\t\t\tclientInfo.getRequest().getRecorder().getContent(),\n\t\t\t\tclientInfo.getResponse().getRecorder().getContent(),\n\t\t\t\ttimeout, uriTemplate,\n\t\t\t\tclientInfo.getResponse().getMockServerResult());\n\t}", "summary_tokens": ["create", "the", "exchange", "result", "for", "the", "given", "request", "id", "header", "value"], "project": "spring-framework"}
{"id": 531, "code": "\tpublic void setResultType(Class<?> resultType) {\n\t\tthis.resultType = resultType;\n\t}", "summary_tokens": ["specify", "the", "type", "of", "the", "result", "from", "evaluating", "the", "property", "path"], "project": "spring-framework"}
{"id": 8016, "code": "\tpublic UrlBasedViewResolverRegistration scriptTemplate() {\n\t\tif (!checkBeanOfType(ScriptTemplateConfigurer.class)) {\n\t\t\tthrow new BeanInitializationException(\"In addition to a script template view resolver \" +\n\t\t\t\t\t\"there must also be a single ScriptTemplateConfig bean in this web application context \" +\n\t\t\t\t\t\"(or its parent): ScriptTemplateConfigurer is the usual implementation. \" +\n\t\t\t\t\t\"This bean may be given any name.\");\n\t\t}\n\t\tScriptRegistration registration = new ScriptRegistration();\n\t\tUrlBasedViewResolver resolver = registration.getViewResolver();\n\t\tif (this.applicationContext != null) {\n\t\t\tresolver.setApplicationContext(this.applicationContext);\n\t\t}\n\t\tthis.viewResolvers.add(resolver);\n\t\treturn registration;\n\t}", "summary_tokens": ["register", "a", "script", "template", "view", "resolver", "with", "an", "empty", "default", "view", "name", "prefix", "and", "suffix"], "project": "spring-framework"}
{"id": 1435, "code": "\tpublic void setConcurrentRefresh(boolean concurrentRefresh) {\n\t\tthis.concurrentRefresh = concurrentRefresh;\n\t}", "summary_tokens": ["specify", "whether", "to", "allow", "for", "concurrent", "refresh", "behavior", "i"], "project": "spring-framework"}
{"id": 8671, "code": "\tpublic PathPatternParser mvcPatternParser() {\n\t\treturn getPathMatchConfigurer().getPatternParserOrDefault();\n\t}", "summary_tokens": ["return", "a", "global", "path", "pattern", "parser", "instance", "to", "use", "for", "parsing", "patterns", "to", "match", "to", "the", "org"], "project": "spring-framework"}
{"id": 2130, "code": "\tprotected void start(MBeanExporter exporter) {\n\t\texporter.afterPropertiesSet();\n\t\texporter.afterSingletonsInstantiated();\n\t}", "summary_tokens": ["start", "the", "specified", "mbean", "exporter"], "project": "spring-framework"}
{"id": 3487, "code": "\tpublic static boolean toBoolean(TypeConverter typeConverter, TypedValue typedValue) {\n\t\treturn convertValue(typeConverter, typedValue, Boolean.class);\n\t}", "summary_tokens": ["attempt", "to", "convert", "a", "typed", "value", "to", "a", "boolean", "using", "the", "supplied", "type", "converter"], "project": "spring-framework"}
{"id": 1982, "code": "\tprotected AbstractPropertyBindingResult getInternalBindingResult() {\n\t\tif (this.bindingResult == null) {\n\t\t\tthis.bindingResult = (this.directFieldAccess ?\n\t\t\t\t\tcreateDirectFieldBindingResult(): createBeanPropertyBindingResult());\n\t\t}\n\t\treturn this.bindingResult;\n\t}", "summary_tokens": ["return", "the", "internal", "binding", "result", "held", "by", "this", "data", "binder", "as", "an", "abstract", "property", "binding", "result"], "project": "spring-framework"}
{"id": 5746, "code": "\tpublic boolean equals(@Nullable Object other) {\n\t\treturn (this == other || (super.equals(other) &&\n\t\t\t\tthis.resourceBasePath.equals(((WebMergedContextConfiguration) other).resourceBasePath)));\n\t}", "summary_tokens": ["determine", "if", "the", "supplied", "object", "is", "equal", "to", "this", "web", "merged", "context", "configuration", "instance", "by", "comparing", "both", "object", "s", "get", "locations", "locations", "get", "classes", "annotated", "classes", "get", "context", "initializer", "classes", "context", "initializer", "classes", "get", "active", "profiles", "active", "profiles", "get", "resource", "base", "path", "resource", "base", "path", "get", "parent", "parents", "and", "the", "fully", "qualified", "names", "of", "their", "get", "context", "loader", "context", "loaders"], "project": "spring-framework"}
{"id": 7367, "code": "\tprotected Resource getResourceByPath(String path) {\n\t\treturn new ServletContextResource(this.servletContext, path);\n\t}", "summary_tokens": ["this", "implementation", "supports", "file", "paths", "beneath", "the", "root", "of", "the", "web", "application"], "project": "spring-framework"}
{"id": 9705, "code": "\tpublic void setEngine(@Nullable ScriptEngine engine) {\n\t\tthis.engine = engine;\n\t}", "summary_tokens": ["set", "the", "script", "engine", "to", "use", "by", "the", "view"], "project": "spring-framework"}
{"id": 8527, "code": "\tdefault boolean usesPathPatterns() {\n\t\treturn false;\n\t}", "summary_tokens": ["whether", "this", "handler", "mapping", "instance", "has", "been", "enabled", "to", "use", "parsed", "org"], "project": "spring-framework"}
{"id": 527, "code": "\tpublic boolean hasPropertyOverridesFor(String beanName) {\n\t\treturn this.beanNames.contains(beanName);\n\t}", "summary_tokens": ["were", "there", "overrides", "for", "this", "bean", "only", "valid", "after", "processing", "has", "occurred", "at", "least", "once"], "project": "spring-framework"}
{"id": 3408, "code": "\tpublic boolean getFeature(String name) throws SAXNotRecognizedException, SAXNotSupportedException {\n\t\tif (name.startsWith(\"http://xml.org/sax/features/\")) {\n\t\t\treturn false;\n\t\t}\n\t\telse {\n\t\t\tthrow new SAXNotRecognizedException(name);\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "throws", "a", "saxnot", "recognized", "exception", "exception", "for", "any", "feature", "outside", "the", "http", "xml"], "project": "spring-framework"}
{"id": 7641, "code": "\tprotected void initializeMultipart() {\n\t\tthrow new IllegalStateException(\"Multipart request not initialized\");\n\t}", "summary_tokens": ["lazily", "initialize", "the", "multipart", "request", "if", "possible"], "project": "spring-framework"}
{"id": 4697, "code": "\tpublic Method resolveMethodByExceptionType(Class<? extends Throwable> exceptionType) {\n\t\tMethod method = this.exceptionLookupCache.get(exceptionType);\n\t\tif (method == null) {\n\t\t\tmethod = getMappedMethod(exceptionType);\n\t\t\tthis.exceptionLookupCache.put(exceptionType, method);\n\t\t}\n\t\treturn (method != NO_MATCHING_EXCEPTION_HANDLER_METHOD ? method : null);\n\t}", "summary_tokens": ["find", "a", "method", "to", "handle", "the", "given", "exception", "type"], "project": "spring-framework"}
{"id": 2408, "code": "public int newMethod(\n    final String owner, final String name, final String descriptor, final boolean isInterface) {\n  return symbolTable.addConstantMethodref(owner, name, descriptor, isInterface).index;\n}", "summary_tokens": ["adds", "a", "method", "reference", "to", "the", "constant", "pool", "of", "the", "class", "being", "build"], "project": "spring-framework"}
{"id": 9066, "code": "\tpublic Cache getCache() {\n\t\treturn this.cache;\n\t}", "summary_tokens": ["return", "the", "configured", "cache"], "project": "spring-framework"}
{"id": 4494, "code": "\tprotected boolean applyBackOffTime(BackOffExecution execution) {\n\t\tif (this.recovering && this.interrupted) {\n\t\t\t\n\t\t\treturn false;\n\t\t}\n\t\tlong interval = execution.nextBackOff();\n\t\tif (interval == BackOffExecution.STOP) {\n\t\t\treturn false;\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\t\t\tthis.lifecycleMonitor.wait(interval);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (InterruptedException interEx) {\n\t\t\t\t\n\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\tif (this.recovering) {\n\t\t\t\t\tthis.interrupted = true;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true;\n\t\t}\n\t}", "summary_tokens": ["apply", "the", "next", "back", "off", "time", "using", "the", "specified", "back", "off", "execution"], "project": "spring-framework"}
{"id": 2240, "code": "\tpublic Map<String, InputStreamSource> getGeneratedFiles(Kind kind) {\n\t\tAssert.notNull(kind, \"'kind' must not be null\");\n\t\treturn Collections.unmodifiableMap(this.files.getOrDefault(kind, Collections.emptyMap()));\n\t}", "summary_tokens": ["return", "a", "map", "of", "the", "generated", "files", "of", "a", "specific", "kind"], "project": "spring-framework"}
{"id": 8949, "code": "\tprotected ServletServerHttpResponse createOutputMessage(NativeWebRequest webRequest) {\n\t\tHttpServletResponse response = webRequest.getNativeResponse(HttpServletResponse.class);\n\t\tAssert.state(response != null, \"No HttpServletResponse\");\n\t\treturn new ServletServerHttpResponse(response);\n\t}", "summary_tokens": ["creates", "a", "new", "http", "output", "message", "from", "the", "given", "native", "web", "request"], "project": "spring-framework"}
{"id": 3192, "code": "\tpublic void add(Iterator<E> iterator) {\n\t\tAssert.state(!this.inUse, \"You can no longer add iterators to a composite iterator that's already in use\");\n\t\tif (this.iterators.contains(iterator)) {\n\t\t\tthrow new IllegalArgumentException(\"You cannot add the same iterator twice\");\n\t\t}\n\t\tthis.iterators.add(iterator);\n\t}", "summary_tokens": ["add", "given", "iterator", "to", "this", "composite"], "project": "spring-framework"}
{"id": 2328, "code": "public ByteVector putInt(final int intValue) {\n  int currentLength = length;\n  if (currentLength + 4 > data.length) {\n    enlarge(4);\n  }\n  byte[] currentData = data;\n  currentData[currentLength++] = (byte) (intValue >>> 24);\n  currentData[currentLength++] = (byte) (intValue >>> 16);\n  currentData[currentLength++] = (byte) (intValue >>> 8);\n  currentData[currentLength++] = (byte) intValue;\n  length = currentLength;\n  return this;\n}", "summary_tokens": ["puts", "an", "int", "into", "this", "byte", "vector"], "project": "spring-framework"}
{"id": 7447, "code": "\tprotected boolean handleInternal(ServerWebExchange exchange,\n\t\t\tCorsConfiguration config, boolean preFlightRequest) {\n\n\t\tServerHttpRequest request = exchange.getRequest();\n\t\tServerHttpResponse response = exchange.getResponse();\n\t\tHttpHeaders responseHeaders = response.getHeaders();\n\n\t\tString requestOrigin = request.getHeaders().getOrigin();\n\t\tString allowOrigin = checkOrigin(config, requestOrigin);\n\t\tif (allowOrigin == null) {\n\t\t\tlogger.debug(\"Reject: '\" + requestOrigin + \"' origin is not allowed\");\n\t\t\trejectRequest(response);\n\t\t\treturn false;\n\t\t}\n\n\t\tHttpMethod requestMethod = getMethodToUse(request, preFlightRequest);\n\t\tList<HttpMethod> allowMethods = checkMethods(config, requestMethod);\n\t\tif (allowMethods == null) {\n\t\t\tlogger.debug(\"Reject: HTTP '\" + requestMethod + \"' is not allowed\");\n\t\t\trejectRequest(response);\n\t\t\treturn false;\n\t\t}\n\n\t\tList<String> requestHeaders = getHeadersToUse(request, preFlightRequest);\n\t\tList<String> allowHeaders = checkHeaders(config, requestHeaders);\n\t\tif (preFlightRequest && allowHeaders == null) {\n\t\t\tlogger.debug(\"Reject: headers '\" + requestHeaders + \"' are not allowed\");\n\t\t\trejectRequest(response);\n\t\t\treturn false;\n\t\t}\n\n\t\tresponseHeaders.setAccessControlAllowOrigin(allowOrigin);\n\n\t\tif (preFlightRequest) {\n\t\t\tresponseHeaders.setAccessControlAllowMethods(allowMethods);\n\t\t}\n\n\t\tif (preFlightRequest && !allowHeaders.isEmpty()) {\n\t\t\tresponseHeaders.setAccessControlAllowHeaders(allowHeaders);\n\t\t}\n\n\t\tif (!CollectionUtils.isEmpty(config.getExposedHeaders())) {\n\t\t\tresponseHeaders.setAccessControlExposeHeaders(config.getExposedHeaders());\n\t\t}\n\n\t\tif (Boolean.TRUE.equals(config.getAllowCredentials())) {\n\t\t\tresponseHeaders.setAccessControlAllowCredentials(true);\n\t\t}\n\n\t\tif (preFlightRequest && config.getMaxAge() != null) {\n\t\t\tresponseHeaders.setAccessControlMaxAge(config.getMaxAge());\n\t\t}\n\n\t\treturn true;\n\t}", "summary_tokens": ["handle", "the", "given", "request"], "project": "spring-framework"}
{"id": 6533, "code": "\tstatic TransactionOperations withoutTransaction() {\n\t\treturn WithoutTransactionOperations.INSTANCE;\n\t}", "summary_tokens": ["return", "an", "implementation", "of", "the", "transaction", "operations", "interface", "which", "executes", "a", "given", "transaction", "callback", "without", "an", "actual", "transaction"], "project": "spring-framework"}
{"id": 1595, "code": "\tprotected String getOperationDescription(Method method, String beanKey) {\n\t\treturn method.getName();\n\t}", "summary_tokens": ["get", "the", "description", "for", "a", "particular", "operation"], "project": "spring-framework"}
{"id": 3430, "code": "\tprivate boolean hasOpeningTag(String content) {\n\t\tif (this.inComment) {\n\t\t\treturn false;\n\t\t}\n\t\tint openTagIndex = content.indexOf('<');\n\t\treturn (openTagIndex > -1 && (content.length() > openTagIndex + 1) &&\n\t\t\t\tCharacter.isLetter(content.charAt(openTagIndex + 1)));\n\t}", "summary_tokens": ["determine", "if", "the", "supplied", "content", "contains", "an", "xml", "opening", "tag"], "project": "spring-framework"}
{"id": 6912, "code": "\tfinal List<HttpMessageWriter<?>> getBaseTypedWriters() {\n\t\tif (!this.registerDefaults) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t\tList<HttpMessageWriter<?>> writers = new ArrayList<>();\n\t\taddCodec(writers, new EncoderHttpMessageWriter<>(new ByteArrayEncoder()));\n\t\taddCodec(writers, new EncoderHttpMessageWriter<>(new ByteBufferEncoder()));\n\t\taddCodec(writers, new EncoderHttpMessageWriter<>(new DataBufferEncoder()));\n\t\tif (nettyByteBufPresent) {\n\t\t\taddCodec(writers, new EncoderHttpMessageWriter<>(new NettyByteBufEncoder()));\n\t\t}\n\t\tif (netty5BufferPresent) {\n\t\t\taddCodec(writers, new EncoderHttpMessageWriter<>(new Netty5BufferEncoder()));\n\t\t}\n\t\taddCodec(writers, new ResourceHttpMessageWriter());\n\t\taddCodec(writers, new EncoderHttpMessageWriter<>(CharSequenceEncoder.textPlainOnly()));\n\t\tif (protobufPresent) {\n\t\t\taddCodec(writers, new ProtobufHttpMessageWriter(this.protobufEncoder != null ?\n\t\t\t\t\t(ProtobufEncoder) this.protobufEncoder : new ProtobufEncoder()));\n\t\t}\n\t\treturn writers;\n\t}", "summary_tokens": ["return", "base", "typed", "writers", "only", "i"], "project": "spring-framework"}
{"id": 5027, "code": "\tpublic void handleFrame(StompHeaders headers, @Nullable Object payload) {\n\t}", "summary_tokens": ["this", "implementation", "is", "empty"], "project": "spring-framework"}
{"id": 8693, "code": "\tprotected Validator getValidator() {\n\t\treturn null;\n\t}", "summary_tokens": ["override", "this", "method", "to", "provide", "a", "custom", "validator"], "project": "spring-framework"}
{"id": 4936, "code": "\tpublic CompletableFuture<StompSession> connectAsync(@Nullable StompHeaders connectHeaders, StompSessionHandler handler) {\n\t\tConnectionHandlingStompSession session = createSession(connectHeaders, handler);\n\t\tthis.tcpClient.connectAsync(session);\n\t\treturn session.getSession();\n\t}", "summary_tokens": ["an", "overloaded", "version", "of", "connect", "async", "stomp", "session", "handler", "that", "accepts", "headers", "to", "use", "for", "the", "stomp", "connect", "frame"], "project": "spring-framework"}
{"id": 293, "code": "\tpublic void testUnionOfSettersAndGetters() {\n\t\tPointcut union = Pointcuts.union(allClassGetterPointcut, allClassSetterPointcut);\n\t\tassertThat(Pointcuts.matches(union, TEST_BEAN_SET_AGE, TestBean.class, 6)).isTrue();\n\t\tassertThat(Pointcuts.matches(union, TEST_BEAN_GET_AGE, TestBean.class)).isTrue();\n\t\tassertThat(Pointcuts.matches(union, TEST_BEAN_ABSQUATULATE, TestBean.class)).isFalse();\n\t}", "summary_tokens": ["should", "match", "all", "setters", "and", "getters", "on", "any", "class"], "project": "spring-framework"}
{"id": 9098, "code": "\tpublic String getExpression() {\n\t\treturn this.expression;\n\t}", "summary_tokens": ["return", "a", "bind", "expression", "that", "can", "be", "used", "in", "html", "forms", "as", "input", "name", "for", "the", "respective", "field", "or", "null", "if", "not", "field", "specific"], "project": "spring-framework"}
{"id": 1066, "code": "\tpublic void setJobClass(Class<? extends Job> jobClass) {\n\t\tthis.jobClass = jobClass;\n\t}", "summary_tokens": ["specify", "the", "job", "s", "implementation", "class"], "project": "spring-framework"}
{"id": 7332, "code": "\tprotected Resource getResourceByPath(String path) {\n\t\tAssert.state(this.servletContext != null, \"No ServletContext available\");\n\t\treturn new ServletContextResource(this.servletContext, path);\n\t}", "summary_tokens": ["this", "implementation", "supports", "file", "paths", "beneath", "the", "root", "of", "the", "servlet", "context"], "project": "spring-framework"}
{"id": 719, "code": "\tpublic static <K,V> ManagedMap<K,V> ofEntries(Entry<? extends K, ? extends V>... entries) {\n\t\tManagedMap<K,V > map = new ManagedMap<>();\n\t\tfor (Entry<? extends K, ? extends V> entry : entries) {\n\t\t\tmap.put(entry.getKey(), entry.getValue());\n\t\t}\n\t\treturn map;\n\t}", "summary_tokens": ["return", "a", "new", "instance", "containing", "keys", "and", "values", "extracted", "from", "the", "given", "entries"], "project": "spring-framework"}
{"id": 3115, "code": "\tpublic static byte[] decodeFromString(String src) {\n\t\tif (src.isEmpty()) {\n\t\t\treturn new byte[0];\n\t\t}\n\t\treturn decode(src.getBytes(DEFAULT_CHARSET));\n\t}", "summary_tokens": ["base", "0", "decode", "the", "given", "byte", "array", "from", "an", "utf", "0", "string"], "project": "spring-framework"}
{"id": 3434, "code": "\tprivate int endComment(String line) {\n\t\treturn commentToken(line, END_COMMENT, false);\n\t}", "summary_tokens": ["try", "to", "consume", "the", "end", "comment", "token"], "project": "spring-framework"}
{"id": 8375, "code": "\tprotected String getPrefix() {\n\t\treturn this.prefix;\n\t}", "summary_tokens": ["return", "the", "prefix", "that", "gets", "prepended", "to", "view", "names", "when", "building", "a", "url"], "project": "spring-framework"}
{"id": 8144, "code": "\tdefault RouterFunction<T> withAttributes(Consumer<Map<String, Object>> attributesConsumer) {\n\t\tAssert.notNull(attributesConsumer, \"AttributesConsumer must not be null\");\n\n\t\tMap<String, Object> attributes = new LinkedHashMap<>();\n\t\tattributesConsumer.accept(attributes);\n\t\treturn new RouterFunctions.AttributesRouterFunction<>(this, attributes);\n\t}", "summary_tokens": ["return", "a", "new", "routing", "function", "with", "attributes", "manipulated", "with", "the", "given", "consumer"], "project": "spring-framework"}
{"id": 2547, "code": "Symbol addConstantLong(final long value) {\n  return addConstantLongOrDouble(Symbol.CONSTANT_LONG_TAG, value);\n}", "summary_tokens": ["adds", "a", "constant", "long", "info", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 2787, "code": "\tboolean isValid(Annotation annotation) {\n\t\tassertAnnotation(annotation);\n\t\tfor (int i = 0; i < size(); i++) {\n\t\t\tif (canThrowTypeNotPresentException(i)) {\n\t\t\t\ttry {\n\t\t\t\t\tget(i).invoke(annotation);\n\t\t\t\t}\n\t\t\t\tcatch (Throwable ex) {\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "if", "values", "from", "the", "given", "annotation", "can", "be", "safely", "accessed", "without", "causing", "any", "type", "not", "present", "exception", "type", "not", "present", "exceptions"], "project": "spring-framework"}
{"id": 8207, "code": "\tpublic ReactiveAdapterRegistry getAdapterRegistry() {\n\t\treturn this.adapterRegistry;\n\t}", "summary_tokens": ["return", "the", "configured", "reactive", "adapter", "registry"], "project": "spring-framework"}
{"id": 4409, "code": "\tpublic void setPubSubNoLocal(boolean pubSubNoLocal) {\n\t\tthis.pubSubNoLocal = pubSubNoLocal;\n\t}", "summary_tokens": ["set", "whether", "to", "inhibit", "the", "delivery", "of", "messages", "published", "by", "its", "own", "connection"], "project": "spring-framework"}
{"id": 1899, "code": "\tpublic static Object createBshObject(String scriptSource, @Nullable Class<?>[] scriptInterfaces, @Nullable ClassLoader classLoader)\n\t\t\tthrows EvalError {\n\n\t\tObject result = evaluateBshScript(scriptSource, scriptInterfaces, classLoader);\n\t\tif (result instanceof Class) {\n\t\t\tClass<?> clazz = (Class<?>) result;\n\t\t\ttry {\n\t\t\t\treturn ReflectionUtils.accessibleConstructor(clazz).newInstance();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\tthrow new IllegalStateException(\"Could not instantiate script class: \" + clazz.getName(), ex);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\treturn result;\n\t\t}\n\t}", "summary_tokens": ["create", "a", "new", "bean", "shell", "scripted", "object", "from", "the", "given", "script", "source"], "project": "spring-framework"}
{"id": 965, "code": "\tprotected com.github.benmanes.caffeine.cache.Cache<Object, Object> createNativeCaffeineCache(String name) {\n\t\treturn (this.cacheLoader != null ? this.cacheBuilder.build(this.cacheLoader) : this.cacheBuilder.build());\n\t}", "summary_tokens": ["build", "a", "common", "caffeine", "cache", "instance", "for", "the", "specified", "cache", "name", "using", "the", "common", "caffeine", "configuration", "specified", "on", "this", "cache", "manager"], "project": "spring-framework"}
{"id": 686, "code": "\tprotected void beforeSingletonCreation(String beanName) {\n\t\tif (!this.inCreationCheckExclusions.contains(beanName) && !this.singletonsCurrentlyInCreation.add(beanName)) {\n\t\t\tthrow new BeanCurrentlyInCreationException(beanName);\n\t\t}\n\t}", "summary_tokens": ["callback", "before", "singleton", "creation"], "project": "spring-framework"}
{"id": 8257, "code": "\tpublic HandlerMethodArgumentResolverComposite addResolvers(\n\t\t\t@Nullable List<? extends HandlerMethodArgumentResolver> resolvers) {\n\n\t\tif (resolvers != null) {\n\t\t\tthis.argumentResolvers.addAll(resolvers);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "given", "handler", "method", "argument", "resolver", "handler", "method", "argument", "resolvers"], "project": "spring-framework"}
{"id": 6862, "code": "\tpublic void setMaxInMemorySize(int maxInMemorySize) {\n\t\tthis.maxInMemorySize = maxInMemorySize;\n\t}", "summary_tokens": ["configure", "the", "maximum", "amount", "of", "memory", "allowed", "per", "part"], "project": "spring-framework"}
{"id": 4491, "code": "\tprotected void recoverAfterListenerSetupFailure() {\n\t\tthis.recovering = true;\n\t\ttry {\n\t\t\trefreshConnectionUntilSuccessful();\n\t\t\trefreshDestination();\n\t\t}\n\t\tfinally {\n\t\t\tthis.recovering = false;\n\t\t\tthis.interrupted = false;\n\t\t}\n\t}", "summary_tokens": ["recover", "this", "listener", "container", "after", "a", "listener", "failed", "to", "set", "itself", "up", "for", "example", "re", "establishing", "the", "underlying", "connection"], "project": "spring-framework"}
{"id": 2438, "code": "private int getConcreteOutputType(final int abstractOutputType, final int numStack) {\n  int dim = abstractOutputType & DIM_MASK;\n  int kind = abstractOutputType & KIND_MASK;\n  if (kind == LOCAL_KIND) {\n      \n      \n      \n    int concreteOutputType = dim + inputLocals[abstractOutputType & VALUE_MASK];\n    if ((abstractOutputType & TOP_IF_LONG_OR_DOUBLE_FLAG) != 0\n        && (concreteOutputType == LONG || concreteOutputType == DOUBLE)) {\n      concreteOutputType = TOP;\n    }\n    return concreteOutputType;\n  } else if (kind == STACK_KIND) {\n      \n      \n      \n    int concreteOutputType = dim + inputStack[numStack - (abstractOutputType & VALUE_MASK)];\n    if ((abstractOutputType & TOP_IF_LONG_OR_DOUBLE_FLAG) != 0\n        && (concreteOutputType == LONG || concreteOutputType == DOUBLE)) {\n      concreteOutputType = TOP;\n    }\n    return concreteOutputType;\n  } else {\n    return abstractOutputType;\n  }\n}", "summary_tokens": ["computes", "the", "concrete", "output", "type", "corresponding", "to", "a", "given", "abstract", "output", "type"], "project": "spring-framework"}
{"id": 4003, "code": "\tpublic static synchronized DerbyEmbeddedDatabaseConfigurer getInstance() {\n\t\tif (instance == null) {\n\t\t\t\n\t\t\tSystem.setProperty(\"derby.stream.error.method\",\n\t\t\t\t\tOutputStreamFactory.class.getName() + \".getNoopOutputStream\");\n\t\t\tinstance = new DerbyEmbeddedDatabaseConfigurer();\n\t\t}\n\t\treturn instance;\n\t}", "summary_tokens": ["get", "the", "singleton", "derby", "embedded", "database", "configurer", "instance"], "project": "spring-framework"}
{"id": 7125, "code": "\tpublic void setUseJaf(boolean useJaf) {\n\t\tsetUseRegisteredExtensionsOnly(!useJaf);\n\t}", "summary_tokens": ["indicate", "whether", "to", "use", "the", "java", "activation", "framework", "as", "a", "fallback", "option", "to", "map", "from", "file", "extensions", "to", "media", "types"], "project": "spring-framework"}
{"id": 9310, "code": "\tpublic void setOnkeypress(String onkeypress) {\n\t\tthis.onkeypress = onkeypress;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "onkeypress", "attribute"], "project": "spring-framework"}
{"id": 6079, "code": "\tpublic ResultMatcher isMethodNotAllowed() {\n\t\treturn matcher(HttpStatus.METHOD_NOT_ALLOWED);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2563, "code": "int addUninitializedType(final String value, final int bytecodeOffset) {\n  int hashCode = hash(Symbol.UNINITIALIZED_TYPE_TAG, value, bytecodeOffset);\n  Entry entry = get(hashCode);\n  while (entry != null) {\n    if (entry.tag == Symbol.UNINITIALIZED_TYPE_TAG\n        && entry.hashCode == hashCode\n        && entry.data == bytecodeOffset\n        && entry.value.equals(value)) {\n      return entry.index;\n    }\n    entry = entry.next;\n  }\n  return addTypeInternal(\n      new Entry(typeCount, Symbol.UNINITIALIZED_TYPE_TAG, value, bytecodeOffset, hashCode));\n}", "summary_tokens": ["adds", "an", "frame", "item", "uninitialized", "type", "in", "the", "type", "table", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 2910, "code": "\tpublic File getFile() throws IOException {\n\t\tthrow new FileNotFoundException(getDescription() + \" cannot be resolved to absolute file path\");\n\t}", "summary_tokens": ["this", "implementation", "throws", "a", "file", "not", "found", "exception", "assuming", "that", "the", "resource", "cannot", "be", "resolved", "to", "an", "absolute", "file", "path"], "project": "spring-framework"}
{"id": 6188, "code": "\tpublic void setTransactionFactory(TransactionFactory transactionFactory) {\n\t\tthis.transactionFactory = transactionFactory;\n\t}", "summary_tokens": ["set", "the", "spring", "transaction", "factory", "to", "use", "for", "wrapping", "endpoint", "invocations", "enlisting", "the", "endpoint", "resource", "in", "each", "such", "transaction"], "project": "spring-framework"}
{"id": 8080, "code": "\tstatic Builder from(ClientResponse other) {\n\t\treturn new DefaultClientResponseBuilder(other, false);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "the", "status", "headers", "and", "cookies", "of", "the", "given", "response"], "project": "spring-framework"}
{"id": 80, "code": "\tprivate void findDefinedEqualsAndHashCodeMethods(Class<?>[] proxiedInterfaces) {\n\t\tfor (Class<?> proxiedInterface : proxiedInterfaces) {\n\t\t\tMethod[] methods = proxiedInterface.getDeclaredMethods();\n\t\t\tfor (Method method : methods) {\n\t\t\t\tif (AopUtils.isEqualsMethod(method)) {\n\t\t\t\t\tthis.equalsDefined = true;\n\t\t\t\t}\n\t\t\t\tif (AopUtils.isHashCodeMethod(method)) {\n\t\t\t\t\tthis.hashCodeDefined = true;\n\t\t\t\t}\n\t\t\t\tif (this.equalsDefined && this.hashCodeDefined) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["finds", "any", "equals", "or", "hash", "code", "method", "that", "may", "be", "defined", "on", "the", "supplied", "set", "of", "interfaces"], "project": "spring-framework"}
{"id": 6121, "code": "\tpublic ResultMatcher node(Matcher<? super Node> matcher) {\n\t\treturn result -> {\n\t\t\tMockHttpServletResponse response = result.getResponse();\n\t\t\tthis.xpathHelper.assertNode(response.getContentAsByteArray(), getDefinedEncoding(response), matcher);\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "xpath", "and", "assert", "the", "node", "content", "found", "with", "the", "given", "hamcrest", "matcher"], "project": "spring-framework"}
{"id": 6856, "code": "\tpublic void setMaxInMemorySize(int byteCount) {\n\t\tthis.stringDecoder.setMaxInMemorySize(byteCount);\n\t}", "summary_tokens": ["configure", "a", "limit", "on", "the", "number", "of", "bytes", "that", "can", "be", "buffered", "whenever", "the", "input", "stream", "needs", "to", "be", "aggregated"], "project": "spring-framework"}
{"id": 8869, "code": "\tprotected String getViewNameForRequest(HttpServletRequest request) {\n\t\tString uri = extractOperableUrl(request);\n\t\treturn getViewNameForUrlPath(uri);\n\t}", "summary_tokens": ["returns", "view", "name", "based", "on", "the", "url", "filename", "with", "prefix", "suffix", "applied", "when", "appropriate"], "project": "spring-framework"}
{"id": 2643, "code": "\tpublic void setSuperclass(Class superclass) {\n\t\tif (superclass != null && superclass.isInterface()) {\n\t\t\tsetInterfaces(new Class[]{superclass});\n\t\t\t\n\t\t\tsetContextClass(superclass);\n\t\t\t\n\t\t}\n\t\telse if (superclass != null && superclass.equals(Object.class)) {\n\t\t\t\n\t\t\tthis.superclass = null;\n\t\t}\n\t\telse {\n\t\t\tthis.superclass = superclass;\n\t\t\t\n\t\t\tsetContextClass(superclass);\n\t\t\t\n\t\t}\n\t}", "summary_tokens": ["set", "the", "class", "which", "the", "generated", "class", "will", "extend"], "project": "spring-framework"}
{"id": 6353, "code": "\tprivate Mono<Void> processCommit(TransactionSynchronizationManager synchronizationManager,\n\t\t\tGenericReactiveTransaction status) throws TransactionException {\n\n\t\tAtomicBoolean beforeCompletionInvoked = new AtomicBoolean();\n\n\t\tMono<Object> commit = prepareForCommit(synchronizationManager, status)\n\t\t\t\t.then(triggerBeforeCommit(synchronizationManager, status))\n\t\t\t\t.then(triggerBeforeCompletion(synchronizationManager, status))\n\t\t\t\t.then(Mono.defer(() -> {\n\t\t\t\t\tbeforeCompletionInvoked.set(true);\n\t\t\t\t\tif (status.isNewTransaction()) {\n\t\t\t\t\t\tif (status.isDebug()) {\n\t\t\t\t\t\t\tlogger.debug(\"Initiating transaction commit\");\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn doCommit(synchronizationManager, status);\n\t\t\t\t\t}\n\t\t\t\t\treturn Mono.empty();\n\t\t\t\t})).then(Mono.empty().onErrorResume(ex -> {\n\t\t\t\t\tMono<Object> propagateException = Mono.error(ex);\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\tMono<Object> result = propagateException;\n\t\t\t\t\tif (ErrorPredicates.UNEXPECTED_ROLLBACK.test(ex)) {\n\t\t\t\t\t\tresult = triggerAfterCompletion(synchronizationManager, status, TransactionSynchronization.STATUS_ROLLED_BACK)\n\t\t\t\t\t\t\t\t.then(propagateException);\n\t\t\t\t\t}\n\t\t\t\t\telse if (ErrorPredicates.TRANSACTION_EXCEPTION.test(ex)) {\n\t\t\t\t\t\tresult = triggerAfterCompletion(synchronizationManager, status, TransactionSynchronization.STATUS_UNKNOWN)\n\t\t\t\t\t\t\t\t.then(propagateException);\n\t\t\t\t\t}\n\t\t\t\t\telse if (ErrorPredicates.RUNTIME_OR_ERROR.test(ex)) {\n\t\t\t\t\t\tMono<Void> mono;\n\t\t\t\t\t\tif (!beforeCompletionInvoked.get()) {\n\t\t\t\t\t\t\tmono = triggerBeforeCompletion(synchronizationManager, status);\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tmono = Mono.empty();\n\t\t\t\t\t\t}\n\t\t\t\t\t\tresult = mono.then(doRollbackOnCommitException(synchronizationManager, status, ex))\n\t\t\t\t\t\t\t\t.then(propagateException);\n\t\t\t\t\t}\n\n\t\t\t\t\treturn result;\n\t\t\t\t})).then(Mono.defer(() -> triggerAfterCommit(synchronizationManager, status).onErrorResume(ex ->\n\t\t\t\t\t\ttriggerAfterCompletion(synchronizationManager, status, TransactionSynchronization.STATUS_COMMITTED).then(Mono.error(ex)))\n\t\t\t\t\t\t.then(triggerAfterCompletion(synchronizationManager, status, TransactionSynchronization.STATUS_COMMITTED))));\n\n\t\treturn commit\n\t\t\t\t.onErrorResume(ex -> cleanupAfterCompletion(synchronizationManager, status)\n\t\t\t\t\t\t.then(Mono.error(ex))).then(cleanupAfterCompletion(synchronizationManager, status));\n\t}", "summary_tokens": ["process", "an", "actual", "commit"], "project": "spring-framework"}
{"id": 446, "code": "\tpublic CodeBlock generateSetBeanDefinitionPropertiesCode(\n\t\t\tGenerationContext generationContext, BeanRegistrationCode beanRegistrationCode,\n\t\t\tRootBeanDefinition beanDefinition, Predicate<String> attributeFilter) {\n\n\t\treturn this.codeFragments.generateSetBeanDefinitionPropertiesCode(\n\t\t\t\tgenerationContext, beanRegistrationCode, beanDefinition, attributeFilter);\n\n\t}", "summary_tokens": ["generate", "the", "code", "that", "sets", "the", "properties", "of", "the", "bean", "definition"], "project": "spring-framework"}
{"id": 6525, "code": "\tprotected boolean shouldUnbindAtCompletion() {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "this", "holder", "should", "be", "unbound", "at", "completion", "or", "should", "rather", "be", "left", "bound", "to", "the", "thread", "after", "the", "transaction"], "project": "spring-framework"}
{"id": 1860, "code": "\tpublic int getKeepAliveSeconds() {\n\t\tsynchronized (this.poolSizeMonitor) {\n\t\t\treturn this.keepAliveSeconds;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "thread", "pool", "executor", "s", "keep", "alive", "seconds"], "project": "spring-framework"}
{"id": 3106, "code": "\tpublic static void noNullElements(@Nullable Collection<?> collection, Supplier<String> messageSupplier) {\n\t\tif (collection != null) {\n\t\t\tfor (Object element : collection) {\n\t\t\t\tif (element == null) {\n\t\t\t\t\tthrow new IllegalArgumentException(nullSafeGet(messageSupplier));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["assert", "that", "a", "collection", "contains", "no", "null", "elements"], "project": "spring-framework"}
{"id": 6056, "code": "\tpublic ResultMatcher isCreated() {\n\t\treturn matcher(HttpStatus.CREATED);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2565, "code": "private int addTypeInternal(final Entry entry) {\n  if (typeTable == null) {\n    typeTable = new Entry[16];\n  }\n  if (typeCount == typeTable.length) {\n    Entry[] newTypeTable = new Entry[2 * typeTable.length];\n    System.arraycopy(typeTable, 0, newTypeTable, 0, typeTable.length);\n    typeTable = newTypeTable;\n  }\n  typeTable[typeCount++] = entry;\n  return put(entry).index;\n}", "summary_tokens": ["adds", "the", "given", "type", "symbol", "to", "type", "table"], "project": "spring-framework"}
{"id": 3886, "code": "\tprotected int[] doExecuteBatch(SqlParameterSource... batch) {\n\t\tcheckCompiled();\n\t\tList<List<Object>> batchValues = new ArrayList<>(batch.length);\n\t\tfor (SqlParameterSource parameterSource : batch) {\n\t\t\tbatchValues.add(matchInParameterValuesWithInsertColumns(parameterSource));\n\t\t}\n\t\treturn executeBatchInternal(batchValues);\n\t}", "summary_tokens": ["delegate", "method", "that", "executes", "a", "batch", "insert", "using", "the", "passed", "in", "sql", "parameter", "source", "sql", "parameter", "sources"], "project": "spring-framework"}
{"id": 1261, "code": "\tpublic void setBeanDefinitionDefaults(@Nullable BeanDefinitionDefaults beanDefinitionDefaults) {\n\t\tthis.beanDefinitionDefaults =\n\t\t\t\t(beanDefinitionDefaults != null ? beanDefinitionDefaults : new BeanDefinitionDefaults());\n\t}", "summary_tokens": ["set", "the", "defaults", "to", "use", "for", "detected", "beans"], "project": "spring-framework"}
{"id": 3324, "code": "\tpublic static String stripFilenameExtension(String path) {\n\t\tint extIndex = path.lastIndexOf(EXTENSION_SEPARATOR);\n\t\tif (extIndex == -1) {\n\t\t\treturn path;\n\t\t}\n\n\t\tint folderIndex = path.lastIndexOf(FOLDER_SEPARATOR_CHAR);\n\t\tif (folderIndex > extIndex) {\n\t\t\treturn path;\n\t\t}\n\n\t\treturn path.substring(0, extIndex);\n\t}", "summary_tokens": ["strip", "the", "filename", "extension", "from", "the", "given", "java", "resource", "path", "e"], "project": "spring-framework"}
{"id": 9296, "code": "\tpublic void setOnclick(String onclick) {\n\t\tthis.onclick = onclick;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "onclick", "attribute"], "project": "spring-framework"}
{"id": 761, "code": "\tpublic void registerExternallyManagedInitMethod(String initMethod) {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\tif (this.externallyManagedInitMethods == null) {\n\t\t\t\tthis.externallyManagedInitMethods = new LinkedHashSet<>(1);\n\t\t\t}\n\t\t\tthis.externallyManagedInitMethods.add(initMethod);\n\t\t}\n\t}", "summary_tokens": ["register", "an", "externally", "managed", "configuration", "initialization", "method", "mdash", "for", "example", "a", "method", "annotated", "with", "jsr", "0", "s", "jakarta"], "project": "spring-framework"}
{"id": 6196, "code": "\tpublic void setMessageListener(Object messageListener) {\n\t\tthis.messageListener = messageListener;\n\t}", "summary_tokens": ["specify", "the", "message", "listener", "object", "that", "the", "endpoint", "should", "expose", "e"], "project": "spring-framework"}
{"id": 3036, "code": "\tpublic void trace(Throwable cause, Supplier<? extends CharSequence> messageSupplier) {\n\t\tif (this.log.isTraceEnabled()) {\n\t\t\tthis.log.trace(LogMessage.of(messageSupplier), cause);\n\t\t}\n\t}", "summary_tokens": ["log", "an", "error", "with", "trace", "log", "level"], "project": "spring-framework"}
{"id": 893, "code": "\tpublic int getNrOfElements() {\n\t\treturn getSource().size();\n\t}", "summary_tokens": ["return", "the", "total", "number", "of", "elements", "in", "the", "source", "list"], "project": "spring-framework"}
{"id": 6311, "code": "\tpublic void setAutodetectTransactionSynchronizationRegistry(boolean autodetectTransactionSynchronizationRegistry) {\n\t\tthis.autodetectTransactionSynchronizationRegistry = autodetectTransactionSynchronizationRegistry;\n\t}", "summary_tokens": ["set", "whether", "to", "autodetect", "a", "jta", "0"], "project": "spring-framework"}
{"id": 3803, "code": "\tpublic NamedParameterJdbcTemplate getNamedParameterJdbcTemplate() {\n\t\treturn this.namedParameterJdbcTemplate;\n\t}", "summary_tokens": ["return", "a", "named", "parameter", "jdbc", "template", "wrapping", "the", "configured", "jdbc", "template"], "project": "spring-framework"}
{"id": 6726, "code": "\tpublic String getDetail() {\n\t\treturn this.detail;\n\t}", "summary_tokens": ["return", "the", "configured", "set", "detail", "string", "problem", "detail"], "project": "spring-framework"}
{"id": 853, "code": "\tpublic final BeanDefinitionRegistry getRegistry() {\n\t\treturn this.reader.getRegistry();\n\t}", "summary_tokens": ["return", "the", "bean", "definition", "registry", "to", "use"], "project": "spring-framework"}
{"id": 1666, "code": "\tpublic void setDescription(String description) {\n\t\tthis.description = description;\n\t}", "summary_tokens": ["set", "a", "description", "for", "this", "parameter"], "project": "spring-framework"}
{"id": 9867, "code": "\tpublic CompletableFuture<StompSession> connectAsync(URI url, @Nullable WebSocketHttpHeaders handshakeHeaders,\n\t\t\t@Nullable StompHeaders connectHeaders, StompSessionHandler sessionHandler) {\n\n\t\tAssert.notNull(url, \"'url' must not be null\");\n\t\tConnectionHandlingStompSession session = createSession(connectHeaders, sessionHandler);\n\t\tWebSocketTcpConnectionHandlerAdapter adapter = new WebSocketTcpConnectionHandlerAdapter(session);\n\t\tgetWebSocketClient()\n\t\t\t\t.execute(new LoggingWebSocketHandlerDecorator(adapter), handshakeHeaders, url)\n\t\t\t\t.whenComplete(adapter);\n\t\treturn session.getSession();\n\t}", "summary_tokens": ["an", "overloaded", "version", "of", "connect", "string", "web", "socket", "http", "headers", "stomp", "session", "handler", "object"], "project": "spring-framework"}
{"id": 1831, "code": "\tpublic void setContinueScheduledExecutionAfterException(boolean continueScheduledExecutionAfterException) {\n\t\tthis.continueScheduledExecutionAfterException = continueScheduledExecutionAfterException;\n\t}", "summary_tokens": ["specify", "whether", "to", "continue", "the", "execution", "of", "a", "scheduled", "task", "after", "it", "threw", "an", "exception"], "project": "spring-framework"}
{"id": 1858, "code": "\tpublic int getMaxPoolSize() {\n\t\tsynchronized (this.poolSizeMonitor) {\n\t\t\treturn this.maxPoolSize;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "thread", "pool", "executor", "s", "maximum", "pool", "size"], "project": "spring-framework"}
{"id": 2826, "code": "\tpublic static String getLogPrefix(@Nullable Map<String, Object> hints) {\n\t\treturn (hints != null ? (String) hints.getOrDefault(LOG_PREFIX_HINT, \"\") : \"\");\n\t}", "summary_tokens": ["obtain", "the", "hint", "log", "prefix", "hint", "if", "present", "or", "an", "empty", "string"], "project": "spring-framework"}
{"id": 506, "code": "\tpublic String getBeanName() {\n\t\treturn this.beanName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "bean"], "project": "spring-framework"}
{"id": 4940, "code": "\tpublic void setRelayPort(int relayPort) {\n\t\tthis.relayPort = relayPort;\n\t}", "summary_tokens": ["set", "the", "stomp", "message", "broker", "port"], "project": "spring-framework"}
{"id": 1647, "code": "\tpublic void setMetricType(MetricType metricType) {\n\t\tAssert.notNull(metricType, \"MetricType must not be null\");\n\t\tthis.metricType = metricType;\n\t}", "summary_tokens": ["a", "description", "of", "how", "this", "metric", "s", "values", "change", "over", "time"], "project": "spring-framework"}
{"id": 5872, "code": "\tpublic WebTestClient.ResponseSpec sameSite(String name, String expected) {\n\t\tString sameSite = getCookie(name).getSameSite();\n\t\tthis.exchangeResult.assertWithDiagnostics(() -> {\n\t\t\tString message = getMessage(name) + \" sameSite\";\n\t\t\tAssertionErrors.assertEquals(message, expected, sameSite);\n\t\t});\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["assert", "a", "cookie", "s", "same", "site", "attribute"], "project": "spring-framework"}
{"id": 3028, "code": "\tpublic boolean isInfoEnabled() {\n\t\treturn this.log.isInfoEnabled();\n\t}", "summary_tokens": ["is", "info", "logging", "currently", "enabled"], "project": "spring-framework"}
{"id": 2989, "code": "\tdefault DataBuffer retainedSlice(int index, int length) {\n\t\treturn DataBufferUtils.retain(slice(index, length));\n\t}", "summary_tokens": ["create", "a", "new", "data", "buffer", "whose", "contents", "is", "a", "shared", "retained", "subsequence", "of", "this", "data", "buffer", "s", "content"], "project": "spring-framework"}
{"id": 7947, "code": "\tpublic void deserializeState(Serializable state) {\n\t\tAssert.isTrue(state instanceof Map, \"Serialized state needs to be of type [java.util.Map]\");\n\t\tthis.attributes.putAll((Map<String, Object>) state);\n\t}", "summary_tokens": ["deserialize", "the", "attributes", "of", "this", "session", "from", "a", "state", "object", "created", "by", "serialize", "state"], "project": "spring-framework"}
{"id": 3148, "code": "\tpublic static boolean isLambdaClass(Class<?> clazz) {\n\t\treturn (clazz.isSynthetic() && (clazz.getSuperclass() == Object.class) &&\n\t\t\t\t(clazz.getInterfaces().length > 0) && clazz.getName().contains(\"$$Lambda\"));\n\t}", "summary_tokens": ["determine", "if", "the", "supplied", "class", "is", "a", "jvm", "generated", "implementation", "class", "for", "a", "lambda", "expression", "or", "method", "reference"], "project": "spring-framework"}
{"id": 8613, "code": "\tpublic PathMatchConfigurer setUseRegisteredSuffixPatternMatch(@Nullable Boolean registeredSuffixPatternMatch) {\n\t\tthis.registeredSuffixPatternMatch = registeredSuffixPatternMatch;\n\t\tthis.preferPathMatcher |= (registeredSuffixPatternMatch != null && registeredSuffixPatternMatch);\n\t\treturn this;\n\t}", "summary_tokens": ["whether", "suffix", "pattern", "matching", "should", "work", "only", "against", "path", "extensions", "explicitly", "registered", "when", "you", "web", "mvc", "configurer", "configure", "content", "negotiation", "configure", "content", "negotiation"], "project": "spring-framework"}
{"id": 2715, "code": "\tpublic static boolean inNativeImage() {\n\t\treturn imageCode;\n\t}", "summary_tokens": ["returns", "true", "if", "invoked", "in", "the", "context", "of", "image", "building", "or", "during", "image", "runtime", "else", "false"], "project": "spring-framework"}
{"id": 2523, "code": "final void collectAttributePrototypes(final Attribute.Set attributePrototypes) {\n  attributePrototypes.addAttributes(firstAttribute);\n}", "summary_tokens": ["collects", "the", "attributes", "of", "this", "record", "component", "into", "the", "given", "set", "of", "attribute", "prototypes"], "project": "spring-framework"}
{"id": 6758, "code": "\tprotected void postProcessHttpRequest(HttpUriRequest request) {\n\t}", "summary_tokens": ["template", "method", "that", "allows", "for", "manipulating", "the", "http", "uri", "request", "before", "it", "is", "returned", "as", "part", "of", "a", "http", "components", "client", "http", "request"], "project": "spring-framework"}
{"id": 884, "code": "\tpublic void setPage(int page) {\n\t\tthis.page = page;\n\t\tthis.newPageSet = true;\n\t}", "summary_tokens": ["set", "the", "current", "page", "number"], "project": "spring-framework"}
{"id": 3908, "code": "\tpublic void setTypeValue(PreparedStatement ps, int paramIndex, int sqlType, @Nullable String typeName)\n\t\t\tthrows SQLException {\n\n\t\tif (sqlType == Types.BLOB) {\n\t\t\tif (this.content instanceof byte[] || this.content == null) {\n\t\t\t\tthis.lobCreator.setBlobAsBytes(ps, paramIndex, (byte[]) this.content);\n\t\t\t}\n\t\t\telse if (this.content instanceof String) {\n\t\t\t\tthis.lobCreator.setBlobAsBytes(ps, paramIndex, ((String) this.content).getBytes());\n\t\t\t}\n\t\t\telse if (this.content instanceof InputStream) {\n\t\t\t\tthis.lobCreator.setBlobAsBinaryStream(ps, paramIndex, (InputStream) this.content, this.length);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\"Content type [\" + this.content.getClass().getName() + \"] not supported for BLOB columns\");\n\t\t\t}\n\t\t}\n\t\telse if (sqlType == Types.CLOB) {\n\t\t\tif (this.content instanceof String || this.content == null) {\n\t\t\t\tthis.lobCreator.setClobAsString(ps, paramIndex, (String) this.content);\n\t\t\t}\n\t\t\telse if (this.content instanceof InputStream) {\n\t\t\t\tthis.lobCreator.setClobAsAsciiStream(ps, paramIndex, (InputStream) this.content, this.length);\n\t\t\t}\n\t\t\telse if (this.content instanceof Reader) {\n\t\t\t\tthis.lobCreator.setClobAsCharacterStream(ps, paramIndex, (Reader) this.content, this.length);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\"Content type [\" + this.content.getClass().getName() + \"] not supported for CLOB columns\");\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"SqlLobValue only supports SQL types BLOB and CLOB\");\n\t\t}\n\t}", "summary_tokens": ["set", "the", "specified", "content", "via", "the", "lob", "creator"], "project": "spring-framework"}
{"id": 9401, "code": "\tprotected String resolveCssClass() throws JspException {\n\t\treturn ObjectUtils.getDisplayString(evaluate(\"cssClass\", getCssClass()));\n\t}", "summary_tokens": ["override", "resolve", "css", "class", "since", "error", "class", "is", "not", "supported"], "project": "spring-framework"}
{"id": 7562, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "method", "argument"], "project": "spring-framework"}
{"id": 4204, "code": "\tpublic void testDefaultInstanceWithOracle() {\n\t\tSQLErrorCodes sec = SQLErrorCodesFactory.getInstance().getErrorCodes(\"Oracle\");\n\t\tassertIsOracle(sec);\n\t}", "summary_tokens": ["check", "that", "a", "known", "database", "produces", "recognizable", "codes"], "project": "spring-framework"}
{"id": 2016, "code": "\tpublic Map<?, ?> close() throws BindException {\n\t\tif (getBindingResult().hasErrors()) {\n\t\t\tthrow new BindException(getBindingResult());\n\t\t}\n\t\treturn getBindingResult().getModel();\n\t}", "summary_tokens": ["close", "this", "data", "binder", "which", "may", "result", "in", "throwing", "a", "bind", "exception", "if", "it", "encountered", "any", "errors"], "project": "spring-framework"}
{"id": 5655, "code": "\tprotected String[] getResourceSuffixes() {\n\t\treturn new String[] {getResourceSuffix()};\n\t}", "summary_tokens": ["get", "the", "suffixes", "to", "append", "to", "application", "context", "resource", "locations", "when", "detecting", "default", "locations"], "project": "spring-framework"}
{"id": 1998, "code": "\tpublic void setMessageCodesResolver(@Nullable MessageCodesResolver messageCodesResolver) {\n\t\tAssert.state(this.messageCodesResolver == null, \"DataBinder is already initialized with MessageCodesResolver\");\n\t\tthis.messageCodesResolver = messageCodesResolver;\n\t\tif (this.bindingResult != null && messageCodesResolver != null) {\n\t\t\tthis.bindingResult.setMessageCodesResolver(messageCodesResolver);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "strategy", "to", "use", "for", "resolving", "errors", "into", "message", "codes"], "project": "spring-framework"}
{"id": 8087, "code": "\tpublic static ExchangeFunction create(ClientHttpConnector connector, ExchangeStrategies strategies) {\n\t\treturn new DefaultExchangeFunction(connector, strategies);\n\t}", "summary_tokens": ["create", "an", "exchange", "function", "with", "the", "given", "client", "http", "connector", "and", "exchange", "strategies"], "project": "spring-framework"}
{"id": 9518, "code": "\tpublic void setExposeSessionAttributes(boolean exposeSessionAttributes) {\n\t\tthis.exposeSessionAttributes = exposeSessionAttributes;\n\t}", "summary_tokens": ["set", "whether", "all", "http", "session", "attributes", "should", "be", "added", "to", "the", "model", "prior", "to", "merging", "with", "the", "template"], "project": "spring-framework"}
{"id": 9752, "code": "\tprotected TypeDescriptor getType() {\n\t\treturn TypeDescriptor.valueOf(resolveTypeArguments()[0]);\n\t}", "summary_tokens": ["returns", "the", "type", "being", "converted"], "project": "spring-framework"}
{"id": 2386, "code": "public void visitAttribute(final Attribute attribute) {\n  if (cv != null) {\n    cv.visitAttribute(attribute);\n  }\n}", "summary_tokens": ["visits", "a", "non", "standard", "attribute", "of", "the", "class"], "project": "spring-framework"}
{"id": 999, "code": "\tpublic CacheResolver getExceptionCacheResolver() {\n\t\treturn SupplierUtils.resolve(this.exceptionCacheResolver);\n\t}", "summary_tokens": ["return", "the", "specified", "exception", "cache", "resolver", "to", "use", "if", "any"], "project": "spring-framework"}
{"id": 2288, "code": "\tstatic TypeReference of(String className) {\n\t\treturn SimpleTypeReference.of(className);\n\t}", "summary_tokens": ["create", "an", "instance", "based", "on", "the", "specified", "class", "name"], "project": "spring-framework"}
{"id": 2885, "code": "\tprotected void assertLegalRelativeAddition(String relativePropertySourceName, PropertySource<?> propertySource) {\n\t\tString newPropertySourceName = propertySource.getName();\n\t\tif (relativePropertySourceName.equals(newPropertySourceName)) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"PropertySource named '\" + newPropertySourceName + \"' cannot be added relative to itself\");\n\t\t}\n\t}", "summary_tokens": ["ensure", "that", "the", "given", "property", "source", "is", "not", "being", "added", "relative", "to", "itself"], "project": "spring-framework"}
{"id": 6652, "code": "\tpublic void setCacheControl(@Nullable String cacheControl) {\n\t\tsetOrRemove(CACHE_CONTROL, cacheControl);\n\t}", "summary_tokens": ["set", "the", "new", "value", "of", "the", "cache", "control", "header"], "project": "spring-framework"}
{"id": 6963, "code": "\tpublic Jackson2ObjectMapperBuilder deserializersByType(Map<Class<?>, JsonDeserializer<?>> deserializers) {\n\t\tthis.deserializers.putAll(deserializers);\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "custom", "deserializers", "for", "the", "given", "types"], "project": "spring-framework"}
{"id": 5612, "code": "\tprotected Statement methodBlock(FrameworkMethod frameworkMethod) {\n\t\tObject testInstance;\n\t\ttry {\n\t\t\ttestInstance = new ReflectiveCallable() {\n\t\t\t\t@Override\n\t\t\t\tprotected Object runReflectiveCall() throws Throwable {\n\t\t\t\t\treturn createTest();\n\t\t\t\t}\n\t\t\t}.run();\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\treturn new Fail(ex);\n\t\t}\n\n\t\tStatement statement = methodInvoker(frameworkMethod, testInstance);\n\t\tstatement = withBeforeTestExecutionCallbacks(frameworkMethod, testInstance, statement);\n\t\tstatement = withAfterTestExecutionCallbacks(frameworkMethod, testInstance, statement);\n\t\tstatement = possiblyExpectingExceptions(frameworkMethod, testInstance, statement);\n\t\tstatement = withBefores(frameworkMethod, testInstance, statement);\n\t\tstatement = withAfters(frameworkMethod, testInstance, statement);\n\t\tstatement = withRulesReflectively(frameworkMethod, testInstance, statement);\n\t\tstatement = withPotentialRepeat(frameworkMethod, testInstance, statement);\n\t\tstatement = withPotentialTimeout(frameworkMethod, testInstance, statement);\n\t\treturn statement;\n\t}", "summary_tokens": ["augment", "the", "default", "junit", "behavior", "with", "potential", "repeat", "with", "potential", "repeats", "of", "the", "entire", "execution", "chain"], "project": "spring-framework"}
{"id": 4010, "code": "\tpublic EmbeddedDatabaseBuilder addScripts(String... scripts) {\n\t\tfor (String script : scripts) {\n\t\t\taddScript(script);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "multiple", "sql", "scripts", "to", "execute", "to", "initialize", "or", "populate", "the", "database"], "project": "spring-framework"}
{"id": 874, "code": "\tpublic void registerCustomEditor(Class<?> requiredType, PropertyEditor propertyEditor) {\n\t\tTypeConverter converter = getTypeConverter();\n\t\tif (!(converter instanceof PropertyEditorRegistry)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"TypeConverter does not implement PropertyEditorRegistry interface: \" + converter);\n\t\t}\n\t\t((PropertyEditorRegistry) converter).registerCustomEditor(requiredType, propertyEditor);\n\t}", "summary_tokens": ["register", "the", "given", "custom", "property", "editor", "for", "all", "properties", "of", "the", "given", "type"], "project": "spring-framework"}
{"id": 1463, "code": "\tpublic void addMessage(String code, Locale locale, String defaultMessage) {\n\t\tgetStaticMessageSource().addMessage(code, locale, defaultMessage);\n\t}", "summary_tokens": ["associate", "the", "given", "message", "with", "the", "given", "code"], "project": "spring-framework"}
{"id": 3049, "code": "\tprotected final ValueStyler getValueStyler() {\n\t\treturn this.valueStyler;\n\t}", "summary_tokens": ["return", "the", "value", "styler", "used", "by", "this", "to", "string", "styler"], "project": "spring-framework"}
{"id": 5063, "code": "\tdefault Message<?> postReceive(Message<?> message, MessageChannel channel) {\n\t\treturn message;\n\t}", "summary_tokens": ["invoked", "immediately", "after", "a", "message", "has", "been", "retrieved", "but", "before", "it", "is", "returned", "to", "the", "caller"], "project": "spring-framework"}
{"id": 3449, "code": "\tvoid standardAnnotationMetadata_nestedAnnotationsAsMap_false() {\n\t\tAnnotationMetadata metadata = new StandardAnnotationMetadata(AnnotatedComponent.class);\n\t\tAnnotationAttributes specialAttrs = (AnnotationAttributes) metadata.getAnnotationAttributes(SpecialAttr.class.getName());\n\t\tAnnotation[] nestedAnnoArray = (Annotation[]) specialAttrs.get(\"nestedAnnoArray\");\n\t\tassertThat(nestedAnnoArray[0]).isInstanceOf(NestedAnno.class);\n\t}", "summary_tokens": ["in", "order", "to", "preserve", "backward", "compatibility", "standard", "annotation", "metadata", "defaults", "to", "return", "nested", "annotations", "and", "annotation", "arrays", "as", "actual", "annotation", "instances"], "project": "spring-framework"}
{"id": 7836, "code": "\tpublic static String encodeQuery(String query, Charset charset) {\n\t\treturn encode(query, charset, HierarchicalUriComponents.Type.QUERY);\n\t}", "summary_tokens": ["encode", "the", "given", "uri", "query", "with", "the", "given", "encoding"], "project": "spring-framework"}
{"id": 5782, "code": "\tprotected <T> T evaluateXpath(Document document, QName evaluationType, Class<T> expectedClass)\n\t\t\tthrows XPathExpressionException {\n\n\t\treturn (T) getXpathExpression().evaluate(document, evaluationType);\n\t}", "summary_tokens": ["apply", "the", "xpath", "expression", "to", "given", "document"], "project": "spring-framework"}
{"id": 933, "code": "\tpublic FactoryMethods newInstance(TestBean tb) {\n\t\treturn FactoryMethods.newInstance(tb);\n\t}", "summary_tokens": ["note", "that", "overloaded", "methods", "are", "supported"], "project": "spring-framework"}
{"id": 251, "code": "\tpublic DefaultIntroductionAdvisor getPoolingConfigMixin() {\n\t\tDelegatingIntroductionInterceptor dii = new DelegatingIntroductionInterceptor(this);\n\t\treturn new DefaultIntroductionAdvisor(dii, PoolingConfig.class);\n\t}", "summary_tokens": ["return", "an", "introduction", "advisor", "that", "provides", "a", "mixin", "exposing", "statistics", "about", "the", "pool", "maintained", "by", "this", "object"], "project": "spring-framework"}
{"id": 2767, "code": "\tpublic static boolean hasMetaAnnotationTypes(AnnotatedElement element, String annotationName) {\n\t\treturn getAnnotations(element).stream(annotationName).anyMatch(MergedAnnotation::isMetaPresent);\n\t}", "summary_tokens": ["determine", "if", "the", "supplied", "annotated", "element", "is", "annotated", "with", "a", "em", "composed", "annotation", "em", "that", "is", "meta", "annotated", "with", "an", "annotation", "of", "the", "specified", "annotation", "name"], "project": "spring-framework"}
{"id": 3703, "code": "\tpublic SqlReturnType getSqlReturnType() {\n\t\treturn this.sqlReturnType;\n\t}", "summary_tokens": ["return", "the", "custom", "return", "type", "if", "any"], "project": "spring-framework"}
{"id": 8158, "code": "\tdefault Mono<ServerResponse> checkNotModified(Instant lastModified, String etag) {\n\t\tAssert.notNull(lastModified, \"LastModified must not be null\");\n\t\tAssert.notNull(etag, \"Etag must not be null\");\n\t\treturn DefaultServerRequest.checkNotModified(exchange(), lastModified, etag);\n\t}", "summary_tokens": ["check", "whether", "the", "requested", "resource", "has", "been", "modified", "given", "the", "supplied", "etag", "entity", "tag", "and", "last", "modified", "timestamp", "as", "determined", "by", "the", "application"], "project": "spring-framework"}
{"id": 4414, "code": "\tpublic void setMessageConverter(@Nullable MessageConverter messageConverter) {\n\t\tthis.messageConverter = messageConverter;\n\t}", "summary_tokens": ["set", "the", "message", "converter", "strategy", "for", "converting", "jms", "messages"], "project": "spring-framework"}
{"id": 1789, "code": "\tpublic static <V> ListenableFuture<V> forExecutionException(Throwable ex) {\n\t\treturn new AsyncResult<>(null, ex);\n\t}", "summary_tokens": ["create", "a", "new", "async", "result", "which", "exposes", "the", "given", "exception", "as", "an", "execution", "exception", "from", "future", "get"], "project": "spring-framework"}
{"id": 6276, "code": "\tprotected Object invokeWithinTransaction(Method method, @Nullable Class<?> targetClass,\n\t\t\tfinal InvocationCallback invocation) throws Throwable {\n\n\t\t\n\t\tTransactionAttributeSource tas = getTransactionAttributeSource();\n\t\tfinal TransactionAttribute txAttr = (tas != null ? tas.getTransactionAttribute(method, targetClass) : null);\n\t\tfinal TransactionManager tm = determineTransactionManager(txAttr);\n\n\t\tif (this.reactiveAdapterRegistry != null && tm instanceof ReactiveTransactionManager) {\n\t\t\tboolean isSuspendingFunction = KotlinDetector.isSuspendingFunction(method);\n\t\t\tboolean hasSuspendingFlowReturnType = isSuspendingFunction &&\n\t\t\t\t\tCOROUTINES_FLOW_CLASS_NAME.equals(new MethodParameter(method, -1).getParameterType().getName());\n\t\t\tif (isSuspendingFunction && !(invocation instanceof CoroutinesInvocationCallback)) {\n\t\t\t\tthrow new IllegalStateException(\"Coroutines invocation not supported: \" + method);\n\t\t\t}\n\t\t\tCoroutinesInvocationCallback corInv = (isSuspendingFunction ? (CoroutinesInvocationCallback) invocation : null);\n\n\t\t\tReactiveTransactionSupport txSupport = this.transactionSupportCache.computeIfAbsent(method, key -> {\n\t\t\t\tClass<?> reactiveType =\n\t\t\t\t\t\t(isSuspendingFunction ? (hasSuspendingFlowReturnType ? Flux.class : Mono.class) : method.getReturnType());\n\t\t\t\tReactiveAdapter adapter = this.reactiveAdapterRegistry.getAdapter(reactiveType);\n\t\t\t\tif (adapter == null) {\n\t\t\t\t\tthrow new IllegalStateException(\"Cannot apply reactive transaction to non-reactive return type: \" +\n\t\t\t\t\t\t\tmethod.getReturnType());\n\t\t\t\t}\n\t\t\t\treturn new ReactiveTransactionSupport(adapter);\n\t\t\t});\n\n\t\t\tInvocationCallback callback = invocation;\n\t\t\tif (corInv != null) {\n\t\t\t\tcallback = () -> CoroutinesUtils.invokeSuspendingFunction(method, corInv.getTarget(), corInv.getArguments());\n\t\t\t}\n\t\t\tObject result = txSupport.invokeWithinTransaction(method, targetClass, callback, txAttr, (ReactiveTransactionManager) tm);\n\t\t\tif (corInv != null) {\n\t\t\t\tPublisher<?> pr = (Publisher<?>) result;\n\t\t\t\treturn (hasSuspendingFlowReturnType ? KotlinDelegate.asFlow(pr) :\n\t\t\t\t\t\tKotlinDelegate.awaitSingleOrNull(pr, corInv.getContinuation()));\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\n\t\tPlatformTransactionManager ptm = asPlatformTransactionManager(tm);\n\t\tfinal String joinpointIdentification = methodIdentification(method, targetClass, txAttr);\n\n\t\tif (txAttr == null || !(ptm instanceof CallbackPreferringPlatformTransactionManager)) {\n\t\t\t\n\t\t\tTransactionInfo txInfo = createTransactionIfNecessary(ptm, txAttr, joinpointIdentification);\n\n\t\t\tObject retVal;\n\t\t\ttry {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tretVal = invocation.proceedWithInvocation();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\t\n\t\t\t\tcompleteTransactionAfterThrowing(txInfo, ex);\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\tcleanupTransactionInfo(txInfo);\n\t\t\t}\n\n\t\t\tif (retVal != null && vavrPresent && VavrDelegate.isVavrTry(retVal)) {\n\t\t\t\t\n\t\t\t\tTransactionStatus status = txInfo.getTransactionStatus();\n\t\t\t\tif (status != null && txAttr != null) {\n\t\t\t\t\tretVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcommitTransactionAfterReturning(txInfo);\n\t\t\treturn retVal;\n\t\t}\n\n\t\telse {\n\t\t\tObject result;\n\t\t\tfinal ThrowableHolder throwableHolder = new ThrowableHolder();\n\n\t\t\t\n\t\t\ttry {\n\t\t\t\tresult = ((CallbackPreferringPlatformTransactionManager) ptm).execute(txAttr, status -> {\n\t\t\t\t\tTransactionInfo txInfo = prepareTransactionInfo(ptm, txAttr, joinpointIdentification, status);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tObject retVal = invocation.proceedWithInvocation();\n\t\t\t\t\t\tif (retVal != null && vavrPresent && VavrDelegate.isVavrTry(retVal)) {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tretVal = VavrDelegate.evaluateTryFailure(retVal, txAttr, status);\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn retVal;\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Throwable ex) {\n\t\t\t\t\t\tif (txAttr.rollbackOn(ex)) {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tif (ex instanceof RuntimeException) {\n\t\t\t\t\t\t\t\tthrow (RuntimeException) ex;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\tthrow new ThrowableHolderException(ex);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\tthrowableHolder.throwable = ex;\n\t\t\t\t\t\t\treturn null;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tfinally {\n\t\t\t\t\t\tcleanupTransactionInfo(txInfo);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t\tcatch (ThrowableHolderException ex) {\n\t\t\t\tthrow ex.getCause();\n\t\t\t}\n\t\t\tcatch (TransactionSystemException ex2) {\n\t\t\t\tif (throwableHolder.throwable != null) {\n\t\t\t\t\tlogger.error(\"Application exception overridden by commit exception\", throwableHolder.throwable);\n\t\t\t\t\tex2.initApplicationException(throwableHolder.throwable);\n\t\t\t\t}\n\t\t\t\tthrow ex2;\n\t\t\t}\n\t\t\tcatch (Throwable ex2) {\n\t\t\t\tif (throwableHolder.throwable != null) {\n\t\t\t\t\tlogger.error(\"Application exception overridden by commit exception\", throwableHolder.throwable);\n\t\t\t\t}\n\t\t\t\tthrow ex2;\n\t\t\t}\n\n\t\t\t\n\t\t\tif (throwableHolder.throwable != null) {\n\t\t\t\tthrow throwableHolder.throwable;\n\t\t\t}\n\t\t\treturn result;\n\t\t}\n\t}", "summary_tokens": ["general", "delegate", "for", "around", "advice", "based", "subclasses", "delegating", "to", "several", "other", "template", "methods", "on", "this", "class"], "project": "spring-framework"}
{"id": 2491, "code": "public AnnotationVisitor visitTryCatchAnnotation(\n    final int typeRef, final TypePath typePath, final String descriptor, final boolean visible) {\n  if (api < Opcodes.ASM5) {\n    throw new UnsupportedOperationException(REQUIRES_ASM5);\n  }\n  if (mv != null) {\n    return mv.visitTryCatchAnnotation(typeRef, typePath, descriptor, visible);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "annotation", "on", "an", "exception", "handler", "type"], "project": "spring-framework"}
{"id": 8862, "code": "\tpublic void afterPropertiesSet() throws Exception {\n\t\tif (this.servletClass == null) {\n\t\t\tthrow new IllegalArgumentException(\"'servletClass' is required\");\n\t\t}\n\t\tif (this.servletName == null) {\n\t\t\tthis.servletName = this.beanName;\n\t\t}\n\t\tthis.servletInstance = ReflectionUtils.accessibleConstructor(this.servletClass).newInstance();\n\t\tthis.servletInstance.init(new DelegatingServletConfig());\n\t}", "summary_tokens": ["initialize", "the", "wrapped", "servlet", "instance"], "project": "spring-framework"}
{"id": 5474, "code": "\tpublic void registerNamedDispatcher(String name, RequestDispatcher requestDispatcher) {\n\t\tAssert.notNull(name, \"RequestDispatcher name must not be null\");\n\t\tAssert.notNull(requestDispatcher, \"RequestDispatcher must not be null\");\n\t\tthis.namedRequestDispatchers.put(name, requestDispatcher);\n\t}", "summary_tokens": ["register", "a", "request", "dispatcher", "typically", "a", "mock", "request", "dispatcher", "that", "acts", "as", "a", "wrapper", "for", "the", "named", "servlet"], "project": "spring-framework"}
{"id": 1872, "code": "\tpublic String getExpression() {\n\t\treturn this.expression;\n\t}", "summary_tokens": ["return", "the", "cron", "expression", "defining", "when", "the", "task", "should", "be", "executed"], "project": "spring-framework"}
{"id": 757, "code": "\tpublic void markAsPostProcessed() {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\tthis.postProcessed = true;\n\t\t}\n\t}", "summary_tokens": ["mark", "this", "bean", "definition", "as", "post", "processed", "i"], "project": "spring-framework"}
{"id": 8513, "code": "\tprotected LocaleContext buildLocaleContext(final HttpServletRequest request) {\n\t\tLocaleResolver lr = this.localeResolver;\n\t\tif (lr instanceof LocaleContextResolver) {\n\t\t\treturn ((LocaleContextResolver) lr).resolveLocaleContext(request);\n\t\t}\n\t\telse {\n\t\t\treturn () -> (lr != null ? lr.resolveLocale(request) : request.getLocale());\n\t\t}\n\t}", "summary_tokens": ["build", "a", "locale", "context", "for", "the", "given", "request", "exposing", "the", "request", "s", "primary", "locale", "as", "current", "locale"], "project": "spring-framework"}
{"id": 5509, "code": "\tpublic int hashCode() {\n\t\tint result = Arrays.hashCode(this.locations);\n\t\tresult = 31 * result + Arrays.hashCode(this.classes);\n\t\tresult = 31 * result + this.contextInitializerClasses.hashCode();\n\t\tresult = 31 * result + Arrays.hashCode(this.activeProfiles);\n\t\tresult = 31 * result + Arrays.hashCode(this.propertySourceLocations);\n\t\tresult = 31 * result + Arrays.hashCode(this.propertySourceProperties);\n\t\tresult = 31 * result + this.contextCustomizers.hashCode();\n\t\tresult = 31 * result + (this.parent != null ? this.parent.hashCode() : 0);\n\t\tresult = 31 * result + nullSafeClassName(this.contextLoader).hashCode();\n\t\treturn result;\n\t}", "summary_tokens": ["generate", "a", "unique", "hash", "code", "for", "all", "properties", "of", "this", "merged", "context", "configuration", "excluding", "the", "get", "test", "class", "test", "class"], "project": "spring-framework"}
{"id": 8778, "code": "\tstatic BodyBuilder badRequest() {\n\t\treturn status(HttpStatus.BAD_REQUEST);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "a", "http", "status", "bad", "request", "0", "bad", "request", "status"], "project": "spring-framework"}
{"id": 9035, "code": "\tpublic Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer,\n\t\t\tNativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception {\n\n\t\tif (mavContainer != null) {\n\t\t\tmavContainer.setRequestHandled(true);\n\t\t}\n\n\t\tClass<?> paramType = parameter.getParameterType();\n\n\t\t\n\t\tif (ServletResponse.class.isAssignableFrom(paramType)) {\n\t\t\treturn resolveNativeResponse(webRequest, paramType);\n\t\t}\n\n\t\t\n\t\treturn resolveArgument(paramType, resolveNativeResponse(webRequest, ServletResponse.class));\n\t}", "summary_tokens": ["set", "model", "and", "view", "container", "set", "request", "handled", "boolean", "to", "false", "to", "indicate", "that", "the", "method", "signature", "provides", "access", "to", "the", "response"], "project": "spring-framework"}
{"id": 3822, "code": "\tdefault int getSqlType(String paramName) {\n\t\treturn TYPE_UNKNOWN;\n\t}", "summary_tokens": ["determine", "the", "sql", "type", "for", "the", "specified", "named", "parameter"], "project": "spring-framework"}
{"id": 1752, "code": "\tpublic Object getProperty(String name) {\n\t\tif (getSource().isResourceRef() && name.indexOf(':') != -1) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\treturn null;\n\t\t}\n\n\t\ttry {\n\t\t\tObject value = this.source.lookup(name);\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"JNDI lookup for name [\" + name + \"] returned: [\" + value + \"]\");\n\t\t\t}\n\t\t\treturn value;\n\t\t}\n\t\tcatch (NamingException ex) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"JNDI lookup for name [\" + name + \"] threw NamingException \" +\n\t\t\t\t\t\t\"with message: \" + ex.getMessage() + \". Returning null.\");\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "looks", "up", "and", "returns", "the", "value", "associated", "with", "the", "given", "name", "from", "the", "underlying", "jndi", "locator", "delegate"], "project": "spring-framework"}
{"id": 463, "code": "\tdefault Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {\n\t\treturn bean;\n\t}", "summary_tokens": ["apply", "this", "bean", "post", "processor", "to", "the", "given", "new", "bean", "instance", "i", "after", "i", "any", "bean", "initialization", "callbacks", "like", "initializing", "bean", "s", "after", "properties", "set", "or", "a", "custom", "init", "method"], "project": "spring-framework"}
{"id": 6177, "code": "\tpublic static <T> T nullableSingleResult(@Nullable Collection<T> results) throws IncorrectResultSizeDataAccessException {\n\t\t\n\t\t\n\t\tif (CollectionUtils.isEmpty(results)) {\n\t\t\tthrow new EmptyResultDataAccessException(1);\n\t\t}\n\t\tif (results.size() > 1) {\n\t\t\tthrow new IncorrectResultSizeDataAccessException(1, results.size());\n\t\t}\n\t\treturn results.iterator().next();\n\t}", "summary_tokens": ["return", "a", "single", "result", "object", "from", "the", "given", "collection"], "project": "spring-framework"}
{"id": 1509, "code": "\tpublic void addTransformer(ClassFileTransformer transformer) {\n\t\tAssert.notNull(transformer, \"Transformer must not be null\");\n\t\tthis.classFileTransformers.add(transformer);\n\t}", "summary_tokens": ["add", "the", "given", "class", "file", "transformer", "to", "the", "list", "of", "transformers", "that", "this", "class", "loader", "will", "apply"], "project": "spring-framework"}
{"id": 8910, "code": "\tpublic PatternsRequestCondition getMatchingCondition(HttpServletRequest request) {\n\t\tString lookupPath = UrlPathHelper.getResolvedLookupPath(request);\n\t\tList<String> matches = getMatchingPatterns(lookupPath);\n\t\treturn !matches.isEmpty() ? new PatternsRequestCondition(new LinkedHashSet<>(matches), this) : null;\n\t}", "summary_tokens": ["checks", "if", "any", "of", "the", "patterns", "match", "the", "given", "request", "and", "returns", "an", "instance", "that", "is", "guaranteed", "to", "contain", "matching", "patterns", "sorted", "via", "path", "matcher", "get", "pattern", "comparator", "string"], "project": "spring-framework"}
{"id": 5122, "code": "\tpublic void setFilterNames(@Nullable String... filterNames) {\n\t\tthis.filterNames = filterNames;\n\t}", "summary_tokens": ["set", "one", "or", "more", "names", "of", "hibernate", "filters", "to", "be", "activated", "for", "all", "sessions", "that", "this", "accessor", "works", "with"], "project": "spring-framework"}
{"id": 464, "code": "\tpublic void setPropertyEditorRegistrars(PropertyEditorRegistrar[] propertyEditorRegistrars) {\n\t\tthis.propertyEditorRegistrars = propertyEditorRegistrars;\n\t}", "summary_tokens": ["specify", "the", "property", "editor", "registrar", "property", "editor", "registrars", "to", "apply", "to", "beans", "defined", "within", "the", "current", "application", "context"], "project": "spring-framework"}
{"id": 7149, "code": "\tpublic final MethodParameter getParameter() {\n\t\treturn this.parameter;\n\t}", "summary_tokens": ["return", "the", "method", "parameter", "bound", "to", "the", "request", "cookie"], "project": "spring-framework"}
{"id": 4534, "code": "\tprotected MessageListener getMessageListener() {\n\t\tAssert.state(this.messageListener != null, \"No MessageListener set\");\n\t\treturn this.messageListener;\n\t}", "summary_tokens": ["return", "the", "jms", "message", "listener", "for", "this", "endpoint"], "project": "spring-framework"}
{"id": 8251, "code": "\tpublic Set<RequestMethod> getMethods() {\n\t\treturn this.methods;\n\t}", "summary_tokens": ["returns", "all", "request", "method", "request", "methods", "contained", "in", "this", "condition"], "project": "spring-framework"}
{"id": 7549, "code": "\tpublic boolean supportsParameter(MethodParameter parameter) {\n\t\ttry {\n\t\t\tNativeWebRequest webRequest = getWebRequest();\n\t\t\tObject result = this.adaptee.resolveArgument(parameter, webRequest);\n\t\t\tif (result == WebArgumentResolver.UNRESOLVED) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\telse {\n\t\t\t\treturn ClassUtils.isAssignableValue(parameter.getParameterType(), result);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\t\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Error in checking support for parameter [\" + parameter + \"]: \" + ex.getMessage());\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["actually", "resolve", "the", "value", "and", "check", "the", "resolved", "value", "is", "not", "web", "argument", "resolver", "unresolved", "absorbing", "any", "exceptions"], "project": "spring-framework"}
{"id": 7540, "code": "\tpublic static HandlerTypePredicate forAnnotation(Class<? extends Annotation>... annotations) {\n\t\treturn new Builder().annotation(annotations).build();\n\t}", "summary_tokens": ["match", "handlers", "annotated", "with", "a", "specific", "annotation"], "project": "spring-framework"}
{"id": 6457, "code": "\tprivate void doRollbackOnCommitException(DefaultTransactionStatus status, Throwable ex) throws TransactionException {\n\t\ttry {\n\t\t\tif (status.isNewTransaction()) {\n\t\t\t\tif (status.isDebug()) {\n\t\t\t\t\tlogger.debug(\"Initiating transaction rollback after commit exception\", ex);\n\t\t\t\t}\n\t\t\t\tdoRollback(status);\n\t\t\t}\n\t\t\telse if (status.hasTransaction() && isGlobalRollbackOnParticipationFailure()) {\n\t\t\t\tif (status.isDebug()) {\n\t\t\t\t\tlogger.debug(\"Marking existing transaction as rollback-only after commit exception\", ex);\n\t\t\t\t}\n\t\t\t\tdoSetRollbackOnly(status);\n\t\t\t}\n\t\t}\n\t\tcatch (RuntimeException | Error rbex) {\n\t\t\tlogger.error(\"Commit exception overridden by rollback exception\", ex);\n\t\t\ttriggerAfterCompletion(status, TransactionSynchronization.STATUS_UNKNOWN);\n\t\t\tthrow rbex;\n\t\t}\n\t\ttriggerAfterCompletion(status, TransactionSynchronization.STATUS_ROLLED_BACK);\n\t}", "summary_tokens": ["invoke", "do", "rollback", "handling", "rollback", "exceptions", "properly"], "project": "spring-framework"}
{"id": 7740, "code": "\tpublic int getMaxSessions() {\n\t\treturn this.maxSessions;\n\t}", "summary_tokens": ["return", "the", "maximum", "number", "of", "sessions", "that", "can", "be", "stored"], "project": "spring-framework"}
{"id": 2111, "code": "\tvoid alreadyLoadedConfigurationClasses() {\n\t\tbeanFactory.registerBeanDefinition(\"unloadedConfig\", new RootBeanDefinition(UnloadedConfig.class.getName()));\n\t\tbeanFactory.registerBeanDefinition(\"loadedConfig\", new RootBeanDefinition(LoadedConfig.class));\n\t\tConfigurationClassPostProcessor pp = new ConfigurationClassPostProcessor();\n\t\tpp.postProcessBeanFactory(beanFactory);\n\t\tbeanFactory.getBean(\"foo\");\n\t\tbeanFactory.getBean(\"bar\");\n\t}", "summary_tokens": ["tests", "the", "fix", "for", "spr", "0", "a", "special", "workaround", "that", "prefers", "reflection", "over", "asm", "if", "a", "bean", "class", "is", "already", "loaded"], "project": "spring-framework"}
{"id": 7993, "code": "\tpublic PathMatchConfigurer setUseCaseSensitiveMatch(Boolean caseSensitiveMatch) {\n\t\tthis.caseSensitiveMatch = caseSensitiveMatch;\n\t\treturn this;\n\t}", "summary_tokens": ["whether", "to", "match", "to", "urls", "irrespective", "of", "their", "case"], "project": "spring-framework"}
{"id": 6823, "code": "\tpublic void setDefaultCharset(Charset charset) {\n\t\tAssert.notNull(charset, \"Charset must not be null\");\n\t\tthis.defaultCharset = charset;\n\t}", "summary_tokens": ["set", "the", "default", "character", "set", "to", "use", "for", "writing", "form", "data", "when", "the", "response", "content", "type", "header", "does", "not", "explicitly", "specify", "it"], "project": "spring-framework"}
{"id": 401, "code": "\tdefault void ifAvailable(Consumer<T> dependencyConsumer) throws BeansException {\n\t\tT dependency = getIfAvailable();\n\t\tif (dependency != null) {\n\t\t\tdependencyConsumer.accept(dependency);\n\t\t}\n\t}", "summary_tokens": ["consume", "an", "instance", "possibly", "shared", "or", "independent", "of", "the", "object", "managed", "by", "this", "factory", "if", "available"], "project": "spring-framework"}
{"id": 5854, "code": "\tpublic static DefaultResponseCreator withSuccess(Resource body, @Nullable MediaType contentType) {\n\t\tDefaultResponseCreator creator = new DefaultResponseCreator(HttpStatus.OK).body(body);\n\t\treturn (contentType != null ? creator.contentType(contentType) : creator);\n\t}", "summary_tokens": ["response", "creator", "for", "a", "0", "response", "ok", "content", "with", "resource", "based", "body"], "project": "spring-framework"}
{"id": 4796, "code": "\tstatic Builder builder() {\n\t\treturn new DefaultRSocketStrategies.DefaultRSocketStrategiesBuilder();\n\t}", "summary_tokens": ["return", "a", "builder", "to", "prepare", "a", "new", "rsocket", "strategies", "instance"], "project": "spring-framework"}
{"id": 8630, "code": "\tpublic ResourceHandlerRegistration setUseLastModified(boolean useLastModified) {\n\t\tthis.useLastModified = useLastModified;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "whether", "the", "resource", "last", "modified", "information", "should", "be", "used", "to", "drive", "http", "responses"], "project": "spring-framework"}
{"id": 2349, "code": "private int[] readTypeAnnotations(\n    final MethodVisitor methodVisitor,\n    final Context context,\n    final int runtimeTypeAnnotationsOffset,\n    final boolean visible) {\n  char[] charBuffer = context.charBuffer;\n  int currentOffset = runtimeTypeAnnotationsOffset;\n    \n  int[] typeAnnotationsOffsets = new int[readUnsignedShort(currentOffset)];\n  currentOffset += 2;\n    \n  for (int i = 0; i < typeAnnotationsOffsets.length; ++i) {\n    typeAnnotationsOffsets[i] = currentOffset;\n      \n      \n    int targetType = readInt(currentOffset);\n    switch (targetType >>> 24) {\n      case TypeReference.LOCAL_VARIABLE:\n      case TypeReference.RESOURCE_VARIABLE:\n          \n          \n        int tableLength = readUnsignedShort(currentOffset + 1);\n        currentOffset += 3;\n        while (tableLength-- > 0) {\n          int startPc = readUnsignedShort(currentOffset);\n          int length = readUnsignedShort(currentOffset + 2);\n            \n          currentOffset += 6;\n          createLabel(startPc, context.currentMethodLabels);\n          createLabel(startPc + length, context.currentMethodLabels);\n        }\n        break;\n      case TypeReference.CAST:\n      case TypeReference.CONSTRUCTOR_INVOCATION_TYPE_ARGUMENT:\n      case TypeReference.METHOD_INVOCATION_TYPE_ARGUMENT:\n      case TypeReference.CONSTRUCTOR_REFERENCE_TYPE_ARGUMENT:\n      case TypeReference.METHOD_REFERENCE_TYPE_ARGUMENT:\n        currentOffset += 4;\n        break;\n      case TypeReference.CLASS_EXTENDS:\n      case TypeReference.CLASS_TYPE_PARAMETER_BOUND:\n      case TypeReference.METHOD_TYPE_PARAMETER_BOUND:\n      case TypeReference.THROWS:\n      case TypeReference.EXCEPTION_PARAMETER:\n      case TypeReference.INSTANCEOF:\n      case TypeReference.NEW:\n      case TypeReference.CONSTRUCTOR_REFERENCE:\n      case TypeReference.METHOD_REFERENCE:\n        currentOffset += 3;\n        break;\n      case TypeReference.CLASS_TYPE_PARAMETER:\n      case TypeReference.METHOD_TYPE_PARAMETER:\n      case TypeReference.METHOD_FORMAL_PARAMETER:\n      case TypeReference.FIELD:\n      case TypeReference.METHOD_RETURN:\n      case TypeReference.METHOD_RECEIVER:\n      default:\n          \n        throw new IllegalArgumentException();\n    }\n      \n      \n    int pathLength = readByte(currentOffset);\n    if ((targetType >>> 24) == TypeReference.EXCEPTION_PARAMETER) {\n        \n      TypePath path = pathLength == 0 ? null : new TypePath(classFileBuffer, currentOffset);\n      currentOffset += 1 + 2 * pathLength;\n        \n      String annotationDescriptor = readUTF8(currentOffset, charBuffer);\n      currentOffset += 2;\n        \n      currentOffset =\n          readElementValues(\n              methodVisitor.visitTryCatchAnnotation(\n                  targetType & 0xFFFFFF00, path, annotationDescriptor, visible),\n              currentOffset,\n               true,\n              charBuffer);\n    } else {\n        \n        \n        \n      currentOffset += 3 + 2 * pathLength;\n        \n        \n      currentOffset =\n          readElementValues(\n               null, currentOffset,  true, charBuffer);\n    }\n  }\n  return typeAnnotationsOffsets;\n}", "summary_tokens": ["parses", "a", "runtime", "in", "visible", "type", "annotations", "attribute", "to", "find", "the", "offset", "of", "each", "type", "annotation", "entry", "it", "contains", "to", "find", "the", "corresponding", "labels", "and", "to", "visit", "the", "try", "catch", "block", "annotations"], "project": "spring-framework"}
{"id": 6127, "code": "\tpublic ResultMatcher string(String expectedValue) {\n\t\treturn result -> {\n\t\t\tMockHttpServletResponse response = result.getResponse();\n\t\t\tthis.xpathHelper.assertString(response.getContentAsByteArray(), getDefinedEncoding(response), expectedValue);\n\t\t};\n\t}", "summary_tokens": ["apply", "the", "xpath", "and", "assert", "the", "string", "value", "found"], "project": "spring-framework"}
{"id": 1082, "code": "\tpublic void setOverwriteExistingJobs(boolean overwriteExistingJobs) {\n\t\tthis.overwriteExistingJobs = overwriteExistingJobs;\n\t}", "summary_tokens": ["set", "whether", "any", "jobs", "defined", "on", "this", "scheduler", "factory", "bean", "should", "overwrite", "existing", "job", "definitions"], "project": "spring-framework"}
{"id": 7333, "code": "\tprotected ResourcePatternResolver getResourcePatternResolver() {\n\t\treturn new ServletContextResourcePatternResolver(this);\n\t}", "summary_tokens": ["this", "implementation", "supports", "pattern", "matching", "in", "unexpanded", "wars", "too"], "project": "spring-framework"}
{"id": 2307, "code": "public AnnotationVisitor visitArray(final String name) {\n  if (av != null) {\n    return av.visitArray(name);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "array", "value", "of", "the", "annotation"], "project": "spring-framework"}
{"id": 4011, "code": "\tpublic EmbeddedDatabaseBuilder setScriptEncoding(String scriptEncoding) {\n\t\tthis.databasePopulator.setSqlScriptEncoding(scriptEncoding);\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "the", "character", "encoding", "used", "in", "all", "sql", "scripts", "if", "different", "from", "the", "platform", "encoding"], "project": "spring-framework"}
{"id": 8458, "code": "\tpublic int getMaxFramePayloadLength() {\n\t\treturn getWebsocketClientSpec().maxFramePayloadLength();\n\t}", "summary_tokens": ["return", "the", "configured", "set", "max", "frame", "payload", "length", "int", "max", "frame", "payload", "length"], "project": "spring-framework"}
{"id": 2852, "code": "\tprotected Set<String> doGetActiveProfiles() {\n\t\tsynchronized (this.activeProfiles) {\n\t\t\tif (this.activeProfiles.isEmpty()) {\n\t\t\t\tString profiles = doGetActiveProfilesProperty();\n\t\t\t\tif (StringUtils.hasText(profiles)) {\n\t\t\t\t\tsetActiveProfiles(StringUtils.commaDelimitedListToStringArray(\n\t\t\t\t\t\t\tStringUtils.trimAllWhitespace(profiles)));\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn this.activeProfiles;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "set", "of", "active", "profiles", "as", "explicitly", "set", "through", "set", "active", "profiles", "or", "if", "the", "current", "set", "of", "active", "profiles", "is", "empty", "check", "for", "the", "presence", "of", "do", "get", "active", "profiles", "property", "and", "assign", "its", "value", "to", "the", "set", "of", "active", "profiles"], "project": "spring-framework"}
{"id": 1773, "code": "\tdefault Clock getClock() {\n\t\treturn Clock.systemDefaultZone();\n\t}", "summary_tokens": ["return", "the", "clock", "to", "use", "for", "trigger", "calculation"], "project": "spring-framework"}
{"id": 5162, "code": "\tpublic void setEntityTypeFilters(TypeFilter... entityTypeFilters) {\n\t\tthis.entityTypeFilters = entityTypeFilters;\n\t}", "summary_tokens": ["specify", "custom", "type", "filters", "for", "spring", "based", "scanning", "for", "entity", "classes"], "project": "spring-framework"}
{"id": 1011, "code": "\tpublic final Exception[] getMessageExceptions() {\n\t\treturn (this.messageExceptions != null ? this.messageExceptions : new Exception[0]);\n\t}", "summary_tokens": ["return", "an", "array", "with", "thrown", "message", "exceptions"], "project": "spring-framework"}
{"id": 7552, "code": "\tpublic boolean hasExceptionMappings() {\n\t\treturn !this.mappedMethods.isEmpty();\n\t}", "summary_tokens": ["whether", "the", "contained", "type", "has", "any", "exception", "mappings"], "project": "spring-framework"}
{"id": 2632, "code": "public void unbox_or_zero(Type type) {\n    if (TypeUtils.isPrimitive(type)) {\n        if (type != Type.VOID_TYPE) {\n            Label nonNull = make_label();\n            Label end = make_label();\n            dup();\n            ifnonnull(nonNull);\n            pop();\n            zero_or_null(type);\n            goTo(end);\n            mark(nonNull);\n            unbox(type);\n            mark(end);\n        }\n    } else {\n        checkcast(type);\n    }\n}", "summary_tokens": ["unboxes", "the", "object", "on", "the", "top", "of", "the", "stack"], "project": "spring-framework"}
{"id": 195, "code": "\tprotected String getInvocationDescription(MethodInvocation invocation) {\n\t\tObject target = invocation.getThis();\n\t\tAssert.state(target != null, \"Target must not be null\");\n\t\tString className = target.getClass().getName();\n\t\treturn \"method '\" + invocation.getMethod().getName() + \"' of class [\" + className + \"]\";\n\t}", "summary_tokens": ["return", "a", "description", "for", "the", "given", "method", "invocation"], "project": "spring-framework"}
{"id": 8305, "code": "\tpublic Map<String, Predicate<Class<?>>> getPathPrefixes() {\n\t\treturn Collections.unmodifiableMap(this.pathPrefixes);\n\t}", "summary_tokens": ["the", "configured", "path", "prefixes", "as", "a", "read", "only", "possibly", "empty", "map"], "project": "spring-framework"}
{"id": 7605, "code": "\tprotected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer,\n\t\t\tObject... providedArgs) throws Exception {\n\n\t\tMethodParameter[] parameters = getMethodParameters();\n\t\tif (ObjectUtils.isEmpty(parameters)) {\n\t\t\treturn EMPTY_ARGS;\n\t\t}\n\n\t\tObject[] args = new Object[parameters.length];\n\t\tfor (int i = 0; i < parameters.length; i++) {\n\t\t\tMethodParameter parameter = parameters[i];\n\t\t\tparameter.initParameterNameDiscovery(this.parameterNameDiscoverer);\n\t\t\targs[i] = findProvidedArgument(parameter, providedArgs);\n\t\t\tif (args[i] != null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (!this.resolvers.supportsParameter(parameter)) {\n\t\t\t\tthrow new IllegalStateException(formatArgumentError(parameter, \"No suitable resolver\"));\n\t\t\t}\n\t\t\ttry {\n\t\t\t\targs[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory);\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\t\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tString exMsg = ex.getMessage();\n\t\t\t\t\tif (exMsg != null && !exMsg.contains(parameter.getExecutable().toGenericString())) {\n\t\t\t\t\t\tlogger.debug(formatArgumentError(parameter, exMsg));\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t}\n\t\treturn args;\n\t}", "summary_tokens": ["get", "the", "method", "argument", "values", "for", "the", "current", "request", "checking", "the", "provided", "argument", "values", "and", "falling", "back", "to", "the", "configured", "argument", "resolvers"], "project": "spring-framework"}
{"id": 8402, "code": "\tpublic void afterPropertiesSet() throws IOException, TemplateException {\n\t\tif (this.configuration == null) {\n\t\t\tthis.configuration = createConfiguration();\n\t\t}\n\t}", "summary_tokens": ["initialize", "free", "marker", "configuration", "factory", "s", "configuration", "if", "not", "overridden", "by", "a", "pre", "configured", "free", "marker", "configuration"], "project": "spring-framework"}
{"id": 552, "code": "\tpublic void setTargetSetClass(@Nullable Class<? extends Set> targetSetClass) {\n\t\tif (targetSetClass == null) {\n\t\t\tthrow new IllegalArgumentException(\"'targetSetClass' must not be null\");\n\t\t}\n\t\tif (!Set.class.isAssignableFrom(targetSetClass)) {\n\t\t\tthrow new IllegalArgumentException(\"'targetSetClass' must implement [java.util.Set]\");\n\t\t}\n\t\tthis.targetSetClass = targetSetClass;\n\t}", "summary_tokens": ["set", "the", "class", "to", "use", "for", "the", "target", "set"], "project": "spring-framework"}
{"id": 3611, "code": "\tpublic void evaluate(String expression, Object expectedValue, Class<?> expectedResultType, boolean shouldBeWritable) {\n\t\tExpression expr = parser.parseExpression(expression);\n\t\tassertThat(expr).as(\"expression\").isNotNull();\n\t\tif (DEBUG) {\n\t\t\tSpelUtilities.printAbstractSyntaxTree(System.out, expr);\n\t\t}\n\t\tObject value = expr.getValue(context);\n\t\tif (value == null) {\n\t\t\tif (expectedValue == null) {\n\t\t\t\treturn;  \n\t\t\t}\n\t\t\tassertThat(expectedValue).as(\"Expression returned null value, but expected '\" + expectedValue + \"'\").isNull();\n\t\t}\n\t\tClass<? extends Object> resultType = value.getClass();\n\t\tif (expectedValue instanceof String) {\n\t\t\tassertThat(AbstractExpressionTests.stringValueOf(value)).as(\"Did not get expected value for expression '\" + expression + \"'.\").isEqualTo(expectedValue);\n\t\t}\n\t\telse {\n\t\t\tassertThat(value).as(\"Did not get expected value for expression '\" + expression + \"'.\").isEqualTo(expectedValue);\n\t\t}\n\t\tassertThat(expectedResultType.equals(resultType)).as(\"Type of the result was not as expected.  Expected '\" + expectedResultType +\n\t\t\t\t\"' but result was of type '\" + resultType + \"'\").isTrue();\n\n\t\tassertThat(expr.isWritable(context)).as(\"isWritable\").isEqualTo(shouldBeWritable);\n\t}", "summary_tokens": ["evaluate", "an", "expression", "and", "check", "that", "the", "actual", "result", "matches", "the", "expected", "value", "and", "the", "class", "of", "the", "result", "matches", "the", "expected", "result", "type"], "project": "spring-framework"}
{"id": 997, "code": "\tpublic CacheResolver getCacheResolver() {\n\t\treturn SupplierUtils.resolve(this.cacheResolver);\n\t}", "summary_tokens": ["return", "the", "specified", "cache", "resolver", "to", "use", "if", "any"], "project": "spring-framework"}
{"id": 6071, "code": "\tpublic ResultMatcher isUseProxy() {\n\t\treturn matcher(HttpStatus.USE_PROXY);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 5084, "code": "\tpublic Map<String, List<String>> toNativeHeaderMap() {\n\t\tMap<String, List<String>> map = getNativeHeaders();\n\t\treturn (map != null ? new LinkedMultiValueMap<>(map) : Collections.emptyMap());\n\t}", "summary_tokens": ["return", "a", "copy", "of", "the", "native", "headers", "sub", "map", "or", "an", "empty", "map"], "project": "spring-framework"}
{"id": 5095, "code": "\tdefault org.springframework.util.concurrent.ListenableFuture<Void> shutdown() {\n\t\treturn new org.springframework.util.concurrent.CompletableToListenableFutureAdapter<>(\n\t\t\t\tshutdownAsync());\n\t}", "summary_tokens": ["shut", "down", "and", "close", "any", "open", "connections"], "project": "spring-framework"}
{"id": 5138, "code": "\tprotected Session createSessionProxy(Session session) {\n\t\treturn (Session) Proxy.newProxyInstance(\n\t\t\t\tsession.getClass().getClassLoader(), new Class<?>[] {Session.class},\n\t\t\t\tnew CloseSuppressingInvocationHandler(session));\n\t}", "summary_tokens": ["create", "a", "close", "suppressing", "proxy", "for", "the", "given", "hibernate", "session"], "project": "spring-framework"}
{"id": 4180, "code": "\tpublic int getPaddingLength() {\n\t\treturn this.paddingLength;\n\t}", "summary_tokens": ["return", "the", "padding", "length", "for", "string", "values"], "project": "spring-framework"}
{"id": 4415, "code": "\tpublic void setExceptionListener(@Nullable ExceptionListener exceptionListener) {\n\t\tthis.exceptionListener = exceptionListener;\n\t}", "summary_tokens": ["set", "the", "jms", "exception", "listener", "to", "notify", "in", "case", "of", "a", "jmsexception", "thrown", "by", "the", "registered", "message", "listener", "or", "the", "invocation", "infrastructure"], "project": "spring-framework"}
{"id": 2515, "code": "public void visitUse(final String service) {\n  if (mv != null) {\n    mv.visitUse(service);\n  }\n}", "summary_tokens": ["visit", "a", "service", "used", "by", "the", "current", "module"], "project": "spring-framework"}
{"id": 4795, "code": "\tstatic RSocketStrategies create() {\n\t\treturn new DefaultRSocketStrategies.DefaultRSocketStrategiesBuilder().build();\n\t}", "summary_tokens": ["create", "an", "rsocket", "strategies", "instance", "with", "default", "settings"], "project": "spring-framework"}
{"id": 1322, "code": "\tdefault int getOrder() {\n\t\treturn LOWEST_PRECEDENCE;\n\t}", "summary_tokens": ["determine", "this", "listener", "s", "order", "in", "a", "set", "of", "listeners", "for", "the", "same", "event"], "project": "spring-framework"}
{"id": 3808, "code": "\tprotected PreparedStatementCreator getPreparedStatementCreator(String sql, SqlParameterSource paramSource,\n\t\t\t@Nullable Consumer<PreparedStatementCreatorFactory> customizer) {\n\n\t\tParsedSql parsedSql = getParsedSql(sql);\n\t\tPreparedStatementCreatorFactory pscf = getPreparedStatementCreatorFactory(parsedSql, paramSource);\n\t\tif (customizer != null) {\n\t\t\tcustomizer.accept(pscf);\n\t\t}\n\t\tObject[] params = NamedParameterUtils.buildValueArray(parsedSql, paramSource, null);\n\t\treturn pscf.newPreparedStatementCreator(params);\n\t}", "summary_tokens": ["build", "a", "prepared", "statement", "creator", "based", "on", "the", "given", "sql", "and", "named", "parameters"], "project": "spring-framework"}
{"id": 4581, "code": "\tpublic static void rollbackIfNecessary(Session session) throws JMSException {\n\t\tAssert.notNull(session, \"Session must not be null\");\n\t\ttry {\n\t\t\tsession.rollback();\n\t\t}\n\t\tcatch (jakarta.jms.TransactionInProgressException | jakarta.jms.IllegalStateException ex) {\n\t\t\t\n\t\t}\n\t}", "summary_tokens": ["rollback", "the", "session", "if", "not", "within", "a", "jta", "transaction"], "project": "spring-framework"}
{"id": 4777, "code": "\tpublic InvocableHandlerMethod initExceptionHandlerMethod(HandlerMethod handlerMethod, Throwable ex) {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Searching for methods to handle \" + ex.getClass().getSimpleName());\n\t\t}\n\t\tClass<?> beanType = handlerMethod.getBeanType();\n\t\tAbstractExceptionHandlerMethodResolver resolver = this.exceptionHandlerCache.get(beanType);\n\t\tif (resolver == null) {\n\t\t\tresolver = this.exceptionMethodResolverFactory.apply(beanType);\n\t\t\tthis.exceptionHandlerCache.put(beanType, resolver);\n\t\t}\n\t\tInvocableHandlerMethod exceptionHandlerMethod = null;\n\t\tMethod method = resolver.resolveMethod(ex);\n\t\tif (method != null) {\n\t\t\texceptionHandlerMethod = new InvocableHandlerMethod(handlerMethod.getBean(), method);\n\t\t}\n\t\telse {\n\t\t\tfor (Map.Entry<MessagingAdviceBean, AbstractExceptionHandlerMethodResolver> entry : this.exceptionHandlerAdviceCache.entrySet()) {\n\t\t\t\tMessagingAdviceBean advice = entry.getKey();\n\t\t\t\tif (advice.isApplicableToBeanType(beanType)) {\n\t\t\t\t\tresolver = entry.getValue();\n\t\t\t\t\tmethod = resolver.resolveMethod(ex);\n\t\t\t\t\tif (method != null) {\n\t\t\t\t\t\texceptionHandlerMethod = new InvocableHandlerMethod(advice.resolveBean(), method);\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (exceptionHandlerMethod != null) {\n\t\t\tlogger.debug(\"Found exception handler \" + exceptionHandlerMethod.getShortLogMessage());\n\t\t\texceptionHandlerMethod.setArgumentResolvers(this.argumentResolvers.getResolvers());\n\t\t}\n\t\telse {\n\t\t\tlogger.error(\"No exception handling method\", ex);\n\t\t}\n\t\treturn exceptionHandlerMethod;\n\t}", "summary_tokens": ["find", "an", "exception", "handling", "method", "for", "the", "given", "exception"], "project": "spring-framework"}
{"id": 9731, "code": "\tpublic static MockHttpServletRequest initRequest(\n\t\t\tString method, @Nullable String contextPath, String path,\n\t\t\tboolean parsedPatterns, @Nullable Consumer<MockHttpServletRequest> postConstructInitializer) {\n\n\t\tMockHttpServletRequest request = createRequest(method, contextPath, path);\n\t\tif (postConstructInitializer != null) {\n\t\t\tpostConstructInitializer.accept(request);\n\t\t}\n\t\t\n\t\tif (parsedPatterns) {\n\t\t\tServletRequestPathUtils.parseAndCache(request);\n\t\t}\n\t\telse {\n\t\t\tUrlPathHelper.defaultInstance.resolveAndCacheLookupPath(request);\n\t\t}\n\t\treturn request;\n\t}", "summary_tokens": ["see", "init", "request", "string", "string", "boolean"], "project": "spring-framework"}
{"id": 5293, "code": "\tpublic void setDatabase(Database database) {\n\t\tthis.database = database;\n\t}", "summary_tokens": ["specify", "the", "target", "database", "to", "operate", "on", "as", "a", "value", "of", "the", "database", "enum", "db", "0", "derby", "h", "0", "hana", "hsql", "informix", "mysql", "oracle", "postgresql", "sql", "server", "sybase", "p", "b", "note", "b", "this", "setting", "will", "override", "your", "jpa", "provider", "s", "default", "algorithm"], "project": "spring-framework"}
{"id": 3103, "code": "\tpublic static void hasText(@Nullable String text) {\n\t\thasText(text,\n\t\t\t\t\"[Assertion failed] - this String argument must have text; it must not be null, empty, or blank\");\n\t}", "summary_tokens": ["assert", "that", "the", "given", "string", "contains", "valid", "text", "content", "that", "is", "it", "must", "not", "be", "null", "and", "must", "contain", "at", "least", "one", "non", "whitespace", "character"], "project": "spring-framework"}
{"id": 7361, "code": "\tpublic String getDescription() {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tsb.append(\"session=[\").append(this.sessionId).append(\"]; \");\n\t\tsb.append(\"user=[\").append(this.userName).append(\"]; \");\n\t\tsb.append(\"time=[\").append(this.processingTimeMillis).append(\"ms]; \");\n\t\tsb.append(\"status=[\");\n\t\tif (!wasFailure()) {\n\t\t\tsb.append(\"OK\");\n\t\t}\n\t\telse {\n\t\t\tsb.append(\"failed: \").append(this.failureCause);\n\t\t}\n\t\tsb.append(']');\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["return", "a", "full", "description", "of", "this", "event", "involving", "all", "available", "context", "data"], "project": "spring-framework"}
{"id": 2598, "code": "public static TypeReference newFormalParameterReference(final int paramIndex) {\n  return new TypeReference((METHOD_FORMAL_PARAMETER << 24) | (paramIndex << 16));\n}", "summary_tokens": ["returns", "a", "reference", "to", "the", "type", "of", "a", "formal", "parameter", "of", "a", "method"], "project": "spring-framework"}
{"id": 742, "code": "\tpublic boolean isInnerBean() {\n\t\treturn this.parent != null;\n\t}", "summary_tokens": ["return", "if", "this", "instance", "is", "for", "an", "inner", "bean"], "project": "spring-framework"}
{"id": 6597, "code": "\tpublic void testDynamicTargetSource() {\n\t\t\n\t\tCallCountingTransactionManager txMan = new CallCountingTransactionManager();\n\t\tPlatformTransactionManagerFacade.delegate = txMan;\n\n\t\tTestBean tb = (TestBean) factory.getBean(\"hotSwapped\");\n\t\tassertThat(tb.getAge()).isEqualTo(666);\n\t\tint newAge = 557;\n\t\ttb.setAge(newAge);\n\t\tassertThat(tb.getAge()).isEqualTo(newAge);\n\n\t\tTestBean target2 = new TestBean();\n\t\ttarget2.setAge(65);\n\t\tHotSwappableTargetSource ts = (HotSwappableTargetSource) factory.getBean(\"swapper\");\n\t\tts.swap(target2);\n\t\tassertThat(tb.getAge()).isEqualTo(target2.getAge());\n\t\ttb.setAge(newAge);\n\t\tassertThat(target2.getAge()).isEqualTo(newAge);\n\n\t\tassertThat(txMan.inflight).isEqualTo(0);\n\t\tassertThat(txMan.commits).isEqualTo(2);\n\t\tassertThat(txMan.rollbacks).isEqualTo(0);\n\t}", "summary_tokens": ["test", "that", "we", "can", "set", "the", "target", "to", "a", "dynamic", "target", "source"], "project": "spring-framework"}
{"id": 9097, "code": "\tpublic String getPath() {\n\t\treturn this.path;\n\t}", "summary_tokens": ["return", "the", "bean", "and", "property", "path", "for", "which", "values", "and", "errors", "will", "be", "resolved", "e"], "project": "spring-framework"}
{"id": 1597, "code": "\tprotected void populateMBeanDescriptor(Descriptor descriptor, Object managedBean, String beanKey) {\n\t\tapplyDefaultCurrencyTimeLimit(descriptor);\n\t}", "summary_tokens": ["allows", "subclasses", "to", "add", "extra", "fields", "to", "the", "descriptor", "for", "an", "mbean"], "project": "spring-framework"}
{"id": 5197, "code": "\tprotected Session openSession(SessionFactory sessionFactory) throws DataAccessResourceFailureException {\n\t\ttry {\n\t\t\tSession session = sessionFactory.openSession();\n\t\t\tsession.setHibernateFlushMode(FlushMode.MANUAL);\n\t\t\treturn session;\n\t\t}\n\t\tcatch (HibernateException ex) {\n\t\t\tthrow new DataAccessResourceFailureException(\"Could not open Hibernate Session\", ex);\n\t\t}\n\t}", "summary_tokens": ["open", "a", "session", "for", "the", "session", "factory", "that", "this", "filter", "uses"], "project": "spring-framework"}
{"id": 7509, "code": "\tpublic HttpStatusCode getRedirectStatus() {\n\t\treturn this.redirectStatus;\n\t}", "summary_tokens": ["return", "the", "configured", "redirect", "status"], "project": "spring-framework"}
{"id": 2226, "code": "\tpublic GeneratedMethods getMethods() {\n\t\treturn this.methods;\n\t}", "summary_tokens": ["return", "generated", "methods", "for", "this", "instance"], "project": "spring-framework"}
{"id": 8921, "code": "\tpublic RequestCondition<?> getCondition() {\n\t\treturn this.condition;\n\t}", "summary_tokens": ["return", "the", "held", "request", "condition", "or", "null", "if", "not", "holding", "one"], "project": "spring-framework"}
{"id": 1068, "code": "\tpublic JobDataMap getJobDataMap() {\n\t\treturn this.jobDataMap;\n\t}", "summary_tokens": ["return", "the", "job", "s", "job", "data", "map"], "project": "spring-framework"}
{"id": 5837, "code": "\tpublic static RequestMatcher queryParam(String name, String... expectedValues) {\n\t\treturn request -> {\n\t\t\tMultiValueMap<String, String> params = getQueryParams(request);\n\t\t\tassertValueCount(\"query param\", name, params, expectedValues.length);\n\t\t\tfor (int i = 0 ; i < expectedValues.length; i++) {\n\t\t\t\tassertEquals(\"Query param [\" + name + \"]\", expectedValues[i], params.get(name).get(i));\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["assert", "request", "query", "parameter", "values"], "project": "spring-framework"}
{"id": 7996, "code": "\tpublic ResourceChainRegistration addResolver(ResourceResolver resolver) {\n\t\tAssert.notNull(resolver, \"The provided ResourceResolver should not be null\");\n\t\tthis.resolvers.add(resolver);\n\t\tif (resolver instanceof VersionResourceResolver) {\n\t\t\tthis.hasVersionResolver = true;\n\t\t}\n\t\telse if (resolver instanceof PathResourceResolver) {\n\t\t\tthis.hasPathResolver = true;\n\t\t}\n\t\telse if (resolver instanceof WebJarsResourceResolver) {\n\t\t\tthis.hasWebjarsResolver = true;\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "resource", "resolver", "to", "the", "chain"], "project": "spring-framework"}
{"id": 19, "code": "\tprivate void maybeBindPrimitiveArgsFromPointcutExpression() {\n\t\tint numUnboundPrimitives = countNumberOfUnboundPrimitiveArguments();\n\t\tif (numUnboundPrimitives > 1) {\n\t\t\tthrow new AmbiguousBindingException(\"Found '\" + numUnboundPrimitives +\n\t\t\t\t\t\"' unbound primitive arguments with no way to distinguish between them.\");\n\t\t}\n\t\tif (numUnboundPrimitives == 1) {\n\t\t\t\n\t\t\tList<String> varNames = new ArrayList<>();\n\t\t\tString[] tokens = StringUtils.tokenizeToStringArray(this.pointcutExpression, \" \");\n\t\t\tfor (int i = 0; i < tokens.length; i++) {\n\t\t\t\tif (tokens[i].equals(\"args\") || tokens[i].startsWith(\"args(\")) {\n\t\t\t\t\tPointcutBody body = getPointcutBody(tokens, i);\n\t\t\t\t\ti += body.numTokensConsumed;\n\t\t\t\t\tmaybeExtractVariableNamesFromArgs(body.text, varNames);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (varNames.size() > 1) {\n\t\t\t\tthrow new AmbiguousBindingException(\"Found \" + varNames.size() +\n\t\t\t\t\t\t\" candidate variable names but only one candidate binding slot when matching primitive args\");\n\t\t\t}\n\t\t\telse if (varNames.size() == 1) {\n\t\t\t\t\n\t\t\t\tfor (int i = 0; i < this.argumentTypes.length; i++) {\n\t\t\t\t\tif (isUnbound(i) && this.argumentTypes[i].isPrimitive()) {\n\t\t\t\t\t\tbindParameterName(i, varNames.get(0));\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["match", "up", "args", "against", "unbound", "arguments", "of", "primitive", "types"], "project": "spring-framework"}
{"id": 3971, "code": "\tprotected synchronized void checkDefaultConnectionProperties(Connection con) throws SQLException {\n\t\tif (this.defaultAutoCommit == null) {\n\t\t\tthis.defaultAutoCommit = con.getAutoCommit();\n\t\t}\n\t\tif (this.defaultTransactionIsolation == null) {\n\t\t\tthis.defaultTransactionIsolation = con.getTransactionIsolation();\n\t\t}\n\t}", "summary_tokens": ["check", "the", "default", "connection", "properties", "auto", "commit", "transaction", "isolation", "keeping", "them", "to", "be", "able", "to", "expose", "them", "correctly", "without", "fetching", "an", "actual", "jdbc", "connection", "from", "the", "target", "data", "source"], "project": "spring-framework"}
{"id": 7559, "code": "\tprotected boolean isBinderMethodApplicable(HandlerMethod initBinderMethod, WebDataBinder dataBinder) {\n\t\tInitBinder ann = initBinderMethod.getMethodAnnotation(InitBinder.class);\n\t\tAssert.state(ann != null, \"No InitBinder annotation\");\n\t\tString[] names = ann.value();\n\t\treturn (ObjectUtils.isEmpty(names) || ObjectUtils.containsElement(names, dataBinder.getObjectName()));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "method", "should", "be", "used", "to", "initialize", "the", "given", "web", "data", "binder", "instance"], "project": "spring-framework"}
{"id": 6864, "code": "\tpublic void setMaxParts(int maxParts) {\n\t\tthis.maxParts = maxParts;\n\t}", "summary_tokens": ["specify", "the", "maximum", "number", "of", "parts", "allowed", "in", "a", "given", "multipart", "request"], "project": "spring-framework"}
{"id": 2163, "code": "\tpublic static Builder of(InstrumentedMethod instrumentedMethod) {\n\t\tAssert.notNull(instrumentedMethod, \"InstrumentedMethod must not be null\");\n\t\treturn new Builder(instrumentedMethod);\n\t}", "summary_tokens": ["initialize", "a", "builder", "for", "the", "given", "instrumented", "method"], "project": "spring-framework"}
{"id": 5005, "code": "\tpublic boolean isHeartbeatEnabled() {\n\t\tlong[] heartbeat = getHeartbeat();\n\t\treturn (heartbeat != null && heartbeat[0] != 0 && heartbeat[1] != 0);\n\t}", "summary_tokens": ["whether", "heartbeats", "are", "enabled"], "project": "spring-framework"}
{"id": 6152, "code": "\tvoid buildMergedConfigWithAtWebAppConfigurationWithAnnotationAndClassesOnSuperclass() {\n\t\tClass<?> webTestClass = WebClassesFoo.class;\n\t\tClass<?> standardTestClass = ClassesFoo.class;\n\t\tWebMergedContextConfiguration webMergedConfig = (WebMergedContextConfiguration) buildMergedContextConfiguration(webTestClass);\n\t\tMergedContextConfiguration standardMergedConfig = buildMergedContextConfiguration(standardTestClass);\n\n\t\tassertThat(webMergedConfig).isEqualTo(webMergedConfig);\n\t\tassertThat(standardMergedConfig).isEqualTo(standardMergedConfig);\n\t\tassertThat(webMergedConfig).isNotEqualTo(standardMergedConfig);\n\t\tassertThat(standardMergedConfig).isNotEqualTo(webMergedConfig);\n\n\t\tassertMergedConfig(webMergedConfig, webTestClass, EMPTY_STRING_ARRAY, array(FooConfig.class),\n\t\t\tWebDelegatingSmartContextLoader.class);\n\t\tassertMergedConfig(standardMergedConfig, standardTestClass, EMPTY_STRING_ARRAY,\n\t\t\tarray(FooConfig.class), DelegatingSmartContextLoader.class);\n\t}", "summary_tokens": ["introduced", "to", "investigate", "claims", "made", "in", "a", "discussion", "on", "a", "href", "https", "stackoverflow"], "project": "spring-framework"}
{"id": 7508, "code": "\tpublic void setRedirectStatus(HttpStatusCode status) {\n\t\tAssert.notNull(status, \"Property 'redirectStatus' is required\");\n\t\tAssert.isTrue(status.is3xxRedirection(), \"Not a redirect status code\");\n\t\tthis.redirectStatus = status;\n\t}", "summary_tokens": ["set", "the", "default", "http", "status", "to", "use", "for", "redirects"], "project": "spring-framework"}
{"id": 723, "code": "\tpublic void setValueTypeName(@Nullable String valueTypeName) {\n\t\tthis.valueTypeName = valueTypeName;\n\t}", "summary_tokens": ["set", "the", "default", "value", "type", "name", "class", "name", "to", "be", "used", "for", "this", "map"], "project": "spring-framework"}
{"id": 9722, "code": "\tpublic void setErrorListener(ErrorListener errorListener) {\n\t\tthis.errorListener = errorListener;\n\t}", "summary_tokens": ["set", "an", "implementation", "of", "the", "javax"], "project": "spring-framework"}
{"id": 4154, "code": "\tpublic SQLExceptionTranslator getExceptionTranslator() {\n\t\tSQLExceptionTranslator exceptionTranslator = this.exceptionTranslator;\n\t\tif (exceptionTranslator != null) {\n\t\t\treturn exceptionTranslator;\n\t\t}\n\t\tsynchronized (this) {\n\t\t\texceptionTranslator = this.exceptionTranslator;\n\t\t\tif (exceptionTranslator == null) {\n\t\t\t\tif (SQLErrorCodeSQLExceptionTranslator.hasUserProvidedErrorCodesFile()) {\n\t\t\t\t\texceptionTranslator = new SQLErrorCodeSQLExceptionTranslator(obtainDataSource());\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\texceptionTranslator = new SQLExceptionSubclassTranslator();\n\t\t\t\t}\n\t\t\t\tthis.exceptionTranslator = exceptionTranslator;\n\t\t\t}\n\t\t\treturn exceptionTranslator;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "exception", "translator", "for", "this", "instance"], "project": "spring-framework"}
{"id": 2947, "code": "\tpublic WritableByteChannel writableChannel() throws IOException {\n\t\treturn FileChannel.open(this.filePath, StandardOpenOption.WRITE);\n\t}", "summary_tokens": ["this", "implementation", "opens", "a", "file", "channel", "for", "the", "underlying", "file"], "project": "spring-framework"}
{"id": 8051, "code": "\tdefault Validator getValidator() {\n\t\treturn null;\n\t}", "summary_tokens": ["provide", "a", "custom", "validator"], "project": "spring-framework"}
{"id": 9577, "code": "\tpublic void setPropagateQueryParams(boolean propagateQueryParams) {\n\t\tthis.propagateQueryParams = propagateQueryParams;\n\t}", "summary_tokens": ["when", "set", "to", "true", "the", "query", "string", "of", "the", "current", "url", "is", "appended", "and", "thus", "propagated", "through", "to", "the", "redirected", "url"], "project": "spring-framework"}
{"id": 4054, "code": "\tpublic void setTrackRowsAffected(boolean trackRowsAffected) {\n\t\tthis.trackRowsAffected = trackRowsAffected;\n\t}", "summary_tokens": ["set", "whether", "to", "track", "the", "rows", "affected", "by", "batch", "updates", "performed", "by", "this", "operation", "object"], "project": "spring-framework"}
{"id": 2587, "code": "public String toString() {\n  return getDescriptor();\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "this", "type"], "project": "spring-framework"}
{"id": 958, "code": "\tpublic void setCacheSpecification(String cacheSpecification) {\n\t\tdoSetCaffeine(Caffeine.from(cacheSpecification));\n\t}", "summary_tokens": ["set", "the", "caffeine", "cache", "specification", "string", "to", "use", "for", "building", "each", "individual", "caffeine", "cache", "instance"], "project": "spring-framework"}
{"id": 7652, "code": "\tprotected MultipartResolver lookupMultipartResolver() {\n\t\tWebApplicationContext wac = WebApplicationContextUtils.getWebApplicationContext(getServletContext());\n\t\tString beanName = getMultipartResolverBeanName();\n\t\tif (wac != null && wac.containsBean(beanName)) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Using MultipartResolver '\" + beanName + \"' for MultipartFilter\");\n\t\t\t}\n\t\t\treturn wac.getBean(beanName, MultipartResolver.class);\n\t\t}\n\t\telse {\n\t\t\treturn this.defaultMultipartResolver;\n\t\t}\n\t}", "summary_tokens": ["look", "for", "a", "multipart", "resolver", "bean", "in", "the", "root", "web", "application", "context"], "project": "spring-framework"}
{"id": 9644, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["specify", "the", "order", "value", "for", "this", "view", "resolver", "bean"], "project": "spring-framework"}
{"id": 1179, "code": "\tpublic void setAllowNullValues(boolean allowNullValues) {\n\t\tif (allowNullValues != this.allowNullValues) {\n\t\t\tthis.allowNullValues = allowNullValues;\n\t\t\t\n\t\t\trecreateCaches();\n\t\t}\n\t}", "summary_tokens": ["specify", "whether", "to", "accept", "and", "convert", "null", "values", "for", "all", "caches", "in", "this", "cache", "manager"], "project": "spring-framework"}
{"id": 89, "code": "\tpublic boolean isOpaque() {\n\t\treturn this.opaque;\n\t}", "summary_tokens": ["return", "whether", "proxies", "created", "by", "this", "configuration", "should", "be", "prevented", "from", "being", "cast", "to", "advised"], "project": "spring-framework"}
{"id": 296, "code": "\tpublic void close() {\n\t\t\n\t\tthis.beanFactory.destroySingletons();\n\t}", "summary_tokens": ["we", "must", "simulate", "container", "shutdown", "which", "should", "clear", "threads"], "project": "spring-framework"}
{"id": 6902, "code": "\tprotected void initTypedReaders() {\n\t\tthis.typedReaders.clear();\n\t\tif (!this.registerDefaults) {\n\t\t\treturn;\n\t\t}\n\t\taddCodec(this.typedReaders, new DecoderHttpMessageReader<>(new ByteArrayDecoder()));\n\t\taddCodec(this.typedReaders, new DecoderHttpMessageReader<>(new ByteBufferDecoder()));\n\t\taddCodec(this.typedReaders, new DecoderHttpMessageReader<>(new DataBufferDecoder()));\n\t\tif (nettyByteBufPresent) {\n\t\t\taddCodec(this.typedReaders, new DecoderHttpMessageReader<>(new NettyByteBufDecoder()));\n\t\t}\n\t\tif (netty5BufferPresent) {\n\t\t\taddCodec(this.typedReaders, new DecoderHttpMessageReader<>(new Netty5BufferDecoder()));\n\t\t}\n\t\taddCodec(this.typedReaders, new ResourceHttpMessageReader(new ResourceDecoder()));\n\t\taddCodec(this.typedReaders, new DecoderHttpMessageReader<>(StringDecoder.textPlainOnly()));\n\t\tif (protobufPresent) {\n\t\t\taddCodec(this.typedReaders, new DecoderHttpMessageReader<>(this.protobufDecoder != null ?\n\t\t\t\t\t(ProtobufDecoder) this.protobufDecoder : new ProtobufDecoder()));\n\t\t}\n\t\taddCodec(this.typedReaders, new FormHttpMessageReader());\n\n\t\t\n\t\textendTypedReaders(this.typedReaders);\n\t}", "summary_tokens": ["reset", "and", "initialize", "typed", "readers"], "project": "spring-framework"}
{"id": 5445, "code": "\tpublic static BaseBuilder<?> get(String urlTemplate, Object... uriVars) {\n\t\treturn method(HttpMethod.GET, urlTemplate, uriVars);\n\t}", "summary_tokens": ["create", "an", "http", "get", "builder", "with", "the", "given", "uri", "template"], "project": "spring-framework"}
{"id": 5875, "code": "\tpublic void consumeWith(Consumer<FluxExchangeResult<T>> consumer) {\n\t\tassertWithDiagnostics(() -> consumer.accept(this));\n\t}", "summary_tokens": ["invoke", "the", "given", "consumer", "within", "assert", "with", "diagnostics", "runnable", "passing", "this", "instance", "to", "it"], "project": "spring-framework"}
{"id": 5649, "code": "\tprotected void prepareContext(ConfigurableApplicationContext context, MergedContextConfiguration mergedConfig) {\n\t\tcontext.getEnvironment().setActiveProfiles(mergedConfig.getActiveProfiles());\n\t\tTestPropertySourceUtils.addPropertiesFilesToEnvironment(context, mergedConfig.getPropertySourceLocations());\n\t\tTestPropertySourceUtils.addInlinedPropertiesToEnvironment(context, mergedConfig.getPropertySourceProperties());\n\t\tinvokeApplicationContextInitializers(context, mergedConfig);\n\t}", "summary_tokens": ["prepare", "the", "configurable", "application", "context", "created", "by", "this", "smart", "context", "loader", "i", "before", "i", "bean", "definitions", "are", "read"], "project": "spring-framework"}
{"id": 8718, "code": "\tdefault void configureAsyncSupport(AsyncSupportConfigurer configurer) {\n\t}", "summary_tokens": ["configure", "asynchronous", "request", "handling", "options"], "project": "spring-framework"}
{"id": 5008, "code": "\tpublic void setServer(@Nullable String server) {\n\t\tset(SERVER, server);\n\t}", "summary_tokens": ["set", "the", "server", "header"], "project": "spring-framework"}
{"id": 2679, "code": "\tprivate static boolean isBridgedCandidateFor(Method candidateMethod, Method bridgeMethod) {\n\t\treturn (!candidateMethod.isBridge() &&\n\t\t\t\tcandidateMethod.getName().equals(bridgeMethod.getName()) &&\n\t\t\t\tcandidateMethod.getParameterCount() == bridgeMethod.getParameterCount());\n\t}", "summary_tokens": ["returns", "true", "if", "the", "supplied", "candidate", "method", "can", "be", "considered", "a", "valid", "candidate", "for", "the", "method", "that", "is", "method", "is", "bridge", "bridged", "by", "the", "supplied", "method", "bridge", "method"], "project": "spring-framework"}
{"id": 6926, "code": "\tpublic void setMarshallerProcessor(Function<Marshaller, Marshaller> processor) {\n\t\tthis.marshallerProcessor = this.marshallerProcessor.andThen(processor);\n\t}", "summary_tokens": ["configure", "a", "processor", "function", "to", "customize", "marshaller", "instances"], "project": "spring-framework"}
{"id": 7099, "code": "\tpublic final ProblemDetail getBody() {\n\t\treturn this.body;\n\t}", "summary_tokens": ["return", "the", "body", "for", "the", "response"], "project": "spring-framework"}
{"id": 2858, "code": "\tprotected void validateProfile(String profile) {\n\t\tif (!StringUtils.hasText(profile)) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid profile [\" + profile + \"]: must contain text\");\n\t\t}\n\t\tif (profile.charAt(0) == '!') {\n\t\t\tthrow new IllegalArgumentException(\"Invalid profile [\" + profile + \"]: must not begin with ! operator\");\n\t\t}\n\t}", "summary_tokens": ["validate", "the", "given", "profile", "called", "internally", "prior", "to", "adding", "to", "the", "set", "of", "active", "or", "default", "profiles"], "project": "spring-framework"}
{"id": 2564, "code": "int addMergedType(final int typeTableIndex1, final int typeTableIndex2) {\n  long data =\n      typeTableIndex1 < typeTableIndex2\n          ? typeTableIndex1 | (((long) typeTableIndex2) << 32)\n          : typeTableIndex2 | (((long) typeTableIndex1) << 32);\n  int hashCode = hash(Symbol.MERGED_TYPE_TAG, typeTableIndex1 + typeTableIndex2);\n  Entry entry = get(hashCode);\n  while (entry != null) {\n    if (entry.tag == Symbol.MERGED_TYPE_TAG && entry.hashCode == hashCode && entry.data == data) {\n      return entry.info;\n    }\n    entry = entry.next;\n  }\n  String type1 = typeTable[typeTableIndex1].value;\n  String type2 = typeTable[typeTableIndex2].value;\n  int commonSuperTypeIndex = addType(classWriter.getCommonSuperClass(type1, type2));\n  put(new Entry(typeCount, Symbol.MERGED_TYPE_TAG, data, hashCode)).info = commonSuperTypeIndex;\n  return commonSuperTypeIndex;\n}", "summary_tokens": ["adds", "a", "merged", "type", "in", "the", "type", "table", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 113, "code": "\tstatic void reset() {\n\t\tinstance = new DefaultAdvisorAdapterRegistry();\n\t}", "summary_tokens": ["reset", "the", "singleton", "default", "advisor", "adapter", "registry", "removing", "any", "advisor", "adapter", "registry", "register", "advisor", "adapter", "advisor", "adapter", "registered", "adapters"], "project": "spring-framework"}
{"id": 9637, "code": "\tprotected AbstractUrlBasedView instantiateView() {\n\t\tClass<?> viewClass = getViewClass();\n\t\tAssert.state(viewClass != null, \"No view class\");\n\t\treturn (AbstractUrlBasedView) BeanUtils.instantiateClass(viewClass);\n\t}", "summary_tokens": ["instantiate", "the", "specified", "view", "class"], "project": "spring-framework"}
{"id": 618, "code": "\tdefault boolean isRequired(DependencyDescriptor descriptor) {\n\t\treturn descriptor.isRequired();\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "descriptor", "is", "effectively", "required"], "project": "spring-framework"}
{"id": 6000, "code": "\tpublic ResultMatcher hasJsonPath() {\n\t\treturn result -> this.jsonPathHelper.hasJsonPath(getContent(result));\n\t}", "summary_tokens": ["evaluate", "the", "json", "path", "expression", "against", "the", "response", "content", "and", "assert", "that", "a", "value", "possibly", "null", "exists"], "project": "spring-framework"}
{"id": 9141, "code": "\tpublic String getMessage(MessageSourceResolvable resolvable, boolean htmlEscape) throws NoSuchMessageException {\n\t\tString msg = this.webApplicationContext.getMessage(resolvable, getLocale());\n\t\treturn (htmlEscape ? HtmlUtils.htmlEscape(msg) : msg);\n\t}", "summary_tokens": ["retrieve", "the", "given", "message", "source", "resolvable", "e"], "project": "spring-framework"}
{"id": 2472, "code": "public AnnotationVisitor visitParameterAnnotation(\n    final int parameter, final String descriptor, final boolean visible) {\n  if (mv != null) {\n    return mv.visitParameterAnnotation(parameter, descriptor, visible);\n  }\n  return null;\n}", "summary_tokens": ["visits", "an", "annotation", "of", "a", "parameter", "this", "method"], "project": "spring-framework"}
{"id": 3821, "code": "\tpublic String toString() {\n\t\treturn this.originalSql;\n\t}", "summary_tokens": ["exposes", "the", "original", "sql", "string"], "project": "spring-framework"}
{"id": 2975, "code": "\tpublic long lastModified() throws IOException {\n\t\t\n\t\t\n\t\treturn Files.getLastModifiedTime(this.path).toMillis();\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "underlying", "file", "s", "timestamp"], "project": "spring-framework"}
{"id": 3298, "code": "\tpublic static OutputStream nonClosing(OutputStream out) {\n\t\tAssert.notNull(out, \"No OutputStream specified\");\n\t\treturn new NonClosingOutputStream(out);\n\t}", "summary_tokens": ["return", "a", "variant", "of", "the", "given", "output", "stream", "where", "calling", "output", "stream", "close", "close", "has", "no", "effect"], "project": "spring-framework"}
{"id": 6949, "code": "\tpublic Jackson2ObjectMapperBuilder factory(JsonFactory factory) {\n\t\tthis.factory = factory;\n\t\treturn this;\n\t}", "summary_tokens": ["define", "the", "json", "factory", "to", "be", "used", "to", "create", "the", "object", "mapper", "instance"], "project": "spring-framework"}
{"id": 7197, "code": "\tpublic void setAutoGrowNestedPaths(boolean autoGrowNestedPaths) {\n\t\tthis.autoGrowNestedPaths = autoGrowNestedPaths;\n\t}", "summary_tokens": ["set", "whether", "a", "binder", "should", "attempt", "to", "auto", "grow", "a", "nested", "path", "that", "contains", "a", "null", "value"], "project": "spring-framework"}
{"id": 3530, "code": "\tpublic static void insertNewArrayCode(MethodVisitor mv, int size, String arraytype) {\n\t\tinsertOptimalLoad(mv, size);\n\t\tif (arraytype.length() == 1) {\n\t\t\tmv.visitIntInsn(NEWARRAY, CodeFlow.arrayCodeFor(arraytype));\n\t\t}\n\t\telse {\n\t\t\tif (arraytype.charAt(0) == '[') {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tif (CodeFlow.isReferenceTypeArray(arraytype)) {\n\t\t\t\t\tmv.visitTypeInsn(ANEWARRAY, arraytype + \";\");\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tmv.visitTypeInsn(ANEWARRAY, arraytype);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tmv.visitTypeInsn(ANEWARRAY, arraytype.substring(1));\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["produce", "the", "correct", "bytecode", "to", "build", "an", "array"], "project": "spring-framework"}
{"id": 2063, "code": "\tpublic void setValidatorProvider(ObjectProvider<Validator> validatorProvider) {\n\t\tthis.validator = validatorProvider::getObject;\n\t}", "summary_tokens": ["set", "a", "lazily", "initialized", "validator", "to", "delegate", "to", "for", "validating", "methods"], "project": "spring-framework"}
{"id": 5070, "code": "\tpublic void setDisableIdGeneration() {\n\t\tthis.idGenerator = ID_VALUE_NONE_GENERATOR;\n\t}", "summary_tokens": ["a", "shortcut", "for", "calling", "set", "id", "generator", "with", "an", "id", "generation", "strategy", "to", "disable", "id", "generation", "completely"], "project": "spring-framework"}
{"id": 1182, "code": "\tpublic boolean isStoreByValue() {\n\t\treturn this.storeByValue;\n\t}", "summary_tokens": ["return", "whether", "this", "cache", "manager", "stores", "a", "copy", "of", "each", "entry", "or", "a", "reference", "for", "all", "its", "caches"], "project": "spring-framework"}
{"id": 3998, "code": "\tpublic void setSchema(String schema) {\n\t\tthis.schema = schema;\n\t}", "summary_tokens": ["specify", "a", "database", "schema", "to", "be", "applied", "to", "each", "retrieved", "connection"], "project": "spring-framework"}
{"id": 4242, "code": "\tpublic Collection<MessageListenerContainer> getListenerContainers() {\n\t\treturn Collections.unmodifiableCollection(this.listenerContainers.values());\n\t}", "summary_tokens": ["return", "the", "managed", "message", "listener", "container", "instance", "s"], "project": "spring-framework"}
{"id": 3251, "code": "\tpublic static byte[] generateMultipartBoundary() {\n\t\tRandom randomToUse = initRandom();\n\t\tbyte[] boundary = new byte[randomToUse.nextInt(11) + 30];\n\t\tfor (int i = 0; i < boundary.length; i++) {\n\t\t\tboundary[i] = BOUNDARY_CHARS[randomToUse.nextInt(BOUNDARY_CHARS.length)];\n\t\t}\n\t\treturn boundary;\n\t}", "summary_tokens": ["generate", "a", "random", "mime", "boundary", "as", "bytes", "often", "used", "in", "multipart", "mime", "types"], "project": "spring-framework"}
{"id": 4794, "code": "\tdefault Builder mutate() {\n\t\treturn new DefaultRSocketStrategies.DefaultRSocketStrategiesBuilder(this);\n\t}", "summary_tokens": ["return", "a", "builder", "to", "create", "a", "new", "rsocket", "strategies", "instance", "replicated", "from", "the", "current", "instance"], "project": "spring-framework"}
{"id": 7401, "code": "\tpublic void setAllowedOrigins(@Nullable List<String> origins) {\n\t\tthis.allowedOrigins = (origins == null ? null :\n\t\t\t\torigins.stream().filter(Objects::nonNull).map(this::trimTrailingSlash).collect(Collectors.toList()));\n\t}", "summary_tokens": ["a", "list", "of", "origins", "for", "which", "cross", "origin", "requests", "are", "allowed"], "project": "spring-framework"}
{"id": 2180, "code": "\tpublic RuntimeHintsInvocationsAssert hasCount(long count) {\n\t\tisNotNull();\n\t\tlong invocationsCount = this.actual.recordedInvocations().count();\n\t\tif(invocationsCount != count) {\n\t\t\tthrowAssertionError(new BasicErrorMessageFactory(\"%nNumber of recorded invocations does not match, expected <%n> but got <%n>.\",\n\t\t\t\t\tinvocationsCount, count));\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["verifies", "that", "the", "count", "of", "recorded", "invocations", "match", "the", "expected", "one"], "project": "spring-framework"}
{"id": 6345, "code": "\tprivate GenericReactiveTransaction newReactiveTransaction(\n\t\t\tTransactionSynchronizationManager synchronizationManager, TransactionDefinition definition,\n\t\t\t@Nullable Object transaction, boolean newTransaction, boolean debug, @Nullable Object suspendedResources) {\n\n\t\treturn new GenericReactiveTransaction(transaction, newTransaction,\n\t\t\t\t!synchronizationManager.isSynchronizationActive(),\n\t\t\t\tdefinition.isReadOnly(), debug, suspendedResources);\n\t}", "summary_tokens": ["create", "a", "reactive", "transaction", "instance", "for", "the", "given", "arguments"], "project": "spring-framework"}
{"id": 9414, "code": "\tpublic void setAutocomplete(String autocomplete) {\n\t\tthis.autocomplete = autocomplete;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "autocomplete", "attribute"], "project": "spring-framework"}
{"id": 176, "code": "\tprotected Class<?> getClassForLogging(Object target) {\n\t\treturn (this.hideProxyClassNames ? AopUtils.getTargetClass(target) : target.getClass());\n\t}", "summary_tokens": ["determine", "the", "class", "to", "use", "for", "logging", "purposes"], "project": "spring-framework"}
{"id": 4938, "code": "\tpublic void setRelayHost(String relayHost) {\n\t\tAssert.hasText(relayHost, \"relayHost must not be empty\");\n\t\tthis.relayHost = relayHost;\n\t}", "summary_tokens": ["set", "the", "stomp", "message", "broker", "host"], "project": "spring-framework"}
{"id": 7329, "code": "\tpublic static AsyncWebRequest createAsyncWebRequest(HttpServletRequest request, HttpServletResponse response) {\n\t\treturn new StandardServletAsyncWebRequest(request, response);\n\t}", "summary_tokens": ["create", "an", "async", "web", "request", "instance"], "project": "spring-framework"}
{"id": 5169, "code": "\tpublic MetadataSources getMetadataSources() {\n\t\tthis.metadataSourcesAccessed = true;\n\t\tif (this.metadataSources == null) {\n\t\t\tBootstrapServiceRegistryBuilder builder = new BootstrapServiceRegistryBuilder();\n\t\t\tif (this.resourcePatternResolver != null) {\n\t\t\t\tbuilder = builder.applyClassLoader(this.resourcePatternResolver.getClassLoader());\n\t\t\t}\n\t\t\tif (this.hibernateIntegrators != null) {\n\t\t\t\tfor (Integrator integrator : this.hibernateIntegrators) {\n\t\t\t\t\tbuilder = builder.applyIntegrator(integrator);\n\t\t\t\t}\n\t\t\t}\n\t\t\tthis.metadataSources = new MetadataSources(builder.build());\n\t\t}\n\t\treturn this.metadataSources;\n\t}", "summary_tokens": ["determine", "the", "hibernate", "metadata", "sources", "to", "use"], "project": "spring-framework"}
{"id": 5181, "code": "\tpublic LocalSessionFactoryBuilder addAnnotatedClasses(Class<?>... annotatedClasses) {\n\t\tfor (Class<?> annotatedClass : annotatedClasses) {\n\t\t\taddAnnotatedClass(annotatedClass);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "the", "given", "annotated", "classes", "in", "a", "batch"], "project": "spring-framework"}
{"id": 2837, "code": "\tpublic Object getValue() {\n\t\treturn this.value;\n\t}", "summary_tokens": ["return", "the", "offending", "value"], "project": "spring-framework"}
{"id": 4142, "code": "\tpublic void afterPropertiesSet() {\n\t\tif (this.dataSource == null) {\n\t\t\tthrow new IllegalArgumentException(\"Property 'dataSource' is required\");\n\t\t}\n\n\t\ttry {\n\t\t\tboolean validated = false;\n\t\t\tlong beginTime = System.currentTimeMillis();\n\t\t\tlong deadLine = beginTime + TimeUnit.SECONDS.toMillis(this.timeout);\n\t\t\tSQLException latestEx = null;\n\n\t\t\twhile (!validated && System.currentTimeMillis() < deadLine) {\n\t\t\t\tConnection con = null;\n\t\t\t\tStatement stmt = null;\n\t\t\t\ttry {\n\t\t\t\t\tcon = this.dataSource.getConnection();\n\t\t\t\t\tif (con == null) {\n\t\t\t\t\t\tthrow new CannotGetJdbcConnectionException(\"Failed to execute validation: \" +\n\t\t\t\t\t\t\t\t\"DataSource returned null from getConnection(): \" + this.dataSource);\n\t\t\t\t\t}\n\t\t\t\t\tif (this.validationQuery == null) {\n\t\t\t\t\t\tvalidated = con.isValid(this.interval);\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tstmt = con.createStatement();\n\t\t\t\t\t\tstmt.execute(this.validationQuery);\n\t\t\t\t\t\tvalidated = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcatch (SQLException ex) {\n\t\t\t\t\tlatestEx = ex;\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tif (this.validationQuery != null) {\n\t\t\t\t\t\t\tlogger.debug(\"Validation query [\" + this.validationQuery + \"] threw exception\", ex);\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tlogger.debug(\"Validation check threw exception\", ex);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\t\t\tfloat rest = ((float) (deadLine - System.currentTimeMillis())) / 1000;\n\t\t\t\t\t\tif (rest > this.interval) {\n\t\t\t\t\t\t\tlogger.info(\"Database has not started up yet - retrying in \" + this.interval +\n\t\t\t\t\t\t\t\t\t\" seconds (timeout in \" + rest + \" seconds)\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tJdbcUtils.closeStatement(stmt);\n\t\t\t\t\tJdbcUtils.closeConnection(con);\n\t\t\t\t}\n\n\t\t\t\tif (!validated) {\n\t\t\t\t\tTimeUnit.SECONDS.sleep(this.interval);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!validated) {\n\t\t\t\tthrow new CannotGetJdbcConnectionException(\n\t\t\t\t\t\t\"Database has not started up within \" + this.timeout + \" seconds\", latestEx);\n\t\t\t}\n\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tfloat duration = ((float) (System.currentTimeMillis() - beginTime)) / 1000;\n\t\t\t\tlogger.info(\"Database startup detected after \" + duration + \" seconds\");\n\t\t\t}\n\t\t}\n\t\tcatch (InterruptedException ex) {\n\t\t\t\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}", "summary_tokens": ["check", "whether", "the", "validation", "query", "can", "be", "executed", "on", "a", "connection", "from", "the", "specified", "data", "source", "with", "the", "specified", "interval", "between", "checks", "until", "the", "specified", "timeout"], "project": "spring-framework"}
{"id": 6562, "code": "\tpublic static boolean sameResourceFactory(ResourceTransactionManager tm, Object resourceFactory) {\n\t\treturn unwrapResourceIfNecessary(tm.getResourceFactory()).equals(unwrapResourceIfNecessary(resourceFactory));\n\t}", "summary_tokens": ["check", "whether", "the", "given", "resource", "transaction", "manager", "refers", "to", "the", "given", "underlying", "resource", "factory"], "project": "spring-framework"}
{"id": 9864, "code": "\tpublic void setPhase(int phase) {\n\t\tthis.phase = phase;\n\t}", "summary_tokens": ["specify", "the", "phase", "in", "which", "the", "web", "socket", "client", "should", "be", "started", "and", "subsequently", "closed"], "project": "spring-framework"}
{"id": 6409, "code": "\tpublic String getCurrentTransactionName() {\n\t\treturn this.transactionContext.getCurrentTransactionName();\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "current", "transaction", "or", "null", "if", "none", "set"], "project": "spring-framework"}
{"id": 9044, "code": "\tprotected ModelAndView handleMissingServletRequestParameter(MissingServletRequestParameterException ex,\n\t\t\tHttpServletRequest request, HttpServletResponse response, @Nullable Object handler) throws IOException {\n\n\t\treturn null;\n\t}", "summary_tokens": ["handle", "the", "case", "when", "a", "required", "parameter", "is", "missing"], "project": "spring-framework"}
{"id": 7072, "code": "\tprotected String initLogPrefix() {\n\t\treturn getId();\n\t}", "summary_tokens": ["subclasses", "can", "override", "this", "to", "provide", "the", "prefix", "to", "use", "for", "log", "messages"], "project": "spring-framework"}
{"id": 8149, "code": "\tpublic static HttpHandler toHttpHandler(RouterFunction<?> routerFunction, HandlerStrategies strategies) {\n\t\tWebHandler webHandler = toWebHandler(routerFunction, strategies);\n\t\treturn WebHttpHandlerBuilder.webHandler(webHandler)\n\t\t\t\t.filters(filters -> filters.addAll(strategies.webFilters()))\n\t\t\t\t.exceptionHandlers(handlers -> handlers.addAll(strategies.exceptionHandlers()))\n\t\t\t\t.localeContextResolver(strategies.localeContextResolver())\n\t\t\t\t.build();\n\t}", "summary_tokens": ["convert", "the", "given", "router", "function", "router", "function", "into", "a", "http", "handler", "using", "the", "given", "strategies"], "project": "spring-framework"}
{"id": 6924, "code": "\tQName toQName(Class<?> outputClass) {\n\t\tString localPart;\n\t\tString namespaceUri;\n\n\t\tif (outputClass.isAnnotationPresent(XmlRootElement.class)) {\n\t\t\tXmlRootElement annotation = outputClass.getAnnotation(XmlRootElement.class);\n\t\t\tlocalPart = annotation.name();\n\t\t\tnamespaceUri = annotation.namespace();\n\t\t}\n\t\telse if (outputClass.isAnnotationPresent(XmlType.class)) {\n\t\t\tXmlType annotation = outputClass.getAnnotation(XmlType.class);\n\t\t\tlocalPart = annotation.name();\n\t\t\tnamespaceUri = annotation.namespace();\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"Output class [\" + outputClass.getName() +\n\t\t\t\t\t\"] is neither annotated with @XmlRootElement nor @XmlType\");\n\t\t}\n\n\t\tif (JAXB_DEFAULT_ANNOTATION_VALUE.equals(localPart)) {\n\t\t\tlocalPart = ClassUtils.getShortNameAsProperty(outputClass);\n\t\t}\n\t\tif (JAXB_DEFAULT_ANNOTATION_VALUE.equals(namespaceUri)) {\n\t\t\tPackage outputClassPackage = outputClass.getPackage();\n\t\t\tif (outputClassPackage != null && outputClassPackage.isAnnotationPresent(XmlSchema.class)) {\n\t\t\t\tXmlSchema annotation = outputClassPackage.getAnnotation(XmlSchema.class);\n\t\t\t\tnamespaceUri = annotation.namespace();\n\t\t\t}\n\t\t\telse {\n\t\t\t\tnamespaceUri = XMLConstants.NULL_NS_URI;\n\t\t\t}\n\t\t}\n\t\treturn new QName(namespaceUri, localPart);\n\t}", "summary_tokens": ["returns", "the", "qualified", "name", "for", "the", "given", "class", "according", "to", "the", "mapping", "rules", "in", "the", "jaxb", "specification"], "project": "spring-framework"}
{"id": 1308, "code": "\tpublic ScopedProxyMode getScopedProxyMode() {\n\t\treturn this.scopedProxyMode;\n\t}", "summary_tokens": ["get", "the", "proxy", "mode", "to", "be", "applied", "to", "the", "scoped", "instance"], "project": "spring-framework"}
{"id": 5418, "code": "\tdefault StatementFilterFunction andThen(StatementFilterFunction afterFilter) {\n\t\tAssert.notNull(afterFilter, \"StatementFilterFunction must not be null\");\n\t\treturn (request, next) -> filter(request, afterRequest -> afterFilter.filter(afterRequest, next));\n\t}", "summary_tokens": ["return", "a", "composed", "filter", "function", "that", "first", "applies", "this", "filter", "and", "then", "applies", "the", "given", "after", "filter"], "project": "spring-framework"}
{"id": 4422, "code": "\tpublic boolean isAcceptMessagesWhileStopping() {\n\t\treturn this.acceptMessagesWhileStopping;\n\t}", "summary_tokens": ["return", "whether", "to", "accept", "received", "messages", "while", "the", "listener", "container", "in", "the", "process", "of", "stopping"], "project": "spring-framework"}
{"id": 2956, "code": "\tpublic boolean exists() {\n\t\treturn true;\n\t}", "summary_tokens": ["this", "implementation", "always", "returns", "true"], "project": "spring-framework"}
{"id": 6383, "code": "\tprotected Mono<Void> cleanupResource(O resourceHolder, K resourceKey, boolean committed) {\n\t\treturn Mono.empty();\n\t}", "summary_tokens": ["perform", "a", "cleanup", "on", "the", "given", "resource", "which", "is", "left", "bound", "to", "the", "thread"], "project": "spring-framework"}
{"id": 3018, "code": "\tpublic long getCount() {\n\t\treturn this.count;\n\t}", "summary_tokens": ["return", "the", "byte", "count", "of", "this", "region", "in", "the", "underlying", "resource"], "project": "spring-framework"}
{"id": 6042, "code": "\tpublic ResultMatcher sessionAttribute(String name, @Nullable Object value) {\n\t\treturn result -> {\n\t\t\tHttpSession session = result.getRequest().getSession();\n\t\t\tAssert.state(session != null, \"No HttpSession\");\n\t\t\tassertEquals(\"Session attribute '\" + name + \"'\", value, session.getAttribute(name));\n\t\t};\n\t}", "summary_tokens": ["assert", "a", "session", "attribute", "value"], "project": "spring-framework"}
{"id": 8532, "code": "\tpublic final void init() throws ServletException {\n\n\t\t\n\t\tPropertyValues pvs = new ServletConfigPropertyValues(getServletConfig(), this.requiredProperties);\n\t\tif (!pvs.isEmpty()) {\n\t\t\ttry {\n\t\t\t\tBeanWrapper bw = PropertyAccessorFactory.forBeanPropertyAccess(this);\n\t\t\t\tResourceLoader resourceLoader = new ServletContextResourceLoader(getServletContext());\n\t\t\t\tbw.registerCustomEditor(Resource.class, new ResourceEditor(resourceLoader, getEnvironment()));\n\t\t\t\tinitBeanWrapper(bw);\n\t\t\t\tbw.setPropertyValues(pvs, true);\n\t\t\t}\n\t\t\tcatch (BeansException ex) {\n\t\t\t\tif (logger.isErrorEnabled()) {\n\t\t\t\t\tlogger.error(\"Failed to set bean properties on servlet '\" + getServletName() + \"'\", ex);\n\t\t\t\t}\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tinitServletBean();\n\t}", "summary_tokens": ["map", "config", "parameters", "onto", "bean", "properties", "of", "this", "servlet", "and", "invoke", "subclass", "initialization"], "project": "spring-framework"}
{"id": 6386, "code": "\tboolean hasContext() {\n\t\treturn !this.transactionStack.isEmpty();\n\t}", "summary_tokens": ["check", "whether", "the", "holder", "has", "a", "transaction", "context"], "project": "spring-framework"}
{"id": 2755, "code": "\tdefault ClassLoader getOriginalClassLoader() {\n\t\treturn (ClassLoader) this;\n\t}", "summary_tokens": ["return", "the", "original", "class", "loader", "for", "this", "smart", "class", "loader", "or", "potentially", "the", "present", "loader", "itself", "if", "it", "is", "self", "sufficient"], "project": "spring-framework"}
{"id": 3623, "code": "\tpublic void parseCheck(String expression, String expectedStringFormOfAST) {\n\t\tSpelExpression e = parser.parseRaw(expression);\n\t\tassertThat(e).isNotNull();\n\t\tassertThat(e.toStringAST()).isEqualTo(expectedStringFormOfAST);\n\t}", "summary_tokens": ["parse", "the", "supplied", "expression", "and", "then", "create", "a", "string", "representation", "of", "the", "resultant", "ast", "it", "should", "be", "the", "expected", "value"], "project": "spring-framework"}
{"id": 1009, "code": "\tpublic void setTargetCacheManager(CacheManager targetCacheManager) {\n\t\tthis.targetCacheManager = targetCacheManager;\n\t}", "summary_tokens": ["set", "the", "target", "cache", "manager", "to", "proxy"], "project": "spring-framework"}
{"id": 4537, "code": "\tpublic MessageListener getMessageListener() {\n\t\treturn this.endpointFactory.getMessageListener();\n\t}", "summary_tokens": ["return", "the", "jms", "message", "listener", "for", "this", "endpoint"], "project": "spring-framework"}
{"id": 3320, "code": "\tpublic static String capitalize(String str) {\n\t\treturn changeFirstCharacterCase(str, true);\n\t}", "summary_tokens": ["capitalize", "a", "string", "changing", "the", "first", "letter", "to", "upper", "case", "as", "per", "character", "to", "upper", "case", "char"], "project": "spring-framework"}
{"id": 3508, "code": "\tpublic static void insertUnboxNumberInsns(\n\t\t\tMethodVisitor mv, char targetDescriptor, @Nullable String stackDescriptor) {\n\n\t\tif (stackDescriptor == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tswitch (targetDescriptor) {\n\t\t\tcase 'D':\n\t\t\t\tif (stackDescriptor.equals(\"Ljava/lang/Object\")) {\n\t\t\t\t\tmv.visitTypeInsn(CHECKCAST, \"java/lang/Number\");\n\t\t\t\t}\n\t\t\t\tmv.visitMethodInsn(INVOKEVIRTUAL, \"java/lang/Number\", \"doubleValue\", \"()D\", false);\n\t\t\t\tbreak;\n\t\t\tcase 'F':\n\t\t\t\tif (stackDescriptor.equals(\"Ljava/lang/Object\")) {\n\t\t\t\t\tmv.visitTypeInsn(CHECKCAST, \"java/lang/Number\");\n\t\t\t\t}\n\t\t\t\tmv.visitMethodInsn(INVOKEVIRTUAL, \"java/lang/Number\", \"floatValue\", \"()F\", false);\n\t\t\t\tbreak;\n\t\t\tcase 'J':\n\t\t\t\tif (stackDescriptor.equals(\"Ljava/lang/Object\")) {\n\t\t\t\t\tmv.visitTypeInsn(CHECKCAST, \"java/lang/Number\");\n\t\t\t\t}\n\t\t\t\tmv.visitMethodInsn(INVOKEVIRTUAL, \"java/lang/Number\", \"longValue\", \"()J\", false);\n\t\t\t\tbreak;\n\t\t\tcase 'I':\n\t\t\t\tif (stackDescriptor.equals(\"Ljava/lang/Object\")) {\n\t\t\t\t\tmv.visitTypeInsn(CHECKCAST, \"java/lang/Number\");\n\t\t\t\t}\n\t\t\t\tmv.visitMethodInsn(INVOKEVIRTUAL, \"java/lang/Number\", \"intValue\", \"()I\", false);\n\t\t\t\tbreak;\n\t\t\t\n\t\t\tdefault:\n\t\t\t\tthrow new IllegalArgumentException(\"Unboxing should not be attempted for descriptor '\" + targetDescriptor + \"'\");\n\t\t}\n\t}", "summary_tokens": ["for", "numbers", "use", "the", "appropriate", "method", "on", "the", "number", "to", "convert", "it", "to", "the", "primitive", "type", "requested"], "project": "spring-framework"}
{"id": 5967, "code": "\tpublic ResultMatcher xml(String xmlContent) {\n\t\treturn result -> {\n\t\t\tString content = result.getResponse().getContentAsString();\n\t\t\tthis.xmlHelper.assertXmlEqual(xmlContent, content);\n\t\t};\n\t}", "summary_tokens": ["parse", "the", "response", "content", "and", "the", "given", "string", "as", "xml", "and", "assert", "the", "two", "are", "similar", "i"], "project": "spring-framework"}
{"id": 864, "code": "\tpublic void setValue(@Nullable Object value) {\n\t\tif (value instanceof Number) {\n\t\t\tsuper.setValue(NumberUtils.convertNumberToTargetClass((Number) value, this.numberClass));\n\t\t}\n\t\telse {\n\t\t\tsuper.setValue(value);\n\t\t}\n\t}", "summary_tokens": ["coerce", "a", "number", "value", "into", "the", "required", "target", "class", "if", "necessary"], "project": "spring-framework"}
{"id": 7966, "code": "\tpublic final List<HandlerMapping> getHandlerMappings() {\n\t\treturn this.handlerMappings;\n\t}", "summary_tokens": ["return", "all", "handler", "mapping", "beans", "detected", "by", "type", "in", "the", "set", "application", "context", "injected", "context", "and", "also", "annotation", "aware", "order", "comparator", "sort", "list", "sorted"], "project": "spring-framework"}
{"id": 5561, "code": "\tString getTransactionManager() {\n\t\treturn this.transactionManager;\n\t}", "summary_tokens": ["get", "the", "bean", "name", "of", "the", "org"], "project": "spring-framework"}
{"id": 5371, "code": "\tpublic void addScript(Resource script) {\n\t\tAssert.notNull(script, \"'script' must not be null\");\n\t\tthis.scripts.add(script);\n\t}", "summary_tokens": ["add", "a", "script", "to", "execute", "to", "initialize", "or", "clean", "up", "the", "database"], "project": "spring-framework"}
{"id": 9587, "code": "\tprotected void appendQueryProperties(StringBuilder targetUrl, Map<String, Object> model, String encodingScheme)\n\t\t\tthrows UnsupportedEncodingException {\n\n\t\t\n\t\tString fragment = null;\n\t\tint anchorIndex = targetUrl.indexOf(\"#\");\n\t\tif (anchorIndex > -1) {\n\t\t\tfragment = targetUrl.substring(anchorIndex);\n\t\t\ttargetUrl.delete(anchorIndex, targetUrl.length());\n\t\t}\n\n\t\t\n\t\tboolean first = (targetUrl.toString().indexOf('?') < 0);\n\t\tfor (Map.Entry<String, Object> entry : queryProperties(model).entrySet()) {\n\t\t\tObject rawValue = entry.getValue();\n\t\t\tCollection<?> values;\n\t\t\tif (rawValue != null && rawValue.getClass().isArray()) {\n\t\t\t\tvalues = CollectionUtils.arrayToList(rawValue);\n\t\t\t}\n\t\t\telse if (rawValue instanceof Collection) {\n\t\t\t\tvalues = ((Collection<?>) rawValue);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tvalues = Collections.singleton(rawValue);\n\t\t\t}\n\t\t\tfor (Object value : values) {\n\t\t\t\tif (first) {\n\t\t\t\t\ttargetUrl.append('?');\n\t\t\t\t\tfirst = false;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\ttargetUrl.append('&');\n\t\t\t\t}\n\t\t\t\tString encodedKey = urlEncode(entry.getKey(), encodingScheme);\n\t\t\t\tString encodedValue = (value != null ? urlEncode(value.toString(), encodingScheme) : \"\");\n\t\t\t\ttargetUrl.append(encodedKey).append('=').append(encodedValue);\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tif (fragment != null) {\n\t\t\ttargetUrl.append(fragment);\n\t\t}\n\t}", "summary_tokens": ["append", "query", "properties", "to", "the", "redirect", "url"], "project": "spring-framework"}
{"id": 4605, "code": "\tpublic void setPubSubDomain(boolean pubSubDomain) {\n\t\tthis.pubSubDomain = pubSubDomain;\n\t}", "summary_tokens": ["configure", "the", "destination", "accessor", "with", "knowledge", "of", "the", "jms", "domain", "used"], "project": "spring-framework"}
{"id": 6689, "code": "\tpublic void setRange(List<HttpRange> ranges) {\n\t\tString value = HttpRange.toString(ranges);\n\t\tset(RANGE, value);\n\t}", "summary_tokens": ["sets", "the", "new", "value", "of", "the", "range", "header"], "project": "spring-framework"}
{"id": 1564, "code": "\tprivate void notifyListenersOfRegistration(ObjectName objectName) {\n\t\tif (this.listeners != null) {\n\t\t\tfor (MBeanExporterListener listener : this.listeners) {\n\t\t\t\tlistener.mbeanRegistered(objectName);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["notifies", "all", "registered", "mbean", "exporter", "listener", "mbean", "exporter", "listeners", "of", "the", "registration", "of", "the", "mbean", "identified", "by", "the", "supplied", "object", "name"], "project": "spring-framework"}
{"id": 8030, "code": "\tprotected RequestMappingHandlerAdapter createRequestMappingHandlerAdapter() {\n\t\treturn new RequestMappingHandlerAdapter();\n\t}", "summary_tokens": ["override", "to", "plug", "a", "subclass", "of", "request", "mapping", "handler", "adapter"], "project": "spring-framework"}
{"id": 8517, "code": "\tprotected void noHandlerFound(HttpServletRequest request, HttpServletResponse response) throws Exception {\n\t\tif (pageNotFoundLogger.isWarnEnabled()) {\n\t\t\tpageNotFoundLogger.warn(\"No mapping for \" + request.getMethod() + \" \" + getRequestUri(request));\n\t\t}\n\t\tif (this.throwExceptionIfNoHandlerFound) {\n\t\t\tthrow new NoHandlerFoundException(request.getMethod(), getRequestUri(request),\n\t\t\t\t\tnew ServletServerHttpRequest(request).getHeaders());\n\t\t}\n\t\telse {\n\t\t\tresponse.sendError(HttpServletResponse.SC_NOT_FOUND);\n\t\t}\n\t}", "summary_tokens": ["no", "handler", "found", "rarr", "set", "appropriate", "http", "response", "status"], "project": "spring-framework"}
{"id": 4802, "code": "\tpublic void setReactiveAdapterRegistry(ReactiveAdapterRegistry registry) {\n\t\tsuper.setReactiveAdapterRegistry(registry);\n\t\tthis.strategies = this.strategies.mutate().reactiveAdapterStrategy(registry).build();\n\t}", "summary_tokens": ["configure", "the", "registry", "for", "adapting", "various", "reactive", "types"], "project": "spring-framework"}
{"id": 7732, "code": "\tpublic void addCookieInitializer(Consumer<ResponseCookie.ResponseCookieBuilder> initializer) {\n\t\tthis.cookieInitializer = this.cookieInitializer != null ?\n\t\t\t\tthis.cookieInitializer.andThen(initializer) : initializer;\n\t}", "summary_tokens": ["add", "a", "consumer", "for", "a", "response", "cookie", "builder", "that", "will", "be", "invoked", "for", "each", "cookie", "being", "built", "just", "before", "the", "call", "to", "build"], "project": "spring-framework"}
{"id": 6846, "code": "\tpublic int getMaxInMemorySize() {\n\t\treturn this.maxInMemorySize;\n\t}", "summary_tokens": ["return", "the", "set", "max", "in", "memory", "size", "configured", "byte", "count", "limit"], "project": "spring-framework"}
{"id": 5697, "code": "\tpublic int hashCode() {\n\t\tint result = Arrays.hashCode(this.locations);\n\t\tresult = 31 * result + Arrays.hashCode(this.properties);\n\t\treturn result;\n\t}", "summary_tokens": ["generate", "a", "unique", "hash", "code", "for", "all", "properties", "of", "this", "merged", "test", "property", "sources", "instance"], "project": "spring-framework"}
{"id": 1941, "code": "\tpublic ModelMap addAttribute(Object attributeValue) {\n\t\tAssert.notNull(attributeValue, \"Model object must not be null\");\n\t\tif (attributeValue instanceof Collection && ((Collection<?>) attributeValue).isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\treturn addAttribute(Conventions.getVariableName(attributeValue), attributeValue);\n\t}", "summary_tokens": ["add", "the", "supplied", "attribute", "to", "this", "map", "using", "a", "org"], "project": "spring-framework"}
{"id": 8076, "code": "\tstatic Builder from(ClientRequest other) {\n\t\treturn new DefaultClientRequestBuilder(other);\n\t}", "summary_tokens": ["create", "a", "builder", "initialized", "with", "the", "http", "method", "url", "headers", "cookies", "attributes", "and", "body", "of", "the", "given", "request"], "project": "spring-framework"}
{"id": 604, "code": "\tpublic void fireAliasRegistered(String beanName, String alias, @Nullable Object source) {\n\t\tthis.eventListener.aliasRegistered(new AliasDefinition(beanName, alias, source));\n\t}", "summary_tokens": ["fire", "an", "alias", "registered", "event"], "project": "spring-framework"}
{"id": 5505, "code": "\tpublic ContextLoader getContextLoader() {\n\t\treturn this.contextLoader;\n\t}", "summary_tokens": ["get", "the", "resolved", "context", "loader", "for", "the", "get", "test", "class", "test", "class"], "project": "spring-framework"}
{"id": 6330, "code": "\tprotected void doJtaBegin(JtaTransactionObject txObject, TransactionDefinition definition)\n\t\t\tthrows NotSupportedException, SystemException {\n\n\t\tapplyIsolationLevel(txObject, definition.getIsolationLevel());\n\t\tint timeout = determineTimeout(definition);\n\t\tapplyTimeout(txObject, timeout);\n\t\ttxObject.getUserTransaction().begin();\n\t}", "summary_tokens": ["perform", "a", "jta", "begin", "on", "the", "jta", "user", "transaction", "or", "transaction", "manager"], "project": "spring-framework"}
{"id": 3484, "code": "\tpublic String getSimpleMessage() {\n\t\treturn super.getMessage();\n\t}", "summary_tokens": ["return", "the", "exception", "simple", "message", "without", "including", "the", "expression", "that", "caused", "the", "failure"], "project": "spring-framework"}
{"id": 2641, "code": "protected V createEntry(final K key, KK cacheKey, Object v) {\n    FutureTask<V> task;\n    boolean creator = false;\n    if (v != null) {\n            \n        task = (FutureTask<V>) v;\n    } else {\n        task = new FutureTask<V>(new Callable<V>() {\n            public V call() throws Exception {\n                return loader.apply(key);\n            }\n        });\n        Object prevTask = map.putIfAbsent(cacheKey, task);\n        if (prevTask == null) {\n                \n            creator = true;\n            task.run();\n        } else if (prevTask instanceof FutureTask) {\n            task = (FutureTask<V>) prevTask;\n        } else {\n            return (V) prevTask;\n        }\n    }\n\n    V result;\n    try {\n        result = task.get();\n    } catch (InterruptedException e) {\n        throw new IllegalStateException(\"Interrupted while loading cache item\", e);\n    } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n            throw ((RuntimeException) cause);\n        }\n        throw new IllegalStateException(\"Unable to load cache item\", cause);\n    }\n    if (creator) {\n        map.put(cacheKey, result);\n    }\n    return result;\n}", "summary_tokens": ["loads", "entry", "to", "the", "cache"], "project": "spring-framework"}
{"id": 5304, "code": "\tpublic Class<?>[] scanPackages() throws UncategorizedMappingException {\n\t\ttry {\n\t\t\tList<Class<?>> jaxb2Classes = new ArrayList<>();\n\t\t\tfor (String packageToScan : this.packagesToScan) {\n\t\t\t\tString pattern = ResourcePatternResolver.CLASSPATH_ALL_URL_PREFIX +\n\t\t\t\t\t\tClassUtils.convertClassNameToResourcePath(packageToScan) + RESOURCE_PATTERN;\n\t\t\t\tResource[] resources = this.resourcePatternResolver.getResources(pattern);\n\t\t\t\tMetadataReaderFactory metadataReaderFactory = new CachingMetadataReaderFactory(this.resourcePatternResolver);\n\t\t\t\tfor (Resource resource : resources) {\n\t\t\t\t\tMetadataReader metadataReader = metadataReaderFactory.getMetadataReader(resource);\n\t\t\t\t\tif (isJaxb2Class(metadataReader, metadataReaderFactory)) {\n\t\t\t\t\t\tString className = metadataReader.getClassMetadata().getClassName();\n\t\t\t\t\t\tClass<?> jaxb2AnnotatedClass =\n\t\t\t\t\t\t\t\tClassUtils.forName(className, this.resourcePatternResolver.getClassLoader());\n\t\t\t\t\t\tjaxb2Classes.add(jaxb2AnnotatedClass);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn ClassUtils.toClassArray(jaxb2Classes);\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new UncategorizedMappingException(\"Failed to scan classpath for unlisted classes\", ex);\n\t\t}\n\t\tcatch (ClassNotFoundException ex) {\n\t\t\tthrow new UncategorizedMappingException(\"Failed to load annotated classes from classpath\", ex);\n\t\t}\n\t}", "summary_tokens": ["scan", "the", "packages", "for", "classes", "marked", "with", "jaxb", "0", "annotations"], "project": "spring-framework"}
{"id": 5996, "code": "\tpublic ResultMatcher exists() {\n\t\treturn result -> this.jsonPathHelper.exists(getContent(result));\n\t}", "summary_tokens": ["evaluate", "the", "json", "path", "expression", "against", "the", "response", "content", "and", "assert", "that", "a", "non", "null", "value", "possibly", "an", "empty", "array", "or", "map", "exists", "at", "the", "given", "path"], "project": "spring-framework"}
{"id": 1122, "code": "\tprotected void startScheduler(final Scheduler scheduler, final int startupDelay) throws SchedulerException {\n\t\tif (startupDelay <= 0) {\n\t\t\tlogger.info(\"Starting Quartz Scheduler now\");\n\t\t\tscheduler.start();\n\t\t}\n\t\telse {\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Will start Quartz Scheduler [\" + scheduler.getSchedulerName() +\n\t\t\t\t\t\t\"] in \" + startupDelay + \" seconds\");\n\t\t\t}\n\t\t\t\n\t\t\t\n\t\t\tThread schedulerThread = new Thread() {\n\t\t\t\t@Override\n\t\t\t\tpublic void run() {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tTimeUnit.SECONDS.sleep(startupDelay);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (InterruptedException ex) {\n\t\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\t\t\tlogger.info(\"Starting Quartz Scheduler now, after delay of \" + startupDelay + \" seconds\");\n\t\t\t\t\t}\n\t\t\t\t\ttry {\n\t\t\t\t\t\tscheduler.start();\n\t\t\t\t\t}\n\t\t\t\t\tcatch (SchedulerException ex) {\n\t\t\t\t\t\tthrow new SchedulingException(\"Could not start Quartz Scheduler after delay\", ex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t};\n\t\t\tschedulerThread.setName(\"Quartz Scheduler [\" + scheduler.getSchedulerName() + \"]\");\n\t\t\tschedulerThread.setDaemon(true);\n\t\t\tschedulerThread.start();\n\t\t}\n\t}", "summary_tokens": ["start", "the", "quartz", "scheduler", "respecting", "the", "startup", "delay", "setting"], "project": "spring-framework"}
{"id": 3265, "code": "\tpublic static boolean isJarFileURL(URL url) {\n\t\treturn (URL_PROTOCOL_FILE.equals(url.getProtocol()) &&\n\t\t\t\turl.getPath().toLowerCase().endsWith(JAR_FILE_EXTENSION));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "url", "points", "to", "a", "jar", "file", "itself", "that", "is", "has", "protocol", "file", "and", "ends", "with", "the"], "project": "spring-framework"}
{"id": 6509, "code": "\tpublic boolean isSynchronizedWithTransaction() {\n\t\treturn this.synchronizedWithTransaction;\n\t}", "summary_tokens": ["return", "whether", "the", "resource", "is", "synchronized", "with", "a", "transaction"], "project": "spring-framework"}
{"id": 6785, "code": "\tpublic Scheduler getScheduler() {\n\t\treturn this.scheduler;\n\t}", "summary_tokens": ["return", "the", "configured", "scheduler"], "project": "spring-framework"}
{"id": 9700, "code": "\tprotected Object filterModel(Map<String, Object> model) {\n\t\tMap<String, Object> result = CollectionUtils.newHashMap(model.size());\n\t\tSet<String> modelKeys = (!CollectionUtils.isEmpty(this.modelKeys) ? this.modelKeys : model.keySet());\n\t\tmodel.forEach((clazz, value) -> {\n\t\t\tif (!(value instanceof BindingResult) && modelKeys.contains(clazz) &&\n\t\t\t\t\t!clazz.equals(JsonView.class.getName()) &&\n\t\t\t\t\t!clazz.equals(FilterProvider.class.getName())) {\n\t\t\t\tresult.put(clazz, value);\n\t\t\t}\n\t\t});\n\t\treturn (this.extractValueFromSingleKeyModel && result.size() == 1 ? result.values().iterator().next() : result);\n\t}", "summary_tokens": ["filter", "out", "undesired", "attributes", "from", "the", "given", "model"], "project": "spring-framework"}
{"id": 1903, "code": "\tprotected AbstractBeanDefinition parseInternal(Element element, ParserContext parserContext) {\n\t\t\n\t\tString engine = element.getAttribute(ENGINE_ATTRIBUTE);\n\n\t\t\n\t\tString value = resolveScriptSource(element, parserContext.getReaderContext());\n\t\tif (value == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\t\n\t\tLangNamespaceUtils.registerScriptFactoryPostProcessorIfNecessary(parserContext.getRegistry());\n\n\t\t\n\t\tGenericBeanDefinition bd = new GenericBeanDefinition();\n\t\tbd.setBeanClassName(this.scriptFactoryClassName);\n\t\tbd.setSource(parserContext.extractSource(element));\n\t\tbd.setAttribute(ScriptFactoryPostProcessor.LANGUAGE_ATTRIBUTE, element.getLocalName());\n\n\t\t\n\t\tString scope = element.getAttribute(SCOPE_ATTRIBUTE);\n\t\tif (StringUtils.hasLength(scope)) {\n\t\t\tbd.setScope(scope);\n\t\t}\n\n\t\t\n\t\tString autowire = element.getAttribute(AUTOWIRE_ATTRIBUTE);\n\t\tint autowireMode = parserContext.getDelegate().getAutowireMode(autowire);\n\t\t\n\t\tif (autowireMode == AbstractBeanDefinition.AUTOWIRE_AUTODETECT) {\n\t\t\tautowireMode = AbstractBeanDefinition.AUTOWIRE_BY_TYPE;\n\t\t}\n\t\telse if (autowireMode == AbstractBeanDefinition.AUTOWIRE_CONSTRUCTOR) {\n\t\t\tautowireMode = AbstractBeanDefinition.AUTOWIRE_NO;\n\t\t}\n\t\tbd.setAutowireMode(autowireMode);\n\n\t\t\n\t\tString dependsOn = element.getAttribute(DEPENDS_ON_ATTRIBUTE);\n\t\tif (StringUtils.hasLength(dependsOn)) {\n\t\t\tbd.setDependsOn(StringUtils.tokenizeToStringArray(\n\t\t\t\t\tdependsOn, BeanDefinitionParserDelegate.MULTI_VALUE_ATTRIBUTE_DELIMITERS));\n\t\t}\n\n\t\t\n\t\tBeanDefinitionDefaults beanDefinitionDefaults = parserContext.getDelegate().getBeanDefinitionDefaults();\n\n\t\t\n\t\tString initMethod = element.getAttribute(INIT_METHOD_ATTRIBUTE);\n\t\tif (StringUtils.hasLength(initMethod)) {\n\t\t\tbd.setInitMethodName(initMethod);\n\t\t}\n\t\telse if (beanDefinitionDefaults.getInitMethodName() != null) {\n\t\t\tbd.setInitMethodName(beanDefinitionDefaults.getInitMethodName());\n\t\t}\n\n\t\tif (element.hasAttribute(DESTROY_METHOD_ATTRIBUTE)) {\n\t\t\tString destroyMethod = element.getAttribute(DESTROY_METHOD_ATTRIBUTE);\n\t\t\tbd.setDestroyMethodName(destroyMethod);\n\t\t}\n\t\telse if (beanDefinitionDefaults.getDestroyMethodName() != null) {\n\t\t\tbd.setDestroyMethodName(beanDefinitionDefaults.getDestroyMethodName());\n\t\t}\n\n\t\t\n\t\tString refreshCheckDelay = element.getAttribute(REFRESH_CHECK_DELAY_ATTRIBUTE);\n\t\tif (StringUtils.hasText(refreshCheckDelay)) {\n\t\t\tbd.setAttribute(ScriptFactoryPostProcessor.REFRESH_CHECK_DELAY_ATTRIBUTE, Long.valueOf(refreshCheckDelay));\n\t\t}\n\n\t\t\n\t\tString proxyTargetClass = element.getAttribute(PROXY_TARGET_CLASS_ATTRIBUTE);\n\t\tif (StringUtils.hasText(proxyTargetClass)) {\n\t\t\tbd.setAttribute(ScriptFactoryPostProcessor.PROXY_TARGET_CLASS_ATTRIBUTE, Boolean.valueOf(proxyTargetClass));\n\t\t}\n\n\t\t\n\t\tConstructorArgumentValues cav = bd.getConstructorArgumentValues();\n\t\tint constructorArgNum = 0;\n\t\tif (StringUtils.hasLength(engine)) {\n\t\t\tcav.addIndexedArgumentValue(constructorArgNum++, engine);\n\t\t}\n\t\tcav.addIndexedArgumentValue(constructorArgNum++, value);\n\t\tif (element.hasAttribute(SCRIPT_INTERFACES_ATTRIBUTE)) {\n\t\t\tcav.addIndexedArgumentValue(\n\t\t\t\t\tconstructorArgNum++, element.getAttribute(SCRIPT_INTERFACES_ATTRIBUTE), \"java.lang.Class[]\");\n\t\t}\n\n\t\t\n\t\tif (element.hasAttribute(CUSTOMIZER_REF_ATTRIBUTE)) {\n\t\t\tString customizerBeanName = element.getAttribute(CUSTOMIZER_REF_ATTRIBUTE);\n\t\t\tif (!StringUtils.hasText(customizerBeanName)) {\n\t\t\t\tparserContext.getReaderContext().error(\"Attribute 'customizer-ref' has empty value\", element);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcav.addIndexedArgumentValue(constructorArgNum++, new RuntimeBeanReference(customizerBeanName));\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tparserContext.getDelegate().parsePropertyElements(element, bd);\n\n\t\treturn bd;\n\t}", "summary_tokens": ["parses", "the", "dynamic", "object", "element", "and", "returns", "the", "resulting", "bean", "definition"], "project": "spring-framework"}
{"id": 268, "code": "\tprotected ObjectPool createObjectPool() {\n\t\tGenericObjectPoolConfig config = new GenericObjectPoolConfig();\n\t\tconfig.setMaxTotal(getMaxSize());\n\t\tconfig.setMaxIdle(getMaxIdle());\n\t\tconfig.setMinIdle(getMinIdle());\n\t\tconfig.setMaxWaitMillis(getMaxWait());\n\t\tconfig.setTimeBetweenEvictionRunsMillis(getTimeBetweenEvictionRunsMillis());\n\t\tconfig.setMinEvictableIdleTimeMillis(getMinEvictableIdleTimeMillis());\n\t\tconfig.setBlockWhenExhausted(isBlockWhenExhausted());\n\t\treturn new GenericObjectPool(this, config);\n\t}", "summary_tokens": ["subclasses", "can", "override", "this", "if", "they", "want", "to", "return", "a", "specific", "commons", "pool"], "project": "spring-framework"}
{"id": 5342, "code": "\tprivate static boolean connectionEquals(ConnectionHolder conHolder, Connection passedInCon) {\n\t\tif (!conHolder.hasConnection()) {\n\t\t\treturn false;\n\t\t}\n\t\tConnection heldCon = conHolder.getConnection();\n\t\t\n\t\t\n\t\treturn (heldCon == passedInCon || heldCon.equals(passedInCon) || getTargetConnection(heldCon).equals(passedInCon));\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "two", "connection", "s", "are", "equal", "asking", "the", "target", "connection", "in", "case", "of", "a", "proxy"], "project": "spring-framework"}
{"id": 9607, "code": "\tpublic void setViewClass(@Nullable Class<?> viewClass) {\n\t\tif (viewClass != null && !requiredViewClass().isAssignableFrom(viewClass)) {\n\t\t\tthrow new IllegalArgumentException(\"Given view class [\" + viewClass.getName() +\n\t\t\t\t\t\"] is not of type [\" + requiredViewClass().getName() + \"]\");\n\t\t}\n\t\tthis.viewClass = viewClass;\n\t}", "summary_tokens": ["set", "the", "view", "class", "that", "should", "be", "used", "to", "create", "views"], "project": "spring-framework"}
{"id": 1055, "code": "\tpublic void setCronExpression(String cronExpression) {\n\t\tthis.cronExpression = cronExpression;\n\t}", "summary_tokens": ["specify", "the", "cron", "expression", "for", "this", "trigger"], "project": "spring-framework"}
{"id": 8932, "code": "\tpublic final boolean supports(Object handler) {\n\t\treturn (handler instanceof HandlerMethod && supportsInternal((HandlerMethod) handler));\n\t}", "summary_tokens": ["this", "implementation", "expects", "the", "handler", "to", "be", "an", "handler", "method"], "project": "spring-framework"}
{"id": 1007, "code": "\tpublic boolean isTransactionAware() {\n\t\treturn this.transactionAware;\n\t}", "summary_tokens": ["return", "whether", "this", "cache", "manager", "has", "been", "configured", "to", "be", "transaction", "aware"], "project": "spring-framework"}
{"id": 4641, "code": "\tpublic void setJsonb(Jsonb jsonb) {\n\t\tAssert.notNull(jsonb, \"A Jsonb instance is required\");\n\t\tthis.jsonb = jsonb;\n\t}", "summary_tokens": ["set", "the", "jsonb", "instance", "to", "use"], "project": "spring-framework"}
{"id": 3857, "code": "\tpublic JdbcTemplate getJdbcTemplate() {\n\t\treturn this.jdbcTemplate;\n\t}", "summary_tokens": ["get", "the", "configured", "jdbc", "template"], "project": "spring-framework"}
{"id": 586, "code": "\tpublic Object getSource() {\n\t\treturn this.source;\n\t}", "summary_tokens": ["get", "the", "actual", "location", "within", "the", "associated", "get", "resource", "resource", "may", "be", "null"], "project": "spring-framework"}
{"id": 7206, "code": "\tpublic final Validator getValidator() {\n\t\treturn this.validator;\n\t}", "summary_tokens": ["return", "the", "validator", "to", "apply", "after", "each", "binding", "step", "if", "any"], "project": "spring-framework"}
{"id": 1108, "code": "\tpublic void setSchedulerContextAsMap(Map<String, ?> schedulerContextAsMap) {\n\t\tthis.schedulerContextMap = schedulerContextAsMap;\n\t}", "summary_tokens": ["register", "objects", "in", "the", "scheduler", "context", "via", "a", "given", "map"], "project": "spring-framework"}
{"id": 8978, "code": "\tprotected boolean isRedirectViewName(String viewName) {\n\t\treturn (PatternMatchUtils.simpleMatch(this.redirectPatterns, viewName) || viewName.startsWith(\"redirect:\"));\n\t}", "summary_tokens": ["whether", "the", "given", "view", "name", "is", "a", "redirect", "view", "reference"], "project": "spring-framework"}
{"id": 633, "code": "\tpublic BeanDefinitionBuilder addConstructorArgReference(String beanName) {\n\t\tthis.beanDefinition.getConstructorArgumentValues().addIndexedArgumentValue(\n\t\t\t\tthis.constructorArgIndex++, new RuntimeBeanReference(beanName));\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "reference", "to", "a", "named", "bean", "as", "a", "constructor", "arg"], "project": "spring-framework"}
{"id": 1380, "code": "\tprotected long getCacheMillis() {\n\t\treturn this.cacheMillis;\n\t}", "summary_tokens": ["return", "the", "number", "of", "milliseconds", "to", "cache", "loaded", "properties", "files"], "project": "spring-framework"}
{"id": 6763, "code": "\tpublic void setConnectTimeout(int connectTimeout) {\n\t\tthis.client = this.client.newBuilder()\n\t\t\t\t.connectTimeout(connectTimeout, TimeUnit.MILLISECONDS)\n\t\t\t\t.build();\n\t}", "summary_tokens": ["set", "the", "underlying", "connect", "timeout", "in", "milliseconds"], "project": "spring-framework"}
{"id": 81, "code": "\tpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n\t\tObject oldProxy = null;\n\t\tboolean setProxyContext = false;\n\n\t\tTargetSource targetSource = this.advised.targetSource;\n\t\tObject target = null;\n\n\t\ttry {\n\t\t\tif (!this.equalsDefined && AopUtils.isEqualsMethod(method)) {\n\t\t\t\t\n\t\t\t\treturn equals(args[0]);\n\t\t\t}\n\t\t\telse if (!this.hashCodeDefined && AopUtils.isHashCodeMethod(method)) {\n\t\t\t\t\n\t\t\t\treturn hashCode();\n\t\t\t}\n\t\t\telse if (method.getDeclaringClass() == DecoratingProxy.class) {\n\t\t\t\t\n\t\t\t\treturn AopProxyUtils.ultimateTargetClass(this.advised);\n\t\t\t}\n\t\t\telse if (!this.advised.opaque && method.getDeclaringClass().isInterface() &&\n\t\t\t\t\tmethod.getDeclaringClass().isAssignableFrom(Advised.class)) {\n\t\t\t\t\n\t\t\t\treturn AopUtils.invokeJoinpointUsingReflection(this.advised, method, args);\n\t\t\t}\n\n\t\t\tObject retVal;\n\n\t\t\tif (this.advised.exposeProxy) {\n\t\t\t\t\n\t\t\t\toldProxy = AopContext.setCurrentProxy(proxy);\n\t\t\t\tsetProxyContext = true;\n\t\t\t}\n\n\t\t\t\n\t\t\t\n\t\t\ttarget = targetSource.getTarget();\n\t\t\tClass<?> targetClass = (target != null ? target.getClass() : null);\n\n\t\t\t\n\t\t\tList<Object> chain = this.advised.getInterceptorsAndDynamicInterceptionAdvice(method, targetClass);\n\n\t\t\t\n\t\t\t\n\t\t\tif (chain.isEmpty()) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tObject[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);\n\t\t\t\tretVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse);\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\tMethodInvocation invocation =\n\t\t\t\t\t\tnew ReflectiveMethodInvocation(proxy, target, method, args, targetClass, chain);\n\t\t\t\t\n\t\t\t\tretVal = invocation.proceed();\n\t\t\t}\n\n\t\t\t\n\t\t\tClass<?> returnType = method.getReturnType();\n\t\t\tif (retVal != null && retVal == target &&\n\t\t\t\t\treturnType != Object.class && returnType.isInstance(proxy) &&\n\t\t\t\t\t!RawTargetAccess.class.isAssignableFrom(method.getDeclaringClass())) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tretVal = proxy;\n\t\t\t}\n\t\t\telse if (retVal == null && returnType != Void.TYPE && returnType.isPrimitive()) {\n\t\t\t\tthrow new AopInvocationException(\n\t\t\t\t\t\t\"Null return value from advice does not match primitive return type for: \" + method);\n\t\t\t}\n\t\t\treturn retVal;\n\t\t}\n\t\tfinally {\n\t\t\tif (target != null && !targetSource.isStatic()) {\n\t\t\t\t\n\t\t\t\ttargetSource.releaseTarget(target);\n\t\t\t}\n\t\t\tif (setProxyContext) {\n\t\t\t\t\n\t\t\t\tAopContext.setCurrentProxy(oldProxy);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["implementation", "of", "invocation", "handler"], "project": "spring-framework"}
{"id": 3820, "code": "\tint getTotalParameterCount() {\n\t\treturn this.totalParameterCount;\n\t}", "summary_tokens": ["return", "the", "total", "count", "of", "all", "the", "parameters", "in", "the", "sql", "statement"], "project": "spring-framework"}
{"id": 3229, "code": "\tpublic LinkedMultiValueMap<K, V> clone() {\n\t\treturn new LinkedMultiValueMap<>(this);\n\t}", "summary_tokens": ["create", "a", "regular", "copy", "of", "this", "map"], "project": "spring-framework"}
{"id": 5212, "code": "\tdefault String getPersistenceProviderRootPackage() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "persistence", "provider", "s", "root", "package", "e"], "project": "spring-framework"}
{"id": 6931, "code": "\tpublic HttpInputMessage getHttpInputMessage() {\n\t\tAssert.state(this.httpInputMessage != null, \"No HttpInputMessage available - use non-deprecated constructors\");\n\t\treturn this.httpInputMessage;\n\t}", "summary_tokens": ["return", "the", "original", "http", "message"], "project": "spring-framework"}
{"id": 3830, "code": "\tpublic String getProcedureName() {\n\t\treturn this.callMetaDataContext.getProcedureName();\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "stored", "procedure"], "project": "spring-framework"}
{"id": 2023, "code": "\tprotected String postProcessMessageCode(String code) {\n\t\treturn getPrefix() + code;\n\t}", "summary_tokens": ["post", "process", "the", "given", "message", "code", "built", "by", "this", "resolver"], "project": "spring-framework"}
{"id": 2937, "code": "\tpublic boolean exists() {\n\t\treturn (this.file != null ? this.file.exists() : Files.exists(this.filePath));\n\t}", "summary_tokens": ["this", "implementation", "returns", "whether", "the", "underlying", "file", "exists"], "project": "spring-framework"}
{"id": 108, "code": "\tprotected void evaluateProxyInterfaces(Class<?> beanClass, ProxyFactory proxyFactory) {\n\t\tClass<?>[] targetInterfaces = ClassUtils.getAllInterfacesForClass(beanClass, getProxyClassLoader());\n\t\tboolean hasReasonableProxyInterface = false;\n\t\tfor (Class<?> ifc : targetInterfaces) {\n\t\t\tif (!isConfigurationCallbackInterface(ifc) && !isInternalLanguageInterface(ifc) &&\n\t\t\t\t\tifc.getMethods().length > 0) {\n\t\t\t\thasReasonableProxyInterface = true;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (hasReasonableProxyInterface) {\n\t\t\t\n\t\t\tfor (Class<?> ifc : targetInterfaces) {\n\t\t\t\tproxyFactory.addInterface(ifc);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tproxyFactory.setProxyTargetClass(true);\n\t\t}\n\t}", "summary_tokens": ["check", "the", "interfaces", "on", "the", "given", "bean", "class", "and", "apply", "them", "to", "the", "proxy", "factory", "if", "appropriate"], "project": "spring-framework"}
{"id": 4361, "code": "\tpublic final JmsTemplate getJmsTemplate() {\n\t\treturn this.jmsTemplate;\n\t}", "summary_tokens": ["return", "the", "jms", "template", "for", "the", "gateway"], "project": "spring-framework"}
{"id": 434, "code": "\tpublic void resolveAndSet(RegisteredBean registeredBean, Object instance) {\n\t\tAssert.notNull(registeredBean, \"'registeredBean' must not be null\");\n\t\tAssert.notNull(instance, \"'instance' must not be null\");\n\t\tField field = getField(registeredBean);\n\t\tObject resolved = resolveValue(registeredBean, field);\n\t\tif (resolved != null) {\n\t\t\tReflectionUtils.makeAccessible(field);\n\t\t\tReflectionUtils.setField(field, instance, resolved);\n\t\t}\n\t}", "summary_tokens": ["resolve", "the", "field", "value", "for", "the", "specified", "registered", "bean", "and", "set", "it", "using", "reflection"], "project": "spring-framework"}
{"id": 1427, "code": "\tpublic Locale getLocale() {\n\t\treturn this.locale;\n\t}", "summary_tokens": ["this", "implementation", "exposes", "the", "specified", "locale", "for", "introspection", "through", "the", "standard", "resource", "bundle"], "project": "spring-framework"}
{"id": 6910, "code": "\tfinal List<HttpMessageWriter<?>> getTypedWriters() {\n\t\treturn this.typedWriters;\n\t}", "summary_tokens": ["return", "all", "writers", "that", "support", "specific", "types"], "project": "spring-framework"}
{"id": 691, "code": "\tprotected boolean isDependent(String beanName, String dependentBeanName) {\n\t\tsynchronized (this.dependentBeanMap) {\n\t\t\treturn isDependent(beanName, dependentBeanName, null);\n\t\t}\n\t}", "summary_tokens": ["determine", "whether", "the", "specified", "dependent", "bean", "has", "been", "registered", "as", "dependent", "on", "the", "given", "bean", "or", "on", "any", "of", "its", "transitive", "dependencies"], "project": "spring-framework"}
{"id": 658, "code": "\tpublic void setDestroyMethodName(@Nullable String destroyMethodName) {\n\t\tthis.destroyMethodName = (StringUtils.hasText(destroyMethodName) ? destroyMethodName : null);\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "default", "destroy", "method"], "project": "spring-framework"}
{"id": 3862, "code": "\tpublic void setCatalogName(@Nullable String catalogName) {\n\t\tcheckIfConfigurationModificationIsAllowed();\n\t\tthis.tableMetaDataContext.setCatalogName(catalogName);\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "catalog", "for", "this", "insert"], "project": "spring-framework"}
{"id": 6782, "code": "\tpublic void setThreadPrefix(String threadPrefix) {\n\t\tAssert.notNull(threadPrefix, \"Thread prefix is required\");\n\t\tthis.threadPrefix = threadPrefix;\n\t}", "summary_tokens": ["configure", "the", "thread", "prefix", "to", "initialize", "queued", "thread", "pool", "executor", "with"], "project": "spring-framework"}
{"id": 7929, "code": "\tpublic static MockServerWebExchange.Builder builder(MockServerHttpRequest.BaseBuilder<?> requestBuilder) {\n\t\treturn new MockServerWebExchange.Builder(requestBuilder.build());\n\t}", "summary_tokens": ["variant", "of", "builder", "mock", "server", "http", "request", "with", "a", "mock", "request", "builder"], "project": "spring-framework"}
{"id": 3378, "code": "\tdefault ThrowingConsumer<T> throwing(BiFunction<String, Exception, RuntimeException> exceptionWrapper) {\n\t\treturn new ThrowingConsumer<>() {\n\n\t\t\t@Override\n\t\t\tpublic void acceptWithException(T t) throws Exception {\n\t\t\t\tThrowingConsumer.this.acceptWithException(t);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void accept(T t) {\n\t\t\t\taccept(t, exceptionWrapper);\n\t\t\t}\n\n\t\t};\n\t}", "summary_tokens": ["return", "a", "new", "throwing", "consumer", "where", "the", "accept", "object", "method", "wraps", "any", "thrown", "checked", "exceptions", "using", "the", "given", "exception", "wrapper"], "project": "spring-framework"}
{"id": 9617, "code": "\tpublic void setRedirectHttp10Compatible(boolean redirectHttp10Compatible) {\n\t\tthis.redirectHttp10Compatible = redirectHttp10Compatible;\n\t}", "summary_tokens": ["set", "whether", "redirects", "should", "stay", "compatible", "with", "http", "0"], "project": "spring-framework"}
{"id": 4183, "code": "\tprotected String getDeleteStatement(long[] values) {\n\t\tStringBuilder sb = new StringBuilder(64);\n\t\tsb.append(\"delete from \").append(getIncrementerName()).append(\" where \").append(getColumnName());\n\t\tif (isDeleteSpecificValues()) {\n\t\t\tsb.append(\" in (\").append(values[0] - 1);\n\t\t\tfor (int i = 0; i < values.length - 1; i++) {\n\t\t\t\tsb.append(\", \").append(values[i]);\n\t\t\t}\n\t\t\tsb.append(')');\n\t\t}\n\t\telse {\n\t\t\tlong maxValue = values[values.length - 1];\n\t\t\tsb.append(\" < \").append(maxValue);\n\t\t}\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["statement", "to", "use", "to", "clean", "up", "sequence", "values"], "project": "spring-framework"}
{"id": 316, "code": "\tstatic CachedIntrospectionResults forClass(Class<?> beanClass) throws BeansException {\n\t\tCachedIntrospectionResults results = strongClassCache.get(beanClass);\n\t\tif (results != null) {\n\t\t\treturn results;\n\t\t}\n\t\tresults = softClassCache.get(beanClass);\n\t\tif (results != null) {\n\t\t\treturn results;\n\t\t}\n\n\t\tresults = new CachedIntrospectionResults(beanClass);\n\t\tConcurrentMap<Class<?>, CachedIntrospectionResults> classCacheToUse;\n\n\t\tif (ClassUtils.isCacheSafe(beanClass, CachedIntrospectionResults.class.getClassLoader()) ||\n\t\t\t\tisClassLoaderAccepted(beanClass.getClassLoader())) {\n\t\t\tclassCacheToUse = strongClassCache;\n\t\t}\n\t\telse {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Not strongly caching class [\" + beanClass.getName() + \"] because it is not cache-safe\");\n\t\t\t}\n\t\t\tclassCacheToUse = softClassCache;\n\t\t}\n\n\t\tCachedIntrospectionResults existing = classCacheToUse.putIfAbsent(beanClass, results);\n\t\treturn (existing != null ? existing : results);\n\t}", "summary_tokens": ["create", "cached", "introspection", "results", "for", "the", "given", "bean", "class"], "project": "spring-framework"}
{"id": 5185, "code": "\tpublic SessionFactory buildSessionFactory(AsyncTaskExecutor bootstrapExecutor) {\n\t\tAssert.notNull(bootstrapExecutor, \"AsyncTaskExecutor must not be null\");\n\t\treturn (SessionFactory) Proxy.newProxyInstance(this.resourcePatternResolver.getClassLoader(),\n\t\t\t\tnew Class<?>[] {SessionFactoryImplementor.class, InfrastructureProxy.class},\n\t\t\t\tnew BootstrapSessionFactoryInvocationHandler(bootstrapExecutor));\n\t}", "summary_tokens": ["build", "the", "hibernate", "session", "factory", "through", "background", "bootstrapping", "using", "the", "given", "executor", "for", "a", "parallel", "initialization", "phase", "e"], "project": "spring-framework"}
{"id": 660, "code": "\tpublic String getResourceDescription() {\n\t\treturn String.valueOf(super.getResourceDescription());\n\t}", "summary_tokens": ["return", "the", "description", "of", "the", "resource", "that", "the", "bean", "definition", "came", "from"], "project": "spring-framework"}
{"id": 1464, "code": "\tpublic void addMessage(String code, Locale locale, String msg) {\n\t\tAssert.notNull(code, \"Code must not be null\");\n\t\tAssert.notNull(locale, \"Locale must not be null\");\n\t\tAssert.notNull(msg, \"Message must not be null\");\n\t\tthis.messageMap.computeIfAbsent(code, key -> new HashMap<>(4)).put(locale, new MessageHolder(msg, locale));\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Added message [\" + msg + \"] for code [\" + code + \"] and Locale [\" + locale + \"]\");\n\t\t}\n\t}", "summary_tokens": ["associate", "the", "given", "message", "with", "the", "given", "code"], "project": "spring-framework"}
{"id": 6253, "code": "\tpublic String getTimeoutString() {\n\t\treturn this.timeoutString;\n\t}", "summary_tokens": ["return", "the", "timeout", "to", "apply", "if", "any", "as", "a", "string", "value", "that", "resolves", "to", "a", "number", "of", "seconds"], "project": "spring-framework"}
{"id": 7519, "code": "\tprotected String generateETagHeaderValue(InputStream inputStream, boolean isWeak) throws IOException {\n\t\t\n\t\tStringBuilder builder = new StringBuilder(37);\n\t\tif (isWeak) {\n\t\t\tbuilder.append(\"W/\");\n\t\t}\n\t\tbuilder.append(\"\\\"0\");\n\t\tDigestUtils.appendMd5DigestAsHex(inputStream, builder);\n\t\tbuilder.append('\"');\n\t\treturn builder.toString();\n\t}", "summary_tokens": ["generate", "the", "etag", "header", "value", "from", "the", "given", "response", "body", "byte", "array"], "project": "spring-framework"}
{"id": 5309, "code": "\tprotected Document buildDocument() {\n\t\ttry {\n\t\t\tDocumentBuilder documentBuilder;\n\t\t\tsynchronized (this.documentBuilderFactoryMonitor) {\n\t\t\t\tif (this.documentBuilderFactory == null) {\n\t\t\t\t\tthis.documentBuilderFactory = createDocumentBuilderFactory();\n\t\t\t\t}\n\t\t\t\tdocumentBuilder = createDocumentBuilder(this.documentBuilderFactory);\n\t\t\t}\n\t\t\treturn documentBuilder.newDocument();\n\t\t}\n\t\tcatch (ParserConfigurationException ex) {\n\t\t\tthrow new UnmarshallingFailureException(\"Could not create document placeholder: \" + ex.getMessage(), ex);\n\t\t}\n\t}", "summary_tokens": ["build", "a", "new", "document", "from", "this", "marshaller", "s", "document", "builder", "factory", "as", "a", "placeholder", "for", "a", "dom", "node"], "project": "spring-framework"}
{"id": 3012, "code": "\tpublic static void fillProperties(Properties props, Resource resource) throws IOException {\n\t\ttry (InputStream is = resource.getInputStream()) {\n\t\t\tString filename = resource.getFilename();\n\t\t\tif (filename != null && filename.endsWith(XML_FILE_EXTENSION)) {\n\t\t\t\tif (shouldIgnoreXml) {\n\t\t\t\t\tthrow new UnsupportedOperationException(\"XML support disabled\");\n\t\t\t\t}\n\t\t\t\tprops.loadFromXML(is);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tprops.load(is);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["fill", "the", "given", "properties", "from", "the", "given", "resource", "in", "iso", "0", "0", "encoding"], "project": "spring-framework"}
{"id": 1500, "code": "\tpublic void setRegisterDefaultFormatters(boolean registerDefaultFormatters) {\n\t\tthis.registerDefaultFormatters = registerDefaultFormatters;\n\t}", "summary_tokens": ["indicate", "whether", "default", "formatters", "should", "be", "registered", "or", "not"], "project": "spring-framework"}
{"id": 6579, "code": "\tpublic void transactionAttributeOnTargetClassMethodOverridesAttributeOnInterfaceMethod() throws Exception {\n\t\tMethod interfaceMethod = ITestBean3.class.getMethod(\"getAge\");\n\t\tMethod interfaceMethod2 = ITestBean3.class.getMethod(\"setAge\", int.class);\n\t\tMethod interfaceMethod3 = ITestBean3.class.getMethod(\"getName\");\n\n\t\tAnnotationTransactionAttributeSource atas = new AnnotationTransactionAttributeSource();\n\t\tatas.setEmbeddedValueResolver(strVal -> (\"${myTimeout}\".equals(strVal) ? \"5\" : strVal));\n\n\t\tTransactionAttribute actual = atas.getTransactionAttribute(interfaceMethod, TestBean3.class);\n\t\tassertThat(actual.getPropagationBehavior()).isEqualTo(TransactionAttribute.PROPAGATION_REQUIRES_NEW);\n\t\tassertThat(actual.getIsolationLevel()).isEqualTo(TransactionAttribute.ISOLATION_REPEATABLE_READ);\n\t\tassertThat(actual.getTimeout()).isEqualTo(5);\n\t\tassertThat(actual.isReadOnly()).isTrue();\n\n\t\tTransactionAttribute actual2 = atas.getTransactionAttribute(interfaceMethod2, TestBean3.class);\n\t\tassertThat(actual2.getPropagationBehavior()).isEqualTo(TransactionAttribute.PROPAGATION_REQUIRES_NEW);\n\t\tassertThat(actual2.getIsolationLevel()).isEqualTo(TransactionAttribute.ISOLATION_REPEATABLE_READ);\n\t\tassertThat(actual2.getTimeout()).isEqualTo(5);\n\t\tassertThat(actual2.isReadOnly()).isTrue();\n\n\t\tRuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute();\n\t\trbta.getRollbackRules().add(new RollbackRuleAttribute(Exception.class));\n\t\trbta.getRollbackRules().add(new NoRollbackRuleAttribute(IOException.class));\n\t\tassertThat(((RuleBasedTransactionAttribute) actual).getRollbackRules()).isEqualTo(rbta.getRollbackRules());\n\n\t\tTransactionAttribute actual3 = atas.getTransactionAttribute(interfaceMethod3, TestBean3.class);\n\t\tassertThat(actual3.getPropagationBehavior()).isEqualTo(TransactionAttribute.PROPAGATION_REQUIRED);\n\t}", "summary_tokens": ["test", "that", "when", "an", "attribute", "exists", "on", "both", "class", "and", "interface", "class", "takes", "precedence"], "project": "spring-framework"}
{"id": 1233, "code": "\tpublic final long getTimestamp() {\n\t\treturn this.timestamp;\n\t}", "summary_tokens": ["return", "the", "time", "in", "milliseconds", "when", "the", "event", "occurred"], "project": "spring-framework"}
{"id": 4781, "code": "\tpublic MetadataEncoder route(String route, Object... routeVars) {\n\t\tthis.route = expand(route, routeVars);\n\t\tassertMetadataEntryCount();\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "route", "to", "a", "remote", "handler", "as", "described", "in", "rsocket", "requester", "route", "string", "object"], "project": "spring-framework"}
{"id": 239, "code": "\tpublic void setClassFilter(ClassFilter classFilter) {\n\t\tthis.classFilter = classFilter;\n\t}", "summary_tokens": ["set", "the", "class", "filter", "to", "use", "for", "this", "pointcut"], "project": "spring-framework"}
{"id": 7922, "code": "\tpublic Method method() {\n\t\treturn this.method;\n\t}", "summary_tokens": ["return", "the", "resolved", "method"], "project": "spring-framework"}
{"id": 2053, "code": "\tpublic void setMappingLocations(Resource... mappingLocations) {\n\t\tthis.mappingLocations = mappingLocations;\n\t}", "summary_tokens": ["specify", "resource", "locations", "to", "load", "xml", "constraint", "mapping", "files", "from", "if", "any"], "project": "spring-framework"}
{"id": 7463, "code": "\tpublic void setMaxPayloadLength(int maxPayloadLength) {\n\t\tAssert.isTrue(maxPayloadLength >= 0, \"'maxPayloadLength' should be larger than or equal to 0\");\n\t\tthis.maxPayloadLength = maxPayloadLength;\n\t}", "summary_tokens": ["set", "the", "maximum", "length", "of", "the", "payload", "body", "to", "be", "included", "in", "the", "log", "message"], "project": "spring-framework"}
{"id": 9305, "code": "\tprotected String getOnmouseover() {\n\t\treturn this.onmouseover;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onmouseover", "attribute"], "project": "spring-framework"}
{"id": 3927, "code": "\tprotected Connection getConnectionFromDriver(@Nullable String username, @Nullable String password) throws SQLException {\n\t\tProperties mergedProps = new Properties();\n\t\tProperties connProps = getConnectionProperties();\n\t\tif (connProps != null) {\n\t\t\tmergedProps.putAll(connProps);\n\t\t}\n\t\tif (username != null) {\n\t\t\tmergedProps.setProperty(\"user\", username);\n\t\t}\n\t\tif (password != null) {\n\t\t\tmergedProps.setProperty(\"password\", password);\n\t\t}\n\n\t\tConnection con = getConnectionFromDriver(mergedProps);\n\t\tif (this.catalog != null) {\n\t\t\tcon.setCatalog(this.catalog);\n\t\t}\n\t\tif (this.schema != null) {\n\t\t\tcon.setSchema(this.schema);\n\t\t}\n\t\treturn con;\n\t}", "summary_tokens": ["build", "properties", "for", "the", "driver", "including", "the", "given", "username", "and", "password", "if", "any", "and", "obtain", "a", "corresponding", "connection"], "project": "spring-framework"}
{"id": 4947, "code": "\tpublic String getSystemLogin() {\n\t\treturn this.systemLogin;\n\t}", "summary_tokens": ["return", "the", "login", "used", "for", "the", "shared", "system", "connection", "to", "the", "stomp", "broker"], "project": "spring-framework"}
{"id": 1131, "code": "\tpublic void setStartTime(Date startTime) {\n\t\tthis.startTime = startTime;\n\t}", "summary_tokens": ["set", "a", "specific", "start", "time", "for", "the", "trigger"], "project": "spring-framework"}
{"id": 4785, "code": "\tdefault void metadataToExtract(\n\t\t\tMimeType mimeType, ParameterizedTypeReference<?> targetType, @Nullable String name) {\n\n\t\tString key = name != null ? name : mimeType.toString();\n\t\tmetadataToExtract(mimeType, targetType, (value, map) -> map.put(key, value));\n\t}", "summary_tokens": ["variant", "of", "metadata", "to", "extract", "mime", "type", "class", "string", "that", "accepts", "parameterized", "type", "reference", "instead", "of", "class", "for", "specifying", "a", "target", "type", "with", "generic", "parameters"], "project": "spring-framework"}
{"id": 9566, "code": "\tprotected RequestDispatcher getRequestDispatcher(HttpServletRequest request, String path) {\n\t\treturn request.getRequestDispatcher(path);\n\t}", "summary_tokens": ["obtain", "the", "request", "dispatcher", "to", "use", "for", "the", "forward", "include"], "project": "spring-framework"}
{"id": 4573, "code": "\tpublic static JmsMessageHeaderAccessor wrap(Message<?> message) {\n\t\treturn new JmsMessageHeaderAccessor(message);\n\t}", "summary_tokens": ["create", "a", "jms", "message", "header", "accessor", "from", "the", "headers", "of", "an", "existing", "message"], "project": "spring-framework"}
{"id": 6690, "code": "\tpublic List<HttpRange> getRange() {\n\t\tString value = getFirst(RANGE);\n\t\treturn HttpRange.parseRanges(value);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "range", "header"], "project": "spring-framework"}
{"id": 4353, "code": "\tprotected MessageProducer createProducer(Session session, @Nullable Destination destination) throws JMSException {\n\t\tMessageProducer producer = doCreateProducer(session, destination);\n\t\tif (!isMessageIdEnabled()) {\n\t\t\tproducer.setDisableMessageID(true);\n\t\t}\n\t\tif (!isMessageTimestampEnabled()) {\n\t\t\tproducer.setDisableMessageTimestamp(true);\n\t\t}\n\t\treturn producer;\n\t}", "summary_tokens": ["create", "a", "jms", "message", "producer", "for", "the", "given", "session", "and", "destination", "configuring", "it", "to", "disable", "message", "ids", "and", "or", "timestamps", "if", "necessary"], "project": "spring-framework"}
{"id": 1351, "code": "\tprotected String getDefaultMessage(String code) {\n\t\tif (isUseCodeAsDefaultMessage()) {\n\t\t\treturn code;\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["return", "a", "fallback", "default", "message", "for", "the", "given", "code", "if", "any"], "project": "spring-framework"}
{"id": 5735, "code": "\tpublic void beforeTestMethod(final TestContext testContext) throws Exception {\n\t\tMethod testMethod = testContext.getTestMethod();\n\t\tClass<?> testClass = testContext.getTestClass();\n\t\tAssert.notNull(testMethod, \"Test method of supplied TestContext must not be null\");\n\n\t\tTransactionContext txContext = TransactionContextHolder.removeCurrentTransactionContext();\n\t\tAssert.state(txContext == null, \"Cannot start new transaction without ending existing transaction\");\n\n\t\tPlatformTransactionManager tm = null;\n\t\tTransactionAttribute transactionAttribute = this.attributeSource.getTransactionAttribute(testMethod, testClass);\n\n\t\tif (transactionAttribute != null) {\n\t\t\ttransactionAttribute = TestContextTransactionUtils.createDelegatingTransactionAttribute(testContext,\n\t\t\t\ttransactionAttribute);\n\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Explicit transaction definition [\" + transactionAttribute +\n\t\t\t\t\t\t\"] found for test context \" + testContext);\n\t\t\t}\n\n\t\t\tif (transactionAttribute.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NOT_SUPPORTED ||\n\t\t\t\t\ttransactionAttribute.getPropagationBehavior() == TransactionDefinition.PROPAGATION_NEVER) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\ttm = getTransactionManager(testContext, transactionAttribute.getQualifier());\n\t\t\tAssert.state(tm != null,\n\t\t\t\t\t() -> \"Failed to retrieve PlatformTransactionManager for @Transactional test: \" + testContext);\n\t\t}\n\n\t\tif (tm != null) {\n\t\t\ttxContext = new TransactionContext(testContext, tm, transactionAttribute, isRollback(testContext));\n\t\t\trunBeforeTransactionMethods(testContext);\n\t\t\ttxContext.startTransaction();\n\t\t\tTransactionContextHolder.setCurrentTransactionContext(txContext);\n\t\t}\n\t}", "summary_tokens": ["if", "the", "test", "method", "of", "the", "supplied", "test", "context", "test", "context", "is", "configured", "to", "run", "within", "a", "transaction", "this", "method", "will", "run", "before", "transaction", "methods", "and", "start", "a", "new", "transaction"], "project": "spring-framework"}
{"id": 5131, "code": "\tpublic String getQueryCacheRegion() {\n\t\treturn this.queryCacheRegion;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "cache", "region", "for", "queries", "executed", "by", "this", "template"], "project": "spring-framework"}
{"id": 9601, "code": "\tpublic void setLocalesToInitialize(Locale... localesToInitialize) {\n\t\tthis.localesToInitialize = localesToInitialize;\n\t}", "summary_tokens": ["specify", "locales", "to", "initialize", "eagerly", "rather", "than", "lazily", "when", "actually", "accessed"], "project": "spring-framework"}
{"id": 694, "code": "\tpublic String[] getDependenciesForBean(String beanName) {\n\t\tSet<String> dependenciesForBean = this.dependenciesForBeanMap.get(beanName);\n\t\tif (dependenciesForBean == null) {\n\t\t\treturn new String[0];\n\t\t}\n\t\tsynchronized (this.dependenciesForBeanMap) {\n\t\t\treturn StringUtils.toStringArray(dependenciesForBean);\n\t\t}\n\t}", "summary_tokens": ["return", "the", "names", "of", "all", "beans", "that", "the", "specified", "bean", "depends", "on", "if", "any"], "project": "spring-framework"}
{"id": 4149, "code": "\tpublic void setLazyInit(boolean lazyInit) {\n\t\tthis.lazyInit = lazyInit;\n\t}", "summary_tokens": ["set", "whether", "to", "lazily", "initialize", "the", "sqlexception", "translator", "for", "this", "accessor", "on", "first", "encounter", "of", "an", "sqlexception"], "project": "spring-framework"}
{"id": 3976, "code": "\tpublic void setDriverClass(Class<? extends Driver> driverClass) {\n\t\tthis.driver = BeanUtils.instantiateClass(driverClass);\n\t}", "summary_tokens": ["specify", "the", "jdbc", "driver", "implementation", "class", "to", "use"], "project": "spring-framework"}
{"id": 6868, "code": "\tpublic void setHeadersCharset(Charset headersCharset) {\n\t\tAssert.notNull(headersCharset, \"HeadersCharset must not be null\");\n\t\tthis.headersCharset = headersCharset;\n\t}", "summary_tokens": ["set", "the", "character", "set", "used", "to", "decode", "headers"], "project": "spring-framework"}
{"id": 7435, "code": "\tpublic void setRemoveSemicolonContent(boolean removeSemicolonContent) {\n\t\tinitUrlPathHelper();\n\t\tthis.urlPathHelper.setRemoveSemicolonContent(removeSemicolonContent);\n\t}", "summary_tokens": ["shortcut", "to", "the", "org"], "project": "spring-framework"}
{"id": 3589, "code": "\tpublic Class<?> getPublicDeclaringClass() {\n\t\tif (!this.computedPublicDeclaringClass) {\n\t\t\tthis.publicDeclaringClass =\n\t\t\t\t\tdiscoverPublicDeclaringClass(this.originalMethod, this.originalMethod.getDeclaringClass());\n\t\t\tthis.computedPublicDeclaringClass = true;\n\t\t}\n\t\treturn this.publicDeclaringClass;\n\t}", "summary_tokens": ["find", "the", "first", "public", "class", "in", "the", "methods", "declaring", "class", "hierarchy", "that", "declares", "this", "method"], "project": "spring-framework"}
{"id": 2168, "code": "\tpublic TypeReference getInstanceTypeReference() {\n\t\tAssert.notNull(this.instance, \"Cannot resolve 'this' for static invocations\");\n\t\treturn TypeReference.of(this.instance.getClass());\n\t}", "summary_tokens": ["return", "the", "type", "reference", "of", "the", "object", "being", "invoked"], "project": "spring-framework"}
{"id": 6682, "code": "\tpublic long getLastModified() {\n\t\treturn getFirstDate(LAST_MODIFIED, false);\n\t}", "summary_tokens": ["return", "the", "time", "the", "resource", "was", "last", "changed", "as", "specified", "by", "the", "last", "modified", "header"], "project": "spring-framework"}
{"id": 7319, "code": "\tpublic void startCallableProcessing(final WebAsyncTask<?> webAsyncTask, Object... processingContext)\n\t\t\tthrows Exception {\n\n\t\tAssert.notNull(webAsyncTask, \"WebAsyncTask must not be null\");\n\t\tAssert.state(this.asyncWebRequest != null, \"AsyncWebRequest must not be null\");\n\n\t\tLong timeout = webAsyncTask.getTimeout();\n\t\tif (timeout != null) {\n\t\t\tthis.asyncWebRequest.setTimeout(timeout);\n\t\t}\n\n\t\tAsyncTaskExecutor executor = webAsyncTask.getExecutor();\n\t\tif (executor != null) {\n\t\t\tthis.taskExecutor = executor;\n\t\t}\n\t\telse {\n\t\t\tlogExecutorWarning();\n\t\t}\n\n\t\tList<CallableProcessingInterceptor> interceptors = new ArrayList<>();\n\t\tinterceptors.add(webAsyncTask.getInterceptor());\n\t\tinterceptors.addAll(this.callableInterceptors.values());\n\t\tinterceptors.add(timeoutCallableInterceptor);\n\n\t\tfinal Callable<?> callable = webAsyncTask.getCallable();\n\t\tfinal CallableInterceptorChain interceptorChain = new CallableInterceptorChain(interceptors);\n\n\t\tthis.asyncWebRequest.addTimeoutHandler(() -> {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Async request timeout for \" + formatRequestUri());\n\t\t\t}\n\t\t\tObject result = interceptorChain.triggerAfterTimeout(this.asyncWebRequest, callable);\n\t\t\tif (result != CallableProcessingInterceptor.RESULT_NONE) {\n\t\t\t\tsetConcurrentResultAndDispatch(result);\n\t\t\t}\n\t\t});\n\n\t\tthis.asyncWebRequest.addErrorHandler(ex -> {\n\t\t\tif (!this.errorHandlingInProgress) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Async request error for \" + formatRequestUri() + \": \" + ex);\n\t\t\t\t}\n\t\t\t\tObject result = interceptorChain.triggerAfterError(this.asyncWebRequest, callable, ex);\n\t\t\t\tresult = (result != CallableProcessingInterceptor.RESULT_NONE ? result : ex);\n\t\t\t\tsetConcurrentResultAndDispatch(result);\n\t\t\t}\n\t\t});\n\n\t\tthis.asyncWebRequest.addCompletionHandler(() ->\n\t\t\t\tinterceptorChain.triggerAfterCompletion(this.asyncWebRequest, callable));\n\n\t\tinterceptorChain.applyBeforeConcurrentHandling(this.asyncWebRequest, callable);\n\t\tstartAsyncProcessing(processingContext);\n\t\ttry {\n\t\t\tFuture<?> future = this.taskExecutor.submit(() -> {\n\t\t\t\tObject result = null;\n\t\t\t\ttry {\n\t\t\t\t\tinterceptorChain.applyPreProcess(this.asyncWebRequest, callable);\n\t\t\t\t\tresult = callable.call();\n\t\t\t\t}\n\t\t\t\tcatch (Throwable ex) {\n\t\t\t\t\tresult = ex;\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\tresult = interceptorChain.applyPostProcess(this.asyncWebRequest, callable, result);\n\t\t\t\t}\n\t\t\t\tsetConcurrentResultAndDispatch(result);\n\t\t\t});\n\t\t\tinterceptorChain.setTaskFuture(future);\n\t\t}\n\t\tcatch (RejectedExecutionException ex) {\n\t\t\tObject result = interceptorChain.applyPostProcess(this.asyncWebRequest, callable, ex);\n\t\t\tsetConcurrentResultAndDispatch(result);\n\t\t\tthrow ex;\n\t\t}\n\t}", "summary_tokens": ["use", "the", "given", "web", "async", "task", "to", "configure", "the", "task", "executor", "as", "well", "as", "the", "timeout", "value", "of", "the", "async", "web", "request", "before", "delegating", "to", "start", "callable", "processing", "callable", "object"], "project": "spring-framework"}
{"id": 6426, "code": "\tpublic final void setTransactionSynchronizationName(String constantName) {\n\t\tsetTransactionSynchronization(constants.asNumber(constantName).intValue());\n\t}", "summary_tokens": ["set", "the", "transaction", "synchronization", "by", "the", "name", "of", "the", "corresponding", "constant", "in", "this", "class", "e"], "project": "spring-framework"}
{"id": 5283, "code": "\tpublic ClassLoader getNewTempClassLoader() {\n\t\tClassLoader tcl = (this.loadTimeWeaver != null ? this.loadTimeWeaver.getThrowawayClassLoader() :\n\t\t\t\tnew SimpleThrowawayClassLoader(this.classLoader));\n\t\tString packageToExclude = getPersistenceProviderPackageName();\n\t\tif (packageToExclude != null && tcl instanceof DecoratingClassLoader) {\n\t\t\t((DecoratingClassLoader) tcl).excludePackage(packageToExclude);\n\t\t}\n\t\treturn tcl;\n\t}", "summary_tokens": ["this", "implementation", "delegates", "to", "the", "load", "time", "weaver", "if", "specified"], "project": "spring-framework"}
{"id": 8145, "code": "\tpublic static <T extends ServerResponse> RouterFunction<T> route(\n\t\t\tRequestPredicate predicate, HandlerFunction<T> handlerFunction) {\n\n\t\treturn new DefaultRouterFunction<>(predicate, handlerFunction);\n\t}", "summary_tokens": ["route", "to", "the", "given", "handler", "function", "if", "the", "given", "request", "predicate", "applies"], "project": "spring-framework"}
{"id": 3662, "code": "\tpublic void setCheckFullyPopulated(boolean checkFullyPopulated) {\n\t\tthis.checkFullyPopulated = checkFullyPopulated;\n\t}", "summary_tokens": ["set", "whether", "we", "re", "strictly", "validating", "that", "all", "bean", "properties", "have", "been", "mapped", "from", "corresponding", "database", "fields"], "project": "spring-framework"}
{"id": 2982, "code": "\tdefault boolean isFile() {\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "whether", "this", "resource", "represents", "a", "file", "in", "a", "file", "system"], "project": "spring-framework"}
{"id": 8974, "code": "\tprotected ServletInvocableHandlerMethod getExceptionHandlerMethod(\n\t\t\t@Nullable HandlerMethod handlerMethod, Exception exception) {\n\n\t\tClass<?> handlerType = null;\n\n\t\tif (handlerMethod != null) {\n\t\t\t\n\t\t\t\n\t\t\thandlerType = handlerMethod.getBeanType();\n\t\t\tExceptionHandlerMethodResolver resolver = this.exceptionHandlerCache.computeIfAbsent(\n\t\t\t\t\thandlerType, ExceptionHandlerMethodResolver::new);\n\t\t\tMethod method = resolver.resolveMethod(exception);\n\t\t\tif (method != null) {\n\t\t\t\treturn new ServletInvocableHandlerMethod(handlerMethod.getBean(), method, this.applicationContext);\n\t\t\t}\n\t\t\t\n\t\t\t\n\t\t\tif (Proxy.isProxyClass(handlerType)) {\n\t\t\t\thandlerType = AopUtils.getTargetClass(handlerMethod.getBean());\n\t\t\t}\n\t\t}\n\n\t\tfor (Map.Entry<ControllerAdviceBean, ExceptionHandlerMethodResolver> entry : this.exceptionHandlerAdviceCache.entrySet()) {\n\t\t\tControllerAdviceBean advice = entry.getKey();\n\t\t\tif (advice.isApplicableToBeanType(handlerType)) {\n\t\t\t\tExceptionHandlerMethodResolver resolver = entry.getValue();\n\t\t\t\tMethod method = resolver.resolveMethod(exception);\n\t\t\t\tif (method != null) {\n\t\t\t\t\treturn new ServletInvocableHandlerMethod(advice.resolveBean(), method, this.applicationContext);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn null;\n\t}", "summary_tokens": ["find", "an", "method", "for", "the", "given", "exception"], "project": "spring-framework"}
{"id": 4425, "code": "\tprotected void invokeListener(Session session, Message message) throws JMSException {\n\t\tObject listener = getMessageListener();\n\n\t\tif (listener instanceof SessionAwareMessageListener) {\n\t\t\tdoInvokeListener((SessionAwareMessageListener) listener, session, message);\n\t\t}\n\t\telse if (listener instanceof MessageListener) {\n\t\t\tdoInvokeListener((MessageListener) listener, message);\n\t\t}\n\t\telse if (listener != null) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Only MessageListener and SessionAwareMessageListener supported: \" + listener);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalStateException(\"No message listener specified - see property 'messageListener'\");\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "specified", "listener", "either", "as", "standard", "jms", "message", "listener", "or", "preferably", "as", "spring", "session", "aware", "message", "listener"], "project": "spring-framework"}
{"id": 2548, "code": "Symbol addConstantDouble(final double value) {\n  return addConstantLongOrDouble(Symbol.CONSTANT_DOUBLE_TAG, Double.doubleToRawLongBits(value));\n}", "summary_tokens": ["adds", "a", "constant", "double", "info", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 1390, "code": "\tprotected final MessageSourceAccessor getMessageSourceAccessor() throws IllegalStateException {\n\t\tif (this.messageSourceAccessor == null && isContextRequired()) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"ApplicationObjectSupport instance [\" + this + \"] does not run in an ApplicationContext\");\n\t\t}\n\t\treturn this.messageSourceAccessor;\n\t}", "summary_tokens": ["return", "a", "message", "source", "accessor", "for", "the", "application", "context", "used", "by", "this", "object", "for", "easy", "message", "access"], "project": "spring-framework"}
{"id": 7997, "code": "\tpublic ResourceChainRegistration addTransformer(ResourceTransformer transformer) {\n\t\tAssert.notNull(transformer, \"The provided ResourceTransformer should not be null\");\n\t\tthis.transformers.add(transformer);\n\t\tif (transformer instanceof CssLinkResourceTransformer) {\n\t\t\tthis.hasCssLinkTransformer = true;\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "resource", "transformer", "to", "the", "chain"], "project": "spring-framework"}
{"id": 8760, "code": "\tdefault String path() {\n\t\treturn requestPath().pathWithinApplication().value();\n\t}", "summary_tokens": ["get", "the", "request", "path"], "project": "spring-framework"}
{"id": 8666, "code": "\tprotected RequestMappingHandlerMapping createRequestMappingHandlerMapping() {\n\t\treturn new RequestMappingHandlerMapping();\n\t}", "summary_tokens": ["protected", "method", "for", "plugging", "in", "a", "custom", "subclass", "of", "request", "mapping", "handler", "mapping"], "project": "spring-framework"}
{"id": 4434, "code": "\tprotected void invokeErrorHandler(Throwable ex) {\n\t\tErrorHandler errorHandler = getErrorHandler();\n\t\tif (errorHandler != null) {\n\t\t\terrorHandler.handleError(ex);\n\t\t}\n\t\telse {\n\t\t\tlogger.warn(\"Execution of JMS message listener failed, and no ErrorHandler has been set.\", ex);\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "registered", "error", "handler", "if", "any"], "project": "spring-framework"}
{"id": 6269, "code": "\tpublic void setTransactionAttributes(Properties transactionAttributes) {\n\t\tNameMatchTransactionAttributeSource tas = new NameMatchTransactionAttributeSource();\n\t\ttas.setProperties(transactionAttributes);\n\t\tthis.transactionAttributeSource = tas;\n\t}", "summary_tokens": ["set", "properties", "with", "method", "names", "as", "keys", "and", "transaction", "attribute", "descriptors", "parsed", "via", "transaction", "attribute", "editor", "as", "values", "e"], "project": "spring-framework"}
{"id": 7457, "code": "\tpublic void setIncludeHeaders(boolean includeHeaders) {\n\t\tthis.includeHeaders = includeHeaders;\n\t}", "summary_tokens": ["set", "whether", "the", "request", "headers", "should", "be", "included", "in", "the", "log", "message"], "project": "spring-framework"}
{"id": 8564, "code": "\tprivate static void registerLocaleResolver(ParserContext context, @Nullable Object source) {\n\t\tif (!containsBeanInHierarchy(context, DispatcherServlet.LOCALE_RESOLVER_BEAN_NAME)) {\n\t\t\tRootBeanDefinition beanDef = new RootBeanDefinition(AcceptHeaderLocaleResolver.class);\n\t\t\tbeanDef.setSource(source);\n\t\t\tbeanDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\t\tcontext.getRegistry().registerBeanDefinition(DispatcherServlet.LOCALE_RESOLVER_BEAN_NAME, beanDef);\n\t\t\tcontext.registerComponent(new BeanComponentDefinition(beanDef, DispatcherServlet.LOCALE_RESOLVER_BEAN_NAME));\n\t\t}\n\t}", "summary_tokens": ["registers", "an", "accept", "header", "locale", "resolver", "under", "a", "well", "known", "name", "unless", "already", "registered"], "project": "spring-framework"}
{"id": 2639, "code": "public int cardinality() {\n    int w = value;\n    int c = 0;\n    while (w != 0) {\n        c += T[w & 255];\n        w >>= 8;\n    }\n    return c;\n}", "summary_tokens": ["if", "bit", "0", "is", "set", "then", "this", "method", "results", "in", "an", "infinite", "loop"], "project": "spring-framework"}
{"id": 7455, "code": "\tpublic void setIncludeClientInfo(boolean includeClientInfo) {\n\t\tthis.includeClientInfo = includeClientInfo;\n\t}", "summary_tokens": ["set", "whether", "the", "client", "address", "and", "session", "id", "should", "be", "included", "in", "the", "log", "message"], "project": "spring-framework"}
{"id": 4364, "code": "\tpublic String getClientId() {\n\t\treturn this.clientId;\n\t}", "summary_tokens": ["return", "the", "jms", "client", "id", "for", "the", "shared", "connection", "created", "and", "used", "by", "this", "container", "if", "any"], "project": "spring-framework"}
{"id": 3435, "code": "\tprivate int commentToken(String line, String token, boolean inCommentIfPresent) {\n\t\tint index = line.indexOf(token);\n\t\tif (index > - 1) {\n\t\t\tthis.inComment = inCommentIfPresent;\n\t\t}\n\t\treturn (index == -1 ? index : index + token.length());\n\t}", "summary_tokens": ["try", "to", "consume", "the", "supplied", "token", "against", "the", "supplied", "content", "and", "update", "the", "in", "comment", "parse", "state", "to", "the", "supplied", "value"], "project": "spring-framework"}
{"id": 764, "code": "\tpublic Set<String> getExternallyManagedInitMethods() {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\treturn (this.externallyManagedInitMethods != null ?\n\t\t\t\t\tCollections.unmodifiableSet(new LinkedHashSet<>(this.externallyManagedInitMethods)) :\n\t\t\t\t\tCollections.emptySet());\n\t\t}\n\t}", "summary_tokens": ["return", "all", "externally", "managed", "initialization", "methods", "as", "an", "immutable", "set"], "project": "spring-framework"}
{"id": 8122, "code": "\tpublic static RequestPredicate methods(HttpMethod... httpMethods) {\n\t\treturn new HttpMethodPredicate(httpMethods);\n\t}", "summary_tokens": ["return", "a", "request", "predicate", "that", "matches", "if", "the", "request", "s", "http", "method", "is", "equal", "to", "one", "the", "of", "the", "given", "methods"], "project": "spring-framework"}
{"id": 7382, "code": "\tprotected ResourcePatternResolver getResourcePatternResolver() {\n\t\treturn new ServletContextResourcePatternResolver(this);\n\t}", "summary_tokens": ["this", "implementation", "supports", "pattern", "matching", "in", "unexpanded", "wars", "too"], "project": "spring-framework"}
{"id": 4247, "code": "\tpublic void setMethod(@Nullable Method method) {\n\t\tthis.method = method;\n\t}", "summary_tokens": ["set", "the", "method", "to", "invoke", "for", "processing", "a", "message", "managed", "by", "this", "endpoint"], "project": "spring-framework"}
{"id": 4706, "code": "\tpublic void setArgumentResolvers(@Nullable List<HandlerMethodArgumentResolver> argumentResolvers) {\n\t\tif (argumentResolvers == null) {\n\t\t\tthis.argumentResolvers.clear();\n\t\t\treturn;\n\t\t}\n\t\tthis.argumentResolvers.addResolvers(argumentResolvers);\n\t}", "summary_tokens": ["configure", "the", "complete", "list", "of", "supported", "argument", "types", "effectively", "overriding", "the", "ones", "configured", "by", "default"], "project": "spring-framework"}
{"id": 8655, "code": "\tpublic UrlBasedViewResolverRegistration jsp(String prefix, String suffix) {\n\t\tInternalResourceViewResolver resolver = new InternalResourceViewResolver();\n\t\tresolver.setPrefix(prefix);\n\t\tresolver.setSuffix(suffix);\n\t\tthis.viewResolvers.add(resolver);\n\t\treturn new UrlBasedViewResolverRegistration(resolver);\n\t}", "summary_tokens": ["register", "jsp", "view", "resolver", "with", "the", "specified", "prefix", "and", "suffix"], "project": "spring-framework"}
{"id": 1051, "code": "\tpublic JobDataMap getJobDataMap() {\n\t\treturn this.jobDataMap;\n\t}", "summary_tokens": ["return", "the", "trigger", "s", "job", "data", "map"], "project": "spring-framework"}
{"id": 3319, "code": "\tpublic static String unqualify(String qualifiedName, char separator) {\n\t\treturn qualifiedName.substring(qualifiedName.lastIndexOf(separator) + 1);\n\t}", "summary_tokens": ["unqualify", "a", "string", "qualified", "by", "a", "separator", "character"], "project": "spring-framework"}
{"id": 2859, "code": "\tprotected boolean suppressGetenvAccess() {\n\t\treturn SpringProperties.getFlag(IGNORE_GETENV_PROPERTY_NAME);\n\t}", "summary_tokens": ["determine", "whether", "to", "suppress", "system", "getenv", "system", "getenv", "string", "access", "for", "the", "purposes", "of", "get", "system", "environment"], "project": "spring-framework"}
{"id": 5984, "code": "\tpublic ResultMatcher handlerType(Class<?> type) {\n\t\treturn result -> {\n\t\t\tObject handler = result.getHandler();\n\t\t\tassertNotNull(\"No handler\", handler);\n\t\t\tClass<?> actual = handler.getClass();\n\t\t\tif (handler instanceof HandlerMethod) {\n\t\t\t\tactual = ((HandlerMethod) handler).getBeanType();\n\t\t\t}\n\t\t\tassertEquals(\"Handler type\", type, ClassUtils.getUserClass(actual));\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "type", "of", "the", "handler", "that", "processed", "the", "request"], "project": "spring-framework"}
{"id": 810, "code": "\tpublic void setAutowire(@Nullable String autowire) {\n\t\tthis.autowire = autowire;\n\t}", "summary_tokens": ["set", "the", "default", "autowire", "setting", "for", "the", "document", "that", "s", "currently", "parsed"], "project": "spring-framework"}
{"id": 5597, "code": "\tpublic void setSqlScriptEncoding(String sqlScriptEncoding) {\n\t\tthis.sqlScriptEncoding = sqlScriptEncoding;\n\t}", "summary_tokens": ["specify", "the", "encoding", "for", "sql", "scripts", "if", "different", "from", "the", "platform", "encoding"], "project": "spring-framework"}
{"id": 4308, "code": "\tprotected Connection getTransactionAwareConnectionProxy(Connection target) {\n\t\tList<Class<?>> classes = new ArrayList<>(3);\n\t\tclasses.add(Connection.class);\n\t\tif (target instanceof QueueConnection) {\n\t\t\tclasses.add(QueueConnection.class);\n\t\t}\n\t\tif (target instanceof TopicConnection) {\n\t\t\tclasses.add(TopicConnection.class);\n\t\t}\n\t\treturn (Connection) Proxy.newProxyInstance(Connection.class.getClassLoader(),\n\t\t\t\tClassUtils.toClassArray(classes), new TransactionAwareConnectionInvocationHandler(target));\n\t}", "summary_tokens": ["wrap", "the", "given", "connection", "with", "a", "proxy", "that", "delegates", "every", "method", "call", "to", "it", "but", "handles", "session", "lookup", "in", "a", "transaction", "aware", "fashion"], "project": "spring-framework"}
{"id": 8020, "code": "\tpublic void order(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "for", "the", "org"], "project": "spring-framework"}
{"id": 5723, "code": "\tprotected int deleteFromTableWhere(String tableName, String whereClause, Object... args) {\n\t\treturn JdbcTestUtils.deleteFromTableWhere(this.jdbcTemplate, tableName, whereClause, args);\n\t}", "summary_tokens": ["convenience", "method", "for", "deleting", "all", "rows", "from", "the", "given", "table", "using", "the", "provided", "where", "clause"], "project": "spring-framework"}
{"id": 4265, "code": "\tpublic void setTargetConnectionFactory(@Nullable ConnectionFactory targetConnectionFactory) {\n\t\tthis.targetConnectionFactory = targetConnectionFactory;\n\t}", "summary_tokens": ["set", "the", "target", "connection", "factory", "that", "this", "connection", "factory", "should", "delegate", "to"], "project": "spring-framework"}
{"id": 949, "code": "\tprotected ListableBeanFactory getListableBeanFactory() {\n\t\tBeanFactory bf = getBeanFactory();\n\t\tif (!(bf instanceof ListableBeanFactory)) {\n\t\t\tthrow new IllegalStateException(\"ListableBeanFactory required\");\n\t\t}\n\t\treturn (ListableBeanFactory) bf;\n\t}", "summary_tokens": ["subclasses", "must", "initialize", "this"], "project": "spring-framework"}
{"id": 3102, "code": "\tpublic static void hasLength(@Nullable String text) {\n\t\thasLength(text,\n\t\t\t\t\"[Assertion failed] - this String argument must have length; it must not be null or empty\");\n\t}", "summary_tokens": ["assert", "that", "the", "given", "string", "is", "not", "empty", "that", "is", "it", "must", "not", "be", "null", "and", "not", "the", "empty", "string"], "project": "spring-framework"}
{"id": 1614, "code": "\tprotected boolean includeReadAttribute(Method method, String beanKey) {\n\t\treturn hasManagedAttribute(method) || hasManagedMetric(method);\n\t}", "summary_tokens": ["vote", "on", "the", "inclusion", "of", "an", "attribute", "accessor"], "project": "spring-framework"}
{"id": 3756, "code": "\tpublic boolean isSupportsCatalogsInProcedureCalls() {\n\t\treturn this.supportsCatalogsInProcedureCalls;\n\t}", "summary_tokens": ["does", "the", "database", "support", "the", "use", "of", "catalog", "name", "in", "procedure", "calls"], "project": "spring-framework"}
{"id": 2747, "code": "\tpublic static ReactiveTypeDescriptor nonDeferredAsyncValue(Class<?> type, Supplier<?> emptySupplier) {\n\t\treturn new ReactiveTypeDescriptor(type, false, false, emptySupplier, false);\n\t}", "summary_tokens": ["the", "same", "as", "single", "optional", "value", "class", "supplier", "but", "for", "a", "non", "deferred", "async", "type", "such", "as", "java"], "project": "spring-framework"}
{"id": 8404, "code": "\tpublic Configuration getConfiguration() {\n\t\tAssert.state(this.configuration != null, \"No Configuration available\");\n\t\treturn this.configuration;\n\t}", "summary_tokens": ["return", "the", "configuration", "object", "wrapped", "by", "this", "bean"], "project": "spring-framework"}
{"id": 2457, "code": "private void addForwardReference(\n    final int sourceInsnBytecodeOffset, final int referenceType, final int referenceHandle) {\n  if (forwardReferences == null) {\n    forwardReferences = new int[FORWARD_REFERENCES_CAPACITY_INCREMENT];\n  }\n  int lastElementIndex = forwardReferences[0];\n  if (lastElementIndex + 2 >= forwardReferences.length) {\n    int[] newValues = new int[forwardReferences.length + FORWARD_REFERENCES_CAPACITY_INCREMENT];\n    System.arraycopy(forwardReferences, 0, newValues, 0, forwardReferences.length);\n    forwardReferences = newValues;\n  }\n  forwardReferences[++lastElementIndex] = sourceInsnBytecodeOffset;\n  forwardReferences[++lastElementIndex] = referenceType | referenceHandle;\n  forwardReferences[0] = lastElementIndex;\n}", "summary_tokens": ["adds", "a", "forward", "reference", "to", "this", "label"], "project": "spring-framework"}
{"id": 7865, "code": "\tpublic String getOriginatingServletPath(HttpServletRequest request) {\n\t\tString servletPath = (String) request.getAttribute(WebUtils.FORWARD_SERVLET_PATH_ATTRIBUTE);\n\t\tif (servletPath == null) {\n\t\t\tservletPath = request.getServletPath();\n\t\t}\n\t\treturn servletPath;\n\t}", "summary_tokens": ["return", "the", "servlet", "path", "for", "the", "given", "request", "detecting", "an", "include", "request", "url", "if", "called", "within", "a", "request", "dispatcher", "include"], "project": "spring-framework"}
{"id": 9275, "code": "\tprotected void renderFromBodyContent(BodyContent bodyContent, TagWriter tagWriter) throws JspException {\n\t\tflushBufferedBodyContent(bodyContent);\n\t}", "summary_tokens": ["render", "the", "tag", "contents", "based", "on", "the", "supplied", "body", "content"], "project": "spring-framework"}
{"id": 2606, "code": "public int getFormalParameterIndex() {\n  return (targetTypeAndInfo & 0x00FF0000) >> 16;\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "formal", "parameter", "whose", "type", "is", "referenced", "by", "this", "type", "reference"], "project": "spring-framework"}
{"id": 8701, "code": "\tprotected final void addDefaultHttpMessageConverters(List<HttpMessageConverter<?>> messageConverters) {\n\t\tmessageConverters.add(new ByteArrayHttpMessageConverter());\n\t\tmessageConverters.add(new StringHttpMessageConverter());\n\t\tmessageConverters.add(new ResourceHttpMessageConverter());\n\t\tmessageConverters.add(new ResourceRegionHttpMessageConverter());\n\t\tif (!shouldIgnoreXml) {\n\t\t\ttry {\n\t\t\t\tmessageConverters.add(new SourceHttpMessageConverter<>());\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\t\tmessageConverters.add(new AllEncompassingFormHttpMessageConverter());\n\n\t\tif (romePresent) {\n\t\t\tmessageConverters.add(new AtomFeedHttpMessageConverter());\n\t\t\tmessageConverters.add(new RssChannelHttpMessageConverter());\n\t\t}\n\n\t\tif (!shouldIgnoreXml) {\n\t\t\tif (jackson2XmlPresent) {\n\t\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.xml();\n\t\t\t\tif (this.applicationContext != null) {\n\t\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t\t}\n\t\t\t\tmessageConverters.add(new MappingJackson2XmlHttpMessageConverter(builder.build()));\n\t\t\t}\n\t\t\telse if (jaxb2Present) {\n\t\t\t\tmessageConverters.add(new Jaxb2RootElementHttpMessageConverter());\n\t\t\t}\n\t\t}\n\n\t\tif (kotlinSerializationJsonPresent) {\n\t\t\tmessageConverters.add(new KotlinSerializationJsonHttpMessageConverter());\n\t\t}\n\t\tif (jackson2Present) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.json();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2HttpMessageConverter(builder.build()));\n\t\t}\n\t\telse if (gsonPresent) {\n\t\t\tmessageConverters.add(new GsonHttpMessageConverter());\n\t\t}\n\t\telse if (jsonbPresent) {\n\t\t\tmessageConverters.add(new JsonbHttpMessageConverter());\n\t\t}\n\n\t\tif (jackson2SmilePresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.smile();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2SmileHttpMessageConverter(builder.build()));\n\t\t}\n\t\tif (jackson2CborPresent) {\n\t\t\tJackson2ObjectMapperBuilder builder = Jackson2ObjectMapperBuilder.cbor();\n\t\t\tif (this.applicationContext != null) {\n\t\t\t\tbuilder.applicationContext(this.applicationContext);\n\t\t\t}\n\t\t\tmessageConverters.add(new MappingJackson2CborHttpMessageConverter(builder.build()));\n\t\t}\n\t}", "summary_tokens": ["adds", "a", "set", "of", "default", "http", "message", "converter", "instances", "to", "the", "given", "list"], "project": "spring-framework"}
{"id": 2699, "code": "\tpublic Set<Object> getValuesForSuffix(@Nullable String nameSuffix) {\n\t\tString suffixToUse = (nameSuffix != null ? nameSuffix.trim().toUpperCase(Locale.ENGLISH) : \"\");\n\t\tSet<Object> values = new HashSet<>();\n\t\tthis.fieldCache.forEach((code, value) -> {\n\t\t\tif (code.endsWith(suffixToUse)) {\n\t\t\t\tvalues.add(value);\n\t\t\t}\n\t\t});\n\t\treturn values;\n\t}", "summary_tokens": ["return", "all", "values", "of", "the", "given", "group", "of", "constants"], "project": "spring-framework"}
{"id": 5513, "code": "\tdefault void publishEvent(Function<TestContext, ? extends ApplicationEvent> eventFactory) {\n\t\tif (hasApplicationContext()) {\n\t\t\tgetApplicationContext().publishEvent(eventFactory.apply(this));\n\t\t}\n\t}", "summary_tokens": ["publish", "the", "application", "event", "created", "by", "the", "given", "event", "factory", "to", "the", "application", "context", "application", "context", "for", "this", "test", "context"], "project": "spring-framework"}
{"id": 3088, "code": "\tpublic void setTrimTokens(boolean trimTokens) {\n\t\tthis.trimTokens = trimTokens;\n\t}", "summary_tokens": ["specify", "whether", "to", "trim", "tokenized", "paths", "and", "patterns"], "project": "spring-framework"}
{"id": 4959, "code": "\tpublic TcpOperations<byte[]> getTcpClient() {\n\t\treturn this.tcpClient;\n\t}", "summary_tokens": ["get", "the", "configured", "tcp", "client", "never", "null", "unless", "not", "configured", "invoked", "and", "this", "method", "is", "invoked", "before", "the", "handler", "is", "started", "and", "hence", "a", "default", "implementation", "initialized"], "project": "spring-framework"}
{"id": 3275, "code": "\tpublic void setKeepTaskList(boolean keepTaskList) {\n\t\tthis.keepTaskList = keepTaskList;\n\t}", "summary_tokens": ["configure", "whether", "the", "task", "info", "array", "is", "built", "over", "time"], "project": "spring-framework"}
{"id": 5438, "code": "\tpublic byte[] getBodyAsBytes() {\n\t\treturn this.body.toByteArray();\n\t}", "summary_tokens": ["return", "body", "content", "as", "a", "byte", "array"], "project": "spring-framework"}
{"id": 9624, "code": "\tpublic void setAttributesMap(@Nullable Map<String, ?> attributes) {\n\t\tif (attributes != null) {\n\t\t\tthis.staticAttributes.putAll(attributes);\n\t\t}\n\t}", "summary_tokens": ["set", "static", "attributes", "from", "a", "map", "for", "all", "views", "returned", "by", "this", "resolver"], "project": "spring-framework"}
{"id": 1012, "code": "\tpublic void setMappingLocation(Resource mappingLocation) {\n\t\tthis.mappingLocation = mappingLocation;\n\t}", "summary_tokens": ["specify", "the", "resource", "from", "which", "mappings", "are", "loaded"], "project": "spring-framework"}
{"id": 6394, "code": "\tdefault Mono<Void> afterCompletion(int status) {\n\t\treturn Mono.empty();\n\t}", "summary_tokens": ["invoked", "after", "transaction", "commit", "rollback"], "project": "spring-framework"}
{"id": 9137, "code": "\tpublic String getContextUrl(String relativeUrl, Map<String, ?> params) {\n\t\tString url = getContextPath() + relativeUrl;\n\t\turl = UriComponentsBuilder.fromUriString(url).buildAndExpand(params).encode().toUri().toASCIIString();\n\t\tif (this.response != null) {\n\t\t\turl = this.response.encodeURL(url);\n\t\t}\n\t\treturn url;\n\t}", "summary_tokens": ["return", "a", "context", "aware", "url", "for", "the", "given", "relative", "url", "with", "placeholders", "named", "keys", "with", "braces"], "project": "spring-framework"}
{"id": 9420, "code": "\tpublic void setFor(String forId) {\n\t\tthis.forId = forId;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "for", "attribute"], "project": "spring-framework"}
{"id": 6089, "code": "\tpublic ResultMatcher isUriTooLong() {\n\t\treturn matcher(HttpStatus.URI_TOO_LONG);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2380, "code": "public void visitSource(final String source, final String debug) {\n  if (cv != null) {\n    cv.visitSource(source, debug);\n  }\n}", "summary_tokens": ["visits", "the", "source", "of", "the", "class"], "project": "spring-framework"}
{"id": 9630, "code": "\tpublic void setViewNames(@Nullable String... viewNames) {\n\t\tthis.viewNames = viewNames;\n\t}", "summary_tokens": ["set", "the", "view", "names", "or", "name", "patterns", "that", "can", "be", "handled", "by", "this", "org"], "project": "spring-framework"}
{"id": 7325, "code": "\tpublic void onTimeout(Callable<V> callback) {\n\t\tthis.timeoutCallback = callback;\n\t}", "summary_tokens": ["register", "code", "to", "invoke", "when", "the", "async", "request", "times", "out"], "project": "spring-framework"}
{"id": 3678, "code": "\tpublic void addParameter(SqlParameter param) {\n\t\tthis.declaredParameters.add(param);\n\t}", "summary_tokens": ["add", "a", "new", "declared", "parameter"], "project": "spring-framework"}
{"id": 4778, "code": "\tpublic void addCustomHandler(HandlerMethodReturnValueHandler... handlers) {\n\t\tAssert.notNull(handlers, \"'handlers' must not be null\");\n\t\tthis.customHandlers.addAll(Arrays.asList(handlers));\n\t}", "summary_tokens": ["configure", "custom", "return", "value", "handlers", "for", "handler", "methods"], "project": "spring-framework"}
{"id": 1434, "code": "\tpublic void setFileEncodings(Properties fileEncodings) {\n\t\tthis.fileEncodings = fileEncodings;\n\t}", "summary_tokens": ["set", "per", "file", "charsets", "to", "use", "for", "parsing", "properties", "files"], "project": "spring-framework"}
{"id": 6643, "code": "\tpublic List<String> getAccessControlRequestHeaders() {\n\t\treturn getValuesAsList(ACCESS_CONTROL_REQUEST_HEADERS);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "access", "control", "request", "headers", "request", "header"], "project": "spring-framework"}
{"id": 7449, "code": "\tprotected List<HttpMethod> checkMethods(CorsConfiguration config, @Nullable HttpMethod requestMethod) {\n\t\treturn config.checkHttpMethod(requestMethod);\n\t}", "summary_tokens": ["check", "the", "http", "method", "and", "determine", "the", "methods", "for", "the", "response", "of", "a", "pre", "flight", "request"], "project": "spring-framework"}
{"id": 3190, "code": "\tpublic static <K, V> MultiValueMap<K, V> toMultiValueMap(Map<K, List<V>> targetMap) {\n\t\treturn new MultiValueMapAdapter<>(targetMap);\n\t}", "summary_tokens": ["adapt", "a", "map", "k", "list", "v", "to", "an", "multi", "value", "map", "k", "v"], "project": "spring-framework"}
{"id": 9537, "code": "\tpublic void setExposeContextBeansAsAttributes(boolean exposeContextBeansAsAttributes) {\n\t\tthis.exposeContextBeansAsAttributes = exposeContextBeansAsAttributes;\n\t}", "summary_tokens": ["set", "whether", "to", "make", "all", "spring", "beans", "in", "the", "application", "context", "accessible", "as", "request", "attributes", "through", "lazy", "checking", "once", "an", "attribute", "gets", "accessed"], "project": "spring-framework"}
{"id": 8605, "code": "\tprotected Object getInterceptor() {\n\n\t\tif (this.includePatterns == null && this.excludePatterns == null) {\n\t\t\treturn this.interceptor;\n\t\t}\n\n\t\tMappedInterceptor mappedInterceptor = new MappedInterceptor(\n\t\t\t\tStringUtils.toStringArray(this.includePatterns),\n\t\t\t\tStringUtils.toStringArray(this.excludePatterns),\n\t\t\t\tthis.interceptor);\n\n\t\tif (this.pathMatcher != null) {\n\t\t\tmappedInterceptor.setPathMatcher(this.pathMatcher);\n\t\t}\n\n\t\treturn mappedInterceptor;\n\t}", "summary_tokens": ["build", "the", "underlying", "interceptor"], "project": "spring-framework"}
{"id": 2530, "code": "int getConstantPoolCount() {\n  return constantPoolCount;\n}", "summary_tokens": ["returns", "the", "number", "of", "items", "in", "this", "symbol", "table", "s", "constant", "pool", "array", "plus", "0"], "project": "spring-framework"}
{"id": 222, "code": "\tprotected boolean matchesExclusion(String candidate, int patternIndex) {\n\t\tMatcher matcher = this.compiledExclusionPatterns[patternIndex].matcher(candidate);\n\t\treturn matcher.matches();\n\t}", "summary_tokens": ["returns", "true", "if", "the", "exclusion", "pattern", "at", "index", "pattern", "index", "matches", "the", "supplied", "candidate", "string"], "project": "spring-framework"}
{"id": 6261, "code": "\tpublic List<RollbackRuleAttribute> getRollbackRules() {\n\t\tif (this.rollbackRules == null) {\n\t\t\tthis.rollbackRules = new ArrayList<>();\n\t\t}\n\t\treturn this.rollbackRules;\n\t}", "summary_tokens": ["return", "the", "list", "of", "rollback", "rule", "attribute", "objects", "never", "null"], "project": "spring-framework"}
{"id": 2093, "code": "\tpublic void testInnerBeanTargetUsingAutowiring() {\n\t\tDefaultListableBeanFactory bf = new DefaultListableBeanFactory();\n\t\tnew XmlBeanDefinitionReader(bf).loadBeanDefinitions(new ClassPathResource(AUTOWIRING_CONTEXT, CLASS));\n\t\tbf.getBean(\"testBean\");\n\t}", "summary_tokens": ["simple", "test", "of", "a", "proxy", "factory", "bean", "that", "has", "an", "inner", "bean", "as", "target", "that", "specifies", "autowiring"], "project": "spring-framework"}
{"id": 68, "code": "\tpublic void setTarget(Object target) {\n\t\tthis.target = target;\n\t}", "summary_tokens": ["set", "the", "target", "object", "that", "is", "the", "bean", "to", "be", "wrapped", "with", "a", "transactional", "proxy"], "project": "spring-framework"}
{"id": 3050, "code": "\tpublic static String style(Object value) {\n\t\treturn DEFAULT_VALUE_STYLER.style(value);\n\t}", "summary_tokens": ["style", "the", "specified", "value", "according", "to", "default", "conventions"], "project": "spring-framework"}
{"id": 7666, "code": "\tpublic List<MediaType> getSupportedMediaTypes() {\n\t\treturn this.supportedMediaTypes;\n\t}", "summary_tokens": ["return", "the", "list", "of", "supported", "content", "types", "in", "cases", "when", "the", "accept", "header", "is", "parsed", "but", "not", "supported", "or", "an", "empty", "list", "otherwise"], "project": "spring-framework"}
{"id": 2498, "code": "private void computeMaxStackAndLocal() {\n    \n  Handler handler = firstHandler;\n  while (handler != null) {\n    Label handlerBlock = handler.handlerPc;\n    Label handlerRangeBlock = handler.startPc;\n    Label handlerRangeEnd = handler.endPc;\n      \n    while (handlerRangeBlock != handlerRangeEnd) {\n      if ((handlerRangeBlock.flags & Label.FLAG_SUBROUTINE_CALLER) == 0) {\n        handlerRangeBlock.outgoingEdges =\n            new Edge(Edge.EXCEPTION, handlerBlock, handlerRangeBlock.outgoingEdges);\n      } else {\n          \n          \n          \n        handlerRangeBlock.outgoingEdges.nextEdge.nextEdge =\n            new Edge(\n                Edge.EXCEPTION, handlerBlock, handlerRangeBlock.outgoingEdges.nextEdge.nextEdge);\n      }\n      handlerRangeBlock = handlerRangeBlock.nextBasicBlock;\n    }\n    handler = handler.nextHandler;\n  }\n\n    \n  if (hasSubroutines) {\n      \n      \n    short numSubroutines = 1;\n    firstBasicBlock.markSubroutine(numSubroutines);\n      \n      \n    for (short currentSubroutine = 1; currentSubroutine <= numSubroutines; ++currentSubroutine) {\n      Label basicBlock = firstBasicBlock;\n      while (basicBlock != null) {\n        if ((basicBlock.flags & Label.FLAG_SUBROUTINE_CALLER) != 0\n            && basicBlock.subroutineId == currentSubroutine) {\n          Label jsrTarget = basicBlock.outgoingEdges.nextEdge.successor;\n          if (jsrTarget.subroutineId == 0) {\n              \n            jsrTarget.markSubroutine(++numSubroutines);\n          }\n        }\n        basicBlock = basicBlock.nextBasicBlock;\n      }\n    }\n      \n      \n      \n    Label basicBlock = firstBasicBlock;\n    while (basicBlock != null) {\n      if ((basicBlock.flags & Label.FLAG_SUBROUTINE_CALLER) != 0) {\n          \n          \n        Label subroutine = basicBlock.outgoingEdges.nextEdge.successor;\n        subroutine.addSubroutineRetSuccessors(basicBlock);\n      }\n      basicBlock = basicBlock.nextBasicBlock;\n    }\n  }\n\n    \n    \n    \n    \n  Label listOfBlocksToProcess = firstBasicBlock;\n  listOfBlocksToProcess.nextListElement = Label.EMPTY_LIST;\n  int maxStackSize = maxStack;\n  while (listOfBlocksToProcess != Label.EMPTY_LIST) {\n      \n      \n      \n    Label basicBlock = listOfBlocksToProcess;\n    listOfBlocksToProcess = listOfBlocksToProcess.nextListElement;\n      \n    int inputStackTop = basicBlock.inputStackSize;\n    int maxBlockStackSize = inputStackTop + basicBlock.outputStackMax;\n      \n    if (maxBlockStackSize > maxStackSize) {\n      maxStackSize = maxBlockStackSize;\n    }\n      \n      \n    Edge outgoingEdge = basicBlock.outgoingEdges;\n    if ((basicBlock.flags & Label.FLAG_SUBROUTINE_CALLER) != 0) {\n        \n        \n        \n        \n      outgoingEdge = outgoingEdge.nextEdge;\n    }\n    while (outgoingEdge != null) {\n      Label successorBlock = outgoingEdge.successor;\n      if (successorBlock.nextListElement == null) {\n        successorBlock.inputStackSize =\n            (short) (outgoingEdge.info == Edge.EXCEPTION ? 1 : inputStackTop + outgoingEdge.info);\n        successorBlock.nextListElement = listOfBlocksToProcess;\n        listOfBlocksToProcess = successorBlock;\n      }\n      outgoingEdge = outgoingEdge.nextEdge;\n    }\n  }\n  this.maxStack = maxStackSize;\n}", "summary_tokens": ["computes", "the", "maximum", "stack", "size", "of", "the", "method"], "project": "spring-framework"}
{"id": 3750, "code": "\tpublic int getParameterType() {\n\t\treturn this.parameterType;\n\t}", "summary_tokens": ["return", "the", "parameter", "type"], "project": "spring-framework"}
{"id": 8575, "code": "\tpublic ContentNegotiationConfigurer favorParameter(boolean favorParameter) {\n\t\tthis.factory.setFavorParameter(favorParameter);\n\t\treturn this;\n\t}", "summary_tokens": ["whether", "a", "request", "parameter", "format", "by", "default", "should", "be", "used", "to", "determine", "the", "requested", "media", "type"], "project": "spring-framework"}
{"id": 9206, "code": "\tprotected boolean isResponseEncodedHtmlEscape() {\n\t\treturn getRequestContext().isResponseEncodedHtmlEscape();\n\t}", "summary_tokens": ["return", "the", "applicable", "default", "for", "the", "use", "of", "response", "encoding", "with", "html", "escaping", "for", "this", "tag"], "project": "spring-framework"}
{"id": 4666, "code": "\tpublic void setReceiveTimeoutHeader(String receiveTimeoutHeader) {\n\t\tAssert.notNull(receiveTimeoutHeader, \"'receiveTimeoutHeader' cannot be null\");\n\t\tthis.receiveTimeoutHeader = receiveTimeoutHeader;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "header", "used", "to", "determine", "the", "send", "timeout", "if", "present"], "project": "spring-framework"}
{"id": 9522, "code": "\tpublic String getUrl() {\n\t\treturn this.url;\n\t}", "summary_tokens": ["return", "the", "url", "of", "the", "resource", "that", "this", "view", "wraps"], "project": "spring-framework"}
{"id": 8603, "code": "\tpublic InterceptorRegistration order(int order){\n\t\tthis.order = order;\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "an", "order", "position", "to", "be", "used"], "project": "spring-framework"}
{"id": 1001, "code": "\tpublic KeyGenerator getKeyGenerator() {\n\t\treturn this.keyGenerator.obtain();\n\t}", "summary_tokens": ["return", "the", "specified", "key", "generator", "to", "use"], "project": "spring-framework"}
{"id": 7709, "code": "\tpublic WebHttpHandlerBuilder sessionManager(WebSessionManager manager) {\n\t\tthis.sessionManager = manager;\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "the", "web", "session", "manager", "to", "set", "on", "the", "server", "web", "exchange", "web", "server", "exchange"], "project": "spring-framework"}
{"id": 6119, "code": "\tprivate ResultMatcher matcher(HttpStatusCode status) {\n\t\treturn result -> assertEquals(\"Status\", status.value(), result.getResponse().getStatus());\n\t}", "summary_tokens": ["match", "the", "expected", "response", "status", "to", "that", "of", "the", "http", "servlet", "response"], "project": "spring-framework"}
{"id": 6832, "code": "\tpublic boolean isEnableLoggingRequestDetails() {\n\t\treturn this.enableLoggingRequestDetails;\n\t}", "summary_tokens": ["whether", "any", "logging", "of", "values", "being", "encoded", "or", "decoded", "is", "explicitly", "disabled", "regardless", "of", "log", "level"], "project": "spring-framework"}
{"id": 8950, "code": "\tprotected <T> void writeWithMessageConverters(@Nullable T value, MethodParameter returnType,\n\t\t\tServletServerHttpRequest inputMessage, ServletServerHttpResponse outputMessage)\n\t\t\tthrows IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException {\n\n\t\tObject body;\n\t\tClass<?> valueType;\n\t\tType targetType;\n\n\t\tif (value instanceof CharSequence) {\n\t\t\tbody = value.toString();\n\t\t\tvalueType = String.class;\n\t\t\ttargetType = String.class;\n\t\t}\n\t\telse {\n\t\t\tbody = value;\n\t\t\tvalueType = getReturnValueType(body, returnType);\n\t\t\ttargetType = GenericTypeResolver.resolveType(getGenericType(returnType), returnType.getContainingClass());\n\t\t}\n\n\t\tif (isResourceType(value, returnType)) {\n\t\t\toutputMessage.getHeaders().set(HttpHeaders.ACCEPT_RANGES, \"bytes\");\n\t\t\tif (value != null && inputMessage.getHeaders().getFirst(HttpHeaders.RANGE) != null &&\n\t\t\t\t\toutputMessage.getServletResponse().getStatus() == 200) {\n\t\t\t\tResource resource = (Resource) value;\n\t\t\t\ttry {\n\t\t\t\t\tList<HttpRange> httpRanges = inputMessage.getHeaders().getRange();\n\t\t\t\t\toutputMessage.getServletResponse().setStatus(HttpStatus.PARTIAL_CONTENT.value());\n\t\t\t\t\tbody = HttpRange.toResourceRegions(httpRanges, resource);\n\t\t\t\t\tvalueType = body.getClass();\n\t\t\t\t\ttargetType = RESOURCE_REGION_LIST_TYPE;\n\t\t\t\t}\n\t\t\t\tcatch (IllegalArgumentException ex) {\n\t\t\t\t\toutputMessage.getHeaders().set(HttpHeaders.CONTENT_RANGE, \"bytes */\" + resource.contentLength());\n\t\t\t\t\toutputMessage.getServletResponse().setStatus(HttpStatus.REQUESTED_RANGE_NOT_SATISFIABLE.value());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tMediaType selectedMediaType = null;\n\t\tMediaType contentType = outputMessage.getHeaders().getContentType();\n\t\tboolean isContentTypePreset = contentType != null && contentType.isConcrete();\n\t\tif (isContentTypePreset) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Found 'Content-Type:\" + contentType + \"' in response\");\n\t\t\t}\n\t\t\tselectedMediaType = contentType;\n\t\t}\n\t\telse {\n\t\t\tHttpServletRequest request = inputMessage.getServletRequest();\n\t\t\tList<MediaType> acceptableTypes;\n\t\t\ttry {\n\t\t\t\tacceptableTypes = getAcceptableMediaTypes(request);\n\t\t\t}\n\t\t\tcatch (HttpMediaTypeNotAcceptableException ex) {\n\t\t\t\tint series = outputMessage.getServletResponse().getStatus() / 100;\n\t\t\t\tif (body == null || series == 4 || series == 5) {\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Ignoring error response content (if any). \" + ex);\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tthrow ex;\n\t\t\t}\n\n\t\t\tList<MediaType> producibleTypes = getProducibleMediaTypes(request, valueType, targetType);\n\t\t\tif (body != null && producibleTypes.isEmpty()) {\n\t\t\t\tthrow new HttpMessageNotWritableException(\n\t\t\t\t\t\t\"No converter found for return value of type: \" + valueType);\n\t\t\t}\n\n\t\t\tList<MediaType> compatibleMediaTypes = new ArrayList<>();\n\t\t\tdetermineCompatibleMediaTypes(acceptableTypes, producibleTypes, compatibleMediaTypes);\n\n\t\t\t\n\t\t\tif (compatibleMediaTypes.isEmpty() && ProblemDetail.class.isAssignableFrom(valueType)) {\n\t\t\t\tdetermineCompatibleMediaTypes(this.problemMediaTypes, producibleTypes, compatibleMediaTypes);\n\t\t\t}\n\n\t\t\tif (compatibleMediaTypes.isEmpty()) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"No match for \" + acceptableTypes + \", supported: \" + producibleTypes);\n\t\t\t\t}\n\t\t\t\tif (body != null) {\n\t\t\t\t\tthrow new HttpMediaTypeNotAcceptableException(producibleTypes);\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tMimeTypeUtils.sortBySpecificity(compatibleMediaTypes);\n\n\t\t\tfor (MediaType mediaType : compatibleMediaTypes) {\n\t\t\t\tif (mediaType.isConcrete()) {\n\t\t\t\t\tselectedMediaType = mediaType;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\telse if (mediaType.isPresentIn(ALL_APPLICATION_MEDIA_TYPES)) {\n\t\t\t\t\tselectedMediaType = MediaType.APPLICATION_OCTET_STREAM;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Using '\" + selectedMediaType + \"', given \" +\n\t\t\t\t\t\tacceptableTypes + \" and supported \" + producibleTypes);\n\t\t\t}\n\t\t}\n\n\t\tif (selectedMediaType != null) {\n\t\t\tselectedMediaType = selectedMediaType.removeQualityValue();\n\t\t\tfor (HttpMessageConverter<?> converter : this.messageConverters) {\n\t\t\t\tGenericHttpMessageConverter genericConverter = (converter instanceof GenericHttpMessageConverter ?\n\t\t\t\t\t\t(GenericHttpMessageConverter<?>) converter : null);\n\t\t\t\tif (genericConverter != null ?\n\t\t\t\t\t\t((GenericHttpMessageConverter) converter).canWrite(targetType, valueType, selectedMediaType) :\n\t\t\t\t\t\tconverter.canWrite(valueType, selectedMediaType)) {\n\t\t\t\t\tbody = getAdvice().beforeBodyWrite(body, returnType, selectedMediaType,\n\t\t\t\t\t\t\t(Class<? extends HttpMessageConverter<?>>) converter.getClass(),\n\t\t\t\t\t\t\tinputMessage, outputMessage);\n\t\t\t\t\tif (body != null) {\n\t\t\t\t\t\tObject theBody = body;\n\t\t\t\t\t\tLogFormatUtils.traceDebug(logger, traceOn ->\n\t\t\t\t\t\t\t\t\"Writing [\" + LogFormatUtils.formatValue(theBody, !traceOn) + \"]\");\n\t\t\t\t\t\taddContentDispositionHeader(inputMessage, outputMessage);\n\t\t\t\t\t\tif (genericConverter != null) {\n\t\t\t\t\t\t\tgenericConverter.write(body, targetType, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t((HttpMessageConverter) converter).write(body, selectedMediaType, outputMessage);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"Nothing to write: null body\");\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (body != null) {\n\t\t\tSet<MediaType> producibleMediaTypes =\n\t\t\t\t\t(Set<MediaType>) inputMessage.getServletRequest()\n\t\t\t\t\t\t\t.getAttribute(HandlerMapping.PRODUCIBLE_MEDIA_TYPES_ATTRIBUTE);\n\n\t\t\tif (isContentTypePreset || !CollectionUtils.isEmpty(producibleMediaTypes)) {\n\t\t\t\tthrow new HttpMessageNotWritableException(\n\t\t\t\t\t\t\"No converter for [\" + valueType + \"] with preset Content-Type '\" + contentType + \"'\");\n\t\t\t}\n\t\t\tthrow new HttpMediaTypeNotAcceptableException(getSupportedMediaTypes(body.getClass()));\n\t\t}\n\t}", "summary_tokens": ["writes", "the", "given", "return", "type", "to", "the", "given", "output", "message"], "project": "spring-framework"}
{"id": 2653, "code": "\tpublic Class createClass() {\n\t\tclassOnly = true;\n\t\treturn (Class) createHelper();\n\t}", "summary_tokens": ["generate", "a", "new", "class", "if", "necessary", "and", "return", "it", "without", "creating", "a", "new", "instance"], "project": "spring-framework"}
{"id": 821, "code": "\tpublic BeanDefinitionHolder decorate(\n\t\t\tNode node, BeanDefinitionHolder definition, ParserContext parserContext) {\n\n\t\tBeanDefinitionDecorator decorator = findDecoratorForNode(node, parserContext);\n\t\treturn (decorator != null ? decorator.decorate(node, definition, parserContext) : null);\n\t}", "summary_tokens": ["decorates", "the", "supplied", "node", "by", "delegating", "to", "the", "bean", "definition", "decorator", "that", "is", "registered", "to", "handle", "that", "node"], "project": "spring-framework"}
{"id": 6022, "code": "\tpublic static ContentResultMatchers content() {\n\t\treturn new ContentResultMatchers();\n\t}", "summary_tokens": ["access", "to", "response", "body", "assertions"], "project": "spring-framework"}
{"id": 4244, "code": "\tprotected MessageListenerContainer createListenerContainer(JmsListenerEndpoint endpoint,\n\t\t\tJmsListenerContainerFactory<?> factory) {\n\n\t\tMessageListenerContainer listenerContainer = factory.createListenerContainer(endpoint);\n\n\t\tif (listenerContainer instanceof InitializingBean) {\n\t\t\ttry {\n\t\t\t\t((InitializingBean) listenerContainer).afterPropertiesSet();\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tthrow new BeanInitializationException(\"Failed to initialize message listener container\", ex);\n\t\t\t}\n\t\t}\n\n\t\tint containerPhase = listenerContainer.getPhase();\n\t\tif (containerPhase < Integer.MAX_VALUE) {  \n\t\t\tif (this.phase < Integer.MAX_VALUE && this.phase != containerPhase) {\n\t\t\t\tthrow new IllegalStateException(\"Encountered phase mismatch between container factory definitions: \" +\n\t\t\t\t\t\tthis.phase + \" vs \" + containerPhase);\n\t\t\t}\n\t\t\tthis.phase = listenerContainer.getPhase();\n\t\t}\n\n\t\treturn listenerContainer;\n\t}", "summary_tokens": ["create", "and", "start", "a", "new", "container", "using", "the", "specified", "factory"], "project": "spring-framework"}
{"id": 2305, "code": "public void visitEnum(final String name, final String descriptor, final String value) {\n  if (av != null) {\n    av.visitEnum(name, descriptor, value);\n  }\n}", "summary_tokens": ["visits", "an", "enumeration", "value", "of", "the", "annotation"], "project": "spring-framework"}
{"id": 5701, "code": "\tprivate void addAll(boolean prepend, List<String> list, String... elements) {\n\t\tlist.addAll((prepend ? 0 : list.size()), Arrays.asList(elements));\n\t}", "summary_tokens": ["add", "all", "the", "supplied", "elements", "to", "the", "provided", "list", "honoring", "the", "prepend", "flag"], "project": "spring-framework"}
{"id": 2644, "code": "\tpublic void setInterfaces(Class[] interfaces) {\n\t\tthis.interfaces = interfaces;\n\t}", "summary_tokens": ["set", "the", "interfaces", "to", "implement"], "project": "spring-framework"}
{"id": 9003, "code": "\tpublic void setContentNegotiationManager(ContentNegotiationManager contentNegotiationManager) {\n\t\tAssert.notNull(contentNegotiationManager, \"ContentNegotiationManager must not be null\");\n\t\tthis.contentNegotiationManager = contentNegotiationManager;\n\t}", "summary_tokens": ["set", "the", "content", "negotiation", "manager", "to", "use", "to", "determine", "requested", "media", "types"], "project": "spring-framework"}
{"id": 4519, "code": "\tprivate Object invokeHandler(jakarta.jms.Message jmsMessage, @Nullable Session session, Message<?> message) {\n\t\tInvocableHandlerMethod handlerMethod = getHandlerMethod();\n\t\ttry {\n\t\t\treturn handlerMethod.invoke(message, jmsMessage, session);\n\t\t}\n\t\tcatch (MessagingException ex) {\n\t\t\tthrow new ListenerExecutionFailedException(\n\t\t\t\t\tcreateMessagingErrorMessage(\"Listener method could not be invoked with incoming message\"), ex);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthrow new ListenerExecutionFailedException(\"Listener method '\" +\n\t\t\t\t\thandlerMethod.getMethod().toGenericString() + \"' threw exception\", ex);\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "handler", "wrapping", "any", "exception", "to", "a", "listener", "execution", "failed", "exception", "with", "a", "dedicated", "error", "message"], "project": "spring-framework"}
{"id": 1807, "code": "\tpublic void setJndiTemplate(JndiTemplate jndiTemplate) {\n\t\tthis.jndiLocator.setJndiTemplate(jndiTemplate);\n\t}", "summary_tokens": ["set", "the", "jndi", "template", "to", "use", "for", "jndi", "lookups"], "project": "spring-framework"}
{"id": 2805, "code": "\tstatic Search search(SearchStrategy searchStrategy) {\n\t\tAssert.notNull(searchStrategy, \"SearchStrategy must not be null\");\n\t\treturn new Search(searchStrategy);\n\t}", "summary_tokens": ["find", "merged", "annotations", "using", "the", "supplied", "search", "strategy", "and", "a", "fluent", "api", "for", "configuring", "and", "performing", "the", "search"], "project": "spring-framework"}
{"id": 4050, "code": "\tpublic void setDataSources(@Nullable Map<String, DataSource> dataSources) {\n\t\tif (dataSources != null) {\n\t\t\tthis.dataSources.putAll(dataSources);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "map", "of", "data", "source", "data", "sources", "the", "keys", "are", "string", "strings", "the", "values", "are", "actual", "data", "source", "instances"], "project": "spring-framework"}
{"id": 9711, "code": "\tpublic void setRenderFunction(@Nullable String renderFunction) {\n\t\tthis.renderFunction = renderFunction;\n\t}", "summary_tokens": ["set", "the", "render", "function", "name", "optional"], "project": "spring-framework"}
{"id": 3636, "code": "\tvoid customStaticFunctions_SPR9038() {\n\t\tExpressionParser parser = new SpelExpressionParser();\n\t\tStandardEvaluationContext context = new StandardEvaluationContext();\n\t\tList<MethodResolver> methodResolvers = new ArrayList<>();\n\t\tmethodResolvers.add(new ReflectiveMethodResolver() {\n\t\t\t@Override\n\t\t\tprotected Method[] getMethods(Class<?> type) {\n\t\t\t\ttry {\n\t\t\t\t\treturn new Method[] {Integer.class.getDeclaredMethod(\"parseInt\", String.class, Integer.TYPE)};\n\t\t\t\t}\n\t\t\t\tcatch (NoSuchMethodException ex) {\n\t\t\t\t\treturn new Method[0];\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\n\t\tcontext.setMethodResolvers(methodResolvers);\n\t\tExpression expression = parser.parseExpression(\"parseInt('-FF', 16)\");\n\n\t\tInteger result = expression.getValue(context, \"\", Integer.class);\n\t\tassertThat(result.intValue()).isEqualTo(-255);\n\t}", "summary_tokens": ["test", "the", "ability", "to", "subclass", "the", "reflective", "method", "resolver", "and", "change", "how", "it", "determines", "the", "set", "of", "methods", "for", "a", "type"], "project": "spring-framework"}
{"id": 4970, "code": "\tpublic void setDefaultHeartbeat(long[] heartbeat) {\n\t\tif (heartbeat.length != 2 || heartbeat[0] < 0 || heartbeat[1] < 0) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid heart-beat: \" + Arrays.toString(heartbeat));\n\t\t}\n\t\tthis.defaultHeartbeat = heartbeat;\n\t}", "summary_tokens": ["configure", "the", "default", "value", "for", "the", "heart", "beat", "header", "of", "the", "stomp", "connect", "frame"], "project": "spring-framework"}
{"id": 1215, "code": "\tpublic void setCacheNames(Collection<String> cacheNames) {\n\t\tthis.cacheNames = cacheNames;\n\t}", "summary_tokens": ["set", "the", "cache", "name", "s", "that", "this", "resolver", "should", "use"], "project": "spring-framework"}
{"id": 1124, "code": "\tpublic void setWaitForJobsToCompleteOnShutdown(boolean waitForJobsToCompleteOnShutdown) {\n\t\tthis.waitForJobsToCompleteOnShutdown = waitForJobsToCompleteOnShutdown;\n\t}", "summary_tokens": ["set", "whether", "to", "wait", "for", "running", "jobs", "to", "complete", "on", "shutdown"], "project": "spring-framework"}
{"id": 7120, "code": "\tpublic void setFavorPathExtension(boolean favorPathExtension) {\n\t\tthis.favorPathExtension = favorPathExtension;\n\t}", "summary_tokens": ["whether", "the", "path", "extension", "in", "the", "url", "path", "should", "be", "used", "to", "determine", "the", "requested", "media", "type"], "project": "spring-framework"}
{"id": 172, "code": "\tpublic void setHideProxyClassNames(boolean hideProxyClassNames) {\n\t\tthis.hideProxyClassNames = hideProxyClassNames;\n\t}", "summary_tokens": ["set", "to", "true", "to", "have", "set", "use", "dynamic", "logger", "dynamic", "loggers", "hide", "proxy", "class", "names", "wherever", "possible"], "project": "spring-framework"}
{"id": 5919, "code": "\tvoid setDefaultResponseCharacterEncoding(@Nullable Charset defaultResponseCharacterEncoding) {\n\t\tthis.defaultResponseCharacterEncoding = defaultResponseCharacterEncoding;\n\t}", "summary_tokens": ["the", "default", "character", "encoding", "to", "be", "applied", "to", "every", "response"], "project": "spring-framework"}
{"id": 9473, "code": "\tprivate static boolean typeRequiresMultiple(Class<?> type) {\n\t\treturn (type.isArray() || Collection.class.isAssignableFrom(type) || Map.class.isAssignableFrom(type));\n\t}", "summary_tokens": ["returns", "true", "for", "arrays", "collection", "collections", "and", "map", "maps"], "project": "spring-framework"}
{"id": 3736, "code": "\tpublic void setNamedBinding(boolean namedBinding) {\n\t\tthis.namedBinding = namedBinding;\n\t}", "summary_tokens": ["specify", "whether", "parameters", "should", "be", "bound", "by", "name"], "project": "spring-framework"}
{"id": 1811, "code": "\tpublic void setThreadFactory(@Nullable ThreadFactory threadFactory) {\n\t\tthis.threadFactory = (threadFactory != null ? threadFactory : this);\n\t}", "summary_tokens": ["set", "the", "thread", "factory", "to", "use", "for", "the", "executor", "service", "s", "thread", "pool"], "project": "spring-framework"}
{"id": 8506, "code": "\tprotected <T> T getDefaultStrategy(ApplicationContext context, Class<T> strategyInterface) {\n\t\tList<T> strategies = getDefaultStrategies(context, strategyInterface);\n\t\tif (strategies.size() != 1) {\n\t\t\tthrow new BeanInitializationException(\n\t\t\t\t\t\"DispatcherServlet needs exactly 1 strategy for interface [\" + strategyInterface.getName() + \"]\");\n\t\t}\n\t\treturn strategies.get(0);\n\t}", "summary_tokens": ["return", "the", "default", "strategy", "object", "for", "the", "given", "strategy", "interface"], "project": "spring-framework"}
{"id": 4475, "code": "\tpublic final int getScheduledConsumerCount() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\treturn this.scheduledInvokers.size();\n\t\t}\n\t}", "summary_tokens": ["return", "the", "number", "of", "currently", "scheduled", "consumers"], "project": "spring-framework"}
{"id": 1204, "code": "\tpublic EvaluationContext createEvaluationContext(Collection<? extends Cache> caches,\n\t\t\tMethod method, Object[] args, Object target, Class<?> targetClass, Method targetMethod,\n\t\t\t@Nullable Object result, @Nullable BeanFactory beanFactory) {\n\n\t\tCacheExpressionRootObject rootObject = new CacheExpressionRootObject(\n\t\t\t\tcaches, method, args, target, targetClass);\n\t\tCacheEvaluationContext evaluationContext = new CacheEvaluationContext(\n\t\t\t\trootObject, targetMethod, args, getParameterNameDiscoverer());\n\t\tif (result == RESULT_UNAVAILABLE) {\n\t\t\tevaluationContext.addUnavailableVariable(RESULT_VARIABLE);\n\t\t}\n\t\telse if (result != NO_RESULT) {\n\t\t\tevaluationContext.setVariable(RESULT_VARIABLE, result);\n\t\t}\n\t\tif (beanFactory != null) {\n\t\t\tevaluationContext.setBeanResolver(new BeanFactoryResolver(beanFactory));\n\t\t}\n\t\treturn evaluationContext;\n\t}", "summary_tokens": ["create", "an", "evaluation", "context"], "project": "spring-framework"}
{"id": 3674, "code": "\tprotected void initBeanWrapper(BeanWrapper bw) {\n\t\tConversionService cs = getConversionService();\n\t\tif (cs != null) {\n\t\t\tbw.setConversionService(cs);\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "given", "bean", "wrapper", "to", "be", "used", "for", "row", "mapping"], "project": "spring-framework"}
{"id": 5628, "code": "\tprivate Statement withProfileValueCheck(Statement next, Class<?> testClass) {\n\t\treturn new ProfileValueChecker(next, testClass, null);\n\t}", "summary_tokens": ["wrap", "the", "supplied", "statement", "with", "a", "profile", "value", "checker", "statement"], "project": "spring-framework"}
{"id": 7286, "code": "\tdefault <T> void afterCompletion(NativeWebRequest request, Callable<T> task) throws Exception {\n\t}", "summary_tokens": ["invoked", "from", "a", "container", "thread", "when", "async", "processing", "completes", "for", "any", "reason", "including", "timeout", "or", "network", "error"], "project": "spring-framework"}
{"id": 7256, "code": "\tprotected void registerContextLoaderListener(ServletContext servletContext) {\n\t\tWebApplicationContext rootAppContext = createRootApplicationContext();\n\t\tif (rootAppContext != null) {\n\t\t\tContextLoaderListener listener = new ContextLoaderListener(rootAppContext);\n\t\t\tlistener.setContextInitializers(getRootApplicationContextInitializers());\n\t\t\tservletContext.addListener(listener);\n\t\t}\n\t\telse {\n\t\t\tlogger.debug(\"No ContextLoaderListener registered, as \" +\n\t\t\t\t\t\"createRootApplicationContext() did not return an application context\");\n\t\t}\n\t}", "summary_tokens": ["register", "a", "context", "loader", "listener", "against", "the", "given", "servlet", "context"], "project": "spring-framework"}
{"id": 1056, "code": "\tpublic void setTimeZone(TimeZone timeZone) {\n\t\tthis.timeZone = timeZone;\n\t}", "summary_tokens": ["specify", "the", "time", "zone", "for", "this", "trigger", "s", "cron", "expression"], "project": "spring-framework"}
{"id": 1785, "code": "\tpublic void setAsyncAnnotationType(Class<? extends Annotation> asyncAnnotationType) {\n\t\tAssert.notNull(asyncAnnotationType, \"'asyncAnnotationType' must not be null\");\n\t\tthis.asyncAnnotationType = asyncAnnotationType;\n\t}", "summary_tokens": ["set", "the", "async", "annotation", "type", "to", "be", "detected", "at", "either", "class", "or", "method", "level"], "project": "spring-framework"}
{"id": 3957, "code": "\tpublic ConnectionHolder getConnectionHolder() {\n\t\tAssert.state(this.connectionHolder != null, \"No ConnectionHolder available\");\n\t\treturn this.connectionHolder;\n\t}", "summary_tokens": ["return", "the", "connection", "holder", "for", "this", "transaction", "object"], "project": "spring-framework"}
{"id": 6074, "code": "\tpublic ResultMatcher isBadRequest() {\n\t\treturn matcher(HttpStatus.BAD_REQUEST);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 3501, "code": "\tpublic void exitCompilationScope() {\n\t\tthis.compilationScopes.pop();\n\t}", "summary_tokens": ["exit", "a", "compilation", "scope", "usually", "after", "a", "nested", "expression", "has", "been", "evaluated"], "project": "spring-framework"}
{"id": 8237, "code": "\tpublic int compareTo(PatternsRequestCondition other, ServerWebExchange exchange) {\n\t\tIterator<PathPattern> iterator = this.patterns.iterator();\n\t\tIterator<PathPattern> iteratorOther = other.getPatterns().iterator();\n\t\twhile (iterator.hasNext() && iteratorOther.hasNext()) {\n\t\t\tint result = PathPattern.SPECIFICITY_COMPARATOR.compare(iterator.next(), iteratorOther.next());\n\t\t\tif (result != 0) {\n\t\t\t\treturn result;\n\t\t\t}\n\t\t}\n\t\tif (iterator.hasNext()) {\n\t\t\treturn -1;\n\t\t}\n\t\telse if (iteratorOther.hasNext()) {\n\t\t\treturn 1;\n\t\t}\n\t\telse {\n\t\t\treturn 0;\n\t\t}\n\t}", "summary_tokens": ["compare", "the", "two", "conditions", "based", "on", "the", "url", "patterns", "they", "contain"], "project": "spring-framework"}
{"id": 5319, "code": "\tpublic final Object unmarshal(Source source) throws IOException, XmlMappingException {\n\t\tif (source instanceof DOMSource) {\n\t\t\treturn unmarshalDomSource((DOMSource) source);\n\t\t}\n\t\telse if (StaxUtils.isStaxSource(source)) {\n\t\t\treturn unmarshalStaxSource(source);\n\t\t}\n\t\telse if (source instanceof SAXSource) {\n\t\t\treturn unmarshalSaxSource((SAXSource) source);\n\t\t}\n\t\telse if (source instanceof StreamSource) {\n\t\t\treturn unmarshalStreamSource((StreamSource) source);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\"Unknown Source type: \" + source.getClass());\n\t\t}\n\t}", "summary_tokens": ["unmarshals", "the", "given", "provided", "javax"], "project": "spring-framework"}
{"id": 5373, "code": "\tpublic void setScripts(Resource... scripts) {\n\t\tassertContentsOfScriptArray(scripts);\n\t\t\n\t\tthis.scripts = new ArrayList<>(Arrays.asList(scripts));\n\t}", "summary_tokens": ["set", "the", "scripts", "to", "execute", "to", "initialize", "or", "clean", "up", "the", "database", "replacing", "any", "previously", "added", "scripts"], "project": "spring-framework"}
{"id": 2945, "code": "\tpublic File getFile() {\n\t\treturn (this.file != null ? this.file : this.filePath.toFile());\n\t}", "summary_tokens": ["this", "implementation", "returns", "the", "underlying", "file", "reference"], "project": "spring-framework"}
{"id": 6333, "code": "\tprotected Object doJtaSuspend(JtaTransactionObject txObject) throws SystemException {\n\t\tif (getTransactionManager() == null) {\n\t\t\tthrow new TransactionSuspensionNotSupportedException(\n\t\t\t\t\t\"JtaTransactionManager needs a JTA TransactionManager for suspending a transaction: \" +\n\t\t\t\t\t\"specify the 'transactionManager' or 'transactionManagerName' property\");\n\t\t}\n\t\treturn getTransactionManager().suspend();\n\t}", "summary_tokens": ["perform", "a", "jta", "suspend", "on", "the", "jta", "transaction", "manager"], "project": "spring-framework"}
{"id": 3348, "code": "\tpublic void updateMessageDigest(MessageDigest messageDigest, int len) throws IOException {\n\t\tint data;\n\t\tint bytesRead = 0;\n\t\twhile (bytesRead < len && (data = read()) != -1) {\n\t\t\tmessageDigest.update((byte) data);\n\t\t\tbytesRead++;\n\t\t}\n\t}", "summary_tokens": ["update", "the", "message", "digest", "with", "the", "next", "len", "bytes", "in", "this", "stream"], "project": "spring-framework"}
{"id": 1700, "code": "\tpublic final MBeanServer getServer() {\n\t\treturn this.server;\n\t}", "summary_tokens": ["return", "the", "mbean", "server", "that", "the", "beans", "will", "be", "registered", "with"], "project": "spring-framework"}
{"id": 4623, "code": "\tvoid testSendDestinationName() throws Exception {\n\t\tdoTestSendDestination(false, false, true, false);\n\t}", "summary_tokens": ["test", "sending", "to", "a", "destination", "using", "the", "method", "send", "string", "d", "message", "creator", "message", "creator"], "project": "spring-framework"}
{"id": 7904, "code": "\tprotected void doTestTony(PropertyValues pvs) throws Exception {\n\t\tassertThat(pvs.getPropertyValues().length == 3).as(\"Contains 3\").isTrue();\n\t\tassertThat(pvs.contains(\"forname\")).as(\"Contains forname\").isTrue();\n\t\tassertThat(pvs.contains(\"surname\")).as(\"Contains surname\").isTrue();\n\t\tassertThat(pvs.contains(\"age\")).as(\"Contains age\").isTrue();\n\t\tboolean condition1 = !pvs.contains(\"tory\");\n\t\tassertThat(condition1).as(\"Doesn't contain tory\").isTrue();\n\n\t\tPropertyValue[] pvArray = pvs.getPropertyValues();\n\t\tMap<String, String> m = new HashMap<>();\n\t\tm.put(\"forname\", \"Tony\");\n\t\tm.put(\"surname\", \"Blair\");\n\t\tm.put(\"age\", \"50\");\n\t\tfor (PropertyValue pv : pvArray) {\n\t\t\tObject val = m.get(pv.getName());\n\t\t\tassertThat(val != null).as(\"Can't have unexpected value\").isTrue();\n\t\t\tboolean condition = val instanceof String;\n\t\t\tassertThat(condition).as(\"Val i string\").isTrue();\n\t\t\tassertThat(val.equals(pv.getValue())).as(\"val matches expected\").isTrue();\n\t\t\tm.remove(pv.getName());\n\t\t}\n\t\tassertThat(m.size() == 0).as(\"Map size is 0\").isTrue();\n\t}", "summary_tokens": ["must", "contain", "forname", "tony", "surname", "blair", "age", "0"], "project": "spring-framework"}
{"id": 3113, "code": "\tpublic static byte[] decodeUrlSafe(byte[] src) {\n\t\tif (src.length == 0) {\n\t\t\treturn src;\n\t\t}\n\t\treturn Base64.getUrlDecoder().decode(src);\n\t}", "summary_tokens": ["base", "0", "decode", "the", "given", "byte", "array", "using", "the", "rfc", "0", "url", "and", "filename", "safe", "alphabet"], "project": "spring-framework"}
{"id": 6494, "code": "\tpublic boolean equals(@Nullable Object other) {\n\t\treturn (this == other || (other instanceof TransactionDefinition && toString().equals(other.toString())));\n\t}", "summary_tokens": ["this", "implementation", "compares", "the", "to", "string", "results"], "project": "spring-framework"}
{"id": 7338, "code": "\tpublic void setScopeMetadataResolver(@Nullable ScopeMetadataResolver scopeMetadataResolver) {\n\t\tthis.scopeMetadataResolver = scopeMetadataResolver;\n\t}", "summary_tokens": ["set", "a", "custom", "scope", "metadata", "resolver", "for", "use", "with", "annotated", "bean", "definition", "reader", "and", "or", "class", "path", "bean", "definition", "scanner"], "project": "spring-framework"}
{"id": 7693, "code": "\tpublic void setCodecConfigurer(ServerCodecConfigurer codecConfigurer) {\n\t\tAssert.notNull(codecConfigurer, \"ServerCodecConfigurer is required\");\n\t\tthis.codecConfigurer = codecConfigurer;\n\n\t\tthis.enableLoggingRequestDetails = false;\n\t\tthis.codecConfigurer.getReaders().stream()\n\t\t\t\t.filter(LoggingCodecSupport.class::isInstance)\n\t\t\t\t.forEach(reader -> {\n\t\t\t\t\tif (((LoggingCodecSupport) reader).isEnableLoggingRequestDetails()) {\n\t\t\t\t\t\tthis.enableLoggingRequestDetails = true;\n\t\t\t\t\t}\n\t\t\t\t});\n\t}", "summary_tokens": ["configure", "a", "custom", "server", "codec", "configurer"], "project": "spring-framework"}
{"id": 8649, "code": "\tpublic RedirectViewControllerRegistration addRedirectViewController(String urlPath, String redirectUrl) {\n\t\tRedirectViewControllerRegistration registration = new RedirectViewControllerRegistration(urlPath, redirectUrl);\n\t\tregistration.setApplicationContext(this.applicationContext);\n\t\tthis.redirectRegistrations.add(registration);\n\t\treturn registration;\n\t}", "summary_tokens": ["map", "a", "view", "controller", "to", "the", "given", "url", "path", "or", "pattern", "in", "order", "to", "redirect", "to", "another", "url"], "project": "spring-framework"}
{"id": 6204, "code": "\tpublic void setActivationSpec(@Nullable ActivationSpec activationSpec) {\n\t\tthis.activationSpec = activationSpec;\n\t}", "summary_tokens": ["set", "the", "jca", "activation", "spec", "to", "use", "for", "activating", "the", "endpoint"], "project": "spring-framework"}
{"id": 7406, "code": "\tpublic void addAllowedOriginPattern(@Nullable String originPattern) {\n\t\tif (originPattern == null) {\n\t\t\treturn;\n\t\t}\n\t\tif (this.allowedOriginPatterns == null) {\n\t\t\tthis.allowedOriginPatterns = new ArrayList<>(4);\n\t\t}\n\t\toriginPattern = trimTrailingSlash(originPattern);\n\t\tthis.allowedOriginPatterns.add(new OriginPattern(originPattern));\n\t\tif (this.allowedOrigins == DEFAULT_PERMIT_ALL) {\n\t\t\tthis.allowedOrigins = null;\n\t\t}\n\t}", "summary_tokens": ["variant", "of", "set", "allowed", "origin", "patterns", "for", "adding", "one", "origin", "at", "a", "time"], "project": "spring-framework"}
{"id": 6536, "code": "\tdefault void beforeCommit(boolean readOnly) {\n\t}", "summary_tokens": ["invoked", "before", "transaction", "commit", "before", "before", "completion"], "project": "spring-framework"}
{"id": 1766, "code": "\tpublic void setShareableResources(String... shareableResources) {\n\t\tCollections.addAll(this.shareableResources, shareableResources);\n\t}", "summary_tokens": ["set", "a", "list", "of", "names", "of", "shareable", "jndi", "resources", "which", "this", "factory", "is", "allowed", "to", "cache", "once", "obtained"], "project": "spring-framework"}
{"id": 5839, "code": "\tpublic static RequestMatcher headerDoesNotExist(String name) {\n\t\treturn request -> {\n\t\t\tList<String> headerValues = request.getHeaders().get(name);\n\t\t\tif (headerValues != null) {\n\t\t\t\tfail(\"Expected header <\" + name + \"> not to exist, but it exists with values: \" +\n\t\t\t\t\t\theaderValues);\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["assert", "that", "the", "given", "request", "header", "does", "not", "exist"], "project": "spring-framework"}
{"id": 9443, "code": "\tprivate String getDisplayString(@Nullable Object value) {\n\t\tPropertyEditor editor = (value != null ? this.bindStatus.findEditor(value.getClass()) : null);\n\t\treturn ValueFormatter.getDisplayString(value, editor, this.htmlEscape);\n\t}", "summary_tokens": ["determine", "the", "display", "value", "of", "the", "supplied", "object", "html", "escaped", "as", "required"], "project": "spring-framework"}
{"id": 8988, "code": "\tpublic UriComponentsBuilder withMethodName(Class<?> controllerType, String methodName, Object... args) {\n\t\treturn fromMethodName(this.baseUrl, controllerType, methodName, args);\n\t}", "summary_tokens": ["an", "alternative", "to", "from", "method", "name", "class", "string", "object"], "project": "spring-framework"}
{"id": 2319, "code": "final int getAttributeCount() {\n  int count = 0;\n  Attribute attribute = this;\n  while (attribute != null) {\n    count += 1;\n    attribute = attribute.nextAttribute;\n  }\n  return count;\n}", "summary_tokens": ["returns", "the", "number", "of", "attributes", "of", "the", "attribute", "list", "that", "begins", "with", "this", "attribute"], "project": "spring-framework"}
{"id": 2468, "code": "public AnnotationVisitor visitAnnotationDefault() {\n  if (mv != null) {\n    return mv.visitAnnotationDefault();\n  }\n  return null;\n}", "summary_tokens": ["visits", "the", "default", "value", "of", "this", "annotation", "interface", "method"], "project": "spring-framework"}
{"id": 65, "code": "\tpublic void setMethodName(String methodName) {\n\t\tthis.methodName = methodName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "method", "to", "locate"], "project": "spring-framework"}
{"id": 2980, "code": "\tdefault boolean isReadable() {\n\t\treturn exists();\n\t}", "summary_tokens": ["indicate", "whether", "non", "empty", "contents", "of", "this", "resource", "can", "be", "read", "via", "get", "input", "stream"], "project": "spring-framework"}
{"id": 9100, "code": "\tpublic Class<?> getValueType() {\n\t\treturn this.valueType;\n\t}", "summary_tokens": ["get", "the", "class", "type", "of", "the", "field"], "project": "spring-framework"}
{"id": 4905, "code": "\tpublic StompBrokerRelayRegistration setClientLogin(String login) {\n\t\tAssert.hasText(login, \"clientLogin must not be empty\");\n\t\tthis.clientLogin = login;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "login", "to", "use", "when", "creating", "connections", "to", "the", "stomp", "broker", "on", "behalf", "of", "connected", "clients"], "project": "spring-framework"}
{"id": 7868, "code": "\tpublic String decodeRequestString(HttpServletRequest request, String source) {\n\t\tif (this.urlDecode) {\n\t\t\treturn decodeInternal(request, source);\n\t\t}\n\t\treturn source;\n\t}", "summary_tokens": ["decode", "the", "given", "source", "string", "with", "a", "urldecoder"], "project": "spring-framework"}
{"id": 7408, "code": "\tpublic List<String> getAllowedMethods() {\n\t\treturn this.allowedMethods;\n\t}", "summary_tokens": ["return", "the", "allowed", "http", "methods", "or", "null", "in", "which", "case", "only", "get", "and", "head", "allowed"], "project": "spring-framework"}
{"id": 4459, "code": "\tpublic void setConcurrentConsumers(int concurrentConsumers) {\n\t\tAssert.isTrue(concurrentConsumers > 0, \"'concurrentConsumers' value must be at least 1 (one)\");\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tthis.concurrentConsumers = concurrentConsumers;\n\t\t\tif (this.maxConcurrentConsumers < concurrentConsumers) {\n\t\t\t\tthis.maxConcurrentConsumers = concurrentConsumers;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["specify", "the", "number", "of", "concurrent", "consumers", "to", "create"], "project": "spring-framework"}
{"id": 2037, "code": "\tpublic static void rejectIfEmptyOrWhitespace(\n\t\t\tErrors errors, String field, String errorCode, @Nullable Object[] errorArgs, @Nullable String defaultMessage) {\n\n\t\tAssert.notNull(errors, \"Errors object must not be null\");\n\t\tObject value = errors.getFieldValue(field);\n\t\tif (value == null ||!StringUtils.hasText(value.toString())) {\n\t\t\terrors.rejectValue(field, errorCode, errorArgs, defaultMessage);\n\t\t}\n\t}", "summary_tokens": ["reject", "the", "given", "field", "with", "the", "given", "error", "code", "error", "arguments", "and", "default", "message", "if", "the", "value", "is", "empty", "or", "just", "contains", "whitespace"], "project": "spring-framework"}
{"id": 8295, "code": "\tpublic SessionAttributesHandler getSessionAttributesHandler(HandlerMethod handlerMethod) {\n\t\tClass<?> handlerType = handlerMethod.getBeanType();\n\t\tSessionAttributesHandler result = this.sessionAttributesHandlerCache.get(handlerType);\n\t\tif (result == null) {\n\t\t\tsynchronized (this.sessionAttributesHandlerCache) {\n\t\t\t\tresult = this.sessionAttributesHandlerCache.get(handlerType);\n\t\t\t\tif (result == null) {\n\t\t\t\t\tresult = new SessionAttributesHandler(handlerType);\n\t\t\t\t\tthis.sessionAttributesHandlerCache.put(handlerType, result);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["return", "the", "handler", "for", "the", "type", "level", "annotation", "based", "on", "the", "given", "controller", "method"], "project": "spring-framework"}
{"id": 9733, "code": "\tprotected WebApplicationContext initDispatcherServlet(\n\t\t\tClass<?> controllerClass, boolean usePathPatterns) throws ServletException {\n\n\t\treturn initDispatcherServlet(controllerClass, usePathPatterns, null);\n\t}", "summary_tokens": ["initialize", "a", "dispatcher", "servlet", "instance", "registering", "zero", "or", "more", "controller", "classes"], "project": "spring-framework"}
{"id": 9736, "code": "\tpublic void withMultiMapWithItemValueAndItemLabel() throws Exception {\n\t\t\n\t\tfinal Locale defaultLocale = Locale.getDefault();\n\t\t\n\t\t\n\t\tLocale.setDefault(Locale.US);\n\n\t\ttry {\n\t\t\tfinal Country austria = Country.COUNTRY_AT;\n\t\t\tfinal Country usa = Country.COUNTRY_US;\n\t\t\tfinal Map someMap = new HashMap();\n\t\t\tsomeMap.put(austria, LOCALE_AT);\n\t\t\tsomeMap.put(usa, Locale.US);\n\t\t\tthis.bean.setSomeMap(someMap);\n\n\t\t\tthis.tag.setPath(\"someMap\"); \n\t\t\tthis.tag.setItems(getCountryToLocaleMap());\n\t\t\tthis.tag.setItemValue(\"isoCode\"); \n\t\t\tthis.tag.setItemLabel(\"displayLanguage\"); \n\n\t\t\tBeanPropertyBindingResult bindingResult = new BeanPropertyBindingResult(getTestBean(), COMMAND_NAME);\n\t\t\tbindingResult.getPropertyAccessor().registerCustomEditor(Country.class, new PropertyEditorSupport() {\n\t\t\t\t@Override\n\t\t\t\tpublic void setAsText(final String text) throws IllegalArgumentException {\n\t\t\t\t\tsetValue(Country.getCountryWithIsoCode(text));\n\t\t\t\t}\n\n\t\t\t\t@Override\n\t\t\t\tpublic String getAsText() {\n\t\t\t\t\treturn ((Country) getValue()).getIsoCode();\n\t\t\t\t}\n\t\t\t});\n\t\t\texposeBindingResult(bindingResult);\n\n\t\t\tint result = this.tag.doStartTag();\n\t\t\tassertThat(result).isEqualTo(Tag.SKIP_BODY);\n\n\t\t\tString output = getOutput();\n\t\t\toutput = \"<doc>\" + output + \"</doc>\";\n\n\t\t\tSAXReader reader = new SAXReader();\n\t\t\tDocument document = reader.read(new StringReader(output));\n\t\t\tElement rootElement = document.getRootElement();\n\t\t\tassertThat(rootElement.elements().size()).isEqualTo(2);\n\n\t\t\tElement selectElement = rootElement.element(\"select\");\n\t\t\tassertThat(selectElement.getName()).isEqualTo(\"select\");\n\t\t\tassertThat(selectElement.attribute(\"name\").getValue()).isEqualTo(\"someMap\");\n\n\t\t\tList children = selectElement.elements();\n\t\t\tassertThat(children.size()).as(\"Incorrect number of children\").isEqualTo(3);\n\n\t\t\tElement e;\n\t\t\te = (Element) selectElement.selectSingleNode(\"option[@value = '\" + austria.getIsoCode() + \"']\");\n\t\t\tassertThat(e).as(\"Option node not found with Country ISO code value [\" + austria.getIsoCode() + \"].\").isNotNull();\n\t\t\tassertThat(e.attribute(\"selected\").getValue()).as(\"AT node not selected.\").isEqualTo(\"selected\");\n\t\t\tassertThat(e.getData()).as(\"AT Locale displayLanguage property not used for option label.\").isEqualTo(LOCALE_AT.getDisplayLanguage());\n\n\t\t\te = (Element) selectElement.selectSingleNode(\"option[@value = '\" + usa.getIsoCode() + \"']\");\n\t\t\tassertThat(e).as(\"Option node not found with Country ISO code value [\" + usa.getIsoCode() + \"].\").isNotNull();\n\t\t\tassertThat(e.attribute(\"selected\").getValue()).as(\"US node not selected.\").isEqualTo(\"selected\");\n\t\t\tassertThat(e.getData()).as(\"US Locale displayLanguage property not used for option label.\").isEqualTo(Locale.US.getDisplayLanguage());\n\n\t\t}\n\t\tfinally {\n\t\t\t\n\t\t\tLocale.setDefault(defaultLocale);\n\t\t}\n\t}", "summary_tokens": ["tests", "new", "support", "added", "as", "a", "result", "of", "a", "href", "https", "opensource"], "project": "spring-framework"}
{"id": 2256, "code": "\tpublic static Builder of(Class<?>... proxiedInterfaces) {\n\t\treturn new Builder().proxiedInterfaces(proxiedInterfaces);\n\t}", "summary_tokens": ["initialize", "a", "builder", "with", "the", "proxied", "interfaces", "to", "use"], "project": "spring-framework"}
{"id": 1210, "code": "\tpublic void setPointcut(Pointcut pointcut) {\n\t\tthis.pointcut = pointcut;\n\t}", "summary_tokens": ["set", "a", "pointcut", "i"], "project": "spring-framework"}
{"id": 5541, "code": "\tpublic ApplicationContextInitializer<ConfigurableApplicationContext> getContextInitializer(Class<?> testClass) {\n\t\tSupplier<ApplicationContextInitializer<ConfigurableApplicationContext>> supplier =\n\t\t\t\tthis.contextInitializers.get(testClass.getName());\n\t\treturn (supplier != null ? supplier.get() : null);\n\t}", "summary_tokens": ["get", "the", "aot", "application", "context", "initializer", "for", "the", "specified", "test", "class"], "project": "spring-framework"}
{"id": 6159, "code": "\tvoid test3IncrementCount2() {\n\t\tint count = dao.getCount(TEST_NAME);\n\t\tassertThat(count).as(\"Expected count=1 after test2IncrementCount1().\").isEqualTo(1);\n\n\t\tcount = dao.incrementCount(TEST_NAME);\n\t\tassertThat(count).as(\"Expected count=2 now.\").isEqualTo(2);\n\t}", "summary_tokens": ["the", "default", "implementation", "of", "this", "method", "assumes", "that", "the", "transaction", "for", "test", "0", "increment", "count", "0", "was", "committed"], "project": "spring-framework"}
{"id": 5496, "code": "\tpublic Class<?>[] getClasses() {\n\t\treturn this.classes;\n\t}", "summary_tokens": ["get", "the", "merged", "annotated", "classes", "for", "the", "get", "test", "class", "test", "class"], "project": "spring-framework"}
{"id": 9299, "code": "\tprotected String getOndblclick() {\n\t\treturn this.ondblclick;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "ondblclick", "attribute"], "project": "spring-framework"}
{"id": 6945, "code": "\tpublic Gson getObject() {\n\t\treturn this.gson;\n\t}", "summary_tokens": ["return", "the", "created", "gson", "instance"], "project": "spring-framework"}
{"id": 4449, "code": "\tprotected void noMessageReceived(Object invoker, Session session) {\n\t}", "summary_tokens": ["template", "method", "that", "gets", "called", "when", "i", "no", "i", "message", "has", "been", "received", "before", "returning", "to", "the", "receive", "loop", "again"], "project": "spring-framework"}
{"id": 9523, "code": "\tprotected boolean isUrlRequired() {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "the", "url", "property", "is", "required"], "project": "spring-framework"}
{"id": 3184, "code": "\tpublic static boolean hasUniqueObject(Collection<?> collection) {\n\t\tif (isEmpty(collection)) {\n\t\t\treturn false;\n\t\t}\n\t\tboolean hasCandidate = false;\n\t\tObject candidate = null;\n\t\tfor (Object elem : collection) {\n\t\t\tif (!hasCandidate) {\n\t\t\t\thasCandidate = true;\n\t\t\t\tcandidate = elem;\n\t\t\t}\n\t\t\telse if (candidate != elem) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "collection", "only", "contains", "a", "single", "unique", "object"], "project": "spring-framework"}
{"id": 8865, "code": "\tpublic void setPrefix(@Nullable String prefix) {\n\t\tthis.prefix = (prefix != null ? prefix : \"\");\n\t}", "summary_tokens": ["set", "the", "prefix", "to", "prepend", "to", "the", "request", "url", "filename", "to", "build", "a", "view", "name"], "project": "spring-framework"}
{"id": 4679, "code": "\tpublic boolean isUseDefaultResolution() {\n\t\treturn this.useDefaultResolution;\n\t}", "summary_tokens": ["whether", "this", "resolver", "is", "configured", "to", "use", "default", "resolution", "i"], "project": "spring-framework"}
{"id": 202, "code": "\tpublic String getExpression() {\n\t\treturn this.expression;\n\t}", "summary_tokens": ["return", "this", "pointcut", "s", "expression"], "project": "spring-framework"}
{"id": 9919, "code": "\tpublic boolean shouldSuppressCors() {\n\t\treturn this.suppressCors;\n\t}", "summary_tokens": ["return", "if", "automatic", "addition", "of", "cors", "headers", "has", "been", "disabled"], "project": "spring-framework"}
{"id": 2115, "code": "\tvoid reproSpr9023() {\n\t\tAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext();\n\t\tctx.register(B.class);\n\t\tctx.refresh();\n\t\tassertThat(ctx.getBeanNamesForType(B.class)[0]).isEqualTo(\"config-b\");\n\t\tassertThat(ctx.getBeanNamesForType(A.class)[0]).isEqualTo(\"config-a\");\n\t\tctx.close();\n\t}", "summary_tokens": ["test", "that", "values", "supplied", "to", "value"], "project": "spring-framework"}
{"id": 4157, "code": "\tpublic void afterPropertiesSet() {\n\t\tsuper.afterPropertiesSet();\n\t\tif (!isLazyInit()) {\n\t\t\tgetExceptionTranslator();\n\t\t}\n\t}", "summary_tokens": ["eagerly", "initialize", "the", "exception", "translator", "if", "demanded", "creating", "a", "default", "one", "for", "the", "specified", "data", "source", "if", "none", "set"], "project": "spring-framework"}
{"id": 1060, "code": "\tpublic void setMisfireInstructionName(String constantName) {\n\t\tthis.misfireInstruction = constants.asNumber(constantName).intValue();\n\t}", "summary_tokens": ["set", "the", "misfire", "instruction", "via", "the", "name", "of", "the", "corresponding", "constant", "in", "the", "org"], "project": "spring-framework"}
{"id": 5568, "code": "\tErrorMode getErrorMode() {\n\t\treturn this.errorMode;\n\t}", "summary_tokens": ["get", "the", "error", "mode"], "project": "spring-framework"}
{"id": 6867, "code": "\tpublic void setStreaming(boolean streaming) {\n\t\tthis.streaming = streaming;\n\t}", "summary_tokens": ["when", "set", "to", "true", "the", "part", "content", "part", "content", "is", "streamed", "directly", "from", "the", "parsed", "input", "buffer", "stream", "and", "not", "stored", "in", "memory", "nor", "file"], "project": "spring-framework"}
{"id": 5787, "code": "\tpublic static void assertModelAttributeValue(ModelAndView mav, String modelName, Object expectedValue) {\n\t\tObject modelValue = assertAndReturnModelAttributeOfType(mav, modelName, Object.class);\n\t\tassertTrue(\"Model value with name '\" + modelName + \"' is not the same as the expected value which was '\" +\n\t\t\t\texpectedValue + \"'\", modelValue.equals(expectedValue));\n\t}", "summary_tokens": ["compare", "a", "given", "expected", "value", "to", "the", "value", "from", "the", "model", "bound", "under", "the", "given", "model", "name"], "project": "spring-framework"}
{"id": 4209, "code": "\tvoid incrementsSequenceUsingH2EmbeddedDatabaseConfigurer() {\n\t\tEmbeddedDatabase database = new EmbeddedDatabaseBuilder()\n\t\t\t\t.setType(EmbeddedDatabaseType.H2)\n\t\t\t\t.generateUniqueName(true)\n\t\t\t\t.addScript(\"classpath:/org/springframework/jdbc/support/incrementer/schema.sql\")\n\t\t\t\t.build();\n\n\t\tassertIncrements(database);\n\n\t\tdatabase.shutdown();\n\t}", "summary_tokens": ["tests", "that", "the", "incrementer", "works", "when", "using", "the", "jdbc", "connection", "url", "used", "in", "the", "h", "0", "embedded", "database", "configurer", "which", "is", "used", "transparently", "when", "using", "spring", "s", "embedded", "database", "builder"], "project": "spring-framework"}
{"id": 868, "code": "\tpublic void setValue(Object value) {\n\t\tif (!(value instanceof Properties) && value instanceof Map) {\n\t\t\tProperties props = new Properties();\n\t\t\tprops.putAll((Map<?, ?>) value);\n\t\t\tsuper.setValue(props);\n\t\t}\n\t\telse {\n\t\t\tsuper.setValue(value);\n\t\t}\n\t}", "summary_tokens": ["take", "properties", "as", "is", "convert", "map", "into", "properties"], "project": "spring-framework"}
{"id": 8181, "code": "\tpublic PathPatternParser getPathPatternParser() {\n\t\treturn this.patternParser;\n\t}", "summary_tokens": ["return", "the", "path", "pattern", "parser", "instance", "that", "is", "used", "for", "set", "cors", "configurations", "map", "cors", "configuration", "checks"], "project": "spring-framework"}
{"id": 4839, "code": "\tpublic void setSendTimeout(long sendTimeout) {\n\t\tthis.sendTimeout = sendTimeout;\n\t}", "summary_tokens": ["specify", "the", "timeout", "value", "to", "use", "for", "send", "operations", "in", "milliseconds"], "project": "spring-framework"}
{"id": 6578, "code": "\tpublic void transactionAttributeDeclaredOnInterfaceMethodOnly() throws Exception {\n\t\tMethod interfaceMethod = ITestBean2.class.getMethod(\"getAge\");\n\n\t\tAnnotationTransactionAttributeSource atas = new AnnotationTransactionAttributeSource();\n\t\tTransactionAttribute actual = atas.getTransactionAttribute(interfaceMethod, TestBean2.class);\n\n\t\tRuleBasedTransactionAttribute rbta = new RuleBasedTransactionAttribute();\n\t\tassertThat(((RuleBasedTransactionAttribute) actual).getRollbackRules()).isEqualTo(rbta.getRollbackRules());\n\t}", "summary_tokens": ["test", "case", "where", "attribute", "is", "on", "the", "interface", "method"], "project": "spring-framework"}
{"id": 4798, "code": "\tpublic void setEncoders(List<? extends Encoder<?>> encoders) {\n\t\tthis.encoders.clear();\n\t\tthis.encoders.addAll(encoders);\n\t\tthis.strategies = this.strategies.mutate()\n\t\t\t\t.encoders(list -> {\n\t\t\t\t\tlist.clear();\n\t\t\t\t\tlist.addAll(encoders);\n\t\t\t\t})\n\t\t\t\t.build();\n\t}", "summary_tokens": ["configure", "the", "encoders", "to", "use", "for", "encoding", "handler", "method", "return", "values"], "project": "spring-framework"}
{"id": 1137, "code": "\tpublic void setMisfireInstructionName(String constantName) {\n\t\tthis.misfireInstruction = constants.asNumber(constantName).intValue();\n\t}", "summary_tokens": ["set", "the", "misfire", "instruction", "via", "the", "name", "of", "the", "corresponding", "constant", "in", "the", "org"], "project": "spring-framework"}
{"id": 2050, "code": "\tpublic void setTraversableResolver(TraversableResolver traversableResolver) {\n\t\tthis.traversableResolver = traversableResolver;\n\t}", "summary_tokens": ["specify", "a", "custom", "traversable", "resolver", "to", "use", "for", "this", "validator", "factory", "and", "its", "exposed", "default", "validator"], "project": "spring-framework"}
{"id": 1769, "code": "\tdefault ScheduledFuture<?> schedule(Runnable task, Date startTime) {\n\t\treturn schedule(task, startTime.toInstant());\n\t}", "summary_tokens": ["schedule", "the", "given", "runnable", "invoking", "it", "at", "the", "specified", "execution", "time"], "project": "spring-framework"}
{"id": 3446, "code": "\tMethod getBridgeMethod() throws NoSuchMethodException {\n\t\tMethod[] methods = StringGenericParameter.class.getMethods();\n\t\tMethod bridgeMethod = null;\n\t\tMethod bridgedMethod = null;\n\n\t\tfor (Method method : methods) {\n\t\t\tif (\"getFor\".equals(method.getName()) && !method.getParameterTypes()[0].equals(Integer.class)) {\n\t\t\t\tif (method.getReturnType().equals(Object.class)) {\n\t\t\t\t\tbridgeMethod = method;\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbridgedMethod = method;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tassertThat(bridgeMethod != null && bridgeMethod.isBridge()).isTrue();\n\t\tboolean condition = bridgedMethod != null && !bridgedMethod.isBridge();\n\t\tassertThat(condition).isTrue();\n\n\t\treturn bridgeMethod;\n\t}", "summary_tokens": ["bridge", "bridged", "method", "setup", "code", "copied", "from", "org"], "project": "spring-framework"}
{"id": 5906, "code": "\tstatic RouterFunctionSpec bindToRouterFunction(RouterFunction<?> routerFunction) {\n\t\treturn new DefaultRouterFunctionSpec(routerFunction);\n\t}", "summary_tokens": ["use", "this", "option", "to", "set", "up", "a", "server", "from", "a", "router", "function"], "project": "spring-framework"}
{"id": 496, "code": "\tdefault PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName)\n\t\t\tthrows BeansException {\n\n\t\treturn pvs;\n\t}", "summary_tokens": ["post", "process", "the", "given", "property", "values", "before", "the", "factory", "applies", "them", "to", "the", "given", "bean"], "project": "spring-framework"}
{"id": 9789, "code": "\tpublic SockJsServiceRegistration setTaskScheduler(TaskScheduler scheduler) {\n\t\tAssert.notNull(scheduler, \"TaskScheduler is required\");\n\t\tthis.scheduler = scheduler;\n\t\treturn this;\n\t}", "summary_tokens": ["a", "scheduler", "instance", "to", "use", "for", "scheduling", "sock", "js", "heart", "beats"], "project": "spring-framework"}
{"id": 9203, "code": "\tpublic void setHtmlEscape(boolean htmlEscape) throws JspException {\n\t\tthis.htmlEscape = htmlEscape;\n\t}", "summary_tokens": ["set", "html", "escaping", "for", "this", "tag", "as", "boolean", "value"], "project": "spring-framework"}
{"id": 3963, "code": "\tpublic void setSavepointAllowed(boolean savepointAllowed) {\n\t\tthis.savepointAllowed = savepointAllowed;\n\t}", "summary_tokens": ["set", "whether", "savepoints", "are", "allowed", "within", "this", "transaction"], "project": "spring-framework"}
{"id": 2628, "code": "public void box(Type type) {\n    if (TypeUtils.isPrimitive(type)) {\n        if (type == Type.VOID_TYPE) {\n            aconst_null();\n        } else {\n            Type boxed = TypeUtils.getBoxedType(type);\n            new_instance(boxed);\n            if (type.getSize() == 2) {\n                    \n                dup_x2();\n                dup_x2();\n                pop();\n            } else {\n                    \n                dup_x1();\n                swap();\n            }\n            invoke_constructor(boxed, new Signature(Constants.CONSTRUCTOR_NAME, Type.VOID_TYPE, new Type[]{ type }));\n        }\n    }\n}", "summary_tokens": ["if", "the", "argument", "is", "a", "primitive", "class", "replaces", "the", "primitive", "value", "on", "the", "top", "of", "the", "stack", "with", "the", "wrapped", "object", "equivalent"], "project": "spring-framework"}
{"id": 7610, "code": "\tpublic void setView(@Nullable Object view) {\n\t\tthis.view = view;\n\t}", "summary_tokens": ["set", "a", "view", "object", "to", "be", "used", "by", "the", "dispatcher", "servlet"], "project": "spring-framework"}
{"id": 8110, "code": "\tstatic HandlerStrategies withDefaults() {\n\t\treturn builder().build();\n\t}", "summary_tokens": ["return", "a", "new", "handler", "strategies", "with", "default", "initialization"], "project": "spring-framework"}
{"id": 8072, "code": "\tpublic MediaType getContentType() {\n\t\treturn this.contentType;\n\t}", "summary_tokens": ["return", "the", "request", "content", "type", "header", "if", "it", "was", "parsed", "successfully", "or", "null", "otherwise"], "project": "spring-framework"}
{"id": 6095, "code": "\tpublic ResultMatcher isInsufficientSpaceOnResource() {\n\t\treturn matcher(HttpStatus.INSUFFICIENT_SPACE_ON_RESOURCE);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2924, "code": "\tpublic String getDescription() {\n\t\treturn \"Byte array resource [\" + this.description + \"]\";\n\t}", "summary_tokens": ["this", "implementation", "returns", "a", "description", "that", "includes", "the", "passed", "in", "description", "if", "any"], "project": "spring-framework"}
{"id": 248, "code": "\tpublic synchronized Object getTarget() throws Exception {\n\t\tif (this.lazyTarget == null) {\n\t\t\tlogger.debug(\"Initializing lazy target object\");\n\t\t\tthis.lazyTarget = createObject();\n\t\t}\n\t\treturn this.lazyTarget;\n\t}", "summary_tokens": ["returns", "the", "lazy", "initialized", "target", "object", "creating", "it", "on", "the", "fly", "if", "it", "doesn", "t", "exist", "already"], "project": "spring-framework"}
{"id": 3710, "code": "\tpublic boolean isResultsParameter() {\n\t\treturn false;\n\t}", "summary_tokens": ["return", "whether", "this", "parameter", "is", "an", "implicit", "return", "parameter", "used", "during", "the", "results", "processing", "of", "callable", "statement"], "project": "spring-framework"}
{"id": 6446, "code": "\tprotected void prepareSynchronization(DefaultTransactionStatus status, TransactionDefinition definition) {\n\t\tif (status.isNewSynchronization()) {\n\t\t\tTransactionSynchronizationManager.setActualTransactionActive(status.hasTransaction());\n\t\t\tTransactionSynchronizationManager.setCurrentTransactionIsolationLevel(\n\t\t\t\t\tdefinition.getIsolationLevel() != TransactionDefinition.ISOLATION_DEFAULT ?\n\t\t\t\t\t\t\tdefinition.getIsolationLevel() : null);\n\t\t\tTransactionSynchronizationManager.setCurrentTransactionReadOnly(definition.isReadOnly());\n\t\t\tTransactionSynchronizationManager.setCurrentTransactionName(definition.getName());\n\t\t\tTransactionSynchronizationManager.initSynchronization();\n\t\t}\n\t}", "summary_tokens": ["initialize", "transaction", "synchronization", "as", "appropriate"], "project": "spring-framework"}
{"id": 8508, "code": "\tprotected Object createDefaultStrategy(ApplicationContext context, Class<?> clazz) {\n\t\treturn context.getAutowireCapableBeanFactory().createBean(clazz);\n\t}", "summary_tokens": ["create", "a", "default", "strategy"], "project": "spring-framework"}
{"id": 6951, "code": "\tpublic Jackson2ObjectMapperBuilder simpleDateFormat(String format) {\n\t\tthis.dateFormat = new SimpleDateFormat(format);\n\t\treturn this;\n\t}", "summary_tokens": ["define", "the", "date", "time", "format", "with", "a", "simple", "date", "format"], "project": "spring-framework"}
{"id": 550, "code": "\tprotected Exception createServiceLocatorException(Constructor<Exception> exceptionConstructor, BeansException cause) {\n\t\tClass<?>[] paramTypes = exceptionConstructor.getParameterTypes();\n\t\tObject[] args = new Object[paramTypes.length];\n\t\tfor (int i = 0; i < paramTypes.length; i++) {\n\t\t\tif (String.class == paramTypes[i]) {\n\t\t\t\targs[i] = cause.getMessage();\n\t\t\t}\n\t\t\telse if (paramTypes[i].isInstance(cause)) {\n\t\t\t\targs[i] = cause;\n\t\t\t}\n\t\t}\n\t\treturn BeanUtils.instantiateClass(exceptionConstructor, args);\n\t}", "summary_tokens": ["create", "a", "service", "locator", "exception", "for", "the", "given", "cause"], "project": "spring-framework"}
{"id": 2295, "code": "\tpublic static ReflectionHintsPredicates reflection() {\n\t\treturn reflection;\n\t}", "summary_tokens": ["return", "a", "predicate", "generator", "for", "reflection", "hints", "reflection", "hints"], "project": "spring-framework"}
{"id": 3409, "code": "\tpublic void setFeature(String name, boolean value) throws SAXNotRecognizedException, SAXNotSupportedException {\n\t\tif (name.startsWith(\"http://xml.org/sax/features/\")) {\n\t\t\tif (value) {\n\t\t\t\tthrow new SAXNotSupportedException(name);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthrow new SAXNotRecognizedException(name);\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "throws", "a", "saxnot", "recognized", "exception", "exception", "for", "any", "feature", "outside", "the", "http", "xml"], "project": "spring-framework"}
{"id": 9101, "code": "\tpublic Object getActualValue() {\n\t\treturn this.actualValue;\n\t}", "summary_tokens": ["return", "the", "actual", "value", "of", "the", "field", "i"], "project": "spring-framework"}
{"id": 2906, "code": "\tpublic boolean isOpen() {\n\t\treturn false;\n\t}", "summary_tokens": ["this", "implementation", "always", "returns", "false"], "project": "spring-framework"}
{"id": 517, "code": "\tpublic void setSystemTreePath(String systemTreePath) {\n\t\tthis.systemTreePath = systemTreePath;\n\t}", "summary_tokens": ["set", "the", "path", "in", "the", "system", "preferences", "tree", "to", "use", "for", "resolving", "placeholders"], "project": "spring-framework"}
{"id": 1172, "code": "\tdefault CacheErrorHandler errorHandler() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "cache", "error", "handler", "to", "use", "to", "handle", "cache", "related", "errors"], "project": "spring-framework"}
{"id": 4961, "code": "\tpublic MessageHeaderInitializer getHeaderInitializer() {\n\t\treturn this.headerInitializer;\n\t}", "summary_tokens": ["return", "the", "configured", "header", "initializer"], "project": "spring-framework"}
{"id": 6425, "code": "\tprivate Mono<Void> rollbackOnException(ReactiveTransaction status, Throwable ex) throws TransactionException {\n\t\tlogger.debug(\"Initiating transaction rollback on application exception\", ex);\n\t\treturn this.transactionManager.rollback(status).onErrorMap(ex2 -> {\n\t\t\t\t\tlogger.error(\"Application exception overridden by rollback exception\", ex);\n\t\t\t\t\tif (ex2 instanceof TransactionSystemException) {\n\t\t\t\t\t\t((TransactionSystemException) ex2).initApplicationException(ex);\n\t\t\t\t\t}\n\t\t\t\t\treturn ex2;\n\t\t\t\t}\n\t\t);\n\t}", "summary_tokens": ["perform", "a", "rollback", "handling", "rollback", "exceptions", "properly"], "project": "spring-framework"}
{"id": 3159, "code": "\tpublic static String getQualifiedName(Class<?> clazz) {\n\t\tAssert.notNull(clazz, \"Class must not be null\");\n\t\treturn clazz.getTypeName();\n\t}", "summary_tokens": ["return", "the", "qualified", "name", "of", "the", "given", "class", "usually", "simply", "the", "class", "name", "but", "component", "type", "class", "name", "for", "arrays"], "project": "spring-framework"}
{"id": 8445, "code": "\tpublic Map<String, Object> getAttributes() {\n\t\treturn this.attributes;\n\t}", "summary_tokens": ["attributes", "extracted", "from", "the", "handshake", "request", "to", "add", "to", "the", "session"], "project": "spring-framework"}
{"id": 2031, "code": "\tpublic void wrap(Object source) {\n\t\tif (this.source != null) {\n\t\t\tthrow new IllegalStateException(\"Already wrapping \" + this.source);\n\t\t}\n\t\tthis.source = source;\n\t}", "summary_tokens": ["preserve", "the", "source", "behind", "this", "error", "possibly", "an", "exception", "typically", "org"], "project": "spring-framework"}
{"id": 8654, "code": "\tpublic void enableContentNegotiation(boolean useNotAcceptableStatus, View... defaultViews) {\n\t\tContentNegotiatingViewResolver vr = initContentNegotiatingViewResolver(defaultViews);\n\t\tvr.setUseNotAcceptableStatusCode(useNotAcceptableStatus);\n\t}", "summary_tokens": ["enable", "use", "of", "a", "content", "negotiating", "view", "resolver", "to", "front", "all", "other", "configured", "view", "resolvers", "and", "select", "among", "all", "selected", "views", "based", "on", "media", "types", "requested", "by", "the", "client", "e"], "project": "spring-framework"}
{"id": 5601, "code": "\tprotected int deleteFromTableWhere(String tableName, String whereClause, Object... args) {\n\t\treturn JdbcTestUtils.deleteFromTableWhere(this.jdbcTemplate, tableName, whereClause, args);\n\t}", "summary_tokens": ["convenience", "method", "for", "deleting", "all", "rows", "from", "the", "given", "table", "using", "the", "provided", "where", "clause"], "project": "spring-framework"}
{"id": 5710, "code": "\tpublic static Map<String, Object> convertInlinedPropertiesToMap(String... inlinedProperties) {\n\t\tAssert.notNull(inlinedProperties, \"'inlinedProperties' must not be null\");\n\t\tMap<String, Object> map = new LinkedHashMap<>();\n\t\tProperties props = new Properties();\n\n\t\tfor (String pair : inlinedProperties) {\n\t\t\tif (!StringUtils.hasText(pair)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tprops.load(new StringReader(pair));\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tthrow new IllegalStateException(\"Failed to load test environment property from [\" + pair + \"]\", ex);\n\t\t\t}\n\t\t\tAssert.state(props.size() == 1, () -> \"Failed to load exactly one test environment property from [\" + pair + \"]\");\n\t\t\tfor (String name : props.stringPropertyNames()) {\n\t\t\t\tmap.put(name, props.getProperty(name));\n\t\t\t}\n\t\t\tprops.clear();\n\t\t}\n\n\t\treturn map;\n\t}", "summary_tokens": ["convert", "the", "supplied", "em", "inlined", "properties", "em", "in", "the", "form", "of", "em", "key", "value", "em", "pairs", "into", "a", "map", "keyed", "by", "property", "name", "preserving", "the", "ordering", "of", "property", "names", "in", "the", "returned", "map"], "project": "spring-framework"}
{"id": 2648, "code": "\tpublic void setUseFactory(boolean useFactory) {\n\t\tthis.useFactory = useFactory;\n\t}", "summary_tokens": ["set", "whether", "the", "enhanced", "object", "instances", "should", "implement", "the", "factory", "interface"], "project": "spring-framework"}
{"id": 4381, "code": "\tprotected void prepareSharedConnection(Connection connection) throws JMSException {\n\t\tString clientId = getClientId();\n\t\tif (clientId != null) {\n\t\t\tconnection.setClientID(clientId);\n\t\t}\n\t}", "summary_tokens": ["prepare", "the", "given", "connection", "which", "is", "about", "to", "be", "registered", "as", "shared", "connection", "for", "this", "container"], "project": "spring-framework"}
{"id": 4440, "code": "\tprotected long getReceiveTimeout() {\n\t\treturn this.receiveTimeout;\n\t}", "summary_tokens": ["return", "the", "receive", "timeout", "ms", "configured", "for", "this", "listener", "container"], "project": "spring-framework"}
{"id": 290, "code": "\tpublic void testCanonicalFrameworkClassesStillCanonicalOnDeserialization() throws Exception {\n\t\tassertThat(SerializationTestUtils.serializeAndDeserialize(MethodMatcher.TRUE)).isSameAs(MethodMatcher.TRUE);\n\t\tassertThat(SerializationTestUtils.serializeAndDeserialize(ClassFilter.TRUE)).isSameAs(ClassFilter.TRUE);\n\t\tassertThat(SerializationTestUtils.serializeAndDeserialize(Pointcut.TRUE)).isSameAs(Pointcut.TRUE);\n\t\tassertThat(SerializationTestUtils.serializeAndDeserialize(EmptyTargetSource.INSTANCE)).isSameAs(EmptyTargetSource.INSTANCE);\n\t\tassertThat(SerializationTestUtils.serializeAndDeserialize(Pointcuts.SETTERS)).isSameAs(Pointcuts.SETTERS);\n\t\tassertThat(SerializationTestUtils.serializeAndDeserialize(Pointcuts.GETTERS)).isSameAs(Pointcuts.GETTERS);\n\t\tassertThat(SerializationTestUtils.serializeAndDeserialize(ExposeInvocationInterceptor.INSTANCE)).isSameAs(ExposeInvocationInterceptor.INSTANCE);\n\t}", "summary_tokens": ["test", "that", "when", "we", "serialize", "and", "deserialize", "various", "canonical", "instances", "of", "aop", "classes", "they", "return", "the", "same", "instance", "not", "a", "new", "instance", "that", "s", "subverted", "the", "singleton", "construction", "limitation"], "project": "spring-framework"}
{"id": 1864, "code": "\tpublic void setPrestartAllCoreThreads(boolean prestartAllCoreThreads) {\n\t\tthis.prestartAllCoreThreads = prestartAllCoreThreads;\n\t}", "summary_tokens": ["specify", "whether", "to", "start", "all", "core", "threads", "causing", "them", "to", "idly", "wait", "for", "work"], "project": "spring-framework"}
{"id": 1404, "code": "\tpublic void setAllowCircularReferences(boolean allowCircularReferences) {\n\t\tthis.beanFactory.setAllowCircularReferences(allowCircularReferences);\n\t}", "summary_tokens": ["set", "whether", "to", "allow", "circular", "references", "between", "beans", "and", "automatically", "try", "to", "resolve", "them"], "project": "spring-framework"}
{"id": 8745, "code": "\tdefault Optional<ServerRequest> nest(ServerRequest request) {\n\t\treturn (test(request) ? Optional.of(request) : Optional.empty());\n\t}", "summary_tokens": ["transform", "the", "given", "request", "into", "a", "request", "used", "for", "a", "nested", "route"], "project": "spring-framework"}
{"id": 2928, "code": "\tpublic ClassLoader getClassLoader() {\n\t\treturn (this.classLoader != null ? this.classLoader : ClassUtils.getDefaultClassLoader());\n\t}", "summary_tokens": ["return", "the", "class", "loader", "to", "load", "class", "path", "resources", "with"], "project": "spring-framework"}
{"id": 9331, "code": "\tpublic void setReadonly(boolean readonly) {\n\t\tthis.readonly = readonly;\n\t}", "summary_tokens": ["sets", "the", "value", "of", "the", "readonly", "attribute"], "project": "spring-framework"}
{"id": 215, "code": "\tpublic boolean implementsInterface(Class<?> ifc) {\n\t\tfor (Class<?> pubIfc : this.publishedInterfaces) {\n\t\t\tif (ifc.isInterface() && ifc.isAssignableFrom(pubIfc)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["check", "whether", "the", "specified", "interfaces", "is", "a", "published", "introduction", "interface"], "project": "spring-framework"}
{"id": 5036, "code": "\tprotected String getTargetDestination(String sourceDestination, String actualDestination,\n\t\t\tString sessionId, @Nullable String user) {\n\n\t\treturn actualDestination + \"-user\" + sessionId;\n\t}", "summary_tokens": ["this", "method", "determines", "how", "to", "translate", "the", "source", "user", "destination", "to", "an", "actual", "target", "destination", "for", "the", "given", "active", "user", "session"], "project": "spring-framework"}
{"id": 3672, "code": "\tpublic T mapRow(ResultSet rs, int rowNumber) throws SQLException {\n\t\tBeanWrapperImpl bw = new BeanWrapperImpl();\n\t\tinitBeanWrapper(bw);\n\n\t\tT mappedObject = constructMappedInstance(rs, bw);\n\t\tbw.setBeanInstance(mappedObject);\n\n\t\tResultSetMetaData rsmd = rs.getMetaData();\n\t\tint columnCount = rsmd.getColumnCount();\n\t\tSet<String> populatedProperties = (isCheckFullyPopulated() ? new HashSet<>() : null);\n\n\t\tfor (int index = 1; index <= columnCount; index++) {\n\t\t\tString column = JdbcUtils.lookupColumnName(rsmd, index);\n\t\t\tString field = lowerCaseName(StringUtils.delete(column, \" \"));\n\t\t\tPropertyDescriptor pd = (this.mappedFields != null ? this.mappedFields.get(field) : null);\n\t\t\tif (pd != null) {\n\t\t\t\ttry {\n\t\t\t\t\tObject value = getColumnValue(rs, index, pd);\n\t\t\t\t\tif (rowNumber == 0 && logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Mapping column '\" + column + \"' to property '\" + pd.getName() +\n\t\t\t\t\t\t\t\t\"' of type '\" + ClassUtils.getQualifiedName(pd.getPropertyType()) + \"'\");\n\t\t\t\t\t}\n\t\t\t\t\ttry {\n\t\t\t\t\t\tbw.setPropertyValue(pd.getName(), value);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (TypeMismatchException ex) {\n\t\t\t\t\t\tif (value == null && this.primitivesDefaultedForNullValue) {\n\t\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\t\tlogger.debug(\"Intercepted TypeMismatchException for row \" + rowNumber +\n\t\t\t\t\t\t\t\t\t\t\" and column '\" + column + \"' with null value when setting property '\" +\n\t\t\t\t\t\t\t\t\t\tpd.getName() + \"' of type '\" +\n\t\t\t\t\t\t\t\t\t\tClassUtils.getQualifiedName(pd.getPropertyType()) +\n\t\t\t\t\t\t\t\t\t\t\"' on object: \" + mappedObject, ex);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tthrow ex;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (populatedProperties != null) {\n\t\t\t\t\t\tpopulatedProperties.add(pd.getName());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcatch (NotWritablePropertyException ex) {\n\t\t\t\t\tthrow new DataRetrievalFailureException(\n\t\t\t\t\t\t\t\"Unable to map column '\" + column + \"' to property '\" + pd.getName() + \"'\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (populatedProperties != null && !populatedProperties.equals(this.mappedProperties)) {\n\t\t\tthrow new InvalidDataAccessApiUsageException(\"Given ResultSet does not contain all fields \" +\n\t\t\t\t\t\"necessary to populate object of \" + this.mappedClass + \": \" + this.mappedProperties);\n\t\t}\n\n\t\treturn mappedObject;\n\t}", "summary_tokens": ["extract", "the", "values", "for", "all", "columns", "in", "the", "current", "row"], "project": "spring-framework"}
{"id": 40, "code": "\tpublic void setIncludePatterns(List<String> patterns) {\n\t\tthis.includePatterns = new ArrayList<>(patterns.size());\n\t\tfor (String patternText : patterns) {\n\t\t\tthis.includePatterns.add(Pattern.compile(patternText));\n\t\t}\n\t}", "summary_tokens": ["set", "a", "list", "of", "regex", "patterns", "matching", "eligible", "bean", "names"], "project": "spring-framework"}
{"id": 3414, "code": "\tpublic void bindNamespaceUri(String prefix, String namespaceUri) {\n\t\tAssert.notNull(prefix, \"No prefix given\");\n\t\tAssert.notNull(namespaceUri, \"No namespaceUri given\");\n\t\tif (XMLConstants.DEFAULT_NS_PREFIX.equals(prefix)) {\n\t\t\tthis.defaultNamespaceUri = namespaceUri;\n\t\t}\n\t\telse {\n\t\t\tthis.prefixToNamespaceUri.put(prefix, namespaceUri);\n\t\t\tSet<String> prefixes =\n\t\t\t\t\tthis.namespaceUriToPrefixes.computeIfAbsent(namespaceUri, k -> new LinkedHashSet<>());\n\t\t\tprefixes.add(prefix);\n\t\t}\n\t}", "summary_tokens": ["bind", "the", "given", "prefix", "to", "the", "given", "namespace"], "project": "spring-framework"}
{"id": 1590, "code": "\tprotected ModelMBeanAttributeInfo[] getAttributeInfo(Object managedBean, String beanKey) throws JMException {\n\t\tPropertyDescriptor[] props = BeanUtils.getPropertyDescriptors(getClassToExpose(managedBean));\n\t\tList<ModelMBeanAttributeInfo> infos = new ArrayList<>();\n\n\t\tfor (PropertyDescriptor prop : props) {\n\t\t\tMethod getter = prop.getReadMethod();\n\t\t\tif (getter != null && getter.getDeclaringClass() == Object.class) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (getter != null && !includeReadAttribute(getter, beanKey)) {\n\t\t\t\tgetter = null;\n\t\t\t}\n\n\t\t\tMethod setter = prop.getWriteMethod();\n\t\t\tif (setter != null && !includeWriteAttribute(setter, beanKey)) {\n\t\t\t\tsetter = null;\n\t\t\t}\n\n\t\t\tif (getter != null || setter != null) {\n\t\t\t\t\n\t\t\t\tString attrName = JmxUtils.getAttributeName(prop, isUseStrictCasing());\n\t\t\t\tString description = getAttributeDescription(prop, beanKey);\n\t\t\t\tModelMBeanAttributeInfo info = new ModelMBeanAttributeInfo(attrName, description, getter, setter);\n\n\t\t\t\tDescriptor desc = info.getDescriptor();\n\t\t\t\tif (getter != null) {\n\t\t\t\t\tdesc.setField(FIELD_GET_METHOD, getter.getName());\n\t\t\t\t}\n\t\t\t\tif (setter != null) {\n\t\t\t\t\tdesc.setField(FIELD_SET_METHOD, setter.getName());\n\t\t\t\t}\n\n\t\t\t\tpopulateAttributeDescriptor(desc, getter, setter, beanKey);\n\t\t\t\tinfo.setDescriptor(desc);\n\t\t\t\tinfos.add(info);\n\t\t\t}\n\t\t}\n\n\t\treturn infos.toArray(new ModelMBeanAttributeInfo[0]);\n\t}", "summary_tokens": ["iterate", "through", "all", "properties", "on", "the", "mbean", "class", "and", "gives", "subclasses", "the", "chance", "to", "vote", "on", "the", "inclusion", "of", "both", "the", "accessor", "and", "mutator"], "project": "spring-framework"}
{"id": 9819, "code": "\tprotected Integer getTimeToFirstMessage() {\n\t\treturn this.timeToFirstMessage;\n\t}", "summary_tokens": ["protected", "accessor", "for", "internal", "use"], "project": "spring-framework"}
{"id": 7312, "code": "\tpublic CallableProcessingInterceptor getCallableInterceptor(Object key) {\n\t\treturn this.callableInterceptors.get(key);\n\t}", "summary_tokens": ["get", "the", "callable", "processing", "interceptor", "registered", "under", "the", "given", "key"], "project": "spring-framework"}
{"id": 2992, "code": "\tdefault OutputStream asOutputStream() {\n\t\treturn new DataBufferOutputStream(this);\n\t}", "summary_tokens": ["expose", "this", "buffer", "s", "data", "as", "an", "output", "stream"], "project": "spring-framework"}
{"id": 5937, "code": "\tpublic T contextPath(String contextPath) {\n\t\tthis.contextPath = contextPath;\n\t\treturn (T) this;\n\t}", "summary_tokens": ["set", "the", "context", "path", "to", "use"], "project": "spring-framework"}
{"id": 844, "code": "\tprotected int getValidationModeForResource(Resource resource) {\n\t\tint validationModeToUse = getValidationMode();\n\t\tif (validationModeToUse != VALIDATION_AUTO) {\n\t\t\treturn validationModeToUse;\n\t\t}\n\t\tint detectedMode = detectValidationMode(resource);\n\t\tif (detectedMode != VALIDATION_AUTO) {\n\t\t\treturn detectedMode;\n\t\t}\n\t\t\n\t\t\n\t\t\n\t\treturn VALIDATION_XSD;\n\t}", "summary_tokens": ["determine", "the", "validation", "mode", "for", "the", "specified", "resource"], "project": "spring-framework"}
{"id": 5853, "code": "\tpublic DefaultResponseCreator headers(HttpHeaders headers) {\n\t\tthis.headers.putAll(headers);\n\t\treturn this;\n\t}", "summary_tokens": ["copy", "all", "given", "headers"], "project": "spring-framework"}
{"id": 9785, "code": "\tpublic void setOrder(int order) {\n\t\tthis.order = order;\n\t}", "summary_tokens": ["set", "the", "order", "for", "the", "resulting", "simple", "url", "handler", "mapping", "relative", "to", "other", "handler", "mappings", "configured", "in", "spring", "mvc"], "project": "spring-framework"}
{"id": 4948, "code": "\tpublic void setSystemPasscode(String systemPasscode) {\n\t\tthis.systemPasscode = systemPasscode;\n\t}", "summary_tokens": ["set", "the", "passcode", "for", "the", "shared", "system", "connection", "used", "to", "send", "messages", "to", "the", "stomp", "broker", "from", "within", "the", "application", "i"], "project": "spring-framework"}
{"id": 4386, "code": "\tprotected void resumePausedTasks() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tif (!this.pausedTasks.isEmpty()) {\n\t\t\t\tfor (Iterator<?> it = this.pausedTasks.iterator(); it.hasNext();) {\n\t\t\t\t\tObject task = it.next();\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdoRescheduleTask(task);\n\t\t\t\t\t\tit.remove();\n\t\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\t\tlogger.debug(\"Resumed paused task: \" + task);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (RuntimeException ex) {\n\t\t\t\t\t\tlogRejectedTask(task, ex);\n\t\t\t\t\t\t\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["try", "to", "resume", "all", "paused", "tasks"], "project": "spring-framework"}
{"id": 8785, "code": "\tpublic void setRouterFunction(@Nullable RouterFunction<?> routerFunction) {\n\t\tthis.routerFunction = routerFunction;\n\t}", "summary_tokens": ["set", "the", "router", "function", "to", "map", "to"], "project": "spring-framework"}
{"id": 9552, "code": "\tpublic void setPrefix(@Nullable String prefix) {\n\t\tthis.prefix = (prefix != null ? prefix : \"\");\n\t}", "summary_tokens": ["set", "the", "prefix", "to", "prepend", "to", "generated", "view", "names"], "project": "spring-framework"}
{"id": 6787, "code": "\tpublic boolean isUseGlobalResources() {\n\t\treturn this.useGlobalResources;\n\t}", "summary_tokens": ["whether", "this", "factory", "exposes", "the", "global", "reactor"], "project": "spring-framework"}
{"id": 5753, "code": "\tpublic static int deleteFromTables(JdbcTemplate jdbcTemplate, String... tableNames) {\n\t\tint totalRowCount = 0;\n\t\tfor (String tableName : tableNames) {\n\t\t\tint rowCount = jdbcTemplate.update(\"DELETE FROM \" + tableName);\n\t\t\ttotalRowCount += rowCount;\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Deleted \" + rowCount + \" rows from table \" + tableName);\n\t\t\t}\n\t\t}\n\t\treturn totalRowCount;\n\t}", "summary_tokens": ["delete", "all", "rows", "from", "the", "specified", "tables"], "project": "spring-framework"}
{"id": 6502, "code": "\tpublic boolean isDebug() {\n\t\treturn this.debug;\n\t}", "summary_tokens": ["return", "whether", "the", "progress", "of", "this", "transaction", "is", "debugged"], "project": "spring-framework"}
{"id": 8750, "code": "\tdefault RouterFunction<T> andNest(RequestPredicate predicate, RouterFunction<T> routerFunction) {\n\t\treturn and(RouterFunctions.nest(predicate, routerFunction));\n\t}", "summary_tokens": ["return", "a", "composed", "routing", "function", "that", "routes", "to", "the", "given", "router", "function", "if", "this", "route", "does", "not", "match", "and", "the", "given", "request", "predicate", "applies"], "project": "spring-framework"}
{"id": 7860, "code": "\tpublic String getRequestUri(HttpServletRequest request) {\n\t\tString uri = (String) request.getAttribute(WebUtils.INCLUDE_REQUEST_URI_ATTRIBUTE);\n\t\tif (uri == null) {\n\t\t\turi = request.getRequestURI();\n\t\t}\n\t\treturn decodeAndCleanUriString(request, uri);\n\t}", "summary_tokens": ["return", "the", "request", "uri", "for", "the", "given", "request", "detecting", "an", "include", "request", "url", "if", "called", "within", "a", "request", "dispatcher", "include"], "project": "spring-framework"}
{"id": 644, "code": "\tpublic BeanDefinitionBuilder addDependsOn(String beanName) {\n\t\tif (this.beanDefinition.getDependsOn() == null) {\n\t\t\tthis.beanDefinition.setDependsOn(beanName);\n\t\t}\n\t\telse {\n\t\t\tString[] added = ObjectUtils.addObjectToArray(this.beanDefinition.getDependsOn(), beanName);\n\t\t\tthis.beanDefinition.setDependsOn(added);\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["append", "the", "specified", "bean", "name", "to", "the", "list", "of", "beans", "that", "this", "definition", "depends", "on"], "project": "spring-framework"}
{"id": 8505, "code": "\tpublic final List<HandlerMapping> getHandlerMappings() {\n\t\treturn (this.handlerMappings != null ? Collections.unmodifiableList(this.handlerMappings) : null);\n\t}", "summary_tokens": ["return", "the", "configured", "handler", "mapping", "beans", "that", "were", "detected", "by", "type", "in", "the", "web", "application", "context", "or", "initialized", "based", "on", "the", "default", "set", "of", "strategies", "from", "dispatcher", "servlet"], "project": "spring-framework"}
{"id": 898, "code": "\tpublic int getLastLinkedPage() {\n\t\treturn Math.min(getFirstLinkedPage() + getMaxLinkedPages() - 1, getPageCount() - 1);\n\t}", "summary_tokens": ["return", "the", "last", "page", "to", "which", "create", "a", "link", "around", "the", "current", "page"], "project": "spring-framework"}
{"id": 7756, "code": "\tprotected void handleContentOverflow(int contentCacheLimit) {\n\t}", "summary_tokens": ["template", "method", "for", "handling", "a", "content", "overflow", "specifically", "a", "request", "body", "being", "read", "that", "exceeds", "the", "specified", "content", "cache", "limit"], "project": "spring-framework"}
{"id": 2925, "code": "\tpublic boolean equals(@Nullable Object other) {\n\t\treturn (this == other || (other instanceof ByteArrayResource &&\n\t\t\t\tArrays.equals(((ByteArrayResource) other).byteArray, this.byteArray)));\n\t}", "summary_tokens": ["this", "implementation", "compares", "the", "underlying", "byte", "array"], "project": "spring-framework"}
{"id": 9307, "code": "\tprotected String getOnmousemove() {\n\t\treturn this.onmousemove;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onmousemove", "attribute"], "project": "spring-framework"}
{"id": 8802, "code": "\tprotected String buildLogMessage(Exception ex, HttpServletRequest request) {\n\t\treturn \"Resolved [\" + LogFormatUtils.formatValue(ex, -1, true) + \"]\";\n\t}", "summary_tokens": ["build", "a", "log", "message", "for", "the", "given", "exception", "occurred", "during", "processing", "the", "given", "request"], "project": "spring-framework"}
{"id": 2006, "code": "\tpublic void setConversionService(@Nullable ConversionService conversionService) {\n\t\tAssert.state(this.conversionService == null, \"DataBinder is already initialized with ConversionService\");\n\t\tthis.conversionService = conversionService;\n\t\tif (this.bindingResult != null && conversionService != null) {\n\t\t\tthis.bindingResult.initConversion(conversionService);\n\t\t}\n\t}", "summary_tokens": ["specify", "a", "spring", "0"], "project": "spring-framework"}
{"id": 1094, "code": "\tprivate boolean addTriggerToScheduler(Trigger trigger) throws SchedulerException {\n\t\tboolean triggerExists = (getScheduler().getTrigger(trigger.getKey()) != null);\n\t\tif (triggerExists && !this.overwriteExistingJobs) {\n\t\t\treturn false;\n\t\t}\n\n\t\t\n\t\tJobDetail jobDetail = (JobDetail) trigger.getJobDataMap().remove(\"jobDetail\");\n\t\tif (triggerExists) {\n\t\t\tif (jobDetail != null && this.jobDetails != null &&\n\t\t\t\t\t!this.jobDetails.contains(jobDetail) && addJobToScheduler(jobDetail)) {\n\t\t\t\tthis.jobDetails.add(jobDetail);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tgetScheduler().rescheduleJob(trigger.getKey(), trigger);\n\t\t\t}\n\t\t\tcatch (ObjectAlreadyExistsException ex) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Unexpectedly encountered existing trigger on rescheduling, assumably due to \" +\n\t\t\t\t\t\t\t\"cluster race condition: \" + ex.getMessage() + \" - can safely be ignored\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\tif (jobDetail != null && this.jobDetails != null && !this.jobDetails.contains(jobDetail) &&\n\t\t\t\t\t\t(this.overwriteExistingJobs || getScheduler().getJobDetail(jobDetail.getKey()) == null)) {\n\t\t\t\t\tgetScheduler().scheduleJob(jobDetail, trigger);\n\t\t\t\t\tthis.jobDetails.add(jobDetail);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tgetScheduler().scheduleJob(trigger);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (ObjectAlreadyExistsException ex) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Unexpectedly encountered existing trigger on job scheduling, assumably due to \" +\n\t\t\t\t\t\t\t\"cluster race condition: \" + ex.getMessage() + \" - can safely be ignored\");\n\t\t\t\t}\n\t\t\t\tif (this.overwriteExistingJobs) {\n\t\t\t\t\tgetScheduler().rescheduleJob(trigger.getKey(), trigger);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["add", "the", "given", "trigger", "to", "the", "scheduler", "if", "it", "doesn", "t", "already", "exist"], "project": "spring-framework"}
{"id": 4928, "code": "\tpublic void setMessageConverter(MessageConverter messageConverter) {\n\t\tAssert.notNull(messageConverter, \"MessageConverter must not be null\");\n\t\tthis.converter = messageConverter;\n\t}", "summary_tokens": ["set", "the", "message", "converter", "to", "use", "to", "convert", "the", "payload", "of", "incoming", "and", "outgoing", "messages", "to", "and", "from", "byte", "based", "on", "object", "type", "or", "expected", "object", "type", "and", "the", "content", "type", "header"], "project": "spring-framework"}
{"id": 6852, "code": "\tprotected List<MimeType> getMimeTypes() {\n\t\treturn this.mimeTypes;\n\t}", "summary_tokens": ["subclasses", "should", "expose", "this", "as", "decodable", "or", "encodable", "mime", "types"], "project": "spring-framework"}
{"id": 9493, "code": "\tpublic String getDefaultThemeName() {\n\t\treturn this.defaultThemeName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "default", "theme"], "project": "spring-framework"}
{"id": 8591, "code": "\tpublic CorsRegistration allowedHeaders(String... headers) {\n\t\tthis.config.setAllowedHeaders(Arrays.asList(headers));\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "list", "of", "headers", "that", "a", "pre", "flight", "request", "can", "list", "as", "allowed", "for", "use", "during", "an", "actual", "request"], "project": "spring-framework"}
{"id": 7534, "code": "\tpublic static Object getSessionMutex(FacesContext fc) {\n\t\tAssert.notNull(fc, \"FacesContext must not be null\");\n\t\tExternalContext ec = fc.getExternalContext();\n\t\tObject mutex = ec.getSessionMap().get(WebUtils.SESSION_MUTEX_ATTRIBUTE);\n\t\tif (mutex == null) {\n\t\t\tmutex = ec.getSession(true);\n\t\t}\n\t\treturn mutex;\n\t}", "summary_tokens": ["return", "the", "best", "available", "mutex", "for", "the", "given", "session", "that", "is", "an", "object", "to", "synchronize", "on", "for", "the", "given", "session"], "project": "spring-framework"}
{"id": 380, "code": "\tpublic Class<?> getRequiredType() {\n\t\treturn this.requiredType;\n\t}", "summary_tokens": ["return", "the", "expected", "type", "for", "the", "bean"], "project": "spring-framework"}
{"id": 31, "code": "\tpublic final Class<?> getAspectClass() {\n\t\treturn this.aspectClass;\n\t}", "summary_tokens": ["return", "the", "specified", "aspect", "class", "never", "null"], "project": "spring-framework"}
{"id": 8552, "code": "\tpublic boolean isEmpty() {\n\t\treturn (this.view == null && CollectionUtils.isEmpty(this.model));\n\t}", "summary_tokens": ["return", "whether", "this", "model", "and", "view", "object", "is", "empty", "i"], "project": "spring-framework"}
{"id": 5051, "code": "\tpublic void setOutboundPrefix(@Nullable String outboundPrefix) {\n\t\tthis.outboundPrefix = (outboundPrefix != null ? outboundPrefix : \"\");\n\t}", "summary_tokens": ["specify", "a", "prefix", "to", "be", "appended", "to", "the", "protocol", "property", "name", "for", "any", "user", "defined", "message", "header", "that", "is", "being", "mapped", "into", "the", "protocol", "specific", "message"], "project": "spring-framework"}
{"id": 7878, "code": "\tprivate int findRegexStart(char[] data, int offset) {\n\t\tint pos = offset;\n\t\twhile (pos < data.length) {\n\t\t\tif (data[pos] == ':') {\n\t\t\t\treturn pos + 1;\n\t\t\t}\n\t\t\tpos++;\n\t\t}\n\t\treturn -1;\n\t}", "summary_tokens": ["for", "a", "path", "element", "representing", "a", "captured", "variable", "locate", "the", "constraint", "pattern"], "project": "spring-framework"}
{"id": 2817, "code": "\tpublic static CharSequenceEncoder textPlainOnly() {\n\t\treturn new CharSequenceEncoder(new MimeType(\"text\", \"plain\", DEFAULT_CHARSET));\n\t}", "summary_tokens": ["create", "a", "char", "sequence", "encoder", "that", "supports", "only", "text", "plain"], "project": "spring-framework"}
{"id": 1472, "code": "\tpublic void setStylePattern(String stylePattern) {\n\t\tthis.stylePattern = stylePattern;\n\t}", "summary_tokens": ["set", "the", "two", "characters", "to", "use", "to", "format", "date", "values"], "project": "spring-framework"}
{"id": 7628, "code": "\tpublic ModelAndViewContainer mergeAttributes(@Nullable Map<String, ?> attributes) {\n\t\tgetModel().mergeAttributes(attributes);\n\t\treturn this;\n\t}", "summary_tokens": ["copy", "attributes", "in", "the", "supplied", "map", "with", "existing", "objects", "of", "the", "same", "name", "taking", "precedence", "i"], "project": "spring-framework"}
{"id": 2000, "code": "\tpublic BindingErrorProcessor getBindingErrorProcessor() {\n\t\treturn this.bindingErrorProcessor;\n\t}", "summary_tokens": ["return", "the", "strategy", "for", "processing", "binding", "errors"], "project": "spring-framework"}
{"id": 5891, "code": "\tpublic WebTestClient.ResponseSpec location(String location) {\n\t\treturn assertHeader(\"Location\", URI.create(location), getHeaders().getLocation());\n\t}", "summary_tokens": ["expect", "a", "location", "header", "with", "the", "given", "value"], "project": "spring-framework"}
{"id": 5455, "code": "\tpublic void setSameSite(@Nullable String sameSite) {\n\t\tthis.sameSite = sameSite;\n\t}", "summary_tokens": ["set", "the", "same", "site", "attribute", "for", "this", "cookie"], "project": "spring-framework"}
{"id": 423, "code": "\tpublic Object getSuggestedValue(DependencyDescriptor descriptor) {\n\t\tObject value = findValue(descriptor.getAnnotations());\n\t\tif (value == null) {\n\t\t\tMethodParameter methodParam = descriptor.getMethodParameter();\n\t\t\tif (methodParam != null) {\n\t\t\t\tvalue = findValue(methodParam.getMethodAnnotations());\n\t\t\t}\n\t\t}\n\t\treturn value;\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "dependency", "declares", "a", "value", "annotation"], "project": "spring-framework"}
{"id": 112, "code": "\tpublic static AdvisorAdapterRegistry getInstance() {\n\t\treturn instance;\n\t}", "summary_tokens": ["return", "the", "singleton", "default", "advisor", "adapter", "registry", "instance"], "project": "spring-framework"}
{"id": 8585, "code": "\tpublic ContentNegotiationConfigurer defaultContentType(MediaType... defaultContentTypes) {\n\t\tthis.factory.setDefaultContentTypes(Arrays.asList(defaultContentTypes));\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "default", "content", "type", "s", "to", "use", "when", "no", "content", "type", "is", "requested", "in", "order", "of", "priority"], "project": "spring-framework"}
{"id": 4667, "code": "\tpublic String getReceiveTimeoutHeader() {\n\t\treturn this.receiveTimeoutHeader;\n\t}", "summary_tokens": ["return", "the", "configured", "receive", "timeout", "header"], "project": "spring-framework"}
{"id": 9005, "code": "\tpublic boolean useSuffixPatternMatch() {\n\t\treturn this.useSuffixPatternMatch;\n\t}", "summary_tokens": ["whether", "to", "use", "registered", "suffixes", "for", "pattern", "matching"], "project": "spring-framework"}
{"id": 5635, "code": "\tprivate Statement withPotentialRepeat(Statement next, Method testMethod, Object testInstance) {\n\t\treturn new SpringRepeat(next, testMethod);\n\t}", "summary_tokens": ["wrap", "the", "supplied", "statement", "with", "a", "spring", "repeat", "statement"], "project": "spring-framework"}
{"id": 7003, "code": "\tpublic void setDefaultViewInclusion(boolean defaultViewInclusion) {\n\t\tthis.builder.defaultViewInclusion(defaultViewInclusion);\n\t}", "summary_tokens": ["shortcut", "for", "mapper", "feature", "default", "view", "inclusion", "option"], "project": "spring-framework"}
{"id": 7249, "code": "\tpublic int getRawStatusCode() {\n\t\treturn this.statusCode.value();\n\t}", "summary_tokens": ["return", "the", "raw", "http", "status", "code", "value"], "project": "spring-framework"}
{"id": 6470, "code": "\tprotected void doSetRollbackOnly(DefaultTransactionStatus status) throws TransactionException {\n\t\tthrow new IllegalTransactionStateException(\n\t\t\t\t\"Participating in existing transactions is not supported - when 'isExistingTransaction' \" +\n\t\t\t\t\"returns true, appropriate 'doSetRollbackOnly' behavior must be provided\");\n\t}", "summary_tokens": ["set", "the", "given", "transaction", "rollback", "only"], "project": "spring-framework"}
{"id": 6400, "code": "\tpublic Object unbindResource(Object key) throws IllegalStateException {\n\t\tObject actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key);\n\t\tObject value = doUnbindResource(actualKey);\n\t\tif (value == null) {\n\t\t\tthrow new IllegalStateException(\"No value for key [\" + actualKey + \"] bound to context\");\n\t\t}\n\t\treturn value;\n\t}", "summary_tokens": ["unbind", "a", "resource", "for", "the", "given", "key", "from", "the", "current", "context"], "project": "spring-framework"}
{"id": 2299, "code": "\tpublic Predicate<RuntimeHints> onType(TypeReference typeReference) {\n\t\tAssert.notNull(typeReference, \"'typeReference' should not be null\");\n\t\treturn hints -> hints.serialization().javaSerialization().anyMatch(\n\t\t\t\thint -> hint.getType().equals(typeReference));\n\t}", "summary_tokens": ["return", "a", "predicate", "that", "checks", "whether", "a", "serialization", "hints", "serialization", "hint", "is", "registered", "for", "the", "given", "type", "reference"], "project": "spring-framework"}
{"id": 7656, "code": "\tpublic static void bindParts(HttpServletRequest request, MutablePropertyValues mpvs, boolean bindEmpty)\n\t\t\tthrows MultipartException {\n\n\t\tgetParts(request).forEach((key, values) -> {\n\t\t\tif (values.size() == 1) {\n\t\t\t\tPart part = values.get(0);\n\t\t\t\tif (bindEmpty || part.getSize() > 0) {\n\t\t\t\t\tmpvs.add(key, part);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tmpvs.add(key, values);\n\t\t\t}\n\t\t});\n\t}", "summary_tokens": ["bind", "all", "parts", "from", "the", "given", "servlet", "request"], "project": "spring-framework"}
{"id": 3347, "code": "\tpublic static String arrayToCommaDelimitedString(@Nullable Object[] arr) {\n\t\treturn arrayToDelimitedString(arr, \",\");\n\t}", "summary_tokens": ["convert", "a", "string", "array", "into", "a", "comma", "delimited", "string", "i"], "project": "spring-framework"}
{"id": 897, "code": "\tpublic int getFirstLinkedPage() {\n\t\treturn Math.max(0, getPage() - (getMaxLinkedPages() / 2));\n\t}", "summary_tokens": ["return", "the", "first", "page", "to", "which", "create", "a", "link", "around", "the", "current", "page"], "project": "spring-framework"}
{"id": 5657, "code": "\tprotected void beforeOrAfterTestMethod(TestContext testContext, MethodMode requiredMethodMode,\n\t\t\tClassMode requiredClassMode) throws Exception {\n\n\t\tAssert.notNull(testContext, \"TestContext must not be null\");\n\t\tAssert.notNull(requiredMethodMode, \"requiredMethodMode must not be null\");\n\t\tAssert.notNull(requiredClassMode, \"requiredClassMode must not be null\");\n\n\t\tClass<?> testClass = testContext.getTestClass();\n\t\tMethod testMethod = testContext.getTestMethod();\n\t\tAssert.notNull(testClass, \"The test class of the supplied TestContext must not be null\");\n\t\tAssert.notNull(testMethod, \"The test method of the supplied TestContext must not be null\");\n\n\t\tDirtiesContext methodAnn = AnnotatedElementUtils.findMergedAnnotation(testMethod, DirtiesContext.class);\n\t\tDirtiesContext classAnn = TestContextAnnotationUtils.findMergedAnnotation(testClass, DirtiesContext.class);\n\t\tboolean methodAnnotated = (methodAnn != null);\n\t\tboolean classAnnotated = (classAnn != null);\n\t\tMethodMode methodMode = (methodAnnotated ? methodAnn.methodMode() : null);\n\t\tClassMode classMode = (classAnnotated ? classAnn.classMode() : null);\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tString phase = (requiredClassMode.name().startsWith(\"BEFORE\") ? \"Before\" : \"After\");\n\t\t\tlogger.debug(String.format(\"%s test method: context %s, class annotated with @DirtiesContext [%s] \"\n\t\t\t\t\t+ \"with mode [%s], method annotated with @DirtiesContext [%s] with mode [%s].\", phase, testContext,\n\t\t\t\tclassAnnotated, classMode, methodAnnotated, methodMode));\n\t\t}\n\n\t\tif ((methodMode == requiredMethodMode) || (classMode == requiredClassMode)) {\n\t\t\tHierarchyMode hierarchyMode = (methodAnnotated ? methodAnn.hierarchyMode() : classAnn.hierarchyMode());\n\t\t\tdirtyContext(testContext, hierarchyMode);\n\t\t}\n\t}", "summary_tokens": ["perform", "the", "actual", "work", "for", "before", "test", "method", "and", "after", "test", "method", "by", "dirtying", "the", "context", "if", "appropriate", "i"], "project": "spring-framework"}
{"id": 4972, "code": "\tpublic boolean isDefaultHeartbeatEnabled() {\n\t\tlong[] heartbeat = getDefaultHeartbeat();\n\t\treturn (heartbeat[0] != 0 && heartbeat[1] != 0);\n\t}", "summary_tokens": ["determine", "whether", "heartbeats", "are", "enabled"], "project": "spring-framework"}
{"id": 4470, "code": "\tpublic int getIdleReceivesPerTaskLimit() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\treturn this.idleReceivesPerTaskLimit;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "maximum", "number", "of", "subsequent", "null", "messages", "to", "receive", "in", "a", "single", "task", "before", "marking", "the", "consumer", "as", "idle"], "project": "spring-framework"}
{"id": 1493, "code": "\tpublic void setFormatName(String formatName) {\n\t\tthis.formatName = formatName;\n\t}", "summary_tokens": ["specify", "the", "format", "name", "to", "be", "resolved", "by", "the", "jsr", "0", "provider", "at", "runtime"], "project": "spring-framework"}
{"id": 8557, "code": "\tpublic static RuntimeBeanReference registerUrlPathHelper(\n\t\t\t@Nullable RuntimeBeanReference urlPathHelperRef, ParserContext context, @Nullable Object source) {\n\n\t\tif (urlPathHelperRef != null) {\n\t\t\tif (context.getRegistry().isAlias(URL_PATH_HELPER_BEAN_NAME)) {\n\t\t\t\tcontext.getRegistry().removeAlias(URL_PATH_HELPER_BEAN_NAME);\n\t\t\t}\n\t\t\tcontext.getRegistry().registerAlias(urlPathHelperRef.getBeanName(), URL_PATH_HELPER_BEAN_NAME);\n\t\t}\n\t\telse if (!context.getRegistry().isAlias(URL_PATH_HELPER_BEAN_NAME) &&\n\t\t\t\t!context.getRegistry().containsBeanDefinition(URL_PATH_HELPER_BEAN_NAME)) {\n\t\t\tRootBeanDefinition urlPathHelperDef = new RootBeanDefinition(UrlPathHelper.class);\n\t\t\turlPathHelperDef.setSource(source);\n\t\t\turlPathHelperDef.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\t\tcontext.getRegistry().registerBeanDefinition(URL_PATH_HELPER_BEAN_NAME, urlPathHelperDef);\n\t\t\tcontext.registerComponent(new BeanComponentDefinition(urlPathHelperDef, URL_PATH_HELPER_BEAN_NAME));\n\t\t}\n\t\treturn new RuntimeBeanReference(URL_PATH_HELPER_BEAN_NAME);\n\t}", "summary_tokens": ["adds", "an", "alias", "to", "an", "existing", "well", "known", "name", "or", "registers", "a", "new", "instance", "of", "a", "url", "path", "helper", "under", "that", "well", "known", "name", "unless", "already", "registered"], "project": "spring-framework"}
{"id": 258, "code": "\tpublic int getMinIdle() {\n\t\treturn this.minIdle;\n\t}", "summary_tokens": ["return", "the", "minimum", "number", "of", "idle", "objects", "in", "the", "pool"], "project": "spring-framework"}
{"id": 4336, "code": "\tpublic void setQosSettings(QosSettings settings) {\n\t\tAssert.notNull(settings, \"Settings must not be null\");\n\t\tsetExplicitQosEnabled(true);\n\t\tsetDeliveryMode(settings.getDeliveryMode());\n\t\tsetPriority(settings.getPriority());\n\t\tsetTimeToLive(settings.getTimeToLive());\n\t}", "summary_tokens": ["set", "the", "qos", "settings", "to", "use", "when", "sending", "a", "message"], "project": "spring-framework"}
{"id": 8878, "code": "\tpublic boolean isEmpty() {\n\t\treturn ObjectUtils.isEmpty(this.requestConditions);\n\t}", "summary_tokens": ["whether", "this", "instance", "contains", "0", "conditions", "or", "not"], "project": "spring-framework"}
{"id": 9276, "code": "\tpublic void doFinally() {\n\t\tsuper.doFinally();\n\t\tremoveAttributes();\n\t\tthis.tagWriter = null;\n\t\tthis.bodyContent = null;\n\t}", "summary_tokens": ["clean", "up", "any", "attributes", "and", "stored", "resources"], "project": "spring-framework"}
{"id": 5644, "code": "\tpublic void evaluate() throws Throwable {\n\t\tthis.testContextManager.beforeTestMethod(this.testInstance, this.testMethod);\n\t\tthis.next.evaluate();\n\t}", "summary_tokens": ["invoke", "test", "context", "manager", "before", "test", "method", "object", "method", "and", "then", "evaluate", "the", "next", "statement", "in", "the", "execution", "chain", "typically", "an", "instance", "of", "org"], "project": "spring-framework"}
{"id": 8053, "code": "\tdefault WebSocketService getWebSocketService() {\n\t\treturn null;\n\t}", "summary_tokens": ["provide", "the", "web", "socket", "service", "to", "create", "org"], "project": "spring-framework"}
{"id": 1794, "code": "\tprotected Runnable createRunnable(Object target, Method method) {\n\t\tAssert.isTrue(method.getParameterCount() == 0, \"Only no-arg methods may be annotated with @Scheduled\");\n\t\tMethod invocableMethod = AopUtils.selectInvocableMethod(method, target.getClass());\n\t\treturn new ScheduledMethodRunnable(target, invocableMethod);\n\t}", "summary_tokens": ["create", "a", "runnable", "for", "the", "given", "bean", "instance", "calling", "the", "specified", "scheduled", "method"], "project": "spring-framework"}
{"id": 563, "code": "\tpublic void setSupportedTypes(Class<?>... supportedTypes) {\n\t\tif (ObjectUtils.isEmpty(supportedTypes)) {\n\t\t\tthis.supportedTypes = Collections.emptySet();\n\t\t}\n\t\telse {\n\t\t\tAssert.noNullElements(supportedTypes, \"'supportedTypes' must not contain null elements\");\n\t\t\tthis.supportedTypes = Arrays.stream(supportedTypes).map(Class::getName)\n\t\t\t\t\t.collect(Collectors.toUnmodifiableSet());\n\t\t}\n\t}", "summary_tokens": ["set", "the", "supported", "types", "that", "can", "be", "loaded", "from", "yaml", "documents"], "project": "spring-framework"}
{"id": 7177, "code": "\tpublic static boolean[] getRequiredBooleanParameters(ServletRequest request, String name)\n\t\t\tthrows ServletRequestBindingException {\n\n\t\treturn BOOLEAN_PARSER.parseBooleans(name, request.getParameterValues(name));\n\t}", "summary_tokens": ["get", "an", "array", "of", "boolean", "parameters", "throwing", "an", "exception", "if", "not", "found", "or", "one", "isn", "t", "a", "boolean"], "project": "spring-framework"}
{"id": 9309, "code": "\tprotected String getOnmouseout() {\n\t\treturn this.onmouseout;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "onmouseout", "attribute"], "project": "spring-framework"}
{"id": 2263, "code": "\tpublic ReflectionHints registerType(Class<?> type, Consumer<TypeHint.Builder> typeHint) {\n\t\treturn registerType(TypeReference.of(type), typeHint);\n\t}", "summary_tokens": ["register", "or", "customize", "reflection", "hints", "for", "the", "specified", "type"], "project": "spring-framework"}
{"id": 4026, "code": "\tpublic void setDatabasePopulator(DatabasePopulator databasePopulator) {\n\t\tthis.databasePopulator = databasePopulator;\n\t}", "summary_tokens": ["set", "the", "database", "populator", "to", "execute", "during", "the", "bean", "initialization", "phase"], "project": "spring-framework"}
{"id": 2257, "code": "\tpublic List<TypeReference> getProxiedInterfaces() {\n\t\treturn this.proxiedInterfaces;\n\t}", "summary_tokens": ["return", "the", "interfaces", "to", "be", "proxied"], "project": "spring-framework"}
{"id": 7991, "code": "\tpublic CorsRegistration addMapping(String pathPattern) {\n\t\tCorsRegistration registration = new CorsRegistration(pathPattern);\n\t\tthis.registrations.add(registration);\n\t\treturn registration;\n\t}", "summary_tokens": ["enable", "cross", "origin", "request", "handling", "for", "the", "specified", "path", "pattern"], "project": "spring-framework"}
{"id": 9787, "code": "\tprotected boolean requiresTaskScheduler() {\n\t\treturn this.registrations.stream()\n\t\t\t\t.anyMatch(r -> r.getSockJsServiceRegistration() != null &&\n\t\t\t\t\t\tr.getSockJsServiceRegistration().getTaskScheduler() == null);\n\t}", "summary_tokens": ["whether", "there", "are", "any", "endpoint", "sock", "js", "registrations", "without", "a", "task", "scheduler"], "project": "spring-framework"}
{"id": 2546, "code": "private void addConstantIntegerOrFloat(final int index, final int tag, final int value) {\n  add(new Entry(index, tag, value, hash(tag, value)));\n}", "summary_tokens": ["adds", "a", "new", "constant", "integer", "info", "or", "constant", "float", "info", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 6674, "code": "\tpublic List<String> getIfMatch() {\n\t\treturn getETagValuesAsList(IF_MATCH);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "if", "match", "header"], "project": "spring-framework"}
{"id": 2726, "code": "\tpublic ReactiveTypeDescriptor getDescriptor() {\n\t\treturn this.descriptor;\n\t}", "summary_tokens": ["return", "the", "descriptor", "of", "the", "reactive", "type", "for", "the", "adapter"], "project": "spring-framework"}
{"id": 3947, "code": "\tprotected DataSource obtainTargetDataSource() {\n\t\tDataSource dataSource = getTargetDataSource();\n\t\tAssert.state(dataSource != null, \"No 'targetDataSource' set\");\n\t\treturn dataSource;\n\t}", "summary_tokens": ["obtain", "the", "target", "data", "source", "for", "actual", "use", "never", "null"], "project": "spring-framework"}
{"id": 5767, "code": "\tpublic static void invokeSetterMethod(Object target, String name, @Nullable Object value, @Nullable Class<?> type) {\n\t\tAssert.notNull(target, \"Target object must not be null\");\n\t\tAssert.hasText(name, \"Method name must not be empty\");\n\t\tClass<?>[] paramTypes = (type != null ? new Class<?>[] {type} : null);\n\n\t\tString setterMethodName = name;\n\t\tif (!name.startsWith(SETTER_PREFIX)) {\n\t\t\tsetterMethodName = SETTER_PREFIX + StringUtils.capitalize(name);\n\t\t}\n\n\t\tMethod method = ReflectionUtils.findMethod(target.getClass(), setterMethodName, paramTypes);\n\t\tif (method == null && !setterMethodName.equals(name)) {\n\t\t\tsetterMethodName = name;\n\t\t\tmethod = ReflectionUtils.findMethod(target.getClass(), setterMethodName, paramTypes);\n\t\t}\n\t\tif (method == null) {\n\t\t\tthrow new IllegalArgumentException(String.format(\n\t\t\t\t\t\"Could not find setter method '%s' on %s with parameter type [%s]\", setterMethodName,\n\t\t\t\t\tsafeToString(target), type));\n\t\t}\n\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(String.format(\"Invoking setter method '%s' on %s with value [%s]\", setterMethodName,\n\t\t\t\t\tsafeToString(target), value));\n\t\t}\n\n\t\tReflectionUtils.makeAccessible(method);\n\t\tReflectionUtils.invokeMethod(method, target, value);\n\t}", "summary_tokens": ["invoke", "the", "setter", "method", "with", "the", "given", "name", "on", "the", "supplied", "target", "object", "with", "the", "supplied", "value"], "project": "spring-framework"}
{"id": 5324, "code": "\tpublic Marshaller getMarshaller() {\n\t\treturn this.marshaller;\n\t}", "summary_tokens": ["return", "the", "marshaller", "used", "by", "this", "marshalling", "source"], "project": "spring-framework"}
{"id": 1121, "code": "\tprivate void populateSchedulerContext(Scheduler scheduler) throws SchedulerException {\n\t\t\n\t\tif (this.schedulerContextMap != null) {\n\t\t\tscheduler.getContext().putAll(this.schedulerContextMap);\n\t\t}\n\n\t\t\n\t\tif (this.applicationContextSchedulerContextKey != null) {\n\t\t\tif (this.applicationContext == null) {\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"SchedulerFactoryBean needs to be set up in an ApplicationContext \" +\n\t\t\t\t\t\"to be able to handle an 'applicationContextSchedulerContextKey'\");\n\t\t\t}\n\t\t\tscheduler.getContext().put(this.applicationContextSchedulerContextKey, this.applicationContext);\n\t\t}\n\t}", "summary_tokens": ["expose", "the", "specified", "context", "attributes", "and", "or", "the", "current", "application", "context", "in", "the", "quartz", "scheduler", "context"], "project": "spring-framework"}
{"id": 2311, "code": "static void putAnnotations(\n    final SymbolTable symbolTable,\n    final AnnotationWriter lastRuntimeVisibleAnnotation,\n    final AnnotationWriter lastRuntimeInvisibleAnnotation,\n    final AnnotationWriter lastRuntimeVisibleTypeAnnotation,\n    final AnnotationWriter lastRuntimeInvisibleTypeAnnotation,\n    final ByteVector output) {\n  if (lastRuntimeVisibleAnnotation != null) {\n    lastRuntimeVisibleAnnotation.putAnnotations(\n        symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_ANNOTATIONS), output);\n  }\n  if (lastRuntimeInvisibleAnnotation != null) {\n    lastRuntimeInvisibleAnnotation.putAnnotations(\n        symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_ANNOTATIONS), output);\n  }\n  if (lastRuntimeVisibleTypeAnnotation != null) {\n    lastRuntimeVisibleTypeAnnotation.putAnnotations(\n        symbolTable.addConstantUtf8(Constants.RUNTIME_VISIBLE_TYPE_ANNOTATIONS), output);\n  }\n  if (lastRuntimeInvisibleTypeAnnotation != null) {\n    lastRuntimeInvisibleTypeAnnotation.putAnnotations(\n        symbolTable.addConstantUtf8(Constants.RUNTIME_INVISIBLE_TYPE_ANNOTATIONS), output);\n  }\n}", "summary_tokens": ["puts", "the", "runtime", "in", "visible", "type", "annotations", "attributes", "containing", "the", "given", "annotations", "and", "all", "their", "i", "predecessors", "i", "see", "previous", "annotation", "in", "the", "given", "byte", "vector"], "project": "spring-framework"}
{"id": 7832, "code": "\tpublic static String encodeHost(String host, Charset charset) {\n\t\treturn encode(host, charset, HierarchicalUriComponents.Type.HOST_IPV4);\n\t}", "summary_tokens": ["encode", "the", "given", "uri", "host", "with", "the", "given", "encoding"], "project": "spring-framework"}
{"id": 5486, "code": "\tprivate static boolean isTestEnabledInThisEnvironment(ProfileValueSource profileValueSource,\n\t\t\t@Nullable IfProfileValue ifProfileValue) {\n\n\t\tif (ifProfileValue == null) {\n\t\t\treturn true;\n\t\t}\n\n\t\tString environmentValue = profileValueSource.get(ifProfileValue.name());\n\t\tString[] annotatedValues = ifProfileValue.values();\n\t\tif (StringUtils.hasLength(ifProfileValue.value())) {\n\t\t\tAssert.isTrue(annotatedValues.length == 0, () -> \"Setting both the 'value' and 'values' attributes \" +\n\t\t\t\t\t\t\"of @IfProfileValue is not allowed: choose one or the other.\");\n\t\t\tannotatedValues = new String[] { ifProfileValue.value() };\n\t\t}\n\n\t\tfor (String value : annotatedValues) {\n\t\t\tif (ObjectUtils.nullSafeEquals(value, environmentValue)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "if", "the", "value", "or", "one", "of", "the", "values", "in", "the", "supplied", "if", "profile", "value", "0", "if", "profile", "value", "annotation", "is", "em", "enabled", "em", "in", "the", "current", "environment"], "project": "spring-framework"}
{"id": 6321, "code": "\tprotected UserTransaction retrieveUserTransaction() throws TransactionSystemException {\n\t\treturn null;\n\t}", "summary_tokens": ["allows", "subclasses", "to", "retrieve", "the", "jta", "user", "transaction", "in", "a", "vendor", "specific", "manner"], "project": "spring-framework"}
{"id": 6997, "code": "\tpublic void setFilters(FilterProvider filters) {\n\t\tthis.builder.filters(filters);\n\t}", "summary_tokens": ["set", "the", "global", "filters", "to", "use", "in", "order", "to", "support", "json", "filter", "annotated", "pojo"], "project": "spring-framework"}
{"id": 4512, "code": "\tpublic void setDefaultListenerMethod(String defaultListenerMethod) {\n\t\tthis.defaultListenerMethod = defaultListenerMethod;\n\t}", "summary_tokens": ["specify", "the", "name", "of", "the", "default", "listener", "method", "to", "delegate", "to", "for", "the", "case", "where", "no", "specific", "listener", "method", "has", "been", "determined"], "project": "spring-framework"}
{"id": 1197, "code": "\tpublic void setCacheOperationSource(CacheOperationSource cacheOperationSource) {\n\t\tthis.cacheOperationSource = cacheOperationSource;\n\t}", "summary_tokens": ["set", "the", "cache", "operation", "attribute", "source", "which", "is", "used", "to", "find", "cache", "attributes"], "project": "spring-framework"}
{"id": 5784, "code": "\tpublic static <T> T assertAndReturnModelAttributeOfType(ModelAndView mav, String modelName, Class<T> expectedType) {\n\t\tMap<String, Object> model = mav.getModel();\n\t\tObject obj = model.get(modelName);\n\t\tif (obj == null) {\n\t\t\tfail(\"Model attribute with name '\" + modelName + \"' is null\");\n\t\t}\n\t\tassertTrue(\"Model attribute is not of expected type '\" + expectedType.getName() + \"' but rather of type '\" +\n\t\t\t\tobj.getClass().getName() + \"'\", expectedType.isAssignableFrom(obj.getClass()));\n\t\treturn (T) obj;\n\t}", "summary_tokens": ["checks", "whether", "the", "model", "value", "under", "the", "given", "model", "name", "exists", "and", "checks", "its", "type", "based", "on", "the", "expected", "type"], "project": "spring-framework"}
{"id": 4429, "code": "\tprotected void rollbackOnExceptionIfNecessary(Session session, Throwable ex) throws JMSException {\n\t\ttry {\n\t\t\tif (session.getTransacted()) {\n\t\t\t\tif (isSessionLocallyTransacted(session)) {\n\t\t\t\t\t\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Initiating transaction rollback on application exception\", ex);\n\t\t\t\t\t}\n\t\t\t\t\tJmsUtils.rollbackIfNecessary(session);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (isClientAcknowledge(session)) {\n\t\t\t\tsession.recover();\n\t\t\t}\n\t\t}\n\t\tcatch (IllegalStateException ex2) {\n\t\t\tlogger.debug(\"Could not roll back because Session already closed\", ex2);\n\t\t}\n\t\tcatch (JMSException | RuntimeException | Error ex2) {\n\t\t\tlogger.error(\"Application exception overridden by rollback error\", ex);\n\t\t\tthrow ex2;\n\t\t}\n\t}", "summary_tokens": ["perform", "a", "rollback", "handling", "rollback", "exceptions", "properly"], "project": "spring-framework"}
{"id": 2224, "code": "\tpublic void reserveMethodNames(String... reservedMethodNames) {\n\t\tfor (String reservedMethodName : reservedMethodNames) {\n\t\t\tString generatedName = generateSequencedMethodName(MethodName.of(reservedMethodNames));\n\t\t\tAssert.state(generatedName.equals(reservedMethodName),\n\t\t\t\t\t() -> String.format(\"Unable to reserve method name '%s'\", reservedMethodName));\n\t\t}\n\t}", "summary_tokens": ["update", "this", "instance", "with", "a", "set", "of", "reserved", "method", "names", "that", "should", "not", "be", "used", "for", "generated", "methods"], "project": "spring-framework"}
{"id": 3303, "code": "\tpublic static String trimWhitespace(String str) {\n\t\tif (!hasLength(str)) {\n\t\t\treturn str;\n\t\t}\n\n\t\treturn str.strip();\n\t}", "summary_tokens": ["trim", "leading", "and", "trailing", "whitespace", "from", "the", "given", "string"], "project": "spring-framework"}
{"id": 2097, "code": "\tprivate void cglibAssertions(TestBean tb) {\n\t\tCountingBeforeAdvice cba = (CountingBeforeAdvice) beanFactory.getBean(\"countingBeforeAdvice\");\n\t\tNopInterceptor nop = (NopInterceptor) beanFactory.getBean(\"nopInterceptor\");\n\t\tassertThat(cba.getCalls()).isEqualTo(0);\n\t\tassertThat(nop.getCount()).isEqualTo(0);\n\t\tassertThat(AopUtils.isCglibProxy(tb)).isTrue();\n\t\tint age = 5;\n\t\ttb.setAge(age);\n\t\tassertThat(tb.getAge()).isEqualTo(age);\n\t\tassertThat(nop.getCount()).isEqualTo(2);\n\t\tassertThat(cba.getCalls()).isEqualTo(2);\n\t}", "summary_tokens": ["also", "has", "counting", "before", "advice"], "project": "spring-framework"}
{"id": 6371, "code": "\tpublic boolean hasTransaction() {\n\t\treturn (this.transaction != null);\n\t}", "summary_tokens": ["return", "whether", "there", "is", "an", "actual", "transaction", "active"], "project": "spring-framework"}
{"id": 5088, "code": "\tpublic void setNativeHeader(String name, @Nullable String value) {\n\t\tAssert.state(isMutable(), \"Already immutable\");\n\t\tMap<String, List<String>> map = getNativeHeaders();\n\t\tif (value == null) {\n\t\t\tif (map != null && map.get(name) != null) {\n\t\t\t\tsetModified(true);\n\t\t\t\tmap.remove(name);\n\t\t\t}\n\t\t\treturn;\n\t\t}\n\t\tif (map == null) {\n\t\t\tmap = new LinkedMultiValueMap<>(3);\n\t\t\tsetHeader(NATIVE_HEADERS, map);\n\t\t}\n\t\tList<String> values = new ArrayList<>(1);\n\t\tvalues.add(value);\n\t\tif (!ObjectUtils.nullSafeEquals(values, getHeader(name))) {\n\t\t\tsetModified(true);\n\t\t\tmap.put(name, values);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "specified", "native", "header", "value", "replacing", "existing", "values"], "project": "spring-framework"}
{"id": 2418, "code": "public int getSize() {\n  char firstCharOfDescriptor = descriptor.charAt(0);\n  return (firstCharOfDescriptor == 'J' || firstCharOfDescriptor == 'D') ? 2 : 1;\n}", "summary_tokens": ["returns", "the", "size", "of", "this", "constant"], "project": "spring-framework"}
{"id": 935, "code": "\tpublic void autoAliasing() {\n\t\tList beanNames = Arrays.asList(getListableBeanFactory().getBeanDefinitionNames());\n\n\t\tTestBean tb1 = (TestBean) getBeanFactory().getBean(\"aliased\");\n\t\tTestBean alias1 = (TestBean) getBeanFactory().getBean(\"myalias\");\n\t\tassertThat(tb1 == alias1).isTrue();\n\t\tList tb1Aliases = Arrays.asList(getBeanFactory().getAliases(\"aliased\"));\n\t\tassertThat(tb1Aliases.size()).isEqualTo(2);\n\t\tassertThat(tb1Aliases.contains(\"myalias\")).isTrue();\n\t\tassertThat(tb1Aliases.contains(\"youralias\")).isTrue();\n\t\tassertThat(beanNames.contains(\"aliased\")).isTrue();\n\t\tassertThat(beanNames.contains(\"myalias\")).isFalse();\n\t\tassertThat(beanNames.contains(\"youralias\")).isFalse();\n\n\t\tTestBean tb2 = (TestBean) getBeanFactory().getBean(\"multiAliased\");\n\t\tTestBean alias2 = (TestBean) getBeanFactory().getBean(\"alias1\");\n\t\tTestBean alias3 = (TestBean) getBeanFactory().getBean(\"alias2\");\n\t\tTestBean alias3a = (TestBean) getBeanFactory().getBean(\"alias3\");\n\t\tTestBean alias3b = (TestBean) getBeanFactory().getBean(\"alias4\");\n\t\tassertThat(tb2 == alias2).isTrue();\n\t\tassertThat(tb2 == alias3).isTrue();\n\t\tassertThat(tb2 == alias3a).isTrue();\n\t\tassertThat(tb2 == alias3b).isTrue();\n\n\t\tList tb2Aliases = Arrays.asList(getBeanFactory().getAliases(\"multiAliased\"));\n\t\tassertThat(tb2Aliases.size()).isEqualTo(4);\n\t\tassertThat(tb2Aliases.contains(\"alias1\")).isTrue();\n\t\tassertThat(tb2Aliases.contains(\"alias2\")).isTrue();\n\t\tassertThat(tb2Aliases.contains(\"alias3\")).isTrue();\n\t\tassertThat(tb2Aliases.contains(\"alias4\")).isTrue();\n\t\tassertThat(beanNames.contains(\"multiAliased\")).isTrue();\n\t\tassertThat(beanNames.contains(\"alias1\")).isFalse();\n\t\tassertThat(beanNames.contains(\"alias2\")).isFalse();\n\t\tassertThat(beanNames.contains(\"alias3\")).isFalse();\n\t\tassertThat(beanNames.contains(\"alias4\")).isFalse();\n\n\t\tTestBean tb3 = (TestBean) getBeanFactory().getBean(\"aliasWithoutId1\");\n\t\tTestBean alias4 = (TestBean) getBeanFactory().getBean(\"aliasWithoutId2\");\n\t\tTestBean alias5 = (TestBean) getBeanFactory().getBean(\"aliasWithoutId3\");\n\t\tassertThat(tb3 == alias4).isTrue();\n\t\tassertThat(tb3 == alias5).isTrue();\n\t\tList tb3Aliases = Arrays.asList(getBeanFactory().getAliases(\"aliasWithoutId1\"));\n\t\tassertThat(tb3Aliases.size()).isEqualTo(2);\n\t\tassertThat(tb3Aliases.contains(\"aliasWithoutId2\")).isTrue();\n\t\tassertThat(tb3Aliases.contains(\"aliasWithoutId3\")).isTrue();\n\t\tassertThat(beanNames.contains(\"aliasWithoutId1\")).isTrue();\n\t\tassertThat(beanNames.contains(\"aliasWithoutId2\")).isFalse();\n\t\tassertThat(beanNames.contains(\"aliasWithoutId3\")).isFalse();\n\n\t\tTestBean tb4 = (TestBean) getBeanFactory().getBean(TestBean.class.getName() + \"#0\");\n\t\tassertThat(tb4.getName()).isNull();\n\n\t\tMap drs = getListableBeanFactory().getBeansOfType(DummyReferencer.class, false, false);\n\t\tassertThat(drs.size()).isEqualTo(5);\n\t\tassertThat(drs.containsKey(DummyReferencer.class.getName() + \"#0\")).isTrue();\n\t\tassertThat(drs.containsKey(DummyReferencer.class.getName() + \"#1\")).isTrue();\n\t\tassertThat(drs.containsKey(DummyReferencer.class.getName() + \"#2\")).isTrue();\n\t}", "summary_tokens": ["test", "that", "properties", "with", "name", "as", "well", "as", "id", "creating", "an", "alias", "up", "front"], "project": "spring-framework"}
{"id": 746, "code": "\tpublic void setQualifiedElement(@Nullable AnnotatedElement qualifiedElement) {\n\t\tthis.qualifiedElement = qualifiedElement;\n\t}", "summary_tokens": ["specify", "the", "annotated", "element", "defining", "qualifiers", "to", "be", "used", "instead", "of", "the", "target", "class", "or", "factory", "method"], "project": "spring-framework"}
{"id": 7544, "code": "\tprivate Object resolveEmbeddedValuesAndExpressions(String value) {\n\t\tif (this.configurableBeanFactory == null || this.expressionContext == null) {\n\t\t\treturn value;\n\t\t}\n\t\tString placeholdersResolved = this.configurableBeanFactory.resolveEmbeddedValue(value);\n\t\tBeanExpressionResolver exprResolver = this.configurableBeanFactory.getBeanExpressionResolver();\n\t\tif (exprResolver == null) {\n\t\t\treturn value;\n\t\t}\n\t\treturn exprResolver.evaluate(placeholdersResolved, this.expressionContext);\n\t}", "summary_tokens": ["resolve", "the", "given", "annotation", "specified", "value", "potentially", "containing", "placeholders", "and", "expressions"], "project": "spring-framework"}
{"id": 9341, "code": "\tpublic String getElement() {\n\t\treturn this.element;\n\t}", "summary_tokens": ["get", "the", "html", "element", "used", "to", "enclose", "input", "type", "checkbox", "radio", "tag"], "project": "spring-framework"}
{"id": 5764, "code": "\tpublic void assertJsonNotEqual(String expected, String actual, boolean strict) throws Exception {\n\t\tJSONAssert.assertNotEquals(expected, actual, strict);\n\t}", "summary_tokens": ["parse", "the", "expected", "and", "actual", "strings", "as", "json", "and", "assert", "the", "two", "are", "not", "similar", "i"], "project": "spring-framework"}
{"id": 1091, "code": "\tpublic void setTransactionManager(PlatformTransactionManager transactionManager) {\n\t\tthis.transactionManager = transactionManager;\n\t}", "summary_tokens": ["set", "the", "transaction", "manager", "to", "be", "used", "for", "registering", "jobs", "and", "triggers", "that", "are", "defined", "by", "this", "scheduler", "factory", "bean"], "project": "spring-framework"}
{"id": 2356, "code": "private int readStackMapFrame(\n    final int stackMapFrameOffset,\n    final boolean compressed,\n    final boolean expand,\n    final Context context) {\n  int currentOffset = stackMapFrameOffset;\n  final char[] charBuffer = context.charBuffer;\n  final Label[] labels = context.currentMethodLabels;\n  int frameType;\n  if (compressed) {\n      \n    frameType = classFileBuffer[currentOffset++] & 0xFF;\n  } else {\n    frameType = Frame.FULL_FRAME;\n    context.currentFrameOffset = -1;\n  }\n  int offsetDelta;\n  context.currentFrameLocalCountDelta = 0;\n  if (frameType < Frame.SAME_LOCALS_1_STACK_ITEM_FRAME) {\n    offsetDelta = frameType;\n    context.currentFrameType = Opcodes.F_SAME;\n    context.currentFrameStackCount = 0;\n  } else if (frameType < Frame.RESERVED) {\n    offsetDelta = frameType - Frame.SAME_LOCALS_1_STACK_ITEM_FRAME;\n    currentOffset =\n        readVerificationTypeInfo(\n            currentOffset, context.currentFrameStackTypes, 0, charBuffer, labels);\n    context.currentFrameType = Opcodes.F_SAME1;\n    context.currentFrameStackCount = 1;\n  } else if (frameType >= Frame.SAME_LOCALS_1_STACK_ITEM_FRAME_EXTENDED) {\n    offsetDelta = readUnsignedShort(currentOffset);\n    currentOffset += 2;\n    if (frameType == Frame.SAME_LOCALS_1_STACK_ITEM_FRAME_EXTENDED) {\n      currentOffset =\n          readVerificationTypeInfo(\n              currentOffset, context.currentFrameStackTypes, 0, charBuffer, labels);\n      context.currentFrameType = Opcodes.F_SAME1;\n      context.currentFrameStackCount = 1;\n    } else if (frameType >= Frame.CHOP_FRAME && frameType < Frame.SAME_FRAME_EXTENDED) {\n      context.currentFrameType = Opcodes.F_CHOP;\n      context.currentFrameLocalCountDelta = Frame.SAME_FRAME_EXTENDED - frameType;\n      context.currentFrameLocalCount -= context.currentFrameLocalCountDelta;\n      context.currentFrameStackCount = 0;\n    } else if (frameType == Frame.SAME_FRAME_EXTENDED) {\n      context.currentFrameType = Opcodes.F_SAME;\n      context.currentFrameStackCount = 0;\n    } else if (frameType < Frame.FULL_FRAME) {\n      int local = expand ? context.currentFrameLocalCount : 0;\n      for (int k = frameType - Frame.SAME_FRAME_EXTENDED; k > 0; k--) {\n        currentOffset =\n            readVerificationTypeInfo(\n                currentOffset, context.currentFrameLocalTypes, local++, charBuffer, labels);\n      }\n      context.currentFrameType = Opcodes.F_APPEND;\n      context.currentFrameLocalCountDelta = frameType - Frame.SAME_FRAME_EXTENDED;\n      context.currentFrameLocalCount += context.currentFrameLocalCountDelta;\n      context.currentFrameStackCount = 0;\n    } else {\n      final int numberOfLocals = readUnsignedShort(currentOffset);\n      currentOffset += 2;\n      context.currentFrameType = Opcodes.F_FULL;\n      context.currentFrameLocalCountDelta = numberOfLocals;\n      context.currentFrameLocalCount = numberOfLocals;\n      for (int local = 0; local < numberOfLocals; ++local) {\n        currentOffset =\n            readVerificationTypeInfo(\n                currentOffset, context.currentFrameLocalTypes, local, charBuffer, labels);\n      }\n      final int numberOfStackItems = readUnsignedShort(currentOffset);\n      currentOffset += 2;\n      context.currentFrameStackCount = numberOfStackItems;\n      for (int stack = 0; stack < numberOfStackItems; ++stack) {\n        currentOffset =\n            readVerificationTypeInfo(\n                currentOffset, context.currentFrameStackTypes, stack, charBuffer, labels);\n      }\n    }\n  } else {\n    throw new IllegalArgumentException();\n  }\n  context.currentFrameOffset += offsetDelta + 1;\n  createLabel(context.currentFrameOffset, labels);\n  return currentOffset;\n}", "summary_tokens": ["reads", "a", "jvms", "stack", "map", "frame", "structure", "and", "stores", "the", "result", "in", "the", "given", "context", "object"], "project": "spring-framework"}
{"id": 6407, "code": "\tpublic void clearSynchronization() throws IllegalStateException {\n\t\tif (!isSynchronizationActive()) {\n\t\t\tthrow new IllegalStateException(\"Cannot deactivate transaction synchronization - not active\");\n\t\t}\n\t\tthis.transactionContext.setSynchronizations(null);\n\t}", "summary_tokens": ["deactivate", "transaction", "synchronization", "for", "the", "current", "context"], "project": "spring-framework"}
{"id": 7944, "code": "\tpublic void invalidate() {\n\t\tassertIsValid();\n\t\tthis.invalid = true;\n\t\tclearAttributes();\n\t}", "summary_tokens": ["invalidates", "this", "session", "then", "unbinds", "any", "objects", "bound", "to", "it"], "project": "spring-framework"}
{"id": 159, "code": "\tprotected final BeanFactory getBeanFactory() {\n\t\treturn this.beanFactory;\n\t}", "summary_tokens": ["return", "the", "bean", "factory", "that", "this", "target", "source", "creators", "runs", "in"], "project": "spring-framework"}
{"id": 5681, "code": "\tstatic Map<String, List<ContextConfigurationAttributes>> buildContextHierarchyMap(Class<?> testClass) {\n\t\tMap<String, List<ContextConfigurationAttributes>> map = new LinkedHashMap<>();\n\t\tint hierarchyLevel = 1;\n\n\t\tfor (List<ContextConfigurationAttributes> configAttributesList : resolveContextHierarchyAttributes(testClass)) {\n\t\t\tfor (ContextConfigurationAttributes configAttributes : configAttributesList) {\n\t\t\t\tString name = configAttributes.getName();\n\n\t\t\t\t\n\t\t\t\tif (!StringUtils.hasText(name)) {\n\t\t\t\t\tname = GENERATED_CONTEXT_HIERARCHY_LEVEL_PREFIX + hierarchyLevel;\n\t\t\t\t}\n\n\t\t\t\t\n\t\t\t\tif (!map.containsKey(name)) {\n\t\t\t\t\thierarchyLevel++;\n\t\t\t\t\tmap.put(name, new ArrayList<>());\n\t\t\t\t}\n\n\t\t\t\tmap.get(name).add(configAttributes);\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tSet<List<ContextConfigurationAttributes>> set = new HashSet<>(map.values());\n\t\tif (set.size() != map.size()) {\n\t\t\tString msg = String.format(\"The @ContextConfiguration elements configured via @ContextHierarchy in \" +\n\t\t\t\t\t\"test class [%s] and its superclasses must define unique contexts per hierarchy level.\",\n\t\t\t\t\ttestClass.getName());\n\t\t\tlogger.error(msg);\n\t\t\tthrow new IllegalStateException(msg);\n\t\t}\n\n\t\treturn map;\n\t}", "summary_tokens": ["build", "a", "em", "context", "hierarchy", "map", "em", "for", "the", "supplied", "class", "test", "class", "and", "its", "superclasses", "and", "enclosing", "classes", "taking", "into", "account", "context", "hierarchies", "declared", "via", "context", "hierarchy", "and", "context", "configuration"], "project": "spring-framework"}
{"id": 9759, "code": "\tpublic boolean isAutoStartup() {\n\t\treturn this.autoStartup;\n\t}", "summary_tokens": ["return", "the", "value", "for", "the", "auto", "startup", "property"], "project": "spring-framework"}
{"id": 372, "code": "\tpublic Class<?> getRequiredType() {\n\t\treturn this.requiredType;\n\t}", "summary_tokens": ["return", "the", "required", "target", "type", "if", "any"], "project": "spring-framework"}
{"id": 5992, "code": "\tpublic ResultMatcher longValue(String name, long value) {\n\t\treturn result -> {\n\t\t\tMockHttpServletResponse response = result.getResponse();\n\t\t\tassertTrue(\"Response does not contain header '\" + name + \"'\", response.containsHeader(name));\n\t\t\tString headerValue = response.getHeader(name);\n\t\t\tif (headerValue != null) {\n\t\t\t\tassertEquals(\"Response header '\" + name + \"'\", value, Long.parseLong(headerValue));\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "primary", "value", "of", "the", "named", "response", "header", "as", "a", "long"], "project": "spring-framework"}
{"id": 358, "code": "\tpublic String getPropertyName() {\n\t\treturn this.propertyName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "requested", "property"], "project": "spring-framework"}
{"id": 3037, "code": "\tpublic static Log getCompositeLog(Log primaryLogger, Log secondaryLogger, Log... tertiaryLoggers) {\n\t\tList<Log> loggers = new ArrayList<>(2 + tertiaryLoggers.length);\n\t\tloggers.add(primaryLogger);\n\t\tloggers.add(secondaryLogger);\n\t\tCollections.addAll(loggers, tertiaryLoggers);\n\t\treturn new CompositeLog(loggers);\n\t}", "summary_tokens": ["create", "a", "composite", "logger", "that", "delegates", "to", "a", "primary", "or", "falls", "back", "on", "a", "secondary", "logger", "if", "logging", "for", "the", "primary", "logger", "is", "not", "enabled"], "project": "spring-framework"}
{"id": 1960, "code": "\tprotected Object formatFieldValue(String field, @Nullable Object value) {\n\t\tString fixedField = fixedField(field);\n\t\t\n\t\tPropertyEditor customEditor = getCustomEditor(fixedField);\n\t\tif (customEditor != null) {\n\t\t\tcustomEditor.setValue(value);\n\t\t\tString textValue = customEditor.getAsText();\n\t\t\t\n\t\t\t\n\t\t\tif (textValue != null) {\n\t\t\t\treturn textValue;\n\t\t\t}\n\t\t}\n\t\tif (this.conversionService != null) {\n\t\t\t\n\t\t\tTypeDescriptor fieldDesc = getPropertyAccessor().getPropertyTypeDescriptor(fixedField);\n\t\t\tTypeDescriptor strDesc = TypeDescriptor.valueOf(String.class);\n\t\t\tif (fieldDesc != null && this.conversionService.canConvert(fieldDesc, strDesc)) {\n\t\t\t\treturn this.conversionService.convert(value, fieldDesc, strDesc);\n\t\t\t}\n\t\t}\n\t\treturn value;\n\t}", "summary_tokens": ["formats", "the", "field", "value", "based", "on", "registered", "property", "editors"], "project": "spring-framework"}
{"id": 4287, "code": "\tprotected String getClientId() {\n\t\treturn this.clientId;\n\t}", "summary_tokens": ["return", "a", "jms", "client", "id", "for", "the", "single", "connection", "created", "and", "exposed", "by", "this", "connection", "factory", "if", "any"], "project": "spring-framework"}
{"id": 9845, "code": "\tpublic List<String> getSubProtocols() {\n\t\treturn new ArrayList<>(this.protocolHandlerLookup.keySet());\n\t}", "summary_tokens": ["return", "all", "supported", "protocols"], "project": "spring-framework"}
{"id": 7288, "code": "\tpublic boolean hasResult() {\n\t\treturn (this.result != RESULT_NONE);\n\t}", "summary_tokens": ["return", "true", "if", "the", "deferred", "result", "has", "been", "set"], "project": "spring-framework"}
{"id": 334, "code": "\tprivate static int getNestedPropertySeparatorIndex(String propertyPath, boolean last) {\n\t\tboolean inKey = false;\n\t\tint length = propertyPath.length();\n\t\tint i = (last ? length - 1 : 0);\n\t\twhile (last ? i >= 0 : i < length) {\n\t\t\tswitch (propertyPath.charAt(i)) {\n\t\t\t\tcase PropertyAccessor.PROPERTY_KEY_PREFIX_CHAR:\n\t\t\t\tcase PropertyAccessor.PROPERTY_KEY_SUFFIX_CHAR:\n\t\t\t\t\tinKey = !inKey;\n\t\t\t\t\tbreak;\n\t\t\t\tcase PropertyAccessor.NESTED_PROPERTY_SEPARATOR_CHAR:\n\t\t\t\t\tif (!inKey) {\n\t\t\t\t\t\treturn i;\n\t\t\t\t\t}\n\t\t\t}\n\t\t\tif (last) {\n\t\t\t\ti--;\n\t\t\t}\n\t\t\telse {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\treturn -1;\n\t}", "summary_tokens": ["determine", "the", "first", "or", "last", "nested", "property", "separator", "in", "the", "given", "property", "path", "ignoring", "dots", "in", "keys", "like", "map", "my"], "project": "spring-framework"}
{"id": 6927, "code": "\tpublic Function<Marshaller, Marshaller> getMarshallerProcessor() {\n\t\treturn this.marshallerProcessor;\n\t}", "summary_tokens": ["return", "the", "configured", "processor", "for", "customizing", "marshaller", "instances"], "project": "spring-framework"}
{"id": 7207, "code": "\tpublic final void setConversionService(@Nullable ConversionService conversionService) {\n\t\tthis.conversionService = conversionService;\n\t}", "summary_tokens": ["specify", "a", "conversion", "service", "which", "will", "apply", "to", "every", "data", "binder"], "project": "spring-framework"}
{"id": 3439, "code": "\tvoid getAllAnnotationAttributesOnClassWithMultipleComposedAnnotations() {\n\t\t\n\t\tMultiValueMap<String, Object> attributes = getAllAnnotationAttributes(TxFromMultipleComposedAnnotations.class, TX_NAME);\n\t\tassertThat(attributes).as(\"Annotation attributes map for @Transactional on TxFromMultipleComposedAnnotations\").isNotNull();\n\t\tassertThat(attributes.get(\"value\")).as(\"value for TxFromMultipleComposedAnnotations.\").isEqualTo(asList(\"TxInheritedComposed\", \"TxComposed\"));\n\t}", "summary_tokens": ["note", "this", "functionality", "is", "required", "by", "org"], "project": "spring-framework"}
{"id": 8959, "code": "\tpublic void setArgumentResolvers(@Nullable List<HandlerMethodArgumentResolver> argumentResolvers) {\n\t\tif (argumentResolvers == null) {\n\t\t\tthis.argumentResolvers = null;\n\t\t}\n\t\telse {\n\t\t\tthis.argumentResolvers = new HandlerMethodArgumentResolverComposite();\n\t\t\tthis.argumentResolvers.addResolvers(argumentResolvers);\n\t\t}\n\t}", "summary_tokens": ["configure", "the", "complete", "list", "of", "supported", "argument", "types", "thus", "overriding", "the", "resolvers", "that", "would", "otherwise", "be", "configured", "by", "default"], "project": "spring-framework"}
{"id": 8546, "code": "\tpublic Map<String, Object> getModel() {\n\t\treturn getModelMap();\n\t}", "summary_tokens": ["return", "the", "model", "map"], "project": "spring-framework"}
{"id": 4115, "code": "\tpublic List<T> executeByNamedParam(Map<String, ?> paramMap) throws DataAccessException {\n\t\treturn executeByNamedParam(paramMap, null);\n\t}", "summary_tokens": ["convenient", "method", "to", "execute", "without", "context"], "project": "spring-framework"}
{"id": 3418, "code": "\tpublic XMLEventWriter getXMLEventWriter() {\n\t\treturn this.eventWriter;\n\t}", "summary_tokens": ["return", "the", "xmlevent", "writer", "used", "by", "this", "stax", "result"], "project": "spring-framework"}
{"id": 2467, "code": "public void visitParameter(final String name, final int access) {\n  if (api < Opcodes.ASM5) {\n    throw new UnsupportedOperationException(REQUIRES_ASM5);\n  }\n  if (mv != null) {\n    mv.visitParameter(name, access);\n  }\n}", "summary_tokens": ["visits", "a", "parameter", "of", "this", "method"], "project": "spring-framework"}
{"id": 962, "code": "\tpublic void registerCustomCache(String name, com.github.benmanes.caffeine.cache.Cache<Object, Object> cache) {\n\t\tthis.customCacheNames.add(name);\n\t\tthis.cacheMap.put(name, adaptCaffeineCache(name, cache));\n\t}", "summary_tokens": ["register", "the", "given", "native", "caffeine", "cache", "instance", "with", "this", "cache", "manager", "adapting", "it", "to", "spring", "s", "cache", "api", "for", "exposure", "through", "get", "cache"], "project": "spring-framework"}
{"id": 3398, "code": "\tpublic long toTerabytes() {\n\t\treturn this.bytes / BYTES_PER_TB;\n\t}", "summary_tokens": ["return", "the", "number", "of", "terabytes", "in", "this", "instance"], "project": "spring-framework"}
{"id": 6929, "code": "\tpublic int getMaxInMemorySize() {\n\t\treturn this.maxInMemorySize;\n\t}", "summary_tokens": ["return", "the", "set", "max", "in", "memory", "size", "configured", "byte", "count", "limit"], "project": "spring-framework"}
{"id": 8378, "code": "\tpublic void setViewNames(@Nullable String... viewNames) {\n\t\tthis.viewNames = viewNames;\n\t}", "summary_tokens": ["set", "the", "view", "names", "or", "name", "patterns", "that", "can", "be", "handled", "by", "this", "view", "resolver"], "project": "spring-framework"}
{"id": 7794, "code": "\tpublic static boolean hasParsedRequestPath(ServletRequest request) {\n\t\treturn (request.getAttribute(PATH_ATTRIBUTE) != null);\n\t}", "summary_tokens": ["check", "for", "a", "parse", "and", "cache", "previously", "parsed", "and", "cached", "request", "path"], "project": "spring-framework"}
{"id": 2825, "code": "\tpublic static <T> T getRequiredHint(@Nullable Map<String, Object> hints, String hintName) {\n\t\tif (hints == null) {\n\t\t\tthrow new IllegalArgumentException(\"No hints map for required hint '\" + hintName + \"'\");\n\t\t}\n\t\tT hint = (T) hints.get(hintName);\n\t\tif (hint == null) {\n\t\t\tthrow new IllegalArgumentException(\"Hints map must contain the hint '\" + hintName + \"'\");\n\t\t}\n\t\treturn hint;\n\t}", "summary_tokens": ["obtain", "the", "value", "for", "a", "required", "hint"], "project": "spring-framework"}
{"id": 9012, "code": "\tprotected RequestMappingInfo createRequestMappingInfo(\n\t\t\tRequestMapping requestMapping, @Nullable RequestCondition<?> customCondition) {\n\n\t\tRequestMappingInfo.Builder builder = RequestMappingInfo\n\t\t\t\t.paths(resolveEmbeddedValuesInPatterns(requestMapping.path()))\n\t\t\t\t.methods(requestMapping.method())\n\t\t\t\t.params(requestMapping.params())\n\t\t\t\t.headers(requestMapping.headers())\n\t\t\t\t.consumes(requestMapping.consumes())\n\t\t\t\t.produces(requestMapping.produces())\n\t\t\t\t.mappingName(requestMapping.name());\n\t\tif (customCondition != null) {\n\t\t\tbuilder.customCondition(customCondition);\n\t\t}\n\t\treturn builder.options(this.config).build();\n\t}", "summary_tokens": ["create", "a", "request", "mapping", "info", "from", "the", "supplied", "request", "mapping", "annotation", "which", "is", "either", "a", "directly", "declared", "annotation", "a", "meta", "annotation", "or", "the", "synthesized", "result", "of", "merging", "annotation", "attributes", "within", "an", "annotation", "hierarchy"], "project": "spring-framework"}
{"id": 5750, "code": "\tprotected MergedContextConfiguration processMergedContextConfiguration(MergedContextConfiguration mergedConfig) {\n\t\tWebAppConfiguration webAppConfiguration = getWebAppConfiguration(mergedConfig.getTestClass());\n\t\tif (webAppConfiguration != null) {\n\t\t\treturn new WebMergedContextConfiguration(mergedConfig, webAppConfiguration.value());\n\t\t}\n\t\telse {\n\t\t\treturn mergedConfig;\n\t\t}\n\t}", "summary_tokens": ["returns", "a", "web", "merged", "context", "configuration", "if", "the", "test", "class", "in", "the", "supplied", "merged", "context", "configuration", "is", "annotated", "with", "web", "app", "configuration", "and", "otherwise", "returns", "the", "supplied", "instance", "unmodified"], "project": "spring-framework"}
{"id": 9605, "code": "\tprotected ResourceBundle getBundle(String basename, Locale locale) throws MissingResourceException {\n\t\treturn ResourceBundle.getBundle(basename, locale, getBundleClassLoader());\n\t}", "summary_tokens": ["obtain", "the", "resource", "bundle", "for", "the", "given", "basename", "and", "locale"], "project": "spring-framework"}
{"id": 1516, "code": "\tpublic byte[] transformIfNecessary(String className, String internalName, byte[] bytes, @Nullable ProtectionDomain pd) {\n\t\tbyte[] result = bytes;\n\t\tfor (ClassFileTransformer cft : this.transformers) {\n\t\t\ttry {\n\t\t\t\tbyte[] transformed = cft.transform(this.classLoader, internalName, null, pd, result);\n\t\t\t\tif (transformed != null) {\n\t\t\t\t\tresult = transformed;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (IllegalClassFormatException ex) {\n\t\t\t\tthrow new IllegalStateException(\"Class file transformation failed\", ex);\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["apply", "transformation", "on", "a", "given", "class", "byte", "definition"], "project": "spring-framework"}
{"id": 5823, "code": "\tpublic RequestMatcher doesNotExist() {\n\t\treturn new AbstractJsonPathRequestMatcher() {\n\t\t\t@Override\n\t\t\tprotected void matchInternal(MockClientHttpRequest request) throws IOException, ParseException {\n\t\t\t\tJsonPathRequestMatchers.this.jsonPathHelper.doesNotExist(request.getBodyAsString());\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "json", "path", "expression", "against", "the", "request", "content", "and", "assert", "that", "a", "value", "does", "not", "exist", "at", "the", "given", "path"], "project": "spring-framework"}
{"id": 3667, "code": "\tpublic ConversionService getConversionService() {\n\t\treturn this.conversionService;\n\t}", "summary_tokens": ["return", "a", "conversion", "service", "for", "binding", "jdbc", "values", "to", "bean", "properties", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 3881, "code": "\tprotected Number doExecuteAndReturnKey(SqlParameterSource parameterSource) {\n\t\tcheckCompiled();\n\t\tList<Object> values = matchInParameterValuesWithInsertColumns(parameterSource);\n\t\treturn executeInsertAndReturnKeyInternal(values);\n\t}", "summary_tokens": ["method", "that", "provides", "execution", "of", "the", "insert", "using", "the", "passed", "in", "sql", "parameter", "source", "and", "returning", "a", "generated", "key"], "project": "spring-framework"}
{"id": 679, "code": "\tprotected Object resolveAutowiredArgument(MethodParameter param, String beanName,\n\t\t\t@Nullable Set<String> autowiredBeanNames, TypeConverter typeConverter, boolean fallback) {\n\n\t\tClass<?> paramType = param.getParameterType();\n\t\tif (InjectionPoint.class.isAssignableFrom(paramType)) {\n\t\t\tInjectionPoint injectionPoint = currentInjectionPoint.get();\n\t\t\tif (injectionPoint == null) {\n\t\t\t\tthrow new IllegalStateException(\"No current InjectionPoint available for \" + param);\n\t\t\t}\n\t\t\treturn injectionPoint;\n\t\t}\n\t\ttry {\n\t\t\treturn this.beanFactory.resolveDependency(\n\t\t\t\t\tnew DependencyDescriptor(param, true), beanName, autowiredBeanNames, typeConverter);\n\t\t}\n\t\tcatch (NoUniqueBeanDefinitionException ex) {\n\t\t\tthrow ex;\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\tif (fallback) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tif (paramType.isArray()) {\n\t\t\t\t\treturn Array.newInstance(paramType.getComponentType(), 0);\n\t\t\t\t}\n\t\t\t\telse if (CollectionFactory.isApproximableCollectionType(paramType)) {\n\t\t\t\t\treturn CollectionFactory.createCollection(paramType, 0);\n\t\t\t\t}\n\t\t\t\telse if (CollectionFactory.isApproximableMapType(paramType)) {\n\t\t\t\t\treturn CollectionFactory.createMap(paramType, 0);\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t}", "summary_tokens": ["template", "method", "for", "resolving", "the", "specified", "argument", "which", "is", "supposed", "to", "be", "autowired"], "project": "spring-framework"}
{"id": 4245, "code": "\tprivate void startIfNecessary(MessageListenerContainer listenerContainer) {\n\t\tif (this.contextRefreshed || listenerContainer.isAutoStartup()) {\n\t\t\tlistenerContainer.start();\n\t\t}\n\t}", "summary_tokens": ["start", "the", "specified", "message", "listener", "container", "if", "it", "should", "be", "started", "on", "startup", "or", "when", "start", "is", "called", "explicitly", "after", "startup"], "project": "spring-framework"}
{"id": 4590, "code": "\tpublic Message toMessage(Object object, Session session) throws JMSException, MessageConversionException {\n\t\tif (object instanceof Message) {\n\t\t\treturn (Message) object;\n\t\t}\n\t\telse if (object instanceof String) {\n\t\t\treturn createMessageForString((String) object, session);\n\t\t}\n\t\telse if (object instanceof byte[]) {\n\t\t\treturn createMessageForByteArray((byte[]) object, session);\n\t\t}\n\t\telse if (object instanceof Map) {\n\t\t\treturn createMessageForMap((Map<? ,?>) object, session);\n\t\t}\n\t\telse if (object instanceof Serializable) {\n\t\t\treturn createMessageForSerializable(((Serializable) object), session);\n\t\t}\n\t\telse {\n\t\t\tthrow new MessageConversionException(\"Cannot convert object of type [\" +\n\t\t\t\t\tObjectUtils.nullSafeClassName(object) + \"] to JMS message. Supported message \" +\n\t\t\t\t\t\"payloads are: String, byte array, Map<String,?>, Serializable object.\");\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "creates", "a", "text", "message", "for", "a", "string", "a", "bytes", "message", "for", "a", "byte", "array", "a", "map", "message", "for", "a", "map", "and", "an", "object", "message", "for", "a", "serializable", "object"], "project": "spring-framework"}
{"id": 291, "code": "\tpublic void testSelectiveApplication() {\n\t\tTestBean target = new TestBean();\n\t\ttarget.setAge(27);\n\t\tNopInterceptor nop = new NopInterceptor();\n\t\tControlFlowPointcut cflow = new ControlFlowPointcut(One.class);\n\t\tPointcut settersUnderOne = Pointcuts.intersection(Pointcuts.SETTERS, cflow);\n\t\tProxyFactory pf = new ProxyFactory(target);\n\t\tITestBean proxied = (ITestBean) pf.getProxy();\n\t\tpf.addAdvisor(new DefaultPointcutAdvisor(settersUnderOne, nop));\n\n\t\t\n\t\ttarget.setAge(16);\n\t\tassertThat(nop.getCount()).isEqualTo(0);\n\n\t\t\n\t\tassertThat(new One().getAge(proxied)).isEqualTo(16);\n\t\tassertThat(nop.getCount()).isEqualTo(0);\n\n\t\t\n\t\tnew One().set(proxied);\n\t\tassertThat(nop.getCount()).isEqualTo(1);\n\n\t\t\n\t\tassertThat(cflow.getEvaluations()).isEqualTo(1);\n\t}", "summary_tokens": ["check", "that", "we", "can", "use", "a", "cflow", "pointcut", "only", "in", "conjunction", "with", "a", "static", "pointcut", "e"], "project": "spring-framework"}
{"id": 7305, "code": "\tpublic boolean isAsyncComplete() {\n\t\treturn this.asyncCompleted.get();\n\t}", "summary_tokens": ["whether", "async", "request", "processing", "has", "completed"], "project": "spring-framework"}
{"id": 8922, "code": "\tpublic RequestConditionHolder combine(RequestConditionHolder other) {\n\t\tif (this.condition == null && other.condition == null) {\n\t\t\treturn this;\n\t\t}\n\t\telse if (this.condition == null) {\n\t\t\treturn other;\n\t\t}\n\t\telse if (other.condition == null) {\n\t\t\treturn this;\n\t\t}\n\t\telse {\n\t\t\tassertEqualConditionTypes(this.condition, other.condition);\n\t\t\tRequestCondition<?> combined = (RequestCondition<?>) this.condition.combine(other.condition);\n\t\t\treturn new RequestConditionHolder(combined);\n\t\t}\n\t}", "summary_tokens": ["combine", "the", "request", "conditions", "held", "by", "the", "two", "request", "condition", "holder", "instances", "after", "making", "sure", "the", "conditions", "are", "of", "the", "same", "type"], "project": "spring-framework"}
{"id": 9489, "code": "\tpublic void setOnselect(String onselect) {\n\t\tthis.onselect = onselect;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "onselect", "attribute"], "project": "spring-framework"}
{"id": 7692, "code": "\tpublic WebSessionManager getSessionManager() {\n\t\treturn this.sessionManager;\n\t}", "summary_tokens": ["return", "the", "configured", "web", "session", "manager"], "project": "spring-framework"}
{"id": 7847, "code": "\tpublic void setRemoveSemicolonContent(boolean removeSemicolonContent) {\n\t\tcheckReadOnly();\n\t\tthis.removeSemicolonContent = removeSemicolonContent;\n\t}", "summary_tokens": ["set", "if", "semicolon", "content", "should", "be", "stripped", "from", "the", "request", "uri"], "project": "spring-framework"}
{"id": 9870, "code": "\tprotected ServerContainer getServerContainer() {\n\t\treturn this.serverContainer;\n\t}", "summary_tokens": ["return", "the", "jsr", "0", "server", "container", "to", "use", "for", "endpoint", "registration"], "project": "spring-framework"}
{"id": 3308, "code": "\tpublic static String trimTrailingCharacter(String str, char trailingCharacter) {\n\t\tif (!hasLength(str)) {\n\t\t\treturn str;\n\t\t}\n\n\t\tint endIdx = str.length() - 1;\n\t\twhile (endIdx >= 0 && trailingCharacter == str.charAt(endIdx)) {\n\t\t\tendIdx--;\n\t\t}\n\t\treturn str.substring(0, endIdx + 1);\n\t}", "summary_tokens": ["trim", "all", "occurrences", "of", "the", "supplied", "trailing", "character", "from", "the", "given", "string"], "project": "spring-framework"}
{"id": 4896, "code": "\tpublic MessageBrokerRegistry setUserDestinationPrefix(String destinationPrefix) {\n\t\tthis.userDestinationPrefix = destinationPrefix;\n\t\treturn this;\n\t}", "summary_tokens": ["configure", "the", "prefix", "used", "to", "identify", "user", "destinations"], "project": "spring-framework"}
{"id": 3427, "code": "\tpublic static void disableIndenting(Transformer transformer) {\n\t\tAssert.notNull(transformer, \"Transformer must not be null\");\n\t\ttransformer.setOutputProperty(OutputKeys.INDENT, \"no\");\n\t}", "summary_tokens": ["disable", "indenting", "for", "the", "supplied", "javax"], "project": "spring-framework"}
{"id": 9611, "code": "\tpublic void setSuffix(@Nullable String suffix) {\n\t\tthis.suffix = (suffix != null ? suffix : \"\");\n\t}", "summary_tokens": ["set", "the", "suffix", "that", "gets", "appended", "to", "view", "names", "when", "building", "a", "url"], "project": "spring-framework"}
{"id": 5645, "code": "\tpublic void evaluate() throws Throwable {\n\t\tthis.testContextManager.prepareTestInstance(this.testInstance);\n\t\tthis.next.evaluate();\n\t}", "summary_tokens": ["invoke", "test", "context", "manager", "prepare", "test", "instance", "object", "and", "then", "evaluate", "the", "next", "statement", "in", "the", "execution", "chain", "typically", "an", "instance", "of", "run", "after", "test", "method", "callbacks"], "project": "spring-framework"}
{"id": 370, "code": "\tpublic String getPropertyName() {\n\t\treturn this.propertyName;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "affected", "property", "if", "available"], "project": "spring-framework"}
{"id": 7971, "code": "\tpublic BindingContext getBindingContext() {\n\t\treturn this.bindingContext;\n\t}", "summary_tokens": ["return", "the", "binding", "context", "used", "for", "request", "handling"], "project": "spring-framework"}
{"id": 7396, "code": "\tprotected final ServletContext getServletContext() throws IllegalStateException {\n\t\tif (this.servletContext != null) {\n\t\t\treturn this.servletContext;\n\t\t}\n\t\tServletContext servletContext = null;\n\t\tWebApplicationContext wac = getWebApplicationContext();\n\t\tif (wac != null) {\n\t\t\tservletContext = wac.getServletContext();\n\t\t}\n\t\tif (servletContext == null && isContextRequired()) {\n\t\t\tthrow new IllegalStateException(\"WebApplicationObjectSupport instance [\" + this +\n\t\t\t\t\t\"] does not run within a ServletContext. Make sure the object is fully configured!\");\n\t\t}\n\t\treturn servletContext;\n\t}", "summary_tokens": ["return", "the", "current", "servlet", "context"], "project": "spring-framework"}
{"id": 491, "code": "\tpublic String getTargetField() {\n\t\treturn this.targetField;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "field", "to", "be", "retrieved"], "project": "spring-framework"}
{"id": 5625, "code": "\tpublic Statement apply(Statement base, Description description) {\n\t\tClass<?> testClass = description.getTestClass();\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Applying SpringClassRule to test class [\" + testClass.getName() + \"]\");\n\t\t}\n\t\tTestContextManager testContextManager = getTestContextManager(testClass);\n\n\t\tStatement statement = base;\n\t\tstatement = withBeforeTestClassCallbacks(statement, testContextManager);\n\t\tstatement = withAfterTestClassCallbacks(statement, testContextManager);\n\t\tstatement = withProfileValueCheck(statement, testClass);\n\t\tstatement = withTestContextManagerCacheEviction(statement, testClass);\n\t\treturn statement;\n\t}", "summary_tokens": ["apply", "em", "class", "level", "em", "features", "of", "the", "em", "spring", "test", "context", "framework", "em", "to", "the", "supplied", "base", "statement"], "project": "spring-framework"}
{"id": 4522, "code": "\tprotected void applyAcknowledgeMode(BeanWrapper bw, int ackMode) {\n\t\tif (ackMode == Session.SESSION_TRANSACTED && bw.isWritableProperty(\"useRAManagedTransaction\")) {\n\t\t\t\n\t\t\tbw.setPropertyValue(\"useRAManagedTransaction\", \"true\");\n\t\t}\n\t\telse {\n\t\t\tsuper.applyAcknowledgeMode(bw, ackMode);\n\t\t}\n\t}", "summary_tokens": ["this", "implementation", "maps", "session", "transacted", "onto", "an", "activation", "spec", "property", "named", "use", "ramanaged", "transaction", "if", "available", "following", "active", "mq", "s", "naming", "conventions"], "project": "spring-framework"}
{"id": 5573, "code": "\tpublic void processAheadOfTime(Class<?> testClass, RuntimeHints runtimeHints, ClassLoader classLoader) {\n\t\tgetSqlAnnotationsFor(testClass).forEach(sql ->\n\t\t\tregisterClasspathResources(getScripts(sql, testClass, null, true), runtimeHints, classLoader));\n\t\tgetSqlMethods(testClass).forEach(testMethod ->\n\t\t\tgetSqlAnnotationsFor(testMethod).forEach(sql ->\n\t\t\t\tregisterClasspathResources(getScripts(sql, testClass, testMethod, false), runtimeHints, classLoader)));\n\t}", "summary_tokens": ["process", "the", "supplied", "test", "class", "and", "its", "methods", "and", "register", "run", "time", "hints", "for", "any", "sql", "scripts", "configured", "or", "detected", "as", "classpath", "resources", "via", "sql"], "project": "spring-framework"}
{"id": 7280, "code": "\tpublic HttpMethod getHttpMethod() {\n\t\treturn HttpMethod.valueOf(getRequest().getMethod());\n\t}", "summary_tokens": ["return", "the", "http", "method", "of", "the", "request"], "project": "spring-framework"}
{"id": 6005, "code": "\tpublic ResultMatcher isArray() {\n\t\treturn result -> this.jsonPathHelper.assertValueIsArray(getContent(result));\n\t}", "summary_tokens": ["evaluate", "the", "json", "path", "expression", "against", "the", "response", "content", "and", "assert", "that", "the", "result", "is", "an", "array"], "project": "spring-framework"}
{"id": 3554, "code": "\tpublic BooleanTypedValue getValueInternal(ExpressionState state) throws EvaluationException {\n\t\tSpelNodeImpl rightOperand = getRightOperand();\n\t\tTypedValue left = getLeftOperand().getValueInternal(state);\n\t\tTypedValue right = rightOperand.getValueInternal(state);\n\t\tObject leftValue = left.getValue();\n\t\tObject rightValue = right.getValue();\n\t\tBooleanTypedValue result;\n\t\tif (!(rightValue instanceof Class)) {\n\t\t\tthrow new SpelEvaluationException(getRightOperand().getStartPosition(),\n\t\t\t\t\tSpelMessage.INSTANCEOF_OPERATOR_NEEDS_CLASS_OPERAND,\n\t\t\t\t\t(rightValue == null ? \"null\" : rightValue.getClass().getName()));\n\t\t}\n\t\tClass<?> rightClass = (Class<?>) rightValue;\n\t\tif (leftValue == null) {\n\t\t\tresult = BooleanTypedValue.FALSE;  \n\t\t}\n\t\telse {\n\t\t\tresult = BooleanTypedValue.forValue(rightClass.isAssignableFrom(leftValue.getClass()));\n\t\t}\n\t\tthis.type = rightClass;\n\t\tif (rightOperand instanceof TypeReference) {\n\t\t\t\n\t\t\t\n\t\t\tthis.exitTypeDescriptor = \"Z\";\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["compare", "the", "left", "operand", "to", "see", "it", "is", "an", "instance", "of", "the", "type", "specified", "as", "the", "right", "operand"], "project": "spring-framework"}
{"id": 4177, "code": "\tpublic void setIncrementerName(String incrementerName) {\n\t\tthis.incrementerName = incrementerName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "sequence", "table"], "project": "spring-framework"}
{"id": 4445, "code": "\tprotected boolean shouldCommitAfterNoMessageReceived(Session session) {\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "whether", "to", "trigger", "a", "commit", "after", "no", "message", "has", "been", "received"], "project": "spring-framework"}
{"id": 2025, "code": "\tprotected ConfigurablePropertyAccessor createDirectFieldAccessor() {\n\t\tif (this.target == null) {\n\t\t\tthrow new IllegalStateException(\"Cannot access fields on null target instance '\" + getObjectName() + \"'\");\n\t\t}\n\t\treturn PropertyAccessorFactory.forDirectFieldAccess(this.target);\n\t}", "summary_tokens": ["create", "a", "new", "direct", "field", "accessor", "for", "the", "underlying", "target", "object"], "project": "spring-framework"}
{"id": 4949, "code": "\tpublic String getSystemPasscode() {\n\t\treturn this.systemPasscode;\n\t}", "summary_tokens": ["return", "the", "passcode", "used", "for", "the", "shared", "system", "connection", "to", "the", "stomp", "broker"], "project": "spring-framework"}
{"id": 5341, "code": "\tprivate static String buildMessage(String task, @Nullable String sql, R2dbcException ex) {\n\t\treturn task + \"; \" + (sql != null ? (\"SQL [\" + sql + \"]; \") : \"\") + ex.getMessage();\n\t}", "summary_tokens": ["build", "a", "message", "string", "for", "the", "given", "r", "0", "dbc", "exception"], "project": "spring-framework"}
{"id": 3358, "code": "\tpublic long getInterval() {\n\t\treturn this.interval;\n\t}", "summary_tokens": ["return", "the", "interval", "between", "two", "attempts", "in", "milliseconds"], "project": "spring-framework"}
{"id": 7647, "code": "\tpublic HttpStatusCode getStatusCode() {\n\t\treturn HttpStatus.BAD_REQUEST;\n\t}", "summary_tokens": ["return", "the", "http", "status", "code", "to", "use", "for", "the", "response"], "project": "spring-framework"}
{"id": 4455, "code": "\tpublic void setCacheLevelName(String constantName) throws IllegalArgumentException {\n\t\tif (!constantName.startsWith(\"CACHE_\")) {\n\t\t\tthrow new IllegalArgumentException(\"Only cache constants allowed\");\n\t\t}\n\t\tsetCacheLevel(constants.asNumber(constantName).intValue());\n\t}", "summary_tokens": ["specify", "the", "level", "of", "caching", "that", "this", "listener", "container", "is", "allowed", "to", "apply", "in", "the", "form", "of", "the", "name", "of", "the", "corresponding", "constant", "e"], "project": "spring-framework"}
{"id": 2585, "code": "public boolean equals(final Object object) {\n  if (this == object) {\n    return true;\n  }\n  if (!(object instanceof Type)) {\n    return false;\n  }\n  Type other = (Type) object;\n  if ((sort == INTERNAL ? OBJECT : sort) != (other.sort == INTERNAL ? OBJECT : other.sort)) {\n    return false;\n  }\n  int begin = valueBegin;\n  int end = valueEnd;\n  int otherBegin = other.valueBegin;\n  int otherEnd = other.valueEnd;\n    \n  if (end - begin != otherEnd - otherBegin) {\n    return false;\n  }\n  for (int i = begin, j = otherBegin; i < end; i++, j++) {\n    if (valueBuffer.charAt(i) != other.valueBuffer.charAt(j)) {\n      return false;\n    }\n  }\n  return true;\n}", "summary_tokens": ["tests", "if", "the", "given", "object", "is", "equal", "to", "this", "type"], "project": "spring-framework"}
{"id": 1606, "code": "\tprotected boolean includeReadAttribute(Method method, String beanKey) {\n\t\treturn isPublicInInterface(method, beanKey);\n\t}", "summary_tokens": ["check", "to", "see", "if", "the", "method", "is", "declared", "in", "one", "of", "the", "configured", "interfaces", "and", "that", "it", "is", "public"], "project": "spring-framework"}
{"id": 9293, "code": "\tprotected String getDir() {\n\t\treturn this.dir;\n\t}", "summary_tokens": ["get", "the", "value", "of", "the", "dir", "attribute"], "project": "spring-framework"}
{"id": 4428, "code": "\tprotected void rollbackIfNecessary(Session session) throws JMSException {\n\t\tif (session.getTransacted()) {\n\t\t\tif (isSessionLocallyTransacted(session)) {\n\t\t\t\t\n\t\t\t\tJmsUtils.rollbackIfNecessary(session);\n\t\t\t}\n\t\t}\n\t\telse if (isClientAcknowledge(session)) {\n\t\t\tsession.recover();\n\t\t}\n\t}", "summary_tokens": ["perform", "a", "rollback", "if", "appropriate"], "project": "spring-framework"}
{"id": 8224, "code": "\tpublic ConsumesRequestCondition getMatchingCondition(ServerWebExchange exchange) {\n\t\tServerHttpRequest request = exchange.getRequest();\n\t\tif (CorsUtils.isPreFlightRequest(request)) {\n\t\t\treturn EMPTY_CONDITION;\n\t\t}\n\t\tif (isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\tif (!hasBody(request) && !this.bodyRequired) {\n\t\t\treturn EMPTY_CONDITION;\n\t\t}\n\t\tList<ConsumeMediaTypeExpression> result = getMatchingExpressions(exchange);\n\t\treturn !CollectionUtils.isEmpty(result) ? new ConsumesRequestCondition(result) : null;\n\t}", "summary_tokens": ["checks", "if", "any", "of", "the", "contained", "media", "type", "expressions", "match", "the", "given", "request", "content", "type", "header", "and", "returns", "an", "instance", "that", "is", "guaranteed", "to", "contain", "matching", "expressions", "only"], "project": "spring-framework"}
{"id": 4358, "code": "\tprotected JmsTemplate createJmsTemplate(ConnectionFactory connectionFactory) {\n\t\treturn new JmsTemplate(connectionFactory);\n\t}", "summary_tokens": ["create", "a", "jms", "template", "for", "the", "given", "connection", "factory"], "project": "spring-framework"}
{"id": 9821, "code": "\tpublic WebSocketTransportRegistration addDecoratorFactory(WebSocketHandlerDecoratorFactory factory) {\n\t\tthis.decoratorFactories.add(factory);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "a", "factory", "that", "to", "decorate", "the", "handler", "used", "to", "process", "web", "socket", "messages"], "project": "spring-framework"}
{"id": 4750, "code": "\tpublic Map<T, HandlerMethod> getHandlerMethods() {\n\t\treturn Collections.unmodifiableMap(this.handlerMethods);\n\t}", "summary_tokens": ["return", "a", "read", "only", "map", "with", "all", "handler", "methods", "and", "their", "mappings"], "project": "spring-framework"}
{"id": 9848, "code": "\tpublic void setSendBufferSizeLimit(int sendBufferSizeLimit) {\n\t\tthis.sendBufferSizeLimit = sendBufferSizeLimit;\n\t}", "summary_tokens": ["specify", "the", "buffer", "size", "limit", "number", "of", "bytes"], "project": "spring-framework"}
{"id": 6170, "code": "\tpublic boolean wasDataUpdated() {\n\t\treturn true;\n\t}", "summary_tokens": ["return", "whether", "data", "was", "updated"], "project": "spring-framework"}
{"id": 8609, "code": "\tpublic PathMatchConfigurer setPatternParser(@Nullable PathPatternParser patternParser) {\n\t\tthis.patternParser = patternParser;\n\t\tthis.preferPathMatcher = (patternParser == null);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "path", "pattern", "parser", "to", "parse", "path", "pattern", "patterns", "with", "for", "url", "path", "matching"], "project": "spring-framework"}
{"id": 9474, "code": "\tpublic int doEndTag() throws JspException {\n\t\tif (this.tagWriter != null) {\n\t\t\tthis.tagWriter.endTag();\n\t\t\twriteHiddenTagIfNecessary(this.tagWriter);\n\t\t}\n\t\treturn EVAL_PAGE;\n\t}", "summary_tokens": ["closes", "any", "block", "tag", "that", "might", "have", "been", "opened", "when", "using", "nested", "option", "tag", "options"], "project": "spring-framework"}
{"id": 9037, "code": "\tpublic void setRedirectPatterns(@Nullable String... redirectPatterns) {\n\t\tthis.redirectPatterns = redirectPatterns;\n\t}", "summary_tokens": ["configure", "one", "more", "simple", "patterns", "as", "described", "in", "pattern", "match", "utils", "simple", "match", "to", "use", "in", "order", "to", "recognize", "custom", "redirect", "prefixes", "in", "addition", "to", "redirect"], "project": "spring-framework"}
{"id": 1581, "code": "\tprotected ModelMBeanNotificationInfo[] getNotificationInfo(Object managedBean, String beanKey)\n\t\t\tthrows JMException {\n\t\treturn new ModelMBeanNotificationInfo[0];\n\t}", "summary_tokens": ["get", "the", "notification", "metadata", "for", "the", "mbean", "resource"], "project": "spring-framework"}
{"id": 2046, "code": "\tpublic void setProviderClass(Class providerClass) {\n\t\tthis.providerClass = providerClass;\n\t}", "summary_tokens": ["specify", "the", "desired", "provider", "class", "if", "any"], "project": "spring-framework"}
{"id": 1445, "code": "\tprotected Properties loadProperties(Resource resource, String filename) throws IOException {\n\t\tProperties props = newProperties();\n\t\ttry (InputStream is = resource.getInputStream()) {\n\t\t\tString resourceFilename = resource.getFilename();\n\t\t\tif (resourceFilename != null && resourceFilename.endsWith(XML_SUFFIX)) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Loading properties [\" + resource.getFilename() + \"]\");\n\t\t\t\t}\n\t\t\t\tthis.propertiesPersister.loadFromXml(props, is);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tString encoding = null;\n\t\t\t\tif (this.fileEncodings != null) {\n\t\t\t\t\tencoding = this.fileEncodings.getProperty(filename);\n\t\t\t\t}\n\t\t\t\tif (encoding == null) {\n\t\t\t\t\tencoding = getDefaultEncoding();\n\t\t\t\t}\n\t\t\t\tif (encoding != null) {\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Loading properties [\" + resource.getFilename() + \"] with encoding '\" + encoding + \"'\");\n\t\t\t\t\t}\n\t\t\t\t\tthis.propertiesPersister.load(props, new InputStreamReader(is, encoding));\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\t\tlogger.debug(\"Loading properties [\" + resource.getFilename() + \"]\");\n\t\t\t\t\t}\n\t\t\t\t\tthis.propertiesPersister.load(props, is);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn props;\n\t\t}\n\t}", "summary_tokens": ["load", "the", "properties", "from", "the", "given", "resource"], "project": "spring-framework"}
{"id": 8276, "code": "\tpublic HandlerResult invokeForHandlerResult(ServerWebExchange exchange,\n\t\t\tBindingContext bindingContext, Object... providedArgs) {\n\n\t\tCompletableFuture<HandlerResult> future =\n\t\t\t\tthis.delegate.invoke(exchange, bindingContext, providedArgs).toFuture();\n\n\t\tif (!future.isDone()) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"SyncInvocableHandlerMethod should have completed synchronously.\");\n\t\t}\n\n\t\tThrowable failure;\n\t\ttry {\n\t\t\treturn future.get();\n\t\t}\n\t\tcatch (ExecutionException ex) {\n\t\t\tfailure = ex.getCause();\n\t\t}\n\t\tcatch (InterruptedException ex) {\n\t\t\tfailure = ex;\n\t\t}\n\t\tthrow (new ServerErrorException(\n\t\t\t\t\"Failed to invoke: \" + getShortLogMessage(), getMethod(), failure));\n\t}", "summary_tokens": ["invoke", "the", "method", "for", "the", "given", "exchange"], "project": "spring-framework"}
{"id": 7526, "code": "\tprotected String getTargetBeanName(FacesContext facesContext) {\n\t\treturn DEFAULT_TARGET_BEAN_NAME;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "target", "navigation", "handler", "bean", "in", "the", "bean", "factory"], "project": "spring-framework"}
{"id": 1429, "code": "\tprotected boolean isAlwaysUseMessageFormat() {\n\t\treturn this.alwaysUseMessageFormat;\n\t}", "summary_tokens": ["return", "whether", "to", "always", "apply", "the", "message", "format", "rules", "parsing", "even", "messages", "without", "arguments"], "project": "spring-framework"}
{"id": 8009, "code": "\tpublic ResourceHandlerRegistry setOrder(int order) {\n\t\tthis.order = order;\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "the", "order", "to", "use", "for", "resource", "handling", "relative", "to", "other", "handler", "mapping", "s", "configured", "in", "the", "spring", "configuration"], "project": "spring-framework"}
{"id": 7581, "code": "\tpublic static String getNameForReturnValue(@Nullable Object returnValue, MethodParameter returnType) {\n\t\tModelAttribute ann = returnType.getMethodAnnotation(ModelAttribute.class);\n\t\tif (ann != null && StringUtils.hasText(ann.value())) {\n\t\t\treturn ann.value();\n\t\t}\n\t\telse {\n\t\t\tMethod method = returnType.getMethod();\n\t\t\tAssert.state(method != null, \"No handler method\");\n\t\t\tClass<?> containingClass = returnType.getContainingClass();\n\t\t\tClass<?> resolvedType = GenericTypeResolver.resolveReturnType(method, containingClass);\n\t\t\treturn Conventions.getVariableNameForReturnType(method, resolvedType, returnValue);\n\t\t}\n\t}", "summary_tokens": ["derive", "the", "model", "attribute", "name", "for", "the", "given", "return", "value"], "project": "spring-framework"}
{"id": 7917, "code": "\tpublic static BaseBuilder<?> get(String urlTemplate, Object... uriVars) {\n\t\treturn method(HttpMethod.GET, urlTemplate, uriVars);\n\t}", "summary_tokens": ["create", "an", "http", "get", "builder", "with", "the", "given", "uri", "template"], "project": "spring-framework"}
{"id": 3336, "code": "\tpublic static String[] trimArrayElements(String[] array) {\n\t\tif (ObjectUtils.isEmpty(array)) {\n\t\t\treturn array;\n\t\t}\n\n\t\tString[] result = new String[array.length];\n\t\tfor (int i = 0; i < array.length; i++) {\n\t\t\tString element = array[i];\n\t\t\tresult[i] = (element != null ? element.trim() : null);\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["trim", "the", "elements", "of", "the", "given", "string", "array", "calling", "string"], "project": "spring-framework"}
{"id": 9639, "code": "\tprotected AbstractUrlBasedView buildView(String viewName) throws Exception {\n\t\tAbstractUrlBasedView view = instantiateView();\n\t\tview.setUrl(getPrefix() + viewName + getSuffix());\n\t\tview.setAttributesMap(getAttributesMap());\n\n\t\tString contentType = getContentType();\n\t\tif (contentType != null) {\n\t\t\tview.setContentType(contentType);\n\t\t}\n\n\t\tString requestContextAttribute = getRequestContextAttribute();\n\t\tif (requestContextAttribute != null) {\n\t\t\tview.setRequestContextAttribute(requestContextAttribute);\n\t\t}\n\n\t\tBoolean exposePathVariables = getExposePathVariables();\n\t\tif (exposePathVariables != null) {\n\t\t\tview.setExposePathVariables(exposePathVariables);\n\t\t}\n\t\tBoolean exposeContextBeansAsAttributes = getExposeContextBeansAsAttributes();\n\t\tif (exposeContextBeansAsAttributes != null) {\n\t\t\tview.setExposeContextBeansAsAttributes(exposeContextBeansAsAttributes);\n\t\t}\n\t\tString[] exposedContextBeanNames = getExposedContextBeanNames();\n\t\tif (exposedContextBeanNames != null) {\n\t\t\tview.setExposedContextBeanNames(exposedContextBeanNames);\n\t\t}\n\n\t\treturn view;\n\t}", "summary_tokens": ["creates", "a", "new", "view", "instance", "of", "the", "specified", "view", "class", "and", "configures", "it"], "project": "spring-framework"}
{"id": 5705, "code": "\tString[] getProperties() {\n\t\treturn StringUtils.toStringArray(this.properties);\n\t}", "summary_tokens": ["get", "the", "inlined", "properties", "that", "were", "declared", "via"], "project": "spring-framework"}
{"id": 2417, "code": "Object[] getBootstrapMethodArgumentsUnsafe() {\n  return bootstrapMethodArguments;\n}", "summary_tokens": ["returns", "the", "arguments", "to", "pass", "to", "the", "bootstrap", "method", "in", "order", "to", "compute", "the", "value", "of", "this", "constant"], "project": "spring-framework"}
{"id": 5866, "code": "\tpublic WebTestClient.ResponseSpec doesNotExist(String name) {\n\t\tResponseCookie cookie = this.exchangeResult.getResponseCookies().getFirst(name);\n\t\tif (cookie != null) {\n\t\t\tString message = getMessage(name) + \" exists with value=[\" + cookie.getValue() + \"]\";\n\t\t\tthis.exchangeResult.assertWithDiagnostics(() -> AssertionErrors.fail(message));\n\t\t}\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["expect", "that", "the", "cookie", "with", "the", "given", "name", "is", "not", "present"], "project": "spring-framework"}
{"id": 7432, "code": "\tprotected List<String> checkHeaders(CorsConfiguration config, List<String> requestHeaders) {\n\t\treturn config.checkHeaders(requestHeaders);\n\t}", "summary_tokens": ["check", "the", "headers", "and", "determine", "the", "headers", "for", "the", "response", "of", "a", "pre", "flight", "request"], "project": "spring-framework"}
{"id": 8804, "code": "\tprotected void preventCaching(HttpServletResponse response) {\n\t\tresponse.addHeader(HEADER_CACHE_CONTROL, \"no-store\");\n\t}", "summary_tokens": ["prevents", "the", "response", "from", "being", "cached", "through", "setting", "corresponding", "http", "cache", "control", "no", "store", "header"], "project": "spring-framework"}
{"id": 2769, "code": "\tpublic static AnnotationAttributes getMergedAnnotationAttributes(AnnotatedElement element,\n\t\t\tString annotationName, boolean classValuesAsString, boolean nestedAnnotationsAsMap) {\n\n\t\tMergedAnnotation<?> mergedAnnotation = getAnnotations(element)\n\t\t\t\t.get(annotationName, null, MergedAnnotationSelectors.firstDirectlyDeclared());\n\t\treturn getAnnotationAttributes(mergedAnnotation, classValuesAsString, nestedAnnotationsAsMap);\n\t}", "summary_tokens": ["get", "the", "first", "annotation", "of", "the", "specified", "annotation", "name", "within", "the", "annotation", "hierarchy", "em", "above", "em", "the", "supplied", "element", "and", "merge", "that", "annotation", "s", "attributes", "with", "em", "matching", "em", "attributes", "from", "annotations", "in", "lower", "levels", "of", "the", "annotation", "hierarchy"], "project": "spring-framework"}
{"id": 8337, "code": "\tpublic String getExpression() {\n\t\treturn this.expression;\n\t}", "summary_tokens": ["return", "a", "bind", "expression", "that", "can", "be", "used", "in", "html", "forms", "as", "input", "name", "for", "the", "respective", "field", "or", "null", "if", "not", "field", "specific"], "project": "spring-framework"}
{"id": 7268, "code": "\tprotected Map<String, Object> getAttributeMap(int scope) {\n\t\tif (scope == SCOPE_REQUEST) {\n\t\t\treturn getExternalContext().getRequestMap();\n\t\t}\n\t\telse {\n\t\t\treturn getExternalContext().getSessionMap();\n\t\t}\n\t}", "summary_tokens": ["return", "the", "jsf", "attribute", "map", "for", "the", "specified", "scope"], "project": "spring-framework"}
{"id": 2258, "code": "\tpublic String getName() {\n\t\treturn this.name;\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "member"], "project": "spring-framework"}
{"id": 6322, "code": "\tprotected TransactionManager retrieveTransactionManager() throws TransactionSystemException {\n\t\treturn null;\n\t}", "summary_tokens": ["allows", "subclasses", "to", "retrieve", "the", "jta", "transaction", "manager", "in", "a", "vendor", "specific", "manner"], "project": "spring-framework"}
{"id": 5414, "code": "\tint getUnnamedParameterCount() {\n\t\treturn this.unnamedParameterCount;\n\t}", "summary_tokens": ["return", "the", "count", "of", "all", "the", "unnamed", "parameters", "in", "the", "sql", "statement"], "project": "spring-framework"}
{"id": 797, "code": "\tprotected String getParentName(Element element) {\n\t\treturn null;\n\t}", "summary_tokens": ["determine", "the", "name", "for", "the", "parent", "of", "the", "currently", "parsed", "bean", "in", "case", "of", "the", "current", "bean", "being", "defined", "as", "a", "child", "bean"], "project": "spring-framework"}
{"id": 3785, "code": "\tpublic boolean isGetGeneratedKeysSimulated() {\n\t\treturn obtainMetaDataProvider().isGetGeneratedKeysSimulated();\n\t}", "summary_tokens": ["does", "this", "database", "support", "simple", "query", "to", "retrieve", "generated", "keys", "when", "the", "jdbc", "0"], "project": "spring-framework"}
{"id": 1115, "code": "\tpublic void setStartupDelay(int startupDelay) {\n\t\tthis.startupDelay = startupDelay;\n\t}", "summary_tokens": ["set", "the", "number", "of", "seconds", "to", "wait", "after", "initialization", "before", "starting", "the", "scheduler", "asynchronously"], "project": "spring-framework"}
{"id": 7679, "code": "\tpublic MediaType getContentType() {\n\t\treturn this.contentType;\n\t}", "summary_tokens": ["return", "the", "request", "content", "type", "header", "if", "it", "was", "parsed", "successfully", "or", "null", "otherwise"], "project": "spring-framework"}
{"id": 4962, "code": "\tpublic String getStatsInfo() {\n\t\treturn this.stats.toString();\n\t}", "summary_tokens": ["return", "a", "string", "describing", "internal", "state", "and", "counters"], "project": "spring-framework"}
{"id": 712, "code": "\tprotected void clearSingletonCache() {\n\t\tsynchronized (getSingletonMutex()) {\n\t\t\tsuper.clearSingletonCache();\n\t\t\tthis.factoryBeanObjectCache.clear();\n\t\t}\n\t}", "summary_tokens": ["overridden", "to", "clear", "the", "factory", "bean", "object", "cache", "as", "well"], "project": "spring-framework"}
{"id": 1174, "code": "\tpublic final boolean isStoreByValue() {\n\t\treturn (this.serialization != null);\n\t}", "summary_tokens": ["return", "whether", "this", "cache", "stores", "a", "copy", "of", "each", "entry", "true", "or", "a", "reference", "false", "default"], "project": "spring-framework"}
{"id": 2232, "code": "\tdefault void addSourceFile(String className, InputStreamSource content) {\n\t\taddFile(Kind.SOURCE, getClassNamePath(className), content);\n\t}", "summary_tokens": ["add", "a", "generated", "kind", "source", "source", "file", "with", "content", "from", "the", "given", "input", "stream", "source"], "project": "spring-framework"}
{"id": 338, "code": "\tpublic final int getExceptionCount() {\n\t\treturn this.propertyAccessExceptions.length;\n\t}", "summary_tokens": ["if", "this", "returns", "0", "no", "errors", "were", "encountered", "during", "binding"], "project": "spring-framework"}
{"id": 2449, "code": "static int getExceptionTableLength(final Handler firstHandler) {\n  int length = 0;\n  Handler handler = firstHandler;\n  while (handler != null) {\n    length++;\n    handler = handler.nextHandler;\n  }\n  return length;\n}", "summary_tokens": ["returns", "the", "number", "of", "elements", "of", "the", "handler", "list", "that", "begins", "with", "the", "given", "element"], "project": "spring-framework"}
{"id": 5251, "code": "\tpublic void setPersistenceUnitPostProcessors(@Nullable PersistenceUnitPostProcessor... postProcessors) {\n\t\tthis.persistenceUnitPostProcessors = postProcessors;\n\t}", "summary_tokens": ["set", "the", "persistence", "unit", "post", "processors", "to", "be", "applied", "to", "each", "persistence", "unit", "info", "that", "has", "been", "parsed", "by", "this", "manager"], "project": "spring-framework"}
{"id": 6702, "code": "\tprotected String getFieldValues(String headerName) {\n\t\tList<String> headerValues = get(headerName);\n\t\treturn (headerValues != null ? toCommaDelimitedString(headerValues) : null);\n\t}", "summary_tokens": ["retrieve", "a", "combined", "result", "from", "the", "field", "values", "of", "multivalued", "headers"], "project": "spring-framework"}
{"id": 9168, "code": "\tpublic final String[] getVaryByRequestHeaders() {\n\t\treturn this.varyByRequestHeaders;\n\t}", "summary_tokens": ["return", "the", "configured", "request", "header", "names", "for", "the", "vary", "response", "header"], "project": "spring-framework"}
{"id": 7525, "code": "\tprotected NavigationHandler getDelegate(FacesContext facesContext) {\n\t\tString targetBeanName = getTargetBeanName(facesContext);\n\t\treturn getBeanFactory(facesContext).getBean(targetBeanName, NavigationHandler.class);\n\t}", "summary_tokens": ["return", "the", "target", "navigation", "handler", "to", "delegate", "to"], "project": "spring-framework"}
{"id": 1532, "code": "\tpublic void setAllowEagerInit(boolean allowEagerInit) {\n\t\tthis.allowEagerInit = allowEagerInit;\n\t}", "summary_tokens": ["specify", "whether", "to", "allow", "eager", "initialization", "of", "candidate", "beans", "when", "autodetecting", "mbeans", "in", "the", "spring", "application", "context"], "project": "spring-framework"}
{"id": 427, "code": "\tdefault Object getObject(int index) {\n\t\treturn toArray()[index];\n\t}", "summary_tokens": ["return", "the", "resolved", "argument", "at", "the", "specified", "index"], "project": "spring-framework"}
{"id": 2599, "code": "public static TypeReference newExceptionReference(final int exceptionIndex) {\n  return new TypeReference((THROWS << 24) | (exceptionIndex << 8));\n}", "summary_tokens": ["returns", "a", "reference", "to", "the", "type", "of", "an", "exception", "in", "a", "throws", "clause", "of", "a", "method"], "project": "spring-framework"}
{"id": 4060, "code": "\tpublic int[] getRowsAffected() {\n\t\tint[] result = new int[this.rowsAffected.size()];\n\t\tfor (int i = 0; i < this.rowsAffected.size(); i++) {\n\t\t\tresult[i] = this.rowsAffected.get(i);\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["return", "the", "number", "of", "affected", "rows", "for", "all", "already", "executed", "statements"], "project": "spring-framework"}
{"id": 3503, "code": "\tpublic void unboxBooleanIfNecessary(MethodVisitor mv) {\n\t\tif (\"Ljava/lang/Boolean\".equals(lastDescriptor())) {\n\t\t\tmv.visitMethodInsn(INVOKEVIRTUAL, \"java/lang/Boolean\", \"booleanValue\", \"()Z\", false);\n\t\t}\n\t}", "summary_tokens": ["if", "the", "codeflow", "shows", "the", "last", "expression", "evaluated", "to", "java"], "project": "spring-framework"}
{"id": 2211, "code": "\tpublic static SourceFiles of(SourceFile... sourceFiles) {\n\t\treturn none().and(sourceFiles);\n\t}", "summary_tokens": ["factory", "method", "that", "can", "be", "used", "to", "create", "a", "source", "files", "instance", "containing", "the", "specified", "files"], "project": "spring-framework"}
{"id": 3182, "code": "\tpublic static <E> E findFirstMatch(Collection<?> source, Collection<E> candidates) {\n\t\tif (isEmpty(source) || isEmpty(candidates)) {\n\t\t\treturn null;\n\t\t}\n\t\tfor (E candidate : candidates) {\n\t\t\tif (source.contains(candidate)) {\n\t\t\t\treturn candidate;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "first", "element", "in", "candidates", "that", "is", "contained", "in", "source"], "project": "spring-framework"}
{"id": 4039, "code": "\tpublic void setBlockCommentStartDelimiter(String blockCommentStartDelimiter) {\n\t\tAssert.hasText(blockCommentStartDelimiter, \"'blockCommentStartDelimiter' must not be null or empty\");\n\t\tthis.blockCommentStartDelimiter = blockCommentStartDelimiter;\n\t}", "summary_tokens": ["set", "the", "start", "delimiter", "that", "identifies", "block", "comments", "within", "the", "sql", "scripts"], "project": "spring-framework"}
{"id": 6922, "code": "\tpublic void setMaxInMemorySize(int byteCount) {\n\t\tthis.maxInMemorySize = byteCount;\n\t\tthis.xmlEventDecoder.setMaxInMemorySize(byteCount);\n\t}", "summary_tokens": ["set", "the", "max", "number", "of", "bytes", "that", "can", "be", "buffered", "by", "this", "decoder"], "project": "spring-framework"}
{"id": 1337, "code": "\tpublic static void setLocale(@Nullable Locale locale, boolean inheritable) {\n\t\tLocaleContext localeContext = getLocaleContext();\n\t\tTimeZone timeZone = (localeContext instanceof TimeZoneAwareLocaleContext ?\n\t\t\t\t((TimeZoneAwareLocaleContext) localeContext).getTimeZone() : null);\n\t\tif (timeZone != null) {\n\t\t\tlocaleContext = new SimpleTimeZoneAwareLocaleContext(locale, timeZone);\n\t\t}\n\t\telse if (locale != null) {\n\t\t\tlocaleContext = new SimpleLocaleContext(locale);\n\t\t}\n\t\telse {\n\t\t\tlocaleContext = null;\n\t\t}\n\t\tsetLocaleContext(localeContext, inheritable);\n\t}", "summary_tokens": ["associate", "the", "given", "locale", "with", "the", "current", "thread", "preserving", "any", "time", "zone", "that", "may", "have", "been", "set", "already"], "project": "spring-framework"}
{"id": 252, "code": "\tprotected Object newPrototypeInstance() throws BeansException {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Creating new instance of bean '\" + getTargetBeanName() + \"'\");\n\t\t}\n\t\treturn getBeanFactory().getBean(getTargetBeanName());\n\t}", "summary_tokens": ["subclasses", "should", "call", "this", "method", "to", "create", "a", "new", "prototype", "instance"], "project": "spring-framework"}
{"id": 888, "code": "\tpublic int getPageCount() {\n\t\tfloat nrOfPages = (float) getNrOfElements() / getPageSize();\n\t\treturn (int) ((nrOfPages > (int) nrOfPages || nrOfPages == 0.0) ? nrOfPages + 1 : nrOfPages);\n\t}", "summary_tokens": ["return", "the", "number", "of", "pages", "for", "the", "current", "source", "list"], "project": "spring-framework"}
{"id": 6427, "code": "\tpublic final void setTransactionSynchronization(int transactionSynchronization) {\n\t\tthis.transactionSynchronization = transactionSynchronization;\n\t}", "summary_tokens": ["set", "when", "this", "transaction", "manager", "should", "activate", "the", "thread", "bound", "transaction", "synchronization", "support"], "project": "spring-framework"}
{"id": 4190, "code": "\tpublic void setCreateTemporaryLob(boolean createTemporaryLob) {\n\t\tthis.createTemporaryLob = createTemporaryLob;\n\t}", "summary_tokens": ["specify", "whether", "to", "copy", "a", "byte", "array", "string", "into", "a", "temporary", "jdbc", "blob", "clob", "object", "created", "through", "the", "jdbc", "0"], "project": "spring-framework"}
{"id": 6357, "code": "\tprivate Mono<Void> triggerBeforeCommit(TransactionSynchronizationManager synchronizationManager,\n\t\t\tGenericReactiveTransaction status) {\n\n\t\tif (status.isNewSynchronization()) {\n\t\t\treturn TransactionSynchronizationUtils.triggerBeforeCommit(\n\t\t\t\t\tsynchronizationManager.getSynchronizations(), status.isReadOnly());\n\t\t}\n\t\treturn Mono.empty();\n\t}", "summary_tokens": ["trigger", "before", "commit", "callbacks"], "project": "spring-framework"}
{"id": 7035, "code": "\tprotected void transform(Source source, Result result) throws TransformerException {\n\t\tthis.transformerFactory.newTransformer().transform(source, result);\n\t}", "summary_tokens": ["transforms", "the", "given", "source", "to", "the", "result"], "project": "spring-framework"}
{"id": 1543, "code": "\tpublic void destroy() {\n\t\tlogger.debug(\"Unregistering JMX-exposed beans on shutdown\");\n\t\tunregisterNotificationListeners();\n\t\tunregisterBeans();\n\t}", "summary_tokens": ["unregisters", "all", "beans", "that", "this", "exported", "has", "exposed", "via", "jmx", "when", "the", "enclosing", "application", "context", "is", "destroyed"], "project": "spring-framework"}
{"id": 5330, "code": "\tpublic R2dbcException getR2dbcException() {\n\t\treturn (R2dbcException) getCause();\n\t}", "summary_tokens": ["return", "the", "wrapped", "r", "0", "dbc", "exception"], "project": "spring-framework"}
{"id": 5518, "code": "\tprivate static UntypedAnnotationDescriptor findAnnotationDescriptorForTypes(@Nullable Class<?> clazz,\n\t\t\tClass<? extends Annotation>[] annotationTypes, Set<Annotation> visited) {\n\n\t\tif (clazz == null || Object.class == clazz) {\n\t\t\treturn null;\n\t\t}\n\n\t\t\n\t\tfor (Class<? extends Annotation> annotationType : annotationTypes) {\n\t\t\tif (AnnotationUtils.isAnnotationDeclaredLocally(annotationType, clazz)) {\n\t\t\t\treturn new UntypedAnnotationDescriptor(clazz, clazz.getAnnotation(annotationType), annotationTypes);\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tfor (Annotation composedAnnotation : clazz.getDeclaredAnnotations()) {\n\t\t\tif (!AnnotationUtils.isInJavaLangAnnotationPackage(composedAnnotation) && visited.add(composedAnnotation)) {\n\t\t\t\tUntypedAnnotationDescriptor descriptor = findAnnotationDescriptorForTypes(\n\t\t\t\t\t\tcomposedAnnotation.annotationType(), annotationTypes, visited);\n\t\t\t\tif (descriptor != null) {\n\t\t\t\t\treturn new UntypedAnnotationDescriptor(clazz, descriptor.getDeclaringClass(),\n\t\t\t\t\t\t\tdescriptor.getAnnotation(), annotationTypes);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tfor (Class<?> ifc : clazz.getInterfaces()) {\n\t\t\tUntypedAnnotationDescriptor descriptor = findAnnotationDescriptorForTypes(ifc, annotationTypes, visited);\n\t\t\tif (descriptor != null) {\n\t\t\t\treturn new UntypedAnnotationDescriptor(clazz, descriptor.getDeclaringClass(),\n\t\t\t\t\t\tdescriptor.getAnnotation(), annotationTypes);\n\t\t\t}\n\t\t}\n\n\t\t\n\t\tUntypedAnnotationDescriptor descriptor =\n\t\t\t\tfindAnnotationDescriptorForTypes(clazz.getSuperclass(), annotationTypes, visited);\n\t\tif (descriptor != null) {\n\t\t\treturn descriptor;\n\t\t}\n\n\t\t\n\t\tif (searchEnclosingClass(clazz)) {\n\t\t\tdescriptor = findAnnotationDescriptorForTypes(clazz.getEnclosingClass(), annotationTypes, visited);\n\t\t\tif (descriptor != null) {\n\t\t\t\treturn descriptor;\n\t\t\t}\n\t\t}\n\n\t\treturn null;\n\t}", "summary_tokens": ["perform", "the", "search", "algorithm", "for", "find", "annotation", "descriptor", "for", "types", "class", "class"], "project": "spring-framework"}
{"id": 5808, "code": "\tpublic static MockRestServiceServer createServer(RestGatewaySupport restGateway) {\n\t\treturn bindTo(restGateway).build();\n\t}", "summary_tokens": ["a", "shortcut", "for", "bind", "to", "rest", "gateway"], "project": "spring-framework"}
{"id": 1874, "code": "\tpublic Duration getIntervalDuration() {\n\t\treturn this.interval;\n\t}", "summary_tokens": ["return", "how", "often", "the", "task", "should", "be", "executed"], "project": "spring-framework"}
{"id": 6939, "code": "\tpublic static GsonBuilder gsonBuilderWithBase64EncodedByteArrays() {\n\t\tGsonBuilder builder = new GsonBuilder();\n\t\tbuilder.registerTypeHierarchyAdapter(byte[].class, new Base64TypeAdapter());\n\t\treturn builder;\n\t}", "summary_tokens": ["obtain", "a", "gson", "builder", "which", "base", "0", "encodes", "byte", "properties", "when", "reading", "and", "writing", "json"], "project": "spring-framework"}
{"id": 3700, "code": "\tprotected Object convertValueToRequiredType(Object value, Class<?> requiredType) {\n\t\tif (String.class == requiredType) {\n\t\t\treturn value.toString();\n\t\t}\n\t\telse if (Number.class.isAssignableFrom(requiredType)) {\n\t\t\tif (value instanceof Number) {\n\t\t\t\t\n\t\t\t\treturn NumberUtils.convertNumberToTargetClass(((Number) value), (Class<Number>) requiredType);\n\t\t\t}\n\t\t\telse {\n\t\t\t\t\n\t\t\t\treturn NumberUtils.parseNumber(value.toString(),(Class<Number>) requiredType);\n\t\t\t}\n\t\t}\n\t\telse if (this.conversionService != null && this.conversionService.canConvert(value.getClass(), requiredType)) {\n\t\t\treturn this.conversionService.convert(value, requiredType);\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Value [\" + value + \"] is of type [\" + value.getClass().getName() +\n\t\t\t\t\t\"] and cannot be converted to required type [\" + requiredType.getName() + \"]\");\n\t\t}\n\t}", "summary_tokens": ["convert", "the", "given", "column", "value", "to", "the", "specified", "required", "type"], "project": "spring-framework"}
{"id": 7453, "code": "\tpublic void setIncludeQueryString(boolean includeQueryString) {\n\t\tthis.includeQueryString = includeQueryString;\n\t}", "summary_tokens": ["set", "whether", "the", "query", "string", "should", "be", "included", "in", "the", "log", "message"], "project": "spring-framework"}
{"id": 4682, "code": "\tprivate NamedValueInfo getNamedValueInfo(MethodParameter parameter) {\n\t\tNamedValueInfo namedValueInfo = this.namedValueInfoCache.get(parameter);\n\t\tif (namedValueInfo == null) {\n\t\t\tnamedValueInfo = createNamedValueInfo(parameter);\n\t\t\tnamedValueInfo = updateNamedValueInfo(parameter, namedValueInfo);\n\t\t\tthis.namedValueInfoCache.put(parameter, namedValueInfo);\n\t\t}\n\t\treturn namedValueInfo;\n\t}", "summary_tokens": ["obtain", "the", "named", "value", "for", "the", "given", "method", "parameter"], "project": "spring-framework"}
{"id": 9262, "code": "\tprotected final Object getBoundValue() throws JspException {\n\t\treturn getBindStatus().getValue();\n\t}", "summary_tokens": ["get", "the", "bound", "value"], "project": "spring-framework"}
{"id": 1680, "code": "\tprivate void replaceNotificationSourceIfNecessary(Notification notification) {\n\t\tif (notification.getSource() == null || notification.getSource().equals(this.managedResource)) {\n\t\t\tnotification.setSource(this.objectName);\n\t\t}\n\t}", "summary_tokens": ["replaces", "the", "notification", "source", "if", "necessary", "to", "do", "so"], "project": "spring-framework"}
{"id": 8882, "code": "\tpublic int compareTo(CompositeRequestCondition other, HttpServletRequest request) {\n\t\tif (isEmpty() && other.isEmpty()) {\n\t\t\treturn 0;\n\t\t}\n\t\telse if (isEmpty()) {\n\t\t\treturn 1;\n\t\t}\n\t\telse if (other.isEmpty()) {\n\t\t\treturn -1;\n\t\t}\n\t\telse {\n\t\t\tassertNumberOfConditions(other);\n\t\t\tfor (int i = 0; i < getLength(); i++) {\n\t\t\t\tint result = this.requestConditions[i].compareTo(other.requestConditions[i], request);\n\t\t\t\tif (result != 0) {\n\t\t\t\t\treturn result;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t}", "summary_tokens": ["if", "one", "instance", "is", "empty", "the", "other", "wins"], "project": "spring-framework"}
{"id": 8427, "code": "\tpublic void setRenderObject(@Nullable String renderObject) {\n\t\tthis.renderObject = renderObject;\n\t}", "summary_tokens": ["set", "the", "object", "where", "the", "render", "function", "belongs", "optional"], "project": "spring-framework"}
{"id": 9890, "code": "\tpublic String getSockJsSessionId() {\n\t\treturn this.sessionId;\n\t}", "summary_tokens": ["return", "the", "sock", "js", "session", "id"], "project": "spring-framework"}
{"id": 2929, "code": "\tpublic void addProtocolResolver(ProtocolResolver resolver) {\n\t\tAssert.notNull(resolver, \"ProtocolResolver must not be null\");\n\t\tthis.protocolResolvers.add(resolver);\n\t}", "summary_tokens": ["register", "the", "given", "resolver", "with", "this", "resource", "loader", "allowing", "for", "additional", "protocols", "to", "be", "handled"], "project": "spring-framework"}
{"id": 1630, "code": "\tprivate String resolveStringDescriptor(@Nullable String getter, @Nullable String setter) {\n\t\treturn (StringUtils.hasLength(getter) ? getter : setter);\n\t}", "summary_tokens": ["locates", "the", "value", "of", "a", "descriptor", "based", "on", "values", "attached", "to", "both", "the", "getter", "and", "setter", "methods"], "project": "spring-framework"}
{"id": 7513, "code": "\tprotected void beforeRequest(HttpServletRequest request, String message) {\n\t\tgetServletContext().log(message);\n\t}", "summary_tokens": ["writes", "a", "log", "message", "before", "the", "request", "is", "processed"], "project": "spring-framework"}
{"id": 3597, "code": "\tpublic List<MethodResolver> getMethodResolvers() {\n\t\treturn this.methodResolvers;\n\t}", "summary_tokens": ["return", "the", "specified", "method", "resolver", "delegates", "if", "any"], "project": "spring-framework"}
{"id": 5540, "code": "\tpublic boolean isSupportedTestClass(Class<?> testClass) {\n\t\treturn this.contextInitializers.containsKey(testClass.getName());\n\t}", "summary_tokens": ["determine", "if", "the", "specified", "test", "class", "has", "an", "aot", "optimized", "application", "context", "initializer"], "project": "spring-framework"}
{"id": 1591, "code": "\tprotected ModelMBeanOperationInfo[] getOperationInfo(Object managedBean, String beanKey) {\n\t\tMethod[] methods = getClassToExpose(managedBean).getMethods();\n\t\tList<ModelMBeanOperationInfo> infos = new ArrayList<>();\n\n\t\tfor (Method method : methods) {\n\t\t\tif (method.isSynthetic()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (Object.class == method.getDeclaringClass()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tModelMBeanOperationInfo info = null;\n\t\t\tPropertyDescriptor pd = BeanUtils.findPropertyForMethod(method);\n\t\t\tif (pd != null && ((method.equals(pd.getReadMethod()) && includeReadAttribute(method, beanKey)) ||\n\t\t\t\t\t\t(method.equals(pd.getWriteMethod()) && includeWriteAttribute(method, beanKey)))) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tinfo = createModelMBeanOperationInfo(method, pd.getName(), beanKey);\n\t\t\t\tDescriptor desc = info.getDescriptor();\n\t\t\t\tif (method.equals(pd.getReadMethod())) {\n\t\t\t\t\tdesc.setField(FIELD_ROLE, ROLE_GETTER);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tdesc.setField(FIELD_ROLE, ROLE_SETTER);\n\t\t\t\t}\n\t\t\t\tdesc.setField(FIELD_VISIBILITY, ATTRIBUTE_OPERATION_VISIBILITY);\n\t\t\t\tif (isExposeClassDescriptor()) {\n\t\t\t\t\tdesc.setField(FIELD_CLASS, getClassForDescriptor(managedBean).getName());\n\t\t\t\t}\n\t\t\t\tinfo.setDescriptor(desc);\n\t\t\t}\n\n\t\t\t\n\t\t\tif (info == null && includeOperation(method, beanKey)) {\n\t\t\t\tinfo = createModelMBeanOperationInfo(method, method.getName(), beanKey);\n\t\t\t\tDescriptor desc = info.getDescriptor();\n\t\t\t\tdesc.setField(FIELD_ROLE, ROLE_OPERATION);\n\t\t\t\tif (isExposeClassDescriptor()) {\n\t\t\t\t\tdesc.setField(FIELD_CLASS, getClassForDescriptor(managedBean).getName());\n\t\t\t\t}\n\t\t\t\tpopulateOperationDescriptor(desc, method, beanKey);\n\t\t\t\tinfo.setDescriptor(desc);\n\t\t\t}\n\n\t\t\tif (info != null) {\n\t\t\t\tinfos.add(info);\n\t\t\t}\n\t\t}\n\n\t\treturn infos.toArray(new ModelMBeanOperationInfo[0]);\n\t}", "summary_tokens": ["iterate", "through", "all", "methods", "on", "the", "mbean", "class", "and", "gives", "subclasses", "the", "chance", "to", "vote", "on", "their", "inclusion"], "project": "spring-framework"}
{"id": 2966, "code": "\tpublic boolean isWritable() {\n\t\treturn (Files.isWritable(this.path) && !Files.isDirectory(this.path));\n\t}", "summary_tokens": ["this", "implementation", "checks", "whether", "the", "underlying", "file", "is", "marked", "as", "writable", "and", "corresponds", "to", "an", "actual", "file", "with", "content", "not", "to", "a", "directory"], "project": "spring-framework"}
{"id": 1412, "code": "\tpublic void refreshForAotProcessing(RuntimeHints runtimeHints) {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Preparing bean factory for AOT processing\");\n\t\t}\n\t\tprepareRefresh();\n\t\tobtainFreshBeanFactory();\n\t\tprepareBeanFactory(this.beanFactory);\n\t\tpostProcessBeanFactory(this.beanFactory);\n\t\tinvokeBeanFactoryPostProcessors(this.beanFactory);\n\t\tthis.beanFactory.freezeConfiguration();\n\t\tPostProcessorRegistrationDelegate.invokeMergedBeanDefinitionPostProcessors(this.beanFactory);\n\t\tpreDetermineBeanTypes(runtimeHints);\n\t}", "summary_tokens": ["load", "or", "refresh", "the", "persistent", "representation", "of", "the", "configuration", "up", "to", "a", "point", "where", "the", "underlying", "bean", "factory", "is", "ready", "to", "create", "bean", "instances"], "project": "spring-framework"}
{"id": 5564, "code": "\tString getSeparator() {\n\t\treturn this.separator;\n\t}", "summary_tokens": ["get", "the", "character", "string", "used", "to", "separate", "individual", "statements", "within", "the", "sql", "scripts"], "project": "spring-framework"}
{"id": 5698, "code": "\tpublic String toString() {\n\t\treturn new ToStringCreator(this)\n\t\t\t\t.append(\"locations\", Arrays.toString(this.locations))\n\t\t\t\t.append(\"properties\", Arrays.toString(this.properties))\n\t\t\t\t.toString();\n\t}", "summary_tokens": ["provide", "a", "string", "representation", "of", "this", "merged", "test", "property", "sources", "instance"], "project": "spring-framework"}
{"id": 7467, "code": "\tpublic void setAfterMessagePrefix(String afterMessagePrefix) {\n\t\tthis.afterMessagePrefix = afterMessagePrefix;\n\t}", "summary_tokens": ["set", "the", "value", "that", "should", "be", "prepended", "to", "the", "log", "message", "written", "i", "after", "i", "a", "request", "is", "processed"], "project": "spring-framework"}
{"id": 4264, "code": "\tpublic static Session doGetTransactionalSession(\n\t\t\tConnectionFactory connectionFactory, ResourceFactory resourceFactory, boolean startConnection)\n\t\t\tthrows JMSException {\n\n\t\tAssert.notNull(connectionFactory, \"ConnectionFactory must not be null\");\n\t\tAssert.notNull(resourceFactory, \"ResourceFactory must not be null\");\n\n\t\tJmsResourceHolder resourceHolder =\n\t\t\t\t(JmsResourceHolder) TransactionSynchronizationManager.getResource(connectionFactory);\n\t\tif (resourceHolder != null) {\n\t\t\tSession session = resourceFactory.getSession(resourceHolder);\n\t\t\tif (session != null) {\n\t\t\t\tif (startConnection) {\n\t\t\t\t\tConnection con = resourceFactory.getConnection(resourceHolder);\n\t\t\t\t\tif (con != null) {\n\t\t\t\t\t\tcon.start();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn session;\n\t\t\t}\n\t\t\tif (resourceHolder.isFrozen()) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t\tif (!TransactionSynchronizationManager.isSynchronizationActive()) {\n\t\t\treturn null;\n\t\t}\n\t\tJmsResourceHolder resourceHolderToUse = resourceHolder;\n\t\tif (resourceHolderToUse == null) {\n\t\t\tresourceHolderToUse = new JmsResourceHolder(connectionFactory);\n\t\t}\n\t\tConnection con = resourceFactory.getConnection(resourceHolderToUse);\n\t\tSession session = null;\n\t\ttry {\n\t\t\tboolean isExistingCon = (con != null);\n\t\t\tif (!isExistingCon) {\n\t\t\t\tcon = resourceFactory.createConnection();\n\t\t\t\tresourceHolderToUse.addConnection(con);\n\t\t\t}\n\t\t\tsession = resourceFactory.createSession(con);\n\t\t\tresourceHolderToUse.addSession(session, con);\n\t\t\tif (startConnection) {\n\t\t\t\tcon.start();\n\t\t\t}\n\t\t}\n\t\tcatch (JMSException ex) {\n\t\t\tif (session != null) {\n\t\t\t\ttry {\n\t\t\t\t\tsession.close();\n\t\t\t\t}\n\t\t\t\tcatch (Throwable ex2) {\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (con != null) {\n\t\t\t\ttry {\n\t\t\t\t\tcon.close();\n\t\t\t\t}\n\t\t\t\tcatch (Throwable ex2) {\n\t\t\t\t\t\n\t\t\t\t}\n\t\t\t}\n\t\t\tthrow ex;\n\t\t}\n\t\tif (resourceHolderToUse != resourceHolder) {\n\t\t\tTransactionSynchronizationManager.registerSynchronization(\n\t\t\t\t\tnew JmsResourceSynchronization(resourceHolderToUse, connectionFactory,\n\t\t\t\t\t\t\tresourceFactory.isSynchedLocalTransactionAllowed()));\n\t\t\tresourceHolderToUse.setSynchronizedWithTransaction(true);\n\t\t\tTransactionSynchronizationManager.bindResource(connectionFactory, resourceHolderToUse);\n\t\t}\n\t\treturn session;\n\t}", "summary_tokens": ["obtain", "a", "jms", "session", "that", "is", "synchronized", "with", "the", "current", "transaction", "if", "any"], "project": "spring-framework"}
{"id": 8795, "code": "\tpublic void setMappedHandlerClasses(Class<?>... mappedHandlerClasses) {\n\t\tthis.mappedHandlerClasses = mappedHandlerClasses;\n\t}", "summary_tokens": ["specify", "the", "set", "of", "classes", "that", "this", "exception", "resolver", "should", "apply", "to"], "project": "spring-framework"}
{"id": 1894, "code": "\tpublic static DelegatingErrorHandlingRunnable decorateTaskWithErrorHandler(\n\t\t\tRunnable task, @Nullable ErrorHandler errorHandler, boolean isRepeatingTask) {\n\n\t\tif (task instanceof DelegatingErrorHandlingRunnable) {\n\t\t\treturn (DelegatingErrorHandlingRunnable) task;\n\t\t}\n\t\tErrorHandler eh = (errorHandler != null ? errorHandler : getDefaultErrorHandler(isRepeatingTask));\n\t\treturn new DelegatingErrorHandlingRunnable(task, eh);\n\t}", "summary_tokens": ["decorate", "the", "task", "for", "error", "handling"], "project": "spring-framework"}
{"id": 5054, "code": "\tprotected <V> V getHeaderIfAvailable(Map<String, Object> headers, String name, Class<V> type) {\n\t\tObject value = headers.get(name);\n\t\tif (value == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (!type.isAssignableFrom(value.getClass())) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Skipping header '\" + name + \"': expected type [\" + type + \"], but got [\" +\n\t\t\t\t\t\tvalue.getClass() + \"]\");\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t\telse {\n\t\t\treturn type.cast(value);\n\t\t}\n\t}", "summary_tokens": ["return", "the", "header", "value", "or", "null", "if", "it", "does", "not", "exist", "or", "does", "not", "match", "the", "requested", "type"], "project": "spring-framework"}
{"id": 5623, "code": "\tprotected Statement withAfters(FrameworkMethod frameworkMethod, Object testInstance, Statement statement) {\n\t\tStatement junitAfters = super.withAfters(frameworkMethod, testInstance, statement);\n\t\treturn new RunAfterTestMethodCallbacks(junitAfters, testInstance, frameworkMethod.getMethod(), getTestContextManager());\n\t}", "summary_tokens": ["wrap", "the", "statement", "returned", "by", "the", "parent", "implementation", "with", "a", "run", "after", "test", "method", "callbacks", "statement", "thus", "preserving", "the", "default", "functionality", "while", "adding", "support", "for", "the", "spring", "test", "context", "framework"], "project": "spring-framework"}
{"id": 8496, "code": "\tprivate void initThemeResolver(ApplicationContext context) {\n\t\ttry {\n\t\t\tthis.themeResolver = context.getBean(THEME_RESOLVER_BEAN_NAME, ThemeResolver.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"Detected \" + this.themeResolver);\n\t\t\t}\n\t\t\telse if (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"Detected \" + this.themeResolver.getClass().getSimpleName());\n\t\t\t}\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\n\t\t\tthis.themeResolver = getDefaultStrategy(context, ThemeResolver.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"No ThemeResolver '\" + THEME_RESOLVER_BEAN_NAME +\n\t\t\t\t\t\t\"': using default [\" + this.themeResolver.getClass().getSimpleName() + \"]\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "theme", "resolver", "used", "by", "this", "class"], "project": "spring-framework"}
{"id": 9876, "code": "\tprotected String selectProtocol(List<String> requestedProtocols, WebSocketHandler webSocketHandler) {\n\t\tList<String> handlerProtocols = determineHandlerSupportedProtocols(webSocketHandler);\n\t\tfor (String protocol : requestedProtocols) {\n\t\t\tif (handlerProtocols.contains(protocol.toLowerCase())) {\n\t\t\t\treturn protocol;\n\t\t\t}\n\t\t\tif (this.supportedProtocols.contains(protocol.toLowerCase())) {\n\t\t\t\treturn protocol;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["perform", "the", "sub", "protocol", "negotiation", "based", "on", "requested", "and", "supported", "sub", "protocols"], "project": "spring-framework"}
{"id": 8429, "code": "\tpublic void setCharset(@Nullable Charset charset) {\n\t\tthis.charset = charset;\n\t}", "summary_tokens": ["set", "the", "charset", "used", "to", "read", "script", "and", "template", "files"], "project": "spring-framework"}
{"id": 2553, "code": "Symbol addConstantMethodType(final String methodDescriptor) {\n  return addConstantUtf8Reference(Symbol.CONSTANT_METHOD_TYPE_TAG, methodDescriptor);\n}", "summary_tokens": ["adds", "a", "constant", "method", "type", "info", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 7573, "code": "\tpublic void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType,\n\t\t\tModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws Exception {\n\n\t\tif (returnValue != null) {\n\t\t\tString name = ModelFactory.getNameForReturnValue(returnValue, returnType);\n\t\t\tmavContainer.addAttribute(name, returnValue);\n\t\t}\n\t}", "summary_tokens": ["add", "non", "null", "return", "values", "to", "the", "model", "and", "view", "container"], "project": "spring-framework"}
{"id": 2541, "code": "Symbol addConstantMethodref(\n    final String owner, final String name, final String descriptor, final boolean isInterface) {\n  int tag = isInterface ? Symbol.CONSTANT_INTERFACE_METHODREF_TAG : Symbol.CONSTANT_METHODREF_TAG;\n  return addConstantMemberReference(tag, owner, name, descriptor);\n}", "summary_tokens": ["adds", "a", "constant", "methodref", "info", "or", "constant", "interface", "methodref", "info", "to", "the", "constant", "pool", "of", "this", "symbol", "table"], "project": "spring-framework"}
{"id": 4670, "code": "\tpublic DestinationPatternsMessageCondition getMatchingCondition(Message<?> message) {\n\t\tObject destination = message.getHeaders().get(LOOKUP_DESTINATION_HEADER);\n\t\tif (destination == null) {\n\t\t\treturn null;\n\t\t}\n\t\tif (this.patterns.isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\n\t\tList<String> matches = null;\n\t\tfor (String pattern : this.patterns) {\n\t\t\tif (pattern.equals(destination) || matchPattern(pattern, destination)) {\n\t\t\t\tif (matches == null) {\n\t\t\t\t\tmatches = new ArrayList<>();\n\t\t\t\t}\n\t\t\t\tmatches.add(pattern);\n\t\t\t}\n\t\t}\n\t\tif (CollectionUtils.isEmpty(matches)) {\n\t\t\treturn null;\n\t\t}\n\n\t\tmatches.sort(getPatternComparator(destination));\n\t\treturn new DestinationPatternsMessageCondition(new LinkedHashSet<>(matches), this.routeMatcher);\n\t}", "summary_tokens": ["check", "if", "any", "of", "the", "patterns", "match", "the", "given", "message", "destination", "and", "return", "an", "instance", "that", "is", "guaranteed", "to", "contain", "matching", "patterns", "sorted", "via", "org"], "project": "spring-framework"}
{"id": 7313, "code": "\tpublic DeferredResultProcessingInterceptor getDeferredResultInterceptor(Object key) {\n\t\treturn this.deferredResultInterceptors.get(key);\n\t}", "summary_tokens": ["get", "the", "deferred", "result", "processing", "interceptor", "registered", "under", "the", "given", "key"], "project": "spring-framework"}
{"id": 8937, "code": "\tprotected Comparator<RequestMappingInfo> getMappingComparator(final HttpServletRequest request) {\n\t\treturn (info1, info2) -> info1.compareTo(info2, request);\n\t}", "summary_tokens": ["provide", "a", "comparator", "to", "sort", "request", "mapping", "infos", "matched", "to", "a", "request"], "project": "spring-framework"}
{"id": 3464, "code": "\tprotected <T> void testEncodeAll(Publisher<? extends T> input, ResolvableType inputType,\n\t\t\t@Nullable MimeType mimeType, @Nullable Map<String, Object> hints,\n\t\t\tConsumer<StepVerifier.FirstStep<DataBuffer>> stepConsumer) {\n\n\t\ttestEncode(input, inputType, mimeType, hints, stepConsumer);\n\t\ttestEncodeError(input, inputType, mimeType, hints);\n\t\ttestEncodeCancel(input, inputType, mimeType, hints);\n\t\ttestEncodeEmpty(inputType, mimeType, hints);\n\t}", "summary_tokens": ["helper", "method", "that", "tests", "for", "a", "variety", "of", "decoding", "scenarios"], "project": "spring-framework"}
{"id": 2878, "code": "\tpublic void addLast(PropertySource<?> propertySource) {\n\t\tsynchronized (this.propertySourceList) {\n\t\t\tremoveIfPresent(propertySource);\n\t\t\tthis.propertySourceList.add(propertySource);\n\t\t}\n\t}", "summary_tokens": ["add", "the", "given", "property", "source", "object", "with", "the", "lowest", "precedence"], "project": "spring-framework"}
{"id": 2134, "code": "\tpublic void testReadOnlyAttribute() throws Exception {\n\t\tModelMBeanInfo inf = getMBeanInfoFromAssembler();\n\t\tModelMBeanAttributeInfo attr = inf.getAttribute(AGE_ATTRIBUTE);\n\t\tassertThat(attr.isWritable()).as(\"The age attribute should not be writable\").isFalse();\n\t}", "summary_tokens": ["tests", "the", "situation", "where", "the", "attribute", "is", "only", "defined", "on", "the", "getter"], "project": "spring-framework"}
{"id": 1801, "code": "\tpublic void setResourceRef(boolean resourceRef) {\n\t\tthis.jndiLocator.setResourceRef(resourceRef);\n\t}", "summary_tokens": ["set", "whether", "the", "lookup", "occurs", "in", "a", "jakarta", "ee", "container", "i"], "project": "spring-framework"}
{"id": 2764, "code": "\tpublic static String getVersion() {\n\t\tPackage pkg = SpringVersion.class.getPackage();\n\t\treturn (pkg != null ? pkg.getImplementationVersion() : null);\n\t}", "summary_tokens": ["return", "the", "full", "version", "string", "of", "the", "present", "spring", "codebase", "or", "null", "if", "it", "cannot", "be", "determined"], "project": "spring-framework"}
{"id": 7192, "code": "\tprotected void checkFieldDefaults(MutablePropertyValues mpvs) {\n\t\tString fieldDefaultPrefix = getFieldDefaultPrefix();\n\t\tif (fieldDefaultPrefix != null) {\n\t\t\tPropertyValue[] pvArray = mpvs.getPropertyValues();\n\t\t\tfor (PropertyValue pv : pvArray) {\n\t\t\t\tif (pv.getName().startsWith(fieldDefaultPrefix)) {\n\t\t\t\t\tString field = pv.getName().substring(fieldDefaultPrefix.length());\n\t\t\t\t\tif (getPropertyAccessor().isWritableProperty(field) && !mpvs.contains(field)) {\n\t\t\t\t\t\tmpvs.add(field, pv.getValue());\n\t\t\t\t\t}\n\t\t\t\t\tmpvs.removePropertyValue(pv);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["check", "the", "given", "property", "values", "for", "field", "defaults", "i"], "project": "spring-framework"}
{"id": 3429, "code": "\tprivate boolean hasDoctype(String content) {\n\t\treturn content.contains(DOCTYPE);\n\t}", "summary_tokens": ["does", "the", "content", "contain", "the", "dtd", "doctype", "declaration"], "project": "spring-framework"}
{"id": 1706, "code": "\tprotected void onRegister(ObjectName objectName) {\n\t}", "summary_tokens": ["called", "when", "an", "mbean", "is", "registered", "under", "the", "given", "object", "name"], "project": "spring-framework"}
{"id": 3631, "code": "\tvoid indexingAsAPropertyAccess_SPR6968_4() {\n\t\tGoo g = Goo.instance;\n\t\tStandardEvaluationContext context = new StandardEvaluationContext(g);\n\t\tcontext.setVariable(\"bar\", \"wibble\");\n\t\tExpression expr = null;\n\t\texpr = new SpelExpressionParser().parseRaw(\"instance[#bar]='world'\");\n\t\t\n\t\texpr.getValue(context, String.class);\n\t\tassertThat(g.wibble).isEqualTo(\"world\");\n\t\texpr.getValue(context, String.class); \n\t\tassertThat(g.wibble).isEqualTo(\"world\");\n\t}", "summary_tokens": ["should", "be", "accessing", "setting", "goo"], "project": "spring-framework"}
{"id": 602, "code": "\tpublic void fireDefaultsRegistered(DefaultsDefinition defaultsDefinition) {\n\t\tthis.eventListener.defaultsRegistered(defaultsDefinition);\n\t}", "summary_tokens": ["fire", "a", "defaults", "registered", "event"], "project": "spring-framework"}
{"id": 4237, "code": "\tpublic void setContainerFactoryBeanName(String containerFactoryBeanName) {\n\t\tthis.containerFactoryBeanName = containerFactoryBeanName;\n\t}", "summary_tokens": ["set", "the", "bean", "name", "of", "the", "jms", "listener", "container", "factory", "to", "use", "in", "case", "a", "jms", "listener", "endpoint", "is", "registered", "with", "a", "null", "container", "factory"], "project": "spring-framework"}
{"id": 1602, "code": "\tpublic void setManagedInterfaces(@Nullable Class<?>... managedInterfaces) {\n\t\tif (managedInterfaces != null) {\n\t\t\tfor (Class<?> ifc : managedInterfaces) {\n\t\t\t\tif (!ifc.isInterface()) {\n\t\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\t\"Management interface [\" + ifc.getName() + \"] is not an interface\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tthis.managedInterfaces = managedInterfaces;\n\t}", "summary_tokens": ["set", "the", "array", "of", "interfaces", "to", "use", "for", "creating", "the", "management", "info"], "project": "spring-framework"}
{"id": 6568, "code": "\tpublic static void invokeAfterCommit(@Nullable List<TransactionSynchronization> synchronizations) {\n\t\tif (synchronizations != null) {\n\t\t\tfor (TransactionSynchronization synchronization : synchronizations) {\n\t\t\t\tsynchronization.afterCommit();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["actually", "invoke", "the", "after", "commit", "methods", "of", "the", "given", "spring", "transaction", "synchronization", "objects"], "project": "spring-framework"}
{"id": 5129, "code": "\tpublic boolean isCacheQueries() {\n\t\treturn this.cacheQueries;\n\t}", "summary_tokens": ["return", "whether", "to", "cache", "all", "queries", "executed", "by", "this", "template"], "project": "spring-framework"}
{"id": 1802, "code": "\tpublic void setJndiName(String jndiName) {\n\t\tthis.jndiName = jndiName;\n\t}", "summary_tokens": ["specify", "a", "jndi", "name", "of", "the", "java"], "project": "spring-framework"}
{"id": 1321, "code": "\tdefault boolean supportsSourceType(@Nullable Class<?> sourceType) {\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "whether", "this", "listener", "actually", "supports", "the", "given", "source", "type"], "project": "spring-framework"}
{"id": 8067, "code": "\tpublic static <T, S extends Publisher<ServerSentEvent<T>>> BodyInserter<S, ServerHttpResponse> fromServerSentEvents(\n\t\t\tS eventsPublisher) {\n\n\t\tAssert.notNull(eventsPublisher, \"'eventsPublisher' must not be null\");\n\t\treturn (serverResponse, context) -> {\n\t\t\tResolvableType elementType = SSE_TYPE;\n\t\t\tMediaType mediaType = MediaType.TEXT_EVENT_STREAM;\n\t\t\tHttpMessageWriter<ServerSentEvent<T>> writer = findWriter(context, elementType, mediaType);\n\t\t\treturn write(eventsPublisher, elementType, mediaType, serverResponse, context, writer);\n\t\t};\n\t}", "summary_tokens": ["inserter", "to", "write", "the", "given", "server", "sent", "event", "publisher"], "project": "spring-framework"}
{"id": 5427, "code": "\tpublic void forEach(Consumer<? super Binding> action) {\n\t\tthis.bindings.forEach((marker, binding) -> action.accept(binding));\n\t}", "summary_tokens": ["perform", "the", "given", "action", "for", "each", "binding", "of", "this", "bindings", "until", "all", "bindings", "have", "been", "processed", "or", "the", "action", "throws", "an", "exception"], "project": "spring-framework"}
{"id": 2505, "code": "private void putAbstractTypes(final int start, final int end) {\n  for (int i = start; i < end; ++i) {\n    Frame.putAbstractType(symbolTable, currentFrame[i], stackMapTableEntries);\n  }\n}", "summary_tokens": ["puts", "some", "abstract", "types", "of", "current", "frame", "in", "stack", "map", "table", "entries", "using", "the", "jvms", "verification", "type", "info", "format", "used", "in", "stack", "map", "table", "attributes"], "project": "spring-framework"}
{"id": 847, "code": "\tprotected BeanDefinitionDocumentReader createBeanDefinitionDocumentReader() {\n\t\treturn BeanUtils.instantiateClass(this.documentReaderClass);\n\t}", "summary_tokens": ["create", "the", "bean", "definition", "document", "reader", "to", "use", "for", "actually", "reading", "bean", "definitions", "from", "an", "xml", "document"], "project": "spring-framework"}
{"id": 130, "code": "\tprotected Object getCacheKey(Class<?> beanClass, @Nullable String beanName) {\n\t\tif (StringUtils.hasLength(beanName)) {\n\t\t\treturn (FactoryBean.class.isAssignableFrom(beanClass) ?\n\t\t\t\t\tBeanFactory.FACTORY_BEAN_PREFIX + beanName : beanName);\n\t\t}\n\t\telse {\n\t\t\treturn beanClass;\n\t\t}\n\t}", "summary_tokens": ["build", "a", "cache", "key", "for", "the", "given", "bean", "class", "and", "bean", "name"], "project": "spring-framework"}
{"id": 2165, "code": "\tpublic MethodReference getMethodReference() {\n\t\treturn this.instrumentedMethod.methodReference();\n\t}", "summary_tokens": ["return", "a", "simple", "representation", "of", "the", "method", "invoked", "here"], "project": "spring-framework"}
{"id": 7734, "code": "\tpublic WebSessionIdResolver getSessionIdResolver() {\n\t\treturn this.sessionIdResolver;\n\t}", "summary_tokens": ["return", "the", "configured", "web", "session", "id", "resolver"], "project": "spring-framework"}
{"id": 2736, "code": "\tpublic static ReactiveAdapterRegistry getSharedInstance() {\n\t\tReactiveAdapterRegistry registry = sharedInstance;\n\t\tif (registry == null) {\n\t\t\tsynchronized (ReactiveAdapterRegistry.class) {\n\t\t\t\tregistry = sharedInstance;\n\t\t\t\tif (registry == null) {\n\t\t\t\t\tregistry = new ReactiveAdapterRegistry();\n\t\t\t\t\tsharedInstance = registry;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn registry;\n\t}", "summary_tokens": ["return", "a", "shared", "default", "reactive", "adapter", "registry", "instance", "lazily", "building", "it", "once", "needed"], "project": "spring-framework"}
{"id": 8284, "code": "\tprivate Object resolveEmbeddedValuesAndExpressions(String value) {\n\t\tif (this.configurableBeanFactory == null || this.expressionContext == null) {\n\t\t\treturn value;\n\t\t}\n\t\tString placeholdersResolved = this.configurableBeanFactory.resolveEmbeddedValue(value);\n\t\tBeanExpressionResolver exprResolver = this.configurableBeanFactory.getBeanExpressionResolver();\n\t\tif (exprResolver == null) {\n\t\t\treturn value;\n\t\t}\n\t\treturn exprResolver.evaluate(placeholdersResolved, this.expressionContext);\n\t}", "summary_tokens": ["resolve", "the", "given", "annotation", "specified", "value", "potentially", "containing", "placeholders", "and", "expressions"], "project": "spring-framework"}
{"id": 376, "code": "\tpublic Throwable[] getRelatedCauses() {\n\t\tif (this.relatedCauses == null) {\n\t\t\treturn null;\n\t\t}\n\t\treturn this.relatedCauses.toArray(new Throwable[0]);\n\t}", "summary_tokens": ["return", "the", "related", "causes", "if", "any"], "project": "spring-framework"}
{"id": 2250, "code": "\tpublic static Consumer<Builder> builtWith(ExecutableMode mode) {\n\t\treturn builder -> builder.withMode(mode);\n\t}", "summary_tokens": ["return", "a", "consumer", "that", "applies", "the", "given", "executable", "mode", "to", "the", "accepted", "builder"], "project": "spring-framework"}
{"id": 4965, "code": "\tpublic void setTaskScheduler(@Nullable TaskScheduler taskScheduler) {\n\t\tthis.taskScheduler = taskScheduler;\n\t}", "summary_tokens": ["configure", "the", "task", "scheduler", "to", "use", "to", "reset", "client", "to", "broker", "message", "count", "in", "the", "current", "heartbeat", "period"], "project": "spring-framework"}
{"id": 3006, "code": "\tpublic void setIgnoreResourceNotFound(boolean ignoreResourceNotFound) {\n\t\tthis.ignoreResourceNotFound = ignoreResourceNotFound;\n\t}", "summary_tokens": ["set", "if", "failure", "to", "find", "the", "property", "resource", "should", "be", "ignored"], "project": "spring-framework"}
{"id": 623, "code": "\tdefault AutowireCandidateResolver cloneIfNecessary() {\n\t\treturn BeanUtils.instantiateClass(getClass());\n\t}", "summary_tokens": ["return", "a", "clone", "of", "this", "resolver", "instance", "if", "necessary", "retaining", "its", "local", "configuration", "and", "allowing", "for", "the", "cloned", "instance", "to", "get", "associated", "with", "a", "new", "bean", "factory", "or", "this", "original", "instance", "if", "there", "is", "no", "such", "state"], "project": "spring-framework"}
{"id": 98, "code": "\tpublic void removeListener(AdvisedSupportListener listener) {\n\t\tAssert.notNull(listener, \"AdvisedSupportListener must not be null\");\n\t\tthis.listeners.remove(listener);\n\t}", "summary_tokens": ["remove", "the", "given", "advised", "support", "listener", "from", "this", "proxy", "configuration"], "project": "spring-framework"}
{"id": 7749, "code": "\tpublic HttpHeaders getHeaders() {\n\t\treturn this.headers;\n\t}", "summary_tokens": ["return", "the", "headers", "for", "the", "request", "if", "any"], "project": "spring-framework"}
{"id": 9871, "code": "\tprotected void registerEndpoints() {\n\t\tSet<Class<?>> endpointClasses = new LinkedHashSet<>();\n\t\tif (this.annotatedEndpointClasses != null) {\n\t\t\tendpointClasses.addAll(this.annotatedEndpointClasses);\n\t\t}\n\n\t\tApplicationContext context = getApplicationContext();\n\t\tif (context != null) {\n\t\t\tString[] endpointBeanNames = context.getBeanNamesForAnnotation(ServerEndpoint.class);\n\t\t\tfor (String beanName : endpointBeanNames) {\n\t\t\t\tendpointClasses.add(context.getType(beanName));\n\t\t\t}\n\t\t}\n\n\t\tfor (Class<?> endpointClass : endpointClasses) {\n\t\t\tregisterEndpoint(endpointClass);\n\t\t}\n\n\t\tif (context != null) {\n\t\t\tMap<String, ServerEndpointConfig> endpointConfigMap = context.getBeansOfType(ServerEndpointConfig.class);\n\t\t\tfor (ServerEndpointConfig endpointConfig : endpointConfigMap.values()) {\n\t\t\t\tregisterEndpoint(endpointConfig);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["actually", "register", "the", "endpoints"], "project": "spring-framework"}
{"id": 9585, "code": "\tprotected StringBuilder replaceUriTemplateVariables(\n\t\t\tString targetUrl, Map<String, Object> model, Map<String, String> currentUriVariables, String encodingScheme)\n\t\t\tthrows UnsupportedEncodingException {\n\n\t\tStringBuilder result = new StringBuilder();\n\t\tMatcher matcher = URI_TEMPLATE_VARIABLE_PATTERN.matcher(targetUrl);\n\t\tint endLastMatch = 0;\n\t\twhile (matcher.find()) {\n\t\t\tString name = matcher.group(1);\n\t\t\tObject value = (model.containsKey(name) ? model.remove(name) : currentUriVariables.get(name));\n\t\t\tif (value == null) {\n\t\t\t\tthrow new IllegalArgumentException(\"Model has no value for key '\" + name + \"'\");\n\t\t\t}\n\t\t\tresult.append(targetUrl, endLastMatch, matcher.start());\n\t\t\tresult.append(UriUtils.encodePathSegment(value.toString(), encodingScheme));\n\t\t\tendLastMatch = matcher.end();\n\t\t}\n\t\tresult.append(targetUrl.substring(endLastMatch));\n\t\treturn result;\n\t}", "summary_tokens": ["replace", "uri", "template", "variables", "in", "the", "target", "url", "with", "encoded", "model", "attributes", "or", "uri", "variables", "from", "the", "current", "request"], "project": "spring-framework"}
{"id": 5756, "code": "\tpublic static void fail(String message, @Nullable Object expected, @Nullable Object actual) {\n\t\tthrow new AssertionError(message + \" expected:<\" + expected + \"> but was:<\" + actual + \">\");\n\t}", "summary_tokens": ["fail", "a", "test", "with", "the", "given", "message", "passing", "along", "expected", "and", "actual", "values", "to", "be", "appended", "to", "the", "message"], "project": "spring-framework"}
{"id": 3168, "code": "\tpublic static Method getMostSpecificMethod(Method method, @Nullable Class<?> targetClass) {\n\t\tif (targetClass != null && targetClass != method.getDeclaringClass() && isOverridable(method, targetClass)) {\n\t\t\ttry {\n\t\t\t\tif (Modifier.isPublic(method.getModifiers())) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\treturn targetClass.getMethod(method.getName(), method.getParameterTypes());\n\t\t\t\t\t}\n\t\t\t\t\tcatch (NoSuchMethodException ex) {\n\t\t\t\t\t\treturn method;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tMethod specificMethod =\n\t\t\t\t\t\t\tReflectionUtils.findMethod(targetClass, method.getName(), method.getParameterTypes());\n\t\t\t\t\treturn (specificMethod != null ? specificMethod : method);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (SecurityException ex) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\t\treturn method;\n\t}", "summary_tokens": ["given", "a", "method", "which", "may", "come", "from", "an", "interface", "and", "a", "target", "class", "used", "in", "the", "current", "reflective", "invocation", "find", "the", "corresponding", "target", "method", "if", "there", "is", "one"], "project": "spring-framework"}
{"id": 938, "code": "\tpublic void setSingleton(boolean singleton) {\n\t\tthis.singleton = singleton;\n\t}", "summary_tokens": ["set", "if", "the", "bean", "managed", "by", "this", "factory", "is", "a", "singleton"], "project": "spring-framework"}
{"id": 2844, "code": "\tpublic static void addDefaultConverters(ConverterRegistry converterRegistry) {\n\t\taddScalarConverters(converterRegistry);\n\t\taddCollectionConverters(converterRegistry);\n\n\t\tconverterRegistry.addConverter(new ByteBufferConverter((ConversionService) converterRegistry));\n\t\tconverterRegistry.addConverter(new StringToTimeZoneConverter());\n\t\tconverterRegistry.addConverter(new ZoneIdToTimeZoneConverter());\n\t\tconverterRegistry.addConverter(new ZonedDateTimeToCalendarConverter());\n\n\t\tconverterRegistry.addConverter(new ObjectToObjectConverter());\n\t\tconverterRegistry.addConverter(new IdToEntityConverter((ConversionService) converterRegistry));\n\t\tconverterRegistry.addConverter(new FallbackObjectToStringConverter());\n\t\tconverterRegistry.addConverter(new ObjectToOptionalConverter((ConversionService) converterRegistry));\n\t}", "summary_tokens": ["add", "converters", "appropriate", "for", "most", "environments"], "project": "spring-framework"}
{"id": 1408, "code": "\tprotected final void refreshBeanFactory() throws IllegalStateException {\n\t\tif (!this.refreshed.compareAndSet(false, true)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"GenericApplicationContext does not support multiple refresh attempts: just call 'refresh' once\");\n\t\t}\n\t\tthis.beanFactory.setSerializationId(getId());\n\t}", "summary_tokens": ["do", "nothing", "we", "hold", "a", "single", "internal", "bean", "factory", "and", "rely", "on", "callers", "to", "register", "beans", "through", "our", "public", "methods", "or", "the", "bean", "factory", "s"], "project": "spring-framework"}
{"id": 5974, "code": "\tpublic ResultMatcher maxAge(String name, int maxAge) {\n\t\treturn result -> {\n\t\t\tCookie cookie = getCookie(result, name);\n\t\t\tassertEquals(\"Response cookie '\" + name + \"' maxAge\", maxAge, cookie.getMaxAge());\n\t\t};\n\t}", "summary_tokens": ["assert", "a", "cookie", "s", "max", "age"], "project": "spring-framework"}
{"id": 626, "code": "\tpublic static BeanDefinitionBuilder childBeanDefinition(String parentName) {\n\t\treturn new BeanDefinitionBuilder(new ChildBeanDefinition(parentName));\n\t}", "summary_tokens": ["create", "a", "new", "bean", "definition", "builder", "used", "to", "construct", "a", "child", "bean", "definition"], "project": "spring-framework"}
{"id": 7729, "code": "\tpublic String getCookieName() {\n\t\treturn this.cookieName;\n\t}", "summary_tokens": ["get", "the", "configured", "cookie", "name"], "project": "spring-framework"}
{"id": 1555, "code": "\tprivate ModelMBeanInfo getMBeanInfo(Object managedBean, String beanKey) throws JMException {\n\t\tModelMBeanInfo info = this.assembler.getMBeanInfo(managedBean, beanKey);\n\t\tif (logger.isInfoEnabled() && ObjectUtils.isEmpty(info.getAttributes()) &&\n\t\t\t\tObjectUtils.isEmpty(info.getOperations())) {\n\t\t\tlogger.info(\"Bean with key '\" + beanKey +\n\t\t\t\t\t\"' has been registered as an MBean but has no exposed attributes or operations\");\n\t\t}\n\t\treturn info;\n\t}", "summary_tokens": ["gets", "the", "model", "mbean", "info", "for", "the", "bean", "with", "the", "supplied", "key", "and", "of", "the", "supplied", "type"], "project": "spring-framework"}
{"id": 9532, "code": "\tpublic Map<String, Object> getAttributesMap() {\n\t\treturn this.staticAttributes;\n\t}", "summary_tokens": ["allow", "map", "access", "to", "the", "static", "attributes", "of", "this", "view", "with", "the", "option", "to", "add", "or", "override", "specific", "entries"], "project": "spring-framework"}
{"id": 4548, "code": "\tprotected Class<?> determineActivationSpecClass(ResourceAdapter adapter) {\n\t\treturn null;\n\t}", "summary_tokens": ["determine", "the", "activation", "spec", "class", "for", "the", "given", "resource", "adapter", "if", "possible"], "project": "spring-framework"}
{"id": 8486, "code": "\tpublic void setDetectAllHandlerMappings(boolean detectAllHandlerMappings) {\n\t\tthis.detectAllHandlerMappings = detectAllHandlerMappings;\n\t}", "summary_tokens": ["set", "whether", "to", "detect", "all", "handler", "mapping", "beans", "in", "this", "servlet", "s", "context"], "project": "spring-framework"}
{"id": 454, "code": "\tpublic final T getObject() throws Exception {\n\t\tif (isSingleton()) {\n\t\t\treturn (this.initialized ? this.singletonInstance : getEarlySingletonInstance());\n\t\t}\n\t\telse {\n\t\t\treturn createInstance();\n\t\t}\n\t}", "summary_tokens": ["expose", "the", "singleton", "instance", "or", "create", "a", "new", "prototype", "instance"], "project": "spring-framework"}
{"id": 6715, "code": "\tpublic static Optional<MediaType> getMediaType(@Nullable String filename) {\n\t\treturn getMediaTypes(filename).stream().findFirst();\n\t}", "summary_tokens": ["determine", "a", "media", "type", "for", "the", "given", "file", "name", "if", "possible"], "project": "spring-framework"}
{"id": 7323, "code": "\tpublic void setBeanFactory(BeanFactory beanFactory) {\n\t\tthis.beanFactory = beanFactory;\n\t}", "summary_tokens": ["a", "bean", "factory", "to", "use", "for", "resolving", "an", "executor", "name"], "project": "spring-framework"}
{"id": 3373, "code": "\tpublic static <T> T resolve(@Nullable Supplier<T> supplier) {\n\t\treturn (supplier != null ? supplier.get() : null);\n\t}", "summary_tokens": ["resolve", "the", "given", "supplier", "getting", "its", "result", "or", "immediately", "returning", "null", "if", "the", "supplier", "itself", "was", "null"], "project": "spring-framework"}
{"id": 4274, "code": "\tpublic <S extends Session> S getSession(Class<S> sessionType, @Nullable Connection connection) {\n\t\tDeque<Session> sessions =\n\t\t\t\t(connection != null ? this.sessionsPerConnection.get(connection) : this.sessions);\n\t\treturn CollectionUtils.findValueOfType(sessions, sessionType);\n\t}", "summary_tokens": ["return", "this", "resource", "holder", "s", "session", "of", "the", "given", "type", "for", "the", "given", "connection", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 3696, "code": "\tpublic void setRequiredType(Class<T> requiredType) {\n\t\tthis.requiredType = ClassUtils.resolvePrimitiveIfNecessary(requiredType);\n\t}", "summary_tokens": ["set", "the", "type", "that", "each", "result", "object", "is", "expected", "to", "match"], "project": "spring-framework"}
{"id": 9544, "code": "\tprotected void prepareResponse(HttpServletRequest request, HttpServletResponse response) {\n\t\tif (generatesDownloadContent()) {\n\t\t\tresponse.setHeader(\"Pragma\", \"private\");\n\t\t\tresponse.setHeader(\"Cache-Control\", \"private, must-revalidate\");\n\t\t}\n\t}", "summary_tokens": ["prepare", "the", "given", "response", "for", "rendering"], "project": "spring-framework"}
{"id": 3746, "code": "\tprotected String createParameterBinding(SqlParameter parameter) {\n\t\treturn (isNamedBinding() ? parameter.getName() + \" => ?\" : \"?\");\n\t}", "summary_tokens": ["build", "the", "parameter", "binding", "fragment"], "project": "spring-framework"}
{"id": 5707, "code": "\tpublic String toString() {\n\t\treturn new ToStringCreator(this)\n\t\t\t\t.append(\"declaringClass\", this.declaringClass.getName())\n\t\t\t\t.append(\"locations\", this.locations)\n\t\t\t\t.append(\"inheritLocations\", this.inheritLocations)\n\t\t\t\t.append(\"properties\", this.properties)\n\t\t\t\t.append(\"inheritProperties\", this.inheritProperties)\n\t\t\t\t.toString();\n\t}", "summary_tokens": ["provide", "a", "string", "representation", "of", "the", "attributes", "and", "declaring", "class"], "project": "spring-framework"}
{"id": 4380, "code": "\tprotected Connection createSharedConnection() throws JMSException {\n\t\tConnection con = createConnection();\n\t\ttry {\n\t\t\tprepareSharedConnection(con);\n\t\t\treturn con;\n\t\t}\n\t\tcatch (JMSException ex) {\n\t\t\tJmsUtils.closeConnection(con);\n\t\t\tthrow ex;\n\t\t}\n\t}", "summary_tokens": ["create", "a", "shared", "connection", "for", "this", "container"], "project": "spring-framework"}
{"id": 7818, "code": "\tpublic UriComponentsBuilder uri(URI uri) {\n\t\tAssert.notNull(uri, \"URI must not be null\");\n\t\tthis.scheme = uri.getScheme();\n\t\tif (uri.isOpaque()) {\n\t\t\tthis.ssp = uri.getRawSchemeSpecificPart();\n\t\t\tresetHierarchicalComponents();\n\t\t}\n\t\telse {\n\t\t\tif (uri.getRawUserInfo() != null) {\n\t\t\t\tthis.userInfo = uri.getRawUserInfo();\n\t\t\t}\n\t\t\tif (uri.getHost() != null) {\n\t\t\t\tthis.host = uri.getHost();\n\t\t\t}\n\t\t\tif (uri.getPort() != -1) {\n\t\t\t\tthis.port = String.valueOf(uri.getPort());\n\t\t\t}\n\t\t\tif (StringUtils.hasLength(uri.getRawPath())) {\n\t\t\t\tthis.pathBuilder = new CompositePathComponentBuilder();\n\t\t\t\tthis.pathBuilder.addPath(uri.getRawPath());\n\t\t\t}\n\t\t\tif (StringUtils.hasLength(uri.getRawQuery())) {\n\t\t\t\tthis.queryParams.clear();\n\t\t\t\tquery(uri.getRawQuery());\n\t\t\t}\n\t\t\tresetSchemeSpecificPart();\n\t\t}\n\t\tif (uri.getRawFragment() != null) {\n\t\t\tthis.fragment = uri.getRawFragment();\n\t\t}\n\t\treturn this;\n\t}", "summary_tokens": ["initialize", "components", "of", "this", "builder", "from", "components", "of", "the", "given", "uri"], "project": "spring-framework"}
{"id": 1331, "code": "\tpublic void setExpressionSuffix(String expressionSuffix) {\n\t\tAssert.hasText(expressionSuffix, \"Expression suffix must not be empty\");\n\t\tthis.expressionSuffix = expressionSuffix;\n\t}", "summary_tokens": ["set", "the", "suffix", "that", "an", "expression", "string", "ends", "with"], "project": "spring-framework"}
{"id": 7967, "code": "\tpublic Object getHandler() {\n\t\treturn this.handler;\n\t}", "summary_tokens": ["return", "the", "handler", "that", "handled", "the", "request"], "project": "spring-framework"}
{"id": 305, "code": "\tpublic boolean equals(Object other) {\n\t\treturn (other != null && other.getClass() == this.getClass());\n\t}", "summary_tokens": ["a", "bit", "simplistic", "just", "wants", "the", "same", "class"], "project": "spring-framework"}
{"id": 6061, "code": "\tpublic ResultMatcher isPartialContent() {\n\t\treturn matcher(HttpStatus.PARTIAL_CONTENT);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 1147, "code": "\tpublic void setPostTemplateLoaders(TemplateLoader... postTemplateLoaders) {\n\t\tthis.postTemplateLoaders = Arrays.asList(postTemplateLoaders);\n\t}", "summary_tokens": ["set", "a", "list", "of", "template", "loader", "s", "that", "will", "be", "used", "to", "search", "for", "templates"], "project": "spring-framework"}
{"id": 2792, "code": "\tint size() {\n\t\treturn this.attributeMethods.length;\n\t}", "summary_tokens": ["get", "the", "number", "of", "attributes", "in", "this", "collection"], "project": "spring-framework"}
{"id": 7621, "code": "\tpublic boolean isBindingDisabled(String name) {\n\t\treturn (this.bindingDisabled.contains(name) || this.noBinding.contains(name));\n\t}", "summary_tokens": ["whether", "binding", "is", "disabled", "for", "the", "given", "model", "attribute"], "project": "spring-framework"}
{"id": 7175, "code": "\tpublic static boolean[] getBooleanParameters(ServletRequest request, String name) {\n\t\ttry {\n\t\t\treturn getRequiredBooleanParameters(request, name);\n\t\t}\n\t\tcatch (ServletRequestBindingException ex) {\n\t\t\treturn new boolean[0];\n\t\t}\n\t}", "summary_tokens": ["get", "an", "array", "of", "boolean", "parameters", "return", "an", "empty", "array", "if", "not", "found"], "project": "spring-framework"}
{"id": 3074, "code": "\tdefault boolean hasSuperClass() {\n\t\treturn (getSuperClassName() != null);\n\t}", "summary_tokens": ["return", "whether", "the", "underlying", "class", "has", "a", "superclass"], "project": "spring-framework"}
{"id": 3528, "code": "\tpublic static int arrayCodeFor(String arraytype) {\n\t\tswitch (arraytype.charAt(0)) {\n\t\t\tcase 'I': return T_INT;\n\t\t\tcase 'J': return T_LONG;\n\t\t\tcase 'F': return T_FLOAT;\n\t\t\tcase 'D': return T_DOUBLE;\n\t\t\tcase 'B': return T_BYTE;\n\t\t\tcase 'C': return T_CHAR;\n\t\t\tcase 'S': return T_SHORT;\n\t\t\tcase 'Z': return T_BOOLEAN;\n\t\t\tdefault:\n\t\t\t\tthrow new IllegalArgumentException(\"Unexpected arraytype \" + arraytype.charAt(0));\n\t\t}\n\t}", "summary_tokens": ["determine", "the", "appropriate", "t", "tag", "to", "use", "for", "the", "newarray", "bytecode"], "project": "spring-framework"}
{"id": 6053, "code": "\tpublic ResultMatcher isProcessing() {\n\t\treturn matcher(HttpStatus.PROCESSING);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 5692, "code": "\tprotected String getResourceSuffix() {\n\t\tthrow new UnsupportedOperationException(\n\t\t\t\t\"GenericGroovyXmlContextLoader does not support the getResourceSuffix() method\");\n\t}", "summary_tokens": ["generic", "groovy", "xml", "context", "loader", "supports", "both", "groovy", "and", "xml", "resource", "types", "for", "detection", "of", "defaults"], "project": "spring-framework"}
{"id": 4792, "code": "\tdefault <T> Encoder<T> encoder(ResolvableType elementType, @Nullable MimeType mimeType) {\n\t\tfor (Encoder<?> encoder : encoders()) {\n\t\t\tif (encoder.canEncode(elementType, mimeType)) {\n\t\t\t\treturn (Encoder<T>) encoder;\n\t\t\t}\n\t\t}\n\t\tthrow new IllegalArgumentException(\"No encoder for \" + elementType);\n\t}", "summary_tokens": ["find", "a", "compatible", "encoder", "for", "the", "given", "element", "type"], "project": "spring-framework"}
{"id": 6376, "code": "\tpublic boolean isRollbackOnly() {\n\t\treturn this.rollbackOnly;\n\t}", "summary_tokens": ["determine", "the", "rollback", "only", "flag", "via", "checking", "this", "reactive", "transaction", "status"], "project": "spring-framework"}
{"id": 4662, "code": "\tpublic void setReceiveTimeout(long receiveTimeout) {\n\t\tthis.receiveTimeout = receiveTimeout;\n\t}", "summary_tokens": ["configure", "the", "default", "timeout", "value", "to", "use", "for", "receive", "operations"], "project": "spring-framework"}
{"id": 8824, "code": "\tprotected int getDepth(String exceptionMapping, Exception ex) {\n\t\treturn getDepth(exceptionMapping, ex.getClass(), 0);\n\t}", "summary_tokens": ["return", "the", "depth", "to", "the", "superclass", "matching"], "project": "spring-framework"}
{"id": 2015, "code": "\tpublic void validate(Object... validationHints) {\n\t\tObject target = getTarget();\n\t\tAssert.state(target != null, \"No target to validate\");\n\t\tBindingResult bindingResult = getBindingResult();\n\t\t\n\t\tfor (Validator validator : getValidators()) {\n\t\t\tif (!ObjectUtils.isEmpty(validationHints) && validator instanceof SmartValidator) {\n\t\t\t\t((SmartValidator) validator).validate(target, bindingResult, validationHints);\n\t\t\t}\n\t\t\telse if (validator != null) {\n\t\t\t\tvalidator.validate(target, bindingResult);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "specified", "validators", "if", "any", "with", "the", "given", "validation", "hints"], "project": "spring-framework"}
{"id": 4988, "code": "\tpublic static StompHeaderAccessor wrap(Message<?> message) {\n\t\treturn new StompHeaderAccessor(message);\n\t}", "summary_tokens": ["create", "an", "instance", "from", "the", "payload", "and", "headers", "of", "the", "given", "message"], "project": "spring-framework"}
{"id": 1891, "code": "\tpublic Object getTarget() {\n\t\treturn this.target;\n\t}", "summary_tokens": ["return", "the", "target", "instance", "to", "call", "the", "method", "on"], "project": "spring-framework"}
{"id": 5942, "code": "\tpublic static MockMvcHtmlUnitDriverBuilder mockMvcSetup(MockMvc mockMvc) {\n\t\tAssert.notNull(mockMvc, \"MockMvc must not be null\");\n\t\treturn new MockMvcHtmlUnitDriverBuilder(mockMvc);\n\t}", "summary_tokens": ["create", "a", "new", "mock", "mvc", "html", "unit", "driver", "builder", "based", "on", "the", "supplied", "mock", "mvc", "instance"], "project": "spring-framework"}
{"id": 5581, "code": "\tpublic ConditionEvaluationResult evaluateExecutionCondition(ExtensionContext context) {\n\t\treturn evaluateAnnotation(DisabledIf.class, DisabledIf::expression, DisabledIf::reason,\n\t\t\t\tDisabledIf::loadContext, false, context);\n\t}", "summary_tokens": ["containers", "and", "tests", "are", "disabled", "if", "is", "present", "on", "the", "corresponding", "test", "class", "or", "test", "method", "and", "the", "configured", "expression", "evaluates", "to", "true"], "project": "spring-framework"}
{"id": 4847, "code": "\tpublic void setDefaultUserDestinationPrefix(String prefix) {\n\t\tthis.defaultUserDestinationPrefix = prefix;\n\t}", "summary_tokens": ["configure", "a", "default", "prefix", "to", "add", "to", "message", "destinations", "in", "cases", "where", "a", "method", "is", "annotated", "with", "send", "to", "user", "but", "does", "not", "specify", "any", "destinations", "through", "the", "annotation", "s", "value", "attribute"], "project": "spring-framework"}
{"id": 1102, "code": "\tpublic void setSchedulerName(String schedulerName) {\n\t\tthis.schedulerName = schedulerName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "scheduler", "to", "create", "via", "the", "scheduler", "factory", "as", "an", "alternative", "to", "the", "org"], "project": "spring-framework"}
{"id": 7309, "code": "\tpublic boolean hasConcurrentResult() {\n\t\treturn (this.concurrentResult != RESULT_NONE);\n\t}", "summary_tokens": ["whether", "a", "result", "value", "exists", "as", "a", "result", "of", "concurrent", "handling"], "project": "spring-framework"}
{"id": 2970, "code": "\tpublic boolean isFile() {\n\t\treturn true;\n\t}", "summary_tokens": ["this", "implementation", "always", "indicates", "a", "file"], "project": "spring-framework"}
{"id": 4117, "code": "\tpublic T findObjectByNamedParam(Map<String, ?> paramMap) throws DataAccessException {\n\t\treturn findObjectByNamedParam(paramMap, null);\n\t}", "summary_tokens": ["convenient", "method", "to", "execute", "without", "context"], "project": "spring-framework"}
{"id": 474, "code": "\tpublic ResolvableType getResolvableType() {\n\t\tResolvableType resolvableType = this.resolvableType;\n\t\tif (resolvableType == null) {\n\t\t\tresolvableType = (this.field != null ?\n\t\t\t\t\tResolvableType.forField(this.field, this.nestingLevel, this.containingClass) :\n\t\t\t\t\tResolvableType.forMethodParameter(obtainMethodParameter()));\n\t\t\tthis.resolvableType = resolvableType;\n\t\t}\n\t\treturn resolvableType;\n\t}", "summary_tokens": ["build", "a", "resolvable", "type", "object", "for", "the", "wrapped", "parameter", "field"], "project": "spring-framework"}
{"id": 2244, "code": "\tMethodName and(String... parts) {\n\t\tAssert.notNull(parts, \"'parts' must not be null\");\n\t\tString joined = join(parts);\n\t\tString prefix = getPrefix(joined);\n\t\tString suffix = joined.substring(prefix.length());\n\t\treturn of(prefix, this.value, suffix);\n\t}", "summary_tokens": ["create", "a", "new", "method", "name", "by", "concatenating", "the", "specified", "parts", "to", "this", "name"], "project": "spring-framework"}
{"id": 559, "code": "\tpublic void setDocumentMatchers(DocumentMatcher... matchers) {\n\t\tthis.documentMatchers = List.of(matchers);\n\t}", "summary_tokens": ["a", "map", "of", "document", "matchers", "allowing", "callers", "to", "selectively", "use", "only", "some", "of", "the", "documents", "in", "a", "yaml", "resource"], "project": "spring-framework"}
{"id": 7882, "code": "\tpublic int getWildcardCount() {\n\t\treturn 0;\n\t}", "summary_tokens": ["return", "the", "number", "of", "wildcard", "elements", "in", "the", "path", "element"], "project": "spring-framework"}
{"id": 8529, "code": "\tpublic void setEnvironment(Environment environment) {\n\t\tAssert.isInstanceOf(ConfigurableEnvironment.class, environment, \"ConfigurableEnvironment required\");\n\t\tthis.environment = (ConfigurableEnvironment) environment;\n\t}", "summary_tokens": ["set", "the", "environment", "that", "this", "servlet", "runs", "in"], "project": "spring-framework"}
{"id": 8411, "code": "\tprotected FreeMarkerConfig autodetectConfiguration() throws BeansException {\n\t\ttry {\n\t\t\treturn BeanFactoryUtils.beanOfTypeIncludingAncestors(\n\t\t\t\t\tobtainApplicationContext(), FreeMarkerConfig.class, true, false);\n\t\t}\n\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\tthrow new ApplicationContextException(\n\t\t\t\t\t\"Must define a single FreeMarkerConfig bean in this application context \" +\n\t\t\t\t\t\t\t\"(may be inherited): FreeMarkerConfigurer is the usual implementation. \" +\n\t\t\t\t\t\t\t\"This bean may be given any name.\", ex);\n\t\t}\n\t}", "summary_tokens": ["autodetect", "a", "free", "marker", "config", "object", "in", "the", "application", "context"], "project": "spring-framework"}
{"id": 8487, "code": "\tpublic void setDetectAllHandlerAdapters(boolean detectAllHandlerAdapters) {\n\t\tthis.detectAllHandlerAdapters = detectAllHandlerAdapters;\n\t}", "summary_tokens": ["set", "whether", "to", "detect", "all", "handler", "adapter", "beans", "in", "this", "servlet", "s", "context"], "project": "spring-framework"}
{"id": 4766, "code": "\tpublic List<HandlerMethodReturnValueHandler> getReturnValueHandlers() {\n\t\treturn Collections.unmodifiableList(this.returnValueHandlers);\n\t}", "summary_tokens": ["return", "a", "read", "only", "list", "with", "the", "configured", "handlers"], "project": "spring-framework"}
{"id": 8537, "code": "\tdefault void setLocale(HttpServletRequest request, @Nullable HttpServletResponse response, @Nullable Locale locale) {\n\t\tsetLocaleContext(request, response, (locale != null ? new SimpleLocaleContext(locale) : null));\n\t}", "summary_tokens": ["default", "implementation", "of", "locale", "resolver", "set", "locale", "http", "servlet", "request", "http", "servlet", "response", "locale", "that", "delegates", "to", "set", "locale", "context", "http", "servlet", "request", "http", "servlet", "response", "locale", "context", "using", "a", "simple", "locale", "context"], "project": "spring-framework"}
{"id": 8868, "code": "\tprotected String getSuffix() {\n\t\treturn this.suffix;\n\t}", "summary_tokens": ["return", "the", "suffix", "to", "append", "to", "the", "request", "url", "filename"], "project": "spring-framework"}
{"id": 6455, "code": "\tpublic final void rollback(TransactionStatus status) throws TransactionException {\n\t\tif (status.isCompleted()) {\n\t\t\tthrow new IllegalTransactionStateException(\n\t\t\t\t\t\"Transaction is already completed - do not call commit or rollback more than once per transaction\");\n\t\t}\n\n\t\tDefaultTransactionStatus defStatus = (DefaultTransactionStatus) status;\n\t\tprocessRollback(defStatus, false);\n\t}", "summary_tokens": ["this", "implementation", "of", "rollback", "handles", "participating", "in", "existing", "transactions"], "project": "spring-framework"}
{"id": 8569, "code": "\tprivate static boolean containsBeanInHierarchy(ParserContext context, String beanName) {\n\t\tBeanDefinitionRegistry registry = context.getRegistry();\n\t\treturn (registry instanceof BeanFactory ? ((BeanFactory) registry).containsBean(beanName) :\n\t\t\t\tregistry.containsBeanDefinition(beanName));\n\t}", "summary_tokens": ["check", "for", "an", "existing", "bean", "of", "the", "given", "name", "ideally", "in", "the", "entire", "context", "hierarchy", "through", "a", "contains", "bean", "call", "since", "this", "is", "also", "what", "dispatcher", "servlet", "does", "or", "otherwise", "just", "in", "the", "local", "context", "through", "contains", "bean", "definition"], "project": "spring-framework"}
{"id": 8982, "code": "\tpublic static UriComponentsBuilder fromMethod(UriComponentsBuilder baseUrl,\n\t\t\t@Nullable Class<?> controllerType, Method method, Object... args) {\n\n\t\treturn fromMethodInternal(baseUrl,\n\t\t\t\t(controllerType != null ? controllerType : method.getDeclaringClass()), method, args);\n\t}", "summary_tokens": ["an", "alternative", "to", "from", "method", "class", "method", "object"], "project": "spring-framework"}
{"id": 3863, "code": "\tpublic String getCatalogName() {\n\t\treturn this.tableMetaDataContext.getCatalogName();\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "catalog", "for", "this", "insert"], "project": "spring-framework"}
{"id": 7905, "code": "\tpublic void testSerializability() throws IOException, ClassNotFoundException {\n\t\tHttpStatusCodeException ex1 = new HttpClientErrorException(\n\t\t\t\tHttpStatus.BAD_REQUEST, null, null, StandardCharsets.US_ASCII);\n\t\tByteArrayOutputStream out = new ByteArrayOutputStream();\n\t\tnew ObjectOutputStream(out).writeObject(ex1);\n\t\tByteArrayInputStream in = new ByteArrayInputStream(out.toByteArray());\n\t\tHttpStatusCodeException ex2 =\n\t\t\t\t(HttpStatusCodeException) new ObjectInputStream(in).readObject();\n\t\tassertThat(ex2.getResponseBodyAsString()).isEqualTo(ex1.getResponseBodyAsString());\n\t}", "summary_tokens": ["corners", "bug", "spr", "0", "which", "reported", "the", "fact", "that", "following", "the", "changes", "made", "in", "spr", "0", "http", "status", "code", "exception", "and", "subtypes", "became", "no", "longer", "serializable", "due", "to", "the", "addition", "of", "a", "non", "serializable", "charset", "field"], "project": "spring-framework"}
{"id": 348, "code": "\tprivate void createDefaultEditors() {\n\t\tthis.defaultEditors = new HashMap<>(64);\n\n\t\t\n\t\t\n\t\tthis.defaultEditors.put(Charset.class, new CharsetEditor());\n\t\tthis.defaultEditors.put(Class.class, new ClassEditor());\n\t\tthis.defaultEditors.put(Class[].class, new ClassArrayEditor());\n\t\tthis.defaultEditors.put(Currency.class, new CurrencyEditor());\n\t\tthis.defaultEditors.put(File.class, new FileEditor());\n\t\tthis.defaultEditors.put(InputStream.class, new InputStreamEditor());\n\t\tif (!shouldIgnoreXml) {\n\t\t\tthis.defaultEditors.put(InputSource.class, new InputSourceEditor());\n\t\t}\n\t\tthis.defaultEditors.put(Locale.class, new LocaleEditor());\n\t\tthis.defaultEditors.put(Path.class, new PathEditor());\n\t\tthis.defaultEditors.put(Pattern.class, new PatternEditor());\n\t\tthis.defaultEditors.put(Properties.class, new PropertiesEditor());\n\t\tthis.defaultEditors.put(Reader.class, new ReaderEditor());\n\t\tthis.defaultEditors.put(Resource[].class, new ResourceArrayPropertyEditor());\n\t\tthis.defaultEditors.put(TimeZone.class, new TimeZoneEditor());\n\t\tthis.defaultEditors.put(URI.class, new URIEditor());\n\t\tthis.defaultEditors.put(URL.class, new URLEditor());\n\t\tthis.defaultEditors.put(UUID.class, new UUIDEditor());\n\t\tthis.defaultEditors.put(ZoneId.class, new ZoneIdEditor());\n\n\t\t\n\t\t\n\t\tthis.defaultEditors.put(Collection.class, new CustomCollectionEditor(Collection.class));\n\t\tthis.defaultEditors.put(Set.class, new CustomCollectionEditor(Set.class));\n\t\tthis.defaultEditors.put(SortedSet.class, new CustomCollectionEditor(SortedSet.class));\n\t\tthis.defaultEditors.put(List.class, new CustomCollectionEditor(List.class));\n\t\tthis.defaultEditors.put(SortedMap.class, new CustomMapEditor(SortedMap.class));\n\n\t\t\n\t\tthis.defaultEditors.put(byte[].class, new ByteArrayPropertyEditor());\n\t\tthis.defaultEditors.put(char[].class, new CharArrayPropertyEditor());\n\n\t\t\n\t\tthis.defaultEditors.put(char.class, new CharacterEditor(false));\n\t\tthis.defaultEditors.put(Character.class, new CharacterEditor(true));\n\n\t\t\n\t\tthis.defaultEditors.put(boolean.class, new CustomBooleanEditor(false));\n\t\tthis.defaultEditors.put(Boolean.class, new CustomBooleanEditor(true));\n\n\t\t\n\t\t\n\t\tthis.defaultEditors.put(byte.class, new CustomNumberEditor(Byte.class, false));\n\t\tthis.defaultEditors.put(Byte.class, new CustomNumberEditor(Byte.class, true));\n\t\tthis.defaultEditors.put(short.class, new CustomNumberEditor(Short.class, false));\n\t\tthis.defaultEditors.put(Short.class, new CustomNumberEditor(Short.class, true));\n\t\tthis.defaultEditors.put(int.class, new CustomNumberEditor(Integer.class, false));\n\t\tthis.defaultEditors.put(Integer.class, new CustomNumberEditor(Integer.class, true));\n\t\tthis.defaultEditors.put(long.class, new CustomNumberEditor(Long.class, false));\n\t\tthis.defaultEditors.put(Long.class, new CustomNumberEditor(Long.class, true));\n\t\tthis.defaultEditors.put(float.class, new CustomNumberEditor(Float.class, false));\n\t\tthis.defaultEditors.put(Float.class, new CustomNumberEditor(Float.class, true));\n\t\tthis.defaultEditors.put(double.class, new CustomNumberEditor(Double.class, false));\n\t\tthis.defaultEditors.put(Double.class, new CustomNumberEditor(Double.class, true));\n\t\tthis.defaultEditors.put(BigDecimal.class, new CustomNumberEditor(BigDecimal.class, true));\n\t\tthis.defaultEditors.put(BigInteger.class, new CustomNumberEditor(BigInteger.class, true));\n\n\t\t\n\t\tif (this.configValueEditorsActive) {\n\t\t\tStringArrayPropertyEditor sae = new StringArrayPropertyEditor();\n\t\t\tthis.defaultEditors.put(String[].class, sae);\n\t\t\tthis.defaultEditors.put(short[].class, sae);\n\t\t\tthis.defaultEditors.put(int[].class, sae);\n\t\t\tthis.defaultEditors.put(long[].class, sae);\n\t\t}\n\t}", "summary_tokens": ["actually", "register", "the", "default", "editors", "for", "this", "registry", "instance"], "project": "spring-framework"}
{"id": 5155, "code": "\tpublic void setPhysicalNamingStrategy(PhysicalNamingStrategy physicalNamingStrategy) {\n\t\tthis.physicalNamingStrategy = physicalNamingStrategy;\n\t}", "summary_tokens": ["set", "a", "hibernate", "0", "physical", "naming", "strategy", "for", "the", "session", "factory"], "project": "spring-framework"}
{"id": 9426, "code": "\tpublic int doEndTag() throws JspException {\n\t\tAssert.state(this.tagWriter != null, \"No TagWriter set\");\n\t\tthis.tagWriter.endTag();\n\t\treturn EVAL_PAGE;\n\t}", "summary_tokens": ["close", "the", "label", "tag"], "project": "spring-framework"}
{"id": 9327, "code": "\tpublic void setAccesskey(String accesskey) {\n\t\tthis.accesskey = accesskey;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "accesskey", "attribute"], "project": "spring-framework"}
{"id": 271, "code": "\tpublic void destroy() throws Exception {\n\t\tif (this.pool != null) {\n\t\t\tlogger.debug(\"Closing Commons ObjectPool\");\n\t\t\tthis.pool.close();\n\t\t}\n\t}", "summary_tokens": ["closes", "the", "underlying", "object", "pool", "when", "destroying", "this", "object"], "project": "spring-framework"}
{"id": 32, "code": "\tpublic int getOrder() {\n\t\treturn getOrderForAspectClass(this.aspectClass);\n\t}", "summary_tokens": ["determine", "the", "order", "for", "this", "factory", "s", "aspect", "instance", "either", "an", "instance", "specific", "order", "expressed", "through", "implementing", "the", "org"], "project": "spring-framework"}
{"id": 3727, "code": "\tpublic String getCatalogName() {\n\t\treturn this.catalogName;\n\t}", "summary_tokens": ["get", "the", "name", "of", "the", "catalog"], "project": "spring-framework"}
{"id": 3009, "code": "\tprotected Properties mergeProperties() throws IOException {\n\t\tProperties result = new Properties();\n\n\t\tif (this.localOverride) {\n\t\t\t\n\t\t\tloadProperties(result);\n\t\t}\n\n\t\tif (this.localProperties != null) {\n\t\t\tfor (Properties localProp : this.localProperties) {\n\t\t\t\tCollectionUtils.mergePropertiesIntoMap(localProp, result);\n\t\t\t}\n\t\t}\n\n\t\tif (!this.localOverride) {\n\t\t\t\n\t\t\tloadProperties(result);\n\t\t}\n\n\t\treturn result;\n\t}", "summary_tokens": ["return", "a", "merged", "properties", "instance", "containing", "both", "the", "loaded", "properties", "and", "properties", "set", "on", "this", "factory", "bean"], "project": "spring-framework"}
{"id": 288, "code": "\tvoid testToStringDoesntHitTarget() throws Throwable {\n\t\tObject target = new TestBean() {\n\t\t\t@Override\n\t\t\tpublic String toString() {\n\t\t\t\tthrow new UnsupportedOperationException(\"toString\");\n\t\t\t}\n\t\t};\n\t\tList<Object> interceptors = Collections.emptyList();\n\n\t\tMethod m = Object.class.getMethod(\"hashCode\");\n\t\tObject proxy = new Object();\n\t\tReflectiveMethodInvocation invocation = new ReflectiveMethodInvocation(proxy, target, m, null, null, interceptors);\n\n\t\t\n\t\t\n\t\tinvocation.toString();\n\t}", "summary_tokens": ["to", "string", "on", "target", "can", "cause", "failure"], "project": "spring-framework"}
{"id": 1790, "code": "\tprivate static Throwable exposedException(Throwable original) {\n\t\tif (original instanceof ExecutionException) {\n\t\t\tThrowable cause = original.getCause();\n\t\t\tif (cause != null) {\n\t\t\t\treturn cause;\n\t\t\t}\n\t\t}\n\t\treturn original;\n\t}", "summary_tokens": ["determine", "the", "exposed", "exception", "either", "the", "cause", "of", "a", "given", "execution", "exception", "or", "the", "original", "exception", "as", "is"], "project": "spring-framework"}
{"id": 7136, "code": "\tprotected MediaType lookupMediaType(String extension) {\n\t\treturn this.mediaTypes.get(extension.toLowerCase(Locale.ENGLISH));\n\t}", "summary_tokens": ["use", "this", "method", "for", "a", "reverse", "lookup", "from", "extension", "to", "media", "type"], "project": "spring-framework"}
{"id": 5439, "code": "\tpublic String getBodyAsString(Charset charset) {\n\t\treturn StreamUtils.copyToString(this.body, charset);\n\t}", "summary_tokens": ["return", "the", "body", "content", "as", "a", "string"], "project": "spring-framework"}
{"id": 5809, "code": "\tpublic RequestMatcher contentType(MediaType expectedContentType) {\n\t\treturn request -> {\n\t\t\tMediaType actualContentType = request.getHeaders().getContentType();\n\t\t\tassertTrue(\"Content type not set\", actualContentType != null);\n\t\t\tassertEquals(\"Content type\", expectedContentType, actualContentType);\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "request", "content", "type", "as", "a", "media", "type"], "project": "spring-framework"}
{"id": 7924, "code": "\tpublic MethodParameter arg(ResolvableType type) {\n\t\treturn new ArgResolver().arg(type);\n\t}", "summary_tokens": ["find", "a", "unique", "argument", "matching", "the", "given", "type"], "project": "spring-framework"}
{"id": 9740, "code": "\tprivate void checkContainsAll(Map expected, Map<String, Object> actual) {\n\t\texpected.forEach((k, v) -> assertThat(actual.get(k)).as(\"Values for model key '\" + k\n\t\t\t\t\t\t+ \"' must match\").isEqualTo(expected.get(k)));\n\t}", "summary_tokens": ["check", "that", "all", "keys", "in", "expected", "have", "same", "values", "in", "actual"], "project": "spring-framework"}
{"id": 9430, "code": "\tpublic void setDisabled(boolean disabled) {\n\t\tthis.disabled = disabled;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "disabled", "attribute"], "project": "spring-framework"}
{"id": 5059, "code": "\tdefault Message<?> preSend(Message<?> message, MessageChannel channel) {\n\t\treturn message;\n\t}", "summary_tokens": ["invoked", "before", "the", "message", "is", "actually", "sent", "to", "the", "channel"], "project": "spring-framework"}
{"id": 2495, "code": "public void visitMaxs(final int maxStack, final int maxLocals) {\n  if (mv != null) {\n    mv.visitMaxs(maxStack, maxLocals);\n  }\n}", "summary_tokens": ["visits", "the", "maximum", "stack", "size", "and", "the", "maximum", "number", "of", "local", "variables", "of", "the", "method"], "project": "spring-framework"}
{"id": 7677, "code": "\tpublic List<String> getConditions() {\n\t\treturn this.conditions;\n\t}", "summary_tokens": ["return", "string", "representations", "of", "the", "unsatisfied", "condition", "s"], "project": "spring-framework"}
{"id": 3634, "code": "\tvoid wideningPrimitiveConversion_SPR8224() throws Exception {\n\n\t\tclass WideningPrimitiveConversion {\n\t\t\tpublic int getX(long i) {\n\t\t\t\treturn 10;\n\t\t\t}\n\t\t}\n\n\t\tfinal Integer INTEGER_VALUE = 7;\n\t\tWideningPrimitiveConversion target = new WideningPrimitiveConversion();\n\t\tEvaluationContext emptyEvalContext = new StandardEvaluationContext();\n\n\t\tList<TypeDescriptor> args = new ArrayList<>();\n\t\targs.add(TypeDescriptor.forObject(INTEGER_VALUE));\n\n\t\tMethodExecutor me = new ReflectiveMethodResolver(true).resolve(emptyEvalContext, target, \"getX\", args);\n\t\tfinal int actual = (Integer) me.execute(emptyEvalContext, target, INTEGER_VALUE).getValue();\n\n\t\tfinal int compiler = target.getX(INTEGER_VALUE);\n\t\tassertThat(actual).isEqualTo(compiler);\n\t}", "summary_tokens": ["test", "whether", "reflective", "method", "resolver", "handles", "widening", "primitive", "conversion"], "project": "spring-framework"}
{"id": 5098, "code": "\tprotected TcpClient extendTcpClient(TcpClient tcpClient, TcpConnectionHandler<P> handler) {\n\t\treturn tcpClient;\n\t}", "summary_tokens": ["provides", "an", "opportunity", "to", "initialize", "the", "tcp", "client", "for", "the", "given", "tcp", "connection", "handler", "which", "may", "implement", "sub", "interfaces", "such", "as", "org"], "project": "spring-framework"}
{"id": 4923, "code": "\tpublic List<Message<byte[]>> decode(ByteBuffer newBuffer) {\n\t\tthis.chunks.add(newBuffer);\n\t\tcheckBufferLimits();\n\n\t\tInteger contentLength = this.expectedContentLength;\n\t\tif (contentLength != null && getBufferSize() < contentLength) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\n\t\tByteBuffer bufferToDecode = assembleChunksAndReset();\n\t\tMultiValueMap<String, String> headers = new LinkedMultiValueMap<>();\n\t\tList<Message<byte[]>> messages = this.stompDecoder.decode(bufferToDecode, headers);\n\n\t\tif (bufferToDecode.hasRemaining()) {\n\t\t\tthis.chunks.add(bufferToDecode);\n\t\t\tthis.expectedContentLength = StompHeaderAccessor.getContentLength(headers);\n\t\t}\n\n\t\treturn messages;\n\t}", "summary_tokens": ["decodes", "one", "or", "more", "stomp", "frames", "from", "the", "given", "byte", "buffer", "into", "a", "list", "of", "message", "messages"], "project": "spring-framework"}
{"id": 3204, "code": "\tpublic void setThreadGroupName(String name) {\n\t\tthis.threadGroup = new ThreadGroup(name);\n\t}", "summary_tokens": ["specify", "the", "name", "of", "the", "thread", "group", "that", "threads", "should", "be", "created", "in"], "project": "spring-framework"}
{"id": 5159, "code": "\tpublic void setCurrentTenantIdentifierResolver(CurrentTenantIdentifierResolver currentTenantIdentifierResolver) {\n\t\tthis.currentTenantIdentifierResolver = currentTenantIdentifierResolver;\n\t}", "summary_tokens": ["set", "a", "current", "tenant", "identifier", "resolver", "to", "be", "passed", "on", "to", "the", "session", "factory"], "project": "spring-framework"}
{"id": 7282, "code": "\tdefault <T> void preProcess(NativeWebRequest request, Callable<T> task) throws Exception {\n\t}", "summary_tokens": ["invoked", "em", "after", "em", "the", "start", "of", "concurrent", "handling", "in", "the", "async", "thread", "in", "which", "the", "callable", "is", "executed", "and", "em", "before", "em", "the", "actual", "invocation", "of", "the", "callable"], "project": "spring-framework"}
{"id": 4966, "code": "\tpublic void setMessageConverter(MessageConverter messageConverter) {\n\t\tAssert.notNull(messageConverter, \"MessageConverter must not be null\");\n\t\tthis.messageConverter = messageConverter;\n\t}", "summary_tokens": ["set", "the", "message", "converter", "to", "use", "to", "convert", "the", "payload", "of", "incoming", "and", "outgoing", "messages", "to", "and", "from", "byte", "based", "on", "object", "type", "and", "the", "content", "type", "header"], "project": "spring-framework"}
{"id": 6588, "code": "\tpublic void transactionShouldSucceed() throws Exception {\n\t\tTransactionAttribute txatt = new DefaultTransactionAttribute();\n\n\t\tMapTransactionAttributeSource tas = new MapTransactionAttributeSource();\n\t\ttas.register(getNameMethod, txatt);\n\n\t\tTransactionStatus status = mock(TransactionStatus.class);\n\t\tPlatformTransactionManager ptm = mock(PlatformTransactionManager.class);\n\t\t\n\t\tgiven(ptm.getTransaction(txatt)).willReturn(status);\n\n\t\tTestBean tb = new TestBean();\n\t\tITestBean itb = (ITestBean) advised(tb, ptm, tas);\n\n\t\tcheckTransactionStatus(false);\n\t\titb.getName();\n\t\tcheckTransactionStatus(false);\n\n\t\tverify(ptm).commit(status);\n\t}", "summary_tokens": ["check", "that", "a", "transaction", "is", "created", "and", "committed"], "project": "spring-framework"}
{"id": 4131, "code": "\tpublic String[] getErrorCodes() {\n\t\treturn this.errorCodes;\n\t}", "summary_tokens": ["return", "the", "sql", "error", "codes", "to", "match"], "project": "spring-framework"}
{"id": 199, "code": "\tpublic void setLocation(@Nullable String location) {\n\t\tthis.location = location;\n\t}", "summary_tokens": ["set", "the", "location", "for", "debugging"], "project": "spring-framework"}
{"id": 8874, "code": "\tprotected ModelAndView resolveResponseStatus(ResponseStatus responseStatus, HttpServletRequest request,\n\t\t\tHttpServletResponse response, @Nullable Object handler, Exception ex) throws Exception {\n\n\t\tint statusCode = responseStatus.code().value();\n\t\tString reason = responseStatus.reason();\n\t\treturn applyStatusAndReason(statusCode, reason, response);\n\t}", "summary_tokens": ["template", "method", "that", "handles", "the", "response", "status", "annotation"], "project": "spring-framework"}
{"id": 3932, "code": "\tprotected boolean isTransactionActive() {\n\t\treturn this.transactionActive;\n\t}", "summary_tokens": ["return", "whether", "this", "holder", "represents", "an", "active", "jdbc", "managed", "transaction"], "project": "spring-framework"}
{"id": 141, "code": "\tpublic static boolean shouldProxyTargetClass(\n\t\t\tConfigurableListableBeanFactory beanFactory, @Nullable String beanName) {\n\n\t\tif (beanName != null && beanFactory.containsBeanDefinition(beanName)) {\n\t\t\tBeanDefinition bd = beanFactory.getBeanDefinition(beanName);\n\t\t\treturn Boolean.TRUE.equals(bd.getAttribute(PRESERVE_TARGET_CLASS_ATTRIBUTE));\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "bean", "should", "be", "proxied", "with", "its", "target", "class", "rather", "than", "its", "interfaces"], "project": "spring-framework"}
{"id": 8002, "code": "\tpublic ResourceChainRegistration resourceChain(boolean cacheResources, Cache cache) {\n\t\tthis.resourceChainRegistration = new ResourceChainRegistration(cacheResources, cache);\n\t\treturn this.resourceChainRegistration;\n\t}", "summary_tokens": ["configure", "a", "chain", "of", "resource", "resolvers", "and", "transformers", "to", "use"], "project": "spring-framework"}
{"id": 899, "code": "\tpublic void resort() {\n\t\tSortDefinition sort = getSort();\n\t\tif (sort != null && !sort.equals(this.sortUsed)) {\n\t\t\tthis.sortUsed = copySortDefinition(sort);\n\t\t\tdoSort(getSource(), sort);\n\t\t\tsetPage(0);\n\t\t}\n\t}", "summary_tokens": ["resort", "the", "list", "if", "necessary", "i"], "project": "spring-framework"}
{"id": 2727, "code": "\tpublic Class<?> getReactiveType() {\n\t\treturn getDescriptor().getReactiveType();\n\t}", "summary_tokens": ["shortcut", "for", "get", "descriptor"], "project": "spring-framework"}
{"id": 1885, "code": "\tpublic static CronField parseDaysOfMonth(String value) {\n\t\tif (!QuartzCronField.isQuartzDaysOfMonthField(value)) {\n\t\t\treturn BitsCronField.parseDaysOfMonth(value);\n\t\t}\n\t\telse {\n\t\t\treturn parseList(value, Type.DAY_OF_MONTH, (field, type) -> {\n\t\t\t\tif (QuartzCronField.isQuartzDaysOfMonthField(field)) {\n\t\t\t\t\treturn QuartzCronField.parseDaysOfMonth(field);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn BitsCronField.parseDaysOfMonth(field);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}", "summary_tokens": ["parse", "the", "given", "value", "into", "a", "days", "of", "months", "cron", "field", "the", "fourth", "entry", "of", "a", "cron", "expression"], "project": "spring-framework"}
{"id": 4363, "code": "\tpublic void setClientId(@Nullable String clientId) {\n\t\tthis.clientId = clientId;\n\t}", "summary_tokens": ["specify", "the", "jms", "client", "id", "for", "a", "shared", "connection", "created", "and", "used", "by", "this", "container"], "project": "spring-framework"}
{"id": 8089, "code": "\tstatic ExchangeStrategies withDefaults() {\n\t\treturn DefaultExchangeStrategiesBuilder.DEFAULT_EXCHANGE_STRATEGIES;\n\t}", "summary_tokens": ["return", "an", "exchange", "strategies", "instance", "with", "default", "configuration", "provided", "by", "client", "codec", "configurer"], "project": "spring-framework"}
{"id": 3951, "code": "\tpublic void setIsolationLevel(int isolationLevel) {\n\t\tif (!constants.getValues(DefaultTransactionDefinition.PREFIX_ISOLATION).contains(isolationLevel)) {\n\t\t\tthrow new IllegalArgumentException(\"Only values of isolation constants allowed\");\n\t\t}\n\t\tthis.isolationLevel = (isolationLevel != TransactionDefinition.ISOLATION_DEFAULT ? isolationLevel : null);\n\t}", "summary_tokens": ["specify", "the", "default", "isolation", "level", "to", "use", "for", "connection", "retrieval", "according", "to", "the", "jdbc", "java"], "project": "spring-framework"}
{"id": 8656, "code": "\tpublic UrlBasedViewResolverRegistration freeMarker() {\n\t\tif (!checkBeanOfType(FreeMarkerConfigurer.class)) {\n\t\t\tthrow new BeanInitializationException(\"In addition to a FreeMarker view resolver \" +\n\t\t\t\t\t\"there must also be a single FreeMarkerConfig bean in this web application context \" +\n\t\t\t\t\t\"(or its parent): FreeMarkerConfigurer is the usual implementation. \" +\n\t\t\t\t\t\"This bean may be given any name.\");\n\t\t}\n\t\tFreeMarkerRegistration registration = new FreeMarkerRegistration();\n\t\tthis.viewResolvers.add(registration.getViewResolver());\n\t\treturn registration;\n\t}", "summary_tokens": ["register", "a", "free", "marker", "view", "resolver", "with", "an", "empty", "default", "view", "name", "prefix", "and", "a", "default", "suffix", "of"], "project": "spring-framework"}
{"id": 5359, "code": "\tprotected Connection getCloseSuppressingConnectionProxy(Connection target) {\n\t\treturn (Connection) Proxy.newProxyInstance(SingleConnectionFactory.class.getClassLoader(),\n\t\t\t\tnew Class<?>[] { Connection.class, Wrapped.class }, new CloseSuppressingInvocationHandler(target));\n\t}", "summary_tokens": ["wrap", "the", "given", "connection", "with", "a", "proxy", "that", "delegates", "every", "method", "call", "to", "it", "but", "suppresses", "close", "calls"], "project": "spring-framework"}
{"id": 3137, "code": "\tpublic static String classNamesToString(@Nullable Collection<Class<?>> classes) {\n\t\tif (CollectionUtils.isEmpty(classes)) {\n\t\t\treturn \"[]\";\n\t\t}\n\t\tStringJoiner stringJoiner = new StringJoiner(\", \", \"[\", \"]\");\n\t\tfor (Class<?> clazz : classes) {\n\t\t\tstringJoiner.add(clazz.getName());\n\t\t}\n\t\treturn stringJoiner.toString();\n\t}", "summary_tokens": ["build", "a", "string", "that", "consists", "of", "the", "names", "of", "the", "classes", "interfaces", "in", "the", "given", "collection"], "project": "spring-framework"}
{"id": 422, "code": "\tpublic boolean hasQualifier(DependencyDescriptor descriptor) {\n\t\tfor (Annotation ann : descriptor.getAnnotations()) {\n\t\t\tif (isQualifier(ann.annotationType())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "dependency", "declares", "a", "qualifier", "annotation"], "project": "spring-framework"}
{"id": 4152, "code": "\tpublic void setDatabaseProductName(String dbName) {\n\t\tif (SQLErrorCodeSQLExceptionTranslator.hasUserProvidedErrorCodesFile()) {\n\t\t\tthis.exceptionTranslator = new SQLErrorCodeSQLExceptionTranslator(dbName);\n\t\t}\n\t\telse {\n\t\t\tthis.exceptionTranslator = new SQLExceptionSubclassTranslator();\n\t\t}\n\t}", "summary_tokens": ["specify", "the", "database", "product", "name", "for", "the", "data", "source", "that", "this", "transaction", "manager", "uses"], "project": "spring-framework"}
{"id": 5254, "code": "\tpublic LoadTimeWeaver getLoadTimeWeaver() {\n\t\treturn this.loadTimeWeaver;\n\t}", "summary_tokens": ["return", "the", "spring", "load", "time", "weaver", "to", "use", "for", "class", "instrumentation", "according", "to", "the", "jpa", "class", "transformer", "contract"], "project": "spring-framework"}
{"id": 1761, "code": "\tpublic void rebind(final String name, final Object object) throws NamingException {\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Rebinding JNDI object with name [\" + name + \"]\");\n\t\t}\n\t\texecute(ctx -> {\n\t\t\tctx.rebind(name, object);\n\t\t\treturn null;\n\t\t});\n\t}", "summary_tokens": ["rebind", "the", "given", "object", "to", "the", "current", "jndi", "context", "using", "the", "given", "name"], "project": "spring-framework"}
{"id": 6503, "code": "\tpublic Object getSuspendedResources() {\n\t\treturn this.suspendedResources;\n\t}", "summary_tokens": ["return", "the", "holder", "for", "resources", "that", "have", "been", "suspended", "for", "this", "transaction", "if", "any"], "project": "spring-framework"}
{"id": 442, "code": "\tstatic BeanRegistrationAotContribution ofBeanRegistrationCodeFragmentsCustomizer(\n\t\t\tUnaryOperator<BeanRegistrationCodeFragments> beanRegistrationCodeFragmentsCustomizer) {\n\t\tAssert.notNull(beanRegistrationCodeFragmentsCustomizer,\n\t\t\t\t\"BeanRegistrationCodeFragmentsCustomizer must not be null\");\n\t\treturn new BeanRegistrationAotContribution() {\n\n\t\t\t@Override\n\t\t\tpublic BeanRegistrationCodeFragments customizeBeanRegistrationCodeFragments(\n\t\t\t\t\tGenerationContext generationContext, BeanRegistrationCodeFragments codeFragments) {\n\t\t\t\treturn beanRegistrationCodeFragmentsCustomizer.apply(codeFragments);\n\t\t\t}\n\n\t\t\t@Override\n\t\t\tpublic void applyTo(GenerationContext generationContext,\n\t\t\t\t\tBeanRegistrationCode beanRegistrationCode) {\n\t\t\t}\n\n\t\t};\n\t}", "summary_tokens": ["factory", "method", "that", "can", "be", "used", "to", "create", "a", "bean", "registration", "aot", "contribution", "that", "applies", "the", "given", "bean", "registration", "code", "fragments", "customizer"], "project": "spring-framework"}
{"id": 9599, "code": "\tprotected ClassLoader getBundleClassLoader() {\n\t\treturn this.bundleClassLoader;\n\t}", "summary_tokens": ["return", "the", "class", "loader", "to", "load", "resource", "bundles", "with"], "project": "spring-framework"}
{"id": 7248, "code": "\tpublic HttpStatusCode getStatusCode() {\n\t\treturn this.statusCode;\n\t}", "summary_tokens": ["return", "the", "http", "status", "code", "value"], "project": "spring-framework"}
{"id": 359, "code": "\tpublic String[] getPossibleMatches() {\n\t\treturn this.possibleMatches;\n\t}", "summary_tokens": ["return", "the", "calculated", "possible", "matches"], "project": "spring-framework"}
{"id": 3216, "code": "\tpublic void writeTo(OutputStream out) throws IOException {\n\t\tIterator<byte[]> it = this.buffers.iterator();\n\t\twhile (it.hasNext()) {\n\t\t\tbyte[] bytes = it.next();\n\t\t\tif (it.hasNext()) {\n\t\t\t\tout.write(bytes, 0, bytes.length);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tout.write(bytes, 0, this.index);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["write", "the", "buffers", "content", "to", "the", "given", "output", "stream"], "project": "spring-framework"}
{"id": 9095, "code": "\tprotected Object getFlashMapsMutex(HttpServletRequest request) {\n\t\treturn DEFAULT_FLASH_MAPS_MUTEX;\n\t}", "summary_tokens": ["obtain", "a", "mutex", "for", "modifying", "the", "flash", "map", "list", "as", "handled", "by", "retrieve", "flash", "maps", "and", "update", "flash", "maps", "p", "the", "default", "implementation", "returns", "a", "shared", "static", "mutex"], "project": "spring-framework"}
{"id": 2406, "code": "public int newInvokeDynamic(\n    final String name,\n    final String descriptor,\n    final Handle bootstrapMethodHandle,\n    final Object... bootstrapMethodArguments) {\n  return symbolTable.addConstantInvokeDynamic(\n          name, descriptor, bootstrapMethodHandle, bootstrapMethodArguments)\n      .index;\n}", "summary_tokens": ["adds", "an", "invokedynamic", "reference", "to", "the", "constant", "pool", "of", "the", "class", "being", "build"], "project": "spring-framework"}
{"id": 9530, "code": "\tpublic void setAttributes(Properties attributes) {\n\t\tCollectionUtils.mergePropertiesIntoMap(attributes, this.staticAttributes);\n\t}", "summary_tokens": ["set", "static", "attributes", "for", "this", "view", "from", "a", "java"], "project": "spring-framework"}
{"id": 9846, "code": "\tpublic void setSendTimeLimit(int sendTimeLimit) {\n\t\tthis.sendTimeLimit = sendTimeLimit;\n\t}", "summary_tokens": ["specify", "the", "send", "time", "limit", "milliseconds"], "project": "spring-framework"}
{"id": 8239, "code": "\tpublic Set<MediaType> getProducibleMediaTypes() {\n\t\tSet<MediaType> result = new LinkedHashSet<>();\n\t\tfor (ProduceMediaTypeExpression expression : this.expressions) {\n\t\t\tif (!expression.isNegated()) {\n\t\t\t\tresult.add(expression.getMediaType());\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["return", "the", "contained", "producible", "media", "types", "excluding", "negated", "expressions"], "project": "spring-framework"}
{"id": 8771, "code": "\tstatic BodyBuilder ok() {\n\t\treturn status(HttpStatus.OK);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "the", "status", "set", "to", "http", "status", "ok", "0", "ok"], "project": "spring-framework"}
{"id": 1151, "code": "\tprotected ResourceLoader getResourceLoader() {\n\t\treturn this.resourceLoader;\n\t}", "summary_tokens": ["return", "the", "spring", "resource", "loader", "to", "use", "for", "loading", "free", "marker", "template", "files"], "project": "spring-framework"}
{"id": 9746, "code": "\tpublic void setTextMessageSizeLimit(int messageSizeLimit) {\n\t}", "summary_tokens": ["this", "method", "is", "a", "no", "op", "for", "jetty"], "project": "spring-framework"}
{"id": 569, "code": "\tpublic String getDescription() {\n\t\treturn getName();\n\t}", "summary_tokens": ["delegates", "to", "get", "name"], "project": "spring-framework"}
{"id": 9333, "code": "\tprotected void writeOptionalAttributes(TagWriter tagWriter) throws JspException {\n\t\tsuper.writeOptionalAttributes(tagWriter);\n\n\t\twriteOptionalAttribute(tagWriter, ONFOCUS_ATTRIBUTE, getOnfocus());\n\t\twriteOptionalAttribute(tagWriter, ONBLUR_ATTRIBUTE, getOnblur());\n\t\twriteOptionalAttribute(tagWriter, ONCHANGE_ATTRIBUTE, getOnchange());\n\t\twriteOptionalAttribute(tagWriter, ACCESSKEY_ATTRIBUTE, getAccesskey());\n\t\tif (isDisabled()) {\n\t\t\ttagWriter.writeAttribute(DISABLED_ATTRIBUTE, \"disabled\");\n\t\t}\n\t\tif (isReadonly()) {\n\t\t\twriteOptionalAttribute(tagWriter, READONLY_ATTRIBUTE, \"readonly\");\n\t\t}\n\t}", "summary_tokens": ["adds", "input", "specific", "optional", "attributes", "as", "defined", "by", "this", "base", "class"], "project": "spring-framework"}
{"id": 455, "code": "\tprivate T getEarlySingletonInstance() throws Exception {\n\t\tClass<?>[] ifcs = getEarlySingletonInterfaces();\n\t\tif (ifcs == null) {\n\t\t\tthrow new FactoryBeanNotInitializedException(\n\t\t\t\t\tgetClass().getName() + \" does not support circular references\");\n\t\t}\n\t\tif (this.earlySingletonInstance == null) {\n\t\t\tthis.earlySingletonInstance = (T) Proxy.newProxyInstance(\n\t\t\t\t\tthis.beanClassLoader, ifcs, new EarlySingletonInvocationHandler());\n\t\t}\n\t\treturn this.earlySingletonInstance;\n\t}", "summary_tokens": ["determine", "an", "early", "singleton", "instance", "exposed", "in", "case", "of", "a", "circular", "reference"], "project": "spring-framework"}
{"id": 3212, "code": "\tpublic byte[] toByteArrayUnsafe() {\n\t\tint totalSize = size();\n\t\tif (totalSize == 0) {\n\t\t\treturn new byte[0];\n\t\t}\n\t\tresize(totalSize);\n\t\treturn this.buffers.getFirst();\n\t}", "summary_tokens": ["convert", "the", "stream", "s", "data", "to", "a", "byte", "array", "and", "return", "the", "byte", "array"], "project": "spring-framework"}
{"id": 4998, "code": "\tpublic String[] getAcceptVersion() {\n\t\tString value = getFirst(ACCEPT_VERSION);\n\t\treturn value != null ? StringUtils.commaDelimitedListToStringArray(value) : null;\n\t}", "summary_tokens": ["get", "the", "accept", "version", "header"], "project": "spring-framework"}
{"id": 8553, "code": "\tpublic boolean wasCleared() {\n\t\treturn (this.cleared && isEmpty());\n\t}", "summary_tokens": ["return", "whether", "this", "model", "and", "view", "object", "is", "empty", "as", "a", "result", "of", "a", "call", "to", "clear", "i"], "project": "spring-framework"}
{"id": 6621, "code": "\tpublic List<String> getOrEmpty(Object headerName) {\n\t\tList<String> values = get(headerName);\n\t\treturn (values != null ? values : Collections.emptyList());\n\t}", "summary_tokens": ["get", "the", "list", "of", "header", "values", "for", "the", "given", "header", "name", "if", "any"], "project": "spring-framework"}
{"id": 9526, "code": "\tpublic String getContentType() {\n\t\treturn this.contentType;\n\t}", "summary_tokens": ["return", "the", "content", "type", "for", "this", "view"], "project": "spring-framework"}
{"id": 5398, "code": "\tprotected Map<String, Object> createColumnMap(int columnCount) {\n\t\treturn new LinkedCaseInsensitiveMap<>(columnCount);\n\t}", "summary_tokens": ["create", "a", "map", "instance", "to", "be", "used", "as", "column", "map"], "project": "spring-framework"}
{"id": 8211, "code": "\tprotected MediaType selectMediaType(\n\t\t\tServerWebExchange exchange, Supplier<List<MediaType>> producibleTypesSupplier,\n\t\t\tList<MediaType> acceptableTypes) {\n\n\t\tMediaType contentType = exchange.getResponse().getHeaders().getContentType();\n\t\tif (contentType != null && contentType.isConcrete()) {\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(exchange.getLogPrefix() + \"Found 'Content-Type:\" + contentType + \"' in response\");\n\t\t\t}\n\t\t\treturn contentType;\n\t\t}\n\n\t\tList<MediaType> producibleTypes = getProducibleTypes(exchange, producibleTypesSupplier);\n\n\t\tSet<MediaType> compatibleMediaTypes = new LinkedHashSet<>();\n\t\tfor (MediaType acceptable : acceptableTypes) {\n\t\t\tfor (MediaType producible : producibleTypes) {\n\t\t\t\tif (acceptable.isCompatibleWith(producible)) {\n\t\t\t\t\tcompatibleMediaTypes.add(selectMoreSpecificMediaType(acceptable, producible));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tList<MediaType> result = new ArrayList<>(compatibleMediaTypes);\n\t\tMimeTypeUtils.sortBySpecificity(result);\n\n\t\tMediaType selected = null;\n\t\tfor (MediaType mediaType : result) {\n\t\t\tif (mediaType.isConcrete()) {\n\t\t\t\tselected = mediaType;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\telse if (mediaType.isPresentIn(ALL_APPLICATION_MEDIA_TYPES)) {\n\t\t\t\tselected = MediaType.APPLICATION_OCTET_STREAM;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif (selected != null) {\n\t\t\tselected = selected.removeQualityValue();\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(exchange.getLogPrefix() + \"Using '\" + selected + \"' given \" + acceptableTypes +\n\t\t\t\t\t\t\" and supported \" + producibleTypes);\n\t\t\t}\n\t\t}\n\t\telse if (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(exchange.getLogPrefix() +\n\t\t\t\t\t\"No match for \" + acceptableTypes + \", supported: \" + producibleTypes);\n\t\t}\n\n\t\treturn selected;\n\t}", "summary_tokens": ["variant", "of", "select", "media", "type", "server", "web", "exchange", "supplier", "with", "a", "given", "list", "of", "requested", "acceptable", "media", "types"], "project": "spring-framework"}
{"id": 4517, "code": "\tprotected Object invokeListenerMethod(String methodName, Object[] arguments) throws JMSException {\n\t\ttry {\n\t\t\tMethodInvoker methodInvoker = new MethodInvoker();\n\t\t\tmethodInvoker.setTargetObject(getDelegate());\n\t\t\tmethodInvoker.setTargetMethod(methodName);\n\t\t\tmethodInvoker.setArguments(arguments);\n\t\t\tmethodInvoker.prepare();\n\t\t\treturn methodInvoker.invoke();\n\t\t}\n\t\tcatch (InvocationTargetException ex) {\n\t\t\tThrowable targetEx = ex.getTargetException();\n\t\t\tif (targetEx instanceof JMSException) {\n\t\t\t\tthrow (JMSException) targetEx;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new ListenerExecutionFailedException(\n\t\t\t\t\t\t\"Listener method '\" + methodName + \"' threw exception\", targetEx);\n\t\t\t}\n\t\t}\n\t\tcatch (Throwable ex) {\n\t\t\tthrow new ListenerExecutionFailedException(\"Failed to invoke target method '\" + methodName +\n\t\t\t\t\t\"' with arguments \" + ObjectUtils.nullSafeToString(arguments), ex);\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "specified", "listener", "method"], "project": "spring-framework"}
{"id": 4099, "code": "\tprotected final void compileInternal() {\n\t\tif (isSqlReadyForUse()) {\n\t\t\tthis.callString = resolveSql();\n\t\t}\n\t\telse {\n\t\t\tStringBuilder callString = new StringBuilder(32);\n\t\t\tList<SqlParameter> parameters = getDeclaredParameters();\n\t\t\tint parameterCount = 0;\n\t\t\tif (isFunction()) {\n\t\t\t\tcallString.append(\"{? = call \").append(resolveSql()).append('(');\n\t\t\t\tparameterCount = -1;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tcallString.append(\"{call \").append(resolveSql()).append('(');\n\t\t\t}\n\t\t\tfor (SqlParameter parameter : parameters) {\n\t\t\t\tif (!parameter.isResultsParameter()) {\n\t\t\t\t\tif (parameterCount > 0) {\n\t\t\t\t\t\tcallString.append(\", \");\n\t\t\t\t\t}\n\t\t\t\t\tif (parameterCount >= 0) {\n\t\t\t\t\t\tcallString.append('?');\n\t\t\t\t\t}\n\t\t\t\t\tparameterCount++;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcallString.append(\")}\");\n\t\t\tthis.callString = callString.toString();\n\t\t}\n\t\tif (logger.isDebugEnabled()) {\n\t\t\tlogger.debug(\"Compiled stored procedure. Call string is [\" + this.callString + \"]\");\n\t\t}\n\n\t\tthis.callableStatementFactory = new CallableStatementCreatorFactory(this.callString, getDeclaredParameters());\n\t\tthis.callableStatementFactory.setResultSetType(getResultSetType());\n\t\tthis.callableStatementFactory.setUpdatableResults(isUpdatableResults());\n\n\t\tonCompileInternal();\n\t}\n\n\t\n\tprotected void onCompileInternal() {\n\t}\n\n\t\n\t@Nullable\n\tpublic String getCallString() {\n\t\treturn this.callString;\n\t}\n\n\t\n\tprotected CallableStatementCreator newCallableStatementCreator(@Nullable Map<String, ?> inParams) {\n\t\tAssert.state(this.callableStatementFactory != null, \"No CallableStatementFactory available\");\n\t\treturn this.callableStatementFactory.newCallableStatementCreator(inParams);\n\t}\n\n\t\n\tprotected CallableStatementCreator newCallableStatementCreator(ParameterMapper inParamMapper) {\n\t\tAssert.state(this.callableStatementFactory != null, \"No CallableStatementFactory available\");\n\t\treturn this.callableStatementFactory.newCallableStatementCreator(inParamMapper);\n\t}\n\n}", "summary_tokens": ["overridden", "method", "to", "configure", "the", "callable", "statement", "creator", "factory", "based", "on", "our", "declared", "parameters"], "project": "spring-framework"}
{"id": 8383, "code": "\tpublic void setApplicationContext(@Nullable ApplicationContext applicationContext) {\n\t\tthis.applicationContext = applicationContext;\n\t}", "summary_tokens": ["accept", "the", "containing", "application", "context", "if", "any"], "project": "spring-framework"}
{"id": 3412, "code": "\tpublic void setBindings(Map<String, String> bindings) {\n\t\tbindings.forEach(this::bindNamespaceUri);\n\t}", "summary_tokens": ["set", "the", "bindings", "for", "this", "namespace", "context"], "project": "spring-framework"}
{"id": 3791, "code": "\tpublic boolean isNullable() {\n\t\treturn this.nullable;\n\t}", "summary_tokens": ["get", "whether", "the", "parameter", "column", "is", "nullable"], "project": "spring-framework"}
{"id": 353, "code": "\tprotected Class<?> guessPropertyTypeFromEditors(String propertyName) {\n\t\tif (this.customEditorsForPath != null) {\n\t\t\tCustomEditorHolder editorHolder = this.customEditorsForPath.get(propertyName);\n\t\t\tif (editorHolder == null) {\n\t\t\t\tList<String> strippedPaths = new ArrayList<>();\n\t\t\t\taddStrippedPropertyPaths(strippedPaths, \"\", propertyName);\n\t\t\t\tfor (Iterator<String> it = strippedPaths.iterator(); it.hasNext() && editorHolder == null;) {\n\t\t\t\t\tString strippedName = it.next();\n\t\t\t\t\teditorHolder = this.customEditorsForPath.get(strippedName);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (editorHolder != null) {\n\t\t\t\treturn editorHolder.getRegisteredType();\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["guess", "the", "property", "type", "of", "the", "specified", "property", "from", "the", "registered", "custom", "editors", "provided", "that", "they", "were", "registered", "for", "a", "specific", "type"], "project": "spring-framework"}
{"id": 6126, "code": "\tpublic ResultMatcher nodeCount(int expectedCount) {\n\t\treturn result -> {\n\t\t\tMockHttpServletResponse response = result.getResponse();\n\t\t\tthis.xpathHelper.assertNodeCount(response.getContentAsByteArray(), getDefinedEncoding(response), expectedCount);\n\t\t};\n\t}", "summary_tokens": ["evaluate", "the", "xpath", "and", "assert", "the", "number", "of", "nodes", "found"], "project": "spring-framework"}
{"id": 8730, "code": "\tdefault void extendHandlerExceptionResolvers(List<HandlerExceptionResolver> resolvers) {\n\t}", "summary_tokens": ["extending", "or", "modify", "the", "list", "of", "exception", "resolvers", "configured", "by", "default"], "project": "spring-framework"}
{"id": 783, "code": "\tpublic int getAutowireMode() {\n\t\treturn this.autowireMode;\n\t}", "summary_tokens": ["return", "one", "of", "the", "constants", "autowire", "by", "name", "autowire", "by", "type", "if", "autowiring", "is", "indicated"], "project": "spring-framework"}
{"id": 8252, "code": "\tpublic RequestMethodsRequestCondition combine(RequestMethodsRequestCondition other) {\n\t\tif (isEmpty() && other.isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\telse if (other.isEmpty()) {\n\t\t\treturn this;\n\t\t}\n\t\telse if (isEmpty()) {\n\t\t\treturn other;\n\t\t}\n\t\tSet<RequestMethod> set = new LinkedHashSet<>(this.methods);\n\t\tset.addAll(other.methods);\n\t\treturn new RequestMethodsRequestCondition(set);\n\t}", "summary_tokens": ["returns", "a", "new", "instance", "with", "a", "union", "of", "the", "http", "request", "methods", "from", "this", "and", "the", "other", "instance"], "project": "spring-framework"}
{"id": 3491, "code": "\tpublic static short toShort(TypeConverter typeConverter, TypedValue typedValue) {\n\t\treturn convertValue(typeConverter, typedValue, Short.class);\n\t}", "summary_tokens": ["attempt", "to", "convert", "a", "typed", "value", "to", "a", "short", "using", "the", "supplied", "type", "converter"], "project": "spring-framework"}
{"id": 5307, "code": "\tpublic void setProcessExternalEntities(boolean processExternalEntities) {\n\t\tthis.processExternalEntities = processExternalEntities;\n\t\tif (processExternalEntities) {\n\t\t\tthis.supportDtd = true;\n\t\t}\n\t}", "summary_tokens": ["indicate", "whether", "external", "xml", "entities", "are", "processed", "when", "unmarshalling"], "project": "spring-framework"}
{"id": 7775, "code": "\tprotected Cookie createCookie(String cookieValue) {\n\t\tCookie cookie = new Cookie(getCookieName(), cookieValue);\n\t\tif (getCookieDomain() != null) {\n\t\t\tcookie.setDomain(getCookieDomain());\n\t\t}\n\t\tcookie.setPath(getCookiePath());\n\t\treturn cookie;\n\t}", "summary_tokens": ["create", "a", "cookie", "with", "the", "given", "value", "using", "the", "cookie", "descriptor", "settings", "of", "this", "generator", "except", "for", "cookie", "max", "age"], "project": "spring-framework"}
{"id": 4856, "code": "\tpublic void setPathMatcher(PathMatcher pathMatcher) {\n\t\tAssert.notNull(pathMatcher, \"PathMatcher must not be null\");\n\t\tthis.pathMatcher = pathMatcher;\n\t\tthis.slashPathSeparator = this.pathMatcher.combine(\"a\", \"a\").equals(\"a/a\");\n\t}", "summary_tokens": ["set", "the", "path", "matcher", "implementation", "to", "use", "for", "matching", "destinations", "against", "configured", "destination", "patterns"], "project": "spring-framework"}
{"id": 9595, "code": "\tprotected HttpStatusCode getHttp11StatusCode(\n\t\t\tHttpServletRequest request, HttpServletResponse response, String targetUrl) {\n\n\t\tif (this.statusCode != null) {\n\t\t\treturn this.statusCode;\n\t\t}\n\t\tHttpStatusCode attributeStatusCode = (HttpStatusCode) request.getAttribute(View.RESPONSE_STATUS_ATTRIBUTE);\n\t\tif (attributeStatusCode != null) {\n\t\t\treturn attributeStatusCode;\n\t\t}\n\t\treturn HttpStatus.SEE_OTHER;\n\t}", "summary_tokens": ["determines", "the", "status", "code", "to", "use", "for", "http", "0"], "project": "spring-framework"}
{"id": 8540, "code": "\tpublic void setView(@Nullable View view) {\n\t\tthis.view = view;\n\t}", "summary_tokens": ["set", "a", "view", "object", "for", "this", "model", "and", "view"], "project": "spring-framework"}
{"id": 8914, "code": "\tpublic Set<MediaType> getProducibleMediaTypes() {\n\t\tSet<MediaType> result = new LinkedHashSet<>();\n\t\tfor (ProduceMediaTypeExpression expression : this.expressions) {\n\t\t\tif (!expression.isNegated()) {\n\t\t\t\tresult.add(expression.getMediaType());\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["return", "the", "contained", "producible", "media", "types", "excluding", "negated", "expressions"], "project": "spring-framework"}
{"id": 4786, "code": "\tpublic static DataBuffer retainDataAndReleasePayload(Payload payload, DataBufferFactory bufferFactory) {\n\t\ttry {\n\t\t\tif (bufferFactory instanceof NettyDataBufferFactory) {\n\t\t\t\tByteBuf byteBuf = payload.sliceData().retain();\n\t\t\t\treturn ((NettyDataBufferFactory) bufferFactory).wrap(byteBuf);\n\t\t\t}\n\t\t\telse {\n\t\t\t\treturn bufferFactory.wrap(payload.getData());\n\t\t\t}\n\t\t}\n\t\tfinally {\n\t\t\tif (payload.refCnt() > 0) {\n\t\t\t\tpayload.release();\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["use", "this", "method", "to", "slice", "retain", "and", "wrap", "the", "data", "portion", "of", "the", "payload", "and", "also", "to", "release", "the", "payload"], "project": "spring-framework"}
{"id": 2803, "code": "\tstatic MergedAnnotations from(Object source, Annotation[] annotations,\n\t\t\tRepeatableContainers repeatableContainers, AnnotationFilter annotationFilter) {\n\n\t\tAssert.notNull(repeatableContainers, \"RepeatableContainers must not be null\");\n\t\tAssert.notNull(annotationFilter, \"AnnotationFilter must not be null\");\n\t\treturn TypeMappedAnnotations.from(source, annotations, repeatableContainers, annotationFilter);\n\t}", "summary_tokens": ["create", "a", "new", "merged", "annotations", "instance", "from", "the", "specified", "annotations"], "project": "spring-framework"}
{"id": 313, "code": "\tdefault Object getSource() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "configuration", "source", "object", "for", "this", "metadata", "element", "may", "be", "null"], "project": "spring-framework"}
{"id": 7018, "code": "\tprivate KSerializer<Object> serializer(Type type) {\n\t\tKSerializer<Object> serializer = serializerCache.get(type);\n\t\tif (serializer == null) {\n\t\t\tserializer = SerializersKt.serializerOrNull(type);\n\t\t\tif (serializer == null || hasPolymorphism(serializer.getDescriptor(), new HashSet<>())) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t\tserializerCache.put(type, serializer);\n\t\t}\n\t\treturn serializer;\n\t}", "summary_tokens": ["tries", "to", "find", "a", "serializer", "that", "can", "marshall", "or", "unmarshall", "instances", "of", "the", "given", "type", "using", "kotlinx"], "project": "spring-framework"}
{"id": 1876, "code": "\tpublic Duration getInitialDelayDuration() {\n\t\treturn this.initialDelay;\n\t}", "summary_tokens": ["return", "the", "initial", "delay", "before", "first", "execution", "of", "the", "task"], "project": "spring-framework"}
{"id": 9915, "code": "\tpublic int getHttpMessageCacheSize() {\n\t\treturn this.httpMessageCacheSize;\n\t}", "summary_tokens": ["return", "the", "size", "of", "the", "http", "message", "cache"], "project": "spring-framework"}
{"id": 3022, "code": "\tpublic static SpringFactoriesLoader forDefaultResourceLocation(@Nullable ClassLoader classLoader) {\n\t\treturn forResourceLocation(FACTORIES_RESOURCE_LOCATION, classLoader);\n\t}", "summary_tokens": ["create", "a", "spring", "factories", "loader", "instance", "that", "will", "load", "and", "instantiate", "the", "factory", "implementations", "from", "factories", "resource", "location", "using", "the", "given", "class", "loader"], "project": "spring-framework"}
{"id": 3782, "code": "\tpublic String createInsertString(String... generatedKeyNames) {\n\t\tSet<String> keys = new LinkedHashSet<>(generatedKeyNames.length);\n\t\tfor (String key : generatedKeyNames) {\n\t\t\tkeys.add(key.toUpperCase());\n\t\t}\n\t\tStringBuilder insertStatement = new StringBuilder();\n\t\tinsertStatement.append(\"INSERT INTO \");\n\t\tif (getSchemaName() != null) {\n\t\t\tinsertStatement.append(getSchemaName());\n\t\t\tinsertStatement.append('.');\n\t\t}\n\t\tinsertStatement.append(getTableName());\n\t\tinsertStatement.append(\" (\");\n\t\tint columnCount = 0;\n\t\tfor (String columnName : getTableColumns()) {\n\t\t\tif (!keys.contains(columnName.toUpperCase())) {\n\t\t\t\tcolumnCount++;\n\t\t\t\tif (columnCount > 1) {\n\t\t\t\t\tinsertStatement.append(\", \");\n\t\t\t\t}\n\t\t\t\tinsertStatement.append(columnName);\n\t\t\t}\n\t\t}\n\t\tinsertStatement.append(\") VALUES(\");\n\t\tif (columnCount < 1) {\n\t\t\tif (this.generatedKeyColumnsUsed) {\n\t\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\t\tlogger.debug(\"Unable to locate non-key columns for table '\" +\n\t\t\t\t\t\t\tgetTableName() + \"' so an empty insert statement is generated\");\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tString message = \"Unable to locate columns for table '\" + getTableName()\n\t\t\t\t\t\t+ \"' so an insert statement can't be generated.\";\n\t\t\t\tif (isAccessTableColumnMetaData()) {\n\t\t\t\t\tmessage += \" Consider specifying explicit column names -- for example, via SimpleJdbcInsert#usingColumns().\";\n\t\t\t\t}\n\t\t\t\tthrow new InvalidDataAccessApiUsageException(message);\n\t\t\t}\n\t\t}\n\t\tString params = String.join(\", \", Collections.nCopies(columnCount, \"?\"));\n\t\tinsertStatement.append(params);\n\t\tinsertStatement.append(')');\n\t\treturn insertStatement.toString();\n\t}", "summary_tokens": ["build", "the", "insert", "string", "based", "on", "configuration", "and", "meta", "data", "information"], "project": "spring-framework"}
{"id": 9378, "code": "\tpublic void setTarget(String target) {\n\t\tthis.target = target;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "target", "attribute"], "project": "spring-framework"}
{"id": 9653, "code": "\tprotected int getViewerPreferences() {\n\t\treturn PdfWriter.ALLOW_PRINTING | PdfWriter.PageLayoutSinglePage;\n\t}", "summary_tokens": ["return", "the", "viewer", "preferences", "for", "the", "pdf", "file"], "project": "spring-framework"}
{"id": 6285, "code": "\tpublic void setAsText(String text) throws IllegalArgumentException {\n\t\tif (StringUtils.hasLength(text)) {\n\t\t\t\n\t\t\tString[] tokens = StringUtils.commaDelimitedListToStringArray(text);\n\t\t\tRuleBasedTransactionAttribute attr = new RuleBasedTransactionAttribute();\n\t\t\tfor (String token : tokens) {\n\t\t\t\t\n\t\t\t\tString trimmedToken = token.strip();\n\t\t\t\t\n\t\t\t\tif (StringUtils.containsWhitespace(trimmedToken)) {\n\t\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\t\"Transaction attribute token contains illegal whitespace: [\" + trimmedToken + \"]\");\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (trimmedToken.startsWith(RuleBasedTransactionAttribute.PREFIX_PROPAGATION)) {\n\t\t\t\t\tattr.setPropagationBehaviorName(trimmedToken);\n\t\t\t\t}\n\t\t\t\telse if (trimmedToken.startsWith(RuleBasedTransactionAttribute.PREFIX_ISOLATION)) {\n\t\t\t\t\tattr.setIsolationLevelName(trimmedToken);\n\t\t\t\t}\n\t\t\t\telse if (trimmedToken.startsWith(RuleBasedTransactionAttribute.PREFIX_TIMEOUT)) {\n\t\t\t\t\tString value = trimmedToken.substring(DefaultTransactionAttribute.PREFIX_TIMEOUT.length());\n\t\t\t\t\tattr.setTimeoutString(value);\n\t\t\t\t}\n\t\t\t\telse if (trimmedToken.equals(RuleBasedTransactionAttribute.READ_ONLY_MARKER)) {\n\t\t\t\t\tattr.setReadOnly(true);\n\t\t\t\t}\n\t\t\t\telse if (trimmedToken.startsWith(RuleBasedTransactionAttribute.PREFIX_COMMIT_RULE)) {\n\t\t\t\t\tattr.getRollbackRules().add(new NoRollbackRuleAttribute(trimmedToken.substring(1)));\n\t\t\t\t}\n\t\t\t\telse if (trimmedToken.startsWith(RuleBasedTransactionAttribute.PREFIX_ROLLBACK_RULE)) {\n\t\t\t\t\tattr.getRollbackRules().add(new RollbackRuleAttribute(trimmedToken.substring(1)));\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tthrow new IllegalArgumentException(\"Invalid transaction attribute token: [\" + trimmedToken + \"]\");\n\t\t\t\t}\n\t\t\t}\n\t\t\tattr.resolveAttributeStrings(null);  \n\t\t\tsetValue(attr);\n\t\t}\n\t\telse {\n\t\t\tsetValue(null);\n\t\t}\n\t}", "summary_tokens": ["format", "is", "propagation", "name", "isolation", "name", "read", "only", "timeout", "nnnn", "exception", "0", "exception", "0"], "project": "spring-framework"}
{"id": 7238, "code": "\tpublic HttpStatusCode getStatusCode() {\n\t\treturn this.statusCode;\n\t}", "summary_tokens": ["return", "the", "http", "status", "code"], "project": "spring-framework"}
{"id": 6673, "code": "\tpublic void setIfMatch(List<String> ifMatchList) {\n\t\tset(IF_MATCH, toCommaDelimitedString(ifMatchList));\n\t}", "summary_tokens": ["set", "the", "new", "value", "of", "the", "if", "match", "header"], "project": "spring-framework"}
{"id": 647, "code": "\tpublic BeanDefinitionBuilder setSynthetic(boolean synthetic) {\n\t\tthis.beanDefinition.setSynthetic(synthetic);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "whether", "this", "bean", "is", "synthetic", "that", "is", "not", "defined", "by", "the", "application", "itself"], "project": "spring-framework"}
{"id": 1346, "code": "\tprotected Properties getCommonMessages() {\n\t\treturn this.commonMessages;\n\t}", "summary_tokens": ["return", "a", "properties", "object", "defining", "locale", "independent", "common", "messages", "if", "any"], "project": "spring-framework"}
{"id": 3988, "code": "\tprotected void prepareConnection(Connection con) throws SQLException {\n\t\tBoolean autoCommit = getAutoCommitValue();\n\t\tif (autoCommit != null && con.getAutoCommit() != autoCommit) {\n\t\t\tcon.setAutoCommit(autoCommit);\n\t\t}\n\t}", "summary_tokens": ["prepare", "the", "given", "connection", "before", "it", "is", "exposed"], "project": "spring-framework"}
{"id": 5015, "code": "\tpublic String getAck() {\n\t\treturn getFirst(ACK);\n\t}", "summary_tokens": ["get", "the", "ack", "header"], "project": "spring-framework"}
{"id": 1856, "code": "\tpublic int getCorePoolSize() {\n\t\tsynchronized (this.poolSizeMonitor) {\n\t\t\treturn this.corePoolSize;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "thread", "pool", "executor", "s", "core", "pool", "size"], "project": "spring-framework"}
{"id": 5172, "code": "\tpublic void setBeanFactory(BeanFactory beanFactory) {\n\t\tif (beanFactory instanceof ConfigurableListableBeanFactory) {\n\t\t\tthis.beanFactory = (ConfigurableListableBeanFactory) beanFactory;\n\t\t}\n\t}", "summary_tokens": ["accept", "the", "containing", "bean", "factory", "registering", "corresponding", "hibernate", "org"], "project": "spring-framework"}
{"id": 277, "code": "\tpublic void releaseTarget(Object target) {\n\t\tdestroyPrototypeInstance(target);\n\t}", "summary_tokens": ["destroy", "the", "given", "independent", "instance"], "project": "spring-framework"}
{"id": 270, "code": "\tpublic void releaseTarget(Object target) throws Exception {\n\t\tif (this.pool != null) {\n\t\t\tthis.pool.returnObject(target);\n\t\t}\n\t}", "summary_tokens": ["returns", "the", "specified", "object", "to", "the", "underlying", "object", "pool"], "project": "spring-framework"}
{"id": 4088, "code": "\tpublic boolean isCompiled() {\n\t\treturn this.compiled;\n\t}", "summary_tokens": ["is", "this", "operation", "compiled", "compilation", "as", "in", "jdo", "means", "that", "the", "operation", "is", "fully", "configured", "and", "ready", "to", "use"], "project": "spring-framework"}
{"id": 9491, "code": "\tpublic static String getDisplayString(\n\t\t\t@Nullable Object value, @Nullable PropertyEditor propertyEditor, boolean htmlEscape) {\n\n\t\tif (propertyEditor != null && !(value instanceof String)) {\n\t\t\ttry {\n\t\t\t\tpropertyEditor.setValue(value);\n\t\t\t\tString text = propertyEditor.getAsText();\n\t\t\t\tif (text != null) {\n\t\t\t\t\treturn getDisplayString(text, htmlEscape);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\t\treturn getDisplayString(value, htmlEscape);\n\t}", "summary_tokens": ["build", "the", "display", "value", "of", "the", "supplied", "object", "html", "escaped", "as", "required"], "project": "spring-framework"}
{"id": 456, "code": "\tprivate T getSingletonInstance() throws IllegalStateException {\n\t\tAssert.state(this.initialized, \"Singleton instance not initialized yet\");\n\t\treturn this.singletonInstance;\n\t}", "summary_tokens": ["expose", "the", "singleton", "instance", "for", "access", "through", "the", "early", "singleton", "proxy"], "project": "spring-framework"}
{"id": 7758, "code": "\tpublic InputStream getContentInputStream() {\n\t\treturn this.content.getInputStream();\n\t}", "summary_tokens": ["return", "an", "input", "stream", "to", "the", "cached", "content"], "project": "spring-framework"}
{"id": 1707, "code": "\tprotected void onUnregister(ObjectName objectName) {\n\t}", "summary_tokens": ["called", "when", "an", "mbean", "is", "unregistered", "under", "the", "given", "object", "name"], "project": "spring-framework"}
{"id": 6303, "code": "\tpublic void setCacheUserTransaction(boolean cacheUserTransaction) {\n\t\tthis.cacheUserTransaction = cacheUserTransaction;\n\t}", "summary_tokens": ["set", "whether", "to", "cache", "the", "jta", "user", "transaction", "object", "fetched", "from", "jndi"], "project": "spring-framework"}
{"id": 1592, "code": "\tprotected ModelMBeanOperationInfo createModelMBeanOperationInfo(Method method, String name, String beanKey) {\n\t\tMBeanParameterInfo[] params = getOperationParameters(method, beanKey);\n\t\tif (params.length == 0) {\n\t\t\treturn new ModelMBeanOperationInfo(getOperationDescription(method, beanKey), method);\n\t\t}\n\t\telse {\n\t\t\treturn new ModelMBeanOperationInfo(method.getName(),\n\t\t\t\tgetOperationDescription(method, beanKey),\n\t\t\t\tgetOperationParameters(method, beanKey),\n\t\t\t\tmethod.getReturnType().getName(),\n\t\t\t\tMBeanOperationInfo.UNKNOWN);\n\t\t}\n\t}", "summary_tokens": ["creates", "an", "instance", "of", "model", "mbean", "operation", "info", "for", "the", "given", "method"], "project": "spring-framework"}
{"id": 6825, "code": "\tdefault Map<String, Object> getEncodeHints(ResolvableType actualType, ResolvableType elementType,\n\t\t\t@Nullable MediaType mediaType, ServerHttpRequest request, ServerHttpResponse response) {\n\n\t\treturn Hints.none();\n\t}", "summary_tokens": ["get", "decoding", "hints", "based", "on", "the", "server", "request", "or", "annotations", "on", "the", "target", "controller", "method", "parameter"], "project": "spring-framework"}
{"id": 9687, "code": "\tpublic void setTemplateEngine(MarkupTemplateEngine templateEngine) {\n\t\tthis.templateEngine = templateEngine;\n\t}", "summary_tokens": ["set", "a", "pre", "configured", "markup", "template", "engine", "to", "use", "for", "the", "groovy", "markup", "template", "web", "configuration"], "project": "spring-framework"}
{"id": 8499, "code": "\tprivate void initHandlerExceptionResolvers(ApplicationContext context) {\n\t\tthis.handlerExceptionResolvers = null;\n\n\t\tif (this.detectAllHandlerExceptionResolvers) {\n\t\t\t\n\t\t\tMap<String, HandlerExceptionResolver> matchingBeans = BeanFactoryUtils\n\t\t\t\t\t.beansOfTypeIncludingAncestors(context, HandlerExceptionResolver.class, true, false);\n\t\t\tif (!matchingBeans.isEmpty()) {\n\t\t\t\tthis.handlerExceptionResolvers = new ArrayList<>(matchingBeans.values());\n\t\t\t\t\n\t\t\t\tAnnotationAwareOrderComparator.sort(this.handlerExceptionResolvers);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\tHandlerExceptionResolver her =\n\t\t\t\t\t\tcontext.getBean(HANDLER_EXCEPTION_RESOLVER_BEAN_NAME, HandlerExceptionResolver.class);\n\t\t\t\tthis.handlerExceptionResolvers = Collections.singletonList(her);\n\t\t\t}\n\t\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\n\t\t\n\t\t\n\t\tif (this.handlerExceptionResolvers == null) {\n\t\t\tthis.handlerExceptionResolvers = getDefaultStrategies(context, HandlerExceptionResolver.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"No HandlerExceptionResolvers declared in servlet '\" + getServletName() +\n\t\t\t\t\t\t\"': using default strategies from DispatcherServlet.properties\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "handler", "exception", "resolver", "used", "by", "this", "class"], "project": "spring-framework"}
{"id": 6208, "code": "\tpublic void setPhase(int phase) {\n\t\tthis.phase = phase;\n\t}", "summary_tokens": ["specify", "the", "phase", "in", "which", "this", "endpoint", "manager", "should", "be", "started", "and", "stopped"], "project": "spring-framework"}
{"id": 2955, "code": "\tprotected Resource getResourceByPath(String path) {\n\t\tif (path.startsWith(\"/\")) {\n\t\t\tpath = path.substring(1);\n\t\t}\n\t\treturn new FileSystemContextResource(path);\n\t}", "summary_tokens": ["resolve", "resource", "paths", "as", "file", "system", "paths"], "project": "spring-framework"}
{"id": 3161, "code": "\tpublic static boolean hasConstructor(Class<?> clazz, Class<?>... paramTypes) {\n\t\treturn (getConstructorIfAvailable(clazz, paramTypes) != null);\n\t}", "summary_tokens": ["determine", "whether", "the", "given", "class", "has", "a", "public", "constructor", "with", "the", "given", "signature"], "project": "spring-framework"}
{"id": 5232, "code": "\tprotected PersistenceUnitInfo determinePersistenceUnitInfo(PersistenceUnitManager persistenceUnitManager) {\n\t\tif (getPersistenceUnitName() != null) {\n\t\t\treturn persistenceUnitManager.obtainPersistenceUnitInfo(getPersistenceUnitName());\n\t\t}\n\t\telse {\n\t\t\treturn persistenceUnitManager.obtainDefaultPersistenceUnitInfo();\n\t\t}\n\t}", "summary_tokens": ["determine", "the", "persistence", "unit", "info", "to", "use", "for", "the", "entity", "manager", "factory", "created", "by", "this", "bean"], "project": "spring-framework"}
{"id": 9855, "code": "\tprotected WebSocketSession decorateSession(WebSocketSession session) {\n\t\treturn new ConcurrentWebSocketSessionDecorator(session, getSendTimeLimit(), getSendBufferSizeLimit());\n\t}", "summary_tokens": ["decorate", "the", "given", "web", "socket", "session", "if", "desired"], "project": "spring-framework"}
{"id": 23, "code": "\tpublic static boolean isBeforeAdvice(Advisor anAdvisor) {\n\t\tAspectJPrecedenceInformation precedenceInfo = getAspectJPrecedenceInformationFor(anAdvisor);\n\t\tif (precedenceInfo != null) {\n\t\t\treturn precedenceInfo.isBeforeAdvice();\n\t\t}\n\t\treturn (anAdvisor.getAdvice() instanceof BeforeAdvice);\n\t}", "summary_tokens": ["return", "true", "if", "the", "advisor", "is", "a", "form", "of", "before", "advice"], "project": "spring-framework"}
{"id": 1446, "code": "\tprotected Properties newProperties() {\n\t\treturn new Properties();\n\t}", "summary_tokens": ["template", "method", "for", "creating", "a", "plain", "new", "properties", "instance"], "project": "spring-framework"}
{"id": 6328, "code": "\tprotected JtaTransactionObject doGetJtaTransaction(UserTransaction ut) {\n\t\treturn new JtaTransactionObject(ut);\n\t}", "summary_tokens": ["get", "a", "jta", "transaction", "object", "for", "the", "given", "current", "user", "transaction"], "project": "spring-framework"}
{"id": 6289, "code": "\tpublic void setTransactionManager(PlatformTransactionManager transactionManager) {\n\t\tthis.transactionInterceptor.setTransactionManager(transactionManager);\n\t}", "summary_tokens": ["set", "the", "default", "transaction", "manager"], "project": "spring-framework"}
{"id": 5740, "code": "\tprotected final boolean isDefaultRollback(TestContext testContext) throws Exception {\n\t\tClass<?> testClass = testContext.getTestClass();\n\t\tRollback rollback = TestContextAnnotationUtils.findMergedAnnotation(testClass, Rollback.class);\n\t\tboolean rollbackPresent = (rollback != null);\n\n\t\tif (rollbackPresent) {\n\t\t\tboolean defaultRollback = rollback.value();\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(String.format(\"Retrieved default @Rollback(%s) for test class [%s].\",\n\t\t\t\t\t\tdefaultRollback, testClass.getName()));\n\t\t\t}\n\t\t\treturn defaultRollback;\n\t\t}\n\n\t\t\n\t\treturn true;\n\t}", "summary_tokens": ["determine", "whether", "to", "rollback", "transactions", "by", "default", "for", "the", "supplied", "test", "context", "test", "context"], "project": "spring-framework"}
{"id": 8274, "code": "\tpublic void setParameterNameDiscoverer(ParameterNameDiscoverer nameDiscoverer) {\n\t\tthis.delegate.setParameterNameDiscoverer(nameDiscoverer);\n\t}", "summary_tokens": ["set", "the", "parameter", "name", "discoverer", "for", "resolving", "parameter", "names", "when", "needed", "e"], "project": "spring-framework"}
{"id": 2691, "code": "\tpublic Number asNumber(String code) throws ConstantException {\n\t\tObject obj = asObject(code);\n\t\tif (!(obj instanceof Number)) {\n\t\t\tthrow new ConstantException(this.className, code, \"not a Number\");\n\t\t}\n\t\treturn (Number) obj;\n\t}", "summary_tokens": ["return", "a", "constant", "value", "cast", "to", "a", "number"], "project": "spring-framework"}
{"id": 4716, "code": "\tpublic Map<T, HandlerMethod> getHandlerMethods() {\n\t\treturn Collections.unmodifiableMap(this.handlerMethods);\n\t}", "summary_tokens": ["return", "a", "map", "with", "all", "handler", "methods", "and", "their", "mappings"], "project": "spring-framework"}
{"id": 9815, "code": "\tprotected Integer getSendTimeLimit() {\n\t\treturn this.sendTimeLimit;\n\t}", "summary_tokens": ["protected", "accessor", "for", "internal", "use"], "project": "spring-framework"}
{"id": 9703, "code": "\tpublic Function<String, String> getTemplateLoader() {\n\t\treturn this.templateLoader;\n\t}", "summary_tokens": ["return", "a", "function", "that", "takes", "a", "template", "path", "as", "input", "and", "returns", "the", "template", "content", "as", "a", "string"], "project": "spring-framework"}
{"id": 8907, "code": "\tpublic boolean isEmptyPathMapping() {\n\t\treturn this.patterns == EMPTY_PATH_PATTERN;\n\t}", "summary_tokens": ["whether", "the", "condition", "is", "the", "empty", "path", "mapping"], "project": "spring-framework"}
{"id": 9525, "code": "\tpublic void setContentType(@Nullable String contentType) {\n\t\tthis.contentType = contentType;\n\t}", "summary_tokens": ["set", "the", "content", "type", "for", "this", "view"], "project": "spring-framework"}
{"id": 7307, "code": "\tpublic void setTaskExecutor(AsyncTaskExecutor taskExecutor) {\n\t\tthis.taskExecutor = taskExecutor;\n\t}", "summary_tokens": ["configure", "an", "async", "task", "executor", "for", "use", "with", "concurrent", "processing", "via", "start", "callable", "processing", "callable", "object"], "project": "spring-framework"}
{"id": 7496, "code": "\tprotected Environment createEnvironment() {\n\t\treturn new StandardServletEnvironment();\n\t}", "summary_tokens": ["create", "and", "return", "a", "new", "standard", "servlet", "environment"], "project": "spring-framework"}
{"id": 3410, "code": "\tpublic Object getProperty(String name) throws SAXNotRecognizedException, SAXNotSupportedException {\n\t\tif (\"http://xml.org/sax/properties/lexical-handler\".equals(name)) {\n\t\t\treturn this.lexicalHandler;\n\t\t}\n\t\telse {\n\t\t\tthrow new SAXNotRecognizedException(name);\n\t\t}\n\t}", "summary_tokens": ["throws", "a", "saxnot", "recognized", "exception", "exception", "when", "the", "given", "property", "does", "not", "signify", "a", "lexical", "handler"], "project": "spring-framework"}
{"id": 2940, "code": "\tpublic boolean isWritable() {\n\t\treturn (this.file != null ? this.file.canWrite() && !this.file.isDirectory() :\n\t\t\t\tFiles.isWritable(this.filePath) && !Files.isDirectory(this.filePath));\n\t}", "summary_tokens": ["this", "implementation", "checks", "whether", "the", "underlying", "file", "is", "marked", "as", "writable", "and", "corresponds", "to", "an", "actual", "file", "with", "content", "not", "to", "a", "directory"], "project": "spring-framework"}
{"id": 1755, "code": "\tpublic <T> T execute(JndiCallback<T> contextCallback) throws NamingException {\n\t\tContext ctx = getContext();\n\t\ttry {\n\t\t\treturn contextCallback.doInContext(ctx);\n\t\t}\n\t\tfinally {\n\t\t\treleaseContext(ctx);\n\t\t}\n\t}", "summary_tokens": ["execute", "the", "given", "jndi", "context", "callback", "implementation"], "project": "spring-framework"}
{"id": 9859, "code": "\tpublic void setTaskScheduler(@Nullable TaskScheduler taskScheduler) {\n\t\tif (!isDefaultHeartbeatEnabled()) {\n\t\t\tsetDefaultHeartbeat(new long[] {10000, 10000});\n\t\t}\n\t\tsuper.setTaskScheduler(taskScheduler);\n\t}", "summary_tokens": ["p", "also", "automatically", "sets", "the", "set", "default", "heartbeat", "default", "heartbeat", "property", "to", "0", "0", "if", "it", "is", "currently", "set", "to", "0", "0"], "project": "spring-framework"}
{"id": 2375, "code": "private ConstantDynamic readConstantDynamic(\n    final int constantPoolEntryIndex, final char[] charBuffer) {\n  ConstantDynamic constantDynamic = constantDynamicValues[constantPoolEntryIndex];\n  if (constantDynamic != null) {\n    return constantDynamic;\n  }\n  int cpInfoOffset = cpInfoOffsets[constantPoolEntryIndex];\n  int nameAndTypeCpInfoOffset = cpInfoOffsets[readUnsignedShort(cpInfoOffset + 2)];\n  String name = readUTF8(nameAndTypeCpInfoOffset, charBuffer);\n  String descriptor = readUTF8(nameAndTypeCpInfoOffset + 2, charBuffer);\n  int bootstrapMethodOffset = bootstrapMethodOffsets[readUnsignedShort(cpInfoOffset)];\n  Handle handle = (Handle) readConst(readUnsignedShort(bootstrapMethodOffset), charBuffer);\n  Object[] bootstrapMethodArguments = new Object[readUnsignedShort(bootstrapMethodOffset + 2)];\n  bootstrapMethodOffset += 4;\n  for (int i = 0; i < bootstrapMethodArguments.length; i++) {\n    bootstrapMethodArguments[i] = readConst(readUnsignedShort(bootstrapMethodOffset), charBuffer);\n    bootstrapMethodOffset += 2;\n  }\n  return constantDynamicValues[constantPoolEntryIndex] =\n      new ConstantDynamic(name, descriptor, handle, bootstrapMethodArguments);\n}", "summary_tokens": ["reads", "a", "constant", "dynamic", "constant", "pool", "entry", "in", "class", "file", "buffer"], "project": "spring-framework"}
{"id": 3914, "code": "\tpublic void setUrl(@Nullable String url) {\n\t\tthis.url = (url != null ? url.trim() : null);\n\t}", "summary_tokens": ["set", "the", "jdbc", "url", "to", "use", "for", "connecting", "through", "the", "driver"], "project": "spring-framework"}
{"id": 6641, "code": "\tpublic long getAccessControlMaxAge() {\n\t\tString value = getFirst(ACCESS_CONTROL_MAX_AGE);\n\t\treturn (value != null ? Long.parseLong(value) : -1);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "access", "control", "max", "age", "response", "header"], "project": "spring-framework"}
{"id": 5325, "code": "\tpublic Object getContent() {\n\t\treturn this.content;\n\t}", "summary_tokens": ["return", "the", "object", "to", "be", "marshalled"], "project": "spring-framework"}
{"id": 5152, "code": "\tpublic void setMappingDirectoryLocations(Resource... mappingDirectoryLocations) {\n\t\tthis.mappingDirectoryLocations = mappingDirectoryLocations;\n\t}", "summary_tokens": ["set", "locations", "of", "directories", "that", "contain", "hibernate", "mapping", "resources", "like", "web", "inf", "mappings"], "project": "spring-framework"}
{"id": 2456, "code": "final void put(\n    final ByteVector code, final int sourceInsnBytecodeOffset, final boolean wideReference) {\n  if ((flags & FLAG_RESOLVED) == 0) {\n    if (wideReference) {\n      addForwardReference(sourceInsnBytecodeOffset, FORWARD_REFERENCE_TYPE_WIDE, code.length);\n      code.putInt(-1);\n    } else {\n      addForwardReference(sourceInsnBytecodeOffset, FORWARD_REFERENCE_TYPE_SHORT, code.length);\n      code.putShort(-1);\n    }\n  } else {\n    if (wideReference) {\n      code.putInt(bytecodeOffset - sourceInsnBytecodeOffset);\n    } else {\n      code.putShort(bytecodeOffset - sourceInsnBytecodeOffset);\n    }\n  }\n}", "summary_tokens": ["puts", "a", "reference", "to", "this", "label", "in", "the", "bytecode", "of", "a", "method"], "project": "spring-framework"}
{"id": 4328, "code": "\tpublic void setPubSubNoLocal(boolean pubSubNoLocal) {\n\t\tthis.pubSubNoLocal = pubSubNoLocal;\n\t}", "summary_tokens": ["set", "whether", "to", "inhibit", "the", "delivery", "of", "messages", "published", "by", "its", "own", "connection"], "project": "spring-framework"}
{"id": 3784, "code": "\tpublic boolean isGetGeneratedKeysSupported() {\n\t\treturn obtainMetaDataProvider().isGetGeneratedKeysSupported();\n\t}", "summary_tokens": ["does", "this", "database", "support", "the", "jdbc", "0"], "project": "spring-framework"}
{"id": 9263, "code": "\tprotected PropertyEditor getPropertyEditor() throws JspException {\n\t\treturn getBindStatus().getEditor();\n\t}", "summary_tokens": ["get", "the", "property", "editor", "if", "any", "in", "use", "for", "value", "bound", "to", "this", "tag"], "project": "spring-framework"}
{"id": 3833, "code": "\tpublic void setCatalogName(@Nullable String catalogName) {\n\t\tthis.callMetaDataContext.setCatalogName(catalogName);\n\t}", "summary_tokens": ["set", "the", "catalog", "name", "to", "use"], "project": "spring-framework"}
{"id": 3426, "code": "\tpublic static void enableIndenting(Transformer transformer, int indentAmount) {\n\t\tAssert.notNull(transformer, \"Transformer must not be null\");\n\t\tif (indentAmount < 0) {\n\t\t\tthrow new IllegalArgumentException(\"Invalid indent amount (must not be less than zero): \" + indentAmount);\n\t\t}\n\t\ttransformer.setOutputProperty(OutputKeys.INDENT, \"yes\");\n\t\ttry {\n\t\t\t\n\t\t\ttransformer.setOutputProperty(\"{http://xml.apache.org/xalan}indent-amount\", String.valueOf(indentAmount));\n\t\t}\n\t\tcatch (IllegalArgumentException ignored) {\n\t\t}\n\t}", "summary_tokens": ["enable", "indenting", "for", "the", "supplied", "javax"], "project": "spring-framework"}
{"id": 8360, "code": "\tpublic void setPropagateQuery(boolean propagateQuery) {\n\t\tthis.propagateQuery = propagateQuery;\n\t}", "summary_tokens": ["whether", "to", "append", "the", "query", "string", "of", "the", "current", "url", "to", "the", "redirect", "url", "true", "or", "not", "false", "the", "default"], "project": "spring-framework"}
{"id": 8425, "code": "\tpublic void setSharedEngine(@Nullable Boolean sharedEngine) {\n\t\tthis.sharedEngine = sharedEngine;\n\t}", "summary_tokens": ["when", "set", "to", "false", "a", "new", "script", "engine", "instance", "will", "be", "created", "for", "each", "request", "else", "the", "same", "instance", "will", "be", "reused"], "project": "spring-framework"}
{"id": 5200, "code": "\tpublic void preHandle(WebRequest request) throws DataAccessException {\n\t\tString key = getParticipateAttributeName();\n\t\tWebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request);\n\t\tif (asyncManager.hasConcurrentResult() && applySessionBindingInterceptor(asyncManager, key)) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (TransactionSynchronizationManager.hasResource(obtainSessionFactory())) {\n\t\t\t\n\t\t\tInteger count = (Integer) request.getAttribute(key, WebRequest.SCOPE_REQUEST);\n\t\t\tint newCount = (count != null ? count + 1 : 1);\n\t\t\trequest.setAttribute(getParticipateAttributeName(), newCount, WebRequest.SCOPE_REQUEST);\n\t\t}\n\t\telse {\n\t\t\tlogger.debug(\"Opening Hibernate Session in OpenSessionInViewInterceptor\");\n\t\t\tSession session = openSession();\n\t\t\tSessionHolder sessionHolder = new SessionHolder(session);\n\t\t\tTransactionSynchronizationManager.bindResource(obtainSessionFactory(), sessionHolder);\n\n\t\t\tAsyncRequestInterceptor asyncRequestInterceptor =\n\t\t\t\t\tnew AsyncRequestInterceptor(obtainSessionFactory(), sessionHolder);\n\t\t\tasyncManager.registerCallableInterceptor(key, asyncRequestInterceptor);\n\t\t\tasyncManager.registerDeferredResultInterceptor(key, asyncRequestInterceptor);\n\t\t}\n\t}", "summary_tokens": ["open", "a", "new", "hibernate", "session", "according", "and", "bind", "it", "to", "the", "thread", "via", "the", "transaction", "synchronization", "manager"], "project": "spring-framework"}
{"id": 4170, "code": "\tprivate String getSqlState(SQLException ex) {\n\t\tString sqlState = ex.getSQLState();\n\t\tif (sqlState == null) {\n\t\t\tSQLException nestedEx = ex.getNextException();\n\t\t\tif (nestedEx != null) {\n\t\t\t\tsqlState = nestedEx.getSQLState();\n\t\t\t}\n\t\t}\n\t\treturn sqlState;\n\t}", "summary_tokens": ["gets", "the", "sql", "state", "code", "from", "the", "supplied", "sqlexception", "exception"], "project": "spring-framework"}
{"id": 9553, "code": "\tpublic void setSuffix(@Nullable String suffix) {\n\t\tthis.suffix = (suffix != null ? suffix : \"\");\n\t}", "summary_tokens": ["set", "the", "suffix", "to", "append", "to", "generated", "view", "names"], "project": "spring-framework"}
{"id": 4392, "code": "\tpublic void setDestinationName(@Nullable String destinationName) {\n\t\tthis.destination = destinationName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "destination", "to", "receive", "messages", "from"], "project": "spring-framework"}
{"id": 2316, "code": "protected Label[] getLabels() {\n  return new Label[0];\n}", "summary_tokens": ["returns", "the", "labels", "corresponding", "to", "this", "attribute"], "project": "spring-framework"}
{"id": 7161, "code": "\tpublic static int[] getRequiredIntParameters(ServletRequest request, String name)\n\t\t\tthrows ServletRequestBindingException {\n\n\t\treturn INT_PARSER.parseInts(name, request.getParameterValues(name));\n\t}", "summary_tokens": ["get", "an", "array", "of", "int", "parameters", "throwing", "an", "exception", "if", "not", "found", "or", "one", "is", "not", "a", "number"], "project": "spring-framework"}
{"id": 7930, "code": "\tpublic final InputStream getSourceStream() {\n\t\treturn this.sourceStream;\n\t}", "summary_tokens": ["return", "the", "underlying", "source", "stream", "never", "null"], "project": "spring-framework"}
{"id": 8482, "code": "public com.google.protobuf.ByteString\n    getFooBytes() {\n  Object ref = foo_;\n  if (ref instanceof String) {\n    com.google.protobuf.ByteString b =\n        com.google.protobuf.ByteString.copyFromUtf8(\n            (String) ref);\n    foo_ = b;\n    return b;\n  } else {\n    return (com.google.protobuf.ByteString) ref;\n  }\n}", "summary_tokens": ["code", "optional", "string", "foo", "0", "code"], "project": "spring-framework"}
{"id": 4752, "code": "\tprotected HandlerMethodArgumentResolverComposite getArgumentResolvers() {\n\t\treturn this.invocableHelper.getArgumentResolvers();\n\t}", "summary_tokens": ["return", "the", "argument", "resolvers", "initialized", "during", "after", "properties", "set"], "project": "spring-framework"}
{"id": 3172, "code": "\tpublic static Method getStaticMethod(Class<?> clazz, String methodName, Class<?>... args) {\n\t\tAssert.notNull(clazz, \"Class must not be null\");\n\t\tAssert.notNull(methodName, \"Method name must not be null\");\n\t\ttry {\n\t\t\tMethod method = clazz.getMethod(methodName, args);\n\t\t\treturn Modifier.isStatic(method.getModifiers()) ? method : null;\n\t\t}\n\t\tcatch (NoSuchMethodException ex) {\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["return", "a", "public", "static", "method", "of", "a", "class"], "project": "spring-framework"}
{"id": 9835, "code": "\tpublic Stats getStats() {\n\t\treturn this.stats;\n\t}", "summary_tokens": ["return", "a", "structured", "object", "with", "internal", "state", "and", "counters"], "project": "spring-framework"}
{"id": 2615, "code": "public Object getBean() {\n    return bean;\n}", "summary_tokens": ["return", "the", "bean", "currently", "in", "use", "by", "this", "map"], "project": "spring-framework"}
{"id": 5991, "code": "\tpublic ResultMatcher doesNotExist(String name) {\n\t\treturn result -> assertFalse(\"Response should not contain header '\" + name + \"'\",\n\t\t\t\tresult.getResponse().containsHeader(name));\n\t}", "summary_tokens": ["assert", "that", "the", "named", "response", "header", "does", "not", "exist"], "project": "spring-framework"}
{"id": 1388, "code": "\tpublic final ApplicationContext getApplicationContext() throws IllegalStateException {\n\t\tif (this.applicationContext == null && isContextRequired()) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"ApplicationObjectSupport instance [\" + this + \"] does not run in an ApplicationContext\");\n\t\t}\n\t\treturn this.applicationContext;\n\t}", "summary_tokens": ["return", "the", "application", "context", "that", "this", "object", "is", "associated", "with"], "project": "spring-framework"}
{"id": 8151, "code": "\tpublic static <T extends ServerResponse> RouterFunction<T> changeParser(RouterFunction<T> routerFunction,\n\t\t\tPathPatternParser parser) {\n\n\t\tAssert.notNull(routerFunction, \"RouterFunction must not be null\");\n\t\tAssert.notNull(parser, \"Parser must not be null\");\n\n\t\tChangePathPatternParserVisitor visitor = new ChangePathPatternParserVisitor(parser);\n\t\trouterFunction.accept(visitor);\n\t\treturn routerFunction;\n\t}", "summary_tokens": ["changes", "the", "path", "pattern", "parser", "on", "the", "given", "router", "function", "router", "function"], "project": "spring-framework"}
{"id": 5409, "code": "\tList<String> getParameterNames() {\n\t\treturn this.parameterNames;\n\t}", "summary_tokens": ["return", "all", "the", "parameters", "bind", "variables", "in", "the", "parsed", "sql", "statement"], "project": "spring-framework"}
{"id": 9155, "code": "\tprotected static HttpServletRequest getCurrentRequest() {\n\t\tRequestAttributes attrs = RequestContextHolder.getRequestAttributes();\n\t\tAssert.state(attrs instanceof ServletRequestAttributes, \"No current ServletRequestAttributes\");\n\t\treturn ((ServletRequestAttributes) attrs).getRequest();\n\t}", "summary_tokens": ["obtain", "current", "request", "through", "request", "context", "holder"], "project": "spring-framework"}
{"id": 4464, "code": "\tpublic final int getMaxMessagesPerTask() {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\treturn this.maxMessagesPerTask;\n\t\t}\n\t}", "summary_tokens": ["return", "the", "maximum", "number", "of", "messages", "to", "process", "in", "one", "task"], "project": "spring-framework"}
{"id": 8361, "code": "\tpublic boolean isPropagateQuery() {\n\t\treturn this.propagateQuery;\n\t}", "summary_tokens": ["whether", "the", "query", "string", "of", "the", "current", "url", "is", "appended", "to", "the", "redirect", "url"], "project": "spring-framework"}
{"id": 1, "code": "\tprivate void applyJavaCompileConventions(Project project) {\n\t\tproject.getTasks().withType(JavaCompile.class)\n\t\t\t\t.matching(compileTask -> compileTask.getName().equals(JavaPlugin.COMPILE_JAVA_TASK_NAME))\n\t\t\t\t.forEach(compileTask -> {\n\t\t\t\t\tcompileTask.getOptions().setCompilerArgs(COMPILER_ARGS);\n\t\t\t\t\tcompileTask.getOptions().setEncoding(\"UTF-8\");\n\t\t\t\t});\n\t\tproject.getTasks().withType(JavaCompile.class)\n\t\t\t\t.matching(compileTask -> compileTask.getName().equals(JavaPlugin.COMPILE_TEST_JAVA_TASK_NAME)\n\t\t\t\t\t\t|| compileTask.getName().equals(\"compileTestFixturesJava\"))\n\t\t\t\t.forEach(compileTask -> {\n\t\t\t\t\tcompileTask.getOptions().setCompilerArgs(TEST_COMPILER_ARGS);\n\t\t\t\t\tcompileTask.getOptions().setEncoding(\"UTF-8\");\n\t\t\t\t});\n\t}", "summary_tokens": ["applies", "the", "common", "java", "compiler", "options", "for", "main", "sources", "test", "fixture", "sources", "and", "test", "sources"], "project": "spring-framework"}
{"id": 5018, "code": "\tpublic void setMessageId(@Nullable String messageId) {\n\t\tset(MESSAGE_ID, messageId);\n\t}", "summary_tokens": ["set", "the", "message", "id", "header"], "project": "spring-framework"}
{"id": 968, "code": "\tpublic CacheManager getCacheManager() {\n\t\treturn this.cacheManager;\n\t}", "summary_tokens": ["return", "the", "backing", "jcache", "cache", "manager", "javax"], "project": "spring-framework"}
{"id": 1188, "code": "\tprotected Cache.ValueWrapper doGet(Cache cache, Object key) {\n\t\ttry {\n\t\t\treturn cache.get(key);\n\t\t}\n\t\tcatch (RuntimeException ex) {\n\t\t\tgetErrorHandler().handleCacheGetError(ex, cache, key);\n\t\t\treturn null;  \n\t\t}\n\t}", "summary_tokens": ["execute", "cache", "get", "object", "on", "the", "specified", "cache", "and", "invoke", "the", "error", "handler", "if", "an", "exception", "occurs"], "project": "spring-framework"}
{"id": 2155, "code": "\tpublic static SimpleNamingContextBuilder emptyActivatedContextBuilder() throws NamingException {\n\t\tSimpleNamingContextBuilder builder = activated;\n\t\tif (builder != null) {\n\t\t\t\n\t\t\tbuilder.clear();\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\tbuilder = new SimpleNamingContextBuilder();\n\t\t\t\n\t\t\tbuilder.activate();\n\t\t}\n\t\treturn builder;\n\t}", "summary_tokens": ["if", "no", "simple", "naming", "context", "builder", "is", "already", "configuring", "jndi", "create", "and", "activate", "one"], "project": "spring-framework"}
{"id": 926, "code": "\tprivate void findTypeOfPrototypeFactoryMethodOnBeanInstance(boolean singleton) {\n\t\tString expectedNameFromProperties = \"tony\";\n\t\tString expectedNameFromArgs = \"gordon\";\n\n\t\tRootBeanDefinition instanceFactoryDefinition = new RootBeanDefinition(BeanWithFactoryMethod.class);\n\t\tMutablePropertyValues pvs = new MutablePropertyValues();\n\t\tpvs.add(\"name\", expectedNameFromProperties);\n\t\tinstanceFactoryDefinition.setPropertyValues(pvs);\n\t\tlbf.registerBeanDefinition(\"factoryBeanInstance\", instanceFactoryDefinition);\n\n\t\tRootBeanDefinition factoryMethodDefinitionWithProperties = new RootBeanDefinition();\n\t\tfactoryMethodDefinitionWithProperties.setFactoryBeanName(\"factoryBeanInstance\");\n\t\tfactoryMethodDefinitionWithProperties.setFactoryMethodName(\"create\");\n\t\tif (!singleton) {\n\t\t\tfactoryMethodDefinitionWithProperties.setScope(BeanDefinition.SCOPE_PROTOTYPE);\n\t\t}\n\t\tlbf.registerBeanDefinition(\"fmWithProperties\", factoryMethodDefinitionWithProperties);\n\n\t\tRootBeanDefinition factoryMethodDefinitionGeneric = new RootBeanDefinition();\n\t\tfactoryMethodDefinitionGeneric.setFactoryBeanName(\"factoryBeanInstance\");\n\t\tfactoryMethodDefinitionGeneric.setFactoryMethodName(\"createGeneric\");\n\t\tif (!singleton) {\n\t\t\tfactoryMethodDefinitionGeneric.setScope(BeanDefinition.SCOPE_PROTOTYPE);\n\t\t}\n\t\tlbf.registerBeanDefinition(\"fmGeneric\", factoryMethodDefinitionGeneric);\n\n\t\tRootBeanDefinition factoryMethodDefinitionWithArgs = new RootBeanDefinition();\n\t\tfactoryMethodDefinitionWithArgs.setFactoryBeanName(\"factoryBeanInstance\");\n\t\tfactoryMethodDefinitionWithArgs.setFactoryMethodName(\"createWithArgs\");\n\t\tConstructorArgumentValues cvals = new ConstructorArgumentValues();\n\t\tcvals.addGenericArgumentValue(expectedNameFromArgs);\n\t\tfactoryMethodDefinitionWithArgs.setConstructorArgumentValues(cvals);\n\t\tif (!singleton) {\n\t\t\tfactoryMethodDefinitionWithArgs.setScope(BeanDefinition.SCOPE_PROTOTYPE);\n\t\t}\n\t\tlbf.registerBeanDefinition(\"fmWithArgs\", factoryMethodDefinitionWithArgs);\n\n\t\tassertThat(lbf.getBeanDefinitionCount()).isEqualTo(4);\n\t\tassertBeanNamesForType(TestBean.class, true, true, \"fmWithProperties\", \"fmWithArgs\");\n\n\t\tTestBean tb = (TestBean) lbf.getBean(\"fmWithProperties\");\n\t\tTestBean second = (TestBean) lbf.getBean(\"fmWithProperties\");\n\t\tif (singleton) {\n\t\t\tassertThat(second).isSameAs(tb);\n\t\t}\n\t\telse {\n\t\t\tassertThat(second).isNotSameAs(tb);\n\t\t}\n\t\tassertThat(tb.getName()).isEqualTo(expectedNameFromProperties);\n\n\t\ttb = (TestBean) lbf.getBean(\"fmGeneric\");\n\t\tsecond = (TestBean) lbf.getBean(\"fmGeneric\");\n\t\tif (singleton) {\n\t\t\tassertThat(second).isSameAs(tb);\n\t\t}\n\t\telse {\n\t\t\tassertThat(second).isNotSameAs(tb);\n\t\t}\n\t\tassertThat(tb.getName()).isEqualTo(expectedNameFromProperties);\n\n\t\tTestBean tb2 = (TestBean) lbf.getBean(\"fmWithArgs\");\n\t\tsecond = (TestBean) lbf.getBean(\"fmWithArgs\");\n\t\tif (singleton) {\n\t\t\tassertThat(second).isSameAs(tb2);\n\t\t}\n\t\telse {\n\t\t\tassertThat(second).isNotSameAs(tb2);\n\t\t}\n\t\tassertThat(tb2.getName()).isEqualTo(expectedNameFromArgs);\n\t}", "summary_tokens": ["singleton", "whether", "the", "bean", "created", "from", "the", "factory", "method", "on", "the", "bean", "instance", "should", "be", "a", "singleton", "or", "prototype"], "project": "spring-framework"}
{"id": 1976, "code": "\tpublic void setAutoGrowCollectionLimit(int autoGrowCollectionLimit) {\n\t\tAssert.state(this.bindingResult == null,\n\t\t\t\t\"DataBinder is already initialized - call setAutoGrowCollectionLimit before other configuration methods\");\n\t\tthis.autoGrowCollectionLimit = autoGrowCollectionLimit;\n\t}", "summary_tokens": ["specify", "the", "limit", "for", "array", "and", "collection", "auto", "growing"], "project": "spring-framework"}
{"id": 8501, "code": "\tprivate void initViewResolvers(ApplicationContext context) {\n\t\tthis.viewResolvers = null;\n\n\t\tif (this.detectAllViewResolvers) {\n\t\t\t\n\t\t\tMap<String, ViewResolver> matchingBeans =\n\t\t\t\t\tBeanFactoryUtils.beansOfTypeIncludingAncestors(context, ViewResolver.class, true, false);\n\t\t\tif (!matchingBeans.isEmpty()) {\n\t\t\t\tthis.viewResolvers = new ArrayList<>(matchingBeans.values());\n\t\t\t\t\n\t\t\t\tAnnotationAwareOrderComparator.sort(this.viewResolvers);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\ttry {\n\t\t\t\tViewResolver vr = context.getBean(VIEW_RESOLVER_BEAN_NAME, ViewResolver.class);\n\t\t\t\tthis.viewResolvers = Collections.singletonList(vr);\n\t\t\t}\n\t\t\tcatch (NoSuchBeanDefinitionException ex) {\n\t\t\t\t\n\t\t\t}\n\t\t}\n\n\t\t\n\t\t\n\t\tif (this.viewResolvers == null) {\n\t\t\tthis.viewResolvers = getDefaultStrategies(context, ViewResolver.class);\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(\"No ViewResolvers declared for servlet '\" + getServletName() +\n\t\t\t\t\t\t\"': using default strategies from DispatcherServlet.properties\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["initialize", "the", "view", "resolvers", "used", "by", "this", "class"], "project": "spring-framework"}
{"id": 324, "code": "\tpublic String[] getPossibleMatches() {\n\t\treturn this.possibleMatches;\n\t}", "summary_tokens": ["return", "suggestions", "for", "actual", "bean", "property", "names", "that", "closely", "match", "the", "invalid", "property", "name", "if", "any"], "project": "spring-framework"}
{"id": 9001, "code": "\tpublic void setPathPrefixes(Map<String, Predicate<Class<?>>> prefixes) {\n\t\tthis.pathPrefixes = (!prefixes.isEmpty() ?\n\t\t\t\tCollections.unmodifiableMap(new LinkedHashMap<>(prefixes)) :\n\t\t\t\tCollections.emptyMap());\n\t}", "summary_tokens": ["configure", "path", "prefixes", "to", "apply", "to", "controller", "methods"], "project": "spring-framework"}
{"id": 665, "code": "\tpublic static String generateBeanName(\n\t\t\tBeanDefinition definition, BeanDefinitionRegistry registry, boolean isInnerBean)\n\t\t\tthrows BeanDefinitionStoreException {\n\n\t\tString generatedBeanName = definition.getBeanClassName();\n\t\tif (generatedBeanName == null) {\n\t\t\tif (definition.getParentName() != null) {\n\t\t\t\tgeneratedBeanName = definition.getParentName() + \"$child\";\n\t\t\t}\n\t\t\telse if (definition.getFactoryBeanName() != null) {\n\t\t\t\tgeneratedBeanName = definition.getFactoryBeanName() + \"$created\";\n\t\t\t}\n\t\t}\n\t\tif (!StringUtils.hasText(generatedBeanName)) {\n\t\t\tthrow new BeanDefinitionStoreException(\"Unnamed bean definition specifies neither \" +\n\t\t\t\t\t\"'class' nor 'parent' nor 'factory-bean' - can't generate bean name\");\n\t\t}\n\n\t\tif (isInnerBean) {\n\t\t\t\n\t\t\treturn generatedBeanName + GENERATED_BEAN_NAME_SEPARATOR + ObjectUtils.getIdentityHexString(definition);\n\t\t}\n\n\t\t\n\t\treturn uniqueBeanName(generatedBeanName, registry);\n\t}", "summary_tokens": ["generate", "a", "bean", "name", "for", "the", "given", "bean", "definition", "unique", "within", "the", "given", "bean", "factory"], "project": "spring-framework"}
{"id": 8708, "code": "\tprotected void configureHandlerExceptionResolvers(List<HandlerExceptionResolver> exceptionResolvers) {\n\t}", "summary_tokens": ["override", "this", "method", "to", "configure", "the", "list", "of", "handler", "exception", "resolver", "handler", "exception", "resolvers", "to", "use"], "project": "spring-framework"}
{"id": 1014, "code": "\tpublic void afterPropertiesSet() {\n\t\tgetFileTypeMap();\n\t}", "summary_tokens": ["creates", "the", "final", "merged", "mapping", "set"], "project": "spring-framework"}
{"id": 4082, "code": "\tprotected String resolveSql() {\n\t\tString sql = getSql();\n\t\tAssert.state(sql != null, \"No SQL set\");\n\t\treturn sql;\n\t}", "summary_tokens": ["resolve", "the", "configured", "sql", "for", "actual", "use"], "project": "spring-framework"}
{"id": 1842, "code": "\tpublic void setTimeUnit(@Nullable TimeUnit timeUnit) {\n\t\tthis.timeUnit = (timeUnit != null ? timeUnit : TimeUnit.MILLISECONDS);\n\t}", "summary_tokens": ["specify", "the", "time", "unit", "for", "the", "delay", "and", "period", "values"], "project": "spring-framework"}
{"id": 4074, "code": "\tpublic void setUpdatableResults(boolean updatableResults) {\n\t\tif (isCompiled()) {\n\t\t\tthrow new InvalidDataAccessApiUsageException(\n\t\t\t\t\t\"The updateableResults flag must be set before the operation is compiled\");\n\t\t}\n\t\tthis.updatableResults = updatableResults;\n\t}", "summary_tokens": ["set", "whether", "to", "use", "statements", "that", "are", "capable", "of", "returning", "updatable", "result", "sets"], "project": "spring-framework"}
{"id": 3613, "code": "\tprotected void parseAndCheckError(String expression, SpelMessage expectedMessage, Object... otherProperties) {\n\t\tassertThatExceptionOfType(SpelParseException.class).isThrownBy(() -> {\n\t\t\tExpression expr = parser.parseExpression(expression);\n\t\t\tSpelUtilities.printAbstractSyntaxTree(System.out, expr);\n\t\t}).satisfies(ex -> {\n\t\t\tassertThat(ex.getMessageCode()).isEqualTo(expectedMessage);\n\t\t\tif (otherProperties != null && otherProperties.length != 0) {\n\t\t\t\t\n\t\t\t\tint pos = ((Integer) otherProperties[0]).intValue();\n\t\t\t\tassertThat(pos).as(\"reported position\").isEqualTo(pos);\n\t\t\t\tif (otherProperties.length > 1) {\n\t\t\t\t\t\n\t\t\t\t\tObject[] inserts = ex.getInserts();\n\t\t\t\t\tassertThat(inserts).as(\"inserts\").hasSizeGreaterThanOrEqualTo(otherProperties.length - 1);\n\t\t\t\t\tObject[] expectedInserts = new Object[inserts.length];\n\t\t\t\t\tSystem.arraycopy(otherProperties, 1, expectedInserts, 0, expectedInserts.length);\n\t\t\t\t\tassertThat(inserts).as(\"inserts\").containsExactly(expectedInserts);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}", "summary_tokens": ["parse", "the", "specified", "expression", "and", "ensure", "the", "expected", "message", "comes", "out"], "project": "spring-framework"}
{"id": 731, "code": "\tpublic String getElementTypeName() {\n\t\treturn this.elementTypeName;\n\t}", "summary_tokens": ["return", "the", "default", "element", "type", "name", "class", "name", "to", "be", "used", "for", "this", "set"], "project": "spring-framework"}
{"id": 7962, "code": "\tpublic void doFilter(ServletRequest request, ServletResponse response) throws ServletException, IOException {\n\t\tif (this.filter != null) {\n\t\t\tthis.filter.doFilter(request, response, this.nextFilterChain);\n\t\t}\n\t\telse {\n\t\t\tAssert.state(this.servlet != null, \"Neither a Filter not a Servlet set\");\n\t\t\tthis.servlet.service(request, response);\n\t\t}\n\t}", "summary_tokens": ["pass", "the", "call", "on", "to", "the", "filter", "servlet"], "project": "spring-framework"}
{"id": 9861, "code": "\tpublic int getInboundMessageSizeLimit() {\n\t\treturn this.inboundMessageSizeLimit;\n\t}", "summary_tokens": ["get", "the", "configured", "inbound", "message", "buffer", "size", "in", "bytes"], "project": "spring-framework"}
{"id": 7665, "code": "\tpublic HttpHeaders getResponseHeaders() {\n\t\treturn getHeaders();\n\t}", "summary_tokens": ["delegates", "to", "get", "headers"], "project": "spring-framework"}
{"id": 5229, "code": "\tpublic void setJtaDataSource(DataSource jtaDataSource) {\n\t\tthis.internalPersistenceUnitManager.setDataSourceLookup(new SingleDataSourceLookup(jtaDataSource));\n\t\tthis.internalPersistenceUnitManager.setDefaultJtaDataSource(jtaDataSource);\n\t}", "summary_tokens": ["specify", "the", "jdbc", "data", "source", "that", "the", "jpa", "persistence", "provider", "is", "supposed", "to", "use", "for", "accessing", "the", "database"], "project": "spring-framework"}
{"id": 4028, "code": "\tpublic void setEnabled(boolean enabled) {\n\t\tthis.enabled = enabled;\n\t}", "summary_tokens": ["flag", "to", "explicitly", "enable", "or", "disable", "the", "set", "database", "populator", "database", "populator", "and", "set", "database", "cleaner", "database", "cleaner"], "project": "spring-framework"}
{"id": 5208, "code": "\tpublic void cleanupTransaction(@Nullable Object transactionData) {\n\t}", "summary_tokens": ["this", "implementation", "does", "nothing", "since", "the", "default", "begin", "transaction", "implementation", "does", "not", "require", "any", "cleanup"], "project": "spring-framework"}
{"id": 6242, "code": "\tpublic int getOrder() {\n\t\treturn this.order;\n\t}", "summary_tokens": ["return", "the", "synchronization", "order", "for", "the", "listener"], "project": "spring-framework"}
{"id": 7555, "code": "\tpublic Method resolveMethodByExceptionType(Class<? extends Throwable> exceptionType) {\n\t\tMethod method = this.exceptionLookupCache.get(exceptionType);\n\t\tif (method == null) {\n\t\t\tmethod = getMappedMethod(exceptionType);\n\t\t\tthis.exceptionLookupCache.put(exceptionType, method);\n\t\t}\n\t\treturn (method != NO_MATCHING_EXCEPTION_HANDLER_METHOD ? method : null);\n\t}", "summary_tokens": ["find", "a", "method", "to", "handle", "the", "given", "exception", "type"], "project": "spring-framework"}
{"id": 661, "code": "\tpublic String getBeanName() {\n\t\treturn String.valueOf(super.getBeanName());\n\t}", "summary_tokens": ["return", "the", "name", "of", "the", "bean"], "project": "spring-framework"}
{"id": 9905, "code": "\tpublic String getSockJsClientLibraryUrl() {\n\t\treturn this.clientLibraryUrl;\n\t}", "summary_tokens": ["return", "he", "url", "to", "the", "sock", "js", "java", "script", "client", "library"], "project": "spring-framework"}
{"id": 6495, "code": "\tpublic int hashCode() {\n\t\treturn toString().hashCode();\n\t}", "summary_tokens": ["this", "implementation", "returns", "to", "string", "s", "hash", "code"], "project": "spring-framework"}
{"id": 9380, "code": "\tpublic void setEnctype(String enctype) {\n\t\tthis.enctype = enctype;\n\t}", "summary_tokens": ["set", "the", "value", "of", "the", "enctype", "attribute"], "project": "spring-framework"}
{"id": 8347, "code": "\tpublic String getErrorMessagesAsString(String delimiter) {\n\t\treturn StringUtils.arrayToDelimitedString(initErrorMessages(), delimiter);\n\t}", "summary_tokens": ["return", "an", "error", "message", "string", "concatenating", "all", "messages", "separated", "by", "the", "given", "delimiter"], "project": "spring-framework"}
{"id": 9075, "code": "\tpublic ResourceUrlProvider getResourceUrlProvider() {\n\t\treturn this.resourceUrlProvider;\n\t}", "summary_tokens": ["return", "the", "configured", "resource", "url", "provider"], "project": "spring-framework"}
{"id": 6476, "code": "\tpublic void setCompleted() {\n\t\tthis.completed = true;\n\t}", "summary_tokens": ["mark", "this", "transaction", "as", "completed", "that", "is", "committed", "or", "rolled", "back"], "project": "spring-framework"}
{"id": 3906, "code": "\tprotected final Connection getConnection() throws CannotGetJdbcConnectionException {\n\t\tDataSource dataSource = getDataSource();\n\t\tAssert.state(dataSource != null, \"No DataSource set\");\n\t\treturn DataSourceUtils.getConnection(dataSource);\n\t}", "summary_tokens": ["get", "a", "jdbc", "connection", "either", "from", "the", "current", "transaction", "or", "a", "new", "one"], "project": "spring-framework"}
{"id": 826, "code": "\tprivate Map<String, String> getSchemaMappings() {\n\t\tMap<String, String> schemaMappings = this.schemaMappings;\n\t\tif (schemaMappings == null) {\n\t\t\tsynchronized (this) {\n\t\t\t\tschemaMappings = this.schemaMappings;\n\t\t\t\tif (schemaMappings == null) {\n\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\tlogger.trace(\"Loading schema mappings from [\" + this.schemaMappingsLocation + \"]\");\n\t\t\t\t\t}\n\t\t\t\t\ttry {\n\t\t\t\t\t\tProperties mappings =\n\t\t\t\t\t\t\t\tPropertiesLoaderUtils.loadAllProperties(this.schemaMappingsLocation, this.classLoader);\n\t\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\t\tlogger.trace(\"Loaded schema mappings: \" + mappings);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tschemaMappings = new ConcurrentHashMap<>(mappings.size());\n\t\t\t\t\t\tCollectionUtils.mergePropertiesIntoMap(mappings, schemaMappings);\n\t\t\t\t\t\tthis.schemaMappings = schemaMappings;\n\t\t\t\t\t}\n\t\t\t\t\tcatch (IOException ex) {\n\t\t\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\t\t\"Unable to load schema mappings from location [\" + this.schemaMappingsLocation + \"]\", ex);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn schemaMappings;\n\t}", "summary_tokens": ["load", "the", "specified", "schema", "mappings", "lazily"], "project": "spring-framework"}
{"id": 488, "code": "\tpublic void setTargetObject(@Nullable Object targetObject) {\n\t\tthis.targetObject = targetObject;\n\t}", "summary_tokens": ["set", "the", "target", "object", "on", "which", "the", "field", "is", "defined"], "project": "spring-framework"}
{"id": 5073, "code": "\tpublic MessageBuilder<T> setHeaders(MessageHeaderAccessor accessor) {\n\t\tAssert.notNull(accessor, \"MessageHeaderAccessor must not be null\");\n\t\tthis.headerAccessor = accessor;\n\t\treturn this;\n\t}", "summary_tokens": ["set", "the", "message", "headers", "to", "use", "by", "providing", "a", "message", "header", "accessor"], "project": "spring-framework"}
{"id": 2255, "code": "\tpublic TypeReference getType() {\n\t\treturn this.type;\n\t}", "summary_tokens": ["return", "the", "type", "reference", "type", "that", "needs", "to", "be", "serialized", "using", "java", "serialization", "at", "runtime"], "project": "spring-framework"}
{"id": 3882, "code": "\tprotected KeyHolder doExecuteAndReturnKeyHolder(SqlParameterSource parameterSource) {\n\t\tcheckCompiled();\n\t\tList<Object> values = matchInParameterValuesWithInsertColumns(parameterSource);\n\t\treturn executeInsertAndReturnKeyHolderInternal(values);\n\t}", "summary_tokens": ["method", "that", "provides", "execution", "of", "the", "insert", "using", "the", "passed", "in", "sql", "parameter", "source", "and", "returning", "all", "generated", "keys"], "project": "spring-framework"}
{"id": 5068, "code": "\tpublic void setIdGenerator(@Nullable IdGenerator idGenerator) {\n\t\tthis.idGenerator = idGenerator;\n\t}", "summary_tokens": ["configure", "the", "id", "generator", "strategy", "to", "initialize", "message", "header", "accessor", "instances", "with"], "project": "spring-framework"}
{"id": 369, "code": "\tpublic void initPropertyName(String propertyName) {\n\t\tAssert.state(this.propertyName == null, \"Property name already initialized\");\n\t\tthis.propertyName = propertyName;\n\t}", "summary_tokens": ["initialize", "this", "exception", "s", "property", "name", "for", "exposure", "through", "get", "property", "name", "as", "an", "alternative", "to", "having", "it", "initialized", "via", "a", "property", "change", "event"], "project": "spring-framework"}
{"id": 3608, "code": "\tpublic void removeImport(String prefix) {\n\t\tthis.knownPackagePrefixes.remove(prefix);\n\t}", "summary_tokens": ["remove", "that", "specified", "prefix", "from", "this", "locator", "s", "list", "of", "imports"], "project": "spring-framework"}
{"id": 4297, "code": "\tpublic void resetConnection() {\n\t\tsynchronized (this.connectionMonitor) {\n\t\t\tif (this.connection != null) {\n\t\t\t\tcloseConnection(this.connection);\n\t\t\t}\n\t\t\tthis.connection = null;\n\t\t}\n\t}", "summary_tokens": ["reset", "the", "underlying", "shared", "connection", "to", "be", "reinitialized", "on", "next", "access"], "project": "spring-framework"}
{"id": 5983, "code": "\tpublic ResultMatcher attributeCount(int count) {\n\t\treturn result -> assertEquals(\"FlashMap size\", count, result.getFlashMap().size());\n\t}", "summary_tokens": ["assert", "the", "number", "of", "flash", "attributes"], "project": "spring-framework"}
{"id": 6640, "code": "\tpublic void setAccessControlMaxAge(long maxAge) {\n\t\tset(ACCESS_CONTROL_MAX_AGE, Long.toString(maxAge));\n\t}", "summary_tokens": ["set", "the", "new", "value", "of", "the", "access", "control", "max", "age", "response", "header"], "project": "spring-framework"}
{"id": 9285, "code": "\tprotected String getCssErrorClass() {\n\t\treturn this.cssErrorClass;\n\t}", "summary_tokens": ["the", "css", "class", "to", "use", "when", "the", "field", "bound", "to", "a", "particular", "tag", "has", "errors"], "project": "spring-framework"}
{"id": 4564, "code": "\tpublic Destination getDestination() {\n\t\treturn (Destination) getHeader(JmsHeaders.DESTINATION);\n\t}", "summary_tokens": ["return", "the", "jms", "headers", "destination", "destination"], "project": "spring-framework"}
{"id": 1223, "code": "\tpublic final boolean isAllowNullValues() {\n\t\treturn this.allowNullValues;\n\t}", "summary_tokens": ["return", "whether", "null", "values", "are", "allowed", "in", "this", "cache"], "project": "spring-framework"}
{"id": 6655, "code": "\tpublic List<String> getConnection() {\n\t\treturn getValuesAsList(CONNECTION);\n\t}", "summary_tokens": ["return", "the", "value", "of", "the", "connection", "header"], "project": "spring-framework"}
{"id": 6447, "code": "\tprotected int determineTimeout(TransactionDefinition definition) {\n\t\tif (definition.getTimeout() != TransactionDefinition.TIMEOUT_DEFAULT) {\n\t\t\treturn definition.getTimeout();\n\t\t}\n\t\treturn getDefaultTimeout();\n\t}", "summary_tokens": ["determine", "the", "actual", "timeout", "to", "use", "for", "the", "given", "definition"], "project": "spring-framework"}
{"id": 7073, "code": "\tprotected Mono<Void> doCommit(@Nullable Supplier<? extends Mono<Void>> writeAction) {\n\t\tFlux<Void> allActions = Flux.empty();\n\t\tif (this.state.compareAndSet(State.NEW, State.COMMITTING)) {\n\t\t\tif (!this.commitActions.isEmpty()) {\n\t\t\t\tallActions = Flux.concat(Flux.fromIterable(this.commitActions).map(Supplier::get))\n\t\t\t\t\t\t.doOnError(ex -> {\n\t\t\t\t\t\t\tif (this.state.compareAndSet(State.COMMITTING, State.COMMIT_ACTION_FAILED)) {\n\t\t\t\t\t\t\t\tgetHeaders().clearContentHeaders();\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t}\n\t\t}\n\t\telse if (this.state.compareAndSet(State.COMMIT_ACTION_FAILED, State.COMMITTING)) {\n\t\t\t\n\t\t}\n\t\telse {\n\t\t\treturn Mono.empty();\n\t\t}\n\n\t\tallActions = allActions.concatWith(Mono.fromRunnable(() -> {\n\t\t\tapplyStatusCode();\n\t\t\tapplyHeaders();\n\t\t\tapplyCookies();\n\t\t\tthis.state.set(State.COMMITTED);\n\t\t}));\n\n\t\tif (writeAction != null) {\n\t\t\tallActions = allActions.concatWith(writeAction.get());\n\t\t}\n\n\t\treturn allActions.then();\n\t}", "summary_tokens": ["apply", "before", "commit", "supplier", "before", "commit", "actions", "apply", "the", "response", "status", "and", "headers", "cookies", "and", "write", "the", "response", "body"], "project": "spring-framework"}
{"id": 7804, "code": "\tpublic final String toString() {\n\t\treturn toUriString();\n\t}", "summary_tokens": ["a", "simple", "pass", "through", "to", "to", "uri", "string"], "project": "spring-framework"}
{"id": 4630, "code": "\tprivate void doTestSendDestination(\n\t\t\tboolean explicitDestination, boolean useDefaultDestination,\n\t\t\tboolean ignoreQOS, boolean disableIdAndTimestamp) throws Exception {\n\n\t\tJmsTemplate template = createTemplate();\n\t\ttemplate.setConnectionFactory(this.connectionFactory);\n\n\t\tString destinationName = \"testDestination\";\n\n\t\tif (useDefaultDestination) {\n\t\t\tif (explicitDestination) {\n\t\t\t\ttemplate.setDefaultDestination(this.queue);\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttemplate.setDefaultDestinationName(destinationName);\n\t\t\t}\n\t\t}\n\t\tif (disableIdAndTimestamp) {\n\t\t\ttemplate.setMessageIdEnabled(false);\n\t\t\ttemplate.setMessageTimestampEnabled(false);\n\t\t}\n\n\t\tMessageProducer messageProducer = mock(MessageProducer.class);\n\t\tTextMessage textMessage = mock(TextMessage.class);\n\n\t\tgiven(this.session.createProducer(this.queue)).willReturn(messageProducer);\n\t\tgiven(this.session.createTextMessage(\"just testing\")).willReturn(textMessage);\n\n\t\tif (!ignoreQOS) {\n\t\t\ttemplate.setQosSettings(this.qosSettings);\n\t\t}\n\n\t\tif (useDefaultDestination) {\n\t\t\ttemplate.send(session -> session.createTextMessage(\"just testing\"));\n\t\t}\n\t\telse {\n\t\t\tif (explicitDestination) {\n\t\t\t\ttemplate.send(this.queue, (MessageCreator) session -> session.createTextMessage(\"just testing\"));\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttemplate.send(destinationName, (MessageCreator) session -> session.createTextMessage(\"just testing\"));\n\t\t\t}\n\t\t}\n\n\t\tif (useTransactedTemplate()) {\n\t\t\tverify(this.session).commit();\n\t\t}\n\n\t\tif (disableIdAndTimestamp) {\n\t\t\tverify(messageProducer).setDisableMessageID(true);\n\t\t\tverify(messageProducer).setDisableMessageTimestamp(true);\n\t\t}\n\n\t\tif (ignoreQOS) {\n\t\t\tverify(messageProducer).send(textMessage);\n\t\t}\n\t\telse {\n\t\t\tverify(messageProducer).send(textMessage, this.qosSettings.getDeliveryMode(),\n\t\t\t\t\tthis.qosSettings.getPriority(), this.qosSettings.getTimeToLive());\n\t\t}\n\t\tverify(messageProducer).close();\n\t\tverify(this.session).close();\n\t\tverify(this.connection).close();\n\t}", "summary_tokens": ["common", "method", "for", "testing", "a", "send", "method", "that", "uses", "the", "message", "creator", "callback", "but", "with", "different", "qos", "options"], "project": "spring-framework"}
{"id": 846, "code": "\tpublic int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException {\n\t\tBeanDefinitionDocumentReader documentReader = createBeanDefinitionDocumentReader();\n\t\tint countBefore = getRegistry().getBeanDefinitionCount();\n\t\tdocumentReader.registerBeanDefinitions(doc, createReaderContext(resource));\n\t\treturn getRegistry().getBeanDefinitionCount() - countBefore;\n\t}", "summary_tokens": ["register", "the", "bean", "definitions", "contained", "in", "the", "given", "dom", "document"], "project": "spring-framework"}
{"id": 8747, "code": "\tdefault RouterFunction<T> and(RouterFunction<T> other) {\n\t\treturn new RouterFunctions.SameComposedRouterFunction<>(this, other);\n\t}", "summary_tokens": ["return", "a", "composed", "routing", "function", "that", "first", "invokes", "this", "function", "and", "then", "invokes", "the", "other", "function", "of", "the", "same", "response", "type", "t", "if", "this", "route", "had", "optional", "empty", "no", "result"], "project": "spring-framework"}
{"id": 9207, "code": "\tprotected String htmlEscape(String content) {\n\t\tString out = content;\n\t\tif (isHtmlEscape()) {\n\t\t\tif (isResponseEncodedHtmlEscape()) {\n\t\t\t\tout = HtmlUtils.htmlEscape(content, this.pageContext.getResponse().getCharacterEncoding());\n\t\t\t}\n\t\t\telse {\n\t\t\t\tout = HtmlUtils.htmlEscape(content);\n\t\t\t}\n\t\t}\n\t\treturn out;\n\t}", "summary_tokens": ["html", "encodes", "the", "given", "string", "only", "if", "the", "html", "escape", "setting", "is", "enabled"], "project": "spring-framework"}
{"id": 7112, "code": "\tpublic List<ContentNegotiationStrategy> getStrategies() {\n\t\treturn this.strategies;\n\t}", "summary_tokens": ["return", "the", "configured", "content", "negotiation", "strategies"], "project": "spring-framework"}
{"id": 4536, "code": "\tpublic void setMessageListener(MessageListener messageListener) {\n\t\tthis.endpointFactory.setMessageListener(messageListener);\n\t\tthis.messageListenerSet = true;\n\t}", "summary_tokens": ["set", "the", "jms", "message", "listener", "for", "this", "endpoint"], "project": "spring-framework"}
{"id": 739, "code": "\tpublic Class<?> getBeanClass() {\n\t\treturn ClassUtils.getUserClass(getBeanType().toClass());\n\t}", "summary_tokens": ["return", "the", "user", "defined", "class", "of", "the", "bean"], "project": "spring-framework"}
{"id": 2179, "code": "\tpublic void match(RuntimeHints runtimeHints) {\n\t\tAssert.notNull(runtimeHints, \"RuntimeHints should not be null\");\n\t\tconfigureRuntimeHints(runtimeHints);\n\t\tList<RecordedInvocation> noMatchInvocations =\n\t\t\t\tthis.actual.recordedInvocations().filter(invocation -> !invocation.matches(runtimeHints)).toList();\n\t\tif (!noMatchInvocations.isEmpty()) {\n\t\t\tthrowAssertionError(errorMessageForInvocation(noMatchInvocations.get(0)));\n\t\t}\n\t}", "summary_tokens": ["verifies", "that", "each", "recorded", "invocation", "match", "at", "least", "once", "hint", "in", "the", "provided", "runtime", "hints"], "project": "spring-framework"}
{"id": 8302, "code": "\tprivate List<String> findModelAttributes(HandlerMethod handlerMethod,\n\t\t\tSessionAttributesHandler sessionAttributesHandler) {\n\n\t\tList<String> result = new ArrayList<>();\n\t\tfor (MethodParameter parameter : handlerMethod.getMethodParameters()) {\n\t\t\tif (parameter.hasParameterAnnotation(ModelAttribute.class)) {\n\t\t\t\tString name = getNameForParameter(parameter);\n\t\t\t\tClass<?> paramType = parameter.getParameterType();\n\t\t\t\tif (sessionAttributesHandler.isHandlerSessionAttribute(name, paramType)) {\n\t\t\t\t\tresult.add(name);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn result;\n\t}", "summary_tokens": ["find", "arguments", "also", "listed", "as"], "project": "spring-framework"}
{"id": 1410, "code": "\tpublic final ConfigurableListableBeanFactory getBeanFactory() {\n\t\treturn this.beanFactory;\n\t}", "summary_tokens": ["return", "the", "single", "internal", "bean", "factory", "held", "by", "this", "context", "as", "configurable", "listable", "bean", "factory"], "project": "spring-framework"}
{"id": 8163, "code": "\tstatic BodyBuilder ok() {\n\t\treturn status(HttpStatus.OK);\n\t}", "summary_tokens": ["create", "a", "builder", "with", "the", "status", "set", "to", "http", "status", "ok", "0", "ok"], "project": "spring-framework"}
{"id": 2669, "code": "\tpublic Object invokeSuper(Object obj, Object[] args) throws Throwable {\n\t\ttry {\n\t\t\tinit();\n\t\t\tFastClassInfo fci = fastClassInfo;\n\t\t\treturn fci.f2.invoke(fci.i2, obj, args);\n\t\t}\n\t\tcatch (InvocationTargetException e) {\n\t\t\tthrow e.getTargetException();\n\t\t}\n\t}", "summary_tokens": ["invoke", "the", "original", "super", "method", "on", "the", "specified", "object"], "project": "spring-framework"}
{"id": 7377, "code": "\tpublic void setServletContext(@Nullable ServletContext servletContext) {\n\t\tthis.servletContext = servletContext;\n\t}", "summary_tokens": ["set", "the", "servlet", "context", "that", "this", "web", "application", "context", "runs", "in"], "project": "spring-framework"}
{"id": 8533, "code": "\tprotected void initBeanWrapper(BeanWrapper bw) throws BeansException {\n\t}", "summary_tokens": ["initialize", "the", "bean", "wrapper", "for", "this", "http", "servlet", "bean", "possibly", "with", "custom", "editors"], "project": "spring-framework"}
{"id": 297, "code": "\tpublic void testBasicFunctionality() {\n\t\tSideEffectBean proxied = (SideEffectBean) beanFactory.getBean(\"swappable\");\n\t\tassertThat(proxied.getCount()).isEqualTo(INITIAL_COUNT);\n\t\tproxied.doWork();\n\t\tassertThat(proxied.getCount()).isEqualTo((INITIAL_COUNT + 1));\n\n\t\tproxied = (SideEffectBean) beanFactory.getBean(\"swappable\");\n\t\tproxied.doWork();\n\t\tassertThat(proxied.getCount()).isEqualTo((INITIAL_COUNT + 2));\n\t}", "summary_tokens": ["check", "it", "works", "like", "a", "normal", "invoker"], "project": "spring-framework"}
{"id": 973, "code": "\tdefault CacheResolver exceptionCacheResolver() {\n\t\treturn null;\n\t}", "summary_tokens": ["return", "the", "cache", "resolver", "bean", "to", "use", "to", "resolve", "exception", "caches", "for", "annotation", "driven", "cache", "management"], "project": "spring-framework"}
{"id": 4465, "code": "\tpublic void setIdleConsumerLimit(int idleConsumerLimit) {\n\t\tAssert.isTrue(idleConsumerLimit > 0, \"'idleConsumerLimit' must be 1 or higher\");\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tthis.idleConsumerLimit = idleConsumerLimit;\n\t\t}\n\t}", "summary_tokens": ["specify", "the", "limit", "for", "the", "number", "of", "consumers", "that", "are", "allowed", "to", "be", "idle", "at", "any", "given", "time"], "project": "spring-framework"}
{"id": 6101, "code": "\tpublic ResultMatcher isTooEarly() {\n\t\treturn matcher(HttpStatus.valueOf(425));\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 5965, "code": "\tpublic ResultMatcher string(String expectedContent) {\n\t\treturn result -> assertEquals(\"Response content\", expectedContent, result.getResponse().getContentAsString());\n\t}", "summary_tokens": ["assert", "the", "response", "body", "content", "as", "a", "string"], "project": "spring-framework"}
{"id": 920, "code": "\tvoid emptyPropertiesIgnored() throws Exception {\n\t\t@SuppressWarnings(\"unused\") class C {\n\t\t\tpublic Object set(Object o) { return null; }\n\t\t\tpublic Object set(int i, Object o) { return null; }\n\t\t}\n\n\t\tBeanInfo bi = Introspector.getBeanInfo(C.class);\n\t\tBeanInfo ebi = new ExtendedBeanInfo(bi);\n\n\t\tassertThat(ebi.getPropertyDescriptors()).isEqualTo(bi.getPropertyDescriptors());\n\t}", "summary_tokens": ["ensures", "that", "an", "empty", "string", "is", "not", "passed", "into", "a", "property", "descriptor", "constructor"], "project": "spring-framework"}
{"id": 3527, "code": "\tpublic static void insertArrayStore(MethodVisitor mv, String arrayElementType) {\n\t\tif (arrayElementType.length()==1) {\n\t\t\tswitch (arrayElementType.charAt(0)) {\n\t\t\t\tcase 'I':\n\t\t\t\t\tmv.visitInsn(IASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'J':\n\t\t\t\t\tmv.visitInsn(LASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'F':\n\t\t\t\t\tmv.visitInsn(FASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'D':\n\t\t\t\t\tmv.visitInsn(DASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'B':\n\t\t\t\t\tmv.visitInsn(BASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'C':\n\t\t\t\t\tmv.visitInsn(CASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'S':\n\t\t\t\t\tmv.visitInsn(SASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'Z':\n\t\t\t\t\tmv.visitInsn(BASTORE);\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\t\t\"Unexpected arraytype \" + arrayElementType.charAt(0));\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tmv.visitInsn(AASTORE);\n\t\t}\n\t}", "summary_tokens": ["produce", "appropriate", "bytecode", "to", "store", "a", "stack", "item", "in", "an", "array"], "project": "spring-framework"}
{"id": 3363, "code": "\tpublic static <T> Comparator<T> nullsHigh(Comparator<T> comparator) {\n\t\treturn new NullSafeComparator<>(comparator, false);\n\t}", "summary_tokens": ["return", "a", "decorator", "for", "the", "given", "comparator", "which", "accepts", "null", "values", "and", "sorts", "them", "higher", "than", "non", "null", "values"], "project": "spring-framework"}
{"id": 966, "code": "\tprivate void refreshCommonCaches() {\n\t\tfor (Map.Entry<String, Cache> entry : this.cacheMap.entrySet()) {\n\t\t\tif (!this.customCacheNames.contains(entry.getKey())) {\n\t\t\t\tentry.setValue(createCaffeineCache(entry.getKey()));\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["recreate", "the", "common", "caches", "with", "the", "current", "state", "of", "this", "manager"], "project": "spring-framework"}
{"id": 8809, "code": "\tpublic List<HandlerMapping> getHandlerMappings() {\n\t\treturn (this.handlerMappings != null ? this.handlerMappings : Collections.emptyList());\n\t}", "summary_tokens": ["return", "the", "configured", "or", "detected", "handler", "mapping", "s"], "project": "spring-framework"}
{"id": 4421, "code": "\tpublic void setAcceptMessagesWhileStopping(boolean acceptMessagesWhileStopping) {\n\t\tthis.acceptMessagesWhileStopping = acceptMessagesWhileStopping;\n\t}", "summary_tokens": ["set", "whether", "to", "accept", "received", "messages", "while", "the", "listener", "container", "in", "the", "process", "of", "stopping"], "project": "spring-framework"}
{"id": 1480, "code": "\tpublic ZoneId getTimeZone() {\n\t\treturn this.timeZone;\n\t}", "summary_tokens": ["return", "the", "user", "s", "time", "zone", "if", "any"], "project": "spring-framework"}
{"id": 1683, "code": "\tpublic void setEnvironmentMap(@Nullable Map<String, ?> environment) {\n\t\tif (environment != null) {\n\t\t\tthis.environment.putAll(environment);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "environment", "properties", "used", "to", "construct", "the", "jmxconnector", "as", "a", "map", "of", "string", "keys", "and", "arbitrary", "object", "values"], "project": "spring-framework"}
{"id": 2294, "code": "\tpublic FieldHintPredicate onField(Field field) {\n\t\tAssert.notNull(field, \"'field' should not be null\");\n\t\treturn new FieldHintPredicate(field);\n\t}", "summary_tokens": ["return", "a", "predicate", "that", "checks", "whether", "a", "reflection", "hint", "is", "registered", "for", "the", "given", "field"], "project": "spring-framework"}
{"id": 4375, "code": "\tprotected void doStop() throws JMSException {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tthis.running = false;\n\t\t\tthis.lifecycleMonitor.notifyAll();\n\t\t}\n\n\t\tif (sharedConnectionEnabled()) {\n\t\t\tstopSharedConnection();\n\t\t}\n\t}", "summary_tokens": ["notify", "all", "invoker", "tasks", "and", "stop", "the", "shared", "connection", "if", "any"], "project": "spring-framework"}
{"id": 3202, "code": "\tpublic void setDaemon(boolean daemon) {\n\t\tthis.daemon = daemon;\n\t}", "summary_tokens": ["set", "whether", "this", "factory", "is", "supposed", "to", "create", "daemon", "threads", "just", "executing", "as", "long", "as", "the", "application", "itself", "is", "running"], "project": "spring-framework"}
{"id": 4474, "code": "\tpublic void stop(Runnable callback) throws JmsException {\n\t\tsynchronized (this.lifecycleMonitor) {\n\t\t\tif (!isRunning() || this.stopCallback != null) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tcallback.run();\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tthis.stopCallback = callback;\n\t\t}\n\t\tstop();\n\t}", "summary_tokens": ["stop", "this", "listener", "container", "invoking", "the", "specific", "callback", "once", "all", "listener", "processing", "has", "actually", "stopped"], "project": "spring-framework"}
{"id": 9076, "code": "\tprotected String resolveUrlPath(String resourcePath, HttpServletRequest request,\n\t\t\tResource resource, ResourceTransformerChain transformerChain) {\n\n\t\tif (resourcePath.startsWith(\"/\")) {\n\t\t\t\n\t\t\tResourceUrlProvider urlProvider = findResourceUrlProvider(request);\n\t\t\treturn (urlProvider != null ? urlProvider.getForRequestUrl(request, resourcePath) : null);\n\t\t}\n\t\telse {\n\t\t\t\n\t\t\treturn transformerChain.getResolverChain().resolveUrlPath(\n\t\t\t\t\tresourcePath, Collections.singletonList(resource));\n\t\t}\n\t}", "summary_tokens": ["a", "transformer", "can", "use", "this", "method", "when", "a", "resource", "being", "transformed", "contains", "links", "to", "other", "resources"], "project": "spring-framework"}
{"id": 5840, "code": "\tpublic static ContentRequestMatchers content() {\n\t\treturn new ContentRequestMatchers();\n\t}", "summary_tokens": ["access", "to", "request", "body", "matchers"], "project": "spring-framework"}
{"id": 2120, "code": "\tvoid repro() {\n\t\tAnnotationConfigApplicationContext ctx = new AnnotationConfigApplicationContext(Config.class);\n\t\tctx.close();\n\t}", "summary_tokens": ["this", "test", "failed", "with", "conflicting", "bean", "definition", "exception", "prior", "to", "fixes", "for", "spr", "0"], "project": "spring-framework"}
{"id": 3815, "code": "\tvoid setNamedParameterCount(int namedParameterCount) {\n\t\tthis.namedParameterCount = namedParameterCount;\n\t}", "summary_tokens": ["set", "the", "count", "of", "named", "parameters", "in", "the", "sql", "statement"], "project": "spring-framework"}
{"id": 8109, "code": "\tstatic <T extends ServerResponse, R extends ServerResponse> HandlerFilterFunction<T, R> ofResponseProcessor(\n\t\t\tFunction<T, Mono<R>> responseProcessor) {\n\n\t\tAssert.notNull(responseProcessor, \"Function must not be null\");\n\t\treturn (request, next) -> next.handle(request).flatMap(responseProcessor);\n\t}", "summary_tokens": ["adapt", "the", "given", "response", "processor", "function", "to", "a", "filter", "function", "that", "only", "operates", "on", "the", "server", "response"], "project": "spring-framework"}
{"id": 6146, "code": "\tpublic void transactionalWithJUnitTimeout() {\n\t\tassertThatTransaction().isNotActive();\n\t}", "summary_tokens": ["overridden", "since", "spring", "s", "rule", "based", "junit", "support", "cannot", "properly", "integrate", "with", "timed", "execution", "that", "is", "controlled", "by", "a", "third", "party", "runner"], "project": "spring-framework"}
{"id": 9069, "code": "\tpublic void setContentCodings(List<String> codings) {\n\t\tAssert.notEmpty(codings, \"At least one content coding expected\");\n\t\tthis.contentCodings.clear();\n\t\tthis.contentCodings.addAll(codings);\n\t}", "summary_tokens": ["configure", "the", "supported", "content", "codings", "in", "order", "of", "preference"], "project": "spring-framework"}
{"id": 9662, "code": "\tprotected Feed newFeed() {\n\t\treturn new Feed(this.feedType);\n\t}", "summary_tokens": ["create", "a", "new", "feed", "instance", "to", "hold", "the", "entries"], "project": "spring-framework"}
{"id": 9120, "code": "\tpublic final Locale getLocale() {\n\t\treturn (this.locale != null ? this.locale : getFallbackLocale());\n\t}", "summary_tokens": ["return", "the", "current", "locale", "falling", "back", "to", "the", "request", "locale", "never", "null"], "project": "spring-framework"}
{"id": 7353, "code": "\tprotected void initBeanDefinitionReader(GroovyBeanDefinitionReader beanDefinitionReader) {\n\t}", "summary_tokens": ["initialize", "the", "bean", "definition", "reader", "used", "for", "loading", "the", "bean", "definitions", "of", "this", "context"], "project": "spring-framework"}
{"id": 8915, "code": "\tpublic boolean isEmpty() {\n\t\treturn this.expressions.isEmpty();\n\t}", "summary_tokens": ["whether", "the", "condition", "has", "any", "media", "type", "expressions"], "project": "spring-framework"}
{"id": 5794, "code": "\tprotected String getRequestDetails() {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tsb.append(this.requests.size()).append(\" request(s) executed\");\n\t\tif (!this.requests.isEmpty()) {\n\t\t\tsb.append(\":\\n\");\n\t\t\tfor (ClientHttpRequest request : this.requests) {\n\t\t\t\tsb.append(request.toString()).append('\\n');\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tsb.append(\".\\n\");\n\t\t}\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["return", "details", "of", "executed", "requests"], "project": "spring-framework"}
{"id": 3013, "code": "\tpublic static Properties loadAllProperties(String resourceName, @Nullable ClassLoader classLoader) throws IOException {\n\t\tAssert.notNull(resourceName, \"Resource name must not be null\");\n\t\tClassLoader classLoaderToUse = classLoader;\n\t\tif (classLoaderToUse == null) {\n\t\t\tclassLoaderToUse = ClassUtils.getDefaultClassLoader();\n\t\t}\n\t\tEnumeration<URL> urls = (classLoaderToUse != null ? classLoaderToUse.getResources(resourceName) :\n\t\t\t\tClassLoader.getSystemResources(resourceName));\n\t\tProperties props = new Properties();\n\t\twhile (urls.hasMoreElements()) {\n\t\t\tURL url = urls.nextElement();\n\t\t\tURLConnection con = url.openConnection();\n\t\t\tResourceUtils.useCachesIfNecessary(con);\n\t\t\ttry (InputStream is = con.getInputStream()) {\n\t\t\t\tif (resourceName.endsWith(XML_FILE_EXTENSION)) {\n\t\t\t\t\tif (shouldIgnoreXml) {\n\t\t\t\t\t\tthrow new UnsupportedOperationException(\"XML support disabled\");\n\t\t\t\t\t}\n\t\t\t\t\tprops.loadFromXML(is);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tprops.load(is);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn props;\n\t}", "summary_tokens": ["load", "all", "properties", "from", "the", "specified", "class", "path", "resource", "in", "iso", "0", "0", "encoding", "using", "the", "given", "class", "loader"], "project": "spring-framework"}
{"id": 3650, "code": "\tpublic String getSql() {\n\t\treturn this.sql;\n\t}", "summary_tokens": ["return", "the", "sql", "that", "caused", "the", "problem"], "project": "spring-framework"}
{"id": 5295, "code": "\tpublic void setDatabasePlatform(@Nullable String databasePlatform) {\n\t\tthis.databasePlatform = databasePlatform;\n\t}", "summary_tokens": ["specify", "the", "name", "of", "the", "target", "database", "to", "operate", "on"], "project": "spring-framework"}
{"id": 921, "code": "\tvoid reproSpr8522() throws Exception {\n\t\t@SuppressWarnings(\"unused\") class C {\n\t\t\tpublic Object setDateFormat(String pattern) { return new Object(); }\n\t\t\tpublic Object setDateFormat(int style) { return new Object(); }\n\t\t\tpublic Object setDateFormat(int dateStyle, int timeStyle) { return new Object(); }\n\t\t}\n\t\tBeanInfo bi = Introspector.getBeanInfo(C.class);\n\n\t\tassertThat(hasReadMethodForProperty(bi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasWriteMethodForProperty(bi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasIndexedReadMethodForProperty(bi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasIndexedWriteMethodForProperty(bi, \"dateFormat\")).isFalse();\n\n\t\tBeanInfo ebi = new ExtendedBeanInfo(bi);\n\n\t\tassertThat(hasReadMethodForProperty(bi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasWriteMethodForProperty(bi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasIndexedReadMethodForProperty(bi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasIndexedWriteMethodForProperty(bi, \"dateFormat\")).isFalse();\n\n\t\tassertThat(hasReadMethodForProperty(ebi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasWriteMethodForProperty(ebi, \"dateFormat\")).isTrue();\n\t\tassertThat(hasIndexedReadMethodForProperty(ebi, \"dateFormat\")).isFalse();\n\t\tassertThat(hasIndexedWriteMethodForProperty(ebi, \"dateFormat\")).isFalse();\n\t}", "summary_tokens": ["corners", "the", "bug", "revealed", "by", "spr", "0", "in", "which", "an", "apparently", "indexed", "write", "method", "without", "a", "corresponding", "indexed", "read", "method", "would", "fail", "to", "be", "processed", "correctly", "by", "extended", "bean", "info"], "project": "spring-framework"}
{"id": 5966, "code": "\tpublic ResultMatcher bytes(byte[] expectedContent) {\n\t\treturn result -> assertEquals(\"Response content\", expectedContent, result.getResponse().getContentAsByteArray());\n\t}", "summary_tokens": ["assert", "the", "response", "body", "content", "as", "a", "byte", "array"], "project": "spring-framework"}
{"id": 1525, "code": "\tpublic void setAgentId(String agentId) {\n\t\tthis.agentId = agentId;\n\t}", "summary_tokens": ["set", "the", "agent", "id", "of", "the", "mbean", "server", "to", "locate"], "project": "spring-framework"}
{"id": 8653, "code": "\tpublic boolean hasRegistrations() {\n\t\treturn (this.contentNegotiatingResolver != null || !this.viewResolvers.isEmpty());\n\t}", "summary_tokens": ["whether", "any", "view", "resolvers", "have", "been", "registered"], "project": "spring-framework"}
{"id": 2461, "code": "private Label pushSuccessors(final Label listOfLabelsToProcess) {\n  Label newListOfLabelsToProcess = listOfLabelsToProcess;\n  Edge outgoingEdge = outgoingEdges;\n  while (outgoingEdge != null) {\n      \n      \n    boolean isJsrTarget =\n        (flags & Label.FLAG_SUBROUTINE_CALLER) != 0 && outgoingEdge == outgoingEdges.nextEdge;\n    if (!isJsrTarget && outgoingEdge.successor.nextListElement == null) {\n        \n        \n      outgoingEdge.successor.nextListElement = newListOfLabelsToProcess;\n      newListOfLabelsToProcess = outgoingEdge.successor;\n    }\n    outgoingEdge = outgoingEdge.nextEdge;\n  }\n  return newListOfLabelsToProcess;\n}", "summary_tokens": ["adds", "the", "successors", "of", "this", "label", "in", "the", "method", "s", "control", "flow", "graph", "except", "those", "corresponding", "to", "a", "jsr", "target", "and", "those", "already", "in", "a", "list", "of", "labels", "to", "the", "given", "list", "of", "blocks", "to", "process", "and", "returns", "the", "new", "list"], "project": "spring-framework"}
{"id": 5888, "code": "\tpublic WebTestClient.ResponseSpec contentTypeCompatibleWith(String mediaType) {\n\t\treturn contentTypeCompatibleWith(MediaType.parseMediaType(mediaType));\n\t}", "summary_tokens": ["expect", "a", "content", "type", "header", "compatible", "with", "the", "given", "value"], "project": "spring-framework"}
{"id": 4041, "code": "\tpublic void setContinueOnError(boolean continueOnError) {\n\t\tthis.continueOnError = continueOnError;\n\t}", "summary_tokens": ["flag", "to", "indicate", "that", "all", "failures", "in", "sql", "should", "be", "logged", "but", "not", "cause", "a", "failure"], "project": "spring-framework"}
{"id": 9592, "code": "\tprotected String updateTargetUrl(String targetUrl, Map<String, Object> model,\n\t\t\tHttpServletRequest request, HttpServletResponse response) {\n\n\t\tWebApplicationContext wac = getWebApplicationContext();\n\t\tif (wac == null) {\n\t\t\twac = RequestContextUtils.findWebApplicationContext(request, getServletContext());\n\t\t}\n\n\t\tif (wac != null && wac.containsBean(RequestContextUtils.REQUEST_DATA_VALUE_PROCESSOR_BEAN_NAME)) {\n\t\t\tRequestDataValueProcessor processor = wac.getBean(\n\t\t\t\t\tRequestContextUtils.REQUEST_DATA_VALUE_PROCESSOR_BEAN_NAME, RequestDataValueProcessor.class);\n\t\t\treturn processor.processUrl(request, targetUrl);\n\t\t}\n\n\t\treturn targetUrl;\n\t}", "summary_tokens": ["find", "the", "registered", "request", "data", "value", "processor", "if", "any", "and", "allow", "it", "to", "update", "the", "redirect", "target", "url"], "project": "spring-framework"}
{"id": 1212, "code": "\tprotected final Log getLogger() {\n\t\treturn logger;\n\t}", "summary_tokens": ["get", "the", "logger", "for", "this", "logging", "cache", "error", "handler"], "project": "spring-framework"}
{"id": 7026, "code": "\tpublic FilterProvider getFilters() {\n\t\treturn this.filters;\n\t}", "summary_tokens": ["return", "the", "jackson", "filter", "provider", "to", "use"], "project": "spring-framework"}
{"id": 6557, "code": "\tpublic static void setCurrentTransactionIsolationLevel(@Nullable Integer isolationLevel) {\n\t\tcurrentTransactionIsolationLevel.set(isolationLevel);\n\t}", "summary_tokens": ["expose", "an", "isolation", "level", "for", "the", "current", "transaction"], "project": "spring-framework"}
{"id": 3847, "code": "\tpublic final synchronized void compile() throws InvalidDataAccessApiUsageException {\n\t\tif (!isCompiled()) {\n\t\t\tif (getProcedureName() == null) {\n\t\t\t\tthrow new InvalidDataAccessApiUsageException(\"Procedure or Function name is required\");\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tthis.jdbcTemplate.afterPropertiesSet();\n\t\t\t}\n\t\t\tcatch (IllegalArgumentException ex) {\n\t\t\t\tthrow new InvalidDataAccessApiUsageException(ex.getMessage());\n\t\t\t}\n\t\t\tcompileInternal();\n\t\t\tthis.compiled = true;\n\t\t\tif (logger.isDebugEnabled()) {\n\t\t\t\tlogger.debug(\"SqlCall for \" + (isFunction() ? \"function\" : \"procedure\") +\n\t\t\t\t\t\t\" [\" + getProcedureName() + \"] compiled\");\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["compile", "this", "jdbc", "call", "using", "provided", "parameters", "and", "meta", "data", "plus", "other", "settings"], "project": "spring-framework"}
{"id": 2938, "code": "\tpublic boolean isReadable() {\n\t\treturn (this.file != null ? this.file.canRead() && !this.file.isDirectory() :\n\t\t\t\tFiles.isReadable(this.filePath) && !Files.isDirectory(this.filePath));\n\t}", "summary_tokens": ["this", "implementation", "checks", "whether", "the", "underlying", "file", "is", "marked", "as", "readable", "and", "corresponds", "to", "an", "actual", "file", "with", "content", "not", "to", "a", "directory"], "project": "spring-framework"}
{"id": 5963, "code": "\tpublic ResultMatcher contentTypeCompatibleWith(MediaType contentType) {\n\t\treturn result -> {\n\t\t\tString actual = result.getResponse().getContentType();\n\t\t\tassertNotNull(\"Content type not set\", actual);\n\t\t\tMediaType actualContentType = MediaType.parseMediaType(actual);\n\t\t\tassertTrue(\"Content type [\" + actual + \"] is not compatible with [\" + contentType + \"]\",\n\t\t\t\t\tactualContentType.isCompatibleWith(contentType));\n\t\t};\n\t}", "summary_tokens": ["assert", "the", "servlet", "response", "content", "type", "is", "compatible", "with", "the", "given", "content", "type", "as", "defined", "by", "media", "type", "is", "compatible", "with", "media", "type"], "project": "spring-framework"}
{"id": 4214, "code": "\tpublic void setEndpointRegistry(JmsListenerEndpointRegistry endpointRegistry) {\n\t\tthis.endpointRegistry = endpointRegistry;\n\t}", "summary_tokens": ["set", "the", "jms", "listener", "endpoint", "registry", "that", "will", "hold", "the", "created", "endpoint", "and", "manage", "the", "lifecycle", "of", "the", "related", "listener", "container"], "project": "spring-framework"}
{"id": 8341, "code": "\tpublic String getDisplayValue() {\n\t\tif (this.value instanceof String) {\n\t\t\treturn (String) this.value;\n\t\t}\n\t\tif (this.value != null) {\n\t\t\treturn (this.htmlEscape ?\n\t\t\t\t\tHtmlUtils.htmlEscape(this.value.toString()) : this.value.toString());\n\t\t}\n\t\treturn \"\";\n\t}", "summary_tokens": ["return", "a", "suitable", "display", "value", "for", "the", "field", "i"], "project": "spring-framework"}
{"id": 8060, "code": "\tpublic static BodyExtractor<Flux<DataBuffer>, ReactiveHttpInputMessage> toDataBuffers() {\n\t\treturn (inputMessage, context) -> inputMessage.getBody();\n\t}", "summary_tokens": ["extractor", "that", "returns", "the", "raw", "data", "buffer", "data", "buffers"], "project": "spring-framework"}
{"id": 352, "code": "\tprivate PropertyEditor getCustomEditor(@Nullable Class<?> requiredType) {\n\t\tif (requiredType == null || this.customEditors == null) {\n\t\t\treturn null;\n\t\t}\n\t\t\n\t\tPropertyEditor editor = this.customEditors.get(requiredType);\n\t\tif (editor == null) {\n\t\t\t\n\t\t\tif (this.customEditorCache != null) {\n\t\t\t\teditor = this.customEditorCache.get(requiredType);\n\t\t\t}\n\t\t\tif (editor == null) {\n\t\t\t\t\n\t\t\t\tfor (Map.Entry<Class<?>, PropertyEditor> entry : this.customEditors.entrySet()) {\n\t\t\t\t\tClass<?> key = entry.getKey();\n\t\t\t\t\tif (key.isAssignableFrom(requiredType)) {\n\t\t\t\t\t\teditor = entry.getValue();\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\tif (this.customEditorCache == null) {\n\t\t\t\t\t\t\tthis.customEditorCache = new HashMap<>();\n\t\t\t\t\t\t}\n\t\t\t\t\t\tthis.customEditorCache.put(requiredType, editor);\n\t\t\t\t\t\tif (editor != null) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn editor;\n\t}", "summary_tokens": ["get", "custom", "editor", "for", "the", "given", "type"], "project": "spring-framework"}
{"id": 8463, "code": "\tpublic Consumer<ConnectionBuilder> getConnectionBuilderConsumer() {\n\t\treturn this.builderConsumer;\n\t}", "summary_tokens": ["return", "the", "configured", "code", "consumer", "lt", "connection", "builder", "gt", "code"], "project": "spring-framework"}
{"id": 8545, "code": "\tpublic ModelMap getModelMap() {\n\t\tif (this.model == null) {\n\t\t\tthis.model = new ModelMap();\n\t\t}\n\t\treturn this.model;\n\t}", "summary_tokens": ["return", "the", "underlying", "model", "map", "instance", "never", "null"], "project": "spring-framework"}
{"id": 4924, "code": "\tpublic int getBufferSize() {\n\t\tint size = 0;\n\t\tfor (ByteBuffer buffer : this.chunks) {\n\t\t\tsize = size + buffer.remaining();\n\t\t}\n\t\treturn size;\n\t}", "summary_tokens": ["calculate", "the", "current", "buffer", "size"], "project": "spring-framework"}
{"id": 4825, "code": "\tpublic static SimpAttributes getAttributes() {\n\t\treturn attributesHolder.get();\n\t}", "summary_tokens": ["return", "the", "simp", "attributes", "currently", "bound", "to", "the", "thread"], "project": "spring-framework"}
{"id": 7098, "code": "\tpublic void setInstance(@Nullable URI instance) {\n\t\tthis.body.setInstance(instance);\n\t}", "summary_tokens": ["set", "the", "problem", "detail", "set", "instance", "uri", "instance", "field", "of", "the", "response", "body"], "project": "spring-framework"}
{"id": 5479, "code": "\tpublic Map<String, ? extends ServletRegistration> getServletRegistrations() {\n\t\treturn Collections.emptyMap();\n\t}", "summary_tokens": ["this", "method", "always", "returns", "an", "collections", "empty", "map", "empty", "map"], "project": "spring-framework"}
{"id": 2427, "code": "static int getAbstractTypeFromInternalName(\n    final SymbolTable symbolTable, final String internalName) {\n  return REFERENCE_KIND | symbolTable.addType(internalName);\n}", "summary_tokens": ["returns", "the", "abstract", "type", "corresponding", "to", "the", "internal", "name", "of", "a", "class"], "project": "spring-framework"}
{"id": 6412, "code": "\tpublic void setCurrentTransactionIsolationLevel(@Nullable Integer isolationLevel) {\n\t\tthis.transactionContext.setCurrentTransactionIsolationLevel(isolationLevel);\n\t}", "summary_tokens": ["expose", "an", "isolation", "level", "for", "the", "current", "transaction"], "project": "spring-framework"}
{"id": 5313, "code": "\tprotected String getDefaultEncoding() {\n\t\treturn null;\n\t}", "summary_tokens": ["determine", "the", "default", "encoding", "to", "use", "for", "marshalling", "or", "unmarshalling", "from", "a", "byte", "stream", "or", "null", "if", "none"], "project": "spring-framework"}
{"id": 4790, "code": "\tstatic RSocketRequester.Builder builder() {\n\t\treturn new DefaultRSocketRequesterBuilder();\n\t}", "summary_tokens": ["obtain", "a", "builder", "to", "create", "a", "client", "rsocket", "requester", "by", "connecting", "to", "an", "rsocket", "server"], "project": "spring-framework"}
{"id": 6964, "code": "\tpublic Jackson2ObjectMapperBuilder autoDetectFields(boolean autoDetectFields) {\n\t\tthis.features.put(MapperFeature.AUTO_DETECT_FIELDS, autoDetectFields);\n\t\treturn this;\n\t}", "summary_tokens": ["shortcut", "for", "mapper", "feature", "auto", "detect", "fields", "option"], "project": "spring-framework"}
{"id": 5222, "code": "\tpublic void setPersistenceUnitRootLocation(String defaultPersistenceUnitRootLocation) {\n\t\tthis.internalPersistenceUnitManager.setDefaultPersistenceUnitRootLocation(defaultPersistenceUnitRootLocation);\n\t}", "summary_tokens": ["set", "a", "persistence", "unit", "root", "location", "for", "the", "default", "persistence", "unit"], "project": "spring-framework"}
{"id": 5468, "code": "\tprotected PrintWriter getTargetWriter() throws IOException {\n\t\tif (this.targetWriter == null) {\n\t\t\tthis.targetWriter = this.response.getWriter();\n\t\t}\n\t\treturn this.targetWriter;\n\t}", "summary_tokens": ["lazily", "initialize", "the", "target", "writer"], "project": "spring-framework"}
{"id": 1991, "code": "\tpublic boolean isIgnoreInvalidFields() {\n\t\treturn this.ignoreInvalidFields;\n\t}", "summary_tokens": ["return", "whether", "to", "ignore", "invalid", "fields", "when", "binding"], "project": "spring-framework"}
{"id": 3912, "code": "\tpublic PrintWriter getLogWriter() {\n\t\tthrow new UnsupportedOperationException(\"getLogWriter\");\n\t}", "summary_tokens": ["log", "writer", "methods", "are", "not", "supported"], "project": "spring-framework"}
{"id": 5780, "code": "\tpublic void assertNumber(byte[] content, @Nullable String encoding, Double expectedValue) throws Exception {\n\t\tDouble actual = evaluateXpath(content, encoding, Double.class);\n\t\tAssertionErrors.assertEquals(\"XPath \" + this.expression, expectedValue, actual);\n\t}", "summary_tokens": ["apply", "the", "xpath", "expression", "and", "assert", "the", "resulting", "content", "as", "a", "double"], "project": "spring-framework"}
{"id": 8083, "code": "\tdefault ExchangeFunction apply(ExchangeFunction exchange) {\n\t\tAssert.notNull(exchange, \"ExchangeFunction must not be null\");\n\t\treturn request -> this.filter(request, exchange);\n\t}", "summary_tokens": ["apply", "this", "filter", "to", "the", "given", "exchange", "function", "resulting", "in", "a", "filtered", "exchange", "function"], "project": "spring-framework"}
{"id": 1961, "code": "\tprotected PropertyEditor getCustomEditor(String fixedField) {\n\t\tClass<?> targetType = getPropertyAccessor().getPropertyType(fixedField);\n\t\tPropertyEditor editor = getPropertyAccessor().findCustomEditor(targetType, fixedField);\n\t\tif (editor == null) {\n\t\t\teditor = BeanUtils.findEditorByConvention(targetType);\n\t\t}\n\t\treturn editor;\n\t}", "summary_tokens": ["retrieve", "the", "custom", "property", "editor", "for", "the", "given", "field", "if", "any"], "project": "spring-framework"}
{"id": 667, "code": "\tpublic static void registerBeanDefinition(\n\t\t\tBeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry)\n\t\t\tthrows BeanDefinitionStoreException {\n\n\t\t\n\t\tString beanName = definitionHolder.getBeanName();\n\t\tregistry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition());\n\n\t\t\n\t\tString[] aliases = definitionHolder.getAliases();\n\t\tif (aliases != null) {\n\t\t\tfor (String alias : aliases) {\n\t\t\t\tregistry.registerAlias(beanName, alias);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["register", "the", "given", "bean", "definition", "with", "the", "given", "bean", "factory"], "project": "spring-framework"}
{"id": 763, "code": "\tboolean hasAnyExternallyManagedInitMethod(String initMethod) {\n\t\tsynchronized (this.postProcessingLock) {\n\t\t\tif (isExternallyManagedInitMethod(initMethod)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\tif (this.externallyManagedInitMethods != null) {\n\t\t\t\tfor (String candidate : this.externallyManagedInitMethods) {\n\t\t\t\t\tint indexOfDot = candidate.lastIndexOf('.');\n\t\t\t\t\tif (indexOfDot >= 0) {\n\t\t\t\t\t\tString methodName = candidate.substring(indexOfDot + 1);\n\t\t\t\t\t\tif (methodName.equals(initMethod)) {\n\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["determine", "if", "the", "given", "method", "name", "indicates", "an", "externally", "managed", "initialization", "method", "regardless", "of", "method", "visibility"], "project": "spring-framework"}
{"id": 9564, "code": "\tprotected void exposeHelpers(HttpServletRequest request) throws Exception {\n\t}", "summary_tokens": ["expose", "helpers", "unique", "to", "each", "rendering", "operation"], "project": "spring-framework"}
{"id": 393, "code": "\tpublic AnnotatedElement getAnnotatedElement() {\n\t\treturn (this.field != null ? this.field : obtainMethodParameter().getAnnotatedElement());\n\t}", "summary_tokens": ["return", "the", "wrapped", "annotated", "element"], "project": "spring-framework"}
{"id": 8883, "code": "\tpublic Set<MediaTypeExpression> getExpressions() {\n\t\treturn new LinkedHashSet<>(this.expressions);\n\t}", "summary_tokens": ["return", "the", "contained", "media", "type", "expressions"], "project": "spring-framework"}
{"id": 5863, "code": "\tpublic WebTestClient.ResponseSpec valueEquals(String name, String value) {\n\t\tthis.exchangeResult.assertWithDiagnostics(() -> {\n\t\t\tString message = getMessage(name);\n\t\t\tAssertionErrors.assertEquals(message, value, getCookie(name).getValue());\n\t\t});\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["expect", "a", "header", "with", "the", "given", "name", "to", "match", "the", "specified", "values"], "project": "spring-framework"}
{"id": 4518, "code": "\tpublic void setHandlerMethod(InvocableHandlerMethod handlerMethod) {\n\t\tthis.handlerMethod = handlerMethod;\n\t}", "summary_tokens": ["set", "the", "invocable", "handler", "method", "to", "use", "to", "invoke", "the", "method", "processing", "an", "incoming", "jakarta"], "project": "spring-framework"}
{"id": 590, "code": "\tpublic Entry peek() {\n\t\treturn this.state.peek();\n\t}", "summary_tokens": ["return", "the", "entry", "currently", "at", "the", "top", "of", "the", "array", "deque", "or", "null", "if", "the", "array", "deque", "is", "empty"], "project": "spring-framework"}
{"id": 2060, "code": "\tpublic void setValidatedAnnotationType(Class<? extends Annotation> validatedAnnotationType) {\n\t\tAssert.notNull(validatedAnnotationType, \"'validatedAnnotationType' must not be null\");\n\t\tthis.validatedAnnotationType = validatedAnnotationType;\n\t}", "summary_tokens": ["set", "the", "validated", "annotation", "type"], "project": "spring-framework"}
{"id": 76, "code": "\tdefault int getAdvisorCount() {\n\t\treturn getAdvisors().length;\n\t}", "summary_tokens": ["return", "the", "number", "of", "advisors", "applying", "to", "this", "proxy"], "project": "spring-framework"}
{"id": 2403, "code": "public int newPackage(final String packageName) {\n  return symbolTable.addConstantPackage(packageName).index;\n}", "summary_tokens": ["adds", "a", "package", "reference", "to", "the", "constant", "pool", "of", "the", "class", "being", "build"], "project": "spring-framework"}
{"id": 3354, "code": "\tpublic long getMaxInterval() {\n\t\treturn this.maxInterval;\n\t}", "summary_tokens": ["return", "the", "maximum", "back", "off", "time"], "project": "spring-framework"}
{"id": 4851, "code": "\tpublic void setDestinationPrefixes(@Nullable Collection<String> prefixes) {\n\t\tsuper.setDestinationPrefixes(appendSlashes(prefixes));\n\t}", "summary_tokens": ["p", "destination", "prefixes", "are", "expected", "to", "be", "slash", "separated", "strings", "and", "therefore", "a", "slash", "is", "automatically", "appended", "where", "missing", "to", "ensure", "a", "proper", "prefix", "based", "match", "i"], "project": "spring-framework"}
{"id": 6531, "code": "\tprotected void cleanupResource(H resourceHolder, K resourceKey, boolean committed) {\n\t}", "summary_tokens": ["perform", "a", "cleanup", "on", "the", "given", "resource", "which", "is", "left", "bound", "to", "the", "thread"], "project": "spring-framework"}
{"id": 1799, "code": "\tpublic void setJndiTemplate(JndiTemplate jndiTemplate) {\n\t\tthis.jndiLocator.setJndiTemplate(jndiTemplate);\n\t}", "summary_tokens": ["set", "the", "jndi", "template", "to", "use", "for", "jndi", "lookups"], "project": "spring-framework"}
{"id": 9481, "code": "\tpublic void forceBlock() throws JspException {\n\t\tif (currentState().isBlockTag()) {\n\t\t\treturn; \n\t\t}\n\t\tcloseTagAndMarkAsBlock();\n\t}", "summary_tokens": ["indicate", "that", "the", "currently", "open", "tag", "should", "be", "closed", "and", "marked", "as", "a", "block", "level", "element"], "project": "spring-framework"}
{"id": 909, "code": "\tvoid copyPropertiesFromSubTypeToSuperType() {\n\t\tIntegerHolder integerHolder = new IntegerHolder();\n\t\tintegerHolder.setNumber(42);\n\t\tNumberHolder numberHolder = new NumberHolder();\n\n\t\tBeanUtils.copyProperties(integerHolder, numberHolder);\n\t\tassertThat(integerHolder.getNumber()).isEqualTo(42);\n\t\tassertThat(numberHolder.getNumber()).isEqualTo(42);\n\t}", "summary_tokens": ["integer", "can", "be", "copied", "to", "number"], "project": "spring-framework"}
{"id": 7915, "code": "\tpublic Flux<DataBuffer> getBody() {\n\t\treturn this.body;\n\t}", "summary_tokens": ["return", "the", "request", "body", "or", "an", "error", "stream", "if", "the", "body", "was", "never", "set", "or", "when", "set", "write", "handler", "is", "configured"], "project": "spring-framework"}
{"id": 3655, "code": "\tpublic int getExpectedRowsAffected() {\n\t\treturn this.expected;\n\t}", "summary_tokens": ["return", "the", "number", "of", "rows", "that", "should", "have", "been", "affected"], "project": "spring-framework"}
{"id": 3673, "code": "\tprotected T constructMappedInstance(ResultSet rs, TypeConverter tc) throws SQLException  {\n\t\tAssert.state(this.mappedClass != null, \"Mapped class was not specified\");\n\t\treturn BeanUtils.instantiateClass(this.mappedClass);\n\t}", "summary_tokens": ["construct", "an", "instance", "of", "the", "mapped", "class", "for", "the", "current", "row"], "project": "spring-framework"}
{"id": 3649, "code": "\tpublic SQLException getSQLException() {\n\t\treturn (SQLException) getCause();\n\t}", "summary_tokens": ["return", "the", "wrapped", "sqlexception"], "project": "spring-framework"}
{"id": 6084, "code": "\tpublic ResultMatcher isGone() {\n\t\treturn matcher(HttpStatus.GONE);\n\t}", "summary_tokens": ["assert", "the", "response", "status", "code", "is", "http", "status"], "project": "spring-framework"}
{"id": 2270, "code": "\tpublic String getPattern() {\n\t\treturn this.pattern;\n\t}", "summary_tokens": ["return", "the", "pattern", "to", "use", "for", "identifying", "the", "resources", "to", "match"], "project": "spring-framework"}
{"id": 7520, "code": "\tpublic static void disableContentCaching(ServletRequest request) {\n\t\tAssert.notNull(request, \"ServletRequest must not be null\");\n\t\trequest.setAttribute(STREAMING_ATTRIBUTE, true);\n\t}", "summary_tokens": ["this", "method", "can", "be", "used", "to", "suppress", "the", "content", "caching", "response", "wrapper", "of", "the", "shallow", "etag", "header", "filter"], "project": "spring-framework"}
{"id": 6634, "code": "\tpublic void setAccessControlAllowMethods(List<HttpMethod> allowedMethods) {\n\t\tset(ACCESS_CONTROL_ALLOW_METHODS, StringUtils.collectionToCommaDelimitedString(allowedMethods));\n\t}", "summary_tokens": ["set", "the", "new", "value", "of", "the", "access", "control", "allow", "methods", "response", "header"], "project": "spring-framework"}
{"id": 4403, "code": "\tpublic void setSubscriptionShared(boolean subscriptionShared) {\n\t\tthis.subscriptionShared = subscriptionShared;\n\t\tif (subscriptionShared) {\n\t\t\tsetPubSubDomain(true);\n\t\t}\n\t}", "summary_tokens": ["set", "whether", "to", "make", "the", "subscription", "shared"], "project": "spring-framework"}
{"id": 2816, "code": "\tpublic Log getLogger() {\n\t\treturn logger;\n\t}", "summary_tokens": ["return", "the", "currently", "configured", "logger"], "project": "spring-framework"}
{"id": 7101, "code": "\tpublic MediaType getContentType() {\n\t\treturn this.contentType;\n\t}", "summary_tokens": ["return", "the", "http", "request", "content", "type", "method", "that", "caused", "the", "failure"], "project": "spring-framework"}
{"id": 9892, "code": "\tpublic void setXhrStreamingDisabled(boolean disabled) {\n\t\tthis.xhrStreamingDisabled = disabled;\n\t}", "summary_tokens": ["an", "xhr", "transport", "can", "support", "both", "the", "xhr", "streaming", "and", "xhr", "sock", "js", "server", "transports"], "project": "spring-framework"}
{"id": 5865, "code": "\tpublic WebTestClient.ResponseSpec exists(String name) {\n\t\tgetCookie(name);\n\t\treturn this.responseSpec;\n\t}", "summary_tokens": ["expect", "that", "the", "cookie", "with", "the", "given", "name", "is", "present"], "project": "spring-framework"}
{"id": 7817, "code": "\tpublic String toUriString() {\n\t\treturn (this.uriVariables.isEmpty() ? build().encode().toUriString() :\n\t\t\t\tbuildInternal(EncodingHint.ENCODE_TEMPLATE).toUriString());\n\t}", "summary_tokens": ["build", "a", "uri", "string"], "project": "spring-framework"}
{"id": 6620, "code": "\tpublic boolean hasBody() {\n\t\treturn (this.body != null);\n\t}", "summary_tokens": ["indicates", "whether", "this", "entity", "has", "a", "body"], "project": "spring-framework"}
{"id": 7081, "code": "\tpublic static <T> T getNativeRequest(ServerHttpRequest request) {\n\t\tif (request instanceof AbstractServerHttpRequest) {\n\t\t\treturn ((AbstractServerHttpRequest) request).getNativeRequest();\n\t\t}\n\t\telse if (request instanceof ServerHttpRequestDecorator) {\n\t\t\treturn getNativeRequest(((ServerHttpRequestDecorator) request).getDelegate());\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Can't find native request in \" + request.getClass().getName());\n\t\t}\n\t}", "summary_tokens": ["return", "the", "native", "request", "of", "the", "underlying", "server", "api", "if", "possible", "also", "unwrapping", "server", "http", "request", "decorator", "if", "necessary"], "project": "spring-framework"}
{"id": 5065, "code": "\tpublic Message<?> getOriginalMessage() {\n\t\treturn this.originalMessage;\n\t}", "summary_tokens": ["return", "the", "original", "message", "if", "available", "at", "the", "point", "in", "the", "stack", "where", "the", "error", "message", "was", "created"], "project": "spring-framework"}
{"id": 8193, "code": "\tprotected void registerHandlers(Map<String, Object> urlMap) throws BeansException {\n\t\tif (urlMap.isEmpty()) {\n\t\t\tlogger.trace(\"No patterns in \" + formatMappingName());\n\t\t}\n\t\telse {\n\t\t\tfor (Map.Entry<String, Object> entry : urlMap.entrySet()) {\n\t\t\t\tString url = entry.getKey();\n\t\t\t\tObject handler = entry.getValue();\n\t\t\t\t\n\t\t\t\tif (!url.startsWith(\"/\")) {\n\t\t\t\t\turl = \"/\" + url;\n\t\t\t\t}\n\t\t\t\t\n\t\t\t\tif (handler instanceof String) {\n\t\t\t\t\thandler = ((String) handler).trim();\n\t\t\t\t}\n\t\t\t\tregisterHandler(url, handler);\n\t\t\t}\n\t\t\tlogMappings();\n\t\t}\n\t}", "summary_tokens": ["register", "all", "handlers", "specified", "in", "the", "url", "map", "for", "the", "corresponding", "paths"], "project": "spring-framework"}
{"id": 8146, "code": "\tpublic static <T extends ServerResponse> RouterFunction<T> nest(\n\t\t\tRequestPredicate predicate, RouterFunction<T> routerFunction) {\n\n\t\treturn new DefaultNestedRouterFunction<>(predicate, routerFunction);\n\t}", "summary_tokens": ["route", "to", "the", "given", "router", "function", "if", "the", "given", "request", "predicate", "applies"], "project": "spring-framework"}
{"id": 7737, "code": "\tpublic void setHeaderName(String headerName) {\n\t\tAssert.hasText(headerName, \"'headerName' must not be empty\");\n\t\tthis.headerName = headerName;\n\t}", "summary_tokens": ["set", "the", "name", "of", "the", "session", "header", "to", "use", "for", "the", "session", "id"], "project": "spring-framework"}
{"id": 9440, "code": "\tprivate void renderFromEnum(TagWriter tagWriter) throws JspException {\n\t\tdoRenderFromCollection(CollectionUtils.arrayToList(((Class<?>) this.optionSource).getEnumConstants()), tagWriter);\n\t}", "summary_tokens": ["render", "the", "inner", "option", "tags", "using", "the", "option", "source"], "project": "spring-framework"}
{"id": 6498, "code": "\tpublic Object getTransaction() {\n\t\tAssert.state(this.transaction != null, \"No transaction active\");\n\t\treturn this.transaction;\n\t}", "summary_tokens": ["return", "the", "underlying", "transaction", "object"], "project": "spring-framework"}
{"id": 9910, "code": "\tpublic void setHeartbeatTime(long heartbeatTime) {\n\t\tthis.heartbeatTime = heartbeatTime;\n\t}", "summary_tokens": ["specify", "the", "amount", "of", "time", "in", "milliseconds", "when", "the", "server", "has", "not", "sent", "any", "messages", "and", "after", "which", "the", "server", "should", "send", "a", "heartbeat", "frame", "to", "the", "client", "in", "order", "to", "keep", "the", "connection", "from", "breaking"], "project": "spring-framework"}
{"id": 640, "code": "\tpublic BeanDefinitionBuilder setAbstract(boolean flag) {\n\t\tthis.beanDefinition.setAbstract(flag);\n\t\treturn this;\n\t}", "summary_tokens": ["set", "whether", "this", "definition", "is", "abstract"], "project": "spring-framework"}
{"id": 4391, "code": "\tpublic Destination getDestination() {\n\t\treturn (this.destination instanceof Destination ? (Destination) this.destination : null);\n\t}", "summary_tokens": ["return", "the", "destination", "to", "receive", "messages", "from"], "project": "spring-framework"}
{"id": 9510, "code": "\tpublic void setExposeRequestAttributes(boolean exposeRequestAttributes) {\n\t\tthis.exposeRequestAttributes = exposeRequestAttributes;\n\t}", "summary_tokens": ["set", "whether", "all", "request", "attributes", "should", "be", "added", "to", "the", "model", "prior", "to", "merging", "with", "the", "template"], "project": "spring-framework"}
{"id": 3659, "code": "\tpublic String getSql() {\n\t\treturn this.sql;\n\t}", "summary_tokens": ["return", "the", "sql", "that", "led", "to", "the", "problem", "if", "known"], "project": "spring-framework"}
{"id": 6811, "code": "\tpublic void setHostname(String hostname) {\n\t\tthis.hostname = hostname;\n\t}", "summary_tokens": ["set", "the", "proxy", "host", "name"], "project": "spring-framework"}
{"id": 3473, "code": "\tpublic static ClassPathResource qualifiedResource(Class<?> clazz, String resourceSuffix) {\n\t\treturn new ClassPathResource(String.format(\"%s-%s\", clazz.getSimpleName(), resourceSuffix), clazz);\n\t}", "summary_tokens": ["load", "a", "class", "path", "resource", "qualified", "by", "the", "simple", "name", "of", "clazz", "and", "relative", "to", "the", "package", "for", "clazz"], "project": "spring-framework"}
{"id": 1780, "code": "\tpublic void setBeanFactory(BeanFactory beanFactory) {\n\t\tif (this.advice instanceof BeanFactoryAware) {\n\t\t\t((BeanFactoryAware) this.advice).setBeanFactory(beanFactory);\n\t\t}\n\t}", "summary_tokens": ["set", "the", "bean", "factory", "to", "be", "used", "when", "looking", "up", "executors", "by", "qualifier"], "project": "spring-framework"}
{"id": 16, "code": "public static ClassName adapterName(ClassName type, String suffix) {\n  return ClassName.get(type.packageName(),\n      Joiner.on('$').join(type.simpleNames()) + suffix);\n}", "summary_tokens": ["returns", "a", "class", "name", "to", "complement", "type"], "project": "dagger"}
{"id": 54, "code": "private static void typeToString(Type type, StringBuilder result, boolean topLevel) {\n  if (type instanceof Class) {\n    Class<?> c = (Class<?>) type;\n    if (c.isArray()) {\n      typeToString(c.getComponentType(), result, false);\n      result.append(\"[]\");\n    } else if (c.isPrimitive()) {\n      if (topLevel) {\n        throw new UnsupportedOperationException(\"Uninjectable type \" + c.getName());\n      }\n      result.append(c.getName());\n    } else {\n      result.append(c.getName());\n    }\n  } else if (type instanceof ParameterizedType) {\n    ParameterizedType parameterizedType = (ParameterizedType) type;\n    typeToString(parameterizedType.getRawType(), result, true);\n    Type[] arguments = parameterizedType.getActualTypeArguments();\n    result.append(\"<\");\n    for (int i = 0; i < arguments.length; i++) {\n      if (i != 0) {\n        result.append(\", \");\n      }\n      typeToString(arguments[i], result, true);\n    }\n    result.append(\">\");\n  } else if (type instanceof GenericArrayType) {\n    GenericArrayType genericArrayType = (GenericArrayType) type;\n    typeToString(genericArrayType.getGenericComponentType(), result, false);\n    result.append(\"[]\");\n  } else {\n    throw new UnsupportedOperationException(\"Uninjectable type \" + type);\n  }\n}", "summary_tokens": ["top", "level", "true", "if", "this", "is", "a", "top", "level", "type", "where", "primitive", "types", "like", "int", "are", "forbidden"], "project": "dagger"}
{"id": 75, "code": "public void getBindings(BindingsGroup map, T module) {\n    \n}", "summary_tokens": ["returns", "bindings", "for", "the", "methods", "of", "module"], "project": "dagger"}
{"id": 8, "code": "@Override public boolean process(Set<? extends TypeElement> types, RoundEnvironment env) {\n  if (!env.processingOver()) {\n      \n      \n    for (Element e : env.getElementsAnnotatedWith(Module.class)) {\n      if (!(e instanceof TypeElement)) {\n        error(\"@Module applies to a type, \" + e.getSimpleName() + \" is a \" + e.getKind(), e);\n        continue;\n      }\n      delayedModuleNames.add(((TypeElement) e).getQualifiedName().toString());\n    }\n    return false;\n  }\n\n  Set<Element> modules = new LinkedHashSet<Element>();\n  for (String moduleName : delayedModuleNames) {\n    modules.add(elements().getTypeElement(moduleName));\n  }\n\n  for (Element element : modules) {\n    Map<String, Object> annotation = null;\n    try {\n      annotation = getAnnotation(Module.class, element);\n    } catch (CodeGenerationIncompleteException e) {\n      continue; \n    }\n\n    TypeElement moduleType = (TypeElement) element;\n    if (annotation == null) {\n      error(\"Missing @Module annotation.\", moduleType);\n      continue;\n    }\n    if (annotation.get(\"complete\").equals(Boolean.TRUE)) {\n      Map<String, Binding<?>> bindings;\n      try {\n        bindings = processCompleteModule(moduleType, false);\n        new ProblemDetector().detectCircularDependencies(bindings.values());\n      } catch (ModuleValidationException e) {\n        error(\"Graph validation failed: \" + e.getMessage(), e.source);\n        continue;\n      } catch (InvalidBindingException e) {\n        error(\"Graph validation failed: \" + e.getMessage(), elements().getTypeElement(e.type));\n        continue;\n      } catch (RuntimeException e) {\n        if (ERROR_NAMES_TO_PROPAGATE.contains(e.getClass().getName())) {\n          throw e;\n        }\n        error(\"Unknown error \" + e.getClass().getName() + \" thrown by javac in graph validation: \"\n            + e.getMessage(), moduleType);\n        continue;\n      }\n      try {\n        writeDotFile(moduleType, bindings);\n      } catch (IOException e) {\n        StringWriter sw = new StringWriter();\n        e.printStackTrace(new PrintWriter(sw));\n        processingEnv.getMessager()\n            .printMessage(Diagnostic.Kind.WARNING,\n                \"Graph visualization failed. Please report this as a bug.\\n\\n\" + sw, moduleType);\n      }\n    }\n\n    if (annotation.get(\"library\").equals(Boolean.FALSE)) {\n      Map<String, Binding<?>> bindings = processCompleteModule(moduleType, true);\n      try {\n        new ProblemDetector().detectUnusedBinding(bindings.values());\n      } catch (IllegalStateException e) {\n        error(\"Graph validation failed: \" + e.getMessage(), moduleType);\n      }\n    }\n  }\n  return false;\n}", "summary_tokens": ["perform", "full", "graph", "analysis", "on", "complete", "modules"], "project": "dagger"}
{"id": 48, "code": "public void getDependencies(Set<Binding<?>> getBindings, Set<Binding<?>> injectMembersBindings) {\n    \n}", "summary_tokens": ["populates", "get", "bindings", "and", "inject", "members", "bindings", "with", "the", "bindings", "used", "by", "this", "binding", "to", "satisfy", "get", "and", "inject", "members", "calls", "respectively"], "project": "dagger"}
{"id": 19, "code": "public static TypeName injectableType(TypeMirror type) {\n  return type.accept(new SimpleTypeVisitor6<TypeName, Void>() {\n    @Override public TypeName visitPrimitive(PrimitiveType primitiveType, Void v) {\n      return box(primitiveType);\n    }\n\n    @Override public TypeName visitError(ErrorType errorType, Void v) {\n        \n        \n        \n\n        \n      if (\"<any>\".equals(errorType.toString())) {\n        throw new CodeGenerationIncompleteException(\n            \"Type reported as <any> is likely a not-yet generated parameterized type.\");\n      }\n\n      return ClassName.bestGuess(errorType.toString());\n    }\n\n    @Override protected TypeName defaultAction(TypeMirror typeMirror, Void v) {\n      return TypeName.get(typeMirror);\n    }\n  }, null);\n}", "summary_tokens": ["returns", "a", "string", "for", "type"], "project": "dagger"}
{"id": 23, "code": "public static boolean isCallableConstructor(ExecutableElement constructor) {\n  if (constructor.getModifiers().contains(Modifier.PRIVATE)) {\n    return false;\n  }\n  TypeElement type = (TypeElement) constructor.getEnclosingElement();\n  return type.getEnclosingElement().getKind() == ElementKind.PACKAGE\n      || type.getModifiers().contains(Modifier.STATIC);\n}", "summary_tokens": ["returns", "true", "if", "generated", "code", "can", "invoke", "constructor"], "project": "dagger"}
{"id": 51, "code": "public static String getMembersKey(Class<?> key) {\n    \n  return \"members/\".concat(key.getName());\n}", "summary_tokens": ["returns", "a", "key", "for", "the", "members", "of", "type"], "project": "dagger"}
{"id": 64, "code": "public Map<String, Binding<?>> linkAll() {\n  assertLockHeld();\n  if (linkedBindings != null) {\n    return linkedBindings;\n  }\n  for (Binding<?> binding : bindings.values()) {\n    if (!binding.isLinked()) {\n      toLink.add(binding);\n    }\n  }\n  linkRequested(); \n  linkedBindings = Collections.unmodifiableMap(bindings);\n  return linkedBindings;\n}", "summary_tokens": ["links", "all", "known", "bindings", "whether", "requested", "or", "installed", "plus", "all", "of", "their", "transitive", "dependencies"], "project": "dagger"}
{"id": 22, "code": "public static ExecutableElement getNoArgsConstructor(TypeElement type) {\n  for (Element enclosed : type.getEnclosedElements()) {\n    if (enclosed.getKind() != ElementKind.CONSTRUCTOR) {\n      continue;\n    }\n    ExecutableElement constructor = (ExecutableElement) enclosed;\n    if (constructor.getParameters().isEmpty()) {\n      return constructor;\n    }\n  }\n  return null;\n}", "summary_tokens": ["returns", "the", "no", "args", "constructor", "for", "type", "or", "null", "if", "no", "such", "constructor", "exists"], "project": "dagger"}
{"id": 72, "code": "private void addError(String message) {\n  errors.add(message);\n}", "summary_tokens": ["enqueue", "message", "as", "a", "fatal", "error", "to", "be", "reported", "to", "the", "user"], "project": "dagger"}
{"id": 17, "code": "public static void typeToString(final TypeMirror type, final StringBuilder result,\n    final char innerClassSeparator) {\n  type.accept(new SimpleTypeVisitor6<Void, Void>() {\n    @Override public Void visitDeclared(DeclaredType declaredType, Void v) {\n      TypeElement typeElement = (TypeElement) declaredType.asElement();\n      rawTypeToString(result, typeElement, innerClassSeparator);\n      List<? extends TypeMirror> typeArguments = declaredType.getTypeArguments();\n      if (!typeArguments.isEmpty()) {\n        result.append(\"<\");\n        for (int i = 0; i < typeArguments.size(); i++) {\n          if (i != 0) {\n            result.append(\", \");\n          }\n          typeToString(typeArguments.get(i), result, innerClassSeparator);\n        }\n        result.append(\">\");\n      }\n      return null;\n    }\n    @Override public Void visitPrimitive(PrimitiveType primitiveType, Void v) {\n      result.append(box((PrimitiveType) type));\n      return null;\n    }\n    @Override public Void visitArray(ArrayType arrayType, Void v) {\n      TypeMirror type = arrayType.getComponentType();\n      if (type instanceof PrimitiveType) {\n        result.append(type.toString()); \n      } else {\n        typeToString(arrayType.getComponentType(), result, innerClassSeparator);\n      }\n      result.append(\"[]\");\n      return null;\n    }\n    @Override public Void visitTypeVariable(TypeVariable typeVariable, Void v) {\n      result.append(typeVariable.asElement().getSimpleName());\n      return null;\n    }\n    @Override public Void visitError(ErrorType errorType, Void v) {\n        \n        \n        \n\n        \n      if (\"<any>\".equals(errorType.toString())) {\n        throw new CodeGenerationIncompleteException(\n            \"Type reported as <any> is likely a not-yet generated parameterized type.\");\n      }\n        \n      result.append(errorType.toString());\n      return null;\n    }\n    @Override protected Void defaultAction(TypeMirror typeMirror, Void v) {\n      throw new UnsupportedOperationException(\n          \"Unexpected TypeKind \" + typeMirror.getKind() + \" for \"  + typeMirror);\n    }\n  }, null);\n}", "summary_tokens": ["appends", "a", "string", "for", "type", "to", "result"], "project": "dagger"}
{"id": 43, "code": "public boolean contains(Object o) {\n    if (o == null)\n        return false;\n    int mask = elements.length - 1;\n    int i = head;\n    Object x;\n    while ((x = elements[i]) != null) {\n        if (o.equals(x))\n            return true;\n        i = (i + 1) & mask;\n    }\n    return false;\n}", "summary_tokens": ["returns", "tt", "true", "tt", "if", "this", "queue", "contains", "the", "specified", "element"], "project": "dagger"}
{"id": 4, "code": "public static String getSetKey(ExecutableElement method) {\n  StringBuilder result = new StringBuilder();\n  AnnotationMirror qualifier = getQualifier(method.getAnnotationMirrors());\n  if (qualifier != null) {\n    qualifierToString(qualifier, result);\n  }\n  result.append(SET_PREFIX);\n  typeToString(method.getReturnType(), result, '$');\n  result.append(\">\");\n  return result.toString();\n}", "summary_tokens": ["returns", "the", "provided", "key", "for", "method", "wrapped", "by", "set"], "project": "dagger"}
{"id": 82, "code": "protected List<Object> getModules() {\n  return Arrays.<Object>asList(new AndroidModule(this));\n}", "summary_tokens": ["a", "list", "of", "modules", "to", "use", "for", "the", "application", "graph"], "project": "dagger"}
{"id": 24, "code": "public static String className(ExecutableElement method) {\n  return ((TypeElement) method.getEnclosingElement()).getQualifiedName().toString();\n}", "summary_tokens": ["returns", "a", "user", "presentable", "string", "like", "coffee"], "project": "dagger"}
{"id": 20, "code": "public static Map<String, Object> getAnnotation(Class<?> annotationType, Element element) {\n  for (AnnotationMirror annotation : element.getAnnotationMirrors()) {\n    if (!rawTypeToString(annotation.getAnnotationType(), '$')\n        .equals(annotationType.getName())) {\n      continue;\n    }\n\n    Map<String, Object> result = new LinkedHashMap<String, Object>();\n    for (Method m : annotationType.getMethods()) {\n      result.put(m.getName(), m.getDefaultValue());\n    }\n    for (Map.Entry<? extends ExecutableElement, ? extends AnnotationValue> e\n        : annotation.getElementValues().entrySet()) {\n      String name = e.getKey().getSimpleName().toString();\n      Object value = e.getValue().accept(VALUE_EXTRACTOR, null);\n      Object defaultValue = result.get(name);\n      if (!lenientIsInstance(defaultValue.getClass(), value)) {\n        throw new IllegalStateException(String.format(\n            \"Value of %s.%s is a %s but expected a %s\\n    value: %s\",\n            annotationType, name, value.getClass().getName(), defaultValue.getClass().getName(),\n            value instanceof Object[] ? Arrays.toString((Object[]) value) : value));\n      }\n      result.put(name, value);\n    }\n    return result;\n  }\n  return null; \n}", "summary_tokens": ["returns", "the", "annotation", "on", "element", "formatted", "as", "a", "map"], "project": "dagger"}
{"id": 1696, "code": "\tprivate Collection<? extends GrantedAuthority> getWebSphereGroupsBasedGrantedAuthorities() {\n\t\tList<String> webSphereGroups = this.wasHelper.getGroupsForCurrentUser();\n\t\tCollection<? extends GrantedAuthority> userGas = this.webSphereGroups2GrantedAuthoritiesMapper\n\t\t\t\t.getGrantedAuthorities(webSphereGroups);\n\t\tthis.logger.debug(\n\t\t\t\tLogMessage.format(\"WebSphere groups: %s mapped to Granted Authorities: %s\", webSphereGroups, userGas));\n\t\treturn userGas;\n\t}", "summary_tokens": ["get", "a", "list", "of", "granted", "authorities", "based", "on", "the", "current", "user", "s", "web", "sphere", "groups"], "project": "spring-security"}
{"id": 349, "code": "\tpublic X509Configurer<H> userDetailsService(UserDetailsService userDetailsService) {\n\t\tUserDetailsByNameServiceWrapper<PreAuthenticatedAuthenticationToken> authenticationUserDetailsService = new UserDetailsByNameServiceWrapper<>();\n\t\tauthenticationUserDetailsService.setUserDetailsService(userDetailsService);\n\t\treturn authenticationUserDetailsService(authenticationUserDetailsService);\n\t}", "summary_tokens": ["shortcut", "for", "invoking", "authentication", "user", "details", "service", "authentication", "user", "details", "service", "with", "a", "user", "details", "by", "name", "service", "wrapper"], "project": "spring-security"}
{"id": 830, "code": "\tprivate static URI parseLdapUrl(String url) {\n\t\tAssert.hasLength(url, \"url must have length\");\n\t\ttry {\n\t\t\treturn new URI(url);\n\t\t}\n\t\tcatch (URISyntaxException ex) {\n\t\t\tthrow new IllegalArgumentException(\"Unable to parse url: \" + url, ex);\n\t\t}\n\t}", "summary_tokens": ["parses", "the", "supplied", "ldap", "url"], "project": "spring-security"}
{"id": 1141, "code": "\tpublic final void setAuthorizationRequestRepository(\n\t\t\tAuthorizationRequestRepository<OAuth2AuthorizationRequest> authorizationRequestRepository) {\n\t\tAssert.notNull(authorizationRequestRepository, \"authorizationRequestRepository cannot be null\");\n\t\tthis.authorizationRequestRepository = authorizationRequestRepository;\n\t}", "summary_tokens": ["sets", "the", "repository", "used", "for", "storing", "oauth", "0", "authorization", "request", "s"], "project": "spring-security"}
{"id": 1436, "code": "\tpublic String getParametersQuery() {\n\t\treturn this.encoder.apply(this.parameters);\n\t}", "summary_tokens": ["get", "an", "encoded", "query", "string", "of", "all", "parameters"], "project": "spring-security"}
{"id": 642, "code": "\tpublic Object invoke(MethodInvocation mi) throws Throwable {\n\t\tPreFilterExpressionAttributeRegistry.PreFilterExpressionAttribute attribute = this.registry.getAttribute(mi);\n\t\tif (attribute == PreFilterExpressionAttributeRegistry.PreFilterExpressionAttribute.NULL_ATTRIBUTE) {\n\t\t\treturn mi.proceed();\n\t\t}\n\t\tMethodSecurityExpressionHandler expressionHandler = this.registry.getExpressionHandler();\n\t\tEvaluationContext ctx = expressionHandler.createEvaluationContext(this.authentication, mi);\n\t\tObject filterTarget = findFilterTarget(attribute.getFilterTarget(), ctx, mi);\n\t\texpressionHandler.filter(filterTarget, attribute.getExpression(), ctx);\n\t\treturn mi.proceed();\n\t}", "summary_tokens": ["filter", "the", "method", "argument", "specified", "in", "the", "pre", "filter", "annotation", "that", "method", "invocation", "specifies"], "project": "spring-security"}
{"id": 534, "code": "\tCollection<? extends GrantedAuthority> extractAuthorities(Authentication authentication) {\n\t\treturn this.roleHierarchy.getReachableGrantedAuthorities(authentication.getAuthorities());\n\t}", "summary_tokens": ["calls", "the", "tt", "role", "hierarchy", "tt", "to", "obtain", "the", "complete", "set", "of", "user", "authorities"], "project": "spring-security"}
{"id": 1058, "code": "\tpublic void setRestOperations(RestOperations restOperations) {\n\t\tAssert.notNull(restOperations, \"restOperations cannot be null\");\n\t\tthis.restOperations = restOperations;\n\t}", "summary_tokens": ["sets", "the", "rest", "operations", "used", "when", "requesting", "the", "oauth", "0"], "project": "spring-security"}
{"id": 1945, "code": "\tpublic Mono<Void> onLogoutSuccess(WebFilterExchange exchange, Authentication authentication) {\n\t\treturn Mono.fromRunnable(() -> exchange.getExchange().getResponse().setStatusCode(this.httpStatusToReturn));\n\t}", "summary_tokens": ["implementation", "of", "server", "logout", "success", "handler", "on", "logout", "success", "web", "filter", "exchange", "authentication"], "project": "spring-security"}
{"id": 638, "code": "\tMethodSecurityExpressionHandler getExpressionHandler() {\n\t\treturn this.expressionHandler;\n\t}", "summary_tokens": ["returns", "the", "method", "security", "expression", "handler"], "project": "spring-security"}
{"id": 1599, "code": "\tprotected void unsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response,\n\t\t\tAuthenticationException failed) throws IOException, ServletException {\n\t\tthis.securityContextHolderStrategy.clearContext();\n\t\tthis.logger.trace(\"Failed to process authentication request\", failed);\n\t\tthis.logger.trace(\"Cleared SecurityContextHolder\");\n\t\tthis.logger.trace(\"Handling authentication failure\");\n\t\tthis.rememberMeServices.loginFail(request, response);\n\t\tthis.failureHandler.onAuthenticationFailure(request, response, failed);\n\t}", "summary_tokens": ["default", "behaviour", "for", "unsuccessful", "authentication"], "project": "spring-security"}
{"id": 501, "code": "\tprotected ParameterNameDiscoverer getParameterNameDiscoverer() {\n\t\treturn this.parameterNameDiscoverer;\n\t}", "summary_tokens": ["the", "current", "parameter", "name", "discoverer"], "project": "spring-security"}
{"id": 257, "code": "\tpublic HeadersConfigurer<H> defaultsDisabled() {\n\t\tthis.contentTypeOptions.disable();\n\t\tthis.xssProtection.disable();\n\t\tthis.cacheControl.disable();\n\t\tthis.hsts.disable();\n\t\tthis.frameOptions.disable();\n\t\treturn this;\n\t}", "summary_tokens": ["clears", "all", "of", "the", "default", "headers", "from", "the", "response"], "project": "spring-security"}
{"id": 1955, "code": "\tpublic void setSpringSecurityContextAttrName(String springSecurityContextAttrName) {\n\t\tAssert.hasText(springSecurityContextAttrName, \"springSecurityContextAttrName cannot be null or empty\");\n\t\tthis.springSecurityContextAttrName = springSecurityContextAttrName;\n\t}", "summary_tokens": ["sets", "the", "session", "attribute", "name", "used", "to", "save", "and", "load", "the", "security", "context", "spring", "security", "context", "attr", "name", "the", "session", "attribute", "name", "to", "use", "to", "save", "and", "load", "the", "security", "context"], "project": "spring-security"}
{"id": 769, "code": "\tprivate static int decode4to3(final byte[] source, final int srcOffset, final byte[] destination,\n\t\t\tfinal int destOffset, final int options) {\n\n\t\t\n\t\tif (source == null) {\n\t\t\tthrow new NullPointerException(\"Source array was null.\");\n\t\t} \n\t\tif (destination == null) {\n\t\t\tthrow new NullPointerException(\"Destination array was null.\");\n\t\t} \n\t\tif (srcOffset < 0 || srcOffset + 3 >= source.length) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\tString.format(\"Source array with length %d cannot have offset of %d and still process four bytes.\",\n\t\t\t\t\t\t\tsource.length, srcOffset));\n\t\t} \n\t\tif (destOffset < 0 || destOffset + 2 >= destination.length) {\n\t\t\tthrow new IllegalArgumentException(String.format(\n\t\t\t\t\t\"Destination array with length %d cannot have offset of %d and still store three bytes.\",\n\t\t\t\t\tdestination.length, destOffset));\n\t\t} \n\n\t\tbyte[] DECODABET = getDecodabet(options);\n\n\t\t\n\t\tif (source[srcOffset + 2] == EQUALS_SIGN) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tint outBuff = ((DECODABET[source[srcOffset]] & 0xFF) << 18)\n\t\t\t\t\t| ((DECODABET[source[srcOffset + 1]] & 0xFF) << 12);\n\n\t\t\tdestination[destOffset] = (byte) (outBuff >>> 16);\n\t\t\treturn 1;\n\t\t}\n\n\t\t\n\t\telse if (source[srcOffset + 3] == EQUALS_SIGN) {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tint outBuff = ((DECODABET[source[srcOffset]] & 0xFF) << 18)\n\t\t\t\t\t| ((DECODABET[source[srcOffset + 1]] & 0xFF) << 12)\n\t\t\t\t\t| ((DECODABET[source[srcOffset + 2]] & 0xFF) << 6);\n\n\t\t\tdestination[destOffset] = (byte) (outBuff >>> 16);\n\t\t\tdestination[destOffset + 1] = (byte) (outBuff >>> 8);\n\t\t\treturn 2;\n\t\t}\n\n\t\t\n\t\telse {\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tint outBuff = ((DECODABET[source[srcOffset]] & 0xFF) << 18)\n\t\t\t\t\t| ((DECODABET[source[srcOffset + 1]] & 0xFF) << 12)\n\t\t\t\t\t| ((DECODABET[source[srcOffset + 2]] & 0xFF) << 6) | ((DECODABET[source[srcOffset + 3]] & 0xFF));\n\n\t\t\tdestination[destOffset] = (byte) (outBuff >> 16);\n\t\t\tdestination[destOffset + 1] = (byte) (outBuff >> 8);\n\t\t\tdestination[destOffset + 2] = (byte) (outBuff);\n\n\t\t\treturn 3;\n\t\t}\n\t}", "summary_tokens": ["decodes", "four", "bytes", "from", "array", "var", "source", "var", "and", "writes", "the", "resulting", "bytes", "up", "to", "three", "of", "them", "to", "var", "destination", "var"], "project": "spring-security"}
{"id": 133, "code": "\tpublic C antMatchers(String... antPatterns) {\n\t\tAssert.state(!this.anyRequestConfigured, \"Can't configure antMatchers after anyRequest\");\n\t\treturn chainRequestMatchers(RequestMatchers.antMatchers(antPatterns));\n\t}", "summary_tokens": ["maps", "a", "list", "of", "org"], "project": "spring-security"}
{"id": 1478, "code": "\tpublic void setAuthoritiesExtractor(\n\t\t\tConverter<Assertion, Collection<? extends GrantedAuthority>> authoritiesExtractor) {\n\t\tAssert.notNull(authoritiesExtractor, \"authoritiesExtractor cannot be null\");\n\t\tthis.authoritiesExtractor = authoritiesExtractor;\n\t}", "summary_tokens": ["sets", "the", "converter", "used", "for", "extracting", "assertion", "attributes", "that", "can", "be", "mapped", "to", "authorities"], "project": "spring-security"}
{"id": 416, "code": "\tpublic void setLdapAuthoritiesPopulator(LdapAuthoritiesPopulator ldapAuthoritiesPopulator) {\n\t\tthis.ldapAuthoritiesPopulator = ldapAuthoritiesPopulator;\n\t}", "summary_tokens": ["sets", "the", "ldap", "authorities", "populator", "used", "to", "obtain", "a", "list", "of", "granted", "authorities", "for", "an", "ldap", "user"], "project": "spring-security"}
{"id": 687, "code": "\tpublic static void setContext(SecurityContext context) {\n\t\tstrategy.setContext(context);\n\t}", "summary_tokens": ["associates", "a", "new", "code", "security", "context", "code", "with", "the", "current", "thread", "of", "execution"], "project": "spring-security"}
{"id": 528, "code": "\tpublic int getMethodMapSize() {\n\t\treturn this.methodMap.size();\n\t}", "summary_tokens": ["map", "size", "for", "unit", "tests", "and", "diagnostics"], "project": "spring-security"}
{"id": 1613, "code": "\tpublic void setUseReferer(boolean useReferer) {\n\t\tthis.useReferer = useReferer;\n\t}", "summary_tokens": ["if", "set", "to", "true", "the", "referer", "header", "will", "be", "used", "if", "available"], "project": "spring-security"}
{"id": 1430, "code": "\tpublic Authentication getAuthentication() {\n\t\treturn this.authentication;\n\t}", "summary_tokens": ["the", "current", "authentication", "the", "authenticated", "user"], "project": "spring-security"}
{"id": 1114, "code": "\tpublic Iterator<ClientRegistration> iterator() {\n\t\treturn this.registrations.values().iterator();\n\t}", "summary_tokens": ["returns", "an", "iterator", "of", "client", "registration"], "project": "spring-security"}
{"id": 929, "code": "\tpublic static SimpDestinationMessageMatcher createSubscribeMatcher(String pattern, PathMatcher matcher) {\n\t\treturn new SimpDestinationMessageMatcher(pattern, SimpMessageType.SUBSCRIBE, matcher);\n\t}", "summary_tokens": ["p", "creates", "a", "new", "instance", "with", "the", "specified", "pattern", "simp", "message", "type"], "project": "spring-security"}
{"id": 832, "code": "\tpublic DirContextOperations retrieveEntry(final String dn, final String[] attributesToRetrieve) {\n\t\treturn (DirContextOperations) executeReadOnly((ContextExecutor) (ctx) -> {\n\t\t\tAttributes attrs = ctx.getAttributes(dn, attributesToRetrieve);\n\t\t\treturn new DirContextAdapter(attrs, new DistinguishedName(dn),\n\t\t\t\t\tnew DistinguishedName(ctx.getNameInNamespace()));\n\t\t});\n\t}", "summary_tokens": ["composes", "an", "object", "from", "the", "attributes", "of", "the", "given", "dn"], "project": "spring-security"}
{"id": 238, "code": "\tAccessDeniedHandler getAccessDeniedHandler(H http) {\n\t\tAccessDeniedHandler deniedHandler = this.accessDeniedHandler;\n\t\tif (deniedHandler == null) {\n\t\t\tdeniedHandler = createDefaultDeniedHandler(http);\n\t\t}\n\t\treturn deniedHandler;\n\t}", "summary_tokens": ["gets", "the", "access", "denied", "handler", "according", "to", "the", "rules", "specified", "by", "access", "denied", "handler", "access", "denied", "handler", "http", "the", "http", "security", "used", "to", "look", "up", "shared", "access", "denied", "handler", "the", "access", "denied", "handler", "to", "use"], "project": "spring-security"}
{"id": 899, "code": "\tprotected String mapPassword(Object passwordValue) {\n\t\tif (!(passwordValue instanceof String)) {\n\t\t\t\n\t\t\tpasswordValue = new String((byte[]) passwordValue);\n\t\t}\n\t\treturn (String) passwordValue;\n\n\t}", "summary_tokens": ["extension", "point", "to", "allow", "customized", "creation", "of", "the", "user", "s", "password", "from", "the", "attribute", "stored", "in", "the", "directory"], "project": "spring-security"}
{"id": 1123, "code": "\tpublic void setAnonymousAuthorizedClientRepository(\n\t\t\tOAuth2AuthorizedClientRepository anonymousAuthorizedClientRepository) {\n\t\tAssert.notNull(anonymousAuthorizedClientRepository, \"anonymousAuthorizedClientRepository cannot be null\");\n\t\tthis.anonymousAuthorizedClientRepository = anonymousAuthorizedClientRepository;\n\t}", "summary_tokens": ["sets", "the", "oauth", "0", "authorized", "client", "repository", "used", "for", "requests", "that", "are", "unauthenticated", "or", "anonymous"], "project": "spring-security"}
{"id": 598, "code": "\tpublic static <T> AuthorityAuthorizationManager<T> hasAnyAuthority(String... authorities) {\n\t\tAssert.notEmpty(authorities, \"authorities cannot be empty\");\n\t\tAssert.noNullElements(authorities, \"authorities cannot contain null values\");\n\t\treturn new AuthorityAuthorizationManager<>(authorities);\n\t}", "summary_tokens": ["creates", "an", "instance", "of", "authority", "authorization", "manager", "with", "the", "provided", "authorities"], "project": "spring-security"}
{"id": 1017, "code": "\tpublic void setAccessTokenResponseClient(\n\t\t\tReactiveOAuth2AccessTokenResponseClient<OAuth2RefreshTokenGrantRequest> accessTokenResponseClient) {\n\t\tAssert.notNull(accessTokenResponseClient, \"accessTokenResponseClient cannot be null\");\n\t\tthis.accessTokenResponseClient = accessTokenResponseClient;\n\t}", "summary_tokens": ["sets", "the", "client", "used", "when", "requesting", "an", "access", "token", "credential", "at", "the", "token", "endpoint", "for", "the", "refresh", "token", "grant"], "project": "spring-security"}
{"id": 1313, "code": "\tprivate static JwtDecoder withProviderConfiguration(Map<String, Object> configuration, String issuer) {\n\t\tJwtDecoderProviderConfigurationUtils.validateIssuer(configuration, issuer);\n\t\tOAuth2TokenValidator<Jwt> jwtValidator = JwtValidators.createDefaultWithIssuer(issuer);\n\t\tString jwkSetUri = configuration.get(\"jwks_uri\").toString();\n\t\tNimbusJwtDecoder jwtDecoder = NimbusJwtDecoder.withJwkSetUri(jwkSetUri)\n\t\t\t\t.jwtProcessorCustomizer(JwtDecoderProviderConfigurationUtils::addJWSAlgorithms).build();\n\t\tjwtDecoder.setJwtValidator(jwtValidator);\n\t\treturn jwtDecoder;\n\t}", "summary_tokens": ["validate", "provided", "issuer", "and", "build", "jwt", "decoder", "from", "a", "href", "https", "openid"], "project": "spring-security"}
{"id": 1711, "code": "\tpublic PersistentRememberMeToken getTokenForSeries(String seriesId) {\n\t\ttry {\n\t\t\treturn getJdbcTemplate().queryForObject(this.tokensBySeriesSql, this::createRememberMeToken, seriesId);\n\t\t}\n\t\tcatch (EmptyResultDataAccessException ex) {\n\t\t\tthis.logger.debug(LogMessage.format(\"Querying token for series '%s' returned no results.\", seriesId), ex);\n\t\t}\n\t\tcatch (IncorrectResultSizeDataAccessException ex) {\n\t\t\tthis.logger.error(LogMessage.format(\n\t\t\t\t\t\"Querying token for series '%s' returned more than one value. Series\" + \" should be unique\",\n\t\t\t\t\tseriesId));\n\t\t}\n\t\tcatch (DataAccessException ex) {\n\t\t\tthis.logger.error(\"Failed to load token for series \" + seriesId, ex);\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["loads", "the", "token", "data", "for", "the", "supplied", "series", "identifier"], "project": "spring-security"}
{"id": 406, "code": "\tprivate String resolveAttribute(ParserContext pc, Element element, String attributeName) {\n\t\treturn pc.getReaderContext().getEnvironment().resolvePlaceholders(element.getAttribute(attributeName));\n\t}", "summary_tokens": ["resolve", "the", "placeholder", "for", "a", "given", "attribute", "on", "a", "element"], "project": "spring-security"}
{"id": 571, "code": "\tprotected void configureJaas(Resource loginConfig) throws IOException {\n\t\tconfigureJaasUsingLoop();\n\t\tif (this.refreshConfigurationOnStartup) {\n\t\t\t\n\t\t\tConfiguration.getConfiguration().refresh();\n\t\t}\n\t}", "summary_tokens": ["hook", "method", "for", "configuring", "jaas"], "project": "spring-security"}
{"id": 1411, "code": "\tpublic String getSaml2Response() {\n\t\treturn this.saml2Response;\n\t}", "summary_tokens": ["returns", "inflated", "and", "decoded", "xml", "representation", "of", "the", "saml", "0", "response", "inflated", "and", "decoded", "xml", "representation", "of", "the", "saml", "0", "response"], "project": "spring-security"}
{"id": 1303, "code": "\tdefault String getSubject() {\n\t\treturn this.getClaimAsString(JwtClaimNames.SUB);\n\t}", "summary_tokens": ["returns", "the", "subject", "sub", "claim", "which", "identifies", "the", "principal", "that", "is", "the", "subject", "of", "the", "jwt"], "project": "spring-security"}
{"id": 1850, "code": "\tprivate static boolean isNormalized(String path) {\n\t\tif (path == null) {\n\t\t\treturn true;\n\t\t}\n\t\tfor (int i = path.length(); i > 0;) {\n\t\t\tint slashIndex = path.lastIndexOf('/', i - 1);\n\t\t\tint gap = i - slashIndex;\n\t\t\tif (gap == 2 && path.charAt(slashIndex + 1) == '.') {\n\t\t\t\treturn false; \n\t\t\t}\n\t\t\tif (gap == 3 && path.charAt(slashIndex + 1) == '.' && path.charAt(slashIndex + 2) == '.') {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\ti = slashIndex;\n\t\t}\n\t\treturn true;\n\t}", "summary_tokens": ["checks", "whether", "a", "path", "is", "normalized", "doesn", "t", "contain", "path", "traversal", "sequences", "like"], "project": "spring-security"}
{"id": 1086, "code": "\tpublic static Map<String, Converter<Object, ?>> createDefaultClaimTypeConverters() {\n\t\tConverter<Object, ?> booleanConverter = getConverter(TypeDescriptor.valueOf(Boolean.class));\n\t\tConverter<Object, ?> instantConverter = getConverter(TypeDescriptor.valueOf(Instant.class));\n\t\tConverter<Object, ?> urlConverter = getConverter(TypeDescriptor.valueOf(URL.class));\n\t\tConverter<Object, ?> stringConverter = getConverter(TypeDescriptor.valueOf(String.class));\n\t\tConverter<Object, ?> collectionStringConverter = getConverter(\n\t\t\t\tTypeDescriptor.collection(Collection.class, TypeDescriptor.valueOf(String.class)));\n\t\tMap<String, Converter<Object, ?>> converters = new HashMap<>();\n\t\tconverters.put(IdTokenClaimNames.ISS, urlConverter);\n\t\tconverters.put(IdTokenClaimNames.AUD, collectionStringConverter);\n\t\tconverters.put(IdTokenClaimNames.NONCE, stringConverter);\n\t\tconverters.put(IdTokenClaimNames.EXP, instantConverter);\n\t\tconverters.put(IdTokenClaimNames.IAT, instantConverter);\n\t\tconverters.put(IdTokenClaimNames.AUTH_TIME, instantConverter);\n\t\tconverters.put(IdTokenClaimNames.AMR, collectionStringConverter);\n\t\tconverters.put(StandardClaimNames.EMAIL_VERIFIED, booleanConverter);\n\t\tconverters.put(StandardClaimNames.PHONE_NUMBER_VERIFIED, booleanConverter);\n\t\tconverters.put(StandardClaimNames.UPDATED_AT, instantConverter);\n\t\treturn converters;\n\t}", "summary_tokens": ["returns", "the", "default", "converter", "s", "used", "for", "type", "conversion", "of", "claim", "values", "for", "an", "oidc", "id", "token"], "project": "spring-security"}
{"id": 933, "code": "\tpublic MethodParameter returnType() {\n\t\treturn new SynthesizingMethodParameter(this.method, -1);\n\t}", "summary_tokens": ["return", "the", "declared", "return", "type", "of", "the", "resolved", "method"], "project": "spring-security"}
{"id": 985, "code": "\tpublic String getPrincipalName() {\n\t\treturn this.principalName;\n\t}", "summary_tokens": ["returns", "the", "end", "user", "s", "principal", "name"], "project": "spring-security"}
{"id": 1733, "code": "\tpublic void onAuthentication(Authentication authentication, HttpServletRequest request,\n\t\t\tHttpServletResponse response) {\n\t\tthis.sessionRegistry.registerNewSession(request.getSession().getId(), authentication.getPrincipal());\n\t}", "summary_tokens": ["in", "addition", "to", "the", "steps", "from", "the", "superclass", "the", "session", "registry", "will", "be", "updated", "with", "the", "new", "session", "information"], "project": "spring-security"}
{"id": 466, "code": "\tpublic Collection<String> getIds() {\n\t\tCollection<String> ids = new ArrayList<>();\n\t\tids.add(getId());\n\t\tthis.childElmts.values().forEach((elmt) -> ids.add(elmt.getId()));\n\t\tthis.attrs.forEach((attr) -> ids.add(attr.getId()));\n\t\tif (!this.childElmts.isEmpty()) {\n\t\t\tids.add(getId() + \"-children\");\n\t\t}\n\t\tif (!this.attrs.isEmpty()) {\n\t\t\tids.add(getId() + \"-attributes\");\n\t\t}\n\t\tif (!this.parentElmts.isEmpty()) {\n\t\t\tids.add(getId() + \"-parents\");\n\t\t}\n\t\treturn ids;\n\t}", "summary_tokens": ["gets", "all", "the", "ids", "related", "to", "this", "element", "including", "attributes", "parent", "elements", "and", "child", "elements"], "project": "spring-security"}
{"id": 1995, "code": "\tpublic static ServerWebExchangeMatcher anyExchange() {\n\t\t\n\t\t\n\t\t\n\t\treturn new ServerWebExchangeMatcher() {\n\n\t\t\t@Override\n\t\t\tpublic Mono<MatchResult> matches(ServerWebExchange exchange) {\n\t\t\t\treturn ServerWebExchangeMatcher.MatchResult.match();\n\t\t\t}\n\n\t\t};\n\t}", "summary_tokens": ["matches", "any", "exchange", "the", "matcher", "to", "use"], "project": "spring-security"}
{"id": 605, "code": "\tdefault Mono<Void> verify(Mono<Authentication> authentication, T object) {\n\t\t\n\t\treturn check(authentication, object)\n\t\t\t\t.filter(AuthorizationDecision::isGranted)\n\t\t\t\t.switchIfEmpty(Mono.defer(() -> Mono.error(new AccessDeniedException(\"Access Denied\"))))\n\t\t\t\t.flatMap((decision) -> Mono.empty());\n\t\t\n\t}", "summary_tokens": ["determines", "if", "access", "should", "be", "granted", "for", "a", "specific", "authentication", "and", "object", "authentication", "the", "authentication", "to", "check", "object", "the", "object", "to", "check", "an", "empty", "mono", "if", "authorization", "is", "granted", "or", "a", "mono", "error", "if", "access", "is", "denied"], "project": "spring-security"}
{"id": 1443, "code": "\tpublic void setEntityDescriptorCustomizer(Consumer<EntityDescriptorParameters> entityDescriptorCustomizer) {\n\t\tAssert.notNull(entityDescriptorCustomizer, \"entityDescriptorCustomizer cannot be null\");\n\t\tthis.entityDescriptorCustomizer = entityDescriptorCustomizer;\n\t}", "summary_tokens": ["set", "a", "consumer", "for", "modifying", "the", "open", "saml", "entity", "descriptor", "entity", "descriptor", "customizer", "a", "consumer", "that", "accepts", "an", "entity", "descriptor", "parameters", "0"], "project": "spring-security"}
{"id": 1227, "code": "\tpublic String getAuthorizationUri() {\n\t\treturn this.authorizationUri;\n\t}", "summary_tokens": ["returns", "the", "uri", "for", "the", "authorization", "endpoint"], "project": "spring-security"}
{"id": 1538, "code": "\tpublic static JwtRequestPostProcessor jwt() {\n\t\treturn new JwtRequestPostProcessor();\n\t}", "summary_tokens": ["establish", "a", "security", "context", "that", "has", "a", "jwt", "authentication", "token", "for", "the", "authentication", "and", "a", "jwt", "for", "the", "authentication", "get", "principal"], "project": "spring-security"}
{"id": 1826, "code": "\tpublic CsrfToken generateToken(HttpServletRequest request) {\n\t\treturn wrap(request, this.delegate.generateToken(request));\n\t}", "summary_tokens": ["generates", "a", "new", "token", "request", "the", "http", "servlet", "request", "to", "use"], "project": "spring-security"}
{"id": 1760, "code": "\tpublic void setResolveHiddenInputs(Function<HttpServletRequest, Map<String, String>> resolveHiddenInputs) {\n\t\tAssert.notNull(resolveHiddenInputs, \"resolveHiddenInputs cannot be null\");\n\t\tthis.resolveHiddenInputs = resolveHiddenInputs;\n\t}", "summary_tokens": ["sets", "a", "function", "used", "to", "resolve", "a", "map", "of", "the", "hidden", "inputs", "where", "the", "key", "is", "the", "name", "of", "the", "input", "and", "the", "value", "is", "the", "value", "of", "the", "input"], "project": "spring-security"}
{"id": 711, "code": "\tpublic void afterPropertiesSet() {\n\t\tAssert.notNull(this.userDetailsService, \"UserDetailsService must be set\");\n\t}", "summary_tokens": ["check", "whether", "all", "required", "properties", "have", "been", "set"], "project": "spring-security"}
{"id": 1470, "code": "\tSaml2LogoutResponse resolve(HttpServletRequest request, Authentication authentication) {\n\t\treturn resolve(request, authentication, (registration, logoutResponse) -> {\n\t\t});\n\t}", "summary_tokens": ["prepare", "to", "create", "sign", "and", "serialize", "a", "saml", "0"], "project": "spring-security"}
{"id": 2033, "code": "\tprivate void doOnResponseCommitted() {\n\t\tif (!this.disableOnCommitted) {\n\t\t\tonResponseCommitted();\n\t\t\tdisableOnResponseCommitted();\n\t\t}\n\t}", "summary_tokens": ["calls", "code", "on", "response", "commmitted", "code", "with", "the", "current", "contents", "as", "long", "as", "disable", "on", "response", "committed", "was", "not", "invoked"], "project": "spring-security"}
{"id": 1828, "code": "\tpublic CsrfToken loadToken(HttpServletRequest request) {\n\t\tif (this.deferLoadToken) {\n\t\t\treturn new LazyLoadCsrfToken(request, this.delegate);\n\t\t}\n\t\treturn this.delegate.loadToken(request);\n\t}", "summary_tokens": ["delegates", "to", "the", "injected", "csrf", "token", "repository"], "project": "spring-security"}
{"id": 476, "code": "\tpublic void countReferencesWhenReviewingDocumentationThenEntireSchemaIsIncluded() throws IOException {\n\t\tMap<String, Element> elementsByElementName = this.xml.elementsByElementName(this.schemaDocumentLocation);\n\t\t\n\t\tList<String> documentIds = namespaceLines()\n\t\t\t\t.filter((line) -> line.matches(\"\\\\[\\\\[(nsa-.*)\\\\]\\\\]\"))\n\t\t\t\t.map((line) -> line.substring(2, line.length() - 2))\n\t\t\t\t.collect(Collectors.toList());\n\t\tSet<String> expectedIds = elementsByElementName.values()\n\t\t\t\t.stream()\n\t\t\t\t.flatMap((element) -> element.getIds().stream())\n\t\t\t\t.collect(Collectors.toSet());\n\t\t\n\t\tdocumentIds.removeAll(this.ignoredIds);\n\t\texpectedIds.removeAll(this.ignoredIds);\n\t\tassertThat(documentIds).containsAll(expectedIds);\n\t\tassertThat(expectedIds).containsAll(documentIds);\n\t}", "summary_tokens": ["this", "uses", "a", "naming", "convention", "for", "the", "ids", "of", "the", "appendix", "to", "ensure", "that", "the", "entire", "appendix", "is", "documented"], "project": "spring-security"}
{"id": 660, "code": "\tpublic static List<GrantedAuthority> createAuthorityList(String... authorities) {\n\t\tList<GrantedAuthority> grantedAuthorities = new ArrayList<>(authorities.length);\n\t\tfor (String authority : authorities) {\n\t\t\tgrantedAuthorities.add(new SimpleGrantedAuthority(authority));\n\t\t}\n\t\treturn grantedAuthorities;\n\t}", "summary_tokens": ["converts", "authorities", "into", "a", "list", "of", "granted", "authority", "objects"], "project": "spring-security"}
{"id": 1515, "code": "\tpublic static void clearContext() {\n\t\tcontextHolder.remove();\n\t\tSecurityContextHolder.clearContext();\n\t}", "summary_tokens": ["clears", "the", "security", "context", "from", "test", "security", "context", "holder", "and", "security", "context", "holder"], "project": "spring-security"}
{"id": 188, "code": "\tprivate Map<Class<?>, Object> createSharedObjects() {\n\t\tMap<Class<?>, Object> sharedObjects = new HashMap<>();\n\t\tsharedObjects.putAll(this.localConfigureAuthenticationBldr.getSharedObjects());\n\t\tsharedObjects.put(UserDetailsService.class, userDetailsService());\n\t\tsharedObjects.put(ApplicationContext.class, this.context);\n\t\tsharedObjects.put(ContentNegotiationStrategy.class, this.contentNegotiationStrategy);\n\t\tsharedObjects.put(AuthenticationTrustResolver.class, this.trustResolver);\n\t\treturn sharedObjects;\n\t}", "summary_tokens": ["creates", "the", "shared", "objects", "the", "shared", "objects"], "project": "spring-security"}
{"id": 1765, "code": "\tstatic Map<String, String> splitEachArrayElementAndCreateMap(String[] array, String delimiter,\n\t\t\tString removeCharacters) {\n\t\tif ((array == null) || (array.length == 0)) {\n\t\t\treturn null;\n\t\t}\n\t\tMap<String, String> map = new HashMap<>();\n\t\tfor (String s : array) {\n\t\t\tString postRemove = (removeCharacters != null) ? StringUtils.replace(s, removeCharacters, \"\") : s;\n\t\t\tString[] splitThisArrayElement = split(postRemove, delimiter);\n\t\t\tif (splitThisArrayElement == null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tmap.put(splitThisArrayElement[0].trim(), splitThisArrayElement[1].trim());\n\t\t}\n\t\treturn map;\n\t}", "summary_tokens": ["takes", "an", "array", "of", "code", "string", "code", "s", "and", "for", "each", "element", "removes", "any", "instances", "of", "code", "remove", "character", "code", "and", "splits", "the", "element", "based", "on", "the", "code", "delimiter", "code"], "project": "spring-security"}
{"id": 1635, "code": "\tprotected String obtainPassword(HttpServletRequest request) {\n\t\treturn request.getParameter(this.passwordParameter);\n\t}", "summary_tokens": ["enables", "subclasses", "to", "override", "the", "composition", "of", "the", "password", "such", "as", "by", "including", "additional", "values", "and", "a", "separator"], "project": "spring-security"}
{"id": 1096, "code": "\tpublic final void setClaimTypeConverterFactory(\n\t\t\tFunction<ClientRegistration, Converter<Map<String, Object>, Map<String, Object>>> claimTypeConverterFactory) {\n\t\tAssert.notNull(claimTypeConverterFactory, \"claimTypeConverterFactory cannot be null\");\n\t\tthis.claimTypeConverterFactory = claimTypeConverterFactory;\n\t}", "summary_tokens": ["sets", "the", "factory", "that", "provides", "a", "converter", "used", "for", "type", "conversion", "of", "claim", "values", "for", "an", "oidc", "user", "info"], "project": "spring-security"}
{"id": 2045, "code": "\tpublic boolean matches(HttpServletRequest request) {\n\t\tif (this.httpMethod != null && StringUtils.hasText(request.getMethod())\n\t\t\t\t&& this.httpMethod != HttpMethod.valueOf(request.getMethod())) {\n\t\t\treturn false;\n\t\t}\n\t\tif (this.pattern.equals(MATCH_ALL)) {\n\t\t\treturn true;\n\t\t}\n\t\tString url = getRequestPath(request);\n\t\treturn this.matcher.matches(url);\n\t}", "summary_tokens": ["returns", "true", "if", "the", "configured", "pattern", "and", "http", "method", "match", "those", "of", "the", "supplied", "request"], "project": "spring-security"}
{"id": 77, "code": "\tpublic LdapAuthenticationProviderConfigurer<AuthenticationManagerBuilder> ldapAuthentication() throws Exception {\n\t\treturn apply(new LdapAuthenticationProviderConfigurer<>());\n\t}", "summary_tokens": ["add", "ldap", "authentication", "to", "the", "authentication", "manager", "builder", "and", "return", "a", "ldap", "authentication", "provider", "configurer", "to", "allow", "customization", "of", "the", "ldap", "authentication"], "project": "spring-security"}
{"id": 1218, "code": "\tpublic static ClaimConversionService getSharedInstance() {\n\t\tClaimConversionService sharedInstance = ClaimConversionService.sharedInstance;\n\t\tif (sharedInstance == null) {\n\t\t\tsynchronized (ClaimConversionService.class) {\n\t\t\t\tsharedInstance = ClaimConversionService.sharedInstance;\n\t\t\t\tif (sharedInstance == null) {\n\t\t\t\t\tsharedInstance = new ClaimConversionService();\n\t\t\t\t\tClaimConversionService.sharedInstance = sharedInstance;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn sharedInstance;\n\t}", "summary_tokens": ["returns", "a", "shared", "instance", "of", "claim", "conversion", "service"], "project": "spring-security"}
{"id": 1099, "code": "\tpublic void setPostLogoutRedirectUri(String postLogoutRedirectUri) {\n\t\tAssert.notNull(postLogoutRedirectUri, \"postLogoutRedirectUri cannot be null\");\n\t\tthis.postLogoutRedirectUri = postLogoutRedirectUri;\n\t}", "summary_tokens": ["set", "the", "post", "logout", "redirect", "uri", "template"], "project": "spring-security"}
{"id": 20, "code": "\tpublic final void setLookupPrimaryKeysWhereClause(String lookupPrimaryKeysWhereClause) {\n\t\tthis.lookupPrimaryKeysWhereClause = lookupPrimaryKeysWhereClause;\n\t}", "summary_tokens": ["the", "sql", "for", "the", "where", "clause", "used", "in", "the", "tt", "lookup", "primary", "key", "tt", "method"], "project": "spring-security"}
{"id": 1742, "code": "\tprivate Authentication getSourceAuthentication(Authentication current) {\n\t\tAuthentication original = null;\n\t\t\n\t\tCollection<? extends GrantedAuthority> authorities = current.getAuthorities();\n\t\tfor (GrantedAuthority auth : authorities) {\n\t\t\t\n\t\t\tif (auth instanceof SwitchUserGrantedAuthority) {\n\t\t\t\toriginal = ((SwitchUserGrantedAuthority) auth).getSource();\n\t\t\t\tthis.logger.debug(LogMessage.format(\"Found original switch user granted authority [%s]\", original));\n\t\t\t}\n\t\t}\n\t\treturn original;\n\t}", "summary_tokens": ["find", "the", "original", "code", "authentication", "code", "object", "from", "the", "current", "user", "s", "granted", "authorities"], "project": "spring-security"}
{"id": 807, "code": "\tpublic void testGensalt() {\n\t\tprint(\"BCrypt.gensalt(): \");\n\t\tfor (int i = 0; i < testObjectsString.size(); i += 4) {\n\t\t\tString plain = testObjectsString.get(i).password;\n\t\t\tString salt = BCrypt.gensalt();\n\t\t\tString hashed1 = BCrypt.hashpw(plain, salt);\n\t\t\tString hashed2 = BCrypt.hashpw(plain, hashed1);\n\t\t\tassertThat(hashed2).isEqualTo(hashed1);\n\t\t\tprint(\".\");\n\t\t}\n\t\tprintln(\"\");\n\t}", "summary_tokens": ["test", "method", "for", "bcrypt"], "project": "spring-security"}
{"id": 112, "code": "\tpublic U getUserDetailsService() {\n\t\treturn this.userDetailsService;\n\t}", "summary_tokens": ["gets", "the", "user", "details", "service", "that", "is", "used", "with", "the", "dao", "authentication", "provider", "the", "user", "details", "service", "that", "is", "used", "with", "the", "dao", "authentication", "provider"], "project": "spring-security"}
{"id": 1040, "code": "\tpublic final void setParametersConverter(Converter<T, MultiValueMap<String, String>> parametersConverter) {\n\t\tAssert.notNull(parametersConverter, \"parametersConverter cannot be null\");\n\t\tthis.parametersConverter = parametersConverter;\n\t}", "summary_tokens": ["sets", "the", "converter", "used", "for", "converting", "the", "abstract", "oauth", "0", "authorization", "grant", "request", "instance", "to", "a", "multi", "value", "map", "of", "the", "parameters", "used", "in", "the", "oauth", "0"], "project": "spring-security"}
{"id": 1655, "code": "\tprivate void doAuthenticate(HttpServletRequest request, HttpServletResponse response)\n\t\t\tthrows IOException, ServletException {\n\t\tObject principal = getPreAuthenticatedPrincipal(request);\n\t\tif (principal == null) {\n\t\t\tthis.logger.debug(\"No pre-authenticated principal found in request\");\n\t\t\treturn;\n\t\t}\n\t\tthis.logger.debug(LogMessage.format(\"preAuthenticatedPrincipal = %s, trying to authenticate\", principal));\n\t\tObject credentials = getPreAuthenticatedCredentials(request);\n\t\ttry {\n\t\t\tPreAuthenticatedAuthenticationToken authenticationRequest = new PreAuthenticatedAuthenticationToken(\n\t\t\t\t\tprincipal, credentials);\n\t\t\tauthenticationRequest.setDetails(this.authenticationDetailsSource.buildDetails(request));\n\t\t\tAuthentication authenticationResult = this.authenticationManager.authenticate(authenticationRequest);\n\t\t\tsuccessfulAuthentication(request, response, authenticationResult);\n\t\t}\n\t\tcatch (AuthenticationException ex) {\n\t\t\tunsuccessfulAuthentication(request, response, ex);\n\t\t\tif (!this.continueFilterChainOnUnsuccessfulAuthentication) {\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["do", "the", "actual", "authentication", "for", "a", "pre", "authenticated", "user"], "project": "spring-security"}
{"id": 1079, "code": "\tpublic final void setAuthoritiesMapper(GrantedAuthoritiesMapper authoritiesMapper) {\n\t\tAssert.notNull(authoritiesMapper, \"authoritiesMapper cannot be null\");\n\t\tthis.authoritiesMapper = authoritiesMapper;\n\t}", "summary_tokens": ["sets", "the", "granted", "authorities", "mapper", "used", "for", "mapping", "oidc", "user", "get", "authorities", "to", "a", "new", "set", "of", "authorities", "which", "will", "be", "associated", "to", "the", "oauth", "0", "login", "authentication", "token"], "project": "spring-security"}
{"id": 1327, "code": "\tpublic static SecretKeyJwtDecoderBuilder withSecretKey(SecretKey secretKey) {\n\t\treturn new SecretKeyJwtDecoderBuilder(secretKey);\n\t}", "summary_tokens": ["use", "the", "given", "secret", "key", "to", "validate", "the", "mac", "on", "a", "json", "web", "signature", "jws"], "project": "spring-security"}
{"id": 683, "code": "\tpublic static void clearContext() {\n\t\tstrategy.clearContext();\n\t}", "summary_tokens": ["explicitly", "clears", "the", "context", "value", "from", "the", "current", "thread"], "project": "spring-security"}
{"id": 1406, "code": "\tdefault String getRelyingPartyRegistrationId() {\n\t\treturn null;\n\t}", "summary_tokens": ["get", "the", "relying", "party", "registration", "identifier", "the", "relying", "party", "registration", "identifier", "0"], "project": "spring-security"}
{"id": 42, "code": "\tpublic Map<String, LocalDate> getTrainDates() {\n\t\tMap<String, LocalDate> releaseDates = new LinkedHashMap<>();\n\t\tswitch (this.releaseTrainSpec.getTrain()) {\n\t\t\tcase ONE:\n\t\t\t\taddTrainDate(releaseDates, \"M1\", Month.JANUARY);\n\t\t\t\taddTrainDate(releaseDates, \"M2\", Month.FEBRUARY);\n\t\t\t\taddTrainDate(releaseDates, \"M3\", Month.MARCH);\n\t\t\t\taddTrainDate(releaseDates, \"RC1\", Month.APRIL);\n\t\t\t\taddTrainDate(releaseDates, null, Month.MAY);\n\t\t\t\tbreak;\n\t\t\tcase TWO:\n\t\t\t\taddTrainDate(releaseDates, \"M1\", Month.JULY);\n\t\t\t\taddTrainDate(releaseDates, \"M2\", Month.AUGUST);\n\t\t\t\taddTrainDate(releaseDates, \"M3\", Month.SEPTEMBER);\n\t\t\t\taddTrainDate(releaseDates, \"RC1\", Month.OCTOBER);\n\t\t\t\taddTrainDate(releaseDates, null, Month.NOVEMBER);\n\t\t\t\tbreak;\n\t\t}\n\n\t\treturn releaseDates;\n\t}", "summary_tokens": ["calculate", "release", "train", "dates", "based", "on", "the", "release", "train", "specification"], "project": "spring-security"}
{"id": 1875, "code": "\tpublic void setPolicy(ReferrerPolicy policy) {\n\t\tAssert.notNull(policy, \"policy can not be null\");\n\t\tthis.policy = policy;\n\t}", "summary_tokens": ["sets", "the", "policy", "to", "be", "used", "in", "the", "response", "header"], "project": "spring-security"}
{"id": 192, "code": "\tpublic final T successHandler(AuthenticationSuccessHandler successHandler) {\n\t\tthis.successHandler = successHandler;\n\t\treturn getSelf();\n\t}", "summary_tokens": ["specifies", "the", "authentication", "success", "handler", "to", "be", "used"], "project": "spring-security"}
{"id": 608, "code": "\tstatic <A extends Annotation> A findUniqueAnnotation(Class<?> type, Class<A> annotationType) {\n\t\tMergedAnnotations mergedAnnotations = MergedAnnotations.from(type,\n\t\t\t\tMergedAnnotations.SearchStrategy.TYPE_HIERARCHY, RepeatableContainers.none());\n\t\tif (hasDuplicate(mergedAnnotations, annotationType)) {\n\t\t\tthrow new AnnotationConfigurationException(\"Found more than one annotation of type \" + annotationType\n\t\t\t\t\t+ \" attributed to \" + type\n\t\t\t\t\t+ \" Please remove the duplicate annotations and publish a bean to handle your authorization logic.\");\n\t\t}\n\t\treturn AnnotationUtils.findAnnotation(type, annotationType);\n\t}", "summary_tokens": ["perform", "an", "exhaustive", "search", "on", "the", "type", "hierarchy", "of", "the", "given", "class", "for", "the", "annotation", "of", "type", "annotation", "type", "including", "any", "annotations", "using", "annotation", "type", "as", "a", "meta", "annotation"], "project": "spring-security"}
{"id": 567, "code": "\tpublic void setCallbackHandlers(JaasAuthenticationCallbackHandler[] callbackHandlers) {\n\t\tthis.callbackHandlers = callbackHandlers;\n\t}", "summary_tokens": ["set", "the", "jaasauthentcation", "callback", "handler", "array", "to", "handle", "callback", "objects", "generated", "by", "the", "login", "context"], "project": "spring-security"}
{"id": 1583, "code": "\tpublic boolean hasIpAddress(String ipAddress) {\n\t\tIpAddressMatcher matcher = new IpAddressMatcher(ipAddress);\n\t\treturn matcher.matches(this.request);\n\t}", "summary_tokens": ["takes", "a", "specific", "ip", "address", "or", "a", "range", "using", "the", "ip", "netmask", "e"], "project": "spring-security"}
{"id": 2019, "code": "\tpublic void setCreateNewSession(boolean createNewSession) {\n\t\tthis.createNewSession = createNewSession;\n\t}", "summary_tokens": ["determines", "whether", "a", "new", "session", "should", "be", "created", "before", "redirecting", "to", "avoid", "possible", "looping", "issues", "where", "the", "same", "session", "id", "is", "sent", "with", "the", "redirected", "request"], "project": "spring-security"}
{"id": 322, "code": "\tpublic SessionManagementConfigurer<H> sessionAuthenticationFailureHandler(\n\t\t\tAuthenticationFailureHandler sessionAuthenticationFailureHandler) {\n\t\tthis.sessionAuthenticationFailureHandler = sessionAuthenticationFailureHandler;\n\t\treturn this;\n\t}", "summary_tokens": ["defines", "the", "authentication", "failure", "handler", "which", "will", "be", "used", "when", "the", "session", "authentication", "strategy", "raises", "an", "exception"], "project": "spring-security"}
{"id": 1690, "code": "\tprivate Document getDocument(InputStream aStream) {\n\t\ttry {\n\t\t\tDocumentBuilderFactory factory = DocumentBuilderFactory.newInstance();\n\t\t\tfactory.setValidating(false);\n\t\t\tDocumentBuilder builder = factory.newDocumentBuilder();\n\t\t\tbuilder.setEntityResolver(new MyEntityResolver());\n\t\t\treturn builder.parse(aStream);\n\t\t}\n\t\tcatch (FactoryConfigurationError | IOException | SAXException | ParserConfigurationException ex) {\n\t\t\tthrow new RuntimeException(\"Unable to parse document object\", ex);\n\t\t}\n\t\tfinally {\n\t\t\ttry {\n\t\t\t\taStream.close();\n\t\t\t}\n\t\t\tcatch (IOException ex) {\n\t\t\t\tthis.logger.warn(\"Failed to close input stream for web.xml\", ex);\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["document", "for", "the", "specified", "input", "stream"], "project": "spring-security"}
{"id": 1480, "code": "\tpublic void setResponseTimeValidationSkew(Duration responseTimeValidationSkew) {\n\t\tthis.responseTimeValidationSkew = responseTimeValidationSkew;\n\t}", "summary_tokens": ["sets", "the", "duration", "for", "how", "much", "time", "skew", "an", "assertion", "may", "tolerate", "during", "timestamp", "not", "on", "or", "before", "and", "not", "on", "or", "after", "validation"], "project": "spring-security"}
{"id": 402, "code": "\tpublic static UserDetailsResourceFactoryBean fromString(String users) {\n\t\tInMemoryResource resource = new InMemoryResource(users);\n\t\treturn fromResource(resource);\n\t}", "summary_tokens": ["creates", "a", "user", "details", "resource", "factory", "bean", "with", "a", "resource", "from", "the", "provided", "string", "users", "the", "string", "representing", "the", "users", "the", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 360, "code": "\tpublic OAuth2LoginConfigurer<B> tokenEndpoint(Customizer<TokenEndpointConfig> tokenEndpointCustomizer) {\n\t\ttokenEndpointCustomizer.customize(this.tokenEndpointConfig);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "the", "authorization", "server", "s", "token", "endpoint"], "project": "spring-security"}
{"id": 991, "code": "\tpublic OAuth2AuthorizedClientProviderBuilder refreshToken(Consumer<RefreshTokenGrantBuilder> builderConsumer) {\n\t\tRefreshTokenGrantBuilder builder = (RefreshTokenGrantBuilder) this.builders.computeIfAbsent(\n\t\t\t\tRefreshTokenOAuth2AuthorizedClientProvider.class, (k) -> new RefreshTokenGrantBuilder());\n\t\tbuilderConsumer.accept(builder);\n\t\treturn OAuth2AuthorizedClientProviderBuilder.this;\n\t}", "summary_tokens": ["configures", "support", "for", "the", "refresh", "token", "grant"], "project": "spring-security"}
{"id": 923, "code": "\tpublic void setBeanResolver(BeanResolver beanResolver) {\n\t\tthis.beanResolver = beanResolver;\n\t}", "summary_tokens": ["sets", "the", "bean", "resolver", "to", "be", "used", "on", "the", "expressions", "bean", "resolver", "the", "bean", "resolver", "to", "use"], "project": "spring-security"}
{"id": 47, "code": "\tstatic <T> Customizer<T> withDefaults() {\n\t\treturn (t) -> {\n\t\t};\n\t}", "summary_tokens": ["returns", "a", "customizer", "that", "does", "not", "alter", "the", "input", "argument"], "project": "spring-security"}
{"id": 1749, "code": "\tpublic void setSwitchUserMatcher(RequestMatcher switchUserMatcher) {\n\t\tAssert.notNull(switchUserMatcher, \"switchUserMatcher cannot be null\");\n\t\tthis.switchUserMatcher = switchUserMatcher;\n\t}", "summary_tokens": ["set", "the", "matcher", "to", "respond", "to", "switch", "user", "processing"], "project": "spring-security"}
{"id": 1084, "code": "\tpublic void setClockSkew(Duration clockSkew) {\n\t\tAssert.notNull(clockSkew, \"clockSkew cannot be null\");\n\t\tAssert.isTrue(clockSkew.getSeconds() >= 0, \"clockSkew must be >= 0\");\n\t\tthis.clockSkew = clockSkew;\n\t}", "summary_tokens": ["sets", "the", "maximum", "acceptable", "clock", "skew"], "project": "spring-security"}
{"id": 1298, "code": "\tpublic static Builder with(JwsAlgorithm jwsAlgorithm) {\n\t\treturn new Builder(jwsAlgorithm);\n\t}", "summary_tokens": ["returns", "a", "new", "builder", "initialized", "with", "the", "provided", "jws", "algorithm"], "project": "spring-security"}
{"id": 901, "code": "\tpublic void setConvertToUpperCase(boolean convertToUpperCase) {\n\t\tthis.convertToUpperCase = convertToUpperCase;\n\t}", "summary_tokens": ["determines", "whether", "role", "field", "values", "will", "be", "converted", "to", "upper", "case", "when", "loaded"], "project": "spring-security"}
{"id": 1025, "code": "\tpublic OAuth2AccessToken getAccessToken() {\n\t\treturn this.accessToken;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "access", "token", "access", "token"], "project": "spring-security"}
{"id": 1197, "code": "\tpublic final String getErrorCode() {\n\t\treturn this.errorCode;\n\t}", "summary_tokens": ["returns", "the", "error", "code"], "project": "spring-security"}
{"id": 87, "code": "\tprivate LdapAuthenticator createLdapAuthenticator(BaseLdapPathContextSource contextSource) {\n\t\tAbstractLdapAuthenticator ldapAuthenticator = (this.passwordEncoder != null)\n\t\t\t\t? createPasswordCompareAuthenticator(contextSource) : createBindAuthenticator(contextSource);\n\t\tLdapUserSearch userSearch = createUserSearch();\n\t\tif (userSearch != null) {\n\t\t\tldapAuthenticator.setUserSearch(userSearch);\n\t\t}\n\t\tif (this.userDnPatterns != null && this.userDnPatterns.length > 0) {\n\t\t\tldapAuthenticator.setUserDnPatterns(this.userDnPatterns);\n\t\t}\n\t\treturn postProcess(ldapAuthenticator);\n\t}", "summary_tokens": ["creates", "the", "ldap", "authenticator", "to", "use", "context", "source", "the", "base", "ldap", "path", "context", "source", "to", "use", "the", "ldap", "authenticator", "to", "use"], "project": "spring-security"}
{"id": 90, "code": "\tpublic ContextSourceBuilder contextSource() {\n\t\treturn this.contextSourceBuilder;\n\t}", "summary_tokens": ["allows", "easily", "configuring", "of", "a", "base", "ldap", "path", "context", "source", "with", "defaults", "pointing", "to", "an", "embedded", "ldap", "server", "that", "is", "created"], "project": "spring-security"}
{"id": 1785, "code": "\tprivate SecurityContext readSecurityContextFromSession(HttpSession httpSession) {\n\t\tif (httpSession == null) {\n\t\t\tthis.logger.trace(\"No HttpSession currently exists\");\n\t\t\treturn null;\n\t\t}\n\t\t\n\t\tObject contextFromSession = httpSession.getAttribute(this.springSecurityContextKey);\n\t\tif (contextFromSession == null) {\n\t\t\tif (this.logger.isTraceEnabled()) {\n\t\t\t\tthis.logger.trace(LogMessage.format(\"Did not find SecurityContext in HttpSession %s \"\n\t\t\t\t\t\t+ \"using the SPRING_SECURITY_CONTEXT session attribute\", httpSession.getId()));\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\n\t\t\n\t\tif (!(contextFromSession instanceof SecurityContext)) {\n\t\t\tthis.logger.warn(LogMessage.format(\n\t\t\t\t\t\"%s did not contain a SecurityContext but contained: '%s'; are you improperly \"\n\t\t\t\t\t\t\t+ \"modifying the HttpSession directly (you should always use SecurityContextHolder) \"\n\t\t\t\t\t\t\t+ \"or using the HttpSession attribute reserved for this class?\",\n\t\t\t\t\tthis.springSecurityContextKey, contextFromSession));\n\t\t\treturn null;\n\t\t}\n\n\t\tif (this.logger.isTraceEnabled()) {\n\t\t\tthis.logger.trace(\n\t\t\t\t\tLogMessage.format(\"Retrieved %s from %s\", contextFromSession, this.springSecurityContextKey));\n\t\t}\n\t\telse if (this.logger.isDebugEnabled()) {\n\t\t\tthis.logger.debug(LogMessage.format(\"Retrieved %s\", contextFromSession));\n\t\t}\n\t\t\n\t\treturn (SecurityContext) contextFromSession;\n\t}", "summary_tokens": ["http", "session", "the", "session", "obtained", "from", "the", "request"], "project": "spring-security"}
{"id": 1491, "code": "\tpublic void setAssertionValidator(Converter<AssertionToken, Saml2ResponseValidatorResult> assertionValidator) {\n\t\tAssert.notNull(assertionValidator, \"assertionValidator cannot be null\");\n\t\tthis.assertionValidator = assertionValidator;\n\t}", "summary_tokens": ["set", "the", "converter", "to", "use", "for", "validating", "each", "assertion", "in", "the", "saml", "0"], "project": "spring-security"}
{"id": 947, "code": "\tpublic void setAuthorizationSuccessHandler(ReactiveOAuth2AuthorizationSuccessHandler authorizationSuccessHandler) {\n\t\tAssert.notNull(authorizationSuccessHandler, \"authorizationSuccessHandler cannot be null\");\n\t\tthis.authorizationSuccessHandler = authorizationSuccessHandler;\n\t}", "summary_tokens": ["sets", "the", "handler", "that", "handles", "successful", "authorizations"], "project": "spring-security"}
{"id": 1175, "code": "\tprivate ClientRegistration.Builder registrationOidcFallback(String path, String body) throws Exception {\n\t\tthis.issuer = createIssuerFromServer(path);\n\t\tthis.response.put(\"issuer\", this.issuer);\n\t\tString responseBody = (body != null) ? body : this.mapper.writeValueAsString(this.response);\n\t\tfinal Dispatcher dispatcher = new Dispatcher() {\n\t\t\t@Override\n\t\t\tpublic MockResponse dispatch(RecordedRequest request) {\n\t\t\t\tswitch (request.getPath()) {\n\t\t\t\tcase \"/issuer1/.well-known/openid-configuration\":\n\t\t\t\tcase \"/.well-known/openid-configuration/\":\n\t\t\t\t\treturn buildSuccessMockResponse(responseBody);\n\t\t\t\t}\n\t\t\t\treturn new MockResponse().setResponseCode(404);\n\t\t\t}\n\t\t};\n\t\tthis.server.setDispatcher(dispatcher);\n\t\treturn ClientRegistrations.fromIssuerLocation(this.issuer).clientId(\"client-id\").clientSecret(\"client-secret\");\n\t}", "summary_tokens": ["simulates", "a", "situation", "when", "the", "client", "registration", "is", "used", "with", "a", "legacy", "application", "where", "the", "oidc", "discovery", "endpoint", "is", "issuer", "0"], "project": "spring-security"}
{"id": 547, "code": "\tprivate void copyDetails(Authentication source, Authentication dest) {\n\t\tif ((dest instanceof AbstractAuthenticationToken) && (dest.getDetails() == null)) {\n\t\t\tAbstractAuthenticationToken token = (AbstractAuthenticationToken) dest;\n\t\t\ttoken.setDetails(source.getDetails());\n\t\t}\n\t}", "summary_tokens": ["copies", "the", "authentication", "details", "from", "a", "source", "authentication", "object", "to", "a", "destination", "one", "provided", "the", "latter", "does", "not", "already", "have", "one", "set"], "project": "spring-security"}
{"id": 2009, "code": "\tpublic String getRemoteUser() {\n\t\tAuthentication auth = getAuthentication();\n\t\tif ((auth == null) || (auth.getPrincipal() == null)) {\n\t\t\treturn null;\n\t\t}\n\t\tif (auth.getPrincipal() instanceof UserDetails) {\n\t\t\treturn ((UserDetails) auth.getPrincipal()).getUsername();\n\t\t}\n\t\tif (auth instanceof AbstractAuthenticationToken) {\n\t\t\treturn auth.getName();\n\t\t}\n\t\treturn auth.getPrincipal().toString();\n\t}", "summary_tokens": ["returns", "the", "principal", "s", "name", "as", "obtained", "from", "the", "code", "security", "context", "holder", "code"], "project": "spring-security"}
{"id": 209, "code": "\tprotected final C chainRequestMatchers(List<RequestMatcher> requestMatchers) {\n\t\tthis.unmappedMatchers = requestMatchers;\n\t\treturn chainRequestMatchersInternal(requestMatchers);\n\t}", "summary_tokens": ["marks", "the", "request", "matcher", "s", "as", "unmapped", "and", "then", "calls", "chain", "request", "matchers", "internal", "list"], "project": "spring-security"}
{"id": 1467, "code": "\tpublic void setRequestMatcher(RequestMatcher requestMatcher) {\n\t\tAssert.notNull(requestMatcher, \"requestMatcher cannot be null\");\n\t\tthis.requestMatcher = requestMatcher;\n\t}", "summary_tokens": ["set", "the", "request", "matcher", "that", "determines", "whether", "this", "filter", "should", "handle", "the", "incoming", "http", "servlet", "request", "request", "matcher", "the", "request", "matcher", "to", "identify", "requests", "for", "metadata"], "project": "spring-security"}
{"id": 992, "code": "\tpublic OAuth2AuthorizedClientProviderBuilder clientCredentials(\n\t\t\tConsumer<ClientCredentialsGrantBuilder> builderConsumer) {\n\t\tClientCredentialsGrantBuilder builder = (ClientCredentialsGrantBuilder) this.builders.computeIfAbsent(\n\t\t\t\tClientCredentialsOAuth2AuthorizedClientProvider.class, (k) -> new ClientCredentialsGrantBuilder());\n\t\tbuilderConsumer.accept(builder);\n\t\treturn OAuth2AuthorizedClientProviderBuilder.this;\n\t}", "summary_tokens": ["configures", "support", "for", "the", "client", "credentials", "grant"], "project": "spring-security"}
{"id": 815, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 623, "code": "\tpublic void setRolePrefix(String rolePrefix) {\n\t\tAssert.notNull(rolePrefix, \"rolePrefix cannot be null\");\n\t\tthis.rolePrefix = rolePrefix;\n\t}", "summary_tokens": ["sets", "the", "role", "prefix"], "project": "spring-security"}
{"id": 156, "code": "\tpublic Saml2LogoutConfigurer<HttpSecurity> saml2Logout() throws Exception {\n\t\treturn getOrApply(new Saml2LogoutConfigurer<>(getContext()));\n\t}", "summary_tokens": ["configures", "logout", "support", "for", "an", "saml", "0"], "project": "spring-security"}
{"id": 419, "code": "\tpublic void setUserDnPatterns(String... userDnPatterns) {\n\t\tthis.userDnPatterns = userDnPatterns;\n\t}", "summary_tokens": ["if", "your", "users", "are", "at", "a", "fixed", "location", "in", "the", "directory", "i"], "project": "spring-security"}
{"id": 765, "code": "\tprivate static byte[] getAlphabet(int options) {\n\t\tif ((options & URL_SAFE) == URL_SAFE) {\n\t\t\treturn _URL_SAFE_ALPHABET;\n\t\t}\n\t\telse if ((options & ORDERED) == ORDERED) {\n\t\t\treturn _ORDERED_ALPHABET;\n\t\t}\n\t\telse {\n\t\t\treturn _STANDARD_ALPHABET;\n\t\t}\n\t}", "summary_tokens": ["returns", "one", "of", "the", "something", "alphabet", "byte", "arrays", "depending", "on", "the", "options", "specified"], "project": "spring-security"}
{"id": 684, "code": "\tpublic static SecurityContext getContext() {\n\t\treturn strategy.getContext();\n\t}", "summary_tokens": ["obtain", "the", "current", "code", "security", "context", "code"], "project": "spring-security"}
{"id": 283, "code": "\tpublic LogoutConfigurer<H> permitAll(boolean permitAll) {\n\t\tthis.permitAll = permitAll;\n\t\treturn this;\n\t}", "summary_tokens": ["grants", "access", "to", "the", "logout", "success", "url", "string", "and", "the", "logout", "url", "string", "for", "every", "user"], "project": "spring-security"}
{"id": 524, "code": "\tprotected Collection<ConfigAttribute> findAttributes(Method method, Class<?> targetClass) {\n\t\tif (targetClass == null) {\n\t\t\treturn null;\n\t\t}\n\t\treturn findAttributesSpecifiedAgainst(method, targetClass);\n\t}", "summary_tokens": ["will", "walk", "the", "method", "inheritance", "tree", "to", "find", "the", "most", "specific", "declaration", "applicable"], "project": "spring-security"}
{"id": 836, "code": "\tprivate void extractStringAttributeValues(DirContextAdapter adapter, Map<String, List<String>> record,\n\t\t\tString attributeName) {\n\t\tObject[] values = adapter.getObjectAttributes(attributeName);\n\t\tif (values == null || values.length == 0) {\n\t\t\tlogger.debug(LogMessage.format(\"Did not find attribute value for %s\", attributeName));\n\t\t\treturn;\n\t\t}\n\t\tList<String> stringValues = new ArrayList<>();\n\t\tfor (Object value : values) {\n\t\t\tif (value != null) {\n\t\t\t\tif (String.class.isAssignableFrom(value.getClass())) {\n\t\t\t\t\tstringValues.add((String) value);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tstringValues.add(value.toString());\n\t\t\t\t\tlogger.debug(LogMessage.format(\"Coerced attribute value for %s of type %s to a String\",\n\t\t\t\t\t\t\tattributeName, value.getClass()));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\trecord.put(attributeName, stringValues);\n\t}", "summary_tokens": ["extracts", "string", "values", "for", "a", "specified", "attribute", "name", "and", "places", "them", "in", "the", "map", "representing", "the", "ldap", "record", "if", "a", "value", "is", "not", "of", "type", "string", "it", "will", "derive", "it", "s", "value", "from", "the", "object", "to", "string", "adapter", "the", "adapter", "that", "contains", "the", "values", "record", "the", "map", "holding", "the", "attribute", "names", "and", "values", "attribute", "name", "the", "name", "for", "which", "to", "fetch", "the", "values", "from"], "project": "spring-security"}
{"id": 837, "code": "\tpublic DirContextOperations searchForSingleEntry(String base, String filter, Object[] params) {\n\t\treturn (DirContextOperations) executeReadOnly((ContextExecutor) (ctx) -> searchForSingleEntryInternal(ctx,\n\t\t\t\tthis.searchControls, base, filter, params));\n\t}", "summary_tokens": ["performs", "a", "search", "with", "the", "requirement", "that", "the", "search", "shall", "return", "a", "single", "directory", "entry", "and", "uses", "the", "supplied", "mapper", "to", "create", "the", "object", "from", "that", "entry"], "project": "spring-security"}
{"id": 36, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1210, "code": "\tdefault String getSubject() {\n\t\treturn getClaimAsString(OAuth2TokenIntrospectionClaimNames.SUB);\n\t}", "summary_tokens": ["returns", "usually", "a", "machine", "readable", "identifier", "sub", "of", "the", "resource", "owner", "who", "authorized", "the", "token", "usually", "a", "machine", "readable", "identifier", "of", "the", "resource", "owner", "who", "authorized", "the", "token"], "project": "spring-security"}
{"id": 351, "code": "\tpublic X509Configurer<H> subjectPrincipalRegex(String subjectPrincipalRegex) {\n\t\tSubjectDnX509PrincipalExtractor principalExtractor = new SubjectDnX509PrincipalExtractor();\n\t\tprincipalExtractor.setSubjectDnRegex(subjectPrincipalRegex);\n\t\tthis.x509PrincipalExtractor = principalExtractor;\n\t\treturn this;\n\t}", "summary_tokens": ["specifies", "the", "regex", "to", "extract", "the", "principal", "from", "the", "certificate"], "project": "spring-security"}
{"id": 1030, "code": "\tpublic OAuth2AuthorizationExchange getAuthorizationExchange() {\n\t\treturn this.authorizationExchange;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "authorization", "exchange", "authorization", "exchange"], "project": "spring-security"}
{"id": 1723, "code": "\tprivate static boolean equals(String expected, String actual) {\n\t\tbyte[] expectedBytes = bytesUtf8(expected);\n\t\tbyte[] actualBytes = bytesUtf8(actual);\n\t\treturn MessageDigest.isEqual(expectedBytes, actualBytes);\n\t}", "summary_tokens": ["constant", "time", "comparison", "to", "prevent", "against", "timing", "attacks"], "project": "spring-security"}
{"id": 1393, "code": "\tpublic boolean isSigningCredential() {\n\t\treturn getCredentialTypes().contains(Saml2X509CredentialType.SIGNING);\n\t}", "summary_tokens": ["indicate", "whether", "this", "credential", "can", "be", "used", "for", "signing", "true", "if", "the", "credential", "has", "a", "saml", "0", "x", "0", "credential", "type", "signing", "type"], "project": "spring-security"}
{"id": 19, "code": "\tpublic final void setSelectClause(String selectClause) {\n\t\tthis.selectClause = selectClause;\n\t}", "summary_tokens": ["the", "sql", "for", "the", "select", "clause"], "project": "spring-security"}
{"id": 1849, "code": "\tpublic void setAllowedHostnames(Predicate<String> allowedHostnames) {\n\t\tAssert.notNull(allowedHostnames, \"allowedHostnames cannot be null\");\n\t\tthis.allowedHostnames = allowedHostnames;\n\t}", "summary_tokens": ["p", "determines", "which", "hostnames", "should", "be", "allowed"], "project": "spring-security"}
{"id": 152, "code": "\tpublic HttpSecurity servletApi(Customizer<ServletApiConfigurer<HttpSecurity>> servletApiCustomizer)\n\t\t\tthrows Exception {\n\t\tservletApiCustomizer.customize(getOrApply(new ServletApiConfigurer<>()));\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["integrates", "the", "http", "servlet", "request", "methods", "with", "the", "values", "found", "on", "the", "security", "context"], "project": "spring-security"}
{"id": 135, "code": "\tpublic C regexMatchers(String... regexPatterns) {\n\t\tAssert.state(!this.anyRequestConfigured, \"Can't configure regexMatchers after anyRequest\");\n\t\treturn chainRequestMatchers(RequestMatchers.regexMatchers(regexPatterns));\n\t}", "summary_tokens": ["create", "a", "list", "of", "org"], "project": "spring-security"}
{"id": 13, "code": "\tprivate Long convertToLong(Serializable identifier) {\n\t\tif (this.conversionService.canConvert(identifier.getClass(), Long.class)) {\n\t\t\treturn this.conversionService.convert(identifier, Long.class);\n\t\t}\n\t\treturn Long.valueOf(identifier.toString());\n\t}", "summary_tokens": ["converts", "to", "a", "long", "attempting", "to", "use", "the", "conversion", "service", "if", "available"], "project": "spring-security"}
{"id": 1409, "code": "\tpublic Object getCredentials() {\n\t\treturn getSaml2Response();\n\t}", "summary_tokens": ["returns", "the", "decoded", "and", "inflated", "saml", "0"], "project": "spring-security"}
{"id": 279, "code": "\tpublic LogoutConfigurer<H> invalidateHttpSession(boolean invalidateHttpSession) {\n\t\tthis.contextLogoutHandler.setInvalidateHttpSession(invalidateHttpSession);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "security", "context", "logout", "handler", "to", "invalidate", "the", "http", "session", "at", "the", "time", "of", "logout"], "project": "spring-security"}
{"id": 1391, "code": "\tpublic static Saml2X509Credential signing(PrivateKey privateKey, X509Certificate certificate) {\n\t\treturn new Saml2X509Credential(privateKey, certificate, Saml2X509Credential.Saml2X509CredentialType.SIGNING);\n\t}", "summary_tokens": ["create", "a", "saml", "0", "x", "0", "credential", "that", "can", "be", "used", "for", "signing"], "project": "spring-security"}
{"id": 942, "code": "\tpublic void setAuthorizationSuccessHandler(OAuth2AuthorizationSuccessHandler authorizationSuccessHandler) {\n\t\tAssert.notNull(authorizationSuccessHandler, \"authorizationSuccessHandler cannot be null\");\n\t\tthis.authorizationSuccessHandler = authorizationSuccessHandler;\n\t}", "summary_tokens": ["sets", "the", "oauth", "0", "authorization", "success", "handler", "that", "handles", "successful", "authorizations"], "project": "spring-security"}
{"id": 960, "code": "\tpublic OAuth2AuthorizedClient authorize(OAuth2AuthorizationContext context) {\n\t\tAssert.notNull(context, \"context cannot be null\");\n\t\tClientRegistration clientRegistration = context.getClientRegistration();\n\t\tif (!AuthorizationGrantType.JWT_BEARER.equals(clientRegistration.getAuthorizationGrantType())) {\n\t\t\treturn null;\n\t\t}\n\t\tOAuth2AuthorizedClient authorizedClient = context.getAuthorizedClient();\n\t\tif (authorizedClient != null && !hasTokenExpired(authorizedClient.getAccessToken())) {\n\t\t\t\n\t\t\t\n\t\t\treturn null;\n\t\t}\n\t\tJwt jwt = this.jwtAssertionResolver.apply(context);\n\t\tif (jwt == null) {\n\t\t\treturn null;\n\t\t}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tJwtBearerGrantRequest jwtBearerGrantRequest = new JwtBearerGrantRequest(clientRegistration, jwt);\n\t\tOAuth2AccessTokenResponse tokenResponse = getTokenResponse(clientRegistration, jwtBearerGrantRequest);\n\t\treturn new OAuth2AuthorizedClient(clientRegistration, context.getPrincipal().getName(),\n\t\t\t\ttokenResponse.getAccessToken());\n\t}", "summary_tokens": ["attempt", "to", "authorize", "or", "re", "authorize", "the", "oauth", "0", "authorization", "context", "get", "client", "registration", "client", "in", "the", "provided", "context"], "project": "spring-security"}
{"id": 940, "code": "\tpublic void setAuthorizedClientProvider(OAuth2AuthorizedClientProvider authorizedClientProvider) {\n\t\tAssert.notNull(authorizedClientProvider, \"authorizedClientProvider cannot be null\");\n\t\tthis.authorizedClientProvider = authorizedClientProvider;\n\t}", "summary_tokens": ["sets", "the", "oauth", "0", "authorized", "client", "provider", "used", "for", "authorizing", "or", "re", "authorizing", "an", "oauth", "0"], "project": "spring-security"}
{"id": 1229, "code": "\tpublic OAuth2AuthorizationResponseType getResponseType() {\n\t\treturn this.responseType;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "authorization", "response", "type", "response", "type"], "project": "spring-security"}
{"id": 1824, "code": "\tpublic void setSessionAttributeName(String sessionAttributeName) {\n\t\tAssert.hasLength(sessionAttributeName, \"sessionAttributename cannot be null or empty\");\n\t\tthis.sessionAttributeName = sessionAttributeName;\n\t}", "summary_tokens": ["sets", "the", "http", "session", "attribute", "name", "that", "the", "csrf", "token", "is", "stored", "in", "session", "attribute", "name", "the", "new", "attribute", "name", "to", "use"], "project": "spring-security"}
{"id": 147, "code": "\tpublic HttpSecurity authorizeRequests(\n\t\t\tCustomizer<ExpressionUrlAuthorizationConfigurer<HttpSecurity>.ExpressionInterceptUrlRegistry> authorizeRequestsCustomizer)\n\t\t\tthrows Exception {\n\t\tApplicationContext context = getContext();\n\t\tauthorizeRequestsCustomizer\n\t\t\t\t.customize(getOrApply(new ExpressionUrlAuthorizationConfigurer<>(context)).getRegistry());\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["allows", "restricting", "access", "based", "upon", "the", "http", "servlet", "request", "using", "request", "matcher", "implementations", "i"], "project": "spring-security"}
{"id": 437, "code": "\tpublic static UserDetailsManagerResourceFactoryBean fromString(String users) {\n\t\tUserDetailsManagerResourceFactoryBean result = new UserDetailsManagerResourceFactoryBean();\n\t\tresult.setResource(new InMemoryResource(users));\n\t\treturn result;\n\t}", "summary_tokens": ["create", "a", "user", "details", "manager", "resource", "factory", "bean", "with", "a", "string", "that", "is", "in", "the", "format", "defined", "in", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 84, "code": "\tprivate LdapAuthoritiesPopulator getLdapAuthoritiesPopulator() {\n\t\tif (this.ldapAuthoritiesPopulator != null) {\n\t\t\treturn this.ldapAuthoritiesPopulator;\n\t\t}\n\t\tDefaultLdapAuthoritiesPopulator defaultAuthoritiesPopulator = new DefaultLdapAuthoritiesPopulator(\n\t\t\t\tthis.contextSource, this.groupSearchBase);\n\t\tdefaultAuthoritiesPopulator.setGroupRoleAttribute(this.groupRoleAttribute);\n\t\tdefaultAuthoritiesPopulator.setGroupSearchFilter(this.groupSearchFilter);\n\t\tdefaultAuthoritiesPopulator.setSearchSubtree(this.groupSearchSubtree);\n\t\tdefaultAuthoritiesPopulator.setRolePrefix(this.rolePrefix);\n\t\tthis.ldapAuthoritiesPopulator = postProcess(defaultAuthoritiesPopulator);\n\t\treturn defaultAuthoritiesPopulator;\n\t}", "summary_tokens": ["gets", "the", "ldap", "authorities", "populator", "and", "defaults", "to", "default", "ldap", "authorities", "populator", "the", "ldap", "authorities", "populator"], "project": "spring-security"}
{"id": 3, "code": "\tpublic boolean supports(Class<?> clazz) {\n\t\treturn true;\n\t}", "summary_tokens": ["this", "implementation", "supports", "any", "type", "of", "class", "because", "it", "does", "not", "query", "the", "presented", "secure", "object"], "project": "spring-security"}
{"id": 961, "code": "\tpublic void setAccessTokenResponseClient(\n\t\t\tOAuth2AccessTokenResponseClient<JwtBearerGrantRequest> accessTokenResponseClient) {\n\t\tAssert.notNull(accessTokenResponseClient, \"accessTokenResponseClient cannot be null\");\n\t\tthis.accessTokenResponseClient = accessTokenResponseClient;\n\t}", "summary_tokens": ["sets", "the", "client", "used", "when", "requesting", "an", "access", "token", "credential", "at", "the", "token", "endpoint", "for", "the", "jwt", "bearer", "grant"], "project": "spring-security"}
{"id": 166, "code": "\tpublic HttpSecurity regexMatcher(String pattern) {\n\t\treturn requestMatcher(new RegexRequestMatcher(pattern, null));\n\t}", "summary_tokens": ["allows", "configuring", "the", "http", "security", "to", "only", "be", "invoked", "when", "matching", "the", "provided", "regex", "pattern"], "project": "spring-security"}
{"id": 631, "code": "\tpublic Mono<AuthorizationDecision> check(Mono<Authentication> authentication, MethodInvocationResult result) {\n\t\tMethodInvocation mi = result.getMethodInvocation();\n\t\tExpressionAttribute attribute = this.registry.getAttribute(mi);\n\t\tif (attribute == ExpressionAttribute.NULL_ATTRIBUTE) {\n\t\t\treturn Mono.empty();\n\t\t}\n\t\tMethodSecurityExpressionHandler expressionHandler = this.registry.getExpressionHandler();\n\t\t\n\t\treturn authentication\n\t\t\t\t.map((auth) -> expressionHandler.createEvaluationContext(auth, mi))\n\t\t\t\t.doOnNext((ctx) -> expressionHandler.setReturnObject(result.getResult(), ctx))\n\t\t\t\t.flatMap((ctx) -> ReactiveExpressionUtils.evaluateAsBoolean(attribute.getExpression(), ctx))\n\t\t\t\t.map((granted) -> new ExpressionAttributeAuthorizationDecision(granted, attribute));\n\t\t\n\t}", "summary_tokens": ["determines", "if", "an", "authentication", "has", "access", "to", "the", "returned", "object", "from", "the", "method", "invocation", "by", "evaluating", "an", "expression", "from", "the", "post", "authorize", "annotation"], "project": "spring-security"}
{"id": 1717, "code": "\tpublic void setAuthenticationSuccessHandler(AuthenticationSuccessHandler successHandler) {\n\t\tAssert.notNull(successHandler, \"successHandler cannot be null\");\n\t\tthis.successHandler = successHandler;\n\t}", "summary_tokens": ["allows", "control", "over", "the", "destination", "a", "remembered", "user", "is", "sent", "to", "when", "they", "are", "successfully", "authenticated"], "project": "spring-security"}
{"id": 1211, "code": "\tdefault List<String> getAudience() {\n\t\treturn getClaimAsStringList(OAuth2TokenIntrospectionClaimNames.AUD);\n\t}", "summary_tokens": ["returns", "the", "intended", "audience", "aud", "for", "the", "token", "the", "intended", "audience", "for", "the", "token"], "project": "spring-security"}
{"id": 352, "code": "\tpublic OAuth2ClientConfigurer<B> clientRegistrationRepository(\n\t\t\tClientRegistrationRepository clientRegistrationRepository) {\n\t\tAssert.notNull(clientRegistrationRepository, \"clientRegistrationRepository cannot be null\");\n\t\tthis.getBuilder().setSharedObject(ClientRegistrationRepository.class, clientRegistrationRepository);\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "repository", "of", "client", "registrations"], "project": "spring-security"}
{"id": 1297, "code": "\tpublic <T> T getHeader(String name) {\n\t\tAssert.hasText(name, \"name cannot be empty\");\n\t\treturn (T) getHeaders().get(name);\n\t}", "summary_tokens": ["returns", "the", "header", "value"], "project": "spring-security"}
{"id": 1815, "code": "\tpublic void setRequireCsrfProtectionMatcher(RequestMatcher requireCsrfProtectionMatcher) {\n\t\tAssert.notNull(requireCsrfProtectionMatcher, \"requireCsrfProtectionMatcher cannot be null\");\n\t\tthis.requireCsrfProtectionMatcher = requireCsrfProtectionMatcher;\n\t}", "summary_tokens": ["specifies", "a", "request", "matcher", "that", "is", "used", "to", "determine", "if", "csrf", "protection", "should", "be", "applied"], "project": "spring-security"}
{"id": 1155, "code": "\tpublic Consumer<WebClient.Builder> oauth2Configuration() {\n\t\treturn (builder) -> builder.defaultRequest(defaultRequest()).filter(this);\n\t}", "summary_tokens": ["configures", "the", "builder", "with", "default", "request", "and", "adds", "this", "as", "a", "exchange", "filter", "function", "the", "consumer", "to", "configure", "the", "builder"], "project": "spring-security"}
{"id": 857, "code": "\tpublic void setContextEnvironmentProperties(Map<String, Object> environment) {\n\t\tAssert.notEmpty(environment, \"environment must not be empty\");\n\t\tthis.contextEnvironmentProperties = new Hashtable<>(environment);\n\t}", "summary_tokens": ["allows", "a", "custom", "environment", "properties", "to", "be", "used", "to", "create", "initial", "ldap", "context"], "project": "spring-security"}
{"id": 252, "code": "\tpublic HeadersConfigurer<H> cacheControl(Customizer<CacheControlConfig> cacheControlCustomizer) {\n\t\tcacheControlCustomizer.customize(this.cacheControl.enable());\n\t\treturn HeadersConfigurer.this;\n\t}", "summary_tokens": ["allows", "customizing", "the", "cache", "control", "headers", "writer"], "project": "spring-security"}
{"id": 107, "code": "\tpublic JdbcUserDetailsManagerConfigurer<B> withDefaultSchema() {\n\t\tthis.initScripts.add(new ClassPathResource(\"org/springframework/security/core/userdetails/jdbc/users.ddl\"));\n\t\treturn this;\n\t}", "summary_tokens": ["populates", "the", "default", "schema", "that", "allows", "users", "and", "authorities", "to", "be", "stored"], "project": "spring-security"}
{"id": 1274, "code": "\tdefault String getWebsite() {\n\t\treturn this.getClaimAsString(StandardClaimNames.WEBSITE);\n\t}", "summary_tokens": ["returns", "the", "url", "of", "the", "user", "s", "web", "page", "or", "blog", "website"], "project": "spring-security"}
{"id": 1530, "code": "\tpublic static OAuth2ClientMutator mockOAuth2Client(String registrationId) {\n\t\treturn new OAuth2ClientMutator(registrationId);\n\t}", "summary_tokens": ["updates", "the", "server", "web", "exchange", "to", "establish", "a", "oauth", "0", "authorized", "client", "in", "the", "session"], "project": "spring-security"}
{"id": 1886, "code": "\tpublic void setBeanResolver(BeanResolver beanResolver) {\n\t\tthis.beanResolver = beanResolver;\n\t}", "summary_tokens": ["sets", "the", "bean", "resolver", "to", "be", "used", "on", "the", "expressions", "bean", "resolver", "the", "bean", "resolver", "to", "use"], "project": "spring-security"}
{"id": 1004, "code": "\tpublic final void setAuthorizedClientRowMapper(\n\t\t\tBiFunction<Row, RowMetadata, OAuth2AuthorizedClientHolder> authorizedClientRowMapper) {\n\t\tAssert.notNull(authorizedClientRowMapper, \"authorizedClientRowMapper cannot be null\");\n\t\tthis.authorizedClientRowMapper = authorizedClientRowMapper;\n\t}", "summary_tokens": ["sets", "the", "bi", "function", "used", "for", "mapping", "the", "current", "io"], "project": "spring-security"}
{"id": 1242, "code": "\tpublic boolean statusOk() {\n\t\treturn !this.statusError();\n\t}", "summary_tokens": ["returns", "true", "if", "the", "authorization", "request", "succeeded", "otherwise", "false"], "project": "spring-security"}
{"id": 1438, "code": "\tpublic RelyingPartyRegistration getRelyingPartyRegistration() {\n\t\treturn this.registration;\n\t}", "summary_tokens": ["the", "relying", "party", "registration", "representing", "this", "relying", "party", "the", "relying", "party"], "project": "spring-security"}
{"id": 1265, "code": "\tdefault String getSubject() {\n\t\treturn this.getClaimAsString(StandardClaimNames.SUB);\n\t}", "summary_tokens": ["returns", "the", "subject", "identifier", "sub"], "project": "spring-security"}
{"id": 624, "code": "\tpublic AuthorizationDecision check(Supplier<Authentication> authentication, MethodInvocation methodInvocation) {\n\t\tAuthorizationManager<MethodInvocation> delegate = this.registry.getManager(methodInvocation);\n\t\treturn delegate.check(authentication, methodInvocation);\n\t}", "summary_tokens": ["determine", "if", "an", "authentication", "has", "access", "to", "a", "method", "by", "evaluating", "the", "deny", "all", "permit", "all", "and", "roles", "allowed", "annotations", "that", "method", "invocation", "specifies"], "project": "spring-security"}
{"id": 1788, "code": "\tpublic void setDisableUrlRewriting(boolean disableUrlRewriting) {\n\t\tthis.disableUrlRewriting = disableUrlRewriting;\n\t}", "summary_tokens": ["allows", "the", "use", "of", "session", "identifiers", "in", "urls", "to", "be", "disabled"], "project": "spring-security"}
{"id": 1011, "code": "\tpublic ReactiveOAuth2AuthorizedClientProvider build() {\n\t\tList<ReactiveOAuth2AuthorizedClientProvider> authorizedClientProviders = this.builders.values().stream()\n\t\t\t\t.map(Builder::build).collect(Collectors.toList());\n\t\treturn new DelegatingReactiveOAuth2AuthorizedClientProvider(authorizedClientProviders);\n\t}", "summary_tokens": ["builds", "an", "instance", "of", "delegating", "reactive", "oauth", "0", "authorized", "client", "provider", "composed", "of", "one", "or", "more", "reactive", "oauth", "0", "authorized", "client", "provider", "s"], "project": "spring-security"}
{"id": 125, "code": "\tpublic PreInvocationAuthorizationAdvice preInvocationAuthorizationAdvice() {\n\t\tExpressionBasedPreInvocationAdvice preInvocationAdvice = new ExpressionBasedPreInvocationAdvice();\n\t\tpreInvocationAdvice.setExpressionHandler(getExpressionHandler());\n\t\treturn preInvocationAdvice;\n\t}", "summary_tokens": ["creates", "the", "pre", "invocation", "authorization", "advice", "to", "be", "used"], "project": "spring-security"}
{"id": 367, "code": "\tpublic Saml2LoginConfigurer<B> relyingPartyRegistrationRepository(RelyingPartyRegistrationRepository repo) {\n\t\tthis.relyingPartyRegistrationRepository = repo;\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "relying", "party", "registration", "repository", "of", "relying", "parties", "each", "party", "representing", "a", "service", "provider", "sp", "and", "this", "host", "and", "identity", "provider", "idp", "pair", "that", "communicate", "with", "each", "other"], "project": "spring-security"}
{"id": 1579, "code": "\tpublic void setTrustResolver(AuthenticationTrustResolver trustResolver) {\n\t\tAssert.notNull(trustResolver, \"trustResolver cannot be null\");\n\t\tthis.trustResolver = trustResolver;\n\t}", "summary_tokens": ["sets", "the", "authentication", "trust", "resolver", "to", "be", "used"], "project": "spring-security"}
{"id": 1414, "code": "\tpublic Saml2MessageBinding getBinding() {\n\t\treturn Saml2MessageBinding.POST;\n\t}", "summary_tokens": ["saml", "0", "message", "binding", "post"], "project": "spring-security"}
{"id": 1559, "code": "\tpublic void sendRedirect(HttpServletRequest request, HttpServletResponse response, String url) throws IOException {\n\t\tString redirectUrl = calculateRedirectUrl(request.getContextPath(), url);\n\t\tredirectUrl = response.encodeRedirectURL(redirectUrl);\n\t\tif (this.logger.isDebugEnabled()) {\n\t\t\tthis.logger.debug(LogMessage.format(\"Redirecting to %s\", redirectUrl));\n\t\t}\n\t\tresponse.sendRedirect(redirectUrl);\n\t}", "summary_tokens": ["redirects", "the", "response", "to", "the", "supplied", "url"], "project": "spring-security"}
{"id": 976, "code": "\tpublic static Builder withAuthorizedClient(OAuth2AuthorizedClient authorizedClient) {\n\t\treturn new Builder(authorizedClient);\n\t}", "summary_tokens": ["returns", "a", "new", "builder", "initialized", "with", "the", "oauth", "0", "authorized", "client"], "project": "spring-security"}
{"id": 1874, "code": "\tpublic void setPolicy(String policy) {\n\t\tAssert.hasLength(policy, \"policy can not be null or empty\");\n\t\tthis.policy = policy;\n\t}", "summary_tokens": ["sets", "the", "policy", "to", "be", "used", "in", "the", "response", "header"], "project": "spring-security"}
{"id": 315, "code": "\tpublic RequestCacheConfigurer<H> requestCache(RequestCache requestCache) {\n\t\tgetBuilder().setSharedObject(RequestCache.class, requestCache);\n\t\treturn this;\n\t}", "summary_tokens": ["allows", "explicit", "configuration", "of", "the", "request", "cache", "to", "be", "used"], "project": "spring-security"}
{"id": 2042, "code": "\tprivate static String buildRequestUrl(String servletPath, String requestURI, String contextPath, String pathInfo,\n\t\t\tString queryString) {\n\t\tStringBuilder url = new StringBuilder();\n\t\tif (servletPath != null) {\n\t\t\turl.append(servletPath);\n\t\t\tif (pathInfo != null) {\n\t\t\t\turl.append(pathInfo);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\turl.append(requestURI.substring(contextPath.length()));\n\t\t}\n\t\tif (queryString != null) {\n\t\t\turl.append(\"?\").append(queryString);\n\t\t}\n\t\treturn url.toString();\n\t}", "summary_tokens": ["obtains", "the", "web", "application", "specific", "fragment", "of", "the", "url"], "project": "spring-security"}
{"id": 453, "code": "\tpublic ServerHttpSecurity oauth2Login(Customizer<OAuth2LoginSpec> oauth2LoginCustomizer) {\n\t\tif (this.oauth2Login == null) {\n\t\t\tthis.oauth2Login = new OAuth2LoginSpec();\n\t\t}\n\t\toauth2LoginCustomizer.customize(this.oauth2Login);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "authentication", "support", "using", "an", "oauth", "0"], "project": "spring-security"}
{"id": 772, "code": "\tpublic static String decode(byte[] bytes) {\n\t\ttry {\n\t\t\treturn CHARSET.newDecoder().decode(ByteBuffer.wrap(bytes)).toString();\n\t\t}\n\t\tcatch (CharacterCodingException ex) {\n\t\t\tthrow new IllegalArgumentException(\"Decoding failed\", ex);\n\t\t}\n\t}", "summary_tokens": ["decode", "the", "bytes", "in", "utf", "0", "form", "into", "a", "string"], "project": "spring-security"}
{"id": 1978, "code": "\tpublic void setPolicy(String policy) {\n\t\tAssert.notNull(policy, \"policy must not be null\");\n\t\tthis.delegate = createDelegate(policy);\n\t}", "summary_tokens": ["set", "the", "policy", "to", "be", "used", "in", "the", "response", "header"], "project": "spring-security"}
{"id": 429, "code": "\tpublic void setPasswordEncoder(PasswordEncoder passwordEncoder) {\n\t\tAssert.notNull(passwordEncoder, \"passwordEncoder must not be null.\");\n\t\tthis.passwordEncoder = passwordEncoder;\n\t}", "summary_tokens": ["specifies", "the", "password", "encoder", "to", "be", "used", "when", "authenticating", "with", "password", "comparison"], "project": "spring-security"}
{"id": 544, "code": "\tpublic void setAdditionalExceptionMappings(\n\t\t\tMap<Class<? extends AuthenticationException>, Class<? extends AbstractAuthenticationFailureEvent>> mappings) {\n\t\tAssert.notEmpty(mappings, \"The mappings Map must not be empty nor null\");\n\t\tfor (Map.Entry<Class<? extends AuthenticationException>, Class<? extends AbstractAuthenticationFailureEvent>> entry : mappings\n\t\t\t\t.entrySet()) {\n\t\t\tClass<?> exceptionClass = entry.getKey();\n\t\t\tClass<?> eventClass = entry.getValue();\n\t\t\tAssert.notNull(exceptionClass, \"exceptionClass cannot be null\");\n\t\t\tAssert.notNull(eventClass, \"eventClass cannot be null\");\n\t\t\taddMapping(exceptionClass.getName(), (Class<? extends AbstractAuthenticationFailureEvent>) eventClass);\n\t\t}\n\t}", "summary_tokens": ["sets", "additional", "exception", "to", "event", "mappings"], "project": "spring-security"}
{"id": 1606, "code": "\tprotected void handle(HttpServletRequest request, HttpServletResponse response, Authentication authentication)\n\t\t\tthrows IOException, ServletException {\n\t\tString targetUrl = determineTargetUrl(request, response, authentication);\n\t\tif (response.isCommitted()) {\n\t\t\tthis.logger.debug(LogMessage.format(\"Did not redirect to %s since response already committed.\", targetUrl));\n\t\t\treturn;\n\t\t}\n\t\tthis.redirectStrategy.sendRedirect(request, response, targetUrl);\n\t}", "summary_tokens": ["invokes", "the", "configured", "redirect", "strategy", "with", "the", "url", "returned", "by", "the", "determine", "target", "url", "method"], "project": "spring-security"}
{"id": 1991, "code": "\tpublic void setUseEquals(boolean useEquals) {\n\t\tthis.useEquals = useEquals;\n\t}", "summary_tokens": ["if", "set", "to", "true", "matches", "on", "exact", "media", "type", "else", "uses", "media", "type", "is", "compatible", "with", "media", "type"], "project": "spring-security"}
{"id": 656, "code": "\tprivate static boolean disableChecks(String springVersion, String springSecurityVersion) {\n\t\tif (springVersion == null || springVersion.equals(springSecurityVersion)) {\n\t\t\treturn true;\n\t\t}\n\t\treturn Boolean.getBoolean(DISABLE_CHECKS);\n\t}", "summary_tokens": ["disable", "if", "spring", "version", "and", "spring", "security", "version", "are", "the", "same", "to", "allow", "working", "with", "uber", "jars"], "project": "spring-security"}
{"id": 1128, "code": "\tpublic void setContextAttributesMapper(\n\t\t\tFunction<OAuth2AuthorizeRequest, Map<String, Object>> contextAttributesMapper) {\n\t\tAssert.notNull(contextAttributesMapper, \"contextAttributesMapper cannot be null\");\n\t\tthis.contextAttributesMapper = contextAttributesMapper;\n\t}", "summary_tokens": ["sets", "the", "function", "used", "for", "mapping", "attribute", "s", "from", "the", "oauth", "0", "authorize", "request", "to", "a", "map", "of", "attributes", "to", "be", "associated", "to", "the", "oauth", "0", "authorization", "context", "get", "attributes", "authorization", "context"], "project": "spring-security"}
{"id": 449, "code": "\tpublic ServerHttpSecurity anonymous(Customizer<AnonymousSpec> anonymousCustomizer) {\n\t\tif (this.anonymous == null) {\n\t\t\tthis.anonymous = new AnonymousSpec();\n\t\t}\n\t\tanonymousCustomizer.customize(this.anonymous);\n\t\treturn this;\n\t}", "summary_tokens": ["enables", "and", "configures", "anonymous", "authentication"], "project": "spring-security"}
{"id": 1651, "code": "\tpublic void setClearAuthentication(boolean clearAuthentication) {\n\t\tthis.clearAuthentication = clearAuthentication;\n\t}", "summary_tokens": ["if", "true", "removes", "the", "authentication", "from", "the", "security", "context", "to", "prevent", "issues", "with", "concurrent", "requests"], "project": "spring-security"}
{"id": 921, "code": "\tprivate <T extends Annotation> T findMethodAnnotation(Class<T> annotationClass, MethodParameter parameter) {\n\t\tT annotation = parameter.getParameterAnnotation(annotationClass);\n\t\tif (annotation != null) {\n\t\t\treturn annotation;\n\t\t}\n\t\tAnnotation[] annotationsToSearch = parameter.getParameterAnnotations();\n\t\tfor (Annotation toSearch : annotationsToSearch) {\n\t\t\tannotation = AnnotationUtils.findAnnotation(toSearch.annotationType(), annotationClass);\n\t\t\tif (annotation != null) {\n\t\t\t\treturn annotation;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["obtains", "the", "specified", "annotation", "on", "the", "specified", "method", "parameter"], "project": "spring-security"}
{"id": 187, "code": "\tprotected final ApplicationContext getApplicationContext() {\n\t\treturn this.context;\n\t}", "summary_tokens": ["gets", "the", "application", "context", "the", "context"], "project": "spring-security"}
{"id": 966, "code": "\tpublic void setAccessTokenResponseClient(\n\t\t\tReactiveOAuth2AccessTokenResponseClient<JwtBearerGrantRequest> accessTokenResponseClient) {\n\t\tAssert.notNull(accessTokenResponseClient, \"accessTokenResponseClient cannot be null\");\n\t\tthis.accessTokenResponseClient = accessTokenResponseClient;\n\t}", "summary_tokens": ["sets", "the", "client", "used", "when", "requesting", "an", "access", "token", "credential", "at", "the", "token", "endpoint", "for", "the", "jwt", "bearer", "grant"], "project": "spring-security"}
{"id": 793, "code": "\tpublic boolean matches(CharSequence rawPassword, String encodedPassword) {\n\t\tString salt = extractSalt(encodedPassword);\n\t\tString rawPasswordEncoded = digest(salt, rawPassword);\n\t\treturn PasswordEncoderUtils.equals(encodedPassword.toString(), rawPasswordEncoded);\n\t}", "summary_tokens": ["takes", "a", "previously", "encoded", "password", "and", "compares", "it", "with", "a", "rawpassword", "after", "mixing", "in", "the", "salt", "and", "encoding", "that", "value", "raw", "password", "plain", "text", "password", "encoded", "password", "previously", "encoded", "password", "true", "or", "false"], "project": "spring-security"}
{"id": 2041, "code": "\tpublic static String buildFullRequestUrl(String scheme, String serverName, int serverPort, String requestURI,\n\t\t\tString queryString) {\n\t\tscheme = scheme.toLowerCase();\n\t\tStringBuilder url = new StringBuilder();\n\t\turl.append(scheme).append(\"://\").append(serverName);\n\t\t\n\t\tif (\"http\".equals(scheme)) {\n\t\t\tif (serverPort != 80) {\n\t\t\t\turl.append(\":\").append(serverPort);\n\t\t\t}\n\t\t}\n\t\telse if (\"https\".equals(scheme)) {\n\t\t\tif (serverPort != 443) {\n\t\t\t\turl.append(\":\").append(serverPort);\n\t\t\t}\n\t\t}\n\t\t\n\t\t\n\t\turl.append(requestURI);\n\t\tif (queryString != null) {\n\t\t\turl.append(\"?\").append(queryString);\n\t\t}\n\t\treturn url.toString();\n\t}", "summary_tokens": ["obtains", "the", "full", "url", "the", "client", "used", "to", "make", "the", "request"], "project": "spring-security"}
{"id": 1503, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock must not be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["use", "this", "clock", "for", "determining", "the", "issued", "instant", "clock", "the", "clock", "to", "use"], "project": "spring-security"}
{"id": 1184, "code": "\tdefault String getClaimAsString(String claim) {\n\t\treturn !hasClaim(claim) ? null\n\t\t\t\t: ClaimConversionService.getSharedInstance().convert(getClaims().get(claim), String.class);\n\t}", "summary_tokens": ["returns", "the", "claim", "value", "as", "a", "string", "or", "null", "if", "it", "does", "not", "exist", "or", "is", "equal", "to", "null"], "project": "spring-security"}
{"id": 941, "code": "\tpublic void setContextAttributesMapper(\n\t\t\tFunction<OAuth2AuthorizeRequest, Map<String, Object>> contextAttributesMapper) {\n\t\tAssert.notNull(contextAttributesMapper, \"contextAttributesMapper cannot be null\");\n\t\tthis.contextAttributesMapper = contextAttributesMapper;\n\t}", "summary_tokens": ["sets", "the", "function", "used", "for", "mapping", "attribute", "s", "from", "the", "oauth", "0", "authorize", "request", "to", "a", "map", "of", "attributes", "to", "be", "associated", "to", "the", "oauth", "0", "authorization", "context", "get", "attributes", "authorization", "context"], "project": "spring-security"}
{"id": 1758, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1105, "code": "\tpublic AuthorizationGrantType getAuthorizationGrantType() {\n\t\treturn this.authorizationGrantType;\n\t}", "summary_tokens": ["returns", "the", "authorization", "grant", "type", "authorization", "grant", "type", "used", "for", "the", "client"], "project": "spring-security"}
{"id": 462, "code": "\tpublic void basicAuthenticationWhenUsingDefaultsThenMatchesNamespace() throws Exception {\n\t\tthis.spring.register(HttpBasicConfig.class, UserConfig.class).autowire();\n\t\tthis.mvc.perform(get(\"/\")).andExpect(status().isUnauthorized());\n\t\tMockHttpServletRequestBuilder requestWithInvalidPassword = get(\"/\").with(httpBasic(\"user\", \"invalid\"));\n\t\t\n\t\tthis.mvc.perform(requestWithInvalidPassword)\n\t\t\t\t.andExpect(status().isUnauthorized())\n\t\t\t\t.andExpect(header().string(HttpHeaders.WWW_AUTHENTICATE, \"Basic realm=\\\"Realm\\\"\"));\n\t\t\n\t\tMockHttpServletRequestBuilder requestWithValidPassword = get(\"/\").with(httpBasic(\"user\", \"password\"));\n\t\tthis.mvc.perform(requestWithValidPassword).andExpect(status().isNotFound());\n\t}", "summary_tokens": ["http", "http", "basic", "equivalent"], "project": "spring-security"}
{"id": 94, "code": "\tpublic LdapAuthenticationProviderConfigurer<B> groupSearchBase(String groupSearchBase) {\n\t\tthis.groupSearchBase = groupSearchBase;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "search", "base", "for", "group", "membership", "searches"], "project": "spring-security"}
{"id": 917, "code": "\tpublic Map<String, String> getVariables() {\n\t\treturn this.variables;\n\t}", "summary_tokens": ["returns", "the", "extracted", "variable", "values", "where", "the", "key", "is", "the", "variable", "name", "and", "the", "value", "is", "the", "variable", "value"], "project": "spring-security"}
{"id": 1840, "code": "\tpublic void setAllowUrlEncodedPercent(boolean allowUrlEncodedPercent) {\n\t\tif (allowUrlEncodedPercent) {\n\t\t\tthis.encodedUrlBlocklist.remove(ENCODED_PERCENT);\n\t\t\tthis.decodedUrlBlocklist.remove(PERCENT);\n\t\t}\n\t\telse {\n\t\t\tthis.encodedUrlBlocklist.add(ENCODED_PERCENT);\n\t\t\tthis.decodedUrlBlocklist.add(PERCENT);\n\t\t}\n\t}", "summary_tokens": ["p", "determines", "if", "a", "percent", "that", "is", "url", "encoded", "0", "should", "be", "allowed", "in", "the", "path", "or", "not"], "project": "spring-security"}
{"id": 346, "code": "\tpublic X509Configurer<H> x509AuthenticationFilter(X509AuthenticationFilter x509AuthenticationFilter) {\n\t\tthis.x509AuthenticationFilter = x509AuthenticationFilter;\n\t\treturn this;\n\t}", "summary_tokens": ["allows", "specifying", "the", "entire", "x", "0", "authentication", "filter"], "project": "spring-security"}
{"id": 417, "code": "\tpublic void setAuthoritiesMapper(GrantedAuthoritiesMapper authoritiesMapper) {\n\t\tthis.authoritiesMapper = authoritiesMapper;\n\t}", "summary_tokens": ["sets", "the", "granted", "authorities", "mapper", "used", "for", "converting", "the", "authorities", "loaded", "from", "storage", "to", "a", "new", "set", "of", "authorities", "which", "will", "be", "associated", "to", "the", "username", "password", "authentication", "token"], "project": "spring-security"}
{"id": 1777, "code": "\tprivate String getWebApplicationContextAttribute() {\n\t\tString dispatcherServletName = getDispatcherWebApplicationContextSuffix();\n\t\tif (dispatcherServletName == null) {\n\t\t\treturn null;\n\t\t}\n\t\treturn SERVLET_CONTEXT_PREFIX + dispatcherServletName;\n\t}", "summary_tokens": ["returns", "the", "delegating", "filter", "proxy", "get", "context", "attribute", "or", "null", "if", "the", "parent", "application", "context", "should", "be", "used"], "project": "spring-security"}
{"id": 2020, "code": "\tpublic void setInvalidSessionStrategy(InvalidSessionStrategy invalidSessionStrategy) {\n\t\tthis.invalidSessionStrategy = invalidSessionStrategy;\n\t}", "summary_tokens": ["sets", "the", "strategy", "which", "will", "be", "invoked", "instead", "of", "allowing", "the", "filter", "chain", "to", "proceed", "if", "the", "user", "agent", "requests", "an", "invalid", "session", "id"], "project": "spring-security"}
{"id": 182, "code": "\tprotected final HttpSecurity getHttp() throws Exception {\n\t\tif (this.http != null) {\n\t\t\treturn this.http;\n\t\t}\n\t\tAuthenticationEventPublisher eventPublisher = getAuthenticationEventPublisher();\n\t\tthis.localConfigureAuthenticationBldr.authenticationEventPublisher(eventPublisher);\n\t\tAuthenticationManager authenticationManager = authenticationManager();\n\t\tthis.authenticationBuilder.parentAuthenticationManager(authenticationManager);\n\t\tMap<Class<?>, Object> sharedObjects = createSharedObjects();\n\t\tthis.http = new HttpSecurity(this.objectPostProcessor, this.authenticationBuilder, sharedObjects);\n\t\tif (!this.disableDefaults) {\n\t\t\tapplyDefaultConfiguration(this.http);\n\t\t\tClassLoader classLoader = this.context.getClassLoader();\n\t\t\tList<AbstractHttpConfigurer> defaultHttpConfigurers = SpringFactoriesLoader\n\t\t\t\t\t.loadFactories(AbstractHttpConfigurer.class, classLoader);\n\t\t\tfor (AbstractHttpConfigurer configurer : defaultHttpConfigurers) {\n\t\t\t\tthis.http.apply(configurer);\n\t\t\t}\n\t\t}\n\t\tconfigure(this.http);\n\t\treturn this.http;\n\t}", "summary_tokens": ["creates", "the", "http", "security", "or", "returns", "the", "current", "instance", "the", "http", "security", "exception"], "project": "spring-security"}
{"id": 1979, "code": "\tpublic void setPolicy(ReferrerPolicy policy) {\n\t\tAssert.notNull(policy, \"policy must not be null\");\n\t\tthis.delegate = createDelegate(policy);\n\t}", "summary_tokens": ["set", "the", "policy", "to", "be", "used", "in", "the", "response", "header"], "project": "spring-security"}
{"id": 629, "code": "\tpublic void setExpressionHandler(MethodSecurityExpressionHandler expressionHandler) {\n\t\tthis.registry = new PostAuthorizeExpressionAttributeRegistry(expressionHandler);\n\t}", "summary_tokens": ["use", "this", "the", "method", "security", "expression", "handler"], "project": "spring-security"}
{"id": 1996, "code": "\tpublic void setMethod(HttpMethod method) {\n\t\tthis.method = method;\n\t}", "summary_tokens": ["method", "the", "method", "to", "set"], "project": "spring-security"}
{"id": 969, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock cannot be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["sets", "the", "clock", "used", "in", "instant", "now", "clock", "when", "checking", "the", "access", "token", "expiry"], "project": "spring-security"}
{"id": 451, "code": "\tpublic ServerHttpSecurity formLogin(Customizer<FormLoginSpec> formLoginCustomizer) {\n\t\tif (this.formLogin == null) {\n\t\t\tthis.formLogin = new FormLoginSpec();\n\t\t}\n\t\tformLoginCustomizer.customize(this.formLogin);\n\t\treturn this;\n\t}", "summary_tokens": ["configures", "form", "based", "authentication"], "project": "spring-security"}
{"id": 2050, "code": "\tpublic boolean matches(HttpServletRequest request) {\n\t\tif (this.httpMethod != null && request.getMethod() != null\n\t\t\t\t&& this.httpMethod != HttpMethod.resolve(request.getMethod())) {\n\t\t\treturn false;\n\t\t}\n\t\tString url = request.getServletPath();\n\t\tString pathInfo = request.getPathInfo();\n\t\tString query = request.getQueryString();\n\t\tif (pathInfo != null || query != null) {\n\t\t\tStringBuilder sb = new StringBuilder(url);\n\t\t\tif (pathInfo != null) {\n\t\t\t\tsb.append(pathInfo);\n\t\t\t}\n\t\t\tif (query != null) {\n\t\t\t\tsb.append('?').append(query);\n\t\t\t}\n\t\t\turl = sb.toString();\n\t\t}\n\t\tlogger.debug(LogMessage.format(\"Checking match of request : '%s'; against '%s'\", url, this.pattern));\n\t\treturn this.pattern.matcher(url).matches();\n\t}", "summary_tokens": ["performs", "the", "match", "of", "the", "request", "url", "servlet", "path", "path", "info", "query", "string", "against", "the", "compiled", "pattern"], "project": "spring-security"}
{"id": 1620, "code": "\tpublic void commence(HttpServletRequest request, HttpServletResponse response, AuthenticationException arg2)\n\t\t\tthrows IOException {\n\t\tlogger.debug(\"Pre-authenticated entry point called. Rejecting access\");\n\t\tresponse.sendError(HttpServletResponse.SC_FORBIDDEN, \"Access Denied\");\n\t}", "summary_tokens": ["always", "returns", "a", "0", "error", "code", "to", "the", "client"], "project": "spring-security"}
{"id": 822, "code": "\tpublic void startWithLdapOverSsl() throws Exception {\n\n\t\tfinal ClassPathResource keyStoreResource = new ClassPathResource(\n\t\t\t\t\"/org/springframework/security/ldap/server/spring.keystore\");\n\t\tfinal File temporaryKeyStoreFile = new File(this.temporaryFolder, \"spring.keystore\");\n\t\tFileCopyUtils.copy(keyStoreResource.getInputStream(), new FileOutputStream(temporaryKeyStoreFile));\n\n\t\tassertThat(temporaryKeyStoreFile).isFile();\n\n\t\tApacheDSContainer server = new ApacheDSContainer(\"dc=springframework,dc=org\", \"classpath:test-server.ldif\");\n\n\t\tList<Integer> ports = getDefaultPorts(1);\n\t\tserver.setPort(ports.get(0));\n\n\t\tserver.setLdapOverSslEnabled(true);\n\t\tserver.setKeyStoreFile(temporaryKeyStoreFile);\n\t\tserver.setCertificatePassord(\"spring\");\n\n\t\ttry {\n\t\t\tserver.afterPropertiesSet();\n\t\t}\n\t\tfinally {\n\t\t\ttry {\n\t\t\t\tserver.destroy();\n\t\t\t}\n\t\t\tcatch (Throwable ex) {\n\t\t\t}\n\t\t}\n\t}", "summary_tokens": ["this", "test", "starts", "an", "ldap", "server", "using", "ldaps", "ldap", "over", "ssl"], "project": "spring-security"}
{"id": 1051, "code": "\tpublic final void setHeadersConverter(Converter<T, HttpHeaders> headersConverter) {\n\t\tAssert.notNull(headersConverter, \"headersConverter cannot be null\");\n\t\tthis.headersConverter = headersConverter;\n\t}", "summary_tokens": ["sets", "the", "converter", "used", "for", "converting", "the", "abstract", "oauth", "0", "authorization", "grant", "request", "instance", "to", "a", "http", "headers", "used", "in", "the", "oauth", "0"], "project": "spring-security"}
{"id": 1013, "code": "\tpublic void setAccessTokenResponseClient(\n\t\t\tOAuth2AccessTokenResponseClient<OAuth2RefreshTokenGrantRequest> accessTokenResponseClient) {\n\t\tAssert.notNull(accessTokenResponseClient, \"accessTokenResponseClient cannot be null\");\n\t\tthis.accessTokenResponseClient = accessTokenResponseClient;\n\t}", "summary_tokens": ["sets", "the", "client", "used", "when", "requesting", "an", "access", "token", "credential", "at", "the", "token", "endpoint", "for", "the", "refresh", "token", "grant"], "project": "spring-security"}
{"id": 1282, "code": "\tdefault Boolean getPhoneNumberVerified() {\n\t\treturn this.getClaimAsBoolean(StandardClaimNames.PHONE_NUMBER_VERIFIED);\n\t}", "summary_tokens": ["returns", "true", "if", "the", "user", "s", "phone", "number", "has", "been", "verified", "phone", "number", "verified", "otherwise", "false"], "project": "spring-security"}
{"id": 1864, "code": "\tpublic void setPins(Map<String, String> pins) {\n\t\tAssert.notNull(pins, \"pins cannot be null\");\n\t\tthis.pins = pins;\n\t\tupdateHpkpHeaderValue();\n\t}", "summary_tokens": ["p", "sets", "the", "value", "for", "the", "pin", "directive", "of", "the", "public", "key", "pins", "header"], "project": "spring-security"}
{"id": 1136, "code": "\tprivate String getStateParameter(HttpServletRequest request) {\n\t\treturn request.getParameter(OAuth2ParameterNames.STATE);\n\t}", "summary_tokens": ["gets", "the", "state", "parameter", "from", "the", "http", "servlet", "request", "request", "the", "request", "to", "use", "the", "state", "parameter", "or", "null", "if", "not", "found"], "project": "spring-security"}
{"id": 248, "code": "\tprivate void initDefaultLoginFilter(H http) {\n\t\tDefaultLoginPageGeneratingFilter loginPageGeneratingFilter = http\n\t\t\t\t.getSharedObject(DefaultLoginPageGeneratingFilter.class);\n\t\tif (loginPageGeneratingFilter != null && !isCustomLoginPage()) {\n\t\t\tloginPageGeneratingFilter.setFormLoginEnabled(true);\n\t\t\tloginPageGeneratingFilter.setUsernameParameter(getUsernameParameter());\n\t\t\tloginPageGeneratingFilter.setPasswordParameter(getPasswordParameter());\n\t\t\tloginPageGeneratingFilter.setLoginPageUrl(getLoginPage());\n\t\t\tloginPageGeneratingFilter.setFailureUrl(getFailureUrl());\n\t\t\tloginPageGeneratingFilter.setAuthenticationUrl(getLoginProcessingUrl());\n\t\t}\n\t}", "summary_tokens": ["if", "available", "initializes", "the", "default", "login", "page", "generating", "filter", "shared", "object"], "project": "spring-security"}
{"id": 987, "code": "\tpublic @Nullable OAuth2RefreshToken getRefreshToken() {\n\t\treturn this.refreshToken;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "refresh", "token", "refresh", "token", "credential", "granted"], "project": "spring-security"}
{"id": 866, "code": "\tpublic boolean isLocked() {\n\t\treturn this.errorStatus == PasswordPolicyErrorStatus.ACCOUNT_LOCKED;\n\t}", "summary_tokens": ["determines", "whether", "an", "account", "locked", "error", "has", "been", "returned"], "project": "spring-security"}
{"id": 1037, "code": "\tpublic final void setHeadersConverter(Converter<T, HttpHeaders> headersConverter) {\n\t\tAssert.notNull(headersConverter, \"headersConverter cannot be null\");\n\t\tthis.headersConverter = headersConverter;\n\t}", "summary_tokens": ["sets", "the", "converter", "used", "for", "converting", "the", "abstract", "oauth", "0", "authorization", "grant", "request", "instance", "to", "a", "http", "headers", "used", "in", "the", "oauth", "0"], "project": "spring-security"}
{"id": 1170, "code": "\tpublic final void setAuthorizationRequestRepository(\n\t\t\tServerAuthorizationRequestRepository<OAuth2AuthorizationRequest> authorizationRequestRepository) {\n\t\tAssert.notNull(authorizationRequestRepository, \"authorizationRequestRepository cannot be null\");\n\t\tthis.authorizationRequestRepository = authorizationRequestRepository;\n\t}", "summary_tokens": ["sets", "the", "repository", "used", "for", "storing", "oauth", "0", "authorization", "request", "s"], "project": "spring-security"}
{"id": 541, "code": "\tpublic void setUserDetailsPasswordService(ReactiveUserDetailsPasswordService userDetailsPasswordService) {\n\t\tthis.userDetailsPasswordService = userDetailsPasswordService;\n\t}", "summary_tokens": ["sets", "the", "service", "to", "use", "for", "upgrading", "passwords", "on", "successful", "authentication"], "project": "spring-security"}
{"id": 2044, "code": "\tpublic static boolean isAbsoluteUrl(String url) {\n\t\treturn (url != null) ? ABSOLUTE_URL.matcher(url).matches() : false;\n\t}", "summary_tokens": ["decides", "if", "a", "url", "is", "absolute", "based", "on", "whether", "it", "contains", "a", "valid", "scheme", "name", "as", "defined", "in", "rfc", "0"], "project": "spring-security"}
{"id": 971, "code": "\tpublic OAuth2AuthorizedClient getAuthorizedClient() {\n\t\treturn this.authorizedClient;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "authorized", "client", "authorized", "client", "or", "null", "if", "the", "with", "client", "registration", "client", "registration", "client", "registration", "was", "supplied"], "project": "spring-security"}
{"id": 1319, "code": "\tpublic static OAuth2TokenValidator<Jwt> createDefaultWithIssuer(String issuer) {\n\t\tList<OAuth2TokenValidator<Jwt>> validators = new ArrayList<>();\n\t\tvalidators.add(new JwtTimestampValidator());\n\t\tvalidators.add(new JwtIssuerValidator(issuer));\n\t\treturn new DelegatingOAuth2TokenValidator<>(validators);\n\t}", "summary_tokens": ["p", "create", "a", "jwt", "validator", "that", "contains", "all", "standard", "validators", "when", "an", "issuer", "is", "known"], "project": "spring-security"}
{"id": 477, "code": "\tpublic void countLinksWhenReviewingDocumentationThenParentsAndChildrenAreCorrectlyLinked() throws IOException {\n\t\tMap<String, List<String>> docAttrNameToChildren = new TreeMap<>();\n\t\tMap<String, List<String>> docAttrNameToParents = new TreeMap<>();\n\t\tString docAttrName = null;\n\t\tMap<String, List<String>> currentDocAttrNameToElmt = null;\n\t\tList<String> lines = namespaceLines().collect(Collectors.toList());\n\t\tfor (String line : lines) {\n\t\t\tif (line.matches(\"^\\\\[\\\\[.*\\\\]\\\\]$\")) {\n\t\t\t\tString id = line.substring(2, line.length() - 2);\n\t\t\t\tif (id.endsWith(\"-children\")) {\n\t\t\t\t\tdocAttrName = id.substring(0, id.length() - 9);\n\t\t\t\t\tcurrentDocAttrNameToElmt = docAttrNameToChildren;\n\t\t\t\t}\n\t\t\t\telse if (id.endsWith(\"-parents\")) {\n\t\t\t\t\tdocAttrName = id.substring(0, id.length() - 8);\n\t\t\t\t\tcurrentDocAttrNameToElmt = docAttrNameToParents;\n\t\t\t\t}\n\t\t\t\telse if (id.endsWith(\"-attributes\") || docAttrName != null && !id.startsWith(docAttrName)) {\n\t\t\t\t\tcurrentDocAttrNameToElmt = null;\n\t\t\t\t\tdocAttrName = null;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (docAttrName != null && currentDocAttrNameToElmt != null) {\n\t\t\t\tString expression = \".*<<(nsa-.*),.*>>.*\";\n\t\t\t\tif (line.matches(expression)) {\n\t\t\t\t\tString elmtId = line.replaceAll(expression, \"$1\");\n\t\t\t\t\tcurrentDocAttrNameToElmt.computeIfAbsent(docAttrName, (key) -> new ArrayList<>()).add(elmtId);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\texpression = \".*xref:.*#(nsa-.*)\\\\[.*\\\\]\";\n\t\t\t\t\tif (line.matches(expression)) {\n\t\t\t\t\t\tString elmtId = line.replaceAll(expression, \"$1\");\n\t\t\t\t\t\tcurrentDocAttrNameToElmt.computeIfAbsent(docAttrName, (key) -> new ArrayList<>()).add(elmtId);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tMap<String, Element> elementNameToElement = this.xml.elementsByElementName(this.schemaDocumentLocation);\n\t\tMap<String, List<String>> schemaAttrNameToChildren = new TreeMap<>();\n\t\tMap<String, List<String>> schemaAttrNameToParents = new TreeMap<>();\n\t\telementNameToElement.entrySet().stream().forEach((entry) -> {\n\t\t\tString key = \"nsa-\" + entry.getKey();\n\t\t\tif (this.ignoredIds.contains(key)) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t\n\t\t\tList<String> parentIds = entry.getValue()\n\t\t\t\t\t.getAllParentElmts()\n\t\t\t\t\t.values()\n\t\t\t\t\t.stream()\n\t\t\t\t\t.filter((element) -> !this.ignoredIds.contains(element.getId()))\n\t\t\t\t\t.map((element) -> element.getId())\n\t\t\t\t\t.sorted()\n\t\t\t\t\t.collect(Collectors.toList());\n\t\t\t\n\t\t\tif (!parentIds.isEmpty()) {\n\t\t\t\tschemaAttrNameToParents.put(key, parentIds);\n\t\t\t}\n\t\t\t\n\t\t\tList<String> childIds = entry.getValue()\n\t\t\t\t\t.getAllChildElmts()\n\t\t\t\t\t.values()\n\t\t\t\t\t.stream()\n\t\t\t\t\t.filter((element) -> !this.ignoredIds.contains(element.getId())).map((element) -> element.getId())\n\t\t\t\t\t.sorted()\n\t\t\t\t\t.collect(Collectors.toList());\n\t\t\t\n\t\t\tif (!childIds.isEmpty()) {\n\t\t\t\tschemaAttrNameToChildren.put(key, childIds);\n\t\t\t}\n\t\t});\n\t\tassertThat(docAttrNameToChildren)\n\t\t\t\t.describedAs(toString(docAttrNameToChildren) + \"\\n!=\\n\\n\" + toString(schemaAttrNameToChildren))\n\t\t\t\t.containsExactlyInAnyOrderEntriesOf(schemaAttrNameToChildren);\n\t\tassertThat(docAttrNameToParents)\n\t\t\t\t.describedAs(toString(docAttrNameToParents) + \"\\n!=\\n\\n\" + toString(schemaAttrNameToParents))\n\t\t\t\t.containsExactlyInAnyOrderEntriesOf(schemaAttrNameToParents);\n\t}", "summary_tokens": ["this", "test", "ensures", "that", "any", "element", "that", "has", "children", "or", "parents", "contains", "a", "section", "that", "has", "links", "pointing", "to", "that", "documentation"], "project": "spring-security"}
{"id": 900, "code": "\tprotected GrantedAuthority createAuthority(Object role) {\n\t\tif (role instanceof String) {\n\t\t\tif (this.convertToUpperCase) {\n\t\t\t\trole = ((String) role).toUpperCase();\n\t\t\t}\n\t\t\treturn new SimpleGrantedAuthority(this.rolePrefix + role);\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["creates", "a", "granted", "authority", "from", "a", "role", "attribute"], "project": "spring-security"}
{"id": 1067, "code": "\tpublic Jwt getJwt() {\n\t\treturn this.jwt;\n\t}", "summary_tokens": ["returns", "the", "jwt", "jwt", "assertion"], "project": "spring-security"}
{"id": 1866, "code": "\tpublic void setMaxAgeInSeconds(long maxAgeInSeconds) {\n\t\tAssert.isTrue(maxAgeInSeconds > 0, () -> \"maxAgeInSeconds must be non-negative. Got \" + maxAgeInSeconds);\n\t\tthis.maxAgeInSeconds = maxAgeInSeconds;\n\t\tupdateHpkpHeaderValue();\n\t}", "summary_tokens": ["p", "sets", "the", "value", "in", "seconds", "for", "the", "max", "age", "directive", "of", "the", "public", "key", "pins", "header"], "project": "spring-security"}
{"id": 1880, "code": "\tpublic static Consumer<HttpHeaders> bearerToken(String bearerTokenValue) {\n\t\tAssert.hasText(bearerTokenValue, \"bearerTokenValue cannot be null\");\n\t\treturn (headers) -> headers.set(HttpHeaders.AUTHORIZATION, \"Bearer \" + bearerTokenValue);\n\t}", "summary_tokens": ["sets", "the", "provided", "value", "as", "a", "bearer", "token", "in", "a", "header", "with", "the", "name", "of", "http", "headers", "authorization", "bearer", "token", "value", "the", "bear", "token", "value", "a", "consumer", "that", "sets", "the", "header"], "project": "spring-security"}
{"id": 1914, "code": "\tpublic void setContextRelative(boolean contextRelative) {\n\t\tthis.contextRelative = contextRelative;\n\t}", "summary_tokens": ["sets", "if", "the", "location", "is", "relative", "to", "the", "context"], "project": "spring-security"}
{"id": 435, "code": "\tpublic static UserDetailsManagerResourceFactoryBean fromResourceLocation(String resourceLocation) {\n\t\tUserDetailsManagerResourceFactoryBean result = new UserDetailsManagerResourceFactoryBean();\n\t\tresult.setResourceLocation(resourceLocation);\n\t\treturn result;\n\t}", "summary_tokens": ["create", "a", "user", "details", "manager", "resource", "factory", "bean", "with", "the", "location", "of", "a", "resource", "that", "is", "a", "properties", "file", "in", "the", "format", "defined", "in", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 916, "code": "\tpublic Message<T> getMessage() {\n\t\treturn this.message;\n\t}", "summary_tokens": ["returns", "the", "http", "servlet", "request"], "project": "spring-security"}
{"id": 1787, "code": "\tpublic void setAllowSessionCreation(boolean allowSessionCreation) {\n\t\tthis.allowSessionCreation = allowSessionCreation;\n\t}", "summary_tokens": ["if", "set", "to", "true", "the", "default", "a", "session", "will", "be", "created", "if", "required", "to", "store", "the", "security", "context", "if", "it", "is", "determined", "that", "its", "contents", "are", "different", "from", "the", "default", "empty", "context", "value"], "project": "spring-security"}
{"id": 2027, "code": "\tpublic final void sendError(int sc, String msg) throws IOException {\n\t\tdoOnResponseCommitted();\n\t\tsuper.sendError(sc, msg);\n\t}", "summary_tokens": ["makes", "sure", "on", "committed", "response", "wrapper", "on", "response", "committed", "is", "invoked", "before", "calling", "the", "superclass", "code", "send", "error", "code"], "project": "spring-security"}
{"id": 1988, "code": "\tpublic void setMatchingRequestParameterName(String matchingRequestParameterName) {\n\t\tthis.matchingRequestParameterName = matchingRequestParameterName;\n\t}", "summary_tokens": ["specify", "the", "name", "of", "a", "query", "parameter", "that", "is", "added", "to", "the", "url", "in", "get", "redirect", "uri", "server", "web", "exchange", "and", "is", "required", "for", "remove", "matching", "request", "server", "web", "exchange", "to", "look", "up", "the", "server", "http", "request"], "project": "spring-security"}
{"id": 1041, "code": "\tpublic final void addParametersConverter(Converter<T, MultiValueMap<String, String>> parametersConverter) {\n\t\tAssert.notNull(parametersConverter, \"parametersConverter cannot be null\");\n\t\tConverter<T, MultiValueMap<String, String>> currentParametersConverter = this.parametersConverter;\n\t\tthis.parametersConverter = (authorizationGrantRequest) -> {\n\t\t\t\n\t\t\tMultiValueMap<String, String> parameters = currentParametersConverter.convert(authorizationGrantRequest);\n\t\t\tif (parameters == null) {\n\t\t\t\tparameters = new LinkedMultiValueMap<>();\n\t\t\t}\n\t\t\tMultiValueMap<String, String> parametersToAdd = parametersConverter.convert(authorizationGrantRequest);\n\t\t\tif (parametersToAdd != null) {\n\t\t\t\tparameters.addAll(parametersToAdd);\n\t\t\t}\n\t\t\treturn parameters;\n\t\t};\n\t}", "summary_tokens": ["add", "compose", "the", "provided", "parameters", "converter", "to", "the", "current", "converter", "used", "for", "converting", "the", "abstract", "oauth", "0", "authorization", "grant", "request", "instance", "to", "a", "multi", "value", "map", "of", "the", "parameters", "used", "in", "the", "oauth", "0"], "project": "spring-security"}
{"id": 715, "code": "\tprotected List<UserDetails> loadUsersByUsername(String username) {\n\t\t\n\t\tRowMapper<UserDetails> mapper = (rs, rowNum) -> {\n\t\t\tString username1 = rs.getString(1);\n\t\t\tString password = rs.getString(2);\n\t\t\tboolean enabled = rs.getBoolean(3);\n\t\t\treturn new User(username1, password, enabled, true, true, true, AuthorityUtils.NO_AUTHORITIES);\n\t\t};\n\t\t\n\t\treturn getJdbcTemplate().query(this.usersByUsernameQuery, mapper, username);\n\t}", "summary_tokens": ["executes", "the", "sql", "tt", "users", "by", "username", "query", "tt", "and", "returns", "a", "list", "of", "user", "details", "objects"], "project": "spring-security"}
{"id": 702, "code": "\tpublic void setSeed(Resource seed) {\n\t\tthis.seed = seed;\n\t}", "summary_tokens": ["allows", "the", "user", "to", "specify", "a", "resource", "which", "will", "act", "as", "a", "seed", "for", "the", "secure", "random", "instance"], "project": "spring-security"}
{"id": 1392, "code": "\tpublic X509Certificate getCertificate() {\n\t\treturn this.certificate;\n\t}", "summary_tokens": ["get", "the", "public", "certificate", "for", "this", "credential", "the", "public", "certificate"], "project": "spring-security"}
{"id": 1965, "code": "\tpublic void setCookieMaxAge(int cookieMaxAge) {\n\t\tAssert.isTrue(cookieMaxAge != 0, \"cookieMaxAge cannot be zero\");\n\t\tthis.cookieMaxAge = cookieMaxAge;\n\t}", "summary_tokens": ["sets", "maximum", "age", "in", "seconds", "for", "the", "cookie", "that", "the", "expected", "csrf", "token", "is", "saved", "to", "and", "read", "from"], "project": "spring-security"}
{"id": 1185, "code": "\tdefault Boolean getClaimAsBoolean(String claim) {\n\t\tif (!hasClaim(claim)) {\n\t\t\treturn null;\n\t\t}\n\t\tObject claimValue = getClaims().get(claim);\n\t\tBoolean convertedValue = ClaimConversionService.getSharedInstance().convert(claimValue, Boolean.class);\n\t\tAssert.notNull(convertedValue,\n\t\t\t\t() -> \"Unable to convert claim '\" + claim + \"' of type '\" + claimValue.getClass() + \"' to Boolean.\");\n\t\treturn convertedValue;\n\t}", "summary_tokens": ["returns", "the", "claim", "value", "as", "a", "boolean", "or", "null", "if", "the", "claim", "does", "not", "exist"], "project": "spring-security"}
{"id": 472, "code": "\tprivate String desc(XmlNode element) {\n\t\treturn element.child(\"annotation\").flatMap((annotation) -> annotation.child(\"documentation\"))\n\t\t\t\t.map((documentation) -> documentation.text()).orElse(null);\n\t}", "summary_tokens": ["obtains", "the", "description", "for", "a", "specific", "element", "element"], "project": "spring-security"}
{"id": 1855, "code": "\tpublic String getName() {\n\t\treturn this.headerName;\n\t}", "summary_tokens": ["gets", "the", "name", "of", "the", "header"], "project": "spring-security"}
{"id": 474, "code": "\tprivate Element elmt(XmlNode n) {\n\t\tString name = n.attribute(\"ref\");\n\t\tif (StringUtils.isEmpty(name)) {\n\t\t\tname = n.attribute(\"name\");\n\t\t}\n\t\telse {\n\t\t\tname = name.split(\":\")[1];\n\t\t\tn = findNode(n, name);\n\t\t}\n\t\tif (this.elementNameToElement.containsKey(name)) {\n\t\t\treturn this.elementNameToElement.get(name);\n\t\t}\n\t\tthis.attrElmts.add(name);\n\t\tElement e = new Element();\n\t\te.setName(n.attribute(\"name\"));\n\t\te.setDesc(desc(n));\n\t\te.setChildElmts(elements(n));\n\t\te.setAttrs(attrs(n));\n\t\te.getAttrs().addAll(attrgrps(n));\n\t\te.getAttrs().forEach((attr) -> attr.setElmt(e));\n\t\te.getChildElmts().values().forEach((element) -> element.getParentElmts().put(e.getName(), e));\n\t\tString subGrpName = n.attribute(\"substitutionGroup\");\n\t\tif (!StringUtils.isEmpty(subGrpName)) {\n\t\t\tElement subGrp = elmt(findNode(n, subGrpName.split(\":\")[1]));\n\t\t\tsubGrp.getSubGrps().add(e);\n\t\t}\n\t\tthis.elementNameToElement.put(name, e);\n\t\treturn e;\n\t}", "summary_tokens": ["given", "an", "element", "creates", "an", "element", "out", "of", "it", "by", "collecting", "all", "its", "attributes", "and", "child", "elements"], "project": "spring-security"}
{"id": 1101, "code": "\tpublic String getRegistrationId() {\n\t\treturn this.registrationId;\n\t}", "summary_tokens": ["returns", "the", "identifier", "for", "the", "registration"], "project": "spring-security"}
{"id": 560, "code": "\tpublic Authentication authenticate(Authentication auth) throws AuthenticationException {\n\t\tif (!(auth instanceof UsernamePasswordAuthenticationToken)) {\n\t\t\treturn null;\n\t\t}\n\t\tUsernamePasswordAuthenticationToken request = (UsernamePasswordAuthenticationToken) auth;\n\t\tSet<GrantedAuthority> authorities;\n\t\ttry {\n\t\t\t\n\t\t\tLoginContext loginContext = createLoginContext(new InternalCallbackHandler(auth));\n\t\t\t\n\t\t\t\n\t\t\tloginContext.login();\n\t\t\t\n\t\t\tSet<Principal> principals = loginContext.getSubject().getPrincipals();\n\t\t\t\n\t\t\t\n\t\t\tauthorities = getAuthorities(principals);\n\t\t\t\n\t\t\tJaasAuthenticationToken result = new JaasAuthenticationToken(request.getPrincipal(),\n\t\t\t\t\trequest.getCredentials(), new ArrayList<>(authorities), loginContext);\n\t\t\t\n\t\t\tpublishSuccessEvent(result);\n\t\t\t\n\t\t\treturn result;\n\n\t\t}\n\t\tcatch (LoginException ex) {\n\t\t\tAuthenticationException resolvedException = this.loginExceptionResolver.resolveException(ex);\n\t\t\tpublishFailureEvent(request, resolvedException);\n\t\t\tthrow resolvedException;\n\t\t}\n\t}", "summary_tokens": ["attempts", "to", "login", "the", "user", "given", "the", "authentication", "objects", "principal", "and", "credential", "auth", "the", "authentication", "object", "to", "be", "authenticated"], "project": "spring-security"}
{"id": 469, "code": "\tprivate Collection<Attribute> attrs(XmlNode element) {\n\t\tCollection<Attribute> attrs = new ArrayList<>();\n\t\telement.children().forEach((c) -> {\n\t\t\tString name = c.simpleName();\n\t\t\tif (\"attribute\".equals(name)) {\n\t\t\t\tattrs.add(attr(c));\n\t\t\t}\n\t\t\telse if (!\"element\".equals(name)) {\n\t\t\t\tattrs.addAll(attrs(c));\n\t\t\t}\n\t\t});\n\t\treturn attrs;\n\t}", "summary_tokens": ["any", "children", "that", "are", "attribute", "will", "be", "returned", "as", "an", "attribute", "object"], "project": "spring-security"}
{"id": 1496, "code": "\tpublic static Converter<ResponseToken, Saml2Authentication> createDefaultResponseAuthenticationConverter() {\n\t\treturn (responseToken) -> {\n\t\t\tResponse response = responseToken.response;\n\t\t\tSaml2AuthenticationToken token = responseToken.token;\n\t\t\tAssertion assertion = CollectionUtils.firstElement(response.getAssertions());\n\t\t\tString username = assertion.getSubject().getNameID().getValue();\n\t\t\tMap<String, List<Object>> attributes = getAssertionAttributes(assertion);\n\t\t\tList<String> sessionIndexes = getSessionIndexes(assertion);\n\t\t\tDefaultSaml2AuthenticatedPrincipal principal = new DefaultSaml2AuthenticatedPrincipal(username, attributes,\n\t\t\t\t\tsessionIndexes);\n\t\t\tString registrationId = responseToken.token.getRelyingPartyRegistration().getRegistrationId();\n\t\t\tprincipal.setRelyingPartyRegistrationId(registrationId);\n\t\t\treturn new Saml2Authentication(principal, token.getSaml2Response(),\n\t\t\t\t\tAuthorityUtils.createAuthorityList(\"ROLE_USER\"));\n\t\t};\n\t}", "summary_tokens": ["construct", "a", "default", "strategy", "for", "converting", "a", "saml", "0"], "project": "spring-security"}
{"id": 1561, "code": "\tprotected boolean isContextRelative() {\n\t\treturn this.contextRelative;\n\t}", "summary_tokens": ["returns", "tt", "true", "tt", "if", "the", "redirection", "url", "should", "be", "calculated", "minus", "the", "protocol", "and", "context", "path", "defaults", "to", "tt", "false", "tt"], "project": "spring-security"}
{"id": 2030, "code": "\tpublic PrintWriter getWriter() throws IOException {\n\t\treturn new SaveContextPrintWriter(super.getWriter());\n\t}", "summary_tokens": ["makes", "sure", "on", "committed", "response", "wrapper", "on", "response", "committed", "is", "invoked", "before", "calling", "the", "code", "get", "writer"], "project": "spring-security"}
{"id": 1146, "code": "\tpublic static Consumer<Map<String, Object>> serverWebExchange(ServerWebExchange serverWebExchange) {\n\t\treturn (attributes) -> attributes.put(SERVER_WEB_EXCHANGE_ATTR_NAME, serverWebExchange);\n\t}", "summary_tokens": ["modifies", "the", "client", "request", "attributes", "to", "include", "the", "server", "web", "exchange", "to", "be", "used", "for", "providing", "the", "bearer", "token"], "project": "spring-security"}
{"id": 1669, "code": "\tpublic void afterPropertiesSet() {\n\t\tAssert.notNull(this.preAuthenticatedUserDetailsService, \"An AuthenticationUserDetailsService must be set\");\n\t}", "summary_tokens": ["check", "whether", "all", "required", "properties", "have", "been", "set"], "project": "spring-security"}
{"id": 302, "code": "\tpublic RememberMeConfigurer<H> rememberMeCookieDomain(String rememberMeCookieDomain) {\n\t\tthis.rememberMeCookieDomain = rememberMeCookieDomain;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "domain", "name", "within", "which", "the", "remember", "me", "cookie", "is", "visible"], "project": "spring-security"}
{"id": 1065, "code": "\tpublic void setRequestEntityConverter(\n\t\t\tConverter<OAuth2RefreshTokenGrantRequest, RequestEntity<?>> requestEntityConverter) {\n\t\tAssert.notNull(requestEntityConverter, \"requestEntityConverter cannot be null\");\n\t\tthis.requestEntityConverter = requestEntityConverter;\n\t}", "summary_tokens": ["sets", "the", "converter", "used", "for", "converting", "the", "oauth", "0", "refresh", "token", "grant", "request", "to", "a", "request", "entity", "representation", "of", "the", "oauth", "0"], "project": "spring-security"}
{"id": 686, "code": "\tpublic static int getInitializeCount() {\n\t\treturn initializeCount;\n\t}", "summary_tokens": ["primarily", "for", "troubleshooting", "purposes", "this", "method", "shows", "how", "many", "times", "the", "class", "has", "re", "initialized", "its", "code", "security", "context", "holder", "strategy", "code"], "project": "spring-security"}
{"id": 2006, "code": "\tpublic void setLogoutHandlers(List<LogoutHandler> logoutHandlers) {\n\t\tthis.logoutHandlers = logoutHandlers;\n\t}", "summary_tokens": ["p", "sets", "the", "logout", "handler", "s", "used", "when", "integrating", "with", "http", "servlet", "request", "with", "servlet", "0", "apis"], "project": "spring-security"}
{"id": 730, "code": "\tprivate static TypeResolverBuilder<? extends TypeResolverBuilder> createAllowlistedDefaultTyping() {\n\t\tTypeResolverBuilder<? extends TypeResolverBuilder> result = new AllowlistTypeResolverBuilder(\n\t\t\t\tObjectMapper.DefaultTyping.NON_FINAL);\n\t\tresult = result.init(JsonTypeInfo.Id.CLASS, null);\n\t\tresult = result.inclusion(JsonTypeInfo.As.PROPERTY);\n\t\treturn result;\n\t}", "summary_tokens": ["creates", "a", "type", "resolver", "builder", "that", "restricts", "allowed", "types"], "project": "spring-security"}
{"id": 78, "code": "\tpublic AuthenticationManagerBuilder authenticationProvider(AuthenticationProvider authenticationProvider) {\n\t\tthis.authenticationProviders.add(authenticationProvider);\n\t\treturn this;\n\t}", "summary_tokens": ["add", "authentication", "based", "upon", "the", "custom", "authentication", "provider", "that", "is", "passed", "in"], "project": "spring-security"}
{"id": 1427, "code": "\tpublic String getRelyingPartyRegistrationId() {\n\t\treturn this.relyingPartyRegistrationId;\n\t}", "summary_tokens": ["the", "identifier", "for", "the", "relying", "party", "registration", "associated", "with", "this", "logout", "request", "the", "relying", "party", "registration", "id"], "project": "spring-security"}
{"id": 49, "code": "\tpublic O getOrBuild() {\n\t\tif (!isUnbuilt()) {\n\t\t\treturn getObject();\n\t\t}\n\t\ttry {\n\t\t\treturn build();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthis.logger.debug(\"Failed to perform build. Returning null\", ex);\n\t\t\treturn null;\n\t\t}\n\t}", "summary_tokens": ["similar", "to", "build", "and", "get", "object", "but", "checks", "the", "state", "to", "determine", "if", "build", "needs", "to", "be", "called", "first"], "project": "spring-security"}
{"id": 1740, "code": "\tprotected Authentication attemptExitUser(HttpServletRequest request)\n\t\t\tthrows AuthenticationCredentialsNotFoundException {\n\t\t\n\t\tAuthentication current = this.securityContextHolderStrategy.getContext().getAuthentication();\n\t\tif (current == null) {\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(this.messages\n\t\t\t\t\t.getMessage(\"SwitchUserFilter.noCurrentUser\", \"No current user associated with this request\"));\n\t\t}\n\t\t\n\t\t\n\t\tAuthentication original = getSourceAuthentication(current);\n\t\tif (original == null) {\n\t\t\tthis.logger.debug(\"Failed to find original user\");\n\t\t\tthrow new AuthenticationCredentialsNotFoundException(this.messages\n\t\t\t\t\t.getMessage(\"SwitchUserFilter.noOriginalAuthentication\", \"Failed to find original user\"));\n\t\t}\n\t\t\n\t\tUserDetails originalUser = null;\n\t\tObject obj = original.getPrincipal();\n\t\tif ((obj != null) && obj instanceof UserDetails) {\n\t\t\toriginalUser = (UserDetails) obj;\n\t\t}\n\t\t\n\t\tif (this.eventPublisher != null) {\n\t\t\tthis.eventPublisher.publishEvent(new AuthenticationSwitchUserEvent(current, originalUser));\n\t\t}\n\t\treturn original;\n\t}", "summary_tokens": ["attempt", "to", "exit", "from", "an", "already", "switched", "user"], "project": "spring-security"}
{"id": 2034, "code": "\tprotected final void registerExtractor(Class<? extends Throwable> throwableType,\n\t\t\tThrowableCauseExtractor extractor) {\n\t\tAssert.notNull(extractor, \"Invalid extractor: null\");\n\t\tthis.extractorMap.put(throwableType, extractor);\n\t}", "summary_tokens": ["registers", "a", "code", "throwable", "cause", "extractor", "code", "for", "the", "specified", "type"], "project": "spring-security"}
{"id": 1468, "code": "\tpublic void setMetadataFilename(String metadataFilename) {\n\t\tAssert.hasText(metadataFilename, \"metadataFilename cannot be empty\");\n\t\tAssert.isTrue(metadataFilename.contains(\"{registrationId}\"),\n\t\t\t\t\"metadataFilename must contain a {registrationId} match variable\");\n\t\tthis.metadataFilename = metadataFilename;\n\t}", "summary_tokens": ["sets", "the", "metadata", "filename", "template", "containing", "the", "registration", "id", "template", "variable"], "project": "spring-security"}
{"id": 1021, "code": "\tprivate boolean hasRemovalErrorCode(OAuth2AuthorizationException authorizationException) {\n\t\treturn this.removeAuthorizedClientErrorCodes.contains(authorizationException.getError().getErrorCode());\n\t}", "summary_tokens": ["returns", "true", "if", "the", "given", "exception", "has", "an", "error", "code", "that", "indicates", "that", "the", "authorized", "client", "should", "be", "removed"], "project": "spring-security"}
{"id": 636, "code": "\tpublic void setExpressionHandler(MethodSecurityExpressionHandler expressionHandler) {\n\t\tthis.registry = new PreAuthorizeExpressionAttributeRegistry(expressionHandler);\n\t}", "summary_tokens": ["sets", "the", "method", "security", "expression", "handler"], "project": "spring-security"}
{"id": 405, "code": "\tprivate void checkFilterStack(List<Filter> filters) {\n\t\tcheckForDuplicates(SecurityContextPersistenceFilter.class, filters);\n\t\tcheckForDuplicates(UsernamePasswordAuthenticationFilter.class, filters);\n\t\tcheckForDuplicates(SessionManagementFilter.class, filters);\n\t\tcheckForDuplicates(BasicAuthenticationFilter.class, filters);\n\t\tcheckForDuplicates(SecurityContextHolderAwareRequestFilter.class, filters);\n\t\tcheckForDuplicates(JaasApiIntegrationFilter.class, filters);\n\t\tcheckForDuplicates(ExceptionTranslationFilter.class, filters);\n\t\tcheckForDuplicates(FilterSecurityInterceptor.class, filters);\n\t\tcheckForDuplicates(AuthorizationFilter.class, filters);\n\t}", "summary_tokens": ["checks", "the", "filter", "list", "for", "possible", "errors", "and", "logs", "them"], "project": "spring-security"}
{"id": 1094, "code": "\tpublic static Map<String, Converter<Object, ?>> createDefaultClaimTypeConverters() {\n\t\tConverter<Object, ?> booleanConverter = getConverter(TypeDescriptor.valueOf(Boolean.class));\n\t\tConverter<Object, ?> instantConverter = getConverter(TypeDescriptor.valueOf(Instant.class));\n\t\tMap<String, Converter<Object, ?>> claimTypeConverters = new HashMap<>();\n\t\tclaimTypeConverters.put(StandardClaimNames.EMAIL_VERIFIED, booleanConverter);\n\t\tclaimTypeConverters.put(StandardClaimNames.PHONE_NUMBER_VERIFIED, booleanConverter);\n\t\tclaimTypeConverters.put(StandardClaimNames.UPDATED_AT, instantConverter);\n\t\treturn claimTypeConverters;\n\t}", "summary_tokens": ["returns", "the", "default", "converter", "s", "used", "for", "type", "conversion", "of", "claim", "values", "for", "an", "oidc", "user", "info"], "project": "spring-security"}
{"id": 1619, "code": "\tpublic void setExceptionMappings(Map<?, ?> failureUrlMap) {\n\t\tthis.failureUrlMap.clear();\n\t\tfor (Map.Entry<?, ?> entry : failureUrlMap.entrySet()) {\n\t\t\tObject exception = entry.getKey();\n\t\t\tObject url = entry.getValue();\n\t\t\tAssert.isInstanceOf(String.class, exception, \"Exception key must be a String (the exception classname).\");\n\t\t\tAssert.isInstanceOf(String.class, url, \"URL must be a String\");\n\t\t\tAssert.isTrue(UrlUtils.isValidRedirectUrl((String) url), () -> \"Not a valid redirect URL: \" + url);\n\t\t\tthis.failureUrlMap.put((String) exception, (String) url);\n\t\t}\n\t}", "summary_tokens": ["sets", "the", "map", "of", "exception", "types", "by", "name", "to", "urls"], "project": "spring-security"}
{"id": 373, "code": "\tpublic Saml2LogoutConfigurer<H> logoutUrl(String logoutUrl) {\n\t\tthis.logoutUrl = logoutUrl;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "url", "by", "which", "the", "relying", "or", "asserting", "party", "can", "trigger", "logout"], "project": "spring-security"}
{"id": 801, "code": "\tpublic void setEncodeHashAsBase64(boolean encodeHashAsBase64) {\n\t\tthis.encodeHashAsBase64 = encodeHashAsBase64;\n\t}", "summary_tokens": ["sets", "if", "the", "resulting", "hash", "should", "be", "encoded", "as", "base", "0"], "project": "spring-security"}
{"id": 1003, "code": "\tpublic final void setAuthorizedClientParametersMapper(\n\t\t\tFunction<OAuth2AuthorizedClientHolder, Map<String, Parameter>> authorizedClientParametersMapper) {\n\t\tAssert.notNull(authorizedClientParametersMapper, \"authorizedClientParametersMapper cannot be null\");\n\t\tthis.authorizedClientParametersMapper = authorizedClientParametersMapper;\n\t}", "summary_tokens": ["sets", "the", "function", "used", "for", "mapping", "oauth", "0", "authorized", "client", "holder", "to", "a", "map", "of", "string", "and", "parameter"], "project": "spring-security"}
{"id": 1352, "code": "\tpublic void setAuthoritiesClaimName(String authoritiesClaimName) {\n\t\tAssert.hasText(authoritiesClaimName, \"authoritiesClaimName cannot be empty\");\n\t\tthis.authoritiesClaimName = authoritiesClaimName;\n\t}", "summary_tokens": ["sets", "the", "name", "of", "token", "claim", "to", "use", "for", "mapping", "granted", "authority", "authorities", "by", "this", "converter"], "project": "spring-security"}
{"id": 74, "code": "\tpublic InMemoryUserDetailsManagerConfigurer<AuthenticationManagerBuilder> inMemoryAuthentication()\n\t\t\tthrows Exception {\n\t\treturn apply(new InMemoryUserDetailsManagerConfigurer<>());\n\t}", "summary_tokens": ["add", "in", "memory", "authentication", "to", "the", "authentication", "manager", "builder", "and", "return", "a", "in", "memory", "user", "details", "manager", "configurer", "to", "allow", "customization", "of", "the", "in", "memory", "authentication"], "project": "spring-security"}
{"id": 443, "code": "\tpublic ServerHttpSecurity addFilterBefore(WebFilter webFilter, SecurityWebFiltersOrder order) {\n\t\tthis.webFilters.add(new OrderedWebFilter(webFilter, order.getOrder() - 1));\n\t\treturn this;\n\t}", "summary_tokens": ["adds", "a", "web", "filter", "before", "specific", "position"], "project": "spring-security"}
{"id": 277, "code": "\tpublic LogoutConfigurer<H> addLogoutHandler(LogoutHandler logoutHandler) {\n\t\tAssert.notNull(logoutHandler, \"logoutHandler cannot be null\");\n\t\tthis.logoutHandlers.add(logoutHandler);\n\t\treturn this;\n\t}", "summary_tokens": ["adds", "a", "logout", "handler"], "project": "spring-security"}
{"id": 1317, "code": "\tpublic void setClock(Clock clock) {\n\t\tAssert.notNull(clock, \"clock cannot be null\");\n\t\tthis.clock = clock;\n\t}", "summary_tokens": ["use", "this", "clock", "with", "instant", "now", "for", "assessing", "timestamp", "validity", "clock"], "project": "spring-security"}
{"id": 481, "code": "\tpublic void autowireWhenCustomLoginPageIsSlashLoginThenNoDefaultLoginPageGeneratingFilterIsWired()\n\t\t\tthrows Exception {\n\t\tthis.spring.configLocations(this.xml(\"ForSec2919\")).autowire();\n\t\tthis.mvc.perform(get(\"/login\")).andExpect(content().string(\"teapot\"));\n\t\tassertThat(getFilter(this.spring.getContext(), DefaultLoginPageGeneratingFilter.class)).isNull();\n\t}", "summary_tokens": ["sec", "0", "default", "login", "generating", "filter", "incorrectly", "used", "if", "login", "url", "login"], "project": "spring-security"}
{"id": 1074, "code": "\tpublic Set<String> getScopes() {\n\t\treturn this.scopes;\n\t}", "summary_tokens": ["returns", "the", "scope", "s", "to", "request"], "project": "spring-security"}
{"id": 313, "code": "\tprivate UserDetailsService getUserDetailsService(H http) {\n\t\tif (this.userDetailsService == null) {\n\t\t\tthis.userDetailsService = getSharedOrBean(http, UserDetailsService.class);\n\t\t}\n\t\tAssert.state(this.userDetailsService != null,\n\t\t\t\t() -> \"userDetailsService cannot be null. Invoke \" + RememberMeConfigurer.class.getSimpleName()\n\t\t\t\t\t\t+ \"#userDetailsService(UserDetailsService) or see its javadoc for alternative approaches.\");\n\t\treturn this.userDetailsService;\n\t}", "summary_tokens": ["gets", "the", "user", "details", "service", "to", "use"], "project": "spring-security"}
{"id": 1839, "code": "\tpublic void setAllowNull(boolean allowNull) {\n\t\tif (allowNull) {\n\t\t\turlBlocklistsRemoveAll(FORBIDDEN_NULL);\n\t\t}\n\t\telse {\n\t\t\turlBlocklistsAddAll(FORBIDDEN_NULL);\n\t\t}\n\t}", "summary_tokens": ["p", "determines", "if", "a", "null", "0", "or", "a", "url", "encoded", "nul", "0", "should", "be", "allowed", "in", "the", "path", "or", "not"], "project": "spring-security"}
{"id": 546, "code": "\tpublic Authentication authenticate(Authentication authentication) throws AuthenticationException {\n\t\tClass<? extends Authentication> toTest = authentication.getClass();\n\t\tAuthenticationException lastException = null;\n\t\tAuthenticationException parentException = null;\n\t\tAuthentication result = null;\n\t\tAuthentication parentResult = null;\n\t\tint currentPosition = 0;\n\t\tint size = this.providers.size();\n\t\tfor (AuthenticationProvider provider : getProviders()) {\n\t\t\tif (!provider.supports(toTest)) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\tlogger.trace(LogMessage.format(\"Authenticating request with %s (%d/%d)\",\n\t\t\t\t\t\tprovider.getClass().getSimpleName(), ++currentPosition, size));\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tresult = provider.authenticate(authentication);\n\t\t\t\tif (result != null) {\n\t\t\t\t\tcopyDetails(authentication, result);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (AccountStatusException | InternalAuthenticationServiceException ex) {\n\t\t\t\tprepareException(ex, authentication);\n\t\t\t\t\n\t\t\t\t\n\t\t\t\tthrow ex;\n\t\t\t}\n\t\t\tcatch (AuthenticationException ex) {\n\t\t\t\tlastException = ex;\n\t\t\t}\n\t\t}\n\t\tif (result == null && this.parent != null) {\n\t\t\t\n\t\t\ttry {\n\t\t\t\tparentResult = this.parent.authenticate(authentication);\n\t\t\t\tresult = parentResult;\n\t\t\t}\n\t\t\tcatch (ProviderNotFoundException ex) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\n\t\t\t}\n\t\t\tcatch (AuthenticationException ex) {\n\t\t\t\tparentException = ex;\n\t\t\t\tlastException = ex;\n\t\t\t}\n\t\t}\n\t\tif (result != null) {\n\t\t\tif (this.eraseCredentialsAfterAuthentication && (result instanceof CredentialsContainer)) {\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t((CredentialsContainer) result).eraseCredentials();\n\t\t\t}\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\tif (parentResult == null) {\n\t\t\t\tthis.eventPublisher.publishAuthenticationSuccess(result);\n\t\t\t}\n\n\t\t\treturn result;\n\t\t}\n\n\t\t\n\t\tif (lastException == null) {\n\t\t\tlastException = new ProviderNotFoundException(this.messages.getMessage(\"ProviderManager.providerNotFound\",\n\t\t\t\t\tnew Object[] { toTest.getName() }, \"No AuthenticationProvider found for {0}\"));\n\t\t}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\tif (parentException == null) {\n\t\t\tprepareException(lastException, authentication);\n\t\t}\n\t\tthrow lastException;\n\t}", "summary_tokens": ["attempts", "to", "authenticate", "the", "passed", "authentication", "object"], "project": "spring-security"}
{"id": 2065, "code": "\tpublic static <T> Builder<T> on(Class<T> objectClass) {\n\t\treturn new Builder<>(objectClass);\n\t}", "summary_tokens": ["main", "entry", "point", "providing", "access", "to", "a", "resolvable", "method", "builder"], "project": "spring-security"}
{"id": 1428, "code": "\tpublic static Builder withRelyingPartyRegistration(RelyingPartyRegistration registration) {\n\t\treturn new Builder(registration);\n\t}", "summary_tokens": ["create", "a", "builder", "instance", "from", "this", "relying", "party", "registration"], "project": "spring-security"}
{"id": 1628, "code": "\tpublic void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response,\n\t\t\tAuthenticationException exception) throws IOException, ServletException {\n\t\tif (this.defaultFailureUrl == null) {\n\t\t\tif (this.logger.isTraceEnabled()) {\n\t\t\t\tthis.logger.trace(\"Sending 401 Unauthorized error since no failure URL is set\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.logger.debug(\"Sending 401 Unauthorized error\");\n\t\t\t}\n\t\t\tresponse.sendError(HttpStatus.UNAUTHORIZED.value(), HttpStatus.UNAUTHORIZED.getReasonPhrase());\n\t\t\treturn;\n\t\t}\n\t\tsaveException(request, exception);\n\t\tif (this.forwardToDestination) {\n\t\t\tthis.logger.debug(\"Forwarding to \" + this.defaultFailureUrl);\n\t\t\trequest.getRequestDispatcher(this.defaultFailureUrl).forward(request, response);\n\t\t}\n\t\telse {\n\t\t\tthis.redirectStrategy.sendRedirect(request, response, this.defaultFailureUrl);\n\t\t}\n\t}", "summary_tokens": ["performs", "the", "redirect", "or", "forward", "to", "the", "default", "failure", "url", "if", "set", "otherwise", "returns", "a", "0", "error", "code"], "project": "spring-security"}
{"id": 422, "code": "\tpublic final AuthenticationManager createAuthenticationManager() {\n\t\tLdapAuthenticationProvider ldapAuthenticationProvider = getProvider();\n\t\treturn new ProviderManager(ldapAuthenticationProvider);\n\t}", "summary_tokens": ["returns", "the", "configured", "authentication", "manager", "that", "can", "be", "used", "to", "perform", "ldap", "authentication"], "project": "spring-security"}
{"id": 652, "code": "\tpublic static Converter<InputStream, RSAPrivateKey> pkcs8() {\n\t\tKeyFactory keyFactory = rsaFactory();\n\t\treturn (source) -> {\n\t\t\tList<String> lines = readAllLines(source);\n\t\t\tAssert.isTrue(!lines.isEmpty() && lines.get(0).startsWith(PKCS8_PEM_HEADER),\n\t\t\t\t\t\"Key is not in PEM-encoded PKCS#8 format, please check that the header begins with \"\n\t\t\t\t\t\t\t+ PKCS8_PEM_HEADER);\n\t\t\tStringBuilder base64Encoded = new StringBuilder();\n\t\t\tfor (String line : lines) {\n\t\t\t\tif (RsaKeyConverters.isNotPkcs8Wrapper(line)) {\n\t\t\t\t\tbase64Encoded.append(line);\n\t\t\t\t}\n\t\t\t}\n\t\t\tbyte[] pkcs8 = Base64.getDecoder().decode(base64Encoded.toString());\n\t\t\ttry {\n\t\t\t\treturn (RSAPrivateKey) keyFactory.generatePrivate(new PKCS8EncodedKeySpec(pkcs8));\n\t\t\t}\n\t\t\tcatch (Exception ex) {\n\t\t\t\tthrow new IllegalArgumentException(ex);\n\t\t\t}\n\t\t};\n\t}", "summary_tokens": ["construct", "a", "converter", "for", "converting", "a", "pem", "encoded", "pkcs", "0", "rsa", "private", "key", "into", "a", "rsaprivate", "key"], "project": "spring-security"}
{"id": 18, "code": "\tpublic final void setPermissionFactory(PermissionFactory permissionFactory) {\n\t\tthis.permissionFactory = permissionFactory;\n\t}", "summary_tokens": ["sets", "the", "permission", "factory", "instance", "which", "will", "be", "used", "to", "convert", "loaded", "permission", "data", "values", "to", "permission", "s"], "project": "spring-security"}
{"id": 1967, "code": "\tpublic void setTokenFromMultipartDataEnabled(boolean tokenFromMultipartDataEnabled) {\n\t\tthis.isTokenFromMultipartDataEnabled = tokenFromMultipartDataEnabled;\n\t}", "summary_tokens": ["specifies", "if", "the", "csrf", "web", "filter", "should", "try", "to", "resolve", "the", "actual", "csrf", "token", "from", "the", "body", "of", "multipart", "data", "requests"], "project": "spring-security"}
{"id": 138, "code": "\tvoid put(Class<? extends Filter> filter, int position) {\n\t\tString className = filter.getName();\n\t\tif (this.filterToOrder.containsKey(className)) {\n\t\t\treturn;\n\t\t}\n\t\tthis.filterToOrder.put(className, position);\n\t}", "summary_tokens": ["register", "a", "filter", "with", "its", "specific", "position"], "project": "spring-security"}
{"id": 563, "code": "\tprotected void publishSuccessEvent(UsernamePasswordAuthenticationToken token) {\n\t\tif (this.applicationEventPublisher != null) {\n\t\t\tthis.applicationEventPublisher.publishEvent(new JaasAuthenticationSuccessEvent(token));\n\t\t}\n\t}", "summary_tokens": ["publishes", "the", "jaas", "authentication", "success", "event"], "project": "spring-security"}
{"id": 189, "code": "\tpublic final T defaultSuccessUrl(String defaultSuccessUrl, boolean alwaysUse) {\n\t\tSavedRequestAwareAuthenticationSuccessHandler handler = new SavedRequestAwareAuthenticationSuccessHandler();\n\t\thandler.setDefaultTargetUrl(defaultSuccessUrl);\n\t\thandler.setAlwaysUseDefaultTargetUrl(alwaysUse);\n\t\tthis.defaultSuccessHandler = handler;\n\t\treturn successHandler(handler);\n\t}", "summary_tokens": ["specifies", "where", "users", "will", "be", "redirected", "after", "authenticating", "successfully", "if", "they", "have", "not", "visited", "a", "secured", "page", "prior", "to", "authenticating", "or", "always", "use", "is", "true"], "project": "spring-security"}
{"id": 1513, "code": "\tpublic int doStartTag() throws JspException {\n\t\ttry {\n\t\t\tthis.authorized = super.authorize();\n\t\t\tif (!this.authorized && TagLibConfig.isUiSecurityDisabled()) {\n\t\t\t\tthis.pageContext.getOut().write(TagLibConfig.getSecuredUiPrefix());\n\t\t\t}\n\t\t\tif (this.var != null) {\n\t\t\t\tthis.pageContext.setAttribute(this.var, this.authorized, PageContext.PAGE_SCOPE);\n\t\t\t}\n\t\t\treturn TagLibConfig.evalOrSkip(this.authorized);\n\t\t}\n\t\tcatch (IOException ex) {\n\t\t\tthrow new JspException(ex);\n\t\t}\n\t}", "summary_tokens": ["invokes", "the", "base", "class", "abstract", "authorize", "tag", "authorize", "method", "to", "decide", "if", "the", "body", "of", "the", "tag", "should", "be", "skipped", "or", "not"], "project": "spring-security"}
{"id": 1357, "code": "\tpublic void setJwtGrantedAuthoritiesConverter(\n\t\t\tConverter<Jwt, Flux<GrantedAuthority>> jwtGrantedAuthoritiesConverter) {\n\t\tAssert.notNull(jwtGrantedAuthoritiesConverter, \"jwtGrantedAuthoritiesConverter cannot be null\");\n\t\tthis.jwtGrantedAuthoritiesConverter = jwtGrantedAuthoritiesConverter;\n\t}", "summary_tokens": ["sets", "the", "converter", "converter", "lt", "jwt", "flux", "lt", "granted", "authority", "gt", "gt", "to", "use"], "project": "spring-security"}
{"id": 1768, "code": "\tpublic void setSecurityContextRepository(SecurityContextRepository securityContextRepository) {\n\t\tAssert.notNull(securityContextRepository, \"securityContextRepository cannot be null\");\n\t\tthis.securityContextRepository = securityContextRepository;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "repository", "to", "save", "the", "security", "context", "on", "authentication", "success"], "project": "spring-security"}
{"id": 480, "code": "\tpublic void logoutWhenDefaultConfigurationThenDisabled() throws Exception {\n\t\tthis.spring.configLocations(this.xml(\"shared-controllers\"), this.xml(\"CsrfEnabled\")).autowire();\n\t\t\n\t\t\n\t\tthis.mvc.perform(get(\"/logout\"))\n\t\t\t\t.andExpect(status().isOk());\n\t\t\n\t\t\n\t\t\n\t\tthis.mvc.perform(get(\"/authenticated\"))\n\t\t\t\t.andExpect(status().isOk());\n\t\t\n\t}", "summary_tokens": ["sec", "0", "csrf", "disables", "logout", "on", "get"], "project": "spring-security"}
{"id": 256, "code": "\tpublic HeadersConfigurer<H> contentSecurityPolicy(\n\t\t\tCustomizer<ContentSecurityPolicyConfig> contentSecurityCustomizer) {\n\t\tthis.contentSecurityPolicy.writer = new ContentSecurityPolicyHeaderWriter();\n\t\tcontentSecurityCustomizer.customize(this.contentSecurityPolicy);\n\t\treturn HeadersConfigurer.this;\n\t}", "summary_tokens": ["p", "allows", "configuration", "for", "a", "href", "https", "www"], "project": "spring-security"}
{"id": 1884, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1609, "code": "\tpublic void setDefaultTargetUrl(String defaultTargetUrl) {\n\t\tAssert.isTrue(UrlUtils.isValidRedirectUrl(defaultTargetUrl),\n\t\t\t\t\"defaultTarget must start with '/' or with 'http(s)'\");\n\t\tthis.defaultTargetUrl = defaultTargetUrl;\n\t}", "summary_tokens": ["supplies", "the", "default", "target", "url", "that", "will", "be", "used", "if", "no", "saved", "request", "is", "found", "in", "the", "session", "or", "the", "always", "use", "default", "target", "url", "property", "is", "set", "to", "true"], "project": "spring-security"}
{"id": 314, "code": "\tprivate String getKey() {\n\t\tif (this.key == null) {\n\t\t\tif (this.rememberMeServices instanceof AbstractRememberMeServices) {\n\t\t\t\tthis.key = ((AbstractRememberMeServices) this.rememberMeServices).getKey();\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthis.key = UUID.randomUUID().toString();\n\t\t\t}\n\t\t}\n\t\treturn this.key;\n\t}", "summary_tokens": ["gets", "the", "key", "to", "use", "for", "validating", "remember", "me", "tokens"], "project": "spring-security"}
{"id": 1878, "code": "\tpublic void setAllowFromParameterName(String allowFromParameterName) {\n\t\tAssert.notNull(allowFromParameterName, \"allowFromParameterName cannot be null\");\n\t\tthis.allowFromParameterName = allowFromParameterName;\n\t}", "summary_tokens": ["sets", "the", "http", "parameter", "used", "to", "retrieve", "the", "value", "for", "the", "origin", "that", "is", "allowed", "from"], "project": "spring-security"}
{"id": 1664, "code": "\tpublic void setInvalidateSessionOnPrincipalChange(boolean invalidateSessionOnPrincipalChange) {\n\t\tthis.invalidateSessionOnPrincipalChange = invalidateSessionOnPrincipalChange;\n\t}", "summary_tokens": ["if", "tt", "check", "for", "principal", "changes", "tt", "is", "set", "and", "a", "change", "of", "principal", "is", "detected", "determines", "whether", "any", "existing", "session", "should", "be", "invalidated", "before", "proceeding", "to", "authenticate", "the", "new", "principal"], "project": "spring-security"}
{"id": 134, "code": "\tprotected final List<MvcRequestMatcher> createMvcMatchers(HttpMethod method, String... mvcPatterns) {\n\t\tAssert.state(!this.anyRequestConfigured, \"Can't configure mvcMatchers after anyRequest\");\n\t\tObjectPostProcessor<Object> opp = this.context.getBean(ObjectPostProcessor.class);\n\t\tif (!this.context.containsBean(HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME)) {\n\t\t\tthrow new NoSuchBeanDefinitionException(\"A Bean named \" + HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME\n\t\t\t\t\t+ \" of type \" + HandlerMappingIntrospector.class.getName()\n\t\t\t\t\t+ \" is required to use MvcRequestMatcher. Please ensure Spring Security & Spring MVC are configured in a shared ApplicationContext.\");\n\t\t}\n\t\tHandlerMappingIntrospector introspector = this.context.getBean(HANDLER_MAPPING_INTROSPECTOR_BEAN_NAME,\n\t\t\t\tHandlerMappingIntrospector.class);\n\t\tList<MvcRequestMatcher> matchers = new ArrayList<>(mvcPatterns.length);\n\t\tfor (String mvcPattern : mvcPatterns) {\n\t\t\tMvcRequestMatcher matcher = new MvcRequestMatcher(introspector, mvcPattern);\n\t\t\topp.postProcess(matcher);\n\t\t\tif (method != null) {\n\t\t\t\tmatcher.setMethod(method);\n\t\t\t}\n\t\t\tmatchers.add(matcher);\n\t\t}\n\t\treturn matchers;\n\t}", "summary_tokens": ["creates", "mvc", "request", "matcher", "instances", "for", "the", "method", "and", "patterns", "passed", "in", "method", "the", "http", "method", "to", "use", "or", "null", "if", "any", "should", "be", "used", "mvc", "patterns", "the", "spring", "mvc", "patterns", "to", "match", "on", "a", "list", "of", "mvc", "request", "matcher", "instances"], "project": "spring-security"}
{"id": 1121, "code": "\tpublic Map<String, Object> getAdditionalParameters() {\n\t\treturn this.additionalParameters;\n\t}", "summary_tokens": ["returns", "the", "additional", "parameters", "that", "may", "be", "used", "in", "the", "request"], "project": "spring-security"}
{"id": 1716, "code": "\tprotected void onUnsuccessfulAuthentication(HttpServletRequest request, HttpServletResponse response,\n\t\t\tAuthenticationException failed) {\n\t}", "summary_tokens": ["called", "if", "the", "authentication", "manager", "rejects", "the", "authentication", "object", "returned", "from", "the", "remember", "me", "services", "auto", "login", "method"], "project": "spring-security"}
{"id": 1075, "code": "\tpublic final void setErrorConverter(HttpMessageConverter<OAuth2Error> oauth2ErrorConverter) {\n\t\tAssert.notNull(oauth2ErrorConverter, \"oauth2ErrorConverter cannot be null\");\n\t\tthis.oauth2ErrorConverter = oauth2ErrorConverter;\n\t}", "summary_tokens": ["sets", "the", "http", "message", "converter", "for", "an", "oauth", "0"], "project": "spring-security"}
{"id": 954, "code": "\tpublic Mono<OAuth2AuthorizedClient> authorize(OAuth2AuthorizationContext context) {\n\t\tAssert.notNull(context, \"context cannot be null\");\n\t\tClientRegistration clientRegistration = context.getClientRegistration();\n\t\tif (!AuthorizationGrantType.CLIENT_CREDENTIALS.equals(clientRegistration.getAuthorizationGrantType())) {\n\t\t\treturn Mono.empty();\n\t\t}\n\t\tOAuth2AuthorizedClient authorizedClient = context.getAuthorizedClient();\n\t\tif (authorizedClient != null && !hasTokenExpired(authorizedClient.getAccessToken())) {\n\t\t\t\n\t\t\t\n\t\t\treturn Mono.empty();\n\t\t}\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\t\n\t\treturn Mono.just(new OAuth2ClientCredentialsGrantRequest(clientRegistration))\n\t\t\t\t.flatMap(this.accessTokenResponseClient::getTokenResponse)\n\t\t\t\t.onErrorMap(OAuth2AuthorizationException.class,\n\t\t\t\t\t\t(ex) -> new ClientAuthorizationException(ex.getError(), clientRegistration.getRegistrationId(),\n\t\t\t\t\t\t\t\tex))\n\t\t\t\t.map((tokenResponse) -> new OAuth2AuthorizedClient(clientRegistration, context.getPrincipal().getName(),\n\t\t\t\t\t\ttokenResponse.getAccessToken()));\n\t}", "summary_tokens": ["attempt", "to", "authorize", "or", "re", "authorize", "the", "oauth", "0", "authorization", "context", "get", "client", "registration", "client", "in", "the", "provided", "context"], "project": "spring-security"}
{"id": 122, "code": "\tprotected AuthenticationManager authenticationManager() throws Exception {\n\t\tif (this.authenticationManager == null) {\n\t\t\tDefaultAuthenticationEventPublisher eventPublisher = this.objectPostProcessor\n\t\t\t\t\t.postProcess(new DefaultAuthenticationEventPublisher());\n\t\t\tthis.auth = new AuthenticationManagerBuilder(this.objectPostProcessor);\n\t\t\tthis.auth.authenticationEventPublisher(eventPublisher);\n\t\t\tconfigure(this.auth);\n\t\t\tthis.authenticationManager = (this.disableAuthenticationRegistry)\n\t\t\t\t\t? getAuthenticationConfiguration().getAuthenticationManager() : this.auth.build();\n\t\t}\n\t\treturn this.authenticationManager;\n\t}", "summary_tokens": ["allows", "providing", "a", "custom", "authentication", "manager"], "project": "spring-security"}
{"id": 849, "code": "\tprotected void handleBindException(String userDn, String username, Throwable cause) {\n\t\tlogger.trace(LogMessage.format(\"Failed to bind as %s\", userDn), cause);\n\t}", "summary_tokens": ["allows", "subclasses", "to", "inspect", "the", "exception", "thrown", "by", "an", "attempt", "to", "bind", "with", "a", "particular", "dn"], "project": "spring-security"}
{"id": 1277, "code": "\tdefault String getGender() {\n\t\treturn this.getClaimAsString(StandardClaimNames.GENDER);\n\t}", "summary_tokens": ["returns", "the", "user", "s", "gender", "gender"], "project": "spring-security"}
{"id": 1477, "code": "\tpublic void setResponseAuthenticationConverter(\n\t\t\tConverter<ResponseToken, ? extends AbstractAuthenticationToken> responseAuthenticationConverter) {\n\t\tAssert.notNull(responseAuthenticationConverter, \"responseAuthenticationConverter cannot be null\");\n\t\tthis.responseAuthenticationConverter = responseAuthenticationConverter;\n\t}", "summary_tokens": ["set", "the", "converter", "to", "use", "for", "converting", "a", "validated", "response", "into", "an", "abstract", "authentication", "token"], "project": "spring-security"}
{"id": 831, "code": "\tpublic boolean compare(String dn, String attributeName, Object value) {\n\t\tString comparisonFilter = \"(\" + attributeName + \"={0})\";\n\t\treturn executeReadOnly((ctx) -> {\n\t\t\tSearchControls searchControls = new SearchControls();\n\t\t\tsearchControls.setReturningAttributes(NO_ATTRS);\n\t\t\tsearchControls.setSearchScope(SearchControls.OBJECT_SCOPE);\n\t\t\tObject[] params = new Object[] { value };\n\t\t\tNamingEnumeration<SearchResult> results = ctx.search(dn, comparisonFilter, params, searchControls);\n\t\t\tBoolean match = results.hasMore();\n\t\t\tLdapUtils.closeEnumeration(results);\n\t\t\treturn match;\n\t\t});\n\t}", "summary_tokens": ["performs", "an", "ldap", "compare", "operation", "of", "the", "value", "of", "an", "attribute", "for", "a", "particular", "directory", "entry"], "project": "spring-security"}
{"id": 1802, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1473, "code": "\tpublic void setLogoutRequestRepository(Saml2LogoutRequestRepository logoutRequestRepository) {\n\t\tAssert.notNull(logoutRequestRepository, \"logoutRequestRepository cannot be null\");\n\t\tthis.logoutRequestRepository = logoutRequestRepository;\n\t}", "summary_tokens": ["use", "this", "saml", "0", "logout", "request", "repository", "for", "saving", "the", "saml", "0"], "project": "spring-security"}
{"id": 461, "code": "\tpublic BeanDefinition parse(Element element, ParserContext parserContext) {\n\t\tString id = element.getAttribute(ID_ATTR);\n\t\tString inSecurityInterceptorName = parseAuthorization(element, parserContext);\n\t\tBeanDefinitionRegistry registry = parserContext.getRegistry();\n\t\tif (StringUtils.hasText(id)) {\n\t\t\tregistry.registerAlias(inSecurityInterceptorName, id);\n\t\t\tif (!registry.containsBeanDefinition(PATH_MATCHER_BEAN_NAME)) {\n\t\t\t\tregistry.registerBeanDefinition(PATH_MATCHER_BEAN_NAME, new RootBeanDefinition(AntPathMatcher.class));\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tboolean sameOriginDisabled = Boolean.parseBoolean(element.getAttribute(DISABLED_ATTR));\n\t\t\tXmlReaderContext context = parserContext.getReaderContext();\n\t\t\tBeanDefinitionBuilder mspp = BeanDefinitionBuilder.rootBeanDefinition(MessageSecurityPostProcessor.class);\n\t\t\tmspp.addConstructorArgValue(inSecurityInterceptorName);\n\t\t\tmspp.addConstructorArgValue(sameOriginDisabled);\n\t\t\tcontext.registerWithGeneratedName(mspp.getBeanDefinition());\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["element", "parser", "context", "the", "bean", "definition"], "project": "spring-security"}
{"id": 378, "code": "\tpublic Constraint nullDestMatcher() {\n\t\treturn matchers(SimpDestinationMessageMatcher.NULL_DESTINATION_MATCHER);\n\t}", "summary_tokens": ["maps", "any", "message", "that", "has", "a", "null", "simp", "message", "header", "accessor", "destination", "header", "i"], "project": "spring-security"}
{"id": 806, "code": "\tpublic void testGensaltInt() {\n\t\tprint(\"BCrypt.gensalt(log_rounds):\");\n\t\tfor (int i = 4; i <= 12; i++) {\n\t\t\tprint(\" \" + Integer.toString(i) + \":\");\n\t\t\tfor (int j = 0; j < testObjectsString.size(); j += 4) {\n\t\t\t\tString plain = testObjectsString.get(j).password;\n\t\t\t\tString salt = BCrypt.gensalt(i);\n\t\t\t\tString hashed1 = BCrypt.hashpw(plain, salt);\n\t\t\t\tString hashed2 = BCrypt.hashpw(plain, hashed1);\n\t\t\t\tassertThat(hashed2).isEqualTo(hashed1);\n\t\t\t\tprint(\".\");\n\t\t\t}\n\t\t}\n\t\tprintln(\"\");\n\t}", "summary_tokens": ["test", "method", "for", "bcrypt"], "project": "spring-security"}
{"id": 242, "code": "\tpublic FormLoginConfigurer<H> usernameParameter(String usernameParameter) {\n\t\tgetAuthenticationFilter().setUsernameParameter(usernameParameter);\n\t\treturn this;\n\t}", "summary_tokens": ["the", "http", "parameter", "to", "look", "for", "the", "username", "when", "performing", "authentication"], "project": "spring-security"}
{"id": 1402, "code": "\tpublic String getId() {\n\t\treturn this.id;\n\t}", "summary_tokens": ["the", "unique", "identifier", "for", "this", "authentication", "request", "the", "authentication", "request", "identifier", "0"], "project": "spring-security"}
{"id": 879, "code": "\tpublic void setConvertToUpperCase(boolean convertToUpperCase) {\n\t\tthis.convertToUpperCase = convertToUpperCase;\n\t}", "summary_tokens": ["convert", "the", "role", "to", "uppercase"], "project": "spring-security"}
{"id": 1340, "code": "\tpublic HttpStatus getHttpStatus() {\n\t\treturn this.httpStatus;\n\t}", "summary_tokens": ["return", "the", "http", "status"], "project": "spring-security"}
{"id": 728, "code": "\tpublic static List<Module> getModules(ClassLoader loader) {\n\t\tList<Module> modules = new ArrayList<>();\n\t\tfor (String className : securityJackson2ModuleClasses) {\n\t\t\taddToModulesList(loader, modules, className);\n\t\t}\n\t\tif (ClassUtils.isPresent(\"jakarta.servlet.http.Cookie\", loader)) {\n\t\t\taddToModulesList(loader, modules, webServletJackson2ModuleClass);\n\t\t}\n\t\tif (ClassUtils.isPresent(\"org.springframework.security.oauth2.client.OAuth2AuthorizedClient\", loader)) {\n\t\t\taddToModulesList(loader, modules, oauth2ClientJackson2ModuleClass);\n\t\t}\n\t\tif (ClassUtils.isPresent(javaTimeJackson2ModuleClass, loader)) {\n\t\t\taddToModulesList(loader, modules, javaTimeJackson2ModuleClass);\n\t\t}\n\t\tif (ClassUtils.isPresent(ldapJackson2ModuleClass, loader)) {\n\t\t\taddToModulesList(loader, modules, ldapJackson2ModuleClass);\n\t\t}\n\t\tif (ClassUtils.isPresent(saml2Jackson2ModuleClass, loader)) {\n\t\t\taddToModulesList(loader, modules, saml2Jackson2ModuleClass);\n\t\t}\n\t\treturn modules;\n\t}", "summary_tokens": ["loader", "the", "class", "loader", "to", "use", "list", "of", "available", "security", "modules", "in", "classpath"], "project": "spring-security"}
{"id": 1166, "code": "\tprivate static void applyNonce(OAuth2AuthorizationRequest.Builder builder) {\n\t\ttry {\n\t\t\tString nonce = DEFAULT_SECURE_KEY_GENERATOR.generateKey();\n\t\t\tString nonceHash = createHash(nonce);\n\t\t\tbuilder.attributes((attrs) -> attrs.put(OidcParameterNames.NONCE, nonce));\n\t\t\tbuilder.additionalParameters((params) -> params.put(OidcParameterNames.NONCE, nonceHash));\n\t\t}\n\t\tcatch (NoSuchAlgorithmException ex) {\n\t\t}\n\t}", "summary_tokens": ["creates", "nonce", "and", "its", "hash", "for", "use", "in", "open", "id", "connect", "0"], "project": "spring-security"}
{"id": 1545, "code": "\tpublic static OidcLoginRequestPostProcessor oidcLogin() {\n\t\tOAuth2AccessToken accessToken = new OAuth2AccessToken(OAuth2AccessToken.TokenType.BEARER, \"access-token\", null,\n\t\t\t\tnull, Collections.singleton(\"read\"));\n\t\treturn new OidcLoginRequestPostProcessor(accessToken);\n\t}", "summary_tokens": ["establish", "a", "security", "context", "that", "has", "a", "oauth", "0", "authentication", "token", "for", "the", "authentication", "a", "oidc", "user", "as", "the", "principal", "and", "a", "oauth", "0", "authorized", "client", "in", "the", "session"], "project": "spring-security"}
{"id": 1687, "code": "\tpublic void setUserRoles2GrantedAuthoritiesMapper(Attributes2GrantedAuthoritiesMapper mapper) {\n\t\tthis.j2eeUserRoles2GrantedAuthoritiesMapper = mapper;\n\t}", "summary_tokens": ["mapper", "the", "attributes", "0", "granted", "authorities", "mapper", "to", "use"], "project": "spring-security"}
{"id": 736, "code": "\tpublic void setUserCache(UserCache userCache) {\n\t\tAssert.notNull(userCache, \"userCache cannot be null\");\n\t\tthis.userCache = userCache;\n\t}", "summary_tokens": ["optionally", "sets", "the", "user", "cache", "if", "one", "is", "in", "use", "in", "the", "application"], "project": "spring-security"}
{"id": 177, "code": "\tpublic WebSecurity requestRejectedHandler(RequestRejectedHandler requestRejectedHandler) {\n\t\tAssert.notNull(requestRejectedHandler, \"requestRejectedHandler cannot be null\");\n\t\tthis.requestRejectedHandler = requestRejectedHandler;\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "handler", "to", "handle", "org"], "project": "spring-security"}
{"id": 1632, "code": "\tpublic void setRedirectStrategy(RedirectStrategy redirectStrategy) {\n\t\tthis.redirectStrategy = redirectStrategy;\n\t}", "summary_tokens": ["allows", "overriding", "of", "the", "behaviour", "when", "redirecting", "to", "a", "target", "url"], "project": "spring-security"}
{"id": 1369, "code": "\tpublic void setAuthenticationDetailsSource(\n\t\t\tAuthenticationDetailsSource<HttpServletRequest, ?> authenticationDetailsSource) {\n\t\tAssert.notNull(authenticationDetailsSource, \"authenticationDetailsSource cannot be null\");\n\t\tthis.authenticationDetailsSource = authenticationDetailsSource;\n\t}", "summary_tokens": ["set", "the", "authentication", "details", "source", "to", "use"], "project": "spring-security"}
{"id": 231, "code": "\tprivate SessionAuthenticationStrategy getSessionAuthenticationStrategy() {\n\t\tif (this.sessionAuthenticationStrategy != null) {\n\t\t\treturn this.sessionAuthenticationStrategy;\n\t\t}\n\t\tCsrfAuthenticationStrategy csrfAuthenticationStrategy = new CsrfAuthenticationStrategy(\n\t\t\t\tthis.csrfTokenRepository);\n\t\tif (this.requestAttributeHandler != null) {\n\t\t\tcsrfAuthenticationStrategy.setRequestAttributeHandler(this.requestAttributeHandler);\n\t\t}\n\t\treturn csrfAuthenticationStrategy;\n\t}", "summary_tokens": ["gets", "the", "session", "authentication", "strategy", "to", "use"], "project": "spring-security"}
{"id": 654, "code": "\tpublic static void main(String... args) {\n\t\tSystem.out.println(\"Display parameters as parsed by Maven (in canonical form) and comparison result:\");\n\t\tif (args.length == 0) {\n\t\t\treturn;\n\t\t}\n\n\t\tComparableVersion prev = null;\n\t\tint i = 1;\n\t\tfor (String version : args) {\n\t\t\tComparableVersion c = new ComparableVersion(version);\n\n\t\t\tif (prev != null) {\n\t\t\t\tint compare = prev.compareTo(c);\n\t\t\t\tSystem.out.println(\"   \" + prev.toString() + ' ' + ((compare == 0) ? \"==\" : ((compare < 0) ? \"<\" : \">\"))\n\t\t\t\t\t\t+ ' ' + version);\n\t\t\t}\n\n\t\t\tSystem.out.println(String.valueOf(i++) + \". \" + version + \" == \" + c.getCanonical());\n\n\t\t\tprev = c;\n\t\t}\n\t}", "summary_tokens": ["main", "to", "test", "version", "parsing", "and", "comparison"], "project": "spring-security"}
{"id": 1543, "code": "\tpublic static RequestPostProcessor httpBasic(String username, String password) {\n\t\treturn new HttpBasicRequestPostProcessor(username, password);\n\t}", "summary_tokens": ["convenience", "mechanism", "for", "setting", "the", "authorization", "header", "to", "use", "http", "basic", "with", "the", "given", "username", "and", "password"], "project": "spring-security"}
{"id": 1877, "code": "\tpublic void setBlock(boolean block) {\n\t\tif (!this.enabled && block) {\n\t\t\tthrow new IllegalArgumentException(\"Cannot set block to true with enabled false\");\n\t\t}\n\t\tthis.block = block;\n\t\tupdateHeaderValue();\n\t}", "summary_tokens": ["if", "false", "will", "not", "specify", "the", "mode", "as", "blocked"], "project": "spring-security"}
{"id": 403, "code": "\tvoid initAccessDeniedHandler(BeanDefinition invalidSessionStrategy, BeanMetadataElement defaultDeniedHandler) {\n\t\tBeanMetadataElement accessDeniedHandler = createAccessDeniedHandler(invalidSessionStrategy,\n\t\t\t\tdefaultDeniedHandler);\n\t\tthis.csrfFilter.getPropertyValues().addPropertyValue(\"accessDeniedHandler\", accessDeniedHandler);\n\t}", "summary_tokens": ["populate", "the", "access", "denied", "handler", "on", "the", "csrf", "filter", "invalid", "session", "strategy", "the", "invalid", "session", "strategy", "to", "use", "default", "denied", "handler", "the", "access", "denied", "handler", "to", "use"], "project": "spring-security"}
{"id": 1537, "code": "\tpublic static RequestPostProcessor user(UserDetails user) {\n\t\treturn new UserDetailsRequestPostProcessor(user);\n\t}", "summary_tokens": ["establish", "a", "security", "context", "that", "has", "a", "username", "password", "authentication", "token", "for", "the", "authentication", "get", "principal", "and", "a", "custom", "user", "details", "for", "the", "username", "password", "authentication", "token", "get", "principal"], "project": "spring-security"}
{"id": 1308, "code": "\tdefault String getId() {\n\t\treturn this.getClaimAsString(JwtClaimNames.JTI);\n\t}", "summary_tokens": ["returns", "the", "jwt", "id", "jti", "claim", "which", "provides", "a", "unique", "identifier", "for", "the", "jwt"], "project": "spring-security"}
{"id": 71, "code": "\tpublic AuthenticationManagerBuilder parentAuthenticationManager(AuthenticationManager authenticationManager) {\n\t\tif (authenticationManager instanceof ProviderManager) {\n\t\t\teraseCredentials(((ProviderManager) authenticationManager).isEraseCredentialsAfterAuthentication());\n\t\t}\n\t\tthis.parentAuthenticationManager = authenticationManager;\n\t\treturn this;\n\t}", "summary_tokens": ["allows", "providing", "a", "parent", "authentication", "manager", "that", "will", "be", "tried", "if", "this", "authentication", "manager", "was", "unable", "to", "attempt", "to", "authenticate", "the", "provided", "authentication"], "project": "spring-security"}
{"id": 1415, "code": "\tpublic static Builder withRelyingPartyRegistration(RelyingPartyRegistration registration) {\n\t\tString location = registration.getAssertingPartyDetails().getSingleSignOnServiceLocation();\n\t\treturn new Builder(registration).authenticationRequestUri(location);\n\t}", "summary_tokens": ["constructs", "a", "builder", "from", "a", "relying", "party", "registration", "object"], "project": "spring-security"}
{"id": 1201, "code": "\tdefault Instant getExpiresAt() {\n\t\treturn null;\n\t}", "summary_tokens": ["returns", "the", "expiration", "time", "on", "or", "after", "which", "the", "token", "must", "not", "be", "accepted"], "project": "spring-security"}
{"id": 840, "code": "\tpublic void setSearchControls(SearchControls searchControls) {\n\t\tthis.searchControls = searchControls;\n\t}", "summary_tokens": ["sets", "the", "search", "controls", "which", "will", "be", "used", "for", "search", "operations", "by", "the", "template"], "project": "spring-security"}
{"id": 1678, "code": "\tprotected Object getPreAuthenticatedCredentials(HttpServletRequest request) {\n\t\tif (this.credentialsEnvironmentVariable != null) {\n\t\t\treturn request.getAttribute(this.credentialsEnvironmentVariable);\n\t\t}\n\t\treturn \"N/A\";\n\t}", "summary_tokens": ["credentials", "aren", "t", "usually", "applicable", "but", "if", "a", "credentials", "environment", "variable", "is", "set", "this", "will", "be", "read", "and", "used", "as", "the", "credentials", "value"], "project": "spring-security"}
{"id": 79, "code": "\tpublic boolean isConfigured() {\n\t\treturn !this.authenticationProviders.isEmpty() || this.parentAuthenticationManager != null;\n\t}", "summary_tokens": ["determines", "if", "the", "authentication", "manager", "builder", "is", "configured", "to", "build", "a", "non", "null", "authentication", "manager"], "project": "spring-security"}
{"id": 1573, "code": "\tpublic boolean isAllowed(String contextPath, String uri, String method, Authentication authentication) {\n\t\tAssert.notNull(uri, \"uri parameter is required\");\n\t\tFilterInvocation filterInvocation = new FilterInvocation(contextPath, uri, method, this.servletContext);\n\t\tCollection<ConfigAttribute> attributes = this.securityInterceptor.obtainSecurityMetadataSource()\n\t\t\t\t.getAttributes(filterInvocation);\n\t\tif (attributes == null) {\n\t\t\treturn (!this.securityInterceptor.isRejectPublicInvocations());\n\t\t}\n\t\tif (authentication == null) {\n\t\t\treturn false;\n\t\t}\n\t\ttry {\n\t\t\tthis.securityInterceptor.getAccessDecisionManager().decide(authentication, filterInvocation, attributes);\n\t\t\treturn true;\n\t\t}\n\t\tcatch (AccessDeniedException ex) {\n\t\t\tlogger.debug(LogMessage.format(\"%s denied for %s\", filterInvocation, authentication), ex);\n\t\t\treturn false;\n\t\t}\n\t}", "summary_tokens": ["determines", "whether", "the", "user", "represented", "by", "the", "supplied", "tt", "authentication", "tt", "object", "is", "allowed", "to", "invoke", "the", "supplied", "uri", "with", "the", "given"], "project": "spring-security"}
{"id": 1703, "code": "\tprotected String encodeCookie(String[] cookieTokens) {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tfor (int i = 0; i < cookieTokens.length; i++) {\n\t\t\ttry {\n\t\t\t\tsb.append(URLEncoder.encode(cookieTokens[i], StandardCharsets.UTF_8.toString()));\n\t\t\t}\n\t\t\tcatch (UnsupportedEncodingException ex) {\n\t\t\t\tthis.logger.error(ex.getMessage(), ex);\n\t\t\t}\n\t\t\tif (i < cookieTokens.length - 1) {\n\t\t\t\tsb.append(DELIMITER);\n\t\t\t}\n\t\t}\n\t\tString value = sb.toString();\n\t\tsb = new StringBuilder(new String(Base64.getEncoder().encode(value.getBytes())));\n\t\twhile (sb.charAt(sb.length() - 1) == '=') {\n\t\t\tsb.deleteCharAt(sb.length() - 1);\n\t\t}\n\t\treturn sb.toString();\n\t}", "summary_tokens": ["inverse", "operation", "of", "decode", "cookie"], "project": "spring-security"}
{"id": 1951, "code": "\tpublic void setAuthenticationEntryPoint(ServerAuthenticationEntryPoint authenticationEntryPoint) {\n\t\tAssert.notNull(authenticationEntryPoint, \"authenticationEntryPoint cannot be null\");\n\t\tthis.authenticationEntryPoint = authenticationEntryPoint;\n\t}", "summary_tokens": ["sets", "the", "authentication", "entry", "point", "used", "when", "authentication", "is", "required", "authentication", "entry", "point", "the", "authentication", "entry", "point", "to", "use"], "project": "spring-security"}
{"id": 533, "code": "\tpublic void decide(Authentication authentication, Object object, Collection<ConfigAttribute> configAttributes)\n\t\t\tthrows AccessDeniedException {\n\t\tint grant = 0;\n\t\tint deny = 0;\n\t\tfor (AccessDecisionVoter voter : getDecisionVoters()) {\n\t\t\tint result = voter.vote(authentication, object, configAttributes);\n\t\t\tswitch (result) {\n\t\t\tcase AccessDecisionVoter.ACCESS_GRANTED:\n\t\t\t\tgrant++;\n\t\t\t\tbreak;\n\t\t\tcase AccessDecisionVoter.ACCESS_DENIED:\n\t\t\t\tdeny++;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (grant > deny) {\n\t\t\treturn;\n\t\t}\n\t\tif (deny > grant) {\n\t\t\tthrow new AccessDeniedException(\n\t\t\t\t\tthis.messages.getMessage(\"AbstractAccessDecisionManager.accessDenied\", \"Access is denied\"));\n\t\t}\n\t\tif ((grant == deny) && (grant != 0)) {\n\t\t\tif (this.allowIfEqualGrantedDeniedDecisions) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tthrow new AccessDeniedException(\n\t\t\t\t\tthis.messages.getMessage(\"AbstractAccessDecisionManager.accessDenied\", \"Access is denied\"));\n\t\t}\n\t\t\n\t\tcheckAllowIfAllAbstainDecisions();\n\t}", "summary_tokens": ["this", "concrete", "implementation", "simply", "polls", "all", "configured", "access", "decision", "voter", "s", "and", "upon", "completion", "determines", "the", "consensus", "of", "granted", "against", "denied", "responses"], "project": "spring-security"}
{"id": 146, "code": "\tpublic HttpSecurity rememberMe(Customizer<RememberMeConfigurer<HttpSecurity>> rememberMeCustomizer)\n\t\t\tthrows Exception {\n\t\trememberMeCustomizer.customize(getOrApply(new RememberMeConfigurer<>()));\n\t\treturn HttpSecurity.this;\n\t}", "summary_tokens": ["allows", "configuring", "of", "remember", "me", "authentication"], "project": "spring-security"}
{"id": 1873, "code": "\tpublic void setPreload(boolean preload) {\n\t\tthis.preload = preload;\n\t\tupdateHstsHeaderValue();\n\t}", "summary_tokens": ["p", "if", "true", "preload", "will", "be", "included", "in", "hsts", "header"], "project": "spring-security"}
{"id": 2017, "code": "\tpublic void sessionCreated(HttpSessionEvent event) {\n\t\textracted(event.getSession(), new HttpSessionCreatedEvent(event.getSession()));\n\t}", "summary_tokens": ["handles", "the", "http", "session", "event", "by", "publishing", "a", "http", "session", "created", "event", "to", "the", "application", "app", "context"], "project": "spring-security"}
{"id": 1629, "code": "\tprotected final void saveException(HttpServletRequest request, AuthenticationException exception) {\n\t\tif (this.forwardToDestination) {\n\t\t\trequest.setAttribute(WebAttributes.AUTHENTICATION_EXCEPTION, exception);\n\t\t\treturn;\n\t\t}\n\t\tHttpSession session = request.getSession(false);\n\t\tif (session != null || this.allowSessionCreation) {\n\t\t\trequest.getSession().setAttribute(WebAttributes.AUTHENTICATION_EXCEPTION, exception);\n\t\t}\n\t}", "summary_tokens": ["caches", "the", "authentication", "exception", "for", "use", "in", "view", "rendering"], "project": "spring-security"}
{"id": 488, "code": "\tpublic int vote(Authentication authentication, Object object, Collection<ConfigAttribute> definition) {\n\t\tboolean jsr250AttributeFound = false;\n\t\tfor (ConfigAttribute attribute : definition) {\n\t\t\tif (Jsr250SecurityConfig.PERMIT_ALL_ATTRIBUTE.equals(attribute)) {\n\t\t\t\treturn ACCESS_GRANTED;\n\t\t\t}\n\t\t\tif (Jsr250SecurityConfig.DENY_ALL_ATTRIBUTE.equals(attribute)) {\n\t\t\t\treturn ACCESS_DENIED;\n\t\t\t}\n\t\t\tif (supports(attribute)) {\n\t\t\t\tjsr250AttributeFound = true;\n\t\t\t\t\n\t\t\t\tfor (GrantedAuthority authority : authentication.getAuthorities()) {\n\t\t\t\t\tif (attribute.getAttribute().equals(authority.getAuthority())) {\n\t\t\t\t\t\treturn ACCESS_GRANTED;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn jsr250AttributeFound ? ACCESS_DENIED : ACCESS_ABSTAIN;\n\t}", "summary_tokens": ["votes", "according", "to", "jsr", "0"], "project": "spring-security"}
{"id": 167, "code": "\tprivate <C extends SecurityConfigurerAdapter<DefaultSecurityFilterChain, HttpSecurity>> C getOrApply(C configurer)\n\t\t\tthrows Exception {\n\t\tC existingConfig = (C) getConfigurer(configurer.getClass());\n\t\tif (existingConfig != null) {\n\t\t\treturn existingConfig;\n\t\t}\n\t\treturn apply(configurer);\n\t}", "summary_tokens": ["if", "the", "security", "configurer", "has", "already", "been", "specified", "get", "the", "original", "otherwise", "apply", "the", "new", "security", "configurer", "adapter"], "project": "spring-security"}
{"id": 407, "code": "\tprivate ManagedMap<BeanMetadataElement, BeanDefinition> parseInterceptUrlsForChannelSecurity() {\n\t\tManagedMap<BeanMetadataElement, BeanDefinition> channelRequestMap = new ManagedMap<>();\n\t\tfor (Element urlElt : this.interceptUrls) {\n\t\t\tString path = urlElt.getAttribute(HttpSecurityBeanDefinitionParser.ATT_PATH_PATTERN);\n\t\t\tString method = urlElt.getAttribute(HttpSecurityBeanDefinitionParser.ATT_HTTP_METHOD);\n\t\t\tString matcherRef = urlElt.getAttribute(HttpSecurityBeanDefinitionParser.ATT_REQUEST_MATCHER_REF);\n\t\t\tboolean hasMatcherRef = StringUtils.hasText(matcherRef);\n\t\t\tif (!hasMatcherRef && !StringUtils.hasText(path)) {\n\t\t\t\tthis.pc.getReaderContext().error(\"pattern attribute cannot be empty or null\", urlElt);\n\t\t\t}\n\t\t\tString requiredChannel = urlElt.getAttribute(HttpSecurityBeanDefinitionParser.ATT_REQUIRES_CHANNEL);\n\t\t\tif (StringUtils.hasText(requiredChannel)) {\n\t\t\t\tBeanMetadataElement matcher = hasMatcherRef ? new RuntimeBeanReference(matcherRef)\n\t\t\t\t\t\t: this.matcherType.createMatcher(this.pc, path, method);\n\t\t\t\tRootBeanDefinition channelAttributes = new RootBeanDefinition(ChannelAttributeFactory.class);\n\t\t\t\tchannelAttributes.getConstructorArgumentValues().addGenericArgumentValue(requiredChannel);\n\t\t\t\tchannelAttributes.setFactoryMethodName(\"createChannelAttributes\");\n\t\t\t\tchannelRequestMap.put(matcher, channelAttributes);\n\t\t\t}\n\t\t}\n\t\treturn channelRequestMap;\n\t}", "summary_tokens": ["parses", "the", "intercept", "url", "elements", "to", "obtain", "the", "map", "used", "by", "channel", "security"], "project": "spring-security"}
{"id": 1000, "code": "\tpublic void setAccessTokenResponseClient(\n\t\t\tReactiveOAuth2AccessTokenResponseClient<OAuth2PasswordGrantRequest> accessTokenResponseClient) {\n\t\tAssert.notNull(accessTokenResponseClient, \"accessTokenResponseClient cannot be null\");\n\t\tthis.accessTokenResponseClient = accessTokenResponseClient;\n\t}", "summary_tokens": ["sets", "the", "client", "used", "when", "requesting", "an", "access", "token", "credential", "at", "the", "token", "endpoint", "for", "the", "password", "grant"], "project": "spring-security"}
{"id": 1314, "code": "\tpublic static JwtEncoderParameters from(JwsHeader jwsHeader, JwtClaimsSet claims) {\n\t\tAssert.notNull(jwsHeader, \"jwsHeader cannot be null\");\n\t\tAssert.notNull(claims, \"claims cannot be null\");\n\t\treturn new JwtEncoderParameters(jwsHeader, claims);\n\t}", "summary_tokens": ["returns", "a", "new", "jwt", "encoder", "parameters", "initialized", "with", "the", "provided", "jws", "header", "and", "jwt", "claims", "set"], "project": "spring-security"}
{"id": 1222, "code": "\tpublic Map<String, Object> getAdditionalParameters() {\n\t\treturn this.additionalParameters;\n\t}", "summary_tokens": ["returns", "the", "additional", "parameters", "returned", "in", "the", "response"], "project": "spring-security"}
{"id": 936, "code": "\tpublic final ArgResolver annotNotPresent(Class<? extends Annotation>... annotationTypes) {\n\t\treturn new ArgResolver().annotNotPresent(annotationTypes);\n\t}", "summary_tokens": ["filter", "on", "method", "arguments", "that", "don", "t", "have", "the", "given", "annotation", "type", "s"], "project": "spring-security"}
{"id": 536, "code": "\tpublic boolean supports(Class<?> clazz) {\n\t\treturn true;\n\t}", "summary_tokens": ["this", "implementation", "supports", "any", "type", "of", "class", "because", "it", "does", "not", "query", "the", "presented", "secure", "object"], "project": "spring-security"}
{"id": 1290, "code": "\tpublic <T extends JwaAlgorithm> T getAlgorithm() {\n\t\treturn (T) getHeader(JoseHeaderNames.ALG);\n\t}", "summary_tokens": ["returns", "the", "jwa", "algorithm", "jwa", "algorithm", "used", "to", "digitally", "sign", "the", "jws", "or", "encrypt", "the", "jwe"], "project": "spring-security"}
{"id": 607, "code": "\tfinal T getAttribute(Method method, Class<?> targetClass) {\n\t\tMethodClassKey cacheKey = new MethodClassKey(method, targetClass);\n\t\treturn this.cachedAttributes.computeIfAbsent(cacheKey, (k) -> resolveAttribute(method, targetClass));\n\t}", "summary_tokens": ["returns", "an", "expression", "attribute", "for", "the", "method", "and", "the", "target", "class"], "project": "spring-security"}
{"id": 1614, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 1728, "code": "\tprotected int getMaximumSessionsForThisUser(Authentication authentication) {\n\t\treturn this.maximumSessions;\n\t}", "summary_tokens": ["method", "intended", "for", "use", "by", "subclasses", "to", "override", "the", "maximum", "number", "of", "sessions", "that", "are", "permitted", "for", "a", "particular", "authentication"], "project": "spring-security"}
{"id": 163, "code": "\tpublic HttpSecurity requestMatcher(RequestMatcher requestMatcher) {\n\t\tthis.requestMatcher = requestMatcher;\n\t\treturn this;\n\t}", "summary_tokens": ["allows", "configuring", "the", "http", "security", "to", "only", "be", "invoked", "when", "matching", "the", "provided", "request", "matcher"], "project": "spring-security"}
{"id": 665, "code": "\tprivate Collection<GrantedAuthority> getGrantedAuthorityCollection(Object value) {\n\t\tCollection<GrantedAuthority> result = new ArrayList<>();\n\t\taddGrantedAuthorityCollection(result, value);\n\t\treturn result;\n\t}", "summary_tokens": ["convert", "the", "given", "value", "to", "a", "collection", "of", "granted", "authorities", "value", "the", "value", "to", "convert", "to", "a", "granted", "authority", "collection", "collection", "containing", "the", "granted", "authority", "collection"], "project": "spring-security"}
{"id": 1456, "code": "\tpublic Collection<Saml2X509Credential> getSigningX509Credentials() {\n\t\treturn this.signingX509Credentials;\n\t}", "summary_tokens": ["get", "the", "collection", "of", "signing", "saml", "0", "x", "0", "credential", "s", "associated", "with", "this", "relying", "party", "the", "collection", "of", "signing", "saml", "0", "x", "0", "credential", "s", "associated", "with", "this", "relying", "party", "0"], "project": "spring-security"}
{"id": 1789, "code": "\tpublic void setSpringSecurityContextKey(String springSecurityContextKey) {\n\t\tAssert.hasText(springSecurityContextKey, \"springSecurityContextKey cannot be empty\");\n\t\tthis.springSecurityContextKey = springSecurityContextKey;\n\t}", "summary_tokens": ["allows", "the", "session", "attribute", "name", "to", "be", "customized", "for", "this", "repository", "instance"], "project": "spring-security"}
{"id": 2068, "code": "\tpublic void publishedEventIsReceivedbyListener() {\n\t\tHttpSessionEventPublisher publisher = new HttpSessionEventPublisher();\n\t\tStaticWebApplicationContext context = new StaticWebApplicationContext();\n\t\tMockServletContext servletContext = new MockServletContext();\n\t\tservletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, context);\n\t\tcontext.setServletContext(servletContext);\n\t\tcontext.registerSingleton(\"listener\", MockApplicationListener.class, null);\n\t\tcontext.refresh();\n\t\tMockHttpSession session = new MockHttpSession(servletContext);\n\t\tMockApplicationListener listener = (MockApplicationListener) context.getBean(\"listener\");\n\t\tHttpSessionEvent event = new HttpSessionEvent(session);\n\t\tpublisher.sessionCreated(event);\n\t\tassertThat(listener.getCreatedEvent()).isNotNull();\n\t\tassertThat(listener.getDestroyedEvent()).isNull();\n\t\tassertThat(listener.getCreatedEvent().getSession()).isEqualTo(session);\n\t\tlistener.setCreatedEvent(null);\n\t\tlistener.setDestroyedEvent(null);\n\t\tpublisher.sessionDestroyed(event);\n\t\tassertThat(listener.getDestroyedEvent()).isNotNull();\n\t\tassertThat(listener.getCreatedEvent()).isNull();\n\t\tassertThat(listener.getDestroyedEvent().getSession()).isEqualTo(session);\n\t\tpublisher.sessionIdChanged(event, \"oldSessionId\");\n\t\tassertThat(listener.getSessionIdChangedEvent()).isNotNull();\n\t\tassertThat(listener.getSessionIdChangedEvent().getOldSessionId()).isEqualTo(\"oldSessionId\");\n\t\tlistener.setSessionIdChangedEvent(null);\n\t}", "summary_tokens": ["it", "s", "not", "that", "complicated", "so", "we", "ll", "just", "run", "it", "straight", "through", "here"], "project": "spring-security"}
{"id": 649, "code": "\tpublic void setSecurityContextHolderStrategy(SecurityContextHolderStrategy securityContextHolderStrategy) {\n\t\tAssert.notNull(securityContextHolderStrategy, \"securityContextHolderStrategy cannot be null\");\n\t\tthis.securityContextHolderStrategy = securityContextHolderStrategy;\n\t\tif (!this.explicitSecurityContextProvided) {\n\t\t\tthis.delegateSecurityContext = this.securityContextHolderStrategy.getContext();\n\t\t}\n\t}", "summary_tokens": ["sets", "the", "security", "context", "holder", "strategy", "to", "use"], "project": "spring-security"}
{"id": 46, "code": "\tpublic void publishRelease(RepositoryRef repository, Release release) {\n\t\tString url = this.baseUrl + \"/repos/\" + repository.getOwner() + \"/\" + repository.getName() + \"/releases\";\n\t\tString json = this.gson.toJson(release);\n\t\tRequestBody body = RequestBody.create(MediaType.parse(\"application/json\"), json);\n\t\tRequest request = new Request.Builder().url(url).post(body).build();\n\t\ttry {\n\t\t\tResponse response = this.httpClient.newCall(request).execute();\n\t\t\tif (!response.isSuccessful()) {\n\t\t\t\tthrow new RuntimeException(String.format(\"Could not create release %s for repository %s/%s. Got response %s\",\n\t\t\t\t\t\trelease.getName(), repository.getOwner(), repository.getName(), response));\n\t\t\t}\n\t\t} catch (IOException ex) {\n\t\t\tthrow new RuntimeException(String.format(\"Could not create release %s for repository %s/%s\",\n\t\t\t\t\trelease.getName(), repository.getOwner(), repository.getName()), ex);\n\t\t}\n\t}", "summary_tokens": ["publish", "a", "release", "with", "no", "binary", "attachments"], "project": "spring-security"}
{"id": 1388, "code": "\tpublic static Saml2X509Credential encryption(X509Certificate certificate) {\n\t\treturn new Saml2X509Credential(certificate, Saml2X509Credential.Saml2X509CredentialType.ENCRYPTION);\n\t}", "summary_tokens": ["create", "a", "saml", "0", "x", "0", "credential", "that", "can", "be", "used", "for", "encryption"], "project": "spring-security"}
{"id": 1795, "code": "\tprotected void onResponseCommitted() {\n\t\tsaveContext(this.securityContextHolderStrategy.getContext());\n\t\tthis.contextSaved = true;\n\t}", "summary_tokens": ["calls", "code", "save", "context", "code", "with", "the", "current", "contents", "of", "the", "tt", "security", "context", "holder", "tt", "as", "long", "as", "disable", "save", "on", "response", "committed", "was", "not", "invoked"], "project": "spring-security"}
{"id": 27, "code": "\tprotected Long createOrRetrieveSidPrimaryKey(String sidName, boolean sidIsPrincipal, boolean allowCreate) {\n\t\tList<Long> sidIds = this.jdbcOperations.queryForList(this.selectSidPrimaryKey,\n\t\t\t\tnew Object[] { sidIsPrincipal, sidName }, Long.class);\n\t\tif (!sidIds.isEmpty()) {\n\t\t\treturn sidIds.get(0);\n\t\t}\n\t\tif (allowCreate) {\n\t\t\tthis.jdbcOperations.update(this.insertSid, sidIsPrincipal, sidName);\n\t\t\tAssert.isTrue(TransactionSynchronizationManager.isSynchronizationActive(), \"Transaction must be running\");\n\t\t\treturn this.jdbcOperations.queryForObject(this.sidIdentityQuery, Long.class);\n\t\t}\n\t\treturn null;\n\t}", "summary_tokens": ["retrieves", "the", "primary", "key", "from", "acl", "sid", "creating", "a", "new", "row", "if", "needed", "and", "the", "allow", "create", "property", "is", "true"], "project": "spring-security"}
{"id": 1087, "code": "\tpublic void setJwtValidatorFactory(Function<ClientRegistration, OAuth2TokenValidator<Jwt>> jwtValidatorFactory) {\n\t\tAssert.notNull(jwtValidatorFactory, \"jwtValidatorFactory cannot be null\");\n\t\tthis.jwtValidatorFactory = jwtValidatorFactory;\n\t}", "summary_tokens": ["sets", "the", "factory", "that", "provides", "an", "oauth", "0", "token", "validator", "which", "is", "used", "by", "the", "reactive", "jwt", "decoder"], "project": "spring-security"}
{"id": 250, "code": "\tpublic HeadersConfigurer<H> contentTypeOptions(Customizer<ContentTypeOptionsConfig> contentTypeOptionsCustomizer) {\n\t\tcontentTypeOptionsCustomizer.customize(this.contentTypeOptions.enable());\n\t\treturn HeadersConfigurer.this;\n\t}", "summary_tokens": ["configures", "the", "xcontent", "type", "options", "header", "writer", "which", "inserts", "the", "a", "href", "https", "msdn"], "project": "spring-security"}
{"id": 852, "code": "\tpublic String getPrincipal() {\n\t\tAuthentication authentication = this.securityContextHolderStrategy.getContext().getAuthentication();\n\t\tif (authentication == null) {\n\t\t\tlog.debug(\"Returning empty String as Principal since authentication is null\");\n\t\t\treturn \"\";\n\t\t}\n\t\tObject principal = authentication.getPrincipal();\n\t\tif (principal instanceof LdapUserDetails) {\n\t\t\tLdapUserDetails details = (LdapUserDetails) principal;\n\t\t\treturn details.getDn();\n\t\t}\n\t\tif (authentication instanceof AnonymousAuthenticationToken) {\n\t\t\tlog.debug(\"Returning empty String as Principal since authentication is anonymous\");\n\t\t\treturn \"\";\n\t\t}\n\t\tthrow new IllegalArgumentException(\n\t\t\t\t\"The principal property of the authentication object\" + \"needs to be an LdapUserDetails.\");\n\t}", "summary_tokens": ["get", "the", "principals", "of", "the", "logged", "in", "user", "in", "this", "case", "the", "distinguished", "name"], "project": "spring-security"}
{"id": 1968, "code": "\tprivate static boolean equalsConstantTime(String expected, String actual) {\n\t\tif (expected == actual) {\n\t\t\treturn true;\n\t\t}\n\t\tif (expected == null || actual == null) {\n\t\t\treturn false;\n\t\t}\n\t\t\n\t\tbyte[] expectedBytes = Utf8.encode(expected);\n\t\tbyte[] actualBytes = Utf8.encode(actual);\n\t\treturn MessageDigest.isEqual(expectedBytes, actualBytes);\n\t}", "summary_tokens": ["constant", "time", "comparison", "to", "prevent", "against", "timing", "attacks"], "project": "spring-security"}
{"id": 993, "code": "\tpublic OAuth2AuthorizedClientProviderBuilder password(Consumer<PasswordGrantBuilder> builderConsumer) {\n\t\tPasswordGrantBuilder builder = (PasswordGrantBuilder) this.builders\n\t\t\t\t.computeIfAbsent(PasswordOAuth2AuthorizedClientProvider.class, (k) -> new PasswordGrantBuilder());\n\t\tbuilderConsumer.accept(builder);\n\t\treturn OAuth2AuthorizedClientProviderBuilder.this;\n\t}", "summary_tokens": ["configures", "support", "for", "the", "password", "grant"], "project": "spring-security"}
{"id": 1132, "code": "\tpublic void setAuthorizedClientProvider(ReactiveOAuth2AuthorizedClientProvider authorizedClientProvider) {\n\t\tAssert.notNull(authorizedClientProvider, \"authorizedClientProvider cannot be null\");\n\t\tthis.authorizedClientProvider = authorizedClientProvider;\n\t}", "summary_tokens": ["sets", "the", "reactive", "oauth", "0", "authorized", "client", "provider", "used", "for", "authorizing", "or", "re", "authorizing", "an", "oauth", "0"], "project": "spring-security"}
{"id": 701, "code": "\tpublic void setAlgorithm(String algorithm) {\n\t\tAssert.hasText(algorithm, \"Algorithm required\");\n\t\tthis.algorithm = algorithm;\n\t}", "summary_tokens": ["allows", "the", "pseudo", "random", "number", "generator", "prng", "algorithm", "to", "be", "nominated"], "project": "spring-security"}
{"id": 569, "code": "\tprotected LoginContext createLoginContext(CallbackHandler handler) throws LoginException {\n\t\treturn new LoginContext(getLoginContextName(), null, handler, getConfiguration());\n\t}", "summary_tokens": ["creates", "a", "login", "context", "using", "the", "configuration", "that", "was", "specified", "in", "set", "configuration", "configuration"], "project": "spring-security"}
{"id": 1158, "code": "\tpublic static Consumer<Map<String, Object>> clientRegistrationId(String clientRegistrationId) {\n\t\treturn (attributes) -> attributes.put(CLIENT_REGISTRATION_ID_ATTR_NAME, clientRegistrationId);\n\t}", "summary_tokens": ["modifies", "the", "client", "request", "attributes", "to", "include", "the", "client", "registration", "get", "registration", "id", "to", "be", "used", "to", "look", "up", "the", "oauth", "0", "authorized", "client"], "project": "spring-security"}
{"id": 1192, "code": "\tpublic TokenType getTokenType() {\n\t\treturn this.tokenType;\n\t}", "summary_tokens": ["returns", "the", "token", "type", "token", "type"], "project": "spring-security"}
{"id": 1442, "code": "\tpublic static Saml2LogoutValidatorResult.Builder withErrors(Saml2Error... errors) {\n\t\treturn new Builder(errors);\n\t}", "summary_tokens": ["construct", "a", "saml", "0", "logout", "validator", "result"], "project": "spring-security"}
{"id": 1239, "code": "\tpublic String getRedirectUri() {\n\t\treturn this.redirectUri;\n\t}", "summary_tokens": ["returns", "the", "uri", "where", "the", "response", "was", "redirected", "to"], "project": "spring-security"}
{"id": 1361, "code": "\tpublic void setRequestEntityConverter(Converter<String, RequestEntity<?>> requestEntityConverter) {\n\t\tAssert.notNull(requestEntityConverter, \"requestEntityConverter cannot be null\");\n\t\tthis.requestEntityConverter = requestEntityConverter;\n\t}", "summary_tokens": ["sets", "the", "converter", "used", "for", "converting", "the", "oauth", "0"], "project": "spring-security"}
{"id": 12, "code": "\tSerializable identifierFrom(Serializable identifier, ResultSet resultSet) throws SQLException {\n\t\tif (isString(identifier) && hasValidClassIdType(resultSet)\n\t\t\t\t&& canConvertFromStringTo(classIdTypeFrom(resultSet))) {\n\t\t\treturn convertFromStringTo((String) identifier, classIdTypeFrom(resultSet));\n\t\t}\n\t\t\n\t\treturn convertToLong(identifier);\n\t}", "summary_tokens": ["converts", "the", "raw", "type", "from", "the", "database", "into", "the", "right", "java", "type"], "project": "spring-security"}
{"id": 1076, "code": "\tpublic final void setJwtDecoderFactory(JwtDecoderFactory<ClientRegistration> jwtDecoderFactory) {\n\t\tAssert.notNull(jwtDecoderFactory, \"jwtDecoderFactory cannot be null\");\n\t\tthis.jwtDecoderFactory = jwtDecoderFactory;\n\t}", "summary_tokens": ["sets", "the", "jwt", "decoder", "factory", "used", "for", "oidc", "id", "token", "signature", "verification"], "project": "spring-security"}
{"id": 1408, "code": "\tpublic Saml2Error getSaml2Error() {\n\t\treturn this.error;\n\t}", "summary_tokens": ["get", "the", "associated", "saml", "0", "error", "the", "associated", "saml", "0", "error"], "project": "spring-security"}
{"id": 493, "code": "\tpublic void setDefaultRolePrefix(String defaultRolePrefix) {\n\t\tthis.defaultRolePrefix = defaultRolePrefix;\n\t}", "summary_tokens": ["p", "sets", "the", "default", "prefix", "to", "be", "added", "to", "has", "any", "role", "string"], "project": "spring-security"}
{"id": 70, "code": "\tpublic void setBuilder(B builder) {\n\t\tthis.securityBuilder = builder;\n\t}", "summary_tokens": ["sets", "the", "security", "builder", "to", "be", "used"], "project": "spring-security"}
{"id": 1466, "code": "\tpublic void setAuthenticationRequestRepository(\n\t\t\tSaml2AuthenticationRequestRepository<AbstractSaml2AuthenticationRequest> authenticationRequestRepository) {\n\t\tAssert.notNull(authenticationRequestRepository, \"authenticationRequestRepository cannot be null\");\n\t\tthis.loader = authenticationRequestRepository::loadAuthenticationRequest;\n\t}", "summary_tokens": ["use", "the", "given", "saml", "0", "authentication", "request", "repository", "to", "load", "authentication", "request"], "project": "spring-security"}
{"id": 267, "code": "\tpublic HttpBasicConfigurer<B> authenticationEntryPoint(AuthenticationEntryPoint authenticationEntryPoint) {\n\t\tthis.authenticationEntryPoint = authenticationEntryPoint;\n\t\treturn this;\n\t}", "summary_tokens": ["the", "authentication", "entry", "point", "to", "be", "populated", "on", "basic", "authentication", "filter", "in", "the", "event", "that", "authentication", "fails"], "project": "spring-security"}
{"id": 2059, "code": "\tpublic void currentSubjectNull() {\n\t\tassertThat(Subject.getSubject(AccessController.getContext())).isNull();\n\t}", "summary_tokens": ["ensure", "a", "subject", "was", "not", "setup", "in", "some", "other", "manner"], "project": "spring-security"}
{"id": 676, "code": "\tpublic void setDefaultAuthority(String authority) {\n\t\tAssert.hasText(authority, \"The authority name cannot be set to an empty value\");\n\t\tthis.defaultAuthority = new SimpleGrantedAuthority(authority);\n\t}", "summary_tokens": ["sets", "a", "default", "authority", "to", "be", "assigned", "to", "all", "users", "authority", "the", "name", "of", "the", "authority", "to", "be", "assigned", "to", "all", "users"], "project": "spring-security"}
{"id": 1009, "code": "\tpublic ReactiveOAuth2AuthorizedClientProviderBuilder clientCredentials(\n\t\t\tConsumer<ClientCredentialsGrantBuilder> builderConsumer) {\n\t\tClientCredentialsGrantBuilder builder = (ClientCredentialsGrantBuilder) this.builders.computeIfAbsent(\n\t\t\t\tClientCredentialsReactiveOAuth2AuthorizedClientProvider.class,\n\t\t\t\t(k) -> new ClientCredentialsGrantBuilder());\n\t\tbuilderConsumer.accept(builder);\n\t\treturn ReactiveOAuth2AuthorizedClientProviderBuilder.this;\n\t}", "summary_tokens": ["configures", "support", "for", "the", "client", "credentials", "grant"], "project": "spring-security"}
{"id": 102, "code": "\tpublic JdbcUserDetailsManagerConfigurer<B> usersByUsernameQuery(String query) {\n\t\tgetUserDetailsService().setUsersByUsernameQuery(query);\n\t\treturn this;\n\t}", "summary_tokens": ["sets", "the", "query", "to", "be", "used", "for", "finding", "a", "user", "by", "their", "username"], "project": "spring-security"}
{"id": 1343, "code": "\tpublic static BearerTokenError insufficientScope(String message, String scope) {\n\t\ttry {\n\t\t\treturn new BearerTokenError(BearerTokenErrorCodes.INSUFFICIENT_SCOPE, HttpStatus.FORBIDDEN, message,\n\t\t\t\t\tDEFAULT_URI, scope);\n\t\t}\n\t\tcatch (IllegalArgumentException ex) {\n\t\t\t\n\t\t\t\n\t\t\treturn DEFAULT_INSUFFICIENT_SCOPE;\n\t\t}\n\t}", "summary_tokens": ["create", "a", "bearer", "token", "error", "caused", "by", "an", "invalid", "token", "scope", "the", "scope", "attribute", "to", "use", "in", "the", "error", "a", "bearer", "token", "error"], "project": "spring-security"}
{"id": 127, "code": "\tpublic void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) {\n\t\tregisterBeanDefinition(\"preFilterAuthorizationMethodInterceptor\",\n\t\t\t\t\"org.springframework.security.authorization.method.aspectj.PreFilterAspect\", \"preFilterAspect$0\",\n\t\t\t\tregistry);\n\t\tregisterBeanDefinition(\"postFilterAuthorizationMethodInterceptor\",\n\t\t\t\t\"org.springframework.security.authorization.method.aspectj.PostFilterAspect\", \"postFilterAspect$0\",\n\t\t\t\tregistry);\n\t\tregisterBeanDefinition(\"preAuthorizeAuthorizationMethodInterceptor\",\n\t\t\t\t\"org.springframework.security.authorization.method.aspectj.PreAuthorizeAspect\", \"preAuthorizeAspect$0\",\n\t\t\t\tregistry);\n\t\tregisterBeanDefinition(\"postAuthorizeAuthorizationMethodInterceptor\",\n\t\t\t\t\"org.springframework.security.authorization.method.aspectj.PostAuthorizeAspect\",\n\t\t\t\t\"postAuthorizeAspect$0\", registry);\n\t\tregisterBeanDefinition(\"securedAuthorizationMethodInterceptor\",\n\t\t\t\t\"org.springframework.security.authorization.method.aspectj.SecuredAspect\", \"securedAspect$0\", registry);\n\t}", "summary_tokens": ["register", "escalate", "and", "configure", "the", "aspect", "j", "auto", "proxy", "creator", "based", "on", "the", "value", "of", "the", "enable", "method", "security", "proxy", "target", "class", "attribute", "on", "the", "importing", "class"], "project": "spring-security"}
{"id": 713, "code": "\tpublic void setUserDetailsService(UserDetailsService aUserDetailsService) {\n\t\tthis.userDetailsService = aUserDetailsService;\n\t}", "summary_tokens": ["set", "the", "wrapped", "user", "details", "service", "implementation", "a", "user", "details", "service", "the", "wrapped", "user", "details", "service", "to", "set"], "project": "spring-security"}
{"id": 983, "code": "\tpublic static Builder withAuthorizedClient(OAuth2AuthorizedClient authorizedClient) {\n\t\treturn new Builder(authorizedClient);\n\t}", "summary_tokens": ["returns", "a", "new", "builder", "initialized", "with", "the", "oauth", "0", "authorized", "client", "authorized", "client"], "project": "spring-security"}
{"id": 126, "code": "\tpublic final void setImportMetadata(AnnotationMetadata importMetadata) {\n\t\tMap<String, Object> annotationAttributes = importMetadata\n\t\t\t\t.getAnnotationAttributes(EnableGlobalMethodSecurity.class.getName());\n\t\tthis.enableMethodSecurity = AnnotationAttributes.fromMap(annotationAttributes);\n\t}", "summary_tokens": ["obtains", "the", "attributes", "from", "enable", "global", "method", "security", "if", "this", "class", "was", "imported", "using", "the", "enable", "global", "method", "security", "annotation"], "project": "spring-security"}
{"id": 1220, "code": "\tpublic OAuth2AccessToken getAccessToken() {\n\t\treturn this.accessToken;\n\t}", "summary_tokens": ["returns", "the", "oauth", "0", "access", "token", "access", "token"], "project": "spring-security"}
{"id": 816, "code": "\tpublic void setTrustResolver(AuthenticationTrustResolver trustResolver) {\n\t\tAssert.notNull(trustResolver, \"trustResolver cannot be null\");\n\t\tthis.trustResolver = trustResolver;\n\t}", "summary_tokens": ["sets", "the", "authentication", "trust", "resolver", "to", "be", "used"], "project": "spring-security"}
{"id": 997, "code": "\tpublic void setClockSkew(Duration clockSkew) {\n\t\tAssert.notNull(clockSkew, \"clockSkew cannot be null\");\n\t\tAssert.isTrue(clockSkew.getSeconds() >= 0, \"clockSkew must be >= 0\");\n\t\tthis.clockSkew = clockSkew;\n\t}", "summary_tokens": ["sets", "the", "maximum", "acceptable", "clock", "skew", "which", "is", "used", "when", "checking", "the", "oauth", "0", "authorized", "client", "get", "access", "token", "access", "token", "expiry"], "project": "spring-security"}
{"id": 1276, "code": "\tdefault Boolean getEmailVerified() {\n\t\treturn this.getClaimAsBoolean(StandardClaimNames.EMAIL_VERIFIED);\n\t}", "summary_tokens": ["returns", "true", "if", "the", "user", "s", "e", "mail", "address", "has", "been", "verified", "email", "verified", "otherwise", "false"], "project": "spring-security"}
{"id": 304, "code": "\tpublic RememberMeConfigurer<H> rememberMeServices(RememberMeServices rememberMeServices) {\n\t\tthis.rememberMeServices = rememberMeServices;\n\t\treturn this;\n\t}", "summary_tokens": ["specify", "the", "remember", "me", "services", "to", "use"], "project": "spring-security"}
{"id": 918, "code": "\tpublic AuthorizationDecision check(Supplier<Authentication> authentication, Message<?> message) {\n\t\tif (this.logger.isTraceEnabled()) {\n\t\t\tthis.logger.trace(LogMessage.format(\"Authorizing message\"));\n\t\t}\n\t\tfor (Entry<AuthorizationManager<MessageAuthorizationContext<?>>> mapping : this.mappings) {\n\t\t\tMessageMatcher<?> matcher = mapping.getMessageMatcher();\n\t\t\tMessageAuthorizationContext<?> authorizationContext = authorizationContext(matcher, message);\n\t\t\tif (authorizationContext != null) {\n\t\t\t\tAuthorizationManager<MessageAuthorizationContext<?>> manager = mapping.getEntry();\n\t\t\t\tif (this.logger.isTraceEnabled()) {\n\t\t\t\t\tthis.logger.trace(LogMessage.format(\"Checking authorization on message using %s\", manager));\n\t\t\t\t}\n\t\t\t\treturn manager.check(authentication, authorizationContext);\n\t\t\t}\n\t\t}\n\t\tthis.logger.trace(\"Abstaining since did not find matching MessageMatcher\");\n\t\treturn null;\n\t}", "summary_tokens": ["delegates", "to", "a", "specific", "authorization", "manager", "based", "on", "a", "message", "matcher", "evaluation"], "project": "spring-security"}
{"id": 1080, "code": "\tpublic static Map<String, Converter<Object, ?>> createDefaultClaimTypeConverters() {\n\t\tConverter<Object, ?> booleanConverter = getConverter(TypeDescriptor.valueOf(Boolean.class));\n\t\tConverter<Object, ?> instantConverter = getConverter(TypeDescriptor.valueOf(Instant.class));\n\t\tConverter<Object, ?> urlConverter = getConverter(TypeDescriptor.valueOf(URL.class));\n\t\tConverter<Object, ?> stringConverter = getConverter(TypeDescriptor.valueOf(String.class));\n\t\tConverter<Object, ?> collectionStringConverter = getConverter(\n\t\t\t\tTypeDescriptor.collection(Collection.class, TypeDescriptor.valueOf(String.class)));\n\t\tMap<String, Converter<Object, ?>> converters = new HashMap<>();\n\t\tconverters.put(IdTokenClaimNames.ISS, urlConverter);\n\t\tconverters.put(IdTokenClaimNames.AUD, collectionStringConverter);\n\t\tconverters.put(IdTokenClaimNames.NONCE, stringConverter);\n\t\tconverters.put(IdTokenClaimNames.EXP, instantConverter);\n\t\tconverters.put(IdTokenClaimNames.IAT, instantConverter);\n\t\tconverters.put(IdTokenClaimNames.AUTH_TIME, instantConverter);\n\t\tconverters.put(IdTokenClaimNames.AMR, collectionStringConverter);\n\t\tconverters.put(StandardClaimNames.EMAIL_VERIFIED, booleanConverter);\n\t\tconverters.put(StandardClaimNames.PHONE_NUMBER_VERIFIED, booleanConverter);\n\t\tconverters.put(StandardClaimNames.UPDATED_AT, instantConverter);\n\t\treturn converters;\n\t}", "summary_tokens": ["returns", "the", "default", "converter", "s", "used", "for", "type", "conversion", "of", "claim", "values", "for", "an", "oidc", "id", "token"], "project": "spring-security"}
{"id": 789, "code": "\tpublic String encode(CharSequence rawPass) {\n\t\tbyte[] salt = this.saltGenerator.generateKey();\n\t\treturn encode(rawPass, salt);\n\t}", "summary_tokens": ["calculates", "the", "hash", "of", "password", "and", "salt", "bytes", "if", "supplied", "and", "returns", "a", "base", "0", "encoded", "concatenation", "of", "the", "hash", "and", "salt", "prefixed", "with", "sha", "or", "ssha", "if", "salt", "was", "used"], "project": "spring-security"}
{"id": 1713, "code": "\tprotected UserDetails processAutoLoginCookie(String[] cookieTokens, HttpServletRequest request,\n\t\t\tHttpServletResponse response) {\n\t\tif (cookieTokens.length != 2) {\n\t\t\tthrow new InvalidCookieException(\"Cookie token did not contain \" + 2 + \" tokens, but contained '\"\n\t\t\t\t\t+ Arrays.asList(cookieTokens) + \"'\");\n\t\t}\n\t\tString presentedSeries = cookieTokens[0];\n\t\tString presentedToken = cookieTokens[1];\n\t\tPersistentRememberMeToken token = this.tokenRepository.getTokenForSeries(presentedSeries);\n\t\tif (token == null) {\n\t\t\t\n\t\t\tthrow new RememberMeAuthenticationException(\"No persistent token found for series id: \" + presentedSeries);\n\t\t}\n\t\t\n\t\tif (!presentedToken.equals(token.getTokenValue())) {\n\t\t\t\n\t\t\t\n\t\t\tthis.tokenRepository.removeUserTokens(token.getUsername());\n\t\t\tthrow new CookieTheftException(this.messages.getMessage(\n\t\t\t\t\t\"PersistentTokenBasedRememberMeServices.cookieStolen\",\n\t\t\t\t\t\"Invalid remember-me token (Series/token) mismatch. Implies previous cookie theft attack.\"));\n\t\t}\n\t\tif (token.getDate().getTime() + getTokenValiditySeconds() * 1000L < System.currentTimeMillis()) {\n\t\t\tthrow new RememberMeAuthenticationException(\"Remember-me login has expired\");\n\t\t}\n\t\t\n\t\t\n\t\tthis.logger.debug(LogMessage.format(\"Refreshing persistent login token for user '%s', series '%s'\",\n\t\t\t\ttoken.getUsername(), token.getSeries()));\n\t\tPersistentRememberMeToken newToken = new PersistentRememberMeToken(token.getUsername(), token.getSeries(),\n\t\t\t\tgenerateTokenData(), new Date());\n\t\ttry {\n\t\t\tthis.tokenRepository.updateToken(newToken.getSeries(), newToken.getTokenValue(), newToken.getDate());\n\t\t\taddCookie(newToken, request, response);\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthis.logger.error(\"Failed to update token: \", ex);\n\t\t\tthrow new RememberMeAuthenticationException(\"Autologin failed due to data access problem\");\n\t\t}\n\t\treturn getUserDetailsService().loadUserByUsername(token.getUsername());\n\t}", "summary_tokens": ["locates", "the", "presented", "cookie", "data", "in", "the", "token", "repository", "using", "the", "series", "id"], "project": "spring-security"}
{"id": 197, "code": "\tpublic final boolean isCustomLoginPage() {\n\t\treturn this.customLoginPage;\n\t}", "summary_tokens": ["true", "if", "a", "custom", "login", "page", "has", "been", "specified", "else", "false"], "project": "spring-security"}
{"id": 1426, "code": "\tpublic String getParametersQuery() {\n\t\treturn this.encoder.apply(this.parameters);\n\t}", "summary_tokens": ["get", "an", "encoded", "query", "string", "of", "all", "parameters"], "project": "spring-security"}
{"id": 394, "code": "\tpublic void setResource(Resource resource) {\n\t\tthis.userDetails.setResource(resource);\n\t}", "summary_tokens": ["sets", "a", "resource", "that", "is", "a", "properties", "file", "in", "the", "format", "defined", "in", "user", "details", "resource", "factory", "bean"], "project": "spring-security"}
{"id": 1331, "code": "\tpublic static PublicKeyReactiveJwtDecoderBuilder withPublicKey(RSAPublicKey key) {\n\t\treturn new PublicKeyReactiveJwtDecoderBuilder(key);\n\t}", "summary_tokens": ["use", "the", "given", "public", "key", "to", "validate", "jwts", "key", "the", "public", "key", "to", "use", "a", "public", "key", "reactive", "jwt", "decoder", "builder", "for", "further", "configurations"], "project": "spring-security"}
{"id": 862, "code": "\tpublic int getGraceLoginsRemaining() {\n\t\treturn this.graceLoginsRemaining;\n\t}", "summary_tokens": ["returns", "the", "grace", "logins", "remaining"], "project": "spring-security"}
{"id": 68, "code": "\tprotected <T> T postProcess(T object) {\n\t\treturn (T) this.objectPostProcessor.postProcess(object);\n\t}", "summary_tokens": ["performs", "post", "processing", "of", "an", "object"], "project": "spring-security"}
{"id": 1031, "code": "private int findNoiseLimit(ByteBuffer buffer) {\n    \n  for (int i = buffer.limit() - 2; i >= buffer.position(); i -= 2) {\n    if (Math.abs(buffer.getShort(i)) > silenceThresholdLevel) {\n        \n      return bytesPerFrame * (i / bytesPerFrame) + bytesPerFrame;\n    }\n  }\n  return buffer.position();\n}", "summary_tokens": ["returns", "the", "earliest", "byte", "position", "in", "position", "limit", "of", "buffer", "such", "that", "all", "frames", "from", "the", "byte", "position", "to", "the", "limit", "are", "classified", "as", "silent"], "project": "ExoPlayer"}
{"id": 139, "code": "public static Looper getImaLooper() {\n    \n    \n  return Looper.getMainLooper();\n}", "summary_tokens": ["returns", "the", "looper", "on", "which", "all", "ima", "sdk", "interaction", "must", "occur"], "project": "ExoPlayer"}
{"id": 1309, "code": "public void discardDownstreamTo(long absolutePosition) {\n  if (absolutePosition == C.POSITION_UNSET) {\n    return;\n  }\n  while (absolutePosition >= firstAllocationNode.endPosition) {\n      \n      \n    allocator.release(firstAllocationNode.allocation);\n    firstAllocationNode = firstAllocationNode.clear();\n  }\n  if (readAllocationNode.startPosition < firstAllocationNode.startPosition) {\n      \n      \n    readAllocationNode = firstAllocationNode;\n  }\n}", "summary_tokens": ["advances", "the", "read", "position", "to", "the", "specified", "absolute", "position"], "project": "ExoPlayer"}
{"id": 2017, "code": "public int getIndexOfLaterOrEqualSynchronizationSample(long timeUs) {\n  int startIndex = Util.binarySearchCeil(timestampsUs, timeUs, true, false);\n  for (int i = startIndex; i < timestampsUs.length; i++) {\n    if ((flags[i] & C.BUFFER_FLAG_KEY_FRAME) != 0) {\n      return i;\n    }\n  }\n  return C.INDEX_UNSET;\n}", "summary_tokens": ["returns", "the", "sample", "index", "of", "the", "closest", "synchronization", "sample", "at", "or", "after", "the", "given", "timestamp", "if", "one", "is", "available"], "project": "ExoPlayer"}
{"id": 927, "code": "public long getMeanElapsedTimeMs() {\n  return playbackCount == 0 ? C.TIME_UNSET : getTotalElapsedTimeMs() / playbackCount;\n}", "summary_tokens": ["returns", "the", "mean", "time", "covered", "by", "any", "playback", "state", "per", "playback", "in", "milliseconds", "or", "c", "time", "unset", "if", "no", "playback", "was", "recorded"], "project": "ExoPlayer"}
{"id": 397, "code": "public AudioAttributesV21 getAudioAttributesV21() {\n  if (audioAttributesV21 == null) {\n    audioAttributesV21 = new AudioAttributesV21(this);\n  }\n  return audioAttributesV21;\n}", "summary_tokens": ["returns", "a", "audio", "attributes", "v", "0", "from", "this", "instance"], "project": "ExoPlayer"}
{"id": 134, "code": " static StreamRequest createStreamRequest(Uri uri) {\n  if (!C.SSAI_SCHEME.equals(uri.getScheme()) || !IMA_AUTHORITY.equals(uri.getAuthority())) {\n    throw new IllegalArgumentException(\"Invalid URI scheme or authority.\");\n  }\n  StreamRequest streamRequest;\n    \n  @Nullable String assetKey = uri.getQueryParameter(ASSET_KEY);\n  @Nullable String apiKey = uri.getQueryParameter(API_KEY);\n  @Nullable String contentSourceId = uri.getQueryParameter(CONTENT_SOURCE_ID);\n  @Nullable String videoId = uri.getQueryParameter(VIDEO_ID);\n  if (!TextUtils.isEmpty(assetKey)) {\n    streamRequest = ImaSdkFactory.getInstance().createLiveStreamRequest(assetKey, apiKey);\n  } else {\n    streamRequest =\n        ImaSdkFactory.getInstance()\n            .createVodStreamRequest(checkNotNull(contentSourceId), checkNotNull(videoId), apiKey);\n  }\n  int format = Integer.parseInt(uri.getQueryParameter(FORMAT));\n  if (format == C.CONTENT_TYPE_DASH) {\n    streamRequest.setFormat(StreamFormat.DASH);\n  } else if (format == C.CONTENT_TYPE_HLS) {\n    streamRequest.setFormat(StreamFormat.HLS);\n  } else {\n    throw new IllegalArgumentException(\"Unsupported stream format:\" + format);\n  }\n    \n  @Nullable String adTagParametersValue = uri.getQueryParameter(AD_TAG_PARAMETERS);\n  if (!TextUtils.isEmpty(adTagParametersValue)) {\n    Map<String, String> adTagParameters = new HashMap<>();\n    Uri adTagParametersUri = Uri.parse(adTagParametersValue);\n    for (String paramName : adTagParametersUri.getQueryParameterNames()) {\n      String singleAdTagParameterValue = adTagParametersUri.getQueryParameter(paramName);\n      if (!TextUtils.isEmpty(singleAdTagParameterValue)) {\n        adTagParameters.put(paramName, singleAdTagParameterValue);\n      }\n    }\n    streamRequest.setAdTagParameters(adTagParameters);\n  }\n  @Nullable String manifestSuffix = uri.getQueryParameter(MANIFEST_SUFFIX);\n  if (manifestSuffix != null) {\n    streamRequest.setManifestSuffix(manifestSuffix);\n  }\n  @Nullable String contentUrl = uri.getQueryParameter(CONTENT_URL);\n  if (contentUrl != null) {\n    streamRequest.setContentUrl(contentUrl);\n  }\n  @Nullable String authToken = uri.getQueryParameter(AUTH_TOKEN);\n  if (authToken != null) {\n    streamRequest.setAuthToken(authToken);\n  }\n  @Nullable String streamActivityMonitorId = uri.getQueryParameter(STREAM_ACTIVITY_MONITOR_ID);\n  if (streamActivityMonitorId != null) {\n    streamRequest.setStreamActivityMonitorId(streamActivityMonitorId);\n  }\n  checkState(\n      streamRequest.getFormat() != StreamFormat.DASH\n          || TextUtils.isEmpty(streamRequest.getAssetKey()),\n      \"DASH live streams are not supported yet.\");\n  return streamRequest;\n}", "summary_tokens": ["returns", "the", "corresponding", "stream", "request"], "project": "ExoPlayer"}
{"id": 1472, "code": "protected boolean shouldDropOutputBuffer(long earlyUs, long elapsedRealtimeUs) {\n  return isBufferLate(earlyUs);\n}", "summary_tokens": ["returns", "whether", "the", "buffer", "being", "processed", "should", "be", "dropped"], "project": "ExoPlayer"}
{"id": 805, "code": "static @TunnelingSupport int getTunnelingSupport(@Capabilities int supportFlags) {\n  return supportFlags & TUNNELING_SUPPORT_MASK;\n}", "summary_tokens": ["returns", "the", "tunneling", "support", "from", "the", "combined", "capabilities"], "project": "ExoPlayer"}
{"id": 739, "code": "public boolean removeAfter(MediaPeriodHolder mediaPeriodHolder) {\n  Assertions.checkState(mediaPeriodHolder != null);\n  if (mediaPeriodHolder.equals(loading)) {\n    return false;\n  }\n  boolean removedReading = false;\n  loading = mediaPeriodHolder;\n  while (mediaPeriodHolder.getNext() != null) {\n    mediaPeriodHolder = mediaPeriodHolder.getNext();\n    if (mediaPeriodHolder == reading) {\n      reading = playing;\n      removedReading = true;\n    }\n    mediaPeriodHolder.release();\n    length--;\n  }\n  loading.setNext(null);\n  notifyQueueUpdate();\n  return removedReading;\n}", "summary_tokens": ["removes", "all", "period", "holders", "after", "the", "given", "period", "holder"], "project": "ExoPlayer"}
{"id": 1831, "code": "private static int getSamplingFrequency(ParsableBitArray bitArray) throws ParserException {\n  int samplingFrequency;\n  int frequencyIndex = bitArray.readBits(4);\n  if (frequencyIndex == AUDIO_SPECIFIC_CONFIG_FREQUENCY_INDEX_ARBITRARY) {\n    samplingFrequency = bitArray.readBits(24);\n  } else if (frequencyIndex < 13) {\n    samplingFrequency = AUDIO_SPECIFIC_CONFIG_SAMPLING_RATE_TABLE[frequencyIndex];\n  } else {\n    throw ParserException.createForMalformedContainer( null,  null);\n  }\n  return samplingFrequency;\n}", "summary_tokens": ["returns", "the", "aac", "sampling", "frequency", "or", "extension", "sampling", "frequency", "as", "specified", "in", "0", "0", "0", "table", "0"], "project": "ExoPlayer"}
{"id": 1398, "code": "public void setDataReader(DataReader dataReader, long length) {\n  this.dataReader = dataReader;\n  resourceLength = length;\n  lastSeekPosition = C.POSITION_UNSET;\n}", "summary_tokens": ["sets", "the", "wrapped", "data", "reader"], "project": "ExoPlayer"}
{"id": 2526, "code": "public void setKeepContentOnPlayerReset(boolean keepContentOnPlayerReset) {\n  if (this.keepContentOnPlayerReset != keepContentOnPlayerReset) {\n    this.keepContentOnPlayerReset = keepContentOnPlayerReset;\n    updateForCurrentTrackSelections( false);\n  }\n}", "summary_tokens": ["sets", "whether", "the", "currently", "displayed", "video", "frame", "or", "media", "artwork", "is", "kept", "visible", "when", "the", "player", "is", "reset"], "project": "ExoPlayer"}
{"id": 1165, "code": "private static boolean codecNeedsEosFlushWorkaround(String name) {\n  return (Util.SDK_INT <= 23 && \"OMX.google.vorbis.decoder\".equals(name))\n      || (Util.SDK_INT <= 19\n          && (\"hb2000\".equals(Util.DEVICE) || \"stvm8\".equals(Util.DEVICE))\n          && (\"OMX.amlogic.avc.decoder.awesome\".equals(name)\n              || \"OMX.amlogic.avc.decoder.awesome.secure\".equals(name)));\n}", "summary_tokens": ["returns", "whether", "the", "decoder", "is", "known", "to", "behave", "incorrectly", "if", "flushed", "after", "receiving", "an", "input", "buffer", "with", "media", "codec", "buffer", "flag", "end", "of", "stream", "set"], "project": "ExoPlayer"}
{"id": 358, "code": "public void setDeviceVolume(int volume) {\n  player.setDeviceVolume(volume);\n}", "summary_tokens": ["calls", "player", "set", "device", "volume", "int", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 260, "code": "public void removeMediaItem(int index) {\n  player.removeMediaItem(index);\n}", "summary_tokens": ["calls", "player", "remove", "media", "item", "int", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1175, "code": "public static Pair<Integer, Integer> getCodecProfileAndLevel(Format format) {\n  if (format.codecs == null) {\n    return null;\n  }\n  String[] parts = format.codecs.split(\"\\\\.\");\n    \n  if (MimeTypes.VIDEO_DOLBY_VISION.equals(format.sampleMimeType)) {\n    return getDolbyVisionProfileAndLevel(format.codecs, parts);\n  }\n  switch (parts[0]) {\n    case CODEC_ID_AVC1:\n    case CODEC_ID_AVC2:\n      return getAvcProfileAndLevel(format.codecs, parts);\n    case CODEC_ID_VP09:\n      return getVp9ProfileAndLevel(format.codecs, parts);\n    case CODEC_ID_HEV1:\n    case CODEC_ID_HVC1:\n      return getHevcProfileAndLevel(format.codecs, parts);\n    case CODEC_ID_AV01:\n      return getAv1ProfileAndLevel(format.codecs, parts, format.colorInfo);\n    case CODEC_ID_MP4A:\n      return getAacCodecProfileAndLevel(format.codecs, parts);\n    default:\n      return null;\n  }\n}", "summary_tokens": ["returns", "profile", "and", "level", "as", "defined", "by", "codec", "profile", "level", "corresponding", "to", "the", "codec", "description", "string", "as", "defined", "by", "rfc", "0", "of", "the", "given", "format"], "project": "ExoPlayer"}
{"id": 1422, "code": "protected final void invalidate() {\n  if (listener != null) {\n    listener.onTrackSelectionsInvalidated();\n  }\n}", "summary_tokens": ["calls", "invalidation", "listener", "on", "track", "selections", "invalidated", "to", "invalidate", "all", "previously", "generated", "track", "selections"], "project": "ExoPlayer"}
{"id": 940, "code": "public int getMeanInitialVideoFormatHeight() {\n  return initialVideoFormatHeightCount == 0\n      ? C.LENGTH_UNSET\n      : totalInitialVideoFormatHeight / initialVideoFormatHeightCount;\n}", "summary_tokens": ["returns", "the", "mean", "initial", "video", "format", "height", "in", "pixels", "or", "c", "length", "unset", "if", "no", "video", "format", "data", "is", "available"], "project": "ExoPlayer"}
{"id": 1841, "code": "public static int parseAc4SyncframeSize(byte[] data, int syncword) {\n  if (data.length < 7) {\n    return C.LENGTH_UNSET;\n  }\n  int headerSize = 2; \n  int frameSize = ((data[2] & 0xFF) << 8) | (data[3] & 0xFF);\n  headerSize += 2;\n  if (frameSize == 0xFFFF) {\n    frameSize = ((data[4] & 0xFF) << 16) | ((data[5] & 0xFF) << 8) | (data[6] & 0xFF);\n    headerSize += 3;\n  }\n  if (syncword == AC41_SYNCWORD) {\n    headerSize += 2;\n  }\n  frameSize += headerSize;\n  return frameSize;\n}", "summary_tokens": ["returns", "the", "size", "in", "bytes", "of", "the", "given", "ac", "0", "syncframe"], "project": "ExoPlayer"}
{"id": 1401, "code": "public static MediaFormat toCaptionsMediaFormat(Format format) {\n  MediaFormat mediaFormat = new MediaFormat();\n  mediaFormat.setString(MediaFormat.KEY_MIME, format.sampleMimeType);\n  if (format.accessibilityChannel != Format.NO_VALUE) {\n    mediaFormat.setInteger(MediaFormat.KEY_CAPTION_SERVICE_NUMBER, format.accessibilityChannel);\n  }\n  return mediaFormat;\n}", "summary_tokens": ["returns", "a", "media", "format", "with", "equivalent", "media", "format", "key", "mime", "and", "media", "format", "key", "caption", "service", "number", "to", "the", "given", "format"], "project": "ExoPlayer"}
{"id": 368, "code": "public static ParserException createForManifestWithUnsupportedFeature(\n    @Nullable String message, @Nullable Throwable cause) {\n  return new ParserException(\n      message, cause,  false, C.DATA_TYPE_MANIFEST);\n}", "summary_tokens": ["creates", "a", "new", "instance", "for", "which", "content", "is", "malformed", "is", "false", "and", "data", "type", "is", "c", "data", "type", "manifest"], "project": "ExoPlayer"}
{"id": 762, "code": "public static ListenableFuture<TrackGroupArray> retrieveMetadata(\n    MediaSource.Factory mediaSourceFactory, MediaItem mediaItem) {\n  return retrieveMetadata(mediaSourceFactory, mediaItem, Clock.DEFAULT);\n}", "summary_tokens": ["retrieves", "the", "track", "group", "array", "corresponding", "to", "a", "media", "item"], "project": "ExoPlayer"}
{"id": 2011, "code": "public void initTables(int trunCount, int sampleCount) {\n  this.trunCount = trunCount;\n  this.sampleCount = sampleCount;\n  if (trunLength.length < trunCount) {\n    trunDataPosition = new long[trunCount];\n    trunLength = new int[trunCount];\n  }\n  if (sampleSizeTable.length < sampleCount) {\n      \n      \n    int tableSize = (sampleCount * 125) / 100;\n    sampleSizeTable = new int[tableSize];\n    samplePresentationTimesUs = new long[tableSize];\n    sampleIsSyncFrameTable = new boolean[tableSize];\n    sampleHasSubsampleEncryptionTable = new boolean[tableSize];\n  }\n}", "summary_tokens": ["configures", "the", "fragment", "for", "the", "specified", "number", "of", "samples"], "project": "ExoPlayer"}
{"id": 821, "code": "public int getVolume() {\n  return volume;\n}", "summary_tokens": ["gets", "the", "current", "volume", "for", "the", "current", "audio", "stream"], "project": "ExoPlayer"}
{"id": 449, "code": "public synchronized boolean block(long timeoutMs) throws InterruptedException {\n  if (timeoutMs <= 0) {\n    return isOpen;\n  }\n  long nowMs = clock.elapsedRealtime();\n  long endMs = nowMs + timeoutMs;\n  if (endMs < nowMs) {\n      \n    block();\n  } else {\n    while (!isOpen && nowMs < endMs) {\n      wait(endMs - nowMs);\n      nowMs = clock.elapsedRealtime();\n    }\n  }\n  return isOpen;\n}", "summary_tokens": ["blocks", "until", "the", "condition", "is", "opened", "or", "until", "timeout", "ms", "have", "passed"], "project": "ExoPlayer"}
{"id": 135, "code": "public static FriendlyObstructionPurpose getFriendlyObstructionPurpose(\n    @AdOverlayInfo.Purpose int purpose) {\n  switch (purpose) {\n    case AdOverlayInfo.PURPOSE_CONTROLS:\n      return FriendlyObstructionPurpose.VIDEO_CONTROLS;\n    case AdOverlayInfo.PURPOSE_CLOSE_AD:\n      return FriendlyObstructionPurpose.CLOSE_AD;\n    case AdOverlayInfo.PURPOSE_NOT_VISIBLE:\n      return FriendlyObstructionPurpose.NOT_VISIBLE;\n    case AdOverlayInfo.PURPOSE_OTHER:\n    default:\n      return FriendlyObstructionPurpose.OTHER;\n  }\n}", "summary_tokens": ["returns", "the", "ima", "friendly", "obstruction", "purpose", "corresponding", "to", "the", "given", "ad", "overlay", "info", "purpose"], "project": "ExoPlayer"}
{"id": 534, "code": "public static String normalizeMimeType(String mimeType) {\n  switch (mimeType) {\n    case BASE_TYPE_AUDIO + \"/x-flac\":\n      return AUDIO_FLAC;\n    case BASE_TYPE_AUDIO + \"/mp3\":\n      return AUDIO_MPEG;\n    case BASE_TYPE_AUDIO + \"/x-wav\":\n      return AUDIO_WAV;\n    default:\n      return mimeType;\n  }\n}", "summary_tokens": ["normalizes", "the", "mime", "type", "provided", "so", "that", "equivalent", "mime", "types", "are", "uniquely", "represented"], "project": "ExoPlayer"}
{"id": 1911, "code": "public FlacStreamMetadata copyWithVorbisComments(List<String> vorbisComments) {\n  @Nullable\n  Metadata appendedMetadata =\n      getMetadataCopyWithAppendedEntriesFrom(parseVorbisComments(vorbisComments));\n  return new FlacStreamMetadata(\n      minBlockSizeSamples,\n      maxBlockSizeSamples,\n      minFrameSize,\n      maxFrameSize,\n      sampleRate,\n      channels,\n      bitsPerSample,\n      totalSamples,\n      seekTable,\n      appendedMetadata);\n}", "summary_tokens": ["returns", "a", "copy", "of", "this", "with", "the", "given", "vorbis", "comments", "added", "to", "the", "metadata"], "project": "ExoPlayer"}
{"id": 662, "code": "protected int skipSource(long positionUs) {\n  return Assertions.checkNotNull(stream).skipData(positionUs - streamOffsetUs);\n}", "summary_tokens": ["attempts", "to", "skip", "to", "the", "keyframe", "before", "the", "specified", "position", "or", "to", "the", "end", "of", "the", "stream", "if", "position", "us", "is", "beyond", "it"], "project": "ExoPlayer"}
{"id": 1159, "code": "private boolean bypassRender(long positionUs, long elapsedRealtimeUs)\n    throws ExoPlaybackException {\n\n    \n  checkState(!outputStreamEnded);\n  if (bypassBatchBuffer.hasSamples()) {\n    if (processOutputBuffer(\n        positionUs,\n        elapsedRealtimeUs,\n         null,\n        bypassBatchBuffer.data,\n        outputIndex,\n         0,\n        bypassBatchBuffer.getSampleCount(),\n        bypassBatchBuffer.getFirstSampleTimeUs(),\n        bypassBatchBuffer.isDecodeOnly(),\n        bypassBatchBuffer.isEndOfStream(),\n        outputFormat)) {\n        \n      onProcessedOutputBuffer(bypassBatchBuffer.getLastSampleTimeUs());\n      bypassBatchBuffer.clear();\n    } else {\n        \n      return false;\n    }\n  }\n\n    \n  if (inputStreamEnded) {\n    outputStreamEnded = true;\n    return false;\n  }\n\n  if (bypassSampleBufferPending) {\n    Assertions.checkState(bypassBatchBuffer.append(bypassSampleBuffer));\n    bypassSampleBufferPending = false;\n  }\n\n  if (bypassDrainAndReinitialize) {\n    if (bypassBatchBuffer.hasSamples()) {\n        \n        \n      return true;\n    }\n      \n    disableBypass();\n    bypassDrainAndReinitialize = false;\n    maybeInitCodecOrBypass();\n    if (!bypassEnabled) {\n        \n      return false;\n    }\n  }\n\n    \n  bypassRead();\n\n  if (bypassBatchBuffer.hasSamples()) {\n    bypassBatchBuffer.flip();\n  }\n\n    \n    \n  return bypassBatchBuffer.hasSamples() || inputStreamEnded || bypassDrainAndReinitialize;\n}", "summary_tokens": ["processes", "any", "pending", "batch", "of", "buffers", "without", "using", "a", "decoder", "and", "drains", "a", "new", "batch", "of", "buffers", "from", "the", "source"], "project": "ExoPlayer"}
{"id": 2633, "code": "public View getVideoSurfaceView() {\n  return surfaceView;\n}", "summary_tokens": ["gets", "the", "view", "onto", "which", "video", "is", "rendered"], "project": "ExoPlayer"}
{"id": 1627, "code": "public void selectTracksPreferTrackWithinCapabilitiesOverSelectionFlag() throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format exceededWithSelectionFlagFormat =\n      formatBuilder.setId(\"exceededFormat\").setSelectionFlags(C.SELECTION_FLAG_DEFAULT).build();\n  Format supportedFormat = formatBuilder.setId(\"supportedFormat\").setSelectionFlags(0).build();\n  TrackGroupArray trackGroups = wrapFormats(exceededWithSelectionFlagFormat, supportedFormat);\n\n  Map<String, Integer> mappedCapabilities = new HashMap<>();\n  mappedCapabilities.put(supportedFormat.id, FORMAT_HANDLED);\n  mappedCapabilities.put(exceededWithSelectionFlagFormat.id, FORMAT_EXCEEDS_CAPABILITIES);\n  RendererCapabilities mappedAudioRendererCapabilities =\n      new FakeMappedRendererCapabilities(C.TRACK_TYPE_AUDIO, mappedCapabilities);\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {mappedAudioRendererCapabilities},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, supportedFormat);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "prefer", "tracks", "that", "are", "within", "renderer", "s", "capabilities", "over", "tracks", "that", "have", "c", "selection", "flag", "default", "but", "exceed", "renderer", "s", "capabilities"], "project": "ExoPlayer"}
{"id": 2357, "code": "private static byte[] extractLumaChannelBuffer(Image image, byte[] lumaChannelBuffer) {\n    \n    \n  Image.Plane[] imagePlanes = image.getPlanes();\n  assertThat(imagePlanes).hasLength(DECODED_IMAGE_CHANNEL_COUNT);\n  Image.Plane lumaPlane = imagePlanes[0];\n  int rowStride = lumaPlane.getRowStride();\n  int pixelStride = lumaPlane.getPixelStride();\n  int width = image.getWidth();\n  int height = image.getHeight();\n  ByteBuffer lumaByteBuffer = lumaPlane.getBuffer();\n  for (int y = 0; y < height; y++) {\n    for (int x = 0; x < width; x++) {\n      lumaChannelBuffer[y * width + x] = lumaByteBuffer.get(y * rowStride + x * pixelStride);\n    }\n  }\n  return lumaChannelBuffer;\n}", "summary_tokens": ["extracts", "sets", "and", "returns", "the", "buffer", "of", "the", "luma", "y", "channel", "of", "the", "image"], "project": "ExoPlayer"}
{"id": 2375, "code": "public static ImmutableSet<String> getSupportedVideoMimeTypes() {\n  return checkNotNull(MIME_TYPE_TO_ENCODERS.get()).keySet();\n}", "summary_tokens": ["returns", "a", "list", "of", "video", "mime", "types", "mime", "types", "that", "can", "be", "encoded"], "project": "ExoPlayer"}
{"id": 341, "code": "public long getContentBufferedPosition() {\n  return player.getContentBufferedPosition();\n}", "summary_tokens": ["calls", "player", "get", "content", "buffered", "position", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2674, "code": "public void destroy() {\n  webView.destroy();\n}", "summary_tokens": ["cleans", "up", "internal", "state", "including", "calling", "web", "view", "destroy", "on", "the", "delegate", "view"], "project": "ExoPlayer"}
{"id": 2068, "code": "private void parseAudioMuxElement(ParsableBitArray data) throws ParserException {\n  boolean useSameStreamMux = data.readBit();\n  if (!useSameStreamMux) {\n    streamMuxRead = true;\n    parseStreamMuxConfig(data);\n  } else if (!streamMuxRead) {\n    return; \n  }\n\n  if (audioMuxVersionA == 0) {\n    if (numSubframes != 0) {\n      throw ParserException.createForMalformedContainer( null,  null);\n    }\n    int muxSlotLengthBytes = parsePayloadLengthInfo(data);\n    parsePayloadMux(data, muxSlotLengthBytes);\n    if (otherDataPresent) {\n      data.skipBits((int) otherDataLenBits);\n    }\n  } else {\n      \n    throw ParserException.createForMalformedContainer( null,  null);\n  }\n}", "summary_tokens": ["parses", "an", "audio", "mux", "element", "as", "defined", "in", "0", "0", "0", "section", "0"], "project": "ExoPlayer"}
{"id": 1819, "code": "public final void flip() {\n  if (data != null) {\n    data.flip();\n  }\n  if (supplementalData != null) {\n    supplementalData.flip();\n  }\n}", "summary_tokens": ["flips", "data", "and", "supplemental", "data", "in", "preparation", "for", "being", "queued", "to", "a", "decoder"], "project": "ExoPlayer"}
{"id": 1297, "code": "default void onLoadCanceled(\n    int windowIndex,\n    @Nullable MediaPeriodId mediaPeriodId,\n    LoadEventInfo loadEventInfo,\n    MediaLoadData mediaLoadData) {}", "summary_tokens": ["called", "when", "a", "load", "is", "canceled"], "project": "ExoPlayer"}
{"id": 2444, "code": "private static TransformationRequest createFallbackTransformationRequest(\n    TransformationRequest transformationRequest,\n    boolean hasOutputFormatRotation,\n    Format requestedFormat,\n    Format supportedFormat) {\n    \n    \n  if (Util.areEqual(requestedFormat.sampleMimeType, supportedFormat.sampleMimeType)\n      && (hasOutputFormatRotation\n          ? requestedFormat.width == supportedFormat.width\n          : requestedFormat.height == supportedFormat.height)) {\n    return transformationRequest;\n  }\n  return transformationRequest\n      .buildUpon()\n      .setVideoMimeType(supportedFormat.sampleMimeType)\n      .setResolution(hasOutputFormatRotation ? requestedFormat.width : requestedFormat.height)\n      .build();\n}", "summary_tokens": ["creates", "a", "fallback", "transformation", "request", "to", "execute", "based", "on", "device", "specific", "support"], "project": "ExoPlayer"}
{"id": 1898, "code": "public static Metadata readId3Metadata(ExtractorInput input, boolean parseData)\n    throws IOException {\n  input.resetPeekPosition();\n  long startingPeekPosition = input.getPeekPosition();\n  @Nullable Metadata id3Metadata = peekId3Metadata(input, parseData);\n  int peekedId3Bytes = (int) (input.getPeekPosition() - startingPeekPosition);\n  input.skipFully(peekedId3Bytes);\n  return id3Metadata;\n}", "summary_tokens": ["reads", "id", "0", "data"], "project": "ExoPlayer"}
{"id": 2193, "code": "public static HevcConfig parse(ParsableByteArray data) throws ParserException {\n  try {\n    data.skipBytes(21); \n    int lengthSizeMinusOne = data.readUnsignedByte() & 0x03;\n\n      \n    int numberOfArrays = data.readUnsignedByte();\n    int csdLength = 0;\n    int csdStartPosition = data.getPosition();\n    for (int i = 0; i < numberOfArrays; i++) {\n      data.skipBytes(1); \n      int numberOfNalUnits = data.readUnsignedShort();\n      for (int j = 0; j < numberOfNalUnits; j++) {\n        int nalUnitLength = data.readUnsignedShort();\n        csdLength += 4 + nalUnitLength; \n        data.skipBytes(nalUnitLength);\n      }\n    }\n\n      \n    data.setPosition(csdStartPosition);\n    byte[] buffer = new byte[csdLength];\n    int bufferPosition = 0;\n    int width = Format.NO_VALUE;\n    int height = Format.NO_VALUE;\n    float pixelWidthHeightRatio = 1;\n    @Nullable String codecs = null;\n    for (int i = 0; i < numberOfArrays; i++) {\n      int nalUnitType = data.readUnsignedByte() & 0x7F; \n      int numberOfNalUnits = data.readUnsignedShort();\n      for (int j = 0; j < numberOfNalUnits; j++) {\n        int nalUnitLength = data.readUnsignedShort();\n        System.arraycopy(\n            NalUnitUtil.NAL_START_CODE,\n            0,\n            buffer,\n            bufferPosition,\n            NalUnitUtil.NAL_START_CODE.length);\n        bufferPosition += NalUnitUtil.NAL_START_CODE.length;\n        System.arraycopy(\n            data.getData(), data.getPosition(), buffer, bufferPosition, nalUnitLength);\n        if (nalUnitType == SPS_NAL_UNIT_TYPE && j == 0) {\n          NalUnitUtil.H265SpsData spsData =\n              NalUnitUtil.parseH265SpsNalUnit(\n                  buffer, bufferPosition, bufferPosition + nalUnitLength);\n          width = spsData.width;\n          height = spsData.height;\n          pixelWidthHeightRatio = spsData.pixelWidthHeightRatio;\n          codecs =\n              CodecSpecificDataUtil.buildHevcCodecString(\n                  spsData.generalProfileSpace,\n                  spsData.generalTierFlag,\n                  spsData.generalProfileIdc,\n                  spsData.generalProfileCompatibilityFlags,\n                  spsData.constraintBytes,\n                  spsData.generalLevelIdc);\n        }\n        bufferPosition += nalUnitLength;\n        data.skipBytes(nalUnitLength);\n      }\n    }\n\n    List<byte[]> initializationData =\n        csdLength == 0 ? Collections.emptyList() : Collections.singletonList(buffer);\n    return new HevcConfig(\n        initializationData, lengthSizeMinusOne + 1, width, height, pixelWidthHeightRatio, codecs);\n  } catch (ArrayIndexOutOfBoundsException e) {\n    throw ParserException.createForMalformedContainer(\"Error parsing HEVC config\", e);\n  }\n}", "summary_tokens": ["parses", "hevc", "configuration", "data"], "project": "ExoPlayer"}
{"id": 834, "code": "default void onPlaybackSuppressionReasonChanged(\n    EventTime eventTime, @PlaybackSuppressionReason int playbackSuppressionReason) {}", "summary_tokens": ["called", "when", "playback", "suppression", "reason", "changed"], "project": "ExoPlayer"}
{"id": 1067, "code": "public static @PlaybackException.ErrorCode int getErrorCodeForMediaDrmException(\n    Exception exception, @ErrorSource int errorSource) {\n  if (Util.SDK_INT >= 21 && Api21.isMediaDrmStateException(exception)) {\n    return Api21.mediaDrmStateExceptionToErrorCode(exception);\n  } else if (Util.SDK_INT >= 23 && Api23.isMediaDrmResetException(exception)) {\n    return PlaybackException.ERROR_CODE_DRM_SYSTEM_ERROR;\n  } else if (Util.SDK_INT >= 18 && Api18.isNotProvisionedException(exception)) {\n    return PlaybackException.ERROR_CODE_DRM_PROVISIONING_FAILED;\n  } else if (Util.SDK_INT >= 18 && Api18.isDeniedByServerException(exception)) {\n    return PlaybackException.ERROR_CODE_DRM_DEVICE_REVOKED;\n  } else if (exception instanceof UnsupportedDrmException) {\n    return PlaybackException.ERROR_CODE_DRM_SCHEME_UNSUPPORTED;\n  } else if (exception instanceof DefaultDrmSessionManager.MissingSchemeDataException) {\n    return PlaybackException.ERROR_CODE_DRM_CONTENT_ERROR;\n  } else if (exception instanceof KeysExpiredException) {\n    return PlaybackException.ERROR_CODE_DRM_LICENSE_EXPIRED;\n  } else if (errorSource == ERROR_SOURCE_EXO_MEDIA_DRM) {\n      \n      \n    return PlaybackException.ERROR_CODE_DRM_SYSTEM_ERROR;\n  } else if (errorSource == ERROR_SOURCE_LICENSE_ACQUISITION) {\n    return PlaybackException.ERROR_CODE_DRM_LICENSE_ACQUISITION_FAILED;\n  } else if (errorSource == ERROR_SOURCE_PROVISIONING) {\n    return PlaybackException.ERROR_CODE_DRM_PROVISIONING_FAILED;\n  } else {\n      \n    throw new IllegalArgumentException();\n  }\n}", "summary_tokens": ["returns", "the", "playback", "exception"], "project": "ExoPlayer"}
{"id": 1481, "code": "protected DecoderReuseEvaluation canReuseDecoder(\n    String decoderName, Format oldFormat, Format newFormat) {\n  return new DecoderReuseEvaluation(\n      decoderName, oldFormat, newFormat, REUSE_RESULT_NO, DISCARD_REASON_REUSE_NOT_IMPLEMENTED);\n}", "summary_tokens": ["evaluates", "whether", "the", "existing", "decoder", "can", "be", "reused", "for", "a", "new", "format"], "project": "ExoPlayer"}
{"id": 116, "code": "public void skipAd() {\n  if (currentAdTagLoader != null) {\n    currentAdTagLoader.skipAd();\n  }\n}", "summary_tokens": ["skips", "the", "current", "ad"], "project": "ExoPlayer"}
{"id": 2286, "code": "public void close() throws IOException {\n    \n    \n  if (closed) {\n    return;\n  }\n  try {\n    if (sender != null) {\n      sender.close();\n    }\n    receiverLoader.release();\n\n    if (socket != null) {\n      socket.close();\n    }\n  } finally {\n    closed = true;\n  }\n}", "summary_tokens": ["closes", "the", "rtsp", "message", "channel"], "project": "ExoPlayer"}
{"id": 2703, "code": "public ExoPlayerTestRunner blockUntilEnded(long timeoutMs) throws Exception {\n  clock.onThreadBlocked();\n  if (!endedCountDownLatch.await(timeoutMs, MILLISECONDS)) {\n    exception = new TimeoutException(\"Test playback timed out waiting for playback to end.\");\n  }\n  release();\n    \n  if (exception != null) {\n    throw exception;\n  }\n  return this;\n}", "summary_tokens": ["blocks", "the", "current", "thread", "until", "the", "test", "runner", "finishes"], "project": "ExoPlayer"}
{"id": 1326, "code": "public final void discardUpstreamFrom(long timeUs) {\n  if (length == 0) {\n    return;\n  }\n  checkArgument(timeUs > getLargestReadTimestampUs());\n  int retainCount = countUnreadSamplesBefore(timeUs);\n  discardUpstreamSamples(absoluteFirstIndex + retainCount);\n}", "summary_tokens": ["discards", "samples", "from", "the", "write", "side", "of", "the", "queue"], "project": "ExoPlayer"}
{"id": 2221, "code": "public byte[] remove(Uri uri) {\n  return backingMap.remove(Assertions.checkNotNull(uri));\n}", "summary_tokens": ["removes", "uri", "from", "the", "cache"], "project": "ExoPlayer"}
{"id": 602, "code": "public final void blockUntilStarted() {\n  started.blockUninterruptible();\n}", "summary_tokens": ["blocks", "until", "the", "task", "has", "started", "or", "has", "been", "canceled", "without", "having", "been", "started"], "project": "ExoPlayer"}
{"id": 760, "code": "private static Object getMediaSourceHolderUid(Object periodUid) {\n  return PlaylistTimeline.getChildTimelineUidFromConcatenatedUid(periodUid);\n}", "summary_tokens": ["return", "uid", "of", "media", "source", "holder", "from", "period", "uid", "of", "concatenated", "source"], "project": "ExoPlayer"}
{"id": 1770, "code": "static long getContentLength(ContentMetadata contentMetadata) {\n  return contentMetadata.get(KEY_CONTENT_LENGTH, C.LENGTH_UNSET);\n}", "summary_tokens": ["returns", "the", "value", "stored", "under", "key", "content", "length", "or", "c", "length", "unset", "if", "not", "set"], "project": "ExoPlayer"}
{"id": 418, "code": "public static void checkState(boolean expression, Object errorMessage) {\n  if (ExoPlayerLibraryInfo.ASSERTIONS_ENABLED && !expression) {\n    throw new IllegalStateException(String.valueOf(errorMessage));\n  }\n}", "summary_tokens": ["throws", "illegal", "state", "exception", "if", "expression", "evaluates", "to", "false"], "project": "ExoPlayer"}
{"id": 2335, "code": "public static RtspResponse newDescribeResponseWithSdpMessage(\n    String sessionDescription, List<RtpPacketStreamDump> rtpPacketStreamDumps, Uri requestedUri) {\n\n  StringBuilder sdpMessageBuilder = new StringBuilder(sessionDescription);\n  for (RtpPacketStreamDump rtpPacketStreamDump : rtpPacketStreamDumps) {\n    sdpMessageBuilder.append(rtpPacketStreamDump.mediaDescription).append(\"\\r\\n\");\n  }\n  String sdpMessage = sdpMessageBuilder.toString();\n\n  return new RtspResponse(\n      200,\n      new RtspHeaders.Builder()\n          .add(RtspHeaders.CONTENT_BASE, requestedUri.toString())\n          .add(\n              RtspHeaders.CONTENT_LENGTH,\n              String.valueOf(sdpMessage.getBytes(RtspMessageChannel.CHARSET).length))\n          .build(),\n       sdpMessage);\n}", "summary_tokens": ["returns", "an", "rtsp", "response", "with", "a", "sdp", "message", "body"], "project": "ExoPlayer"}
{"id": 2063, "code": "private boolean skipToNextSync(ParsableByteArray pesBuffer) {\n  while (pesBuffer.bytesLeft() > 0) {\n    syncBytes <<= 8;\n    syncBytes |= pesBuffer.readUnsignedByte();\n    if (DtsUtil.isSyncWord(syncBytes)) {\n      byte[] headerData = headerScratchBytes.getData();\n      headerData[0] = (byte) ((syncBytes >> 24) & 0xFF);\n      headerData[1] = (byte) ((syncBytes >> 16) & 0xFF);\n      headerData[2] = (byte) ((syncBytes >> 8) & 0xFF);\n      headerData[3] = (byte) (syncBytes & 0xFF);\n      bytesRead = 4;\n      syncBytes = 0;\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["locates", "the", "next", "sync", "value", "in", "the", "buffer", "advancing", "the", "position", "to", "the", "byte", "that", "immediately", "follows", "it"], "project": "ExoPlayer"}
{"id": 1289, "code": "public void setMediaSource(MediaSource mediaSource) {\n  checkState(this.mediaSource == null);\n  this.mediaSource = mediaSource;\n}", "summary_tokens": ["sets", "the", "media", "source", "that", "will", "create", "the", "underlying", "media", "period"], "project": "ExoPlayer"}
{"id": 713, "code": "public TrackSelectorResult selectTracks(float playbackSpeed, Timeline timeline)\n    throws ExoPlaybackException {\n  TrackSelectorResult selectorResult =\n      trackSelector.selectTracks(rendererCapabilities, getTrackGroups(), info.id, timeline);\n  for (ExoTrackSelection trackSelection : selectorResult.selections) {\n    if (trackSelection != null) {\n      trackSelection.onPlaybackSpeed(playbackSpeed);\n    }\n  }\n  return selectorResult;\n}", "summary_tokens": ["selects", "tracks", "for", "the", "period"], "project": "ExoPlayer"}
{"id": 181, "code": "public void setDispatchUnsupportedActionsEnabled(boolean dispatchUnsupportedActionsEnabled) {\n  this.dispatchUnsupportedActionsEnabled = dispatchUnsupportedActionsEnabled;\n}", "summary_tokens": ["sets", "whether", "actions", "that", "are", "not", "advertised", "to", "the", "media", "session", "compat", "will", "be", "dispatched", "either", "way"], "project": "ExoPlayer"}
{"id": 1231, "code": "public static void sendResumeDownloads(\n    Context context, Class<? extends DownloadService> clazz, boolean foreground) {\n  Intent intent = buildResumeDownloadsIntent(context, clazz, foreground);\n  startService(context, intent, foreground);\n}", "summary_tokens": ["starts", "the", "service", "if", "not", "started", "already", "and", "resumes", "all", "downloads"], "project": "ExoPlayer"}
{"id": 1655, "code": "private static Parameters buildParametersForEqualsTest() {\n  return Parameters.DEFAULT_WITHOUT_CONTEXT\n      .buildUpon()\n        \n      .setMaxVideoSize( 0,  1)\n      .setMaxVideoFrameRate(2)\n      .setMaxVideoBitrate(3)\n      .setMinVideoSize( 4,  5)\n      .setMinVideoFrameRate(6)\n      .setMinVideoBitrate(7)\n      .setExceedVideoConstraintsIfNecessary(false)\n      .setAllowVideoMixedMimeTypeAdaptiveness(true)\n      .setAllowVideoNonSeamlessAdaptiveness(false)\n      .setAllowVideoMixedDecoderSupportAdaptiveness(true)\n      .setViewportSize(\n           8,\n           9,\n           true)\n      .setPreferredVideoMimeTypes(MimeTypes.VIDEO_AV1, MimeTypes.VIDEO_H264)\n        \n      .setPreferredAudioLanguages(\"zh\", \"jp\")\n      .setPreferredAudioRoleFlags(C.ROLE_FLAG_COMMENTARY)\n      .setMaxAudioChannelCount(10)\n      .setMaxAudioBitrate(11)\n      .setExceedAudioConstraintsIfNecessary(false)\n      .setAllowAudioMixedMimeTypeAdaptiveness(true)\n      .setAllowAudioMixedSampleRateAdaptiveness(false)\n      .setAllowAudioMixedChannelCountAdaptiveness(true)\n      .setAllowAudioMixedDecoderSupportAdaptiveness(false)\n      .setPreferredAudioMimeTypes(MimeTypes.AUDIO_AC3, MimeTypes.AUDIO_E_AC3)\n      .setConstrainAudioChannelCountToDeviceCapabilities(false)\n        \n      .setPreferredTextLanguages(\"de\", \"en\")\n      .setPreferredTextRoleFlags(C.ROLE_FLAG_CAPTION)\n      .setSelectUndeterminedTextLanguage(true)\n      .setIgnoredTextSelectionFlags(C.SELECTION_FLAG_AUTOSELECT)\n        \n      .setForceLowestBitrate(false)\n      .setForceHighestSupportedBitrate(true)\n      .setExceedRendererCapabilitiesIfNecessary(false)\n      .setTunnelingEnabled(true)\n      .setAllowMultipleAdaptiveSelections(true)\n      .setSelectionOverride(\n           2,\n          new TrackGroupArray(VIDEO_TRACK_GROUP),\n          new SelectionOverride(0, 1))\n      .setSelectionOverride(\n           2, new TrackGroupArray(AUDIO_TRACK_GROUP),  null)\n      .setSelectionOverride(\n           5, new TrackGroupArray(VIDEO_TRACK_GROUP),  null)\n      .setRendererDisabled(1, true)\n      .setRendererDisabled(3, true)\n      .setRendererDisabled(5, false)\n      .setOverrideForType(\n          new TrackSelectionOverride(\n              new TrackGroup(AUDIO_FORMAT, AUDIO_FORMAT, AUDIO_FORMAT, AUDIO_FORMAT),\n               ImmutableList.of(0, 2, 3)))\n      .setDisabledTrackTypes(ImmutableSet.of(C.TRACK_TYPE_AUDIO))\n      .build();\n}", "summary_tokens": ["returns", "parameters", "suitable", "for", "simple", "round", "trip", "equality", "tests"], "project": "ExoPlayer"}
{"id": 1720, "code": "public static void closeQuietly(@Nullable DataSource dataSource) {\n  try {\n    if (dataSource != null) {\n      dataSource.close();\n    }\n  } catch (IOException e) {\n      \n  }\n}", "summary_tokens": ["closes", "a", "data", "source", "suppressing", "any", "ioexception", "that", "may", "occur"], "project": "ExoPlayer"}
{"id": 697, "code": "private int initializeKeepSessionIdAudioTrack(int audioSessionId) {\n  if (keepSessionIdAudioTrack != null\n      && keepSessionIdAudioTrack.getAudioSessionId() != audioSessionId) {\n    keepSessionIdAudioTrack.release();\n    keepSessionIdAudioTrack = null;\n  }\n  if (keepSessionIdAudioTrack == null) {\n    int sampleRate = 4000; \n    int channelConfig = AudioFormat.CHANNEL_OUT_MONO;\n    @C.PcmEncoding int encoding = C.ENCODING_PCM_16BIT;\n    int bufferSize = 2; \n    keepSessionIdAudioTrack =\n        new AudioTrack(\n            C.STREAM_TYPE_DEFAULT,\n            sampleRate,\n            channelConfig,\n            encoding,\n            bufferSize,\n            AudioTrack.MODE_STATIC,\n            audioSessionId);\n  }\n  return keepSessionIdAudioTrack.getAudioSessionId();\n}", "summary_tokens": ["initializes", "keep", "session", "id", "audio", "track", "to", "keep", "an", "audio", "session", "id", "alive"], "project": "ExoPlayer"}
{"id": 922, "code": "public long getTotalWaitTimeMs() {\n  return getPlaybackStateDurationMs(PLAYBACK_STATE_JOINING_FOREGROUND)\n      + getPlaybackStateDurationMs(PLAYBACK_STATE_BUFFERING)\n      + getPlaybackStateDurationMs(PLAYBACK_STATE_SEEKING);\n}", "summary_tokens": ["returns", "the", "total", "time", "spent", "actively", "waiting", "for", "playback", "in", "milliseconds"], "project": "ExoPlayer"}
{"id": 1677, "code": "private void maybeNotifyDashManifestRefreshNeeded() {\n  if (!chunkLoadedCompletedSinceLastManifestRefreshRequest) {\n      \n    return;\n  }\n  isWaitingForManifestRefresh = true;\n  chunkLoadedCompletedSinceLastManifestRefreshRequest = false;\n  playerEmsgCallback.onDashManifestRefreshRequested();\n}", "summary_tokens": ["requests", "dash", "media", "manifest", "to", "be", "refreshed", "if", "necessary"], "project": "ExoPlayer"}
{"id": 2755, "code": "public long getLargestQueuedTimestampUs() {\n  return sampleQueue.getLargestQueuedTimestampUs();\n}", "summary_tokens": ["returns", "the", "timestamp", "of", "the", "largest", "queued", "sample", "in", "the", "queue", "or", "long", "min", "value", "if", "no", "samples", "are", "queued"], "project": "ExoPlayer"}
{"id": 949, "code": "public float getFatalErrorRatio() {\n  return foregroundPlaybackCount == 0\n      ? 0f\n      : (float) fatalErrorPlaybackCount / foregroundPlaybackCount;\n}", "summary_tokens": ["returns", "the", "ratio", "of", "foreground", "playbacks", "which", "experienced", "fatal", "errors", "or", "0"], "project": "ExoPlayer"}
{"id": 1408, "code": "default void onPlayWhenReadyChanged(boolean playWhenReady) {}", "summary_tokens": ["called", "to", "notify", "when", "the", "playback", "is", "paused", "or", "resumed"], "project": "ExoPlayer"}
{"id": 2746, "code": "protected void releaseMediaPeriod(MediaPeriod mediaPeriod) {\n  ((FakeMediaPeriod) mediaPeriod).release();\n}", "summary_tokens": ["releases", "a", "media", "period", "created", "by", "create", "media", "period", "media", "period", "id", "track", "group", "array", "allocator", "media", "source", "event", "listener"], "project": "ExoPlayer"}
{"id": 306, "code": "public Tracks getCurrentTracks() {\n  return player.getCurrentTracks();\n}", "summary_tokens": ["calls", "player", "get", "current", "tracks", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2077, "code": "public boolean endNalUnit(int discardPadding) {\n  if (!isFilling) {\n    return false;\n  }\n  nalLength -= discardPadding;\n  isFilling = false;\n  isCompleted = true;\n  return true;\n}", "summary_tokens": ["called", "to", "indicate", "that", "a", "nal", "unit", "has", "ended"], "project": "ExoPlayer"}
{"id": 1566, "code": "private static ByteBuffer createDefaultSilenceBuffer() {\n  return ByteBuffer.allocateDirect(\n          SAMPLE_RATE_44_1 * CHANNEL_COUNT_STEREO * BYTES_PER_FRAME_16_BIT)\n      .order(ByteOrder.nativeOrder());\n}", "summary_tokens": ["creates", "a", "one", "second", "silence", "buffer", "for", "0"], "project": "ExoPlayer"}
{"id": 622, "code": "public static boolean isEndTag(XmlPullParser xpp) throws XmlPullParserException {\n  return xpp.getEventType() == XmlPullParser.END_TAG;\n}", "summary_tokens": ["returns", "whether", "the", "current", "event", "is", "an", "end", "tag"], "project": "ExoPlayer"}
{"id": 2432, "code": " long getCurrentFrameOutputTimeUs(long inputTimeUs) {\n  long outputTimeUs = inputTimeUs + frameTimeDeltaUs;\n  if (currentSegmentInfo != null) {\n    outputTimeUs +=\n        (inputTimeUs - currentSegmentInfo.startTimeUs) * (currentSegmentInfo.speedDivisor - 1);\n  }\n  return Math.round(outputTimeUs * INPUT_FRAME_RATE / captureFrameRate);\n}", "summary_tokens": ["returns", "the", "time", "of", "the", "current", "frame", "in", "the", "output", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 613, "code": "public static long usToNonWrappedPts(long us) {\n  return (us * 90000) / C.MICROS_PER_SECOND;\n}", "summary_tokens": ["converts", "a", "timestamp", "in", "microseconds", "to", "a", "0", "k", "hz", "clock", "timestamp"], "project": "ExoPlayer"}
{"id": 1573, "code": "public void addDownloadWithStopReason_whilstRemoving_addsStoppedDownload() throws Throwable {\n  postDownloadRequest(ID1);\n  getDownloaderAt(0).finish();\n  assertCompleted(ID1);\n\n  postRemoveRequest(ID1);\n  FakeDownloader downloadRemover = getDownloaderAt(1);\n  downloadRemover.assertRemoveStarted();\n\n    \n  runOnMainThread(\n      () -> downloadManager.addDownload(createDownloadRequest(ID1),  1234));\n\n  downloadRemover.finish();\n  downloadManagerListener.blockUntilIdle();\n\n  assertDownloadIndexSize(1);\n    \n    \n  assertDownloaderCount(2);\n    \n  assertCurrentDownloadCount(1);\n\n  List<Download> downloads = postGetCurrentDownloads();\n  Download download = downloads.get(0);\n  assertThat(download.request.id).isEqualTo(ID1);\n  assertThat(download.state).isEqualTo(Download.STATE_STOPPED);\n  assertThat(download.stopReason).isEqualTo(1234);\n}", "summary_tokens": ["test", "for", "https", "github"], "project": "ExoPlayer"}
{"id": 1856, "code": "public int handlePendingSeek(ExtractorInput input, PositionHolder seekPositionHolder)\n    throws IOException {\n  while (true) {\n    SeekOperationParams seekOperationParams =\n        Assertions.checkStateNotNull(this.seekOperationParams);\n    long floorPosition = seekOperationParams.getFloorBytePosition();\n    long ceilingPosition = seekOperationParams.getCeilingBytePosition();\n    long searchPosition = seekOperationParams.getNextSearchBytePosition();\n\n    if (ceilingPosition - floorPosition <= minimumSearchRange) {\n        \n      markSeekOperationFinished( false, floorPosition);\n      return seekToPosition(input, floorPosition, seekPositionHolder);\n    }\n    if (!skipInputUntilPosition(input, searchPosition)) {\n      return seekToPosition(input, searchPosition, seekPositionHolder);\n    }\n\n    input.resetPeekPosition();\n    TimestampSearchResult timestampSearchResult =\n        timestampSeeker.searchForTimestamp(input, seekOperationParams.getTargetTimePosition());\n\n    switch (timestampSearchResult.type) {\n      case TimestampSearchResult.TYPE_POSITION_OVERESTIMATED:\n        seekOperationParams.updateSeekCeiling(\n            timestampSearchResult.timestampToUpdate, timestampSearchResult.bytePositionToUpdate);\n        break;\n      case TimestampSearchResult.TYPE_POSITION_UNDERESTIMATED:\n        seekOperationParams.updateSeekFloor(\n            timestampSearchResult.timestampToUpdate, timestampSearchResult.bytePositionToUpdate);\n        break;\n      case TimestampSearchResult.TYPE_TARGET_TIMESTAMP_FOUND:\n        skipInputUntilPosition(input, timestampSearchResult.bytePositionToUpdate);\n        markSeekOperationFinished(\n             true, timestampSearchResult.bytePositionToUpdate);\n        return seekToPosition(\n            input, timestampSearchResult.bytePositionToUpdate, seekPositionHolder);\n      case TimestampSearchResult.TYPE_NO_TIMESTAMP:\n          \n          \n        markSeekOperationFinished( false, searchPosition);\n        return seekToPosition(input, searchPosition, seekPositionHolder);\n      default:\n        throw new IllegalStateException(\"Invalid case\");\n    }\n  }\n}", "summary_tokens": ["continues", "to", "handle", "the", "pending", "seek", "operation"], "project": "ExoPlayer"}
{"id": 2518, "code": "public @ResizeMode int getResizeMode() {\n  Assertions.checkStateNotNull(contentFrame);\n  return contentFrame.getResizeMode();\n}", "summary_tokens": ["returns", "the", "resize", "mode"], "project": "ExoPlayer"}
{"id": 2101, "code": "public Id3Frame getSubFrame(int index) {\n  return subFrames[index];\n}", "summary_tokens": ["returns", "the", "sub", "frame", "at", "index"], "project": "ExoPlayer"}
{"id": 1605, "code": "public void selectTracks_withEmptyTrackOverrideForDifferentTracks_hasNoEffect()\n    throws ExoPlaybackException {\n  TrackGroup videoGroup0 = VIDEO_TRACK_GROUP.copyWithId(\"0\");\n  TrackGroup videoGroup1 = VIDEO_TRACK_GROUP.copyWithId(\"1\");\n  trackSelector.setParameters(\n      trackSelector\n          .buildUponParameters()\n          .setOverrideForType(\n              new TrackSelectionOverride(\n                  new TrackGroup(VIDEO_FORMAT, VIDEO_FORMAT), ImmutableList.of()))\n          .build());\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          RENDERER_CAPABILITIES,\n          new TrackGroupArray(videoGroup0, AUDIO_TRACK_GROUP, videoGroup1),\n          periodId,\n          TIMELINE);\n\n  assertThat(result.selections)\n      .asList()\n      .containsExactly(\n          new FixedTrackSelection(videoGroup0,  0),\n          new FixedTrackSelection(AUDIO_TRACK_GROUP,  0))\n      .inOrder();\n  assertThat(result.rendererConfigurations)\n      .isEqualTo(new RendererConfiguration[] {DEFAULT, DEFAULT});\n}", "summary_tokens": ["tests", "that", "an", "empty", "override", "is", "not", "applied", "for", "a", "different", "set", "of", "available", "track", "groups"], "project": "ExoPlayer"}
{"id": 1423, "code": "protected final BandwidthMeter getBandwidthMeter() {\n  return checkStateNotNull(bandwidthMeter);\n}", "summary_tokens": ["returns", "a", "bandwidth", "meter", "which", "can", "be", "used", "by", "track", "selections", "to", "select", "tracks"], "project": "ExoPlayer"}
{"id": 1492, "code": "protected void onQueueInputBuffer(DecoderInputBuffer buffer) throws ExoPlaybackException {\n    \n    \n  if (!tunneling) {\n    buffersInCodecCount++;\n  }\n  if (Util.SDK_INT < 23 && tunneling) {\n      \n      \n    onProcessedTunneledBuffer(buffer.timeUs);\n  }\n}", "summary_tokens": ["called", "immediately", "before", "an", "input", "buffer", "is", "queued", "into", "the", "codec"], "project": "ExoPlayer"}
{"id": 932, "code": "public float getMeanSeekCount() {\n  return foregroundPlaybackCount == 0 ? 0f : (float) totalSeekCount / foregroundPlaybackCount;\n}", "summary_tokens": ["returns", "the", "mean", "number", "of", "times", "a", "seek", "occurred", "per", "foreground", "playback", "or", "0"], "project": "ExoPlayer"}
{"id": 2468, "code": "public void setShowMultiWindowTimeBar(boolean showMultiWindowTimeBar) {\n  this.showMultiWindowTimeBar = showMultiWindowTimeBar;\n  updateTimeline();\n}", "summary_tokens": ["sets", "whether", "the", "time", "bar", "should", "show", "all", "windows", "as", "opposed", "to", "just", "the", "current", "one"], "project": "ExoPlayer"}
{"id": 844, "code": "default void onMaxSeekToPreviousPositionChanged(\n    EventTime eventTime, long maxSeekToPreviousPositionMs) {}", "summary_tokens": ["called", "when", "the", "maximum", "position", "for", "which", "player", "seek", "to", "previous", "seeks", "to", "the", "previous", "window", "changes"], "project": "ExoPlayer"}
{"id": 2640, "code": "private static void applyTextureViewRotation(TextureView textureView, int textureViewRotation) {\n  Matrix transformMatrix = new Matrix();\n  float textureViewWidth = textureView.getWidth();\n  float textureViewHeight = textureView.getHeight();\n  if (textureViewWidth != 0 && textureViewHeight != 0 && textureViewRotation != 0) {\n    float pivotX = textureViewWidth / 2;\n    float pivotY = textureViewHeight / 2;\n    transformMatrix.postRotate(textureViewRotation, pivotX, pivotY);\n\n      \n    RectF originalTextureRect = new RectF(0, 0, textureViewWidth, textureViewHeight);\n    RectF rotatedTextureRect = new RectF();\n    transformMatrix.mapRect(rotatedTextureRect, originalTextureRect);\n    transformMatrix.postScale(\n        textureViewWidth / rotatedTextureRect.width(),\n        textureViewHeight / rotatedTextureRect.height(),\n        pivotX,\n        pivotY);\n  }\n  textureView.setTransform(transformMatrix);\n}", "summary_tokens": ["applies", "a", "texture", "rotation", "to", "a", "texture", "view"], "project": "ExoPlayer"}
{"id": 1114, "code": "public Point alignVideoSizeV21(int width, int height) {\n  if (capabilities == null) {\n    return null;\n  }\n  VideoCapabilities videoCapabilities = capabilities.getVideoCapabilities();\n  if (videoCapabilities == null) {\n    return null;\n  }\n  return alignVideoSizeV21(videoCapabilities, width, height);\n}", "summary_tokens": ["returns", "the", "smallest", "video", "size", "greater", "than", "or", "equal", "to", "a", "specified", "size", "that", "also", "satisfies", "the", "media", "codec", "s", "width", "and", "height", "alignment", "requirements"], "project": "ExoPlayer"}
{"id": 724, "code": "private static void releaseMediaPeriod(MediaSourceList mediaSourceList, MediaPeriod mediaPeriod) {\n  try {\n    if (mediaPeriod instanceof ClippingMediaPeriod) {\n      mediaSourceList.releasePeriod(((ClippingMediaPeriod) mediaPeriod).mediaPeriod);\n    } else {\n      mediaSourceList.releasePeriod(mediaPeriod);\n    }\n  } catch (RuntimeException e) {\n      \n    Log.e(TAG, \"Period release failed.\", e);\n  }\n}", "summary_tokens": ["releases", "the", "given", "media", "period", "logging", "and", "suppressing", "any", "errors"], "project": "ExoPlayer"}
{"id": 728, "code": "public boolean updateShuffleModeEnabled(Timeline timeline, boolean shuffleModeEnabled) {\n  this.shuffleModeEnabled = shuffleModeEnabled;\n  return updateForPlaybackModeChange(timeline);\n}", "summary_tokens": ["sets", "whether", "shuffling", "is", "enabled", "and", "returns", "whether", "the", "shuffle", "mode", "change", "has", "been", "fully", "handled"], "project": "ExoPlayer"}
{"id": 1701, "code": "public void seekToThenUpdateStreamContinueToReadFromSeekPositionEvenSeekMoreThanAvailable() {\n  long presentationTimeUs1 = 1000000;\n  long presentationTimeUs2 = 2000000;\n  long presentationTimeUs3 = 3000000;\n  EventMessage eventMessage1 = newEventMessageWithId(1);\n  EventMessage eventMessage2 = newEventMessageWithId(2);\n  EventMessage eventMessage3 = newEventMessageWithId(3);\n  EventStream eventStream1 =\n      new EventStream(\n          SCHEME_ID,\n          VALUE,\n          TIME_SCALE,\n          new long[] {presentationTimeUs1},\n          new EventMessage[] {eventMessage1});\n  EventStream eventStream2 =\n      new EventStream(\n          SCHEME_ID,\n          VALUE,\n          TIME_SCALE,\n          new long[] {presentationTimeUs1, presentationTimeUs2, presentationTimeUs3},\n          new EventMessage[] {eventMessage1, eventMessage2, eventMessage3});\n  EventSampleStream sampleStream = new EventSampleStream(eventStream1, FORMAT, true);\n    \n  readData(sampleStream);\n  sampleStream.seekToUs(presentationTimeUs2 + 1);\n\n  sampleStream.updateEventStream(eventStream2, true);\n  int result = readData(sampleStream);\n  assertThat(result).isEqualTo(C.RESULT_BUFFER_READ);\n  assertThat(inputBuffer.data.array()).isEqualTo(getEncodedMessage(eventMessage3));\n}", "summary_tokens": ["tests", "that", "event", "sample", "stream", "update", "event", "stream", "event", "stream", "boolean", "will", "update", "the", "underlying", "event", "stream", "but", "keep", "the", "timestamp", "the", "stream", "has", "seek", "to", "so", "the", "next", "event", "sample", "stream", "read", "data", "format", "holder", "decoder", "input", "buffer", "int", "call", "will", "return", "sample", "data", "from", "the", "seek", "position"], "project": "ExoPlayer"}
{"id": 1162, "code": "private static boolean codecNeedsDiscardToSpsWorkaround(String name, Format format) {\n  return Util.SDK_INT < 21\n      && format.initializationData.isEmpty()\n      && \"OMX.MTK.VIDEO.DECODER.AVC\".equals(name);\n}", "summary_tokens": ["returns", "whether", "the", "decoder", "is", "an", "h"], "project": "ExoPlayer"}
{"id": 2123, "code": "private static ClutDefinition parseClutDefinition(ParsableBitArray data, int length) {\n  int clutId = data.readBits(8);\n  data.skipBits(8); \n  int remainingLength = length - 2;\n\n  int[] clutEntries2Bit = generateDefault2BitClutEntries();\n  int[] clutEntries4Bit = generateDefault4BitClutEntries();\n  int[] clutEntries8Bit = generateDefault8BitClutEntries();\n\n  while (remainingLength > 0) {\n    int entryId = data.readBits(8);\n    int entryFlags = data.readBits(8);\n    remainingLength -= 2;\n\n    int[] clutEntries;\n    if ((entryFlags & 0x80) != 0) {\n      clutEntries = clutEntries2Bit;\n    } else if ((entryFlags & 0x40) != 0) {\n      clutEntries = clutEntries4Bit;\n    } else {\n      clutEntries = clutEntries8Bit;\n    }\n\n    int y;\n    int cr;\n    int cb;\n    int t;\n    if ((entryFlags & 0x01) != 0) {\n      y = data.readBits(8);\n      cr = data.readBits(8);\n      cb = data.readBits(8);\n      t = data.readBits(8);\n      remainingLength -= 4;\n    } else {\n      y = data.readBits(6) << 2;\n      cr = data.readBits(4) << 4;\n      cb = data.readBits(4) << 4;\n      t = data.readBits(2) << 6;\n      remainingLength -= 2;\n    }\n\n    if (y == 0x00) {\n      cr = 0x00;\n      cb = 0x00;\n      t = 0xFF;\n    }\n\n    int a = (byte) (0xFF - (t & 0xFF));\n    int r = (int) (y + (1.40200 * (cr - 128)));\n    int g = (int) (y - (0.34414 * (cb - 128)) - (0.71414 * (cr - 128)));\n    int b = (int) (y + (1.77200 * (cb - 128)));\n    clutEntries[entryId] =\n        getColor(\n            a,\n            Util.constrainValue(r, 0, 255),\n            Util.constrainValue(g, 0, 255),\n            Util.constrainValue(b, 0, 255));\n  }\n\n  return new ClutDefinition(clutId, clutEntries2Bit, clutEntries4Bit, clutEntries8Bit);\n}", "summary_tokens": ["parses", "a", "clut", "definition", "segment", "as", "defined", "by", "etsi", "en", "0", "0", "0"], "project": "ExoPlayer"}
{"id": 2270, "code": "public void startPlayback(long offsetMs) {\n  messageSender.sendPlayRequest(uri, offsetMs, checkNotNull(sessionId));\n}", "summary_tokens": ["starts", "rtsp", "playback", "by", "sending", "rtsp", "play", "request"], "project": "ExoPlayer"}
{"id": 778, "code": "public PlaybackInfo copyWithIsLoading(boolean isLoading) {\n  return new PlaybackInfo(\n      timeline,\n      periodId,\n      requestedContentPositionUs,\n      discontinuityStartPositionUs,\n      playbackState,\n      playbackError,\n      isLoading,\n      trackGroups,\n      trackSelectorResult,\n      staticMetadata,\n      loadingMediaPeriodId,\n      playWhenReady,\n      playbackSuppressionReason,\n      playbackParameters,\n      bufferedPositionUs,\n      totalBufferedDurationUs,\n      positionUs,\n      sleepingForOffload);\n}", "summary_tokens": ["copies", "playback", "info", "with", "new", "loading", "state"], "project": "ExoPlayer"}
{"id": 417, "code": "public static int checkIndex(int index, int start, int limit) {\n  if (index < start || index >= limit) {\n    throw new IndexOutOfBoundsException();\n  }\n  return index;\n}", "summary_tokens": ["throws", "index", "out", "of", "bounds", "exception", "if", "index", "falls", "outside", "the", "specified", "bounds"], "project": "ExoPlayer"}
{"id": 2361, "code": "private boolean feedProcessorFromDecoder() throws TransformationException {\n    \n    \n  if (processorOutputBuffer.hasRemaining()\n      || speedChangingAudioProcessor.getOutput().hasRemaining()) {\n    return false;\n  }\n\n  if (decoder.isEnded()) {\n    speedChangingAudioProcessor.queueEndOfStream();\n    return false;\n  }\n  checkState(!speedChangingAudioProcessor.isEnded());\n\n  @Nullable ByteBuffer decoderOutputBuffer = decoder.getOutputBuffer();\n  if (decoderOutputBuffer == null) {\n    return false;\n  }\n\n  speedChangingAudioProcessor.queueInput(decoderOutputBuffer);\n  if (!decoderOutputBuffer.hasRemaining()) {\n    decoder.releaseOutputBuffer( false);\n  }\n  return true;\n}", "summary_tokens": ["attempts", "to", "process", "decoder", "output", "data", "and", "returns", "whether", "it", "may", "be", "possible", "to", "process", "more", "data", "immediately", "by", "calling", "this", "method", "again"], "project": "ExoPlayer"}
{"id": 1862, "code": "private void ensureSpaceForPeek(int length) {\n  int requiredLength = peekBufferPosition + length;\n  if (requiredLength > peekBuffer.length) {\n    int newPeekCapacity =\n        Util.constrainValue(\n            peekBuffer.length * 2,\n            requiredLength + PEEK_MIN_FREE_SPACE_AFTER_RESIZE,\n            requiredLength + PEEK_MAX_FREE_SPACE);\n    peekBuffer = Arrays.copyOf(peekBuffer, newPeekCapacity);\n  }\n}", "summary_tokens": ["ensures", "peek", "buffer", "is", "large", "enough", "to", "store", "at", "least", "length", "bytes", "from", "the", "current", "peek", "position"], "project": "ExoPlayer"}
{"id": 2596, "code": "public @ResizeMode int getResizeMode() {\n  Assertions.checkStateNotNull(contentFrame);\n  return contentFrame.getResizeMode();\n}", "summary_tokens": ["returns", "the", "resize", "mode"], "project": "ExoPlayer"}
{"id": 2085, "code": "public @Extractor.ReadResult int readDuration(\n    ExtractorInput input, PositionHolder seekPositionHolder, int pcrPid) throws IOException {\n  if (pcrPid <= 0) {\n    return finishReadDuration(input);\n  }\n  if (!isLastPcrValueRead) {\n    return readLastPcrValue(input, seekPositionHolder, pcrPid);\n  }\n  if (lastPcrValue == C.TIME_UNSET) {\n    return finishReadDuration(input);\n  }\n  if (!isFirstPcrValueRead) {\n    return readFirstPcrValue(input, seekPositionHolder, pcrPid);\n  }\n  if (firstPcrValue == C.TIME_UNSET) {\n    return finishReadDuration(input);\n  }\n\n  long minPcrPositionUs = pcrTimestampAdjuster.adjustTsTimestamp(firstPcrValue);\n  long maxPcrPositionUs = pcrTimestampAdjuster.adjustTsTimestamp(lastPcrValue);\n  durationUs = maxPcrPositionUs - minPcrPositionUs;\n  if (durationUs < 0) {\n    Log.w(TAG, \"Invalid duration: \" + durationUs + \". Using TIME_UNSET instead.\");\n    durationUs = C.TIME_UNSET;\n  }\n  return finishReadDuration(input);\n}", "summary_tokens": ["reads", "a", "ts", "duration", "from", "the", "input", "using", "the", "given", "pcr", "pid"], "project": "ExoPlayer"}
{"id": 1146, "code": "protected float getCodecOperatingRateV23(\n    float targetPlaybackSpeed, Format format, Format[] streamFormats) {\n  return CODEC_OPERATING_RATE_UNSET;\n}", "summary_tokens": ["returns", "the", "media", "format", "key", "operating", "rate", "value", "for", "a", "given", "playback", "speed", "current", "format", "and", "set", "of", "possible", "stream", "formats"], "project": "ExoPlayer"}
{"id": 1177, "code": "private static ArrayList<MediaCodecInfo> getDecoderInfosInternal(\n    CodecKey key, MediaCodecListCompat mediaCodecList) throws DecoderQueryException {\n  try {\n    ArrayList<MediaCodecInfo> decoderInfos = new ArrayList<>();\n    String mimeType = key.mimeType;\n    int numberOfCodecs = mediaCodecList.getCodecCount();\n    boolean secureDecodersExplicit = mediaCodecList.secureDecodersExplicit();\n      \n    for (int i = 0; i < numberOfCodecs; i++) {\n      android.media.MediaCodecInfo codecInfo = mediaCodecList.getCodecInfoAt(i);\n      if (isAlias(codecInfo)) {\n          \n          \n        continue;\n      }\n      String name = codecInfo.getName();\n      if (!isCodecUsableDecoder(codecInfo, name, secureDecodersExplicit, mimeType)) {\n        continue;\n      }\n      @Nullable String codecMimeType = getCodecMimeType(codecInfo, name, mimeType);\n      if (codecMimeType == null) {\n        continue;\n      }\n      try {\n        CodecCapabilities capabilities = codecInfo.getCapabilitiesForType(codecMimeType);\n        boolean tunnelingSupported =\n            mediaCodecList.isFeatureSupported(\n                CodecCapabilities.FEATURE_TunneledPlayback, codecMimeType, capabilities);\n        boolean tunnelingRequired =\n            mediaCodecList.isFeatureRequired(\n                CodecCapabilities.FEATURE_TunneledPlayback, codecMimeType, capabilities);\n        if ((!key.tunneling && tunnelingRequired) || (key.tunneling && !tunnelingSupported)) {\n          continue;\n        }\n        boolean secureSupported =\n            mediaCodecList.isFeatureSupported(\n                CodecCapabilities.FEATURE_SecurePlayback, codecMimeType, capabilities);\n        boolean secureRequired =\n            mediaCodecList.isFeatureRequired(\n                CodecCapabilities.FEATURE_SecurePlayback, codecMimeType, capabilities);\n        if ((!key.secure && secureRequired) || (key.secure && !secureSupported)) {\n          continue;\n        }\n        boolean hardwareAccelerated = isHardwareAccelerated(codecInfo, mimeType);\n        boolean softwareOnly = isSoftwareOnly(codecInfo, mimeType);\n        boolean vendor = isVendor(codecInfo);\n        if ((secureDecodersExplicit && key.secure == secureSupported)\n            || (!secureDecodersExplicit && !key.secure)) {\n          decoderInfos.add(\n              MediaCodecInfo.newInstance(\n                  name,\n                  mimeType,\n                  codecMimeType,\n                  capabilities,\n                  hardwareAccelerated,\n                  softwareOnly,\n                  vendor,\n                   false,\n                   false));\n        } else if (!secureDecodersExplicit && secureSupported) {\n          decoderInfos.add(\n              MediaCodecInfo.newInstance(\n                  name + \".secure\",\n                  mimeType,\n                  codecMimeType,\n                  capabilities,\n                  hardwareAccelerated,\n                  softwareOnly,\n                  vendor,\n                   false,\n                   true));\n            \n          return decoderInfos;\n        }\n      } catch (Exception e) {\n        if (Util.SDK_INT <= 23 && !decoderInfos.isEmpty()) {\n            \n          Log.e(TAG, \"Skipping codec \" + name + \" (failed to query capabilities)\");\n        } else {\n            \n            \n          Log.e(TAG, \"Failed to query codec \" + name + \" (\" + codecMimeType + \")\");\n          throw e;\n        }\n      }\n    }\n    return decoderInfos;\n  } catch (Exception e) {\n      \n      \n    throw new DecoderQueryException(e);\n  }\n}", "summary_tokens": ["returns", "media", "codec", "info", "s", "for", "the", "given", "codec", "codec", "key", "in", "the", "order", "given", "by", "media", "codec", "list"], "project": "ExoPlayer"}
{"id": 1265, "code": "protected final void prepareChildSource(@UnknownNull T id, MediaSource mediaSource) {\n  Assertions.checkArgument(!childSources.containsKey(id));\n  MediaSourceCaller caller =\n      (source, timeline) -> onChildSourceInfoRefreshed(id, source, timeline);\n  ForwardingEventListener eventListener = new ForwardingEventListener(id);\n  childSources.put(id, new MediaSourceAndListener<>(mediaSource, caller, eventListener));\n  mediaSource.addEventListener(Assertions.checkNotNull(eventHandler), eventListener);\n  mediaSource.addDrmEventListener(Assertions.checkNotNull(eventHandler), eventListener);\n  mediaSource.prepareSource(caller, mediaTransferListener, getPlayerId());\n  if (!isEnabled()) {\n    mediaSource.disable(caller);\n  }\n}", "summary_tokens": ["prepares", "a", "child", "source"], "project": "ExoPlayer"}
{"id": 2037, "code": "private boolean continueRead(ParsableByteArray source, byte[] target, int targetLength) {\n  int bytesToRead = min(source.bytesLeft(), targetLength - bytesRead);\n  source.readBytes(target, bytesRead, bytesToRead);\n  bytesRead += bytesToRead;\n  return bytesRead == targetLength;\n}", "summary_tokens": ["continues", "a", "read", "from", "the", "provided", "source", "into", "a", "given", "target"], "project": "ExoPlayer"}
{"id": 1775, "code": "public ContentMetadataMutations remove(String name) {\n  removedValues.add(name);\n  editedValues.remove(name);\n  return this;\n}", "summary_tokens": ["adds", "a", "mutation", "to", "remove", "a", "metadata", "value"], "project": "ExoPlayer"}
{"id": 2455, "code": "public static CaptionStyleCompat createFromCaptionStyle(\n    CaptioningManager.CaptionStyle captionStyle) {\n  if (Util.SDK_INT >= 21) {\n    return createFromCaptionStyleV21(captionStyle);\n  } else {\n      \n      \n    return createFromCaptionStyleV19(captionStyle);\n  }\n}", "summary_tokens": ["creates", "a", "caption", "style", "compat", "equivalent", "to", "a", "provided", "caption", "style"], "project": "ExoPlayer"}
{"id": 1245, "code": "public Requirements filterRequirements(int requirementsFilter) {\n  int filteredRequirements = requirements & requirementsFilter;\n  return filteredRequirements == requirements ? this : new Requirements(filteredRequirements);\n}", "summary_tokens": ["filters", "the", "requirements", "returning", "the", "subset", "that", "are", "enabled", "by", "the", "provided", "filter"], "project": "ExoPlayer"}
{"id": 1842, "code": "public static int parseAc4SyncframeAudioSampleCount(ByteBuffer buffer) {\n  byte[] bufferBytes = new byte[HEADER_SIZE_FOR_PARSER];\n  int position = buffer.position();\n  buffer.get(bufferBytes);\n  buffer.position(position);\n  return parseAc4SyncframeInfo(new ParsableBitArray(bufferBytes)).sampleCount;\n}", "summary_tokens": ["reads", "the", "number", "of", "audio", "samples", "represented", "by", "the", "given", "ac", "0", "syncframe"], "project": "ExoPlayer"}
{"id": 2380, "code": "public static ImmutableSet<Integer> findSupportedEncodingProfiles(\n    MediaCodecInfo encoderInfo, String mimeType) {\n  MediaCodecInfo.CodecProfileLevel[] profileLevels =\n      encoderInfo.getCapabilitiesForType(mimeType).profileLevels;\n  ImmutableSet.Builder<Integer> supportedProfilesBuilder = new ImmutableSet.Builder<>();\n  for (MediaCodecInfo.CodecProfileLevel profileLevel : profileLevels) {\n    supportedProfilesBuilder.add(profileLevel.profile);\n  }\n  return supportedProfilesBuilder.build();\n}", "summary_tokens": ["returns", "a", "immutable", "set", "set", "of", "supported", "media", "codec", "info"], "project": "ExoPlayer"}
{"id": 1150, "code": "private void drainAndReinitializeCodec() throws ExoPlaybackException {\n  if (codecReceivedBuffers) {\n    codecDrainState = DRAIN_STATE_SIGNAL_END_OF_STREAM;\n    codecDrainAction = DRAIN_ACTION_REINITIALIZE;\n  } else {\n      \n    reinitializeCodec();\n  }\n}", "summary_tokens": ["starts", "draining", "the", "codec", "for", "re", "initialization"], "project": "ExoPlayer"}
{"id": 958, "code": "public static AudioCapabilities getCapabilities(Context context) {\n  Intent intent =\n      context.registerReceiver(\n           null, new IntentFilter(AudioManager.ACTION_HDMI_AUDIO_PLUG));\n  return getCapabilities(context, intent);\n}", "summary_tokens": ["returns", "the", "current", "audio", "capabilities", "for", "the", "device"], "project": "ExoPlayer"}
{"id": 1442, "code": "public <T extends Loadable> long startLoading(\n    T loadable, Callback<T> callback, int defaultMinRetryCount) {\n  Looper looper = Assertions.checkStateNotNull(Looper.myLooper());\n  fatalError = null;\n  long startTimeMs = SystemClock.elapsedRealtime();\n  new LoadTask<>(looper, loadable, callback, defaultMinRetryCount, startTimeMs).start(0);\n  return startTimeMs;\n}", "summary_tokens": ["starts", "loading", "a", "loadable"], "project": "ExoPlayer"}
{"id": 2180, "code": "public static void clearPrefixFlags(boolean[] prefixFlags) {\n  prefixFlags[0] = false;\n  prefixFlags[1] = false;\n  prefixFlags[2] = false;\n}", "summary_tokens": ["clears", "prefix", "flags", "as", "used", "by", "find", "nal", "unit", "byte", "int", "int", "boolean"], "project": "ExoPlayer"}
{"id": 1849, "code": "public static int parseMpegAudioFrameSampleCount(int headerData) {\n  if (!isMagicPresent(headerData)) {\n    return C.LENGTH_UNSET;\n  }\n\n  int version = (headerData >>> 19) & 3;\n  if (version == 1) {\n    return C.LENGTH_UNSET;\n  }\n\n  int layer = (headerData >>> 17) & 3;\n  if (layer == 0) {\n    return C.LENGTH_UNSET;\n  }\n\n    \n  int bitrateIndex = (headerData >>> 12) & 15;\n  int samplingRateIndex = (headerData >>> 10) & 3;\n  if (bitrateIndex == 0 || bitrateIndex == 0xF || samplingRateIndex == 3) {\n    return C.LENGTH_UNSET;\n  }\n\n  return getFrameSizeInSamples(version, layer);\n}", "summary_tokens": ["returns", "the", "number", "of", "samples", "per", "frame", "associated", "with", "header", "data", "or", "c", "length", "unset", "if", "it", "is", "invalid"], "project": "ExoPlayer"}
{"id": 1232, "code": "public static void sendPauseDownloads(\n    Context context, Class<? extends DownloadService> clazz, boolean foreground) {\n  Intent intent = buildPauseDownloadsIntent(context, clazz, foreground);\n  startService(context, intent, foreground);\n}", "summary_tokens": ["starts", "the", "service", "if", "not", "started", "already", "and", "pauses", "all", "downloads"], "project": "ExoPlayer"}
{"id": 142, "code": "public static AdPlaybackState updateAdDurationInAdGroup(\n    int adGroupIndex, int adIndexInAdGroup, long adDurationUs, AdPlaybackState adPlaybackState) {\n  AdPlaybackState.AdGroup adGroup = adPlaybackState.getAdGroup(adGroupIndex);\n  checkArgument(adIndexInAdGroup < adGroup.durationsUs.length);\n  long[] adDurationsUs =\n      updateAdDurationAndPropagate(\n          Arrays.copyOf(adGroup.durationsUs, adGroup.durationsUs.length),\n          adIndexInAdGroup,\n          adDurationUs,\n          adGroup.durationsUs[adIndexInAdGroup]);\n  return adPlaybackState.withAdDurationsUs(adGroupIndex, adDurationsUs);\n}", "summary_tokens": ["updates", "the", "duration", "of", "an", "ad", "in", "and", "ad", "group"], "project": "ExoPlayer"}
{"id": 56, "code": "public void onMediaItemsAdded(List<MediaItem> mediaItems, MediaQueueItem[] mediaQueueItems) {\n  for (int i = 0; i < mediaItems.size(); i++) {\n    mediaItemsByContentId.put(\n        checkNotNull(mediaQueueItems[i].getMedia()).getContentId(), mediaItems.get(i));\n  }\n}", "summary_tokens": ["called", "when", "media", "items", "player", "add", "media", "items", "list", "have", "been", "added", "and", "are", "sent", "to", "the", "cast", "playback", "queue"], "project": "ExoPlayer"}
{"id": 1793, "code": "public static SimpleCacheSpan createHole(String key, long position, long length) {\n  return new SimpleCacheSpan(key, position, length, C.TIME_UNSET, null);\n}", "summary_tokens": ["creates", "a", "hole", "span"], "project": "ExoPlayer"}
{"id": 367, "code": "public static ParserException createForMalformedManifest(\n    @Nullable String message, @Nullable Throwable cause) {\n  return new ParserException(\n      message, cause,  true, C.DATA_TYPE_MANIFEST);\n}", "summary_tokens": ["creates", "a", "new", "instance", "for", "which", "content", "is", "malformed", "is", "true", "and", "data", "type", "is", "c", "data", "type", "manifest"], "project": "ExoPlayer"}
{"id": 479, "code": "public static boolean isProtectedContentExtensionSupported(Context context) {\n  if (Util.SDK_INT < 24) {\n    return false;\n  }\n  if (Util.SDK_INT < 26 && (\"samsung\".equals(Util.MANUFACTURER) || \"XT1650\".equals(Util.MODEL))) {\n      \n      \n      \n      \n    return false;\n  }\n  if (Util.SDK_INT < 26\n      && !context\n          .getPackageManager()\n          .hasSystemFeature(PackageManager.FEATURE_VR_MODE_HIGH_PERFORMANCE)) {\n      \n    return false;\n  }\n\n  EGLDisplay display = EGL14.eglGetDisplay(EGL14.EGL_DEFAULT_DISPLAY);\n  @Nullable String eglExtensions = EGL14.eglQueryString(display, EGL10.EGL_EXTENSIONS);\n  return eglExtensions != null && eglExtensions.contains(EXTENSION_PROTECTED_CONTENT);\n}", "summary_tokens": ["returns", "whether", "creating", "a", "gl", "context", "with", "extension", "protected", "content", "is", "possible"], "project": "ExoPlayer"}
{"id": 1871, "code": "public synchronized DefaultExtractorsFactory setAmrExtractorFlags(@AmrExtractor.Flags int flags) {\n  this.amrFlags = flags;\n  return this;\n}", "summary_tokens": ["sets", "flags", "for", "amr", "extractor", "instances", "created", "by", "the", "factory"], "project": "ExoPlayer"}
{"id": 1347, "code": "protected final void invalidateUpstreamFormatAdjustment() {\n  upstreamFormatAdjustmentRequired = true;\n}", "summary_tokens": ["invalidates", "the", "last", "upstream", "format", "adjustment"], "project": "ExoPlayer"}
{"id": 242, "code": "public Format copyWithFrameRate(float frameRate) {\n  return buildUpon().setFrameRate(frameRate).build();\n}", "summary_tokens": ["use", "build", "upon", "and", "builder", "set", "frame", "rate", "float"], "project": "ExoPlayer"}
{"id": 1713, "code": "public byte[] getData() {\n  return stream == null ? null : stream.toByteArray();\n}", "summary_tokens": ["returns", "the", "data", "written", "to", "the", "sink", "since", "the", "last", "call", "to", "open", "data", "spec", "or", "null", "if", "open", "data", "spec", "has", "never", "been", "called"], "project": "ExoPlayer"}
{"id": 1939, "code": "public void onChunkStart(int size) {\n  currentChunkSize = size;\n  bytesRemainingInCurrentChunk = size;\n}", "summary_tokens": ["prepares", "for", "parsing", "a", "chunk", "with", "the", "given", "size"], "project": "ExoPlayer"}
{"id": 262, "code": "public void clearMediaItems() {\n  player.clearMediaItems();\n}", "summary_tokens": ["calls", "player", "clear", "media", "items", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1253, "code": "public @Requirements.RequirementFlags int start() {\n  notMetRequirements = requirements.getNotMetRequirements(context);\n\n  IntentFilter filter = new IntentFilter();\n  if (requirements.isNetworkRequired()) {\n    if (Util.SDK_INT >= 24) {\n      registerNetworkCallbackV24();\n    } else {\n      filter.addAction(ConnectivityManager.CONNECTIVITY_ACTION);\n    }\n  }\n  if (requirements.isChargingRequired()) {\n    filter.addAction(Intent.ACTION_POWER_CONNECTED);\n    filter.addAction(Intent.ACTION_POWER_DISCONNECTED);\n  }\n  if (requirements.isIdleRequired()) {\n    if (Util.SDK_INT >= 23) {\n      filter.addAction(PowerManager.ACTION_DEVICE_IDLE_MODE_CHANGED);\n    } else {\n      filter.addAction(Intent.ACTION_SCREEN_ON);\n      filter.addAction(Intent.ACTION_SCREEN_OFF);\n    }\n  }\n  if (requirements.isStorageNotLowRequired()) {\n    filter.addAction(Intent.ACTION_DEVICE_STORAGE_LOW);\n    filter.addAction(Intent.ACTION_DEVICE_STORAGE_OK);\n  }\n  receiver = new DeviceStatusChangeReceiver();\n  context.registerReceiver(receiver, filter, null, handler);\n  return notMetRequirements;\n}", "summary_tokens": ["starts", "watching", "for", "changes"], "project": "ExoPlayer"}
{"id": 1761, "code": "public boolean lockRange(long position, long length) {\n  for (int i = 0; i < lockedRanges.size(); i++) {\n    if (lockedRanges.get(i).intersects(position, length)) {\n      return false;\n    }\n  }\n  lockedRanges.add(new Range(position, length));\n  return true;\n}", "summary_tokens": ["attempts", "to", "lock", "the", "specified", "range", "of", "the", "resource"], "project": "ExoPlayer"}
{"id": 197, "code": "public void experimentalSetDiscardPaddingEnabled(boolean enabled) {\n  this.experimentalDiscardPaddingEnabled = enabled;\n}", "summary_tokens": ["sets", "whether", "discard", "padding", "is", "enabled"], "project": "ExoPlayer"}
{"id": 183, "code": "public void setMapStateIdleToSessionStateStopped(boolean mapIdleToStopped) {\n  this.mapIdleToStopped = mapIdleToStopped;\n}", "summary_tokens": ["sets", "whether", "player", "state", "idle", "should", "be", "mapped", "to", "playback", "state", "compat", "state", "stopped"], "project": "ExoPlayer"}
{"id": 2548, "code": "public void setShowMultiWindowTimeBar(boolean showMultiWindowTimeBar) {\n  Assertions.checkStateNotNull(controller);\n  controller.setShowMultiWindowTimeBar(showMultiWindowTimeBar);\n}", "summary_tokens": ["sets", "whether", "the", "time", "bar", "should", "show", "all", "windows", "as", "opposed", "to", "just", "the", "current", "one"], "project": "ExoPlayer"}
{"id": 2433, "code": "private static MetadataInfo getMetadataInfo(@Nullable Metadata metadata) {\n  MetadataInfo metadataInfo = new MetadataInfo();\n  if (metadata == null) {\n    return metadataInfo;\n  }\n\n  for (int i = 0; i < metadata.length(); i++) {\n    Metadata.Entry entry = metadata.get(i);\n    if (entry instanceof SmtaMetadataEntry) {\n      SmtaMetadataEntry smtaMetadataEntry = (SmtaMetadataEntry) entry;\n      metadataInfo.captureFrameRate = smtaMetadataEntry.captureFrameRate;\n      metadataInfo.inputMaxLayer = smtaMetadataEntry.svcTemporalLayerCount - 1;\n    } else if (entry instanceof SlowMotionData) {\n      metadataInfo.slowMotionData = (SlowMotionData) entry;\n    }\n  }\n\n  if (metadataInfo.slowMotionData == null) {\n    return metadataInfo;\n  }\n\n  checkState(metadataInfo.inputMaxLayer != C.INDEX_UNSET, \"SVC temporal layer count not found.\");\n  checkState(metadataInfo.captureFrameRate != C.RATE_UNSET, \"Capture frame rate not found.\");\n  checkState(\n      metadataInfo.captureFrameRate % 1 == 0\n          && metadataInfo.captureFrameRate % TARGET_OUTPUT_FRAME_RATE == 0,\n      \"Invalid capture frame rate: \" + metadataInfo.captureFrameRate);\n\n  int frameCountDivisor = (int) metadataInfo.captureFrameRate / TARGET_OUTPUT_FRAME_RATE;\n  int normalSpeedMaxLayer = metadataInfo.inputMaxLayer;\n  while (normalSpeedMaxLayer >= 0) {\n    if ((frameCountDivisor & 1) == 1) {\n        \n        \n        \n      checkState(\n          frameCountDivisor >> 1 == 0,\n          \"Could not compute normal speed max SVC layer for capture frame rate  \"\n              + metadataInfo.captureFrameRate);\n      metadataInfo.normalSpeedMaxLayer = normalSpeedMaxLayer;\n      break;\n    }\n    frameCountDivisor >>= 1;\n    normalSpeedMaxLayer--;\n  }\n  return metadataInfo;\n}", "summary_tokens": ["returns", "the", "metadata", "info", "derived", "from", "the", "metadata", "provided"], "project": "ExoPlayer"}
{"id": 1683, "code": "public RangedUri attemptMerge(@Nullable RangedUri other, String baseUri) {\n  final String resolvedUri = resolveUriString(baseUri);\n  if (other == null || !resolvedUri.equals(other.resolveUriString(baseUri))) {\n    return null;\n  } else if (length != C.LENGTH_UNSET && start + length == other.start) {\n    return new RangedUri(\n        resolvedUri,\n        start,\n        other.length == C.LENGTH_UNSET ? C.LENGTH_UNSET : length + other.length);\n  } else if (other.length != C.LENGTH_UNSET && other.start + other.length == start) {\n    return new RangedUri(\n        resolvedUri,\n        other.start,\n        length == C.LENGTH_UNSET ? C.LENGTH_UNSET : other.length + length);\n  } else {\n    return null;\n  }\n}", "summary_tokens": ["attempts", "to", "merge", "this", "ranged", "uri", "with", "another", "and", "an", "optional", "common", "base", "uri"], "project": "ExoPlayer"}
{"id": 2519, "code": "public boolean getUseArtwork() {\n  return useArtwork;\n}", "summary_tokens": ["returns", "whether", "artwork", "is", "displayed", "if", "present", "in", "the", "media"], "project": "ExoPlayer"}
{"id": 2714, "code": "public static void assertBehavior(\n    ExtractorFactory factory,\n    String file,\n    AssertionConfig assertionConfig,\n    SimulationConfig simulationConfig)\n    throws IOException {\n    \n  Extractor extractor = factory.create();\n  extractor.seek(0, 0);\n  extractor.release();\n    \n  Context context = ApplicationProvider.getApplicationContext();\n  byte[] fileData = TestUtil.getByteArray(context, file);\n  String dumpFilesPrefix;\n  if (assertionConfig.dumpFilesPrefix != null) {\n    dumpFilesPrefix = assertionConfig.dumpFilesPrefix;\n  } else {\n    String[] path = file.split(\"/\");\n    checkState(\n        path.length > 0 && path[0].equals(\"media\"),\n        \"AssertionConfig.dumpFilesPrefix == null but file isn't in a media/ sub-directory.\\n\"\n            + \"Expected : 'media/<path-to-file>'\\n\"\n            + \"Found    : '\"\n            + file\n            + \"'\\n\"\n            + \"You need to set AssertionConfig.dumpFilesPrefix explicitly if your media and dump\"\n            + \" file aren't located in the expected structure (see docs on\"\n            + \" AssertionConfig.dumpFilesPrefix)\");\n    path[0] = \"extractordumps\";\n    dumpFilesPrefix = Joiner.on('/').join(path);\n  }\n  assertOutput(\n      factory.create(),\n      dumpFilesPrefix,\n      fileData,\n      context,\n      assertionConfig.deduplicateConsecutiveFormats,\n      simulationConfig.sniffFirst,\n      simulationConfig.simulateIOErrors,\n      simulationConfig.simulateUnknownLength,\n      simulationConfig.simulatePartialReads);\n}", "summary_tokens": ["asserts", "that", "an", "extractor", "consumes", "valid", "input", "data", "successfully", "successfully", "under", "the", "conditions", "specified", "by", "simulation", "config"], "project": "ExoPlayer"}
{"id": 751, "code": "public Timeline addMediaSources(\n    int index, List<MediaSourceHolder> holders, ShuffleOrder shuffleOrder) {\n  if (!holders.isEmpty()) {\n    this.shuffleOrder = shuffleOrder;\n    for (int insertionIndex = index; insertionIndex < index + holders.size(); insertionIndex++) {\n      MediaSourceHolder holder = holders.get(insertionIndex - index);\n      if (insertionIndex > 0) {\n        MediaSourceHolder previousHolder = mediaSourceHolders.get(insertionIndex - 1);\n        Timeline previousTimeline = previousHolder.mediaSource.getTimeline();\n        holder.reset(\n             previousHolder.firstWindowIndexInChild\n                + previousTimeline.getWindowCount());\n      } else {\n        holder.reset( 0);\n      }\n      Timeline newTimeline = holder.mediaSource.getTimeline();\n      correctOffsets(\n           insertionIndex,\n           newTimeline.getWindowCount());\n      mediaSourceHolders.add(insertionIndex, holder);\n      mediaSourceByUid.put(holder.uid, holder);\n      if (isPrepared) {\n        prepareChildSource(holder);\n        if (mediaSourceByMediaPeriod.isEmpty()) {\n          enabledMediaSourceHolders.add(holder);\n        } else {\n          disableChildSource(holder);\n        }\n      }\n    }\n  }\n  return createTimeline();\n}", "summary_tokens": ["adds", "multiple", "media", "source", "holder", "s", "to", "the", "playlist"], "project": "ExoPlayer"}
{"id": 1380, "code": "public void setSampleOffsetUs(long sampleOffsetUs) {\n  for (SampleQueue sampleQueue : sampleQueues) {\n    sampleQueue.setSampleOffsetUs(sampleOffsetUs);\n  }\n}", "summary_tokens": ["sets", "an", "offset", "that", "will", "be", "added", "to", "the", "timestamps", "and", "sub", "sample", "timestamps", "of", "samples", "subsequently", "written", "to", "the", "sample", "queues"], "project": "ExoPlayer"}
{"id": 4, "code": "public int getMediaQueueSize() {\n  return mediaQueue.size();\n}", "summary_tokens": ["returns", "the", "size", "of", "the", "media", "queue"], "project": "ExoPlayer"}
{"id": 2722, "code": "public FakeData newData(Uri uri) {\n  FakeData data = new FakeData(this, uri);\n  dataMap.put(uri, data);\n  return data;\n}", "summary_tokens": ["returns", "a", "new", "fake", "data", "with", "the", "given", "uri"], "project": "ExoPlayer"}
{"id": 346, "code": "public void clearVideoSurface(@Nullable Surface surface) {\n  player.clearVideoSurface(surface);\n}", "summary_tokens": ["calls", "player", "clear", "video", "surface", "surface", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 433, "code": "public static <T extends Bundleable> SparseArray<T> fromBundleSparseArray(\n    Bundleable.Creator<T> creator, SparseArray<Bundle> bundleSparseArray) {\n  SparseArray<T> result = new SparseArray<>(bundleSparseArray.size());\n  for (int i = 0; i < bundleSparseArray.size(); i++) {\n    result.put(bundleSparseArray.keyAt(i), creator.fromBundle(bundleSparseArray.valueAt(i)));\n  }\n  return result;\n}", "summary_tokens": ["converts", "a", "sparse", "array", "of", "bundle", "to", "a", "sparse", "array", "of", "bundleable"], "project": "ExoPlayer"}
{"id": 2685, "code": "public void blockUntilIdleAndThrowAnyFailure() throws Exception {\n  blockUntilIdle();\n  if (failureReason != Download.FAILURE_REASON_NONE) {\n    throw new Exception(\"Failure reason: \" + failureReason);\n  }\n}", "summary_tokens": ["blocks", "until", "the", "manager", "is", "idle", "and", "throws", "if", "any", "of", "the", "downloads", "failed"], "project": "ExoPlayer"}
{"id": 693, "code": "public RuntimeException getUnexpectedException() {\n  Assertions.checkState(type == TYPE_UNEXPECTED);\n  return (RuntimeException) Assertions.checkNotNull(getCause());\n}", "summary_tokens": ["retrieves", "the", "underlying", "error", "when", "type", "is", "type", "unexpected"], "project": "ExoPlayer"}
{"id": 1056, "code": "static void replaceSession(\n    @Nullable DrmSession previousSession, @Nullable DrmSession newSession) {\n  if (previousSession == newSession) {\n      \n    return;\n  }\n  if (newSession != null) {\n    newSession.acquire( null);\n  }\n  if (previousSession != null) {\n    previousSession.release( null);\n  }\n}", "summary_tokens": ["acquires", "new", "session", "then", "releases", "previous", "session"], "project": "ExoPlayer"}
{"id": 675, "code": "public DefaultRenderersFactory setEnableAudioFloatOutput(boolean enableFloatOutput) {\n  this.enableFloatOutput = enableFloatOutput;\n  return this;\n}", "summary_tokens": ["sets", "whether", "floating", "point", "audio", "should", "be", "output", "when", "possible"], "project": "ExoPlayer"}
{"id": 2791, "code": "public TestExoPlayerBuilder setBandwidthMeter(BandwidthMeter bandwidthMeter) {\n  Assertions.checkNotNull(bandwidthMeter);\n  this.bandwidthMeter = bandwidthMeter;\n  return this;\n}", "summary_tokens": ["sets", "the", "bandwidth", "meter"], "project": "ExoPlayer"}
{"id": 263, "code": "public boolean isCommandAvailable(@Command int command) {\n  return player.isCommandAvailable(command);\n}", "summary_tokens": ["calls", "player", "is", "command", "available", "int", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 296, "code": "public boolean hasNextMediaItem() {\n  return player.hasNextMediaItem();\n}", "summary_tokens": ["calls", "player", "has", "next", "media", "item", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 1298, "code": "default void onLoadError(\n    int windowIndex,\n    @Nullable MediaPeriodId mediaPeriodId,\n    LoadEventInfo loadEventInfo,\n    MediaLoadData mediaLoadData,\n    IOException error,\n    boolean wasCanceled) {}", "summary_tokens": ["called", "when", "a", "load", "error", "occurs"], "project": "ExoPlayer"}
{"id": 282, "code": "public long getSeekBackIncrement() {\n  return player.getSeekBackIncrement();\n}", "summary_tokens": ["calls", "player", "get", "seek", "back", "increment", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 88, "code": "public void decodeSampleWithBacktrackPosition(ByteBuffer output, long retryPosition)\n    throws IOException, FlacFrameDecodeException {\n  try {\n    decodeSample(output);\n  } catch (IOException e) {\n    if (retryPosition >= 0) {\n      reset(retryPosition);\n      if (extractorInput != null) {\n        extractorInput.setRetryPosition(retryPosition, e);\n      }\n    }\n    throw e;\n  }\n}", "summary_tokens": ["decodes", "and", "consumes", "the", "next", "frame", "from", "the", "flac", "stream", "into", "the", "given", "byte", "buffer"], "project": "ExoPlayer"}
{"id": 1730, "code": "public long open(DataSpec dataSpec) throws HttpDataSourceException {\n  this.dataSpec = dataSpec;\n  bytesRead = 0;\n  bytesToRead = 0;\n  transferInitializing(dataSpec);\n\n  String responseMessage;\n  HttpURLConnection connection;\n  try {\n    this.connection = makeConnection(dataSpec);\n    connection = this.connection;\n    responseCode = connection.getResponseCode();\n    responseMessage = connection.getResponseMessage();\n  } catch (IOException e) {\n    closeConnectionQuietly();\n    throw HttpDataSourceException.createForIOException(\n        e, dataSpec, HttpDataSourceException.TYPE_OPEN);\n  }\n\n    \n  if (responseCode < 200 || responseCode > 299) {\n    Map<String, List<String>> headers = connection.getHeaderFields();\n    if (responseCode == 416) {\n      long documentSize =\n          HttpUtil.getDocumentSize(connection.getHeaderField(HttpHeaders.CONTENT_RANGE));\n      if (dataSpec.position == documentSize) {\n        opened = true;\n        transferStarted(dataSpec);\n        return dataSpec.length != C.LENGTH_UNSET ? dataSpec.length : 0;\n      }\n    }\n\n    @Nullable InputStream errorStream = connection.getErrorStream();\n    byte[] errorResponseBody;\n    try {\n      errorResponseBody =\n          errorStream != null ? Util.toByteArray(errorStream) : Util.EMPTY_BYTE_ARRAY;\n    } catch (IOException e) {\n      errorResponseBody = Util.EMPTY_BYTE_ARRAY;\n    }\n    closeConnectionQuietly();\n    @Nullable\n    IOException cause =\n        responseCode == 416\n            ? new DataSourceException(PlaybackException.ERROR_CODE_IO_READ_POSITION_OUT_OF_RANGE)\n            : null;\n    throw new InvalidResponseCodeException(\n        responseCode, responseMessage, cause, headers, dataSpec, errorResponseBody);\n  }\n\n    \n  String contentType = connection.getContentType();\n  if (contentTypePredicate != null && !contentTypePredicate.apply(contentType)) {\n    closeConnectionQuietly();\n    throw new InvalidContentTypeException(contentType, dataSpec);\n  }\n\n    \n    \n    \n  long bytesToSkip = responseCode == 200 && dataSpec.position != 0 ? dataSpec.position : 0;\n\n    \n  boolean isCompressed = isCompressed(connection);\n  if (!isCompressed) {\n    if (dataSpec.length != C.LENGTH_UNSET) {\n      bytesToRead = dataSpec.length;\n    } else {\n      long contentLength =\n          HttpUtil.getContentLength(\n              connection.getHeaderField(HttpHeaders.CONTENT_LENGTH),\n              connection.getHeaderField(HttpHeaders.CONTENT_RANGE));\n      bytesToRead =\n          contentLength != C.LENGTH_UNSET ? (contentLength - bytesToSkip) : C.LENGTH_UNSET;\n    }\n  } else {\n      \n      \n      \n    bytesToRead = dataSpec.length;\n  }\n\n  try {\n    inputStream = connection.getInputStream();\n    if (isCompressed) {\n      inputStream = new GZIPInputStream(inputStream);\n    }\n  } catch (IOException e) {\n    closeConnectionQuietly();\n    throw new HttpDataSourceException(\n        e,\n        dataSpec,\n        PlaybackException.ERROR_CODE_IO_UNSPECIFIED,\n        HttpDataSourceException.TYPE_OPEN);\n  }\n\n  opened = true;\n  transferStarted(dataSpec);\n\n  try {\n    skipFully(bytesToSkip, dataSpec);\n  } catch (IOException e) {\n    closeConnectionQuietly();\n\n    if (e instanceof HttpDataSourceException) {\n      throw (HttpDataSourceException) e;\n    }\n    throw new HttpDataSourceException(\n        e,\n        dataSpec,\n        PlaybackException.ERROR_CODE_IO_UNSPECIFIED,\n        HttpDataSourceException.TYPE_OPEN);\n  }\n\n  return bytesToRead;\n}", "summary_tokens": ["opens", "the", "source", "to", "read", "the", "specified", "data"], "project": "ExoPlayer"}
{"id": 410, "code": "public Format getFormat(int index) {\n  return formats[index];\n}", "summary_tokens": ["returns", "the", "format", "of", "the", "track", "at", "a", "given", "index"], "project": "ExoPlayer"}
{"id": 1810, "code": "public final void addFlag(@C.BufferFlags int flag) {\n  flags |= flag;\n}", "summary_tokens": ["adds", "the", "flag", "to", "this", "buffer", "s", "flags"], "project": "ExoPlayer"}
{"id": 2712, "code": "public static void assertSniff(\n    Extractor extractor, FakeExtractorInput input, boolean expectedResult) throws IOException {\n  long originalPosition = input.getPosition();\n  while (true) {\n    try {\n      assertThat(extractor.sniff(input)).isEqualTo(expectedResult);\n      if (!expectedResult) {\n        assertThat(input.getPosition()).isEqualTo(originalPosition);\n      }\n      return;\n    } catch (SimulatedIOException e) {\n        \n    }\n  }\n}", "summary_tokens": ["asserts", "that", "extractor", "sniff", "extractor", "input", "returns", "the", "expected", "result", "for", "a", "given", "input", "retrying", "repeatedly", "when", "simulated", "ioexception", "is", "thrown"], "project": "ExoPlayer"}
{"id": 1431, "code": "public static synchronized DefaultBandwidthMeter getSingletonInstance(Context context) {\n  if (singletonInstance == null) {\n    singletonInstance = new DefaultBandwidthMeter.Builder(context).build();\n  }\n  return singletonInstance;\n}", "summary_tokens": ["returns", "a", "singleton", "instance", "of", "a", "default", "bandwidth", "meter", "with", "default", "configuration"], "project": "ExoPlayer"}
{"id": 497, "code": "public static String loadAsset(Context context, String assetPath) throws IOException {\n  @Nullable InputStream inputStream = null;\n  try {\n    inputStream = context.getAssets().open(assetPath);\n    return Util.fromUtf8Bytes(Util.toByteArray(inputStream));\n  } finally {\n    Util.closeQuietly(inputStream);\n  }\n}", "summary_tokens": ["loads", "a", "file", "from", "the", "assets", "folder"], "project": "ExoPlayer"}
{"id": 2315, "code": "private void maybeOutputSampleMetadata() {\n  if (numBytesPendingMetadataOutput > 0) {\n    outputSampleMetadataForFragmentedPackets();\n  }\n}", "summary_tokens": ["checks", "and", "outputs", "sample", "metadata", "if", "the", "last", "packet", "of", "a", "series", "of", "fragmented", "packets", "is", "lost"], "project": "ExoPlayer"}
{"id": 1567, "code": "private static long process(\n    SilenceSkippingAudioProcessor processor,\n    InputBufferProvider inputBufferProvider,\n    int inputBufferSize) {\n  int bytesPerFrame = AUDIO_FORMAT.bytesPerFrame;\n  processor.flush();\n  long totalOutputFrames = 0;\n  while (inputBufferProvider.hasRemaining()) {\n    ByteBuffer inputBuffer = inputBufferProvider.getNextInputBuffer(inputBufferSize);\n    while (inputBuffer.hasRemaining()) {\n      processor.queueInput(inputBuffer);\n      ByteBuffer outputBuffer = processor.getOutput();\n      totalOutputFrames += outputBuffer.remaining() / bytesPerFrame;\n      outputBuffer.clear();\n    }\n  }\n  processor.queueEndOfStream();\n  while (!processor.isEnded()) {\n    ByteBuffer outputBuffer = processor.getOutput();\n    totalOutputFrames += outputBuffer.remaining() / bytesPerFrame;\n    outputBuffer.clear();\n  }\n  return totalOutputFrames;\n}", "summary_tokens": ["processes", "the", "entire", "stream", "provided", "by", "input", "buffer", "provider", "in", "chunks", "of", "input", "buffer", "size", "and", "returns", "the", "total", "number", "of", "output", "frames"], "project": "ExoPlayer"}
{"id": 533, "code": "public static @C.TrackType int getTrackTypeOfCodec(String codec) {\n  return getTrackType(getMediaMimeType(codec));\n}", "summary_tokens": ["equivalent", "to", "get", "track", "type", "get", "media", "mime", "type", "codec"], "project": "ExoPlayer"}
{"id": 929, "code": "public float getEndedRatio() {\n  return foregroundPlaybackCount == 0 ? 0f : (float) endedCount / foregroundPlaybackCount;\n}", "summary_tokens": ["returns", "the", "ratio", "of", "foreground", "playbacks", "which", "reached", "the", "ended", "state", "at", "least", "once", "or", "0"], "project": "ExoPlayer"}
{"id": 1569, "code": "private int feedAndDrainAudioProcessorToEndOfTrackOne() throws Exception {\n    \n  ByteBuffer inputBuffer = ByteBuffer.allocate(TRACK_ONE_BUFFER_SIZE_BYTES);\n  int outputSize = 0;\n  while (!trimmingAudioProcessor.isEnded()) {\n    if (inputBuffer.hasRemaining()) {\n      trimmingAudioProcessor.queueInput(inputBuffer);\n      if (!inputBuffer.hasRemaining()) {\n          \n        trimmingAudioProcessor.setTrimFrameCount(\n            TRACK_TWO_TRIM_START_FRAME_COUNT, TRACK_TWO_TRIM_END_FRAME_COUNT);\n        trimmingAudioProcessor.configure(AUDIO_FORMAT);\n        trimmingAudioProcessor.queueEndOfStream();\n      }\n    }\n    ByteBuffer outputBuffer = trimmingAudioProcessor.getOutput();\n    outputSize += outputBuffer.remaining();\n    outputBuffer.clear();\n  }\n  trimmingAudioProcessor.reset();\n  return outputSize;\n}", "summary_tokens": ["feeds", "and", "drains", "the", "audio", "processor", "up", "to", "the", "end", "of", "track", "one", "returning", "the", "total", "output", "size", "in", "bytes"], "project": "ExoPlayer"}
{"id": 2262, "code": "public static boolean isFormatSupported(MediaDescription mediaDescription) {\n  switch (Ascii.toUpperCase(mediaDescription.rtpMapAttribute.mediaEncoding)) {\n    case RTP_MEDIA_AC3:\n    case RTP_MEDIA_AMR:\n    case RTP_MEDIA_AMR_WB:\n    case RTP_MEDIA_H263_1998:\n    case RTP_MEDIA_H263_2000:\n    case RTP_MEDIA_H264:\n    case RTP_MEDIA_H265:\n    case RTP_MEDIA_MPEG4_VIDEO:\n    case RTP_MEDIA_MPEG4_GENERIC:\n    case RTP_MEDIA_OPUS:\n    case RTP_MEDIA_PCM_L8:\n    case RTP_MEDIA_PCM_L16:\n    case RTP_MEDIA_PCMA:\n    case RTP_MEDIA_PCMU:\n    case RTP_MEDIA_VP8:\n    case RTP_MEDIA_VP9:\n      return true;\n    default:\n      return false;\n  }\n}", "summary_tokens": ["returns", "whether", "the", "format", "of", "a", "media", "description", "is", "supported"], "project": "ExoPlayer"}
{"id": 614, "code": "public static void beginSection(String sectionName) {\n  if (ExoPlayerLibraryInfo.TRACE_ENABLED && Util.SDK_INT >= 18) {\n    beginSectionV18(sectionName);\n  }\n}", "summary_tokens": ["writes", "a", "trace", "message", "to", "indicate", "that", "a", "given", "section", "of", "code", "has", "begun"], "project": "ExoPlayer"}
{"id": 1685, "code": "public RangedUri getInitializationUri() {\n  return initializationUri;\n}", "summary_tokens": ["returns", "a", "ranged", "uri", "defining", "the", "location", "of", "the", "representation", "s", "initialization", "data", "or", "null", "if", "no", "initialization", "data", "exists"], "project": "ExoPlayer"}
{"id": 1684, "code": "public static Representation newInstance(\n    long revisionId,\n    Format format,\n    List<BaseUrl> baseUrls,\n    SegmentBase segmentBase,\n    @Nullable List<Descriptor> inbandEventStreams,\n    List<Descriptor> essentialProperties,\n    List<Descriptor> supplementalProperties,\n    @Nullable String cacheKey) {\n  if (segmentBase instanceof SingleSegmentBase) {\n    return new SingleSegmentRepresentation(\n        revisionId,\n        format,\n        baseUrls,\n        (SingleSegmentBase) segmentBase,\n        inbandEventStreams,\n        essentialProperties,\n        supplementalProperties,\n        cacheKey,\n         C.LENGTH_UNSET);\n  } else if (segmentBase instanceof MultiSegmentBase) {\n    return new MultiSegmentRepresentation(\n        revisionId,\n        format,\n        baseUrls,\n        (MultiSegmentBase) segmentBase,\n        inbandEventStreams,\n        essentialProperties,\n        supplementalProperties);\n  } else {\n    throw new IllegalArgumentException(\n        \"segmentBase must be of type SingleSegmentBase or \" + \"MultiSegmentBase\");\n  }\n}", "summary_tokens": ["constructs", "a", "new", "instance"], "project": "ExoPlayer"}
{"id": 726, "code": "public MediaPeriodInfo copyWithRequestedContentPositionUs(long requestedContentPositionUs) {\n  return requestedContentPositionUs == this.requestedContentPositionUs\n      ? this\n      : new MediaPeriodInfo(\n          id,\n          startPositionUs,\n          requestedContentPositionUs,\n          endPositionUs,\n          durationUs,\n          isFollowedByTransitionToSameStream,\n          isLastInTimelinePeriod,\n          isLastInTimelineWindow,\n          isFinal);\n}", "summary_tokens": ["returns", "a", "copy", "of", "this", "instance", "with", "the", "requested", "content", "position", "set", "to", "the", "specified", "value"], "project": "ExoPlayer"}
{"id": 874, "code": "default void onAudioDecoderReleased(EventTime eventTime, String decoderName) {}", "summary_tokens": ["called", "when", "an", "audio", "renderer", "releases", "a", "decoder"], "project": "ExoPlayer"}
{"id": 2488, "code": "public boolean isVisible() {\n  return getVisibility() == VISIBLE;\n}", "summary_tokens": ["returns", "whether", "the", "controller", "is", "currently", "visible"], "project": "ExoPlayer"}
{"id": 1882, "code": "public static boolean readFullyQuietly(\n    ExtractorInput input, byte[] output, int offset, int length) throws IOException {\n  try {\n    input.readFully(output, offset, length);\n  } catch (EOFException e) {\n    return false;\n  }\n  return true;\n}", "summary_tokens": ["equivalent", "to", "extractor", "input", "read", "fully", "byte", "int", "int", "except", "that", "it", "returns", "false", "instead", "of", "throwing", "an", "eofexception", "if", "the", "end", "of", "input", "is", "encountered", "without", "having", "fully", "satisfied", "the", "read"], "project": "ExoPlayer"}
{"id": 256, "code": "public void addMediaItem(int index, MediaItem mediaItem) {\n  player.addMediaItem(index, mediaItem);\n}", "summary_tokens": ["calls", "player", "add", "media", "item", "int", "media", "item", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1869, "code": "public synchronized DefaultExtractorsFactory setConstantBitrateSeekingAlwaysEnabled(\n    boolean constantBitrateSeekingAlwaysEnabled) {\n  this.constantBitrateSeekingAlwaysEnabled = constantBitrateSeekingAlwaysEnabled;\n  return this;\n}", "summary_tokens": ["convenience", "method", "to", "set", "whether", "approximate", "seeking", "using", "constant", "bitrate", "assumptions", "should", "be", "enabled", "for", "all", "extractors", "that", "support", "it", "and", "if", "it", "should", "be", "enabled", "even", "if", "the", "content", "length", "and", "hence", "the", "duration", "of", "the", "media", "is", "unknown"], "project": "ExoPlayer"}
{"id": 2683, "code": "public void blockUntilInitialized() throws InterruptedException {\n  assertThat(initializedCondition.block(TIMEOUT_MS)).isTrue();\n}", "summary_tokens": ["blocks", "until", "the", "manager", "is", "initialized"], "project": "ExoPlayer"}
{"id": 1633, "code": "public void selectAudioTracks_withinCapabilities_andDifferentLanguage_selectsFirstTrack()\n    throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format firstLanguageFormat = formatBuilder.setAverageBitrate(15000).setLanguage(\"hi\").build();\n  Format higherBitrateFormat = formatBuilder.setAverageBitrate(30000).setLanguage(\"te\").build();\n  TrackGroupArray trackGroups = wrapFormats(firstLanguageFormat, higherBitrateFormat);\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_SUPPORTED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, firstLanguageFormat);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "select", "the", "first", "audio", "track", "even", "if", "other", "tracks", "with", "a", "different", "language", "have", "higher", "bit", "rates", "all", "other", "factors", "are", "the", "same", "and", "tracks", "are", "within", "renderer", "s", "capabilities"], "project": "ExoPlayer"}
{"id": 1362, "code": "public void discardFrom(int discardFromKey) {\n  for (int i = spans.size() - 1; i >= 0 && discardFromKey < spans.keyAt(i); i--) {\n    removeCallback.accept(spans.valueAt(i));\n    spans.removeAt(i);\n  }\n  memoizedReadIndex = spans.size() > 0 ? min(memoizedReadIndex, spans.size() - 1) : C.INDEX_UNSET;\n}", "summary_tokens": ["discard", "the", "spans", "from", "the", "end", "back", "to", "discard", "from", "key"], "project": "ExoPlayer"}
{"id": 1894, "code": "private static boolean checkAndReadSampleRate(\n    ParsableByteArray data, FlacStreamMetadata flacStreamMetadata, int sampleRateKey) {\n  int expectedSampleRate = flacStreamMetadata.sampleRate;\n  if (sampleRateKey == 0) {\n    return true;\n  } else if (sampleRateKey <= 11) {\n    return sampleRateKey == flacStreamMetadata.sampleRateLookupKey;\n  } else if (sampleRateKey == 12) {\n    return data.readUnsignedByte() * 1000 == expectedSampleRate;\n  } else if (sampleRateKey <= 14) {\n    int sampleRate = data.readUnsignedShort();\n    if (sampleRateKey == 14) {\n      sampleRate *= 10;\n    }\n    return sampleRate == expectedSampleRate;\n  } else {\n    return false;\n  }\n}", "summary_tokens": ["checks", "whether", "the", "given", "sample", "rate", "key", "and", "sample", "rate", "bits", "are", "valid", "and", "if", "so", "reads", "the", "sample", "rate", "bits"], "project": "ExoPlayer"}
{"id": 851, "code": "default void onPlayerErrorChanged(EventTime eventTime, @Nullable PlaybackException error) {}", "summary_tokens": ["called", "when", "the", "playback", "exception", "returned", "by", "player", "get", "player", "error", "changes"], "project": "ExoPlayer"}
{"id": 2790, "code": "public LoadControl getLoadControl() {\n  return loadControl;\n}", "summary_tokens": ["returns", "the", "load", "control", "that", "will", "be", "used", "by", "the", "player"], "project": "ExoPlayer"}
{"id": 1682, "code": "public String resolveUriString(String baseUri) {\n  return UriUtil.resolve(baseUri, referenceUri);\n}", "summary_tokens": ["returns", "the", "resolved", "uri", "represented", "by", "the", "instance", "as", "a", "string"], "project": "ExoPlayer"}
{"id": 2509, "code": "public final void invalidate() {\n  if (isNotificationStarted) {\n    postStartOrUpdateNotification();\n  }\n}", "summary_tokens": ["forces", "an", "update", "of", "the", "notification", "if", "already", "started"], "project": "ExoPlayer"}
{"id": 1435, "code": "public long getRetryDelayMsFor(LoadErrorInfo loadErrorInfo) {\n  IOException exception = loadErrorInfo.exception;\n  return exception instanceof ParserException\n          || exception instanceof FileNotFoundException\n          || exception instanceof CleartextNotPermittedException\n          || exception instanceof UnexpectedLoaderException\n          || DataSourceException.isCausedByPositionOutOfRange(exception)\n      ? C.TIME_UNSET\n      : min((loadErrorInfo.errorCount - 1) * 1000, 5000);\n}", "summary_tokens": ["retries", "for", "any", "exception", "that", "is", "not", "a", "subclass", "of", "parser", "exception", "file", "not", "found", "exception", "cleartext", "not", "permitted", "exception", "or", "unexpected", "loader", "exception", "and", "for", "which", "data", "source", "exception", "is", "caused", "by", "position", "out", "of", "range", "returns", "false"], "project": "ExoPlayer"}
{"id": 2748, "code": "public List<Format> getFormatsRead() {\n  return Collections.unmodifiableList(formatsRead);\n}", "summary_tokens": ["returns", "the", "list", "of", "formats", "read", "by", "the", "renderer"], "project": "ExoPlayer"}
{"id": 1059, "code": "default void onDrmKeysLoaded(int windowIndex, @Nullable MediaPeriodId mediaPeriodId) {}", "summary_tokens": ["called", "each", "time", "keys", "are", "loaded"], "project": "ExoPlayer"}
{"id": 47, "code": "", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "does", "nothing"], "project": "ExoPlayer"}
{"id": 2429, "code": "private void enterNextSegment() {\n  if (currentSegmentInfo != null) {\n    leaveCurrentSegment();\n  }\n  currentSegmentInfo = nextSegmentInfo;\n  nextSegmentInfo =\n      segmentIterator.hasNext()\n          ? new SegmentInfo(segmentIterator.next(), inputMaxLayer, normalSpeedMaxLayer)\n          : null;\n}", "summary_tokens": ["updates", "the", "segments", "information", "so", "that", "the", "next", "segment", "becomes", "the", "current", "segment"], "project": "ExoPlayer"}
{"id": 2417, "code": "public void addTrackFormat(Format format) throws Muxer.MuxerException {\n  checkState(trackCount > 0, \"All tracks should be registered before the formats are added.\");\n  checkState(trackFormatCount < trackCount, \"All track formats have already been added.\");\n  @Nullable String sampleMimeType = format.sampleMimeType;\n  boolean isAudio = MimeTypes.isAudio(sampleMimeType);\n  boolean isVideo = MimeTypes.isVideo(sampleMimeType);\n  checkState(isAudio || isVideo, \"Unsupported track format: \" + sampleMimeType);\n  @C.TrackType int trackType = MimeTypes.getTrackType(sampleMimeType);\n  checkState(\n      trackTypeToIndex.get(trackType,  C.INDEX_UNSET) == C.INDEX_UNSET,\n      \"There is already a track of type \" + trackType);\n\n  int trackIndex = muxer.addTrack(format);\n  trackTypeToIndex.put(trackType, trackIndex);\n  trackTypeToSampleCount.put(trackType, 0);\n  trackTypeToTimeUs.put(trackType, 0L);\n  trackTypeToBytesWritten.put(trackType, 0L);\n  trackFormatCount++;\n  if (trackFormatCount == trackCount) {\n    isReady = true;\n  }\n}", "summary_tokens": ["adds", "a", "track", "format", "to", "the", "muxer"], "project": "ExoPlayer"}
{"id": 2426, "code": "public boolean dropOrTransformSample(ByteBuffer buffer, long bufferTimeUs) {\n  if (slowMotionData == null) {\n      \n    lastSamplePresentationTimeUs = bufferTimeUs;\n    return false;\n  }\n\n  int originalPosition = buffer.position();\n  buffer.position(originalPosition + NAL_START_CODE_LENGTH);\n  buffer.get(scratch, 0, 4); \n  int nalUnitType = scratch[0] & 0x1F;\n  boolean svcExtensionFlag = ((scratch[1] & 0xFF) >> 7) == 1;\n  checkState(\n      nalUnitType == NAL_UNIT_TYPE_PREFIX && svcExtensionFlag,\n      \"Missing SVC extension prefix NAL unit.\");\n  int layer = (scratch[3] & 0xFF) >> 5;\n  boolean shouldKeepFrame = processCurrentFrame(layer, bufferTimeUs);\n    \n    \n  lastSamplePresentationTimeUs = getCurrentFrameOutputTimeUs(bufferTimeUs);\n  if (shouldKeepFrame) {\n    buffer.position(originalPosition);\n    return false;\n  }\n  return true;\n}", "summary_tokens": ["applies", "slow", "motion", "flattening", "by", "either", "indicating", "that", "the", "buffer", "s", "data", "should", "be", "dropped", "or", "transforming", "it", "in", "place"], "project": "ExoPlayer"}
{"id": 2781, "code": "public TrackGroupArray getCurrentTrackGroups() {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["use", "get", "current", "tracks"], "project": "ExoPlayer"}
{"id": 1638, "code": "public void selectTracksExceedingCapabilitiesSelectLowerBitrate() throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format lowerBitrateFormat = formatBuilder.setAverageBitrate(15000).build();\n  Format higherBitrateFormat = formatBuilder.setAverageBitrate(30000).build();\n  TrackGroupArray trackGroups = wrapFormats(lowerBitrateFormat, higherBitrateFormat);\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_EXCEEDED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, lowerBitrateFormat);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "select", "audio", "tracks", "with", "lower", "bit", "rate", "when", "other", "factors", "are", "the", "same", "and", "tracks", "exceed", "renderer", "s", "capabilities"], "project": "ExoPlayer"}
{"id": 1893, "code": "private static boolean checkAndReadBlockSizeSamples(\n    ParsableByteArray data, FlacStreamMetadata flacStreamMetadata, int blockSizeKey) {\n  int blockSizeSamples = readFrameBlockSizeSamplesFromKey(data, blockSizeKey);\n  return blockSizeSamples != -1 && blockSizeSamples <= flacStreamMetadata.maxBlockSizeSamples;\n}", "summary_tokens": ["checks", "whether", "the", "given", "frame", "block", "size", "key", "and", "block", "size", "bits", "are", "valid", "and", "if", "so", "reads", "the", "block", "size", "bits"], "project": "ExoPlayer"}
{"id": 1166, "code": "private static boolean codecNeedsEosBufferTimestampWorkaround(String codecName) {\n  return Util.SDK_INT < 21\n      && \"OMX.SEC.mp3.dec\".equals(codecName)\n      && \"samsung\".equals(Util.MANUFACTURER)\n      && (Util.DEVICE.startsWith(\"baffin\")\n          || Util.DEVICE.startsWith(\"grand\")\n          || Util.DEVICE.startsWith(\"fortuna\")\n          || Util.DEVICE.startsWith(\"gprimelte\")\n          || Util.DEVICE.startsWith(\"j2y18lte\")\n          || Util.DEVICE.startsWith(\"ms01\"));\n}", "summary_tokens": ["returns", "whether", "the", "decoder", "may", "output", "a", "non", "empty", "buffer", "with", "timestamp", "0", "as", "the", "end", "of", "stream", "buffer"], "project": "ExoPlayer"}
{"id": 1222, "code": "public static Intent buildRemoveDownloadIntent(\n    Context context, Class<? extends DownloadService> clazz, String id, boolean foreground) {\n  return getIntent(context, clazz, ACTION_REMOVE_DOWNLOAD, foreground)\n      .putExtra(KEY_CONTENT_ID, id);\n}", "summary_tokens": ["builds", "an", "intent", "for", "removing", "the", "download", "with", "the", "id"], "project": "ExoPlayer"}
{"id": 104, "code": "public void addListenerWithAdView(EventListener eventListener, AdViewProvider adViewProvider) {\n  boolean isStarted = !eventListeners.isEmpty();\n  eventListeners.add(eventListener);\n  if (isStarted) {\n    if (!AdPlaybackState.NONE.equals(adPlaybackState)) {\n        \n      eventListener.onAdPlaybackState(adPlaybackState);\n    }\n    return;\n  }\n  lastVolumePercent = 0;\n  lastAdProgress = VideoProgressUpdate.VIDEO_TIME_NOT_READY;\n  lastContentProgress = VideoProgressUpdate.VIDEO_TIME_NOT_READY;\n  maybeNotifyPendingAdLoadError();\n  if (!AdPlaybackState.NONE.equals(adPlaybackState)) {\n      \n    eventListener.onAdPlaybackState(adPlaybackState);\n  } else if (adsManager != null) {\n    adPlaybackState =\n        new AdPlaybackState(adsId, getAdGroupTimesUsForCuePoints(adsManager.getAdCuePoints()));\n    updateAdPlaybackState();\n  }\n  for (AdOverlayInfo overlayInfo : adViewProvider.getAdOverlayInfos()) {\n    adDisplayContainer.registerFriendlyObstruction(\n        imaFactory.createFriendlyObstruction(\n            overlayInfo.view,\n            ImaUtil.getFriendlyObstructionPurpose(overlayInfo.purpose),\n            overlayInfo.reasonDetail));\n  }\n}", "summary_tokens": ["starts", "passing", "events", "from", "this", "instance", "including", "any", "pending", "ad", "playback", "state", "and", "registers", "obstructions"], "project": "ExoPlayer"}
{"id": 176, "code": "public void setRatingCallback(@Nullable RatingCallback ratingCallback) {\n  if (this.ratingCallback != ratingCallback) {\n    unregisterCommandReceiver(this.ratingCallback);\n    this.ratingCallback = ratingCallback;\n    registerCommandReceiver(this.ratingCallback);\n  }\n}", "summary_tokens": ["sets", "the", "rating", "callback", "to", "handle", "user", "ratings"], "project": "ExoPlayer"}
{"id": 1456, "code": "public final void stop() {\n  if (!started) {\n    return;\n  }\n  started = false;\n  player.removeListener(updater);\n  textView.removeCallbacks(updater);\n}", "summary_tokens": ["stops", "periodic", "updates", "of", "the", "text", "view"], "project": "ExoPlayer"}
{"id": 1444, "code": "public void cancelLoading() {\n  Assertions.checkStateNotNull(currentTask).cancel(false);\n}", "summary_tokens": ["cancels", "the", "current", "load"], "project": "ExoPlayer"}
{"id": 2772, "code": "public Timeline assertTimelineChangeBlocking() {\n  try {\n    timeline = timelines.poll(TIMEOUT_MS, MILLISECONDS);\n    assertThat(timeline).isNotNull(); \n    assertNoTimelineChange();\n    return timeline;\n  } catch (InterruptedException e) {\n      \n    throw new RuntimeException(e);\n  }\n}", "summary_tokens": ["asserts", "that", "the", "source", "notifies", "its", "listener", "of", "a", "single", "timeline", "change"], "project": "ExoPlayer"}
{"id": 469, "code": "public int getAttributeArrayLocationAndEnable(String attributeName) {\n  int location = getAttributeLocation(attributeName);\n  GLES20.glEnableVertexAttribArray(location);\n  GlUtil.checkGlError();\n  return location;\n}", "summary_tokens": ["returns", "the", "location", "of", "an", "attribute", "which", "has", "been", "enabled", "as", "a", "vertex", "attribute", "array"], "project": "ExoPlayer"}
{"id": 1617, "code": "public void selectTracksSelectTrackWithSelectionFlag() throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format audioFormat = formatBuilder.setSelectionFlags(0).build();\n  Format formatWithSelectionFlag =\n      formatBuilder.setSelectionFlags(C.SELECTION_FLAG_DEFAULT).build();\n  TrackGroupArray trackGroups = wrapFormats(audioFormat, formatWithSelectionFlag);\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_SUPPORTED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, formatWithSelectionFlag);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "select", "audio", "track", "with", "c", "selection", "flag", "default", "given", "default", "values", "of", "parameters"], "project": "ExoPlayer"}
{"id": 1917, "code": "public boolean hasGaplessInfo() {\n  return encoderDelay != Format.NO_VALUE && encoderPadding != Format.NO_VALUE;\n}", "summary_tokens": ["returns", "whether", "encoder", "delay", "and", "encoder", "padding", "have", "been", "set"], "project": "ExoPlayer"}
{"id": 1659, "code": "public BaseUrl selectBaseUrl(List<BaseUrl> baseUrls) {\n  List<BaseUrl> includedBaseUrls = applyExclusions(baseUrls);\n  if (includedBaseUrls.size() < 2) {\n    return Iterables.getFirst(includedBaseUrls,  null);\n  }\n    \n  Collections.sort(includedBaseUrls, BaseUrlExclusionList::compareBaseUrl);\n    \n  List<Pair<String, Integer>> candidateKeys = new ArrayList<>();\n  int lowestPriority = includedBaseUrls.get(0).priority;\n  for (int i = 0; i < includedBaseUrls.size(); i++) {\n    BaseUrl baseUrl = includedBaseUrls.get(i);\n    if (lowestPriority != baseUrl.priority) {\n      if (candidateKeys.size() == 1) {\n          \n        return includedBaseUrls.get(0);\n      }\n      break;\n    }\n    candidateKeys.add(new Pair<>(baseUrl.serviceLocation, baseUrl.weight));\n  }\n    \n  @Nullable BaseUrl baseUrl = selectionsTaken.get(candidateKeys);\n  if (baseUrl == null) {\n      \n    baseUrl = selectWeighted(includedBaseUrls.subList(0, candidateKeys.size()));\n      \n    selectionsTaken.put(candidateKeys, baseUrl);\n  }\n  return baseUrl;\n}", "summary_tokens": ["selects", "the", "base", "url", "to", "use", "from", "the", "given", "list"], "project": "ExoPlayer"}
{"id": 804, "code": "static @AdaptiveSupport int getAdaptiveSupport(@Capabilities int supportFlags) {\n  return supportFlags & ADAPTIVE_SUPPORT_MASK;\n}", "summary_tokens": ["returns", "the", "adaptive", "support", "from", "the", "combined", "capabilities"], "project": "ExoPlayer"}
{"id": 120, "code": "public ImaServerSideAdInsertionUriBuilder setAuthToken(@Nullable String authToken) {\n  this.authToken = authToken;\n  return this;\n}", "summary_tokens": ["sets", "the", "stream", "request", "authorization", "token"], "project": "ExoPlayer"}
{"id": 255, "code": "public void setMediaItem(MediaItem mediaItem, boolean resetPosition) {\n  player.setMediaItem(mediaItem, resetPosition);\n}", "summary_tokens": ["calls", "player", "set", "media", "item", "media", "item", "boolean", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1419, "code": "public void setParameters(TrackSelectionParameters parameters) {\n    \n}", "summary_tokens": ["called", "by", "the", "player", "to", "provide", "parameters", "for", "track", "selection"], "project": "ExoPlayer"}
{"id": 912, "code": "public long getTotalPlayTimeMs() {\n  return getPlaybackStateDurationMs(PLAYBACK_STATE_PLAYING);\n}", "summary_tokens": ["returns", "the", "total", "time", "spent", "actively", "playing", "in", "milliseconds"], "project": "ExoPlayer"}
{"id": 163, "code": "public static AudioAttributes getAudioAttributes(AudioAttributesCompat audioAttributesCompat) {\n  return new AudioAttributes.Builder()\n      .setContentType(audioAttributesCompat.getContentType())\n      .setFlags(audioAttributesCompat.getFlags())\n      .setUsage(audioAttributesCompat.getUsage())\n      .build();\n}", "summary_tokens": ["returns", "exo", "player", "audio", "attributes", "for", "the", "given", "audio", "attributes"], "project": "ExoPlayer"}
{"id": 425, "code": "public OutputStream startWrite() throws IOException {\n    \n  if (baseName.exists()) {\n    if (!backupName.exists()) {\n      if (!baseName.renameTo(backupName)) {\n        Log.w(TAG, \"Couldn't rename file \" + baseName + \" to backup file \" + backupName);\n      }\n    } else {\n      baseName.delete();\n    }\n  }\n  OutputStream str;\n  try {\n    str = new AtomicFileOutputStream(baseName);\n  } catch (FileNotFoundException e) {\n    File parent = baseName.getParentFile();\n    if (parent == null || !parent.mkdirs()) {\n      throw new IOException(\"Couldn't create \" + baseName, e);\n    }\n      \n    try {\n      str = new AtomicFileOutputStream(baseName);\n    } catch (FileNotFoundException e2) {\n      throw new IOException(\"Couldn't create \" + baseName, e2);\n    }\n  }\n  return str;\n}", "summary_tokens": ["start", "a", "new", "write", "operation", "on", "the", "file"], "project": "ExoPlayer"}
{"id": 2730, "code": "public void resetProvisioning() {\n  provisionsReceived = 0;\n}", "summary_tokens": ["resets", "the", "provisioning", "state", "of", "this", "instance", "so", "it", "requires", "builder", "set", "provisions", "required", "int", "provisions", "required", "possibly", "zero", "provision", "operations", "before", "it", "s", "operational", "again"], "project": "ExoPlayer"}
{"id": 2400, "code": "public void signalEndOfInputStream() {\n  inputStreamEnded = true;\n}", "summary_tokens": ["informs", "the", "frame", "processor", "chain", "that", "no", "further", "input", "frames", "should", "be", "accepted"], "project": "ExoPlayer"}
{"id": 982, "code": "public boolean hasAdvancingTimestamp() {\n  return state == STATE_TIMESTAMP_ADVANCING;\n}", "summary_tokens": ["returns", "whether", "this", "instance", "has", "an", "advancing", "timestamp"], "project": "ExoPlayer"}
{"id": 374, "code": "public long getMediaTimeUsForPlayoutTimeMs(long timeMs) {\n  return timeMs * scaledUsPerMs;\n}", "summary_tokens": ["returns", "the", "media", "time", "in", "microseconds", "that", "will", "elapse", "in", "time", "ms", "milliseconds", "of", "wallclock", "time"], "project": "ExoPlayer"}
{"id": 1564, "code": "private static ArgumentMatcher<Timeline> noUid(Timeline timeline) {\n  return argument -> timelinesAreSame(argument, timeline);\n}", "summary_tokens": ["returns", "an", "argument", "matcher", "for", "timeline", "instances", "that", "ignores", "period", "and", "window", "uids"], "project": "ExoPlayer"}
{"id": 43, "code": "public int getDeviceVolume() {\n  return 0;\n}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "always", "returns", "0"], "project": "ExoPlayer"}
{"id": 1158, "code": "private boolean drmNeedsCodecReinitialization(\n    MediaCodecInfo codecInfo,\n    Format newFormat,\n    @Nullable DrmSession oldSession,\n    @Nullable DrmSession newSession)\n    throws ExoPlaybackException {\n  if (oldSession == newSession) {\n      \n    return false;\n  }\n\n    \n\n  if (newSession == null || oldSession == null) {\n      \n    return true;\n  }\n\n    \n\n  if (Util.SDK_INT < 23) {\n      \n      \n    return true;\n  }\n  if (C.PLAYREADY_UUID.equals(oldSession.getSchemeUuid())\n      || C.PLAYREADY_UUID.equals(newSession.getSchemeUuid())) {\n      \n      \n      \n    return true;\n  }\n  @Nullable FrameworkCryptoConfig newCryptoConfig = getFrameworkCryptoConfig(newSession);\n  if (newCryptoConfig == null) {\n      \n      \n      \n      \n      \n      \n      \n    return true;\n  }\n\n  boolean requiresSecureDecoder;\n  if (newCryptoConfig.forceAllowInsecureDecoderComponents) {\n    requiresSecureDecoder = false;\n  } else {\n    requiresSecureDecoder = newSession.requiresSecureDecoder(newFormat.sampleMimeType);\n  }\n  if (!codecInfo.secure && requiresSecureDecoder) {\n      \n      \n    return true;\n  }\n\n  return false;\n}", "summary_tokens": ["returns", "whether", "it", "s", "necessary", "to", "re", "initialize", "the", "codec", "to", "handle", "a", "drm", "change"], "project": "ExoPlayer"}
{"id": 441, "code": "public static String buildHevcCodecString(\n    int generalProfileSpace,\n    boolean generalTierFlag,\n    int generalProfileIdc,\n    int generalProfileCompatibilityFlags,\n    int[] constraintBytes,\n    int generalLevelIdc) {\n  StringBuilder builder =\n      new StringBuilder(\n          Util.formatInvariant(\n              \"hvc1.%s%d.%X.%c%d\",\n              HEVC_GENERAL_PROFILE_SPACE_STRINGS[generalProfileSpace],\n              generalProfileIdc,\n              generalProfileCompatibilityFlags,\n              generalTierFlag ? 'H' : 'L',\n              generalLevelIdc));\n    \n  int trailingZeroIndex = constraintBytes.length;\n  while (trailingZeroIndex > 0 && constraintBytes[trailingZeroIndex - 1] == 0) {\n    trailingZeroIndex--;\n  }\n  for (int i = 0; i < trailingZeroIndex; i++) {\n    builder.append(String.format(\".%02X\", constraintBytes[i]));\n  }\n  return builder.toString();\n}", "summary_tokens": ["builds", "an", "rfc", "0", "hevc", "codec", "string", "using", "the", "provided", "parameters"], "project": "ExoPlayer"}
{"id": 2800, "code": "public Looper getLooper() {\n  return looper;\n}", "summary_tokens": ["returns", "the", "looper", "that", "will", "be", "used", "by", "the", "player", "or", "null", "if", "no", "looper", "has", "been", "set", "yet", "and", "no", "default", "is", "available"], "project": "ExoPlayer"}
{"id": 1214, "code": "public void removeDownload(String id) {\n  pendingMessages++;\n  internalHandler.obtainMessage(MSG_REMOVE_DOWNLOAD, id).sendToTarget();\n}", "summary_tokens": ["cancels", "the", "download", "with", "the", "id", "and", "removes", "all", "downloaded", "data"], "project": "ExoPlayer"}
{"id": 1672, "code": "public static String resolveCacheKey(Representation representation, RangedUri rangedUri) {\n  @Nullable String cacheKey = representation.getCacheKey();\n  return cacheKey != null\n      ? cacheKey\n      : rangedUri.resolveUri(representation.baseUrls.get(0).url).toString();\n}", "summary_tokens": ["resolves", "the", "cache", "key", "to", "be", "used", "when", "requesting", "the", "given", "ranged", "uri", "for", "the", "given", "representation"], "project": "ExoPlayer"}
{"id": 1786, "code": "private SimpleCacheSpan touchSpan(String key, SimpleCacheSpan span) {\n  if (!touchCacheSpans) {\n    return span;\n  }\n  String fileName = Assertions.checkNotNull(span.file).getName();\n  long length = span.length;\n  long lastTouchTimestamp = System.currentTimeMillis();\n  boolean updateFile = false;\n  if (fileIndex != null) {\n    try {\n      fileIndex.set(fileName, length, lastTouchTimestamp);\n    } catch (IOException e) {\n      Log.w(TAG, \"Failed to update index with new touch timestamp.\");\n    }\n  } else {\n      \n      \n    updateFile = true;\n  }\n  SimpleCacheSpan newSpan =\n      contentIndex.get(key).setLastTouchTimestamp(span, lastTouchTimestamp, updateFile);\n  notifySpanTouched(span, newSpan);\n  return newSpan;\n}", "summary_tokens": ["touches", "a", "cache", "span", "returning", "the", "updated", "result"], "project": "ExoPlayer"}
{"id": 1188, "code": "public boolean isTerminalState() {\n  return state == STATE_COMPLETED || state == STATE_FAILED;\n}", "summary_tokens": ["returns", "whether", "the", "download", "is", "completed", "or", "failed"], "project": "ExoPlayer"}
{"id": 365, "code": "public static ParserException createForMalformedDataOfUnknownType(\n    @Nullable String message, @Nullable Throwable cause) {\n  return new ParserException(message, cause,  true, C.DATA_TYPE_UNKNOWN);\n}", "summary_tokens": ["creates", "a", "new", "instance", "for", "which", "content", "is", "malformed", "is", "true", "and", "data", "type", "is", "c", "data", "type", "unknown"], "project": "ExoPlayer"}
{"id": 297, "code": "public void next() {\n  player.next();\n}", "summary_tokens": ["calls", "player", "next", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 2171, "code": "public static void discardToSps(ByteBuffer data) {\n  int length = data.position();\n  int consecutiveZeros = 0;\n  int offset = 0;\n  while (offset + 1 < length) {\n    int value = data.get(offset) & 0xFF;\n    if (consecutiveZeros == 3) {\n      if (value == 1 && (data.get(offset + 1) & 0x1F) == H264_NAL_UNIT_TYPE_SPS) {\n          \n        ByteBuffer offsetData = data.duplicate();\n        offsetData.position(offset - 3);\n        offsetData.limit(length);\n        data.position(0);\n        data.put(offsetData);\n        return;\n      }\n    } else if (value == 0) {\n      consecutiveZeros++;\n    }\n    if (value != 0) {\n      consecutiveZeros = 0;\n    }\n    offset++;\n  }\n    \n  data.clear();\n}", "summary_tokens": ["discards", "data", "from", "the", "buffer", "up", "to", "the", "first", "sps", "where", "data"], "project": "ExoPlayer"}
{"id": 1213, "code": "public void addDownload(DownloadRequest request, int stopReason) {\n  pendingMessages++;\n  internalHandler\n      .obtainMessage(MSG_ADD_DOWNLOAD, stopReason,  0, request)\n      .sendToTarget();\n}", "summary_tokens": ["adds", "a", "download", "defined", "by", "the", "given", "request", "and", "with", "the", "specified", "stop", "reason"], "project": "ExoPlayer"}
{"id": 192, "code": "private void skipFully(long bytesToSkip, DataSpec dataSpec) throws HttpDataSourceException {\n  if (bytesToSkip == 0) {\n    return;\n  }\n  byte[] skipBuffer = new byte[4096];\n  try {\n    while (bytesToSkip > 0) {\n      int readLength = (int) min(bytesToSkip, skipBuffer.length);\n      int read = castNonNull(responseByteStream).read(skipBuffer, 0, readLength);\n      if (Thread.currentThread().isInterrupted()) {\n        throw new InterruptedIOException();\n      }\n      if (read == -1) {\n        throw new HttpDataSourceException(\n            dataSpec,\n            PlaybackException.ERROR_CODE_IO_READ_POSITION_OUT_OF_RANGE,\n            HttpDataSourceException.TYPE_OPEN);\n      }\n      bytesToSkip -= read;\n      bytesTransferred(read);\n    }\n    return;\n  } catch (IOException e) {\n    if (e instanceof HttpDataSourceException) {\n      throw (HttpDataSourceException) e;\n    } else {\n      throw new HttpDataSourceException(\n          dataSpec,\n          PlaybackException.ERROR_CODE_IO_UNSPECIFIED,\n          HttpDataSourceException.TYPE_OPEN);\n    }\n  }\n}", "summary_tokens": ["attempts", "to", "skip", "the", "specified", "number", "of", "bytes", "in", "full"], "project": "ExoPlayer"}
{"id": 1325, "code": "public final void discardUpstreamSamples(int discardFromIndex) {\n  sampleDataQueue.discardUpstreamSampleBytes(discardUpstreamSampleMetadata(discardFromIndex));\n}", "summary_tokens": ["discards", "samples", "from", "the", "write", "side", "of", "the", "queue"], "project": "ExoPlayer"}
{"id": 1176, "code": "public static String getAlternativeCodecMimeType(Format format) {\n  if (MimeTypes.AUDIO_E_AC3_JOC.equals(format.sampleMimeType)) {\n      \n    return MimeTypes.AUDIO_E_AC3;\n  }\n  if (MimeTypes.VIDEO_DOLBY_VISION.equals(format.sampleMimeType)) {\n      \n      \n      \n      \n    @Nullable\n    Pair<Integer, Integer> codecProfileAndLevel = MediaCodecUtil.getCodecProfileAndLevel(format);\n    if (codecProfileAndLevel != null) {\n      int profile = codecProfileAndLevel.first;\n      if (profile == CodecProfileLevel.DolbyVisionProfileDvheDtr\n          || profile == CodecProfileLevel.DolbyVisionProfileDvheSt) {\n        return MimeTypes.VIDEO_H265;\n      } else if (profile == CodecProfileLevel.DolbyVisionProfileDvavSe) {\n        return MimeTypes.VIDEO_H264;\n      }\n    }\n  }\n  return null;\n}", "summary_tokens": ["returns", "an", "alternative", "codec", "mime", "type", "besides", "the", "default", "format", "sample", "mime", "type", "that", "can", "be", "used", "to", "decode", "samples", "of", "the", "provided", "format"], "project": "ExoPlayer"}
{"id": 298, "code": "public void seekToNextWindow() {\n  player.seekToNextWindow();\n}", "summary_tokens": ["calls", "player", "seek", "to", "next", "window", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 2091, "code": "private static long readPcrValueFromPcrBytes(byte[] pcrBytes) {\n  return (pcrBytes[0] & 0xFFL) << 25\n      | (pcrBytes[1] & 0xFFL) << 17\n      | (pcrBytes[2] & 0xFFL) << 9\n      | (pcrBytes[3] & 0xFFL) << 1\n      | (pcrBytes[4] & 0xFFL) >> 7;\n}", "summary_tokens": ["returns", "the", "value", "of", "pcr", "base", "first", "0", "bits", "in", "big", "endian", "order", "from", "the", "pcr", "bytes"], "project": "ExoPlayer"}
{"id": 1870, "code": "public synchronized DefaultExtractorsFactory setAdtsExtractorFlags(\n    @AdtsExtractor.Flags int flags) {\n  this.adtsFlags = flags;\n  return this;\n}", "summary_tokens": ["sets", "flags", "for", "adts", "extractor", "instances", "created", "by", "the", "factory"], "project": "ExoPlayer"}
{"id": 1808, "code": "public final boolean hasSupplementalData() {\n  return getFlag(C.BUFFER_FLAG_HAS_SUPPLEMENTAL_DATA);\n}", "summary_tokens": ["returns", "whether", "the", "c", "buffer", "flag", "has", "supplemental", "data", "flag", "is", "set"], "project": "ExoPlayer"}
{"id": 1356, "code": "private long getLargestTimestamp(int length) {\n  if (length == 0) {\n    return Long.MIN_VALUE;\n  }\n  long largestTimestampUs = Long.MIN_VALUE;\n  int relativeSampleIndex = getRelativeIndex(length - 1);\n  for (int i = 0; i < length; i++) {\n    largestTimestampUs = max(largestTimestampUs, timesUs[relativeSampleIndex]);\n    if ((flags[relativeSampleIndex] & C.BUFFER_FLAG_KEY_FRAME) != 0) {\n      break;\n    }\n    relativeSampleIndex--;\n    if (relativeSampleIndex == -1) {\n      relativeSampleIndex = capacity - 1;\n    }\n  }\n  return largestTimestampUs;\n}", "summary_tokens": ["finds", "the", "largest", "timestamp", "of", "any", "sample", "from", "the", "start", "of", "the", "queue", "up", "to", "the", "specified", "length", "assuming", "that", "the", "timestamps", "prior", "to", "a", "keyframe", "are", "always", "less", "than", "the", "timestamp", "of", "the", "keyframe", "itself", "and", "of", "subsequent", "frames"], "project": "ExoPlayer"}
{"id": 2121, "code": "private static PageComposition parsePageComposition(ParsableBitArray data, int length) {\n  int timeoutSecs = data.readBits(8);\n  int version = data.readBits(4);\n  int state = data.readBits(2);\n  data.skipBits(2);\n  int remainingLength = length - 2;\n\n  SparseArray<PageRegion> regions = new SparseArray<>();\n  while (remainingLength > 0) {\n    int regionId = data.readBits(8);\n    data.skipBits(8); \n    int regionHorizontalAddress = data.readBits(16);\n    int regionVerticalAddress = data.readBits(16);\n    remainingLength -= 6;\n    regions.put(regionId, new PageRegion(regionHorizontalAddress, regionVerticalAddress));\n  }\n\n  return new PageComposition(timeoutSecs, version, state, regions);\n}", "summary_tokens": ["parses", "a", "page", "composition", "segment", "as", "defined", "by", "etsi", "en", "0", "0", "0"], "project": "ExoPlayer"}
{"id": 1170, "code": "public static MediaCodecInfo getDecryptOnlyDecoderInfo() throws DecoderQueryException {\n  return getDecoderInfo(MimeTypes.AUDIO_RAW,  false,  false);\n}", "summary_tokens": ["returns", "information", "about", "a", "decoder", "that", "will", "only", "decrypt", "data", "without", "decoding", "it"], "project": "ExoPlayer"}
{"id": 2569, "code": "public void setShowPreviousButton(boolean showPreviousButton) {\n  controlViewLayoutManager.setShowButton(previousButton, showPreviousButton);\n  updateNavigation();\n}", "summary_tokens": ["sets", "whether", "the", "previous", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 1863, "code": "private int skipFromPeekBuffer(int length) {\n  int bytesSkipped = min(peekBufferLength, length);\n  updatePeekBuffer(bytesSkipped);\n  return bytesSkipped;\n}", "summary_tokens": ["skips", "from", "the", "peek", "buffer"], "project": "ExoPlayer"}
{"id": 938, "code": "public float getRebufferRate() {\n  long playTimeMs = getTotalPlayTimeMs();\n  return playTimeMs == 0 ? 0f : 1000f * totalRebufferCount / playTimeMs;\n}", "summary_tokens": ["returns", "the", "rate", "of", "rebuffer", "events", "in", "rebuffers", "per", "play", "time", "second", "or", "0"], "project": "ExoPlayer"}
{"id": 2305, "code": "public static void checkManifestExpression(boolean expression, @Nullable String message)\n    throws ParserException {\n  if (!expression) {\n    throw ParserException.createForMalformedManifest(message,  null);\n  }\n}", "summary_tokens": ["throws", "parser", "exception", "create", "for", "malformed", "manifest", "parser", "exception", "if", "expression", "evaluates", "to", "false"], "project": "ExoPlayer"}
{"id": 2114, "code": "private boolean skipInput(ExtractorInput input) throws IOException {\n  return input.skip(\n          input.getLength() != C.LENGTH_UNSET\n              ? Ints.checkedCast(input.getLength())\n              : DEFAULT_BUFFER_SIZE)\n      == C.RESULT_END_OF_INPUT;\n}", "summary_tokens": ["returns", "whether", "the", "input", "has", "been", "fully", "skipped"], "project": "ExoPlayer"}
{"id": 1306, "code": "public void rewind() {\n  readAllocationNode = firstAllocationNode;\n}", "summary_tokens": ["rewinds", "the", "read", "position", "to", "the", "first", "sample", "in", "the", "queue"], "project": "ExoPlayer"}
{"id": 2823, "code": "private static double getPsnr(Bitmap firstBitmap, Bitmap secondBitmap) {\n  assertThat(firstBitmap.getWidth()).isEqualTo(secondBitmap.getWidth());\n  assertThat(firstBitmap.getHeight()).isEqualTo(secondBitmap.getHeight());\n  long mse = 0;\n  for (int i = 0; i < firstBitmap.getWidth(); i++) {\n    for (int j = 0; j < firstBitmap.getHeight(); j++) {\n      int firstColorInt = firstBitmap.getPixel(i, j);\n      int firstRed = Color.red(firstColorInt);\n      int firstGreen = Color.green(firstColorInt);\n      int firstBlue = Color.blue(firstColorInt);\n      int secondColorInt = secondBitmap.getPixel(i, j);\n      int secondRed = Color.red(secondColorInt);\n      int secondGreen = Color.green(secondColorInt);\n      int secondBlue = Color.blue(secondColorInt);\n      mse +=\n          ((firstRed - secondRed) * (firstRed - secondRed)\n              + (firstGreen - secondGreen) * (firstGreen - secondGreen)\n              + (firstBlue - secondBlue) * (firstBlue - secondBlue));\n    }\n  }\n  double normalizedMse =\n      mse / (255.0 * 255.0 * 3.0 * firstBitmap.getWidth() * firstBitmap.getHeight());\n  return 10 * Math.log10(1.0 / normalizedMse);\n}", "summary_tokens": ["calculates", "the", "peak", "signal", "to", "noise", "ratio", "value", "for", "0", "bitmaps"], "project": "ExoPlayer"}
{"id": 2148, "code": "public TtmlStyle chain(@Nullable TtmlStyle ancestor) {\n  return inherit(ancestor, true);\n}", "summary_tokens": ["chains", "this", "style", "to", "referential", "style"], "project": "ExoPlayer"}
{"id": 345, "code": "public VideoSize getVideoSize() {\n  return player.getVideoSize();\n}", "summary_tokens": ["calls", "player", "get", "video", "size", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2612, "code": "public int getControllerShowTimeoutMs() {\n  return controllerShowTimeoutMs;\n}", "summary_tokens": ["returns", "the", "playback", "controls", "timeout"], "project": "ExoPlayer"}
{"id": 324, "code": "public long getDuration() {\n  return player.getDuration();\n}", "summary_tokens": ["calls", "player", "get", "duration", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 78, "code": "public static String getVersion() {\n  if (!isAvailable()) {\n    return null;\n  }\n  if (version == null) {\n    version = ffmpegGetVersion();\n  }\n  return version;\n}", "summary_tokens": ["returns", "the", "version", "of", "the", "underlying", "library", "if", "available", "or", "null", "otherwise"], "project": "ExoPlayer"}
{"id": 1080, "code": "public synchronized void releaseLicense(byte[] offlineLicenseKeySetId)\n    throws DrmSessionException {\n  Assertions.checkNotNull(offlineLicenseKeySetId);\n  blockingKeyRequest(\n      DefaultDrmSessionManager.MODE_RELEASE,\n      offlineLicenseKeySetId,\n      FORMAT_WITH_EMPTY_DRM_INIT_DATA);\n}", "summary_tokens": ["releases", "an", "offline", "license"], "project": "ExoPlayer"}
{"id": 280, "code": "public void seekToDefaultPosition(int mediaItemIndex) {\n  player.seekToDefaultPosition(mediaItemIndex);\n}", "summary_tokens": ["calls", "player", "seek", "to", "default", "position", "int", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 338, "code": "public int getCurrentAdIndexInAdGroup() {\n  return player.getCurrentAdIndexInAdGroup();\n}", "summary_tokens": ["calls", "player", "get", "current", "ad", "index", "in", "ad", "group", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 13, "code": "public static boolean willHaveContent(Tracks tracks) {\n  for (Tracks.Group trackGroup : tracks.getGroups()) {\n    if (SUPPORTED_TRACK_TYPES.contains(trackGroup.getType())) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "whether", "a", "track", "selection", "dialog", "will", "have", "content", "to", "display", "if", "initialized", "with", "the", "specified", "tracks"], "project": "ExoPlayer"}
{"id": 1273, "code": "public synchronized void addMediaSources(\n    int index,\n    Collection<MediaSource> mediaSources,\n    Handler handler,\n    Runnable onCompletionAction) {\n  addPublicMediaSources(index, mediaSources, handler, onCompletionAction);\n}", "summary_tokens": ["adds", "multiple", "media", "source", "s", "to", "the", "playlist", "and", "executes", "a", "custom", "action", "on", "completion"], "project": "ExoPlayer"}
{"id": 464, "code": "public boolean containsAny(int... flags) {\n  for (int flag : flags) {\n    if (contains(flag)) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "whether", "the", "set", "contains", "at", "least", "one", "of", "the", "given", "flags"], "project": "ExoPlayer"}
{"id": 1999, "code": "public static Metadata.Entry parseIlstElement(ParsableByteArray ilst) {\n  int position = ilst.getPosition();\n  int endPosition = position + ilst.readInt();\n  int type = ilst.readInt();\n  int typeTopByte = (type >> 24) & 0xFF;\n  try {\n    if (typeTopByte == TYPE_TOP_BYTE_COPYRIGHT || typeTopByte == TYPE_TOP_BYTE_REPLACEMENT) {\n      int shortType = type & 0x00FFFFFF;\n      if (shortType == SHORT_TYPE_COMMENT) {\n        return parseCommentAttribute(type, ilst);\n      } else if (shortType == SHORT_TYPE_NAME_1 || shortType == SHORT_TYPE_NAME_2) {\n        return parseTextAttribute(type, \"TIT2\", ilst);\n      } else if (shortType == SHORT_TYPE_COMPOSER_1 || shortType == SHORT_TYPE_COMPOSER_2) {\n        return parseTextAttribute(type, \"TCOM\", ilst);\n      } else if (shortType == SHORT_TYPE_YEAR) {\n        return parseTextAttribute(type, \"TDRC\", ilst);\n      } else if (shortType == SHORT_TYPE_ARTIST) {\n        return parseTextAttribute(type, \"TPE1\", ilst);\n      } else if (shortType == SHORT_TYPE_ENCODER) {\n        return parseTextAttribute(type, \"TSSE\", ilst);\n      } else if (shortType == SHORT_TYPE_ALBUM) {\n        return parseTextAttribute(type, \"TALB\", ilst);\n      } else if (shortType == SHORT_TYPE_LYRICS) {\n        return parseTextAttribute(type, \"USLT\", ilst);\n      } else if (shortType == SHORT_TYPE_GENRE) {\n        return parseTextAttribute(type, \"TCON\", ilst);\n      } else if (shortType == TYPE_GROUPING) {\n        return parseTextAttribute(type, \"TIT1\", ilst);\n      }\n    } else if (type == TYPE_GENRE) {\n      return parseStandardGenreAttribute(ilst);\n    } else if (type == TYPE_DISK_NUMBER) {\n      return parseIndexAndCountAttribute(type, \"TPOS\", ilst);\n    } else if (type == TYPE_TRACK_NUMBER) {\n      return parseIndexAndCountAttribute(type, \"TRCK\", ilst);\n    } else if (type == TYPE_TEMPO) {\n      return parseUint8Attribute(type, \"TBPM\", ilst, true, false);\n    } else if (type == TYPE_COMPILATION) {\n      return parseUint8Attribute(type, \"TCMP\", ilst, true, true);\n    } else if (type == TYPE_COVER_ART) {\n      return parseCoverArt(ilst);\n    } else if (type == TYPE_ALBUM_ARTIST) {\n      return parseTextAttribute(type, \"TPE2\", ilst);\n    } else if (type == TYPE_SORT_TRACK_NAME) {\n      return parseTextAttribute(type, \"TSOT\", ilst);\n    } else if (type == TYPE_SORT_ALBUM) {\n      return parseTextAttribute(type, \"TSO2\", ilst);\n    } else if (type == TYPE_SORT_ARTIST) {\n      return parseTextAttribute(type, \"TSOA\", ilst);\n    } else if (type == TYPE_SORT_ALBUM_ARTIST) {\n      return parseTextAttribute(type, \"TSOP\", ilst);\n    } else if (type == TYPE_SORT_COMPOSER) {\n      return parseTextAttribute(type, \"TSOC\", ilst);\n    } else if (type == TYPE_RATING) {\n      return parseUint8Attribute(type, \"ITUNESADVISORY\", ilst, false, false);\n    } else if (type == TYPE_GAPLESS_ALBUM) {\n      return parseUint8Attribute(type, \"ITUNESGAPLESS\", ilst, false, true);\n    } else if (type == TYPE_TV_SORT_SHOW) {\n      return parseTextAttribute(type, \"TVSHOWSORT\", ilst);\n    } else if (type == TYPE_TV_SHOW) {\n      return parseTextAttribute(type, \"TVSHOW\", ilst);\n    } else if (type == TYPE_INTERNAL) {\n      return parseInternalAttribute(ilst, endPosition);\n    }\n    Log.d(TAG, \"Skipped unknown metadata entry: \" + Atom.getAtomTypeString(type));\n    return null;\n  } finally {\n    ilst.setPosition(endPosition);\n  }\n}", "summary_tokens": ["parses", "a", "single", "userdata", "ilst", "element", "from", "a", "parsable", "byte", "array"], "project": "ExoPlayer"}
{"id": 1558, "code": "public void playEmptyTimeline() throws Exception {\n  Timeline timeline = Timeline.EMPTY;\n  Timeline expectedMaskingTimeline =\n      new MaskingMediaSource.PlaceholderTimeline(FakeMediaSource.FAKE_MEDIA_ITEM);\n  FakeRenderer renderer = new FakeRenderer(C.TRACK_TYPE_UNKNOWN);\n\n  ExoPlayer player = new TestExoPlayerBuilder(context).setRenderers(renderer).build();\n  Player.Listener mockListener = mock(Player.Listener.class);\n  player.addListener(mockListener);\n\n  player.setMediaSource(new FakeMediaSource(timeline, ExoPlayerTestRunner.VIDEO_FORMAT));\n  player.prepare();\n  player.play();\n  runUntilPlaybackState(player, Player.STATE_ENDED);\n\n  InOrder inOrder = inOrder(mockListener);\n  inOrder\n      .verify(mockListener)\n      .onTimelineChanged(\n          argThat(noUid(expectedMaskingTimeline)),\n          eq(Player.TIMELINE_CHANGE_REASON_PLAYLIST_CHANGED));\n  inOrder\n      .verify(mockListener)\n      .onTimelineChanged(\n          argThat(noUid(timeline)), eq(Player.TIMELINE_CHANGE_REASON_SOURCE_UPDATE));\n  inOrder.verify(mockListener, never()).onPositionDiscontinuity(anyInt());\n  inOrder.verify(mockListener, never()).onPositionDiscontinuity(any(), any(), anyInt());\n  assertThat(renderer.getFormatsRead()).isEmpty();\n  assertThat(renderer.sampleBufferReadCount).isEqualTo(0);\n  assertThat(renderer.isEnded).isFalse();\n}", "summary_tokens": ["tests", "playback", "of", "a", "source", "that", "exposes", "an", "empty", "timeline"], "project": "ExoPlayer"}
{"id": 2614, "code": "public boolean getControllerHideOnTouch() {\n  return controllerHideOnTouch;\n}", "summary_tokens": ["returns", "whether", "the", "playback", "controls", "are", "hidden", "by", "touch", "events"], "project": "ExoPlayer"}
{"id": 1721, "code": "public static String getStringForHttpMethod(@HttpMethod int httpMethod) {\n  switch (httpMethod) {\n    case HTTP_METHOD_GET:\n      return \"GET\";\n    case HTTP_METHOD_POST:\n      return \"POST\";\n    case HTTP_METHOD_HEAD:\n      return \"HEAD\";\n    default:\n        \n      throw new IllegalStateException();\n  }\n}", "summary_tokens": ["returns", "an", "uppercase", "http", "method", "name", "e"], "project": "ExoPlayer"}
{"id": 1746, "code": "public Cache getCache() {\n  return cache;\n}", "summary_tokens": ["returns", "the", "cache", "used", "by", "this", "instance"], "project": "ExoPlayer"}
{"id": 2469, "code": "public void setExtraAdGroupMarkers(\n    @Nullable long[] extraAdGroupTimesMs, @Nullable boolean[] extraPlayedAdGroups) {\n  if (extraAdGroupTimesMs == null) {\n    this.extraAdGroupTimesMs = new long[0];\n    this.extraPlayedAdGroups = new boolean[0];\n  } else {\n    extraPlayedAdGroups = Assertions.checkNotNull(extraPlayedAdGroups);\n    Assertions.checkArgument(extraAdGroupTimesMs.length == extraPlayedAdGroups.length);\n    this.extraAdGroupTimesMs = extraAdGroupTimesMs;\n    this.extraPlayedAdGroups = extraPlayedAdGroups;\n  }\n  updateTimeline();\n}", "summary_tokens": ["sets", "the", "millisecond", "positions", "of", "extra", "ad", "markers", "relative", "to", "the", "start", "of", "the", "window", "or", "timeline", "if", "in", "multi", "window", "mode", "and", "whether", "each", "extra", "ad", "has", "been", "played", "or", "not"], "project": "ExoPlayer"}
{"id": 1009, "code": "private boolean shouldUseFloatOutput(@C.PcmEncoding int pcmEncoding) {\n  return enableFloatOutput && Util.isEncodingHighResolutionPcm(pcmEncoding);\n}", "summary_tokens": ["returns", "whether", "audio", "in", "the", "specified", "pcm", "encoding", "should", "be", "written", "to", "the", "audio", "track", "as", "float", "pcm"], "project": "ExoPlayer"}
{"id": 2108, "code": "private static byte[] copyOfRangeIfValid(byte[] data, int from, int to) {\n  if (to <= from) {\n      \n    return Util.EMPTY_BYTE_ARRAY;\n  }\n  return Arrays.copyOfRange(data, from, to);\n}", "summary_tokens": ["copies", "the", "specified", "range", "of", "an", "array", "or", "returns", "a", "zero", "length", "array", "if", "the", "range", "is", "invalid"], "project": "ExoPlayer"}
{"id": 1776, "code": "public List<String> getRemovedValues() {\n  return Collections.unmodifiableList(new ArrayList<>(removedValues));\n}", "summary_tokens": ["returns", "a", "list", "of", "names", "of", "metadata", "values", "to", "be", "removed"], "project": "ExoPlayer"}
{"id": 1275, "code": "public synchronized void removeMediaSourceRange(\n    int fromIndex, int toIndex, Handler handler, Runnable onCompletionAction) {\n  removePublicMediaSources(fromIndex, toIndex, handler, onCompletionAction);\n}", "summary_tokens": ["removes", "a", "range", "of", "media", "source", "s", "from", "the", "playlist", "by", "specifying", "an", "initial", "index", "included", "and", "a", "final", "index", "excluded", "and", "executes", "a", "custom", "action", "on", "completion"], "project": "ExoPlayer"}
{"id": 272, "code": "public void pause() {\n  player.pause();\n}", "summary_tokens": ["calls", "player", "pause", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1023, "code": "public long getSkippedFrames() {\n  return skippedFrames;\n}", "summary_tokens": ["returns", "the", "total", "number", "of", "frames", "of", "input", "audio", "that", "were", "skipped", "due", "to", "being", "classified", "as", "silence", "since", "the", "last", "call", "to", "flush"], "project": "ExoPlayer"}
{"id": 1100, "code": "public DefaultMediaCodecAdapterFactory forceDisableAsynchronous() {\n  asynchronousMode = MODE_DISABLED;\n  return this;\n}", "summary_tokens": ["forces", "the", "factory", "to", "always", "create", "synchronous", "media", "codec", "adapter", "instances"], "project": "ExoPlayer"}
{"id": 1848, "code": "public static int getFrameSize(int headerData) {\n  if (!isMagicPresent(headerData)) {\n    return C.LENGTH_UNSET;\n  }\n\n  int version = (headerData >>> 19) & 3;\n  if (version == 1) {\n    return C.LENGTH_UNSET;\n  }\n\n  int layer = (headerData >>> 17) & 3;\n  if (layer == 0) {\n    return C.LENGTH_UNSET;\n  }\n\n  int bitrateIndex = (headerData >>> 12) & 15;\n  if (bitrateIndex == 0 || bitrateIndex == 0xF) {\n      \n    return C.LENGTH_UNSET;\n  }\n\n  int samplingRateIndex = (headerData >>> 10) & 3;\n  if (samplingRateIndex == 3) {\n    return C.LENGTH_UNSET;\n  }\n\n  int samplingRate = SAMPLING_RATE_V1[samplingRateIndex];\n  if (version == 2) {\n      \n    samplingRate /= 2;\n  } else if (version == 0) {\n      \n    samplingRate /= 4;\n  }\n\n  int bitrate;\n  int padding = (headerData >>> 9) & 1;\n  if (layer == 3) {\n      \n    bitrate = version == 3 ? BITRATE_V1_L1[bitrateIndex - 1] : BITRATE_V2_L1[bitrateIndex - 1];\n    return (12 * bitrate / samplingRate + padding) * 4;\n  } else {\n      \n    if (version == 3) {\n      bitrate = layer == 2 ? BITRATE_V1_L2[bitrateIndex - 1] : BITRATE_V1_L3[bitrateIndex - 1];\n    } else {\n        \n      bitrate = BITRATE_V2[bitrateIndex - 1];\n    }\n  }\n\n  if (version == 3) {\n      \n    return 144 * bitrate / samplingRate + padding;\n  } else {\n      \n    return (layer == 1 ? 72 : 144) * bitrate / samplingRate + padding;\n  }\n}", "summary_tokens": ["returns", "the", "size", "of", "the", "frame", "associated", "with", "header", "or", "c", "length", "unset", "if", "it", "is", "invalid"], "project": "ExoPlayer"}
{"id": 378, "code": "public boolean isThumbsUp() {\n  return isThumbsUp;\n}", "summary_tokens": ["returns", "whether", "the", "rating", "is", "thumbs", "up"], "project": "ExoPlayer"}
{"id": 485, "code": "public static EGLSurface getEglSurfaceBt2020Pq(EGLDisplay eglDisplay, Object surface) {\n  return Api17.getEglSurface(\n      eglDisplay,\n      surface,\n      EGL_CONFIG_ATTRIBUTES_RGBA_1010102,\n      EGL_WINDOW_SURFACE_ATTRIBUTES_BT2020_PQ);\n}", "summary_tokens": ["returns", "a", "new", "eglsurface", "wrapping", "the", "specified", "surface", "for", "hdr", "rendering", "with", "rec"], "project": "ExoPlayer"}
{"id": 287, "code": "public boolean hasPreviousWindow() {\n  return player.hasPreviousWindow();\n}", "summary_tokens": ["calls", "player", "has", "previous", "window", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 1551, "code": "public void removeVideoSurfaceListener(VideoSurfaceListener listener) {\n  videoSurfaceListeners.remove(listener);\n}", "summary_tokens": ["removes", "a", "video", "surface", "listener"], "project": "ExoPlayer"}
{"id": 451, "code": "public synchronized boolean isOpen() {\n  return isOpen;\n}", "summary_tokens": ["returns", "whether", "the", "condition", "is", "opened"], "project": "ExoPlayer"}
{"id": 594, "code": "public String readLine() {\n  if (bytesLeft() == 0) {\n    return null;\n  }\n  int lineLimit = position;\n  while (lineLimit < limit && !Util.isLinebreak(data[lineLimit])) {\n    lineLimit++;\n  }\n  if (lineLimit - position >= 3\n      && data[position] == (byte) 0xEF\n      && data[position + 1] == (byte) 0xBB\n      && data[position + 2] == (byte) 0xBF) {\n      \n    position += 3;\n  }\n  String line = Util.fromUtf8Bytes(data, position, lineLimit - position);\n  position = lineLimit;\n  if (position == limit) {\n    return line;\n  }\n  if (data[position] == '\\r') {\n    position++;\n    if (position == limit) {\n      return line;\n    }\n  }\n  if (data[position] == '\\n') {\n    position++;\n  }\n  return line;\n}", "summary_tokens": ["reads", "a", "line", "of", "text"], "project": "ExoPlayer"}
{"id": 2684, "code": "public void blockUntilIdle() throws InterruptedException {\n  idleCondition.close();\n    \n    \n  ConditionVariable checkedOnMainThread = createRobolectricConditionVariable();\n  new Handler(downloadManager.getApplicationLooper())\n      .post(\n          () -> {\n            if (downloadManager.isIdle()) {\n              idleCondition.open();\n            }\n            checkedOnMainThread.open();\n          });\n  assertThat(checkedOnMainThread.block(TIMEOUT_MS)).isTrue();\n  assertThat(idleCondition.block(TIMEOUT_MS)).isTrue();\n}", "summary_tokens": ["blocks", "until", "the", "manager", "is", "idle"], "project": "ExoPlayer"}
{"id": 2094, "code": "public static WavFormat readFormat(ExtractorInput input) throws IOException {\n    \n  ParsableByteArray scratch = new ParsableByteArray(16);\n    \n  ChunkHeader chunkHeader = skipToChunk( WavUtil.FMT_FOURCC, input, scratch);\n  Assertions.checkState(chunkHeader.size >= 16);\n  input.peekFully(scratch.getData(), 0, 16);\n  scratch.setPosition(0);\n  int audioFormatType = scratch.readLittleEndianUnsignedShort();\n  int numChannels = scratch.readLittleEndianUnsignedShort();\n  int frameRateHz = scratch.readLittleEndianUnsignedIntToInt();\n  int averageBytesPerSecond = scratch.readLittleEndianUnsignedIntToInt();\n  int blockSize = scratch.readLittleEndianUnsignedShort();\n  int bitsPerSample = scratch.readLittleEndianUnsignedShort();\n\n  int bytesLeft = (int) chunkHeader.size - 16;\n  byte[] extraData;\n  if (bytesLeft > 0) {\n    extraData = new byte[bytesLeft];\n    input.peekFully(extraData, 0, bytesLeft);\n  } else {\n    extraData = Util.EMPTY_BYTE_ARRAY;\n  }\n\n  input.skipFully((int) (input.getPeekPosition() - input.getPosition()));\n  return new WavFormat(\n      audioFormatType,\n      numChannels,\n      frameRateHz,\n      averageBytesPerSecond,\n      blockSize,\n      bitsPerSample,\n      extraData);\n}", "summary_tokens": ["reads", "and", "returns", "a", "wav", "format"], "project": "ExoPlayer"}
{"id": 1843, "code": "public static void getAc4SampleHeader(int size, ParsableByteArray buffer) {\n    \n  buffer.reset(SAMPLE_HEADER_SIZE);\n  byte[] data = buffer.getData();\n  data[0] = (byte) 0xAC;\n  data[1] = 0x40;\n  data[2] = (byte) 0xFF;\n  data[3] = (byte) 0xFF;\n  data[4] = (byte) ((size >> 16) & 0xFF);\n  data[5] = (byte) ((size >> 8) & 0xFF);\n  data[6] = (byte) (size & 0xFF);\n}", "summary_tokens": ["populates", "buffer", "with", "an", "ac", "0", "sample", "header", "for", "a", "sample", "of", "the", "specified", "size"], "project": "ExoPlayer"}
{"id": 182, "code": "public void setClearMediaItemsOnStop(boolean clearMediaItemsOnStop) {\n  this.clearMediaItemsOnStop = clearMediaItemsOnStop;\n}", "summary_tokens": ["sets", "whether", "media", "items", "are", "cleared", "from", "the", "playlist", "when", "a", "client", "sends", "a", "media", "controller", "compat"], "project": "ExoPlayer"}
{"id": 2699, "code": "public void runTestOnMainThread(int timeoutMs, final TestRunnable runnable) {\n  if (Looper.myLooper() == handler.getLooper()) {\n    try {\n      runnable.run();\n    } catch (Exception e) {\n      Util.sneakyThrow(e);\n    }\n  } else {\n    CountDownLatch finishedLatch = new CountDownLatch(1);\n    AtomicReference<Throwable> thrown = new AtomicReference<>();\n    handler.post(\n        () -> {\n          try {\n            runnable.run();\n          } catch (Throwable t) {\n            thrown.set(t);\n          }\n          finishedLatch.countDown();\n        });\n    try {\n      assertThat(finishedLatch.await(timeoutMs, MILLISECONDS)).isTrue();\n    } catch (InterruptedException e) {\n      Util.sneakyThrow(e);\n    }\n    if (thrown.get() != null) {\n      Util.sneakyThrow(thrown.get());\n    }\n  }\n}", "summary_tokens": ["runs", "the", "provided", "test", "runnable", "on", "the", "main", "thread", "blocking", "until", "execution", "completes", "or", "until", "timeout", "milliseconds", "have", "passed"], "project": "ExoPlayer"}
{"id": 2218, "code": "public byte[] get(@Nullable Uri uri) {\n  if (uri == null) {\n    return null;\n  }\n  return backingMap.get(uri);\n}", "summary_tokens": ["returns", "the", "encryption", "key", "cached", "against", "this", "uri", "or", "null", "if", "uri", "is", "null", "or", "not", "present", "in", "the", "cache"], "project": "ExoPlayer"}
{"id": 2796, "code": "public RenderersFactory getRenderersFactory() {\n  return renderersFactory;\n}", "summary_tokens": ["returns", "the", "renderers", "factory", "that", "has", "been", "set", "with", "set", "renderers", "factory", "or", "null", "if", "no", "factory", "has", "been", "explicitly", "set"], "project": "ExoPlayer"}
{"id": 2577, "code": "public boolean getShowSubtitleButton() {\n  return controlViewLayoutManager.getShowButton(subtitleButton);\n}", "summary_tokens": ["returns", "whether", "the", "subtitle", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 234, "code": "public static @PlaybackException.ErrorCode int getErrorCodeForMediaDrmErrorCode(\n    int mediaDrmErrorCode) {\n  return Util.getErrorCodeForMediaDrmErrorCode(mediaDrmErrorCode);\n}", "summary_tokens": ["use", "util", "get", "error", "code", "for", "media", "drm", "error", "code", "int"], "project": "ExoPlayer"}
{"id": 2059, "code": "private SeiReader buildSeiReader(EsInfo esInfo) {\n  return new SeiReader(getClosedCaptionFormats(esInfo));\n}", "summary_tokens": ["if", "flag", "override", "caption", "descriptors", "is", "set", "returns", "a", "sei", "reader", "for", "closed", "caption", "formats"], "project": "ExoPlayer"}
{"id": 389, "code": "public Period getPeriodByUid(Object periodUid, Period period) {\n  return getPeriod(getIndexOfPeriod(periodUid), period,  true);\n}", "summary_tokens": ["populates", "a", "period", "with", "data", "for", "the", "period", "with", "the", "specified", "unique", "identifier"], "project": "ExoPlayer"}
{"id": 1787, "code": "private SimpleCacheSpan getSpan(String key, long position, long length) {\n  @Nullable CachedContent cachedContent = contentIndex.get(key);\n  if (cachedContent == null) {\n    return SimpleCacheSpan.createHole(key, position, length);\n  }\n  while (true) {\n    SimpleCacheSpan span = cachedContent.getSpan(position, length);\n    if (span.isCached && span.file.length() != span.length) {\n        \n        \n      removeStaleSpans();\n      continue;\n    }\n    return span;\n  }\n}", "summary_tokens": ["returns", "the", "cache", "span", "corresponding", "to", "the", "provided", "key", "and", "range"], "project": "ExoPlayer"}
{"id": 952, "code": "public float getMeanNonFatalErrorCount() {\n  return foregroundPlaybackCount == 0 ? 0f : (float) nonFatalErrorCount / foregroundPlaybackCount;\n}", "summary_tokens": ["returns", "the", "mean", "number", "of", "non", "fatal", "errors", "per", "foreground", "playback", "or", "0"], "project": "ExoPlayer"}
{"id": 555, "code": "public void skipBytes(int length) {\n  Assertions.checkState(bitOffset == 0);\n  byteOffset += length;\n  assertValidOffset();\n}", "summary_tokens": ["skips", "the", "next", "length", "bytes"], "project": "ExoPlayer"}
{"id": 573, "code": "public short readLittleEndianShort() {\n  return (short) ((data[position++] & 0xFF) | (data[position++] & 0xFF) << 8);\n}", "summary_tokens": ["reads", "the", "next", "two", "bytes", "as", "a", "signed", "value"], "project": "ExoPlayer"}
{"id": 1125, "code": "protected boolean shouldReinitCodec() {\n  return false;\n}", "summary_tokens": ["returns", "whether", "the", "renderer", "needs", "to", "re", "initialize", "the", "codec", "possibly", "as", "a", "result", "of", "a", "change", "in", "device", "capabilities"], "project": "ExoPlayer"}
{"id": 772, "code": "public static PlaybackInfo createDummy(TrackSelectorResult emptyTrackSelectorResult) {\n  return new PlaybackInfo(\n      Timeline.EMPTY,\n      PLACEHOLDER_MEDIA_PERIOD_ID,\n       C.TIME_UNSET,\n       0,\n      Player.STATE_IDLE,\n       null,\n       false,\n      TrackGroupArray.EMPTY,\n      emptyTrackSelectorResult,\n       ImmutableList.of(),\n      PLACEHOLDER_MEDIA_PERIOD_ID,\n       false,\n      Player.PLAYBACK_SUPPRESSION_REASON_NONE,\n      PlaybackParameters.DEFAULT,\n       0,\n       0,\n       0,\n       false);\n}", "summary_tokens": ["creates", "an", "empty", "placeholder", "playback", "info", "which", "can", "be", "used", "for", "masking", "as", "long", "as", "no", "real", "playback", "info", "is", "available"], "project": "ExoPlayer"}
{"id": 2525, "code": "public void setShutterBackgroundColor(int color) {\n  if (shutterView != null) {\n    shutterView.setBackgroundColor(color);\n  }\n}", "summary_tokens": ["sets", "the", "background", "color", "of", "the", "exo", "shutter", "view"], "project": "ExoPlayer"}
{"id": 2247, "code": "public void setSequenceNumber(int sequenceNumber) {\n  if (!checkNotNull(extractor).hasReadFirstRtpPacket()) {\n    extractor.setFirstSequenceNumber(sequenceNumber);\n  }\n}", "summary_tokens": ["sets", "the", "timestamp", "of", "an", "rtp", "packet", "to", "arrive"], "project": "ExoPlayer"}
{"id": 2450, "code": "public void setAspectRatio(float widthHeightRatio) {\n  if (this.videoAspectRatio != widthHeightRatio) {\n    this.videoAspectRatio = widthHeightRatio;\n    requestLayout();\n  }\n}", "summary_tokens": ["sets", "the", "aspect", "ratio", "that", "this", "view", "should", "satisfy"], "project": "ExoPlayer"}
{"id": 1744, "code": "public Map<String, List<String>> getLastResponseHeaders() {\n  return lastResponseHeaders;\n}", "summary_tokens": ["returns", "the", "response", "headers", "associated", "with", "the", "last", "open", "data", "spec", "call"], "project": "ExoPlayer"}
{"id": 939, "code": "public float getMeanTimeBetweenRebuffers() {\n  return 1f / getRebufferRate();\n}", "summary_tokens": ["returns", "the", "mean", "play", "time", "between", "rebuffer", "events", "in", "seconds"], "project": "ExoPlayer"}
{"id": 92, "code": "public long getLastFrameFirstSampleIndex() {\n  return flacGetLastFrameFirstSampleIndex(nativeDecoderContext);\n}", "summary_tokens": ["returns", "the", "first", "sample", "index", "of", "the", "last", "extracted", "frame"], "project": "ExoPlayer"}
{"id": 55, "code": "public void onMediaItemsSet(List<MediaItem> mediaItems, MediaQueueItem[] mediaQueueItems) {\n  mediaItemsByContentId.clear();\n  onMediaItemsAdded(mediaItems, mediaQueueItems);\n}", "summary_tokens": ["called", "when", "media", "items", "player", "set", "media", "items", "have", "been", "set", "to", "the", "playlist", "and", "are", "sent", "to", "the", "cast", "playback", "queue"], "project": "ExoPlayer"}
{"id": 1485, "code": "public boolean isSynced() {\n  return currentMatcher.isSynced();\n}", "summary_tokens": ["returns", "whether", "the", "estimator", "has", "detected", "a", "fixed", "frame", "rate"], "project": "ExoPlayer"}
{"id": 435, "code": "public static void ensureClassLoader(@Nullable Bundle bundle) {\n  if (bundle != null) {\n    bundle.setClassLoader(castNonNull(BundleableUtil.class.getClassLoader()));\n  }\n}", "summary_tokens": ["sets", "the", "application", "class", "loader", "to", "the", "given", "bundle", "if", "no", "class", "loader", "is", "present"], "project": "ExoPlayer"}
{"id": 783, "code": "public Timeline getTimeline() {\n  return timeline;\n}", "summary_tokens": ["returns", "the", "timeline", "used", "for", "setting", "the", "position", "with", "set", "position", "long"], "project": "ExoPlayer"}
{"id": 799, "code": "public synchronized void markAsProcessed(boolean isDelivered) {\n  this.isDelivered |= isDelivered;\n  isProcessed = true;\n  notifyAll();\n}", "summary_tokens": ["marks", "the", "message", "as", "processed"], "project": "ExoPlayer"}
{"id": 249, "code": "public boolean initializationDataEquals(Format other) {\n  if (initializationData.size() != other.initializationData.size()) {\n    return false;\n  }\n  for (int i = 0; i < initializationData.size(); i++) {\n    if (!Arrays.equals(initializationData.get(i), other.initializationData.get(i))) {\n      return false;\n    }\n  }\n  return true;\n}", "summary_tokens": ["returns", "whether", "the", "initialization", "data", "s", "belonging", "to", "this", "format", "and", "other", "are", "equal"], "project": "ExoPlayer"}
{"id": 2515, "code": "public Player getPlayer() {\n  return player;\n}", "summary_tokens": ["returns", "the", "player", "currently", "set", "on", "this", "view", "or", "null", "if", "no", "player", "is", "set"], "project": "ExoPlayer"}
{"id": 1816, "code": "public void resetSupplementalData(int length) {\n  if (supplementalData == null || supplementalData.capacity() < length) {\n    supplementalData = ByteBuffer.allocate(length);\n  } else {\n    supplementalData.clear();\n  }\n}", "summary_tokens": ["clears", "supplemental", "data", "and", "ensures", "that", "it", "s", "large", "enough", "to", "accommodate", "length", "bytes"], "project": "ExoPlayer"}
{"id": 1736, "code": "private void closeConnectionQuietly() {\n  if (connection != null) {\n    try {\n      connection.disconnect();\n    } catch (Exception e) {\n      Log.e(TAG, \"Unexpected error while disconnecting\", e);\n    }\n    connection = null;\n  }\n}", "summary_tokens": ["closes", "the", "current", "connection", "quietly", "if", "there", "is", "one"], "project": "ExoPlayer"}
{"id": 150, "code": "public void setPlayingAdPosition(\n    int periodIndex,\n    int adGroupIndex,\n    int adIndexInAdGroup,\n    long positionMs,\n    long contentPositionMs) {\n  boolean notify = !isPlayingAd || this.adIndexInAdGroup != adIndexInAdGroup;\n  PositionInfo oldPosition =\n      new PositionInfo(\n          windowUid,\n           0,\n          mediaItem,\n          periodUid,\n           0,\n          this.positionMs,\n          this.contentPositionMs,\n          this.adGroupIndex,\n          this.adIndexInAdGroup);\n  isPlayingAd = true;\n  this.periodIndex = periodIndex;\n  this.adGroupIndex = adGroupIndex;\n  this.adIndexInAdGroup = adIndexInAdGroup;\n  this.positionMs = positionMs;\n  this.contentPositionMs = contentPositionMs;\n  if (notify) {\n    PositionInfo newPosition =\n        new PositionInfo(\n            windowUid,\n             0,\n            mediaItem,\n            periodUid,\n             0,\n            positionMs,\n            contentPositionMs,\n            adGroupIndex,\n            adIndexInAdGroup);\n    listeners.sendEvent(\n        EVENT_POSITION_DISCONTINUITY,\n        listener ->\n            listener.onPositionDiscontinuity(\n                oldPosition, newPosition, DISCONTINUITY_REASON_AUTO_TRANSITION));\n  }\n}", "summary_tokens": ["sets", "the", "state", "of", "this", "player", "as", "if", "it", "were", "playing", "an", "ad", "with", "the", "given", "indices", "at", "the", "given", "position"], "project": "ExoPlayer"}
{"id": 1929, "code": "public static CommentHeader readVorbisCommentHeader(\n    ParsableByteArray headerData, boolean hasMetadataHeader, boolean hasFramingBit)\n    throws ParserException {\n\n  if (hasMetadataHeader) {\n    verifyVorbisHeaderCapturePattern( 0x03, headerData,  false);\n  }\n  int length = 7;\n\n  int len = (int) headerData.readLittleEndianUnsignedInt();\n  length += 4;\n  String vendor = headerData.readString(len);\n  length += vendor.length();\n\n  long commentListLen = headerData.readLittleEndianUnsignedInt();\n  String[] comments = new String[(int) commentListLen];\n  length += 4;\n  for (int i = 0; i < commentListLen; i++) {\n    len = (int) headerData.readLittleEndianUnsignedInt();\n    length += 4;\n    comments[i] = headerData.readString(len);\n    length += comments[i].length();\n  }\n  if (hasFramingBit && (headerData.readUnsignedByte() & 0x01) == 0) {\n    throw ParserException.createForMalformedContainer(\n        \"framing bit expected to be set\",  null);\n  }\n  length += 1;\n  return new CommentHeader(vendor, comments, length);\n}", "summary_tokens": ["reads", "a", "vorbis", "comment", "header"], "project": "ExoPlayer"}
{"id": 800, "code": "public synchronized boolean blockUntilDelivered(long timeoutMs)\n    throws InterruptedException, TimeoutException {\n  Assertions.checkState(isSent);\n  Assertions.checkState(looper.getThread() != Thread.currentThread());\n\n  long deadlineMs = clock.elapsedRealtime() + timeoutMs;\n  long remainingMs = timeoutMs;\n  while (!isProcessed && remainingMs > 0) {\n    clock.onThreadBlocked();\n    wait(remainingMs);\n    remainingMs = deadlineMs - clock.elapsedRealtime();\n  }\n  if (!isProcessed) {\n    throw new TimeoutException(\"Message delivery timed out.\");\n  }\n  return isDelivered;\n}", "summary_tokens": ["blocks", "until", "after", "the", "message", "has", "been", "delivered", "or", "the", "player", "is", "no", "longer", "able", "to", "deliver", "the", "message", "or", "the", "specified", "timeout", "elapsed"], "project": "ExoPlayer"}
{"id": 1506, "code": "protected CodecMaxValues getCodecMaxValues(\n    MediaCodecInfo codecInfo, Format format, Format[] streamFormats) {\n  int maxWidth = format.width;\n  int maxHeight = format.height;\n  int maxInputSize = getMaxInputSize(codecInfo, format);\n  if (streamFormats.length == 1) {\n      \n      \n    if (maxInputSize != Format.NO_VALUE) {\n      int codecMaxInputSize = getCodecMaxInputSize(codecInfo, format);\n      if (codecMaxInputSize != Format.NO_VALUE) {\n          \n          \n          \n        int scaledMaxInputSize =\n            (int) (maxInputSize * INITIAL_FORMAT_MAX_INPUT_SIZE_SCALE_FACTOR);\n          \n        maxInputSize = min(scaledMaxInputSize, codecMaxInputSize);\n      }\n    }\n    return new CodecMaxValues(maxWidth, maxHeight, maxInputSize);\n  }\n  boolean haveUnknownDimensions = false;\n  for (Format streamFormat : streamFormats) {\n    if (format.colorInfo != null && streamFormat.colorInfo == null) {\n        \n        \n      streamFormat = streamFormat.buildUpon().setColorInfo(format.colorInfo).build();\n    }\n    if (codecInfo.canReuseCodec(format, streamFormat).result != REUSE_RESULT_NO) {\n      haveUnknownDimensions |=\n          (streamFormat.width == Format.NO_VALUE || streamFormat.height == Format.NO_VALUE);\n      maxWidth = max(maxWidth, streamFormat.width);\n      maxHeight = max(maxHeight, streamFormat.height);\n      maxInputSize = max(maxInputSize, getMaxInputSize(codecInfo, streamFormat));\n    }\n  }\n  if (haveUnknownDimensions) {\n    Log.w(TAG, \"Resolutions unknown. Codec max resolution: \" + maxWidth + \"x\" + maxHeight);\n    @Nullable Point codecMaxSize = getCodecMaxSize(codecInfo, format);\n    if (codecMaxSize != null) {\n      maxWidth = max(maxWidth, codecMaxSize.x);\n      maxHeight = max(maxHeight, codecMaxSize.y);\n      maxInputSize =\n          max(\n              maxInputSize,\n              getCodecMaxInputSize(\n                  codecInfo, format.buildUpon().setWidth(maxWidth).setHeight(maxHeight).build()));\n      Log.w(TAG, \"Codec max resolution adjusted to: \" + maxWidth + \"x\" + maxHeight);\n    }\n  }\n  return new CodecMaxValues(maxWidth, maxHeight, maxInputSize);\n}", "summary_tokens": ["returns", "codec", "max", "values", "suitable", "for", "configuring", "a", "codec", "for", "format", "in", "a", "way", "that", "will", "allow", "possible", "adaptation", "to", "other", "compatible", "formats", "in", "stream", "formats"], "project": "ExoPlayer"}
{"id": 2507, "code": "public final void setUseChronometer(boolean useChronometer) {\n  if (this.useChronometer != useChronometer) {\n    this.useChronometer = useChronometer;\n    invalidate();\n  }\n}", "summary_tokens": ["sets", "whether", "the", "elapsed", "time", "of", "the", "media", "playback", "should", "be", "displayed"], "project": "ExoPlayer"}
{"id": 2204, "code": "private static MetadataInputBuffer createMetadataInputBuffer(byte[] data) {\n  MetadataInputBuffer buffer = new MetadataInputBuffer();\n  buffer.data = ByteBuffer.allocate(data.length).put(data);\n  buffer.data.flip();\n  return buffer;\n}", "summary_tokens": ["create", "a", "new", "metadata", "input", "buffer", "and", "copy", "data", "into", "the", "backing", "byte", "buffer"], "project": "ExoPlayer"}
{"id": 2339, "code": "public static StreamElement createStreamElement(\n    String name, @C.TrackType int trackType, Format... formats) {\n  return new StreamElement(\n      TEST_BASE_URI,\n      TEST_CHUNK_TEMPLATE,\n      trackType,\n      TEST_SUB_TYPE,\n      TEST_TIMESCALE,\n      name,\n      TEST_MAX_WIDTH,\n      TEST_MAX_HEIGHT,\n      TEST_MAX_WIDTH,\n      TEST_MAX_HEIGHT,\n      TEST_LANGUAGE,\n      formats,\n       Collections.emptyList(),\n       0);\n}", "summary_tokens": ["creates", "test", "video", "stream", "element", "with", "the", "given", "name", "track", "type", "and", "formats"], "project": "ExoPlayer"}
{"id": 2214, "code": "public void parseH265SpsNalUnitPayload_exoghi_10316() {\n  byte[] spsNalUnitPayload =\n      new byte[] {\n        1, 2, 32, 0, 0, 3, 0, -112, 0, 0, 3, 0, 0, 3, 0, -106, -96, 1, -32, 32, 2, 28, 77, -98,\n        87, -110, 66, -111, -123, 22, 74, -86, -53, -101, -98, -68, -28, 9, 119, -21, -103, 120,\n        -16, 22, -95, 34, 1, 54, -62, 0, 0, 7, -46, 0, 0, -69, -127, -12, 85, -17, 126, 0, -29,\n        -128, 28, 120, 1, -57, 0, 56, -15\n      };\n\n  NalUnitUtil.H265SpsData spsData =\n      NalUnitUtil.parseH265SpsNalUnitPayload(spsNalUnitPayload, 0, spsNalUnitPayload.length);\n\n  assertThat(spsData.constraintBytes).isEqualTo(new int[] {144, 0, 0, 0, 0, 0});\n  assertThat(spsData.generalLevelIdc).isEqualTo(150);\n  assertThat(spsData.generalProfileCompatibilityFlags).isEqualTo(4);\n  assertThat(spsData.generalProfileIdc).isEqualTo(2);\n  assertThat(spsData.generalProfileSpace).isEqualTo(0);\n  assertThat(spsData.generalTierFlag).isFalse();\n  assertThat(spsData.height).isEqualTo(2160);\n  assertThat(spsData.pixelWidthHeightRatio).isEqualTo(1);\n  assertThat(spsData.seqParameterSetId).isEqualTo(0);\n  assertThat(spsData.width).isEqualTo(3840);\n}", "summary_tokens": ["regression", "test", "for", "https", "github"], "project": "ExoPlayer"}
{"id": 627, "code": "private static byte[] buildTestData(int length, int seed) {\n  byte[] source = new byte[length];\n  new Random(seed).nextBytes(source);\n  return source;\n}", "summary_tokens": ["generates", "an", "array", "of", "random", "bytes", "with", "the", "specified", "length"], "project": "ExoPlayer"}
{"id": 401, "code": "public DrmInitData merge(DrmInitData drmInitData) {\n  Assertions.checkState(\n      schemeType == null\n          || drmInitData.schemeType == null\n          || TextUtils.equals(schemeType, drmInitData.schemeType));\n  String mergedSchemeType = schemeType != null ? this.schemeType : drmInitData.schemeType;\n  SchemeData[] mergedSchemeDatas =\n      Util.nullSafeArrayConcatenation(schemeDatas, drmInitData.schemeDatas);\n  return new DrmInitData(mergedSchemeType, mergedSchemeDatas);\n}", "summary_tokens": ["returns", "an", "instance", "containing", "the", "scheme", "datas", "from", "both", "this", "and", "other"], "project": "ExoPlayer"}
{"id": 1499, "code": "protected void dropOutputBuffer(MediaCodecAdapter codec, int index, long presentationTimeUs) {\n  TraceUtil.beginSection(\"dropVideoBuffer\");\n  codec.releaseOutputBuffer(index, false);\n  TraceUtil.endSection();\n  updateDroppedBufferCounters(\n       0,  1);\n}", "summary_tokens": ["drops", "the", "output", "buffer", "with", "the", "specified", "index"], "project": "ExoPlayer"}
{"id": 1654, "code": "public void deprecatedParametersBuilderOverridesAllTrackSelectionParametersBuilderMethods()\n    throws Exception {\n  List<Method> methods = TestUtil.getPublicMethods(TrackSelectionParameters.Builder.class);\n  for (Method method : methods) {\n    assertThat(\n            DefaultTrackSelector.ParametersBuilder.class\n                .getDeclaredMethod(method.getName(), method.getParameterTypes())\n                .getDeclaringClass())\n        .isEqualTo(DefaultTrackSelector.ParametersBuilder.class);\n  }\n}", "summary_tokens": ["the", "deprecated", "default", "track", "selector"], "project": "ExoPlayer"}
{"id": 1986, "code": "private static long parseMehd(ParsableByteArray mehd) {\n  mehd.setPosition(Atom.HEADER_SIZE);\n  int fullAtom = mehd.readInt();\n  int version = Atom.parseFullAtomVersion(fullAtom);\n  return version == 0 ? mehd.readUnsignedInt() : mehd.readUnsignedLongToLong();\n}", "summary_tokens": ["parses", "an", "mehd", "atom", "defined", "in", "0", "0"], "project": "ExoPlayer"}
{"id": 2423, "code": "public int getTrackSampleCount(@C.TrackType int trackType) {\n  return trackTypeToSampleCount.get(trackType,  0);\n}", "summary_tokens": ["returns", "the", "number", "of", "samples", "written", "to", "the", "track", "of", "the", "provided", "track", "type"], "project": "ExoPlayer"}
{"id": 2770, "code": "public void assertNoTimelineChange() {\n  assertThat(timelines).isEmpty();\n}", "summary_tokens": ["asserts", "that", "the", "source", "has", "not", "notified", "its", "listener", "of", "a", "timeline", "change", "since", "the", "last", "call", "to", "assert", "timeline", "change", "blocking", "or", "assert", "timeline", "change", "or", "since", "the", "runner", "was", "created", "if", "neither", "method", "has", "been", "called"], "project": "ExoPlayer"}
{"id": 549, "code": "public void skipBits(int numBits) {\n  int numBytes = numBits / 8;\n  byteOffset += numBytes;\n  bitOffset += numBits - (numBytes * 8);\n  if (bitOffset > 7) {\n    byteOffset++;\n    bitOffset -= 8;\n  }\n  assertValidOffset();\n}", "summary_tokens": ["skips", "bits", "and", "moves", "current", "reading", "position", "forward"], "project": "ExoPlayer"}
{"id": 2742, "code": "public void assertReleased() {\n  assertThat(releasedSource || !preparedSource).isTrue();\n}", "summary_tokens": ["assert", "that", "the", "source", "and", "all", "periods", "have", "been", "released"], "project": "ExoPlayer"}
{"id": 1631, "code": "public void selectTracksWithinCapabilitiesSelectHigherSampleRate() throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format higherSampleRateFormat = formatBuilder.setSampleRate(44100).build();\n  Format lowerSampleRateFormat = formatBuilder.setSampleRate(22050).build();\n  TrackGroupArray trackGroups = wrapFormats(higherSampleRateFormat, lowerSampleRateFormat);\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_SUPPORTED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, higherSampleRateFormat);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "select", "audio", "tracks", "with", "higher", "sample", "rate", "when", "other", "factors", "are", "the", "same", "and", "tracks", "are", "within", "renderer", "s", "capabilities"], "project": "ExoPlayer"}
{"id": 1091, "code": "public long getFirstSampleTimeUs() {\n  return timeUs;\n}", "summary_tokens": ["returns", "the", "timestamp", "of", "the", "first", "sample", "in", "the", "buffer"], "project": "ExoPlayer"}
{"id": 1385, "code": "public void discardBuffer(long positionUs, boolean toKeyframe) {\n  if (isPendingReset()) {\n    return;\n  }\n  int oldFirstSampleIndex = primarySampleQueue.getFirstIndex();\n  primarySampleQueue.discardTo(positionUs, toKeyframe, true);\n  int newFirstSampleIndex = primarySampleQueue.getFirstIndex();\n  if (newFirstSampleIndex > oldFirstSampleIndex) {\n    long discardToUs = primarySampleQueue.getFirstTimestampUs();\n    for (int i = 0; i < embeddedSampleQueues.length; i++) {\n      embeddedSampleQueues[i].discardTo(discardToUs, toKeyframe, embeddedTracksSelected[i]);\n    }\n  }\n  discardDownstreamMediaChunks(newFirstSampleIndex);\n}", "summary_tokens": ["discards", "buffered", "media", "up", "to", "the", "specified", "position"], "project": "ExoPlayer"}
{"id": 901, "code": "default void onPlayerReleased(EventTime eventTime) {}", "summary_tokens": ["called", "when", "the", "player", "is", "released"], "project": "ExoPlayer"}
{"id": 872, "code": "default void onAudioPositionAdvancing(EventTime eventTime, long playoutStartSystemTimeMs) {}", "summary_tokens": ["called", "when", "the", "audio", "position", "has", "increased", "for", "the", "first", "time", "since", "the", "last", "pause", "or", "position", "reset"], "project": "ExoPlayer"}
{"id": 509, "code": "public static String getThrowableString(@Nullable Throwable throwable) {\n  synchronized (lock) {\n    if (throwable == null) {\n      return null;\n    } else if (isCausedByUnknownHostException(throwable)) {\n        \n        \n        \n        \n        \n        \n        \n      return \"UnknownHostException (no network)\";\n    } else if (!logStackTraces) {\n      return throwable.getMessage();\n    } else {\n      return android.util.Log.getStackTraceString(throwable).trim().replace(\"\\t\", \"    \");\n    }\n  }\n}", "summary_tokens": ["returns", "a", "string", "representation", "of", "a", "throwable", "suitable", "for", "logging", "taking", "into", "account", "whether", "set", "log", "stack", "traces", "boolean", "stack", "trace", "logging", "is", "enabled"], "project": "ExoPlayer"}
{"id": 1686, "code": "public RangedUri getInitialization(Representation representation) {\n  return initialization;\n}", "summary_tokens": ["returns", "the", "ranged", "uri", "defining", "the", "location", "of", "initialization", "data", "for", "a", "given", "representation", "or", "null", "if", "no", "initialization", "data", "exists"], "project": "ExoPlayer"}
{"id": 1405, "code": "private void handleDecoderError(SubtitleDecoderException e) {\n  Log.e(TAG, \"Subtitle decoding failed. streamFormat=\" + streamFormat, e);\n  clearOutput();\n  replaceDecoder();\n}", "summary_tokens": ["called", "when", "decoder", "throws", "an", "exception", "so", "it", "can", "be", "logged", "and", "playback", "can", "continue"], "project": "ExoPlayer"}
{"id": 603, "code": "public final void blockUntilFinished() {\n  finished.blockUninterruptible();\n}", "summary_tokens": ["blocks", "until", "the", "task", "has", "finished", "or", "has", "been", "canceled", "without", "having", "been", "started"], "project": "ExoPlayer"}
{"id": 993, "code": "public void reset() {\n  resetSyncParams();\n  audioTrack = null;\n  audioTimestampPoller = null;\n}", "summary_tokens": ["resets", "the", "position", "tracker"], "project": "ExoPlayer"}
{"id": 159, "code": "public SessionCallbackBuilder setDisconnectedCallback(\n    @Nullable DisconnectedCallback disconnectedCallback) {\n  this.disconnectedCallback = disconnectedCallback;\n  return this;\n}", "summary_tokens": ["sets", "the", "disconnected", "callback", "to", "handle", "cleaning", "up", "controller"], "project": "ExoPlayer"}
{"id": 1063, "code": "default void onDrmSessionReleased(int windowIndex, @Nullable MediaPeriodId mediaPeriodId) {}", "summary_tokens": ["called", "each", "time", "a", "drm", "session", "is", "released"], "project": "ExoPlayer"}
{"id": 1055, "code": "private static List<SchemeData> getSchemeDatas(\n    DrmInitData drmInitData, UUID uuid, boolean allowMissingData) {\n    \n  List<SchemeData> matchingSchemeDatas = new ArrayList<>(drmInitData.schemeDataCount);\n  for (int i = 0; i < drmInitData.schemeDataCount; i++) {\n    SchemeData schemeData = drmInitData.get(i);\n    boolean uuidMatches =\n        schemeData.matches(uuid)\n            || (C.CLEARKEY_UUID.equals(uuid) && schemeData.matches(C.COMMON_PSSH_UUID));\n    if (uuidMatches && (schemeData.data != null || allowMissingData)) {\n      matchingSchemeDatas.add(schemeData);\n    }\n  }\n  return matchingSchemeDatas;\n}", "summary_tokens": ["extracts", "scheme", "data", "instances", "suitable", "for", "the", "given", "drm", "scheme", "uuid"], "project": "ExoPlayer"}
{"id": 2074, "code": "public boolean isCompleted() {\n  return isCompleted;\n}", "summary_tokens": ["returns", "whether", "the", "buffer", "currently", "holds", "a", "complete", "nal", "unit", "of", "the", "target", "type"], "project": "ExoPlayer"}
{"id": 1424, "code": "public boolean isRendererEnabled(int index) {\n  return rendererConfigurations[index] != null;\n}", "summary_tokens": ["returns", "whether", "the", "renderer", "at", "the", "specified", "index", "is", "enabled"], "project": "ExoPlayer"}
{"id": 2442, "code": "protected void maybeQueueSampleToPipeline(DecoderInputBuffer inputBuffer)\n    throws TransformationException {\n  if (sefSlowMotionFlattener == null) {\n    samplePipeline.queueInputBuffer();\n    return;\n  }\n\n  ByteBuffer data = inputBuffer.data;\n  long presentationTimeUs = inputBuffer.timeUs - streamOffsetUs;\n  boolean shouldDropSample =\n      sefSlowMotionFlattener.dropOrTransformSample(data, presentationTimeUs);\n  inputBuffer.timeUs = streamOffsetUs + sefSlowMotionFlattener.getSamplePresentationTimeUs();\n  if (shouldDropSample) {\n    data.clear();\n  } else {\n    samplePipeline.queueInputBuffer();\n  }\n}", "summary_tokens": ["queues", "the", "input", "buffer", "to", "the", "sample", "pipeline", "unless", "it", "should", "be", "dropped", "because", "of", "slow", "motion", "flattening"], "project": "ExoPlayer"}
{"id": 1671, "code": "public static void loadInitializationData(\n    ChunkExtractor chunkExtractor,\n    DataSource dataSource,\n    Representation representation,\n    boolean loadIndex)\n    throws IOException {\n  loadInitializationData(\n      chunkExtractor, dataSource, representation,  0, loadIndex);\n}", "summary_tokens": ["loads", "initialization", "data", "for", "the", "representation", "and", "optionally", "index", "data", "then", "returns", "a", "bundled", "chunk", "extractor", "which", "contains", "the", "output"], "project": "ExoPlayer"}
{"id": 1695, "code": "public void skipDataThenReadDataReturnDataFromSkippedPosition() {\n  long presentationTimeUs1 = 1000000;\n  long presentationTimeUs2 = 2000000;\n  EventMessage eventMessage1 = newEventMessageWithId(1);\n  EventMessage eventMessage2 = newEventMessageWithId(2);\n  EventStream eventStream =\n      new EventStream(\n          SCHEME_ID,\n          VALUE,\n          TIME_SCALE,\n          new long[] {presentationTimeUs1, presentationTimeUs2},\n          new EventMessage[] {eventMessage1, eventMessage2});\n  EventSampleStream sampleStream = new EventSampleStream(eventStream, FORMAT, false);\n    \n  readData(sampleStream);\n\n  int skipped = sampleStream.skipData(presentationTimeUs2);\n  int result = readData(sampleStream);\n  assertThat(skipped).isEqualTo(1);\n  assertThat(result).isEqualTo(C.RESULT_BUFFER_READ);\n  assertThat(inputBuffer.data.array()).isEqualTo(getEncodedMessage(eventMessage2));\n}", "summary_tokens": ["tests", "that", "event", "sample", "stream", "skip", "data", "long", "will", "skip", "until", "the", "given", "position", "and", "the", "next", "event", "sample", "stream", "read", "data", "format", "holder", "decoder", "input", "buffer", "int", "call", "will", "return", "sample", "data", "from", "that", "position"], "project": "ExoPlayer"}
{"id": 535, "code": "public static boolean isMatroska(@Nullable String mimeType) {\n  if (mimeType == null) {\n    return false;\n  }\n  return mimeType.startsWith(MimeTypes.VIDEO_WEBM)\n      || mimeType.startsWith(MimeTypes.AUDIO_WEBM)\n      || mimeType.startsWith(MimeTypes.APPLICATION_WEBM)\n      || mimeType.startsWith(MimeTypes.VIDEO_MATROSKA)\n      || mimeType.startsWith(MimeTypes.AUDIO_MATROSKA)\n      || mimeType.startsWith(MimeTypes.APPLICATION_MATROSKA);\n}", "summary_tokens": ["returns", "whether", "the", "given", "mime", "type", "is", "a", "matroska", "mime", "type", "including", "web", "m"], "project": "ExoPlayer"}
{"id": 1747, "code": "public CacheKeyFactory getCacheKeyFactory() {\n  return cacheKeyFactory;\n}", "summary_tokens": ["returns", "the", "cache", "key", "factory", "used", "by", "this", "instance"], "project": "ExoPlayer"}
{"id": 1653, "code": "public void roundTripViaBundle_ofSelectionOverride_yieldsEqualInstance() {\n  SelectionOverride selectionOverrideToBundle =\n      new SelectionOverride( 1,  2, 3);\n\n  SelectionOverride selectionOverrideFromBundle =\n      DefaultTrackSelector.SelectionOverride.CREATOR.fromBundle(\n          selectionOverrideToBundle.toBundle());\n\n  assertThat(selectionOverrideFromBundle).isEqualTo(selectionOverrideToBundle);\n}", "summary_tokens": ["tests", "selection", "override", "s", "bundleable", "implementation"], "project": "ExoPlayer"}
{"id": 136, "code": "public static long[] getAdGroupTimesUsForCuePoints(List<Float> cuePoints) {\n  if (cuePoints.isEmpty()) {\n    return new long[] {0L};\n  }\n\n  int count = cuePoints.size();\n  long[] adGroupTimesUs = new long[count];\n  int adGroupIndex = 0;\n  for (int i = 0; i < count; i++) {\n    double cuePoint = cuePoints.get(i);\n    if (cuePoint == -1.0) {\n      adGroupTimesUs[count - 1] = C.TIME_END_OF_SOURCE;\n    } else {\n      adGroupTimesUs[adGroupIndex++] = Math.round(C.MICROS_PER_SECOND * cuePoint);\n    }\n  }\n    \n  Arrays.sort(adGroupTimesUs, 0, adGroupIndex);\n  return adGroupTimesUs;\n}", "summary_tokens": ["returns", "the", "microsecond", "ad", "group", "timestamps", "corresponding", "to", "the", "specified", "cue", "points"], "project": "ExoPlayer"}
{"id": 2561, "code": "public void setPlayer(@Nullable Player player) {\n  Assertions.checkState(Looper.myLooper() == Looper.getMainLooper());\n  Assertions.checkArgument(\n      player == null || player.getApplicationLooper() == Looper.getMainLooper());\n  if (this.player == player) {\n    return;\n  }\n  if (this.player != null) {\n    this.player.removeListener(componentListener);\n  }\n  this.player = player;\n  if (player != null) {\n    player.addListener(componentListener);\n  }\n  if (player instanceof ForwardingPlayer) {\n    player = ((ForwardingPlayer) player).getWrappedPlayer();\n  }\n  updateAll();\n}", "summary_tokens": ["sets", "the", "player", "to", "control"], "project": "ExoPlayer"}
{"id": 781, "code": "public PlaybackInfo copyWithPlaybackParameters(PlaybackParameters playbackParameters) {\n  return new PlaybackInfo(\n      timeline,\n      periodId,\n      requestedContentPositionUs,\n      discontinuityStartPositionUs,\n      playbackState,\n      playbackError,\n      isLoading,\n      trackGroups,\n      trackSelectorResult,\n      staticMetadata,\n      loadingMediaPeriodId,\n      playWhenReady,\n      playbackSuppressionReason,\n      playbackParameters,\n      bufferedPositionUs,\n      totalBufferedDurationUs,\n      positionUs,\n      sleepingForOffload);\n}", "summary_tokens": ["copies", "playback", "info", "with", "new", "playback", "parameters"], "project": "ExoPlayer"}
{"id": 2606, "code": "public void setErrorMessageProvider(\n    @Nullable ErrorMessageProvider<? super PlaybackException> errorMessageProvider) {\n  if (this.errorMessageProvider != errorMessageProvider) {\n    this.errorMessageProvider = errorMessageProvider;\n    updateErrorMessage();\n  }\n}", "summary_tokens": ["sets", "the", "optional", "error", "message", "provider"], "project": "ExoPlayer"}
{"id": 1234, "code": "public static void sendSetRequirements(\n    Context context,\n    Class<? extends DownloadService> clazz,\n    Requirements requirements,\n    boolean foreground) {\n  Intent intent = buildSetRequirementsIntent(context, clazz, requirements, foreground);\n  startService(context, intent, foreground);\n}", "summary_tokens": ["starts", "the", "service", "if", "not", "started", "already", "and", "sets", "the", "requirements", "that", "need", "to", "be", "met", "for", "downloads", "to", "progress"], "project": "ExoPlayer"}
{"id": 812, "code": "public DeviceComponent getDeviceComponent() {\n  return this;\n}", "summary_tokens": ["use", "player", "as", "the", "device", "component", "methods", "are", "defined", "by", "that", "interface"], "project": "ExoPlayer"}
{"id": 25, "code": "public boolean isCastSessionAvailable() {\n  return remoteMediaClient != null;\n}", "summary_tokens": ["returns", "whether", "a", "cast", "session", "is", "available"], "project": "ExoPlayer"}
{"id": 2783, "code": "public void setHandleWakeLock(boolean handleWakeLock) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["use", "set", "wake", "mode", "int", "instead"], "project": "ExoPlayer"}
{"id": 2367, "code": "private static ImmutableList<MediaCodecInfo> filterEncodersByBitrate(\n    List<MediaCodecInfo> encoders, String mimeType, int requestedBitrate) {\n  return filterEncoders(\n      encoders,\n       (encoderInfo) -> {\n        int achievableBitrate =\n            EncoderUtil.getSupportedBitrateRange(encoderInfo, mimeType).clamp(requestedBitrate);\n        return abs(achievableBitrate - requestedBitrate);\n      },\n       \"bitrate\");\n}", "summary_tokens": ["returns", "a", "list", "of", "encoders", "that", "support", "the", "requested", "bitrate", "most", "closely"], "project": "ExoPlayer"}
{"id": 964, "code": "private static int getMaxSupportedChannelCountForPassthrough(\n    @C.Encoding int encoding, int sampleRate) {\n    \n    \n    \n  if (Util.SDK_INT >= 29) {\n    return Api29.getMaxSupportedChannelCountForPassthrough(encoding, sampleRate);\n  }\n  return checkNotNull(ALL_SURROUND_ENCODINGS_AND_MAX_CHANNELS.getOrDefault(encoding, 0));\n}", "summary_tokens": ["returns", "the", "maximum", "number", "of", "channels", "supported", "for", "passthrough", "playback", "of", "audio", "in", "the", "given", "encoding", "or", "0", "if", "the", "format", "is", "unsupported"], "project": "ExoPlayer"}
{"id": 1663, "code": "public void updateManifest(DashManifest manifest, int periodIndex) {\n  this.manifest = manifest;\n  this.periodIndex = periodIndex;\n  playerEmsgHandler.updateManifest(manifest);\n  if (sampleStreams != null) {\n    for (ChunkSampleStream<DashChunkSource> sampleStream : sampleStreams) {\n      sampleStream.getChunkSource().updateManifest(manifest, periodIndex);\n    }\n    callback.onContinueLoadingRequested(this);\n  }\n  eventStreams = manifest.getPeriod(periodIndex).eventStreams;\n  for (EventSampleStream eventSampleStream : eventSampleStreams) {\n    for (EventStream eventStream : eventStreams) {\n      if (eventStream.id().equals(eventSampleStream.eventStreamId())) {\n        int lastPeriodIndex = manifest.getPeriodCount() - 1;\n        eventSampleStream.updateEventStream(\n            eventStream,\n             manifest.dynamic && periodIndex == lastPeriodIndex);\n        break;\n      }\n    }\n  }\n}", "summary_tokens": ["updates", "the", "dash", "manifest", "and", "the", "index", "of", "this", "period", "in", "the", "manifest"], "project": "ExoPlayer"}
{"id": 1527, "code": "default void onDroppedFrames(int count, long elapsedMs) {}", "summary_tokens": ["called", "to", "report", "the", "number", "of", "frames", "dropped", "by", "the", "renderer"], "project": "ExoPlayer"}
{"id": 1805, "code": "public final boolean isFirstSample() {\n  return getFlag(C.BUFFER_FLAG_FIRST_SAMPLE);\n}", "summary_tokens": ["returns", "whether", "the", "c", "buffer", "flag", "first", "sample", "flag", "is", "set"], "project": "ExoPlayer"}
{"id": 2762, "code": "public static void assertTrackGroups(MediaPeriod mediaPeriod, TrackGroupArray expectedGroups) {\n  TrackGroupArray actualGroups = prepareAndGetTrackGroups(mediaPeriod);\n  assertThat(actualGroups).isEqualTo(expectedGroups);\n}", "summary_tokens": ["prepares", "the", "media", "period", "and", "asserts", "that", "it", "provides", "the", "specified", "track", "groups"], "project": "ExoPlayer"}
{"id": 1580, "code": "public void getNextLoadPositionUsReturnMinimumNonEndOfSourceLoaderNextLoadPositionUs() {\n  FakeSequenceableLoader loader1 =\n      new FakeSequenceableLoader( 1000,  2000);\n  FakeSequenceableLoader loader2 =\n      new FakeSequenceableLoader( 1001,  2001);\n  FakeSequenceableLoader loader3 =\n      new FakeSequenceableLoader(\n           1001,  C.TIME_END_OF_SOURCE);\n  CompositeSequenceableLoader compositeSequenceableLoader =\n      new CompositeSequenceableLoader(new SequenceableLoader[] {loader1, loader2, loader3});\n  assertThat(compositeSequenceableLoader.getNextLoadPositionUs()).isEqualTo(2000);\n}", "summary_tokens": ["tests", "that", "composite", "sequenceable", "loader", "get", "next", "load", "position", "us", "returns", "minimum", "next", "load", "position", "that", "is", "not", "c", "time", "end", "of", "source", "among", "all", "sub", "loaders"], "project": "ExoPlayer"}
{"id": 2021, "code": "public boolean populate(ExtractorInput input) throws IOException {\n  Assertions.checkState(input != null);\n\n  if (populated) {\n    populated = false;\n    packetArray.reset( 0);\n  }\n\n  while (!populated) {\n    if (currentSegmentIndex < 0) {\n        \n      if (!pageHeader.skipToNextPage(input) || !pageHeader.populate(input,  true)) {\n        return false;\n      }\n      int segmentIndex = 0;\n      int bytesToSkip = pageHeader.headerSize;\n      if ((pageHeader.type & 0x01) == 0x01 && packetArray.limit() == 0) {\n          \n          \n        bytesToSkip += calculatePacketSize(segmentIndex);\n        segmentIndex += segmentCount;\n      }\n      if (!skipFullyQuietly(input, bytesToSkip)) {\n        return false;\n      }\n      currentSegmentIndex = segmentIndex;\n    }\n\n    int size = calculatePacketSize(currentSegmentIndex);\n    int segmentIndex = currentSegmentIndex + segmentCount;\n    if (size > 0) {\n      packetArray.ensureCapacity(packetArray.limit() + size);\n      if (!readFullyQuietly(input, packetArray.getData(), packetArray.limit(), size)) {\n        return false;\n      }\n      packetArray.setLimit(packetArray.limit() + size);\n      populated = pageHeader.laces[segmentIndex - 1] != 255;\n    }\n      \n    currentSegmentIndex =\n        segmentIndex == pageHeader.pageSegmentCount ? C.INDEX_UNSET : segmentIndex;\n  }\n  return true;\n}", "summary_tokens": ["reads", "the", "next", "packet", "of", "the", "ogg", "stream"], "project": "ExoPlayer"}
{"id": 1453, "code": "private void ensureSortedByIndex() {\n  if (currentSortOrder != SORT_ORDER_BY_INDEX) {\n    Collections.sort(samples, INDEX_COMPARATOR);\n    currentSortOrder = SORT_ORDER_BY_INDEX;\n  }\n}", "summary_tokens": ["sorts", "the", "samples", "by", "index"], "project": "ExoPlayer"}
{"id": 1020, "code": "private static boolean deviceDoesntSupportOperatingRate() {\n  return Util.SDK_INT == 23\n      && (\"ZTE B2017G\".equals(Util.MODEL) || \"AXON 7 mini\".equals(Util.MODEL));\n}", "summary_tokens": ["returns", "whether", "the", "device", "s", "decoders", "are", "known", "to", "not", "support", "setting", "the", "codec", "operating", "rate"], "project": "ExoPlayer"}
{"id": 979, "code": "public void rejectTimestamp() {\n  updateState(STATE_ERROR);\n}", "summary_tokens": ["rejects", "the", "timestamp", "last", "polled", "in", "maybe", "poll", "timestamp", "long"], "project": "ExoPlayer"}
{"id": 1184, "code": "private static int avcLevelToMaxFrameSize(int avcLevel) {\n  switch (avcLevel) {\n    case CodecProfileLevel.AVCLevel1:\n    case CodecProfileLevel.AVCLevel1b:\n      return 99 * 16 * 16;\n    case CodecProfileLevel.AVCLevel12:\n    case CodecProfileLevel.AVCLevel13:\n    case CodecProfileLevel.AVCLevel2:\n      return 396 * 16 * 16;\n    case CodecProfileLevel.AVCLevel21:\n      return 792 * 16 * 16;\n    case CodecProfileLevel.AVCLevel22:\n    case CodecProfileLevel.AVCLevel3:\n      return 1620 * 16 * 16;\n    case CodecProfileLevel.AVCLevel31:\n      return 3600 * 16 * 16;\n    case CodecProfileLevel.AVCLevel32:\n      return 5120 * 16 * 16;\n    case CodecProfileLevel.AVCLevel4:\n    case CodecProfileLevel.AVCLevel41:\n      return 8192 * 16 * 16;\n    case CodecProfileLevel.AVCLevel42:\n      return 8704 * 16 * 16;\n    case CodecProfileLevel.AVCLevel5:\n      return 22080 * 16 * 16;\n    case CodecProfileLevel.AVCLevel51:\n    case CodecProfileLevel.AVCLevel52:\n      return 36864 * 16 * 16;\n    case CodecProfileLevel.AVCLevel6:\n    case CodecProfileLevel.AVCLevel61:\n    case CodecProfileLevel.AVCLevel62:\n      return 139264 * 16 * 16;\n    default:\n      return -1;\n  }\n}", "summary_tokens": ["conversion", "values", "taken", "from", "iso", "0", "0", "table", "a", "0"], "project": "ExoPlayer"}
{"id": 564, "code": "public int capacity() {\n  return data.length;\n}", "summary_tokens": ["returns", "the", "capacity", "of", "the", "array", "which", "may", "be", "larger", "than", "the", "limit"], "project": "ExoPlayer"}
{"id": 381, "code": "public int getPreviousWindowIndex(\n    int windowIndex, @Player.RepeatMode int repeatMode, boolean shuffleModeEnabled) {\n  switch (repeatMode) {\n    case Player.REPEAT_MODE_OFF:\n      return windowIndex == getFirstWindowIndex(shuffleModeEnabled)\n          ? C.INDEX_UNSET\n          : windowIndex - 1;\n    case Player.REPEAT_MODE_ONE:\n      return windowIndex;\n    case Player.REPEAT_MODE_ALL:\n      return windowIndex == getFirstWindowIndex(shuffleModeEnabled)\n          ? getLastWindowIndex(shuffleModeEnabled)\n          : windowIndex - 1;\n    default:\n      throw new IllegalStateException();\n  }\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "window", "before", "the", "window", "at", "index", "window", "index", "depending", "on", "the", "repeat", "mode", "and", "whether", "shuffling", "is", "enabled"], "project": "ExoPlayer"}
{"id": 471, "code": "public void setSamplerTexIdUniform(String name, int texId, int texUnitIndex) {\n  checkNotNull(uniformByName.get(name)).setSamplerTexId(texId, texUnitIndex);\n}", "summary_tokens": ["sets", "a", "texture", "sampler", "type", "uniform"], "project": "ExoPlayer"}
{"id": 813, "code": "public void prepare(MediaSource mediaSource, boolean resetPosition, boolean resetState) {\n  blockUntilConstructorFinished();\n  player.prepare(mediaSource, resetPosition, resetState);\n}", "summary_tokens": ["use", "set", "media", "source", "media", "source", "boolean", "and", "exo", "player", "prepare", "instead"], "project": "ExoPlayer"}
{"id": 1399, "code": "public void setCurrentPosition(long position) {\n  currentPosition = position;\n}", "summary_tokens": ["sets", "the", "absolute", "position", "in", "the", "resource", "from", "which", "the", "wrapped", "data", "reader", "reads"], "project": "ExoPlayer"}
{"id": 2095, "code": "public static Pair<Long, Long> skipToSampleData(ExtractorInput input) throws IOException {\n    \n  input.resetPeekPosition();\n\n  ParsableByteArray scratch = new ParsableByteArray(ChunkHeader.SIZE_IN_BYTES);\n    \n  ChunkHeader chunkHeader = skipToChunk( WavUtil.DATA_FOURCC, input, scratch);\n    \n  input.skipFully(ChunkHeader.SIZE_IN_BYTES);\n\n  long dataStartPosition = input.getPosition();\n  return Pair.create(dataStartPosition, chunkHeader.size);\n}", "summary_tokens": ["skips", "to", "the", "data", "in", "the", "given", "wav", "input", "stream", "and", "returns", "its", "start", "position", "and", "size"], "project": "ExoPlayer"}
{"id": 842, "code": "default void onSeekBackIncrementChanged(EventTime eventTime, long seekBackIncrementMs) {}", "summary_tokens": ["called", "when", "the", "seek", "back", "increment", "changed"], "project": "ExoPlayer"}
{"id": 1717, "code": "public void open() throws IOException {\n  checkOpened();\n}", "summary_tokens": ["optional", "call", "to", "open", "the", "underlying", "data", "source"], "project": "ExoPlayer"}
{"id": 1228, "code": "public static void sendAddDownload(\n    Context context,\n    Class<? extends DownloadService> clazz,\n    DownloadRequest downloadRequest,\n    int stopReason,\n    boolean foreground) {\n  Intent intent = buildAddDownloadIntent(context, clazz, downloadRequest, stopReason, foreground);\n  startService(context, intent, foreground);\n}", "summary_tokens": ["starts", "the", "service", "if", "not", "started", "already", "and", "adds", "a", "new", "download"], "project": "ExoPlayer"}
{"id": 1007, "code": "protected DecoderReuseEvaluation canReuseDecoder(\n    String decoderName, Format oldFormat, Format newFormat) {\n  return new DecoderReuseEvaluation(\n      decoderName, oldFormat, newFormat, REUSE_RESULT_NO, DISCARD_REASON_REUSE_NOT_IMPLEMENTED);\n}", "summary_tokens": ["evaluates", "whether", "the", "existing", "decoder", "can", "be", "reused", "for", "a", "new", "format"], "project": "ExoPlayer"}
{"id": 1137, "code": "protected DecoderReuseEvaluation onInputFormatChanged(FormatHolder formatHolder)\n    throws ExoPlaybackException {\n  waitingForFirstSampleInFormat = true;\n  Format newFormat = checkNotNull(formatHolder.format);\n  if (newFormat.sampleMimeType == null) {\n      \n      \n\n    throw createRendererException(\n        new IllegalArgumentException(),\n        newFormat,\n        PlaybackException.ERROR_CODE_DECODING_FORMAT_UNSUPPORTED);\n  }\n  setSourceDrmSession(formatHolder.drmSession);\n  inputFormat = newFormat;\n\n  if (bypassEnabled) {\n    bypassDrainAndReinitialize = true;\n    return null; \n  }\n\n  if (codec == null) {\n    availableCodecInfos = null;\n    maybeInitCodecOrBypass();\n    return null;\n  }\n\n    \n    \n    \n\n    \n    \n  MediaCodecAdapter codec = this.codec;\n  MediaCodecInfo codecInfo = this.codecInfo;\n\n  Format oldFormat = codecInputFormat;\n  if (drmNeedsCodecReinitialization(codecInfo, newFormat, codecDrmSession, sourceDrmSession)) {\n    drainAndReinitializeCodec();\n    return new DecoderReuseEvaluation(\n        codecInfo.name,\n        oldFormat,\n        newFormat,\n        REUSE_RESULT_NO,\n        DISCARD_REASON_DRM_SESSION_CHANGED);\n  }\n  boolean drainAndUpdateCodecDrmSession = sourceDrmSession != codecDrmSession;\n  Assertions.checkState(!drainAndUpdateCodecDrmSession || Util.SDK_INT >= 23);\n\n  DecoderReuseEvaluation evaluation = canReuseCodec(codecInfo, oldFormat, newFormat);\n  @DecoderDiscardReasons int overridingDiscardReasons = 0;\n  switch (evaluation.result) {\n    case REUSE_RESULT_NO:\n      drainAndReinitializeCodec();\n      break;\n    case REUSE_RESULT_YES_WITH_FLUSH:\n      if (!updateCodecOperatingRate(newFormat)) {\n        overridingDiscardReasons |= DISCARD_REASON_OPERATING_RATE_CHANGED;\n      } else {\n        codecInputFormat = newFormat;\n        if (drainAndUpdateCodecDrmSession) {\n          if (!drainAndUpdateCodecDrmSessionV23()) {\n            overridingDiscardReasons |= DISCARD_REASON_WORKAROUND;\n          }\n        } else if (!drainAndFlushCodec()) {\n          overridingDiscardReasons |= DISCARD_REASON_WORKAROUND;\n        }\n      }\n      break;\n    case REUSE_RESULT_YES_WITH_RECONFIGURATION:\n      if (!updateCodecOperatingRate(newFormat)) {\n        overridingDiscardReasons |= DISCARD_REASON_OPERATING_RATE_CHANGED;\n      } else {\n        codecReconfigured = true;\n        codecReconfigurationState = RECONFIGURATION_STATE_WRITE_PENDING;\n        codecNeedsAdaptationWorkaroundBuffer =\n            codecAdaptationWorkaroundMode == ADAPTATION_WORKAROUND_MODE_ALWAYS\n                || (codecAdaptationWorkaroundMode == ADAPTATION_WORKAROUND_MODE_SAME_RESOLUTION\n                    && newFormat.width == oldFormat.width\n                    && newFormat.height == oldFormat.height);\n        codecInputFormat = newFormat;\n        if (drainAndUpdateCodecDrmSession && !drainAndUpdateCodecDrmSessionV23()) {\n          overridingDiscardReasons |= DISCARD_REASON_WORKAROUND;\n        }\n      }\n      break;\n    case REUSE_RESULT_YES_WITHOUT_RECONFIGURATION:\n      if (!updateCodecOperatingRate(newFormat)) {\n        overridingDiscardReasons |= DISCARD_REASON_OPERATING_RATE_CHANGED;\n      } else {\n        codecInputFormat = newFormat;\n        if (drainAndUpdateCodecDrmSession && !drainAndUpdateCodecDrmSessionV23()) {\n          overridingDiscardReasons |= DISCARD_REASON_WORKAROUND;\n        }\n      }\n      break;\n    default:\n      throw new IllegalStateException(); \n  }\n\n  if (evaluation.result != REUSE_RESULT_NO\n      && (this.codec != codec || codecDrainAction == DRAIN_ACTION_REINITIALIZE)) {\n      \n      \n    return new DecoderReuseEvaluation(\n        codecInfo.name, oldFormat, newFormat, REUSE_RESULT_NO, overridingDiscardReasons);\n  }\n\n  return evaluation;\n}", "summary_tokens": ["called", "when", "a", "new", "format", "is", "read", "from", "the", "upstream", "media", "period"], "project": "ExoPlayer"}
{"id": 2317, "code": "private static long toSampleTimeUs(\n    long startTimeOffsetUs, long rtpTimestamp, long firstReceivedRtpTimestamp, int sampleRate) {\n  return startTimeOffsetUs\n      + Util.scaleLargeTimestamp(\n          rtpTimestamp - firstReceivedRtpTimestamp,\n           C.MICROS_PER_SECOND,\n           sampleRate);\n}", "summary_tokens": ["returns", "the", "correct", "sample", "time", "from", "rtp", "timestamp", "accounting", "for", "the", "amr", "sampling", "rate"], "project": "ExoPlayer"}
{"id": 1711, "code": "protected final void bytesTransferred(int bytesTransferred) {\n  DataSpec dataSpec = castNonNull(this.dataSpec);\n  for (int i = 0; i < listenerCount; i++) {\n    listeners\n        .get(i)\n        .onBytesTransferred( this, dataSpec, isNetwork, bytesTransferred);\n  }\n}", "summary_tokens": ["notifies", "listeners", "that", "bytes", "were", "transferred"], "project": "ExoPlayer"}
{"id": 1578, "code": "public void getBufferedPositionUsReturnsEndOfSourceWhenAllLoaderBufferedTillEndOfSource() {\n  FakeSequenceableLoader loader1 =\n      new FakeSequenceableLoader(\n           C.TIME_END_OF_SOURCE,\n           C.TIME_END_OF_SOURCE);\n  FakeSequenceableLoader loader2 =\n      new FakeSequenceableLoader(\n           C.TIME_END_OF_SOURCE,\n           C.TIME_END_OF_SOURCE);\n  CompositeSequenceableLoader compositeSequenceableLoader =\n      new CompositeSequenceableLoader(new SequenceableLoader[] {loader1, loader2});\n  assertThat(compositeSequenceableLoader.getBufferedPositionUs()).isEqualTo(C.TIME_END_OF_SOURCE);\n}", "summary_tokens": ["tests", "that", "composite", "sequenceable", "loader", "get", "buffered", "position", "us", "returns", "c", "time", "end", "of", "source", "when", "all", "sub", "loaders", "have", "buffered", "till", "end", "of", "source"], "project": "ExoPlayer"}
{"id": 1641, "code": "public void textTrackSelectionFlags() throws ExoPlaybackException {\n  Format.Builder formatBuilder = TEXT_FORMAT.buildUpon().setLanguage(\"eng\");\n  Format forcedOnly = formatBuilder.setSelectionFlags(C.SELECTION_FLAG_FORCED).build();\n  Format forcedDefault =\n      formatBuilder.setSelectionFlags(C.SELECTION_FLAG_FORCED | C.SELECTION_FLAG_DEFAULT).build();\n  Format defaultOnly = formatBuilder.setSelectionFlags(C.SELECTION_FLAG_DEFAULT).build();\n  Format noFlag = formatBuilder.setSelectionFlags(0).build();\n\n  RendererCapabilities[] textRendererCapabilities =\n      new RendererCapabilities[] {ALL_TEXT_FORMAT_SUPPORTED_RENDERER_CAPABILITIES};\n\n    \n  TrackGroupArray trackGroups = wrapFormats(forcedOnly, forcedDefault, defaultOnly, noFlag);\n  TrackSelectorResult result =\n      trackSelector.selectTracks(textRendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, forcedDefault);\n\n    \n  trackGroups = wrapFormats(forcedOnly, noFlag, defaultOnly);\n  result = trackSelector.selectTracks(textRendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, defaultOnly);\n\n    \n    \n  trackGroups = wrapFormats(defaultOnly, noFlag, forcedOnly, forcedDefault);\n  trackSelector.setParameters(\n      defaultParameters.buildUpon().setIgnoredTextSelectionFlags(C.SELECTION_FLAG_DEFAULT));\n  result = trackSelector.selectTracks(textRendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertNoSelection(result.selections[0]);\n\n    \n    \n  trackGroups = wrapFormats(forcedOnly, forcedDefault, defaultOnly, noFlag);\n  trackSelector.setParameters(\n      trackSelector\n          .getParameters()\n          .buildUpon()\n          .setIgnoredTextSelectionFlags(C.SELECTION_FLAG_DEFAULT | C.SELECTION_FLAG_FORCED));\n  result = trackSelector.selectTracks(textRendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertNoSelection(result.selections[0]);\n\n    \n    \n  trackSelector.setParameters(defaultParameters.buildUpon().setPreferredTextLanguage(\"eng\"));\n  result = trackSelector.selectTracks(textRendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, defaultOnly);\n\n    \n    \n    \n  trackGroups = wrapFormats(noFlag, forcedOnly, forcedDefault, defaultOnly);\n  trackSelector.setParameters(\n      trackSelector\n          .getParameters()\n          .buildUpon()\n          .setIgnoredTextSelectionFlags(C.SELECTION_FLAG_DEFAULT));\n  result = trackSelector.selectTracks(textRendererCapabilities, trackGroups, periodId, TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, noFlag);\n}", "summary_tokens": ["tests", "text", "track", "selection", "flags"], "project": "ExoPlayer"}
{"id": 2027, "code": "public boolean skipToNextPage(ExtractorInput input, long limit) throws IOException {\n  Assertions.checkArgument(input.getPosition() == input.getPeekPosition());\n  scratch.reset( CAPTURE_PATTERN_SIZE);\n  while ((limit == C.POSITION_UNSET || input.getPosition() + CAPTURE_PATTERN_SIZE < limit)\n      && peekFullyQuietly(\n          input, scratch.getData(), 0, CAPTURE_PATTERN_SIZE,  true)) {\n    scratch.setPosition(0);\n    if (scratch.readUnsignedInt() == CAPTURE_PATTERN) {\n      input.resetPeekPosition();\n      return true;\n    }\n      \n    input.skipFully(1);\n  }\n    \n  while ((limit == C.POSITION_UNSET || input.getPosition() < limit)\n      && input.skip(1) != C.RESULT_END_OF_INPUT) {}\n  return false;\n}", "summary_tokens": ["advances", "through", "input", "looking", "for", "the", "start", "of", "the", "next", "ogg", "page"], "project": "ExoPlayer"}
{"id": 1304, "code": "public void reset() {\n  clearAllocationNodes(firstAllocationNode);\n  firstAllocationNode.reset( 0, allocationLength);\n  readAllocationNode = firstAllocationNode;\n  writeAllocationNode = firstAllocationNode;\n  totalBytesWritten = 0;\n  allocator.trim();\n}", "summary_tokens": ["clears", "all", "sample", "data"], "project": "ExoPlayer"}
{"id": 419, "code": "public static <T> T checkStateNotNull(@Nullable T reference, Object errorMessage) {\n  if (ExoPlayerLibraryInfo.ASSERTIONS_ENABLED && reference == null) {\n    throw new IllegalStateException(String.valueOf(errorMessage));\n  }\n  return reference;\n}", "summary_tokens": ["throws", "illegal", "state", "exception", "if", "reference", "is", "null"], "project": "ExoPlayer"}
{"id": 2371, "code": "private static String findFallbackMimeType(\n    EncoderSelector encoderSelector, String requestedMimeType, List<String> allowedMimeTypes) {\n  if (mimeTypeIsSupported(encoderSelector, requestedMimeType, allowedMimeTypes)) {\n    return requestedMimeType;\n  } else if (mimeTypeIsSupported(encoderSelector, MimeTypes.VIDEO_H265, allowedMimeTypes)) {\n    return MimeTypes.VIDEO_H265;\n  } else if (mimeTypeIsSupported(encoderSelector, MimeTypes.VIDEO_H264, allowedMimeTypes)) {\n    return MimeTypes.VIDEO_H264;\n  } else {\n    for (int i = 0; i < allowedMimeTypes.size(); i++) {\n      String allowedMimeType = allowedMimeTypes.get(i);\n      if (mimeTypeIsSupported(encoderSelector, allowedMimeType, allowedMimeTypes)) {\n        return allowedMimeType;\n      }\n    }\n  }\n  return null;\n}", "summary_tokens": ["finds", "a", "mime", "types", "mime", "type", "that", "is", "supported", "by", "the", "encoder", "and", "in", "the", "allowed", "mime", "types"], "project": "ExoPlayer"}
{"id": 1807, "code": "public final boolean isKeyFrame() {\n  return getFlag(C.BUFFER_FLAG_KEY_FRAME);\n}", "summary_tokens": ["returns", "whether", "the", "c", "buffer", "flag", "key", "frame", "flag", "is", "set"], "project": "ExoPlayer"}
{"id": 1103, "code": "public int remove() {\n  if (size == 0) {\n    throw new NoSuchElementException();\n  }\n\n  int value = data[headIndex];\n  headIndex = (headIndex + 1) & wrapAroundMask;\n  size--;\n\n  return value;\n}", "summary_tokens": ["remove", "an", "item", "from", "the", "queue"], "project": "ExoPlayer"}
{"id": 2329, "code": "private void outputSampleMetadataForFragmentedPackets() {\n  checkNotNull(trackOutput)\n      .sampleMetadata(\n          fragmentedSampleTimeUs,\n          isKeyFrame ? C.BUFFER_FLAG_KEY_FRAME : 0,\n          fragmentedSampleSizeBytes,\n           0,\n           null);\n  fragmentedSampleSizeBytes = 0;\n  fragmentedSampleTimeUs = C.TIME_UNSET;\n  gotFirstPacketOfVp8Frame = false;\n}", "summary_tokens": ["outputs", "sample", "metadata", "of", "the", "received", "fragmented", "packets"], "project": "ExoPlayer"}
{"id": 2668, "code": "public void setAllowMultipleOverrides(boolean allowMultipleOverrides) {\n  if (this.allowMultipleOverrides != allowMultipleOverrides) {\n    this.allowMultipleOverrides = allowMultipleOverrides;\n    if (!allowMultipleOverrides && overrides.size() > 1) {\n        \n      Map<TrackGroup, TrackSelectionOverride> filteredOverrides =\n          filterOverrides(overrides, trackGroups,  false);\n      overrides.clear();\n      overrides.putAll(filteredOverrides);\n    }\n    updateViews();\n  }\n}", "summary_tokens": ["sets", "whether", "tracks", "from", "multiple", "track", "groups", "can", "be", "selected"], "project": "ExoPlayer"}
{"id": 40, "code": "public VideoSize getVideoSize() {\n  return VideoSize.UNKNOWN;\n}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "returns", "video", "size", "unknown"], "project": "ExoPlayer"}
{"id": 33, "code": "public void setVideoSurface(@Nullable Surface surface) {}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "does", "nothing"], "project": "ExoPlayer"}
{"id": 1284, "code": "public static long getNewId() {\n  return idSource.getAndIncrement();\n}", "summary_tokens": ["returns", "an", "non", "negative", "identifier", "which", "is", "unique", "to", "the", "jvm", "instance"], "project": "ExoPlayer"}
{"id": 2510, "code": "protected NotificationCompat.Builder createNotification(\n    Player player,\n    @Nullable NotificationCompat.Builder builder,\n    boolean ongoing,\n    @Nullable Bitmap largeIcon) {\n  if (player.getPlaybackState() == Player.STATE_IDLE && player.getCurrentTimeline().isEmpty()) {\n    builderActions = null;\n    return null;\n  }\n\n  List<String> actionNames = getActions(player);\n  List<NotificationCompat.Action> actions = new ArrayList<>(actionNames.size());\n  for (int i = 0; i < actionNames.size(); i++) {\n    String actionName = actionNames.get(i);\n    @Nullable\n    NotificationCompat.Action action =\n        playbackActions.containsKey(actionName)\n            ? playbackActions.get(actionName)\n            : customActions.get(actionName);\n    if (action != null) {\n      actions.add(action);\n    }\n  }\n\n  if (builder == null || !actions.equals(builderActions)) {\n    builder = new NotificationCompat.Builder(context, channelId);\n    builderActions = actions;\n    for (int i = 0; i < actions.size(); i++) {\n      builder.addAction(actions.get(i));\n    }\n  }\n\n  MediaStyle mediaStyle = new MediaStyle();\n  if (mediaSessionToken != null) {\n    mediaStyle.setMediaSession(mediaSessionToken);\n  }\n  mediaStyle.setShowActionsInCompactView(getActionIndicesForCompactView(actionNames, player));\n    \n  mediaStyle.setShowCancelButton(!ongoing);\n  mediaStyle.setCancelButtonIntent(dismissPendingIntent);\n  builder.setStyle(mediaStyle);\n\n    \n  builder.setDeleteIntent(dismissPendingIntent);\n\n    \n  builder\n      .setBadgeIconType(badgeIconType)\n      .setOngoing(ongoing)\n      .setColor(color)\n      .setColorized(colorized)\n      .setSmallIcon(smallIconResourceId)\n      .setVisibility(visibility)\n      .setPriority(priority)\n      .setDefaults(defaults);\n\n    \n  if (Util.SDK_INT >= 21\n      && useChronometer\n      && player.isPlaying()\n      && !player.isPlayingAd()\n      && !player.isCurrentMediaItemDynamic()\n      && player.getPlaybackParameters().speed == 1f) {\n    builder\n        .setWhen(System.currentTimeMillis() - player.getContentPosition())\n        .setShowWhen(true)\n        .setUsesChronometer(true);\n  } else {\n    builder.setShowWhen(false).setUsesChronometer(false);\n  }\n\n    \n  builder.setContentTitle(mediaDescriptionAdapter.getCurrentContentTitle(player));\n  builder.setContentText(mediaDescriptionAdapter.getCurrentContentText(player));\n  builder.setSubText(mediaDescriptionAdapter.getCurrentSubText(player));\n  if (largeIcon == null) {\n    largeIcon =\n        mediaDescriptionAdapter.getCurrentLargeIcon(\n            player, new BitmapCallback(++currentNotificationTag));\n  }\n  setLargeIcon(builder, largeIcon);\n  builder.setContentIntent(mediaDescriptionAdapter.createCurrentContentIntent(player));\n\n  if (groupKey != null) {\n    builder.setGroup(groupKey);\n  }\n\n  builder.setOnlyAlertOnce(true);\n  return builder;\n}", "summary_tokens": ["creates", "the", "notification", "given", "the", "current", "player", "state"], "project": "ExoPlayer"}
{"id": 1250, "code": "public boolean isStorageNotLowRequired() {\n  return (requirements & DEVICE_STORAGE_NOT_LOW) != 0;\n}", "summary_tokens": ["returns", "whether", "the", "device", "is", "required", "to", "not", "be", "low", "on", "em", "internal", "em", "storage"], "project": "ExoPlayer"}
{"id": 1815, "code": "public static DecoderInputBuffer newNoDataInstance() {\n  return new DecoderInputBuffer(BUFFER_REPLACEMENT_MODE_DISABLED);\n}", "summary_tokens": ["returns", "a", "new", "instance", "that", "s", "not", "able", "to", "hold", "any", "data"], "project": "ExoPlayer"}
{"id": 2657, "code": "public TrackSelectionDialogBuilder setTheme(@StyleRes int themeResId) {\n  this.themeResId = themeResId;\n  return this;\n}", "summary_tokens": ["sets", "the", "resource", "id", "of", "the", "theme", "used", "to", "inflate", "this", "dialog"], "project": "ExoPlayer"}
{"id": 2229, "code": "private void feedDataToExtractor(\n    DataSource dataSource,\n    DataSpec dataSpec,\n    boolean dataIsEncrypted,\n    boolean initializeTimestampAdjuster)\n    throws IOException {\n    \n    \n    \n    \n  DataSpec loadDataSpec;\n  boolean skipLoadedBytes;\n  if (dataIsEncrypted) {\n    loadDataSpec = dataSpec;\n    skipLoadedBytes = nextLoadPosition != 0;\n  } else {\n    loadDataSpec = dataSpec.subrange(nextLoadPosition);\n    skipLoadedBytes = false;\n  }\n  try {\n    ExtractorInput input =\n        prepareExtraction(dataSource, loadDataSpec, initializeTimestampAdjuster);\n    if (skipLoadedBytes) {\n      input.skipFully(nextLoadPosition);\n    }\n    try {\n      while (!loadCanceled && extractor.read(input)) {}\n    } catch (EOFException e) {\n      if ((trackFormat.roleFlags & C.ROLE_FLAG_TRICK_PLAY) != 0) {\n          \n          \n        extractor.onTruncatedSegmentParsed();\n      } else {\n        throw e;\n      }\n    } finally {\n      nextLoadPosition = (int) (input.getPosition() - dataSpec.position);\n    }\n  } finally {\n    DataSourceUtil.closeQuietly(dataSource);\n  }\n}", "summary_tokens": ["attempts", "to", "feed", "the", "given", "data", "spec", "to", "this"], "project": "ExoPlayer"}
{"id": 448, "code": "public synchronized boolean open() {\n  if (isOpen) {\n    return false;\n  }\n  isOpen = true;\n  notifyAll();\n  return true;\n}", "summary_tokens": ["opens", "the", "condition", "and", "releases", "all", "threads", "that", "are", "blocked"], "project": "ExoPlayer"}
{"id": 2552, "code": "public FrameLayout getOverlayFrameLayout() {\n  return overlayFrameLayout;\n}", "summary_tokens": ["gets", "the", "overlay", "frame", "layout", "which", "can", "be", "populated", "with", "ui", "elements", "to", "show", "on", "top", "of", "the", "player"], "project": "ExoPlayer"}
{"id": 1799, "code": "private static void assertDataSourceContent(\n    DataSource dataSource, DataSpec dataSpec, byte[] expectedData) throws IOException {\n  try {\n    long length = dataSource.open(dataSpec);\n    assertThat(length).isEqualTo(expectedData.length);\n    byte[] readData = DataSourceUtil.readToEnd(dataSource);\n    assertThat(readData).isEqualTo(expectedData);\n  } finally {\n    dataSource.close();\n  }\n}", "summary_tokens": ["asserts", "that", "data", "read", "from", "a", "data", "source", "matches", "expected"], "project": "ExoPlayer"}
{"id": 1313, "code": "private static AllocationNode readSampleData(\n    AllocationNode allocationNode,\n    DecoderInputBuffer buffer,\n    SampleExtrasHolder extrasHolder,\n    ParsableByteArray scratch) {\n  if (buffer.isEncrypted()) {\n    allocationNode = readEncryptionData(allocationNode, buffer, extrasHolder, scratch);\n  }\n    \n  if (buffer.hasSupplementalData()) {\n      \n    scratch.reset(4);\n    allocationNode = readData(allocationNode, extrasHolder.offset, scratch.getData(), 4);\n    int sampleSize = scratch.readUnsignedIntToInt();\n    extrasHolder.offset += 4;\n    extrasHolder.size -= 4;\n\n      \n    buffer.ensureSpaceForWrite(sampleSize);\n    allocationNode = readData(allocationNode, extrasHolder.offset, buffer.data, sampleSize);\n    extrasHolder.offset += sampleSize;\n    extrasHolder.size -= sampleSize;\n\n      \n    buffer.resetSupplementalData(extrasHolder.size);\n    allocationNode =\n        readData(allocationNode, extrasHolder.offset, buffer.supplementalData, extrasHolder.size);\n  } else {\n      \n    buffer.ensureSpaceForWrite(extrasHolder.size);\n    allocationNode =\n        readData(allocationNode, extrasHolder.offset, buffer.data, extrasHolder.size);\n  }\n  return allocationNode;\n}", "summary_tokens": ["reads", "data", "from", "the", "rolling", "buffer", "to", "populate", "a", "decoder", "input", "buffer"], "project": "ExoPlayer"}
{"id": 1814, "code": "public void increaseClearDataFirstSubSampleBy(int count) {\n  if (count == 0) {\n    return;\n  }\n  if (numBytesOfClearData == null) {\n    numBytesOfClearData = new int[1];\n    frameworkCryptoInfo.numBytesOfClearData = numBytesOfClearData;\n  }\n  numBytesOfClearData[0] += count;\n}", "summary_tokens": ["increases", "the", "number", "of", "clear", "data", "for", "the", "first", "sub", "sample", "by", "count"], "project": "ExoPlayer"}
{"id": 2694, "code": "public static void assertCacheEmpty(Cache cache) {\n  assertThat(cache.getCacheSpace()).isEqualTo(0);\n  assertThat(cache.getKeys()).isEmpty();\n}", "summary_tokens": ["asserts", "that", "the", "cache", "is", "empty"], "project": "ExoPlayer"}
{"id": 45, "code": "public void setDeviceVolume(int volume) {}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "does", "nothing"], "project": "ExoPlayer"}
{"id": 1493, "code": "protected void onProcessedTunneledBuffer(long presentationTimeUs) throws ExoPlaybackException {\n  updateOutputFormatForTime(presentationTimeUs);\n  maybeNotifyVideoSizeChanged();\n  decoderCounters.renderedOutputBufferCount++;\n  maybeNotifyRenderedFirstFrame();\n  onProcessedOutputBuffer(presentationTimeUs);\n}", "summary_tokens": ["called", "when", "a", "buffer", "was", "processed", "in", "tunneling", "mode"], "project": "ExoPlayer"}
{"id": 2484, "code": "public void setShowVrButton(boolean showVrButton) {\n  if (vrButton != null) {\n    vrButton.setVisibility(showVrButton ? VISIBLE : GONE);\n  }\n}", "summary_tokens": ["sets", "whether", "the", "vr", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 1560, "code": "public void playMultiPeriodTimeline() throws Exception {\n  Timeline timeline = new FakeTimeline( 3);\n  FakeRenderer renderer = new FakeRenderer(C.TRACK_TYPE_VIDEO);\n  ExoPlayer player = new TestExoPlayerBuilder(context).setRenderers(renderer).build();\n  Player.Listener mockPlayerListener = mock(Player.Listener.class);\n  player.addListener(mockPlayerListener);\n\n  player.setMediaSource(new FakeMediaSource(timeline, ExoPlayerTestRunner.VIDEO_FORMAT));\n  player.prepare();\n  player.play();\n  runUntilPlaybackState(player, Player.STATE_ENDED);\n\n  InOrder inOrder = Mockito.inOrder(mockPlayerListener);\n  inOrder\n      .verify(mockPlayerListener)\n      .onTimelineChanged(\n          argThat(noUid(new FakeMediaSource.InitialTimeline(timeline))),\n          eq(Player.DISCONTINUITY_REASON_AUTO_TRANSITION));\n  inOrder\n      .verify(mockPlayerListener)\n      .onTimelineChanged(\n          argThat(noUid(timeline)), eq(Player.TIMELINE_CHANGE_REASON_SOURCE_UPDATE));\n  inOrder\n      .verify(mockPlayerListener, times(2))\n      .onPositionDiscontinuity(any(), any(), eq(Player.DISCONTINUITY_REASON_AUTO_TRANSITION));\n  assertThat(renderer.getFormatsRead())\n      .containsExactly(\n          ExoPlayerTestRunner.VIDEO_FORMAT,\n          ExoPlayerTestRunner.VIDEO_FORMAT,\n          ExoPlayerTestRunner.VIDEO_FORMAT);\n  assertThat(renderer.sampleBufferReadCount).isEqualTo(3);\n  assertThat(renderer.isEnded).isTrue();\n}", "summary_tokens": ["tests", "playback", "of", "a", "source", "that", "exposes", "three", "periods"], "project": "ExoPlayer"}
{"id": 886, "code": "default void onVideoInputFormatChanged(\n    EventTime eventTime,\n    Format format,\n    @Nullable DecoderReuseEvaluation decoderReuseEvaluation) {}", "summary_tokens": ["called", "when", "the", "format", "of", "the", "media", "being", "consumed", "by", "a", "video", "renderer", "changes"], "project": "ExoPlayer"}
{"id": 279, "code": "public boolean isLoading() {\n  return player.isLoading();\n}", "summary_tokens": ["calls", "player", "is", "loading", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 76, "code": "public static void setLibraries(String... libraries) {\n  LOADER.setLibraries(libraries);\n}", "summary_tokens": ["override", "the", "names", "of", "the", "ffmpeg", "native", "libraries"], "project": "ExoPlayer"}
{"id": 2520, "code": "public void setUseArtwork(boolean useArtwork) {\n  Assertions.checkState(!useArtwork || artworkView != null);\n  if (this.useArtwork != useArtwork) {\n    this.useArtwork = useArtwork;\n    updateForCurrentTrackSelections( false);\n  }\n}", "summary_tokens": ["sets", "whether", "artwork", "is", "displayed", "if", "present", "in", "the", "media"], "project": "ExoPlayer"}
{"id": 2459, "code": "public void setScrubberColor(@ColorInt int scrubberColor) {\n  scrubberPaint.setColor(scrubberColor);\n  invalidate(seekBounds);\n}", "summary_tokens": ["sets", "the", "color", "for", "the", "scrubber", "handle"], "project": "ExoPlayer"}
{"id": 2631, "code": "public void setExtraAdGroupMarkers(\n    @Nullable long[] extraAdGroupTimesMs, @Nullable boolean[] extraPlayedAdGroups) {\n  Assertions.checkStateNotNull(controller);\n  controller.setExtraAdGroupMarkers(extraAdGroupTimesMs, extraPlayedAdGroups);\n}", "summary_tokens": ["sets", "the", "millisecond", "positions", "of", "extra", "ad", "markers", "relative", "to", "the", "start", "of", "the", "window", "or", "timeline", "if", "in", "multi", "window", "mode", "and", "whether", "each", "extra", "ad", "has", "been", "played", "or", "not"], "project": "ExoPlayer"}
{"id": 719, "code": "public TrackSelectorResult getTrackSelectorResult() {\n  return trackSelectorResult;\n}", "summary_tokens": ["returns", "the", "track", "selector", "result", "which", "is", "currently", "applied"], "project": "ExoPlayer"}
{"id": 803, "code": "static @Capabilities int create(\n    @C.FormatSupport int formatSupport,\n    @AdaptiveSupport int adaptiveSupport,\n    @TunnelingSupport int tunnelingSupport,\n    @HardwareAccelerationSupport int hardwareAccelerationSupport,\n    @DecoderSupport int decoderSupport) {\n  return formatSupport\n      | adaptiveSupport\n      | tunnelingSupport\n      | hardwareAccelerationSupport\n      | decoderSupport;\n}", "summary_tokens": ["returns", "capabilities", "combining", "the", "given", "c"], "project": "ExoPlayer"}
{"id": 2403, "code": "private void releaseTextureProcessorsAndDestroyGlContext() {\n  try {\n    for (int i = 0; i < textureProcessors.size(); i++) {\n      textureProcessors.get(i).release();\n    }\n    GlUtil.destroyEglContext(eglDisplay, eglContext);\n  } catch (RuntimeException e) {\n    listener.onFrameProcessingError(new FrameProcessingException(e));\n  }\n}", "summary_tokens": ["releases", "the", "single", "frame", "gl", "texture", "processor", "single", "frame", "gl", "texture", "processors", "and", "destroys", "the", "open", "gl", "context"], "project": "ExoPlayer"}
{"id": 1946, "code": "private static Boolean readAmfBoolean(ParsableByteArray data) {\n  return data.readUnsignedByte() == 1;\n}", "summary_tokens": ["read", "a", "boolean", "from", "an", "amf", "encoded", "buffer"], "project": "ExoPlayer"}
{"id": 53, "code": "private static int fetchPlaybackState(RemoteMediaClient remoteMediaClient) {\n  int receiverAppStatus = remoteMediaClient.getPlayerState();\n  switch (receiverAppStatus) {\n    case MediaStatus.PLAYER_STATE_BUFFERING:\n      return STATE_BUFFERING;\n    case MediaStatus.PLAYER_STATE_PLAYING:\n    case MediaStatus.PLAYER_STATE_PAUSED:\n      return STATE_READY;\n    case MediaStatus.PLAYER_STATE_IDLE:\n    case MediaStatus.PLAYER_STATE_UNKNOWN:\n    default:\n      return STATE_IDLE;\n  }\n}", "summary_tokens": ["retrieves", "the", "playback", "state", "from", "remote", "media", "client", "and", "maps", "it", "into", "a", "player", "state"], "project": "ExoPlayer"}
{"id": 396, "code": "public boolean isTypeSelected(@C.TrackType int trackType) {\n  for (int i = 0; i < groups.size(); i++) {\n    Group group = groups.get(i);\n    if (group.isSelected() && group.getType() == trackType) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "true", "if", "at", "least", "one", "track", "of", "the", "type", "track", "type", "is", "selected", "for", "playback"], "project": "ExoPlayer"}
{"id": 1765, "code": "public SimpleCacheSpan getSpan(long position, long length) {\n  SimpleCacheSpan lookupSpan = SimpleCacheSpan.createLookup(key, position);\n  SimpleCacheSpan floorSpan = cachedSpans.floor(lookupSpan);\n  if (floorSpan != null && floorSpan.position + floorSpan.length > position) {\n    return floorSpan;\n  }\n  SimpleCacheSpan ceilSpan = cachedSpans.ceiling(lookupSpan);\n  if (ceilSpan != null) {\n    long holeLength = ceilSpan.position - position;\n    length = length == C.LENGTH_UNSET ? holeLength : min(holeLength, length);\n  }\n  return SimpleCacheSpan.createHole(key, position, length);\n}", "summary_tokens": ["returns", "the", "cache", "span", "corresponding", "to", "the", "provided", "range"], "project": "ExoPlayer"}
{"id": 11, "code": "public void setPlayer(@Nullable ExoPlayer player) {\n  if (player == this.player) {\n    return;\n  }\n  if (this.player != null) {\n    if (surface != null) {\n      this.player.clearVideoSurface(surface);\n    }\n    this.player.clearVideoFrameMetadataListener(renderer);\n  }\n  this.player = player;\n  if (this.player != null) {\n    this.player.setVideoFrameMetadataListener(renderer);\n    this.player.setVideoSurface(surface);\n  }\n}", "summary_tokens": ["attaches", "or", "detaches", "if", "player", "is", "null", "this", "view", "from", "the", "player"], "project": "ExoPlayer"}
{"id": 413, "code": "private static ImmutableList<Cue> filterOutBitmapCues(List<Cue> cues) {\n  ImmutableList.Builder<Cue> builder = ImmutableList.builder();\n  for (int i = 0; i < cues.size(); i++) {\n    if (cues.get(i).bitmap != null) {\n      continue;\n    }\n    builder.add(cues.get(i));\n  }\n  return builder.build();\n}", "summary_tokens": ["filters", "out", "cue", "objects", "containing", "bitmap"], "project": "ExoPlayer"}
{"id": 766, "code": "protected void onStarted() throws ExoPlaybackException {\n    \n}", "summary_tokens": ["called", "when", "the", "renderer", "is", "started"], "project": "ExoPlayer"}
{"id": 1307, "code": "public void readToBuffer(DecoderInputBuffer buffer, SampleExtrasHolder extrasHolder) {\n  readAllocationNode = readSampleData(readAllocationNode, buffer, extrasHolder, scratch);\n}", "summary_tokens": ["reads", "data", "from", "the", "rolling", "buffer", "to", "populate", "a", "decoder", "input", "buffer", "and", "advances", "the", "read", "position"], "project": "ExoPlayer"}
{"id": 2006, "code": "private static PsshAtom parsePsshAtom(byte[] atom) {\n  ParsableByteArray atomData = new ParsableByteArray(atom);\n  if (atomData.limit() < Atom.FULL_HEADER_SIZE + 16  + 4 ) {\n      \n    return null;\n  }\n  atomData.setPosition(0);\n  int atomSize = atomData.readInt();\n  if (atomSize != atomData.bytesLeft() + 4) {\n      \n    return null;\n  }\n  int atomType = atomData.readInt();\n  if (atomType != Atom.TYPE_pssh) {\n      \n    return null;\n  }\n  int atomVersion = Atom.parseFullAtomVersion(atomData.readInt());\n  if (atomVersion > 1) {\n    Log.w(TAG, \"Unsupported pssh version: \" + atomVersion);\n    return null;\n  }\n  UUID uuid = new UUID(atomData.readLong(), atomData.readLong());\n  if (atomVersion == 1) {\n    int keyIdCount = atomData.readUnsignedIntToInt();\n    atomData.skipBytes(16 * keyIdCount);\n  }\n  int dataSize = atomData.readUnsignedIntToInt();\n  if (dataSize != atomData.bytesLeft()) {\n      \n    return null;\n  }\n  byte[] data = new byte[dataSize];\n  atomData.readBytes(data, 0, dataSize);\n  return new PsshAtom(uuid, atomVersion, data);\n}", "summary_tokens": ["parses", "a", "pssh", "atom"], "project": "ExoPlayer"}
{"id": 2149, "code": "public TtmlStyle inherit(@Nullable TtmlStyle ancestor) {\n  return inherit(ancestor, false);\n}", "summary_tokens": ["inherits", "from", "an", "ancestor", "style"], "project": "ExoPlayer"}
{"id": 826, "code": "public void setMuted(boolean muted) {\n  if (Util.SDK_INT >= 23) {\n    audioManager.adjustStreamVolume(\n        streamType, muted ? AudioManager.ADJUST_MUTE : AudioManager.ADJUST_UNMUTE, VOLUME_FLAGS);\n  } else {\n    audioManager.setStreamMute(streamType, muted);\n  }\n  updateVolumeAndNotifyIfChanged();\n}", "summary_tokens": ["sets", "the", "mute", "state", "of", "the", "current", "audio", "stream"], "project": "ExoPlayer"}
{"id": 1658, "code": "public void exclude(BaseUrl baseUrlToExclude, long exclusionDurationMs) {\n  long excludeUntilMs = SystemClock.elapsedRealtime() + exclusionDurationMs;\n  addExclusion(baseUrlToExclude.serviceLocation, excludeUntilMs, excludedServiceLocations);\n  if (baseUrlToExclude.priority != BaseUrl.PRIORITY_UNSET) {\n    addExclusion(baseUrlToExclude.priority, excludeUntilMs, excludedPriorities);\n  }\n}", "summary_tokens": ["excludes", "the", "given", "base", "url"], "project": "ExoPlayer"}
{"id": 647, "code": "protected void onEnabled(boolean joining, boolean mayRenderStartOfStream)", "summary_tokens": ["called", "when", "the", "renderer", "is", "enabled"], "project": "ExoPlayer"}
{"id": 84, "code": "public boolean isEndOfData() {\n  if (byteBufferData != null) {\n    return byteBufferData.remaining() == 0;\n  } else if (extractorInput != null) {\n    return endOfExtractorInput;\n  } else {\n    return true;\n  }\n}", "summary_tokens": ["returns", "whether", "the", "end", "of", "the", "data", "to", "be", "parsed", "has", "been", "reached", "or", "true", "if", "no", "data", "was", "set"], "project": "ExoPlayer"}
{"id": 839, "code": "default void onSeekStarted(EventTime eventTime) {}", "summary_tokens": ["use", "on", "position", "discontinuity", "event", "time", "player"], "project": "ExoPlayer"}
{"id": 1243, "code": "protected final M getManifest(DataSource dataSource, DataSpec dataSpec, boolean removing)\n    throws InterruptedException, IOException {\n  return execute(\n      new RunnableFutureTask<M, IOException>() {\n        @Override\n        protected M doWork() throws IOException {\n          return ParsingLoadable.load(dataSource, manifestParser, dataSpec, C.DATA_TYPE_MANIFEST);\n        }\n      },\n      removing);\n}", "summary_tokens": ["loads", "and", "parses", "a", "manifest"], "project": "ExoPlayer"}
{"id": 1427, "code": "public Notification buildDownloadCompletedNotification(\n    Context context,\n    @DrawableRes int smallIcon,\n    @Nullable PendingIntent contentIntent,\n    @Nullable String message) {\n  int titleStringId = R.string.exo_download_completed;\n  return buildEndStateNotification(context, smallIcon, contentIntent, message, titleStringId);\n}", "summary_tokens": ["returns", "a", "notification", "for", "a", "completed", "download"], "project": "ExoPlayer"}
{"id": 41, "code": "public CueGroup getCurrentCues() {\n  return CueGroup.EMPTY;\n}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "returns", "an", "empty", "cue", "group"], "project": "ExoPlayer"}
{"id": 755, "code": "public boolean isPrepared() {\n  return isPrepared;\n}", "summary_tokens": ["whether", "the", "playlist", "is", "prepared"], "project": "ExoPlayer"}
{"id": 2472, "code": "public void setProgressUpdateListener(@Nullable ProgressUpdateListener listener) {\n  this.progressUpdateListener = listener;\n}", "summary_tokens": ["sets", "the", "progress", "update", "listener"], "project": "ExoPlayer"}
{"id": 663, "code": "protected final boolean isSourceReady() {\n  return hasReadStreamToEnd() ? streamIsFinal : Assertions.checkNotNull(stream).isReady();\n}", "summary_tokens": ["returns", "whether", "the", "upstream", "source", "is", "ready"], "project": "ExoPlayer"}
{"id": 1295, "code": "default void onLoadStarted(\n    int windowIndex,\n    @Nullable MediaPeriodId mediaPeriodId,\n    LoadEventInfo loadEventInfo,\n    MediaLoadData mediaLoadData) {}", "summary_tokens": ["called", "when", "a", "load", "begins"], "project": "ExoPlayer"}
{"id": 48, "code": "public void setDeviceMuted(boolean muted) {}", "summary_tokens": ["this", "method", "is", "not", "supported", "and", "does", "nothing"], "project": "ExoPlayer"}
{"id": 476, "code": "public static float[] getNormalizedCoordinateBounds() {\n  return new float[] {\n    -1, -1, 0, 1,\n    1, -1, 0, 1,\n    -1, 1, 0, 1,\n    1, 1, 0, 1\n  };\n}", "summary_tokens": ["bounds", "of", "normalized", "device", "coordinates", "commonly", "used", "for", "defining", "viewport", "boundaries"], "project": "ExoPlayer"}
{"id": 701, "code": "private static Pair<Object, Long> resolveSeekPositionUs(\n    Timeline timeline,\n    SeekPosition seekPosition,\n    boolean trySubsequentPeriods,\n    @RepeatMode int repeatMode,\n    boolean shuffleModeEnabled,\n    Timeline.Window window,\n    Timeline.Period period) {\n  Timeline seekTimeline = seekPosition.timeline;\n  if (timeline.isEmpty()) {\n      \n    return null;\n  }\n  if (seekTimeline.isEmpty()) {\n      \n      \n    seekTimeline = timeline;\n  }\n    \n  Pair<Object, Long> periodPositionUs;\n  try {\n    periodPositionUs =\n        seekTimeline.getPeriodPositionUs(\n            window, period, seekPosition.windowIndex, seekPosition.windowPositionUs);\n  } catch (IndexOutOfBoundsException e) {\n      \n    return null;\n  }\n  if (timeline.equals(seekTimeline)) {\n      \n    return periodPositionUs;\n  }\n    \n  int periodIndex = timeline.getIndexOfPeriod(periodPositionUs.first);\n  if (periodIndex != C.INDEX_UNSET) {\n      \n    if (seekTimeline.getPeriodByUid(periodPositionUs.first, period).isPlaceholder\n        && seekTimeline.getWindow(period.windowIndex, window).firstPeriodIndex\n            == seekTimeline.getIndexOfPeriod(periodPositionUs.first)) {\n        \n        \n        \n      int newWindowIndex = timeline.getPeriodByUid(periodPositionUs.first, period).windowIndex;\n      periodPositionUs =\n          timeline.getPeriodPositionUs(\n              window, period, newWindowIndex, seekPosition.windowPositionUs);\n    }\n    return periodPositionUs;\n  }\n  if (trySubsequentPeriods) {\n      \n    @Nullable\n    Object periodUid =\n        resolveSubsequentPeriod(\n            window,\n            period,\n            repeatMode,\n            shuffleModeEnabled,\n            periodPositionUs.first,\n            seekTimeline,\n            timeline);\n    if (periodUid != null) {\n        \n      return timeline.getPeriodPositionUs(\n          window,\n          period,\n          timeline.getPeriodByUid(periodUid, period).windowIndex,\n           C.TIME_UNSET);\n    }\n  }\n    \n  return null;\n}", "summary_tokens": ["converts", "a", "seek", "position", "into", "the", "corresponding", "period", "uid", "period", "position", "us", "for", "the", "internal", "timeline"], "project": "ExoPlayer"}
{"id": 2747, "code": "protected void onFormatChanged(Format format) {}", "summary_tokens": ["called", "when", "the", "renderer", "reads", "a", "new", "format"], "project": "ExoPlayer"}
{"id": 2278, "code": "public ImmutableListMultimap<String, String> asMultiMap() {\n  return namesAndValues;\n}", "summary_tokens": ["returns", "a", "map", "that", "associates", "header", "names", "to", "the", "list", "of", "values", "associated", "with", "the", "corresponding", "header", "name"], "project": "ExoPlayer"}
{"id": 2342, "code": "public static JSONObject getDeviceDetailsAsJsonObject() throws JSONException {\n  return new JSONObject()\n      .put(\"manufacturer\", Build.MANUFACTURER)\n      .put(\"model\", Build.MODEL)\n      .put(\"sdkVersion\", Build.VERSION.SDK_INT)\n      .put(\"fingerprint\", Build.FINGERPRINT);\n}", "summary_tokens": ["returns", "a", "jsonobject", "containing", "device", "specific", "details", "from", "build", "including", "manufacturer", "model", "sdk", "version", "and", "build", "fingerprint"], "project": "ExoPlayer"}
{"id": 342, "code": "public AudioAttributes getAudioAttributes() {\n  return player.getAudioAttributes();\n}", "summary_tokens": ["calls", "player", "get", "audio", "attributes", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 1044, "code": "public void setTrimFrameCount(int trimStartFrames, int trimEndFrames) {\n  this.trimStartFrames = trimStartFrames;\n  this.trimEndFrames = trimEndFrames;\n}", "summary_tokens": ["sets", "the", "number", "of", "audio", "frames", "to", "trim", "from", "the", "start", "and", "end", "of", "audio", "passed", "to", "this", "processor"], "project": "ExoPlayer"}
{"id": 1988, "code": "private static void parseSaio(ParsableByteArray saio, TrackFragment out) throws ParserException {\n  saio.setPosition(Atom.HEADER_SIZE);\n  int fullAtom = saio.readInt();\n  int flags = Atom.parseFullAtomFlags(fullAtom);\n  if ((flags & 0x01) == 1) {\n    saio.skipBytes(8);\n  }\n\n  int entryCount = saio.readUnsignedIntToInt();\n  if (entryCount != 1) {\n      \n    throw ParserException.createForMalformedContainer(\n        \"Unexpected saio entry count: \" + entryCount,  null);\n  }\n\n  int version = Atom.parseFullAtomVersion(fullAtom);\n  out.auxiliaryDataPosition +=\n      version == 0 ? saio.readUnsignedInt() : saio.readUnsignedLongToLong();\n}", "summary_tokens": ["parses", "a", "saio", "atom", "defined", "in", "0", "0"], "project": "ExoPlayer"}
{"id": 1013, "code": "protected int getPassthroughBufferSizeInBytes(@C.Encoding int encoding) {\n  int bufferSizeUs = passthroughBufferDurationUs;\n  if (encoding == C.ENCODING_AC3) {\n    bufferSizeUs *= ac3BufferMultiplicationFactor;\n  }\n  int maxByteRate = getMaximumEncodedRateBytesPerSecond(encoding);\n  return checkedCast((long) bufferSizeUs * maxByteRate / C.MICROS_PER_SECOND);\n}", "summary_tokens": ["returns", "the", "buffer", "size", "for", "passthrough", "playback"], "project": "ExoPlayer"}
{"id": 559, "code": "public void ensureCapacity(int requiredCapacity) {\n  if (requiredCapacity > capacity()) {\n    data = Arrays.copyOf(data, requiredCapacity);\n  }\n}", "summary_tokens": ["ensures", "the", "backing", "array", "is", "at", "least", "required", "capacity", "long"], "project": "ExoPlayer"}
{"id": 2036, "code": " static int readBits(byte src, int length, int leastSignificantBitIndex) {\n  return (src >> leastSignificantBitIndex) & (255 >>> (8 - length));\n}", "summary_tokens": ["reads", "an", "int", "of", "length", "bits", "from", "src", "starting", "at", "least", "significant", "bit", "index"], "project": "ExoPlayer"}
{"id": 504, "code": "public synchronized boolean isAvailable() {\n  if (loadAttempted) {\n    return isAvailable;\n  }\n  loadAttempted = true;\n  try {\n    for (String lib : nativeLibraries) {\n      loadLibrary(lib);\n    }\n    isAvailable = true;\n  } catch (UnsatisfiedLinkError exception) {\n      \n      \n    Log.w(TAG, \"Failed to load \" + Arrays.toString(nativeLibraries));\n  }\n  return isAvailable;\n}", "summary_tokens": ["returns", "whether", "the", "underlying", "libraries", "are", "available", "loading", "them", "if", "necessary"], "project": "ExoPlayer"}
{"id": 1768, "code": "public boolean isEmpty() {\n  return cachedSpans.isEmpty();\n}", "summary_tokens": ["returns", "whether", "there", "are", "any", "spans", "cached"], "project": "ExoPlayer"}
{"id": 2228, "code": "public void publish() {\n  isPublished = true;\n}", "summary_tokens": ["sets", "the", "publish", "flag", "of", "the", "media", "chunk", "to", "indicate", "that", "it", "is", "not", "based", "on", "a", "part", "that", "is", "a", "preload", "hint", "in", "the", "playlist"], "project": "ExoPlayer"}
{"id": 1022, "code": "public void setEnabled(boolean enabled) {\n  this.enabled = enabled;\n}", "summary_tokens": ["sets", "whether", "to", "skip", "silence", "in", "the", "input"], "project": "ExoPlayer"}
{"id": 1288, "code": "public long getPreparePositionOverrideUs() {\n  return preparePositionOverrideUs;\n}", "summary_tokens": ["returns", "the", "prepare", "position", "override", "set", "by", "override", "prepare", "position", "us", "long"], "project": "ExoPlayer"}
{"id": 355, "code": "public DeviceInfo getDeviceInfo() {\n  return player.getDeviceInfo();\n}", "summary_tokens": ["calls", "player", "get", "device", "info", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 596, "code": "public void add(int priority) {\n  synchronized (lock) {\n    queue.add(priority);\n    highestPriority = max(highestPriority, priority);\n  }\n}", "summary_tokens": ["register", "a", "new", "task"], "project": "ExoPlayer"}
{"id": 1907, "code": "public long getApproxBytesPerFrame() {\n  long approxBytesPerFrame;\n  if (maxFrameSize > 0) {\n    approxBytesPerFrame = ((long) maxFrameSize + minFrameSize) / 2 + 1;\n  } else {\n      \n      \n    long blockSizeSamples =\n        (minBlockSizeSamples == maxBlockSizeSamples && minBlockSizeSamples > 0)\n            ? minBlockSizeSamples\n            : 4096;\n    approxBytesPerFrame = (blockSizeSamples * channels * bitsPerSample) / 8 + 64;\n  }\n  return approxBytesPerFrame;\n}", "summary_tokens": ["returns", "the", "approximate", "number", "of", "bytes", "per", "frame", "for", "the", "current", "flac", "stream"], "project": "ExoPlayer"}
{"id": 343, "code": "public void setVolume(float volume) {\n  player.setVolume(volume);\n}", "summary_tokens": ["calls", "player", "set", "volume", "float", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 810, "code": "public VideoComponent getVideoComponent() {\n  return this;\n}", "summary_tokens": ["use", "exo", "player", "as", "the", "video", "component", "methods", "are", "defined", "by", "that", "interface"], "project": "ExoPlayer"}
{"id": 2337, "code": "public static Uri getTestUriWithUserInfo(\n    String username, String password, int serverRtspPortNumber) {\n  return Uri.parse(\n      Util.formatInvariant(\n          TEST_BASE_URI_WITH_USER_INFO, username, password, serverRtspPortNumber));\n}", "summary_tokens": ["returns", "the", "test", "rtsp", "uri", "with", "user", "info"], "project": "ExoPlayer"}
{"id": 2451, "code": "public void setAspectRatioListener(@Nullable AspectRatioListener listener) {\n  this.aspectRatioListener = listener;\n}", "summary_tokens": ["sets", "the", "aspect", "ratio", "listener"], "project": "ExoPlayer"}
{"id": 194, "code": "private void closeConnectionQuietly() {\n  if (response != null) {\n    Assertions.checkNotNull(response.body()).close();\n    response = null;\n  }\n  responseByteStream = null;\n}", "summary_tokens": ["closes", "the", "current", "connection", "quietly", "if", "there", "is", "one"], "project": "ExoPlayer"}
{"id": 1501, "code": "protected void updateDroppedBufferCounters(\n    int droppedInputBufferCount, int droppedDecoderBufferCount) {\n  decoderCounters.droppedInputBufferCount += droppedInputBufferCount;\n  int totalDroppedBufferCount = droppedInputBufferCount + droppedDecoderBufferCount;\n  decoderCounters.droppedBufferCount += totalDroppedBufferCount;\n  droppedFrames += totalDroppedBufferCount;\n  consecutiveDroppedFrameCount += totalDroppedBufferCount;\n  decoderCounters.maxConsecutiveDroppedBufferCount =\n      max(consecutiveDroppedFrameCount, decoderCounters.maxConsecutiveDroppedBufferCount);\n  if (maxDroppedFramesToNotify > 0 && droppedFrames >= maxDroppedFramesToNotify) {\n    maybeNotifyDroppedFrames();\n  }\n}", "summary_tokens": ["updates", "local", "counters", "and", "decoder", "counters", "to", "reflect", "that", "buffers", "were", "dropped"], "project": "ExoPlayer"}
{"id": 1072, "code": "private static boolean needsForceWidevineL3Workaround() {\n  return \"ASUS_Z00AD\".equals(Util.MODEL);\n}", "summary_tokens": ["returns", "whether", "the", "device", "codec", "is", "known", "to", "fail", "if", "security", "level", "l", "0", "is", "used"], "project": "ExoPlayer"}
{"id": 2768, "code": "public void releasePeriod(final MediaPeriod mediaPeriod) {\n  runOnPlaybackThread(() -> mediaSource.releasePeriod(mediaPeriod));\n}", "summary_tokens": ["calls", "media", "source", "release", "period", "media", "period", "on", "the", "playback", "thread"], "project": "ExoPlayer"}
{"id": 2079, "code": "public boolean isDurationReadFinished() {\n  return isDurationRead;\n}", "summary_tokens": ["returns", "true", "if", "a", "ps", "duration", "has", "been", "read"], "project": "ExoPlayer"}
{"id": 1230, "code": "public static void sendRemoveAllDownloads(\n    Context context, Class<? extends DownloadService> clazz, boolean foreground) {\n  Intent intent = buildRemoveAllDownloadsIntent(context, clazz, foreground);\n  startService(context, intent, foreground);\n}", "summary_tokens": ["starts", "the", "service", "if", "not", "started", "already", "and", "removes", "all", "downloads"], "project": "ExoPlayer"}
{"id": 166, "code": "public static int getShuffleMode(boolean exoPlayerShuffleMode) {\n  return exoPlayerShuffleMode ? SessionPlayer.SHUFFLE_MODE_ALL : SessionPlayer.SHUFFLE_MODE_NONE;\n}", "summary_tokens": ["returns", "the", "shuffle", "mode", "for", "the", "given", "exo", "player", "s", "shuffle", "mode"], "project": "ExoPlayer"}
{"id": 773, "code": "public static MediaPeriodId getDummyPeriodForEmptyTimeline() {\n  return PLACEHOLDER_MEDIA_PERIOD_ID;\n}", "summary_tokens": ["returns", "a", "placeholder", "period", "id", "for", "an", "empty", "timeline"], "project": "ExoPlayer"}
{"id": 1912, "code": "public FlacStreamMetadata copyWithPictureFrames(List<PictureFrame> pictureFrames) {\n  @Nullable\n  Metadata appendedMetadata = getMetadataCopyWithAppendedEntriesFrom(new Metadata(pictureFrames));\n  return new FlacStreamMetadata(\n      minBlockSizeSamples,\n      maxBlockSizeSamples,\n      minFrameSize,\n      maxFrameSize,\n      sampleRate,\n      channels,\n      bitsPerSample,\n      totalSamples,\n      seekTable,\n      appendedMetadata);\n}", "summary_tokens": ["returns", "a", "copy", "of", "this", "with", "the", "given", "picture", "frames", "added", "to", "the", "metadata"], "project": "ExoPlayer"}
{"id": 2807, "code": "public ExoPlayer build() {\n  Assertions.checkNotNull(\n      looper, \"TestExoPlayer builder run on a thread without Looper and no Looper specified.\");\n    \n    \n  RenderersFactory playerRenderersFactory = renderersFactory;\n  if (playerRenderersFactory == null) {\n    playerRenderersFactory =\n        (eventHandler,\n            videoRendererEventListener,\n            audioRendererEventListener,\n            textRendererOutput,\n            metadataRendererOutput) ->\n            renderers != null\n                ? renderers\n                : new Renderer[] {\n                  new FakeVideoRenderer(eventHandler, videoRendererEventListener),\n                  new FakeAudioRenderer(eventHandler, audioRendererEventListener)\n                };\n  }\n\n  ExoPlayer.Builder builder =\n      new ExoPlayer.Builder(context, playerRenderersFactory)\n          .setTrackSelector(trackSelector)\n          .setLoadControl(loadControl)\n          .setBandwidthMeter(bandwidthMeter)\n          .setAnalyticsCollector(new DefaultAnalyticsCollector(clock))\n          .setClock(clock)\n          .setUseLazyPreparation(useLazyPreparation)\n          .setLooper(looper)\n          .setSeekBackIncrementMs(seekBackIncrementMs)\n          .setSeekForwardIncrementMs(seekForwardIncrementMs);\n  if (mediaSourceFactory != null) {\n    builder.setMediaSourceFactory(mediaSourceFactory);\n  }\n  return builder.build();\n}", "summary_tokens": ["builds", "an", "exo", "player", "using", "the", "provided", "values", "or", "their", "defaults"], "project": "ExoPlayer"}
{"id": 331, "code": "public boolean isCurrentWindowLive() {\n  return player.isCurrentWindowLive();\n}", "summary_tokens": ["calls", "player", "is", "current", "window", "live", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 525, "code": "public static boolean allSamplesAreSyncSamples(\n    @Nullable String mimeType, @Nullable String codec) {\n  if (mimeType == null) {\n    return false;\n  }\n    \n    \n    \n    \n  switch (mimeType) {\n    case AUDIO_MPEG:\n    case AUDIO_MPEG_L1:\n    case AUDIO_MPEG_L2:\n    case AUDIO_RAW:\n    case AUDIO_ALAW:\n    case AUDIO_MLAW:\n    case AUDIO_FLAC:\n    case AUDIO_AC3:\n    case AUDIO_E_AC3:\n    case AUDIO_E_AC3_JOC:\n      return true;\n    case AUDIO_AAC:\n      if (codec == null) {\n        return false;\n      }\n      @Nullable Mp4aObjectType objectType = getObjectTypeFromMp4aRFC6381CodecString(codec);\n      if (objectType == null) {\n        return false;\n      }\n      @C.Encoding int encoding = objectType.getEncoding();\n        \n        \n        \n      return encoding != C.ENCODING_INVALID && encoding != C.ENCODING_AAC_XHE;\n    default:\n      return false;\n  }\n}", "summary_tokens": ["returns", "true", "if", "it", "is", "known", "that", "all", "samples", "in", "a", "stream", "of", "the", "given", "mime", "type", "and", "codec", "are", "guaranteed", "to", "be", "sync", "samples", "i"], "project": "ExoPlayer"}
{"id": 2497, "code": "public final void setUseFastForwardActionInCompactView(\n    boolean useFastForwardActionInCompactView) {\n  if (this.useFastForwardActionInCompactView != useFastForwardActionInCompactView) {\n    this.useFastForwardActionInCompactView = useFastForwardActionInCompactView;\n    if (useFastForwardActionInCompactView) {\n      useNextActionInCompactView = false;\n    }\n    invalidate();\n  }\n}", "summary_tokens": ["sets", "whether", "the", "fast", "forward", "action", "should", "also", "be", "used", "in", "compact", "view"], "project": "ExoPlayer"}
{"id": 2000, "code": "public static MdtaMetadataEntry parseMdtaMetadataEntryFromIlst(\n    ParsableByteArray ilst, int endPosition, String key) {\n  int atomPosition;\n  while ((atomPosition = ilst.getPosition()) < endPosition) {\n    int atomSize = ilst.readInt();\n    int atomType = ilst.readInt();\n    if (atomType == Atom.TYPE_data) {\n      int typeIndicator = ilst.readInt();\n      int localeIndicator = ilst.readInt();\n      int dataSize = atomSize - 16;\n      byte[] value = new byte[dataSize];\n      ilst.readBytes(value, 0, dataSize);\n      return new MdtaMetadataEntry(key, value, localeIndicator, typeIndicator);\n    }\n    ilst.setPosition(atomPosition + atomSize);\n  }\n  return null;\n}", "summary_tokens": ["parses", "an", "mdta", "metadata", "entry", "starting", "at", "the", "current", "position", "in", "an", "ilst", "box"], "project": "ExoPlayer"}
{"id": 589, "code": "public float readFloat() {\n  return Float.intBitsToFloat(readInt());\n}", "summary_tokens": ["reads", "the", "next", "four", "bytes", "as", "a", "0", "bit", "floating", "point", "value"], "project": "ExoPlayer"}
{"id": 1892, "code": "private static boolean checkAndReadFirstSampleNumber(\n    ParsableByteArray data,\n    FlacStreamMetadata flacStreamMetadata,\n    boolean isBlockSizeVariable,\n    SampleNumberHolder sampleNumberHolder) {\n  long utf8Value;\n  try {\n    utf8Value = data.readUtf8EncodedLong();\n  } catch (NumberFormatException e) {\n    return false;\n  }\n\n  sampleNumberHolder.sampleNumber =\n      isBlockSizeVariable ? utf8Value : utf8Value * flacStreamMetadata.maxBlockSizeSamples;\n  return true;\n}", "summary_tokens": ["checks", "whether", "the", "given", "sample", "number", "is", "valid", "and", "if", "so", "reads", "it", "and", "writes", "it", "in", "sample", "number", "holder"], "project": "ExoPlayer"}
{"id": 2056, "code": "private void parseId3Header() {\n  id3Output.sampleData(id3HeaderBuffer, ID3_HEADER_SIZE);\n  id3HeaderBuffer.setPosition(ID3_SIZE_OFFSET);\n  setReadingSampleState(\n      id3Output, 0, ID3_HEADER_SIZE, id3HeaderBuffer.readSynchSafeInt() + ID3_HEADER_SIZE);\n}", "summary_tokens": ["parses", "the", "id", "0", "header"], "project": "ExoPlayer"}
{"id": 158, "code": "public SessionCallbackBuilder setPostConnectCallback(\n    @Nullable PostConnectCallback postConnectCallback) {\n  this.postConnectCallback = postConnectCallback;\n  return this;\n}", "summary_tokens": ["sets", "the", "post", "connect", "callback", "to", "handle", "extra", "initialization", "after", "the", "connection"], "project": "ExoPlayer"}
{"id": 1364, "code": "public TrackGroup get(int index) {\n  return trackGroups.get(index);\n}", "summary_tokens": ["returns", "the", "group", "at", "a", "given", "index"], "project": "ExoPlayer"}
{"id": 2713, "code": "public static void assertAllBehaviors(\n    ExtractorFactory factory, String file, String dumpFilesPrefix) throws IOException {\n    \n  Extractor extractor = factory.create();\n  extractor.seek(0, 0);\n  extractor.release();\n    \n  Context context = ApplicationProvider.getApplicationContext();\n  byte[] fileData = TestUtil.getByteArray(context, file);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, false, false, false);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, false, false, true);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, false, true, false);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, false, true, true);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, true, false, false);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, true, false, true);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, true, true, false);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, true, true, true, true);\n  assertOutput(\n      factory.create(), dumpFilesPrefix, fileData, context, false, false, false, false, false);\n}", "summary_tokens": ["asserts", "that", "an", "extractor", "behaves", "correctly", "given", "valid", "input", "data"], "project": "ExoPlayer"}
{"id": 563, "code": "public byte[] getData() {\n  return data;\n}", "summary_tokens": ["returns", "the", "underlying", "array"], "project": "ExoPlayer"}
{"id": 580, "code": "public int readInt() {\n  return (data[position++] & 0xFF) << 24\n      | (data[position++] & 0xFF) << 16\n      | (data[position++] & 0xFF) << 8\n      | (data[position++] & 0xFF);\n}", "summary_tokens": ["reads", "the", "next", "four", "bytes", "as", "a", "signed", "value"], "project": "ExoPlayer"}
{"id": 2645, "code": "public void setFixedTextSize(@Dimension int unit, float size) {\n  Context context = getContext();\n  Resources resources;\n  if (context == null) {\n    resources = Resources.getSystem();\n  } else {\n    resources = context.getResources();\n  }\n  setTextSize(\n      Cue.TEXT_SIZE_TYPE_ABSOLUTE,\n      TypedValue.applyDimension(unit, size, resources.getDisplayMetrics()));\n}", "summary_tokens": ["sets", "the", "text", "size", "to", "a", "given", "unit", "and", "value"], "project": "ExoPlayer"}
{"id": 356, "code": "public int getDeviceVolume() {\n  return player.getDeviceVolume();\n}", "summary_tokens": ["calls", "player", "get", "device", "volume", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2828, "code": "public static ExtractorInput getExtractorInputFromPosition(\n    DataSource dataSource, long position, Uri uri) throws IOException {\n  DataSpec dataSpec = new DataSpec(uri, position, C.LENGTH_UNSET);\n  long length = dataSource.open(dataSpec);\n  if (length != C.LENGTH_UNSET) {\n    length += position;\n  }\n  return new DefaultExtractorInput(dataSource, position, length);\n}", "summary_tokens": ["returns", "an", "extractor", "input", "to", "read", "from", "the", "given", "input", "at", "given", "position"], "project": "ExoPlayer"}
{"id": 759, "code": "public Timeline createTimeline() {\n  if (mediaSourceHolders.isEmpty()) {\n    return Timeline.EMPTY;\n  }\n  int windowOffset = 0;\n  for (int i = 0; i < mediaSourceHolders.size(); i++) {\n    MediaSourceHolder mediaSourceHolder = mediaSourceHolders.get(i);\n    mediaSourceHolder.firstWindowIndexInChild = windowOffset;\n    windowOffset += mediaSourceHolder.mediaSource.getTimeline().getWindowCount();\n  }\n  return new PlaylistTimeline(mediaSourceHolders, shuffleOrder);\n}", "summary_tokens": ["creates", "a", "timeline", "reflecting", "the", "current", "state", "of", "the", "playlist"], "project": "ExoPlayer"}
{"id": 853, "code": "default void onTrackSelectionParametersChanged(\n    EventTime eventTime, TrackSelectionParameters trackSelectionParameters) {}", "summary_tokens": ["called", "when", "track", "selection", "parameters", "change"], "project": "ExoPlayer"}
{"id": 1877, "code": "public synchronized DefaultExtractorsFactory setTsExtractorMode(@TsExtractor.Mode int mode) {\n  tsMode = mode;\n  return this;\n}", "summary_tokens": ["sets", "the", "mode", "for", "ts", "extractor", "instances", "created", "by", "the", "factory"], "project": "ExoPlayer"}
{"id": 186, "code": "public final void invalidateMediaSessionPlaybackState() {\n  PlaybackStateCompat.Builder builder = new PlaybackStateCompat.Builder();\n  @Nullable Player player = this.player;\n  if (player == null) {\n    builder\n        .setActions(buildPrepareActions())\n        .setState(\n            PlaybackStateCompat.STATE_NONE,\n             0,\n             0,\n             SystemClock.elapsedRealtime());\n\n    mediaSession.setRepeatMode(PlaybackStateCompat.REPEAT_MODE_NONE);\n    mediaSession.setShuffleMode(PlaybackStateCompat.SHUFFLE_MODE_NONE);\n    mediaSession.setPlaybackState(builder.build());\n    return;\n  }\n\n  Map<String, CustomActionProvider> currentActions = new HashMap<>();\n  for (CustomActionProvider customActionProvider : customActionProviders) {\n    @Nullable\n    PlaybackStateCompat.CustomAction customAction = customActionProvider.getCustomAction(player);\n    if (customAction != null) {\n      currentActions.put(customAction.getAction(), customActionProvider);\n      builder.addCustomAction(customAction);\n    }\n  }\n  customActionMap = Collections.unmodifiableMap(currentActions);\n\n  Bundle extras = new Bundle();\n  @Nullable PlaybackException playbackError = player.getPlayerError();\n  boolean reportError = playbackError != null || customError != null;\n  int sessionPlaybackState =\n      reportError\n          ? PlaybackStateCompat.STATE_ERROR\n          : getMediaSessionPlaybackState(player.getPlaybackState(), player.getPlayWhenReady());\n  if (customError != null) {\n    builder.setErrorMessage(customError.first, customError.second);\n    if (customErrorExtras != null) {\n      extras.putAll(customErrorExtras);\n    }\n  } else if (playbackError != null && errorMessageProvider != null) {\n    Pair<Integer, String> message = errorMessageProvider.getErrorMessage(playbackError);\n    builder.setErrorMessage(message.first, message.second);\n  }\n  long activeQueueItemId =\n      queueNavigator != null\n          ? queueNavigator.getActiveQueueItemId(player)\n          : MediaSessionCompat.QueueItem.UNKNOWN_ID;\n  float playbackSpeed = player.getPlaybackParameters().speed;\n  extras.putFloat(EXTRAS_SPEED, playbackSpeed);\n  float sessionPlaybackSpeed = player.isPlaying() ? playbackSpeed : 0f;\n  @Nullable MediaItem currentMediaItem = player.getCurrentMediaItem();\n  if (currentMediaItem != null && !MediaItem.DEFAULT_MEDIA_ID.equals(currentMediaItem.mediaId)) {\n    extras.putString(PLAYBACK_STATE_EXTRAS_KEY_MEDIA_ID, currentMediaItem.mediaId);\n  }\n  builder\n      .setActions(buildPrepareActions() | buildPlaybackActions(player))\n      .setActiveQueueItemId(activeQueueItemId)\n      .setBufferedPosition(player.getBufferedPosition())\n      .setState(\n          sessionPlaybackState,\n          player.getCurrentPosition(),\n          sessionPlaybackSpeed,\n           SystemClock.elapsedRealtime())\n      .setExtras(extras);\n\n  @Player.RepeatMode int repeatMode = player.getRepeatMode();\n  mediaSession.setRepeatMode(\n      repeatMode == Player.REPEAT_MODE_ONE\n          ? PlaybackStateCompat.REPEAT_MODE_ONE\n          : repeatMode == Player.REPEAT_MODE_ALL\n              ? PlaybackStateCompat.REPEAT_MODE_ALL\n              : PlaybackStateCompat.REPEAT_MODE_NONE);\n  mediaSession.setShuffleMode(\n      player.getShuffleModeEnabled()\n          ? PlaybackStateCompat.SHUFFLE_MODE_ALL\n          : PlaybackStateCompat.SHUFFLE_MODE_NONE);\n  mediaSession.setPlaybackState(builder.build());\n}", "summary_tokens": ["updates", "the", "playback", "state", "of", "the", "media", "session"], "project": "ExoPlayer"}
{"id": 1791, "code": "public static File getCacheFile(File cacheDir, int id, long position, long timestamp) {\n  return new File(cacheDir, id + \".\" + position + \".\" + timestamp + SUFFIX);\n}", "summary_tokens": ["returns", "a", "new", "file", "instance", "from", "cache", "dir", "id", "position", "timestamp"], "project": "ExoPlayer"}
{"id": 307, "code": "public TrackSelectionParameters getTrackSelectionParameters() {\n  return player.getTrackSelectionParameters();\n}", "summary_tokens": ["calls", "player", "get", "track", "selection", "parameters", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 522, "code": "public static boolean isVideo(@Nullable String mimeType) {\n  return BASE_TYPE_VIDEO.equals(getTopLevelType(mimeType));\n}", "summary_tokens": ["returns", "whether", "the", "given", "string", "is", "a", "video", "mime", "type"], "project": "ExoPlayer"}
{"id": 825, "code": "public void decreaseVolume() {\n  if (volume <= getMinVolume()) {\n    return;\n  }\n  audioManager.adjustStreamVolume(streamType, AudioManager.ADJUST_LOWER, VOLUME_FLAGS);\n  updateVolumeAndNotifyIfChanged();\n}", "summary_tokens": ["decreases", "the", "volume", "by", "one", "for", "the", "current", "audio", "stream"], "project": "ExoPlayer"}
{"id": 1402, "code": "public static void setLogSessionIdOnMediaParser(MediaParser mediaParser, PlayerId playerId) {\n  Api31.setLogSessionIdOnMediaParser(mediaParser, playerId);\n}", "summary_tokens": ["calls", "media", "parser", "set", "log", "session", "id", "log", "session", "id"], "project": "ExoPlayer"}
{"id": 1469, "code": "protected void onInputFormatChanged(FormatHolder formatHolder) throws ExoPlaybackException {\n  waitingForFirstSampleInFormat = true;\n  Format newFormat = Assertions.checkNotNull(formatHolder.format);\n  setSourceDrmSession(formatHolder.drmSession);\n  Format oldFormat = inputFormat;\n  inputFormat = newFormat;\n\n  if (decoder == null) {\n    maybeInitDecoder();\n    eventDispatcher.inputFormatChanged(inputFormat,  null);\n    return;\n  }\n\n  DecoderReuseEvaluation evaluation;\n  if (sourceDrmSession != decoderDrmSession) {\n    evaluation =\n        new DecoderReuseEvaluation(\n            decoder.getName(),\n            oldFormat,\n            newFormat,\n            REUSE_RESULT_NO,\n            DISCARD_REASON_DRM_SESSION_CHANGED);\n  } else {\n    evaluation = canReuseDecoder(decoder.getName(), oldFormat, newFormat);\n  }\n\n  if (evaluation.result == REUSE_RESULT_NO) {\n    if (decoderReceivedBuffers) {\n        \n      decoderReinitializationState = REINITIALIZATION_STATE_SIGNAL_END_OF_STREAM;\n    } else {\n        \n      releaseDecoder();\n      maybeInitDecoder();\n    }\n  }\n  eventDispatcher.inputFormatChanged(inputFormat, evaluation);\n}", "summary_tokens": ["called", "when", "a", "new", "format", "is", "read", "from", "the", "upstream", "source"], "project": "ExoPlayer"}
{"id": 2072, "code": "private void readFrameRemainder(ParsableByteArray source) {\n  int bytesToRead = min(source.bytesLeft(), frameSize - frameBytesRead);\n  output.sampleData(source, bytesToRead);\n  frameBytesRead += bytesToRead;\n  if (frameBytesRead < frameSize) {\n      \n    return;\n  }\n\n  if (timeUs != C.TIME_UNSET) {\n    output.sampleMetadata(timeUs, C.BUFFER_FLAG_KEY_FRAME, frameSize, 0, null);\n    timeUs += frameDurationUs;\n  }\n  frameBytesRead = 0;\n  state = STATE_FINDING_HEADER;\n}", "summary_tokens": ["attempts", "to", "read", "the", "remainder", "of", "the", "frame"], "project": "ExoPlayer"}
{"id": 1050, "code": "public static byte[] adjustRequestData(byte[] request) {\n  if (Util.SDK_INT >= 27) {\n    return request;\n  }\n    \n    \n    \n    \n  String requestString = Util.fromUtf8Bytes(request);\n  return Util.getUtf8Bytes(base64ToBase64Url(requestString));\n}", "summary_tokens": ["adjusts", "clear", "key", "request", "data", "obtained", "from", "the", "android", "clear", "key", "cdm", "to", "be", "spec", "compliant"], "project": "ExoPlayer"}
{"id": 508, "code": "public static void setLogger(Logger logger) {\n  synchronized (lock) {\n    Log.logger = logger;\n  }\n}", "summary_tokens": ["sets", "a", "custom", "logger", "as", "the", "output"], "project": "ExoPlayer"}
{"id": 1391, "code": "private boolean haveReadFromMediaChunk(int mediaChunkIndex) {\n  BaseMediaChunk mediaChunk = mediaChunks.get(mediaChunkIndex);\n  if (primarySampleQueue.getReadIndex() > mediaChunk.getFirstSampleIndex(0)) {\n    return true;\n  }\n  for (int i = 0; i < embeddedSampleQueues.length; i++) {\n    if (embeddedSampleQueues[i].getReadIndex() > mediaChunk.getFirstSampleIndex(i + 1)) {\n      return true;\n    }\n  }\n  return false;\n}", "summary_tokens": ["returns", "whether", "samples", "have", "been", "read", "from", "media", "chunk", "at", "given", "index"], "project": "ExoPlayer"}
{"id": 1958, "code": "private double readFloat(ExtractorInput input, int byteLength) throws IOException {\n  long integerValue = readInteger(input, byteLength);\n  double floatValue;\n  if (byteLength == VALID_FLOAT32_ELEMENT_SIZE_BYTES) {\n    floatValue = Float.intBitsToFloat((int) integerValue);\n  } else {\n    floatValue = Double.longBitsToDouble(integerValue);\n  }\n  return floatValue;\n}", "summary_tokens": ["reads", "and", "returns", "a", "float", "of", "length", "byte", "length", "from", "the", "extractor", "input"], "project": "ExoPlayer"}
{"id": 2385, "code": "public static ImmutableList<Integer> getSupportedColorFormats(\n    MediaCodecInfo encoderInfo, String mimeType) {\n  return ImmutableList.copyOf(\n      Ints.asList(encoderInfo.getCapabilitiesForType(mimeType).colorFormats));\n}", "summary_tokens": ["returns", "a", "immutable", "list", "list", "of", "supported", "media", "codec", "info"], "project": "ExoPlayer"}
{"id": 2801, "code": "public MediaSource.Factory getMediaSourceFactory() {\n  return mediaSourceFactory;\n}", "summary_tokens": ["returns", "the", "media", "source"], "project": "ExoPlayer"}
{"id": 380, "code": "public int getNextWindowIndex(\n    int windowIndex, @Player.RepeatMode int repeatMode, boolean shuffleModeEnabled) {\n  switch (repeatMode) {\n    case Player.REPEAT_MODE_OFF:\n      return windowIndex == getLastWindowIndex(shuffleModeEnabled)\n          ? C.INDEX_UNSET\n          : windowIndex + 1;\n    case Player.REPEAT_MODE_ONE:\n      return windowIndex;\n    case Player.REPEAT_MODE_ALL:\n      return windowIndex == getLastWindowIndex(shuffleModeEnabled)\n          ? getFirstWindowIndex(shuffleModeEnabled)\n          : windowIndex + 1;\n    default:\n      throw new IllegalStateException();\n  }\n}", "summary_tokens": ["returns", "the", "index", "of", "the", "window", "after", "the", "window", "at", "index", "window", "index", "depending", "on", "the", "repeat", "mode", "and", "whether", "shuffling", "is", "enabled"], "project": "ExoPlayer"}
{"id": 793, "code": "public PlayerMessage setPosition(int mediaItemIndex, long positionMs) {\n  Assertions.checkState(!isSent);\n  Assertions.checkArgument(positionMs != C.TIME_UNSET);\n  if (mediaItemIndex < 0\n      || (!timeline.isEmpty() && mediaItemIndex >= timeline.getWindowCount())) {\n    throw new IllegalSeekPositionException(timeline, mediaItemIndex, positionMs);\n  }\n  this.mediaItemIndex = mediaItemIndex;\n  this.positionMs = positionMs;\n  return this;\n}", "summary_tokens": ["sets", "a", "position", "in", "a", "media", "item", "at", "which", "the", "message", "will", "be", "delivered"], "project": "ExoPlayer"}
{"id": 2723, "code": "public FakeData getData(Uri uri) {\n  @Nullable FakeData data = dataMap.get(uri);\n  return data != null ? data : defaultData;\n}", "summary_tokens": ["returns", "the", "data", "for", "the", "given", "uri", "or", "default", "data", "if", "no", "data", "is", "set"], "project": "ExoPlayer"}
{"id": 625, "code": "public static String getAttributeValue(XmlPullParser xpp, String attributeName) {\n  int attributeCount = xpp.getAttributeCount();\n  for (int i = 0; i < attributeCount; i++) {\n    if (xpp.getAttributeName(i).equals(attributeName)) {\n      return xpp.getAttributeValue(i);\n    }\n  }\n  return null;\n}", "summary_tokens": ["returns", "the", "value", "of", "an", "attribute", "of", "the", "current", "start", "tag"], "project": "ExoPlayer"}
{"id": 2517, "code": "public void setResizeMode(@ResizeMode int resizeMode) {\n  Assertions.checkStateNotNull(contentFrame);\n  contentFrame.setResizeMode(resizeMode);\n}", "summary_tokens": ["sets", "the", "resize", "mode"], "project": "ExoPlayer"}
{"id": 738, "code": "public MediaPeriodHolder advancePlayingPeriod() {\n  if (playing == null) {\n    return null;\n  }\n  if (playing == reading) {\n    reading = playing.getNext();\n  }\n  playing.release();\n  length--;\n  if (length == 0) {\n    loading = null;\n    oldFrontPeriodUid = playing.uid;\n    oldFrontPeriodWindowSequenceNumber = playing.info.id.windowSequenceNumber;\n  }\n  playing = playing.getNext();\n  notifyQueueUpdate();\n  return playing;\n}", "summary_tokens": ["dequeues", "the", "playing", "period", "holder", "from", "the", "front", "of", "the", "queue", "and", "advances", "the", "playing", "period", "holder", "to", "be", "the", "next", "item", "in", "the", "queue"], "project": "ExoPlayer"}
{"id": 920, "code": "public long getMeanSeekTimeMs() {\n  return foregroundPlaybackCount == 0\n      ? C.TIME_UNSET\n      : getTotalSeekTimeMs() / foregroundPlaybackCount;\n}", "summary_tokens": ["returns", "the", "mean", "time", "spent", "per", "foreground", "playback", "from", "the", "start", "of", "a", "seek", "until", "playback", "is", "ready", "again", "in", "milliseconds", "or", "c", "time", "unset", "if", "no", "playback", "has", "been", "in", "foreground"], "project": "ExoPlayer"}
{"id": 311, "code": "public void setPlaylistMetadata(MediaMetadata mediaMetadata) {\n  player.setPlaylistMetadata(mediaMetadata);\n}", "summary_tokens": ["calls", "player", "set", "playlist", "metadata", "media", "metadata", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 1601, "code": "public void roundTripViaBundle_ofParameters_yieldsEqualInstance() {\n  Parameters parametersToBundle = buildParametersForEqualsTest();\n\n  Parameters parametersFromBundle = Parameters.CREATOR.fromBundle(parametersToBundle.toBundle());\n\n  assertThat(parametersFromBundle).isEqualTo(parametersToBundle);\n}", "summary_tokens": ["tests", "parameters", "bundleable", "implementation"], "project": "ExoPlayer"}
{"id": 1932, "code": "public static Mode[] readVorbisModes(ParsableByteArray headerData, int channels)\n    throws ParserException {\n\n  verifyVorbisHeaderCapturePattern(0x05, headerData, false);\n\n  int numberOfBooks = headerData.readUnsignedByte() + 1;\n\n  VorbisBitArray bitArray = new VorbisBitArray(headerData.getData());\n  bitArray.skipBits(headerData.getPosition() * 8);\n\n  for (int i = 0; i < numberOfBooks; i++) {\n    readBook(bitArray);\n  }\n\n  int timeCount = bitArray.readBits(6) + 1;\n  for (int i = 0; i < timeCount; i++) {\n    if (bitArray.readBits(16) != 0x00) {\n      throw ParserException.createForMalformedContainer(\n          \"placeholder of time domain transforms not zeroed out\",  null);\n    }\n  }\n  readFloors(bitArray);\n  readResidues(bitArray);\n  readMappings(channels, bitArray);\n\n  Mode[] modes = readModes(bitArray);\n  if (!bitArray.readBit()) {\n    throw ParserException.createForMalformedContainer(\n        \"framing bit after modes not set as expected\",  null);\n  }\n  return modes;\n}", "summary_tokens": ["this", "method", "reads", "the", "modes", "which", "are", "located", "at", "the", "very", "end", "of", "the", "vorbis", "setup", "header"], "project": "ExoPlayer"}
{"id": 2003, "code": "public static UUID parseUuid(byte[] atom) {\n  @Nullable PsshAtom parsedAtom = parsePsshAtom(atom);\n  if (parsedAtom == null) {\n    return null;\n  }\n  return parsedAtom.uuid;\n}", "summary_tokens": ["parses", "the", "uuid", "from", "a", "pssh", "atom"], "project": "ExoPlayer"}
{"id": 1781, "code": "public static synchronized boolean isCacheFolderLocked(File cacheFolder) {\n  return lockedCacheDirs.contains(cacheFolder.getAbsoluteFile());\n}", "summary_tokens": ["returns", "whether", "cache", "folder", "is", "locked", "by", "a", "simple", "cache", "instance"], "project": "ExoPlayer"}
{"id": 1673, "code": "public void seekToUs(long positionUs) {\n  currentIndex =\n      Util.binarySearchCeil(\n          eventTimesUs, positionUs,  true,  false);\n  boolean isPendingSeek = eventStreamAppendable && currentIndex == eventTimesUs.length;\n  pendingSeekPositionUs = isPendingSeek ? positionUs : C.TIME_UNSET;\n}", "summary_tokens": ["seeks", "to", "the", "specified", "position", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 1749, "code": "public static void delete(DatabaseProvider databaseProvider, long uid)\n    throws DatabaseIOException {\n  String hexUid = Long.toHexString(uid);\n  try {\n    String tableName = getTableName(hexUid);\n    SQLiteDatabase writableDatabase = databaseProvider.getWritableDatabase();\n    writableDatabase.beginTransactionNonExclusive();\n    try {\n      VersionTable.removeVersion(\n          writableDatabase, VersionTable.FEATURE_CACHE_FILE_METADATA, hexUid);\n      dropTable(writableDatabase, tableName);\n      writableDatabase.setTransactionSuccessful();\n    } finally {\n      writableDatabase.endTransaction();\n    }\n  } catch (SQLException e) {\n    throw new DatabaseIOException(e);\n  }\n}", "summary_tokens": ["deletes", "index", "data", "for", "the", "specified", "cache"], "project": "ExoPlayer"}
{"id": 2409, "code": "private static float[] getMatrix4x4Array(float[] matrix3x3Array) {\n  float[] matrix4x4Array = new float[16];\n  matrix4x4Array[10] = 1;\n  for (int inputRow = 0; inputRow < 3; inputRow++) {\n    for (int inputColumn = 0; inputColumn < 3; inputColumn++) {\n      int outputRow = (inputRow == 2) ? 3 : inputRow;\n      int outputColumn = (inputColumn == 2) ? 3 : inputColumn;\n      matrix4x4Array[outputRow * 4 + outputColumn] = matrix3x3Array[inputRow * 3 + inputColumn];\n    }\n  }\n  return matrix4x4Array;\n}", "summary_tokens": ["returns", "a", "0", "x", "0", "matrix", "array", "containing", "the", "0", "x", "0", "matrix", "array", "s", "contents"], "project": "ExoPlayer"}
{"id": 556, "code": "public String readBytesAsString(int length, Charset charset) {\n  byte[] bytes = new byte[length];\n  readBytes(bytes, 0, length);\n  return new String(bytes, charset);\n}", "summary_tokens": ["reads", "the", "next", "length", "bytes", "as", "a", "string", "encoded", "in", "charset"], "project": "ExoPlayer"}
{"id": 2686, "code": "public void assertState(String id, @Download.State int state) {\n  assertStateInternal(id, state);\n}", "summary_tokens": ["asserts", "that", "the", "specified", "download", "transitions", "to", "the", "specified", "state"], "project": "ExoPlayer"}
{"id": 2113, "code": "public void release() {\n  if (state == STATE_RELEASED) {\n    return;\n  }\n  subtitleDecoder.release();\n  state = STATE_RELEASED;\n}", "summary_tokens": ["releases", "the", "extractor", "s", "resources", "including", "the", "subtitle", "decoder"], "project": "ExoPlayer"}
{"id": 2354, "code": "public static int createGlTextureFromBitmap(Bitmap bitmap) {\n  int texId = GlUtil.createTexture(bitmap.getWidth(), bitmap.getHeight());\n    \n    \n  GLUtils.texImage2D(GLES20.GL_TEXTURE_2D, 0, flipBitmapVertically(bitmap), 0);\n  GlUtil.checkGlError();\n  return texId;\n}", "summary_tokens": ["creates", "a", "gles", "0", "gl", "texture", "0", "d", "0", "dimensional", "open", "gl", "texture", "with", "the", "bitmap", "s", "contents"], "project": "ExoPlayer"}
{"id": 2150, "code": "public boolean getTextCombine() {\n  return textCombine == ON;\n}", "summary_tokens": ["returns", "true", "if", "the", "source", "entity", "has", "tts", "text", "combine", "all"], "project": "ExoPlayer"}
{"id": 253, "code": "public void removeListener(Listener listener) {\n  player.removeListener(new ForwardingListener(this, listener));\n}", "summary_tokens": ["calls", "player", "remove", "listener", "listener", "on", "the", "delegate"], "project": "ExoPlayer"}
{"id": 121, "code": "public ImaServerSideAdInsertionUriBuilder setContentSourceId(@Nullable String contentSourceId) {\n  this.contentSourceId = contentSourceId;\n  return this;\n}", "summary_tokens": ["the", "stream", "request", "content", "source", "id", "used", "for", "on", "demand", "streams"], "project": "ExoPlayer"}
{"id": 2290, "code": "public static ImmutableList<String> serializeResponse(RtspResponse response) {\n  checkArgument(response.headers.get(RtspHeaders.CSEQ) != null);\n\n  ImmutableList.Builder<String> builder = new ImmutableList.Builder<>();\n    \n  builder.add(\n      Util.formatInvariant(\n          \"%s %s %s\", RTSP_VERSION, response.status, getRtspStatusReasonPhrase(response.status)));\n\n  ImmutableListMultimap<String, String> headers = response.headers.asMultiMap();\n  for (String headerName : headers.keySet()) {\n    ImmutableList<String> headerValuesForName = headers.get(headerName);\n    for (int i = 0; i < headerValuesForName.size(); i++) {\n      builder.add(Util.formatInvariant(\"%s: %s\", headerName, headerValuesForName.get(i)));\n    }\n  }\n    \n  builder.add(\"\");\n  builder.add(response.messageBody);\n  return builder.build();\n}", "summary_tokens": ["serializes", "an", "rtsp", "response", "to", "an", "immutable", "list", "of", "strings"], "project": "ExoPlayer"}
{"id": 990, "code": "public void handleEndOfStream(long writtenFrames) {\n  stopPlaybackHeadPosition = getPlaybackHeadPosition();\n  stopTimestampUs = SystemClock.elapsedRealtime() * 1000;\n  endPlaybackHeadPosition = writtenFrames;\n}", "summary_tokens": ["records", "the", "writing", "position", "at", "which", "the", "stream", "ended", "so", "that", "the", "reported", "position", "can", "continue", "to", "increment", "while", "remaining", "data", "is", "played", "out"], "project": "ExoPlayer"}
{"id": 1620, "code": "public void selectTracks_withPreferredAudioRoleFlags_selectPreferredTrack() throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format noRoleFlags = formatBuilder.build();\n  Format lessRoleFlags = formatBuilder.setRoleFlags(C.ROLE_FLAG_CAPTION).build();\n  Format moreRoleFlags =\n      formatBuilder\n          .setRoleFlags(C.ROLE_FLAG_CAPTION | C.ROLE_FLAG_COMMENTARY | C.ROLE_FLAG_DUB)\n          .build();\n  TrackGroupArray trackGroups = wrapFormats(noRoleFlags, moreRoleFlags, lessRoleFlags);\n\n  trackSelector.setParameters(\n      defaultParameters\n          .buildUpon()\n          .setPreferredAudioRoleFlags(C.ROLE_FLAG_CAPTION | C.ROLE_FLAG_COMMENTARY));\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_SUPPORTED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, moreRoleFlags);\n\n    \n  trackSelector.setParameters(\n      defaultParameters.buildUpon().setPreferredAudioRoleFlags(C.ROLE_FLAG_CAPTION));\n  result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_SUPPORTED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, lessRoleFlags);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "select", "the", "audio", "track", "with", "the", "highest", "number", "of", "matching", "role", "flags", "given", "by", "parameters"], "project": "ExoPlayer"}
{"id": 1639, "code": "public void selectTracksExceedingCapabilitiesPreferLowerNumChannelBeforeSampleRate()\n    throws Exception {\n  Format.Builder formatBuilder = AUDIO_FORMAT.buildUpon();\n  Format lowerChannelHigherSampleRateFormat =\n      formatBuilder.setChannelCount(2).setSampleRate(44100).build();\n  Format higherChannelLowerSampleRateFormat =\n      formatBuilder.setChannelCount(6).setSampleRate(22050).build();\n  TrackGroupArray trackGroups =\n      wrapFormats(higherChannelLowerSampleRateFormat, lowerChannelHigherSampleRateFormat);\n\n  TrackSelectorResult result =\n      trackSelector.selectTracks(\n          new RendererCapabilities[] {ALL_AUDIO_FORMAT_EXCEEDED_RENDERER_CAPABILITIES},\n          trackGroups,\n          periodId,\n          TIMELINE);\n  assertFixedSelection(result.selections[0], trackGroups, lowerChannelHigherSampleRateFormat);\n}", "summary_tokens": ["tests", "that", "track", "selector", "will", "prefer", "audio", "tracks", "with", "lower", "channel", "count", "over", "tracks", "with", "lower", "sample", "rate", "when", "other", "factors", "are", "the", "same", "and", "tracks", "are", "within", "renderer", "s", "capabilities"], "project": "ExoPlayer"}
{"id": 1372, "code": "public static long getStreamPositionUsForAd(\n    long positionUs, int adGroupIndex, int adIndexInAdGroup, AdPlaybackState adPlaybackState) {\n  AdPlaybackState.AdGroup currentAdGroup = adPlaybackState.getAdGroup(adGroupIndex);\n  positionUs += currentAdGroup.timeUs;\n  for (int i = adPlaybackState.removedAdGroupCount; i < adGroupIndex; i++) {\n    AdPlaybackState.AdGroup adGroup = adPlaybackState.getAdGroup(i);\n    for (int j = 0; j < getAdCountInGroup(adPlaybackState,  i); j++) {\n      positionUs += adGroup.durationsUs[j];\n    }\n    positionUs -= adGroup.contentResumeOffsetUs;\n  }\n  if (adIndexInAdGroup < getAdCountInGroup(adPlaybackState, adGroupIndex)) {\n    for (int i = 0; i < adIndexInAdGroup; i++) {\n      positionUs += currentAdGroup.durationsUs[i];\n    }\n  }\n  return positionUs;\n}", "summary_tokens": ["returns", "the", "position", "in", "the", "underlying", "server", "side", "inserted", "ads", "stream", "for", "a", "position", "in", "an", "ad", "media", "period"], "project": "ExoPlayer"}
{"id": 1957, "code": "private long readInteger(ExtractorInput input, int byteLength) throws IOException {\n  input.readFully(scratch, 0, byteLength);\n  long value = 0;\n  for (int i = 0; i < byteLength; i++) {\n    value = (value << 8) | (scratch[i] & 0xFF);\n  }\n  return value;\n}", "summary_tokens": ["reads", "and", "returns", "an", "integer", "of", "length", "byte", "length", "from", "the", "extractor", "input"], "project": "ExoPlayer"}
{"id": 155, "code": "public SessionCallbackBuilder setMediaItemProvider(\n    @Nullable MediaItemProvider mediaItemProvider) {\n  this.mediaItemProvider = mediaItemProvider;\n  return this;\n}", "summary_tokens": ["sets", "the", "media", "item", "provider", "that", "will", "convert", "media", "ids", "to", "media", "item", "media", "items"], "project": "ExoPlayer"}
{"id": 889, "code": "default void onVideoDisabled(EventTime eventTime, DecoderCounters decoderCounters) {}", "summary_tokens": ["called", "when", "a", "video", "renderer", "is", "disabled"], "project": "ExoPlayer"}
{"id": 1069, "code": "default void setPlayerIdForSession(byte[] sessionId, PlayerId playerId) {}", "summary_tokens": ["sets", "the", "player", "id", "of", "the", "player", "using", "a", "session"], "project": "ExoPlayer"}
{"id": 2544, "code": "public void setShowPreviousButton(boolean showPreviousButton) {\n  Assertions.checkStateNotNull(controller);\n  controller.setShowPreviousButton(showPreviousButton);\n}", "summary_tokens": ["sets", "whether", "the", "previous", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 1156, "code": "protected final long getOutputStreamOffsetUs() {\n  return outputStreamOffsetUs;\n}", "summary_tokens": ["returns", "the", "offset", "that", "should", "be", "subtracted", "from", "buffer", "presentation", "time", "us", "in", "process", "output", "buffer", "long", "long", "media", "codec", "adapter", "byte", "buffer", "int", "int", "int", "long", "boolean", "boolean", "format", "to", "get", "the", "playback", "position", "with", "respect", "to", "the", "media"], "project": "ExoPlayer"}
{"id": 2448, "code": "private static List<Integer> getKeptOutputLayers(\n    SefSlowMotionFlattener sefSlowMotionFlattener, int[] layerSequence, int frameCount) {\n  List<Integer> outputLayers = new ArrayList<>();\n  for (int i = 0; i < frameCount; i++) {\n    int layer = layerSequence[i % layerSequence.length];\n    long timeUs = i * C.MICROS_PER_SECOND / INPUT_FRAME_RATE;\n    if (sefSlowMotionFlattener.processCurrentFrame(layer, timeUs)) {\n      outputLayers.add(layer);\n    }\n  }\n  return outputLayers;\n}", "summary_tokens": ["returns", "a", "list", "containing", "the", "temporal", "svc", "layers", "of", "the", "frames", "that", "should", "be", "kept", "according", "to", "sef", "slow", "motion", "flattener", "process", "current", "frame", "int", "long"], "project": "ExoPlayer"}
{"id": 2797, "code": "public TestExoPlayerBuilder setClock(Clock clock) {\n  assertThat(clock).isNotNull();\n  this.clock = clock;\n  return this;\n}", "summary_tokens": ["sets", "the", "clock", "to", "be", "used", "by", "the", "player"], "project": "ExoPlayer"}
{"id": 2482, "code": "public void setShowShuffleButton(boolean showShuffleButton) {\n  this.showShuffleButton = showShuffleButton;\n  updateShuffleButton();\n}", "summary_tokens": ["sets", "whether", "the", "shuffle", "button", "is", "shown"], "project": "ExoPlayer"}
{"id": 270, "code": "public PlaybackException getPlayerError() {\n  return player.getPlayerError();\n}", "summary_tokens": ["calls", "player", "get", "player", "error", "on", "the", "delegate", "and", "returns", "the", "result"], "project": "ExoPlayer"}
{"id": 2443, "code": "public Builder buildUpon() {\n  return new Builder(this);\n}", "summary_tokens": ["returns", "a", "video", "encoder", "settings"], "project": "ExoPlayer"}
{"id": 1792, "code": "public static SimpleCacheSpan createLookup(String key, long position) {\n  return new SimpleCacheSpan(key, position, C.LENGTH_UNSET, C.TIME_UNSET, null);\n}", "summary_tokens": ["creates", "a", "lookup", "span"], "project": "ExoPlayer"}
{"id": 729, "code": "public boolean isLoading(MediaPeriod mediaPeriod) {\n  return loading != null && loading.mediaPeriod == mediaPeriod;\n}", "summary_tokens": ["returns", "whether", "media", "period", "is", "the", "current", "loading", "media", "period"], "project": "ExoPlayer"}
{"id": 551, "code": "public void readBits(byte[] buffer, int offset, int numBits) {\n    \n  int to = offset + (numBits >> 3) ;\n  for (int i = offset; i < to; i++) {\n    buffer[i] = (byte) (data[byteOffset++] << bitOffset);\n    buffer[i] = (byte) (buffer[i] | ((data[byteOffset] & 0xFF) >> (8 - bitOffset)));\n  }\n    \n  int bitsLeft = numBits & 7 ;\n  if (bitsLeft == 0) {\n    return;\n  }\n    \n  buffer[to] = (byte) (buffer[to] & (0xFF >> bitsLeft));\n  if (bitOffset + bitsLeft > 8) {\n      \n    buffer[to] = (byte) (buffer[to] | ((data[byteOffset++] & 0xFF) << bitOffset));\n    bitOffset -= 8;\n  }\n  bitOffset += bitsLeft;\n  int lastDataByteTrailingBits = (data[byteOffset] & 0xFF) >> (8 - bitOffset);\n  buffer[to] |= (byte) (lastDataByteTrailingBits << (8 - bitsLeft));\n  if (bitOffset == 8) {\n    bitOffset = 0;\n    byteOffset++;\n  }\n  assertValidOffset();\n}", "summary_tokens": ["reads", "num", "bits", "bits", "into", "buffer"], "project": "ExoPlayer"}
{"id": 1075, "code": "public void clearKeyRequestProperty(String name) {\n  Assertions.checkNotNull(name);\n  synchronized (keyRequestProperties) {\n    keyRequestProperties.remove(name);\n  }\n}", "summary_tokens": ["clears", "a", "header", "for", "key", "requests", "made", "by", "the", "callback"], "project": "ExoPlayer"}
{"id": 2784, "code": "public void stop(boolean reset) {\n  throw new UnsupportedOperationException();\n}", "summary_tokens": ["use", "stop", "and", "clear", "media", "items", "if", "reset", "is", "true", "or", "just", "stop", "if", "reset", "is", "false"], "project": "ExoPlayer"}
{"id": 2323, "code": "private void processFragmentationUnitPacket(ParsableByteArray data, int packetSequenceNumber)\n    throws ParserException {\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n  if (data.getData().length < 3) {\n    throw ParserException.createForMalformedManifest(\"Malformed FU header.\",  null);\n  }\n  int tid = (data.getData()[1] & 0x7);\n  int fuHeader = data.getData()[2];\n  int nalUnitType = fuHeader & 0x3F;\n  boolean isFirstFuPacket = (fuHeader & 0x80) > 0;\n  boolean isLastFuPacket = (fuHeader & 0x40) > 0;\n\n  if (isFirstFuPacket) {\n      \n    fragmentedSampleSizeBytes += writeStartCode();\n\n      \n      \n      \n      \n      \n    data.getData()[1] = (byte) ((nalUnitType << 1) & 0x7F);\n    data.getData()[2] = (byte) tid;\n    fuScratchBuffer.reset(data.getData());\n    fuScratchBuffer.setPosition(1);\n  } else {\n      \n    int expectedSequenceNumber = (previousSequenceNumber + 1) % RtpPacket.MAX_SEQUENCE_NUMBER;\n    if (packetSequenceNumber != expectedSequenceNumber) {\n      Log.w(\n          TAG,\n          Util.formatInvariant(\n              \"Received RTP packet with unexpected sequence number. Expected: %d; received: %d.\"\n                  + \" Dropping packet.\",\n              expectedSequenceNumber, packetSequenceNumber));\n      return;\n    }\n\n      \n    fuScratchBuffer.reset(data.getData());\n    fuScratchBuffer.setPosition(FU_PAYLOAD_OFFSET);\n  }\n\n  int fragmentSize = fuScratchBuffer.bytesLeft();\n  trackOutput.sampleData(fuScratchBuffer, fragmentSize);\n  fragmentedSampleSizeBytes += fragmentSize;\n\n  if (isLastFuPacket) {\n    bufferFlags = getBufferFlagsFromNalType(nalUnitType);\n  }\n}", "summary_tokens": ["processes", "fragmentation", "unit", "packet", "rfc", "0", "section", "0"], "project": "ExoPlayer"}
{"id": 1997, "code": "private static boolean shouldParseLeafAtom(int atom) {\n  return atom == Atom.TYPE_hdlr\n      || atom == Atom.TYPE_mdhd\n      || atom == Atom.TYPE_mvhd\n      || atom == Atom.TYPE_sidx\n      || atom == Atom.TYPE_stsd\n      || atom == Atom.TYPE_stts\n      || atom == Atom.TYPE_ctts\n      || atom == Atom.TYPE_stsc\n      || atom == Atom.TYPE_stsz\n      || atom == Atom.TYPE_stz2\n      || atom == Atom.TYPE_stco\n      || atom == Atom.TYPE_co64\n      || atom == Atom.TYPE_stss\n      || atom == Atom.TYPE_tfdt\n      || atom == Atom.TYPE_tfhd\n      || atom == Atom.TYPE_tkhd\n      || atom == Atom.TYPE_trex\n      || atom == Atom.TYPE_trun\n      || atom == Atom.TYPE_pssh\n      || atom == Atom.TYPE_saiz\n      || atom == Atom.TYPE_saio\n      || atom == Atom.TYPE_senc\n      || atom == Atom.TYPE_uuid\n      || atom == Atom.TYPE_sbgp\n      || atom == Atom.TYPE_sgpd\n      || atom == Atom.TYPE_elst\n      || atom == Atom.TYPE_mehd\n      || atom == Atom.TYPE_emsg;\n}", "summary_tokens": ["returns", "whether", "the", "extractor", "should", "decode", "a", "leaf", "atom", "with", "type", "atom"], "project": "ExoPlayer"}
{"id": 224, "code": "public final int getNextWindowIndex() {\n  return getNextMediaItemIndex();\n}", "summary_tokens": ["use", "get", "next", "media", "item", "index", "instead"], "project": "ExoPlayer"}
{"id": 2350, "code": "public static Bitmap createArgb8888BitmapFromRgba8888Image(Image image) {\n  int width = image.getWidth();\n  int height = image.getHeight();\n  assertThat(image.getPlanes()).hasLength(1);\n  assertThat(image.getFormat()).isEqualTo(PixelFormat.RGBA_8888);\n  Image.Plane plane = image.getPlanes()[0];\n  ByteBuffer buffer = plane.getBuffer();\n  int[] colors = new int[width * height];\n  for (int y = 0; y < height; y++) {\n    for (int x = 0; x < width; x++) {\n      int offset = y * plane.getRowStride() + x * plane.getPixelStride();\n      int r = buffer.get(offset) & 0xFF;\n      int g = buffer.get(offset + 1) & 0xFF;\n      int b = buffer.get(offset + 2) & 0xFF;\n      int a = buffer.get(offset + 3) & 0xFF;\n      colors[y * width + x] = Color.argb(a, r, g, b);\n    }\n  }\n  return Bitmap.createBitmap(colors, width, height, Bitmap.Config.ARGB_8888);\n}", "summary_tokens": ["returns", "a", "bitmap", "with", "the", "same", "information", "as", "the", "provided", "alpha", "red", "green", "blue", "0", "bits", "per", "component", "image"], "project": "ExoPlayer"}
{"id": 965, "code": "public AudioCapabilities register() {\n  if (registered) {\n    return Assertions.checkNotNull(audioCapabilities);\n  }\n  registered = true;\n  if (externalSurroundSoundSettingObserver != null) {\n    externalSurroundSoundSettingObserver.register();\n  }\n  Intent stickyIntent = null;\n  if (receiver != null) {\n    IntentFilter intentFilter = new IntentFilter(AudioManager.ACTION_HDMI_AUDIO_PLUG);\n    stickyIntent =\n        context.registerReceiver(\n            receiver, intentFilter,  null, handler);\n  }\n  audioCapabilities = AudioCapabilities.getCapabilities(context, stickyIntent);\n  return audioCapabilities;\n}", "summary_tokens": ["registers", "the", "receiver", "meaning", "it", "will", "notify", "the", "listener", "when", "audio", "capability", "changes", "occur"], "project": "ExoPlayer"}
{"id": 2338, "code": "public static SsManifest createSsManifest(StreamElement... streamElements) {\n  return new SsManifest(\n      TEST_MAJOR_VERSION,\n      TEST_MINOR_VERSION,\n      TEST_TIMESCALE,\n      TEST_DURATION,\n      TEST_DVR_WINDOW_LENGTH,\n      TEST_LOOKAHEAD_COUNT,\n      TEST_IS_LIVE,\n      TEST_PROTECTION_ELEMENT,\n      streamElements);\n}", "summary_tokens": ["creates", "test", "manifest", "with", "the", "given", "stream", "elements"], "project": "ExoPlayer"}
{"id": 734, "code": "public MediaPeriodHolder getLoadingPeriod() {\n  return loading;\n}", "summary_tokens": ["returns", "the", "loading", "period", "holder", "which", "is", "at", "the", "end", "of", "the", "queue", "or", "null", "if", "the", "queue", "is", "empty"], "project": "ExoPlayer"}
{"id": 1384, "code": "public final Map<String, List<String>> getResponseHeaders() {\n  return dataSource.getLastResponseHeaders();\n}", "summary_tokens": ["returns", "the", "response", "headers", "associated", "with", "the", "last", "data", "source", "open", "call"], "project": "ExoPlayer"}
{"id": 1853, "code": "public final SeekMap getSeekMap() {\n  return seekMap;\n}", "summary_tokens": ["returns", "the", "seek", "map", "for", "the", "stream"], "project": "ExoPlayer"}
{"id": 1978, "code": "public static XingSeeker create(\n    long inputLength,\n    long position,\n    MpegAudioUtil.Header mpegAudioHeader,\n    ParsableByteArray frame) {\n  int samplesPerFrame = mpegAudioHeader.samplesPerFrame;\n  int sampleRate = mpegAudioHeader.sampleRate;\n\n  int flags = frame.readInt();\n  int frameCount;\n  if ((flags & 0x01) != 0x01 || (frameCount = frame.readUnsignedIntToInt()) == 0) {\n      \n    return null;\n  }\n  long durationUs =\n      Util.scaleLargeTimestamp(frameCount, samplesPerFrame * C.MICROS_PER_SECOND, sampleRate);\n  if ((flags & 0x06) != 0x06) {\n      \n    return new XingSeeker(position, mpegAudioHeader.frameSize, durationUs);\n  }\n\n  long dataSize = frame.readUnsignedInt();\n  long[] tableOfContents = new long[100];\n  for (int i = 0; i < 100; i++) {\n    tableOfContents[i] = frame.readUnsignedByte();\n  }\n\n    \n    \n    \n\n  if (inputLength != C.LENGTH_UNSET && inputLength != position + dataSize) {\n    Log.w(TAG, \"XING data size mismatch: \" + inputLength + \", \" + (position + dataSize));\n  }\n  return new XingSeeker(\n      position, mpegAudioHeader.frameSize, durationUs, dataSize, tableOfContents);\n}", "summary_tokens": ["returns", "a", "xing", "seeker", "for", "seeking", "in", "the", "stream", "if", "required", "information", "is", "present"], "project": "ExoPlayer"}
{"id": 2259, "code": "public synchronized boolean offer(RtpPacket packet, long receivedTimestampMs) {\n  if (packetQueue.size() >= QUEUE_SIZE_THRESHOLD_FOR_RESET) {\n    throw new IllegalStateException(\n        \"Queue size limit of \" + QUEUE_SIZE_THRESHOLD_FOR_RESET + \" reached.\");\n  }\n\n  int packetSequenceNumber = packet.sequenceNumber;\n  if (!started) {\n    reset();\n    lastDequeuedSequenceNumber = RtpPacket.getPreviousSequenceNumber(packetSequenceNumber);\n    started = true;\n    addToQueue(new RtpPacketContainer(packet, receivedTimestampMs));\n    return true;\n  }\n\n  int expectedSequenceNumber = RtpPacket.getNextSequenceNumber(lastReceivedSequenceNumber);\n    \n  int sequenceNumberShift =\n      calculateSequenceNumberShift(packetSequenceNumber, expectedSequenceNumber);\n  if (abs(sequenceNumberShift) < MAX_SEQUENCE_LEAP_ALLOWED) {\n    if (calculateSequenceNumberShift(packetSequenceNumber, lastDequeuedSequenceNumber) > 0) {\n        \n      addToQueue(new RtpPacketContainer(packet, receivedTimestampMs));\n      return true;\n    }\n  } else {\n      \n    lastDequeuedSequenceNumber = RtpPacket.getPreviousSequenceNumber(packetSequenceNumber);\n    packetQueue.clear();\n    addToQueue(new RtpPacketContainer(packet, receivedTimestampMs));\n    return true;\n  }\n  return false;\n}", "summary_tokens": ["offer", "one", "packet", "to", "the", "reordering", "queue"], "project": "ExoPlayer"}
{"id": 444, "code": "private static int findNalStartCode(byte[] data, int index) {\n  int endIndex = data.length - NAL_START_CODE.length;\n  for (int i = index; i <= endIndex; i++) {\n    if (isNalStartCode(data, i)) {\n      return i;\n    }\n  }\n  return C.INDEX_UNSET;\n}", "summary_tokens": ["finds", "the", "next", "occurrence", "of", "the", "nal", "start", "code", "from", "a", "given", "index"], "project": "ExoPlayer"}
{"id": 1375, "code": "public static long getMediaPeriodPositionUsForContent(\n    long positionUs, int nextAdGroupIndex, AdPlaybackState adPlaybackState) {\n  long totalAdDurationBeforePositionUs = 0;\n  if (nextAdGroupIndex == C.INDEX_UNSET) {\n    nextAdGroupIndex = adPlaybackState.adGroupCount;\n  }\n  for (int i = adPlaybackState.removedAdGroupCount; i < nextAdGroupIndex; i++) {\n    AdPlaybackState.AdGroup adGroup = adPlaybackState.getAdGroup(i);\n    if (adGroup.timeUs == C.TIME_END_OF_SOURCE\n        || adGroup.timeUs > positionUs - totalAdDurationBeforePositionUs) {\n      break;\n    }\n    for (int j = 0; j < getAdCountInGroup(adPlaybackState,  i); j++) {\n      totalAdDurationBeforePositionUs += adGroup.durationsUs[j];\n    }\n    totalAdDurationBeforePositionUs -= adGroup.contentResumeOffsetUs;\n    long adGroupResumePositionUs = adGroup.timeUs + adGroup.contentResumeOffsetUs;\n    if (adGroupResumePositionUs > positionUs - totalAdDurationBeforePositionUs) {\n        \n      return max(adGroup.timeUs, positionUs - totalAdDurationBeforePositionUs);\n    }\n  }\n  return positionUs - totalAdDurationBeforePositionUs;\n}", "summary_tokens": ["returns", "the", "position", "in", "a", "content", "media", "period", "for", "a", "position", "in", "the", "underlying", "server", "side", "inserted", "ads", "stream"], "project": "ExoPlayer"}
{"id": 905, "code": "protected final EventTime generateEventTime(\n    Timeline timeline, int windowIndex, @Nullable MediaPeriodId mediaPeriodId) {\n  if (timeline.isEmpty()) {\n      \n    mediaPeriodId = null;\n  }\n  long realtimeMs = clock.elapsedRealtime();\n  long eventPositionMs;\n  boolean isInCurrentWindow =\n      timeline.equals(player.getCurrentTimeline())\n          && windowIndex == player.getCurrentMediaItemIndex();\n  if (mediaPeriodId != null && mediaPeriodId.isAd()) {\n    boolean isCurrentAd =\n        isInCurrentWindow\n            && player.getCurrentAdGroupIndex() == mediaPeriodId.adGroupIndex\n            && player.getCurrentAdIndexInAdGroup() == mediaPeriodId.adIndexInAdGroup;\n      \n    eventPositionMs = isCurrentAd ? player.getCurrentPosition() : 0;\n  } else if (isInCurrentWindow) {\n    eventPositionMs = player.getContentPosition();\n  } else {\n      \n      \n    eventPositionMs =\n        timeline.isEmpty() ? 0 : timeline.getWindow(windowIndex, window).getDefaultPositionMs();\n  }\n  @Nullable\n  MediaPeriodId currentMediaPeriodId = mediaPeriodQueueTracker.getCurrentPlayerMediaPeriod();\n  return new EventTime(\n      realtimeMs,\n      timeline,\n      windowIndex,\n      mediaPeriodId,\n      eventPositionMs,\n      player.getCurrentTimeline(),\n      player.getCurrentMediaItemIndex(),\n      currentMediaPeriodId,\n      player.getCurrentPosition(),\n      player.getTotalBufferedDuration());\n}", "summary_tokens": ["returns", "a", "new", "event", "time", "for", "the", "specified", "timeline", "window", "and", "media", "period", "id"], "project": "ExoPlayer"}
{"id": 1418, "code": "public TrackSelectionParameters getParameters() {\n  return TrackSelectionParameters.DEFAULT_WITHOUT_CONTEXT;\n}", "summary_tokens": ["returns", "the", "current", "parameters", "for", "track", "selection"], "project": "ExoPlayer"}
{"id": 1668, "code": "public static Format loadFormatWithDrmInitData(DataSource dataSource, Period period)\n    throws IOException {\n  @C.TrackType int primaryTrackType = C.TRACK_TYPE_VIDEO;\n  Representation representation = getFirstRepresentation(period, primaryTrackType);\n  if (representation == null) {\n    primaryTrackType = C.TRACK_TYPE_AUDIO;\n    representation = getFirstRepresentation(period, primaryTrackType);\n    if (representation == null) {\n      return null;\n    }\n  }\n  Format manifestFormat = representation.format;\n  @Nullable\n  Format sampleFormat = DashUtil.loadSampleFormat(dataSource, primaryTrackType, representation);\n  return sampleFormat == null\n      ? manifestFormat\n      : sampleFormat.withManifestFormatInfo(manifestFormat);\n}", "summary_tokens": ["loads", "a", "format", "for", "acquiring", "keys", "for", "a", "given", "period", "in", "a", "dash", "manifest"], "project": "ExoPlayer"}
{"id": 2044, "code": "public static boolean isAdtsSyncWord(int candidateSyncWord) {\n  return (candidateSyncWord & 0xFFF6) == 0xFFF0;\n}", "summary_tokens": ["returns", "whether", "an", "integer", "matches", "an", "adts", "sync", "word"], "project": "ExoPlayer"}
{"id": 895, "code": "default void onDrmSessionAcquired(EventTime eventTime, @DrmSession.State int state) {}", "summary_tokens": ["called", "each", "time", "a", "drm", "session", "is", "acquired"], "project": "ExoPlayer"}
{"id": 140, "code": "public static String getStringForVideoProgressUpdate(VideoProgressUpdate videoProgressUpdate) {\n  if (VideoProgressUpdate.VIDEO_TIME_NOT_READY.equals(videoProgressUpdate)) {\n    return \"not ready\";\n  } else {\n    return Util.formatInvariant(\n        \"%d ms of %d ms\",\n        videoProgressUpdate.getCurrentTimeMs(), videoProgressUpdate.getDurationMs());\n  }\n}", "summary_tokens": ["returns", "a", "human", "readable", "representation", "of", "a", "video", "progress", "update"], "project": "ExoPlayer"}
{"id": 1925, "code": "public void setPosition(int position) {\n  byteOffset = position / 8;\n  bitOffset = position - (byteOffset * 8);\n  assertValidOffset();\n}", "summary_tokens": ["sets", "the", "reading", "position", "in", "bits"], "project": "ExoPlayer"}
{"id": 193, "code": "private int readInternal(byte[] buffer, int offset, int readLength) throws IOException {\n  if (readLength == 0) {\n    return 0;\n  }\n  if (bytesToRead != C.LENGTH_UNSET) {\n    long bytesRemaining = bytesToRead - bytesRead;\n    if (bytesRemaining == 0) {\n      return C.RESULT_END_OF_INPUT;\n    }\n    readLength = (int) min(readLength, bytesRemaining);\n  }\n\n  int read = castNonNull(responseByteStream).read(buffer, offset, readLength);\n  if (read == -1) {\n    return C.RESULT_END_OF_INPUT;\n  }\n\n  bytesRead += read;\n  bytesTransferred(read);\n  return read;\n}", "summary_tokens": ["reads", "up", "to", "length", "bytes", "of", "data", "and", "stores", "them", "into", "buffer", "starting", "at", "index", "offset"], "project": "ExoPlayer"}
{"id": 1390, "code": "public void seekToUs(long positionUs) {\n  lastSeekPositionUs = positionUs;\n  if (isPendingReset()) {\n      \n    pendingResetPositionUs = positionUs;\n    return;\n  }\n\n    \n  @Nullable BaseMediaChunk seekToMediaChunk = null;\n  for (int i = 0; i < mediaChunks.size(); i++) {\n    BaseMediaChunk mediaChunk = mediaChunks.get(i);\n    long mediaChunkStartTimeUs = mediaChunk.startTimeUs;\n    if (mediaChunkStartTimeUs == positionUs && mediaChunk.clippedStartTimeUs == C.TIME_UNSET) {\n      seekToMediaChunk = mediaChunk;\n      break;\n    } else if (mediaChunkStartTimeUs > positionUs) {\n        \n      break;\n    }\n  }\n\n    \n  boolean seekInsideBuffer;\n  if (seekToMediaChunk != null) {\n      \n      \n      \n    seekInsideBuffer = primarySampleQueue.seekTo(seekToMediaChunk.getFirstSampleIndex(0));\n  } else {\n    seekInsideBuffer =\n        primarySampleQueue.seekTo(\n            positionUs,  positionUs < getNextLoadPositionUs());\n  }\n\n  if (seekInsideBuffer) {\n      \n    nextNotifyPrimaryFormatMediaChunkIndex =\n        primarySampleIndexToMediaChunkIndex(\n            primarySampleQueue.getReadIndex(),  0);\n      \n    for (SampleQueue embeddedSampleQueue : embeddedSampleQueues) {\n      embeddedSampleQueue.seekTo(positionUs,  true);\n    }\n  } else {\n      \n    pendingResetPositionUs = positionUs;\n    loadingFinished = false;\n    mediaChunks.clear();\n    nextNotifyPrimaryFormatMediaChunkIndex = 0;\n    if (loader.isLoading()) {\n        \n      primarySampleQueue.discardToEnd();\n      for (SampleQueue embeddedSampleQueue : embeddedSampleQueues) {\n        embeddedSampleQueue.discardToEnd();\n      }\n      loader.cancelLoading();\n    } else {\n      loader.clearFatalError();\n      resetSampleQueues();\n    }\n  }\n}", "summary_tokens": ["seeks", "to", "the", "specified", "position", "in", "microseconds"], "project": "ExoPlayer"}
{"id": 871, "code": "default void onAudioInputFormatChanged(\n    EventTime eventTime,\n    Format format,\n    @Nullable DecoderReuseEvaluation decoderReuseEvaluation) {}", "summary_tokens": ["called", "when", "the", "format", "of", "the", "media", "being", "consumed", "by", "an", "audio", "renderer", "changes"], "project": "ExoPlayer"}
{"id": 1875, "code": "public synchronized DefaultExtractorsFactory setFragmentedMp4ExtractorFlags(\n    @FragmentedMp4Extractor.Flags int flags) {\n  this.fragmentedMp4Flags = flags;\n  return this;\n}", "summary_tokens": ["sets", "flags", "for", "fragmented", "mp", "0", "extractor", "instances", "created", "by", "the", "factory"], "project": "ExoPlayer"}
{"id": 2429, "code": "public Path logSegment() {\n    return logSegment;\n}", "summary_tokens": ["log", "segment", "file", "of", "this", "segment"], "project": "kafka"}
{"id": 2151, "code": "protected boolean checkConnectorAndTasksAreStopped(String connectorName) {\n    ConnectorStateInfo info;\n    try {\n        info = connect.connectorStatus(connectorName);\n    } catch (ConnectRestException e) {\n        return e.statusCode() == Response.Status.NOT_FOUND.getStatusCode();\n    } catch (Exception e) {\n        log.error(\"Could not check connector state info.\", e);\n        return false;\n    }\n    if (info == null) {\n        return true;\n    }\n    return !info.connector().state().equals(AbstractStatus.State.RUNNING.toString())\n            && info.tasks().stream().noneMatch(s -> s.state().equals(AbstractStatus.State.RUNNING.toString()));\n}", "summary_tokens": ["check", "whether", "the", "connector", "or", "any", "of", "its", "tasks", "are", "still", "in", "running", "state"], "project": "kafka"}
{"id": 742, "code": "private void ensureNotFinished() {\n    if (finished) {\n        throw new IllegalStateException(CLOSED_STREAM);\n    }\n}", "summary_tokens": ["a", "simple", "state", "check", "to", "ensure", "the", "stream", "is", "still", "open"], "project": "kafka"}
{"id": 1850, "code": "public static ByteBuffer serializeAssignment(ExtendedAssignment assignment, boolean sessioned) {\n        \n    if (assignment == null || ExtendedAssignment.empty().equals(assignment)) {\n        return null;\n    }\n    Struct struct = assignment.toStruct();\n    Struct protocolHeader = sessioned ? CONNECT_PROTOCOL_HEADER_V2 : CONNECT_PROTOCOL_HEADER_V1;\n    ByteBuffer buffer = ByteBuffer.allocate(protocolHeader.sizeOf()\n                                            + ASSIGNMENT_V1.sizeOf(struct));\n    protocolHeader.writeTo(buffer);\n    ASSIGNMENT_V1.write(buffer, struct);\n    buffer.flip();\n    return buffer;\n}", "summary_tokens": ["the", "fields", "are", "serialized", "in", "sequence", "as", "follows", "complete", "assignment", "v", "0", "pre", "version", "int", "0", "error", "int", "0", "leader", "string", "leader", "url", "string", "config", "offset", "int", "0", "assignment", "connector", "assignment", "revoked", "connector", "assignment", "scheduled", "delay", "int", "0", "pre"], "project": "kafka"}
{"id": 1635, "code": "public static Integer convertToInteger(Schema schema, Object value) throws DataException {\n    return (Integer) convertTo(Schema.OPTIONAL_INT32_SCHEMA, schema, value);\n}", "summary_tokens": ["convert", "the", "specified", "value", "to", "an", "type", "int", "0", "int", "value"], "project": "kafka"}
{"id": 2018, "code": "public TaskHandle taskHandle(String taskId, Consumer<SinkRecord> consumer) {\n    return taskHandles.computeIfAbsent(taskId, k -> new TaskHandle(this, taskId, consumer));\n}", "summary_tokens": ["get", "or", "create", "a", "task", "handle", "for", "a", "given", "task", "id"], "project": "kafka"}
{"id": 2979, "code": "public R getResult() {\n    throw new IllegalArgumentException(\n        \"Cannot get result for failed query. Failure is \" + failureReason.name() + \": \"\n            + failure);\n}", "summary_tokens": ["returns", "the", "result", "of", "executing", "the", "query", "on", "one", "partition"], "project": "kafka"}
{"id": 1045, "code": "public static int nextEpoch(int prevEpoch) {\n    if (prevEpoch < 0) {\n            \n        return FINAL_EPOCH;\n    } else if (prevEpoch == Integer.MAX_VALUE) {\n        return 1;\n    } else {\n        return prevEpoch + 1;\n    }\n}", "summary_tokens": ["returns", "the", "next", "epoch"], "project": "kafka"}
{"id": 936, "code": "public boolean isNullable() {\n    return false;\n}", "summary_tokens": ["check", "if", "the", "type", "supports", "null", "values", "whether", "or", "not", "null", "is", "a", "valid", "value", "for", "the", "type", "implementation"], "project": "kafka"}
{"id": 2974, "code": "public Position getPosition() {\n    return position;\n}", "summary_tokens": ["this", "state", "partition", "s", "exact", "position", "in", "its", "history", "when", "this", "query", "was", "executed"], "project": "kafka"}
{"id": 1648, "code": "public static SchemaAndValue parseString(String value) {\n    if (value == null) {\n        return NULL_SCHEMA_AND_VALUE;\n    }\n    if (value.isEmpty()) {\n        return new SchemaAndValue(Schema.STRING_SCHEMA, value);\n    }\n    Parser parser = new Parser(value);\n    return parse(parser, false);\n}", "summary_tokens": ["parse", "the", "specified", "string", "representation", "of", "a", "value", "into", "its", "schema", "and", "value"], "project": "kafka"}
{"id": 1920, "code": "public Response setLevel(final @PathParam(\"logger\") String namedLogger,\n                         final Map<String, String> levelMap) {\n    String desiredLevelStr = levelMap.get(\"level\");\n    if (desiredLevelStr == null) {\n        throw new BadRequestException(\"Desired 'level' parameter was not specified in request.\");\n    }\n\n    Level level = Level.toLevel(desiredLevelStr.toUpperCase(Locale.ROOT), null);\n    if (level == null) {\n        throw new NotFoundException(\"invalid log level '\" + desiredLevelStr + \"'.\");\n    }\n\n    List<Logger> childLoggers;\n    if (ROOT_LOGGER_NAME.equalsIgnoreCase(namedLogger)) {\n        childLoggers = Collections.list(currentLoggers());\n        childLoggers.add(rootLogger());\n    } else {\n        childLoggers = new ArrayList<>();\n        Logger ancestorLogger = lookupLogger(namedLogger);\n        Enumeration<Logger> en = currentLoggers();\n        boolean present = false;\n        while (en.hasMoreElements()) {\n            Logger current = en.nextElement();\n            if (current.getName().startsWith(namedLogger)) {\n                childLoggers.add(current);\n            }\n            if (namedLogger.equals(current.getName())) {\n                present = true;\n            }\n        }\n        if (!present) {\n            childLoggers.add(ancestorLogger);\n        }\n    }\n\n    List<String> modifiedLoggerNames = new ArrayList<>();\n    for (Logger logger: childLoggers) {\n        logger.setLevel(level);\n        modifiedLoggerNames.add(logger.getName());\n    }\n    Collections.sort(modifiedLoggerNames);\n\n    return Response.ok(modifiedLoggerNames).build();\n}", "summary_tokens": ["adjust", "level", "of", "a", "named", "logger"], "project": "kafka"}
{"id": 1095, "code": "public static String firstPrincipal(Subject subject) {\n    Set<Principal> principals = subject.getPrincipals();\n    synchronized (principals) {\n        Iterator<Principal> iterator = principals.iterator();\n        if (iterator.hasNext())\n            return iterator.next().getName();\n        else\n            throw new KafkaException(\"Principal could not be determined from Subject, this may be a transient failure due to Kerberos re-login\");\n    }\n}", "summary_tokens": ["returns", "the", "first", "principal", "from", "subject"], "project": "kafka"}
{"id": 1151, "code": "public String scopeClaimName() {\n    return scopeClaimName;\n}", "summary_tokens": ["return", "the", "always", "non", "null", "non", "empty", "scope", "claim", "name"], "project": "kafka"}
{"id": 576, "code": "private void freeUp(int size) {\n    while (!this.free.isEmpty() && this.nonPooledAvailableMemory < size)\n        this.nonPooledAvailableMemory += this.free.pollLast().capacity();\n}", "summary_tokens": ["attempt", "to", "ensure", "we", "have", "at", "least", "the", "requested", "number", "of", "bytes", "of", "memory", "for", "allocation", "by", "deallocating", "pooled", "buffers", "if", "needed"], "project": "kafka"}
{"id": 769, "code": "private List<ConfigKey> sortedConfigs() {\n    final Map<String, Integer> groupOrd = new HashMap<>(groups.size());\n    int ord = 0;\n    for (String group: groups) {\n        groupOrd.put(group, ord++);\n    }\n\n    List<ConfigKey> configs = new ArrayList<>(configKeys.values());\n    Collections.sort(configs, (k1, k2) -> compare(k1, k2, groupOrd));\n    return configs;\n}", "summary_tokens": ["get", "a", "list", "of", "configs", "sorted", "taking", "the", "group", "and", "order", "in", "group", "into", "account"], "project": "kafka"}
{"id": 3121, "code": "public void suppressShouldNotDropTombstonesForSessionWindows() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(untilTimeLimit(ofMillis(0), maxRecords(0)), sessionWindowedSerdeFrom(String.class), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final Windowed<String> key = new Windowed<>(\"hey\", new SessionWindow(0L, 0L));\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(1));\n    final MockProcessorContext.CapturedForward capturedForward = context.forwarded().get(0);\n    assertThat(capturedForward.record(), is(new Record<>(key, value, timestamp)));\n}", "summary_tokens": ["it", "s", "not", "ok", "to", "drop", "tombstones", "for", "non", "final", "results", "windowed", "streams", "since", "we", "may", "have", "emitted", "some", "results", "for", "the", "window", "before", "getting", "the", "tombstone", "see", "the", "suppressed", "internal", "javadoc"], "project": "kafka"}
{"id": 2084, "code": "public void testExternalZombieFencingRequestAsynchronousFailure() throws Exception {\n    expectHerderStartup();\n    EasyMock.expect(member.memberId()).andStubReturn(\"leader\");\n    EasyMock.expect(member.currentProtocolVersion()).andStubReturn(CONNECT_PROTOCOL_V2);\n    expectConfigRefreshAndSnapshot(SNAPSHOT);\n\n    expectRebalance(1, Collections.emptyList(), Collections.emptyList(), true);\n    SessionKey sessionKey = expectNewSessionKey();\n\n    expectAnyTicks();\n\n    member.wakeup();\n    EasyMock.expectLastCall();\n\n    ClusterConfigState configState = exactlyOnceSnapshot(\n            sessionKey,\n            TASK_CONFIGS_MAP,\n            Collections.singletonMap(CONN1, 2),\n            Collections.singletonMap(CONN1, 5),\n            Collections.singleton(CONN1)\n    );\n    expectConfigRefreshAndSnapshot(configState);\n\n        \n    KafkaFuture<Void> workerFencingFuture = EasyMock.mock(KafkaFuture.class);\n        \n    KafkaFuture<Void> herderFencingFuture = EasyMock.mock(KafkaFuture.class);\n        \n    Capture<KafkaFuture.BiConsumer<Void, Throwable>> herderFencingCallbacks = EasyMock.newCapture(CaptureType.ALL);\n\n    EasyMock.expect(worker.fenceZombies(EasyMock.eq(CONN1), EasyMock.eq(2), EasyMock.eq(CONN1_CONFIG)))\n            .andReturn(workerFencingFuture);\n\n    EasyMock.expect(workerFencingFuture.thenApply(EasyMock.<KafkaFuture.BaseFunction<Void, Void>>anyObject()))\n            .andReturn(herderFencingFuture);\n\n    CountDownLatch callbacksInstalled = new CountDownLatch(2);\n    for (int i = 0; i < 2; i++) {\n        EasyMock.expect(herderFencingFuture.whenComplete(EasyMock.capture(herderFencingCallbacks))).andAnswer(() -> {\n            callbacksInstalled.countDown();\n            return null;\n        });\n    }\n\n    expectHerderShutdown(true);\n\n    PowerMock.replayAll(workerFencingFuture, herderFencingFuture);\n\n\n    startBackgroundHerder();\n\n    FutureCallback<Void> fencing = new FutureCallback<>();\n    herder.fenceZombieSourceTasks(CONN1, fencing);\n\n    assertTrue(callbacksInstalled.await(10, TimeUnit.SECONDS));\n\n    Exception fencingException = new AuthorizationException(\"you didn't say the magic word\");\n    herderFencingCallbacks.getValues().forEach(cb -> cb.accept(null, fencingException));\n\n    ExecutionException exception = assertThrows(ExecutionException.class, () -> fencing.get(10, TimeUnit.SECONDS));\n    assertTrue(exception.getCause() instanceof ConnectException);\n\n    stopBackgroundHerder();\n\n    PowerMock.verifyAll();\n}", "summary_tokens": ["the", "herder", "tries", "to", "perform", "a", "round", "of", "fencing", "and", "is", "able", "to", "retrieve", "a", "future", "from", "worker", "fence", "zombies", "but", "the", "attempt", "fails", "at", "a", "later", "point"], "project": "kafka"}
{"id": 2398, "code": "public static FileRawSnapshotWriter create(\n    Path logDir,\n    OffsetAndEpoch snapshotId,\n    Optional<ReplicatedLog> replicatedLog\n) {\n    Path path = Snapshots.createTempFile(logDir, snapshotId);\n\n    try {\n        return new FileRawSnapshotWriter(\n            path,\n            FileChannel.open(path, StandardOpenOption.WRITE, StandardOpenOption.APPEND),\n            snapshotId,\n            replicatedLog\n        );\n    } catch (IOException e) {\n        throw new UncheckedIOException(\n            String.format(\n                \"Error creating snapshot writer. path = %s, snapshotId %s.\",\n                path,\n                snapshotId\n            ),\n            e\n        );\n    }\n}", "summary_tokens": ["create", "a", "snapshot", "writer", "for", "topic", "partition", "log", "dir", "and", "snapshot", "id"], "project": "kafka"}
{"id": 2590, "code": "public Joined<K, V, VO> withName(final String name) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}", "summary_tokens": ["set", "the", "base", "name", "used", "for", "all", "components", "of", "the", "join", "this", "may", "include", "any", "repartition", "topics", "created", "to", "complete", "the", "join"], "project": "kafka"}
{"id": 2730, "code": "public ValidationResult validate(final Map<String, InternalTopicConfig> topicConfigs) {\n    log.info(\"Starting to validate internal topics {}.\", topicConfigs.keySet());\n\n    final long now = time.milliseconds();\n    final long deadline = now + retryTimeoutMs;\n\n    final ValidationResult validationResult = new ValidationResult();\n    final Set<String> topicDescriptionsStillToValidate = new HashSet<>(topicConfigs.keySet());\n    final Set<String> topicConfigsStillToValidate = new HashSet<>(topicConfigs.keySet());\n    while (!topicDescriptionsStillToValidate.isEmpty() || !topicConfigsStillToValidate.isEmpty()) {\n        Map<String, KafkaFuture<TopicDescription>> descriptionsForTopic = Collections.emptyMap();\n        if (!topicDescriptionsStillToValidate.isEmpty()) {\n            final DescribeTopicsResult describeTopicsResult = adminClient.describeTopics(topicDescriptionsStillToValidate);\n            descriptionsForTopic = describeTopicsResult.topicNameValues();\n        }\n        Map<String, KafkaFuture<Config>> configsForTopic = Collections.emptyMap();\n        if (!topicConfigsStillToValidate.isEmpty()) {\n            final DescribeConfigsResult describeConfigsResult = adminClient.describeConfigs(\n                topicConfigsStillToValidate.stream()\n                    .map(topic -> new ConfigResource(Type.TOPIC, topic))\n                    .collect(Collectors.toSet())\n            );\n            configsForTopic = describeConfigsResult.values().entrySet().stream()\n                .collect(Collectors.toMap(entry -> entry.getKey().name(), Map.Entry::getValue));\n        }\n\n        while (!descriptionsForTopic.isEmpty() || !configsForTopic.isEmpty()) {\n            if (!descriptionsForTopic.isEmpty()) {\n                doValidateTopic(\n                    validationResult,\n                    descriptionsForTopic,\n                    topicConfigs,\n                    topicDescriptionsStillToValidate,\n                    (streamsSide, brokerSide) -> validatePartitionCount(validationResult, streamsSide, brokerSide)\n                );\n            }\n            if (!configsForTopic.isEmpty()) {\n                doValidateTopic(\n                    validationResult,\n                    configsForTopic,\n                    topicConfigs,\n                    topicConfigsStillToValidate,\n                    (streamsSide, brokerSide) -> validateCleanupPolicy(validationResult, streamsSide, brokerSide)\n                );\n            }\n\n            maybeThrowTimeoutException(\n                Arrays.asList(topicDescriptionsStillToValidate, topicConfigsStillToValidate),\n                deadline,\n                String.format(\"Could not validate internal topics within %d milliseconds. \" +\n                    \"This can happen if the Kafka cluster is temporarily not available.\", retryTimeoutMs)\n            );\n\n            if (!descriptionsForTopic.isEmpty() || !configsForTopic.isEmpty()) {\n                Utils.sleep(100);\n            }\n        }\n\n        maybeSleep(\n            Arrays.asList(topicDescriptionsStillToValidate, topicConfigsStillToValidate),\n            deadline,\n            \"validated\"\n        );\n    }\n\n    log.info(\"Completed validation of internal topics {}.\", topicConfigs.keySet());\n    return validationResult;\n}", "summary_tokens": ["validates", "the", "internal", "topics", "passed"], "project": "kafka"}
{"id": 1141, "code": "public boolean loginRefreshReloginAllowedBeforeLogout() {\n    return loginRefreshReloginAllowedBeforeLogout;\n}", "summary_tokens": ["if", "the", "login", "module", "and", "sasl", "client", "implementations", "support", "multiple", "simultaneous", "login", "contexts", "on", "a", "single", "subject", "at", "the", "same", "time"], "project": "kafka"}
{"id": 3117, "code": "public void finalResultsWithZeroGraceShouldStillBufferUntilTheWindowEnd() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(finalResults(ofMillis(0L)), timeWindowedSerdeFrom(String.class, 100L), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n        \n        \n    final long timestamp = 5L;\n    final long windowEnd = 100L;\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    final Windowed<String> key = new Windowed<>(\"hey\", new TimeWindow(0, windowEnd));\n    final Change<Long> value = ARBITRARY_CHANGE;\n    harness.processor.process(new Record<>(key, value, timestamp));\n    assertThat(context.forwarded(), hasSize(0));\n\n    context.setRecordMetadata(\"\", 0, 1L);\n    context.setTimestamp(windowEnd);\n    harness.processor.process(new Record<>(new Windowed<>(\"dummyKey\", new TimeWindow(windowEnd, windowEnd + 100L)), ARBITRARY_CHANGE, windowEnd));\n\n    assertThat(context.forwarded(), hasSize(1));\n    final MockProcessorContext.CapturedForward capturedForward = context.forwarded().get(0);\n    assertThat(capturedForward.record(), is(new Record<>(key, value, timestamp)));\n}", "summary_tokens": ["testing", "a", "special", "case", "of", "final", "results", "that", "even", "with", "a", "grace", "period", "of", "0", "it", "will", "still", "buffer", "events", "and", "emit", "only", "after", "the", "end", "of", "the", "window"], "project": "kafka"}
{"id": 13, "code": "public long pollDelayMs(String id, long now) {\n    long throttleDelayMs = throttleDelayMs(id, now);\n    if (isConnected(id) && throttleDelayMs > 0) {\n        return throttleDelayMs;\n    } else {\n        return connectionDelay(id, now);\n    }\n}", "summary_tokens": ["return", "the", "number", "of", "milliseconds", "to", "wait", "based", "on", "the", "connection", "state", "and", "the", "throttle", "time", "before", "attempting", "to", "send", "data"], "project": "kafka"}
{"id": 22, "code": "private void resetReconnectBackoff(NodeConnectionState nodeState) {\n    nodeState.failedAttempts = 0;\n    nodeState.reconnectBackoffMs = reconnectBackoff.backoff(0);\n}", "summary_tokens": ["resets", "the", "failure", "count", "for", "a", "node", "and", "sets", "the", "reconnect", "backoff", "to", "the", "base", "value", "configured", "via", "reconnect"], "project": "kafka"}
{"id": 1030, "code": "private static MemoryRecordsBuilder convertRecordBatch(byte magic, ByteBuffer buffer, RecordBatchAndRecords recordBatchAndRecords) {\n    RecordBatch batch = recordBatchAndRecords.batch;\n    final TimestampType timestampType = batch.timestampType();\n    long logAppendTime = timestampType == TimestampType.LOG_APPEND_TIME ? batch.maxTimestamp() : RecordBatch.NO_TIMESTAMP;\n\n    MemoryRecordsBuilder builder = MemoryRecords.builder(buffer, magic, batch.compressionType(),\n            timestampType, recordBatchAndRecords.baseOffset, logAppendTime);\n    for (Record record : recordBatchAndRecords.records) {\n            \n        if (magic > RecordBatch.MAGIC_VALUE_V1)\n            builder.append(record);\n        else\n            builder.appendWithOffset(record.offset(), record.timestamp(), record.key(), record.value());\n    }\n\n    builder.close();\n    return builder;\n}", "summary_tokens": ["return", "a", "buffer", "containing", "the", "converted", "record", "batches"], "project": "kafka"}
{"id": 1939, "code": "public boolean pendingFencing(String connectorName) {\n    return connectorsPendingFencing.contains(connectorName);\n}", "summary_tokens": ["get", "whether", "the", "connector", "requires", "a", "round", "of", "zombie", "fencing", "before", "a", "new", "generation", "of", "tasks", "can", "be", "brought", "up", "for", "it"], "project": "kafka"}
{"id": 1362, "code": "private byte[] bytesWithPoorCompression(Random random, int size) {\n    byte[] value = new byte[size];\n    random.nextBytes(value);\n    return value;\n}", "summary_tokens": ["generates", "the", "compression", "ratio", "at", "about", "0"], "project": "kafka"}
{"id": 1925, "code": "protected static void configureSslContextFactoryKeyStore(SslContextFactory ssl, Map<String, Object> sslConfigValues) {\n    ssl.setKeyStoreType((String) getOrDefault(sslConfigValues, SslConfigs.SSL_KEYSTORE_TYPE_CONFIG, SslConfigs.DEFAULT_SSL_KEYSTORE_TYPE));\n\n    String sslKeystoreLocation = (String) sslConfigValues.get(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG);\n    if (sslKeystoreLocation != null)\n        ssl.setKeyStorePath(sslKeystoreLocation);\n\n    Password sslKeystorePassword = (Password) sslConfigValues.get(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG);\n    if (sslKeystorePassword != null)\n        ssl.setKeyStorePassword(sslKeystorePassword.value());\n\n    Password sslKeyPassword = (Password) sslConfigValues.get(SslConfigs.SSL_KEY_PASSWORD_CONFIG);\n    if (sslKeyPassword != null)\n        ssl.setKeyManagerPassword(sslKeyPassword.value());\n}", "summary_tokens": ["configures", "key", "store", "related", "settings", "in", "ssl", "context", "factory"], "project": "kafka"}
{"id": 2350, "code": "public Set<Integer> unrecordedVoters() {\n    return votersInState(State.UNRECORDED);\n}", "summary_tokens": ["get", "the", "set", "of", "voters", "which", "have", "not", "been", "counted", "as", "granted", "or", "rejected", "yet"], "project": "kafka"}
{"id": 52, "code": "public synchronized Cluster fetch() {\n    return cache.cluster();\n}", "summary_tokens": ["get", "the", "current", "cluster", "info", "without", "blocking"], "project": "kafka"}
{"id": 2400, "code": "private void initializeSnapshotWithHeader() {\n    if (snapshot.sizeInBytes() != 0) {\n        String message = String.format(\n            \"Initializing writer with a non-empty snapshot: id = '%s'.\",\n            snapshot.snapshotId()\n        );\n        throw new IllegalStateException(message);\n    }\n\n    SnapshotHeaderRecord headerRecord = new SnapshotHeaderRecord()\n        .setVersion(ControlRecordUtils.SNAPSHOT_HEADER_CURRENT_VERSION)\n        .setLastContainedLogTimestamp(lastContainedLogTimestamp);\n    accumulator.appendSnapshotHeaderRecord(headerRecord, time.milliseconds());\n    accumulator.forceDrain();\n}", "summary_tokens": ["adds", "a", "snapshot", "header", "record", "to", "snapshot"], "project": "kafka"}
{"id": 3244, "code": "void removeFault(String mountPath, KiboshFaultSpec spec) throws IOException {\n    KiboshProcess process = findProcessObject(mountPath);\n    process.removeFault(spec);\n}", "summary_tokens": ["remove", "a", "kibosh", "fault"], "project": "kafka"}
{"id": 215, "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["return", "a", "future", "which", "succeeds", "only", "if", "all", "the", "records", "deletions", "succeed"], "project": "kafka"}
{"id": 903, "code": "protected Runnable delegatedTask() {\n    return sslEngine.getDelegatedTask();\n}", "summary_tokens": ["returns", "delegated", "task", "for", "the", "sslengine"], "project": "kafka"}
{"id": 960, "code": "public static void removeEstimation(String topic) {\n    COMPRESSION_RATIO.remove(topic);\n}", "summary_tokens": ["remove", "the", "compression", "ratio", "estimation", "for", "a", "topic"], "project": "kafka"}
{"id": 554, "code": "public synchronized List<Map<String, Map<TopicPartition, OffsetAndMetadata>>> consumerGroupOffsetsHistory() {\n    return new ArrayList<>(this.consumerGroupOffsets);\n}", "summary_tokens": ["get", "the", "list", "of", "committed", "consumer", "group", "offsets", "since", "the", "last", "call", "to", "clear"], "project": "kafka"}
{"id": 2266, "code": "public static ConfigEntry.ConfigType translateConfigType(ConfigDef.Type type) {\n    switch (type) {\n        case BOOLEAN:\n            return ConfigEntry.ConfigType.BOOLEAN;\n        case STRING:\n            return ConfigEntry.ConfigType.STRING;\n        case INT:\n            return ConfigEntry.ConfigType.INT;\n        case SHORT:\n            return ConfigEntry.ConfigType.SHORT;\n        case LONG:\n            return ConfigEntry.ConfigType.LONG;\n        case DOUBLE:\n            return ConfigEntry.ConfigType.DOUBLE;\n        case LIST:\n            return ConfigEntry.ConfigType.LIST;\n        case CLASS:\n            return ConfigEntry.ConfigType.CLASS;\n        case PASSWORD:\n            return ConfigEntry.ConfigType.PASSWORD;\n        default:\n            return ConfigEntry.ConfigType.UNKNOWN;\n    }\n}", "summary_tokens": ["translate", "a", "config", "def"], "project": "kafka"}
{"id": 981, "code": "public TimestampAndOffset largestTimestampAfter(int startingPosition) {\n    long maxTimestamp = RecordBatch.NO_TIMESTAMP;\n    long offsetOfMaxTimestamp = -1L;\n    int leaderEpochOfMaxTimestamp = RecordBatch.NO_PARTITION_LEADER_EPOCH;\n\n    for (RecordBatch batch : batchesFrom(startingPosition)) {\n        long timestamp = batch.maxTimestamp();\n        if (timestamp > maxTimestamp) {\n            maxTimestamp = timestamp;\n            offsetOfMaxTimestamp = batch.lastOffset();\n            leaderEpochOfMaxTimestamp = batch.partitionLeaderEpoch();\n        }\n    }\n    return new TimestampAndOffset(maxTimestamp, offsetOfMaxTimestamp,\n            maybeLeaderEpoch(leaderEpochOfMaxTimestamp));\n}", "summary_tokens": ["return", "the", "largest", "timestamp", "of", "the", "messages", "after", "a", "given", "position", "in", "this", "file", "message", "set"], "project": "kafka"}
{"id": 528, "code": "synchronized int numAssignedPartitions() {\n    return this.assignment.size();\n}", "summary_tokens": ["provides", "the", "number", "of", "assigned", "partitions", "in", "a", "thread", "safe", "manner"], "project": "kafka"}
{"id": 329, "code": "public static OffsetSpec forTimestamp(long timestamp) {\n    return new TimestampSpec(timestamp);\n}", "summary_tokens": ["used", "to", "retrieve", "the", "earliest", "offset", "whose", "timestamp", "is", "greater", "than", "or", "equal", "to", "the", "given", "timestamp", "in", "the", "corresponding", "partition", "timestamp", "in", "milliseconds"], "project": "kafka"}
{"id": 1544, "code": "public void testRepeatedValidSaslPlainOverSsl() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n        \n    saslServerConfigs.put(BrokerSecurityConfigs.CONNECTIONS_MAX_REAUTH_MS,\n            Double.valueOf(1.1 * 1000L / 0.85).longValue());\n\n    server = createEchoServer(securityProtocol);\n    createClientConnection(securityProtocol, node);\n    checkClientConnection(node);\n    server.verifyAuthenticationMetrics(1, 0);\n    server.verifyReauthenticationMetrics(0, 0);\n    double successfulReauthentications = 0;\n    int desiredNumReauthentications = 5;\n    long startMs = Time.SYSTEM.milliseconds();\n    long timeoutMs = startMs + 1000 * 15; \n    while (successfulReauthentications < desiredNumReauthentications\n            && Time.SYSTEM.milliseconds() < timeoutMs) {\n        checkClientConnection(node);\n        successfulReauthentications = server.metricValue(\"successful-reauthentication-total\");\n    }\n    server.verifyReauthenticationMetrics(desiredNumReauthentications, 0);\n}", "summary_tokens": ["tests", "good", "path", "sasl", "plain", "client", "and", "server", "channels", "using", "ssl", "transport", "layer"], "project": "kafka"}
{"id": 2883, "code": "public boolean hasNoLocalTopology() {\n    return evaluateConditionIsTrueForAnyBuilders(InternalTopologyBuilder::hasNoLocalTopology);\n}", "summary_tokens": ["true", "iff", "any", "of", "the", "topologies", "have", "no", "local", "aka", "non", "global", "topology"], "project": "kafka"}
{"id": 2518, "code": "public synchronized <K, V> KTable<K, V> table(final String topic,\n                                              final Materialized<K, V, KeyValueStore<Bytes, byte[]>> materialized) {\n    Objects.requireNonNull(topic, \"topic can't be null\");\n    Objects.requireNonNull(materialized, \"materialized can't be null\");\n\n    final MaterializedInternal<K, V, KeyValueStore<Bytes, byte[]>> materializedInternal =\n        new MaterializedInternal<>(materialized, internalStreamsBuilder, topic + \"-\");\n\n    final ConsumedInternal<K, V> consumedInternal =\n            new ConsumedInternal<>(Consumed.with(materializedInternal.keySerde(), materializedInternal.valueSerde()));\n\n    return internalStreamsBuilder.table(topic, consumedInternal, materializedInternal);\n}", "summary_tokens": ["create", "a", "ktable", "for", "the", "specified", "topic"], "project": "kafka"}
{"id": 722, "code": "public boolean matchesAtMostOne() {\n    return findIndefiniteField() == null;\n}", "summary_tokens": ["returns", "true", "if", "this", "filter", "could", "only", "match", "one", "ace", "in", "other", "words", "if", "there", "are", "no", "any", "or", "unknown", "fields"], "project": "kafka"}
{"id": 2694, "code": "public static To all() {\n    return new To(null, -1);\n}", "summary_tokens": ["forward", "the", "key", "value", "pair", "to", "all", "downstream", "processors", "a", "new", "to", "instance", "configured", "for", "all", "downstream", "processor"], "project": "kafka"}
{"id": 2514, "code": "public QueryableStoreType<T> queryableStoreType() {\n    return queryableStoreType;\n}", "summary_tokens": ["get", "the", "queryable", "store", "type", "for", "which", "key", "is", "queried", "by", "the", "user"], "project": "kafka"}
{"id": 1145, "code": "public static boolean isValidScopeItem(String scopeItem) {\n    return INDIVIDUAL_SCOPE_ITEM_PATTERN.matcher(Objects.requireNonNull(scopeItem)).matches();\n}", "summary_tokens": ["return", "true", "if", "the", "given", "value", "meets", "the", "definition", "of", "a", "valid", "scope", "item", "as", "per", "a", "href", "https", "tools"], "project": "kafka"}
{"id": 56, "code": "public synchronized boolean updateLastSeenEpochIfNewer(TopicPartition topicPartition, int leaderEpoch) {\n    Objects.requireNonNull(topicPartition, \"TopicPartition cannot be null\");\n    if (leaderEpoch < 0)\n        throw new IllegalArgumentException(\"Invalid leader epoch \" + leaderEpoch + \" (must be non-negative)\");\n\n    Integer oldEpoch = lastSeenLeaderEpochs.get(topicPartition);\n    log.trace(\"Determining if we should replace existing epoch {} with new epoch {} for partition {}\", oldEpoch, leaderEpoch, topicPartition);\n\n    final boolean updated;\n    if (oldEpoch == null) {\n        log.debug(\"Not replacing null epoch with new epoch {} for partition {}\", leaderEpoch, topicPartition);\n        updated = false;\n    } else if (leaderEpoch > oldEpoch) {\n        log.debug(\"Updating last seen epoch from {} to {} for partition {}\", oldEpoch, leaderEpoch, topicPartition);\n        lastSeenLeaderEpochs.put(topicPartition, leaderEpoch);\n        updated = true;\n    } else {\n        log.debug(\"Not replacing existing epoch {} with new epoch {} for partition {}\", oldEpoch, leaderEpoch, topicPartition);\n        updated = false;\n    }\n\n    this.needFullUpdate = this.needFullUpdate || updated;\n    return updated;\n}", "summary_tokens": ["request", "an", "update", "for", "the", "partition", "metadata", "iff", "we", "have", "seen", "a", "newer", "leader", "epoch"], "project": "kafka"}
{"id": 341, "code": "public boolean isFuture() {\n    return isFuture;\n}", "summary_tokens": ["whether", "this", "replica", "has", "been", "created", "by", "a", "alter", "replica", "log", "dirs", "request", "but", "not", "yet", "replaced", "the", "current", "replica", "on", "the", "broker"], "project": "kafka"}
{"id": 3022, "code": "public static SessionBytesStoreSupplier persistentSessionStore(final String name,\n                                                               final Duration retentionPeriod) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(retentionPeriod, \"retentionPeriod\");\n    final long retentionPeriodMs = validateMillisecondDuration(retentionPeriod, msgPrefix);\n    if (retentionPeriodMs < 0) {\n        throw new IllegalArgumentException(\"retentionPeriod cannot be negative\");\n    }\n    return new RocksDbSessionBytesStoreSupplier(name, retentionPeriodMs);\n}", "summary_tokens": ["create", "a", "persistent", "session", "bytes", "store", "supplier"], "project": "kafka"}
{"id": 2824, "code": "public void setStreamsUncaughtExceptionHandler(final BiConsumer<Throwable, Boolean> streamsUncaughtExceptionHandler) {\n    this.streamsUncaughtExceptionHandler = streamsUncaughtExceptionHandler;\n}", "summary_tokens": ["sets", "the", "streams", "uncaught", "exception", "handler"], "project": "kafka"}
{"id": 3072, "code": "private static boolean verifyEquivalentMetadataForHost(final StreamsMetadataImpl left, final StreamsMetadataImpl right) {\n    return left.hostInfo().equals(right.hostInfo())\n        && left.stateStoreNames().equals(right.stateStoreNames())\n        && left.topicPartitions().equals(right.topicPartitions())\n        && left.standbyStateStoreNames().equals(right.standbyStateStoreNames())\n        && left.standbyTopicPartitions().equals(right.standbyTopicPartitions());\n}", "summary_tokens": ["true", "iff", "all", "fields", "other", "than", "streams", "metadata", "impl", "topology", "name", "match", "between", "the", "two", "streams", "metadata", "objects"], "project": "kafka"}
{"id": 777, "code": "public ConfigTransformerResult transform(Map<String, String> configs) {\n    Map<String, Map<String, Set<String>>> keysByProvider = new HashMap<>();\n    Map<String, Map<String, Map<String, String>>> lookupsByProvider = new HashMap<>();\n\n        \n    for (Map.Entry<String, String> config : configs.entrySet()) {\n        if (config.getValue() != null) {\n            List<ConfigVariable> vars = getVars(config.getValue(), DEFAULT_PATTERN);\n            for (ConfigVariable var : vars) {\n                Map<String, Set<String>> keysByPath = keysByProvider.computeIfAbsent(var.providerName, k -> new HashMap<>());\n                Set<String> keys = keysByPath.computeIfAbsent(var.path, k -> new HashSet<>());\n                keys.add(var.variable);\n            }\n        }\n    }\n\n        \n    Map<String, Long> ttls = new HashMap<>();\n    for (Map.Entry<String, Map<String, Set<String>>> entry : keysByProvider.entrySet()) {\n        String providerName = entry.getKey();\n        ConfigProvider provider = configProviders.get(providerName);\n        Map<String, Set<String>> keysByPath = entry.getValue();\n        if (provider != null && keysByPath != null) {\n            for (Map.Entry<String, Set<String>> pathWithKeys : keysByPath.entrySet()) {\n                String path = pathWithKeys.getKey();\n                Set<String> keys = new HashSet<>(pathWithKeys.getValue());\n                ConfigData configData = provider.get(path, keys);\n                Map<String, String> data = configData.data();\n                Long ttl = configData.ttl();\n                if (ttl != null && ttl >= 0) {\n                    ttls.put(path, ttl);\n                }\n                Map<String, Map<String, String>> keyValuesByPath =\n                        lookupsByProvider.computeIfAbsent(providerName, k -> new HashMap<>());\n                keyValuesByPath.put(path, data);\n            }\n        }\n    }\n\n        \n    Map<String, String> data = new HashMap<>(configs);\n    for (Map.Entry<String, String> config : configs.entrySet()) {\n        data.put(config.getKey(), replace(lookupsByProvider, config.getValue(), DEFAULT_PATTERN));\n    }\n    return new ConfigTransformerResult(data, ttls);\n}", "summary_tokens": ["transforms", "the", "given", "configuration", "data", "by", "using", "the", "config", "provider", "instances", "to", "look", "up", "values", "to", "replace", "the", "variables", "in", "the", "pattern"], "project": "kafka"}
{"id": 1473, "code": "public void testChecksum(Args args) {\n    CompressionType compression = args.compression;\n    byte magic = args.magic;\n        \n    if (compression != CompressionType.NONE && compression != CompressionType.LZ4)\n        return;\n\n    SimpleRecord[] records = {\n        new SimpleRecord(283843L, \"key1\".getBytes(), \"value1\".getBytes()),\n        new SimpleRecord(1234L, \"key2\".getBytes(), \"value2\".getBytes())\n    };\n    RecordBatch batch = MemoryRecords.withRecords(magic, compression, records).batches().iterator().next();\n    long expectedChecksum;\n    if (magic == RecordBatch.MAGIC_VALUE_V0) {\n        if (compression == CompressionType.NONE)\n            expectedChecksum = 1978725405L;\n        else\n            expectedChecksum = 66944826L;\n    } else if (magic == RecordBatch.MAGIC_VALUE_V1) {\n        if (compression == CompressionType.NONE)\n            expectedChecksum = 109425508L;\n        else\n            expectedChecksum = 1407303399L;\n    } else {\n        if (compression == CompressionType.NONE)\n            expectedChecksum = 3851219455L;\n        else\n            expectedChecksum = 2745969314L;\n    }\n    assertEquals(expectedChecksum, batch.checksum(), \"Unexpected checksum for magic \" + magic +\n        \" and compression type \" + compression);\n}", "summary_tokens": ["this", "test", "verifies", "that", "the", "checksum", "returned", "for", "various", "versions", "matches", "hardcoded", "values", "to", "catch", "unintentional", "changes", "to", "how", "the", "checksum", "is", "computed"], "project": "kafka"}
{"id": 756, "code": "public ConfigDef defineInternal(final String name, final Type type, final Object defaultValue, final Validator validator, final Importance importance, final String documentation) {\n    return define(new ConfigKey(name, type, defaultValue, validator, importance, documentation, \"\", -1, Width.NONE, name, Collections.<String>emptyList(), null, true));\n}", "summary_tokens": ["define", "a", "new", "internal", "configuration"], "project": "kafka"}
{"id": 1285, "code": "public static String jmxSanitize(String name) {\n    return MBEAN_PATTERN.matcher(name).matches() ? name : ObjectName.quote(name);\n}", "summary_tokens": ["quote", "name", "using", "object", "name", "quote", "string", "if", "name", "contains", "characters", "that", "are", "not", "safe", "for", "use", "in", "jmx"], "project": "kafka"}
{"id": 1653, "code": "private void checkSchemaType(Schema schema, Type type) {\n    if (schema.type() != type) {\n        throw new DataException(\"Expecting \" + type + \" but instead found \" + schema.type());\n    }\n}", "summary_tokens": ["check", "the", "schema", "type", "schema", "s", "type", "matches", "the", "specified", "type"], "project": "kafka"}
{"id": 2375, "code": "public void acknowledgeResignation(int voterId) {\n    if (!voters.contains(voterId)) {\n        throw new IllegalArgumentException(\"Attempt to acknowledge delivery of `EndQuorumEpoch` \" +\n            \"by a non-voter \" + voterId);\n    }\n    unackedVoters.remove(voterId);\n}", "summary_tokens": ["invoked", "after", "receiving", "a", "successful", "end", "quorum", "epoch", "response"], "project": "kafka"}
{"id": 1101, "code": "public static KerberosName parse(String principalName) {\n    Matcher match = NAME_PARSER.matcher(principalName);\n    if (!match.matches()) {\n        if (principalName.contains(\"@\")) {\n            throw new IllegalArgumentException(\"Malformed Kerberos name: \" + principalName);\n        } else {\n            return new KerberosName(principalName, null, null);\n        }\n    } else {\n        return new KerberosName(match.group(1), match.group(3), match.group(4));\n    }\n}", "summary_tokens": ["create", "a", "name", "from", "the", "full", "kerberos", "principal", "name"], "project": "kafka"}
{"id": 2323, "code": "public void testStartWithEarlyStartListeners() throws Exception {\n    StandardAuthorizer authorizer = new StandardAuthorizer();\n    authorizer.configure(Collections.singletonMap(SUPER_USERS_CONFIG, \"User:superman\"));\n    Map<Endpoint, ? extends CompletionStage<Void>> futures2 = authorizer.\n        start(new AuthorizerTestServerInfo(Arrays.asList(PLAINTEXT, CONTROLLER)));\n    assertEquals(new HashSet<>(Arrays.asList(PLAINTEXT, CONTROLLER)), futures2.keySet());\n    assertFalse(futures2.get(PLAINTEXT).toCompletableFuture().isDone());\n    assertTrue(futures2.get(CONTROLLER).toCompletableFuture().isDone());\n}", "summary_tokens": ["test", "that", "standard", "authorizer", "start", "returns", "a", "completed", "future", "for", "early", "start", "listeners"], "project": "kafka"}
{"id": 1697, "code": "private JsonNode convertToJson(Schema schema, Object value) {\n    if (value == null) {\n        if (schema == null) \n            return null;\n        if (schema.defaultValue() != null)\n            return convertToJson(schema, schema.defaultValue());\n        if (schema.isOptional())\n            return JSON_NODE_FACTORY.nullNode();\n        throw new DataException(\"Conversion error: null value for field that is required and has no default value\");\n    }\n\n    if (schema != null && schema.name() != null) {\n        LogicalTypeConverter logicalConverter = LOGICAL_CONVERTERS.get(schema.name());\n        if (logicalConverter != null)\n            return logicalConverter.toJson(schema, value, config);\n    }\n\n    try {\n        final Schema.Type schemaType;\n        if (schema == null) {\n            schemaType = ConnectSchema.schemaType(value.getClass());\n            if (schemaType == null)\n                throw new DataException(\"Java class \" + value.getClass() + \" does not have corresponding schema type.\");\n        } else {\n            schemaType = schema.type();\n        }\n        switch (schemaType) {\n            case INT8:\n                return JSON_NODE_FACTORY.numberNode((Byte) value);\n            case INT16:\n                return JSON_NODE_FACTORY.numberNode((Short) value);\n            case INT32:\n                return JSON_NODE_FACTORY.numberNode((Integer) value);\n            case INT64:\n                return JSON_NODE_FACTORY.numberNode((Long) value);\n            case FLOAT32:\n                return JSON_NODE_FACTORY.numberNode((Float) value);\n            case FLOAT64:\n                return JSON_NODE_FACTORY.numberNode((Double) value);\n            case BOOLEAN:\n                return JSON_NODE_FACTORY.booleanNode((Boolean) value);\n            case STRING:\n                CharSequence charSeq = (CharSequence) value;\n                return JSON_NODE_FACTORY.textNode(charSeq.toString());\n            case BYTES:\n                if (value instanceof byte[])\n                    return JSON_NODE_FACTORY.binaryNode((byte[]) value);\n                else if (value instanceof ByteBuffer)\n                    return JSON_NODE_FACTORY.binaryNode(((ByteBuffer) value).array());\n                else\n                    throw new DataException(\"Invalid type for bytes type: \" + value.getClass());\n            case ARRAY: {\n                Collection<?> collection = (Collection<?>) value;\n                ArrayNode list = JSON_NODE_FACTORY.arrayNode();\n                for (Object elem : collection) {\n                    Schema valueSchema = schema == null ? null : schema.valueSchema();\n                    JsonNode fieldValue = convertToJson(valueSchema, elem);\n                    list.add(fieldValue);\n                }\n                return list;\n            }\n            case MAP: {\n                Map<?, ?> map = (Map<?, ?>) value;\n                    \n                boolean objectMode;\n                if (schema == null) {\n                    objectMode = true;\n                    for (Map.Entry<?, ?> entry : map.entrySet()) {\n                        if (!(entry.getKey() instanceof String)) {\n                            objectMode = false;\n                            break;\n                        }\n                    }\n                } else {\n                    objectMode = schema.keySchema().type() == Schema.Type.STRING;\n                }\n                ObjectNode obj = null;\n                ArrayNode list = null;\n                if (objectMode)\n                    obj = JSON_NODE_FACTORY.objectNode();\n                else\n                    list = JSON_NODE_FACTORY.arrayNode();\n                for (Map.Entry<?, ?> entry : map.entrySet()) {\n                    Schema keySchema = schema == null ? null : schema.keySchema();\n                    Schema valueSchema = schema == null ? null : schema.valueSchema();\n                    JsonNode mapKey = convertToJson(keySchema, entry.getKey());\n                    JsonNode mapValue = convertToJson(valueSchema, entry.getValue());\n\n                    if (objectMode)\n                        obj.set(mapKey.asText(), mapValue);\n                    else\n                        list.add(JSON_NODE_FACTORY.arrayNode().add(mapKey).add(mapValue));\n                }\n                return objectMode ? obj : list;\n            }\n            case STRUCT: {\n                Struct struct = (Struct) value;\n                if (!struct.schema().equals(schema))\n                    throw new DataException(\"Mismatching schema.\");\n                ObjectNode obj = JSON_NODE_FACTORY.objectNode();\n                for (Field field : schema.fields()) {\n                    obj.set(field.name(), convertToJson(field.schema(), struct.get(field)));\n                }\n                return obj;\n            }\n        }\n\n        throw new DataException(\"Couldn't convert \" + value + \" to JSON.\");\n    } catch (ClassCastException e) {\n        String schemaTypeStr = (schema != null) ? schema.type().toString() : \"unknown schema\";\n        throw new DataException(\"Invalid type for \" + schemaTypeStr + \": \" + value.getClass());\n    }\n}", "summary_tokens": ["convert", "this", "object", "in", "the", "org"], "project": "kafka"}
{"id": 2611, "code": "public static <K, V> Produced<K, V> valueSerde(final Serde<V> valueSerde) {\n    return new Produced<>(null, valueSerde, null, null);\n}", "summary_tokens": ["create", "a", "produced", "instance", "with", "provided", "value", "serde"], "project": "kafka"}
{"id": 1183, "code": "public static String validateSubject(String claimName, String claimValue) throws ValidateException {\n    return validateString(claimName, claimValue);\n}", "summary_tokens": ["validates", "that", "the", "given", "claim", "value", "is", "valid", "where", "i", "invalid", "i", "means", "i", "any", "i", "of", "the", "following"], "project": "kafka"}
{"id": 366, "code": "public void transitionToUpdatePending(long now) {\n    this.state = State.UPDATE_PENDING;\n    this.lastMetadataFetchAttemptMs = now;\n}", "summary_tokens": ["transition", "into", "the", "update", "pending", "state"], "project": "kafka"}
{"id": 1574, "code": "public static void isValidClusterId(String clusterId) {\n    assertNotNull(clusterId);\n\n        \n    assertEquals(clusterId.length(), 22);\n\n    Pattern clusterIdPattern = Pattern.compile(\"[a-zA-Z0-9_\\\\-]+\");\n    Matcher matcher = clusterIdPattern.matcher(clusterId);\n    assertTrue(matcher.matches());\n\n        \n    String originalClusterId = String.format(\"%s==\", clusterId.replace(\"_\", \"/\").replace(\"-\", \"+\"));\n    byte[] decodedUuid = Base64.getDecoder().decode(originalClusterId);\n\n        \n    assertEquals(decodedUuid.length, 16);\n\n        \n    try {\n        ByteBuffer uuidBuffer = ByteBuffer.wrap(decodedUuid);\n        new UUID(uuidBuffer.getLong(), uuidBuffer.getLong()).toString();\n    } catch (Exception e) {\n        fail(clusterId + \" cannot be converted back to UUID.\");\n    }\n}", "summary_tokens": ["checks", "if", "a", "cluster", "id", "is", "valid"], "project": "kafka"}
{"id": 1229, "code": "static public Serde<UUID> UUID() {\n    return new UUIDSerde();\n}", "summary_tokens": ["a", "serde", "for", "nullable", "uuid", "type"], "project": "kafka"}
{"id": 2020, "code": "public String name() {\n    return connectorName;\n}", "summary_tokens": ["get", "the", "connector", "s", "name", "corresponding", "to", "this", "handle"], "project": "kafka"}
{"id": 2544, "code": "public synchronized <KIn, VIn, KOut, VOut> Topology addProcessor(final String name,\n                                                                 final ProcessorSupplier<KIn, VIn, KOut, VOut> supplier,\n                                                                 final String... parentNames) {\n    internalTopologyBuilder.addProcessor(name, supplier, parentNames);\n    final Set<StoreBuilder<?>> stores = supplier.stores();\n    if (stores != null) {\n        for (final StoreBuilder storeBuilder : stores) {\n            internalTopologyBuilder.addStateStore(storeBuilder, name);\n        }\n    }\n    return this;\n}", "summary_tokens": ["add", "a", "new", "processor", "node", "that", "receives", "and", "processes", "records", "output", "by", "one", "or", "more", "parent", "source", "or", "processor", "node"], "project": "kafka"}
{"id": 2217, "code": "long nextCheckTimeNs() {\n    BrokerHeartbeatState broker = unfenced.first();\n    if (broker == null) {\n        return Long.MAX_VALUE;\n    } else {\n        return broker.lastContactNs + sessionTimeoutNs;\n    }\n}", "summary_tokens": ["return", "the", "time", "in", "monotonic", "nanoseconds", "at", "which", "we", "should", "check", "if", "a", "broker", "session", "needs", "to", "be", "expired"], "project": "kafka"}
{"id": 1217, "code": "default T deserialize(String topic, Headers headers, byte[] data) {\n    return deserialize(topic, data);\n}", "summary_tokens": ["deserialize", "a", "record", "value", "from", "a", "byte", "array", "into", "a", "value", "or", "object"], "project": "kafka"}
{"id": 463, "code": "RequestFuture<Void> sendOffsetCommitRequest(final Map<TopicPartition, OffsetAndMetadata> offsets) {\n    if (offsets.isEmpty())\n        return RequestFuture.voidSuccess();\n\n    Node coordinator = checkAndGetCoordinator();\n    if (coordinator == null)\n        return RequestFuture.coordinatorNotAvailable();\n\n        \n    Map<String, OffsetCommitRequestData.OffsetCommitRequestTopic> requestTopicDataMap = new HashMap<>();\n    for (Map.Entry<TopicPartition, OffsetAndMetadata> entry : offsets.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        OffsetAndMetadata offsetAndMetadata = entry.getValue();\n        if (offsetAndMetadata.offset() < 0) {\n            return RequestFuture.failure(new IllegalArgumentException(\"Invalid offset: \" + offsetAndMetadata.offset()));\n        }\n\n        OffsetCommitRequestData.OffsetCommitRequestTopic topic = requestTopicDataMap\n                .getOrDefault(topicPartition.topic(),\n                        new OffsetCommitRequestData.OffsetCommitRequestTopic()\n                                .setName(topicPartition.topic())\n                );\n\n        topic.partitions().add(new OffsetCommitRequestData.OffsetCommitRequestPartition()\n                .setPartitionIndex(topicPartition.partition())\n                .setCommittedOffset(offsetAndMetadata.offset())\n                .setCommittedLeaderEpoch(offsetAndMetadata.leaderEpoch().orElse(RecordBatch.NO_PARTITION_LEADER_EPOCH))\n                .setCommittedMetadata(offsetAndMetadata.metadata())\n        );\n        requestTopicDataMap.put(topicPartition.topic(), topic);\n    }\n\n    final Generation generation;\n    if (subscriptions.hasAutoAssignedPartitions()) {\n        generation = generationIfStable();\n            \n            \n        if (generation == null) {\n            log.info(\"Failing OffsetCommit request since the consumer is not part of an active group\");\n\n            if (rebalanceInProgress()) {\n                    \n                    \n                return RequestFuture.failure(new RebalanceInProgressException(\"Offset commit cannot be completed since the \" +\n                    \"consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance \" +\n                    \"by calling poll() and then retry the operation.\"));\n            } else {\n                return RequestFuture.failure(new CommitFailedException(\"Offset commit cannot be completed since the \" +\n                    \"consumer is not part of an active group for auto partition assignment; it is likely that the consumer \" +\n                    \"was kicked out of the group.\"));\n            }\n        }\n    } else {\n        generation = Generation.NO_GENERATION;\n    }\n\n    OffsetCommitRequest.Builder builder = new OffsetCommitRequest.Builder(\n            new OffsetCommitRequestData()\n                    .setGroupId(this.rebalanceConfig.groupId)\n                    .setGenerationId(generation.generationId)\n                    .setMemberId(generation.memberId)\n                    .setGroupInstanceId(rebalanceConfig.groupInstanceId.orElse(null))\n                    .setTopics(new ArrayList<>(requestTopicDataMap.values()))\n    );\n\n    log.trace(\"Sending OffsetCommit request with {} to coordinator {}\", offsets, coordinator);\n\n    return client.send(coordinator, builder)\n            .compose(new OffsetCommitResponseHandler(offsets, generation));\n}", "summary_tokens": ["commit", "offsets", "for", "the", "specified", "list", "of", "topics", "and", "partitions"], "project": "kafka"}
{"id": 635, "code": "public void awaitFlushCompletion() throws InterruptedException {\n    try {\n            \n            \n            \n            \n        for (ProduceRequestResult result : this.incomplete.requestResults())\n            result.await();\n    } finally {\n        this.flushesInProgress.decrementAndGet();\n    }\n}", "summary_tokens": ["mark", "all", "partitions", "as", "ready", "to", "send", "and", "block", "until", "the", "send", "is", "complete"], "project": "kafka"}
{"id": 955, "code": "public static int recordBatchHeaderSizeInBytes(byte magic, CompressionType compressionType) {\n    if (magic > RecordBatch.MAGIC_VALUE_V1) {\n        return DefaultRecordBatch.RECORD_BATCH_OVERHEAD;\n    } else if (compressionType != CompressionType.NONE) {\n        return Records.LOG_OVERHEAD + LegacyRecord.recordOverhead(magic);\n    } else {\n        return 0;\n    }\n}", "summary_tokens": ["return", "the", "size", "of", "the", "record", "batch", "header"], "project": "kafka"}
{"id": 99, "code": "private void initiateConnect(Node node, long now) {\n    String nodeConnectionId = node.idString();\n    try {\n        connectionStates.connecting(nodeConnectionId, now, node.host());\n        InetAddress address = connectionStates.currentAddress(nodeConnectionId);\n        log.debug(\"Initiating connection to node {} using address {}\", node, address);\n        selector.connect(nodeConnectionId,\n                new InetSocketAddress(address, node.port()),\n                this.socketSendBuffer,\n                this.socketReceiveBuffer);\n    } catch (IOException e) {\n        log.warn(\"Error connecting to node {}\", node, e);\n            \n        connectionStates.disconnected(nodeConnectionId, now);\n            \n        metadataUpdater.handleServerDisconnect(now, nodeConnectionId, Optional.empty());\n    }\n}", "summary_tokens": ["initiate", "a", "connection", "to", "the", "given", "node", "node", "the", "node", "to", "connect", "to", "now", "current", "time", "in", "epoch", "milliseconds"], "project": "kafka"}
{"id": 2381, "code": "public void appendLeaderChangeMessage(\n    LeaderChangeMessage leaderChangeMessage,\n    long currentTimestamp\n) {\n    appendControlMessage(buffer -> {\n        return MemoryRecords.withLeaderChangeMessage(\n            this.nextOffset,\n            currentTimestamp,\n            this.epoch,\n            buffer,\n            leaderChangeMessage\n        );\n    });\n}", "summary_tokens": ["append", "a", "leader", "change", "message", "record", "to", "the", "batch"], "project": "kafka"}
{"id": 999, "code": "public CompressionType compressionType() {\n    return CompressionType.forId(buffer.get(ATTRIBUTES_OFFSET) & COMPRESSION_CODEC_MASK);\n}", "summary_tokens": ["the", "compression", "type", "used", "with", "this", "record"], "project": "kafka"}
{"id": 1615, "code": "public Short getInt16(String fieldName) {\n    return (Short) getCheckType(fieldName, Schema.Type.INT16);\n}", "summary_tokens": ["equivalent", "to", "calling", "get", "string", "and", "casting", "the", "result", "to", "a", "short"], "project": "kafka"}
{"id": 2687, "code": "public void writeTo(final DataOutputStream out, final int version) throws IOException {\n    writeTaskIdTo(this, out, version);\n}", "summary_tokens": ["ioexception", "if", "cannot", "write", "to", "output", "stream", "since", "0"], "project": "kafka"}
{"id": 603, "code": "public void abort(RuntimeException exception) {\n    if (!finalState.compareAndSet(null, FinalState.ABORTED))\n        throw new IllegalStateException(\"Batch has already been completed in final state \" + finalState.get());\n\n    log.trace(\"Aborting batch for partition {}\", topicPartition, exception);\n    completeFutureAndFireCallbacks(ProduceResponse.INVALID_OFFSET, RecordBatch.NO_TIMESTAMP, index -> exception);\n}", "summary_tokens": ["abort", "the", "batch", "and", "complete", "the", "future", "and", "callbacks"], "project": "kafka"}
{"id": 151, "code": "public AlterClientQuotasOptions validateOnly(boolean validateOnly) {\n    this.validateOnly = validateOnly;\n    return this;\n}", "summary_tokens": ["sets", "whether", "the", "request", "should", "be", "validated", "without", "altering", "the", "configs"], "project": "kafka"}
{"id": 736, "code": "private void readBlock() throws IOException {\n    if (in.remaining() < 4) {\n        throw new IOException(PREMATURE_EOS);\n    }\n\n    int blockSize = in.getInt();\n    boolean compressed = (blockSize & LZ4_FRAME_INCOMPRESSIBLE_MASK) == 0;\n    blockSize &= ~LZ4_FRAME_INCOMPRESSIBLE_MASK;\n\n        \n    if (blockSize == 0) {\n        finished = true;\n        if (flg.isContentChecksumSet())\n            in.getInt(); \n        return;\n    } else if (blockSize > maxBlockSize) {\n        throw new IOException(String.format(\"Block size %d exceeded max: %d\", blockSize, maxBlockSize));\n    }\n\n    if (in.remaining() < blockSize) {\n        throw new IOException(PREMATURE_EOS);\n    }\n\n    if (compressed) {\n        try {\n            final int bufferSize = DECOMPRESSOR.decompress(in, in.position(), blockSize, decompressionBuffer, 0,\n                maxBlockSize);\n            decompressionBuffer.position(0);\n            decompressionBuffer.limit(bufferSize);\n            decompressedBuffer = decompressionBuffer;\n        } catch (LZ4Exception e) {\n            throw new IOException(e);\n        }\n    } else {\n        decompressedBuffer = in.slice();\n        decompressedBuffer.limit(blockSize);\n    }\n\n        \n    if (flg.isBlockChecksumSet()) {\n        int hash = CHECKSUM.hash(in, in.position(), blockSize, 0);\n        in.position(in.position() + blockSize);\n        if (hash != in.getInt()) {\n            throw new IOException(BLOCK_HASH_MISMATCH);\n        }\n    } else {\n        in.position(in.position() + blockSize);\n    }\n}", "summary_tokens": ["decompresses", "if", "necessary", "buffered", "data", "optionally", "computes", "and", "validates", "a", "xxhash", "0", "checksum", "and", "writes", "the", "result", "to", "a", "buffer"], "project": "kafka"}
{"id": 2144, "code": "protected Optional<Boolean> checkValidationErrors(String connectorClass, Map<String, String> connConfig,\n    int numErrors, BiFunction<Integer, Integer, Boolean> comp) {\n    try {\n        int numErrorsProduced = connect.validateConnectorConfig(connectorClass, connConfig).errorCount();\n        return Optional.of(comp.apply(numErrorsProduced, numErrors));\n    } catch (Exception e) {\n        log.error(\"Could not check config validation error count.\", e);\n        return Optional.empty();\n    }\n}", "summary_tokens": ["confirm", "that", "the", "requested", "number", "of", "errors", "are", "produced", "by", "embedded", "connect", "cluster", "validate", "connector", "config"], "project": "kafka"}
{"id": 1379, "code": "public void testConcurrentReadUpdate() throws Exception {\n    final Random random = new Random();\n    final Deque<Sensor> sensors = new ConcurrentLinkedDeque<>();\n    metrics = new Metrics(new MockTime(10));\n    SensorCreator sensorCreator = new SensorCreator(metrics);\n\n    final AtomicBoolean alive = new AtomicBoolean(true);\n    executorService = Executors.newSingleThreadExecutor();\n    executorService.submit(new ConcurrentMetricOperation(alive, \"record\",\n        () -> sensors.forEach(sensor -> sensor.record(random.nextInt(10000)))));\n\n    for (int i = 0; i < 10000; i++) {\n        if (sensors.size() > 5) {\n            Sensor sensor = random.nextBoolean() ? sensors.removeFirst() : sensors.removeLast();\n            metrics.removeSensor(sensor.name());\n        }\n        StatType statType = StatType.forId(random.nextInt(StatType.values().length));\n        sensors.add(sensorCreator.createSensor(statType, i));\n        for (Sensor sensor : sensors) {\n            for (KafkaMetric metric : sensor.metrics()) {\n                assertNotNull(metric.metricValue(), \"Invalid metric value\");\n            }\n        }\n    }\n    alive.set(false);\n}", "summary_tokens": ["verifies", "that", "concurrent", "sensor", "add", "remove", "updates", "and", "read", "don", "t", "result", "in", "errors", "or", "deadlock"], "project": "kafka"}
{"id": 2433, "code": "public ByteBuffer leaderEpochIndex() {\n    return leaderEpochIndex;\n}", "summary_tokens": ["leader", "epoch", "index", "until", "this", "segment"], "project": "kafka"}
{"id": 2787, "code": "public File getOrCreateDirectoryForTask(final TaskId taskId) {\n    final File taskParentDir = getTaskDirectoryParentName(taskId);\n    final File taskDir = new File(taskParentDir, StateManagerUtil.toTaskDirString(taskId));\n    if (hasPersistentStores) {\n        if (!taskDir.exists()) {\n            synchronized (taskDirCreationLock) {\n                    \n                    \n                    \n                    \n                if (!taskParentDir.exists() && !taskParentDir.mkdir()) {\n                    throw new ProcessorStateException(\n                        String.format(\"Parent [%s] of task directory [%s] doesn't exist and couldn't be created\",\n                            taskParentDir.getPath(), taskDir.getPath()));\n                }\n                if (!taskDir.exists() && !taskDir.mkdir()) {\n                    throw new ProcessorStateException(\n                        String.format(\"task directory [%s] doesn't exist and couldn't be created\", taskDir.getPath()));\n                }\n            }\n        } else if (!taskDir.isDirectory()) {\n            throw new ProcessorStateException(\n                String.format(\"state directory [%s] can't be created as there is an existing file with the same name\", taskDir.getPath()));\n        }\n    }\n    return taskDir;\n}", "summary_tokens": ["get", "or", "create", "the", "directory", "for", "the", "provided", "task", "id"], "project": "kafka"}
{"id": 3080, "code": "public String bootstrapServers() {\n    return brokers[0].brokerList();\n}", "summary_tokens": ["this", "cluster", "s", "bootstrap"], "project": "kafka"}
{"id": 3252, "code": "public final long durationMs() {\n    return durationMs;\n}", "summary_tokens": ["get", "the", "duration", "of", "this", "task", "in", "ms"], "project": "kafka"}
{"id": 977, "code": "public void renameTo(File f) throws IOException {\n    try {\n        Utils.atomicMoveWithFallback(file.toPath(), f.toPath(), false);\n    } finally {\n        this.file = f;\n    }\n}", "summary_tokens": ["rename", "the", "file", "that", "backs", "this", "message", "set", "ioexception", "if", "rename", "fails"], "project": "kafka"}
{"id": 2786, "code": "private boolean lockStateDirectory() {\n    final File lockFile = new File(stateDir, LOCK_FILE_NAME);\n    try {\n        stateDirLockChannel = FileChannel.open(lockFile.toPath(), StandardOpenOption.CREATE, StandardOpenOption.WRITE);\n        stateDirLock = tryLock(stateDirLockChannel);\n    } catch (final IOException e) {\n        log.error(\"Unable to lock the state directory due to unexpected exception\", e);\n        throw new ProcessorStateException(String.format(\"Failed to lock the state directory [%s] during startup\",\n            stateDir.getAbsolutePath()), e);\n    }\n    return stateDirLock != null;\n}", "summary_tokens": ["true", "if", "the", "state", "directory", "was", "successfully", "locked"], "project": "kafka"}
{"id": 437, "code": "protected synchronized Generation generationIfStable() {\n    if (this.state != MemberState.STABLE)\n        return null;\n    return generation;\n}", "summary_tokens": ["get", "the", "current", "generation", "state", "if", "the", "group", "is", "stable", "otherwise", "return", "null"], "project": "kafka"}
{"id": 3190, "code": "public void setRecordMetadata(final String topic,\n                              final int partition,\n                              final long offset) {\n    recordMetadata = new MockRecordMetadata(topic, partition, offset);\n}", "summary_tokens": ["the", "context", "exposes", "these", "metadata", "for", "use", "in", "the", "processor"], "project": "kafka"}
{"id": 2594, "code": "public Materialized<K, V, S> withKeySerde(final Serde<K> keySerde) {\n    this.keySerde = keySerde;\n    return this;\n}", "summary_tokens": ["set", "the", "key", "serde", "the", "materialize", "state", "store", "will", "use"], "project": "kafka"}
{"id": 1476, "code": "public void testStructBuild() {\n    for (short version : ApiKeys.OFFSET_FETCH.allVersions()) {\n        if (version < 8) {\n            partitionDataMap.put(new TopicPartition(topicTwo, partitionTwo), new PartitionData(\n                offset,\n                leaderEpochTwo,\n                metadata,\n                Errors.GROUP_AUTHORIZATION_FAILED\n            ));\n\n            OffsetFetchResponse latestResponse = new OffsetFetchResponse(throttleTimeMs, Errors.NONE, partitionDataMap);\n            OffsetFetchResponseData data = new OffsetFetchResponseData(\n                new ByteBufferAccessor(latestResponse.serialize(version)), version);\n\n            OffsetFetchResponse oldResponse = new OffsetFetchResponse(data, version);\n\n            if (version <= 1) {\n                assertEquals(Errors.NONE.code(), data.errorCode());\n\n                    \n                assertEquals(Errors.GROUP_AUTHORIZATION_FAILED, oldResponse.error());\n                assertEquals(Utils.mkMap(Utils.mkEntry(Errors.GROUP_AUTHORIZATION_FAILED, 2),\n                    Utils.mkEntry(Errors.TOPIC_AUTHORIZATION_FAILED, 1)),\n                    oldResponse.errorCounts());\n            } else {\n                assertEquals(Errors.NONE.code(), data.errorCode());\n\n                assertEquals(Errors.NONE, oldResponse.error());\n                assertEquals(Utils.mkMap(\n                    Utils.mkEntry(Errors.NONE, 1),\n                    Utils.mkEntry(Errors.GROUP_AUTHORIZATION_FAILED, 1),\n                    Utils.mkEntry(Errors.TOPIC_AUTHORIZATION_FAILED, 1)),\n                    oldResponse.errorCounts());\n            }\n\n            if (version <= 2) {\n                assertEquals(DEFAULT_THROTTLE_TIME, oldResponse.throttleTimeMs());\n            } else {\n                assertEquals(throttleTimeMs, oldResponse.throttleTimeMs());\n            }\n\n            Map<TopicPartition, PartitionData> expectedDataMap = new HashMap<>();\n            for (Map.Entry<TopicPartition, PartitionData> entry : partitionDataMap.entrySet()) {\n                PartitionData partitionData = entry.getValue();\n                expectedDataMap.put(entry.getKey(), new PartitionData(\n                    partitionData.offset,\n                    version <= 4 ? Optional.empty() : partitionData.leaderEpoch,\n                    partitionData.metadata,\n                    partitionData.error\n                ));\n            }\n\n            Map<TopicPartition, PartitionData> responseData = oldResponse.responseDataV0ToV7();\n            assertEquals(expectedDataMap, responseData);\n\n            responseData.forEach((tp, rdata) -> assertTrue(rdata.hasError()));\n        } else {\n            partitionDataMap.put(new TopicPartition(topicTwo, partitionTwo), new PartitionData(\n                offset,\n                leaderEpochTwo,\n                metadata,\n                Errors.GROUP_AUTHORIZATION_FAILED));\n            OffsetFetchResponse latestResponse = new OffsetFetchResponse(\n                throttleTimeMs,\n                Collections.singletonMap(groupOne, Errors.NONE),\n                Collections.singletonMap(groupOne, partitionDataMap));\n            OffsetFetchResponseData data = new OffsetFetchResponseData(\n                new ByteBufferAccessor(latestResponse.serialize(version)), version);\n            OffsetFetchResponse oldResponse = new OffsetFetchResponse(data, version);\n            assertEquals(Errors.NONE.code(), data.groups().get(0).errorCode());\n\n            assertEquals(Errors.NONE, oldResponse.groupLevelError(groupOne));\n            assertEquals(Utils.mkMap(\n                Utils.mkEntry(Errors.NONE, 1),\n                Utils.mkEntry(Errors.GROUP_AUTHORIZATION_FAILED, 1),\n                Utils.mkEntry(Errors.TOPIC_AUTHORIZATION_FAILED, 1)),\n                oldResponse.errorCounts());\n            assertEquals(throttleTimeMs, oldResponse.throttleTimeMs());\n\n            Map<TopicPartition, PartitionData> expectedDataMap = new HashMap<>();\n            for (Map.Entry<TopicPartition, PartitionData> entry : partitionDataMap.entrySet()) {\n                PartitionData partitionData = entry.getValue();\n                expectedDataMap.put(entry.getKey(), new PartitionData(\n                    partitionData.offset,\n                    partitionData.leaderEpoch,\n                    partitionData.metadata,\n                    partitionData.error\n                ));\n            }\n\n            Map<TopicPartition, PartitionData> responseData = oldResponse.partitionDataMap(groupOne);\n            assertEquals(expectedDataMap, responseData);\n\n            responseData.forEach((tp, rdata) -> assertTrue(rdata.hasError()));\n        }\n    }\n}", "summary_tokens": ["test", "behavior", "changes", "over", "the", "versions"], "project": "kafka"}
{"id": 680, "code": "public Set<String> tags() {\n    return tags;\n}", "summary_tokens": ["get", "the", "set", "of", "tag", "names", "for", "the", "metric"], "project": "kafka"}
{"id": 674, "code": "public String host() {\n    return host;\n}", "summary_tokens": ["returns", "advertised", "host", "name", "of", "this", "endpoint"], "project": "kafka"}
{"id": 104, "code": "public ApiVersion apiVersion(ApiKeys apiKey) {\n    return supportedVersions.get(apiKey);\n}", "summary_tokens": ["get", "the", "version", "information", "for", "a", "given", "api"], "project": "kafka"}
{"id": 337, "code": "public KafkaFuture<Void> memberResult(MemberToRemove member) {\n    if (removeAll()) {\n        throw new IllegalArgumentException(\"The method: memberResult is not applicable in 'removeAll' mode\");\n    }\n    if (!memberInfos.contains(member)) {\n        throw new IllegalArgumentException(\"Member \" + member + \" was not included in the original request\");\n    }\n\n    final KafkaFutureImpl<Void> result = new KafkaFutureImpl<>();\n    this.future.whenComplete((memberErrors, throwable) -> {\n        if (throwable != null) {\n            result.completeExceptionally(throwable);\n        } else if (!maybeCompleteExceptionally(memberErrors, member.toMemberIdentity(), result)) {\n            result.complete(null);\n        }\n    });\n    return result;\n}", "summary_tokens": ["returns", "the", "selected", "member", "future"], "project": "kafka"}
{"id": 2893, "code": "public static AssignmentInfo decode(final ByteBuffer data) {\n        \n    data.rewind();\n\n    try (final DataInputStream in = new DataInputStream(new ByteBufferInputStream(data))) {\n        final AssignmentInfo assignmentInfo;\n\n        final int usedVersion = in.readInt();\n        final int commonlySupportedVersion;\n        switch (usedVersion) {\n            case 1:\n                assignmentInfo = new AssignmentInfo(usedVersion, UNKNOWN);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                assignmentInfo.partitionsByHost = new HashMap<>();\n                break;\n            case 2:\n                assignmentInfo = new AssignmentInfo(usedVersion, UNKNOWN);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHost(assignmentInfo, in);\n                break;\n            case 3:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHost(assignmentInfo, in);\n                break;\n            case 4:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHost(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                break;\n            case 5:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodePartitionsByHostUsingDictionary(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                break;\n            case 6:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodeActiveAndStandbyHostPartitions(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                break;\n            case 7:\n            case 8:\n            case 9:\n            case 10:\n            case 11:\n                commonlySupportedVersion = in.readInt();\n                assignmentInfo = new AssignmentInfo(usedVersion, commonlySupportedVersion);\n                decodeActiveTasks(assignmentInfo, in);\n                decodeStandbyTasks(assignmentInfo, in);\n                decodeActiveAndStandbyHostPartitions(assignmentInfo, in);\n                assignmentInfo.errCode = in.readInt();\n                assignmentInfo.nextRebalanceMs = in.readLong();\n                break;\n            default:\n                final TaskAssignmentException fatalException = new TaskAssignmentException(\"Unable to decode assignment data: \" +\n                    \"used version: \" + usedVersion + \"; latest supported version: \" + LATEST_SUPPORTED_VERSION);\n                log.error(fatalException.getMessage(), fatalException);\n                throw fatalException;\n        }\n\n        return assignmentInfo;\n    } catch (final IOException ex) {\n        throw new TaskAssignmentException(\"Failed to decode AssignmentInfo\", ex);\n    }\n}", "summary_tokens": ["task", "assignment", "exception", "if", "method", "fails", "to", "decode", "the", "data", "or", "if", "the", "data", "version", "is", "unknown"], "project": "kafka"}
{"id": 588, "code": "public void updatePartitionLoadStats(int[] queueSizes, int[] partitionIds, int length) {\n    if (queueSizes == null) {\n        log.trace(\"No load stats for topic {}, not using adaptive\", topic);\n        partitionLoadStats = null;\n        return;\n    }\n    assert queueSizes.length == partitionIds.length;\n    assert length <= queueSizes.length;\n\n        \n        \n        \n        \n        \n        \n        \n    if (length < 1 || queueSizes.length < 2) {\n        log.trace(\"The number of partitions is too small: available={}, all={}, not using adaptive for topic {}\",\n                length, queueSizes.length, topic);\n        partitionLoadStats = null;\n        return;\n    }\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n\n        \n    int maxSizePlus1 = queueSizes[0];\n    boolean allEqual = true;\n    for (int i = 1; i < length; i++) {\n        if (queueSizes[i] != maxSizePlus1)\n            allEqual = false;\n        if (queueSizes[i] > maxSizePlus1)\n            maxSizePlus1 = queueSizes[i];\n    }\n    ++maxSizePlus1;\n\n    if (allEqual && length == queueSizes.length) {\n            \n            \n            \n        log.trace(\"All queue lengths are the same, not using adaptive for topic {}\", topic);\n        partitionLoadStats = null;\n        return;\n    }\n\n        \n    queueSizes[0] = maxSizePlus1 - queueSizes[0];\n    for (int i = 1; i < length; i++) {\n        queueSizes[i] = maxSizePlus1 - queueSizes[i] + queueSizes[i - 1];\n    }\n    log.trace(\"Partition load stats for topic {}: CFT={}, IDs={}, length={}\",\n            topic, queueSizes, partitionIds, length);\n    partitionLoadStats = new PartitionLoadStats(queueSizes, partitionIds, length);\n}", "summary_tokens": ["update", "partition", "load", "stats", "from", "the", "queue", "sizes", "of", "each", "partition", "note", "queue", "sizes", "are", "modified", "in", "place", "to", "avoid", "allocations"], "project": "kafka"}
{"id": 1551, "code": "public void unrecognizedExtensionsAreNotSaved() throws Exception {\n    saslServer = new OAuthBearerSaslServer(EXTENSIONS_VALIDATOR_CALLBACK_HANDLER);\n    Map<String, String> customExtensions = new HashMap<>();\n    customExtensions.put(\"firstKey\", \"value1\");\n    customExtensions.put(\"secondKey\", \"value1\");\n    customExtensions.put(\"thirdKey\", \"value1\");\n\n    byte[] nextChallenge = saslServer\n            .evaluateResponse(clientInitialResponse(null, false, customExtensions));\n\n    assertTrue(nextChallenge.length == 0, \"Next challenge is not empty\");\n    assertNull(saslServer.getNegotiatedProperty(\"thirdKey\"), \"Extensions not recognized by the server must be ignored\");\n}", "summary_tokens": ["sasl", "extensions", "that", "were", "not", "recognized", "neither", "validated", "nor", "invalidated", "by", "the", "callback", "handler", "must", "not", "be", "accessible", "through", "the", "get", "negotiated", "property", "method"], "project": "kafka"}
{"id": 1588, "code": "public void validateValue(Object value) {\n    validateValue(this, value);\n}", "summary_tokens": ["validate", "that", "the", "value", "can", "be", "used", "for", "this", "schema", "i"], "project": "kafka"}
{"id": 772, "code": "private static Recommender embeddedRecommender(final String keyPrefix, final Recommender base) {\n    if (base == null) return null;\n    return new Recommender() {\n        private String unprefixed(String k) {\n            return k.substring(keyPrefix.length());\n        }\n\n        private Map<String, Object> unprefixed(Map<String, Object> parsedConfig) {\n            final Map<String, Object> unprefixedParsedConfig = new HashMap<>(parsedConfig.size());\n            for (Map.Entry<String, Object> e : parsedConfig.entrySet()) {\n                if (e.getKey().startsWith(keyPrefix)) {\n                    unprefixedParsedConfig.put(unprefixed(e.getKey()), e.getValue());\n                }\n            }\n            return unprefixedParsedConfig;\n        }\n\n        @Override\n        public List<Object> validValues(String name, Map<String, Object> parsedConfig) {\n            return base.validValues(unprefixed(name), unprefixed(parsedConfig));\n        }\n\n        @Override\n        public boolean visible(String name, Map<String, Object> parsedConfig) {\n            return base.visible(unprefixed(name), unprefixed(parsedConfig));\n        }\n    };\n}", "summary_tokens": ["returns", "a", "new", "recommender", "instance", "that", "delegates", "to", "the", "base", "recommender", "but", "unprefixes", "the", "input", "parameters", "along", "the", "way"], "project": "kafka"}
{"id": 2987, "code": "public static HostInfo unavailable() {\n    return new HostInfo(\"unavailable\", -1);\n}", "summary_tokens": ["a", "sentinel", "for", "cases", "where", "the", "host", "metadata", "is", "currently", "unavailable", "eg", "during", "rebalance", "operations"], "project": "kafka"}
{"id": 1484, "code": "public void testValidSaslPlainOverSsl() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n\n    server = createEchoServer(securityProtocol);\n    checkAuthenticationAndReauthentication(securityProtocol, node);\n}", "summary_tokens": ["tests", "good", "path", "sasl", "plain", "client", "and", "server", "channels", "using", "ssl", "transport", "layer"], "project": "kafka"}
{"id": 2741, "code": "public Collection<String> sourceTopicsForStore(final String storeName) {\n    return maybeDecorateInternalSourceTopics(stateStoreNameToRawSourceTopicNames.get(storeName));\n}", "summary_tokens": ["the", "full", "names", "including", "application", "id", "topology", "name", "prefix", "of", "all", "source", "topics", "whose", "processors", "are", "connected", "to", "the", "given", "state", "store"], "project": "kafka"}
{"id": 1219, "code": "", "summary_tokens": ["close", "this", "serde", "class", "which", "will", "close", "the", "underlying", "serializer", "and", "deserializer"], "project": "kafka"}
{"id": 584, "code": "private int nextPartition(Cluster cluster) {\n    int random = mockRandom != null ? mockRandom.get() : Utils.toPositive(ThreadLocalRandom.current().nextInt());\n\n        \n    PartitionLoadStats partitionLoadStats = this.partitionLoadStats;\n    int partition;\n\n    if (partitionLoadStats == null) {\n            \n            \n        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);\n        if (availablePartitions.size() > 0) {\n            partition = availablePartitions.get(random % availablePartitions.size()).partition();\n        } else {\n                \n            List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\n            partition = random % partitions.size();\n        }\n    } else {\n            \n            \n        assert partitionLoadStats.length > 0;\n\n        int[] cumulativeFrequencyTable = partitionLoadStats.cumulativeFrequencyTable;\n        int weightedRandom = random % cumulativeFrequencyTable[partitionLoadStats.length - 1];\n\n            \n            \n        int searchResult = Arrays.binarySearch(cumulativeFrequencyTable, 0, partitionLoadStats.length, weightedRandom);\n\n            \n            \n            \n            \n            \n            \n            \n            \n            \n        int partitionIndex = Math.abs(searchResult + 1);\n        assert partitionIndex < partitionLoadStats.length;\n        partition = partitionLoadStats.partitionIds[partitionIndex];\n    }\n\n    log.trace(\"Switching to partition {} in topic {}\", partition, topic);\n    return partition;\n}", "summary_tokens": ["calculate", "the", "next", "partition", "for", "the", "topic", "based", "on", "the", "partition", "load", "stats"], "project": "kafka"}
{"id": 2280, "code": "public static Set<Integer> toSet(int[] replicas) {\n    Set<Integer> result = new HashSet<>();\n    for (int replica : replicas) {\n        result.add(replica);\n    }\n    return result;\n}", "summary_tokens": ["convert", "a", "replica", "array", "to", "a", "set"], "project": "kafka"}
{"id": 1491, "code": "public void testMechanismPluggability() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    configureMechanisms(\"DIGEST-MD5\", Arrays.asList(\"DIGEST-MD5\"));\n    configureDigestMd5ServerCallback(securityProtocol);\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientConnection(securityProtocol, node);\n}", "summary_tokens": ["tests", "that", "mechanisms", "that", "are", "not", "supported", "in", "kafka", "can", "be", "plugged", "in", "without", "modifying", "kafka", "code", "if", "sasl", "client", "and", "server", "providers", "are", "available"], "project": "kafka"}
{"id": 1173, "code": "public static OAuthBearerValidationResult validateScope(OAuthBearerToken token, List<String> requiredScope) {\n    final Set<String> tokenScope = token.scope();\n    if (requiredScope == null || requiredScope.isEmpty())\n        return OAuthBearerValidationResult.newSuccess();\n    for (String requiredScopeElement : requiredScope) {\n        if (!tokenScope.contains(requiredScopeElement))\n            return OAuthBearerValidationResult.newFailure(String.format(\n                    \"The provided scope (%s) was mising a required scope (%s).  All required scope elements: %s\",\n                    String.valueOf(tokenScope), requiredScopeElement, requiredScope.toString()),\n                    requiredScope.toString(), null);\n    }\n    return OAuthBearerValidationResult.newSuccess();\n}", "summary_tokens": ["validate", "the", "given", "token", "s", "scope", "against", "the", "required", "scope"], "project": "kafka"}
{"id": 2649, "code": "public TableJoined<K, KO> withOtherPartitioner(final StreamPartitioner<KO, Void> otherPartitioner) {\n    return new TableJoined<>(partitioner, otherPartitioner, name);\n}", "summary_tokens": ["set", "the", "custom", "other", "stream", "partitioner", "to", "be", "used", "as", "part", "of", "computing", "the", "join"], "project": "kafka"}
{"id": 472, "code": "public void poll(Timer timer, PollCondition pollCondition, boolean disableWakeup) {\n        \n    firePendingCompletedRequests();\n\n    lock.lock();\n    try {\n            \n        handlePendingDisconnects();\n\n            \n        long pollDelayMs = trySend(timer.currentTimeMs());\n\n            \n            \n            \n        if (pendingCompletion.isEmpty() && (pollCondition == null || pollCondition.shouldBlock())) {\n                \n            long pollTimeout = Math.min(timer.remainingMs(), pollDelayMs);\n            if (client.inFlightRequestCount() == 0)\n                pollTimeout = Math.min(pollTimeout, retryBackoffMs);\n            client.poll(pollTimeout, timer.currentTimeMs());\n        } else {\n            client.poll(0, timer.currentTimeMs());\n        }\n        timer.update();\n\n            \n            \n            \n        checkDisconnects(timer.currentTimeMs());\n        if (!disableWakeup) {\n                \n                \n            maybeTriggerWakeup();\n        }\n            \n        maybeThrowInterruptException();\n\n            \n            \n        trySend(timer.currentTimeMs());\n\n            \n        failExpiredRequests(timer.currentTimeMs());\n\n            \n        unsent.clean();\n    } finally {\n        lock.unlock();\n    }\n\n        \n    firePendingCompletedRequests();\n\n    metadata.maybeThrowAnyException();\n}", "summary_tokens": ["poll", "for", "any", "network", "io"], "project": "kafka"}
{"id": 446, "code": "private List<TopicPartition> getUnassignedPartitions(int totalPartitionsCount,\n                                                     Map<String, Integer> partitionsPerTopic,\n                                                     List<TopicPartition> sortedAssignedPartitions) {\n    List<String> sortedAllTopics = new ArrayList<>(partitionsPerTopic.keySet());\n        \n    Collections.sort(sortedAllTopics);\n\n    if (sortedAssignedPartitions.isEmpty()) {\n            \n        return getAllTopicPartitions(partitionsPerTopic, sortedAllTopics, totalPartitionsCount);\n    }\n\n    List<TopicPartition> unassignedPartitions = new ArrayList<>(totalPartitionsCount - sortedAssignedPartitions.size());\n\n    Collections.sort(sortedAssignedPartitions, Comparator.comparing(TopicPartition::topic).thenComparing(TopicPartition::partition));\n\n    boolean shouldAddDirectly = false;\n    Iterator<TopicPartition> sortedAssignedPartitionsIter = sortedAssignedPartitions.iterator();\n    TopicPartition nextAssignedPartition = sortedAssignedPartitionsIter.next();\n\n    for (String topic : sortedAllTopics) {\n        int partitionCount = partitionsPerTopic.get(topic);\n        for (int i = 0; i < partitionCount; i++) {\n            if (shouldAddDirectly || !(nextAssignedPartition.topic().equals(topic) && nextAssignedPartition.partition() == i)) {\n                unassignedPartitions.add(new TopicPartition(topic, i));\n            } else {\n                    \n                if (sortedAssignedPartitionsIter.hasNext()) {\n                    nextAssignedPartition = sortedAssignedPartitionsIter.next();\n                } else {\n                        \n                    shouldAddDirectly = true;\n                }\n            }\n        }\n    }\n\n    return unassignedPartitions;\n}", "summary_tokens": ["get", "the", "unassigned", "partition", "list", "by", "computing", "the", "difference", "set", "of", "all", "sorted", "partitions", "and", "sorted", "assigned", "partitions"], "project": "kafka"}
{"id": 2916, "code": "public void cleanUpNamedTopology(final String name) {\n    if (getTopologyByName(name).isPresent()) {\n        throw new IllegalStateException(\"Can't clean up local state for an active NamedTopology: \" + name);\n    }\n    stateDirectory.clearLocalStateForNamedTopology(name);\n}", "summary_tokens": ["do", "a", "clean", "up", "of", "the", "local", "state", "directory", "for", "this", "named", "topology", "by", "deleting", "all", "data", "with", "regard", "to", "the", "streams", "config", "application", "id", "config", "application", "id", "in", "the", "streams", "config", "state", "dir", "config", "p", "may", "be", "called", "while", "the", "streams", "is", "in", "any", "state", "but", "only", "on", "a", "named", "topology", "that", "has", "already", "been", "removed", "via", "remove", "named", "topology", "string"], "project": "kafka"}
{"id": 1718, "code": "public static Set<String> checkpointTopics(Map<String, Object> properties)\n        throws InterruptedException, TimeoutException {\n    try (MirrorClient client = new MirrorClient(properties)) {\n        return client.checkpointTopics();\n    }\n}", "summary_tokens": ["find", "all", "checkpoint", "topics"], "project": "kafka"}
{"id": 2413, "code": "public long firstProducerId() {\n    return firstProducerId;\n}", "summary_tokens": ["get", "the", "first", "id", "inclusive", "to", "be", "assigned", "from", "this", "block"], "project": "kafka"}
{"id": 311, "code": "public OptionalLong totalBytes() {\n    return totalBytes;\n}", "summary_tokens": ["the", "total", "size", "of", "the", "volume", "this", "log", "directory", "is", "on", "or", "empty", "if", "the", "broker", "did", "not", "return", "a", "value"], "project": "kafka"}
{"id": 832, "code": "public String name() {\n    return this.name;\n}", "summary_tokens": ["the", "name", "this", "sensor", "is", "registered", "with"], "project": "kafka"}
{"id": 571, "code": "public int partition() {\n    return this.topicPartition.partition();\n}", "summary_tokens": ["the", "partition", "the", "record", "was", "sent", "to"], "project": "kafka"}
{"id": 2842, "code": "private boolean populateClientStatesMap(final Map<UUID, ClientState> clientStates,\n                                        final Map<UUID, ClientMetadata> clientMetadataMap,\n                                        final Map<TopicPartition, TaskId> taskForPartition,\n                                        final ChangelogTopics changelogTopics) {\n    boolean fetchEndOffsetsSuccessful;\n    Map<TaskId, Long> allTaskEndOffsetSums;\n    try {\n            \n            \n        final KafkaFuture<Map<TopicPartition, ListOffsetsResultInfo>> endOffsetsFuture =\n            fetchEndOffsetsFuture(changelogTopics.preExistingNonSourceTopicBasedPartitions(), adminClient);\n\n        final Map<TopicPartition, Long> sourceChangelogEndOffsets =\n            fetchCommittedOffsets(changelogTopics.preExistingSourceTopicBasedPartitions(), mainConsumerSupplier.get());\n\n        final Map<TopicPartition, ListOffsetsResultInfo> endOffsets = ClientUtils.getEndOffsets(endOffsetsFuture);\n\n        allTaskEndOffsetSums = computeEndOffsetSumsByTask(\n            endOffsets,\n            sourceChangelogEndOffsets,\n            changelogTopics\n        );\n        fetchEndOffsetsSuccessful = true;\n    } catch (final StreamsException | TimeoutException e) {\n        allTaskEndOffsetSums = changelogTopics.statefulTaskIds().stream().collect(Collectors.toMap(t -> t, t -> UNKNOWN_OFFSET_SUM));\n        fetchEndOffsetsSuccessful = false;\n    }\n\n    for (final Map.Entry<UUID, ClientMetadata> entry : clientMetadataMap.entrySet()) {\n        final UUID uuid = entry.getKey();\n        final ClientState state = entry.getValue().state;\n        state.initializePrevTasks(taskForPartition, taskManager.topologyMetadata().hasNamedTopologies());\n\n        state.computeTaskLags(uuid, allTaskEndOffsetSums);\n        clientStates.put(uuid, state);\n    }\n\n    return fetchEndOffsetsSuccessful;\n}", "summary_tokens": ["builds", "a", "map", "from", "client", "to", "state", "and", "readies", "each", "client", "state", "for", "assignment", "by", "adding", "any", "missing", "prev", "tasks", "and", "computing", "the", "per", "task", "overall", "lag", "based", "on", "the", "fetched", "end", "offsets", "for", "each", "changelog"], "project": "kafka"}
{"id": 1592, "code": "public static byte[] fromLogical(Schema schema, BigDecimal value) {\n    int schemaScale = scale(schema);\n    if (value.scale() != schemaScale)\n        throw new DataException(String.format(\n            \"Decimal value has mismatching scale for given Decimal schema. \"\n                + \"Schema has scale %d, value has scale %d.\",\n            schemaScale,\n            value.scale()\n        ));\n    return value.unscaledValue().toByteArray();\n}", "summary_tokens": ["convert", "a", "value", "from", "its", "logical", "format", "big", "decimal", "to", "it", "s", "encoded", "format"], "project": "kafka"}
{"id": 1677, "code": "public void commitRecord(SourceRecord record, RecordMetadata metadata)\n        throws InterruptedException {\n        \n    commitRecord(record);\n}", "summary_tokens": ["p", "commit", "an", "individual", "source", "record", "when", "the", "callback", "from", "the", "producer", "client", "is", "received"], "project": "kafka"}
{"id": 2966, "code": "public void addResult(final int partition, final QueryResult<R> r) {\n    partitionResults.put(partition, r);\n}", "summary_tokens": ["set", "the", "result", "for", "a", "partitioned", "store", "query"], "project": "kafka"}
{"id": 1355, "code": "public void testBlockTimeout() throws Exception {\n    BufferPool pool = new BufferPool(10, 1, metrics, Time.SYSTEM, metricGroup);\n    ByteBuffer buffer1 = pool.allocate(1, maxBlockTimeMs);\n    ByteBuffer buffer2 = pool.allocate(1, maxBlockTimeMs);\n    ByteBuffer buffer3 = pool.allocate(1, maxBlockTimeMs);\n        \n    delayedDeallocate(pool, buffer1, maxBlockTimeMs / 2);\n    delayedDeallocate(pool, buffer2, maxBlockTimeMs);\n        \n    delayedDeallocate(pool, buffer3, maxBlockTimeMs / 2 * 5);\n\n    long beginTimeMs = Time.SYSTEM.milliseconds();\n    try {\n        pool.allocate(10, maxBlockTimeMs);\n        fail(\"The buffer allocated more memory than its maximum value 10\");\n    } catch (BufferExhaustedException e) {\n            \n    }\n        \n    assertTrue(pool.availableMemory() >= 7 && pool.availableMemory() <= 10, \"available memory \" + pool.availableMemory());\n    long durationMs = Time.SYSTEM.milliseconds() - beginTimeMs;\n    assertTrue(durationMs >= maxBlockTimeMs, \"BufferExhaustedException should not throw before maxBlockTimeMs\");\n    assertTrue(durationMs < maxBlockTimeMs + 1000, \"BufferExhaustedException should throw soon after maxBlockTimeMs\");\n}", "summary_tokens": ["verify", "that", "a", "failed", "allocation", "attempt", "due", "to", "not", "enough", "memory", "finishes", "soon", "after", "the", "max", "block", "time", "ms"], "project": "kafka"}
{"id": 2474, "code": "default Admin getAdmin(final Map<String, Object> config) {\n    throw new UnsupportedOperationException(\"Implementations of KafkaClientSupplier should implement the getAdmin() method.\");\n}", "summary_tokens": ["create", "an", "admin", "which", "is", "used", "for", "internal", "topic", "management"], "project": "kafka"}
{"id": 2989, "code": "public static <K, V> QueryableStoreType<ReadOnlyKeyValueStore<K, ValueAndTimestamp<V>>> timestampedKeyValueStore() {\n    return new TimestampedKeyValueStoreType<>();\n}", "summary_tokens": ["a", "queryable", "store", "type", "that", "accepts", "read", "only", "key", "value", "store", "read", "only", "key", "value", "store", "k", "value", "and", "timestamp", "v"], "project": "kafka"}
{"id": 1760, "code": "public SecretKey key() {\n    return key;\n}", "summary_tokens": ["get", "the", "cryptographic", "key", "to", "use", "for", "request", "validation"], "project": "kafka"}
{"id": 945, "code": "public Collection<ClientQuotaFilterComponent> components() {\n    return this.components;\n}", "summary_tokens": ["the", "filter", "s", "components"], "project": "kafka"}
{"id": 1127, "code": "public String errorOpenIDConfiguration() {\n    return errorOpenIDConfiguration;\n}", "summary_tokens": ["return", "the", "potentially", "null", "error", "openid", "configuration", "value", "as", "per", "a", "href", "https", "tools"], "project": "kafka"}
{"id": 524, "code": "synchronized boolean matchesSubscribedPattern(String topic) {\n    Pattern pattern = this.subscribedPattern;\n    if (hasPatternSubscription() && pattern != null)\n        return pattern.matcher(topic).matches();\n    return false;\n}", "summary_tokens": ["check", "whether", "a", "topic", "matches", "a", "subscribed", "pattern"], "project": "kafka"}
{"id": 918, "code": "public int sizeOf(Object o) {\n    int size = 0;\n    Struct r = (Struct) o;\n    for (BoundField field : fields) {\n        try {\n            size += field.def.type.sizeOf(r.get(field));\n        } catch (Exception e) {\n            throw new SchemaException(\"Error computing size for field '\" + field.def.name + \"': \" +\n                    (e.getMessage() == null ? e.getClass().getName() : e.getMessage()));\n        }\n    }\n    return size;\n}", "summary_tokens": ["the", "size", "of", "the", "given", "record"], "project": "kafka"}
{"id": 579, "code": "public long unallocatedMemory() {\n    lock.lock();\n    try {\n        return this.nonPooledAvailableMemory;\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["get", "the", "unallocated", "memory", "not", "in", "the", "free", "list", "or", "in", "use"], "project": "kafka"}
{"id": 2921, "code": "public Map<String, Map<Integer, LagInfo>> allLocalStorePartitionLagsForTopology(final String topologyName) {\n    if (!getTopologyByName(topologyName).isPresent()) {\n        log.error(\"Can't get local store partition lags since topology {} does not exist in this application\",\n                  topologyName);\n        throw new UnknownTopologyException(\"Can't get local store partition lags\", topologyName);\n    }\n    final List<Task> allTopologyTasks = new ArrayList<>();\n    processStreamThread(thread -> allTopologyTasks.addAll(\n        thread.allTasks().values().stream()\n            .filter(t -> topologyName.equals(t.id().topologyName()))\n            .collect(Collectors.toList())));\n    return allLocalStorePartitionLags(allTopologyTasks);\n}", "summary_tokens": ["see", "kafka", "streams", "all", "local", "store", "partition", "lags"], "project": "kafka"}
{"id": 1149, "code": "public Map<String, Object> claims() {\n    return claims;\n}", "summary_tokens": ["return", "the", "jwt", "claim", "set", "as", "a", "map"], "project": "kafka"}
{"id": 492, "code": "public void resetOffsetsIfNeeded() {\n        \n    RuntimeException exception = cachedListOffsetsException.getAndSet(null);\n    if (exception != null)\n        throw exception;\n\n    Set<TopicPartition> partitions = subscriptions.partitionsNeedingReset(time.milliseconds());\n    if (partitions.isEmpty())\n        return;\n\n    final Map<TopicPartition, Long> offsetResetTimestamps = new HashMap<>();\n    for (final TopicPartition partition : partitions) {\n        Long timestamp = offsetResetStrategyTimestamp(partition);\n        if (timestamp != null)\n            offsetResetTimestamps.put(partition, timestamp);\n    }\n\n    resetOffsetsAsync(offsetResetTimestamps);\n}", "summary_tokens": ["reset", "offsets", "for", "all", "assigned", "partitions", "that", "require", "it"], "project": "kafka"}
{"id": 154, "code": "public AlterConfigsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}", "summary_tokens": ["set", "the", "timeout", "in", "milliseconds", "for", "this", "operation", "or", "null", "if", "the", "default", "api", "timeout", "for", "the", "admin", "client", "should", "be", "used"], "project": "kafka"}
{"id": 2705, "code": "public long timestamp() {\n    return timestamp;\n}", "summary_tokens": ["the", "timestamp", "of", "the", "record"], "project": "kafka"}
{"id": 2088, "code": "private void assertNoRedundantAssignments() {\n    List<String> existingConnectors = ConnectUtils.combineCollections(memberAssignments.values(), ConnectorsAndTasks::connectors);\n    List<String> newConnectors = ConnectUtils.combineCollections(returnedAssignments.newlyAssignedConnectors().values());\n    List<ConnectorTaskId> existingTasks = ConnectUtils.combineCollections(memberAssignments.values(), ConnectorsAndTasks::tasks);\n    List<ConnectorTaskId> newTasks = ConnectUtils.combineCollections(returnedAssignments.newlyAssignedTasks().values());\n\n    assertNoDuplicates(\n            newConnectors,\n            \"Connectors should be unique in assignments but duplicates were found; the set of newly-assigned connectors is \" + newConnectors\n    );\n    assertNoDuplicates(\n            newTasks,\n            \"Tasks should be unique in assignments but duplicates were found; the set of newly-assigned tasks is \" + newTasks\n    );\n\n    existingConnectors.retainAll(newConnectors);\n    assertEquals(\"Found connectors in new assignment that already exist in current assignment\",\n            Collections.emptyList(),\n            existingConnectors);\n    existingTasks.retainAll(newTasks);\n    assertEquals(\"Found tasks in new assignment that already exist in current assignment\",\n            Collections.emptyList(),\n            existingConnectors);\n}", "summary_tokens": ["ensure", "that", "no", "connectors", "or", "tasks", "that", "were", "already", "assigned", "during", "the", "previous", "round", "are", "newly", "assigned", "in", "this", "round", "and", "that", "each", "newly", "assigned", "connector", "and", "task", "is", "only", "assigned", "to", "a", "single", "worker"], "project": "kafka"}
{"id": 3152, "code": "public void pipeRecordList(final List<? extends TestRecord<K, V>> records) {\n    for (final TestRecord<K, V> record : records) {\n        pipeInput(record);\n    }\n}", "summary_tokens": ["send", "input", "records", "with", "the", "given", "key", "value", "list", "on", "the", "topic", "then", "commit", "each", "record", "individually"], "project": "kafka"}
{"id": 2392, "code": "public long lastOffset() {\n    return nextOffset - 1;\n}", "summary_tokens": ["return", "the", "offset", "of", "the", "last", "appended", "record"], "project": "kafka"}
{"id": 2825, "code": "void runOnce() {\n    final long startMs = time.milliseconds();\n    now = startMs;\n\n    final long pollLatency = pollPhase();\n\n        \n        \n        \n        \n    if (!isRunning()) {\n        log.debug(\"Thread state is already {}, skipping the run once call after poll request\", state);\n        return;\n    }\n\n    initializeAndRestorePhase();\n\n        \n        \n    advanceNowAndComputeLatency();\n\n    int totalProcessed = 0;\n    long totalCommitLatency = 0L;\n    long totalProcessLatency = 0L;\n    long totalPunctuateLatency = 0L;\n    if (state == State.RUNNING\n        || (stateUpdaterEnabled && isRunning())) {\n            \n        do {\n            log.debug(\"Processing tasks with {} iterations.\", numIterations);\n            final int processed = taskManager.process(numIterations, time);\n            final long processLatency = advanceNowAndComputeLatency();\n            totalProcessLatency += processLatency;\n            if (processed > 0) {\n                    \n                    \n                processRateSensor.record(processed, now);\n\n                    \n                    \n                    \n                    \n                processLatencySensor.record(processLatency / (double) processed, now);\n\n                totalProcessed += processed;\n                totalRecordsProcessedSinceLastSummary += processed;\n            }\n\n            log.debug(\"Processed {} records with {} iterations; invoking punctuators if necessary\",\n                      processed,\n                      numIterations);\n\n            final int punctuated = taskManager.punctuate();\n            totalPunctuatorsSinceLastSummary += punctuated;\n            final long punctuateLatency = advanceNowAndComputeLatency();\n            totalPunctuateLatency += punctuateLatency;\n            if (punctuated > 0) {\n                punctuateSensor.record(punctuateLatency / (double) punctuated, now);\n            }\n\n            log.debug(\"{} punctuators ran.\", punctuated);\n\n            final long beforeCommitMs = now;\n            final int committed = maybeCommit();\n            final long commitLatency = Math.max(now - beforeCommitMs, 0);\n            totalCommitLatency += commitLatency;\n            if (committed > 0) {\n                totalCommittedSinceLastSummary += committed;\n                commitSensor.record(commitLatency / (double) committed, now);\n\n                if (log.isDebugEnabled()) {\n                    log.debug(\"Committed all active tasks {} and standby tasks {} in {}ms\",\n                        taskManager.activeTaskIds(), taskManager.standbyTaskIds(), commitLatency);\n                }\n            }\n\n            if (processed == 0) {\n                    \n                break;\n            } else if (Math.max(now - lastPollMs, 0) > maxPollTimeMs / 2) {\n                numIterations = numIterations > 1 ? numIterations / 2 : numIterations;\n                break;\n            } else if (punctuated > 0 || committed > 0) {\n                numIterations = numIterations > 1 ? numIterations / 2 : numIterations;\n            } else {\n                numIterations++;\n            }\n        } while (true);\n\n            \n            \n        taskManager.recordTaskProcessRatio(totalProcessLatency, now);\n    }\n\n    now = time.milliseconds();\n    final long runOnceLatency = now - startMs;\n    processRecordsSensor.record(totalProcessed, now);\n    processRatioSensor.record((double) totalProcessLatency / runOnceLatency, now);\n    punctuateRatioSensor.record((double) totalPunctuateLatency / runOnceLatency, now);\n    pollRatioSensor.record((double) pollLatency / runOnceLatency, now);\n    commitRatioSensor.record((double) totalCommitLatency / runOnceLatency, now);\n\n    final boolean logProcessingSummary = now - lastLogSummaryMs > LOG_SUMMARY_INTERVAL_MS;\n    if (logProcessingSummary) {\n        log.info(\"Processed {} total records, ran {} punctuators, and committed {} total tasks since the last update\",\n             totalRecordsProcessedSinceLastSummary, totalPunctuatorsSinceLastSummary, totalCommittedSinceLastSummary);\n\n        totalRecordsProcessedSinceLastSummary = 0L;\n        totalPunctuatorsSinceLastSummary = 0L;\n        totalCommittedSinceLastSummary = 0L;\n        lastLogSummaryMs = now;\n    }\n}", "summary_tokens": ["one", "iteration", "of", "a", "thread", "includes", "the", "following", "steps"], "project": "kafka"}
{"id": 2036, "code": "public void testPollBoundary() throws Exception {\n        \n    workerProps.put(WorkerConfig.OFFSET_COMMIT_INTERVAL_MS_CONFIG, \"600000\");\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int numTasks = 1;\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, Integer.toString(numTasks));\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TRANSACTION_BOUNDARY_CONFIG, POLL.toString());\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n\n        \n    connectorHandle.expectedRecords(recordsProduced);\n    connectorHandle.expectedCommits(recordsProduced);\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    log.info(\"Waiting for records to be provided to worker by task\");\n        \n    connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n    log.info(\"Waiting for records to be committed to Kafka by worker\");\n        \n    connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n    StartAndStopLatch connectorStop = connectorHandle.expectedStops(1, true);\n    connect.deleteConnector(CONNECTOR_NAME);\n    assertConnectorStopped(connectorStop);\n\n        \n    ConsumerRecords<byte[], byte[]> records = connect.kafka().consumeAll(\n            CONSUME_RECORDS_TIMEOUT_MS,\n            Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n            null,\n            topic\n    );\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + records.count(),\n            records.count() >= recordsProduced);\n    assertExactlyOnceSeqnos(records, numTasks);\n}", "summary_tokens": ["a", "simple", "green", "path", "test", "that", "ensures", "the", "worker", "can", "start", "up", "a", "source", "task", "with", "exactly", "once", "support", "enabled", "and", "write", "some", "records", "to", "kafka", "that", "will", "be", "visible", "to", "a", "downstream", "consumer", "using", "the", "read", "committed", "isolation", "level"], "project": "kafka"}
{"id": 715, "code": "boolean isUnknown() {\n    return operation.isUnknown() || permissionType.isUnknown();\n}", "summary_tokens": ["return", "true", "if", "there", "are", "any", "unknown", "components"], "project": "kafka"}
{"id": 2552, "code": "public static long validateMillisecondInstant(final Instant instant, final String messagePrefix) {\n    try {\n        if (instant == null) {\n            throw new IllegalArgumentException(messagePrefix + VALIDATE_MILLISECOND_NULL_SUFFIX);\n        }\n\n        return instant.toEpochMilli();\n    } catch (final ArithmeticException e) {\n        throw new IllegalArgumentException(messagePrefix + VALIDATE_MILLISECOND_OVERFLOW_SUFFIX, e);\n    }\n}", "summary_tokens": ["validates", "that", "milliseconds", "from", "instant", "can", "be", "retrieved"], "project": "kafka"}
{"id": 641, "code": "private List<ProducerBatch> getExpiredInflightBatches(long now) {\n    List<ProducerBatch> expiredBatches = new ArrayList<>();\n\n    for (Iterator<Map.Entry<TopicPartition, List<ProducerBatch>>> batchIt = inFlightBatches.entrySet().iterator(); batchIt.hasNext();) {\n        Map.Entry<TopicPartition, List<ProducerBatch>> entry = batchIt.next();\n        List<ProducerBatch> partitionInFlightBatches = entry.getValue();\n        if (partitionInFlightBatches != null) {\n            Iterator<ProducerBatch> iter = partitionInFlightBatches.iterator();\n            while (iter.hasNext()) {\n                ProducerBatch batch = iter.next();\n                if (batch.hasReachedDeliveryTimeout(accumulator.getDeliveryTimeoutMs(), now)) {\n                    iter.remove();\n                        \n                        \n                        \n                    if (!batch.isDone()) {\n                        expiredBatches.add(batch);\n                    } else {\n                        throw new IllegalStateException(batch.topicPartition + \" batch created at \" +\n                            batch.createdMs + \" gets unexpected final state \" + batch.finalState());\n                    }\n                } else {\n                    accumulator.maybeUpdateNextBatchExpiryTime(batch);\n                    break;\n                }\n            }\n            if (partitionInFlightBatches.isEmpty()) {\n                batchIt.remove();\n            }\n        }\n    }\n    return expiredBatches;\n}", "summary_tokens": ["get", "the", "in", "flight", "batches", "that", "has", "reached", "delivery", "timeout"], "project": "kafka"}
{"id": 1813, "code": "public void removeMetrics() {\n    taskMetricsGroup.close();\n}", "summary_tokens": ["remove", "all", "metrics", "published", "by", "this", "task"], "project": "kafka"}
{"id": 3026, "code": "public static <K, V> StoreBuilder<WindowStore<K, V>> windowStoreBuilder(final WindowBytesStoreSupplier supplier,\n                                                                        final Serde<K> keySerde,\n                                                                        final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new WindowStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}", "summary_tokens": ["creates", "a", "store", "builder", "that", "can", "be", "used", "to", "build", "a", "window", "store"], "project": "kafka"}
{"id": 640, "code": "public void close() {\n    this.closed = true;\n    this.free.close();\n}", "summary_tokens": ["close", "this", "accumulator", "and", "force", "all", "the", "record", "buffers", "to", "be", "drained"], "project": "kafka"}
{"id": 1440, "code": "public void testPeerNotifiedOfHandshakeFailure(Args args) throws Exception {\n    args.sslServerConfigs = args.serverCertStores.getUntrustingConfig();\n    args.sslServerConfigs.putAll(args.sslConfigOverrides);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n\n        \n    for (int i = 0; i < 3; i++) {\n        String node = String.valueOf(i);\n        TestSslChannelBuilder serverChannelBuilder = new TestSslChannelBuilder(Mode.SERVER);\n        serverChannelBuilder.configure(args.sslServerConfigs);\n        serverChannelBuilder.flushDelayCount = i;\n        server = new NioEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n                SecurityProtocol.SSL, new TestSecurityConfig(args.sslServerConfigs),\n                \"localhost\", serverChannelBuilder, null, time);\n        server.start();\n        createSelector(args.sslClientConfigs);\n        InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n        selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n\n        NetworkTestUtils.waitForChannelClose(selector, node, ChannelState.State.AUTHENTICATION_FAILED);\n        server.close();\n        selector.close();\n        serverChannelBuilder.close();\n    }\n}", "summary_tokens": ["tests", "that", "handshake", "failures", "are", "propagated", "only", "after", "writes", "complete", "even", "when", "there", "are", "delays", "in", "writes", "to", "ensure", "that", "clients", "see", "an", "authentication", "exception", "rather", "than", "a", "connection", "failure"], "project": "kafka"}
{"id": 1882, "code": "public void reporters(Collection<ErrorReporter> reporters) {\n    Objects.requireNonNull(reporters);\n    this.reporters = reporters;\n}", "summary_tokens": ["set", "the", "error", "reporters", "for", "this", "connector"], "project": "kafka"}
{"id": 2756, "code": "public int hashCode() {\n    throw new UnsupportedOperationException(\"ProcessorRecordContext is unsafe for use in Hash collections\");\n}", "summary_tokens": ["equality", "is", "implemented", "in", "support", "of", "tests", "not", "for", "use", "in", "hash", "collections", "since", "this", "class", "is", "mutable"], "project": "kafka"}
{"id": 1064, "code": "public Errors error() {\n    return Errors.forCode(data.errorCode());\n}", "summary_tokens": ["possible", "error", "codes", "sasl", "authentication", "failed", "0", "authentication", "failed"], "project": "kafka"}
{"id": 1137, "code": "public double loginRefreshWindowFactor() {\n    return loginRefreshWindowFactor;\n}", "summary_tokens": ["background", "login", "refresh", "thread", "will", "sleep", "until", "the", "specified", "window", "factor", "relative", "to", "the", "credential", "s", "total", "lifetime", "has", "been", "reached", "at", "which", "time", "it", "will", "try", "to", "refresh", "the", "credential"], "project": "kafka"}
{"id": 1793, "code": "public ConnectMetrics metrics() {\n    return metrics;\n}", "summary_tokens": ["get", "the", "connect", "metrics", "that", "uses", "kafka", "metrics", "and", "manages", "the", "jmx", "reporter"], "project": "kafka"}
{"id": 2177, "code": "default Optional<ListenerName> controllerListenerName() {\n    return Optional.empty();\n}", "summary_tokens": ["the", "listener", "for", "the", "kraft", "cluster", "controller", "configured", "by", "controller"], "project": "kafka"}
{"id": 233, "code": "public DescribeConfigsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}", "summary_tokens": ["set", "the", "timeout", "in", "milliseconds", "for", "this", "operation", "or", "null", "if", "the", "default", "api", "timeout", "for", "the", "admin", "client", "should", "be", "used"], "project": "kafka"}
{"id": 96, "code": "private void handleCompletedReceives(List<ClientResponse> responses, long now) {\n    for (NetworkReceive receive : this.selector.completedReceives()) {\n        String source = receive.source();\n        InFlightRequest req = inFlightRequests.completeNext(source);\n\n        AbstractResponse response = parseResponse(receive.payload(), req.header);\n        if (throttleTimeSensor != null)\n            throttleTimeSensor.record(response.throttleTimeMs(), now);\n\n        if (log.isDebugEnabled()) {\n            log.debug(\"Received {} response from node {} for request with header {}: {}\",\n                req.header.apiKey(), req.destination, req.header, response);\n        }\n\n            \n        maybeThrottle(response, req.header.apiVersion(), req.destination, now);\n        if (req.isInternalRequest && response instanceof MetadataResponse)\n            metadataUpdater.handleSuccessfulResponse(req.header, now, (MetadataResponse) response);\n        else if (req.isInternalRequest && response instanceof ApiVersionsResponse)\n            handleApiVersionsResponse(responses, req, now, (ApiVersionsResponse) response);\n        else\n            responses.add(req.completed(response, now));\n    }\n}", "summary_tokens": ["handle", "any", "completed", "receives", "and", "update", "the", "response", "list", "with", "the", "responses", "received"], "project": "kafka"}
{"id": 2528, "code": "public static String producerPrefix(final String producerProp) {\n    return PRODUCER_PREFIX + producerProp;\n}", "summary_tokens": ["prefix", "a", "property", "with", "producer", "prefix"], "project": "kafka"}
{"id": 358, "code": "private void completeExceptionally(Map<K, Throwable> errors) {\n    if (!errors.isEmpty()) {\n        future.completeExceptionally(errors);\n        clear(errors.keySet());\n    }\n}", "summary_tokens": ["complete", "the", "future", "associated", "with", "the", "given", "key", "exceptionally"], "project": "kafka"}
{"id": 3002, "code": "default KeyValueIterator<Windowed<K>, V> backwardFetchAll(Instant timeFrom, Instant timeTo) throws IllegalArgumentException  {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["gets", "all", "the", "key", "value", "pairs", "that", "belong", "to", "the", "windows", "within", "in", "the", "given", "time", "range", "in", "backward", "order", "with", "respect", "to", "time", "from", "end", "to", "beginning", "of", "time"], "project": "kafka"}
{"id": 1572, "code": "public static void waitForCondition(\n    final TestCondition testCondition,\n    final long maxWaitMs,\n    final long pollIntervalMs,\n    Supplier<String> conditionDetailsSupplier\n) throws InterruptedException {\n    retryOnExceptionWithTimeout(maxWaitMs, pollIntervalMs, () -> {\n        String conditionDetailsSupplied = conditionDetailsSupplier != null ? conditionDetailsSupplier.get() : null;\n        String conditionDetails = conditionDetailsSupplied != null ? conditionDetailsSupplied : \"\";\n        assertTrue(testCondition.conditionMet(),\n            \"Condition not met within timeout \" + maxWaitMs + \". \" + conditionDetails);\n    });\n}", "summary_tokens": ["wait", "for", "condition", "to", "be", "met", "for", "at", "most", "max", "wait", "ms", "with", "a", "polling", "interval", "of", "poll", "interval", "ms", "and", "throw", "assertion", "failure", "otherwise"], "project": "kafka"}
{"id": 1916, "code": "ServerConnector findConnector(String protocol) {\n    for (Connector connector : jettyServer.getConnectors()) {\n        String connectorName = connector.getName();\n            \n            \n            \n            \n            \n        if (connectorName.startsWith(protocol + \"_\") && !ADMIN_SERVER_CONNECTOR_NAME.equals(connectorName))\n            return (ServerConnector) connector;\n    }\n\n    return null;\n}", "summary_tokens": ["locate", "a", "jetty", "connector", "for", "the", "standard", "non", "admin", "rest", "api", "that", "uses", "the", "given", "protocol"], "project": "kafka"}
{"id": 1988, "code": "public String bootstrapServers() {\n    return adminProps.getOrDefault(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"<unknown>\").toString();\n}", "summary_tokens": ["get", "the", "string", "containing", "the", "list", "of", "bootstrap", "server", "addresses", "to", "the", "kafka", "broker", "s", "to", "which", "the", "admin", "client", "connects"], "project": "kafka"}
{"id": 929, "code": "public void clear() {\n    Arrays.fill(this.values, null);\n}", "summary_tokens": ["empty", "all", "the", "values", "from", "this", "record"], "project": "kafka"}
{"id": 2347, "code": "public boolean recordGrantedVote(int remoteNodeId) {\n    State state = voteStates.get(remoteNodeId);\n    if (state == null) {\n        throw new IllegalArgumentException(\"Attempt to grant vote to non-voter \" + remoteNodeId);\n    } else if (state == State.REJECTED) {\n        throw new IllegalArgumentException(\"Attempt to grant vote from node \" + remoteNodeId +\n            \" which previously rejected our request\");\n    }\n    return voteStates.put(remoteNodeId, State.GRANTED) == State.UNRECORDED;\n}", "summary_tokens": ["record", "a", "granted", "vote", "from", "one", "of", "the", "voters"], "project": "kafka"}
{"id": 108, "code": "default void close() {\n    close(Duration.ofMillis(Long.MAX_VALUE));\n}", "summary_tokens": ["close", "the", "admin", "and", "release", "all", "associated", "resources"], "project": "kafka"}
{"id": 288, "code": "public ListConsumerGroupsOptions inStates(Set<ConsumerGroupState> states) {\n    this.states = (states == null) ? Collections.emptySet() : new HashSet<>(states);\n    return this;\n}", "summary_tokens": ["if", "states", "is", "set", "only", "groups", "in", "these", "states", "will", "be", "returned", "by", "list", "consumer", "groups", "otherwise", "all", "groups", "are", "returned"], "project": "kafka"}
{"id": 3137, "code": "public int checkForRestoredEntries(final KeyValueStore<K, V> store) {\n    int missing = 0;\n    for (final KeyValue<byte[], byte[]> kv : restorableEntries) {\n        if (kv != null) {\n            final V value = store.get(stateSerdes.keyFrom(kv.key));\n            if (!Objects.equals(value, stateSerdes.valueFrom(kv.value))) {\n                ++missing;\n            }\n        }\n    }\n    return missing;\n}", "summary_tokens": ["utility", "method", "that", "will", "count", "the", "number", "of", "add", "entry", "to", "restore", "log", "object", "object", "restore", "entries", "missing", "from", "the", "supplied", "store"], "project": "kafka"}
{"id": 2666, "code": "static public <T> Serde<Windowed<T>> sessionWindowedSerdeFrom(final Class<T> type) {\n    return new SessionWindowedSerde<>(Serdes.serdeFrom(type));\n}", "summary_tokens": ["construct", "a", "session", "windowed", "serde", "object", "for", "the", "specified", "inner", "class", "type"], "project": "kafka"}
{"id": 2951, "code": "public Optional<K> getUpperBound() {\n    return upper;\n}", "summary_tokens": ["the", "upper", "bound", "of", "the", "query", "if", "specified"], "project": "kafka"}
{"id": 1937, "code": "public List<Map<String, String>> allTaskConfigs(String connector) {\n    Map<Integer, Map<String, String>> taskConfigs = new TreeMap<>();\n    for (Map.Entry<ConnectorTaskId, Map<String, String>> taskConfigEntry : this.taskConfigs.entrySet()) {\n        if (taskConfigEntry.getKey().connector().equals(connector)) {\n            Map<String, String> configs = taskConfigEntry.getValue();\n            if (configTransformer != null) {\n                configs = configTransformer.transform(connector, configs);\n            }\n            taskConfigs.put(taskConfigEntry.getKey().task(), configs);\n        }\n    }\n    return Collections.unmodifiableList(new ArrayList<>(taskConfigs.values()));\n}", "summary_tokens": ["get", "all", "task", "configs", "for", "a", "connector"], "project": "kafka"}
{"id": 1861, "code": "public short currentProtocolVersion() {\n    return coordinator.currentProtocolVersion();\n}", "summary_tokens": ["get", "the", "version", "of", "the", "connect", "protocol", "that", "is", "currently", "active", "in", "the", "group", "of", "workers"], "project": "kafka"}
{"id": 2832, "code": "public StreamsMetadata getLocalMetadata() {\n    return localMetadata.get();\n}", "summary_tokens": ["get", "the", "streams", "metadata", "s", "for", "the", "local", "instance", "in", "a", "kafka", "streams", "application"], "project": "kafka"}
{"id": 1281, "code": "final public List<E> findAll(E key) {\n    if (key == null || size() == 0) {\n        return Collections.<E>emptyList();\n    }\n    ArrayList<E> results = new ArrayList<>();\n    int slot = slot(elements, key);\n    for (int seen = 0; seen < elements.length; seen++) {\n        Element element = elements[slot];\n        if (element == null) {\n            break;\n        }\n        if (key.elementKeysAreEqual(element)) {\n            @SuppressWarnings(\"unchecked\")\n            E result = (E) elements[slot];\n            results.add(result);\n        }\n        slot = (slot + 1) % elements.length;\n    }\n    return results;\n}", "summary_tokens": ["returns", "all", "of", "the", "elements", "e", "in", "the", "collection", "such", "that", "key"], "project": "kafka"}
{"id": 512, "code": "public RuntimeException exception() {\n    if (!failed())\n        throw new IllegalStateException(\"Attempt to retrieve exception from future which hasn't failed\");\n    return (RuntimeException) result.get();\n}", "summary_tokens": ["get", "the", "exception", "from", "a", "failed", "result", "only", "available", "if", "the", "request", "failed", "the", "exception", "set", "in", "raise", "runtime", "exception", "illegal", "state", "exception", "if", "the", "future", "is", "not", "complete", "or", "completed", "successfully"], "project": "kafka"}
{"id": 2032, "code": "public StartAndStopLatch expectedStarts(int expectedStarts, boolean includeTasks) {\n    List<StartAndStopLatch> taskLatches = includeTasks\n            ? taskHandles.values().stream()\n            .map(task -> task.expectedStarts(expectedStarts))\n            .collect(Collectors.toList())\n            : Collections.emptyList();\n    return startAndStopCounter.expectedStarts(expectedStarts, taskLatches);\n}", "summary_tokens": ["obtain", "a", "start", "and", "stop", "latch", "that", "can", "be", "used", "to", "wait", "until", "the", "connector", "using", "this", "handle", "and", "optionally", "all", "tasks", "using", "task", "handle", "have", "completed", "the", "expected", "number", "of", "starts", "starting", "the", "counts", "at", "the", "time", "this", "method", "is", "called"], "project": "kafka"}
{"id": 419, "code": "public Map<TopicPartition, OffsetAndMetadata> divergentOffsets() {\n    return divergentOffsets;\n}", "summary_tokens": ["get", "the", "divergent", "offsets", "for", "the", "partitions", "which", "were", "truncated"], "project": "kafka"}
{"id": 1296, "code": "public void update(long currentTimeMs) {\n    this.currentTimeMs = Math.max(currentTimeMs, this.currentTimeMs);\n}", "summary_tokens": ["update", "the", "cached", "current", "time", "to", "a", "specific", "value"], "project": "kafka"}
{"id": 3256, "code": "public Map<String, PartitionsSpec> materialize() {\n    HashMap<String, PartitionsSpec> all = new HashMap<>();\n    for (Map.Entry<String, PartitionsSpec> entry : map.entrySet()) {\n        String topicName = entry.getKey();\n        PartitionsSpec partitions = entry.getValue();\n        for (String expandedTopicName : StringExpander.expand(topicName))\n            all.put(expandedTopicName, partitions);\n    }\n    return all;\n}", "summary_tokens": ["enumerate", "the", "partitions", "inside", "this", "topics", "spec"], "project": "kafka"}
{"id": 2984, "code": "public String getFailureMessage() {\n    throw new IllegalArgumentException(\n        \"Cannot get failure message because this query did not fail.\"\n    );\n}", "summary_tokens": ["if", "this", "partition", "failed", "to", "execute", "the", "query", "returns", "the", "failure", "message"], "project": "kafka"}
{"id": 1289, "code": "public static ThreadFactory createThreadFactory(final String pattern,\n                                                final boolean daemon) {\n    return new ThreadFactory() {\n        private final AtomicLong threadEpoch = new AtomicLong(0);\n\n        @Override\n        public Thread newThread(Runnable r) {\n            String threadName;\n            if (pattern.contains(\"%d\")) {\n                threadName = String.format(pattern, threadEpoch.addAndGet(1));\n            } else {\n                threadName = pattern;\n            }\n            Thread thread = new Thread(r, threadName);\n            thread.setDaemon(daemon);\n            return thread;\n        }\n    };\n}", "summary_tokens": ["create", "a", "new", "thread", "factory"], "project": "kafka"}
{"id": 937, "code": "public Optional<Type> arrayElementType() {\n    return Optional.empty();\n}", "summary_tokens": ["if", "the", "type", "is", "an", "array", "return", "the", "type", "of", "the", "array", "elements"], "project": "kafka"}
{"id": 388, "code": "public Set<TopicPartition> assignment() {\n    acquireAndEnsureOpen();\n    try {\n        return Collections.unmodifiableSet(this.subscriptions.assignedPartitions());\n    } finally {\n        release();\n    }\n}", "summary_tokens": ["get", "the", "set", "of", "partitions", "currently", "assigned", "to", "this", "consumer"], "project": "kafka"}
{"id": 1022, "code": "private int estimatedBytesWritten() {\n    if (compressionType == CompressionType.NONE) {\n        return batchHeaderSizeInBytes + uncompressedRecordsSizeInBytes;\n    } else {\n            \n        return batchHeaderSizeInBytes + (int) (uncompressedRecordsSizeInBytes * estimatedCompressionRatio * COMPRESSION_RATE_ESTIMATION_FACTOR);\n    }\n}", "summary_tokens": ["get", "an", "estimate", "of", "the", "number", "of", "bytes", "written", "based", "on", "the", "estimation", "factor", "hard", "coded", "in", "compression", "type"], "project": "kafka"}
{"id": 410, "code": "public Map<TopicPartition, Long> endOffsets(Collection<TopicPartition> partitions, Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        return fetcher.endOffsets(partitions, time.timer(timeout));\n    } finally {\n        release();\n    }\n}", "summary_tokens": ["get", "the", "end", "offsets", "for", "the", "given", "partitions"], "project": "kafka"}
{"id": 236, "code": "public Map<ConfigResource, KafkaFuture<Config>> values() {\n    return futures;\n}", "summary_tokens": ["return", "a", "map", "from", "resources", "to", "futures", "which", "can", "be", "used", "to", "check", "the", "status", "of", "the", "configuration", "for", "each", "resource"], "project": "kafka"}
{"id": 322, "code": "public String name() {\n    return name;\n}", "summary_tokens": ["the", "name", "of", "the", "topic", "to", "be", "created"], "project": "kafka"}
{"id": 3168, "code": "public final Set<String> producedTopicNames() {\n    return Collections.unmodifiableSet(outputRecordsByTopic.keySet());\n}", "summary_tokens": ["get", "all", "the", "names", "of", "all", "the", "topics", "to", "which", "records", "have", "been", "produced", "during", "the", "test", "run"], "project": "kafka"}
{"id": 58, "code": "synchronized Optional<MetadataResponse.PartitionMetadata> partitionMetadataIfCurrent(TopicPartition topicPartition) {\n    Integer epoch = lastSeenLeaderEpochs.get(topicPartition);\n    Optional<MetadataResponse.PartitionMetadata> partitionMetadata = cache.partitionMetadata(topicPartition);\n    if (epoch == null) {\n            \n        return partitionMetadata;\n    } else {\n        return partitionMetadata.filter(metadata ->\n                metadata.leaderEpoch.orElse(NO_PARTITION_LEADER_EPOCH).equals(epoch));\n    }\n}", "summary_tokens": ["return", "the", "cached", "partition", "info", "if", "it", "exists", "and", "a", "newer", "leader", "epoch", "isn", "t", "known", "about"], "project": "kafka"}
{"id": 9, "code": "public InetAddress currentAddress(String id) throws UnknownHostException {\n    return nodeState(id).currentAddress();\n}", "summary_tokens": ["returns", "a", "resolved", "address", "for", "the", "given", "connection", "resolving", "it", "if", "necessary"], "project": "kafka"}
{"id": 1537, "code": "public void oldSaslPlainSslClientWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(true, false, SecurityProtocol.SASL_SSL, \"PLAIN\");\n}", "summary_tokens": ["tests", "sasl", "plain", "authentication", "failure", "over", "ssl", "with", "old", "version", "of", "client", "that", "does", "not", "support", "sasl", "authenticate", "headers", "and", "new", "version", "of", "server"], "project": "kafka"}
{"id": 3058, "code": "public Set<TopicPartition> topicPartitions() {\n    return topicPartitions;\n}", "summary_tokens": ["topic", "partitions", "consumed", "by", "the", "instance", "as", "an", "active", "replica"], "project": "kafka"}
{"id": 2983, "code": "public FailureReason getFailureReason() {\n    throw new IllegalArgumentException(\n        \"Cannot get failure reason because this query did not fail.\"\n    );\n}", "summary_tokens": ["if", "this", "partition", "failed", "to", "execute", "the", "query", "returns", "the", "reason"], "project": "kafka"}
{"id": 123, "code": "default CreatePartitionsResult createPartitions(Map<String, NewPartitions> newPartitions) {\n    return createPartitions(newPartitions, new CreatePartitionsOptions());\n}", "summary_tokens": ["increase", "the", "number", "of", "partitions", "of", "the", "topics", "given", "as", "the", "keys", "of", "new", "partitions", "according", "to", "the", "corresponding", "values"], "project": "kafka"}
{"id": 2556, "code": "public static <K, V> Branched<K, V> withFunction(\n        final Function<? super KStream<K, V>, ? extends KStream<K, V>> chain, final String name) {\n    Objects.requireNonNull(chain, \"chain function cannot be null\");\n    return new Branched<>(name, chain, null);\n}", "summary_tokens": ["create", "an", "instance", "of", "branched", "with", "provided", "chain", "function", "and", "branch", "name", "suffix"], "project": "kafka"}
{"id": 1847, "code": "public static ByteBuffer serializeMetadata(ExtendedWorkerState workerState, boolean sessioned) {\n    Struct configState = new Struct(CONFIG_STATE_V1)\n            .set(URL_KEY_NAME, workerState.url())\n            .set(CONFIG_OFFSET_KEY_NAME, workerState.offset());\n        \n    Struct allocation = new Struct(ALLOCATION_V1)\n            .set(ALLOCATION_KEY_NAME, serializeAssignment(workerState.assignment(), sessioned));\n    Struct connectProtocolHeader = sessioned ? CONNECT_PROTOCOL_HEADER_V2 : CONNECT_PROTOCOL_HEADER_V1;\n    ByteBuffer buffer = ByteBuffer.allocate(connectProtocolHeader.sizeOf()\n                                            + CONFIG_STATE_V1.sizeOf(configState)\n                                            + ALLOCATION_V1.sizeOf(allocation));\n    connectProtocolHeader.writeTo(buffer);\n    CONFIG_STATE_V1.write(buffer, configState);\n    ALLOCATION_V1.write(buffer, allocation);\n    buffer.flip();\n    return buffer;\n}", "summary_tokens": ["the", "fields", "are", "serialized", "in", "sequence", "as", "follows", "subscription", "v", "0", "pre", "version", "int", "0", "url", "string", "config", "offset", "int", "0", "current", "assignment", "byte", "pre"], "project": "kafka"}
{"id": 1278, "code": "public Set<E> valuesSet() {\n    return new ImplicitLinkedHashCollectionSetView();\n}", "summary_tokens": ["returns", "a", "set", "view", "of", "the", "elements", "contained", "in", "the", "collection"], "project": "kafka"}
{"id": 3262, "code": "public void testProcessStop() throws Exception {\n    if (OperatingSystem.IS_WINDOWS) return;\n    ExternalCommandWorker worker =\n        new ExternalCommandWorkerBuilder(\"testStopTask\").\n            command(\"sleep\", \"3600000\").build();\n    KafkaFutureImpl<String> doneFuture = new KafkaFutureImpl<>();\n    worker.start(null, new AgentWorkerStatusTracker(), doneFuture);\n    worker.stop(null);\n        \n        \n    assertTrue(doneFuture.get().startsWith(\"exited with return code \"));\n}", "summary_tokens": ["test", "running", "a", "process", "which", "times", "out"], "project": "kafka"}
{"id": 980, "code": "public TimestampAndOffset searchForTimestamp(long targetTimestamp, int startingPosition, long startingOffset) {\n    for (RecordBatch batch : batchesFrom(startingPosition)) {\n        if (batch.maxTimestamp() >= targetTimestamp) {\n                \n            for (Record record : batch) {\n                long timestamp = record.timestamp();\n                if (timestamp >= targetTimestamp && record.offset() >= startingOffset)\n                    return new TimestampAndOffset(timestamp, record.offset(),\n                            maybeLeaderEpoch(batch.partitionLeaderEpoch()));\n            }\n        }\n    }\n    return null;\n}", "summary_tokens": ["search", "forward", "for", "the", "first", "message", "that", "meets", "the", "following", "requirements", "message", "s", "timestamp", "is", "greater", "than", "or", "equals", "to", "the", "target", "timestamp"], "project": "kafka"}
{"id": 167, "code": "public Collection<ConfigEntry> entries() {\n    return Collections.unmodifiableCollection(entries.values());\n}", "summary_tokens": ["configuration", "entries", "for", "a", "resource"], "project": "kafka"}
{"id": 2013, "code": "public NewTopic newTopic(String topic) {\n    TopicAdmin.NewTopicBuilder builder = new TopicAdmin.NewTopicBuilder(topic);\n    return builder.partitions(numPartitions)\n            .replicationFactor(replicationFactor)\n            .config(otherConfigs)\n            .build();\n}", "summary_tokens": ["return", "the", "description", "for", "a", "new", "topic", "with", "the", "given", "topic", "name", "with", "the", "topic", "settings", "defined", "for", "this", "topic", "creation", "group"], "project": "kafka"}
{"id": 2352, "code": "public Set<Integer> rejectingVoters() {\n    return votersInState(State.REJECTED);\n}", "summary_tokens": ["get", "the", "set", "of", "voters", "that", "have", "rejected", "our", "candidacy"], "project": "kafka"}
{"id": 964, "code": "static int estimateBatchSizeUpperBound(ByteBuffer key, ByteBuffer value, Header[] headers) {\n    return RECORD_BATCH_OVERHEAD + DefaultRecord.recordSizeUpperBound(key, value, headers);\n}", "summary_tokens": ["get", "an", "upper", "bound", "on", "the", "size", "of", "a", "batch", "with", "only", "a", "single", "record", "using", "a", "given", "key", "and", "value"], "project": "kafka"}
{"id": 441, "code": "final boolean hasMatchingGenerationId(int generationId) {\n    return !generation.equals(Generation.NO_GENERATION) && generation.generationId == generationId;\n}", "summary_tokens": ["check", "whether", "given", "generation", "id", "is", "matching", "the", "record", "within", "current", "generation"], "project": "kafka"}
{"id": 2305, "code": "public void testConfigurationOperations() throws Throwable {\n    try (\n        LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty());\n        QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> {\n            b.setConfigSchema(SCHEMA);\n        })\n    ) {\n        controlEnv.activeController().registerBroker(ANONYMOUS_CONTEXT,\n            new BrokerRegistrationRequestData().\n            setFeatures(brokerFeatures(MetadataVersion.IBP_3_0_IV1, MetadataVersion.IBP_3_3_IV3)).\n            setBrokerId(0).\n            setClusterId(logEnv.clusterId())).get();\n        testConfigurationOperations(controlEnv.activeController());\n    }\n}", "summary_tokens": ["test", "setting", "some", "configuration", "values", "and", "reading", "them", "back"], "project": "kafka"}
{"id": 1931, "code": "public SessionKey sessionKey() {\n    return sessionKey;\n}", "summary_tokens": ["get", "the", "latest", "session", "key", "from", "the", "config", "state", "the", "session", "key", "session", "key", "may", "be", "null", "if", "no", "key", "has", "been", "read", "yet"], "project": "kafka"}
{"id": 978, "code": "public int truncateTo(int targetSize) throws IOException {\n    int originalSize = sizeInBytes();\n    if (targetSize > originalSize || targetSize < 0)\n        throw new KafkaException(\"Attempt to truncate log segment \" + file + \" to \" + targetSize + \" bytes failed, \" +\n                \" size of this log segment is \" + originalSize + \" bytes.\");\n    if (targetSize < (int) channel.size()) {\n        channel.truncate(targetSize);\n        size.set(targetSize);\n    }\n    return originalSize - targetSize;\n}", "summary_tokens": ["truncate", "this", "file", "message", "set", "to", "the", "given", "size", "in", "bytes"], "project": "kafka"}
{"id": 2798, "code": "static void registerStateStores(final Logger log,\n                                final String logPrefix,\n                                final ProcessorTopology topology,\n                                final ProcessorStateManager stateMgr,\n                                final StateDirectory stateDirectory,\n                                final InternalProcessorContext processorContext) {\n    if (topology.stateStores().isEmpty()) {\n        return;\n    }\n\n    final TaskId id = stateMgr.taskId();\n    if (!stateDirectory.lock(id)) {\n        throw new LockException(String.format(\"%sFailed to lock the state directory for task %s\", logPrefix, id));\n    }\n    log.debug(\"Acquired state directory lock\");\n\n    final boolean storeDirsEmpty = stateDirectory.directoryForTaskIsEmpty(id);\n\n    stateMgr.registerStateStores(topology.stateStores(), processorContext);\n    log.debug(\"Registered state stores\");\n\n        \n        \n        \n    stateMgr.initializeStoreOffsetsFromCheckpoint(storeDirsEmpty);\n    log.debug(\"Initialized state stores\");\n}", "summary_tokens": ["streams", "exception", "if", "the", "store", "s", "changelog", "does", "not", "contain", "the", "partition"], "project": "kafka"}
{"id": 2302, "code": "public void testValidateNewAcl() {\n    AclControlManager.validateNewAcl(new AclBinding(\n        new ResourcePattern(TOPIC, \"*\", LITERAL),\n        new AccessControlEntry(\"User:*\", \"*\", ALTER, ALLOW)));\n    assertEquals(\"Invalid patternType UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(TOPIC, \"*\", PatternType.UNKNOWN),\n                new AccessControlEntry(\"User:*\", \"*\", ALTER, ALLOW)))).\n            getMessage());\n    assertEquals(\"Invalid resourceType UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(ResourceType.UNKNOWN, \"*\", LITERAL),\n                new AccessControlEntry(\"User:*\", \"*\", ALTER, ALLOW)))).\n            getMessage());\n    assertEquals(\"Invalid operation UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(TOPIC, \"*\", LITERAL),\n                new AccessControlEntry(\"User:*\", \"*\", AclOperation.UNKNOWN, ALLOW)))).\n            getMessage());\n    assertEquals(\"Invalid permissionType UNKNOWN\",\n        assertThrows(InvalidRequestException.class, () ->\n            AclControlManager.validateNewAcl(new AclBinding(\n                new ResourcePattern(TOPIC, \"*\", LITERAL),\n                new AccessControlEntry(\"User:*\", \"*\", ALTER, AclPermissionType.UNKNOWN)))).\n            getMessage());\n}", "summary_tokens": ["verify", "that", "validate", "new", "acl", "catches", "invalid", "acls"], "project": "kafka"}
{"id": 1037, "code": "final ByteBuffer serializeWithHeader(ResponseHeader header, short version) {\n    return RequestUtils.serialize(header.data(), header.headerVersion(), data(), version);\n}", "summary_tokens": ["serializes", "header", "and", "body", "without", "prefixing", "with", "size", "unlike", "to", "send", "which", "does", "include", "a", "size", "prefix"], "project": "kafka"}
{"id": 831, "code": "default void contextChange(MetricsContext metricsContext) {\n}", "summary_tokens": ["sets", "the", "context", "labels", "for", "the", "service", "or", "library", "exposing", "metrics"], "project": "kafka"}
{"id": 3250, "code": "public final long startMs() {\n    return startMs;\n}", "summary_tokens": ["get", "the", "target", "start", "time", "of", "this", "task", "in", "ms"], "project": "kafka"}
{"id": 397, "code": "public void seek(TopicPartition partition, OffsetAndMetadata offsetAndMetadata) {\n    long offset = offsetAndMetadata.offset();\n    if (offset < 0) {\n        throw new IllegalArgumentException(\"seek offset must not be a negative number\");\n    }\n\n    acquireAndEnsureOpen();\n    try {\n        if (offsetAndMetadata.leaderEpoch().isPresent()) {\n            log.info(\"Seeking to offset {} for partition {} with epoch {}\",\n                    offset, partition, offsetAndMetadata.leaderEpoch().get());\n        } else {\n            log.info(\"Seeking to offset {} for partition {}\", offset, partition);\n        }\n        Metadata.LeaderAndEpoch currentLeaderAndEpoch = this.metadata.currentLeader(partition);\n        SubscriptionState.FetchPosition newPosition = new SubscriptionState.FetchPosition(\n                offsetAndMetadata.offset(),\n                offsetAndMetadata.leaderEpoch(),\n                currentLeaderAndEpoch);\n        this.updateLastSeenEpochIfNewer(partition, offsetAndMetadata);\n        this.subscriptions.seekUnvalidated(partition, newPosition);\n    } finally {\n        release();\n    }\n}", "summary_tokens": ["overrides", "the", "fetch", "offsets", "that", "the", "consumer", "will", "use", "on", "the", "next", "poll", "duration", "poll", "timeout"], "project": "kafka"}
{"id": 3091, "code": "public static void purgeLocalStreamsState(final Collection<Properties> streamsConfigurations) throws IOException {\n    for (final Properties streamsConfig : streamsConfigurations) {\n        purgeLocalStreamsState(streamsConfig);\n    }\n}", "summary_tokens": ["removes", "local", "state", "stores"], "project": "kafka"}
{"id": 2696, "code": "public int hashCode() {\n    throw new UnsupportedOperationException(\"To is unsafe for use in Hash collections\");\n}", "summary_tokens": ["equality", "is", "implemented", "in", "support", "of", "tests", "not", "for", "use", "in", "hash", "collections", "since", "this", "class", "is", "mutable"], "project": "kafka"}
{"id": 1253, "code": "private static String toString(final byte[] b, int off, int len) {\n    StringBuilder result = new StringBuilder();\n\n    if (b == null)\n        return result.toString();\n\n        \n    if (off >= b.length)\n        return result.toString();\n\n    if (off + len > b.length)\n        len = b.length - off;\n\n    for (int i = off; i < off + len; ++i) {\n        int ch = b[i] & 0xFF;\n        if (ch >= ' ' && ch <= '~' && ch != '\\\\') {\n            result.append((char) ch);\n        } else {\n            result.append(\"\\\\x\");\n            result.append(HEX_CHARS_UPPER[ch / 0x10]);\n            result.append(HEX_CHARS_UPPER[ch % 0x10]);\n        }\n    }\n    return result.toString();\n}", "summary_tokens": ["write", "a", "printable", "representation", "of", "a", "byte", "array"], "project": "kafka"}
{"id": 3126, "code": "public void testStickyTaskAssignorLargePartitionCount() {\n    completeLargeAssignment(2_000, 2, 1, 1, StickyTaskAssignor.class);\n}", "summary_tokens": ["sticky", "task", "assignor", "tests"], "project": "kafka"}
{"id": 348, "code": "public String name() {\n    return name;\n}", "summary_tokens": ["the", "name", "of", "the", "topic"], "project": "kafka"}
{"id": 1147, "code": "public List<String> splits() {\n    return splits;\n}", "summary_tokens": ["return", "the", "0", "or", "0", "dot", "separated", "sections", "of", "the", "jwt", "compact", "serialization"], "project": "kafka"}
{"id": 1690, "code": "public void shouldFailToConvertToListFromStringWithExtraDelimiters() {\n    assertThrows(DataException.class, () -> Values.convertToList(Schema.STRING_SCHEMA, \"[1, 2, 3,,,]\"));\n}", "summary_tokens": ["this", "is", "technically", "invalid", "json", "and", "we", "don", "t", "want", "to", "simply", "ignore", "the", "blank", "elements"], "project": "kafka"}
{"id": 2409, "code": "default void scheduleDeferred(String tag,\n                              Function<OptionalLong, OptionalLong> deadlineNsCalculator,\n                              Event event) {\n    enqueue(EventInsertionType.DEFERRED, tag, deadlineNsCalculator, event);\n}", "summary_tokens": ["schedule", "an", "event", "to", "be", "run", "at", "a", "specific", "time"], "project": "kafka"}
{"id": 2926, "code": "public final KafkaFuture<Void> all() {\n    if (resetOffsetsFuture == null) {\n        return removeTopologyFuture;\n    } else {\n        return resetOffsetsFuture;\n    }\n}", "summary_tokens": ["a", "kafka", "future", "that", "completes", "successfully", "when", "all", "threads", "on", "this", "client", "have", "removed", "the", "corresponding", "named", "topology", "and", "all", "source", "topic", "offsets", "have", "been", "deleted", "if", "applicable"], "project": "kafka"}
{"id": 1730, "code": "public Optional<RestartPlan> buildRestartPlan(RestartRequest request) {\n    String connectorName = request.connectorName();\n    ConnectorStatus connectorStatus = statusBackingStore.get(connectorName);\n    if (connectorStatus == null) {\n        return Optional.empty();\n    }\n\n        \n    AbstractStatus.State connectorState = request.shouldRestartConnector(connectorStatus) ? AbstractStatus.State.RESTARTING : connectorStatus.state();\n    ConnectorStateInfo.ConnectorState connectorInfoState = new ConnectorStateInfo.ConnectorState(\n            connectorState.toString(),\n            connectorStatus.workerId(),\n            connectorStatus.trace()\n    );\n\n        \n    List<ConnectorStateInfo.TaskState> taskStates = statusBackingStore.getAll(connectorName)\n            .stream()\n            .map(taskStatus -> {\n                AbstractStatus.State taskState = request.shouldRestartTask(taskStatus) ? AbstractStatus.State.RESTARTING : taskStatus.state();\n                return new ConnectorStateInfo.TaskState(\n                        taskStatus.id().task(),\n                        taskState.toString(),\n                        taskStatus.workerId(),\n                        taskStatus.trace()\n                );\n            })\n            .collect(Collectors.toList());\n        \n    Map<String, String> conf = rawConfig(connectorName);\n    ConnectorStateInfo stateInfo = new ConnectorStateInfo(\n            connectorName,\n            connectorInfoState,\n            taskStates,\n            conf == null ? ConnectorType.UNKNOWN : connectorTypeForClass(conf.get(ConnectorConfig.CONNECTOR_CLASS_CONFIG))\n    );\n    return Optional.of(new RestartPlan(request, stateInfo));\n}", "summary_tokens": ["build", "the", "restart", "plan", "that", "describes", "what", "should", "and", "should", "not", "be", "restarted", "given", "the", "restart", "request", "and", "the", "current", "status", "of", "the", "connector", "and", "task", "instances"], "project": "kafka"}
{"id": 2977, "code": "public FailureReason getFailureReason() {\n    return failureReason;\n}", "summary_tokens": ["if", "this", "partition", "failed", "to", "execute", "the", "query", "returns", "the", "reason"], "project": "kafka"}
{"id": 158, "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["return", "a", "future", "which", "succeeds", "only", "if", "all", "the", "alter", "configs", "operations", "succeed"], "project": "kafka"}
{"id": 455, "code": "public long timeToNextPoll(long now) {\n    if (!autoCommitEnabled)\n        return timeToNextHeartbeat(now);\n\n    return Math.min(nextAutoCommitTimer.remainingMs(), timeToNextHeartbeat(now));\n}", "summary_tokens": ["return", "the", "time", "to", "the", "next", "needed", "invocation", "of", "consumer", "network", "client", "poll", "timer"], "project": "kafka"}
{"id": 3232, "code": "public TasksResponse tasks(TasksRequest request) throws ExecutionException, InterruptedException {\n    return executor.submit(new GetTasksResponse(request)).get();\n}", "summary_tokens": ["get", "information", "about", "the", "tasks", "being", "managed"], "project": "kafka"}
{"id": 269, "code": "public KafkaFuture<Short> epochId(String transactionalId) {\n    return findAndApply(transactionalId, p -> p.epoch);\n}", "summary_tokens": ["returns", "a", "future", "that", "provides", "the", "epoch", "id", "generated", "while", "initializing", "the", "given", "transaction", "when", "the", "request", "completes"], "project": "kafka"}
{"id": 153, "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["returns", "a", "future", "which", "succeeds", "only", "if", "all", "quota", "alterations", "succeed"], "project": "kafka"}
{"id": 2497, "code": "public Set<org.apache.kafka.streams.processor.ThreadMetadata> localThreadsMetadata() {\n    return metadataForLocalThreads().stream().map(threadMetadata -> new org.apache.kafka.streams.processor.ThreadMetadata(\n            threadMetadata.threadName(),\n            threadMetadata.threadState(),\n            threadMetadata.consumerClientId(),\n            threadMetadata.restoreConsumerClientId(),\n            threadMetadata.producerClientIds(),\n            threadMetadata.adminClientId(),\n            threadMetadata.activeTasks().stream().map(taskMetadata -> new org.apache.kafka.streams.processor.TaskMetadata(\n                    taskMetadata.taskId().toString(),\n                    taskMetadata.topicPartitions(),\n                    taskMetadata.committedOffsets(),\n                    taskMetadata.endOffsets(),\n                    taskMetadata.timeCurrentIdlingStarted())\n            ).collect(Collectors.toSet()),\n            threadMetadata.standbyTasks().stream().map(taskMetadata -> new org.apache.kafka.streams.processor.TaskMetadata(\n                    taskMetadata.taskId().toString(),\n                    taskMetadata.topicPartitions(),\n                    taskMetadata.committedOffsets(),\n                    taskMetadata.endOffsets(),\n                    taskMetadata.timeCurrentIdlingStarted())\n            ).collect(Collectors.toSet())))\n            .collect(Collectors.toSet());\n}", "summary_tokens": ["returns", "runtime", "information", "about", "the", "local", "threads", "of", "this", "kafka", "streams", "instance"], "project": "kafka"}
{"id": 2142, "code": "public void assertTopicSettings(String topicName, int replicas, int partitions, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkTopicSettings(\n                topicName,\n                replicas,\n                partitions\n            ).orElse(false),\n            VALIDATION_DURATION_MS,\n            \"Topic \" + topicName + \" does not exist or does not have exactly \"\n                    + partitions + \" partitions or at least \"\n                    + replicas + \" per partition\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "the", "named", "topic", "is", "configured", "to", "have", "the", "specified", "replication", "factor", "and", "number", "of", "partitions"], "project": "kafka"}
{"id": 2710, "code": "public static <KIn, VIn> FixedKeyRecord<KIn, VIn> create(final Record<KIn, VIn> record) {\n    return new FixedKeyRecord<>(\n        record.key(),\n        record.value(),\n        record.timestamp(),\n        record.headers()\n    );\n}", "summary_tokens": ["only", "allowed", "way", "to", "create", "fixed", "key", "record", "s"], "project": "kafka"}
{"id": 1130, "code": "public String tokenValue() {\n    return tokenValue;\n}", "summary_tokens": ["return", "the", "always", "non", "null", "token", "value"], "project": "kafka"}
{"id": 2588, "code": "public Joined<K, V, VO> withValueSerde(final Serde<V> valueSerde) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}", "summary_tokens": ["set", "the", "value", "serde", "to", "be", "used"], "project": "kafka"}
{"id": 730, "code": "public final AccessControlEntryFilter entryFilter() {\n    return entryFilter;\n}", "summary_tokens": ["the", "access", "control", "entry", "filter"], "project": "kafka"}
{"id": 2430, "code": "public Path timeIndex() {\n    return timeIndex;\n}", "summary_tokens": ["time", "index", "file", "of", "this", "segment"], "project": "kafka"}
{"id": 1788, "code": "public static String taskTransactionalId(String groupId, String connector, int taskId) {\n    return String.format(\"%s-%s-%d\", groupId, connector, taskId);\n}", "summary_tokens": ["the", "producer", "config", "transactional", "id", "config", "transactional", "id", "to", "use", "for", "a", "task", "that", "writes", "records", "and", "or", "offsets", "in", "a", "transaction"], "project": "kafka"}
{"id": 2058, "code": "public void commit(int batchSize) {\n    if (recordsToCommitLatch != null) {\n        IntStream.range(0, batchSize).forEach(i -> recordsToCommitLatch.countDown());\n    }\n    connectorHandle.commit(batchSize);\n}", "summary_tokens": ["record", "commit", "on", "a", "batch", "of", "messages", "from", "the", "task", "and", "the", "connector", "overall"], "project": "kafka"}
{"id": 1043, "code": "public String messageWithFallback() {\n    if (message == null)\n        return error.message();\n    return message;\n}", "summary_tokens": ["if", "message", "is", "defined", "return", "it"], "project": "kafka"}
{"id": 2060, "code": "public void expectedCommits(int expected) {\n    expectedRecords = expected;\n    recordsToCommitLatch = new CountDownLatch(expected);\n}", "summary_tokens": ["set", "the", "number", "of", "expected", "record", "commits", "performed", "by", "this", "task"], "project": "kafka"}
{"id": 1773, "code": "public int task() {\n    return task;\n}", "summary_tokens": ["get", "the", "id", "of", "the", "task", "that", "stored", "the", "topic", "status"], "project": "kafka"}
{"id": 878, "code": "", "summary_tokens": ["performs", "ssl", "handshake", "hence", "is", "a", "no", "op", "for", "the", "non", "secure", "implementation"], "project": "kafka"}
{"id": 3184, "code": "public Headers headers() {\n    return headers;\n}", "summary_tokens": ["returns", "the", "headers", "of", "the", "current", "input", "record", "could", "be", "null", "if", "it", "is", "not", "available"], "project": "kafka"}
{"id": 2764, "code": "public void flush() {\n    log.debug(\"Flushing record collector\");\n    streamsProducer.flush();\n    checkForException();\n}", "summary_tokens": ["streams", "exception", "fatal", "error", "that", "should", "cause", "the", "thread", "to", "die", "task", "migrated", "exception", "recoverable", "error", "that", "would", "cause", "the", "task", "to", "be", "removed"], "project": "kafka"}
{"id": 3223, "code": "public static int perSecToPerPeriod(float perSec, long periodMs) {\n    float period = ((float) periodMs) / 1000.0f;\n    float perPeriod = perSec * period;\n    perPeriod = Math.max(1.0f, perPeriod);\n    return (int) perPeriod;\n}", "summary_tokens": ["convert", "a", "rate", "expressed", "per", "second", "to", "a", "rate", "expressed", "per", "the", "given", "period"], "project": "kafka"}
{"id": 2029, "code": "public void awaitCommits(long timeout) throws InterruptedException {\n    if (recordsToCommitLatch == null || expectedCommits < 0) {\n        throw new IllegalStateException(\"expectedCommits() was not set for this connector?\");\n    }\n    if (!recordsToCommitLatch.await(timeout, TimeUnit.MILLISECONDS)) {\n        String msg = String.format(\n                \"Insufficient records committed by connector %s in %d millis. Records expected=%d, actual=%d\",\n                connectorName,\n                timeout,\n                expectedCommits,\n                expectedCommits - recordsToCommitLatch.getCount());\n        throw new DataException(msg);\n    }\n}", "summary_tokens": ["wait", "for", "this", "connector", "to", "meet", "the", "expected", "number", "of", "commits", "as", "defined", "by", "expected", "commits"], "project": "kafka"}
{"id": 776, "code": "public boolean isDefault() {\n    return name.isEmpty();\n}", "summary_tokens": ["returns", "true", "if", "this", "is", "the", "default", "resource", "of", "a", "resource", "type"], "project": "kafka"}
{"id": 951, "code": "public Optional<String> match() {\n    return this.match;\n}", "summary_tokens": ["the", "optional", "match", "string", "where", "if", "present", "the", "name", "that", "s", "matched", "exactly", "if", "empty", "matches", "the", "default", "name", "if", "null", "matches", "any", "specified", "name"], "project": "kafka"}
{"id": 434, "code": "public boolean coordinatorUnknown() {\n    return checkAndGetCoordinator() == null;\n}", "summary_tokens": ["check", "if", "we", "know", "who", "the", "coordinator", "is", "and", "we", "have", "an", "active", "connection", "true", "if", "the", "coordinator", "is", "unknown"], "project": "kafka"}
{"id": 1333, "code": "public void testSubscriptionChangesWithAutoCommitEnabled() {\n    ConsumerMetadata metadata = createMetadata(subscription);\n    MockClient client = new MockClient(time, metadata);\n\n    Map<String, Integer> tpCounts = new HashMap<>();\n    tpCounts.put(topic, 1);\n    tpCounts.put(topic2, 1);\n    tpCounts.put(topic3, 1);\n    initMetadata(client, tpCounts);\n    Node node = metadata.fetch().nodes().get(0);\n\n    ConsumerPartitionAssignor assignor = new RangeAssignor();\n\n    KafkaConsumer<String, String> consumer = newConsumer(time, client, subscription, metadata, assignor, true, groupInstanceId);\n\n        \n    consumer.subscribe(Arrays.asList(topic, topic2), getConsumerRebalanceListener(consumer));\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic2));\n    assertTrue(consumer.assignment().isEmpty());\n\n        \n    Node coordinator = prepareRebalance(client, node, assignor, Arrays.asList(tp0, t2p0), null);\n\n    consumer.updateAssignmentMetadataIfNeeded(time.timer(Long.MAX_VALUE));\n    consumer.poll(Duration.ZERO);\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic2));\n    assertEquals(2, consumer.assignment().size());\n    assertTrue(consumer.assignment().contains(tp0) && consumer.assignment().contains(t2p0));\n\n        \n    Map<TopicPartition, FetchInfo> fetches1 = new HashMap<>();\n    fetches1.put(tp0, new FetchInfo(0, 1));\n    fetches1.put(t2p0, new FetchInfo(0, 10));\n    client.respondFrom(fetchResponse(fetches1), node);\n    client.poll(0, time.milliseconds());\n\n    ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1));\n\n        \n    fetches1.put(tp0, new FetchInfo(1, 0));\n    fetches1.put(t2p0, new FetchInfo(10, 0));\n    client.respondFrom(fetchResponse(fetches1), node);\n    client.poll(0, time.milliseconds());\n\n        \n    assertEquals(11, records.count());\n    assertEquals(1L, consumer.position(tp0));\n    assertEquals(10L, consumer.position(t2p0));\n\n        \n    consumer.subscribe(Arrays.asList(topic, topic3), getConsumerRebalanceListener(consumer));\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic3));\n    assertEquals(2, consumer.assignment().size());\n    assertTrue(consumer.assignment().contains(tp0) && consumer.assignment().contains(t2p0));\n\n        \n    Map<TopicPartition, Long> partitionOffsets1 = new HashMap<>();\n    partitionOffsets1.put(tp0, 1L);\n    partitionOffsets1.put(t2p0, 10L);\n    AtomicBoolean commitReceived = prepareOffsetCommitResponse(client, coordinator, partitionOffsets1);\n\n        \n    prepareRebalance(client, node, assignor, Arrays.asList(tp0, t3p0), coordinator);\n\n        \n    Map<TopicPartition, FetchInfo> fetches2 = new HashMap<>();\n    fetches2.put(tp0, new FetchInfo(1, 1));\n    fetches2.put(t3p0, new FetchInfo(0, 100));\n    client.prepareResponse(fetchResponse(fetches2));\n\n    records = consumer.poll(Duration.ofMillis(1));\n\n        \n    assertEquals(101, records.count());\n    assertEquals(2L, consumer.position(tp0));\n    assertEquals(100L, consumer.position(t3p0));\n\n        \n    assertTrue(commitReceived.get());\n\n        \n    assertEquals(2, consumer.subscription().size());\n    assertTrue(consumer.subscription().contains(topic) && consumer.subscription().contains(topic3));\n    assertEquals(2, consumer.assignment().size());\n    assertTrue(consumer.assignment().contains(tp0) && consumer.assignment().contains(t3p0));\n\n    consumer.unsubscribe();\n\n        \n    assertTrue(consumer.subscription().isEmpty());\n    assertTrue(consumer.assignment().isEmpty());\n\n    client.requests().clear();\n    consumer.close();\n}", "summary_tokens": ["verify", "that", "when", "a", "consumer", "changes", "its", "topic", "subscription", "its", "assigned", "partitions", "do", "not", "immediately", "change", "and", "the", "latest", "consumed", "offsets", "of", "its", "to", "be", "revoked", "partitions", "are", "properly", "committed", "when", "auto", "commit", "is", "enabled"], "project": "kafka"}
{"id": 2624, "code": "public Repartitioned<K, V> withStreamPartitioner(final StreamPartitioner<K, V> partitioner) {\n    return new Repartitioned<>(name, keySerde, valueSerde, numberOfPartitions, partitioner);\n}", "summary_tokens": ["create", "a", "new", "instance", "of", "repartitioned", "with", "the", "provided", "partitioner"], "project": "kafka"}
{"id": 3011, "code": "public K keyFrom(final byte[] rawKey) {\n    return keySerde.deserializer().deserialize(topic, rawKey);\n}", "summary_tokens": ["deserialize", "the", "key", "from", "raw", "bytes"], "project": "kafka"}
{"id": 424, "code": "public Optional<Integer> leaderEpoch() {\n    if (leaderEpoch == null || leaderEpoch < 0)\n        return Optional.empty();\n    return Optional.of(leaderEpoch);\n}", "summary_tokens": ["get", "the", "leader", "epoch", "of", "the", "previously", "consumed", "record", "if", "one", "is", "known"], "project": "kafka"}
{"id": 1080, "code": "public static JaasContext loadServerContext(ListenerName listenerName, String mechanism, Map<String, ?> configs) {\n    if (listenerName == null)\n        throw new IllegalArgumentException(\"listenerName should not be null for SERVER\");\n    if (mechanism == null)\n        throw new IllegalArgumentException(\"mechanism should not be null for SERVER\");\n    String listenerContextName = listenerName.value().toLowerCase(Locale.ROOT) + \".\" + GLOBAL_CONTEXT_NAME_SERVER;\n    Password dynamicJaasConfig = (Password) configs.get(mechanism.toLowerCase(Locale.ROOT) + \".\" + SaslConfigs.SASL_JAAS_CONFIG);\n    if (dynamicJaasConfig == null && configs.get(SaslConfigs.SASL_JAAS_CONFIG) != null)\n        LOG.warn(\"Server config {} should be prefixed with SASL mechanism name, ignoring config\", SaslConfigs.SASL_JAAS_CONFIG);\n    return load(Type.SERVER, listenerContextName, GLOBAL_CONTEXT_NAME_SERVER, dynamicJaasConfig);\n}", "summary_tokens": ["returns", "an", "instance", "of", "this", "class"], "project": "kafka"}
{"id": 1132, "code": "public static void validateExtensions(SaslExtensions extensions) throws SaslException {\n    if (extensions == null)\n        return;\n    if (extensions.map().containsKey(OAuthBearerClientInitialResponse.AUTH_KEY))\n        throw new SaslException(\"Extension name \" + OAuthBearerClientInitialResponse.AUTH_KEY + \" is invalid\");\n\n    for (Map.Entry<String, String> entry : extensions.map().entrySet()) {\n        String extensionName = entry.getKey();\n        String extensionValue = entry.getValue();\n\n        if (!EXTENSION_KEY_PATTERN.matcher(extensionName).matches())\n            throw new SaslException(\"Extension name \" + extensionName + \" is invalid\");\n        if (!EXTENSION_VALUE_PATTERN.matcher(extensionValue).matches())\n            throw new SaslException(\"Extension value (\" + extensionValue + \") for extension \" + extensionName + \" is invalid\");\n    }\n}", "summary_tokens": ["validates", "that", "the", "given", "extensions", "conform", "to", "the", "standard"], "project": "kafka"}
{"id": 2629, "code": "public long inactivityGap() {\n    return gapMs;\n}", "summary_tokens": ["return", "the", "specified", "gap", "for", "the", "session", "windows", "in", "milliseconds"], "project": "kafka"}
{"id": 68, "code": "public synchronized void fatalError(KafkaException exception) {\n    this.fatalException = exception;\n}", "summary_tokens": ["propagate", "a", "fatal", "error", "which", "affects", "the", "ability", "to", "fetch", "metadata", "for", "the", "cluster"], "project": "kafka"}
{"id": 2284, "code": "public int compareTo(StandardAcl other) {\n    int result;\n    result = resourceType.compareTo(other.resourceType);\n    if (result != 0) return result;\n    result = other.resourceName.compareTo(resourceName); \n    if (result != 0) return result;\n    result = patternType.compareTo(other.patternType);\n    if (result != 0) return result;\n    result = operation.compareTo(other.operation);\n    if (result != 0) return result;\n    result = principal.compareTo(other.principal);\n    if (result != 0) return result;\n    result = host.compareTo(other.host);\n    if (result != 0) return result;\n    result = permissionType.compareTo(other.permissionType);\n    return result;\n}", "summary_tokens": ["compare", "two", "standard", "acl", "objects"], "project": "kafka"}
{"id": 365, "code": "public long metadataFetchDelayMs(long now) {\n    switch (state) {\n        case QUIESCENT:\n                \n                \n                \n            return Math.max(delayBeforeNextAttemptMs(now), delayBeforeNextExpireMs(now));\n        case UPDATE_REQUESTED:\n                \n            return delayBeforeNextAttemptMs(now);\n        default:\n                \n            return Long.MAX_VALUE;\n    }\n}", "summary_tokens": ["determine", "if", "the", "admin", "client", "should", "fetch", "new", "metadata"], "project": "kafka"}
{"id": 2877, "code": "public void pauseTopology(final String topologyName) {\n    pausedTopologies.add(topologyName);\n}", "summary_tokens": ["pauses", "a", "topology", "by", "name", "topology", "name", "name", "of", "the", "topology", "to", "pause"], "project": "kafka"}
{"id": 1614, "code": "public Byte getInt8(String fieldName) {\n    return (Byte) getCheckType(fieldName, Schema.Type.INT8);\n}", "summary_tokens": ["equivalent", "to", "calling", "get", "string", "and", "casting", "the", "result", "to", "a", "byte"], "project": "kafka"}
{"id": 274, "code": "static String generateClientId(AdminClientConfig config) {\n    String clientId = config.getString(AdminClientConfig.CLIENT_ID_CONFIG);\n    if (!clientId.isEmpty())\n        return clientId;\n    return \"adminclient-\" + ADMIN_CLIENT_ID_SEQUENCE.getAndIncrement();\n}", "summary_tokens": ["generate", "the", "client", "id", "based", "on", "the", "configuration"], "project": "kafka"}
{"id": 2219, "code": "BrokerControlStates calculateNextBrokerState(int brokerId,\n                                             BrokerHeartbeatRequestData request,\n                                             long registerBrokerRecordOffset,\n                                             Supplier<Boolean> hasLeaderships) {\n    BrokerHeartbeatState broker = brokers.getOrDefault(brokerId,\n        new BrokerHeartbeatState(brokerId));\n    BrokerControlState currentState = currentBrokerState(broker);\n    switch (currentState) {\n        case FENCED:\n            if (request.wantShutDown()) {\n                log.info(\"Fenced broker {} has requested and been granted an immediate \" +\n                    \"shutdown.\", brokerId);\n                return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n            } else if (!request.wantFence()) {\n                if (request.currentMetadataOffset() >= registerBrokerRecordOffset) {\n                    log.info(\"The request from broker {} to unfence has been granted \" +\n                            \"because it has caught up with the offset of it's register \" +\n                            \"broker record {}.\", brokerId, registerBrokerRecordOffset);\n                    return new BrokerControlStates(currentState, UNFENCED);\n                } else {\n                    if (log.isDebugEnabled()) {\n                        log.debug(\"The request from broker {} to unfence cannot yet \" +\n                            \"be granted because it has not caught up with the offset of \" +\n                            \"it's register broker record {}. It is still at offset {}.\",\n                            brokerId, registerBrokerRecordOffset, request.currentMetadataOffset());\n                    }\n                    return new BrokerControlStates(currentState, FENCED);\n                }\n            }\n            return new BrokerControlStates(currentState, FENCED);\n\n        case UNFENCED:\n            if (request.wantFence()) {\n                if (request.wantShutDown()) {\n                    log.info(\"Unfenced broker {} has requested and been granted an \" +\n                        \"immediate shutdown.\", brokerId);\n                    return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n                } else {\n                    log.info(\"Unfenced broker {} has requested and been granted \" +\n                        \"fencing\", brokerId);\n                    return new BrokerControlStates(currentState, FENCED);\n                }\n            } else if (request.wantShutDown()) {\n                if (hasLeaderships.get()) {\n                    log.info(\"Unfenced broker {} has requested and been granted a \" +\n                        \"controlled shutdown.\", brokerId);\n                    return new BrokerControlStates(currentState, CONTROLLED_SHUTDOWN);\n                } else {\n                    log.info(\"Unfenced broker {} has requested and been granted an \" +\n                        \"immediate shutdown.\", brokerId);\n                    return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n                }\n            }\n            return new BrokerControlStates(currentState, UNFENCED);\n\n        case CONTROLLED_SHUTDOWN:\n            if (hasLeaderships.get()) {\n                log.debug(\"Broker {} is in controlled shutdown state, but can not \" +\n                    \"shut down because more leaders still need to be moved.\", brokerId);\n                return new BrokerControlStates(currentState, CONTROLLED_SHUTDOWN);\n            }\n            long lowestActiveOffset = lowestActiveOffset();\n            if (broker.controlledShutDownOffset <= lowestActiveOffset) {\n                log.info(\"The request from broker {} to shut down has been granted \" +\n                    \"since the lowest active offset {} is now greater than the \" +\n                    \"broker's controlled shutdown offset {}.\", brokerId,\n                    lowestActiveOffset, broker.controlledShutDownOffset);\n                return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n            }\n            log.debug(\"The request from broker {} to shut down can not yet be granted \" +\n                \"because the lowest active offset {} is not greater than the broker's \" +\n                \"shutdown offset {}.\", brokerId, lowestActiveOffset,\n                broker.controlledShutDownOffset);\n            return new BrokerControlStates(currentState, CONTROLLED_SHUTDOWN);\n\n        default:\n            return new BrokerControlStates(currentState, SHUTDOWN_NOW);\n    }\n}", "summary_tokens": ["calculate", "the", "next", "broker", "state", "for", "a", "broker", "that", "just", "sent", "a", "heartbeat", "request"], "project": "kafka"}
{"id": 3212, "code": "public void send(String key, String value) {\n    ProducerRecord<String, String> record;\n\n        \n        \n        \n    if (createTime != null) {\n        record = new ProducerRecord<>(topic, null, createTime, key, value);\n        createTime += System.currentTimeMillis() - startTime;\n    } else {\n        record = new ProducerRecord<>(topic, key, value);\n    }\n\n    numSent++;\n    try {\n        producer.send(record, new PrintInfoCallback(key, value));\n    } catch (Exception e) {\n\n        synchronized (System.out) {\n            printJson(new FailedSend(key, value, topic, e));\n        }\n    }\n}", "summary_tokens": ["produce", "a", "message", "with", "given", "key", "and", "value"], "project": "kafka"}
{"id": 3027, "code": "public static <K, V> StoreBuilder<TimestampedWindowStore<K, V>> timestampedWindowStoreBuilder(final WindowBytesStoreSupplier supplier,\n                                                                                              final Serde<K> keySerde,\n                                                                                              final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new TimestampedWindowStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}", "summary_tokens": ["creates", "a", "store", "builder", "that", "can", "be", "used", "to", "build", "a", "timestamped", "window", "store"], "project": "kafka"}
{"id": 1291, "code": "default Timer timer(Duration timeout) {\n    return timer(timeout.toMillis());\n}", "summary_tokens": ["get", "a", "timer", "which", "is", "bound", "to", "this", "time", "instance", "and", "expires", "after", "the", "given", "timeout"], "project": "kafka"}
{"id": 2697, "code": "public long onInvalidTimestamp(final ConsumerRecord<Object, Object> record,\n                               final long recordTimestamp,\n                               final long partitionTime)\n        throws StreamsException {\n    if (partitionTime < 0) {\n        throw new StreamsException(\"Could not infer new timestamp for input record \" + record\n                + \" because partition time is unknown.\");\n    }\n    return partitionTime;\n}", "summary_tokens": ["returns", "the", "current", "stream", "time", "as", "new", "timestamp", "for", "the", "record"], "project": "kafka"}
{"id": 1017, "code": "public void appendWithOffset(long offset, LegacyRecord record) {\n    appendWithOffset(offset, record.timestamp(), record.key(), record.value());\n}", "summary_tokens": ["add", "a", "record", "with", "a", "given", "offset"], "project": "kafka"}
{"id": 497, "code": "private Map<Node, Map<TopicPartition, ListOffsetsPartition>> groupListOffsetRequests(\n        Map<TopicPartition, Long> timestampsToSearch,\n        Set<TopicPartition> partitionsToRetry) {\n    final Map<TopicPartition, ListOffsetsPartition> partitionDataMap = new HashMap<>();\n    for (Map.Entry<TopicPartition, Long> entry: timestampsToSearch.entrySet()) {\n        TopicPartition tp  = entry.getKey();\n        Long offset = entry.getValue();\n        Metadata.LeaderAndEpoch leaderAndEpoch = metadata.currentLeader(tp);\n\n        if (!leaderAndEpoch.leader.isPresent()) {\n            log.debug(\"Leader for partition {} is unknown for fetching offset {}\", tp, offset);\n            metadata.requestUpdate();\n            partitionsToRetry.add(tp);\n        } else {\n            Node leader = leaderAndEpoch.leader.get();\n            if (client.isUnavailable(leader)) {\n                client.maybeThrowAuthFailure(leader);\n\n                    \n                    \n                    \n                log.debug(\"Leader {} for partition {} is unavailable for fetching offset until reconnect backoff expires\",\n                        leader, tp);\n                partitionsToRetry.add(tp);\n            } else {\n                int currentLeaderEpoch = leaderAndEpoch.epoch.orElse(ListOffsetsResponse.UNKNOWN_EPOCH);\n                partitionDataMap.put(tp, new ListOffsetsPartition()\n                        .setPartitionIndex(tp.partition())\n                        .setTimestamp(offset)\n                        .setCurrentLeaderEpoch(currentLeaderEpoch));\n            }\n        }\n    }\n    return regroupPartitionMapByNode(partitionDataMap);\n}", "summary_tokens": ["groups", "timestamps", "to", "search", "by", "node", "for", "topic", "partitions", "in", "timestamps", "to", "search", "that", "have", "leaders", "available"], "project": "kafka"}
{"id": 630, "code": "public void deallocate(ProducerBatch batch) {\n    incomplete.remove(batch);\n        \n        \n    if (!batch.isSplitBatch())\n        free.deallocate(batch.buffer(), batch.initialCapacity());\n}", "summary_tokens": ["deallocate", "the", "record", "batch"], "project": "kafka"}
{"id": 298, "code": "public boolean shouldListInternal() {\n    return listInternal;\n}", "summary_tokens": ["return", "true", "if", "we", "should", "list", "internal", "topics"], "project": "kafka"}
{"id": 1351, "code": "public void testSimple() throws Exception {\n    long totalMemory = 64 * 1024;\n    int size = 1024;\n    BufferPool pool = new BufferPool(totalMemory, size, metrics, time, metricGroup);\n    ByteBuffer buffer = pool.allocate(size, maxBlockTimeMs);\n    assertEquals(size, buffer.limit(), \"Buffer size should equal requested size.\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"Unallocated memory should have shrunk\");\n    assertEquals(totalMemory - size, pool.availableMemory(), \"Available memory should have shrunk\");\n    buffer.putInt(1);\n    buffer.flip();\n    pool.deallocate(buffer);\n    assertEquals(totalMemory, pool.availableMemory(), \"All memory should be available\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"But now some is on the free list\");\n    buffer = pool.allocate(size, maxBlockTimeMs);\n    assertEquals(0, buffer.position(), \"Recycled buffer should be cleared.\");\n    assertEquals(buffer.capacity(), buffer.limit(), \"Recycled buffer should be cleared.\");\n    pool.deallocate(buffer);\n    assertEquals(totalMemory, pool.availableMemory(), \"All memory should be available\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"Still a single buffer on the free list\");\n    buffer = pool.allocate(2 * size, maxBlockTimeMs);\n    pool.deallocate(buffer);\n    assertEquals(totalMemory, pool.availableMemory(), \"All memory should be available\");\n    assertEquals(totalMemory - size, pool.unallocatedMemory(), \"Non-standard size didn't go to the free list.\");\n}", "summary_tokens": ["test", "the", "simple", "non", "blocking", "allocation", "paths"], "project": "kafka"}
{"id": 2715, "code": "public long timestamp() {\n    return timestamp;\n}", "summary_tokens": ["the", "timestamp", "of", "the", "record"], "project": "kafka"}
{"id": 925, "code": "public Object get(String name) {\n    BoundField field = schema.get(name);\n    if (field == null)\n        throw new SchemaException(\"No such field: \" + name);\n    return getFieldOrDefault(field);\n}", "summary_tokens": ["get", "the", "record", "value", "for", "the", "field", "with", "the", "given", "name", "by", "doing", "a", "hash", "table", "lookup", "slower"], "project": "kafka"}
{"id": 12, "code": "public long throttleDelayMs(String id, long now) {\n    NodeConnectionState state = nodeState.get(id);\n    if (state != null && state.throttleUntilTimeMs > now) {\n        return state.throttleUntilTimeMs - now;\n    } else {\n        return 0;\n    }\n}", "summary_tokens": ["return", "the", "remaining", "throttling", "delay", "in", "milliseconds", "if", "throttling", "is", "in", "progress"], "project": "kafka"}
{"id": 1297, "code": "public long remainingMs() {\n    return Math.max(0, deadlineMs - currentTimeMs);\n}", "summary_tokens": ["get", "the", "remaining", "time", "in", "milliseconds", "until", "the", "timer", "expires"], "project": "kafka"}
{"id": 3142, "code": "public int numFlushedEntryRemoved() {\n    return flushedRemovals.size();\n}", "summary_tokens": ["return", "number", "of", "removed", "entry"], "project": "kafka"}
{"id": 381, "code": "public TimestampType timestampType() {\n    return timestampType;\n}", "summary_tokens": ["the", "timestamp", "type", "of", "this", "record"], "project": "kafka"}
{"id": 1883, "code": "public synchronized <V> V execute(Operation<V> operation, Stage stage, Class<?> executingClass) {\n    context.currentContext(stage, executingClass);\n\n    if (context.failed()) {\n        log.debug(\"ProcessingContext is already in failed state. Ignoring requested operation.\");\n        return null;\n    }\n\n    try {\n        Class<? extends Exception> ex = TOLERABLE_EXCEPTIONS.getOrDefault(context.stage(), RetriableException.class);\n        return execAndHandleError(operation, ex);\n    } finally {\n        if (context.failed()) {\n            errorHandlingMetrics.recordError();\n            context.report();\n        }\n    }\n}", "summary_tokens": ["execute", "the", "recoverable", "operation"], "project": "kafka"}
{"id": 2021, "code": "public Collection<TaskHandle> tasks() {\n    return taskHandles.values();\n}", "summary_tokens": ["get", "the", "list", "of", "tasks", "handles", "monitored", "by", "this", "connector", "handle"], "project": "kafka"}
{"id": 1073, "code": "public boolean isUnknown() {\n    return resourceType.isUnknown() || patternType.isUnknown();\n}", "summary_tokens": ["true", "if", "this", "resource", "has", "any", "unknown", "components"], "project": "kafka"}
{"id": 1727, "code": "default boolean isMM2InternalTopic(String topic) {\n    return  topic.endsWith(\".internal\");\n}", "summary_tokens": ["check", "topic", "is", "one", "of", "mm", "0", "internal", "topic", "this", "is", "used", "to", "make", "sure", "the", "topic", "doesn", "t", "need", "to", "be", "replicated"], "project": "kafka"}
{"id": 2794, "code": "private IOException maybeCleanEmptyNamedTopologyDirs(final boolean logExceptionAsWarn) {\n    if (!hasNamedTopologies) {\n        return null;\n    }\n\n    final AtomicReference<IOException> firstException = new AtomicReference<>(null);\n    final File[] namedTopologyDirs = stateDir.listFiles(pathname ->\n            pathname.isDirectory() && NAMED_TOPOLOGY_DIR_PATH_NAME.matcher(pathname.getName()).matches()\n    );\n    if (namedTopologyDirs != null) {\n        for (final File namedTopologyDir : namedTopologyDirs) {\n            final File[] contents = namedTopologyDir.listFiles();\n            if (contents != null && contents.length == 0) {\n                try {\n                    Utils.delete(namedTopologyDir);\n                } catch (final IOException exception) {\n                    if (logExceptionAsWarn) {\n                        log.warn(\n                            String.format(\"%sSwallowed the following exception during deletion of named topology directory %s\",\n                                logPrefix(), namedTopologyDir.getName()),\n                            exception\n                        );\n                    } else {\n                        log.error(\n                            String.format(\"%s Failed to delete named topology directory %s with exception:\",\n                                logPrefix(), namedTopologyDir.getName()),\n                            exception\n                        );\n                    }\n                    firstException.compareAndSet(null, exception);\n                }\n            }\n        }\n    }\n    return firstException.get();\n}", "summary_tokens": ["cleans", "up", "any", "leftover", "named", "topology", "directories", "that", "are", "empty", "if", "any", "exist", "log", "exception", "as", "warn", "if", "true", "an", "exception", "will", "be", "logged", "as", "a", "warning", "if", "false", "an", "exception", "will", "be", "logged", "as", "error", "the", "first", "ioexception", "to", "be", "encountered"], "project": "kafka"}
{"id": 414, "code": "public void close(Duration timeout) {\n    if (timeout.toMillis() < 0)\n        throw new IllegalArgumentException(\"The timeout cannot be negative.\");\n    acquire();\n    try {\n        if (!closed) {\n                \n                \n            close(timeout.toMillis(), false);\n        }\n    } finally {\n        closed = true;\n        release();\n    }\n}", "summary_tokens": ["tries", "to", "close", "the", "consumer", "cleanly", "within", "the", "specified", "timeout"], "project": "kafka"}
{"id": 833, "code": "public boolean shouldRecord() {\n    return this.recordingLevel.shouldRecord(config.recordLevel().id);\n}", "summary_tokens": ["true", "if", "the", "sensor", "s", "record", "level", "indicates", "that", "the", "metric", "will", "be", "recorded", "false", "otherwise"], "project": "kafka"}
{"id": 3083, "code": "public void deleteTopic(final String topic) throws InterruptedException {\n    deleteTopicsAndWait(-1L, topic);\n}", "summary_tokens": ["deletes", "a", "topic", "returns", "immediately"], "project": "kafka"}
{"id": 1504, "code": "public void testSaslUnsupportedClientVersions() throws Exception {\n    configureMechanisms(\"SCRAM-SHA-512\", Arrays.asList(\"SCRAM-SHA-512\"));\n\n    server = startServerApiVersionsUnsupportedByClient(SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\");\n    updateScramCredentialCache(TestJaasConfig.USERNAME, TestJaasConfig.PASSWORD);\n\n    String node = \"0\";\n\n    createClientConnection(SecurityProtocol.SASL_SSL, \"SCRAM-SHA-512\", node, true);\n    NetworkTestUtils.checkClientConnection(selector, \"0\", 100, 10);\n}", "summary_tokens": ["tests", "correct", "negotiation", "of", "handshake", "and", "authenticate", "api", "versions", "by", "having", "the", "server", "return", "a", "higher", "version", "than", "supported", "on", "the", "client"], "project": "kafka"}
{"id": 403, "code": "public List<PartitionInfo> partitionsFor(String topic, Duration timeout) {\n    acquireAndEnsureOpen();\n    try {\n        Cluster cluster = this.metadata.fetch();\n        List<PartitionInfo> parts = cluster.partitionsForTopic(topic);\n        if (!parts.isEmpty())\n            return parts;\n\n        Timer timer = time.timer(timeout);\n        Map<String, List<PartitionInfo>> topicMetadata = fetcher.getTopicMetadata(\n                new MetadataRequest.Builder(Collections.singletonList(topic), metadata.allowAutoTopicCreation()), timer);\n        return topicMetadata.getOrDefault(topic, Collections.emptyList());\n    } finally {\n        release();\n    }\n}", "summary_tokens": ["get", "metadata", "about", "the", "partitions", "for", "a", "given", "topic"], "project": "kafka"}
{"id": 449, "code": "private boolean isBalanced(Map<String, List<TopicPartition>> currentAssignment,\n                           TreeSet<String> sortedCurrentSubscriptions,\n                           Map<String, List<String>> allSubscriptions,\n                           Map<String, Integer> partitionsPerTopic,\n                           int totalPartitionCount) {\n    int min = currentAssignment.get(sortedCurrentSubscriptions.first()).size();\n    int max = currentAssignment.get(sortedCurrentSubscriptions.last()).size();\n    if (min >= max - 1)\n            \n        return true;\n\n        \n    final Map<TopicPartition, String> allPartitions = new HashMap<>();\n    Set<Entry<String, List<TopicPartition>>> assignments = currentAssignment.entrySet();\n    for (Map.Entry<String, List<TopicPartition>> entry: assignments) {\n        List<TopicPartition> topicPartitions = entry.getValue();\n        for (TopicPartition topicPartition: topicPartitions) {\n            if (allPartitions.containsKey(topicPartition))\n                log.error(\"{} is assigned to more than one consumer.\", topicPartition);\n            allPartitions.put(topicPartition, entry.getKey());\n        }\n    }\n\n        \n        \n    for (String consumer: sortedCurrentSubscriptions) {\n        List<TopicPartition> consumerPartitions = currentAssignment.get(consumer);\n        int consumerPartitionCount = consumerPartitions.size();\n\n            \n        List<String> allSubscribedTopics = allSubscriptions.get(consumer);\n        int maxAssignmentSize = getMaxAssignmentSize(totalPartitionCount, allSubscribedTopics, partitionsPerTopic);\n\n        if (consumerPartitionCount == maxAssignmentSize)\n            continue;\n\n            \n        for (String topic: allSubscribedTopics) {\n            int partitionCount = partitionsPerTopic.get(topic);\n            for (int i = 0; i < partitionCount; i++) {\n                TopicPartition topicPartition = new TopicPartition(topic, i);\n                if (!currentAssignment.get(consumer).contains(topicPartition)) {\n                    String otherConsumer = allPartitions.get(topicPartition);\n                    int otherConsumerPartitionCount = currentAssignment.get(otherConsumer).size();\n                    if (consumerPartitionCount < otherConsumerPartitionCount) {\n                        log.debug(\"{} can be moved from consumer {} to consumer {} for a more balanced assignment.\",\n                            topicPartition, otherConsumer, consumer);\n                        return false;\n                    }\n                }\n            }\n        }\n    }\n    return true;\n}", "summary_tokens": ["determine", "if", "the", "current", "assignment", "is", "a", "balanced", "one"], "project": "kafka"}
{"id": 2357, "code": "private EndQuorumEpochResponseData handleEndQuorumEpochRequest(\n    RaftRequest.Inbound requestMetadata,\n    long currentTimeMs\n) {\n    EndQuorumEpochRequestData request = (EndQuorumEpochRequestData) requestMetadata.data;\n\n    if (!hasValidClusterId(request.clusterId())) {\n        return new EndQuorumEpochResponseData().setErrorCode(Errors.INCONSISTENT_CLUSTER_ID.code());\n    }\n\n    if (!hasValidTopicPartition(request, log.topicPartition())) {\n            \n        return new EndQuorumEpochResponseData().setErrorCode(Errors.INVALID_REQUEST.code());\n    }\n\n    EndQuorumEpochRequestData.PartitionData partitionRequest =\n        request.topics().get(0).partitions().get(0);\n\n    int requestEpoch = partitionRequest.leaderEpoch();\n    int requestLeaderId = partitionRequest.leaderId();\n\n    Optional<Errors> errorOpt = validateVoterOnlyRequest(requestLeaderId, requestEpoch);\n    if (errorOpt.isPresent()) {\n        return buildEndQuorumEpochResponse(errorOpt.get());\n    }\n    maybeTransition(OptionalInt.of(requestLeaderId), requestEpoch, currentTimeMs);\n\n    if (quorum.isFollower()) {\n        FollowerState state = quorum.followerStateOrThrow();\n        if (state.leaderId() == requestLeaderId) {\n            List<Integer> preferredSuccessors = partitionRequest.preferredSuccessors();\n            long electionBackoffMs = endEpochElectionBackoff(preferredSuccessors);\n            logger.debug(\"Overriding follower fetch timeout to {} after receiving \" +\n                \"EndQuorumEpoch request from leader {} in epoch {}\", electionBackoffMs,\n                requestLeaderId, requestEpoch);\n            state.overrideFetchTimeout(currentTimeMs, electionBackoffMs);\n        }\n    }\n    return buildEndQuorumEpochResponse(Errors.NONE);\n}", "summary_tokens": ["handle", "an", "end", "epoch", "request"], "project": "kafka"}
{"id": 2272, "code": "public static List<Integer> toList(int[] array) {\n    if (array == null) return null;\n    ArrayList<Integer> list = new ArrayList<>(array.length);\n    for (int i = 0; i < array.length; i++) {\n        list.add(array[i]);\n    }\n    return list;\n}", "summary_tokens": ["convert", "an", "array", "of", "integers", "to", "a", "list", "of", "ints"], "project": "kafka"}
{"id": 813, "code": "public static boolean hasCollisionChars(String topic) {\n    return topic.contains(\"_\") || topic.contains(\".\");\n}", "summary_tokens": ["due", "to", "limitations", "in", "metric", "names", "topics", "with", "a", "period"], "project": "kafka"}
{"id": 1120, "code": "public String errorDescription() {\n    return errorDescription;\n}", "summary_tokens": ["return", "the", "potentially", "null", "error", "description", "as", "per", "a", "href", "https", "tools"], "project": "kafka"}
{"id": 1565, "code": "public static X509Certificate generateCertificate(String dn, KeyPair pair,\n                                                  int days, String algorithm)\n    throws  CertificateException {\n    return new CertificateBuilder(days, algorithm).generate(dn, pair);\n}", "summary_tokens": ["create", "a", "self", "signed", "x"], "project": "kafka"}
{"id": 851, "code": "default Long clientSessionReauthenticationTimeNanos() {\n    return null;\n}", "summary_tokens": ["return", "the", "time", "on", "or", "after", "which", "a", "client", "should", "re", "authenticate", "this", "session", "if", "any", "otherwise", "null"], "project": "kafka"}
{"id": 2027, "code": "public void commit(int batchSize) {\n    if (recordsToCommitLatch != null) {\n        IntStream.range(0, batchSize).forEach(i -> recordsToCommitLatch.countDown());\n    }\n}", "summary_tokens": ["record", "commit", "on", "a", "batch", "of", "messages", "from", "the", "connector"], "project": "kafka"}
{"id": 435, "code": "protected synchronized Node checkAndGetCoordinator() {\n    if (coordinator != null && client.isUnavailable(coordinator)) {\n        markCoordinatorUnknown(true, \"coordinator unavailable\");\n        return null;\n    }\n    return this.coordinator;\n}", "summary_tokens": ["get", "the", "coordinator", "if", "its", "connection", "is", "still", "active"], "project": "kafka"}
{"id": 2850, "code": "private boolean verifyHostInfo(final Set<HostInfo> groupHostInfo) {\n    if (userEndPoint != null && !groupHostInfo.isEmpty()) {\n        final HostInfo myHostInfo = HostInfo.buildFromEndpoint(userEndPoint);\n\n        return groupHostInfo.contains(myHostInfo);\n    } else {\n        return true;\n    }\n}", "summary_tokens": ["verify", "that", "this", "client", "s", "host", "info", "was", "included", "in", "the", "map", "returned", "in", "the", "assignment", "and", "trigger", "a", "rebalance", "if", "not"], "project": "kafka"}
{"id": 1166, "code": "public String failureScope() {\n    return failureScope;\n}", "summary_tokens": ["return", "the", "potentially", "null", "scope", "to", "be", "reported", "with", "the", "failure"], "project": "kafka"}
{"id": 1465, "code": "public void testTruncateNotCalledIfSizeIsSameAsTargetSize() throws IOException {\n    FileChannel channelMock = mock(FileChannel.class);\n\n    when(channelMock.size()).thenReturn(42L);\n    when(channelMock.position(42L)).thenReturn(null);\n\n    FileRecords fileRecords = new FileRecords(tempFile(), channelMock, 0, Integer.MAX_VALUE, false);\n    fileRecords.truncateTo(42);\n\n    verify(channelMock, atLeastOnce()).size();\n    verify(channelMock, times(0)).truncate(anyLong());\n}", "summary_tokens": ["test", "that", "truncate", "to", "only", "calls", "truncate", "on", "the", "file", "channel", "if", "the", "size", "of", "the", "file", "channel", "is", "bigger", "than", "the", "target", "size"], "project": "kafka"}
{"id": 249, "code": "public DescribeTopicsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}", "summary_tokens": ["set", "the", "timeout", "in", "milliseconds", "for", "this", "operation", "or", "null", "if", "the", "default", "api", "timeout", "for", "the", "admin", "client", "should", "be", "used"], "project": "kafka"}
{"id": 675, "code": "public int port() {\n    return port;\n}", "summary_tokens": ["returns", "the", "port", "to", "which", "the", "listener", "is", "bound"], "project": "kafka"}
{"id": 2774, "code": "public long headRecordTimestamp() {\n    return headRecord == null ? UNKNOWN : headRecord.timestamp;\n}", "summary_tokens": ["returns", "the", "head", "record", "s", "timestamp"], "project": "kafka"}
{"id": 1014, "code": "public void closeForRecordAppends() {\n    if (appendStream != CLOSED_STREAM) {\n        try {\n            appendStream.close();\n        } catch (IOException e) {\n            throw new KafkaException(e);\n        } finally {\n            appendStream = CLOSED_STREAM;\n        }\n    }\n}", "summary_tokens": ["release", "resources", "required", "for", "record", "appends", "e"], "project": "kafka"}
{"id": 3085, "code": "public void deleteTopics(final String... topics) throws InterruptedException {\n    deleteTopicsAndWait(-1, topics);\n}", "summary_tokens": ["deletes", "multiple", "topics", "returns", "immediately"], "project": "kafka"}
{"id": 420, "code": "public synchronized void rebalance(Collection<TopicPartition> newAssignment) {\n        \n    this.records.clear();\n    this.subscriptions.assignFromSubscribed(newAssignment);\n}", "summary_tokens": ["simulate", "a", "rebalance", "event"], "project": "kafka"}
{"id": 2477, "code": "public void setStateListener(final KafkaStreams.StateListener listener) {\n    synchronized (stateLock) {\n        if (state.hasNotStarted()) {\n            stateListener = listener;\n        } else {\n            throw new IllegalStateException(\"Can only set StateListener before calling start(). Current state is: \" + state);\n        }\n    }\n}", "summary_tokens": ["an", "app", "can", "set", "a", "single", "kafka", "streams"], "project": "kafka"}
{"id": 1158, "code": "public static Map<String, Object> toMap(String split) throws OAuthBearerIllegalTokenException {\n    Map<String, Object> retval = new HashMap<>();\n    try {\n        byte[] decode = Base64.getDecoder().decode(split);\n        JsonNode jsonNode = new ObjectMapper().readTree(decode);\n        if (jsonNode == null)\n            throw new OAuthBearerIllegalTokenException(OAuthBearerValidationResult.newFailure(\"malformed JSON\"));\n        for (Iterator<Entry<String, JsonNode>> iterator = jsonNode.fields(); iterator.hasNext();) {\n            Entry<String, JsonNode> entry = iterator.next();\n            retval.put(entry.getKey(), convert(entry.getValue()));\n        }\n        return Collections.unmodifiableMap(retval);\n    } catch (IllegalArgumentException e) {\n            \n        throw new OAuthBearerIllegalTokenException(\n                OAuthBearerValidationResult.newFailure(\"malformed Base64 URL encoded value\"));\n    } catch (IOException e) {\n        throw new OAuthBearerIllegalTokenException(OAuthBearerValidationResult.newFailure(\"malformed JSON\"));\n    }\n}", "summary_tokens": ["decode", "the", "given", "base", "0", "url", "encoded", "value", "parse", "the", "resulting", "json", "as", "a", "json", "object", "and", "return", "the", "map", "of", "member", "names", "to", "their", "values", "each", "value", "being", "represented", "as", "either", "a", "string", "a", "number", "or", "a", "list", "of", "strings"], "project": "kafka"}
{"id": 1552, "code": "public void throwsAuthenticationExceptionOnInvalidExtensions() {\n    OAuthBearerUnsecuredValidatorCallbackHandler invalidHandler = new OAuthBearerUnsecuredValidatorCallbackHandler() {\n        @Override\n        public void handle(Callback[] callbacks) throws UnsupportedCallbackException {\n            for (Callback callback : callbacks) {\n                if (callback instanceof OAuthBearerValidatorCallback) {\n                    OAuthBearerValidatorCallback validationCallback = (OAuthBearerValidatorCallback) callback;\n                    validationCallback.token(new OAuthBearerTokenMock());\n                } else if (callback instanceof OAuthBearerExtensionsValidatorCallback) {\n                    OAuthBearerExtensionsValidatorCallback extensionsCallback = (OAuthBearerExtensionsValidatorCallback) callback;\n                    extensionsCallback.error(\"firstKey\", \"is not valid\");\n                    extensionsCallback.error(\"secondKey\", \"is not valid either\");\n                } else\n                    throw new UnsupportedCallbackException(callback);\n            }\n        }\n    };\n    saslServer = new OAuthBearerSaslServer(invalidHandler);\n    Map<String, String> customExtensions = new HashMap<>();\n    customExtensions.put(\"firstKey\", \"value\");\n    customExtensions.put(\"secondKey\", \"value\");\n\n    assertThrows(SaslAuthenticationException.class,\n        () -> saslServer.evaluateResponse(clientInitialResponse(null, false, customExtensions)));\n}", "summary_tokens": ["if", "the", "callback", "handler", "handles", "the", "oauth", "bearer", "extensions", "validator", "callback", "and", "finds", "an", "invalid", "extension", "sasl", "server", "should", "throw", "an", "authentication", "exception"], "project": "kafka"}
{"id": 514, "code": "public void addListener(RequestFutureListener<T> listener) {\n    this.listeners.add(listener);\n    if (failed())\n        fireFailure();\n    else if (succeeded())\n        fireSuccess();\n}", "summary_tokens": ["add", "a", "listener", "which", "will", "be", "notified", "when", "the", "future", "completes", "listener", "non", "null", "listener", "to", "add"], "project": "kafka"}
{"id": 819, "code": "public static String toHtmlTable(String domain, Iterable<MetricNameTemplate> allMetrics) {\n    Map<String, Map<String, String>> beansAndAttributes = new TreeMap<>();\n    \n    try (Metrics metrics = new Metrics()) {\n        for (MetricNameTemplate template : allMetrics) {\n            Map<String, String> tags = new LinkedHashMap<>();\n            for (String s : template.tags()) {\n                tags.put(s, \"{\" + s + \"}\");\n            }\n    \n            MetricName metricName = metrics.metricName(template.name(), template.group(), template.description(), tags);\n            String mBeanName = JmxReporter.getMBeanName(domain, metricName);\n            if (!beansAndAttributes.containsKey(mBeanName)) {\n                beansAndAttributes.put(mBeanName, new TreeMap<>());\n            }\n            Map<String, String> attrAndDesc = beansAndAttributes.get(mBeanName);\n            if (!attrAndDesc.containsKey(template.name())) {\n                attrAndDesc.put(template.name(), template.description());\n            } else {\n                throw new IllegalArgumentException(\"mBean '\" + mBeanName + \"' attribute '\" + template.name() + \"' is defined twice.\");\n            }\n        }\n    }\n        \n    StringBuilder b = new StringBuilder();\n    b.append(\"<table class=\\\"data-table\\\"><tbody>\\n\");\n    \n    for (Entry<String, Map<String, String>> e : beansAndAttributes.entrySet()) {\n        b.append(\"<tr>\\n\");\n        b.append(\"<td colspan=3 class=\\\"mbeanName\\\" style=\\\"background-color:#ccc; font-weight: bold;\\\">\");\n        b.append(e.getKey());\n        b.append(\"</td>\");\n        b.append(\"</tr>\\n\");\n            \n        b.append(\"<tr>\\n\");\n        b.append(\"<th style=\\\"width: 90px\\\"></th>\\n\");\n        b.append(\"<th>Attribute name</th>\\n\");\n        b.append(\"<th>Description</th>\\n\");\n        b.append(\"</tr>\\n\");\n            \n        for (Entry<String, String> e2 : e.getValue().entrySet()) {\n            b.append(\"<tr>\\n\");\n            b.append(\"<td></td>\");\n            b.append(\"<td>\");\n            b.append(e2.getKey());\n            b.append(\"</td>\");\n            b.append(\"<td>\");\n            b.append(e2.getValue());\n            b.append(\"</td>\");\n            b.append(\"</tr>\\n\");\n        }\n    \n    }\n    b.append(\"</tbody></table>\");\n    \n    return b.toString();\n    \n}", "summary_tokens": ["use", "the", "specified", "domain", "and", "metric", "name", "templates", "to", "generate", "an", "html", "table", "documenting", "the", "metrics"], "project": "kafka"}
{"id": 1757, "code": "public boolean shouldRestartConnector(ConnectorStatus status) {\n    return !onlyFailed || status.state() == AbstractStatus.State.FAILED;\n}", "summary_tokens": ["determine", "whether", "the", "connector", "with", "the", "given", "status", "is", "to", "be", "restarted"], "project": "kafka"}
{"id": 636, "code": "public boolean hasIncomplete() {\n    return !this.incomplete.isEmpty();\n}", "summary_tokens": ["check", "whether", "there", "are", "any", "pending", "batches", "whether", "sent", "or", "unsent"], "project": "kafka"}
{"id": 975, "code": "public void trim() throws IOException {\n    truncateTo(sizeInBytes());\n}", "summary_tokens": ["trim", "file", "when", "close", "or", "roll", "to", "next", "file"], "project": "kafka"}
{"id": 2275, "code": "public static boolean validate(int[] replicas) {\n    if (replicas.length == 0) return true;\n    int[] sortedReplicas = clone(replicas);\n    Arrays.sort(sortedReplicas);\n    int prev = sortedReplicas[0];\n    if (prev < 0) return false;\n    for (int i = 1; i < sortedReplicas.length; i++) {\n        int replica = sortedReplicas[i];\n        if (prev == replica) return false;\n        prev = replica;\n    }\n    return true;\n}", "summary_tokens": ["check", "that", "a", "replica", "set", "is", "valid"], "project": "kafka"}
{"id": 661, "code": "public Cluster withPartitions(Map<TopicPartition, PartitionInfo> partitions) {\n    Map<TopicPartition, PartitionInfo> combinedPartitions = new HashMap<>(this.partitionsByTopicPartition);\n    combinedPartitions.putAll(partitions);\n    return new Cluster(clusterResource.clusterId(), this.nodes, combinedPartitions.values(),\n            new HashSet<>(this.unauthorizedTopics), new HashSet<>(this.invalidTopics),\n            new HashSet<>(this.internalTopics), this.controller);\n}", "summary_tokens": ["return", "a", "copy", "of", "this", "cluster", "combined", "with", "partitions"], "project": "kafka"}
{"id": 230, "code": "public KafkaFuture<Node> controller() {\n    return controller;\n}", "summary_tokens": ["returns", "a", "future", "which", "yields", "the", "current", "controller", "id"], "project": "kafka"}
{"id": 638, "code": "void abortBatches(final RuntimeException reason) {\n    for (ProducerBatch batch : incomplete.copyAll()) {\n        Deque<ProducerBatch> dq = getDeque(batch.topicPartition);\n        synchronized (dq) {\n            batch.abortRecordAppends();\n            dq.remove(batch);\n        }\n        batch.abort(reason);\n        deallocate(batch);\n    }\n}", "summary_tokens": ["abort", "all", "incomplete", "batches", "whether", "they", "have", "been", "sent", "or", "not"], "project": "kafka"}
{"id": 1418, "code": "public void testECKeyPair(Args args) throws Exception {\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).keyAlgorithm(\"EC\").build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).keyAlgorithm(\"EC\").build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    verifySslConfigs(args);\n}", "summary_tokens": ["tests", "key", "pair", "created", "using", "ec"], "project": "kafka"}
{"id": 2592, "code": "public static <K, V, S extends StateStore> Materialized<K, V, S> with(final Serde<K> keySerde,\n                                                                      final Serde<V> valueSerde) {\n    return new Materialized<K, V, S>((String) null).withKeySerde(keySerde).withValueSerde(valueSerde);\n}", "summary_tokens": ["materialize", "a", "state", "store", "with", "the", "provided", "key", "and", "value", "serde", "s"], "project": "kafka"}
{"id": 1178, "code": "public long lifetimeMs() {\n    return lifetimeMs;\n}", "summary_tokens": ["the", "token", "s", "lifetime", "expressed", "as", "the", "number", "of", "milliseconds", "since", "the", "epoch", "as", "per", "a", "href", "https", "tools"], "project": "kafka"}
{"id": 2250, "code": "void handleBrokerUnfenced(int brokerId, long brokerEpoch, List<ApiMessageAndVersion> records) {\n    if (featureControl.metadataVersion().isBrokerRegistrationChangeRecordSupported()) {\n        records.add(new ApiMessageAndVersion(new BrokerRegistrationChangeRecord().\n            setBrokerId(brokerId).setBrokerEpoch(brokerEpoch).\n            setFenced(BrokerRegistrationFencingChange.UNFENCE.value()),\n            (short) 0));\n    } else {\n        records.add(new ApiMessageAndVersion(new UnfenceBrokerRecord().setId(brokerId).\n            setEpoch(brokerEpoch), (short) 0));\n    }\n    generateLeaderAndIsrUpdates(\"handleBrokerUnfenced\", NO_LEADER, brokerId, records,\n        brokersToIsrs.partitionsWithNoLeader());\n}", "summary_tokens": ["generate", "the", "appropriate", "records", "to", "handle", "a", "broker", "becoming", "unfenced"], "project": "kafka"}
{"id": 110, "code": "default DeleteTopicsResult deleteTopics(TopicCollection topics) {\n    return deleteTopics(topics, new DeleteTopicsOptions());\n}", "summary_tokens": ["this", "is", "a", "convenience", "method", "for", "delete", "topics", "topic", "collection", "delete", "topics", "options", "with", "default", "options"], "project": "kafka"}
{"id": 2589, "code": "public Joined<K, V, VO> withOtherValueSerde(final Serde<VO> otherValueSerde) {\n    return new Joined<>(keySerde, valueSerde, otherValueSerde, name);\n}", "summary_tokens": ["set", "the", "other", "value", "serde", "to", "be", "used"], "project": "kafka"}
{"id": 1781, "code": "public Set<String> connectorNames() {\n    return connectors.keySet();\n}", "summary_tokens": ["get", "the", "ids", "of", "the", "connectors", "currently", "running", "in", "this", "worker"], "project": "kafka"}
{"id": 1063, "code": "static boolean flag(ProduceRequest request, Predicate<RecordBatch> predicate) {\n    for (ProduceRequestData.TopicProduceData tp : request.data().topicData()) {\n        for (ProduceRequestData.PartitionProduceData p : tp.partitionData()) {\n            if (p.records() instanceof Records) {\n                Iterator<? extends RecordBatch> iter = (((Records) p.records())).batchIterator();\n                if (iter.hasNext() && predicate.test(iter.next())) return true;\n            }\n        }\n    }\n    return false;\n}", "summary_tokens": ["find", "a", "flag", "from", "all", "records", "of", "a", "produce", "request"], "project": "kafka"}
{"id": 2690, "code": "public Map<TopicPartition, Long> committedOffsets() {\n    return committedOffsets;\n}", "summary_tokens": ["this", "function", "will", "return", "a", "map", "of", "topic", "partitions", "and", "the", "highest", "committed", "offset", "seen", "so", "far"], "project": "kafka"}
{"id": 3254, "code": "private Set<String> expandTopicName(String topicName) {\n    Set<String> expandedNames = StringExpander.expand(topicName);\n    if (expandedNames.size() == 1) {\n        return expandedNames;\n    }\n\n    Set<String> newNames = new HashSet<>();\n    for (String name : expandedNames) {\n        newNames.addAll(expandTopicName(name));\n    }\n    return newNames;\n}", "summary_tokens": ["expands", "a", "topic", "name", "until", "there", "are", "no", "more", "ranges", "in", "it"], "project": "kafka"}
{"id": 3035, "code": "public static <V> V getValueOrNull(final ValueAndTimestamp<V> valueAndTimestamp) {\n    return valueAndTimestamp == null ? null : valueAndTimestamp.value();\n}", "summary_tokens": ["return", "the", "wrapped", "value", "of", "the", "given", "value", "and", "timestamp", "parameter", "if", "the", "parameter", "is", "not", "null"], "project": "kafka"}
{"id": 1105, "code": "public String realm() {\n    return realm;\n}", "summary_tokens": ["get", "the", "realm", "of", "the", "name"], "project": "kafka"}
{"id": 1481, "code": "public void testInvalidPasswordSaslScram() throws Exception {\n    String node = \"0\";\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    TestJaasConfig jaasConfig = configureMechanisms(\"SCRAM-SHA-256\", Collections.singletonList(\"SCRAM-SHA-256\"));\n    jaasConfig.setClientOptions(\"SCRAM-SHA-256\", TestJaasConfig.USERNAME, \"invalidpassword\");\n\n    server = createEchoServer(securityProtocol);\n    createAndCheckClientAuthenticationFailure(securityProtocol, node, \"SCRAM-SHA-256\", null);\n    server.verifyAuthenticationMetrics(0, 1);\n}", "summary_tokens": ["tests", "that", "sasl", "scram", "clients", "with", "invalid", "password", "fail", "authentication", "with", "connection", "close", "delay", "if", "configured"], "project": "kafka"}
{"id": 36, "code": "static <T> Set<T> findMissing(Set<T> toFind, Set<T> toSearch) {\n    Set<T> ret = new LinkedHashSet<>();\n    for (T toFindItem: toFind) {\n        if (!toSearch.contains(toFindItem)) {\n            ret.add(toFindItem);\n        }\n    }\n    return ret;\n}", "summary_tokens": ["return", "missing", "items", "which", "are", "expected", "to", "be", "in", "a", "particular", "set", "but", "which", "are", "not"], "project": "kafka"}
{"id": 2301, "code": "public void reset() {\n    deleteSnapshotsUpTo(LATEST_EPOCH);\n\n    for (Revertable revertable : revertables) {\n        revertable.reset();\n    }\n}", "summary_tokens": ["delete", "all", "snapshots", "and", "resets", "all", "of", "the", "revertable", "object", "registered"], "project": "kafka"}
{"id": 2145, "code": "public void assertConnectorAndAtLeastNumTasksAreRunning(String connectorName, int numTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorState(\n                connectorName,\n                AbstractStatus.State.RUNNING,\n                numTasks,\n                AbstractStatus.State.RUNNING,\n                (actual, expected) -> actual >= expected\n            ).orElse(false),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"The connector or at least \" + numTasks + \" of tasks are not running.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "a", "connector", "is", "running", "with", "at", "least", "the", "given", "number", "of", "tasks", "all", "in", "running", "state"], "project": "kafka"}
{"id": 2510, "code": "public long offsetLag() {\n    return this.offsetLag;\n}", "summary_tokens": ["get", "the", "measured", "lag", "between", "current", "and", "end", "offset", "positions", "for", "this", "store", "partition", "replica"], "project": "kafka"}
{"id": 479, "code": "public void maybeThrowAuthFailure(Node node) {\n    lock.lock();\n    try {\n        AuthenticationException exception = client.authenticationException(node);\n        if (exception != null)\n            throw exception;\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["check", "for", "an", "authentication", "error", "on", "a", "given", "node", "and", "raise", "the", "exception", "if", "there", "is", "one"], "project": "kafka"}
{"id": 2242, "code": "void triggerLeaderEpochBumpIfNeeded(PartitionChangeRecord record) {\n    if (record.leader() == NO_LEADER_CHANGE) {\n        if (!Replicas.contains(targetIsr, partition.isr) ||\n                !Replicas.contains(targetReplicas, partition.replicas)) {\n            record.setLeader(partition.leader);\n        }\n    }\n}", "summary_tokens": ["trigger", "a", "leader", "epoch", "bump", "if", "one", "is", "needed"], "project": "kafka"}
{"id": 2724, "code": "public static Map<TopicPartition, ListOffsetsResultInfo> fetchEndOffsets(final Collection<TopicPartition> partitions,\n                                                                         final Admin adminClient) {\n    if (partitions.isEmpty()) {\n        return Collections.emptyMap();\n    }\n    return getEndOffsets(fetchEndOffsetsFuture(partitions, adminClient));\n}", "summary_tokens": ["streams", "exception", "if", "the", "admin", "client", "request", "throws", "an", "exception"], "project": "kafka"}
{"id": 3148, "code": "public static Map<String, String> parseConfigs(final String formattedConfigs) {\n    Objects.requireNonNull(formattedConfigs, \"Formatted config String can't be null\");\n\n    if (formattedConfigs.indexOf('=') == -1) {\n        throw new IllegalStateException(String.format(\"Provided string [ %s ] does not have expected key-value separator of '='\", formattedConfigs));\n    }\n\n    final String[] parts = formattedConfigs.split(\",\");\n    final Map<String, String> configs = new HashMap<>();\n    for (final String part : parts) {\n        final String[] keyValue = part.split(\"=\");\n        if (keyValue.length > 2) {\n            throw new IllegalStateException(\n                String.format(\"Provided string [ %s ] does not have expected key-value pair separator of ','\", formattedConfigs));\n        }\n        configs.put(keyValue[KEY], keyValue[VALUE]);\n    }\n    return configs;\n}", "summary_tokens": ["takes", "a", "string", "with", "keys", "and", "values", "separated", "by", "and", "each", "key", "value", "pair", "separated", "by", "for", "example", "max"], "project": "kafka"}
{"id": 3159, "code": "public Map<K, V> readKeyValuesToMap() {\n    final Map<K, V> output = new HashMap<>();\n    TestRecord<K, V> outputRow;\n    while (!isEmpty()) {\n        outputRow = readRecord();\n        if (outputRow.key() == null) {\n            throw new IllegalStateException(\"Null keys not allowed with readKeyValuesToMap method\");\n        }\n        output.put(outputRow.key(), outputRow.value());\n    }\n    return output;\n}", "summary_tokens": ["read", "output", "to", "map"], "project": "kafka"}
{"id": 326, "code": "public Map<String, String> configs() {\n    return configs;\n}", "summary_tokens": ["the", "configuration", "for", "the", "new", "topic", "or", "null", "if", "no", "configs", "ever", "specified"], "project": "kafka"}
{"id": 1585, "code": "public String connectorName() {\n    return connectorName;\n}", "summary_tokens": ["name", "of", "the", "connector", "specified", "in", "the", "connector", "config"], "project": "kafka"}
{"id": 1415, "code": "public void testClientAuthenticationRequestedValidProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"requested\");\n    verifySslConfigs(args);\n}", "summary_tokens": ["tests", "that", "server", "accepts", "connections", "from", "a", "client", "configured", "with", "a", "valid", "certificate", "if", "client", "authentication", "is", "requested"], "project": "kafka"}
{"id": 2316, "code": "public void testParsingRecordWithGarbageAtEnd() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    RegisterBrokerRecord message = new RegisterBrokerRecord().setBrokerId(1).setBrokerEpoch(2);\n\n    ObjectSerializationCache cache = new ObjectSerializationCache();\n    ApiMessageAndVersion messageAndVersion = new ApiMessageAndVersion(message, (short) 0);\n    int size = serde.recordSize(messageAndVersion, cache);\n    ByteBuffer buffer = ByteBuffer.allocate(size + 1);\n\n    serde.write(messageAndVersion, cache, new ByteBufferAccessor(buffer));\n    buffer.clear();\n    assertStartsWith(\"Found 1 byte(s) of garbage after\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), size + 1)).getMessage());\n}", "summary_tokens": ["test", "attempting", "to", "parse", "an", "event", "which", "has", "a", "malformed", "message", "version", "varint"], "project": "kafka"}
{"id": 1276, "code": "public int hashCode() {\n    return this.valuesList().hashCode();\n}", "summary_tokens": ["returns", "the", "hash", "code", "value", "for", "this", "collection"], "project": "kafka"}
{"id": 1830, "code": "private boolean readConfigToEnd(long timeoutMs) {\n    if (configState.offset() < assignment.offset()) {\n        log.info(\"Current config state offset {} is behind group assignment {}, reading to end of config log\", configState.offset(), assignment.offset());\n    } else {\n        log.info(\"Reading to end of config log; current config state offset: {}\", configState.offset());\n    }\n    if (refreshConfigSnapshot(timeoutMs)) {\n        backoffRetries = BACKOFF_RETRIES;\n        return true;\n    } else {\n            \n            \n        member.maybeLeaveGroup(\"taking too long to read the log\");\n        backoff(workerUnsyncBackoffMs);\n        return false;\n    }\n}", "summary_tokens": ["try", "to", "read", "to", "the", "end", "of", "the", "config", "log", "within", "the", "given", "timeout"], "project": "kafka"}
{"id": 1488, "code": "public void testMissingUsernameSaslPlain() throws Exception {\n    String node = \"0\";\n    TestJaasConfig jaasConfig = configureMechanisms(\"PLAIN\", Arrays.asList(\"PLAIN\"));\n    jaasConfig.setClientOptions(\"PLAIN\", null, \"mypassword\");\n\n    SecurityProtocol securityProtocol = SecurityProtocol.SASL_SSL;\n    server = createEchoServer(securityProtocol);\n    createSelector(securityProtocol, saslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    try {\n        selector.connect(node, addr, BUFFER_SIZE, BUFFER_SIZE);\n        fail(\"SASL/PLAIN channel created without username\");\n    } catch (IOException e) {\n            \n        assertTrue(selector.channels().isEmpty(), \"Channels not closed\");\n        for (SelectionKey key : selector.keys())\n            assertFalse(key.isValid(), \"Key not cancelled\");\n    }\n}", "summary_tokens": ["tests", "that", "sasl", "plain", "clients", "without", "valid", "username", "fail", "authentication"], "project": "kafka"}
{"id": 2214, "code": "void register(int brokerId, boolean fenced) {\n    BrokerHeartbeatState broker = brokers.get(brokerId);\n    if (broker == null) {\n        touch(brokerId, fenced, -1);\n    } else if (broker.fenced() != fenced) {\n        touch(brokerId, fenced, broker.metadataOffset);\n    }\n}", "summary_tokens": ["register", "this", "broker", "if", "we", "haven", "t", "already", "and", "make", "sure", "its", "fencing", "state", "is", "correct"], "project": "kafka"}
{"id": 3029, "code": "public HostInfo hostInfo() {\n    return hostInfo;\n}", "summary_tokens": ["the", "value", "of", "org"], "project": "kafka"}
{"id": 1212, "code": "public byte[] evaluateResponse(byte[] response) throws SaslException, SaslAuthenticationException {\n    try {\n        switch (state) {\n            case RECEIVE_CLIENT_FIRST_MESSAGE:\n                this.clientFirstMessage = new ClientFirstMessage(response);\n                this.scramExtensions = clientFirstMessage.extensions();\n                if (!SUPPORTED_EXTENSIONS.containsAll(scramExtensions.map().keySet())) {\n                    log.debug(\"Unsupported extensions will be ignored, supported {}, provided {}\",\n                            SUPPORTED_EXTENSIONS, scramExtensions.map().keySet());\n                }\n                String serverNonce = formatter.secureRandomString();\n                try {\n                    String saslName = clientFirstMessage.saslName();\n                    this.username = ScramFormatter.username(saslName);\n                    NameCallback nameCallback = new NameCallback(\"username\", username);\n                    ScramCredentialCallback credentialCallback;\n                    if (scramExtensions.tokenAuthenticated()) {\n                        DelegationTokenCredentialCallback tokenCallback = new DelegationTokenCredentialCallback();\n                        credentialCallback = tokenCallback;\n                        callbackHandler.handle(new Callback[]{nameCallback, tokenCallback});\n                        if (tokenCallback.tokenOwner() == null)\n                            throw new SaslException(\"Token Authentication failed: Invalid tokenId : \" + username);\n                        this.authorizationId = tokenCallback.tokenOwner();\n                        this.tokenExpiryTimestamp = tokenCallback.tokenExpiryTimestamp();\n                    } else {\n                        credentialCallback = new ScramCredentialCallback();\n                        callbackHandler.handle(new Callback[]{nameCallback, credentialCallback});\n                        this.authorizationId = username;\n                        this.tokenExpiryTimestamp = null;\n                    }\n                    this.scramCredential = credentialCallback.scramCredential();\n                    if (scramCredential == null)\n                        throw new SaslException(\"Authentication failed: Invalid user credentials\");\n                    String authorizationIdFromClient = clientFirstMessage.authorizationId();\n                    if (!authorizationIdFromClient.isEmpty() && !authorizationIdFromClient.equals(username))\n                        throw new SaslAuthenticationException(\"Authentication failed: Client requested an authorization id that is different from username\");\n\n                    if (scramCredential.iterations() < mechanism.minIterations())\n                        throw new SaslException(\"Iterations \" + scramCredential.iterations() +  \" is less than the minimum \" + mechanism.minIterations() + \" for \" + mechanism);\n                    this.serverFirstMessage = new ServerFirstMessage(clientFirstMessage.nonce(),\n                            serverNonce,\n                            scramCredential.salt(),\n                            scramCredential.iterations());\n                    setState(State.RECEIVE_CLIENT_FINAL_MESSAGE);\n                    return serverFirstMessage.toBytes();\n                } catch (SaslException | AuthenticationException e) {\n                    throw e;\n                } catch (Throwable e) {\n                    throw new SaslException(\"Authentication failed: Credentials could not be obtained\", e);\n                }\n\n            case RECEIVE_CLIENT_FINAL_MESSAGE:\n                try {\n                    ClientFinalMessage clientFinalMessage = new ClientFinalMessage(response);\n                    verifyClientProof(clientFinalMessage);\n                    byte[] serverKey = scramCredential.serverKey();\n                    byte[] serverSignature = formatter.serverSignature(serverKey, clientFirstMessage, serverFirstMessage, clientFinalMessage);\n                    ServerFinalMessage serverFinalMessage = new ServerFinalMessage(null, serverSignature);\n                    clearCredentials();\n                    setState(State.COMPLETE);\n                    return serverFinalMessage.toBytes();\n                } catch (InvalidKeyException e) {\n                    throw new SaslException(\"Authentication failed: Invalid client final message\", e);\n                }\n\n            default:\n                throw new IllegalSaslStateException(\"Unexpected challenge in Sasl server state \" + state);\n        }\n    } catch (SaslException | AuthenticationException e) {\n        clearCredentials();\n        setState(State.FAILED);\n        throw e;\n    }\n}", "summary_tokens": ["sasl", "authentication", "exception", "if", "the", "requested", "authorization", "id", "is", "not", "the", "same", "as", "username"], "project": "kafka"}
{"id": 618, "code": "private RecordAppendResult appendNewBatch(String topic,\n                                          int partition,\n                                          Deque<ProducerBatch> dq,\n                                          long timestamp,\n                                          byte[] key,\n                                          byte[] value,\n                                          Header[] headers,\n                                          AppendCallbacks callbacks,\n                                          ByteBuffer buffer,\n                                          long nowMs) {\n    assert partition != RecordMetadata.UNKNOWN_PARTITION;\n\n    RecordAppendResult appendResult = tryAppend(timestamp, key, value, headers, callbacks, dq, nowMs);\n    if (appendResult != null) {\n            \n        return appendResult;\n    }\n\n    MemoryRecordsBuilder recordsBuilder = recordsBuilder(buffer, apiVersions.maxUsableProduceMagic());\n    ProducerBatch batch = new ProducerBatch(new TopicPartition(topic, partition), recordsBuilder, nowMs);\n    FutureRecordMetadata future = Objects.requireNonNull(batch.tryAppend(timestamp, key, value, headers,\n            callbacks, nowMs));\n\n    dq.addLast(batch);\n    incomplete.add(batch);\n\n    return new RecordAppendResult(future, dq.size() > 1 || batch.isFull(), true, false, batch.estimatedSizeInBytes());\n}", "summary_tokens": ["append", "a", "new", "batch", "to", "the", "queue"], "project": "kafka"}
{"id": 3044, "code": "public static int hash32(byte[] data, int offset, int length, int seed) {\n    int hash = seed;\n    final int nblocks = length >> 2;\n\n        \n    for (int i = 0; i < nblocks; i++) {\n        int i_4 = i << 2;\n        int k = (data[offset + i_4] & 0xff)\n                | ((data[offset + i_4 + 1] & 0xff) << 8)\n                | ((data[offset + i_4 + 2] & 0xff) << 16)\n                | ((data[offset + i_4 + 3] & 0xff) << 24);\n\n        hash = mix32(k, hash);\n    }\n\n        \n    int idx = nblocks << 2;\n    int k1 = 0;\n    switch (length - idx) {\n        case 3:\n            k1 ^= data[offset + idx + 2] << 16;\n        case 2:\n            k1 ^= data[offset + idx + 1] << 8;\n        case 1:\n            k1 ^= data[offset + idx];\n\n                \n            k1 *= C1_32;\n            k1 = Integer.rotateLeft(k1, R1_32);\n            k1 *= C2_32;\n            hash ^= k1;\n    }\n\n    return fmix32(length, hash);\n}", "summary_tokens": ["murmur", "0", "0", "bit", "variant"], "project": "kafka"}
{"id": 871, "code": "public Long reauthenticationLatencyMs() {\n    return authenticator.reauthenticationLatencyMs();\n}", "summary_tokens": ["return", "the", "number", "of", "milliseconds", "that", "elapsed", "while", "re", "authenticating", "this", "session", "from", "the", "perspective", "of", "this", "instance", "if", "applicable", "otherwise", "null"], "project": "kafka"}
{"id": 117, "code": "default DescribeConfigsResult describeConfigs(Collection<ConfigResource> resources) {\n    return describeConfigs(resources, new DescribeConfigsOptions());\n}", "summary_tokens": ["get", "the", "configuration", "for", "the", "specified", "resources", "with", "the", "default", "options"], "project": "kafka"}
{"id": 1099, "code": "public LoginContext login() throws LoginException {\n\n    this.lastLogin = currentElapsedTime();\n    loginContext = super.login();\n    subject = loginContext.getSubject();\n    isKrbTicket = !subject.getPrivateCredentials(KerberosTicket.class).isEmpty();\n\n    AppConfigurationEntry[] entries = configuration().getAppConfigurationEntry(contextName());\n    if (entries.length == 0) {\n        isUsingTicketCache = false;\n        principal = null;\n    } else {\n            \n        AppConfigurationEntry entry = entries[0];\n        if (entry.getOptions().get(\"useTicketCache\") != null) {\n            String val = (String) entry.getOptions().get(\"useTicketCache\");\n            isUsingTicketCache = val.equals(\"true\");\n        } else\n            isUsingTicketCache = false;\n        if (entry.getOptions().get(\"principal\") != null)\n            principal = (String) entry.getOptions().get(\"principal\");\n        else\n            principal = null;\n    }\n\n    if (!isKrbTicket) {\n        log.debug(\"[Principal={}]: It is not a Kerberos ticket\", principal);\n        t = null;\n            \n        return loginContext;\n    }\n    log.debug(\"[Principal={}]: It is a Kerberos ticket\", principal);\n\n        \n        \n        \n        \n    t = KafkaThread.daemon(String.format(\"kafka-kerberos-refresh-thread-%s\", principal), () -> {\n        log.info(\"[Principal={}]: TGT refresh thread started.\", principal);\n        while (true) {  \n            KerberosTicket tgt = getTGT();\n            long now = currentWallTime();\n            long nextRefresh;\n            Date nextRefreshDate;\n            if (tgt == null) {\n                nextRefresh = now + minTimeBeforeRelogin;\n                nextRefreshDate = new Date(nextRefresh);\n                log.warn(\"[Principal={}]: No TGT found: will try again at {}\", principal, nextRefreshDate);\n            } else {\n                nextRefresh = getRefreshTime(tgt);\n                long expiry = tgt.getEndTime().getTime();\n                Date expiryDate = new Date(expiry);\n                if (isUsingTicketCache && tgt.getRenewTill() != null && tgt.getRenewTill().getTime() < expiry) {\n                    log.warn(\"The TGT cannot be renewed beyond the next expiry date: {}.\" +\n                        \"This process will not be able to authenticate new SASL connections after that \" +\n                        \"time (for example, it will not be able to authenticate a new connection with a Kafka \" +\n                        \"Broker).  Ask your system administrator to either increase the \" +\n                        \"'renew until' time by doing : 'modprinc -maxrenewlife {} ' within \" +\n                        \"kadmin, or instead, to generate a keytab for {}. Because the TGT's \" +\n                        \"expiry cannot be further extended by refreshing, exiting refresh thread now.\",\n                        expiryDate, principal, principal);\n                    return;\n                }\n                    \n                    \n                    \n                    \n                if ((nextRefresh > expiry) || (minTimeBeforeRelogin > expiry - now)) {\n                        \n                    log.info(\"[Principal={}]: Refreshing now because expiry is before next scheduled refresh time.\", principal);\n                    nextRefresh = now;\n                } else {\n                    if (nextRefresh - now < minTimeBeforeRelogin) {\n                            \n                        Date until = new Date(nextRefresh);\n                        Date newUntil = new Date(now + minTimeBeforeRelogin);\n                        log.warn(\"[Principal={}]: TGT refresh thread time adjusted from {} to {} since the former is sooner \" +\n                            \"than the minimum refresh interval ({} seconds) from now.\",\n                            principal, until, newUntil, minTimeBeforeRelogin / 1000);\n                    }\n                    nextRefresh = Math.max(nextRefresh, now + minTimeBeforeRelogin);\n                }\n                nextRefreshDate = new Date(nextRefresh);\n                if (nextRefresh > expiry) {\n                    log.error(\"[Principal={}]: Next refresh: {} is later than expiry {}. This may indicate a clock skew problem.\" +\n                        \"Check that this host and the KDC hosts' clocks are in sync. Exiting refresh thread.\",\n                        principal, nextRefreshDate, expiryDate);\n                    return;\n                }\n            }\n            if (now < nextRefresh) {\n                Date until = new Date(nextRefresh);\n                log.info(\"[Principal={}]: TGT refresh sleeping until: {}\", principal, until);\n                try {\n                    Thread.sleep(nextRefresh - now);\n                } catch (InterruptedException ie) {\n                    log.warn(\"[Principal={}]: TGT renewal thread has been interrupted and will exit.\", principal);\n                    return;\n                }\n            } else {\n                log.error(\"[Principal={}]: NextRefresh: {} is in the past: exiting refresh thread. Check\"\n                    + \" clock sync between this host and KDC - (KDC's clock is likely ahead of this host).\"\n                    + \" Manual intervention will be required for this client to successfully authenticate.\"\n                    + \" Exiting refresh thread.\", principal, nextRefreshDate);\n                return;\n            }\n            if (isUsingTicketCache) {\n                String kinitArgs = \"-R\";\n                int retry = 1;\n                while (retry >= 0) {\n                    try {\n                        log.debug(\"[Principal={}]: Running ticket cache refresh command: {} {}\", principal, kinitCmd, kinitArgs);\n                        Shell.execCommand(kinitCmd, kinitArgs);\n                        break;\n                    } catch (Exception e) {\n                        if (retry > 0) {\n                            log.warn(\"[Principal={}]: Error when trying to renew with TicketCache, but will retry \", principal, e);\n                            --retry;\n                                \n                            try {\n                                Thread.sleep(10 * 1000);\n                            } catch (InterruptedException ie) {\n                                log.error(\"[Principal={}]: Interrupted while renewing TGT, exiting Login thread\", principal);\n                                return;\n                            }\n                        } else {\n                            log.warn(\"[Principal={}]: Could not renew TGT due to problem running shell command: '{} {}'. \" +\n                                \"Exiting refresh thread.\", principal, kinitCmd, kinitArgs, e);\n                            return;\n                        }\n                    }\n                }\n            }\n            try {\n                int retry = 1;\n                while (retry >= 0) {\n                    try {\n                        reLogin();\n                        break;\n                    } catch (LoginException le) {\n                        if (retry > 0) {\n                            log.warn(\"[Principal={}]: Error when trying to re-Login, but will retry \", principal, le);\n                            --retry;\n                                \n                            try {\n                                Thread.sleep(10 * 1000);\n                            } catch (InterruptedException e) {\n                                log.error(\"[Principal={}]: Interrupted during login retry after LoginException:\", principal, le);\n                                throw le;\n                            }\n                        } else {\n                            log.error(\"[Principal={}]: Could not refresh TGT.\", principal, le);\n                        }\n                    }\n                }\n            } catch (LoginException le) {\n                log.error(\"[Principal={}]: Failed to refresh TGT: refresh thread exiting now.\", principal, le);\n                return;\n            }\n        }\n    });\n    t.start();\n    return loginContext;\n}", "summary_tokens": ["performs", "login", "for", "each", "login", "module", "specified", "for", "the", "login", "context", "of", "this", "instance", "and", "starts", "the", "thread", "used", "to", "periodically", "re", "login", "to", "the", "kerberos", "ticket", "granting", "server"], "project": "kafka"}
{"id": 3064, "code": "public void addDirtyEntryFlushListener(final String namespace, final DirtyEntryFlushListener listener) {\n    final NamedCache cache = getOrCreateCache(namespace);\n    cache.setListener(listener);\n}", "summary_tokens": ["add", "a", "listener", "that", "is", "called", "each", "time", "an", "entry", "is", "evicted", "from", "the", "cache", "or", "an", "explicit", "flush", "is", "called"], "project": "kafka"}
{"id": 1121, "code": "public String errorUri() {\n    return errorUri;\n}", "summary_tokens": ["return", "the", "potentially", "null", "error", "uri", "as", "per", "a", "href", "https", "tools"], "project": "kafka"}
{"id": 552, "code": "public void setMockMetrics(MetricName name, Metric metric) {\n    mockMetrics.put(name, metric);\n}", "summary_tokens": ["set", "a", "mock", "metric", "for", "testing", "purpose"], "project": "kafka"}
{"id": 2923, "code": "public List<String> sourceTopics() {\n    return super.internalTopologyBuilder.fullSourceTopicNames();\n}", "summary_tokens": ["the", "list", "of", "all", "source", "topics", "this", "topology", "is", "subscribed", "to"], "project": "kafka"}
{"id": 911, "code": "public static byte[] byteBufferToArray(ByteBuffer buf) {\n    byte[] arr = new byte[buf.remaining()];\n    int prevPosition = buf.position();\n    try {\n        buf.get(arr);\n    } finally {\n        buf.position(prevPosition);\n    }\n    return arr;\n}", "summary_tokens": ["copy", "a", "byte", "buffer", "into", "an", "array"], "project": "kafka"}
{"id": 500, "code": "Node selectReadReplica(TopicPartition partition, Node leaderReplica, long currentTimeMs) {\n    Optional<Integer> nodeId = subscriptions.preferredReadReplica(partition, currentTimeMs);\n    if (nodeId.isPresent()) {\n        Optional<Node> node = nodeId.flatMap(id -> metadata.fetch().nodeIfOnline(partition, id));\n        if (node.isPresent()) {\n            return node.get();\n        } else {\n            log.trace(\"Not fetching from {} for partition {} since it is marked offline or is missing from our metadata,\" +\n                      \" using the leader instead.\", nodeId, partition);\n            subscriptions.clearPreferredReadReplica(partition);\n            return leaderReplica;\n        }\n    } else {\n        return leaderReplica;\n    }\n}", "summary_tokens": ["determine", "which", "replica", "to", "read", "from"], "project": "kafka"}
{"id": 2389, "code": "public OptionalInt bytesNeeded(Collection<T> records, ObjectSerializationCache serializationCache) {\n    int bytesNeeded = bytesNeededForRecords(\n        records,\n        serializationCache\n    );\n\n    if (!isOpenForAppends) {\n        return OptionalInt.of(batchHeaderSizeInBytes() + bytesNeeded);\n    }\n\n    int approxUnusedSizeInBytes = maxBytes - approximateSizeInBytes();\n    if (approxUnusedSizeInBytes >= bytesNeeded) {\n        return OptionalInt.empty();\n    } else if (unflushedBytes > 0) {\n        recordOutput.flush();\n        unflushedBytes = 0;\n        int unusedSizeInBytes = maxBytes - flushedSizeInBytes();\n        if (unusedSizeInBytes >= bytesNeeded) {\n            return OptionalInt.empty();\n        }\n    }\n\n    return OptionalInt.of(batchHeaderSizeInBytes() + bytesNeeded);\n}", "summary_tokens": ["check", "whether", "the", "batch", "has", "enough", "room", "for", "all", "the", "record", "values"], "project": "kafka"}
{"id": 1100, "code": "protected void reLogin() throws LoginException {\n    if (!isKrbTicket) {\n        return;\n    }\n    if (loginContext == null) {\n        throw new LoginException(\"Login must be done first\");\n    }\n    if (!hasSufficientTimeElapsed()) {\n        return;\n    }\n    synchronized (KerberosLogin.class) {\n        log.info(\"Initiating logout for {}\", principal);\n            \n        lastLogin = currentElapsedTime();\n            \n            \n            \n            \n        if (subject != null && !subject.getPrincipals().isEmpty()) {\n            logout();\n        }\n            \n            \n        loginContext = new LoginContext(contextName(), subject, null, configuration());\n        log.info(\"Initiating re-login for {}\", principal);\n        login(loginContext);\n    }\n}", "summary_tokens": ["re", "login", "a", "principal"], "project": "kafka"}
{"id": 1448, "code": "public void testCiphersSuiteForTls12FailsForTls13() throws Exception {\n    String cipherSuite = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n\n    sslServerConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Collections.singletonList(\"TLSv1.3\"));\n    sslServerConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL, new TestSecurityConfig(sslServerConfigs), null, TIME);\n\n    sslClientConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Collections.singletonList(\"TLSv1.3\"));\n    sslClientConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n\n    checkAuthentiationFailed();\n}", "summary_tokens": ["tests", "that", "connections", "fails", "if", "tlsv", "0"], "project": "kafka"}
{"id": 523, "code": "synchronized boolean hasPatternSubscription() {\n    return this.subscriptionType == SubscriptionType.AUTO_PATTERN;\n}", "summary_tokens": ["check", "whether", "pattern", "subscription", "is", "in", "use"], "project": "kafka"}
{"id": 1134, "code": "public boolean configured() {\n    return configured;\n}", "summary_tokens": ["return", "true", "if", "this", "instance", "has", "been", "configured", "otherwise", "false"], "project": "kafka"}
{"id": 2181, "code": "String fieldAbstractJavaType(HeaderGenerator headerGenerator,\n                             StructRegistry structRegistry) {\n    if (type instanceof FieldType.BoolFieldType) {\n        return \"boolean\";\n    } else if (type instanceof FieldType.Int8FieldType) {\n        return \"byte\";\n    } else if (type instanceof FieldType.Int16FieldType) {\n        return \"short\";\n    } else if (type instanceof FieldType.Uint16FieldType) {\n        return \"int\";\n    } else if (type instanceof FieldType.Uint32FieldType) {\n        return \"long\";\n    } else if (type instanceof FieldType.Int32FieldType) {\n        return \"int\";\n    } else if (type instanceof FieldType.Int64FieldType) {\n        return \"long\";\n    } else if (type instanceof FieldType.UUIDFieldType) {\n        headerGenerator.addImport(MessageGenerator.UUID_CLASS);\n        return \"Uuid\";\n    } else if (type instanceof FieldType.Float64FieldType) {\n        return \"double\";\n    } else if (type.isString()) {\n        return \"String\";\n    } else if (type.isBytes()) {\n        if (zeroCopy) {\n            headerGenerator.addImport(MessageGenerator.BYTE_BUFFER_CLASS);\n            return \"ByteBuffer\";\n        } else {\n            return \"byte[]\";\n        }\n    } else if (type instanceof FieldType.RecordsFieldType) {\n        headerGenerator.addImport(MessageGenerator.BASE_RECORDS_CLASS);\n        return \"BaseRecords\";\n    } else if (type.isStruct()) {\n        return MessageGenerator.capitalizeFirst(typeString());\n    } else if (type.isArray()) {\n        FieldType.ArrayType arrayType = (FieldType.ArrayType) type;\n        if (structRegistry.isStructArrayWithKeys(this)) {\n            headerGenerator.addImport(MessageGenerator.IMPLICIT_LINKED_HASH_MULTI_COLLECTION_CLASS);\n            return collectionType(arrayType.elementType().toString());\n        } else {\n            headerGenerator.addImport(MessageGenerator.LIST_CLASS);\n            return String.format(\"List<%s>\",\n                arrayType.elementType().getBoxedJavaType(headerGenerator));\n        }\n    } else {\n        throw new RuntimeException(\"Unknown field type \" + type);\n    }\n}", "summary_tokens": ["get", "the", "abstract", "java", "type", "of", "the", "field", "for", "example", "list"], "project": "kafka"}
{"id": 702, "code": "public long getMostSignificantBits() {\n    return this.mostSignificantBits;\n}", "summary_tokens": ["returns", "the", "most", "significant", "bits", "of", "the", "uuid", "s", "0", "value"], "project": "kafka"}
{"id": 1417, "code": "public void testDsaKeyPair(Args args) throws Exception {\n        \n    assumeTrue(args.tlsProtocol.equals(\"TLSv1.2\"));\n    args.serverCertStores = certBuilder(true, \"server\", args.useInlinePem).keyAlgorithm(\"DSA\").build();\n    args.clientCertStores = certBuilder(false, \"client\", args.useInlinePem).keyAlgorithm(\"DSA\").build();\n    args.sslServerConfigs = args.getTrustingConfig(args.serverCertStores, args.clientCertStores);\n    args.sslClientConfigs = args.getTrustingConfig(args.clientCertStores, args.serverCertStores);\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"required\");\n    verifySslConfigs(args);\n}", "summary_tokens": ["tests", "key", "pair", "created", "using", "dsa"], "project": "kafka"}
{"id": 1824, "code": "public String transactionalProducerId() {\n    return transactionalProducerId(groupId());\n}", "summary_tokens": ["the", "producer", "config", "transactional", "id", "config", "transactional", "id", "to", "use", "for", "the", "worker", "s", "producer", "if", "using", "a", "transactional", "producer", "for", "writes", "to", "internal", "topics", "such", "as", "the", "config", "topic"], "project": "kafka"}
{"id": 3219, "code": "public static String dateString(long timeMs, ZoneOffset zoneOffset) {\n    return new Date(timeMs).toInstant().\n        atOffset(zoneOffset).\n        format(DateTimeFormatter.ISO_OFFSET_DATE_TIME);\n}", "summary_tokens": ["pretty", "print", "a", "date", "string"], "project": "kafka"}
{"id": 1812, "code": "public boolean awaitStop(long timeoutMs) {\n    try {\n        return shutdownLatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        return false;\n    }\n}", "summary_tokens": ["wait", "for", "this", "task", "to", "finish", "stopping"], "project": "kafka"}
{"id": 2331, "code": "public void testClaimsLeadership() throws Exception {\n    try (LocalLogManagerTestEnv env =\n             LocalLogManagerTestEnv.createWithMockListeners(1, Optional.empty())) {\n        assertEquals(new LeaderAndEpoch(OptionalInt.of(0), 1), env.waitForLeader());\n        env.close();\n        assertEquals(null, env.firstError.get());\n    }\n}", "summary_tokens": ["test", "that", "the", "local", "log", "manager", "will", "claim", "leadership"], "project": "kafka"}
{"id": 595, "code": "public long baseOffset() {\n    return baseOffset;\n}", "summary_tokens": ["the", "base", "offset", "for", "the", "request", "the", "first", "offset", "in", "the", "record", "set"], "project": "kafka"}
{"id": 2434, "code": "public long eventTimestampMs() {\n    return eventTimestampMs;\n}", "summary_tokens": ["epoch", "time", "in", "milli", "seconds", "at", "which", "this", "event", "is", "occurred"], "project": "kafka"}
{"id": 2093, "code": "public static List<String> pluginPath() {\n    return PLUGIN_JARS.values()\n        .stream()\n        .map(File::getPath)\n        .collect(Collectors.toList());\n}", "summary_tokens": ["a", "list", "of", "jar", "files", "containing", "test", "plugins", "a", "list", "of", "plugin", "jar", "filenames"], "project": "kafka"}
{"id": 3140, "code": "public boolean flushedEntryRemoved(final K key) {\n    return flushedRemovals.contains(key);\n}", "summary_tokens": ["determine", "whether", "the", "store", "key", "value", "store", "flush", "flushed", "the", "removal", "of", "the", "given", "key"], "project": "kafka"}
{"id": 2924, "code": "public NamedTopologyStoreQueryParameters<T> withPartition(final Integer partition) {\n    return new NamedTopologyStoreQueryParameters<>(this.topologyName(), this.storeName(), this.queryableStoreType(), partition, this.staleStoresEnabled());\n}", "summary_tokens": ["see", "store", "query", "parameters", "with", "partition", "integer"], "project": "kafka"}
{"id": 1322, "code": "public static DeleteTopicsResult deleteTopicsResult(String topic, Throwable t) {\n    KafkaFutureImpl<Void> future = new KafkaFutureImpl<>();\n    future.completeExceptionally(t);\n    return DeleteTopicsResult.ofTopicNames(Collections.singletonMap(topic, future));\n}", "summary_tokens": ["helper", "to", "create", "a", "delete", "topics", "result", "instance", "for", "a", "given", "throwable"], "project": "kafka"}
{"id": 112, "code": "default DescribeTopicsResult describeTopics(TopicCollection topics) {\n    return describeTopics(topics, new DescribeTopicsOptions());\n}", "summary_tokens": ["this", "is", "a", "convenience", "method", "for", "describe", "topics", "topic", "collection", "describe", "topics", "options", "with", "default", "options"], "project": "kafka"}
{"id": 2814, "code": "private Cancellable schedule(final long startTime, final long interval, final PunctuationType type, final Punctuator punctuator) {\n    if (processorContext.currentNode() == null) {\n        throw new IllegalStateException(String.format(\"%sCurrent node is null\", logPrefix));\n    }\n\n    final PunctuationSchedule schedule = new PunctuationSchedule(processorContext.currentNode(), startTime, interval, punctuator);\n\n    switch (type) {\n        case STREAM_TIME:\n                \n                \n            return streamTimePunctuationQueue.schedule(schedule);\n        case WALL_CLOCK_TIME:\n                \n            return systemTimePunctuationQueue.schedule(schedule);\n        default:\n            throw new IllegalArgumentException(\"Unrecognized PunctuationType: \" + type);\n    }\n}", "summary_tokens": ["schedules", "a", "punctuation", "for", "the", "processor"], "project": "kafka"}
{"id": 2237, "code": "OptionalLong highestPendingOffset() {\n    if (pending.isEmpty()) {\n        return OptionalLong.empty();\n    } else {\n        return OptionalLong.of(pending.lastKey());\n    }\n}", "summary_tokens": ["get", "the", "offset", "of", "the", "highest", "pending", "event", "or", "empty", "if", "there", "are", "no", "pending", "events"], "project": "kafka"}
{"id": 1915, "code": "public URI adminUrl() {\n    ServerConnector adminConnector = null;\n    for (Connector connector : jettyServer.getConnectors()) {\n        if (ADMIN_SERVER_CONNECTOR_NAME.equals(connector.getName()))\n            adminConnector = (ServerConnector) connector;\n    }\n\n    if (adminConnector == null) {\n        List<String> adminListeners = config.getList(WorkerConfig.ADMIN_LISTENERS_CONFIG);\n        if (adminListeners == null) {\n            return advertisedUrl();\n        } else if (adminListeners.isEmpty()) {\n            return null;\n        } else {\n            log.error(\"No admin connector found for listeners {}\", adminListeners);\n            return null;\n        }\n    }\n\n    UriBuilder builder = UriBuilder.fromUri(jettyServer.getURI());\n    builder.port(adminConnector.getLocalPort());\n\n    return builder.build();\n}", "summary_tokens": ["the", "admin", "url", "for", "this", "worker"], "project": "kafka"}
{"id": 1414, "code": "public void testClientAuthenticationDisabledNotProvided(Args args) throws Exception {\n    args.sslServerConfigs.put(BrokerSecurityConfigs.SSL_CLIENT_AUTH_CONFIG, \"none\");\n\n    CertStores.KEYSTORE_PROPS.forEach(args.sslClientConfigs::remove);\n    verifySslConfigs(args);\n}", "summary_tokens": ["tests", "that", "server", "accepts", "connections", "from", "a", "client", "that", "does", "not", "provide", "a", "certificate", "if", "client", "authentication", "is", "disabled"], "project": "kafka"}
{"id": 1005, "code": "public static void write(DataOutputStream out,\n                         byte magic,\n                         long crc,\n                         byte attributes,\n                         long timestamp,\n                         byte[] key,\n                         byte[] value) throws IOException {\n    write(out, magic, crc, attributes, timestamp, wrapNullable(key), wrapNullable(value));\n}", "summary_tokens": ["write", "a", "record", "using", "raw", "fields", "without", "validation"], "project": "kafka"}
{"id": 107, "code": "static Admin create(Map<String, Object> conf) {\n    return KafkaAdminClient.createInternal(new AdminClientConfig(conf, true), null, null);\n}", "summary_tokens": ["create", "a", "new", "admin", "with", "the", "given", "configuration"], "project": "kafka"}
{"id": 1834, "code": "public short version() {\n    return version;\n}", "summary_tokens": ["return", "the", "version", "of", "the", "connect", "protocol", "that", "this", "assignment", "belongs", "to"], "project": "kafka"}
{"id": 2136, "code": "public void assertExactlyNumWorkersAreUp(int numWorkers, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkWorkersUp(numWorkers, (actual, expected) -> actual == expected).orElse(false),\n            WORKER_SETUP_DURATION_MS,\n            \"Didn't meet the exact requested number of online workers: \" + numWorkers);\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "at", "least", "the", "requested", "number", "of", "workers", "are", "up", "and", "running"], "project": "kafka"}
{"id": 2681, "code": "public long onInvalidTimestamp(final ConsumerRecord<Object, Object> record,\n                               final long recordTimestamp,\n                               final long partitionTime)\n        throws StreamsException {\n\n    final String message = \"Input record \" + record + \" has invalid (negative) timestamp. \" +\n        \"Possibly because a pre-0.10 producer client was used to write this record to Kafka without embedding \" +\n        \"a timestamp, or because the input topic was created before upgrading the Kafka cluster to 0.10+. \" +\n        \"Use a different TimestampExtractor to process this data.\";\n\n    log.error(message);\n    throw new StreamsException(message);\n}", "summary_tokens": ["raises", "an", "exception", "on", "every", "call"], "project": "kafka"}
{"id": 1876, "code": "public Stage stage() {\n    return position;\n}", "summary_tokens": ["the", "stage", "in", "the", "connector", "pipeline", "which", "is", "currently", "executing"], "project": "kafka"}
{"id": 1344, "code": "public void testFetchRequestWhenRecordTooLarge() {\n    try {\n        buildFetcher();\n\n        client.setNodeApiVersions(NodeApiVersions.create(ApiKeys.FETCH.id, (short) 2, (short) 2));\n        makeFetchRequestWithIncompleteRecord();\n        try {\n            fetcher.collectFetch();\n            fail(\"RecordTooLargeException should have been raised\");\n        } catch (RecordTooLargeException e) {\n            assertTrue(e.getMessage().startsWith(\"There are some messages at [Partition=Offset]: \"));\n                \n            assertEquals(0, subscriptions.position(tp0).offset);\n        }\n    } finally {\n        client.setNodeApiVersions(NodeApiVersions.create());\n    }\n}", "summary_tokens": ["test", "the", "case", "where", "the", "client", "makes", "a", "pre", "v", "0", "fetch", "request", "but", "the", "server", "replies", "with", "only", "a", "partial", "request"], "project": "kafka"}
{"id": 1893, "code": "public PluginClassLoader pluginClassLoader(String name) {\n    if (!PluginUtils.shouldLoadInIsolation(name)) {\n        return null;\n    }\n    SortedMap<PluginDesc<?>, ClassLoader> inner = pluginLoaders.get(name);\n    if (inner == null) {\n        return null;\n    }\n    ClassLoader pluginLoader = inner.get(inner.lastKey());\n    return pluginLoader instanceof PluginClassLoader\n           ? (PluginClassLoader) pluginLoader\n           : null;\n}", "summary_tokens": ["retrieve", "the", "plugin", "class", "loader", "associated", "with", "a", "plugin", "class", "name", "the", "fully", "qualified", "class", "name", "of", "the", "plugin", "the", "plugin", "class", "loader", "that", "should", "be", "used", "to", "load", "this", "or", "null", "if", "the", "plugin", "is", "not", "isolated"], "project": "kafka"}
{"id": 3201, "code": "static ArgumentParser argParser() {\n    ArgumentParser parser = ArgumentParsers\n            .newArgumentParser(\"producer-performance\")\n            .defaultHelp(true)\n            .description(\"This tool is used to verify the producer performance.\");\n\n    MutuallyExclusiveGroup payloadOptions = parser\n            .addMutuallyExclusiveGroup()\n            .required(true)\n            .description(\"either --record-size or --payload-file must be specified but not both.\");\n\n    parser.addArgument(\"--topic\")\n            .action(store())\n            .required(true)\n            .type(String.class)\n            .metavar(\"TOPIC\")\n            .help(\"produce messages to this topic\");\n\n    parser.addArgument(\"--num-records\")\n            .action(store())\n            .required(true)\n            .type(Long.class)\n            .metavar(\"NUM-RECORDS\")\n            .dest(\"numRecords\")\n            .help(\"number of messages to produce\");\n\n    payloadOptions.addArgument(\"--record-size\")\n            .action(store())\n            .required(false)\n            .type(Integer.class)\n            .metavar(\"RECORD-SIZE\")\n            .dest(\"recordSize\")\n            .help(\"message size in bytes. Note that you must provide exactly one of --record-size or --payload-file.\");\n\n    payloadOptions.addArgument(\"--payload-file\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"PAYLOAD-FILE\")\n            .dest(\"payloadFile\")\n            .help(\"file to read the message payloads from. This works only for UTF-8 encoded text files. \" +\n                    \"Payloads will be read from this file and a payload will be randomly selected when sending messages. \" +\n                    \"Note that you must provide exactly one of --record-size or --payload-file.\");\n\n    parser.addArgument(\"--payload-delimiter\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"PAYLOAD-DELIMITER\")\n            .dest(\"payloadDelimiter\")\n            .setDefault(\"\\\\n\")\n            .help(\"provides delimiter to be used when --payload-file is provided. \" +\n                    \"Defaults to new line. \" +\n                    \"Note that this parameter will be ignored if --payload-file is not provided.\");\n\n    parser.addArgument(\"--throughput\")\n            .action(store())\n            .required(true)\n            .type(Integer.class)\n            .metavar(\"THROUGHPUT\")\n            .help(\"throttle maximum message throughput to *approximately* THROUGHPUT messages/sec. Set this to -1 to disable throttling.\");\n\n    parser.addArgument(\"--producer-props\")\n             .nargs(\"+\")\n             .required(false)\n             .metavar(\"PROP-NAME=PROP-VALUE\")\n             .type(String.class)\n             .dest(\"producerConfig\")\n             .help(\"kafka producer related configuration properties like bootstrap.servers,client.id etc. \" +\n                     \"These configs take precedence over those passed via --producer.config.\");\n\n    parser.addArgument(\"--producer.config\")\n            .action(store())\n            .required(false)\n            .type(String.class)\n            .metavar(\"CONFIG-FILE\")\n            .dest(\"producerConfigFile\")\n            .help(\"producer config properties file.\");\n\n    parser.addArgument(\"--print-metrics\")\n            .action(storeTrue())\n            .type(Boolean.class)\n            .metavar(\"PRINT-METRICS\")\n            .dest(\"printMetrics\")\n            .help(\"print out metrics at the end of the test.\");\n\n    parser.addArgument(\"--transactional-id\")\n           .action(store())\n           .required(false)\n           .type(String.class)\n           .metavar(\"TRANSACTIONAL-ID\")\n           .dest(\"transactionalId\")\n           .setDefault(\"performance-producer-default-transactional-id\")\n           .help(\"The transactionalId to use if transaction-duration-ms is > 0. Useful when testing the performance of concurrent transactions.\");\n\n    parser.addArgument(\"--transaction-duration-ms\")\n           .action(store())\n           .required(false)\n           .type(Long.class)\n           .metavar(\"TRANSACTION-DURATION\")\n           .dest(\"transactionDurationMs\")\n           .setDefault(0L)\n           .help(\"The max age of each transaction. The commitTransaction will be called after this time has elapsed. Transactions are only enabled if this value is positive.\");\n\n\n    return parser;\n}", "summary_tokens": ["get", "the", "command", "line", "argument", "parser"], "project": "kafka"}
{"id": 489, "code": "public Map<String, List<PartitionInfo>> getAllTopicMetadata(Timer timer) {\n    return getTopicMetadata(MetadataRequest.Builder.allTopics(), timer);\n}", "summary_tokens": ["get", "topic", "metadata", "for", "all", "topics", "in", "the", "cluster", "timer", "timer", "bounding", "how", "long", "this", "method", "can", "block", "the", "map", "of", "topics", "with", "their", "partition", "information"], "project": "kafka"}
{"id": 1573, "code": "public static void retryOnExceptionWithTimeout(final long timeoutMs,\n                                               final long pollIntervalMs,\n                                               final ValuelessCallable runnable) throws InterruptedException {\n    final long expectedEnd = System.currentTimeMillis() + timeoutMs;\n\n    while (true) {\n        try {\n            runnable.call();\n            return;\n        } catch (final NoRetryException e) {\n            throw e;\n        } catch (final AssertionError t) {\n            if (expectedEnd <= System.currentTimeMillis()) {\n                throw t;\n            }\n        } catch (final Exception e) {\n            if (expectedEnd <= System.currentTimeMillis()) {\n                throw new AssertionError(String.format(\"Assertion failed with an exception after %s ms\", timeoutMs), e);\n            }\n        }\n        Thread.sleep(Math.min(pollIntervalMs, timeoutMs));\n    }\n}", "summary_tokens": ["wait", "for", "the", "given", "runnable", "to", "complete", "successfully", "i"], "project": "kafka"}
{"id": 147, "code": "default AbortTransactionResult abortTransaction(AbortTransactionSpec spec) {\n    return abortTransaction(spec, new AbortTransactionOptions());\n}", "summary_tokens": ["forcefully", "abort", "a", "transaction", "which", "is", "open", "on", "a", "topic", "partition"], "project": "kafka"}
{"id": 3095, "code": "public static <V> void produceValuesSynchronously(final String topic,\n                                                  final Collection<V> records,\n                                                  final Properties producerConfig,\n                                                  final Time time,\n                                                  final boolean enableTransactions) {\n    final Collection<KeyValue<Object, V>> keyedRecords = new ArrayList<>();\n    for (final V value : records) {\n        final KeyValue<Object, V> kv = new KeyValue<>(null, value);\n        keyedRecords.add(kv);\n    }\n    produceKeyValuesSynchronously(topic, keyedRecords, producerConfig, time, enableTransactions);\n}", "summary_tokens": ["topic", "kafka", "topic", "to", "write", "the", "data", "records", "to", "records", "data", "records", "to", "write", "to", "kafka", "producer", "config", "kafka", "producer", "configuration", "time", "timestamp", "provider", "enable", "transactions", "send", "messages", "in", "a", "transaction", "v", "value", "type", "of", "the", "data", "records"], "project": "kafka"}
{"id": 2334, "code": "public void appendInitialRecords(List<ApiMessageAndVersion> records) {\n    int initialLeaderEpoch = 1;\n    shared.append(new LeaderChangeBatch(\n        new LeaderAndEpoch(OptionalInt.empty(), initialLeaderEpoch + 1)));\n    shared.append(new LocalRecordBatch(initialLeaderEpoch + 1, 0, records));\n    shared.append(new LeaderChangeBatch(\n        new LeaderAndEpoch(OptionalInt.of(0), initialLeaderEpoch + 2)));\n}", "summary_tokens": ["append", "some", "records", "to", "the", "log"], "project": "kafka"}
{"id": 1907, "code": "public static void addToRequest(SecretKey key, byte[] requestBody, String signatureAlgorithm, Request request) {\n    Mac mac;\n    try {\n        mac = mac(signatureAlgorithm);\n    }  catch (NoSuchAlgorithmException e) {\n        throw new ConnectException(e);\n    }\n    byte[] requestSignature = sign(mac, key, requestBody);\n    request.header(InternalRequestSignature.SIGNATURE_HEADER, Base64.getEncoder().encodeToString(requestSignature))\n           .header(InternalRequestSignature.SIGNATURE_ALGORITHM_HEADER, signatureAlgorithm);\n}", "summary_tokens": ["add", "a", "signature", "to", "a", "request"], "project": "kafka"}
{"id": 2647, "code": "public static <K, KO> TableJoined<K, KO> as(final String name) {\n    return new TableJoined<>(null, null, name);\n}", "summary_tokens": ["create", "an", "instance", "of", "table", "joined", "with", "base", "name", "for", "all", "components", "of", "the", "join", "including", "internal", "topics", "created", "to", "complete", "the", "join"], "project": "kafka"}
{"id": 2712, "code": "default void close() {}", "summary_tokens": ["close", "this", "processor", "and", "clean", "up", "any", "resources"], "project": "kafka"}
{"id": 2249, "code": "void handleBrokerUnregistered(int brokerId, long brokerEpoch,\n                              List<ApiMessageAndVersion> records) {\n    generateLeaderAndIsrUpdates(\"handleBrokerUnregistered\", brokerId, NO_LEADER, records,\n        brokersToIsrs.partitionsWithBrokerInIsr(brokerId));\n    records.add(new ApiMessageAndVersion(new UnregisterBrokerRecord().\n        setBrokerId(brokerId).setBrokerEpoch(brokerEpoch),\n        (short) 0));\n}", "summary_tokens": ["generate", "the", "appropriate", "records", "to", "handle", "a", "broker", "being", "unregistered"], "project": "kafka"}
{"id": 71, "code": "public synchronized void close() {\n    this.isClosed = true;\n}", "summary_tokens": ["close", "this", "metadata", "instance", "to", "indicate", "that", "metadata", "updates", "are", "no", "longer", "possible"], "project": "kafka"}
{"id": 3242, "code": "private synchronized KiboshProcess findProcessObject(String mountPath) {\n    String path = Paths.get(mountPath).normalize().toString();\n    KiboshProcess process = processes.get(path);\n    if (process == null) {\n        process = new KiboshProcess(mountPath);\n        processes.put(path, process);\n    }\n    return process;\n}", "summary_tokens": ["get", "or", "create", "a", "kibosh", "process", "object", "to", "manage", "the", "kibosh", "process", "at", "a", "given", "path"], "project": "kafka"}
{"id": 134, "code": "default ElectLeadersResult electLeaders(ElectionType electionType, Set<TopicPartition> partitions) {\n    return electLeaders(electionType, partitions, new ElectLeadersOptions());\n}", "summary_tokens": ["elect", "a", "replica", "as", "leader", "for", "topic", "partitions"], "project": "kafka"}
{"id": 2216, "code": "void updateControlledShutdownOffset(int brokerId, long controlledShutDownOffset) {\n    BrokerHeartbeatState broker = brokers.get(brokerId);\n    if (broker == null) {\n        throw new RuntimeException(\"Unable to locate broker \" + brokerId);\n    }\n    if (broker.fenced()) {\n        throw new RuntimeException(\"Fenced brokers cannot enter controlled shutdown.\");\n    }\n    active.remove(broker);\n    broker.controlledShutDownOffset = controlledShutDownOffset;\n    log.debug(\"Updated the controlled shutdown offset for broker {} to {}.\",\n        brokerId, controlledShutDownOffset);\n}", "summary_tokens": ["mark", "a", "broker", "as", "being", "in", "the", "controlled", "shutdown", "state"], "project": "kafka"}
{"id": 355, "code": "public List<ScramCredentialInfo> credentialInfos() {\n    return credentialInfos;\n}", "summary_tokens": ["the", "always", "non", "null", "unmodifiable", "list", "of", "sasl", "scram", "credential", "representations", "for", "the", "user"], "project": "kafka"}
{"id": 475, "code": "public boolean awaitPendingRequests(Node node, Timer timer) {\n    while (hasPendingRequests(node) && timer.notExpired()) {\n        poll(timer);\n    }\n    return !hasPendingRequests(node);\n}", "summary_tokens": ["block", "until", "all", "pending", "requests", "from", "the", "given", "node", "have", "finished"], "project": "kafka"}
{"id": 222, "code": "public KafkaFuture<Void> all() {\n    return (topicIdFutures == null) ? KafkaFuture.allOf(nameFutures.values().toArray(new KafkaFuture[0])) :\n        KafkaFuture.allOf(topicIdFutures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["a", "future", "which", "succeeds", "only", "if", "all", "the", "topic", "deletions", "succeed"], "project": "kafka"}
{"id": 1865, "code": "public void recordSkipped() {\n    recordsSkipped.record();\n}", "summary_tokens": ["increment", "the", "number", "of", "records", "skipped"], "project": "kafka"}
{"id": 858, "code": "public KafkaPrincipal principal() {\n    return authenticator.principal();\n}", "summary_tokens": ["returns", "the", "principal", "returned", "by", "authenticator"], "project": "kafka"}
{"id": 2721, "code": "public void maybeCheckpoint(final boolean enforceCheckpoint) {\n    final Map<TopicPartition, Long> offsetSnapshot = stateMgr.changelogOffsets();\n    if (StateManagerUtil.checkpointNeeded(enforceCheckpoint, offsetSnapshotSinceLastFlush, offsetSnapshot)) {\n            \n        stateMgr.flush();\n        stateMgr.checkpoint();\n        offsetSnapshotSinceLastFlush = new HashMap<>(offsetSnapshot);\n    }\n}", "summary_tokens": ["the", "following", "exceptions", "maybe", "thrown", "from", "the", "state", "manager", "flushing", "call"], "project": "kafka"}
{"id": 413, "code": "public void enforceRebalance(final String reason) {\n    acquireAndEnsureOpen();\n    try {\n        if (coordinator == null) {\n            throw new IllegalStateException(\"Tried to force a rebalance but consumer does not have a group.\");\n        }\n        coordinator.requestRejoin(reason == null || reason.isEmpty() ? DEFAULT_REASON : reason);\n    } finally {\n        release();\n    }\n}", "summary_tokens": ["alert", "the", "consumer", "to", "trigger", "a", "new", "rebalance", "by", "rejoining", "the", "group"], "project": "kafka"}
{"id": 1294, "code": "public void reset(long timeoutMs) {\n    if (timeoutMs < 0)\n        throw new IllegalArgumentException(\"Invalid negative timeout \" + timeoutMs);\n\n    this.timeoutMs = timeoutMs;\n    this.startMs = this.currentTimeMs;\n\n    if (currentTimeMs > Long.MAX_VALUE - timeoutMs)\n        this.deadlineMs = Long.MAX_VALUE;\n    else\n        this.deadlineMs = currentTimeMs + timeoutMs;\n}", "summary_tokens": ["reset", "the", "timer", "using", "a", "new", "timeout"], "project": "kafka"}
{"id": 3041, "code": "public KeyValueIterator<Bytes, byte[]> all() {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support all() function.\");\n}", "summary_tokens": ["unsupported", "operation", "exception", "at", "every", "invocation"], "project": "kafka"}
{"id": 477, "code": "public boolean hasPendingRequests() {\n    if (unsent.hasRequests())\n        return true;\n    lock.lock();\n    try {\n        return client.hasInFlightRequests();\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["check", "whether", "there", "is", "pending", "request"], "project": "kafka"}
{"id": 2470, "code": "private boolean createTopic(AdminClient adminClient, NewTopic topic) {\n    boolean topicCreated = false;\n    try {\n        adminClient.createTopics(Collections.singleton(topic)).all().get();\n        topicCreated = true;\n    } catch (Exception e) {\n        if (e.getCause() instanceof TopicExistsException) {\n            log.info(\"Topic [{}] already exists\", topic.name());\n            topicCreated = true;\n        } else {\n            log.error(\"Encountered error while creating remote log metadata topic.\", e);\n        }\n    }\n\n    return topicCreated;\n}", "summary_tokens": ["topic", "topic", "to", "be", "created"], "project": "kafka"}
{"id": 532, "code": "public synchronized Optional<Integer> preferredReadReplica(TopicPartition tp, long timeMs) {\n    final TopicPartitionState topicPartitionState = assignedStateOrNull(tp);\n    if (topicPartitionState == null) {\n        return Optional.empty();\n    } else {\n        return topicPartitionState.preferredReadReplica(timeMs);\n    }\n}", "summary_tokens": ["get", "the", "preferred", "read", "replica"], "project": "kafka"}
{"id": 1896, "code": "public static boolean isConcrete(Class<?> klass) {\n    int mod = klass.getModifiers();\n    return !Modifier.isAbstract(mod) && !Modifier.isInterface(mod);\n}", "summary_tokens": ["verify", "the", "given", "class", "corresponds", "to", "a", "concrete", "class", "and", "not", "to", "an", "abstract", "class", "or", "interface"], "project": "kafka"}
{"id": 2183, "code": "    void generateNonDefaultValueCheck(HeaderGenerator headerGenerator,\n                                      StructRegistry structRegistry,\n                                      CodeBuffer buffer,\n                                      String fieldPrefix,\n                                      Versions nullableVersions) {\n        String fieldDefault = fieldDefault(headerGenerator, structRegistry);\n        if (type().isArray()) {\n            if (fieldDefault.equals(\"null\")) {\n                buffer.printf(\"if (%s%s != null) {%n\", fieldPrefix, camelCaseName());\n            } else if (nullableVersions.empty()) {\n                buffer.printf(\"if (!%s%s.isEmpty()) {%n\", fieldPrefix, camelCaseName());\n            } else {\n                buffer.printf(\"if (%s%s == null || !%s%s.isEmpty()) {%n\",\n                    fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName());\n            }\n        } else if (type().isBytes()) {\n            if (fieldDefault.equals(\"null\")) {\n                buffer.printf(\"if (%s%s != null) {%n\", fieldPrefix, camelCaseName());\n            } else if (nullableVersions.empty()) {\n                if (zeroCopy()) {\n                    buffer.printf(\"if (%s%s.hasRemaining()) {%n\",\n                        fieldPrefix, camelCaseName());\n                } else {\n                    buffer.printf(\"if (%s%s.length != 0) {%n\",\n                        fieldPrefix, camelCaseName());\n                }\n            } else {\n                if (zeroCopy()) {\n                    buffer.printf(\"if (%s%s == null || %s%s.remaining() > 0) {%n\",\n                        fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName());\n                } else {\n                    buffer.printf(\"if (%s%s == null || %s%s.length != 0) {%n\",\n                        fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName());\n                }\n            }\n        } else if (type().isString() || type().isStruct() || type() instanceof FieldType.UUIDFieldType) {\n            if (fieldDefault.equals(\"null\")) {\n                buffer.printf(\"if (%s%s != null) {%n\", fieldPrefix, camelCaseName());\n            } else if (nullableVersions.empty()) {\n                buffer.printf(\"if (!%s%s.equals(%s)) {%n\",\n                    fieldPrefix, camelCaseName(), fieldDefault);\n            } else {\n                buffer.printf(\"if (%s%s == null || !%s%s.equals(%s)) {%n\",\n                    fieldPrefix, camelCaseName(), fieldPrefix, camelCaseName(),\n                    fieldDefault);\n            }\n        } else if (type() instanceof FieldType.BoolFieldType) {\n            buffer.printf(\"if (%s%s%s) {%n\",\n                fieldDefault.equals(\"true\") ? \"!\" : \"\",\n                fieldPrefix, camelCaseName());\n        } else {\n            buffer.printf(\"if (%s%s != %s) {%n\",\n                fieldPrefix, camelCaseName(), fieldDefault);\n        }\n    }\n\n    \n    void generateNonIgnorableFieldCheck(HeaderGenerator headerGenerator,\n                                        StructRegistry structRegistry,\n                                        String fieldPrefix,\n                                        CodeBuffer buffer) {\n        generateNonDefaultValueCheck(headerGenerator, structRegistry,\n            buffer, fieldPrefix, nullableVersions());\n        buffer.incrementIndent();\n        headerGenerator.addImport(MessageGenerator.UNSUPPORTED_VERSION_EXCEPTION_CLASS);\n        buffer.printf(\"throw new UnsupportedVersionException(\" +\n                \"\\\"Attempted to write a non-default %s at version \\\" + _version);%n\",\n            camelCaseName());\n        buffer.decrementIndent();\n        buffer.printf(\"}%n\");\n    }\n}\n", "summary_tokens": ["generate", "an", "if", "statement", "that", "checks", "if", "this", "field", "has", "a", "non", "default", "value"], "project": "kafka"}
{"id": 1329, "code": "public void testPropagatedMetadataFetchException() throws Exception {\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(Time.SYSTEM,\n            mockCluster(3, 0),\n            newStrMap(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:8121\",\n            AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"10\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        env.kafkaClient().createPendingAuthenticationError(env.cluster().nodeById(0),\n                TimeUnit.DAYS.toMillis(1));\n        env.kafkaClient().prepareResponse(prepareCreateTopicsResponse(\"myTopic\", Errors.NONE));\n        KafkaFuture<Void> future = env.adminClient().createTopics(\n            singleton(new NewTopic(\"myTopic\", Collections.singletonMap(0, asList(0, 1, 2)))),\n            new CreateTopicsOptions().timeoutMs(1000)).all();\n        TestUtils.assertFutureError(future, SaslAuthenticationException.class);\n    }\n}", "summary_tokens": ["test", "that", "we", "propagate", "exceptions", "encountered", "when", "fetching", "metadata"], "project": "kafka"}
{"id": 2534, "code": "public Map<String, Object> getGlobalConsumerConfigs(final String clientId) {\n    final Map<String, Object> baseConsumerProps = getCommonConsumerConfigs();\n\n        \n    final Map<String, Object> globalConsumerProps = originalsWithPrefix(GLOBAL_CONSUMER_PREFIX);\n    for (final Map.Entry<String, Object> entry: globalConsumerProps.entrySet()) {\n        baseConsumerProps.put(entry.getKey(), entry.getValue());\n    }\n\n        \n    baseConsumerProps.remove(ConsumerConfig.GROUP_ID_CONFIG);\n        \n    baseConsumerProps.remove(ConsumerConfig.GROUP_INSTANCE_ID_CONFIG);\n\n        \n    baseConsumerProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId + \"-global-consumer\");\n    baseConsumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"none\");\n\n    return baseConsumerProps;\n}", "summary_tokens": ["get", "the", "configs", "for", "the", "kafka", "consumer", "global", "consumer"], "project": "kafka"}
{"id": 1395, "code": "public void testPartialReceiveGracefulClose() throws Exception {\n    String id = \"0\";\n    blockingConnect(id);\n    KafkaChannel channel = selector.channel(id);\n        \n    injectNetworkReceive(channel, 100000);\n    sendNoReceive(channel, 2); \n    selector.poll(1000); \n    assertEquals(0, selector.completedReceives().size());\n    server.closeConnections();\n    TestUtils.waitForCondition(() -> {\n        try {\n            selector.poll(100);\n            return !selector.disconnected().isEmpty();\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    }, 10000, \"Channel not disconnected\");\n    assertEquals(1, selector.disconnected().size());\n    assertEquals(channel.id(), selector.disconnected().keySet().iterator().next());\n    assertEquals(0, selector.completedReceives().size());\n}", "summary_tokens": ["tests", "that", "graceful", "close", "is", "not", "delayed", "if", "only", "part", "of", "an", "incoming", "receive", "is", "available", "in", "the", "socket", "buffer"], "project": "kafka"}
{"id": 2863, "code": "public Map<TaskId, Long> getTaskOffsetSums() {\n    final Map<TaskId, Long> taskOffsetSums = new HashMap<>();\n\n        \n        \n        \n    for (final TaskId id : union(HashSet::new, lockedTaskDirectories, tasks.allTaskIds())) {\n        final Task task = tasks.contains(id) ? tasks.task(id) : null;\n            \n        if (task != null && task.state() != State.CREATED && task.state() != State.CLOSED) {\n            final Map<TopicPartition, Long> changelogOffsets = task.changelogOffsets();\n            if (changelogOffsets.isEmpty()) {\n                log.debug(\"Skipping to encode apparently stateless (or non-logged) offset sum for task {}\", id);\n            } else {\n                taskOffsetSums.put(id, sumOfChangelogOffsets(id, changelogOffsets));\n            }\n        } else {\n            final File checkpointFile = stateDirectory.checkpointFileFor(id);\n            try {\n                if (checkpointFile.exists()) {\n                    taskOffsetSums.put(id, sumOfChangelogOffsets(id, new OffsetCheckpoint(checkpointFile).read()));\n                }\n            } catch (final IOException e) {\n                log.warn(String.format(\"Exception caught while trying to read checkpoint for task %s:\", id), e);\n            }\n        }\n    }\n\n    return taskOffsetSums;\n}", "summary_tokens": ["compute", "the", "offset", "total", "summed", "across", "all", "stores", "in", "a", "task"], "project": "kafka"}
{"id": 541, "code": "private void onNewBatch(String topic, Cluster cluster, int prevPartition) {\n    assert partitioner != null;\n    partitioner.onNewBatch(topic, cluster, prevPartition);\n}", "summary_tokens": ["call", "deprecated", "partitioner", "on", "new", "batch"], "project": "kafka"}
{"id": 934, "code": "public static TaggedFields of(Object... fields) {\n    if (fields.length % 2 != 0) {\n        throw new RuntimeException(\"TaggedFields#of takes an even \" +\n            \"number of parameters.\");\n    }\n    TreeMap<Integer, Field> newFields = new TreeMap<>();\n    for (int i = 0; i < fields.length; i += 2) {\n        Integer tag = (Integer) fields[i];\n        Field field = (Field) fields[i + 1];\n        newFields.put(tag, field);\n    }\n    return new TaggedFields(newFields);\n}", "summary_tokens": ["create", "a", "new", "tagged", "fields", "object", "with", "the", "given", "tags", "and", "fields"], "project": "kafka"}
{"id": 2550, "code": "public Optional<TaskId> taskId() {\n    return Optional.ofNullable(taskId);\n}", "summary_tokens": ["the", "task", "id", "that", "this", "exception", "originated", "from", "or", "optional", "empty", "if", "the", "exception", "cannot", "be", "traced", "back", "to", "a", "particular", "task"], "project": "kafka"}
{"id": 696, "code": "public TopicPartition topicPartition() {\n    return topicPartition;\n}", "summary_tokens": ["topic", "partition", "representing", "this", "instance"], "project": "kafka"}
{"id": 2566, "code": "static EmitStrategy onWindowClose() {\n    return new WindowCloseStrategy();\n}", "summary_tokens": ["this", "strategy", "indicates", "that", "the", "aggregated", "result", "for", "a", "window", "will", "only", "be", "emitted", "when", "the", "window", "closes", "instead", "of", "when", "there", "s", "an", "update", "to", "the", "window"], "project": "kafka"}
{"id": 1451, "code": "public void testCiphersSuiteForTls12() throws Exception {\n    String cipherSuite = \"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\";\n\n    sslServerConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(SslConfigs.DEFAULT_SSL_ENABLED_PROTOCOLS.split(\",\")));\n    sslServerConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    server = NetworkTestUtils.createEchoServer(ListenerName.forSecurityProtocol(SecurityProtocol.SSL),\n        SecurityProtocol.SSL, new TestSecurityConfig(sslServerConfigs), null, TIME);\n\n    sslClientConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(SslConfigs.DEFAULT_SSL_ENABLED_PROTOCOLS.split(\",\")));\n    sslClientConfigs.put(SslConfigs.SSL_CIPHER_SUITES_CONFIG, Collections.singletonList(cipherSuite));\n    checkAuthenticationSucceed();\n}", "summary_tokens": ["tests", "that", "connections", "can", "be", "made", "with", "tlsv", "0"], "project": "kafka"}
{"id": 2575, "code": "public static JoinWindows ofTimeDifferenceAndGrace(final Duration timeDifference, final Duration afterWindowEnd) {\n    final String timeDifferenceMsgPrefix = prepareMillisCheckFailMsgPrefix(timeDifference, \"timeDifference\");\n    final long timeDifferenceMs = validateMillisecondDuration(timeDifference, timeDifferenceMsgPrefix);\n\n    final String afterWindowEndMsgPrefix = prepareMillisCheckFailMsgPrefix(afterWindowEnd, \"afterWindowEnd\");\n    final long afterWindowEndMs = validateMillisecondDuration(afterWindowEnd, afterWindowEndMsgPrefix);\n\n    return new JoinWindows(timeDifferenceMs, timeDifferenceMs, afterWindowEndMs, true);\n}", "summary_tokens": ["specifies", "that", "records", "of", "the", "same", "key", "are", "joinable", "if", "their", "timestamps", "are", "within", "time", "difference", "i"], "project": "kafka"}
{"id": 2222, "code": "public void replay(ClientQuotaRecord record) {\n    Map<String, String> entityMap = new HashMap<>(2);\n    record.entity().forEach(entityData -> entityMap.put(entityData.entityType(), entityData.entityName()));\n    ClientQuotaEntity entity = new ClientQuotaEntity(entityMap);\n    TimelineHashMap<String, Double> quotas = clientQuotaData.get(entity);\n    if (quotas == null) {\n        quotas = new TimelineHashMap<>(snapshotRegistry, 0);\n        clientQuotaData.put(entity, quotas);\n    }\n    if (record.remove()) {\n        quotas.remove(record.key());\n        if (quotas.size() == 0) {\n            clientQuotaData.remove(entity);\n        }\n    } else {\n        quotas.put(record.key(), record.value());\n    }\n}", "summary_tokens": ["apply", "a", "quota", "record", "to", "the", "in", "memory", "state"], "project": "kafka"}
{"id": 1321, "code": "public static CreateTopicsResult createTopicsResult(String topic, Throwable t) {\n    KafkaFutureImpl<TopicMetadataAndConfig> future = new KafkaFutureImpl<>();\n    future.completeExceptionally(t);\n    return new CreateTopicsResult(Collections.singletonMap(topic, future));\n}", "summary_tokens": ["helper", "to", "create", "a", "create", "topics", "result", "instance", "for", "a", "given", "throwable"], "project": "kafka"}
{"id": 1256, "code": "public boolean hasNext() {\n    return true;\n}", "summary_tokens": ["returns", "true", "since", "the", "iteration", "will", "forever", "cycle", "through", "the", "provided", "collection"], "project": "kafka"}
{"id": 1818, "code": "public static ByteBuffer serializeMetadata(WorkerState workerState) {\n    Struct struct = new Struct(CONFIG_STATE_V0);\n    struct.set(URL_KEY_NAME, workerState.url());\n    struct.set(CONFIG_OFFSET_KEY_NAME, workerState.offset());\n    ByteBuffer buffer = ByteBuffer.allocate(CONNECT_PROTOCOL_HEADER_V0.sizeOf() + CONFIG_STATE_V0.sizeOf(struct));\n    CONNECT_PROTOCOL_HEADER_V0.writeTo(buffer);\n    CONFIG_STATE_V0.write(buffer, struct);\n    buffer.flip();\n    return buffer;\n}", "summary_tokens": ["the", "fields", "are", "serialized", "in", "sequence", "as", "follows", "subscription", "v", "0", "pre", "version", "int", "0", "url", "string", "config", "offset", "int", "0", "pre"], "project": "kafka"}
{"id": 1047, "code": "public FetchMetadata nextCloseExisting() {\n    return new FetchMetadata(sessionId, INITIAL_EPOCH);\n}", "summary_tokens": ["return", "the", "metadata", "for", "the", "next", "error", "response"], "project": "kafka"}
{"id": 2128, "code": "public Response requestPut(String url, String body) {\n    return requestHttpMethod(url, body, Collections.emptyMap(), \"PUT\");\n}", "summary_tokens": ["execute", "a", "put", "request", "on", "the", "given", "url"], "project": "kafka"}
{"id": 1917, "code": "protected void configureHttpResponsHeaderFilter(ServletContextHandler context) {\n    String headerConfig = config.getString(WorkerConfig.RESPONSE_HTTP_HEADERS_CONFIG);\n    FilterHolder headerFilterHolder = new FilterHolder(HeaderFilter.class);\n    headerFilterHolder.setInitParameter(\"headerConfig\", headerConfig);\n    context.addFilter(headerFilterHolder, \"/*\", EnumSet.of(DispatcherType.REQUEST));\n}", "summary_tokens": ["register", "header", "filter", "to", "servlet", "context", "handler"], "project": "kafka"}
{"id": 973, "code": "public void closeHandlers() throws IOException {\n    channel.close();\n}", "summary_tokens": ["close", "file", "handlers", "used", "by", "the", "file", "channel", "but", "don", "t", "write", "to", "disk"], "project": "kafka"}
{"id": 3200, "code": "public static void main(final String[] args) throws Exception {\n    if (args.length < 2) {\n        System.err.println(\"StreamsUpgradeTest requires two arguments (zookeeper-url, properties-file) but only \" + args.length + \" provided: \"\n            + (args.length > 0 ? args[0] + \" \" : \"\"));\n    }\n    final String zookeeper = args[0];\n    final String propFileName = args[1];\n\n    final Properties streamsProperties = Utils.loadProps(propFileName);\n\n    System.out.println(\"StreamsTest instance started (StreamsUpgradeTest v0.10.1)\");\n    System.out.println(\"zookeeper=\" + zookeeper);\n    System.out.println(\"props=\" + streamsProperties);\n\n    final KStreamBuilder builder = new KStreamBuilder();\n    final KStream dataStream = builder.stream(\"data\");\n    dataStream.process(printProcessorSupplier());\n    dataStream.to(\"echo\");\n\n    final Properties config = new Properties();\n    config.setProperty(StreamsConfig.APPLICATION_ID_CONFIG, \"StreamsUpgradeTest\");\n    config.setProperty(StreamsConfig.ZOOKEEPER_CONNECT_CONFIG, zookeeper);\n    config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 1000L);\n    config.putAll(streamsProperties);\n\n    final KafkaStreams streams = new KafkaStreams(builder, config);\n    streams.start();\n\n    Runtime.getRuntime().addShutdownHook(new Thread() {\n        @Override\n        public void run() {\n            System.out.println(\"closing Kafka Streams instance\");\n            System.out.flush();\n            streams.close();\n            System.out.println(\"UPGRADE-TEST-CLIENT-CLOSED\");\n            System.out.flush();\n        }\n    });\n}", "summary_tokens": ["this", "test", "cannot", "be", "executed", "as", "long", "as", "kafka", "0"], "project": "kafka"}
{"id": 2, "code": "static List<InetAddress> filterPreferredAddresses(InetAddress[] allAddresses) {\n    List<InetAddress> preferredAddresses = new ArrayList<>();\n    Class<? extends InetAddress> clazz = null;\n    for (InetAddress address : allAddresses) {\n        if (clazz == null) {\n            clazz = address.getClass();\n        }\n        if (clazz.isInstance(address)) {\n            preferredAddresses.add(address);\n        }\n    }\n    return preferredAddresses;\n}", "summary_tokens": ["return", "a", "list", "containing", "the", "first", "address", "in", "all", "addresses", "and", "subsequent", "addresses", "that", "are", "a", "subtype", "of", "the", "first", "address"], "project": "kafka"}
{"id": 1997, "code": "public boolean verifyTopicCleanupPolicyOnlyCompact(String topic, String workerTopicConfig,\n        String topicPurpose) {\n    Set<String> cleanupPolicies = topicCleanupPolicy(topic);\n    if (cleanupPolicies.isEmpty()) {\n        log.info(\"Unable to use admin client to verify the cleanup policy of '{}' \"\n                  + \"topic is '{}', either because the broker is an older \"\n                  + \"version or because the Kafka principal used for Connect \"\n                  + \"internal topics does not have the required permission to \"\n                  + \"describe topic configurations.\", topic, TopicConfig.CLEANUP_POLICY_COMPACT);\n        return false;\n    }\n    Set<String> expectedPolicies = Collections.singleton(TopicConfig.CLEANUP_POLICY_COMPACT);\n    if (!cleanupPolicies.equals(expectedPolicies)) {\n        String expectedPolicyStr = String.join(\",\", expectedPolicies);\n        String cleanupPolicyStr = String.join(\",\", cleanupPolicies);\n        String msg = String.format(\"Topic '%s' supplied via the '%s' property is required \"\n                + \"to have '%s=%s' to guarantee consistency and durability of \"\n                + \"%s, but found the topic currently has '%s=%s'. Continuing would likely \"\n                + \"result in eventually losing %s and problems restarting this Connect \"\n                + \"cluster in the future. Change the '%s' property in the \"\n                + \"Connect worker configurations to use a topic with '%s=%s'.\",\n                topic, workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr,\n                topicPurpose, TopicConfig.CLEANUP_POLICY_CONFIG, cleanupPolicyStr, topicPurpose,\n                workerTopicConfig, TopicConfig.CLEANUP_POLICY_CONFIG, expectedPolicyStr);\n        throw new ConfigException(msg);\n    }\n    return true;\n}", "summary_tokens": ["verify", "the", "named", "topic", "uses", "only", "compaction", "for", "the", "cleanup", "policy"], "project": "kafka"}
{"id": 2993, "code": "default KeyValueIterator<K, V> reverseRange(K from, K to) {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["get", "a", "reverse", "iterator", "over", "a", "given", "range", "of", "keys"], "project": "kafka"}
{"id": 546, "code": "public List<PartitionInfo> partitionsFor(String topic) {\n    Objects.requireNonNull(topic, \"topic cannot be null\");\n    try {\n        return waitOnMetadata(topic, null, time.milliseconds(), maxBlockTimeMs).cluster.partitionsForTopic(topic);\n    } catch (InterruptedException e) {\n        throw new InterruptException(e);\n    }\n}", "summary_tokens": ["get", "the", "partition", "metadata", "for", "the", "given", "topic"], "project": "kafka"}
{"id": 2980, "code": "public static <R> QueryResult<R> copyAndSubstituteDeserializedResult(\n    final QueryResult<?> rawResult,\n    final R deserializedResult) {\n\n    if (rawResult.isFailure()) {\n        throw new IllegalArgumentException(\n            \"Callers must avoid calling this method on a failed result.\"\n        );\n    } else {\n        return new SucceededQueryResult<>(\n            deserializedResult,\n            rawResult.getExecutionInfo(),\n            rawResult.getPosition()\n        );\n    }\n}", "summary_tokens": ["creates", "a", "new", "query", "result", "preserving", "the", "execution", "info", "and", "position", "of", "the", "provided", "result"], "project": "kafka"}
{"id": 1008, "code": "public Integer firstBatchSize() {\n    if (buffer.remaining() < HEADER_SIZE_UP_TO_MAGIC)\n        return null;\n    return new ByteBufferLogInputStream(buffer, Integer.MAX_VALUE).nextBatchSize();\n}", "summary_tokens": ["validates", "the", "header", "of", "the", "first", "batch", "and", "returns", "batch", "size"], "project": "kafka"}
{"id": 2220, "code": "void update(Uuid topicId, int partitionId, int[] prevIsr, int[] nextIsr,\n            int prevLeader, int nextLeader) {\n    int[] prev;\n    if (prevIsr == null) {\n        prev = NONE;\n    } else {\n        if (prevLeader == NO_LEADER) {\n            prev = Replicas.copyWith(prevIsr, NO_LEADER);\n            if (nextLeader != NO_LEADER) {\n                offlinePartitionCount.decrement();\n            }\n        } else {\n            prev = Replicas.clone(prevIsr);\n        }\n        Arrays.sort(prev);\n    }\n    int[] next;\n    if (nextIsr == null) {\n        next = NONE;\n    } else {\n        if (nextLeader == NO_LEADER) {\n            next = Replicas.copyWith(nextIsr, NO_LEADER);\n            if (prevLeader != NO_LEADER) {\n                offlinePartitionCount.increment();\n            }\n        } else {\n            next = Replicas.clone(nextIsr);\n        }\n        Arrays.sort(next);\n    }\n    int i = 0, j = 0;\n    while (true) {\n        if (i == prev.length) {\n            if (j == next.length) {\n                break;\n            }\n            int newReplica = next[j];\n            add(newReplica, topicId, partitionId, newReplica == nextLeader);\n            j++;\n        } else if (j == next.length) {\n            int prevReplica = prev[i];\n            remove(prevReplica, topicId, partitionId, prevReplica == prevLeader);\n            i++;\n        } else {\n            int prevReplica = prev[i];\n            int newReplica = next[j];\n            if (prevReplica < newReplica) {\n                remove(prevReplica, topicId, partitionId, prevReplica == prevLeader);\n                i++;\n            } else if (prevReplica > newReplica) {\n                add(newReplica, topicId, partitionId, newReplica == nextLeader);\n                j++;\n            } else {\n                boolean wasLeader = prevReplica == prevLeader;\n                boolean isLeader = prevReplica == nextLeader;\n                if (wasLeader != isLeader) {\n                    change(prevReplica, topicId, partitionId, wasLeader, isLeader);\n                }\n                i++;\n                j++;\n            }\n        }\n    }\n}", "summary_tokens": ["update", "our", "records", "of", "a", "partition", "s", "isr"], "project": "kafka"}
{"id": 1258, "code": "public T peek() {\n    return nextValue;\n}", "summary_tokens": ["peek", "at", "the", "next", "value", "in", "the", "iterator"], "project": "kafka"}
{"id": 1456, "code": "public void testResponseThrottleTime() {\n    Set<ApiKeys> authenticationKeys = EnumSet.of(ApiKeys.SASL_HANDSHAKE, ApiKeys.SASL_AUTHENTICATE);\n        \n    Set<ApiKeys> clusterActionsWithThrottleTimeMs = EnumSet.of(ApiKeys.ALTER_PARTITION, ApiKeys.ALLOCATE_PRODUCER_IDS, ApiKeys.UPDATE_FEATURES);\n    for (ApiKeys apiKey: ApiKeys.zkBrokerApis()) {\n        Schema responseSchema = apiKey.messageType.responseSchemas()[apiKey.latestVersion()];\n        BoundField throttleTimeField = responseSchema.get(\"throttle_time_ms\");\n        if ((apiKey.clusterAction && !clusterActionsWithThrottleTimeMs.contains(apiKey))\n            || authenticationKeys.contains(apiKey))\n            assertNull(throttleTimeField, \"Unexpected throttle time field: \" + apiKey);\n        else\n            assertNotNull(throttleTimeField, \"Throttle time field missing: \" + apiKey);\n    }\n}", "summary_tokens": ["all", "valid", "client", "responses", "which", "may", "be", "throttled", "should", "have", "a", "field", "named", "throttle", "time", "ms", "to", "return", "the", "throttle", "time", "to", "the", "client"], "project": "kafka"}
{"id": 795, "code": "public boolean isIncompatibleWith(short version) {\n    return min() > version || max() < version;\n}", "summary_tokens": ["checks", "if", "the", "version", "level", "does", "not", "fall", "within", "the", "min", "max", "range", "of", "this", "supported", "version", "range"], "project": "kafka"}
{"id": 2232, "code": "public void replay(ConfigRecord record) {\n    Type type = Type.forId(record.resourceType());\n    ConfigResource configResource = new ConfigResource(type, record.resourceName());\n    TimelineHashMap<String, String> configs = configData.get(configResource);\n    if (configs == null) {\n        configs = new TimelineHashMap<>(snapshotRegistry, 0);\n        configData.put(configResource, configs);\n    }\n    if (record.value() == null) {\n        configs.remove(record.name());\n    } else {\n        configs.put(record.name(), record.value());\n    }\n    if (configs.isEmpty()) {\n        configData.remove(configResource);\n    }\n    if (configSchema.isSensitive(record)) {\n        log.info(\"{}: set configuration {} to {}\", configResource, record.name(), Password.HIDDEN);\n    } else {\n        log.info(\"{}: set configuration {} to {}\", configResource, record.name(), record.value());\n    }\n}", "summary_tokens": ["apply", "a", "configuration", "record", "to", "the", "in", "memory", "state"], "project": "kafka"}
{"id": 2635, "code": "public StreamJoined<K, V1, V2> withName(final String name) {\n    return new StreamJoined<>(\n        keySerde,\n        valueSerde,\n        otherValueSerde,\n        thisStoreSupplier,\n        otherStoreSupplier,\n        name,\n        storeName,\n        loggingEnabled,\n        topicConfig\n    );\n}", "summary_tokens": ["set", "the", "name", "to", "use", "for", "the", "join", "processor", "and", "the", "repartition", "topic", "s", "if", "required"], "project": "kafka"}
{"id": 905, "code": "private void handshakeFailure(SSLException sslException, boolean flush) throws IOException {\n        \n    log.debug(\"SSL Handshake failed\", sslException);\n    sslEngine.closeOutbound();\n    try {\n        sslEngine.closeInbound();\n    } catch (SSLException e) {\n        log.debug(\"SSLEngine.closeInBound() raised an exception.\", e);\n    }\n\n    state = State.HANDSHAKE_FAILED;\n    handshakeException = new SslAuthenticationException(\"SSL handshake failed\", sslException);\n\n        \n        \n        \n    if (!flush || handshakeWrapAfterFailure(flush))\n        throw handshakeException;\n    else\n        log.debug(\"Delay propagation of handshake exception till {} bytes remaining are flushed\", netWriteBuffer.remaining());\n}", "summary_tokens": ["ssl", "exceptions", "are", "propagated", "as", "authentication", "failures", "so", "that", "clients", "can", "avoid", "retries", "and", "report", "the", "failure"], "project": "kafka"}
{"id": 224, "code": "public DescribeAclsOptions timeoutMs(Integer timeoutMs) {\n    this.timeoutMs = timeoutMs;\n    return this;\n}", "summary_tokens": ["set", "the", "timeout", "in", "milliseconds", "for", "this", "operation", "or", "null", "if", "the", "default", "api", "timeout", "for", "the", "admin", "client", "should", "be", "used"], "project": "kafka"}
{"id": 1934, "code": "public Map<String, String> connectorConfig(String connector) {\n    Map<String, String> configs = connectorConfigs.get(connector);\n    if (configTransformer != null) {\n        configs = configTransformer.transform(connector, configs);\n    }\n    return configs;\n}", "summary_tokens": ["get", "the", "configuration", "for", "a", "connector"], "project": "kafka"}
{"id": 2905, "code": "public KafkaFuture<Void> all() {\n    return addTopologyFuture;\n}", "summary_tokens": ["a", "kafka", "future", "that", "completes", "successfully", "when", "all", "threads", "on", "this", "client", "have", "picked", "up", "the", "new", "named", "topology"], "project": "kafka"}
{"id": 2135, "code": "public void assertAtLeastNumWorkersAreUp(int numWorkers, String detailMessage) throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkWorkersUp(numWorkers, (actual, expected) -> actual >= expected).orElse(false),\n            WORKER_SETUP_DURATION_MS,\n            \"Didn't meet the minimum requested number of online workers: \" + numWorkers);\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "at", "least", "the", "requested", "number", "of", "workers", "are", "up", "and", "running"], "project": "kafka"}
{"id": 2734, "code": "public void setup(final Map<String, InternalTopicConfig> topicConfigs) {\n    log.info(\"Starting to setup internal topics {}.\", topicConfigs.keySet());\n\n    final long now = time.milliseconds();\n    final long deadline = now + retryTimeoutMs;\n\n    final Map<String, Map<String, String>> streamsSideTopicConfigs = topicConfigs.values().stream()\n        .collect(Collectors.toMap(\n            InternalTopicConfig::name,\n            topicConfig -> topicConfig.getProperties(defaultTopicConfigs, windowChangeLogAdditionalRetention)\n        ));\n    final Set<String> createdTopics = new HashSet<>();\n    final Set<String> topicStillToCreate = new HashSet<>(topicConfigs.keySet());\n    while (!topicStillToCreate.isEmpty()) {\n        final Set<NewTopic> newTopics = topicStillToCreate.stream()\n            .map(topicName -> new NewTopic(\n                    topicName,\n                    topicConfigs.get(topicName).numberOfPartitions(),\n                    Optional.of(replicationFactor)\n                ).configs(streamsSideTopicConfigs.get(topicName))\n            ).collect(Collectors.toSet());\n\n        log.info(\"Going to create internal topics: \" + newTopics);\n        final CreateTopicsResult createTopicsResult = adminClient.createTopics(newTopics);\n\n        processCreateTopicResults(createTopicsResult, topicStillToCreate, createdTopics, deadline);\n\n        maybeSleep(Collections.singletonList(topicStillToCreate), deadline, \"created\");\n    }\n\n    log.info(\"Completed setup of internal topics {}.\", topicConfigs.keySet());\n}", "summary_tokens": ["sets", "up", "internal", "topics"], "project": "kafka"}
{"id": 2052, "code": "public int stops() {\n    return stopCounter.get();\n}", "summary_tokens": ["get", "the", "number", "of", "stops"], "project": "kafka"}
{"id": 2251, "code": "void handleBrokerInControlledShutdown(int brokerId, long brokerEpoch, List<ApiMessageAndVersion> records) {\n    if (featureControl.metadataVersion().isInControlledShutdownStateSupported()\n            && !clusterControl.inControlledShutdown(brokerId)) {\n        records.add(new ApiMessageAndVersion(new BrokerRegistrationChangeRecord().\n            setBrokerId(brokerId).setBrokerEpoch(brokerEpoch).\n            setInControlledShutdown(BrokerRegistrationInControlledShutdownChange.IN_CONTROLLED_SHUTDOWN.value()),\n            (short) 1));\n    }\n    generateLeaderAndIsrUpdates(\"enterControlledShutdown[\" + brokerId + \"]\",\n        brokerId, NO_LEADER, records, brokersToIsrs.partitionsWithBrokerInIsr(brokerId));\n}", "summary_tokens": ["generate", "the", "appropriate", "records", "to", "handle", "a", "broker", "starting", "a", "controlled", "shutdown"], "project": "kafka"}
{"id": 1664, "code": "public int taskId() {\n    return taskId;\n}", "summary_tokens": ["provides", "the", "id", "of", "the", "task"], "project": "kafka"}
{"id": 1789, "code": "public void stopAndAwaitTasks(Collection<ConnectorTaskId> ids) {\n    stopTasks(ids);\n    awaitStopTasks(ids);\n}", "summary_tokens": ["stop", "asynchronously", "a", "collection", "of", "tasks", "that", "belong", "to", "this", "worker", "and", "await", "their", "termination"], "project": "kafka"}
{"id": 2837, "code": "public void configure(final Map<String, ?> configs) {\n    final AssignorConfiguration assignorConfiguration = new AssignorConfiguration(configs);\n\n    logPrefix = assignorConfiguration.logPrefix();\n    log = new LogContext(logPrefix).logger(getClass());\n    usedSubscriptionMetadataVersion = assignorConfiguration.configuredMetadataVersion(usedSubscriptionMetadataVersion);\n\n    final ReferenceContainer referenceContainer = assignorConfiguration.referenceContainer();\n    mainConsumerSupplier = () -> Objects.requireNonNull(referenceContainer.mainConsumer, \"Main consumer was not specified\");\n    adminClient = Objects.requireNonNull(referenceContainer.adminClient, \"Admin client was not specified\");\n    taskManager = Objects.requireNonNull(referenceContainer.taskManager, \"TaskManager was not specified\");\n    streamsMetadataState = Objects.requireNonNull(referenceContainer.streamsMetadataState, \"StreamsMetadataState was not specified\");\n    assignmentErrorCode = referenceContainer.assignmentErrorCode;\n    nextScheduledRebalanceMs = referenceContainer.nextScheduledRebalanceMs;\n    nonFatalExceptionsToHandle = referenceContainer.nonFatalExceptionsToHandle;\n    time = Objects.requireNonNull(referenceContainer.time, \"Time was not specified\");\n    assignmentConfigs = assignorConfiguration.assignmentConfigs();\n    partitionGrouper = new PartitionGrouper();\n    userEndPoint = assignorConfiguration.userEndPoint();\n    internalTopicManager = assignorConfiguration.internalTopicManager();\n    copartitionedTopicsEnforcer = assignorConfiguration.copartitionedTopicsEnforcer();\n    rebalanceProtocol = assignorConfiguration.rebalanceProtocol();\n    taskAssignorSupplier = assignorConfiguration::taskAssignor;\n    assignmentListener = assignorConfiguration.assignmentListener();\n    uniqueField = 0;\n    clientTags = referenceContainer.clientTags;\n}", "summary_tokens": ["we", "need", "to", "have", "the", "partition", "assignor", "and", "its", "stream", "thread", "to", "be", "mutually", "accessible", "since", "the", "former", "needs", "latter", "s", "cached", "metadata", "while", "sending", "subscriptions", "and", "the", "latter", "needs", "former", "s", "returned", "assignment", "when", "adding", "tasks"], "project": "kafka"}
{"id": 2700, "code": "protected final ProcessorContext<KOut, VOut> context() {\n    return context;\n}", "summary_tokens": ["get", "the", "processor", "s", "context", "set", "during", "init", "processor", "context", "initialization"], "project": "kafka"}
{"id": 2359, "code": "private FetchSnapshotResponseData handleFetchSnapshotRequest(\n    RaftRequest.Inbound requestMetadata\n) {\n    FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n\n    if (!hasValidClusterId(data.clusterId())) {\n        return new FetchSnapshotResponseData().setErrorCode(Errors.INCONSISTENT_CLUSTER_ID.code());\n    }\n\n    if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n        return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n    }\n\n    Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n        .forTopicPartition(data, log.topicPartition());\n    if (!partitionSnapshotOpt.isPresent()) {\n            \n        TopicPartition unknownTopicPartition = new TopicPartition(\n            data.topics().get(0).name(),\n            data.topics().get(0).partitions().get(0).partition()\n        );\n\n        return FetchSnapshotResponse.singleton(\n            unknownTopicPartition,\n            responsePartitionSnapshot -> responsePartitionSnapshot\n                .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code())\n        );\n    }\n\n    FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n    Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n            partitionSnapshot.currentLeaderEpoch()\n    );\n    if (leaderValidation.isPresent()) {\n        return FetchSnapshotResponse.singleton(\n            log.topicPartition(),\n            responsePartitionSnapshot -> addQuorumLeader(responsePartitionSnapshot)\n                .setErrorCode(leaderValidation.get().code())\n        );\n    }\n\n    OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n        partitionSnapshot.snapshotId().endOffset(),\n        partitionSnapshot.snapshotId().epoch()\n    );\n    Optional<RawSnapshotReader> snapshotOpt = log.readSnapshot(snapshotId);\n    if (!snapshotOpt.isPresent()) {\n        return FetchSnapshotResponse.singleton(\n            log.topicPartition(),\n            responsePartitionSnapshot -> addQuorumLeader(responsePartitionSnapshot)\n                .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code())\n        );\n    }\n\n    RawSnapshotReader snapshot = snapshotOpt.get();\n    long snapshotSize = snapshot.sizeInBytes();\n    if (partitionSnapshot.position() < 0 || partitionSnapshot.position() >= snapshotSize) {\n        return FetchSnapshotResponse.singleton(\n            log.topicPartition(),\n            responsePartitionSnapshot -> addQuorumLeader(responsePartitionSnapshot)\n                .setErrorCode(Errors.POSITION_OUT_OF_RANGE.code())\n        );\n    }\n\n    if (partitionSnapshot.position() > Integer.MAX_VALUE) {\n        throw new IllegalStateException(\n            String.format(\n                \"Trying to fetch a snapshot with size (%d) and a position (%d) larger than %d\",\n                snapshotSize,\n                partitionSnapshot.position(),\n                Integer.MAX_VALUE\n            )\n        );\n    }\n\n    int maxSnapshotSize;\n    try {\n        maxSnapshotSize = Math.toIntExact(snapshotSize);\n    } catch (ArithmeticException e) {\n        maxSnapshotSize = Integer.MAX_VALUE;\n    }\n\n    UnalignedRecords records = snapshot.slice(partitionSnapshot.position(), Math.min(data.maxBytes(), maxSnapshotSize));\n\n    return FetchSnapshotResponse.singleton(\n        log.topicPartition(),\n        responsePartitionSnapshot -> {\n            addQuorumLeader(responsePartitionSnapshot)\n                .snapshotId()\n                .setEndOffset(snapshotId.offset)\n                .setEpoch(snapshotId.epoch);\n\n            return responsePartitionSnapshot\n                .setSize(snapshotSize)\n                .setPosition(partitionSnapshot.position())\n                .setUnalignedRecords(records);\n        }\n    );\n}", "summary_tokens": ["handle", "a", "fetch", "snapshot", "request", "similar", "to", "the", "fetch", "request", "but", "we", "use", "unaligned", "records", "in", "response", "because", "the", "records", "are", "not", "necessarily", "offset", "aligned"], "project": "kafka"}
{"id": 907, "code": "default int size(ObjectSerializationCache cache, short version) {\n    MessageSizeAccumulator size = new MessageSizeAccumulator();\n    addSize(size, cache, version);\n    return size.totalSize();\n}", "summary_tokens": ["returns", "the", "number", "of", "bytes", "it", "would", "take", "to", "write", "out", "this", "message"], "project": "kafka"}
{"id": 2203, "code": "static VersionConditional forVersions(Versions containingVersions,\n                                      Versions possibleVersions) {\n    return new VersionConditional(containingVersions, possibleVersions);\n}", "summary_tokens": ["create", "a", "version", "conditional"], "project": "kafka"}
{"id": 170, "code": "public String value() {\n    return value;\n}", "summary_tokens": ["return", "the", "value", "or", "null"], "project": "kafka"}
{"id": 2867, "code": "void closeAndCleanUpTasks(final Collection<Task> activeTasks, final Collection<Task> standbyTasks, final boolean clean) {\n    final AtomicReference<RuntimeException> firstException = new AtomicReference<>(null);\n\n    final Set<Task> tasksToCloseDirty = new HashSet<>();\n    tasksToCloseDirty.addAll(tryCloseCleanActiveTasks(activeTasks, clean, firstException));\n    tasksToCloseDirty.addAll(tryCloseCleanStandbyTasks(standbyTasks, clean, firstException));\n\n    for (final Task task : tasksToCloseDirty) {\n        closeTaskDirty(task, true);\n    }\n\n    final RuntimeException exception = firstException.get();\n    if (exception != null) {\n        throw exception;\n    }\n}", "summary_tokens": ["closes", "and", "cleans", "up", "after", "the", "provided", "tasks", "including", "closing", "their", "corresponding", "task", "producers"], "project": "kafka"}
{"id": 1194, "code": "public List<JsonWebKey> getJsonWebKeys() throws JoseException, IOException {\n    if (!isInitialized)\n        throw new IllegalStateException(\"Please call init() first\");\n\n    try {\n        refreshLock.readLock().lock();\n        return jsonWebKeys;\n    } finally {\n        refreshLock.readLock().unlock();\n    }\n}", "summary_tokens": ["our", "implementation", "avoids", "the", "blocking", "call", "within", "https", "jwks", "refresh", "that", "is", "sometimes", "called", "internal", "to", "https", "jwks", "get", "json", "web", "keys"], "project": "kafka"}
{"id": 2441, "code": "public int segmentSizeInBytes() {\n    return segmentSizeInBytes;\n}", "summary_tokens": ["total", "size", "of", "this", "segment", "in", "bytes"], "project": "kafka"}
{"id": 2619, "code": "public static <K, V> Repartitioned<K, V> numberOfPartitions(final int numberOfPartitions) {\n    return new Repartitioned<>(null, null, null, numberOfPartitions, null);\n}", "summary_tokens": ["create", "a", "repartitioned", "instance", "with", "provided", "number", "of", "partitions", "for", "repartition", "topic"], "project": "kafka"}
{"id": 66, "code": "public synchronized void maybeThrowExceptionForTopic(String topic) {\n    clearErrorsAndMaybeThrowException(() -> recoverableExceptionForTopic(topic));\n}", "summary_tokens": ["if", "any", "non", "retriable", "exceptions", "were", "encountered", "during", "metadata", "update", "throw", "exception", "if", "the", "exception", "is", "fatal", "or", "related", "to", "the", "specified", "topic"], "project": "kafka"}
{"id": 521, "code": "public synchronized boolean checkAssignmentMatchedSubscription(Collection<TopicPartition> assignments) {\n    for (TopicPartition topicPartition : assignments) {\n        if (this.subscribedPattern != null) {\n            if (!this.subscribedPattern.matcher(topicPartition.topic()).matches()) {\n                log.info(\"Assigned partition {} for non-subscribed topic regex pattern; subscription pattern is {}\",\n                    topicPartition,\n                    this.subscribedPattern);\n\n                return false;\n            }\n        } else {\n            if (!this.subscription.contains(topicPartition.topic())) {\n                log.info(\"Assigned partition {} for non-subscribed topic; subscription is {}\", topicPartition, this.subscription);\n\n                return false;\n            }\n        }\n    }\n\n    return true;\n}", "summary_tokens": ["true", "if", "assignments", "matches", "subscription", "otherwise", "false"], "project": "kafka"}
{"id": 2486, "code": "public void cleanUp() {\n    if (!(state.hasNotStarted() || state.hasCompletedShutdown())) {\n        throw new IllegalStateException(\"Cannot clean up while running.\");\n    }\n    stateDirectory.clean();\n}", "summary_tokens": ["do", "a", "clean", "up", "of", "the", "local", "state", "store", "directory", "streams", "config", "state", "dir", "config", "by", "deleting", "all", "data", "with", "regard", "to", "the", "streams", "config", "application", "id", "config", "application", "id"], "project": "kafka"}
{"id": 139, "code": "default DescribeClientQuotasResult describeClientQuotas(ClientQuotaFilter filter) {\n    return describeClientQuotas(filter, new DescribeClientQuotasOptions());\n}", "summary_tokens": ["describes", "all", "entities", "matching", "the", "provided", "filter", "that", "have", "at", "least", "one", "client", "quota", "configuration", "value", "defined"], "project": "kafka"}
{"id": 1054, "code": "public static FetchSnapshotResponseData withTopLevelError(Errors error) {\n    return new FetchSnapshotResponseData().setErrorCode(error.code());\n}", "summary_tokens": ["creates", "a", "fetch", "snapshot", "response", "data", "with", "a", "top", "level", "error"], "project": "kafka"}
{"id": 2268, "code": "public boolean isSplittable(ConfigResource.Type type, String key) {\n    ConfigDef configDef = configDefs.get(type);\n    if (configDef == null) return false;\n    ConfigDef.ConfigKey configKey = configDef.configKeys().get(key);\n    if (configKey == null) return false;\n    return configKey.type == ConfigDef.Type.LIST;\n}", "summary_tokens": ["returns", "true", "if", "the", "configuration", "key", "specified", "is", "splittable", "only", "lists", "are", "splittable"], "project": "kafka"}
{"id": 339, "code": "public long size() {\n    return size;\n}", "summary_tokens": ["the", "total", "size", "of", "the", "log", "segments", "in", "this", "replica", "in", "bytes"], "project": "kafka"}
{"id": 2661, "code": "public Instant startTime() {\n    return startTime;\n}", "summary_tokens": ["return", "the", "start", "time", "of", "this", "window"], "project": "kafka"}
{"id": 619, "code": "private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers,\n                                     Callback callback, Deque<ProducerBatch> deque, long nowMs) {\n    if (closed)\n        throw new KafkaException(\"Producer closed while send in progress\");\n    ProducerBatch last = deque.peekLast();\n    if (last != null) {\n        int initialBytes = last.estimatedSizeInBytes();\n        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, headers, callback, nowMs);\n        if (future == null) {\n            last.closeForRecordAppends();\n        } else {\n            int appendedBytes = last.estimatedSizeInBytes() - initialBytes;\n            return new RecordAppendResult(future, deque.size() > 1 || last.isFull(), false, false, appendedBytes);\n        }\n    }\n    return null;\n}", "summary_tokens": ["try", "to", "append", "to", "a", "producer", "batch"], "project": "kafka"}
{"id": 2981, "code": "public boolean isSuccess() {\n    return true;\n}", "summary_tokens": ["true", "iff", "the", "query", "was", "successfully", "executed"], "project": "kafka"}
{"id": 2038, "code": "public void testConnectorBoundary() throws Exception {\n    String offsetsTopic = \"exactly-once-source-cluster-offsets\";\n    workerProps.put(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, offsetsTopic);\n    connectBuilder.numWorkers(1);\n    startConnect();\n\n    String topic = \"test-topic\";\n    connect.kafka().createTopic(topic, 3);\n\n    int recordsProduced = 100;\n\n    Map<String, String> props = new HashMap<>();\n    props.put(CONNECTOR_CLASS_CONFIG, MonitorableSourceConnector.class.getName());\n    props.put(TASKS_MAX_CONFIG, \"1\");\n    props.put(TOPIC_CONFIG, topic);\n    props.put(KEY_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(VALUE_CONVERTER_CLASS_CONFIG, StringConverter.class.getName());\n    props.put(NAME_CONFIG, CONNECTOR_NAME);\n    props.put(TRANSACTION_BOUNDARY_CONFIG, CONNECTOR.toString());\n    props.put(CUSTOM_TRANSACTION_BOUNDARIES_CONFIG, MonitorableSourceConnector.TRANSACTION_BOUNDARIES_SUPPORTED);\n    props.put(MESSAGES_PER_POLL_CONFIG, Integer.toString(recordsProduced));\n\n        \n    connectorHandle.expectedRecords(recordsProduced);\n    connectorHandle.expectedCommits(recordsProduced);\n\n        \n    connect.configureConnector(CONNECTOR_NAME, props);\n\n    log.info(\"Waiting for records to be provided to worker by task\");\n        \n    connectorHandle.awaitRecords(SOURCE_TASK_PRODUCE_TIMEOUT_MS);\n\n    log.info(\"Waiting for records to be committed to Kafka by worker\");\n        \n    connectorHandle.awaitCommits(TimeUnit.MINUTES.toMillis(1));\n\n    Map<String, Object> consumerProps = new HashMap<>();\n    consumerProps.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\");\n        \n    ConsumerRecords<byte[], byte[]> sourceRecords = connect.kafka().consumeAll(\n            CONSUME_RECORDS_TIMEOUT_MS,\n            Collections.singletonMap(ConsumerConfig.ISOLATION_LEVEL_CONFIG, \"read_committed\"),\n            null,\n            topic\n    );\n    assertTrue(\"Not enough records produced by source connector. Expected at least: \" + recordsProduced + \" + but got \" + sourceRecords.count(),\n            sourceRecords.count() >= recordsProduced);\n\n        \n        \n    List<Long> expectedOffsetSeqnos = new ArrayList<>();\n    long lastExpectedOffsetSeqno = 1;\n    long nextExpectedOffsetSeqno = 1;\n    while (nextExpectedOffsetSeqno <= recordsProduced) {\n        expectedOffsetSeqnos.add(nextExpectedOffsetSeqno);\n        nextExpectedOffsetSeqno += lastExpectedOffsetSeqno;\n        lastExpectedOffsetSeqno = nextExpectedOffsetSeqno - lastExpectedOffsetSeqno;\n    }\n    ConsumerRecords<byte[], byte[]> offsetRecords = connect.kafka()\n            .consume(\n                    expectedOffsetSeqnos.size(),\n                    TimeUnit.MINUTES.toMillis(1),\n                    consumerProps,\n                    offsetsTopic\n            );\n\n    List<Long> actualOffsetSeqnos = parseAndAssertOffsetsForSingleTask(offsetRecords);\n\n    assertEquals(\"Committed offsets should match connector-defined transaction boundaries\",\n            expectedOffsetSeqnos, actualOffsetSeqnos.subList(0, expectedOffsetSeqnos.size()));\n\n    List<Long> expectedRecordSeqnos = LongStream.range(1, recordsProduced + 1).boxed().collect(Collectors.toList());\n    long priorBoundary = 1;\n    long nextBoundary = 2;\n    while (priorBoundary < expectedRecordSeqnos.get(expectedRecordSeqnos.size() - 1)) {\n        if (nextBoundary % 2 == 0) {\n            for (long i = priorBoundary + 1; i < nextBoundary + 1; i++) {\n                expectedRecordSeqnos.remove(i);\n            }\n        }\n        nextBoundary += priorBoundary;\n        priorBoundary = nextBoundary - priorBoundary;\n    }\n    List<Long> actualRecordSeqnos = parseAndAssertValuesForSingleTask(sourceRecords);\n        \n    Collections.sort(actualRecordSeqnos);\n    assertEquals(\"Committed records should exclude connector-aborted transactions\",\n            expectedRecordSeqnos, actualRecordSeqnos.subList(0, expectedRecordSeqnos.size()));\n}", "summary_tokens": ["a", "simple", "green", "path", "test", "that", "ensures", "the", "worker", "can", "start", "up", "a", "source", "task", "with", "exactly", "once", "support", "enabled", "and", "write", "some", "records", "to", "kafka", "that", "will", "be", "visible", "to", "a", "downstream", "consumer", "using", "the", "read", "committed", "isolation", "level"], "project": "kafka"}
{"id": 2313, "code": "public void testParsingVersionTooLarge() {\n    MetadataRecordSerde serde = new MetadataRecordSerde();\n    ByteBuffer buffer = ByteBuffer.allocate(64);\n    buffer.clear();\n    buffer.put((byte) 0x01); \n    buffer.put((byte) 0x08); \n    buffer.put((byte) 0xff); \n    buffer.put((byte) 0xff); \n    buffer.put((byte) 0xff); \n    buffer.put((byte) 0x7f); \n    buffer.put((byte) 0x80);\n    buffer.position(0);\n    buffer.limit(64);\n    assertStartsWith(\"Value for version was too large\",\n            assertThrows(MetadataParseException.class,\n                    () -> serde.read(new ByteBufferAccessor(buffer), buffer.remaining())).getMessage());\n}", "summary_tokens": ["test", "attempting", "to", "parse", "an", "event", "which", "has", "a", "version", "short"], "project": "kafka"}
{"id": 1181, "code": "public static Set<String> validateScopes(String scopeClaimName, Collection<String> scopes) throws ValidateException {\n    if (scopes == null)\n        throw new ValidateException(String.format(\"%s value must be non-null\", scopeClaimName));\n\n    Set<String> copy = new HashSet<>();\n\n    for (String scope : scopes) {\n        scope = validateString(scopeClaimName, scope);\n\n        if (copy.contains(scope))\n            throw new ValidateException(String.format(\"%s value must not contain duplicates - %s already present\", scopeClaimName, scope));\n\n        copy.add(scope);\n    }\n\n    return Collections.unmodifiableSet(copy);\n}", "summary_tokens": ["validates", "that", "the", "scopes", "are", "valid", "where", "i", "invalid", "i", "means", "i", "any", "i", "of", "the", "following"], "project": "kafka"}
{"id": 1952, "code": "public void configure(WorkerConfig config) {\n        \n    connectorStore.ifPresent(store -> store.configure(config));\n}", "summary_tokens": ["if", "configured", "to", "use", "a", "connector", "specific", "offset", "store", "offset", "backing", "store", "configure", "worker", "config", "configure", "that", "store"], "project": "kafka"}
{"id": 1269, "code": "final public boolean add(E newElement) {\n    if (newElement == null) {\n        return false;\n    }\n    if (newElement.prev() != INVALID_INDEX || newElement.next() != INVALID_INDEX) {\n        return false;\n    }\n    if ((size + 1) >= elements.length / 2) {\n        changeCapacity(calculateCapacity(elements.length));\n    }\n    int slot = addInternal(newElement, elements);\n    if (slot >= 0) {\n        addToListTail(head, elements, slot);\n        size++;\n        return true;\n    }\n    return false;\n}", "summary_tokens": ["add", "a", "new", "element", "to", "the", "collection"], "project": "kafka"}
{"id": 176, "code": "public ConfigType type() {\n    return type;\n}", "summary_tokens": ["return", "the", "config", "data", "type"], "project": "kafka"}
{"id": 3031, "code": "public Set<TopicPartition> topicPartitions() {\n    return Collections.unmodifiableSet(topicPartitions);\n}", "summary_tokens": ["topic", "partitions", "consumed", "by", "the", "instance", "as", "an", "active", "replica"], "project": "kafka"}
{"id": 539, "code": "public void abortTransaction() throws ProducerFencedException {\n    throwIfNoTransactionManager();\n    throwIfProducerClosed();\n    log.info(\"Aborting incomplete transaction\");\n    long abortStart = time.nanoseconds();\n    TransactionalRequestResult result = transactionManager.beginAbort();\n    sender.wakeup();\n    result.await(maxBlockTimeMs, TimeUnit.MILLISECONDS);\n    producerMetrics.recordAbortTxn(time.nanoseconds() - abortStart);\n}", "summary_tokens": ["aborts", "the", "ongoing", "transaction"], "project": "kafka"}
{"id": 842, "code": "synchronized Map<K, Integer> values() {\n    HashMap<K, Integer> values = new HashMap<>();\n    for (Map.Entry<K, StoredIntGauge> entry : gauges.entrySet()) {\n        values.put(entry.getKey(), entry.getValue().value());\n    }\n    return values;\n}", "summary_tokens": ["return", "a", "map", "from", "keys", "to", "current", "reference", "counts"], "project": "kafka"}
{"id": 2897, "code": "public boolean assign(final Map<UUID, ClientState> clients,\n                      final Set<TaskId> allTaskIds,\n                      final Set<TaskId> statefulTaskIds,\n                      final AssignorConfiguration.AssignmentConfigs configs) {\n    final int numStandbyReplicas = configs.numStandbyReplicas;\n    final Set<String> rackAwareAssignmentTags = new HashSet<>(configs.rackAwareAssignmentTags);\n\n    final Map<TaskId, Integer> tasksToRemainingStandbys = computeTasksToRemainingStandbys(\n        numStandbyReplicas,\n        statefulTaskIds\n    );\n\n    final Map<String, Set<String>> tagKeyToValues = new HashMap<>();\n    final Map<TagEntry, Set<UUID>> tagEntryToClients = new HashMap<>();\n\n    fillClientsTagStatistics(clients, tagEntryToClients, tagKeyToValues);\n\n    final ConstrainedPrioritySet standbyTaskClientsByTaskLoad = createLeastLoadedPrioritySetConstrainedByAssignedTask(clients);\n\n    final Map<TaskId, UUID> pendingStandbyTasksToClientId = new HashMap<>();\n\n    for (final TaskId statefulTaskId : statefulTaskIds) {\n        for (final Map.Entry<UUID, ClientState> entry : clients.entrySet()) {\n            final UUID clientId = entry.getKey();\n            final ClientState clientState = entry.getValue();\n\n            if (clientState.activeTasks().contains(statefulTaskId)) {\n                assignStandbyTasksToClientsWithDifferentTags(\n                    numStandbyReplicas,\n                    standbyTaskClientsByTaskLoad,\n                    statefulTaskId,\n                    clientId,\n                    rackAwareAssignmentTags,\n                    clients,\n                    tasksToRemainingStandbys,\n                    tagKeyToValues,\n                    tagEntryToClients,\n                    pendingStandbyTasksToClientId\n                );\n            }\n        }\n    }\n\n    if (!tasksToRemainingStandbys.isEmpty()) {\n        assignPendingStandbyTasksToLeastLoadedClients(clients,\n                                                      numStandbyReplicas,\n                                                      standbyTaskClientsByTaskLoad,\n                                                      tasksToRemainingStandbys);\n    }\n\n        \n    return false;\n}", "summary_tokens": ["the", "algorithm", "distributes", "standby", "tasks", "for", "the", "stateful", "task", "ids", "over", "different", "tag", "dimensions"], "project": "kafka"}
{"id": 1921, "code": "private static Map<String, String> effectiveLevelToMap(Logger logger) {\n    Level level = logger.getLevel();\n    if (level == null) {\n        level = logger.getEffectiveLevel();\n    }\n    return Collections.singletonMap(\"level\", String.valueOf(level));\n}", "summary_tokens": ["map", "representation", "of", "a", "logger", "s", "effective", "log", "level"], "project": "kafka"}
{"id": 2525, "code": "public static String restoreConsumerPrefix(final String consumerProp) {\n    return RESTORE_CONSUMER_PREFIX + consumerProp;\n}", "summary_tokens": ["prefix", "a", "property", "with", "restore", "consumer", "prefix"], "project": "kafka"}
{"id": 267, "code": "public Map<String, KafkaFuture<Void>> fencedProducers() {\n    return futures.entrySet().stream().collect(Collectors.toMap(\n        e -> e.getKey().idValue,\n        e -> e.getValue().thenApply(p -> null)\n    ));\n}", "summary_tokens": ["return", "a", "map", "from", "transactional", "id", "to", "futures", "which", "can", "be", "used", "to", "check", "the", "status", "of", "individual", "fencings"], "project": "kafka"}
{"id": 3051, "code": "private int readInt(final BufferedReader reader) throws IOException {\n    final String line = reader.readLine();\n    if (line == null) {\n        throw new EOFException(\"File ended prematurely.\");\n    }\n    return Integer.parseInt(line);\n}", "summary_tokens": ["ioexception", "if", "file", "read", "ended", "prematurely"], "project": "kafka"}
{"id": 2126, "code": "public Response requestGet(String url) {\n    return requestHttpMethod(url, null, Collections.emptyMap(), \"GET\");\n}", "summary_tokens": ["execute", "a", "get", "request", "on", "the", "given", "url"], "project": "kafka"}
{"id": 2744, "code": "StampedRecord nextRecord(final RecordInfo info, final long wallClockTime) {\n    StampedRecord record = null;\n\n    final RecordQueue queue = nonEmptyQueuesByTime.poll();\n    info.queue = queue;\n\n    if (queue != null) {\n            \n        record = queue.poll(wallClockTime);\n\n        if (record != null) {\n            --totalBuffered;\n\n            if (queue.isEmpty()) {\n                    \n                allBuffered = false;\n            } else {\n                nonEmptyQueuesByTime.offer(queue);\n            }\n\n                \n            if (record.timestamp > streamTime) {\n                streamTime = record.timestamp;\n                recordLatenessSensor.record(0, wallClockTime);\n            } else {\n                recordLatenessSensor.record(streamTime - record.timestamp, wallClockTime);\n            }\n        }\n    }\n\n    return record;\n}", "summary_tokens": ["get", "the", "next", "record", "and", "queue"], "project": "kafka"}
{"id": 2625, "code": "public static SessionWindows ofInactivityGapWithNoGrace(final Duration inactivityGap) {\n    return ofInactivityGapAndGrace(inactivityGap, ofMillis(NO_GRACE_PERIOD));\n}", "summary_tokens": ["creates", "a", "new", "window", "specification", "with", "the", "specified", "inactivity", "gap"], "project": "kafka"}
{"id": 3120, "code": "public void suppressShouldNotDropTombstonesForTimeWindows() {\n    final Harness<Windowed<String>, Long> harness =\n        new Harness<>(untilTimeLimit(ofMillis(0), maxRecords(0)), timeWindowedSerdeFrom(String.class, 100L), Long());\n    final MockInternalNewProcessorContext<Windowed<String>, Change<Long>> context = harness.context;\n\n    final long timestamp = 100L;\n    final Headers headers = new RecordHeaders().add(\"k\", \"v\".getBytes(StandardCharsets.UTF_8));\n    context.setRecordMetadata(\"\", 0, 0L);\n    context.setTimestamp(timestamp);\n    context.setHeaders(headers);\n    final Windowed<String> key = new Windowed<>(\"hey\", new TimeWindow(0L, 100L));\n    final Change<Long> value = new Change<>(null, ARBITRARY_LONG);\n    harness.processor.process(new Record<>(key, value, timestamp));\n\n    assertThat(context.forwarded(), hasSize(1));\n    final MockProcessorContext.CapturedForward capturedForward = context.forwarded().get(0);\n    assertThat(capturedForward.record(), is(new Record<>(key, value, timestamp, headers)));\n}", "summary_tokens": ["it", "s", "not", "ok", "to", "drop", "tombstones", "for", "non", "final", "results", "windowed", "streams", "since", "we", "may", "have", "emitted", "some", "results", "for", "the", "window", "before", "getting", "the", "tombstone", "see", "the", "suppressed", "internal", "javadoc"], "project": "kafka"}
{"id": 501, "code": "private void validatePositionsOnMetadataChange() {\n    int newMetadataUpdateVersion = metadata.updateVersion();\n    if (metadataUpdateVersion.getAndSet(newMetadataUpdateVersion) != newMetadataUpdateVersion) {\n        subscriptions.assignedPartitions().forEach(topicPartition -> {\n            ConsumerMetadata.LeaderAndEpoch leaderAndEpoch = metadata.currentLeader(topicPartition);\n            subscriptions.maybeValidatePositionForCurrentLeader(apiVersions, topicPartition, leaderAndEpoch);\n        });\n    }\n}", "summary_tokens": ["if", "we", "have", "seen", "new", "metadata", "as", "tracked", "by", "org"], "project": "kafka"}
{"id": 2570, "code": "public static <K, V> Grouped<K, V> valueSerde(final Serde<V> valueSerde) {\n    return new Grouped<>(null, null, valueSerde);\n}", "summary_tokens": ["create", "a", "grouped", "instance", "with", "the", "provided", "value", "serde"], "project": "kafka"}
{"id": 155, "code": "public boolean shouldValidateOnly() {\n    return validateOnly;\n}", "summary_tokens": ["return", "true", "if", "the", "request", "should", "be", "validated", "without", "altering", "the", "configs"], "project": "kafka"}
{"id": 3178, "code": "public void setTopic(final String topic) {\n    this.topic = topic;\n}", "summary_tokens": ["the", "context", "exposes", "this", "metadata", "for", "use", "in", "the", "processor"], "project": "kafka"}
{"id": 1764, "code": "public boolean usesTopicCreation() {\n    return enrichedSourceConfig != null;\n}", "summary_tokens": ["returns", "whether", "this", "configuration", "uses", "topic", "creation", "properties"], "project": "kafka"}
{"id": 3043, "code": "public <PS extends Serializer<P>, P> KeyValueIterator<Bytes, byte[]> prefixScan(final P prefix,\n                                                                                final PS prefixKeySerializer) {\n    throw new UnsupportedOperationException(\"MemoryLRUCache does not support prefixScan() function.\");\n}", "summary_tokens": ["unsupported", "operation", "exception", "at", "every", "invocation"], "project": "kafka"}
{"id": 3238, "code": "private void childHandler(String networkDevice, Consumer<String> consumer) {\n    Stream.of(\"sudo\", \"tc\", \"qdisc\", \"add\", \"dev\", networkDevice, \"parent\", \"1:1\", \"handle\", \"10:\").forEach(consumer);\n}", "summary_tokens": ["construct", "the", "first", "part", "of", "a", "tc", "command", "to", "define", "a", "qdisc", "child", "handler", "for", "the", "given", "interface"], "project": "kafka"}
{"id": 1738, "code": "public ConnectMetricsRegistry registry() {\n    return registry;\n}", "summary_tokens": ["get", "the", "registry", "of", "metric", "names"], "project": "kafka"}
{"id": 2555, "code": "public static <K, V> Branched<K, V> as(final String name) {\n    Objects.requireNonNull(name, \"name cannot be null\");\n    return new Branched<>(name, null, null);\n}", "summary_tokens": ["create", "an", "instance", "of", "branched", "with", "provided", "branch", "name", "suffix"], "project": "kafka"}
{"id": 2439, "code": "public long startOffset() {\n    return startOffset;\n}", "summary_tokens": ["start", "offset", "of", "this", "segment", "inclusive"], "project": "kafka"}
{"id": 2112, "code": "public void deleteConnector(String connName) {\n    String url = endpointForResource(String.format(\"connectors/%s\", connName));\n    Response response = requestDelete(url);\n    if (response.getStatus() >= Response.Status.BAD_REQUEST.getStatusCode()) {\n        throw new ConnectRestException(response.getStatus(),\n                \"Could not execute DELETE request. Error response: \" + responseToString(response));\n    }\n}", "summary_tokens": ["delete", "an", "existing", "connector"], "project": "kafka"}
{"id": 1685, "code": "public static <T> List<List<T>> groupPartitions(List<T> elements, int numGroups) {\n    if (numGroups <= 0)\n        throw new IllegalArgumentException(\"Number of groups must be positive.\");\n\n    List<List<T>> result = new ArrayList<>(numGroups);\n\n        \n    int perGroup = elements.size() / numGroups;\n    int leftover = elements.size() - (numGroups * perGroup);\n\n    int assigned = 0;\n    for (int group = 0; group < numGroups; group++) {\n        int numThisGroup = group < leftover ? perGroup + 1 : perGroup;\n        List<T> groupList = new ArrayList<>(numThisGroup);\n        for (int i = 0; i < numThisGroup; i++) {\n            groupList.add(elements.get(assigned));\n            assigned++;\n        }\n        result.add(groupList);\n    }\n\n    return result;\n}", "summary_tokens": ["given", "a", "list", "of", "elements", "and", "a", "target", "number", "of", "groups", "generates", "list", "of", "groups", "of", "elements", "to", "match", "the", "target", "number", "of", "groups", "spreading", "them", "evenly", "among", "the", "groups"], "project": "kafka"}
{"id": 2946, "code": "public static <K, V> RangeQuery<K, V> withRange(final K lower, final K upper) {\n    return new RangeQuery<>(Optional.of(lower), Optional.of(upper));\n}", "summary_tokens": ["interactive", "range", "query", "using", "a", "lower", "and", "upper", "bound", "to", "filter", "the", "keys", "returned"], "project": "kafka"}
{"id": 3235, "code": "public void waitForShutdown() throws InterruptedException {\n    while (!executor.awaitTermination(1, TimeUnit.DAYS)) { }\n}", "summary_tokens": ["wait", "for", "shutdown", "to", "complete"], "project": "kafka"}
{"id": 2147, "code": "public void assertConnectorIsRunningAndTasksHaveFailed(String connectorName, int numTasks, String detailMessage)\n        throws InterruptedException {\n    try {\n        waitForCondition(\n            () -> checkConnectorState(\n                connectorName,\n                AbstractStatus.State.RUNNING,\n                numTasks,\n                AbstractStatus.State.FAILED,\n                (actual, expected) -> actual >= expected\n            ).orElse(false),\n            CONNECTOR_SETUP_DURATION_MS,\n            \"Either the connector is not running or not all the \" + numTasks + \" tasks have failed.\");\n    } catch (AssertionError e) {\n        throw new AssertionError(detailMessage, e);\n    }\n}", "summary_tokens": ["assert", "that", "a", "connector", "is", "running", "that", "it", "has", "a", "specific", "number", "of", "tasks", "and", "that", "all", "of", "its", "tasks", "are", "in", "the", "failed", "state"], "project": "kafka"}
{"id": 621, "code": "public void reenqueue(ProducerBatch batch, long now) {\n    batch.reenqueued(now);\n    Deque<ProducerBatch> deque = getOrCreateDeque(batch.topicPartition);\n    synchronized (deque) {\n        if (transactionManager != null)\n            insertInSequenceOrder(deque, batch);\n        else\n            deque.addFirst(batch);\n    }\n}", "summary_tokens": ["re", "enqueue", "the", "given", "record", "batch", "in", "the", "accumulator"], "project": "kafka"}
{"id": 2349, "code": "public void startBackingOff(long currentTimeMs, long backoffDurationMs) {\n    this.backoffTimer.update(currentTimeMs);\n    this.backoffTimer.reset(backoffDurationMs);\n    this.isBackingOff = true;\n}", "summary_tokens": ["record", "the", "current", "election", "has", "failed", "since", "we", "ve", "either", "received", "sufficient", "rejecting", "voters", "or", "election", "timed", "out"], "project": "kafka"}
{"id": 3055, "code": "public long approximateNumEntries() {\n    validateStoreOpen();\n    final long numEntries;\n    try {\n        numEntries = dbAccessor.approximateNumEntries();\n    } catch (final RocksDBException e) {\n        throw new ProcessorStateException(\"Error fetching property from store \" + name, e);\n    }\n    if (isOverflowing(numEntries)) {\n        return Long.MAX_VALUE;\n    }\n    return numEntries;\n}", "summary_tokens": ["return", "an", "approximate", "count", "of", "key", "value", "mappings", "in", "this", "store"], "project": "kafka"}
{"id": 598, "code": "public RuntimeException error(int batchIndex) {\n    if (errorsByIndex == null) {\n        return null;\n    } else {\n        return errorsByIndex.apply(batchIndex);\n    }\n}", "summary_tokens": ["the", "error", "thrown", "generally", "on", "the", "server", "while", "processing", "this", "request"], "project": "kafka"}
{"id": 2627, "code": "public static SessionWindows with(final Duration inactivityGap) {\n    final String msgPrefix = prepareMillisCheckFailMsgPrefix(inactivityGap, \"inactivityGap\");\n    final long inactivityGapMs = validateMillisecondDuration(inactivityGap, msgPrefix);\n\n    return new SessionWindows(inactivityGapMs, Math.max(DEPRECATED_DEFAULT_24_HR_GRACE_PERIOD - inactivityGapMs, 0), false);\n}", "summary_tokens": ["create", "a", "new", "window", "specification", "with", "the", "specified", "inactivity", "gap"], "project": "kafka"}
{"id": 658, "code": "synchronized int firstInFlightSequence(TopicPartition topicPartition) {\n    if (!hasInflightBatches(topicPartition))\n        return RecordBatch.NO_SEQUENCE;\n\n    SortedSet<ProducerBatch> inflightBatches = txnPartitionMap.get(topicPartition).inflightBatchesBySequence;\n    if (inflightBatches.isEmpty())\n        return RecordBatch.NO_SEQUENCE;\n    else\n        return inflightBatches.first().baseSequence();\n}", "summary_tokens": ["returns", "the", "first", "inflight", "sequence", "for", "a", "given", "partition"], "project": "kafka"}
{"id": 333, "code": "public List<Integer> removingReplicas() {\n    return removingReplicas;\n}", "summary_tokens": ["the", "brokers", "that", "we", "are", "removing", "this", "partition", "from", "as", "part", "of", "a", "reassignment"], "project": "kafka"}
{"id": 1155, "code": "public Number expirationTime() throws OAuthBearerIllegalTokenException {\n    return claim(\"exp\", Number.class);\n}", "summary_tokens": ["return", "the", "a", "href", "https", "tools"], "project": "kafka"}
{"id": 734, "code": "public boolean ignoreFlagDescriptorChecksum() {\n    return this.ignoreFlagDescriptorChecksum;\n}", "summary_tokens": ["check", "whether", "kafka", "lz", "0", "block", "input", "stream", "is", "configured", "to", "ignore", "the", "frame", "descriptor", "checksum", "which", "is", "useful", "for", "compatibility", "with", "old", "client", "implementations", "that", "use", "incorrect", "checksum", "calculations"], "project": "kafka"}
{"id": 3028, "code": "public static <K, V> StoreBuilder<SessionStore<K, V>> sessionStoreBuilder(final SessionBytesStoreSupplier supplier,\n                                                                          final Serde<K> keySerde,\n                                                                          final Serde<V> valueSerde) {\n    Objects.requireNonNull(supplier, \"supplier cannot be null\");\n    return new SessionStoreBuilder<>(supplier, keySerde, valueSerde, Time.SYSTEM);\n}", "summary_tokens": ["creates", "a", "store", "builder", "that", "can", "be", "used", "to", "build", "a", "session", "store"], "project": "kafka"}
{"id": 2618, "code": "public static <K, V> Repartitioned<K, V> streamPartitioner(final StreamPartitioner<K, V> partitioner) {\n    return new Repartitioned<>(null, null, null, null, partitioner);\n}", "summary_tokens": ["create", "a", "repartitioned", "instance", "with", "provided", "partitioner"], "project": "kafka"}
{"id": 1992, "code": "public boolean createTopic(NewTopic topic) {\n    if (topic == null) return false;\n    Set<String> newTopicNames = createTopics(topic);\n    return newTopicNames.contains(topic.name());\n}", "summary_tokens": ["attempt", "to", "create", "the", "topic", "described", "by", "the", "given", "definition", "returning", "true", "if", "the", "topic", "was", "created", "or", "false", "if", "the", "topic", "already", "existed"], "project": "kafka"}
{"id": 290, "code": "public KafkaFuture<Collection<ConsumerGroupListing>> all() {\n    return all;\n}", "summary_tokens": ["returns", "a", "future", "that", "yields", "either", "an", "exception", "or", "the", "full", "set", "of", "consumer", "group", "listings"], "project": "kafka"}
{"id": 923, "code": "public Schema schema() {\n    return this.schema;\n}", "summary_tokens": ["the", "schema", "for", "this", "struct"], "project": "kafka"}
{"id": 1575, "code": "public static <T> void checkEquals(Iterable<T> it1, Iterable<T> it2) {\n    assertEquals(toList(it1), toList(it2));\n}", "summary_tokens": ["checks", "the", "two", "iterables", "for", "equality", "by", "first", "converting", "both", "to", "a", "list"], "project": "kafka"}
{"id": 2062, "code": "public void partitionsRevoked(Collection<TopicPartition> partitions) {\n    partitions.forEach(partition -> this.partitions.computeIfAbsent(partition, PartitionHistory::new).revoked());\n}", "summary_tokens": ["removes", "a", "set", "of", "partitions", "to", "the", "sink", "task", "s", "assignment"], "project": "kafka"}
{"id": 1712, "code": "public Map<TopicPartition, OffsetAndMetadata> remoteConsumerOffsets(String consumerGroupId,\n        String remoteClusterAlias, Duration timeout) {\n    long deadline = System.currentTimeMillis() + timeout.toMillis();\n    Map<TopicPartition, OffsetAndMetadata> offsets = new HashMap<>();\n\n    try (KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(consumerConfig,\n            new ByteArrayDeserializer(), new ByteArrayDeserializer())) {\n            \n            \n        String checkpointTopic = replicationPolicy.checkpointsTopic(remoteClusterAlias);\n        List<TopicPartition> checkpointAssignment =\n            Collections.singletonList(new TopicPartition(checkpointTopic, 0));\n        consumer.assign(checkpointAssignment);\n        consumer.seekToBeginning(checkpointAssignment);\n        while (System.currentTimeMillis() < deadline && !endOfStream(consumer, checkpointAssignment)) {\n            ConsumerRecords<byte[], byte[]> records = consumer.poll(timeout);\n            for (ConsumerRecord<byte[], byte[]> record : records) {\n                try {\n                    Checkpoint checkpoint = Checkpoint.deserializeRecord(record);\n                    if (checkpoint.consumerGroupId().equals(consumerGroupId)) {\n                        offsets.put(checkpoint.topicPartition(), checkpoint.offsetAndMetadata());\n                    }\n                } catch (SchemaException e) {\n                    log.info(\"Could not deserialize record. Skipping.\", e);\n                }\n            }\n        }\n        log.info(\"Consumed {} checkpoint records for {} from {}.\", offsets.size(),\n            consumerGroupId, checkpointTopic);\n    }\n    return offsets;\n}", "summary_tokens": ["translate", "a", "remote", "consumer", "group", "s", "offsets", "into", "corresponding", "local", "offsets"], "project": "kafka"}
{"id": 484, "code": "public int numRecords() {\n    return numRecords;\n}", "summary_tokens": ["the", "total", "number", "of", "non", "control", "messages", "for", "this", "fetch", "across", "all", "partitions"], "project": "kafka"}
{"id": 2454, "code": "RemoteLogSegmentId floorEntry(long offset) {\n    Map.Entry<Long, RemoteLogSegmentId> entry = offsetToId.floorEntry(offset);\n\n    return entry == null ? null : entry.getValue();\n}", "summary_tokens": ["returns", "the", "remote", "log", "segment", "id", "of", "a", "segment", "for", "the", "given", "offset", "if", "there", "exists", "a", "mapping", "associated", "with", "the", "greatest", "offset", "less", "than", "or", "equal", "to", "the", "given", "offset", "or", "null", "if", "there", "is", "no", "such", "mapping"], "project": "kafka"}
{"id": 382, "code": "public int serializedKeySize() {\n    return this.serializedKeySize;\n}", "summary_tokens": ["the", "size", "of", "the", "serialized", "uncompressed", "key", "in", "bytes"], "project": "kafka"}
{"id": 200, "code": "public boolean shouldRetryOnQuotaViolation() {\n    return retryOnQuotaViolation;\n}", "summary_tokens": ["returns", "true", "if", "quota", "violation", "should", "be", "automatically", "retried"], "project": "kafka"}
{"id": 359, "code": "private void complete(Map<K, V> values) {\n    if (!values.isEmpty()) {\n        future.complete(values);\n        clear(values.keySet());\n    }\n}", "summary_tokens": ["complete", "the", "future", "associated", "with", "the", "given", "key"], "project": "kafka"}
{"id": 2269, "code": "public boolean isSensitive(ConfigResource.Type type, String key) {\n    ConfigDef configDef = configDefs.get(type);\n    if (configDef == null) return true;\n    ConfigDef.ConfigKey configKey = configDef.configKeys().get(key);\n    if (configKey == null) return true;\n    return configKey.type.isSensitive();\n}", "summary_tokens": ["returns", "true", "if", "the", "configuration", "key", "specified", "is", "sensitive", "or", "if", "we", "don", "t", "know", "whether", "it", "is", "sensitive"], "project": "kafka"}
{"id": 990, "code": "public int keySize() {\n    if (magic() == RecordBatch.MAGIC_VALUE_V0)\n        return buffer.getInt(KEY_SIZE_OFFSET_V0);\n    else\n        return buffer.getInt(KEY_SIZE_OFFSET_V1);\n}", "summary_tokens": ["the", "length", "of", "the", "key", "in", "bytes", "the", "size", "in", "bytes", "of", "the", "key", "0", "if", "the", "key", "is", "null"], "project": "kafka"}
{"id": 2902, "code": "public ByteBuffer encode() {\n    if (data.version() > LATEST_SUPPORTED_VERSION) {\n        throw new IllegalStateException(\n            \"Should never try to encode a SubscriptionInfo with version [\" +\n                data.version() + \"] > LATEST_SUPPORTED_VERSION [\" + LATEST_SUPPORTED_VERSION + \"]\"\n        );\n    } else return MessageUtil.toByteBuffer(data, (short) data.version());\n}", "summary_tokens": ["task", "assignment", "exception", "if", "method", "fails", "to", "encode", "the", "data"], "project": "kafka"}
{"id": 2930, "code": "public boolean isSkipCache() {\n    return skipCache;\n}", "summary_tokens": ["the", "flag", "whether", "to", "skip", "the", "cache", "or", "not", "during", "query", "evaluation"], "project": "kafka"}
{"id": 299, "code": "public KafkaFuture<Map<String, TopicListing>> namesToListings() {\n    return future;\n}", "summary_tokens": ["return", "a", "future", "which", "yields", "a", "map", "of", "topic", "names", "to", "topic", "listing", "objects"], "project": "kafka"}
{"id": 659, "code": "public static Cluster empty() {\n    return new Cluster(null, new ArrayList<>(0), new ArrayList<>(0), Collections.emptySet(),\n        Collections.emptySet(), null);\n}", "summary_tokens": ["create", "an", "empty", "cluster", "instance", "with", "no", "nodes", "and", "no", "topic", "partitions"], "project": "kafka"}
{"id": 2776, "code": "long partitionTime() {\n    return partitionTime;\n}", "summary_tokens": ["the", "local", "partition", "time", "for", "this", "particular", "record", "queue"], "project": "kafka"}
{"id": 570, "code": "public String topic() {\n    return this.topicPartition.topic();\n}", "summary_tokens": ["the", "topic", "the", "record", "was", "appended", "to"], "project": "kafka"}
{"id": 351, "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["return", "a", "future", "which", "succeeds", "if", "all", "the", "feature", "updates", "succeed"], "project": "kafka"}
{"id": 1423, "code": "public void testInvalidTruststorePassword(Args args) {\n    try (SslChannelBuilder channelBuilder = newClientChannelBuilder()) {\n        args.sslClientConfigs.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, \"invalid\");\n        assertThrows(KafkaException.class, () -> channelBuilder.configure(args.sslClientConfigs));\n    }\n}", "summary_tokens": ["tests", "that", "channels", "cannot", "be", "created", "if", "truststore", "cannot", "be", "loaded"], "project": "kafka"}
{"id": 711, "code": "public AclPermissionType permissionType() {\n    return data.permissionType();\n}", "summary_tokens": ["return", "the", "acl", "permission", "type"], "project": "kafka"}
{"id": 1593, "code": "public String name() {\n    return name;\n}", "summary_tokens": ["get", "the", "name", "of", "this", "field"], "project": "kafka"}
{"id": 793, "code": "public Map<String, Map<String, Short>> toMap() {\n    return features.entrySet().stream().collect(\n        Collectors.toMap(\n            Map.Entry::getKey,\n            entry -> entry.getValue().toMap()));\n}", "summary_tokens": ["a", "map", "representation", "of", "the", "underlying", "features"], "project": "kafka"}
{"id": 2995, "code": "default <PS extends Serializer<P>, P> KeyValueIterator<K, V> prefixScan(P prefix, PS prefixKeySerializer) {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["return", "an", "iterator", "over", "all", "keys", "with", "the", "specified", "prefix"], "project": "kafka"}
{"id": 2564, "code": "public Consumed<K, V> withOffsetResetPolicy(final Topology.AutoOffsetReset resetPolicy) {\n    this.resetPolicy = resetPolicy;\n    return this;\n}", "summary_tokens": ["configure", "the", "instance", "of", "consumed", "with", "a", "org"], "project": "kafka"}
{"id": 3081, "code": "public void createTopics(final String... topics) throws InterruptedException {\n    for (final String topic : topics) {\n        createTopic(topic, 1, 1, Collections.emptyMap());\n    }\n}", "summary_tokens": ["create", "multiple", "kafka", "topics", "each", "with", "0", "partition", "and", "a", "replication", "factor", "of", "0"], "project": "kafka"}
{"id": 2376, "code": "public boolean hasElectionTimeoutExpired(long currentTimeMs) {\n    electionTimer.update(currentTimeMs);\n    return electionTimer.isExpired();\n}", "summary_tokens": ["check", "whether", "the", "timeout", "has", "expired"], "project": "kafka"}
{"id": 1499, "code": "public void testUnauthenticatedApiVersionsRequestOverPlaintextHandshakeVersion0() throws Exception {\n    testUnauthenticatedApiVersionsRequest(SecurityProtocol.SASL_PLAINTEXT, (short) 0);\n}", "summary_tokens": ["tests", "that", "kafka", "api", "versions", "requests", "are", "handled", "by", "the", "sasl", "server", "authenticator", "prior", "to", "sasl", "handshake", "flow", "and", "that", "subsequent", "authentication", "succeeds", "when", "transport", "layer", "is", "plaintext"], "project": "kafka"}
{"id": 301, "code": "public KafkaFuture<Set<String>> names() {\n    return future.thenApply(namesToListings -> namesToListings.keySet());\n}", "summary_tokens": ["return", "a", "future", "which", "yields", "a", "collection", "of", "topic", "names"], "project": "kafka"}
{"id": 2010, "code": "public static Map<String, TopicCreationGroup> configuredGroups(SourceConnectorConfig config) {\n    if (!config.usesTopicCreation()) {\n        return Collections.emptyMap();\n    }\n    List<String> groupNames = config.getList(TOPIC_CREATION_GROUPS_CONFIG);\n    Map<String, TopicCreationGroup> groups = new LinkedHashMap<>();\n    for (String group : groupNames) {\n        groups.put(group, new TopicCreationGroup(group, config));\n    }\n        \n        \n        \n    groups.put(DEFAULT_TOPIC_CREATION_GROUP, new TopicCreationGroup(DEFAULT_TOPIC_CREATION_GROUP, config));\n    return groups;\n}", "summary_tokens": ["parses", "the", "configuration", "of", "a", "source", "connector", "and", "returns", "the", "topic", "creation", "groups", "defined", "in", "the", "given", "configuration", "as", "a", "map", "of", "group", "names", "to", "topic", "creation", "objects"], "project": "kafka"}
{"id": 1346, "code": "public void testFetchOffsetErrors() {\n    buildFetcher();\n    assignFromUser(singleton(tp0));\n    subscriptions.requestOffsetReset(tp0, OffsetResetStrategy.LATEST);\n\n        \n    client.prepareResponse(listOffsetRequestMatcher(ListOffsetsRequest.LATEST_TIMESTAMP,\n        validLeaderEpoch), listOffsetResponse(Errors.OFFSET_NOT_AVAILABLE, 1L, 5L), false);\n    fetcher.resetOffsetsIfNeeded();\n    consumerClient.pollNoWakeup();\n    assertFalse(subscriptions.hasValidPosition(tp0));\n    assertTrue(subscriptions.isOffsetResetNeeded(tp0));\n    assertFalse(subscriptions.isFetchable(tp0));\n\n        \n    time.sleep(retryBackoffMs);\n    client.prepareResponse(listOffsetRequestMatcher(ListOffsetsRequest.LATEST_TIMESTAMP,\n        validLeaderEpoch), listOffsetResponse(Errors.LEADER_NOT_AVAILABLE, 1L, 5L), false);\n    fetcher.resetOffsetsIfNeeded();\n    consumerClient.pollNoWakeup();\n    assertFalse(subscriptions.hasValidPosition(tp0));\n    assertTrue(subscriptions.isOffsetResetNeeded(tp0));\n    assertFalse(subscriptions.isFetchable(tp0));\n\n        \n    time.sleep(retryBackoffMs);\n    client.prepareResponse(listOffsetRequestMatcher(ListOffsetsRequest.LATEST_TIMESTAMP),\n            listOffsetResponse(Errors.NONE, 1L, 5L), false);\n    fetcher.resetOffsetsIfNeeded();\n    consumerClient.pollNoWakeup();\n    assertTrue(subscriptions.hasValidPosition(tp0));\n    assertFalse(subscriptions.isOffsetResetNeeded(tp0));\n    assertTrue(subscriptions.isFetchable(tp0));\n    assertEquals(subscriptions.position(tp0).offset, 5L);\n}", "summary_tokens": ["make", "sure", "the", "client", "behaves", "appropriately", "when", "receiving", "an", "exception", "for", "unavailable", "offsets"], "project": "kafka"}
{"id": 3078, "code": "public void stop() {\n    if (brokers.length > 1) {\n            \n        final Set<String> topics = getAllTopicsInCluster();\n        if (!topics.isEmpty()) {\n            try (final Admin adminClient = brokers[0].createAdminClient()) {\n                adminClient.deleteTopics(topics).all().get();\n            } catch (final InterruptedException e) {\n                log.warn(\"Got interrupted while deleting topics in preparation for stopping embedded brokers\", e);\n                throw new RuntimeException(e);\n            } catch (final ExecutionException | RuntimeException e) {\n                log.warn(\"Couldn't delete all topics before stopping brokers\", e);\n            }\n        }\n    }\n    for (final KafkaEmbedded broker : brokers) {\n        broker.stopAsync();\n    }\n    for (final KafkaEmbedded broker : brokers) {\n        broker.awaitStoppedAndPurge();\n    }\n    zookeeper.shutdown();\n}", "summary_tokens": ["stop", "the", "kafka", "cluster"], "project": "kafka"}
{"id": 1052, "code": "public static FetchSnapshotRequestData singleton(\n    String clusterId,\n    TopicPartition topicPartition,\n    UnaryOperator<FetchSnapshotRequestData.PartitionSnapshot> operator\n) {\n    FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = operator.apply(\n        new FetchSnapshotRequestData.PartitionSnapshot().setPartition(topicPartition.partition())\n    );\n\n    return new FetchSnapshotRequestData()\n        .setClusterId(clusterId)\n        .setTopics(\n            Collections.singletonList(\n                new FetchSnapshotRequestData.TopicSnapshot()\n                    .setName(topicPartition.topic())\n                    .setPartitions(Collections.singletonList(partitionSnapshot))\n            )\n        );\n}", "summary_tokens": ["creates", "a", "fetch", "snapshot", "request", "data", "with", "a", "single", "partition", "snapshot", "for", "the", "topic", "partition"], "project": "kafka"}
{"id": 2612, "code": "public static <K, V> Produced<K, V> streamPartitioner(final StreamPartitioner<? super K, ? super V> partitioner) {\n    return new Produced<>(null, null, partitioner, null);\n}", "summary_tokens": ["create", "a", "produced", "instance", "with", "provided", "partitioner"], "project": "kafka"}
{"id": 594, "code": "public boolean await(long timeout, TimeUnit unit) throws InterruptedException {\n    return latch.await(timeout, unit);\n}", "summary_tokens": ["await", "the", "completion", "of", "this", "request", "up", "to", "the", "given", "time", "interval", "timeout", "the", "maximum", "time", "to", "wait", "unit", "the", "unit", "for", "the", "max", "time", "true", "if", "the", "request", "completed", "false", "if", "we", "timed", "out"], "project": "kafka"}
{"id": 2343, "code": "public static <T> Batch<T> data(\n    long baseOffset,\n    int epoch,\n    long appendTimestamp,\n    int sizeInBytes,\n    List<T> records\n) {\n    if (records.isEmpty()) {\n        throw new IllegalArgumentException(\n            String.format(\n                \"Batch must contain at least one record; baseOffset = %s; epoch = %s\",\n                baseOffset,\n                epoch\n            )\n        );\n    }\n\n    return new Batch<>(\n        baseOffset,\n        epoch,\n        appendTimestamp,\n        sizeInBytes,\n        baseOffset + records.size() - 1,\n        records\n    );\n}", "summary_tokens": ["create", "a", "data", "batch", "with", "the", "given", "base", "offset", "epoch", "and", "records"], "project": "kafka"}
{"id": 1439, "code": "public void testGracefulRemoteCloseDuringHandshakeWrite(Args args) throws Exception {\n    server = createEchoServer(args, SecurityProtocol.SSL);\n    testIOExceptionsDuringHandshake(args, server::closeKafkaChannels, FailureAction.NO_OP);\n}", "summary_tokens": ["tests", "that", "if", "the", "remote", "end", "closes", "the", "connection", "during", "ssl", "handshake", "while", "writing", "data", "the", "disconnection", "is", "not", "treated", "as", "an", "authentication", "failure"], "project": "kafka"}
{"id": 363, "code": "default void completeLookup(Map<K, Integer> brokerIdMapping) {\n}", "summary_tokens": ["invoked", "when", "lookup", "of", "a", "set", "of", "keys", "succeeds"], "project": "kafka"}
{"id": 2851, "code": "void initTransaction() {\n    if (!eosEnabled()) {\n        throw new IllegalStateException(formatException(\"Exactly-once is not enabled\"));\n    }\n    if (!transactionInitialized) {\n            \n            \n        try {\n            producer.initTransactions();\n            transactionInitialized = true;\n        } catch (final TimeoutException timeoutException) {\n            log.warn(\n                \"Timeout exception caught trying to initialize transactions. \" +\n                    \"The broker is either slow or in bad state (like not having enough replicas) in \" +\n                    \"responding to the request, or the connection to broker was interrupted sending \" +\n                    \"the request or receiving the response. \" +\n                    \"Will retry initializing the task in the next loop. \" +\n                    \"Consider overwriting {} to a larger value to avoid timeout errors\",\n                ProducerConfig.MAX_BLOCK_MS_CONFIG\n            );\n\n                \n            throw timeoutException;\n        } catch (final KafkaException exception) {\n            throw new StreamsException(\n                formatException(\"Error encountered trying to initialize transactions\"),\n                exception\n            );\n        }\n    }\n}", "summary_tokens": ["illegal", "state", "exception", "if", "eos", "is", "disabled"], "project": "kafka"}
{"id": 877, "code": "public int size() {\n    return payload().limit() + size.limit();\n}", "summary_tokens": ["returns", "the", "total", "size", "of", "the", "receive", "including", "payload", "and", "size", "buffer", "for", "use", "in", "metrics"], "project": "kafka"}
{"id": 972, "code": "public void close() throws IOException {\n    flush();\n    trim();\n    channel.close();\n}", "summary_tokens": ["close", "this", "record", "set"], "project": "kafka"}
{"id": 746, "code": "public Map<String, Object> valuesWithPrefixOverride(String prefix) {\n    Map<String, Object> result = new RecordingMap<>(values(), prefix, true);\n    for (Map.Entry<String, ?> entry : originals.entrySet()) {\n        if (entry.getKey().startsWith(prefix) && entry.getKey().length() > prefix.length()) {\n            String keyWithNoPrefix = entry.getKey().substring(prefix.length());\n            ConfigDef.ConfigKey configKey = definition.configKeys().get(keyWithNoPrefix);\n            if (configKey != null)\n                result.put(keyWithNoPrefix, definition.parseValue(configKey, entry.getValue(), true));\n            else {\n                String keyWithNoSecondaryPrefix = keyWithNoPrefix.substring(keyWithNoPrefix.indexOf('.') + 1);\n                configKey = definition.configKeys().get(keyWithNoSecondaryPrefix);\n                if (configKey != null)\n                    result.put(keyWithNoPrefix, definition.parseValue(configKey, entry.getValue(), true));\n            }\n        }\n    }\n    return result;\n}", "summary_tokens": ["put", "all", "keys", "that", "do", "not", "start", "with", "prefix", "and", "their", "parsed", "values", "in", "the", "result", "map", "and", "then", "put", "all", "the", "remaining", "keys", "with", "the", "prefix", "stripped", "and", "their", "parsed", "values", "in", "the", "result", "map"], "project": "kafka"}
{"id": 2414, "code": "public int size() {\n    return blockSize;\n}", "summary_tokens": ["get", "the", "number", "of", "ids", "contained", "in", "this", "block"], "project": "kafka"}
{"id": 2720, "code": "public Record<K, V> withHeaders(final Headers headers) {\n    return new Record<>(key, value, timestamp, headers);\n}", "summary_tokens": ["a", "convenient", "way", "to", "produce", "a", "new", "record", "if", "you", "only", "need", "to", "change", "the", "headers"], "project": "kafka"}
{"id": 2028, "code": "public void awaitRecords(long timeout) throws InterruptedException {\n    if (recordsRemainingLatch == null || expectedRecords < 0) {\n        throw new IllegalStateException(\"expectedRecords() was not set for this connector?\");\n    }\n    if (!recordsRemainingLatch.await(timeout, TimeUnit.MILLISECONDS)) {\n        String msg = String.format(\n                \"Insufficient records seen by connector %s in %d millis. Records expected=%d, actual=%d\",\n                connectorName,\n                timeout,\n                expectedRecords,\n                expectedRecords - recordsRemainingLatch.getCount());\n        throw new DataException(msg);\n    }\n}", "summary_tokens": ["wait", "for", "this", "connector", "to", "meet", "the", "expected", "number", "of", "records", "as", "defined", "by", "expected", "records"], "project": "kafka"}
{"id": 1227, "code": "static public Serde<ByteBuffer> ByteBuffer() {\n    return new ByteBufferSerde();\n}", "summary_tokens": ["a", "serde", "for", "nullable", "byte", "buffer", "type"], "project": "kafka"}
{"id": 3221, "code": "public static String prettyPrintGrid(List<List<String>> lines) {\n    int numColumns = -1;\n    int rowIndex = 0;\n    for (List<String> col : lines) {\n        if (numColumns == -1) {\n            numColumns = col.size();\n        } else if (numColumns != col.size()) {\n            throw new RuntimeException(\"Expected \" + numColumns + \" columns in row \" +\n                rowIndex + \", but got \" + col.size());\n        }\n        rowIndex++;\n    }\n    List<Integer> widths = new ArrayList<>(numColumns);\n    for (int x = 0; x < numColumns; x++) {\n        int w = 0;\n        for (List<String> cols : lines) {\n            w = Math.max(w, cols.get(x).length() + 1);\n        }\n        widths.add(w);\n    }\n    StringBuilder bld = new StringBuilder();\n    for (int y = 0; y < lines.size(); y++) {\n        List<String> cols = lines.get(y);\n        for (int x = 0; x < cols.size(); x++) {\n            String val = cols.get(x);\n            int minWidth = widths.get(x);\n            bld.append(val);\n            for (int i = 0; i < minWidth - val.length(); i++) {\n                bld.append(\" \");\n            }\n        }\n        bld.append(String.format(\"%n\"));\n    }\n    return bld.toString();\n}", "summary_tokens": ["formats", "strings", "in", "a", "grid", "pattern"], "project": "kafka"}
{"id": 1240, "code": "public static int readUnsignedVarint(DataInput in) throws IOException {\n    int value = 0;\n    int i = 0;\n    int b;\n    while (((b = in.readByte()) & 0x80) != 0) {\n        value |= (b & 0x7f) << i;\n        i += 7;\n        if (i > 28)\n            throw illegalVarintException(value);\n    }\n    value |= b << i;\n    return value;\n}", "summary_tokens": ["read", "an", "integer", "stored", "in", "variable", "length", "format", "using", "unsigned", "decoding", "from", "a", "href", "http", "code"], "project": "kafka"}
{"id": 1987, "code": "public TopicAdmin topicAdmin() {\n    return admin.updateAndGet(this::createAdmin);\n}", "summary_tokens": ["get", "the", "shared", "topic", "admin", "instance"], "project": "kafka"}
{"id": 1903, "code": "public Converter newConverter(AbstractConfig config, String classPropertyName, ClassLoaderUsage classLoaderUsage) {\n    if (!config.originals().containsKey(classPropertyName)) {\n            \n        return null;\n    }\n\n    Class<? extends Converter> klass = null;\n    switch (classLoaderUsage) {\n        case CURRENT_CLASSLOADER:\n                \n                \n                \n            klass = pluginClassFromConfig(config, classPropertyName, Converter.class, delegatingLoader.converters());\n            break;\n        case PLUGINS:\n                \n            String converterClassOrAlias = config.getClass(classPropertyName).getName();\n            try {\n                klass = pluginClass(delegatingLoader, converterClassOrAlias, Converter.class);\n            } catch (ClassNotFoundException e) {\n                throw new ConnectException(\n                        \"Failed to find any class that implements Converter and which name matches \"\n                        + converterClassOrAlias + \", available converters are: \"\n                        + pluginNames(delegatingLoader.converters())\n                );\n            }\n            break;\n    }\n    if (klass == null) {\n        throw new ConnectException(\"Unable to initialize the Converter specified in '\" + classPropertyName + \"'\");\n    }\n\n        \n    final boolean isKeyConverter = WorkerConfig.KEY_CONVERTER_CLASS_CONFIG.equals(classPropertyName);\n\n        \n    String configPrefix = classPropertyName + \".\";\n    Map<String, Object> converterConfig = config.originalsWithPrefix(configPrefix);\n    log.debug(\"Configuring the {} converter with configuration keys:{}{}\",\n              isKeyConverter ? \"key\" : \"value\", System.lineSeparator(), converterConfig.keySet());\n\n    Converter plugin;\n    ClassLoader savedLoader = compareAndSwapLoaders(klass.getClassLoader());\n    try {\n        plugin = newPlugin(klass);\n        plugin.configure(converterConfig, isKeyConverter);\n    } finally {\n        compareAndSwapLoaders(savedLoader);\n    }\n    return plugin;\n}", "summary_tokens": ["if", "the", "given", "configuration", "defines", "a", "converter", "using", "the", "named", "configuration", "property", "return", "a", "new", "configured", "instance"], "project": "kafka"}
{"id": 3124, "code": "private static Map<TopicPartition, Long> getTopicPartitionOffsetsMap(final List<String> changelogTopics,\n                                                                     final List<Integer> topicsNumPartitions) {\n    if (changelogTopics.size() != topicsNumPartitions.size()) {\n        throw new IllegalStateException(\"Passed in \" + changelogTopics.size() + \" changelog topic names, but \" +\n                topicsNumPartitions.size() + \" different numPartitions for the topics\");\n    }\n    final Map<TopicPartition, Long> changelogEndOffsets = new HashMap<>();\n    for (int i = 0; i < changelogTopics.size(); ++i) {\n        final String topic = changelogTopics.get(i);\n        final int numPartitions = topicsNumPartitions.get(i);\n        for (int partition = 0; partition < numPartitions; ++partition) {\n            changelogEndOffsets.put(new TopicPartition(topic, partition), Long.MAX_VALUE);\n        }\n    }\n    return changelogEndOffsets;\n}", "summary_tokens": ["helper", "for", "building", "the", "input", "to", "create", "mock", "admin", "client", "in", "cases", "where", "we", "don", "t", "care", "about", "the", "actual", "offsets", "changelog", "topics", "the", "names", "of", "all", "changelog", "topics", "in", "the", "topology", "topics", "num", "partitions", "the", "number", "of", "partitions", "for", "the", "corresponding", "changelog", "topic", "such", "that", "the", "number", "of", "partitions", "of", "the", "ith", "topic", "in", "changelog", "topics", "is", "given", "by", "the", "ith", "element", "of", "topics", "num", "partitions"], "project": "kafka"}
{"id": 19, "code": "public boolean isConnected(String id) {\n    NodeConnectionState state = nodeState.get(id);\n    return state != null && state.state.isConnected();\n}", "summary_tokens": ["return", "true", "if", "the", "connection", "has", "been", "established", "id", "the", "id", "of", "the", "node", "to", "check"], "project": "kafka"}
{"id": 2504, "code": "public HostInfo activeHost() {\n    return activeHost;\n}", "summary_tokens": ["get", "the", "active", "kafka", "streams", "instance", "for", "given", "key"], "project": "kafka"}
{"id": 1733, "code": "protected final boolean maybeAddConfigErrors(\n    ConfigInfos configInfos,\n    Callback<Created<ConnectorInfo>> callback\n) {\n    int errors = configInfos.errorCount();\n    boolean hasErrors = errors > 0;\n    if (hasErrors) {\n        StringBuilder messages = new StringBuilder();\n        messages.append(\"Connector configuration is invalid and contains the following \")\n            .append(errors).append(\" error(s):\");\n        for (ConfigInfo configInfo : configInfos.values()) {\n            for (String msg : configInfo.configValue().errors()) {\n                messages.append('\\n').append(msg);\n            }\n        }\n        callback.onCompletion(\n            new BadRequestException(\n                messages.append(\n                    \"\\nYou can also find the above list of errors at the endpoint `/connector-plugins/{connectorType}/config/validate`\"\n                ).toString()\n            ), null\n        );\n    }\n    return hasErrors;\n}", "summary_tokens": ["checks", "a", "given", "config", "infos", "for", "validation", "error", "messages", "and", "adds", "an", "exception", "to", "the", "given", "callback", "if", "any", "were", "found"], "project": "kafka"}
{"id": 2338, "code": "public long appendTimestamp() {\n    return appendTimestamp;\n}", "summary_tokens": ["the", "append", "timestamp", "in", "milliseconds", "of", "the", "batch"], "project": "kafka"}
{"id": 1159, "code": "public boolean configured() {\n    return configured;\n}", "summary_tokens": ["return", "true", "if", "this", "instance", "has", "been", "configured", "otherwise", "false"], "project": "kafka"}
{"id": 1472, "code": "public void testConversion(CompressionType compressionType, byte toMagic, boolean overflow) throws IOException {\n    doTestConversion(compressionType, toMagic, overflow);\n}", "summary_tokens": ["test", "the", "lazy", "down", "conversion", "path"], "project": "kafka"}
{"id": 2584, "code": "public static <K, V, VO> Joined<K, V, VO> valueSerde(final Serde<V> valueSerde) {\n    return new Joined<>(null, valueSerde, null, null);\n}", "summary_tokens": ["create", "an", "instance", "of", "joined", "with", "a", "value", "serde"], "project": "kafka"}
{"id": 958, "code": "public static float estimation(String topic, CompressionType type) {\n    float[] compressionRatioForTopic = getAndCreateEstimationIfAbsent(topic);\n    return compressionRatioForTopic[type.id];\n}", "summary_tokens": ["get", "the", "compression", "ratio", "estimation", "for", "a", "topic", "and", "compression", "type"], "project": "kafka"}
{"id": 2736, "code": "public synchronized ProcessorTopology buildSubtopology(final int topicGroupId) {\n    final Set<String> nodeGroup = nodeGroups().get(topicGroupId);\n    return build(nodeGroup);\n}", "summary_tokens": ["topic", "group", "id", "group", "of", "topics", "corresponding", "to", "a", "single", "subtopology", "subset", "of", "the", "full", "topology"], "project": "kafka"}
{"id": 870, "code": "public boolean maybeBeginClientReauthentication(Supplier<Long> nowNanosSupplier)\n        throws AuthenticationException, IOException {\n    if (!ready())\n        throw new IllegalStateException(\n                \"KafkaChannel should always be \\\"ready\\\" when it is checked for possible re-authentication\");\n    if (muteState != ChannelMuteState.NOT_MUTED || midWrite\n            || authenticator.clientSessionReauthenticationTimeNanos() == null)\n        return false;\n        \n    long nowNanos = nowNanosSupplier.get();\n    if (nowNanos < authenticator.clientSessionReauthenticationTimeNanos())\n        return false;\n    swapAuthenticatorsAndBeginReauthentication(new ReauthenticationContext(authenticator, receive, nowNanos));\n    receive = null;\n    return true;\n}", "summary_tokens": ["if", "this", "is", "a", "client", "side", "connection", "that", "is", "not", "muted", "there", "is", "no", "in", "progress", "write", "and", "there", "is", "a", "session", "expiration", "time", "defined", "that", "has", "past", "then", "begin", "the", "process", "of", "re", "authenticating", "the", "connection", "and", "return", "true", "otherwise", "return", "false"], "project": "kafka"}
{"id": 445, "code": "private Map<String, List<TopicPartition>> generalAssign(Map<String, Integer> partitionsPerTopic,\n                                                        Map<String, Subscription> subscriptions,\n                                                        Map<String, List<TopicPartition>> currentAssignment) {\n    if (log.isDebugEnabled()) {\n        log.debug(\"performing general assign. partitionsPerTopic: {}, subscriptions: {}, currentAssignment: {}\",\n            partitionsPerTopic, subscriptions, currentAssignment);\n    }\n\n    Map<TopicPartition, ConsumerGenerationPair> prevAssignment = new HashMap<>();\n    partitionMovements = new PartitionMovements();\n\n    prepopulateCurrentAssignments(subscriptions, prevAssignment);\n\n        \n    final Map<String, List<String>> topic2AllPotentialConsumers = new HashMap<>(partitionsPerTopic.keySet().size());\n        \n    final Map<String, List<String>> consumer2AllPotentialTopics = new HashMap<>(subscriptions.keySet().size());\n\n        \n    partitionsPerTopic.keySet().stream().forEach(\n        topicName -> topic2AllPotentialConsumers.put(topicName, new ArrayList<>()));\n\n    for (Entry<String, Subscription> entry: subscriptions.entrySet()) {\n        String consumerId = entry.getKey();\n        List<String> subscribedTopics = new ArrayList<>(entry.getValue().topics().size());\n        consumer2AllPotentialTopics.put(consumerId, subscribedTopics);\n        entry.getValue().topics().stream().filter(topic -> partitionsPerTopic.get(topic) != null).forEach(topic -> {\n            subscribedTopics.add(topic);\n            topic2AllPotentialConsumers.get(topic).add(consumerId);\n        });\n\n            \n        if (!currentAssignment.containsKey(consumerId))\n            currentAssignment.put(consumerId, new ArrayList<>());\n    }\n\n        \n    Map<TopicPartition, String> currentPartitionConsumer = new HashMap<>();\n    for (Map.Entry<String, List<TopicPartition>> entry: currentAssignment.entrySet())\n        for (TopicPartition topicPartition: entry.getValue())\n            currentPartitionConsumer.put(topicPartition, entry.getKey());\n\n    int totalPartitionsCount = partitionsPerTopic.values().stream().reduce(0, Integer::sum);\n    List<String> sortedAllTopics = new ArrayList<>(topic2AllPotentialConsumers.keySet());\n    Collections.sort(sortedAllTopics, new TopicComparator(topic2AllPotentialConsumers));\n    List<TopicPartition> sortedAllPartitions = getAllTopicPartitions(partitionsPerTopic, sortedAllTopics, totalPartitionsCount);\n\n        \n    List<TopicPartition> assignedPartitions = new ArrayList<>();\n    boolean revocationRequired = false;\n    for (Iterator<Entry<String, List<TopicPartition>>> it = currentAssignment.entrySet().iterator(); it.hasNext();) {\n        Map.Entry<String, List<TopicPartition>> entry = it.next();\n        Subscription consumerSubscription = subscriptions.get(entry.getKey());\n        if (consumerSubscription == null) {\n                \n            for (TopicPartition topicPartition: entry.getValue())\n                currentPartitionConsumer.remove(topicPartition);\n            it.remove();\n        } else {\n                \n            for (Iterator<TopicPartition> partitionIter = entry.getValue().iterator(); partitionIter.hasNext();) {\n                TopicPartition partition = partitionIter.next();\n                if (!topic2AllPotentialConsumers.containsKey(partition.topic())) {\n                        \n                    partitionIter.remove();\n                    currentPartitionConsumer.remove(partition);\n                } else if (!consumerSubscription.topics().contains(partition.topic())) {\n                        \n                    partitionIter.remove();\n                    revocationRequired = true;\n                } else {\n                        \n                        \n                        \n                    assignedPartitions.add(partition);\n                }\n            }\n        }\n    }\n\n        \n    List<TopicPartition> unassignedPartitions = getUnassignedPartitions(sortedAllPartitions, assignedPartitions, topic2AllPotentialConsumers);\n\n    if (log.isDebugEnabled()) {\n        log.debug(\"unassigned Partitions: {}\", unassignedPartitions);\n    }\n\n        \n        \n        \n\n        \n    TreeSet<String> sortedCurrentSubscriptions = new TreeSet<>(new SubscriptionComparator(currentAssignment));\n    sortedCurrentSubscriptions.addAll(currentAssignment.keySet());\n\n    balance(currentAssignment, prevAssignment, sortedAllPartitions, unassignedPartitions, sortedCurrentSubscriptions,\n        consumer2AllPotentialTopics, topic2AllPotentialConsumers, currentPartitionConsumer, revocationRequired,\n        partitionsPerTopic, totalPartitionsCount);\n\n    log.info(\"Final assignment of partitions to consumers: \\n{}\", currentAssignment);\n\n    return currentAssignment;\n}", "summary_tokens": ["this", "general", "assign", "algorithm", "guarantees", "the", "assignment", "that", "is", "as", "balanced", "as", "possible"], "project": "kafka"}
{"id": 1027, "code": "public Map<TopicPartition, RecordConversionStats> recordConversionStats() {\n    return recordConversionStats;\n}", "summary_tokens": ["get", "any", "statistics", "that", "were", "recorded", "as", "part", "of", "executing", "this", "multi", "records", "send"], "project": "kafka"}
{"id": 1637, "code": "public static Float convertToFloat(Schema schema, Object value) throws DataException {\n    return (Float) convertTo(Schema.OPTIONAL_FLOAT32_SCHEMA, schema, value);\n}", "summary_tokens": ["convert", "the", "specified", "value", "to", "an", "type", "float", "0", "float", "value"], "project": "kafka"}
{"id": 664, "code": "public Optional<Node> nodeIfOnline(TopicPartition partition, int id) {\n    Node node = nodeById(id);\n    PartitionInfo partitionInfo = partition(partition);\n    if (node != null && partitionInfo != null && !Arrays.asList(partitionInfo.offlineReplicas()).contains(node)) {\n        return Optional.of(node);\n    } else {\n        return Optional.empty();\n    }\n}", "summary_tokens": ["get", "the", "node", "by", "node", "id", "if", "the", "replica", "for", "the", "given", "partition", "is", "online", "partition", "id", "the", "node"], "project": "kafka"}
{"id": 1665, "code": "public void initialize(SinkTaskContext context) {\n    this.context = context;\n}", "summary_tokens": ["initialize", "the", "context", "of", "this", "task"], "project": "kafka"}
{"id": 1452, "code": "private void checkAuthentiationFailed() throws IOException, InterruptedException {\n    sslClientConfigs.put(SslConfigs.SSL_ENABLED_PROTOCOLS_CONFIG, Arrays.asList(\"TLSv1.3\"));\n    createSelector(sslClientConfigs);\n    InetSocketAddress addr = new InetSocketAddress(\"localhost\", server.port());\n    selector.connect(\"0\", addr, BUFFER_SIZE, BUFFER_SIZE);\n\n    NetworkTestUtils.waitForChannelClose(selector, \"0\", ChannelState.State.AUTHENTICATION_FAILED);\n    server.verifyAuthenticationMetrics(0, 1);\n}", "summary_tokens": ["checks", "connection", "failed", "using", "the", "specified", "tls", "version"], "project": "kafka"}
{"id": 2210, "code": "private static ProduceResponse response() {\n    return new ProduceResponse(PARTITION_RESPONSE_MAP);\n}", "summary_tokens": ["this", "method", "is", "still", "used", "by", "production", "so", "we", "benchmark", "it"], "project": "kafka"}
{"id": 703, "code": "public long getLeastSignificantBits() {\n    return this.leastSignificantBits;\n}", "summary_tokens": ["returns", "the", "least", "significant", "bits", "of", "the", "uuid", "s", "0", "value"], "project": "kafka"}
{"id": 3129, "code": "public static UUID uuidForInt(final int n) {\n    return new UUID(0, n);\n}", "summary_tokens": ["builds", "a", "uuid", "by", "repeating", "the", "given", "number", "n"], "project": "kafka"}
{"id": 2745, "code": "int addRawRecords(final TopicPartition partition, final Iterable<ConsumerRecord<byte[], byte[]>> rawRecords) {\n    final RecordQueue recordQueue = partitionQueues.get(partition);\n\n    if (recordQueue == null) {\n        throw new IllegalStateException(\"Partition \" + partition + \" not found.\");\n    }\n\n    final int oldSize = recordQueue.size();\n    final int newSize = recordQueue.addRawRecords(rawRecords);\n\n        \n    if (oldSize == 0 && newSize > 0) {\n        nonEmptyQueuesByTime.offer(recordQueue);\n\n            \n            \n            \n        if (nonEmptyQueuesByTime.size() == this.partitionQueues.size()) {\n            allBuffered = true;\n        }\n    }\n\n    totalBuffered += newSize - oldSize;\n\n    return newSize;\n}", "summary_tokens": ["adds", "raw", "records", "to", "this", "partition", "group"], "project": "kafka"}
{"id": 1762, "code": "public static void validate(Map<String, String> props) {\n    final boolean hasTopicsConfig = hasTopicsConfig(props);\n    final boolean hasTopicsRegexConfig = hasTopicsRegexConfig(props);\n    final boolean hasDlqTopicConfig = hasDlqTopicConfig(props);\n\n    if (hasTopicsConfig && hasTopicsRegexConfig) {\n        throw new ConfigException(SinkTask.TOPICS_CONFIG + \" and \" + SinkTask.TOPICS_REGEX_CONFIG +\n            \" are mutually exclusive options, but both are set.\");\n    }\n\n    if (!hasTopicsConfig && !hasTopicsRegexConfig) {\n        throw new ConfigException(\"Must configure one of \" +\n            SinkTask.TOPICS_CONFIG + \" or \" + SinkTask.TOPICS_REGEX_CONFIG);\n    }\n\n    if (hasDlqTopicConfig) {\n        String dlqTopic = props.get(DLQ_TOPIC_NAME_CONFIG).trim();\n        if (hasTopicsConfig) {\n            List<String> topics = parseTopicsList(props);\n            if (topics.contains(dlqTopic)) {\n                throw new ConfigException(String.format(\"The DLQ topic '%s' may not be included in the list of \"\n                        + \"topics ('%s=%s') consumed by the connector\", dlqTopic, SinkTask.TOPICS_REGEX_CONFIG, topics));\n            }\n        }\n        if (hasTopicsRegexConfig) {\n            String topicsRegexStr = props.get(SinkTask.TOPICS_REGEX_CONFIG);\n            Pattern pattern = Pattern.compile(topicsRegexStr);\n            if (pattern.matcher(dlqTopic).matches()) {\n                throw new ConfigException(String.format(\"The DLQ topic '%s' may not be included in the regex matching the \"\n                        + \"topics ('%s=%s') consumed by the connector\", dlqTopic, SinkTask.TOPICS_REGEX_CONFIG, topicsRegexStr));\n            }\n        }\n    }\n}", "summary_tokens": ["throw", "an", "exception", "if", "the", "passed", "in", "properties", "do", "not", "constitute", "a", "valid", "sink"], "project": "kafka"}
{"id": 1293, "code": "public void updateAndReset(long timeoutMs) {\n    update();\n    reset(timeoutMs);\n}", "summary_tokens": ["reset", "the", "timer", "to", "the", "specific", "timeout"], "project": "kafka"}
{"id": 1088, "code": "public void extensions(SaslExtensions extensions) {\n    this.extensions = Objects.requireNonNull(extensions, \"extensions must not be null\");\n}", "summary_tokens": ["sets", "the", "sasl", "extensions", "on", "this", "callback"], "project": "kafka"}
{"id": 1330, "code": "public void testClientSideTimeoutAfterFailureToSend() throws Exception {\n    Cluster cluster = mockCluster(3, 0);\n    CompletableFuture<String> disconnectFuture = new CompletableFuture<>();\n    MockTime time = new MockTime();\n    try (final AdminClientUnitTestEnv env = new AdminClientUnitTestEnv(time, cluster,\n            newStrMap(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, \"1\",\n                      AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG, \"100000\",\n                      AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, \"1\"))) {\n        env.kafkaClient().setNodeApiVersions(NodeApiVersions.create());\n        for (Node node : cluster.nodes()) {\n            env.kafkaClient().delayReady(node, 100);\n        }\n\n            \n            \n            \n        CountDownLatch readyLatch = new CountDownLatch(2);\n\n        env.kafkaClient().setDisconnectFuture(disconnectFuture);\n        env.kafkaClient().setReadyCallback(node -> readyLatch.countDown());\n        env.kafkaClient().prepareResponse(prepareMetadataResponse(cluster, Errors.NONE));\n\n        final ListTopicsResult result = env.adminClient().listTopics();\n\n        readyLatch.await(TestUtils.DEFAULT_MAX_WAIT_MS, TimeUnit.MILLISECONDS);\n        log.debug(\"Advancing clock by 25 ms to trigger client-side disconnect.\");\n        time.sleep(25);\n        disconnectFuture.get();\n\n        log.debug(\"Enabling nodes to send requests again.\");\n        for (Node node : cluster.nodes()) {\n            env.kafkaClient().delayReady(node, 0);\n        }\n        time.sleep(5);\n        log.info(\"Waiting for result.\");\n        assertEquals(0, result.listings().get().size());\n    }\n}", "summary_tokens": ["test", "that", "if", "the", "client", "can", "obtain", "a", "node", "assignment", "but", "can", "t", "send", "to", "the", "given", "node", "it", "will", "disconnect", "and", "try", "a", "different", "node"], "project": "kafka"}
{"id": 1768, "code": "public SubmittedRecord submit(SourceRecord record) {\n    return submit((Map<String, Object>) record.sourcePartition(), (Map<String, Object>) record.sourceOffset());\n}", "summary_tokens": ["enqueue", "a", "new", "source", "record", "before", "dispatching", "it", "to", "a", "producer"], "project": "kafka"}
{"id": 2194, "code": "default Optional<Integer> fixedLength() {\n    return Optional.empty();\n}", "summary_tokens": ["gets", "the", "fixed", "length", "of", "the", "field", "or", "none", "if", "the", "field", "is", "variable", "length"], "project": "kafka"}
{"id": 2522, "code": "public synchronized Topology build(final Properties props) {\n    final boolean optimizeTopology =\n        props != null &&\n        StreamsConfig.OPTIMIZE.equals(props.getProperty(StreamsConfig.TOPOLOGY_OPTIMIZATION_CONFIG));\n\n    internalStreamsBuilder.buildAndOptimizeTopology(optimizeTopology);\n    return topology;\n}", "summary_tokens": ["returns", "the", "topology", "that", "represents", "the", "specified", "processing", "logic", "and", "accepts", "a", "properties", "instance", "used", "to", "indicate", "whether", "to", "optimize", "topology", "or", "not"], "project": "kafka"}
{"id": 1849, "code": "public static ExtendedWorkerState deserializeMetadata(ByteBuffer buffer) {\n    Struct header = CONNECT_PROTOCOL_HEADER_SCHEMA.read(buffer);\n    Short version = header.getShort(VERSION_KEY_NAME);\n    checkVersionCompatibility(version);\n    Struct configState = CONFIG_STATE_V1.read(buffer);\n    long configOffset = configState.getLong(CONFIG_OFFSET_KEY_NAME);\n    String url = configState.getString(URL_KEY_NAME);\n    Struct allocation = ALLOCATION_V1.read(buffer);\n        \n    ExtendedAssignment assignment = deserializeAssignment(allocation.getBytes(ALLOCATION_KEY_NAME));\n    return new ExtendedWorkerState(url, configOffset, assignment);\n}", "summary_tokens": ["given", "a", "byte", "buffer", "that", "contains", "protocol", "metadata", "return", "the", "deserialized", "form", "of", "the", "metadata"], "project": "kafka"}
{"id": 208, "code": "public Map<AclBindingFilter, KafkaFuture<FilterResults>> values() {\n    return futures;\n}", "summary_tokens": ["return", "a", "map", "from", "acl", "filters", "to", "futures", "which", "can", "be", "used", "to", "check", "the", "status", "of", "the", "deletions", "by", "each", "filter"], "project": "kafka"}
{"id": 3104, "code": "public static void startApplicationAndWaitUntilRunning(final List<KafkaStreams> streamsList,\n                                                       final Duration timeout) throws Exception {\n    final Lock stateLock = new ReentrantLock();\n    final Condition stateUpdate = stateLock.newCondition();\n    final Map<KafkaStreams, State> stateMap = new HashMap<>();\n    for (final KafkaStreams streams : streamsList) {\n        stateMap.put(streams, streams.state());\n        final StateListener prevStateListener = getStateListener(streams);\n        final StateListener newStateListener = (newState, oldState) -> {\n            stateLock.lock();\n            try {\n                stateMap.put(streams, newState);\n                if (newState == State.RUNNING) {\n                    if (stateMap.values().stream().allMatch(state -> state == State.RUNNING)) {\n                        stateUpdate.signalAll();\n                    }\n                }\n            } finally {\n                stateLock.unlock();\n            }\n        };\n\n        streams.setStateListener(prevStateListener != null\n            ? new CompositeStateListener(prevStateListener, newStateListener)\n            : newStateListener);\n    }\n\n    for (final KafkaStreams streams : streamsList) {\n        streams.start();\n    }\n\n    final long expectedEnd = System.currentTimeMillis() + timeout.toMillis();\n    stateLock.lock();\n    try {\n            \n            \n        while (true) {\n            final Map<KafkaStreams, State> nonRunningStreams = new HashMap<>();\n            for (final Entry<KafkaStreams, State> entry : stateMap.entrySet()) {\n                if (entry.getValue() != State.RUNNING) {\n                    nonRunningStreams.put(entry.getKey(), entry.getValue());\n                }\n            }\n\n            if (nonRunningStreams.isEmpty()) {\n                return;\n            }\n\n            final long millisRemaining = expectedEnd - System.currentTimeMillis();\n            if (millisRemaining <= 0) {\n                fail(\n                    \"Application did not reach a RUNNING state for all streams instances. \" +\n                        \"Non-running instances: \" + nonRunningStreams\n                );\n            }\n\n            stateUpdate.await(millisRemaining, TimeUnit.MILLISECONDS);\n        }\n    } finally {\n        stateLock.unlock();\n    }\n}", "summary_tokens": ["starts", "the", "given", "kafka", "streams", "instances", "and", "waits", "for", "all", "of", "them", "to", "reach", "the", "state", "running", "state", "at", "the", "same", "time"], "project": "kafka"}
{"id": 2427, "code": "private static boolean isGlobSpecialCharacter(char ch) {\n    switch (ch) {\n        case '*':\n        case '?':\n        case '\\\\':\n        case '{':\n        case '}':\n            return true;\n        default:\n            break;\n    }\n    return false;\n}", "summary_tokens": ["returns", "true", "if", "the", "character", "is", "a", "special", "character", "for", "globs"], "project": "kafka"}
{"id": 2140, "code": "public void assertTopicsDoNotExist(String... topicNames) throws InterruptedException {\n    Set<String> topicNameSet = new HashSet<>(Arrays.asList(topicNames));\n    AtomicReference<Set<String>> existingTopics = new AtomicReference<>(topicNameSet);\n    waitForCondition(\n        () -> checkTopicsExist(topicNameSet, (actual, expected) -> {\n            existingTopics.set(actual);\n            return actual.isEmpty();\n        }).orElse(false),\n        CONNECTOR_SETUP_DURATION_MS,\n        \"Unexpectedly found topics \" + existingTopics.get());\n}", "summary_tokens": ["assert", "that", "the", "topics", "with", "the", "specified", "names", "do", "not", "exist"], "project": "kafka"}
{"id": 432, "code": "RequestFuture<ByteBuffer> sendJoinGroupRequest() {\n    if (coordinatorUnknown())\n        return RequestFuture.coordinatorNotAvailable();\n\n        \n    log.info(\"(Re-)joining group\");\n    JoinGroupRequest.Builder requestBuilder = new JoinGroupRequest.Builder(\n            new JoinGroupRequestData()\n                    .setGroupId(rebalanceConfig.groupId)\n                    .setSessionTimeoutMs(this.rebalanceConfig.sessionTimeoutMs)\n                    .setMemberId(this.generation.memberId)\n                    .setGroupInstanceId(this.rebalanceConfig.groupInstanceId.orElse(null))\n                    .setProtocolType(protocolType())\n                    .setProtocols(metadata())\n                    .setRebalanceTimeoutMs(this.rebalanceConfig.rebalanceTimeoutMs)\n                    .setReason(JoinGroupRequest.maybeTruncateReason(this.rejoinReason))\n    );\n\n    log.debug(\"Sending JoinGroup ({}) to coordinator {}\", requestBuilder, this.coordinator);\n\n        \n        \n    int joinGroupTimeoutMs = Math.max(\n        client.defaultRequestTimeoutMs(),\n        Math.max(\n            rebalanceConfig.rebalanceTimeoutMs + JOIN_GROUP_TIMEOUT_LAPSE,\n            rebalanceConfig.rebalanceTimeoutMs) \n        );\n    return client.send(coordinator, requestBuilder, joinGroupTimeoutMs)\n            .compose(new JoinGroupResponseHandler(generation));\n}", "summary_tokens": ["join", "the", "group", "and", "return", "the", "assignment", "for", "the", "next", "generation"], "project": "kafka"}
{"id": 1201, "code": "public OAuthBearerToken validate(String accessToken) throws ValidateException {\n    SerializedJwt serializedJwt = new SerializedJwt(accessToken);\n\n    JwtContext jwt;\n\n    try {\n        jwt = jwtConsumer.process(serializedJwt.getToken());\n    } catch (InvalidJwtException e) {\n        throw new ValidateException(String.format(\"Could not validate the access token: %s\", e.getMessage()), e);\n    }\n\n    JwtClaims claims = jwt.getJwtClaims();\n\n    Object scopeRaw = getClaim(() -> claims.getClaimValue(scopeClaimName), scopeClaimName);\n    Collection<String> scopeRawCollection;\n\n    if (scopeRaw instanceof String)\n        scopeRawCollection = Collections.singletonList((String) scopeRaw);\n    else if (scopeRaw instanceof Collection)\n        scopeRawCollection = (Collection<String>) scopeRaw;\n    else\n        scopeRawCollection = Collections.emptySet();\n\n    NumericDate expirationRaw = getClaim(claims::getExpirationTime, ReservedClaimNames.EXPIRATION_TIME);\n    String subRaw = getClaim(() -> claims.getStringClaimValue(subClaimName), subClaimName);\n    NumericDate issuedAtRaw = getClaim(claims::getIssuedAt, ReservedClaimNames.ISSUED_AT);\n\n    Set<String> scopes = ClaimValidationUtils.validateScopes(scopeClaimName, scopeRawCollection);\n    long expiration = ClaimValidationUtils.validateExpiration(ReservedClaimNames.EXPIRATION_TIME,\n        expirationRaw != null ? expirationRaw.getValueInMillis() : null);\n    String sub = ClaimValidationUtils.validateSubject(subClaimName, subRaw);\n    Long issuedAt = ClaimValidationUtils.validateIssuedAt(ReservedClaimNames.ISSUED_AT,\n        issuedAtRaw != null ? issuedAtRaw.getValueInMillis() : null);\n\n    OAuthBearerToken token = new BasicOAuthBearerToken(accessToken,\n        scopes,\n        expiration,\n        sub,\n        issuedAt);\n\n    return token;\n}", "summary_tokens": ["accepts", "an", "oauth", "jwt", "access", "token", "in", "base", "0", "encoded", "format", "validates", "and", "returns", "an", "oauth", "bearer", "token"], "project": "kafka"}
{"id": 861, "code": "private void delayCloseOnAuthenticationFailure() {\n    transportLayer.removeInterestOps(SelectionKey.OP_WRITE);\n}", "summary_tokens": ["delay", "channel", "close", "on", "authentication", "failure"], "project": "kafka"}
{"id": 2813, "code": "public void addRecords(final TopicPartition partition, final Iterable<ConsumerRecord<byte[], byte[]>> records) {\n    final int newQueueSize = partitionGroup.addRawRecords(partition, records);\n\n    if (log.isTraceEnabled()) {\n        log.trace(\"Added records into the buffered queue of partition {}, new queue size is {}\", partition, newQueueSize);\n    }\n\n        \n        \n    if (newQueueSize > maxBufferedSize) {\n        mainConsumer.pause(singleton(partition));\n    }\n}", "summary_tokens": ["adds", "records", "to", "queues"], "project": "kafka"}
{"id": 1107, "code": "static String replaceSubstitution(String base, Pattern from, String to,\n                                  boolean repeat) {\n    Matcher match = from.matcher(base);\n    if (repeat) {\n        return match.replaceAll(to);\n    } else {\n        return match.replaceFirst(to);\n    }\n}", "summary_tokens": ["replace", "the", "matches", "of", "the", "from", "pattern", "in", "the", "base", "string", "with", "the", "value", "of", "the", "to", "string"], "project": "kafka"}
{"id": 1195, "code": "private void refresh() {\n    if (!refreshInProgressFlag.compareAndSet(false, true)) {\n        log.debug(\"OAuth JWKS refresh is already in progress; ignoring concurrent refresh\");\n        return;\n    }\n\n    try {\n        log.info(\"OAuth JWKS refresh of {} starting\", httpsJwks.getLocation());\n        Retry<List<JsonWebKey>> retry = new Retry<>(refreshRetryBackoffMs, refreshRetryBackoffMaxMs);\n        List<JsonWebKey> localJWKs = retry.execute(() -> {\n            try {\n                log.debug(\"JWKS validation key calling refresh of {} starting\", httpsJwks.getLocation());\n                    \n                    \n                httpsJwks.refresh();\n                List<JsonWebKey> jwks = httpsJwks.getJsonWebKeys();\n                log.debug(\"JWKS validation key refresh of {} complete\", httpsJwks.getLocation());\n                return jwks;\n            } catch (Exception e) {\n                throw new ExecutionException(e);\n            }\n        });\n\n        try {\n            refreshLock.writeLock().lock();\n\n            for (JsonWebKey jwk : localJWKs)\n                missingKeyIds.remove(jwk.getKeyId());\n\n            jsonWebKeys = Collections.unmodifiableList(localJWKs);\n        } finally {\n            refreshLock.writeLock().unlock();\n        }\n\n        log.info(\"OAuth JWKS refresh of {} complete\", httpsJwks.getLocation());\n    } catch (ExecutionException e) {\n        log.warn(\"OAuth JWKS refresh of {} encountered an error; not updating local JWKS cache\", httpsJwks.getLocation(), e);\n    } finally {\n        refreshInProgressFlag.set(false);\n    }\n}", "summary_tokens": ["p", "code", "refresh", "code", "is", "an", "internal", "method", "that", "will", "refresh", "the", "jwks", "cache", "and", "is", "invoked", "in", "one", "of", "two", "ways"], "project": "kafka"}
{"id": 1532, "code": "public void oldSaslPlainPlaintextServerWithoutSaslAuthenticateHeaderFailure() throws Exception {\n    verifySaslAuthenticateHeaderInteropWithFailure(false, true, SecurityProtocol.SASL_PLAINTEXT, \"PLAIN\");\n}", "summary_tokens": ["tests", "sasl", "plain", "authentication", "failure", "over", "plaintext", "with", "old", "version", "of", "server", "that", "does", "not", "support", "sasl", "authenticate", "headers", "and", "new", "version", "of", "client"], "project": "kafka"}
{"id": 2019, "code": "public StartAndStopCounter startAndStopCounter() {\n    return startAndStopCounter;\n}", "summary_tokens": ["gets", "the", "start", "and", "stop", "counter", "corresponding", "to", "this", "handle"], "project": "kafka"}
{"id": 849, "code": "default void handleAuthenticationFailure() throws IOException {\n}", "summary_tokens": ["perform", "any", "processing", "related", "to", "authentication", "failure"], "project": "kafka"}
{"id": 3173, "code": "public <K, V> WindowStore<K, V> getWindowStore(final String name) {\n    final StateStore store = getStateStore(name, false);\n    if (store instanceof TimestampedWindowStore) {\n        log.info(\"Method #getTimestampedWindowStore() should be used to access a TimestampedWindowStore.\");\n        return new WindowStoreFacade<>((TimestampedWindowStore<K, V>) store);\n    }\n    return store instanceof WindowStore ? (WindowStore<K, V>) store : null;\n}", "summary_tokens": ["get", "the", "window", "store", "or", "timestamped", "window", "store", "with", "the", "given", "name"], "project": "kafka"}
{"id": 314, "code": "public String consumerId() {\n    return memberId;\n}", "summary_tokens": ["the", "consumer", "id", "of", "the", "group", "member"], "project": "kafka"}
{"id": 520, "code": "public synchronized boolean assignFromUser(Set<TopicPartition> partitions) {\n    setSubscriptionType(SubscriptionType.USER_ASSIGNED);\n\n    if (this.assignment.partitionSet().equals(partitions))\n        return false;\n\n    assignmentId++;\n\n        \n    Set<String> manualSubscribedTopics = new HashSet<>();\n    Map<TopicPartition, TopicPartitionState> partitionToState = new HashMap<>();\n    for (TopicPartition partition : partitions) {\n        TopicPartitionState state = assignment.stateValue(partition);\n        if (state == null)\n            state = new TopicPartitionState();\n        partitionToState.put(partition, state);\n\n        manualSubscribedTopics.add(partition.topic());\n    }\n\n    this.assignment.set(partitionToState);\n    return changeSubscription(manualSubscribedTopics);\n}", "summary_tokens": ["change", "the", "assignment", "to", "the", "specified", "partitions", "provided", "by", "the", "user", "note", "this", "is", "different", "from", "assign", "from", "subscribed", "collection", "whose", "input", "partitions", "are", "provided", "from", "the", "subscribed", "topics"], "project": "kafka"}
{"id": 212, "code": "public Map<String, KafkaFuture<Void>> deletedGroups() {\n    Map<String, KafkaFuture<Void>> deletedGroups = new HashMap<>(futures.size());\n    futures.forEach((key, future) -> deletedGroups.put(key, future));\n    return deletedGroups;\n}", "summary_tokens": ["return", "a", "map", "from", "group", "id", "to", "futures", "which", "can", "be", "used", "to", "check", "the", "status", "of", "individual", "deletions"], "project": "kafka"}
{"id": 2404, "code": "public static void markForDelete(Path logDir, OffsetAndEpoch snapshotId) {\n    Path immutablePath = snapshotPath(logDir, snapshotId);\n    Path deletedPath = deleteRename(immutablePath, snapshotId);\n    try {\n        Utils.atomicMoveWithFallback(immutablePath, deletedPath, false);\n    } catch (IOException e) {\n        throw new UncheckedIOException(\n            String.format(\n                \"Error renaming snapshot file from %s to %s.\",\n                immutablePath,\n                deletedPath\n            ),\n            e\n        );\n    }\n}", "summary_tokens": ["mark", "a", "snapshot", "for", "deletion", "by", "renaming", "with", "the", "deleted", "suffix"], "project": "kafka"}
{"id": 1774, "code": "public long discoverTimestamp() {\n    return discoverTimestamp;\n}", "summary_tokens": ["get", "a", "timestamp", "that", "represents", "when", "this", "topic", "was", "discovered", "as", "being", "actively", "used", "by", "this", "connector"], "project": "kafka"}
{"id": 1401, "code": "protected void connect(String node, InetSocketAddress serverAddr) throws IOException {\n    blockingConnect(node, serverAddr);\n}", "summary_tokens": ["connects", "and", "waits", "for", "handshake", "to", "complete"], "project": "kafka"}
{"id": 3116, "code": "public void shouldNotThrowIllegalStateExceptionWhenMultiCacheEvictions() {\n    final String agg = \"agg\";\n    final String tableOne = \"tableOne\";\n    final String tableTwo = \"tableTwo\";\n    final String tableThree = \"tableThree\";\n    final String tableFour = \"tableFour\";\n    final String tableFive = \"tableFive\";\n    final String tableSix = \"tableSix\";\n    final String[] inputs = {agg, tableOne, tableTwo, tableThree, tableFour, tableFive, tableSix};\n\n    final StreamsBuilder builder = new StreamsBuilder();\n    final Consumed<Long, String> consumed = Consumed.with(Serdes.Long(), Serdes.String());\n    final KTable<Long, String> aggTable = builder\n        .table(agg, consumed, Materialized.as(Stores.inMemoryKeyValueStore(\"agg-base-store\")))\n        .groupBy(KeyValue::new, Grouped.with(Serdes.Long(), Serdes.String()))\n        .reduce(\n            MockReducer.STRING_ADDER,\n            MockReducer.STRING_ADDER,\n            Materialized.as(Stores.inMemoryKeyValueStore(\"agg-store\")));\n\n    final KTable<Long, String> one = builder.table(\n        tableOne,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableOne-base-store\")));\n    final KTable<Long, String> two = builder.table(\n        tableTwo,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableTwo-base-store\")));\n    final KTable<Long, String> three = builder.table(\n        tableThree,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableThree-base-store\")));\n    final KTable<Long, String> four = builder.table(\n        tableFour,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableFour-base-store\")));\n    final KTable<Long, String> five = builder.table(\n        tableFive,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableFive-base-store\")));\n    final KTable<Long, String> six = builder.table(\n        tableSix,\n        consumed,\n        Materialized.as(Stores.inMemoryKeyValueStore(\"tableSix-base-store\")));\n\n    final ValueMapper<String, String> mapper = value -> value.toUpperCase(Locale.ROOT);\n\n    final KTable<Long, String> seven = one.mapValues(mapper);\n\n    final KTable<Long, String> eight = six.leftJoin(seven, MockValueJoiner.TOSTRING_JOINER);\n\n    aggTable\n        .leftJoin(one, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(two, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(three, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(four, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(five, MockValueJoiner.TOSTRING_JOINER)\n        .leftJoin(eight, MockValueJoiner.TOSTRING_JOINER)\n        .mapValues(mapper);\n\n    try (final TopologyTestDriver driver = new TopologyTestDriver(builder.build(), props)) {\n        final String[] values = {\n            \"a\", \"AA\", \"BBB\", \"CCCC\", \"DD\", \"EEEEEEEE\", \"F\", \"GGGGGGGGGGGGGGG\", \"HHH\", \"IIIIIIIIII\",\n            \"J\", \"KK\", \"LLLL\", \"MMMMMMMMMMMMMMMMMMMMMM\", \"NNNNN\", \"O\", \"P\", \"QQQQQ\", \"R\", \"SSSS\",\n            \"T\", \"UU\", \"VVVVVVVVVVVVVVVVVVV\"\n        };\n\n        TestInputTopic<Long, String> inputTopic;\n        final Random random = new Random();\n        for (int i = 0; i < 1000; i++) {\n            for (final String input : inputs) {\n                final Long key = (long) random.nextInt(1000);\n                final String value = values[random.nextInt(values.length)];\n                inputTopic = driver.createInputTopic(input, Serdes.Long().serializer(), Serdes.String().serializer());\n                inputTopic.pipeInput(key, value);\n            }\n        }\n    }\n}", "summary_tokens": ["this", "test", "was", "written", "to", "reproduce", "https", "issues"], "project": "kafka"}
{"id": 1086, "code": "public final boolean equals(Object o) {\n    return super.equals(o);\n}", "summary_tokens": ["implements", "equals", "using", "the", "reference", "comparison", "implementation", "from", "object", "equals", "object"], "project": "kafka"}
{"id": 189, "code": "public KafkaFuture<Void> all() {\n    return KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]));\n}", "summary_tokens": ["return", "a", "future", "which", "succeeds", "only", "if", "all", "the", "acl", "creations", "succeed"], "project": "kafka"}
{"id": 2248, "code": "void handleBrokerFenced(int brokerId, List<ApiMessageAndVersion> records) {\n    BrokerRegistration brokerRegistration = clusterControl.brokerRegistrations().get(brokerId);\n    if (brokerRegistration == null) {\n        throw new RuntimeException(\"Can't find broker registration for broker \" + brokerId);\n    }\n    generateLeaderAndIsrUpdates(\"handleBrokerFenced\", brokerId, NO_LEADER, records,\n        brokersToIsrs.partitionsWithBrokerInIsr(brokerId));\n    if (featureControl.metadataVersion().isBrokerRegistrationChangeRecordSupported()) {\n        records.add(new ApiMessageAndVersion(new BrokerRegistrationChangeRecord().\n                setBrokerId(brokerId).setBrokerEpoch(brokerRegistration.epoch()).\n                setFenced(BrokerRegistrationFencingChange.FENCE.value()),\n                (short) 0));\n    } else {\n        records.add(new ApiMessageAndVersion(new FenceBrokerRecord().\n                setId(brokerId).setEpoch(brokerRegistration.epoch()),\n                (short) 0));\n    }\n}", "summary_tokens": ["generate", "the", "appropriate", "records", "to", "handle", "a", "broker", "being", "fenced"], "project": "kafka"}
{"id": 857, "code": "static Map<String, Object> channelBuilderConfigs(final AbstractConfig config, final ListenerName listenerName) {\n    Map<String, Object> parsedConfigs;\n    if (listenerName == null)\n        parsedConfigs = (Map<String, Object>) config.values();\n    else\n        parsedConfigs = config.valuesWithPrefixOverride(listenerName.configPrefix());\n\n    config.originals().entrySet().stream()\n        .filter(e -> !parsedConfigs.containsKey(e.getKey())) \n            \n        .filter(e -> !(listenerName != null && e.getKey().startsWith(listenerName.configPrefix()) &&\n            parsedConfigs.containsKey(e.getKey().substring(listenerName.configPrefix().length()))))\n            \n        .filter(e -> !(listenerName != null && parsedConfigs.containsKey(e.getKey().substring(e.getKey().indexOf('.') + 1))))\n        .forEach(e -> parsedConfigs.put(e.getKey(), e.getValue()));\n    return parsedConfigs;\n}", "summary_tokens": ["a", "mutable", "recording", "map"], "project": "kafka"}
{"id": 1280, "code": "int findElementToRemove(Object key) {\n    if (key == null || size() == 0) {\n        return INVALID_INDEX;\n    }\n    int slot = slot(elements, key);\n    int bestSlot = INVALID_INDEX;\n    for (int seen = 0; seen < elements.length; seen++) {\n        Element element = elements[slot];\n        if (element == null) {\n            return bestSlot;\n        }\n        if (key == element) {\n            return slot;\n        } else if (element.elementKeysAreEqual(key)) {\n            bestSlot = slot;\n        }\n        slot = (slot + 1) % elements.length;\n    }\n    return INVALID_INDEX;\n}", "summary_tokens": ["find", "an", "element", "matching", "an", "example", "element"], "project": "kafka"}
{"id": 1527, "code": "public void oldSaslScramPlaintextClientWithoutSaslAuthenticateHeader() throws Exception {\n    verifySaslAuthenticateHeaderInterop(true, false, SecurityProtocol.SASL_PLAINTEXT, \"SCRAM-SHA-256\");\n}", "summary_tokens": ["tests", "good", "path", "sasl", "scram", "authentication", "over", "plaintext", "with", "old", "version", "of", "client", "that", "does", "not", "support", "sasl", "authenticate", "headers", "and", "new", "version", "of", "server"], "project": "kafka"}
{"id": 3216, "code": "boolean exec(TaskSpec spec, PrintStream out) throws Exception {\n    TaskController controller = null;\n    try {\n        controller = spec.newController(EXEC_TASK_ID);\n    } catch (Exception e) {\n        out.println(\"Unable to create the task controller.\");\n        e.printStackTrace(out);\n        return false;\n    }\n    Set<String> nodes = controller.targetNodes(platform.topology());\n    if (!nodes.contains(platform.curNode().name())) {\n        out.println(\"This task is not configured to run on this node.  It runs on node(s): \" +\n            Utils.join(nodes, \", \") + \", whereas this node is \" +\n            platform.curNode().name());\n        return false;\n    }\n    KafkaFuture<String> future = null;\n    try {\n        future = workerManager.createWorker(EXEC_WORKER_ID, EXEC_TASK_ID, spec);\n    } catch (Throwable e) {\n        out.println(\"createWorker failed\");\n        e.printStackTrace(out);\n        return false;\n    }\n    out.println(\"Waiting for completion of task:\" + JsonUtil.toPrettyJsonString(spec));\n    String error = future.get();\n    if (error == null || error.isEmpty()) {\n        out.println(\"Task succeeded with status \" +\n            JsonUtil.toPrettyJsonString(workerManager.workerStates().get(EXEC_WORKER_ID).status()));\n        return true;\n    } else {\n        out.println(\"Task failed with status \" +\n            JsonUtil.toPrettyJsonString(workerManager.workerStates().get(EXEC_WORKER_ID).status()) +\n            \" and error \" + error);\n        return false;\n    }\n}", "summary_tokens": ["start", "a", "task", "on", "the", "agent", "and", "block", "until", "it", "completes"], "project": "kafka"}
{"id": 1911, "code": "private static Map<String, String> convertHttpFieldsToMap(HttpFields httpFields) {\n    Map<String, String> headers = new HashMap<>();\n\n    if (httpFields == null || httpFields.size() == 0)\n        return headers;\n\n    for (HttpField field : httpFields) {\n        headers.put(field.getName(), field.getValue());\n    }\n\n    return headers;\n}", "summary_tokens": ["convert", "response", "parameters", "from", "jetty", "format", "http", "fields", "http", "fields"], "project": "kafka"}
{"id": 2170, "code": "public void requestTimeout(long requestTimeoutMs) {\n    worker.rest().requestTimeout(requestTimeoutMs);\n}", "summary_tokens": ["set", "a", "new", "timeout", "for", "rest", "requests", "to", "the", "worker"], "project": "kafka"}
{"id": 1990, "code": "protected TopicAdmin createAdmin(TopicAdmin existing) {\n    if (closed.get()) {\n        throw new ConnectException(\"The \" + this + \" has already been closed and cannot be used.\");\n    }\n    if (existing != null) {\n        return existing;\n    }\n    return factory.apply(adminProps);\n}", "summary_tokens": ["method", "used", "to", "create", "a", "topic", "admin", "instance"], "project": "kafka"}
{"id": 649, "code": "private String formatErrMsg(ProduceResponse.PartitionResponse response) {\n    String errorMessageSuffix = (response.errorMessage == null || response.errorMessage.isEmpty()) ?\n            \"\" : String.format(\". Error Message: %s\", response.errorMessage);\n    return String.format(\"%s%s\", response.error, errorMessageSuffix);\n}", "summary_tokens": ["format", "the", "error", "from", "a", "produce", "response"], "project": "kafka"}
{"id": 2709, "code": "public FixedKeyRecord<K, V> withHeaders(final Headers headers) {\n    return new FixedKeyRecord<>(key, value, timestamp, headers);\n}", "summary_tokens": ["a", "convenient", "way", "to", "produce", "a", "new", "record", "if", "you", "only", "need", "to", "change", "the", "headers"], "project": "kafka"}
{"id": 2911, "code": "public RemoveNamedTopologyResult removeNamedTopology(final String topologyToRemove) {\n    return removeNamedTopology(topologyToRemove, false);\n}", "summary_tokens": ["remove", "an", "existing", "named", "topology", "from", "a", "running", "kafka", "streams", "app"], "project": "kafka"}
{"id": 2890, "code": "public Map<String, String> getProperties(final Map<String, String> defaultProperties, final long additionalRetentionMs) {\n        \n    final Map<String, String> topicConfig = new HashMap<>(UNWINDOWED_STORE_CHANGELOG_TOPIC_DEFAULT_OVERRIDES);\n\n    topicConfig.putAll(defaultProperties);\n\n    topicConfig.putAll(topicConfigs);\n\n    return topicConfig;\n}", "summary_tokens": ["get", "the", "configured", "properties", "for", "this", "topic"], "project": "kafka"}
{"id": 1568, "code": "public static String randomString(final int len) {\n    final StringBuilder b = new StringBuilder();\n    for (int i = 0; i < len; i++)\n        b.append(LETTERS_AND_DIGITS.charAt(SEEDED_RANDOM.nextInt(LETTERS_AND_DIGITS.length())));\n    return b.toString();\n}", "summary_tokens": ["generate", "a", "random", "string", "of", "letters", "and", "digits", "of", "the", "given", "length"], "project": "kafka"}
{"id": 461, "code": "public ConsumerGroupMetadata groupMetadata() {\n    return groupMetadata;\n}", "summary_tokens": ["return", "the", "consumer", "group", "metadata"], "project": "kafka"}
{"id": 1662, "code": "public Map<Integer, TaskState> tasksState() {\n    return tasks;\n}", "summary_tokens": ["provides", "the", "current", "state", "of", "the", "connector", "tasks"], "project": "kafka"}
{"id": 1049, "code": "public FetchMetadata nextIncremental() {\n    return new FetchMetadata(sessionId, nextEpoch(epoch));\n}", "summary_tokens": ["return", "the", "metadata", "for", "the", "next", "incremental", "response"], "project": "kafka"}
{"id": 755, "code": "public ConfigDef define(String name, Type type, Importance importance, String documentation) {\n    return define(name, type, NO_DEFAULT_VALUE, null, importance, documentation);\n}", "summary_tokens": ["define", "a", "new", "configuration", "with", "no", "default", "value", "and", "no", "special", "validation", "logic", "name", "the", "name", "of", "the", "config", "parameter", "type", "the", "type", "of", "the", "config", "importance", "the", "importance", "of", "this", "config", "is", "this", "something", "you", "will", "likely", "need", "to", "change"], "project": "kafka"}
{"id": 750, "code": "public <T> List<T> getConfiguredInstances(List<String> classNames, Class<T> t, Map<String, Object> configOverrides) {\n    List<T> objects = new ArrayList<>();\n    if (classNames == null)\n        return objects;\n    Map<String, Object> configPairs = originals();\n    configPairs.putAll(configOverrides);\n    for (Object klass : classNames) {\n        Object o = getConfiguredInstance(klass, t, configPairs);\n        objects.add(t.cast(o));\n    }\n    return objects;\n}", "summary_tokens": ["get", "a", "list", "of", "configured", "instances", "of", "the", "given", "class", "specified", "by", "the", "given", "configuration", "key"], "project": "kafka"}
{"id": 968, "code": "public FileRecords slice(int position, int size) throws IOException {\n    int availableBytes = availableBytes(position, size);\n    int startPosition = this.start + position;\n    return new FileRecords(file, channel, startPosition, startPosition + availableBytes, true);\n}", "summary_tokens": ["return", "a", "slice", "of", "records", "from", "this", "instance", "which", "is", "a", "view", "into", "this", "set", "starting", "from", "the", "given", "position", "and", "with", "the", "given", "size", "limit"], "project": "kafka"}
{"id": 2952, "code": "public static InStore inStore(final String name) {\n    return new InStore(name);\n}", "summary_tokens": ["specifies", "the", "name", "of", "the", "store", "to", "query"], "project": "kafka"}
{"id": 1123, "code": "public String tokenValue() {\n    return tokenValue;\n}", "summary_tokens": ["return", "the", "always", "non", "null", "token", "value"], "project": "kafka"}
{"id": 2542, "code": "public synchronized Topology addSource(final AutoOffsetReset offsetReset,\n                                       final String name,\n                                       final TimestampExtractor timestampExtractor,\n                                       final Deserializer<?> keyDeserializer,\n                                       final Deserializer<?> valueDeserializer,\n                                       final Pattern topicPattern) {\n    internalTopologyBuilder.addSource(offsetReset, name, timestampExtractor, keyDeserializer, valueDeserializer, topicPattern);\n    return this;\n}", "summary_tokens": ["add", "a", "new", "source", "that", "consumes", "from", "topics", "matching", "the", "given", "pattern", "and", "forwards", "the", "records", "to", "child", "processor", "and", "or", "sink", "nodes"], "project": "kafka"}
{"id": 2730, "code": "public void setQuoteStrings(boolean quoteStrings) {\n    this.quoteStrings = quoteStrings;\n}", "summary_tokens": ["configures", "whether", "the", "output", "format", "should", "quote", "string", "values"], "project": "flink"}
{"id": 880, "code": "private static Authentication createAuthentication(Configuration configuration) {\n    if (configuration.contains(PULSAR_AUTH_PLUGIN_CLASS_NAME)) {\n        String authPluginClassName = configuration.get(PULSAR_AUTH_PLUGIN_CLASS_NAME);\n\n        if (configuration.contains(PULSAR_AUTH_PARAMS)) {\n            String authParamsString = configuration.get(PULSAR_AUTH_PARAMS);\n            return sneakyClient(\n                    () -> AuthenticationFactory.create(authPluginClassName, authParamsString));\n        } else if (configuration.contains(PULSAR_AUTH_PARAM_MAP)) {\n            Map<String, String> paramsMap = configuration.get(PULSAR_AUTH_PARAM_MAP);\n            return sneakyClient(\n                    () -> AuthenticationFactory.create(authPluginClassName, paramsMap));\n        } else {\n            throw new IllegalArgumentException(\n                    String.format(\n                            \"No %s or %s provided\",\n                            PULSAR_AUTH_PARAMS.key(), PULSAR_AUTH_PARAM_MAP.key()));\n        }\n    }\n\n    return AuthenticationDisabled.INSTANCE;\n}", "summary_tokens": ["create", "the", "authentication", "instance", "for", "both", "pulsar", "client", "and", "pulsar", "admin"], "project": "flink"}
{"id": 693, "code": "public void runOneSourceMultiplePartitionsExactlyOnceTest() throws Exception {\n    final String topic = \"oneToManyTopic\";\n    final int numPartitions = 5;\n    final int numElementsPerPartition = 1000;\n    final int totalElements = numPartitions * numElementsPerPartition;\n    final int failAfterElements = numElementsPerPartition / 3;\n\n    final int parallelism = 2;\n\n    createTestTopic(topic, numPartitions, 1);\n\n    DataGenerators.generateRandomizedIntegerSequence(\n            StreamExecutionEnvironment.getExecutionEnvironment(),\n            kafkaServer,\n            topic,\n            numPartitions,\n            numElementsPerPartition,\n            true);\n\n        \n\n    DeserializationSchema<Integer> schema =\n            new TypeInformationSerializationSchema<>(\n                    BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.enableCheckpointing(500);\n    env.setParallelism(parallelism);\n    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\n    Properties props = new Properties();\n    props.putAll(standardProps);\n    props.putAll(secureProps);\n\n    getStream(env, topic, schema, props)\n            .map(new PartitionValidatingMapper(numPartitions, 3))\n            .map(new FailingIdentityMapper<Integer>(failAfterElements))\n            .addSink(new ValidatingExactlyOnceSink(totalElements))\n            .setParallelism(1);\n\n    FailingIdentityMapper.failedBefore = false;\n    tryExecute(env, \"One-source-multi-partitions exactly once test\");\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["tests", "the", "proper", "consumption", "when", "having", "fewer", "flink", "sources", "than", "kafka", "partitions", "so", "one", "flink", "source", "will", "read", "multiple", "kafka", "partitions"], "project": "flink"}
{"id": 3764, "code": "public void checkJoinWithReplicatedSourceInputBehindFlatMap() {\n\n    ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    TupleTypeInfo<Tuple1<String>> typeInfo = TupleTypeInfo.getBasicTupleTypeInfo(String.class);\n    ReplicatingInputFormat<Tuple1<String>, FileInputSplit> rif =\n            new ReplicatingInputFormat<Tuple1<String>, FileInputSplit>(\n                    new TupleCsvInputFormat<Tuple1<String>>(new Path(\"/some/path\"), typeInfo));\n\n    DataSet<Tuple1<String>> source1 =\n            env.createInput(\n                    rif, new TupleTypeInfo<Tuple1<String>>(BasicTypeInfo.STRING_TYPE_INFO));\n    DataSet<Tuple1<String>> source2 = env.readCsvFile(\"/some/otherpath\").types(String.class);\n\n    DataSink<Tuple2<Tuple1<String>, Tuple1<String>>> out =\n            source1.flatMap(new IdFlatMap())\n                    .join(source2)\n                    .where(\"*\")\n                    .equalTo(\"*\")\n                    .writeAsText(\"/some/newpath\");\n\n    Plan plan = env.createProgramPlan();\n\n        \n    OptimizedPlan oPlan = compileNoStats(plan);\n\n        \n        \n    SinkPlanNode sinkNode = oPlan.getDataSinks().iterator().next();\n    DualInputPlanNode joinNode = (DualInputPlanNode) sinkNode.getPredecessor();\n\n    ShipStrategyType joinIn1 = joinNode.getInput1().getShipStrategy();\n    ShipStrategyType joinIn2 = joinNode.getInput2().getShipStrategy();\n\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\", ShipStrategyType.FORWARD, joinIn1);\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\", ShipStrategyType.FORWARD, joinIn2);\n}", "summary_tokens": ["tests", "join", "program", "with", "replicated", "data", "source", "behind", "flat", "map"], "project": "flink"}
{"id": 9596, "code": "public void testUserSpecificParallelism() throws Exception {\n    Configuration config = new Configuration();\n    config.setString(AkkaOptions.STARTUP_TIMEOUT, VALID_STARTUP_TIMEOUT);\n\n    final URI restAddress = MINI_CLUSTER_RESOURCE.getRestAddres();\n    final String hostname = restAddress.getHost();\n    final int port = restAddress.getPort();\n\n    final ExecutionEnvironment env =\n            ExecutionEnvironment.createRemoteEnvironment(hostname, port, config);\n    env.setParallelism(USER_DOP);\n\n    DataSet<Integer> result =\n            env.createInput(new ParallelismDependentInputFormat())\n                    .rebalance()\n                    .mapPartition(\n                            new RichMapPartitionFunction<Integer, Integer>() {\n                                @Override\n                                public void mapPartition(\n                                        Iterable<Integer> values, Collector<Integer> out)\n                                        throws Exception {\n                                    out.collect(getRuntimeContext().getIndexOfThisSubtask());\n                                }\n                            });\n    List<Integer> resultCollection = result.collect();\n    assertEquals(USER_DOP, resultCollection.size());\n}", "summary_tokens": ["ensure", "that", "the", "program", "parallelism", "can", "be", "set", "even", "if", "the", "configuration", "is", "supplied"], "project": "flink"}
{"id": 4847, "code": "protected void clear() {\n    this.currentSegment = null;\n    this.positionInSegment = this.headerLength;\n}", "summary_tokens": ["clears", "the", "internal", "state"], "project": "flink"}
{"id": 2651, "code": "public <R> JoinOperatorSets<T, R> joinWithTiny(DataSet<R> other) {\n    return new JoinOperatorSets<>(this, other, JoinHint.BROADCAST_HASH_SECOND);\n}", "summary_tokens": ["initiates", "a", "join", "transformation"], "project": "flink"}
{"id": 8789, "code": "public Frame decorrelateRel(RelNode rel) {\n    RelNode newRel = rel.copy(rel.getTraitSet(), rel.getInputs());\n\n    if (rel.getInputs().size() > 0) {\n        List<RelNode> oldInputs = rel.getInputs();\n        List<RelNode> newInputs = new ArrayList<>();\n        for (int i = 0; i < oldInputs.size(); ++i) {\n            final Frame frame = getInvoke(oldInputs.get(i), rel);\n            if (frame == null || !frame.corDefOutputs.isEmpty()) {\n                    \n                    \n                return null;\n            }\n            newInputs.add(frame.r);\n            newRel.replaceInput(i, frame.r);\n        }\n\n        if (!Util.equalShallow(oldInputs, newInputs)) {\n            newRel = rel.copy(rel.getTraitSet(), newInputs);\n        }\n    }\n\n        \n        \n    return register(\n            rel,\n            newRel,\n            identityMap(rel.getRowType().getFieldCount()),\n            ImmutableSortedMap.of());\n}", "summary_tokens": ["fallback", "if", "none", "of", "the", "other", "decorrelate", "rel", "methods", "match"], "project": "flink"}
{"id": 8604, "code": "private static @Nullable Integer commonMin(List<ArgumentCount> counts) {\n        \n        \n    int commonMin = Integer.MAX_VALUE;\n    for (ArgumentCount count : counts) {\n        final Optional<Integer> min = count.getMinCount();\n        if (!min.isPresent()) {\n            return null;\n        }\n        commonMin = Math.min(commonMin, min.get());\n    }\n    if (commonMin == Integer.MAX_VALUE) {\n        return null;\n    }\n    return commonMin;\n}", "summary_tokens": ["returns", "the", "common", "minimum", "argument", "count", "or", "null", "if", "undefined"], "project": "flink"}
{"id": 7769, "code": "public void testWindowSeparationAndFiring() throws Exception {\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(\n                    CountTrigger.<TimeWindow>of(3), new TimeWindow.Serializer());\n\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n        \n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers());\n\n    assertEquals(2, testHarness.numStateEntries());\n    assertEquals(1, testHarness.numStateEntries(new TimeWindow(0, 2)));\n    assertEquals(1, testHarness.numStateEntries(new TimeWindow(2, 4)));\n\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.FIRE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n        \n        \n    assertEquals(1, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numStateEntries(new TimeWindow(0, 2)));\n    assertEquals(1, testHarness.numStateEntries(new TimeWindow(2, 4)));\n\n    assertEquals(\n            TriggerResult.FIRE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n        \n    assertEquals(0, testHarness.numStateEntries());\n}", "summary_tokens": ["verify", "that", "state", "of", "separate", "windows", "does", "not", "leak", "into", "other", "windows"], "project": "flink"}
{"id": 6348, "code": "private void runUntilMetricChanged(\n        String name, int maxRuns, CheckedSupplier<Object> objectCreator, Gauge<Long> metric)\n        throws Exception {\n    maxRuns = Math.max(1, maxRuns);\n    long initialValue = metric.getValue();\n    for (int i = 0; i < maxRuns; i++) {\n        Object object = objectCreator.get();\n        long currentValue = metric.getValue();\n        if (currentValue != initialValue) {\n            return;\n        }\n        referencedObjects.add(object);\n        Thread.sleep(50);\n    }\n    String msg =\n            String.format(\n                    \"%s usage metric never changed its value after %d runs.\", name, maxRuns);\n    Assert.fail(msg);\n}", "summary_tokens": ["caller", "may", "choose", "to", "run", "multiple", "times", "for", "possible", "interference", "with", "other", "tests"], "project": "flink"}
{"id": 3612, "code": "protected void computeOperatorSpecificDefaultEstimates(DataStatistics statistics) {\n    this.estimatedNumRecords = (long) (getPredecessorNode().getEstimatedNumRecords() * 0.5);\n    this.estimatedOutputSize = (long) (getPredecessorNode().getEstimatedOutputSize() * 0.5);\n}", "summary_tokens": ["computes", "the", "estimates", "for", "the", "filter", "operator"], "project": "flink"}
{"id": 7725, "code": "private void verifyIdsEqual(JobGraph jobGraph, Map<JobVertexID, String> ids) {\n        \n    assertEquals(jobGraph.getNumberOfVertices(), ids.size());\n\n        \n    for (JobVertex vertex : jobGraph.getVertices()) {\n        String expectedName = ids.get(vertex.getID());\n        assertNotNull(expectedName);\n        assertEquals(expectedName, vertex.getName());\n    }\n}", "summary_tokens": ["verifies", "that", "each", "job", "vertex", "id", "of", "the", "job", "graph", "is", "contained", "in", "the", "given", "map", "and", "mapped", "to", "the", "same", "vertex", "name"], "project": "flink"}
{"id": 6238, "code": "public void testConcurrentRecycleAndRelease() throws Exception {\n        \n    final int numExclusiveSegments = 120;\n    final NetworkBufferPool networkBufferPool = new NetworkBufferPool(248, 32);\n    final int numFloatingBuffers = 128;\n\n    final ExecutorService executor = Executors.newFixedThreadPool(3);\n\n    final SingleInputGate inputGate = createSingleInputGate(1, networkBufferPool);\n    final RemoteInputChannel inputChannel =\n            InputChannelTestUtils.createRemoteInputChannel(inputGate, numExclusiveSegments);\n    inputGate.setInputChannels(inputChannel);\n    Throwable thrown = null;\n    try {\n        final BufferPool bufferPool =\n                networkBufferPool.createBufferPool(numFloatingBuffers, numFloatingBuffers);\n        inputGate.setBufferPool(bufferPool);\n        inputGate.setupChannels();\n        inputChannel.requestSubpartition(0);\n\n        final Callable<Void> releaseTask =\n                new Callable<Void>() {\n                    @Override\n                    public Void call() throws Exception {\n                        inputChannel.releaseAllResources();\n\n                        return null;\n                    }\n                };\n\n            \n        submitTasksAndWaitForResults(\n                executor,\n                new Callable[] {\n                    recycleBufferTask(\n                            inputChannel, bufferPool, numExclusiveSegments, numFloatingBuffers),\n                    releaseTask\n                });\n\n        assertEquals(\n                \"There should be no buffers available in the channel.\",\n                0,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be \" + numFloatingBuffers + \" buffers available in local pool.\",\n                numFloatingBuffers,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertEquals(\n                \"There should be \"\n                        + numExclusiveSegments\n                        + \" buffers available in global pool.\",\n                numExclusiveSegments,\n                networkBufferPool.getNumberOfAvailableMemorySegments());\n    } catch (Throwable t) {\n        thrown = t;\n    } finally {\n        cleanup(networkBufferPool, executor, null, thrown, inputChannel);\n    }\n}", "summary_tokens": ["tests", "to", "verify", "that", "there", "is", "no", "race", "condition", "with", "two", "things", "running", "in", "parallel", "recycling", "the", "exclusive", "or", "floating", "buffers", "and", "some", "other", "thread", "releasing", "the", "input", "channel"], "project": "flink"}
{"id": 1190, "code": "public static void initDefaultsFromConfiguration(Configuration configuration) {\n    final boolean overwrite = configuration.getBoolean(CoreOptions.FILESYTEM_DEFAULT_OVERRIDE);\n\n    DEFAULT_WRITE_MODE = overwrite ? WriteMode.OVERWRITE : WriteMode.NO_OVERWRITE;\n\n    final boolean alwaysCreateDirectory =\n            configuration.getBoolean(CoreOptions.FILESYSTEM_OUTPUT_ALWAYS_CREATE_DIRECTORY);\n\n    DEFAULT_OUTPUT_DIRECTORY_MODE =\n            alwaysCreateDirectory ? OutputDirectoryMode.ALWAYS : OutputDirectoryMode.PARONLY;\n}", "summary_tokens": ["initialize", "defaults", "for", "output", "format"], "project": "flink"}
{"id": 355, "code": "public static Object toFlinkObject(ObjectInspector inspector, Object data, HiveShim hiveShim) {\n    if (data == null || inspector instanceof VoidObjectInspector) {\n        return null;\n    }\n\n    if (inspector instanceof PrimitiveObjectInspector) {\n        if (inspector instanceof BooleanObjectInspector\n                || inspector instanceof StringObjectInspector\n                || inspector instanceof ByteObjectInspector\n                || inspector instanceof ShortObjectInspector\n                || inspector instanceof IntObjectInspector\n                || inspector instanceof LongObjectInspector\n                || inspector instanceof FloatObjectInspector\n                || inspector instanceof DoubleObjectInspector\n                || inspector instanceof BinaryObjectInspector) {\n\n            PrimitiveObjectInspector poi = (PrimitiveObjectInspector) inspector;\n            return poi.getPrimitiveJavaObject(data);\n        } else if (inspector instanceof DateObjectInspector) {\n            PrimitiveObjectInspector poi = (PrimitiveObjectInspector) inspector;\n            return hiveShim.toFlinkDate(poi.getPrimitiveJavaObject(data));\n        } else if (inspector instanceof TimestampObjectInspector) {\n            PrimitiveObjectInspector poi = (PrimitiveObjectInspector) inspector;\n            return hiveShim.toFlinkTimestamp(poi.getPrimitiveJavaObject(data));\n        } else if (inspector instanceof HiveCharObjectInspector) {\n            HiveCharObjectInspector oi = (HiveCharObjectInspector) inspector;\n\n            return oi.getPrimitiveJavaObject(data).getValue();\n        } else if (inspector instanceof HiveVarcharObjectInspector) {\n            HiveVarcharObjectInspector oi = (HiveVarcharObjectInspector) inspector;\n\n            return oi.getPrimitiveJavaObject(data).getValue();\n        } else if (inspector instanceof HiveDecimalObjectInspector) {\n            HiveDecimalObjectInspector oi = (HiveDecimalObjectInspector) inspector;\n\n            return oi.getPrimitiveJavaObject(data).bigDecimalValue();\n        }\n    }\n\n    if (inspector instanceof ListObjectInspector) {\n        ListObjectInspector listInspector = (ListObjectInspector) inspector;\n        List<?> list = listInspector.getList(data);\n        if (list == null) {\n            return null;\n        }\n\n            \n            \n        ObjectInspector elementInspector = listInspector.getListElementObjectInspector();\n        Object[] result =\n                (Object[])\n                        Array.newInstance(\n                                HiveTypeUtil.toFlinkType(elementInspector).getConversionClass(),\n                                list.size());\n        for (int i = 0; i < list.size(); i++) {\n            result[i] = toFlinkObject(elementInspector, list.get(i), hiveShim);\n        }\n        return result;\n    }\n\n    if (inspector instanceof MapObjectInspector) {\n        MapObjectInspector mapInspector = (MapObjectInspector) inspector;\n        Map<?, ?> map = mapInspector.getMap(data);\n        if (map == null) {\n            return null;\n        }\n\n        Map<Object, Object> result = new HashMap<>(map.size());\n        for (Map.Entry<?, ?> entry : map.entrySet()) {\n            result.put(\n                    toFlinkObject(\n                            mapInspector.getMapKeyObjectInspector(), entry.getKey(), hiveShim),\n                    toFlinkObject(\n                            mapInspector.getMapValueObjectInspector(),\n                            entry.getValue(),\n                            hiveShim));\n        }\n        return result;\n    }\n\n    if (inspector instanceof StructObjectInspector) {\n        StructObjectInspector structInspector = (StructObjectInspector) inspector;\n\n        List<? extends StructField> fields = structInspector.getAllStructFieldRefs();\n\n        Row row = new Row(fields.size());\n            \n            \n        if (!data.getClass().isArray()\n                && !(data instanceof List)\n                && (inspector instanceof StandardStructObjectInspector)) {\n            data = new Object[] {data};\n        }\n        for (int i = 0; i < row.getArity(); i++) {\n            row.setField(\n                    i,\n                    toFlinkObject(\n                            fields.get(i).getFieldObjectInspector(),\n                            structInspector.getStructFieldData(data, fields.get(i)),\n                            hiveShim));\n        }\n        return row;\n    }\n\n    throw new FlinkHiveUDFException(\n            String.format(\"Unwrap does not support ObjectInspector '%s' yet\", inspector));\n}", "summary_tokens": ["converts", "a", "hive", "object", "to", "flink", "object", "with", "an", "object", "inspector"], "project": "flink"}
{"id": 7500, "code": "public void setOperatorId(String id) throws Exception {\n    this.operatorId = id;\n}", "summary_tokens": ["internally", "used", "to", "set", "the", "operator", "id", "after", "instantiation"], "project": "flink"}
{"id": 3997, "code": "public void testConcurrentActorSystemCreation() throws Exception {\n    final int concurrentCreations = 10;\n    final ExecutorService executorService = Executors.newFixedThreadPool(concurrentCreations);\n    final CyclicBarrier cyclicBarrier = new CyclicBarrier(concurrentCreations);\n\n    try {\n        final List<CompletableFuture<Void>> actorSystemFutures =\n                IntStream.range(0, concurrentCreations)\n                        .mapToObj(\n                                ignored ->\n                                        CompletableFuture.supplyAsync(\n                                                CheckedSupplier.unchecked(\n                                                        () -> {\n                                                            cyclicBarrier.await();\n\n                                                            return AkkaBootstrapTools\n                                                                    .startRemoteActorSystem(\n                                                                            new Configuration(),\n                                                                            \"localhost\",\n                                                                            \"0\",\n                                                                            LOG);\n                                                        }),\n                                                executorService))\n                        .map(\n                                    \n                                actorSystemFuture ->\n                                        actorSystemFuture.thenCompose(\n                                                AkkaUtils::terminateActorSystem))\n                        .collect(Collectors.toList());\n\n        FutureUtils.completeAll(actorSystemFutures).get();\n    } finally {\n        ExecutorUtils.gracefulShutdown(10000L, TimeUnit.MILLISECONDS, executorService);\n    }\n}", "summary_tokens": ["tests", "that", "we", "can", "concurrently", "create", "two", "actor", "system", "without", "port", "conflicts"], "project": "flink"}
{"id": 7721, "code": "public void testManualHashAssignmentCollisionThrowsException() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(4);\n    env.disableOperatorChaining();\n\n    env.addSource(new NoOpSourceFunction())\n            .uid(\"source\")\n            .map(new NoOpMapFunction())\n            .uid(\"source\") \n            .addSink(new DiscardingSink<>());\n\n        \n    env.getStreamGraph().getJobGraph();\n}", "summary_tokens": ["tests", "that", "a", "collision", "on", "the", "manual", "hash", "throws", "an", "exception"], "project": "flink"}
{"id": 5846, "code": "public void testGetFailsHaStoreForJobHa() throws IOException {\n    final JobID jobId = new JobID();\n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore())) {\n\n        server.start();\n\n            \n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n        BlobKey blobKey = put(server, jobId, data, PERMANENT_BLOB);\n        assertTrue(server.getStorageLocation(jobId, blobKey).delete());\n\n        File tempFileDir = server.createTemporaryFilename().getParentFile();\n\n            \n        exception.expect(NoSuchFileException.class);\n\n        try {\n            get(server, jobId, blobKey);\n        } finally {\n            HashSet<String> expectedDirs = new HashSet<>();\n            expectedDirs.add(\"incoming\");\n            expectedDirs.add(JOB_DIR_PREFIX + jobId);\n                \n            File storageDir = tempFileDir.getParentFile();\n            String[] actualDirs = storageDir.list();\n            assertNotNull(actualDirs);\n            assertEquals(expectedDirs, new HashSet<>(Arrays.asList(actualDirs)));\n\n                \n            File jobDir = new File(tempFileDir.getParentFile(), JOB_DIR_PREFIX + jobId);\n            assertArrayEquals(new String[] {}, jobDir.list());\n        }\n    }\n}", "summary_tokens": ["retrieves", "a", "blob", "from", "the", "ha", "store", "to", "a", "blob", "server", "whose", "ha", "store", "does", "not", "contain", "the", "file"], "project": "flink"}
{"id": 8893, "code": "private Operation convertShowCreateView(SqlShowCreateView sqlShowCreateView) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlShowCreateView.getFullViewName());\n    ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n    return new ShowCreateViewOperation(identifier);\n}", "summary_tokens": ["convert", "show", "create", "view", "statement"], "project": "flink"}
{"id": 7658, "code": "public void fixConstants() {\n    String expectedTimerStatePrefix = \"_timer_state\";\n    Assert.assertEquals(\n            expectedTimerStatePrefix, InternalTimeServiceManagerImpl.TIMER_STATE_PREFIX);\n    Assert.assertEquals(\n            expectedTimerStatePrefix + \"/processing_\",\n            InternalTimeServiceManagerImpl.PROCESSING_TIMER_PREFIX);\n    Assert.assertEquals(\n            expectedTimerStatePrefix + \"/event_\",\n            InternalTimeServiceManagerImpl.EVENT_TIMER_PREFIX);\n}", "summary_tokens": ["this", "test", "fixes", "some", "constants", "because", "changing", "them", "can", "harm", "backwards", "compatibility"], "project": "flink"}
{"id": 664, "code": "public void testDisableFilterRestoredParitionsWithRemovedTopic() throws Exception {\n    checkFilterRestoredPartitionsWithDisovered(\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            true);\n}", "summary_tokens": ["tests", "that", "removed", "partitions", "will", "not", "be", "removed", "from", "subscribed", "partitions", "even", "if", "it", "s", "still", "in", "restored", "partitions"], "project": "flink"}
{"id": 3448, "code": "public void testGroupReduceOnNeighborsInvalidEdgeTrgId() throws Exception {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(PARALLELISM);\n\n    Graph<Long, Long, Long> graph =\n            Graph.fromDataSet(\n                    TestGraphUtils.getLongLongVertexData(env),\n                    TestGraphUtils.getLongLongEdgeInvalidSrcData(env),\n                    env);\n\n    try {\n        DataSet<Tuple2<Long, Long>> verticesWithSumOfAllNeighborValues =\n                graph.reduceOnNeighbors(new SumNeighbors(), EdgeDirection.ALL);\n\n        verticesWithSumOfAllNeighborValues.output(new DiscardingOutputFormat<>());\n        env.execute();\n    } catch (Exception e) {\n            \n    }\n}", "summary_tokens": ["test", "group", "reduce", "on", "neighbors", "neighbors", "function", "with", "an", "edge", "having", "a", "trg", "id", "that", "does", "not", "exist", "in", "the", "vertex", "data", "set"], "project": "flink"}
{"id": 8711, "code": "public boolean isNull() {\n    return value == null;\n}", "summary_tokens": ["returns", "whether", "this", "literal", "s", "value", "is", "null"], "project": "flink"}
{"id": 1609, "code": "private static <T> PojoSerializerSnapshot<T> buildSnapshot(\n        Class<T> pojoType,\n        LinkedHashMap<Class<?>, Integer> registeredSubclassesToTags,\n        TypeSerializer<?>[] registeredSubclassSerializers,\n        Field[] fields,\n        TypeSerializer<?>[] fieldSerializers,\n        Map<Class<?>, TypeSerializer<?>> nonRegisteredSubclassSerializerCache) {\n\n    final LinkedHashMap<Class<?>, TypeSerializer<?>> subclassRegistry =\n            new LinkedHashMap<>(registeredSubclassesToTags.size());\n\n    for (Map.Entry<Class<?>, Integer> entry : registeredSubclassesToTags.entrySet()) {\n        subclassRegistry.put(entry.getKey(), registeredSubclassSerializers[entry.getValue()]);\n    }\n\n    return new PojoSerializerSnapshot<>(\n            pojoType,\n            fields,\n            fieldSerializers,\n            subclassRegistry,\n            nonRegisteredSubclassSerializerCache);\n}", "summary_tokens": ["build", "and", "return", "a", "snapshot", "of", "the", "serializer", "s", "parameters", "and", "currently", "cached", "serializers"], "project": "flink"}
{"id": 7241, "code": "public StreamExecutionEnvironment setDefaultSavepointDirectory(Path savepointDirectory) {\n    this.defaultSavepointDirectory = Preconditions.checkNotNull(savepointDirectory);\n    return this;\n}", "summary_tokens": ["sets", "the", "default", "savepoint", "directory", "where", "savepoints", "will", "be", "written", "to", "if", "no", "is", "explicitly", "provided", "when", "triggered"], "project": "flink"}
{"id": 9402, "code": "public static long toUtcTimestampMills(long epochMills, ZoneId shiftTimeZone) {\n        \n    if (UTC_ZONE_ID.equals(shiftTimeZone) || Long.MAX_VALUE == epochMills) {\n        return epochMills;\n    }\n    LocalDateTime localDateTime =\n            LocalDateTime.ofInstant(Instant.ofEpochMilli(epochMills), shiftTimeZone);\n    return localDateTime.atZone(UTC_ZONE_ID).toInstant().toEpochMilli();\n}", "summary_tokens": ["convert", "a", "epoch", "mills", "to", "timestamp", "mills", "which", "can", "describe", "a", "locate", "date", "time"], "project": "flink"}
{"id": 1703, "code": "public long getStart() {\n    return start;\n}", "summary_tokens": ["returns", "the", "position", "of", "the", "first", "byte", "in", "the", "file", "to", "process"], "project": "flink"}
{"id": 8195, "code": "public static DataType newListViewDataType(DataType elementDataType) {\n    return DataTypes.STRUCTURED(\n            ListView.class,\n            DataTypes.FIELD(\"list\", DataTypes.ARRAY(elementDataType).bridgedTo(List.class)));\n}", "summary_tokens": ["utility", "method", "for", "creating", "a", "data", "type", "of", "list", "view", "explicitly"], "project": "flink"}
{"id": 8876, "code": "private FunctionLanguage parseLanguage(String languageString) {\n    if (StringUtils.isNullOrWhitespaceOnly(languageString)) {\n        return FunctionLanguage.JAVA;\n    }\n\n    FunctionLanguage language;\n    try {\n        language = FunctionLanguage.valueOf(languageString);\n    } catch (IllegalArgumentException e) {\n        throw new UnsupportedOperationException(\n                String.format(\"Unrecognized function language string %s\", languageString), e);\n    }\n\n    return language;\n}", "summary_tokens": ["converts", "language", "string", "to", "the", "function", "language"], "project": "flink"}
{"id": 457, "code": "default Optional<String> defaultDriverName() {\n    return Optional.empty();\n}", "summary_tokens": ["the", "default", "driver", "class", "name", "if", "user", "has", "not", "configured", "the", "driver", "class", "name", "then", "this", "one", "will", "be", "used"], "project": "flink"}
{"id": 5471, "code": "StateMapEntry<K, N, S>[] snapshotMapArrays() {\n\n        \n        \n        \n        \n        \n    synchronized (snapshotVersions) {\n\n            \n        if (++stateMapVersion < 0) {\n                \n                \n            throw new IllegalStateException(\n                    \"Version count overflow in CopyOnWriteStateMap. Enforcing restart.\");\n        }\n\n        highestRequiredSnapshotVersion = stateMapVersion;\n        snapshotVersions.add(highestRequiredSnapshotVersion);\n    }\n\n    StateMapEntry<K, N, S>[] table = primaryTable;\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n    final int totalMapIndexSize = rehashIndex + table.length;\n    final int copiedArraySize = Math.max(totalMapIndexSize, size());\n    final StateMapEntry<K, N, S>[] copy = new StateMapEntry[copiedArraySize];\n\n    if (isRehashing()) {\n            \n            \n        final int localRehashIndex = rehashIndex;\n        final int localCopyLength = table.length - localRehashIndex;\n            \n        System.arraycopy(table, localRehashIndex, copy, 0, localCopyLength);\n\n            \n            \n        table = incrementalRehashTable;\n        System.arraycopy(table, 0, copy, localCopyLength, localRehashIndex);\n        System.arraycopy(\n                table,\n                table.length >>> 1,\n                copy,\n                localCopyLength + localRehashIndex,\n                localRehashIndex);\n    } else {\n            \n        System.arraycopy(table, 0, copy, 0, table.length);\n    }\n\n    return copy;\n}", "summary_tokens": ["creates", "combined", "copy", "of", "the", "table", "arrays", "for", "a", "snapshot"], "project": "flink"}
{"id": 6371, "code": "public void testLargeRecordsWithManyCompactions() {\n    try {\n        final int numElements = 1000;\n\n        final String longString1 = getLongString(100000), longString2 = getLongString(110000);\n        List<MemorySegment> memory = getMemory(3800, 32 * 1024);\n\n        InPlaceMutableHashTable<Tuple2<Long, String>> table =\n                new InPlaceMutableHashTable<>(serializer, comparator, memory);\n        table.open();\n\n            \n        for (long i = 0; i < numElements; i++) {\n            table.insertOrReplaceRecord(Tuple2.of(i, longString1));\n        }\n\n            \n        for (long i = 0; i < numElements; i++) {\n            table.insertOrReplaceRecord(Tuple2.of(i, longString2));\n        }\n\n            \n        InPlaceMutableHashTable<Tuple2<Long, String>>.HashTableProber<Tuple2<Long, String>>\n                prober = table.getProber(comparator, new SameTypePairComparator<>(comparator));\n        Tuple2<Long, String> reuse = new Tuple2<>();\n        for (long i = 0; i < numElements; i++) {\n            assertNotNull(prober.getMatchFor(Tuple2.of(i, longString2), reuse));\n        }\n\n        table.close();\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["the", "records", "are", "larger", "than", "one", "segment"], "project": "flink"}
{"id": 890, "code": "public static <OUT> PulsarSourceBuilder<OUT> builder() {\n    return new PulsarSourceBuilder<>();\n}", "summary_tokens": ["get", "a", "pulsar", "source", "builder", "to", "builder", "a", "pulsar", "source"], "project": "flink"}
{"id": 3531, "code": "public double getDouble(String key, double defaultValue) {\n    String argument = getProperty(key, null);\n    return argument == null ? defaultValue : Double.parseDouble(argument);\n}", "summary_tokens": ["searches", "for", "the", "property", "with", "the", "specified", "key", "in", "this", "property", "list"], "project": "flink"}
{"id": 7912, "code": "private static String sanitizeName(final String registrationName) {\n    return registrationName.substring(\n            registrationName.lastIndexOf(PARENT_GROUP_NAME) + PARENT_GROUP_NAME.length() + 1);\n}", "summary_tokens": ["removes", "all", "parts", "from", "the", "metric", "identifier", "preceding", "the", "latency", "related", "parts"], "project": "flink"}
{"id": 9602, "code": "public void testQueryWithStatsForRepartitionMerge() throws Exception {\n    Plan p = getTPCH3Plan();\n    p.setExecutionConfig(defaultExecutionConfig);\n        \n    OperatorResolver cr = getContractResolver(p);\n    DualInputOperator<?, ?, ?, ?> match = cr.getNode(JOIN_NAME);\n    match.getCompilerHints().setFilterFactor(100f);\n\n    testQueryGeneric(\n            100L * 1024 * 1024 * 1024 * 1024,\n            100L * 1024 * 1024 * 1024 * 1024,\n            0.01f,\n            100f,\n            false,\n            true,\n            false,\n            false,\n            true);\n}", "summary_tokens": ["statistics", "that", "push", "towards", "a", "repartition", "merge", "join"], "project": "flink"}
{"id": 7081, "code": "public <R> SingleOutputStreamOperator<R> transform(\n        String operatorName,\n        TypeInformation<R> outTypeInfo,\n        OneInputStreamOperatorFactory<T, R> operatorFactory) {\n\n    return doTransform(operatorName, outTypeInfo, operatorFactory);\n}", "summary_tokens": ["method", "for", "passing", "user", "defined", "operators", "created", "by", "the", "given", "factory", "along", "with", "the", "type", "information", "that", "will", "transform", "the", "data", "stream"], "project": "flink"}
{"id": 5610, "code": "public void pauseMeasurement() {\n    if (measurementStartTime != NOT_TRACKED) {\n        currentMeasurementTime += clock.absoluteTimeMillis() - measurementStartTime;\n    }\n    measurementStartTime = NOT_TRACKED;\n}", "summary_tokens": ["mark", "when", "the", "time", "should", "not", "be", "taken", "into", "account"], "project": "flink"}
{"id": 7043, "code": "public <KEY> ConnectedStreams<IN1, IN2> keyBy(\n        KeySelector<IN1, KEY> keySelector1,\n        KeySelector<IN2, KEY> keySelector2,\n        TypeInformation<KEY> keyType) {\n    return new ConnectedStreams<>(\n            environment,\n            inputStream1.keyBy(keySelector1, keyType),\n            inputStream2.keyBy(keySelector2, keyType));\n}", "summary_tokens": ["key", "by", "operation", "for", "connected", "data", "stream"], "project": "flink"}
{"id": 5439, "code": "private void pruneCheckpoints(LongPredicate pruningChecker, boolean breakOnceCheckerFalse) {\n\n    final List<Map.Entry<Long, TaskStateSnapshot>> toRemove = new ArrayList<>();\n\n    synchronized (lock) {\n        Iterator<Map.Entry<Long, TaskStateSnapshot>> entryIterator =\n                storedTaskStateByCheckpointID.entrySet().iterator();\n\n        while (entryIterator.hasNext()) {\n\n            Map.Entry<Long, TaskStateSnapshot> snapshotEntry = entryIterator.next();\n            long entryCheckpointId = snapshotEntry.getKey();\n\n            if (pruningChecker.test(entryCheckpointId)) {\n                toRemove.add(snapshotEntry);\n                entryIterator.remove();\n            } else if (breakOnceCheckerFalse) {\n                break;\n            }\n        }\n    }\n\n    asyncDiscardLocalStateForCollection(toRemove);\n}", "summary_tokens": ["pruning", "the", "useless", "checkpoints", "it", "should", "be", "called", "only", "when", "holding", "the", "lock"], "project": "flink"}
{"id": 9498, "code": "public static boolean containsCause(Throwable throwable, Class<? extends Throwable> cause) {\n    Throwable current = throwable;\n\n    while (current != null) {\n        if (cause.isAssignableFrom(current.getClass())) {\n            return true;\n        }\n\n        current = current.getCause();\n    }\n\n    return false;\n}", "summary_tokens": ["checks", "whether", "the", "given", "throwable", "contains", "the", "given", "cause", "as", "a", "cause"], "project": "flink"}
{"id": 6970, "code": "public void setPriorityQueueStateType(PriorityQueueStateType priorityQueueStateType) {\n    rocksDBStateBackend.setPriorityQueueStateType(\n            LegacyEnumBridge.convert(priorityQueueStateType));\n}", "summary_tokens": ["sets", "the", "type", "of", "the", "priority", "queue", "state"], "project": "flink"}
{"id": 4696, "code": "public int getAndResetUnannouncedCredit() {\n    return unannouncedCredit.getAndSet(0);\n}", "summary_tokens": ["gets", "the", "unannounced", "credit", "and", "resets", "it", "to", "tt", "0", "tt", "atomically"], "project": "flink"}
{"id": 9213, "code": "public long getMaxOutputDelay() {\n    return Math.max(leftRelativeSize, rightRelativeSize) + allowedLateness;\n}", "summary_tokens": ["get", "the", "maximum", "interval", "between", "receiving", "a", "row", "and", "emitting", "it", "as", "part", "of", "a", "joined", "result"], "project": "flink"}
{"id": 1015, "code": "public static Map<String, String> getConfSystemProperties() {\n  Map<String, String> systemProperties = new HashMap<String, String>();\n\n  for (ConfVars oneVar : ConfVars.values()) {\n    if (System.getProperty(oneVar.varname) != null) {\n      if (System.getProperty(oneVar.varname).length() > 0) {\n        systemProperties.put(oneVar.varname, System.getProperty(oneVar.varname));\n      }\n    }\n  }\n\n  return systemProperties;\n}", "summary_tokens": ["this", "method", "returns", "a", "mapping", "from", "config", "variable", "name", "to", "its", "value", "for", "all", "config", "variables", "which", "have", "been", "set", "using", "system", "properties"], "project": "flink"}
{"id": 1317, "code": "public static Optional<RestartStrategyConfiguration> fromConfiguration(\n        ReadableConfig configuration) {\n    return configuration\n            .getOptional(RestartStrategyOptions.RESTART_STRATEGY)\n            .map(confName -> parseConfiguration(confName, configuration));\n}", "summary_tokens": ["reads", "a", "restart", "strategy", "configuration", "from", "a", "given", "readable", "config"], "project": "flink"}
{"id": 7709, "code": "public void testValueStateDefaultValue() throws Exception {\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n\n    ValueStateDescriptor<String> kvId = new ValueStateDescriptor<>(\"id\", String.class, \"Hello\");\n\n    ValueState<String> state =\n            backend.getPartitionedState(\n                    VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n    backend.setCurrentKey(1);\n    assertEquals(\"Hello\", state.value());\n\n    state.update(\"Ciao\");\n    assertEquals(\"Ciao\", state.value());\n\n    state.clear();\n    assertEquals(\"Hello\", state.value());\n\n    backend.dispose();\n}", "summary_tokens": ["verify", "that", "an", "empty", "value", "state", "will", "yield", "the", "default", "value"], "project": "flink"}
{"id": 6691, "code": "public static Configuration createZooKeeperHAConfig(\n        String zooKeeperQuorum, String fsStateHandlePath) {\n\n    return configureZooKeeperHA(new Configuration(), zooKeeperQuorum, fsStateHandlePath);\n}", "summary_tokens": ["creates", "a", "configuration", "to", "operate", "in", "high", "availability", "mode", "zookeeper"], "project": "flink"}
{"id": 1239, "code": "default void execute(ThrowingRunnable<? extends Exception> command, String description) {\n    execute(command, description, EMPTY_ARGS);\n}", "summary_tokens": ["executes", "the", "given", "command", "at", "some", "time", "in", "the", "future", "in", "the", "mailbox", "thread"], "project": "flink"}
{"id": 6147, "code": "public void testRequestMemorySegmentsInterruptable2() throws Exception {\n    final int numBuffers = 10;\n\n    NetworkBufferPool globalPool = new NetworkBufferPool(numBuffers, 128);\n    MemorySegment segment = globalPool.requestMemorySegment();\n    assertNotNull(segment);\n\n    final OneShotLatch isRunning = new OneShotLatch();\n    CheckedThread asyncRequest =\n            new CheckedThread() {\n                @Override\n                public void go() throws IOException {\n                    isRunning.trigger();\n                    globalPool.requestMemorySegments(10);\n                }\n            };\n    asyncRequest.start();\n\n        \n        \n        \n    isRunning.await();\n    Thread.sleep(10);\n    asyncRequest.interrupt();\n\n    globalPool.recycle(segment);\n\n    try {\n        asyncRequest.sync();\n    } catch (IOException e) {\n        assertThat(e, hasProperty(\"cause\", instanceOf(InterruptedException.class)));\n\n            \n            \n        globalPool.createBufferPool(10, 10);\n    } finally {\n        globalPool.destroy();\n    }\n}", "summary_tokens": ["tests", "network", "buffer", "pool", "request", "memory", "segments", "int", "verifying", "it", "may", "be", "aborted", "and", "remains", "in", "a", "defined", "state", "even", "if", "the", "waiting", "is", "interrupted"], "project": "flink"}
{"id": 2144, "code": "public void testTwoNestedDirectoriesTrue() {\n    try {\n        String firstLevelDir = TestFileUtils.randomFileName();\n        String secondLevelDir = TestFileUtils.randomFileName();\n        String thirdLevelDir = TestFileUtils.randomFileName();\n\n        File nestedNestedDir =\n                tempFolder.newFolder(firstLevelDir, secondLevelDir, thirdLevelDir);\n        File insideNestedDir = nestedNestedDir.getParentFile();\n        File nestedDir = insideNestedDir.getParentFile();\n\n            \n            \n        TestFileUtils.createTempFileInDirectory(nestedDir.getAbsolutePath(), \"paella\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"kalamari\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"fideua\");\n        TestFileUtils.createTempFileInDirectory(nestedNestedDir.getAbsolutePath(), \"bravas\");\n\n        this.format.setFilePath(new Path(nestedDir.toURI().toString()));\n        this.config.setBoolean(\"recursive.file.enumeration\", true);\n        format.configure(this.config);\n\n        FileInputSplit[] splits = format.createInputSplits(1);\n        Assert.assertEquals(4, splits.length);\n    } catch (Exception ex) {\n        ex.printStackTrace();\n        Assert.fail(ex.getMessage());\n    }\n}", "summary_tokens": ["test", "with", "two", "nested", "directories", "and", "recursive"], "project": "flink"}
{"id": 4640, "code": "public void prioritize(T element) {\n    final Iterator<T> iterator = deque.iterator();\n        \n    for (int i = 0; i < numPriorityElements && iterator.hasNext(); i++) {\n        if (iterator.next() == element) {\n            return;\n        }\n    }\n        \n        \n    if (iterator.hasNext() && iterator.next() == element) {\n        numPriorityElements++;\n        return;\n    }\n        \n    while (iterator.hasNext()) {\n        if (iterator.next() == element) {\n            iterator.remove();\n            break;\n        }\n    }\n    addPriorityElement(element);\n}", "summary_tokens": ["prioritizes", "an", "already", "existing", "element"], "project": "flink"}
{"id": 5592, "code": "public void failExternally(Throwable cause) {\n    LOG.info(\"Attempting to fail task externally {} ({}).\", taskNameWithSubtask, executionId);\n    cancelOrFailAndCancelInvokable(ExecutionState.FAILED, cause);\n}", "summary_tokens": ["marks", "task", "execution", "failed", "for", "an", "external", "reason", "a", "reason", "other", "than", "the", "task", "code", "itself", "throwing", "an", "exception"], "project": "flink"}
{"id": 8643, "code": "public static LogicalType findSumAggType(LogicalType argType) {\n        \n        \n    final LogicalType resultType;\n    if (argType.is(DECIMAL)) {\n            \n        if (argType instanceof LegacyTypeInformationType) {\n            return argType;\n        }\n        resultType = new DecimalType(false, 38, getScale(argType));\n    } else {\n        resultType = argType;\n    }\n    return resultType.copy(argType.isNullable());\n}", "summary_tokens": ["finds", "the", "result", "type", "of", "a", "decimal", "sum", "aggregation"], "project": "flink"}
{"id": 8298, "code": "public long getMillisecond() {\n    return millisecond;\n}", "summary_tokens": ["returns", "the", "number", "of", "milliseconds", "since", "0", "0", "0", "0", "0", "0"], "project": "flink"}
{"id": 2236, "code": "public void testRetryWithDelayRetryStrategy() throws Exception {\n    final int retries = 4;\n    final Time delay = Time.milliseconds(5L);\n    final AtomicInteger countDown = new AtomicInteger(retries);\n\n    long start = System.currentTimeMillis();\n\n    CompletableFuture<Boolean> retryFuture =\n            FutureUtils.retryWithDelay(\n                    () -> {\n                        if (countDown.getAndDecrement() == 0) {\n                            return CompletableFuture.completedFuture(true);\n                        } else {\n                            return FutureUtils.completedExceptionally(\n                                    new FlinkException(\"Test exception.\"));\n                        }\n                    },\n                    new ExponentialBackoffRetryStrategy(\n                            retries, Duration.ofMillis(2L), Duration.ofMillis(5L)),\n                    TestingUtils.defaultScheduledExecutor());\n\n    Boolean result = retryFuture.get();\n\n    long completionTime = System.currentTimeMillis() - start;\n\n    assertTrue(result);\n    assertTrue(\n            \"The completion time should be at least retries times delay between retries.\",\n            completionTime >= (2 + 4 + 5 + 5));\n}", "summary_tokens": ["tests", "that", "the", "delay", "is", "respected", "between", "subsequent", "retries", "of", "a", "retry", "future", "with", "retry", "delay"], "project": "flink"}
{"id": 3725, "code": "public List<Channel> getOutgoingChannels() {\n    return this.outChannels;\n}", "summary_tokens": ["gets", "a", "list", "of", "all", "outgoing", "channels", "leading", "to", "successors"], "project": "flink"}
{"id": 5992, "code": "public void testJobSubmissionUnderSameJobId() throws Exception {\n    final TestingJobManagerRunnerFactory jobManagerRunnerFactory =\n            startDispatcherAndSubmitJob(1);\n\n    runningJobsRegistry.setJobRunning(jobId);\n    final TestingJobManagerRunner testingJobManagerRunner =\n            jobManagerRunnerFactory.takeCreatedJobManagerRunner();\n    suspendJob(testingJobManagerRunner);\n\n        \n        \n        \n    testingJobManagerRunner.getCloseAsyncCalledLatch().await();\n\n    final CompletableFuture<Acknowledge> submissionFuture =\n            dispatcherGateway.submitJob(jobGraph, timeout);\n\n    try {\n        submissionFuture.get(10L, TimeUnit.MILLISECONDS);\n        fail(\n                \"The job submission future should not complete until the previous JobManager \"\n                        + \"termination future has been completed.\");\n    } catch (TimeoutException ignored) {\n            \n    } finally {\n        testingJobManagerRunner.completeTerminationFuture();\n    }\n\n    assertThat(submissionFuture.get(), equalTo(Acknowledge.get()));\n}", "summary_tokens": ["tests", "that", "the", "previous", "job", "manager", "needs", "to", "be", "completely", "terminated", "before", "a", "new", "job", "with", "the", "same", "job", "id", "is", "started"], "project": "flink"}
{"id": 5340, "code": "static void writeCoordinatorSerdeVersion(DataOutputStream out) throws IOException {\n    out.writeInt(CURRENT_VERSION);\n}", "summary_tokens": ["write", "the", "current", "serde", "version"], "project": "flink"}
{"id": 2668, "code": "public <K> SortPartitionOperator<T> sortPartition(KeySelector<T, K> keyExtractor, Order order) {\n    final TypeInformation<K> keyType =\n            TypeExtractor.getKeySelectorTypes(keyExtractor, getType());\n    return new SortPartitionOperator<>(\n            this,\n            new Keys.SelectorFunctionKeys<>(clean(keyExtractor), getType(), keyType),\n            order,\n            Utils.getCallLocationName());\n}", "summary_tokens": ["locally", "sorts", "the", "partitions", "of", "the", "data", "set", "on", "the", "extracted", "key", "in", "the", "specified", "order"], "project": "flink"}
{"id": 4693, "code": "private void notifyCreditAvailable() throws IOException {\n    checkPartitionRequestQueueInitialized();\n\n    partitionRequestClient.notifyCreditAvailable(this);\n}", "summary_tokens": ["enqueue", "this", "input", "channel", "in", "the", "pipeline", "for", "notifying", "the", "producer", "of", "unannounced", "credit"], "project": "flink"}
{"id": 8533, "code": "static ValidationException extractionError(Throwable cause, String message, Object... args) {\n    return new ValidationException(String.format(message, args), cause);\n}", "summary_tokens": ["helper", "method", "for", "creating", "consistent", "exceptions", "during", "extraction"], "project": "flink"}
{"id": 1708, "code": "public static URI getDefaultFsUri() {\n    return defaultScheme != null ? defaultScheme : LocalFileSystem.getLocalFsURI();\n}", "summary_tokens": ["gets", "the", "default", "file", "system", "uri", "that", "is", "used", "for", "paths", "and", "file", "systems", "that", "do", "not", "specify", "and", "explicit", "scheme"], "project": "flink"}
{"id": 4260, "code": "public Long getRestoredCheckpointId() {\n    return restoredCheckpointId;\n}", "summary_tokens": ["returns", "the", "checkpoint", "id", "if", "this", "was", "created", "for", "a", "restored", "operator", "null", "otherwise"], "project": "flink"}
{"id": 5345, "code": "public List<SplitT> getAndRemoveUncheckpointedAssignment(\n        int subtaskId, long restoredCheckpointId) {\n    final ArrayList<SplitT> splits = new ArrayList<>();\n\n    for (final Map.Entry<Long, Map<Integer, LinkedHashSet<SplitT>>> entry :\n            assignmentsByCheckpointId.entrySet()) {\n        if (entry.getKey() > restoredCheckpointId) {\n            removeFromAssignment(subtaskId, entry.getValue(), splits);\n        }\n    }\n\n    removeFromAssignment(subtaskId, uncheckpointedAssignments, splits);\n    return splits;\n}", "summary_tokens": ["this", "method", "is", "invoked", "when", "a", "source", "reader", "fails", "over"], "project": "flink"}
{"id": 9123, "code": "public ResultFuture<?> getResultFuture() {\n    return this.resultFuture;\n}", "summary_tokens": ["gets", "the", "internal", "collector", "which", "used", "to", "emit", "the", "final", "row"], "project": "flink"}
{"id": 5321, "code": "public static Pair<Integer, Integer> getMinMaxNetworkBuffersPerResultPartition(\n        final int configuredNetworkBuffersPerChannel,\n        final int numFloatingBuffersPerGate,\n        final int sortShuffleMinParallelism,\n        final int sortShuffleMinBuffers,\n        final int numSubpartitions,\n        final ResultPartitionType type) {\n    int min =\n            type.isBlocking() && numSubpartitions >= sortShuffleMinParallelism\n                    ? sortShuffleMinBuffers\n                    : numSubpartitions + 1;\n    int max =\n            type.isBounded()\n                    ? numSubpartitions * configuredNetworkBuffersPerChannel\n                            + numFloatingBuffersPerGate\n                    : Integer.MAX_VALUE;\n        \n        \n        \n        \n        \n    return Pair.of(min, Math.max(min, max));\n}", "summary_tokens": ["calculates", "and", "returns", "local", "network", "buffer", "pool", "size", "used", "by", "the", "result", "partition"], "project": "flink"}
{"id": 3153, "code": "static void verifyParallelism(String[] arguments, String... fullParallelismOperatorNames)\n        throws Exception {\n        \n    final int parallelism = 8;\n    arguments = ArrayUtils.addAll(arguments, \"--__parallelism\", Integer.toString(parallelism));\n\n        \n    Runner runner = new Runner(arguments).run();\n\n        \n        \n        \n    DataSet result = runner.getResult();\n    if (result != null) {\n        result.output(new DiscardingOutputFormat());\n    }\n\n        \n    ExecutionEnvironment env = runner.getExecutionEnvironment();\n    env.setParallelism(2 * parallelism);\n\n        \n        \n    List<Pattern> patterns = new ArrayList<>();\n    patterns.add(\n            Pattern.compile(\n                    \"DataSink \\\\(org\\\\.apache\\\\.flink\\\\.api\\\\.java\\\\.io\\\\.DiscardingOutputFormat@[0-9a-f]{1,8}\\\\)\"));\n    patterns.add(Pattern.compile(\"FlatMap \\\\(Translate results IDs\\\\)\"));\n\n        \n    for (String largeOperatorName : fullParallelismOperatorNames) {\n        patterns.add(Pattern.compile(largeOperatorName));\n    }\n\n    Optimizer compiler = new Optimizer(null, new DefaultCostEstimator(), new Configuration());\n    OptimizedPlan optimizedPlan = compiler.compile(env.createProgramPlan());\n\n        \n    List<PlanNode> queue = new ArrayList<>();\n    queue.addAll(optimizedPlan.getDataSinks());\n\n    while (queue.size() > 0) {\n        PlanNode node = queue.remove(queue.size() - 1);\n\n            \n            \n        boolean matched = false;\n        for (Pattern pattern : patterns) {\n            matched |= pattern.matcher(node.getNodeName()).matches();\n        }\n\n        if (!matched) {\n                \n                \n            assertTrue(\n                    \"Wrong parallelism for \" + node.toString(),\n                    node.getParallelism() <= parallelism);\n        }\n\n        for (Channel channel : node.getInputs()) {\n            queue.add(channel.getSource());\n        }\n    }\n}", "summary_tokens": ["verify", "algorithm", "driver", "parallelism"], "project": "flink"}
{"id": 7539, "code": "protected final boolean isCleanupTime(W window, long time) {\n    return time == cleanupTime(window);\n}", "summary_tokens": ["returns", "true", "if", "the", "given", "time", "is", "the", "cleanup", "time", "for", "the", "given", "window"], "project": "flink"}
{"id": 6183, "code": "public void testValidSslConnectionAdvanced() throws Exception {\n    Configuration sslConfig = createSslConfig();\n    sslConfig.setInteger(SSL_INTERNAL_SESSION_CACHE_SIZE, 1);\n    sslConfig.setInteger(SSL_INTERNAL_SESSION_TIMEOUT, 1_000);\n    sslConfig.setInteger(SSL_INTERNAL_HANDSHAKE_TIMEOUT, 1_000);\n    sslConfig.setInteger(SSL_INTERNAL_CLOSE_NOTIFY_FLUSH_TIMEOUT, 1_000);\n\n    testValidSslConnection(sslConfig);\n}", "summary_tokens": ["verify", "valid", "advanced", "ssl", "configuration", "and", "connection"], "project": "flink"}
{"id": 3677, "code": "public void setOrdering(Ordering ordering) {\n    this.ordering = ordering;\n}", "summary_tokens": ["sets", "the", "order", "for", "these", "interesting", "local", "properties"], "project": "flink"}
{"id": 4148, "code": "public void registerJob(JobID jobId) {\n    checkNotNull(jobId);\n\n    synchronized (jobRefCounters) {\n        RefCount ref = jobRefCounters.get(jobId);\n        if (ref == null) {\n            ref = new RefCount();\n            jobRefCounters.put(jobId, ref);\n        } else {\n                \n            ref.keepUntil = -1;\n        }\n        ++ref.references;\n    }\n}", "summary_tokens": ["registers", "use", "of", "job", "related", "blobs"], "project": "flink"}
{"id": 1582, "code": "public static <IN1, IN2, OUT> TypeInformation<OUT> getBinaryOperatorReturnType(\n        Function function,\n        Class<?> baseClass,\n        int input1TypeArgumentIndex,\n        int input2TypeArgumentIndex,\n        int outputTypeArgumentIndex,\n        int[] lambdaOutputTypeArgumentIndices,\n        TypeInformation<IN1> in1Type,\n        TypeInformation<IN2> in2Type,\n        String functionName,\n        boolean allowMissing) {\n\n    Preconditions.checkArgument(\n            in1Type == null || input1TypeArgumentIndex >= 0,\n            \"Input 1 type argument index was not provided\");\n    Preconditions.checkArgument(\n            in2Type == null || input2TypeArgumentIndex >= 0,\n            \"Input 2 type argument index was not provided\");\n    Preconditions.checkArgument(\n            outputTypeArgumentIndex >= 0, \"Output type argument index was not provided\");\n    Preconditions.checkArgument(\n            lambdaOutputTypeArgumentIndices != null,\n            \"Indices for output type arguments within lambda not provided\");\n\n        \n    if (function instanceof ResultTypeQueryable) {\n        return ((ResultTypeQueryable<OUT>) function).getProducedType();\n    }\n\n        \n    try {\n        final LambdaExecutable exec;\n        try {\n            exec = checkAndExtractLambda(function);\n        } catch (TypeExtractionException e) {\n            throw new InvalidTypesException(\"Internal error occurred.\", e);\n        }\n        if (exec != null) {\n\n            final Method sam = TypeExtractionUtils.getSingleAbstractMethod(baseClass);\n            final int baseParametersLen = sam.getParameterTypes().length;\n\n                \n                \n            final int paramLen = exec.getParameterTypes().length;\n\n            final Type output;\n            if (lambdaOutputTypeArgumentIndices.length > 0) {\n                output =\n                        TypeExtractionUtils.extractTypeFromLambda(\n                                baseClass,\n                                exec,\n                                lambdaOutputTypeArgumentIndices,\n                                paramLen,\n                                baseParametersLen);\n            } else {\n                output = exec.getReturnType();\n                TypeExtractionUtils.validateLambdaType(baseClass, output);\n            }\n\n            return new TypeExtractor().privateCreateTypeInfo(output, in1Type, in2Type);\n        } else {\n            if (in1Type != null) {\n                validateInputType(\n                        baseClass, function.getClass(), input1TypeArgumentIndex, in1Type);\n            }\n            if (in2Type != null) {\n                validateInputType(\n                        baseClass, function.getClass(), input2TypeArgumentIndex, in2Type);\n            }\n            return new TypeExtractor()\n                    .privateCreateTypeInfo(\n                            baseClass,\n                            function.getClass(),\n                            outputTypeArgumentIndex,\n                            in1Type,\n                            in2Type);\n        }\n    } catch (InvalidTypesException e) {\n        if (allowMissing) {\n            return (TypeInformation<OUT>)\n                    new MissingTypeInfo(\n                            functionName != null ? functionName : function.toString(), e);\n        } else {\n            throw e;\n        }\n    }\n}", "summary_tokens": ["returns", "the", "binary", "operator", "s", "return", "type"], "project": "flink"}
{"id": 8025, "code": "public static Builder forManaged() {\n    return new Builder();\n}", "summary_tokens": ["creates", "a", "new", "builder", "for", "a", "managed", "table"], "project": "flink"}
{"id": 560, "code": "static TupleSerializer<Tuple2<KafkaTopicPartition, Long>> createStateSerializer(\n        ExecutionConfig executionConfig) {\n        \n        \n    TypeSerializer<?>[] fieldSerializers =\n            new TypeSerializer<?>[] {\n                new KryoSerializer<>(KafkaTopicPartition.class, executionConfig),\n                LongSerializer.INSTANCE\n            };\n    @SuppressWarnings(\"unchecked\")\n    Class<Tuple2<KafkaTopicPartition, Long>> tupleClass =\n            (Class<Tuple2<KafkaTopicPartition, Long>>) (Class<?>) Tuple2.class;\n    return new TupleSerializer<>(tupleClass, fieldSerializers);\n}", "summary_tokens": ["creates", "state", "serializer", "for", "kafka", "topic", "partition", "to", "offset", "tuple"], "project": "flink"}
{"id": 2458, "code": "public void testForGeneric_withValidParams_succeeds() {\n    assertThat(\n            GlueSchemaRegistryAvroSerializationSchema.forGeneric(\n                    userSchema, testTopic, configs),\n            notNullValue());\n    assertThat(\n            GlueSchemaRegistryAvroSerializationSchema.forGeneric(\n                    userSchema, testTopic, configs),\n            instanceOf(GlueSchemaRegistryAvroSerializationSchema.class));\n}", "summary_tokens": ["test", "whether", "for", "generic", "method", "works"], "project": "flink"}
{"id": 8551, "code": "static FunctionTemplate fromAnnotation(DataTypeFactory typeFactory, FunctionHint hint) {\n    return new FunctionTemplate(\n            createSignatureTemplate(\n                    typeFactory,\n                    defaultAsNull(hint, FunctionHint::input),\n                    defaultAsNull(hint, FunctionHint::argumentNames),\n                    hint.isVarArgs()),\n            createResultTemplate(typeFactory, defaultAsNull(hint, FunctionHint::accumulator)),\n            createResultTemplate(typeFactory, defaultAsNull(hint, FunctionHint::output)));\n}", "summary_tokens": ["creates", "an", "instance", "using", "the", "given", "function", "hint"], "project": "flink"}
{"id": 9505, "code": "public static <T> FutureWillFailMatcher<T> futureWillCompleteExceptionally(Duration timeout) {\n    return futureWillCompleteExceptionally(Throwable.class, timeout);\n}", "summary_tokens": ["checks", "whether", "completable", "future", "will", "completed", "exceptionally", "within", "a", "certain", "time"], "project": "flink"}
{"id": 7548, "code": "public final Watermark asWatermark() {\n    return (Watermark) this;\n}", "summary_tokens": ["casts", "this", "element", "into", "a", "watermark"], "project": "flink"}
{"id": 5553, "code": "public ClusterInformation getClusterInformation() {\n    return clusterInformation;\n}", "summary_tokens": ["gets", "the", "cluster", "information"], "project": "flink"}
{"id": 6491, "code": "public void testFileCaching() throws Exception {\n    final File outputFile = runFileCachingTest(Time.milliseconds(5000L), Time.milliseconds(0L));\n\n    assertThat(outputFile.length(), is(greaterThan(0L)));\n    assertThat(FileUtils.readFileUtf8(outputFile), is(equalTo(fileContent1)));\n}", "summary_tokens": ["tests", "that", "files", "are", "cached"], "project": "flink"}
{"id": 2740, "code": "public CsvReader ignoreInvalidLines() {\n    ignoreInvalidLines = true;\n    return this;\n}", "summary_tokens": ["sets", "the", "csv", "reader", "to", "ignore", "any", "invalid", "lines"], "project": "flink"}
{"id": 7509, "code": "public final V put(K key, V value) {\n    final int hash = hash(key);\n    final int slot = indexOf(hash);\n\n        \n    for (Entry<K, V> e = table[slot]; e != null; e = e.next) {\n        Object k;\n        if (e.hashCode == hash && ((k = e.key) == key || key.equals(k))) {\n                \n            V old = e.value;\n            e.value = value;\n            return old;\n        }\n    }\n\n        \n    insertNewEntry(hash, key, value, slot);\n    return null;\n}", "summary_tokens": ["inserts", "the", "given", "value", "mapped", "under", "the", "given", "key"], "project": "flink"}
{"id": 4085, "code": "public int getPort() {\n    final InetSocketAddress currentServerAddress = serverAddress;\n\n    if (currentServerAddress != null) {\n        return currentServerAddress.getPort();\n    } else {\n        return -1;\n    }\n}", "summary_tokens": ["returns", "the", "port", "the", "blob", "server", "is", "listening", "on"], "project": "flink"}
{"id": 2527, "code": "private static Map<String, String> getModifiedOptions(\n        Consumer<Map<String, String>> optionModifier) {\n    Map<String, String> options = getAllOptions();\n    optionModifier.accept(options);\n    return options;\n}", "summary_tokens": ["returns", "the", "full", "options", "modified", "by", "the", "given", "consumer", "option", "modifier"], "project": "flink"}
{"id": 5115, "code": "public KvStateID registerKvState(\n        JobID jobId,\n        JobVertexID jobVertexId,\n        KeyGroupRange keyGroupRange,\n        String registrationName,\n        InternalKvState<?, ?, ?> kvState,\n        ClassLoader userClassLoader) {\n\n    KvStateID kvStateId = new KvStateID();\n\n    if (registeredKvStates.putIfAbsent(kvStateId, new KvStateEntry<>(kvState, userClassLoader))\n            == null) {\n        final KvStateRegistryListener listener = getKvStateRegistryListener(jobId);\n\n        if (listener != null) {\n            listener.notifyKvStateRegistered(\n                    jobId, jobVertexId, keyGroupRange, registrationName, kvStateId);\n        }\n\n        return kvStateId;\n    } else {\n        throw new IllegalStateException(\n                \"State \\\"\"\n                        + registrationName\n                        + \" \\\"(id=\"\n                        + kvStateId\n                        + \") appears registered although it should not.\");\n    }\n}", "summary_tokens": ["registers", "the", "kv", "state", "instance", "and", "returns", "the", "assigned", "id"], "project": "flink"}
{"id": 469, "code": "public RowData nextRecord(RowData reuse) throws IOException {\n    try {\n        if (!hasNext) {\n            return null;\n        }\n        RowData row = rowConverter.toInternal(resultSet);\n            \n        hasNext = resultSet.next();\n        return row;\n    } catch (SQLException se) {\n        throw new IOException(\"Couldn't read data - \" + se.getMessage(), se);\n    } catch (NullPointerException npe) {\n        throw new IOException(\"Couldn't access resultSet\", npe);\n    }\n}", "summary_tokens": ["stores", "the", "next", "result", "set", "row", "in", "a", "tuple"], "project": "flink"}
{"id": 3847, "code": "private ArrowRecordBatch loadBatch(int nextIndexOfArrowDataToProcess) throws IOException {\n    ByteArrayInputStream bais =\n            new ByteArrayInputStream(arrowData[nextIndexOfArrowDataToProcess]);\n    return MessageSerializer.deserializeRecordBatch(\n            new ReadChannel(Channels.newChannel(bais)), allocator);\n}", "summary_tokens": ["load", "the", "specified", "batch", "of", "data", "to", "process"], "project": "flink"}
{"id": 6870, "code": "public EmbeddedRocksDBStateBackend configure(ReadableConfig config, ClassLoader classLoader) {\n    return new EmbeddedRocksDBStateBackend(this, config, classLoader);\n}", "summary_tokens": ["creates", "a", "copy", "of", "this", "state", "backend", "that", "uses", "the", "values", "defined", "in", "the", "configuration", "for", "fields", "where", "that", "were", "not", "yet", "specified", "in", "this", "state", "backend"], "project": "flink"}
{"id": 2557, "code": "public void testMissingNode() throws Exception {\n    ObjectMapper objectMapper = new ObjectMapper();\n\n        \n    ObjectNode root = objectMapper.createObjectNode();\n    root.put(\"id\", 123123123);\n    byte[] serializedJson = objectMapper.writeValueAsBytes(root);\n\n    TypeInformation<Row> rowTypeInformation =\n            Types.ROW_NAMED(new String[] {\"name\"}, Types.STRING);\n\n    JsonRowDeserializationSchema deserializationSchema =\n            new JsonRowDeserializationSchema.Builder(rowTypeInformation).build();\n\n    Row row = new Row(1);\n    assertThat(serializedJson, whenDeserializedWith(deserializationSchema).equalsTo(row));\n\n    deserializationSchema =\n            new JsonRowDeserializationSchema.Builder(rowTypeInformation)\n                    .failOnMissingField()\n                    .build();\n\n    assertThat(\n            serializedJson,\n            whenDeserializedWith(deserializationSchema)\n                    .failsWithException(hasCause(instanceOf(IllegalStateException.class))));\n\n        \n    deserializationSchema =\n            new JsonRowDeserializationSchema.Builder(rowTypeInformation)\n                    .ignoreParseErrors()\n                    .build();\n    assertThat(serializedJson, whenDeserializedWith(deserializationSchema).equalsTo(row));\n\n    thrown.expect(IllegalArgumentException.class);\n    thrown.expectMessage(\n            \"JSON format doesn't support failOnMissingField and ignoreParseErrors are both true\");\n    new JsonRowDeserializationSchema.Builder(rowTypeInformation)\n            .failOnMissingField()\n            .ignoreParseErrors()\n            .build();\n}", "summary_tokens": ["tests", "deserialization", "with", "non", "existing", "field", "name"], "project": "flink"}
{"id": 625, "code": "public static <T> KeyedStream<T, Tuple> persistentKeyBy(\n        DataStream<T> dataStream,\n        String topic,\n        int producerParallelism,\n        int numberOfPartitions,\n        Properties properties,\n        int... fields) {\n    return persistentKeyBy(\n            dataStream,\n            topic,\n            producerParallelism,\n            numberOfPartitions,\n            properties,\n            keySelector(dataStream, fields));\n}", "summary_tokens": ["uses", "kafka", "as", "a", "message", "bus", "to", "persist", "key", "by", "shuffle"], "project": "flink"}
{"id": 4795, "code": "public boolean allowNonRestoredState() {\n    return allowNonRestoredState;\n}", "summary_tokens": ["returns", "whether", "non", "restored", "state", "is", "allowed", "if", "the", "savepoint", "contains", "state", "that", "cannot", "be", "mapped", "back", "to", "the", "job"], "project": "flink"}
{"id": 5376, "code": "public static KeyGroupRange of(int startKeyGroup, int endKeyGroup) {\n    return startKeyGroup <= endKeyGroup\n            ? new KeyGroupRange(startKeyGroup, endKeyGroup)\n            : EMPTY_KEY_GROUP_RANGE;\n}", "summary_tokens": ["factory", "method", "that", "also", "handles", "creation", "of", "empty", "key", "groups"], "project": "flink"}
{"id": 3260, "code": "public Graph<KT, VVT, Projection<KB, VVB, VVT, EV>> projectionTopFull() {\n    DataSet<Tuple5<KT, KB, EV, VVT, VVB>> edgesWithVertices = joinEdgeWithVertices();\n\n    DataSet<Edge<KT, Projection<KB, VVB, VVT, EV>>> newEdges =\n            edgesWithVertices\n                    .join(edgesWithVertices)\n                    .where(1)\n                    .equalTo(1)\n                    .with(new ProjectionTopFull<>())\n                    .name(\"Full top projection\");\n\n    return Graph.fromDataSet(topVertices, newEdges, context);\n}", "summary_tokens": ["convert", "a", "bipartite", "graph", "into", "a", "graph", "that", "contains", "only", "top", "vertices"], "project": "flink"}
{"id": 7911, "code": "public ContentWriter createWriter(String name) {\n    checkArgument(!filesContent.containsKey(name), \"File [%s] already exists\", name);\n    filesContent.put(name, new ArrayList<>());\n    return new ContentWriter(name, this);\n}", "summary_tokens": ["creates", "an", "empty", "file"], "project": "flink"}
{"id": 2019, "code": "public static String unresolvedHostAndPortToNormalizedString(String host, int port) {\n    Preconditions.checkArgument(isValidHostPort(port), \"Port is not within the valid range,\");\n    return unresolvedHostToNormalizedString(host) + \":\" + port;\n}", "summary_tokens": ["returns", "a", "valid", "address", "for", "akka"], "project": "flink"}
{"id": 7551, "code": "public T getValue() {\n    return value;\n}", "summary_tokens": ["returns", "the", "value", "wrapped", "in", "this", "stream", "value"], "project": "flink"}
{"id": 1137, "code": "public void aggregate(long value) {\n    sum += value;\n}", "summary_tokens": ["adds", "the", "given", "value", "to", "the", "current", "aggregate"], "project": "flink"}
{"id": 3222, "code": "public GraphCsvReader ignoreCommentsVertices(String commentPrefix) {\n    if (this.vertexReader != null) {\n        this.vertexReader.ignoreComments(commentPrefix);\n    }\n    return this;\n}", "summary_tokens": ["configures", "the", "string", "that", "starts", "comments", "for", "the", "vertex", "csv", "reader"], "project": "flink"}
{"id": 7189, "code": "public boolean isForceCheckpointing() {\n    return forceCheckpointing;\n}", "summary_tokens": ["checks", "whether", "checkpointing", "is", "forced", "despite", "currently", "non", "checkpointable", "iteration", "feedback"], "project": "flink"}
{"id": 2851, "code": "public long getNonNullCount() {\n    return 0;\n}", "summary_tokens": ["the", "number", "of", "non", "null", "values", "in", "this", "column"], "project": "flink"}
{"id": 3945, "code": "public void testQueryUnknownKey() throws Exception {\n    KvStateRegistry registry = new KvStateRegistry();\n    AtomicKvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n    MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    KvStateServerHandler handler =\n            new KvStateServerHandler(testServer, registry, serializer, stats);\n    EmbeddedChannel channel = new EmbeddedChannel(getFrameDecoder(), handler);\n\n    int numKeyGroups = 1;\n    AbstractStateBackend abstractBackend = new MemoryStateBackend();\n    DummyEnvironment dummyEnv = new DummyEnvironment(\"test\", 1, 0);\n    dummyEnv.setKvStateRegistry(registry);\n    KeyedStateBackend<Integer> backend =\n            createKeyedStateBackend(registry, numKeyGroups, abstractBackend, dummyEnv);\n\n    final TestRegistryListener registryListener = new TestRegistryListener();\n    registry.registerListener(dummyEnv.getJobID(), registryListener);\n\n        \n    ValueStateDescriptor<Integer> desc =\n            new ValueStateDescriptor<>(\"any\", IntSerializer.INSTANCE);\n    desc.setQueryable(\"vanilla\");\n\n    backend.getPartitionedState(VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, desc);\n\n    byte[] serializedKeyAndNamespace =\n            KvStateSerializer.serializeKeyAndNamespace(\n                    1238283,\n                    IntSerializer.INSTANCE,\n                    VoidNamespace.INSTANCE,\n                    VoidNamespaceSerializer.INSTANCE);\n\n    long requestId = Integer.MAX_VALUE + 22982L;\n\n    assertTrue(registryListener.registrationName.equals(\"vanilla\"));\n\n    KvStateInternalRequest request =\n            new KvStateInternalRequest(registryListener.kvStateId, serializedKeyAndNamespace);\n    ByteBuf serRequest =\n            MessageSerializer.serializeRequest(channel.alloc(), requestId, request);\n\n        \n    channel.writeInbound(serRequest);\n\n    ByteBuf buf = (ByteBuf) readInboundBlocking(channel);\n    buf.skipBytes(4); \n\n        \n    assertEquals(MessageType.REQUEST_FAILURE, MessageSerializer.deserializeHeader(buf));\n    RequestFailure response = MessageSerializer.deserializeRequestFailure(buf);\n    buf.release();\n\n    assertEquals(requestId, response.getRequestId());\n\n    assertTrue(\n            \"Did not respond with expected failure cause\",\n            response.getCause() instanceof UnknownKeyOrNamespaceException);\n\n    assertEquals(1L, stats.getNumRequests());\n    assertEquals(1L, stats.getNumFailed());\n}", "summary_tokens": ["tests", "the", "failure", "response", "with", "unknown", "key", "or", "namespace", "exception", "as", "cause", "on", "queries", "for", "non", "existing", "keys"], "project": "flink"}
{"id": 4307, "code": "public InflightDataRescalingDescriptor getInputRescalingDescriptor() {\n    return getMapping(OperatorSubtaskState::getInputRescalingDescriptor);\n}", "summary_tokens": ["returns", "the", "input", "channel", "mapping", "for", "rescaling", "with", "in", "flight", "data", "or", "inflight", "data", "rescaling", "descriptor", "no", "rescale"], "project": "flink"}
{"id": 285, "code": "public void testBoundedTextFileSourceWithTaskManagerFailover() throws Exception {\n    testBoundedTextFileSource(FailoverType.TM);\n}", "summary_tokens": ["this", "test", "runs", "a", "job", "reading", "bounded", "input", "with", "a", "stream", "record", "format", "text", "lines", "and", "restarts", "task", "manager"], "project": "flink"}
{"id": 2540, "code": "public void testSerialize_withNullObject_returnNull() {\n    GlueSchemaRegistryJsonSerializationSchema glueSchemaRegistryJsonSerializationSchema =\n            new GlueSchemaRegistryJsonSerializationSchema<>(testTopic, configs);\n    assertThat(glueSchemaRegistryJsonSerializationSchema.serialize(null), nullValue());\n}", "summary_tokens": ["test", "whether", "serialize", "method", "returns", "null", "when", "input", "object", "is", "null"], "project": "flink"}
{"id": 679, "code": "public void testFailBeforeNotifyAndResumeWorkAfterwards() throws Exception {\n    String topic = \"flink-kafka-producer-fail-before-notify\";\n\n    OneInputStreamOperatorTestHarness<Integer, Object> testHarness1 = createTestHarness(topic);\n    checkProducerLeak();\n    testHarness1.setup();\n    testHarness1.open();\n    testHarness1.processElement(42, 0);\n    testHarness1.snapshot(0, 1);\n    testHarness1.processElement(43, 2);\n    OperatorSubtaskState snapshot1 = testHarness1.snapshot(1, 3);\n\n    testHarness1.processElement(44, 4);\n    testHarness1.snapshot(2, 5);\n    testHarness1.processElement(45, 6);\n\n        \n        \n        \n    OneInputStreamOperatorTestHarness<Integer, Object> testHarness2 = createTestHarness(topic);\n    testHarness2.setup();\n        \n    testHarness2.initializeState(snapshot1);\n    testHarness2.open();\n\n        \n    testHarness2.processElement(46, 7);\n    testHarness2.snapshot(4, 8);\n    testHarness2.processElement(47, 9);\n    testHarness2.notifyOfCompletedCheckpoint(4);\n\n        \n        \n        \n        \n        \n    assertExactlyOnceForTopic(createProperties(), topic, Arrays.asList(42, 43, 46));\n\n    try {\n        testHarness1.close();\n    } catch (Exception e) {\n            \n            \n            \n        if (!(e.getCause() instanceof ProducerFencedException)) {\n            fail(\"Received unexpected exception \" + e);\n        }\n    }\n    testHarness2.close();\n    deleteTestTopic(topic);\n    checkProducerLeak();\n}", "summary_tokens": ["this", "tests", "checks", "whether", "flink", "kafka", "producer", "correctly", "aborts", "lingering", "transactions", "after", "a", "failure"], "project": "flink"}
{"id": 9056, "code": "public void testJoinLookupTable() throws Exception {\n    String jsonPlan =\n            tableEnv.getJsonPlan(\n                    \"insert into MySink \"\n                            + \"SELECT T.id, T.len, T.content, D.name FROM src AS T JOIN user_table \\n\"\n                            + \"for system_time as of T.proctime AS D ON T.id = D.id \\n\");\n    tableEnv.executeJsonPlan(jsonPlan).await();\n    List<String> expected =\n            Arrays.asList(\n                    \"+I[1, 12, Julian, Julian]\",\n                    \"+I[2, 15, Hello, Jark]\",\n                    \"+I[3, 15, Fabian, Fabian]\");\n    assertResult(expected, TestValuesTableFactory.getResults(\"MySink\"));\n}", "summary_tokens": ["test", "join", "temporal", "table"], "project": "flink"}
{"id": 9281, "code": "public synchronized void addChannel(FileIOChannel.ID id) {\n    checkArgument(!closed);\n    channels.add(id);\n}", "summary_tokens": ["add", "a", "new", "file", "channel"], "project": "flink"}
{"id": 1108, "code": "public void setExecutionConfig(ExecutionConfig executionConfig) {\n    this.executionConfig = executionConfig;\n}", "summary_tokens": ["sets", "the", "runtime", "config", "object", "defining", "execution", "parameters"], "project": "flink"}
{"id": 4076, "code": "public void sendGetRequest(String path, Duration timeout)\n        throws TimeoutException, InterruptedException {\n    if (!path.startsWith(\"/\")) {\n        path = \"/\" + path;\n    }\n\n    HttpRequest getRequest =\n            new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET, path);\n    getRequest.headers().set(HttpHeaders.Names.HOST, host);\n    getRequest.headers().set(HttpHeaders.Names.CONNECTION, HttpHeaders.Values.CLOSE);\n\n    sendRequest(getRequest, timeout);\n}", "summary_tokens": ["sends", "a", "simple", "get", "request", "to", "the", "given", "path"], "project": "flink"}
{"id": 5894, "code": "public void testSerialIncrementAndGet() throws Exception {\n    final CheckpointIDCounter counter = createCheckpointIdCounter();\n\n    try {\n        counter.start();\n\n        assertEquals(1, counter.getAndIncrement());\n        assertEquals(2, counter.get());\n        assertEquals(2, counter.getAndIncrement());\n        assertEquals(3, counter.get());\n        assertEquals(3, counter.getAndIncrement());\n        assertEquals(4, counter.get());\n        assertEquals(4, counter.getAndIncrement());\n    } finally {\n        counter.shutdown(JobStatus.FINISHED);\n    }\n}", "summary_tokens": ["tests", "serial", "increment", "and", "get", "calls"], "project": "flink"}
{"id": 2672, "code": "public DataSink<T> print(String sinkIdentifier) {\n    return output(new PrintingOutputFormat<T>(sinkIdentifier, false));\n}", "summary_tokens": ["writes", "a", "data", "set", "to", "the", "standard", "output", "stream", "stdout"], "project": "flink"}
{"id": 8686, "code": "private static List<String> getRowtimeAttributes(TableSource<?> tableSource) {\n    if (tableSource instanceof DefinedRowtimeAttributes) {\n        return ((DefinedRowtimeAttributes) tableSource)\n                .getRowtimeAttributeDescriptors().stream()\n                        .map(RowtimeAttributeDescriptor::getAttributeName)\n                        .collect(Collectors.toList());\n    } else {\n        return Collections.emptyList();\n    }\n}", "summary_tokens": ["returns", "a", "list", "with", "all", "rowtime", "attribute", "names", "of", "the", "table", "source"], "project": "flink"}
{"id": 534, "code": "static OffsetsInitializer earliest() {\n    return new ReaderHandledOffsetsInitializer(\n            KafkaPartitionSplit.EARLIEST_OFFSET, OffsetResetStrategy.EARLIEST);\n}", "summary_tokens": ["get", "an", "offsets", "initializer", "which", "initializes", "the", "offsets", "to", "the", "earliest", "available", "offsets", "of", "each", "partition"], "project": "flink"}
{"id": 6047, "code": "public static void finishAllVertices(ExecutionGraph eg) {\n    for (ExecutionVertex vertex : eg.getAllExecutionVertices()) {\n        vertex.getCurrentExecutionAttempt().markFinished();\n    }\n}", "summary_tokens": ["takes", "all", "vertices", "in", "the", "given", "execution", "graph", "and", "switches", "their", "current", "execution", "to", "finished"], "project": "flink"}
{"id": 8382, "code": "public <U> TypeSerializerSnapshot<MapView<K, V>> transformLegacySerializerSnapshot(\n        TypeSerializerSnapshot<U> legacySnapshot) {\n    if (legacySnapshot instanceof MapViewSerializerSnapshot) {\n        return (TypeSerializerSnapshot<MapView<K, V>>) legacySnapshot;\n    } else if (legacySnapshot instanceof MapSerializerConfigSnapshot) {\n            \n            \n        MapSerializerSnapshot<K, V> transformedNestedMapSerializerSnapshot =\n                new MapSerializerSnapshot<>();\n        MapSerializerConfigSnapshot<K, V> snapshot =\n                (MapSerializerConfigSnapshot<K, V>) legacySnapshot;\n        CompositeTypeSerializerUtil.setNestedSerializersSnapshots(\n                transformedNestedMapSerializerSnapshot,\n                snapshot.getNestedSerializersAndConfigs().get(0).f1,\n                snapshot.getNestedSerializersAndConfigs().get(1).f1);\n\n            \n            \n        MapViewSerializerSnapshot<K, V> transformedMapViewSerializerSnapshot =\n                new MapViewSerializerSnapshot<>();\n        CompositeTypeSerializerUtil.setNestedSerializersSnapshots(\n                transformedMapViewSerializerSnapshot, transformedNestedMapSerializerSnapshot);\n\n        return transformedMapViewSerializerSnapshot;\n    } else {\n        throw new UnsupportedOperationException(\n                legacySnapshot.getClass().getCanonicalName() + \" is not supported.\");\n    }\n}", "summary_tokens": ["we", "need", "to", "override", "this", "as", "a", "legacy", "serializer", "snapshot", "transformer", "because", "in", "flink", "0"], "project": "flink"}
{"id": 9451, "code": "private TestingBatchMultipleInputStreamOperator createMultipleInputStreamOperator()\n        throws Exception {\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    Transformation<RowData> source1 = createSource(env, \"source1\");\n    Transformation<RowData> source2 = createSource(env, \"source2\");\n    Transformation<RowData> source3 = createSource(env, \"source3\");\n    OneInputTransformation<RowData, RowData> agg1 =\n            createOneInputTransform(\n                    source1,\n                    \"agg1\",\n                    new TestingOneInputStreamOperator(true),\n                    InternalTypeInfo.of(RowType.of(DataTypes.STRING().getLogicalType())));\n    OneInputTransformation<RowData, RowData> agg2 =\n            createOneInputTransform(\n                    source2,\n                    \"agg2\",\n                    new TestingOneInputStreamOperator(true),\n                    InternalTypeInfo.of(RowType.of(DataTypes.STRING().getLogicalType())));\n    TwoInputTransformation<RowData, RowData, RowData> join1 =\n            createTwoInputTransform(\n                    agg1,\n                    agg2,\n                    \"join1\",\n                    new TestingTwoInputStreamOperator(true),\n                    InternalTypeInfo.of(RowType.of(DataTypes.STRING().getLogicalType())));\n\n    TwoInputTransformation<RowData, RowData, RowData> join2 =\n            createTwoInputTransform(\n                    join1,\n                    source3,\n                    \"join2\",\n                    new TestingTwoInputStreamOperator(true),\n                    InternalTypeInfo.of(RowType.of(DataTypes.STRING().getLogicalType())));\n\n    TableOperatorWrapperGenerator generator =\n            new TableOperatorWrapperGenerator(\n                    Arrays.asList(source1, source2, source3), join2, new int[] {1, 2, 0});\n    generator.generate();\n\n    List<Pair<Transformation<?>, InputSpec>> inputTransformAndInputSpecPairs =\n            generator.getInputTransformAndInputSpecPairs();\n\n    List<StreamElement> outputData = new ArrayList<>();\n    return new TestingBatchMultipleInputStreamOperator(\n            createStreamOperatorParameters(new TestingOutput(outputData)),\n            inputTransformAndInputSpecPairs.stream()\n                    .map(Pair::getValue)\n                    .collect(Collectors.toList()),\n            generator.getHeadWrappers(),\n            generator.getTailWrapper(),\n            outputData);\n}", "summary_tokens": ["create", "a", "batch", "multiple", "input", "stream", "operator", "which", "contains", "the", "following", "sub", "graph"], "project": "flink"}
{"id": 3877, "code": "public Iterable<K> keys() {\n    return Collections.unmodifiableSet(state.keySet());\n}", "summary_tokens": ["returns", "all", "the", "keys", "in", "the", "state", "in", "a", "collections", "unmodifiable", "set", "set"], "project": "flink"}
{"id": 6997, "code": "public void testResetInitFlag() throws Exception {\n    EmbeddedRocksDBStateBackend.resetRocksDBLoadedFlag();\n}", "summary_tokens": ["this", "test", "checks", "that", "the", "rocks", "db", "native", "code", "loader", "still", "responds", "to", "resetting", "the", "init", "flag"], "project": "flink"}
{"id": 1008, "code": "public static final Set<String> getLlapDaemonConfVars() {\n  return llapDaemonVarsSet;\n}", "summary_tokens": ["get", "a", "set", "containing", "configuration", "parameter", "names", "used", "by", "llap", "server", "isntances", "an", "unmodifiable", "set", "containing", "llap", "conf", "vars"], "project": "flink"}
{"id": 1473, "code": "public void setFields(\n        T0 f0,\n        T1 f1,\n        T2 f2,\n        T3 f3,\n        T4 f4,\n        T5 f5,\n        T6 f6,\n        T7 f7,\n        T8 f8,\n        T9 f9,\n        T10 f10,\n        T11 f11,\n        T12 f12) {\n    this.f0 = f0;\n    this.f1 = f1;\n    this.f2 = f2;\n    this.f3 = f3;\n    this.f4 = f4;\n    this.f5 = f5;\n    this.f6 = f6;\n    this.f7 = f7;\n    this.f8 = f8;\n    this.f9 = f9;\n    this.f10 = f10;\n    this.f11 = f11;\n    this.f12 = f12;\n}", "summary_tokens": ["sets", "new", "values", "to", "all", "fields", "of", "the", "tuple"], "project": "flink"}
{"id": 3909, "code": "private byte[] serializeInitValue(List<Long> toSerialize) throws IOException {\n    TypeSerializer<Long> serializer = listStateDesc.getElementSerializer();\n\n    ByteArrayOutputStream baos = new ByteArrayOutputStream();\n    DataOutputViewStreamWrapper view = new DataOutputViewStreamWrapper(baos);\n\n        \n    for (int i = 0; i < toSerialize.size(); i++) {\n        serializer.serialize(toSerialize.get(i), view);\n        if (i < toSerialize.size() - 1) {\n            view.writeByte(',');\n        }\n    }\n    view.flush();\n\n    return baos.toByteArray();\n}", "summary_tokens": ["copied", "from", "heap", "list", "state"], "project": "flink"}
{"id": 8269, "code": "static InputFormatProvider of(InputFormat<RowData, ?> inputFormat) {\n    return new InputFormatProvider() {\n        @Override\n        public InputFormat<RowData, ?> createInputFormat() {\n            return inputFormat;\n        }\n\n        @Override\n        public boolean isBounded() {\n            return true;\n        }\n    };\n}", "summary_tokens": ["helper", "method", "for", "creating", "a", "static", "provider"], "project": "flink"}
{"id": 1952, "code": "public static void rethrowException(Throwable t) throws Exception {\n    if (t instanceof Error) {\n        throw (Error) t;\n    } else if (t instanceof Exception) {\n        throw (Exception) t;\n    } else {\n        throw new Exception(t.getMessage(), t);\n    }\n}", "summary_tokens": ["throws", "the", "given", "throwable", "in", "scenarios", "where", "the", "signatures", "do", "allow", "to", "throw", "a", "exception"], "project": "flink"}
{"id": 1678, "code": "public static boolean isSensitive(String key) {\n    Preconditions.checkNotNull(key, \"key is null\");\n    final String keyInLower = key.toLowerCase();\n    for (String hideKey : SENSITIVE_KEYS) {\n        if (keyInLower.length() >= hideKey.length() && keyInLower.contains(hideKey)) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["check", "whether", "the", "key", "is", "a", "hidden", "key"], "project": "flink"}
{"id": 8221, "code": "public static PhysicalColumn physical(String name, DataType dataType) {\n    Preconditions.checkNotNull(name, \"Column name can not be null.\");\n    Preconditions.checkNotNull(dataType, \"Column data type can not be null.\");\n    return new PhysicalColumn(name, dataType);\n}", "summary_tokens": ["creates", "a", "regular", "table", "column", "that", "represents", "physical", "data"], "project": "flink"}
{"id": 483, "code": "public static Metric getKafkaMetric(\n        Map<MetricName, ? extends Metric> metrics,\n        Predicate<Map.Entry<MetricName, ? extends Metric>> filter) {\n    return metrics.entrySet().stream()\n            .filter(filter)\n            .map(Map.Entry::getValue)\n            .findFirst()\n            .orElseThrow(\n                    () ->\n                            new IllegalStateException(\n                                    \"Cannot find Kafka metric matching current filter.\"));\n}", "summary_tokens": ["tries", "to", "find", "the", "kafka", "metric", "in", "the", "provided", "metrics", "matching", "a", "given", "filter"], "project": "flink"}
{"id": 6654, "code": "public void testSubmitTaskFailure() throws Exception {\n    final ExecutionAttemptID eid = new ExecutionAttemptID();\n\n    final TaskDeploymentDescriptor tdd =\n            createTestTaskDeploymentDescriptor(\n                    \"test task\",\n                    eid,\n                    BlockingNoOpInvokable.class,\n                    0); \n        \n\n    try (TaskSubmissionTestEnvironment env =\n            new TaskSubmissionTestEnvironment.Builder(jobId).build()) {\n        TaskExecutorGateway tmGateway = env.getTaskExecutorGateway();\n        TaskSlotTable taskSlotTable = env.getTaskSlotTable();\n\n        taskSlotTable.allocateSlot(0, jobId, tdd.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd, env.getJobMasterId(), timeout).get();\n    } catch (Exception e) {\n        assertThat(e.getCause(), instanceOf(IllegalArgumentException.class));\n    }\n}", "summary_tokens": ["tests", "that", "the", "task", "manager", "sends", "a", "proper", "exception", "back", "to", "the", "sender", "if", "the", "submit", "task", "message", "fails"], "project": "flink"}
{"id": 9364, "code": "public MapData copy(MapData from) {\n    if (from instanceof BinaryMapData) {\n        return ((BinaryMapData) from).copy();\n    } else {\n        return toBinaryMap(from);\n    }\n}", "summary_tokens": ["note", "map", "should", "be", "a", "hash", "map", "when", "we", "insert", "the", "key", "value", "pairs", "of", "the", "tree", "map", "into", "a", "hash", "map", "problems", "maybe", "occur"], "project": "flink"}
{"id": 6207, "code": "private void testCleanupReleasedPartition(boolean createView) throws Exception {\n    PipelinedSubpartition partition = createSubpartition();\n\n    BufferConsumer buffer1 = createFilledFinishedBufferConsumer(4096);\n    BufferConsumer buffer2 = createFilledFinishedBufferConsumer(4096);\n    boolean buffer1Recycled;\n    boolean buffer2Recycled;\n    try {\n        partition.add(buffer1);\n        partition.add(buffer2);\n        assertEquals(2, partition.getNumberOfQueuedBuffers());\n\n            \n        ResultSubpartitionView view = null;\n        if (createView) {\n            view = partition.createReadView(new NoOpBufferAvailablityListener());\n        }\n\n        partition.release();\n        assertEquals(0, partition.getNumberOfQueuedBuffers());\n\n        assertTrue(partition.isReleased());\n        if (createView) {\n            assertTrue(view.isReleased());\n        }\n        assertTrue(buffer1.isRecycled());\n    } finally {\n        buffer1Recycled = buffer1.isRecycled();\n        if (!buffer1Recycled) {\n            buffer1.close();\n        }\n        buffer2Recycled = buffer2.isRecycled();\n        if (!buffer2Recycled) {\n            buffer2.close();\n        }\n    }\n    if (!buffer1Recycled) {\n        Assert.fail(\"buffer 1 not recycled\");\n    }\n    if (!buffer2Recycled) {\n        Assert.fail(\"buffer 2 not recycled\");\n    }\n    assertEquals(2, partition.getTotalNumberOfBuffersUnsafe());\n    assertEquals(0, partition.getTotalNumberOfBytesUnsafe()); \n}", "summary_tokens": ["tests", "cleanup", "of", "pipelined", "subpartition", "release"], "project": "flink"}
{"id": 7568, "code": "public void endOperatorInput(int inputId) throws Exception {\n    if (wrapped instanceof BoundedOneInput) {\n        ((BoundedOneInput) wrapped).endInput();\n    } else if (wrapped instanceof BoundedMultiInput) {\n        ((BoundedMultiInput) wrapped).endInput(inputId);\n    }\n}", "summary_tokens": ["ends", "an", "input", "of", "the", "operator", "contained", "by", "this", "wrapper"], "project": "flink"}
{"id": 5436, "code": "public CompletableFuture<Void> dispose() {\n\n    Collection<Map.Entry<Long, TaskStateSnapshot>> statesCopy;\n\n    synchronized (lock) {\n        disposed = true;\n        statesCopy = new ArrayList<>(storedTaskStateByCheckpointID.entrySet());\n        storedTaskStateByCheckpointID.clear();\n    }\n\n    return CompletableFuture.runAsync(\n            () -> {\n                    \n                syncDiscardLocalStateForCollection(statesCopy);\n\n                    \n                LocalRecoveryDirectoryProvider directoryProvider =\n                        localRecoveryConfig.getLocalStateDirectoryProvider();\n                for (int i = 0; i < directoryProvider.allocationBaseDirsCount(); ++i) {\n                    File subtaskBaseDirectory = directoryProvider.selectSubtaskBaseDirectory(i);\n                    try {\n                        deleteDirectory(subtaskBaseDirectory);\n                    } catch (IOException e) {\n                        LOG.warn(\n                                \"Exception when deleting local recovery subtask base directory {} in subtask ({} - {} - {})\",\n                                subtaskBaseDirectory,\n                                jobID,\n                                jobVertexID,\n                                subtaskIndex,\n                                e);\n                    }\n                }\n            },\n            discardExecutor);\n}", "summary_tokens": ["disposes", "the", "state", "of", "all", "local", "snapshots", "managed", "by", "this", "object"], "project": "flink"}
{"id": 5146, "code": "private boolean clearStateForWorker(ResourceID resourceId) {\n    WorkerType worker = workerNodeMap.remove(resourceId);\n    if (worker == null) {\n        log.debug(\"Ignore unrecognized worker {}.\", resourceId.getStringWithMetadata());\n        return false;\n    }\n\n    WorkerResourceSpec workerResourceSpec =\n            currentAttemptUnregisteredWorkers.remove(resourceId);\n    previousAttemptUnregisteredWorkers.remove(resourceId);\n    if (workerResourceSpec != null) {\n        final int count = pendingWorkerCounter.decreaseAndGet(workerResourceSpec);\n        log.info(\n                \"Worker {} with resource spec {} was requested in current attempt and has not registered.\"\n                        + \" Current pending count after removing: {}.\",\n                resourceId.getStringWithMetadata(),\n                workerResourceSpec,\n                count);\n    }\n    return true;\n}", "summary_tokens": ["clear", "states", "for", "a", "terminated", "worker"], "project": "flink"}
{"id": 3852, "code": "public void reset() {\n    valueVector.reset();\n    count = 0;\n}", "summary_tokens": ["resets", "the", "state", "of", "the", "writer", "to", "write", "the", "next", "batch", "of", "fields"], "project": "flink"}
{"id": 269, "code": "public static List<Path> listTaskTemporaryPaths(FileSystem fs, Path basePath) throws Exception {\n    List<Path> taskTmpPaths = new ArrayList<>();\n\n    for (FileStatus taskStatus : fs.listStatus(basePath)) {\n        if (isTaskDir(taskStatus.getPath().getName())) {\n            taskTmpPaths.add(taskStatus.getPath());\n        }\n    }\n    return taskTmpPaths;\n}", "summary_tokens": ["returns", "task", "temporary", "paths", "in", "this", "checkpoint"], "project": "flink"}
{"id": 7005, "code": "public void testNonFileSchemePath() throws Exception {\n    String checkpointPath = tempFolder.newFolder().toURI().toString();\n    RocksDBStateBackend rocksDbBackend = new RocksDBStateBackend(checkpointPath);\n    rocksDbBackend.setDbStoragePath(\"hdfs:///some/path/to/perdition\");\n}", "summary_tokens": ["validates", "that", "schemes", "other", "than", "file", "are", "not", "allowed"], "project": "flink"}
{"id": 3086, "code": "public Pattern<T, F> times(int from, int to) {\n    checkIfNoNotPattern();\n    checkIfQuantifierApplied();\n    this.quantifier = Quantifier.times(quantifier.getConsumingStrategy());\n    if (from == 0) {\n        this.quantifier.optional();\n        from = 1;\n    }\n    this.times = Times.of(from, to);\n    return this;\n}", "summary_tokens": ["specifies", "that", "the", "pattern", "can", "occur", "between", "from", "and", "to", "times"], "project": "flink"}
{"id": 2177, "code": "public void testReconfigureWithDifferentPojoType() throws Exception {\n    PojoSerializer<SubTestUserClassB> pojoSerializer1 =\n            (PojoSerializer<SubTestUserClassB>)\n                    TypeExtractor.getForClass(SubTestUserClassB.class)\n                            .createSerializer(new ExecutionConfig());\n\n        \n    TypeSerializerSnapshot pojoSerializerConfigSnapshot =\n            pojoSerializer1.snapshotConfiguration();\n    byte[] serializedConfig;\n    try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n        TypeSerializerSnapshotSerializationUtil.writeSerializerSnapshot(\n                new DataOutputViewStreamWrapper(out),\n                pojoSerializerConfigSnapshot,\n                pojoSerializer1);\n        serializedConfig = out.toByteArray();\n    }\n\n    PojoSerializer<SubTestUserClassA> pojoSerializer2 =\n            (PojoSerializer<SubTestUserClassA>)\n                    TypeExtractor.getForClass(SubTestUserClassA.class)\n                            .createSerializer(new ExecutionConfig());\n\n        \n    try (ByteArrayInputStream in = new ByteArrayInputStream(serializedConfig)) {\n        pojoSerializerConfigSnapshot =\n                TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(\n                        new DataInputViewStreamWrapper(in),\n                        Thread.currentThread().getContextClassLoader(),\n                        pojoSerializer2);\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    TypeSerializerSchemaCompatibility<SubTestUserClassA> compatResult =\n            pojoSerializerConfigSnapshot.resolveSchemaCompatibility(pojoSerializer2);\n    assertTrue(compatResult.isIncompatible());\n}", "summary_tokens": ["verifies", "that", "reconfiguring", "with", "a", "config", "snapshot", "of", "a", "preceding", "pojo", "serializer", "with", "different", "pojo", "type", "will", "result", "in", "incompatible"], "project": "flink"}
{"id": 2789, "code": "public Partitioner<?> getPartitioner() {\n    return customPartitioner;\n}", "summary_tokens": ["gets", "the", "custom", "partitioner", "used", "by", "this", "join", "or", "null", "if", "none", "is", "set"], "project": "flink"}
{"id": 7754, "code": "private void testMultiChaining(StreamExecutionEnvironment env) throws Exception {\n\n        \n        \n    env.setParallelism(2);\n\n        \n    DataStream<Integer> input = env.fromElements(1, 2, 3);\n\n    sink1Results = new ArrayList<>();\n    sink2Results = new ArrayList<>();\n\n    input = input.map(value -> value);\n\n    input.map(value -> \"First: \" + value)\n            .addSink(\n                    new SinkFunction<String>() {\n\n                        @Override\n                        public void invoke(String value, Context ctx) throws Exception {\n                            sink1Results.add(value);\n                        }\n                    });\n\n    input.map(value -> \"Second: \" + value)\n            .addSink(\n                    new SinkFunction<String>() {\n\n                        @Override\n                        public void invoke(String value, Context ctx) throws Exception {\n                            sink2Results.add(value);\n                        }\n                    });\n\n        \n    JobGraph jobGraph = env.getStreamGraph().getJobGraph();\n\n    Assert.assertTrue(jobGraph.getVerticesSortedTopologicallyFromSources().size() == 2);\n\n    JobVertex chainedVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(1);\n\n    Configuration configuration = chainedVertex.getConfiguration();\n\n    StreamConfig streamConfig = new StreamConfig(configuration);\n\n    StreamMap<Integer, Integer> headOperator =\n            streamConfig.getStreamOperator(Thread.currentThread().getContextClassLoader());\n\n    try (MockEnvironment environment = createMockEnvironment(chainedVertex.getName())) {\n        StreamTask<Integer, StreamMap<Integer, Integer>> mockTask =\n                createMockTask(streamConfig, environment);\n        OperatorChain<Integer, StreamMap<Integer, Integer>> operatorChain =\n                createOperatorChain(streamConfig, environment, mockTask);\n\n        headOperator.setup(mockTask, streamConfig, operatorChain.getMainOperatorOutput());\n\n        operatorChain.initializeStateAndOpenOperators(null);\n\n        headOperator.processElement(new StreamRecord<>(1));\n        headOperator.processElement(new StreamRecord<>(2));\n        headOperator.processElement(new StreamRecord<>(3));\n\n        assertThat(sink1Results, contains(\"First: 1\", \"First: 2\", \"First: 3\"));\n        assertThat(sink2Results, contains(\"Second: 1\", \"Second: 2\", \"Second: 3\"));\n    }\n}", "summary_tokens": ["verify", "that", "multi", "chaining", "works"], "project": "flink"}
{"id": 8558, "code": "static Set<FunctionTemplate> findResultMappingTemplates(\n        Set<FunctionTemplate> globalTemplates,\n        Set<FunctionTemplate> localTemplates,\n        Function<FunctionTemplate, FunctionResultTemplate> accessor) {\n    return Stream.concat(globalTemplates.stream(), localTemplates.stream())\n            .filter(t -> t.getSignatureTemplate() != null && accessor.apply(t) != null)\n            .collect(Collectors.toCollection(LinkedHashSet::new));\n}", "summary_tokens": ["hints", "that", "map", "a", "signature", "to", "a", "result"], "project": "flink"}
{"id": 2748, "code": "public CoGroupOperator<I1, I2, OUT> withPartitioner(Partitioner<?> partitioner) {\n    if (partitioner != null) {\n        keys1.validateCustomPartitioner(partitioner, null);\n        keys2.validateCustomPartitioner(partitioner, null);\n    }\n    this.customPartitioner = getInput1().clean(partitioner);\n    return this;\n}", "summary_tokens": ["sets", "a", "custom", "partitioner", "for", "the", "co", "group", "operation"], "project": "flink"}
{"id": 495, "code": "public <T extends IN> KafkaRecordSerializationSchemaBuilder<T> setKeySerializationSchema(\n        SerializationSchema<? super T> keySerializationSchema) {\n    checkKeySerializerNotSet();\n    KafkaRecordSerializationSchemaBuilder<T> self = self();\n    self.keySerializationSchema = checkNotNull(keySerializationSchema);\n    return self;\n}", "summary_tokens": ["sets", "a", "serialization", "schema", "which", "is", "used", "to", "serialize", "the", "incoming", "element", "to", "the", "key", "of", "the", "producer", "record"], "project": "flink"}
{"id": 2128, "code": "public static <A> Consumer<A> uncheckedConsumer(ThrowingConsumer<A, ?> throwingConsumer) {\n    return (A value) -> {\n        try {\n            throwingConsumer.accept(value);\n        } catch (Throwable t) {\n            ExceptionUtils.rethrow(t);\n        }\n    };\n}", "summary_tokens": ["converts", "a", "throwing", "consumer", "into", "a", "consumer", "which", "throws", "checked", "exceptions", "as", "unchecked"], "project": "flink"}
{"id": 9147, "code": "public static int byteArrayCompare(byte[] array1, byte[] array2) {\n    for (int i = 0, j = 0; i < array1.length && j < array2.length; i++, j++) {\n        int a = (array1[i] & 0xff);\n        int b = (array2[j] & 0xff);\n        if (a != b) {\n            return a - b;\n        }\n    }\n    return array1.length - array2.length;\n}", "summary_tokens": ["compares", "two", "byte", "arrays", "in", "lexicographical", "order"], "project": "flink"}
{"id": 15, "code": "public Configuration getConfiguration() {\n    Configuration copiedConfiguration = new Configuration();\n\n    copiedConfiguration.addAll(configuration);\n\n    return copiedConfiguration;\n}", "summary_tokens": ["getter", "which", "returns", "a", "copy", "of", "the", "associated", "configuration"], "project": "flink"}
{"id": 3258, "code": "public Graph<KT, VVT, Tuple2<EV, EV>> projectionTopSimple() {\n    DataSet<Edge<KT, Tuple2<EV, EV>>> newEdges =\n            edges.join(edges)\n                    .where(1)\n                    .equalTo(1)\n                    .with(new ProjectionTopSimple<>())\n                    .name(\"Simple top projection\");\n\n    return Graph.fromDataSet(topVertices, newEdges, context);\n}", "summary_tokens": ["convert", "a", "bipartite", "graph", "into", "an", "undirected", "graph", "that", "contains", "only", "top", "vertices"], "project": "flink"}
{"id": 7009, "code": "public void testMultiThreadRestoreThreadPoolExceptionRethrow() {\n    SpecifiedException expectedException =\n            new SpecifiedException(\"throw exception while multi thread restore.\");\n    StreamStateHandle stateHandle = new ThrowingStateHandle(expectedException);\n\n    Map<StateHandleID, StreamStateHandle> stateHandles = new HashMap<>(1);\n    stateHandles.put(new StateHandleID(\"state1\"), stateHandle);\n\n    IncrementalRemoteKeyedStateHandle incrementalKeyedStateHandle =\n            new IncrementalRemoteKeyedStateHandle(\n                    UUID.randomUUID(),\n                    KeyGroupRange.EMPTY_KEY_GROUP_RANGE,\n                    1,\n                    stateHandles,\n                    stateHandles,\n                    stateHandle);\n\n    try (RocksDBStateDownloader rocksDBStateDownloader = new RocksDBStateDownloader(5)) {\n        rocksDBStateDownloader.transferAllStateDataToDirectory(\n                incrementalKeyedStateHandle,\n                temporaryFolder.newFolder().toPath(),\n                new CloseableRegistry());\n        fail();\n    } catch (Exception e) {\n        assertEquals(expectedException, e);\n    }\n}", "summary_tokens": ["test", "that", "the", "exception", "arose", "in", "the", "thread", "pool", "will", "rethrow", "to", "the", "main", "thread"], "project": "flink"}
{"id": 814, "code": "private int adaptRecordsToRead(\n        long runLoopTimeNanos,\n        int numRecords,\n        long recordBatchSizeBytes,\n        int maxNumberOfRecordsPerFetch) {\n    if (numRecords != 0 && runLoopTimeNanos != 0) {\n        long averageRecordSizeBytes = recordBatchSizeBytes / numRecords;\n            \n            \n            \n        double loopFrequencyHz = 1000000000.0d / runLoopTimeNanos;\n        double bytesPerRead = KINESIS_SHARD_BYTES_PER_SECOND_LIMIT / loopFrequencyHz;\n        maxNumberOfRecordsPerFetch = (int) (bytesPerRead / averageRecordSizeBytes);\n            \n        maxNumberOfRecordsPerFetch =\n                Math.max(\n                        1,\n                        Math.min(\n                                maxNumberOfRecordsPerFetch,\n                                ConsumerConfigConstants.DEFAULT_SHARD_GETRECORDS_MAX));\n\n            \n        metricsReporter.setLoopFrequencyHz(loopFrequencyHz);\n        metricsReporter.setBytesPerRead(bytesPerRead);\n    }\n    return maxNumberOfRecordsPerFetch;\n}", "summary_tokens": ["calculates", "how", "many", "records", "to", "read", "each", "time", "through", "the", "loop", "based", "on", "a", "target", "throughput", "and", "the", "measured", "frequenecy", "of", "the", "loop"], "project": "flink"}
{"id": 2773, "code": "public DeltaIteration<ST, WT> registerAggregator(String name, Aggregator<?> aggregator) {\n    this.aggregators.registerAggregator(name, aggregator);\n    return this;\n}", "summary_tokens": ["registers", "an", "aggregator", "for", "the", "iteration"], "project": "flink"}
{"id": 2159, "code": "public void testSerializeConfigurationSnapshots() throws Exception {\n    TypeSerializerSerializationUtilTest.TestConfigSnapshot<String> configSnapshot1 =\n            new TypeSerializerSerializationUtilTest.TestConfigSnapshot<>(1, \"foo\");\n\n    byte[] serializedConfig;\n    try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n        TypeSerializerSnapshotSerializationUtil.writeSerializerSnapshot(\n                new DataOutputViewStreamWrapper(out),\n                configSnapshot1,\n                StringSerializer.INSTANCE);\n\n        serializedConfig = out.toByteArray();\n    }\n\n    TypeSerializerSnapshot<?> restoredConfigs;\n    try (ByteArrayInputStream in = new ByteArrayInputStream(serializedConfig)) {\n        restoredConfigs =\n                TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(\n                        new DataInputViewStreamWrapper(in),\n                        Thread.currentThread().getContextClassLoader(),\n                        null);\n    }\n\n    assertEquals(configSnapshot1, restoredConfigs);\n}", "summary_tokens": ["verifies", "that", "reading", "and", "writing", "configuration", "snapshots", "work", "correctly"], "project": "flink"}
{"id": 6103, "code": "public void testConcurrentRevokeLeadershipAndShutdown() throws Exception {\n    final EmbeddedLeaderService embeddedLeaderService =\n            new EmbeddedLeaderService(TestingUtils.defaultExecutor());\n\n    try {\n        final LeaderElectionService leaderElectionService =\n                embeddedLeaderService.createLeaderElectionService();\n\n        final TestingLeaderContender contender = new TestingLeaderContender();\n\n        leaderElectionService.start(contender);\n\n            \n        contender.getLeaderSessionFuture().get();\n\n        final CompletableFuture<Void> revokeLeadershipFuture =\n                embeddedLeaderService.revokeLeadership();\n        leaderElectionService.stop();\n\n        try {\n                \n            revokeLeadershipFuture.get(10L, TimeUnit.MILLISECONDS);\n        } catch (TimeoutException ignored) {\n                \n        }\n\n            \n        Assert.assertThat(embeddedLeaderService.isShutdown(), is(false));\n    } finally {\n        embeddedLeaderService.shutdown();\n    }\n}", "summary_tokens": ["tests", "that", "the", "embedded", "leader", "service", "can", "handle", "a", "concurrent", "revoke", "leadership", "call", "and", "a", "shutdown"], "project": "flink"}
{"id": 1570, "code": "public static Type extractTypeFromLambda(\n        Class<?> baseClass,\n        LambdaExecutable exec,\n        int[] lambdaTypeArgumentIndices,\n        int paramLen,\n        int baseParametersLen) {\n    Type output =\n            exec.getParameterTypes()[\n                    paramLen - baseParametersLen + lambdaTypeArgumentIndices[0]];\n    for (int i = 1; i < lambdaTypeArgumentIndices.length; i++) {\n        validateLambdaType(baseClass, output);\n        output = extractTypeArgument(output, lambdaTypeArgumentIndices[i]);\n    }\n    validateLambdaType(baseClass, output);\n    return output;\n}", "summary_tokens": ["extracts", "type", "from", "given", "index", "from", "lambda"], "project": "flink"}
{"id": 3882, "code": "public static <T> byte[] serializeValue(T value, TypeSerializer<T> serializer)\n        throws IOException {\n    if (value != null) {\n            \n        DataOutputSerializer dos = new DataOutputSerializer(32);\n        serializer.serialize(value, dos);\n        return dos.getCopyOfBuffer();\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["serializes", "the", "value", "with", "the", "given", "serializer"], "project": "flink"}
{"id": 3510, "code": "public F removeOperator(String uid) {\n    metadata.removeOperator(uid);\n    return (F) this;\n}", "summary_tokens": ["drop", "an", "existing", "operator", "from", "the", "savepoint"], "project": "flink"}
{"id": 5154, "code": "private int internalTryAllocateSlots(\n        JobID jobId, String targetAddress, ResourceRequirement resourceRequirement) {\n    final ResourceProfile requiredResource = resourceRequirement.getResourceProfile();\n    Collection<TaskManagerSlotInformation> freeSlots = slotTracker.getFreeSlots();\n\n    int numUnfulfilled = 0;\n    for (int x = 0; x < resourceRequirement.getNumberOfRequiredSlots(); x++) {\n\n        final Optional<TaskManagerSlotInformation> reservedSlot =\n                slotMatchingStrategy.findMatchingSlot(\n                        requiredResource, freeSlots, this::getNumberRegisteredSlotsOf);\n        if (reservedSlot.isPresent()) {\n                \n                \n            allocateSlot(reservedSlot.get(), jobId, targetAddress, requiredResource);\n        } else {\n                \n            int numRemaining = resourceRequirement.getNumberOfRequiredSlots() - x;\n            numUnfulfilled += numRemaining;\n            break;\n        }\n    }\n    return numUnfulfilled;\n}", "summary_tokens": ["tries", "to", "allocate", "slots", "for", "the", "given", "requirement"], "project": "flink"}
{"id": 1300, "code": "public boolean isSolutionSetUnManaged() {\n    return solutionSetUnManaged;\n}", "summary_tokens": ["gets", "whether", "the", "solution", "set", "is", "in", "managed", "or", "unmanaged", "memory"], "project": "flink"}
{"id": 2993, "code": "public static Map<String, String> getTaskManagerSelectors(String clusterId) {\n    final Map<String, String> labels = getCommonLabels(clusterId);\n    labels.put(Constants.LABEL_COMPONENT_KEY, Constants.LABEL_COMPONENT_TASK_MANAGER);\n    return Collections.unmodifiableMap(labels);\n}", "summary_tokens": ["get", "task", "manager", "selectors", "for", "the", "current", "flink", "cluster"], "project": "flink"}
{"id": 9166, "code": "public void ensureNumBuffersReturned(final int minRequiredAvailable) {\n    if (minRequiredAvailable > internalPool.freePages() + this.buildSpillRetBufferNumbers) {\n        throw new IllegalArgumentException(\n                \"More buffers requested available than totally available.\");\n    }\n\n    try {\n        while (internalPool.freePages() < minRequiredAvailable) {\n            returnPage(this.buildSpillReturnBuffers.take());\n            this.buildSpillRetBufferNumbers--;\n        }\n    } catch (InterruptedException iex) {\n        throw new RuntimeException(\"Hash Join was interrupted.\");\n    }\n}", "summary_tokens": ["this", "method", "makes", "sure", "that", "at", "least", "a", "certain", "number", "of", "memory", "segments", "is", "in", "the", "list", "of", "free", "segments"], "project": "flink"}
{"id": 9681, "code": "private void generateOrderedTimelyTimestamps(long minTimestamp, int onTimeEventCountInSession) {\n    long generatedTimestamp = minTimestamp;\n\n    for (int i = 1; i < onTimeEventCountInSession; ++i) {\n        orderedTimelyTimestamps.add(generatedTimestamp);\n        generatedTimestamp += randomGenerator.randomLongBetween(0, getGap() - 1);\n    }\n\n    orderedTimelyTimestamps.add(generatedTimestamp);\n}", "summary_tokens": ["pre", "computes", "and", "stores", "the", "timestamps", "for", "timely", "events", "in", "this", "session", "in", "a", "list", "ordered"], "project": "flink"}
{"id": 8114, "code": "public static Planner createPlanner(\n        String plannerIdentifier,\n        Executor executor,\n        TableConfig tableConfig,\n        ModuleManager moduleManager,\n        CatalogManager catalogManager,\n        FunctionCatalog functionCatalog) {\n    final PlannerFactory plannerFactory =\n            FactoryUtil.discoverFactory(\n                    Thread.currentThread().getContextClassLoader(),\n                    PlannerFactory.class,\n                    plannerIdentifier);\n\n    final Context context =\n            new DefaultPlannerContext(\n                    executor, tableConfig, moduleManager, catalogManager, functionCatalog);\n    return plannerFactory.create(context);\n}", "summary_tokens": ["discovers", "a", "planner", "factory", "and", "creates", "a", "planner", "instance"], "project": "flink"}
{"id": 5002, "code": "public void open() {\n    open(calcInitialNumBucketSegments());\n}", "summary_tokens": ["initialize", "the", "hash", "table"], "project": "flink"}
{"id": 7537, "code": "protected void deleteCleanupTimer(W window) {\n    long cleanupTime = cleanupTime(window);\n    if (cleanupTime == Long.MAX_VALUE) {\n            \n        return;\n    }\n    if (windowAssigner.isEventTime()) {\n        triggerContext.deleteEventTimeTimer(cleanupTime);\n    } else {\n        triggerContext.deleteProcessingTimeTimer(cleanupTime);\n    }\n}", "summary_tokens": ["deletes", "the", "cleanup", "timer", "set", "for", "the", "contents", "of", "the", "provided", "window"], "project": "flink"}
{"id": 4033, "code": "protected <V> CompletableFuture<V> callAsyncWithoutFencing(Callable<V> callable, Time timeout) {\n    if (rpcServer instanceof FencedMainThreadExecutable) {\n        return ((FencedMainThreadExecutable) rpcServer)\n                .callAsyncWithoutFencing(callable, timeout);\n    } else {\n        throw new RuntimeException(\n                \"FencedRpcEndpoint has not been started with a FencedMainThreadExecutable RpcServer.\");\n    }\n}", "summary_tokens": ["run", "the", "given", "callable", "in", "the", "main", "thread", "of", "the", "rpc", "endpoint", "without", "checking", "the", "fencing", "token"], "project": "flink"}
{"id": 2341, "code": "public void setInt(String name, int value) {\n    set(name, Integer.toString(value));\n}", "summary_tokens": ["set", "the", "value", "of", "the", "code", "name", "code", "property", "to", "an", "code", "int", "code"], "project": "flink"}
{"id": 6651, "code": "public void testJobRecoveryWithFailingTaskExecutor() throws Exception {\n    final JobGraph jobGraph = createJobGraphWithRestartStrategy(PARALLELISM);\n\n    final CompletableFuture<JobResult> jobResultFuture = submitJobAndWaitUntilRunning(jobGraph);\n\n        \n    miniCluster.startTaskManager();\n\n    miniCluster.terminateTaskManager(0).get(); \n\n    BlockingOperator.unblock();\n\n    assertThat(jobResultFuture.get().isSuccess(), is(true));\n}", "summary_tokens": ["tests", "that", "the", "job", "can", "recover", "from", "a", "failing", "task", "executor"], "project": "flink"}
{"id": 6062, "code": "public void testUnrecoverableErrorCheck() {\n        \n    assertFalse(ExecutionFailureHandler.isUnrecoverableError(new Exception()));\n\n        \n    assertTrue(\n            ExecutionFailureHandler.isUnrecoverableError(\n                    new SuppressRestartsException(new Exception())));\n\n        \n    assertTrue(\n            ExecutionFailureHandler.isUnrecoverableError(\n                    new Exception(new SuppressRestartsException(new Exception()))));\n}", "summary_tokens": ["tests", "the", "check", "for", "unrecoverable", "error"], "project": "flink"}
{"id": 7071, "code": "public AllWindowedStream<T, TimeWindow> timeWindowAll(Time size, Time slide) {\n    if (environment.getStreamTimeCharacteristic() == TimeCharacteristic.ProcessingTime) {\n        return windowAll(SlidingProcessingTimeWindows.of(size, slide));\n    } else {\n        return windowAll(SlidingEventTimeWindows.of(size, slide));\n    }\n}", "summary_tokens": ["windows", "this", "data", "stream", "into", "sliding", "time", "windows"], "project": "flink"}
{"id": 1281, "code": "public void setGroupOrderForInputOne(Ordering order) {\n    setGroupOrder(0, order);\n}", "summary_tokens": ["sets", "the", "order", "of", "the", "elements", "within", "a", "group", "for", "the", "first", "input"], "project": "flink"}
{"id": 5794, "code": "public void testUntrackBlobWithNullJobId() {\n    tracker.untrack(Tuple2.of(null, BlobKey.createKey(BlobType.PERMANENT_BLOB)));\n}", "summary_tokens": ["since", "the", "blob", "cache", "size", "limit", "tracker", "only", "works", "in", "permanent", "blob", "cache", "the", "job", "id", "shouldn", "t", "be", "null"], "project": "flink"}
{"id": 5596, "code": "public Throwable getError(ClassLoader userCodeClassloader) {\n    if (this.throwable == null) {\n        return null;\n    } else {\n        return this.throwable.deserializeError(userCodeClassloader);\n    }\n}", "summary_tokens": ["gets", "the", "attached", "exception", "which", "is", "in", "serialized", "form"], "project": "flink"}
{"id": 662, "code": "public void testSetFilterRestoredParitionsWithAddedTopic() throws Exception {\n    checkFilterRestoredPartitionsWithDisovered(\n            Arrays.asList(new String[] {\"kafka_topic_1\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            Arrays.asList(new String[] {\"kafka_topic_1\", \"kafka_topic_2\"}),\n            false);\n}", "summary_tokens": ["tests", "that", "newly", "added", "partitions", "will", "be", "added", "to", "subscribed", "partitions"], "project": "flink"}
{"id": 4589, "code": "void onNewMessageReceived(int msgId, int messageLength) {\n    this.msgId = msgId;\n    this.messageLength = messageLength;\n}", "summary_tokens": ["notifies", "that", "a", "new", "message", "is", "to", "be", "decoded"], "project": "flink"}
{"id": 3978, "code": "protected Object envelopeSelfMessage(Object message) {\n    return message;\n}", "summary_tokens": ["hook", "to", "envelope", "self", "messages"], "project": "flink"}
{"id": 6565, "code": "public void exists() throws Exception {\n    File folderRoot = temporaryFolder.getRoot();\n    File folderA = new File(folderRoot, String.valueOf(UUID.randomUUID()));\n\n    Assert.assertFalse(folderA.isDirectory());\n    Path path = folderA.toPath();\n    SnapshotDirectory snapshotDirectory = SnapshotDirectory.permanent(path);\n    Assert.assertFalse(snapshotDirectory.exists());\n    Assert.assertTrue(folderA.mkdirs());\n    Assert.assertTrue(snapshotDirectory.exists());\n    Assert.assertTrue(folderA.delete());\n    Assert.assertFalse(snapshotDirectory.exists());\n}", "summary_tokens": ["tests", "if", "indication", "of", "directory", "existence", "works"], "project": "flink"}
{"id": 10, "code": "public static DescribedPredicate<JavaClass> areJavaClasses() {\n    return new DescribedPredicate<JavaClass>(\"are Java classes\") {\n        @Override\n        public boolean apply(JavaClass clazz) {\n            return isJavaClass(clazz);\n        }\n    };\n}", "summary_tokens": ["tests", "that", "a", "given", "class", "is", "a", "java", "class"], "project": "flink"}
{"id": 2829, "code": "public <R> GroupCombineOperator<T, R> combineGroup(GroupCombineFunction<T, R> combiner) {\n    if (combiner == null) {\n        throw new NullPointerException(\"GroupCombine function must not be null.\");\n    }\n    TypeInformation<R> resultType =\n            TypeExtractor.getGroupCombineReturnTypes(\n                    combiner,\n                    this.getInputDataSet().getType(),\n                    Utils.getCallLocationName(),\n                    true);\n\n    return new GroupCombineOperator<T, R>(\n            this, resultType, inputDataSet.clean(combiner), Utils.getCallLocationName());\n}", "summary_tokens": ["applies", "a", "group", "combine", "function", "on", "a", "grouped", "data", "set"], "project": "flink"}
{"id": 9756, "code": "public void testCopyFromLocalRecursiveWithoutScheme() throws Exception {\n    final FileSystem targetFileSystem = hdfsRootPath.getFileSystem(hadoopConfig);\n    final Path targetDir = targetFileSystem.getWorkingDirectory();\n\n    testRegisterMultipleLocalResources(\n            targetFileSystem, targetDir, LOCAL_RESOURCE_DIRECTORY, tempFolder, false, false);\n}", "summary_tokens": ["verifies", "that", "nested", "directories", "are", "properly", "copied", "with", "a", "tt", "hdfs", "tt", "file", "system", "from", "a", "tt", "absolute", "path", "tt", "source", "path"], "project": "flink"}
{"id": 1237, "code": "public void accept(Visitor<Operator<?>> visitor) {\n    if (visitor.preVisit(this)) {\n        visitor.postVisit(this);\n    }\n}", "summary_tokens": ["accepts", "the", "visitor", "and", "applies", "it", "this", "instance"], "project": "flink"}
{"id": 4100, "code": "public static List<PermanentBlobKey> uploadFiles(\n        InetSocketAddress serverAddress,\n        Configuration clientConfig,\n        JobID jobId,\n        List<Path> files)\n        throws IOException {\n\n    checkNotNull(jobId);\n\n    if (files.isEmpty()) {\n        return Collections.emptyList();\n    } else {\n        List<PermanentBlobKey> blobKeys = new ArrayList<>();\n\n        try (BlobClient blobClient = new BlobClient(serverAddress, clientConfig)) {\n            for (final Path file : files) {\n                final PermanentBlobKey key = blobClient.uploadFile(jobId, file);\n                blobKeys.add(key);\n            }\n        }\n\n        return blobKeys;\n    }\n}", "summary_tokens": ["uploads", "the", "jar", "files", "to", "the", "permanent", "blob", "service", "of", "the", "blob", "server", "at", "the", "given", "address", "with", "ha", "as", "configured"], "project": "flink"}
{"id": 7146, "code": "public <T0, T1, T2, T3, T4, T5, T6>\n        SingleOutputStreamOperator<Tuple7<T0, T1, T2, T3, T4, T5, T6>> projectTuple7() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<Tuple7<T0, T1, T2, T3, T4, T5, T6>> tType =\n            new TupleTypeInfo<Tuple7<T0, T1, T2, T3, T4, T5, T6>>(fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<IN, Tuple7<T0, T1, T2, T3, T4, T5, T6>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 5706, "code": "default CompletableFuture<CoordinationResponse> deliverCoordinationRequestToCoordinator(\n        JobID jobId,\n        OperatorID operatorId,\n        SerializedValue<CoordinationRequest> serializedRequest,\n        @RpcTimeout Time timeout) {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["deliver", "a", "coordination", "request", "to", "a", "specified", "coordinator", "and", "return", "the", "response"], "project": "flink"}
{"id": 4936, "code": "protected void initBroadcastInputReaders() throws Exception {\n    final int numBroadcastInputs = this.config.getNumBroadcastInputs();\n    final MutableReader<?>[] broadcastInputReaders = new MutableReader<?>[numBroadcastInputs];\n\n    int currentReaderOffset = config.getNumInputs();\n\n    for (int i = 0; i < this.config.getNumBroadcastInputs(); i++) {\n            \n            \n        final int groupSize = this.config.getBroadcastGroupSize(i);\n        if (groupSize == 1) {\n                \n            broadcastInputReaders[i] =\n                    new MutableRecordReader<>(\n                            getEnvironment().getInputGate(currentReaderOffset),\n                            getEnvironment().getTaskManagerInfo().getTmpDirectories());\n        } else if (groupSize > 1) {\n                \n            IndexedInputGate[] readers = new IndexedInputGate[groupSize];\n            for (int j = 0; j < groupSize; ++j) {\n                readers[j] = getEnvironment().getInputGate(currentReaderOffset + j);\n            }\n            broadcastInputReaders[i] =\n                    new MutableRecordReader<>(\n                            new UnionInputGate(readers),\n                            getEnvironment().getTaskManagerInfo().getTmpDirectories());\n        } else {\n            throw new Exception(\"Illegal input group size in task configuration: \" + groupSize);\n        }\n\n        currentReaderOffset += groupSize;\n    }\n    this.broadcastInputReaders = broadcastInputReaders;\n}", "summary_tokens": ["creates", "the", "record", "readers", "for", "the", "extra", "broadcast", "inputs", "as", "configured", "by", "task", "config", "get", "num", "broadcast", "inputs"], "project": "flink"}
{"id": 562, "code": "public void setLogFailuresOnly(boolean logFailuresOnly) {\n    this.logFailuresOnly = logFailuresOnly;\n}", "summary_tokens": ["defines", "whether", "the", "producer", "should", "fail", "on", "errors", "or", "only", "log", "them"], "project": "flink"}
{"id": 718, "code": "public void testAssignedToPartitionFailureRecoveryProcessingTime() throws Exception {\n    testAssignedToPartitionFailureRecovery(500, ProcessingTime);\n}", "summary_tokens": ["failure", "recovery", "after", "data", "is", "repartitioned", "with", "time", "characteristic", "processing", "time"], "project": "flink"}
{"id": 5849, "code": "static void verifyDeleted(BlobService service, @Nullable JobID jobId, BlobKey key)\n        throws IOException {\n    try {\n        get(service, jobId, key);\n        fail(\"File \" + jobId + \"/\" + key + \" should have been deleted.\");\n    } catch (IOException e) {\n            \n    }\n}", "summary_tokens": ["checks", "that", "the", "given", "blob", "does", "not", "exist", "anymore", "by", "trying", "to", "access", "it"], "project": "flink"}
{"id": 4021, "code": "public void testScheduledExecutorServicePeriodicSchedule() throws Exception {\n    ScheduledExecutor scheduledExecutor = akkaRpcService.getScheduledExecutor();\n\n    final int tries = 4;\n    final long delay = 10L;\n    final CountDownLatch countDownLatch = new CountDownLatch(tries);\n\n    long currentTime = System.nanoTime();\n\n    ScheduledFuture<?> future =\n            scheduledExecutor.scheduleAtFixedRate(\n                    countDownLatch::countDown, delay, delay, TimeUnit.MILLISECONDS);\n\n    assertTrue(!future.isDone());\n\n    countDownLatch.await();\n\n        \n    assertTrue(!future.isDone());\n\n    long finalTime = System.nanoTime() - currentTime;\n\n        \n    assertTrue(finalTime >= tries * delay);\n\n    future.cancel(true);\n}", "summary_tokens": ["tests", "that", "the", "rpc", "service", "s", "scheduled", "executor", "service", "can", "execute", "runnables", "at", "a", "fixed", "rate"], "project": "flink"}
{"id": 3516, "code": "private @Nullable Path getStateFilePathFromStreamStateHandle(StreamStateHandle handle) {\n    if (handle instanceof FileStateHandle) {\n        return ((FileStateHandle) handle).getFilePath();\n    } else if (handle instanceof OperatorStateHandle) {\n        return getStateFilePathFromStreamStateHandle(\n                ((OperatorStateHandle) handle).getDelegateStateHandle());\n    } else if (handle instanceof KeyedStateHandle) {\n        if (handle instanceof KeyGroupsStateHandle) {\n            return getStateFilePathFromStreamStateHandle(\n                    ((KeyGroupsStateHandle) handle).getDelegateStateHandle());\n        }\n            \n            \n    }\n    return null;\n}", "summary_tokens": ["this", "method", "recursively", "looks", "for", "the", "contained", "file", "state", "handle", "s", "in", "a", "given", "stream", "state", "handle"], "project": "flink"}
{"id": 9699, "code": "public void testNonexistingQueueWARNmessage() throws Exception {\n    runTest(\n            () -> {\n                LOG.info(\"Starting testNonexistingQueueWARNmessage()\");\n                try {\n                    runWithArgs(\n                            new String[] {\n                                \"-j\",\n                                flinkUberjar.getAbsolutePath(),\n                                \"-t\",\n                                flinkLibFolder.getAbsolutePath(),\n                                \"-jm\",\n                                \"768m\",\n                                \"-tm\",\n                                \"1024m\",\n                                \"-qu\",\n                                \"doesntExist\"\n                            },\n                            \"to unknown queue: doesntExist\",\n                            null,\n                            RunTypes.YARN_SESSION,\n                            1);\n                } catch (Exception e) {\n                    assertTrue(\n                            ExceptionUtils.findThrowableWithMessage(\n                                            e, \"to unknown queue: doesntExist\")\n                                    .isPresent());\n                }\n                assertThat(\n                        yarTestLoggerResource.getMessages(),\n                        hasItem(\n                                containsString(\n                                        \"The specified queue 'doesntExist' does not exist. Available queues\")));\n                LOG.info(\"Finished testNonexistingQueueWARNmessage()\");\n            });\n}", "summary_tokens": ["test", "deployment", "to", "non", "existing", "queue", "ensure", "that", "the", "system", "logs", "a", "warn", "message", "for", "the", "user"], "project": "flink"}
{"id": 9263, "code": "private ChannelWithMeta mergeChannels(List<ChannelWithMeta> channelIDs) throws IOException {\n        \n    List<FileIOChannel> openChannels = new ArrayList<>(channelIDs.size());\n    final BinaryMergeIterator<Entry> mergeIterator =\n            getMergingIterator(channelIDs, openChannels);\n\n        \n    final FileIOChannel.ID mergedChannelID = ioManager.createChannel();\n    channelManager.addChannel(mergedChannelID);\n    AbstractChannelWriterOutputView output = null;\n\n    int numBytesInLastBlock;\n    int numBlocksWritten;\n    try {\n        output =\n                FileChannelUtil.createOutputView(\n                        ioManager,\n                        mergedChannelID,\n                        compressionEnable,\n                        compressionCodecFactory,\n                        compressionBlockSize,\n                        pageSize);\n        writeMergingOutput(mergeIterator, output);\n        numBytesInLastBlock = output.close();\n        numBlocksWritten = output.getBlockCount();\n    } catch (IOException e) {\n        if (output != null) {\n            output.close();\n            output.getChannel().deleteChannel();\n        }\n        throw e;\n    }\n\n        \n    for (FileIOChannel channel : openChannels) {\n        channelManager.removeChannel(channel.getChannelID());\n        try {\n            channel.closeAndDelete();\n        } catch (Throwable ignored) {\n        }\n    }\n\n    return new ChannelWithMeta(mergedChannelID, numBlocksWritten, numBytesInLastBlock);\n}", "summary_tokens": ["merges", "the", "sorted", "runs", "described", "by", "the", "given", "channel", "ids", "into", "a", "single", "sorted", "run"], "project": "flink"}
{"id": 7077, "code": "public DataStreamSink<T> writeAsText(String path, WriteMode writeMode) {\n    TextOutputFormat<T> tof = new TextOutputFormat<>(new Path(path));\n    tof.setWriteMode(writeMode);\n    return writeUsingOutputFormat(tof);\n}", "summary_tokens": ["writes", "a", "data", "stream", "to", "the", "file", "specified", "by", "path", "in", "text", "format"], "project": "flink"}
{"id": 8345, "code": "public static <T> RawValueData<T> readRawValueData(\n        MemorySegment[] segments, int baseOffset, long offsetAndSize) {\n    final int size = ((int) offsetAndSize);\n    int offset = (int) (offsetAndSize >> 32);\n    return new BinaryRawValueData<>(segments, offset + baseOffset, size, null);\n}", "summary_tokens": ["gets", "an", "instance", "of", "raw", "value", "data", "from", "underlying", "memory", "segment"], "project": "flink"}
{"id": 6241, "code": "public void testPartitionConnectionExceptionWhileRequestingPartition() throws Exception {\n    final RemoteInputChannel inputChannel =\n            InputChannelTestUtils.createRemoteInputChannel(\n                    createSingleInputGate(1), 0, new TestingExceptionConnectionManager());\n    try {\n        inputChannel.requestSubpartition(0);\n        fail(\"Expected PartitionConnectionException.\");\n    } catch (PartitionConnectionException ex) {\n        assertThat(inputChannel.getPartitionId(), is(ex.getPartitionId()));\n    }\n}", "summary_tokens": ["tests", "that", "any", "exceptions", "thrown", "by", "connection", "manager", "create", "partition", "request", "client", "connection", "id", "would", "be", "wrapped", "into", "partition", "connection", "exception", "during", "remote", "input", "channel", "request", "subpartition", "int"], "project": "flink"}
{"id": 4675, "code": "public int getChannelIndex() {\n    return channelInfo.getInputChannelIdx();\n}", "summary_tokens": ["returns", "the", "index", "of", "this", "channel", "within", "its", "single", "input", "gate"], "project": "flink"}
{"id": 7479, "code": "public long getEnd() {\n    return end;\n}", "summary_tokens": ["gets", "the", "end", "timestamp", "of", "this", "window"], "project": "flink"}
{"id": 8991, "code": "private Frame addProjectionForExists(Frame frame) {\n    final List<Integer> corIndices = new ArrayList<>(frame.getCorInputRefIndices());\n    final RelNode rel = frame.r;\n    final RelDataType rowType = rel.getRowType();\n    if (corIndices.size() == rowType.getFieldCount()) {\n            \n        return frame;\n    }\n\n    final List<RexNode> projects = new ArrayList<>();\n    final Map<Integer, Integer> mapInputToOutput = new HashMap<>();\n\n    Collections.sort(corIndices);\n    int newPos = 0;\n    for (int index : corIndices) {\n        projects.add(RexInputRef.of(index, rowType));\n        mapInputToOutput.put(index, newPos++);\n    }\n\n    relBuilder.clear();\n    relBuilder.push(frame.r);\n    relBuilder.project(projects);\n    final RelNode newProject = relBuilder.build();\n    final RexNode newCondition =\n            adjustInputRefs(frame.c, mapInputToOutput, newProject.getRowType());\n\n        \n    return new Frame(rel, newProject, newCondition, new HashMap<>());\n}", "summary_tokens": ["adds", "projection", "to", "choose", "the", "fields", "used", "by", "join", "condition"], "project": "flink"}
{"id": 2234, "code": "public void testRetryWithDelayRetryStrategyFailure() throws Throwable {\n    CompletableFuture<?> retryFuture =\n            FutureUtils.retryWithDelay(\n                    () ->\n                            FutureUtils.completedExceptionally(\n                                    new FlinkException(\"Test exception\")),\n                    new FixedRetryStrategy(3, Duration.ofMillis(1L)),\n                    TestingUtils.defaultScheduledExecutor());\n\n    try {\n        retryFuture.get(TestingUtils.TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);\n    } catch (ExecutionException ee) {\n        throw ExceptionUtils.stripExecutionException(ee);\n    }\n}", "summary_tokens": ["tests", "that", "retry", "with", "delay", "fails", "after", "having", "exceeded", "all", "retries"], "project": "flink"}
{"id": 314, "code": "public static boolean isSupportedType(LogicalType type) {\n        \n    switch (type.getTypeRoot()) {\n        case CHAR:\n        case VARCHAR:\n        case BOOLEAN:\n        case BINARY:\n        case VARBINARY:\n        case DECIMAL:\n        case TINYINT:\n        case SMALLINT:\n        case INTEGER:\n        case DATE:\n        case INTERVAL_YEAR_MONTH:\n        case BIGINT:\n        case INTERVAL_DAY_TIME:\n        case FLOAT:\n        case DOUBLE:\n            return true;\n        case TIME_WITHOUT_TIME_ZONE:\n            final int timePrecision = getPrecision(type);\n            if (timePrecision < MIN_TIME_PRECISION || timePrecision > MAX_TIME_PRECISION) {\n                throw new UnsupportedOperationException(\n                        String.format(\n                                \"The precision %s of TIME type is out of the range [%s, %s] supported by \"\n                                        + \"HBase connector\",\n                                timePrecision, MIN_TIME_PRECISION, MAX_TIME_PRECISION));\n            }\n            return true;\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            final int timestampPrecision = getPrecision(type);\n            if (timestampPrecision < MIN_TIMESTAMP_PRECISION\n                    || timestampPrecision > MAX_TIMESTAMP_PRECISION) {\n                throw new UnsupportedOperationException(\n                        String.format(\n                                \"The precision %s of TIMESTAMP type is out of the range [%s, %s] supported by \"\n                                        + \"HBase connector\",\n                                timestampPrecision,\n                                MIN_TIMESTAMP_PRECISION,\n                                MAX_TIMESTAMP_PRECISION));\n            }\n            return true;\n        case TIMESTAMP_WITH_TIME_ZONE:\n        case ARRAY:\n        case MULTISET:\n        case MAP:\n        case ROW:\n        case STRUCTURED_TYPE:\n        case DISTINCT_TYPE:\n        case RAW:\n        case NULL:\n        case SYMBOL:\n        case UNRESOLVED:\n            return false;\n        default:\n            throw new IllegalArgumentException();\n    }\n}", "summary_tokens": ["checks", "whether", "the", "given", "logical", "type", "is", "supported", "in", "hbase", "connector"], "project": "flink"}
{"id": 3970, "code": "protected RpcInvocation createRpcInvocationMessage(\n        final String declaringClassName,\n        final String methodName,\n        final Class<?>[] parameterTypes,\n        final Object[] args)\n        throws IOException {\n    final RpcInvocation rpcInvocation;\n\n    if (isLocal) {\n        rpcInvocation =\n                new LocalRpcInvocation(declaringClassName, methodName, parameterTypes, args);\n    } else {\n        try {\n            RemoteRpcInvocation remoteRpcInvocation =\n                    new RemoteRpcInvocation(\n                            declaringClassName, methodName, parameterTypes, args);\n\n            if (remoteRpcInvocation.getSize() > maximumFramesize) {\n                throw new IOException(\n                        String.format(\n                                \"The rpc invocation size %d exceeds the maximum akka framesize.\",\n                                remoteRpcInvocation.getSize()));\n            } else {\n                rpcInvocation = remoteRpcInvocation;\n            }\n        } catch (IOException e) {\n            LOG.warn(\n                    \"Could not create remote rpc invocation message. Failing rpc invocation because...\",\n                    e);\n            throw e;\n        }\n    }\n\n    return rpcInvocation;\n}", "summary_tokens": ["create", "the", "rpc", "invocation", "message", "for", "the", "given", "rpc"], "project": "flink"}
{"id": 1556, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple9)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple9 tuple = (Tuple9) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    if (f5 != null ? !f5.equals(tuple.f5) : tuple.f5 != null) {\n        return false;\n    }\n    if (f6 != null ? !f6.equals(tuple.f6) : tuple.f6 != null) {\n        return false;\n    }\n    if (f7 != null ? !f7.equals(tuple.f7) : tuple.f7 != null) {\n        return false;\n    }\n    if (f8 != null ? !f8.equals(tuple.f8) : tuple.f8 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 4138, "code": "static File getIncomingDirectory(File storageDir) throws IOException {\n    final File incomingDir = new File(storageDir, \"incoming\");\n\n    Files.createDirectories(incomingDir.toPath());\n\n    return incomingDir;\n}", "summary_tokens": ["returns", "the", "blob", "service", "s", "directory", "for", "incoming", "job", "unrelated", "files"], "project": "flink"}
{"id": 3618, "code": "protected void computeOperatorSpecificDefaultEstimates(DataStatistics statistics) {\n    long card1 = getFirstPredecessorNode().getEstimatedNumRecords();\n    long card2 = getSecondPredecessorNode().getEstimatedNumRecords();\n    this.estimatedNumRecords = (card1 < 0 || card2 < 0) ? -1 : Math.max(card1, card2);\n\n    if (this.estimatedNumRecords >= 0) {\n        float width1 = getFirstPredecessorNode().getEstimatedAvgWidthPerOutputRecord();\n        float width2 = getSecondPredecessorNode().getEstimatedAvgWidthPerOutputRecord();\n        float width = (width1 <= 0 || width2 <= 0) ? -1 : width1 + width2;\n\n        if (width > 0) {\n            this.estimatedOutputSize = (long) (width * this.estimatedNumRecords);\n        }\n    }\n}", "summary_tokens": ["the", "default", "estimates", "build", "on", "the", "principle", "of", "inclusion", "the", "smaller", "input", "key", "domain", "is", "included", "in", "the", "larger", "input", "key", "domain"], "project": "flink"}
{"id": 5415, "code": "public static SnapshotDirectory permanent(@Nonnull Path directory) throws IOException {\n    return new PermanentSnapshotDirectory(directory);\n}", "summary_tokens": ["creates", "a", "permanent", "snapshot", "directory", "for", "the", "given", "path", "which", "will", "not", "delete", "the", "underlying", "directory", "in", "cleanup", "after", "complete", "snapshot", "and", "get", "handle", "was", "called"], "project": "flink"}
{"id": 4145, "code": "static void readFully(InputStream inputStream, byte[] buf, int off, int len, String type)\n        throws IOException {\n\n    int bytesRead = 0;\n    while (bytesRead < len) {\n\n        final int read = inputStream.read(buf, off + bytesRead, len - bytesRead);\n        if (read < 0) {\n            throw new EOFException(\"Received an incomplete \" + type);\n        }\n        bytesRead += read;\n    }\n}", "summary_tokens": ["auxiliary", "method", "to", "read", "a", "particular", "number", "of", "bytes", "from", "an", "input", "stream"], "project": "flink"}
{"id": 9177, "code": "final boolean isInMemory() {\n    return this.buildSideChannel == null;\n}", "summary_tokens": ["checks", "whether", "this", "partition", "is", "in", "memory", "or", "spilled"], "project": "flink"}
{"id": 332, "code": "public static CatalogLock.Factory createFactory(HiveConf hiveConf) {\n    return new HiveCatalogLockFactory(hiveConf);\n}", "summary_tokens": ["create", "a", "hive", "lock", "factory"], "project": "flink"}
{"id": 1193, "code": "", "summary_tokens": ["opens", "this", "input", "format", "instance"], "project": "flink"}
{"id": 1069, "code": "public void disableForceAvro() {\n    forceAvro = false;\n}", "summary_tokens": ["disables", "the", "apache", "avro", "serializer", "as", "the", "forced", "serializer", "for", "pojos"], "project": "flink"}
{"id": 4137, "code": "static File initLocalStorageDirectory(Configuration config) throws IOException {\n\n    String basePath = config.getString(BlobServerOptions.STORAGE_DIRECTORY);\n\n    File baseDir;\n    if (StringUtils.isNullOrWhitespaceOnly(basePath)) {\n        final String[] tmpDirPaths = ConfigurationUtils.parseTempDirectories(config);\n        baseDir = new File(tmpDirPaths[RANDOM.nextInt(tmpDirPaths.length)]);\n    } else {\n        baseDir = new File(basePath);\n    }\n\n    File storageDir;\n\n        \n    int maxAttempts = 10;\n    for (int attempt = 0; attempt < maxAttempts; attempt++) {\n        storageDir =\n                new File(baseDir, String.format(\"blobStore-%s\", UUID.randomUUID().toString()));\n\n            \n            \n        if (storageDir.mkdirs()) {\n            return storageDir;\n        }\n    }\n\n        \n    throw new IOException(\n            \"Could not create storage directory for BLOB store in '\" + baseDir + \"'.\");\n}", "summary_tokens": ["creates", "a", "local", "storage", "directory", "for", "a", "blob", "service", "under", "the", "configuration", "parameter", "given", "by", "blob", "server", "options", "storage", "directory"], "project": "flink"}
{"id": 5338, "code": "void onCheckpointComplete(long checkpointId) {\n    assignmentTracker.onCheckpointComplete(checkpointId);\n}", "summary_tokens": ["invoked", "when", "a", "successful", "checkpoint", "has", "been", "taken"], "project": "flink"}
{"id": 3060, "code": "public EventId registerEvent(V value, long timestamp) throws Exception {\n    return sharedBuffer.registerEvent(value, timestamp);\n}", "summary_tokens": ["adds", "another", "unique", "event", "to", "the", "shared", "buffer", "and", "assigns", "a", "unique", "id", "for", "it"], "project": "flink"}
{"id": 6863, "code": "public DefaultConfigurableOptionsFactory setLogDir(String logDir) {\n    Preconditions.checkArgument(\n            new File(logDir).isAbsolute(),\n            \"Invalid configuration: \" + logDir + \" does not point to an absolute path.\");\n    setInternal(LOG_DIR.key(), logDir);\n    return this;\n}", "summary_tokens": ["the", "directory", "for", "rocks", "db", "s", "logging", "files"], "project": "flink"}
{"id": 8396, "code": "public Map<String, String> toProperties() {\n    DescriptorProperties properties = new DescriptorProperties();\n    List<Map<String, String>> subKeyValues = new ArrayList<>();\n    for (Map.Entry<String, LinkedHashMap<String, String>> entry : tableSchema.entrySet()) {\n        String name = entry.getKey();\n        LinkedHashMap<String, String> props = entry.getValue();\n        Map<String, String> map = new HashMap<>();\n        map.put(SCHEMA_NAME, name);\n        map.putAll(props);\n        subKeyValues.add(map);\n    }\n    properties.putIndexedVariableProperties(SCHEMA, subKeyValues);\n    return properties.asMap();\n}", "summary_tokens": ["converts", "this", "descriptor", "into", "a", "set", "of", "properties"], "project": "flink"}
{"id": 4753, "code": "public void setExecutionConfig(ExecutionConfig executionConfig) throws IOException {\n    checkNotNull(executionConfig, \"ExecutionConfig must not be null.\");\n    setSerializedExecutionConfig(new SerializedValue<>(executionConfig));\n}", "summary_tokens": ["sets", "the", "execution", "config"], "project": "flink"}
{"id": 759, "code": "protected void stopWithError(Throwable throwable) {\n    if (this.error.compareAndSet(null, throwable)) {\n        shutdownFetcher();\n    }\n}", "summary_tokens": ["called", "by", "created", "threads", "to", "pass", "on", "errors"], "project": "flink"}
{"id": 2125, "code": "public static <T> Function<T, Void> nullFn() {\n    return (Function<T, Void>) NULL_FN;\n}", "summary_tokens": ["function", "which", "returns", "null", "type", "void"], "project": "flink"}
{"id": 2146, "code": "public void testTwoNestedDirectoriesWithFilteredFilesTrue() {\n    try {\n        String firstLevelDir = TestFileUtils.randomFileName();\n        String secondLevelDir = TestFileUtils.randomFileName();\n        String thirdLevelDir = TestFileUtils.randomFileName();\n        String secondLevelFilterDir = \"_\" + TestFileUtils.randomFileName();\n        String thirdLevelFilterDir = \"_\" + TestFileUtils.randomFileName();\n\n        File nestedNestedDirFiltered =\n                tempFolder.newFolder(\n                        firstLevelDir, secondLevelDir, thirdLevelDir, thirdLevelFilterDir);\n        File nestedNestedDir = nestedNestedDirFiltered.getParentFile();\n        File insideNestedDir = nestedNestedDir.getParentFile();\n        File nestedDir = insideNestedDir.getParentFile();\n        File insideNestedDirFiltered =\n                tempFolder.newFolder(firstLevelDir, secondLevelFilterDir);\n        File filteredFile = new File(nestedDir, \"_IWillBeFiltered\");\n        filteredFile.createNewFile();\n\n            \n            \n        TestFileUtils.createTempFileInDirectory(nestedDir.getAbsolutePath(), \"paella\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"kalamari\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"fideua\");\n        TestFileUtils.createTempFileInDirectory(nestedNestedDir.getAbsolutePath(), \"bravas\");\n            \n        TestFileUtils.createTempFileInDirectory(\n                insideNestedDirFiltered.getAbsolutePath(), \"kalamari\");\n        TestFileUtils.createTempFileInDirectory(\n                insideNestedDirFiltered.getAbsolutePath(), \"fideua\");\n        TestFileUtils.createTempFileInDirectory(\n                nestedNestedDirFiltered.getAbsolutePath(), \"bravas\");\n\n        this.format.setFilePath(new Path(nestedDir.toURI().toString()));\n        this.config.setBoolean(\"recursive.file.enumeration\", true);\n        format.configure(this.config);\n\n        FileInputSplit[] splits = format.createInputSplits(1);\n        Assert.assertEquals(4, splits.length);\n    } catch (Exception ex) {\n        ex.printStackTrace();\n        Assert.fail(ex.getMessage());\n    }\n}", "summary_tokens": ["test", "with", "two", "nested", "directories", "and", "recursive"], "project": "flink"}
{"id": 6114, "code": "public void testRegisterTaskWithLimitedBuffers() throws Exception {\n        \n        \n    final int bufferCount =\n            18 + 10 * NettyShuffleEnvironmentOptions.NETWORK_BUFFERS_PER_CHANNEL.defaultValue();\n\n    testRegisterTaskWithLimitedBuffers(bufferCount);\n}", "summary_tokens": ["verifies", "that", "task", "setup", "partitions", "and", "gates", "result", "partition", "writer", "input", "gate", "sets", "up", "un", "bounded", "buffer", "pool", "instances", "for", "various", "types", "of", "input", "and", "output", "channels", "working", "with", "the", "bare", "minimum", "of", "required", "buffers"], "project": "flink"}
{"id": 9486, "code": "public void testTaskManagerFailure(\n        TestEnvironment testEnv,\n        ExternalContext<T> externalContext,\n        ClusterControllable controller)\n        throws Exception {\n    int splitIndex = 0;\n\n    LOG.info(\"Writing test data to split {}\", splitIndex);\n    final List<T> testRecordsBeforeFailure =\n            externalContext.generateTestData(\n                    splitIndex, ThreadLocalRandom.current().nextLong());\n    final SourceSplitDataWriter<T> sourceSplitDataWriter =\n            externalContext.createSourceSplitDataWriter();\n    sourceSplitDataWriter.writeRecords(testRecordsBeforeFailure);\n\n    final StreamExecutionEnvironment env = testEnv.createExecutionEnvironment();\n\n    env.enableCheckpointing(50);\n    final DataStreamSource<T> dataStreamSource =\n            env.fromSource(\n                            externalContext.createSource(Boundedness.CONTINUOUS_UNBOUNDED),\n                            WatermarkStrategy.noWatermarks(),\n                            \"Tested Source\")\n                    .setParallelism(1);\n\n        \n        \n        \n    TypeSerializer<T> serializer = dataStreamSource.getType().createSerializer(env.getConfig());\n    String accumulatorName = \"dataStreamCollect_\" + UUID.randomUUID();\n    CollectSinkOperatorFactory<T> factory =\n            new CollectSinkOperatorFactory<>(serializer, accumulatorName);\n    CollectSinkOperator<T> operator = (CollectSinkOperator<T>) factory.getOperator();\n    CollectResultIterator<T> iterator =\n            new CollectResultIterator<>(\n                    operator.getOperatorIdFuture(),\n                    serializer,\n                    accumulatorName,\n                    env.getCheckpointConfig());\n    CollectStreamSink<T> sink = new CollectStreamSink<>(dataStreamSource, factory);\n    sink.name(\"Data stream collect sink\");\n    env.addOperator(sink.getTransformation());\n\n    LOG.info(\"Submitting Flink job to test environment\");\n    final JobClient jobClient = env.executeAsync(\"TaskManager Failover Test\");\n    iterator.setJobClient(jobClient);\n        \n\n    LOG.info(\"Checking records before killing TaskManagers\");\n    assertThat(\n            iterator,\n            matchesSplitTestData(testRecordsBeforeFailure, testRecordsBeforeFailure.size()));\n\n        \n    LOG.info(\"Trigger TaskManager failover\");\n    controller.triggerTaskManagerFailover(jobClient, () -> {});\n\n    LOG.info(\"Waiting for job recovering from failure\");\n    CommonTestUtils.waitForJobStatus(\n            jobClient,\n            Collections.singletonList(JobStatus.RUNNING),\n            Deadline.fromNow(Duration.ofSeconds(30)));\n\n    LOG.info(\"Writing test data to split {}\", splitIndex);\n    final List<T> testRecordsAfterFailure =\n            externalContext.generateTestData(\n                    splitIndex, ThreadLocalRandom.current().nextLong());\n    sourceSplitDataWriter.writeRecords(testRecordsAfterFailure);\n\n    LOG.info(\"Checking records after job failover\");\n    assertThat(\n            iterator,\n            matchesSplitTestData(testRecordsAfterFailure, testRecordsAfterFailure.size()));\n\n        \n    iterator.close();\n    CommonTestUtils.terminateJob(jobClient, Duration.ofSeconds(30));\n    CommonTestUtils.waitForJobStatus(\n            jobClient,\n            Collections.singletonList(JobStatus.CANCELED),\n            Deadline.fromNow(Duration.ofSeconds(30)));\n}", "summary_tokens": ["test", "connector", "source", "with", "task", "manager", "failover"], "project": "flink"}
{"id": 5564, "code": "public Iterator<T> getTasks() {\n    return tasks.values().iterator();\n}", "summary_tokens": ["get", "all", "tasks", "running", "in", "this", "task", "slot"], "project": "flink"}
{"id": 8671, "code": "public static int addMonths(int date, int m) {\n    int y0 = (int) extractFromDate(TimeUnitRange.YEAR, date);\n    int m0 = (int) extractFromDate(TimeUnitRange.MONTH, date);\n    int d0 = (int) extractFromDate(TimeUnitRange.DAY, date);\n    m0 += m;\n    int deltaYear = (int) DateTimeUtils.floorDiv(m0, 12);\n    y0 += deltaYear;\n    m0 = (int) DateTimeUtils.floorMod(m0, 12);\n    if (m0 == 0) {\n        y0 -= 1;\n        m0 += 12;\n    }\n\n    int last = lastDay(y0, m0);\n    if (d0 > last) {\n        d0 = last;\n    }\n    return ymdToUnixDate(y0, m0, d0);\n}", "summary_tokens": ["adds", "a", "given", "number", "of", "months", "to", "a", "date", "represented", "as", "the", "number", "of", "days", "since", "the", "epoch"], "project": "flink"}
{"id": 9261, "code": "public BinaryMergeIterator<Entry> getMergingIterator(\n        List<ChannelWithMeta> channelIDs, List<FileIOChannel> openChannels) throws IOException {\n        \n    if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Performing merge of \" + channelIDs.size() + \" sorted streams.\");\n    }\n\n    final List<MutableObjectIterator<Entry>> iterators = new ArrayList<>(channelIDs.size() + 1);\n\n    for (ChannelWithMeta channel : channelIDs) {\n        AbstractChannelReaderInputView view =\n                FileChannelUtil.createInputView(\n                        ioManager,\n                        channel,\n                        openChannels,\n                        compressionEnable,\n                        compressionCodecFactory,\n                        compressionBlockSize,\n                        pageSize);\n        iterators.add(channelReaderInputViewIterator(view));\n    }\n\n    return new BinaryMergeIterator<>(\n            iterators, mergeReusedEntries(channelIDs.size()), mergeComparator());\n}", "summary_tokens": ["returns", "an", "iterator", "that", "iterates", "over", "the", "merged", "result", "from", "all", "given", "channels"], "project": "flink"}
{"id": 6616, "code": "public void confirmCheckpoint() throws Exception {\n\n    final int chkCount = 3;\n    final int confirmed = chkCount - 1;\n    List<TestingTaskStateSnapshot> taskStateSnapshots = storeStates(chkCount);\n    taskLocalStateStore.confirmCheckpoint(confirmed);\n    checkPrunedAndDiscarded(taskStateSnapshots, 0, confirmed);\n    checkStoredAsExpected(taskStateSnapshots, confirmed, chkCount);\n}", "summary_tokens": ["tests", "pruning", "of", "previous", "checkpoints", "if", "a", "new", "checkpoint", "is", "confirmed"], "project": "flink"}
{"id": 5828, "code": "private void testCompares(BlobKey.BlobType blobType) {\n    final BlobKey k1 = BlobKey.createKey(blobType, KEY_ARRAY_1, RANDOM_ARRAY_1);\n    final BlobKey k2 = BlobKey.createKey(blobType, KEY_ARRAY_1, RANDOM_ARRAY_1);\n    final BlobKey k3 = BlobKey.createKey(blobType, KEY_ARRAY_2, RANDOM_ARRAY_1);\n    final BlobKey k4 = BlobKey.createKey(blobType, KEY_ARRAY_1, RANDOM_ARRAY_2);\n    assertThat(k1.compareTo(k2), is(0));\n    assertThat(k2.compareTo(k1), is(0));\n    assertThat(k1.compareTo(k3), lessThan(0));\n    assertThat(k1.compareTo(k4), lessThan(0));\n    assertThat(k3.compareTo(k1), greaterThan(0));\n    assertThat(k4.compareTo(k1), greaterThan(0));\n}", "summary_tokens": ["tests", "the", "compares", "method"], "project": "flink"}
{"id": 7557, "code": "private long cleanup() throws Exception {\n    LOG.debug(\n            \"Cleanup AsyncCheckpointRunnable for checkpoint {} of {}.\",\n            checkpointMetaData.getCheckpointId(),\n            taskName);\n\n    Exception exception = null;\n\n        \n    long stateSize = 0;\n    for (OperatorSnapshotFutures operatorSnapshotResult :\n            operatorSnapshotsInProgress.values()) {\n        if (operatorSnapshotResult != null) {\n            try {\n                stateSize += operatorSnapshotResult.cancel();\n            } catch (Exception cancelException) {\n                exception = ExceptionUtils.firstOrSuppressed(cancelException, exception);\n            }\n        }\n    }\n\n    if (null != exception) {\n        throw exception;\n    }\n    return stateSize;\n}", "summary_tokens": ["discarded", "state", "size", "if", "available"], "project": "flink"}
{"id": 1222, "code": "public void setInput(Operator<IN> input) {\n    this.input = checkNotNull(input, \"The input may not be null.\");\n}", "summary_tokens": ["sets", "the", "given", "operator", "as", "the", "input", "to", "this", "operator"], "project": "flink"}
{"id": 7916, "code": "public static <IN1, IN2, OUT>\n        TwoInputStreamOperatorTestHarness<IN1, IN2, OUT> forCoProcessFunction(\n                final CoProcessFunction<IN1, IN2, OUT> function) throws Exception {\n\n    TwoInputStreamOperatorTestHarness<IN1, IN2, OUT> testHarness =\n            new TwoInputStreamOperatorTestHarness<>(\n                    new CoProcessOperator<>(Preconditions.checkNotNull(function)), 1, 1, 0);\n    testHarness.open();\n    return testHarness;\n}", "summary_tokens": ["returns", "an", "initialized", "test", "harness", "for", "co", "process", "function", "with", "two", "input", "streams"], "project": "flink"}
{"id": 4879, "code": "public void startQueryService(RpcService rpcService, ResourceID resourceID) {\n    synchronized (lock) {\n        Preconditions.checkState(\n                !isShutdown(), \"The metric registry has already been shut down.\");\n\n        try {\n            metricQueryServiceRpcService = rpcService;\n            queryService =\n                    MetricQueryService.createMetricQueryService(\n                            rpcService, resourceID, maximumFramesize);\n            queryService.start();\n        } catch (Exception e) {\n            LOG.warn(\n                    \"Could not start MetricDumpActor. No metrics will be submitted to the WebInterface.\",\n                    e);\n        }\n    }\n}", "summary_tokens": ["initializes", "the", "metric", "query", "service"], "project": "flink"}
{"id": 273, "code": "default void applyFilters(List<ResolvedExpression> filters) {}", "summary_tokens": ["provides", "a", "list", "of", "filters", "in", "conjunctive", "form", "for", "filtering", "on", "a", "best", "effort", "basis"], "project": "flink"}
{"id": 6227, "code": "public void testConcurrentReleaseAndRetriggerPartitionRequest() throws Exception {\n    final SingleInputGate gate = createSingleInputGate(1);\n\n    ResultPartitionManager partitionManager = mock(ResultPartitionManager.class);\n    when(partitionManager.createSubpartitionView(\n                    any(ResultPartitionID.class),\n                    anyInt(),\n                    any(BufferAvailabilityListener.class)))\n            .thenAnswer(\n                    (Answer<ResultSubpartitionView>)\n                            invocationOnMock -> {\n                                    \n                                    \n                                    \n                                Thread.sleep(100);\n                                throw new PartitionNotFoundException(new ResultPartitionID());\n                            });\n\n    final LocalInputChannel channel = createLocalInputChannel(gate, partitionManager, 1, 1);\n\n    Thread releaser =\n            new Thread(\n                    () -> {\n                        try {\n                            gate.close();\n                        } catch (IOException ignored) {\n                        }\n                    });\n\n    Thread requester =\n            new Thread(\n                    () -> {\n                        try {\n                            channel.requestSubpartition(0);\n                        } catch (IOException ignored) {\n                        }\n                    });\n\n    requester.start();\n    releaser.start();\n\n    releaser.join();\n    requester.join();\n}", "summary_tokens": ["verifies", "that", "concurrent", "release", "via", "the", "single", "input", "gate", "and", "re", "triggering", "of", "a", "partition", "request", "works", "smoothly"], "project": "flink"}
{"id": 7931, "code": "public void close() {\n    if (terminal != null) {\n        closeTerminal();\n    }\n}", "summary_tokens": ["closes", "the", "cli", "instance"], "project": "flink"}
{"id": 1084, "code": "public LinkedHashSet<Class<?>> getRegisteredPojoTypes() {\n    return registeredPojoTypes;\n}", "summary_tokens": ["returns", "the", "registered", "pojo", "types"], "project": "flink"}
{"id": 793, "code": "public int getDeregisterStreamMaxRetries() {\n    return deregisterStreamMaxRetries;\n}", "summary_tokens": ["get", "maximum", "retry", "attempts", "for", "the", "register", "stream", "operation"], "project": "flink"}
{"id": 1217, "code": "public void addFirstInputs(List<Operator<IN1>> inputs) {\n    this.input1 =\n            Operator.createUnionCascade(\n                    this.input1, inputs.toArray(new Operator[inputs.size()]));\n}", "summary_tokens": ["add", "to", "the", "first", "input", "the", "union", "of", "the", "given", "operators"], "project": "flink"}
{"id": 5053, "code": "public E next() throws IOException {\n    if (this.heap.size() > 0) {\n            \n        final HeadStream<E> top = this.heap.peek();\n        E result = top.getHead();\n\n            \n        if (!top.nextHead()) {\n            this.heap.poll();\n        } else {\n            this.heap.adjustTop();\n        }\n        return result;\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["gets", "the", "next", "smallest", "element", "with", "respect", "to", "the", "definition", "of", "order", "implied", "by", "the", "type", "serializer", "provided", "to", "this", "iterator"], "project": "flink"}
{"id": 9235, "code": "public void cleanupState(long time) {\n    leftState.clear();\n    rightState.clear();\n    nextLeftIndex.clear();\n    registeredTimer.clear();\n}", "summary_tokens": ["the", "method", "to", "be", "called", "when", "a", "cleanup", "timer", "fires"], "project": "flink"}
{"id": 6910, "code": "static long calculateWriteBufferManagerCapacity(long totalMemorySize, double writeBufferRatio) {\n    return (long) (2 * totalMemorySize * writeBufferRatio / 3);\n}", "summary_tokens": ["calculate", "the", "actual", "memory", "capacity", "of", "write", "buffer", "manager", "which", "would", "be", "shared", "among", "rocks", "db", "instance", "s"], "project": "flink"}
{"id": 4939, "code": "protected void initLocalStrategies(int numInputs) throws Exception {\n\n    final MemoryManager memMan = getMemoryManager();\n    final IOManager ioMan = getIOManager();\n\n    this.localStrategies = new CloseableInputProvider<?>[numInputs];\n    this.inputs = new MutableObjectIterator<?>[numInputs];\n    this.excludeFromReset = new boolean[numInputs];\n    this.inputIsCached = new boolean[numInputs];\n    this.inputIsAsyncMaterialized = new boolean[numInputs];\n    this.materializationMemory = new int[numInputs];\n\n        \n        \n    for (int i = 0; i < numInputs; i++) {\n        initInputLocalStrategy(i);\n    }\n\n        \n        \n\n        \n        \n        \n        \n        \n        \n        \n    this.resettableInputs = new SpillingResettableMutableObjectIterator<?>[numInputs];\n    this.tempBarriers = new TempBarrier<?>[numInputs];\n\n    for (int i = 0; i < numInputs; i++) {\n        final int memoryPages;\n        final boolean async = this.config.isInputAsynchronouslyMaterialized(i);\n        final boolean cached = this.config.isInputCached(i);\n\n        this.inputIsAsyncMaterialized[i] = async;\n        this.inputIsCached[i] = cached;\n\n        if (async || cached) {\n            memoryPages =\n                    memMan.computeNumberOfPages(\n                            this.config.getRelativeInputMaterializationMemory(i));\n            if (memoryPages <= 0) {\n                throw new Exception(\n                        \"Input marked as materialized/cached, but no memory for materialization provided.\");\n            }\n            this.materializationMemory[i] = memoryPages;\n        } else {\n            memoryPages = 0;\n        }\n\n        if (async) {\n            @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n            TempBarrier<?> barrier =\n                    new TempBarrier(\n                            this,\n                            getInput(i),\n                            this.inputSerializers[i],\n                            memMan,\n                            ioMan,\n                            memoryPages,\n                            emptyList());\n            barrier.startReading();\n            this.tempBarriers[i] = barrier;\n            this.inputs[i] = null;\n        } else if (cached) {\n            @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n            SpillingResettableMutableObjectIterator<?> iter =\n                    new SpillingResettableMutableObjectIterator(\n                            getInput(i),\n                            this.inputSerializers[i].getSerializer(),\n                            getMemoryManager(),\n                            getIOManager(),\n                            memoryPages,\n                            this);\n            this.resettableInputs[i] = iter;\n            this.inputs[i] = iter;\n        }\n    }\n}", "summary_tokens": ["note", "this", "method", "must", "be", "invoked", "after", "the", "invocation", "of", "init", "input", "readers", "and", "init", "input", "serializers", "and", "comparators", "int"], "project": "flink"}
{"id": 3913, "code": "public void testServerInitializationFailure() throws Throwable {\n\n        \n    expectedEx.expect(FlinkRuntimeException.class);\n    expectedEx.expectMessage(\n            \"Unable to start Test Server 2. All ports in provided range are occupied.\");\n\n    List<Integer> portList = Collections.singletonList(0);\n\n    try (TestServer server1 =\n            new TestServer(\n                    \"Test Server 1\", new DisabledKvStateRequestStats(), portList.iterator())) {\n        server1.start();\n\n        try (TestServer server2 =\n                new TestServer(\n                        \"Test Server 2\",\n                        new DisabledKvStateRequestStats(),\n                        Collections.singletonList(server1.getServerAddress().getPort())\n                                .iterator())) {\n            server2.start();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "in", "case", "of", "port", "collision", "a", "flink", "runtime", "exception", "is", "thrown", "with", "a", "specific", "message"], "project": "flink"}
{"id": 3264, "code": "public static <K, EV> DataSet<Vertex<K, NullValue>> vertexSet(\n        DataSet<Edge<K, EV>> edges, int parallelism) {\n    DataSet<Vertex<K, NullValue>> vertexSet =\n            edges.flatMap(new EmitSrcAndTarget<>())\n                    .setParallelism(parallelism)\n                    .name(\"Emit source and target labels\");\n\n    return vertexSet\n            .distinct()\n            .setCombineHint(CombineHint.HASH)\n            .setParallelism(parallelism)\n            .name(\"Emit vertex labels\");\n}", "summary_tokens": ["generates", "vertex", "vertices", "present", "in", "the", "given", "set", "of", "edge", "s"], "project": "flink"}
{"id": 9124, "code": "public void setCollector(Collector<T> collector) {\n    this.collector = collector;\n}", "summary_tokens": ["sets", "the", "current", "collector", "which", "is", "used", "to", "emit", "the", "final", "result"], "project": "flink"}
{"id": 7356, "code": "protected boolean isUsingCustomRawKeyedState() {\n    return false;\n}", "summary_tokens": ["indicates", "whether", "or", "not", "implementations", "of", "this", "class", "is", "writing", "to", "the", "raw", "keyed", "state", "streams", "on", "snapshots", "using", "snapshot", "state", "state", "snapshot", "context"], "project": "flink"}
{"id": 6681, "code": "public void testFatalErrorOnCanceling() throws Exception {\n    final CompletableFuture<Throwable> fatalErrorFuture = new CompletableFuture<>();\n    final TestingTaskManagerActions taskManagerActions =\n            TestingTaskManagerActions.newBuilder()\n                    .setNotifyFatalErrorConsumer(\n                            (s, throwable) -> fatalErrorFuture.complete(throwable))\n                    .build();\n\n    final Configuration config = new Configuration();\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_INTERVAL, 5);\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT, 50);\n\n    final Task task =\n            spy(\n                    createTaskBuilder()\n                            .setInvokable(InvokableBlockingWithTrigger.class)\n                            .setTaskManagerConfig(config)\n                            .setTaskManagerActions(taskManagerActions)\n                            .build());\n\n    final Class<OutOfMemoryError> fatalErrorType = OutOfMemoryError.class;\n    doThrow(fatalErrorType)\n            .when(task)\n            .cancelOrFailAndCancelInvokableInternal(eq(ExecutionState.CANCELING), eq(null));\n\n    try {\n        task.startTaskThread();\n\n        awaitLatch.await();\n\n        task.cancelExecution();\n\n            \n        final Throwable fatalError = fatalErrorFuture.join();\n        assertThat(fatalError, instanceOf(fatalErrorType));\n    } finally {\n        triggerLatch.trigger();\n    }\n}", "summary_tokens": ["tests", "that", "a", "fatal", "error", "gotten", "from", "canceling", "task", "is", "notified"], "project": "flink"}
{"id": 2983, "code": "public FlinkPod decorateFlinkPod(FlinkPod flinkPod) {\n    return flinkPod;\n}", "summary_tokens": ["apply", "transformations", "on", "the", "given", "flink", "pod", "in", "accordance", "to", "this", "feature"], "project": "flink"}
{"id": 846, "code": "private static AWSCredentialsProvider getCredentialsProvider(\n        final Properties configProps, final String configPrefix) {\n    CredentialProvider credentialProviderType =\n            AWSKinesisDataStreamsUtil.getCredentialProviderType(configProps, configPrefix);\n\n    switch (credentialProviderType) {\n        case ENV_VAR:\n            return new EnvironmentVariableCredentialsProvider();\n\n        case SYS_PROP:\n            return new SystemPropertiesCredentialsProvider();\n\n        case PROFILE:\n            String profileName =\n                    configProps.getProperty(AWSConfigConstants.profileName(configPrefix), null);\n            String profileConfigPath =\n                    configProps.getProperty(AWSConfigConstants.profilePath(configPrefix), null);\n            return (profileConfigPath == null)\n                    ? new ProfileCredentialsProvider(profileName)\n                    : new ProfileCredentialsProvider(profileConfigPath, profileName);\n\n        case BASIC:\n            return new AWSCredentialsProvider() {\n                @Override\n                public AWSCredentials getCredentials() {\n                    return new BasicAWSCredentials(\n                            configProps.getProperty(\n                                    AWSConfigConstants.accessKeyId(configPrefix)),\n                            configProps.getProperty(\n                                    AWSConfigConstants.secretKey(configPrefix)));\n                }\n\n                @Override\n                public void refresh() {\n                        \n                }\n            };\n\n        case ASSUME_ROLE:\n            final AWSSecurityTokenService baseCredentials =\n                    AWSSecurityTokenServiceClientBuilder.standard()\n                            .withCredentials(\n                                    getCredentialsProvider(\n                                            configProps,\n                                            AWSConfigConstants.roleCredentialsProvider(\n                                                    configPrefix)))\n                            .withRegion(configProps.getProperty(AWSConfigConstants.AWS_REGION))\n                            .build();\n            return new STSAssumeRoleSessionCredentialsProvider.Builder(\n                            configProps.getProperty(AWSConfigConstants.roleArn(configPrefix)),\n                            configProps.getProperty(\n                                    AWSConfigConstants.roleSessionName(configPrefix)))\n                    .withExternalId(\n                            configProps.getProperty(\n                                    AWSConfigConstants.externalId(configPrefix)))\n                    .withStsClient(baseCredentials)\n                    .build();\n\n        case WEB_IDENTITY_TOKEN:\n            return WebIdentityTokenCredentialsProvider.builder()\n                    .roleArn(\n                            configProps.getProperty(\n                                    AWSConfigConstants.roleArn(configPrefix), null))\n                    .roleSessionName(\n                            configProps.getProperty(\n                                    AWSConfigConstants.roleSessionName(configPrefix), null))\n                    .webIdentityTokenFile(\n                            configProps.getProperty(\n                                    AWSConfigConstants.webIdentityTokenFile(configPrefix),\n                                    null))\n                    .build();\n\n        case AUTO:\n            return new DefaultAWSCredentialsProviderChain();\n\n        default:\n            throw new IllegalArgumentException(\n                    \"Credential provider not supported: \" + credentialProviderType);\n    }\n}", "summary_tokens": ["if", "the", "provider", "is", "assume", "role", "then", "the", "credentials", "for", "assuming", "this", "role", "are", "determined", "recursively"], "project": "flink"}
{"id": 1920, "code": "public static final Date parseField(byte[] bytes, int startPos, int length, char delimiter) {\n    final int limitedLen = nextStringLength(bytes, startPos, length, delimiter);\n\n    if (limitedLen > 0\n            && (Character.isWhitespace(bytes[startPos])\n                    || Character.isWhitespace(bytes[startPos + limitedLen - 1]))) {\n        throw new NumberFormatException(\n                \"There is leading or trailing whitespace in the numeric field.\");\n    }\n\n    final String str = new String(bytes, startPos, limitedLen, ConfigConstants.DEFAULT_CHARSET);\n    return Date.valueOf(str);\n}", "summary_tokens": ["static", "utility", "to", "parse", "a", "field", "of", "type", "date", "from", "a", "byte", "sequence", "that", "represents", "text", "characters", "such", "as", "when", "read", "from", "a", "file", "stream"], "project": "flink"}
{"id": 3316, "code": "public VertexMetrics<K, VV, EV> setReduceOnTargetId(boolean reduceOnTargetId) {\n    this.reduceOnTargetId = reduceOnTargetId;\n\n    return this;\n}", "summary_tokens": ["the", "degree", "can", "be", "counted", "from", "either", "the", "edge", "source", "or", "target", "ids"], "project": "flink"}
{"id": 5691, "code": "public static <T extends Serializable>\n        ZooKeeperStateHandleStore<T> createZooKeeperStateHandleStore(\n                final CuratorFramework client,\n                final String path,\n                final RetrievableStateStorageHelper<T> stateStorage)\n                throws Exception {\n    return new ZooKeeperStateHandleStore<>(\n            useNamespaceAndEnsurePath(client, path), stateStorage);\n}", "summary_tokens": ["creates", "an", "instance", "of", "zoo", "keeper", "state", "handle", "store"], "project": "flink"}
{"id": 5255, "code": "public final boolean isResolved() {\n    return resolved;\n}", "summary_tokens": ["returns", "whether", "this", "parameter", "has", "been", "resolved"], "project": "flink"}
{"id": 7631, "code": "public void testOutputTypeConfigurationWithOneInputTransformation() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStream<Integer> source = env.fromElements(1, 10);\n\n    OutputTypeConfigurableOperationWithOneInput outputTypeConfigurableOperation =\n            new OutputTypeConfigurableOperationWithOneInput();\n\n    DataStream<Integer> result =\n            source.transform(\n                    \"Single input and output type configurable operation\",\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    outputTypeConfigurableOperation);\n\n    result.addSink(new DiscardingSink<>());\n\n    env.getStreamGraph();\n\n    assertEquals(\n            BasicTypeInfo.INT_TYPE_INFO, outputTypeConfigurableOperation.getTypeInformation());\n}", "summary_tokens": ["test", "whether", "an", "output", "type", "configurable", "implementation", "gets", "called", "with", "the", "correct", "output", "type"], "project": "flink"}
{"id": 6308, "code": "public void testZooKeeperLeaderElectionRetrieval() throws Exception {\n\n    final TestingLeaderElectionEventHandler electionEventHandler =\n            new TestingLeaderElectionEventHandler(TEST_LEADER);\n    final TestingLeaderRetrievalEventHandler retrievalEventHandler =\n            new TestingLeaderRetrievalEventHandler();\n    LeaderElectionDriver leaderElectionDriver = null;\n    LeaderRetrievalDriver leaderRetrievalDriver = null;\n    try {\n\n        leaderElectionDriver =\n                createAndInitLeaderElectionDriver(\n                        curatorFrameworkWrapper.asCuratorFramework(), electionEventHandler);\n        leaderRetrievalDriver =\n                ZooKeeperUtils.createLeaderRetrievalDriverFactory(\n                                curatorFrameworkWrapper.asCuratorFramework())\n                        .createLeaderRetrievalDriver(\n                                retrievalEventHandler, retrievalEventHandler::handleError);\n\n        electionEventHandler.waitForLeader(timeout);\n        assertThat(electionEventHandler.getConfirmedLeaderInformation(), is(TEST_LEADER));\n\n        retrievalEventHandler.waitForNewLeader(timeout);\n\n        assertThat(\n                retrievalEventHandler.getLeaderSessionID(),\n                is(TEST_LEADER.getLeaderSessionID()));\n        assertThat(retrievalEventHandler.getAddress(), is(TEST_LEADER.getLeaderAddress()));\n    } finally {\n        electionEventHandler.close();\n        if (leaderElectionDriver != null) {\n            leaderElectionDriver.close();\n        }\n        if (leaderRetrievalDriver != null) {\n            leaderRetrievalDriver.close();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "the", "zoo", "keeper", "leader", "election", "retrieval", "service", "return", "both", "the", "correct", "url"], "project": "flink"}
{"id": 926, "code": "public static TopicRange createFullRange() {\n    return new TopicRange(MIN_RANGE, MAX_RANGE);\n}", "summary_tokens": ["create", "a", "topic", "range", "which", "contains", "the", "fully", "hash", "range"], "project": "flink"}
{"id": 821, "code": "public static StartingPosition continueFromSequenceNumber(final SequenceNumber sequenceNumber) {\n    return fromSequenceNumber(sequenceNumber, false);\n}", "summary_tokens": ["returns", "the", "starting", "position", "for", "the", "next", "record", "to", "consume", "from", "the", "given", "sequence", "number"], "project": "flink"}
{"id": 7544, "code": "public final boolean isWatermarkStatus() {\n    return getClass() == WatermarkStatus.class;\n}", "summary_tokens": ["checks", "whether", "this", "element", "is", "a", "watermark", "status"], "project": "flink"}
{"id": 5193, "code": "public void registerOngoingOperation(\n        final K operationKey, final CompletableFuture<R> operationResultFuture) {\n    final ResultAccessTracker<R> inProgress = ResultAccessTracker.inProgress();\n\n    synchronized (lock) {\n        checkState(isRunning(), \"The CompletedOperationCache has already been closed.\");\n        registeredOperationTriggers.put(operationKey, inProgress);\n    }\n\n    operationResultFuture.whenComplete(\n            (result, error) -> {\n                if (error == null) {\n                    completedOperations.put(\n                            operationKey,\n                            inProgress.finishOperation(OperationResult.success(result)));\n                } else {\n                    completedOperations.put(\n                            operationKey,\n                            inProgress.finishOperation(OperationResult.failure(error)));\n                }\n                registeredOperationTriggers.remove(operationKey);\n            });\n}", "summary_tokens": ["registers", "an", "ongoing", "operation", "with", "the", "cache"], "project": "flink"}
{"id": 932, "code": "private void cumulativeAcknowledgmentMessage() {\n    Map<TopicPartition, MessageId> cursors = new HashMap<>(cursorsOfFinishedSplits);\n\n        \n        \n    List<PulsarPartitionSplit> splits = super.snapshotState(1L);\n    for (PulsarPartitionSplit split : splits) {\n        MessageId latestConsumedId = split.getLatestConsumedId();\n        if (latestConsumedId != null) {\n            cursors.put(split.getPartition(), latestConsumedId);\n        }\n    }\n\n    try {\n        ((PulsarOrderedFetcherManager<OUT>) splitFetcherManager).acknowledgeMessages(cursors);\n            \n        cursorsOfFinishedSplits.keySet().removeAll(cursors.keySet());\n    } catch (Exception e) {\n        LOG.error(\"Fail in auto cursor commit.\", e);\n        cursorCommitThrowable.compareAndSet(null, e);\n    }\n}", "summary_tokens": ["acknowledge", "the", "pulsar", "topic", "partition", "cursor", "by", "the", "last", "consumed", "message", "id"], "project": "flink"}
{"id": 1500, "code": "public static <\n                T0,\n                T1,\n                T2,\n                T3,\n                T4,\n                T5,\n                T6,\n                T7,\n                T8,\n                T9,\n                T10,\n                T11,\n                T12,\n                T13,\n                T14,\n                T15,\n                T16,\n                T17,\n                T18>\n        Tuple19<\n                        T0,\n                        T1,\n                        T2,\n                        T3,\n                        T4,\n                        T5,\n                        T6,\n                        T7,\n                        T8,\n                        T9,\n                        T10,\n                        T11,\n                        T12,\n                        T13,\n                        T14,\n                        T15,\n                        T16,\n                        T17,\n                        T18>\n                of(\n                        T0 f0,\n                        T1 f1,\n                        T2 f2,\n                        T3 f3,\n                        T4 f4,\n                        T5 f5,\n                        T6 f6,\n                        T7 f7,\n                        T8 f8,\n                        T9 f9,\n                        T10 f10,\n                        T11 f11,\n                        T12 f12,\n                        T13 f13,\n                        T14 f14,\n                        T15 f15,\n                        T16 f16,\n                        T17 f17,\n                        T18 f18) {\n    return new Tuple19<>(\n            f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17,\n            f18);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 3491, "code": "public <K, T, OUT> DataSource<OUT> reduce(\n        String uid,\n        ReduceFunction<T> function,\n        WindowReaderFunction<T, OUT, K, W> readerFunction,\n        TypeInformation<K> keyType,\n        TypeInformation<T> reduceType,\n        TypeInformation<OUT> outputType)\n        throws IOException {\n\n    WindowReaderOperator<?, K, T, W, OUT> operator =\n            WindowReaderOperator.reduce(\n                    function, readerFunction, keyType, windowSerializer, reduceType);\n\n    return readWindowOperator(uid, outputType, operator);\n}", "summary_tokens": ["reads", "window", "state", "generated", "using", "a", "reduce", "function"], "project": "flink"}
{"id": 879, "code": "public static PulsarAdmin createAdmin(Configuration configuration) {\n    PulsarAdminBuilder builder = PulsarAdmin.builder();\n\n    setOptionValue(configuration, PULSAR_ADMIN_URL, builder::serviceHttpUrl);\n    builder.authentication(createAuthentication(configuration));\n    setOptionValue(\n            configuration, PULSAR_TLS_TRUST_CERTS_FILE_PATH, builder::tlsTrustCertsFilePath);\n    setOptionValue(\n            configuration,\n            PULSAR_TLS_ALLOW_INSECURE_CONNECTION,\n            builder::allowTlsInsecureConnection);\n    setOptionValue(\n            configuration,\n            PULSAR_TLS_HOSTNAME_VERIFICATION_ENABLE,\n            builder::enableTlsHostnameVerification);\n    setOptionValue(configuration, PULSAR_USE_KEY_STORE_TLS, builder::useKeyStoreTls);\n    setOptionValue(configuration, PULSAR_SSL_PROVIDER, builder::sslProvider);\n    setOptionValue(configuration, PULSAR_TLS_TRUST_STORE_TYPE, builder::tlsTrustStoreType);\n    setOptionValue(configuration, PULSAR_TLS_TRUST_STORE_PATH, builder::tlsTrustStorePath);\n    setOptionValue(\n            configuration, PULSAR_TLS_TRUST_STORE_PASSWORD, builder::tlsTrustStorePassword);\n    setOptionValue(configuration, PULSAR_TLS_CIPHERS, TreeSet::new, builder::tlsCiphers);\n    setOptionValue(configuration, PULSAR_TLS_PROTOCOLS, TreeSet::new, builder::tlsProtocols);\n    setOptionValue(\n            configuration,\n            PULSAR_CONNECT_TIMEOUT,\n            v -> builder.connectionTimeout(v, MILLISECONDS));\n    setOptionValue(\n            configuration, PULSAR_READ_TIMEOUT, v -> builder.readTimeout(v, MILLISECONDS));\n    setOptionValue(\n            configuration,\n            PULSAR_REQUEST_TIMEOUT,\n            v -> builder.requestTimeout(v, MILLISECONDS));\n    setOptionValue(\n            configuration,\n            PULSAR_AUTO_CERT_REFRESH_TIME,\n            v -> builder.autoCertRefreshTime(v, MILLISECONDS));\n\n    return sneakyClient(builder::build);\n}", "summary_tokens": ["pulsar", "admin", "shares", "almost", "the", "same", "configuration", "with", "pulsar", "client", "but", "we", "separate", "this", "create", "method", "for", "directly", "create", "it"], "project": "flink"}
{"id": 7456, "code": "private boolean hasTimestamp(Iterable<TimestampedValue<Object>> elements) {\n    Iterator<TimestampedValue<Object>> it = elements.iterator();\n    if (it.hasNext()) {\n        return it.next().hasTimestamp();\n    }\n    return false;\n}", "summary_tokens": ["returns", "true", "if", "the", "first", "element", "in", "the", "iterable", "of", "timestamped", "value", "has", "a", "timestamp"], "project": "flink"}
{"id": 5518, "code": "public Path getCheckpointPath() {\n    return location.getBaseCheckpointPath();\n}", "summary_tokens": ["the", "location", "where", "checkpoints", "will", "be", "externalized", "if", "set"], "project": "flink"}
{"id": 464, "code": "static FieldNamedPreparedStatement prepareStatement(\n        Connection connection, String sql, String[] fieldNames) throws SQLException {\n    return FieldNamedPreparedStatementImpl.prepareStatement(connection, sql, fieldNames);\n}", "summary_tokens": ["creates", "a", "code", "named", "prepared", "statement", "code", "object", "for", "sending", "parameterized", "sql", "statements", "to", "the", "database"], "project": "flink"}
{"id": 9694, "code": "private void stopTaskManagerContainer() throws Exception {\n        \n    ContainerId taskManagerContainer = null;\n    NodeManager nodeManager = null;\n    NMTokenIdentifier nmIdent = null;\n    UserGroupInformation remoteUgi = UserGroupInformation.getCurrentUser();\n\n    for (int nmId = 0; nmId < NUM_NODEMANAGERS; nmId++) {\n        NodeManager nm = yarnCluster.getNodeManager(nmId);\n        ConcurrentMap<ContainerId, Container> containers = nm.getNMContext().getContainers();\n        for (Map.Entry<ContainerId, Container> entry : containers.entrySet()) {\n            String command =\n                    StringUtils.join(entry.getValue().getLaunchContext().getCommands(), \" \");\n            if (command.contains(YarnTaskExecutorRunner.class.getSimpleName())) {\n                taskManagerContainer = entry.getKey();\n                nodeManager = nm;\n                nmIdent =\n                        new NMTokenIdentifier(\n                                taskManagerContainer.getApplicationAttemptId(), null, \"\", 0);\n                    \n                    \n                remoteUgi.addTokenIdentifier(nmIdent);\n            }\n        }\n    }\n\n    assertNotNull(\"Unable to find container with TaskManager\", taskManagerContainer);\n    assertNotNull(\"Illegal state\", nodeManager);\n\n    StopContainersRequest scr =\n            StopContainersRequest.newInstance(Collections.singletonList(taskManagerContainer));\n\n    nodeManager.getNMContext().getContainerManager().stopContainers(scr);\n\n        \n    remoteUgi.getTokenIdentifiers().remove(nmIdent);\n}", "summary_tokens": ["stops", "a", "container", "running", "yarn", "task", "executor", "runner"], "project": "flink"}
{"id": 3352, "code": "<VertexWithDegree> void updateVertexFromScatterGatherIteration(\n        Vertex<K, VertexWithDegree> vertexState, MessageIterator<Message> inMessages)\n        throws Exception {\n\n    Vertex<K, VV> vertex =\n            new Vertex<>(vertexState.f0, ((Tuple3<VV, Long, Long>) vertexState.getValue()).f0);\n\n    updateVertex(vertex, inMessages);\n}", "summary_tokens": ["in", "order", "to", "hide", "the", "tuple", "0", "actual", "value", "in", "degree", "out", "degree", "vertex", "value", "from", "the", "user", "another", "function", "will", "be", "called", "from", "org"], "project": "flink"}
{"id": 7000, "code": "public void testGetDbOptionsWithSharedResources() throws Exception {\n    final int optionNumber = 20;\n    OpaqueMemoryResource<RocksDBSharedResources> sharedResources = getSharedResources();\n    RocksDBResourceContainer container =\n            new RocksDBResourceContainer(PredefinedOptions.DEFAULT, null, sharedResources);\n    HashSet<WriteBufferManager> writeBufferManagers = new HashSet<>();\n    for (int i = 0; i < optionNumber; i++) {\n        DBOptions dbOptions = container.getDbOptions();\n        WriteBufferManager writeBufferManager = getWriteBufferManager(dbOptions);\n        writeBufferManagers.add(writeBufferManager);\n    }\n    assertThat(writeBufferManagers.size(), is(1));\n    assertThat(\n            writeBufferManagers.iterator().next(),\n            is(sharedResources.getResourceHandle().getWriteBufferManager()));\n    container.close();\n}", "summary_tokens": ["guard", "that", "rocks", "dbresource", "container", "get", "db", "options", "shares", "the", "same", "write", "buffer", "manager", "instance", "if", "the", "rocks", "dbresource", "container", "instance", "is", "initiated", "with", "opaque", "memory", "resource"], "project": "flink"}
{"id": 1123, "code": "public static Map<String, OptionalFailure<Object>> deserializeAccumulators(\n        Map<String, SerializedValue<OptionalFailure<Object>>> serializedAccumulators,\n        ClassLoader loader)\n        throws IOException, ClassNotFoundException {\n\n    if (serializedAccumulators == null || serializedAccumulators.isEmpty()) {\n        return Collections.emptyMap();\n    }\n\n    Map<String, OptionalFailure<Object>> accumulators =\n            new HashMap<>(serializedAccumulators.size());\n\n    for (Map.Entry<String, SerializedValue<OptionalFailure<Object>>> entry :\n            serializedAccumulators.entrySet()) {\n\n        OptionalFailure<Object> value = null;\n        if (entry.getValue() != null) {\n            value = entry.getValue().deserializeValue(loader);\n        }\n\n        accumulators.put(entry.getKey(), value);\n    }\n\n    return accumulators;\n}", "summary_tokens": ["takes", "the", "serialized", "accumulator", "results", "and", "tries", "to", "deserialize", "them", "using", "the", "provided", "class", "loader"], "project": "flink"}
{"id": 6154, "code": "private static void testRetainBuffer(boolean isBuffer) {\n    NetworkBuffer buffer = newBuffer(1024, 1024, isBuffer);\n    assertFalse(buffer.isRecycled());\n    buffer.retainBuffer();\n    assertFalse(buffer.isRecycled());\n    assertEquals(2, buffer.refCnt());\n}", "summary_tokens": ["tests", "that", "network", "buffer", "retain", "buffer", "and", "network", "buffer", "is", "recycled", "are", "coupled", "and", "are", "also", "consistent", "with", "network", "buffer", "ref", "cnt"], "project": "flink"}
{"id": 5874, "code": "public void testNullOrInvalidId() throws Exception {\n    ExecutionGraph graph =\n            new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                    .addJobVertex(new JobVertexID())\n                    .build();\n    final CheckpointCoordinator cc = instantiateCheckpointCoordinator(graph);\n\n    try {\n        cc.addMasterHook(null);\n        fail(\"expected an exception\");\n    } catch (NullPointerException ignored) {\n    }\n\n    try {\n        cc.addMasterHook(mock(MasterTriggerRestoreHook.class));\n        fail(\"expected an exception\");\n    } catch (IllegalArgumentException ignored) {\n    }\n\n    try {\n        MasterTriggerRestoreHook<?> hook = mock(MasterTriggerRestoreHook.class);\n        when(hook.getIdentifier()).thenReturn(\"        \");\n\n        cc.addMasterHook(hook);\n        fail(\"expected an exception\");\n    } catch (IllegalArgumentException ignored) {\n    }\n}", "summary_tokens": ["test", "that", "validates", "correct", "exceptions", "when", "supplying", "hooks", "with", "invalid", "ids"], "project": "flink"}
{"id": 6939, "code": "public void enableBlockCacheCapacity() {\n    this.properties.add(RocksDBProperty.BlockCacheCapacity.getRocksDBProperty());\n}", "summary_tokens": ["returns", "block", "cache", "capacity"], "project": "flink"}
{"id": 519, "code": "public KafkaSourceBuilder<OUT> setUnbounded(OffsetsInitializer stoppingOffsetsInitializer) {\n    this.boundedness = Boundedness.CONTINUOUS_UNBOUNDED;\n    this.stoppingOffsetsInitializer = stoppingOffsetsInitializer;\n    return this;\n}", "summary_tokens": ["by", "default", "the", "kafka", "source", "is", "set", "to", "run", "in", "boundedness", "continuous", "unbounded", "manner", "and", "thus", "never", "stops", "until", "the", "flink", "job", "fails", "or", "is", "canceled"], "project": "flink"}
{"id": 3271, "code": "public long getFirstElement() {\n    return firstElement;\n}", "summary_tokens": ["the", "index", "of", "the", "first", "element", "in", "this", "block"], "project": "flink"}
{"id": 6746, "code": "private long updateValueWithReplace(long node, byte[] value) {\n        \n    int valueSize = value == null ? 0 : value.length;\n    int totalValueLen = SkipListUtils.getValueMetaLen() + valueSize;\n    long valuePointer = allocateSpace(totalValueLen);\n\n    Node nodeStorage = getNodeSegmentAndOffset(node);\n    MemorySegment nodeSegment = nodeStorage.nodeSegment;\n    int offsetInNodeSegment = nodeStorage.nodeOffset;\n\n    long oldValuePointer = SkipListUtils.getValuePointer(nodeSegment, offsetInNodeSegment);\n    long nextValuePointer =\n            SkipListUtils.helpGetNextValuePointer(oldValuePointer, spaceAllocator);\n\n    doWriteValue(valuePointer, value, stateMapVersion, node, nextValuePointer);\n\n        \n        \n    SkipListUtils.putValuePointer(nodeSegment, offsetInNodeSegment, valuePointer);\n\n    return oldValuePointer;\n}", "summary_tokens": ["update", "the", "value", "of", "the", "node", "with", "replace", "mode"], "project": "flink"}
{"id": 997, "code": "public static void mergeHadoopConf(Configuration hadoopConfig) {\n\n        \n        \n    org.apache.flink.configuration.Configuration flinkConfiguration =\n            GlobalConfiguration.loadConfiguration();\n\n    Configuration hadoopConf =\n            org.apache.flink.api.java.hadoop.mapred.utils.HadoopUtils.getHadoopConfiguration(\n                    flinkConfiguration);\n\n    for (Map.Entry<String, String> e : hadoopConf) {\n        if (hadoopConfig.get(e.getKey()) == null) {\n            hadoopConfig.set(e.getKey(), e.getValue());\n        }\n    }\n}", "summary_tokens": ["merge", "hadoop", "configuration", "into", "configuration"], "project": "flink"}
{"id": 7813, "code": "public void writeApplyProcessingTimeWindowsSnapshot() throws Exception {\n    final int windowSize = 3;\n\n    ListStateDescriptor<Tuple2<String, Integer>> stateDesc =\n            new ListStateDescriptor<>(\n                    \"window-contents\",\n                    STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n    WindowOperator<\n                    String,\n                    Tuple2<String, Integer>,\n                    Iterable<Tuple2<String, Integer>>,\n                    Tuple2<String, Integer>,\n                    TimeWindow>\n            operator =\n                    new WindowOperator<>(\n                            TumblingProcessingTimeWindows.of(\n                                    Time.of(windowSize, TimeUnit.SECONDS)),\n                            new TimeWindow.Serializer(),\n                            new TupleKeySelector<>(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()),\n                            stateDesc,\n                            new InternalIterableWindowFunction<>(\n                                    new RichSumReducer<TimeWindow>()),\n                            ProcessingTimeTrigger.create(),\n                            0,\n                            null );\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>>\n            testHarness =\n                    new KeyedOneInputStreamOperatorTestHarness<>(\n                            operator, new TupleKeySelector<>(), BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.setProcessingTime(10);\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1)));\n\n    testHarness.setProcessingTime(3010);\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key3\", 1)));\n\n    expectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 2999));\n    expectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 2999));\n\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new Tuple2ResultSortComparator<>());\n\n        \n    OperatorSubtaskState snapshot = testHarness.snapshot(0, 0);\n    OperatorSnapshotUtil.writeStateHandle(\n            snapshot,\n            \"src/test/resources/win-op-migration-test-apply-processing-time-flink\"\n                    + flinkGenerateSavepointVersion\n                    + \"-snapshot\");\n\n    testHarness.close();\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 8956, "code": "public List<List<RexNode>> getTuples() {\n    return (List<List<RexNode>>) (Object) tuples;\n}", "summary_tokens": ["in", "order", "to", "use", "rex", "node", "json", "serializer", "to", "serialize", "rex", "literal", "so", "we", "force", "cast", "element", "of", "tuples", "to", "rex", "node", "which", "is", "the", "parent", "class", "of", "rex", "literal"], "project": "flink"}
{"id": 2176, "code": "public void testTuplePojoTestEquality() {\n\n        \n    PojoTypeInfo<TestUserClass> pType = (PojoTypeInfo<TestUserClass>) type;\n    List<FlatFieldDescriptor> result = new ArrayList<FlatFieldDescriptor>();\n    pType.getFlatFields(\"nestedClass.dumm2\", 0, result);\n    int[] fields = new int[1]; \n    fields[0] = result.get(0).getPosition();\n    TypeComparator<TestUserClass> pojoComp =\n            pType.createComparator(fields, new boolean[] {true}, 0, new ExecutionConfig());\n\n    TestUserClass pojoTestRecord =\n            new TestUserClass(\n                    0,\n                    \"abc\",\n                    3d,\n                    new int[] {1, 2, 3},\n                    new Date(),\n                    new NestedTestUserClass(1, \"haha\", 4d, new int[] {5, 4, 3}));\n    int pHash = pojoComp.hash(pojoTestRecord);\n\n    Tuple1<String> tupleTest = new Tuple1<String>(\"haha\");\n    TupleTypeInfo<Tuple1<String>> tType =\n            (TupleTypeInfo<Tuple1<String>>) TypeExtractor.getForObject(tupleTest);\n    TypeComparator<Tuple1<String>> tupleComp =\n            tType.createComparator(\n                    new int[] {0}, new boolean[] {true}, 0, new ExecutionConfig());\n\n    int tHash = tupleComp.hash(tupleTest);\n\n    Assert.assertTrue(\n            \"The hashing for tuples and pojos must be the same, so that they are mixable\",\n            pHash == tHash);\n\n    Tuple3<Integer, String, Double> multiTupleTest =\n            new Tuple3<Integer, String, Double>(\n                    1, \"haha\", 4d); \n    TupleTypeInfo<Tuple3<Integer, String, Double>> multiTupleType =\n            (TupleTypeInfo<Tuple3<Integer, String, Double>>)\n                    TypeExtractor.getForObject(multiTupleTest);\n\n    ExpressionKeys fieldKey = new ExpressionKeys(new int[] {1, 0, 2}, multiTupleType);\n    ExpressionKeys expressKey =\n            new ExpressionKeys(\n                    new String[] {\n                        \"nestedClass.dumm2\", \"nestedClass.dumm1\", \"nestedClass.dumm3\"\n                    },\n                    pType);\n    try {\n        Assert.assertTrue(\n                \"Expecting the keys to be compatible\", fieldKey.areCompatible(expressKey));\n    } catch (IncompatibleKeysException e) {\n        e.printStackTrace();\n        Assert.fail(\"Keys must be compatible: \" + e.getMessage());\n    }\n    TypeComparator<TestUserClass> multiPojoComp =\n            pType.createComparator(\n                    expressKey.computeLogicalKeyPositions(),\n                    new boolean[] {true, true, true},\n                    0,\n                    new ExecutionConfig());\n    int multiPojoHash = multiPojoComp.hash(pojoTestRecord);\n\n        \n    TypeComparator<Tuple3<Integer, String, Double>> multiTupleComp =\n            multiTupleType.createComparator(\n                    fieldKey.computeLogicalKeyPositions(),\n                    new boolean[] {true, true, true},\n                    0,\n                    new ExecutionConfig());\n    int multiTupleHash = multiTupleComp.hash(multiTupleTest);\n\n    Assert.assertTrue(\n            \"The hashing for tuples and pojos must be the same, so that they are mixable. Also for those with multiple key fields\",\n            multiPojoHash == multiTupleHash);\n}", "summary_tokens": ["this", "tests", "if", "the", "hashes", "returned", "by", "the", "pojo", "and", "tuple", "comparators", "are", "the", "same"], "project": "flink"}
{"id": 6458, "code": "public void testTaskManagerTimeoutDoesNotRemoveSlots() throws Exception {\n    final Time taskManagerTimeout = Time.milliseconds(10L);\n\n    final CompletableFuture<InstanceID> releaseResourceFuture = new CompletableFuture<>();\n    final ResourceActions resourceActions =\n            createResourceActionsBuilder()\n                    .setReleaseResourceConsumer(\n                            (instanceId, ignored) -> releaseResourceFuture.complete(instanceId))\n                    .build();\n\n    final Executor mainThreadExecutor = TestingUtils.defaultExecutor();\n\n    try (final TaskExecutorManager taskExecutorManager =\n            createTaskExecutorManagerBuilder()\n                    .setTaskManagerTimeout(taskManagerTimeout)\n                    .setResourceActions(resourceActions)\n                    .setMainThreadExecutor(mainThreadExecutor)\n                    .createTaskExecutorManager()) {\n\n        CompletableFuture.supplyAsync(\n                        () -> {\n                            InstanceID newTaskExecutorId =\n                                    createAndRegisterTaskExecutor(\n                                            taskExecutorManager, 1, ResourceProfile.ANY);\n                            assertEquals(1, taskExecutorManager.getNumberRegisteredSlots());\n                            return newTaskExecutorId;\n                        },\n                        mainThreadExecutor)\n                    \n                .thenCombine(\n                        releaseResourceFuture,\n                        (registeredInstance, releasedInstance) -> {\n                            assertThat(registeredInstance, is(releasedInstance));\n                            assertEquals(1, taskExecutorManager.getNumberRegisteredSlots());\n                            return registeredInstance;\n                        })\n                .thenAccept(\n                        taskExecutorId -> {\n                            taskExecutorManager.unregisterTaskExecutor(taskExecutorId);\n                            assertEquals(0, taskExecutorManager.getNumberRegisteredSlots());\n                        })\n                .get();\n    }\n}", "summary_tokens": ["tests", "that", "a", "task", "manager", "timeout", "does", "not", "remove", "the", "slots", "from", "the", "slot", "manager"], "project": "flink"}
{"id": 1260, "code": "public UnaryOperatorInformation<IN, OUT> getOperatorInfo() {\n    return (UnaryOperatorInformation<IN, OUT>) this.operatorInfo;\n}", "summary_tokens": ["gets", "the", "information", "about", "the", "operators", "input", "output", "types"], "project": "flink"}
{"id": 2938, "code": "public void testOutOfTupleBoundsDataset1() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    DataSet<Tuple5<Integer, Long, String, Long, Integer>> tupleDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo);\n\n        \n    tupleDs.minBy(5);\n}", "summary_tokens": ["this", "test", "validates", "that", "an", "index", "which", "is", "out", "of", "bounds", "throws", "an", "index", "out", "of", "bounds", "exception"], "project": "flink"}
{"id": 4626, "code": "void getIndexEntry(FileChannel indexFile, ByteBuffer target, int region, int subpartition)\n        throws IOException {\n    checkArgument(target.capacity() == INDEX_ENTRY_SIZE, \"Illegal target buffer size.\");\n\n    target.clear();\n    long indexEntryOffset = getIndexEntryOffset(region, subpartition);\n    if (indexEntryCache != null) {\n        for (int i = 0; i < INDEX_ENTRY_SIZE; ++i) {\n            target.put(indexEntryCache.get((int) indexEntryOffset + i));\n        }\n    } else {\n        indexFile.position(indexEntryOffset);\n        BufferReaderWriterUtil.readByteBufferFully(indexFile, target);\n    }\n    target.flip();\n}", "summary_tokens": ["gets", "the", "index", "entry", "of", "the", "target", "region", "and", "subpartition", "either", "from", "the", "index", "data", "cache", "or", "the", "index", "data", "file"], "project": "flink"}
{"id": 990, "code": "public static DefaultRollingPolicy.PolicyBuilder builder() {\n    return new DefaultRollingPolicy.PolicyBuilder(\n            DEFAULT_MAX_PART_SIZE, DEFAULT_ROLLOVER_INTERVAL, DEFAULT_INACTIVITY_INTERVAL);\n}", "summary_tokens": ["creates", "a", "new", "policy", "builder", "that", "is", "used", "to", "configure", "and", "build", "an", "instance", "of", "default", "rolling", "policy"], "project": "flink"}
{"id": 4649, "code": "public void clear() {\n    deque.clear();\n    numPriorityElements = 0;\n}", "summary_tokens": ["removes", "all", "priority", "and", "non", "priority", "elements"], "project": "flink"}
{"id": 981, "code": "public void setCustomEndpointInitializer(EndpointInitializer initializer) {\n    Objects.requireNonNull(initializer, \"Initializer has to be set\");\n    ClosureCleaner.ensureSerializable(initializer);\n    this.initializer = initializer;\n}", "summary_tokens": ["set", "a", "custom", "endpoint", "initializer"], "project": "flink"}
{"id": 7991, "code": "public OverWindow as(Expression alias) {\n    return new OverWindow(\n            alias,\n            partitionBy,\n            orderBy,\n            unresolvedCall(BuiltInFunctionDefinitions.UNBOUNDED_RANGE),\n            Optional.empty());\n}", "summary_tokens": ["assigns", "an", "alias", "for", "this", "window", "that", "the", "following", "select", "clause", "can", "refer", "to"], "project": "flink"}
{"id": 6384, "code": "public void testCompare() throws Exception {\n    final int numSegments = MEMORY_SIZE / MEMORY_PAGE_SIZE;\n    final List<MemorySegment> memory =\n            this.memoryManager.allocatePages(new DummyInvokable(), numSegments);\n\n    NormalizedKeySorter<Tuple2<Integer, String>> sorter = newSortBuffer(memory);\n    TestData.TupleGenerator generator =\n            new TestData.TupleGenerator(\n                    SEED, KEY_MAX, VALUE_LENGTH, KeyMode.SORTED, ValueMode.RANDOM_LENGTH);\n\n        \n    Tuple2<Integer, String> record = new Tuple2<>();\n    int num = -1;\n    do {\n        generator.next(record);\n        num++;\n    } while (sorter.write(record));\n\n        \n    Random rnd = new Random(SEED << 1);\n    for (int i = 0; i < 2 * num; i++) {\n        int pos1 = rnd.nextInt(num);\n        int pos2 = rnd.nextInt(num);\n\n        int cmp = sorter.compare(pos1, pos2);\n\n        if (pos1 < pos2) {\n            Assert.assertTrue(cmp <= 0);\n        } else {\n            Assert.assertTrue(cmp >= 0);\n        }\n    }\n\n        \n    sorter.dispose();\n    this.memoryManager.release(memory);\n}", "summary_tokens": ["the", "compare", "test", "creates", "a", "sorted", "stream", "writes", "it", "to", "the", "buffer", "and", "compares", "random", "elements"], "project": "flink"}
{"id": 9325, "code": "public void put(W window, RowData key, UV value) throws Exception {\n    windowState.setCurrentNamespace(window);\n    windowState.put(key, value);\n}", "summary_tokens": ["associates", "a", "new", "value", "with", "the", "given", "key"], "project": "flink"}
{"id": 297, "code": "public void open(TableInputSplit split) throws IOException {\n    initTable();\n\n    if (split == null) {\n        throw new IOException(\"Input split is null!\");\n    }\n\n    logSplitInfo(\"opening\", split);\n\n        \n    currentRow = split.getStartRow();\n    scan.setStartRow(currentRow);\n    scan.setStopRow(split.getEndRow());\n\n    resultScanner = table.getScanner(scan);\n    endReached = false;\n    scannedRows = 0;\n}", "summary_tokens": ["creates", "a", "scan", "object", "and", "opens", "the", "htable", "connection"], "project": "flink"}
{"id": 4488, "code": "public void close() throws IOException {\n    close(false);\n}", "summary_tokens": ["closes", "this", "output", "writing", "pending", "data", "and", "releasing", "the", "memory"], "project": "flink"}
{"id": 2153, "code": "public static <T> Matcher<TypeSerializerSchemaCompatibility<T>> isCompatibleAfterMigration() {\n    return propertyMatcher(\n            TypeSerializerSchemaCompatibility::isCompatibleAfterMigration,\n            \"type serializer schema that is compatible after migration\");\n}", "summary_tokens": ["matches", "is", "compatible", "after", "migration", "type", "serializer", "schema", "compatibility"], "project": "flink"}
{"id": 5179, "code": "public SSLHandlerFactory getSslHandlerFactory() {\n    return sslHandlerFactory;\n}", "summary_tokens": ["returns", "the", "sslengine", "that", "the", "rest", "server", "endpoint", "should", "use"], "project": "flink"}
{"id": 3240, "code": "public VertexDegrees<K, VV, EV> setIncludeZeroDegreeVertices(\n        boolean includeZeroDegreeVertices) {\n    this.includeZeroDegreeVertices.set(includeZeroDegreeVertices);\n\n    return this;\n}", "summary_tokens": ["by", "default", "only", "the", "edge", "set", "is", "processed", "for", "the", "computation", "of", "degree"], "project": "flink"}
{"id": 4082, "code": "public Map<String, Accumulator<?, ?>> deserializeUserAccumulators(ClassLoader classLoader)\n        throws IOException, ClassNotFoundException {\n    return userAccumulators.deserializeValue(classLoader);\n}", "summary_tokens": ["gets", "the", "user", "defined", "accumulators", "values"], "project": "flink"}
{"id": 8510, "code": "public static List<DataType> getFieldDataTypes(DataType dataType) {\n    final LogicalType type = dataType.getLogicalType();\n    if (type.is(LogicalTypeRoot.DISTINCT_TYPE)) {\n        return getFieldDataTypes(dataType.getChildren().get(0));\n    } else if (isCompositeType(type)) {\n        return dataType.getChildren();\n    }\n    return Collections.emptyList();\n}", "summary_tokens": ["returns", "the", "first", "level", "field", "data", "types", "for", "the", "provided", "data", "type"], "project": "flink"}
{"id": 4992, "code": "public void resetRWViews() {\n    this.writeView.resetTo(0L);\n    this.readView.setReadPosition(0L);\n}", "summary_tokens": ["resets", "read", "and", "write", "views", "and", "should", "only", "be", "used", "on", "compaction", "partition"], "project": "flink"}
{"id": 8133, "code": "static List<Expression> createAliasList(List<Expression> aliases, QueryOperation child) {\n    ResolvedSchema childSchema = child.getResolvedSchema();\n\n    if (aliases.size() > childSchema.getColumnCount()) {\n        throw new ValidationException(\"Aliasing more fields than we actually have.\");\n    }\n\n    List<ValueLiteralExpression> fieldAliases =\n            aliases.stream()\n                    .map(f -> f.accept(aliasLiteralValidator))\n                    .collect(Collectors.toList());\n\n    List<String> childNames = childSchema.getColumnNames();\n    return IntStream.range(0, childNames.size())\n            .mapToObj(\n                    idx -> {\n                        UnresolvedReferenceExpression oldField =\n                                unresolvedRef(childNames.get(idx));\n                        if (idx < fieldAliases.size()) {\n                            ValueLiteralExpression alias = fieldAliases.get(idx);\n                            return unresolvedCall(\n                                    BuiltInFunctionDefinitions.AS, oldField, alias);\n                        } else {\n                            return oldField;\n                        }\n                    })\n            .collect(Collectors.toList());\n}", "summary_tokens": ["creates", "a", "list", "of", "valid", "alias", "expressions"], "project": "flink"}
{"id": 2272, "code": "public void restartTaskManager(RunnableWithException afterFailAction) throws Exception {\n    taskManagers.forEach(GenericContainer::stop);\n    afterFailAction.run();\n    taskManagers.forEach(GenericContainer::start);\n}", "summary_tokens": ["restarts", "all", "task", "manager", "containers"], "project": "flink"}
{"id": 1965, "code": "public static void tryDeserializeAndThrow(Throwable throwable, ClassLoader classLoader)\n        throws Throwable {\n    Throwable current = throwable;\n\n    while (!(current instanceof SerializedThrowable) && current.getCause() != null) {\n        current = current.getCause();\n    }\n\n    if (current instanceof SerializedThrowable) {\n        throw ((SerializedThrowable) current).deserializeError(classLoader);\n    } else {\n        throw throwable;\n    }\n}", "summary_tokens": ["tries", "to", "find", "a", "serialized", "throwable", "as", "the", "cause", "of", "the", "given", "throwable", "and", "throws", "its", "deserialized", "value"], "project": "flink"}
{"id": 4534, "code": "protected boolean handleEvent(AbstractEvent event) throws IOException {\n    final Class<?> eventType = event.getClass();\n\n    try {\n            \n            \n            \n\n            \n            \n        if (eventType == EndOfPartitionEvent.class) {\n            return true;\n        } else if (eventType == EndOfSuperstepEvent.class) {\n            return incrementEndOfSuperstepEventAndCheck();\n        }\n\n            \n            \n            \n        else if (event instanceof TaskEvent) {\n            taskEventHandler.publish((TaskEvent) event);\n\n            return false;\n        } else {\n            throw new IllegalStateException(\n                    \"Received unexpected event of type \" + eventType + \" at reader.\");\n        }\n    } catch (Throwable t) {\n        throw new IOException(\n                \"Error while handling event of type \" + eventType + \": \" + t.getMessage(), t);\n    }\n}", "summary_tokens": ["handles", "the", "event", "and", "returns", "whether", "the", "reader", "reached", "an", "end", "of", "stream", "event", "either", "the", "end", "of", "the", "whole", "stream", "or", "the", "end", "of", "an", "superstep"], "project": "flink"}
{"id": 1005, "code": "public HCatInputFormatBase<T> getFields(String... fields) throws IOException {\n\n        \n    ArrayList<HCatFieldSchema> fieldSchemas = new ArrayList<HCatFieldSchema>(fields.length);\n    for (String field : fields) {\n        fieldSchemas.add(this.outputSchema.get(field));\n    }\n    this.outputSchema = new HCatSchema(fieldSchemas);\n\n        \n    configuration.set(\"mapreduce.lib.hcat.output.schema\", HCatUtil.serialize(outputSchema));\n\n    return this;\n}", "summary_tokens": ["specifies", "the", "fields", "which", "are", "returned", "by", "the", "input", "format", "and", "their", "order"], "project": "flink"}
{"id": 5733, "code": "private void requestThreadInfo(\n        Map<ExecutionAttemptID, CompletableFuture<TaskExecutorThreadInfoGateway>>\n                executionWithGateways,\n        ThreadInfoSamplesRequest requestParams,\n        Time timeout) {\n\n        \n    for (Map.Entry<ExecutionAttemptID, CompletableFuture<TaskExecutorThreadInfoGateway>>\n            executionWithGateway : executionWithGateways.entrySet()) {\n\n        CompletableFuture<TaskExecutorThreadInfoGateway> executorGatewayFuture =\n                executionWithGateway.getValue();\n\n        CompletableFuture<TaskThreadInfoResponse> threadInfo =\n                executorGatewayFuture.thenCompose(\n                        executorGateway ->\n                                executorGateway.requestThreadInfoSamples(\n                                        executionWithGateway.getKey(), requestParams, timeout));\n\n        threadInfo.whenCompleteAsync(\n                (TaskThreadInfoResponse threadInfoSamplesResponse, Throwable throwable) -> {\n                    if (threadInfoSamplesResponse != null) {\n                        handleSuccessfulResponse(\n                                requestParams.getRequestId(),\n                                executionWithGateway.getKey(),\n                                threadInfoSamplesResponse.getSamples());\n                    } else {\n                        handleFailedResponse(requestParams.getRequestId(), throwable);\n                    }\n                },\n                executor);\n    }\n}", "summary_tokens": ["requests", "thread", "infos", "from", "given", "subtasks"], "project": "flink"}
{"id": 8337, "code": "public static float getFloat(MemorySegment[] segments, int offset) {\n    if (inFirstSegment(segments, offset, 4)) {\n        return segments[0].getFloat(offset);\n    } else {\n        return getFloatMultiSegments(segments, offset);\n    }\n}", "summary_tokens": ["get", "float", "from", "segments"], "project": "flink"}
{"id": 6091, "code": "public void testLastHeartbeatFromUnregisteredTarget() {\n    final long heartbeatTimeout = 100L;\n    final ResourceID resourceId = ResourceID.generate();\n    final HeartbeatListener<Object, Object> heartbeatListener =\n            new TestingHeartbeatListenerBuilder<>().createNewTestingHeartbeatListener();\n\n    HeartbeatManager<?, ?> heartbeatManager =\n            new HeartbeatManagerImpl<>(\n                    heartbeatTimeout,\n                    FAILED_RPC_THRESHOLD,\n                    resourceId,\n                    heartbeatListener,\n                    TestingUtils.defaultScheduledExecutor(),\n                    LOG);\n\n    try {\n        assertEquals(-1L, heartbeatManager.getLastHeartbeatFrom(ResourceID.generate()));\n    } finally {\n        heartbeatManager.stop();\n    }\n}", "summary_tokens": ["tests", "that", "the", "last", "heartbeat", "from", "an", "unregistered", "target", "equals", "0"], "project": "flink"}
{"id": 3767, "code": "public void checkCrossWithReplicatedSourceInput() {\n\n    ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    TupleTypeInfo<Tuple1<String>> typeInfo = TupleTypeInfo.getBasicTupleTypeInfo(String.class);\n    ReplicatingInputFormat<Tuple1<String>, FileInputSplit> rif =\n            new ReplicatingInputFormat<Tuple1<String>, FileInputSplit>(\n                    new TupleCsvInputFormat<Tuple1<String>>(new Path(\"/some/path\"), typeInfo));\n\n    DataSet<Tuple1<String>> source1 =\n            env.createInput(\n                    rif, new TupleTypeInfo<Tuple1<String>>(BasicTypeInfo.STRING_TYPE_INFO));\n    DataSet<Tuple1<String>> source2 = env.readCsvFile(\"/some/otherpath\").types(String.class);\n\n    DataSink<Tuple2<Tuple1<String>, Tuple1<String>>> out =\n            source1.cross(source2).writeAsText(\"/some/newpath\");\n\n    Plan plan = env.createProgramPlan();\n\n        \n    OptimizedPlan oPlan = compileNoStats(plan);\n\n        \n        \n    SinkPlanNode sinkNode = oPlan.getDataSinks().iterator().next();\n    DualInputPlanNode crossNode = (DualInputPlanNode) sinkNode.getPredecessor();\n\n    ShipStrategyType crossIn1 = crossNode.getInput1().getShipStrategy();\n    ShipStrategyType crossIn2 = crossNode.getInput2().getShipStrategy();\n\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\", ShipStrategyType.FORWARD, crossIn1);\n    Assert.assertEquals(\n            \"Invalid ship strategy for an operator.\", ShipStrategyType.FORWARD, crossIn2);\n}", "summary_tokens": ["tests", "cross", "program", "with", "replicated", "data", "source"], "project": "flink"}
{"id": 7647, "code": "private StreamGraph createStreamGraphForSlotSharingTest() {\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setBufferTimeout(-1);\n\n    final DataStream<Integer> source1 = env.fromElements(1, 2, 3).name(\"source1\");\n    source1.rebalance().map(v -> v).name(\"map1\");\n\n    final DataStream<Integer> source2 = env.fromElements(4, 5, 6).name(\"source2\");\n    final DataStream<Integer> partitioned =\n            new DataStream<>(\n                    env,\n                    new PartitionTransformation<>(\n                            source2.getTransformation(),\n                            new RebalancePartitioner<>(),\n                            StreamExchangeMode.BATCH));\n    partitioned.map(v -> v).name(\"map2\");\n\n    return env.getStreamGraph();\n}", "summary_tokens": ["create", "a", "stream", "graph", "as", "below"], "project": "flink"}
{"id": 452, "code": "public String getDeleteStatement(String tableName, String[] conditionFields) {\n    String conditionClause =\n            Arrays.stream(conditionFields)\n                    .map(f -> format(\"%s = :%s\", quoteIdentifier(f), f))\n                    .collect(Collectors.joining(\" AND \"));\n    return \"DELETE FROM \" + quoteIdentifier(tableName) + \" WHERE \" + conditionClause;\n}", "summary_tokens": ["a", "simple", "single", "row", "delete", "statement"], "project": "flink"}
{"id": 3285, "code": "public List<Tuple2<String, DataSet<?>>> getSumBcastVars() {\n    return this.bcVarsSum;\n}", "summary_tokens": ["get", "the", "broadcast", "variables", "of", "the", "sum", "function"], "project": "flink"}
{"id": 8386, "code": "public Rowtime watermarksPeriodicAscending() {\n    internalProperties.putString(\n            ROWTIME_WATERMARKS_TYPE, ROWTIME_WATERMARKS_TYPE_VALUE_PERIODIC_ASCENDING);\n    return this;\n}", "summary_tokens": ["sets", "a", "built", "in", "watermark", "strategy", "for", "ascending", "rowtime", "attributes"], "project": "flink"}
{"id": 1323, "code": "public Charset getCharset() {\n    return charset;\n}", "summary_tokens": ["gets", "the", "charset", "used", "by", "this", "schema", "for", "serialization"], "project": "flink"}
{"id": 1995, "code": "public static <K, V> MergeResult<K, V> mergeRightIntoLeft(\n        LinkedOptionalMap<K, V> left, LinkedOptionalMap<K, V> right) {\n    LinkedOptionalMap<K, V> merged = new LinkedOptionalMap<>(left);\n    merged.putAll(right);\n\n    return new MergeResult<>(merged, isLeftPrefixOfRight(left, right));\n}", "summary_tokens": ["tries", "to", "merges", "the", "keys", "and", "the", "values", "of", "into"], "project": "flink"}
{"id": 2315, "code": "private static void executeLastDatedValueFunction(TableEnvironment env) {\n        \n    final Table customers =\n            env.fromValues(\n                    DataTypes.of(\"ROW<name STRING, order_date DATE, item_count INT>\"),\n                    Row.of(\"Guillermo Smith\", LocalDate.parse(\"2020-12-01\"), 3),\n                    Row.of(\"Guillermo Smith\", LocalDate.parse(\"2020-12-05\"), 5),\n                    Row.of(\"Valeria Mendoza\", LocalDate.parse(\"2020-03-23\"), 4),\n                    Row.of(\"Valeria Mendoza\", LocalDate.parse(\"2020-06-02\"), 10),\n                    Row.of(\"Leann Holloway\", LocalDate.parse(\"2020-05-26\"), 9),\n                    Row.of(\"Leann Holloway\", LocalDate.parse(\"2020-05-27\"), null),\n                    Row.of(\"Brandy Sanders\", LocalDate.parse(\"2020-10-14\"), 1),\n                    Row.of(\"John Turner\", LocalDate.parse(\"2020-10-02\"), 12),\n                    Row.of(\"Ellen Ortega\", LocalDate.parse(\"2020-06-18\"), 100));\n    env.createTemporaryView(\"customers\", customers);\n\n        \n    env.createTemporarySystemFunction(\"LastDatedValueFunction\", LastDatedValueFunction.class);\n    env.executeSql(\n                    \"SELECT name, LastDatedValueFunction(item_count, order_date) \"\n                            + \"FROM customers GROUP BY name\")\n            .print();\n\n        \n    env.dropTemporaryView(\"customers\");\n}", "summary_tokens": ["aggregates", "data", "by", "name", "and", "returns", "the", "latest", "non", "null", "item", "count", "value", "with", "its", "corresponding", "order", "date"], "project": "flink"}
{"id": 2955, "code": "protected NumericColumnSummary<Double> summarize(Double... values) {\n\n    DoubleValue[] doubleValues = new DoubleValue[values.length];\n    for (int i = 0; i < values.length; i++) {\n        if (values[i] != null) {\n            doubleValues[i] = new DoubleValue(values[i]);\n        }\n    }\n\n    return new AggregateCombineHarness<\n            DoubleValue,\n            NumericColumnSummary<Double>,\n            ValueSummaryAggregator.DoubleValueSummaryAggregator>() {\n\n        @Override\n        protected void compareResults(\n                NumericColumnSummary<Double> result1, NumericColumnSummary<Double> result2) {\n            Assert.assertEquals(result1.getMin(), result2.getMin(), 0.0);\n            Assert.assertEquals(result1.getMax(), result2.getMax(), 0.0);\n            Assert.assertEquals(result1.getMean(), result2.getMean(), 1e-12d);\n            Assert.assertEquals(result1.getVariance(), result2.getVariance(), 1e-9d);\n            Assert.assertEquals(\n                    result1.getStandardDeviation(), result2.getStandardDeviation(), 1e-12d);\n        }\n    }.summarize(doubleValues);\n}", "summary_tokens": ["helper", "method", "for", "summarizing", "a", "list", "of", "values"], "project": "flink"}
{"id": 6848, "code": "public void testPhysicallyRemoveWithRemove() throws IOException {\n    testPhysicallyRemoveWithFunction(\n            (map, reference, i) -> {\n                map.remove(i, (long) i);\n                return 0;\n            });\n}", "summary_tokens": ["tests", "that", "remove", "states", "physically", "when", "remove", "is", "invoked"], "project": "flink"}
{"id": 7124, "code": "public SingleOutputStreamOperator<T> name(String name) {\n    transformation.setName(name);\n    return this;\n}", "summary_tokens": ["sets", "the", "name", "of", "the", "current", "data", "stream"], "project": "flink"}
{"id": 2428, "code": "public ListVersionsHandler parseListVersionsResponse(\n        InputStream inputStream, final boolean shouldSDKDecodeResponse) throws IOException {\n    ListVersionsHandler handler = new ListVersionsHandler(shouldSDKDecodeResponse);\n    parseXmlInputStream(handler, sanitizeXmlDocument(handler, inputStream));\n    return handler;\n}", "summary_tokens": ["parses", "a", "list", "versions", "response", "xml", "document", "from", "an", "input", "stream"], "project": "flink"}
{"id": 81, "code": "public void testTriggerSavepointCustomTarget() throws Exception {\n    replaceStdOutAndStdErr();\n\n    JobID jobId = new JobID();\n\n    String savepointDirectory = \"customTargetDirectory\";\n\n    final ClusterClient<String> clusterClient = createClusterClient(savepointDirectory);\n\n    try {\n        MockedCliFrontend frontend = new MockedCliFrontend(clusterClient);\n\n        String[] parameters = {jobId.toString(), savepointDirectory};\n        frontend.savepoint(parameters);\n\n        verify(clusterClient, times(1)).triggerSavepoint(eq(jobId), eq(savepointDirectory));\n\n        assertTrue(buffer.toString().contains(savepointDirectory));\n    } finally {\n        clusterClient.close();\n\n        restoreStdOutAndStdErr();\n    }\n}", "summary_tokens": ["tests", "that", "a", "cli", "call", "with", "a", "custom", "savepoint", "directory", "target", "is", "forwarded", "correctly", "to", "the", "cluster", "client"], "project": "flink"}
{"id": 9573, "code": "public void testCoStreamCheckpointingProgram() throws Exception {\n    assertTrue(\"Broken test setup\", NUM_STRINGS % 40 == 0);\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(PARALLELISM);\n    env.enableCheckpointing(50);\n    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(Integer.MAX_VALUE, 0L));\n\n    DataStream<String> stream =\n            env.addSource(new StringGeneratingSourceFunction(NUM_STRINGS, NUM_STRINGS / 5));\n\n    stream\n                \n            .filter(new StringRichFilterFunction())\n\n                \n            .connect(stream)\n            .flatMap(new LeftIdentityCoRichFlatMapFunction())\n\n                \n            .map(new StringPrefixCountRichMapFunction())\n            .startNewChain()\n            .map(new StatefulCounterFunction())\n\n                \n            .keyBy(\"prefix\")\n            .reduce(new OnceFailingReducer(NUM_STRINGS))\n            .addSink(\n                    new SinkFunction<PrefixCount>() {\n\n                        @Override\n                        public void invoke(PrefixCount value) {\n                                \n                        }\n                    });\n\n    TestUtils.tryExecute(env, \"Fault Tolerance Test\");\n\n        \n\n    long filterSum = 0;\n    for (long l : StringRichFilterFunction.counts) {\n        filterSum += l;\n    }\n\n    long coMapSum = 0;\n    for (long l : LeftIdentityCoRichFlatMapFunction.counts) {\n        coMapSum += l;\n    }\n\n    long mapSum = 0;\n    for (long l : StringPrefixCountRichMapFunction.counts) {\n        mapSum += l;\n    }\n\n    long countSum = 0;\n    for (long l : StatefulCounterFunction.counts) {\n        countSum += l;\n    }\n\n        \n    assertEquals(NUM_STRINGS, filterSum);\n    assertEquals(NUM_STRINGS, coMapSum);\n    assertEquals(NUM_STRINGS, mapSum);\n    assertEquals(NUM_STRINGS, countSum);\n}", "summary_tokens": ["runs", "the", "following", "program"], "project": "flink"}
{"id": 942, "code": "protected PulsarRuntime runtime() {\n    return PulsarRuntime.mock();\n}", "summary_tokens": ["choose", "the", "desired", "pulsar", "runtime", "as", "the", "test", "backend"], "project": "flink"}
{"id": 1661, "code": "public static String assembleDynamicConfigsStr(final Map<String, String> config) {\n    return config.entrySet().stream()\n            .map(e -> String.format(\"-D %s=%s\", e.getKey(), e.getValue()))\n            .collect(Collectors.joining(\" \"));\n}", "summary_tokens": ["creates", "a", "dynamic", "parameter", "list", "string", "of", "the", "passed", "configuration", "map"], "project": "flink"}
{"id": 9514, "code": "public void triggerNonPeriodicScheduledTask() {\n    final ScheduledTask<?> poll = nonPeriodicScheduledTasks.remove();\n    if (poll != null) {\n        poll.execute();\n    }\n}", "summary_tokens": ["triggers", "a", "single", "non", "periodically", "scheduled", "task"], "project": "flink"}
{"id": 5932, "code": "public void testCleanUpOnShutdown() throws Exception {\n    JobStatus[] terminalStates =\n            new JobStatus[] {\n                JobStatus.FINISHED, JobStatus.CANCELED, JobStatus.FAILED, JobStatus.SUSPENDED\n            };\n\n    for (JobStatus status : terminalStates) {\n\n        OperatorState state = mock(OperatorState.class);\n        Map<OperatorID, OperatorState> operatorStates = new HashMap<>();\n        operatorStates.put(new OperatorID(), state);\n\n        EmptyStreamStateHandle retainedHandle = new EmptyStreamStateHandle();\n        TestCompletedCheckpointStorageLocation retainedLocation =\n                new TestCompletedCheckpointStorageLocation(retainedHandle, \"ptr\");\n\n            \n        CheckpointProperties retainProps =\n                new CheckpointProperties(\n                        false,\n                        CheckpointType.CHECKPOINT,\n                        false,\n                        false,\n                        false,\n                        false,\n                        false,\n                        false);\n        CompletedCheckpoint checkpoint =\n                new CompletedCheckpoint(\n                        new JobID(),\n                        0,\n                        0,\n                        1,\n                        new HashMap<>(operatorStates),\n                        Collections.emptyList(),\n                        retainProps,\n                        retainedLocation);\n\n        checkpoint.discardOnShutdown(status);\n\n        verify(state, times(0)).discardState();\n        assertFalse(retainedLocation.isDisposed());\n        assertFalse(retainedHandle.isDisposed());\n\n            \n        EmptyStreamStateHandle discardHandle = new EmptyStreamStateHandle();\n        TestCompletedCheckpointStorageLocation discardLocation =\n                new TestCompletedCheckpointStorageLocation(discardHandle, \"ptr\");\n\n            \n        CheckpointProperties discardProps =\n                new CheckpointProperties(\n                        false, CheckpointType.CHECKPOINT, true, true, true, true, true, false);\n\n        checkpoint =\n                new CompletedCheckpoint(\n                        new JobID(),\n                        0,\n                        0,\n                        1,\n                        new HashMap<>(operatorStates),\n                        Collections.emptyList(),\n                        discardProps,\n                        discardLocation);\n\n        checkpoint.discardOnShutdown(status);\n\n        verify(state, times(1)).discardState();\n        assertTrue(discardLocation.isDisposed());\n        assertTrue(discardHandle.isDisposed());\n    }\n}", "summary_tokens": ["tests", "that", "the", "garbage", "collection", "properties", "are", "respected", "when", "shutting", "down"], "project": "flink"}
{"id": 6261, "code": "public void testIsJavaSerializable() throws Exception {\n    JobCheckpointingSettings settings =\n            new JobCheckpointingSettings(\n                    new CheckpointCoordinatorConfiguration(\n                            1231231,\n                            1231,\n                            112,\n                            12,\n                            CheckpointRetentionPolicy.RETAIN_ON_FAILURE,\n                            false,\n                            false,\n                            0,\n                            0),\n                    new SerializedValue<>(new MemoryStateBackend()));\n\n    JobCheckpointingSettings copy = CommonTestUtils.createCopySerializable(settings);\n    assertEquals(\n            settings.getCheckpointCoordinatorConfiguration(),\n            copy.getCheckpointCoordinatorConfiguration());\n    assertNotNull(copy.getDefaultStateBackend());\n    assertTrue(\n            copy.getDefaultStateBackend()\n                            .deserializeValue(this.getClass().getClassLoader())\n                            .getClass()\n                    == MemoryStateBackend.class);\n}", "summary_tokens": ["tests", "that", "the", "settings", "are", "actually", "serializable"], "project": "flink"}
{"id": 2337, "code": "public synchronized void unset(String name) {\n    String[] names = null;\n    if (!isDeprecated(name)) {\n        names = getAlternativeNames(name);\n        if (names == null) {\n            names = new String[] {name};\n        }\n    } else {\n        names = handleDeprecation(deprecationContext.get(), name);\n    }\n\n    for (String n : names) {\n        getOverlay().remove(n);\n        getProps().remove(n);\n    }\n}", "summary_tokens": ["unset", "a", "previously", "set", "property"], "project": "flink"}
{"id": 9485, "code": "public void testIdleReader(TestEnvironment testEnv, ExternalContext<T> externalContext)\n        throws Exception {\n\n    final int splitNumber = 4;\n    final List<List<T>> testRecordsLists = new ArrayList<>();\n    LOG.info(\"Writing test data to split 0 to 3\");\n    for (int i = 0; i < splitNumber; i++) {\n        testRecordsLists.add(generateAndWriteTestData(i, externalContext));\n    }\n\n    LOG.info(\"Submitting Flink job to test environment\");\n    try (CloseableIterator<T> resultIterator =\n            testEnv.createExecutionEnvironment()\n                    .fromSource(\n                            externalContext.createSource(Boundedness.BOUNDED),\n                            WatermarkStrategy.noWatermarks(),\n                            \"Tested Source\")\n                    .setParallelism(splitNumber + 1)\n                    .executeAndCollect(\"Idle Reader Test\")) {\n        LOG.info(\"Checking test results\");\n        assertThat(resultIterator, matchesMultipleSplitTestData(testRecordsLists));\n    }\n}", "summary_tokens": ["test", "connector", "source", "with", "an", "idle", "reader"], "project": "flink"}
{"id": 3071, "code": "private void advanceTime(NFAState nfaState, long timestamp) throws Exception {\n    try (SharedBufferAccessor<IN> sharedBufferAccessor = partialMatches.getAccessor()) {\n        Collection<Tuple2<Map<String, List<IN>>, Long>> timedOut =\n                nfa.advanceTime(sharedBufferAccessor, nfaState, timestamp);\n        if (!timedOut.isEmpty()) {\n            processTimedOutSequences(timedOut);\n        }\n    }\n}", "summary_tokens": ["advances", "the", "time", "for", "the", "given", "nfa", "to", "the", "given", "timestamp"], "project": "flink"}
{"id": 7268, "code": "public JobClient executeAsync(StreamGraph streamGraph) throws Exception {\n    checkNotNull(streamGraph, \"StreamGraph cannot be null.\");\n    checkNotNull(\n            configuration.get(DeploymentOptions.TARGET),\n            \"No execution.target specified in your configuration file.\");\n\n    final PipelineExecutorFactory executorFactory =\n            executorServiceLoader.getExecutorFactory(configuration);\n\n    checkNotNull(\n            executorFactory,\n            \"Cannot find compatible factory for specified execution.target (=%s)\",\n            configuration.get(DeploymentOptions.TARGET));\n\n    CompletableFuture<JobClient> jobClientFuture =\n            executorFactory\n                    .getExecutor(configuration)\n                    .execute(streamGraph, configuration, userClassloader);\n\n    try {\n        JobClient jobClient = jobClientFuture.get();\n        jobListeners.forEach(jobListener -> jobListener.onJobSubmitted(jobClient, null));\n        return jobClient;\n    } catch (ExecutionException executionException) {\n        final Throwable strippedException =\n                ExceptionUtils.stripExecutionException(executionException);\n        jobListeners.forEach(\n                jobListener -> jobListener.onJobSubmitted(null, strippedException));\n\n        throw new FlinkException(\n                String.format(\"Failed to execute job '%s'.\", streamGraph.getJobName()),\n                strippedException);\n    }\n}", "summary_tokens": ["triggers", "the", "program", "execution", "asynchronously"], "project": "flink"}
{"id": 6941, "code": "public void enableBlockCachePinnedUsage() {\n    this.properties.add(RocksDBProperty.BlockCachePinnedUsage.getRocksDBProperty());\n}", "summary_tokens": ["returns", "the", "memory", "size", "for", "the", "entries", "being", "pinned", "in", "block", "cache"], "project": "flink"}
{"id": 453, "code": "public String getSelectFromStatement(\n        String tableName, String[] selectFields, String[] conditionFields) {\n    String selectExpressions =\n            Arrays.stream(selectFields)\n                    .map(this::quoteIdentifier)\n                    .collect(Collectors.joining(\", \"));\n    String fieldExpressions =\n            Arrays.stream(conditionFields)\n                    .map(f -> format(\"%s = :%s\", quoteIdentifier(f), f))\n                    .collect(Collectors.joining(\" AND \"));\n    return \"SELECT \"\n            + selectExpressions\n            + \" FROM \"\n            + quoteIdentifier(tableName)\n            + (conditionFields.length > 0 ? \" WHERE \" + fieldExpressions : \"\");\n}", "summary_tokens": ["a", "simple", "select", "statement"], "project": "flink"}
{"id": 6805, "code": "public static int getValueMetaLen() {\n    return VALUE_DATA_OFFSET;\n}", "summary_tokens": ["returns", "the", "length", "of", "value", "meta"], "project": "flink"}
{"id": 8982, "code": "private void doRewrite(\n        RelBuilder relBuilder,\n        Aggregate aggregate,\n        int n,\n        List<Integer> argList,\n        int filterArg,\n        List<RexInputRef> refs) {\n    final RexBuilder rexBuilder = aggregate.getCluster().getRexBuilder();\n    final List<RelDataTypeField> leftFields;\n    if (n == 0) {\n        leftFields = null;\n    } else {\n        leftFields = relBuilder.peek().getRowType().getFieldList();\n    }\n\n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n        \n\n        \n        \n    final Map<Integer, Integer> sourceOf = new HashMap<>();\n    createSelectDistinct(relBuilder, aggregate, argList, filterArg, sourceOf);\n\n        \n        \n        \n        \n        \n        \n    final List<AggregateCall> aggCallList = new ArrayList<>();\n    final List<AggregateCall> aggCalls = aggregate.getAggCallList();\n\n    final int groupCount = aggregate.getGroupCount();\n    int i = groupCount - 1;\n    for (AggregateCall aggCall : aggCalls) {\n        ++i;\n\n            \n            \n            \n            \n        if (!aggCall.isDistinct()) {\n            continue;\n        }\n        if (!aggCall.getArgList().equals(argList)) {\n            continue;\n        }\n\n            \n        final int argCount = aggCall.getArgList().size();\n        final List<Integer> newArgs = new ArrayList<>(argCount);\n        for (int j = 0; j < argCount; j++) {\n            final Integer arg = aggCall.getArgList().get(j);\n            newArgs.add(sourceOf.get(arg));\n        }\n        final int newFilterArg = aggCall.filterArg >= 0 ? sourceOf.get(aggCall.filterArg) : -1;\n        final AggregateCall newAggCall =\n                AggregateCall.create(\n                        aggCall.getAggregation(),\n                        false,\n                        aggCall.isApproximate(),\n                        false,\n                        newArgs,\n                        newFilterArg,\n                        RelCollations.EMPTY,\n                        aggCall.getType(),\n                        aggCall.getName());\n        assert refs.get(i) == null;\n        if (n == 0) {\n            refs.set(i, new RexInputRef(groupCount + aggCallList.size(), newAggCall.getType()));\n        } else {\n            refs.set(\n                    i,\n                    new RexInputRef(\n                            leftFields.size() + groupCount + aggCallList.size(),\n                            newAggCall.getType()));\n        }\n        aggCallList.add(newAggCall);\n    }\n\n    final Map<Integer, Integer> map = new HashMap<>();\n    for (Integer key : aggregate.getGroupSet()) {\n        map.put(key, map.size());\n    }\n    final ImmutableBitSet newGroupSet = aggregate.getGroupSet().permute(map);\n    assert newGroupSet.equals(ImmutableBitSet.range(aggregate.getGroupSet().cardinality()));\n    relBuilder.push(\n            aggregate.copy(\n                    aggregate.getTraitSet(),\n                    relBuilder.build(),\n                    newGroupSet,\n                    null,\n                    aggCallList));\n\n        \n    if (n == 0) {\n        return;\n    }\n\n        \n        \n        \n    final List<RelDataTypeField> distinctFields = relBuilder.peek().getRowType().getFieldList();\n    final List<RexNode> conditions = com.google.common.collect.Lists.newArrayList();\n    for (i = 0; i < groupCount; ++i) {\n            \n            \n            \n        conditions.add(\n                rexBuilder.makeCall(\n                        SqlStdOperatorTable.IS_NOT_DISTINCT_FROM,\n                        RexInputRef.of(i, leftFields),\n                        new RexInputRef(\n                                leftFields.size() + i, distinctFields.get(i).getType())));\n    }\n\n        \n    relBuilder.join(JoinRelType.INNER, conditions);\n}", "summary_tokens": ["converts", "all", "distinct", "aggregate", "calls", "to", "a", "given", "set", "of", "arguments"], "project": "flink"}
{"id": 4682, "code": "protected int getCurrentBackoff() {\n    return currentBackoff <= 0 ? 0 : currentBackoff;\n}", "summary_tokens": ["returns", "the", "current", "backoff", "in", "ms"], "project": "flink"}
{"id": 3744, "code": "public void testBranchingDisjointPlan() {\n        \n    final String out1Path = \"file:///test/1\";\n    final String out2Path = \"file:///test/2\";\n    final String out3Path = \"file:///test/3\";\n    final String out4Path = \"file:///test/4\";\n\n        \n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n    DataSet<Long> sourceA = env.generateSequence(0, 1);\n    DataSet<Long> sourceB = env.generateSequence(0, 1);\n\n    sourceA.writeAsText(out1Path);\n    sourceB.writeAsText(out2Path);\n    sourceA.writeAsText(out3Path);\n    sourceB.writeAsText(out4Path);\n\n    Plan plan = env.createProgramPlan();\n    compileNoStats(plan);\n}", "summary_tokens": ["pre", "sink", "0", "sink", "0", "sink", "0", "sink", "0", "src", "a", "src", "b", "pre"], "project": "flink"}
{"id": 4745, "code": "public void setOperatorLevelCachingDescription(String operatorLevelCachingDescription) {\n    this.operatorLevelCachingDescription = operatorLevelCachingDescription;\n}", "summary_tokens": ["sets", "the", "operator", "level", "caching", "description", "for", "this", "input"], "project": "flink"}
{"id": 6750, "code": "private int getRandomIndexLevel() {\n    int x = randomSeed;\n    x ^= x << 13;\n    x ^= x >>> 17;\n    x ^= x << 5;\n    randomSeed = x;\n        \n    if ((x & 0x8001) != 0) {\n        return 0;\n    }\n    int level = 1;\n    int curMax = levelIndexHeader.getLevel();\n    x >>>= 1;\n    while ((x & 1) != 0) {\n        ++level;\n        x >>>= 1;\n            \n        if (level > curMax) {\n            break;\n        }\n    }\n    return level;\n}", "summary_tokens": ["return", "a", "random", "level", "for", "new", "node"], "project": "flink"}
{"id": 3853, "code": "public void setCurrentKey(Object key) {\n    keyForTimerService = key;\n}", "summary_tokens": ["as", "the", "beam", "state", "g", "rpc", "service", "will", "access", "the", "keyed", "state", "backend", "in", "parallel", "with", "this", "operator", "we", "must", "override", "this", "method", "to", "prevent", "changing", "the", "current", "key", "of", "the", "keyed", "state", "backend", "while", "the", "beam", "service", "is", "handling", "requests"], "project": "flink"}
{"id": 480, "code": "public void noDuplication() throws Exception {\n    sinkHelper.notifyCheckpointComplete(0);\n    TestXaSinkStateHandler newState = new TestXaSinkStateHandler();\n    newState.store(sinkHelper.getState().load(null));\n    sinkHelper.emitAndSnapshot(JdbcTestFixture.CP0);\n    sinkHelper.close(); \n    sinkHelper = buildSinkHelper(newState);\n    sinkHelper.emitAndCheckpoint(JdbcTestFixture.CP0);\n    xaHelper.assertDbContentsEquals(JdbcTestFixture.CP0);\n}", "summary_tokens": ["checkpoint", "capture", "state", "emit", "snapshot", "close", "init", "captured", "state", "open", "emit", "checkpoint"], "project": "flink"}
{"id": 5597, "code": "public ExecutionAttemptID getID() {\n    return this.executionId;\n}", "summary_tokens": ["returns", "the", "id", "of", "the", "task", "this", "result", "belongs", "to"], "project": "flink"}
{"id": 6305, "code": "public synchronized CompletableFuture<LeaderConnectionInfo> getConfirmationFuture() {\n    return confirmationFuture;\n}", "summary_tokens": ["gets", "a", "future", "that", "completes", "when", "leadership", "is", "confirmed"], "project": "flink"}
{"id": 7882, "code": "public void testBatchAndNonBatchTake() throws InterruptedException {\n    final List<Mail> mails =\n            IntStream.range(0, 6)\n                    .mapToObj(i -> new Mail(NO_OP, DEFAULT_PRIORITY, String.valueOf(i)))\n                    .collect(Collectors.toList());\n\n        \n    mails.subList(0, 3).forEach(taskMailbox::put);\n    Assert.assertTrue(taskMailbox.createBatch());\n        \n    mails.subList(3, 6).forEach(taskMailbox::put);\n\n        \n    assertEquals(Optional.ofNullable(mails.get(0)), taskMailbox.tryTakeFromBatch());\n    assertEquals(Optional.ofNullable(mails.get(1)), taskMailbox.tryTake(DEFAULT_PRIORITY));\n    assertEquals(mails.get(2), taskMailbox.take(DEFAULT_PRIORITY));\n\n        \n    assertEquals(Optional.empty(), taskMailbox.tryTakeFromBatch());\n    assertEquals(Optional.ofNullable(mails.get(3)), taskMailbox.tryTake(DEFAULT_PRIORITY));\n    assertEquals(mails.get(4), taskMailbox.take(DEFAULT_PRIORITY));\n\n        \n    assertEquals(Collections.singletonList(mails.get(5)), taskMailbox.close());\n}", "summary_tokens": ["tests", "the", "interaction", "of", "batch", "and", "non", "batch", "methods"], "project": "flink"}
{"id": 742, "code": "public void setFailOnError(boolean failOnError) {\n    this.failOnError = failOnError;\n}", "summary_tokens": ["if", "set", "to", "true", "the", "producer", "will", "immediately", "fail", "with", "an", "exception", "on", "any", "error"], "project": "flink"}
{"id": 3876, "code": "public Iterable<Map.Entry<K, V>> entries() {\n    return Collections.unmodifiableSet(state.entrySet());\n}", "summary_tokens": ["returns", "all", "the", "mappings", "in", "the", "state", "in", "a", "collections", "unmodifiable", "set", "set"], "project": "flink"}
{"id": 6860, "code": "public void testUpdateToMoreThanMaximumAllowed() {\n    try {\n        heapHeadIndex.updateLevel(MAX_LEVEL + 1);\n        Assert.fail(\"Should throw exception\");\n    } catch (Exception e) {\n        Assert.assertTrue(e instanceof IllegalArgumentException);\n    }\n}", "summary_tokens": ["test", "update", "to", "more", "than", "max", "level", "is", "not", "allowed"], "project": "flink"}
{"id": 7314, "code": "public byte[] getSerializedData() {\n    return serializedData;\n}", "summary_tokens": ["gets", "the", "binary", "data", "for", "the", "serialized", "elements"], "project": "flink"}
{"id": 6156, "code": "public void testForwardsRecycleBuffer1() {\n    ReadOnlySlicedNetworkBuffer slice = buffer.readOnlySlice();\n    assertFalse(slice.isRecycled());\n    slice.recycleBuffer();\n    assertTrue(slice.isRecycled());\n    assertTrue(buffer.isRecycled());\n}", "summary_tokens": ["tests", "forwarding", "of", "both", "read", "only", "sliced", "network", "buffer", "recycle", "buffer", "and", "read", "only", "sliced", "network", "buffer", "is", "recycled"], "project": "flink"}
{"id": 9389, "code": "public static int getInt(MemorySegment[] segments, int offset) {\n    if (inFirstSegment(segments, offset, 4)) {\n        return segments[0].getInt(offset);\n    } else {\n        return getIntMultiSegments(segments, offset);\n    }\n}", "summary_tokens": ["get", "int", "from", "segments"], "project": "flink"}
{"id": 7382, "code": "default void setOutputType(TypeInformation<OUT> type, ExecutionConfig executionConfig) {}", "summary_tokens": ["is", "called", "by", "the", "stream", "graph", "add", "operator", "method", "when", "the", "stream", "graph", "is", "generated"], "project": "flink"}
{"id": 2221, "code": "public static Collection<java.nio.file.Path> prepareTestFiles(final java.nio.file.Path dir)\n        throws IOException {\n    final java.nio.file.Path jobSubDir1 = Files.createDirectory(dir.resolve(\"_sub_dir1\"));\n    final java.nio.file.Path jobSubDir2 = Files.createDirectory(dir.resolve(\"_sub_dir2\"));\n    final java.nio.file.Path jarFile1 = Files.createFile(dir.resolve(\"file1.jar\"));\n    final java.nio.file.Path jarFile2 = Files.createFile(dir.resolve(\"file2.jar\"));\n    final java.nio.file.Path jarFile3 = Files.createFile(jobSubDir1.resolve(\"file3.jar\"));\n    final java.nio.file.Path jarFile4 = Files.createFile(jobSubDir2.resolve(\"file4.jar\"));\n    final Collection<java.nio.file.Path> jarFiles = new ArrayList<>();\n\n    Files.createFile(dir.resolve(\"file1.txt\"));\n    Files.createFile(jobSubDir2.resolve(\"file2.txt\"));\n\n    jarFiles.add(jarFile1);\n    jarFiles.add(jarFile2);\n    jarFiles.add(jarFile3);\n    jarFiles.add(jarFile4);\n    return jarFiles;\n}", "summary_tokens": ["generate", "some", "files", "in", "the", "directory", "dir"], "project": "flink"}
{"id": 9394, "code": "public static void setShort(MemorySegment[] segments, int offset, short value) {\n    if (inFirstSegment(segments, offset, 2)) {\n        segments[0].putShort(offset, value);\n    } else {\n        setShortMultiSegments(segments, offset, value);\n    }\n}", "summary_tokens": ["set", "short", "from", "segments"], "project": "flink"}
{"id": 743, "code": "public void setQueueLimit(int queueLimit) {\n    checkArgument(queueLimit > 0, \"queueLimit must be a positive number\");\n    this.queueLimit = queueLimit;\n}", "summary_tokens": ["the", "kinesis", "producer", "holds", "an", "unbounded", "queue", "internally"], "project": "flink"}
{"id": 2318, "code": "public void accumulate(Accumulator<T> acc, T input, LocalDate date) {\n    if (input != null && (acc.date == null || date.isAfter(acc.date))) {\n        acc.value = input;\n        acc.date = date;\n    }\n}", "summary_tokens": ["generic", "runtime", "function", "that", "will", "be", "called", "with", "different", "kind", "of", "instances", "for", "input", "depending", "on", "actual", "call", "in", "the", "query"], "project": "flink"}
{"id": 5441, "code": "public void notifyCheckpointAborted(long checkpointId) {\n    localStateStore.abortCheckpoint(checkpointId);\n}", "summary_tokens": ["tracking", "when", "some", "local", "state", "can", "be", "disposed"], "project": "flink"}
{"id": 4546, "code": "public int finish() {\n    int writtenBytes = positionMarker.markFinished();\n    commit();\n    return writtenBytes;\n}", "summary_tokens": ["mark", "this", "buffer", "builder", "and", "associated", "buffer", "consumer", "as", "finished", "no", "new", "data", "writes", "will", "be", "allowed"], "project": "flink"}
{"id": 52, "code": "public Optional<File> getJarFile() {\n    return Optional.empty();\n}", "summary_tokens": ["always", "returns", "an", "empty", "optional", "because", "this", "implementation", "relies", "on", "the", "jar", "archive", "being", "available", "on", "either", "the", "user", "or", "the", "system", "classpath"], "project": "flink"}
{"id": 4885, "code": "public void notifyOfRemovedView(View view) {\n    synchronized (lock) {\n        toRemove.add(view);\n    }\n}", "summary_tokens": ["notifies", "this", "view", "updater", "of", "a", "metric", "that", "should", "no", "longer", "be", "regularly", "updated"], "project": "flink"}
{"id": 8254, "code": "public CatalogTableStatistics copy() {\n    return new CatalogTableStatistics(\n            this.rowCount,\n            this.fileCount,\n            this.totalSize,\n            this.rawDataSize,\n            new HashMap<>(this.properties));\n}", "summary_tokens": ["create", "a", "deep", "copy", "of", "this", "instance"], "project": "flink"}
{"id": 9096, "code": "public static BinaryStringData trim(BinaryStringData str, BinaryStringData trimStr) {\n    if (trimStr == null) {\n        return null;\n    }\n    return trimRight(trimLeft(str, trimStr), trimStr);\n}", "summary_tokens": ["walk", "each", "character", "of", "current", "string", "from", "both", "ends", "remove", "the", "character", "if", "it", "is", "in", "trim", "string"], "project": "flink"}
{"id": 2995, "code": "public static Map<String, String> getCommonLabels(String clusterId) {\n    final Map<String, String> commonLabels = new HashMap<>();\n    commonLabels.put(Constants.LABEL_TYPE_KEY, Constants.LABEL_TYPE_NATIVE_TYPE);\n    commonLabels.put(Constants.LABEL_APP_KEY, clusterId);\n\n    return commonLabels;\n}", "summary_tokens": ["get", "the", "common", "labels", "for", "flink", "native", "clusters"], "project": "flink"}
{"id": 5769, "code": "private void testGetTransientRemoteDeleteFails(@Nullable final JobID jobId) throws IOException {\n    assumeTrue(!OperatingSystem.isWindows()); \n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    File blobFile = null;\n    File directory = null;\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n        try {\n            byte[] data = new byte[2000000];\n            rnd.nextBytes(data);\n\n                \n            TransientBlobKey key = (TransientBlobKey) put(server, jobId, data, TRANSIENT_BLOB);\n            assertNotNull(key);\n\n            blobFile = server.getStorageLocation(jobId, key);\n            directory = blobFile.getParentFile();\n\n            assertTrue(blobFile.setWritable(false, false));\n            assertTrue(directory.setWritable(false, false));\n\n                \n            verifyContents(cache, jobId, key, data);\n                \n            assertTrue(delete(cache, jobId, key));\n            File blobFileAtCache =\n                    cache.getTransientBlobService().getStorageLocation(jobId, key);\n            assertFalse(blobFileAtCache.exists());\n\n                \n            verifyContents(server, jobId, key, data);\n                \n            verifyContents(cache, jobId, key, data);\n        } finally {\n            if (blobFile != null && directory != null) {\n                    \n                blobFile.setWritable(true, false);\n                    \n                directory.setWritable(true, false);\n            }\n        }\n    }\n}", "summary_tokens": ["uploads", "a", "byte", "array", "for", "the", "given", "job", "and", "verifies", "that", "a", "get", "operation", "of", "a", "transient", "blob", "via", "the", "blob", "cache", "service", "also", "deletes", "the", "file", "on", "the", "blob", "server", "does", "not", "fail", "even", "if", "the", "file", "is", "not", "deletable", "on", "the", "blob", "server", "e"], "project": "flink"}
{"id": 3514, "code": "public void remove() {\n    if (currentKey == null) {\n        return;\n    }\n\n    for (StateDescriptor<?, ?> descriptor : descriptors) {\n        try {\n            State state =\n                    backend.getPartitionedState(\n                            VoidNamespace.INSTANCE,\n                            VoidNamespaceSerializer.INSTANCE,\n                            descriptor);\n\n            state.clear();\n        } catch (Exception e) {\n            throw new RuntimeException(\n                    \"Failed to drop partitioned state from state backend\", e);\n        }\n    }\n}", "summary_tokens": ["removes", "the", "current", "key", "from", "b", "all", "b", "known", "states", "in", "the", "state", "backend"], "project": "flink"}
{"id": 9612, "code": "public void testScaleUpOnAdditionalTaskManager() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    final DataStream<String> input = env.addSource(new DummySource());\n    input.addSink(new DiscardingSink<>());\n\n    final JobClient jobClient = env.executeAsync();\n\n    waitUntilParallelismForVertexReached(\n            miniClusterResource.getRestClusterClient(),\n            jobClient.getJobID(),\n            NUMBER_SLOTS_PER_TASK_MANAGER * INITIAL_NUMBER_TASK_MANAGERS);\n\n        \n    miniClusterResource.getMiniCluster().startTaskManager();\n\n    waitUntilParallelismForVertexReached(\n            miniClusterResource.getRestClusterClient(),\n            jobClient.getJobID(),\n            NUMBER_SLOTS_PER_TASK_MANAGER * (INITIAL_NUMBER_TASK_MANAGERS + 1));\n}", "summary_tokens": ["test", "that", "a", "job", "scales", "up", "when", "a", "task", "manager", "gets", "added", "to", "the", "cluster"], "project": "flink"}
{"id": 5924, "code": "public void testExceptionOnNoRetainedCheckpoints() throws Exception {\n    createRecoveredCompletedCheckpointStore(0);\n}", "summary_tokens": ["tests", "that", "at", "least", "one", "checkpoint", "needs", "to", "be", "retained"], "project": "flink"}
{"id": 9294, "code": "public static CumulativeWindowAssigner of(Duration maxSize, Duration step) {\n    return new CumulativeWindowAssigner(maxSize.toMillis(), step.toMillis(), 0, true);\n}", "summary_tokens": ["creates", "a", "new", "cumulative", "window", "assigner", "that", "assigns", "elements", "to", "cumulative", "time", "windows", "based", "on", "the", "element", "timestamp"], "project": "flink"}
{"id": 3936, "code": "public void testDeserializeListTooShort1() throws Exception {\n        \n    KvStateSerializer.deserializeList(new byte[] {1}, LongSerializer.INSTANCE);\n}", "summary_tokens": ["tests", "list", "deserialization", "with", "too", "few", "bytes"], "project": "flink"}
{"id": 6473, "code": "public void testStaticFileServerHandler() throws Exception {\n    final File file = temporaryFolder.newFile();\n    Files.write(file.toPath(), Collections.singletonList(\"foobar\"));\n\n    final URL url = new URL(serverEndpoint.getRestBaseUrl() + \"/\" + file.getName());\n    final HttpURLConnection connection = (HttpURLConnection) url.openConnection();\n    connection.setRequestMethod(\"GET\");\n    final String fileContents = IOUtils.toString(connection.getInputStream());\n\n    assertEquals(\"foobar\", fileContents.trim());\n}", "summary_tokens": ["tests", "that", "files", "can", "be", "served", "with", "the", "static", "file", "server", "handler"], "project": "flink"}
{"id": 4582, "code": "public ResultSubpartitionView.AvailabilityWithBacklog getAvailabilityAndBacklog() {\n    return subpartitionView.getAvailabilityAndBacklog(numCreditsAvailable);\n}", "summary_tokens": ["returns", "true", "only", "if", "the", "next", "buffer", "is", "an", "event", "or", "the", "reader", "has", "both", "available", "credits", "and", "buffers"], "project": "flink"}
{"id": 526, "code": "public KafkaSource<OUT> build() {\n    sanityCheck();\n    parseAndSetRequiredProperties();\n    return new KafkaSource<>(\n            subscriber,\n            startingOffsetsInitializer,\n            stoppingOffsetsInitializer,\n            boundedness,\n            deserializationSchema,\n            props);\n}", "summary_tokens": ["build", "the", "kafka", "source"], "project": "flink"}
{"id": 3308, "code": "public TriangleListingBase<K, VV, EV, R> setPermuteResults(boolean permuteResults) {\n    this.permuteResults = permuteResults;\n\n    return this;\n}", "summary_tokens": ["by", "default", "only", "one", "result", "is", "output", "for", "each", "triangle", "whether", "vertices", "are", "sorted", "or", "unsorted"], "project": "flink"}
{"id": 3599, "code": "public ShipStrategyType getShipStrategy() {\n    return this.shipStrategy;\n}", "summary_tokens": ["gets", "the", "shipping", "strategy", "for", "this", "connection"], "project": "flink"}
{"id": 4406, "code": "public CompletableFuture<Acknowledge> triggerCheckpoint(\n        long checkpointId, long timestamp, CheckpointOptions checkpointOptions) {\n    return triggerCheckpointHelper(checkpointId, timestamp, checkpointOptions);\n}", "summary_tokens": ["trigger", "a", "new", "checkpoint", "on", "the", "task", "of", "this", "execution"], "project": "flink"}
{"id": 3116, "code": "private static PatternProcessFunction<Event, String> extractTimestampAndNames(\n        int stateNumber, OutputTag<String> timedOutTag) {\n    return new AccessContextWithNamesWithTimedOut(\n            stateNumber, timedOutTag, context -> String.valueOf(context.timestamp()));\n}", "summary_tokens": ["creates", "a", "pattern", "process", "function", "that", "as", "a", "result", "will", "produce", "strings", "as", "follows", "timestamp", "event"], "project": "flink"}
{"id": 3447, "code": "public void testGroupReduceOnNeighborsInvalidEdgeSrcId() throws Exception {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(PARALLELISM);\n\n    Graph<Long, Long, Long> graph =\n            Graph.fromDataSet(\n                    TestGraphUtils.getLongLongVertexData(env),\n                    TestGraphUtils.getLongLongEdgeInvalidTrgData(env),\n                    env);\n\n    try {\n        DataSet<Tuple2<Long, Long>> verticesWithSumOfAllNeighborValues =\n                graph.reduceOnNeighbors(new SumNeighbors(), EdgeDirection.ALL);\n\n        verticesWithSumOfAllNeighborValues.output(new DiscardingOutputFormat<>());\n        env.execute();\n    } catch (Exception e) {\n            \n    }\n}", "summary_tokens": ["test", "group", "reduce", "on", "neighbors", "neighbors", "function", "with", "an", "edge", "having", "a", "src", "id", "that", "does", "not", "exist", "in", "the", "vertex", "data", "set"], "project": "flink"}
{"id": 2074, "code": "public static TemporaryClassLoaderContext of(ClassLoader cl) {\n    final Thread t = Thread.currentThread();\n    final ClassLoader original = t.getContextClassLoader();\n\n    t.setContextClassLoader(cl);\n\n    return new TemporaryClassLoaderContext(t, original);\n}", "summary_tokens": ["sets", "the", "context", "class", "loader", "to", "the", "given", "class", "loader", "and", "returns", "a", "resource", "that", "sets", "it", "back", "to", "the", "current", "context", "class", "loader", "when", "the", "resource", "is", "closed"], "project": "flink"}
{"id": 8448, "code": "public static ObjectIdentifier normalizeObjectIdentifier(ObjectIdentifier oi) {\n    return ObjectIdentifier.of(\n            oi.getCatalogName(), oi.getDatabaseName(), normalizeName(oi.getObjectName()));\n}", "summary_tokens": ["normalize", "an", "object", "identifier", "by", "only", "normalizing", "the", "function", "name"], "project": "flink"}
{"id": 9072, "code": "public static MapEntry<String, String> entry(String key, String value) {\n    return new MapEntry<>(key, value);\n}", "summary_tokens": ["helper", "method", "for", "easier", "creating", "maps", "in", "matchers"], "project": "flink"}
{"id": 8525, "code": "public static void validateStructuredClass(Class<?> clazz) {\n    final int m = clazz.getModifiers();\n    if (Modifier.isAbstract(m)) {\n        throw extractionError(\"Class '%s' must not be abstract.\", clazz.getName());\n    }\n    if (!Modifier.isPublic(m)) {\n        throw extractionError(\"Class '%s' is not public.\", clazz.getName());\n    }\n    if (clazz.getEnclosingClass() != null\n            && (clazz.getDeclaringClass() == null || !Modifier.isStatic(m))) {\n        throw extractionError(\n                \"Class '%s' is a not a static, globally accessible class.\", clazz.getName());\n    }\n}", "summary_tokens": ["validates", "the", "characteristics", "of", "a", "class", "for", "a", "structured", "type", "such", "as", "accessibility"], "project": "flink"}
{"id": 841, "code": "private static <T> KinesisPartitioner<T> initializePartitioner(\n        String name, ClassLoader classLoader) {\n    try {\n        Class<?> clazz = Class.forName(name, true, classLoader);\n        if (!KinesisPartitioner.class.isAssignableFrom(clazz)) {\n            throw new ValidationException(\n                    String.format(\n                            \"Partitioner class '%s' should have %s in its parents chain\",\n                            name, KinesisPartitioner.class.getName()));\n        }\n        @SuppressWarnings(\"unchecked\")\n        final KinesisPartitioner<T> partitioner =\n                InstantiationUtil.instantiate(name, KinesisPartitioner.class, classLoader);\n\n        return partitioner;\n    } catch (ClassNotFoundException | FlinkException e) {\n        throw new ValidationException(\n                String.format(\"Could not find and instantiate partitioner class '%s'\", name),\n                e);\n    }\n}", "summary_tokens": ["returns", "a", "class", "value", "with", "the", "given", "class", "name"], "project": "flink"}
{"id": 3792, "code": "static PythonEnvironment preparePythonEnvironment(\n        ReadableConfig config, String entryPointScript, String tmpDir) throws IOException {\n    PythonEnvironment env = new PythonEnvironment();\n\n        \n    String pythonExec =\n            config.getOptional(PYTHON_CLIENT_EXECUTABLE)\n                    .orElse(System.getenv(PYFLINK_CLIENT_EXECUTABLE));\n    if (pythonExec != null) {\n        env.pythonExec = pythonExec;\n    }\n\n        \n    tmpDir = new File(tmpDir).getAbsolutePath();\n    Path tmpDirPath = new Path(tmpDir);\n    tmpDirPath.getFileSystem().mkdirs(tmpDirPath);\n    env.tempDirectory = tmpDir;\n\n        \n    if (System.getenv(ConfigConstants.ENV_FLINK_OPT_DIR) != null) {\n        String pythonLibDir =\n                System.getenv(ConfigConstants.ENV_FLINK_OPT_DIR) + File.separator + \"python\";\n        env.pythonPath =\n                getLibFiles(pythonLibDir).stream()\n                        .map(p -> p.toFile().getAbsolutePath())\n                        .collect(Collectors.joining(File.pathSeparator));\n    }\n\n        \n    if (config.getOptional(PYTHON_FILES).isPresent()) {\n        List<Path> pythonFiles =\n                Arrays.stream(config.get(PYTHON_FILES).split(FILE_DELIMITER))\n                        .map(Path::new)\n                        .collect(Collectors.toList());\n        addToPythonPath(env, pythonFiles);\n    }\n\n        \n        \n    if (config.getOptional(PYTHON_ARCHIVES).isPresent()\n            && (config.getOptional(PYTHON_CLIENT_EXECUTABLE).isPresent()\n                    || !StringUtils.isNullOrWhitespaceOnly(\n                            System.getenv(PYFLINK_CLIENT_EXECUTABLE)))) {\n        env.archivesDirectory = String.join(File.separator, tmpDir, PYTHON_ARCHIVES_DIR);\n\n            \n        config.getOptional(PYTHON_ARCHIVES)\n                .ifPresent(\n                        pyArchives -> {\n                            for (String archive : pyArchives.split(FILE_DELIMITER)) {\n                                final Path archivePath;\n                                final String targetDirName;\n                                final String originalFileName;\n                                if (archive.contains(PythonDependencyUtils.PARAM_DELIMITER)) {\n                                    String[] filePathAndTargetDir =\n                                            archive.split(\n                                                    PythonDependencyUtils.PARAM_DELIMITER, 2);\n                                    archivePath = new Path(filePathAndTargetDir[0]);\n                                    targetDirName = filePathAndTargetDir[1];\n                                    originalFileName = archivePath.getName();\n                                } else {\n                                    archivePath = new Path(archive);\n                                    targetDirName = archivePath.getName();\n                                    originalFileName = targetDirName;\n                                }\n                                try {\n                                    CompressionUtils.extractFile(\n                                            archivePath.getPath(),\n                                            String.join(\n                                                    File.separator,\n                                                    env.archivesDirectory,\n                                                    targetDirName),\n                                            originalFileName);\n                                } catch (IOException e) {\n                                    throw new RuntimeException(\n                                            \"Extract archives to archives directory failed.\",\n                                            e);\n                                }\n                            }\n                        });\n    }\n\n    if (entryPointScript != null) {\n        addToPythonPath(env, Collections.singletonList(new Path(entryPointScript)));\n    }\n    return env;\n}", "summary_tokens": ["prepares", "python", "environment", "to", "start", "python", "process"], "project": "flink"}
{"id": 7876, "code": "public void testCheckpointBarrierMetrics() throws Exception {\n    final TwoInputStreamTaskTestHarness<String, Integer, String> testHarness =\n            new TwoInputStreamTaskTestHarness<>(\n                    TwoInputStreamTask::new,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n    final StreamConfig streamConfig = testHarness.getStreamConfig();\n    final CoStreamMap<String, Integer, String> coMapOperator =\n            new CoStreamMap<>(new IdentityMap());\n    testHarness.setupOutputForSingletonOperatorChain();\n    streamConfig.setStreamOperator(coMapOperator);\n\n    final Map<String, Metric> metrics = new ConcurrentHashMap<>();\n    final TaskMetricGroup taskMetricGroup =\n            StreamTaskTestHarness.createTaskMetricGroup(metrics);\n    final StreamMockEnvironment environment = testHarness.createEnvironment();\n    environment.setTaskMetricGroup(taskMetricGroup);\n\n    testHarness.invoke(environment);\n    testHarness.waitForTaskRunning();\n\n    assertThat(metrics, IsMapContaining.hasKey(MetricNames.CHECKPOINT_ALIGNMENT_TIME));\n    assertThat(metrics, IsMapContaining.hasKey(MetricNames.CHECKPOINT_START_DELAY_TIME));\n\n    testHarness.endInput();\n    testHarness.waitForTaskCompletion();\n}", "summary_tokens": ["tests", "the", "checkpoint", "related", "metrics", "are", "registered", "into", "task", "iometric", "group", "correctly", "while", "generating", "the", "two", "input", "stream", "task"], "project": "flink"}
{"id": 4631, "code": "public PartitionedFile finish() throws IOException {\n    checkState(!isFinished, \"File writer is already finished.\");\n    checkState(!isClosed, \"File writer is already closed.\");\n\n    isFinished = true;\n\n    writeRegionIndex();\n    flushIndexBuffer();\n    indexBuffer.rewind();\n\n    long dataFileSize = dataFileChannel.size();\n    long indexFileSize = indexFileChannel.size();\n    close();\n\n    ByteBuffer indexEntryCache = null;\n    if (allIndexEntriesCached) {\n        indexEntryCache = indexBuffer;\n    }\n    indexBuffer = null;\n    return new PartitionedFile(\n            numRegions,\n            numSubpartitions,\n            dataFilePath,\n            indexFilePath,\n            dataFileSize,\n            indexFileSize,\n            numBuffers,\n            indexEntryCache);\n}", "summary_tokens": ["finishes", "writing", "the", "partitioned", "file", "which", "closes", "the", "file", "channel", "and", "returns", "the", "corresponding", "partitioned", "file"], "project": "flink"}
{"id": 6998, "code": "public ColumnFamilyHandle createNewColumnFamily(String name) {\n    try {\n        final ColumnFamilyHandle columnFamily =\n                rocksDB.createColumnFamily(\n                        new ColumnFamilyDescriptor(name.getBytes(), columnFamilyOptions));\n        columnFamilyHandles.add(columnFamily);\n        return columnFamily;\n    } catch (Exception ex) {\n        throw new FlinkRuntimeException(\"Could not create column family.\", ex);\n    }\n}", "summary_tokens": ["creates", "and", "returns", "a", "new", "column", "family", "with", "the", "given", "name"], "project": "flink"}
{"id": 9370, "code": "public void close() {\n    clearChannels();\n    inMemoryBuffer.close();\n    pool.close();\n}", "summary_tokens": ["delete", "all", "files", "and", "release", "the", "memory"], "project": "flink"}
{"id": 985, "code": "public SimpleVersionedSerializer<InProgressFileWriter.PendingFileRecoverable>\n        getPendingFileRecoverableSerializer() {\n    return pendingFileRecoverableSerializer;\n}", "summary_tokens": ["the", "serializer", "for", "the", "in", "progress", "file", "writer"], "project": "flink"}
{"id": 1318, "code": "public boolean isEndOfStream(T nextElement) {\n    return false;\n}", "summary_tokens": ["method", "to", "decide", "whether", "the", "element", "signals", "the", "end", "of", "the", "stream"], "project": "flink"}
{"id": 1227, "code": "public void setLocalOrder(Ordering localOrder) {\n    this.localOrdering = localOrder;\n}", "summary_tokens": ["sets", "the", "order", "in", "which", "the", "sink", "must", "write", "its", "data", "within", "each", "fragment", "in", "the", "distributed", "file", "system"], "project": "flink"}
{"id": 1885, "code": "public static Row createRowWithNamedPositions(\n        RowKind kind, Object[] fieldByPosition, LinkedHashMap<String, Integer> positionByName) {\n    return new Row(kind, fieldByPosition, null, positionByName);\n}", "summary_tokens": ["internal", "utility", "for", "creating", "a", "row", "in", "static", "named", "position", "field", "mode"], "project": "flink"}
{"id": 6971, "code": "public void setPredefinedOptions(@Nonnull PredefinedOptions options) {\n    rocksDBStateBackend.setPredefinedOptions(options);\n}", "summary_tokens": ["sets", "the", "predefined", "options", "for", "rocks", "db"], "project": "flink"}
{"id": 1979, "code": "public static void closeQuietly(AutoCloseable closeable) {\n    try {\n        if (closeable != null) {\n            closeable.close();\n        }\n    } catch (Throwable ignored) {\n    }\n}", "summary_tokens": ["closes", "the", "given", "auto", "closeable"], "project": "flink"}
{"id": 1054, "code": "public ExecutionConfig setNumberOfExecutionRetries(int numberOfExecutionRetries) {\n    if (numberOfExecutionRetries < -1) {\n        throw new IllegalArgumentException(\n                \"The number of execution retries must be non-negative, or -1 (use system default)\");\n    }\n    this.numberOfExecutionRetries = numberOfExecutionRetries;\n    return this;\n}", "summary_tokens": ["sets", "the", "number", "of", "times", "that", "failed", "tasks", "are", "re", "executed"], "project": "flink"}
{"id": 5121, "code": "public void registerKvState(\n        KeyGroupRange keyGroupRange,\n        String registrationName,\n        InternalKvState<?, ?, ?> kvState,\n        ClassLoader userClassLoader) {\n    KvStateID kvStateId =\n            registry.registerKvState(\n                    jobId,\n                    jobVertexId,\n                    keyGroupRange,\n                    registrationName,\n                    kvState,\n                    userClassLoader);\n    registeredKvStates.add(new KvStateInfo(keyGroupRange, registrationName, kvStateId));\n}", "summary_tokens": ["registers", "the", "kv", "state", "instance", "at", "the", "kv", "state", "registry"], "project": "flink"}
{"id": 5111, "code": "public void notifyKvStateRegistered(\n        JobVertexID jobVertexId,\n        KeyGroupRange keyGroupRange,\n        String registrationName,\n        KvStateID kvStateId,\n        InetSocketAddress kvStateServerAddress) {\n\n    KvStateLocation location = lookupTable.get(registrationName);\n\n    if (location == null) {\n            \n        ExecutionJobVertex vertex = jobVertices.get(jobVertexId);\n\n        if (vertex != null) {\n            int parallelism = vertex.getMaxParallelism();\n            location = new KvStateLocation(jobId, jobVertexId, parallelism, registrationName);\n            lookupTable.put(registrationName, location);\n        } else {\n            throw new IllegalArgumentException(\"Unknown JobVertexID \" + jobVertexId);\n        }\n    }\n\n        \n    if (!location.getJobVertexId().equals(jobVertexId)) {\n        IllegalStateException duplicate =\n                new IllegalStateException(\n                        \"Registration name clash. KvState with name '\"\n                                + registrationName\n                                + \"' has already been registered by another operator (\"\n                                + location.getJobVertexId()\n                                + \").\");\n\n        ExecutionJobVertex vertex = jobVertices.get(jobVertexId);\n        if (vertex != null) {\n            vertex.fail(new SuppressRestartsException(duplicate));\n        }\n\n        throw duplicate;\n    }\n    location.registerKvState(keyGroupRange, kvStateId, kvStateServerAddress);\n}", "summary_tokens": ["notifies", "the", "registry", "about", "a", "registered", "kv", "state", "instance"], "project": "flink"}
{"id": 5582, "code": "public ExecutionState getExecutionState() {\n    return this.executionState;\n}", "summary_tokens": ["returns", "the", "current", "execution", "state", "of", "the", "task"], "project": "flink"}
{"id": 2732, "code": "public CsvReader lineDelimiter(String delimiter) {\n    if (delimiter == null || delimiter.length() == 0) {\n        throw new IllegalArgumentException(\"The delimiter must not be null or an empty string\");\n    }\n\n    this.lineDelimiter = delimiter;\n    return this;\n}", "summary_tokens": ["configures", "the", "delimiter", "that", "separates", "the", "lines", "rows"], "project": "flink"}
{"id": 5732, "code": "public CompletableFuture<JobVertexThreadInfoStats> triggerThreadInfoRequest(\n        Map<ExecutionAttemptID, CompletableFuture<TaskExecutorThreadInfoGateway>>\n                executionWithGateways,\n        int numSamples,\n        Duration delayBetweenSamples,\n        int maxStackTraceDepth) {\n\n    checkNotNull(executionWithGateways, \"Tasks to sample\");\n    checkArgument(executionWithGateways.size() > 0, \"No tasks to sample\");\n    checkArgument(numSamples >= 1, \"No number of samples\");\n    checkArgument(maxStackTraceDepth >= 0, \"Negative maximum stack trace depth\");\n\n        \n    Collection<ExecutionAttemptID> runningSubtasksIds =\n            Collections.unmodifiableSet(executionWithGateways.keySet());\n\n    synchronized (lock) {\n        if (isShutDown) {\n            return FutureUtils.completedExceptionally(new IllegalStateException(\"Shut down\"));\n        }\n\n        final int requestId = requestIdCounter++;\n\n        log.debug(\"Triggering thread info request {}\", requestId);\n\n        final PendingThreadInfoRequest pending =\n                new PendingThreadInfoRequest(requestId, runningSubtasksIds);\n\n            \n            \n            \n            \n        long expectedDuration = numSamples * delayBetweenSamples.toMillis();\n        Time timeout = Time.milliseconds(expectedDuration + requestTimeout.toMillis());\n\n            \n            \n        pendingRequests.put(requestId, pending);\n\n        ThreadInfoSamplesRequest requestParams =\n                new ThreadInfoSamplesRequest(\n                        requestId, numSamples, delayBetweenSamples, maxStackTraceDepth);\n\n        requestThreadInfo(executionWithGateways, requestParams, timeout);\n\n        return pending.getStatsFuture();\n    }\n}", "summary_tokens": ["triggers", "collection", "of", "thread", "info", "stats", "of", "a", "job", "vertex", "by", "combining", "thread", "info", "responses", "from", "given", "subtasks"], "project": "flink"}
{"id": 7659, "code": "public void testOnlySetsOnePhysicalProcessingTimeTimer() throws Exception {\n    @SuppressWarnings(\"unchecked\")\n    Triggerable<Integer, String> mockTriggerable = mock(Triggerable.class);\n\n    TestKeyContext keyContext = new TestKeyContext();\n\n    TestProcessingTimeService processingTimeService = new TestProcessingTimeService();\n    PriorityQueueSetFactory priorityQueueSetFactory =\n            new HeapPriorityQueueSetFactory(testKeyGroupRange, maxParallelism, 128);\n    InternalTimerServiceImpl<Integer, String> timerService =\n            createAndStartInternalTimerService(\n                    mockTriggerable,\n                    keyContext,\n                    processingTimeService,\n                    testKeyGroupRange,\n                    priorityQueueSetFactory);\n\n    int key = getKeyInKeyGroupRange(testKeyGroupRange, maxParallelism);\n    keyContext.setCurrentKey(key);\n\n    timerService.registerProcessingTimeTimer(\"ciao\", 10);\n    timerService.registerProcessingTimeTimer(\"ciao\", 20);\n    timerService.registerProcessingTimeTimer(\"ciao\", 30);\n    timerService.registerProcessingTimeTimer(\"hello\", 10);\n    timerService.registerProcessingTimeTimer(\"hello\", 20);\n\n    assertEquals(5, timerService.numProcessingTimeTimers());\n    assertEquals(2, timerService.numProcessingTimeTimers(\"hello\"));\n    assertEquals(3, timerService.numProcessingTimeTimers(\"ciao\"));\n\n    assertEquals(1, processingTimeService.getNumActiveTimers());\n    assertThat(processingTimeService.getActiveTimerTimestamps(), containsInAnyOrder(10L));\n\n    processingTimeService.setCurrentTime(10);\n\n    assertEquals(3, timerService.numProcessingTimeTimers());\n    assertEquals(1, timerService.numProcessingTimeTimers(\"hello\"));\n    assertEquals(2, timerService.numProcessingTimeTimers(\"ciao\"));\n\n    assertEquals(1, processingTimeService.getNumActiveTimers());\n    assertThat(processingTimeService.getActiveTimerTimestamps(), containsInAnyOrder(20L));\n\n    processingTimeService.setCurrentTime(20);\n\n    assertEquals(1, timerService.numProcessingTimeTimers());\n    assertEquals(0, timerService.numProcessingTimeTimers(\"hello\"));\n    assertEquals(1, timerService.numProcessingTimeTimers(\"ciao\"));\n\n    assertEquals(1, processingTimeService.getNumActiveTimers());\n    assertThat(processingTimeService.getActiveTimerTimestamps(), containsInAnyOrder(30L));\n\n    processingTimeService.setCurrentTime(30);\n\n    assertEquals(0, timerService.numProcessingTimeTimers());\n\n    assertEquals(0, processingTimeService.getNumActiveTimers());\n\n    timerService.registerProcessingTimeTimer(\"ciao\", 40);\n\n    assertEquals(1, processingTimeService.getNumActiveTimers());\n}", "summary_tokens": ["verify", "that", "we", "only", "ever", "have", "one", "processing", "time", "task", "registered", "at", "the", "processing", "time", "service"], "project": "flink"}
{"id": 645, "code": "void usePoolForTransactional() throws Exception {\n    try (final KafkaWriter<Integer> writer =\n            createWriterWithConfiguration(\n                    getKafkaClientConfiguration(), DeliveryGuarantee.EXACTLY_ONCE)) {\n        assertThat(writer.getProducerPool(), hasSize(0));\n\n        List<KafkaCommittable> committables0 = writer.prepareCommit(false);\n        writer.snapshotState(1);\n        assertThat(committables0, hasSize(1));\n        assertThat(committables0.get(0).getProducer().isPresent(), equalTo(true));\n\n        FlinkKafkaInternalProducer<?, ?> firstProducer =\n                committables0.get(0).getProducer().get().getObject();\n        assertThat(\n                \"Expected different producer\",\n                firstProducer,\n                not(sameInstance(writer.getCurrentProducer())));\n\n            \n        assertThat(writer.getProducerPool(), hasSize(0));\n        firstProducer.commitTransaction();\n        committables0.get(0).getProducer().get().close();\n        assertThat(writer.getProducerPool(), hasSize(1));\n\n        List<KafkaCommittable> committables1 = writer.prepareCommit(false);\n        writer.snapshotState(2);\n        assertThat(committables1, hasSize(1));\n        assertThat(committables1.get(0).getProducer().isPresent(), equalTo(true));\n\n        assertThat(\n                \"Expected recycled producer\",\n                firstProducer,\n                sameInstance(writer.getCurrentProducer()));\n    }\n}", "summary_tokens": ["test", "that", "producers", "are", "reused", "when", "committed"], "project": "flink"}
{"id": 3896, "code": "public static <RESP extends MessageBody> ByteBuf serializeResponse(\n        final ByteBufAllocator alloc, final long requestId, final RESP response) {\n    Preconditions.checkNotNull(response);\n    return writePayload(alloc, requestId, MessageType.REQUEST_RESULT, response.serialize());\n}", "summary_tokens": ["serializes", "the", "response", "sent", "to", "the", "org"], "project": "flink"}
{"id": 7277, "code": "public static StreamExecutionEnvironment createLocalEnvironmentWithWebUI(Configuration conf) {\n    checkNotNull(conf, \"conf\");\n\n    if (!conf.contains(RestOptions.PORT)) {\n            \n        conf.setInteger(RestOptions.PORT, RestOptions.PORT.defaultValue());\n    }\n\n    return createLocalEnvironment(conf);\n}", "summary_tokens": ["creates", "a", "local", "stream", "environment", "for", "local", "program", "execution", "that", "also", "starts", "the", "web", "monitoring", "ui"], "project": "flink"}
{"id": 5615, "code": "default PR getPipelinedRegionOfVertex(VID vertexId) {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["the", "pipelined", "region", "for", "a", "specified", "vertex"], "project": "flink"}
{"id": 3796, "code": "private static void resetCallbackClientExecutorService(GatewayServer gatewayServer)\n        throws NoSuchFieldException, IllegalAccessException, NoSuchMethodException,\n                InvocationTargetException {\n    CallbackClient callbackClient = (CallbackClient) gatewayServer.getCallbackClient();\n        \n        \n    Field executor = CallbackClient.class.getDeclaredField(\"executor\");\n    executor.setAccessible(true);\n    ((ScheduledExecutorService) executor.get(callbackClient)).shutdown();\n    executor.set(callbackClient, Executors.newScheduledThreadPool(1, Thread::new));\n    Method setupCleaner = CallbackClient.class.getDeclaredMethod(\"setupCleaner\");\n    setupCleaner.setAccessible(true);\n    setupCleaner.invoke(callbackClient);\n}", "summary_tokens": ["reset", "a", "daemon", "thread", "to", "the", "callback", "client", "thread", "pool", "so", "that", "the", "callback", "server", "can", "be", "terminated", "when", "gate", "way", "server", "is", "shutting", "down"], "project": "flink"}
{"id": 4715, "code": "public void notifyOfEndOfSuperstep() {\n    queue.offer(buffer);\n}", "summary_tokens": ["called", "by", "iteration", "tail", "to", "signal", "that", "all", "input", "of", "a", "superstep", "has", "been", "processed", "unblocks", "iteration", "head"], "project": "flink"}
{"id": 2158, "code": "public void testSerializerSerializationWithInvalidClass() throws Exception {\n\n    TypeSerializer<?> serializer = IntSerializer.INSTANCE;\n\n    byte[] serialized;\n    try (ByteArrayOutputStreamWithPos out = new ByteArrayOutputStreamWithPos()) {\n        TypeSerializerSerializationUtil.writeSerializer(\n                new DataOutputViewStreamWrapper(out), serializer);\n        serialized = out.toByteArray();\n    }\n\n    TypeSerializer<?> deserializedSerializer;\n\n    try (ByteArrayInputStreamWithPos in = new ByteArrayInputStreamWithPos(serialized)) {\n        deserializedSerializer =\n                TypeSerializerSerializationUtil.tryReadSerializer(\n                        new DataInputViewStreamWrapper(in),\n                        new ArtificialCNFExceptionThrowingClassLoader(\n                                Thread.currentThread().getContextClassLoader(),\n                                Collections.singleton(IntSerializer.class.getName())),\n                        true);\n    }\n    Assert.assertTrue(deserializedSerializer instanceof UnloadableDummyTypeSerializer);\n}", "summary_tokens": ["verifies", "deserialization", "failure", "cases", "when", "reading", "a", "serializer", "from", "bytes", "in", "the", "case", "of", "a", "invalid", "class", "exception"], "project": "flink"}
{"id": 6660, "code": "public void testLocalPartitionNotFound() throws Exception {\n    ResourceID producerLocation = ResourceID.generate();\n    NettyShuffleDescriptor shuffleDescriptor =\n            createRemoteWithIdAndLocation(\n                    new IntermediateResultPartitionID(), producerLocation);\n    TaskDeploymentDescriptor tdd = createReceiver(shuffleDescriptor);\n    ExecutionAttemptID eid = tdd.getExecutionAttemptId();\n\n    Configuration config = new Configuration();\n    config.setInteger(NettyShuffleEnvironmentOptions.NETWORK_REQUEST_BACKOFF_INITIAL, 100);\n    config.setInteger(NettyShuffleEnvironmentOptions.NETWORK_REQUEST_BACKOFF_MAX, 200);\n\n    final CompletableFuture<Void> taskRunningFuture = new CompletableFuture<>();\n    final CompletableFuture<Void> taskFailedFuture = new CompletableFuture<>();\n\n    try (TaskSubmissionTestEnvironment env =\n            new TaskSubmissionTestEnvironment.Builder(jobId)\n                    .setResourceID(producerLocation)\n                    .setSlotSize(1)\n                    .addTaskManagerActionListener(\n                            eid, ExecutionState.RUNNING, taskRunningFuture)\n                    .addTaskManagerActionListener(eid, ExecutionState.FAILED, taskFailedFuture)\n                    .setConfiguration(config)\n                    .useRealNonMockShuffleEnvironment()\n                    .build()) {\n        TaskExecutorGateway tmGateway = env.getTaskExecutorGateway();\n        TaskSlotTable<Task> taskSlotTable = env.getTaskSlotTable();\n\n        taskSlotTable.allocateSlot(0, jobId, tdd.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd, env.getJobMasterId(), timeout).get();\n        taskRunningFuture.get();\n\n        taskFailedFuture.get();\n\n        assertSame(taskSlotTable.getTask(eid).getExecutionState(), ExecutionState.FAILED);\n        assertThat(\n                taskSlotTable.getTask(eid).getFailureCause(),\n                instanceOf(PartitionNotFoundException.class));\n    }\n}", "summary_tokens": ["tests", "that", "repeated", "local", "partition", "not", "found", "exception", "s", "ultimately", "fail", "the", "receiver"], "project": "flink"}
{"id": 5331, "code": "private byte[] toBytes(long checkpointId) throws Exception {\n    return writeCheckpointBytes(\n            enumerator.snapshotState(checkpointId), enumCheckpointSerializer);\n}", "summary_tokens": ["serialize", "the", "coordinator", "state"], "project": "flink"}
{"id": 4372, "code": "private CompletableFuture<Void> closeClusterComponent(\n        ApplicationStatus applicationStatus,\n        ShutdownBehaviour shutdownBehaviour,\n        @Nullable String diagnostics) {\n    synchronized (lock) {\n        if (clusterComponent != null) {\n            switch (shutdownBehaviour) {\n                case STOP_APPLICATION:\n                    return clusterComponent.stopApplication(applicationStatus, diagnostics);\n                case STOP_PROCESS:\n                default:\n                    return clusterComponent.stopProcess();\n            }\n        } else {\n            return CompletableFuture.completedFuture(null);\n        }\n    }\n}", "summary_tokens": ["close", "cluster", "components", "and", "deregister", "the", "flink", "application", "from", "the", "resource", "management", "system", "by", "signalling", "the", "resource", "manager"], "project": "flink"}
{"id": 7344, "code": "public void setProcessingTimeService(ProcessingTimeService processingTimeService) {\n    this.processingTimeService = Preconditions.checkNotNull(processingTimeService);\n}", "summary_tokens": ["the", "processing", "time", "service", "instance", "should", "be", "passed", "by", "the", "operator", "constructor", "and", "this", "method", "will", "be", "removed", "along", "with", "setupable", "stream", "operator"], "project": "flink"}
{"id": 8761, "code": "protected SetopNamespace createSetopNamespace(SqlCall call, SqlNode enclosingNode) {\n    return new SetopNamespace(this, call, enclosingNode);\n}", "summary_tokens": ["creates", "a", "namespace", "for", "a", "set", "operation", "code", "union", "code", "code", "intersect", "code", "or", "code", "except", "code"], "project": "flink"}
{"id": 2354, "code": "public void setTimeDuration(String name, long value, TimeUnit unit) {\n    set(name, value + ParsedTimeDuration.unitFor(unit).suffix());\n}", "summary_tokens": ["set", "the", "value", "of", "code", "name", "code", "to", "the", "given", "time", "duration"], "project": "flink"}
{"id": 986, "code": "public SimpleVersionedSerializer<InProgressFileWriter.InProgressFileRecoverable>\n        getInProgressFileRecoverableSerializer() {\n    return inProgressFileRecoverableSerializer;\n}", "summary_tokens": ["the", "serializer", "for", "the", "in", "progress", "file", "writer"], "project": "flink"}
{"id": 4017, "code": "public void testExecuteRunnable() throws Exception {\n    final OneShotLatch latch = new OneShotLatch();\n\n    akkaRpcService.execute(latch::trigger);\n\n    latch.await(30L, TimeUnit.SECONDS);\n}", "summary_tokens": ["tests", "that", "the", "akka", "rpc", "service", "can", "execute", "runnables"], "project": "flink"}
{"id": 826, "code": "public long calculateFullJitterBackoff(\n        long baseMillis, long maxMillis, double power, int attempt) {\n    long exponentialBackoff = (long) Math.min(maxMillis, baseMillis * Math.pow(power, attempt));\n    return (long) (seed.nextDouble() * exponentialBackoff);\n}", "summary_tokens": ["calculates", "the", "sleep", "time", "for", "full", "jitter", "based", "on", "the", "given", "parameters"], "project": "flink"}
{"id": 6252, "code": "public void testRequestBuffersWithRemoteInputChannel() throws Exception {\n    final NettyShuffleEnvironment network = createNettyShuffleEnvironment();\n    final SingleInputGate inputGate =\n            createInputGate(network, 1, ResultPartitionType.PIPELINED_BOUNDED);\n    int buffersPerChannel = 2;\n    int extraNetworkBuffersPerGate = 8;\n\n    try (Closer closer = Closer.create()) {\n        closer.register(network::close);\n        closer.register(inputGate::close);\n\n        RemoteInputChannel remote =\n                InputChannelBuilder.newBuilder()\n                        .setupFromNettyShuffleEnvironment(network)\n                        .setConnectionManager(new TestingConnectionManager())\n                        .buildRemoteChannel(inputGate);\n        inputGate.setInputChannels(remote);\n        inputGate.setup();\n\n        NetworkBufferPool bufferPool = network.getNetworkBufferPool();\n            \n        assertEquals(buffersPerChannel, remote.getNumberOfAvailableBuffers());\n\n        assertEquals(\n                bufferPool.getTotalNumberOfMemorySegments() - buffersPerChannel - 1,\n                bufferPool.getNumberOfAvailableMemorySegments());\n            \n            \n        assertEquals(extraNetworkBuffersPerGate, bufferPool.countBuffers());\n    }\n}", "summary_tokens": ["tests", "that", "input", "gate", "requests", "and", "assigns", "network", "buffers", "for", "remote", "input", "channel"], "project": "flink"}
{"id": 3522, "code": "public List<BootstrapTransformationWithID<?>> getNewOperators() {\n    return operatorStateIndex.values().stream()\n            .filter(OperatorStateSpec::isNewStateTransformation)\n            .map(OperatorStateSpec::asNewStateTransformation)\n            .collect(Collectors.toList());\n}", "summary_tokens": ["list", "of", "new", "operator", "states", "for", "the", "savepoint", "represented", "by", "their", "target", "operator", "id", "and", "bootstrap", "transformation"], "project": "flink"}
{"id": 1096, "code": "public boolean isJobExecutionResult() {\n    return false;\n}", "summary_tokens": ["checks", "if", "this", "job", "submission", "result", "is", "also", "a", "job", "execution", "result"], "project": "flink"}
{"id": 2622, "code": "public void testSubmittingJobViaRestClusterClient() throws Exception {\n    RestClusterClient<String> restClusterClient =\n            new RestClusterClient<>(\n                    MINI_CLUSTER_RESOURCE.getClientConfiguration(),\n                    \"testSubmittingJobViaRestClusterClient\");\n\n    final JobGraph jobGraph =\n            createJobWithRegisteredCachedFiles().getStreamGraph().getJobGraph();\n\n    final JobResult jobResult =\n            restClusterClient\n                    .submitJob(jobGraph)\n                    .thenCompose(restClusterClient::requestJobResult)\n                    .get();\n\n    final String messageInCaseOfFailure =\n            jobResult.getSerializedThrowable().isPresent()\n                    ? jobResult.getSerializedThrowable().get().getFullStringifiedStackTrace()\n                    : \"Job failed.\";\n    assertTrue(messageInCaseOfFailure, jobResult.isSuccess());\n}", "summary_tokens": ["all", "the", "flink", "standalone", "yarn", "kubernetes", "sessions", "are", "using", "rest", "cluster", "client", "submit", "job", "job", "graph", "to", "submit", "a", "job", "to", "an", "existing", "session"], "project": "flink"}
{"id": 4331, "code": "public static ContaineredTaskManagerParameters create(\n        Configuration config, TaskExecutorProcessSpec taskExecutorProcessSpec) {\n\n        \n    final HashMap<String, String> envVars = new HashMap<>();\n    final String prefix = ResourceManagerOptions.CONTAINERIZED_TASK_MANAGER_ENV_PREFIX;\n\n    for (String key : config.keySet()) {\n        if (key.startsWith(prefix) && key.length() > prefix.length()) {\n                \n            String envVarKey = key.substring(prefix.length());\n            envVars.put(envVarKey, config.getString(key, null));\n        }\n    }\n\n        \n    return new ContaineredTaskManagerParameters(taskExecutorProcessSpec, envVars);\n}", "summary_tokens": ["computes", "the", "parameters", "to", "be", "used", "to", "start", "a", "task", "manager", "java", "process"], "project": "flink"}
{"id": 5634, "code": "public static String getScalaVersion() {\n    return getVersionsInstance().scalaVersion;\n}", "summary_tokens": ["returns", "the", "version", "of", "the", "used", "scala", "compiler", "as", "string"], "project": "flink"}
{"id": 8628, "code": "public static int getPrecision(LogicalType logicalType) {\n    return logicalType.accept(PRECISION_EXTRACTOR);\n}", "summary_tokens": ["returns", "the", "precision", "of", "all", "types", "that", "define", "a", "precision", "implicitly", "or", "explicitly"], "project": "flink"}
{"id": 7244, "code": "public RestartStrategies.RestartStrategyConfiguration getRestartStrategy() {\n    return config.getRestartStrategy();\n}", "summary_tokens": ["returns", "the", "specified", "restart", "strategy", "configuration"], "project": "flink"}
{"id": 7002, "code": "public void testSetDbPath() throws Exception {\n    final EmbeddedRocksDBStateBackend rocksDbBackend = new EmbeddedRocksDBStateBackend();\n\n    final String testDir1 = tempFolder.newFolder().getAbsolutePath();\n    final String testDir2 = tempFolder.newFolder().getAbsolutePath();\n\n    assertNull(rocksDbBackend.getDbStoragePaths());\n\n    rocksDbBackend.setDbStoragePath(testDir1);\n    assertArrayEquals(new String[] {testDir1}, rocksDbBackend.getDbStoragePaths());\n\n    rocksDbBackend.setDbStoragePath(null);\n    assertNull(rocksDbBackend.getDbStoragePaths());\n\n    rocksDbBackend.setDbStoragePaths(testDir1, testDir2);\n    assertArrayEquals(new String[] {testDir1, testDir2}, rocksDbBackend.getDbStoragePaths());\n\n    final MockEnvironment env = getMockEnvironment(tempFolder.newFolder());\n    final RocksDBKeyedStateBackend<Integer> keyedBackend =\n            createKeyedStateBackend(rocksDbBackend, env, IntSerializer.INSTANCE);\n\n    try {\n        File instanceBasePath = keyedBackend.getInstanceBasePath();\n        assertThat(\n                instanceBasePath.getAbsolutePath(),\n                anyOf(startsWith(testDir1), startsWith(testDir2)));\n\n            \n        rocksDbBackend.setDbStoragePaths(null);\n        assertNull(rocksDbBackend.getDbStoragePaths());\n    } finally {\n        IOUtils.closeQuietly(keyedBackend);\n        keyedBackend.dispose();\n        env.close();\n    }\n}", "summary_tokens": ["this", "test", "checks", "the", "behavior", "for", "basic", "setting", "of", "local", "db", "directories"], "project": "flink"}
{"id": 2943, "code": "public void testOutOfTupleBoundsGrouping1() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    UnsortedGrouping<Tuple5<Integer, Long, String, Long, Integer>> groupDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo).groupBy(0);\n\n        \n    groupDs.minBy(5);\n}", "summary_tokens": ["this", "test", "validates", "that", "an", "index", "which", "is", "out", "of", "bounds", "throws", "an", "index", "out", "of", "bounds", "exception"], "project": "flink"}
{"id": 7801, "code": "private void testNoTimerFiringForGarbageCollectedMergingWindow(\n        final TimeDomainAdaptor timeAdaptor) throws Exception {\n\n    MergingWindowAssigner<Integer, TimeWindow> mockAssigner = mockMergingAssigner();\n    timeAdaptor.setIsEventTime(mockAssigner);\n    Trigger<Integer, TimeWindow> mockTrigger = mockTrigger();\n\n    @SuppressWarnings(\"unchecked\")\n    InternalWindowFunction<Iterable<Integer>, List<Integer>, Integer, TimeWindow>\n            mockWindowFunction = mock(InternalWindowFunction.class);\n\n    KeyedOneInputStreamOperatorTestHarness<Integer, Integer, List<Integer>> testHarness =\n            createWindowOperator(mockAssigner, mockTrigger, 0L, mockWindowFunction);\n\n    testHarness.open();\n\n    timeAdaptor.advanceTime(testHarness, Long.MIN_VALUE);\n\n    when(mockAssigner.assignWindows(anyInt(), anyLong(), anyAssignerContext()))\n            .thenReturn(Arrays.asList(new TimeWindow(2, 4)));\n\n    assertEquals(0, testHarness.extractOutputStreamRecords().size());\n    assertEquals(0, testHarness.numKeyedStateEntries());\n\n    doAnswer(\n                    new Answer<TriggerResult>() {\n                        @Override\n                        public TriggerResult answer(InvocationOnMock invocation)\n                                throws Exception {\n                            Trigger.TriggerContext context =\n                                    (Trigger.TriggerContext) invocation.getArguments()[3];\n                                \n                            timeAdaptor.registerTimer(context, 10L);\n                            return TriggerResult.CONTINUE;\n                        }\n                    })\n            .when(mockTrigger)\n            .onElement(\n                    Matchers.<Integer>anyObject(),\n                    anyLong(),\n                    anyTimeWindow(),\n                    anyTriggerContext());\n\n    testHarness.processElement(new StreamRecord<>(0, 0L));\n\n    assertEquals(\n            2, testHarness.numKeyedStateEntries()); \n    assertEquals(2, timeAdaptor.numTimers(testHarness)); \n\n    timeAdaptor.shouldContinueOnTime(mockTrigger);\n\n        \n    timeAdaptor.advanceTime(testHarness, 4L);\n\n    verify(mockTrigger, times(1)).clear(anyTimeWindow(), anyTriggerContext());\n\n    assertEquals(0, testHarness.numKeyedStateEntries());\n        \n    assertEquals(1, timeAdaptor.numTimers(testHarness));\n\n    timeAdaptor.verifyTriggerCallback(mockTrigger, times(1), null, null);\n\n    verify(mockWindowFunction, never())\n            .process(\n                    anyInt(),\n                    anyTimeWindow(),\n                    anyInternalWindowContext(),\n                    anyIntIterable(),\n                    WindowOperatorContractTest.<List<Integer>>anyCollector());\n\n        \n    timeAdaptor.advanceTime(testHarness, 10L);\n\n        \n    timeAdaptor.verifyTriggerCallback(mockTrigger, times(1), null, null);\n}", "summary_tokens": ["verify", "that", "we", "neither", "invoke", "the", "trigger", "nor", "the", "window", "function", "if", "a", "timer", "fires", "for", "a", "merging", "window", "that", "was", "already", "garbage", "collected"], "project": "flink"}
{"id": 7927, "code": "public static <InputT, CommT> OperatorSubtaskState buildSubtaskState(\n        OneInputStreamOperatorTestHarness<InputT, CommT> testHarness, List<InputT> input)\n        throws Exception {\n    testHarness.initializeEmptyState();\n    testHarness.open();\n\n    testHarness.processElements(\n            input.stream().map(StreamRecord::new).collect(Collectors.toList()));\n    testHarness.prepareSnapshotPreBarrier(1);\n    final OperatorSubtaskState operatorSubtaskState = testHarness.snapshot(1, 1);\n    testHarness.close();\n\n    return operatorSubtaskState;\n}", "summary_tokens": ["get", "the", "operator", "s", "state", "after", "processing", "given", "inputs"], "project": "flink"}
{"id": 466, "code": "public void open(InputSplit inputSplit) throws IOException {\n    try {\n        if (inputSplit != null && parameterValues != null) {\n            for (int i = 0; i < parameterValues[inputSplit.getSplitNumber()].length; i++) {\n                Object param = parameterValues[inputSplit.getSplitNumber()][i];\n                if (param instanceof String) {\n                    statement.setString(i + 1, (String) param);\n                } else if (param instanceof Long) {\n                    statement.setLong(i + 1, (Long) param);\n                } else if (param instanceof Integer) {\n                    statement.setInt(i + 1, (Integer) param);\n                } else if (param instanceof Double) {\n                    statement.setDouble(i + 1, (Double) param);\n                } else if (param instanceof Boolean) {\n                    statement.setBoolean(i + 1, (Boolean) param);\n                } else if (param instanceof Float) {\n                    statement.setFloat(i + 1, (Float) param);\n                } else if (param instanceof BigDecimal) {\n                    statement.setBigDecimal(i + 1, (BigDecimal) param);\n                } else if (param instanceof Byte) {\n                    statement.setByte(i + 1, (Byte) param);\n                } else if (param instanceof Short) {\n                    statement.setShort(i + 1, (Short) param);\n                } else if (param instanceof Date) {\n                    statement.setDate(i + 1, (Date) param);\n                } else if (param instanceof Time) {\n                    statement.setTime(i + 1, (Time) param);\n                } else if (param instanceof Timestamp) {\n                    statement.setTimestamp(i + 1, (Timestamp) param);\n                } else if (param instanceof Array) {\n                    statement.setArray(i + 1, (Array) param);\n                } else {\n                        \n                    throw new IllegalArgumentException(\n                            \"open() failed. Parameter \"\n                                    + i\n                                    + \" of type \"\n                                    + param.getClass()\n                                    + \" is not handled (yet).\");\n                }\n            }\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\n                        String.format(\n                                \"Executing '%s' with parameters %s\",\n                                queryTemplate,\n                                Arrays.deepToString(\n                                        parameterValues[inputSplit.getSplitNumber()])));\n            }\n        }\n        resultSet = statement.executeQuery();\n        hasNext = resultSet.next();\n    } catch (SQLException se) {\n        throw new IllegalArgumentException(\"open() failed.\" + se.getMessage(), se);\n    }\n}", "summary_tokens": ["connects", "to", "the", "source", "database", "and", "executes", "the", "query", "in", "a", "b", "parallel", "fashion", "b", "if", "this", "input", "format", "is", "built", "using", "a", "parameterized", "query", "i"], "project": "flink"}
{"id": 6769, "code": "S helpGetState(long valuePointer) {\n    return helpGetState(valuePointer, skipListValueSerializer);\n}", "summary_tokens": ["return", "the", "state", "pointed", "by", "the", "given", "pointer"], "project": "flink"}
{"id": 5947, "code": "public void testAbortDiscardsState() throws Exception {\n    CheckpointProperties props =\n            new CheckpointProperties(\n                    false, CheckpointType.CHECKPOINT, false, false, false, false, false, false);\n    QueueExecutor executor = new QueueExecutor();\n\n    OperatorState state = mock(OperatorState.class);\n    doNothing().when(state).registerSharedStates(any(SharedStateRegistry.class), eq(0L));\n\n        \n    PendingCheckpoint pending = createPendingCheckpoint(props, executor);\n    setTaskState(pending, state);\n\n    abort(pending, CheckpointFailureReason.CHECKPOINT_DECLINED);\n        \n    executor.runQueuedCommands();\n    verify(state, times(1)).discardState();\n\n        \n    Mockito.reset(state);\n\n    pending = createPendingCheckpoint(props, executor);\n    setTaskState(pending, state);\n\n    abort(pending, CheckpointFailureReason.CHECKPOINT_DECLINED);\n        \n    executor.runQueuedCommands();\n    verify(state, times(1)).discardState();\n\n        \n    Mockito.reset(state);\n\n    pending = createPendingCheckpoint(props, executor);\n    setTaskState(pending, state);\n\n    abort(pending, CheckpointFailureReason.CHECKPOINT_EXPIRED);\n        \n    executor.runQueuedCommands();\n    verify(state, times(1)).discardState();\n\n        \n    Mockito.reset(state);\n\n    pending = createPendingCheckpoint(props, executor);\n    setTaskState(pending, state);\n\n    abort(pending, CheckpointFailureReason.CHECKPOINT_SUBSUMED);\n        \n    executor.runQueuedCommands();\n    verify(state, times(1)).discardState();\n}", "summary_tokens": ["tests", "that", "abort", "discards", "state"], "project": "flink"}
{"id": 1653, "code": "public boolean contains(ConfigOption<?> configOption) {\n    synchronized (this.confData) {\n        final BiFunction<String, Boolean, Optional<Boolean>> applier =\n                (key, canBePrefixMap) -> {\n                    if (canBePrefixMap && containsPrefixMap(this.confData, key)\n                            || this.confData.containsKey(key)) {\n                        return Optional.of(true);\n                    }\n                    return Optional.empty();\n                };\n        return applyWithOption(configOption, applier).orElse(false);\n    }\n}", "summary_tokens": ["checks", "whether", "there", "is", "an", "entry", "for", "the", "given", "config", "option"], "project": "flink"}
{"id": 991, "code": "public static DefaultRollingPolicy.PolicyBuilder create() {\n    return builder();\n}", "summary_tokens": ["this", "method", "is", "deprecated", "use", "default", "rolling", "policy", "builder", "instead"], "project": "flink"}
{"id": 6945, "code": "public boolean isColumnFamilyAsVariable() {\n    return this.columnFamilyAsVariable;\n}", "summary_tokens": ["rocks", "dbnative", "metric", "monitor", "whether", "to", "expose", "the", "column", "family", "as", "a", "variable"], "project": "flink"}
{"id": 9426, "code": "public void reset() {\n    super.reset();\n        \n    recordArea.reset();\n    numKeys = 0;\n}", "summary_tokens": ["reset", "the", "map", "s", "record", "and", "bucket", "area", "s", "memory", "segments", "for", "reusing"], "project": "flink"}
{"id": 8230, "code": "public String asSummaryString() {\n    return String.join(\".\", catalogName, databaseName, objectName);\n}", "summary_tokens": ["returns", "a", "string", "that", "summarizes", "this", "instance", "for", "printing", "to", "a", "console", "or", "log"], "project": "flink"}
{"id": 7303, "code": "private Map<Long, List<TimestampedFileInputSplit>> getInputSplitsSortedByModTime(\n        Map<Path, FileStatus> eligibleFiles) throws IOException {\n\n    Map<Long, List<TimestampedFileInputSplit>> splitsByModTime = new TreeMap<>();\n    if (eligibleFiles.isEmpty()) {\n        return splitsByModTime;\n    }\n\n    for (FileInputSplit split : format.createInputSplits(readerParallelism)) {\n        FileStatus fileStatus = eligibleFiles.get(split.getPath());\n        if (fileStatus != null) {\n            Long modTime = fileStatus.getModificationTime();\n            List<TimestampedFileInputSplit> splitsToForward = splitsByModTime.get(modTime);\n            if (splitsToForward == null) {\n                splitsToForward = new ArrayList<>();\n                splitsByModTime.put(modTime, splitsToForward);\n            }\n            splitsToForward.add(\n                    new TimestampedFileInputSplit(\n                            modTime,\n                            split.getSplitNumber(),\n                            split.getPath(),\n                            split.getStart(),\n                            split.getLength(),\n                            split.getHostnames()));\n        }\n    }\n    return splitsByModTime;\n}", "summary_tokens": ["creates", "the", "input", "splits", "to", "be", "forwarded", "to", "the", "downstream", "tasks", "of", "the", "continuous", "file", "reader", "operator"], "project": "flink"}
{"id": 259, "code": "public EnrichedRowData replaceMutableRow(RowData mutableRow) {\n    this.mutableRow = mutableRow;\n    return this;\n}", "summary_tokens": ["replaces", "the", "mutable", "row", "data", "backing", "this", "enriched", "row", "data"], "project": "flink"}
{"id": 4496, "code": "public LinkedBlockingQueue<MemorySegment> getReturnQueue() {\n    return this.returnSegments;\n}", "summary_tokens": ["gets", "the", "queue", "in", "which", "the", "full", "memory", "segments", "are", "queued", "after", "the", "asynchronous", "read", "is", "complete"], "project": "flink"}
{"id": 5886, "code": "public void testExternalizedCheckpoints() throws Exception {\n    ExecutionGraph graph =\n            new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                    .addJobVertex(new JobVertexID())\n                    .build();\n\n        \n    CheckpointCoordinatorConfiguration chkConfig =\n            new CheckpointCoordinatorConfiguration.CheckpointCoordinatorConfigurationBuilder()\n                    .setCheckpointRetentionPolicy(CheckpointRetentionPolicy.RETAIN_ON_FAILURE)\n                    .build();\n    CheckpointCoordinator checkpointCoordinator =\n            new CheckpointCoordinatorBuilder()\n                    .setExecutionGraph(graph)\n                    .setCheckpointCoordinatorConfiguration(chkConfig)\n                    .setTimer(manuallyTriggeredScheduledExecutor)\n                    .build();\n\n    CompletableFuture<CompletedCheckpoint> checkpointFuture =\n            checkpointCoordinator.triggerCheckpoint(false);\n    manuallyTriggeredScheduledExecutor.triggerAll();\n    FutureUtils.throwIfCompletedExceptionally(checkpointFuture);\n\n    for (PendingCheckpoint checkpoint :\n            checkpointCoordinator.getPendingCheckpoints().values()) {\n        CheckpointProperties props = checkpoint.getProps();\n        CheckpointProperties expected =\n                CheckpointProperties.forCheckpoint(CheckpointRetentionPolicy.RETAIN_ON_FAILURE);\n\n        assertEquals(expected, props);\n    }\n\n        \n    checkpointCoordinator.shutdown();\n}", "summary_tokens": ["tests", "that", "the", "externalized", "checkpoint", "configuration", "is", "respected"], "project": "flink"}
{"id": 1750, "code": "public static <T> void writeVersionAndSerializeList(\n        SimpleVersionedSerializer<T> serializer, List<T> data, DataOutputView out)\n        throws IOException {\n    checkNotNull(serializer);\n    checkNotNull(data);\n    checkNotNull(out);\n\n    out.writeInt(serializer.getVersion());\n    out.writeInt(data.size());\n    for (final T datum : data) {\n        final byte[] serializedDatum = serializer.serialize(datum);\n        out.writeInt(serializedDatum.length);\n        out.write(serializer.serialize(datum));\n    }\n}", "summary_tokens": ["serializes", "the", "version", "and", "data", "into", "a", "stream"], "project": "flink"}
{"id": 7104, "code": "private TypeInformation<KEY> validateKeyType(TypeInformation<KEY> keyType) {\n    Stack<TypeInformation<?>> stack = new Stack<>();\n    stack.push(keyType);\n\n    List<TypeInformation<?>> unsupportedTypes = new ArrayList<>();\n\n    while (!stack.isEmpty()) {\n        TypeInformation<?> typeInfo = stack.pop();\n\n        if (!validateKeyTypeIsHashable(typeInfo)) {\n            unsupportedTypes.add(typeInfo);\n        }\n\n        if (typeInfo instanceof TupleTypeInfoBase) {\n            for (int i = 0; i < typeInfo.getArity(); i++) {\n                stack.push(((TupleTypeInfoBase) typeInfo).getTypeAt(i));\n            }\n        }\n    }\n\n    if (!unsupportedTypes.isEmpty()) {\n        throw new InvalidProgramException(\n                \"Type \"\n                        + keyType\n                        + \" cannot be used as key. Contained \"\n                        + \"UNSUPPORTED key types: \"\n                        + StringUtils.join(unsupportedTypes, \", \")\n                        + \". Look \"\n                        + \"at the keyBy() documentation for the conditions a type has to satisfy in order to be \"\n                        + \"eligible for a key.\");\n    }\n\n    return keyType;\n}", "summary_tokens": ["validates", "that", "a", "given", "type", "of", "element", "as", "encoded", "by", "the", "provided", "type", "information", "can", "be", "used", "as", "a", "key", "in", "the", "data", "stream"], "project": "flink"}
{"id": 613, "code": "public void shutdown() {\n    running = false;\n\n        \n    unassignedPartitionsQueue.close();\n\n        \n        \n\n        \n    handover.wakeupProducer();\n\n        \n    synchronized (consumerReassignmentLock) {\n        if (consumer != null) {\n            consumer.wakeup();\n        } else {\n                \n                \n                \n            hasBufferedWakeup = true;\n        }\n    }\n}", "summary_tokens": ["shuts", "this", "thread", "down", "waking", "up", "the", "thread", "gracefully", "if", "blocked", "without", "thread"], "project": "flink"}
{"id": 2399, "code": "public void setClassLoader(ClassLoader classLoader) {\n    this.classLoader = classLoader;\n}", "summary_tokens": ["set", "the", "class", "loader", "that", "will", "be", "used", "to", "load", "the", "various", "objects"], "project": "flink"}
{"id": 1823, "code": "default void configure(Configuration config) {}", "summary_tokens": ["optional", "method", "for", "plugins", "to", "pick", "up", "settings", "from", "the", "configuration"], "project": "flink"}
{"id": 9338, "code": "public static <W extends Window> AfterEndOfWindow<W> afterEndOfWindow() {\n    return new AfterEndOfWindow<>();\n}", "summary_tokens": ["creates", "a", "trigger", "that", "fires", "when", "the", "watermark", "passes", "the", "end", "of", "the", "window"], "project": "flink"}
{"id": 6161, "code": "public void testGetSetReaderIndex2() {\n    testGetSetReaderIndex(buffer.readOnlySlice(1, 2));\n}", "summary_tokens": ["tests", "the", "independence", "of", "the", "reader", "index", "via", "read", "only", "sliced", "network", "buffer", "set", "reader", "index", "int", "and", "read", "only", "sliced", "network", "buffer", "get", "reader", "index"], "project": "flink"}
{"id": 4233, "code": "public static <R extends ResourceVersion<R>>\n        Collection<CompletedCheckpoint> retrieveCompletedCheckpoints(\n                StateHandleStore<CompletedCheckpoint, R> checkpointStateHandleStore,\n                CheckpointStoreUtil completedCheckpointStoreUtil)\n                throws Exception {\n\n    LOG.info(\"Recovering checkpoints from {}.\", checkpointStateHandleStore);\n\n        \n    final List<Tuple2<RetrievableStateHandle<CompletedCheckpoint>, String>> initialCheckpoints =\n            checkpointStateHandleStore.getAllAndLock();\n\n        \n    initialCheckpoints.sort(Comparator.comparing(o -> o.f1));\n\n    final int numberOfInitialCheckpoints = initialCheckpoints.size();\n\n    LOG.info(\n            \"Found {} checkpoints in {}.\",\n            numberOfInitialCheckpoints,\n            checkpointStateHandleStore);\n    final List<CompletedCheckpoint> retrievedCheckpoints =\n            new ArrayList<>(numberOfInitialCheckpoints);\n    LOG.info(\"Trying to fetch {} checkpoints from storage.\", numberOfInitialCheckpoints);\n\n    for (Tuple2<RetrievableStateHandle<CompletedCheckpoint>, String> checkpointStateHandle :\n            initialCheckpoints) {\n        retrievedCheckpoints.add(\n                checkNotNull(\n                        retrieveCompletedCheckpoint(\n                                completedCheckpointStoreUtil, checkpointStateHandle)));\n    }\n    return Collections.unmodifiableList(retrievedCheckpoints);\n}", "summary_tokens": ["fetch", "all", "completed", "checkpoint", "completed", "checkpoints", "from", "an", "state", "handle", "store", "external", "store"], "project": "flink"}
{"id": 2271, "code": "public void restartJobManager(RunnableWithException afterFailAction) throws Exception {\n    if (this.haService == null) {\n        LOG.warn(\n                \"Restarting JobManager without HA service. This might drop all your running jobs\");\n    }\n    jobManager.stop();\n    afterFailAction.run();\n    jobManager.start();\n        \n    waitUntilJobManagerRESTReachable(jobManager);\n    this.restClusterClient = createClusterClient();\n    waitUntilAllTaskManagerConnected();\n}", "summary_tokens": ["restarts", "job", "manager", "container"], "project": "flink"}
{"id": 3923, "code": "public void testReadCallbacksAndBufferRecycling() throws Exception {\n    final ClientHandlerCallback<KvStateResponse> callback = mock(ClientHandlerCallback.class);\n\n    final MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n    final EmbeddedChannel channel =\n            new EmbeddedChannel(new ClientHandler<>(\"Test Client\", serializer, callback));\n\n    final byte[] content = new byte[0];\n    final KvStateResponse response = new KvStateResponse(content);\n\n        \n        \n        \n    ByteBuf buf = MessageSerializer.serializeResponse(channel.alloc(), 1222112277L, response);\n    buf.skipBytes(4); \n\n        \n    channel.writeInbound(buf);\n    verify(callback, times(1)).onRequestResult(eq(1222112277L), any(KvStateResponse.class));\n    assertEquals(\"Buffer not recycled\", 0, buf.refCnt());\n\n        \n        \n        \n    buf =\n            MessageSerializer.serializeRequestFailure(\n                    channel.alloc(),\n                    1222112278,\n                    new RuntimeException(\"Expected test Exception\"));\n    buf.skipBytes(4); \n\n        \n    channel.writeInbound(buf);\n    verify(callback, times(1)).onRequestFailure(eq(1222112278L), isA(RuntimeException.class));\n    assertEquals(\"Buffer not recycled\", 0, buf.refCnt());\n\n        \n        \n        \n    buf =\n            MessageSerializer.serializeServerFailure(\n                    channel.alloc(), new RuntimeException(\"Expected test Exception\"));\n    buf.skipBytes(4); \n\n        \n    channel.writeInbound(buf);\n    verify(callback, times(1)).onFailure(isA(RuntimeException.class));\n\n        \n        \n        \n    buf = channel.alloc().buffer(4).writeInt(1223823);\n\n        \n    channel.writeInbound(buf);\n    verify(callback, times(1)).onFailure(isA(IllegalStateException.class));\n    assertEquals(\"Buffer not recycled\", 0, buf.refCnt());\n\n        \n        \n        \n    channel.pipeline().fireExceptionCaught(new RuntimeException(\"Expected test Exception\"));\n    verify(callback, times(3)).onFailure(isA(RuntimeException.class));\n\n        \n        \n        \n    channel.pipeline().fireChannelInactive();\n    verify(callback, times(1)).onFailure(isA(ClosedChannelException.class));\n}", "summary_tokens": ["tests", "that", "on", "reads", "the", "expected", "callback", "methods", "are", "called", "and", "read", "buffers", "are", "recycled"], "project": "flink"}
{"id": 2894, "code": "public int getNumberOfParameters() {\n    return data.size();\n}", "summary_tokens": ["returns", "number", "of", "parameters", "in", "parameter", "tool"], "project": "flink"}
{"id": 8231, "code": "default TableSchema getSchema() {\n    return TableSchema.fromResolvedSchema(getResolvedSchema());\n}", "summary_tokens": ["this", "method", "returns", "the", "deprecated", "table", "schema", "class"], "project": "flink"}
{"id": 4029, "code": "public void testMaximumFramesizeRemoteMessageTransfer() throws Exception {\n    LinkedBlockingQueue<Object> linkedBlockingQueue = new LinkedBlockingQueue<>();\n\n    TestEndpoint testEndpoint = new TestEndpoint(akkaRpcService1, linkedBlockingQueue);\n    testEndpoint.start();\n\n    String address = testEndpoint.getAddress();\n\n    CompletableFuture<TestGateway> remoteGatewayFuture =\n            akkaRpcService2.connect(address, TestGateway.class);\n\n    TestGateway remoteGateway = remoteGatewayFuture.get(timeout.getSize(), timeout.getUnit());\n\n    int bufferSize = maxFrameSize + 1;\n    byte[] buffer = new byte[bufferSize];\n\n    remoteGateway.foobar(buffer);\n\n    fail(\"Should have failed due to exceeding the maximum framesize.\");\n}", "summary_tokens": ["tests", "that", "a", "message", "which", "exceeds", "the", "maximum", "frame", "size", "is", "detected", "and", "a", "corresponding", "exception", "is", "thrown"], "project": "flink"}
{"id": 3216, "code": "public GraphCsvReader lineDelimiterEdges(String delimiter) {\n    edgeReader.lineDelimiter(delimiter);\n    return this;\n}", "summary_tokens": ["configures", "the", "delimiter", "that", "separates", "rows", "for", "the", "csv", "reader", "used", "to", "read", "the", "edges", "n", "is", "used", "by", "default"], "project": "flink"}
{"id": 6550, "code": "public void testHighAvailabilityDefault() throws Exception {\n    final String haPersistenceDir = new Path(tmp.newFolder().toURI()).toString();\n    testMemoryBackendHighAvailabilityDefault(haPersistenceDir, null);\n\n    final Path checkpointPath = new Path(tmp.newFolder().toURI().toString());\n    testMemoryBackendHighAvailabilityDefault(haPersistenceDir, checkpointPath);\n}", "summary_tokens": ["this", "tests", "the", "default", "behaviour", "in", "the", "case", "of", "configured", "high", "availability"], "project": "flink"}
{"id": 426, "code": "public static boolean implicitConvertible(\n        PrimitiveObjectInspector.PrimitiveCategory from,\n        PrimitiveObjectInspector.PrimitiveCategory to) {\n    if (from == to) {\n        return true;\n    }\n\n    PrimitiveObjectInspectorUtils.PrimitiveGrouping fromPg =\n            PrimitiveObjectInspectorUtils.getPrimitiveGrouping(from);\n    PrimitiveObjectInspectorUtils.PrimitiveGrouping toPg =\n            PrimitiveObjectInspectorUtils.getPrimitiveGrouping(to);\n\n        \n    if (fromPg == PrimitiveObjectInspectorUtils.PrimitiveGrouping.STRING_GROUP\n            && to == PrimitiveObjectInspector.PrimitiveCategory.DOUBLE) {\n        return true;\n    }\n\n        \n    if (from == PrimitiveObjectInspector.PrimitiveCategory.VOID) {\n        return true;\n    }\n\n        \n    if (fromPg == PrimitiveObjectInspectorUtils.PrimitiveGrouping.DATE_GROUP\n            && toPg == PrimitiveObjectInspectorUtils.PrimitiveGrouping.STRING_GROUP) {\n        return true;\n    }\n        \n    if (fromPg == PrimitiveObjectInspectorUtils.PrimitiveGrouping.NUMERIC_GROUP\n            && toPg == PrimitiveObjectInspectorUtils.PrimitiveGrouping.STRING_GROUP) {\n        return true;\n    }\n        \n    if (fromPg == PrimitiveObjectInspectorUtils.PrimitiveGrouping.STRING_GROUP\n            && toPg == PrimitiveObjectInspectorUtils.PrimitiveGrouping.STRING_GROUP) {\n        return true;\n    }\n\n        \n        \n    Integer f = numericTypes.get(from);\n    Integer t = numericTypes.get(to);\n    if (f == null || t == null) {\n        return false;\n    }\n    return f <= t;\n}", "summary_tokens": ["test", "if", "it", "s", "implicitly", "convertible", "for", "data", "comparison"], "project": "flink"}
{"id": 4354, "code": "public ResultPartitionType getConsumedPartitionType() {\n    return consumedPartitionType;\n}", "summary_tokens": ["returns", "the", "type", "of", "this", "input", "channel", "s", "consumed", "result", "partition"], "project": "flink"}
{"id": 8695, "code": "public static DataType getPojoWithCustomOrderDataType(Class<?> pojoClass) {\n    final StructuredType.Builder builder = StructuredType.newBuilder(pojoClass);\n    builder.attributes(\n            Arrays.asList(\n                    new StructuredAttribute(\"z\", new BigIntType()),\n                    new StructuredAttribute(\"y\", new BooleanType()),\n                    new StructuredAttribute(\"x\", new IntType())));\n    builder.setFinal(true);\n    builder.setInstantiable(true);\n    final StructuredType structuredType = builder.build();\n\n    final List<DataType> fieldDataTypes =\n            Arrays.asList(DataTypes.BIGINT(), DataTypes.BOOLEAN(), DataTypes.INT());\n\n    return new FieldsDataType(structuredType, pojoClass, fieldDataTypes);\n}", "summary_tokens": ["testing", "data", "type", "shared", "with", "the", "scala", "tests"], "project": "flink"}
{"id": 5532, "code": "public static QueryableStateConfiguration fromConfiguration(Configuration config) {\n    if (!config.getBoolean(QueryableStateOptions.ENABLE_QUERYABLE_STATE_PROXY_SERVER)) {\n        return null;\n    }\n\n    final Iterator<Integer> proxyPorts =\n            NetUtils.getPortRangeFromString(\n                    config.getString(QueryableStateOptions.PROXY_PORT_RANGE));\n    final Iterator<Integer> serverPorts =\n            NetUtils.getPortRangeFromString(\n                    config.getString(QueryableStateOptions.SERVER_PORT_RANGE));\n\n    final int numProxyServerNetworkThreads =\n            config.getInteger(QueryableStateOptions.PROXY_NETWORK_THREADS);\n    final int numProxyServerQueryThreads =\n            config.getInteger(QueryableStateOptions.PROXY_ASYNC_QUERY_THREADS);\n\n    final int numStateServerNetworkThreads =\n            config.getInteger(QueryableStateOptions.SERVER_NETWORK_THREADS);\n    final int numStateServerQueryThreads =\n            config.getInteger(QueryableStateOptions.SERVER_ASYNC_QUERY_THREADS);\n\n    return new QueryableStateConfiguration(\n            proxyPorts,\n            serverPorts,\n            numProxyServerNetworkThreads,\n            numProxyServerQueryThreads,\n            numStateServerNetworkThreads,\n            numStateServerQueryThreads);\n}", "summary_tokens": ["creates", "the", "queryable", "state", "configuration", "from", "the", "given", "configuration"], "project": "flink"}
{"id": 8877, "code": "private Operation convertSqlInsert(RichSqlInsert insert) {\n        \n    List<String> targetTablePath = ((SqlIdentifier) insert.getTargetTableID()).names;\n        \n    HintStrategyTable hintStrategyTable =\n            flinkPlanner.config().getSqlToRelConverterConfig().getHintStrategyTable();\n    List<RelHint> tableHints = SqlUtil.getRelHint(hintStrategyTable, insert.getTableHints());\n    Map<String, String> dynamicOptions = FlinkHints.getHintedOptions(tableHints);\n\n    UnresolvedIdentifier unresolvedIdentifier = UnresolvedIdentifier.of(targetTablePath);\n    ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n\n    PlannerQueryOperation query =\n            (PlannerQueryOperation)\n                    SqlToOperationConverter.convert(\n                                    flinkPlanner, catalogManager, insert.getSource())\n                            .orElseThrow(\n                                    () ->\n                                            new TableException(\n                                                    \"Unsupported node type \"\n                                                            + insert.getSource()\n                                                                    .getClass()\n                                                                    .getSimpleName()));\n\n    return new CatalogSinkModifyOperation(\n            identifier,\n            query,\n            insert.getStaticPartitionKVs(),\n            insert.isOverwrite(),\n            dynamicOptions);\n}", "summary_tokens": ["convert", "insert", "into", "statement"], "project": "flink"}
{"id": 7966, "code": "public static List<RowtimeAttributeDescriptor> deriveRowtimeAttributes(\n        DescriptorProperties properties) {\n\n    Map<String, String> names = properties.getIndexedProperty(SCHEMA, SCHEMA_NAME);\n\n    List<RowtimeAttributeDescriptor> attributes = new ArrayList<>();\n\n        \n    for (int i = 0; i < names.size(); i++) {\n        Optional<Tuple2<TimestampExtractor, WatermarkStrategy>> rowtimeComponents =\n                RowtimeValidator.getRowtimeComponents(properties, SCHEMA + \".\" + i + \".\");\n        int index = i;\n            \n        rowtimeComponents.ifPresent(\n                tuple2 ->\n                        attributes.add(\n                                new RowtimeAttributeDescriptor(\n                                        properties.getString(\n                                                SCHEMA + \".\" + index + \".\" + SCHEMA_NAME),\n                                        tuple2.f0,\n                                        tuple2.f1)));\n    }\n\n    return attributes;\n}", "summary_tokens": ["finds", "the", "rowtime", "attributes", "if", "defined"], "project": "flink"}
{"id": 9656, "code": "public void testTimestampExtractorWithDecreasingCustomWatermarkEmit() throws Exception {\n    final int numElements = 10;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    env.getConfig().setAutoWatermarkInterval(1);\n    env.setParallelism(1);\n\n    DataStream<Integer> source1 =\n            env.addSource(\n                    new SourceFunction<Integer>() {\n                        @Override\n                        public void run(SourceContext<Integer> ctx) throws Exception {\n                            int index = 1;\n                            while (index <= numElements) {\n                                ctx.collect(index);\n                                Thread.sleep(100);\n                                ctx.collect(index - 1);\n                                latch.await();\n                                index++;\n                            }\n                        }\n\n                        @Override\n                        public void cancel() {}\n                    });\n\n    source1.assignTimestampsAndWatermarks(\n                    new AssignerWithPunctuatedWatermarks<Integer>() {\n\n                        @Override\n                        public long extractTimestamp(Integer element, long previousTimestamp) {\n                            return element;\n                        }\n\n                        @Override\n                        public Watermark checkAndGetNextWatermark(\n                                Integer element, long extractedTimestamp) {\n                            return new Watermark(extractedTimestamp - 1);\n                        }\n                    })\n            .transform(\"Watermark Check\", BasicTypeInfo.INT_TYPE_INFO, new CustomOperator(true))\n            .transform(\n                    \"Timestamp Check\",\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    new TimestampCheckingOperator());\n\n    env.execute();\n\n        \n    for (int j = 0; j < numElements; j++) {\n        if (!CustomOperator.finalWatermarks[0].get(j).equals(new Watermark(j))) {\n            Assert.fail(\"Wrong watermark.\");\n        }\n    }\n        \n    assertEquals(\n            Watermark.MAX_WATERMARK,\n            CustomOperator.finalWatermarks[0].get(\n                    CustomOperator.finalWatermarks[0].size() - 1));\n}", "summary_tokens": ["this", "test", "verifies", "that", "the", "timestamp", "extractor", "does", "not", "emit", "decreasing", "watermarks"], "project": "flink"}
{"id": 304, "code": "public byte[] getStartRow() {\n    return this.startRow;\n}", "summary_tokens": ["returns", "the", "start", "row"], "project": "flink"}
{"id": 9601, "code": "public void testQueryWithStatsForRepartitionAny() throws Exception {\n    testQueryGeneric(\n            100L * 1024 * 1024 * 1024 * 1024,\n            100L * 1024 * 1024 * 1024 * 1024,\n            0.1f,\n            0.5f,\n            false,\n            true,\n            true,\n            true,\n            true);\n}", "summary_tokens": ["statistics", "that", "push", "towards", "a", "broadcast", "join"], "project": "flink"}
{"id": 8872, "code": "private Operation convertAlterTable(SqlAlterTable sqlAlterTable) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlAlterTable.fullTableName());\n    ObjectIdentifier tableIdentifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n    Optional<CatalogManager.TableLookupResult> optionalCatalogTable =\n            catalogManager.getTable(tableIdentifier);\n    if (!optionalCatalogTable.isPresent() || optionalCatalogTable.get().isTemporary()) {\n        throw new ValidationException(\n                String.format(\n                        \"Table %s doesn't exist or is a temporary table.\",\n                        tableIdentifier.toString()));\n    }\n    CatalogBaseTable baseTable = optionalCatalogTable.get().getTable();\n    if (baseTable instanceof CatalogView) {\n        throw new ValidationException(\"ALTER TABLE for a view is not allowed\");\n    }\n    if (sqlAlterTable instanceof SqlAlterTableRename) {\n        UnresolvedIdentifier newUnresolvedIdentifier =\n                UnresolvedIdentifier.of(\n                        ((SqlAlterTableRename) sqlAlterTable).fullNewTableName());\n        ObjectIdentifier newTableIdentifier =\n                catalogManager.qualifyIdentifier(newUnresolvedIdentifier);\n        return new AlterTableRenameOperation(tableIdentifier, newTableIdentifier);\n    } else if (sqlAlterTable instanceof SqlAlterTableOptions) {\n        return convertAlterTableOptions(\n                tableIdentifier,\n                (CatalogTable) baseTable,\n                (SqlAlterTableOptions) sqlAlterTable);\n    } else if (sqlAlterTable instanceof SqlAlterTableReset) {\n        return convertAlterTableReset(\n                tableIdentifier, (CatalogTable) baseTable, (SqlAlterTableReset) sqlAlterTable);\n    } else if (sqlAlterTable instanceof SqlAlterTableAddConstraint) {\n        SqlTableConstraint constraint =\n                ((SqlAlterTableAddConstraint) sqlAlterTable).getConstraint();\n        validateTableConstraint(constraint);\n        TableSchema oriSchema =\n                TableSchema.fromResolvedSchema(\n                        baseTable\n                                .getUnresolvedSchema()\n                                .resolve(catalogManager.getSchemaResolver()));\n            \n        TableSchema.Builder builder = TableSchemaUtils.builderWithGivenSchema(oriSchema);\n        if (constraint.getConstraintName().isPresent()) {\n            builder.primaryKey(\n                    constraint.getConstraintName().get(), constraint.getColumnNames());\n        } else {\n            builder.primaryKey(constraint.getColumnNames());\n        }\n        builder.build();\n        return new AlterTableAddConstraintOperation(\n                tableIdentifier,\n                constraint.getConstraintName().orElse(null),\n                constraint.getColumnNames());\n    } else if (sqlAlterTable instanceof SqlAlterTableDropConstraint) {\n        SqlAlterTableDropConstraint dropConstraint =\n                ((SqlAlterTableDropConstraint) sqlAlterTable);\n        String constraintName = dropConstraint.getConstraintName().getSimple();\n        TableSchema oriSchema =\n                TableSchema.fromResolvedSchema(\n                        baseTable\n                                .getUnresolvedSchema()\n                                .resolve(catalogManager.getSchemaResolver()));\n        if (!oriSchema\n                .getPrimaryKey()\n                .filter(pk -> pk.getName().equals(constraintName))\n                .isPresent()) {\n            throw new ValidationException(\n                    String.format(\"CONSTRAINT [%s] does not exist\", constraintName));\n        }\n        return new AlterTableDropConstraintOperation(tableIdentifier, constraintName);\n    } else if (sqlAlterTable instanceof SqlAddReplaceColumns) {\n        return OperationConverterUtils.convertAddReplaceColumns(\n                tableIdentifier,\n                (SqlAddReplaceColumns) sqlAlterTable,\n                (CatalogTable) baseTable,\n                flinkPlanner.getOrCreateSqlValidator());\n    } else if (sqlAlterTable instanceof SqlChangeColumn) {\n        return OperationConverterUtils.convertChangeColumn(\n                tableIdentifier,\n                (SqlChangeColumn) sqlAlterTable,\n                (CatalogTable) baseTable,\n                flinkPlanner.getOrCreateSqlValidator());\n    } else if (sqlAlterTable instanceof SqlAddPartitions) {\n        List<CatalogPartitionSpec> specs = new ArrayList<>();\n        List<CatalogPartition> partitions = new ArrayList<>();\n        SqlAddPartitions addPartitions = (SqlAddPartitions) sqlAlterTable;\n        for (int i = 0; i < addPartitions.getPartSpecs().size(); i++) {\n            specs.add(new CatalogPartitionSpec(addPartitions.getPartitionKVs(i)));\n            Map<String, String> props =\n                    OperationConverterUtils.extractProperties(\n                            addPartitions.getPartProps().get(i));\n            partitions.add(new CatalogPartitionImpl(props, null));\n        }\n        return new AddPartitionsOperation(\n                tableIdentifier, addPartitions.ifNotExists(), specs, partitions);\n    } else if (sqlAlterTable instanceof SqlDropPartitions) {\n        SqlDropPartitions dropPartitions = (SqlDropPartitions) sqlAlterTable;\n        List<CatalogPartitionSpec> specs = new ArrayList<>();\n        for (int i = 0; i < dropPartitions.getPartSpecs().size(); i++) {\n            specs.add(new CatalogPartitionSpec(dropPartitions.getPartitionKVs(i)));\n        }\n        return new DropPartitionsOperation(tableIdentifier, dropPartitions.ifExists(), specs);\n    } else {\n        throw new ValidationException(\n                String.format(\n                        \"[%s] needs to implement\",\n                        sqlAlterTable.toSqlString(CalciteSqlDialect.DEFAULT)));\n    }\n}", "summary_tokens": ["convert", "alter", "table", "statement"], "project": "flink"}
{"id": 2760, "code": "public Configuration getParameters() {\n    return this.parameters;\n}", "summary_tokens": ["configuration", "for", "the", "input", "format"], "project": "flink"}
{"id": 8496, "code": "public TypeInformation<?>[] getFieldTypes() {\n    if (fieldTypes.isPresent()) {\n        return fieldTypes.get();\n    } else {\n        throw new IllegalStateException(\n                \"Table sink must be configured to retrieve field types.\");\n    }\n}", "summary_tokens": ["returns", "the", "field", "types", "of", "the", "table", "to", "emit"], "project": "flink"}
{"id": 7406, "code": "public static <E> SourceOutputWithWatermarks<E> createWithSameOutputs(\n        PushingAsyncDataInput.DataOutput<E> recordsAndWatermarksOutput,\n        TimestampAssigner<E> timestampAssigner,\n        WatermarkGenerator<E> watermarkGenerator) {\n\n    final WatermarkOutput watermarkOutput =\n            new WatermarkToDataOutput(recordsAndWatermarksOutput);\n\n    return new SourceOutputWithWatermarks<>(\n            recordsAndWatermarksOutput,\n            watermarkOutput,\n            watermarkOutput,\n            timestampAssigner,\n            watermarkGenerator);\n}", "summary_tokens": ["creates", "a", "new", "source", "output", "with", "watermarks", "that", "emits", "records", "to", "the", "given", "data", "output", "and", "watermarks", "to", "the", "possibly", "different", "watermark", "output"], "project": "flink"}
{"id": 7844, "code": "public void testDeclineCallOnCancelBarrierTwoInputs() throws Exception {\n\n    TwoInputStreamTaskTestHarness<String, String, String> testHarness =\n            new TwoInputStreamTaskTestHarness<>(\n                    TwoInputStreamTask::new,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n    testHarness.setupOutputForSingletonOperatorChain();\n\n    StreamConfig streamConfig = testHarness.getStreamConfig();\n    CoStreamMap<String, String, String> op = new CoStreamMap<>(new UnionCoMap());\n    streamConfig.setStreamOperator(op);\n    streamConfig.setOperatorID(new OperatorID());\n\n    StreamMockEnvironment environment = spy(testHarness.createEnvironment());\n\n        \n    testHarness.invoke(environment);\n    testHarness.waitForTaskRunning();\n\n        \n    testHarness.processEvent(new CancelCheckpointMarker(2L), 0, 0);\n    testHarness.processEvent(new CancelCheckpointMarker(2L), 1, 0);\n    testHarness.waitForInputProcessing();\n\n        \n    verify(environment, times(1))\n            .declineCheckpoint(\n                    eq(2L),\n                    argThat(\n                            new AlignedCheckpointsTest.CheckpointExceptionMatcher(\n                                    CheckpointFailureReason\n                                            .CHECKPOINT_DECLINED_ON_CANCELLATION_BARRIER)));\n\n        \n    Object result = testHarness.getOutput().poll();\n    assertNotNull(\"nothing emitted\", result);\n    assertTrue(\"wrong type emitted\", result instanceof CancelCheckpointMarker);\n    assertEquals(\n            \"wrong checkpoint id\", 2L, ((CancelCheckpointMarker) result).getCheckpointId());\n\n        \n    testHarness.endInput();\n    testHarness.waitForTaskCompletion();\n}", "summary_tokens": ["this", "test", "verifies", "for", "two", "input", "tasks", "that", "the", "stream", "tasks", "react", "the", "following", "way", "to", "receiving", "a", "checkpoint", "cancellation", "barrier", "send", "a", "decline", "checkpoint", "notification", "out", "to", "the", "job", "manager", "emit", "a", "cancellation", "barrier", "downstream"], "project": "flink"}
{"id": 6542, "code": "static SplitsAssignment<MockSourceSplit> getSplitsAssignment(\n        int numSubtasks, int startingSplitId) {\n    Map<Integer, List<MockSourceSplit>> assignments = new HashMap<>();\n    int splitId = startingSplitId;\n    for (int subtaskIndex = 0; subtaskIndex < numSubtasks; subtaskIndex++) {\n        List<MockSourceSplit> subtaskAssignment = new ArrayList<>();\n        for (int j = 0; j < subtaskIndex + 1; j++) {\n            subtaskAssignment.add(new MockSourceSplit(splitId++));\n        }\n        assignments.put(subtaskIndex, subtaskAssignment);\n    }\n    return new SplitsAssignment<>(assignments);\n}", "summary_tokens": ["create", "a", "splits", "assignment"], "project": "flink"}
{"id": 3988, "code": "private static Config getDefaultAkkaConfig() {\n    return getAkkaConfig(new Configuration(), new HostAndPort(\"\", 0));\n}", "summary_tokens": ["creates", "the", "default", "akka", "configuration", "which", "listens", "on", "a", "random", "port", "on", "the", "local", "machine"], "project": "flink"}
{"id": 484, "code": "public static void sync(Metric from, Counter to) {\n    to.inc(((Number) from.metricValue()).longValue() - to.getCount());\n}", "summary_tokens": ["ensures", "that", "the", "counter", "has", "the", "same", "value", "as", "the", "given", "kafka", "metric"], "project": "flink"}
{"id": 2157, "code": "public void testSerializerSerializationWithClassNotFound() throws Exception {\n\n    TypeSerializer<?> serializer = IntSerializer.INSTANCE;\n\n    byte[] serialized;\n    try (ByteArrayOutputStreamWithPos out = new ByteArrayOutputStreamWithPos()) {\n        TypeSerializerSerializationUtil.writeSerializer(\n                new DataOutputViewStreamWrapper(out), serializer);\n        serialized = out.toByteArray();\n    }\n\n    TypeSerializer<?> deserializedSerializer;\n\n    try (ByteArrayInputStreamWithPos in = new ByteArrayInputStreamWithPos(serialized)) {\n        deserializedSerializer =\n                TypeSerializerSerializationUtil.tryReadSerializer(\n                        new DataInputViewStreamWrapper(in),\n                        new ArtificialCNFExceptionThrowingClassLoader(\n                                Thread.currentThread().getContextClassLoader(),\n                                Collections.singleton(IntSerializer.class.getName())),\n                        true);\n    }\n    Assert.assertTrue(deserializedSerializer instanceof UnloadableDummyTypeSerializer);\n\n    Assert.assertArrayEquals(\n            InstantiationUtil.serializeObject(serializer),\n            ((UnloadableDummyTypeSerializer<?>) deserializedSerializer).getActualBytes());\n}", "summary_tokens": ["verifies", "deserialization", "failure", "cases", "when", "reading", "a", "serializer", "from", "bytes", "in", "the", "case", "of", "a", "class", "not", "found", "exception"], "project": "flink"}
{"id": 9057, "code": "public void testJoinTemporalFunction() throws Exception {\n\n    String jsonPlan =\n            tableEnv.getJsonPlan(\n                    \"INSERT INTO MySink \"\n                            + \"SELECT amount * r.rate \"\n                            + \"FROM Orders AS o,  \"\n                            + \"LATERAL TABLE (Rates(o.rowtime)) AS r \"\n                            + \"WHERE o.currency = r.currency \");\n    tableEnv.executeJsonPlan(jsonPlan).await();\n    List<String> expected = Arrays.asList(\"+I[102]\", \"+I[228]\", \"+I[348]\", \"+I[50]\");\n    assertResult(expected, TestValuesTableFactory.getResults(\"MySink\"));\n}", "summary_tokens": ["test", "process", "time", "inner", "join"], "project": "flink"}
{"id": 3485, "code": "public <T> SavepointWriter withOperator(\n        String uid, StateBootstrapTransformation<T> transformation) {\n    metadata.addOperator(uid, transformation);\n    return this;\n}", "summary_tokens": ["adds", "a", "new", "operator", "to", "the", "savepoint"], "project": "flink"}
{"id": 9009, "code": "public RelDataType getRowType() {\n    return rowType;\n}", "summary_tokens": ["returns", "the", "type", "of", "rows", "returned", "by", "this", "table"], "project": "flink"}
{"id": 3603, "code": "public boolean isBreakingPipeline() {\n    return this.breakPipeline;\n}", "summary_tokens": ["checks", "whether", "this", "connection", "is", "marked", "to", "break", "the", "pipeline"], "project": "flink"}
{"id": 5843, "code": "private void testGetFailsDuringLookup(\n        @Nullable final JobID jobId1, @Nullable final JobID jobId2, BlobKey.BlobType blobType)\n        throws IOException {\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore())) {\n\n        server.start();\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n\n            \n        BlobKey key = put(server, jobId1, data, blobType);\n        assertNotNull(key);\n\n            \n        File blobFile = server.getStorageLocation(jobId1, key);\n        assertTrue(blobFile.delete());\n\n            \n        verifyDeleted(server, jobId1, key);\n\n            \n        BlobKey key2 = put(server, jobId2, data, blobType);\n        assertNotNull(key2);\n        verifyKeyDifferentHashEquals(key, key2);\n\n            \n        get(server, jobId2, key2);\n            \n        verifyDeleted(server, jobId1, key);\n\n            \n        blobFile = server.getStorageLocation(jobId2, key2);\n        assertTrue(blobFile.delete());\n        verifyDeleted(server, jobId2, key2);\n    }\n}", "summary_tokens": ["checks", "the", "correct", "result", "if", "a", "get", "operation", "fails", "during", "the", "lookup", "of", "the", "file"], "project": "flink"}
{"id": 5421, "code": "public static StateBackend fromApplicationOrConfigOrDefault(\n        @Nullable StateBackend fromApplication,\n        TernaryBoolean isChangelogStateBackendEnableFromApplication,\n        Configuration config,\n        ClassLoader classLoader,\n        @Nullable Logger logger)\n        throws IllegalConfigurationException, DynamicCodeLoadingException, IOException {\n\n    StateBackend rootBackend =\n            loadFromApplicationOrConfigOrDefaultInternal(\n                    fromApplication, config, classLoader, logger);\n\n        \n    boolean enableChangeLog =\n            TernaryBoolean.TRUE.equals(isChangelogStateBackendEnableFromApplication)\n                    || (TernaryBoolean.UNDEFINED.equals(\n                                    isChangelogStateBackendEnableFromApplication)\n                            && config.get(StateChangelogOptions.ENABLE_STATE_CHANGE_LOG));\n\n    StateBackend backend;\n    if (enableChangeLog) {\n        backend = loadChangelogStateBackend(rootBackend, classLoader);\n        LOG.info(\n                \"State backend loader loads {} to delegate {}\",\n                backend.getClass().getSimpleName(),\n                rootBackend.getClass().getSimpleName());\n    } else {\n        backend = rootBackend;\n        LOG.info(\n                \"State backend loader loads the state backend as {}\",\n                backend.getClass().getSimpleName());\n    }\n    return backend;\n}", "summary_tokens": ["this", "is", "the", "state", "backend", "loader", "that", "loads", "a", "delegating", "state", "backend", "wrapping", "the", "state", "backend", "loaded", "from", "state", "backend", "loader", "load", "from", "application", "or", "config", "or", "default", "internal", "when", "delegation", "is", "enabled"], "project": "flink"}
{"id": 5431, "code": "public static void bestEffortDiscardAllStateObjects(\n        Iterable<? extends StateObject> handlesToDiscard) throws Exception {\n    LambdaUtil.applyToAllWhileSuppressingExceptions(\n            handlesToDiscard, StateObject::discardState);\n}", "summary_tokens": ["iterates", "through", "the", "passed", "state", "handles", "and", "calls", "discard", "state", "on", "each", "handle", "that", "is", "not", "null"], "project": "flink"}
{"id": 3110, "code": "public void testReleaseNodesWithLongPath() throws Exception {\n    SharedBuffer<Event> sharedBuffer =\n            TestSharedBuffer.createTestBuffer(Event.createTypeSerializer(), cacheConfig);\n\n    final int numberEvents = 100000;\n    Event[] events = new Event[numberEvents];\n    EventId[] eventIds = new EventId[numberEvents];\n    NodeId[] nodeIds = new NodeId[numberEvents];\n\n    final long timestamp = 1L;\n\n    for (int i = 0; i < numberEvents; i++) {\n        events[i] = new Event(i + 1, \"e\" + (i + 1), i);\n        eventIds[i] = sharedBuffer.registerEvent(events[i], timestamp);\n    }\n\n    try (SharedBufferAccessor<Event> sharedBufferAccessor = sharedBuffer.getAccessor()) {\n\n        for (int i = 0; i < numberEvents; i++) {\n            NodeId prevId = i == 0 ? null : nodeIds[i - 1];\n            nodeIds[i] =\n                    sharedBufferAccessor.put(\n                            \"n\" + i, eventIds[i], prevId, DeweyNumber.fromString(\"1.0\"));\n        }\n\n        NodeId lastNode = nodeIds[numberEvents - 1];\n        sharedBufferAccessor.releaseNode(lastNode, DeweyNumber.fromString(\"1.0\"));\n\n        for (int i = 0; i < numberEvents; i++) {\n            sharedBufferAccessor.releaseEvent(eventIds[i]);\n        }\n    }\n\n    assertTrue(sharedBuffer.isEmpty());\n}", "summary_tokens": ["test", "releasing", "a", "node", "which", "has", "a", "long", "path", "to", "the", "terminal", "node", "the", "node", "without", "an", "out", "going", "edge"], "project": "flink"}
{"id": 1173, "code": "protected static String extractFileExtension(String fileName) {\n    checkNotNull(fileName);\n    int lastPeriodIndex = fileName.lastIndexOf('.');\n    if (lastPeriodIndex < 0) {\n        return null;\n    } else {\n        return fileName.substring(lastPeriodIndex + 1);\n    }\n}", "summary_tokens": ["returns", "the", "extension", "of", "a", "file", "name", "a", "path"], "project": "flink"}
{"id": 3344, "code": "public void postSuperstep() throws Exception {}", "summary_tokens": ["this", "method", "is", "executed", "once", "per", "superstep", "after", "the", "gather", "function", "has", "been", "invoked", "for", "each", "vertex"], "project": "flink"}
{"id": 7422, "code": "public StreamOperatorFactory<OUT> getOperatorFactory() {\n    return operatorFactory;\n}", "summary_tokens": ["returns", "the", "stream", "operator", "factory", "of", "this", "transformation"], "project": "flink"}
{"id": 1219, "code": "public void addForwardedField(int input, int sourceField, int targetField) {\n\n    Map<Integer, FieldSet> fieldMapping;\n\n    if (input != 0 && input != 1) {\n        throw new IndexOutOfBoundsException();\n    } else if (input == 0) {\n        fieldMapping = this.fieldMapping1;\n    } else {\n        fieldMapping = this.fieldMapping2;\n    }\n\n    if (isTargetFieldPresent(targetField, fieldMapping)) {\n        throw new InvalidSemanticAnnotationException(\n                \"Target field \" + targetField + \" was added twice to input \" + input);\n    }\n\n    FieldSet targetFields = fieldMapping.get(sourceField);\n    if (targetFields != null) {\n        fieldMapping.put(sourceField, targetFields.addField(targetField));\n    } else {\n        fieldMapping.put(sourceField, new FieldSet(targetField));\n    }\n}", "summary_tokens": ["adds", "to", "the", "existing", "information", "a", "field", "that", "is", "forwarded", "directly", "from", "the", "source", "record", "s", "in", "the", "first", "input", "to", "the", "destination", "record", "s"], "project": "flink"}
{"id": 13, "code": "public static JobGraph getJobGraphUnderUserClassLoader(\n        final ClassLoader userClassloader,\n        final Pipeline pipeline,\n        final Configuration configuration,\n        final int defaultParallelism) {\n    final ClassLoader contextClassLoader = Thread.currentThread().getContextClassLoader();\n    try {\n        Thread.currentThread().setContextClassLoader(userClassloader);\n        return FlinkPipelineTranslationUtil.getJobGraph(\n                pipeline, configuration, defaultParallelism);\n    } finally {\n        Thread.currentThread().setContextClassLoader(contextClassLoader);\n    }\n}", "summary_tokens": ["transmogrifies", "the", "given", "pipeline", "under", "the", "user", "classloader", "to", "a", "job", "graph"], "project": "flink"}
{"id": 2147, "code": "public void testFileInputSplit() {\n    try {\n        String tempFile =\n                TestFileUtils.createTempFileDirExtension(\n                        temporaryFolder.newFolder(),\n                        \".deflate\",\n                        \"some\",\n                        \"stupid\",\n                        \"meaningless\",\n                        \"files\");\n        final DummyFileInputFormat format = new DummyFileInputFormat();\n        format.setFilePath(tempFile);\n        format.configure(new Configuration());\n        FileInputSplit[] splits = format.createInputSplits(2);\n        Assert.assertEquals(4, splits.length);\n        for (FileInputSplit split : splits) {\n            Assert.assertEquals(\n                    -1L, split.getLength()); \n                \n            Assert.assertEquals(0L, split.getStart()); \n        }\n\n            \n        TestFileUtils.createTempFileInDirectory(\n                tempFile.replace(\"file:\", \"\"),\n                \"this creates a test file with a random extension (at least not .deflate)\");\n\n        final DummyFileInputFormat formatMixed = new DummyFileInputFormat();\n        formatMixed.setFilePath(tempFile);\n        formatMixed.configure(new Configuration());\n        FileInputSplit[] splitsMixed = formatMixed.createInputSplits(2);\n        Assert.assertEquals(5, splitsMixed.length);\n        for (FileInputSplit split : splitsMixed) {\n            if (split.getPath().getName().endsWith(\".deflate\")) {\n                Assert.assertEquals(\n                        -1L,\n                        split.getLength()); \n                    \n                Assert.assertEquals(0L, split.getStart()); \n            } else {\n                Assert.assertEquals(0L, split.getStart());\n                Assert.assertTrue(\"split size not correct\", split.getLength() > 0);\n            }\n        }\n\n    } catch (Exception ex) {\n        ex.printStackTrace();\n        Assert.fail(ex.getMessage());\n    }\n}", "summary_tokens": ["create", "directory", "with", "files", "with"], "project": "flink"}
{"id": 6055, "code": "public void testPointwiseConnectionSequence() throws Exception {\n        \n    testConnections(3, 5, new int[][] {{0}, {0}, {1}, {1}, {2}});\n    testConnections(3, 10, new int[][] {{0}, {0}, {0}, {0}, {1}, {1}, {1}, {2}, {2}, {2}});\n    testConnections(4, 6, new int[][] {{0}, {0}, {1}, {2}, {2}, {3}});\n    testConnections(6, 10, new int[][] {{0}, {0}, {1}, {1}, {2}, {3}, {3}, {4}, {4}, {5}});\n\n        \n    testConnections(5, 3, new int[][] {{0}, {1, 2}, {3, 4}});\n    testConnections(10, 3, new int[][] {{0, 1, 2}, {3, 4, 5}, {6, 7, 8, 9}});\n    testConnections(6, 4, new int[][] {{0}, {1, 2}, {3}, {4, 5}});\n    testConnections(10, 6, new int[][] {{0}, {1, 2}, {3, 4}, {5}, {6, 7}, {8, 9}});\n}", "summary_tokens": ["verify", "the", "connection", "sequences", "for", "pointwise", "edges", "is", "correct", "and", "make", "sure", "the", "descendant", "logic", "of", "building", "pointwise", "edges", "follows", "the", "initial", "logic"], "project": "flink"}
{"id": 3680, "code": "public boolean isTrivial() {\n    return ordering == null && this.groupedFields == null;\n}", "summary_tokens": ["checks", "if", "the", "properties", "in", "this", "object", "are", "trivial", "i"], "project": "flink"}
{"id": 7208, "code": "public ExternalizedCheckpointCleanup getExternalizedCheckpointCleanup() {\n    return externalizedCheckpointCleanup;\n}", "summary_tokens": ["returns", "the", "cleanup", "behaviour", "for", "externalized", "checkpoints"], "project": "flink"}
{"id": 41, "code": "public static ExecutionConfigAccessor fromConfiguration(final Configuration configuration) {\n    return new ExecutionConfigAccessor(checkNotNull(configuration));\n}", "summary_tokens": ["creates", "an", "execution", "config", "accessor", "based", "on", "the", "provided", "configuration"], "project": "flink"}
{"id": 8563, "code": "public static TypeInference forTableAggregateFunction(\n        DataTypeFactory typeFactory, Class<? extends TableAggregateFunction<?, ?>> function) {\n    final FunctionMappingExtractor mappingExtractor =\n            new FunctionMappingExtractor(\n                    typeFactory,\n                    function,\n                    UserDefinedFunctionHelper.TABLE_AGGREGATE_ACCUMULATE,\n                    createParameterSignatureExtraction(1),\n                    createGenericResultExtraction(TableAggregateFunction.class, 1, false),\n                    createGenericResultExtraction(TableAggregateFunction.class, 0, true),\n                    createParameterWithAccumulatorVerification());\n    return extractTypeInference(mappingExtractor);\n}", "summary_tokens": ["extracts", "a", "type", "inference", "from", "a", "table", "aggregate", "function"], "project": "flink"}
{"id": 5488, "code": "public HeapPriorityQueueSnapshotRestoreWrapper<T> forUpdatedSerializer(\n        @Nonnull TypeSerializer<T> updatedSerializer) {\n\n    RegisteredPriorityQueueStateBackendMetaInfo<T> updatedMetaInfo =\n            new RegisteredPriorityQueueStateBackendMetaInfo<>(\n                    metaInfo.getName(), updatedSerializer);\n\n    return new HeapPriorityQueueSnapshotRestoreWrapper<>(\n            priorityQueue,\n            updatedMetaInfo,\n            keyExtractorFunction,\n            localKeyGroupRange,\n            totalKeyGroups);\n}", "summary_tokens": ["returns", "a", "deep", "copy", "of", "the", "snapshot", "where", "the", "serializer", "is", "changed", "to", "the", "given", "serializer"], "project": "flink"}
{"id": 2918, "code": "public void testMinByComparison() {\n    SelectByMinFunction<Tuple5<Integer, Long, String, Long, Integer>> minByTuple =\n            new SelectByMinFunction<Tuple5<Integer, Long, String, Long, Integer>>(\n                    tupleTypeInfo, new int[] {0});\n\n    try {\n        Assert.assertSame(\n                \"SelectByMin must return smaller tuple\",\n                smaller,\n                minByTuple.reduce(smaller, bigger));\n        Assert.assertSame(\n                \"SelectByMin must return smaller tuple\",\n                smaller,\n                minByTuple.reduce(bigger, smaller));\n    } catch (Exception e) {\n        Assert.fail(\"No exception should be thrown while comparing both tuples\");\n    }\n}", "summary_tokens": ["this", "test", "validates", "whether", "the", "order", "of", "tuples", "has", "any", "impact", "on", "the", "outcome", "and", "if", "the", "smaller", "tuple", "is", "returned"], "project": "flink"}
{"id": 2762, "code": "public DataSet<ST> getInitialSolutionSet() {\n    return initialSolutionSet;\n}", "summary_tokens": ["gets", "the", "initial", "solution", "set"], "project": "flink"}
{"id": 8710, "code": "public static RexLiteral fromJdbcString(\n        RelDataType type, SqlTypeName typeName, String literal) {\n    if (literal == null) {\n        return null;\n    }\n\n    switch (typeName) {\n        case CHAR:\n            Charset charset = type.getCharset();\n            SqlCollation collation = type.getCollation();\n            NlsString str = new NlsString(literal, charset.name(), collation);\n            return new RexLiteral(str, type, typeName);\n        case BOOLEAN:\n            boolean b = ConversionUtil.toBoolean(literal);\n            return new RexLiteral(b, type, typeName);\n        case DECIMAL:\n        case DOUBLE:\n            BigDecimal d = new BigDecimal(literal);\n            return new RexLiteral(d, type, typeName);\n        case BINARY:\n            byte[] bytes = ConversionUtil.toByteArrayFromString(literal, 16);\n            return new RexLiteral(new ByteString(bytes), type, typeName);\n        case NULL:\n            return new RexLiteral(null, type, typeName);\n        case INTERVAL_DAY:\n        case INTERVAL_DAY_HOUR:\n        case INTERVAL_DAY_MINUTE:\n        case INTERVAL_DAY_SECOND:\n        case INTERVAL_HOUR:\n        case INTERVAL_HOUR_MINUTE:\n        case INTERVAL_HOUR_SECOND:\n        case INTERVAL_MINUTE:\n        case INTERVAL_MINUTE_SECOND:\n        case INTERVAL_SECOND:\n            long millis = SqlParserUtil.intervalToMillis(literal, type.getIntervalQualifier());\n            return new RexLiteral(BigDecimal.valueOf(millis), type, typeName);\n        case INTERVAL_YEAR:\n        case INTERVAL_YEAR_MONTH:\n        case INTERVAL_MONTH:\n            long months = SqlParserUtil.intervalToMonths(literal, type.getIntervalQualifier());\n            return new RexLiteral(BigDecimal.valueOf(months), type, typeName);\n        case DATE:\n        case TIME:\n        case TIMESTAMP:\n            String format = getCalendarFormat(typeName);\n            TimeZone tz = DateTimeUtils.UTC_ZONE;\n            final Comparable v;\n            switch (typeName) {\n                case DATE:\n                    final Calendar cal =\n                            DateTimeUtils.parseDateFormat(\n                                    literal, new SimpleDateFormat(format, Locale.ROOT), tz);\n                    if (cal == null) {\n                        throw new AssertionError(\n                                \"fromJdbcString: invalid date/time value '\" + literal + \"'\");\n                    }\n                    v = DateString.fromCalendarFields(cal);\n                    break;\n                default:\n                        \n                    assert format != null;\n                    final DateTimeUtils.PrecisionTime ts =\n                            DateTimeUtils.parsePrecisionDateTimeLiteral(\n                                    literal, new SimpleDateFormat(format, Locale.ROOT), tz, -1);\n                    if (ts == null) {\n                        throw new AssertionError(\n                                \"fromJdbcString: invalid date/time value '\" + literal + \"'\");\n                    }\n                    switch (typeName) {\n                        case TIMESTAMP:\n                            v =\n                                    TimestampString.fromCalendarFields(ts.getCalendar())\n                                            .withFraction(ts.getFraction());\n                            break;\n                        case TIME:\n                            v =\n                                    TimeString.fromCalendarFields(ts.getCalendar())\n                                            .withFraction(ts.getFraction());\n                            break;\n                        default:\n                            throw new AssertionError();\n                    }\n            }\n            return new RexLiteral(v, type, typeName);\n\n        case SYMBOL:\n                \n        default:\n            throw new AssertionError(\"fromJdbcString: unsupported type\");\n    }\n}", "summary_tokens": ["converts", "a", "jdbc", "string", "into", "a", "rex", "literal"], "project": "flink"}
{"id": 2105, "code": "public static Duration toDuration(Time time) {\n    return Duration.ofMillis(time.toMilliseconds());\n}", "summary_tokens": ["converts", "flink", "time", "into", "a", "duration"], "project": "flink"}
{"id": 6751, "code": "private void doWriteKey(\n        long node,\n        int level,\n        MemorySegment keySegment,\n        int keyOffset,\n        int keyLen,\n        long valuePointer,\n        long nextNode) {\n    Node nodeStorage = getNodeSegmentAndOffset(node);\n    MemorySegment segment = nodeStorage.nodeSegment;\n    int offsetInSegment = nodeStorage.nodeOffset;\n\n    SkipListUtils.putLevelAndNodeStatus(segment, offsetInSegment, level, NodeStatus.PUT);\n    SkipListUtils.putKeyLen(segment, offsetInSegment, keyLen);\n    SkipListUtils.putValuePointer(segment, offsetInSegment, valuePointer);\n    SkipListUtils.putNextKeyPointer(segment, offsetInSegment, nextNode);\n    SkipListUtils.putKeyData(segment, offsetInSegment, keySegment, keyOffset, keyLen, level);\n}", "summary_tokens": ["write", "the", "meta", "and", "data", "for", "the", "key", "to", "the", "given", "node"], "project": "flink"}
{"id": 6211, "code": "public void testReportProcessingWithPartitionLossOnSameTaskExecutor() {\n    TestClusterPartitionReleaser partitionReleaser = new TestClusterPartitionReleaser();\n    final ResourceManagerPartitionTracker tracker =\n            new ResourceManagerPartitionTrackerImpl(partitionReleaser);\n\n    report(tracker, TASK_EXECUTOR_ID_1, DATA_SET_ID, 2, PARTITION_ID_1, PARTITION_ID_2);\n    report(tracker, TASK_EXECUTOR_ID_1, DATA_SET_ID, 2, PARTITION_ID_2);\n\n    assertThat(\n            partitionReleaser.releaseCalls,\n            contains(Tuple2.of(TASK_EXECUTOR_ID_1, Collections.singleton(DATA_SET_ID))));\n}", "summary_tokens": ["verifies", "that", "a", "task", "executor", "hosting", "multiple", "partitions", "of", "a", "data", "set", "receives", "a", "release", "call", "if", "a", "subset", "of", "its", "partitions", "is", "lost"], "project": "flink"}
{"id": 961, "code": "public String getHost() {\n    return host;\n}", "summary_tokens": ["the", "host", "to", "use", "for", "connections"], "project": "flink"}
{"id": 8583, "code": "public static CallContext adaptArguments(\n        TypeInference typeInference, CallContext callContext, @Nullable DataType outputType) {\n    return adaptArguments(typeInference, callContext, outputType, true);\n}", "summary_tokens": ["adapts", "the", "call", "s", "argument", "if", "necessary"], "project": "flink"}
{"id": 6456, "code": "public void testPendingSlotNotFulfilledIfProfilesAreNotExactMatch() {\n    final int numWorkerCpuCores = 3;\n    final WorkerResourceSpec workerResourceSpec =\n            new WorkerResourceSpec.Builder().setCpuCores(numWorkerCpuCores).build();\n    final ResourceProfile requestedSlotProfile =\n            ResourceProfile.newBuilder().setCpuCores(numWorkerCpuCores).build();\n    final ResourceProfile offeredSlotProfile =\n            ResourceProfile.newBuilder().setCpuCores(numWorkerCpuCores - 1).build();\n\n    try (final TaskExecutorManager taskExecutorManager =\n            createTaskExecutorManagerBuilder()\n                    .setDefaultWorkerResourceSpec(workerResourceSpec)\n                    .setNumSlotsPerWorker(\n                            1) \n                        \n                    .setMaxNumSlots(2)\n                    .createTaskExecutorManager()) {\n\n            \n        taskExecutorManager.allocateWorker(requestedSlotProfile);\n        assertThat(taskExecutorManager.getNumberPendingTaskManagerSlots(), is(1));\n\n        createAndRegisterTaskExecutor(taskExecutorManager, 1, offeredSlotProfile);\n\n            \n            \n        assertThat(taskExecutorManager.getNumberRegisteredSlots(), is(1));\n        assertThat(taskExecutorManager.getNumberPendingTaskManagerSlots(), is(1));\n    }\n}", "summary_tokens": ["tests", "that", "a", "pending", "slot", "is", "only", "fulfilled", "by", "an", "exactly", "matching", "received", "slot"], "project": "flink"}
{"id": 589, "code": "public void close() throws Exception {\n    closed = true;\n    closeConnections();\n}", "summary_tokens": ["closes", "the", "partition", "discoverer", "cleaning", "up", "all", "kafka", "connections"], "project": "flink"}
{"id": 2403, "code": "private static String stripHostname(final String originalHostname) {\n\n        \n    final int index = originalHostname.indexOf(DOMAIN_SEPARATOR);\n    if (index == -1) {\n        return originalHostname;\n    }\n\n        \n    final Matcher matcher = IPV4_PATTERN.matcher(originalHostname);\n    if (matcher.matches()) {\n        return originalHostname;\n    }\n\n    if (index == 0) {\n        throw new IllegalStateException(\n                \"Hostname \" + originalHostname + \" starts with a \" + DOMAIN_SEPARATOR);\n    }\n\n    return originalHostname.substring(0, index);\n}", "summary_tokens": ["looks", "for", "a", "domain", "suffix", "in", "a", "fqdn", "and", "strips", "it", "if", "present"], "project": "flink"}
{"id": 7986, "code": "public static Builder forFormat(String format) {\n    Preconditions.checkNotNull(format, \"Format descriptors require a format identifier.\");\n    return new Builder(format);\n}", "summary_tokens": ["creates", "a", "new", "builder", "describing", "a", "format", "with", "the", "given", "format", "identifier"], "project": "flink"}
{"id": 3519, "code": "public static CheckpointMetadata loadSavepointMetadata(String savepointPath)\n        throws IOException {\n    CompletedCheckpointStorageLocation location =\n            AbstractFsCheckpointStorageAccess.resolveCheckpointPointer(savepointPath);\n\n    try (DataInputStream stream =\n            new DataInputStream(location.getMetadataHandle().openInputStream())) {\n        return Checkpoints.loadCheckpointMetadata(\n                stream, Thread.currentThread().getContextClassLoader(), savepointPath);\n    }\n}", "summary_tokens": ["takes", "the", "given", "string", "representing", "a", "pointer", "to", "a", "checkpoint", "and", "resolves", "it", "to", "a", "file", "status", "for", "the", "checkpoint", "s", "metadata", "file"], "project": "flink"}
{"id": 1526, "code": "public void setFields(\n        T0 f0,\n        T1 f1,\n        T2 f2,\n        T3 f3,\n        T4 f4,\n        T5 f5,\n        T6 f6,\n        T7 f7,\n        T8 f8,\n        T9 f9,\n        T10 f10,\n        T11 f11,\n        T12 f12,\n        T13 f13,\n        T14 f14,\n        T15 f15,\n        T16 f16,\n        T17 f17,\n        T18 f18,\n        T19 f19,\n        T20 f20,\n        T21 f21,\n        T22 f22,\n        T23 f23,\n        T24 f24) {\n    this.f0 = f0;\n    this.f1 = f1;\n    this.f2 = f2;\n    this.f3 = f3;\n    this.f4 = f4;\n    this.f5 = f5;\n    this.f6 = f6;\n    this.f7 = f7;\n    this.f8 = f8;\n    this.f9 = f9;\n    this.f10 = f10;\n    this.f11 = f11;\n    this.f12 = f12;\n    this.f13 = f13;\n    this.f14 = f14;\n    this.f15 = f15;\n    this.f16 = f16;\n    this.f17 = f17;\n    this.f18 = f18;\n    this.f19 = f19;\n    this.f20 = f20;\n    this.f21 = f21;\n    this.f22 = f22;\n    this.f23 = f23;\n    this.f24 = f24;\n}", "summary_tokens": ["sets", "new", "values", "to", "all", "fields", "of", "the", "tuple"], "project": "flink"}
{"id": 3212, "code": "public <K, VV, EV> Graph<K, VV, EV> types(\n        Class<K> vertexKey, Class<VV> vertexValue, Class<EV> edgeValue) {\n\n    if (edgeReader == null) {\n        throw new RuntimeException(\"The edge input file cannot be null!\");\n    }\n\n    DataSet<Tuple3<K, K, EV>> edges = edgeReader.types(vertexKey, vertexKey, edgeValue);\n\n        \n    if (vertexReader != null) {\n        DataSet<Tuple2<K, VV>> vertices =\n                vertexReader.types(vertexKey, vertexValue).name(GraphCsvReader.class.getName());\n\n        return Graph.fromTupleDataSet(vertices, edges, executionContext);\n    } else if (mapper != null) {\n        return Graph.fromTupleDataSet(edges, (MapFunction<K, VV>) mapper, executionContext);\n    } else {\n        throw new RuntimeException(\n                \"Vertex values have to be specified through a vertices input file\"\n                        + \"or a user-defined map function.\");\n    }\n}", "summary_tokens": ["creates", "a", "graph", "from", "csv", "input", "with", "vertex", "values", "and", "edge", "values"], "project": "flink"}
{"id": 6507, "code": "public void testMainThreadExecutorUnderChangingFencingToken() throws Exception {\n    final Time shortTimeout = Time.milliseconds(100L);\n    final UUID initialFencingToken = UUID.randomUUID();\n    final String value = \"foobar\";\n    final FencedTestingEndpoint fencedTestingEndpoint =\n            new FencedTestingEndpoint(rpcService, value, initialFencingToken);\n\n    try {\n        fencedTestingEndpoint.start();\n\n        FencedTestingGateway selfGateway =\n                fencedTestingEndpoint.getSelfGateway(FencedTestingGateway.class);\n\n        CompletableFuture<Acknowledge> mainThreadExecutorComputation =\n                selfGateway.triggerMainThreadExecutorComputation(timeout);\n\n            \n            \n            \n            \n        final UUID newFencingToken = UUID.randomUUID();\n        CompletableFuture<Acknowledge> newFencingTokenFuture =\n                fencedTestingEndpoint.setFencingTokenInMainThread(newFencingToken, timeout);\n\n        newFencingTokenFuture.get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\n            \n        CompletableFuture<Acknowledge> triggerFuture =\n                selfGateway.triggerComputationLatch(timeout);\n\n        triggerFuture.get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\n            \n        try {\n            mainThreadExecutorComputation.get(\n                    shortTimeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n            fail(\n                    \"The MainThreadExecutor computation should be able to complete because it was filtered out leading to a timeout exception.\");\n        } catch (TimeoutException ignored) {\n                \n        }\n\n    } finally {\n        RpcUtils.terminateRpcEndpoint(fencedTestingEndpoint, timeout);\n    }\n}", "summary_tokens": ["tests", "that", "call", "via", "the", "main", "thread", "executor", "fail", "after", "the", "fencing", "token", "changes"], "project": "flink"}
{"id": 571, "code": "protected <K, V> KafkaProducer<K, V> getKafkaProducer(Properties props) {\n    return new KafkaProducer<>(props);\n}", "summary_tokens": ["used", "for", "testing", "only"], "project": "flink"}
{"id": 670, "code": "public void testPartitionerInvokedWithDeterminatePartitionList() throws Exception {\n    FlinkKafkaPartitioner<String> mockPartitioner = mock(FlinkKafkaPartitioner.class);\n\n    RuntimeContext mockRuntimeContext = mock(StreamingRuntimeContext.class);\n    when(mockRuntimeContext.getIndexOfThisSubtask()).thenReturn(0);\n    when(mockRuntimeContext.getNumberOfParallelSubtasks()).thenReturn(1);\n\n        \n    List<PartitionInfo> mockPartitionsList = new ArrayList<>(4);\n    mockPartitionsList.add(\n            new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 3, null, null, null));\n    mockPartitionsList.add(\n            new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 1, null, null, null));\n    mockPartitionsList.add(\n            new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 0, null, null, null));\n    mockPartitionsList.add(\n            new PartitionInfo(DummyFlinkKafkaProducer.DUMMY_TOPIC, 2, null, null, null));\n\n    final DummyFlinkKafkaProducer<String> producer =\n            new DummyFlinkKafkaProducer<>(\n                    FakeStandardProducerConfig.get(),\n                    new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()),\n                    mockPartitioner);\n    producer.setRuntimeContext(mockRuntimeContext);\n\n    final KafkaProducer mockProducer = producer.getMockKafkaProducer();\n    when(mockProducer.partitionsFor(anyString())).thenReturn(mockPartitionsList);\n    when(mockProducer.metrics()).thenReturn(null);\n\n    producer.open(new Configuration());\n    verify(mockPartitioner, times(1)).open(0, 1);\n\n    producer.invoke(\"foobar\", SinkContextUtil.forTimestamp(0));\n    verify(mockPartitioner, times(1))\n            .partition(\n                    \"foobar\",\n                    null,\n                    \"foobar\".getBytes(),\n                    DummyFlinkKafkaProducer.DUMMY_TOPIC,\n                    new int[] {0, 1, 2, 3});\n}", "summary_tokens": ["tests", "that", "partitions", "list", "is", "determinate", "and", "correctly", "provided", "to", "custom", "partitioner"], "project": "flink"}
{"id": 3753, "code": "public void testCorrectChoosing() {\n    try {\n\n        Plan plan = getTestPlanRightStatic(\"\");\n\n        SourceCollectorVisitor sourceCollector = new SourceCollectorVisitor();\n        plan.accept(sourceCollector);\n\n        for (GenericDataSourceBase<?, ?> s : sourceCollector.getSources()) {\n            if (s.getName().equals(\"bigFile\")) {\n                this.setSourceStatistics(s, 10000000, 1000);\n            } else if (s.getName().equals(\"smallFile\")) {\n                this.setSourceStatistics(s, 100, 100);\n            }\n        }\n\n        OptimizedPlan oPlan = compileNoStats(plan);\n\n        OptimizerPlanNodeResolver resolver = getOptimizerPlanNodeResolver(oPlan);\n        DualInputPlanNode innerJoin = resolver.getNode(\"DummyJoiner\");\n\n            \n        assertEquals(\n                DriverStrategy.HYBRIDHASH_BUILD_SECOND_CACHED, innerJoin.getDriverStrategy());\n        assertEquals(TempMode.NONE, innerJoin.getInput1().getTempMode());\n        assertEquals(TempMode.NONE, innerJoin.getInput2().getTempMode());\n\n        new JobGraphGenerator().compileJobGraph(oPlan);\n    } catch (Exception e) {\n        System.err.println(e.getMessage());\n        e.printStackTrace();\n        fail(\"Test errored: \" + e.getMessage());\n    }\n}", "summary_tokens": ["this", "test", "simulates", "a", "join", "of", "a", "big", "left", "side", "with", "a", "small", "right", "side", "inside", "of", "an", "iteration", "where", "the", "small", "side", "is", "on", "a", "static", "path"], "project": "flink"}
{"id": 7272, "code": "public <F> F clean(F f) {\n    if (getConfig().isClosureCleanerEnabled()) {\n        ClosureCleaner.clean(f, getConfig().getClosureCleanerLevel(), true);\n    }\n    ClosureCleaner.ensureSerializable(f);\n    return f;\n}", "summary_tokens": ["returns", "a", "closure", "cleaned", "version", "of", "the", "given", "function"], "project": "flink"}
{"id": 6604, "code": "public void testConcurrentModificationWithApplyToAllKeys() throws Exception {\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n\n    try {\n        ListStateDescriptor<String> listStateDescriptor =\n                new ListStateDescriptor<>(\"foo\", StringSerializer.INSTANCE);\n\n        ListState<String> listState =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE,\n                        VoidNamespaceSerializer.INSTANCE,\n                        listStateDescriptor);\n\n        for (int i = 0; i < 100; ++i) {\n            backend.setCurrentKey(i);\n            listState.add(\"Hello\" + i);\n        }\n\n            \n        backend.applyToAllKeys(\n                VoidNamespace.INSTANCE,\n                VoidNamespaceSerializer.INSTANCE,\n                listStateDescriptor,\n                new KeyedStateFunction<Integer, ListState<String>>() {\n                    @Override\n                    public void process(Integer key, ListState<String> state) throws Exception {\n                        assertEquals(\"Hello\" + key, state.get().iterator().next());\n                    }\n                });\n\n            \n        backend.applyToAllKeys(\n                VoidNamespace.INSTANCE,\n                VoidNamespaceSerializer.INSTANCE,\n                listStateDescriptor,\n                new KeyedStateFunction<Integer, ListState<String>>() {\n                    @Override\n                    public void process(Integer key, ListState<String> state) throws Exception {\n                        state.clear();\n                    }\n                });\n\n            \n        backend.applyToAllKeys(\n                VoidNamespace.INSTANCE,\n                VoidNamespaceSerializer.INSTANCE,\n                listStateDescriptor,\n                new KeyedStateFunction<Integer, ListState<String>>() {\n                    @Override\n                    public void process(Integer key, ListState<String> state) throws Exception {\n                        assertFalse(state.get().iterator().hasNext());\n                    }\n                });\n\n            \n        backend.applyToAllKeys(\n                VoidNamespace.INSTANCE,\n                VoidNamespaceSerializer.INSTANCE,\n                listStateDescriptor,\n                new KeyedStateFunction<Integer, ListState<String>>() {\n                    @Override\n                    public void process(Integer key, ListState<String> state) throws Exception {\n                        state.add(\"Hello\" + key);\n                        state.clear();\n                        state.add(\"Hello_\" + key);\n                    }\n                });\n\n            \n        backend.applyToAllKeys(\n                VoidNamespace.INSTANCE,\n                VoidNamespaceSerializer.INSTANCE,\n                listStateDescriptor,\n                new KeyedStateFunction<Integer, ListState<String>>() {\n                    @Override\n                    public void process(Integer key, ListState<String> state) throws Exception {\n                        final Iterator<String> it = state.get().iterator();\n                        assertEquals(\"Hello_\" + key, it.next());\n                        assertFalse(it.hasNext()); \n                    }\n                });\n    } finally {\n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["since", "abstract", "keyed", "state", "backend", "get", "keys", "string", "object", "does", "t", "support", "concurrent", "modification", "and", "abstract", "keyed", "state", "backend", "apply", "to", "all", "keys", "object", "type", "serializer", "state", "descriptor", "keyed", "state", "function", "rely", "on", "it", "to", "get", "keys", "from", "backend"], "project": "flink"}
{"id": 3740, "code": "private DistributionPattern connectJobVertices(\n        Channel channel,\n        int inputNumber,\n        final JobVertex sourceVertex,\n        final TaskConfig sourceConfig,\n        final JobVertex targetVertex,\n        final TaskConfig targetConfig,\n        boolean isBroadcast)\n        throws CompilerException {\n        \n    final DistributionPattern distributionPattern;\n\n    switch (channel.getShipStrategy()) {\n        case FORWARD:\n            distributionPattern = DistributionPattern.POINTWISE;\n            break;\n        case PARTITION_RANDOM:\n        case BROADCAST:\n        case PARTITION_HASH:\n        case PARTITION_CUSTOM:\n        case PARTITION_RANGE:\n        case PARTITION_FORCED_REBALANCE:\n            distributionPattern = DistributionPattern.ALL_TO_ALL;\n            break;\n        default:\n            throw new RuntimeException(\n                    \"Unknown runtime ship strategy: \" + channel.getShipStrategy());\n    }\n\n    final ResultPartitionType resultType;\n\n    switch (channel.getDataExchangeMode()) {\n        case PIPELINED:\n            resultType = ResultPartitionType.PIPELINED;\n            break;\n\n        case BATCH:\n                \n                \n                \n            resultType =\n                    channel.getSource().isOnDynamicPath()\n                            ? ResultPartitionType.PIPELINED\n                            : ResultPartitionType.BLOCKING;\n            break;\n\n        case PIPELINE_WITH_BATCH_FALLBACK:\n            throw new UnsupportedOperationException(\n                    \"Data exchange mode \"\n                            + channel.getDataExchangeMode()\n                            + \" currently not supported.\");\n\n        default:\n            throw new UnsupportedOperationException(\"Unknown data exchange mode.\");\n    }\n\n    JobEdge edge =\n            targetVertex.connectNewDataSetAsInput(\n                    sourceVertex, distributionPattern, resultType);\n\n        \n        \n    final int outputIndex = sourceConfig.getNumOutputs();\n    sourceConfig.addOutputShipStrategy(channel.getShipStrategy());\n    if (outputIndex == 0) {\n        sourceConfig.setOutputSerializer(channel.getSerializer());\n    }\n    if (channel.getShipStrategyComparator() != null) {\n        sourceConfig.setOutputComparator(channel.getShipStrategyComparator(), outputIndex);\n    }\n\n    if (channel.getShipStrategy() == ShipStrategyType.PARTITION_RANGE) {\n\n        final DataDistribution dataDistribution = channel.getDataDistribution();\n        if (dataDistribution != null) {\n            sourceConfig.setOutputDataDistribution(dataDistribution, outputIndex);\n        } else {\n            throw new RuntimeException(\"Range partitioning requires data distribution.\");\n        }\n    }\n\n    if (channel.getShipStrategy() == ShipStrategyType.PARTITION_CUSTOM) {\n        if (channel.getPartitioner() != null) {\n            sourceConfig.setOutputPartitioner(channel.getPartitioner(), outputIndex);\n        } else {\n            throw new CompilerException(\n                    \"The ship strategy was set to custom partitioning, but no partitioner was set.\");\n        }\n    }\n\n        \n    if (isBroadcast) {\n        targetConfig.addBroadcastInputToGroup(inputNumber);\n    } else {\n        targetConfig.addInputToGroup(inputNumber);\n    }\n\n        \n\n    String shipStrategy = JsonMapper.getShipStrategyString(channel.getShipStrategy());\n    if (channel.getShipStrategyKeys() != null && channel.getShipStrategyKeys().size() > 0) {\n        shipStrategy +=\n                \" on \"\n                        + (channel.getShipStrategySortOrder() == null\n                                ? channel.getShipStrategyKeys().toString()\n                                : Utils.createOrdering(\n                                                channel.getShipStrategyKeys(),\n                                                channel.getShipStrategySortOrder())\n                                        .toString());\n    }\n\n    String localStrategy;\n    if (channel.getLocalStrategy() == null\n            || channel.getLocalStrategy() == LocalStrategy.NONE) {\n        localStrategy = null;\n    } else {\n        localStrategy = JsonMapper.getLocalStrategyString(channel.getLocalStrategy());\n        if (localStrategy != null\n                && channel.getLocalStrategyKeys() != null\n                && channel.getLocalStrategyKeys().size() > 0) {\n            localStrategy +=\n                    \" on \"\n                            + (channel.getLocalStrategySortOrder() == null\n                                    ? channel.getLocalStrategyKeys().toString()\n                                    : Utils.createOrdering(\n                                                    channel.getLocalStrategyKeys(),\n                                                    channel.getLocalStrategySortOrder())\n                                            .toString());\n        }\n    }\n\n    String caching =\n            channel.getTempMode() == TempMode.NONE ? null : channel.getTempMode().toString();\n\n    edge.setShipStrategyName(shipStrategy);\n    edge.setPreProcessingOperationName(localStrategy);\n    edge.setOperatorLevelCachingDescription(caching);\n\n    return distributionPattern;\n}", "summary_tokens": ["note", "the", "channel", "for", "global", "and", "local", "strategies", "are", "different", "if", "we", "connect", "a", "union"], "project": "flink"}
{"id": 275, "code": "private boolean watermarkHasPassedWithDelay(\n        long watermark, LocalDateTime partitionTime, long commitDelay) {\n        \n        \n    long epochPartTime = partitionTime.atZone(watermarkTimeZone).toInstant().toEpochMilli();\n    return watermark > epochPartTime + commitDelay;\n}", "summary_tokens": ["returns", "the", "watermark", "has", "passed", "the", "partition", "time", "or", "not", "if", "true", "means", "it", "s", "time", "to", "commit", "the", "partition"], "project": "flink"}
{"id": 1634, "code": "public void setString(ConfigOption<String> key, String value) {\n    setValueInternal(key.key(), value);\n}", "summary_tokens": ["adds", "the", "given", "value", "to", "the", "configuration", "object"], "project": "flink"}
{"id": 8296, "code": "static StringData fromString(String str) {\n    return BinaryStringData.fromString(str);\n}", "summary_tokens": ["creates", "an", "instance", "of", "string", "data", "from", "the", "given", "string"], "project": "flink"}
{"id": 5265, "code": "default boolean acceptsFileUploads() {\n    return false;\n}", "summary_tokens": ["returns", "whether", "this", "header", "allows", "file", "uploads"], "project": "flink"}
{"id": 872, "code": "public void testAtLeastOnceProducer() throws Throwable {\n    final DummyFlinkKinesisProducer<String> producer =\n            new DummyFlinkKinesisProducer<>(new SimpleStringSchema());\n\n    OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer));\n\n    testHarness.open();\n\n    testHarness.processElement(new StreamRecord<>(\"msg-1\"));\n    testHarness.processElement(new StreamRecord<>(\"msg-2\"));\n    testHarness.processElement(new StreamRecord<>(\"msg-3\"));\n\n        \n    CheckedThread snapshotThread =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                        \n                        \n                        \n                    testHarness.snapshot(123L, 123L);\n                }\n            };\n    snapshotThread.start();\n\n        \n        \n        \n    producer.waitUntilFlushStarted();\n    Assert.assertTrue(\n            \"Snapshot returned before all records were flushed\", snapshotThread.isAlive());\n\n        \n    UserRecordResult result = mock(UserRecordResult.class);\n    when(result.isSuccessful()).thenReturn(true);\n\n    producer.getPendingRecordFutures().get(0).set(result);\n    Assert.assertTrue(\n            \"Snapshot returned before all records were flushed\", snapshotThread.isAlive());\n\n    producer.getPendingRecordFutures().get(1).set(result);\n    Assert.assertTrue(\n            \"Snapshot returned before all records were flushed\", snapshotThread.isAlive());\n\n    producer.getPendingRecordFutures().get(2).set(result);\n\n        \n        \n    snapshotThread.sync();\n\n    testHarness.close();\n}", "summary_tokens": ["test", "ensuring", "that", "the", "producer", "is", "not", "dropping", "buffered", "records", "we", "set", "a", "timeout", "because", "the", "test", "will", "not", "finish", "if", "the", "logic", "is", "broken"], "project": "flink"}
{"id": 9617, "code": "public void testWatermarkEmissionWithChaining() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment(1);\n    env.getConfig().setAutoWatermarkInterval(WATERMARK_INTERVAL_MILLIS);\n    SharedReference<CountDownLatch> latch =\n            sharedObjects.add(new CountDownLatch(EXPECTED_WATERMARKS));\n    checkState(env.isChainingEnabled());\n    env.createInput(new InfiniteIntegerInputFormat(true))\n            .assignTimestampsAndWatermarks(\n                    WatermarkStrategy.<Integer>forMonotonousTimestamps()\n                            .withTimestampAssigner(context -> getExtractorAssigner()))\n            .addSink(getWatermarkCounter(latch));\n    env.executeAsync();\n    latch.get().await();\n}", "summary_tokens": ["adds", "an", "infinite", "split", "that", "causes", "the", "input", "of", "org"], "project": "flink"}
{"id": 2795, "code": "public O name(String newName) {\n    this.name = newName;\n    @SuppressWarnings(\"unchecked\")\n    O returnType = (O) this;\n    return returnType;\n}", "summary_tokens": ["sets", "the", "name", "of", "this", "operator"], "project": "flink"}
{"id": 9021, "code": "public ChangelogMode toChangelogMode() {\n    ChangelogMode.Builder builder = ChangelogMode.newBuilder();\n    if (this.contains(ModifyKind.INSERT)) {\n        builder.addContainedKind(RowKind.INSERT);\n    }\n    if (this.contains(ModifyKind.UPDATE)) {\n        builder.addContainedKind(RowKind.UPDATE_BEFORE);\n        builder.addContainedKind(RowKind.UPDATE_AFTER);\n    }\n    if (this.contains(ModifyKind.DELETE)) {\n        builder.addContainedKind(RowKind.DELETE);\n    }\n    return builder.build();\n}", "summary_tokens": ["returns", "the", "default", "changelog", "mode", "from", "this", "modify", "kind", "set"], "project": "flink"}
{"id": 6883, "code": "public void setWriteBatchSize(long writeBatchSize) {\n    checkArgument(writeBatchSize >= 0, \"Write batch size have to be no negative.\");\n    this.writeBatchSize = writeBatchSize;\n}", "summary_tokens": ["sets", "the", "max", "batch", "size", "will", "be", "used", "in", "rocks", "dbwrite", "batch", "wrapper", "no", "positive", "value", "will", "disable", "memory", "size", "controller", "just", "use", "item", "count", "controller"], "project": "flink"}
{"id": 4144, "code": "static Throwable readExceptionFromStream(InputStream in) throws IOException {\n    int len = readLength(in);\n    byte[] bytes = new byte[len];\n    readFully(in, bytes, 0, len, \"Error message\");\n\n    try {\n        return (Throwable)\n                InstantiationUtil.deserializeObject(bytes, ClassLoader.getSystemClassLoader());\n    } catch (ClassNotFoundException e) {\n            \n        throw new IOException(\"Could not transfer error message\", e);\n    }\n}", "summary_tokens": ["reads", "exception", "from", "given", "input", "stream"], "project": "flink"}
{"id": 3077, "code": "public Pattern<T, F> within(Time windowTime) {\n    if (windowTime != null) {\n        this.windowTime = windowTime;\n    }\n\n    return this;\n}", "summary_tokens": ["defines", "the", "maximum", "time", "interval", "in", "which", "a", "matching", "pattern", "has", "to", "be", "completed", "in", "order", "to", "be", "considered", "valid"], "project": "flink"}
{"id": 3554, "code": "public void testHistogramReporting() throws Exception {\n    String histogramName = \"histogram\";\n\n    final JMXReporter reporter = new JMXReporter(null);\n\n    TestHistogram histogram = new TestHistogram();\n\n    reporter.notifyOfAddedMetric(histogram, histogramName, metricGroup);\n\n    MBeanServer mBeanServer = ManagementFactory.getPlatformMBeanServer();\n\n    ObjectName objectName =\n            new ObjectName(\n                    JMX_DOMAIN_PREFIX + \"taskmanager.\" + histogramName,\n                    JMXReporter.generateJmxTable(metricGroup.getAllVariables()));\n\n    MBeanInfo info = mBeanServer.getMBeanInfo(objectName);\n\n    MBeanAttributeInfo[] attributeInfos = info.getAttributes();\n\n    assertEquals(11, attributeInfos.length);\n\n    assertEquals(histogram.getCount(), mBeanServer.getAttribute(objectName, \"Count\"));\n    HistogramStatistics statistics = histogram.getStatistics();\n    assertEquals(statistics.getMean(), mBeanServer.getAttribute(objectName, \"Mean\"));\n    assertEquals(statistics.getStdDev(), mBeanServer.getAttribute(objectName, \"StdDev\"));\n    assertEquals(statistics.getMax(), mBeanServer.getAttribute(objectName, \"Max\"));\n    assertEquals(statistics.getMin(), mBeanServer.getAttribute(objectName, \"Min\"));\n    assertEquals(statistics.getQuantile(0.5), mBeanServer.getAttribute(objectName, \"Median\"));\n    assertEquals(\n            statistics.getQuantile(0.75),\n            mBeanServer.getAttribute(objectName, \"75thPercentile\"));\n    assertEquals(\n            statistics.getQuantile(0.95),\n            mBeanServer.getAttribute(objectName, \"95thPercentile\"));\n    assertEquals(\n            statistics.getQuantile(0.98),\n            mBeanServer.getAttribute(objectName, \"98thPercentile\"));\n    assertEquals(\n            statistics.getQuantile(0.99),\n            mBeanServer.getAttribute(objectName, \"99thPercentile\"));\n    assertEquals(\n            statistics.getQuantile(0.999),\n            mBeanServer.getAttribute(objectName, \"999thPercentile\"));\n}", "summary_tokens": ["tests", "that", "histograms", "are", "properly", "reported", "via", "the", "jmxreporter"], "project": "flink"}
{"id": 310, "code": "public static Configuration deserializeConfiguration(\n        byte[] serializedConfig, Configuration targetConfig) {\n    if (null == targetConfig) {\n        targetConfig = new Configuration();\n    }\n    try {\n        deserializeWritable(targetConfig, serializedConfig);\n    } catch (IOException e) {\n        throw new RuntimeException(\n                \"Encounter an IOException when deserialize the Configuration.\", e);\n    }\n    return targetConfig;\n}", "summary_tokens": ["deserialize", "a", "hadoop", "configuration", "from", "byte"], "project": "flink"}
{"id": 9633, "code": "public void testWatermarkForwarding() throws Exception {\n    final OutputTag<String> sideOutputTag1 = new OutputTag<String>(\"side\") {};\n    final OutputTag<String> sideOutputTag2 = new OutputTag<String>(\"other-side\") {};\n\n    TestListResultSink<String> sideOutputResultSink1 = new TestListResultSink<>();\n    TestListResultSink<String> sideOutputResultSink2 = new TestListResultSink<>();\n    TestListResultSink<String> resultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(3);\n\n    DataStream<Integer> dataStream =\n            env.addSource(\n                    new SourceFunction<Integer>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public void run(SourceContext<Integer> ctx) throws Exception {\n                            ctx.collectWithTimestamp(1, 0);\n                            ctx.emitWatermark(new Watermark(0));\n                            ctx.collectWithTimestamp(2, 1);\n                            ctx.collectWithTimestamp(5, 2);\n                            ctx.emitWatermark(new Watermark(2));\n                            ctx.collectWithTimestamp(3, 3);\n                            ctx.collectWithTimestamp(4, 4);\n                        }\n\n                        @Override\n                        public void cancel() {}\n                    });\n\n    SingleOutputStreamOperator<Integer> passThroughtStream =\n            dataStream.process(\n                    new ProcessFunction<Integer, Integer>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public void processElement(\n                                Integer value, Context ctx, Collector<Integer> out)\n                                throws Exception {\n                            out.collect(value);\n                            ctx.output(sideOutputTag1, \"sideout-\" + String.valueOf(value));\n                        }\n                    });\n\n    class WatermarkReifier extends AbstractStreamOperator<String>\n            implements OneInputStreamOperator<String, String> {\n        private static final long serialVersionUID = 1L;\n\n        @Override\n        public void processElement(StreamRecord<String> element) throws Exception {\n            output.collect(new StreamRecord<>(\"E:\" + element.getValue()));\n        }\n\n        @Override\n        public void processWatermark(Watermark mark) throws Exception {\n            super.processWatermark(mark);\n            output.collect(new StreamRecord<>(\"WM:\" + mark.getTimestamp()));\n        }\n    }\n\n    passThroughtStream\n            .getSideOutput(sideOutputTag1)\n            .transform(\n                    \"ReifyWatermarks\", BasicTypeInfo.STRING_TYPE_INFO, new WatermarkReifier())\n            .addSink(sideOutputResultSink1);\n\n    passThroughtStream\n            .getSideOutput(sideOutputTag2)\n            .transform(\n                    \"ReifyWatermarks\", BasicTypeInfo.STRING_TYPE_INFO, new WatermarkReifier())\n            .addSink(sideOutputResultSink2);\n\n    passThroughtStream\n            .map(\n                    new MapFunction<Integer, String>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public String map(Integer value) throws Exception {\n                            return value.toString();\n                        }\n                    })\n            .transform(\n                    \"ReifyWatermarks\", BasicTypeInfo.STRING_TYPE_INFO, new WatermarkReifier())\n            .addSink(resultSink);\n\n    env.execute();\n\n    assertEquals(\n            Arrays.asList(\n                    \"E:sideout-1\",\n                    \"E:sideout-2\",\n                    \"E:sideout-3\",\n                    \"E:sideout-4\",\n                    \"E:sideout-5\",\n                    \"WM:0\",\n                    \"WM:0\",\n                    \"WM:0\",\n                    \"WM:2\",\n                    \"WM:2\",\n                    \"WM:2\",\n                    \"WM:\" + Long.MAX_VALUE,\n                    \"WM:\" + Long.MAX_VALUE,\n                    \"WM:\" + Long.MAX_VALUE),\n            sideOutputResultSink1.getSortedResult());\n\n    assertEquals(\n            Arrays.asList(\n                    \"E:sideout-1\",\n                    \"E:sideout-2\",\n                    \"E:sideout-3\",\n                    \"E:sideout-4\",\n                    \"E:sideout-5\",\n                    \"WM:0\",\n                    \"WM:0\",\n                    \"WM:0\",\n                    \"WM:2\",\n                    \"WM:2\",\n                    \"WM:2\",\n                    \"WM:\" + Long.MAX_VALUE,\n                    \"WM:\" + Long.MAX_VALUE,\n                    \"WM:\" + Long.MAX_VALUE),\n            sideOutputResultSink1.getSortedResult());\n\n    assertEquals(\n            Arrays.asList(\n                    \"E:1\",\n                    \"E:2\",\n                    \"E:3\",\n                    \"E:4\",\n                    \"E:5\",\n                    \"WM:0\",\n                    \"WM:0\",\n                    \"WM:0\",\n                    \"WM:2\",\n                    \"WM:2\",\n                    \"WM:2\",\n                    \"WM:\" + Long.MAX_VALUE,\n                    \"WM:\" + Long.MAX_VALUE,\n                    \"WM:\" + Long.MAX_VALUE),\n            resultSink.getSortedResult());\n}", "summary_tokens": ["verify", "that", "watermarks", "are", "forwarded", "to", "all", "side", "outputs"], "project": "flink"}
{"id": 3059, "code": "public void advanceTime(long timestamp) throws Exception {\n    sharedBuffer.advanceTime(timestamp);\n}", "summary_tokens": ["notifies", "shared", "buffer", "that", "there", "will", "be", "no", "events", "with", "timestamp", "lt", "eq", "the", "given", "value"], "project": "flink"}
{"id": 1808, "code": "public boolean equalTo(MemorySegment seg2, int offset1, int offset2, int length) {\n    int i = 0;\n\n        \n        \n    while (i <= length - 8) {\n        if (getLong(offset1 + i) != seg2.getLong(offset2 + i)) {\n            return false;\n        }\n        i += 8;\n    }\n\n        \n    while (i < length) {\n        if (get(offset1 + i) != seg2.get(offset2 + i)) {\n            return false;\n        }\n        i += 1;\n    }\n\n    return true;\n}", "summary_tokens": ["equals", "two", "memory", "segment", "regions"], "project": "flink"}
{"id": 1838, "code": "public final boolean isLeft() {\n    return getClass() == Left.class;\n}", "summary_tokens": ["true", "if", "this", "is", "a", "left", "value", "false", "if", "this", "is", "a", "right", "value"], "project": "flink"}
{"id": 9721, "code": "public static void deleteApplicationFiles(final String applicationFilesDir) {\n    if (!StringUtils.isNullOrWhitespaceOnly(applicationFilesDir)) {\n        final org.apache.flink.core.fs.Path path =\n                new org.apache.flink.core.fs.Path(applicationFilesDir);\n        try {\n            final org.apache.flink.core.fs.FileSystem fileSystem = path.getFileSystem();\n            if (!fileSystem.delete(path, true)) {\n                LOG.error(\n                        \"Deleting yarn application files under {} was unsuccessful.\",\n                        applicationFilesDir);\n            }\n        } catch (final IOException e) {\n            LOG.error(\n                    \"Could not properly delete yarn application files directory {}.\",\n                    applicationFilesDir,\n                    e);\n        }\n    } else {\n        LOG.debug(\n                \"No yarn application files directory set. Therefore, cannot clean up the data.\");\n    }\n}", "summary_tokens": ["deletes", "the", "yarn", "application", "files", "e"], "project": "flink"}
{"id": 1772, "code": "public char getCharBigEndian(int index) {\n    if (LITTLE_ENDIAN) {\n        return Character.reverseBytes(getChar(index));\n    } else {\n        return getChar(index);\n    }\n}", "summary_tokens": ["reads", "a", "character", "value", "0", "bit", "0", "bytes", "from", "the", "given", "position", "in", "big", "endian", "byte", "order"], "project": "flink"}
{"id": 7451, "code": "public static SlidingProcessingTimeWindows of(Time size, Time slide, Time offset) {\n    return new SlidingProcessingTimeWindows(\n            size.toMilliseconds(), slide.toMilliseconds(), offset.toMilliseconds());\n}", "summary_tokens": ["creates", "a", "new", "sliding", "processing", "time", "windows", "window", "assigner", "that", "assigns", "elements", "to", "time", "windows", "based", "on", "the", "element", "timestamp", "and", "offset"], "project": "flink"}
{"id": 6877, "code": "public void setPriorityQueueStateType(PriorityQueueStateType priorityQueueStateType) {\n    this.priorityQueueStateType = checkNotNull(priorityQueueStateType);\n}", "summary_tokens": ["sets", "the", "type", "of", "the", "priority", "queue", "state"], "project": "flink"}
{"id": 5414, "code": "public static SnapshotDirectory temporary(@Nonnull File directory) throws IOException {\n    return new TemporarySnapshotDirectory(directory);\n}", "summary_tokens": ["creates", "a", "local", "temporary", "snapshot", "directory", "for", "the", "given", "path"], "project": "flink"}
{"id": 7528, "code": "public StreamRecord<T> getStreamRecord() {\n    StreamRecord<T> streamRecord = new StreamRecord<>(value);\n    if (hasTimestamp) {\n        streamRecord.setTimestamp(timestamp);\n    }\n    return streamRecord;\n}", "summary_tokens": ["creates", "a", "stream", "record", "from", "this", "timestamped", "value"], "project": "flink"}
{"id": 5787, "code": "public void testBlobNoJobFetchWithTooManyFailures() throws IOException {\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    testBlobFetchWithTooManyFailures(config, new VoidBlobStore(), null, TRANSIENT_BLOB);\n}", "summary_tokens": ["a", "test", "where", "the", "connection", "fails", "too", "often", "and", "eventually", "fails", "the", "get", "request", "job", "unrelated", "blob"], "project": "flink"}
{"id": 3437, "code": "public static DataSet<Edge<Long, Long>> getLongLongEdgeDataDifference(\n        ExecutionEnvironment env) {\n    return env.fromCollection(getLongLongEdgesForDifference());\n}", "summary_tokens": ["utils", "for", "getting", "the", "second", "graph", "for", "the", "test", "of", "method", "difference"], "project": "flink"}
{"id": 7467, "code": "public static Time days(long days) {\n    return of(days, TimeUnit.DAYS);\n}", "summary_tokens": ["creates", "a", "new", "time", "that", "represents", "the", "given", "number", "of", "days"], "project": "flink"}
{"id": 8223, "code": "public static MetadataColumn metadata(\n        String name, DataType dataType, @Nullable String metadataKey, boolean isVirtual) {\n    Preconditions.checkNotNull(name, \"Column name can not be null.\");\n    Preconditions.checkNotNull(dataType, \"Column data type can not be null.\");\n    return new MetadataColumn(name, dataType, metadataKey, isVirtual);\n}", "summary_tokens": ["creates", "a", "metadata", "column", "from", "metadata", "of", "the", "given", "column", "name", "or", "from", "metadata", "of", "the", "given", "key", "if", "not", "null"], "project": "flink"}
{"id": 2761, "code": "public DataSet<ST> closeWith(DataSet<ST> solutionSetDelta, DataSet<WT> newWorkset) {\n    return new DeltaIterationResultSet<ST, WT>(\n            initialSolutionSet.getExecutionEnvironment(),\n            initialSolutionSet.getType(),\n            initialWorkset.getType(),\n            this,\n            solutionSetDelta,\n            newWorkset,\n            keys,\n            maxIterations);\n}", "summary_tokens": ["closes", "the", "delta", "iteration"], "project": "flink"}
{"id": 5379, "code": "public static int computeKeyGroupForKeyHash(int keyHash, int maxParallelism) {\n    return MathUtils.murmurHash(keyHash) % maxParallelism;\n}", "summary_tokens": ["assigns", "the", "given", "key", "to", "a", "key", "group", "index"], "project": "flink"}
{"id": 9137, "code": "public static String splitIndex(String str, int character, int index) {\n    if (character > 255 || character < 1 || index < 0) {\n        return null;\n    }\n    String[] values = StringUtils.splitPreserveAllTokens(str, (char) character);\n    if (index >= values.length) {\n        return null;\n    } else {\n        return values[index];\n    }\n}", "summary_tokens": ["split", "target", "string", "with", "custom", "separator", "and", "pick", "the", "index", "th", "start", "with", "0", "result"], "project": "flink"}
{"id": 4903, "code": "public static String asVariable(String scope) {\n    return SCOPE_VARIABLE_PREFIX + scope + SCOPE_VARIABLE_SUFFIX;\n}", "summary_tokens": ["formats", "the", "given", "string", "to", "resemble", "a", "scope", "variable"], "project": "flink"}
{"id": 4186, "code": "public static CheckpointProperties forCheckpoint(CheckpointRetentionPolicy policy) {\n    switch (policy) {\n        case NEVER_RETAIN_AFTER_TERMINATION:\n            return CHECKPOINT_NEVER_RETAINED;\n        case RETAIN_ON_FAILURE:\n            return CHECKPOINT_RETAINED_ON_FAILURE;\n        case RETAIN_ON_CANCELLATION:\n            return CHECKPOINT_RETAINED_ON_CANCELLATION;\n        default:\n            throw new IllegalArgumentException(\"unknown policy: \" + policy);\n    }\n}", "summary_tokens": ["creates", "the", "checkpoint", "properties", "for", "a", "checkpoint"], "project": "flink"}
{"id": 4387, "code": "public void jobVertexFinished() {\n    assertRunningInJobMasterMainThread();\n    final int numFinished = ++numFinishedJobVertices;\n    if (numFinished == numJobVerticesTotal) {\n            \n\n            \n        if (state == JobStatus.RUNNING) {\n                \n                \n\n            try {\n                for (ExecutionJobVertex ejv : verticesInCreationOrder) {\n                    ejv.getJobVertex().finalizeOnMaster(getUserClassLoader());\n                }\n            } catch (Throwable t) {\n                ExceptionUtils.rethrowIfFatalError(t);\n                ClusterEntryPointExceptionUtils.tryEnrichClusterEntryPointError(t);\n                failGlobal(new Exception(\"Failed to finalize execution on master\", t));\n                return;\n            }\n\n                \n                \n            if (transitionState(JobStatus.RUNNING, JobStatus.FINISHED)) {\n                onTerminalState(JobStatus.FINISHED);\n            }\n        }\n    }\n}", "summary_tokens": ["called", "whenever", "a", "job", "vertex", "reaches", "state", "finished", "completed", "successfully"], "project": "flink"}
{"id": 755, "code": "public void shutdownFetcher() {\n    LOG.info(\n            \"Starting shutdown of shard consumer threads and AWS SDK resources of subtask {} ...\",\n            indexOfThisConsumerSubtask,\n            error.get());\n\n    running = false;\n    try {\n        try {\n            deregisterStreamConsumer();\n        } catch (Exception e) {\n            LOG.warn(\"Encountered exception deregistering stream consumers\", e);\n        }\n\n        try {\n            closeRecordPublisherFactory();\n        } catch (Exception e) {\n            LOG.warn(\"Encountered exception closing record publisher factory\", e);\n        }\n    } finally {\n        shardConsumersExecutor.shutdownNow();\n\n        cancelFuture.complete(null);\n\n        if (watermarkTracker != null) {\n            watermarkTracker.close();\n        }\n        this.recordEmitter.stop();\n    }\n\n    LOG.info(\n            \"Shutting down the shard consumer threads of subtask {} ...\",\n            indexOfThisConsumerSubtask);\n}", "summary_tokens": ["starts", "shutting", "down", "the", "fetcher"], "project": "flink"}
{"id": 6274, "code": "public void testExecutionDeploymentReconciliation() throws Exception {\n    JobMasterBuilder.TestingOnCompletionActions onCompletionActions =\n            new JobMasterBuilder.TestingOnCompletionActions();\n\n    TestingExecutionDeploymentTrackerWrapper deploymentTrackerWrapper =\n            new TestingExecutionDeploymentTrackerWrapper();\n    final JobGraph jobGraph = JobGraphTestUtils.singleNoOpJobGraph();\n    JobMaster jobMaster =\n            createAndStartJobMaster(onCompletionActions, deploymentTrackerWrapper, jobGraph);\n    JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class);\n    RPC_SERVICE_RESOURCE\n            .getTestingRpcService()\n            .registerGateway(jobMasterGateway.getAddress(), jobMasterGateway);\n\n    final CompletableFuture<ExecutionAttemptID> taskCancellationFuture =\n            new CompletableFuture<>();\n    TaskExecutorGateway taskExecutorGateway = createTaskExecutorGateway(taskCancellationFuture);\n    LocalUnresolvedTaskManagerLocation localUnresolvedTaskManagerLocation =\n            new LocalUnresolvedTaskManagerLocation();\n\n    registerTaskExecutorAndOfferSlots(\n            jobMasterGateway,\n            jobGraph.getJobID(),\n            taskExecutorGateway,\n            localUnresolvedTaskManagerLocation);\n\n    ExecutionAttemptID deployedExecution =\n            deploymentTrackerWrapper.getTaskDeploymentFuture().get();\n    assertFalse(taskCancellationFuture.isDone());\n\n    ExecutionAttemptID unknownDeployment = new ExecutionAttemptID();\n        \n        \n        \n    jobMasterGateway.heartbeatFromTaskManager(\n            localUnresolvedTaskManagerLocation.getResourceID(),\n            new TaskExecutorToJobManagerHeartbeatPayload(\n                    new AccumulatorReport(Collections.emptyList()),\n                    new ExecutionDeploymentReport(Collections.singleton(unknownDeployment))));\n\n    assertThat(taskCancellationFuture.get(), is(unknownDeployment));\n    assertThat(deploymentTrackerWrapper.getStopFuture().get(), is(deployedExecution));\n\n    assertThat(\n            onCompletionActions\n                    .getJobReachedGloballyTerminalStateFuture()\n                    .get()\n                    .getArchivedExecutionGraph()\n                    .getState(),\n            is(JobStatus.FAILED));\n}", "summary_tokens": ["tests", "how", "the", "job", "master", "handles", "unknown", "missing", "executions"], "project": "flink"}
{"id": 4932, "code": "public void invoke() throws Exception {\n        \n        \n        \n    if (LOG.isDebugEnabled()) {\n        LOG.debug(formatLogString(\"Start registering input and output.\"));\n    }\n\n        \n    Configuration taskConf = getTaskConfiguration();\n    this.config = new TaskConfig(taskConf);\n\n        \n    final Class<? extends Driver<S, OT>> driverClass = this.config.getDriver();\n    this.driver = InstantiationUtil.instantiate(driverClass, Driver.class);\n\n    String headName = getEnvironment().getTaskInfo().getTaskName().split(\"->\")[0].trim();\n    this.metrics =\n            getEnvironment()\n                    .getMetricGroup()\n                    .getOrAddOperator(\n                            headName.startsWith(\"CHAIN\") ? headName.substring(6) : headName);\n    this.metrics.getIOMetricGroup().reuseInputMetricsForTask();\n    if (config.getNumberOfChainedStubs() == 0) {\n        this.metrics.getIOMetricGroup().reuseOutputMetricsForTask();\n    }\n\n        \n        \n    initInputReaders();\n    initBroadcastInputReaders();\n\n        \n    initOutputs();\n\n    if (LOG.isDebugEnabled()) {\n        LOG.debug(formatLogString(\"Finished registering input and output.\"));\n    }\n\n        \n        \n        \n    if (LOG.isDebugEnabled()) {\n        LOG.debug(formatLogString(\"Start task code.\"));\n    }\n\n    this.runtimeUdfContext = createRuntimeContext(metrics);\n\n        \n        \n        \n        \n        \n        \n    try {\n            \n            \n            \n        try {\n            int numInputs = driver.getNumberOfInputs();\n            int numComparators = driver.getNumberOfDriverComparators();\n            int numBroadcastInputs = this.config.getNumBroadcastInputs();\n\n            initInputsSerializersAndComparators(numInputs, numComparators);\n            initBroadcastInputsSerializers(numBroadcastInputs);\n\n                \n            {\n                List<Integer> iterativeInputs = new ArrayList<>();\n\n                for (int i = 0; i < numInputs; i++) {\n                    final int numberOfEventsUntilInterrupt =\n                            getTaskConfig().getNumberOfEventsUntilInterruptInIterativeGate(i);\n\n                    if (numberOfEventsUntilInterrupt < 0) {\n                        throw new IllegalArgumentException();\n                    } else if (numberOfEventsUntilInterrupt > 0) {\n                        this.inputReaders[i].setIterativeReader();\n                        iterativeInputs.add(i);\n\n                        if (LOG.isDebugEnabled()) {\n                            LOG.debug(\n                                    formatLogString(\n                                            \"Input [\"\n                                                    + i\n                                                    + \"] reads in supersteps with [\"\n                                                    + numberOfEventsUntilInterrupt\n                                                    + \"] event(s) till next superstep.\"));\n                        }\n                    }\n                }\n                this.iterativeInputs = asArray(iterativeInputs);\n            }\n\n            {\n                List<Integer> iterativeBcInputs = new ArrayList<>();\n\n                for (int i = 0; i < numBroadcastInputs; i++) {\n                    final int numberOfEventsUntilInterrupt =\n                            getTaskConfig()\n                                    .getNumberOfEventsUntilInterruptInIterativeBroadcastGate(i);\n\n                    if (numberOfEventsUntilInterrupt < 0) {\n                        throw new IllegalArgumentException();\n                    } else if (numberOfEventsUntilInterrupt > 0) {\n                        this.broadcastInputReaders[i].setIterativeReader();\n                        iterativeBcInputs.add(i);\n\n                        if (LOG.isDebugEnabled()) {\n                            LOG.debug(\n                                    formatLogString(\n                                            \"Broadcast input [\"\n                                                    + i\n                                                    + \"] reads in supersteps with [\"\n                                                    + numberOfEventsUntilInterrupt\n                                                    + \"] event(s) till next superstep.\"));\n                        }\n                    }\n                }\n                this.iterativeBroadcastInputs = asArray(iterativeBcInputs);\n            }\n\n            initLocalStrategies(numInputs);\n        } catch (Exception e) {\n            throw new RuntimeException(\n                    \"Initializing the input processing failed\"\n                            + (e.getMessage() == null ? \".\" : \": \" + e.getMessage()),\n                    e);\n        }\n\n        if (!this.running) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(formatLogString(\"Task cancelled before task code was started.\"));\n            }\n            return;\n        }\n\n            \n        initialize();\n\n            \n        for (int i = 0; i < this.config.getNumBroadcastInputs(); i++) {\n            final String name = this.config.getBroadcastInputName(i);\n            readAndSetBroadcastInput(\n                    i, name, this.runtimeUdfContext, 1 );\n        }\n\n            \n        run();\n    } finally {\n            \n        closeLocalStrategiesAndCaches();\n\n        clearReaders(inputReaders);\n        clearWriters(eventualOutputs);\n    }\n\n    if (this.running) {\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(formatLogString(\"Finished task code.\"));\n        }\n    } else {\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(formatLogString(\"Task code cancelled.\"));\n        }\n    }\n}", "summary_tokens": ["the", "main", "work", "method"], "project": "flink"}
{"id": 8987, "code": "protected Tuple2<SupportsFilterPushDown.Result, TableSourceTable>\n        resolveFiltersAndCreateTableSourceTable(\n                RexNode[] convertiblePredicates,\n                TableSourceTable oldTableSourceTable,\n                TableScan scan,\n                RelBuilder relBuilder) {\n        \n    int originPredicatesSize = convertiblePredicates.length;\n\n        \n    DynamicTableSource newTableSource = oldTableSourceTable.tableSource().copy();\n\n    SupportsFilterPushDown.Result result =\n            FilterPushDownSpec.apply(\n                    Arrays.asList(convertiblePredicates),\n                    newTableSource,\n                    SourceAbilityContext.from(scan));\n\n    relBuilder.push(scan);\n    List<RexNode> acceptedPredicates =\n            convertExpressionToRexNode(result.getAcceptedFilters(), relBuilder);\n    FilterPushDownSpec filterPushDownSpec = new FilterPushDownSpec(acceptedPredicates);\n\n        \n    int updatedPredicatesSize = result.getRemainingFilters().size();\n        \n    TableSourceTable newTableSourceTable =\n            oldTableSourceTable.copy(\n                    newTableSource,\n                    getNewFlinkStatistic(\n                            oldTableSourceTable, originPredicatesSize, updatedPredicatesSize),\n                    new SourceAbilitySpec[] {filterPushDownSpec});\n\n    return new Tuple2<>(result, newTableSourceTable);\n}", "summary_tokens": ["resolves", "filters", "using", "the", "underlying", "sources", "supports", "filter", "push", "down", "and", "creates", "a", "new", "table", "source", "table", "with", "the", "supplied", "predicates"], "project": "flink"}
{"id": 5284, "code": "private static VertexParallelismStore computeVertexParallelismStore(\n        JobGraph jobGraph, SchedulerExecutionMode executionMode) {\n    if (executionMode == SchedulerExecutionMode.REACTIVE) {\n        return computeReactiveModeVertexParallelismStore(\n                jobGraph.getVertices(), SchedulerBase::getDefaultMaxParallelism, true);\n    }\n    return SchedulerBase.computeVertexParallelismStore(jobGraph);\n}", "summary_tokens": ["creates", "the", "parallelism", "store", "that", "should", "be", "used", "for", "determining", "scheduling", "requirements", "which", "may", "choose", "different", "parallelisms", "than", "set", "in", "the", "job", "graph", "depending", "on", "the", "execution", "mode"], "project": "flink"}
{"id": 2689, "code": "public DataSource<String> readTextFile(String filePath, String charsetName) {\n    Preconditions.checkNotNull(filePath, \"The file path may not be null.\");\n\n    TextInputFormat format = new TextInputFormat(new Path(filePath));\n    format.setCharsetName(charsetName);\n    return new DataSource<>(\n            this, format, BasicTypeInfo.STRING_TYPE_INFO, Utils.getCallLocationName());\n}", "summary_tokens": ["creates", "a", "data", "set", "that", "represents", "the", "strings", "produced", "by", "reading", "the", "given", "file", "line", "wise"], "project": "flink"}
{"id": 5389, "code": "public StreamStateHandle getDelegateStateHandle() {\n    return stateHandle;\n}", "summary_tokens": ["the", "handle", "to", "the", "actual", "states"], "project": "flink"}
{"id": 8580, "code": "public static Signature of(List<Argument> arguments) {\n    return new Signature(arguments);\n}", "summary_tokens": ["creates", "an", "immutable", "instance", "of", "signature"], "project": "flink"}
{"id": 3678, "code": "public FieldSet getGroupedFields() {\n    return this.groupedFields;\n}", "summary_tokens": ["gets", "the", "grouped", "fields"], "project": "flink"}
{"id": 1499, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple19)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple19 tuple = (Tuple19) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    if (f5 != null ? !f5.equals(tuple.f5) : tuple.f5 != null) {\n        return false;\n    }\n    if (f6 != null ? !f6.equals(tuple.f6) : tuple.f6 != null) {\n        return false;\n    }\n    if (f7 != null ? !f7.equals(tuple.f7) : tuple.f7 != null) {\n        return false;\n    }\n    if (f8 != null ? !f8.equals(tuple.f8) : tuple.f8 != null) {\n        return false;\n    }\n    if (f9 != null ? !f9.equals(tuple.f9) : tuple.f9 != null) {\n        return false;\n    }\n    if (f10 != null ? !f10.equals(tuple.f10) : tuple.f10 != null) {\n        return false;\n    }\n    if (f11 != null ? !f11.equals(tuple.f11) : tuple.f11 != null) {\n        return false;\n    }\n    if (f12 != null ? !f12.equals(tuple.f12) : tuple.f12 != null) {\n        return false;\n    }\n    if (f13 != null ? !f13.equals(tuple.f13) : tuple.f13 != null) {\n        return false;\n    }\n    if (f14 != null ? !f14.equals(tuple.f14) : tuple.f14 != null) {\n        return false;\n    }\n    if (f15 != null ? !f15.equals(tuple.f15) : tuple.f15 != null) {\n        return false;\n    }\n    if (f16 != null ? !f16.equals(tuple.f16) : tuple.f16 != null) {\n        return false;\n    }\n    if (f17 != null ? !f17.equals(tuple.f17) : tuple.f17 != null) {\n        return false;\n    }\n    if (f18 != null ? !f18.equals(tuple.f18) : tuple.f18 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 7174, "code": "public SingleOutputStreamOperator<T> min(String field) {\n    return aggregate(\n            new ComparableAggregator<>(\n                    field,\n                    input.getType(),\n                    AggregationFunction.AggregationType.MIN,\n                    false,\n                    input.getExecutionConfig()));\n}", "summary_tokens": ["applies", "an", "aggregation", "that", "that", "gives", "the", "minimum", "value", "of", "the", "pojo", "data", "stream", "at", "the", "given", "field", "expression", "for", "every", "window"], "project": "flink"}
{"id": 6232, "code": "public void testAvailableBuffersEqualToRequiredBuffers() throws Exception {\n        \n    final NetworkBufferPool networkBufferPool = new NetworkBufferPool(16, 32);\n    final int numFloatingBuffers = 14;\n\n    final SingleInputGate inputGate = createSingleInputGate(1, networkBufferPool);\n    final RemoteInputChannel inputChannel = createRemoteInputChannel(inputGate);\n    inputGate.setInputChannels(inputChannel);\n    Throwable thrown = null;\n    try {\n        final BufferPool bufferPool =\n                spy(networkBufferPool.createBufferPool(numFloatingBuffers, numFloatingBuffers));\n        inputGate.setBufferPool(bufferPool);\n        inputGate.setupChannels();\n        inputChannel.requestSubpartition(0);\n\n            \n        final Buffer exclusiveBuffer = inputChannel.requestBuffer();\n        assertNotNull(exclusiveBuffer);\n        final Buffer floatingBuffer = bufferPool.requestBuffer();\n        assertNotNull(floatingBuffer);\n        verify(bufferPool, times(1)).requestBuffer();\n\n            \n        inputChannel.onSenderBacklog(12);\n\n            \n            \n        verify(bufferPool, times(14)).requestBuffer();\n        verify(bufferPool, times(0)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 14 buffers required in the channel\",\n                14,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n\n            \n        floatingBuffer.recycleBuffer();\n\n            \n            \n            \n        verify(bufferPool, times(14)).requestBuffer();\n        verify(bufferPool, times(0)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 14 buffers required in the channel\",\n                14,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 1 buffer available in local pool\",\n                1,\n                bufferPool.getNumberOfAvailableMemorySegments());\n\n            \n        exclusiveBuffer.recycleBuffer();\n\n            \n            \n            \n        verify(bufferPool, times(14)).requestBuffer();\n        verify(bufferPool, times(0)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 14 buffers required in the channel\",\n                14,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 2 buffers available in local pool\",\n                2,\n                bufferPool.getNumberOfAvailableMemorySegments());\n    } catch (Throwable t) {\n        thrown = t;\n    } finally {\n        cleanup(networkBufferPool, null, null, thrown, inputChannel);\n    }\n}", "summary_tokens": ["tests", "to", "verify", "the", "behaviours", "of", "recycling", "floating", "and", "exclusive", "buffers", "if", "the", "number", "of", "available", "buffers", "equals", "to", "required", "buffers"], "project": "flink"}
{"id": 9200, "code": "public SlicingWindowAggOperatorBuilder countStarIndex(int indexOfCountStart) {\n    this.indexOfCountStart = indexOfCountStart;\n    return this;\n}", "summary_tokens": ["specify", "the", "index", "position", "of", "the", "count", "value", "in", "the", "accumulator", "buffer"], "project": "flink"}
{"id": 8451, "code": "public TypeInformation<T> getResultType() {\n    return null;\n}", "summary_tokens": ["returns", "the", "type", "information", "of", "the", "imperative", "aggregate", "function", "s", "result"], "project": "flink"}
{"id": 2699, "code": "public void registerJobListener(JobListener jobListener) {\n    checkNotNull(jobListener, \"JobListener cannot be null\");\n    jobListeners.add(jobListener);\n}", "summary_tokens": ["register", "a", "job", "listener", "in", "this", "environment"], "project": "flink"}
{"id": 2962, "code": "protected NumericColumnSummary<Long> summarize(Long... values) {\n\n    LongValue[] longValues = new LongValue[values.length];\n    for (int i = 0; i < values.length; i++) {\n        if (values[i] != null) {\n            longValues[i] = new LongValue(values[i]);\n        }\n    }\n\n    return new AggregateCombineHarness<\n            LongValue,\n            NumericColumnSummary<Long>,\n            ValueSummaryAggregator.LongValueSummaryAggregator>() {\n\n        @Override\n        protected void compareResults(\n                NumericColumnSummary<Long> result1, NumericColumnSummary<Long> result2) {\n\n            Assert.assertEquals(result1.getTotalCount(), result2.getTotalCount());\n            Assert.assertEquals(result1.getNullCount(), result2.getNullCount());\n            Assert.assertEquals(result1.getMissingCount(), result2.getMissingCount());\n            Assert.assertEquals(result1.getNonMissingCount(), result2.getNonMissingCount());\n            Assert.assertEquals(result1.getInfinityCount(), result2.getInfinityCount());\n            Assert.assertEquals(result1.getNanCount(), result2.getNanCount());\n\n            Assert.assertEquals(result1.containsNull(), result2.containsNull());\n            Assert.assertEquals(result1.containsNonNull(), result2.containsNonNull());\n\n            Assert.assertEquals(result1.getMin().longValue(), result2.getMin().longValue());\n            Assert.assertEquals(result1.getMax().longValue(), result2.getMax().longValue());\n            Assert.assertEquals(result1.getSum().longValue(), result2.getSum().longValue());\n            Assert.assertEquals(\n                    result1.getMean().doubleValue(), result2.getMean().doubleValue(), 1e-12d);\n            Assert.assertEquals(\n                    result1.getVariance().doubleValue(),\n                    result2.getVariance().doubleValue(),\n                    1e-9d);\n            Assert.assertEquals(\n                    result1.getStandardDeviation().doubleValue(),\n                    result2.getStandardDeviation().doubleValue(),\n                    1e-12d);\n        }\n    }.summarize(longValues);\n}", "summary_tokens": ["helper", "method", "for", "summarizing", "a", "list", "of", "values"], "project": "flink"}
{"id": 1914, "code": "public void setCharset(Charset charset) {\n    this.charset = charset;\n}", "summary_tokens": ["sets", "the", "character", "set", "used", "for", "this", "parser"], "project": "flink"}
{"id": 7637, "code": "public void testEnableSlotSharing() {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    DataStream<Integer> sourceDataStream = env.fromElements(1, 2, 3);\n    DataStream<Integer> mapDataStream = sourceDataStream.map(x -> x + 1);\n\n    final List<Transformation<?>> transformations = new ArrayList<>();\n    transformations.add(sourceDataStream.getTransformation());\n    transformations.add(mapDataStream.getTransformation());\n\n        \n    StreamGraph streamGraph =\n            new StreamGraphGenerator(\n                            transformations, env.getConfig(), env.getCheckpointConfig())\n                    .generate();\n\n    Collection<StreamNode> streamNodes = streamGraph.getStreamNodes();\n    for (StreamNode streamNode : streamNodes) {\n        assertEquals(\n                StreamGraphGenerator.DEFAULT_SLOT_SHARING_GROUP,\n                streamNode.getSlotSharingGroup());\n    }\n}", "summary_tokens": ["test", "slot", "sharing", "is", "enabled"], "project": "flink"}
{"id": 6145, "code": "public void testRequestMemorySegmentsWithBuffersTaken()\n        throws IOException, InterruptedException {\n    final int numBuffers = 10;\n\n    NetworkBufferPool networkBufferPool = new NetworkBufferPool(numBuffers, 128);\n\n    final List<Buffer> buffers = new ArrayList<>(numBuffers);\n    List<MemorySegment> memorySegments = Collections.emptyList();\n    Thread bufferRecycler = null;\n    BufferPool lbp1 = null;\n    try {\n        lbp1 = networkBufferPool.createBufferPool(numBuffers / 2, numBuffers);\n\n            \n        for (int i = 0; i < numBuffers; ++i) {\n            Buffer buffer = lbp1.requestBuffer();\n            buffers.add(buffer);\n            assertNotNull(buffer);\n        }\n\n            \n            \n        final OneShotLatch isRunning = new OneShotLatch();\n        bufferRecycler =\n                new Thread(\n                        () -> {\n                            try {\n                                isRunning.trigger();\n                                Thread.sleep(100);\n                            } catch (InterruptedException ignored) {\n                            }\n\n                            for (Buffer buffer : buffers) {\n                                buffer.recycleBuffer();\n                            }\n                        });\n        bufferRecycler.start();\n\n            \n        isRunning.await();\n        memorySegments = networkBufferPool.requestMemorySegments(numBuffers / 2);\n        assertThat(memorySegments, not(hasItem(nullValue())));\n    } finally {\n        if (bufferRecycler != null) {\n            bufferRecycler.join();\n        }\n        if (lbp1 != null) {\n            lbp1.lazyDestroy();\n        }\n        networkBufferPool.recycleMemorySegments(memorySegments);\n        networkBufferPool.destroy();\n    }\n}", "summary_tokens": ["tests", "network", "buffer", "pool", "request", "memory", "segments", "int", "with", "the", "network", "buffer", "pool", "currently", "not", "containing", "the", "number", "of", "required", "free", "segments", "currently", "occupied", "by", "a", "buffer", "pool"], "project": "flink"}
{"id": 676, "code": "public void resourceCleanUp(FlinkKafkaProducer.Semantic semantic) throws Exception {\n    String topic = \"flink-kafka-producer-resource-cleanup-\" + semantic;\n\n    final int allowedEpsilonThreadCountGrow = 50;\n\n    Optional<Integer> initialActiveThreads = Optional.empty();\n    for (int i = 0; i < allowedEpsilonThreadCountGrow * 2; i++) {\n        try (OneInputStreamOperatorTestHarness<Integer, Object> testHarness1 =\n                createTestHarness(topic, 1, 1, 0, semantic)) {\n            testHarness1.setup();\n            testHarness1.open();\n        }\n\n        if (initialActiveThreads.isPresent()) {\n            assertThat(\n                    \"active threads count\",\n                    Thread.activeCount(),\n                    lessThan(initialActiveThreads.get() + allowedEpsilonThreadCountGrow));\n        } else {\n            initialActiveThreads = Optional.of(Thread.activeCount());\n        }\n    }\n    checkProducerLeak();\n}", "summary_tokens": ["this", "tests", "checks", "whether", "there", "is", "some", "resource", "leak", "in", "form", "of", "growing", "threads", "number"], "project": "flink"}
{"id": 7289, "code": "default void invoke(IN value, Context context) throws Exception {\n    invoke(value);\n}", "summary_tokens": ["writes", "the", "given", "value", "to", "the", "sink"], "project": "flink"}
{"id": 9061, "code": "public synchronized void set(String testCaseName, String resourceName, String value) {\n    assert resourceName != null;\n    update(testCaseName, resourceName, value);\n}", "summary_tokens": ["sets", "the", "value", "of", "a", "given", "resource", "of", "the", "current", "test", "case"], "project": "flink"}
{"id": 6132, "code": "public void testDiscardReadBytes2() {\n    buffer.writerIndex(0);\n    for (int i = 0; i < buffer.capacity(); i++) {\n        buffer.writeByte((byte) i);\n    }\n    ByteBuf copy = copiedBuffer(buffer);\n\n        \n    buffer.setIndex(CAPACITY / 2 - 1, CAPACITY - 1);\n    buffer.discardReadBytes();\n    assertEquals(0, buffer.readerIndex());\n    assertEquals(CAPACITY / 2, buffer.writerIndex());\n    for (int i = 0; i < CAPACITY / 2; i++) {\n        assertEquals(\n                copy.slice(CAPACITY / 2 - 1 + i, CAPACITY / 2 - i),\n                buffer.slice(i, CAPACITY / 2 - i));\n    }\n    copy.release();\n}", "summary_tokens": ["the", "similar", "test", "case", "with", "test", "discard", "read", "bytes", "but", "this", "one", "discards", "a", "large", "chunk", "at", "once"], "project": "flink"}
{"id": 3084, "code": "public Pattern<T, F> oneOrMore() {\n    checkIfNoNotPattern();\n    checkIfQuantifierApplied();\n    this.quantifier = Quantifier.looping(quantifier.getConsumingStrategy());\n    this.times = Times.of(1);\n    return this;\n}", "summary_tokens": ["specifies", "that", "this", "pattern", "can", "occur", "one", "or", "more", "times"], "project": "flink"}
{"id": 1827, "code": "public static Optional<JMXServer> getInstance() {\n    return Optional.ofNullable(jmxServer);\n}", "summary_tokens": ["acquire", "the", "global", "singleton", "jmxserver", "instance"], "project": "flink"}
{"id": 2104, "code": "public static <T> CompletableFuture<T> supplyAsync(\n        SupplierWithException<T, ?> supplier, Executor executor) {\n    return CompletableFuture.supplyAsync(\n            () -> {\n                try {\n                    return supplier.get();\n                } catch (Throwable e) {\n                    throw new CompletionException(e);\n                }\n            },\n            executor);\n}", "summary_tokens": ["returns", "a", "future", "which", "is", "completed", "with", "the", "result", "of", "the", "supplier", "with", "exception"], "project": "flink"}
{"id": 8462, "code": "public static <T, ACC> TypeInformation<T> getReturnTypeOfAggregateFunction(\n        ImperativeAggregateFunction<T, ACC> aggregateFunction, TypeInformation<T> scalaType) {\n\n    TypeInformation<T> userProvidedType = aggregateFunction.getResultType();\n    if (userProvidedType != null) {\n        return userProvidedType;\n    } else if (scalaType != null) {\n        return scalaType;\n    } else {\n        return TypeExtractor.createTypeInfo(\n                aggregateFunction,\n                ImperativeAggregateFunction.class,\n                aggregateFunction.getClass(),\n                0);\n    }\n}", "summary_tokens": ["tries", "to", "infer", "the", "type", "information", "of", "an", "aggregate", "function", "s", "accumulator", "type"], "project": "flink"}
{"id": 2784, "code": "public <X extends Value> IterativeDataSet<T> registerAggregationConvergenceCriterion(\n        String name, Aggregator<X> aggregator, ConvergenceCriterion<X> convergenceCheck) {\n    this.aggregators.registerAggregationConvergenceCriterion(\n            name, aggregator, convergenceCheck);\n    return this;\n}", "summary_tokens": ["registers", "an", "aggregator", "for", "the", "iteration", "together", "with", "a", "convergence", "criterion"], "project": "flink"}
{"id": 2438, "code": "public void testConfigKeysForwardingShortHadoopStyle() {\n    Configuration conf = new Configuration();\n    conf.setString(\"s3.access.key\", \"my_key_a\");\n    conf.setString(\"s3.secret.key\", \"my_key_b\");\n\n    checkHadoopAccessKeys(conf, \"my_key_a\", \"my_key_b\");\n}", "summary_tokens": ["test", "forwarding", "of", "shortened", "hadoop", "style", "credential", "keys"], "project": "flink"}
{"id": 5736, "code": "public Duration getDelayBetweenSamples() {\n    return delayBetweenSamples;\n}", "summary_tokens": ["returns", "the", "configured", "delay", "between", "the", "individual", "samples"], "project": "flink"}
{"id": 7386, "code": "default boolean isRestored() {\n    return getRestoredCheckpointId().isPresent();\n}", "summary_tokens": ["returns", "true", "if", "the", "states", "provided", "by", "this", "context", "are", "restored", "from", "a", "checkpoint", "savepoint"], "project": "flink"}
{"id": 6195, "code": "public void testReadOnlyBufferWriting() throws Exception {\n    testBufferWriting(new ReadOnlyBufferResultSubpartitionView(1));\n}", "summary_tokens": ["tests", "partition", "request", "queue", "buffer", "writing", "with", "read", "only", "buffers"], "project": "flink"}
{"id": 1478, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f5)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f6)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f7)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f8)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f9)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f10)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f11)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f12)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f13)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 3679, "code": "public void setGroupedFields(FieldSet groupedFields) {\n    this.groupedFields = groupedFields;\n}", "summary_tokens": ["sets", "the", "fields", "that", "are", "grouped", "in", "these", "data", "properties"], "project": "flink"}
{"id": 3790, "code": "synchronized <T> T releaseInternal(final Resource<T> resource, final T instance) {\n    final Instance cached = instances.get(resource);\n    if (cached == null) {\n        throw new IllegalArgumentException(\"No cached instance found for \" + resource);\n    }\n    Preconditions.checkArgument(instance == cached.payload, \"Releasing the wrong instance\");\n    Preconditions.checkState(cached.refcount > 0, \"Refcount has already reached zero\");\n    cached.refcount--;\n    if (cached.refcount == 0) {\n        Preconditions.checkState(cached.destroyTask == null, \"Destroy task already scheduled\");\n            \n        if (destroyer == null) {\n            destroyer = destroyerFactory.createScheduledExecutor();\n        }\n        cached.destroyTask =\n                destroyer.schedule(\n                        new LogExceptionRunnable(\n                                new Runnable() {\n                                    @Override\n                                    public void run() {\n                                        synchronized (SharedResourceHolder.this) {\n                                                \n                                                \n                                            if (cached.refcount == 0) {\n                                                try {\n                                                    resource.close(instance);\n                                                } finally {\n                                                    instances.remove(resource);\n                                                    if (instances.isEmpty()) {\n                                                        destroyer.shutdown();\n                                                        destroyer = null;\n                                                    }\n                                                }\n                                            }\n                                        }\n                                    }\n                                }),\n                        DESTROY_DELAY_SECONDS,\n                        TimeUnit.SECONDS);\n    }\n        \n    return null;\n}", "summary_tokens": ["visible", "to", "unit", "tests"], "project": "flink"}
{"id": 21, "code": "protected void cancel(String[] args) throws Exception {\n    LOG.info(\"Running 'cancel' command.\");\n\n    final Options commandOptions = CliFrontendParser.getCancelCommandOptions();\n    final CommandLine commandLine = getCommandLine(commandOptions, args, false);\n\n    CancelOptions cancelOptions = new CancelOptions(commandLine);\n\n        \n    if (cancelOptions.isPrintHelp()) {\n        CliFrontendParser.printHelpForCancel(customCommandLines);\n        return;\n    }\n\n    final CustomCommandLine activeCommandLine = validateAndGetActiveCommandLine(commandLine);\n\n    final String[] cleanedArgs = cancelOptions.getArgs();\n\n    if (cancelOptions.isWithSavepoint()) {\n\n        logAndSysout(\n                \"DEPRECATION WARNING: Cancelling a job with savepoint is deprecated. Use \\\"stop\\\" instead.\");\n\n        final JobID jobId;\n        final String targetDirectory;\n\n        if (cleanedArgs.length > 0) {\n            jobId = parseJobId(cleanedArgs[0]);\n            targetDirectory = cancelOptions.getSavepointTargetDirectory();\n        } else {\n            jobId = parseJobId(cancelOptions.getSavepointTargetDirectory());\n            targetDirectory = null;\n        }\n\n        if (targetDirectory == null) {\n            logAndSysout(\n                    \"Cancelling job \"\n                            + jobId\n                            + \" with savepoint to default savepoint directory.\");\n        } else {\n            logAndSysout(\n                    \"Cancelling job \" + jobId + \" with savepoint to \" + targetDirectory + '.');\n        }\n\n        runClusterAction(\n                activeCommandLine,\n                commandLine,\n                clusterClient -> {\n                    final String savepointPath;\n                    try {\n                        savepointPath =\n                                clusterClient\n                                        .cancelWithSavepoint(jobId, targetDirectory)\n                                        .get(clientTimeout.toMillis(), TimeUnit.MILLISECONDS);\n                    } catch (Exception e) {\n                        throw new FlinkException(\"Could not cancel job \" + jobId + '.', e);\n                    }\n                    logAndSysout(\n                            \"Cancelled job \"\n                                    + jobId\n                                    + \". Savepoint stored in \"\n                                    + savepointPath\n                                    + '.');\n                });\n    } else {\n        final JobID jobId;\n\n        if (cleanedArgs.length > 0) {\n            jobId = parseJobId(cleanedArgs[0]);\n        } else {\n            throw new CliArgsException(\"Missing JobID. Specify a JobID to cancel a job.\");\n        }\n\n        logAndSysout(\"Cancelling job \" + jobId + '.');\n\n        runClusterAction(\n                activeCommandLine,\n                commandLine,\n                clusterClient -> {\n                    try {\n                        clusterClient\n                                .cancel(jobId)\n                                .get(clientTimeout.toMillis(), TimeUnit.MILLISECONDS);\n                    } catch (Exception e) {\n                        throw new FlinkException(\"Could not cancel job \" + jobId + '.', e);\n                    }\n                });\n\n        logAndSysout(\"Cancelled job \" + jobId + '.');\n    }\n}", "summary_tokens": ["executes", "the", "cancel", "action"], "project": "flink"}
{"id": 9225, "code": "public static JoinInputSideSpec withUniqueKeyContainedByJoinKey(\n        InternalTypeInfo<RowData> uniqueKeyType,\n        KeySelector<RowData, RowData> uniqueKeySelector) {\n    checkNotNull(uniqueKeyType);\n    checkNotNull(uniqueKeySelector);\n    return new JoinInputSideSpec(true, uniqueKeyType, uniqueKeySelector);\n}", "summary_tokens": ["creates", "a", "join", "input", "side", "spec", "that", "input", "has", "an", "unique", "key", "and", "the", "unique", "key", "is", "contained", "by", "the", "join", "key"], "project": "flink"}
{"id": 4456, "code": "public Future<Path> createTmpFile(\n        String name, DistributedCacheEntry entry, JobID jobID, ExecutionAttemptID executionId)\n        throws Exception {\n    synchronized (lock) {\n        Map<String, Future<Path>> jobEntries =\n                entries.computeIfAbsent(jobID, k -> new HashMap<>());\n\n            \n        final Set<ExecutionAttemptID> refHolders =\n                jobRefHolders.computeIfAbsent(jobID, id -> new HashSet<>());\n        refHolders.add(executionId);\n\n        Future<Path> fileEntry = jobEntries.get(name);\n        if (fileEntry != null) {\n                \n                \n            return fileEntry;\n        } else {\n                \n\n                \n            File tempDirToUse = new File(storageDirectories[nextDirectory++], jobID.toString());\n            if (nextDirectory >= storageDirectories.length) {\n                nextDirectory = 0;\n            }\n\n                \n            Callable<Path> cp;\n            if (entry.blobKey != null) {\n                cp =\n                        new CopyFromBlobProcess(\n                                entry,\n                                jobID,\n                                blobService,\n                                new Path(tempDirToUse.getAbsolutePath()));\n            } else {\n                cp = new CopyFromDFSProcess(entry, new Path(tempDirToUse.getAbsolutePath()));\n            }\n            FutureTask<Path> copyTask = new FutureTask<>(cp);\n            executorService.submit(copyTask);\n\n                \n            jobEntries.put(name, copyTask);\n\n            return copyTask;\n        }\n    }\n}", "summary_tokens": ["if", "the", "file", "doesn", "t", "exists", "locally", "retrieve", "the", "file", "from", "the", "blob", "service"], "project": "flink"}
{"id": 1841, "code": "public static <L, R> Right<L, R> obtainRight(\n        Either<L, R> input, TypeSerializer<R> rightSerializer) {\n    if (input.isRight()) {\n        return (Right<L, R>) input;\n    } else {\n        Left<L, R> left = (Left<L, R>) input;\n        if (left.right == null) {\n            left.right = Right.of(rightSerializer.createInstance());\n            left.right.left = left;\n        }\n        return left.right;\n    }\n}", "summary_tokens": ["utility", "function", "for", "either", "serializer", "to", "support", "object", "reuse"], "project": "flink"}
{"id": 7774, "code": "public void testMergingLateWindows() throws Exception {\n\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(EventTimeTrigger.create(), new TimeWindow.Serializer());\n\n    assertTrue(EventTimeTrigger.create().canMerge());\n\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(2, testHarness.numEventTimeTimers());\n    assertEquals(1, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(1, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.advanceWatermark(10);\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(0, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.mergeWindows(\n            new TimeWindow(0, 4),\n            Lists.newArrayList(new TimeWindow(0, 2), new TimeWindow(2, 4)));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers());\n    assertEquals(0, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(0, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n    assertEquals(0, testHarness.numEventTimeTimers(new TimeWindow(0, 4)));\n}", "summary_tokens": ["merging", "a", "late", "window", "should", "not", "register", "a", "timer", "otherwise", "we", "would", "get", "two", "firings", "one", "from", "on", "element", "on", "the", "merged", "window", "and", "one", "from", "the", "timer"], "project": "flink"}
{"id": 2380, "code": "public <U> List<U> getInstances(String name, Class<U> xface) {\n    List<U> ret = new ArrayList<U>();\n    Class<?>[] classes = getClasses(name);\n    for (Class<?> cl : classes) {\n        if (!xface.isAssignableFrom(cl)) {\n            throw new RuntimeException(cl + \" does not implement \" + xface);\n        }\n        ret.add((U) ReflectionUtils.newInstance(cl, this));\n    }\n    return ret;\n}", "summary_tokens": ["get", "the", "value", "of", "the", "code", "name", "code", "property", "as", "a", "code", "list", "code", "of", "objects", "implementing", "the", "interface", "specified", "by", "code", "xface", "code"], "project": "flink"}
{"id": 2970, "code": "private Tuple2<Boolean, Boolean> repStep(BufferedReader in)\n        throws IOException, InterruptedException {\n    final long startTime = System.currentTimeMillis();\n    while ((System.currentTimeMillis() - startTime) < CLIENT_POLLING_INTERVAL_MS\n            && (!in.ready())) {\n        Thread.sleep(200L);\n    }\n        \n\n    if (in.ready()) {\n        final String command = in.readLine();\n        switch (command) {\n            case \"quit\":\n                return new Tuple2<>(false, false);\n            case \"stop\":\n                return new Tuple2<>(false, true);\n\n            case \"help\":\n                System.err.println(KUBERNETES_CLUSTER_HELP);\n                break;\n            default:\n                System.err.println(\"Unknown command '\" + command + \"'. Showing help:\");\n                System.err.println(KUBERNETES_CLUSTER_HELP);\n                break;\n        }\n    }\n\n    return new Tuple2<>(true, false);\n}", "summary_tokens": ["check", "whether", "need", "to", "continue", "or", "kill", "the", "cluster"], "project": "flink"}
{"id": 8317, "code": "public static void copyFromBytes(\n        MemorySegment[] segments, int offset, byte[] bytes, int bytesOffset, int numBytes) {\n    if (segments.length == 1) {\n        segments[0].put(offset, bytes, bytesOffset, numBytes);\n    } else {\n        copyMultiSegmentsFromBytes(segments, offset, bytes, bytesOffset, numBytes);\n    }\n}", "summary_tokens": ["copy", "target", "segments", "from", "source", "byte"], "project": "flink"}
{"id": 8057, "code": "public Set<String> listCatalogs() {\n    return Collections.unmodifiableSet(catalogs.keySet());\n}", "summary_tokens": ["retrieves", "names", "of", "all", "registered", "catalogs"], "project": "flink"}
{"id": 5689, "code": "public static CompletedCheckpointStore createCompletedCheckpoints(\n        CuratorFramework client,\n        Configuration configuration,\n        int maxNumberOfCheckpointsToRetain,\n        SharedStateRegistryFactory sharedStateRegistryFactory,\n        Executor ioExecutor,\n        Executor executor)\n        throws Exception {\n\n    checkNotNull(configuration, \"Configuration\");\n\n    RetrievableStateStorageHelper<CompletedCheckpoint> stateStorage =\n            createFileSystemStateStorage(configuration, HA_STORAGE_COMPLETED_CHECKPOINT);\n\n    final ZooKeeperStateHandleStore<CompletedCheckpoint> completedCheckpointStateHandleStore =\n            createZooKeeperStateHandleStore(client, getCheckpointsPath(), stateStorage);\n    Collection<CompletedCheckpoint> completedCheckpoints =\n            DefaultCompletedCheckpointStoreUtils.retrieveCompletedCheckpoints(\n                    completedCheckpointStateHandleStore, ZooKeeperCheckpointStoreUtil.INSTANCE);\n    final CompletedCheckpointStore zooKeeperCompletedCheckpointStore =\n            new DefaultCompletedCheckpointStore<>(\n                    maxNumberOfCheckpointsToRetain,\n                    completedCheckpointStateHandleStore,\n                    ZooKeeperCheckpointStoreUtil.INSTANCE,\n                    completedCheckpoints,\n                    sharedStateRegistryFactory.create(ioExecutor, completedCheckpoints),\n                    executor);\n    LOG.info(\n            \"Initialized {} in '{}' with {}.\",\n            DefaultCompletedCheckpointStore.class.getSimpleName(),\n            completedCheckpointStateHandleStore,\n            getCheckpointsPath());\n    return zooKeeperCompletedCheckpointStore;\n}", "summary_tokens": ["creates", "a", "default", "completed", "checkpoint", "store", "instance", "with", "zoo", "keeper", "state", "handle", "store"], "project": "flink"}
{"id": 319, "code": "default void seekToRow(long rowCount, RowData reuse) throws IOException {\n    for (int i = 0; i < rowCount; i++) {\n        boolean end = reachedEnd();\n        if (end) {\n            throw new RuntimeException(\"Seek too many rows.\");\n        }\n        nextRecord(reuse);\n    }\n}", "summary_tokens": ["seek", "to", "a", "particular", "row", "number"], "project": "flink"}
{"id": 5504, "code": "public int getMaxStateSize() {\n    return maxStateSize;\n}", "summary_tokens": ["gets", "the", "maximum", "size", "that", "an", "individual", "state", "can", "have", "as", "configured", "in", "the", "constructor", "by", "default", "default", "max", "state", "size"], "project": "flink"}
{"id": 4469, "code": "private void addContender(EmbeddedLeaderElectionService service, LeaderContender contender) {\n    synchronized (lock) {\n        checkState(!shutdown, \"leader election service is shut down\");\n        checkState(!service.running, \"leader election service is already started\");\n\n        try {\n            if (!allLeaderContenders.add(service)) {\n                throw new IllegalStateException(\n                        \"leader election service was added to this service multiple times\");\n            }\n\n            service.contender = contender;\n            service.running = true;\n\n            updateLeader()\n                    .whenComplete(\n                            (aVoid, throwable) -> {\n                                if (throwable != null) {\n                                    fatalError(throwable);\n                                }\n                            });\n        } catch (Throwable t) {\n            fatalError(t);\n        }\n    }\n}", "summary_tokens": ["callback", "from", "leader", "contenders", "when", "they", "start", "their", "service"], "project": "flink"}
{"id": 9415, "code": "public static long nextPowerOfTwo(long x) {\n    if (x == 0L) {\n        return 1L;\n    } else {\n        --x;\n        x |= x >> 1;\n        x |= x >> 2;\n        x |= x >> 4;\n        x |= x >> 8;\n        x |= x >> 16;\n        return (x | x >> 32) + 1L;\n    }\n}", "summary_tokens": ["return", "the", "least", "power", "of", "two", "greater", "than", "or", "equal", "to", "the", "specified", "value"], "project": "flink"}
{"id": 8607, "code": "private static @Nullable DataType findDataTypeOfRoot(\n        DataType actualDataType, LogicalTypeRoot expectedRoot) {\n    final LogicalType actualType = actualDataType.getLogicalType();\n    if (actualType.is(expectedRoot)) {\n        return actualDataType;\n    }\n    switch (expectedRoot) {\n        case CHAR:\n            return DataTypes.CHAR(CharType.DEFAULT_LENGTH);\n        case VARCHAR:\n            if (actualType.is(CHAR)) {\n                return DataTypes.VARCHAR(getLength(actualType));\n            }\n            return DataTypes.VARCHAR(VarCharType.DEFAULT_LENGTH);\n        case BOOLEAN:\n            return DataTypes.BOOLEAN();\n        case BINARY:\n            return DataTypes.BINARY(BinaryType.DEFAULT_LENGTH);\n        case VARBINARY:\n            if (actualType.is(BINARY)) {\n                return DataTypes.VARBINARY(getLength(actualType));\n            }\n            return DataTypes.VARBINARY(VarBinaryType.DEFAULT_LENGTH);\n        case DECIMAL:\n            if (actualType.is(EXACT_NUMERIC)) {\n                return DataTypes.DECIMAL(getPrecision(actualType), getScale(actualType));\n            } else if (actualType.is(APPROXIMATE_NUMERIC)) {\n                final int precision = getPrecision(actualType);\n                    \n                return DataTypes.DECIMAL(precision * 2, precision);\n            }\n            return DataTypes.DECIMAL(DecimalType.MIN_PRECISION, DecimalType.MIN_SCALE);\n        case TINYINT:\n            return DataTypes.TINYINT();\n        case SMALLINT:\n            return DataTypes.SMALLINT();\n        case INTEGER:\n            return DataTypes.INT();\n        case BIGINT:\n            return DataTypes.BIGINT();\n        case FLOAT:\n            return DataTypes.FLOAT();\n        case DOUBLE:\n            return DataTypes.DOUBLE();\n        case DATE:\n            return DataTypes.DATE();\n        case TIME_WITHOUT_TIME_ZONE:\n            if (actualType.is(TIMESTAMP_WITHOUT_TIME_ZONE)) {\n                return DataTypes.TIME(getPrecision(actualType));\n            }\n            return DataTypes.TIME();\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n            return DataTypes.TIMESTAMP();\n        case TIMESTAMP_WITH_TIME_ZONE:\n            return DataTypes.TIMESTAMP_WITH_TIME_ZONE();\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            return DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE();\n        case INTERVAL_YEAR_MONTH:\n            return DataTypes.INTERVAL(DataTypes.MONTH());\n        case INTERVAL_DAY_TIME:\n            return DataTypes.INTERVAL(DataTypes.SECOND());\n        case NULL:\n            return DataTypes.NULL();\n        case ARRAY:\n        case MULTISET:\n        case MAP:\n        case ROW:\n        case DISTINCT_TYPE:\n        case STRUCTURED_TYPE:\n        case RAW:\n        case SYMBOL:\n        case UNRESOLVED:\n        default:\n            return null;\n    }\n}", "summary_tokens": ["returns", "a", "data", "type", "for", "the", "given", "data", "type", "and", "expected", "root"], "project": "flink"}
{"id": 6726, "code": "public void deleteAll() throws Exception {\n    final String path = \"/\" + client.getNamespace();\n\n    int maxAttempts = 10;\n\n    for (int i = 0; i < maxAttempts; i++) {\n        try {\n            ZKPaths.deleteChildren(client.getZookeeperClient().getZooKeeper(), path, false);\n            return;\n        } catch (org.apache.zookeeper.KeeperException.NoNodeException e) {\n                \n                \n            return;\n        } catch (KeeperException.ConnectionLossException e) {\n                \n            Thread.sleep(100);\n        }\n    }\n\n    throw new Exception(\n            \"Could not clear the ZNodes under \"\n                    + path\n                    + \". ZooKeeper is not in \"\n                    + \"a clean state.\");\n}", "summary_tokens": ["deletes", "all", "znodes", "under", "the", "root", "node"], "project": "flink"}
{"id": 5558, "code": "private static void checkTempDirs(String[] tmpDirs) throws IOException {\n    for (String dir : tmpDirs) {\n        if (dir != null && !dir.equals(\"\")) {\n            File file = new File(dir);\n            if (!file.exists()) {\n                if (!file.mkdirs()) {\n                    throw new IOException(\n                            \"Temporary file directory \"\n                                    + file.getAbsolutePath()\n                                    + \" does not exist and could not be created.\");\n                }\n            }\n            if (!file.isDirectory()) {\n                throw new IOException(\n                        \"Temporary file directory \"\n                                + file.getAbsolutePath()\n                                + \" is not a directory.\");\n            }\n            if (!file.canWrite()) {\n                throw new IOException(\n                        \"Temporary file directory \"\n                                + file.getAbsolutePath()\n                                + \" is not writable.\");\n            }\n\n            if (LOG.isInfoEnabled()) {\n                long totalSpaceGb = file.getTotalSpace() >> 30;\n                long usableSpaceGb = file.getUsableSpace() >> 30;\n                double usablePercentage = (double) usableSpaceGb / totalSpaceGb * 100;\n                String path = file.getAbsolutePath();\n                LOG.info(\n                        String.format(\n                                \"Temporary file directory '%s': total %d GB, \"\n                                        + \"usable %d GB (%.2f%% usable)\",\n                                path, totalSpaceGb, usableSpaceGb, usablePercentage));\n            }\n        } else {\n            throw new IllegalArgumentException(\"Temporary file directory #$id is null.\");\n        }\n    }\n}", "summary_tokens": ["validates", "that", "all", "the", "directories", "denoted", "by", "the", "strings", "do", "actually", "exist", "or", "can", "be", "created", "are", "proper", "directories", "not", "files", "and", "are", "writable"], "project": "flink"}
{"id": 7493, "code": "public void close() throws IOException {\n    barrierHandler.close();\n}", "summary_tokens": ["cleans", "up", "all", "internally", "held", "resources"], "project": "flink"}
{"id": 4110, "code": "private static BlobKey receiveAndCheckPutResponse(\n        InputStream is, MessageDigest md, BlobKey.BlobType blobType) throws IOException {\n    int response = is.read();\n    if (response < 0) {\n        throw new EOFException(\"Premature end of response\");\n    } else if (response == RETURN_OKAY) {\n\n        BlobKey remoteKey = BlobKey.readFromInputStream(is);\n        byte[] localHash = md.digest();\n\n        if (blobType != remoteKey.getType()) {\n            throw new IOException(\"Detected data corruption during transfer\");\n        }\n        if (!Arrays.equals(localHash, remoteKey.getHash())) {\n            throw new IOException(\"Detected data corruption during transfer\");\n        }\n\n        return remoteKey;\n    } else if (response == RETURN_ERROR) {\n        Throwable cause = BlobUtils.readExceptionFromStream(is);\n        throw new IOException(\"Server side error: \" + cause.getMessage(), cause);\n    } else {\n        throw new IOException(\"Unrecognized response: \" + response + '.');\n    }\n}", "summary_tokens": ["reads", "the", "response", "from", "the", "input", "stream", "and", "throws", "in", "case", "of", "errors"], "project": "flink"}
{"id": 79, "code": "public void testCancelWithSavepoint() throws Exception {\n    {\n            \n        JobID jid = new JobID();\n\n        OneShotLatch cancelWithSavepointLatch = new OneShotLatch();\n\n        String[] parameters = {\"-s\", jid.toString()};\n        TestingClusterClient<String> clusterClient = new TestingClusterClient<>();\n        clusterClient.setCancelWithSavepointFunction(\n                (jobID, savepointDirectory) -> {\n                    assertNull(savepointDirectory);\n                    cancelWithSavepointLatch.trigger();\n                    return CompletableFuture.completedFuture(savepointDirectory);\n                });\n        MockedCliFrontend testFrontend = new MockedCliFrontend(clusterClient);\n        testFrontend.cancel(parameters);\n        cancelWithSavepointLatch.await();\n    }\n\n    {\n            \n        JobID jid = new JobID();\n\n        OneShotLatch cancelWithSavepointLatch = new OneShotLatch();\n\n        String[] parameters = {\"-s\", \"targetDirectory\", jid.toString()};\n        TestingClusterClient<String> clusterClient = new TestingClusterClient<>();\n        clusterClient.setCancelWithSavepointFunction(\n                (jobID, savepointDirectory) -> {\n                    assertNotNull(savepointDirectory);\n                    cancelWithSavepointLatch.trigger();\n                    return CompletableFuture.completedFuture(savepointDirectory);\n                });\n        MockedCliFrontend testFrontend = new MockedCliFrontend(clusterClient);\n        testFrontend.cancel(parameters);\n        cancelWithSavepointLatch.await();\n    }\n}", "summary_tokens": ["tests", "cancelling", "with", "the", "savepoint", "option"], "project": "flink"}
{"id": 4422, "code": "public void resetForNewExecution() {\n    resetForNewExecutionInternal(System.currentTimeMillis());\n}", "summary_tokens": ["archives", "the", "current", "execution", "and", "creates", "a", "new", "execution", "for", "this", "vertex"], "project": "flink"}
{"id": 6009, "code": "public void testCacheLoading() throws IOException {\n    final File rootDir = temporaryFolder.newFolder();\n\n    try (final FileExecutionGraphInfoStore executionGraphInfoStore =\n            new FileExecutionGraphInfoStore(\n                    rootDir,\n                    Time.hours(1L),\n                    Integer.MAX_VALUE,\n                    100L << 10,\n                    TestingUtils.defaultScheduledExecutor(),\n                    Ticker.systemTicker())) {\n\n        final LoadingCache<JobID, ExecutionGraphInfo> executionGraphInfoCache =\n                executionGraphInfoStore.getExecutionGraphInfoCache();\n\n        Collection<ExecutionGraphInfo> executionGraphInfos = new ArrayList<>(64);\n\n        boolean continueInserting = true;\n\n            \n        while (continueInserting) {\n                \n            final ExecutionGraphInfo executionGraphInfo =\n                    new ExecutionGraphInfo(\n                            new ArchivedExecutionGraphBuilder()\n                                    .setState(JobStatus.FINISHED)\n                                    .build());\n\n            executionGraphInfoStore.put(executionGraphInfo);\n\n            executionGraphInfos.add(executionGraphInfo);\n\n            continueInserting = executionGraphInfoCache.size() == executionGraphInfos.size();\n        }\n\n        final File storageDirectory = executionGraphInfoStore.getStorageDir();\n\n        assertThat(\n                storageDirectory.listFiles().length,\n                Matchers.equalTo(executionGraphInfos.size()));\n\n        for (ExecutionGraphInfo executionGraphInfo : executionGraphInfos) {\n            assertThat(\n                    executionGraphInfoStore.get(executionGraphInfo.getJobId()),\n                    matchesPartiallyWith(executionGraphInfo));\n        }\n    }\n}", "summary_tokens": ["tests", "that", "evicted", "execution", "graph", "info", "are", "loaded", "from", "disk", "again"], "project": "flink"}
{"id": 1817, "code": "public static MemorySegment wrapOffHeapMemory(ByteBuffer memory) {\n    return new MemorySegment(memory, null);\n}", "summary_tokens": ["creates", "a", "memory", "segment", "that", "wraps", "the", "off", "heap", "memory", "backing", "the", "given", "byte", "buffer"], "project": "flink"}
{"id": 6013, "code": "public void testTerminationAfterJobCompletion() throws Exception {\n    final MiniDispatcher miniDispatcher =\n            createMiniDispatcher(ClusterEntrypoint.ExecutionMode.DETACHED);\n\n    miniDispatcher.start();\n\n    try {\n            \n        final TestingJobManagerRunner testingJobManagerRunner =\n                testingJobManagerRunnerFactory.takeCreatedJobManagerRunner();\n\n        testingJobManagerRunner.completeResultFuture(executionGraphInfo);\n\n            \n        miniDispatcher.getShutDownFuture().get();\n    } finally {\n        RpcUtils.terminateRpcEndpoint(miniDispatcher, timeout);\n    }\n}", "summary_tokens": ["tests", "that", "in", "detached", "mode", "the", "mini", "dispatcher", "will", "complete", "the", "future", "that", "signals", "job", "termination"], "project": "flink"}
{"id": 5938, "code": "public void testClosingSchedulerShutsDownCheckpointCoordinatorOnFinishedExecutionGraph()\n        throws Exception {\n    final CompletableFuture<JobStatus> counterShutdownFuture = new CompletableFuture<>();\n    CheckpointIDCounter counter = new TestingCheckpointIDCounter(counterShutdownFuture);\n\n    final CompletableFuture<JobStatus> storeShutdownFuture = new CompletableFuture<>();\n    CompletedCheckpointStore store = new TestingCompletedCheckpointStore(storeShutdownFuture);\n\n    final SchedulerBase scheduler = createSchedulerAndEnableCheckpointing(counter, store);\n    final ExecutionGraph graph = scheduler.getExecutionGraph();\n    final CheckpointCoordinator checkpointCoordinator = graph.getCheckpointCoordinator();\n\n    assertThat(checkpointCoordinator, Matchers.notNullValue());\n    assertThat(checkpointCoordinator.isShutdown(), is(false));\n\n    scheduler.startScheduling();\n\n    for (ExecutionVertex executionVertex : graph.getAllExecutionVertices()) {\n        final Execution currentExecutionAttempt = executionVertex.getCurrentExecutionAttempt();\n        scheduler.updateTaskExecutionState(\n                new TaskExecutionState(\n                        currentExecutionAttempt.getAttemptId(), ExecutionState.FINISHED));\n    }\n\n    assertThat(graph.getTerminationFuture().get(), is(JobStatus.FINISHED));\n\n    scheduler.closeAsync().get();\n\n    assertThat(checkpointCoordinator.isShutdown(), is(true));\n    assertThat(counterShutdownFuture.get(), is(JobStatus.FINISHED));\n    assertThat(storeShutdownFuture.get(), is(JobStatus.FINISHED));\n}", "summary_tokens": ["tests", "that", "the", "checkpoint", "coordinator", "is", "shut", "down", "if", "the", "execution", "graph", "is", "finished"], "project": "flink"}
{"id": 8418, "code": "static ManagedTableFactory discoverManagedTableFactory(ClassLoader classLoader) {\n    return FactoryUtil.discoverManagedTableFactory(classLoader, ManagedTableFactory.class);\n}", "summary_tokens": ["discovers", "the", "unique", "implementation", "of", "managed", "table", "factory", "without", "identifier"], "project": "flink"}
{"id": 6231, "code": "public void testAvailableBuffersLessThanRequiredBuffers() throws Exception {\n        \n    final NetworkBufferPool networkBufferPool = new NetworkBufferPool(16, 32);\n    final int numFloatingBuffers = 14;\n\n    final SingleInputGate inputGate = createSingleInputGate(1, networkBufferPool);\n    final RemoteInputChannel inputChannel = createRemoteInputChannel(inputGate);\n    inputGate.setInputChannels(inputChannel);\n    Throwable thrown = null;\n    try {\n        final BufferPool bufferPool =\n                spy(networkBufferPool.createBufferPool(numFloatingBuffers, numFloatingBuffers));\n        inputGate.setBufferPool(bufferPool);\n        inputGate.setupChannels();\n        inputChannel.requestSubpartition(0);\n\n            \n        final Buffer exclusiveBuffer = inputChannel.requestBuffer();\n        assertNotNull(exclusiveBuffer);\n\n        final int numRecycleFloatingBuffers = 2;\n        final ArrayDeque<Buffer> floatingBufferQueue =\n                new ArrayDeque<>(numRecycleFloatingBuffers);\n        for (int i = 0; i < numRecycleFloatingBuffers; i++) {\n            Buffer floatingBuffer = bufferPool.requestBuffer();\n            assertNotNull(floatingBuffer);\n            floatingBufferQueue.add(floatingBuffer);\n        }\n\n        verify(bufferPool, times(numRecycleFloatingBuffers)).requestBuffer();\n\n            \n        inputChannel.onSenderBacklog(14);\n\n            \n            \n            \n        verify(bufferPool, times(15)).requestBuffer();\n        verify(bufferPool, times(1)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 13 buffers available in the channel\",\n                13,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 16 buffers required in the channel\",\n                16,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertTrue(inputChannel.isWaitingForFloatingBuffers());\n\n            \n        inputChannel.onSenderBacklog(16);\n\n            \n            \n        verify(bufferPool, times(15)).requestBuffer();\n        verify(bufferPool, times(1)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 13 buffers available in the channel\",\n                13,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 18 buffers required in the channel\",\n                18,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertTrue(inputChannel.isWaitingForFloatingBuffers());\n\n            \n        exclusiveBuffer.recycleBuffer();\n\n            \n        verify(bufferPool, times(15)).requestBuffer();\n        verify(bufferPool, times(1)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 18 buffers required in the channel\",\n                18,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertTrue(inputChannel.isWaitingForFloatingBuffers());\n\n            \n        floatingBufferQueue.poll().recycleBuffer();\n\n            \n            \n        verify(bufferPool, times(16)).requestBuffer();\n        verify(bufferPool, times(2)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 15 buffers available in the channel\",\n                15,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 18 buffers required in the channel\",\n                18,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertTrue(inputChannel.isWaitingForFloatingBuffers());\n\n            \n        inputChannel.onSenderBacklog(13);\n\n            \n        verify(bufferPool, times(16)).requestBuffer();\n        verify(bufferPool, times(2)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 15 buffers available in the channel\",\n                15,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 15 buffers required in the channel\",\n                15,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertTrue(inputChannel.isWaitingForFloatingBuffers());\n\n            \n        floatingBufferQueue.poll().recycleBuffer();\n\n            \n            \n        verify(bufferPool, times(16)).requestBuffer();\n        verify(bufferPool, times(2)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 15 buffers available in the channel\",\n                15,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 15 buffers required in the channel\",\n                15,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 1 buffers available in local pool\",\n                1,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertFalse(inputChannel.isWaitingForFloatingBuffers());\n\n            \n        inputChannel.onSenderBacklog(15);\n\n            \n            \n        verify(bufferPool, times(18)).requestBuffer();\n        verify(bufferPool, times(3)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 16 buffers available in the channel\",\n                16,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 17 buffers required in the channel\",\n                17,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n        assertTrue(inputChannel.isWaitingForFloatingBuffers());\n    } catch (Throwable t) {\n        thrown = t;\n    } finally {\n        cleanup(networkBufferPool, null, null, thrown, inputChannel);\n    }\n}", "summary_tokens": ["tests", "to", "verify", "the", "behaviours", "of", "three", "different", "processes", "if", "the", "number", "of", "available", "buffers", "is", "less", "than", "required", "buffers"], "project": "flink"}
{"id": 772, "code": "public static StreamShardHandle convertToStreamShardHandle(\n        StreamShardMetadata streamShardMetadata) {\n    Shard shard = new Shard();\n    shard.withShardId(streamShardMetadata.getShardId());\n    shard.withParentShardId(streamShardMetadata.getParentShardId());\n    shard.withAdjacentParentShardId(streamShardMetadata.getAdjacentParentShardId());\n\n    HashKeyRange hashKeyRange = new HashKeyRange();\n    hashKeyRange.withStartingHashKey(streamShardMetadata.getStartingHashKey());\n    hashKeyRange.withEndingHashKey(streamShardMetadata.getEndingHashKey());\n    shard.withHashKeyRange(hashKeyRange);\n\n    SequenceNumberRange sequenceNumberRange = new SequenceNumberRange();\n    sequenceNumberRange.withStartingSequenceNumber(\n            streamShardMetadata.getStartingSequenceNumber());\n    sequenceNumberRange.withEndingSequenceNumber(streamShardMetadata.getEndingSequenceNumber());\n    shard.withSequenceNumberRange(sequenceNumberRange);\n\n    return new StreamShardHandle(streamShardMetadata.getStreamName(), shard);\n}", "summary_tokens": ["utility", "function", "to", "convert", "stream", "shard", "metadata", "into", "stream", "shard", "handle"], "project": "flink"}
{"id": 1016, "code": "private static void applyDefaultNonNullConfVars(Configuration conf) {\n  for (ConfVars var : ConfVars.values()) {\n    String defaultValue = var.getDefaultValue();\n    if (defaultValue == null) {\n        \n      continue;\n    }\n    conf.set(var.varname, defaultValue);\n  }\n}", "summary_tokens": ["overlays", "conf", "var", "properties", "with", "non", "null", "values"], "project": "flink"}
{"id": 3907, "code": "public long getRequestId() {\n    return requestId;\n}", "summary_tokens": ["returns", "the", "request", "id", "responding", "to"], "project": "flink"}
{"id": 1221, "code": "public Operator<IN> getInput() {\n    return this.input;\n}", "summary_tokens": ["returns", "this", "operator", "s", "input", "operator"], "project": "flink"}
{"id": 7402, "code": "public T next() {\n    if (userVisibleHead == userVisibleTail) {\n        return null;\n    }\n    T ret = buffer.removeFirst();\n    userVisibleHead++;\n\n    sanityCheck();\n    return ret;\n}", "summary_tokens": ["get", "next", "user", "visible", "result", "returns", "null", "if", "currently", "there", "is", "no", "more"], "project": "flink"}
{"id": 3042, "code": "public Optional<String> getPatternName() {\n    return Optional.empty();\n}", "summary_tokens": ["name", "of", "pattern", "that", "processing", "will", "be", "skipped", "to"], "project": "flink"}
{"id": 8887, "code": "private Operation convertShowCurrentCatalog(SqlShowCurrentCatalog sqlShowCurrentCatalog) {\n    return new ShowCurrentCatalogOperation();\n}", "summary_tokens": ["convert", "show", "current", "catalog", "statement"], "project": "flink"}
{"id": 399, "code": "public HiveParserASTNode getClusterByForClause(String clause) {\n    return destToClusterby.get(clause);\n}", "summary_tokens": ["get", "the", "cluster", "by", "ast", "for", "the", "clause"], "project": "flink"}
{"id": 3694, "code": "public int getReplicationFactor() {\n    return this.replicationFactor;\n}", "summary_tokens": ["returns", "the", "replication", "factor", "of", "the", "connection"], "project": "flink"}
{"id": 4882, "code": "public boolean isShutdown() {\n    synchronized (lock) {\n        return isShutdown;\n    }\n}", "summary_tokens": ["returns", "whether", "this", "registry", "has", "been", "shutdown"], "project": "flink"}
{"id": 6633, "code": "public void testStorageLocationMkdirs() throws Exception {\n    FsCheckpointStorageAccess storage =\n            new FsCheckpointStorageAccess(\n                    randomTempPath(),\n                    null,\n                    new JobID(),\n                    FILE_SIZE_THRESHOLD,\n                    WRITE_BUFFER_SIZE);\n\n    File baseDir = new File(storage.getCheckpointsDirectory().getPath());\n    assertFalse(baseDir.exists());\n\n        \n    storage.initializeBaseLocationsForCheckpoint();\n    assertTrue(baseDir.exists());\n\n        \n    storage =\n            new FsCheckpointStorageAccess(\n                    randomTempPath(),\n                    null,\n                    new JobID(),\n                    FILE_SIZE_THRESHOLD,\n                    WRITE_BUFFER_SIZE);\n\n    FsCheckpointStorageLocation location =\n            (FsCheckpointStorageLocation)\n                    storage.resolveCheckpointStorageLocation(\n                            177, CheckpointStorageLocationReference.getDefault());\n\n    Path checkpointPath = location.getCheckpointDirectory();\n    File checkpointDir = new File(checkpointPath.getPath());\n    assertFalse(checkpointDir.exists());\n}", "summary_tokens": ["this", "test", "checks", "that", "the", "expected", "mkdirs", "action", "for", "checkpoint", "storage", "only", "be", "called", "when", "initialize", "base", "locations", "and", "not", "called", "when", "resolve", "checkpoint", "storage", "location"], "project": "flink"}
{"id": 3165, "code": "public DataSet<Edge<K, EV>> getEdges() {\n    return edges;\n}", "summary_tokens": ["the", "edge", "data", "set"], "project": "flink"}
{"id": 782, "code": "public long getSubscribeToShardMaxBackoffMillis() {\n    return subscribeToShardMaxBackoffMillis;\n}", "summary_tokens": ["get", "maximum", "backoff", "millis", "for", "the", "subscribe", "to", "shard", "operation"], "project": "flink"}
{"id": 9488, "code": "public void awaitBlocker() throws InterruptedException {\n    synchronized (lock) {\n        while (!blockerReady) {\n            lock.wait();\n        }\n    }\n}", "summary_tokens": ["waits", "until", "the", "blocking", "thread", "has", "entered", "the", "method", "block", "or", "block", "non", "interruptible"], "project": "flink"}
{"id": 7977, "code": "public static Builder newInstance() {\n    return new Builder();\n}", "summary_tokens": ["creates", "a", "builder", "for", "creating", "an", "instance", "of", "environment", "settings"], "project": "flink"}
{"id": 8173, "code": "public static TypeInformation<java.time.LocalTime> LOCAL_TIME() {\n    return org.apache.flink.api.common.typeinfo.Types.LOCAL_TIME;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "local", "time", "type"], "project": "flink"}
{"id": 728, "code": "public void testAssignedToPartitionEventTime() throws Exception {\n    testAssignedToPartition(100000, EventTime);\n}", "summary_tokens": ["to", "test", "data", "is", "partitioned", "to", "the", "right", "partition", "with", "time", "characteristic", "event", "time"], "project": "flink"}
{"id": 8503, "code": "default String explainSource() {\n    return TableConnectorUtils.generateRuntimeName(\n            getClass(), getTableSchema().getFieldNames());\n}", "summary_tokens": ["describes", "the", "table", "source"], "project": "flink"}
{"id": 5791, "code": "public void testCheckLimitForEmptyBlob() {\n    List<Tuple2<JobID, BlobKey>> keys = tracker.checkLimit(0L);\n\n    assertEquals(0, keys.size());\n}", "summary_tokens": ["if", "an", "empty", "blob", "is", "intended", "to", "be", "stored", "no", "blobs", "should", "be", "removed"], "project": "flink"}
{"id": 2110, "code": "public static <IN, OUT> CompletableFuture<OUT> handleAsyncIfNotDone(\n        CompletableFuture<IN> completableFuture,\n        Executor executor,\n        BiFunction<? super IN, Throwable, ? extends OUT> handler) {\n    return completableFuture.isDone()\n            ? completableFuture.handle(handler)\n            : completableFuture.handleAsync(handler, executor);\n}", "summary_tokens": ["this", "function", "takes", "a", "completable", "future", "and", "a", "handler", "function", "for", "the", "result", "of", "this", "future"], "project": "flink"}
{"id": 8781, "code": "protected void checkTypeAssignment(\n        SqlValidatorScope sourceScope,\n        SqlValidatorTable table,\n        RelDataType sourceRowType,\n        RelDataType targetRowType,\n        final SqlNode query) {\n        \n        \n        \n    boolean isUpdateModifiableViewTable = false;\n    if (query instanceof SqlUpdate) {\n        final SqlNodeList targetColumnList = ((SqlUpdate) query).getTargetColumnList();\n        if (targetColumnList != null) {\n            final int targetColumnCnt = targetColumnList.size();\n            targetRowType =\n                    SqlTypeUtil.extractLastNFields(typeFactory, targetRowType, targetColumnCnt);\n            sourceRowType =\n                    SqlTypeUtil.extractLastNFields(typeFactory, sourceRowType, targetColumnCnt);\n        }\n        isUpdateModifiableViewTable = table.unwrap(ModifiableViewTable.class) != null;\n    }\n    if (SqlTypeUtil.equalAsStructSansNullability(\n            typeFactory, sourceRowType, targetRowType, null)) {\n            \n        return;\n    }\n    if (config.typeCoercionEnabled() && !isUpdateModifiableViewTable) {\n            \n        boolean coerced =\n                typeCoercion.querySourceCoercion(\n                        sourceScope, sourceRowType, targetRowType, query);\n        if (coerced) {\n            return;\n        }\n    }\n\n        \n    List<RelDataTypeField> sourceFields = sourceRowType.getFieldList();\n    List<RelDataTypeField> targetFields = targetRowType.getFieldList();\n    final int sourceCount = sourceFields.size();\n    for (int i = 0; i < sourceCount; ++i) {\n        RelDataType sourceType = sourceFields.get(i).getType();\n        RelDataType targetType = targetFields.get(i).getType();\n        if (!SqlTypeUtil.canAssignFrom(targetType, sourceType)) {\n            SqlNode node = getNthExpr(query, i, sourceCount);\n            if (node instanceof SqlDynamicParam) {\n                continue;\n            }\n            String targetTypeString;\n            String sourceTypeString;\n            if (SqlTypeUtil.areCharacterSetsMismatched(sourceType, targetType)) {\n                sourceTypeString = sourceType.getFullTypeString();\n                targetTypeString = targetType.getFullTypeString();\n            } else {\n                sourceTypeString = sourceType.toString();\n                targetTypeString = targetType.toString();\n            }\n            throw newValidationError(\n                    node,\n                    RESOURCE.typeNotAssignable(\n                            targetFields.get(i).getName(), targetTypeString,\n                            sourceFields.get(i).getName(), sourceTypeString));\n        }\n    }\n}", "summary_tokens": ["checks", "the", "type", "assignment", "of", "an", "insert", "or", "update", "query"], "project": "flink"}
{"id": 5328, "code": "public static <T, SD extends ShuffleDescriptor> T applyWithShuffleTypeCheck(\n        Class<SD> shuffleDescriptorClass,\n        ShuffleDescriptor shuffleDescriptor,\n        Function<UnknownShuffleDescriptor, T> functionOfUnknownDescriptor,\n        Function<SD, T> functionOfKnownDescriptor) {\n    if (shuffleDescriptor.isUnknown()) {\n        return functionOfUnknownDescriptor.apply((UnknownShuffleDescriptor) shuffleDescriptor);\n    } else if (shuffleDescriptorClass.equals(shuffleDescriptor.getClass())) {\n        return functionOfKnownDescriptor.apply((SD) shuffleDescriptor);\n    } else {\n        throw new IllegalArgumentException(\n                String.format(\n                        \"Unsupported ShuffleDescriptor type <%s>, only <%s> is supported\",\n                        shuffleDescriptor.getClass().getName(),\n                        shuffleDescriptorClass.getName()));\n    }\n}", "summary_tokens": ["apply", "different", "functions", "to", "known", "and", "unknown", "shuffle", "descriptor", "s"], "project": "flink"}
{"id": 7765, "code": "public void testWindowSeparationAndFiring() throws Exception {\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(\n                    ContinuousEventTimeTrigger.<TimeWindow>of(Time.hours(1)),\n                    new TimeWindow.Serializer());\n\n        \n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n    assertEquals(2, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(4, testHarness.numEventTimeTimers());\n    assertEquals(2, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(2, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    Collection<Tuple2<TimeWindow, TriggerResult>> triggerResults =\n            testHarness.advanceWatermark(2);\n    boolean sawFiring = false;\n    for (Tuple2<TimeWindow, TriggerResult> r : triggerResults) {\n        if (r.f0.equals(new TimeWindow(0, 2))) {\n            sawFiring = true;\n            assertTrue(r.f1.equals(TriggerResult.FIRE));\n        }\n    }\n    assertTrue(sawFiring);\n\n    assertEquals(2, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(3, testHarness.numEventTimeTimers());\n    assertEquals(1, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(2, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    triggerResults = testHarness.advanceWatermark(4);\n    sawFiring = false;\n    for (Tuple2<TimeWindow, TriggerResult> r : triggerResults) {\n        if (r.f0.equals(new TimeWindow(2, 4))) {\n            sawFiring = true;\n            assertTrue(r.f1.equals(TriggerResult.FIRE));\n        }\n    }\n    assertTrue(sawFiring);\n\n    assertEquals(2, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(2, testHarness.numEventTimeTimers());\n}", "summary_tokens": ["verify", "that", "state", "lt", "time", "window", "gt", "of", "separate", "windows", "does", "not", "leak", "into", "other", "windows"], "project": "flink"}
{"id": 3597, "code": "public OptimizerNode getSource() {\n    return this.source;\n}", "summary_tokens": ["gets", "the", "source", "of", "the", "connection"], "project": "flink"}
{"id": 7466, "code": "public static Time hours(long hours) {\n    return of(hours, TimeUnit.HOURS);\n}", "summary_tokens": ["creates", "a", "new", "time", "that", "represents", "the", "given", "number", "of", "hours"], "project": "flink"}
{"id": 7851, "code": "private static void systemExit() {\n    SecurityManager securityManager = System.getSecurityManager();\n    if (securityManager != null) {\n        securityManager.checkExit(TEST_EXIT_CODE);\n    }\n}", "summary_tokens": ["perform", "the", "check", "system"], "project": "flink"}
{"id": 2915, "code": "public void testMaxByComparisonSpecialCase2() {\n    SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>> maxByTuple =\n            new SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>>(\n                    tupleTypeInfo, new int[] {0, 2, 1, 4, 3});\n\n    try {\n        Assert.assertSame(\n                \"SelectByMax must return bigger tuple\",\n                bigger,\n                maxByTuple.reduce(specialCaseBigger, bigger));\n        Assert.assertSame(\n                \"SelectByMax must return bigger tuple\",\n                bigger,\n                maxByTuple.reduce(bigger, specialCaseBigger));\n    } catch (Exception e) {\n        Assert.fail(\"No exception should be thrown while comparing both tuples\");\n    }\n}", "summary_tokens": ["this", "test", "cases", "checks", "when", "two", "tuples", "only", "differ", "in", "one", "value"], "project": "flink"}
{"id": 9630, "code": "public void testBroadcast() throws Exception {\n    int inputCount = 100000;\n    int parallelism = 4;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(parallelism);\n    env.getConfig().setLatencyTrackingInterval(2000);\n    env.setRestartStrategy(RestartStrategies.noRestart());\n\n    List<Integer> broadcastData =\n            IntStream.range(0, inputCount).boxed().collect(Collectors.toList());\n    DataStream<Integer> broadcastDataStream =\n            env.fromCollection(broadcastData).setParallelism(1);\n\n        \n\n    DataStream<String> streamWithoutData =\n            env.fromCollection(Collections.emptyList(), TypeInformation.of(String.class));\n\n    MapStateDescriptor<String, Integer> stateDescriptor =\n            new MapStateDescriptor<>(\n                    \"BroadcastState\",\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.INT_TYPE_INFO);\n\n    SingleOutputStreamOperator<Integer> processor =\n            streamWithoutData\n                    .connect(broadcastDataStream.broadcast(stateDescriptor))\n                    .process(\n                            new BroadcastProcessFunction<String, Integer, Integer>() {\n                                int expected = 0;\n\n                                public void processElement(\n                                        String value,\n                                        ReadOnlyContext ctx,\n                                        Collector<Integer> out) {}\n\n                                public void processBroadcastElement(\n                                        Integer value, Context ctx, Collector<Integer> out) {\n                                    if (value != expected++) {\n                                        throw new AssertionError(\n                                                String.format(\n                                                        \"Value was supposed to be: '%s', but was: '%s'\",\n                                                        expected - 1, value));\n                                    }\n                                    out.collect(value);\n                                }\n                            });\n\n    processor.addSink(new AccumulatorCountingSink<>()).setParallelism(1);\n\n    JobExecutionResult executionResult = env.execute();\n\n    Integer count =\n            executionResult.getAccumulatorResult(\n                    AccumulatorCountingSink.NUM_ELEMENTS_ACCUMULATOR);\n    Assert.assertEquals(inputCount * parallelism, count.intValue());\n}", "summary_tokens": ["flink", "0", "tests", "that", "streams", "are", "not", "corrupted", "records", "lost", "when", "using", "latency", "markers", "with", "broadcast"], "project": "flink"}
{"id": 5187, "code": "public static <R extends RequestBody, M extends MessageParameters> HandlerRequest<R> create(\n        R requestBody, M messageParameters, Collection<File> uploadedFiles) {\n    return new HandlerRequest<R>(\n            requestBody,\n            mapParameters(messageParameters.getPathParameters()),\n            mapParameters(messageParameters.getQueryParameters()),\n            uploadedFiles);\n}", "summary_tokens": ["creates", "a", "new", "handler", "request"], "project": "flink"}
{"id": 3999, "code": "public void testWrongGatewayEndpointConnection() throws Exception {\n    AkkaRpcActorTest.DummyRpcEndpoint rpcEndpoint =\n            new AkkaRpcActorTest.DummyRpcEndpoint(akkaRpcService1);\n\n    rpcEndpoint.start();\n\n    CompletableFuture<WrongRpcGateway> futureGateway =\n            akkaRpcService2.connect(rpcEndpoint.getAddress(), WrongRpcGateway.class);\n\n    try {\n        futureGateway.get(timeout.getSize(), timeout.getUnit());\n        fail(\"We expected a HandshakeException.\");\n    } catch (ExecutionException executionException) {\n        assertThat(\n                ExceptionUtils.stripExecutionException(executionException),\n                instanceOf(HandshakeException.class));\n    } finally {\n        RpcUtils.terminateRpcEndpoint(rpcEndpoint, timeout);\n    }\n}", "summary_tokens": ["tests", "that", "we", "receive", "a", "handshake", "exception", "when", "connecting", "to", "a", "rpc", "endpoint", "which", "does", "not", "support", "the", "requested", "rpc", "gateway"], "project": "flink"}
{"id": 7196, "code": "public void setTolerableCheckpointFailureNumber(int tolerableCheckpointFailureNumber) {\n    if (tolerableCheckpointFailureNumber < 0) {\n        throw new IllegalArgumentException(\n                \"The tolerable failure checkpoint number must be non-negative.\");\n    }\n    this.tolerableCheckpointFailureNumber = tolerableCheckpointFailureNumber;\n}", "summary_tokens": ["this", "defines", "how", "many", "consecutive", "checkpoint", "failures", "will", "be", "tolerated", "before", "the", "whole", "job", "is", "failed", "over"], "project": "flink"}
{"id": 8478, "code": "default Optional<FunctionDefinition> getFunctionDefinition(String name) {\n    return Optional.empty();\n}", "summary_tokens": ["get", "an", "optional", "of", "function", "definition", "by", "a", "given", "name"], "project": "flink"}
{"id": 5526, "code": "public Iterator<Integer> getStateServerPortRange() {\n    return qserverPortRange;\n}", "summary_tokens": ["returns", "the", "port", "range", "where", "the", "queryable", "state", "server", "can", "listen"], "project": "flink"}
{"id": 904, "code": "private <T extends OUT> PulsarSourceBuilder<T> specialized() {\n    return (PulsarSourceBuilder<T>) this;\n}", "summary_tokens": ["helper", "method", "for", "java", "compiler", "recognize", "the", "generic", "type"], "project": "flink"}
{"id": 4931, "code": "public static SslContext createRestNettySSLContext(\n        Configuration config, boolean clientMode, ClientAuth clientAuth, SslProvider provider)\n        throws Exception {\n    checkNotNull(config, \"config\");\n\n    if (!SecurityOptions.isRestSSLEnabled(config)) {\n        return null;\n    }\n\n    String[] sslProtocols = getEnabledProtocols(config);\n\n    final SslContextBuilder sslContextBuilder;\n    if (clientMode) {\n        sslContextBuilder = SslContextBuilder.forClient();\n        if (clientAuth != ClientAuth.NONE) {\n            KeyManagerFactory kmf = getKeyManagerFactory(config, false, provider);\n            sslContextBuilder.keyManager(kmf);\n        }\n    } else {\n        KeyManagerFactory kmf = getKeyManagerFactory(config, false, provider);\n        sslContextBuilder = SslContextBuilder.forServer(kmf);\n    }\n\n    if (clientMode || clientAuth != ClientAuth.NONE) {\n        TrustManagerFactory tmf = getTrustManagerFactory(config, false);\n        sslContextBuilder.trustManager(tmf);\n    }\n\n    return sslContextBuilder\n            .sslProvider(provider)\n            .protocols(sslProtocols)\n            .clientAuth(clientAuth)\n            .build();\n}", "summary_tokens": ["creates", "an", "ssl", "context", "for", "the", "external", "rest", "ssl"], "project": "flink"}
{"id": 7054, "code": "public <R> BroadcastConnectedStream<T, R> connect(BroadcastStream<R> broadcastStream) {\n    return new BroadcastConnectedStream<>(\n            environment,\n            this,\n            Preconditions.checkNotNull(broadcastStream),\n            broadcastStream.getBroadcastStateDescriptors());\n}", "summary_tokens": ["creates", "a", "new", "broadcast", "connected", "stream", "by", "connecting", "the", "current", "data", "stream", "or", "keyed", "stream", "with", "a", "broadcast", "stream"], "project": "flink"}
{"id": 9741, "code": "public void testClusterClientRetrievalOfFinishedYarnApplication() throws Exception {\n    final ApplicationId applicationId =\n            ApplicationId.newInstance(System.currentTimeMillis(), 42);\n    final ApplicationReport applicationReport =\n            createApplicationReport(\n                    applicationId,\n                    YarnApplicationState.FINISHED,\n                    FinalApplicationStatus.SUCCEEDED);\n\n    final YarnClient yarnClient =\n            new TestingYarnClient(Collections.singletonMap(applicationId, applicationReport));\n    final YarnConfiguration yarnConfiguration = new YarnConfiguration();\n    yarnClient.init(yarnConfiguration);\n    yarnClient.start();\n\n    final YarnClusterDescriptor clusterDescriptor =\n            YarnTestUtils.createClusterDescriptorWithLogging(\n                    temporaryFolder.newFolder().getAbsolutePath(),\n                    new Configuration(),\n                    yarnConfiguration,\n                    yarnClient,\n                    false);\n\n    try {\n        clusterDescriptor.retrieve(applicationId);\n    } finally {\n        clusterDescriptor.close();\n    }\n}", "summary_tokens": ["tests", "that", "the", "cluster", "retrieval", "of", "a", "finished", "yarn", "application", "fails"], "project": "flink"}
{"id": 5522, "code": "public void setTtlState(@Nonnull AbstractTtlState<K, N, ?, S, ?> ttlState) {\n    this.ttlState = ttlState;\n}", "summary_tokens": ["as", "ttl", "state", "wrapper", "depends", "on", "this", "class", "through", "access", "callback", "it", "has", "to", "be", "set", "here", "after", "its", "construction", "is", "done"], "project": "flink"}
{"id": 6002, "code": "public void testPut() throws IOException {\n    assertPutJobGraphWithStatus(JobStatus.FINISHED);\n}", "summary_tokens": ["tests", "that", "we", "can", "put", "execution", "graph", "info", "into", "the", "file", "execution", "graph", "info", "store", "and", "that", "the", "graph", "is", "persisted"], "project": "flink"}
{"id": 4598, "code": "NettyPartitionRequestClient createPartitionRequestClient(ConnectionID connectionId)\n        throws IOException, InterruptedException {\n    while (true) {\n        final CompletableFuture<NettyPartitionRequestClient> newClientFuture =\n                new CompletableFuture<>();\n\n        final CompletableFuture<NettyPartitionRequestClient> clientFuture =\n                clients.putIfAbsent(connectionId, newClientFuture);\n\n        final NettyPartitionRequestClient client;\n\n        if (clientFuture == null) {\n            try {\n                client = connectWithRetries(connectionId);\n            } catch (Throwable e) {\n                newClientFuture.completeExceptionally(\n                        new IOException(\"Could not create Netty client.\", e));\n                clients.remove(connectionId, newClientFuture);\n                throw e;\n            }\n\n            newClientFuture.complete(client);\n        } else {\n            try {\n                client = clientFuture.get();\n            } catch (ExecutionException e) {\n                ExceptionUtils.rethrowIOException(ExceptionUtils.stripExecutionException(e));\n                return null;\n            }\n        }\n\n            \n            \n        if (client.incrementReferenceCounter()) {\n            return client;\n        } else {\n            destroyPartitionRequestClient(connectionId, client);\n        }\n    }\n}", "summary_tokens": ["atomically", "establishes", "a", "tcp", "connection", "to", "the", "given", "remote", "address", "and", "creates", "a", "netty", "partition", "request", "client", "instance", "for", "this", "connection"], "project": "flink"}
{"id": 472, "code": "public static void setRecordToStatement(PreparedStatement upload, int[] typesArray, Row row)\n        throws SQLException {\n    if (typesArray != null && typesArray.length > 0 && typesArray.length != row.getArity()) {\n        LOG.warn(\n                \"Column SQL types array doesn't match arity of passed Row! Check the passed array...\");\n    }\n    if (typesArray == null) {\n            \n        for (int index = 0; index < row.getArity(); index++) {\n            LOG.warn(\n                    \"Unknown column type for column {}. Best effort approach to set its value: {}.\",\n                    index + 1,\n                    row.getField(index));\n            upload.setObject(index + 1, row.getField(index));\n        }\n    } else {\n            \n        for (int i = 0; i < row.getArity(); i++) {\n            setField(upload, typesArray[i], row.getField(i), i);\n        }\n    }\n}", "summary_tokens": ["adds", "a", "record", "to", "the", "prepared", "statement"], "project": "flink"}
{"id": 4328, "code": "public Configuration getSystemProperties() {\n    return systemProperties;\n}", "summary_tokens": ["get", "the", "system", "properties"], "project": "flink"}
{"id": 9070, "code": "public static Matcher<Operation> isCreateTableOperation(\n        Matcher<CreateTableOperation>... nestedMatchers) {\n    return new CreateTableOperationMatcher(nestedMatchers);\n}", "summary_tokens": ["checks", "for", "a", "create", "table", "operation"], "project": "flink"}
{"id": 6228, "code": "public void testGetNextAfterPartitionReleased() throws Exception {\n    ResultSubpartitionView subpartitionView =\n            InputChannelTestUtils.createResultSubpartitionView(false);\n    TestingResultPartitionManager partitionManager =\n            new TestingResultPartitionManager(subpartitionView);\n    LocalInputChannel channel =\n            createLocalInputChannel(new SingleInputGateBuilder().build(), partitionManager);\n\n    channel.requestSubpartition(0);\n    assertFalse(channel.getNextBuffer().isPresent());\n\n        \n    subpartitionView.releaseAllResources();\n\n    try {\n        channel.getNextBuffer();\n        fail(\"Did not throw expected CancelTaskException\");\n    } catch (CancelTaskException ignored) {\n    }\n\n    channel.releaseAllResources();\n    assertFalse(channel.getNextBuffer().isPresent());\n}", "summary_tokens": ["tests", "that", "reading", "from", "a", "channel", "when", "after", "the", "partition", "has", "been", "released", "are", "handled", "and", "don", "t", "lead", "to", "npes"], "project": "flink"}
{"id": 4244, "code": "public TaskAcknowledgeResult acknowledgeTask(\n        ExecutionAttemptID executionAttemptId,\n        TaskStateSnapshot operatorSubtaskStates,\n        CheckpointMetrics metrics,\n        @Nullable PendingCheckpointStats statsCallback) {\n\n    synchronized (lock) {\n        if (disposed) {\n            return TaskAcknowledgeResult.DISCARDED;\n        }\n\n        final ExecutionVertex vertex = notYetAcknowledgedTasks.remove(executionAttemptId);\n\n        if (vertex == null) {\n            if (acknowledgedTasks.contains(executionAttemptId)) {\n                return TaskAcknowledgeResult.DUPLICATE;\n            } else {\n                return TaskAcknowledgeResult.UNKNOWN;\n            }\n        } else {\n            acknowledgedTasks.add(executionAttemptId);\n        }\n\n        long ackTimestamp = System.currentTimeMillis();\n        if (operatorSubtaskStates != null && operatorSubtaskStates.isTaskDeployedAsFinished()) {\n            checkpointPlan.reportTaskFinishedOnRestore(vertex);\n        } else {\n            List<OperatorIDPair> operatorIDs = vertex.getJobVertex().getOperatorIDs();\n            for (OperatorIDPair operatorID : operatorIDs) {\n                updateOperatorState(vertex, operatorSubtaskStates, operatorID);\n            }\n\n            if (operatorSubtaskStates != null && operatorSubtaskStates.isTaskFinished()) {\n                checkpointPlan.reportTaskHasFinishedOperators(vertex);\n            }\n        }\n\n        ++numAcknowledgedTasks;\n\n            \n            \n        if (statsCallback != null) {\n                \n            long alignmentDurationMillis = metrics.getAlignmentDurationNanos() / 1_000_000;\n            long checkpointStartDelayMillis =\n                    metrics.getCheckpointStartDelayNanos() / 1_000_000;\n\n            SubtaskStateStats subtaskStateStats =\n                    new SubtaskStateStats(\n                            vertex.getParallelSubtaskIndex(),\n                            ackTimestamp,\n                            metrics.getTotalBytesPersisted(),\n                            metrics.getSyncDurationMillis(),\n                            metrics.getAsyncDurationMillis(),\n                            metrics.getBytesProcessedDuringAlignment(),\n                            metrics.getBytesPersistedDuringAlignment(),\n                            alignmentDurationMillis,\n                            checkpointStartDelayMillis,\n                            metrics.getUnalignedCheckpoint(),\n                            true);\n\n            LOG.trace(\n                    \"Checkpoint {} stats for {}: size={}Kb, duration={}ms, sync part={}ms, async part={}ms\",\n                    checkpointId,\n                    vertex.getTaskNameWithSubtaskIndex(),\n                    subtaskStateStats.getStateSize() == 0\n                            ? 0\n                            : subtaskStateStats.getStateSize() / 1024,\n                    subtaskStateStats.getEndToEndDuration(statsCallback.getTriggerTimestamp()),\n                    subtaskStateStats.getSyncCheckpointDuration(),\n                    subtaskStateStats.getAsyncCheckpointDuration());\n            statsCallback.reportSubtaskStats(vertex.getJobvertexId(), subtaskStateStats);\n        }\n\n        return TaskAcknowledgeResult.SUCCESS;\n    }\n}", "summary_tokens": ["acknowledges", "the", "task", "with", "the", "given", "execution", "attempt", "id", "and", "the", "given", "subtask", "state"], "project": "flink"}
{"id": 8733, "code": "private static RexNode simplifyBooleanCaseGeneric(\n        RexBuilder rexBuilder, List<CaseBranch> branches) {\n\n    boolean booleanBranches =\n            branches.stream()\n                    .allMatch(\n                            branch ->\n                                    branch.value.isAlwaysTrue()\n                                            || branch.value.isAlwaysFalse());\n    final List<RexNode> terms = new ArrayList<>();\n    final List<RexNode> notTerms = new ArrayList<>();\n    for (CaseBranch branch : branches) {\n        boolean useBranch = !branch.value.isAlwaysFalse();\n        if (useBranch) {\n            final RexNode branchTerm;\n            if (branch.value.isAlwaysTrue()) {\n                branchTerm = branch.cond;\n            } else {\n                branchTerm =\n                        rexBuilder.makeCall(SqlStdOperatorTable.AND, branch.cond, branch.value);\n            }\n            terms.add(RexUtil.andNot(rexBuilder, branchTerm, notTerms));\n        }\n        if (booleanBranches && useBranch) {\n                \n                \n        } else {\n            notTerms.add(branch.cond);\n        }\n    }\n    return RexUtil.composeDisjunction(rexBuilder, terms);\n}", "summary_tokens": ["generic", "boolean", "case", "simplification"], "project": "flink"}
{"id": 6583, "code": "public void testValueStateNullUpdate() throws Exception {\n        \n        \n    try {\n        LongSerializer.INSTANCE.serialize(\n                null, new DataOutputViewStreamWrapper(new ByteArrayOutputStream()));\n        fail(\"Should fail with NullPointerException\");\n    } catch (NullPointerException e) {\n            \n    }\n\n    CheckpointStreamFactory streamFactory = createStreamFactory();\n    SharedStateRegistry sharedStateRegistry = new SharedStateRegistryImpl();\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n    try {\n        ValueStateDescriptor<Long> kvId =\n                new ValueStateDescriptor<>(\"id\", LongSerializer.INSTANCE, 42L);\n\n        ValueState<Long> state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n            \n        backend.setCurrentKey(1);\n\n            \n        assertEquals(42L, (long) state.value());\n        state.update(1L);\n        assertEquals(1L, (long) state.value());\n\n        backend.setCurrentKey(2);\n        assertEquals(42L, (long) state.value());\n\n        backend.setCurrentKey(1);\n        state.clear();\n        assertEquals(42L, (long) state.value());\n\n        state.update(17L);\n        assertEquals(17L, (long) state.value());\n\n        state.update(null);\n        assertEquals(42L, (long) state.value());\n\n            \n        KeyedStateHandle snapshot1 =\n                runSnapshot(\n                        backend.snapshot(\n                                682375462378L,\n                                2,\n                                streamFactory,\n                                CheckpointOptions.forCheckpointWithDefaultLocation()),\n                        sharedStateRegistry);\n\n        backend.dispose();\n        backend = restoreKeyedBackend(IntSerializer.INSTANCE, snapshot1);\n\n        snapshot1.discardState();\n\n        backend.getPartitionedState(\n                VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n    } finally {\n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["this", "test", "verifies", "that", "passing", "null", "to", "value", "state", "update", "object", "acts", "the", "same", "as", "value", "state", "clear"], "project": "flink"}
{"id": 7989, "code": "public OverWindowPartitionedOrdered orderBy(Expression orderBy) {\n    return new OverWindowPartitionedOrdered(partitionBy, orderBy);\n}", "summary_tokens": ["specifies", "the", "time", "attribute", "on", "which", "rows", "are", "ordered"], "project": "flink"}
{"id": 5413, "code": "public boolean isSnapshotCompleted() {\n    return State.COMPLETED == state.get();\n}", "summary_tokens": ["returns", "code", "true", "code", "if", "the", "snapshot", "is", "marked", "as", "completed"], "project": "flink"}
{"id": 7793, "code": "public Collection<Tuple2<W, TriggerResult>> advanceWatermark(long time) throws Exception {\n    Collection<TestInternalTimerService.Timer<Integer, W>> firedTimers =\n            internalTimerService.advanceWatermark(time);\n\n    Collection<Tuple2<W, TriggerResult>> result = new ArrayList<>();\n\n    for (TestInternalTimerService.Timer<Integer, W> timer : firedTimers) {\n        TriggerResult triggerResult = invokeOnEventTime(timer);\n        result.add(new Tuple2<>(timer.getNamespace(), triggerResult));\n    }\n\n    return result;\n}", "summary_tokens": ["advanced", "the", "watermark", "and", "processes", "any", "timers", "that", "fire", "because", "of", "this"], "project": "flink"}
{"id": 4325, "code": "public List<Artifact> getArtifacts() {\n    return artifacts;\n}", "summary_tokens": ["get", "the", "container", "artifacts"], "project": "flink"}
{"id": 700, "code": "public void runEndOfStreamTest() throws Exception {\n\n    final int elementCount = 300;\n    final String topic = writeSequence(\"testEndOfStream\", elementCount, 1, 1);\n\n        \n    final StreamExecutionEnvironment env1 =\n            StreamExecutionEnvironment.getExecutionEnvironment();\n    env1.setParallelism(1);\n    env1.getConfig().setRestartStrategy(RestartStrategies.noRestart());\n\n    Properties props = new Properties();\n    props.putAll(standardProps);\n    props.putAll(secureProps);\n    DataStream<Tuple2<Integer, Integer>> fromKafka =\n            getStream(env1, topic, new FixedNumberDeserializationSchema(elementCount), props);\n\n    fromKafka.flatMap(\n            new FlatMapFunction<Tuple2<Integer, Integer>, Void>() {\n                @Override\n                public void flatMap(Tuple2<Integer, Integer> value, Collector<Void> out)\n                        throws Exception {\n                        \n                }\n            });\n\n    tryExecute(env1, \"Consume \" + elementCount + \" elements from Kafka\");\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["test", "that", "ensures", "that", "deserialization", "schema"], "project": "flink"}
{"id": 7444, "code": "public static <T> DynamicEventTimeSessionWindows<T> withDynamicGap(\n        SessionWindowTimeGapExtractor<T> sessionWindowTimeGapExtractor) {\n    return new DynamicEventTimeSessionWindows<>(sessionWindowTimeGapExtractor);\n}", "summary_tokens": ["creates", "a", "new", "session", "windows", "window", "assigner", "that", "assigns", "elements", "to", "sessions", "based", "on", "the", "element", "timestamp"], "project": "flink"}
{"id": 1775, "code": "public void putCharBigEndian(int index, char value) {\n    if (LITTLE_ENDIAN) {\n        putChar(index, Character.reverseBytes(value));\n    } else {\n        putChar(index, value);\n    }\n}", "summary_tokens": ["writes", "the", "given", "character", "0", "bit", "0", "bytes", "to", "the", "given", "position", "in", "big", "endian", "byte", "order"], "project": "flink"}
{"id": 5320, "code": "public static Pair<Integer, Integer> getMinMaxFloatingBuffersPerInputGate(\n        final int numFloatingBuffersPerGate) {\n        \n    return Pair.of(1, numFloatingBuffersPerGate);\n}", "summary_tokens": ["calculates", "and", "returns", "the", "floating", "network", "buffer", "pool", "size", "used", "by", "the", "input", "gate"], "project": "flink"}
{"id": 3943, "code": "public void testSimpleQuery() throws Exception {\n    KvStateRegistry registry = new KvStateRegistry();\n    AtomicKvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n    MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    KvStateServerHandler handler =\n            new KvStateServerHandler(testServer, registry, serializer, stats);\n    EmbeddedChannel channel = new EmbeddedChannel(getFrameDecoder(), handler);\n\n        \n    ValueStateDescriptor<Integer> desc =\n            new ValueStateDescriptor<>(\"any\", IntSerializer.INSTANCE);\n    desc.setQueryable(\"vanilla\");\n\n    int numKeyGroups = 1;\n    AbstractStateBackend abstractBackend = new MemoryStateBackend();\n    DummyEnvironment dummyEnv = new DummyEnvironment(\"test\", 1, 0);\n    dummyEnv.setKvStateRegistry(registry);\n    AbstractKeyedStateBackend<Integer> backend =\n            createKeyedStateBackend(registry, numKeyGroups, abstractBackend, dummyEnv);\n\n    final TestRegistryListener registryListener = new TestRegistryListener();\n    registry.registerListener(dummyEnv.getJobID(), registryListener);\n\n        \n    int expectedValue = 712828289;\n\n    int key = 99812822;\n    backend.setCurrentKey(key);\n    ValueState<Integer> state =\n            backend.getPartitionedState(\n                    VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, desc);\n\n    state.update(expectedValue);\n\n    byte[] serializedKeyAndNamespace =\n            KvStateSerializer.serializeKeyAndNamespace(\n                    key,\n                    IntSerializer.INSTANCE,\n                    VoidNamespace.INSTANCE,\n                    VoidNamespaceSerializer.INSTANCE);\n\n    long requestId = Integer.MAX_VALUE + 182828L;\n\n    assertTrue(registryListener.registrationName.equals(\"vanilla\"));\n\n    KvStateInternalRequest request =\n            new KvStateInternalRequest(registryListener.kvStateId, serializedKeyAndNamespace);\n\n    ByteBuf serRequest =\n            MessageSerializer.serializeRequest(channel.alloc(), requestId, request);\n\n        \n    channel.writeInbound(serRequest);\n\n    ByteBuf buf = (ByteBuf) readInboundBlocking(channel);\n    buf.skipBytes(4); \n\n        \n    assertEquals(MessageType.REQUEST_RESULT, MessageSerializer.deserializeHeader(buf));\n    long deserRequestId = MessageSerializer.getRequestId(buf);\n    KvStateResponse response = serializer.deserializeResponse(buf);\n    buf.release();\n\n    assertEquals(requestId, deserRequestId);\n\n    int actualValue =\n            KvStateSerializer.deserializeValue(response.getContent(), IntSerializer.INSTANCE);\n    assertEquals(expectedValue, actualValue);\n\n    assertEquals(stats.toString(), 1, stats.getNumRequests());\n\n        \n    long deadline = System.nanoTime() + TimeUnit.NANOSECONDS.convert(30, TimeUnit.SECONDS);\n    while (stats.getNumSuccessful() != 1L && System.nanoTime() <= deadline) {\n        Thread.sleep(10L);\n    }\n\n    assertEquals(stats.toString(), 1L, stats.getNumSuccessful());\n}", "summary_tokens": ["tests", "a", "simple", "successful", "query", "via", "an", "embedded", "channel"], "project": "flink"}
{"id": 7654, "code": "private <T> List<T> extractResult(OneInputStreamOperatorTestHarness<?, T> testHarness) {\n    List<StreamRecord<? extends T>> streamRecords = testHarness.extractOutputStreamRecords();\n    List<T> result = new ArrayList<>();\n    for (Object in : streamRecords) {\n        if (in instanceof StreamRecord) {\n            result.add((T) ((StreamRecord) in).getValue());\n        }\n    }\n    testHarness.getOutput().clear();\n    return result;\n}", "summary_tokens": ["extracts", "the", "result", "values", "form", "the", "test", "harness", "and", "clear", "the", "output", "queue"], "project": "flink"}
{"id": 2656, "code": "public <R> CoGroupOperator.CoGroupOperatorSets<T, R> coGroup(DataSet<R> other) {\n    return new CoGroupOperator.CoGroupOperatorSets<>(this, other);\n}", "summary_tokens": ["initiates", "a", "co", "group", "transformation"], "project": "flink"}
{"id": 6197, "code": "public void testEnqueueReaderByNotifyingBufferAndCredit() throws Exception {\n        \n    final ResultSubpartitionView view = new DefaultBufferResultSubpartitionView(10);\n\n    ResultPartitionProvider partitionProvider =\n            (partitionId, index, availabilityListener) -> view;\n\n    final InputChannelID receiverId = new InputChannelID();\n    final PartitionRequestQueue queue = new PartitionRequestQueue();\n    final CreditBasedSequenceNumberingViewReader reader =\n            new CreditBasedSequenceNumberingViewReader(receiverId, 2, queue);\n    final EmbeddedChannel channel = new EmbeddedChannel(queue);\n    reader.addCredit(-2);\n\n    reader.requestSubpartitionView(partitionProvider, new ResultPartitionID(), 0);\n    queue.notifyReaderCreated(reader);\n\n        \n    ByteBuf channelBlockingBuffer = blockChannel(channel);\n    assertNull(channel.readOutbound());\n\n        \n    final int notifyNumBuffers = 5;\n    for (int i = 0; i < notifyNumBuffers; i++) {\n        reader.notifyDataAvailable();\n    }\n\n    channel.runPendingTasks();\n\n        \n        \n    assertEquals(0, queue.getAvailableReaders().size());\n    assertTrue(reader.hasBuffersAvailable().isAvailable());\n    assertFalse(reader.isRegisteredAsAvailable());\n    assertEquals(0, reader.getNumCreditsAvailable());\n\n        \n    final int notifyNumCredits = 3;\n    for (int i = 1; i <= notifyNumCredits; i++) {\n        queue.addCreditOrResumeConsumption(receiverId, viewReader -> viewReader.addCredit(1));\n\n            \n            \n            \n            \n            \n        assertTrue(reader.isRegisteredAsAvailable());\n        assertThat(queue.getAvailableReaders(), contains(reader)); \n        assertEquals(i, reader.getNumCreditsAvailable());\n        assertTrue(reader.hasBuffersAvailable().isAvailable());\n    }\n\n        \n    channel.flush();\n    assertSame(channelBlockingBuffer, channel.readOutbound());\n\n    assertEquals(0, queue.getAvailableReaders().size());\n    assertEquals(0, reader.getNumCreditsAvailable());\n    assertTrue(reader.hasBuffersAvailable().isAvailable());\n    assertFalse(reader.isRegisteredAsAvailable());\n    for (int i = 1; i <= notifyNumCredits; i++) {\n        assertThat(channel.readOutbound(), instanceOf(NettyMessage.BufferResponse.class));\n    }\n    assertNull(channel.readOutbound());\n}", "summary_tokens": ["tests", "partition", "request", "queue", "enqueue", "available", "reader", "network", "sequence", "view", "reader", "verifying", "the", "reader", "would", "be", "enqueued", "in", "the", "pipeline", "iff", "it", "has", "both", "available", "credits", "and", "buffers"], "project": "flink"}
{"id": 7797, "code": "public void testNoLateSideOutputForSkippedWindows() throws Exception {\n\n    OutputTag<Integer> lateOutputTag = new OutputTag<Integer>(\"late\") {};\n\n    WindowAssigner<Integer, TimeWindow> mockAssigner = mockTimeWindowAssigner();\n    Trigger<Integer, TimeWindow> mockTrigger = mockTrigger();\n    InternalWindowFunction<Iterable<Integer>, Void, Integer, TimeWindow> mockWindowFunction =\n            mockWindowFunction();\n\n    OneInputStreamOperatorTestHarness<Integer, Void> testHarness =\n            createWindowOperator(\n                    mockAssigner, mockTrigger, 0L, mockWindowFunction, lateOutputTag);\n\n    testHarness.open();\n\n    when(mockAssigner.assignWindows(anyInt(), anyLong(), anyAssignerContext()))\n            .thenReturn(Collections.<TimeWindow>emptyList());\n\n    testHarness.processWatermark(0);\n    testHarness.processElement(new StreamRecord<>(0, 5L));\n\n    verify(mockAssigner, times(1)).assignWindows(eq(0), eq(5L), anyAssignerContext());\n\n    assertTrue(\n            testHarness.getSideOutput(lateOutputTag) == null\n                    || testHarness.getSideOutput(lateOutputTag).isEmpty());\n}", "summary_tokens": ["verify", "that", "there", "is", "no", "late", "data", "side", "output", "if", "the", "window", "assigner", "does", "not", "assign", "any", "windows"], "project": "flink"}
{"id": 6987, "code": "public RocksDBRestoreResult restore()\n        throws IOException, StateMigrationException, RocksDBException {\n    rocksHandle.openDB();\n    try (ThrowingIterator<SavepointRestoreResult> restore =\n            savepointRestoreOperation.restore()) {\n        while (restore.hasNext()) {\n            applyRestoreResult(restore.next());\n        }\n    }\n    return new RocksDBRestoreResult(\n            this.rocksHandle.getDb(),\n            this.rocksHandle.getDefaultColumnFamilyHandle(),\n            this.rocksHandle.getNativeMetricMonitor(),\n            -1,\n            null,\n            null);\n}", "summary_tokens": ["restores", "all", "key", "groups", "data", "that", "is", "referenced", "by", "the", "passed", "state", "handles"], "project": "flink"}
{"id": 5986, "code": "public static ComponentMainThreadExecutor forSingleThreadExecutor(\n        @Nonnull ScheduledExecutorService singleThreadExecutor) {\n    final Thread thread =\n            CompletableFuture.supplyAsync(Thread::currentThread, singleThreadExecutor).join();\n    return new ComponentMainThreadExecutorServiceAdapter(singleThreadExecutor, thread);\n}", "summary_tokens": ["creates", "a", "test", "executor", "that", "delegates", "to", "the", "given", "scheduled", "executor", "service"], "project": "flink"}
{"id": 529, "code": "private PartitionSplitChange initializePartitionSplits(PartitionChange partitionChange) {\n    Set<TopicPartition> newPartitions =\n            Collections.unmodifiableSet(partitionChange.getNewPartitions());\n    OffsetsInitializer.PartitionOffsetsRetriever offsetsRetriever = getOffsetsRetriever();\n\n    Map<TopicPartition, Long> startingOffsets =\n            startingOffsetInitializer.getPartitionOffsets(newPartitions, offsetsRetriever);\n    Map<TopicPartition, Long> stoppingOffsets =\n            stoppingOffsetInitializer.getPartitionOffsets(newPartitions, offsetsRetriever);\n\n    Set<KafkaPartitionSplit> partitionSplits = new HashSet<>(newPartitions.size());\n    for (TopicPartition tp : newPartitions) {\n        Long startingOffset = startingOffsets.get(tp);\n        long stoppingOffset =\n                stoppingOffsets.getOrDefault(tp, KafkaPartitionSplit.NO_STOPPING_OFFSET);\n        partitionSplits.add(new KafkaPartitionSplit(tp, startingOffset, stoppingOffset));\n    }\n    return new PartitionSplitChange(partitionSplits, partitionChange.getRemovedPartitions());\n}", "summary_tokens": ["initialize", "splits", "for", "newly", "discovered", "partitions"], "project": "flink"}
{"id": 8359, "code": "public BinaryStringData substring(int beginIndex, int endIndex) {\n    ensureMaterialized();\n    if (endIndex <= beginIndex || beginIndex >= binarySection.sizeInBytes) {\n        return EMPTY_UTF8;\n    }\n    if (inFirstSegment()) {\n        MemorySegment segment = binarySection.segments[0];\n        int i = 0;\n        int c = 0;\n        while (i < binarySection.sizeInBytes && c < beginIndex) {\n            i += numBytesForFirstByte(segment.get(i + binarySection.offset));\n            c += 1;\n        }\n\n        int j = i;\n        while (i < binarySection.sizeInBytes && c < endIndex) {\n            i += numBytesForFirstByte(segment.get(i + binarySection.offset));\n            c += 1;\n        }\n\n        if (i > j) {\n            byte[] bytes = new byte[i - j];\n            segment.get(binarySection.offset + j, bytes, 0, i - j);\n            return fromBytes(bytes);\n        } else {\n            return EMPTY_UTF8;\n        }\n    } else {\n        return substringMultiSegs(beginIndex, endIndex);\n    }\n}", "summary_tokens": ["returns", "a", "binary", "string", "that", "is", "a", "substring", "of", "this", "binary", "string"], "project": "flink"}
{"id": 7750, "code": "public void testLatencyMarkEmissionEnabledViaExecutionConfig() throws Exception {\n\n    Configuration taskConfiguration = new Configuration();\n    ExecutionConfig executionConfig = new ExecutionConfig();\n    executionConfig.setLatencyTrackingInterval(LATENCY_MARK_INTERVAL);\n\n    testLatencyMarkEmission(true, taskConfiguration, executionConfig);\n}", "summary_tokens": ["verifies", "that", "latency", "metrics", "can", "be", "enabled", "via", "the", "execution", "config"], "project": "flink"}
{"id": 2942, "code": "public void testCustomKeyFieldsGrouping() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n    this.customTypeData.add(new CustomType());\n\n    UnsortedGrouping<CustomType> groupDs = env.fromCollection(customTypeData).groupBy(0);\n        \n    groupDs.minBy(0);\n}", "summary_tokens": ["this", "test", "validates", "that", "an", "invalid", "program", "exception", "is", "thrown", "when", "min", "by", "is", "used", "on", "a", "custom", "data", "type"], "project": "flink"}
{"id": 8738, "code": "private RexNode simplifyCeilFloor(RexCall e) {\n    if (e.getOperands().size() != 2) {\n            \n        return e;\n    }\n    final RexNode operand = simplify(e.getOperands().get(0), UNKNOWN);\n    if (e.getKind() == operand.getKind()) {\n        assert e.getKind() == SqlKind.CEIL || e.getKind() == SqlKind.FLOOR;\n            \n        final RexCall child = (RexCall) operand;\n        if (child.getOperands().size() != 2) {\n                \n            return e;\n        }\n        final RexLiteral parentFlag = (RexLiteral) e.operands.get(1);\n        final TimeUnitRange parentFlagValue = (TimeUnitRange) parentFlag.getValue();\n        final RexLiteral childFlag = (RexLiteral) child.operands.get(1);\n        final TimeUnitRange childFlagValue = (TimeUnitRange) childFlag.getValue();\n        if (parentFlagValue != null && childFlagValue != null) {\n            if (canRollUp(parentFlagValue.startUnit, childFlagValue.startUnit)) {\n                return e.clone(\n                        e.getType(), ImmutableList.of(child.getOperands().get(0), parentFlag));\n            }\n        }\n    }\n    return e.clone(e.getType(), ImmutableList.of(operand, e.getOperands().get(1)));\n}", "summary_tokens": ["tries", "to", "simplify", "ceil", "floor", "function", "on", "top", "of", "ceil", "floor"], "project": "flink"}
{"id": 3454, "code": "public <K, T, OUT> DataStream<OUT> reduce(\n        String uid,\n        ReduceFunction<T> function,\n        WindowReaderFunction<T, OUT, K, W> readerFunction,\n        TypeInformation<K> keyType,\n        TypeInformation<T> reduceType,\n        TypeInformation<OUT> outputType)\n        throws IOException {\n\n    WindowReaderOperator<?, K, StreamRecord<T>, W, OUT> operator =\n            WindowReaderOperator.evictingWindow(\n                    new ReduceEvictingWindowReaderFunction<>(readerFunction, function),\n                    keyType,\n                    windowSerializer,\n                    reduceType,\n                    env.getConfig());\n\n    return readWindowOperator(uid, outputType, operator);\n}", "summary_tokens": ["reads", "window", "state", "generated", "using", "a", "reduce", "function"], "project": "flink"}
{"id": 7559, "code": "protected Iterable<StreamOperatorWrapper<?, ?>> getAllOperators(boolean reverse) {\n    return reverse\n            ? new StreamOperatorWrapper.ReadIterator(tailOperatorWrapper, true)\n            : new StreamOperatorWrapper.ReadIterator(mainOperatorWrapper, false);\n}", "summary_tokens": ["returns", "an", "iterable", "which", "traverses", "all", "operators", "in", "forward", "or", "reverse", "topological", "order"], "project": "flink"}
{"id": 9065, "code": "private synchronized void update(String testCaseName, String resourceName, String value) {\n    final List<Pair<String, Element>> map = new ArrayList<>();\n    Element testCaseElement = getTestCaseElement(testCaseName, true, map);\n    if (testCaseElement == null) {\n        testCaseElement = doc.createElement(TEST_CASE_TAG);\n        testCaseElement.setAttribute(TEST_CASE_NAME_ATTR, testCaseName);\n        Node refElement = ref(testCaseName, map);\n        root.insertBefore(testCaseElement, refElement);\n    }\n    Element resourceElement = getResourceElement(testCaseElement, resourceName, true);\n    if (resourceElement == null) {\n        resourceElement = doc.createElement(RESOURCE_TAG);\n        resourceElement.setAttribute(RESOURCE_NAME_ATTR, resourceName);\n        testCaseElement.appendChild(resourceElement);\n    } else {\n        removeAllChildren(resourceElement);\n    }\n    if (!value.equals(\"\")) {\n        resourceElement.appendChild(doc.createCDATASection(value));\n    }\n\n        \n    flushDoc();\n}", "summary_tokens": ["creates", "a", "new", "document", "with", "a", "given", "resource"], "project": "flink"}
{"id": 8047, "code": "public void unregisterCatalog(String catalogName, boolean ignoreIfNotExists) {\n    checkArgument(\n            !StringUtils.isNullOrWhitespaceOnly(catalogName),\n            \"Catalog name cannot be null or empty.\");\n\n    if (catalogs.containsKey(catalogName)) {\n        Catalog catalog = catalogs.remove(catalogName);\n        catalog.close();\n    } else if (!ignoreIfNotExists) {\n        throw new CatalogException(format(\"Catalog %s does not exist.\", catalogName));\n    }\n}", "summary_tokens": ["unregisters", "a", "catalog", "under", "the", "given", "name"], "project": "flink"}
{"id": 6324, "code": "public void testReporterArgumentForwarding() {\n    final Configuration config = new Configuration();\n\n    configureReporter1(config);\n\n    final List<ReporterSetup> reporterSetups = ReporterSetup.fromConfiguration(config, null);\n\n    Assert.assertEquals(1, reporterSetups.size());\n\n    final ReporterSetup reporterSetup = reporterSetups.get(0);\n    assertReporter1Configured(reporterSetup);\n}", "summary_tokens": ["verifies", "that", "a", "reporter", "can", "be", "configured", "with", "all", "it", "s", "arguments", "being", "forwarded"], "project": "flink"}
{"id": 7950, "code": "public SqlNodeList getStaticPartitions() {\n    return staticPartitions;\n}", "summary_tokens": ["the", "list", "of", "partition", "key", "value", "pairs", "returns", "empty", "if", "there", "is", "no", "partition", "specifications"], "project": "flink"}
{"id": 9638, "code": "public void testLegacyKeyedCoProcessFunctionSideOutput() throws Exception {\n    final OutputTag<String> sideOutputTag = new OutputTag<String>(\"side\") {};\n\n    TestListResultSink<String> sideOutputResultSink = new TestListResultSink<>();\n    TestListResultSink<Integer> resultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(3);\n\n    DataStream<Integer> ds1 = see.fromCollection(elements);\n    DataStream<Integer> ds2 = see.fromCollection(elements);\n\n    SingleOutputStreamOperator<Integer> passThroughtStream =\n            ds1.keyBy(i -> i)\n                    .connect(ds2.keyBy(i -> i))\n                    .process(\n                            new CoProcessFunction<Integer, Integer, Integer>() {\n                                @Override\n                                public void processElement1(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value < 3) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag,\n                                                \"sideout1-\" + String.valueOf(value));\n                                    }\n                                }\n\n                                @Override\n                                public void processElement2(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value >= 3) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag,\n                                                \"sideout2-\" + String.valueOf(value));\n                                    }\n                                }\n                            });\n\n    passThroughtStream.getSideOutput(sideOutputTag).addSink(sideOutputResultSink);\n    passThroughtStream.addSink(resultSink);\n    see.execute();\n\n    assertEquals(\n            Arrays.asList(\"sideout1-1\", \"sideout1-2\", \"sideout2-3\", \"sideout2-4\", \"sideout2-5\"),\n            sideOutputResultSink.getSortedResult());\n    assertEquals(Arrays.asList(1, 2, 3, 4, 5), resultSink.getSortedResult());\n}", "summary_tokens": ["test", "keyed", "co", "process", "function", "side", "output"], "project": "flink"}
{"id": 6039, "code": "public void testSuspendedOutOfCanceled() throws Exception {\n    final InteractionsCountingTaskManagerGateway gateway =\n            new InteractionsCountingTaskManagerGateway();\n    final int parallelism = 10;\n    final SchedulerBase scheduler = createScheduler(gateway, parallelism);\n    final ExecutionGraph eg = scheduler.getExecutionGraph();\n\n    scheduler.startScheduling();\n    ExecutionGraphTestUtils.switchAllVerticesToRunning(eg);\n\n    scheduler.cancel();\n\n    assertEquals(JobStatus.CANCELLING, eg.getState());\n    validateCancelRpcCalls(gateway, parallelism);\n\n    ExecutionGraphTestUtils.completeCancellingForAllVertices(eg);\n    assertEquals(JobStatus.CANCELED, eg.getTerminationFuture().get());\n\n        \n    scheduler.closeAsync();\n\n        \n    assertEquals(JobStatus.CANCELED, eg.getState());\n    validateCancelRpcCalls(gateway, parallelism);\n}", "summary_tokens": ["suspending", "from", "cancelled", "should", "do", "nothing"], "project": "flink"}
{"id": 518, "code": "public KafkaSourceBuilder<OUT> setStartingOffsets(\n        OffsetsInitializer startingOffsetsInitializer) {\n    this.startingOffsetsInitializer = startingOffsetsInitializer;\n    return this;\n}", "summary_tokens": ["specify", "from", "which", "offsets", "the", "kafka", "source", "should", "start", "consume", "from", "by", "providing", "an", "offsets", "initializer"], "project": "flink"}
{"id": 1474, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f5)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f6)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f7)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f8)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f9)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f10)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f11)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f12)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 9527, "code": "public static String getOSSEndpoint() {\n    if (ENDPOINT != null) {\n        return ENDPOINT;\n    } else {\n        throw new IllegalStateException(\"OSS endpoint is not available\");\n    }\n}", "summary_tokens": ["get", "oss", "endpoint", "used", "to", "connect"], "project": "flink"}
{"id": 731, "code": "public void testSerDeIngestionTime() throws Exception {\n    testRecordSerDe(IngestionTime);\n}", "summary_tokens": ["to", "test", "value", "and", "watermark", "serialization", "and", "deserialization", "with", "time", "characteristic", "ingestion", "time"], "project": "flink"}
{"id": 6984, "code": "public RocksDBRestoreResult restore()\n        throws IOException, StateMigrationException, RocksDBException {\n    rocksHandle.openDB();\n    try (ThrowingIterator<SavepointRestoreResult> restore =\n            savepointRestoreOperation.restore()) {\n        while (restore.hasNext()) {\n            applyRestoreResult(restore.next());\n        }\n    }\n    return new RocksDBRestoreResult(\n            this.rocksHandle.getDb(),\n            this.rocksHandle.getDefaultColumnFamilyHandle(),\n            this.rocksHandle.getNativeMetricMonitor(),\n            -1,\n            null,\n            null);\n}", "summary_tokens": ["restores", "all", "key", "groups", "data", "that", "is", "referenced", "by", "the", "passed", "state", "handles"], "project": "flink"}
{"id": 7443, "code": "public static EventTimeSessionWindows withGap(Time size) {\n    return new EventTimeSessionWindows(size.toMilliseconds());\n}", "summary_tokens": ["creates", "a", "new", "session", "windows", "window", "assigner", "that", "assigns", "elements", "to", "sessions", "based", "on", "the", "element", "timestamp"], "project": "flink"}
{"id": 8215, "code": "default Schema getUnresolvedSchema() {\n    final TableSchema oldSchema = getSchema();\n    if (oldSchema == null) {\n        throw new UnsupportedOperationException(\n                \"A CatalogBaseTable must implement getUnresolvedSchema().\");\n    }\n    return oldSchema.toSchema();\n}", "summary_tokens": ["returns", "the", "schema", "of", "the", "table", "or", "view"], "project": "flink"}
{"id": 8778, "code": "private void checkConstraint(\n        SqlValidatorTable validatorTable, SqlUpdate update, RelDataType targetRowType) {\n    final ModifiableViewTable modifiableViewTable =\n            validatorTable.unwrap(ModifiableViewTable.class);\n    if (modifiableViewTable != null) {\n        final Table table = modifiableViewTable.unwrap(Table.class);\n        final RelDataType tableRowType = table.getRowType(typeFactory);\n\n        final Map<Integer, RexNode> projectMap =\n                RelOptUtil.getColumnConstraints(\n                        modifiableViewTable, targetRowType, typeFactory);\n        final Map<String, Integer> nameToIndex =\n                SqlValidatorUtil.mapNameToIndex(tableRowType.getFieldList());\n\n            \n        final List<SqlNode> targets = update.getTargetColumnList().getList();\n        final List<SqlNode> sources = update.getSourceExpressionList().getList();\n        for (final Pair<SqlNode, SqlNode> column : Pair.zip(targets, sources)) {\n            final String columnName = ((SqlIdentifier) column.left).getSimple();\n            final Integer columnIndex = nameToIndex.get(columnName);\n            if (projectMap.containsKey(columnIndex)) {\n                final RexNode columnConstraint = projectMap.get(columnIndex);\n                final ValidationError validationError =\n                        new ValidationError(\n                                column.right,\n                                RESOURCE.viewConstraintNotSatisfied(\n                                        columnName,\n                                        Util.last(validatorTable.getQualifiedName())));\n                RelOptUtil.validateValueAgainstConstraint(\n                        column.right, columnConstraint, validationError);\n            }\n        }\n    }\n}", "summary_tokens": ["validates", "updates", "against", "the", "constraint", "of", "a", "modifiable", "view"], "project": "flink"}
{"id": 5969, "code": "public void testShutdownRemovesState() throws Exception {\n    ZooKeeperCheckpointIDCounter counter = createCheckpointIdCounter();\n    counter.start();\n\n    CuratorFramework client = ZooKeeper.getClient();\n    assertNotNull(client.checkExists().forPath(counter.getPath()));\n\n    counter.shutdown(JobStatus.FINISHED);\n    assertNull(client.checkExists().forPath(counter.getPath()));\n}", "summary_tokens": ["tests", "that", "counter", "node", "is", "removed", "from", "zoo", "keeper", "after", "shutdown"], "project": "flink"}
{"id": 4773, "code": "public JobVertexID getID() {\n    return this.id;\n}", "summary_tokens": ["returns", "the", "id", "of", "this", "job", "vertex"], "project": "flink"}
{"id": 4522, "code": "public BlockChannelReader<MemorySegment> createBlockChannelReader(\n        FileIOChannel.ID channelID, LinkedBlockingQueue<MemorySegment> returnQueue)\n        throws IOException {\n    checkState(!isShutdown.get(), \"I/O-Manager is shut down.\");\n    return new AsynchronousBlockReader(\n            channelID, this.readers[channelID.getThreadNum()].requestQueue, returnQueue);\n}", "summary_tokens": ["creates", "a", "block", "channel", "reader", "that", "reads", "blocks", "from", "the", "given", "channel"], "project": "flink"}
{"id": 2423, "code": "private static int parseInt(String s) {\n    try {\n        return Integer.parseInt(s);\n    } catch (NumberFormatException nfe) {\n        log.error(\"Unable to parse integer value '\" + s + \"'\", nfe);\n    }\n\n    return -1;\n}", "summary_tokens": ["safely", "parses", "the", "specified", "string", "as", "an", "integer", "and", "returns", "the", "value"], "project": "flink"}
{"id": 6821, "code": "static int helpGetValueLen(long valuePointer, Allocator spaceAllocator) {\n    Chunk chunk = spaceAllocator.getChunkById(SpaceUtils.getChunkIdByAddress(valuePointer));\n    int offsetInChunk = SpaceUtils.getChunkOffsetByAddress(valuePointer);\n    MemorySegment segment = chunk.getMemorySegment(offsetInChunk);\n    int offsetInByteBuffer = chunk.getOffsetInSegment(offsetInChunk);\n\n    return getValueLen(segment, offsetInByteBuffer);\n}", "summary_tokens": ["returns", "the", "length", "of", "the", "value"], "project": "flink"}
{"id": 4532, "code": "public void clearAll() {\n    synchronized (registeredHandlers) {\n        registeredHandlers.clear();\n    }\n}", "summary_tokens": ["removes", "all", "registered", "event", "handlers"], "project": "flink"}
{"id": 7273, "code": "public void addOperator(Transformation<?> transformation) {\n    Preconditions.checkNotNull(transformation, \"transformation must not be null.\");\n    this.transformations.add(transformation);\n}", "summary_tokens": ["adds", "an", "operator", "to", "the", "list", "of", "operators", "that", "should", "be", "executed", "when", "calling", "execute"], "project": "flink"}
{"id": 5871, "code": "public void testTaskManagerFallbackFallbackBlobStorageDirectory1() throws IOException {\n    Configuration config = new Configuration();\n\n    File dir = BlobUtils.initLocalStorageDirectory(config);\n    assertThat(dir.getAbsolutePath(), startsWith(CoreOptions.TMP_DIRS.defaultValue()));\n}", "summary_tokens": ["tests", "blob", "utils", "init", "local", "storage", "directory", "s", "fallback", "to", "the", "default", "value", "of", "core", "options", "tmp", "dirs"], "project": "flink"}
{"id": 777, "code": "private RecordPublisherRunResult runWithBackoff(\n        final Consumer<SubscribeToShardEvent> eventConsumer) throws InterruptedException {\n    FanOutShardSubscriber fanOutShardSubscriber =\n            new FanOutShardSubscriber(\n                    consumerArn,\n                    subscribedShard.getShard().getShardId(),\n                    kinesisProxy,\n                    configuration.getSubscribeToShardTimeout());\n    boolean complete;\n\n    try {\n        complete =\n                fanOutShardSubscriber.subscribeToShardAndConsumeRecords(\n                        toSdkV2StartingPosition(nextStartingPosition), eventConsumer);\n        attempt = 0;\n    } catch (FanOutSubscriberInterruptedException ex) {\n        LOG.info(\n                \"Thread interrupted, closing record publisher for shard {}.\",\n                subscribedShard.getShard().getShardId(),\n                ex);\n        return CANCELLED;\n    } catch (RecoverableFanOutSubscriberException ex) {\n            \n            \n        backoff(ex);\n        return INCOMPLETE;\n    } catch (FanOutSubscriberException ex) {\n            \n            \n            \n        if (ex.getCause() instanceof ResourceNotFoundException) {\n            LOG.warn(\n                    \"Received ResourceNotFoundException. Either the shard does not exist, or the stream subscriber has been deregistered.\"\n                            + \"Marking this shard as complete {} ({})\",\n                    subscribedShard.getShard().getShardId(),\n                    consumerArn);\n\n            return COMPLETE;\n        }\n\n        if (attempt == configuration.getSubscribeToShardMaxRetries()) {\n            final String errorMessage =\n                    \"Maximum retries exceeded for SubscribeToShard. \"\n                            + \"Failed \"\n                            + configuration.getSubscribeToShardMaxRetries()\n                            + \" times.\";\n            LOG.error(errorMessage, ex.getCause());\n            throw new RuntimeException(errorMessage, ex.getCause());\n        }\n\n        attempt++;\n        backoff(ex);\n        return INCOMPLETE;\n    }\n\n    return complete ? COMPLETE : INCOMPLETE;\n}", "summary_tokens": ["runs", "the", "record", "publisher", "will", "sleep", "for", "configuration", "computed", "jitter", "period", "in", "the", "case", "of", "certain", "exceptions"], "project": "flink"}
{"id": 8194, "code": "public void clear() {\n    list.clear();\n}", "summary_tokens": ["removes", "all", "of", "the", "elements", "from", "this", "list", "view"], "project": "flink"}
{"id": 2714, "code": "protected static void initializeContextEnvironment(ExecutionEnvironmentFactory ctx) {\n    contextEnvironmentFactory = Preconditions.checkNotNull(ctx);\n    threadLocalContextEnvironmentFactory.set(contextEnvironmentFactory);\n}", "summary_tokens": ["sets", "a", "context", "environment", "factory", "that", "creates", "the", "context", "environment", "for", "running", "programs", "with", "pre", "configured", "environments"], "project": "flink"}
{"id": 8917, "code": "public static List<RelCollation> table(RelOptTable table) {\n        \n        \n    List<RelCollation> collations = table.getCollationList();\n    return collations == null ? Collections.emptyList() : collations;\n}", "summary_tokens": ["helper", "method", "to", "determine", "a", "org"], "project": "flink"}
{"id": 3669, "code": "public DataDistribution getDataDistribution() {\n    return this.dataDistribution;\n}", "summary_tokens": ["gets", "the", "data", "distribution"], "project": "flink"}
{"id": 783, "code": "public long getSubscribeToShardBaseBackoffMillis() {\n    return subscribeToShardBaseBackoffMillis;\n}", "summary_tokens": ["get", "base", "backoff", "millis", "for", "the", "subscribe", "to", "shard", "operation"], "project": "flink"}
{"id": 1943, "code": "public static boolean isJvmFatalOrOutOfMemoryError(Throwable t) {\n    return isJvmFatalError(t) || t instanceof OutOfMemoryError;\n}", "summary_tokens": ["checks", "whether", "the", "given", "exception", "indicates", "a", "situation", "that", "may", "leave", "the", "jvm", "in", "a", "corrupted", "state", "or", "an", "out", "of", "memory", "error"], "project": "flink"}
{"id": 8021, "code": "public long getMaxIdleStateRetentionTime() {\n    return getMinIdleStateRetentionTime() * 3 / 2;\n}", "summary_tokens": ["note", "currently", "the", "concept", "of", "min", "max", "idle", "state", "retention", "has", "been", "deprecated", "and", "only", "idle", "state", "retention", "time", "is", "supported"], "project": "flink"}
{"id": 1009, "code": "private static synchronized InputStream getConfVarInputStream() {\n  if (confVarByteArray == null) {\n    try {\n        \n      Configuration conf = new Configuration(false);\n\n      applyDefaultNonNullConfVars(conf);\n\n      ByteArrayOutputStream confVarBaos = new ByteArrayOutputStream();\n      conf.writeXml(confVarBaos);\n      confVarByteArray = confVarBaos.toByteArray();\n    } catch (Exception e) {\n        \n      throw new RuntimeException(\"Failed to initialize default Hive configuration variables!\", e);\n    }\n  }\n  return new LoopingByteArrayInputStream(confVarByteArray);\n}", "summary_tokens": ["writes", "the", "default", "conf", "vars", "out", "to", "a", "byte", "array", "and", "returns", "an", "input", "stream", "wrapping", "that", "byte", "array"], "project": "flink"}
{"id": 6141, "code": "public void testConsistentAvailability() throws Exception {\n    NetworkBufferPool globalPool = new TestNetworkBufferPool(numBuffers, memorySegmentSize);\n    try {\n        BufferPool localPool = new LocalBufferPool(globalPool, 1);\n        MemorySegment segment = localPool.requestMemorySegmentBlocking();\n        localPool.setNumBuffers(2);\n\n        localPool.recycle(segment);\n        localPool.lazyDestroy();\n    } finally {\n        globalPool.destroy();\n    }\n}", "summary_tokens": ["for", "flink", "0", "https", "issues"], "project": "flink"}
{"id": 5542, "code": "public Long getTaskHeap() {\n    return taskHeap;\n}", "summary_tokens": ["returns", "the", "configured", "heap", "size", "used", "by", "the", "tasks"], "project": "flink"}
{"id": 4523, "code": "public BulkBlockChannelReader createBulkBlockChannelReader(\n        FileIOChannel.ID channelID, List<MemorySegment> targetSegments, int numBlocks)\n        throws IOException {\n    checkState(!isShutdown.get(), \"I/O-Manager is shut down.\");\n    return new AsynchronousBulkBlockReader(\n            channelID,\n            this.readers[channelID.getThreadNum()].requestQueue,\n            targetSegments,\n            numBlocks);\n}", "summary_tokens": ["creates", "a", "block", "channel", "reader", "that", "reads", "all", "blocks", "from", "the", "given", "channel", "directly", "in", "one", "bulk"], "project": "flink"}
{"id": 7419, "code": "public void setBoundedness(Boundedness boundedness) {\n    this.boundedness = boundedness;\n}", "summary_tokens": ["mutable", "for", "legacy", "sources", "in", "the", "table", "api"], "project": "flink"}
{"id": 3575, "code": "public void addCpuCost(double cost) {\n    this.cpuCost = (this.cpuCost < 0 || cost < 0) ? UNKNOWN : this.cpuCost + cost;\n}", "summary_tokens": ["adds", "the", "given", "cpu", "cost", "to", "the", "current", "cpu", "cost", "for", "this", "costs", "object"], "project": "flink"}
{"id": 7924, "code": "public static <T> void assertOutputEquals(String message, Queue<T> expected, Queue<T> actual) {\n    Assert.assertArrayEquals(message, expected.toArray(), actual.toArray());\n}", "summary_tokens": ["compare", "the", "two", "queues", "containing", "operator", "task", "output", "by", "converting", "them", "to", "an", "array", "first"], "project": "flink"}
{"id": 5019, "code": "public MemorySegment nextSegment() {\n    final MemorySegment seg = getNextBuffer();\n    if (seg != null) {\n        return seg;\n    } else {\n        try {\n            spillPartition();\n        } catch (IOException ioex) {\n            throw new RuntimeException(\n                    \"Error spilling Hash Join Partition\"\n                            + (ioex.getMessage() == null ? \".\" : \": \" + ioex.getMessage()),\n                    ioex);\n        }\n\n        MemorySegment fromSpill = getNextBuffer();\n        if (fromSpill == null) {\n            throw new RuntimeException(\n                    \"BUG in Hybrid Hash Join: Spilling did not free a buffer.\");\n        } else {\n            return fromSpill;\n        }\n    }\n}", "summary_tokens": ["this", "is", "the", "method", "called", "by", "the", "partitions", "to", "request", "memory", "to", "serialize", "records"], "project": "flink"}
{"id": 4771, "code": "public boolean hasUsercodeJarFiles() {\n    return this.userJars.size() > 0;\n}", "summary_tokens": ["checks", "whether", "the", "job", "graph", "has", "user", "code", "jar", "files", "attached"], "project": "flink"}
{"id": 5657, "code": "public static void installAsShutdownHook(Logger logger, long delayMillis) {\n    checkArgument(delayMillis >= 0, \"delay must be >= 0\");\n\n        \n    Thread shutdownHook = new JvmShutdownSafeguard(delayMillis);\n    ShutdownHookUtil.addShutdownHookThread(\n            shutdownHook, JvmShutdownSafeguard.class.getSimpleName(), logger);\n}", "summary_tokens": ["installs", "the", "safeguard", "shutdown", "hook"], "project": "flink"}
{"id": 2630, "code": "public TypeInformation<T> getType() {\n    if (type instanceof MissingTypeInfo) {\n        MissingTypeInfo typeInfo = (MissingTypeInfo) type;\n        throw new InvalidTypesException(\n                \"The return type of function '\"\n                        + typeInfo.getFunctionName()\n                        + \"' could not be determined automatically, due to type erasure. \"\n                        + \"You can give type information hints by using the returns(...) method on the result of \"\n                        + \"the transformation call, or by letting your function implement the 'ResultTypeQueryable' \"\n                        + \"interface.\",\n                typeInfo.getTypeException());\n    }\n    typeUsed = true;\n    return this.type;\n}", "summary_tokens": ["returns", "the", "type", "information", "for", "the", "type", "of", "this", "data", "set"], "project": "flink"}
{"id": 3125, "code": "private static String getAlgorithmUsage(String algorithmName) {\n    StrBuilder strBuilder = new StrBuilder();\n\n    Driver algorithm = driverFactory.get(algorithmName);\n\n    strBuilder\n            .appendNewLine()\n            .appendNewLine()\n            .appendln(algorithm.getLongDescription())\n            .appendNewLine()\n            .append(\"usage: flink run examples/flink-gelly-examples_<version>.jar --algorithm \")\n            .append(algorithmName)\n            .append(\n                    \" [algorithm options] --input <input> [input options] --output <output> [output options]\")\n            .appendNewLine()\n            .appendNewLine()\n            .appendln(\"Available inputs:\");\n\n    for (Input input : inputFactory) {\n        strBuilder\n                .append(\"  --input \")\n                .append(input.getName())\n                .append(\" \")\n                .appendln(input.getUsage());\n    }\n\n    String algorithmParameterization = algorithm.getUsage();\n\n    if (algorithmParameterization.length() > 0) {\n        strBuilder\n                .appendNewLine()\n                .appendln(\"Algorithm configuration:\")\n                .append(\"  \")\n                .appendln(algorithm.getUsage());\n    }\n\n    strBuilder.appendNewLine().appendln(\"Available outputs:\");\n\n    for (Output output : outputFactory) {\n        strBuilder\n                .append(\"  --output \")\n                .append(output.getName())\n                .append(\" \")\n                .appendln(output.getUsage());\n    }\n\n    return strBuilder.appendNewLine().toString();\n}", "summary_tokens": ["display", "the", "usage", "for", "the", "given", "algorithm"], "project": "flink"}
{"id": 8741, "code": "public RexNode simplifyFilterPredicates(Iterable<? extends RexNode> predicates) {\n    final RexNode simplifiedAnds =\n            withPredicateElimination(Bug.CALCITE_2401_FIXED)\n                    .simplifyUnknownAsFalse(RexUtil.composeConjunction(rexBuilder, predicates));\n    if (simplifiedAnds.isAlwaysFalse()) {\n        return null;\n    }\n\n        \n        \n        \n    return removeNullabilityCast(simplifiedAnds);\n}", "summary_tokens": ["combines", "predicates", "and", "optimizes", "and", "returns", "null", "if", "the", "result", "is", "always", "false"], "project": "flink"}
{"id": 9117, "code": "public void reset() {\n    this.collected = false;\n    if (collector instanceof TableFunctionCollector) {\n        ((TableFunctionCollector) collector).reset();\n    }\n}", "summary_tokens": ["resets", "the", "flag", "to", "indicate", "whether", "collect", "t", "has", "been", "called"], "project": "flink"}
{"id": 2055, "code": "public static boolean addShutdownHookThread(\n        final Thread shutdownHook, final String serviceName, final Logger logger) {\n\n    checkNotNull(shutdownHook);\n    checkNotNull(logger);\n\n    try {\n            \n        Runtime.getRuntime().addShutdownHook(shutdownHook);\n        return true;\n    } catch (IllegalStateException e) {\n            \n    } catch (Throwable t) {\n        logger.error(\n                \"Cannot register shutdown hook that cleanly terminates {}.\", serviceName, t);\n    }\n    return false;\n}", "summary_tokens": ["adds", "a", "shutdown", "hook", "to", "the", "jvm"], "project": "flink"}
{"id": 3149, "code": "protected void expectedOutputChecksum(String[] parameters, Checksum expected) throws Exception {\n    String output = getSystemOutput(parameters);\n\n    long count = 0;\n    long checksum = 0;\n\n    for (String line : output.split(System.getProperty(\"line.separator\"))) {\n        if (line.length() > 0) {\n            count++;\n\n                \n            checksum += line.hashCode() & 0xffffffffL;\n        }\n    }\n\n    Assert.assertEquals(expected.getCount(), count);\n    Assert.assertEquals(expected.getChecksum(), checksum);\n}", "summary_tokens": ["simpler", "variant", "of", "expected", "output", "string", "string", "that", "sums", "the", "hash", "code", "of", "each", "line", "of", "output"], "project": "flink"}
{"id": 1278, "code": "public Ordering getGroupOrderForInputOne() {\n    return getGroupOrder(0);\n}", "summary_tokens": ["gets", "the", "order", "of", "elements", "within", "a", "group", "for", "the", "first", "input"], "project": "flink"}
{"id": 3315, "code": "public VertexMetrics<K, VV, EV> setIncludeZeroDegreeVertices(\n        boolean includeZeroDegreeVertices) {\n    this.includeZeroDegreeVertices = includeZeroDegreeVertices;\n\n    return this;\n}", "summary_tokens": ["by", "default", "only", "the", "edge", "set", "is", "processed", "for", "the", "computation", "of", "degree"], "project": "flink"}
{"id": 2041, "code": "public static int getInt(Properties config, String key, int defaultValue) {\n    String val = config.getProperty(key);\n    if (val == null) {\n        return defaultValue;\n    } else {\n        try {\n            return Integer.parseInt(val);\n        } catch (NumberFormatException nfe) {\n            throw new IllegalArgumentException(\n                    \"Value for configuration key='\"\n                            + key\n                            + \"' is not set correctly. \"\n                            + \"Entered value='\"\n                            + val\n                            + \"'. Default value='\"\n                            + defaultValue\n                            + \"'\");\n        }\n    }\n}", "summary_tokens": ["get", "integer", "from", "properties"], "project": "flink"}
{"id": 8768, "code": "protected void validateSelect(SqlSelect select, RelDataType targetRowType) {\n    assert targetRowType != null;\n        \n    final SelectNamespace ns = getNamespace(select).unwrap(SelectNamespace.class);\n\n        \n        \n        \n    assert ns.rowType == null;\n\n    if (select.isDistinct()) {\n        validateFeature(\n                RESOURCE.sQLFeature_E051_01(),\n                select.getModifierNode(SqlSelectKeyword.DISTINCT).getParserPosition());\n    }\n\n    final SqlNodeList selectItems = select.getSelectList();\n    RelDataType fromType = unknownType;\n    if (selectItems.size() == 1) {\n        final SqlNode selectItem = selectItems.get(0);\n        if (selectItem instanceof SqlIdentifier) {\n            SqlIdentifier id = (SqlIdentifier) selectItem;\n            if (id.isStar() && (id.names.size() == 1)) {\n                    \n                    \n                    \n                    \n                    \n                fromType = targetRowType;\n            }\n        }\n    }\n\n        \n    final SelectScope fromScope = (SelectScope) getFromScope(select);\n    List<String> names = fromScope.getChildNames();\n    if (!catalogReader.nameMatcher().isCaseSensitive()) {\n        names =\n                names.stream()\n                        .map(s -> s.toUpperCase(Locale.ROOT))\n                        .collect(Collectors.toList());\n    }\n    final int duplicateAliasOrdinal = Util.firstDuplicate(names);\n    if (duplicateAliasOrdinal >= 0) {\n        final ScopeChild child = fromScope.children.get(duplicateAliasOrdinal);\n        throw newValidationError(\n                child.namespace.getEnclosingNode(), RESOURCE.fromAliasDuplicate(child.name));\n    }\n\n    if (select.getFrom() == null) {\n        if (this.config.sqlConformance().isFromRequired()) {\n            throw newValidationError(select, RESOURCE.selectMissingFrom());\n        }\n    } else {\n        validateFrom(select.getFrom(), fromType, fromScope);\n    }\n\n    validateWhereClause(select);\n    validateGroupClause(select);\n    validateHavingClause(select);\n    validateWindowClause(select);\n    handleOffsetFetch(select.getOffset(), select.getFetch());\n\n        \n        \n        \n    final RelDataType rowType = validateSelectList(selectItems, select, targetRowType);\n    ns.setType(rowType);\n\n        \n        \n        \n    validateOrderList(select);\n\n    if (shouldCheckForRollUp(select.getFrom())) {\n        checkRollUpInSelectList(select);\n        checkRollUp(null, select, select.getWhere(), getWhereScope(select));\n        checkRollUp(null, select, select.getHaving(), getHavingScope(select));\n        checkRollUpInWindowDecl(select);\n        checkRollUpInGroupBy(select);\n        checkRollUpInOrderBy(select);\n    }\n}", "summary_tokens": ["validates", "a", "select", "statement"], "project": "flink"}
{"id": 4525, "code": "public boolean isClosed() {\n    return this.closed;\n}", "summary_tokens": ["checks", "whether", "this", "request", "queue", "is", "closed"], "project": "flink"}
{"id": 3486, "code": "public <T> SavepointWriter withConfiguration(ConfigOption<T> option, T value) {\n    configuration.set(option, value);\n    return this;\n}", "summary_tokens": ["sets", "a", "configuration", "that", "will", "be", "applied", "to", "the", "stream", "operators", "used", "to", "bootstrap", "a", "new", "savepoint"], "project": "flink"}
{"id": 2377, "code": "public Class<?> getClassByNameOrNull(String name) {\n    Map<String, WeakReference<Class<?>>> map;\n\n    synchronized (CACHE_CLASSES) {\n        map = CACHE_CLASSES.get(classLoader);\n        if (map == null) {\n            map =\n                    Collections.synchronizedMap(\n                            new WeakHashMap<String, WeakReference<Class<?>>>());\n            CACHE_CLASSES.put(classLoader, map);\n        }\n    }\n\n    Class<?> clazz = null;\n    WeakReference<Class<?>> ref = map.get(name);\n    if (ref != null) {\n        clazz = ref.get();\n    }\n\n    if (clazz == null) {\n        try {\n            clazz = Class.forName(name, true, classLoader);\n        } catch (ClassNotFoundException e) {\n                \n            map.put(name, new WeakReference<Class<?>>(NEGATIVE_CACHE_SENTINEL));\n            return null;\n        }\n            \n        map.put(name, new WeakReference<Class<?>>(clazz));\n        return clazz;\n    } else if (clazz == NEGATIVE_CACHE_SENTINEL) {\n        return null; \n    } else {\n            \n        return clazz;\n    }\n}", "summary_tokens": ["load", "a", "class", "by", "name", "returning", "null", "rather", "than", "throwing", "an", "exception", "if", "it", "couldn", "t", "be", "loaded"], "project": "flink"}
{"id": 9091, "code": "public static int toInt(BinaryStringData str) throws NumberFormatException {\n    int sizeInBytes = str.getSizeInBytes();\n    byte[] tmpBytes = getTmpBytes(str, sizeInBytes);\n    if (sizeInBytes == 0) {\n        throw numberFormatExceptionFor(str, \"Input is empty.\");\n    }\n    int i = 0;\n\n    byte b = tmpBytes[i];\n    final boolean negative = b == '-';\n    if (negative || b == '+') {\n        i++;\n        if (sizeInBytes == 1) {\n            throw numberFormatExceptionFor(str, \"Input has only positive or negative symbol.\");\n        }\n    }\n\n    int result = 0;\n    final byte separator = '.';\n    final int radix = 10;\n    final long stopValue = Integer.MIN_VALUE / radix;\n    while (i < sizeInBytes) {\n        b = tmpBytes[i];\n        i++;\n        if (b == separator) {\n                \n                \n                \n            break;\n        }\n\n        int digit;\n        if (b >= '0' && b <= '9') {\n            digit = b - '0';\n        } else {\n            throw numberFormatExceptionFor(str, \"Invalid character found.\");\n        }\n\n            \n            \n            \n            \n        if (result < stopValue) {\n            throw numberFormatExceptionFor(str, \"Overflow.\");\n        }\n\n        result = result * radix - digit;\n            \n            \n            \n        if (result > 0) {\n            throw numberFormatExceptionFor(str, \"Overflow.\");\n        }\n    }\n\n        \n        \n        \n    while (i < sizeInBytes) {\n        byte currentByte = tmpBytes[i];\n        if (currentByte < '0' || currentByte > '9') {\n            throw numberFormatExceptionFor(str, \"Invalid character found.\");\n        }\n        i++;\n    }\n\n    if (!negative) {\n        result = -result;\n        if (result < 0) {\n            throw numberFormatExceptionFor(str, \"Overflow.\");\n        }\n    }\n    return result;\n}", "summary_tokens": ["parses", "this", "binary", "string", "data", "to", "int"], "project": "flink"}
{"id": 5357, "code": "private static CheckpointStorage createDefaultCheckpointStorage(\n        ReadableConfig config, ClassLoader classLoader, @Nullable Logger logger) {\n\n    if (config.getOptional(CheckpointingOptions.CHECKPOINTS_DIRECTORY).isPresent()) {\n        return createFileSystemCheckpointStorage(config, classLoader, logger);\n    }\n\n    return createJobManagerCheckpointStorage(config, classLoader, logger);\n}", "summary_tokens": ["creates", "a", "default", "checkpoint", "storage", "instance", "if", "none", "was", "explicitly", "configured"], "project": "flink"}
{"id": 5473, "code": "private StateMapEntry<K, N, S> addNewStateMapEntry(\n        StateMapEntry<K, N, S>[] table, K key, N namespace, int hash) {\n\n        \n    if (namespace.equals(lastNamespace)) {\n        namespace = lastNamespace;\n    } else {\n        lastNamespace = namespace;\n    }\n\n    int index = hash & (table.length - 1);\n    StateMapEntry<K, N, S> newEntry =\n            new StateMapEntry<>(\n                    key, namespace, null, hash, table[index], stateMapVersion, stateMapVersion);\n    table[index] = newEntry;\n\n    if (table == primaryTable) {\n        ++primaryTableSize;\n    } else {\n        ++incrementalRehashTableSize;\n    }\n    return newEntry;\n}", "summary_tokens": ["creates", "and", "inserts", "a", "new", "state", "map", "entry"], "project": "flink"}
{"id": 3104, "code": "public void testSimplePatternWithTimeWindowNFA() throws Exception {\n    List<StreamRecord<Event>> events = new ArrayList<>();\n\n    final Event startEvent;\n    final Event middleEvent;\n    final Event endEvent;\n\n    events.add(new StreamRecord<>(new Event(1, \"start\", 1.0), 1));\n    events.add(new StreamRecord<>(startEvent = new Event(2, \"start\", 1.0), 2));\n    events.add(new StreamRecord<>(middleEvent = new Event(3, \"middle\", 1.0), 3));\n    events.add(new StreamRecord<>(new Event(4, \"foobar\", 1.0), 4));\n    events.add(new StreamRecord<>(endEvent = new Event(5, \"end\", 1.0), 11));\n    events.add(new StreamRecord<>(new Event(6, \"end\", 1.0), 13));\n\n    Pattern<Event, ?> pattern =\n            Pattern.<Event>begin(\"start\")\n                    .where(\n                            new SimpleCondition<Event>() {\n                                private static final long serialVersionUID =\n                                        7907391379273505897L;\n\n                                @Override\n                                public boolean filter(Event value) throws Exception {\n                                    return value.getName().equals(\"start\");\n                                }\n                            })\n                    .followedBy(\"middle\")\n                    .where(\n                            new SimpleCondition<Event>() {\n                                private static final long serialVersionUID =\n                                        -3268741540234334074L;\n\n                                @Override\n                                public boolean filter(Event value) throws Exception {\n                                    return value.getName().equals(\"middle\");\n                                }\n                            })\n                    .followedBy(\"end\")\n                    .where(\n                            new SimpleCondition<Event>() {\n                                private static final long serialVersionUID =\n                                        -8995174172182138608L;\n\n                                @Override\n                                public boolean filter(Event value) throws Exception {\n                                    return value.getName().equals(\"end\");\n                                }\n                            })\n                    .within(Time.milliseconds(10));\n\n    NFA<Event> nfa = compile(pattern, false);\n\n    List<List<Event>> resultingPatterns = feedNFA(events, nfa);\n\n    comparePatterns(\n            resultingPatterns,\n            Lists.<List<Event>>newArrayList(\n                    Lists.newArrayList(startEvent, middleEvent, endEvent)));\n}", "summary_tokens": ["tests", "that", "the", "nfa", "successfully", "filters", "out", "expired", "elements", "with", "respect", "to", "the", "window", "length"], "project": "flink"}
{"id": 145, "code": "public T peek() {\n    lock.lock();\n    try {\n        return queue.peek();\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["get", "the", "first", "element", "from", "the", "queue", "without", "removing", "it"], "project": "flink"}
{"id": 6734, "code": "public void updateChangelogSnapshotState(\n        SnapshotResult<KeyedStateHandle> materializedSnapshot, SequenceNumber upTo) {\n\n    LOG.info(\n            \"Task {} finishes materialization, updates the snapshotState upTo {} : {}\",\n            subtaskName,\n            upTo,\n            materializedSnapshot);\n    changelogSnapshotState =\n            new ChangelogSnapshotState(\n                    getMaterializedResult(materializedSnapshot), Collections.emptyList(), upTo);\n}", "summary_tokens": ["this", "method", "is", "not", "thread", "safe"], "project": "flink"}
{"id": 7088, "code": "public DataStreamSink<T> name(String name) {\n    transformation.setName(name);\n    return this;\n}", "summary_tokens": ["sets", "the", "name", "of", "this", "sink"], "project": "flink"}
{"id": 703, "code": "protected void readSequence(\n        final StreamExecutionEnvironment env,\n        final StartupMode startupMode,\n        final Map<KafkaTopicPartition, Long> specificStartupOffsets,\n        final Long startupTimestamp,\n        final Properties cc,\n        final int sourceParallelism,\n        final String topicName,\n        final int valuesCount,\n        final int startFrom)\n        throws Exception {\n    HashMap<Integer, Tuple2<Integer, Integer>> partitionsToValuesCountAndStartOffset =\n            new HashMap<>();\n    for (int i = 0; i < sourceParallelism; i++) {\n        partitionsToValuesCountAndStartOffset.put(i, new Tuple2<>(valuesCount, startFrom));\n    }\n    readSequence(\n            env,\n            startupMode,\n            specificStartupOffsets,\n            startupTimestamp,\n            cc,\n            topicName,\n            partitionsToValuesCountAndStartOffset);\n}", "summary_tokens": ["variant", "of", "kafka", "consumer", "test", "base", "read", "sequence", "stream", "execution", "environment", "startup", "mode", "map", "long", "properties", "string", "map", "to", "expect", "reading", "from", "the", "same", "start", "offset", "and", "the", "same", "value", "count", "for", "all", "partitions", "of", "a", "single", "kafka", "topic"], "project": "flink"}
{"id": 7110, "code": "public WindowedStream<T, KEY, TimeWindow> timeWindow(Time size, Time slide) {\n    if (environment.getStreamTimeCharacteristic() == TimeCharacteristic.ProcessingTime) {\n        return window(SlidingProcessingTimeWindows.of(size, slide));\n    } else {\n        return window(SlidingEventTimeWindows.of(size, slide));\n    }\n}", "summary_tokens": ["windows", "this", "keyed", "stream", "into", "sliding", "time", "windows"], "project": "flink"}
{"id": 8285, "code": "public static @Nullable DecimalData zero(int precision, int scale) {\n    if (precision <= MAX_COMPACT_PRECISION) {\n        return new DecimalData(precision, scale, 0, null);\n    } else {\n        return fromBigDecimal(BigDecimal.ZERO, precision, scale);\n    }\n}", "summary_tokens": ["creates", "an", "instance", "of", "decimal", "data", "for", "a", "zero", "value", "with", "the", "given", "precision", "and", "scale"], "project": "flink"}
{"id": 4738, "code": "public SubtaskStateMapper getDownstreamSubtaskStateMapper() {\n    return downstreamSubtaskStateMapper;\n}", "summary_tokens": ["gets", "the", "channel", "state", "rescaler", "used", "for", "rescaling", "persisted", "data", "on", "downstream", "side", "of", "this", "job", "edge"], "project": "flink"}
{"id": 6283, "code": "public void testResourceManagerConnectionAfterStart() throws Exception {\n    final JobMaster jobMaster =\n            new JobMasterBuilder(jobGraph, rpcService)\n                    .withJobMasterId(jobMasterId)\n                    .withConfiguration(configuration)\n                    .withHighAvailabilityServices(haServices)\n                    .withHeartbeatServices(heartbeatServices)\n                    .createJobMaster();\n\n    try {\n        final TestingResourceManagerGateway testingResourceManagerGateway =\n                createAndRegisterTestingResourceManagerGateway();\n\n        final BlockingQueue<JobMasterId> registrationQueue = new ArrayBlockingQueue<>(1);\n        testingResourceManagerGateway.setRegisterJobManagerFunction(\n                (jobMasterId, resourceID, s, jobID) -> {\n                    registrationQueue.offer(jobMasterId);\n                    return CompletableFuture.completedFuture(\n                            testingResourceManagerGateway.getJobMasterRegistrationSuccess());\n                });\n\n        notifyResourceManagerLeaderListeners(testingResourceManagerGateway);\n\n        jobMaster.start();\n\n        final JobMasterId firstRegistrationAttempt = registrationQueue.take();\n\n        assertThat(firstRegistrationAttempt, equalTo(jobMasterId));\n    } finally {\n        RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout);\n    }\n}", "summary_tokens": ["tests", "that", "the", "a", "jm", "connects", "to", "the", "leading", "rm", "after", "regaining", "leadership"], "project": "flink"}
{"id": 8063, "code": "public boolean schemaExists(String catalogName, String databaseName) {\n    return temporaryDatabaseExists(catalogName, databaseName)\n            || permanentDatabaseExists(catalogName, databaseName);\n}", "summary_tokens": ["checks", "if", "there", "is", "a", "database", "with", "given", "name", "in", "a", "given", "catalog", "or", "is", "there", "a", "temporary", "object", "registered", "within", "a", "given", "catalog", "and", "database"], "project": "flink"}
{"id": 8896, "code": "private Operation convertCreateView(SqlCreateView sqlCreateView) {\n    final SqlNode query = sqlCreateView.getQuery();\n    final SqlNodeList fieldList = sqlCreateView.getFieldList();\n\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlCreateView.fullViewName());\n    ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n\n    String comment =\n            sqlCreateView.getComment().map(c -> c.getNlsString().getValue()).orElse(null);\n    CatalogView catalogView =\n            convertViewQuery(\n                    query,\n                    fieldList.getList(),\n                    OperationConverterUtils.extractProperties(\n                            sqlCreateView.getProperties().orElse(null)),\n                    comment);\n    return new CreateViewOperation(\n            identifier,\n            catalogView,\n            sqlCreateView.isIfNotExists(),\n            sqlCreateView.isTemporary());\n}", "summary_tokens": ["convert", "create", "view", "statement"], "project": "flink"}
{"id": 440, "code": "public void open(InputSplit inputSplit) throws IOException {\n    try {\n        if (inputSplit != null && parameterValues != null) {\n            for (int i = 0; i < parameterValues[inputSplit.getSplitNumber()].length; i++) {\n                Object param = parameterValues[inputSplit.getSplitNumber()][i];\n                if (param instanceof String) {\n                    statement.setString(i + 1, (String) param);\n                } else if (param instanceof Long) {\n                    statement.setLong(i + 1, (Long) param);\n                } else if (param instanceof Integer) {\n                    statement.setInt(i + 1, (Integer) param);\n                } else if (param instanceof Double) {\n                    statement.setDouble(i + 1, (Double) param);\n                } else if (param instanceof Boolean) {\n                    statement.setBoolean(i + 1, (Boolean) param);\n                } else if (param instanceof Float) {\n                    statement.setFloat(i + 1, (Float) param);\n                } else if (param instanceof BigDecimal) {\n                    statement.setBigDecimal(i + 1, (BigDecimal) param);\n                } else if (param instanceof Byte) {\n                    statement.setByte(i + 1, (Byte) param);\n                } else if (param instanceof Short) {\n                    statement.setShort(i + 1, (Short) param);\n                } else if (param instanceof Date) {\n                    statement.setDate(i + 1, (Date) param);\n                } else if (param instanceof Time) {\n                    statement.setTime(i + 1, (Time) param);\n                } else if (param instanceof Timestamp) {\n                    statement.setTimestamp(i + 1, (Timestamp) param);\n                } else if (param instanceof Array) {\n                    statement.setArray(i + 1, (Array) param);\n                } else {\n                        \n                    throw new IllegalArgumentException(\n                            \"open() failed. Parameter \"\n                                    + i\n                                    + \" of type \"\n                                    + param.getClass()\n                                    + \" is not handled (yet).\");\n                }\n            }\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\n                        String.format(\n                                \"Executing '%s' with parameters %s\",\n                                queryTemplate,\n                                Arrays.deepToString(\n                                        parameterValues[inputSplit.getSplitNumber()])));\n            }\n        }\n        resultSet = statement.executeQuery();\n        hasNext = resultSet.next();\n    } catch (SQLException se) {\n        throw new IllegalArgumentException(\"open() failed.\" + se.getMessage(), se);\n    }\n}", "summary_tokens": ["connects", "to", "the", "source", "database", "and", "executes", "the", "query", "in", "a", "b", "parallel", "fashion", "b", "if", "this", "input", "format", "is", "built", "using", "a", "parameterized", "query", "i"], "project": "flink"}
{"id": 8528, "code": "public static Optional<Method> getStructuredFieldSetter(Class<?> clazz, Field field) {\n    final String normalizedFieldName = normalizeAccessorName(field.getName());\n\n    final List<Method> methods = collectStructuredMethods(clazz);\n    for (Method method : methods) {\n\n            \n            \n            \n            \n        final String normalizedMethodName = normalizeAccessorName(method.getName());\n        final boolean hasName =\n                normalizedMethodName.equals(\"SET\" + normalizedFieldName)\n                        || normalizedMethodName.equals(normalizedFieldName)\n                        || normalizedMethodName.equals(normalizedFieldName + \"$EQ\");\n        if (!hasName) {\n            continue;\n        }\n\n            \n            \n        final Class<?> returnType = method.getReturnType();\n        final boolean hasReturnType = returnType == Void.TYPE || returnType == clazz;\n        if (!hasReturnType) {\n            continue;\n        }\n\n            \n            \n        final boolean hasParameter =\n                method.getParameterCount() == 1\n                        && (method.getGenericParameterTypes()[0].equals(field.getGenericType())\n                                || primitiveToWrapper(method.getGenericParameterTypes()[0])\n                                        .equals(field.getGenericType()));\n        if (!hasParameter) {\n            continue;\n        }\n\n            \n        return Optional.of(method);\n    }\n\n        \n    return Optional.empty();\n}", "summary_tokens": ["checks", "for", "a", "field", "setters", "of", "a", "structured", "type"], "project": "flink"}
{"id": 4760, "code": "public JobCheckpointingSettings getCheckpointingSettings() {\n    return snapshotSettings;\n}", "summary_tokens": ["gets", "the", "settings", "for", "asynchronous", "snapshots"], "project": "flink"}
{"id": 8648, "code": "public static RowType renameRowFields(RowType rowType, List<String> newFieldNames) {\n    Preconditions.checkArgument(\n            rowType.getFieldCount() == newFieldNames.size(),\n            \"Row length and new names must match.\");\n    final List<RowField> newFields =\n            IntStream.range(0, rowType.getFieldCount())\n                    .mapToObj(\n                            pos -> {\n                                final RowField oldField = rowType.getFields().get(pos);\n                                return new RowField(\n                                        newFieldNames.get(pos),\n                                        oldField.getType(),\n                                        oldField.getDescription().orElse(null));\n                            })\n                    .collect(Collectors.toList());\n    return new RowType(rowType.isNullable(), newFields);\n}", "summary_tokens": ["renames", "the", "fields", "of", "the", "given", "row", "type"], "project": "flink"}
{"id": 3230, "code": "public void setName(String name) {\n    this.name = name;\n}", "summary_tokens": ["sets", "the", "name", "for", "the", "iteration"], "project": "flink"}
{"id": 303, "code": "public byte[] getTableName() {\n    return this.tableName;\n}", "summary_tokens": ["returns", "the", "table", "name"], "project": "flink"}
{"id": 6919, "code": "public void enableCompactionPending() {\n    this.properties.add(RocksDBProperty.CompactionPending.getRocksDBProperty());\n}", "summary_tokens": ["returns", "0", "if", "at", "least", "one", "compaction", "is", "pending", "otherwise", "returns", "0"], "project": "flink"}
{"id": 5368, "code": "protected void reportAllElementKeyGroups() {\n\n    Preconditions.checkState(partitioningSource.length >= numberOfElements);\n\n    for (int i = 0; i < numberOfElements; ++i) {\n        int keyGroup =\n                KeyGroupRangeAssignment.assignToKeyGroup(\n                        keyExtractorFunction.extractKeyFromElement(partitioningSource[i]),\n                        totalKeyGroups);\n        reportKeyGroupOfElementAtIndex(i, keyGroup);\n    }\n}", "summary_tokens": ["this", "method", "iterates", "over", "the", "input", "data", "and", "reports", "the", "key", "group", "for", "each", "element"], "project": "flink"}
{"id": 1208, "code": "public Operator<IN2> getSecondInput() {\n    return this.input2;\n}", "summary_tokens": ["returns", "the", "second", "input", "or", "null", "if", "none", "is", "set"], "project": "flink"}
{"id": 6060, "code": "public void testRestartingSuppressedFailureHandlingResult() {\n        \n    backoffTimeStrategy.setCanRestart(false);\n\n        \n    final Throwable error = new Exception(\"expected test failure\");\n    final long timestamp = System.currentTimeMillis();\n    final FailureHandlingResult result =\n            executionFailureHandler.getFailureHandlingResult(\n                    new ExecutionVertexID(new JobVertexID(), 0), error, timestamp);\n\n        \n    assertFalse(result.canRestart());\n    assertThat(result.getError(), containsCause(error));\n    assertThat(result.getTimestamp(), is(timestamp));\n    assertFalse(ExecutionFailureHandler.isUnrecoverableError(result.getError()));\n    try {\n        result.getVerticesToRestart();\n        fail(\"get tasks to restart is not allowed when restarting is suppressed\");\n    } catch (IllegalStateException ex) {\n            \n    }\n    try {\n        result.getRestartDelayMS();\n        fail(\"get restart delay is not allowed when restarting is suppressed\");\n    } catch (IllegalStateException ex) {\n            \n    }\n    assertEquals(0, executionFailureHandler.getNumberOfRestarts());\n}", "summary_tokens": ["tests", "the", "case", "that", "task", "restarting", "is", "suppressed"], "project": "flink"}
{"id": 3287, "code": "public EdgeDirection getDirection() {\n    return direction;\n}", "summary_tokens": ["gets", "the", "direction", "from", "which", "the", "neighbors", "are", "to", "be", "selected", "by", "default", "the", "neighbors", "who", "are", "target", "of", "the", "edges", "are", "selected"], "project": "flink"}
{"id": 2521, "code": "public static <T extends SpecificRecord> byte[] writeRecord(T record) throws IOException {\n    ByteArrayOutputStream stream = new ByteArrayOutputStream();\n    BinaryEncoder encoder = EncoderFactory.get().binaryEncoder(stream, null);\n\n    @SuppressWarnings(\"unchecked\")\n    SpecificDatumWriter<T> writer = new SpecificDatumWriter<>((Class<T>) record.getClass());\n    writer.write(record, encoder);\n    encoder.flush();\n    return stream.toByteArray();\n}", "summary_tokens": ["writes", "given", "specific", "record"], "project": "flink"}
{"id": 4131, "code": "public void close() {\n    closeSilently(clientSocket, LOG);\n    interrupt();\n}", "summary_tokens": ["closes", "the", "connection", "socket", "and", "lets", "the", "thread", "exit"], "project": "flink"}
{"id": 9748, "code": "public void testMemoryPropertyWithArbitraryUnit() throws Exception {\n    final String[] args = new String[] {\"-yjm\", \"1g\", \"-ytm\", \"2g\"};\n    final FlinkYarnSessionCli flinkYarnSessionCli = createFlinkYarnSessionCli();\n    final CommandLine commandLine = flinkYarnSessionCli.parseCommandLineOptions(args, false);\n\n    final Configuration executorConfig = flinkYarnSessionCli.toConfiguration(commandLine);\n    final ClusterClientFactory<ApplicationId> clientFactory =\n            getClusterClientFactory(executorConfig);\n    final ClusterSpecification clusterSpecification =\n            clientFactory.getClusterSpecification(executorConfig);\n\n    assertThat(clusterSpecification.getMasterMemoryMB(), is(1024));\n    assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(2048));\n}", "summary_tokens": ["tests", "the", "specifying", "total", "process", "memory", "with", "arbitrary", "unit", "for", "job", "manager", "and", "task", "manager"], "project": "flink"}
{"id": 8639, "code": "public static DecimalType findMultiplicationDecimalType(\n        int precision1, int scale1, int precision2, int scale2) {\n    int scale = scale1 + scale2;\n    int precision = precision1 + precision2 + 1;\n    return adjustPrecisionScale(precision, scale);\n}", "summary_tokens": ["finds", "the", "result", "type", "of", "a", "decimal", "multiplication", "operation"], "project": "flink"}
{"id": 5204, "code": "public static void sendNotModified(ChannelHandlerContext ctx) {\n    FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, NOT_MODIFIED);\n    setDateHeader(response);\n\n        \n    ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE);\n}", "summary_tokens": ["send", "the", "0", "not", "modified", "response"], "project": "flink"}
{"id": 9478, "code": "private void updateOutputBuffer(BinaryRowData reuse, Random rnd) {\n    long longVal = rnd.nextLong();\n    double doubleVal = rnd.nextDouble();\n    boolean boolVal = longVal % 2 == 0;\n    reuse.setDouble(2, doubleVal);\n    reuse.setLong(3, longVal);\n    reuse.setBoolean(4, boolVal);\n}", "summary_tokens": ["it", "will", "be", "codegened", "when", "in", "hash", "agg", "exec", "using", "rnd", "to", "mock", "update", "init", "exprs", "result", "term"], "project": "flink"}
{"id": 6934, "code": "public void enableEstimatePendingCompactionBytes() {\n    this.properties.add(RocksDBProperty.EstimatePendingCompactionBytes.getRocksDBProperty());\n}", "summary_tokens": ["returns", "estimated", "total", "number", "of", "bytes", "compaction", "needs", "to", "rewrite", "to", "get", "all", "levels", "down", "to", "under", "target", "size"], "project": "flink"}
{"id": 7795, "code": "public void mergeWindows(W targetWindow, Collection<W> mergedWindows) throws Exception {\n    TestOnMergeContext<Integer, W> onMergeContext =\n            new TestOnMergeContext<>(\n                    KEY,\n                    targetWindow,\n                    mergedWindows,\n                    internalTimerService,\n                    stateBackend,\n                    windowSerializer);\n    trigger.onMerge(targetWindow, onMergeContext);\n\n    for (W mergedWindow : mergedWindows) {\n        clearTriggerState(mergedWindow);\n    }\n}", "summary_tokens": ["calls", "trigger", "on", "merge", "window", "trigger"], "project": "flink"}
{"id": 1366, "code": "public static TypeInformation<Row> ROW_NAMED(String[] fieldNames, TypeInformation<?>... types) {\n    return new RowTypeInfo(types, fieldNames);\n}", "summary_tokens": ["returns", "type", "information", "for", "org"], "project": "flink"}
{"id": 4096, "code": "private static void sendGetHeader(\n        OutputStream outputStream, @Nullable JobID jobId, BlobKey blobKey) throws IOException {\n    checkNotNull(blobKey);\n    checkArgument(\n            jobId != null || blobKey instanceof TransientBlobKey,\n            \"permanent BLOBs must be job-related\");\n\n        \n    outputStream.write(GET_OPERATION);\n\n        \n    if (jobId == null) {\n        outputStream.write(JOB_UNRELATED_CONTENT);\n    } else {\n        outputStream.write(JOB_RELATED_CONTENT);\n        outputStream.write(jobId.getBytes());\n    }\n    blobKey.writeToOutputStream(outputStream);\n}", "summary_tokens": ["constructs", "and", "writes", "the", "header", "data", "for", "a", "get", "operation", "to", "the", "given", "output", "stream"], "project": "flink"}
{"id": 377, "code": "public static void readProps(HiveParserASTNode prop, Map<String, String> mapProp) {\n\n    for (int propChild = 0; propChild < prop.getChildCount(); propChild++) {\n        String key = unescapeSQLString(prop.getChild(propChild).getChild(0).getText());\n        String value = null;\n        if (prop.getChild(propChild).getChild(1) != null) {\n            value = unescapeSQLString(prop.getChild(propChild).getChild(1).getText());\n        }\n        mapProp.put(key, value);\n    }\n}", "summary_tokens": ["converts", "parsed", "key", "value", "properties", "pairs", "into", "a", "map"], "project": "flink"}
{"id": 7810, "code": "public void writeReducingEventTimeWindowsSnapshot() throws Exception {\n    final int windowSize = 3;\n\n    ReducingStateDescriptor<Tuple2<String, Integer>> stateDesc =\n            new ReducingStateDescriptor<>(\n                    \"window-contents\",\n                    new SumReducer<>(),\n                    STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n    WindowOperator<\n                    String,\n                    Tuple2<String, Integer>,\n                    Tuple2<String, Integer>,\n                    Tuple2<String, Integer>,\n                    TimeWindow>\n            operator =\n                    new WindowOperator<>(\n                            TumblingEventTimeWindows.of(Time.of(windowSize, TimeUnit.SECONDS)),\n                            new TimeWindow.Serializer(),\n                            new TupleKeySelector<>(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()),\n                            stateDesc,\n                            new InternalSingleValueWindowFunction<>(\n                                    new PassThroughWindowFunction<\n                                            String, TimeWindow, Tuple2<String, Integer>>()),\n                            EventTimeTrigger.create(),\n                            0,\n                            null );\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>>\n            testHarness =\n                    new KeyedOneInputStreamOperatorTestHarness<>(\n                            operator, new TupleKeySelector<>(), BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n        \n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 3999));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 3000));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 20));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 0));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1), 999));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 1998));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 1999));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1), 1000));\n\n    testHarness.processWatermark(new Watermark(999));\n    expectedOutput.add(new Watermark(999));\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new Tuple2ResultSortComparator<>());\n\n    testHarness.processWatermark(new Watermark(1999));\n    expectedOutput.add(new Watermark(1999));\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new Tuple2ResultSortComparator<>());\n\n        \n    OperatorSubtaskState snapshot = testHarness.snapshot(0, 0);\n    OperatorSnapshotUtil.writeStateHandle(\n            snapshot,\n            \"src/test/resources/win-op-migration-test-reduce-event-time-flink\"\n                    + flinkGenerateSavepointVersion\n                    + \"-snapshot\");\n\n    testHarness.close();\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 6057, "code": "public void execute(@Nonnull ThrowingRunnable<Throwable> throwingRunnable) {\n    execute(\n            () -> {\n                throwingRunnable.run();\n                return null;\n            });\n}", "summary_tokens": ["executes", "the", "given", "runnable", "with", "the", "main", "thread", "executor", "and", "blocks", "until", "completion"], "project": "flink"}
{"id": 1758, "code": "public int size() {\n    return size;\n}", "summary_tokens": ["gets", "the", "size", "of", "the", "memory", "segment", "in", "bytes"], "project": "flink"}
{"id": 1961, "code": "public static <T extends Throwable> void assertThrowableWithMessage(\n        Throwable throwable, String searchMessage) throws T {\n    if (!findThrowableWithMessage(throwable, searchMessage).isPresent()) {\n        throw (T) throwable;\n    }\n}", "summary_tokens": ["the", "same", "as", "find", "throwable", "with", "message", "throwable", "string", "but", "rethrows", "original", "exception", "if", "the", "expected", "exception", "was", "not", "found"], "project": "flink"}
{"id": 4528, "code": "public void registerPartition(ResultPartitionID partitionId) {\n    checkNotNull(partitionId);\n\n    synchronized (registeredHandlers) {\n        LOG.debug(\"registering {}\", partitionId);\n        if (registeredHandlers.put(partitionId, new TaskEventHandler()) != null) {\n            throw new IllegalStateException(\n                    \"Partition \"\n                            + partitionId\n                            + \" already registered at task event dispatcher.\");\n        }\n    }\n}", "summary_tokens": ["registers", "the", "given", "partition", "for", "incoming", "task", "events", "allowing", "calls", "to", "subscribe", "to", "event", "result", "partition", "id", "event", "listener", "class"], "project": "flink"}
{"id": 2165, "code": "private Path getGenerateSerializerSnapshotFilePath() {\n    return Paths.get(getGenerateResourceDirectory() + \"/serializer-snapshot\");\n}", "summary_tokens": ["paths", "to", "use", "during", "snapshot", "generation", "which", "should", "only", "use", "the", "current", "version"], "project": "flink"}
{"id": 6315, "code": "public void testConnectingAddressRetrievalWithDelayedLeaderElection() throws Exception {\n    Duration timeout = Duration.ofMinutes(1L);\n\n    long sleepingTime = 1000;\n\n    LeaderElectionService leaderElectionService = null;\n    LeaderElectionService faultyLeaderElectionService;\n\n    ServerSocket serverSocket;\n    InetAddress localHost;\n\n    Thread thread;\n\n    try {\n        String wrongAddress =\n                RPC_SYSTEM.getRpcUrl(\n                        \"1.1.1.1\",\n                        1234,\n                        \"foobar\",\n                        AddressResolution.NO_ADDRESS_RESOLUTION,\n                        config);\n\n        try {\n            localHost = InetAddress.getLocalHost();\n            serverSocket = new ServerSocket(0, 50, localHost);\n        } catch (UnknownHostException e) {\n                \n            System.err.println(\"Skipping 'testNetworkInterfaceSelection' test.\");\n            return;\n        } catch (IOException e) {\n                \n            System.err.println(\"Skipping 'testNetworkInterfaceSelection' test.\");\n            return;\n        }\n\n        InetSocketAddress correctInetSocketAddress =\n                new InetSocketAddress(localHost, serverSocket.getLocalPort());\n\n        String correctAddress =\n                RPC_SYSTEM.getRpcUrl(\n                        localHost.getHostName(),\n                        correctInetSocketAddress.getPort(),\n                        JobMaster.JOB_MANAGER_NAME,\n                        AddressResolution.NO_ADDRESS_RESOLUTION,\n                        config);\n\n        faultyLeaderElectionService =\n                highAvailabilityServices.getJobManagerLeaderElectionService(\n                        HighAvailabilityServices.DEFAULT_JOB_ID);\n        TestingContender wrongLeaderAddressContender =\n                new TestingContender(wrongAddress, faultyLeaderElectionService);\n\n        faultyLeaderElectionService.start(wrongLeaderAddressContender);\n\n        FindConnectingAddress findConnectingAddress =\n                new FindConnectingAddress(\n                        timeout,\n                        highAvailabilityServices.getJobManagerLeaderRetriever(\n                                HighAvailabilityServices.DEFAULT_JOB_ID));\n\n        thread = new Thread(findConnectingAddress);\n\n        thread.start();\n\n        leaderElectionService =\n                highAvailabilityServices.getJobManagerLeaderElectionService(\n                        HighAvailabilityServices.DEFAULT_JOB_ID);\n        TestingContender correctLeaderAddressContender =\n                new TestingContender(correctAddress, leaderElectionService);\n\n        Thread.sleep(sleepingTime);\n\n        faultyLeaderElectionService.stop();\n\n        leaderElectionService.start(correctLeaderAddressContender);\n\n        thread.join();\n\n        InetAddress result = findConnectingAddress.getInetAddress();\n\n            \n        Socket socket = new Socket();\n        try {\n                \n            SocketAddress bindP = new InetSocketAddress(result, 0);\n                \n            socket.bind(bindP);\n            socket.connect(correctInetSocketAddress, 1000);\n        } finally {\n            socket.close();\n        }\n    } finally {\n        if (leaderElectionService != null) {\n            leaderElectionService.stop();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "leader", "retrieval", "utils"], "project": "flink"}
{"id": 6700, "code": "public void testGatewayRetrievalFailures() throws Exception {\n    final String address = \"localhost\";\n    final UUID leaderId = UUID.randomUUID();\n\n    RpcGateway rpcGateway = mock(RpcGateway.class);\n\n    TestingLeaderGatewayRetriever leaderGatewayRetriever =\n            new TestingLeaderGatewayRetriever(rpcGateway);\n    SettableLeaderRetrievalService settableLeaderRetrievalService =\n            new SettableLeaderRetrievalService();\n\n    settableLeaderRetrievalService.start(leaderGatewayRetriever);\n\n    CompletableFuture<RpcGateway> gatewayFuture = leaderGatewayRetriever.getFuture();\n\n        \n    settableLeaderRetrievalService.notifyListener(address, leaderId);\n\n        \n    try {\n        gatewayFuture.get();\n\n        fail(\"The first future should have been failed.\");\n    } catch (ExecutionException ignored) {\n            \n    }\n\n        \n    assertFalse((leaderGatewayRetriever.getNow().isPresent()));\n\n        \n    assertEquals(rpcGateway, leaderGatewayRetriever.getNow().get());\n}", "summary_tokens": ["tests", "that", "the", "gateway", "retrieval", "is", "retried", "in", "case", "of", "a", "failure"], "project": "flink"}
{"id": 6410, "code": "public void testRequestTaskManagerInfo() throws Exception {\n    final ResourceID taskManagerId = ResourceID.generate();\n    final TaskExecutorGateway taskExecutorGateway =\n            new TestingTaskExecutorGatewayBuilder()\n                    .setAddress(UUID.randomUUID().toString())\n                    .createTestingTaskExecutorGateway();\n    rpcService.registerGateway(taskExecutorGateway.getAddress(), taskExecutorGateway);\n\n    resourceManager = new ResourceManagerBuilder().buildAndStart();\n    final ResourceManagerGateway resourceManagerGateway =\n            resourceManager.getSelfGateway(ResourceManagerGateway.class);\n\n    registerTaskExecutor(\n            resourceManagerGateway, taskManagerId, taskExecutorGateway.getAddress());\n\n    CompletableFuture<TaskManagerInfoWithSlots> taskManagerInfoFuture =\n            resourceManagerGateway.requestTaskManagerDetailsInfo(\n                    taskManagerId, TestingUtils.TIMEOUT);\n\n    TaskManagerInfoWithSlots taskManagerInfoWithSlots = taskManagerInfoFuture.get();\n    TaskManagerInfo taskManagerInfo = taskManagerInfoWithSlots.getTaskManagerInfo();\n\n    assertEquals(taskManagerId, taskManagerInfo.getResourceId());\n    assertEquals(hardwareDescription, taskManagerInfo.getHardwareDescription());\n    assertEquals(taskExecutorGateway.getAddress(), taskManagerInfo.getAddress());\n    assertEquals(dataPort, taskManagerInfo.getDataPort());\n    assertEquals(jmxPort, taskManagerInfo.getJmxPort());\n    assertEquals(0, taskManagerInfo.getNumberSlots());\n    assertEquals(0, taskManagerInfo.getNumberAvailableSlots());\n    assertThat(taskManagerInfoWithSlots.getAllocatedSlots(), is(empty()));\n}", "summary_tokens": ["tests", "that", "we", "can", "retrieve", "the", "correct", "task", "manager", "info", "from", "the", "resource", "manager"], "project": "flink"}
{"id": 8066, "code": "public void createTemporaryTable(\n        CatalogBaseTable table, ObjectIdentifier objectIdentifier, boolean ignoreIfExists) {\n    Optional<TemporaryOperationListener> listener =\n            getTemporaryOperationListener(objectIdentifier);\n    temporaryTables.compute(\n            objectIdentifier,\n            (k, v) -> {\n                if (v != null) {\n                    if (!ignoreIfExists) {\n                        throw new ValidationException(\n                                String.format(\n                                        \"Temporary table '%s' already exists\",\n                                        objectIdentifier));\n                    }\n                    return v;\n                } else {\n                    ResolvedCatalogBaseTable<?> resolvedTable = resolveCatalogBaseTable(table);\n                    ResolvedCatalogBaseTable<?> resolvedListenedTable =\n                            managedTableListener.notifyTableCreation(\n                                    getCatalog(objectIdentifier.getCatalogName()).orElse(null),\n                                    objectIdentifier,\n                                    resolvedTable,\n                                    true,\n                                    ignoreIfExists);\n\n                    if (listener.isPresent()) {\n                        return listener.get()\n                                .onCreateTemporaryTable(\n                                        objectIdentifier.toObjectPath(), resolvedListenedTable);\n                    }\n                    return resolvedListenedTable;\n                }\n            });\n}", "summary_tokens": ["creates", "a", "temporary", "table", "in", "a", "given", "fully", "qualified", "path"], "project": "flink"}
{"id": 1348, "code": "public long getSize() {\n    return size;\n}", "summary_tokens": ["gets", "the", "length", "of", "this", "policy", "s", "time", "interval"], "project": "flink"}
{"id": 1062, "code": "public void enableGenericTypes() {\n    disableGenericTypes = false;\n}", "summary_tokens": ["enables", "the", "use", "generic", "types", "which", "are", "serialized", "via", "kryo"], "project": "flink"}
{"id": 851, "code": "public static RecordPublisherType validateRecordPublisherType(Properties config) {\n    if (config.containsKey(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE)) {\n        String recordPublisherType =\n                config.getProperty(ConsumerConfigConstants.RECORD_PUBLISHER_TYPE);\n\n            \n        try {\n            return RecordPublisherType.valueOf(recordPublisherType);\n        } catch (IllegalArgumentException e) {\n            String errorMessage =\n                    Arrays.stream(RecordPublisherType.values())\n                            .map(Enum::name)\n                            .collect(Collectors.joining(\", \"));\n            throw new IllegalArgumentException(\n                    \"Invalid record publisher type in stream set in config. Valid values are: \"\n                            + errorMessage);\n        }\n    } else {\n        return RecordPublisherType.POLLING;\n    }\n}", "summary_tokens": ["validate", "the", "record", "publisher", "type"], "project": "flink"}
{"id": 2279, "code": "public FlinkContainersBuilder setLogger(Logger logger) {\n    this.logger = logger;\n    return this;\n}", "summary_tokens": ["sets", "a", "logger", "to", "the", "cluster", "in", "order", "to", "consume", "stdout", "of", "containers", "to", "the", "logger"], "project": "flink"}
{"id": 1975, "code": "public static void closeStream(final java.io.Closeable stream) {\n    cleanup(null, stream);\n}", "summary_tokens": ["closes", "the", "stream", "ignoring", "ioexception"], "project": "flink"}
{"id": 7791, "code": "public TriggerResult processElement(StreamRecord<T> element, W window) throws Exception {\n    TestTriggerContext<Integer, W> triggerContext =\n            new TestTriggerContext<>(\n                    KEY, window, internalTimerService, stateBackend, windowSerializer);\n    return trigger.onElement(\n            element.getValue(), element.getTimestamp(), window, triggerContext);\n}", "summary_tokens": ["injects", "one", "element", "into", "the", "trigger", "for", "the", "given", "window", "and", "returns", "the", "result", "of", "trigger", "on", "element", "object", "long", "window", "trigger"], "project": "flink"}
{"id": 7448, "code": "public static <T> DynamicProcessingTimeSessionWindows<T> withDynamicGap(\n        SessionWindowTimeGapExtractor<T> sessionWindowTimeGapExtractor) {\n    return new DynamicProcessingTimeSessionWindows<>(sessionWindowTimeGapExtractor);\n}", "summary_tokens": ["creates", "a", "new", "session", "windows", "window", "assigner", "that", "assigns", "elements", "to", "sessions", "based", "on", "the", "element", "timestamp"], "project": "flink"}
{"id": 2529, "code": "public T deserialize(byte[] bytes) {\n    if (bytes == null) {\n        return null;\n    }\n\n    if (glueSchemaRegistryJsonSchemaCoder == null) {\n        glueSchemaRegistryJsonSchemaCoder = glueSchemaRegistryJsonSchemaCoderProvider.get();\n    }\n    return (T) glueSchemaRegistryJsonSchemaCoder.deserialize(bytes);\n}", "summary_tokens": ["deserializes", "the", "incoming", "byte", "array", "which", "contains", "bytes", "of", "aws", "glue", "schema", "registry", "information", "back", "to", "the", "original", "object"], "project": "flink"}
{"id": 8774, "code": "private void validateOrderItem(SqlSelect select, SqlNode orderItem) {\n    switch (orderItem.getKind()) {\n        case DESCENDING:\n            validateFeature(\n                    RESOURCE.sQLConformance_OrderByDesc(), orderItem.getParserPosition());\n            validateOrderItem(select, ((SqlCall) orderItem).operand(0));\n            return;\n    }\n\n    final SqlValidatorScope orderScope = getOrderScope(select);\n    validateExpr(orderItem, orderScope);\n}", "summary_tokens": ["validates", "an", "item", "in", "the", "order", "by", "clause", "of", "a", "select", "statement"], "project": "flink"}
{"id": 8765, "code": "private void registerOperandSubQueries(\n        SqlValidatorScope parentScope, SqlCall call, int operandOrdinal) {\n    SqlNode operand = call.operand(operandOrdinal);\n    if (operand == null) {\n        return;\n    }\n    if (operand.getKind().belongsTo(SqlKind.QUERY)\n            && call.getOperator().argumentMustBeScalar(operandOrdinal)) {\n        operand =\n                SqlStdOperatorTable.SCALAR_QUERY.createCall(\n                        operand.getParserPosition(), operand);\n        call.setOperand(operandOrdinal, operand);\n    }\n    registerSubQueries(parentScope, operand);\n}", "summary_tokens": ["registers", "any", "sub", "queries", "inside", "a", "given", "call", "operand", "and", "converts", "the", "operand", "to", "a", "scalar", "sub", "query", "if", "the", "operator", "requires", "it"], "project": "flink"}
{"id": 8099, "code": "public ResolvedCatalogBaseTable<?> notifyTableCreation(\n        @Nullable Catalog catalog,\n        ObjectIdentifier identifier,\n        ResolvedCatalogBaseTable<?> table,\n        boolean isTemporary,\n        boolean ignoreIfExists) {\n    if (isManagedTable(catalog, table)) {\n        ResolvedCatalogTable managedTable = enrichOptions(identifier, table, isTemporary);\n        discoverManagedTableFactory(classLoader)\n                .onCreateTable(\n                        createTableFactoryContext(identifier, managedTable, isTemporary),\n                        ignoreIfExists);\n        return managedTable;\n    }\n    return table;\n}", "summary_tokens": ["notify", "for", "creating", "managed", "table"], "project": "flink"}
{"id": 1727, "code": "void unregisterInputStream(InStream stream) {\n    lock.lock();\n    try {\n            \n        if (openInputStreams.remove(stream)) {\n            numReservedInputStreams--;\n            available.signalAll();\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["atomically", "removes", "the", "given", "input", "stream", "from", "the", "set", "of", "currently", "open", "input", "streams", "and", "signals", "that", "new", "stream", "can", "now", "be", "opened"], "project": "flink"}
{"id": 9692, "code": "public void testKillYarnSessionClusterEntrypoint() throws Exception {\n    runTest(\n            () -> {\n                assumeTrue(\n                        \"This test kills processes via the pkill command. Thus, it only runs on Linux, Mac OS, Free BSD and Solaris.\",\n                        OperatingSystem.isLinux()\n                                || OperatingSystem.isMac()\n                                || OperatingSystem.isFreeBSD()\n                                || OperatingSystem.isSolaris());\n\n                final YarnClusterDescriptor yarnClusterDescriptor =\n                        setupYarnClusterDescriptor();\n                final RestClusterClient<ApplicationId> restClusterClient =\n                        deploySessionCluster(yarnClusterDescriptor);\n\n                try {\n                    final JobID jobId = submitJob(restClusterClient);\n                    final ApplicationId id = restClusterClient.getClusterId();\n\n                    waitUntilJobIsRunning(restClusterClient, jobId);\n\n                    killApplicationMaster(\n                            yarnClusterDescriptor.getYarnSessionClusterEntrypoint());\n                    waitForApplicationAttempt(id, 2);\n\n                    waitForJobTermination(restClusterClient, jobId);\n\n                    killApplicationAndWait(id);\n                } finally {\n                    restClusterClient.close();\n                }\n            });\n}", "summary_tokens": ["tests", "that", "yarn", "will", "restart", "a", "killed", "yarn", "session", "cluster", "entrypoint", "which", "will", "then", "resume", "a", "persisted", "job", "graph"], "project": "flink"}
{"id": 3482, "code": "public static SavepointWriter fromExistingSavepoint(String path, StateBackend stateBackend)\n        throws IOException {\n    CheckpointMetadata metadata = SavepointLoader.loadSavepointMetadata(path);\n\n    int maxParallelism =\n            metadata.getOperatorStates().stream()\n                    .map(OperatorState::getMaxParallelism)\n                    .max(Comparator.naturalOrder())\n                    .orElseThrow(\n                            () ->\n                                    new RuntimeException(\n                                            \"Savepoint must contain at least one operator state.\"));\n\n    SavepointMetadataV2 savepointMetadata =\n            new SavepointMetadataV2(\n                    maxParallelism, metadata.getMasterStates(), metadata.getOperatorStates());\n    return new SavepointWriter(savepointMetadata, stateBackend);\n}", "summary_tokens": ["loads", "an", "existing", "savepoint"], "project": "flink"}
{"id": 8488, "code": "public TableStats merge(TableStats other) {\n    Map<String, ColumnStats> colStats = new HashMap<>();\n    for (Map.Entry<String, ColumnStats> entry : this.colStats.entrySet()) {\n        String col = entry.getKey();\n        ColumnStats stats = entry.getValue();\n        ColumnStats otherStats = other.colStats.get(col);\n        if (otherStats != null) {\n            colStats.put(col, stats.merge(otherStats));\n        }\n    }\n    return new TableStats(\n            this.rowCount >= 0 && other.rowCount >= 0\n                    ? this.rowCount + other.rowCount\n                    : UNKNOWN.rowCount,\n            colStats);\n}", "summary_tokens": ["merges", "two", "table", "stats"], "project": "flink"}
{"id": 9101, "code": "default E toExternalOrNull(I internal) {\n    if (internal == null) {\n        return null;\n    }\n    return toExternal(internal);\n}", "summary_tokens": ["converts", "to", "external", "data", "structure", "or", "null"], "project": "flink"}
{"id": 2122, "code": "public static <T> CompletableFuture<T> switchExecutor(\n        CompletableFuture<? extends T> source, Executor executor) {\n    return source.handleAsync(\n            (t, throwable) -> {\n                if (throwable != null) {\n                    throw new CompletionException(throwable);\n                } else {\n                    return t;\n                }\n            },\n            executor);\n}", "summary_tokens": ["switches", "the", "execution", "context", "of", "the", "given", "source", "future"], "project": "flink"}
{"id": 6024, "code": "protected void checkTaskOffloaded(ExecutionGraph eg, JobVertexID jobVertexId) throws Exception {\n    assertTrue(eg.getJobVertex(jobVertexId).getTaskInformationOrBlobKey().isLeft());\n}", "summary_tokens": ["checks", "that", "the", "task", "information", "for", "the", "job", "vertex", "has", "been", "offloaded", "successfully", "if", "offloading", "is", "used"], "project": "flink"}
{"id": 3324, "code": "public void preSuperstep() throws Exception {}", "summary_tokens": ["this", "method", "is", "executed", "once", "per", "superstep", "before", "the", "vertex", "update", "function", "is", "invoked", "for", "each", "vertex"], "project": "flink"}
{"id": 4896, "code": "public void reuseInputMetricsForTask() {\n    TaskIOMetricGroup taskIO = parentMetricGroup.getTaskIOMetricGroup();\n    taskIO.reuseRecordsInputCounter(this.numRecordsIn);\n}", "summary_tokens": ["causes", "the", "containing", "task", "to", "use", "this", "operators", "input", "record", "counter"], "project": "flink"}
{"id": 8674, "code": "public static String escapeJava(String str) {\n    return escapeJavaStyleString(str, false);\n}", "summary_tokens": ["escapes", "the", "characters", "in", "a", "code", "string", "code", "using", "java", "string", "rules"], "project": "flink"}
{"id": 5394, "code": "public void startNewKeyGroup(int keyGroupId) throws IOException {\n    if (isKeyGroupAlreadyStarted(keyGroupId)) {\n        throw new IOException(\"Key group \" + keyGroupId + \" already registered!\");\n    }\n    keyGroupRangeOffsets.setKeyGroupOffset(keyGroupId, delegate.getPos());\n    currentKeyGroup = keyGroupId;\n}", "summary_tokens": ["user", "code", "can", "call", "this", "method", "to", "signal", "that", "it", "begins", "to", "write", "a", "new", "key", "group", "with", "the", "given", "key", "group", "id"], "project": "flink"}
{"id": 2525, "code": "public static CsvSchema convert(RowType rowType) {\n    Builder builder = new CsvSchema.Builder();\n    List<RowType.RowField> fields = rowType.getFields();\n    for (int i = 0; i < rowType.getFieldCount(); i++) {\n        String fieldName = fields.get(i).getName();\n        LogicalType fieldType = fields.get(i).getType();\n        builder.addColumn(new Column(i, fieldName, convertType(fieldName, fieldType)));\n    }\n    return builder.build();\n}", "summary_tokens": ["convert", "row", "type", "to", "csv", "schema"], "project": "flink"}
{"id": 8614, "code": "public boolean isAnyOf(LogicalTypeRoot... typeRoots) {\n    return Arrays.stream(typeRoots).anyMatch(tr -> this.typeRoot == tr);\n}", "summary_tokens": ["returns", "whether", "the", "root", "of", "the", "type", "equals", "to", "at", "least", "on", "of", "the", "type", "roots", "or", "not"], "project": "flink"}
{"id": 2149, "code": "public void testSerializerDuplication() throws Exception {\n        \n        \n    TypeSerializer<String> statefulSerializer =\n            new KryoSerializer<>(String.class, new ExecutionConfig());\n\n    TestStateDescriptor<String> descr = new TestStateDescriptor<>(\"foobar\", statefulSerializer);\n\n    TypeSerializer<String> serializerA = descr.getSerializer();\n    TypeSerializer<String> serializerB = descr.getSerializer();\n\n        \n    assertNotSame(serializerA, serializerB);\n}", "summary_tokens": ["flink", "0", "tests", "that", "the", "returned", "serializer", "is", "duplicated"], "project": "flink"}
{"id": 9490, "code": "public void blockNonInterruptible() {\n    synchronized (lock) {\n        blockerReady = true;\n        lock.notifyAll();\n\n        while (!blockerReleased) {\n            try {\n                lock.wait();\n            } catch (InterruptedException ignored) {\n            }\n        }\n    }\n}", "summary_tokens": ["blocks", "until", "release", "blocker", "is", "called"], "project": "flink"}
{"id": 2194, "code": "public void checkEnableRestSSLAuthentication() {\n        \n    Configuration noSSLOptions = new Configuration();\n    noSSLOptions.setBoolean(SecurityOptions.SSL_REST_ENABLED, false);\n    noSSLOptions.setBoolean(SecurityOptions.SSL_REST_AUTHENTICATION_ENABLED, true);\n    assertFalse(SecurityOptions.isRestSSLAuthenticationEnabled(noSSLOptions));\n\n        \n    Configuration defaultOptions = new Configuration();\n    defaultOptions.setBoolean(SecurityOptions.SSL_REST_ENABLED, true);\n    assertFalse(SecurityOptions.isRestSSLAuthenticationEnabled(defaultOptions));\n\n    Configuration options = new Configuration();\n    options.setBoolean(SecurityOptions.SSL_REST_ENABLED, true);\n    options.setBoolean(SecurityOptions.SSL_REST_AUTHENTICATION_ENABLED, true);\n    assertTrue(SecurityOptions.isRestSSLAuthenticationEnabled(options));\n}", "summary_tokens": ["tests", "whether", "activation", "of", "rest", "mutual", "ssl", "authentication", "evaluates", "the", "config", "flags", "correctly"], "project": "flink"}
{"id": 2994, "code": "public static Map<String, String> getJobManagerSelectors(String clusterId) {\n    final Map<String, String> labels = getCommonLabels(clusterId);\n    labels.put(Constants.LABEL_COMPONENT_KEY, Constants.LABEL_COMPONENT_JOB_MANAGER);\n    return Collections.unmodifiableMap(labels);\n}", "summary_tokens": ["get", "job", "manager", "selectors", "for", "the", "current", "flink", "cluster"], "project": "flink"}
{"id": 8380, "code": "public static ProjectedRowData from(Projection projection) {\n    return new ProjectedRowData(projection.toTopLevelIndexes());\n}", "summary_tokens": ["create", "an", "empty", "projected", "row", "data", "starting", "from", "a", "projection"], "project": "flink"}
{"id": 9530, "code": "private static boolean credentialsAvailable() {\n    return isNotEmpty(S3_TEST_BUCKET)\n            && isNotEmpty(S3_TEST_ACCESS_KEY)\n            && isNotEmpty(S3_TEST_SECRET_KEY);\n}", "summary_tokens": ["checks", "whether", "s", "0", "test", "credentials", "are", "available", "in", "the", "environment", "variables", "of", "this", "jvm"], "project": "flink"}
{"id": 3755, "code": "public void testBulkIterationWithPartialSolutionProperties() throws Exception {\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n    DataSet<Tuple1<Long>> input1 =\n            env.generateSequence(1, 10)\n                    .map(\n                            new MapFunction<Long, Tuple1<Long>>() {\n                                @Override\n                                public Tuple1<Long> map(Long value) throws Exception {\n                                    return new Tuple1<>(value);\n                                }\n                            });\n\n    DataSet<Tuple1<Long>> input2 =\n            env.generateSequence(1, 10)\n                    .map(\n                            new MapFunction<Long, Tuple1<Long>>() {\n                                @Override\n                                public Tuple1<Long> map(Long value) throws Exception {\n                                    return new Tuple1<>(value);\n                                }\n                            });\n\n    DataSet<Tuple1<Long>> distinctInput = input1.distinct();\n\n    IterativeDataSet<Tuple1<Long>> iteration = distinctInput.iterate(10);\n\n    DataSet<Tuple1<Long>> iterationStep =\n            iteration\n                    .coGroup(input2)\n                    .where(0)\n                    .equalTo(0)\n                    .with(\n                            new CoGroupFunction<Tuple1<Long>, Tuple1<Long>, Tuple1<Long>>() {\n                                @Override\n                                public void coGroup(\n                                        Iterable<Tuple1<Long>> first,\n                                        Iterable<Tuple1<Long>> second,\n                                        Collector<Tuple1<Long>> out)\n                                        throws Exception {\n                                    Iterator<Tuple1<Long>> it = first.iterator();\n\n                                    if (it.hasNext()) {\n                                        out.collect(it.next());\n                                    }\n                                }\n                            });\n\n    DataSet<Tuple1<Long>> iterationResult = iteration.closeWith(iterationStep);\n\n    iterationResult.output(new DiscardingOutputFormat<Tuple1<Long>>());\n\n    Plan p = env.createProgramPlan();\n    OptimizedPlan op = compileNoStats(p);\n\n    new JobGraphGenerator().compileJobGraph(op);\n}", "summary_tokens": ["tests", "that", "interesting", "properties", "can", "be", "pushed", "out", "of", "the", "bulk", "iteration"], "project": "flink"}
{"id": 3712, "code": "public String getNodeName() {\n    return this.nodeName;\n}", "summary_tokens": ["gets", "the", "name", "of", "the", "plan", "node"], "project": "flink"}
{"id": 1350, "code": "public static Time of(long size, TimeUnit unit) {\n    return new Time(size, unit);\n}", "summary_tokens": ["creates", "a", "new", "time", "of", "the", "given", "duration", "and", "time", "unit"], "project": "flink"}
{"id": 2025, "code": "public static Iterator<Integer> getPortRangeFromString(String rangeDefinition)\n        throws NumberFormatException {\n    final String[] ranges = rangeDefinition.trim().split(\",\");\n\n    UnionIterator<Integer> iterators = new UnionIterator<>();\n\n    for (String rawRange : ranges) {\n        Iterator<Integer> rangeIterator;\n        String range = rawRange.trim();\n        int dashIdx = range.indexOf('-');\n        if (dashIdx == -1) {\n                \n            final int port = Integer.valueOf(range);\n            if (!isValidHostPort(port)) {\n                throw new IllegalConfigurationException(\n                        \"Invalid port configuration. Port must be between 0\"\n                                + \"and 65535, but was \"\n                                + port\n                                + \".\");\n            }\n            rangeIterator = Collections.singleton(Integer.valueOf(range)).iterator();\n        } else {\n                \n            final int start = Integer.valueOf(range.substring(0, dashIdx));\n            if (!isValidHostPort(start)) {\n                throw new IllegalConfigurationException(\n                        \"Invalid port configuration. Port must be between 0\"\n                                + \"and 65535, but was \"\n                                + start\n                                + \".\");\n            }\n            final int end = Integer.valueOf(range.substring(dashIdx + 1, range.length()));\n            if (!isValidHostPort(end)) {\n                throw new IllegalConfigurationException(\n                        \"Invalid port configuration. Port must be between 0\"\n                                + \"and 65535, but was \"\n                                + end\n                                + \".\");\n            }\n            rangeIterator =\n                    new Iterator<Integer>() {\n                        int i = start;\n\n                        @Override\n                        public boolean hasNext() {\n                            return i <= end;\n                        }\n\n                        @Override\n                        public Integer next() {\n                            return i++;\n                        }\n\n                        @Override\n                        public void remove() {\n                            throw new UnsupportedOperationException(\"Remove not supported\");\n                        }\n                    };\n        }\n        iterators.add(rangeIterator);\n    }\n\n    return iterators;\n}", "summary_tokens": ["returns", "an", "iterator", "over", "available", "ports", "defined", "by", "the", "range", "definition"], "project": "flink"}
{"id": 492, "code": "public <T extends IN> KafkaRecordSerializationSchemaBuilder<T> setPartitioner(\n        FlinkKafkaPartitioner<? super T> partitioner) {\n    KafkaRecordSerializationSchemaBuilder<T> self = self();\n    self.partitioner = checkNotNull(partitioner);\n    return self;\n}", "summary_tokens": ["sets", "a", "custom", "partitioner", "determining", "the", "target", "partition", "of", "the", "target", "topic"], "project": "flink"}
{"id": 734, "code": "private void testKafkaShuffle(int numElementsPerProducer, TimeCharacteristic timeCharacteristic)\n        throws Exception {\n    String topic = topic(\"test_simple\", timeCharacteristic);\n    final int numberOfPartitions = 1;\n    final int producerParallelism = 1;\n\n    createTestTopic(topic, numberOfPartitions, 1);\n\n    final StreamExecutionEnvironment env =\n            createEnvironment(producerParallelism, timeCharacteristic);\n    createKafkaShuffle(\n                    env,\n                    topic,\n                    numElementsPerProducer,\n                    producerParallelism,\n                    timeCharacteristic,\n                    numberOfPartitions)\n            .map(\n                    new ElementCountNoMoreThanValidator(\n                            numElementsPerProducer * producerParallelism))\n            .setParallelism(1)\n            .map(\n                    new ElementCountNoLessThanValidator(\n                            numElementsPerProducer * producerParallelism))\n            .setParallelism(1);\n\n    tryExecute(env, topic);\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["to", "test", "no", "data", "is", "lost", "or", "duplicated", "end", "0", "end"], "project": "flink"}
{"id": 3585, "code": "public void addCosts(Costs other) {\n        \n    if (this.networkCost == UNKNOWN || other.networkCost == UNKNOWN) {\n        this.networkCost = UNKNOWN;\n    } else {\n        this.networkCost += other.networkCost;\n    }\n\n    if (this.diskCost == UNKNOWN || other.diskCost == UNKNOWN) {\n        this.diskCost = UNKNOWN;\n    } else {\n        this.diskCost += other.diskCost;\n    }\n\n    if (this.cpuCost == UNKNOWN || other.cpuCost == UNKNOWN) {\n        this.cpuCost = UNKNOWN;\n    } else {\n        this.cpuCost += other.cpuCost;\n    }\n\n        \n\n    this.heuristicNetworkCost += other.heuristicNetworkCost;\n    this.heuristicDiskCost += other.heuristicDiskCost;\n    this.heuristicCpuCost += other.heuristicCpuCost;\n}", "summary_tokens": ["adds", "the", "given", "costs", "to", "these", "costs"], "project": "flink"}
{"id": 1296, "code": "public Map<String, Operator<?>> getBroadcastInputs() {\n    return Collections.emptyMap();\n}", "summary_tokens": ["delta", "iteration", "meta", "operator", "cannot", "have", "broadcast", "inputs"], "project": "flink"}
{"id": 2282, "code": "public FlinkContainersBuilder enableZookeeperHA() {\n    this.enableZookeeperHA = true;\n    return this;\n}", "summary_tokens": ["enables", "high", "availability", "service"], "project": "flink"}
{"id": 4287, "code": "public long getMinimum() {\n    return min;\n}", "summary_tokens": ["returns", "the", "minimum", "seen", "value"], "project": "flink"}
{"id": 3952, "code": "public void testChunkedResponse() throws Exception {\n    KvStateRegistry registry = new KvStateRegistry();\n    KvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n    MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    KvStateServerHandler handler =\n            new KvStateServerHandler(testServer, registry, serializer, stats);\n    EmbeddedChannel channel = new EmbeddedChannel(getFrameDecoder(), handler);\n\n    int numKeyGroups = 1;\n    AbstractStateBackend abstractBackend = new MemoryStateBackend();\n    DummyEnvironment dummyEnv = new DummyEnvironment(\"test\", 1, 0);\n    dummyEnv.setKvStateRegistry(registry);\n    AbstractKeyedStateBackend<Integer> backend =\n            createKeyedStateBackend(registry, numKeyGroups, abstractBackend, dummyEnv);\n\n    final TestRegistryListener registryListener = new TestRegistryListener();\n    registry.registerListener(dummyEnv.getJobID(), registryListener);\n\n        \n    ValueStateDescriptor<byte[]> desc =\n            new ValueStateDescriptor<>(\"any\", BytePrimitiveArraySerializer.INSTANCE);\n    desc.setQueryable(\"vanilla\");\n\n    ValueState<byte[]> state =\n            backend.getPartitionedState(\n                    VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, desc);\n\n        \n    byte[] bytes = new byte[2 * channel.config().getWriteBufferHighWaterMark()];\n\n    byte current = 0;\n    for (int i = 0; i < bytes.length; i++) {\n        bytes[i] = current++;\n    }\n\n    int key = 99812822;\n    backend.setCurrentKey(key);\n    state.update(bytes);\n\n        \n    byte[] serializedKeyAndNamespace =\n            KvStateSerializer.serializeKeyAndNamespace(\n                    key,\n                    IntSerializer.INSTANCE,\n                    VoidNamespace.INSTANCE,\n                    VoidNamespaceSerializer.INSTANCE);\n\n    long requestId = Integer.MAX_VALUE + 182828L;\n\n    assertTrue(registryListener.registrationName.equals(\"vanilla\"));\n\n    KvStateInternalRequest request =\n            new KvStateInternalRequest(registryListener.kvStateId, serializedKeyAndNamespace);\n    ByteBuf serRequest =\n            MessageSerializer.serializeRequest(channel.alloc(), requestId, request);\n\n        \n    channel.writeInbound(serRequest);\n\n    Object msg = readInboundBlocking(channel);\n    assertTrue(\"Not ChunkedByteBuf\", msg instanceof ChunkedByteBuf);\n    ((ChunkedByteBuf) msg).close();\n}", "summary_tokens": ["tests", "that", "large", "responses", "are", "chunked"], "project": "flink"}
{"id": 6044, "code": "public static void waitForAllExecutionsPredicate(\n        ExecutionGraph executionGraph,\n        Predicate<AccessExecution> executionPredicate,\n        long maxWaitMillis)\n        throws TimeoutException {\n    final Predicate<AccessExecutionGraph> allExecutionsPredicate =\n            allExecutionsPredicate(executionPredicate);\n    final Deadline deadline = Deadline.fromNow(Duration.ofMillis(maxWaitMillis));\n    boolean predicateResult;\n\n    do {\n        predicateResult = allExecutionsPredicate.test(executionGraph);\n\n        if (!predicateResult) {\n            try {\n                Thread.sleep(2L);\n            } catch (InterruptedException ignored) {\n                Thread.currentThread().interrupt();\n            }\n        }\n    } while (!predicateResult && deadline.hasTimeLeft());\n\n    if (!predicateResult) {\n        throw new TimeoutException(\"Not all executions fulfilled the predicate in time.\");\n    }\n}", "summary_tokens": ["waits", "until", "all", "executions", "fulfill", "the", "given", "predicate"], "project": "flink"}
{"id": 9185, "code": "public boolean tryProbe(RowData record) throws IOException {\n    if (!this.probeIterator.hasSource()) {\n            \n        this.probeIterator.setInstance(record);\n    }\n        \n    BinaryRowData probeKey = probeSideProjection.apply(record);\n    final int hash = hash(probeKey.hashCode(), this.currentRecursionDepth);\n\n    BinaryHashPartition p = this.partitionsBeingBuilt.get(hash % partitionsBeingBuilt.size());\n\n        \n        \n    if (p.isInMemory()) {\n        this.probeKey = probeKey;\n        this.probeRow = record;\n        p.bucketArea.startLookup(hash);\n        return true;\n    } else {\n        if (p.testHashBloomFilter(hash)) {\n            BinaryRowData row = originProbeSideSerializer.toBinaryRow(record);\n            p.insertIntoProbeBuffer(row);\n        }\n        return false;\n    }\n}", "summary_tokens": ["find", "matched", "build", "side", "rows", "for", "a", "probe", "row"], "project": "flink"}
{"id": 2505, "code": "public void testDeserializationReuseAvroRecordFalse() throws IOException {\n    Configuration parameters = new Configuration();\n\n    AvroInputFormat<User> format =\n            new AvroInputFormat<>(new Path(testFile.getAbsolutePath()), User.class);\n    format.setReuseAvroValue(false);\n\n    format.configure(parameters);\n    FileInputSplit[] splits = format.createInputSplits(1);\n    assertEquals(splits.length, 1);\n    format.open(splits[0]);\n\n    User u = format.nextRecord(null);\n    assertNotNull(u);\n\n    String name = u.getName().toString();\n    assertNotNull(\"empty record\", name);\n    assertEquals(\"name not equal\", TEST_NAME, name);\n\n        \n    List<CharSequence> sl = u.getTypeArrayString();\n    assertEquals(\"element 0 not equal\", TEST_ARRAY_STRING_1, sl.get(0).toString());\n    assertEquals(\"element 1 not equal\", TEST_ARRAY_STRING_2, sl.get(1).toString());\n\n    List<Boolean> bl = u.getTypeArrayBoolean();\n    assertEquals(\"element 0 not equal\", TEST_ARRAY_BOOLEAN_1, bl.get(0));\n    assertEquals(\"element 1 not equal\", TEST_ARRAY_BOOLEAN_2, bl.get(1));\n\n        \n    Colors enumValue = u.getTypeEnum();\n    assertEquals(\"enum not equal\", TEST_ENUM_COLOR, enumValue);\n\n        \n    Map<CharSequence, Long> lm = u.getTypeMap();\n    assertEquals(\n            \"map value of key 1 not equal\",\n            TEST_MAP_VALUE1,\n            lm.get(new Utf8(TEST_MAP_KEY1)).longValue());\n    assertEquals(\n            \"map value of key 2 not equal\",\n            TEST_MAP_VALUE2,\n            lm.get(new Utf8(TEST_MAP_KEY2)).longValue());\n\n    assertFalse(\"expecting second element\", format.reachedEnd());\n    assertNotNull(\"expecting second element\", format.nextRecord(u));\n\n    assertNull(format.nextRecord(u));\n    assertTrue(format.reachedEnd());\n\n    format.close();\n}", "summary_tokens": ["test", "if", "the", "avro", "input", "format", "is", "able", "to", "properly", "read", "data", "from", "an", "avro", "file"], "project": "flink"}
{"id": 8545, "code": "static <T extends Annotation> Set<T> collectAnnotationsOfMethod(\n        Class<T> annotation, Method annotatedMethod) {\n    return new LinkedHashSet<>(Arrays.asList(annotatedMethod.getAnnotationsByType(annotation)));\n}", "summary_tokens": ["collects", "all", "annotations", "of", "the", "given", "type", "defined", "in", "the", "given", "method"], "project": "flink"}
{"id": 127, "code": "void runOnce() {\n    try {\n            \n            \n        if (shouldRunFetchTask()) {\n            runningTask = fetchTask;\n        } else {\n            runningTask = taskQueue.take();\n        }\n            \n            \n            \n            \n            \n            \n            \n            \n        LOG.debug(\"Prepare to run {}\", runningTask);\n        if (!wakeUp.get() && runningTask.run()) {\n            LOG.debug(\"Finished running task {}\", runningTask);\n                \n            runningTask = null;\n            checkAndSetIdle();\n        }\n    } catch (Exception e) {\n        throw new RuntimeException(\n                String.format(\n                        \"SplitFetcher thread %d received unexpected exception while polling the records\",\n                        id),\n                e);\n    }\n        \n        \n    maybeEnqueueTask(runningTask);\n    synchronized (wakeUp) {\n            \n            \n        runningTask = null;\n            \n        wakeUp.set(false);\n        LOG.debug(\"Cleaned wakeup flag.\");\n    }\n}", "summary_tokens": ["package", "private", "method", "to", "help", "unit", "test"], "project": "flink"}
{"id": 1450, "code": "public void setBufferTimeout(long bufferTimeout) {\n    checkArgument(bufferTimeout >= -1);\n    this.bufferTimeout = bufferTimeout;\n}", "summary_tokens": ["set", "the", "buffer", "timeout", "of", "this", "transformation"], "project": "flink"}
{"id": 1265, "code": "public void accept(Visitor<Operator<?>> visitor) {\n    if (visitor.preVisit(this)) {\n        this.input.accept(visitor);\n        for (Operator<?> c : this.broadcastInputs.values()) {\n            c.accept(visitor);\n        }\n        visitor.postVisit(this);\n    }\n}", "summary_tokens": ["accepts", "the", "visitor", "and", "applies", "it", "this", "instance"], "project": "flink"}
{"id": 2330, "code": "public String get(String name, String defaultValue) {\n    String[] names = handleDeprecation(deprecationContext.get(), name);\n    String result = null;\n    for (String n : names) {\n        result = substituteVars(getProps().getProperty(n, defaultValue));\n    }\n    return result;\n}", "summary_tokens": ["get", "the", "value", "of", "the", "code", "name", "code"], "project": "flink"}
{"id": 5699, "code": "static List<String> getJmResourceParams(Configuration configuration) {\n    JobManagerProcessSpec jobManagerProcessSpec =\n            JobManagerProcessUtils.processSpecFromConfigWithNewOptionToInterpretLegacyHeap(\n                    configuration, JobManagerOptions.JVM_HEAP_MEMORY);\n\n    logMasterConfiguration(jobManagerProcessSpec);\n\n    return Arrays.asList(\n            JobManagerProcessUtils.generateJvmParametersStr(\n                    jobManagerProcessSpec, configuration),\n            JobManagerProcessUtils.generateDynamicConfigsStr(jobManagerProcessSpec));\n}", "summary_tokens": ["generate", "and", "print", "jvm", "parameters", "of", "flink", "master", "resources", "as", "one", "line"], "project": "flink"}
{"id": 4069, "code": "private static <R extends JarRequestBody, M extends MessageParameters>\n        List<String> getProgramArgs(HandlerRequest<R> request, Logger log)\n                throws RestHandlerException {\n    JarRequestBody requestBody = request.getRequestBody();\n    @SuppressWarnings(\"deprecation\")\n    List<String> programArgs =\n            tokenizeArguments(\n                    fromRequestBodyOrQueryParameter(\n                            emptyToNull(requestBody.getProgramArguments()),\n                            () -> getQueryParameter(request, ProgramArgsQueryParameter.class),\n                            null,\n                            log));\n    List<String> programArgsList =\n            fromRequestBodyOrQueryParameter(\n                    requestBody.getProgramArgumentsList(),\n                    () -> request.getQueryParameter(ProgramArgQueryParameter.class),\n                    null,\n                    log);\n    if (!programArgsList.isEmpty()) {\n        if (!programArgs.isEmpty()) {\n            throw new RestHandlerException(\n                    \"Confusing request: programArgs and programArgsList are specified, please, use only programArgsList\",\n                    HttpResponseStatus.BAD_REQUEST);\n        }\n        return programArgsList;\n    } else {\n        return programArgs;\n    }\n}", "summary_tokens": ["parse", "program", "arguments", "in", "jar", "run", "or", "plan", "request"], "project": "flink"}
{"id": 8100, "code": "public void notifyTableDrop(\n        @Nullable Catalog catalog,\n        ObjectIdentifier identifier,\n        ResolvedCatalogBaseTable<?> table,\n        boolean isTemporary,\n        boolean ignoreIfNotExists) {\n    if (isManagedTable(catalog, table)) {\n        discoverManagedTableFactory(classLoader)\n                .onDropTable(\n                        createTableFactoryContext(\n                                identifier, (ResolvedCatalogTable) table, isTemporary),\n                        ignoreIfNotExists);\n    }\n}", "summary_tokens": ["notify", "for", "dropping", "managed", "table"], "project": "flink"}
{"id": 3630, "code": "public int getParallelism() {\n    return this.parallelism;\n}", "summary_tokens": ["gets", "the", "parallelism", "for", "the", "operator", "represented", "by", "this", "optimizer", "node"], "project": "flink"}
{"id": 6311, "code": "public void testLeaderShouldBeCorrectedWhenOverwritten() throws Exception {\n    final String faultyContenderUrl = \"faultyContender\";\n\n    final TestingLeaderElectionEventHandler electionEventHandler =\n            new TestingLeaderElectionEventHandler(TEST_LEADER);\n    final TestingLeaderRetrievalEventHandler retrievalEventHandler =\n            new TestingLeaderRetrievalEventHandler();\n\n    ZooKeeperLeaderElectionDriver leaderElectionDriver = null;\n    LeaderRetrievalDriver leaderRetrievalDriver = null;\n\n    CuratorFrameworkWithUnhandledErrorListener anotherCuratorFrameworkWrapper = null;\n\n    try {\n\n        leaderElectionDriver =\n                createAndInitLeaderElectionDriver(\n                        curatorFrameworkWrapper.asCuratorFramework(), electionEventHandler);\n\n        electionEventHandler.waitForLeader(timeout);\n        assertThat(electionEventHandler.getConfirmedLeaderInformation(), is(TEST_LEADER));\n\n        anotherCuratorFrameworkWrapper =\n                ZooKeeperUtils.startCuratorFramework(\n                        configuration, NoOpFatalErrorHandler.INSTANCE);\n\n        ByteArrayOutputStream baos = new ByteArrayOutputStream();\n        ObjectOutputStream oos = new ObjectOutputStream(baos);\n\n        oos.writeUTF(faultyContenderUrl);\n        oos.writeObject(UUID.randomUUID());\n\n        oos.close();\n\n            \n        boolean dataWritten = false;\n\n        final String connectionInformationPath =\n                leaderElectionDriver.getConnectionInformationPath();\n\n        while (!dataWritten) {\n            anotherCuratorFrameworkWrapper\n                    .asCuratorFramework()\n                    .delete()\n                    .forPath(connectionInformationPath);\n\n            try {\n                anotherCuratorFrameworkWrapper\n                        .asCuratorFramework()\n                        .create()\n                        .forPath(connectionInformationPath, baos.toByteArray());\n\n                dataWritten = true;\n            } catch (KeeperException.NodeExistsException e) {\n                    \n            }\n        }\n\n            \n        leaderRetrievalDriver =\n                ZooKeeperUtils.createLeaderRetrievalDriverFactory(\n                                curatorFrameworkWrapper.asCuratorFramework())\n                        .createLeaderRetrievalDriver(\n                                retrievalEventHandler, retrievalEventHandler::handleError);\n\n        if (retrievalEventHandler.waitForNewLeader(timeout).equals(faultyContenderUrl)) {\n            retrievalEventHandler.waitForNewLeader(timeout);\n        }\n\n        assertThat(\n                retrievalEventHandler.getLeaderSessionID(),\n                is(TEST_LEADER.getLeaderSessionID()));\n        assertThat(retrievalEventHandler.getAddress(), is(TEST_LEADER.getLeaderAddress()));\n    } finally {\n        electionEventHandler.close();\n        if (leaderElectionDriver != null) {\n            leaderElectionDriver.close();\n        }\n        if (leaderRetrievalDriver != null) {\n            leaderRetrievalDriver.close();\n        }\n        if (anotherCuratorFrameworkWrapper != null) {\n            anotherCuratorFrameworkWrapper.close();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "the", "current", "leader", "is", "notified", "when", "his", "leader", "connection", "information", "in", "zoo", "keeper", "are", "overwritten"], "project": "flink"}
{"id": 3947, "code": "public void testCloseChannelOnExceptionCaught() throws Exception {\n    KvStateRegistry registry = new KvStateRegistry();\n    AtomicKvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n    MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    KvStateServerHandler handler =\n            new KvStateServerHandler(testServer, registry, serializer, stats);\n    EmbeddedChannel channel = new EmbeddedChannel(handler);\n\n    channel.pipeline().fireExceptionCaught(new RuntimeException(\"Expected test Exception\"));\n\n    ByteBuf buf = (ByteBuf) readInboundBlocking(channel);\n    buf.skipBytes(4); \n\n        \n    assertEquals(MessageType.SERVER_FAILURE, MessageSerializer.deserializeHeader(buf));\n    Throwable response = MessageSerializer.deserializeServerFailure(buf);\n    buf.release();\n\n    assertTrue(response.getMessage().contains(\"Expected test Exception\"));\n\n    channel.closeFuture().await(READ_TIMEOUT_MILLIS);\n    assertFalse(channel.isActive());\n}", "summary_tokens": ["tests", "that", "the", "channel", "is", "closed", "if", "an", "exception", "reaches", "the", "channel", "handler"], "project": "flink"}
{"id": 9396, "code": "public static void setFloat(MemorySegment[] segments, int offset, float value) {\n    if (inFirstSegment(segments, offset, 4)) {\n        segments[0].putFloat(offset, value);\n    } else {\n        setFloatMultiSegments(segments, offset, value);\n    }\n}", "summary_tokens": ["set", "float", "from", "segments"], "project": "flink"}
{"id": 1900, "code": "public static final BigDecimal parseField(\n        byte[] bytes, int startPos, int length, char delimiter) {\n    if (length <= 0) {\n        throw new NumberFormatException(\"Invalid input: Empty string\");\n    }\n    int i = 0;\n    final byte delByte = (byte) delimiter;\n\n    while (i < length && bytes[startPos + i] != delByte) {\n        i++;\n    }\n\n    if (i > 0\n            && (Character.isWhitespace(bytes[startPos])\n                    || Character.isWhitespace(bytes[startPos + i - 1]))) {\n        throw new NumberFormatException(\n                \"There is leading or trailing whitespace in the numeric field.\");\n    }\n\n    final char[] chars = new char[i];\n    for (int j = 0; j < i; j++) {\n        final byte b = bytes[startPos + j];\n        if ((b < '0' || b > '9') && b != '-' && b != '+' && b != '.' && b != 'E' && b != 'e') {\n            throw new NumberFormatException();\n        }\n        chars[j] = (char) bytes[startPos + j];\n    }\n    return new BigDecimal(chars);\n}", "summary_tokens": ["static", "utility", "to", "parse", "a", "field", "of", "type", "big", "decimal", "from", "a", "byte", "sequence", "that", "represents", "text", "characters", "such", "as", "when", "read", "from", "a", "file", "stream"], "project": "flink"}
{"id": 9278, "code": "public static void putStringNormalizedKey(\n        StringData value, MemorySegment target, int offset, int numBytes) {\n    BinaryStringData binaryString = (BinaryStringData) value;\n    final int limit = offset + numBytes;\n    final int end = binaryString.getSizeInBytes();\n    for (int i = 0; i < end && offset < limit; i++) {\n        target.put(offset++, binaryString.byteAt(i));\n    }\n\n    for (int i = offset; i < limit; i++) {\n        target.put(i, (byte) 0);\n    }\n}", "summary_tokens": ["utf", "0", "supports", "bytes", "comparison"], "project": "flink"}
{"id": 3817, "code": "public boolean isBundleFinished() {\n    return elementCount == 0;\n}", "summary_tokens": ["returns", "whether", "the", "bundle", "is", "finished"], "project": "flink"}
{"id": 2877, "code": "public int getNumberOfParameters() {\n    return data.size();\n}", "summary_tokens": ["returns", "number", "of", "parameters", "in", "parameter", "tool"], "project": "flink"}
{"id": 188, "code": "public B setConnectionUsername(String username) {\n    checkNotNull(username);\n    this.username = username;\n    return self();\n}", "summary_tokens": ["sets", "the", "username", "used", "to", "authenticate", "the", "connection", "with", "the", "elasticsearch", "cluster"], "project": "flink"}
{"id": 7491, "code": "public void checkpointStarted(CheckpointBarrier barrier) {\n    blockConsumption(null);\n}", "summary_tokens": ["this", "method", "is", "used", "with", "unaligned", "checkpoints", "to", "mark", "the", "arrival", "of", "a", "first", "checkpoint", "barrier"], "project": "flink"}
{"id": 5704, "code": "default CompletableFuture<Acknowledge> disposeSavepoint(\n        final String savepointPath, @RpcTimeout final Time timeout) {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["dispose", "the", "given", "savepoint"], "project": "flink"}
{"id": 9634, "code": "public void testProcessFunctionSideOutput() throws Exception {\n    final OutputTag<String> sideOutputTag = new OutputTag<String>(\"side\") {};\n\n    TestListResultSink<String> sideOutputResultSink = new TestListResultSink<>();\n    TestListResultSink<Integer> resultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(3);\n\n    DataStream<Integer> dataStream = see.fromCollection(elements);\n\n    SingleOutputStreamOperator<Integer> passThroughtStream =\n            dataStream.process(\n                    new ProcessFunction<Integer, Integer>() {\n                        private static final long serialVersionUID = 1L;\n\n                        @Override\n                        public void processElement(\n                                Integer value, Context ctx, Collector<Integer> out)\n                                throws Exception {\n                            out.collect(value);\n                            ctx.output(sideOutputTag, \"sideout-\" + String.valueOf(value));\n                        }\n                    });\n\n    passThroughtStream.getSideOutput(sideOutputTag).addSink(sideOutputResultSink);\n    passThroughtStream.addSink(resultSink);\n    see.execute();\n\n    assertEquals(\n            Arrays.asList(\"sideout-1\", \"sideout-2\", \"sideout-3\", \"sideout-4\", \"sideout-5\"),\n            sideOutputResultSink.getSortedResult());\n    assertEquals(Arrays.asList(1, 2, 3, 4, 5), resultSink.getSortedResult());\n}", "summary_tokens": ["test", "process", "function", "side", "output"], "project": "flink"}
{"id": 6745, "code": "private long updateValueWithCopyOnWrite(long node, byte[] value) {\n        \n    int valueSize = value == null ? 0 : value.length;\n    int totalValueLen = SkipListUtils.getValueMetaLen() + valueSize;\n    long valuePointer = allocateSpace(totalValueLen);\n\n    Node nodeStorage = getNodeSegmentAndOffset(node);\n    MemorySegment nodeSegment = nodeStorage.nodeSegment;\n    int offsetInNodeSegment = nodeStorage.nodeOffset;\n    long oldValuePointer = SkipListUtils.getValuePointer(nodeSegment, offsetInNodeSegment);\n\n    doWriteValue(valuePointer, value, stateMapVersion, node, oldValuePointer);\n\n        \n        \n    SkipListUtils.putValuePointer(nodeSegment, offsetInNodeSegment, valuePointer);\n\n    return oldValuePointer;\n}", "summary_tokens": ["update", "the", "value", "of", "the", "node", "with", "copy", "on", "write", "mode"], "project": "flink"}
{"id": 1071, "code": "public ExecutionConfig enableObjectReuse() {\n    objectReuse = true;\n    return this;\n}", "summary_tokens": ["enables", "reusing", "objects", "that", "flink", "internally", "uses", "for", "deserialization", "and", "passing", "data", "to", "user", "code", "functions"], "project": "flink"}
{"id": 4995, "code": "public void setIsCompacted(boolean compacted) {\n    this.compacted = compacted;\n}", "summary_tokens": ["sets", "compaction", "status", "should", "only", "be", "set", "code", "true", "code", "directly", "after", "compaction", "and", "code", "false", "code", "when", "garbage", "was", "created"], "project": "flink"}
{"id": 7385, "code": "public static <OUT, OP extends StreamOperator<OUT>>\n        Tuple2<OP, Optional<ProcessingTimeService>> createOperator(\n                StreamOperatorFactory<OUT> operatorFactory,\n                StreamTask<OUT, ?> containingTask,\n                StreamConfig configuration,\n                Output<StreamRecord<OUT>> output,\n                OperatorEventDispatcher operatorEventDispatcher) {\n\n    MailboxExecutor mailboxExecutor =\n            containingTask\n                    .getMailboxExecutorFactory()\n                    .createExecutor(configuration.getChainIndex());\n\n    if (operatorFactory instanceof YieldingOperatorFactory) {\n        ((YieldingOperatorFactory<?>) operatorFactory).setMailboxExecutor(mailboxExecutor);\n    }\n\n    final Supplier<ProcessingTimeService> processingTimeServiceFactory =\n            () ->\n                    containingTask\n                            .getProcessingTimeServiceFactory()\n                            .createProcessingTimeService(mailboxExecutor);\n\n    final ProcessingTimeService processingTimeService;\n    if (operatorFactory instanceof ProcessingTimeServiceAware) {\n        processingTimeService = processingTimeServiceFactory.get();\n        ((ProcessingTimeServiceAware) operatorFactory)\n                .setProcessingTimeService(processingTimeService);\n    } else {\n        processingTimeService = null;\n    }\n\n        \n    OP op =\n            operatorFactory.createStreamOperator(\n                    new StreamOperatorParameters<>(\n                            containingTask,\n                            configuration,\n                            output,\n                            processingTimeService != null\n                                    ? () -> processingTimeService\n                                    : processingTimeServiceFactory,\n                            operatorEventDispatcher));\n    return new Tuple2<>(op, Optional.ofNullable(processingTimeService));\n}", "summary_tokens": ["creates", "a", "new", "operator", "using", "a", "factory", "and", "makes", "sure", "that", "all", "special", "factory", "traits", "are", "properly", "handled"], "project": "flink"}
{"id": 6167, "code": "public void testWrappingOfRemoteErrorMessage() throws Exception {\n    EmbeddedChannel ch = createEmbeddedChannel();\n\n    NetworkClientHandler handler = getClientHandler(ch);\n\n        \n    RemoteInputChannel[] rich =\n            new RemoteInputChannel[] {createRemoteInputChannel(), createRemoteInputChannel()};\n\n    for (RemoteInputChannel r : rich) {\n        when(r.getInputChannelId()).thenReturn(new InputChannelID());\n        handler.addInputChannel(r);\n    }\n\n        \n    ch.pipeline()\n            .fireChannelRead(\n                    new NettyMessage.ErrorResponse(\n                            new RuntimeException(\"Expected test exception\"),\n                            rich[0].getInputChannelId()));\n\n    try {\n            \n        ch.checkException();\n    } catch (Exception e) {\n        fail(\n                \"The exception reached the end of the pipeline and \"\n                        + \"was not handled correctly by the last handler.\");\n    }\n\n    verify(rich[0], times(1)).onError(isA(RemoteTransportException.class));\n    verify(rich[1], never()).onError(any(Throwable.class));\n\n        \n    ch.pipeline()\n            .fireChannelRead(\n                    new NettyMessage.ErrorResponse(\n                            new RuntimeException(\"Expected test exception\")));\n\n    try {\n            \n        ch.checkException();\n    } catch (Exception e) {\n        fail(\n                \"The exception reached the end of the pipeline and \"\n                        + \"was not handled correctly by the last handler.\");\n    }\n\n    verify(rich[0], times(2)).onError(isA(RemoteTransportException.class));\n    verify(rich[1], times(1)).onError(isA(RemoteTransportException.class));\n}", "summary_tokens": ["verifies", "that", "netty", "message"], "project": "flink"}
{"id": 4129, "code": "List<BlobServerConnection> getCurrentActiveConnections() {\n    synchronized (activeConnections) {\n        return new ArrayList<>(activeConnections);\n    }\n}", "summary_tokens": ["returns", "all", "the", "current", "active", "connections", "in", "the", "blob", "server"], "project": "flink"}
{"id": 5173, "code": "public String getRestBaseUrl() {\n    synchronized (lock) {\n        Preconditions.checkState(\n                state != State.CREATED, \"The RestServerEndpoint has not been started yet.\");\n        return restBaseUrl;\n    }\n}", "summary_tokens": ["returns", "the", "base", "url", "of", "the", "rest", "server", "endpoint"], "project": "flink"}
{"id": 3456, "code": "public <K, T, OUT> DataStream<OUT> process(\n        String uid,\n        WindowReaderFunction<T, OUT, K, W> readerFunction,\n        TypeInformation<K> keyType,\n        TypeInformation<T> stateType,\n        TypeInformation<OUT> outputType)\n        throws IOException {\n\n    WindowReaderOperator<?, K, StreamRecord<T>, W, OUT> operator =\n            WindowReaderOperator.evictingWindow(\n                    new ProcessEvictingWindowReader<>(readerFunction),\n                    keyType,\n                    windowSerializer,\n                    stateType,\n                    env.getConfig());\n\n    return readWindowOperator(uid, outputType, operator);\n}", "summary_tokens": ["reads", "window", "state", "generated", "without", "any", "preaggregation", "such", "as", "windowed", "stream", "apply", "and", "windowed", "stream", "process"], "project": "flink"}
{"id": 4139, "code": "static File getStorageLocation(File storageDir, @Nullable JobID jobId, BlobKey key)\n        throws IOException {\n    File file = new File(getStorageLocationPath(storageDir.getAbsolutePath(), jobId, key));\n\n    Files.createDirectories(file.getParentFile().toPath());\n\n    return file;\n}", "summary_tokens": ["returns", "the", "designated", "physical", "storage", "location", "of", "the", "blob", "with", "the", "given", "key"], "project": "flink"}
{"id": 3976, "code": "private Method lookupRpcMethod(final String methodName, final Class<?>[] parameterTypes)\n        throws NoSuchMethodException {\n    return rpcEndpoint.getClass().getMethod(methodName, parameterTypes);\n}", "summary_tokens": ["look", "up", "the", "rpc", "method", "on", "the", "given", "rpc", "endpoint", "instance"], "project": "flink"}
{"id": 2121, "code": "public static <T> void doForward(\n        @Nullable T value, @Nullable Throwable throwable, CompletableFuture<T> target) {\n    if (throwable != null) {\n        target.completeExceptionally(throwable);\n    } else {\n        target.complete(value);\n    }\n}", "summary_tokens": ["completes", "the", "given", "future", "with", "either", "the", "given", "value", "or", "throwable", "depending", "on", "which", "parameter", "is", "not", "null"], "project": "flink"}
{"id": 7753, "code": "public void testLatencyMarkEmissionDisabledOverrideViaExecutionConfig() throws Exception {\n    Configuration taskConfiguration = new Configuration();\n    taskConfiguration.setLong(MetricOptions.LATENCY_INTERVAL, LATENCY_MARK_INTERVAL);\n    ExecutionConfig executionConfig = new ExecutionConfig();\n    executionConfig.setLatencyTrackingInterval(0);\n\n    testLatencyMarkEmission(false, taskConfiguration, executionConfig);\n}", "summary_tokens": ["verifies", "that", "latency", "metrics", "can", "be", "disabled", "via", "the", "execution", "config", "even", "if", "they", "are", "enabled", "via", "the", "configuration"], "project": "flink"}
{"id": 7330, "code": "private <T> Collection<Integer> transformFeedback(FeedbackTransformation<T> iterate) {\n\n    if (shouldExecuteInBatchMode) {\n        throw new UnsupportedOperationException(\n                \"Iterations are not supported in BATCH\"\n                        + \" execution mode. If you want to execute such a pipeline, please set the \"\n                        + \"'\"\n                        + ExecutionOptions.RUNTIME_MODE.key()\n                        + \"'=\"\n                        + RuntimeExecutionMode.STREAMING.name());\n    }\n\n    if (iterate.getFeedbackEdges().size() <= 0) {\n        throw new IllegalStateException(\n                \"Iteration \" + iterate + \" does not have any feedback edges.\");\n    }\n\n    List<Transformation<?>> inputs = iterate.getInputs();\n    checkState(inputs.size() == 1);\n    Transformation<?> input = inputs.get(0);\n\n    List<Integer> resultIds = new ArrayList<>();\n\n        \n    Collection<Integer> inputIds = transform(input);\n    resultIds.addAll(inputIds);\n\n        \n    if (alreadyTransformed.containsKey(iterate)) {\n        return alreadyTransformed.get(iterate);\n    }\n\n        \n    Tuple2<StreamNode, StreamNode> itSourceAndSink =\n            streamGraph.createIterationSourceAndSink(\n                    iterate.getId(),\n                    getNewIterationNodeId(),\n                    getNewIterationNodeId(),\n                    iterate.getWaitTime(),\n                    iterate.getParallelism(),\n                    iterate.getMaxParallelism(),\n                    iterate.getMinResources(),\n                    iterate.getPreferredResources());\n\n    StreamNode itSource = itSourceAndSink.f0;\n    StreamNode itSink = itSourceAndSink.f1;\n\n        \n    streamGraph.setSerializers(\n            itSource.getId(),\n            null,\n            null,\n            iterate.getOutputType().createSerializer(executionConfig));\n    streamGraph.setSerializers(\n            itSink.getId(),\n            iterate.getOutputType().createSerializer(executionConfig),\n            null,\n            null);\n\n        \n        \n    resultIds.add(itSource.getId());\n\n        \n        \n    alreadyTransformed.put(iterate, resultIds);\n\n        \n    List<Integer> allFeedbackIds = new ArrayList<>();\n\n    for (Transformation<T> feedbackEdge : iterate.getFeedbackEdges()) {\n        Collection<Integer> feedbackIds = transform(feedbackEdge);\n        allFeedbackIds.addAll(feedbackIds);\n        for (Integer feedbackId : feedbackIds) {\n            streamGraph.addEdge(feedbackId, itSink.getId(), 0);\n        }\n    }\n\n    String slotSharingGroup = determineSlotSharingGroup(null, allFeedbackIds);\n        \n    if (slotSharingGroup == null) {\n        slotSharingGroup = \"SlotSharingGroup-\" + iterate.getId();\n    }\n\n    itSink.setSlotSharingGroup(slotSharingGroup);\n    itSource.setSlotSharingGroup(slotSharingGroup);\n\n    return resultIds;\n}", "summary_tokens": ["transforms", "a", "feedback", "transformation"], "project": "flink"}
{"id": 1397, "code": "public boolean isCompatibleAsIs() {\n    return resultType == Type.COMPATIBLE_AS_IS;\n}", "summary_tokens": ["returns", "whether", "or", "not", "the", "type", "of", "the", "compatibility", "is", "type", "compatible", "as", "is"], "project": "flink"}
{"id": 6199, "code": "static ByteBuf blockChannel(EmbeddedChannel channel) {\n    final int highWaterMark = channel.config().getWriteBufferHighWaterMark();\n        \n        \n    ByteBuf channelBlockingBuffer = Unpooled.buffer(highWaterMark).writerIndex(highWaterMark);\n    channel.write(channelBlockingBuffer);\n    assertFalse(channel.isWritable());\n\n    return channelBlockingBuffer;\n}", "summary_tokens": ["blocks", "the", "given", "channel", "by", "adding", "a", "buffer", "that", "is", "bigger", "than", "the", "high", "watermark"], "project": "flink"}
{"id": 2190, "code": "public void testLoggersParentFirst() {\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"org.slf4j\"));\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"org.apache.log4j\"));\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"org.apache.logging\"));\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"org.apache.commons.logging\"));\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"ch.qos.logback\"));\n}", "summary_tokens": ["to", "avoid", "multiple", "binding", "problems", "and", "warnings", "for", "logger", "frameworks", "we", "load", "them", "parent", "first"], "project": "flink"}
{"id": 1779, "code": "public void putShort(int index, short value) {\n    final long pos = address + index;\n    if (index >= 0 && pos <= addressLimit - 2) {\n        UNSAFE.putShort(heapMemory, pos, value);\n    } else if (address > addressLimit) {\n        throw new IllegalStateException(\"segment has been freed\");\n    } else {\n            \n        throw new IndexOutOfBoundsException();\n    }\n}", "summary_tokens": ["writes", "the", "given", "short", "value", "into", "this", "buffer", "at", "the", "given", "position", "using", "the", "native", "byte", "order", "of", "the", "system"], "project": "flink"}
{"id": 7957, "code": "private RelDataType createCollectionType(\n        RelDataType elementType, RelDataTypeFactory typeFactory) {\n    switch (collectionTypeName) {\n        case MULTISET:\n            return typeFactory.createMultisetType(elementType, -1);\n        case ARRAY:\n            return typeFactory.createArrayType(elementType, -1);\n\n        default:\n            throw Util.unexpected(collectionTypeName);\n    }\n}", "summary_tokens": ["create", "collection", "data", "type"], "project": "flink"}
{"id": 7048, "code": "public int getParallelism() {\n    return transformation.getParallelism();\n}", "summary_tokens": ["gets", "the", "parallelism", "for", "this", "operator"], "project": "flink"}
{"id": 5627, "code": "public static int getPageSize(Configuration configuration) {\n    final int pageSize =\n            checkedDownCast(\n                    configuration.get(TaskManagerOptions.MEMORY_SEGMENT_SIZE).getBytes());\n\n        \n    checkConfigParameter(\n            pageSize >= MemoryManager.MIN_PAGE_SIZE,\n            pageSize,\n            TaskManagerOptions.MEMORY_SEGMENT_SIZE.key(),\n            \"Minimum memory segment size is \" + MemoryManager.MIN_PAGE_SIZE);\n        \n    checkConfigParameter(\n            MathUtils.isPowerOf2(pageSize),\n            pageSize,\n            TaskManagerOptions.MEMORY_SEGMENT_SIZE.key(),\n            \"Memory segment size must be a power of 2.\");\n\n    return pageSize;\n}", "summary_tokens": ["parses", "the", "configuration", "to", "get", "the", "page", "size", "and", "validates", "the", "value"], "project": "flink"}
{"id": 749, "code": "private void flushSync() throws Exception {\n    while (producer.getOutstandingRecordsCount() > 0) {\n        producer.flush();\n        try {\n            Thread.sleep(500);\n        } catch (InterruptedException e) {\n            LOG.warn(\"Flushing was interrupted.\");\n            break;\n        }\n    }\n}", "summary_tokens": ["a", "reimplementation", "of", "kinesis", "producer", "flush", "sync"], "project": "flink"}
{"id": 7703, "code": "public void testListStateAddAllNullEntries() throws Exception {\n    CheckpointableKeyedStateBackend<String> keyedBackend =\n            createKeyedBackend(StringSerializer.INSTANCE);\n\n    final ListStateDescriptor<Long> stateDescr =\n            new ListStateDescriptor<>(\"my-state\", Long.class);\n\n    try {\n        ListState<Long> state =\n                keyedBackend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, stateDescr);\n\n        keyedBackend.setCurrentKey(\"abc\");\n        assertNull(state.get());\n\n        expectedException.expect(NullPointerException.class);\n\n        List<Long> adding = new ArrayList<>();\n        adding.add(3L);\n        adding.add(null);\n        adding.add(5L);\n        state.addAll(adding);\n    } finally {\n        keyedBackend.close();\n        keyedBackend.dispose();\n    }\n}", "summary_tokens": ["this", "test", "verifies", "that", "all", "list", "state", "implementations", "are", "consistent", "in", "not", "allowing", "list", "state", "add", "all", "list", "to", "be", "called", "with", "null", "entries", "in", "the", "list", "of", "entries", "to", "add"], "project": "flink"}
{"id": 7044, "code": "public <R> SingleOutputStreamOperator<R> map(\n        CoMapFunction<IN1, IN2, R> coMapper, TypeInformation<R> outputType) {\n    return transform(\"Co-Map\", outputType, new CoStreamMap<>(inputStream1.clean(coMapper)));\n}", "summary_tokens": ["applies", "a", "co", "map", "transformation", "on", "a", "connected", "streams", "and", "maps", "the", "output", "to", "a", "common", "type"], "project": "flink"}
{"id": 9184, "code": "public void putBuildRow(RowData row) throws IOException {\n    final int hashCode = hash(this.buildSideProjection.apply(row).hashCode(), 0);\n        \n    insertIntoTable(originBuildSideSerializer.toBinaryRow(row), hashCode);\n}", "summary_tokens": ["put", "a", "build", "side", "row", "to", "hash", "table"], "project": "flink"}
{"id": 2145, "code": "public void testOnlyLevel2NestedDirectories() {\n    try {\n        String rootDir = TestFileUtils.randomFileName();\n        String nestedDir = TestFileUtils.randomFileName();\n        String firstNestedNestedDir = TestFileUtils.randomFileName();\n        String secondNestedNestedDir = TestFileUtils.randomFileName();\n\n        File testDir = tempFolder.newFolder(rootDir);\n        tempFolder.newFolder(rootDir, nestedDir);\n        File nestedNestedDir1 = tempFolder.newFolder(rootDir, nestedDir, firstNestedNestedDir);\n        File nestedNestedDir2 = tempFolder.newFolder(rootDir, nestedDir, secondNestedNestedDir);\n\n            \n        TestFileUtils.createTempFileInDirectory(nestedNestedDir1.getAbsolutePath(), \"paella\");\n        TestFileUtils.createTempFileInDirectory(nestedNestedDir1.getAbsolutePath(), \"kalamari\");\n        TestFileUtils.createTempFileInDirectory(nestedNestedDir2.getAbsolutePath(), \"fideua\");\n        TestFileUtils.createTempFileInDirectory(nestedNestedDir2.getAbsolutePath(), \"bravas\");\n\n        this.format.setFilePath(new Path(testDir.getAbsolutePath()));\n        this.config.setBoolean(\"recursive.file.enumeration\", true);\n        format.configure(this.config);\n\n        FileInputSplit[] splits = format.createInputSplits(1);\n        Assert.assertEquals(4, splits.length);\n    } catch (Exception ex) {\n        ex.printStackTrace();\n        Assert.fail(ex.getMessage());\n    }\n}", "summary_tokens": ["tests", "if", "the", "recursion", "is", "invoked", "correctly", "in", "nested", "directories"], "project": "flink"}
{"id": 871, "code": "public void testAsyncErrorRethrownAfterFlush() throws Throwable {\n    final DummyFlinkKinesisProducer<String> producer =\n            new DummyFlinkKinesisProducer<>(new SimpleStringSchema());\n\n    OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer));\n\n    testHarness.open();\n\n    testHarness.processElement(new StreamRecord<>(\"msg-1\"));\n    testHarness.processElement(new StreamRecord<>(\"msg-2\"));\n    testHarness.processElement(new StreamRecord<>(\"msg-3\"));\n\n        \n    UserRecordResult result = mock(UserRecordResult.class);\n    when(result.isSuccessful()).thenReturn(true);\n    producer.getPendingRecordFutures().get(0).set(result);\n\n    CheckedThread snapshotThread =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                        \n                        \n                    testHarness.snapshot(123L, 123L);\n                }\n            };\n    snapshotThread.start();\n\n        \n    producer.getPendingRecordFutures()\n            .get(1)\n            .setException(new Exception(\"artificial async failure for 2nd message\"));\n    producer.getPendingRecordFutures().get(2).set(mock(UserRecordResult.class));\n\n    try {\n        snapshotThread.sync();\n    } catch (Exception e) {\n            \n        Assert.assertTrue(\n                ExceptionUtils.findThrowableWithMessage(\n                                e, \"artificial async failure for 2nd message\")\n                        .isPresent());\n\n            \n        return;\n    }\n\n    Assert.fail();\n}", "summary_tokens": ["test", "ensuring", "that", "if", "an", "async", "exception", "is", "caught", "for", "one", "of", "the", "flushed", "requests", "on", "checkpoint", "it", "should", "be", "rethrown", "we", "set", "a", "timeout", "because", "the", "test", "will", "not", "finish", "if", "the", "logic", "is", "broken"], "project": "flink"}
{"id": 4150, "code": "public File getFile(JobID jobId, PermanentBlobKey key) throws IOException {\n    checkNotNull(jobId);\n    return getFileInternal(jobId, key);\n}", "summary_tokens": ["returns", "the", "path", "to", "a", "local", "copy", "of", "the", "file", "associated", "with", "the", "provided", "job", "id", "and", "blob", "key"], "project": "flink"}
{"id": 5935, "code": "public void testCorruptDataInStateHandleStoreShouldNotBeSkipped() throws Exception {\n    final long corruptCkpId = 2L;\n    checkpointStorageHelper.setRetrieveStateFunction(\n            state -> {\n                if (state.getCheckpointID() == corruptCkpId) {\n                    throw new IOException(\"Failed to retrieve checkpoint \" + corruptCkpId);\n                }\n                return state;\n            });\n\n    final TestingStateHandleStore<CompletedCheckpoint> stateHandleStore =\n            builder.setGetAllSupplier(() -> createStateHandles(3)).build();\n    try {\n        createCompletedCheckpointStore(stateHandleStore);\n    } catch (Exception e) {\n        if (ExceptionUtils.findThrowable(e, IOException.class).isPresent()) {\n            return;\n        }\n        throw e;\n    }\n    fail();\n}", "summary_tokens": ["we", "got", "an", "ioexception", "when", "retrieving", "checkpoint", "0"], "project": "flink"}
{"id": 6246, "code": "public void testSetupLogic() throws Exception {\n    final NettyShuffleEnvironment environment = createNettyShuffleEnvironment();\n    final SingleInputGate inputGate = createInputGate(environment);\n    try (Closer closer = Closer.create()) {\n        closer.register(environment::close);\n        closer.register(inputGate::close);\n\n            \n        assertNull(inputGate.getBufferPool());\n        for (InputChannel inputChannel : inputGate.getInputChannels().values()) {\n            assertTrue(\n                    inputChannel instanceof RecoveredInputChannel\n                            || inputChannel instanceof UnknownInputChannel);\n            if (inputChannel instanceof RecoveredInputChannel) {\n                assertEquals(\n                        0,\n                        ((RecoveredInputChannel) inputChannel)\n                                .bufferManager.getNumberOfAvailableBuffers());\n            }\n        }\n\n        inputGate.setup();\n\n            \n        assertNotNull(inputGate.getBufferPool());\n        assertEquals(1, inputGate.getBufferPool().getNumberOfRequiredMemorySegments());\n        for (InputChannel inputChannel : inputGate.getInputChannels().values()) {\n            if (inputChannel instanceof RemoteRecoveredInputChannel) {\n                assertEquals(\n                        0,\n                        ((RemoteRecoveredInputChannel) inputChannel)\n                                .bufferManager.getNumberOfAvailableBuffers());\n            } else if (inputChannel instanceof LocalRecoveredInputChannel) {\n                assertEquals(\n                        0,\n                        ((LocalRecoveredInputChannel) inputChannel)\n                                .bufferManager.getNumberOfAvailableBuffers());\n            }\n        }\n\n        inputGate.convertRecoveredInputChannels();\n        assertNotNull(inputGate.getBufferPool());\n        assertEquals(1, inputGate.getBufferPool().getNumberOfRequiredMemorySegments());\n        for (InputChannel inputChannel : inputGate.getInputChannels().values()) {\n            if (inputChannel instanceof RemoteInputChannel) {\n                assertEquals(\n                        2, ((RemoteInputChannel) inputChannel).getNumberOfAvailableBuffers());\n            }\n        }\n    }\n}", "summary_tokens": ["tests", "input", "gate", "setup", "should", "create", "the", "respective", "buffer", "pool", "and", "assign", "exclusive", "buffers", "for", "remote", "input", "channel", "s", "but", "should", "not", "request", "partitions"], "project": "flink"}
{"id": 8400, "code": "public <T> Optional<T> getValueAs(Class<T> clazz) {\n    Preconditions.checkArgument(!clazz.isPrimitive());\n\n    if (value == null) {\n        return Optional.empty();\n    }\n\n    Object convertedValue = null;\n\n    if (clazz.isInstance(value)) {\n        convertedValue = clazz.cast(value);\n    } else {\n        Class<?> valueClass = value.getClass();\n        if (clazz == Period.class) {\n            convertedValue = convertToPeriod(value, valueClass);\n        } else if (clazz == Duration.class) {\n            convertedValue = convertToDuration(value, valueClass);\n        } else if (clazz == LocalDate.class) {\n            convertedValue = convertToLocalDate(value, valueClass);\n        } else if (clazz == LocalTime.class) {\n            convertedValue = convertToLocalTime(value, valueClass);\n        } else if (clazz == LocalDateTime.class) {\n            convertedValue = convertToLocalDateTime(value, valueClass);\n        } else if (clazz == OffsetDateTime.class) {\n            convertedValue = convertToOffsetDateTime(value, valueClass);\n        } else if (clazz == Instant.class) {\n            convertedValue = convertToInstant(value, valueClass);\n        } else if (clazz == BigDecimal.class) {\n            convertedValue = convertToBigDecimal(value);\n        }\n    }\n\n    return Optional.ofNullable((T) convertedValue);\n}", "summary_tokens": ["returns", "the", "value", "excluding", "null", "as", "an", "instance", "of", "the", "given", "class"], "project": "flink"}
{"id": 3132, "code": "public ChoiceParameter addHiddenChoices(String... hiddenChoices) {\n    Collections.addAll(this.hiddenChoices, hiddenChoices);\n    return this;\n}", "summary_tokens": ["add", "additional", "hidden", "choices"], "project": "flink"}
{"id": 2601, "code": "private boolean nextBatch() throws IOException {\n    for (WritableColumnVector v : writableVectors) {\n        v.reset();\n    }\n    columnarBatch.setNumRows(0);\n    if (rowsReturned >= totalRowCount) {\n        return false;\n    }\n    if (rowsReturned == totalCountLoadedSoFar) {\n        readNextRowGroup();\n    }\n\n    int num = (int) Math.min(batchSize, totalCountLoadedSoFar - rowsReturned);\n    for (int i = 0; i < columnReaders.length; ++i) {\n            \n        columnReaders[i].readToVector(num, writableVectors[i]);\n    }\n    rowsReturned += num;\n    columnarBatch.setNumRows(num);\n    rowsInBatch = num;\n    return true;\n}", "summary_tokens": ["advances", "to", "the", "next", "batch", "of", "rows"], "project": "flink"}
{"id": 1415, "code": "default List<WriterStateT> snapshotState(long checkpointId) throws IOException {\n    return snapshotState();\n}", "summary_tokens": ["the", "writer", "s", "state"], "project": "flink"}
{"id": 3654, "code": "public Set<RequestedLocalProperties> getLocalProperties() {\n    return this.localProps;\n}", "summary_tokens": ["gets", "the", "interesting", "local", "properties"], "project": "flink"}
{"id": 8128, "code": "public Optional<FunctionDefinition> getFunctionDefinition(String name) {\n    for (String moduleName : usedModules) {\n        if (loadedModules.get(moduleName).listFunctions().stream()\n                .anyMatch(name::equalsIgnoreCase)) {\n            LOG.debug(\"Got FunctionDefinition '{}' from '{}' module.\", name, moduleName);\n            return loadedModules.get(moduleName).getFunctionDefinition(name);\n        }\n    }\n\n    LOG.debug(\"Cannot find FunctionDefinition '{}' from any loaded modules.\", name);\n    return Optional.empty();\n}", "summary_tokens": ["get", "an", "optional", "of", "function", "definition", "by", "a", "given", "name"], "project": "flink"}
{"id": 8798, "code": "private RelNode projectJoinOutputWithNullability(\n        Join join, Project project, int nullIndicatorPos) {\n    final RelDataTypeFactory typeFactory = join.getCluster().getTypeFactory();\n    final RelNode left = join.getLeft();\n    final JoinRelType joinType = join.getJoinType();\n\n    RexInputRef nullIndicator =\n            new RexInputRef(\n                    nullIndicatorPos,\n                    typeFactory.createTypeWithNullability(\n                            join.getRowType().getFieldList().get(nullIndicatorPos).getType(),\n                            true));\n\n        \n    List<Pair<RexNode, String>> newProjExprs = new ArrayList<>();\n\n        \n        \n    List<RelDataTypeField> leftInputFields = left.getRowType().getFieldList();\n\n    for (int i = 0; i < leftInputFields.size(); i++) {\n        newProjExprs.add(RexInputRef.of2(i, leftInputFields));\n    }\n\n        \n        \n        \n    boolean projectPulledAboveLeftCorrelator = joinType.generatesNullsOnRight();\n\n    for (Pair<RexNode, String> pair : project.getNamedProjects()) {\n        RexNode newProjExpr =\n                removeCorrelationExpr(\n                        pair.left, projectPulledAboveLeftCorrelator, nullIndicator);\n\n        newProjExprs.add(Pair.of(newProjExpr, pair.right));\n    }\n\n    return relBuilder\n            .push(join)\n            .projectNamed(Pair.left(newProjExprs), Pair.right(newProjExprs), true)\n            .build();\n}", "summary_tokens": ["pulls", "project", "above", "the", "join", "from", "its", "rhs", "input"], "project": "flink"}
{"id": 2910, "code": "public void checkStatistics() {\n    BinaryInputFormat<T> input = this.createInputFormat();\n    BaseStatistics statistics = input.getStatistics(null);\n    Assert.assertEquals(this.numberOfTuples, statistics.getNumberOfRecords());\n}", "summary_tokens": ["tests", "the", "statistics", "of", "the", "given", "format"], "project": "flink"}
{"id": 6006, "code": "public void testAvailableJobDetails() throws IOException {\n    final int numberExecutionGraphs = 10;\n    final Collection<ExecutionGraphInfo> executionGraphInfos =\n            generateTerminalExecutionGraphInfos(numberExecutionGraphs);\n\n    final Collection<JobDetails> jobDetails = generateJobDetails(executionGraphInfos);\n\n    final File rootDir = temporaryFolder.newFolder();\n\n    try (final FileExecutionGraphInfoStore executionGraphInfoStore =\n            createDefaultExecutionGraphInfoStore(rootDir)) {\n        for (ExecutionGraphInfo executionGraphInfo : executionGraphInfos) {\n            executionGraphInfoStore.put(executionGraphInfo);\n        }\n\n        assertThat(\n                executionGraphInfoStore.getAvailableJobDetails(),\n                Matchers.containsInAnyOrder(jobDetails.toArray()));\n    }\n}", "summary_tokens": ["tests", "that", "we", "obtain", "the", "correct", "collection", "of", "available", "job", "details"], "project": "flink"}
{"id": 7848, "code": "public void processUntil(Supplier<Boolean> condition) throws Exception {\n    while (!condition.get()) {\n        processAll();\n    }\n}", "summary_tokens": ["process", "until", "condition", "is", "met"], "project": "flink"}
{"id": 341, "code": "public static Partition createHivePartition(\n        String dbName,\n        String tableName,\n        List<String> values,\n        StorageDescriptor sd,\n        Map<String, String> parameters) {\n    Partition partition = new Partition();\n    partition.setDbName(dbName);\n    partition.setTableName(tableName);\n    partition.setValues(values);\n    partition.setParameters(parameters);\n    partition.setSd(sd);\n    int currentTime = (int) (System.currentTimeMillis() / 1000);\n    partition.setCreateTime(currentTime);\n    partition.setLastAccessTime(currentTime);\n    return partition;\n}", "summary_tokens": ["creates", "a", "hive", "partition", "instance"], "project": "flink"}
{"id": 3313, "code": "public VertexMetrics<K, VV, EV> setIncludeZeroDegreeVertices(\n        boolean includeZeroDegreeVertices) {\n    this.includeZeroDegreeVertices = includeZeroDegreeVertices;\n\n    return this;\n}", "summary_tokens": ["by", "default", "only", "the", "edge", "set", "is", "processed", "for", "the", "computation", "of", "degree"], "project": "flink"}
{"id": 1539, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 7558, "code": "public void closeAllOperators() throws Exception {\n    isClosed = true;\n}", "summary_tokens": ["execute", "stream", "operator", "close", "of", "each", "operator", "in", "the", "chain", "of", "this", "stream", "task"], "project": "flink"}
{"id": 8653, "code": "public static java.sql.Date toSQLDate(int v) {\n        \n    final long t = v * MILLIS_PER_DAY;\n    return new java.sql.Date(t - LOCAL_TZ.getOffset(t));\n}", "summary_tokens": ["converts", "the", "internal", "representation", "of", "a", "sql", "date", "int", "to", "the", "java", "type", "used", "for", "udf", "parameters", "java"], "project": "flink"}
{"id": 5621, "code": "public Iterator<T> iterator() {\n    return elements.iterator();\n}", "summary_tokens": ["returns", "the", "bounded", "fifoqueue", "s", "iterator"], "project": "flink"}
{"id": 2440, "code": "public static ConfluentRegistryAvroDeserializationSchema<GenericRecord> forGeneric(\n        Schema schema,\n        String url,\n        int identityMapCapacity,\n        @Nullable Map<String, ?> registryConfigs) {\n    return new ConfluentRegistryAvroDeserializationSchema<>(\n            GenericRecord.class,\n            schema,\n            new CachedSchemaCoderProvider(null, url, identityMapCapacity, registryConfigs));\n}", "summary_tokens": ["creates", "confluent", "registry", "avro", "deserialization", "schema", "that", "produces", "generic", "record", "using", "the", "provided", "reader", "schema", "and", "looks", "up", "the", "writer", "schema", "in", "the", "confluent", "schema", "registry"], "project": "flink"}
{"id": 7563, "code": "private <OUT, OP extends StreamOperator<OUT>> OP createOperator(\n        StreamTask<OUT, ?> containingTask,\n        StreamConfig operatorConfig,\n        ClassLoader userCodeClassloader,\n        WatermarkGaugeExposingOutput<StreamRecord<OUT>> output,\n        List<StreamOperatorWrapper<?, ?>> allOperatorWrappers,\n        boolean isHead) {\n\n        \n    Tuple2<OP, Optional<ProcessingTimeService>> chainedOperatorAndTimeService =\n            StreamOperatorFactoryUtil.createOperator(\n                    operatorConfig.getStreamOperatorFactory(userCodeClassloader),\n                    containingTask,\n                    operatorConfig,\n                    output,\n                    operatorEventDispatcher);\n\n    OP chainedOperator = chainedOperatorAndTimeService.f0;\n    allOperatorWrappers.add(\n            createOperatorWrapper(\n                    chainedOperator,\n                    containingTask,\n                    operatorConfig,\n                    chainedOperatorAndTimeService.f1,\n                    isHead));\n\n    chainedOperator\n            .getMetricGroup()\n            .gauge(\n                    MetricNames.IO_CURRENT_OUTPUT_WATERMARK,\n                    output.getWatermarkGauge()::getValue);\n    return chainedOperator;\n}", "summary_tokens": ["create", "and", "return", "a", "single", "operator", "from", "the", "given", "operator", "config", "that", "will", "be", "producing", "records", "to", "the", "output"], "project": "flink"}
{"id": 3107, "code": "public void testTimeoutWindowPruningWindowBorders() throws Exception {\n    List<StreamRecord<Event>> streamEvents = new ArrayList<>();\n\n    streamEvents.add(new StreamRecord<>(new Event(1, \"start\", 1.0), 1L));\n    streamEvents.add(new StreamRecord<>(new Event(2, \"start\", 2.0), 2L));\n    streamEvents.add(new StreamRecord<>(new Event(3, \"foobar\", 3.0), 3L));\n    streamEvents.add(new StreamRecord<>(new Event(4, \"end\", 4.0), 3L));\n\n    List<Map<String, List<Event>>> expectedPatterns = new ArrayList<>();\n\n    Map<String, List<Event>> secondPattern = new HashMap<>();\n    secondPattern.put(\"start\", Collections.singletonList(new Event(2, \"start\", 2.0)));\n    secondPattern.put(\"end\", Collections.singletonList(new Event(4, \"end\", 4.0)));\n\n    expectedPatterns.add(secondPattern);\n\n    NFA<Event> nfa = createStartEndNFA();\n    NFATestHarness nfaTestHarness = NFATestHarness.forNFA(nfa).build();\n\n    Collection<Map<String, List<Event>>> actualPatterns =\n            nfaTestHarness.consumeRecords(streamEvents);\n\n    assertEquals(expectedPatterns, actualPatterns);\n}", "summary_tokens": ["tests", "that", "pruning", "shared", "buffer", "elements", "and", "computations", "state", "use", "the", "same", "window", "border", "semantics", "left", "side", "inclusive", "and", "right", "side", "exclusive"], "project": "flink"}
{"id": 2988, "code": "public static String getInternalServiceName(String clusterId) {\n    return clusterId;\n}", "summary_tokens": ["generate", "name", "of", "the", "internal", "service"], "project": "flink"}
{"id": 882, "code": "public static <T, V> void setOptionValue(\n        Configuration configuration,\n        ConfigOption<T> option,\n        Function<T, V> convertor,\n        Consumer<V> setter) {\n    if (configuration.contains(option)) {\n        V value = getOptionValue(configuration, option, convertor);\n        setter.accept(value);\n    }\n}", "summary_tokens": ["query", "the", "config", "option", "s", "value", "convert", "it", "into", "a", "required", "type", "set", "it", "to", "a", "given", "builder"], "project": "flink"}
{"id": 819, "code": "public static boolean isValidShardId(String shardId) {\n    return shardId == null ? false : shardId.matches(\"^shardId-\\\\d{20}-{0,1}\\\\w{0,36}\");\n}", "summary_tokens": ["dynamodb", "streams", "shard", "id", "is", "a", "char", "string", "ranging", "from", "0", "characters", "to", "0", "characters"], "project": "flink"}
{"id": 9673, "code": "public static void tryExecute(StreamExecutionEnvironment see, String name) throws Exception {\n    JobClient jobClient = null;\n    try {\n        StreamGraph graph = see.getStreamGraph();\n        graph.setJobName(name);\n        jobClient = see.executeAsync(graph);\n        jobClient.getJobExecutionResult().get();\n    } catch (Throwable root) {\n        if (jobClient != null) {\n            try {\n                jobClient.cancel().get();\n            } catch (Exception e) {\n                    \n                    \n            }\n        }\n\n        Optional<SuccessException> successAsCause =\n                ExceptionUtils.findThrowable(root, SuccessException.class);\n\n        if (!successAsCause.isPresent()) {\n            root.printStackTrace();\n            fail(\"Test failed: \" + root.getMessage());\n        }\n    }\n}", "summary_tokens": ["execute", "the", "job", "and", "wait", "for", "the", "job", "result", "synchronously"], "project": "flink"}
{"id": 4746, "code": "public JobID getJobID() {\n    return this.jobID;\n}", "summary_tokens": ["returns", "the", "id", "of", "the", "job"], "project": "flink"}
{"id": 4237, "code": "default void reset() throws Exception {}", "summary_tokens": ["this", "method", "is", "called", "by", "the", "checkpoint", "coordinator", "to", "reset", "the", "hook", "when", "execution", "is", "restarted", "in", "the", "absence", "of", "any", "checkpoint", "state"], "project": "flink"}
{"id": 4481, "code": "default boolean isApproximatelyAvailable() {\n    return getAvailableFuture() == AVAILABLE;\n}", "summary_tokens": ["checks", "whether", "this", "instance", "is", "available", "only", "via", "constant", "available", "to", "avoid", "performance", "concern", "caused", "by", "volatile", "access", "in", "completable", "future", "is", "done"], "project": "flink"}
{"id": 1429, "code": "public int getParallelism() {\n    return parallelism;\n}", "summary_tokens": ["returns", "the", "parallelism", "of", "this", "transformation"], "project": "flink"}
{"id": 7375, "code": "public InternalTimersSnapshot<K, N> snapshotTimersForKeyGroup(int keyGroupIdx) {\n    return new InternalTimersSnapshot<>(\n            keySerializer,\n            namespaceSerializer,\n            eventTimeTimersQueue.getSubsetForKeyGroup(keyGroupIdx),\n            processingTimeTimersQueue.getSubsetForKeyGroup(keyGroupIdx));\n}", "summary_tokens": ["snapshots", "the", "timers", "both", "processing", "and", "event", "time", "ones", "for", "a", "given", "key", "group", "idx"], "project": "flink"}
{"id": 1496, "code": "public static <T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17>\n        Tuple18<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16, T17>\n                of(\n                        T0 f0,\n                        T1 f1,\n                        T2 f2,\n                        T3 f3,\n                        T4 f4,\n                        T5 f5,\n                        T6 f6,\n                        T7 f7,\n                        T8 f8,\n                        T9 f9,\n                        T10 f10,\n                        T11 f11,\n                        T12 f12,\n                        T13 f13,\n                        T14 f14,\n                        T15 f15,\n                        T16 f16,\n                        T17 f17) {\n    return new Tuple18<>(\n            f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 2700, "code": "public void clearJobListeners() {\n    this.jobListeners.clear();\n}", "summary_tokens": ["clear", "all", "registered", "job", "listener", "s"], "project": "flink"}
{"id": 4003, "code": "public void testFailingAddressResolution() throws Exception {\n    CompletableFuture<DummyRpcGateway> futureRpcGateway =\n            akkaRpcService.connect(\"foobar\", DummyRpcGateway.class);\n\n    try {\n        futureRpcGateway.get(timeout.getSize(), timeout.getUnit());\n\n        fail(\"The rpc connection resolution should have failed.\");\n    } catch (ExecutionException exception) {\n            \n        assertTrue(exception.getCause() instanceof RpcConnectionException);\n    }\n}", "summary_tokens": ["tests", "that", "a", "rpc", "connection", "exception", "is", "thrown", "if", "the", "rpc", "endpoint", "cannot", "be", "connected", "to"], "project": "flink"}
{"id": 9112, "code": "static void write(\n        BinaryWriter writer,\n        int pos,\n        Object o,\n        LogicalType type,\n        TypeSerializer<?> serializer) {\n    switch (type.getTypeRoot()) {\n        case BOOLEAN:\n            writer.writeBoolean(pos, (boolean) o);\n            break;\n        case TINYINT:\n            writer.writeByte(pos, (byte) o);\n            break;\n        case SMALLINT:\n            writer.writeShort(pos, (short) o);\n            break;\n        case INTEGER:\n        case DATE:\n        case TIME_WITHOUT_TIME_ZONE:\n        case INTERVAL_YEAR_MONTH:\n            writer.writeInt(pos, (int) o);\n            break;\n        case BIGINT:\n        case INTERVAL_DAY_TIME:\n            writer.writeLong(pos, (long) o);\n            break;\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n            TimestampType timestampType = (TimestampType) type;\n            writer.writeTimestamp(pos, (TimestampData) o, timestampType.getPrecision());\n            break;\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            LocalZonedTimestampType lzTs = (LocalZonedTimestampType) type;\n            writer.writeTimestamp(pos, (TimestampData) o, lzTs.getPrecision());\n            break;\n        case FLOAT:\n            writer.writeFloat(pos, (float) o);\n            break;\n        case DOUBLE:\n            writer.writeDouble(pos, (double) o);\n            break;\n        case CHAR:\n        case VARCHAR:\n            writer.writeString(pos, (StringData) o);\n            break;\n        case DECIMAL:\n            DecimalType decimalType = (DecimalType) type;\n            writer.writeDecimal(pos, (DecimalData) o, decimalType.getPrecision());\n            break;\n        case ARRAY:\n            writer.writeArray(pos, (ArrayData) o, (ArrayDataSerializer) serializer);\n            break;\n        case MAP:\n        case MULTISET:\n            writer.writeMap(pos, (MapData) o, (MapDataSerializer) serializer);\n            break;\n        case ROW:\n        case STRUCTURED_TYPE:\n            writer.writeRow(pos, (RowData) o, (RowDataSerializer) serializer);\n            break;\n        case RAW:\n            writer.writeRawValue(\n                    pos, (RawValueData<?>) o, (RawValueDataSerializer<?>) serializer);\n            break;\n        case BINARY:\n        case VARBINARY:\n            writer.writeBinary(pos, (byte[]) o);\n            break;\n        default:\n            throw new UnsupportedOperationException(\"Not support type: \" + type);\n    }\n}", "summary_tokens": ["use", "create", "value", "setter", "logical", "type", "for", "avoiding", "logical", "types", "during", "runtime"], "project": "flink"}
{"id": 1884, "code": "public static boolean compareRows(List<Row> l1, List<Row> l2, boolean ignoreOrder) {\n    if (l1 == l2) {\n        return true;\n    } else if (l1 == null || l2 == null) {\n        return false;\n    }\n    if (ignoreOrder) {\n        return deepEqualsListUnordered(l1, l2);\n    } else {\n        return deepEqualsListOrdered(l1, l2);\n    }\n}", "summary_tokens": ["compares", "two", "list", "s", "of", "row", "for", "deep", "equality"], "project": "flink"}
{"id": 2665, "code": "public <K extends Comparable<K>> PartitionOperator<T> partitionByRange(\n        KeySelector<T, K> keyExtractor) {\n    final TypeInformation<K> keyType =\n            TypeExtractor.getKeySelectorTypes(keyExtractor, getType());\n    return new PartitionOperator<>(\n            this,\n            PartitionMethod.RANGE,\n            new Keys.SelectorFunctionKeys<>(clean(keyExtractor), this.getType(), keyType),\n            Utils.getCallLocationName());\n}", "summary_tokens": ["range", "partitions", "a", "data", "set", "using", "the", "specified", "key", "selector"], "project": "flink"}
{"id": 4418, "code": "public static ExecutionState getAggregateJobVertexState(\n        int[] verticesPerState, int parallelism) {\n    if (verticesPerState == null || verticesPerState.length != ExecutionState.values().length) {\n        throw new IllegalArgumentException(\n                \"Must provide an array as large as there are execution states.\");\n    }\n\n    if (verticesPerState[ExecutionState.FAILED.ordinal()] > 0) {\n        return ExecutionState.FAILED;\n    }\n    if (verticesPerState[ExecutionState.CANCELING.ordinal()] > 0) {\n        return ExecutionState.CANCELING;\n    } else if (verticesPerState[ExecutionState.CANCELED.ordinal()] > 0) {\n        return ExecutionState.CANCELED;\n    } else if (verticesPerState[ExecutionState.INITIALIZING.ordinal()] > 0) {\n        return ExecutionState.INITIALIZING;\n    } else if (verticesPerState[ExecutionState.RUNNING.ordinal()] > 0) {\n        return ExecutionState.RUNNING;\n    } else if (verticesPerState[ExecutionState.FINISHED.ordinal()] > 0) {\n        return verticesPerState[ExecutionState.FINISHED.ordinal()] == parallelism\n                ? ExecutionState.FINISHED\n                : ExecutionState.RUNNING;\n    } else {\n            \n        return ExecutionState.CREATED;\n    }\n}", "summary_tokens": ["a", "utility", "function", "that", "computes", "an", "aggregated", "state", "for", "the", "vertex"], "project": "flink"}
{"id": 8366, "code": "public BinaryStringData toLowerCase() {\n    if (javaObject != null) {\n        return javaToLowerCase();\n    }\n    if (binarySection.sizeInBytes == 0) {\n        return EMPTY_UTF8;\n    }\n    int size = binarySection.segments[0].size();\n    BinaryStringData.SegmentAndOffset segmentAndOffset = startSegmentAndOffset(size);\n    byte[] bytes = new byte[binarySection.sizeInBytes];\n    bytes[0] = (byte) Character.toTitleCase(segmentAndOffset.value());\n    for (int i = 0; i < binarySection.sizeInBytes; i++) {\n        byte b = segmentAndOffset.value();\n        if (numBytesForFirstByte(b) != 1) {\n                \n            return javaToLowerCase();\n        }\n        int lower = Character.toLowerCase((int) b);\n        if (lower > 127) {\n                \n            return javaToLowerCase();\n        }\n        bytes[i] = (byte) lower;\n        segmentAndOffset.nextByte(size);\n    }\n    return fromBytes(bytes);\n}", "summary_tokens": ["converts", "all", "of", "the", "characters", "in", "this", "binary", "string", "data", "to", "lower", "case"], "project": "flink"}
{"id": 4823, "code": "protected void onClose() {}", "summary_tokens": ["this", "method", "is", "called", "when", "the", "slot", "pool", "service", "is", "closed"], "project": "flink"}
{"id": 8679, "code": "public static int[] getPrimaryKeyIndices(TableSchema schema) {\n    if (schema.getPrimaryKey().isPresent()) {\n        List<String> fieldNames = DataTypeUtils.flattenToNames(schema.toPhysicalRowDataType());\n        return schema.getPrimaryKey().get().getColumns().stream()\n                .mapToInt(fieldNames::indexOf)\n                .toArray();\n    } else {\n        return new int[0];\n    }\n}", "summary_tokens": ["returns", "the", "field", "indices", "of", "primary", "key", "in", "the", "physical", "columns", "of", "this", "schema", "not", "include", "computed", "columns", "or", "metadata", "columns"], "project": "flink"}
{"id": 5765, "code": "private void testGetFailsDuringLookup(\n        final JobID jobId1, final JobID jobId2, BlobKey.BlobType blobType)\n        throws IOException, InterruptedException {\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n\n            \n        BlobKey key = put(server, jobId1, data, blobType);\n        assertNotNull(key);\n        verifyType(blobType, key);\n\n            \n        File blobFile = server.getStorageLocation(jobId1, key);\n        assertTrue(blobFile.delete());\n\n            \n        verifyDeleted(cache, jobId1, key);\n\n            \n        BlobKey key2 = put(server, jobId2, data, blobType);\n        assertNotNull(key2);\n        verifyKeyDifferentHashEquals(key, key2);\n\n            \n        get(cache, jobId2, key2);\n            \n        verifyDeleted(cache, jobId1, key);\n\n        if (blobType == PERMANENT_BLOB) {\n                \n            assertTrue(server.getStorageLocation(jobId2, key2).exists());\n                \n            blobFile = cache.getPermanentBlobService().getStorageLocation(jobId2, key2);\n            assertTrue(blobFile.delete());\n                \n            get(cache, jobId2, key2);\n\n                \n            blobFile = cache.getPermanentBlobService().getStorageLocation(jobId2, key2);\n            assertTrue(blobFile.delete());\n            blobFile = server.getStorageLocation(jobId2, key2);\n            assertTrue(blobFile.delete());\n            verifyDeleted(cache, jobId2, key2);\n        } else {\n                \n            verifyDeletedEventually(server, jobId2, key2);\n                \n            blobFile = cache.getTransientBlobService().getStorageLocation(jobId2, key2);\n            assertTrue(blobFile.delete());\n                \n            verifyDeleted(cache, jobId2, key2);\n        }\n    }\n}", "summary_tokens": ["checks", "the", "correct", "result", "if", "a", "get", "operation", "fails", "during", "the", "lookup", "of", "the", "file"], "project": "flink"}
{"id": 4804, "code": "private void verifyIsRunning() {\n    checkState(running, \"Not running. Forgot to call start()?\");\n}", "summary_tokens": ["verifies", "that", "the", "state", "is", "running"], "project": "flink"}
{"id": 883, "code": "private void validateSchemaInfo(SchemaInfo info) {\n    SchemaType type = info.getType();\n    if (type == SchemaType.PROTOBUF || type == SchemaType.PROTOBUF_NATIVE) {\n        checkState(\n                haveProtobuf(), \"protobuf-java should be provided if you use related schema.\");\n    }\n}", "summary_tokens": ["we", "would", "throw", "exception", "if", "schema", "type", "is", "protobuf", "and", "user", "don", "t", "provide", "protobuf", "java", "in", "class", "path"], "project": "flink"}
{"id": 9665, "code": "public void testAdditionalFieldWithKeyedState() throws Exception {\n    testPojoSerializerUpgrade(SOURCE_A, SOURCE_D, true, true);\n}", "summary_tokens": ["adding", "fields", "to", "a", "pojo", "as", "keyed", "state", "should", "succeed"], "project": "flink"}
{"id": 6416, "code": "public void testWorkerTerminatedNoLongerRequired() throws Exception {\n    new Context() {\n        {\n            final ResourceID tmResourceId = ResourceID.generate();\n            final AtomicInteger requestCount = new AtomicInteger(0);\n\n            final List<CompletableFuture<TaskExecutorProcessSpec>>\n                    requestWorkerFromDriverFutures = new ArrayList<>();\n            requestWorkerFromDriverFutures.add(new CompletableFuture<>());\n            requestWorkerFromDriverFutures.add(new CompletableFuture<>());\n\n            driverBuilder.setRequestResourceFunction(\n                    taskExecutorProcessSpec -> {\n                        int idx = requestCount.getAndIncrement();\n                        assertThat(idx, lessThan(2));\n\n                        requestWorkerFromDriverFutures\n                                .get(idx)\n                                .complete(taskExecutorProcessSpec);\n                        return CompletableFuture.completedFuture(tmResourceId);\n                    });\n\n            runTest(\n                    () -> {\n                            \n                        CompletableFuture<Boolean> startNewWorkerFuture =\n                                runInMainThread(\n                                        () ->\n                                                getResourceManager()\n                                                        .startNewWorker(WORKER_RESOURCE_SPEC));\n                        TaskExecutorProcessSpec taskExecutorProcessSpec =\n                                requestWorkerFromDriverFutures\n                                        .get(0)\n                                        .get(TIMEOUT_SEC, TimeUnit.SECONDS);\n\n                        assertThat(\n                                startNewWorkerFuture.get(TIMEOUT_SEC, TimeUnit.SECONDS),\n                                is(true));\n                        assertThat(\n                                taskExecutorProcessSpec,\n                                is(\n                                        TaskExecutorProcessUtils\n                                                .processSpecFromWorkerResourceSpec(\n                                                        flinkConfig, WORKER_RESOURCE_SPEC)));\n\n                            \n                        CompletableFuture<RegistrationResponse> registerTaskExecutorFuture =\n                                registerTaskExecutor(tmResourceId);\n                        assertThat(\n                                registerTaskExecutorFuture.get(TIMEOUT_SEC, TimeUnit.SECONDS),\n                                instanceOf(RegistrationResponse.Success.class));\n\n                            \n                        runInMainThread(\n                                        () -> {\n                                            getResourceManager()\n                                                    .onWorkerTerminated(\n                                                            tmResourceId,\n                                                            \"terminate for testing\");\n                                                \n                                                \n                                                \n                                            return null;\n                                        })\n                                .get(TIMEOUT_SEC, TimeUnit.SECONDS);\n                        assertFalse(requestWorkerFromDriverFutures.get(1).isDone());\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "worker", "terminated", "and", "is", "no", "longer", "required"], "project": "flink"}
{"id": 4956, "code": "public long getOversizedRecordCount() {\n    return oversizedRecordCount;\n}", "summary_tokens": ["gets", "the", "number", "of", "oversized", "records", "handled", "by", "this", "combiner"], "project": "flink"}
{"id": 8186, "code": "public List<String> getColumns() {\n    return columns;\n}", "summary_tokens": ["list", "of", "column", "names", "for", "which", "the", "primary", "key", "was", "defined"], "project": "flink"}
{"id": 6551, "code": "private void testCloseBeforeComplete(CheckpointStreamWithResultProvider resultProvider)\n        throws IOException {\n    resultProvider.getCheckpointOutputStream().write(0x42);\n    resultProvider.close();\n    try {\n        resultProvider.closeAndFinalizeCheckpointStreamResult();\n        Assert.fail();\n    } catch (IOException ignore) {\n    }\n}", "summary_tokens": ["test", "that", "an", "exception", "is", "thrown", "if", "the", "stream", "was", "already", "closed", "before", "and", "we", "ask", "for", "a", "result", "later"], "project": "flink"}
{"id": 1068, "code": "public void enableForceAvro() {\n    forceAvro = true;\n}", "summary_tokens": ["forces", "flink", "to", "use", "the", "apache", "avro", "serializer", "for", "pojos"], "project": "flink"}
{"id": 1407, "code": "static <T> TypeSerializerSnapshot<T> readVersionedSnapshot(DataInputView in, ClassLoader cl)\n        throws IOException {\n    final TypeSerializerSnapshot<T> snapshot =\n            TypeSerializerSnapshotSerializationUtil.readAndInstantiateSnapshotClass(in, cl);\n\n    int version = in.readInt();\n\n    if (version == ADAPTER_VERSION && !(snapshot instanceof TypeSerializerConfigSnapshot)) {\n            \n            \n            \n            \n            \n        TypeSerializerSerializationUtil.tryReadSerializer(in, cl, true);\n        version = in.readInt();\n    }\n    snapshot.readSnapshot(version, in, cl);\n\n    return snapshot;\n}", "summary_tokens": ["reads", "a", "snapshot", "from", "the", "stream", "performing", "resolving"], "project": "flink"}
{"id": 9094, "code": "public static BinaryStringData concatWs(\n        BinaryStringData separator, BinaryStringData... inputs) {\n    return concatWs(separator, Arrays.asList(inputs));\n}", "summary_tokens": ["concatenates", "input", "strings", "together", "into", "a", "single", "string", "using", "the", "separator"], "project": "flink"}
{"id": 8585, "code": "public static String generateSignature(\n        TypeInference typeInference, String name, FunctionDefinition definition) {\n    if (typeInference.getTypedArguments().isPresent()) {\n        return formatNamedOrTypedArguments(name, typeInference);\n    }\n    return typeInference.getInputTypeStrategy().getExpectedSignatures(definition).stream()\n            .map(s -> formatSignature(name, s))\n            .collect(Collectors.joining(\"\\n\"));\n}", "summary_tokens": ["generates", "a", "signature", "of", "the", "given", "function", "definition"], "project": "flink"}
{"id": 9167, "code": "public void close() {\n        \n    if (!this.closed.compareAndSet(false, true)) {\n        return;\n    }\n\n        \n    if (this.currentSpilledProbeSide != null) {\n        try {\n            this.currentSpilledProbeSide.getChannel().closeAndDelete();\n        } catch (Throwable t) {\n            LOG.warn(\n                    \"Could not close and delete the temp file for the current spilled partition probe side.\",\n                    t);\n        }\n    }\n\n        \n    clearPartitions();\n\n        \n    for (int i = 0; i < this.buildSpillRetBufferNumbers; i++) {\n        try {\n            returnPage(this.buildSpillReturnBuffers.take());\n        } catch (InterruptedException iex) {\n            throw new RuntimeException(\"Hashtable closing was interrupted\");\n        }\n    }\n    this.buildSpillRetBufferNumbers = 0;\n}", "summary_tokens": ["closes", "the", "hash", "table"], "project": "flink"}
{"id": 4487, "code": "public void close() throws Exception {\n        \n    if (!isShutdown.compareAndSet(false, true)) {\n        return;\n    }\n\n    IOUtils.closeAll(\n            Arrays.stream(paths)\n                    .filter(File::exists)\n                    .map(FileChannelManagerImpl::getFileCloser)\n                    .collect(Collectors.toList()));\n\n    ShutdownHookUtil.removeShutdownHook(\n            shutdownHook, String.format(\"%s-%s\", getClass().getSimpleName(), prefix), LOG);\n}", "summary_tokens": ["remove", "all", "the", "temp", "directories"], "project": "flink"}
{"id": 948, "code": "default void open(DeserializationSchema.InitializationContext context) throws Exception {}", "summary_tokens": ["initialization", "method", "for", "the", "schema"], "project": "flink"}
{"id": 1519, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f5)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f6)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f7)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f8)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f9)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f10)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f11)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f12)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f13)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f14)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f15)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f16)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f17)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f18)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f19)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f20)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f21)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f22)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 4672, "code": "protected AbstractEvent parseEvent(Buffer buffer) throws IOException {\n    if (buffer.isBuffer()) {\n        return null;\n    } else {\n        AbstractEvent event = EventSerializer.fromBuffer(buffer, getClass().getClassLoader());\n            \n            \n            \n        buffer.setReaderIndex(0);\n        return event;\n    }\n}", "summary_tokens": ["parses", "the", "buffer", "as", "an", "event", "and", "returns", "the", "checkpoint", "barrier", "if", "the", "event", "is", "indeed", "a", "barrier", "or", "returns", "null", "in", "all", "other", "cases"], "project": "flink"}
{"id": 4865, "code": "public T getResourceHandle() {\n    return resourceHandle;\n}", "summary_tokens": ["gets", "the", "handle", "to", "the", "resource"], "project": "flink"}
{"id": 5816, "code": "private static byte[] createTestBuffer() {\n    final byte[] buf = new byte[TEST_BUFFER_SIZE];\n    for (int i = 0; i < buf.length; ++i) {\n        buf[i] = (byte) (i % 128);\n    }\n    return buf;\n}", "summary_tokens": ["creates", "a", "test", "buffer", "and", "fills", "it", "with", "a", "specific", "byte", "pattern"], "project": "flink"}
{"id": 7578, "code": "private void disableInterruptOnCancel() {\n    synchronized (shouldInterruptOnCancelLock) {\n        shouldInterruptOnCancel = false;\n    }\n}", "summary_tokens": ["while", "we", "are", "outside", "the", "user", "code", "we", "do", "not", "want", "to", "be", "interrupted", "further", "upon", "cancellation"], "project": "flink"}
{"id": 5900, "code": "public void testNonRestoredStateWhenAllowed() throws Exception {\n    final OperatorID operatorId = new OperatorID();\n    final int parallelism = 9;\n\n    final CompletedCheckpointStorageLocation testSavepoint =\n            createSavepointWithOperatorSubtaskState(242L, operatorId, parallelism);\n    final Map<JobVertexID, ExecutionJobVertex> tasks = Collections.emptyMap();\n\n    final CompletedCheckpoint loaded =\n            Checkpoints.loadAndValidateCheckpoint(\n                    new JobID(),\n                    tasks,\n                    testSavepoint,\n                    cl,\n                    true,\n                    CheckpointProperties.forSavepoint(false));\n\n    assertTrue(loaded.getOperatorStates().isEmpty());\n}", "summary_tokens": ["tests", "that", "savepoint", "loading", "succeeds", "when", "there", "is", "non", "restored", "state", "and", "it", "is", "not", "allowed"], "project": "flink"}
{"id": 6190, "code": "public void testClientMessageDecodeWithReleasedInputChannel() throws Exception {\n    testNettyMessageClientDecoding(false, true, false);\n}", "summary_tokens": ["verifies", "that", "the", "client", "side", "decoder", "works", "well", "with", "buffers", "sent", "to", "a", "released", "input", "channel"], "project": "flink"}
{"id": 4173, "code": "public CheckpointStorageLocationReference getTargetLocation() {\n    return targetLocation;\n}", "summary_tokens": ["returns", "the", "target", "location", "for", "the", "checkpoint"], "project": "flink"}
{"id": 1097, "code": "public JobExecutionResult getJobExecutionResult() {\n    throw new ClassCastException(\"This JobSubmissionResult is not a JobExecutionResult.\");\n}", "summary_tokens": ["returns", "the", "job", "execution", "result", "if", "available"], "project": "flink"}
{"id": 2169, "code": "public void checkAppendedField() throws Exception {\n    Assert.assertTrue(\n            checkCompatibility(ENUM_A, ENUM_B).isCompatibleWithReconfiguredSerializer());\n}", "summary_tokens": ["check", "that", "appending", "fields", "to", "the", "enum", "does", "not", "require", "migration"], "project": "flink"}
{"id": 7457, "code": "private long getMaxTimestamp(Iterable<TimestampedValue<Object>> elements) {\n    long currentTime = Long.MIN_VALUE;\n    for (Iterator<TimestampedValue<Object>> iterator = elements.iterator();\n            iterator.hasNext(); ) {\n        TimestampedValue<Object> record = iterator.next();\n        currentTime = Math.max(currentTime, record.getTimestamp());\n    }\n    return currentTime;\n}", "summary_tokens": ["elements", "the", "elements", "currently", "in", "the", "pane"], "project": "flink"}
{"id": 8468, "code": "public static void validateClassForRuntime(\n        Class<? extends UserDefinedFunction> functionClass,\n        String methodName,\n        Class<?>[] argumentClasses,\n        Class<?> outputClass,\n        String functionName) {\n    final List<Method> methods = ExtractionUtils.collectMethods(functionClass, methodName);\n        \n    final boolean isMatching =\n            methods.stream()\n                    .anyMatch(\n                            method ->\n                                    ExtractionUtils.isInvokable(method, argumentClasses)\n                                            && ExtractionUtils.isAssignable(\n                                                    outputClass, method.getReturnType(), true));\n    if (!isMatching) {\n        throw new ValidationException(\n                String.format(\n                        \"Could not find an implementation method '%s' in class '%s' for function '%s' that \"\n                                + \"matches the following signature:\\n%s\",\n                        methodName,\n                        functionClass.getName(),\n                        functionName,\n                        ExtractionUtils.createMethodSignatureString(\n                                methodName, argumentClasses, outputClass)));\n    }\n}", "summary_tokens": ["validates", "a", "user", "defined", "function", "class", "for", "usage", "in", "the", "runtime"], "project": "flink"}
{"id": 8055, "code": "public Optional<TableLookupResult> getTable(ObjectIdentifier objectIdentifier) {\n    CatalogBaseTable temporaryTable = temporaryTables.get(objectIdentifier);\n    if (temporaryTable != null) {\n        final ResolvedCatalogBaseTable<?> resolvedTable =\n                resolveCatalogBaseTable(temporaryTable);\n        return Optional.of(TableLookupResult.temporary(resolvedTable));\n    } else {\n        return getPermanentTable(objectIdentifier);\n    }\n}", "summary_tokens": ["retrieves", "a", "fully", "qualified", "table"], "project": "flink"}
{"id": 5301, "code": "public Throwable getRootCause() {\n    return rootCause;\n}", "summary_tokens": ["the", "actual", "failure", "that", "is", "handled"], "project": "flink"}
{"id": 5309, "code": "public CompletableFuture<String> stopWithSavepoint(\n        CompletableFuture<CompletedCheckpoint> completedSavepointFuture,\n        CompletableFuture<Collection<ExecutionState>> terminatedExecutionStatesFuture,\n        ComponentMainThreadExecutor mainThreadExecutor) {\n    FutureUtils.assertNoException(\n            completedSavepointFuture\n                        \n                        \n                    .handleAsync(\n                            (completedSavepoint, throwable) -> {\n                                stopWithSavepointTerminationHandler.handleSavepointCreation(\n                                        completedSavepoint, throwable);\n                                return null;\n                            },\n                            mainThreadExecutor)\n                    .thenRun(\n                            () ->\n                                    FutureUtils.assertNoException(\n                                                \n                                                \n                                                \n                                            terminatedExecutionStatesFuture.thenAcceptAsync(\n                                                    stopWithSavepointTerminationHandler\n                                                            ::handleExecutionsTermination,\n                                                    mainThreadExecutor))));\n\n    return stopWithSavepointTerminationHandler.getSavepointPath();\n}", "summary_tokens": ["enforces", "the", "correct", "completion", "order", "of", "the", "passed", "completable", "future", "instances", "in", "accordance", "to", "the", "contract", "of", "stop", "with", "savepoint", "termination", "handler"], "project": "flink"}
{"id": 4650, "code": "public boolean isEmpty() {\n    return deque.isEmpty();\n}", "summary_tokens": ["returns", "true", "if", "there", "are", "no", "elements"], "project": "flink"}
{"id": 6938, "code": "public void enableIsWriteStopped() {\n    this.properties.add(RocksDBProperty.IsWriteStopped.getRocksDBProperty());\n}", "summary_tokens": ["returns", "0", "if", "write", "has", "been", "stopped"], "project": "flink"}
{"id": 7529, "code": "public static <T> TimestampedValue<T> from(StreamRecord<T> streamRecord) {\n    if (streamRecord.hasTimestamp()) {\n        return new TimestampedValue<>(streamRecord.getValue(), streamRecord.getTimestamp());\n    } else {\n        return new TimestampedValue<>(streamRecord.getValue());\n    }\n}", "summary_tokens": ["creates", "a", "timestamped", "value", "from", "given", "stream", "record"], "project": "flink"}
{"id": 5025, "code": "public void reopenProbe(MutableObjectIterator<V1> probeInput) throws IOException {\n    reopenHashTable.reopenProbe(probeInput);\n}", "summary_tokens": ["set", "new", "input", "for", "probe", "side"], "project": "flink"}
{"id": 4663, "code": "protected void onConsumedSubpartition() {\n    parent.onConsumedSubpartition(getSubPartitionIndex());\n}", "summary_tokens": ["notifies", "the", "parent", "partition", "about", "a", "consumed", "result", "subpartition", "view"], "project": "flink"}
{"id": 5943, "code": "public void testReportCompletedCheckpoint() throws Exception {\n    TaskStateStats task1 = new TaskStateStats(new JobVertexID(), 3);\n    TaskStateStats task2 = new TaskStateStats(new JobVertexID(), 4);\n\n    HashMap<JobVertexID, TaskStateStats> taskStats = new HashMap<>();\n    taskStats.put(task1.getJobVertexId(), task1);\n    taskStats.put(task2.getJobVertexId(), task2);\n\n    CheckpointStatsTracker.PendingCheckpointStatsCallback callback =\n            mock(CheckpointStatsTracker.PendingCheckpointStatsCallback.class);\n\n    PendingCheckpointStats pending =\n            new PendingCheckpointStats(\n                    0,\n                    1,\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    task1.getNumberOfSubtasks() + task2.getNumberOfSubtasks(),\n                    taskStats,\n                    callback);\n\n        \n    for (int i = 0; i < task1.getNumberOfSubtasks(); i++) {\n        pending.reportSubtaskStats(task1.getJobVertexId(), createSubtaskStats(i));\n    }\n\n    for (int i = 0; i < task2.getNumberOfSubtasks(); i++) {\n        pending.reportSubtaskStats(task2.getJobVertexId(), createSubtaskStats(i));\n    }\n\n        \n    String externalPath = \"asdjkasdjkasd\";\n\n    CompletedCheckpointStats.DiscardCallback discardCallback =\n            pending.reportCompletedCheckpoint(externalPath);\n\n    ArgumentCaptor<CompletedCheckpointStats> args =\n            ArgumentCaptor.forClass(CompletedCheckpointStats.class);\n    verify(callback).reportCompletedCheckpoint(args.capture());\n\n    CompletedCheckpointStats completed = args.getValue();\n\n    assertNotNull(completed);\n    assertEquals(CheckpointStatsStatus.COMPLETED, completed.getStatus());\n    assertFalse(completed.isDiscarded());\n    discardCallback.notifyDiscardedCheckpoint();\n    assertTrue(completed.isDiscarded());\n    assertEquals(externalPath, completed.getExternalPath());\n\n    assertEquals(pending.getCheckpointId(), completed.getCheckpointId());\n    assertEquals(\n            pending.getNumberOfAcknowledgedSubtasks(),\n            completed.getNumberOfAcknowledgedSubtasks());\n    assertEquals(\n            pending.getLatestAcknowledgedSubtaskStats(),\n            completed.getLatestAcknowledgedSubtaskStats());\n    assertEquals(pending.getLatestAckTimestamp(), completed.getLatestAckTimestamp());\n    assertEquals(pending.getEndToEndDuration(), completed.getEndToEndDuration());\n    assertEquals(pending.getStateSize(), completed.getStateSize());\n    assertEquals(task1, completed.getTaskStateStats(task1.getJobVertexId()));\n    assertEquals(task2, completed.getTaskStateStats(task2.getJobVertexId()));\n}", "summary_tokens": ["test", "reporting", "of", "a", "completed", "checkpoint"], "project": "flink"}
{"id": 8455, "code": "public TypeInformation<T> getResultType() {\n    return null;\n}", "summary_tokens": ["returns", "the", "result", "type", "of", "the", "evaluation", "method"], "project": "flink"}
{"id": 9189, "code": "protected int spillPartition() throws IOException {\n        \n    int largestNumBlocks = 0;\n    int largestPartNum = -1;\n\n    for (int i = 0; i < partitionsBeingBuilt.size(); i++) {\n        BinaryHashPartition p = partitionsBeingBuilt.get(i);\n        if (p.isInMemory() && p.getNumOccupiedMemorySegments() > largestNumBlocks) {\n            largestNumBlocks = p.getNumOccupiedMemorySegments();\n            largestPartNum = i;\n        }\n    }\n    final BinaryHashPartition p = partitionsBeingBuilt.get(largestPartNum);\n\n        \n    int numBuffersFreed =\n            p.spillPartition(\n                    this.ioManager,\n                    this.currentEnumerator.next(),\n                    this.buildSpillReturnBuffers);\n    this.buildSpillRetBufferNumbers += numBuffersFreed;\n\n    LOG.info(\n            String.format(\n                    \"Grace hash join: Ran out memory, choosing partition \"\n                            + \"[%d] to spill, %d memory segments being freed\",\n                    largestPartNum, numBuffersFreed));\n\n        \n    MemorySegment currBuff;\n    while (this.buildSpillRetBufferNumbers > 0\n            && (currBuff = this.buildSpillReturnBuffers.poll()) != null) {\n        returnPage(currBuff);\n        this.buildSpillRetBufferNumbers--;\n    }\n    numSpillFiles++;\n    spillInBytes += numBuffersFreed * segmentSize;\n        \n    p.buildBloomFilterAndFreeBucket();\n    return largestPartNum;\n}", "summary_tokens": ["selects", "a", "partition", "and", "spills", "it"], "project": "flink"}
{"id": 5480, "code": "private static int compositeHash(Object key, Object namespace) {\n        \n        \n    return MathUtils.bitMix(key.hashCode() ^ namespace.hashCode());\n}", "summary_tokens": ["helper", "function", "that", "creates", "and", "scrambles", "a", "composite", "hash", "for", "key", "and", "namespace"], "project": "flink"}
{"id": 7824, "code": "public void testSourceCheckpointFirstUnaligned() throws Exception {\n    try (StreamTaskMailboxTestHarness<String> testHarness =\n            buildTestHarness(true, objectReuse)) {\n        testHarness.setAutoProcess(false);\n        ArrayDeque<Object> expectedOutput = new ArrayDeque<>();\n        addRecords(testHarness);\n\n        CheckpointBarrier barrier = createBarrier(testHarness);\n        Future<Boolean> checkpointFuture =\n                testHarness\n                        .getStreamTask()\n                        .triggerCheckpointAsync(metaData, barrier.getCheckpointOptions());\n        processSingleStepUntil(testHarness, checkpointFuture::isDone);\n\n        assertThat(testHarness.getOutput(), contains(barrier));\n\n        testHarness.processAll();\n\n        expectedOutput.add(new StreamRecord<>(\"44\", TimestampAssigner.NO_TIMESTAMP));\n        expectedOutput.add(new StreamRecord<>(\"44\", TimestampAssigner.NO_TIMESTAMP));\n        expectedOutput.add(new StreamRecord<>(\"47.0\", TimestampAssigner.NO_TIMESTAMP));\n        expectedOutput.add(new StreamRecord<>(\"47.0\", TimestampAssigner.NO_TIMESTAMP));\n\n        ArrayList<Object> actualOutput = new ArrayList<>(testHarness.getOutput());\n        assertThat(\n                actualOutput.subList(1, expectedOutput.size() + 1),\n                containsInAnyOrder(expectedOutput.toArray()));\n    }\n}", "summary_tokens": ["in", "this", "scenario", "0"], "project": "flink"}
{"id": 1006, "code": "public HCatInputFormatBase<T> withFilter(String filter) throws IOException {\n\n        \n    this.hCatInputFormat.setFilter(filter);\n\n    return this;\n}", "summary_tokens": ["specifies", "a", "sql", "like", "filter", "condition", "on", "the", "table", "s", "partition", "columns"], "project": "flink"}
{"id": 8852, "code": "public static @Nullable CastRule<?, ?> resolve(LogicalType inputType, LogicalType targetType) {\n    return INSTANCE.internalResolve(inputType, targetType);\n}", "summary_tokens": ["resolve", "a", "cast", "rule", "for", "the", "provided", "input", "type", "and", "target", "type"], "project": "flink"}
{"id": 167, "code": "protected void onWriteSuccess() {}", "summary_tokens": ["callback", "that", "is", "invoked", "after", "a", "record", "is", "written", "to", "cassandra", "successfully"], "project": "flink"}
{"id": 6166, "code": "public void testExceptionOnWrite() throws Exception {\n\n    NettyProtocol protocol =\n            new NettyProtocol(\n                    mock(ResultPartitionProvider.class), mock(TaskEventDispatcher.class)) {\n\n                @Override\n                public ChannelHandler[] getServerChannelHandlers() {\n                    return new ChannelHandler[0];\n                }\n            };\n\n        \n        \n    NettyServerAndClient serverAndClient = initServerAndClient(protocol, createConfig());\n\n    Channel ch = connect(serverAndClient);\n\n    NetworkClientHandler handler = getClientHandler(ch);\n\n        \n    ch.pipeline()\n            .addFirst(\n                    new ChannelOutboundHandlerAdapter() {\n                        int writeNum = 0;\n\n                        @Override\n                        public void write(\n                                ChannelHandlerContext ctx, Object msg, ChannelPromise promise)\n                                throws Exception {\n\n                            if (writeNum >= 1) {\n                                throw new RuntimeException(\"Expected test exception.\");\n                            }\n\n                            writeNum++;\n                            ctx.write(msg, promise);\n                        }\n                    });\n\n    PartitionRequestClient requestClient =\n            new NettyPartitionRequestClient(\n                    ch,\n                    handler,\n                    mock(ConnectionID.class),\n                    mock(PartitionRequestClientFactory.class));\n\n        \n    RemoteInputChannel[] rich =\n            new RemoteInputChannel[] {createRemoteInputChannel(), createRemoteInputChannel()};\n\n    final CountDownLatch sync = new CountDownLatch(1);\n\n        \n        \n        \n    doAnswer(\n                    new Answer<Void>() {\n                        @Override\n                        public Void answer(InvocationOnMock invocation) throws Throwable {\n                            sync.countDown();\n                            return null;\n                        }\n                    })\n            .when(rich[1])\n            .onError(isA(LocalTransportException.class));\n\n        \n    requestClient.requestSubpartition(new ResultPartitionID(), 0, rich[0], 0);\n\n        \n    requestClient.requestSubpartition(new ResultPartitionID(), 0, rich[1], 0);\n\n        \n    if (!sync.await(TestingUtils.TESTING_DURATION.toMillis(), TimeUnit.MILLISECONDS)) {\n        fail(\n                \"Timed out after waiting for \"\n                        + TestingUtils.TESTING_DURATION.toMillis()\n                        + \" ms to be notified about the channel error.\");\n    }\n\n        \n    verify(rich[0], times(0)).onError(any(LocalTransportException.class));\n\n    shutdown(serverAndClient);\n}", "summary_tokens": ["verifies", "that", "failed", "client", "requests", "via", "partition", "request", "client", "are", "correctly", "attributed", "to", "the", "respective", "remote", "input", "channel"], "project": "flink"}
{"id": 9168, "code": "public void freeCurrent() {\n    internalPool.cleanCache();\n}", "summary_tokens": ["free", "the", "memory", "not", "used"], "project": "flink"}
{"id": 8722, "code": "RexNode simplify(RexNode e, RexUnknownAs unknownAs) {\n    if (strong.isNull(e)) {\n            \n            \n        if (e.getType().getSqlTypeName() == SqlTypeName.BOOLEAN) {\n            switch (unknownAs) {\n                case FALSE:\n                case TRUE:\n                    return rexBuilder.makeLiteral(unknownAs.toBoolean());\n            }\n        }\n        return rexBuilder.makeNullLiteral(e.getType());\n    }\n    switch (e.getKind()) {\n        case AND:\n            return simplifyAnd((RexCall) e, unknownAs);\n        case OR:\n            return simplifyOr((RexCall) e, unknownAs);\n        case NOT:\n            return simplifyNot((RexCall) e, unknownAs);\n        case CASE:\n            return simplifyCase((RexCall) e, unknownAs);\n        case COALESCE:\n            return simplifyCoalesce((RexCall) e);\n        case CAST:\n            return simplifyCast((RexCall) e);\n        case CEIL:\n        case FLOOR:\n            return simplifyCeilFloor((RexCall) e);\n        case IS_NULL:\n        case IS_NOT_NULL:\n        case IS_TRUE:\n        case IS_NOT_TRUE:\n        case IS_FALSE:\n        case IS_NOT_FALSE:\n            assert e instanceof RexCall;\n            return simplifyIs((RexCall) e, unknownAs);\n        case EQUALS:\n        case GREATER_THAN:\n        case GREATER_THAN_OR_EQUAL:\n        case LESS_THAN:\n        case LESS_THAN_OR_EQUAL:\n        case NOT_EQUALS:\n            return simplifyComparison((RexCall) e, unknownAs);\n        case SEARCH:\n            return simplifySearch((RexCall) e, unknownAs);\n        case LIKE:\n            return simplifyLike((RexCall) e);\n        case MINUS_PREFIX:\n            return simplifyUnaryMinus((RexCall) e, unknownAs);\n        case PLUS_PREFIX:\n            return simplifyUnaryPlus((RexCall) e, unknownAs);\n        default:\n            if (e.getClass() == RexCall.class) {\n                return simplifyGenericNode((RexCall) e);\n            } else {\n                return e;\n            }\n    }\n}", "summary_tokens": ["internal", "method", "to", "simplify", "an", "expression"], "project": "flink"}
{"id": 4133, "code": "private void put(InputStream inputStream, OutputStream outputStream, byte[] buf)\n        throws IOException {\n    File incomingFile = null;\n\n    try {\n            \n        final int mode = inputStream.read();\n        if (mode < 0) {\n            throw new EOFException(\"Premature end of PUT request\");\n        }\n\n        final JobID jobId;\n        if (mode == JOB_UNRELATED_CONTENT) {\n            jobId = null;\n        } else if (mode == JOB_RELATED_CONTENT) {\n            byte[] jidBytes = new byte[JobID.SIZE];\n            readFully(inputStream, jidBytes, 0, JobID.SIZE, \"JobID\");\n            jobId = JobID.fromByteArray(jidBytes);\n        } else {\n            throw new IOException(\"Unknown type of BLOB addressing.\");\n        }\n\n        final BlobKey.BlobType blobType;\n        {\n            final int read = inputStream.read();\n            if (read < 0) {\n                throw new EOFException(\"Read an incomplete BLOB type\");\n            } else if (read == TRANSIENT_BLOB.ordinal()) {\n                blobType = TRANSIENT_BLOB;\n            } else if (read == PERMANENT_BLOB.ordinal()) {\n                blobType = PERMANENT_BLOB;\n                checkArgument(jobId != null, \"Invalid BLOB addressing for permanent BLOBs\");\n            } else {\n                throw new IOException(\"Invalid data received for the BLOB type: \" + read);\n            }\n        }\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\n                    \"Received PUT request for BLOB of job {} with from {}.\",\n                    jobId,\n                    clientSocket.getInetAddress());\n        }\n\n        incomingFile = blobServer.createTemporaryFilename();\n        byte[] digest = readFileFully(inputStream, incomingFile, buf);\n\n        BlobKey blobKey = blobServer.moveTempFileToStore(incomingFile, jobId, digest, blobType);\n\n            \n        outputStream.write(RETURN_OKAY);\n        blobKey.writeToOutputStream(outputStream);\n    } catch (SocketException e) {\n            \n        LOG.debug(\"Socket connection closed\", e);\n    } catch (Throwable t) {\n        LOG.error(\"PUT operation failed\", t);\n        try {\n            writeErrorToStream(outputStream, t);\n        } catch (IOException e) {\n                \n                \n                \n        }\n        clientSocket.close();\n    } finally {\n        if (incomingFile != null) {\n            if (!incomingFile.delete() && incomingFile.exists()) {\n                LOG.warn(\n                        \"Cannot delete BLOB server staging file \"\n                                + incomingFile.getAbsolutePath());\n            }\n        }\n    }\n}", "summary_tokens": ["handles", "an", "incoming", "put", "request", "from", "a", "blob", "client"], "project": "flink"}
{"id": 1553, "code": "public static <T0, T1, T2, T3, T4, T5, T6, T7> Tuple8<T0, T1, T2, T3, T4, T5, T6, T7> of(\n        T0 f0, T1 f1, T2 f2, T3 f3, T4 f4, T5 f5, T6 f6, T7 f7) {\n    return new Tuple8<>(f0, f1, f2, f3, f4, f5, f6, f7);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 3039, "code": "public static AfterMatchSkipStrategy skipToNext() {\n    return SkipToNextStrategy.INSTANCE;\n}", "summary_tokens": ["discards", "every", "partial", "match", "that", "started", "with", "the", "same", "event", "emitted", "match", "was", "started"], "project": "flink"}
{"id": 6849, "code": "public void testPhysicallyRemoveWithRemoveAndGetOld() throws IOException {\n    testPhysicallyRemoveWithFunction(\n            (map, reference, i) -> {\n                assertNull(map.removeAndGetOld(i, (long) i));\n                return 0;\n            });\n}", "summary_tokens": ["tests", "that", "remove", "states", "physically", "when", "remove", "and", "get", "old", "is", "invoked"], "project": "flink"}
{"id": 8441, "code": "public MetricGroup getMetricGroup() {\n    return context.getMetricGroup();\n}", "summary_tokens": ["returns", "the", "metric", "group", "for", "this", "parallel", "subtask"], "project": "flink"}
{"id": 7224, "code": "public int getParallelism() {\n    return config.getParallelism();\n}", "summary_tokens": ["gets", "the", "parallelism", "with", "which", "operation", "are", "executed", "by", "default"], "project": "flink"}
{"id": 8663, "code": "public static String convertTz(String dateStr, String tzFrom, String tzTo) {\n    try {\n        return formatTimestampTz(parseTimestampTz(dateStr, tzFrom), tzTo);\n    } catch (ParseException e) {\n        return null;\n    }\n}", "summary_tokens": ["convert", "datetime", "string", "from", "a", "time", "zone", "to", "another", "time", "zone"], "project": "flink"}
{"id": 1018, "code": "public String getUser() throws IOException {\n  try {\n    UserGroupInformation ugi = Utils.getUGI();\n    return ugi.getUserName();\n  } catch (LoginException le) {\n    throw new IOException(le);\n  }\n}", "summary_tokens": ["the", "user", "name", "set", "in", "hadoop"], "project": "flink"}
{"id": 9609, "code": "public void testJobExecutionOnClusterWithLeaderChange() throws Exception {\n    final int numDispatchers = 3;\n    final int numTMs = 2;\n    final int numSlotsPerTM = 2;\n\n    final Configuration configuration =\n            ZooKeeperTestUtils.createZooKeeperHAConfig(\n                    zkServer.getConnectString(), tempFolder.newFolder().getAbsolutePath());\n\n        \n    configuration.setLong(ClusterOptions.REFUSED_REGISTRATION_DELAY, 50L);\n\n    final TestingMiniClusterConfiguration miniClusterConfiguration =\n            TestingMiniClusterConfiguration.newBuilder()\n                    .setConfiguration(configuration)\n                    .setNumberDispatcherResourceManagerComponents(numDispatchers)\n                    .setNumTaskManagers(numTMs)\n                    .setNumSlotsPerTaskManager(numSlotsPerTM)\n                    .build();\n\n    Deadline timeout = Deadline.fromNow(TEST_TIMEOUT);\n\n    try (TestingMiniCluster miniCluster = new TestingMiniCluster(miniClusterConfiguration)) {\n        miniCluster.start();\n\n        final int parallelism = numTMs * numSlotsPerTM;\n        JobGraph jobGraph = createJobGraph(parallelism);\n\n        miniCluster.submitJob(jobGraph).get();\n\n        String previousLeaderAddress = null;\n\n        for (int i = 0; i < numDispatchers - 1; i++) {\n            final DispatcherGateway leaderDispatcherGateway =\n                    getNextLeadingDispatcherGateway(\n                            miniCluster, previousLeaderAddress, timeout);\n            previousLeaderAddress = leaderDispatcherGateway.getAddress();\n\n            CommonTestUtils.waitUntilCondition(\n                    () ->\n                            leaderDispatcherGateway\n                                            .requestJobStatus(jobGraph.getJobID(), RPC_TIMEOUT)\n                                            .get()\n                                    == JobStatus.RUNNING,\n                    timeout,\n                    50L);\n\n            leaderDispatcherGateway.shutDownCluster();\n        }\n\n        final DispatcherGateway leaderDispatcherGateway =\n                getNextLeadingDispatcherGateway(miniCluster, previousLeaderAddress, timeout);\n        CommonTestUtils.waitUntilCondition(\n                () ->\n                        leaderDispatcherGateway\n                                        .requestJobStatus(jobGraph.getJobID(), RPC_TIMEOUT)\n                                        .get()\n                                == JobStatus.RUNNING,\n                timeout,\n                50L);\n        CompletableFuture<JobResult> jobResultFuture =\n                leaderDispatcherGateway.requestJobResult(jobGraph.getJobID(), RPC_TIMEOUT);\n        BlockingOperator.unblock();\n\n        assertThat(jobResultFuture.get().isSuccess(), is(true));\n    }\n}", "summary_tokens": ["tests", "that", "a", "job", "can", "be", "executed", "after", "a", "new", "leader", "has", "been", "elected"], "project": "flink"}
{"id": 4181, "code": "public CheckpointType getCheckpointType() {\n    return checkpointType;\n}", "summary_tokens": ["gets", "the", "type", "of", "the", "checkpoint", "checkpoint", "savepoint"], "project": "flink"}
{"id": 5646, "code": "public static String getJvmStartupOptions() {\n    try {\n        final RuntimeMXBean bean = ManagementFactory.getRuntimeMXBean();\n        final StringBuilder bld = new StringBuilder();\n\n        for (String s : bean.getInputArguments()) {\n            bld.append(s).append(' ');\n        }\n\n        return bld.toString();\n    } catch (Throwable t) {\n        return UNKNOWN;\n    }\n}", "summary_tokens": ["gets", "the", "system", "parameters", "and", "environment", "parameters", "that", "were", "passed", "to", "the", "jvm", "on", "startup"], "project": "flink"}
{"id": 1944, "code": "public static void tryEnrichOutOfMemoryError(\n        @Nullable Throwable root,\n        @Nullable String jvmMetaspaceOomNewErrorMessage,\n        @Nullable String jvmDirectOomNewErrorMessage,\n        @Nullable String jvmHeapSpaceOomNewErrorMessage) {\n    updateDetailMessage(\n            root,\n            t -> {\n                if (isMetaspaceOutOfMemoryError(t)) {\n                    return jvmMetaspaceOomNewErrorMessage;\n                } else if (isDirectOutOfMemoryError(t)) {\n                    return jvmDirectOomNewErrorMessage;\n                } else if (isHeapSpaceOutOfMemoryError(t)) {\n                    return jvmHeapSpaceOomNewErrorMessage;\n                }\n\n                return null;\n            });\n}", "summary_tokens": ["tries", "to", "enrich", "out", "of", "memory", "errors", "being", "part", "of", "the", "passed", "root", "throwable", "s", "cause", "tree"], "project": "flink"}
{"id": 3520, "code": "public OperatorState getOperatorState(String uid) throws IOException {\n    OperatorID operatorID = OperatorIDGenerator.fromUid(uid);\n\n    OperatorStateSpec operatorState = operatorStateIndex.get(operatorID);\n    if (operatorState == null || operatorState.isNewStateTransformation()) {\n        throw new IOException(\"Savepoint does not contain state with operator uid \" + uid);\n    }\n\n    return operatorState.asExistingState();\n}", "summary_tokens": ["operator", "state", "for", "the", "given", "uid"], "project": "flink"}
{"id": 6648, "code": "public void testNetworkRequestBackoffAndBuffers() {\n\n        \n    final Configuration config = new Configuration();\n    config.setInteger(NettyShuffleEnvironmentOptions.NETWORK_REQUEST_BACKOFF_INITIAL, 100);\n    config.setInteger(NettyShuffleEnvironmentOptions.NETWORK_REQUEST_BACKOFF_MAX, 200);\n    config.setInteger(NettyShuffleEnvironmentOptions.NETWORK_BUFFERS_PER_CHANNEL, 10);\n    config.setInteger(NettyShuffleEnvironmentOptions.NETWORK_EXTRA_BUFFERS_PER_GATE, 100);\n\n    final NettyShuffleEnvironmentConfiguration networkConfig =\n            NettyShuffleEnvironmentConfiguration.fromConfiguration(\n                    config, MEM_SIZE_PARAM, true, InetAddress.getLoopbackAddress());\n\n    assertEquals(networkConfig.partitionRequestInitialBackoff(), 100);\n    assertEquals(networkConfig.partitionRequestMaxBackoff(), 200);\n    assertEquals(networkConfig.networkBuffersPerChannel(), 10);\n    assertEquals(networkConfig.floatingNetworkBuffersPerGate(), 100);\n}", "summary_tokens": ["verifies", "that", "netty", "shuffle", "environment", "configuration", "from", "configuration", "configuration", "memory", "size", "boolean", "inet", "address", "returns", "the", "correct", "result", "for", "new", "configurations", "via", "netty", "shuffle", "environment", "options", "network", "request", "backoff", "initial", "netty", "shuffle", "environment", "options", "network", "request", "backoff", "max", "netty", "shuffle", "environment", "options", "network", "buffers", "per", "channel", "and", "netty", "shuffle", "environment", "options", "network", "extra", "buffers", "per", "gate"], "project": "flink"}
{"id": 20, "code": "protected void stop(String[] args) throws Exception {\n    LOG.info(\"Running 'stop-with-savepoint' command.\");\n\n    final Options commandOptions = CliFrontendParser.getStopCommandOptions();\n    final CommandLine commandLine = getCommandLine(commandOptions, args, false);\n\n    final StopOptions stopOptions = new StopOptions(commandLine);\n    if (stopOptions.isPrintHelp()) {\n        CliFrontendParser.printHelpForStop(customCommandLines);\n        return;\n    }\n\n    final String[] cleanedArgs = stopOptions.getArgs();\n\n    final String targetDirectory =\n            stopOptions.hasSavepointFlag() && cleanedArgs.length > 0\n                    ? stopOptions.getTargetDirectory()\n                    : null; \n\n    final JobID jobId =\n            cleanedArgs.length != 0\n                    ? parseJobId(cleanedArgs[0])\n                    : parseJobId(stopOptions.getTargetDirectory());\n\n    final boolean advanceToEndOfEventTime = stopOptions.shouldAdvanceToEndOfEventTime();\n\n    logAndSysout(\n            (advanceToEndOfEventTime ? \"Draining job \" : \"Suspending job \")\n                    + \"\\\"\"\n                    + jobId\n                    + \"\\\" with a savepoint.\");\n\n    final CustomCommandLine activeCommandLine = validateAndGetActiveCommandLine(commandLine);\n    runClusterAction(\n            activeCommandLine,\n            commandLine,\n            clusterClient -> {\n                final String savepointPath;\n                try {\n                    savepointPath =\n                            clusterClient\n                                    .stopWithSavepoint(\n                                            jobId, advanceToEndOfEventTime, targetDirectory)\n                                    .get(clientTimeout.toMillis(), TimeUnit.MILLISECONDS);\n                } catch (Exception e) {\n                    throw new FlinkException(\n                            \"Could not stop with a savepoint job \\\"\" + jobId + \"\\\".\", e);\n                }\n                logAndSysout(\"Savepoint completed. Path: \" + savepointPath);\n            });\n}", "summary_tokens": ["executes", "the", "stop", "action"], "project": "flink"}
{"id": 9242, "code": "static BinaryRowData getNextOrNull(ResettableExternalBuffer.BufferIterator iterator) {\n    return iterator.advanceNext() ? iterator.getRow().copy() : null;\n}", "summary_tokens": ["get", "next", "row", "from", "iterator"], "project": "flink"}
{"id": 7831, "code": "public void testCheckpointBarrierMetrics() throws Exception {\n    final Map<String, Metric> metrics = new ConcurrentHashMap<>();\n    final TaskMetricGroup taskMetricGroup =\n            StreamTaskTestHarness.createTaskMetricGroup(metrics);\n\n    try (StreamTaskMailboxTestHarness<String> testHarness =\n            new StreamTaskMailboxTestHarnessBuilder<>(\n                            MultipleInputStreamTask::new, BasicTypeInfo.STRING_TYPE_INFO)\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO, 2)\n                    .addInput(BasicTypeInfo.INT_TYPE_INFO, 2)\n                    .addInput(BasicTypeInfo.DOUBLE_TYPE_INFO, 2)\n                    .setupOutputForSingletonOperatorChain(\n                            new MapToStringMultipleInputOperatorFactory(3))\n                    .setTaskMetricGroup(taskMetricGroup)\n                    .build()) {\n\n        assertThat(metrics, IsMapContaining.hasKey(MetricNames.CHECKPOINT_ALIGNMENT_TIME));\n        assertThat(metrics, IsMapContaining.hasKey(MetricNames.CHECKPOINT_START_DELAY_TIME));\n\n        testHarness.endInput();\n        testHarness.waitForTaskCompletion();\n    }\n}", "summary_tokens": ["tests", "the", "checkpoint", "related", "metrics", "are", "registered", "into", "task", "iometric", "group", "correctly", "while", "generating", "the", "two", "input", "stream", "task"], "project": "flink"}
{"id": 9279, "code": "public static void putDecimalNormalizedKey(\n        DecimalData record, MemorySegment target, int offset, int len) {\n    assert record.isCompact();\n    putLongNormalizedKey(record.toUnscaledLong(), target, offset, len);\n}", "summary_tokens": ["just", "support", "the", "compact", "precision", "decimal"], "project": "flink"}
{"id": 3770, "code": "public void checkJoinWithReplicatedSourceInputBehindMapChangingparallelism() {\n\n    ExecutionEnvironment env = ExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n\n    TupleTypeInfo<Tuple1<String>> typeInfo = TupleTypeInfo.getBasicTupleTypeInfo(String.class);\n    ReplicatingInputFormat<Tuple1<String>, FileInputSplit> rif =\n            new ReplicatingInputFormat<Tuple1<String>, FileInputSplit>(\n                    new TupleCsvInputFormat<Tuple1<String>>(new Path(\"/some/path\"), typeInfo));\n\n    DataSet<Tuple1<String>> source1 =\n            env.createInput(\n                    rif, new TupleTypeInfo<Tuple1<String>>(BasicTypeInfo.STRING_TYPE_INFO));\n    DataSet<Tuple1<String>> source2 = env.readCsvFile(\"/some/otherpath\").types(String.class);\n\n    DataSink<Tuple2<Tuple1<String>, Tuple1<String>>> out =\n            source1.map(new IdMap())\n                    .setParallelism(DEFAULT_PARALLELISM + 1)\n                    .join(source2)\n                    .where(\"*\")\n                    .equalTo(\"*\")\n                    .writeAsText(\"/some/newpath\");\n\n    Plan plan = env.createProgramPlan();\n\n        \n    OptimizedPlan oPlan = compileNoStats(plan);\n}", "summary_tokens": ["tests", "compiler", "fail", "for", "join", "program", "with", "replicated", "data", "source", "behind", "map", "and", "changing", "parallelism"], "project": "flink"}
{"id": 7546, "code": "public final boolean isLatencyMarker() {\n    return getClass() == LatencyMarker.class;\n}", "summary_tokens": ["checks", "whether", "this", "element", "is", "a", "latency", "marker"], "project": "flink"}
{"id": 2614, "code": "static void setup() throws IOException {\n        \n    schema =\n            new Schema.Parser()\n                    .parse(\n                            \"{\\\"type\\\": \\\"record\\\", \"\n                                    + \"\\\"name\\\": \\\"User\\\", \"\n                                    + \"\\\"fields\\\": [\\n\"\n                                    + \"        {\\\"name\\\": \\\"name\\\", \\\"type\\\": \\\"string\\\" },\\n\"\n                                    + \"        {\\\"name\\\": \\\"favoriteNumber\\\",  \\\"type\\\": [\\\"int\\\", \\\"null\\\"] },\\n\"\n                                    + \"        {\\\"name\\\": \\\"favoriteColor\\\", \\\"type\\\": [\\\"string\\\", \\\"null\\\"] }\\n\"\n                                    + \"    ]\\n\"\n                                    + \"    }\");\n\n    userRecords.add(createUser(\"Peter\", 1, \"red\"));\n    userRecords.add(createUser(\"Tom\", 2, \"yellow\"));\n    userRecords.add(createUser(\"Jack\", 3, \"green\"));\n\n    userPath = new Path(temporaryFolder.resolve(USER_PARQUET_FILE).toUri());\n    createParquetFile(AvroParquetWriters.forGenericRecord(schema), userPath, userRecords);\n\n        \n    addressRecords.addAll(createAddressList());\n    addressPath = new Path(temporaryFolder.resolve(ADDRESS_PARQUET_FILE).toUri());\n    createParquetFile(\n            AvroParquetWriters.forSpecificRecord(Address.class), addressPath, addressRecords);\n\n        \n    datumRecords.addAll(createDatumList());\n    datumPath = new Path(temporaryFolder.resolve(DATUM_PARQUET_FILE).toUri());\n    createParquetFile(\n            AvroParquetWriters.forReflectRecord(Datum.class), datumPath, datumRecords);\n}", "summary_tokens": ["create", "a", "parquet", "file", "in", "the", "temporary", "folder", "directory"], "project": "flink"}
{"id": 2834, "code": "public <K> JoinOperatorSetsPredicateBase where(KeySelector<I1, K> keySelector) {\n    TypeInformation<K> keyType =\n            TypeExtractor.getKeySelectorTypes(keySelector, input1.getType());\n    return new JoinOperatorSetsPredicateBase(\n            new Keys.SelectorFunctionKeys<>(keySelector, input1.getType(), keyType));\n}", "summary_tokens": ["continues", "a", "join", "transformation", "and", "defines", "a", "key", "selector", "function", "for", "the", "first", "join", "data", "set"], "project": "flink"}
{"id": 8772, "code": "protected void validateOrderList(SqlSelect select) {\n        \n        \n        \n    SqlNodeList orderList = select.getOrderList();\n    if (orderList == null) {\n        return;\n    }\n    if (!shouldAllowIntermediateOrderBy()) {\n        if (!cursorSet.contains(select)) {\n            throw newValidationError(select, RESOURCE.invalidOrderByPos());\n        }\n    }\n    final SqlValidatorScope orderScope = getOrderScope(select);\n    Objects.requireNonNull(orderScope);\n\n    List<SqlNode> expandList = new ArrayList<>();\n    for (SqlNode orderItem : orderList) {\n        SqlNode expandedOrderItem = expand(orderItem, orderScope);\n        expandList.add(expandedOrderItem);\n    }\n\n    SqlNodeList expandedOrderList = new SqlNodeList(expandList, orderList.getParserPosition());\n    select.setOrderBy(expandedOrderList);\n\n    for (SqlNode orderItem : expandedOrderList) {\n        validateOrderItem(select, orderItem);\n    }\n}", "summary_tokens": ["validates", "the", "order", "by", "clause", "of", "a", "select", "statement"], "project": "flink"}
{"id": 1816, "code": "public static MemorySegment allocateOffHeapUnsafeMemory(\n        int size, Object owner, Runnable customCleanupAction) {\n    long address = MemoryUtils.allocateUnsafe(size);\n    ByteBuffer offHeapBuffer = MemoryUtils.wrapUnsafeMemoryWithByteBuffer(address, size);\n    Runnable cleaner = MemoryUtils.createMemoryCleaner(address, customCleanupAction);\n    return new MemorySegment(offHeapBuffer, owner, false, cleaner);\n}", "summary_tokens": ["allocates", "an", "off", "heap", "unsafe", "memory", "and", "creates", "a", "new", "memory", "segment", "to", "represent", "that", "memory"], "project": "flink"}
{"id": 1980, "code": "public static void deleteFileQuietly(Path path) {\n    try {\n        Files.deleteIfExists(path);\n    } catch (Throwable ignored) {\n    }\n}", "summary_tokens": ["deletes", "the", "given", "file"], "project": "flink"}
{"id": 7291, "code": "default void finish() throws Exception {}", "summary_tokens": ["this", "method", "is", "called", "at", "the", "end", "of", "data", "processing"], "project": "flink"}
{"id": 4036, "code": "public String getEndpointId() {\n    return endpointId;\n}", "summary_tokens": ["returns", "the", "rpc", "endpoint", "s", "identifier"], "project": "flink"}
{"id": 1926, "code": "protected final boolean removeCloseableInternal(R closeable) {\n    synchronized (getSynchronizationLock()) {\n        return closeableToRef.remove(closeable) != null;\n    }\n}", "summary_tokens": ["removes", "a", "mapping", "from", "the", "registry", "map", "respecting", "locking"], "project": "flink"}
{"id": 1392, "code": "public final TypeSerializer<T> restoreSerializer() {\n    if (serializer == null) {\n        throw new IllegalStateException(\n                \"Trying to restore the prior serializer via TypeSerializerConfigSnapshot, \"\n                        + \"but the prior serializer has not been set.\");\n    } else if (serializer instanceof UnloadableDummyTypeSerializer) {\n        Throwable originalError =\n                ((UnloadableDummyTypeSerializer<?>) serializer).getOriginalError();\n\n        throw new IllegalStateException(\n                \"Could not Java-deserialize TypeSerializer while restoring checkpoint metadata for serializer \"\n                        + \"snapshot '\"\n                        + getClass().getName()\n                        + \"'. \"\n                        + \"Please update to the TypeSerializerSnapshot interface that removes Java Serialization to avoid \"\n                        + \"this problem in the future.\",\n                originalError);\n    } else {\n        return this.serializer;\n    }\n}", "summary_tokens": ["creates", "a", "serializer", "using", "this", "configuration", "that", "is", "capable", "of", "reading", "data", "written", "by", "the", "serializer", "described", "by", "this", "configuration"], "project": "flink"}
{"id": 4359, "code": "public int getAttemptNumber() {\n    return attemptNumber;\n}", "summary_tokens": ["returns", "the", "attempt", "number", "of", "the", "subtask"], "project": "flink"}
{"id": 5757, "code": "public void testPermanentBlobDeferredCleanup() throws IOException, InterruptedException {\n        \n    long cleanupInterval = 5L;\n\n    JobID jobId = new JobID();\n    List<PermanentBlobKey> keys = new ArrayList<>();\n    BlobServer server = null;\n    PermanentBlobCache cache = null;\n\n    final byte[] buf = new byte[128];\n\n    try {\n        Configuration config = new Configuration();\n        config.setString(\n                BlobServerOptions.STORAGE_DIRECTORY,\n                temporaryFolder.newFolder().getAbsolutePath());\n        config.setLong(BlobServerOptions.CLEANUP_INTERVAL, cleanupInterval);\n\n        server = new BlobServer(config, new VoidBlobStore());\n        server.start();\n        InetSocketAddress serverAddress = new InetSocketAddress(\"localhost\", server.getPort());\n        final BlobCacheSizeTracker tracker =\n                new BlobCacheSizeTracker(MemorySize.ofMebiBytes(100).getBytes());\n        cache = new PermanentBlobCache(config, new VoidBlobStore(), serverAddress, tracker);\n\n            \n        keys.add(server.putPermanent(jobId, buf));\n        buf[0] += 1;\n        keys.add(server.putPermanent(jobId, buf));\n\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(0, jobId, cache);\n        checkBlobCacheSizeTracker(tracker, jobId, 0);\n\n            \n        cache.registerJob(jobId);\n\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(0, jobId, cache);\n        checkBlobCacheSizeTracker(tracker, jobId, 0);\n\n        for (PermanentBlobKey key : keys) {\n            cache.readFile(jobId, key);\n        }\n\n            \n        cache.registerJob(jobId);\n        for (PermanentBlobKey key : keys) {\n            cache.readFile(jobId, key);\n        }\n\n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(2, jobId, cache);\n        checkBlobCacheSizeTracker(tracker, jobId, 2);\n\n            \n        cache.releaseJob(jobId);\n\n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, server);\n        checkFileCountForJob(2, jobId, cache);\n        checkBlobCacheSizeTracker(tracker, jobId, 2);\n\n            \n        cache.releaseJob(jobId);\n\n            \n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, cache);\n\n        Thread.sleep(cleanupInterval / 5);\n            \n        assertEquals(2, checkFilesExist(jobId, keys, cache, true));\n        checkFileCountForJob(2, jobId, cache);\n\n        Thread.sleep((cleanupInterval * 4) / 5);\n\n            \n        verifyJobCleanup(cache, jobId, keys);\n        checkBlobCacheSizeTracker(tracker, jobId, 0);\n            \n        checkFileCountForJob(2, jobId, server);\n    } finally {\n        if (cache != null) {\n            cache.close();\n        }\n\n        if (server != null) {\n            server.close();\n        }\n            \n        checkFileCountForJob(0, jobId, server);\n    }\n}", "summary_tokens": ["tests", "the", "deferred", "cleanup", "of", "permanent", "blob", "cache", "i"], "project": "flink"}
{"id": 2757, "code": "private DataSink<T> setResources(ResourceSpec resources) {\n    OperatorValidationUtils.validateResources(resources);\n\n    this.minResources = resources;\n    this.preferredResources = resources;\n\n    return this;\n}", "summary_tokens": ["sets", "the", "resources", "for", "this", "data", "sink", "and", "the", "minimum", "and", "preferred", "resources", "are", "the", "same", "by", "default"], "project": "flink"}
{"id": 4633, "code": "public PipelinedSubpartitionView createReadView(\n        BufferAvailabilityListener availabilityListener) {\n    synchronized (buffers) {\n        checkState(!isReleased);\n\n        releaseView();\n\n        LOG.debug(\n                \"{}: Creating read view for subpartition {} of partition {}.\",\n                parent.getOwningTaskName(),\n                getSubPartitionIndex(),\n                parent.getPartitionId());\n\n        readView = new PipelinedApproximateSubpartitionView(this, availabilityListener);\n    }\n\n    return readView;\n}", "summary_tokens": ["to", "simply", "the", "view", "releasing", "threading", "model", "pipelined", "approximate", "subpartition", "release", "view", "is", "called", "only", "before", "creating", "a", "new", "view"], "project": "flink"}
{"id": 2085, "code": "public static ExecutorService newDirectExecutorService() {\n    return new DirectExecutorService();\n}", "summary_tokens": ["return", "a", "new", "direct", "executor", "service"], "project": "flink"}
{"id": 4277, "code": "private static void checkStateMappingCompleteness(\n        boolean allowNonRestoredState,\n        Map<OperatorID, OperatorState> operatorStates,\n        Set<ExecutionJobVertex> tasks) {\n\n    Set<OperatorID> allOperatorIDs = new HashSet<>();\n    for (ExecutionJobVertex executionJobVertex : tasks) {\n        for (OperatorIDPair operatorIDPair : executionJobVertex.getOperatorIDs()) {\n            allOperatorIDs.add(operatorIDPair.getGeneratedOperatorID());\n            operatorIDPair.getUserDefinedOperatorID().ifPresent(allOperatorIDs::add);\n        }\n    }\n    for (Map.Entry<OperatorID, OperatorState> operatorGroupStateEntry :\n            operatorStates.entrySet()) {\n        OperatorState operatorState = operatorGroupStateEntry.getValue();\n            \n            \n\n        if (!allOperatorIDs.contains(operatorGroupStateEntry.getKey())) {\n            if (allowNonRestoredState) {\n                LOG.info(\n                        \"Skipped checkpoint state for operator {}.\",\n                        operatorState.getOperatorID());\n            } else {\n                throw new IllegalStateException(\n                        \"There is no operator for the state \" + operatorState.getOperatorID());\n            }\n        }\n    }\n}", "summary_tokens": ["verifies", "that", "all", "operator", "states", "can", "be", "mapped", "to", "an", "execution", "job", "vertex"], "project": "flink"}
{"id": 75, "code": "public void testWaitUntilJobInitializationFinished_throwsInitializationException() {\n    Iterator<JobStatus> statusSequenceIterator =\n            Arrays.asList(JobStatus.INITIALIZING, JobStatus.INITIALIZING, JobStatus.FAILED)\n                    .iterator();\n\n    CommonTestUtils.assertThrows(\n            \"Something is wrong\",\n            JobInitializationException.class,\n            () -> {\n                ClientUtils.waitUntilJobInitializationFinished(\n                        statusSequenceIterator::next,\n                        () -> {\n                            Throwable throwable =\n                                    new JobInitializationException(\n                                            TESTING_JOB_ID,\n                                            \"Something is wrong\",\n                                            new RuntimeException(\"Err\"));\n                            return buildJobResult(throwable);\n                        },\n                        ClassLoader.getSystemClassLoader());\n                return null;\n            });\n}", "summary_tokens": ["ensure", "that", "the", "wait", "until", "job", "initialization", "finished", "method", "throws", "job", "initialization", "exception"], "project": "flink"}
{"id": 5230, "code": "public String decodedPath() {\n    return decodedPath;\n}", "summary_tokens": ["returns", "the", "decoded", "request", "path"], "project": "flink"}
{"id": 1298, "code": "public <X> void setBroadcastVariables(Map<String, Operator<X>> inputs) {\n    throw new UnsupportedOperationException(\n            \"The DeltaIteration meta operator cannot have broadcast inputs.\");\n}", "summary_tokens": ["the", "delta", "iteration", "meta", "operator", "cannot", "have", "broadcast", "inputs"], "project": "flink"}
{"id": 649, "code": "public static List<ProducerRecord<String, Integer>> getRecordsForPartition(TopicPartition tp) {\n    List<ProducerRecord<String, Integer>> records = new ArrayList<>();\n    for (int i = 0; i < NUM_RECORDS_PER_PARTITION; i++) {\n        records.add(\n                new ProducerRecord<>(tp.topic(), tp.partition(), i * 1000L, tp.toString(), i));\n    }\n    return records;\n}", "summary_tokens": ["for", "a", "given", "partition", "topic", "partition", "the", "i", "th", "records", "looks", "like", "following"], "project": "flink"}
{"id": 8946, "code": "protected boolean inputsContainSingleton() {\n    return getInputEdges().stream()\n            .map(ExecEdge::getSource)\n            .anyMatch(\n                    i ->\n                            i instanceof CommonExecExchange\n                                    && i.getInputProperties()\n                                                    .get(0)\n                                                    .getRequiredDistribution()\n                                                    .getType()\n                                            == InputProperty.DistributionType.SINGLETON);\n}", "summary_tokens": ["whether", "there", "is", "singleton", "exchange", "node", "as", "input"], "project": "flink"}
{"id": 8734, "code": "RexNode simplifyAnd2ForUnknownAsFalse(List<RexNode> terms, List<RexNode> notTerms) {\n        \n    return simplifyAnd2ForUnknownAsFalse(terms, notTerms, Comparable.class);\n}", "summary_tokens": ["as", "simplify", "and", "0", "list", "list", "but", "we", "assume", "that", "if", "the", "expression", "returns", "unknown", "it", "will", "be", "interpreted", "as", "false"], "project": "flink"}
{"id": 5068, "code": "private static void fix(IndexedSortable s, int pN, int pO, int rN, int rO) {\n    if (s.compare(pN, pO, rN, rO) > 0) {\n        s.swap(pN, pO, rN, rO);\n    }\n}", "summary_tokens": ["fix", "the", "records", "into", "sorted", "order", "swapping", "when", "the", "first", "record", "is", "greater", "than", "the", "second", "record"], "project": "flink"}
{"id": 4815, "code": "public static JobResult createFrom(AccessExecutionGraph accessExecutionGraph) {\n    final JobID jobId = accessExecutionGraph.getJobID();\n    final JobStatus jobStatus = accessExecutionGraph.getState();\n\n    checkArgument(\n            jobStatus.isTerminalState(),\n            \"The job \"\n                    + accessExecutionGraph.getJobName()\n                    + '('\n                    + jobId\n                    + \") is not in a \"\n                    + \"terminal state. It is in state \"\n                    + jobStatus\n                    + '.');\n\n    final JobResult.Builder builder = new JobResult.Builder();\n    builder.jobId(jobId);\n\n    builder.applicationStatus(ApplicationStatus.fromJobStatus(accessExecutionGraph.getState()));\n\n    final long netRuntime =\n            accessExecutionGraph.getStatusTimestamp(jobStatus)\n                    - accessExecutionGraph.getStatusTimestamp(JobStatus.INITIALIZING);\n        \n    final long guardedNetRuntime = Math.max(netRuntime, 0L);\n    builder.netRuntime(guardedNetRuntime);\n    builder.accumulatorResults(accessExecutionGraph.getAccumulatorsSerialized());\n\n    if (jobStatus == JobStatus.FAILED) {\n        final ErrorInfo errorInfo = accessExecutionGraph.getFailureInfo();\n        checkNotNull(errorInfo, \"No root cause is found for the job failure.\");\n\n        builder.serializedThrowable(errorInfo.getException());\n    }\n\n    return builder.build();\n}", "summary_tokens": ["creates", "the", "job", "result", "from", "the", "given", "access", "execution", "graph", "which", "must", "be", "in", "a", "globally", "terminal", "state"], "project": "flink"}
{"id": 8078, "code": "public void registerTemporarySystemFunction(\n        String name,\n        String fullyQualifiedName,\n        FunctionLanguage language,\n        boolean ignoreIfExists) {\n    registerTemporarySystemFunction(\n            name, new CatalogFunctionImpl(fullyQualifiedName, language), ignoreIfExists);\n}", "summary_tokens": ["registers", "a", "uninstantiated", "temporary", "system", "function"], "project": "flink"}
{"id": 2160, "code": "public void testFailsWhenConfigurationSnapshotClassNotFound() throws Exception {\n    byte[] serializedConfig;\n    try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n        TypeSerializerSnapshotSerializationUtil.writeSerializerSnapshot(\n                new DataOutputViewStreamWrapper(out),\n                new TypeSerializerSerializationUtilTest.TestConfigSnapshot<>(123, \"foobar\"),\n                StringSerializer.INSTANCE);\n        serializedConfig = out.toByteArray();\n    }\n\n    try (ByteArrayInputStream in = new ByteArrayInputStream(serializedConfig)) {\n            \n        TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(\n                new DataInputViewStreamWrapper(in), new URLClassLoader(new URL[0], null), null);\n    }\n\n    fail(\"Expected a ClassNotFoundException wrapped in IOException\");\n}", "summary_tokens": ["verifies", "that", "deserializing", "config", "snapshots", "fail", "if", "the", "config", "class", "could", "not", "be", "found"], "project": "flink"}
{"id": 323, "code": "public static String getDefaultPartitionName(JobConf jobConf) {\n    return jobConf.get(\n            HiveConf.ConfVars.DEFAULTPARTITIONNAME.varname,\n            HiveConf.ConfVars.DEFAULTPARTITIONNAME.defaultStrVal);\n}", "summary_tokens": ["gets", "the", "hive", "conf"], "project": "flink"}
{"id": 9162, "code": "private int getPartitioningFanOutNoEstimates() {\n    return Math.max(\n            11,\n            findSmallerPrime(\n                    (int)\n                            Math.min(\n                                    buildRowCount * avgRecordLen / (10 * segmentSize),\n                                    MAX_NUM_PARTITIONS)));\n}", "summary_tokens": ["gets", "the", "number", "of", "partitions", "to", "be", "used", "for", "an", "initial", "hash", "table"], "project": "flink"}
{"id": 1934, "code": "public static <T> Collection<List<T>> partition(Collection<T> elements, int numBuckets) {\n    Map<Integer, List<T>> buckets = new HashMap<>(numBuckets);\n\n    int initialCapacity = elements.size() / numBuckets;\n\n    int index = 0;\n    for (T element : elements) {\n        int bucket = index % numBuckets;\n        buckets.computeIfAbsent(bucket, key -> new ArrayList<>(initialCapacity)).add(element);\n        index++;\n    }\n\n    return buckets.values();\n}", "summary_tokens": ["partition", "a", "collection", "into", "approximately", "n", "buckets"], "project": "flink"}
{"id": 2627, "code": "public void testBlobCacheCorruptedFile() throws Exception {\n    org.apache.flink.configuration.Configuration config =\n            new org.apache.flink.configuration.Configuration();\n    config.setString(HighAvailabilityOptions.HA_MODE, \"ZOOKEEPER\");\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n    config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI);\n\n    BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config);\n\n    try {\n        BlobCacheCorruptionTest.testGetFailsFromCorruptFile(\n                new JobID(), config, blobStoreService, exception);\n    } finally {\n        blobStoreService.closeAndCleanupAllData();\n    }\n}", "summary_tokens": ["tests", "that", "with", "high", "availability", "mode", "zookeeper", "distributed", "corrupted", "jars", "are", "recognised", "during", "the", "download", "via", "a", "blob", "cache"], "project": "flink"}
{"id": 2610, "code": "private int readUnsignedVarInt() throws IOException {\n    int value = 0;\n    int shift = 0;\n    int b;\n    do {\n        b = in.read();\n        value |= (b & 0x7F) << shift;\n        shift += 7;\n    } while ((b & 0x80) != 0);\n    return value;\n}", "summary_tokens": ["reads", "the", "next", "varint", "encoded", "int"], "project": "flink"}
{"id": 1580, "code": "public static void validateLambdaType(Class<?> baseClass, Type t) {\n    if (!(t instanceof Class)) {\n        return;\n    }\n    final Class<?> clazz = (Class<?>) t;\n\n    if (clazz.getTypeParameters().length > 0) {\n        throw new InvalidTypesException(\n                \"The generic type parameters of '\"\n                        + clazz.getSimpleName()\n                        + \"' are missing. \"\n                        + \"In many cases lambda methods don't provide enough information for automatic type extraction when Java generics are involved. \"\n                        + \"An easy workaround is to use an (anonymous) class instead that implements the '\"\n                        + baseClass.getName()\n                        + \"' interface. \"\n                        + \"Otherwise the type has to be specified explicitly using type information.\");\n    }\n}", "summary_tokens": ["checks", "whether", "the", "given", "type", "has", "the", "generic", "parameters", "declared", "in", "the", "class", "definition"], "project": "flink"}
{"id": 2142, "code": "public void testOneNestedDirectoryTrue() {\n    try {\n        String firstLevelDir = TestFileUtils.randomFileName();\n        String secondLevelDir = TestFileUtils.randomFileName();\n\n        File insideNestedDir = tempFolder.newFolder(firstLevelDir, secondLevelDir);\n        File nestedDir = insideNestedDir.getParentFile();\n\n            \n        TestFileUtils.createTempFileInDirectory(nestedDir.getAbsolutePath(), \"paella\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"kalamari\");\n        TestFileUtils.createTempFileInDirectory(insideNestedDir.getAbsolutePath(), \"fideua\");\n\n        this.format.setFilePath(new Path(nestedDir.toURI().toString()));\n        this.config.setBoolean(\"recursive.file.enumeration\", true);\n        format.configure(this.config);\n\n        FileInputSplit[] splits = format.createInputSplits(1);\n        Assert.assertEquals(3, splits.length);\n    } catch (Exception ex) {\n        ex.printStackTrace();\n        Assert.fail(ex.getMessage());\n    }\n}", "summary_tokens": ["test", "with", "one", "nested", "directory", "and", "recursive"], "project": "flink"}
{"id": 9724, "code": "public static void addToEnvironment(\n        Map<String, String> environment, String variable, String value) {\n    String val = environment.get(variable);\n    if (val == null) {\n        val = value;\n    } else {\n        val = val + File.pathSeparator + value;\n    }\n    environment.put(StringInterner.weakIntern(variable), StringInterner.weakIntern(val));\n}", "summary_tokens": ["copied", "method", "from", "org"], "project": "flink"}
{"id": 2081, "code": "public static RuntimeException wrapIfNecessary(Throwable throwable) {\n    if (throwable instanceof RuntimeException) {\n        return (RuntimeException) throwable;\n    }\n    return new WrappingRuntimeException(throwable);\n}", "summary_tokens": ["ensures", "that", "any", "throwable", "can", "be", "thrown", "as", "a", "checked", "exception", "by", "potentially", "wrapping", "it"], "project": "flink"}
{"id": 5498, "code": "public S removeAndGetOld(N namespace) {\n    return removeAndGetOld(\n            keyContext.getCurrentKey(), keyContext.getCurrentKeyGroupIndex(), namespace);\n}", "summary_tokens": ["removes", "the", "mapping", "for", "the", "composite", "of", "active", "key", "and", "given", "namespace", "returning", "the", "state", "that", "was", "found", "under", "the", "entry"], "project": "flink"}
{"id": 6052, "code": "public void testTerminationFutureIsCompletedAfterSlotRelease() throws Exception {\n    final JobVertex jobVertex = createNoOpJobVertex();\n    final JobVertexID jobVertexId = jobVertex.getID();\n\n    final TestingPhysicalSlotProvider physicalSlotProvider =\n            TestingPhysicalSlotProvider.createWithLimitedAmountOfPhysicalSlots(1);\n    final SchedulerBase scheduler =\n            SchedulerTestingUtils.newSchedulerBuilder(\n                            JobGraphTestUtils.streamingJobGraph(jobVertex),\n                            ComponentMainThreadExecutorServiceAdapter.forMainThread())\n                    .setExecutionSlotAllocatorFactory(\n                            SchedulerTestingUtils.newSlotSharingExecutionSlotAllocatorFactory(\n                                    physicalSlotProvider))\n                    .build();\n\n    ExecutionJobVertex executionJobVertex = scheduler.getExecutionJobVertex(jobVertexId);\n\n    ExecutionVertex executionVertex = executionJobVertex.getTaskVertices()[0];\n\n    scheduler.startScheduling();\n\n    Execution currentExecutionAttempt = executionVertex.getCurrentExecutionAttempt();\n\n    CompletableFuture<? extends PhysicalSlot> returnedSlotFuture =\n            physicalSlotProvider.getFirstResponseOrFail();\n    CompletableFuture<?> terminationFuture = executionVertex.cancel();\n\n    currentExecutionAttempt.completeCancelling();\n\n    CompletableFuture<Boolean> restartFuture =\n            terminationFuture.thenApply(\n                    ignored -> {\n                        assertTrue(returnedSlotFuture.isDone());\n                        return true;\n                    });\n\n        \n    restartFuture.get();\n}", "summary_tokens": ["checks", "that", "the", "execution", "termination", "future", "is", "only", "completed", "after", "the", "assigned", "slot", "has", "been", "released"], "project": "flink"}
{"id": 9534, "code": "public static String getS3SecretKey() {\n    if (S3_TEST_SECRET_KEY != null) {\n        return S3_TEST_SECRET_KEY;\n    } else {\n        throw new IllegalStateException(\"S3 test secret key not available\");\n    }\n}", "summary_tokens": ["gets", "the", "s", "0", "secret", "key"], "project": "flink"}
{"id": 4413, "code": "private void releaseAssignedResource(@Nullable Throwable cause) {\n\n    assertRunningInJobMasterMainThread();\n\n    final LogicalSlot slot = assignedResource;\n\n    if (slot != null) {\n        ComponentMainThreadExecutor jobMasterMainThreadExecutor =\n                getVertex().getExecutionGraphAccessor().getJobMasterMainThreadExecutor();\n\n        slot.releaseSlot(cause)\n                .whenComplete(\n                        (Object ignored, Throwable throwable) -> {\n                            jobMasterMainThreadExecutor.assertRunningInMainThread();\n                            if (throwable != null) {\n                                releaseFuture.completeExceptionally(throwable);\n                            } else {\n                                releaseFuture.complete(null);\n                            }\n                        });\n    } else {\n            \n        releaseFuture.complete(null);\n    }\n}", "summary_tokens": ["releases", "the", "assigned", "resource", "and", "completes", "the", "release", "future", "once", "the", "assigned", "resource", "has", "been", "successfully", "released"], "project": "flink"}
{"id": 1719, "code": "public int getMaxNumOpenInputStreams() {\n    return maxNumOpenInputStreams;\n}", "summary_tokens": ["gets", "the", "maximum", "number", "of", "concurrently", "open", "input", "streams"], "project": "flink"}
{"id": 3645, "code": "public SolutionSetPlaceHolder<?> getOperator() {\n    return (SolutionSetPlaceHolder<?>) super.getOperator();\n}", "summary_tokens": ["gets", "the", "contract", "object", "for", "this", "data", "source", "node"], "project": "flink"}
{"id": 6733, "code": "public Optional<MaterializationRunnable> initMaterialization() throws Exception {\n    SequenceNumber upTo = getLastAppendedTo();\n    SequenceNumber lastMaterializedTo = changelogSnapshotState.lastMaterializedTo();\n\n    LOG.info(\n            \"Initialize Materialization. Current changelog writers last append to sequence number {}\",\n            upTo);\n\n    if (upTo.compareTo(lastMaterializedTo) > 0) {\n\n        LOG.info(\"Starting materialization from {} : {}\", lastMaterializedTo, upTo);\n\n        MaterializationRunnable materializationRunnable =\n                new MaterializationRunnable(\n                        keyedStateBackend.snapshot(\n                                    \n                                    \n                                    \n                                    \n                                    \n                                    \n                                materializedId++,\n                                System.currentTimeMillis(),\n                                streamFactory,\n                                CHECKPOINT_OPTIONS),\n                        upTo);\n\n            \n        for (ChangelogState changelogState : changelogStates.values()) {\n            changelogState.resetWritingMetaFlag();\n        }\n\n        for (ChangelogKeyGroupedPriorityQueue<?> priorityQueueState :\n                priorityQueueStatesByName.values()) {\n            priorityQueueState.resetWritingMetaFlag();\n        }\n\n        return Optional.of(materializationRunnable);\n    } else {\n        LOG.debug(\n                \"Skip materialization, last materialized to {} : last log to {}\",\n                lastMaterializedTo,\n                upTo);\n\n        return Optional.empty();\n    }\n}", "summary_tokens": ["initialize", "state", "materialization", "so", "that", "materialized", "data", "can", "be", "persisted", "durably", "and", "included", "into", "the", "checkpoint"], "project": "flink"}
{"id": 7978, "code": "public static EnvironmentSettings fromConfiguration(ReadableConfig configuration) {\n    final Builder builder = new Builder();\n    switch (configuration.get(RUNTIME_MODE)) {\n        case STREAMING:\n            builder.inStreamingMode();\n            break;\n        case BATCH:\n            builder.inBatchMode();\n            break;\n        case AUTOMATIC:\n        default:\n            throw new TableException(\n                    String.format(\n                            \"Unsupported mode '%s' for '%s'. \"\n                                    + \"Only an explicit BATCH or STREAMING mode is supported in Table API.\",\n                            configuration.get(RUNTIME_MODE), RUNTIME_MODE.key()));\n    }\n\n    switch (configuration.get(TABLE_PLANNER)) {\n        case BLINK:\n            builder.useBlinkPlanner();\n            break;\n        case OLD:\n            builder.useOldPlanner();\n            break;\n        default:\n            throw new IllegalArgumentException(\n                    String.format(\n                            \"Unrecognized value '%s' for option '%s'.\",\n                            configuration.get(TABLE_PLANNER), TABLE_PLANNER.key()));\n    }\n    return builder.build();\n}", "summary_tokens": ["creates", "an", "instance", "of", "environment", "settings", "from", "configuration"], "project": "flink"}
{"id": 9249, "code": "public void putAll(RowData sortKey, Collection<RowData> values) {\n    Collection<RowData> oldValues = treeMap.get(sortKey);\n    if (oldValues != null) {\n        currentTopNum -= oldValues.size();\n    }\n    treeMap.put(sortKey, values);\n    currentTopNum += values.size();\n}", "summary_tokens": ["puts", "a", "record", "list", "into", "the", "buffer", "under", "the", "sort", "key"], "project": "flink"}
{"id": 4023, "code": "public void testScheduledExecutorServiceCancelWithFixedDelay() throws InterruptedException {\n    ScheduledExecutor scheduledExecutor = akkaRpcService.getScheduledExecutor();\n\n    long delay = 10L;\n\n    final OneShotLatch futureTask = new OneShotLatch();\n    final OneShotLatch latch = new OneShotLatch();\n    final OneShotLatch shouldNotBeTriggeredLatch = new OneShotLatch();\n\n    ScheduledFuture<?> future =\n            scheduledExecutor.scheduleWithFixedDelay(\n                    () -> {\n                        try {\n                            if (futureTask.isTriggered()) {\n                                shouldNotBeTriggeredLatch.trigger();\n                            } else {\n                                    \n                                futureTask.trigger();\n                                latch.await();\n                            }\n                        } catch (InterruptedException ignored) {\n                                \n                        }\n                    },\n                    delay,\n                    delay,\n                    TimeUnit.MILLISECONDS);\n\n        \n    futureTask.await();\n\n        \n    future.cancel(false);\n\n    latch.trigger();\n\n    try {\n        shouldNotBeTriggeredLatch.await(5 * delay, TimeUnit.MILLISECONDS);\n        fail(\"The shouldNotBeTriggeredLatch should never be triggered.\");\n    } catch (TimeoutException e) {\n            \n    }\n}", "summary_tokens": ["tests", "that", "canceling", "the", "returned", "future", "will", "stop", "the", "execution", "of", "the", "scheduled", "runnable"], "project": "flink"}
{"id": 2015, "code": "private static URL validateHostPortString(String hostPort) {\n    try {\n        URL u = new URL(\"http://\" + hostPort);\n        if (u.getHost() == null) {\n            throw new IllegalArgumentException(\n                    \"The given host:port ('\" + hostPort + \"') doesn't contain a valid host\");\n        }\n        if (u.getPort() == -1) {\n            throw new IllegalArgumentException(\n                    \"The given host:port ('\" + hostPort + \"') doesn't contain a valid port\");\n        }\n        return u;\n    } catch (MalformedURLException e) {\n        throw new IllegalArgumentException(\n                \"The given host:port ('\" + hostPort + \"') is invalid\", e);\n    }\n}", "summary_tokens": ["validates", "if", "the", "given", "string", "represents", "a", "hostname", "port"], "project": "flink"}
{"id": 5895, "code": "public void testConcurrentGetAndIncrement() throws Exception {\n        \n    final int numThreads = 8;\n\n        \n    final CountDownLatch startLatch = new CountDownLatch(1);\n    final CheckpointIDCounter counter = createCheckpointIdCounter();\n    counter.start();\n\n    ExecutorService executor = null;\n    try {\n        executor = Executors.newFixedThreadPool(numThreads);\n\n        List<Future<List<Long>>> resultFutures = new ArrayList<>(numThreads);\n\n        for (int i = 0; i < numThreads; i++) {\n            resultFutures.add(executor.submit(new Incrementer(startLatch, counter)));\n        }\n\n            \n        startLatch.countDown();\n\n        final int expectedTotal = numThreads * Incrementer.NumIncrements;\n\n        List<Long> all = new ArrayList<>(expectedTotal);\n\n            \n        for (Future<List<Long>> result : resultFutures) {\n            List<Long> counts = result.get();\n            all.addAll(counts);\n        }\n\n            \n        Collections.sort(all);\n\n        assertEquals(expectedTotal, all.size());\n\n        long current = 0;\n        for (long val : all) {\n                \n            assertEquals(++current, val);\n        }\n\n            \n        assertEquals(expectedTotal + 1, counter.get());\n        assertEquals(expectedTotal + 1, counter.getAndIncrement());\n    } finally {\n        if (executor != null) {\n            executor.shutdown();\n        }\n\n        counter.shutdown(JobStatus.FINISHED);\n    }\n}", "summary_tokens": ["tests", "concurrent", "increment", "and", "get", "calls", "from", "multiple", "threads", "and", "verifies", "that", "the", "numbers", "counts", "strictly", "increasing"], "project": "flink"}
{"id": 9107, "code": "public void writeString(int pos, StringData input) {\n    BinaryStringData string = (BinaryStringData) input;\n    if (string.getSegments() == null) {\n        String javaObject = string.toString();\n        writeBytes(pos, javaObject.getBytes(StandardCharsets.UTF_8));\n    } else {\n        int len = string.getSizeInBytes();\n        if (len <= 7) {\n            byte[] bytes = BinarySegmentUtils.allocateReuseBytes(len);\n            BinarySegmentUtils.copyToBytes(\n                    string.getSegments(), string.getOffset(), bytes, 0, len);\n            writeBytesToFixLenPart(segment, getFieldOffset(pos), bytes, len);\n        } else {\n            writeSegmentsToVarLenPart(pos, string.getSegments(), string.getOffset(), len);\n        }\n    }\n}", "summary_tokens": ["see", "binary", "segment", "utils", "read", "string", "data", "memory", "segment", "int", "int", "long"], "project": "flink"}
{"id": 9508, "code": "public static Matcher<CompletableFuture<?>> willNotComplete(Duration timeout) {\n    return new WillNotCompleteMatcher(timeout);\n}", "summary_tokens": ["checks", "that", "a", "completable", "future", "won", "t", "complete", "within", "the", "given", "timeout"], "project": "flink"}
{"id": 648, "code": "public static Configuration getKafkaSourceConfiguration(KafkaSource<?> kafkaSource) {\n    return kafkaSource.getConfiguration();\n}", "summary_tokens": ["get", "configuration", "of", "kafka", "source"], "project": "flink"}
{"id": 5390, "code": "public long getOffsetForKeyGroup(int keyGroupId) {\n    return groupRangeOffsets.getKeyGroupOffset(keyGroupId);\n}", "summary_tokens": ["key", "group", "id", "the", "id", "of", "a", "key", "group"], "project": "flink"}
{"id": 8479, "code": "default Optional<DynamicTableSourceFactory> getTableSourceFactory() {\n    return Optional.empty();\n}", "summary_tokens": ["returns", "a", "dynamic", "table", "source", "factory", "for", "creating", "source", "tables"], "project": "flink"}
{"id": 8019, "code": "public void setIdleStateRetention(Duration duration) {\n    configuration.set(ExecutionConfigOptions.IDLE_STATE_RETENTION, duration);\n}", "summary_tokens": ["specifies", "a", "retention", "time", "interval", "for", "how", "long", "idle", "state", "i"], "project": "flink"}
{"id": 5432, "code": "public static long discardStateFuture(Future<? extends StateObject> stateFuture)\n        throws Exception {\n    long stateSize = 0;\n    if (null != stateFuture) {\n        if (!stateFuture.cancel(true)) {\n\n            try {\n                    \n                if (stateFuture instanceof RunnableFuture<?> && !stateFuture.isDone()) {\n                    ((RunnableFuture<?>) stateFuture).run();\n                }\n                StateObject stateObject = stateFuture.get();\n                if (stateObject != null) {\n                    stateSize = stateObject.getStateSize();\n                    stateObject.discardState();\n                }\n\n            } catch (Exception ex) {\n                LOG.debug(\n                        \"Cancelled execution of snapshot future runnable. Cancellation produced the following \"\n                                + \"exception, which is expected an can be ignored.\",\n                        ex);\n            }\n        } else if (stateFuture.isDone()) {\n            try {\n                stateSize = stateFuture.get().getStateSize();\n            } catch (Exception e) {\n                    \n            }\n        }\n    }\n    return stateSize;\n}", "summary_tokens": ["discards", "the", "given", "state", "future", "by", "first", "trying", "to", "cancel", "it"], "project": "flink"}
{"id": 2612, "code": "private int readIntLittleEndianPaddedOnBitWidth() throws IOException {\n    switch (bytesWidth) {\n        case 0:\n            return 0;\n        case 1:\n            return in.read();\n        case 2:\n            {\n                int ch2 = in.read();\n                int ch1 = in.read();\n                return (ch1 << 8) + ch2;\n            }\n        case 3:\n            {\n                int ch3 = in.read();\n                int ch2 = in.read();\n                int ch1 = in.read();\n                return (ch1 << 16) + (ch2 << 8) + ch3;\n            }\n        case 4:\n            {\n                return readIntLittleEndian();\n            }\n    }\n    throw new RuntimeException(\"Unreachable\");\n}", "summary_tokens": ["reads", "the", "next", "byte", "width", "little", "endian", "int"], "project": "flink"}
{"id": 9424, "code": "public void append(LookupInfo<K, Iterator<RowData>> lookupInfo, BinaryRowData value)\n        throws IOException {\n    try {\n        if (lookupInfo.found) {\n                \n            int newPointer = ((RecordArea) recordArea).appendValue(value);\n            if (pointerToSecondValue == -1) {\n                    \n                ((RecordArea) recordArea).updateValuePointerInKeyArea(newPointer, endPtr);\n            } else {\n                ((RecordArea) recordArea).updateValuePointerInValueArea(newPointer, endPtr);\n            }\n                \n            endPtr = newPointer;\n            ((RecordArea) recordArea).updateValuePointerInKeyArea(newPointer, endPtrOffset);\n        } else {\n            if (numKeys >= growthThreshold) {\n                growAndRehash();\n                    \n                lookup(lookupInfo.key);\n            }\n                \n            int pointerToAppended = recordArea.appendRecord(lookupInfo, value);\n            bucketSegments\n                    .get(lookupInfo.bucketSegmentIndex)\n                    .putInt(lookupInfo.bucketOffset, pointerToAppended);\n            bucketSegments\n                    .get(lookupInfo.bucketSegmentIndex)\n                    .putInt(\n                            lookupInfo.bucketOffset + ELEMENT_POINT_LENGTH,\n                            lookupInfo.keyHashCode);\n            numKeys++;\n        }\n        numElements++;\n    } catch (EOFException e) {\n        numSpillFiles++;\n        spillInBytes += recordArea.getSegmentsSize();\n        throw e;\n    }\n}", "summary_tokens": ["append", "an", "value", "into", "the", "hash", "map", "s", "record", "area"], "project": "flink"}
{"id": 524, "code": "public KafkaSourceBuilder<OUT> setProperty(String key, String value) {\n    props.setProperty(key, value);\n    return this;\n}", "summary_tokens": ["set", "an", "arbitrary", "property", "for", "the", "kafka", "source", "and", "kafka", "consumer"], "project": "flink"}
{"id": 7525, "code": "public T getValue() {\n    return value;\n}", "summary_tokens": ["the", "value", "wrapped", "in", "this", "timestamped", "value"], "project": "flink"}
{"id": 277, "code": "public boolean add(long checkpointId, int task) {\n    Set<Integer> tasks = notifiedTasks.computeIfAbsent(checkpointId, (k) -> new HashSet<>());\n    tasks.add(task);\n    if (tasks.size() == numberOfTasks) {\n        notifiedTasks.headMap(checkpointId, true).clear();\n        return true;\n    }\n    return false;\n}", "summary_tokens": ["true", "if", "this", "checkpoint", "id", "need", "be", "committed"], "project": "flink"}
{"id": 944, "code": "public void setupTopic(String topic) {\n    Random random = new Random(System.currentTimeMillis());\n    setupTopic(topic, Schema.STRING, () -> randomAlphanumeric(10 + random.nextInt(20)));\n}", "summary_tokens": ["create", "a", "topic", "with", "default", "default", "partitions", "partitions", "and", "send", "a", "fixed", "number", "num", "records", "per", "partition", "of", "records", "to", "this", "topic"], "project": "flink"}
{"id": 46, "code": "private void runApplicationEntryPoint(\n        final CompletableFuture<List<JobID>> jobIdsFuture,\n        final Set<JobID> tolerateMissingResult,\n        final DispatcherGateway dispatcherGateway,\n        final ScheduledExecutor scheduledExecutor,\n        final boolean enforceSingleJobExecution) {\n    try {\n        final List<JobID> applicationJobIds = new ArrayList<>(recoveredJobIds);\n\n        final PipelineExecutorServiceLoader executorServiceLoader =\n                new EmbeddedExecutorServiceLoader(\n                        applicationJobIds, dispatcherGateway, scheduledExecutor);\n\n        ClientUtils.executeProgram(\n                executorServiceLoader,\n                configuration,\n                application,\n                enforceSingleJobExecution,\n                true );\n\n        if (applicationJobIds.isEmpty()) {\n            jobIdsFuture.completeExceptionally(\n                    new ApplicationExecutionException(\n                            \"The application contains no execute() calls.\"));\n        } else {\n            jobIdsFuture.complete(applicationJobIds);\n        }\n    } catch (Throwable t) {\n            \n            \n        final Optional<DuplicateJobSubmissionException> maybeDuplicate =\n                ExceptionUtils.findThrowable(t, DuplicateJobSubmissionException.class);\n        if (enforceSingleJobExecution\n                && maybeDuplicate.isPresent()\n                && maybeDuplicate.get().isGloballyTerminated()) {\n            final JobID jobId = maybeDuplicate.get().getJobID();\n            tolerateMissingResult.add(jobId);\n            jobIdsFuture.complete(Collections.singletonList(jobId));\n        } else {\n            jobIdsFuture.completeExceptionally(\n                    new ApplicationExecutionException(\"Could not execute application.\", t));\n        }\n    }\n}", "summary_tokens": ["runs", "the", "user", "program", "entrypoint", "and", "completes", "the", "given", "job", "ids", "future", "with", "the", "job", "id", "job", "ids", "of", "the", "submitted", "jobs"], "project": "flink"}
{"id": 8532, "code": "public static Optional<Class<?>> extractSimpleGeneric(\n        Class<?> baseClass, Class<?> clazz, int pos) {\n    try {\n        if (clazz.getSuperclass() != baseClass) {\n            return Optional.empty();\n        }\n        final Type t =\n                ((ParameterizedType) clazz.getGenericSuperclass())\n                        .getActualTypeArguments()[pos];\n        return Optional.ofNullable(toClass(t));\n    } catch (Exception unused) {\n        return Optional.empty();\n    }\n}", "summary_tokens": ["a", "minimal", "version", "to", "extract", "a", "generic", "parameter", "from", "a", "given", "class"], "project": "flink"}
{"id": 9404, "code": "public static long toEpochMills(long utcTimestampMills, ZoneId shiftTimeZone) {\n        \n    if (UTC_ZONE_ID.equals(shiftTimeZone) || Long.MAX_VALUE == utcTimestampMills) {\n        return utcTimestampMills;\n    }\n    LocalDateTime utcTimestamp =\n            LocalDateTime.ofInstant(Instant.ofEpochMilli(utcTimestampMills), UTC_ZONE_ID);\n    return utcTimestamp.atZone(shiftTimeZone).toInstant().toEpochMilli();\n}", "summary_tokens": ["convert", "a", "timestamp", "mills", "with", "the", "given", "timezone", "to", "epoch", "mills"], "project": "flink"}
{"id": 1406, "code": "static void writeVersionedSnapshot(DataOutputView out, TypeSerializerSnapshot<?> snapshot)\n        throws IOException {\n    out.writeUTF(snapshot.getClass().getName());\n    out.writeInt(snapshot.getCurrentVersion());\n    snapshot.writeSnapshot(out);\n}", "summary_tokens": ["writes", "the", "given", "snapshot", "to", "the", "out", "stream"], "project": "flink"}
{"id": 3380, "code": "private void setUpIteration(DeltaIteration<?, ?> iteration) {\n\n        \n    if (this.configuration != null) {\n\n        iteration.name(\n                this.configuration.getName(\n                        \"Scatter-gather iteration (\"\n                                + gatherFunction\n                                + \" | \"\n                                + scatterFunction\n                                + \")\"));\n        iteration.parallelism(this.configuration.getParallelism());\n        iteration.setSolutionSetUnManaged(this.configuration.isSolutionSetUnmanagedMemory());\n\n            \n        for (Map.Entry<String, Aggregator<?>> entry :\n                this.configuration.getAggregators().entrySet()) {\n            iteration.registerAggregator(entry.getKey(), entry.getValue());\n        }\n    } else {\n            \n        iteration.name(\n                \"Scatter-gather iteration (\" + gatherFunction + \" | \" + scatterFunction + \")\");\n    }\n}", "summary_tokens": ["helper", "method", "which", "sets", "up", "an", "iteration", "with", "the", "given", "vertex", "value", "either", "simple", "or", "with", "degrees"], "project": "flink"}
{"id": 9462, "code": "private long localMills(long epochMills) {\n    return toUtcTimestampMills(epochMills, shiftTimeZone);\n}", "summary_tokens": ["get", "the", "timestamp", "in", "mills", "by", "given", "epoch", "mills", "and", "timezone"], "project": "flink"}
{"id": 4031, "code": "protected Executor getUnfencedMainThreadExecutor() {\n    return unfencedMainThreadExecutor;\n}", "summary_tokens": ["returns", "a", "main", "thread", "executor", "which", "is", "not", "bound", "to", "the", "fencing", "token"], "project": "flink"}
{"id": 827, "code": "public void sleep(long millisToSleep) throws InterruptedException {\n    Thread.sleep(millisToSleep);\n}", "summary_tokens": ["puts", "the", "current", "thread", "to", "sleep", "for", "the", "specified", "number", "of", "millis"], "project": "flink"}
{"id": 6173, "code": "public void testReceiveEmptyBuffer() throws Exception {\n        \n    final BufferProvider bufferProvider = mock(BufferProvider.class);\n    when(bufferProvider.requestBuffer()).thenReturn(TestBufferFactory.createBuffer(0));\n\n    final RemoteInputChannel inputChannel = mock(RemoteInputChannel.class);\n    when(inputChannel.getInputChannelId()).thenReturn(new InputChannelID());\n    when(inputChannel.getBufferProvider()).thenReturn(bufferProvider);\n\n        \n    final Buffer emptyBuffer = TestBufferFactory.createBuffer(0);\n\n    final CreditBasedPartitionRequestClientHandler client =\n            new CreditBasedPartitionRequestClientHandler();\n    client.addInputChannel(inputChannel);\n\n    final int backlog = 2;\n    final BufferResponse receivedBuffer =\n            createBufferResponse(\n                    emptyBuffer,\n                    0,\n                    inputChannel.getInputChannelId(),\n                    backlog,\n                    new NetworkBufferAllocator(client));\n\n        \n    client.channelRead(mock(ChannelHandlerContext.class), receivedBuffer);\n\n        \n    verify(inputChannel, never()).onError(any(Throwable.class));\n    verify(inputChannel, times(1)).onEmptyBuffer(0, backlog);\n}", "summary_tokens": ["tests", "a", "fix", "for", "flink", "0"], "project": "flink"}
{"id": 95, "code": "public void testNotShowSuspendedJobStatus() throws Exception {\n    final List<JobDetailsInfo> jobDetails = new ArrayList<>();\n    jobDetails.add(buildJobDetail(JobStatus.SUSPENDED));\n    jobDetails.add(buildJobDetail(JobStatus.RUNNING));\n    final TestJobStatusHandler jobStatusHandler =\n            new TestJobStatusHandler(jobDetails.iterator());\n\n    try (TestRestServerEndpoint restServerEndpoint =\n            createRestServerEndpoint(jobStatusHandler)) {\n        final RestClusterClient<?> restClusterClient =\n                createRestClusterClient(restServerEndpoint.getServerAddress().getPort());\n        try {\n            final CompletableFuture<JobStatus> future = restClusterClient.getJobStatus(jobId);\n            assertEquals(JobStatus.RUNNING, future.get());\n        } finally {\n            restClusterClient.close();\n        }\n    }\n}", "summary_tokens": ["the", "suspended", "job", "status", "should", "never", "be", "returned", "by", "the", "client", "thus", "client", "retries", "until", "it", "either", "receives", "a", "different", "job", "status", "or", "the", "cluster", "is", "not", "reachable"], "project": "flink"}
{"id": 5925, "code": "public void testAddAndGetLatestCheckpoint() throws Exception {\n    SharedStateRegistry sharedStateRegistry = new SharedStateRegistryImpl();\n    CompletedCheckpointStore checkpoints = createRecoveredCompletedCheckpointStore(4);\n\n        \n    assertEquals(0, checkpoints.getNumberOfRetainedCheckpoints());\n    assertEquals(0, checkpoints.getAllCheckpoints().size());\n\n    TestCompletedCheckpoint[] expected =\n            new TestCompletedCheckpoint[] {\n                createCheckpoint(0, sharedStateRegistry),\n                createCheckpoint(1, sharedStateRegistry)\n            };\n\n        \n    checkpoints.addCheckpointAndSubsumeOldestOne(\n            expected[0], new CheckpointsCleaner(), () -> {});\n    assertEquals(1, checkpoints.getNumberOfRetainedCheckpoints());\n    verifyCheckpoint(expected[0], checkpoints.getLatestCheckpoint());\n\n    checkpoints.addCheckpointAndSubsumeOldestOne(\n            expected[1], new CheckpointsCleaner(), () -> {});\n    assertEquals(2, checkpoints.getNumberOfRetainedCheckpoints());\n    verifyCheckpoint(expected[1], checkpoints.getLatestCheckpoint());\n}", "summary_tokens": ["tests", "adding", "and", "getting", "a", "checkpoint"], "project": "flink"}
{"id": 4772, "code": "public List<PermanentBlobKey> getUserJarBlobKeys() {\n    return this.userJarBlobKeys;\n}", "summary_tokens": ["returns", "a", "set", "of", "blob", "keys", "referring", "to", "the", "jar", "files", "required", "to", "run", "this", "job"], "project": "flink"}
{"id": 3527, "code": "static LogicalScopeProvider castFrom(MetricGroup metricGroup) throws IllegalStateException {\n    if (metricGroup instanceof LogicalScopeProvider) {\n        return (LogicalScopeProvider) metricGroup;\n    } else {\n        throw new IllegalStateException(\n                \"The given metric group does not implement the LogicalScopeProvider interface.\");\n    }\n}", "summary_tokens": ["casts", "the", "given", "metric", "group", "to", "a", "logical", "scope", "provider", "if", "it", "implements", "the", "interface"], "project": "flink"}
{"id": 3074, "code": "public Pattern<T, F> or(IterativeCondition<F> condition) {\n    Preconditions.checkNotNull(condition, \"The condition cannot be null.\");\n\n    ClosureCleaner.clean(condition, ExecutionConfig.ClosureCleanerLevel.RECURSIVE, true);\n\n    if (this.condition == null) {\n        this.condition = condition;\n    } else {\n        this.condition = new RichOrCondition<>(this.condition, condition);\n    }\n    return this;\n}", "summary_tokens": ["adds", "a", "condition", "that", "has", "to", "be", "satisfied", "by", "an", "event", "in", "order", "to", "be", "considered", "a", "match"], "project": "flink"}
{"id": 3548, "code": "public void testDropwizardHistogramWrapper() {\n    int size = 10;\n    DropwizardHistogramWrapper histogramWrapper =\n            new DropwizardHistogramWrapper(\n                    new com.codahale.metrics.Histogram(new SlidingWindowReservoir(size)));\n    testHistogram(size, histogramWrapper);\n}", "summary_tokens": ["tests", "the", "histogram", "functionality", "of", "the", "dropwizard", "histogram", "wrapper"], "project": "flink"}
{"id": 9081, "code": "private SerializationRuntimeConverter createNotNullConverter(\n        LogicalType type, String charsetName, boolean isBigEndian) {\n    switch (type.getTypeRoot()) {\n        case CHAR:\n        case VARCHAR:\n            return createStringConverter(charsetName);\n\n        case VARBINARY:\n        case BINARY:\n            return row -> row.getBinary(0);\n\n        case RAW:\n            return createRawValueConverter((RawType<?>) type);\n\n        case BOOLEAN:\n            return row -> {\n                byte b = (byte) (row.getBoolean(0) ? 1 : 0);\n                return new byte[] {b};\n            };\n\n        case TINYINT:\n            return row -> new byte[] {row.getByte(0)};\n\n        case SMALLINT:\n            return new ShortSerializationConverter(isBigEndian);\n\n        case INTEGER:\n            return new IntegerSerializationConverter(isBigEndian);\n\n        case BIGINT:\n            return new LongSerializationConverter(isBigEndian);\n\n        case FLOAT:\n            return new FloatSerializationConverter(isBigEndian);\n\n        case DOUBLE:\n            return new DoubleSerializationConverter(isBigEndian);\n\n        default:\n            throw new UnsupportedOperationException(\n                    \"'raw' format currently doesn't support type: \" + type);\n    }\n}", "summary_tokens": ["creates", "a", "runtime", "converter"], "project": "flink"}
{"id": 7846, "code": "public void testWaitingForUnalignedChannelStatesIfFinishedOnRestore() throws Exception {\n    OperatorID operatorId = new OperatorID();\n    try (StreamTaskMailboxTestHarness<String> harness =\n            new StreamTaskMailboxTestHarnessBuilder<>(\n                            OneInputStreamTask::new, BasicTypeInfo.STRING_TYPE_INFO)\n                    .modifyStreamConfig(\n                            streamConfig -> streamConfig.setUnalignedCheckpointsEnabled(true))\n                    .addInput(BasicTypeInfo.STRING_TYPE_INFO, 3)\n                    .setCollectNetworkEvents()\n                    .setTaskStateSnapshot(1, TaskStateSnapshot.FINISHED_ON_RESTORE)\n                    .setupOperatorChain(new TestFinishedOnRestoreStreamOperator())\n                    .chain(\n                            operatorId,\n                            new TestFinishedOnRestoreStreamOperator(operatorId),\n                            StringSerializer.INSTANCE)\n                    .finish()\n                    .build()) {\n            \n        harness.processAll();\n\n        TestCheckpointResponder checkpointResponder = harness.getCheckpointResponder();\n        checkpointResponder.setAcknowledgeLatch(new OneShotLatch());\n        checkpointResponder.setDeclinedLatch(new OneShotLatch());\n\n        CheckpointBarrier unalignedBarrier =\n                new CheckpointBarrier(\n                        2,\n                        2,\n                        CheckpointOptions.unaligned(CheckpointType.CHECKPOINT, getDefault()));\n\n            \n            \n            \n        harness.processEvent(unalignedBarrier, 0, 0);\n        Thread.sleep(CONCURRENT_EVENT_WAIT_PERIOD_MS);\n\n            \n        harness.processEvent(unalignedBarrier, 0, 1);\n        harness.processEvent(unalignedBarrier, 0, 2);\n\n            \n        CommonTestUtils.waitUntilCondition(\n                () ->\n                        checkpointResponder.getAcknowledgeLatch().isTriggered()\n                                || checkpointResponder.getDeclinedLatch().isTriggered(),\n                Deadline.fromNow(Duration.ofSeconds(10)));\n\n        assertEquals(\n                Collections.singletonList(2L),\n                checkpointResponder.getAcknowledgeReports().stream()\n                        .map(TestCheckpointResponder.AbstractReport::getCheckpointId)\n                        .collect(Collectors.toList()));\n        assertEquals(\n                Collections.emptyList(),\n                checkpointResponder.getDeclineReports().stream()\n                        .map(TestCheckpointResponder.AbstractReport::getCheckpointId)\n                        .collect(Collectors.toList()));\n    }\n}", "summary_tokens": ["this", "test", "verifies", "for", "tasks", "that", "finished", "on", "restore", "when", "taking", "unaligned", "checkpoint", "the", "asynchronous", "part", "would", "wait", "for", "the", "channel", "states", "futures", "get", "completed", "which", "means", "the", "barriers", "are", "aligned"], "project": "flink"}
{"id": 5292, "code": "public JobGraph copyJobGraph() throws IOException, ClassNotFoundException {\n    return InstantiationUtil.clone(jobGraph);\n}", "summary_tokens": ["returns", "a", "copy", "of", "a", "job", "graph", "that", "can", "be", "mutated"], "project": "flink"}
{"id": 5424, "code": "public static <T> StateSerializerProvider<T> fromPreviousSerializerSnapshot(\n        TypeSerializerSnapshot<T> stateSerializerSnapshot) {\n    return new LazilyRegisteredStateSerializerProvider<>(stateSerializerSnapshot);\n}", "summary_tokens": ["creates", "a", "state", "serializer", "provider", "for", "restored", "state", "from", "the", "previous", "serializer", "s", "snapshot"], "project": "flink"}
{"id": 4433, "code": "public long getRestartDelayMS() {\n    if (canRestart()) {\n        return restartDelayMS;\n    } else {\n        throw new IllegalStateException(\n                \"Cannot get restart delay when the restarting is suppressed.\");\n    }\n}", "summary_tokens": ["returns", "the", "delay", "before", "the", "restarting"], "project": "flink"}
{"id": 7675, "code": "public void testCancelAndCleanup() throws Exception {\n    OperatorSnapshotFutures operatorSnapshotResult = new OperatorSnapshotFutures();\n\n    operatorSnapshotResult.cancel();\n\n    KeyedStateHandle keyedManagedStateHandle = mock(KeyedStateHandle.class);\n    SnapshotResult<KeyedStateHandle> keyedStateManagedResult =\n            SnapshotResult.of(keyedManagedStateHandle);\n    RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateManagedFuture =\n            spy(DoneFuture.of(keyedStateManagedResult));\n\n    KeyedStateHandle keyedRawStateHandle = mock(KeyedStateHandle.class);\n    SnapshotResult<KeyedStateHandle> keyedStateRawResult =\n            SnapshotResult.of(keyedRawStateHandle);\n    RunnableFuture<SnapshotResult<KeyedStateHandle>> keyedStateRawFuture =\n            spy(DoneFuture.of(keyedStateRawResult));\n\n    OperatorStateHandle operatorManagedStateHandle = mock(OperatorStreamStateHandle.class);\n    SnapshotResult<OperatorStateHandle> operatorStateManagedResult =\n            SnapshotResult.of(operatorManagedStateHandle);\n    RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateManagedFuture =\n            spy(DoneFuture.of(operatorStateManagedResult));\n\n    OperatorStateHandle operatorRawStateHandle = mock(OperatorStreamStateHandle.class);\n    SnapshotResult<OperatorStateHandle> operatorStateRawResult =\n            SnapshotResult.of(operatorRawStateHandle);\n    RunnableFuture<SnapshotResult<OperatorStateHandle>> operatorStateRawFuture =\n            spy(DoneFuture.of(operatorStateRawResult));\n\n    InputChannelStateHandle inputChannelRawStateHandle = mock(InputChannelStateHandle.class);\n    SnapshotResult<StateObjectCollection<InputChannelStateHandle>> inputChannelStateRawResult =\n            SnapshotResult.of(StateObjectCollection.singleton(inputChannelRawStateHandle));\n    Future<SnapshotResult<StateObjectCollection<InputChannelStateHandle>>>\n            inputChannelStateRawFuture = spy(DoneFuture.of(inputChannelStateRawResult));\n\n    ResultSubpartitionStateHandle resultSubpartitionRawStateHandle =\n            mock(ResultSubpartitionStateHandle.class);\n    SnapshotResult<StateObjectCollection<ResultSubpartitionStateHandle>>\n            resultSubpartitionStateRawResult =\n                    SnapshotResult.of(\n                            StateObjectCollection.singleton(resultSubpartitionRawStateHandle));\n    Future<SnapshotResult<StateObjectCollection<ResultSubpartitionStateHandle>>>\n            resultSubpartitionStateRawFuture =\n                    spy(DoneFuture.of(resultSubpartitionStateRawResult));\n\n    operatorSnapshotResult =\n            new OperatorSnapshotFutures(\n                    keyedStateManagedFuture,\n                    keyedStateRawFuture,\n                    operatorStateManagedFuture,\n                    operatorStateRawFuture,\n                    inputChannelStateRawFuture,\n                    resultSubpartitionStateRawFuture);\n\n    operatorSnapshotResult.cancel();\n\n    verify(keyedStateManagedFuture).cancel(true);\n    verify(keyedStateRawFuture).cancel(true);\n    verify(operatorStateManagedFuture).cancel(true);\n    verify(operatorStateRawFuture).cancel(true);\n    verify(inputChannelStateRawFuture).cancel(true);\n    verify(resultSubpartitionStateRawFuture).cancel(true);\n\n    verify(keyedManagedStateHandle).discardState();\n    verify(keyedRawStateHandle).discardState();\n    verify(operatorManagedStateHandle).discardState();\n    verify(operatorRawStateHandle).discardState();\n    verify(inputChannelRawStateHandle).discardState();\n    verify(resultSubpartitionRawStateHandle).discardState();\n}", "summary_tokens": ["tests", "that", "all", "runnable", "futures", "in", "an", "operator", "snapshot", "result", "are", "properly", "cancelled", "and", "if", "the", "stream", "state", "handle", "result", "is", "retrievable", "that", "the", "state", "handle", "are", "discarded"], "project": "flink"}
{"id": 202, "code": "default void add(ActionRequest... actionRequests) {\n    for (ActionRequest actionRequest : actionRequests) {\n        if (actionRequest instanceof IndexRequest) {\n            add((IndexRequest) actionRequest);\n        } else if (actionRequest instanceof DeleteRequest) {\n            add((DeleteRequest) actionRequest);\n        } else if (actionRequest instanceof UpdateRequest) {\n            add((UpdateRequest) actionRequest);\n        } else {\n            throw new IllegalArgumentException(\n                    \"RequestIndexer only supports Index, Delete and Update requests\");\n        }\n    }\n}", "summary_tokens": ["add", "multiple", "action", "request", "to", "the", "indexer", "to", "prepare", "for", "sending", "requests", "to", "elasticsearch"], "project": "flink"}
{"id": 8081, "code": "public boolean dropTemporaryCatalogFunction(\n        UnresolvedIdentifier unresolvedIdentifier, boolean ignoreIfNotExist) {\n    final ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n    return dropTempCatalogFunction(identifier, ignoreIfNotExist) != null;\n}", "summary_tokens": ["drops", "a", "temporary", "catalog", "function"], "project": "flink"}
{"id": 6944, "code": "public boolean isEnabled() {\n    return !properties.isEmpty();\n}", "summary_tokens": ["rocks", "dbnative", "metric", "monitor", "is", "enabled", "is", "any", "property", "is", "set"], "project": "flink"}
{"id": 1925, "code": "protected final Object getSynchronizationLock() {\n    return lock;\n}", "summary_tokens": ["returns", "the", "lock", "on", "which", "manipulations", "to", "members", "closeable", "to", "ref", "and", "closeable", "must", "be", "synchronized"], "project": "flink"}
{"id": 9647, "code": "private DataStream<Long> createProgramWithMultipleUnionInputs() {\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(PARALLELISM);\n    env.getConfig().enableObjectReuse();\n\n    final DataStream<Long> source1 =\n            env.fromSource(\n                    new NumberSequenceSource(1L, 10L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-1\");\n\n    final DataStream<Long> source2 =\n            env.fromSource(\n                    new NumberSequenceSource(11L, 20L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-2\");\n\n    final DataStream<Long> source3 =\n            env.fromSource(\n                    new NumberSequenceSource(21L, 30L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-3\");\n\n    final DataStream<Long> source4 =\n            env.fromSource(\n                    new NumberSequenceSource(31L, 40L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-4\");\n\n    final DataStream<Long> source5 =\n            env.fromSource(\n                    new NumberSequenceSource(41L, 50L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-5\");\n\n    final DataStream<Long> source6 =\n            env.fromSource(\n                    new NumberSequenceSource(51L, 60L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-6\");\n\n    return nAryInputStreamOperation(\n            source1.map((v) -> v),\n            source2.union(source3),\n            source4.map((v) -> v).union(source5.map((v) -> v)),\n            source6);\n}", "summary_tokens": ["creates", "a", "data", "stream", "program", "as", "shown", "below"], "project": "flink"}
{"id": 6282, "code": "public void testReconnectionAfterDisconnect() throws Exception {\n    final JobMaster jobMaster =\n            new JobMasterBuilder(jobGraph, rpcService)\n                    .withJobMasterId(jobMasterId)\n                    .withConfiguration(configuration)\n                    .withHighAvailabilityServices(haServices)\n                    .withHeartbeatServices(heartbeatServices)\n                    .createJobMaster();\n\n    jobMaster.start();\n\n    final JobMasterGateway jobMasterGateway = jobMaster.getSelfGateway(JobMasterGateway.class);\n\n    try {\n        final TestingResourceManagerGateway testingResourceManagerGateway =\n                createAndRegisterTestingResourceManagerGateway();\n        final BlockingQueue<JobMasterId> registrationsQueue = new ArrayBlockingQueue<>(1);\n\n        testingResourceManagerGateway.setRegisterJobManagerFunction(\n                (jobMasterId, resourceID, s, jobID) -> {\n                    registrationsQueue.offer(jobMasterId);\n                    return CompletableFuture.completedFuture(\n                            testingResourceManagerGateway.getJobMasterRegistrationSuccess());\n                });\n\n        final ResourceManagerId resourceManagerId =\n                testingResourceManagerGateway.getFencingToken();\n        notifyResourceManagerLeaderListeners(testingResourceManagerGateway);\n\n            \n        final JobMasterId firstRegistrationAttempt = registrationsQueue.take();\n\n        assertThat(firstRegistrationAttempt, equalTo(jobMasterId));\n\n        assertThat(registrationsQueue.isEmpty(), is(true));\n        jobMasterGateway.disconnectResourceManager(\n                resourceManagerId, new FlinkException(\"Test exception\"));\n\n            \n        assertThat(registrationsQueue.take(), equalTo(jobMasterId));\n    } finally {\n        RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout);\n    }\n}", "summary_tokens": ["tests", "that", "we", "continue", "reconnecting", "to", "the", "latest", "known", "rm", "after", "a", "disconnection", "message"], "project": "flink"}
{"id": 282, "code": "public static void checkIntegerSequenceSinkOutput(\n        String path, int numRecords, int numBuckets, int numSources) throws Exception {\n    File dir = new File(path);\n    String[] subDirNames = dir.list();\n    assertNotNull(subDirNames);\n\n    Arrays.sort(subDirNames, Comparator.comparingInt(Integer::parseInt));\n    assertEquals(numBuckets, subDirNames.length);\n    for (int i = 0; i < numBuckets; ++i) {\n        assertEquals(Integer.toString(i), subDirNames[i]);\n\n            \n        File bucketDir = new File(path, subDirNames[i]);\n        assertTrue(\n                bucketDir.getAbsolutePath() + \" Should be a existing directory\",\n                bucketDir.isDirectory());\n\n        Map<Integer, Integer> counts = new HashMap<>();\n        File[] files = bucketDir.listFiles(f -> !f.getName().startsWith(\".\"));\n        assertNotNull(files);\n\n        for (File file : files) {\n            assertTrue(file.isFile());\n\n            try (DataInputStream dataInputStream =\n                    new DataInputStream(new FileInputStream(file))) {\n                while (true) {\n                    int value = dataInputStream.readInt();\n                    counts.compute(value, (k, v) -> v == null ? 1 : v + 1);\n                }\n            } catch (EOFException e) {\n                    \n            }\n        }\n\n        int expectedCount = numRecords / numBuckets + (i < numRecords % numBuckets ? 1 : 0);\n        assertEquals(expectedCount, counts.size());\n\n        for (int j = i; j < numRecords; j += numBuckets) {\n            assertEquals(\n                    \"The record \"\n                            + j\n                            + \" should occur \"\n                            + numSources\n                            + \" times, \"\n                            + \" but only occurs \"\n                            + counts.getOrDefault(j, 0)\n                            + \"time\",\n                    numSources,\n                    counts.getOrDefault(j, 0).intValue());\n        }\n    }\n}", "summary_tokens": ["verifies", "the", "files", "written", "by", "the", "sink", "contains", "the", "expected", "integer", "sequences"], "project": "flink"}
{"id": 2453, "code": "public void testForSpecific_withValidParams_succeeds() {\n    assertThat(\n            GlueSchemaRegistryAvroDeserializationSchema.forSpecific(User.class, configs),\n            notNullValue());\n    assertThat(\n            GlueSchemaRegistryAvroDeserializationSchema.forSpecific(User.class, configs),\n            instanceOf(GlueSchemaRegistryAvroDeserializationSchema.class));\n}", "summary_tokens": ["test", "whether", "for", "specific", "method", "works"], "project": "flink"}
{"id": 4702, "code": "public void checkpointStarted(CheckpointBarrier barrier) throws CheckpointException {\n    synchronized (receivedBuffers) {\n        if (barrier.getId() < lastBarrierId) {\n            throw new CheckpointException(\n                    String.format(\n                            \"Sequence number for checkpoint %d is not known (it was likely been overwritten by a newer checkpoint %d)\",\n                            barrier.getId(), lastBarrierId),\n                    CheckpointFailureReason\n                            .CHECKPOINT_SUBSUMED); \n                \n        } else if (barrier.getId() > lastBarrierId) {\n                \n                \n                \n                \n            resetLastBarrier();\n        }\n\n        channelStatePersister.startPersisting(\n                barrier.getId(), getInflightBuffersUnsafe(barrier.getId()));\n    }\n}", "summary_tokens": ["spills", "all", "queued", "buffers", "on", "checkpoint", "start"], "project": "flink"}
{"id": 8716, "code": "public <T> T getValueAs(Class<T> clazz) {\n    if (value == null || clazz.isInstance(value)) {\n        return clazz.cast(value);\n    }\n    switch (typeName) {\n        case BINARY:\n            if (clazz == byte[].class) {\n                return clazz.cast(((ByteString) value).getBytes());\n            }\n            break;\n        case CHAR:\n            if (clazz == String.class) {\n                return clazz.cast(((NlsString) value).getValue());\n            } else if (clazz == Character.class) {\n                return clazz.cast(((NlsString) value).getValue().charAt(0));\n            }\n            break;\n        case VARCHAR:\n            if (clazz == String.class) {\n                return clazz.cast(((NlsString) value).getValue());\n            }\n            break;\n        case DECIMAL:\n            if (clazz == Long.class) {\n                return clazz.cast(((BigDecimal) value).unscaledValue().longValue());\n            }\n                \n        case BIGINT:\n        case INTEGER:\n        case SMALLINT:\n        case TINYINT:\n        case DOUBLE:\n        case REAL:\n        case FLOAT:\n            if (clazz == Long.class) {\n                return clazz.cast(((BigDecimal) value).longValue());\n            } else if (clazz == Integer.class) {\n                return clazz.cast(((BigDecimal) value).intValue());\n            } else if (clazz == Short.class) {\n                return clazz.cast(((BigDecimal) value).shortValue());\n            } else if (clazz == Byte.class) {\n                return clazz.cast(((BigDecimal) value).byteValue());\n            } else if (clazz == Double.class) {\n                return clazz.cast(((BigDecimal) value).doubleValue());\n            } else if (clazz == Float.class) {\n                return clazz.cast(((BigDecimal) value).floatValue());\n            }\n            break;\n        case DATE:\n            if (clazz == Integer.class) {\n                return clazz.cast(((DateString) value).getDaysSinceEpoch());\n            } else if (clazz == Calendar.class) {\n                return clazz.cast(((DateString) value).toCalendar());\n            }\n            break;\n        case TIME:\n            if (clazz == Integer.class) {\n                return clazz.cast(((TimeString) value).getMillisOfDay());\n            } else if (clazz == Calendar.class) {\n                    \n                return clazz.cast(((TimeString) value).toCalendar());\n            }\n            break;\n        case TIME_WITH_LOCAL_TIME_ZONE:\n            if (clazz == Integer.class) {\n                    \n                return clazz.cast(((TimeString) value).getMillisOfDay());\n            }\n            break;\n        case TIMESTAMP:\n            if (clazz == Long.class) {\n                    \n                return clazz.cast(((TimestampString) value).getMillisSinceEpoch());\n            } else if (clazz == Calendar.class) {\n                    \n                return clazz.cast(((TimestampString) value).toCalendar());\n            }\n            break;\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            if (clazz == Long.class) {\n                    \n                return clazz.cast(((TimestampString) value).getMillisSinceEpoch());\n            } else if (clazz == Calendar.class) {\n                    \n                return clazz.cast(((TimestampString) value).toCalendar());\n            }\n            break;\n        case INTERVAL_YEAR:\n        case INTERVAL_YEAR_MONTH:\n        case INTERVAL_MONTH:\n        case INTERVAL_DAY:\n        case INTERVAL_DAY_HOUR:\n        case INTERVAL_DAY_MINUTE:\n        case INTERVAL_DAY_SECOND:\n        case INTERVAL_HOUR:\n        case INTERVAL_HOUR_MINUTE:\n        case INTERVAL_HOUR_SECOND:\n        case INTERVAL_MINUTE:\n        case INTERVAL_MINUTE_SECOND:\n        case INTERVAL_SECOND:\n            if (clazz == Integer.class) {\n                return clazz.cast(((BigDecimal) value).intValue());\n            } else if (clazz == Long.class) {\n                return clazz.cast(((BigDecimal) value).longValue());\n            } else if (clazz == String.class) {\n                return clazz.cast(intervalString(getValueAs(BigDecimal.class).abs()));\n            } else if (clazz == Boolean.class) {\n                    \n                return clazz.cast(getValueAs(BigDecimal.class).signum() < 0);\n            }\n            break;\n    }\n    throw new AssertionError(\"cannot convert \" + typeName + \" literal to \" + clazz);\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "literal", "as", "an", "instance", "of", "the", "specified", "class"], "project": "flink"}
{"id": 4452, "code": "public static String generateExternalResourcesString(\n        Collection<ExternalResource> extendedResources) {\n    return extendedResources.stream()\n            .map(resource -> resource.getName() + \"=\" + resource.getValue())\n            .collect(Collectors.joining(\", \"));\n}", "summary_tokens": ["generate", "the", "string", "expression", "of", "the", "given", "external", "resources"], "project": "flink"}
{"id": 1255, "code": "public Ordering appendOrdering(\n        Integer index, Class<? extends Comparable<?>> type, Order order) {\n    if (index < 0) {\n        throw new IllegalArgumentException(\"The key index must not be negative.\");\n    }\n    if (order == null) {\n        throw new NullPointerException();\n    }\n    if (order == Order.NONE) {\n        throw new IllegalArgumentException(\n                \"An ordering must not be created with a NONE order.\");\n    }\n\n    if (!this.indexes.contains(index)) {\n        this.indexes = this.indexes.addField(index);\n        this.types.add(type);\n        this.orders.add(order);\n    }\n\n    return this;\n}", "summary_tokens": ["extends", "this", "ordering", "by", "appending", "an", "additional", "order", "requirement"], "project": "flink"}
{"id": 1567, "code": "public static RowTypeInfo projectFields(RowTypeInfo rowType, int[] fieldMapping) {\n    TypeInformation[] fieldTypes = new TypeInformation[fieldMapping.length];\n    String[] fieldNames = new String[fieldMapping.length];\n    for (int i = 0; i < fieldMapping.length; i++) {\n        fieldTypes[i] = rowType.getTypeAt(fieldMapping[i]);\n        fieldNames[i] = rowType.getFieldNames()[fieldMapping[i]];\n    }\n    return new RowTypeInfo(fieldTypes, fieldNames);\n}", "summary_tokens": ["creates", "a", "row", "type", "info", "with", "projected", "fields"], "project": "flink"}
{"id": 8079, "code": "public boolean dropTemporarySystemFunction(String name, boolean ignoreIfNotExist) {\n    final String normalizedName = FunctionIdentifier.normalizeName(name);\n    final CatalogFunction function = tempSystemFunctions.remove(normalizedName);\n\n    if (function == null && !ignoreIfNotExist) {\n        throw new ValidationException(\n                String.format(\n                        \"Could not drop temporary system function. A function named '%s' doesn't exist.\",\n                        name));\n    }\n\n    return function != null;\n}", "summary_tokens": ["drops", "a", "temporary", "system", "function"], "project": "flink"}
{"id": 4805, "code": "public Throwable getInitializationFailure() {\n    Preconditions.checkState(isInitializationFailure());\n    return failure;\n}", "summary_tokens": ["this", "method", "returns", "the", "initialization", "failure"], "project": "flink"}
{"id": 4008, "code": "public void testOnStopExecutedByMainThread() throws Exception {\n    SimpleRpcEndpoint simpleRpcEndpoint =\n            new SimpleRpcEndpoint(akkaRpcService, \"SimpleRpcEndpoint\");\n    simpleRpcEndpoint.start();\n\n    CompletableFuture<Void> terminationFuture = simpleRpcEndpoint.closeAsync();\n\n        \n        \n    terminationFuture.get();\n}", "summary_tokens": ["checks", "that", "the", "on", "stop", "callback", "is", "executed", "within", "the", "main", "thread"], "project": "flink"}
{"id": 8588, "code": "public static TableException createUnexpectedException(\n        CallContext callContext, Throwable cause) {\n    return new TableException(\n            String.format(\n                    \"Unexpected error in type inference logic of function '%s'. This is a bug.\",\n                    callContext.getName()),\n            cause);\n}", "summary_tokens": ["returns", "an", "exception", "for", "an", "unexpected", "error", "during", "type", "inference"], "project": "flink"}
{"id": 9053, "code": "public void testGroupWindowAggregate() {\n    createSourceWithTimeAttribute();\n    verifyQuery(\n            \"SELECT\\n\"\n                    + \"  b,\\n\"\n                    + \"  TUMBLE_END(rowtime, INTERVAL '15' MINUTE) as window_end,\\n\"\n                    + \"  COUNT(*)\\n\"\n                    + \"FROM MyTable\\n\"\n                    + \"GROUP BY b, TUMBLE(rowtime, INTERVAL '15' MINUTE)\");\n}", "summary_tokens": ["verify", "group", "window", "aggregate"], "project": "flink"}
{"id": 1416, "code": "public int getSubtaskId() {\n    return subtaskId;\n}", "summary_tokens": ["the", "id", "of", "the", "subtask", "that", "runs", "the", "source", "reader"], "project": "flink"}
{"id": 1282, "code": "public void setGroupOrderForInputTwo(Ordering order) {\n    setGroupOrder(1, order);\n}", "summary_tokens": ["sets", "the", "order", "of", "the", "elements", "within", "a", "group", "for", "the", "second", "input"], "project": "flink"}
{"id": 6300, "code": "public void testPendingBatchSlotRequestTimeoutAfterSlotRelease() throws Exception {\n    final ManualClock clock = new ManualClock();\n    final Time batchSlotTimeout = Time.milliseconds(10000L);\n\n    try (final DeclarativeSlotPoolBridge slotPool =\n            createAndSetUpSlotPool(mainThreadExecutor, null, batchSlotTimeout, clock)) {\n\n        SlotPoolUtils.requestNewAllocatedBatchSlot(\n                slotPool, mainThreadExecutor, resourceProfile);\n\n        final ResourceID taskManagerResourceId =\n                SlotPoolUtils.offerSlots(\n                        slotPool, mainThreadExecutor, Arrays.asList(resourceProfile));\n\n        final CompletableFuture<PhysicalSlot> firstPendingSlotFuture =\n                SlotPoolUtils.requestNewAllocatedBatchSlot(\n                        slotPool, mainThreadExecutor, ResourceProfile.UNKNOWN);\n        final CompletableFuture<PhysicalSlot> secondPendingSlotFuture =\n                SlotPoolUtils.requestNewAllocatedBatchSlot(\n                        slotPool, mainThreadExecutor, resourceProfile);\n\n        final List<CompletableFuture<PhysicalSlot>> slotFutures =\n                Arrays.asList(firstPendingSlotFuture, secondPendingSlotFuture);\n\n            \n        advanceTimeAndTriggerCheckBatchSlotTimeout(\n                slotPool, mainThreadExecutor, clock, batchSlotTimeout);\n\n        assertThat(\n                CompletableFuture.anyOf(slotFutures.toArray(COMPLETABLE_FUTURES_EMPTY_ARRAY))\n                        .isDone(),\n                is(false));\n\n        SlotPoolUtils.releaseTaskManager(slotPool, mainThreadExecutor, taskManagerResourceId);\n\n        advanceTimeAndTriggerCheckBatchSlotTimeout(\n                slotPool, mainThreadExecutor, clock, batchSlotTimeout);\n\n        for (CompletableFuture<PhysicalSlot> slotFuture : slotFutures) {\n            assertThat(slotFuture.isCompletedExceptionally(), is(true));\n\n            try {\n                slotFuture.get();\n                fail(\"Expected that the slot future times out.\");\n            } catch (ExecutionException ee) {\n                assertThat(ee, FlinkMatchers.containsCause(TimeoutException.class));\n            }\n        }\n    }\n}", "summary_tokens": ["tests", "that", "a", "pending", "batch", "slot", "request", "times", "out", "after", "the", "last", "fulfilling", "slot", "gets", "released"], "project": "flink"}
{"id": 4187, "code": "private Optional<CheckpointTriggerRequest> chooseRequestToExecute(\n        boolean isTriggering, long lastCompletionMs) {\n    if (isTriggering\n            || queuedRequests.isEmpty()\n            || numberOfCleaningCheckpointsSupplier.getAsInt()\n                    > maxConcurrentCheckpointAttempts) {\n        return Optional.empty();\n    }\n    if (pendingCheckpointsSizeSupplier.getAsInt() >= maxConcurrentCheckpointAttempts) {\n        return Optional.of(queuedRequests.first())\n                .filter(CheckpointTriggerRequest::isForce)\n                .map(unused -> queuedRequests.pollFirst());\n    }\n\n    CheckpointTriggerRequest first = queuedRequests.first();\n    if (!first.isForce() && first.isPeriodic) {\n        long nextTriggerDelayMillis = nextTriggerDelayMillis(lastCompletionMs);\n        if (nextTriggerDelayMillis > 0) {\n            queuedRequests\n                    .pollFirst()\n                    .completeExceptionally(\n                            new CheckpointException(MINIMUM_TIME_BETWEEN_CHECKPOINTS));\n            rescheduleTrigger.accept(nextTriggerDelayMillis);\n            return Optional.empty();\n        }\n    }\n\n    return Optional.of(queuedRequests.pollFirst());\n}", "summary_tokens": ["choose", "the", "next", "checkpoint", "trigger", "request", "request", "to", "execute", "based", "on", "the", "provided", "candidate", "and", "the", "current", "state"], "project": "flink"}
{"id": 825, "code": "protected AmazonKinesis createKinesisClient(Properties configProps) {\n    ClientConfiguration awsClientConfig = new ClientConfigurationFactory().getConfig();\n    setAwsClientConfigProperties(awsClientConfig, configProps);\n\n    AWSCredentialsProvider credentials = getCredentialsProvider(configProps);\n    awsClientConfig.setUserAgentPrefix(\n            String.format(\n                    USER_AGENT_FORMAT,\n                    EnvironmentInformation.getVersion(),\n                    EnvironmentInformation.getRevisionInformation().commitId));\n\n    AmazonDynamoDBStreamsAdapterClient adapterClient =\n            new AmazonDynamoDBStreamsAdapterClient(credentials, awsClientConfig);\n\n    if (configProps.containsKey(AWS_ENDPOINT)) {\n        adapterClient.setEndpoint(configProps.getProperty(AWS_ENDPOINT));\n    } else {\n        adapterClient.setRegion(\n                Region.getRegion(Regions.fromName(configProps.getProperty(AWS_REGION))));\n    }\n\n    return adapterClient;\n}", "summary_tokens": ["creates", "an", "amazon", "dynamo", "dbstreams", "adapter", "client"], "project": "flink"}
{"id": 3650, "code": "public void setRangePartitioned(Ordering ordering, DataDistribution distribution) {\n    if (ordering == null) {\n        throw new NullPointerException();\n    }\n\n    this.partitioning = PartitioningProperty.RANGE_PARTITIONED;\n    this.ordering = ordering;\n    this.partitioningFields = ordering.getInvolvedIndexes();\n    this.distribution = distribution;\n}", "summary_tokens": ["set", "the", "parameters", "for", "range", "partition"], "project": "flink"}
{"id": 4660, "code": "void onConsumedSubpartition(int subpartitionIndex) {\n\n    if (isReleased.get()) {\n        return;\n    }\n\n    LOG.debug(\n            \"{}: Received release notification for subpartition {}.\", this, subpartitionIndex);\n}", "summary_tokens": ["notification", "when", "a", "subpartition", "is", "released"], "project": "flink"}
{"id": 5418, "code": "default boolean supportsNoClaimRestoreMode() {\n    return false;\n}", "summary_tokens": ["tells", "if", "a", "state", "backend", "supports", "the", "restore", "mode", "no", "claim", "mode"], "project": "flink"}
{"id": 418, "code": "public boolean fillStorageFormat(HiveParserASTNode child) throws SemanticException {\n    switch (child.getToken().getType()) {\n        case HiveASTParser.TOK_TABLEFILEFORMAT:\n            if (child.getChildCount() < 2) {\n                throw new SemanticException(\n                        \"Incomplete specification of File Format. \"\n                                + \"You must provide InputFormat, OutputFormat.\");\n            }\n            inputFormat =\n                    HiveParserBaseSemanticAnalyzer.unescapeSQLString(\n                            child.getChild(0).getText());\n            outputFormat =\n                    HiveParserBaseSemanticAnalyzer.unescapeSQLString(\n                            child.getChild(1).getText());\n            if (child.getChildCount() == 3) {\n                serde =\n                        HiveParserBaseSemanticAnalyzer.unescapeSQLString(\n                                child.getChild(2).getText());\n            }\n            break;\n        case HiveASTParser.TOK_STORAGEHANDLER:\n            storageHandler =\n                    HiveParserBaseSemanticAnalyzer.unescapeSQLString(\n                            child.getChild(0).getText());\n            if (child.getChildCount() == 2) {\n                HiveParserBaseSemanticAnalyzer.readProps(\n                        (HiveParserASTNode) (child.getChild(1).getChild(0)), serdeProps);\n            }\n            break;\n        case HiveASTParser.TOK_FILEFORMAT_GENERIC:\n            HiveParserASTNode grandChild = (HiveParserASTNode) child.getChild(0);\n            genericName = (grandChild == null ? \"\" : grandChild.getText()).trim().toUpperCase();\n            processStorageFormat(genericName);\n            break;\n        default:\n                \n            return false;\n    }\n    return true;\n}", "summary_tokens": ["returns", "true", "if", "the", "passed", "token", "was", "a", "storage", "format", "token", "and", "thus", "was", "processed", "accordingly"], "project": "flink"}
{"id": 1542, "code": "public void setFields(T0 f0, T1 f1, T2 f2, T3 f3, T4 f4, T5 f5) {\n    this.f0 = f0;\n    this.f1 = f1;\n    this.f2 = f2;\n    this.f3 = f3;\n    this.f4 = f4;\n    this.f5 = f5;\n}", "summary_tokens": ["sets", "new", "values", "to", "all", "fields", "of", "the", "tuple"], "project": "flink"}
{"id": 1204, "code": "public void addUniqueField(int field) {\n    if (this.uniqueFields == null) {\n        this.uniqueFields = new HashSet<FieldSet>();\n    }\n    this.uniqueFields.add(new FieldSet(field));\n}", "summary_tokens": ["adds", "a", "field", "as", "having", "only", "unique", "values"], "project": "flink"}
{"id": 6520, "code": "private CountDownLatch getCheckpointTriggeredLatch() {\n    final CountDownLatch checkpointTriggeredLatch = new CountDownLatch(1);\n    final SimpleAckingTaskManagerGateway taskManagerGateway =\n            new SimpleAckingTaskManagerGateway();\n    testExecutionSlotAllocator\n            .getLogicalSlotBuilder()\n            .setTaskManagerGateway(taskManagerGateway);\n    taskManagerGateway.setCheckpointConsumer(\n            (executionAttemptID, jobId, checkpointId, timestamp, checkpointOptions) -> {\n                checkpointTriggeredLatch.countDown();\n            });\n    return checkpointTriggeredLatch;\n}", "summary_tokens": ["since", "checkpoint", "is", "triggered", "asynchronously", "we", "need", "to", "figure", "out", "when", "checkpoint", "is", "really", "triggered"], "project": "flink"}
{"id": 5650, "code": "public static void logEnvironmentInfo(\n        Logger log, String componentName, String[] commandLineArgs) {\n    if (log.isInfoEnabled()) {\n        RevisionInformation rev = getRevisionInformation();\n        String version = getVersion();\n        String scalaVersion = getScalaVersion();\n\n        String jvmVersion = getJvmVersion();\n        String[] options = getJvmStartupOptionsArray();\n\n        String javaHome = System.getenv(\"JAVA_HOME\");\n\n        String inheritedLogs = System.getenv(\"FLINK_INHERITED_LOGS\");\n\n        long maxHeapMegabytes = getMaxJvmHeapMemory() >>> 20;\n\n        if (inheritedLogs != null) {\n            log.info(\n                    \"--------------------------------------------------------------------------------\");\n            log.info(\" Preconfiguration: \");\n            log.info(inheritedLogs);\n        }\n\n        log.info(\n                \"--------------------------------------------------------------------------------\");\n        log.info(\n                \" Starting \"\n                        + componentName\n                        + \" (Version: \"\n                        + version\n                        + \", Scala: \"\n                        + scalaVersion\n                        + \", \"\n                        + \"Rev:\"\n                        + rev.commitId\n                        + \", \"\n                        + \"Date:\"\n                        + rev.commitDate\n                        + \")\");\n        log.info(\" OS current user: \" + System.getProperty(\"user.name\"));\n        log.info(\" Current Hadoop/Kerberos user: \" + getHadoopUser());\n        log.info(\" JVM: \" + jvmVersion);\n        log.info(\" Maximum heap size: \" + maxHeapMegabytes + \" MiBytes\");\n        log.info(\" JAVA_HOME: \" + (javaHome == null ? \"(not set)\" : javaHome));\n\n        String hadoopVersionString = getHadoopVersionString();\n        if (hadoopVersionString != null) {\n            log.info(\" Hadoop version: \" + hadoopVersionString);\n        } else {\n            log.info(\" No Hadoop Dependency available\");\n        }\n\n        if (options.length == 0) {\n            log.info(\" JVM Options: (none)\");\n        } else {\n            log.info(\" JVM Options:\");\n            for (String s : options) {\n                log.info(\"    \" + s);\n            }\n        }\n\n        if (commandLineArgs == null || commandLineArgs.length == 0) {\n            log.info(\" Program Arguments: (none)\");\n        } else {\n            log.info(\" Program Arguments:\");\n            for (String s : commandLineArgs) {\n                if (GlobalConfiguration.isSensitive(s)) {\n                    log.info(\n                            \"    \"\n                                    + GlobalConfiguration.HIDDEN_CONTENT\n                                    + \" (sensitive information)\");\n                } else {\n                    log.info(\"    \" + s);\n                }\n            }\n        }\n\n        log.info(\" Classpath: \" + System.getProperty(\"java.class.path\"));\n\n        log.info(\n                \"--------------------------------------------------------------------------------\");\n    }\n}", "summary_tokens": ["logs", "information", "about", "the", "environment", "like", "code", "revision", "current", "user", "java", "version", "and", "jvm", "parameters"], "project": "flink"}
{"id": 97, "code": "public static CredentialProvider getCredentialProviderType(\n        final Properties configProps, final String configPrefix) {\n    if (!configProps.containsKey(configPrefix)) {\n        if (configProps.containsKey(AWSConfigConstants.accessKeyId(configPrefix))\n                && configProps.containsKey(AWSConfigConstants.secretKey(configPrefix))) {\n                \n                \n            return CredentialProvider.BASIC;\n        } else {\n                \n            return CredentialProvider.AUTO;\n        }\n    } else {\n        return CredentialProvider.valueOf(configProps.getProperty(configPrefix));\n    }\n}", "summary_tokens": ["determines", "and", "returns", "the", "credential", "provider", "type", "from", "the", "given", "properties"], "project": "flink"}
{"id": 6000, "code": "public void testFailingJobManagerRunnerCleanup() throws Exception {\n    final FlinkException testException = new FlinkException(\"Test exception.\");\n    final ArrayBlockingQueue<Optional<Exception>> queue = new ArrayBlockingQueue<>(2);\n\n    final BlockingJobManagerRunnerFactory blockingJobManagerRunnerFactory =\n            new BlockingJobManagerRunnerFactory(\n                    () -> {\n                        final Optional<Exception> maybeException = queue.take();\n                        if (maybeException.isPresent()) {\n                            throw maybeException.get();\n                        }\n                    });\n\n    final BlockingQueue<String> cleanUpEvents = new LinkedBlockingQueue<>();\n\n        \n    final CompletableFuture<JobID> cleanupJobData = new CompletableFuture<>();\n    haServices.setCleanupJobDataFuture(cleanupJobData);\n    cleanupJobData.thenAccept(jobId -> cleanUpEvents.add(CLEANUP_HA_SERVICES));\n\n        \n    final TestingJobGraphStore jobGraphStore =\n            TestingJobGraphStore.newBuilder()\n                    .setReleaseJobGraphConsumer(\n                            jobId -> cleanUpEvents.add(CLEANUP_JOB_GRAPH_RELEASE))\n                    .setRemoveJobGraphConsumer(\n                            jobId -> cleanUpEvents.add(CLEANUP_JOB_GRAPH_REMOVE))\n                    .build();\n    jobGraphStore.start(null);\n    haServices.setJobGraphStore(jobGraphStore);\n\n        \n    haServices.setRunningJobsRegistry(\n            new StandaloneRunningJobsRegistry() {\n\n                @Override\n                public void clearJob(JobID jobID) {\n                    super.clearJob(jobID);\n                    cleanUpEvents.add(CLEANUP_RUNNING_JOBS_REGISTRY);\n                }\n            });\n\n    dispatcher =\n            createAndStartDispatcher(\n                    heartbeatServices, haServices, blockingJobManagerRunnerFactory);\n\n    final DispatcherGateway dispatcherGateway =\n            dispatcher.getSelfGateway(DispatcherGateway.class);\n\n        \n    queue.offer(Optional.of(testException));\n    try {\n        dispatcherGateway.submitJob(jobGraph, TIMEOUT).get();\n    } catch (Throwable expectedException) {\n        assertThat(expectedException, containsCause(FlinkException.class));\n        assertThat(expectedException, containsMessage(testException.getMessage()));\n            \n        assertThat(\n                new ArrayList<>(cleanUpEvents),\n                equalTo(\n                        Arrays.asList(\n                                CLEANUP_JOB_GRAPH_REMOVE,\n                                CLEANUP_RUNNING_JOBS_REGISTRY,\n                                CLEANUP_HA_SERVICES)));\n    }\n\n        \n    queue.offer(Optional.empty());\n        \n    dispatcherGateway.submitJob(jobGraph, TIMEOUT).get();\n    blockingJobManagerRunnerFactory.setJobStatus(JobStatus.RUNNING);\n\n        \n    awaitStatus(dispatcherGateway, jobId, JobStatus.RUNNING);\n}", "summary_tokens": ["tests", "that", "a", "failing", "job", "manager", "runner", "will", "be", "properly", "cleaned", "up"], "project": "flink"}
{"id": 3331, "code": "public final <T extends Value> T getPreviousIterationAggregate(String name) {\n    return this.runtimeContext.getPreviousIterationAggregate(name);\n}", "summary_tokens": ["get", "the", "aggregated", "value", "that", "an", "aggregator", "computed", "in", "the", "previous", "iteration"], "project": "flink"}
{"id": 2626, "code": "public void testBlobCacheRecovery() throws Exception {\n    org.apache.flink.configuration.Configuration config =\n            new org.apache.flink.configuration.Configuration();\n    config.setString(HighAvailabilityOptions.HA_MODE, \"ZOOKEEPER\");\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n    config.setString(HighAvailabilityOptions.HA_STORAGE_PATH, hdfsURI);\n\n    BlobStoreService blobStoreService = BlobUtils.createBlobStoreFromConfig(config);\n\n    try {\n        BlobCacheRecoveryTest.testBlobCacheRecovery(config, blobStoreService);\n    } finally {\n        blobStoreService.closeAndCleanupAllData();\n    }\n}", "summary_tokens": ["tests", "that", "with", "high", "availability", "mode", "zookeeper", "distributed", "jars", "are", "recoverable", "from", "any", "participating", "blob", "server", "when", "uploaded", "via", "a", "blob", "cache"], "project": "flink"}
{"id": 4332, "code": "public final String getResourceIdString() {\n    return resourceId;\n}", "summary_tokens": ["gets", "the", "resource", "id", "as", "string"], "project": "flink"}
{"id": 3064, "code": "public void lockNode(final NodeId node, final DeweyNumber version) {\n    Lockable<SharedBufferNode> sharedBufferNode = sharedBuffer.getEntry(node);\n    if (sharedBufferNode != null) {\n        sharedBufferNode.lock();\n        for (Lockable<SharedBufferEdge> edge : sharedBufferNode.getElement().getEdges()) {\n            if (version.isCompatibleWith(edge.getElement().getDeweyNumber())) {\n                edge.lock();\n            }\n        }\n        sharedBuffer.upsertEntry(node, sharedBufferNode);\n    }\n}", "summary_tokens": ["increases", "the", "reference", "counter", "for", "the", "given", "entry", "so", "that", "it", "is", "not", "accidentally", "removed"], "project": "flink"}
{"id": 4645, "code": "public int getNumPriorityElements() {\n    return numPriorityElements;\n}", "summary_tokens": ["returns", "the", "current", "number", "of", "priority", "elements", "0", "size"], "project": "flink"}
{"id": 3001, "code": "public static CompletedCheckpointStore createCompletedCheckpointStore(\n        Configuration configuration,\n        FlinkKubeClient kubeClient,\n        Executor executor,\n        String configMapName,\n        String lockIdentity,\n        int maxNumberOfCheckpointsToRetain,\n        SharedStateRegistryFactory sharedStateRegistryFactory,\n        Executor ioExecutor)\n        throws Exception {\n\n    final RetrievableStateStorageHelper<CompletedCheckpoint> stateStorage =\n            new FileSystemStateStorageHelper<>(\n                    HighAvailabilityServicesUtils.getClusterHighAvailableStoragePath(\n                            configuration),\n                    COMPLETED_CHECKPOINT_FILE_SUFFIX);\n    final KubernetesStateHandleStore<CompletedCheckpoint> stateHandleStore =\n            new KubernetesStateHandleStore<>(\n                    kubeClient,\n                    configMapName,\n                    stateStorage,\n                    k -> k.startsWith(CHECKPOINT_ID_KEY_PREFIX),\n                    lockIdentity);\n    Collection<CompletedCheckpoint> checkpoints =\n            DefaultCompletedCheckpointStoreUtils.retrieveCompletedCheckpoints(\n                    stateHandleStore, KubernetesCheckpointStoreUtil.INSTANCE);\n\n    return new DefaultCompletedCheckpointStore<>(\n            maxNumberOfCheckpointsToRetain,\n            stateHandleStore,\n            KubernetesCheckpointStoreUtil.INSTANCE,\n            checkpoints,\n            sharedStateRegistryFactory.create(ioExecutor, checkpoints),\n            executor);\n}", "summary_tokens": ["create", "a", "default", "completed", "checkpoint", "store", "with", "kubernetes", "state", "handle", "store"], "project": "flink"}
{"id": 8257, "code": "public static ChangelogMode all() {\n    return ALL;\n}", "summary_tokens": ["shortcut", "for", "a", "changelog", "that", "can", "contain", "all", "row", "kind", "s"], "project": "flink"}
{"id": 8790, "code": "private static void shiftMapping(Map<Integer, Integer> mapping, int startIndex, int offset) {\n    for (Map.Entry<Integer, Integer> entry : mapping.entrySet()) {\n        if (entry.getValue() >= startIndex) {\n            mapping.put(entry.getKey(), entry.getValue() + offset);\n        } else {\n            mapping.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "summary_tokens": ["shift", "the", "mapping", "to", "fixed", "offset", "from", "the", "start", "index"], "project": "flink"}
{"id": 6015, "code": "public int getInteger() {\n    return this.value;\n}", "summary_tokens": ["returns", "the", "stored", "integer", "value"], "project": "flink"}
{"id": 7326, "code": "public double getDelta(DATA oldDataPoint, DATA newDataPoint) {\n    if (converter == null) {\n            \n            \n            \n        return getNestedDelta((TO) oldDataPoint, (TO) newDataPoint);\n    } else {\n        return getNestedDelta(converter.extract(oldDataPoint), converter.extract(newDataPoint));\n    }\n}", "summary_tokens": ["this", "method", "takes", "the", "two", "data", "point", "and", "runs", "the", "set", "extractor", "on", "it"], "project": "flink"}
{"id": 5980, "code": "public static Collection<MasterState> createRandomMasterStates(Random random, int num) {\n    final ArrayList<MasterState> states = new ArrayList<>(num);\n\n    for (int i = 0; i < num; i++) {\n        int version = random.nextInt(10);\n        String name = StringUtils.getRandomString(random, 5, 500);\n        byte[] bytes = new byte[random.nextInt(5000) + 1];\n        random.nextBytes(bytes);\n\n        states.add(new MasterState(name, bytes, version));\n    }\n\n    return states;\n}", "summary_tokens": ["creates", "a", "bunch", "of", "random", "master", "states"], "project": "flink"}
{"id": 7305, "code": "private boolean shouldIgnore(Path filePath, long modificationTime) {\n    assert (Thread.holdsLock(checkpointLock));\n    boolean shouldIgnore = modificationTime <= globalModificationTime;\n    if (shouldIgnore && LOG.isDebugEnabled()) {\n        LOG.debug(\n                \"Ignoring \"\n                        + filePath\n                        + \", with mod time= \"\n                        + modificationTime\n                        + \" and global mod time= \"\n                        + globalModificationTime);\n    }\n    return shouldIgnore;\n}", "summary_tokens": ["returns", "true", "if", "the", "file", "is", "not", "to", "be", "processed", "further"], "project": "flink"}
{"id": 3844, "code": "public void reset() {\n    root.setRowCount(0);\n    for (ArrowFieldWriter fieldWriter : fieldWriters) {\n        fieldWriter.reset();\n    }\n}", "summary_tokens": ["resets", "the", "state", "of", "the", "writer", "to", "write", "the", "next", "batch", "of", "rows"], "project": "flink"}
{"id": 828, "code": "protected AmazonKinesis createKinesisClient(Properties configProps) {\n\n    ClientConfiguration awsClientConfig = new ClientConfigurationFactory().getConfig();\n    AWSUtil.setAwsClientConfigProperties(awsClientConfig, configProps);\n    return AWSUtil.createKinesisClient(configProps, awsClientConfig);\n}", "summary_tokens": ["create", "the", "kinesis", "client", "using", "the", "provided", "configuration", "properties", "and", "default", "client", "configuration"], "project": "flink"}
{"id": 169, "code": "public void close() {\n    mapper = null;\n    try {\n        if (session != null) {\n            session.close();\n        }\n    } catch (Exception e) {\n        LOG.error(\"Error while closing session.\", e);\n    }\n\n    try {\n        if (cluster != null) {\n            cluster.close();\n        }\n    } catch (Exception e) {\n        LOG.error(\"Error while closing cluster.\", e);\n    }\n}", "summary_tokens": ["closes", "all", "resources", "used"], "project": "flink"}
{"id": 3589, "code": "public BulkPartialSolutionNode getPartialSolution() {\n    return partialSolution;\n}", "summary_tokens": ["gets", "the", "partial", "solution", "from", "this", "bulk", "iteration", "node"], "project": "flink"}
{"id": 6685, "code": "public static String getJavaCommandPath() {\n    File javaHome = new File(System.getProperty(\"java.home\"));\n\n    String path1 = new File(javaHome, \"java\").getAbsolutePath();\n    String path2 = new File(new File(javaHome, \"bin\"), \"java\").getAbsolutePath();\n\n    try {\n        ProcessBuilder bld = new ProcessBuilder(path1, \"-version\");\n        Process process = bld.start();\n        if (process.waitFor() == 0) {\n            return path1;\n        }\n    } catch (Throwable t) {\n            \n    }\n\n    try {\n        ProcessBuilder bld = new ProcessBuilder(path2, \"-version\");\n        Process process = bld.start();\n        if (process.waitFor() == 0) {\n            return path2;\n        }\n    } catch (Throwable tt) {\n            \n    }\n    return null;\n}", "summary_tokens": ["tries", "to", "get", "the", "java", "executable", "command", "with", "which", "the", "current", "jvm", "was", "started"], "project": "flink"}
{"id": 3176, "code": "public <T> Graph<K, VV, EV> joinWithEdgesOnSource(\n        DataSet<Tuple2<K, T>> inputDataSet, final EdgeJoinFunction<EV, T> edgeJoinFunction) {\n\n    DataSet<Edge<K, EV>> resultedEdges =\n            this.getEdges()\n                    .coGroup(inputDataSet)\n                    .where(0)\n                    .equalTo(0)\n                    .with(\n                            new ApplyCoGroupToEdgeValuesOnEitherSourceOrTarget<>(\n                                    edgeJoinFunction))\n                    .name(\"Join with edges on source\");\n\n    return new Graph<>(this.vertices, resultedEdges, this.context);\n}", "summary_tokens": ["joins", "the", "edge", "data", "set", "with", "an", "input", "tuple", "0", "data", "set", "and", "applies", "a", "user", "defined", "transformation", "on", "the", "values", "of", "the", "matched", "records"], "project": "flink"}
{"id": 6343, "code": "public Metric get(String name) {\n    return intercepted.get(name);\n}", "summary_tokens": ["returns", "the", "registered", "metric", "for", "the", "given", "name", "or", "null", "if", "it", "was", "never", "registered"], "project": "flink"}
{"id": 8836, "code": "public FlinkRelBuilder createRelBuilder(String currentCatalog, String currentDatabase) {\n    FlinkCalciteCatalogReader relOptSchema =\n            createCatalogReader(false, currentCatalog, currentDatabase);\n\n    Context chain =\n            Contexts.of(\n                    context,\n                        \n                    createFlinkPlanner(currentCatalog, currentDatabase).createToRelContext());\n    return new FlinkRelBuilder(chain, cluster, relOptSchema);\n}", "summary_tokens": ["creates", "a", "configured", "flink", "rel", "builder", "for", "a", "planning", "session"], "project": "flink"}
{"id": 1481, "code": "public void setFields(\n        T0 f0,\n        T1 f1,\n        T2 f2,\n        T3 f3,\n        T4 f4,\n        T5 f5,\n        T6 f6,\n        T7 f7,\n        T8 f8,\n        T9 f9,\n        T10 f10,\n        T11 f11,\n        T12 f12,\n        T13 f13,\n        T14 f14) {\n    this.f0 = f0;\n    this.f1 = f1;\n    this.f2 = f2;\n    this.f3 = f3;\n    this.f4 = f4;\n    this.f5 = f5;\n    this.f6 = f6;\n    this.f7 = f7;\n    this.f8 = f8;\n    this.f9 = f9;\n    this.f10 = f10;\n    this.f11 = f11;\n    this.f12 = f12;\n    this.f13 = f13;\n    this.f14 = f14;\n}", "summary_tokens": ["sets", "new", "values", "to", "all", "fields", "of", "the", "tuple"], "project": "flink"}
{"id": 8335, "code": "public static short getShort(MemorySegment[] segments, int offset) {\n    if (inFirstSegment(segments, offset, 2)) {\n        return segments[0].getShort(offset);\n    } else {\n        return getShortMultiSegments(segments, offset);\n    }\n}", "summary_tokens": ["get", "short", "from", "segments"], "project": "flink"}
{"id": 2298, "code": "private static void format(File originFile, File destFile) throws Exception {\n    BufferedReader reader = new BufferedReader(new FileReader(originFile));\n    BufferedWriter writer = new BufferedWriter(new FileWriter(destFile));\n\n    String line;\n    List<Integer> colLengthList;\n    List<String> content = new ArrayList<>();\n    while ((line = reader.readLine()) != null) {\n        content.add(line);\n    }\n\n    if (isFormat1(content)) {\n        colLengthList =\n                Arrays.stream(content.get(1).split(REGEX_SPLIT_BAR))\n                        .map(col -> col.length())\n                        .collect(Collectors.toList());\n        writeContent(writer, content, colLengthList);\n    } else if (isFormat2(content)) {\n        colLengthList =\n                Arrays.stream(content.get(1).split(RESULT_HEAD_STRING_SPACE))\n                        .map(col -> col.length())\n                        .collect(Collectors.toList());\n        writeContent(writer, content, colLengthList);\n    } else {\n        writeContent(writer, content, null);\n    }\n\n    reader.close();\n    writer.close();\n}", "summary_tokens": ["tpc", "ds", "answer", "set", "has", "three", "kind", "of", "formats", "recognize", "them", "and", "convert", "to", "unified", "format"], "project": "flink"}
{"id": 5586, "code": "public void run() {\n    try {\n        doRun();\n    } finally {\n        terminationFuture.complete(executionState);\n    }\n}", "summary_tokens": ["the", "core", "work", "method", "that", "bootstraps", "the", "task", "and", "executes", "its", "code"], "project": "flink"}
{"id": 7588, "code": "public void runMailboxLoop() throws Exception {\n    suspended = !mailboxLoopRunning;\n\n    final TaskMailbox localMailbox = mailbox;\n\n    checkState(\n            localMailbox.isMailboxThread(),\n            \"Method must be executed by declared mailbox thread!\");\n\n    assert localMailbox.getState() == TaskMailbox.State.OPEN : \"Mailbox must be opened!\";\n\n    final MailboxController defaultActionContext = new MailboxController(this);\n\n    while (isNextLoopPossible()) {\n            \n        processMail(localMailbox, false);\n        if (isNextLoopPossible()) {\n            mailboxDefaultAction.runDefaultAction(\n                    defaultActionContext); \n        }\n    }\n}", "summary_tokens": ["runs", "the", "mailbox", "processing", "loop"], "project": "flink"}
{"id": 9197, "code": "public RowData addInput(@Nullable RowData previousAcc, RowData input) throws Exception {\n    RowData currentAcc;\n    if (previousAcc == null) {\n        currentAcc = localAgg.createAccumulators();\n    } else {\n        currentAcc = previousAcc;\n    }\n\n    localAgg.setAccumulators(currentAcc);\n    localAgg.merge(input);\n    return localAgg.getAccumulators();\n}", "summary_tokens": ["the", "previous", "acc", "is", "accumulator", "but", "input", "is", "a", "row", "in", "lt", "key", "accumulator", "gt", "schema", "the", "specific", "generated", "local", "agg", "will", "project", "the", "input", "to", "accumulator", "in", "merge", "method"], "project": "flink"}
{"id": 9729, "code": "List<String> registerMultipleLocalResources(\n        final Collection<Path> shipFiles,\n        final String localResourcesDirectory,\n        final LocalResourceType resourceType)\n        throws IOException {\n\n    final List<Path> localPaths = new ArrayList<>();\n    final List<Path> relativePaths = new ArrayList<>();\n    for (Path shipFile : shipFiles) {\n        if (Utils.isRemotePath(shipFile.toString())) {\n            if (fileSystem.isDirectory(shipFile)) {\n                final URI parentURI = shipFile.getParent().toUri();\n                final RemoteIterator<LocatedFileStatus> iterable =\n                        fileSystem.listFiles(shipFile, true);\n                while (iterable.hasNext()) {\n                    final Path current = iterable.next().getPath();\n                    localPaths.add(current);\n                    relativePaths.add(\n                            new Path(\n                                    localResourcesDirectory,\n                                    parentURI.relativize(current.toUri()).getPath()));\n                }\n                continue;\n            }\n        } else {\n            final File file = new File(shipFile.toUri().getPath());\n            if (file.isDirectory()) {\n                final java.nio.file.Path shipPath = file.toPath().toRealPath();\n                final java.nio.file.Path parentPath = shipPath.getParent();\n                Collection<java.nio.file.Path> paths =\n                        FileUtils.listFilesInDirectory(shipPath, path -> true);\n                for (java.nio.file.Path javaPath : paths) {\n                    localPaths.add(new Path(javaPath.toUri()));\n                    relativePaths.add(\n                            new Path(\n                                    localResourcesDirectory,\n                                    parentPath.relativize(javaPath).toString()));\n                }\n                continue;\n            }\n        }\n        localPaths.add(shipFile);\n        relativePaths.add(new Path(localResourcesDirectory, shipFile.getName()));\n    }\n\n    final Set<String> archives = new HashSet<>();\n    final Set<String> resources = new HashSet<>();\n    for (int i = 0; i < localPaths.size(); i++) {\n        final Path localPath = localPaths.get(i);\n        final Path relativePath = relativePaths.get(i);\n        if (!isFlinkDistJar(relativePath.getName())) {\n            final String key = relativePath.toString();\n            final YarnLocalResourceDescriptor resourceDescriptor =\n                    registerSingleLocalResource(\n                            key,\n                            localPath,\n                            relativePath.getParent().toString(),\n                            resourceType,\n                            true,\n                            true);\n\n            if (!resourceDescriptor.alreadyRegisteredAsLocalResource()) {\n                if (key.endsWith(\"jar\")) {\n                    archives.add(relativePath.toString());\n                } else {\n                    resources.add(relativePath.getParent().toString());\n                }\n            }\n        }\n    }\n\n        \n        \n    final ArrayList<String> classPaths = new ArrayList<>();\n    resources.stream().sorted().forEach(classPaths::add);\n    archives.stream().sorted().forEach(classPaths::add);\n    return classPaths;\n}", "summary_tokens": ["recursively", "uploads", "and", "registers", "any", "user", "and", "system", "files", "in", "tt", "ship", "files", "tt", "except", "for", "files", "matching", "tt", "flink", "dist"], "project": "flink"}
{"id": 1413, "code": "default Collection<String> getCompatibleStateNames() {\n    return Collections.emptyList();\n}", "summary_tokens": ["a", "list", "of", "state", "names", "of", "sinks", "from", "which", "the", "state", "can", "be", "restored"], "project": "flink"}
{"id": 545, "code": "public void removeRecordsLagMetric(TopicPartition tp) {\n    if (recordsLagMetrics != null) {\n        recordsLagMetrics.remove(tp);\n    }\n}", "summary_tokens": ["remove", "a", "partition", "s", "records", "lag", "metric", "from", "tracking", "list"], "project": "flink"}
{"id": 9398, "code": "public static void setDouble(MemorySegment[] segments, int offset, double value) {\n    if (inFirstSegment(segments, offset, 8)) {\n        segments[0].putDouble(offset, value);\n    } else {\n        setDoubleMultiSegments(segments, offset, value);\n    }\n}", "summary_tokens": ["set", "double", "from", "segments"], "project": "flink"}
{"id": 229, "code": "public static <T> FileSourceBuilder<T> forRecordFileFormat(\n        final FileRecordFormat<T> recordFormat, final Path... paths) {\n    return forBulkFileFormat(new FileRecordFormatAdapter<>(recordFormat), paths);\n}", "summary_tokens": ["builds", "a", "new", "file", "source", "using", "a", "file", "record", "format", "to", "read", "record", "by", "record", "from", "a", "a", "file", "path"], "project": "flink"}
{"id": 9179, "code": "void addHashBloomFilter(int hash) {\n    if (bloomFilter != null) {\n            \n        if (!bloomFilter.addHash(hash)) {\n            freeBloomFilter();\n        }\n    }\n}", "summary_tokens": ["add", "new", "hash", "to", "bloom", "filter", "when", "insert", "a", "record", "to", "spilled", "partition"], "project": "flink"}
{"id": 553, "code": "public FlinkKafkaConsumerBase<T> setCommitOffsetsOnCheckpoints(boolean commitOnCheckpoints) {\n    this.enableCommitOnCheckpoints = commitOnCheckpoints;\n    return this;\n}", "summary_tokens": ["specifies", "whether", "or", "not", "the", "consumer", "should", "commit", "offsets", "back", "to", "kafka", "on", "checkpoints"], "project": "flink"}
{"id": 5417, "code": "default boolean useManagedMemory() {\n    return false;\n}", "summary_tokens": ["whether", "the", "state", "backend", "uses", "flink", "s", "managed", "memory"], "project": "flink"}
{"id": 9301, "code": "public void reset() {\n    nextWindow = null;\n    watermark = Long.MIN_VALUE;\n    triggerWindowStartIndex = 0;\n    emptyWindowTriggered = true;\n    resetBuffer();\n}", "summary_tokens": ["reset", "for", "next", "group"], "project": "flink"}
{"id": 3081, "code": "public Pattern<T, T> notFollowedBy(final String name) {\n    if (quantifier.hasProperty(Quantifier.QuantifierProperty.OPTIONAL)) {\n        throw new UnsupportedOperationException(\n                \"Specifying a pattern with an optional path to NOT condition is not supported yet. \"\n                        + \"You can simulate such pattern with two independent patterns, one with and the other without \"\n                        + \"the optional part.\");\n    }\n    return new Pattern<>(name, this, ConsumingStrategy.NOT_FOLLOW, afterMatchSkipStrategy);\n}", "summary_tokens": ["appends", "a", "new", "pattern", "to", "the", "existing", "one"], "project": "flink"}
{"id": 5702, "code": "default CompletableFuture<Acknowledge> stopWithSavepoint(\n        final AsynchronousJobOperationKey operationKey,\n        final String targetDirectory,\n        final TriggerSavepointMode savepointMode,\n        @RpcTimeout final Time timeout) {\n    throw new UnsupportedOperationException();\n}", "summary_tokens": ["stops", "the", "job", "with", "a", "savepoint", "returning", "a", "future", "that", "completes", "when", "the", "operation", "is", "started"], "project": "flink"}
{"id": 3225, "code": "public GraphCsvReader includeFieldsEdges(long mask) {\n    this.edgeReader.includeFields(mask);\n    return this;\n}", "summary_tokens": ["configures", "which", "fields", "of", "the", "csv", "file", "containing", "edges", "data", "should", "be", "included", "and", "which", "should", "be", "skipped"], "project": "flink"}
{"id": 4123, "code": "public boolean cleanupJob(JobID jobId, boolean cleanupBlobStoreFiles) {\n    checkNotNull(jobId);\n\n    final File jobDir =\n            new File(BlobUtils.getStorageLocationPath(storageDir.getAbsolutePath(), jobId));\n\n    readWriteLock.writeLock().lock();\n\n    try {\n            \n        boolean deletedLocally = false;\n        try {\n            FileUtils.deleteDirectory(jobDir);\n\n                \n                \n                \n                \n\n            deletedLocally = true;\n        } catch (IOException e) {\n            LOG.warn(\n                    \"Failed to locally delete BLOB storage directory at \"\n                            + jobDir.getAbsolutePath(),\n                    e);\n        }\n\n            \n        final boolean deletedHA = !cleanupBlobStoreFiles || blobStore.deleteAll(jobId);\n\n        return deletedLocally && deletedHA;\n    } finally {\n        readWriteLock.writeLock().unlock();\n    }\n}", "summary_tokens": ["removes", "all", "blobs", "from", "local", "and", "ha", "store", "belonging", "to", "the", "given", "job", "id"], "project": "flink"}
{"id": 4754, "code": "public void addVertex(JobVertex vertex) {\n    final JobVertexID id = vertex.getID();\n    JobVertex previous = taskVertices.put(id, vertex);\n\n        \n    if (previous != null) {\n        taskVertices.put(id, previous);\n        throw new IllegalArgumentException(\n                \"The JobGraph already contains a vertex with that id.\");\n    }\n}", "summary_tokens": ["adds", "a", "new", "task", "vertex", "to", "the", "job", "graph", "if", "it", "is", "not", "already", "included"], "project": "flink"}
{"id": 3568, "code": "public void setNetworkCost(double bytes) {\n    if (bytes == UNKNOWN || bytes >= 0) {\n        this.networkCost = bytes;\n    } else {\n        throw new IllegalArgumentException();\n    }\n}", "summary_tokens": ["sets", "the", "network", "cost", "for", "this", "costs", "object"], "project": "flink"}
{"id": 8491, "code": "default TypeInformation<T> getOutputType() {\n    return null;\n}", "summary_tokens": ["this", "method", "will", "be", "removed", "in", "future", "versions", "as", "it", "uses", "the", "old", "type", "system"], "project": "flink"}
{"id": 8668, "code": "private static StringBuilder hms(StringBuilder b, int h, int m, int s) {\n    int2(b, h);\n    b.append(':');\n    int2(b, m);\n    b.append(':');\n    int2(b, s);\n    return b;\n}", "summary_tokens": ["appends", "hour", "minute", "second", "to", "a", "buffer", "assumes", "they", "are", "valid"], "project": "flink"}
{"id": 1189, "code": "public boolean supportsMultiPaths() {\n    return false;\n}", "summary_tokens": ["override", "this", "method", "to", "supports", "multiple", "paths"], "project": "flink"}
{"id": 2042, "code": "public static long getLong(Properties config, String key, long defaultValue, Logger logger) {\n    try {\n        return getLong(config, key, defaultValue);\n    } catch (IllegalArgumentException iae) {\n        logger.warn(iae.getMessage());\n        return defaultValue;\n    }\n}", "summary_tokens": ["get", "long", "from", "properties"], "project": "flink"}
{"id": 9677, "code": "public <T> T chooseRandomElement(Collection<T> collection) {\n    int choice = choseRandomIndex(collection);\n    for (T key : collection) {\n        if (choice == 0) {\n            return key;\n        }\n        --choice;\n    }\n    return null;\n}", "summary_tokens": ["a", "randomly", "chosen", "element", "from", "collection"], "project": "flink"}
{"id": 3748, "code": "public void testIterationWithStaticInput() {\n    try {\n        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n        env.setParallelism(100);\n\n        DataSet<Long> source = env.generateSequence(1, 1000000);\n\n        DataSet<Long> mapped = source.map(new IdentityMapper<Long>());\n\n        DataSet<Long> reduced =\n                source.groupBy(new IdentityKeyExtractor<Long>())\n                        .reduce(new SelectOneReducer<Long>());\n\n        IterativeDataSet<Long> iteration = mapped.iterate(10);\n        iteration\n                .closeWith(\n                        iteration\n                                .join(reduced)\n                                .where(new IdentityKeyExtractor<Long>())\n                                .equalTo(new IdentityKeyExtractor<Long>())\n                                .with(new DummyFlatJoinFunction<Long>()))\n                .output(new DiscardingOutputFormat<Long>());\n\n        compileNoStats(env.createProgramPlan());\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["pre", "iteration", "map", "sink", "src", "map", "join", "reduce", "pre"], "project": "flink"}
{"id": 4790, "code": "public void setStrictlyCoLocatedWith(JobVertex strictlyCoLocatedWith) {\n    if (this.slotSharingGroup == null\n            || this.slotSharingGroup != strictlyCoLocatedWith.slotSharingGroup) {\n        throw new IllegalArgumentException(\n                \"Strict co-location requires that both vertices are in the same slot sharing group.\");\n    }\n\n    CoLocationGroupImpl thisGroup = this.coLocationGroup;\n    CoLocationGroupImpl otherGroup = strictlyCoLocatedWith.coLocationGroup;\n\n    if (otherGroup == null) {\n        if (thisGroup == null) {\n            CoLocationGroupImpl group = new CoLocationGroupImpl(this, strictlyCoLocatedWith);\n            this.coLocationGroup = group;\n            strictlyCoLocatedWith.coLocationGroup = group;\n        } else {\n            thisGroup.addVertex(strictlyCoLocatedWith);\n            strictlyCoLocatedWith.coLocationGroup = thisGroup;\n        }\n    } else {\n        if (thisGroup == null) {\n            otherGroup.addVertex(this);\n            this.coLocationGroup = otherGroup;\n        } else {\n                \n            thisGroup.mergeInto(otherGroup);\n        }\n    }\n}", "summary_tokens": ["tells", "this", "vertex", "to", "strictly", "co", "locate", "its", "subtasks", "with", "the", "subtasks", "of", "the", "given", "vertex"], "project": "flink"}
{"id": 7041, "code": "public TypeInformation<IN1> getType1() {\n    return inputStream1.getType();\n}", "summary_tokens": ["gets", "the", "type", "of", "the", "first", "input"], "project": "flink"}
{"id": 5882, "code": "public void testStateCleanupForLateOrUnknownMessages() throws Exception {\n    JobVertexID jobVertexID1 = new JobVertexID();\n    JobVertexID jobVertexID2 = new JobVertexID();\n\n    CheckpointCoordinatorTestingUtils.CheckpointRecorderTaskManagerGateway gateway =\n            new CheckpointCoordinatorTestingUtils.CheckpointRecorderTaskManagerGateway();\n\n    ExecutionGraph graph =\n            new CheckpointCoordinatorTestingUtils.CheckpointExecutionGraphBuilder()\n                    .addJobVertex(jobVertexID1)\n                    .addJobVertex(jobVertexID2, false)\n                    .setTaskManagerGateway(gateway)\n                    .build();\n\n    ExecutionVertex vertex1 = graph.getJobVertex(jobVertexID1).getTaskVertices()[0];\n    ExecutionVertex vertex2 = graph.getJobVertex(jobVertexID2).getTaskVertices()[0];\n\n    ExecutionAttemptID attemptID1 = vertex1.getCurrentExecutionAttempt().getAttemptId();\n    ExecutionAttemptID attemptID2 = vertex2.getCurrentExecutionAttempt().getAttemptId();\n\n    CheckpointCoordinatorConfiguration chkConfig =\n            new CheckpointCoordinatorConfiguration.CheckpointCoordinatorConfigurationBuilder()\n                    .setMaxConcurrentCheckpoints(1)\n                    .build();\n    CheckpointCoordinator checkpointCoordinator =\n            new CheckpointCoordinatorBuilder()\n                    .setExecutionGraph(graph)\n                    .setCheckpointCoordinatorConfiguration(chkConfig)\n                    .setTimer(manuallyTriggeredScheduledExecutor)\n                    .build();\n\n    final CompletableFuture<CompletedCheckpoint> checkpointFuture =\n            checkpointCoordinator.triggerCheckpoint(false);\n    manuallyTriggeredScheduledExecutor.triggerAll();\n    FutureUtils.throwIfCompletedExceptionally(checkpointFuture);\n\n    assertEquals(1, checkpointCoordinator.getNumberOfPendingCheckpoints());\n\n    PendingCheckpoint pendingCheckpoint =\n            checkpointCoordinator.getPendingCheckpoints().values().iterator().next();\n\n    long checkpointId = pendingCheckpoint.getCheckpointId();\n\n    OperatorID opIDtrigger =\n            vertex1.getJobVertex().getOperatorIDs().get(0).getGeneratedOperatorID();\n\n    TaskStateSnapshot taskOperatorSubtaskStatesTrigger = spy(new TaskStateSnapshot());\n    OperatorSubtaskState subtaskStateTrigger = mock(OperatorSubtaskState.class);\n    taskOperatorSubtaskStatesTrigger.putSubtaskStateByOperatorID(\n            opIDtrigger, subtaskStateTrigger);\n\n        \n    checkpointCoordinator.receiveAcknowledgeMessage(\n            new AcknowledgeCheckpoint(\n                    graph.getJobID(),\n                    attemptID1,\n                    checkpointId,\n                    new CheckpointMetrics(),\n                    taskOperatorSubtaskStatesTrigger),\n            TASK_MANAGER_LOCATION_INFO);\n\n        \n    verify(subtaskStateTrigger, never()).discardState();\n\n    TaskStateSnapshot unknownSubtaskState = mock(TaskStateSnapshot.class);\n\n        \n    checkpointCoordinator.receiveAcknowledgeMessage(\n            new AcknowledgeCheckpoint(\n                    graph.getJobID(),\n                    new ExecutionAttemptID(),\n                    checkpointId,\n                    new CheckpointMetrics(),\n                    unknownSubtaskState),\n            TASK_MANAGER_LOCATION_INFO);\n\n        \n    verify(unknownSubtaskState, times(1)).discardState();\n\n    TaskStateSnapshot differentJobSubtaskState = mock(TaskStateSnapshot.class);\n\n        \n    checkpointCoordinator.receiveAcknowledgeMessage(\n            new AcknowledgeCheckpoint(\n                    new JobID(),\n                    new ExecutionAttemptID(),\n                    checkpointId,\n                    new CheckpointMetrics(),\n                    differentJobSubtaskState),\n            TASK_MANAGER_LOCATION_INFO);\n\n        \n    verify(differentJobSubtaskState, never()).discardState();\n\n        \n    TaskStateSnapshot triggerSubtaskState = mock(TaskStateSnapshot.class);\n    checkpointCoordinator.receiveAcknowledgeMessage(\n            new AcknowledgeCheckpoint(\n                    graph.getJobID(),\n                    attemptID1,\n                    checkpointId,\n                    new CheckpointMetrics(),\n                    triggerSubtaskState),\n            TASK_MANAGER_LOCATION_INFO);\n\n        \n    verify(triggerSubtaskState, never()).discardState();\n\n        \n    reset(subtaskStateTrigger);\n    checkpointCoordinator.receiveDeclineMessage(\n            new DeclineCheckpoint(\n                    graph.getJobID(),\n                    attemptID1,\n                    checkpointId,\n                    new CheckpointException(CHECKPOINT_DECLINED)),\n            TASK_MANAGER_LOCATION_INFO);\n\n    assertTrue(pendingCheckpoint.isDisposed());\n\n        \n    verify(subtaskStateTrigger, times(1)).discardState();\n\n    TaskStateSnapshot ackSubtaskState = mock(TaskStateSnapshot.class);\n\n        \n    checkpointCoordinator.receiveAcknowledgeMessage(\n            new AcknowledgeCheckpoint(\n                    graph.getJobID(),\n                    attemptID2,\n                    checkpointId,\n                    new CheckpointMetrics(),\n                    ackSubtaskState),\n            TASK_MANAGER_LOCATION_INFO);\n\n        \n    verify(ackSubtaskState, times(1)).discardState();\n\n        \n    reset(differentJobSubtaskState);\n    checkpointCoordinator.receiveAcknowledgeMessage(\n            new AcknowledgeCheckpoint(\n                    new JobID(),\n                    new ExecutionAttemptID(),\n                    checkpointId,\n                    new CheckpointMetrics(),\n                    differentJobSubtaskState),\n            TASK_MANAGER_LOCATION_INFO);\n\n        \n    verify(differentJobSubtaskState, never()).discardState();\n\n    TaskStateSnapshot unknownSubtaskState2 = mock(TaskStateSnapshot.class);\n\n        \n    checkpointCoordinator.receiveAcknowledgeMessage(\n            new AcknowledgeCheckpoint(\n                    graph.getJobID(),\n                    new ExecutionAttemptID(),\n                    checkpointId,\n                    new CheckpointMetrics(),\n                    unknownSubtaskState2),\n            TASK_MANAGER_LOCATION_INFO);\n\n        \n    verify(unknownSubtaskState2, times(1)).discardState();\n}", "summary_tokens": ["tests", "that", "late", "acknowledge", "checkpoint", "messages", "are", "properly", "cleaned", "up"], "project": "flink"}
{"id": 4553, "code": "void skip(int bytesToSkip) {\n    writerPosition.update();\n    int cachedWriterPosition = writerPosition.getCached();\n    int bytesReadable = cachedWriterPosition - currentReaderPosition;\n    checkState(bytesToSkip <= bytesReadable, \"bytes to skip beyond readable range\");\n    currentReaderPosition += bytesToSkip;\n}", "summary_tokens": ["bytes", "to", "skip", "number", "of", "bytes", "to", "skip", "from", "current", "reader", "position"], "project": "flink"}
{"id": 8405, "code": "public static DynamicTableSource createDynamicTableSource(\n        @Nullable DynamicTableSourceFactory preferredFactory,\n        ObjectIdentifier objectIdentifier,\n        ResolvedCatalogTable catalogTable,\n        ReadableConfig configuration,\n        ClassLoader classLoader,\n        boolean isTemporary) {\n    final DefaultDynamicTableContext context =\n            new DefaultDynamicTableContext(\n                    objectIdentifier, catalogTable, configuration, classLoader, isTemporary);\n    try {\n        final DynamicTableSourceFactory factory =\n                preferredFactory != null\n                        ? preferredFactory\n                        : discoverTableFactory(DynamicTableSourceFactory.class, context);\n        return factory.createDynamicTableSource(context);\n    } catch (Throwable t) {\n        throw new ValidationException(\n                String.format(\n                        \"Unable to create a source for reading table '%s'.\\n\\n\"\n                                + \"Table options are:\\n\\n\"\n                                + \"%s\",\n                        objectIdentifier.asSummaryString(),\n                        catalogTable.getOptions().entrySet().stream()\n                                .map(e -> stringifyOption(e.getKey(), e.getValue()))\n                                .sorted()\n                                .collect(Collectors.joining(\"\\n\"))),\n                t);\n    }\n}", "summary_tokens": ["creates", "a", "dynamic", "table", "source", "from", "a", "catalog", "table"], "project": "flink"}
{"id": 2066, "code": "public static void writeNullableString(@Nullable String str, DataOutputView out)\n        throws IOException {\n    if (str != null) {\n        out.writeBoolean(true);\n        writeString(str, out);\n    } else {\n        out.writeBoolean(false);\n    }\n}", "summary_tokens": ["writes", "a", "string", "to", "the", "given", "output"], "project": "flink"}
{"id": 6836, "code": "public void testBasicSnapshot() {\n        \n    CopyOnWriteSkipListStateMapSnapshot<Integer, Long, String> snapshot =\n            stateMap.stateSnapshot();\n    snapshot.release();\n        \n    stateMap.put(1, namespace, \"1\");\n        \n    CopyOnWriteSkipListStateMapSnapshot<Integer, Long, String> snapshot2 =\n            stateMap.stateSnapshot();\n    assertEquals(2, stateMap.getStateMapVersion());\n    assertEquals(2, stateMap.getHighestRequiredSnapshotVersionPlusOne());\n    assertEquals(1, stateMap.getSnapshotVersions().size());\n    assertThat(stateMap.getSnapshotVersions(), contains(2));\n    assertEquals(1, stateMap.getResourceGuard().getLeaseCount());\n    snapshot2.release();\n    stateMap.close();\n}", "summary_tokens": ["test", "basic", "snapshot", "correctness"], "project": "flink"}
{"id": 2056, "code": "public static void removeShutdownHook(\n        final Thread shutdownHook, final String serviceName, final Logger logger) {\n\n        \n    if (shutdownHook == null || shutdownHook == Thread.currentThread()) {\n        return;\n    }\n\n    checkNotNull(logger);\n\n    try {\n        Runtime.getRuntime().removeShutdownHook(shutdownHook);\n    } catch (IllegalStateException e) {\n            \n        logger.debug(\n                \"Unable to remove shutdown hook for {}, shutdown already in progress\",\n                serviceName,\n                e);\n    } catch (Throwable t) {\n        logger.warn(\"Exception while un-registering {}'s shutdown hook.\", serviceName, t);\n    }\n}", "summary_tokens": ["removes", "a", "shutdown", "hook", "from", "the", "jvm"], "project": "flink"}
{"id": 3513, "code": "public final void write(String path) {\n    final Path savepointPath = new Path(path);\n\n    List<BootstrapTransformationWithID<?>> newOperatorTransformations =\n            metadata.getNewOperators();\n    DataSet<OperatorState> newOperatorStates =\n            writeOperatorStates(newOperatorTransformations, configuration, savepointPath);\n\n    List<OperatorState> existingOperators = metadata.getExistingOperators();\n\n    DataSet<OperatorState> finalOperatorStates;\n    if (existingOperators.isEmpty()) {\n        finalOperatorStates = newOperatorStates;\n    } else {\n        DataSet<OperatorState> existingOperatorStates =\n                newOperatorStates\n                        .getExecutionEnvironment()\n                        .fromCollection(existingOperators)\n                        .name(\"existingOperatorStates\");\n\n        existingOperatorStates\n                .flatMap(new StatePathExtractor())\n                .setParallelism(1)\n                .output(new FileCopyFunction(path));\n\n        finalOperatorStates = newOperatorStates.union(existingOperatorStates);\n    }\n    finalOperatorStates\n            .reduceGroup(new MergeOperatorStates(metadata.getMasterStates()))\n            .name(\"reduce(OperatorState)\")\n            .output(new SavepointOutputFormat(savepointPath))\n            .name(path);\n}", "summary_tokens": ["write", "out", "a", "new", "or", "updated", "savepoint"], "project": "flink"}
{"id": 5144, "code": "private CompletableFuture<Boolean> startResourceManagerIfIsLeader(\n        ResourceManager<?> resourceManager) {\n    if (isLeader(resourceManager)) {\n        resourceManager.start();\n        forwardTerminationFuture(resourceManager);\n        return resourceManager.getStartedFuture().thenApply(ignore -> true);\n    } else {\n        return CompletableFuture.completedFuture(false);\n    }\n}", "summary_tokens": ["returns", "a", "future", "that", "completes", "as", "true", "if", "the", "resource", "manager", "is", "still", "leader", "and", "started", "and", "false", "if", "it", "s", "no", "longer", "leader"], "project": "flink"}
{"id": 6026, "code": "public void testAccumulatorsAndMetricsStorage() throws Exception {\n    final JobVertexID jid1 = new JobVertexID();\n    final JobVertexID jid2 = new JobVertexID();\n\n    JobVertex v1 = new JobVertex(\"v1\", jid1);\n    JobVertex v2 = new JobVertex(\"v2\", jid2);\n\n    SchedulerBase scheduler = setupScheduler(v1, 1, v2, 1);\n    Map<ExecutionAttemptID, Execution> executions =\n            scheduler.getExecutionGraph().getRegisteredExecutions();\n\n    IOMetrics ioMetrics = new IOMetrics(0, 0, 0, 0);\n    Map<String, Accumulator<?, ?>> accumulators = Collections.emptyMap();\n\n    Execution execution1 = executions.values().iterator().next();\n    execution1.cancel();\n    execution1.completeCancelling(accumulators, ioMetrics, false);\n\n    assertEquals(ioMetrics, execution1.getIOMetrics());\n    assertEquals(accumulators, execution1.getUserAccumulators());\n\n    Execution execution2 = executions.values().iterator().next();\n    execution2.markFailed(new Throwable(), false, accumulators, ioMetrics, false, true);\n\n    assertEquals(ioMetrics, execution2.getIOMetrics());\n    assertEquals(accumulators, execution2.getUserAccumulators());\n}", "summary_tokens": ["verifies", "that", "execution", "complete", "cancelling", "map", "iometrics", "boolean", "and", "execution", "mark", "failed", "throwable", "boolean", "map", "iometrics", "boolean", "boolean", "store", "the", "given", "accumulators", "and", "metrics", "correctly"], "project": "flink"}
{"id": 1387, "code": "public static void setNestedSerializersSnapshots(\n        CompositeTypeSerializerSnapshot<?, ?> compositeSnapshot,\n        TypeSerializerSnapshot<?>... nestedSnapshots) {\n\n    NestedSerializersSnapshotDelegate delegate =\n            new NestedSerializersSnapshotDelegate(nestedSnapshots);\n    compositeSnapshot.setNestedSerializersSnapshotDelegate(delegate);\n}", "summary_tokens": ["overrides", "the", "existing", "nested", "serializer", "s", "snapshots", "with", "the", "provided", "nested", "snapshots"], "project": "flink"}
{"id": 4825, "code": "protected void onReleaseTaskManager(ResourceCounter previouslyFulfilledRequirement) {}", "summary_tokens": ["this", "method", "is", "called", "when", "a", "task", "manager", "is", "released"], "project": "flink"}
{"id": 6463, "code": "public void testUploadCleanupOnFailure() throws IOException {\n    OkHttpClient client = createOkHttpClientWithNoTimeouts();\n\n    Request request =\n            buildMalformedRequest(\n                    multipartUpdateResource\n                            .getMixedHandler()\n                            .getMessageHeaders()\n                            .getTargetRestEndpointURL());\n    try (Response response = client.newCall(request).execute()) {\n            \n        assertEquals(HttpResponseStatus.INTERNAL_SERVER_ERROR.code(), response.code());\n    }\n    multipartUpdateResource.assertUploadDirectoryIsEmpty();\n\n    verifyNoFileIsRegisteredToDeleteOnExitHook();\n}", "summary_tokens": ["crashes", "the", "handler", "be", "submitting", "a", "malformed", "multipart", "request", "and", "tests", "that", "the", "upload", "directory", "is", "cleaned", "up"], "project": "flink"}
{"id": 7496, "code": "long getCheckpointStartDelayNanos() {\n    return barrierHandler.getCheckpointStartDelayNanos();\n}", "summary_tokens": ["the", "time", "that", "elapsed", "in", "nanoseconds", "between", "the", "creation", "of", "the", "latest", "checkpoint", "and", "the", "time", "when", "it", "s", "first", "checkpoint", "barrier", "was", "received", "by", "this", "input", "gate"], "project": "flink"}
{"id": 2599, "code": "public boolean reachedEnd() throws IOException {\n    return !ensureBatch();\n}", "summary_tokens": ["method", "used", "to", "check", "if", "the", "end", "of", "the", "input", "is", "reached"], "project": "flink"}
{"id": 715, "code": "public void testFailureRecoveryProcessingTime() throws Exception {\n    testKafkaShuffleFailureRecovery(1000, ProcessingTime);\n}", "summary_tokens": ["failure", "recovery", "after", "processing", "0", "0", "data", "with", "time", "characteristic", "processing", "time"], "project": "flink"}
{"id": 2531, "code": "public void testForGeneric_withValidParams_succeeds() {\n    assertThat(\n            new GlueSchemaRegistryJsonDeserializationSchema<>(\n                    JsonDataWithSchema.class, testTopic, configs),\n            notNullValue());\n    assertThat(\n            new GlueSchemaRegistryJsonDeserializationSchema<>(\n                    JsonDataWithSchema.class, testTopic, configs),\n            instanceOf(GlueSchemaRegistryJsonDeserializationSchema.class));\n}", "summary_tokens": ["test", "initialization", "for", "generic", "type", "json", "schema", "works"], "project": "flink"}
{"id": 1174, "code": "public Path getFilePath() {\n\n    if (supportsMultiPaths()) {\n        if (this.filePaths == null || this.filePaths.length == 0) {\n            return null;\n        } else if (this.filePaths.length == 1) {\n            return this.filePaths[0];\n        } else {\n            throw new UnsupportedOperationException(\n                    \"FileInputFormat is configured with multiple paths. Use getFilePaths() instead.\");\n        }\n    } else {\n        return filePath;\n    }\n}", "summary_tokens": ["the", "path", "of", "the", "file", "to", "read"], "project": "flink"}
{"id": 5640, "code": "public static String getGitCommitTimeString() {\n    return getVersionsInstance().gitCommitTimeStr;\n}", "summary_tokens": ["the", "instant", "of", "the", "last", "commit", "of", "this", "code", "as", "a", "string", "using", "the", "europe", "berlin", "timezone"], "project": "flink"}
{"id": 965, "code": "public Integer getNetworkRecoveryInterval() {\n    return networkRecoveryInterval;\n}", "summary_tokens": ["returns", "automatic", "connection", "recovery", "interval", "in", "milliseconds"], "project": "flink"}
{"id": 7094, "code": "public DataStreamSink<T> disableChaining() {\n    this.transformation.setChainingStrategy(ChainingStrategy.NEVER);\n    return this;\n}", "summary_tokens": ["turns", "off", "chaining", "for", "this", "operator", "so", "thread", "co", "location", "will", "not", "be", "used", "as", "an", "optimization"], "project": "flink"}
{"id": 508, "code": "private void abortTransactionsWithPrefix(String prefix, long startCheckpointId) {\n    for (int subtaskId = this.subtaskId; ; subtaskId += parallelism) {\n        if (abortTransactionOfSubtask(prefix, startCheckpointId, subtaskId) == 0) {\n                \n                \n            break;\n        }\n    }\n}", "summary_tokens": ["aborts", "all", "transactions", "that", "have", "been", "created", "by", "this", "subtask", "in", "a", "previous", "run"], "project": "flink"}
{"id": 429, "code": "public void addCopyTranslation(HiveParserASTNode targetNode, HiveParserASTNode sourceNode) {\n    if (!enabled) {\n        return;\n    }\n\n    if (targetNode.getOrigin() != null) {\n        return;\n    }\n\n    CopyTranslation copyTranslation = new CopyTranslation();\n    copyTranslation.targetNode = targetNode;\n    copyTranslation.sourceNode = sourceNode;\n    copyTranslations.add(copyTranslation);\n}", "summary_tokens": ["register", "a", "copy", "translation", "in", "which", "a", "node", "will", "be", "translated", "into", "whatever", "the", "translation", "turns", "out", "to", "be", "for", "another", "node", "after", "previously", "registered", "translations", "have", "already", "been", "performed"], "project": "flink"}
{"id": 1916, "code": "public static final float parseField(byte[] bytes, int startPos, int length, char delimiter) {\n    final int limitedLen = nextStringLength(bytes, startPos, length, delimiter);\n\n    if (limitedLen > 0\n            && (Character.isWhitespace(bytes[startPos])\n                    || Character.isWhitespace(bytes[startPos + limitedLen - 1]))) {\n        throw new NumberFormatException(\n                \"There is leading or trailing whitespace in the numeric field.\");\n    }\n\n    final String str = new String(bytes, startPos, limitedLen, ConfigConstants.DEFAULT_CHARSET);\n    return Float.parseFloat(str);\n}", "summary_tokens": ["static", "utility", "to", "parse", "a", "field", "of", "type", "float", "from", "a", "byte", "sequence", "that", "represents", "text", "characters", "such", "as", "when", "read", "from", "a", "file", "stream"], "project": "flink"}
{"id": 1065, "code": "public void enableAutoGeneratedUIDs() {\n    enableAutoGeneratedUids = true;\n}", "summary_tokens": ["enables", "the", "flink", "runtime", "to", "auto", "generate", "uid", "s", "for", "operators"], "project": "flink"}
{"id": 4072, "code": "private void respondWithFile(ChannelHandlerContext ctx, HttpRequest request, String requestPath)\n        throws IOException, ParseException, RestHandlerException {\n\n        \n    if (requestPath.endsWith(\"/\")) {\n        requestPath = requestPath + \"index.html\";\n    }\n\n    if (!requestPath.contains(\".\")) { \n        requestPath = requestPath + \".json\";\n    }\n\n        \n    final File file = new File(rootPath, requestPath);\n\n    if (!file.exists()) {\n            \n        ClassLoader cl = HistoryServerStaticFileServerHandler.class.getClassLoader();\n\n        try (InputStream resourceStream = cl.getResourceAsStream(\"web\" + requestPath)) {\n            boolean success = false;\n            try {\n                if (resourceStream != null) {\n                    URL root = cl.getResource(\"web\");\n                    URL requested = cl.getResource(\"web\" + requestPath);\n\n                    if (root != null && requested != null) {\n                        URI rootURI = new URI(root.getPath()).normalize();\n                        URI requestedURI = new URI(requested.getPath()).normalize();\n\n                            \n                            \n                        if (!rootURI.relativize(requestedURI).equals(requestedURI)) {\n                            LOG.debug(\"Loading missing file from classloader: {}\", requestPath);\n                                \n                            file.getParentFile().mkdirs();\n                            Files.copy(resourceStream, file.toPath());\n\n                            success = true;\n                        }\n                    }\n                }\n            } catch (Throwable t) {\n                LOG.error(\"error while responding\", t);\n            } finally {\n                if (!success) {\n                    LOG.debug(\"Unable to load requested file {} from classloader\", requestPath);\n                    throw new NotFoundException(\"File not found.\");\n                }\n            }\n        }\n    }\n\n    StaticFileServerHandler.checkFileValidity(file, rootPath, LOG);\n\n        \n    final String ifModifiedSince = request.headers().get(IF_MODIFIED_SINCE);\n    if (ifModifiedSince != null && !ifModifiedSince.isEmpty()) {\n        SimpleDateFormat dateFormatter =\n                new SimpleDateFormat(StaticFileServerHandler.HTTP_DATE_FORMAT, Locale.US);\n        Date ifModifiedSinceDate = dateFormatter.parse(ifModifiedSince);\n\n            \n            \n        long ifModifiedSinceDateSeconds = ifModifiedSinceDate.getTime() / 1000;\n        long fileLastModifiedSeconds = file.lastModified() / 1000;\n        if (ifModifiedSinceDateSeconds == fileLastModifiedSeconds) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\n                        \"Responding 'NOT MODIFIED' for file '\" + file.getAbsolutePath() + '\\'');\n            }\n\n            StaticFileServerHandler.sendNotModified(ctx);\n            return;\n        }\n    }\n\n    if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Responding with file '\" + file.getAbsolutePath() + '\\'');\n    }\n\n    // Don't need to close this manually. Netty's DefaultFileRegion will take care of it.\n    final RandomAccessFile raf;\n    try {\n        raf = new RandomAccessFile(file, \"r\");\n    } catch (FileNotFoundException e) {\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\"Could not find file {}.\", file.getAbsolutePath());\n        }\n        HandlerUtils.sendErrorResponse(\n                ctx,\n                request,\n                new ErrorResponseBody(\"File not found.\"),\n                NOT_FOUND,\n                Collections.emptyMap());\n        return;\n    }\n\n    try {\n        long fileLength = raf.length();\n\n        HttpResponse response = new DefaultHttpResponse(HTTP_1_1, OK);\n        StaticFileServerHandler.setContentTypeHeader(response, file);\n\n        // the job overview should be updated as soon as possible\n        if (!requestPath.equals(\"/joboverview.json\")) {\n            StaticFileServerHandler.setDateAndCacheHeaders(response, file);\n        }\n        if (HttpHeaders.isKeepAlive(request)) {\n            response.headers().set(CONNECTION, HttpHeaders.Values.KEEP_ALIVE);\n        }\n        HttpHeaders.setContentLength(response, fileLength);\n\n        // write the initial line and the header.\n        ctx.write(response);\n\n        // write the content.\n        ChannelFuture lastContentFuture;\n        if (ctx.pipeline().get(SslHandler.class) == null) {\n            ctx.write(\n                    new DefaultFileRegion(raf.getChannel(), 0, fileLength),\n                    ctx.newProgressivePromise());\n            lastContentFuture = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT);\n        } else {\n            lastContentFuture =\n                    ctx.writeAndFlush(\n                            new HttpChunkedInput(new ChunkedFile(raf, 0, fileLength, 8192)),\n                            ctx.newProgressivePromise());\n            // HttpChunkedInput will write the end marker (LastHttpContent) for us.\n        }\n\n        // close the connection, if no keep-alive is needed\n        if (!HttpHeaders.isKeepAlive(request)) {\n            lastContentFuture.addListener(ChannelFutureListener.CLOSE);\n        }\n    } catch (Exception e) {\n        raf.close();\n        LOG.error(\"Failed to serve file.\", e);\n        throw new RestHandlerException(\"Internal server error.\", INTERNAL_SERVER_ERROR);\n    }\n}", "summary_tokens": ["response", "when", "running", "with", "leading", "job", "manager"], "project": "flink"}
{"id": 4124, "code": "public final int getMinOffloadingSize() {\n    return blobServiceConfiguration.getInteger(BlobServerOptions.OFFLOAD_MINSIZE);\n}", "summary_tokens": ["returns", "the", "configuration", "used", "by", "the", "blob", "server"], "project": "flink"}
{"id": 8728, "code": "private void validateStrongPolicy(RexNode rexNode) {\n    if (hasCustomNullabilityRules(rexNode.getKind())) {\n        return;\n    }\n    switch (Strong.policy(rexNode)) {\n        case NOT_NULL:\n            assert !rexNode.getType().isNullable();\n            break;\n        case ANY:\n            List<RexNode> operands = ((RexCall) rexNode).getOperands();\n            if (rexNode.getType().isNullable()) {\n                assert operands.stream()\n                        .map(RexNode::getType)\n                        .anyMatch(RelDataType::isNullable);\n            } else {\n                assert operands.stream()\n                        .map(RexNode::getType)\n                        .noneMatch(RelDataType::isNullable);\n            }\n    }\n}", "summary_tokens": ["validates", "strong", "policy", "for", "specified", "rex", "node"], "project": "flink"}
{"id": 2172, "code": "public int[] getNext(boolean blocking) throws InterruptedException {\n    Integer value = blocking ? records.take() : records.poll();\n    return value == null ? null : new int[] {value, index++};\n}", "summary_tokens": ["get", "the", "next", "element"], "project": "flink"}
{"id": 3298, "code": "public static <K, VV, EV, M> GatherSumApplyIteration<K, VV, EV, M> withEdges(\n        DataSet<Edge<K, EV>> edges,\n        GatherFunction<VV, EV, M> gather,\n        SumFunction<VV, EV, M> sum,\n        ApplyFunction<K, VV, M> apply,\n        int maximumNumberOfIterations) {\n\n    return new GatherSumApplyIteration<>(gather, sum, apply, edges, maximumNumberOfIterations);\n}", "summary_tokens": ["creates", "a", "new", "gather", "sum", "apply", "iteration", "operator", "for", "graphs"], "project": "flink"}
{"id": 9476, "code": "public static RowData row(Object... fields) {\n    return rowOfKind(RowKind.INSERT, fields);\n}", "summary_tokens": ["receives", "a", "object", "array", "generates", "a", "row", "data", "based", "on", "the", "array"], "project": "flink"}
{"id": 5723, "code": "private void triggerThreadInfoSampleInternal(\n        final Key key, final AccessExecutionJobVertex vertex) {\n    assert (Thread.holdsLock(lock));\n\n    if (shutDown) {\n        return;\n    }\n\n    if (!pendingStats.contains(key)) {\n        pendingStats.add(key);\n\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(\n                    \"Triggering thread info sample for tasks: {}\",\n                    Arrays.toString(vertex.getTaskVertices()));\n        }\n\n        final AccessExecutionVertex[] executionVertices = vertex.getTaskVertices();\n        final CompletableFuture<ResourceManagerGateway> gatewayFuture =\n                resourceManagerGatewayRetriever.getFuture();\n\n        CompletableFuture<JobVertexThreadInfoStats> sample =\n                gatewayFuture.thenCompose(\n                        (ResourceManagerGateway resourceManagerGateway) ->\n                                coordinator.triggerThreadInfoRequest(\n                                        matchExecutionsWithGateways(\n                                                executionVertices, resourceManagerGateway),\n                                        numSamples,\n                                        delayBetweenSamples,\n                                        maxThreadInfoDepth));\n\n        sample.whenCompleteAsync(new ThreadInfoSampleCompletionCallback(key, vertex), executor);\n    }\n}", "summary_tokens": ["triggers", "a", "request", "for", "a", "vertex", "to", "gather", "the", "thread", "info", "statistics"], "project": "flink"}
{"id": 2796, "code": "public O setParallelism(int parallelism) {\n    OperatorValidationUtils.validateParallelism(parallelism);\n\n    this.parallelism = parallelism;\n\n    @SuppressWarnings(\"unchecked\")\n    O returnType = (O) this;\n    return returnType;\n}", "summary_tokens": ["sets", "the", "parallelism", "for", "this", "operator"], "project": "flink"}
{"id": 5062, "code": "public boolean offer(T element) {\n    if (size < capacity) {\n        put(element);\n        return true;\n    } else if (size > 0 && !lessThan(element, peek())) {\n        heap[1] = element;\n        adjustTop();\n        return true;\n    } else {\n        return false;\n    }\n}", "summary_tokens": ["adds", "element", "to", "the", "priority", "queue", "in", "log", "size", "time", "if", "either", "the", "priority", "queue", "is", "not", "full", "or", "not", "less", "than", "element", "top"], "project": "flink"}
{"id": 408, "code": "public HiveParserASTNode getExpressionSource(HiveParserASTNode node) {\n    return expressionMap.get(node.toStringTree());\n}", "summary_tokens": ["retrieves", "the", "source", "expression", "matching", "a", "given", "hive", "parser", "astnode", "s", "string", "rendering", "exactly"], "project": "flink"}
{"id": 8664, "code": "public static int timestampMillisToDate(long ts) {\n    int days = (int) (ts / MILLIS_PER_DAY);\n    if (days < 0) {\n        days = days - 1;\n    }\n    return days;\n}", "summary_tokens": ["get", "date", "from", "a", "timestamp"], "project": "flink"}
{"id": 3745, "code": "public void testClosure() {\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n    DataSet<Long> sourceA = env.generateSequence(0, 1);\n    DataSet<Long> sourceB = env.generateSequence(0, 1);\n\n    sourceA.output(new DiscardingOutputFormat<Long>());\n    sourceB.output(new DiscardingOutputFormat<Long>());\n\n    IterativeDataSet<Long> loopHead = sourceA.iterate(10).name(\"Loop\");\n\n    DataSet<Long> loopTail = loopHead.cross(sourceB).with(new IdentityCrosser<Long>());\n    DataSet<Long> loopRes = loopHead.closeWith(loopTail);\n\n    loopRes.output(new DiscardingOutputFormat<Long>());\n\n    Plan plan = env.createProgramPlan();\n\n    try {\n        compileNoStats(plan);\n    } catch (Exception e) {\n        e.printStackTrace();\n        Assert.fail(e.getMessage());\n    }\n}", "summary_tokens": ["test", "to", "ensure", "that", "source", "a", "is", "inside", "as", "well", "as", "outside", "of", "the", "iteration", "the", "same", "node"], "project": "flink"}
{"id": 2209, "code": "public void testSetNegativePosition() throws Exception {\n    stream.write(new byte[BUFFER_SIZE]);\n\n    thrown.expect(IllegalArgumentException.class);\n    thrown.expectMessage(\"Position out of bounds\");\n    stream.setPosition(-1);\n}", "summary_tokens": ["test", "setting", "negative", "position"], "project": "flink"}
{"id": 9156, "code": "public static <T> Class<T> compile(ClassLoader cl, String name, String code) {\n    try {\n        Cache<ClassLoader, Class> compiledClasses =\n                COMPILED_CACHE.get(\n                            \n                            \n                        code,\n                        () ->\n                                CacheBuilder.newBuilder()\n                                        .maximumSize(5)\n                                        .weakKeys()\n                                        .softValues()\n                                        .build());\n        return compiledClasses.get(cl, () -> doCompile(cl, name, code));\n    } catch (Exception e) {\n        throw new FlinkRuntimeException(e.getMessage(), e);\n    }\n}", "summary_tokens": ["compiles", "a", "generated", "code", "to", "a", "class"], "project": "flink"}
{"id": 6840, "code": "public void testNamespaceNodeIteratorIllegalNextInvocation() {\n    SkipListKeySerializer<Integer, Long> skipListKeySerializer =\n            new SkipListKeySerializer<>(IntSerializer.INSTANCE, LongSerializer.INSTANCE);\n    byte[] namespaceBytes = skipListKeySerializer.serializeNamespace(namespace);\n    MemorySegment namespaceSegment = MemorySegmentFactory.wrap(namespaceBytes);\n    Iterator<Long> iterator =\n            stateMap.new NamespaceNodeIterator(namespaceSegment, 0, namespaceBytes.length);\n    while (iterator.hasNext()) {\n        iterator.next();\n    }\n    try {\n        iterator.next();\n        fail(\"Should have thrown NoSuchElementException.\");\n    } catch (NoSuchElementException e) {\n            \n    }\n}", "summary_tokens": ["test", "state", "map", "iterator", "illegal", "next", "call"], "project": "flink"}
{"id": 5559, "code": "public static TaskManagerServicesConfiguration fromConfiguration(\n        Configuration configuration,\n        ResourceID resourceID,\n        String externalAddress,\n        boolean localCommunicationOnly,\n        TaskExecutorResourceSpec taskExecutorResourceSpec)\n        throws Exception {\n    final String[] tmpDirs = ConfigurationUtils.parseTempDirectories(configuration);\n    String[] localStateRootDir = ConfigurationUtils.parseLocalStateDirectories(configuration);\n    if (localStateRootDir.length == 0) {\n            \n        localStateRootDir = tmpDirs;\n    }\n\n    boolean localRecoveryMode = configuration.getBoolean(CheckpointingOptions.LOCAL_RECOVERY);\n\n    final QueryableStateConfiguration queryableStateConfig =\n            QueryableStateConfiguration.fromConfiguration(configuration);\n\n    long timerServiceShutdownTimeout =\n            configuration.get(AkkaOptions.ASK_TIMEOUT_DURATION).toMillis();\n\n    final RetryingRegistrationConfiguration retryingRegistrationConfiguration =\n            RetryingRegistrationConfiguration.fromConfiguration(configuration);\n\n    final int externalDataPort =\n            configuration.getInteger(NettyShuffleEnvironmentOptions.DATA_PORT);\n\n    String bindAddr =\n            configuration.getString(\n                    TaskManagerOptions.BIND_HOST, NetUtils.getWildcardIPAddress());\n    InetAddress bindAddress = InetAddress.getByName(bindAddr);\n\n    final String classLoaderResolveOrder =\n            configuration.getString(CoreOptions.CLASSLOADER_RESOLVE_ORDER);\n\n    final String[] alwaysParentFirstLoaderPatterns =\n            CoreOptions.getParentFirstLoaderPatterns(configuration);\n\n    final int numIoThreads = ClusterEntrypointUtils.getPoolSize(configuration);\n\n    return new TaskManagerServicesConfiguration(\n            configuration,\n            resourceID,\n            externalAddress,\n            bindAddress,\n            externalDataPort,\n            localCommunicationOnly,\n            tmpDirs,\n            localStateRootDir,\n            localRecoveryMode,\n            queryableStateConfig,\n            ConfigurationParserUtils.getSlot(configuration),\n            ConfigurationParserUtils.getPageSize(configuration),\n            taskExecutorResourceSpec,\n            timerServiceShutdownTimeout,\n            retryingRegistrationConfiguration,\n            ConfigurationUtils.getSystemResourceMetricsProbingInterval(configuration),\n            FlinkUserCodeClassLoaders.ResolveOrder.fromString(classLoaderResolveOrder),\n            alwaysParentFirstLoaderPatterns,\n            numIoThreads);\n}", "summary_tokens": ["utility", "method", "to", "extract", "task", "manager", "config", "parameters", "from", "the", "configuration", "and", "to", "sanity", "check", "them"], "project": "flink"}
{"id": 7216, "code": "public Configuration getClientConfiguration() {\n    return configuration;\n}", "summary_tokens": ["this", "method", "is", "going", "to", "be", "removed", "in", "the", "next", "releases"], "project": "flink"}
{"id": 1308, "code": "public int[] toArray() {\n    int[] a = new int[this.collection.size()];\n    int i = 0;\n    for (int col : this.collection) {\n        a[i++] = col;\n    }\n    return a;\n}", "summary_tokens": ["transforms", "the", "field", "set", "into", "an", "array", "of", "field", "ids"], "project": "flink"}
{"id": 9635, "code": "public void testCoProcessFunctionSideOutput() throws Exception {\n    final OutputTag<String> sideOutputTag = new OutputTag<String>(\"side\") {};\n\n    TestListResultSink<String> sideOutputResultSink = new TestListResultSink<>();\n    TestListResultSink<Integer> resultSink = new TestListResultSink<>();\n\n    StreamExecutionEnvironment see = StreamExecutionEnvironment.getExecutionEnvironment();\n    see.setParallelism(3);\n\n    DataStream<Integer> ds1 = see.fromCollection(elements);\n    DataStream<Integer> ds2 = see.fromCollection(elements);\n\n    SingleOutputStreamOperator<Integer> passThroughtStream =\n            ds1.connect(ds2)\n                    .process(\n                            new CoProcessFunction<Integer, Integer, Integer>() {\n                                @Override\n                                public void processElement1(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value < 3) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag,\n                                                \"sideout1-\" + String.valueOf(value));\n                                    }\n                                }\n\n                                @Override\n                                public void processElement2(\n                                        Integer value, Context ctx, Collector<Integer> out)\n                                        throws Exception {\n                                    if (value >= 3) {\n                                        out.collect(value);\n                                        ctx.output(\n                                                sideOutputTag,\n                                                \"sideout2-\" + String.valueOf(value));\n                                    }\n                                }\n                            });\n\n    passThroughtStream.getSideOutput(sideOutputTag).addSink(sideOutputResultSink);\n    passThroughtStream.addSink(resultSink);\n    see.execute();\n\n    assertEquals(\n            Arrays.asList(\"sideout1-1\", \"sideout1-2\", \"sideout2-3\", \"sideout2-4\", \"sideout2-5\"),\n            sideOutputResultSink.getSortedResult());\n    assertEquals(Arrays.asList(1, 2, 3, 4, 5), resultSink.getSortedResult());\n}", "summary_tokens": ["test", "co", "process", "function", "side", "output"], "project": "flink"}
{"id": 4967, "code": "private void insertBucketEntryFromSearch(\n        MemorySegment originalBucket,\n        MemorySegment currentBucket,\n        int originalBucketOffset,\n        int currentBucketOffset,\n        int countInCurrentBucket,\n        long originalForwardPointer,\n        int hashCode,\n        long pointer,\n        int partitionNumber)\n        throws IOException {\n    boolean checkForResize = false;\n    if (countInCurrentBucket < NUM_ENTRIES_PER_BUCKET) {\n            \n        currentBucket.putInt(\n                currentBucketOffset\n                        + BUCKET_HEADER_LENGTH\n                        + (countInCurrentBucket * HASH_CODE_LEN),\n                hashCode); \n        currentBucket.putLong(\n                currentBucketOffset\n                        + BUCKET_POINTER_START_OFFSET\n                        + (countInCurrentBucket * POINTER_LEN),\n                pointer); \n        currentBucket.putInt(\n                currentBucketOffset + HEADER_COUNT_OFFSET,\n                countInCurrentBucket + 1); \n    } else {\n            \n        final InMemoryPartition<T> partition = this.partitions.get(partitionNumber);\n        MemorySegment overflowSeg;\n        final int overflowSegmentNum;\n        final int overflowBucketOffset;\n\n            \n            \n        if (partition.nextOverflowBucket == 0) {\n                \n            overflowSeg = getNextBuffer();\n            overflowBucketOffset = 0;\n            overflowSegmentNum = partition.numOverflowSegments;\n\n                \n            if (partition.overflowSegments.length <= partition.numOverflowSegments) {\n                MemorySegment[] newSegsArray =\n                        new MemorySegment[partition.overflowSegments.length * 2];\n                System.arraycopy(\n                        partition.overflowSegments,\n                        0,\n                        newSegsArray,\n                        0,\n                        partition.overflowSegments.length);\n                partition.overflowSegments = newSegsArray;\n            }\n            partition.overflowSegments[partition.numOverflowSegments] = overflowSeg;\n            partition.numOverflowSegments++;\n            checkForResize = true;\n        } else {\n                \n            overflowSegmentNum = partition.numOverflowSegments - 1;\n            overflowSeg = partition.overflowSegments[overflowSegmentNum];\n            overflowBucketOffset = partition.nextOverflowBucket << NUM_INTRA_BUCKET_BITS;\n        }\n\n            \n            \n            \n        partition.nextOverflowBucket =\n                (partition.nextOverflowBucket == this.bucketsPerSegmentMask\n                        ? 0\n                        : partition.nextOverflowBucket + 1);\n\n            \n\n            \n            \n        overflowSeg.putLong(\n                overflowBucketOffset + HEADER_FORWARD_OFFSET, originalForwardPointer);\n        final long pointerToNewBucket =\n                (((long) overflowSegmentNum) << 32) | ((long) overflowBucketOffset);\n        originalBucket.putLong(\n                originalBucketOffset + HEADER_FORWARD_OFFSET, pointerToNewBucket);\n\n            \n        overflowSeg.putInt(overflowBucketOffset + BUCKET_HEADER_LENGTH, hashCode); \n        overflowSeg.putLong(\n                overflowBucketOffset + BUCKET_POINTER_START_OFFSET, pointer); \n\n            \n        overflowSeg.putInt(overflowBucketOffset + HEADER_COUNT_OFFSET, 1);\n        if (checkForResize && !this.isResizing) {\n                \n            if (this.buckets.length <= getOverflowSegmentCount()) {\n                resizeHashTable();\n            }\n        }\n    }\n}", "summary_tokens": ["important", "we", "pass", "only", "the", "partition", "number", "because", "we", "must", "make", "sure", "we", "get", "a", "fresh", "partition", "reference"], "project": "flink"}
{"id": 5664, "code": "public int getTotalResourceCount() {\n    return resources.isEmpty() ? 0 : resources.values().stream().reduce(0, Integer::sum);\n}", "summary_tokens": ["computes", "the", "total", "number", "of", "resources", "in", "this", "counter"], "project": "flink"}
{"id": 3280, "code": "public <T> Collection<T> getBroadcastSet(String name) {\n    return this.runtimeContext.getBroadcastVariable(name);\n}", "summary_tokens": ["gets", "the", "broadcast", "data", "set", "registered", "under", "the", "given", "name"], "project": "flink"}
{"id": 1503, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 1592, "code": "private boolean isValidPojoField(Field f, Class<?> clazz, List<Type> typeHierarchy) {\n    if (Modifier.isPublic(f.getModifiers())) {\n        return true;\n    } else {\n        boolean hasGetter = false, hasSetter = false;\n        final String fieldNameLow = f.getName().toLowerCase().replaceAll(\"_\", \"\");\n\n        Type fieldType = f.getGenericType();\n        Class<?> fieldTypeWrapper = ClassUtils.primitiveToWrapper(f.getType());\n\n        TypeVariable<?> fieldTypeGeneric = null;\n        if (fieldType instanceof TypeVariable) {\n            fieldTypeGeneric = (TypeVariable<?>) fieldType;\n            fieldType = materializeTypeVariable(typeHierarchy, (TypeVariable<?>) fieldType);\n        }\n        for (Method m : clazz.getMethods()) {\n            final String methodNameLow =\n                    m.getName().endsWith(\"_$eq\")\n                            ? m.getName()\n                                    .toLowerCase()\n                                    .replaceAll(\"_\", \"\")\n                                    .replaceFirst(\"\\\\$eq$\", \"_\\\\$eq\")\n                            : m.getName().toLowerCase().replaceAll(\"_\", \"\");\n\n                \n            if ( \n                \n            (methodNameLow.equals(\"get\" + fieldNameLow)\n                            || methodNameLow.equals(\"is\" + fieldNameLow)\n                            || methodNameLow.equals(fieldNameLow))\n                    &&\n                        \n                    m.getParameterTypes().length == 0\n                    &&\n                        \n                    (m.getGenericReturnType().equals(fieldType)\n                            || (m.getReturnType().equals(fieldTypeWrapper))\n                            || (m.getGenericReturnType().equals(fieldTypeGeneric)))) {\n                hasGetter = true;\n            }\n                \n            if ((methodNameLow.equals(\"set\" + fieldNameLow)\n                            || methodNameLow.equals(fieldNameLow + \"_$eq\"))\n                    && m.getParameterTypes().length == 1\n                    && \n                    (m.getGenericParameterTypes()[0].equals(fieldType)\n                            || (m.getParameterTypes()[0].equals(fieldTypeWrapper))\n                            || (m.getGenericParameterTypes()[0].equals(fieldTypeGeneric)))\n                    &&\n                        \n                    (m.getReturnType().equals(Void.TYPE) || m.getReturnType().equals(clazz))) {\n                hasSetter = true;\n            }\n        }\n        if (hasGetter && hasSetter) {\n            return true;\n        } else {\n            if (!hasGetter && clazz != Row.class) {\n                LOG.info(clazz + \" does not contain a getter for field \" + f.getName());\n            }\n            if (!hasSetter && clazz != Row.class) {\n                LOG.info(clazz + \" does not contain a setter for field \" + f.getName());\n            }\n            return false;\n        }\n    }\n}", "summary_tokens": ["checks", "if", "the", "given", "field", "is", "a", "valid", "pojo", "field", "it", "is", "public", "or", "there", "are", "getter", "and", "setter", "methods", "for", "the", "field"], "project": "flink"}
{"id": 8399, "code": "default String asSerializableString() {\n    throw new TableException(\n            String.format(\n                    \"Expression '%s' is not string serializable. Currently, only expressions that \"\n                            + \"originated from a SQL expression have a well-defined string representation.\",\n                    asSummaryString()));\n}", "summary_tokens": ["returns", "a", "string", "that", "fully", "serializes", "this", "instance"], "project": "flink"}
{"id": 7972, "code": "default TableSource<T> createTableSource(Map<String, String> properties) {\n    StreamTableSource<T> source = createStreamTableSource(properties);\n    if (source == null) {\n        throw new ValidationException(\"Please override 'createTableSource(Context)' method.\");\n    }\n    return source;\n}", "summary_tokens": ["only", "create", "a", "stream", "table", "source"], "project": "flink"}
{"id": 9668, "code": "public void testMissingFieldWithOperatorState() throws Exception {\n    testPojoSerializerUpgrade(SOURCE_A, SOURCE_E, false, false);\n}", "summary_tokens": ["removing", "fields", "from", "a", "pojo", "as", "operator", "state", "should", "succeed"], "project": "flink"}
{"id": 6222, "code": "public void testIsAvailableOrNot() throws IOException {\n    final int numAllBuffers = 10;\n    final int bufferSize = 1024;\n    final NettyShuffleEnvironment network =\n            new NettyShuffleEnvironmentBuilder()\n                    .setNumNetworkBuffers(numAllBuffers)\n                    .setBufferSize(bufferSize)\n                    .build();\n    final ResultPartition resultPartition =\n            createPartition(network, ResultPartitionType.PIPELINED, 1);\n\n    try {\n        resultPartition.setup();\n\n        resultPartition.getBufferPool().setNumBuffers(2);\n\n        assertTrue(resultPartition.getAvailableFuture().isDone());\n\n        resultPartition.emitRecord(ByteBuffer.allocate(bufferSize), 0);\n        resultPartition.emitRecord(ByteBuffer.allocate(bufferSize), 0);\n        assertFalse(resultPartition.getAvailableFuture().isDone());\n    } finally {\n        resultPartition.release();\n        network.close();\n    }\n}", "summary_tokens": ["tests", "result", "partition", "get", "available", "future"], "project": "flink"}
{"id": 1724, "code": "public int getNumberOfOpenOutputStreams() {\n    lock.lock();\n    try {\n        return numReservedOutputStreams;\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["gets", "the", "number", "of", "currently", "open", "output", "streams"], "project": "flink"}
{"id": 6549, "code": "public void testLoadFileSystemCheckpointStorageMixed() throws Exception {\n    final Path appCheckpointDir = new Path(tmp.newFolder().toURI());\n    final String checkpointDir = new Path(tmp.newFolder().toURI()).toString();\n    final String savepointDir = new Path(tmp.newFolder().toURI()).toString();\n\n    final Path expectedSavepointsPath = new Path(savepointDir);\n\n    final int threshold = 1000000;\n    final int writeBufferSize = 4000000;\n\n    final FileSystemCheckpointStorage storage =\n            new FileSystemCheckpointStorage(appCheckpointDir, threshold, writeBufferSize);\n\n    final Configuration config = new Configuration();\n    config.set(\n            CheckpointingOptions.CHECKPOINT_STORAGE,\n            \"jobmanager\"); \n    config.set(\n            CheckpointingOptions.CHECKPOINTS_DIRECTORY,\n            checkpointDir); \n    config.set(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir);\n    config.set(\n            CheckpointingOptions.FS_SMALL_FILE_THRESHOLD,\n            MemorySize.parse(\"20\")); \n    config.setInteger(\n            CheckpointingOptions.FS_WRITE_BUFFER_SIZE, 3000000); \n\n    final CheckpointStorage loadedStorage =\n            CheckpointStorageLoader.load(\n                    storage, null, new ModernStateBackend(), config, cl, log);\n    Assert.assertThat(loadedStorage, Matchers.instanceOf(FileSystemCheckpointStorage.class));\n\n    final FileSystemCheckpointStorage fs = (FileSystemCheckpointStorage) loadedStorage;\n    Assert.assertThat(fs.getCheckpointPath(), normalizedPath(appCheckpointDir));\n    Assert.assertThat(fs.getSavepointPath(), normalizedPath(expectedSavepointsPath));\n    Assert.assertEquals(threshold, fs.getMinFileSizeThreshold());\n    Assert.assertEquals(writeBufferSize, fs.getWriteBufferSize());\n}", "summary_tokens": ["validates", "taking", "the", "application", "defined", "file", "system", "state", "backend", "and", "adding", "with", "additional", "parameters", "from", "the", "cluster", "configuration", "but", "giving", "precedence", "to", "application", "defined", "parameters", "over", "configuration", "defined", "parameters"], "project": "flink"}
{"id": 196, "code": "default void open() {}", "summary_tokens": ["initialize", "the", "index", "generator", "this", "will", "be", "called", "only", "once", "before", "generate", "row", "data", "is", "called"], "project": "flink"}
{"id": 4616, "code": "public void finishWrite() throws IOException {\n    assert currentBuffer != null;\n\n    currentBuffer.flip();\n    fullBuffers.add(currentBuffer);\n    currentBuffer = null; \n    file.close(); \n}", "summary_tokens": ["finishes", "the", "current", "region", "and", "prevents", "further", "writes"], "project": "flink"}
{"id": 9708, "code": "public void shutdownYarnClient() {\n    yarnClient.stop();\n}", "summary_tokens": ["sleep", "a", "bit", "between", "the", "tests", "we", "are", "re", "using", "the", "yarn", "cluster", "for", "the", "tests"], "project": "flink"}
{"id": 4518, "code": "public File[] getSpillingDirectories() {\n    return fileChannelManager.getPaths();\n}", "summary_tokens": ["gets", "the", "directories", "that", "the", "i", "o", "manager", "spills", "to"], "project": "flink"}
{"id": 1245, "code": "public Configuration getParameters() {\n    return this.parameters;\n}", "summary_tokens": ["gets", "the", "stub", "parameters", "of", "this", "contract"], "project": "flink"}
{"id": 2325, "code": "public static synchronized void addDefaultResource(String name) {\n    if (!defaultResources.contains(name)) {\n        defaultResources.add(name);\n        for (Configuration conf : REGISTRY.keySet()) {\n            if (conf.loadDefaults) {\n                conf.reloadConfiguration();\n            }\n        }\n    }\n}", "summary_tokens": ["add", "a", "default", "resource"], "project": "flink"}
{"id": 2792, "code": "public int getParallelism() {\n    return this.parallelism;\n}", "summary_tokens": ["returns", "the", "parallelism", "of", "this", "operator"], "project": "flink"}
{"id": 7672, "code": "public void testProcessingTimeTimerWithState() throws Exception {\n\n    LegacyKeyedProcessOperator<Integer, Integer, String> operator =\n            new LegacyKeyedProcessOperator<>(\n                    new TriggeringStatefulFlatMapFunction(TimeDomain.PROCESSING_TIME));\n\n    OneInputStreamOperatorTestHarness<Integer, String> testHarness =\n            new KeyedOneInputStreamOperatorTestHarness<>(\n                    operator, new IdentityKeySelector<Integer>(), BasicTypeInfo.INT_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.setProcessingTime(1);\n    testHarness.processElement(new StreamRecord<>(17)); \n\n    testHarness.setProcessingTime(2);\n    testHarness.processElement(new StreamRecord<>(42)); \n\n    testHarness.setProcessingTime(6);\n    testHarness.setProcessingTime(7);\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    expectedOutput.add(new StreamRecord<>(\"INPUT:17\"));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:42\"));\n    expectedOutput.add(new StreamRecord<>(\"STATE:17\"));\n    expectedOutput.add(new StreamRecord<>(\"STATE:42\"));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.close();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "leakage", "between", "different", "keys"], "project": "flink"}
{"id": 4207, "code": "PendingCheckpointStats reportPendingCheckpoint(\n        long checkpointId,\n        long triggerTimestamp,\n        CheckpointProperties props,\n        Map<JobVertexID, Integer> vertexToDop) {\n\n    PendingCheckpointStats pending =\n            new PendingCheckpointStats(\n                    checkpointId,\n                    triggerTimestamp,\n                    props,\n                    vertexToDop,\n                    PendingCheckpointStatsCallback.proxyFor(this));\n\n    statsReadWriteLock.lock();\n    try {\n        counts.incrementInProgressCheckpoints();\n        history.addInProgressCheckpoint(pending);\n\n        dirty = true;\n    } finally {\n        statsReadWriteLock.unlock();\n    }\n\n    return pending;\n}", "summary_tokens": ["creates", "a", "new", "pending", "checkpoint", "tracker"], "project": "flink"}
{"id": 7935, "code": "public static void printHelpClient() {\n    System.out.println(\"./sql-client [MODE] [OPTIONS]\");\n    System.out.println();\n    System.out.println(\"The following options are available:\");\n\n    printHelpEmbeddedModeClient();\n    printHelpGatewayModeClient();\n\n    System.out.println();\n}", "summary_tokens": ["prints", "the", "help", "for", "the", "client"], "project": "flink"}
{"id": 5214, "code": "synchronized void addAll(List<MetricDump> metricDumps) {\n    for (MetricDump metric : metricDumps) {\n        add(metric);\n    }\n}", "summary_tokens": ["add", "metric", "dumps", "to", "the", "store"], "project": "flink"}
{"id": 2523, "code": "private long findNextLineStartOffset() throws IOException {\n    boolean usesEscapeChar = csvSchema.usesEscapeChar();\n    byte[] escapeBytes =\n            Character.toString((char) csvSchema.getEscapeChar())\n                    .getBytes(StandardCharsets.UTF_8);\n    long startPos = stream.getPos();\n\n    byte b;\n    while ((b = (byte) stream.read()) != -1) {\n        if (b == '\\r' || b == '\\n') {\n                \n            if (usesEscapeChar && stream.getPos() - startPos <= escapeBytes.length) {\n                long front = stream.getPos() - escapeBytes.length - 1;\n                if (front > 0) {\n                    stream.seek(front);\n                    byte[] readBytes = new byte[escapeBytes.length];\n                    stream.read(readBytes); \n                    stream.read(); \n                    if (Arrays.equals(escapeBytes, readBytes)) {\n                            \n                        continue;\n                    }\n                }\n            }\n\n            long pos = stream.getPos();\n\n                \n            if (b == '\\r' && (byte) stream.read() == '\\n') {\n                return stream.getPos();\n            } else {\n                return pos;\n            }\n        } else if (usesEscapeChar && b == escapeBytes[0]) {\n            boolean equal = true;\n            for (int i = 1; i < escapeBytes.length; i++) {\n                if ((byte) stream.read() != escapeBytes[i]) {\n                    equal = false;\n                    break;\n                }\n            }\n            if (equal) {\n                    \n                stream.skip(1);\n            }\n        }\n    }\n    return stream.getPos();\n}", "summary_tokens": ["find", "next", "legal", "line", "separator", "to", "return", "next", "offset", "first", "byte", "offset", "of", "next", "line"], "project": "flink"}
{"id": 4341, "code": "public MemorySize getOperatorsMemory() {\n    throwUnsupportedOperationExceptionIfUnknown();\n    return taskHeapMemory.add(taskOffHeapMemory).add(managedMemory);\n}", "summary_tokens": ["get", "the", "memory", "the", "operators", "needed"], "project": "flink"}
{"id": 3180, "code": "public Graph<K, VV, EV> filterOnEdges(FilterFunction<Edge<K, EV>> edgeFilter) {\n    DataSet<Edge<K, EV>> filteredEdges = this.edges.filter(edgeFilter).name(\"Filter on edges\");\n\n    return new Graph<>(this.vertices, filteredEdges, this.context);\n}", "summary_tokens": ["apply", "a", "filtering", "function", "to", "the", "graph", "and", "return", "a", "sub", "graph", "that", "satisfies", "the", "predicates", "only", "for", "the", "edges"], "project": "flink"}
{"id": 5629, "code": "public static <E> EmptyIterator<E> get() {\n    @SuppressWarnings(\"unchecked\")\n    EmptyIterator<E> iter = (EmptyIterator<E>) INSTANCE;\n    return iter;\n}", "summary_tokens": ["gets", "a", "singleton", "instance", "of", "the", "empty", "iterator"], "project": "flink"}
{"id": 7767, "code": "public void testClear() throws Exception {\n    TriggerTestHarness<Object, TimeWindow> testHarness =\n            new TriggerTestHarness<>(\n                    ContinuousEventTimeTrigger.<TimeWindow>of(Time.hours(1)),\n                    new TimeWindow.Serializer());\n\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(0, 2)));\n    assertEquals(\n            TriggerResult.CONTINUE,\n            testHarness.processElement(new StreamRecord<Object>(1), new TimeWindow(2, 4)));\n\n    assertEquals(2, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(4, testHarness.numEventTimeTimers());\n    assertEquals(2, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(2, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(2, 4));\n\n    assertEquals(1, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(3, testHarness.numEventTimeTimers());\n    assertEquals(2, testHarness.numEventTimeTimers(new TimeWindow(0, 2)));\n    assertEquals(1, testHarness.numEventTimeTimers(new TimeWindow(2, 4)));\n\n    testHarness.clearTriggerState(new TimeWindow(0, 2));\n\n    assertEquals(0, testHarness.numStateEntries());\n    assertEquals(0, testHarness.numProcessingTimeTimers());\n    assertEquals(2, testHarness.numEventTimeTimers()); \n}", "summary_tokens": ["verify", "that", "clear", "does", "not", "leak", "across", "windows"], "project": "flink"}
{"id": 8277, "code": "public BigDecimal toBigDecimal() {\n    BigDecimal bd = decimalVal;\n    if (bd == null) {\n        decimalVal = bd = BigDecimal.valueOf(longVal, scale);\n    }\n    return bd;\n}", "summary_tokens": ["converts", "this", "decimal", "data", "into", "an", "instance", "of", "big", "decimal"], "project": "flink"}
{"id": 541, "code": "public void recordSucceededCommit() {\n    commitsSucceeded.inc();\n}", "summary_tokens": ["mark", "a", "successful", "commit"], "project": "flink"}
{"id": 9223, "code": "public KeySelector<RowData, RowData> getUniqueKeySelector() {\n    return uniqueKeySelector;\n}", "summary_tokens": ["returns", "the", "key", "selector", "to", "extract", "unique", "key", "from", "the", "input", "row"], "project": "flink"}
{"id": 437, "code": "private static Future<Void> startHMS(HiveServerContext context, int port) throws Exception {\n    context.init();\n    context.getHiveConf().setVar(METASTOREURIS, \"thrift://localhost:\" + port);\n    HiveConf outsideConf = context.getHiveConf();\n    List<String> args = new ArrayList<>();\n    String javaHome = System.getProperty(\"java.home\");\n    args.add(Joiner.on(File.separator).join(javaHome, \"bin\", \"java\"));\n        \n    args.add(\"-cp\");\n    args.add(System.getProperty(\"java.class.path\"));\n\n        \n    args.add(\n            hiveCmdLineConfig(\n                    METASTOREWAREHOUSE.varname, outsideConf.getVar(METASTOREWAREHOUSE)));\n    args.add(hiveCmdLineConfig(SCRATCHDIR.varname, outsideConf.getVar(SCRATCHDIR)));\n    args.add(hiveCmdLineConfig(LOCALSCRATCHDIR.varname, outsideConf.getVar(LOCALSCRATCHDIR)));\n    args.add(\n            hiveCmdLineConfig(\n                    HIVEHISTORYFILELOC.varname, outsideConf.getVar(HIVEHISTORYFILELOC)));\n        \n    args.add(\n            hiveCmdLineConfig(\n                    \"hive.warehouse.subdir.inherit.perms\",\n                    String.valueOf(\n                            outsideConf.getBoolean(\n                                    \"hive.warehouse.subdir.inherit.perms\", true))));\n    args.add(hiveCmdLineConfig(\"hadoop.tmp.dir\", outsideConf.get(\"hadoop.tmp.dir\")));\n    args.add(hiveCmdLineConfig(\"test.log.dir\", outsideConf.get(\"test.log.dir\")));\n    args.add(\n            hiveCmdLineConfig(\n                    METASTORECONNECTURLKEY.varname,\n                    outsideConf.getVar(METASTORECONNECTURLKEY)));\n        \n    File derbyLog = File.createTempFile(\"derby\", \".log\");\n    derbyLog.deleteOnExit();\n    args.add(hiveCmdLineConfig(\"derby.stream.error.file\", derbyLog.getAbsolutePath()));\n        \n    if (outsideConf.getBoolVar(HIVE_IN_TEST)) {\n        args.add(hiveCmdLineConfig(HIVE_IN_TEST.varname, \"true\"));\n    }\n\n    args.add(HiveMetaStore.class.getCanonicalName());\n    args.add(\"-p\");\n    args.add(String.valueOf(port));\n\n    ProcessBuilder builder = new ProcessBuilder(args);\n    Process process = builder.start();\n\n    try {\n        Thread inLogger = new Thread(new LogRedirect(process.getInputStream(), LOGGER));\n        Thread errLogger = new Thread(new LogRedirect(process.getErrorStream(), LOGGER));\n        inLogger.setDaemon(true);\n        inLogger.setName(\"HMS-IN-Logger\");\n        errLogger.setDaemon(true);\n        errLogger.setName(\"HMS-ERR-Logger\");\n        inLogger.start();\n        errLogger.start();\n\n        FutureTask<Void> res =\n                new FutureTask<>(\n                        () -> {\n                            try {\n                                int r = process.waitFor();\n                                inLogger.join();\n                                errLogger.join();\n                                if (r != 0) {\n                                    throw new RuntimeException(\"HMS process exited with \" + r);\n                                }\n                            } catch (InterruptedException e) {\n                                LOGGER.info(\"Shutting down HMS\");\n                            } finally {\n                                if (process.isAlive()) {\n                                        \n                                    process.destroy();\n                                    try {\n                                        process.waitFor(5, TimeUnit.SECONDS);\n                                    } catch (InterruptedException e) {\n                                        LOGGER.info(\n                                                \"Interrupted waiting for HMS to shut down, killing it forcibly\");\n                                    }\n                                    process.destroyForcibly();\n                                }\n                            }\n                        },\n                        null);\n        Thread thread = new Thread(res);\n        thread.setName(\"HMS-Watcher\");\n            \n        thread.setDaemon(false);\n        thread.start();\n        waitForHMSStart(port);\n        return res;\n    } catch (Throwable e) {\n            \n        process.destroyForcibly();\n        throw e;\n    }\n}", "summary_tokens": ["launches", "hms", "process", "and", "returns", "a", "future", "representing", "that", "process"], "project": "flink"}
{"id": 9340, "code": "public static <W extends Window> AfterFirstElementPeriodic<W> every(Duration time) {\n    return new AfterFirstElementPeriodic<>(time.toMillis());\n}", "summary_tokens": ["creates", "a", "trigger", "that", "fires", "by", "a", "certain", "interval", "after", "reception", "of", "the", "first", "element"], "project": "flink"}
{"id": 5852, "code": "private void checkedThreadSimpleTest(CheckedThread[] threads) throws Exception {\n\n        \n    for (CheckedThread t : threads) {\n        t.start();\n    }\n\n        \n    for (CheckedThread t : threads) {\n        t.sync();\n    }\n}", "summary_tokens": ["helper", "method", "to", "first", "start", "all", "threads", "and", "then", "wait", "for", "their", "completion"], "project": "flink"}
{"id": 4541, "code": "public BufferConsumer createBufferConsumer() {\n    return createBufferConsumer(positionMarker.cachedPosition);\n}", "summary_tokens": ["this", "method", "always", "creates", "a", "buffer", "consumer", "starting", "from", "the", "current", "writer", "offset"], "project": "flink"}
{"id": 7834, "code": "public void testWatermarksNotForwardedWithinChainWhenIdle() throws Exception {\n\n    final OneInputStreamTaskTestHarness<String, String> testHarness =\n            new OneInputStreamTaskTestHarness<>(\n                    OneInputStreamTask::new,\n                    1,\n                    1,\n                    BasicTypeInfo.STRING_TYPE_INFO,\n                    BasicTypeInfo.STRING_TYPE_INFO);\n\n    TriggerableFailOnWatermarkTestOperator headOperator =\n            new TriggerableFailOnWatermarkTestOperator();\n    WatermarkGeneratingTestOperator watermarkOperator = new WatermarkGeneratingTestOperator();\n    TriggerableFailOnWatermarkTestOperator tailOperator =\n            new TriggerableFailOnWatermarkTestOperator();\n\n    testHarness\n            .setupOperatorChain(new OperatorID(42L, 42L), headOperator)\n            .chain(new OperatorID(4711L, 42L), watermarkOperator, StringSerializer.INSTANCE)\n            .chain(new OperatorID(123L, 123L), tailOperator, StringSerializer.INSTANCE)\n            .finish();\n\n        \n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    testHarness.invoke();\n    testHarness.waitForTaskRunning();\n\n        \n    testHarness.processElement(\n            new StreamRecord<>(\n                    TriggerableFailOnWatermarkTestOperator.EXPECT_FORWARDED_WATERMARKS_MARKER));\n\n    testHarness.processElement(new StreamRecord<>(\"10\"), 0, 0);\n\n        \n        \n        \n    testHarness.processElement(new Watermark(15));\n\n    testHarness.processElement(new StreamRecord<>(\"20\"), 0, 0);\n    testHarness.processElement(new StreamRecord<>(\"30\"), 0, 0);\n\n    testHarness.waitForInputProcessing();\n\n    expectedOutput.add(\n            new StreamRecord<>(\n                    TriggerableFailOnWatermarkTestOperator.EXPECT_FORWARDED_WATERMARKS_MARKER));\n    expectedOutput.add(new StreamRecord<>(\"10\"));\n    expectedOutput.add(new Watermark(10));\n    expectedOutput.add(new StreamRecord<>(\"20\"));\n    expectedOutput.add(new Watermark(20));\n    expectedOutput.add(new StreamRecord<>(\"30\"));\n    expectedOutput.add(new Watermark(30));\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n        \n    testHarness.processElement(WatermarkStatus.IDLE);\n\n        \n        \n    testHarness.processElement(\n            new StreamRecord<>(\n                    TriggerableFailOnWatermarkTestOperator.NO_FORWARDED_WATERMARKS_MARKER));\n\n        \n        \n    testHarness.processElement(new StreamRecord<>(\"40\"), 0, 0);\n    testHarness.processElement(new StreamRecord<>(\"50\"), 0, 0);\n    testHarness.processElement(new StreamRecord<>(\"60\"), 0, 0);\n    testHarness.processElement(\n            new Watermark(\n                    65)); \n    testHarness.waitForInputProcessing();\n\n        \n        \n        \n    expectedOutput.add(WatermarkStatus.IDLE);\n    expectedOutput.add(\n            new StreamRecord<>(\n                    TriggerableFailOnWatermarkTestOperator.NO_FORWARDED_WATERMARKS_MARKER));\n    expectedOutput.add(new StreamRecord<>(\"40\"));\n    expectedOutput.add(new StreamRecord<>(\"50\"));\n    expectedOutput.add(new StreamRecord<>(\"60\"));\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n        \n    testHarness.processElement(WatermarkStatus.ACTIVE);\n    testHarness.processElement(\n            new StreamRecord<>(\n                    TriggerableFailOnWatermarkTestOperator.EXPECT_FORWARDED_WATERMARKS_MARKER));\n\n    testHarness.processElement(new StreamRecord<>(\"70\"), 0, 0);\n    testHarness.processElement(new StreamRecord<>(\"80\"), 0, 0);\n    testHarness.processElement(new StreamRecord<>(\"90\"), 0, 0);\n    testHarness.waitForInputProcessing();\n\n    expectedOutput.add(WatermarkStatus.ACTIVE);\n    expectedOutput.add(\n            new StreamRecord<>(\n                    TriggerableFailOnWatermarkTestOperator.EXPECT_FORWARDED_WATERMARKS_MARKER));\n    expectedOutput.add(new StreamRecord<>(\"70\"));\n    expectedOutput.add(new Watermark(70));\n    expectedOutput.add(new StreamRecord<>(\"80\"));\n    expectedOutput.add(new Watermark(80));\n    expectedOutput.add(new StreamRecord<>(\"90\"));\n    expectedOutput.add(new Watermark(90));\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.endInput();\n\n    testHarness.waitForTaskCompletion();\n\n    List<String> resultElements =\n            TestHarnessUtil.getRawElementsFromOutput(testHarness.getOutput());\n    assertEquals(12, resultElements.size());\n}", "summary_tokens": ["this", "test", "verifies", "that", "watermarks", "are", "not", "forwarded", "when", "the", "task", "is", "idle"], "project": "flink"}
{"id": 7967, "code": "public static TableSchema deriveTableSinkSchema(DescriptorProperties properties) {\n    TableSchema.Builder builder = TableSchema.builder();\n    TableSchema tableSchema = properties.getTableSchema(SCHEMA);\n    for (int i = 0; i < tableSchema.getFieldCount(); i++) {\n        final TableColumn tableColumn = tableSchema.getTableColumns().get(i);\n        final String fieldName = tableColumn.getName();\n        final DataType dataType = tableColumn.getType();\n        if (!tableColumn.isPhysical()) {\n                \n            continue;\n        }\n        boolean isProctime =\n                properties\n                        .getOptionalBoolean(SCHEMA + \".\" + i + \".\" + SCHEMA_PROCTIME)\n                        .orElse(false);\n        String tsType = SCHEMA + \".\" + i + \".\" + ROWTIME_TIMESTAMPS_TYPE;\n        boolean isRowtime = properties.containsKey(tsType);\n        if (!isProctime && !isRowtime) {\n                \n            String aliasName =\n                    properties\n                            .getOptionalString(SCHEMA + \".\" + i + \".\" + SCHEMA_FROM)\n                            .orElse(fieldName);\n            builder.field(aliasName, dataType);\n        }\n            \n        else if (isRowtime) {\n            switch (properties.getString(tsType)) {\n                case ROWTIME_TIMESTAMPS_TYPE_VALUE_FROM_FIELD:\n                    String field =\n                            properties.getString(\n                                    SCHEMA + \".\" + i + \".\" + ROWTIME_TIMESTAMPS_FROM);\n                    builder.field(field, dataType);\n                    break;\n                        \n                        \n                default:\n                    throw new TableException(\n                            format(\n                                    \"Unsupported rowtime type '%s' for sink\"\n                                            + \" table schema. Currently only '%s' is supported for table sinks.\",\n                                    dataType, ROWTIME_TIMESTAMPS_TYPE_VALUE_FROM_FIELD));\n            }\n        }\n    }\n\n    return builder.build();\n}", "summary_tokens": ["derives", "the", "table", "schema", "for", "a", "table", "sink"], "project": "flink"}
{"id": 1492, "code": "public static <T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16>\n        Tuple17<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> of(\n                T0 f0,\n                T1 f1,\n                T2 f2,\n                T3 f3,\n                T4 f4,\n                T5 f5,\n                T6 f6,\n                T7 f7,\n                T8 f8,\n                T9 f9,\n                T10 f10,\n                T11 f11,\n                T12 f12,\n                T13 f13,\n                T14 f14,\n                T15 f15,\n                T16 f16) {\n    return new Tuple17<>(\n            f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 3302, "code": "public void preSuperstep() {}", "summary_tokens": ["this", "method", "is", "executed", "once", "per", "superstep", "before", "the", "vertex", "update", "function", "is", "invoked", "for", "each", "vertex"], "project": "flink"}
{"id": 4855, "code": "public void releaseMemory(Object owner, long size) {\n    checkMemoryReservationPreconditions(owner, size);\n    if (size == 0L) {\n        return;\n    }\n\n    reservedMemory.compute(\n            owner,\n            (o, currentlyReserved) -> {\n                long newReservedMemory = 0;\n                if (currentlyReserved != null) {\n                    if (currentlyReserved < size) {\n                        LOG.warn(\n                                \"Trying to release more memory {} than it was reserved {} so far for the owner {}\",\n                                size,\n                                currentlyReserved,\n                                owner);\n                    }\n\n                    newReservedMemory =\n                            releaseAndCalculateReservedMemory(size, currentlyReserved);\n                }\n\n                return newReservedMemory == 0 ? null : newReservedMemory;\n            });\n}", "summary_tokens": ["releases", "a", "memory", "chunk", "of", "a", "certain", "size", "from", "an", "owner", "to", "this", "memory", "manager"], "project": "flink"}
{"id": 6593, "code": "public void testListStateDefaultValue() throws Exception {\n    ListStateDescriptor<String> kvId = new ListStateDescriptor<>(\"id\", String.class);\n\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n    try {\n        ListState<String> state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n        backend.setCurrentKey(1);\n        assertNull(state.get());\n\n        state.update(Arrays.asList(\"Ciao\", \"Bello\"));\n        assertThat(state.get(), containsInAnyOrder(\"Ciao\", \"Bello\"));\n\n        state.clear();\n        assertNull(state.get());\n    } finally {\n        IOUtils.closeQuietly(backend);\n        backend.dispose();\n    }\n}", "summary_tokens": ["verify", "that", "an", "empty", "list", "state", "yields", "null"], "project": "flink"}
{"id": 3457, "code": "public <T> DataSource<T> readListState(\n        String uid, String name, TypeInformation<T> typeInfo, TypeSerializer<T> serializer)\n        throws IOException {\n\n    OperatorState operatorState = metadata.getOperatorState(uid);\n    ListStateDescriptor<T> descriptor = new ListStateDescriptor<>(name, serializer);\n    ListStateInputFormat<T> inputFormat = new ListStateInputFormat<>(operatorState, descriptor);\n    return env.createInput(inputFormat, typeInfo);\n}", "summary_tokens": ["read", "operator", "list", "state", "from", "a", "savepoint", "when", "a", "custom", "serializer", "was", "used", "e"], "project": "flink"}
{"id": 6361, "code": "public void verifyCheckpointEventOrderWhenCheckpointFutureCompletedImmediately()\n        throws Exception {\n    checkpointEventValueAtomicity(FutureCompletedInstantlyTestCoordinator::new);\n}", "summary_tokens": ["this", "test", "verifies", "that", "the", "order", "of", "checkpoint", "completion", "and", "event", "sending", "observed", "from", "the", "outside", "matches", "that", "from", "within", "the", "operator", "coordinator"], "project": "flink"}
{"id": 361, "code": "public HiveParserTypeCheckProcFactory.BoolExprProcessor getBoolExprProcessor() {\n    return new HiveParserTypeCheckProcFactory.BoolExprProcessor();\n}", "summary_tokens": ["factory", "method", "to", "get", "bool", "expr", "processor"], "project": "flink"}
{"id": 7271, "code": "public String getExecutionPlan() {\n    return getStreamGraph(false).getStreamingPlanAsJSON();\n}", "summary_tokens": ["creates", "the", "plan", "with", "which", "the", "system", "will", "execute", "the", "program", "and", "returns", "it", "as", "a", "string", "using", "a", "json", "representation", "of", "the", "execution", "data", "flow", "graph"], "project": "flink"}
{"id": 8212, "code": "default Optional<FunctionDefinitionFactory> getFunctionDefinitionFactory() {\n    return Optional.empty();\n}", "summary_tokens": ["get", "an", "optional", "function", "definition", "factory", "instance", "that", "s", "responsible", "for", "instantiating", "function", "definitions"], "project": "flink"}
{"id": 2134, "code": "public static Matcher<Watermark> watermark(long timestamp) {\n    return new FeatureMatcher<Watermark, Long>(\n            equalTo(timestamp), \"a watermark with value\", \"value of watermark\") {\n        @Override\n        protected Long featureValueOf(Watermark actual) {\n            return actual.getTimestamp();\n        }\n    };\n}", "summary_tokens": ["creates", "a", "matcher", "that", "matches", "when", "the", "examined", "watermark", "has", "the", "given", "timestamp"], "project": "flink"}
{"id": 4449, "code": "public static ExternalResourceInfoProvider createStaticExternalResourceInfoProviderFromConfig(\n        Configuration configuration, PluginManager pluginManager) {\n\n    final Map<String, Long> externalResourceAmountMap =\n            getExternalResourceAmountMap(configuration);\n    LOG.info(\"Enabled external resources: {}\", externalResourceAmountMap.keySet());\n\n    return createStaticExternalResourceInfoProvider(\n            externalResourceAmountMap,\n            externalResourceDriversFromConfig(configuration, pluginManager));\n}", "summary_tokens": ["instantiate", "static", "external", "resource", "info", "provider", "for", "all", "of", "enabled", "external", "resources"], "project": "flink"}
{"id": 9317, "code": "static ClockService ofSystem() {\n    return System::currentTimeMillis;\n}", "summary_tokens": ["creates", "a", "clock", "service", "which", "assigns", "as", "current", "processing", "time", "the", "result", "of", "calling", "system", "current", "time", "millis"], "project": "flink"}
{"id": 5299, "code": "public static FailureHandlingResultSnapshot create(\n        FailureHandlingResult failureHandlingResult,\n        Function<ExecutionVertexID, Execution> latestExecutionLookup) {\n    final Execution rootCauseExecution =\n            failureHandlingResult\n                    .getExecutionVertexIdOfFailedTask()\n                    .map(latestExecutionLookup)\n                    .orElse(null);\n    Preconditions.checkArgument(\n            rootCauseExecution == null || rootCauseExecution.getFailureInfo().isPresent(),\n            String.format(\n                    \"The execution %s didn't provide a failure info even though the corresponding ExecutionVertex %s is marked as having handled the root cause of this failure.\",\n                        \n                        \n                    rootCauseExecution != null ? rootCauseExecution.getAttemptId() : \"(null)\",\n                    failureHandlingResult\n                            .getExecutionVertexIdOfFailedTask()\n                            .map(Objects::toString)\n                            .orElse(\"(null)\")));\n\n    final ExecutionVertexID rootCauseExecutionVertexId =\n            failureHandlingResult.getExecutionVertexIdOfFailedTask().orElse(null);\n    final Set<Execution> concurrentlyFailedExecutions =\n            failureHandlingResult.getVerticesToRestart().stream()\n                    .filter(\n                            executionVertexId ->\n                                    !executionVertexId.equals(rootCauseExecutionVertexId))\n                    .map(latestExecutionLookup)\n                    .filter(execution -> execution.getFailureInfo().isPresent())\n                    .collect(Collectors.toSet());\n\n    return new FailureHandlingResultSnapshot(\n            rootCauseExecution,\n            ErrorInfo.handleMissingThrowable(failureHandlingResult.getError()),\n            failureHandlingResult.getTimestamp(),\n            concurrentlyFailedExecutions);\n}", "summary_tokens": ["creates", "a", "failure", "handling", "result", "snapshot", "based", "on", "the", "passed", "failure", "handling", "result", "and", "execution", "vertex", "execution", "vertices"], "project": "flink"}
{"id": 4489, "code": "public void closeAndDelete() throws IOException {\n    close(true);\n}", "summary_tokens": ["closes", "this", "output", "writing", "pending", "data", "and", "releasing", "the", "memory"], "project": "flink"}
{"id": 3688, "code": "public void setDataExchangeMode(DataExchangeMode dataExchangeMode) {\n    this.dataExchangeMode = checkNotNull(dataExchangeMode);\n}", "summary_tokens": ["sets", "the", "data", "exchange", "mode", "batch", "pipelined", "to", "use", "for", "the", "data", "exchange", "of", "this", "channel"], "project": "flink"}
{"id": 1287, "code": "public Operator<WT> getWorkset() {\n    return this.worksetPlaceholder;\n}", "summary_tokens": ["gets", "the", "contract", "that", "represents", "the", "workset", "for", "the", "step", "function"], "project": "flink"}
{"id": 7067, "code": "public SingleOutputStreamOperator<T> filter(FilterFunction<T> filter) {\n    return transform(\"Filter\", getType(), new StreamFilter<>(clean(filter)));\n}", "summary_tokens": ["applies", "a", "filter", "transformation", "on", "a", "data", "stream"], "project": "flink"}
{"id": 7594, "code": "private void sendPoisonMail(RunnableWithException mail) {\n    mailbox.runExclusively(\n            () -> {\n                    \n                    \n                    \n                if (mailbox.getState() == TaskMailbox.State.OPEN) {\n                    sendControlMail(mail, \"poison mail\");\n                }\n            });\n}", "summary_tokens": ["send", "mail", "in", "first", "priority", "for", "internal", "needs"], "project": "flink"}
{"id": 5698, "code": "private static List<String> getTmResourceParams(Configuration configuration) {\n    Configuration configurationWithFallback =\n            TaskExecutorProcessUtils.getConfigurationMapLegacyTaskManagerHeapSizeToConfigOption(\n                    configuration, TaskManagerOptions.TOTAL_FLINK_MEMORY);\n    TaskExecutorProcessSpec taskExecutorProcessSpec =\n            TaskExecutorProcessUtils.processSpecFromConfig(configurationWithFallback);\n\n    logTaskExecutorConfiguration(taskExecutorProcessSpec);\n\n    return Arrays.asList(\n            ProcessMemoryUtils.generateJvmParametersStr(taskExecutorProcessSpec),\n            TaskExecutorProcessUtils.generateDynamicConfigsStr(taskExecutorProcessSpec));\n}", "summary_tokens": ["generate", "and", "print", "jvm", "parameters", "and", "dynamic", "configs", "of", "task", "executor", "resources"], "project": "flink"}
{"id": 5406, "code": "public void setKeyAndKeyGroup(@Nonnull K key, @Nonnegative int keyGroupId) {\n    try {\n        serializeKeyGroupAndKey(key, keyGroupId);\n    } catch (IOException shouldNeverHappen) {\n        throw new FlinkRuntimeException(shouldNeverHappen);\n    }\n}", "summary_tokens": ["sets", "the", "key", "and", "key", "group", "as", "prefix"], "project": "flink"}
{"id": 1572, "code": "public static Method getSingleAbstractMethod(Class<?> baseClass) {\n\n    if (!baseClass.isInterface()) {\n        throw new InvalidTypesException(\n                \"Given class: \" + baseClass + \"is not a FunctionalInterface.\");\n    }\n\n    Method sam = null;\n    for (Method method : baseClass.getMethods()) {\n        if (Modifier.isAbstract(method.getModifiers())) {\n            if (sam == null) {\n                sam = method;\n            } else {\n                throw new InvalidTypesException(\n                        \"Given class: \"\n                                + baseClass\n                                + \" is not a FunctionalInterface. It has more than one abstract method.\");\n            }\n        }\n    }\n\n    if (sam == null) {\n        throw new InvalidTypesException(\n                \"Given class: \"\n                        + baseClass\n                        + \" is not a FunctionalInterface. It does not have any abstract methods.\");\n    }\n\n    return sam;\n}", "summary_tokens": ["extracts", "a", "single", "abstract", "method", "sam", "as", "defined", "in", "java", "specification", "0"], "project": "flink"}
{"id": 2398, "code": "public ClassLoader getClassLoader() {\n    return classLoader;\n}", "summary_tokens": ["get", "the", "class", "loader", "for", "this", "job"], "project": "flink"}
{"id": 1168, "code": "public void close() throws IOException {\n    this.wrapBuffer = null;\n    this.readBuffer = null;\n    super.close();\n}", "summary_tokens": ["closes", "the", "input", "by", "releasing", "all", "buffers", "and", "closing", "the", "file", "input", "stream"], "project": "flink"}
{"id": 4839, "code": "public void advance() throws IOException {\n    doAdvance();\n}", "summary_tokens": ["advances", "the", "view", "to", "the", "next", "memory", "segment"], "project": "flink"}
{"id": 6661, "code": "public void testFailingNotifyPartitionDataAvailable() throws Exception {\n    final Configuration configuration = new Configuration();\n\n        \n        \n        \n    configuration.set(TaskManagerOptions.MEMORY_SEGMENT_SIZE, MemorySize.parse(\"4096\"));\n\n    NettyShuffleDescriptor sdd =\n            createRemoteWithIdAndLocation(\n                    new IntermediateResultPartitionID(), ResourceID.generate());\n    TaskDeploymentDescriptor tdd =\n            createSender(sdd, TestingAbstractInvokables.TestInvokableRecordCancel.class);\n    ExecutionAttemptID eid = tdd.getExecutionAttemptId();\n\n    final CompletableFuture<Void> taskRunningFuture = new CompletableFuture<>();\n\n    final Exception exception = new Exception(\"Failed notifyPartitionDataAvailable\");\n\n    final JobMasterId jobMasterId = JobMasterId.generate();\n    TestingJobMasterGateway testingJobMasterGateway =\n            new TestingJobMasterGatewayBuilder()\n                    .setFencingTokenSupplier(() -> jobMasterId)\n                    .setNotifyPartitionDataAvailableFunction(\n                            resultPartitionID -> FutureUtils.completedExceptionally(exception))\n                    .build();\n\n    try (TaskSubmissionTestEnvironment env =\n            new TaskSubmissionTestEnvironment.Builder(jobId)\n                    .setSlotSize(1)\n                    .setConfiguration(configuration)\n                    .addTaskManagerActionListener(\n                            eid, ExecutionState.RUNNING, taskRunningFuture)\n                    .setJobMasterId(jobMasterId)\n                    .setJobMasterGateway(testingJobMasterGateway)\n                    .useRealNonMockShuffleEnvironment()\n                    .build()) {\n        TaskExecutorGateway tmGateway = env.getTaskExecutorGateway();\n        TaskSlotTable<Task> taskSlotTable = env.getTaskSlotTable();\n\n        TestingAbstractInvokables.TestInvokableRecordCancel.resetGotCanceledFuture();\n\n        taskSlotTable.allocateSlot(0, jobId, tdd.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd, jobMasterId, timeout).get();\n        taskRunningFuture.get();\n\n        CompletableFuture<Boolean> cancelFuture =\n                TestingAbstractInvokables.TestInvokableRecordCancel.gotCanceled();\n\n        assertTrue(cancelFuture.get());\n        assertTrue(\n                ExceptionUtils.findThrowableWithMessage(\n                                taskSlotTable.getTask(eid).getFailureCause(),\n                                exception.getMessage())\n                        .isPresent());\n    }\n}", "summary_tokens": ["test", "that", "a", "failing", "notify", "partition", "data", "available", "call", "leads", "to", "the", "failing", "of", "the", "respective", "task"], "project": "flink"}
{"id": 3518, "code": "public static OperatorID fromUid(String uid) {\n    byte[] hash = Hashing.murmur3_128(0).newHasher().putString(uid, UTF_8).hash().asBytes();\n    return new OperatorID(hash);\n}", "summary_tokens": ["generate", "operator", "id", "s", "from", "uid", "s"], "project": "flink"}
{"id": 6481, "code": "public void testGetMetric() throws Exception {\n    @SuppressWarnings(\"unchecked\")\n    final CompletableFuture<MetricCollectionResponseBody> completableFuture =\n            metricsHandler.handleRequest(\n                    HandlerRequest.resolveParametersAndCreate(\n                            EmptyRequestBody.getInstance(),\n                            metricsHandler.getMessageHeaders().getUnresolvedMessageParameters(),\n                            pathParameters,\n                            Collections.emptyMap(),\n                            Collections.emptyList()),\n                    mockDispatcherGateway);\n\n    assertTrue(completableFuture.isDone());\n\n    final MetricCollectionResponseBody metricCollectionResponseBody = completableFuture.get();\n    assertThat(metricCollectionResponseBody.getMetrics(), hasSize(1));\n\n    final Metric metric = metricCollectionResponseBody.getMetrics().iterator().next();\n    assertThat(metric.getId(), equalTo(getExpectedIdForMetricName(TEST_METRIC_NAME)));\n}", "summary_tokens": ["tests", "that", "the", "metric", "with", "name", "defined", "under", "test", "metric", "name", "can", "be", "retrieved", "from", "the", "metric", "store"], "project": "flink"}
{"id": 2447, "code": "public static GlueSchemaRegistryAvroSerializationSchema<GenericRecord> forGeneric(\n        Schema schema, String transportName, Map<String, Object> configs) {\n    return new GlueSchemaRegistryAvroSerializationSchema<>(\n            GenericRecord.class,\n            schema,\n            new GlueSchemaRegistryAvroSchemaCoderProvider(transportName, configs));\n}", "summary_tokens": ["creates", "glue", "schema", "registry", "avro", "serialization", "schema", "that", "serializes", "generic", "record", "using", "provided", "schema"], "project": "flink"}
{"id": 4448, "code": "public static Map<String, String> getExternalResourceConfigurationKeys(\n        Configuration config, String suffix) {\n    final Set<String> resourceSet = getExternalResourceSet(config);\n    final Map<String, String> configKeysToResourceNameMap = new HashMap<>();\n    LOG.info(\"Enabled external resources: {}\", resourceSet);\n\n    if (resourceSet.isEmpty()) {\n        return Collections.emptyMap();\n    }\n\n    final Map<String, String> externalResourceConfigs = new HashMap<>();\n    for (String resourceName : resourceSet) {\n        final ConfigOption<String> configKeyOption =\n                key(ExternalResourceOptions.getSystemConfigKeyConfigOptionForResource(\n                                resourceName, suffix))\n                        .stringType()\n                        .noDefaultValue();\n        final String configKey = config.get(configKeyOption);\n\n        if (StringUtils.isNullOrWhitespaceOnly(configKey)) {\n            LOG.warn(\n                    \"Could not find valid {} for {}. Will ignore that resource.\",\n                    configKeyOption.key(),\n                    resourceName);\n        } else {\n            configKeysToResourceNameMap.compute(\n                    configKey,\n                    (ignored, previousResource) -> {\n                        if (previousResource != null) {\n                            LOG.warn(\n                                    \"Duplicate config key {} occurred for external resources, the one named {} will overwrite the value.\",\n                                    configKey,\n                                    resourceName);\n                            externalResourceConfigs.remove(previousResource);\n                        }\n                        return resourceName;\n                    });\n            externalResourceConfigs.put(resourceName, configKey);\n        }\n    }\n\n    return externalResourceConfigs;\n}", "summary_tokens": ["get", "the", "external", "resource", "configuration", "keys", "map", "indexed", "by", "the", "resource", "name"], "project": "flink"}
{"id": 7920, "code": "public TestCheckpointedInputGateBuilder withRemoteChannels() {\n    this.gateBuilder = this::buildRemoteGate;\n    return this;\n}", "summary_tokens": ["uses", "remote", "input", "channel", "remote", "input", "channels", "and", "enables", "with", "mailbox", "executor", "by", "default"], "project": "flink"}
{"id": 5490, "code": "public void releaseSnapshot(\n        StateMapSnapshot<K, N, S, ? extends StateMap<K, N, S>> snapshotToRelease) {}", "summary_tokens": ["releases", "a", "snapshot", "for", "this", "state", "map"], "project": "flink"}
{"id": 1875, "code": "public <T> T getFieldAs(String name) {\n    return (T) getField(name);\n}", "summary_tokens": ["returns", "the", "field", "s", "content", "using", "the", "specified", "field", "name"], "project": "flink"}
{"id": 1124, "code": "public static Map<String, Object> deserializeAndUnwrapAccumulators(\n        Map<String, SerializedValue<OptionalFailure<Object>>> serializedAccumulators,\n        ClassLoader loader)\n        throws IOException, ClassNotFoundException {\n\n    Map<String, OptionalFailure<Object>> deserializedAccumulators =\n            deserializeAccumulators(serializedAccumulators, loader);\n\n    if (deserializedAccumulators.isEmpty()) {\n        return Collections.emptyMap();\n    }\n\n    Map<String, Object> accumulators = new HashMap<>(serializedAccumulators.size());\n\n    for (Map.Entry<String, OptionalFailure<Object>> entry :\n            deserializedAccumulators.entrySet()) {\n        accumulators.put(entry.getKey(), entry.getValue().getUnchecked());\n    }\n\n    return accumulators;\n}", "summary_tokens": ["takes", "the", "serialized", "accumulator", "results", "and", "tries", "to", "deserialize", "them", "using", "the", "provided", "class", "loader", "and", "then", "try", "to", "unwrap", "the", "value", "unchecked"], "project": "flink"}
{"id": 2163, "code": "public void generateTestSetupFiles() throws Exception {\n    Files.createDirectories(getSerializerSnapshotFilePath().getParent());\n\n    try (ThreadContextClassLoader ignored =\n            new ThreadContextClassLoader(testSpecification.setup.setupClassloader)) {\n        TypeSerializer<PreviousElementT> priorSerializer =\n                testSpecification.setup.createPriorSerializer();\n\n            \n            \n            \n            \n            \n        DataOutputSerializer testDataOut = new DataOutputSerializer(INITIAL_OUTPUT_BUFFER_SIZE);\n        priorSerializer.serialize(testSpecification.setup.createTestData(), testDataOut);\n        writeContentsTo(getGenerateDataFilePath(), testDataOut.getCopyOfBuffer());\n\n            \n        DataOutputSerializer serializerSnapshotOut =\n                new DataOutputSerializer(INITIAL_OUTPUT_BUFFER_SIZE);\n        writeSerializerSnapshot(serializerSnapshotOut, priorSerializer, CURRENT_VERSION);\n        writeContentsTo(\n                getGenerateSerializerSnapshotFilePath(),\n                serializerSnapshotOut.getCopyOfBuffer());\n    }\n}", "summary_tokens": ["execute", "this", "test", "to", "generate", "test", "files"], "project": "flink"}
{"id": 1714, "code": "private static List<FileSystemFactory> loadFileSystemFactories(\n        Collection<Supplier<Iterator<FileSystemFactory>>> factoryIteratorsSuppliers) {\n\n    final ArrayList<FileSystemFactory> list = new ArrayList<>();\n\n        \n    list.add(new LocalFileSystemFactory());\n\n    LOG.debug(\"Loading extension file systems via services\");\n\n    for (Supplier<Iterator<FileSystemFactory>> factoryIteratorsSupplier :\n            factoryIteratorsSuppliers) {\n        try {\n            addAllFactoriesToList(factoryIteratorsSupplier.get(), list);\n        } catch (Throwable t) {\n                \n                \n            ExceptionUtils.rethrowIfFatalErrorOrOOM(t);\n            LOG.error(\"Failed to load additional file systems via services\", t);\n        }\n    }\n\n    return Collections.unmodifiableList(list);\n}", "summary_tokens": ["loads", "the", "factories", "for", "the", "file", "systems", "directly", "supported", "by", "flink"], "project": "flink"}
{"id": 7431, "code": "public Transformation<IN2> getInput2() {\n    return input2;\n}", "summary_tokens": ["returns", "the", "second", "input", "transformation", "of", "this", "two", "input", "transformation"], "project": "flink"}
{"id": 8115, "code": "public static <T> TableSource<T> findAndCreateTableSource(\n        @Nullable Catalog catalog,\n        ObjectIdentifier objectIdentifier,\n        CatalogTable catalogTable,\n        ReadableConfig configuration,\n        boolean isTemporary) {\n    TableSourceFactory.Context context =\n            new TableSourceFactoryContextImpl(\n                    objectIdentifier, catalogTable, configuration, isTemporary);\n    Optional<TableFactory> factoryOptional =\n            catalog == null ? Optional.empty() : catalog.getTableFactory();\n    if (factoryOptional.isPresent()) {\n        TableFactory factory = factoryOptional.get();\n        if (factory instanceof TableSourceFactory) {\n            return ((TableSourceFactory<T>) factory).createTableSource(context);\n        } else {\n            throw new ValidationException(\n                    \"Cannot query a sink-only table. \"\n                            + \"TableFactory provided by catalog must implement TableSourceFactory\");\n        }\n    } else {\n        return findAndCreateTableSource(context);\n    }\n}", "summary_tokens": ["creates", "a", "table", "source", "from", "a", "catalog", "table"], "project": "flink"}
{"id": 8444, "code": "public Set<ExternalResourceInfo> getExternalResourceInfos(String resourceName) {\n    return context.getExternalResourceInfos(resourceName);\n}", "summary_tokens": ["get", "the", "external", "resource", "information"], "project": "flink"}
{"id": 7442, "code": "public void mergeWindows(Collection<TimeWindow> windows, MergeCallback<TimeWindow> c) {\n    TimeWindow.mergeWindows(windows, c);\n}", "summary_tokens": ["merge", "overlapping", "time", "window", "s"], "project": "flink"}
{"id": 280, "code": "protected JobGraph createJobGraph(String path) {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    Configuration config = new Configuration();\n    config.set(ExecutionOptions.RUNTIME_MODE, RuntimeExecutionMode.BATCH);\n    env.configure(config, getClass().getClassLoader());\n\n    if (triggerFailover) {\n        env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, Time.milliseconds(100)));\n    } else {\n        env.setRestartStrategy(RestartStrategies.noRestart());\n    }\n\n        \n    StreamSource<Integer, ?> sourceOperator =\n            new StreamSource<>(new BatchExecutionTestSource(NUM_RECORDS));\n    DataStreamSource<Integer> source =\n            new DataStreamSource<>(\n                    env,\n                    BasicTypeInfo.INT_TYPE_INFO,\n                    sourceOperator,\n                    true,\n                    \"Source\",\n                    Boundedness.BOUNDED);\n\n    source.setParallelism(NUM_SOURCES)\n            .rebalance()\n            .map(new BatchExecutionOnceFailingMap(NUM_RECORDS, triggerFailover))\n            .setParallelism(NUM_SINKS)\n            .sinkTo(createFileSink(path))\n            .setParallelism(NUM_SINKS);\n\n    StreamGraph streamGraph = env.getStreamGraph();\n    return streamGraph.getJobGraph();\n}", "summary_tokens": ["creating", "the", "testing", "job", "graph", "in", "batch", "mode"], "project": "flink"}
{"id": 7245, "code": "public void setNumberOfExecutionRetries(int numberOfExecutionRetries) {\n    config.setNumberOfExecutionRetries(numberOfExecutionRetries);\n}", "summary_tokens": ["sets", "the", "number", "of", "times", "that", "failed", "tasks", "are", "re", "executed"], "project": "flink"}
{"id": 8567, "code": "public static InputTypeStrategy varyingSequence(\n        String[] argumentNames, ArgumentTypeStrategy[] strategies) {\n    return new VaryingSequenceInputTypeStrategy(\n            Arrays.asList(strategies), Arrays.asList(argumentNames));\n}", "summary_tokens": ["strategy", "for", "a", "varying", "named", "function", "signature", "like", "f", "i", "int", "str", "string", "num", "numeric"], "project": "flink"}
{"id": 5668, "code": "public boolean containsResource(ResourceProfile resourceProfile) {\n    return resources.containsKey(resourceProfile);\n}", "summary_tokens": ["checks", "whether", "resource", "profile", "is", "contained", "in", "this", "counter"], "project": "flink"}
{"id": 671, "code": "public void testAsyncErrorRethrownOnInvoke() throws Throwable {\n    final DummyFlinkKafkaProducer<String> producer =\n            new DummyFlinkKafkaProducer<>(\n                    FakeStandardProducerConfig.get(),\n                    new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()),\n                    null);\n\n    OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer));\n\n    testHarness.open();\n\n    testHarness.processElement(new StreamRecord<>(\"msg-1\"));\n\n        \n    producer.getPendingCallbacks()\n            .get(0)\n            .onCompletion(null, new Exception(\"artificial async exception\"));\n\n    try {\n        testHarness.processElement(new StreamRecord<>(\"msg-2\"));\n    } catch (Exception e) {\n            \n        Assert.assertTrue(e.getCause().getMessage().contains(\"artificial async exception\"));\n\n            \n        return;\n    }\n\n    Assert.fail();\n}", "summary_tokens": ["test", "ensuring", "that", "if", "an", "invoke", "call", "happens", "right", "after", "an", "async", "exception", "is", "caught", "it", "should", "be", "rethrown"], "project": "flink"}
{"id": 8543, "code": "static List<Method> collectStructuredMethods(Class<?> clazz) {\n    final List<Method> methods = new ArrayList<>();\n    while (clazz != Object.class) {\n        final Method[] declaredMethods = clazz.getDeclaredMethods();\n        Stream.of(declaredMethods)\n                .filter(\n                        field -> {\n                            final int m = field.getModifiers();\n                            return Modifier.isPublic(m)\n                                    && !Modifier.isNative(m)\n                                    && !Modifier.isAbstract(m);\n                        })\n                .forEach(methods::add);\n        clazz = clazz.getSuperclass();\n    }\n    return methods;\n}", "summary_tokens": ["collects", "all", "methods", "that", "qualify", "as", "methods", "of", "a", "structured", "type"], "project": "flink"}
{"id": 4254, "code": "public List<StateObjectCollection<KeyedStateHandle>> getPrioritizedRawKeyedState() {\n    return prioritizedRawKeyedState;\n}", "summary_tokens": ["returns", "an", "immutable", "list", "with", "all", "alternative", "snapshots", "to", "restore", "the", "raw", "keyed", "state", "in", "the", "order", "in", "which", "we", "should", "attempt", "to", "restore"], "project": "flink"}
{"id": 1723, "code": "public int getTotalNumberOfOpenStreams() {\n    lock.lock();\n    try {\n        return numReservedOutputStreams + numReservedInputStreams;\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["gets", "the", "total", "number", "of", "open", "streams", "input", "plus", "output"], "project": "flink"}
{"id": 3848, "code": "public ValueVector getValueVector() {\n    return valueVector;\n}", "summary_tokens": ["returns", "the", "underlying", "container", "which", "stores", "the", "sequence", "of", "values", "of", "a", "column"], "project": "flink"}
{"id": 3583, "code": "public void setHeuristicCpuCost(double cost) {\n    if (cost <= 0) {\n        throw new IllegalArgumentException(\"Heuristic costs must be positive.\");\n    }\n    this.heuristicCpuCost = cost;\n}", "summary_tokens": ["sets", "the", "heuristic", "cost", "for", "the", "cpu"], "project": "flink"}
{"id": 5581, "code": "private static NettyConfig createNettyConfig(\n        Configuration configuration,\n        boolean localTaskManagerCommunication,\n        InetAddress taskManagerAddress,\n        int dataport) {\n\n    final NettyConfig nettyConfig;\n    if (!localTaskManagerCommunication) {\n        final InetSocketAddress taskManagerInetSocketAddress =\n                new InetSocketAddress(taskManagerAddress, dataport);\n\n        nettyConfig =\n                new NettyConfig(\n                        taskManagerInetSocketAddress.getAddress(),\n                        taskManagerInetSocketAddress.getPort(),\n                        ConfigurationParserUtils.getPageSize(configuration),\n                        ConfigurationParserUtils.getSlot(configuration),\n                        configuration);\n    } else {\n        nettyConfig = null;\n    }\n\n    return nettyConfig;\n}", "summary_tokens": ["generates", "netty", "config", "from", "flink", "configuration"], "project": "flink"}
{"id": 9323, "code": "public void add(W window, RowData value) throws Exception {\n    windowState.setCurrentNamespace(window);\n    windowState.add(value);\n}", "summary_tokens": ["updates", "the", "operator", "state", "accessible", "by", "get", "w", "by", "adding", "the", "given", "value", "to", "the", "list", "of", "values"], "project": "flink"}
{"id": 7233, "code": "public boolean isForceCheckpointing() {\n    return checkpointCfg.isForceCheckpointing();\n}", "summary_tokens": ["returns", "whether", "checkpointing", "is", "force", "enabled"], "project": "flink"}
{"id": 4266, "code": "private List<Map<StreamStateHandle, OperatorStateHandle>> initMergeMapList(\n        List<List<OperatorStateHandle>> parallelSubtaskStates) {\n\n    int parallelism = parallelSubtaskStates.size();\n\n    final List<Map<StreamStateHandle, OperatorStateHandle>> mergeMapList =\n            new ArrayList<>(parallelism);\n\n    for (List<OperatorStateHandle> previousParallelSubtaskState : parallelSubtaskStates) {\n        mergeMapList.add(\n                previousParallelSubtaskState.stream()\n                        .collect(\n                                Collectors.toMap(\n                                        OperatorStateHandle::getDelegateStateHandle,\n                                        Function.identity())));\n    }\n\n    return mergeMapList;\n}", "summary_tokens": ["init", "the", "list", "of", "stream", "state", "handle", "operator", "state", "handle", "map", "with", "given", "parallel", "subtask", "states", "when", "parallelism", "not", "changed"], "project": "flink"}
{"id": 6137, "code": "public void testUniformDistributionBounded4() throws IOException {\n    NetworkBufferPool globalPool = new NetworkBufferPool(10, 128);\n    try {\n        BufferPool first = globalPool.createBufferPool(1, 10);\n        assertEquals(10, first.getNumBuffers());\n\n        List<MemorySegment> segmentList1 = globalPool.requestMemorySegments(2);\n        assertEquals(2, segmentList1.size());\n        assertEquals(8, first.getNumBuffers());\n\n        BufferPool second = globalPool.createBufferPool(1, 10);\n        assertEquals(4, first.getNumBuffers());\n        assertEquals(4, second.getNumBuffers());\n\n        List<MemorySegment> segmentList2 = globalPool.requestMemorySegments(2);\n        assertEquals(2, segmentList2.size());\n        assertEquals(3, first.getNumBuffers());\n        assertEquals(3, second.getNumBuffers());\n\n        List<MemorySegment> segmentList3 = globalPool.requestMemorySegments(2);\n        assertEquals(2, segmentList3.size());\n        assertEquals(2, first.getNumBuffers());\n        assertEquals(2, second.getNumBuffers());\n\n        String msg =\n                \"Wrong number of available segments after creating buffer pools and requesting segments.\";\n        assertEquals(msg, 2, globalPool.getNumberOfAvailableMemorySegments());\n\n        globalPool.recycleMemorySegments(segmentList1);\n        assertEquals(msg, 4, globalPool.getNumberOfAvailableMemorySegments());\n        assertEquals(3, first.getNumBuffers());\n        assertEquals(3, second.getNumBuffers());\n\n        globalPool.recycleMemorySegments(segmentList2);\n        assertEquals(msg, 6, globalPool.getNumberOfAvailableMemorySegments());\n        assertEquals(4, first.getNumBuffers());\n        assertEquals(4, second.getNumBuffers());\n\n        globalPool.recycleMemorySegments(segmentList3);\n        assertEquals(msg, 8, globalPool.getNumberOfAvailableMemorySegments());\n        assertEquals(5, first.getNumBuffers());\n        assertEquals(5, second.getNumBuffers());\n\n        first.lazyDestroy();\n        assertEquals(msg, 9, globalPool.getNumberOfAvailableMemorySegments());\n        assertEquals(10, second.getNumBuffers());\n    } finally {\n        globalPool.destroyAllBufferPools();\n        globalPool.destroy();\n    }\n}", "summary_tokens": ["tests", "the", "interaction", "of", "requesting", "memory", "segments", "and", "creating", "local", "buffer", "pool", "and", "verifies", "the", "number", "of", "assigned", "buffers", "match", "after", "redistributing", "buffers", "because", "of", "newly", "requested", "memory", "segments", "or", "new", "buffer", "pools", "created"], "project": "flink"}
{"id": 9755, "code": "public void testCopyFromLocalRecursiveWithScheme() throws Exception {\n    final FileSystem targetFileSystem = hdfsRootPath.getFileSystem(hadoopConfig);\n    final Path targetDir = targetFileSystem.getWorkingDirectory();\n\n    testRegisterMultipleLocalResources(\n            targetFileSystem, targetDir, LOCAL_RESOURCE_DIRECTORY, tempFolder, true, false);\n}", "summary_tokens": ["verifies", "that", "nested", "directories", "are", "properly", "copied", "with", "a", "tt", "hdfs", "tt", "file", "system", "from", "a", "tt", "file", "absolute", "path", "tt", "source", "path"], "project": "flink"}
{"id": 8858, "code": "private static RelDataType inferRowType(SqlOperatorBinding opBinding) {\n    final RelDataTypeFactory typeFactory = opBinding.getTypeFactory();\n    final RelDataType inputRowType = opBinding.getOperandType(0);\n    final RelDataType descriptorType = opBinding.getOperandType(1);\n    final RelDataTypeField timeField = descriptorType.getFieldList().get(0);\n    final RelDataType timeAttributeType;\n    if (timeField.getType().getSqlTypeName() == SqlTypeName.NULL) {\n            \n            \n        RelDataTypeField field = inputRowType.getField(timeField.getName(), false, false);\n        if (field == null) {\n            throw new IllegalArgumentException(\n                    String.format(\n                            \"Can't find the time attribute field '%s' in the input schema %s.\",\n                            timeField.getName(), inputRowType.getFullTypeString()));\n        }\n        timeAttributeType = field.getType();\n    } else {\n            \n        timeAttributeType = timeField.getType();\n    }\n    return inferRowType(typeFactory, inputRowType, timeAttributeType);\n}", "summary_tokens": ["helper", "for", "arg", "0", "table", "function", "windowing"], "project": "flink"}
{"id": 653, "code": "public void writeSnapshot() throws Exception {\n    writeSnapshot(\n            \"src/test/resources/kafka-consumer-migration-test-flink\"\n                    + flinkGenerateSavepointVersion\n                    + \"-snapshot\",\n            PARTITION_STATE);\n\n    final HashMap<KafkaTopicPartition, Long> emptyState = new HashMap<>();\n    writeSnapshot(\n            \"src/test/resources/kafka-consumer-migration-test-flink\"\n                    + flinkGenerateSavepointVersion\n                    + \"-empty-state-snapshot\",\n            emptyState);\n}", "summary_tokens": ["manually", "run", "this", "to", "write", "binary", "snapshot", "data"], "project": "flink"}
{"id": 4098, "code": "BlobKey putBuffer(\n        @Nullable JobID jobId, byte[] value, int offset, int len, BlobKey.BlobType blobType)\n        throws IOException {\n\n    if (this.socket.isClosed()) {\n        throw new IllegalStateException(\n                \"BLOB Client is not connected. \"\n                        + \"Client has been shut down or encountered an error before.\");\n    }\n    checkNotNull(value);\n\n    if (LOG.isDebugEnabled()) {\n        LOG.debug(\n                \"PUT BLOB buffer (\"\n                        + len\n                        + \" bytes) to \"\n                        + socket.getLocalSocketAddress()\n                        + \".\");\n    }\n\n    try (BlobOutputStream os = new BlobOutputStream(jobId, blobType, socket)) {\n        os.write(value, offset, len);\n            \n        return os.finish();\n    } catch (Throwable t) {\n        BlobUtils.closeSilently(socket, LOG);\n        throw new IOException(\"PUT operation failed: \" + t.getMessage(), t);\n    }\n}", "summary_tokens": ["uploads", "data", "from", "the", "given", "byte", "buffer", "to", "the", "blob", "server"], "project": "flink"}
{"id": 9153, "code": "private static boolean checkBegin(\n        BinaryStringData pattern, MemorySegment[] segments, int start, int len) {\n    int lenSub = pattern.getSizeInBytes();\n    return len >= lenSub\n            && SegmentsUtil.equals(pattern.getSegments(), 0, segments, start, lenSub);\n}", "summary_tokens": ["matches", "the", "beginning", "of", "each", "string", "to", "a", "pattern"], "project": "flink"}
{"id": 5281, "code": "private static boolean containsIntraRegionAllToAllEdge(\n        DefaultLogicalPipelinedRegion logicalPipelinedRegion) {\n    for (LogicalVertex vertex : logicalPipelinedRegion.getVertices()) {\n        for (LogicalEdge inputEdge : vertex.getInputs()) {\n            if (inputEdge.getDistributionPattern() == DistributionPattern.ALL_TO_ALL\n                    && logicalPipelinedRegion.contains(inputEdge.getProducerVertexId())) {\n                return true;\n            }\n        }\n    }\n    return false;\n}", "summary_tokens": ["check", "if", "the", "default", "logical", "pipelined", "region", "contains", "intra", "region", "all", "to", "all", "edges", "or", "not"], "project": "flink"}
{"id": 6992, "code": "private List<ColumnFamilyDescriptor> createlumnFamilyDescriptors(\n        List<StateMetaInfoSnapshot> stateMetaInfoSnapshots, boolean registerTtlCompactFilter) {\n\n    List<ColumnFamilyDescriptor> columnFamilyDescriptors =\n            new ArrayList<>(stateMetaInfoSnapshots.size());\n\n    for (StateMetaInfoSnapshot stateMetaInfoSnapshot : stateMetaInfoSnapshots) {\n        RegisteredStateMetaInfoBase metaInfoBase =\n                RegisteredStateMetaInfoBase.fromMetaInfoSnapshot(stateMetaInfoSnapshot);\n        ColumnFamilyDescriptor columnFamilyDescriptor =\n                RocksDBOperationUtils.createColumnFamilyDescriptor(\n                        metaInfoBase,\n                        this.rocksHandle.getColumnFamilyOptionsFactory(),\n                        registerTtlCompactFilter\n                                ? this.rocksHandle.getTtlCompactFiltersManager()\n                                : null,\n                        this.rocksHandle.getWriteBufferManagerCapacity());\n\n        columnFamilyDescriptors.add(columnFamilyDescriptor);\n    }\n    return columnFamilyDescriptors;\n}", "summary_tokens": ["this", "method", "recreates", "and", "registers", "all", "column", "family", "descriptor", "from", "flink", "s", "state", "meta", "data", "snapshot"], "project": "flink"}
{"id": 501, "code": "public KafkaSinkBuilder<IN> setDeliverGuarantee(DeliveryGuarantee deliveryGuarantee) {\n    this.deliveryGuarantee = checkNotNull(deliveryGuarantee, \"deliveryGuarantee\");\n    return this;\n}", "summary_tokens": ["sets", "the", "wanted", "the", "delivery", "guarantee"], "project": "flink"}
{"id": 5583, "code": "public boolean isCanceledOrFailed() {\n    return executionState == ExecutionState.CANCELING\n            || executionState == ExecutionState.CANCELED\n            || executionState == ExecutionState.FAILED;\n}", "summary_tokens": ["checks", "whether", "the", "task", "has", "failed", "is", "canceled", "or", "is", "being", "canceled", "at", "the", "moment"], "project": "flink"}
{"id": 4025, "code": "public void testAkkaRpcServiceShutDownWithFailingRpcEndpoints() throws Exception {\n    final AkkaRpcService akkaRpcService = startAkkaRpcService();\n\n    final int numberActors = 5;\n\n    CompletableFuture<Void> terminationFuture = akkaRpcService.getTerminationFuture();\n\n    final Collection<CompletableFuture<Void>> onStopFutures =\n            startStopNCountingAsynchronousOnStopEndpoints(akkaRpcService, numberActors);\n\n    Iterator<CompletableFuture<Void>> iterator = onStopFutures.iterator();\n\n    for (int i = 0; i < numberActors - 1; i++) {\n        iterator.next().complete(null);\n    }\n\n    iterator.next().completeExceptionally(new OnStopException(\"onStop exception occurred.\"));\n\n    for (CompletableFuture<Void> onStopFuture : onStopFutures) {\n        onStopFuture.complete(null);\n    }\n\n    try {\n        terminationFuture.get();\n        fail(\"Expected the termination future to complete exceptionally.\");\n    } catch (ExecutionException e) {\n        assertThat(\n                ExceptionUtils.findThrowable(e, OnStopException.class).isPresent(), is(true));\n    }\n\n    assertThat(akkaRpcService.getActorSystem().whenTerminated().isCompleted(), is(true));\n}", "summary_tokens": ["tests", "that", "akka", "rpc", "service", "terminates", "all", "its", "rpc", "endpoints", "and", "also", "stops", "the", "underlying", "actor", "system", "if", "one", "of", "the", "rpc", "endpoints", "fails", "while", "stopping"], "project": "flink"}
{"id": 805, "code": "public Optional<String> getStreamConsumerArn(String stream) {\n    return Optional.ofNullable(streamConsumerArns.get(stream));\n}", "summary_tokens": ["get", "the", "according", "consumer", "arn", "to", "the", "stream", "will", "be", "null", "if", "efo", "registration", "type", "is", "lazy", "or", "eager"], "project": "flink"}
{"id": 7645, "code": "public void testIteration() {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStream<Integer> source = env.fromElements(1, 2, 3).name(\"source\");\n    IterativeStream<Integer> iteration = source.iterate(3000);\n    iteration.name(\"iteration\").setParallelism(2);\n    DataStream<Integer> map = iteration.map(x -> x + 1).name(\"map\").setParallelism(2);\n    DataStream<Integer> filter = map.filter((x) -> false).name(\"filter\").setParallelism(2);\n    iteration.closeWith(filter).print();\n\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\n    SlotSharingGroup slotSharingGroup = jobGraph.getVerticesAsArray()[0].getSlotSharingGroup();\n    assertNotNull(slotSharingGroup);\n\n    CoLocationGroup iterationSourceCoLocationGroup = null;\n    CoLocationGroup iterationSinkCoLocationGroup = null;\n\n    for (JobVertex jobVertex : jobGraph.getVertices()) {\n            \n        assertEquals(slotSharingGroup, jobVertex.getSlotSharingGroup());\n\n            \n            \n        if (jobVertex.getName().startsWith(StreamGraph.ITERATION_SOURCE_NAME_PREFIX)) {\n            iterationSourceCoLocationGroup = jobVertex.getCoLocationGroup();\n            assertTrue(\n                    iterationSourceCoLocationGroup.getVertexIds().contains(jobVertex.getID()));\n        } else if (jobVertex.getName().startsWith(StreamGraph.ITERATION_SINK_NAME_PREFIX)) {\n            iterationSinkCoLocationGroup = jobVertex.getCoLocationGroup();\n            assertTrue(iterationSinkCoLocationGroup.getVertexIds().contains(jobVertex.getID()));\n        } else {\n            assertNull(jobVertex.getCoLocationGroup());\n        }\n    }\n\n    assertNotNull(iterationSourceCoLocationGroup);\n    assertNotNull(iterationSinkCoLocationGroup);\n    assertEquals(iterationSourceCoLocationGroup, iterationSinkCoLocationGroup);\n}", "summary_tokens": ["test", "iteration", "job", "check", "slot", "sharing", "group", "and", "co", "location", "group"], "project": "flink"}
{"id": 2235, "code": "public void testRetryWithDelayFixedArgs() throws Exception {\n    final int retries = 4;\n    final Time delay = Time.milliseconds(5L);\n    final AtomicInteger countDown = new AtomicInteger(retries);\n\n    long start = System.currentTimeMillis();\n\n    CompletableFuture<Boolean> retryFuture =\n            FutureUtils.retryWithDelay(\n                    () -> {\n                        if (countDown.getAndDecrement() == 0) {\n                            return CompletableFuture.completedFuture(true);\n                        } else {\n                            return FutureUtils.completedExceptionally(\n                                    new FlinkException(\"Test exception.\"));\n                        }\n                    },\n                    retries,\n                    delay,\n                    TestingUtils.defaultScheduledExecutor());\n\n    Boolean result = retryFuture.get();\n\n    long completionTime = System.currentTimeMillis() - start;\n\n    assertTrue(result);\n    assertTrue(\n            \"The completion time should be at least retries times delay between retries.\",\n            completionTime >= retries * delay.toMilliseconds());\n}", "summary_tokens": ["tests", "that", "the", "delay", "is", "respected", "between", "subsequent", "retries", "of", "a", "retry", "future", "with", "retry", "delay"], "project": "flink"}
{"id": 5759, "code": "static void verifyJobCleanup(\n        PermanentBlobCache cache, JobID jobId, List<? extends BlobKey> keys)\n        throws InterruptedException, IOException {\n        \n        \n    {\n        long deadline = System.currentTimeMillis() + 30_000L;\n        do {\n            Thread.sleep(100);\n        } while (checkFilesExist(jobId, keys, cache, false) != 0\n                && System.currentTimeMillis() < deadline);\n    }\n\n        \n        \n    checkFileCountForJob(0, jobId, cache);\n}", "summary_tokens": ["checks", "that", "blobs", "for", "the", "given", "tt", "job", "id", "tt", "are", "cleaned", "up", "eventually", "after", "calling", "permanent", "blob", "cache", "release", "job", "job", "id", "which", "is", "not", "done", "by", "this", "method", "waits", "at", "most", "0", "s"], "project": "flink"}
{"id": 6298, "code": "public void testPendingBatchSlotRequestFailsIfAllocationFailsUnfulfillably() throws Exception {\n    final TestingResourceManagerGateway testingResourceManagerGateway =\n            new TestingResourceManagerGateway();\n\n    try (final DeclarativeSlotPoolBridge slotPool =\n            new DeclarativeSlotPoolBridgeBuilder()\n                    .setResourceManagerGateway(testingResourceManagerGateway)\n                    .buildAndStart(mainThreadExecutor)) {\n\n        final CompletableFuture<PhysicalSlot> slotFuture =\n                SlotPoolUtils.requestNewAllocatedBatchSlot(\n                        slotPool, mainThreadExecutor, resourceProfile);\n\n        SlotPoolUtils.notifyNotEnoughResourcesAvailable(\n                slotPool, mainThreadExecutor, Collections.emptyList());\n\n        assertThat(\n                slotFuture,\n                FlinkMatchers.futureWillCompleteExceptionally(Duration.ofSeconds(10L)));\n    }\n}", "summary_tokens": ["tests", "that", "a", "batch", "slot", "request", "does", "react", "to", "slot", "pool", "service", "notify", "not", "enough", "resources", "available"], "project": "flink"}
{"id": 8766, "code": "protected void validateFrom(SqlNode node, RelDataType targetRowType, SqlValidatorScope scope) {\n    Objects.requireNonNull(targetRowType);\n    switch (node.getKind()) {\n        case AS:\n        case TABLE_REF:\n            validateFrom(((SqlCall) node).operand(0), targetRowType, scope);\n            break;\n        case VALUES:\n            validateValues((SqlCall) node, targetRowType, scope);\n            break;\n        case JOIN:\n            validateJoin((SqlJoin) node, scope);\n            break;\n        case OVER:\n            validateOver((SqlCall) node, scope);\n            break;\n        case UNNEST:\n            validateUnnest((SqlCall) node, scope, targetRowType);\n            break;\n        default:\n            validateQuery(node, scope, targetRowType);\n            break;\n    }\n\n        \n        \n    getNamespace(node, scope).validate(targetRowType);\n}", "summary_tokens": ["validates", "the", "from", "clause", "of", "a", "query", "or", "recursively", "a", "child", "node", "of", "the", "from", "clause", "as", "over", "join", "values", "or", "sub", "query"], "project": "flink"}
{"id": 3031, "code": "private Collection<ComputationState> computeNextStates(\n        final SharedBufferAccessor<T> sharedBufferAccessor,\n        final ComputationState computationState,\n        final EventWrapper event,\n        final TimerService timerService)\n        throws Exception {\n\n    final ConditionContext context =\n            new ConditionContext(\n                    sharedBufferAccessor, computationState, timerService, event.getTimestamp());\n\n    final OutgoingEdges<T> outgoingEdges =\n            createDecisionGraph(context, computationState, event.getEvent());\n\n        \n        \n        \n    final List<StateTransition<T>> edges = outgoingEdges.getEdges();\n    int takeBranchesToVisit = Math.max(0, outgoingEdges.getTotalTakeBranches() - 1);\n    int ignoreBranchesToVisit = outgoingEdges.getTotalIgnoreBranches();\n    int totalTakeToSkip = Math.max(0, outgoingEdges.getTotalTakeBranches() - 1);\n\n    final List<ComputationState> resultingComputationStates = new ArrayList<>();\n    for (StateTransition<T> edge : edges) {\n        switch (edge.getAction()) {\n            case IGNORE:\n                {\n                    if (!isStartState(computationState)) {\n                        final DeweyNumber version;\n                        if (isEquivalentState(\n                                edge.getTargetState(), getState(computationState))) {\n                                \n                                \n                            final int toIncrease =\n                                    calculateIncreasingSelfState(\n                                            outgoingEdges.getTotalIgnoreBranches(),\n                                            outgoingEdges.getTotalTakeBranches());\n                            version = computationState.getVersion().increase(toIncrease);\n                        } else {\n                                \n                            version =\n                                    computationState\n                                            .getVersion()\n                                            .increase(totalTakeToSkip + ignoreBranchesToVisit)\n                                            .addStage();\n                            ignoreBranchesToVisit--;\n                        }\n\n                        addComputationState(\n                                sharedBufferAccessor,\n                                resultingComputationStates,\n                                edge.getTargetState(),\n                                computationState.getPreviousBufferEntry(),\n                                version,\n                                computationState.getStartTimestamp(),\n                                computationState.getStartEventID());\n                    }\n                }\n                break;\n            case TAKE:\n                final State<T> nextState = edge.getTargetState();\n                final State<T> currentState = edge.getSourceState();\n\n                final NodeId previousEntry = computationState.getPreviousBufferEntry();\n\n                final DeweyNumber currentVersion =\n                        computationState.getVersion().increase(takeBranchesToVisit);\n                final DeweyNumber nextVersion = new DeweyNumber(currentVersion).addStage();\n                takeBranchesToVisit--;\n\n                final NodeId newEntry =\n                        sharedBufferAccessor.put(\n                                currentState.getName(),\n                                event.getEventId(),\n                                previousEntry,\n                                currentVersion);\n\n                final long startTimestamp;\n                final EventId startEventId;\n                if (isStartState(computationState)) {\n                    startTimestamp = event.getTimestamp();\n                    startEventId = event.getEventId();\n                } else {\n                    startTimestamp = computationState.getStartTimestamp();\n                    startEventId = computationState.getStartEventID();\n                }\n\n                addComputationState(\n                        sharedBufferAccessor,\n                        resultingComputationStates,\n                        nextState,\n                        newEntry,\n                        nextVersion,\n                        startTimestamp,\n                        startEventId);\n\n                    \n                final State<T> finalState =\n                        findFinalStateAfterProceed(context, nextState, event.getEvent());\n                if (finalState != null) {\n                    addComputationState(\n                            sharedBufferAccessor,\n                            resultingComputationStates,\n                            finalState,\n                            newEntry,\n                            nextVersion,\n                            startTimestamp,\n                            startEventId);\n                }\n                break;\n        }\n    }\n\n    if (isStartState(computationState)) {\n        int totalBranches =\n                calculateIncreasingSelfState(\n                        outgoingEdges.getTotalIgnoreBranches(),\n                        outgoingEdges.getTotalTakeBranches());\n\n        DeweyNumber startVersion = computationState.getVersion().increase(totalBranches);\n        ComputationState startState =\n                ComputationState.createStartState(\n                        computationState.getCurrentStateName(), startVersion);\n        resultingComputationStates.add(startState);\n    }\n\n    if (computationState.getPreviousBufferEntry() != null) {\n            \n        sharedBufferAccessor.releaseNode(\n                computationState.getPreviousBufferEntry(), computationState.getVersion());\n    }\n\n    return resultingComputationStates;\n}", "summary_tokens": ["computes", "the", "next", "computation", "states", "based", "on", "the", "given", "computation", "state", "the", "current", "event", "its", "timestamp", "and", "the", "internal", "state", "machine"], "project": "flink"}
{"id": 8196, "code": "public Map<K, V> getMap() {\n    return map;\n}", "summary_tokens": ["returns", "the", "entire", "view", "s", "content", "as", "an", "instance", "of", "map"], "project": "flink"}
{"id": 8239, "code": "public List<WatermarkSpec> getWatermarkSpecs() {\n    return watermarkSpecs;\n}", "summary_tokens": ["returns", "a", "list", "of", "watermark", "specifications", "each", "consisting", "of", "a", "rowtime", "attribute", "and", "watermark", "strategy", "expression"], "project": "flink"}
{"id": 6778, "code": "K deserializeKey(MemorySegment memorySegment, int offset, int len) {\n    MemorySegmentInputStreamWithPos inputStream =\n            new MemorySegmentInputStreamWithPos(memorySegment, offset, len);\n    DataInputViewStreamWrapper inputView = new DataInputViewStreamWrapper(inputStream);\n    int namespaceLen = memorySegment.getInt(offset);\n    inputStream.setPosition(offset + Integer.BYTES + namespaceLen + Integer.BYTES);\n    try {\n        return keySerializer.deserialize(inputView);\n    } catch (IOException e) {\n        throw new RuntimeException(\"deserialize key failed\", e);\n    }\n}", "summary_tokens": ["deserialize", "the", "partition", "key", "from", "the", "byte", "buffer", "which", "stores", "skip", "list", "key"], "project": "flink"}
{"id": 7644, "code": "public void testExchangeModeUndefined() {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n        \n    DataStream<Integer> sourceDataStream = env.fromElements(1, 2, 3);\n\n    DataStream<Integer> partitionAfterSourceDataStream =\n            new DataStream<>(\n                    env,\n                    new PartitionTransformation<>(\n                            sourceDataStream.getTransformation(),\n                            new ForwardPartitioner<>(),\n                            StreamExchangeMode.UNDEFINED));\n    DataStream<Integer> mapDataStream =\n            partitionAfterSourceDataStream.map(value -> value).setParallelism(1);\n\n    DataStream<Integer> partitionAfterMapDataStream =\n            new DataStream<>(\n                    env,\n                    new PartitionTransformation<>(\n                            mapDataStream.getTransformation(),\n                            new RescalePartitioner<>(),\n                            StreamExchangeMode.UNDEFINED));\n    partitionAfterMapDataStream.print().setParallelism(2);\n\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n\n    List<JobVertex> verticesSorted = jobGraph.getVerticesSortedTopologicallyFromSources();\n    assertEquals(2, verticesSorted.size());\n\n        \n    JobVertex sourceAndMapVertex = verticesSorted.get(0);\n\n        \n    assertEquals(\n            ResultPartitionType.PIPELINED_BOUNDED,\n            sourceAndMapVertex.getProducedDataSets().get(0).getResultType());\n}", "summary_tokens": ["test", "setting", "exchange", "mode", "to", "stream", "exchange", "mode", "undefined"], "project": "flink"}
{"id": 6527, "code": "public void awaitCanceledVertices(int count) throws InterruptedException {\n    canceledVertices.await(count);\n}", "summary_tokens": ["waits", "until", "the", "given", "number", "of", "vertices", "have", "been", "canceled"], "project": "flink"}
{"id": 4844, "code": "public int getSegmentSize() {\n    return this.segmentSize;\n}", "summary_tokens": ["gets", "the", "size", "of", "the", "segments", "used", "by", "this", "view"], "project": "flink"}
{"id": 9745, "code": "public void testConfigurationClusterSpecification() throws Exception {\n    final Configuration configuration = new Configuration();\n    final int jobManagerMemory = 1337;\n    configuration.set(\n            JobManagerOptions.TOTAL_PROCESS_MEMORY, MemorySize.ofMebiBytes(jobManagerMemory));\n    final int taskManagerMemory = 7331;\n    configuration.set(\n            TaskManagerOptions.TOTAL_PROCESS_MEMORY, MemorySize.ofMebiBytes(taskManagerMemory));\n    final int slotsPerTaskManager = 42;\n    configuration.setInteger(TaskManagerOptions.NUM_TASK_SLOTS, slotsPerTaskManager);\n\n    final String[] args = {};\n    final FlinkYarnSessionCli flinkYarnSessionCli = createFlinkYarnSessionCli(configuration);\n\n    CommandLine commandLine = flinkYarnSessionCli.parseCommandLineOptions(args, false);\n\n    configuration.addAll(flinkYarnSessionCli.toConfiguration(commandLine));\n\n    ClusterClientFactory<ApplicationId> clientFactory = getClusterClientFactory(configuration);\n    ClusterSpecification clusterSpecification =\n            clientFactory.getClusterSpecification(configuration);\n\n    assertThat(clusterSpecification.getMasterMemoryMB(), is(jobManagerMemory));\n    assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(taskManagerMemory));\n    assertThat(clusterSpecification.getSlotsPerTaskManager(), is(slotsPerTaskManager));\n}", "summary_tokens": ["tests", "that", "the", "configuration", "settings", "are", "used", "to", "create", "the", "cluster", "specification"], "project": "flink"}
{"id": 9506, "code": "public static Matcher<Throwable> containsCause(Throwable failureCause) {\n    return new ContainsCauseAndMessageMatcher(failureCause);\n}", "summary_tokens": ["checks", "for", "a", "throwable", "that", "matches", "by", "class", "and", "message"], "project": "flink"}
{"id": 1809, "code": "public byte[] getHeapMemory() {\n    return heapMemory;\n}", "summary_tokens": ["get", "the", "heap", "byte", "array", "object"], "project": "flink"}
{"id": 1391, "code": "public final ClassLoader getUserCodeClassLoader() {\n    return userCodeClassLoader;\n}", "summary_tokens": ["returns", "the", "user", "code", "class", "loader"], "project": "flink"}
{"id": 8162, "code": "public static TypeInformation<Byte> BYTE() {\n    return org.apache.flink.api.common.typeinfo.Types.BYTE;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "byte", "or", "sql", "tinyint", "type"], "project": "flink"}
{"id": 9333, "code": "public boolean isEmpty(W window) throws Exception {\n    windowState.setCurrentNamespace(window);\n    return windowState.isEmpty();\n}", "summary_tokens": ["returns", "true", "if", "this", "state", "contains", "no", "key", "value", "mappings", "otherwise", "false"], "project": "flink"}
{"id": 9198, "code": "public static RecordCounter of(int indexOfCountStar) {\n    if (indexOfCountStar >= 0) {\n        return new RetractionRecordCounter(indexOfCountStar);\n    } else {\n        return new AccumulationRecordCounter();\n    }\n}", "summary_tokens": ["creates", "a", "record", "counter", "depends", "on", "the", "index", "of", "count"], "project": "flink"}
{"id": 7589, "code": "public void suspend() {\n    sendPoisonMail(() -> suspended = true);\n}", "summary_tokens": ["suspend", "the", "running", "of", "the", "loop", "which", "was", "started", "by", "run", "mailbox", "loop"], "project": "flink"}
{"id": 6506, "code": "public void testRemoteAndSelfGateways() throws Exception {\n    final UUID initialFencingToken = UUID.randomUUID();\n    final UUID newFencingToken = UUID.randomUUID();\n    final String value = \"foobar\";\n\n    final FencedTestingEndpoint fencedTestingEndpoint =\n            new FencedTestingEndpoint(rpcService, value, initialFencingToken);\n\n    try {\n        fencedTestingEndpoint.start();\n\n        FencedTestingGateway selfGateway =\n                fencedTestingEndpoint.getSelfGateway(FencedTestingGateway.class);\n        FencedTestingGateway remoteGateway =\n                rpcService\n                        .connect(\n                                fencedTestingEndpoint.getAddress(),\n                                initialFencingToken,\n                                FencedTestingGateway.class)\n                        .get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\n        assertEquals(initialFencingToken, selfGateway.getFencingToken());\n        assertEquals(initialFencingToken, remoteGateway.getFencingToken());\n\n        assertEquals(\n                value,\n                selfGateway\n                        .foobar(timeout)\n                        .get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS));\n        assertEquals(\n                value,\n                remoteGateway\n                        .foobar(timeout)\n                        .get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS));\n\n        CompletableFuture<Acknowledge> newFencingTokenFuture =\n                fencedTestingEndpoint.setFencingTokenInMainThread(newFencingToken, timeout);\n\n            \n        newFencingTokenFuture.get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\n        assertEquals(newFencingToken, selfGateway.getFencingToken());\n        assertNotEquals(newFencingToken, remoteGateway.getFencingToken());\n\n        assertEquals(\n                value,\n                selfGateway\n                        .foobar(timeout)\n                        .get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS));\n\n        try {\n            remoteGateway.foobar(timeout).get(timeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n            fail(\"This should have failed because we don't have the right fencing token.\");\n        } catch (ExecutionException e) {\n            assertTrue(\n                    ExceptionUtils.stripExecutionException(e) instanceof FencingTokenException);\n        }\n    } finally {\n        RpcUtils.terminateRpcEndpoint(fencedTestingEndpoint, timeout);\n    }\n}", "summary_tokens": ["tests", "that", "the", "self", "gateway", "always", "uses", "the", "current", "fencing", "token", "whereas", "the", "remote", "gateway", "has", "a", "fixed", "fencing", "token"], "project": "flink"}
{"id": 1335, "code": "public String getQueryableStateName() {\n    return queryableStateName;\n}", "summary_tokens": ["returns", "the", "queryable", "state", "name"], "project": "flink"}
{"id": 6782, "code": "public static NodeStatus getNodeStatus(MemorySegment memorySegment, int offset) {\n    byte status = (byte) ((memorySegment.getInt(offset + KEY_META_OFFSET) >>> 8) & BYTE_MASK);\n    return NodeStatus.valueOf(status);\n}", "summary_tokens": ["returns", "the", "status", "of", "the", "node"], "project": "flink"}
{"id": 1258, "code": "public ResourceSpec subtract(final ResourceSpec other) {\n    checkNotNull(other, \"Cannot subtract null resources\");\n\n    if (this.equals(UNKNOWN) || other.equals(UNKNOWN)) {\n        return UNKNOWN;\n    }\n\n    checkArgument(\n            other.lessThanOrEqual(this),\n            \"Cannot subtract a larger ResourceSpec from this one.\");\n\n    Map<String, ExternalResource> resultExtendedResources = new HashMap<>(extendedResources);\n    for (ExternalResource resource : other.extendedResources.values()) {\n        resultExtendedResources.merge(\n                resource.getName(), resource, (v1, v2) -> v1.subtract(v2));\n    }\n\n    return new ResourceSpec(\n            this.cpuCores.subtract(other.cpuCores),\n            this.taskHeapMemory.subtract(other.taskHeapMemory),\n            this.taskOffHeapMemory.subtract(other.taskOffHeapMemory),\n            this.managedMemory.subtract(other.managedMemory),\n            resultExtendedResources);\n}", "summary_tokens": ["subtracts", "another", "resource", "spec", "from", "this", "one"], "project": "flink"}
{"id": 747, "code": "private void checkAndPropagateAsyncError() throws Exception {\n    if (thrownException != null) {\n        String errorMessages = \"\";\n        if (thrownException instanceof UserRecordFailedException) {\n            List<Attempt> attempts =\n                    ((UserRecordFailedException) thrownException).getResult().getAttempts();\n            for (Attempt attempt : attempts) {\n                if (attempt.getErrorMessage() != null) {\n                    errorMessages += attempt.getErrorMessage() + \"\\n\";\n                }\n            }\n        }\n        if (failOnError) {\n            throw new RuntimeException(\n                    \"An exception was thrown while processing a record: \" + errorMessages,\n                    thrownException);\n        } else {\n            LOG.warn(\n                    \"An exception was thrown while processing a record: {}.\",\n                    errorMessages,\n                    thrownException);\n\n                \n            thrownException = null;\n        }\n    }\n}", "summary_tokens": ["check", "if", "there", "are", "any", "asynchronous", "exceptions"], "project": "flink"}
{"id": 5136, "code": "protected void onFatalError(Throwable t) {\n    try {\n        log.error(\"Fatal error occurred in ResourceManager.\", t);\n    } catch (Throwable ignored) {\n    }\n\n        \n    fatalErrorHandler.onFatalError(t);\n}", "summary_tokens": ["notifies", "the", "resource", "manager", "that", "a", "fatal", "error", "has", "occurred", "and", "it", "cannot", "proceed"], "project": "flink"}
{"id": 2328, "code": "    private static int[] findSubVariable(String eval) {\n        int[] result = {-1, -1};\n\n        int matchStart;\n        int leftBrace;\n\n        \n        \n        \n        match_loop:\n        for (matchStart = 1, leftBrace = eval.indexOf('{', matchStart);\n                \n                leftBrace > 0\n                        \n                        && leftBrace + \"{c\".length() < eval.length();\n                leftBrace = eval.indexOf('{', matchStart)) {\n            int matchedLen = 0;\n            if (eval.charAt(leftBrace - 1) == '$') {\n                int subStart = leftBrace + 1; \n                for (int i = subStart; i < eval.length(); i++) {\n                    switch (eval.charAt(i)) {\n                        case '}':\n                            if (matchedLen > 0) { \n                                result[SUB_START_IDX] = subStart;\n                                result[SUB_END_IDX] = subStart + matchedLen;\n                                break match_loop;\n                            }\n                            \n                        case ' ':\n                        case '$':\n                            matchStart = i + 1;\n                            continue match_loop;\n                        default:\n                            matchedLen++;\n                    }\n                }\n                \n                \n                break match_loop;\n            } else {\n                \n                \n                matchStart = leftBrace + 1;\n            }\n        }\n        return result;\n    }\n\n    \n    private String substituteVars(String expr) {\n        if (expr == null) {\n            return null;\n        }\n        String eval = expr;\n        for (int s = 0; s < MAX_SUBST; s++) {\n            final int[] varBounds = findSubVariable(eval);\n            if (varBounds[SUB_START_IDX] == -1) {\n                return eval;\n            }\n            final String var = eval.substring(varBounds[SUB_START_IDX], varBounds[SUB_END_IDX]);\n            String val = null;\n            if (!restrictSystemProps) {\n                try {\n                    if (var.startsWith(\"env.\") && 4 < var.length()) {\n                        String v = var.substring(4);\n                        int i = 0;\n                        for (; i < v.length(); i++) {\n                            char c = v.charAt(i);\n                            if (c == ':' && i < v.length() - 1 && v.charAt(i + 1) == '-') {\n                                val = getenv(v.substring(0, i));\n                                if (val == null || val.length() == 0) {\n                                    val = v.substring(i + 2);\n                                }\n                                break;\n                            } else if (c == '-') {\n                                val = getenv(v.substring(0, i));\n                                if (val == null) {\n                                    val = v.substring(i + 1);\n                                }\n                                break;\n                            }\n                        }\n                        if (i == v.length()) {\n                            val = getenv(v);\n                        }\n                    } else {\n                        val = getProperty(var);\n                    }\n                } catch (SecurityException se) {\n                    LOG.warn(\"Unexpected SecurityException in Configuration\", se);\n                }\n            }\n            if (val == null) {\n                val = getRaw(var);\n            }\n            if (val == null) {\n                return eval; \n            }\n\n            final int dollar = varBounds[SUB_START_IDX] - \"${\".length();\n            final int afterRightBrace = varBounds[SUB_END_IDX] + \"}\".length();\n            final String refVar = eval.substring(dollar, afterRightBrace);\n\n            \n            if (val.contains(refVar)) {\n                return expr; \n            }\n\n            \n            eval = eval.substring(0, dollar) + val + eval.substring(afterRightBrace);\n        }\n        throw new IllegalStateException(\n                \"Variable substitution depth too large: \" + MAX_SUBST + \" \" + expr);\n    }\n\n    String getenv(String name) {\n        return System.getenv(name);\n    }\n\n    String getProperty(String key) {\n        return System.getProperty(key);\n    }\n\n    \n    public String get(String name) {\n        String[] names = handleDeprecation(deprecationContext.get(), name);\n        String result = null;\n        for (String n : names) {\n            result = substituteVars(getProps().getProperty(n));\n        }\n        return result;\n    }\n\n    \n    @VisibleForTesting\n    public void setAllowNullValueProperties(boolean val) {\n        this.allowNullValueProperties = val;\n    }\n\n    public void setRestrictSystemProps(boolean val) {\n        this.restrictSystemProps = val;\n    }\n\n    \n    @VisibleForTesting\n    public boolean onlyKeyExists(String name) {\n        String[] names = handleDeprecation(deprecationContext.get(), name);\n        for (String n : names) {\n            if (getProps().getProperty(n, DEFAULT_STRING_CHECK).equals(DEFAULT_STRING_CHECK)) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    \n    public String getTrimmed(String name) {\n        String value = get(name);\n\n        if (null == value) {\n            return null;\n        } else {\n            return value.trim();\n        }\n    }\n\n    \n    public String getTrimmed(String name, String defaultValue) {\n        String ret = getTrimmed(name);\n        return ret == null ? defaultValue : ret;\n    }\n\n    \n    public String getRaw(String name) {\n        String[] names = handleDeprecation(deprecationContext.get(), name);\n        String result = null;\n        for (String n : names) {\n            result = getProps().getProperty(n);\n        }\n        return result;\n    }\n\n    \n    private String[] getAlternativeNames(String name) {\n        String altNames[] = null;\n        DeprecatedKeyInfo keyInfo = null;\n        DeprecationContext cur = deprecationContext.get();\n        String depKey = cur.getReverseDeprecatedKeyMap().get(name);\n        if (depKey != null) {\n            keyInfo = cur.getDeprecatedKeyMap().get(depKey);\n            if (keyInfo.newKeys.length > 0) {\n                if (getProps().containsKey(depKey)) {\n                    \n                    List<String> list = new ArrayList<String>();\n                    list.addAll(Arrays.asList(keyInfo.newKeys));\n                    list.add(depKey);\n                    altNames = list.toArray(new String[list.size()]);\n                } else {\n                    altNames = keyInfo.newKeys;\n                }\n            }\n        }\n        return altNames;\n    }\n\n    \n    public void set(String name, String value) {\n        set(name, value, null);\n    }\n\n    \n    public void set(String name, String value, String source) {\n        Preconditions.checkArgument(name != null, \"Property name must not be null\");\n        Preconditions.checkArgument(\n                value != null, \"The value of property %s must not be null\", name);\n        name = name.trim();\n        DeprecationContext deprecations = deprecationContext.get();\n        if (deprecations.getDeprecatedKeyMap().isEmpty()) {\n            getProps();\n        }\n        getOverlay().setProperty(name, value);\n        getProps().setProperty(name, value);\n        String newSource = (source == null ? \"programmatically\" : source);\n\n        if (!isDeprecated(name)) {\n            putIntoUpdatingResource(name, new String[] {newSource});\n            String[] altNames = getAlternativeNames(name);\n            if (altNames != null) {\n                for (String n : altNames) {\n                    if (!n.equals(name)) {\n                        getOverlay().setProperty(n, value);\n                        getProps().setProperty(n, value);\n                        putIntoUpdatingResource(n, new String[] {newSource});\n                    }\n                }\n            }\n        } else {\n            String[] names = handleDeprecation(deprecationContext.get(), name);\n            String altSource = \"because \" + name + \" is deprecated\";\n            for (String n : names) {\n                getOverlay().setProperty(n, value);\n                getProps().setProperty(n, value);\n                putIntoUpdatingResource(n, new String[] {altSource});\n            }\n        }\n    }\n\n    @VisibleForTesting\n    void logDeprecation(String message) {\n        LOG_DEPRECATION.info(message);\n    }\n\n    void logDeprecationOnce(String name, String source) {\n        DeprecatedKeyInfo keyInfo = getDeprecatedKeyInfo(name);\n        if (keyInfo != null && !keyInfo.getAndSetAccessed()) {\n            LOG_DEPRECATION.info(keyInfo.getWarningMessage(name, source));\n        }\n    }\n\n    \n    public synchronized void unset(String name) {\n        String[] names = null;\n        if (!isDeprecated(name)) {\n            names = getAlternativeNames(name);\n            if (names == null) {\n                names = new String[] {name};\n            }\n        } else {\n            names = handleDeprecation(deprecationContext.get(), name);\n        }\n\n        for (String n : names) {\n            getOverlay().remove(n);\n            getProps().remove(n);\n        }\n    }\n\n    \n    public synchronized void setIfUnset(String name, String value) {\n        if (get(name) == null) {\n            set(name, value);\n        }\n    }\n\n    private synchronized Properties getOverlay() {\n        if (overlay == null) {\n            overlay = new Properties();\n        }\n        return overlay;\n    }\n\n    \n    public String get(String name, String defaultValue) {\n        String[] names = handleDeprecation(deprecationContext.get(), name);\n        String result = null;\n        for (String n : names) {\n            result = substituteVars(getProps().getProperty(n, defaultValue));\n        }\n        return result;\n    }\n\n    \n    public int getInt(String name, int defaultValue) {\n        String valueString = getTrimmed(name);\n        if (valueString == null) return defaultValue;\n        String hexString = getHexDigits(valueString);\n        if (hexString != null) {\n            return Integer.parseInt(hexString, 16);\n        }\n        return Integer.parseInt(valueString);\n    }\n\n    \n    public int[] getInts(String name) {\n        String[] strings = getTrimmedStrings(name);\n        int[] ints = new int[strings.length];\n        for (int i = 0; i < strings.length; i++) {\n            ints[i] = Integer.parseInt(strings[i]);\n        }\n        return ints;\n    }\n\n    \n    public void setInt(String name, int value) {\n        set(name, Integer.toString(value));\n    }\n\n    \n    public long getLong(String name, long defaultValue) {\n        String valueString = getTrimmed(name);\n        if (valueString == null) return defaultValue;\n        String hexString = getHexDigits(valueString);\n        if (hexString != null) {\n            return Long.parseLong(hexString, 16);\n        }\n        return Long.parseLong(valueString);\n    }\n\n    \n    public long getLongBytes(String name, long defaultValue) {\n        String valueString = getTrimmed(name);\n        if (valueString == null) return defaultValue;\n        return StringUtils.TraditionalBinaryPrefix.string2long(valueString);\n    }\n\n    private String getHexDigits(String value) {\n        boolean negative = false;\n        String str = value;\n        String hexString = null;\n        if (value.startsWith(\"-\")) {\n            negative = true;\n            str = value.substring(1);\n        }\n        if (str.startsWith(\"0x\") || str.startsWith(\"0X\")) {\n            hexString = str.substring(2);\n            if (negative) {\n                hexString = \"-\" + hexString;\n            }\n            return hexString;\n        }\n        return null;\n    }\n\n    \n    public void setLong(String name, long value) {\n        set(name, Long.toString(value));\n    }\n\n    \n    public float getFloat(String name, float defaultValue) {\n        String valueString = getTrimmed(name);\n        if (valueString == null) return defaultValue;\n        return Float.parseFloat(valueString);\n    }\n\n    \n    public void setFloat(String name, float value) {\n        set(name, Float.toString(value));\n    }\n\n    \n    public double getDouble(String name, double defaultValue) {\n        String valueString = getTrimmed(name);\n        if (valueString == null) return defaultValue;\n        return Double.parseDouble(valueString);\n    }\n\n    \n    public void setDouble(String name, double value) {\n        set(name, Double.toString(value));\n    }\n\n    \n    public boolean getBoolean(String name, boolean defaultValue) {\n        String valueString = getTrimmed(name);\n        if (null == valueString || valueString.isEmpty()) {\n            return defaultValue;\n        }\n\n        if (StringUtils.equalsIgnoreCase(\"true\", valueString)) return true;\n        else if (StringUtils.equalsIgnoreCase(\"false\", valueString)) return false;\n        else return defaultValue;\n    }\n\n    \n    public void setBoolean(String name, boolean value) {\n        set(name, Boolean.toString(value));\n    }\n\n    \n    public void setBooleanIfUnset(String name, boolean value) {\n        setIfUnset(name, Boolean.toString(value));\n    }\n\n    \n    public <T extends Enum<T>> void setEnum(String name, T value) {\n        set(name, value.toString());\n    }\n\n    \n    public <T extends Enum<T>> T getEnum(String name, T defaultValue) {\n        final String val = getTrimmed(name);\n        return null == val ? defaultValue : Enum.valueOf(defaultValue.getDeclaringClass(), val);\n    }\n\n    enum ParsedTimeDuration {\n        NS {\n            TimeUnit unit() {\n                return TimeUnit.NANOSECONDS;\n            }\n\n            String suffix() {\n                return \"ns\";\n            }\n        },\n        US {\n            TimeUnit unit() {\n                return TimeUnit.MICROSECONDS;\n            }\n\n            String suffix() {\n                return \"us\";\n            }\n        },\n        MS {\n            TimeUnit unit() {\n                return TimeUnit.MILLISECONDS;\n            }\n\n            String suffix() {\n                return \"ms\";\n            }\n        },\n        S {\n            TimeUnit unit() {\n                return TimeUnit.SECONDS;\n            }\n\n            String suffix() {\n                return \"s\";\n            }\n        },\n        M {\n            TimeUnit unit() {\n                return TimeUnit.MINUTES;\n            }\n\n            String suffix() {\n                return \"m\";\n            }\n        },\n        H {\n            TimeUnit unit() {\n                return TimeUnit.HOURS;\n            }\n\n            String suffix() {\n                return \"h\";\n            }\n        },\n        D {\n            TimeUnit unit() {\n                return TimeUnit.DAYS;\n            }\n\n            String suffix() {\n                return \"d\";\n            }\n        };\n\n        abstract TimeUnit unit();\n\n        abstract String suffix();\n\n        static ParsedTimeDuration unitFor(String s) {\n            for (ParsedTimeDuration ptd : values()) {\n                \n                if (s.endsWith(ptd.suffix())) {\n                    return ptd;\n                }\n            }\n            return null;\n        }\n\n        static ParsedTimeDuration unitFor(TimeUnit unit) {\n            for (ParsedTimeDuration ptd : values()) {\n                if (ptd.unit() == unit) {\n                    return ptd;\n                }\n            }\n            return null;\n        }\n    }\n\n    \n    public void setTimeDuration(String name, long value, TimeUnit unit) {\n        set(name, value + ParsedTimeDuration.unitFor(unit).suffix());\n    }\n\n    \n    public long getTimeDuration(String name, long defaultValue, TimeUnit unit) {\n        String vStr = get(name);\n        if (null == vStr) {\n            return defaultValue;\n        } else {\n            return getTimeDurationHelper(name, vStr, unit);\n        }\n    }\n\n    public long getTimeDuration(String name, String defaultValue, TimeUnit unit) {\n        String vStr = get(name);\n        if (null == vStr) {\n            return getTimeDurationHelper(name, defaultValue, unit);\n        } else {\n            return getTimeDurationHelper(name, vStr, unit);\n        }\n    }\n\n    \n    public long getTimeDurationHelper(String name, String vStr, TimeUnit unit) {\n        vStr = vStr.trim();\n        vStr = StringUtils.toLowerCase(vStr);\n        ParsedTimeDuration vUnit = ParsedTimeDuration.unitFor(vStr);\n        if (null == vUnit) {\n            logDeprecation(\"No unit for \" + name + \"(\" + vStr + \") assuming \" + unit);\n            vUnit = ParsedTimeDuration.unitFor(unit);\n        } else {\n            vStr = vStr.substring(0, vStr.lastIndexOf(vUnit.suffix()));\n        }\n\n        long raw = Long.parseLong(vStr);\n        long converted = unit.convert(raw, vUnit.unit());\n        if (vUnit.unit().convert(converted, unit) < raw) {\n            logDeprecation(\n                    \"Possible loss of precision converting \"\n                            + vStr\n                            + vUnit.suffix()\n                            + \" to \"\n                            + unit\n                            + \" for \"\n                            + name);\n        }\n        return converted;\n    }\n\n    public long[] getTimeDurations(String name, TimeUnit unit) {\n        String[] strings = getTrimmedStrings(name);\n        long[] durations = new long[strings.length];\n        for (int i = 0; i < strings.length; i++) {\n            durations[i] = getTimeDurationHelper(name, strings[i], unit);\n        }\n        return durations;\n    }\n    \n    public double getStorageSize(String name, String defaultValue, StorageUnit targetUnit) {\n        Preconditions.checkState(isNotBlank(name), \"Key cannot be blank.\");\n        String vString = get(name);\n        if (isBlank(vString)) {\n            vString = defaultValue;\n        }\n\n        \n        \n        \n\n        \n\n        StorageSize measure = StorageSize.parse(vString);\n        return convertStorageUnit(measure.getValue(), measure.getUnit(), targetUnit);\n    }\n\n    \n    public double getStorageSize(String name, double defaultValue, StorageUnit targetUnit) {\n        Preconditions.checkNotNull(targetUnit, \"Conversion unit cannot be null.\");\n        Preconditions.checkState(isNotBlank(name), \"Name cannot be blank.\");\n        String vString = get(name);\n        if (isBlank(vString)) {\n            return targetUnit.getDefault(defaultValue);\n        }\n\n        StorageSize measure = StorageSize.parse(vString);\n        return convertStorageUnit(measure.getValue(), measure.getUnit(), targetUnit);\n    }\n\n    \n    public void setStorageSize(String name, double value, StorageUnit unit) {\n        set(name, value + unit.getShortName());\n    }\n\n    \n    private double convertStorageUnit(\n            double value, StorageUnit sourceUnit, StorageUnit targetUnit) {\n        double byteValue = sourceUnit.toBytes(value);\n        return targetUnit.fromBytes(byteValue);\n    }\n\n    \n    public Pattern getPattern(String name, Pattern defaultValue) {\n        String valString = get(name);\n        if (null == valString || valString.isEmpty()) {\n            return defaultValue;\n        }\n        try {\n            return Pattern.compile(valString);\n        } catch (PatternSyntaxException pse) {\n            LOG.warn(\n                    \"Regular expression '\"\n                            + valString\n                            + \"' for property '\"\n                            + name\n                            + \"' not valid. Using default\",\n                    pse);\n            return defaultValue;\n        }\n    }\n\n    \n    public void setPattern(String name, Pattern pattern) {\n        assert pattern != null : \"Pattern cannot be null\";\n        set(name, pattern.pattern());\n    }\n\n    \n    @InterfaceStability.Unstable\n    public synchronized String[] getPropertySources(String name) {\n        if (properties == null) {\n            \n            \n            \n            getProps();\n        }\n        \n        \n        if (properties == null || updatingResource == null) {\n            return null;\n        } else {\n            String[] source = updatingResource.get(name);\n            if (source == null) {\n                return null;\n            } else {\n                return Arrays.copyOf(source, source.length);\n            }\n        }\n    }\n\n    \n    public static class IntegerRanges implements Iterable<Integer> {\n        private static class Range {\n            int start;\n            int end;\n        }\n\n        private static class RangeNumberIterator implements Iterator<Integer> {\n            Iterator<Range> internal;\n            int at;\n            int end;\n\n            public RangeNumberIterator(List<Range> ranges) {\n                if (ranges != null) {\n                    internal = ranges.iterator();\n                }\n                at = -1;\n                end = -2;\n            }\n\n            @Override\n            public boolean hasNext() {\n                if (at <= end) {\n                    return true;\n                } else if (internal != null) {\n                    return internal.hasNext();\n                }\n                return false;\n            }\n\n            @Override\n            public Integer next() {\n                if (at <= end) {\n                    at++;\n                    return at - 1;\n                } else if (internal != null) {\n                    Range found = internal.next();\n                    if (found != null) {\n                        at = found.start;\n                        end = found.end;\n                        at++;\n                        return at - 1;\n                    }\n                }\n                return null;\n            }\n\n            @Override\n            public void remove() {\n                throw new UnsupportedOperationException();\n            }\n        };\n\n        List<Range> ranges = new ArrayList<Range>();\n\n        public IntegerRanges() {}\n\n        public IntegerRanges(String newValue) {\n            StringTokenizer itr = new StringTokenizer(newValue, \",\");\n            while (itr.hasMoreTokens()) {\n                String rng = itr.nextToken().trim();\n                String[] parts = rng.split(\"-\", 3);\n                if (parts.length < 1 || parts.length > 2) {\n                    throw new IllegalArgumentException(\"integer range badly formed: \" + rng);\n                }\n                Range r = new Range();\n                r.start = convertToInt(parts[0], 0);\n                if (parts.length == 2) {\n                    r.end = convertToInt(parts[1], Integer.MAX_VALUE);\n                } else {\n                    r.end = r.start;\n                }\n                if (r.start > r.end) {\n                    throw new IllegalArgumentException(\n                            \"IntegerRange from \" + r.start + \" to \" + r.end + \" is invalid\");\n                }\n                ranges.add(r);\n            }\n        }\n\n        \n        private static int convertToInt(String value, int defaultValue) {\n            String trim = value.trim();\n            if (trim.length() == 0) {\n                return defaultValue;\n            }\n            return Integer.parseInt(trim);\n        }\n\n        \n        public boolean isIncluded(int value) {\n            for (Range r : ranges) {\n                if (r.start <= value && value <= r.end) {\n                    return true;\n                }\n            }\n            return false;\n        }\n\n        \n        public boolean isEmpty() {\n            return ranges == null || ranges.isEmpty();\n        }\n\n        @Override\n        public String toString() {\n            StringBuilder result = new StringBuilder();\n            boolean first = true;\n            for (Range r : ranges) {\n                if (first) {\n                    first = false;\n                } else {\n                    result.append(',');\n                }\n                result.append(r.start);\n                result.append('-');\n                result.append(r.end);\n            }\n            return result.toString();\n        }\n\n        \n        public int getRangeStart() {\n            if (ranges == null || ranges.isEmpty()) {\n                return -1;\n            }\n            Range r = ranges.get(0);\n            return r.start;\n        }\n\n        @Override\n        public Iterator<Integer> iterator() {\n            return new RangeNumberIterator(ranges);\n        }\n    }\n\n    \n    public IntegerRanges getRange(String name, String defaultValue) {\n        return new IntegerRanges(get(name, defaultValue));\n    }\n\n    \n    public Collection<String> getStringCollection(String name) {\n        String valueString = get(name);\n        return StringUtils.getStringCollection(valueString);\n    }\n\n    \n    public String[] getStrings(String name) {\n        String valueString = get(name);\n        return StringUtils.getStrings(valueString);\n    }\n\n    \n    public String[] getStrings(String name, String... defaultValue) {\n        String valueString = get(name);\n        if (valueString == null) {\n            return defaultValue;\n        } else {\n            return StringUtils.getStrings(valueString);\n        }\n    }\n\n    \n    public Collection<String> getTrimmedStringCollection(String name) {\n        String valueString = get(name);\n        if (null == valueString) {\n            Collection<String> empty = new ArrayList<String>();\n            return empty;\n        }\n        return StringUtils.getTrimmedStringCollection(valueString);\n    }\n\n    \n    public String[] getTrimmedStrings(String name) {\n        String valueString = get(name);\n        return StringUtils.getTrimmedStrings(valueString);\n    }\n\n    \n    public String[] getTrimmedStrings(String name, String... defaultValue) {\n        String valueString = get(name);\n        if (null == valueString) {\n            return defaultValue;\n        } else {\n            return StringUtils.getTrimmedStrings(valueString);\n        }\n    }\n\n    \n    public void setStrings(String name, String... values) {\n        set(name, StringUtils.arrayToString(values));\n    }\n\n    \n    public char[] getPassword(String name) throws IOException {\n        char[] pass = null;\n\n        pass = getPasswordFromCredentialProviders(name);\n\n        if (pass == null) {\n            pass = getPasswordFromConfig(name);\n        }\n\n        return pass;\n    }\n\n    \n    private CredentialEntry getCredentialEntry(CredentialProvider provider, String name)\n            throws IOException {\n        CredentialEntry entry = provider.getCredentialEntry(name);\n        if (entry != null) {\n            return entry;\n        }\n\n        \n        String oldName = getDeprecatedKey(name);\n        if (oldName != null) {\n            entry = provider.getCredentialEntry(oldName);\n            if (entry != null) {\n                logDeprecationOnce(oldName, provider.toString());\n                return entry;\n            }\n        }\n\n        \n        DeprecatedKeyInfo keyInfo = getDeprecatedKeyInfo(name);\n        if (keyInfo != null && keyInfo.newKeys != null) {\n            for (String newName : keyInfo.newKeys) {\n                entry = provider.getCredentialEntry(newName);\n                if (entry != null) {\n                    logDeprecationOnce(name, null);\n                    return entry;\n                }\n            }\n        }\n\n        return null;\n    }\n\n    \n    protected char[] getPasswordFromCredentialProviders(String name) throws IOException {\n        char[] pass = null;\n        try {\n            List<CredentialProvider> providers = CredentialProviderFactory.getProviders(this);\n\n            if (providers != null) {\n                for (CredentialProvider provider : providers) {\n                    try {\n                        CredentialEntry entry = getCredentialEntry(provider, name);\n                        if (entry != null) {\n                            pass = entry.getCredential();\n                            break;\n                        }\n                    } catch (IOException ioe) {\n                        throw new IOException(\n                                \"Can't get key \"\n                                        + name\n                                        + \" from key provider\"\n                                        + \"of type: \"\n                                        + provider.getClass().getName()\n                                        + \".\",\n                                ioe);\n                    }\n                }\n            }\n        } catch (IOException ioe) {\n            throw new IOException(\"Configuration problem with provider path.\", ioe);\n        }\n\n        return pass;\n    }\n\n    \n    protected char[] getPasswordFromConfig(String name) {\n        char[] pass = null;\n        if (getBoolean(\n                CredentialProvider.CLEAR_TEXT_FALLBACK,\n                CommonConfigurationKeysPublic\n                        .HADOOP_SECURITY_CREDENTIAL_CLEAR_TEXT_FALLBACK_DEFAULT)) {\n            String passStr = get(name);\n            if (passStr != null) {\n                pass = passStr.toCharArray();\n            }\n        }\n        return pass;\n    }\n\n    \n    public InetSocketAddress getSocketAddr(\n            String hostProperty,\n            String addressProperty,\n            String defaultAddressValue,\n            int defaultPort) {\n\n        InetSocketAddress bindAddr =\n                getSocketAddr(addressProperty, defaultAddressValue, defaultPort);\n\n        final String host = get(hostProperty);\n\n        if (host == null || host.isEmpty()) {\n            return bindAddr;\n        }\n\n        return NetUtils.createSocketAddr(host, bindAddr.getPort(), hostProperty);\n    }\n\n    \n    public InetSocketAddress getSocketAddr(String name, String defaultAddress, int defaultPort) {\n        final String address = getTrimmed(name, defaultAddress);\n        return NetUtils.createSocketAddr(address, defaultPort, name);\n    }\n\n    \n    public void setSocketAddr(String name, InetSocketAddress addr) {\n        set(name, NetUtils.getHostPortString(addr));\n    }\n\n    \n    public InetSocketAddress updateConnectAddr(\n            String hostProperty,\n            String addressProperty,\n            String defaultAddressValue,\n            InetSocketAddress addr) {\n\n        final String host = get(hostProperty);\n        final String connectHostPort = getTrimmed(addressProperty, defaultAddressValue);\n\n        if (host == null\n                || host.isEmpty()\n                || connectHostPort == null\n                || connectHostPort.isEmpty()) {\n            \n            return updateConnectAddr(addressProperty, addr);\n        }\n\n        final String connectHost = connectHostPort.split(\":\")[0];\n        \n        return updateConnectAddr(\n                addressProperty, NetUtils.createSocketAddrForHost(connectHost, addr.getPort()));\n    }\n\n    \n    public InetSocketAddress updateConnectAddr(String name, InetSocketAddress addr) {\n        final InetSocketAddress connectAddr = NetUtils.getConnectAddress(addr);\n        setSocketAddr(name, connectAddr);\n        return connectAddr;\n    }\n\n    \n    public Class<?> getClassByName(String name) throws ClassNotFoundException {\n        Class<?> ret = getClassByNameOrNull(name);\n        if (ret == null) {\n            throw new ClassNotFoundException(\"Class \" + name + \" not found\");\n        }\n        return ret;\n    }\n\n    \n    public Class<?> getClassByNameOrNull(String name) {\n        Map<String, WeakReference<Class<?>>> map;\n\n        synchronized (CACHE_CLASSES) {\n            map = CACHE_CLASSES.get(classLoader);\n            if (map == null) {\n                map =\n                        Collections.synchronizedMap(\n                                new WeakHashMap<String, WeakReference<Class<?>>>());\n                CACHE_CLASSES.put(classLoader, map);\n            }\n        }\n\n        Class<?> clazz = null;\n        WeakReference<Class<?>> ref = map.get(name);\n        if (ref != null) {\n            clazz = ref.get();\n        }\n\n        if (clazz == null) {\n            try {\n                clazz = Class.forName(name, true, classLoader);\n            } catch (ClassNotFoundException e) {\n                \n                map.put(name, new WeakReference<Class<?>>(NEGATIVE_CACHE_SENTINEL));\n                return null;\n            }\n            \n            map.put(name, new WeakReference<Class<?>>(clazz));\n            return clazz;\n        } else if (clazz == NEGATIVE_CACHE_SENTINEL) {\n            return null; \n        } else {\n            \n            return clazz;\n        }\n    }\n\n    \n    public Class<?>[] getClasses(String name, Class<?>... defaultValue) {\n        String valueString = getRaw(name);\n        if (null == valueString) {\n            return defaultValue;\n        }\n        String[] classnames = getTrimmedStrings(name);\n        try {\n            Class<?>[] classes = new Class<?>[classnames.length];\n            for (int i = 0; i < classnames.length; i++) {\n                classes[i] = getClassByName(classnames[i]);\n            }\n            return classes;\n        } catch (ClassNotFoundException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    \n    public Class<?> getClass(String name, Class<?> defaultValue) {\n        String valueString = getTrimmed(name);\n        if (valueString == null) return defaultValue;\n        try {\n            return getClassByName(valueString);\n        } catch (ClassNotFoundException e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    \n    public <U> Class<? extends U> getClass(\n            String name, Class<? extends U> defaultValue, Class<U> xface) {\n        try {\n            Class<?> theClass = getClass(name, defaultValue);\n            if (theClass != null && !xface.isAssignableFrom(theClass))\n                throw new RuntimeException(theClass + \" not \" + xface.getName());\n            else if (theClass != null) return theClass.asSubclass(xface);\n            else return null;\n        } catch (Exception e) {\n            throw new RuntimeException(e);\n        }\n    }\n\n    \n    @SuppressWarnings(\"unchecked\")\n    public <U> List<U> getInstances(String name, Class<U> xface) {\n        List<U> ret = new ArrayList<U>();\n        Class<?>[] classes = getClasses(name);\n        for (Class<?> cl : classes) {\n            if (!xface.isAssignableFrom(cl)) {\n                throw new RuntimeException(cl + \" does not implement \" + xface);\n            }\n            ret.add((U) ReflectionUtils.newInstance(cl, this));\n        }\n        return ret;\n    }\n\n    \n    public void setClass(String name, Class<?> theClass, Class<?> xface) {\n        if (!xface.isAssignableFrom(theClass))\n            throw new RuntimeException(theClass + \" not \" + xface.getName());\n        set(name, theClass.getName());\n    }\n\n    \n    public Path getLocalPath(String dirsProp, String path) throws IOException {\n        String[] dirs = getTrimmedStrings(dirsProp);\n        int hashCode = path.hashCode();\n        FileSystem fs = FileSystem.getLocal(this);\n        for (int i = 0; i < dirs.length; i++) { \n            int index = (hashCode + i & Integer.MAX_VALUE) % dirs.length;\n            Path file = new Path(dirs[index], path);\n            Path dir = file.getParent();\n            if (fs.mkdirs(dir) || fs.exists(dir)) {\n                return file;\n            }\n        }\n        LOG.warn(\"Could not make \" + path + \" in local directories from \" + dirsProp);\n        for (int i = 0; i < dirs.length; i++) {\n            int index = (hashCode + i & Integer.MAX_VALUE) % dirs.length;\n            LOG.warn(dirsProp + \"[\" + index + \"]=\" + dirs[index]);\n        }\n        throw new IOException(\"No valid local directories in property: \" + dirsProp);\n    }\n\n    \n    public File getFile(String dirsProp, String path) throws IOException {\n        String[] dirs = getTrimmedStrings(dirsProp);\n        int hashCode = path.hashCode();\n        for (int i = 0; i < dirs.length; i++) { \n            int index = (hashCode + i & Integer.MAX_VALUE) % dirs.length;\n            File file = new File(dirs[index], path);\n            File dir = file.getParentFile();\n            if (dir.exists() || dir.mkdirs()) {\n                return file;\n            }\n        }\n        throw new IOException(\"No valid local directories in property: \" + dirsProp);\n    }\n\n    \n    public URL getResource(String name) {\n        return classLoader.getResource(name);\n    }\n\n    \n    public InputStream getConfResourceAsInputStream(String name) {\n        try {\n            URL url = getResource(name);\n\n            if (url == null) {\n                LOG.info(name + \" not found\");\n                return null;\n            } else {\n                LOG.info(\"found resource \" + name + \" at \" + url);\n            }\n\n            return url.openStream();\n        } catch (Exception e) {\n            return null;\n        }\n    }\n\n    \n    public Reader getConfResourceAsReader(String name) {\n        try {\n            URL url = getResource(name);\n\n            if (url == null) {\n                LOG.info(name + \" not found\");\n                return null;\n            } else {\n                LOG.info(\"found resource \" + name + \" at \" + url);\n            }\n\n            return new InputStreamReader(url.openStream(), Charsets.UTF_8);\n        } catch (Exception e) {\n            return null;\n        }\n    }\n\n    \n    public Set<String> getFinalParameters() {\n        Set<String> setFinalParams =\n                Collections.newSetFromMap(new ConcurrentHashMap<String, Boolean>());\n        setFinalParams.addAll(finalParameters);\n        return setFinalParams;\n    }\n\n    protected synchronized Properties getProps() {\n        if (properties == null) {\n            properties = new Properties();\n            Map<String, String[]> backup =\n                    updatingResource != null\n                            ? new ConcurrentHashMap<String, String[]>(updatingResource)\n                            : null;\n            loadResources(properties, resources, quietmode);\n\n            if (overlay != null) {\n                properties.putAll(overlay);\n                if (backup != null) {\n                    for (Map.Entry<Object, Object> item : overlay.entrySet()) {\n                        String key = (String) item.getKey();\n                        String[] source = backup.get(key);\n                        if (source != null) {\n                            updatingResource.put(key, source);\n                        }\n                    }\n                }\n            }\n        }\n        return properties;\n    }\n\n    \n    public int size() {\n        return getProps().size();\n    }\n\n    \n    public void clear() {\n        getProps().clear();\n        getOverlay().clear();\n    }\n\n    \n    @Override\n    public Iterator<Map.Entry<String, String>> iterator() {\n        \n        \n        \n        \n        Map<String, String> result = new HashMap<String, String>();\n        for (Map.Entry<Object, Object> item : getProps().entrySet()) {\n            if (item.getKey() instanceof String && item.getValue() instanceof String) {\n                result.put((String) item.getKey(), (String) item.getValue());\n            }\n        }\n        return result.entrySet().iterator();\n    }\n\n    \n    public Map<String, String> getPropsWithPrefix(String confPrefix) {\n        Properties props = getProps();\n        Enumeration e = props.propertyNames();\n        Map<String, String> configMap = new HashMap<>();\n        String name = null;\n        while (e.hasMoreElements()) {\n            name = (String) e.nextElement();\n            if (name.startsWith(confPrefix)) {\n                String value = props.getProperty(name);\n                name = name.substring(confPrefix.length());\n                configMap.put(name, value);\n            }\n        }\n        return configMap;\n    }\n\n    private XMLStreamReader parse(URL url, boolean restricted)\n            throws IOException, XMLStreamException {\n        if (!quietmode) {\n            if (LOG.isDebugEnabled()) {\n                LOG.debug(\"parsing URL \" + url);\n            }\n        }\n        if (url == null) {\n            return null;\n        }\n\n        URLConnection connection = url.openConnection();\n        if (connection instanceof JarURLConnection) {\n            \n            \n            connection.setUseCaches(false);\n        }\n        return parse(connection.getInputStream(), url.toString(), restricted);\n    }\n\n    private XMLStreamReader parse(InputStream is, String systemIdStr, boolean restricted)\n            throws IOException, XMLStreamException {\n        if (!quietmode) {\n            LOG.debug(\"parsing input stream \" + is);\n        }\n        if (is == null) {\n            return null;\n        }\n        SystemId systemId = SystemId.construct(systemIdStr);\n        ReaderConfig readerConfig = XML_INPUT_FACTORY.createPrivateConfig();\n        if (restricted) {\n            readerConfig.setProperty(XMLInputFactory.SUPPORT_DTD, false);\n        }\n        return XML_INPUT_FACTORY.createSR(\n                readerConfig,\n                systemId,\n                StreamBootstrapper.getInstance(null, systemId, is),\n                false,\n                true);\n    }\n\n    private void loadResources(\n            Properties properties, ArrayList<Resource> resources, boolean quiet) {\n        if (loadDefaults) {\n            for (String resource : defaultResources) {\n                loadResource(properties, new Resource(resource, false), quiet);\n            }\n        }\n\n        for (int i = 0; i < resources.size(); i++) {\n            Resource ret = loadResource(properties, resources.get(i), quiet);\n            if (ret != null) {\n                resources.set(i, ret);\n            }\n        }\n    }\n\n    private Resource loadResource(Properties properties, Resource wrapper, boolean quiet) {\n        String name = UNKNOWN_RESOURCE;\n        try {\n            Object resource = wrapper.getResource();\n            name = wrapper.getName();\n            XMLStreamReader2 reader = null;\n            boolean returnCachedProperties = false;\n            boolean isRestricted = wrapper.isParserRestricted();\n\n            if (resource instanceof URL) { \n                reader = (XMLStreamReader2) parse((URL) resource, isRestricted);\n            } else if (resource instanceof String) { \n                URL url = getResource((String) resource);\n                reader = (XMLStreamReader2) parse(url, isRestricted);\n            } else if (resource instanceof Path) { \n                \n                \n                File file = new File(((Path) resource).toUri().getPath()).getAbsoluteFile();\n                if (file.exists()) {\n                    if (!quiet) {\n                        LOG.debug(\"parsing File \" + file);\n                    }\n                    reader =\n                            (XMLStreamReader2)\n                                    parse(\n                                            new BufferedInputStream(new FileInputStream(file)),\n                                            ((Path) resource).toString(),\n                                            isRestricted);\n                }\n            } else if (resource instanceof InputStream) {\n                reader = (XMLStreamReader2) parse((InputStream) resource, null, isRestricted);\n                returnCachedProperties = true;\n            } else if (resource instanceof Properties) {\n                overlay(properties, (Properties) resource);\n            }\n\n            if (reader == null) {\n                if (quiet) {\n                    return null;\n                }\n                throw new RuntimeException(resource + \" not found\");\n            }\n            Properties toAddTo = properties;\n            if (returnCachedProperties) {\n                toAddTo = new Properties();\n            }\n            DeprecationContext deprecations = deprecationContext.get();\n\n            StringBuilder token = new StringBuilder();\n            String confName = null;\n            String confValue = null;\n            String confInclude = null;\n            boolean confFinal = false;\n            boolean fallbackAllowed = false;\n            boolean fallbackEntered = false;\n            boolean parseToken = false;\n            LinkedList<String> confSource = new LinkedList<String>();\n\n            while (reader.hasNext()) {\n                switch (reader.next()) {\n                    case XMLStreamConstants.START_ELEMENT:\n                        switch (reader.getLocalName()) {\n                            case \"property\":\n                                confName = null;\n                                confValue = null;\n                                confFinal = false;\n                                confSource.clear();\n\n                                \n                                int attrCount = reader.getAttributeCount();\n                                for (int i = 0; i < attrCount; i++) {\n                                    String propertyAttr = reader.getAttributeLocalName(i);\n                                    if (\"name\".equals(propertyAttr)) {\n                                        confName =\n                                                StringInterner.weakIntern(\n                                                        reader.getAttributeValue(i));\n                                    } else if (\"value\".equals(propertyAttr)) {\n                                        confValue =\n                                                StringInterner.weakIntern(\n                                                        reader.getAttributeValue(i));\n                                    } else if (\"final\".equals(propertyAttr)) {\n                                        confFinal = \"true\".equals(reader.getAttributeValue(i));\n                                    } else if (\"source\".equals(propertyAttr)) {\n                                        confSource.add(\n                                                StringInterner.weakIntern(\n                                                        reader.getAttributeValue(i)));\n                                    }\n                                }\n                                break;\n                            case \"name\":\n                            case \"value\":\n                            case \"final\":\n                            case \"source\":\n                                parseToken = true;\n                                token.setLength(0);\n                                break;\n                            case \"include\":\n                                \n                                confInclude = null;\n                                attrCount = reader.getAttributeCount();\n                                for (int i = 0; i < attrCount; i++) {\n                                    String attrName = reader.getAttributeLocalName(i);\n                                    if (\"href\".equals(attrName)) {\n                                        confInclude = reader.getAttributeValue(i);\n                                    }\n                                }\n                                if (confInclude == null) {\n                                    break;\n                                }\n                                if (isRestricted) {\n                                    throw new RuntimeException(\n                                            \"Error parsing resource \"\n                                                    + wrapper\n                                                    + \": XInclude is not supported for restricted resources\");\n                                }\n                                \n                                \n                                \n                                URL include = getResource(confInclude);\n                                if (include != null) {\n                                    Resource classpathResource =\n                                            new Resource(\n                                                    include, name, wrapper.isParserRestricted());\n                                    loadResource(properties, classpathResource, quiet);\n                                } else {\n                                    URL url;\n                                    try {\n                                        url = new URL(confInclude);\n                                        url.openConnection().connect();\n                                    } catch (IOException ioe) {\n                                        File href = new File(confInclude);\n                                        if (!href.isAbsolute()) {\n                                            \n                                            \n                                            File baseFile = new File(name).getParentFile();\n                                            href = new File(baseFile, href.getPath());\n                                        }\n                                        if (!href.exists()) {\n                                            \n                                            \n                                            fallbackAllowed = true;\n                                            break;\n                                        }\n                                        url = href.toURI().toURL();\n                                    }\n                                    Resource uriResource =\n                                            new Resource(url, name, wrapper.isParserRestricted());\n                                    loadResource(properties, uriResource, quiet);\n                                }\n                                break;\n                            case \"fallback\":\n                                fallbackEntered = true;\n                                break;\n                            case \"configuration\":\n                                break;\n                            default:\n                                break;\n                        }\n                        break;\n\n                    case XMLStreamConstants.CHARACTERS:\n                        if (parseToken) {\n                            char[] text = reader.getTextCharacters();\n                            token.append(text, reader.getTextStart(), reader.getTextLength());\n                        }\n                        break;\n\n                    case XMLStreamConstants.END_ELEMENT:\n                        switch (reader.getLocalName()) {\n                            case \"name\":\n                                if (token.length() > 0) {\n                                    confName = StringInterner.weakIntern(token.toString().trim());\n                                }\n                                break;\n                            case \"value\":\n                                if (token.length() > 0) {\n                                    confValue = StringInterner.weakIntern(token.toString());\n                                }\n                                break;\n                            case \"final\":\n                                confFinal = \"true\".equals(token.toString());\n                                break;\n                            case \"source\":\n                                confSource.add(StringInterner.weakIntern(token.toString()));\n                                break;\n                            case \"include\":\n                                if (fallbackAllowed && !fallbackEntered) {\n                                    throw new IOException(\n                                            \"Fetch fail on include for '\"\n                                                    + confInclude\n                                                    + \"' with no fallback while loading '\"\n                                                    + name\n                                                    + \"'\");\n                                }\n                                fallbackAllowed = false;\n                                fallbackEntered = false;\n                                break;\n                            case \"property\":\n                                if (confName == null || (!fallbackAllowed && fallbackEntered)) {\n                                    break;\n                                }\n                                confSource.add(name);\n                                DeprecatedKeyInfo keyInfo =\n                                        deprecations.getDeprecatedKeyMap().get(confName);\n                                if (keyInfo != null) {\n                                    keyInfo.clearAccessed();\n                                    for (String key : keyInfo.newKeys) {\n                                        \n                                        loadProperty(\n                                                toAddTo,\n                                                name,\n                                                key,\n                                                confValue,\n                                                confFinal,\n                                                confSource.toArray(new String[confSource.size()]));\n                                    }\n                                } else {\n                                    loadProperty(\n                                            toAddTo,\n                                            name,\n                                            confName,\n                                            confValue,\n                                            confFinal,\n                                            confSource.toArray(new String[confSource.size()]));\n                                }\n                                break;\n                            default:\n                                break;\n                        }\n                    default:\n                        break;\n                }\n            }\n            reader.close();\n\n            if (returnCachedProperties) {\n                overlay(properties, toAddTo);\n                return new Resource(toAddTo, name, wrapper.isParserRestricted());\n            }\n            return null;\n        } catch (IOException e) {\n            LOG.error(\"error parsing conf \" + name, e);\n            throw new RuntimeException(e);\n        } catch (XMLStreamException e) {\n            LOG.error(\"error parsing conf \" + name, e);\n            throw new RuntimeException(e);\n        }\n    }\n\n    private void overlay(Properties to, Properties from) {\n        for (Entry<Object, Object> entry : from.entrySet()) {\n            to.put(entry.getKey(), entry.getValue());\n        }\n    }\n\n    private void loadProperty(\n            Properties properties,\n            String name,\n            String attr,\n            String value,\n            boolean finalParameter,\n            String[] source) {\n        if (value != null || allowNullValueProperties) {\n            if (value == null) {\n                value = DEFAULT_STRING_CHECK;\n            }\n            if (!finalParameters.contains(attr)) {\n                properties.setProperty(attr, value);\n                if (source != null) {\n                    putIntoUpdatingResource(attr, source);\n                }\n            } else {\n                \n                checkForOverride(this.properties, name, attr, value);\n                if (this.properties != properties) {\n                    checkForOverride(properties, name, attr, value);\n                }\n            }\n        }\n        if (finalParameter && attr != null) {\n            finalParameters.add(attr);\n        }\n    }\n\n    \n    private void checkForOverride(Properties properties, String name, String attr, String value) {\n        String propertyValue = properties.getProperty(attr);\n        if (propertyValue != null && !propertyValue.equals(value)) {\n            LOG.warn(name + \":an attempt to override final parameter: \" + attr + \";  Ignoring.\");\n        }\n    }\n\n    \n    public void writeXml(OutputStream out) throws IOException {\n        writeXml(new OutputStreamWriter(out, \"UTF-8\"));\n    }\n\n    public void writeXml(Writer out) throws IOException {\n        writeXml(null, out);\n    }\n\n    \n    public void writeXml(String propertyName, Writer out)\n            throws IOException, IllegalArgumentException {\n        Document doc = asXmlDocument(propertyName);\n\n        try {\n            DOMSource source = new DOMSource(doc);\n            StreamResult result = new StreamResult(out);\n            TransformerFactory transFactory = TransformerFactory.newInstance();\n            Transformer transformer = transFactory.newTransformer();\n\n            \n            \n            \n            transformer.transform(source, result);\n        } catch (TransformerException te) {\n            throw new IOException(te);\n        }\n    }\n\n    \n    private synchronized Document asXmlDocument(String propertyName)\n            throws IOException, IllegalArgumentException {\n        Document doc;\n        try {\n            doc = DocumentBuilderFactory.newInstance().newDocumentBuilder().newDocument();\n        } catch (ParserConfigurationException pe) {\n            throw new IOException(pe);\n        }\n\n        Element conf = doc.createElement(\"configuration\");\n        doc.appendChild(conf);\n        conf.appendChild(doc.createTextNode(\"\\n\"));\n        handleDeprecation(); \n\n        if (!Strings.isNullOrEmpty(propertyName)) {\n            if (!properties.containsKey(propertyName)) {\n                \n                throw new IllegalArgumentException(\"Property \" + propertyName + \" not found\");\n            } else {\n                \n                appendXMLProperty(doc, conf, propertyName);\n                conf.appendChild(doc.createTextNode(\"\\n\"));\n            }\n        } else {\n            \n            for (Enumeration<Object> e = properties.keys(); e.hasMoreElements(); ) {\n                appendXMLProperty(doc, conf, (String) e.nextElement());\n                conf.appendChild(doc.createTextNode(\"\\n\"));\n            }\n        }\n        return doc;\n    }\n\n    \n    private synchronized void appendXMLProperty(Document doc, Element conf, String propertyName) {\n        \n        if (!Strings.isNullOrEmpty(propertyName)) {\n            String value = properties.getProperty(propertyName);\n            if (value != null) {\n                Element propNode = doc.createElement(\"property\");\n                conf.appendChild(propNode);\n\n                Element nameNode = doc.createElement(\"name\");\n                nameNode.appendChild(doc.createTextNode(propertyName));\n                propNode.appendChild(nameNode);\n\n                Element valueNode = doc.createElement(\"value\");\n                valueNode.appendChild(doc.createTextNode(properties.getProperty(propertyName)));\n                propNode.appendChild(valueNode);\n\n                Element finalNode = doc.createElement(\"final\");\n                finalNode.appendChild(\n                        doc.createTextNode(String.valueOf(finalParameters.contains(propertyName))));\n                propNode.appendChild(finalNode);\n\n                if (updatingResource != null) {\n                    String[] sources = updatingResource.get(propertyName);\n                    if (sources != null) {\n                        for (String s : sources) {\n                            Element sourceNode = doc.createElement(\"source\");\n                            sourceNode.appendChild(doc.createTextNode(s));\n                            propNode.appendChild(sourceNode);\n                        }\n                    }\n                }\n            }\n        }\n    }\n\n    \n    public static void dumpConfiguration(Configuration config, String propertyName, Writer out)\n            throws IOException {\n        if (Strings.isNullOrEmpty(propertyName)) {\n            dumpConfiguration(config, out);\n        } else if (Strings.isNullOrEmpty(config.get(propertyName))) {\n            throw new IllegalArgumentException(\"Property \" + propertyName + \" not found\");\n        } else {\n            JsonFactory dumpFactory = new JsonFactory();\n            JsonGenerator dumpGenerator = dumpFactory.createGenerator(out);\n            dumpGenerator.writeStartObject();\n            dumpGenerator.writeFieldName(\"property\");\n            appendJSONProperty(dumpGenerator, config, propertyName, new ConfigRedactor(config));\n            dumpGenerator.writeEndObject();\n            dumpGenerator.flush();\n        }\n    }\n\n    \n    public static void dumpConfiguration(Configuration config, Writer out) throws IOException {\n        JsonFactory dumpFactory = new JsonFactory();\n        JsonGenerator dumpGenerator = dumpFactory.createGenerator(out);\n        dumpGenerator.writeStartObject();\n        dumpGenerator.writeFieldName(\"properties\");\n        dumpGenerator.writeStartArray();\n        dumpGenerator.flush();\n        ConfigRedactor redactor = new ConfigRedactor(config);\n        synchronized (config) {\n            for (Map.Entry<Object, Object> item : config.getProps().entrySet()) {\n                appendJSONProperty(dumpGenerator, config, item.getKey().toString(), redactor);\n            }\n        }\n        dumpGenerator.writeEndArray();\n        dumpGenerator.writeEndObject();\n        dumpGenerator.flush();\n    }\n\n    \n    private static void appendJSONProperty(\n            JsonGenerator jsonGen, Configuration config, String name, ConfigRedactor redactor)\n            throws IOException {\n        \n        if (!Strings.isNullOrEmpty(name) && jsonGen != null) {\n            jsonGen.writeStartObject();\n            jsonGen.writeStringField(\"key\", name);\n            jsonGen.writeStringField(\"value\", redactor.redact(name, config.get(name)));\n            jsonGen.writeBooleanField(\"isFinal\", config.finalParameters.contains(name));\n            String[] resources =\n                    config.updatingResource != null ? config.updatingResource.get(name) : null;\n            String resource = UNKNOWN_RESOURCE;\n            if (resources != null && resources.length > 0) {\n                resource = resources[0];\n            }\n            jsonGen.writeStringField(\"resource\", resource);\n            jsonGen.writeEndObject();\n        }\n    }\n\n    \n    public ClassLoader getClassLoader() {\n        return classLoader;\n    }\n\n    \n    public void setClassLoader(ClassLoader classLoader) {\n        this.classLoader = classLoader;\n    }\n\n    @Override\n    public String toString() {\n        StringBuilder sb = new StringBuilder();\n        sb.append(\"Configuration: \");\n        if (loadDefaults) {\n            toString(defaultResources, sb);\n            if (resources.size() > 0) {\n                sb.append(\", \");\n            }\n        }\n        toString(resources, sb);\n        return sb.toString();\n    }\n\n    private <T> void toString(List<T> resources, StringBuilder sb) {\n        ListIterator<T> i = resources.listIterator();\n        while (i.hasNext()) {\n            if (i.nextIndex() != 0) {\n                sb.append(\", \");\n            }\n            sb.append(i.next());\n        }\n    }\n\n    \n    public synchronized void setQuietMode(boolean quietmode) {\n        this.quietmode = quietmode;\n    }\n\n    synchronized boolean getQuietMode() {\n        return this.quietmode;\n    }\n\n    \n    public static void main(String[] args) throws Exception {\n        new Configuration().writeXml(System.out);\n    }\n\n    @Override\n    public void readFields(DataInput in) throws IOException {\n        clear();\n        int size = WritableUtils.readVInt(in);\n        for (int i = 0; i < size; ++i) {\n            String key = org.apache.hadoop.io.Text.readString(in);\n            String value = org.apache.hadoop.io.Text.readString(in);\n            set(key, value);\n            String sources[] = WritableUtils.readCompressedStringArray(in);\n            if (sources != null) {\n                putIntoUpdatingResource(key, sources);\n            }\n        }\n    }\n\n    \n    @Override\n    public void write(DataOutput out) throws IOException {\n        Properties props = getProps();\n        WritableUtils.writeVInt(out, props.size());\n        for (Map.Entry<Object, Object> item : props.entrySet()) {\n            org.apache.hadoop.io.Text.writeString(out, (String) item.getKey());\n            org.apache.hadoop.io.Text.writeString(out, (String) item.getValue());\n            WritableUtils.writeCompressedStringArray(\n                    out, updatingResource != null ? updatingResource.get(item.getKey()) : null);\n        }\n    }\n\n    \n    public Map<String, String> getValByRegex(String regex) {\n        Pattern p = Pattern.compile(regex);\n\n        Map<String, String> result = new HashMap<String, String>();\n        Matcher m;\n\n        for (Map.Entry<Object, Object> item : getProps().entrySet()) {\n            if (item.getKey() instanceof String && item.getValue() instanceof String) {\n                m = p.matcher((String) item.getKey());\n                if (m.find()) { \n                    result.put(\n                            (String) item.getKey(),\n                            substituteVars(getProps().getProperty((String) item.getKey())));\n                }\n            }\n        }\n        return result;\n    }\n\n    \n    private abstract static class NegativeCacheSentinel {}\n\n    public static void dumpDeprecatedKeys() {\n        DeprecationContext deprecations = deprecationContext.get();\n        for (Map.Entry<String, DeprecatedKeyInfo> entry :\n                deprecations.getDeprecatedKeyMap().entrySet()) {\n            StringBuilder newKeys = new StringBuilder();\n            for (String newKey : entry.getValue().newKeys) {\n                newKeys.append(newKey).append(\"\\t\");\n            }\n            System.out.println(entry.getKey() + \"\\t\" + newKeys.toString());\n        }\n    }\n\n    \n    public static boolean hasWarnedDeprecation(String name) {\n        DeprecationContext deprecations = deprecationContext.get();\n        if (deprecations.getDeprecatedKeyMap().containsKey(name)) {\n            if (deprecations.getDeprecatedKeyMap().get(name).accessed.get()) {\n                return true;\n            }\n        }\n        return false;\n    }\n\n    private void putIntoUpdatingResource(String key, String[] value) {\n        Map<String, String[]> localUR = updatingResource;\n        if (localUR == null) {\n            synchronized (this) {\n                localUR = updatingResource;\n                if (localUR == null) {\n                    updatingResource = localUR = new ConcurrentHashMap<>(8);\n                }\n            }\n        }\n        localUR.put(key, value);\n    }\n}\n", "summary_tokens": ["this", "is", "a", "manual", "implementation", "of", "the", "following", "regex"], "project": "flink"}
{"id": 6811, "code": "static boolean isNodeRemoved(long node, Allocator spaceAllocator) {\n    if (node == NIL_NODE) {\n        return false;\n    }\n\n    Chunk chunk = spaceAllocator.getChunkById(SpaceUtils.getChunkIdByAddress(node));\n    int offsetInChunk = SpaceUtils.getChunkOffsetByAddress(node);\n    MemorySegment segment = chunk.getMemorySegment(offsetInChunk);\n    int offsetInByteBuffer = chunk.getOffsetInSegment(offsetInChunk);\n    return getNodeStatus(segment, offsetInByteBuffer) == NodeStatus.REMOVE;\n}", "summary_tokens": ["whether", "the", "node", "has", "been", "logically", "removed"], "project": "flink"}
{"id": 2397, "code": "private static void appendJSONProperty(\n        JsonGenerator jsonGen, Configuration config, String name, ConfigRedactor redactor)\n        throws IOException {\n        \n    if (!Strings.isNullOrEmpty(name) && jsonGen != null) {\n        jsonGen.writeStartObject();\n        jsonGen.writeStringField(\"key\", name);\n        jsonGen.writeStringField(\"value\", redactor.redact(name, config.get(name)));\n        jsonGen.writeBooleanField(\"isFinal\", config.finalParameters.contains(name));\n        String[] resources =\n                config.updatingResource != null ? config.updatingResource.get(name) : null;\n        String resource = UNKNOWN_RESOURCE;\n        if (resources != null && resources.length > 0) {\n            resource = resources[0];\n        }\n        jsonGen.writeStringField(\"resource\", resource);\n        jsonGen.writeEndObject();\n    }\n}", "summary_tokens": ["write", "property", "and", "its", "attributes", "as", "json", "format", "to", "given", "json", "generator"], "project": "flink"}
{"id": 3747, "code": "public void testDeltaIterationWithStaticInput() {\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(DEFAULT_PARALLELISM);\n    DataSet<Tuple2<Long, Long>> source = env.generateSequence(0, 1).map(new Duplicator<Long>());\n\n    DataSet<Tuple2<Long, Long>> map = source.map(new IdentityMapper<Tuple2<Long, Long>>());\n    DataSet<Tuple2<Long, Long>> reduce =\n            source.reduceGroup(new IdentityGroupReducer<Tuple2<Long, Long>>());\n\n    DeltaIteration<Tuple2<Long, Long>, Tuple2<Long, Long>> loop =\n            source.iterateDelta(map, 10, 0);\n\n    DataSet<Tuple2<Long, Long>> workset =\n            loop.getWorkset()\n                    .join(reduce)\n                    .where(0)\n                    .equalTo(0)\n                    .with(new IdentityJoiner<Tuple2<Long, Long>>())\n                    .name(\"Next work set\");\n    DataSet<Tuple2<Long, Long>> delta =\n            loop.getSolutionSet()\n                    .join(workset)\n                    .where(0)\n                    .equalTo(0)\n                    .with(new IdentityJoiner<Tuple2<Long, Long>>())\n                    .name(\"Solution set delta\");\n\n    DataSet<Tuple2<Long, Long>> result = loop.closeWith(delta, workset);\n    result.output(new DiscardingOutputFormat<Tuple2<Long, Long>>());\n\n    Plan plan = env.createProgramPlan();\n\n    try {\n        compileNoStats(plan);\n    } catch (Exception e) {\n        e.printStackTrace();\n        Assert.fail(e.getMessage());\n    }\n}", "summary_tokens": ["pre", "iteration", "join", "sink", "solution", "map", "workset", "src", "map", "join", "reduce", "pre"], "project": "flink"}
{"id": 4426, "code": "void notifyStateTransition(Execution execution, ExecutionState newState) {\n        \n        \n    if (isCurrentExecution(execution)) {\n        getExecutionGraphAccessor().notifyExecutionChange(execution, newState);\n    }\n}", "summary_tokens": ["simply", "forward", "this", "notification"], "project": "flink"}
{"id": 8763, "code": "protected SqlNode getAggregate(SqlSelect select) {\n    SqlNode node = select.getGroup();\n    if (node != null) {\n        return node;\n    }\n    node = select.getHaving();\n    if (node != null) {\n        return node;\n    }\n    return getAgg(select);\n}", "summary_tokens": ["returns", "the", "parse", "tree", "node", "group", "by", "having", "or", "an", "aggregate", "function", "call", "that", "causes", "select", "to", "be", "an", "aggregate", "query", "or", "null", "if", "it", "is", "not", "an", "aggregate", "query"], "project": "flink"}
{"id": 8757, "code": "protected void addToSelectList(\n        List<SqlNode> list,\n        Set<String> aliases,\n        List<Map.Entry<String, RelDataType>> fieldList,\n        SqlNode exp,\n        SelectScope scope,\n        final boolean includeSystemVars) {\n    String alias = SqlValidatorUtil.getAlias(exp, -1);\n    String uniqueAlias =\n            SqlValidatorUtil.uniquify(alias, aliases, SqlValidatorUtil.EXPR_SUGGESTER);\n    if (!Objects.equals(alias, uniqueAlias)) {\n        exp = SqlValidatorUtil.addAlias(exp, uniqueAlias);\n    }\n    fieldList.add(Pair.of(uniqueAlias, deriveType(scope, exp)));\n    list.add(exp);\n}", "summary_tokens": ["adds", "an", "expression", "to", "a", "select", "list", "ensuring", "that", "its", "alias", "does", "not", "clash", "with", "any", "existing", "expressions", "on", "the", "list"], "project": "flink"}
{"id": 6289, "code": "public void testJobFailureWhenGracefulTaskExecutorTermination() throws Exception {\n    runJobFailureWhenTaskExecutorTerminatesTest(\n            heartbeatServices,\n            (localTaskManagerLocation, jobMasterGateway) ->\n                    jobMasterGateway.disconnectTaskManager(\n                            localTaskManagerLocation.getResourceID(),\n                            new FlinkException(\"Test disconnectTaskManager exception.\")),\n            (jobMasterGateway, resourceID) ->\n                    (ignoredA, ignoredB) -> FutureUtils.completedVoidFuture());\n}", "summary_tokens": ["tests", "that", "the", "job", "execution", "is", "failed", "if", "the", "task", "executor", "disconnects", "from", "the", "job", "master"], "project": "flink"}
{"id": 5411, "code": "public Path[] listDirectory() throws IOException {\n    return FileUtils.listDirectory(directory);\n}", "summary_tokens": ["list", "the", "files", "in", "the", "snapshot", "directory"], "project": "flink"}
{"id": 6650, "code": "public void testJobReExecutionAfterTaskExecutorTermination() throws Exception {\n    final JobGraph jobGraph = createJobGraph(PARALLELISM);\n\n    final CompletableFuture<JobResult> jobResultFuture = submitJobAndWaitUntilRunning(jobGraph);\n\n        \n    miniCluster.terminateTaskManager(0);\n\n    final JobResult jobResult = jobResultFuture.get();\n\n    assertThat(jobResult.isSuccess(), is(false));\n\n    miniCluster.startTaskManager();\n\n    final JobGraph newJobGraph = createJobGraph(PARALLELISM);\n    BlockingOperator.unblock();\n    miniCluster.submitJob(newJobGraph).get();\n\n    miniCluster.requestJobResult(newJobGraph.getJobID()).get();\n}", "summary_tokens": ["tests", "that", "a", "job", "can", "be", "re", "executed", "after", "the", "job", "has", "failed", "due", "to", "a", "task", "executor", "termination"], "project": "flink"}
{"id": 7265, "code": "public JobExecutionResult execute(StreamGraph streamGraph) throws Exception {\n    final JobClient jobClient = executeAsync(streamGraph);\n\n    try {\n        final JobExecutionResult jobExecutionResult;\n\n        if (configuration.getBoolean(DeploymentOptions.ATTACHED)) {\n            jobExecutionResult = jobClient.getJobExecutionResult().get();\n        } else {\n            jobExecutionResult = new DetachedJobExecutionResult(jobClient.getJobID());\n        }\n\n        jobListeners.forEach(\n                jobListener -> jobListener.onJobExecuted(jobExecutionResult, null));\n\n        return jobExecutionResult;\n    } catch (Throwable t) {\n            \n            \n            \n        Throwable strippedException = ExceptionUtils.stripExecutionException(t);\n\n        jobListeners.forEach(\n                jobListener -> {\n                    jobListener.onJobExecuted(null, strippedException);\n                });\n        ExceptionUtils.rethrowException(strippedException);\n\n            \n        return null;\n    }\n}", "summary_tokens": ["triggers", "the", "program", "execution"], "project": "flink"}
{"id": 5035, "code": "public List<RecordWriter<SerializationDelegate<T>>> getWriters() {\n    return Collections.unmodifiableList(Arrays.asList(this.writers));\n}", "summary_tokens": ["list", "of", "writers", "that", "are", "associated", "with", "this", "output", "collector"], "project": "flink"}
{"id": 7117, "code": "public SingleOutputStreamOperator<T> minBy(int positionToMinBy, boolean first) {\n    return aggregate(\n            new ComparableAggregator<>(\n                    positionToMinBy,\n                    getType(),\n                    AggregationFunction.AggregationType.MINBY,\n                    first,\n                    getExecutionConfig()));\n}", "summary_tokens": ["applies", "an", "aggregation", "that", "gives", "the", "current", "element", "with", "the", "minimum", "value", "at", "the", "given", "position", "by", "the", "given", "key"], "project": "flink"}
{"id": 1083, "code": "public LinkedHashSet<Class<?>> getRegisteredKryoTypes() {\n    if (isForceKryoEnabled()) {\n            \n            \n        LinkedHashSet<Class<?>> result = new LinkedHashSet<>();\n        result.addAll(registeredKryoTypes);\n        for (Class<?> t : registeredPojoTypes) {\n            if (!result.contains(t)) {\n                result.add(t);\n            }\n        }\n        return result;\n    } else {\n        return registeredKryoTypes;\n    }\n}", "summary_tokens": ["returns", "the", "registered", "kryo", "types"], "project": "flink"}
{"id": 1476, "code": "public static <T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12>\n        Tuple13<T0, T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12> of(\n                T0 f0,\n                T1 f1,\n                T2 f2,\n                T3 f3,\n                T4 f4,\n                T5 f5,\n                T6 f6,\n                T7 f7,\n                T8 f8,\n                T9 f9,\n                T10 f10,\n                T11 f11,\n                T12 f12) {\n    return new Tuple13<>(f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12);\n}", "summary_tokens": ["creates", "a", "new", "tuple", "and", "assigns", "the", "given", "values", "to", "the", "tuple", "s", "fields"], "project": "flink"}
{"id": 5374, "code": "public int getStartKeyGroup() {\n    return startKeyGroup;\n}", "summary_tokens": ["the", "first", "key", "group", "in", "the", "range"], "project": "flink"}
{"id": 7022, "code": "public <ACC, V, R> SingleOutputStreamOperator<R> aggregate(\n        AggregateFunction<T, ACC, V> aggregateFunction,\n        ProcessAllWindowFunction<V, R, W> windowFunction,\n        TypeInformation<ACC> accumulatorType,\n        TypeInformation<V> aggregateResultType,\n        TypeInformation<R> resultType) {\n\n    checkNotNull(aggregateFunction, \"aggregateFunction\");\n    checkNotNull(windowFunction, \"windowFunction\");\n    checkNotNull(accumulatorType, \"accumulatorType\");\n    checkNotNull(aggregateResultType, \"aggregateResultType\");\n    checkNotNull(resultType, \"resultType\");\n\n    if (aggregateFunction instanceof RichFunction) {\n        throw new UnsupportedOperationException(\n                \"This aggregate function cannot be a RichFunction.\");\n    }\n\n        \n    windowFunction = input.getExecutionEnvironment().clean(windowFunction);\n    aggregateFunction = input.getExecutionEnvironment().clean(aggregateFunction);\n\n    final String callLocation = Utils.getCallLocationName();\n    final String udfName = \"AllWindowedStream.\" + callLocation;\n\n    final String opName;\n    final KeySelector<T, Byte> keySel = input.getKeySelector();\n\n    OneInputStreamOperator<T, R> operator;\n\n    if (evictor != null) {\n        @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n        TypeSerializer<StreamRecord<T>> streamRecordSerializer =\n                (TypeSerializer<StreamRecord<T>>)\n                        new StreamElementSerializer(\n                                input.getType()\n                                        .createSerializer(\n                                                getExecutionEnvironment().getConfig()));\n\n        ListStateDescriptor<StreamRecord<T>> stateDesc =\n                new ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n        opName =\n                \"TriggerWindow(\"\n                        + windowAssigner\n                        + \", \"\n                        + stateDesc\n                        + \", \"\n                        + trigger\n                        + \", \"\n                        + evictor\n                        + \", \"\n                        + udfName\n                        + \")\";\n\n        operator =\n                new EvictingWindowOperator<>(\n                        windowAssigner,\n                        windowAssigner.getWindowSerializer(\n                                getExecutionEnvironment().getConfig()),\n                        keySel,\n                        input.getKeyType()\n                                .createSerializer(getExecutionEnvironment().getConfig()),\n                        stateDesc,\n                        new InternalAggregateProcessAllWindowFunction<>(\n                                aggregateFunction, windowFunction),\n                        trigger,\n                        evictor,\n                        allowedLateness,\n                        lateDataOutputTag);\n\n    } else {\n        AggregatingStateDescriptor<T, ACC, V> stateDesc =\n                new AggregatingStateDescriptor<>(\n                        \"window-contents\",\n                        aggregateFunction,\n                        accumulatorType.createSerializer(\n                                getExecutionEnvironment().getConfig()));\n\n        opName =\n                \"TriggerWindow(\"\n                        + windowAssigner\n                        + \", \"\n                        + stateDesc\n                        + \", \"\n                        + trigger\n                        + \", \"\n                        + udfName\n                        + \")\";\n\n        operator =\n                new WindowOperator<>(\n                        windowAssigner,\n                        windowAssigner.getWindowSerializer(\n                                getExecutionEnvironment().getConfig()),\n                        keySel,\n                        input.getKeyType()\n                                .createSerializer(getExecutionEnvironment().getConfig()),\n                        stateDesc,\n                        new InternalSingleValueProcessAllWindowFunction<>(windowFunction),\n                        trigger,\n                        allowedLateness,\n                        lateDataOutputTag);\n    }\n\n    return input.transform(opName, resultType, operator).forceNonParallel();\n}", "summary_tokens": ["applies", "the", "given", "window", "function", "to", "each", "window"], "project": "flink"}
{"id": 284, "code": "public void testBoundedTextFileSource() throws Exception {\n    testBoundedTextFileSource(FailoverType.NONE);\n}", "summary_tokens": ["this", "test", "runs", "a", "job", "reading", "bounded", "input", "with", "a", "stream", "record", "format", "text", "lines"], "project": "flink"}
{"id": 2293, "code": "public V get(final V defaultValue) {\n    final String value = System.getProperty(propertyName);\n    return value == null ? defaultValue : converter.apply(value);\n}", "summary_tokens": ["retrieves", "the", "value", "of", "this", "property", "or", "the", "given", "default", "if", "no", "value", "was", "set"], "project": "flink"}
{"id": 7902, "code": "public List<OUT> extractOutputValues() {\n    List<StreamRecord<? extends OUT>> streamRecords = extractOutputStreamRecords();\n    List<OUT> outputValues = new ArrayList<>();\n    for (StreamRecord<? extends OUT> streamRecord : streamRecords) {\n        outputValues.add(streamRecord.getValue());\n    }\n    return outputValues;\n}", "summary_tokens": ["get", "the", "list", "of", "out", "values", "emitted", "by", "the", "operator"], "project": "flink"}
{"id": 4249, "code": "CompletedCheckpointStats.DiscardCallback reportCompletedCheckpoint(String externalPointer) {\n    CompletedCheckpointStats completed =\n            new CompletedCheckpointStats(\n                    checkpointId,\n                    triggerTimestamp,\n                    props,\n                    numberOfSubtasks,\n                    new HashMap<>(taskStats),\n                    currentNumAcknowledgedSubtasks,\n                    currentStateSize,\n                    currentProcessedData,\n                    currentPersistedData,\n                    latestAcknowledgedSubtask,\n                    externalPointer);\n\n    trackerCallback.reportCompletedCheckpoint(completed);\n\n    return completed.getDiscardCallback();\n}", "summary_tokens": ["reports", "a", "successfully", "completed", "pending", "checkpoint"], "project": "flink"}
{"id": 2595, "code": "public static ParquetWriterFactory<RowData> createWriterFactory(\n        RowType rowType, Configuration conf, boolean utcTimestamp) {\n    return new ParquetWriterFactory<>(new FlinkParquetBuilder(rowType, conf, utcTimestamp));\n}", "summary_tokens": ["create", "a", "parquet", "bulk", "writer"], "project": "flink"}
{"id": 523, "code": "public KafkaSourceBuilder<OUT> setClientIdPrefix(String prefix) {\n    return setProperty(KafkaSourceOptions.CLIENT_ID_PREFIX.key(), prefix);\n}", "summary_tokens": ["sets", "the", "client", "id", "prefix", "of", "this", "kafka", "source"], "project": "flink"}
{"id": 1677, "code": "private static Configuration loadYAMLResource(File file) {\n    final Configuration config = new Configuration();\n\n    try (BufferedReader reader =\n            new BufferedReader(new InputStreamReader(new FileInputStream(file)))) {\n\n        String line;\n        int lineNo = 0;\n        while ((line = reader.readLine()) != null) {\n            lineNo++;\n                \n            String[] comments = line.split(\"#\", 2);\n            String conf = comments[0].trim();\n\n                \n            if (conf.length() > 0) {\n                String[] kv = conf.split(\": \", 2);\n\n                    \n                if (kv.length == 1) {\n                    LOG.warn(\n                            \"Error while trying to split key and value in configuration file \"\n                                    + file\n                                    + \":\"\n                                    + lineNo\n                                    + \": \\\"\"\n                                    + line\n                                    + \"\\\"\");\n                    continue;\n                }\n\n                String key = kv[0].trim();\n                String value = kv[1].trim();\n\n                    \n                if (key.length() == 0 || value.length() == 0) {\n                    LOG.warn(\n                            \"Error after splitting key and value in configuration file \"\n                                    + file\n                                    + \":\"\n                                    + lineNo\n                                    + \": \\\"\"\n                                    + line\n                                    + \"\\\"\");\n                    continue;\n                }\n\n                LOG.info(\n                        \"Loading configuration property: {}, {}\",\n                        key,\n                        isSensitive(key) ? HIDDEN_CONTENT : value);\n                config.setString(key, value);\n            }\n        }\n    } catch (IOException e) {\n        throw new RuntimeException(\"Error parsing YAML configuration.\", e);\n    }\n\n    return config;\n}", "summary_tokens": ["loads", "a", "yaml", "file", "of", "key", "value", "pairs"], "project": "flink"}
{"id": 4240, "code": "public long getCheckpointId() {\n    return getCheckpointID();\n}", "summary_tokens": ["use", "get", "checkpoint", "id"], "project": "flink"}
{"id": 861, "code": "public void run() {\n    LOG.info(\"Starting emitter with maxLookaheadMillis: {}\", this.maxLookaheadMillis);\n    emitRecords();\n}", "summary_tokens": ["run", "loop", "does", "not", "return", "unless", "stop", "was", "called"], "project": "flink"}
{"id": 8904, "code": "private Operation convertUseModules(SqlUseModules sqlUseModules) {\n    return new UseModulesOperation(sqlUseModules.moduleNames());\n}", "summary_tokens": ["convert", "use", "modules", "statement"], "project": "flink"}
{"id": 5246, "code": "public static <\n                X,\n                P extends MessageQueryParameter<X>,\n                R extends RequestBody,\n                M extends MessageParameters>\n        X getQueryParameter(final HandlerRequest<R> request, final Class<P> queryParameterClass)\n                throws RestHandlerException {\n\n    return getQueryParameter(request, queryParameterClass, null);\n}", "summary_tokens": ["returns", "the", "value", "of", "a", "query", "parameter", "or", "null", "if", "the", "query", "parameter", "is", "not", "set"], "project": "flink"}
{"id": 5335, "code": "void registerSourceReader(ReaderInfo readerInfo) {\n    final ReaderInfo previousReader =\n            registeredReaders.put(readerInfo.getSubtaskId(), readerInfo);\n    if (previousReader != null) {\n        throw new IllegalStateException(\n                \"Overwriting \" + previousReader + \" with \" + readerInfo);\n    }\n}", "summary_tokens": ["register", "a", "source", "reader"], "project": "flink"}
{"id": 6277, "code": "public void testConcurrentLeadershipOperationsBlockingClose() throws Exception {\n    final CompletableFuture<Void> terminationFuture = new CompletableFuture<>();\n\n    final JobManagerRunner jobManagerRunner =\n            newJobMasterServiceLeadershipRunnerBuilder()\n                    .withJobMasterServiceProcesses(\n                            TestingJobMasterServiceProcess.newBuilder()\n                                    .setTerminationFuture(terminationFuture)\n                                    .withManualTerminationFutureCompletion()\n                                    .build(),\n                            TestingJobMasterServiceProcess.newBuilder().build())\n                    .build();\n\n    jobManagerRunner.start();\n\n    leaderElectionService.isLeader(UUID.randomUUID()).get();\n\n    leaderElectionService.notLeader();\n\n    final CompletableFuture<UUID> leaderFuture =\n            leaderElectionService.isLeader(UUID.randomUUID());\n\n        \n    assertThat(leaderFuture.isDone(), is(false));\n\n    try {\n        leaderFuture.get(1L, TimeUnit.MILLISECONDS);\n        fail(\"Granted leadership even though the JobMaster has not been suspended.\");\n    } catch (TimeoutException expected) {\n            \n    }\n\n    terminationFuture.complete(null);\n\n    leaderFuture.get();\n}", "summary_tokens": ["tests", "that", "the", "job", "master", "service", "leadership", "runner", "always", "waits", "for", "the", "previous", "leadership", "operation", "granting", "or", "revoking", "leadership", "to", "finish", "before", "starting", "a", "new", "leadership", "operation"], "project": "flink"}
{"id": 6423, "code": "private void testResourceCanBeAllocatedForDifferentJobAfterFree(\n        SecondRequirementDeclarationTime secondRequirementDeclarationTime) throws Exception {\n    final CompletableFuture<AllocationID> allocationIdFuture1 = new CompletableFuture<>();\n    final CompletableFuture<AllocationID> allocationIdFuture2 = new CompletableFuture<>();\n    final ResourceRequirements resourceRequirements1 =\n            createResourceRequirementsForSingleSlot();\n    final ResourceRequirements resourceRequirements2 =\n            createResourceRequirementsForSingleSlot();\n\n    final TaskExecutorGateway taskExecutorGateway =\n            new TestingTaskExecutorGatewayBuilder()\n                    .setRequestSlotFunction(\n                            tuple6 -> {\n                                if (!allocationIdFuture1.isDone()) {\n                                    allocationIdFuture1.complete(tuple6.f2);\n                                } else {\n                                    allocationIdFuture2.complete(tuple6.f2);\n                                }\n                                return CompletableFuture.completedFuture(Acknowledge.get());\n                            })\n                    .createTestingTaskExecutorGateway();\n    final ResourceID resourceID = ResourceID.generate();\n    final TaskExecutorConnection taskManagerConnection =\n            new TaskExecutorConnection(resourceID, taskExecutorGateway);\n    final SlotReport slotReport = new SlotReport();\n\n    new Context() {\n        {\n            runTest(\n                    () -> {\n                        runInMainThread(\n                                () -> {\n                                    getSlotManager()\n                                            .registerTaskManager(\n                                                    taskManagerConnection,\n                                                    slotReport,\n                                                    DEFAULT_SLOT_RESOURCE_PROFILE,\n                                                    DEFAULT_SLOT_RESOURCE_PROFILE);\n                                    getSlotManager()\n                                            .processResourceRequirements(resourceRequirements1);\n                                });\n\n                        final AllocationID allocationId1 =\n                                assertFutureCompleteAndReturn(allocationIdFuture1);\n                        TaskManagerSlotInformation slot =\n                                getTaskManagerTracker()\n                                        .getAllocatedOrPendingSlot(allocationId1)\n                                        .get();\n\n                        assertEquals(\n                                \"The slot has not been allocated to the expected job id.\",\n                                resourceRequirements1.getJobId(),\n                                slot.getJobId());\n\n                        if (secondRequirementDeclarationTime\n                                == SecondRequirementDeclarationTime.BEFORE_FREE) {\n                            runInMainThread(\n                                    () ->\n                                            getSlotManager()\n                                                    .processResourceRequirements(\n                                                            resourceRequirements2));\n                        }\n\n                            \n                            \n                        runInMainThread(\n                                () -> {\n                                    getSlotManager()\n                                            .processResourceRequirements(\n                                                    ResourceRequirements.create(\n                                                            resourceRequirements1.getJobId(),\n                                                            resourceRequirements1\n                                                                    .getTargetAddress(),\n                                                            Collections.emptyList()));\n                                    getSlotManager()\n                                            .freeSlot(\n                                                    SlotID.getDynamicSlotID(resourceID),\n                                                    allocationId1);\n                                });\n\n                        if (secondRequirementDeclarationTime\n                                == SecondRequirementDeclarationTime.AFTER_FREE) {\n                            runInMainThread(\n                                    () ->\n                                            getSlotManager()\n                                                    .processResourceRequirements(\n                                                            resourceRequirements2));\n                        }\n\n                        slot =\n                                getTaskManagerTracker()\n                                        .getAllocatedOrPendingSlot(\n                                                assertFutureCompleteAndReturn(\n                                                        allocationIdFuture2))\n                                        .get();\n                        assertEquals(\n                                \"The slot has not been allocated to the expected job id.\",\n                                resourceRequirements2.getJobId(),\n                                slot.getJobId());\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "that", "a", "resource", "allocated", "for", "one", "job", "can", "be", "allocated", "for", "another", "job", "after", "being", "freed"], "project": "flink"}
{"id": 5958, "code": "public void testAddCheckpointWithFailedRemove() throws Exception {\n\n    final int numCheckpointsToRetain = 1;\n    CompletedCheckpointStore store =\n            createRecoveredCompletedCheckpointStore(\n                    numCheckpointsToRetain, Executors.directExecutor());\n\n    CountDownLatch discardAttempted = new CountDownLatch(1);\n    for (long i = 0; i < numCheckpointsToRetain + 1; ++i) {\n        CompletedCheckpoint checkpointToAdd =\n                new CompletedCheckpoint(\n                        new JobID(),\n                        i,\n                        i,\n                        i,\n                        Collections.emptyMap(),\n                        Collections.emptyList(),\n                        CheckpointProperties.forCheckpoint(NEVER_RETAIN_AFTER_TERMINATION),\n                        new TestCompletedCheckpointStorageLocation()) {\n                    @Override\n                    public boolean discardOnSubsume() {\n                        discardAttempted.countDown();\n                        throw new RuntimeException();\n                    }\n                };\n            \n        store.addCheckpointAndSubsumeOldestOne(\n                checkpointToAdd, new CheckpointsCleaner(), () -> {});\n    }\n    discardAttempted.await();\n}", "summary_tokens": ["tests", "that", "the", "checkpoint", "does", "not", "exist", "in", "the", "store", "when", "we", "fail", "to", "add", "it", "into", "the", "store", "i"], "project": "flink"}
{"id": 7093, "code": "private DataStreamSink<T> setResources(ResourceSpec resources) {\n    transformation.setResources(resources, resources);\n\n    return this;\n}", "summary_tokens": ["sets", "the", "resources", "for", "this", "sink", "the", "minimum", "and", "preferred", "resources", "are", "the", "same", "by", "default"], "project": "flink"}
{"id": 3169, "code": "public <NV> Graph<K, NV, EV> mapVertices(\n        final MapFunction<Vertex<K, VV>, NV> mapper,\n        TypeInformation<Vertex<K, NV>> returnType) {\n    DataSet<Vertex<K, NV>> mappedVertices =\n            vertices.map(\n                            new MapFunction<Vertex<K, VV>, Vertex<K, NV>>() {\n                                private Vertex<K, NV> output = new Vertex<>();\n\n                                public Vertex<K, NV> map(Vertex<K, VV> value) throws Exception {\n                                    output.f0 = value.f0;\n                                    output.f1 = mapper.map(value);\n                                    return output;\n                                }\n                            })\n                    .returns(returnType)\n                    .withForwardedFields(\"f0\")\n                    .name(\"Map vertices\");\n\n    return new Graph<>(mappedVertices, this.edges, this.context);\n}", "summary_tokens": ["apply", "a", "function", "to", "the", "attribute", "of", "each", "vertex", "in", "the", "graph"], "project": "flink"}
{"id": 8661, "code": "public static String formatDate(int date) {\n    final StringBuilder buf = new StringBuilder(10);\n    formatDate(buf, date);\n    return buf.toString();\n}", "summary_tokens": ["helper", "for", "cast", "date", "as", "varchar", "n"], "project": "flink"}
{"id": 2843, "code": "public long getMissingCount() {\n    return nullCount + nanCount + infinityCount;\n}", "summary_tokens": ["the", "number", "of", "missing", "values", "where", "missing", "is", "defined", "as", "null", "na", "n", "or", "infinity"], "project": "flink"}
{"id": 3591, "code": "public OptimizerNode getNextPartialSolution() {\n    return nextPartialSolution;\n}", "summary_tokens": ["gets", "the", "next", "partial", "solution", "from", "this", "bulk", "iteration", "node"], "project": "flink"}
{"id": 2941, "code": "public void testMinByKeyFieldsGrouping() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    UnsortedGrouping<Tuple5<Integer, Long, String, Long, Integer>> groupDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo).groupBy(0);\n\n        \n    try {\n        groupDs.minBy(4, 0, 1, 2, 3);\n    } catch (Exception e) {\n        Assert.fail();\n    }\n}", "summary_tokens": ["this", "test", "validates", "that", "no", "exceptions", "is", "thrown", "when", "an", "empty", "grouping", "calls", "min", "by"], "project": "flink"}
{"id": 4858, "code": "public <T extends AutoCloseable> OpaqueMemoryResource<T> getExternalSharedMemoryResource(\n        String type, LongFunctionWithException<T, Exception> initializer, long numBytes)\n        throws Exception {\n\n        \n        \n        \n        \n    final Object leaseHolder = new Object();\n\n    final SharedResources.ResourceAndSize<T> resource =\n            sharedResources.getOrAllocateSharedResource(\n                    type, leaseHolder, initializer, numBytes);\n\n    final ThrowingRunnable<Exception> disposer =\n            () -> sharedResources.release(type, leaseHolder);\n\n    return new OpaqueMemoryResource<>(resource.resourceHandle(), resource.size(), disposer);\n}", "summary_tokens": ["acquires", "a", "shared", "resource", "identified", "by", "a", "type", "string"], "project": "flink"}
{"id": 4765, "code": "public void addJar(Path jar) {\n    if (jar == null) {\n        throw new IllegalArgumentException();\n    }\n\n    if (!userJars.contains(jar)) {\n        userJars.add(jar);\n    }\n}", "summary_tokens": ["adds", "the", "path", "of", "a", "jar", "file", "required", "to", "run", "the", "job", "on", "a", "task", "manager"], "project": "flink"}
{"id": 8166, "code": "public static TypeInformation<Float> FLOAT() {\n    return org.apache.flink.api.common.typeinfo.Types.FLOAT;\n}", "summary_tokens": ["returns", "type", "information", "for", "a", "table", "api", "float", "or", "sql", "float", "real", "type"], "project": "flink"}
{"id": 7097, "code": "public static <OUT> ClientAndIterator<OUT> collectWithClient(\n        DataStream<OUT> stream, String jobExecutionName) throws Exception {\n    return stream.executeAndCollectWithClient(jobExecutionName);\n}", "summary_tokens": ["starts", "the", "execution", "of", "the", "program", "and", "returns", "an", "iterator", "to", "read", "the", "result", "of", "the", "given", "data", "stream", "plus", "a", "job", "client", "to", "interact", "with", "the", "application", "execution"], "project": "flink"}
{"id": 4434, "code": "public Optional<ExecutionVertexID> getExecutionVertexIdOfFailedTask() {\n    return Optional.ofNullable(failingExecutionVertexId);\n}", "summary_tokens": ["returns", "an", "optional", "with", "the", "execution", "vertex", "id", "of", "the", "task", "causing", "this", "failure", "or", "an", "empty", "optional", "if", "it", "s", "a", "global", "failure"], "project": "flink"}
{"id": 1085, "code": "public void disableAutoTypeRegistration() {\n    this.autoTypeRegistrationEnabled = false;\n}", "summary_tokens": ["control", "whether", "flink", "is", "automatically", "registering", "all", "types", "in", "the", "user", "programs", "with", "kryo"], "project": "flink"}
{"id": 7646, "code": "public void testDefaultJobType() {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    StreamGraph streamGraph =\n            new StreamGraphGenerator(\n                            Collections.emptyList(), env.getConfig(), env.getCheckpointConfig())\n                    .generate();\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(streamGraph);\n    assertEquals(JobType.STREAMING, jobGraph.getJobType());\n}", "summary_tokens": ["test", "default", "job", "type"], "project": "flink"}
{"id": 5841, "code": "private void testConcurrentDeleteOperations(@Nullable final JobID jobId)\n        throws IOException, InterruptedException, ExecutionException {\n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    final int concurrentDeleteOperations = 3;\n    final ExecutorService executor = Executors.newFixedThreadPool(concurrentDeleteOperations);\n\n    final List<CompletableFuture<Void>> deleteFutures =\n            new ArrayList<>(concurrentDeleteOperations);\n\n    final byte[] data = {1, 2, 3};\n\n    try (final BlobServer server = new BlobServer(config, new VoidBlobStore())) {\n\n        server.start();\n\n        final TransientBlobKey blobKey =\n                (TransientBlobKey) put(server, jobId, data, TRANSIENT_BLOB);\n\n        assertTrue(server.getStorageLocation(jobId, blobKey).exists());\n\n        for (int i = 0; i < concurrentDeleteOperations; i++) {\n            CompletableFuture<Void> deleteFuture =\n                    CompletableFuture.supplyAsync(\n                            () -> {\n                                try {\n                                    assertTrue(delete(server, jobId, blobKey));\n                                    assertFalse(\n                                            server.getStorageLocation(jobId, blobKey).exists());\n                                    return null;\n                                } catch (IOException e) {\n                                    throw new CompletionException(\n                                            new FlinkException(\n                                                    \"Could not delete the given blob key \"\n                                                            + blobKey\n                                                            + '.'));\n                                }\n                            },\n                            executor);\n\n            deleteFutures.add(deleteFuture);\n        }\n\n        CompletableFuture<Void> waitFuture = FutureUtils.waitForAll(deleteFutures);\n\n            \n            \n        waitFuture.get();\n\n        assertFalse(server.getStorageLocation(jobId, blobKey).exists());\n\n    } finally {\n        executor.shutdownNow();\n    }\n}", "summary_tokens": ["flink", "0", "tests", "that", "concurrent", "delete", "operations", "don", "t", "interfere", "with", "each", "other"], "project": "flink"}
{"id": 5508, "code": "public static StateMetaInfoWriter getWriter() {\n    return CurrentWriterImpl.INSTANCE;\n}", "summary_tokens": ["returns", "the", "writer", "for", "state", "meta", "info", "snapshot"], "project": "flink"}
{"id": 7885, "code": "public void testAvoidStarvation() throws Exception {\n\n    final int expectedInvocations = 3;\n    final AtomicInteger counter = new AtomicInteger(0);\n    MailboxThread mailboxThread =\n            new MailboxThread() {\n                @Override\n                public void runDefaultAction(Controller controller) {\n                    if (counter.incrementAndGet() == expectedInvocations) {\n                        controller.allActionsCompleted();\n                    }\n                }\n            };\n\n    mailboxThread.start();\n    final MailboxProcessor mailboxProcessor = mailboxThread.getMailboxProcessor();\n    final MailboxExecutor mailboxExecutor =\n            mailboxProcessor.getMailboxExecutor(DEFAULT_PRIORITY);\n    AtomicInteger index = new AtomicInteger();\n    mailboxExecutor.execute(\n            new RunnableWithException() {\n                @Override\n                public void run() {\n                    mailboxExecutor.execute(this, \"Blocking mail\" + index.incrementAndGet());\n                }\n            },\n            \"Blocking mail\" + index.get());\n\n    mailboxThread.signalStart();\n    mailboxThread.join();\n\n    Assert.assertEquals(expectedInvocations, counter.get());\n    Assert.assertEquals(expectedInvocations, index.get());\n}", "summary_tokens": ["flink", "0", "avoid", "newly", "spawned", "letters", "to", "prevent", "input", "processing", "from", "ever", "happening"], "project": "flink"}
{"id": 8685, "code": "public static void checkPhysicalLogicalTypeCompatible(\n        LogicalType physicalFieldType,\n        LogicalType logicalFieldType,\n        String physicalFieldName,\n        String logicalFieldName,\n        boolean isSource) {\n    if (isSource) {\n        checkIfCompatible(\n                physicalFieldType,\n                logicalFieldType,\n                (cause) ->\n                        new ValidationException(\n                                String.format(\n                                        \"Type %s of table field '%s' does not match with \"\n                                                + \"the physical type %s of the '%s' field of the TableSource return type.\",\n                                        logicalFieldType,\n                                        logicalFieldName,\n                                        physicalFieldType,\n                                        physicalFieldName),\n                                cause));\n    } else {\n        checkIfCompatible(\n                logicalFieldType,\n                physicalFieldType,\n                (cause) ->\n                        new ValidationException(\n                                String.format(\n                                        \"Type %s of table field '%s' does not match with \"\n                                                + \"the physical type %s of the '%s' field of the TableSink consumed type.\",\n                                        logicalFieldType,\n                                        logicalFieldName,\n                                        physicalFieldType,\n                                        physicalFieldName),\n                                cause));\n    }\n}", "summary_tokens": ["checks", "whether", "the", "given", "physical", "field", "type", "and", "logical", "field", "type", "are", "compatible", "at", "the", "edges", "of", "the", "table", "ecosystem"], "project": "flink"}
{"id": 5957, "code": "public void testSuspendDiscardsCheckpoints() throws Exception {\n    SharedStateRegistry sharedStateRegistry = new SharedStateRegistryImpl();\n    CompletedCheckpointStore store = createRecoveredCompletedCheckpointStore(1);\n    TestCompletedCheckpoint checkpoint = createCheckpoint(0, sharedStateRegistry);\n    Collection<OperatorState> taskStates = checkpoint.getOperatorStates().values();\n\n    store.addCheckpointAndSubsumeOldestOne(checkpoint, new CheckpointsCleaner(), () -> {});\n    assertEquals(1, store.getNumberOfRetainedCheckpoints());\n    verifyCheckpointRegistered(taskStates, sharedStateRegistry);\n\n    store.shutdown(JobStatus.SUSPENDED, new CheckpointsCleaner());\n    assertEquals(0, store.getNumberOfRetainedCheckpoints());\n    assertTrue(checkpoint.isDiscarded());\n    verifyCheckpointDiscarded(taskStates);\n}", "summary_tokens": ["tests", "that", "suspends", "discards", "all", "checkpoints", "as", "they", "cannot", "be", "recovered", "later", "in", "standalone", "recovery", "mode"], "project": "flink"}
{"id": 1512, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple21)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple21 tuple = (Tuple21) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    if (f5 != null ? !f5.equals(tuple.f5) : tuple.f5 != null) {\n        return false;\n    }\n    if (f6 != null ? !f6.equals(tuple.f6) : tuple.f6 != null) {\n        return false;\n    }\n    if (f7 != null ? !f7.equals(tuple.f7) : tuple.f7 != null) {\n        return false;\n    }\n    if (f8 != null ? !f8.equals(tuple.f8) : tuple.f8 != null) {\n        return false;\n    }\n    if (f9 != null ? !f9.equals(tuple.f9) : tuple.f9 != null) {\n        return false;\n    }\n    if (f10 != null ? !f10.equals(tuple.f10) : tuple.f10 != null) {\n        return false;\n    }\n    if (f11 != null ? !f11.equals(tuple.f11) : tuple.f11 != null) {\n        return false;\n    }\n    if (f12 != null ? !f12.equals(tuple.f12) : tuple.f12 != null) {\n        return false;\n    }\n    if (f13 != null ? !f13.equals(tuple.f13) : tuple.f13 != null) {\n        return false;\n    }\n    if (f14 != null ? !f14.equals(tuple.f14) : tuple.f14 != null) {\n        return false;\n    }\n    if (f15 != null ? !f15.equals(tuple.f15) : tuple.f15 != null) {\n        return false;\n    }\n    if (f16 != null ? !f16.equals(tuple.f16) : tuple.f16 != null) {\n        return false;\n    }\n    if (f17 != null ? !f17.equals(tuple.f17) : tuple.f17 != null) {\n        return false;\n    }\n    if (f18 != null ? !f18.equals(tuple.f18) : tuple.f18 != null) {\n        return false;\n    }\n    if (f19 != null ? !f19.equals(tuple.f19) : tuple.f19 != null) {\n        return false;\n    }\n    if (f20 != null ? !f20.equals(tuple.f20) : tuple.f20 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 2258, "code": "public void testPersistAfterReset() throws Exception {\n    withWriter(\n            (writer, uploader) -> {\n                byte[] bytes = getBytes();\n                SequenceNumber sqn = append(writer, bytes);\n                writer.reset(sqn, SequenceNumber.of(Long.MAX_VALUE));\n                uploader.reset();\n                writer.persist(sqn);\n                assertSubmittedOnly(uploader, bytes);\n            });\n}", "summary_tokens": ["emulates", "checkpoint", "abortion", "followed", "by", "a", "new", "checkpoint"], "project": "flink"}
{"id": 7057, "code": "public BroadcastStream<T> broadcast(\n        final MapStateDescriptor<?, ?>... broadcastStateDescriptors) {\n    Preconditions.checkNotNull(broadcastStateDescriptors);\n    final DataStream<T> broadcastStream = setConnectionType(new BroadcastPartitioner<>());\n    return new BroadcastStream<>(environment, broadcastStream, broadcastStateDescriptors);\n}", "summary_tokens": ["sets", "the", "partitioning", "of", "the", "data", "stream", "so", "that", "the", "output", "elements", "are", "broadcasted", "to", "every", "parallel", "instance", "of", "the", "next", "operation"], "project": "flink"}
{"id": 6353, "code": "public void testRESTClientSSLMissingPassword() throws Exception {\n    Configuration config = new Configuration();\n    config.setBoolean(SecurityOptions.SSL_REST_ENABLED, true);\n    config.setString(SecurityOptions.SSL_REST_TRUSTSTORE, TRUST_STORE_PATH);\n\n    try {\n        SSLUtils.createRestClientSSLEngineFactory(config);\n        fail(\"exception expected\");\n    } catch (IllegalConfigurationException ignored) {\n    }\n}", "summary_tokens": ["tests", "that", "rest", "client", "ssl", "creation", "fails", "with", "bad", "ssl", "configuration"], "project": "flink"}
{"id": 4716, "code": "public void handIn(String key, V obj) {\n    if (!retrieveSharedQueue(key).offer(obj)) {\n        throw new RuntimeException(\n                \"Could not register the given element, broker slot is already occupied.\");\n    }\n}", "summary_tokens": ["hand", "in", "the", "object", "to", "share"], "project": "flink"}
{"id": 3109, "code": "public void testDuplicate() {\n    IntSerializer nonDuplicatingInnerSerializer = IntSerializer.INSTANCE;\n    Assert.assertSame(nonDuplicatingInnerSerializer, nonDuplicatingInnerSerializer.duplicate());\n    Lockable.LockableTypeSerializer<Integer> candidateTestShallowDuplicate =\n            new Lockable.LockableTypeSerializer<>(nonDuplicatingInnerSerializer);\n    Assert.assertSame(candidateTestShallowDuplicate, candidateTestShallowDuplicate.duplicate());\n\n    TestDuplicateSerializer duplicatingInnerSerializer = new TestDuplicateSerializer();\n    Assert.assertNotSame(duplicatingInnerSerializer, duplicatingInnerSerializer.duplicate());\n\n    Lockable.LockableTypeSerializer<Integer> candidateTestDeepDuplicate =\n            new Lockable.LockableTypeSerializer<>(duplicatingInnerSerializer);\n\n    Lockable.LockableTypeSerializer<Integer> deepDuplicate =\n            candidateTestDeepDuplicate.duplicate();\n    Assert.assertNotSame(candidateTestDeepDuplicate, deepDuplicate);\n    Assert.assertNotSame(\n            candidateTestDeepDuplicate.getElementSerializer(),\n            deepDuplicate.getElementSerializer());\n}", "summary_tokens": ["this", "tests", "that", "lockable"], "project": "flink"}
{"id": 8104, "code": "public static boolean isFunction(\n        Expression expression, BuiltInFunctionDefinition functionDefinition) {\n    if (expression instanceof UnresolvedCallExpression) {\n        return ((UnresolvedCallExpression) expression).getFunctionDefinition()\n                == functionDefinition;\n    }\n    if (expression instanceof CallExpression) {\n        return ((CallExpression) expression).getFunctionDefinition() == functionDefinition;\n    }\n    return false;\n}", "summary_tokens": ["checks", "if", "the", "given", "expression", "is", "a", "given", "builtin", "function"], "project": "flink"}
{"id": 5232, "code": "public Map<String, List<String>> queryParams() {\n    return queryParams;\n}", "summary_tokens": ["returns", "all", "params", "in", "the", "query", "part", "of", "the", "request", "uri"], "project": "flink"}
{"id": 5362, "code": "public StreamStateHandle closeAndGetPrimaryHandle() throws IOException {\n    flushInternalBuffer();\n    return primaryOutputStream.closeAndGetHandle();\n}", "summary_tokens": ["returns", "the", "state", "handle", "from", "the", "primary", "output", "stream"], "project": "flink"}
{"id": 3750, "code": "public void testRightSideCountercheck() {\n    try {\n\n        Plan plan = getTestPlanRightStatic(Optimizer.HINT_LOCAL_STRATEGY_HASH_BUILD_FIRST);\n\n        OptimizedPlan oPlan = compileNoStats(plan);\n\n        OptimizerPlanNodeResolver resolver = getOptimizerPlanNodeResolver(oPlan);\n        DualInputPlanNode innerJoin = resolver.getNode(\"DummyJoiner\");\n\n            \n        assertEquals(DriverStrategy.HYBRIDHASH_BUILD_FIRST, innerJoin.getDriverStrategy());\n        assertEquals(TempMode.NONE, innerJoin.getInput1().getTempMode());\n        assertEquals(TempMode.CACHED, innerJoin.getInput2().getTempMode());\n\n        new JobGraphGenerator().compileJobGraph(oPlan);\n    } catch (Exception e) {\n        System.err.println(e.getMessage());\n        e.printStackTrace();\n        fail(\"Test errored: \" + e.getMessage());\n    }\n}", "summary_tokens": ["this", "test", "makes", "sure", "that", "only", "a", "hybridhash", "on", "the", "static", "path", "is", "transformed", "to", "the", "cached", "variant"], "project": "flink"}
{"id": 5100, "code": "public KvStateInfo<K, N, V> duplicate() {\n    final TypeSerializer<K> dupKeySerializer = keySerializer.duplicate();\n    final TypeSerializer<N> dupNamespaceSerializer = namespaceSerializer.duplicate();\n    final TypeSerializer<V> dupSVSerializer = stateValueSerializer.duplicate();\n\n    if (dupKeySerializer == keySerializer\n            && dupNamespaceSerializer == namespaceSerializer\n            && dupSVSerializer == stateValueSerializer) {\n        return this;\n    }\n\n    return new KvStateInfo<>(dupKeySerializer, dupNamespaceSerializer, dupSVSerializer);\n}", "summary_tokens": ["creates", "a", "deep", "copy", "of", "the", "current", "kv", "state", "info", "by", "duplicating", "all", "the", "included", "serializers"], "project": "flink"}
{"id": 1745, "code": "public static URI getLocalFsURI() {\n    return LOCAL_URI;\n}", "summary_tokens": ["gets", "the", "uri", "that", "represents", "the", "local", "file", "system"], "project": "flink"}
{"id": 6262, "code": "public void testBlobServerCleanupFinishedJob() throws Exception {\n    testBlobServerCleanup(TestCase.JOB_FINISHES_SUCESSFULLY);\n}", "summary_tokens": ["test", "cleanup", "for", "a", "job", "that", "finishes", "ordinarily"], "project": "flink"}
{"id": 2407, "code": "public org.apache.hadoop.fs.FSDataOutputStream getHadoopOutputStream() {\n    return fdos;\n}", "summary_tokens": ["gets", "the", "wrapped", "hadoop", "output", "stream"], "project": "flink"}
{"id": 3955, "code": "public void testSimpleRequest() throws Throwable {\n    KvStateServerImpl server = null;\n    Bootstrap bootstrap = null;\n    try {\n        KvStateRegistry registry = new KvStateRegistry();\n        KvStateRequestStats stats = new AtomicKvStateRequestStats();\n\n        server =\n                new KvStateServerImpl(\n                        InetAddress.getLocalHost().getHostName(),\n                        Collections.singletonList(0).iterator(),\n                        1,\n                        1,\n                        registry,\n                        stats);\n        server.start();\n\n        InetSocketAddress serverAddress = server.getServerAddress();\n        int numKeyGroups = 1;\n        AbstractStateBackend abstractBackend = new MemoryStateBackend();\n        DummyEnvironment dummyEnv = new DummyEnvironment(\"test\", 1, 0);\n        dummyEnv.setKvStateRegistry(registry);\n        final JobID jobId = new JobID();\n        AbstractKeyedStateBackend<Integer> backend =\n                abstractBackend.createKeyedStateBackend(\n                        dummyEnv,\n                        jobId,\n                        \"test_op\",\n                        IntSerializer.INSTANCE,\n                        numKeyGroups,\n                        new KeyGroupRange(0, 0),\n                        registry.createTaskRegistry(jobId, new JobVertexID()),\n                        TtlTimeProvider.DEFAULT,\n                        new UnregisteredMetricsGroup(),\n                        Collections.emptyList(),\n                        new CloseableRegistry());\n\n        final KvStateServerHandlerTest.TestRegistryListener registryListener =\n                new KvStateServerHandlerTest.TestRegistryListener();\n\n        registry.registerListener(jobId, registryListener);\n\n        ValueStateDescriptor<Integer> desc =\n                new ValueStateDescriptor<>(\"any\", IntSerializer.INSTANCE);\n        desc.setQueryable(\"vanilla\");\n\n        ValueState<Integer> state =\n                backend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, desc);\n\n            \n        int expectedValue = 712828289;\n\n        int key = 99812822;\n        backend.setCurrentKey(key);\n        state.update(expectedValue);\n\n            \n        byte[] serializedKeyAndNamespace =\n                KvStateSerializer.serializeKeyAndNamespace(\n                        key,\n                        IntSerializer.INSTANCE,\n                        VoidNamespace.INSTANCE,\n                        VoidNamespaceSerializer.INSTANCE);\n\n            \n        final BlockingQueue<ByteBuf> responses = new LinkedBlockingQueue<>();\n        bootstrap =\n                createBootstrap(\n                        new LengthFieldBasedFrameDecoder(Integer.MAX_VALUE, 0, 4, 0, 4),\n                        new ChannelInboundHandlerAdapter() {\n                            @Override\n                            public void channelRead(ChannelHandlerContext ctx, Object msg)\n                                    throws Exception {\n                                responses.add((ByteBuf) msg);\n                            }\n                        });\n\n        Channel channel =\n                bootstrap\n                        .connect(serverAddress.getAddress(), serverAddress.getPort())\n                        .sync()\n                        .channel();\n\n        long requestId = Integer.MAX_VALUE + 182828L;\n\n        assertTrue(registryListener.registrationName.equals(\"vanilla\"));\n\n        final KvStateInternalRequest request =\n                new KvStateInternalRequest(\n                        registryListener.kvStateId, serializedKeyAndNamespace);\n\n        ByteBuf serializeRequest =\n                MessageSerializer.serializeRequest(channel.alloc(), requestId, request);\n\n        channel.writeAndFlush(serializeRequest);\n\n        ByteBuf buf = responses.poll(TIMEOUT_MILLIS, TimeUnit.MILLISECONDS);\n\n        assertEquals(MessageType.REQUEST_RESULT, MessageSerializer.deserializeHeader(buf));\n        assertEquals(requestId, MessageSerializer.getRequestId(buf));\n        KvStateResponse response = server.getSerializer().deserializeResponse(buf);\n\n        int actualValue =\n                KvStateSerializer.deserializeValue(\n                        response.getContent(), IntSerializer.INSTANCE);\n        assertEquals(expectedValue, actualValue);\n    } finally {\n        if (server != null) {\n            server.shutdown();\n        }\n\n        if (bootstrap != null) {\n            EventLoopGroup group = bootstrap.group();\n            if (group != null) {\n                    \n                group.shutdownGracefully(0, 10, TimeUnit.SECONDS);\n            }\n        }\n    }\n}", "summary_tokens": ["tests", "a", "simple", "successful", "query", "via", "a", "socket", "channel"], "project": "flink"}
{"id": 5437, "code": "private void discardLocalStateForCheckpoint(long checkpointID, TaskStateSnapshot o) {\n\n    if (LOG.isTraceEnabled()) {\n        LOG.trace(\n                \"Discarding local task state snapshot of checkpoint {} for subtask ({} - {} - {}).\",\n                checkpointID,\n                jobID,\n                jobVertexID,\n                subtaskIndex);\n    } else {\n        LOG.debug(\n                \"Discarding local task state snapshot {} of checkpoint {} for subtask ({} - {} - {}).\",\n                o,\n                checkpointID,\n                jobID,\n                jobVertexID,\n                subtaskIndex);\n    }\n\n    try {\n        o.discardState();\n    } catch (Exception discardEx) {\n        LOG.warn(\n                \"Exception while discarding local task state snapshot of checkpoint {} in subtask ({} - {} - {}).\",\n                checkpointID,\n                jobID,\n                jobVertexID,\n                subtaskIndex,\n                discardEx);\n    }\n\n    LocalRecoveryDirectoryProvider directoryProvider =\n            localRecoveryConfig.getLocalStateDirectoryProvider();\n    File checkpointDir = directoryProvider.subtaskSpecificCheckpointDirectory(checkpointID);\n\n    LOG.debug(\n            \"Deleting local state directory {} of checkpoint {} for subtask ({} - {} - {}).\",\n            checkpointDir,\n            checkpointID,\n            jobID,\n            jobVertexID,\n            subtaskIndex);\n\n    try {\n        deleteDirectory(checkpointDir);\n    } catch (IOException ex) {\n        LOG.warn(\n                \"Exception while deleting local state directory of checkpoint {} in subtask ({} - {} - {}).\",\n                checkpointID,\n                jobID,\n                jobVertexID,\n                subtaskIndex,\n                ex);\n    }\n}", "summary_tokens": ["helper", "method", "that", "discards", "state", "objects", "with", "an", "executor", "and", "reports", "exceptions", "to", "the", "log"], "project": "flink"}
{"id": 7744, "code": "public void testStartNewCheckpointViaAnnouncement() throws Exception {\n    int numChannels = 3;\n    ValidatingCheckpointHandler target = new ValidatingCheckpointHandler();\n    long alignmentTimeOut = 10000L;\n\n    try (CheckpointedInputGate gate =\n            new TestCheckpointedInputGateBuilder(\n                            numChannels, getTestBarrierHandlerFactory(target))\n                    .withRemoteChannels()\n                    .withMailboxExecutor()\n                    .build()) {\n        getChannel(gate, 0)\n                .onBuffer(\n                        barrier(\n                                1,\n                                clock.relativeTimeMillis(),\n                                alignedWithTimeout(\n                                        CheckpointType.CHECKPOINT,\n                                        getDefault(),\n                                        alignmentTimeOut)),\n                        0,\n                        0);\n        getChannel(gate, 1).onBuffer(endOfPartition(), 0, 0);\n\n            \n        assertAnnouncement(gate);\n\n            \n        assertEvent(gate, EndOfPartitionEvent.class);\n        assertTrue(gate.getCheckpointBarrierHandler().isDuringAlignment());\n\n            \n        assertBarrier(gate);\n\n            \n        getChannel(gate, 2)\n                .onBuffer(\n                        barrier(\n                                1,\n                                clock.relativeTimeMillis(),\n                                alignedWithTimeout(\n                                        CheckpointType.CHECKPOINT,\n                                        getDefault(),\n                                        alignmentTimeOut)),\n                        0,\n                        0);\n        assertAnnouncement(gate);\n        assertBarrier(gate);\n\n        assertThat(target.triggeredCheckpoints, contains(1L));\n    }\n}", "summary_tokens": ["this", "test", "verifies", "a", "special", "case", "that", "the", "checkpoint", "handler", "starts", "the", "new", "checkpoint", "via", "received", "barrier", "announcement", "from", "the", "first", "channel", "then", "end", "of", "partition", "event", "from", "the", "second", "channel", "and", "then", "the", "barrier", "from", "the", "first", "channel"], "project": "flink"}
{"id": 1019, "code": "public void addToRestrictList(String restrictListStr) {\n  if (restrictListStr == null) {\n    return;\n  }\n  String oldList = this.getVar(ConfVars.HIVE_CONF_RESTRICTED_LIST);\n  if (oldList == null || oldList.isEmpty()) {\n    this.setVar(ConfVars.HIVE_CONF_RESTRICTED_LIST, restrictListStr);\n  } else {\n    this.setVar(ConfVars.HIVE_CONF_RESTRICTED_LIST, oldList + \",\" + restrictListStr);\n  }\n  setupRestrictList();\n}", "summary_tokens": ["append", "comma", "separated", "list", "of", "config", "vars", "to", "the", "restrict", "list", "restrict", "list", "str"], "project": "flink"}
{"id": 8758, "code": "protected void registerNamespace(\n        SqlValidatorScope usingScope,\n        String alias,\n        SqlValidatorNamespace ns,\n        boolean forceNullable) {\n    namespaces.put(ns.getNode(), ns);\n    if (usingScope != null) {\n        usingScope.addChild(ns, alias, forceNullable);\n    }\n}", "summary_tokens": ["registers", "a", "new", "namespace", "and", "adds", "it", "as", "a", "child", "of", "its", "parent", "scope"], "project": "flink"}
{"id": 1091, "code": "public static JobExecutionResult fromJobSubmissionResult(JobSubmissionResult result) {\n    return new JobExecutionResult(result.getJobID(), -1, null);\n}", "summary_tokens": ["returns", "a", "dummy", "object", "for", "wrapping", "a", "job", "submission", "result"], "project": "flink"}
{"id": 568, "code": "private FlinkKafkaInternalProducer<byte[], byte[]> createTransactionalProducer()\n        throws FlinkKafkaException {\n    String transactionalId = availableTransactionalIds.poll();\n    if (transactionalId == null) {\n        throw new FlinkKafkaException(\n                FlinkKafkaErrorCode.PRODUCERS_POOL_EMPTY,\n                \"Too many ongoing snapshots. Increase kafka producers pool size or decrease number of concurrent checkpoints.\");\n    }\n    FlinkKafkaInternalProducer<byte[], byte[]> producer =\n            initTransactionalProducer(transactionalId, true);\n    producer.initTransactions();\n    return producer;\n}", "summary_tokens": ["for", "each", "checkpoint", "we", "create", "new", "flink", "kafka", "internal", "producer", "so", "that", "new", "transactions", "will", "not", "clash", "with", "transactions", "created", "during", "previous", "checkpoints", "producer"], "project": "flink"}
{"id": 7175, "code": "public SingleOutputStreamOperator<T> minBy(String field, boolean first) {\n    return aggregate(\n            new ComparableAggregator<>(\n                    field,\n                    input.getType(),\n                    AggregationFunction.AggregationType.MINBY,\n                    first,\n                    input.getExecutionConfig()));\n}", "summary_tokens": ["applies", "an", "aggregation", "that", "that", "gives", "the", "minimum", "element", "of", "the", "pojo", "data", "stream", "by", "the", "given", "field", "expression", "for", "every", "window"], "project": "flink"}
{"id": 8307, "code": "public static boolean isCompact(int precision) {\n    return precision <= 3;\n}", "summary_tokens": ["returns", "whether", "the", "timestamp", "data", "is", "small", "enough", "to", "be", "stored", "in", "a", "long", "of", "milliseconds"], "project": "flink"}
{"id": 6138, "code": "public void testDestroyWhileBlockingRequest() throws Exception {\n    AtomicReference<Exception> asyncException = new AtomicReference<>();\n\n    NetworkBufferPool networkBufferPool = null;\n    LocalBufferPool localBufferPool = null;\n\n    try {\n        networkBufferPool = new NetworkBufferPool(1, 4096);\n        localBufferPool = new LocalBufferPool(networkBufferPool, 1);\n\n            \n        assertNotNull(localBufferPool.requestBuffer());\n        assertNull(localBufferPool.requestBuffer());\n\n            \n        Thread thread = new Thread(new BufferRequestTask(localBufferPool, asyncException));\n        thread.start();\n\n            \n        boolean success = false;\n\n        for (int i = 0; i < 50; i++) {\n            StackTraceElement[] stackTrace = thread.getStackTrace();\n            success = isInBlockingBufferRequest(stackTrace);\n\n            if (success) {\n                break;\n            } else {\n                    \n                Thread.sleep(500);\n            }\n        }\n\n            \n        assertTrue(\"Did not trigger blocking buffer request.\", success);\n\n            \n        localBufferPool.lazyDestroy();\n\n            \n        thread.join();\n\n            \n        assertNotNull(\"Did not throw expected Exception\", asyncException.get());\n        assertTrue(asyncException.get() instanceof CancelTaskException);\n    } finally {\n        if (localBufferPool != null) {\n            localBufferPool.lazyDestroy();\n        }\n\n        if (networkBufferPool != null) {\n            networkBufferPool.destroyAllBufferPools();\n            networkBufferPool.destroy();\n        }\n    }\n}", "summary_tokens": ["tests", "that", "a", "blocking", "request", "fails", "properly", "if", "the", "buffer", "pool", "is", "destroyed"], "project": "flink"}
{"id": 6206, "code": "public void testCleanupReleasedPartitionWithView() throws Exception {\n    testCleanupReleasedPartition(true);\n}", "summary_tokens": ["tests", "cleanup", "of", "pipelined", "subpartition", "release", "with", "a", "read", "view", "attached"], "project": "flink"}
{"id": 4184, "code": "public static CheckpointProperties forSavepoint(boolean forced) {\n    return forced ? SAVEPOINT : SAVEPOINT_NO_FORCE;\n}", "summary_tokens": ["creates", "the", "checkpoint", "properties", "for", "a", "manually", "triggered", "savepoint"], "project": "flink"}
{"id": 5129, "code": "public boolean isStarted() {\n    return jobLeaderIdActions != null;\n}", "summary_tokens": ["checks", "whether", "the", "service", "has", "been", "started"], "project": "flink"}
{"id": 8514, "code": "public DataType toDataType(DataTypeFactory factory) {\n    DataType resolvedDataType = resolutionFactory.apply(factory);\n    if (isNullable == Boolean.TRUE) {\n        resolvedDataType = resolvedDataType.nullable();\n    } else if (isNullable == Boolean.FALSE) {\n        resolvedDataType = resolvedDataType.notNull();\n    }\n    if (conversionClass != null) {\n        resolvedDataType = resolvedDataType.bridgedTo(conversionClass);\n    }\n    return resolvedDataType;\n}", "summary_tokens": ["converts", "this", "instance", "to", "a", "resolved", "data", "type", "possibly", "enriched", "with", "additional", "nullability", "and", "conversion", "class", "information"], "project": "flink"}
{"id": 2393, "code": "public void writeXml(String propertyName, Writer out)\n        throws IOException, IllegalArgumentException {\n    Document doc = asXmlDocument(propertyName);\n\n    try {\n        DOMSource source = new DOMSource(doc);\n        StreamResult result = new StreamResult(out);\n        TransformerFactory transFactory = TransformerFactory.newInstance();\n        Transformer transformer = transFactory.newTransformer();\n\n            \n            \n            \n        transformer.transform(source, result);\n    } catch (TransformerException te) {\n        throw new IOException(te);\n    }\n}", "summary_tokens": ["write", "out", "the", "non", "default", "properties", "in", "this", "configuration", "to", "the", "given", "writer"], "project": "flink"}
{"id": 7318, "code": "public void setSplitState(Serializable state) {\n    this.splitState = state;\n}", "summary_tokens": ["sets", "the", "state", "of", "the", "split"], "project": "flink"}
{"id": 9319, "code": "public static HoppingSliceAssigner hopping(\n        int rowtimeIndex, ZoneId shiftTimeZone, Duration size, Duration slide) {\n    return new HoppingSliceAssigner(\n            rowtimeIndex, shiftTimeZone, size.toMillis(), slide.toMillis(), 0);\n}", "summary_tokens": ["creates", "a", "hopping", "window", "slice", "assigner", "that", "assigns", "elements", "to", "slices", "of", "hopping", "windows"], "project": "flink"}
{"id": 3295, "code": "public <T> Collection<T> getBroadcastSet(String name) {\n    return this.runtimeContext.getBroadcastVariable(name);\n}", "summary_tokens": ["gets", "the", "broadcast", "data", "set", "registered", "under", "the", "given", "name"], "project": "flink"}
{"id": 3625, "code": "public List<String> getBroadcastConnectionNames() {\n    return this.broadcastConnectionNames;\n}", "summary_tokens": ["return", "the", "list", "of", "names", "associated", "with", "broadcast", "inputs", "for", "this", "node"], "project": "flink"}
{"id": 698, "code": "public void runBigRecordTestTopology() throws Exception {\n\n    final String topic = \"bigRecordTestTopic\";\n    final int parallelism = 1; \n\n    createTestTopic(topic, parallelism, 1);\n\n    final TypeInformation<Tuple2<Long, byte[]>> longBytesInfo =\n            TypeInformation.of(new TypeHint<Tuple2<Long, byte[]>>() {});\n\n    final TypeInformationSerializationSchema<Tuple2<Long, byte[]>> serSchema =\n            new TypeInformationSerializationSchema<>(longBytesInfo, new ExecutionConfig());\n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setRestartStrategy(RestartStrategies.noRestart());\n    env.enableCheckpointing(100);\n    env.setParallelism(parallelism);\n\n        \n    Properties consumerProps = new Properties();\n    consumerProps.putAll(standardProps);\n    consumerProps.setProperty(\"fetch.message.max.bytes\", Integer.toString(1024 * 1024 * 14));\n    consumerProps.setProperty(\n            \"max.partition.fetch.bytes\",\n            Integer.toString(1024 * 1024 * 14)); \n    consumerProps.setProperty(\"queued.max.message.chunks\", \"1\");\n    consumerProps.putAll(secureProps);\n\n    DataStreamSource<Tuple2<Long, byte[]>> consuming =\n            getStream(env, topic, serSchema, consumerProps);\n\n    consuming.addSink(\n            new SinkFunction<Tuple2<Long, byte[]>>() {\n\n                private int elCnt = 0;\n\n                @Override\n                public void invoke(Tuple2<Long, byte[]> value) throws Exception {\n                    elCnt++;\n                    if (value.f0 == -1) {\n                            \n                        if (elCnt == 11) {\n                            throw new SuccessException();\n                        } else {\n                            throw new RuntimeException(\n                                    \"There have been \" + elCnt + \" elements\");\n                        }\n                    }\n                    if (elCnt > 10) {\n                        throw new RuntimeException(\"More than 10 elements seen: \" + elCnt);\n                    }\n                }\n            });\n\n        \n    Properties producerProps = new Properties();\n    producerProps.setProperty(\"max.request.size\", Integer.toString(1024 * 1024 * 15));\n    producerProps.setProperty(\"retries\", \"3\");\n    producerProps.putAll(secureProps);\n    producerProps.setProperty(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerConnectionStrings);\n\n    DataStream<Tuple2<Long, byte[]>> stream =\n            env.addSource(\n                    new RichSourceFunction<Tuple2<Long, byte[]>>() {\n\n                        private boolean running;\n\n                        @Override\n                        public void open(Configuration parameters) throws Exception {\n                            super.open(parameters);\n                            running = true;\n                        }\n\n                        @Override\n                        public void run(SourceContext<Tuple2<Long, byte[]>> ctx)\n                                throws Exception {\n                            Random rnd = new Random();\n                            long cnt = 0;\n                            int sevenMb = 1024 * 1024 * 7;\n\n                            while (running) {\n                                byte[] wl = new byte[sevenMb + rnd.nextInt(sevenMb)];\n                                ctx.collect(new Tuple2<>(cnt++, wl));\n\n                                Thread.sleep(100);\n\n                                if (cnt == 10) {\n                                        \n                                    ctx.collect(new Tuple2<>(-1L, new byte[] {1}));\n                                    break;\n                                }\n                            }\n                        }\n\n                        @Override\n                        public void cancel() {\n                            running = false;\n                        }\n                    });\n\n    kafkaServer.produceIntoKafka(stream, topic, serSchema, producerProps, null);\n\n    tryExecute(env, \"big topology test\");\n    deleteTestTopic(topic);\n}", "summary_tokens": ["test", "flink", "s", "kafka", "integration", "also", "with", "very", "big", "records", "0", "mb"], "project": "flink"}
{"id": 6740, "code": "private S removeNode(\n        SkipListNodePointers pointers, Boolean isLogicallyRemoved, boolean returnOldState) {\n    long prevNode = pointers.prevNode;\n    long currentNode = pointers.currentNode;\n    long nextNode = pointers.nextNode;\n        \n        \n    if (isLogicallyRemoved && highestRequiredSnapshotVersionPlusOne != 0) {\n        return null;\n    }\n\n    long oldValuePointer;\n    boolean oldValueNeedFree;\n\n    if (highestRequiredSnapshotVersionPlusOne == 0) {\n            \n        oldValuePointer = doPhysicalRemoveAndGetValue(currentNode, prevNode, nextNode);\n            \n        if (isLogicallyRemoved) {\n            logicallyRemovedNodes.remove(currentNode);\n        }\n        oldValueNeedFree = true;\n    } else {\n        int version = SkipListUtils.helpGetNodeLatestVersion(currentNode, spaceAllocator);\n        if (version < highestRequiredSnapshotVersionPlusOne) {\n                \n                \n            oldValuePointer = updateValueWithCopyOnWrite(currentNode, null);\n            oldValueNeedFree = false;\n        } else {\n                \n            oldValuePointer = updateValueWithReplace(currentNode, null);\n            oldValueNeedFree = true;\n        }\n\n        helpSetNodeStatus(currentNode, NodeStatus.REMOVE);\n        logicallyRemovedNodes.add(currentNode);\n    }\n\n    S oldState = null;\n    if (returnOldState) {\n        oldState = helpGetState(oldValuePointer);\n    }\n\n    if (oldValueNeedFree) {\n        spaceAllocator.free(oldValuePointer);\n    }\n\n    return oldState;\n}", "summary_tokens": ["remove", "the", "given", "node", "indicated", "by", "skip", "list", "node", "pointers", "current", "node"], "project": "flink"}
{"id": 9678, "code": "public E nextEvent() {\n\n        \n    if (subGeneratorLists.isEmpty()) {\n        return null;\n    }\n\n    final long globalWatermark = getWatermark();\n\n        \n        \n        \n    final int choice = randomGenerator.choseRandomIndex(subGeneratorLists);\n\n    for (int i = choice; i < choice + subGeneratorLists.size(); ++i) {\n\n        final int index = i % subGeneratorLists.size();\n        EventGenerator<K, E> subGenerator = subGeneratorLists.get(index);\n\n            \n        if (subGenerator.canGenerateEventAtWatermark(globalWatermark)) {\n\n            E event = subGenerator.generateEvent(globalWatermark);\n\n                \n            if (!subGenerator.hasMoreEvents()) {\n\n                    \n                if (generatorFactory.getProducedGeneratorsCount() < sessionCountLimit) {\n                    subGeneratorLists.set(\n                            index,\n                            generatorFactory.newSessionGeneratorForKey(\n                                    randomGenerator.chooseRandomElement(sessionKeys),\n                                    getWatermark()));\n                } else {\n                        \n                        \n                    subGeneratorLists.remove(index);\n                }\n            }\n            return event;\n        }\n    }\n\n        \n    throw new IllegalStateException(\n            \"Unable to find an open sub-generator that can produce events\");\n}", "summary_tokens": ["the", "next", "generated", "event"], "project": "flink"}
{"id": 5133, "code": "private RegistrationResponse registerTaskExecutorInternal(\n        TaskExecutorGateway taskExecutorGateway,\n        TaskExecutorRegistration taskExecutorRegistration) {\n    ResourceID taskExecutorResourceId = taskExecutorRegistration.getResourceId();\n    WorkerRegistration<WorkerType> oldRegistration =\n            taskExecutors.remove(taskExecutorResourceId);\n    if (oldRegistration != null) {\n            \n        log.debug(\n                \"Replacing old registration of TaskExecutor {}.\",\n                taskExecutorResourceId.getStringWithMetadata());\n\n            \n        slotManager.unregisterTaskManager(\n                oldRegistration.getInstanceID(),\n                new ResourceManagerException(\n                        String.format(\n                                \"TaskExecutor %s re-connected to the ResourceManager.\",\n                                taskExecutorResourceId.getStringWithMetadata())));\n    }\n\n    final WorkerType newWorker = workerStarted(taskExecutorResourceId);\n\n    String taskExecutorAddress = taskExecutorRegistration.getTaskExecutorAddress();\n    if (newWorker == null) {\n        log.warn(\n                \"Discard registration from TaskExecutor {} at ({}) because the framework did \"\n                        + \"not recognize it\",\n                taskExecutorResourceId.getStringWithMetadata(),\n                taskExecutorAddress);\n        return new TaskExecutorRegistrationRejection(\n                \"The ResourceManager does not recognize this TaskExecutor.\");\n    } else {\n        WorkerRegistration<WorkerType> registration =\n                new WorkerRegistration<>(\n                        taskExecutorGateway,\n                        newWorker,\n                        taskExecutorRegistration.getDataPort(),\n                        taskExecutorRegistration.getJmxPort(),\n                        taskExecutorRegistration.getHardwareDescription(),\n                        taskExecutorRegistration.getMemoryConfiguration(),\n                        taskExecutorRegistration.getTotalResourceProfile(),\n                        taskExecutorRegistration.getDefaultSlotResourceProfile());\n\n        log.info(\n                \"Registering TaskManager with ResourceID {} ({}) at ResourceManager\",\n                taskExecutorResourceId.getStringWithMetadata(),\n                taskExecutorAddress);\n        taskExecutors.put(taskExecutorResourceId, registration);\n\n        taskManagerHeartbeatManager.monitorTarget(\n                taskExecutorResourceId, new TaskExecutorHeartbeatSender(taskExecutorGateway));\n\n        return new TaskExecutorRegistrationSuccess(\n                registration.getInstanceID(), resourceId, clusterInformation);\n    }\n}", "summary_tokens": ["registers", "a", "new", "task", "executor"], "project": "flink"}
{"id": 8593, "code": "public static TypeStrategy mapping(Map<InputTypeStrategy, TypeStrategy> mappings) {\n    return new MappingTypeStrategy(mappings);\n}", "summary_tokens": ["type", "strategy", "that", "maps", "an", "input", "type", "strategy", "to", "a", "type", "strategy", "if", "the", "input", "strategy", "infers", "identical", "types"], "project": "flink"}
{"id": 31, "code": "private <ClusterID> void runClusterAction(\n        CustomCommandLine activeCommandLine,\n        CommandLine commandLine,\n        ClusterAction<ClusterID> clusterAction)\n        throws FlinkException {\n    final Configuration effectiveConfiguration =\n            getEffectiveConfiguration(activeCommandLine, commandLine);\n    LOG.debug(\n            \"Effective configuration after Flink conf, and custom commandline: {}\",\n            effectiveConfiguration);\n\n    final ClusterClientFactory<ClusterID> clusterClientFactory =\n            clusterClientServiceLoader.getClusterClientFactory(effectiveConfiguration);\n\n    final ClusterID clusterId = clusterClientFactory.getClusterId(effectiveConfiguration);\n    if (clusterId == null) {\n        throw new FlinkException(\n                \"No cluster id was specified. Please specify a cluster to which you would like to connect.\");\n    }\n\n    try (final ClusterDescriptor<ClusterID> clusterDescriptor =\n            clusterClientFactory.createClusterDescriptor(effectiveConfiguration)) {\n        try (final ClusterClient<ClusterID> clusterClient =\n                clusterDescriptor.retrieve(clusterId).getClusterClient()) {\n            clusterAction.runAction(clusterClient);\n        }\n    }\n}", "summary_tokens": ["retrieves", "the", "cluster", "client", "from", "the", "given", "custom", "command", "line", "and", "runs", "the", "given", "cluster", "action", "against", "it"], "project": "flink"}
{"id": 2751, "code": "public DataSink<T> sortLocalOutput(String fieldExpression, Order order) {\n\n    int numFields;\n    int[] fields;\n    Order[] orders;\n\n        \n    Keys.ExpressionKeys<T> ek = new Keys.ExpressionKeys<>(fieldExpression, this.type);\n    fields = ek.computeLogicalKeyPositions();\n\n    if (!Keys.ExpressionKeys.isSortKey(fieldExpression, this.type)) {\n        throw new InvalidProgramException(\"Selected sort key is not a sortable type\");\n    }\n\n    numFields = fields.length;\n    orders = new Order[numFields];\n    Arrays.fill(orders, order);\n\n    if (this.sortKeyPositions == null) {\n            \n        this.sortKeyPositions = fields;\n        this.sortOrders = orders;\n    } else {\n            \n        int oldLength = this.sortKeyPositions.length;\n        int newLength = oldLength + numFields;\n        this.sortKeyPositions = Arrays.copyOf(this.sortKeyPositions, newLength);\n        this.sortOrders = Arrays.copyOf(this.sortOrders, newLength);\n        for (int i = 0; i < numFields; i++) {\n            this.sortKeyPositions[oldLength + i] = fields[i];\n            this.sortOrders[oldLength + i] = orders[i];\n        }\n    }\n\n    return this;\n}", "summary_tokens": ["sorts", "each", "local", "partition", "of", "a", "data", "set", "on", "the", "field", "s", "specified", "by", "the", "field", "expression", "in", "the", "specified", "order", "before", "it", "is", "emitted", "by", "the", "output", "format"], "project": "flink"}
{"id": 2712, "code": "public static int getDefaultLocalParallelism() {\n    return defaultLocalDop;\n}", "summary_tokens": ["gets", "the", "default", "parallelism", "that", "will", "be", "used", "for", "the", "local", "execution", "environment", "created", "by", "create", "local", "environment"], "project": "flink"}
{"id": 1933, "code": "static <T> CloseableIterable<T> empty() {\n    return new CloseableIterable.Empty<>();\n}", "summary_tokens": ["returns", "an", "empty", "iterator"], "project": "flink"}
{"id": 1322, "code": "default void open(InitializationContext context) throws Exception {}", "summary_tokens": ["initialization", "method", "for", "the", "schema"], "project": "flink"}
{"id": 6575, "code": "public void testLoadFileSystemStateBackend() throws Exception {\n    final String checkpointDir = new Path(tmp.newFolder().toURI()).toString();\n    final String savepointDir = new Path(tmp.newFolder().toURI()).toString();\n    final Path expectedCheckpointsPath = new Path(checkpointDir);\n    final Path expectedSavepointsPath = new Path(savepointDir);\n    final MemorySize threshold = MemorySize.parse(\"900kb\");\n    final int minWriteBufferSize = 1024;\n\n        \n        \n        \n    final Configuration config1 = new Configuration();\n    config1.setString(backendKey, \"filesystem\");\n    config1.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir);\n    config1.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir);\n    config1.set(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, threshold);\n    config1.setInteger(CheckpointingOptions.FS_WRITE_BUFFER_SIZE, minWriteBufferSize);\n\n    final Configuration config2 = new Configuration();\n    config2.setString(backendKey, FsStateBackendFactory.class.getName());\n    config2.setString(CheckpointingOptions.CHECKPOINTS_DIRECTORY, checkpointDir);\n    config2.setString(CheckpointingOptions.SAVEPOINT_DIRECTORY, savepointDir);\n    config2.set(CheckpointingOptions.FS_SMALL_FILE_THRESHOLD, threshold);\n    config1.setInteger(CheckpointingOptions.FS_WRITE_BUFFER_SIZE, minWriteBufferSize);\n\n    StateBackend backend1 = StateBackendLoader.loadStateBackendFromConfig(config1, cl, null);\n    StateBackend backend2 = StateBackendLoader.loadStateBackendFromConfig(config2, cl, null);\n\n    assertTrue(backend1 instanceof HashMapStateBackend);\n    assertTrue(backend2 instanceof FsStateBackend);\n\n    HashMapStateBackend fs1 = (HashMapStateBackend) backend1;\n    FsStateBackend fs2 = (FsStateBackend) backend2;\n\n    assertEquals(expectedCheckpointsPath, fs2.getCheckpointPath());\n    assertEquals(expectedSavepointsPath, fs2.getSavepointPath());\n    assertEquals(threshold.getBytes(), fs2.getMinFileSizeThreshold());\n    assertEquals(Math.max(threshold.getBytes(), minWriteBufferSize), fs2.getWriteBufferSize());\n}", "summary_tokens": ["validates", "loading", "a", "file", "system", "state", "backend", "with", "additional", "parameters", "from", "the", "cluster", "configuration"], "project": "flink"}
{"id": 4224, "code": "private void checkNoPartlyOperatorsFinishedVertexUsedUnionListState(\n        Map<JobVertexID, ExecutionJobVertex> partlyFinishedVertex,\n        Map<OperatorID, OperatorState> operatorStates) {\n    for (Map.Entry<ExecutionJobVertex, Integer> entry :\n            vertexOperatorsFinishedTasksCount.entrySet()) {\n        ExecutionJobVertex vertex = entry.getKey();\n\n            \n            \n        if (partlyFinishedVertex.containsKey(vertex.getJobVertexId())) {\n            continue;\n        }\n\n        if (entry.getValue() != vertex.getParallelism()\n                && hasUsedUnionListState(vertex, operatorStates)) {\n            throw new FlinkRuntimeException(\n                    String.format(\n                            \"The vertex %s (id = %s) has used\"\n                                    + \" UnionListState, but part of its tasks has called operators' finish method.\",\n                            vertex.getName(), vertex.getJobVertexId()));\n        }\n    }\n}", "summary_tokens": ["if", "a", "job", "vertex", "using", "union", "list", "state", "has", "all", "the", "tasks", "in", "running", "state", "but", "part", "of", "the", "tasks", "have", "reported", "that", "the", "operators", "are", "finished", "the", "checkpoint", "would", "be", "aborted"], "project": "flink"}
{"id": 6487, "code": "public void testImmediateCacheInvalidationAfterFailure() throws Exception {\n    final Time timeout = Time.milliseconds(100L);\n    final Time timeToLive = Time.hours(1L);\n\n        \n    final CountingRestfulGateway restfulGateway =\n            createCountingRestfulGateway(\n                    expectedJobId,\n                    FutureUtils.completedExceptionally(\n                            new FlinkJobNotFoundException(expectedJobId)),\n                    CompletableFuture.completedFuture(expectedExecutionGraphInfo));\n\n    try (ExecutionGraphCache executionGraphCache =\n            new DefaultExecutionGraphCache(timeout, timeToLive)) {\n        CompletableFuture<ExecutionGraphInfo> executionGraphFuture =\n                executionGraphCache.getExecutionGraphInfo(expectedJobId, restfulGateway);\n\n        try {\n            executionGraphFuture.get();\n\n            fail(\"The execution graph future should have been completed exceptionally.\");\n        } catch (ExecutionException ee) {\n            ee.printStackTrace();\n            assertTrue(ee.getCause() instanceof FlinkException);\n        }\n\n        CompletableFuture<ExecutionGraphInfo> executionGraphFuture2 =\n                executionGraphCache.getExecutionGraphInfo(expectedJobId, restfulGateway);\n\n        assertEquals(expectedExecutionGraphInfo, executionGraphFuture2.get());\n    }\n}", "summary_tokens": ["tests", "that", "a", "failure", "in", "requesting", "an", "access", "execution", "graph", "from", "the", "gateway", "will", "not", "create", "a", "cache", "entry", "another", "cache", "request", "will", "trigger", "a", "new", "gateway", "request"], "project": "flink"}
{"id": 2641, "code": "public List<T> collect() throws Exception {\n    final String id = new AbstractID().toString();\n    final TypeSerializer<T> serializer =\n            getType().createSerializer(getExecutionEnvironment().getConfig());\n\n    this.output(new Utils.CollectHelper<>(id, serializer)).name(\"collect()\");\n    JobExecutionResult res = getExecutionEnvironment().execute();\n\n    ArrayList<byte[]> accResult = res.getAccumulatorResult(id);\n    if (accResult != null) {\n        try {\n            return SerializedListAccumulator.deserializeList(accResult, serializer);\n        } catch (ClassNotFoundException e) {\n            throw new RuntimeException(\"Cannot find type class of collected data type.\", e);\n        } catch (IOException e) {\n            throw new RuntimeException(\n                    \"Serialization error while deserializing collected data\", e);\n        }\n    } else {\n        throw new RuntimeException(\"The call to collect() could not retrieve the DataSet.\");\n    }\n}", "summary_tokens": ["convenience", "method", "to", "get", "the", "elements", "of", "a", "data", "set", "as", "a", "list"], "project": "flink"}
{"id": 6159, "code": "public void testForwardsRetainBuffer2() {\n    ReadOnlySlicedNetworkBuffer slice = buffer.readOnlySlice(1, 2);\n    assertEquals(buffer.refCnt(), slice.refCnt());\n    slice.retainBuffer();\n    assertEquals(buffer.refCnt(), slice.refCnt());\n}", "summary_tokens": ["tests", "forwarding", "of", "both", "read", "only", "sliced", "network", "buffer", "retain", "buffer", "and", "read", "only", "sliced", "network", "buffer", "is", "recycled"], "project": "flink"}
{"id": 9390, "code": "public static void setInt(MemorySegment[] segments, int offset, int value) {\n    if (inFirstSegment(segments, offset, 4)) {\n        segments[0].putInt(offset, value);\n    } else {\n        setIntMultiSegments(segments, offset, value);\n    }\n}", "summary_tokens": ["set", "int", "from", "segments"], "project": "flink"}
{"id": 6957, "code": "private boolean overwriteFilterIfExist(BlockBasedTableConfig blockBasedTableConfig) {\n    if (blockBasedTableConfig.filterPolicy() != null) {\n            \n            \n        BloomFilter newFilter = new BloomFilter(10, false);\n        LOG.info(\n                \"Existing filter has been overwritten to full filters since partitioned index filters is enabled.\");\n        blockBasedTableConfig.setFilterPolicy(newFilter);\n        handlesToClose.add(newFilter);\n    }\n    return true;\n}", "summary_tokens": ["overwrite", "configured", "filter", "if", "enable", "partitioned", "filter"], "project": "flink"}
{"id": 8324, "code": "public static void bitUnSet(MemorySegment[] segments, int baseOffset, int index) {\n    if (segments.length == 1) {\n        MemorySegment segment = segments[0];\n        int offset = baseOffset + byteIndex(index);\n        byte current = segment.get(offset);\n        current &= ~(1 << (index & BIT_BYTE_INDEX_MASK));\n        segment.put(offset, current);\n    } else {\n        bitUnSetMultiSegments(segments, baseOffset, index);\n    }\n}", "summary_tokens": ["unset", "bit", "from", "segments"], "project": "flink"}
{"id": 4690, "code": "public void requestSubpartition(int subpartitionIndex)\n        throws IOException, InterruptedException {\n    if (partitionRequestClient == null) {\n        LOG.debug(\n                \"{}: Requesting REMOTE subpartition {} of partition {}. {}\",\n                this,\n                subpartitionIndex,\n                partitionId,\n                channelStatePersister);\n            \n        try {\n            partitionRequestClient =\n                    connectionManager.createPartitionRequestClient(connectionId);\n        } catch (IOException e) {\n                \n                \n            throw new PartitionConnectionException(partitionId, e);\n        }\n\n        partitionRequestClient.requestSubpartition(partitionId, subpartitionIndex, this, 0);\n    }\n}", "summary_tokens": ["requests", "a", "remote", "subpartition"], "project": "flink"}
{"id": 1166, "code": "public void open(FileInputSplit split) throws IOException {\n    super.open(split);\n    initBuffers();\n\n    this.offset = splitStart;\n    if (this.splitStart != 0) {\n        this.stream.seek(offset);\n        readLine();\n            \n            \n        if (this.overLimit) {\n            this.end = true;\n        }\n    } else {\n        fillBuffer(0);\n    }\n    initializeSplit(split, null);\n}", "summary_tokens": ["opens", "the", "given", "input", "split"], "project": "flink"}
{"id": 8028, "code": "static TableEnvironment create(Configuration configuration) {\n    return TableEnvironmentImpl.create(configuration);\n}", "summary_tokens": ["creates", "a", "table", "environment", "that", "is", "the", "entry", "point", "and", "central", "context", "for", "creating", "table", "and", "sql", "api", "programs"], "project": "flink"}
{"id": 6763, "code": "int helpGetValueLen(long valuePointer) {\n    return SkipListUtils.helpGetValueLen(valuePointer, spaceAllocator);\n}", "summary_tokens": ["returns", "the", "length", "of", "the", "value"], "project": "flink"}
{"id": 1619, "code": "private static boolean previousSerializerHasNonRegisteredSubclasses(\n        LinkedOptionalMap<Class<?>, TypeSerializerSnapshot<?>>\n                nonRegisteredSubclassSerializerSnapshots) {\n    return nonRegisteredSubclassSerializerSnapshots.size() > 0;\n}", "summary_tokens": ["checks", "whether", "the", "previous", "serializer", "represented", "by", "this", "snapshot", "has", "non", "registered", "subclasses"], "project": "flink"}
{"id": 7486, "code": "public void close() throws Exception {\n    try {\n        if (outputStream != null) {\n            outputStream.flush();\n            outputStream.close();\n        }\n\n            \n        if (client != null) {\n            client.close();\n        }\n    } catch (Exception e) {\n        throw new IOException(\n                \"Error while closing connection that streams data back to client at \"\n                        + hostIp.toString()\n                        + \":\"\n                        + port,\n                e);\n    } finally {\n            \n        if (client != null) {\n            try {\n                client.close();\n            } catch (Throwable t) {\n                    \n            }\n        }\n    }\n}", "summary_tokens": ["closes", "the", "connection", "with", "the", "socket", "server"], "project": "flink"}
{"id": 673, "code": "public void testAsyncErrorRethrownOnCheckpointAfterFlush() throws Throwable {\n    final DummyFlinkKafkaProducer<String> producer =\n            new DummyFlinkKafkaProducer<>(\n                    FakeStandardProducerConfig.get(),\n                    new KeyedSerializationSchemaWrapper<>(new SimpleStringSchema()),\n                    null);\n    producer.setFlushOnCheckpoint(true);\n\n    final KafkaProducer<?, ?> mockProducer = producer.getMockKafkaProducer();\n\n    final OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer));\n\n    testHarness.open();\n\n    testHarness.processElement(new StreamRecord<>(\"msg-1\"));\n    testHarness.processElement(new StreamRecord<>(\"msg-2\"));\n    testHarness.processElement(new StreamRecord<>(\"msg-3\"));\n\n    verify(mockProducer, times(3)).send(any(ProducerRecord.class), any(Callback.class));\n\n        \n    producer.getPendingCallbacks().get(0).onCompletion(null, null);\n\n    CheckedThread snapshotThread =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                        \n                        \n                    testHarness.snapshot(123L, 123L);\n                }\n            };\n    snapshotThread.start();\n\n        \n    producer.getPendingCallbacks()\n            .get(1)\n            .onCompletion(null, new Exception(\"artificial async failure for 2nd message\"));\n    producer.getPendingCallbacks().get(2).onCompletion(null, null);\n\n    try {\n        snapshotThread.sync();\n    } catch (Exception e) {\n            \n        Assert.assertTrue(\n                e.getCause().getMessage().contains(\"artificial async failure for 2nd message\"));\n\n            \n        return;\n    }\n\n    Assert.fail();\n}", "summary_tokens": ["test", "ensuring", "that", "if", "an", "async", "exception", "is", "caught", "for", "one", "of", "the", "flushed", "requests", "on", "checkpoint", "it", "should", "be", "rethrown", "we", "set", "a", "timeout", "because", "the", "test", "will", "not", "finish", "if", "the", "logic", "is", "broken"], "project": "flink"}
{"id": 6841, "code": "public void testSnapshotNodeIteratorIllegalNextInvocation() {\n    CopyOnWriteSkipListStateMapSnapshot<Integer, Long, String> snapshot =\n            stateMap.stateSnapshot();\n    CopyOnWriteSkipListStateMapSnapshot.SnapshotNodeIterator iterator =\n            snapshot.new SnapshotNodeIterator(false);\n    while (iterator.hasNext()) {\n        iterator.next();\n    }\n    try {\n        iterator.next();\n        fail(\"Should have thrown NoSuchElementException.\");\n    } catch (NoSuchElementException e) {\n            \n    } finally {\n        snapshot.release();\n    }\n}", "summary_tokens": ["test", "snapshot", "node", "iterator", "illegal", "next", "call"], "project": "flink"}
{"id": 1490, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f5)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f6)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f7)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f8)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f9)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f10)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f11)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f12)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f13)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f14)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f15)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f16)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 3784, "code": "public void testResourcesForChainedOperators() throws Exception {\n    ResourceSpec resource1 = ResourceSpec.newBuilder(0.1, 100).build();\n    ResourceSpec resource2 = ResourceSpec.newBuilder(0.2, 200).build();\n    ResourceSpec resource3 = ResourceSpec.newBuilder(0.3, 300).build();\n    ResourceSpec resource4 = ResourceSpec.newBuilder(0.4, 400).build();\n    ResourceSpec resource5 = ResourceSpec.newBuilder(0.5, 500).build();\n    ResourceSpec resource6 = ResourceSpec.newBuilder(0.6, 600).build();\n    ResourceSpec resource7 = ResourceSpec.newBuilder(0.7, 700).build();\n\n    Method opMethod = Operator.class.getDeclaredMethod(\"setResources\", ResourceSpec.class);\n    opMethod.setAccessible(true);\n\n    Method sinkMethod = DataSink.class.getDeclaredMethod(\"setResources\", ResourceSpec.class);\n    sinkMethod.setAccessible(true);\n\n    MapFunction<Long, Long> mapFunction =\n            new MapFunction<Long, Long>() {\n                @Override\n                public Long map(Long value) throws Exception {\n                    return value;\n                }\n            };\n\n    FilterFunction<Long> filterFunction =\n            new FilterFunction<Long>() {\n                @Override\n                public boolean filter(Long value) throws Exception {\n                    return false;\n                }\n            };\n\n    ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n    DataSet<Long> input = env.fromElements(1L, 2L, 3L);\n    opMethod.invoke(input, resource1);\n\n    DataSet<Long> map1 = input.map(mapFunction);\n    opMethod.invoke(map1, resource2);\n\n        \n    DataSet<Long> filter1 = map1.filter(filterFunction);\n    opMethod.invoke(filter1, resource3);\n\n    IterativeDataSet<Long> startOfIteration = filter1.iterate(10);\n    opMethod.invoke(startOfIteration, resource4);\n\n    DataSet<Long> map2 = startOfIteration.map(mapFunction);\n    opMethod.invoke(map2, resource5);\n\n        \n    DataSet<Long> feedback = map2.filter(filterFunction);\n    opMethod.invoke(feedback, resource6);\n\n    DataSink<Long> sink =\n            startOfIteration.closeWith(feedback).output(new DiscardingOutputFormat<Long>());\n    sinkMethod.invoke(sink, resource7);\n\n    JobGraph jobGraph = compileJob(env);\n\n    JobVertex sourceMapFilterVertex =\n            jobGraph.getVerticesSortedTopologicallyFromSources().get(0);\n    JobVertex iterationHeadVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(1);\n    JobVertex feedbackVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(2);\n    JobVertex sinkVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(3);\n    JobVertex iterationSyncVertex = jobGraph.getVerticesSortedTopologicallyFromSources().get(4);\n\n    assertTrue(\n            sourceMapFilterVertex\n                    .getMinResources()\n                    .equals(resource1.merge(resource2).merge(resource3)));\n    assertTrue(iterationHeadVertex.getPreferredResources().equals(resource4));\n    assertTrue(feedbackVertex.getMinResources().equals(resource5.merge(resource6)));\n    assertTrue(sinkVertex.getPreferredResources().equals(resource7));\n    assertTrue(iterationSyncVertex.getMinResources().equals(resource4));\n}", "summary_tokens": ["verifies", "that", "the", "resources", "are", "merged", "correctly", "for", "chained", "operators", "when", "generating", "job", "graph"], "project": "flink"}
{"id": 1455, "code": "public String toString() {\n    return \"()\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form"], "project": "flink"}
{"id": 7698, "code": "public void testEventTimeTimerWithState() throws Exception {\n\n    KeyedCoProcessOperator<String, Integer, String, String> operator =\n            new KeyedCoProcessOperator<>(new EventTimeTriggeringStatefulProcessFunction());\n\n    TwoInputStreamOperatorTestHarness<Integer, String, String> testHarness =\n            new KeyedTwoInputStreamOperatorTestHarness<>(\n                    operator,\n                    new IntToStringKeySelector<>(),\n                    new IdentityKeySelector<String>(),\n                    BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.processWatermark1(new Watermark(1));\n    testHarness.processWatermark2(new Watermark(1));\n    testHarness.processElement1(new StreamRecord<>(17, 0L)); \n    testHarness.processElement1(new StreamRecord<>(13, 0L)); \n\n    testHarness.processWatermark1(new Watermark(2));\n    testHarness.processWatermark2(new Watermark(2));\n    testHarness.processElement1(new StreamRecord<>(13, 1L)); \n    testHarness.processElement2(new StreamRecord<>(\"42\", 1L)); \n\n    testHarness.processWatermark1(new Watermark(6));\n    testHarness.processWatermark2(new Watermark(6));\n\n    testHarness.processWatermark1(new Watermark(7));\n    testHarness.processWatermark2(new Watermark(7));\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    expectedOutput.add(new Watermark(1L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT1:17\", 0L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT1:13\", 0L));\n    expectedOutput.add(new Watermark(2L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT2:42\", 1L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:17\", 6L));\n    expectedOutput.add(new Watermark(6L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:42\", 7L));\n    expectedOutput.add(new Watermark(7L));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.close();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "leakage", "between", "different", "keys"], "project": "flink"}
{"id": 9747, "code": "public void testMemoryPropertyWithUnitMB() throws Exception {\n    final String[] args = new String[] {\"-yjm\", \"1024m\", \"-ytm\", \"2048m\"};\n    final FlinkYarnSessionCli flinkYarnSessionCli = createFlinkYarnSessionCli();\n    final CommandLine commandLine = flinkYarnSessionCli.parseCommandLineOptions(args, false);\n\n    final Configuration executorConfig = flinkYarnSessionCli.toConfiguration(commandLine);\n    final ClusterClientFactory<ApplicationId> clientFactory =\n            getClusterClientFactory(executorConfig);\n    final ClusterSpecification clusterSpecification =\n            clientFactory.getClusterSpecification(executorConfig);\n\n    assertThat(clusterSpecification.getMasterMemoryMB(), is(1024));\n    assertThat(clusterSpecification.getTaskManagerMemoryMB(), is(2048));\n}", "summary_tokens": ["tests", "the", "specifying", "total", "process", "memory", "with", "unit", "mb", "for", "job", "manager", "and", "task", "manager"], "project": "flink"}
{"id": 3229, "code": "public GraphCsvReader ignoreInvalidLinesVertices() {\n    if (this.vertexReader != null) {\n        this.vertexReader.ignoreInvalidLines();\n    }\n    return this;\n}", "summary_tokens": ["sets", "the", "csv", "reader", "vertices", "file", "to", "ignore", "any", "invalid", "lines"], "project": "flink"}
{"id": 5712, "code": "public CompletableFuture<Tuple2<String, UUID>> getLeaderFuture() {\n    return atomicLeaderFuture.get();\n}", "summary_tokens": ["returns", "the", "current", "job", "manager", "gateway", "future"], "project": "flink"}
{"id": 8856, "code": "protected static <T> T getLiteralValueAs(LiteralValueAccessor accessor, Class<T> clazz) {\n    Preconditions.checkArgument(!clazz.isPrimitive());\n\n    Object convertedValue = null;\n\n    if (clazz == Duration.class) {\n        final long longVal = accessor.getValueAs(Long.class);\n        convertedValue = Duration.ofMillis(longVal);\n    } else if (clazz == Period.class) {\n        final long longVal = accessor.getValueAs(Long.class);\n        if (longVal <= Integer.MAX_VALUE && longVal >= Integer.MIN_VALUE) {\n            convertedValue = Period.ofMonths((int) longVal);\n        }\n    } else if (clazz == java.time.LocalDate.class) {\n        final DateString dateString = accessor.getValueAs(DateString.class);\n        convertedValue = java.time.LocalDate.parse(dateString.toString());\n    } else if (clazz == java.time.LocalTime.class) {\n        final TimeString timeString = accessor.getValueAs(TimeString.class);\n        convertedValue = java.time.LocalTime.parse(timeString.toString());\n    } else if (clazz == java.time.LocalDateTime.class) {\n        final TimestampString timestampString = accessor.getValueAs(TimestampString.class);\n        convertedValue =\n                java.time.LocalDateTime.parse(timestampString.toString().replace(' ', 'T'));\n    } else if (clazz == java.time.Instant.class) {\n            \n        final TimestampString timestampString = accessor.getValueAs(TimestampString.class);\n        convertedValue =\n                java.time.LocalDateTime.parse(timestampString.toString().replace(' ', 'T'))\n                        .atOffset(ZoneOffset.UTC)\n                        .toInstant();\n    }\n\n    if (convertedValue != null) {\n        return (T) convertedValue;\n    }\n\n    return accessor.getValueAs(clazz);\n}", "summary_tokens": ["bridges", "to", "value", "literal", "expression", "get", "value", "as", "class"], "project": "flink"}
{"id": 7708, "code": "public void testValueStateNullAsDefaultValue() throws Exception {\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n\n    ValueStateDescriptor<String> kvId = new ValueStateDescriptor<>(\"id\", String.class, null);\n\n    ValueState<String> state =\n            backend.getPartitionedState(\n                    VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n    backend.setCurrentKey(1);\n    assertNull(state.value());\n\n    state.update(\"Ciao\");\n    assertEquals(\"Ciao\", state.value());\n\n    state.clear();\n    assertNull(state.value());\n\n    backend.dispose();\n}", "summary_tokens": ["verify", "that", "value", "state", "descriptor", "allows", "null", "as", "default"], "project": "flink"}
{"id": 5045, "code": "public static <E> ExternalSorterBuilder<E> newBuilder(\n        MemoryManager memoryManager,\n        AbstractInvokable parentTask,\n        TypeSerializer<E> serializer,\n        TypeComparator<E> comparator) {\n    return newBuilder(\n            checkNotNull(memoryManager),\n            checkNotNull(parentTask),\n            checkNotNull(serializer),\n            checkNotNull(comparator),\n            parentTask.getExecutionConfig());\n}", "summary_tokens": ["creates", "a", "builder", "for", "the", "external", "sorter"], "project": "flink"}
{"id": 8232, "code": "public static ResolvedSchema of(Column... columns) {\n    return ResolvedSchema.of(Arrays.asList(columns));\n}", "summary_tokens": ["shortcut", "for", "a", "resolved", "schema", "of", "only", "columns"], "project": "flink"}
{"id": 1652, "code": "public boolean containsKey(String key) {\n    synchronized (this.confData) {\n        return this.confData.containsKey(key);\n    }\n}", "summary_tokens": ["checks", "whether", "there", "is", "an", "entry", "with", "the", "specified", "key"], "project": "flink"}
{"id": 963, "code": "public String getVirtualHost() {\n    return virtualHost;\n}", "summary_tokens": ["retrieve", "the", "virtual", "host"], "project": "flink"}
{"id": 7883, "code": "public void testRunExclusively() throws InterruptedException {\n    CountDownLatch exclusiveCodeStarted = new CountDownLatch(1);\n\n    final int numMails = 10;\n\n        \n    new Thread(\n                    () ->\n                            taskMailbox.runExclusively(\n                                    () -> {\n                                        exclusiveCodeStarted.countDown();\n                                        for (int index = 0; index < numMails; index++) {\n                                            try {\n                                                taskMailbox.put(new Mail(() -> {}, 1, \"mailD\"));\n                                                Thread.sleep(1);\n                                            } catch (Exception e) {\n                                            }\n                                        }\n                                    }))\n            .start();\n\n    exclusiveCodeStarted.await();\n        \n    assertEquals(numMails, taskMailbox.close().size());\n}", "summary_tokens": ["testing", "that", "we", "cannot", "close", "while", "running", "exclusively"], "project": "flink"}
{"id": 2405, "code": "public void forceSeek(long seekPos) throws IOException {\n    fsDataInputStream.seek(seekPos);\n}", "summary_tokens": ["positions", "the", "stream", "to", "the", "given", "location"], "project": "flink"}
{"id": 7089, "code": "public DataStreamSink<T> uid(String uid) {\n    transformation.setUid(uid);\n    return this;\n}", "summary_tokens": ["sets", "an", "id", "for", "this", "operator"], "project": "flink"}
{"id": 6657, "code": "public void testCancellingDependentAndStateUpdateFails() throws Exception {\n    ResourceID producerLocation = ResourceID.generate();\n    NettyShuffleDescriptor sdd =\n            createRemoteWithIdAndLocation(\n                    new IntermediateResultPartitionID(), producerLocation);\n\n    TaskDeploymentDescriptor tdd1 = createSender(sdd);\n    TaskDeploymentDescriptor tdd2 = createReceiver(sdd);\n    ExecutionAttemptID eid1 = tdd1.getExecutionAttemptId();\n    ExecutionAttemptID eid2 = tdd2.getExecutionAttemptId();\n\n    final CompletableFuture<Void> task1RunningFuture = new CompletableFuture<>();\n    final CompletableFuture<Void> task2RunningFuture = new CompletableFuture<>();\n    final CompletableFuture<Void> task1FailedFuture = new CompletableFuture<>();\n    final CompletableFuture<Void> task2CanceledFuture = new CompletableFuture<>();\n\n    final JobMasterId jobMasterId = JobMasterId.generate();\n    TestingJobMasterGateway testingJobMasterGateway =\n            new TestingJobMasterGatewayBuilder()\n                    .setFencingTokenSupplier(() -> jobMasterId)\n                    .setUpdateTaskExecutionStateFunction(\n                            taskExecutionState -> {\n                                if (taskExecutionState != null\n                                        && taskExecutionState.getID().equals(eid1)\n                                        && taskExecutionState.getExecutionState()\n                                                == ExecutionState.RUNNING) {\n                                    return FutureUtils.completedExceptionally(\n                                            new ExecutionGraphException(\n                                                    \"The execution attempt \"\n                                                            + eid2\n                                                            + \" was not found.\"));\n                                } else {\n                                    return CompletableFuture.completedFuture(Acknowledge.get());\n                                }\n                            })\n                    .build();\n\n    try (TaskSubmissionTestEnvironment env =\n            new TaskSubmissionTestEnvironment.Builder(jobId)\n                    .setResourceID(producerLocation)\n                    .setSlotSize(2)\n                    .addTaskManagerActionListener(\n                            eid1, ExecutionState.RUNNING, task1RunningFuture)\n                    .addTaskManagerActionListener(\n                            eid2, ExecutionState.RUNNING, task2RunningFuture)\n                    .addTaskManagerActionListener(\n                            eid1, ExecutionState.FAILED, task1FailedFuture)\n                    .addTaskManagerActionListener(\n                            eid2, ExecutionState.CANCELED, task2CanceledFuture)\n                    .setJobMasterId(jobMasterId)\n                    .setJobMasterGateway(testingJobMasterGateway)\n                    .useRealNonMockShuffleEnvironment()\n                    .build()) {\n        TaskExecutorGateway tmGateway = env.getTaskExecutorGateway();\n        TaskSlotTable<Task> taskSlotTable = env.getTaskSlotTable();\n\n        taskSlotTable.allocateSlot(0, jobId, tdd1.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd1, jobMasterId, timeout).get();\n        task1RunningFuture.get();\n\n        taskSlotTable.allocateSlot(1, jobId, tdd2.getAllocationId(), Time.seconds(60));\n        tmGateway.submitTask(tdd2, jobMasterId, timeout).get();\n        task2RunningFuture.get();\n\n        task1FailedFuture.get();\n        assertSame(taskSlotTable.getTask(eid1).getExecutionState(), ExecutionState.FAILED);\n\n        tmGateway.cancelTask(eid2, timeout);\n\n        task2CanceledFuture.get();\n        assertSame(taskSlotTable.getTask(eid2).getExecutionState(), ExecutionState.CANCELED);\n    }\n}", "summary_tokens": ["this", "tests", "creates", "two", "tasks"], "project": "flink"}
{"id": 7555, "code": "public StreamRecord<T> copy(T valueCopy) {\n    StreamRecord<T> copy = new StreamRecord<>(valueCopy);\n    copy.timestamp = this.timestamp;\n    copy.hasTimestamp = this.hasTimestamp;\n    return copy;\n}", "summary_tokens": ["creates", "a", "copy", "of", "this", "stream", "record"], "project": "flink"}
{"id": 9251, "code": "public void removeAll(RowData sortKey) {\n    Collection<RowData> collection = treeMap.get(sortKey);\n    if (collection != null) {\n        currentTopNum -= collection.size();\n        treeMap.remove(sortKey);\n    }\n}", "summary_tokens": ["removes", "all", "record", "list", "from", "the", "buffer", "under", "the", "sort", "key"], "project": "flink"}
{"id": 9356, "code": "public void pointTo(int length, BinaryRowData reuse, AbstractPagedInputView headerLessView)\n        throws IOException {\n    checkArgument(headerLessView.getHeaderLength() == 0);\n    if (length < 0) {\n        throw new IOException(\n                String.format(\n                        \"Read unexpected bytes in source of positionInSegment[%d] and limitInSegment[%d]\",\n                        headerLessView.getCurrentPositionInSegment(),\n                        headerLessView.getCurrentSegmentLimit()));\n    }\n\n    int remainInSegment =\n            headerLessView.getCurrentSegmentLimit()\n                    - headerLessView.getCurrentPositionInSegment();\n    MemorySegment currSeg = headerLessView.getCurrentSegment();\n    int currPosInSeg = headerLessView.getCurrentPositionInSegment();\n    if (remainInSegment >= length) {\n            \n        reuse.pointTo(currSeg, currPosInSeg, length);\n        headerLessView.skipBytesToRead(length);\n    } else {\n        pointToMultiSegments(\n                reuse, headerLessView, length, length - remainInSegment, currSeg, currPosInSeg);\n    }\n}", "summary_tokens": ["point", "row", "to", "memory", "segments", "with", "offset", "in", "the", "abstract", "paged", "input", "view", "and", "length"], "project": "flink"}
{"id": 3983, "code": "private static Config getBasicAkkaConfig(Configuration configuration) {\n    final int akkaThroughput = configuration.getInteger(AkkaOptions.DISPATCHER_THROUGHPUT);\n    final String jvmExitOnFatalError =\n            booleanToOnOrOff(configuration.getBoolean(AkkaOptions.JVM_EXIT_ON_FATAL_ERROR));\n    final String logLifecycleEvents =\n            booleanToOnOrOff(configuration.getBoolean(AkkaOptions.LOG_LIFECYCLE_EVENTS));\n    final String supervisorStrategy = EscalatingSupervisorStrategy.class.getCanonicalName();\n\n    return new AkkaConfigBuilder()\n            .add(\"akka {\")\n            .add(\"  daemonic = off\")\n            .add(\"  loggers = [\\\"akka.event.slf4j.Slf4jLogger\\\"]\")\n            .add(\"  logging-filter = \\\"akka.event.slf4j.Slf4jLoggingFilter\\\"\")\n            .add(\"  log-config-on-start = off\")\n            .add(\"  logger-startup-timeout = 50s\")\n            .add(\"  loglevel = \" + getLogLevel())\n            .add(\"  stdout-loglevel = OFF\")\n            .add(\"  log-dead-letters = \" + logLifecycleEvents)\n            .add(\"  log-dead-letters-during-shutdown = \" + logLifecycleEvents)\n            .add(\"  jvm-exit-on-fatal-error = \" + jvmExitOnFatalError)\n            .add(\"  serialize-messages = off\")\n            .add(\"  actor {\")\n            .add(\"    guardian-supervisor-strategy = \" + supervisorStrategy)\n            .add(\"    warn-about-java-serializer-usage = off\")\n            .add(\"    allow-java-serialization = on\")\n            .add(\"    default-dispatcher {\")\n            .add(\"      throughput = \" + akkaThroughput)\n            .add(\"    }\")\n            .add(\"    supervisor-dispatcher {\")\n            .add(\"      type = Dispatcher\")\n            .add(\"      executor = \\\"thread-pool-executor\\\"\")\n            .add(\"      thread-pool-executor {\")\n            .add(\"        core-pool-size-min = 1\")\n            .add(\"        core-pool-size-max = 1\")\n            .add(\"      }\")\n            .add(\"    }\")\n            .add(\"  }\")\n            .add(\"}\")\n            .build();\n}", "summary_tokens": ["gets", "the", "basic", "akka", "config", "which", "is", "shared", "by", "remote", "and", "local", "actor", "systems"], "project": "flink"}
{"id": 8395, "code": "public Schema rowtime(Rowtime rowtime) {\n    if (lastField == null) {\n        throw new ValidationException(\"No field defined previously. Use field() before.\");\n    }\n    tableSchema.get(lastField).putAll(rowtime.toProperties());\n    lastField = null;\n    return this;\n}", "summary_tokens": ["specifies", "the", "previously", "defined", "field", "as", "an", "event", "time", "attribute"], "project": "flink"}
{"id": 5028, "code": "void storeInitialHashTable() throws IOException {\n    if (spilled) {\n        return; \n            \n    }\n    spilled = true;\n\n    for (int partIdx = 0; partIdx < initialPartitions.size(); partIdx++) {\n        final ReOpenableHashPartition<BT, PT> p =\n                (ReOpenableHashPartition<BT, PT>) initialPartitions.get(partIdx);\n        if (p.isInMemory()) { \n            this.writeBehindBuffersAvailable +=\n                    p.spillInMemoryPartition(\n                            spilledInMemoryPartitions.next(), ioManager, writeBehindBuffers);\n        }\n    }\n}", "summary_tokens": ["this", "method", "stores", "the", "initial", "hash", "table", "s", "contents", "on", "disk", "if", "hash", "join", "needs", "the", "memory", "for", "further", "partition", "processing"], "project": "flink"}
{"id": 3311, "code": "public LocalClusteringCoefficient<K, VV, EV> setIncludeZeroDegreeVertices(\n        boolean includeZeroDegreeVertices) {\n    this.includeZeroDegreeVertices.set(includeZeroDegreeVertices);\n\n    return this;\n}", "summary_tokens": ["by", "default", "the", "vertex", "set", "is", "checked", "for", "zero", "degree", "vertices"], "project": "flink"}
{"id": 2815, "code": "public TypeInformation<IN1> getInput1Type() {\n    return this.input1.getType();\n}", "summary_tokens": ["gets", "the", "type", "information", "of", "the", "data", "type", "of", "the", "first", "input", "data", "set"], "project": "flink"}
{"id": 3484, "code": "public SavepointWriter removeOperator(String uid) {\n    metadata.removeOperator(uid);\n    return this;\n}", "summary_tokens": ["drop", "an", "existing", "operator", "from", "the", "savepoint"], "project": "flink"}
{"id": 9032, "code": "public static boolean isListViewDataType(DataType dataType) {\n    return dataType.getConversionClass().equals(ListView.class)\n            && dataType instanceof FieldsDataType\n            && dataType.getChildren().size() == 1\n            && dataType.getChildren().get(0) instanceof CollectionDataType;\n}", "summary_tokens": ["check", "if", "the", "given", "data", "type", "represents", "a", "list", "view"], "project": "flink"}
{"id": 17, "code": "private List<URL> getJobJarAndDependencies(ProgramOptions programOptions)\n        throws CliArgsException {\n    String entryPointClass = programOptions.getEntryPointClassName();\n    String jarFilePath = programOptions.getJarFilePath();\n\n    try {\n        File jarFile = jarFilePath != null ? getJarFile(jarFilePath) : null;\n        return PackagedProgram.getJobJarAndDependencies(jarFile, entryPointClass);\n    } catch (FileNotFoundException | ProgramInvocationException e) {\n        throw new CliArgsException(\n                \"Could not get job jar and dependencies from JAR file: \" + e.getMessage(), e);\n    }\n}", "summary_tokens": ["get", "all", "provided", "libraries", "needed", "to", "run", "the", "program", "from", "the", "program", "options"], "project": "flink"}
{"id": 2571, "code": "public static org.apache.flink.table.data.columnar.vector.ColumnVector\n        createFlinkVectorFromConstant(LogicalType type, Object value, int batchSize) {\n    return createFlinkVector(createHiveVectorFromConstant(type, value, batchSize), type);\n}", "summary_tokens": ["create", "flink", "vector", "by", "hive", "vector", "from", "constant"], "project": "flink"}
{"id": 3453, "code": "public <K, T, OUT> DataSet<OUT> process(\n        String uid,\n        WindowReaderFunction<T, OUT, K, W> readerFunction,\n        TypeInformation<K> keyType,\n        TypeInformation<T> stateType,\n        TypeInformation<OUT> outputType)\n        throws IOException {\n\n    WindowReaderOperator<?, K, StreamRecord<T>, W, OUT> operator =\n            WindowReaderOperator.evictingWindow(\n                    new ProcessEvictingWindowReader<>(readerFunction),\n                    keyType,\n                    windowSerializer,\n                    stateType,\n                    env.getConfig());\n\n    return readWindowOperator(uid, outputType, operator);\n}", "summary_tokens": ["reads", "window", "state", "generated", "without", "any", "preaggregation", "such", "as", "windowed", "stream", "apply", "and", "windowed", "stream", "process"], "project": "flink"}
{"id": 982, "code": "public String getPartPrefix() {\n    return partPrefix;\n}", "summary_tokens": ["the", "prefix", "for", "the", "part", "name"], "project": "flink"}
{"id": 5997, "code": "public void testCacheJobExecutionResult() throws Exception {\n    dispatcher =\n            createAndStartDispatcher(\n                    heartbeatServices,\n                    haServices,\n                    new ExpectedJobIdJobManagerRunnerFactory(\n                            jobId, createdJobManagerRunnerLatch));\n\n    final DispatcherGateway dispatcherGateway =\n            dispatcher.getSelfGateway(DispatcherGateway.class);\n\n    final JobID failedJobId = new JobID();\n\n    final JobStatus expectedState = JobStatus.FAILED;\n    final ExecutionGraphInfo failedExecutionGraphInfo =\n            new ExecutionGraphInfo(\n                    new ArchivedExecutionGraphBuilder()\n                            .setJobID(failedJobId)\n                            .setState(expectedState)\n                            .setFailureCause(\n                                    new ErrorInfo(new RuntimeException(\"expected\"), 1L))\n                            .build());\n\n    dispatcher.completeJobExecution(failedExecutionGraphInfo);\n\n    assertThat(\n            dispatcherGateway.requestJobStatus(failedJobId, TIMEOUT).get(),\n            equalTo(expectedState));\n    assertThat(\n            dispatcherGateway.requestExecutionGraphInfo(failedJobId, TIMEOUT).get(),\n            equalTo(failedExecutionGraphInfo));\n}", "summary_tokens": ["test", "that", "job", "result", "is", "cached", "when", "the", "job", "finishes"], "project": "flink"}
{"id": 7480, "code": "public long maxTimestamp() {\n    return end - 1;\n}", "summary_tokens": ["gets", "the", "largest", "timestamp", "that", "still", "belongs", "to", "this", "window"], "project": "flink"}
{"id": 3975, "code": "private void handleRpcInvocation(RpcInvocation rpcInvocation) {\n    Method rpcMethod = null;\n\n    try {\n        String methodName = rpcInvocation.getMethodName();\n        Class<?>[] parameterTypes = rpcInvocation.getParameterTypes();\n\n        rpcMethod = lookupRpcMethod(methodName, parameterTypes);\n    } catch (ClassNotFoundException e) {\n        log.error(\"Could not load method arguments.\", e);\n\n        RpcConnectionException rpcException =\n                new RpcConnectionException(\"Could not load method arguments.\", e);\n        getSender().tell(new Status.Failure(rpcException), getSelf());\n    } catch (IOException e) {\n        log.error(\"Could not deserialize rpc invocation message.\", e);\n\n        RpcConnectionException rpcException =\n                new RpcConnectionException(\"Could not deserialize rpc invocation message.\", e);\n        getSender().tell(new Status.Failure(rpcException), getSelf());\n    } catch (final NoSuchMethodException e) {\n        log.error(\"Could not find rpc method for rpc invocation.\", e);\n\n        RpcConnectionException rpcException =\n                new RpcConnectionException(\"Could not find rpc method for rpc invocation.\", e);\n        getSender().tell(new Status.Failure(rpcException), getSelf());\n    }\n\n    if (rpcMethod != null) {\n        try {\n                \n            rpcMethod.setAccessible(true);\n\n            final Method capturedRpcMethod = rpcMethod;\n            if (rpcMethod.getReturnType().equals(Void.TYPE)) {\n                    \n                runWithContextClassLoader(\n                        () -> capturedRpcMethod.invoke(rpcEndpoint, rpcInvocation.getArgs()),\n                        flinkClassLoader);\n            } else {\n                final Object result;\n                try {\n                    result =\n                            runWithContextClassLoader(\n                                    () ->\n                                            capturedRpcMethod.invoke(\n                                                    rpcEndpoint, rpcInvocation.getArgs()),\n                                    flinkClassLoader);\n                } catch (InvocationTargetException e) {\n                    log.debug(\n                            \"Reporting back error thrown in remote procedure {}\", rpcMethod, e);\n\n                        \n                    getSender().tell(new Status.Failure(e.getTargetException()), getSelf());\n                    return;\n                }\n\n                final String methodName = rpcMethod.getName();\n\n                if (result instanceof CompletableFuture) {\n                    final CompletableFuture<?> responseFuture = (CompletableFuture<?>) result;\n                    sendAsyncResponse(responseFuture, methodName);\n                } else {\n                    sendSyncResponse(result, methodName);\n                }\n            }\n        } catch (Throwable e) {\n            log.error(\"Error while executing remote procedure call {}.\", rpcMethod, e);\n                \n            getSender().tell(new Status.Failure(e), getSelf());\n        }\n    }\n}", "summary_tokens": ["handle", "rpc", "invocations", "by", "looking", "up", "the", "rpc", "method", "on", "the", "rpc", "endpoint", "and", "calling", "this", "method", "with", "the", "provided", "method", "arguments"], "project": "flink"}
{"id": 6219, "code": "public void testCreateSubpartitionOnFailingPartition() throws Exception {\n    final ResultPartitionManager manager = new ResultPartitionManager();\n    final ResultPartition partition =\n            new ResultPartitionBuilder().setResultPartitionManager(manager).build();\n\n    manager.registerResultPartition(partition);\n\n    partition.fail(null);\n\n    verifyCreateSubpartitionViewThrowsException(manager, partition.getPartitionId());\n}", "summary_tokens": ["tests", "result", "partition", "manager", "create", "subpartition", "view", "result", "partition", "id", "int", "buffer", "availability", "listener", "would", "throw", "a", "partition", "not", "found", "exception", "if", "the", "registered", "partition", "was", "released", "from", "manager", "via", "result", "partition", "fail", "throwable", "before"], "project": "flink"}
{"id": 7296, "code": "public void invoke(IN tuple) {\n\n    tupleList.add(tuple);\n    if (updateCondition()) {\n        format.write(path, tupleList);\n        resetParameters();\n    }\n}", "summary_tokens": ["implementation", "of", "the", "invoke", "method", "of", "the", "sink", "function", "class"], "project": "flink"}
{"id": 2637, "code": "public AggregateOperator<T> sum(int field) {\n    return aggregate(Aggregations.SUM, field);\n}", "summary_tokens": ["syntactic", "sugar", "for", "aggregate", "sum", "field"], "project": "flink"}
{"id": 2691, "code": "public <X> DataSource<X> readFileOfPrimitives(\n        String filePath, String delimiter, Class<X> typeClass) {\n    Preconditions.checkNotNull(filePath, \"The file path may not be null.\");\n\n    return new DataSource<>(\n            this,\n            new PrimitiveInputFormat<>(new Path(filePath), delimiter, typeClass),\n            TypeExtractor.getForClass(typeClass),\n            Utils.getCallLocationName());\n}", "summary_tokens": ["creates", "a", "data", "set", "that", "represents", "the", "primitive", "type", "produced", "by", "reading", "the", "given", "file", "in", "delimited", "way"], "project": "flink"}
{"id": 2295, "code": "private static int getJvmPid() throws Exception {\n    java.lang.management.RuntimeMXBean runtime =\n            java.lang.management.ManagementFactory.getRuntimeMXBean();\n    java.lang.reflect.Field jvm = runtime.getClass().getDeclaredField(\"jvm\");\n    jvm.setAccessible(true);\n    sun.management.VMManagement mgmt = (sun.management.VMManagement) jvm.get(runtime);\n    java.lang.reflect.Method pidMethod = mgmt.getClass().getDeclaredMethod(\"getProcessId\");\n    pidMethod.setAccessible(true);\n\n    return (int) (Integer) pidMethod.invoke(mgmt);\n}", "summary_tokens": ["this", "code", "is", "copied", "from", "stack", "overflow"], "project": "flink"}
{"id": 6445, "code": "public void testSpreadOutSlotAllocationStrategy() throws Exception {\n    try (DeclarativeSlotManager slotManager =\n            createDeclarativeSlotManagerBuilder()\n                    .setSlotMatchingStrategy(LeastUtilizationSlotMatchingStrategy.INSTANCE)\n                    .buildAndStartWithDirectExec()) {\n\n        final List<CompletableFuture<JobID>> requestSlotFutures = new ArrayList<>();\n\n        final int numberTaskExecutors = 5;\n\n            \n        for (int i = 0; i < numberTaskExecutors; i++) {\n            final CompletableFuture<JobID> requestSlotFuture = new CompletableFuture<>();\n            requestSlotFutures.add(requestSlotFuture);\n            registerTaskExecutorWithTwoSlots(slotManager, requestSlotFuture);\n        }\n\n        final JobID jobId = new JobID();\n\n        final ResourceRequirements resourceRequirements =\n                createResourceRequirements(jobId, numberTaskExecutors);\n        slotManager.processResourceRequirements(resourceRequirements);\n\n            \n        final Set<JobID> jobIds =\n                new HashSet<>(\n                        FutureUtils.combineAll(requestSlotFutures).get(10L, TimeUnit.SECONDS));\n        assertThat(jobIds, hasSize(1));\n        assertThat(jobIds, containsInAnyOrder(jobId));\n    }\n}", "summary_tokens": ["the", "spread", "out", "slot", "allocation", "strategy", "should", "spread", "out", "the", "allocated", "slots", "across", "all", "available", "task", "executors"], "project": "flink"}
{"id": 1087, "code": "public long getNetRuntime(TimeUnit desiredUnit) {\n    return desiredUnit.convert(getNetRuntime(), TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["gets", "the", "net", "execution", "time", "of", "the", "job", "i"], "project": "flink"}
{"id": 1215, "code": "public void addFirstInput(Operator<IN1>... input) {\n    this.input1 = Operator.createUnionCascade(this.input1, input);\n}", "summary_tokens": ["add", "to", "the", "first", "input", "the", "union", "of", "the", "given", "operators"], "project": "flink"}
{"id": 2076, "code": "public static String getStringInMillis(final Duration duration) {\n    return duration.toMillis() + TimeUnit.MILLISECONDS.labels.get(0);\n}", "summary_tokens": ["duration", "to", "convert", "to", "string", "duration", "string", "in", "millis"], "project": "flink"}
{"id": 2077, "code": "public static String formatWithHighestUnit(Duration duration) {\n    long nanos = duration.toNanos();\n\n    List<TimeUnit> orderedUnits =\n            Arrays.asList(\n                    TimeUnit.NANOSECONDS,\n                    TimeUnit.MICROSECONDS,\n                    TimeUnit.MILLISECONDS,\n                    TimeUnit.SECONDS,\n                    TimeUnit.MINUTES,\n                    TimeUnit.HOURS,\n                    TimeUnit.DAYS);\n\n    TimeUnit highestIntegerUnit =\n            IntStream.range(0, orderedUnits.size())\n                    .sequential()\n                    .filter(\n                            idx ->\n                                    nanos % orderedUnits.get(idx).unit.getDuration().toNanos()\n                                            != 0)\n                    .boxed()\n                    .findFirst()\n                    .map(\n                            idx -> {\n                                if (idx == 0) {\n                                    return orderedUnits.get(0);\n                                } else {\n                                    return orderedUnits.get(idx - 1);\n                                }\n                            })\n                    .orElse(TimeUnit.MILLISECONDS);\n\n    return String.format(\n            \"%d %s\",\n            nanos / highestIntegerUnit.unit.getDuration().toNanos(),\n            highestIntegerUnit.getLabels().get(0));\n}", "summary_tokens": ["pretty", "prints", "the", "duration", "as", "a", "lowest", "granularity", "unit", "that", "does", "not", "lose", "precision"], "project": "flink"}
{"id": 996, "code": "public void close() throws IOException {\n\n        \n    synchronized (CLOSE_MUTEX) {\n        try {\n            this.recordWriter.close(this.context);\n        } catch (InterruptedException e) {\n            throw new IOException(\"Could not close RecordReader.\", e);\n        }\n\n        if (this.outputCommitter.needsTaskCommit(this.context)) {\n            this.outputCommitter.commitTask(this.context);\n        }\n\n        Path outputPath = new Path(this.configuration.get(\"mapred.output.dir\"));\n\n            \n        FileSystem fs = FileSystem.get(outputPath.toUri(), this.configuration);\n\n        String taskNumberStr = Integer.toString(this.taskNumber);\n        String tmpFileTemplate = \"tmp-r-00000\";\n        String tmpFile =\n                tmpFileTemplate.substring(0, 11 - taskNumberStr.length()) + taskNumberStr;\n\n        if (fs.exists(new Path(outputPath.toString() + \"/\" + tmpFile))) {\n            fs.rename(\n                    new Path(outputPath.toString() + \"/\" + tmpFile),\n                    new Path(outputPath.toString() + \"/\" + taskNumberStr));\n        }\n    }\n}", "summary_tokens": ["commit", "the", "task", "by", "moving", "the", "output", "file", "out", "from", "the", "temporary", "directory"], "project": "flink"}
{"id": 8312, "code": "public boolean anyNull() {\n        \n    if ((segments[0].getLong(0) & FIRST_BYTE_ZERO) != 0) {\n        return true;\n    }\n    for (int i = 8; i < nullBitsSizeInBytes; i += 8) {\n        if (segments[0].getLong(i) != 0) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["the", "bit", "is", "0", "when", "the", "field", "is", "null"], "project": "flink"}
{"id": 3937, "code": "public void testDeserializeListTooShort2() throws Exception {\n        \n    KvStateSerializer.deserializeList(\n            new byte[] {1, 1, 1, 1, 1, 1, 1, 1, 2, 3}, LongSerializer.INSTANCE);\n}", "summary_tokens": ["tests", "list", "deserialization", "with", "too", "few", "bytes"], "project": "flink"}
{"id": 6017, "code": "public void testIntegerTaskEvent() {\n\n    try {\n        final IntegerTaskEvent orig = new IntegerTaskEvent(11);\n        final IntegerTaskEvent copy = InstantiationUtil.createCopyWritable(orig);\n\n        assertEquals(orig.getInteger(), copy.getInteger());\n        assertEquals(orig.hashCode(), copy.hashCode());\n        assertTrue(orig.equals(copy));\n\n    } catch (IOException ioe) {\n        fail(ioe.getMessage());\n    }\n}", "summary_tokens": ["this", "test", "checks", "the", "serialization", "deserialization", "of", "integer", "task", "event", "objects"], "project": "flink"}
{"id": 8189, "code": "public void setList(List<T> list) {\n    this.list = list;\n}", "summary_tokens": ["replaces", "the", "entire", "view", "s", "content", "with", "the", "content", "of", "the", "given", "list"], "project": "flink"}
{"id": 3451, "code": "public <K, T, OUT> DataSet<OUT> reduce(\n        String uid,\n        ReduceFunction<T> function,\n        WindowReaderFunction<T, OUT, K, W> readerFunction,\n        TypeInformation<K> keyType,\n        TypeInformation<T> reduceType,\n        TypeInformation<OUT> outputType)\n        throws IOException {\n\n    WindowReaderOperator<?, K, StreamRecord<T>, W, OUT> operator =\n            WindowReaderOperator.evictingWindow(\n                    new ReduceEvictingWindowReaderFunction<>(readerFunction, function),\n                    keyType,\n                    windowSerializer,\n                    reduceType,\n                    env.getConfig());\n\n    return readWindowOperator(uid, outputType, operator);\n}", "summary_tokens": ["reads", "window", "state", "generated", "using", "a", "reduce", "function"], "project": "flink"}
{"id": 3808, "code": "Map<String, String> constructEnvironmentVariables(String baseDirectory)\n        throws IOException, IllegalArgumentException {\n    Map<String, String> env = new HashMap<>(this.systemEnv);\n\n    constructFilesDirectory(env, baseDirectory);\n\n    constructArchivesDirectory(env, baseDirectory);\n\n    constructRequirementsDirectory(env, baseDirectory);\n\n        \n    env.put(\"BOOT_LOG_DIR\", baseDirectory);\n\n        \n        \n        \n        \n        \n        \n    env.put(PYFLINK_GATEWAY_DISABLED, \"true\");\n\n        \n    env.put(\"python\", dependencyInfo.getPythonExec());\n    LOG.info(\"Python interpreter path: {}\", dependencyInfo.getPythonExec());\n    return env;\n}", "summary_tokens": ["constructs", "the", "environment", "variables", "which", "is", "used", "to", "launch", "the", "python", "udf", "worker"], "project": "flink"}
{"id": 6636, "code": "public void testRandomModificationsAndCopyOnWriteIsolation() throws Exception {\n    final CopyOnWriteStateMap<Integer, Integer, ArrayList<Integer>> stateMap =\n            new CopyOnWriteStateMap<>(new ArrayListSerializer<>(IntSerializer.INSTANCE));\n\n    final HashMap<Tuple2<Integer, Integer>, ArrayList<Integer>> referenceMap = new HashMap<>();\n\n    final Random random = new Random(42);\n\n        \n    CopyOnWriteStateMap.StateMapEntry<Integer, Integer, ArrayList<Integer>>[] snapshot = null;\n    int snapshotSize = 0;\n\n        \n    Tuple3<Integer, Integer, ArrayList<Integer>>[] reference = null;\n\n    int val = 0;\n\n    int snapshotCounter = 0;\n    int referencedSnapshotId = 0;\n\n    final StateTransformationFunction<ArrayList<Integer>, Integer> transformationFunction =\n            (previousState, value) -> {\n                if (previousState == null) {\n                    previousState = new ArrayList<>();\n                }\n                previousState.add(value);\n                    \n                return previousState;\n            };\n\n    StateIncrementalVisitor<Integer, Integer, ArrayList<Integer>> updatingIterator =\n            stateMap.getStateIncrementalVisitor(5);\n\n        \n    for (int i = 0; i < 10_000_000; ++i) {\n\n        int key = random.nextInt(20);\n        int namespace = random.nextInt(4);\n        Tuple2<Integer, Integer> compositeKey = new Tuple2<>(key, namespace);\n\n        int op = random.nextInt(10);\n\n        ArrayList<Integer> state = null;\n        ArrayList<Integer> referenceState = null;\n\n        switch (op) {\n            case 0:\n            case 1:\n                {\n                    state = stateMap.get(key, namespace);\n                    referenceState = referenceMap.get(compositeKey);\n                    if (null == state) {\n                        state = new ArrayList<>();\n                        stateMap.put(key, namespace, state);\n                        referenceState = new ArrayList<>();\n                        referenceMap.put(compositeKey, referenceState);\n                    }\n                    break;\n                }\n            case 2:\n                {\n                    stateMap.put(key, namespace, new ArrayList<>());\n                    referenceMap.put(compositeKey, new ArrayList<>());\n                    break;\n                }\n            case 3:\n                {\n                    state = stateMap.putAndGetOld(key, namespace, new ArrayList<>());\n                    referenceState = referenceMap.put(compositeKey, new ArrayList<>());\n                    break;\n                }\n            case 4:\n                {\n                    stateMap.remove(key, namespace);\n                    referenceMap.remove(compositeKey);\n                    break;\n                }\n            case 5:\n                {\n                    state = stateMap.removeAndGetOld(key, namespace);\n                    referenceState = referenceMap.remove(compositeKey);\n                    break;\n                }\n            case 6:\n                {\n                    final int updateValue = random.nextInt(1000);\n                    stateMap.transform(key, namespace, updateValue, transformationFunction);\n                    referenceMap.put(\n                            compositeKey,\n                            transformationFunction.apply(\n                                    referenceMap.remove(compositeKey), updateValue));\n                    break;\n                }\n            case 7:\n            case 8:\n            case 9:\n                if (!updatingIterator.hasNext()) {\n                    updatingIterator = stateMap.getStateIncrementalVisitor(5);\n                    if (!updatingIterator.hasNext()) {\n                        break;\n                    }\n                }\n                testStateIteratorWithUpdate(\n                        updatingIterator, stateMap, referenceMap, op == 8, op == 9);\n                break;\n            default:\n                {\n                    Assert.fail(\"Unknown op-code \" + op);\n                }\n        }\n\n        Assert.assertEquals(referenceMap.size(), stateMap.size());\n\n        if (state != null) {\n            Assert.assertNotNull(referenceState);\n                \n            if (random.nextBoolean() && !state.isEmpty()) {\n                state.remove(state.size() - 1);\n                referenceState.remove(referenceState.size() - 1);\n            } else {\n                state.add(val);\n                referenceState.add(val);\n                ++val;\n            }\n        }\n\n        Assert.assertEquals(referenceState, state);\n\n            \n        if (i > 0 && i % 500 == 0) {\n\n            if (snapshot != null) {\n                    \n                deepCheck(reference, convert(snapshot, snapshotSize));\n\n                if (i % 1_000 == 0) {\n                        \n                    ++snapshotCounter;\n                    stateMap.snapshotMapArrays();\n                    stateMap.releaseSnapshot(snapshotCounter);\n                }\n\n                    \n                if (i % 5_000 == 0) {\n                    snapshot = null;\n                    reference = null;\n                    snapshotSize = 0;\n                    stateMap.releaseSnapshot(referencedSnapshotId);\n                }\n\n            } else {\n                    \n                ++snapshotCounter;\n                referencedSnapshotId = snapshotCounter;\n                snapshot = stateMap.snapshotMapArrays();\n                snapshotSize = stateMap.size();\n                reference = manualDeepDump(referenceMap);\n            }\n        }\n    }\n}", "summary_tokens": ["this", "test", "does", "some", "random", "modifications", "to", "a", "state", "map", "and", "a", "reference", "hash", "map"], "project": "flink"}
{"id": 9328, "code": "public boolean contains(W window, RowData key) throws Exception {\n    windowState.setCurrentNamespace(window);\n    return windowState.contains(key);\n}", "summary_tokens": ["returns", "whether", "there", "exists", "the", "given", "mapping"], "project": "flink"}
{"id": 4232, "code": "private boolean tryRemove(long checkpointId) throws Exception {\n    return checkpointStateHandleStore.releaseAndTryRemove(\n            completedCheckpointStoreUtil.checkpointIDToName(checkpointId));\n}", "summary_tokens": ["tries", "to", "remove", "the", "checkpoint", "identified", "by", "the", "given", "checkpoint", "id"], "project": "flink"}
{"id": 7756, "code": "public void testLatencyMarkEmissionDisabled() throws Exception {\n    testLatencyMarkEmission(\n            0,\n            (operator, timeProvider) ->\n                    setupSourceOperator(\n                            operator,\n                            new ExecutionConfig(),\n                            MockEnvironment.builder().build(),\n                            timeProvider));\n}", "summary_tokens": ["verifies", "that", "by", "default", "no", "latency", "metrics", "are", "emitted"], "project": "flink"}
{"id": 4285, "code": "public long getCount() {\n    return count;\n}", "summary_tokens": ["returns", "the", "count", "of", "all", "seen", "values"], "project": "flink"}
{"id": 3151, "code": "protected String regexSubstring(String input) {\n        \n        \n        \n    return \"(?s).*\" + Pattern.quote(input) + \".*\";\n}", "summary_tokens": ["generate", "a", "regular", "expression", "string", "by", "quoting", "the", "input", "string", "and", "adding", "wildcard", "matchers", "to", "the", "beginning", "and", "end"], "project": "flink"}
{"id": 214, "code": "public void runElasticsearchSinkCborTest() throws Exception {\n    runElasticSearchSinkTest(\n            \"elasticsearch-sink-test-cbor-index\", SourceSinkDataTestKit::getCborSinkFunction);\n}", "summary_tokens": ["tests", "that", "the", "elasticsearch", "sink", "works", "properly", "with", "cbor"], "project": "flink"}
{"id": 6076, "code": "public void testIndividualVertices() {\n    TestingSchedulingTopology topology = new TestingSchedulingTopology();\n\n    TestingSchedulingExecutionVertex v1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v2 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex v3 = topology.newExecutionVertex();\n\n    Map<ExecutionVertexID, Set<SchedulingExecutionVertex>> pipelinedRegionByVertex =\n            computePipelinedRegionByVertex(topology);\n\n    Set<SchedulingExecutionVertex> r1 = pipelinedRegionByVertex.get(v1.getId());\n    Set<SchedulingExecutionVertex> r2 = pipelinedRegionByVertex.get(v2.getId());\n    Set<SchedulingExecutionVertex> r3 = pipelinedRegionByVertex.get(v3.getId());\n\n    assertDistinctRegions(r1, r2, r3);\n}", "summary_tokens": ["tests", "that", "validates", "that", "a", "graph", "with", "single", "unconnected", "vertices", "works", "correctly"], "project": "flink"}
{"id": 4973, "code": "private int getMinPartition() {\n    int minPartition = Integer.MAX_VALUE;\n    for (InMemoryPartition<T> p1 : this.partitions) {\n        if (p1.getBlockCount() < minPartition) {\n            minPartition = p1.getBlockCount();\n        }\n    }\n    return minPartition;\n}", "summary_tokens": ["number", "of", "memory", "segments", "in", "the", "smallest", "partition"], "project": "flink"}
{"id": 4802, "code": "public Configuration getJobConfiguration() {\n    return this.environment.getJobConfiguration();\n}", "summary_tokens": ["returns", "the", "job", "configuration", "object", "which", "was", "attached", "to", "the", "original", "org"], "project": "flink"}
{"id": 877, "code": "public void waitUntilAwaitTermination(long timeout, TimeUnit timeUnit)\n        throws InterruptedException, TimeoutException {\n    awaitTerminationWaiter.await(timeout, timeUnit);\n}", "summary_tokens": ["block", "until", "await", "termination", "has", "been", "called", "on", "this", "class"], "project": "flink"}
{"id": 913, "code": "public boolean noMoreNewPartitionSplits() {\n    return !sourceConfiguration.enablePartitionDiscovery()\n            && initialized\n            && pendingPartitionSplits.isEmpty();\n}", "summary_tokens": ["it", "would", "return", "true", "only", "if", "periodically", "partition", "discovery", "is", "disabled", "the", "initializing", "partition", "discovery", "has", "finished", "and", "there", "is", "no", "pending", "splits", "for", "assignment"], "project": "flink"}
{"id": 8645, "code": "public static Class<?> toInternalConversionClass(LogicalType type) {\n        \n    switch (type.getTypeRoot()) {\n        case CHAR:\n        case VARCHAR:\n            return StringData.class;\n        case BOOLEAN:\n            return Boolean.class;\n        case BINARY:\n        case VARBINARY:\n            return byte[].class;\n        case DECIMAL:\n            return DecimalData.class;\n        case TINYINT:\n            return Byte.class;\n        case SMALLINT:\n            return Short.class;\n        case INTEGER:\n        case DATE:\n        case TIME_WITHOUT_TIME_ZONE:\n        case INTERVAL_YEAR_MONTH:\n            return Integer.class;\n        case BIGINT:\n        case INTERVAL_DAY_TIME:\n            return Long.class;\n        case FLOAT:\n            return Float.class;\n        case DOUBLE:\n            return Double.class;\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            return TimestampData.class;\n        case TIMESTAMP_WITH_TIME_ZONE:\n            throw new UnsupportedOperationException(\"Unsupported type: \" + type);\n        case ARRAY:\n            return ArrayData.class;\n        case MULTISET:\n        case MAP:\n            return MapData.class;\n        case ROW:\n        case STRUCTURED_TYPE:\n            return RowData.class;\n        case DISTINCT_TYPE:\n            return toInternalConversionClass(((DistinctType) type).getSourceType());\n        case RAW:\n            return RawValueData.class;\n        case NULL:\n            return Object.class;\n        case SYMBOL:\n        case UNRESOLVED:\n        default:\n            throw new IllegalArgumentException(\"Illegal type: \" + type);\n    }\n}", "summary_tokens": ["returns", "the", "conversion", "class", "for", "the", "given", "logical", "type", "that", "is", "used", "by", "the", "table", "runtime", "as", "internal", "data", "structure"], "project": "flink"}
{"id": 6644, "code": "public static <T> Matcher<TtlValue<T>> ttlValue(\n        Matcher<T> valueMatcher, Matcher<Long> timestampMatcher) {\n    return new IsTtlValue<>(valueMatcher, timestampMatcher);\n}", "summary_tokens": ["creates", "a", "matcher", "that", "matches", "when", "the", "given", "value", "and", "timestamp", "matchers", "match", "the", "value", "and", "timestamp", "in", "a", "ttl", "value"], "project": "flink"}
{"id": 7778, "code": "public void testTimeEvictorNoTimestamp() throws Exception {\n    AtomicInteger closeCalled = new AtomicInteger(0);\n    final int triggerCount = 2;\n    final boolean evictAfter = true;\n\n    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n    TypeSerializer<StreamRecord<Tuple2<String, Integer>>> streamRecordSerializer =\n            (TypeSerializer<StreamRecord<Tuple2<String, Integer>>>)\n                    new StreamElementSerializer(\n                            STRING_INT_TUPLE.createSerializer(new ExecutionConfig()));\n\n    ListStateDescriptor<StreamRecord<Tuple2<String, Integer>>> stateDesc =\n            new ListStateDescriptor<>(\"window-contents\", streamRecordSerializer);\n\n    EvictingWindowOperator<\n                    String, Tuple2<String, Integer>, Tuple2<String, Integer>, GlobalWindow>\n            operator =\n                    new EvictingWindowOperator<>(\n                            GlobalWindows.create(),\n                            new GlobalWindow.Serializer(),\n                            new TupleKeySelector(),\n                            BasicTypeInfo.STRING_TYPE_INFO.createSerializer(\n                                    new ExecutionConfig()),\n                            stateDesc,\n                            new InternalIterableWindowFunction<>(\n                                    new RichSumReducer<GlobalWindow>(closeCalled)),\n                            CountTrigger.of(triggerCount),\n                            TimeEvictor.of(Time.seconds(2), evictAfter),\n                            0,\n                            null );\n\n    OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, Tuple2<String, Integer>>\n            testHarness =\n                    new KeyedOneInputStreamOperatorTestHarness<>(\n                            operator, new TupleKeySelector(), BasicTypeInfo.STRING_TYPE_INFO);\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    testHarness.open();\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1)));\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n\n    expectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 2), Long.MAX_VALUE));\n    expectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 2), Long.MAX_VALUE));\n    expectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 4), Long.MAX_VALUE));\n\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new ResultSortComparator());\n\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key1\", 1)));\n    testHarness.processElement(new StreamRecord<>(new Tuple2<>(\"key2\", 1)));\n\n    expectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key1\", 4), Long.MAX_VALUE));\n    expectedOutput.add(new StreamRecord<>(new Tuple2<>(\"key2\", 6), Long.MAX_VALUE));\n\n    TestHarnessUtil.assertOutputEqualsSorted(\n            \"Output was not correct.\",\n            expectedOutput,\n            testHarness.getOutput(),\n            new ResultSortComparator());\n\n    testHarness.close();\n\n    Assert.assertEquals(\"Close was not called.\", 1, closeCalled.get());\n}", "summary_tokens": ["tests", "time", "evictor", "if", "no", "timestamp", "information", "in", "the", "stream", "record"], "project": "flink"}
{"id": 2864, "code": "public boolean getBoolean(String key, boolean defaultValue) {\n    addToDefaults(key, Boolean.toString(defaultValue));\n    String value = get(key);\n    if (value == null) {\n        return defaultValue;\n    } else {\n        return Boolean.valueOf(value);\n    }\n}", "summary_tokens": ["returns", "the", "boolean", "value", "for", "the", "given", "key"], "project": "flink"}
{"id": 2513, "code": "public void testSchemaToDataTypeToSchemaNullable() {\n    String schemaStr =\n            \"{\\n\"\n                    + \"  \\\"type\\\" : \\\"record\\\",\\n\"\n                    + \"  \\\"name\\\" : \\\"record\\\",\\n\"\n                    + \"  \\\"fields\\\" : [ {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_null\\\",\\n\"\n                    + \"    \\\"type\\\" : \\\"null\\\",\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_boolean\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", \\\"boolean\\\" ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_int\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", \\\"int\\\" ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_bigint\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", \\\"long\\\" ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_float\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", \\\"float\\\" ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_double\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", \\\"double\\\" ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_string\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", \\\"string\\\" ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_varbinary\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", \\\"bytes\\\" ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_timestamp\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"      \\\"type\\\" : \\\"long\\\",\\n\"\n                    + \"      \\\"logicalType\\\" : \\\"timestamp-millis\\\"\\n\"\n                    + \"    } ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_date\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"      \\\"type\\\" : \\\"int\\\",\\n\"\n                    + \"      \\\"logicalType\\\" : \\\"date\\\"\\n\"\n                    + \"    } ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_time\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"      \\\"type\\\" : \\\"int\\\",\\n\"\n                    + \"      \\\"logicalType\\\" : \\\"time-millis\\\"\\n\"\n                    + \"    } ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_decimal\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"      \\\"type\\\" : \\\"bytes\\\",\\n\"\n                    + \"      \\\"logicalType\\\" : \\\"decimal\\\",\\n\"\n                    + \"      \\\"precision\\\" : 10,\\n\"\n                    + \"      \\\"scale\\\" : 0\\n\"\n                    + \"    } ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_row\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"      \\\"type\\\" : \\\"record\\\",\\n\"\n                    + \"      \\\"name\\\" : \\\"record_f_row\\\",\\n\"\n                    + \"      \\\"fields\\\" : [ {\\n\"\n                    + \"        \\\"name\\\" : \\\"f0\\\",\\n\"\n                    + \"        \\\"type\\\" : [ \\\"null\\\", \\\"int\\\" ],\\n\"\n                    + \"        \\\"default\\\" : null\\n\"\n                    + \"      }, {\\n\"\n                    + \"        \\\"name\\\" : \\\"f1\\\",\\n\"\n                    + \"        \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"          \\\"type\\\" : \\\"long\\\",\\n\"\n                    + \"          \\\"logicalType\\\" : \\\"timestamp-millis\\\"\\n\"\n                    + \"        } ],\\n\"\n                    + \"        \\\"default\\\" : null\\n\"\n                    + \"      } ]\\n\"\n                    + \"    } ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_map\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"      \\\"type\\\" : \\\"map\\\",\\n\"\n                    + \"      \\\"values\\\" : [ \\\"null\\\", \\\"int\\\" ]\\n\"\n                    + \"    } ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  }, {\\n\"\n                    + \"    \\\"name\\\" : \\\"f_array\\\",\\n\"\n                    + \"    \\\"type\\\" : [ \\\"null\\\", {\\n\"\n                    + \"      \\\"type\\\" : \\\"array\\\",\\n\"\n                    + \"      \\\"items\\\" : [ \\\"null\\\", \\\"int\\\" ]\\n\"\n                    + \"    } ],\\n\"\n                    + \"    \\\"default\\\" : null\\n\"\n                    + \"  } ]\\n\"\n                    + \"}\";\n    DataType dataType = AvroSchemaConverter.convertToDataType(schemaStr);\n    Schema schema = AvroSchemaConverter.convertToSchema(dataType.getLogicalType());\n    assertEquals(new Schema.Parser().parse(schemaStr), schema);\n}", "summary_tokens": ["test", "convert", "nullable", "avro", "schema", "to", "data", "type", "then", "converts", "back"], "project": "flink"}
{"id": 2013, "code": "public static URL getCorrectHostnamePort(String hostPort) {\n    return validateHostPortString(hostPort);\n}", "summary_tokens": ["converts", "a", "string", "of", "the", "form", "host", "port", "into", "an", "url"], "project": "flink"}
{"id": 2820, "code": "public void setSemanticProperties(DualInputSemanticProperties properties) {\n    this.udfSemantics = properties;\n    this.analyzedUdfSemantics = false;\n}", "summary_tokens": ["sets", "the", "semantic", "properties", "for", "the", "user", "defined", "function", "udf"], "project": "flink"}
{"id": 6986, "code": "private void restoreInstanceDirectoryFromPath(Path source) throws IOException {\n    final Path instanceRocksDBDirectory = Paths.get(dbPath);\n    final Path[] files = FileUtils.listDirectory(source);\n\n    if (!new File(dbPath).mkdirs()) {\n        String errMsg = \"Could not create RocksDB data directory: \" + dbPath;\n        logger.error(errMsg);\n        throw new IOException(errMsg);\n    }\n\n    for (Path file : files) {\n        final String fileName = file.getFileName().toString();\n        final Path targetFile = instanceRocksDBDirectory.resolve(fileName);\n        if (fileName.endsWith(SST_FILE_SUFFIX)) {\n            try {\n                    \n                Files.createLink(targetFile, file);\n                continue;\n            } catch (IOException ioe) {\n                final String logMessage =\n                        String.format(\n                                \"Could not hard link sst file %s. Trying to copy it over. This might \"\n                                        + \"increase the recovery time. In order to avoid this, configure \"\n                                        + \"RocksDB's working directory and the local state directory to be on the same volume.\",\n                                fileName);\n                if (logger.isDebugEnabled()) {\n                    logger.debug(logMessage, ioe);\n                } else {\n                    logger.info(logMessage);\n                }\n            }\n        }\n\n            \n        Files.copy(file, targetFile, StandardCopyOption.REPLACE_EXISTING);\n    }\n}", "summary_tokens": ["this", "recreates", "the", "new", "working", "directory", "of", "the", "recovered", "rocks", "db", "instance", "and", "links", "copies", "the", "contents", "from", "a", "local", "state"], "project": "flink"}
{"id": 1720, "code": "public int getMaxNumOpenStreamsTotal() {\n    return maxNumOpenStreamsTotal;\n}", "summary_tokens": ["gets", "the", "maximum", "number", "of", "concurrently", "open", "streams", "input", "output"], "project": "flink"}
{"id": 7994, "code": "public static SessionWithGap withGap(Expression gap) {\n    return new SessionWithGap(gap);\n}", "summary_tokens": ["creates", "a", "session", "window"], "project": "flink"}
{"id": 4567, "code": "public MemorySegment getMemorySegment() {\n    return getBuffer().getMemorySegment();\n}", "summary_tokens": ["returns", "the", "underlying", "memory", "segment"], "project": "flink"}
{"id": 4324, "code": "public long getNetRuntime(TimeUnit desiredUnit) {\n    return desiredUnit.convert(getNetRuntime(), TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["gets", "the", "net", "execution", "time", "of", "the", "job", "i"], "project": "flink"}
{"id": 113, "code": "public ConcreteBuilderT setMaxBatchSize(int maxBatchSize) {\n    this.maxBatchSize = maxBatchSize;\n    return (ConcreteBuilderT) this;\n}", "summary_tokens": ["max", "batch", "size", "maximum", "number", "of", "elements", "that", "may", "be", "passed", "in", "a", "list", "to", "be", "written", "downstream"], "project": "flink"}
{"id": 5052, "code": "public void close() throws IOException {\n\n        \n        \n    Throwable ex = null;\n\n    synchronized (this) {\n        if (closed) {\n            return;\n        }\n        closed = true;\n\n            \n        if (recordsOutFile != null) {\n            try {\n                recordsOutFile.close();\n                recordsOutFile = null;\n            } catch (Throwable t) {\n                LOG.error(\"Cannot close the large records spill file.\", t);\n                ex = t;\n            }\n        }\n        if (keysOutFile != null) {\n            try {\n                keysOutFile.close();\n                keysOutFile = null;\n            } catch (Throwable t) {\n                LOG.error(\"Cannot close the large records key spill file.\", t);\n                ex = ex == null ? t : ex;\n            }\n        }\n\n            \n        if (recordsReader != null) {\n            try {\n                recordsReader.close();\n                recordsReader = null;\n            } catch (Throwable t) {\n                LOG.error(\"Cannot close the large records reader.\", t);\n                ex = ex == null ? t : ex;\n            }\n        }\n        if (keysReader != null) {\n            try {\n                keysReader.close();\n                keysReader = null;\n            } catch (Throwable t) {\n                LOG.error(\"Cannot close the large records key reader.\", t);\n                ex = ex == null ? t : ex;\n            }\n        }\n\n            \n        if (recordsChannel != null) {\n            try {\n                ioManager.deleteChannel(recordsChannel);\n                recordsChannel = null;\n            } catch (Throwable t) {\n                LOG.error(\"Cannot delete the large records spill file.\", t);\n                ex = ex == null ? t : ex;\n            }\n        }\n        if (keysChannel != null) {\n            try {\n                ioManager.deleteChannel(keysChannel);\n                keysChannel = null;\n            } catch (Throwable t) {\n                LOG.error(\"Cannot delete the large records key spill file.\", t);\n                ex = ex == null ? t : ex;\n            }\n        }\n\n            \n        if (keySorter != null) {\n            try {\n                keySorter.close();\n                keySorter = null;\n            } catch (Throwable t) {\n                LOG.error(\n                        \"Cannot properly dispose the key sorter and clean up its temporary files.\",\n                        t);\n                ex = ex == null ? t : ex;\n            }\n        }\n\n        memManager.release(memory);\n\n        recordCounter = 0;\n    }\n\n        \n    if (ex != null) {\n        throw new IOException(\n                \"An error occurred cleaning up spill files in the large record handler.\", ex);\n    }\n}", "summary_tokens": ["closes", "all", "structures", "and", "deletes", "all", "temporary", "files"], "project": "flink"}
{"id": 7178, "code": "public boolean isCheckpointingEnabled() {\n    return checkpointInterval > 0;\n}", "summary_tokens": ["checks", "whether", "checkpointing", "is", "enabled"], "project": "flink"}
{"id": 2558, "code": "public void testNumberOfFieldNamesAndTypesMismatch() {\n    try {\n        new JsonRowDeserializationSchema.Builder(\n                        Types.ROW_NAMED(new String[] {\"one\", \"two\", \"three\"}, Types.LONG))\n                .build();\n        Assert.fail(\"Did not throw expected Exception\");\n    } catch (IllegalArgumentException ignored) {\n            \n    }\n}", "summary_tokens": ["tests", "that", "number", "of", "field", "names", "and", "types", "has", "to", "match"], "project": "flink"}
{"id": 8363, "code": "public BinaryStringData trim() {\n    ensureMaterialized();\n    if (inFirstSegment()) {\n        int s = 0;\n        int e = this.binarySection.sizeInBytes - 1;\n            \n        while (s < this.binarySection.sizeInBytes && getByteOneSegment(s) == 0x20) {\n            s++;\n        }\n            \n        while (e >= s && getByteOneSegment(e) == 0x20) {\n            e--;\n        }\n        if (s > e) {\n                \n            return EMPTY_UTF8;\n        } else {\n            return copyBinaryStringInOneSeg(s, e - s + 1);\n        }\n    } else {\n        return trimMultiSegs();\n    }\n}", "summary_tokens": ["returns", "a", "string", "whose", "value", "is", "this", "string", "with", "any", "leading", "and", "trailing", "whitespace", "removed"], "project": "flink"}
{"id": 3791, "code": "static List<String> constructPythonCommands(final PythonDriverOptions pythonDriverOptions) {\n    final List<String> commands = new ArrayList<>();\n    if (pythonDriverOptions.getEntryPointScript().isPresent()) {\n        commands.add(pythonDriverOptions.getEntryPointScript().get());\n    } else {\n        commands.add(\"-m\");\n        commands.add(pythonDriverOptions.getEntryPointModule());\n    }\n    commands.addAll(pythonDriverOptions.getProgramArgs());\n    return commands;\n}", "summary_tokens": ["constructs", "the", "python", "commands", "which", "will", "be", "executed", "in", "python", "process"], "project": "flink"}
{"id": 873, "code": "public void testBackpressure() throws Throwable {\n    final Deadline deadline = Deadline.fromNow(Duration.ofSeconds(10));\n\n    final DummyFlinkKinesisProducer<String> producer =\n            new DummyFlinkKinesisProducer<>(new SimpleStringSchema());\n    producer.setQueueLimit(1);\n\n    OneInputStreamOperatorTestHarness<String, Object> testHarness =\n            new OneInputStreamOperatorTestHarness<>(new StreamSink<>(producer));\n\n    testHarness.open();\n\n    UserRecordResult result = mock(UserRecordResult.class);\n    when(result.isSuccessful()).thenReturn(true);\n\n    CheckedThread msg1 =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                    testHarness.processElement(new StreamRecord<>(\"msg-1\"));\n                }\n            };\n    msg1.start();\n    msg1.trySync(deadline.timeLeftIfAny().toMillis());\n    assertFalse(\"Flush triggered before reaching queue limit\", msg1.isAlive());\n\n        \n    producer.getPendingRecordFutures().get(0).set(result);\n\n    CheckedThread msg2 =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                    testHarness.processElement(new StreamRecord<>(\"msg-2\"));\n                }\n            };\n    msg2.start();\n    msg2.trySync(deadline.timeLeftIfAny().toMillis());\n    assertFalse(\"Flush triggered before reaching queue limit\", msg2.isAlive());\n\n    CheckedThread moreElementsThread =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                        \n                    testHarness.processElement(new StreamRecord<>(\"msg-3\"));\n                        \n                    testHarness.processElement(new StreamRecord<>(\"msg-4\"));\n                }\n            };\n    moreElementsThread.start();\n\n    assertTrue(\"Producer should still block, but doesn't\", moreElementsThread.isAlive());\n\n        \n    while (producer.getPendingRecordFutures().size() < 2) {\n        Thread.sleep(50);\n    }\n    producer.getPendingRecordFutures().get(1).set(result);\n\n    assertTrue(\"Producer should still block, but doesn't\", moreElementsThread.isAlive());\n\n        \n    while (producer.getPendingRecordFutures().size() < 3) {\n        Thread.sleep(50);\n    }\n    producer.getPendingRecordFutures().get(2).set(result);\n\n    moreElementsThread.trySync(deadline.timeLeftIfAny().toMillis());\n\n    assertFalse(\n            \"Prodcuer still blocks although the queue is flushed\",\n            moreElementsThread.isAlive());\n\n    producer.getPendingRecordFutures().get(3).set(result);\n\n    testHarness.close();\n}", "summary_tokens": ["test", "ensuring", "that", "the", "producer", "blocks", "if", "the", "queue", "limit", "is", "exceeded", "until", "the", "queue", "length", "drops", "below", "the", "limit", "we", "set", "a", "timeout", "because", "the", "test", "will", "not", "finish", "if", "the", "logic", "is", "broken"], "project": "flink"}
{"id": 244, "code": "public long getOffset() {\n    return offset;\n}", "summary_tokens": ["gets", "the", "offset", "that", "the", "reader", "will", "seek", "to", "when", "restored", "from", "this", "checkpoint"], "project": "flink"}
{"id": 5568, "code": "public boolean markActive() {\n    if (TaskSlotState.ALLOCATED == state || TaskSlotState.ACTIVE == state) {\n        state = TaskSlotState.ACTIVE;\n\n        return true;\n    } else {\n        return false;\n    }\n}", "summary_tokens": ["mark", "this", "slot", "as", "active"], "project": "flink"}
{"id": 2816, "code": "public TypeInformation<IN2> getInput2Type() {\n    return this.input2.getType();\n}", "summary_tokens": ["gets", "the", "type", "information", "of", "the", "data", "type", "of", "the", "second", "input", "data", "set"], "project": "flink"}
{"id": 3434, "code": "public static List<Vertex<Long, Long>> getLongLongVertices() {\n    List<Vertex<Long, Long>> vertices = new ArrayList<>();\n    vertices.add(new Vertex<>(1L, 1L));\n    vertices.add(new Vertex<>(2L, 2L));\n    vertices.add(new Vertex<>(3L, 3L));\n    vertices.add(new Vertex<>(4L, 4L));\n    vertices.add(new Vertex<>(5L, 5L));\n\n    return vertices;\n}", "summary_tokens": ["function", "that", "produces", "an", "array", "list", "of", "vertices"], "project": "flink"}
{"id": 629, "code": "public void invoke(Watermark watermark) throws FlinkKafkaException {\n    checkErroneous();\n    KafkaTransactionState transaction = currentTransaction();\n\n    int[] partitions = getPartitions(transaction);\n    int subtask = getRuntimeContext().getIndexOfThisSubtask();\n\n        \n    long timestamp = watermark.getTimestamp();\n    for (int partition : partitions) {\n        ProducerRecord<byte[], byte[]> record =\n                new ProducerRecord<>(\n                        defaultTopicId,\n                        partition,\n                        timestamp,\n                        null,\n                        kafkaSerializer.serializeWatermark(watermark, subtask));\n\n        pendingRecords.incrementAndGet();\n        transaction.getProducer().send(record, callback);\n    }\n}", "summary_tokens": ["this", "is", "the", "function", "invoked", "to", "handle", "each", "watermark"], "project": "flink"}
{"id": 7499, "code": "public void setJobId(String id) throws Exception {\n    this.jobId = id;\n}", "summary_tokens": ["internally", "used", "to", "set", "the", "job", "id", "after", "instantiation"], "project": "flink"}
{"id": 455, "code": "public Optional<Range> timestampPrecisionRange() {\n    return Optional.empty();\n}", "summary_tokens": ["the", "inclusive", "range", "min", "max", "of", "supported", "precisions", "for", "timestamp", "type", "columns"], "project": "flink"}
{"id": 2657, "code": "public <R> CrossOperator.DefaultCross<T, R> cross(DataSet<R> other) {\n    return new CrossOperator.DefaultCross<>(\n            this, other, CrossHint.OPTIMIZER_CHOOSES, Utils.getCallLocationName());\n}", "summary_tokens": ["initiates", "a", "cross", "transformation"], "project": "flink"}
{"id": 6755, "code": "private void releaseAllResource() {\n    long node = levelIndexHeader.getNextNode(0);\n    while (node != NIL_NODE) {\n        long nextNode = helpGetNextNode(node, 0);\n        long valuePointer = SkipListUtils.helpGetValuePointer(node, spaceAllocator);\n        spaceAllocator.free(node);\n        SkipListUtils.removeAllValues(valuePointer, spaceAllocator);\n        node = nextNode;\n    }\n    totalSize = 0;\n    logicallyRemovedNodes.clear();\n}", "summary_tokens": ["release", "all", "resource", "used", "by", "the", "map"], "project": "flink"}
{"id": 5122, "code": "public void unregisterAll() {\n    for (KvStateInfo kvState : registeredKvStates) {\n        registry.unregisterKvState(\n                jobId,\n                jobVertexId,\n                kvState.keyGroupRange,\n                kvState.registrationName,\n                kvState.kvStateId);\n    }\n}", "summary_tokens": ["unregisters", "all", "registered", "kv", "state", "instances", "from", "the", "kv", "state", "registry"], "project": "flink"}
{"id": 7541, "code": "public SubtaskStateMapper getUpstreamSubtaskStateMapper() {\n    return SubtaskStateMapper.ARBITRARY;\n}", "summary_tokens": ["defines", "the", "behavior", "of", "this", "partitioner", "when", "upstream", "rescaled", "during", "recovery", "of", "in", "flight", "data"], "project": "flink"}
{"id": 5403, "code": "OperatorStateHandle closeAndGetHandle() throws IOException {\n    StreamStateHandle streamStateHandle = super.closeAndGetHandleAfterLeasesReleased();\n\n    if (null == streamStateHandle) {\n        return null;\n    }\n\n    if (partitionOffsets.isEmpty() && delegate.getPos() > initialPosition) {\n        startNewPartition();\n    }\n\n    Map<String, OperatorStateHandle.StateMetaInfo> offsetsMap = new HashMap<>(1);\n\n    OperatorStateHandle.StateMetaInfo metaInfo =\n            new OperatorStateHandle.StateMetaInfo(\n                    partitionOffsets.toArray(), OperatorStateHandle.Mode.SPLIT_DISTRIBUTE);\n\n    offsetsMap.put(DefaultOperatorStateBackend.DEFAULT_OPERATOR_STATE_NAME, metaInfo);\n\n    return new OperatorStreamStateHandle(offsetsMap, streamStateHandle);\n}", "summary_tokens": ["this", "method", "should", "not", "be", "public", "so", "as", "to", "not", "expose", "internals", "to", "user", "code"], "project": "flink"}
{"id": 6280, "code": "public void testCheckpointPrecedesSavepointRecovery() throws Exception {\n\n        \n    final long savepointId = 42L;\n    final File savepointFile = createSavepoint(savepointId);\n\n        \n    final SavepointRestoreSettings savepointRestoreSettings =\n            SavepointRestoreSettings.forPath(\"\" + savepointFile.getAbsolutePath(), true);\n    final JobGraph jobGraph = createJobGraphWithCheckpointing(savepointRestoreSettings);\n\n    final long checkpointId = 1L;\n\n    final CompletedCheckpoint completedCheckpoint =\n            new CompletedCheckpoint(\n                    jobGraph.getJobID(),\n                    checkpointId,\n                    1L,\n                    1L,\n                    Collections.emptyMap(),\n                    null,\n                    CheckpointProperties.forCheckpoint(\n                            CheckpointRetentionPolicy.NEVER_RETAIN_AFTER_TERMINATION),\n                    new DummyCheckpointStorageLocation());\n\n    final StandaloneCompletedCheckpointStore completedCheckpointStore =\n            new StandaloneCompletedCheckpointStore(1);\n    completedCheckpointStore.addCheckpointAndSubsumeOldestOne(\n            completedCheckpoint, new CheckpointsCleaner(), () -> {});\n    final CheckpointRecoveryFactory testingCheckpointRecoveryFactory =\n            PerJobCheckpointRecoveryFactory.withoutCheckpointStoreRecovery(\n                    maxCheckpoints -> completedCheckpointStore);\n    haServices.setCheckpointRecoveryFactory(testingCheckpointRecoveryFactory);\n\n    final JobMaster jobMaster = new JobMasterBuilder(jobGraph, rpcService).createJobMaster();\n\n    try {\n            \n        final CompletedCheckpoint savepointCheckpoint =\n                completedCheckpointStore.getLatestCheckpoint();\n\n        assertThat(savepointCheckpoint, Matchers.notNullValue());\n\n        assertThat(savepointCheckpoint.getCheckpointID(), is(checkpointId));\n    } finally {\n        RpcUtils.terminateRpcEndpoint(jobMaster, testingTimeout);\n    }\n}", "summary_tokens": ["tests", "that", "an", "existing", "checkpoint", "will", "have", "precedence", "over", "an", "savepoint"], "project": "flink"}
{"id": 203, "code": "public static ElasticsearchContainer createElasticsearchContainer(\n        String dockerImageVersion, Logger log) {\n    String logLevel;\n    if (log.isTraceEnabled()) {\n        logLevel = \"TRACE\";\n    } else if (log.isDebugEnabled()) {\n        logLevel = \"DEBUG\";\n    } else if (log.isInfoEnabled()) {\n        logLevel = \"INFO\";\n    } else if (log.isWarnEnabled()) {\n        logLevel = \"WARN\";\n    } else if (log.isErrorEnabled()) {\n        logLevel = \"ERROR\";\n    } else {\n        logLevel = \"OFF\";\n    }\n\n    return new ElasticsearchContainer(DockerImageName.parse(dockerImageVersion))\n            .withEnv(\"ES_JAVA_OPTS\", \"-Xms2g -Xmx2g\")\n            .withEnv(\"logger.org.elasticsearch\", logLevel)\n            .withLogConsumer(new Slf4jLogConsumer(log));\n}", "summary_tokens": ["creates", "a", "preconfigured", "elasticsearch", "container", "with", "limited", "memory", "allocation", "and", "aligns", "the", "internal", "elasticsearch", "log", "levels", "with", "the", "ones", "used", "by", "the", "capturing", "logger"], "project": "flink"}
{"id": 1371, "code": "public static <E> TypeInformation<E[]> OBJECT_ARRAY(TypeInformation<E> elementType) {\n    if (elementType == Types.STRING) {\n        return (TypeInformation) BasicArrayTypeInfo.STRING_ARRAY_TYPE_INFO;\n    }\n    return ObjectArrayTypeInfo.getInfoFor(elementType);\n}", "summary_tokens": ["returns", "type", "information", "for", "java", "arrays", "of", "object", "types", "such", "as", "code", "string", "code", "code", "integer", "code"], "project": "flink"}
{"id": 6008, "code": "public void testCloseCleansUp() throws IOException {\n    final File rootDir = temporaryFolder.newFolder();\n\n    assertThat(rootDir.listFiles().length, Matchers.equalTo(0));\n\n    try (final FileExecutionGraphInfoStore executionGraphInfoStore =\n            createDefaultExecutionGraphInfoStore(rootDir)) {\n\n        assertThat(rootDir.listFiles().length, Matchers.equalTo(1));\n\n        final File storageDirectory = executionGraphInfoStore.getStorageDir();\n\n        assertThat(storageDirectory.listFiles().length, Matchers.equalTo(0));\n\n        executionGraphInfoStore.put(\n                new ExecutionGraphInfo(\n                        new ArchivedExecutionGraphBuilder()\n                                .setState(JobStatus.FINISHED)\n                                .build()));\n\n        assertThat(storageDirectory.listFiles().length, Matchers.equalTo(1));\n    }\n\n    assertThat(rootDir.listFiles().length, Matchers.equalTo(0));\n}", "summary_tokens": ["tests", "that", "all", "persisted", "files", "are", "cleaned", "up", "after", "closing", "the", "store"], "project": "flink"}
{"id": 3700, "code": "public void setLocalStrategyComparator(TypeComparatorFactory<?> localStrategyComparator) {\n    this.localStrategyComparator = localStrategyComparator;\n}", "summary_tokens": ["sets", "the", "local", "strategy", "comparator", "for", "this", "channel"], "project": "flink"}
{"id": 612, "code": "public void wakeupProducer() {\n    synchronized (lock) {\n        wakeupProducer = true;\n        lock.notifyAll();\n    }\n}", "summary_tokens": ["wakes", "the", "producer", "thread", "up"], "project": "flink"}
{"id": 9406, "code": "public static boolean isWindowFired(\n        long windowEnd, long currentProgress, ZoneId shiftTimeZone) {\n        \n    if (windowEnd == Long.MAX_VALUE) {\n        return false;\n    }\n    long windowTriggerTime = toEpochMillsForTimer(windowEnd - 1, shiftTimeZone);\n    return currentProgress >= windowTriggerTime;\n}", "summary_tokens": ["returns", "the", "window", "should", "fired", "or", "not", "on", "current", "progress"], "project": "flink"}
{"id": 8482, "code": "public Comparable<?> getMax() {\n    return max;\n}", "summary_tokens": ["returns", "null", "if", "this", "instance", "is", "constructed", "by", "column", "stats", "column", "stats", "long", "long", "double", "integer", "number", "number"], "project": "flink"}
{"id": 4864, "code": "public static MemoryManager create(long memorySize, int pageSize) {\n    return new MemoryManager(memorySize, pageSize);\n}", "summary_tokens": ["creates", "a", "memory", "manager", "with", "the", "given", "capacity", "and", "given", "page", "size"], "project": "flink"}
{"id": 2921, "code": "public void testMinByComparisonMultiple() {\n    SelectByMinFunction<Tuple5<Integer, Long, String, Long, Integer>> minByTuple =\n            new SelectByMinFunction<Tuple5<Integer, Long, String, Long, Integer>>(\n                    tupleTypeInfo, new int[] {0, 1, 2, 3, 4});\n\n    try {\n        Assert.assertSame(\n                \"SelectByMin must return smaller tuple\",\n                smaller,\n                minByTuple.reduce(smaller, bigger));\n        Assert.assertSame(\n                \"SelectByMin must return smaller tuple\",\n                smaller,\n                minByTuple.reduce(bigger, smaller));\n    } catch (Exception e) {\n        Assert.fail(\"No exception should be thrown while comparing both tuples\");\n    }\n}", "summary_tokens": ["checks", "whether", "reduce", "does", "behave", "as", "expected", "if", "both", "values", "are", "the", "same", "object"], "project": "flink"}
{"id": 2949, "code": "protected BooleanColumnSummary summarize(Boolean... values) {\n    return new AggregateCombineHarness<\n            Boolean, BooleanColumnSummary, BooleanSummaryAggregator>() {\n        @Override\n        protected void compareResults(\n                BooleanColumnSummary result1, BooleanColumnSummary result2) {\n            Assert.assertEquals(result1.getNullCount(), result2.getNullCount());\n            Assert.assertEquals(result1.getNonNullCount(), result2.getNonNullCount());\n            Assert.assertEquals(result1.getTrueCount(), result2.getTrueCount());\n            Assert.assertEquals(result1.getFalseCount(), result2.getFalseCount());\n        }\n    }.summarize(values);\n}", "summary_tokens": ["helper", "method", "for", "summarizing", "a", "list", "of", "values"], "project": "flink"}
{"id": 3727, "code": "public boolean isPruneMarkerSet() {\n    return this.pFlag;\n}", "summary_tokens": ["checks", "whether", "the", "pruning", "marker", "was", "set"], "project": "flink"}
{"id": 9336, "code": "public static <W extends Window> EveryElement<W> every() {\n    return new EveryElement<>();\n}", "summary_tokens": ["creates", "a", "new", "trigger", "that", "triggers", "on", "receiving", "of", "every", "element"], "project": "flink"}
{"id": 1277, "code": "public Ordering getGroupOrder(int inputNum) {\n    if (inputNum == 0) {\n        return this.groupOrder1;\n    } else if (inputNum == 1) {\n        return this.groupOrder2;\n    } else {\n        throw new IndexOutOfBoundsException();\n    }\n}", "summary_tokens": ["gets", "the", "value", "order", "for", "an", "input", "i"], "project": "flink"}
{"id": 6854, "code": "public void testPhysicallyRemoveDuringSyncPartOfSnapshot() throws IOException {\n    testPhysicallyRemoveDuringSyncPartOfSnapshot(SnapshotVerificationMode.SERIALIZED);\n}", "summary_tokens": ["tests", "that", "remove", "states", "physically", "during", "sync", "part", "of", "snapshot"], "project": "flink"}
{"id": 6082, "code": "public void testTwoComponentsViaBlockingExchange2() {\n    TestingSchedulingTopology topology = new TestingSchedulingTopology();\n\n    TestingSchedulingExecutionVertex va1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex va2 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vb1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vb2 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vc1 = topology.newExecutionVertex();\n    TestingSchedulingExecutionVertex vc2 = topology.newExecutionVertex();\n\n    topology.connect(va1, vb1, ResultPartitionType.PIPELINED)\n            .connect(va1, vb2, ResultPartitionType.PIPELINED)\n            .connect(va2, vb1, ResultPartitionType.PIPELINED)\n            .connect(va2, vb2, ResultPartitionType.PIPELINED)\n            .connect(vb1, vc1, ResultPartitionType.BLOCKING)\n            .connect(vb1, vc2, ResultPartitionType.BLOCKING)\n            .connect(vb2, vc1, ResultPartitionType.BLOCKING)\n            .connect(vb2, vc2, ResultPartitionType.BLOCKING);\n\n    Map<ExecutionVertexID, Set<SchedulingExecutionVertex>> pipelinedRegionByVertex =\n            computePipelinedRegionByVertex(topology);\n\n    Set<SchedulingExecutionVertex> ra1 = pipelinedRegionByVertex.get(va1.getId());\n    Set<SchedulingExecutionVertex> ra2 = pipelinedRegionByVertex.get(va2.getId());\n    Set<SchedulingExecutionVertex> rb1 = pipelinedRegionByVertex.get(vb1.getId());\n    Set<SchedulingExecutionVertex> rb2 = pipelinedRegionByVertex.get(vb2.getId());\n    Set<SchedulingExecutionVertex> rc1 = pipelinedRegionByVertex.get(vc1.getId());\n    Set<SchedulingExecutionVertex> rc2 = pipelinedRegionByVertex.get(vc2.getId());\n\n    assertSameRegion(ra1, ra2, rb1, rb2);\n\n    assertDistinctRegions(ra1, rc1, rc2);\n}", "summary_tokens": ["tests", "the", "below", "topology"], "project": "flink"}
{"id": 5088, "code": "public void set(int index) {\n    Preconditions.checkArgument(index < bitLength && index >= 0);\n\n    int byteIndex = index >>> 3;\n    byte current = memorySegment.get(offset + byteIndex);\n    current |= (1 << (index & BYTE_INDEX_MASK));\n    memorySegment.put(offset + byteIndex, current);\n}", "summary_tokens": ["sets", "the", "bit", "at", "specified", "index"], "project": "flink"}
{"id": 8520, "code": "boolean isAllowAnyPattern(@Nullable Class<?> clazz) {\n    if (allowRawPattern == null || clazz == null) {\n        return false;\n    }\n    final String className = clazz.getName();\n    for (String pattern : allowRawPattern) {\n        if (className.startsWith(pattern)) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["returns", "whether", "the", "given", "class", "is", "eligible", "for", "being", "treated", "as", "raw", "type"], "project": "flink"}
{"id": 3232, "code": "public void setParallelism(int parallelism) {\n    Preconditions.checkArgument(\n            parallelism > 0 || parallelism == ExecutionConfig.PARALLELISM_DEFAULT,\n            \"The parallelism must be at least one, or ExecutionConfig.PARALLELISM_DEFAULT (use system default).\");\n    this.parallelism = parallelism;\n}", "summary_tokens": ["sets", "the", "parallelism", "for", "the", "iteration"], "project": "flink"}
{"id": 1471, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple12)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple12 tuple = (Tuple12) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    if (f5 != null ? !f5.equals(tuple.f5) : tuple.f5 != null) {\n        return false;\n    }\n    if (f6 != null ? !f6.equals(tuple.f6) : tuple.f6 != null) {\n        return false;\n    }\n    if (f7 != null ? !f7.equals(tuple.f7) : tuple.f7 != null) {\n        return false;\n    }\n    if (f8 != null ? !f8.equals(tuple.f8) : tuple.f8 != null) {\n        return false;\n    }\n    if (f9 != null ? !f9.equals(tuple.f9) : tuple.f9 != null) {\n        return false;\n    }\n    if (f10 != null ? !f10.equals(tuple.f10) : tuple.f10 != null) {\n        return false;\n    }\n    if (f11 != null ? !f11.equals(tuple.f11) : tuple.f11 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 1799, "code": "public void putFloatBigEndian(int index, float value) {\n    putIntBigEndian(index, Float.floatToRawIntBits(value));\n}", "summary_tokens": ["writes", "the", "given", "single", "precision", "float", "value", "0", "bit", "0", "bytes", "to", "the", "given", "position", "in", "big", "endian", "byte", "order"], "project": "flink"}
{"id": 638, "code": "public boolean isEndOfStream(Tuple2<K, V> nextElement) {\n    return false;\n}", "summary_tokens": ["this", "schema", "never", "considers", "an", "element", "to", "signal", "end", "of", "stream", "so", "this", "method", "returns", "always", "false"], "project": "flink"}
{"id": 7540, "code": "public int selectChannel(SerializationDelegate<StreamRecord<T>> record) {\n    throw new UnsupportedOperationException(\n            \"Broadcast partitioner does not support select channels.\");\n}", "summary_tokens": ["note", "broadcast", "mode", "could", "be", "handled", "directly", "for", "all", "the", "output", "channels", "in", "record", "writer", "so", "it", "is", "no", "need", "to", "select", "channels", "via", "this", "method"], "project": "flink"}
{"id": 7759, "code": "public void testLatencyMarkEmissionEnabledOverrideViaExecutionConfig() throws Exception {\n    testLatencyMarkEmission(\n            (int) (maxProcessingTime / latencyMarkInterval) + 1,\n            (operator, timeProvider) -> {\n                ExecutionConfig executionConfig = new ExecutionConfig();\n                executionConfig.setLatencyTrackingInterval(latencyMarkInterval);\n\n                Configuration tmConfig = new Configuration();\n                tmConfig.setLong(MetricOptions.LATENCY_INTERVAL, 0L);\n\n                Environment env =\n                        MockEnvironment.builder()\n                                .setTaskManagerRuntimeInfo(\n                                        new TestingTaskManagerRuntimeInfo(tmConfig))\n                                .build();\n\n                setupSourceOperator(operator, executionConfig, env, timeProvider);\n            });\n}", "summary_tokens": ["verifies", "that", "latency", "metrics", "can", "be", "enabled", "via", "the", "execution", "config", "even", "if", "they", "are", "disabled", "via", "the", "configuration"], "project": "flink"}
{"id": 7214, "code": "public String getHost() {\n    return configuration.getString(JobManagerOptions.ADDRESS);\n}", "summary_tokens": ["gets", "the", "hostname", "of", "the", "master", "job", "manager", "where", "the", "program", "will", "be", "executed"], "project": "flink"}
{"id": 1411, "code": "public void putNormalizedKey(BigInteger record, MemorySegment target, int offset, int len) {\n        \n    int bitLen = 0;\n    if (len > 0) {\n        final int signum = record.signum();\n        bitLen = record.bitLength();\n\n            \n            \n            \n        int normBitLen = signum < 0 ? Integer.MAX_VALUE - bitLen : bitLen;\n\n            \n        if (signum >= 0) {\n            normBitLen |= (1 << 31);\n        }\n\n        for (int i = 0; i < 4 && len > 0; i++, len--) {\n            final byte b = (byte) (normBitLen >>> (8 * (3 - i)));\n            target.put(offset++, b);\n        }\n    }\n\n        \n    int bitPos = bitLen - 1;\n    for (; len > 0; len--) {\n        byte b = 0;\n        for (int bytePos = 0; bytePos < 8 && bitPos >= 0; bytePos++, bitPos--) {\n            b <<= 1;\n            if (record.testBit(bitPos)) {\n                b |= 1;\n            }\n        }\n            \n            \n        target.put(offset++, b);\n    }\n}", "summary_tokens": ["adds", "a", "normalized", "key", "containing", "the", "normalized", "number", "of", "bits", "and", "msbs", "of", "the", "given", "record"], "project": "flink"}
{"id": 3705, "code": "public Collection<SinkPlanNode> getDataSinks() {\n    return dataSinks;\n}", "summary_tokens": ["gets", "the", "data", "sinks", "from", "this", "optimized", "plan"], "project": "flink"}
{"id": 4976, "code": "private static byte assignPartition(int bucket, byte numPartitions) {\n    return (byte) (bucket % numPartitions);\n}", "summary_tokens": ["assigns", "a", "partition", "to", "a", "bucket"], "project": "flink"}
{"id": 6007, "code": "public void testExecutionGraphExpiration() throws Exception {\n    final File rootDir = temporaryFolder.newFolder();\n\n    final Time expirationTime = Time.milliseconds(1L);\n\n    final ManuallyTriggeredScheduledExecutor scheduledExecutor =\n            new ManuallyTriggeredScheduledExecutor();\n\n    final ManualTicker manualTicker = new ManualTicker();\n\n    try (final FileExecutionGraphInfoStore executionGraphInfoStore =\n            new FileExecutionGraphInfoStore(\n                    rootDir,\n                    expirationTime,\n                    Integer.MAX_VALUE,\n                    10000L,\n                    scheduledExecutor,\n                    manualTicker)) {\n\n        final ExecutionGraphInfo executionGraphInfo =\n                new ExecutionGraphInfo(\n                        new ArchivedExecutionGraphBuilder()\n                                .setState(JobStatus.FINISHED)\n                                .build());\n\n        executionGraphInfoStore.put(executionGraphInfo);\n\n            \n        assertThat(executionGraphInfoStore.size(), Matchers.equalTo(1));\n\n        manualTicker.advanceTime(expirationTime.toMilliseconds(), TimeUnit.MILLISECONDS);\n\n            \n        scheduledExecutor.triggerScheduledTasks();\n\n        assertThat(executionGraphInfoStore.size(), Matchers.equalTo(0));\n\n        assertThat(\n                executionGraphInfoStore.get(executionGraphInfo.getJobId()),\n                Matchers.nullValue());\n\n        final File storageDirectory = executionGraphInfoStore.getStorageDir();\n\n            \n        assertThat(storageDirectory.listFiles().length, Matchers.equalTo(0));\n    }\n}", "summary_tokens": ["tests", "that", "an", "expired", "execution", "graph", "is", "removed", "from", "the", "execution", "graph", "store"], "project": "flink"}
{"id": 6534, "code": "public void close() {\n    trap.run();\n}", "summary_tokens": ["if", "the", "validator", "has", "been", "activated", "check", "if", "input", "has", "been", "provided", "e"], "project": "flink"}
{"id": 4898, "code": "public InternalOperatorIOMetricGroup getIOMetricGroup() {\n    return ioMetrics;\n}", "summary_tokens": ["returns", "the", "operator", "iometric", "group", "for", "this", "operator"], "project": "flink"}
{"id": 8934, "code": "public Double getColumnNullCount(RelNode rel, int index) {\n    for (; ; ) {\n        try {\n            return columnNullCountHandler.getColumnNullCount(rel, this, index);\n        } catch (JaninoRelMetadataProvider.NoHandler e) {\n            columnNullCountHandler = revise(e.relClass, FlinkMetadata.ColumnNullCount.DEF);\n        }\n    }\n}", "summary_tokens": ["returns", "the", "null", "count", "of", "the", "given", "column"], "project": "flink"}
{"id": 8322, "code": "private static boolean inFirstSegment(MemorySegment[] segments, int offset, int numBytes) {\n    return numBytes + offset <= segments[0].size();\n}", "summary_tokens": ["is", "it", "just", "in", "first", "memory", "segment", "we", "use", "quick", "way", "to", "do", "something"], "project": "flink"}
{"id": 2114, "code": "public static <T> T getOrDefault(CompletableFuture<T> future, T defaultValue) {\n    T value = getWithoutException(future);\n    return value == null ? defaultValue : value;\n}", "summary_tokens": ["the", "result", "of", "completable", "future", "or", "the", "default", "value", "if", "it", "has", "not", "yet", "completed"], "project": "flink"}
{"id": 8954, "code": "private Transformation<RowData> applyKeyBy(\n        TableConfig config,\n        Transformation<RowData> inputTransform,\n        int[] primaryKeys,\n        int sinkParallelism,\n        int inputParallelism,\n        boolean inputInsertOnly,\n        boolean needMaterialize) {\n    final ExecutionConfigOptions.SinkKeyedShuffle sinkShuffleByPk =\n            config.getConfiguration().get(ExecutionConfigOptions.TABLE_EXEC_SINK_KEYED_SHUFFLE);\n    boolean sinkKeyBy = false;\n    switch (sinkShuffleByPk) {\n        case NONE:\n            break;\n        case AUTO:\n            sinkKeyBy = inputInsertOnly && sinkParallelism != inputParallelism;\n            break;\n        case FORCE:\n                \n            sinkKeyBy = sinkParallelism != 1 || inputParallelism != 1;\n            break;\n    }\n    if (!sinkKeyBy && !needMaterialize) {\n        return inputTransform;\n    }\n\n    final RowDataKeySelector selector =\n            KeySelectorUtil.getRowDataSelector(primaryKeys, getInputTypeInfo());\n    final KeyGroupStreamPartitioner<RowData, RowData> partitioner =\n            new KeyGroupStreamPartitioner<>(\n                    selector, KeyGroupRangeAssignment.DEFAULT_LOWER_BOUND_MAX_PARALLELISM);\n    Transformation<RowData> partitionedTransform =\n            new PartitionTransformation<>(inputTransform, partitioner);\n    partitionedTransform.setParallelism(sinkParallelism);\n    return partitionedTransform;\n}", "summary_tokens": ["apply", "a", "primary", "key", "partition", "transformation", "to", "guarantee", "the", "strict", "ordering", "of", "changelog", "messages"], "project": "flink"}
{"id": 2233, "code": "public void testRetryWithDelayFixedArgsFailure() throws Throwable {\n    CompletableFuture<?> retryFuture =\n            FutureUtils.retryWithDelay(\n                    () ->\n                            FutureUtils.completedExceptionally(\n                                    new FlinkException(\"Test exception\")),\n                    3,\n                    Time.milliseconds(1L),\n                    TestingUtils.defaultScheduledExecutor());\n\n    try {\n        retryFuture.get(TestingUtils.TIMEOUT.toMilliseconds(), TimeUnit.MILLISECONDS);\n    } catch (ExecutionException ee) {\n        throw ExceptionUtils.stripExecutionException(ee);\n    }\n}", "summary_tokens": ["tests", "that", "retry", "with", "delay", "fails", "after", "having", "exceeded", "all", "retries"], "project": "flink"}
{"id": 289, "code": "public void testContinuousTextFileSourceWithJobManagerFailover() throws Exception {\n    testContinuousTextFileSource(FailoverType.JM);\n}", "summary_tokens": ["this", "test", "runs", "a", "job", "reading", "continuous", "input", "files", "appearing", "over", "time", "with", "a", "stream", "record", "format", "text", "lines", "and", "triggers", "job", "manager", "failover"], "project": "flink"}
{"id": 4055, "code": "public static String createRandomName(String prefix) {\n    Preconditions.checkNotNull(prefix, \"Prefix must not be null.\");\n\n    long nameOffset;\n\n        \n    do {\n        nameOffset = nextNameOffset.get();\n    } while (!nextNameOffset.compareAndSet(nameOffset, nameOffset + 1L));\n\n    return prefix + '_' + nameOffset;\n}", "summary_tokens": ["creates", "a", "random", "name", "of", "the", "form", "prefix", "x", "where", "x", "is", "an", "increasing", "number"], "project": "flink"}
{"id": 8764, "code": "private SqlNode getAgg(SqlSelect select) {\n    final SelectScope selectScope = getRawSelectScope(select);\n    if (selectScope != null) {\n        final List<SqlNode> selectList = selectScope.getExpandedSelectList();\n        if (selectList != null) {\n            return aggFinder.findAgg(selectList);\n        }\n    }\n    return aggFinder.findAgg(select.getSelectList());\n}", "summary_tokens": ["if", "there", "is", "at", "least", "one", "call", "to", "an", "aggregate", "function", "returns", "the", "first"], "project": "flink"}
{"id": 2402, "code": "public static boolean hasWarnedDeprecation(String name) {\n    DeprecationContext deprecations = deprecationContext.get();\n    if (deprecations.getDeprecatedKeyMap().containsKey(name)) {\n        if (deprecations.getDeprecatedKeyMap().get(name).accessed.get()) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["returns", "whether", "or", "not", "a", "deprecated", "name", "has", "been", "warned"], "project": "flink"}
{"id": 9158, "code": "public static ExpressionEvaluator compileExpression(\n        String code,\n        List<String> argumentNames,\n        List<Class<?>> argumentClasses,\n        Class<?> returnClass) {\n    try {\n        ExpressionEntry key =\n                new ExpressionEntry(code, argumentNames, argumentClasses, returnClass);\n        return COMPILED_EXPRESSION_CACHE.get(\n                key,\n                () -> {\n                    ExpressionEvaluator expressionEvaluator = new ExpressionEvaluator();\n                        \n                    expressionEvaluator.setParameters(\n                            argumentNames.toArray(new String[0]),\n                            argumentClasses.toArray(new Class[0]));\n                        \n                    expressionEvaluator.setExpressionType(returnClass);\n                    try {\n                            \n                        expressionEvaluator.cook(code);\n                    } catch (CompileException e) {\n                        throw new InvalidProgramException(\n                                \"Table program cannot be compiled. This is a bug. Please file an issue.\\nExpression: \"\n                                        + code,\n                                e);\n                    }\n                    return expressionEvaluator;\n                });\n    } catch (Exception e) {\n        throw new FlinkRuntimeException(e.getMessage(), e);\n    }\n}", "summary_tokens": ["compiles", "an", "expression", "code", "to", "a", "janino", "expression", "evaluator"], "project": "flink"}
{"id": 7439, "code": "public static <T> DynamicEventTimeSessionWindows<T> withDynamicGap(\n        SessionWindowTimeGapExtractor<T> sessionWindowTimeGapExtractor) {\n    return new DynamicEventTimeSessionWindows<>(sessionWindowTimeGapExtractor);\n}", "summary_tokens": ["creates", "a", "new", "session", "windows", "window", "assigner", "that", "assigns", "elements", "to", "sessions", "based", "on", "the", "element", "timestamp"], "project": "flink"}
{"id": 3827, "code": "private RunnerApi.Environment createPythonExecutionEnvironment(long memoryLimitBytes)\n        throws Exception {\n    PythonEnvironment environment = environmentManager.createEnvironment();\n    if (environment instanceof ProcessPythonEnvironment) {\n        ProcessPythonEnvironment processEnvironment = (ProcessPythonEnvironment) environment;\n        Map<String, String> env = processEnvironment.getEnv();\n        env.putAll(jobOptions);\n        env.put(PYTHON_WORKER_MEMORY_LIMIT, String.valueOf(memoryLimitBytes));\n        return Environments.createProcessEnvironment(\n                \"\", \"\", processEnvironment.getCommand(), env);\n    }\n    throw new RuntimeException(\"Currently only ProcessPythonEnvironment is supported.\");\n}", "summary_tokens": ["creates", "a", "specification", "which", "specifies", "the", "portability", "python", "execution", "environment"], "project": "flink"}
{"id": 717, "code": "public void testFailureRecoveryEventTime() throws Exception {\n    testKafkaShuffleFailureRecovery(1000, EventTime);\n}", "summary_tokens": ["failure", "recovery", "after", "processing", "0", "0", "data", "with", "time", "characteristic", "event", "time"], "project": "flink"}
{"id": 905, "code": "private void ensureSubscriberIsNull(String attemptingSubscribeMode) {\n    if (subscriber != null) {\n        throw new IllegalStateException(\n                String.format(\n                        \"Cannot use %s for consumption because a %s is already set for consumption.\",\n                        attemptingSubscribeMode, subscriber.getClass().getSimpleName()));\n    }\n}", "summary_tokens": ["topic", "name", "and", "topic", "pattern", "is", "conflict", "make", "sure", "they", "are", "set", "only", "once"], "project": "flink"}
{"id": 5097, "code": "public TypeSerializer<K> getKeySerializer() {\n    return keySerializer;\n}", "summary_tokens": ["the", "serializer", "for", "the", "key", "the", "state", "is", "associated", "to"], "project": "flink"}
{"id": 3857, "code": "public FlinkFnApi.UserDefinedAggregateFunctions getUserDefinedFunctionsProto() {\n    FlinkFnApi.UserDefinedAggregateFunctions.Builder builder =\n            super.getUserDefinedFunctionsProto().toBuilder();\n    builder.setCountStarInserted(countStarInserted);\n    return builder.build();\n}", "summary_tokens": ["gets", "the", "proto", "representation", "of", "the", "python", "user", "defined", "aggregate", "functions", "to", "be", "executed"], "project": "flink"}
{"id": 9172, "code": "boolean insertToBucket(int hashCode, int pointer, boolean sizeAddAndCheckResize)\n        throws IOException {\n    final int posHashCode = findBucket(hashCode);\n        \n    final int bucketArrayPos = posHashCode >> table.bucketsPerSegmentBits;\n    final int bucketInSegmentPos =\n            (posHashCode & table.bucketsPerSegmentMask) << BUCKET_SIZE_BITS;\n    final MemorySegment bucket = this.buckets[bucketArrayPos];\n    return insertToBucket(bucket, bucketInSegmentPos, hashCode, pointer, sizeAddAndCheckResize);\n}", "summary_tokens": ["insert", "into", "bucket", "by", "hash", "code", "and", "pointer"], "project": "flink"}
{"id": 520, "code": "public KafkaSourceBuilder<OUT> setBounded(OffsetsInitializer stoppingOffsetsInitializer) {\n    this.boundedness = Boundedness.BOUNDED;\n    this.stoppingOffsetsInitializer = stoppingOffsetsInitializer;\n    return this;\n}", "summary_tokens": ["by", "default", "the", "kafka", "source", "is", "set", "to", "run", "in", "boundedness", "continuous", "unbounded", "manner", "and", "thus", "never", "stops", "until", "the", "flink", "job", "fails", "or", "is", "canceled"], "project": "flink"}
{"id": 7472, "code": "public static EventTimeTrigger create() {\n    return new EventTimeTrigger();\n}", "summary_tokens": ["creates", "an", "event", "time", "trigger", "that", "fires", "once", "the", "watermark", "passes", "the", "end", "of", "the", "window"], "project": "flink"}
{"id": 3577, "code": "public void setHeuristicNetworkCost(double cost) {\n    if (cost <= 0) {\n        throw new IllegalArgumentException(\"Heuristic costs must be positive.\");\n    }\n    this.heuristicNetworkCost = cost;\n}", "summary_tokens": ["sets", "the", "heuristic", "network", "cost", "for", "this", "costs", "object"], "project": "flink"}
{"id": 8667, "code": "public static long unixTimestamp(String dateStr, String format, TimeZone tz) {\n    long ts = internalParseTimestampMillis(dateStr, format, tz);\n    if (ts == Long.MIN_VALUE) {\n        return Long.MIN_VALUE;\n    } else {\n            \n        return ts / 1000;\n    }\n}", "summary_tokens": ["returns", "the", "value", "of", "the", "argument", "as", "an", "unsigned", "integer", "in", "seconds", "since", "0", "0", "0", "0", "0", "0", "utc"], "project": "flink"}
{"id": 8515, "code": "static DataTypeTemplate fromAnnotation(DataTypeHint hint, @Nullable DataType dataType) {\n    return new DataTypeTemplate(\n            dataType,\n            defaultAsNull(hint, DataTypeHint::rawSerializer),\n            defaultAsNull(hint, DataTypeHint::inputGroup),\n            defaultAsNull(hint, DataTypeHint::version),\n            hintFlagToBoolean(defaultAsNull(hint, DataTypeHint::allowRawGlobally)),\n            defaultAsNull(hint, DataTypeHint::allowRawPattern),\n            defaultAsNull(hint, DataTypeHint::forceRawPattern),\n            defaultAsNull(hint, DataTypeHint::defaultDecimalPrecision),\n            defaultAsNull(hint, DataTypeHint::defaultDecimalScale),\n            defaultAsNull(hint, DataTypeHint::defaultYearPrecision),\n            defaultAsNull(hint, DataTypeHint::defaultSecondPrecision));\n}", "summary_tokens": ["creates", "an", "instance", "from", "the", "given", "data", "type", "hint", "with", "a", "resolved", "data", "type", "if", "available"], "project": "flink"}
{"id": 4477, "code": "public long getSizeOfPhysicalMemory() {\n    return this.sizeOfPhysicalMemory;\n}", "summary_tokens": ["returns", "the", "size", "of", "physical", "memory", "in", "bytes", "available", "on", "the", "compute", "node"], "project": "flink"}
{"id": 5555, "code": "static RpcService createRpcService(\n        final Configuration configuration,\n        final HighAvailabilityServices haServices,\n        final RpcSystem rpcSystem)\n        throws Exception {\n\n    checkNotNull(configuration);\n    checkNotNull(haServices);\n\n    return RpcUtils.createRemoteRpcService(\n            rpcSystem,\n            configuration,\n            determineTaskManagerBindAddress(configuration, haServices, rpcSystem),\n            configuration.getString(TaskManagerOptions.RPC_PORT),\n            configuration.getString(TaskManagerOptions.BIND_HOST),\n            configuration.getOptional(TaskManagerOptions.RPC_BIND_PORT));\n}", "summary_tokens": ["create", "a", "rpc", "service", "for", "the", "task", "manager"], "project": "flink"}
{"id": 3920, "code": "public void testClientServerIntegration() throws Throwable {\n        \n    final int numServers = 2;\n    final int numServerEventLoopThreads = 2;\n    final int numServerQueryThreads = 2;\n\n    final int numClientEventLoopThreads = 4;\n    final int numClientsTasks = 8;\n\n    final int batchSize = 16;\n\n    final int numKeyGroups = 1;\n\n    AbstractStateBackend abstractBackend = new MemoryStateBackend();\n    KvStateRegistry dummyRegistry = new KvStateRegistry();\n    DummyEnvironment dummyEnv = new DummyEnvironment(\"test\", 1, 0);\n    dummyEnv.setKvStateRegistry(dummyRegistry);\n\n    AbstractKeyedStateBackend<Integer> backend =\n            abstractBackend.createKeyedStateBackend(\n                    dummyEnv,\n                    new JobID(),\n                    \"test_op\",\n                    IntSerializer.INSTANCE,\n                    numKeyGroups,\n                    new KeyGroupRange(0, 0),\n                    dummyRegistry.createTaskRegistry(new JobID(), new JobVertexID()),\n                    TtlTimeProvider.DEFAULT,\n                    new UnregisteredMetricsGroup(),\n                    Collections.emptyList(),\n                    new CloseableRegistry());\n\n    AtomicKvStateRequestStats clientStats = new AtomicKvStateRequestStats();\n\n    final MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    Client<KvStateInternalRequest, KvStateResponse> client = null;\n    ExecutorService clientTaskExecutor = null;\n    final KvStateServerImpl[] server = new KvStateServerImpl[numServers];\n\n    try {\n        client =\n                new Client<>(\"Test Client\", numClientEventLoopThreads, serializer, clientStats);\n        clientTaskExecutor = Executors.newFixedThreadPool(numClientsTasks);\n\n            \n        ValueStateDescriptor<Integer> desc =\n                new ValueStateDescriptor<>(\"any\", IntSerializer.INSTANCE);\n        desc.setQueryable(\"any\");\n\n            \n        KvStateRegistry[] registry = new KvStateRegistry[numServers];\n        AtomicKvStateRequestStats[] serverStats = new AtomicKvStateRequestStats[numServers];\n        final KvStateID[] ids = new KvStateID[numServers];\n\n        for (int i = 0; i < numServers; i++) {\n            registry[i] = new KvStateRegistry();\n            serverStats[i] = new AtomicKvStateRequestStats();\n            server[i] =\n                    new KvStateServerImpl(\n                            InetAddress.getLocalHost().getHostName(),\n                            Collections.singletonList(0).iterator(),\n                            numServerEventLoopThreads,\n                            numServerQueryThreads,\n                            registry[i],\n                            serverStats[i]);\n\n            server[i].start();\n\n            backend.setCurrentKey(1010 + i);\n\n                \n            ValueState<Integer> state =\n                    backend.getPartitionedState(\n                            VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, desc);\n\n            state.update(201 + i);\n\n                \n            InternalKvState<Integer, ?, Integer> kvState =\n                    (InternalKvState<Integer, ?, Integer>) state;\n\n                \n            ids[i] =\n                    registry[i].registerKvState(\n                            new JobID(),\n                            new JobVertexID(),\n                            new KeyGroupRange(0, 0),\n                            \"any\",\n                            kvState,\n                            getClass().getClassLoader());\n        }\n\n        final Client<KvStateInternalRequest, KvStateResponse> finalClient = client;\n        Callable<Void> queryTask =\n                () -> {\n                    while (true) {\n                        if (Thread.interrupted()) {\n                            throw new InterruptedException();\n                        }\n\n                            \n                        List<Integer> random = new ArrayList<>();\n                        for (int j = 0; j < batchSize; j++) {\n                            random.add(j);\n                        }\n                        Collections.shuffle(random);\n\n                            \n                        List<CompletableFuture<KvStateResponse>> futures =\n                                new ArrayList<>(batchSize);\n\n                        for (int j = 0; j < batchSize; j++) {\n                            int targetServer = random.get(j) % numServers;\n\n                            byte[] serializedKeyAndNamespace =\n                                    KvStateSerializer.serializeKeyAndNamespace(\n                                            1010 + targetServer,\n                                            IntSerializer.INSTANCE,\n                                            VoidNamespace.INSTANCE,\n                                            VoidNamespaceSerializer.INSTANCE);\n\n                            KvStateInternalRequest request =\n                                    new KvStateInternalRequest(\n                                            ids[targetServer], serializedKeyAndNamespace);\n                            futures.add(\n                                    finalClient.sendRequest(\n                                            server[targetServer].getServerAddress(), request));\n                        }\n\n                            \n                        for (int j = 0; j < batchSize; j++) {\n                            int targetServer = random.get(j) % numServers;\n\n                            Future<KvStateResponse> future = futures.get(j);\n                            byte[] buf = future.get().getContent();\n                            int value =\n                                    KvStateSerializer.deserializeValue(\n                                            buf, IntSerializer.INSTANCE);\n                            assertEquals(201L + targetServer, value);\n                        }\n                    }\n                };\n\n            \n        List<Future<Void>> taskFutures = new ArrayList<>();\n        for (int i = 0; i < numClientsTasks; i++) {\n            taskFutures.add(clientTaskExecutor.submit(queryTask));\n        }\n\n        long numRequests;\n        while ((numRequests = clientStats.getNumRequests()) < 100_000L) {\n            Thread.sleep(100L);\n            LOG.info(\"Number of requests {}/100_000\", numRequests);\n        }\n\n        try {\n            client.shutdown().get();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        Assert.assertTrue(client.isEventGroupShutdown());\n\n        final CombinableMatcher<Throwable> exceptionMatcher =\n                either(FlinkMatchers.containsCause(ClosedChannelException.class))\n                        .or(FlinkMatchers.containsCause(IllegalStateException.class));\n\n        for (Future<Void> future : taskFutures) {\n            try {\n                future.get();\n                fail(\"Did not throw expected Exception after shut down\");\n            } catch (ExecutionException t) {\n                assertThat(t, exceptionMatcher);\n            }\n        }\n\n        assertEquals(\"Connection leak (client)\", 0L, clientStats.getNumConnections());\n        for (int i = 0; i < numServers; i++) {\n            boolean success = false;\n            int numRetries = 0;\n            while (!success) {\n                try {\n                    assertEquals(\n                            \"Connection leak (server)\", 0L, serverStats[i].getNumConnections());\n                    success = true;\n                } catch (Throwable t) {\n                    if (numRetries < 10) {\n                        LOG.info(\"Retrying connection leak check (server)\");\n                        Thread.sleep((numRetries + 1) * 50L);\n                        numRetries++;\n                    } else {\n                        throw t;\n                    }\n                }\n            }\n        }\n    } finally {\n        if (client != null) {\n            try {\n                client.shutdown().get();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            Assert.assertTrue(client.isEventGroupShutdown());\n        }\n\n        for (int i = 0; i < numServers; i++) {\n            if (server[i] != null) {\n                server[i].shutdown();\n            }\n        }\n\n        if (clientTaskExecutor != null) {\n            clientTaskExecutor.shutdown();\n        }\n    }\n}", "summary_tokens": ["tests", "multiple", "clients", "querying", "multiple", "servers", "until", "0", "k", "queries", "have", "been", "processed"], "project": "flink"}
{"id": 7269, "code": "public StreamGraph getStreamGraph(boolean clearTransformations) {\n    final StreamGraph streamGraph = getStreamGraphGenerator(transformations).generate();\n    if (clearTransformations) {\n        transformations.clear();\n    }\n    return streamGraph;\n}", "summary_tokens": ["getter", "of", "the", "stream", "graph", "of", "the", "streaming", "job", "with", "the", "option", "to", "clear", "previously", "registered", "transformation", "transformations"], "project": "flink"}
{"id": 9572, "code": "public void localTaskFailureRecoveryTwoMapTasks() throws Exception {\n    final int failAfterElements = 20;\n    final int keyByChannelNumber = 2;\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(1)\n            .setBufferTimeout(0)\n            .disableOperatorChaining()\n            .setMaxParallelism(128)\n            .setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n    env.getCheckpointConfig().enableApproximateLocalRecovery(true);\n\n    env.addSource(\n                    new AppSourceFunction(\n                            BUFFER_SIZE, env.getMaxParallelism(), keyByChannelNumber))\n            .slotSharingGroup(\"source\")\n            .keyBy(InvertedKeyTuple::key)\n            .map(new FailingMapper<>(failAfterElements))\n            .setParallelism(keyByChannelNumber)\n            .slotSharingGroup(\"map\")\n            .addSink(new ValidatingAtMostOnceSink(200, keyByChannelNumber))\n            .slotSharingGroup(\"sink\");\n\n    FailingMapper.failedBefore = false;\n    tryExecute(env, \"testTwoMapTasks\");\n}", "summary_tokens": ["test", "the", "following", "topology"], "project": "flink"}
{"id": 2311, "code": "public Event nextInvalid() {\n    final Iterator<Entry<Integer, State>> iter = states.entrySet().iterator();\n    if (iter.hasNext()) {\n        final Entry<Integer, State> entry = iter.next();\n\n        State currentState = entry.getValue();\n        int address = entry.getKey();\n        iter.remove();\n\n        EventType event = currentState.randomInvalidTransition(rnd);\n        return new Event(event, address);\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["creates", "an", "event", "for", "an", "illegal", "state", "transition", "of", "one", "of", "the", "internal", "state", "machines"], "project": "flink"}
{"id": 1134, "code": "public String getName() {\n    return name;\n}", "summary_tokens": ["gets", "the", "name", "that", "the", "aggregator", "is", "registered", "under"], "project": "flink"}
{"id": 1382, "code": "protected void writeOuterSnapshot(DataOutputView out) throws IOException {}", "summary_tokens": ["writes", "the", "outer", "snapshot", "i"], "project": "flink"}
{"id": 1732, "code": "public FileSystem getFileSystem() throws IOException {\n    return FileSystem.get(this.toUri());\n}", "summary_tokens": ["returns", "the", "file", "system", "that", "owns", "this", "path"], "project": "flink"}
{"id": 6524, "code": "public void testGetNonExistingExecutionVertexWillThrowException() throws Exception {\n    final JobVertex jobVertex = ExecutionGraphTestUtils.createNoOpVertex(1);\n\n    final ExecutionGraph eg = ExecutionGraphTestUtils.createSimpleTestGraph(jobVertex);\n    final ExecutionGraphToInputsLocationsRetrieverAdapter inputsLocationsRetriever =\n            new ExecutionGraphToInputsLocationsRetrieverAdapter(eg);\n\n    ExecutionVertexID invalidExecutionVertexId = new ExecutionVertexID(new JobVertexID(), 0);\n    try {\n        inputsLocationsRetriever.getTaskManagerLocation(invalidExecutionVertexId);\n        fail(\"Should throw exception if execution vertex doesn't exist!\");\n    } catch (IllegalStateException expected) {\n            \n    }\n}", "summary_tokens": ["tests", "that", "it", "will", "throw", "exception", "when", "getting", "the", "task", "manager", "location", "of", "a", "non", "existing", "execution"], "project": "flink"}
{"id": 7740, "code": "public void testSwitchToUnalignedByUpstream() throws Exception {\n    ValidatingCheckpointHandler target = new ValidatingCheckpointHandler();\n    try (CheckpointedInputGate gate =\n            new TestCheckpointedInputGateBuilder(2, getTestBarrierHandlerFactory(target))\n                    .build()) {\n\n        CheckpointBarrier aligned =\n                new CheckpointBarrier(\n                        1,\n                        clock.relativeTimeMillis(),\n                        alignedWithTimeout(\n                                CheckpointType.CHECKPOINT, getDefault(), Integer.MAX_VALUE));\n\n        send(\n                toBuffer(new EventAnnouncement(aligned, 0), true),\n                0,\n                gate); \n        assertEquals(0, target.triggeredCheckpointCounter);\n        send(\n                toBuffer(aligned.asUnaligned(), true),\n                1,\n                gate); \n            \n        assertEquals(1, target.triggeredCheckpointCounter);\n    }\n}", "summary_tokens": ["if", "a", "checkpoint", "announcement", "was", "processed", "from", "one", "channel", "and", "then", "uc", "barrier", "arrives", "on", "another", "channel", "this", "uc", "barrier", "should", "be", "processed", "by", "the", "uc", "controller"], "project": "flink"}
{"id": 3321, "code": "public JaccardIndex<K, VV, EV> setMinimumScore(int numerator, int denominator) {\n    Preconditions.checkArgument(numerator >= 0, \"Minimum score numerator must be non-negative\");\n    Preconditions.checkArgument(\n            denominator > 0, \"Minimum score denominator must be greater than zero\");\n    Preconditions.checkArgument(\n            numerator <= denominator,\n            \"Minimum score fraction must be less than or equal to one\");\n\n    this.unboundedScores = false;\n    this.minimumScoreNumerator = numerator;\n    this.minimumScoreDenominator = denominator;\n\n    return this;\n}", "summary_tokens": ["filter", "out", "jaccard", "index", "scores", "less", "than", "the", "given", "minimum", "fraction"], "project": "flink"}
{"id": 2702, "code": "public String getExecutionPlan() throws Exception {\n    Plan p = createProgramPlan(getJobName(), false);\n    return ExecutionPlanUtil.getExecutionPlanAsJSON(p);\n}", "summary_tokens": ["creates", "the", "plan", "with", "which", "the", "system", "will", "execute", "the", "program", "and", "returns", "it", "as", "a", "string", "using", "a", "json", "representation", "of", "the", "execution", "data", "flow", "graph"], "project": "flink"}
{"id": 2267, "code": "public GenericContainer<?> getJobManager() {\n    return this.jobManager;\n}", "summary_tokens": ["gets", "job", "manager", "container"], "project": "flink"}
{"id": 6626, "code": "public void testCloseDoesNotLock() throws Exception {\n    final Path folder = new Path(tmp.newFolder().toURI());\n    final String fileName = \"this-is-ignored-anyways.file\";\n\n    final FileSystem fileSystem = spy(new TestFs((path) -> new BlockerStream()));\n\n    final FSDataOutputStream checkpointStream = createTestStream(fileSystem, folder, fileName);\n\n    final OneShotLatch sync = new OneShotLatch();\n\n    final CheckedThread thread =\n            new CheckedThread() {\n\n                @Override\n                public void go() throws Exception {\n                    sync.trigger();\n                        \n                    closeAndGetResult(checkpointStream);\n                }\n            };\n    thread.start();\n\n    sync.await();\n    checkpointStream.close();\n\n        \n        \n    try {\n        thread.sync();\n    } catch (IOException ignored) {\n    }\n}", "summary_tokens": ["this", "test", "validates", "that", "a", "close", "operation", "can", "happen", "even", "while", "a", "close", "and", "get", "handle", "call", "is", "in", "progress"], "project": "flink"}
{"id": 6424, "code": "public void testRequestNewResources() throws Exception {\n    final JobID jobId = new JobID();\n    final List<CompletableFuture<Void>> allocateResourceFutures = new ArrayList<>();\n    allocateResourceFutures.add(new CompletableFuture<>());\n    allocateResourceFutures.add(new CompletableFuture<>());\n\n    new Context() {\n        {\n            resourceActionsBuilder.setAllocateResourceConsumer(\n                    ignored -> {\n                        if (allocateResourceFutures.get(0).isDone()) {\n                            allocateResourceFutures.get(1).complete(null);\n                        } else {\n                            allocateResourceFutures.get(0).complete(null);\n                        }\n                    });\n            runTest(\n                    () -> {\n                            \n                            \n                        runInMainThread(\n                                () ->\n                                        getSlotManager()\n                                                .processResourceRequirements(\n                                                        createResourceRequirements(\n                                                                jobId,\n                                                                DEFAULT_NUM_SLOTS_PER_WORKER)));\n                        assertFutureCompleteAndReturn(allocateResourceFutures.get(0));\n                        assertFutureNotComplete(allocateResourceFutures.get(1));\n\n                        runInMainThread(\n                                () ->\n                                        getSlotManager()\n                                                .processResourceRequirements(\n                                                        createResourceRequirements(\n                                                                jobId,\n                                                                DEFAULT_NUM_SLOTS_PER_WORKER\n                                                                        + 1)));\n                        assertFutureCompleteAndReturn(allocateResourceFutures.get(1));\n                    });\n        }\n    };\n}", "summary_tokens": ["tests", "that", "we", "only", "request", "new", "resources", "containers", "once", "we", "have", "assigned", "all", "pending", "task", "managers"], "project": "flink"}
{"id": 4377, "code": "public static void configureUncaughtExceptionHandler(Configuration config) {\n    Thread.setDefaultUncaughtExceptionHandler(\n            new ClusterUncaughtExceptionHandler(\n                    config.get(ClusterOptions.UNCAUGHT_EXCEPTION_HANDLING)));\n}", "summary_tokens": ["sets", "the", "uncaught", "exception", "handler", "for", "current", "thread", "based", "on", "configuration"], "project": "flink"}
{"id": 6736, "code": "public void testMetadataOperationLogged() throws IOException {\n    TestingStateChangelogWriter writer = new TestingStateChangelogWriter();\n    InternalKeyContextImpl<String> keyContext =\n            new InternalKeyContextImpl<>(KeyGroupRange.of(1, 1000), 1000);\n\n    try (StateChangeLogger<String, Namespace> logger = getLogger(writer, keyContext)) {\n        List<Tuple2<Integer, StateChangeOperation>> expectedAppends = new ArrayList<>();\n        expectedAppends.add(Tuple2.of(COMMON_KEY_GROUP, METADATA));\n\n            \n        int numOpTypes = StateChangeOperation.values().length;\n        for (int i = 0; i < numOpTypes * 7; i++) {\n            String element = Integer.toString(i);\n            StateChangeOperation operation =\n                    StateChangeOperation.byCode((byte) (i % numOpTypes));\n            log(operation, element, logger, keyContext).ifPresent(expectedAppends::add);\n        }\n        assertEquals(expectedAppends, writer.appends);\n    }\n}", "summary_tokens": ["a", "basic", "test", "for", "appending", "the", "metadata", "on", "first", "state", "access"], "project": "flink"}
{"id": 2886, "code": "public Option type(OptionType type) {\n    this.type = type;\n    return this;\n}", "summary_tokens": ["define", "the", "type", "of", "the", "option"], "project": "flink"}
{"id": 2797, "code": "private O setResources(ResourceSpec resources) {\n    OperatorValidationUtils.validateResources(resources);\n\n    this.minResources = resources;\n    this.preferredResources = resources;\n\n    @SuppressWarnings(\"unchecked\")\n    O returnType = (O) this;\n    return returnType;\n}", "summary_tokens": ["sets", "the", "resources", "for", "this", "operator"], "project": "flink"}
{"id": 2259, "code": "public void await() throws InterruptedException {\n    if (isReleasedOrReleasable()) {\n        return;\n    }\n\n    awaitLatchFile(watchService);\n}", "summary_tokens": ["waits", "until", "the", "latch", "file", "is", "created"], "project": "flink"}
{"id": 5026, "code": "int spillInMemoryPartition(\n        FileIOChannel.ID targetChannel,\n        IOManager ioManager,\n        LinkedBlockingQueue<MemorySegment> writeBehindBuffers)\n        throws IOException {\n    this.initialPartitionBuffersCount = partitionBuffers.length; \n    this.initialBuildSideChannel = targetChannel;\n\n    initialBuildSideWriter =\n            ioManager.createBlockChannelWriter(targetChannel, writeBehindBuffers);\n\n    final int numSegments = this.partitionBuffers.length;\n    for (int i = 0; i < numSegments; i++) {\n        initialBuildSideWriter.writeBlock(partitionBuffers[i]);\n    }\n    this.partitionBuffers = null;\n    initialBuildSideWriter.close();\n        \n    return numSegments;\n}", "summary_tokens": ["spills", "this", "partition", "to", "disk"], "project": "flink"}
{"id": 7550, "code": "public final LatencyMarker asLatencyMarker() {\n    return (LatencyMarker) this;\n}", "summary_tokens": ["casts", "this", "element", "into", "a", "latency", "marker"], "project": "flink"}
{"id": 8102, "code": "public static Expression objectToExpression(Object expression) {\n    if (expression == null) {\n        return valueLiteral(null, DataTypes.NULL());\n    } else if (expression instanceof ApiExpression) {\n        return ((ApiExpression) expression).toExpr();\n    } else if (expression instanceof Expression) {\n        return (Expression) expression;\n    } else if (expression instanceof Row) {\n        RowKind kind = ((Row) expression).getKind();\n        if (kind != RowKind.INSERT) {\n            throw new ValidationException(\n                    String.format(\n                            \"Unsupported kind '%s' of a row [%s]. Only rows with 'INSERT' kind are supported when\"\n                                    + \" converting to an expression.\",\n                            kind, expression));\n        }\n        return convertRow((Row) expression);\n    } else if (expression instanceof Map) {\n        return convertJavaMap((Map<?, ?>) expression);\n    } else if (expression instanceof byte[]) {\n            \n        return valueLiteral(expression);\n    } else if (expression.getClass().isArray()) {\n        return convertArray(expression);\n    } else if (expression instanceof List) {\n        return convertJavaList((List<?>) expression);\n    } else {\n        return convertScala(expression).orElseGet(() -> valueLiteral(expression));\n    }\n}", "summary_tokens": ["converts", "a", "given", "object", "to", "an", "expression"], "project": "flink"}
{"id": 4058, "code": "static RpcSystem load(Configuration config) {\n    final Iterator<RpcSystemLoader> iterator =\n            ServiceLoader.load(RpcSystemLoader.class).iterator();\n\n    Exception loadError = null;\n    while (iterator.hasNext()) {\n        final RpcSystemLoader next = iterator.next();\n        try {\n            return next.loadRpcSystem(config);\n        } catch (Exception e) {\n            loadError = ExceptionUtils.firstOrSuppressed(e, loadError);\n        }\n    }\n    throw new RpcLoaderException(\"Could not load RpcSystem.\", loadError);\n}", "summary_tokens": ["loads", "the", "rpc", "system"], "project": "flink"}
{"id": 695, "code": "public void runCancelingOnFullInputTest() throws Exception {\n    final String topic = \"cancelingOnFullTopic\";\n\n    final int parallelism = 3;\n    createTestTopic(topic, parallelism, 1);\n\n        \n    DataGenerators.InfiniteStringsGenerator generator =\n            new DataGenerators.InfiniteStringsGenerator(kafkaServer, topic);\n    generator.start();\n\n        \n\n    final AtomicReference<Throwable> jobError = new AtomicReference<>();\n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(parallelism);\n    env.enableCheckpointing(100);\n\n    Properties props = new Properties();\n    props.putAll(standardProps);\n    props.putAll(secureProps);\n    getStream(env, topic, new SimpleStringSchema(), props)\n            .addSink(new DiscardingSink<String>());\n\n    JobGraph jobGraph = StreamingJobGraphGenerator.createJobGraph(env.getStreamGraph());\n    final JobID jobId = jobGraph.getJobID();\n\n    final Runnable jobRunner =\n            () -> {\n                try {\n                    submitJobAndWaitForResult(client, jobGraph, getClass().getClassLoader());\n                } catch (Throwable t) {\n                    jobError.set(t);\n                }\n            };\n\n    Thread runnerThread = new Thread(jobRunner, \"program runner thread\");\n    runnerThread.start();\n\n        \n    Thread.sleep(2000);\n\n    Throwable failueCause = jobError.get();\n    if (failueCause != null) {\n        failueCause.printStackTrace();\n        Assert.fail(\"Test failed prematurely with: \" + failueCause.getMessage());\n    }\n\n        \n    client.cancel(jobId).get();\n\n        \n    runnerThread.join();\n\n    assertEquals(JobStatus.CANCELED, client.getJobStatus(jobId).get());\n\n    if (generator.isAlive()) {\n        generator.shutdown();\n        generator.join();\n    } else {\n        Throwable t = generator.getError();\n        if (t != null) {\n            t.printStackTrace();\n            fail(\"Generator failed: \" + t.getMessage());\n        } else {\n            fail(\"Generator failed with no exception\");\n        }\n    }\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["tests", "that", "the", "source", "can", "be", "properly", "canceled", "when", "reading", "full", "partitions"], "project": "flink"}
{"id": 8209, "code": "public static DataType newMapViewDataType(DataType keyDataType, DataType valueDataType) {\n    return DataTypes.STRUCTURED(\n            MapView.class,\n            DataTypes.FIELD(\n                    \"map\", DataTypes.MAP(keyDataType, valueDataType).bridgedTo(Map.class)));\n}", "summary_tokens": ["utility", "method", "for", "creating", "a", "data", "type", "of", "map", "view", "explicitly"], "project": "flink"}
{"id": 1364, "code": "public static <T> TypeInformation<T> of(TypeHint<T> typeHint) {\n    return typeHint.getTypeInfo();\n}", "summary_tokens": ["creates", "a", "type", "information", "for", "a", "generic", "type", "via", "a", "utility", "type", "hint"], "project": "flink"}
{"id": 5976, "code": "public void testDiscardingCheckpointsAtShutDown() throws Exception {\n    final SharedStateRegistry sharedStateRegistry = new SharedStateRegistryImpl();\n    final Configuration configuration = new Configuration();\n    configuration.setString(\n            HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, zooKeeperResource.getConnectString());\n\n    final CuratorFrameworkWithUnhandledErrorListener curatorFrameworkWrapper =\n            ZooKeeperUtils.startCuratorFramework(configuration, NoOpFatalErrorHandler.INSTANCE);\n    final CompletedCheckpointStore checkpointStore =\n            createZooKeeperCheckpointStore(curatorFrameworkWrapper.asCuratorFramework());\n\n    try {\n        final CompletedCheckpointStoreTest.TestCompletedCheckpoint checkpoint1 =\n                CompletedCheckpointStoreTest.createCheckpoint(0, sharedStateRegistry);\n\n        checkpointStore.addCheckpointAndSubsumeOldestOne(\n                checkpoint1, new CheckpointsCleaner(), () -> {});\n        assertThat(checkpointStore.getAllCheckpoints(), Matchers.contains(checkpoint1));\n\n        checkpointStore.shutdown(JobStatus.FINISHED, new CheckpointsCleaner());\n\n            \n        CompletedCheckpointStoreTest.verifyCheckpointDiscarded(checkpoint1);\n    } finally {\n        curatorFrameworkWrapper.close();\n    }\n}", "summary_tokens": ["tests", "that", "checkpoints", "are", "discarded", "when", "the", "completed", "checkpoint", "store", "is", "shut", "down", "with", "a", "globally", "terminal", "state"], "project": "flink"}
{"id": 9000, "code": "private StreamPhysicalCalc projectWith(\n        RelBuilder relBuilder, StreamPhysicalCalc projectFromCalc, StreamPhysicalCalc calc) {\n    final RexProgramBuilder programBuilder =\n            new RexProgramBuilder(calc.getRowType(), relBuilder.getRexBuilder());\n    if (calc.getProgram().getCondition() != null) {\n        programBuilder.addCondition(\n                calc.getProgram().expandLocalRef(calc.getProgram().getCondition()));\n    }\n\n    for (Pair<RexLocalRef, String> projectRef :\n            projectFromCalc.getProgram().getNamedProjects()) {\n        final RexNode project = projectFromCalc.getProgram().expandLocalRef(projectRef.left);\n        programBuilder.addProject(project, projectRef.right);\n    }\n\n    final RexProgram newProgram = programBuilder.getProgram();\n    return (StreamPhysicalCalc) calc.copy(calc.getTraitSet(), calc.getInput(), newProgram);\n}", "summary_tokens": ["returns", "a", "stream", "physical", "calc", "which", "is", "a", "copy", "of", "calc", "but", "with", "the", "projections", "applied", "from", "project", "from", "calc"], "project": "flink"}
{"id": 5007, "code": "private void compactOrThrow() throws IOException {\n    if (holes > (double) recordArea.getTotalSize() * 0.05) {\n        rebuild();\n    } else {\n        throw new EOFException(\n                \"InPlaceMutableHashTable memory ran out. \" + getMemoryConsumptionString());\n    }\n}", "summary_tokens": ["if", "there", "is", "wasted", "space", "due", "to", "updated", "records", "not", "fitting", "in", "their", "old", "places", "then", "do", "a", "compaction"], "project": "flink"}
{"id": 8415, "code": "public static void validateFactoryOptions(\n        Set<ConfigOption<?>> requiredOptions,\n        Set<ConfigOption<?>> optionalOptions,\n        ReadableConfig options) {\n        \n        \n\n    final List<String> missingRequiredOptions =\n            requiredOptions.stream()\n                        \n                        \n                    .filter(\n                            option ->\n                                    allKeys(option)\n                                            .noneMatch(k -> k.contains(PLACEHOLDER_SYMBOL)))\n                    .filter(option -> readOption(options, option) == null)\n                    .map(ConfigOption::key)\n                    .sorted()\n                    .collect(Collectors.toList());\n\n    if (!missingRequiredOptions.isEmpty()) {\n        throw new ValidationException(\n                String.format(\n                        \"One or more required options are missing.\\n\\n\"\n                                + \"Missing required options are:\\n\\n\"\n                                + \"%s\",\n                        String.join(\"\\n\", missingRequiredOptions)));\n    }\n\n    optionalOptions.forEach(option -> readOption(options, option));\n}", "summary_tokens": ["validates", "the", "required", "options", "and", "optional", "options"], "project": "flink"}
{"id": 456, "code": "public Optional<Range> decimalPrecisionRange() {\n    return Optional.empty();\n}", "summary_tokens": ["the", "inclusive", "range", "min", "max", "of", "supported", "precisions", "for", "decimal", "type", "columns"], "project": "flink"}
{"id": 5114, "code": "public void unregisterListener(JobID jobId) {\n    listeners.remove(jobId);\n}", "summary_tokens": ["unregisters", "the", "listener", "with", "the", "registry"], "project": "flink"}
{"id": 7733, "code": "public void executeBenchmark(long records, boolean flushAfterLastEmit) throws Exception {\n    final LongValue value = new LongValue();\n    value.setValue(0);\n\n    CompletableFuture<?> recordsReceived = receiver.setExpectedRecord(records);\n\n    for (int i = 1; i < records; i++) {\n        recordWriter.emit(value);\n    }\n    value.setValue(records);\n    recordWriter.broadcastEmit(value);\n    if (flushAfterLastEmit) {\n        recordWriter.flushAll();\n    }\n\n    recordsReceived.get(RECEIVER_TIMEOUT, TimeUnit.MILLISECONDS);\n}", "summary_tokens": ["executes", "the", "latency", "benchmark", "with", "the", "given", "number", "of", "records"], "project": "flink"}
{"id": 7622, "code": "public void testFallbackStrategyOnClientSideWhenCheckpointingEnabled() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.enableCheckpointing(500);\n\n    env.fromElements(1).print();\n\n    StreamGraph graph = env.getStreamGraph();\n    JobGraph jobGraph = graph.getJobGraph();\n\n    RestartStrategies.RestartStrategyConfiguration restartStrategy =\n            jobGraph.getSerializedExecutionConfig()\n                    .deserializeValue(getClass().getClassLoader())\n                    .getRestartStrategy();\n\n    Assert.assertNotNull(restartStrategy);\n    Assert.assertTrue(\n            restartStrategy instanceof RestartStrategies.FallbackRestartStrategyConfiguration);\n}", "summary_tokens": ["tests", "that", "in", "a", "streaming", "use", "case", "where", "checkpointing", "is", "enabled", "there", "is", "no", "default", "strategy", "set", "on", "the", "client", "side"], "project": "flink"}
{"id": 2989, "code": "public static String getNamespacedInternalServiceName(String clusterId, String namespace) {\n    return getInternalServiceName(clusterId) + \".\" + namespace;\n}", "summary_tokens": ["generate", "namespaced", "name", "of", "the", "internal", "service"], "project": "flink"}
{"id": 4930, "code": "public static SSLContext createRestSSLContext(Configuration config, boolean clientMode)\n        throws Exception {\n    ClientAuth clientAuth =\n            SecurityOptions.isRestSSLAuthenticationEnabled(config)\n                    ? ClientAuth.REQUIRE\n                    : ClientAuth.NONE;\n    JdkSslContext nettySSLContext =\n            (JdkSslContext) createRestNettySSLContext(config, clientMode, clientAuth, JDK);\n    if (nettySSLContext != null) {\n        return nettySSLContext.context();\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["creates", "an", "ssl", "context", "for", "clients", "against", "the", "external", "rest", "endpoint"], "project": "flink"}
{"id": 818, "code": "public PollingRecordPublisher create(\n        final StartingPosition startingPosition,\n        final Properties consumerConfig,\n        final MetricGroup metricGroup,\n        final StreamShardHandle streamShardHandle)\n        throws InterruptedException {\n    Preconditions.checkNotNull(startingPosition);\n    Preconditions.checkNotNull(consumerConfig);\n    Preconditions.checkNotNull(metricGroup);\n    Preconditions.checkNotNull(streamShardHandle);\n\n    final PollingRecordPublisherConfiguration configuration =\n            new PollingRecordPublisherConfiguration(consumerConfig);\n    final PollingRecordPublisherMetricsReporter metricsReporter =\n            new PollingRecordPublisherMetricsReporter(metricGroup);\n    final KinesisProxyInterface kinesisProxy = kinesisProxyFactory.create(consumerConfig);\n\n    if (configuration.isAdaptiveReads()) {\n        return new AdaptivePollingRecordPublisher(\n                startingPosition,\n                streamShardHandle,\n                metricsReporter,\n                kinesisProxy,\n                configuration.getMaxNumberOfRecordsPerFetch(),\n                configuration.getFetchIntervalMillis());\n    } else {\n        return new PollingRecordPublisher(\n                startingPosition,\n                streamShardHandle,\n                metricsReporter,\n                kinesisProxy,\n                configuration.getMaxNumberOfRecordsPerFetch(),\n                configuration.getFetchIntervalMillis());\n    }\n}", "summary_tokens": ["create", "a", "polling", "record", "publisher"], "project": "flink"}
{"id": 9080, "code": "private SerializationRuntimeConverter createConverter(\n        LogicalType type, String charsetName, boolean isBigEndian) {\n    final SerializationRuntimeConverter converter =\n            createNotNullConverter(type, charsetName, isBigEndian);\n\n    return new SerializationRuntimeConverter() {\n        private static final long serialVersionUID = 1L;\n\n        @Override\n        public void open() {\n            converter.open();\n        }\n\n        @Override\n        public byte[] convert(RowData row) throws IOException {\n            if (row.isNullAt(0)) {\n                return null;\n            }\n            return converter.convert(row);\n        }\n    };\n}", "summary_tokens": ["creates", "a", "runtime", "converter"], "project": "flink"}
{"id": 4935, "code": "protected void initInputReaders() throws Exception {\n    final int numInputs = getNumTaskInputs();\n    final MutableReader<?>[] inputReaders = new MutableReader<?>[numInputs];\n\n    int currentReaderOffset = 0;\n\n    for (int i = 0; i < numInputs; i++) {\n            \n            \n        final int groupSize = this.config.getGroupSize(i);\n\n        if (groupSize == 1) {\n                \n            inputReaders[i] =\n                    new MutableRecordReader<>(\n                            getEnvironment().getInputGate(currentReaderOffset),\n                            getEnvironment().getTaskManagerInfo().getTmpDirectories());\n        } else if (groupSize > 1) {\n                \n            IndexedInputGate[] readers = new IndexedInputGate[groupSize];\n            for (int j = 0; j < groupSize; ++j) {\n                readers[j] = getEnvironment().getInputGate(currentReaderOffset + j);\n            }\n            inputReaders[i] =\n                    new MutableRecordReader<>(\n                            new UnionInputGate(readers),\n                            getEnvironment().getTaskManagerInfo().getTmpDirectories());\n        } else {\n            throw new Exception(\"Illegal input group size in task configuration: \" + groupSize);\n        }\n\n        currentReaderOffset += groupSize;\n    }\n    this.inputReaders = inputReaders;\n\n        \n    if (currentReaderOffset != this.config.getNumInputs()) {\n        throw new Exception(\n                \"Illegal configuration: Number of input gates and group sizes are not consistent.\");\n    }\n}", "summary_tokens": ["creates", "the", "record", "readers", "for", "the", "number", "of", "inputs", "as", "defined", "by", "get", "num", "task", "inputs"], "project": "flink"}
{"id": 7190, "code": "public void setForceCheckpointing(boolean forceCheckpointing) {\n    this.forceCheckpointing = forceCheckpointing;\n}", "summary_tokens": ["checks", "whether", "checkpointing", "is", "forced", "despite", "currently", "non", "checkpointable", "iteration", "feedback"], "project": "flink"}
{"id": 1821, "code": "static long getByteBufferAddress(ByteBuffer buffer) {\n    Preconditions.checkNotNull(buffer, \"buffer is null\");\n    Preconditions.checkArgument(\n            buffer.isDirect(), \"Can't get address of a non-direct ByteBuffer.\");\n\n    long offHeapAddress;\n    try {\n        offHeapAddress = UNSAFE.getLong(buffer, BUFFER_ADDRESS_FIELD_OFFSET);\n    } catch (Throwable t) {\n        throw new Error(\"Could not access direct byte buffer address field.\", t);\n    }\n\n    Preconditions.checkState(offHeapAddress > 0, \"negative pointer or size\");\n    Preconditions.checkState(\n            offHeapAddress < Long.MAX_VALUE - Integer.MAX_VALUE,\n            \"Segment initialized with too large address: \"\n                    + offHeapAddress\n                    + \" ; Max allowed address is \"\n                    + (Long.MAX_VALUE - Integer.MAX_VALUE - 1));\n\n    return offHeapAddress;\n}", "summary_tokens": ["get", "native", "memory", "address", "wrapped", "by", "the", "given", "byte", "buffer"], "project": "flink"}
{"id": 9621, "code": "public void testRunIsolatedJob() throws Exception {\n    LocalStreamEnvironment env = new LocalStreamEnvironment();\n    assertEquals(1, env.getParallelism());\n\n    addSmallBoundedJob(env, 3);\n    env.execute();\n}", "summary_tokens": ["test", "test", "verifies", "that", "the", "execution", "environment", "can", "be", "used", "to", "execute", "a", "single", "job", "with", "multiple", "slots"], "project": "flink"}
{"id": 6645, "code": "public void handlesConcurrentJobAdditionsAndLeaderChanges() throws Exception {\n    final JobLeaderService jobLeaderService =\n            new DefaultJobLeaderService(\n                    new LocalUnresolvedTaskManagerLocation(),\n                    RetryingRegistrationConfiguration.defaultConfiguration());\n\n    final TestingJobLeaderListener jobLeaderListener = new TestingJobLeaderListener();\n    final int numberOperations = 20;\n    final BlockingQueue<SettableLeaderRetrievalService> instantiatedLeaderRetrievalServices =\n            new ArrayBlockingQueue<>(numberOperations);\n\n    final HighAvailabilityServices haServices =\n            new TestingHighAvailabilityServicesBuilder()\n                    .setJobMasterLeaderRetrieverFunction(\n                            leaderForJobId -> {\n                                final SettableLeaderRetrievalService leaderRetrievalService =\n                                        new SettableLeaderRetrievalService();\n                                instantiatedLeaderRetrievalServices.offer(\n                                        leaderRetrievalService);\n                                return leaderRetrievalService;\n                            })\n                    .build();\n\n    jobLeaderService.start(\n            \"foobar\", rpcServiceResource.getTestingRpcService(), haServices, jobLeaderListener);\n\n    final CheckedThread addJobAction =\n            new CheckedThread() {\n                @Override\n                public void go() throws Exception {\n                    for (int i = 0; i < numberOperations; i++) {\n                        final JobID jobId = JobID.generate();\n                        jobLeaderService.addJob(jobId, \"foobar\");\n                        Thread.yield();\n                        jobLeaderService.removeJob(jobId);\n                    }\n                }\n            };\n    addJobAction.start();\n\n    for (int i = 0; i < numberOperations; i++) {\n        final SettableLeaderRetrievalService leaderRetrievalService =\n                instantiatedLeaderRetrievalServices.take();\n        leaderRetrievalService.notifyListener(\"foobar\", UUID.randomUUID());\n    }\n\n    addJobAction.sync();\n}", "summary_tokens": ["tests", "that", "we", "can", "concurrently", "modify", "the", "job", "leader", "service", "and", "complete", "the", "leader", "retrieval", "operation"], "project": "flink"}
{"id": 721, "code": "private void testKafkaShuffleFailureRecovery(\n        int numElementsPerProducer, TimeCharacteristic timeCharacteristic) throws Exception {\n\n    String topic = topic(\"failure_recovery\", timeCharacteristic);\n    final int numberOfPartitions = 1;\n    final int producerParallelism = 1;\n    final int failAfterElements = numElementsPerProducer * numberOfPartitions * 2 / 3;\n\n    createTestTopic(topic, numberOfPartitions, 1);\n\n    final StreamExecutionEnvironment env =\n            createEnvironment(producerParallelism, timeCharacteristic).enableCheckpointing(500);\n\n    createKafkaShuffle(\n                    env,\n                    topic,\n                    numElementsPerProducer,\n                    producerParallelism,\n                    timeCharacteristic,\n                    numberOfPartitions)\n            .map(new FailingIdentityMapper<>(failAfterElements))\n            .setParallelism(1)\n            .map(new ToInteger(producerParallelism))\n            .setParallelism(1)\n            .addSink(\n                    new ValidatingExactlyOnceSink(numElementsPerProducer * producerParallelism))\n            .setParallelism(1);\n\n    FailingIdentityMapper.failedBefore = false;\n\n    tryExecute(env, topic);\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["to", "test", "failure", "recovery", "after", "processing", "0", "0", "data"], "project": "flink"}
{"id": 4312, "code": "public long getLatestAckTimestamp() {\n    SubtaskStateStats subtask = latestAckedSubtaskStats;\n    if (subtask != null) {\n        return subtask.getAckTimestamp();\n    } else {\n        return -1;\n    }\n}", "summary_tokens": ["ack", "timestamp", "of", "the", "latest", "acknowledged", "subtask", "or", "code", "0", "code", "if", "none", "was", "acknowledged", "yet"], "project": "flink"}
{"id": 8112, "code": "public List<FieldReferenceExpression> getAllInputFields() {\n    return fieldReferences.stream().flatMap(input -> input.values().stream()).collect(toList());\n}", "summary_tokens": ["gives", "all", "fields", "of", "underlying", "inputs", "in", "order", "of", "those", "inputs", "and", "order", "of", "fields", "within", "input"], "project": "flink"}
{"id": 3879, "code": "public Iterator<Map.Entry<K, V>> iterator() {\n    return Collections.unmodifiableSet(state.entrySet()).iterator();\n}", "summary_tokens": ["iterates", "over", "all", "the", "mappings", "in", "the", "state"], "project": "flink"}
{"id": 8866, "code": "public List<String> mergePartitions(\n        MergingStrategy mergingStrategy,\n        List<String> sourcePartitions,\n        List<String> derivedPartitions) {\n\n    if (!derivedPartitions.isEmpty()\n            && !sourcePartitions.isEmpty()\n            && mergingStrategy != MergingStrategy.EXCLUDING) {\n        throw new ValidationException(\n                \"The base table already has partitions defined. You might want to specify \"\n                        + \"EXCLUDING PARTITIONS.\");\n    }\n\n    if (!derivedPartitions.isEmpty()) {\n        return derivedPartitions;\n    }\n    return sourcePartitions;\n}", "summary_tokens": ["merges", "the", "partitions", "part", "of", "create", "table", "statement"], "project": "flink"}
{"id": 2927, "code": "public void testOutOfTupleBoundsDataset2() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    DataSet<Tuple5<Integer, Long, String, Long, Integer>> tupleDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo);\n\n        \n    tupleDs.maxBy(-1);\n}", "summary_tokens": ["this", "test", "validates", "that", "an", "index", "which", "is", "out", "of", "bounds", "throws", "an", "index", "out", "of", "bounds", "exception"], "project": "flink"}
{"id": 8742, "code": "private static <E> boolean replaceLast(List<E> list, E oldVal, E newVal) {\n    final int index = list.lastIndexOf(oldVal);\n    if (index < 0) {\n        return false;\n    }\n    list.set(index, newVal);\n    return true;\n}", "summary_tokens": ["replaces", "the", "last", "occurrence", "of", "one", "specified", "value", "in", "a", "list", "with", "another"], "project": "flink"}
{"id": 7388, "code": "protected void markCanceledOrStopped() {\n    this.canceledOrStopped = true;\n}", "summary_tokens": ["marks", "this", "source", "as", "canceled", "or", "stopped"], "project": "flink"}
{"id": 1338, "code": "public boolean isSerializerInitialized() {\n    return serializerAtomicReference.get() != null;\n}", "summary_tokens": ["checks", "whether", "the", "serializer", "has", "been", "initialized"], "project": "flink"}
{"id": 177, "code": "public CassandraSink<IN> slotSharingGroup(String slotSharingGroup) {\n    if (useDataStreamSink) {\n        getSinkTransformation().setSlotSharingGroup(slotSharingGroup);\n    } else {\n        getTransformation().setSlotSharingGroup(slotSharingGroup);\n    }\n    return this;\n}", "summary_tokens": ["sets", "the", "slot", "sharing", "group", "of", "this", "operation"], "project": "flink"}
{"id": 8002, "code": "default Table limit(int offset, int fetch) {\n    return offset(offset).fetch(fetch);\n}", "summary_tokens": ["limits", "a", "possibly", "sorted", "result", "to", "the", "first", "n", "rows", "from", "an", "offset", "position"], "project": "flink"}
{"id": 8247, "code": "public final String asSummaryString() {\n    return String.format(\n            \"CONSTRAINT %s %s (%s)%s\",\n            EncodingUtils.escapeIdentifier(getName()),\n            getTypeString(),\n            columns.stream()\n                    .map(EncodingUtils::escapeIdentifier)\n                    .collect(Collectors.joining(\", \")),\n            isEnforced() ? \"\" : \" NOT ENFORCED\");\n}", "summary_tokens": ["returns", "constraint", "s", "summary"], "project": "flink"}
{"id": 2687, "code": "public void registerType(Class<?> type) {\n    if (type == null) {\n        throw new NullPointerException(\"Cannot register null type class.\");\n    }\n\n    TypeInformation<?> typeInfo = TypeExtractor.createTypeInfo(type);\n\n    if (typeInfo instanceof PojoTypeInfo) {\n        config.registerPojoType(type);\n    } else {\n        config.registerKryoType(type);\n    }\n}", "summary_tokens": ["registers", "the", "given", "type", "with", "the", "serialization", "stack"], "project": "flink"}
{"id": 1528, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple25)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple25 tuple = (Tuple25) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    if (f5 != null ? !f5.equals(tuple.f5) : tuple.f5 != null) {\n        return false;\n    }\n    if (f6 != null ? !f6.equals(tuple.f6) : tuple.f6 != null) {\n        return false;\n    }\n    if (f7 != null ? !f7.equals(tuple.f7) : tuple.f7 != null) {\n        return false;\n    }\n    if (f8 != null ? !f8.equals(tuple.f8) : tuple.f8 != null) {\n        return false;\n    }\n    if (f9 != null ? !f9.equals(tuple.f9) : tuple.f9 != null) {\n        return false;\n    }\n    if (f10 != null ? !f10.equals(tuple.f10) : tuple.f10 != null) {\n        return false;\n    }\n    if (f11 != null ? !f11.equals(tuple.f11) : tuple.f11 != null) {\n        return false;\n    }\n    if (f12 != null ? !f12.equals(tuple.f12) : tuple.f12 != null) {\n        return false;\n    }\n    if (f13 != null ? !f13.equals(tuple.f13) : tuple.f13 != null) {\n        return false;\n    }\n    if (f14 != null ? !f14.equals(tuple.f14) : tuple.f14 != null) {\n        return false;\n    }\n    if (f15 != null ? !f15.equals(tuple.f15) : tuple.f15 != null) {\n        return false;\n    }\n    if (f16 != null ? !f16.equals(tuple.f16) : tuple.f16 != null) {\n        return false;\n    }\n    if (f17 != null ? !f17.equals(tuple.f17) : tuple.f17 != null) {\n        return false;\n    }\n    if (f18 != null ? !f18.equals(tuple.f18) : tuple.f18 != null) {\n        return false;\n    }\n    if (f19 != null ? !f19.equals(tuple.f19) : tuple.f19 != null) {\n        return false;\n    }\n    if (f20 != null ? !f20.equals(tuple.f20) : tuple.f20 != null) {\n        return false;\n    }\n    if (f21 != null ? !f21.equals(tuple.f21) : tuple.f21 != null) {\n        return false;\n    }\n    if (f22 != null ? !f22.equals(tuple.f22) : tuple.f22 != null) {\n        return false;\n    }\n    if (f23 != null ? !f23.equals(tuple.f23) : tuple.f23 != null) {\n        return false;\n    }\n    if (f24 != null ? !f24.equals(tuple.f24) : tuple.f24 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 1363, "code": "public boolean isSortKeyType() {\n    return isKeyType();\n}", "summary_tokens": ["checks", "whether", "this", "type", "can", "be", "used", "as", "a", "key", "for", "sorting"], "project": "flink"}
{"id": 6447, "code": "public void testWorkerOnlyAllocatedIfRequestedSlotCouldBeFulfilled() throws Exception {\n    final AtomicInteger resourceRequests = new AtomicInteger(0);\n\n    new Context() {\n        {\n            resourceActionsBuilder.setAllocateResourceFunction(\n                    ignored -> {\n                        resourceRequests.incrementAndGet();\n                        return true;\n                    });\n            runTest(\n                    () -> {\n                        runInMainThread(\n                                () ->\n                                        getSlotManager()\n                                                .processResourceRequirements(\n                                                        createResourceRequirements(\n                                                                new JobID(),\n                                                                1,\n                                                                OTHER_SLOT_RESOURCE_PROFILE)));\n                        assertThat(resourceRequests.get(), is(0));\n                    });\n        }\n    };\n}", "summary_tokens": ["test", "that", "the", "slot", "manager", "only", "allocates", "new", "workers", "if", "their", "worker", "spec", "can", "fulfill", "the", "requested", "resource", "profile"], "project": "flink"}
{"id": 3782, "code": "public void testReJoinedBranches() {\n    try {\n            \n\n        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n        DataSet<Tuple2<Long, Long>> data =\n                env.fromElements(33L, 44L)\n                        .map(\n                                new MapFunction<Long, Tuple2<Long, Long>>() {\n                                    @Override\n                                    public Tuple2<Long, Long> map(Long value) {\n                                        return new Tuple2<Long, Long>(value, value);\n                                    }\n                                });\n\n        DataSet<Tuple2<Long, Long>> reduced =\n                data.groupBy(0).reduce(new SelectOneReducer<Tuple2<Long, Long>>());\n        reduced.output(new DiscardingOutputFormat<Tuple2<Long, Long>>());\n\n        DataSet<Tuple2<Long, Long>> filtered =\n                data.filter(\n                        new FilterFunction<Tuple2<Long, Long>>() {\n                            @Override\n                            public boolean filter(Tuple2<Long, Long> value) throws Exception {\n                                return false;\n                            }\n                        });\n\n        DataSet<Tuple2<Long, Long>> joined =\n                reduced.join(filtered)\n                        .where(1)\n                        .equalTo(1)\n                        .with(new DummyFlatJoinFunction<Tuple2<Long, Long>>());\n\n        joined.flatMap(new IdentityFlatMapper<Tuple2<Long, Long>>())\n                .output(new DiscardingOutputFormat<Tuple2<Long, Long>>());\n\n        joined.coGroup(\n                        filtered.groupBy(1)\n                                .reduceGroup(new Top1GroupReducer<Tuple2<Long, Long>>()))\n                .where(0)\n                .equalTo(0)\n                .with(new DummyCoGroupFunction<Tuple2<Long, Long>, Tuple2<Long, Long>>())\n                .output(\n                        new DiscardingOutputFormat<\n                                Tuple2<Tuple2<Long, Long>, Tuple2<Long, Long>>>());\n\n        List<DataSinkNode> sinks = convertPlan(env.createProgramPlan());\n\n            \n\n        DataSinkNode sinkAfterReduce = sinks.get(0);\n        DataSinkNode sinkAfterFlatMap = sinks.get(1);\n        DataSinkNode sinkAfterCoGroup = sinks.get(2);\n\n        SingleInputNode reduceNode = (SingleInputNode) sinkAfterReduce.getPredecessorNode();\n        SingleInputNode mapNode = (SingleInputNode) reduceNode.getPredecessorNode();\n\n        SingleInputNode flatMapNode = (SingleInputNode) sinkAfterFlatMap.getPredecessorNode();\n        TwoInputNode joinNode = (TwoInputNode) flatMapNode.getPredecessorNode();\n        SingleInputNode filterNode = (SingleInputNode) joinNode.getSecondPredecessorNode();\n\n        TwoInputNode coGroupNode = (TwoInputNode) sinkAfterCoGroup.getPredecessorNode();\n        SingleInputNode otherReduceNode =\n                (SingleInputNode) coGroupNode.getSecondPredecessorNode();\n\n            \n\n        assertEquals(reduceNode, joinNode.getFirstPredecessorNode());\n        assertEquals(mapNode, filterNode.getPredecessorNode());\n        assertEquals(joinNode, coGroupNode.getFirstPredecessorNode());\n        assertEquals(filterNode, otherReduceNode.getPredecessorNode());\n\n            \n\n        assertFalse(sinkAfterReduce.getInputConnection().isBreakingPipeline());\n        assertFalse(sinkAfterFlatMap.getInputConnection().isBreakingPipeline());\n        assertFalse(sinkAfterCoGroup.getInputConnection().isBreakingPipeline());\n\n        assertFalse(mapNode.getIncomingConnection().isBreakingPipeline());\n        assertFalse(flatMapNode.getIncomingConnection().isBreakingPipeline());\n        assertFalse(joinNode.getFirstIncomingConnection().isBreakingPipeline());\n        assertFalse(coGroupNode.getFirstIncomingConnection().isBreakingPipeline());\n        assertFalse(coGroupNode.getSecondIncomingConnection().isBreakingPipeline());\n\n            \n        assertTrue(reduceNode.getIncomingConnection().isBreakingPipeline());\n        assertTrue(filterNode.getIncomingConnection().isBreakingPipeline());\n        assertTrue(otherReduceNode.getIncomingConnection().isBreakingPipeline());\n        assertTrue(joinNode.getSecondIncomingConnection().isBreakingPipeline());\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["tests", "that", "branches", "that", "are", "re", "joined", "have", "place", "pipeline", "breakers"], "project": "flink"}
{"id": 3957, "code": "public void testRequestSerializationWithZeroLengthKeyAndNamespace() throws Exception {\n\n    long requestId = Integer.MAX_VALUE + 1337L;\n    KvStateID kvStateId = new KvStateID();\n    byte[] serializedKeyAndNamespace = new byte[0];\n\n    final KvStateInternalRequest request =\n            new KvStateInternalRequest(kvStateId, serializedKeyAndNamespace);\n    final MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    ByteBuf buf = MessageSerializer.serializeRequest(alloc, requestId, request);\n\n    int frameLength = buf.readInt();\n    assertEquals(MessageType.REQUEST, MessageSerializer.deserializeHeader(buf));\n    assertEquals(requestId, MessageSerializer.getRequestId(buf));\n    KvStateInternalRequest requestDeser = serializer.deserializeRequest(buf);\n\n    assertEquals(buf.readerIndex(), frameLength + 4);\n\n    assertEquals(kvStateId, requestDeser.getKvStateId());\n    assertArrayEquals(serializedKeyAndNamespace, requestDeser.getSerializedKeyAndNamespace());\n}", "summary_tokens": ["tests", "request", "serialization", "with", "zero", "length", "serialized", "key", "and", "namespace"], "project": "flink"}
{"id": 2109, "code": "public static <IN> CompletableFuture<Void> thenAcceptAsyncIfNotDone(\n        CompletableFuture<IN> completableFuture,\n        Executor executor,\n        Consumer<? super IN> consumer) {\n    return completableFuture.isDone()\n            ? completableFuture.thenAccept(consumer)\n            : completableFuture.thenAcceptAsync(consumer, executor);\n}", "summary_tokens": ["this", "function", "takes", "a", "completable", "future", "and", "a", "consumer", "to", "accept", "the", "result", "of", "this", "future"], "project": "flink"}
{"id": 9093, "code": "public static BinaryStringData concat(BinaryStringData... inputs) {\n    return concat(Arrays.asList(inputs));\n}", "summary_tokens": ["concatenates", "input", "strings", "together", "into", "a", "single", "string"], "project": "flink"}
{"id": 2548, "code": "private static void validateDecodingFormatOptions(ReadableConfig tableOptions) {\n    JsonFormatOptionsUtil.validateDecodingFormatOptions(tableOptions);\n}", "summary_tokens": ["validator", "for", "canal", "decoding", "format"], "project": "flink"}
{"id": 4763, "code": "public void setClasspaths(List<URL> paths) {\n    classpaths = paths;\n}", "summary_tokens": ["sets", "the", "classpaths", "required", "to", "run", "the", "job", "on", "a", "task", "manager"], "project": "flink"}
{"id": 1159, "code": "public long getAccumulatedRecordCount() {\n    return this.accumulatedRecordCount;\n}", "summary_tokens": ["returns", "the", "accumulated", "record", "count"], "project": "flink"}
{"id": 7039, "code": "public DataStream<IN1> getFirstInput() {\n    return inputStream1;\n}", "summary_tokens": ["returns", "the", "first", "data", "stream"], "project": "flink"}
{"id": 7079, "code": "public DataStreamSink<T> writeToSocket(\n        String hostName, int port, SerializationSchema<T> schema) {\n    DataStreamSink<T> returnStream = addSink(new SocketClientSink<>(hostName, port, schema, 0));\n    returnStream.setParallelism(\n            1); \n    return returnStream;\n}", "summary_tokens": ["writes", "the", "data", "stream", "to", "a", "socket", "as", "a", "byte", "array"], "project": "flink"}
{"id": 896, "code": "public PulsarSourceBuilder<OUT> setTopicPattern(\n        Pattern topicsPattern, RegexSubscriptionMode regexSubscriptionMode) {\n    ensureSubscriberIsNull(\"topic pattern\");\n    this.subscriber =\n            PulsarSubscriber.getTopicPatternSubscriber(topicsPattern, regexSubscriptionMode);\n    return this;\n}", "summary_tokens": ["set", "a", "topic", "pattern", "to", "consume", "from", "the", "java", "pattern"], "project": "flink"}
{"id": 4079, "code": "public SimpleHttpResponse getNextResponse(Duration timeout)\n        throws InterruptedException, TimeoutException {\n\n    SimpleHttpResponse response = responses.poll(timeout.toMillis(), TimeUnit.MILLISECONDS);\n\n    if (response == null) {\n        throw new TimeoutException(\"No response within timeout of \" + timeout + \" ms\");\n    } else {\n        return response;\n    }\n}", "summary_tokens": ["returns", "the", "next", "available", "http", "response"], "project": "flink"}
{"id": 8751, "code": "protected SqlNode getSelfJoinExprForUpdate(SqlNode table, String alias) {\n    return null;\n}", "summary_tokens": ["allows", "a", "subclass", "to", "provide", "information", "about", "how", "to", "convert", "an", "update", "into", "a", "merge", "via", "self", "join"], "project": "flink"}
{"id": 2822, "code": "public UnsortedGrouping<T> withPartitioner(Partitioner<?> partitioner) {\n    Preconditions.checkNotNull(partitioner);\n    getKeys().validateCustomPartitioner(partitioner, null);\n\n    this.customPartitioner = partitioner;\n    return this;\n}", "summary_tokens": ["uses", "a", "custom", "partitioner", "for", "the", "grouping"], "project": "flink"}
{"id": 603, "code": "public List<E> getBatchBlocking(long timeoutMillis) throws InterruptedException {\n    if (timeoutMillis == 0L) {\n            \n        return getBatchBlocking();\n    } else if (timeoutMillis < 0L) {\n        throw new IllegalArgumentException(\"invalid timeout\");\n    }\n\n    final long deadline = System.nanoTime() + timeoutMillis * 1_000_000L;\n\n    lock.lock();\n    try {\n        while (open && elements.isEmpty() && timeoutMillis > 0) {\n            nonEmpty.await(timeoutMillis, TimeUnit.MILLISECONDS);\n            timeoutMillis = (deadline - System.nanoTime()) / 1_000_000L;\n        }\n\n        if (!open) {\n            throw new IllegalStateException(\"queue is closed\");\n        } else if (elements.isEmpty()) {\n            return Collections.emptyList();\n        } else {\n            ArrayList<E> result = new ArrayList<>(elements);\n            elements.clear();\n            return result;\n        }\n    } finally {\n        lock.unlock();\n    }\n}", "summary_tokens": ["gets", "all", "the", "elements", "found", "in", "the", "list", "or", "blocks", "until", "at", "least", "one", "element", "was", "added"], "project": "flink"}
{"id": 5466, "code": "public StateTable<K, N, SV> getStateTable() {\n    return stateTable;\n}", "summary_tokens": ["this", "should", "only", "be", "used", "for", "testing"], "project": "flink"}
{"id": 1156, "code": "public long getFirstRecordStart() {\n    return this.firstRecordStart;\n}", "summary_tokens": ["returns", "the", "first", "record", "start"], "project": "flink"}
{"id": 1873, "code": "public int getArity() {\n    if (fieldByPosition != null) {\n        return fieldByPosition.length;\n    } else {\n        assert fieldByName != null;\n        return fieldByName.size();\n    }\n}", "summary_tokens": ["returns", "the", "number", "of", "fields", "in", "the", "row"], "project": "flink"}
{"id": 5963, "code": "public void testAddNonPositiveStats() throws Exception {\n    StatsSummary mma = new StatsSummary();\n    mma.add(-1);\n\n    assertEquals(0, mma.getMinimum());\n    assertEquals(0, mma.getMaximum());\n    assertEquals(0, mma.getSum());\n    assertEquals(0, mma.getCount());\n    assertEquals(0, mma.getAverage());\n\n    mma.add(0);\n\n    assertEquals(0, mma.getMinimum());\n    assertEquals(0, mma.getMaximum());\n    assertEquals(0, mma.getSum());\n    assertEquals(1, mma.getCount());\n    assertEquals(0, mma.getAverage());\n}", "summary_tokens": ["test", "that", "non", "positive", "numbers", "are", "not", "counted"], "project": "flink"}
{"id": 9307, "code": "public void close() throws Exception {}", "summary_tokens": ["the", "tear", "down", "method", "of", "the", "function"], "project": "flink"}
{"id": 4661, "code": "protected boolean canBeCompressed(Buffer buffer) {\n    return bufferCompressor != null && buffer.isBuffer() && buffer.readableBytes() > 0;\n}", "summary_tokens": ["whether", "the", "buffer", "can", "be", "compressed", "or", "not"], "project": "flink"}
{"id": 8020, "code": "public long getMinIdleStateRetentionTime() {\n    return configuration.get(ExecutionConfigOptions.IDLE_STATE_RETENTION).toMillis();\n}", "summary_tokens": ["note", "currently", "the", "concept", "of", "min", "max", "idle", "state", "retention", "has", "been", "deprecated", "and", "only", "idle", "state", "retention", "time", "is", "supported"], "project": "flink"}
{"id": 4047, "code": "public String getHostname() {\n    return rpcServer.getHostname();\n}", "summary_tokens": ["gets", "the", "hostname", "of", "the", "underlying", "rpc", "endpoint"], "project": "flink"}
{"id": 6679, "code": "public void testInterruptibleSharedLockInInvokeAndCancel() throws Exception {\n    final TaskManagerActions taskManagerActions = new ProhibitFatalErrorTaskManagerActions();\n\n    final Configuration config = new Configuration();\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_INTERVAL, 5);\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT, 50);\n\n    final Task task =\n            createTaskBuilder()\n                    .setInvokable(InvokableInterruptibleSharedLockInInvokeAndCancel.class)\n                    .setTaskManagerConfig(config)\n                    .setTaskManagerActions(taskManagerActions)\n                    .build();\n\n    task.startTaskThread();\n\n    awaitLatch.await();\n\n    task.cancelExecution();\n    task.getExecutingThread().join();\n}", "summary_tokens": ["the", "invoke", "method", "holds", "a", "lock", "trigger", "await", "latch", "after", "acquisition", "and", "cancel", "cannot", "complete", "because", "it", "also", "tries", "to", "acquire", "the", "same", "lock"], "project": "flink"}
{"id": 3657, "code": "public FieldList getGroupedFields() {\n    return this.groupedFields;\n}", "summary_tokens": ["gets", "the", "grouped", "fields"], "project": "flink"}
{"id": 5410, "code": "public byte[] build() throws IOException {\n    return keyOutView.getCopyOfBuffer();\n}", "summary_tokens": ["returns", "a", "serialized", "composite", "key", "from", "whatever", "was", "set", "so", "far"], "project": "flink"}
{"id": 4512, "code": "public long getBytesWritten() {\n    return this.bytesBeforeSegment + getCurrentPositionInSegment() - HEADER_LENGTH;\n}", "summary_tokens": ["gets", "the", "number", "of", "pay", "load", "bytes", "already", "written"], "project": "flink"}
{"id": 745, "code": "public void setDefaultPartition(String defaultPartition) {\n    this.defaultPartition = defaultPartition;\n}", "summary_tokens": ["set", "default", "partition", "id"], "project": "flink"}
{"id": 5514, "code": "public Path getSavepointPath() {\n    return location.getBaseSavepointPath();\n}", "summary_tokens": ["the", "default", "location", "where", "savepoints", "will", "be", "externalized", "if", "set"], "project": "flink"}
{"id": 739, "code": "public void setPeriodicWatermarkAssigner(\n        AssignerWithPeriodicWatermarks<T> periodicWatermarkAssigner) {\n    this.periodicWatermarkAssigner = periodicWatermarkAssigner;\n    ClosureCleaner.clean(\n            this.periodicWatermarkAssigner,\n            ExecutionConfig.ClosureCleanerLevel.RECURSIVE,\n            true);\n}", "summary_tokens": ["set", "the", "assigner", "that", "will", "extract", "the", "timestamp", "from", "t", "and", "calculate", "the", "watermark"], "project": "flink"}
{"id": 2178, "code": "public void testReconfigureDifferentSubclassRegistrationOrder() throws Exception {\n    ExecutionConfig executionConfig = new ExecutionConfig();\n    executionConfig.registerPojoType(SubTestUserClassA.class);\n    executionConfig.registerPojoType(SubTestUserClassB.class);\n\n    PojoSerializer<TestUserClass> pojoSerializer =\n            (PojoSerializer<TestUserClass>) type.createSerializer(executionConfig);\n\n        \n    int subClassATag = pojoSerializer.getRegisteredClasses().get(SubTestUserClassA.class);\n    int subClassBTag = pojoSerializer.getRegisteredClasses().get(SubTestUserClassB.class);\n\n        \n    TypeSerializerSnapshot pojoSerializerConfigSnapshot =\n            pojoSerializer.snapshotConfiguration();\n    byte[] serializedConfig;\n    try (ByteArrayOutputStream out = new ByteArrayOutputStream()) {\n        TypeSerializerSnapshotSerializationUtil.writeSerializerSnapshot(\n                new DataOutputViewStreamWrapper(out),\n                pojoSerializerConfigSnapshot,\n                pojoSerializer);\n        serializedConfig = out.toByteArray();\n    }\n\n        \n    executionConfig = new ExecutionConfig();\n    executionConfig.registerPojoType(\n            SubTestUserClassB.class); \n    executionConfig.registerPojoType(SubTestUserClassA.class);\n\n    pojoSerializer = (PojoSerializer<TestUserClass>) type.createSerializer(executionConfig);\n\n        \n    try (ByteArrayInputStream in = new ByteArrayInputStream(serializedConfig)) {\n        pojoSerializerConfigSnapshot =\n                TypeSerializerSnapshotSerializationUtil.readSerializerSnapshot(\n                        new DataInputViewStreamWrapper(in),\n                        Thread.currentThread().getContextClassLoader(),\n                        pojoSerializer);\n    }\n\n    @SuppressWarnings(\"unchecked\")\n    TypeSerializerSchemaCompatibility<TestUserClass> compatResult =\n            pojoSerializerConfigSnapshot.resolveSchemaCompatibility(pojoSerializer);\n    assertTrue(compatResult.isCompatibleWithReconfiguredSerializer());\n    assertThat(compatResult.getReconfiguredSerializer(), instanceOf(PojoSerializer.class));\n\n        \n        \n        \n    PojoSerializer<TestUserClass> reconfiguredPojoSerializer =\n            (PojoSerializer<TestUserClass>) compatResult.getReconfiguredSerializer();\n    assertEquals(\n            subClassATag,\n            reconfiguredPojoSerializer\n                    .getRegisteredClasses()\n                    .get(SubTestUserClassA.class)\n                    .intValue());\n    assertEquals(\n            subClassBTag,\n            reconfiguredPojoSerializer\n                    .getRegisteredClasses()\n                    .get(SubTestUserClassB.class)\n                    .intValue());\n}", "summary_tokens": ["tests", "that", "reconfiguration", "correctly", "reorders", "subclass", "registrations", "to", "their", "previous", "order"], "project": "flink"}
{"id": 8407, "code": "public static DynamicTableSink createDynamicTableSink(\n        @Nullable DynamicTableSinkFactory preferredFactory,\n        ObjectIdentifier objectIdentifier,\n        ResolvedCatalogTable catalogTable,\n        ReadableConfig configuration,\n        ClassLoader classLoader,\n        boolean isTemporary) {\n    final DefaultDynamicTableContext context =\n            new DefaultDynamicTableContext(\n                    objectIdentifier, catalogTable, configuration, classLoader, isTemporary);\n\n    try {\n        final DynamicTableSinkFactory factory =\n                preferredFactory != null\n                        ? preferredFactory\n                        : discoverTableFactory(DynamicTableSinkFactory.class, context);\n\n        return factory.createDynamicTableSink(context);\n    } catch (Throwable t) {\n        throw new ValidationException(\n                String.format(\n                        \"Unable to create a sink for writing table '%s'.\\n\\n\"\n                                + \"Table options are:\\n\\n\"\n                                + \"%s\",\n                        objectIdentifier.asSummaryString(),\n                        catalogTable.getOptions().entrySet().stream()\n                                .map(e -> stringifyOption(e.getKey(), e.getValue()))\n                                .sorted()\n                                .collect(Collectors.joining(\"\\n\"))),\n                t);\n    }\n}", "summary_tokens": ["creates", "a", "dynamic", "table", "sink", "from", "a", "catalog", "table"], "project": "flink"}
{"id": 9541, "code": "public Optional<Counter> getCounter(String... identifier) {\n    return getMetric(Counter.class, identifier);\n}", "summary_tokens": ["get", "registered", "counter", "with", "identifier", "relative", "to", "the", "root", "metric", "group"], "project": "flink"}
{"id": 1003, "code": "public void collect(final KEY key, final VALUE val) throws IOException {\n    this.outTuple.f0 = key;\n    this.outTuple.f1 = val;\n    this.flinkCollector.collect(outTuple);\n}", "summary_tokens": ["use", "the", "wrapped", "flink", "collector", "to", "collect", "a", "key", "value", "pair", "for", "flink"], "project": "flink"}
{"id": 3609, "code": "public List<DagConnection> getOutgoingConnections() {\n    return Collections.emptyList();\n}", "summary_tokens": ["gets", "all", "outgoing", "connections", "which", "is", "an", "empty", "set", "for", "the", "data", "sink"], "project": "flink"}
{"id": 8040, "code": "public CatalogDatabase copy() {\n    return copy(getProperties());\n}", "summary_tokens": ["get", "a", "deep", "copy", "of", "the", "catalog", "database", "instance"], "project": "flink"}
{"id": 4955, "code": "private String getLogString(String message, String taskName) {\n    return BatchTask.constructLogString(message, taskName, this);\n}", "summary_tokens": ["utility", "function", "that", "composes", "a", "string", "for", "logging", "purposes"], "project": "flink"}
{"id": 5044, "code": "public void close() {\n        \n    synchronized (this) {\n        if (this.closed) {\n            return;\n        }\n\n            \n        this.closed = true;\n    }\n\n        \n        \n        \n    try {\n            \n        if (this.readThread != null) {\n            closeThread(this.readThread, \"reader\");\n        }\n        closeThread(this.sortThread, \"sorter\");\n        closeThread(this.spillThread, \"spilling\");\n    } finally {\n\n            \n            \n        this.queues.close();\n\n            \n        for (InMemorySorter<?> inMemorySorter : inMemorySorters) {\n            inMemorySorter.dispose();\n        }\n\n            \n            \n        try {\n            if (!this.writeMemory.isEmpty()) {\n                this.memoryManager.release(this.writeMemory);\n            }\n            this.writeMemory.clear();\n        } catch (Throwable ignored) {\n        }\n\n        try {\n            if (!this.sortReadMemory.isEmpty()) {\n                this.memoryManager.release(this.sortReadMemory);\n            }\n            this.sortReadMemory.clear();\n        } catch (Throwable ignored) {\n        }\n\n        this.spillChannelManager.close();\n\n        try {\n            if (this.largeRecordHandler != null) {\n                this.largeRecordHandler.close();\n            }\n        } catch (Throwable ignored) {\n        }\n    }\n}", "summary_tokens": ["shuts", "down", "all", "the", "threads", "initiated", "by", "this", "sort", "merger"], "project": "flink"}
{"id": 8288, "code": "public Object get(Object key) {\n    return map.get(key);\n}", "summary_tokens": ["returns", "the", "value", "to", "which", "the", "specified", "key", "is", "mapped", "or", "null", "if", "this", "map", "contains", "no", "mapping", "for", "the", "key"], "project": "flink"}
{"id": 9025, "code": "public static RowDataKeySelector getRowDataSelector(\n        int[] keyFields, InternalTypeInfo<RowData> rowType) {\n    if (keyFields.length > 0) {\n        LogicalType[] inputFieldTypes = rowType.toRowFieldTypes();\n        LogicalType[] keyFieldTypes = new LogicalType[keyFields.length];\n        for (int i = 0; i < keyFields.length; ++i) {\n            keyFieldTypes[i] = inputFieldTypes[keyFields[i]];\n        }\n            \n            \n        RowType returnType = RowType.of(keyFieldTypes);\n        RowType inputType = rowType.toRowType();\n        GeneratedProjection generatedProjection =\n                ProjectionCodeGenerator.generateProjection(\n                        CodeGeneratorContext.apply(new TableConfig()),\n                        \"KeyProjection\",\n                        inputType,\n                        returnType,\n                        keyFields);\n        InternalTypeInfo<RowData> keyRowType = InternalTypeInfo.of(returnType);\n        return new BinaryRowDataKeySelector(keyRowType, generatedProjection);\n    } else {\n        return EmptyRowDataKeySelector.INSTANCE;\n    }\n}", "summary_tokens": ["create", "a", "row", "data", "key", "selector", "to", "extract", "keys", "from", "data", "stream", "which", "type", "is", "internal", "type", "info", "of", "row", "data"], "project": "flink"}
{"id": 1880, "code": "public static Row ofKind(RowKind kind, Object... values) {\n    final Row row = new Row(kind, values.length);\n    for (int i = 0; i < values.length; i++) {\n        row.setField(i, values[i]);\n    }\n    return row;\n}", "summary_tokens": ["creates", "a", "fixed", "length", "row", "in", "position", "based", "field", "mode", "with", "given", "kind", "and", "assigns", "the", "given", "values", "to", "the", "row", "s", "fields"], "project": "flink"}
{"id": 556, "code": "public FlinkKafkaConsumerBase<T> setStartFromTimestamp(long startupOffsetsTimestamp) {\n    checkArgument(\n            startupOffsetsTimestamp >= 0,\n            \"The provided value for the startup offsets timestamp is invalid.\");\n\n    long currentTimestamp = System.currentTimeMillis();\n    checkArgument(\n            startupOffsetsTimestamp <= currentTimestamp,\n            \"Startup time[%s] must be before current time[%s].\",\n            startupOffsetsTimestamp,\n            currentTimestamp);\n\n    this.startupMode = StartupMode.TIMESTAMP;\n    this.startupOffsetsTimestamp = startupOffsetsTimestamp;\n    this.specificStartupOffsets = null;\n    return this;\n}", "summary_tokens": ["specifies", "the", "consumer", "to", "start", "reading", "partitions", "from", "a", "specified", "timestamp"], "project": "flink"}
{"id": 7706, "code": "public void testListStateUpdateNull() throws Exception {\n    CheckpointableKeyedStateBackend<String> keyedBackend =\n            createKeyedBackend(StringSerializer.INSTANCE);\n\n    final ListStateDescriptor<Long> stateDescr =\n            new ListStateDescriptor<>(\"my-state\", Long.class);\n\n    try {\n        ListState<Long> state =\n                keyedBackend.getPartitionedState(\n                        VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, stateDescr);\n\n        keyedBackend.setCurrentKey(\"abc\");\n        assertNull(state.get());\n\n        expectedException.expect(NullPointerException.class);\n        state.update(null);\n    } finally {\n        keyedBackend.close();\n        keyedBackend.dispose();\n    }\n}", "summary_tokens": ["this", "test", "verifies", "that", "all", "list", "state", "implementations", "are", "consistent", "in", "not", "allowing", "list", "state", "update", "list", "to", "be", "called", "with", "null"], "project": "flink"}
{"id": 8531, "code": "public static boolean isStructuredFieldDirectlyWritable(Field field) {\n    final int m = field.getModifiers();\n\n        \n    if (Modifier.isFinal(m)) {\n        return false;\n    }\n\n        \n    return Modifier.isPublic(m);\n}", "summary_tokens": ["checks", "whether", "a", "field", "is", "directly", "writable", "without", "a", "setter", "or", "constructor"], "project": "flink"}
{"id": 4374, "code": "public static <T> T parseParametersOrExit(\n        String[] args, ParserResultFactory<T> parserResultFactory, Class<?> mainClass) {\n    final CommandLineParser<T> commandLineParser = new CommandLineParser<>(parserResultFactory);\n\n    try {\n        return commandLineParser.parse(args);\n    } catch (Exception e) {\n        LOG.error(\"Could not parse command line arguments {}.\", args, e);\n        commandLineParser.printHelp(mainClass.getSimpleName());\n        System.exit(ClusterEntrypoint.STARTUP_FAILURE_RETURN_CODE);\n    }\n\n    return null;\n}", "summary_tokens": ["parses", "passed", "string", "array", "using", "the", "parameter", "definitions", "of", "the", "passed", "parser", "result", "factory"], "project": "flink"}
{"id": 5749, "code": "public void release(String pathInZooKeeper) throws Exception {\n    final String path = normalizePath(pathInZooKeeper);\n    try {\n        client.delete().forPath(getLockPath(path));\n    } catch (KeeperException.NoNodeException ignored) {\n            \n    } catch (Exception e) {\n        throw new Exception(\n                \"Could not release the lock: \" + getLockPath(pathInZooKeeper) + '.', e);\n    }\n}", "summary_tokens": ["releases", "the", "lock", "from", "the", "node", "under", "the", "given", "zoo", "keeper", "path"], "project": "flink"}
{"id": 2929, "code": "public void testMaxByKeyFieldsGrouping() {\n\n    final ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n    UnsortedGrouping<Tuple5<Integer, Long, String, Long, Integer>> groupDs =\n            env.fromCollection(emptyTupleData, tupleTypeInfo).groupBy(0);\n\n        \n    try {\n        groupDs.maxBy(4, 0, 1, 2, 3);\n    } catch (Exception e) {\n        Assert.fail();\n    }\n}", "summary_tokens": ["this", "test", "validates", "that", "no", "exceptions", "is", "thrown", "when", "an", "empty", "grouping", "calls", "max", "by"], "project": "flink"}
{"id": 7105, "code": "private boolean validateKeyTypeIsHashable(TypeInformation<?> type) {\n    try {\n        return (type instanceof PojoTypeInfo)\n                ? !type.getTypeClass()\n                        .getMethod(\"hashCode\")\n                        .getDeclaringClass()\n                        .equals(Object.class)\n                : !(isArrayType(type) || isEnumType(type));\n    } catch (NoSuchMethodException ignored) {\n            \n    }\n    return false;\n}", "summary_tokens": ["validates", "that", "a", "given", "type", "of", "element", "as", "encoded", "by", "the", "provided", "type", "information", "can", "be", "used", "as", "a", "key", "in", "the", "data", "stream"], "project": "flink"}
{"id": 2283, "code": "public FlinkImageBuilder setTempDirectory(Path tempDirectory) {\n    this.tempDirectory = tempDirectory;\n    return this;\n}", "summary_tokens": ["sets", "temporary", "path", "for", "holding", "temp", "files", "when", "building", "the", "image"], "project": "flink"}
{"id": 927, "code": "default void open(InitializationContext context) throws Exception {\n        \n}", "summary_tokens": ["initialization", "method", "for", "the", "schema"], "project": "flink"}
{"id": 722, "code": "private void testAssignedToPartitionFailureRecovery(\n        int numElementsPerProducer, TimeCharacteristic timeCharacteristic) throws Exception {\n    String topic = topic(\"partition_failure_recovery\", timeCharacteristic);\n    final int numberOfPartitions = 3;\n    final int producerParallelism = 2;\n    final int failAfterElements = numElementsPerProducer * producerParallelism * 2 / 3;\n\n    createTestTopic(topic, numberOfPartitions, 1);\n\n    final StreamExecutionEnvironment env =\n            createEnvironment(producerParallelism, timeCharacteristic);\n\n    KeyedStream<Tuple3<Integer, Long, Integer>, Tuple> keyedStream =\n            createKafkaShuffle(\n                    env,\n                    topic,\n                    numElementsPerProducer,\n                    producerParallelism,\n                    timeCharacteristic,\n                    numberOfPartitions);\n    keyedStream\n            .process(\n                    new PartitionValidator(\n                            keyedStream.getKeySelector(), numberOfPartitions, topic))\n            .setParallelism(numberOfPartitions)\n            .map(new ToInteger(producerParallelism))\n            .setParallelism(numberOfPartitions)\n            .map(new FailingIdentityMapper<>(failAfterElements))\n            .setParallelism(1)\n            .addSink(\n                    new ValidatingExactlyOnceSink(numElementsPerProducer * producerParallelism))\n            .setParallelism(1);\n\n    FailingIdentityMapper.failedBefore = false;\n\n    tryExecute(env, topic);\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["to", "test", "failure", "recovery", "with", "partition", "assignment", "after", "processing", "0", "0", "data"], "project": "flink"}
{"id": 9429, "code": "private void checkSkipReadForPointer(AbstractPagedInputView source) throws IOException {\n        \n        \n    int available = source.getCurrentSegmentLimit() - source.getCurrentPositionInSegment();\n    if (available < ELEMENT_POINT_LENGTH) {\n        source.advance();\n    }\n}", "summary_tokens": ["for", "pointer", "needing", "update", "skip", "unaligned", "part", "0", "bytes", "for", "convenient", "updating"], "project": "flink"}
{"id": 1803, "code": "public void putDouble(int index, double value) {\n    putLong(index, Double.doubleToRawLongBits(value));\n}", "summary_tokens": ["writes", "the", "given", "double", "precision", "floating", "point", "value", "0", "bit", "0", "bytes", "to", "the", "given", "position", "in", "the", "system", "s", "native", "byte", "order"], "project": "flink"}
{"id": 5222, "code": "public MethodlessRouter<T> addRoute(String pathPattern, T target) {\n    PathPattern p = new PathPattern(pathPattern);\n    if (routes.containsKey(p)) {\n        return this;\n    }\n\n    routes.put(p, target);\n    return this;\n}", "summary_tokens": ["this", "method", "does", "nothing", "if", "the", "path", "pattern", "has", "already", "been", "added"], "project": "flink"}
{"id": 1717, "code": "public static void closeSafetyNetAndGuardedResourcesForThread() {\n    SafetyNetCloseableRegistry registry = REGISTRIES.get();\n    if (null != registry) {\n        REGISTRIES.remove();\n        IOUtils.closeQuietly(registry);\n    }\n}", "summary_tokens": ["closes", "the", "safety", "net", "for", "a", "thread"], "project": "flink"}
{"id": 1152, "code": "static <T> WatermarkStrategy<T> forBoundedOutOfOrderness(Duration maxOutOfOrderness) {\n    return (ctx) -> new BoundedOutOfOrdernessWatermarks<>(maxOutOfOrderness);\n}", "summary_tokens": ["creates", "a", "watermark", "strategy", "for", "situations", "where", "records", "are", "out", "of", "order", "but", "you", "can", "place", "an", "upper", "bound", "on", "how", "far", "the", "events", "are", "out", "of", "order"], "project": "flink"}
{"id": 3030, "code": "public Collection<Tuple2<Map<String, List<T>>, Long>> advanceTime(\n        final SharedBufferAccessor<T> sharedBufferAccessor,\n        final NFAState nfaState,\n        final long timestamp)\n        throws Exception {\n\n    final Collection<Tuple2<Map<String, List<T>>, Long>> timeoutResult = new ArrayList<>();\n    final PriorityQueue<ComputationState> newPartialMatches =\n            new PriorityQueue<>(NFAState.COMPUTATION_STATE_COMPARATOR);\n\n    for (ComputationState computationState : nfaState.getPartialMatches()) {\n        if (isStateTimedOut(computationState, timestamp)) {\n\n            if (handleTimeout) {\n                    \n                Map<String, List<T>> timedOutPattern =\n                        sharedBufferAccessor.materializeMatch(\n                                extractCurrentMatches(sharedBufferAccessor, computationState));\n                timeoutResult.add(\n                        Tuple2.of(\n                                timedOutPattern,\n                                computationState.getStartTimestamp() + windowTime));\n            }\n\n            sharedBufferAccessor.releaseNode(\n                    computationState.getPreviousBufferEntry(), computationState.getVersion());\n\n            nfaState.setStateChanged();\n        } else {\n            newPartialMatches.add(computationState);\n        }\n    }\n\n    nfaState.setNewPartialMatches(newPartialMatches);\n\n    sharedBufferAccessor.advanceTime(timestamp);\n\n    return timeoutResult;\n}", "summary_tokens": ["prunes", "states", "assuming", "there", "will", "be", "no", "events", "with", "timestamp", "b", "lower", "b", "than", "the", "given", "one"], "project": "flink"}
{"id": 4842, "code": "public MemorySegment getCurrentSegment() {\n    return this.currentSegment;\n}", "summary_tokens": ["gets", "the", "segment", "that", "the", "view", "currently", "writes", "to"], "project": "flink"}
{"id": 2032, "code": "public T getUnchecked() throws FlinkRuntimeException {\n    if (value != null) {\n        return value;\n    }\n    checkNotNull(failureCause);\n    throw new FlinkRuntimeException(failureCause);\n}", "summary_tokens": ["same", "as", "get", "but", "throws", "a", "flink", "runtime", "exception"], "project": "flink"}
{"id": 8863, "code": "public static Map<String, String> mergeTableOptions(\n        Map<String, String> hints, Map<String, String> props) {\n    if (hints.size() == 0) {\n        return props;\n    }\n    Map<String, String> newProps = new HashMap<>();\n    newProps.putAll(props);\n    newProps.putAll(hints);\n    return Collections.unmodifiableMap(newProps);\n}", "summary_tokens": ["merges", "the", "dynamic", "table", "options", "from", "hints", "and", "static", "table", "options", "from", "table", "definition", "props"], "project": "flink"}
{"id": 2775, "code": "public AggregatorRegistry getAggregators() {\n    return this.aggregators;\n}", "summary_tokens": ["gets", "the", "registry", "for", "aggregators", "for", "the", "iteration"], "project": "flink"}
{"id": 7711, "code": "public void testListStateDefaultValue() throws Exception {\n    CheckpointableKeyedStateBackend<Integer> backend =\n            createKeyedBackend(IntSerializer.INSTANCE);\n\n    ListStateDescriptor<String> kvId = new ListStateDescriptor<>(\"id\", String.class);\n\n    ListState<String> state =\n            backend.getPartitionedState(\n                    VoidNamespace.INSTANCE, VoidNamespaceSerializer.INSTANCE, kvId);\n\n    backend.setCurrentKey(1);\n    assertNull(state.get());\n\n    state.update(Arrays.asList(\"Ciao\", \"Bello\"));\n    assertThat(state.get(), containsInAnyOrder(\"Ciao\", \"Bello\"));\n\n    state.clear();\n    assertNull(state.get());\n\n    backend.dispose();\n}", "summary_tokens": ["verify", "that", "an", "empty", "list", "state", "yields", "null"], "project": "flink"}
{"id": 3436, "code": "public static void pipeSystemOutToNull() {\n    System.setOut(new PrintStream(new BlackholeOutputSteam()));\n}", "summary_tokens": ["method", "useful", "for", "suppressing", "sysout", "printing"], "project": "flink"}
{"id": 6016, "code": "public String getString() {\n    return this.message;\n}", "summary_tokens": ["returns", "the", "stored", "string"], "project": "flink"}
{"id": 5205, "code": "public static void setDateHeader(FullHttpResponse response) {\n    SimpleDateFormat dateFormatter = new SimpleDateFormat(HTTP_DATE_FORMAT, Locale.US);\n    dateFormatter.setTimeZone(GMT_TIMEZONE);\n\n    Calendar time = new GregorianCalendar();\n    response.headers().set(DATE, dateFormatter.format(time.getTime()));\n}", "summary_tokens": ["sets", "the", "date", "header", "for", "the", "http", "response"], "project": "flink"}
{"id": 7760, "code": "public void testLatencyMarkEmissionDisabledOverrideViaExecutionConfig() throws Exception {\n    testLatencyMarkEmission(\n            0,\n            (operator, timeProvider) -> {\n                Configuration tmConfig = new Configuration();\n                tmConfig.setLong(MetricOptions.LATENCY_INTERVAL, latencyMarkInterval);\n\n                Environment env =\n                        MockEnvironment.builder()\n                                .setTaskManagerRuntimeInfo(\n                                        new TestingTaskManagerRuntimeInfo(tmConfig))\n                                .build();\n\n                ExecutionConfig executionConfig = new ExecutionConfig();\n                executionConfig.setLatencyTrackingInterval(0);\n\n                setupSourceOperator(operator, executionConfig, env, timeProvider);\n            });\n}", "summary_tokens": ["verifies", "that", "latency", "metrics", "can", "be", "disabled", "via", "the", "execution", "config", "even", "if", "they", "are", "enabled", "via", "the", "configuration"], "project": "flink"}
{"id": 4928, "code": "private static SSLContext createInternalSSLContext(Configuration config, boolean clientMode)\n        throws Exception {\n    JdkSslContext nettySSLContext =\n            (JdkSslContext) createInternalNettySSLContext(config, clientMode, JDK);\n    if (nettySSLContext != null) {\n        return nettySSLContext.context();\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["creates", "the", "ssl", "context", "for", "internal", "ssl", "if", "internal", "ssl", "is", "configured"], "project": "flink"}
{"id": 4482, "code": "static BlockCompressionFactory createBlockCompressionFactory(String compressionFactoryName) {\n\n    checkNotNull(compressionFactoryName);\n\n    CompressionFactoryName compressionName;\n    try {\n        compressionName = CompressionFactoryName.valueOf(compressionFactoryName.toUpperCase());\n    } catch (IllegalArgumentException e) {\n        compressionName = null;\n    }\n\n    BlockCompressionFactory blockCompressionFactory = null;\n    if (compressionName != null) {\n        switch (compressionName) {\n            case LZ4:\n                blockCompressionFactory = new Lz4BlockCompressionFactory();\n                break;\n            default:\n                throw new IllegalStateException(\"Unknown CompressionMethod \" + compressionName);\n        }\n    } else {\n        Object factoryObj;\n        try {\n            factoryObj = Class.forName(compressionFactoryName).newInstance();\n        } catch (ClassNotFoundException e) {\n            throw new IllegalConfigurationException(\n                    \"Cannot load class \" + compressionFactoryName, e);\n        } catch (Exception e) {\n            throw new IllegalConfigurationException(\n                    \"Cannot create object for class \" + compressionFactoryName, e);\n        }\n        if (factoryObj instanceof BlockCompressionFactory) {\n            blockCompressionFactory = (BlockCompressionFactory) factoryObj;\n        } else {\n            throw new IllegalArgumentException(\n                    \"CompressionFactoryName should inherit from\"\n                            + \" interface BlockCompressionFactory, or use the default compression codec.\");\n        }\n    }\n\n    checkNotNull(blockCompressionFactory);\n    return blockCompressionFactory;\n}", "summary_tokens": ["creates", "block", "compression", "factory", "according", "to", "the", "configuration"], "project": "flink"}
{"id": 5196, "code": "public TriggerId getTriggerId() {\n    return triggerId;\n}", "summary_tokens": ["get", "the", "trigger", "id", "for", "the", "given", "operation", "key"], "project": "flink"}
{"id": 9277, "code": "public static void maxNormalizedKey(MemorySegment target, int offset, int numBytes) {\n        \n    for (int i = 0; i < numBytes; i++) {\n        target.put(offset + i, (byte) -1);\n    }\n}", "summary_tokens": ["max", "unsigned", "byte", "is", "0"], "project": "flink"}
{"id": 5086, "code": "protected boolean isRunning() {\n    return this.alive;\n}", "summary_tokens": ["checks", "whether", "this", "thread", "is", "still", "alive"], "project": "flink"}
{"id": 5021, "code": "public static int getPartitioningFanOutNoEstimates(int numBuffers) {\n    return Math.max(10, Math.min(numBuffers / 10, MAX_NUM_PARTITIONS));\n}", "summary_tokens": ["gets", "the", "number", "of", "partitions", "to", "be", "used", "for", "an", "initial", "hash", "table", "when", "no", "estimates", "are", "available"], "project": "flink"}
{"id": 5397, "code": "public int getCurrentKeyGroup() {\n    return currentKeyGroup;\n}", "summary_tokens": ["returns", "the", "key", "group", "that", "is", "currently", "being", "written"], "project": "flink"}
{"id": 2070, "code": "public static String toQuotedListString(Object[] values) {\n    return Arrays.stream(values)\n            .filter(Objects::nonNull)\n            .map(v -> v.toString().toLowerCase())\n            .collect(Collectors.joining(\", \", \"\\\"\", \"\\\"\"));\n}", "summary_tokens": ["generates", "a", "string", "containing", "a", "comma", "separated", "list", "of", "values", "in", "double", "quotes"], "project": "flink"}
{"id": 7722, "code": "public void testManualHashAssignmentForIntermediateNodeInChain() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();\n    env.setParallelism(4);\n\n    env.addSource(new NoOpSourceFunction())\n                \n            .map(new NoOpMapFunction())\n            .uid(\"map\")\n            .addSink(new DiscardingSink<>());\n\n    env.getStreamGraph().getJobGraph();\n}", "summary_tokens": ["tests", "that", "a", "manual", "hash", "for", "an", "intermediate", "chain", "node", "is", "accepted"], "project": "flink"}
{"id": 8985, "code": "private void setJoinAdjustments(\n        int[] adjustments, int nFieldsX, int nFieldsY, int nFieldsZ, int adjustY, int adjustZ) {\n    for (int i = 0; i < nFieldsX; i++) {\n        adjustments[i] = 0;\n    }\n    for (int i = nFieldsX; i < (nFieldsX + nFieldsY); i++) {\n        adjustments[i] = adjustY;\n    }\n    for (int i = nFieldsX + nFieldsY; i < (nFieldsX + nFieldsY + nFieldsZ); i++) {\n        adjustments[i] = adjustZ;\n    }\n}", "summary_tokens": ["sets", "an", "array", "to", "reflect", "how", "much", "each", "index", "corresponding", "to", "a", "field", "needs", "to", "be", "adjusted"], "project": "flink"}
{"id": 8220, "code": "static CatalogView of(\n        Schema schema,\n        @Nullable String comment,\n        String originalQuery,\n        String expandedQuery,\n        Map<String, String> options) {\n    return new DefaultCatalogView(schema, comment, originalQuery, expandedQuery, options);\n}", "summary_tokens": ["creates", "a", "basic", "implementation", "of", "this", "interface"], "project": "flink"}
{"id": 3617, "code": "public InnerJoinOperatorBase<?, ?, ?, ?> getOperator() {\n    return (InnerJoinOperatorBase<?, ?, ?, ?>) super.getOperator();\n}", "summary_tokens": ["gets", "the", "contract", "object", "for", "this", "match", "node"], "project": "flink"}
{"id": 2504, "code": "public void testDeserialization() throws IOException {\n    Configuration parameters = new Configuration();\n\n    AvroInputFormat<User> format =\n            new AvroInputFormat<>(new Path(testFile.getAbsolutePath()), User.class);\n\n    format.configure(parameters);\n    FileInputSplit[] splits = format.createInputSplits(1);\n    assertEquals(splits.length, 1);\n    format.open(splits[0]);\n\n    User u = format.nextRecord(null);\n    assertNotNull(u);\n\n    String name = u.getName().toString();\n    assertNotNull(\"empty record\", name);\n    assertEquals(\"name not equal\", TEST_NAME, name);\n\n        \n    List<CharSequence> sl = u.getTypeArrayString();\n    assertEquals(\"element 0 not equal\", TEST_ARRAY_STRING_1, sl.get(0).toString());\n    assertEquals(\"element 1 not equal\", TEST_ARRAY_STRING_2, sl.get(1).toString());\n\n    List<Boolean> bl = u.getTypeArrayBoolean();\n    assertEquals(\"element 0 not equal\", TEST_ARRAY_BOOLEAN_1, bl.get(0));\n    assertEquals(\"element 1 not equal\", TEST_ARRAY_BOOLEAN_2, bl.get(1));\n\n        \n    Colors enumValue = u.getTypeEnum();\n    assertEquals(\"enum not equal\", TEST_ENUM_COLOR, enumValue);\n\n        \n    Map<CharSequence, Long> lm = u.getTypeMap();\n    assertEquals(\n            \"map value of key 1 not equal\",\n            TEST_MAP_VALUE1,\n            lm.get(new Utf8(TEST_MAP_KEY1)).longValue());\n    assertEquals(\n            \"map value of key 2 not equal\",\n            TEST_MAP_VALUE2,\n            lm.get(new Utf8(TEST_MAP_KEY2)).longValue());\n\n    assertFalse(\"expecting second element\", format.reachedEnd());\n    assertNotNull(\"expecting second element\", format.nextRecord(u));\n\n    assertNull(format.nextRecord(u));\n    assertTrue(format.reachedEnd());\n\n    format.close();\n}", "summary_tokens": ["test", "if", "the", "avro", "input", "format", "is", "able", "to", "properly", "read", "data", "from", "an", "avro", "file"], "project": "flink"}
{"id": 5149, "code": "public void close() throws Exception {\n    LOG.info(\"Closing the slot manager.\");\n\n    suspend();\n}", "summary_tokens": ["closes", "the", "slot", "manager"], "project": "flink"}
{"id": 8821, "code": "private static RowType createConsumedType(ResolvedSchema schema, DynamicTableSink sink) {\n    final Map<String, DataType> metadataMap = extractMetadataMap(sink);\n\n    final Stream<RowField> physicalFields =\n            schema.getColumns().stream()\n                    .filter(Column::isPhysical)\n                    .map(c -> new RowField(c.getName(), c.getDataType().getLogicalType()));\n\n    final Stream<RowField> metadataFields =\n            createRequiredMetadataKeys(schema, sink).stream()\n                    .map(k -> new RowField(k, metadataMap.get(k).getLogicalType()));\n\n    final List<RowField> rowFields =\n            Stream.concat(physicalFields, metadataFields).collect(Collectors.toList());\n\n    return new RowType(false, rowFields);\n}", "summary_tokens": ["returns", "the", "data", "type", "that", "a", "sink", "should", "consume", "as", "the", "output", "from", "the", "runtime"], "project": "flink"}
{"id": 2635, "code": "public <OUT extends Tuple> ProjectOperator<?, OUT> project(int... fieldIndexes) {\n    return new Projection<>(this, fieldIndexes).projectTupleX();\n}", "summary_tokens": ["applies", "a", "project", "transformation", "on", "a", "tuple", "data", "set"], "project": "flink"}
{"id": 2352, "code": "public <T extends Enum<T>> void setEnum(String name, T value) {\n    set(name, value.toString());\n}", "summary_tokens": ["set", "the", "value", "of", "the", "code", "name", "code", "property", "to", "the", "given", "type"], "project": "flink"}
{"id": 3428, "code": "private static <T extends Comparable<T>> void validate(\n        Graph<T, NullValue, NullValue> graph, Result result) throws Exception {\n    Result edgeMetrics = new EdgeMetrics<T, NullValue, NullValue>().run(graph).execute();\n\n    assertEquals(result, edgeMetrics);\n}", "summary_tokens": ["validate", "a", "test", "result"], "project": "flink"}
{"id": 9239, "code": "private void calculateManagedMemoryFraction() {\n    for (Map.Entry<Transformation<?>, TableOperatorWrapper<?>> entry :\n            visitedTransforms.entrySet()) {\n        double fraction = 0;\n        if (managedMemoryWeight != 0) {\n            fraction =\n                    entry.getKey()\n                                    .getManagedMemoryOperatorScopeUseCaseWeights()\n                                    .getOrDefault(ManagedMemoryUseCase.OPERATOR, 0)\n                            * 1.0\n                            / this.managedMemoryWeight;\n        }\n        entry.getValue().setManagedMemoryFraction(fraction);\n    }\n}", "summary_tokens": ["calculate", "managed", "memory", "fraction", "for", "each", "operator", "wrapper"], "project": "flink"}
{"id": 4011, "code": "public void testMainThreadExecutionOnStop() throws Exception {\n    final MainThreadExecutorOnStopEndpoint endpoint =\n            new MainThreadExecutorOnStopEndpoint(akkaRpcService);\n\n    try {\n        endpoint.start();\n\n        CompletableFuture<Void> terminationFuture = endpoint.closeAsync();\n\n        terminationFuture.get();\n    } finally {\n        RpcUtils.terminateRpcEndpoint(endpoint, timeout);\n    }\n}", "summary_tokens": ["tests", "that", "we", "can", "still", "run", "commands", "via", "the", "main", "thread", "executor", "when", "the", "on", "stop", "method", "is", "called"], "project": "flink"}
{"id": 3498, "code": "public WindowedOperatorTransformation<T, K, W> trigger(Trigger<? super T, ? super W> trigger) {\n    builder.trigger(trigger);\n    return this;\n}", "summary_tokens": ["sets", "the", "trigger", "that", "should", "be", "used", "to", "trigger", "window", "emission"], "project": "flink"}
{"id": 250, "code": "public synchronized void add(T object) {\n    if (poolSize >= poolCapacity) {\n        throw new IllegalStateException(\"No space left in pool\");\n    }\n    poolSize++;\n\n    addBack(object);\n}", "summary_tokens": ["adds", "an", "entry", "to", "the", "pool", "with", "an", "optional", "payload"], "project": "flink"}
{"id": 2902, "code": "private void registerCachedFilesWithPlan(Plan p) throws IOException {\n    for (Tuple2<String, DistributedCache.DistributedCacheEntry> entry : cacheFile) {\n        p.registerCachedFile(entry.f0, entry.f1);\n    }\n}", "summary_tokens": ["registers", "all", "files", "that", "were", "registered", "at", "this", "execution", "environment", "s", "cache", "registry", "of", "the", "given", "plan", "s", "cache", "registry"], "project": "flink"}
{"id": 4544, "code": "public int append(ByteBuffer source) {\n    checkState(!isFinished());\n\n    int needed = source.remaining();\n    int available = getMaxCapacity() - positionMarker.getCached();\n    int toCopy = Math.min(needed, available);\n\n    memorySegment.put(positionMarker.getCached(), source, toCopy);\n    positionMarker.move(toCopy);\n    return toCopy;\n}", "summary_tokens": ["append", "as", "many", "data", "as", "possible", "from", "source"], "project": "flink"}
{"id": 5113, "code": "public void registerListener(JobID jobId, KvStateRegistryListener listener) {\n    final KvStateRegistryListener previousValue = listeners.putIfAbsent(jobId, listener);\n\n    if (previousValue != null) {\n        throw new IllegalStateException(\"Listener already registered under \" + jobId + '.');\n    }\n}", "summary_tokens": ["registers", "a", "listener", "with", "the", "registry"], "project": "flink"}
{"id": 9626, "code": "public void testCoGroupOperatorWithCheckpoint() throws Exception {\n\n        \n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(1);\n\n    DataStream<Tuple2<String, Integer>> source1 =\n            env.fromElements(Tuple2.of(\"a\", 0), Tuple2.of(\"b\", 3));\n    DataStream<Tuple2<String, Integer>> source2 =\n            env.fromElements(Tuple2.of(\"a\", 1), Tuple2.of(\"b\", 6));\n\n    DataStream<String> coGroupWindow =\n            source1.coGroup(source2)\n                    .where(new Tuple2KeyExtractor())\n                    .equalTo(new Tuple2KeyExtractor())\n                    .window(TumblingEventTimeWindows.of(Time.of(3, TimeUnit.MILLISECONDS)))\n                    .apply(\n                            new CoGroupFunction<\n                                    Tuple2<String, Integer>,\n                                    Tuple2<String, Integer>,\n                                    String>() {\n                                @Override\n                                public void coGroup(\n                                        Iterable<Tuple2<String, Integer>> first,\n                                        Iterable<Tuple2<String, Integer>> second,\n                                        Collector<String> out)\n                                        throws Exception {\n                                    out.collect(first + \":\" + second);\n                                }\n                            });\n\n    OneInputTransformation<Tuple2<String, Integer>, String> transform =\n            (OneInputTransformation<Tuple2<String, Integer>, String>)\n                    coGroupWindow.getTransformation();\n    OneInputStreamOperator<Tuple2<String, Integer>, String> operator = transform.getOperator();\n\n        \n    OneInputStreamOperatorTestHarness<Tuple2<String, Integer>, String> testHarness =\n            new KeyedOneInputStreamOperatorTestHarness<>(\n                    operator, new Tuple2KeyExtractor(), BasicTypeInfo.STRING_TYPE_INFO);\n\n    testHarness.open();\n    testHarness.snapshot(0L, 0L);\n}", "summary_tokens": ["verifies", "that", "pipelines", "including", "co", "grouped", "streams", "can", "be", "checkpointed", "properly", "which", "includes", "snapshotting", "configurations", "of", "any", "involved", "serializers"], "project": "flink"}
{"id": 831, "code": "protected static boolean isRecoverableException(AmazonServiceException ex) {\n    if (ex.getErrorType() == null) {\n        return false;\n    }\n\n    switch (ex.getErrorType()) {\n        case Client:\n            return ex instanceof ProvisionedThroughputExceededException;\n        case Service:\n        case Unknown:\n            return true;\n        default:\n            return false;\n    }\n}", "summary_tokens": ["determines", "whether", "the", "exception", "is", "recoverable", "using", "exponential", "backoff"], "project": "flink"}
{"id": 9658, "code": "public void testTimestampExtractorWithLongMaxWatermarkFromSource2() throws Exception {\n    final int numElements = 10;\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    env.getConfig().setAutoWatermarkInterval(10);\n    env.setParallelism(2);\n\n    DataStream<Integer> source1 =\n            env.addSource(\n                    new SourceFunction<Integer>() {\n                        @Override\n                        public void run(SourceContext<Integer> ctx) throws Exception {\n                            int index = 1;\n                            while (index <= numElements) {\n                                ctx.collectWithTimestamp(index, index);\n                                ctx.collectWithTimestamp(index - 1, index - 1);\n                                index++;\n                                ctx.emitWatermark(new Watermark(index - 2));\n                            }\n\n                                \n                                \n                                \n                            ctx.emitWatermark(new Watermark(Long.MAX_VALUE));\n                            ctx.emitWatermark(new Watermark(Long.MAX_VALUE));\n                        }\n\n                        @Override\n                        public void cancel() {}\n                    });\n\n    source1.assignTimestampsAndWatermarks(\n                    new AssignerWithPeriodicWatermarks<Integer>() {\n\n                        @Override\n                        public long extractTimestamp(Integer element, long currentTimestamp) {\n                            return element;\n                        }\n\n                        @Override\n                        public Watermark getCurrentWatermark() {\n                            return null;\n                        }\n                    })\n            .transform(\n                    \"Watermark Check\", BasicTypeInfo.INT_TYPE_INFO, new CustomOperator(true));\n\n    env.execute();\n\n    Assert.assertTrue(CustomOperator.finalWatermarks[0].size() == 1);\n    Assert.assertTrue(\n            CustomOperator.finalWatermarks[0].get(0).getTimestamp() == Long.MAX_VALUE);\n}", "summary_tokens": ["this", "test", "verifies", "that", "the", "timestamp", "extractor", "forwards", "long"], "project": "flink"}
{"id": 9540, "code": "public Optional<Meter> getMeter(String... identifier) {\n    return getMetric(Meter.class, identifier);\n}", "summary_tokens": ["get", "registered", "meter", "with", "identifier", "relative", "to", "the", "root", "metric", "group"], "project": "flink"}
{"id": 3497, "code": "public <K, T, OUT> DataStream<OUT> process(\n        String uid,\n        WindowReaderFunction<T, OUT, K, W> readerFunction,\n        TypeInformation<K> keyType,\n        TypeInformation<T> stateType,\n        TypeInformation<OUT> outputType)\n        throws IOException {\n\n    WindowReaderOperator<?, K, T, W, OUT> operator =\n            WindowReaderOperator.process(readerFunction, keyType, windowSerializer, stateType);\n\n    return readWindowOperator(uid, outputType, operator);\n}", "summary_tokens": ["reads", "window", "state", "generated", "without", "any", "preaggregation", "such", "as", "windowed", "stream", "apply", "and", "windowed", "stream", "process"], "project": "flink"}
{"id": 5079, "code": "public void go() throws IOException, InterruptedException {\n\n        \n    final Queue<CircularElement<E>> cache = new ArrayDeque<>();\n    boolean cacheOnly = readCache(cache);\n\n        \n    if (!isRunning()) {\n        return;\n    }\n\n    MutableObjectIterator<E> largeRecords = null;\n\n        \n    if (cacheOnly && largeRecordHandler != null && largeRecordHandler.hasData()) {\n        List<MemorySegment> memoryForLargeRecordSorting = new ArrayList<>();\n\n        CircularElement<E> circElement;\n        while ((circElement = this.dispatcher.poll(SortStage.READ)) != null) {\n            circElement.getBuffer().dispose();\n            memoryForLargeRecordSorting.addAll(circElement.getMemory());\n        }\n\n        if (memoryForLargeRecordSorting.isEmpty()) {\n            cacheOnly = false;\n            LOG.debug(\"Going to disk-based merge because of large records.\");\n        } else {\n            LOG.debug(\"Sorting large records, to add them to in-memory merge.\");\n            largeRecords =\n                    largeRecordHandler.finishWriteAndSortKeys(memoryForLargeRecordSorting);\n        }\n    }\n\n        \n    if (cacheOnly) {\n        mergeInMemory(cache, largeRecords);\n        return;\n    }\n\n        \n    List<ChannelWithBlockCount> channelIDs = startSpilling(cache);\n\n        \n\n    mergeOnDisk(channelIDs);\n}", "summary_tokens": ["entry", "point", "of", "the", "thread"], "project": "flink"}
{"id": 9155, "code": "private static int indexMiddle(\n        BinaryStringData pattern, MemorySegment[] segments, int start, int len) {\n    return SegmentsUtil.find(\n            segments,\n            start,\n            len,\n            pattern.getSegments(),\n            pattern.getOffset(),\n            pattern.getSizeInBytes());\n}", "summary_tokens": ["matches", "the", "middle", "of", "each", "string", "to", "its", "pattern"], "project": "flink"}
{"id": 9743, "code": "public void testInvalidYarnPropertiesFile() throws Exception {\n\n    File directoryPath = writeYarnPropertiesFile(invalidPropertiesFile);\n\n    final Configuration configuration = new Configuration();\n    configuration.setString(\n            YarnConfigOptions.PROPERTIES_FILE_LOCATION, directoryPath.getAbsolutePath());\n\n    createFlinkYarnSessionCli(configuration);\n}", "summary_tokens": ["tests", "that", "we", "fail", "when", "reading", "an", "invalid", "yarn", "properties", "file", "when", "retrieving", "the", "cluster", "id"], "project": "flink"}
{"id": 1279, "code": "public Ordering getGroupOrderForInputTwo() {\n    return getGroupOrder(1);\n}", "summary_tokens": ["gets", "the", "order", "of", "elements", "within", "a", "group", "for", "the", "second", "input"], "project": "flink"}
{"id": 1486, "code": "public String toString() {\n    return \"(\"\n            + StringUtils.arrayAwareToString(this.f0)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f1)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f2)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f3)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f4)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f5)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f6)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f7)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f8)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f9)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f10)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f11)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f12)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f13)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f14)\n            + \",\"\n            + StringUtils.arrayAwareToString(this.f15)\n            + \")\";\n}", "summary_tokens": ["creates", "a", "string", "representation", "of", "the", "tuple", "in", "the", "form", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "f", "0", "where", "the", "individual", "fields", "are", "the", "value", "returned", "by", "calling", "object", "to", "string", "on", "that", "field"], "project": "flink"}
{"id": 1149, "code": "default WatermarkStrategy<T> withTimestampAssigner(\n        SerializableTimestampAssigner<T> timestampAssigner) {\n    checkNotNull(timestampAssigner, \"timestampAssigner\");\n    return new WatermarkStrategyWithTimestampAssigner<>(\n            this, TimestampAssignerSupplier.of(timestampAssigner));\n}", "summary_tokens": ["creates", "a", "new", "watermark", "strategy", "that", "wraps", "this", "strategy", "but", "instead", "uses", "the", "given", "serializable", "timestamp", "assigner"], "project": "flink"}
{"id": 3186, "code": "public Graph<K, VV, EV> reverse() throws UnsupportedOperationException {\n    DataSet<Edge<K, EV>> reversedEdges =\n            edges.map(new ReverseEdgesMap<>()).name(\"Reverse edges\");\n    return new Graph<>(vertices, reversedEdges, this.context);\n}", "summary_tokens": ["reverse", "the", "direction", "of", "the", "edges", "in", "the", "graph"], "project": "flink"}
{"id": 3478, "code": "public <T> DataStream<T> readUnionState(\n        String uid, String name, TypeInformation<T> typeInfo, TypeSerializer<T> serializer)\n        throws IOException {\n\n    OperatorState operatorState = metadata.getOperatorState(uid);\n    ListStateDescriptor<T> descriptor = new ListStateDescriptor<>(name, serializer);\n    UnionStateInputFormat<T> inputFormat =\n            new UnionStateInputFormat<>(operatorState, descriptor);\n    return SourceBuilder.fromFormat(env, inputFormat, typeInfo);\n}", "summary_tokens": ["read", "operator", "union", "state", "from", "a", "savepoint", "when", "a", "custom", "serializer", "was", "used", "e"], "project": "flink"}
{"id": 2494, "code": "public static <T extends SpecificData> SpecificData getSpecificDataForClass(\n        Class<T> type, ClassLoader cl) {\n    try {\n        Field specificDataField = type.getDeclaredField(\"MODEL$\");\n        specificDataField.setAccessible(true);\n        return (SpecificData) specificDataField.get((Object) null);\n    } catch (IllegalAccessException e) {\n        throw new FlinkRuntimeException(\"Could not access the MODEL$ field of avro record\", e);\n    } catch (NoSuchFieldException e) {\n        return new SpecificData(cl);\n    }\n}", "summary_tokens": ["creates", "a", "specific", "data", "object", "for", "a", "given", "class"], "project": "flink"}
{"id": 3671, "code": "public boolean isTrivial() {\n    return this.partitioning == null\n            || this.partitioning == PartitioningProperty.RANDOM_PARTITIONED;\n}", "summary_tokens": ["checks", "if", "the", "properties", "in", "this", "object", "are", "trivial", "i"], "project": "flink"}
{"id": 3636, "code": "public void computeUnionOfInterestingPropertiesFromSuccessors() {\n    List<DagConnection> conns = getOutgoingConnections();\n    if (conns.size() == 0) {\n            \n        this.intProps = new InterestingProperties();\n    } else {\n        this.intProps = conns.get(0).getInterestingProperties().clone();\n        for (int i = 1; i < conns.size(); i++) {\n            this.intProps.addInterestingProperties(conns.get(i).getInterestingProperties());\n        }\n    }\n    this.intProps.dropTrivials();\n}", "summary_tokens": ["computes", "all", "the", "interesting", "properties", "that", "are", "relevant", "to", "this", "node"], "project": "flink"}
{"id": 2819, "code": "public O returns(TypeInformation<OUT> typeInfo) {\n    requireNonNull(typeInfo, \"TypeInformation must not be null\");\n\n    fillInType(typeInfo);\n    @SuppressWarnings(\"unchecked\")\n    O returnType = (O) this;\n    return returnType;\n}", "summary_tokens": ["adds", "a", "type", "information", "hint", "about", "the", "return", "type", "of", "this", "operator"], "project": "flink"}
{"id": 791, "code": "public long getDeregisterStreamMaxBackoffMillis() {\n    return deregisterStreamMaxBackoffMillis;\n}", "summary_tokens": ["get", "maximum", "backoff", "millis", "for", "the", "deregister", "stream", "operation"], "project": "flink"}
{"id": 3378, "code": "private CoGroupOperator<?, ?, Tuple2<K, Message>> buildScatterFunction(\n        DeltaIteration<Vertex<K, VV>, Vertex<K, VV>> iteration,\n        TypeInformation<Tuple2<K, Message>> messageTypeInfo,\n        int whereArg,\n        int equalToArg,\n        DataSet<LongValue> numberOfVertices) {\n\n        \n    CoGroupOperator<?, ?, Tuple2<K, Message>> messages;\n    ScatterUdfWithEdgeValues<K, VV, VV, Message, EV> messenger =\n            new ScatterUdfWithEVsSimpleVV<>(scatterFunction, messageTypeInfo);\n\n    messages =\n            this.edgesWithValue\n                    .coGroup(iteration.getWorkset())\n                    .where(whereArg)\n                    .equalTo(equalToArg)\n                    .with(messenger);\n\n        \n    messages = messages.name(\"Messaging\");\n    if (this.configuration != null) {\n        for (Tuple2<String, DataSet<?>> e : this.configuration.getScatterBcastVars()) {\n            messages = messages.withBroadcastSet(e.f1, e.f0);\n        }\n        if (this.configuration.isOptNumVertices()) {\n            messages = messages.withBroadcastSet(numberOfVertices, \"number of vertices\");\n        }\n    }\n\n    return messages;\n}", "summary_tokens": ["method", "that", "builds", "the", "scatter", "function", "using", "a", "co", "group", "operator", "for", "a", "simple", "vertex", "without", "degrees"], "project": "flink"}
{"id": 865, "code": "public static void deregisterStreamConsumers(\n        final Properties configProps, final List<String> streams) {\n    if (isConsumerDeregistrationRequired(configProps)) {\n        StreamConsumerRegistrar registrar = createStreamConsumerRegistrar(configProps, streams);\n        try {\n            deregisterStreamConsumers(registrar, configProps, streams);\n        } finally {\n            registrar.close();\n        }\n    }\n}", "summary_tokens": ["deregisters", "stream", "consumers", "for", "the", "given", "streams", "if", "efo", "is", "enabled", "with", "eager", "lazy", "registration", "strategy"], "project": "flink"}
{"id": 4540, "code": "private void notifyFlusherException(Throwable t) {\n    if (flusherException == null) {\n        LOG.error(\"An exception happened while flushing the outputs\", t);\n        flusherException = t;\n        volatileFlusherException = t;\n    }\n}", "summary_tokens": ["notifies", "the", "writer", "that", "the", "output", "flusher", "thread", "encountered", "an", "exception"], "project": "flink"}
{"id": 7800, "code": "private void testNoTimerFiringForPurgedMergingWindow(final TimeDomainAdaptor timeAdaptor)\n        throws Exception {\n\n    MergingWindowAssigner<Integer, TimeWindow> mockAssigner = mockMergingAssigner();\n    timeAdaptor.setIsEventTime(mockAssigner);\n    Trigger<Integer, TimeWindow> mockTrigger = mockTrigger();\n\n    @SuppressWarnings(\"unchecked\")\n    InternalWindowFunction<Iterable<Integer>, List<Integer>, Integer, TimeWindow>\n            mockWindowFunction = mock(InternalWindowFunction.class);\n\n    KeyedOneInputStreamOperatorTestHarness<Integer, Integer, List<Integer>> testHarness =\n            createWindowOperator(mockAssigner, mockTrigger, 0L, mockWindowFunction);\n\n    testHarness.open();\n\n    timeAdaptor.advanceTime(testHarness, Long.MIN_VALUE);\n\n    when(mockAssigner.assignWindows(anyInt(), anyLong(), anyAssignerContext()))\n            .thenReturn(Arrays.asList(new TimeWindow(2, 4)));\n\n    assertEquals(0, testHarness.extractOutputStreamRecords().size());\n    assertEquals(0, testHarness.numKeyedStateEntries());\n\n    doAnswer(\n                    new Answer<TriggerResult>() {\n                        @Override\n                        public TriggerResult answer(InvocationOnMock invocation)\n                                throws Exception {\n                            Trigger.TriggerContext context =\n                                    (Trigger.TriggerContext) invocation.getArguments()[3];\n                                \n                            timeAdaptor.registerTimer(context, 0L);\n                            return TriggerResult.PURGE;\n                        }\n                    })\n            .when(mockTrigger)\n            .onElement(\n                    Matchers.<Integer>anyObject(),\n                    anyLong(),\n                    anyTimeWindow(),\n                    anyTriggerContext());\n\n    testHarness.processElement(new StreamRecord<>(0, 0L));\n\n    assertEquals(1, testHarness.numKeyedStateEntries()); \n    assertEquals(2, timeAdaptor.numTimers(testHarness)); \n\n    timeAdaptor.advanceTime(testHarness, 0L);\n\n        \n    timeAdaptor.verifyTriggerCallback(mockTrigger, times(1), null, null);\n\n    verify(mockWindowFunction, never())\n            .process(\n                    anyInt(),\n                    anyTimeWindow(),\n                    anyInternalWindowContext(),\n                    anyIntIterable(),\n                    WindowOperatorContractTest.<List<Integer>>anyCollector());\n\n    assertEquals(1, timeAdaptor.numTimers(testHarness)); \n}", "summary_tokens": ["verify", "that", "we", "neither", "invoke", "the", "trigger", "nor", "the", "window", "function", "if", "a", "timer", "for", "an", "empty", "merging", "window", "fires"], "project": "flink"}
{"id": 9361, "code": "public static <T> ExternalTypeInfo<T> of(DataType dataType, boolean isInternalInput) {\n    final TypeSerializer<T> serializer =\n            createExternalTypeSerializer(dataType, isInternalInput);\n    return new ExternalTypeInfo<>(dataType, serializer);\n}", "summary_tokens": ["creates", "type", "information", "for", "a", "data", "type", "that", "is", "possibly", "represented", "by", "internal", "data", "structures", "but", "serialized", "and", "deserialized", "into", "external", "data", "structures"], "project": "flink"}
{"id": 3227, "code": "public GraphCsvReader ignoreFirstLineVertices() {\n    if (this.vertexReader != null) {\n        this.vertexReader.ignoreFirstLine();\n    }\n    return this;\n}", "summary_tokens": ["sets", "the", "csv", "reader", "for", "the", "vertices", "file", "to", "ignore", "the", "first", "line"], "project": "flink"}
{"id": 6562, "code": "public void testRegistryNormal() {\n\n    SharedStateRegistry sharedStateRegistry = new SharedStateRegistryImpl();\n\n        \n    TestSharedState firstState = new TestSharedState(\"first\");\n    StreamStateHandle result =\n            sharedStateRegistry.registerReference(\n                    firstState.getRegistrationKey(), firstState, 0L);\n    assertTrue(firstState == result);\n    assertFalse(firstState.isDiscarded());\n\n        \n    TestSharedState secondState = new TestSharedState(\"second\");\n    result =\n            sharedStateRegistry.registerReference(\n                    secondState.getRegistrationKey(), secondState, 0L);\n    assertTrue(secondState == result);\n    assertFalse(firstState.isDiscarded());\n    assertFalse(secondState.isDiscarded());\n\n        \n        \n    TestSharedState firstStatePrime =\n            new TestSharedState(firstState.getRegistrationKey().getKeyString());\n    result =\n            sharedStateRegistry.registerReference(\n                    firstState.getRegistrationKey(), firstStatePrime, 0L);\n    assertTrue(firstStatePrime == result);\n    assertFalse(firstStatePrime.isDiscarded());\n    assertFalse(firstState == result);\n    assertTrue(firstState.isDiscarded());\n\n        \n        \n    sharedStateRegistry.checkpointCompleted(0L);\n    TestSharedState firstStateDPrime =\n            new TestSharedState(firstState.getRegistrationKey().getKeyString());\n    result =\n            sharedStateRegistry.registerReference(\n                    firstState.getRegistrationKey(), firstStateDPrime, 0L);\n    assertFalse(firstStateDPrime == result);\n    assertTrue(firstStateDPrime.isDiscarded());\n    assertTrue(firstStatePrime == result);\n    assertFalse(firstStatePrime.isDiscarded());\n\n        \n    result =\n            sharedStateRegistry.registerReference(\n                    firstState.getRegistrationKey(), firstState, 0L);\n    assertTrue(firstStatePrime == result);\n    assertFalse(firstStatePrime.isDiscarded());\n\n    sharedStateRegistry.unregisterUnusedState(1L);\n    assertTrue(secondState.isDiscarded());\n    assertTrue(firstState.isDiscarded());\n}", "summary_tokens": ["validate", "that", "all", "states", "can", "be", "correctly", "registered", "at", "the", "registry"], "project": "flink"}
{"id": 1599, "code": "public static <T> TypeSerializer<T> wrap(\n        @Nonnull TypeSerializer<T> originalSerializer, boolean padNullValueIfFixedLen) {\n    return originalSerializer instanceof NullableSerializer\n            ? originalSerializer\n            : new NullableSerializer<>(originalSerializer, padNullValueIfFixedLen);\n}", "summary_tokens": ["this", "method", "wraps", "the", "original", "serializer", "with", "the", "nullable", "serializer", "if", "not", "already", "wrapped"], "project": "flink"}
{"id": 2189, "code": "public void testAllCorePatterns() {\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"java.\"));\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"org.apache.flink.\"));\n    assertTrue(PARENT_FIRST_PACKAGES.contains(\"javax.annotation.\"));\n}", "summary_tokens": ["all", "java", "and", "flink", "classes", "must", "be", "loaded", "parent", "first"], "project": "flink"}
{"id": 2973, "code": "public void replace(String key, StringResourceVersion resourceVersion, T state)\n        throws Exception {\n    checkNotNull(key, \"Key in ConfigMap.\");\n    checkNotNull(state, \"State.\");\n\n    final RetrievableStateHandle<T> oldStateHandle = getAndLock(key);\n\n    final RetrievableStateHandle<T> newStateHandle = storage.store(state);\n\n    final byte[] serializedStateHandle = serializeOrDiscard(newStateHandle);\n\n        \n    boolean discardOldState = false;\n    boolean discardNewState = true;\n    try {\n        boolean success =\n                kubeClient\n                        .checkAndUpdateConfigMap(\n                                configMapName,\n                                c -> {\n                                    if (KubernetesLeaderElector.hasLeadership(\n                                            c, lockIdentity)) {\n                                            \n                                        if (c.getData().containsKey(key)) {\n                                            c.getData()\n                                                    .put(\n                                                            key,\n                                                            encodeStateHandle(\n                                                                    serializedStateHandle));\n                                        } else {\n                                            throw new CompletionException(\n                                                    getKeyNotExistException(key));\n                                        }\n                                        return Optional.of(c);\n                                    }\n                                    return Optional.empty();\n                                })\n                        .get();\n\n            \n        discardOldState = success;\n        discardNewState = !success;\n    } catch (Exception ex) {\n        final Optional<PossibleInconsistentStateException> possibleInconsistentStateException =\n                ExceptionUtils.findThrowable(ex, PossibleInconsistentStateException.class);\n        if (possibleInconsistentStateException.isPresent()) {\n                \n                \n            discardNewState = false;\n            throw possibleInconsistentStateException.get();\n        }\n\n        throw ExceptionUtils.findThrowable(ex, NotExistException.class).orElseThrow(() -> ex);\n    } finally {\n        if (discardNewState) {\n            newStateHandle.discardState();\n        }\n\n        if (discardOldState) {\n            oldStateHandle.discardState();\n        }\n    }\n}", "summary_tokens": ["replaces", "a", "state", "handle", "in", "config", "map", "and", "discards", "the", "old", "state", "handle"], "project": "flink"}
{"id": 2666, "code": "public <K extends Comparable<K>> PartitionOperator<T> partitionCustom(\n        Partitioner<K> partitioner, KeySelector<T, K> keyExtractor) {\n    final TypeInformation<K> keyType =\n            TypeExtractor.getKeySelectorTypes(keyExtractor, getType());\n    return new PartitionOperator<>(\n            this,\n            new Keys.SelectorFunctionKeys<>(keyExtractor, getType(), keyType),\n            clean(partitioner),\n            Utils.getCallLocationName());\n}", "summary_tokens": ["partitions", "a", "data", "set", "on", "the", "key", "returned", "by", "the", "selector", "using", "a", "custom", "partitioner"], "project": "flink"}
{"id": 6111, "code": "public void testZooKeeperRegistry() throws Exception {\n    Configuration configuration = new Configuration();\n    configuration.setString(\n            HighAvailabilityOptions.HA_ZOOKEEPER_QUORUM, testingServer.getConnectString());\n    configuration.setString(HighAvailabilityOptions.HA_MODE, \"zookeeper\");\n\n    final HighAvailabilityServices zkHaService =\n            new ZooKeeperHaServices(\n                    ZooKeeperUtils.startCuratorFramework(\n                            configuration, NoOpFatalErrorHandler.INSTANCE),\n                    Executors.directExecutor(),\n                    configuration,\n                    new VoidBlobStore());\n\n    final RunningJobsRegistry zkRegistry = zkHaService.getRunningJobsRegistry();\n\n    try {\n        JobID jobID = JobID.generate();\n        assertEquals(JobSchedulingStatus.PENDING, zkRegistry.getJobSchedulingStatus(jobID));\n\n            \n        zkRegistry.setJobRunning(jobID);\n        assertEquals(JobSchedulingStatus.RUNNING, zkRegistry.getJobSchedulingStatus(jobID));\n\n            \n        zkRegistry.setJobFinished(jobID);\n        assertEquals(JobSchedulingStatus.DONE, zkRegistry.getJobSchedulingStatus(jobID));\n\n        zkRegistry.clearJob(jobID);\n        assertEquals(JobSchedulingStatus.PENDING, zkRegistry.getJobSchedulingStatus(jobID));\n\n            \n        zkRegistry.clearJob(jobID);\n    } finally {\n        zkHaService.closeAndCleanupAllData();\n    }\n}", "summary_tokens": ["tests", "that", "the", "function", "of", "zookeeper", "registry", "set", "job", "running", "set", "job", "finished", "is", "job", "running"], "project": "flink"}
{"id": 1059, "code": "public InputDependencyConstraint getDefaultInputDependencyConstraint() {\n    return InputDependencyConstraint.ANY;\n}", "summary_tokens": ["this", "method", "is", "deprecated"], "project": "flink"}
{"id": 5191, "code": "public CompletableFuture<Void> awaitAsync() {\n    phaser.arriveAndDeregister();\n    return terminationFuture;\n}", "summary_tokens": ["returns", "a", "future", "that", "completes", "when", "the", "in", "flight", "requests", "that", "were", "registered", "prior", "to", "calling", "this", "method", "are", "deregistered"], "project": "flink"}
{"id": 1177, "code": "public void setFilePaths(Path... filePaths) {\n    if (!supportsMultiPaths() && filePaths.length > 1) {\n        throw new UnsupportedOperationException(\n                \"Multiple paths are not supported by this FileInputFormat.\");\n    }\n    if (filePaths.length < 1) {\n        throw new IllegalArgumentException(\"At least one file path must be specified.\");\n    }\n    if (filePaths.length == 1) {\n            \n        this.filePath = filePaths[0];\n    } else {\n            \n        this.filePath = null;\n    }\n\n    this.filePaths = filePaths;\n}", "summary_tokens": ["sets", "multiple", "paths", "of", "files", "to", "be", "read"], "project": "flink"}
{"id": 3093, "code": "public static <T> IterativeCondition<T> trueFunction() {\n    return new SimpleCondition<T>() {\n        private static final long serialVersionUID = 8379409657655181451L;\n\n        @Override\n        public boolean filter(T value) throws Exception {\n            return true;\n        }\n    };\n}", "summary_tokens": ["an", "iterative", "condition", "that", "always", "returns", "true"], "project": "flink"}
{"id": 1268, "code": "public Operator<T> getPartialSolution() {\n    return this.inputPlaceHolder;\n}", "summary_tokens": ["the", "operator", "representing", "the", "partial", "solution"], "project": "flink"}
{"id": 2917, "code": "public void testMaxByComparisonMustReturnATuple() {\n    SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>> maxByTuple =\n            new SelectByMaxFunction<Tuple5<Integer, Long, String, Long, Integer>>(\n                    tupleTypeInfo, new int[] {0});\n\n    try {\n        Assert.assertSame(\n                \"SelectByMax must return bigger tuple\",\n                bigger,\n                maxByTuple.reduce(bigger, bigger));\n        Assert.assertSame(\n                \"SelectByMax must return smaller tuple\",\n                smaller,\n                maxByTuple.reduce(smaller, smaller));\n    } catch (Exception e) {\n        Assert.fail(\"No exception should be thrown while comparing both tuples\");\n    }\n}", "summary_tokens": ["checks", "whether", "reduce", "does", "behave", "as", "expected", "if", "both", "values", "are", "the", "same", "object"], "project": "flink"}
{"id": 3801, "code": "private static void printHelp() {\n    System.out.print(\"Flink Python Shell\\n\");\n    System.out.print(\"Usage: pyflink-shell.sh [local|remote|yarn] [options] <args>...\\n\");\n    System.out.print('\\n');\n    printLocalHelp();\n    printRemoteHelp();\n    printYarnHelp();\n    System.out.println(\"-h | --help\");\n    System.out.println(\"      Prints this usage text\");\n    System.exit(0);\n}", "summary_tokens": ["prints", "the", "help", "for", "the", "client"], "project": "flink"}
{"id": 8436, "code": "protected List<String> supportedFormatProperties() {\n    return Collections.emptyList();\n}", "summary_tokens": ["format", "specific", "supported", "properties"], "project": "flink"}
{"id": 9293, "code": "public WindowOperatorBuilder withInputCountIndex(int inputCountIndex) {\n    this.inputCountIndex = inputCountIndex;\n    return this;\n}", "summary_tokens": ["the", "index", "of", "count", "in", "the", "aggregates"], "project": "flink"}
{"id": 1853, "code": "public void setNumFields(final int numFields) {\n    final int oldNumFields = this.numFields;\n        \n    if (numFields > oldNumFields) {\n        makeSpace(numFields);\n        for (int i = oldNumFields; i < numFields; i++) {\n            this.offsets[i] = NULL_INDICATOR_OFFSET;\n        }\n        markModified(oldNumFields);\n    } else {\n            \n            \n            \n            \n        markModified(numFields);\n    }\n    this.numFields = numFields;\n}", "summary_tokens": ["sets", "the", "number", "of", "fields", "in", "the", "record"], "project": "flink"}
{"id": 6098, "code": "public void testResourceManagerLeaderElection() throws Exception {\n    LeaderContender leaderContender1 = mock(LeaderContender.class);\n    LeaderContender leaderContender2 = mock(LeaderContender.class);\n\n    LeaderElectionService leaderElectionService1 =\n            embeddedHaServices.getResourceManagerLeaderElectionService();\n    LeaderElectionService leaderElectionService2 =\n            embeddedHaServices.getResourceManagerLeaderElectionService();\n\n    leaderElectionService1.start(leaderContender1);\n    leaderElectionService2.start(leaderContender2);\n\n    ArgumentCaptor<UUID> leaderIdArgumentCaptor1 = ArgumentCaptor.forClass(UUID.class);\n    ArgumentCaptor<UUID> leaderIdArgumentCaptor2 = ArgumentCaptor.forClass(UUID.class);\n    verify(leaderContender1, atLeast(0)).grantLeadership(leaderIdArgumentCaptor1.capture());\n    verify(leaderContender2, atLeast(0)).grantLeadership(leaderIdArgumentCaptor2.capture());\n\n    assertTrue(\n            leaderIdArgumentCaptor1.getAllValues().isEmpty()\n                    ^ leaderIdArgumentCaptor2.getAllValues().isEmpty());\n}", "summary_tokens": ["tests", "that", "exactly", "one", "resource", "manager", "is", "elected", "as", "the", "leader"], "project": "flink"}
{"id": 1629, "code": "public static <IN, OUT, E extends Throwable> List<OUT> decodeListFromConfig(\n        final ReadableConfig configuration,\n        final ConfigOption<List<IN>> key,\n        final FunctionWithException<IN, OUT, E> mapper)\n        throws E {\n\n    checkNotNull(configuration);\n    checkNotNull(key);\n    checkNotNull(mapper);\n\n    final List<IN> encodedString = configuration.get(key);\n    if (encodedString == null || encodedString.isEmpty()) {\n        return new ArrayList<>();\n    }\n\n    final List<OUT> result = new ArrayList<>(encodedString.size());\n    for (IN input : encodedString) {\n        result.add(mapper.apply(input));\n    }\n    return result;\n}", "summary_tokens": ["gets", "a", "list", "of", "values", "of", "type", "in", "from", "a", "readable", "config", "and", "transforms", "it", "to", "a", "list", "of", "type", "out", "based", "on", "the", "provided", "mapper", "function"], "project": "flink"}
{"id": 5953, "code": "private static <T extends StateObject> StateObjectCollection<T> deepCopy(\n        StateObjectCollection<T> original) {\n    if (original == null || original.isEmpty()) {\n        return StateObjectCollection.empty();\n    }\n    return new StateObjectCollection<>(\n            original.stream()\n                    .map(PrioritizedOperatorSubtaskStateTest::deepCopy)\n                    .collect(Collectors.toList()));\n}", "summary_tokens": ["creates", "a", "deep", "copy", "of", "the", "first", "state", "object", "in", "the", "given", "collection", "or", "null", "if", "the", "collection", "is", "empy"], "project": "flink"}
{"id": 8287, "code": "public Object[] toObjectArray() {\n    if (isPrimitiveArray) {\n        Class<?> arrayClass = array.getClass();\n        if (int[].class.equals(arrayClass)) {\n            return ArrayUtils.toObject((int[]) array);\n        } else if (long[].class.equals(arrayClass)) {\n            return ArrayUtils.toObject((long[]) array);\n        } else if (float[].class.equals(arrayClass)) {\n            return ArrayUtils.toObject((float[]) array);\n        } else if (double[].class.equals(arrayClass)) {\n            return ArrayUtils.toObject((double[]) array);\n        } else if (short[].class.equals(arrayClass)) {\n            return ArrayUtils.toObject((short[]) array);\n        } else if (byte[].class.equals(arrayClass)) {\n            return ArrayUtils.toObject((byte[]) array);\n        } else if (boolean[].class.equals(arrayClass)) {\n            return ArrayUtils.toObject((boolean[]) array);\n        }\n        throw new RuntimeException(\"Unsupported primitive array: \" + arrayClass);\n    } else {\n        return (Object[]) array;\n    }\n}", "summary_tokens": ["converts", "this", "generic", "array", "data", "into", "an", "array", "of", "java", "object"], "project": "flink"}
{"id": 4552, "code": "public Buffer build() {\n    writerPosition.update();\n    int cachedWriterPosition = writerPosition.getCached();\n    Buffer slice =\n            buffer.readOnlySlice(\n                    currentReaderPosition, cachedWriterPosition - currentReaderPosition);\n    currentReaderPosition = cachedWriterPosition;\n    return slice.retainBuffer();\n}", "summary_tokens": ["sliced", "buffer", "containing", "the", "not", "yet", "consumed", "data"], "project": "flink"}
{"id": 6798, "code": "public static void putValueVersion(MemorySegment memorySegment, int offset, int version) {\n    memorySegment.putInt(offset + VALUE_VERSION_OFFSET, version);\n}", "summary_tokens": ["puts", "the", "version", "of", "value", "to", "value", "space"], "project": "flink"}
{"id": 1155, "code": "protected SequentialStatistics createStatistics(\n        List<FileStatus> files, FileBaseStatistics stats) throws IOException {\n    if (files.isEmpty()) {\n        return null;\n    }\n\n    BlockInfo blockInfo = new BlockInfo();\n    long totalCount = 0;\n    for (FileStatus file : files) {\n            \n        if (file.getLen() < blockInfo.getInfoSize()) {\n            continue;\n        }\n\n        FileSystem fs = file.getPath().getFileSystem();\n        try (FSDataInputStream fdis = fs.open(file.getPath(), blockInfo.getInfoSize())) {\n            fdis.seek(file.getLen() - blockInfo.getInfoSize());\n\n            blockInfo.read(new DataInputViewStreamWrapper(fdis));\n            totalCount += blockInfo.getAccumulatedRecordCount();\n        }\n    }\n\n    final float avgWidth =\n            totalCount == 0 ? 0 : ((float) stats.getTotalInputSize() / totalCount);\n    return new SequentialStatistics(\n            stats.getLastModificationTime(), stats.getTotalInputSize(), avgWidth, totalCount);\n}", "summary_tokens": ["fill", "in", "the", "statistics"], "project": "flink"}
{"id": 2309, "code": "public static String formatAddress(int address) {\n    int b1 = (address >>> 24) & 0xff;\n    int b2 = (address >>> 16) & 0xff;\n    int b3 = (address >>> 8) & 0xff;\n    int b4 = address & 0xff;\n\n    return \"\" + b1 + '.' + b2 + '.' + b3 + '.' + b4;\n}", "summary_tokens": ["util", "method", "to", "create", "a", "string", "representation", "of", "a", "0", "bit", "integer", "representing", "an", "ipv", "0", "address"], "project": "flink"}
{"id": 547, "code": "static <V> KafkaRecordDeserializationSchema<V> of(\n        KafkaDeserializationSchema<V> kafkaDeserializationSchema) {\n    return new KafkaDeserializationSchemaWrapper<>(kafkaDeserializationSchema);\n}", "summary_tokens": ["wraps", "a", "legacy", "kafka", "deserialization", "schema", "as", "the", "deserializer", "of", "the", "consumer", "record", "consumer", "records"], "project": "flink"}
{"id": 2519, "code": "public static Tuple3<Class<? extends SpecificRecord>, SpecificRecord, Row>\n        getSpecificTestData() {\n    final Address addr =\n            Address.newBuilder()\n                    .setNum(42)\n                    .setStreet(\"Main Street 42\")\n                    .setCity(\"Test City\")\n                    .setState(\"Test State\")\n                    .setZip(\"12345\")\n                    .build();\n\n    final Row rowAddr = new Row(5);\n    rowAddr.setField(0, 42);\n    rowAddr.setField(1, \"Main Street 42\");\n    rowAddr.setField(2, \"Test City\");\n    rowAddr.setField(3, \"Test State\");\n    rowAddr.setField(4, \"12345\");\n\n    final User user =\n            User.newBuilder()\n                    .setName(\"Charlie\")\n                    .setFavoriteNumber(null)\n                    .setFavoriteColor(\"blue\")\n                    .setTypeLongTest(1337L)\n                    .setTypeDoubleTest(1.337d)\n                    .setTypeNullTest(null)\n                    .setTypeBoolTest(false)\n                    .setTypeArrayString(Arrays.asList(\"hello\", \"world\"))\n                    .setTypeArrayBoolean(Arrays.asList(true, true, false))\n                    .setTypeNullableArray(null)\n                    .setTypeEnum(Colors.RED)\n                    .setTypeMap(Collections.singletonMap(\"test\", 12L))\n                    .setTypeFixed(\n                            new Fixed16(\n                                    new byte[] {\n                                        1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16\n                                    }))\n                    .setTypeUnion(12.0)\n                    .setTypeNested(addr)\n                    .setTypeBytes(ByteBuffer.allocate(10))\n                    .setTypeDate(LocalDate.parse(\"2014-03-01\"))\n                    .setTypeTimeMillis(LocalTime.parse(\"12:12:12\"))\n                    .setTypeTimeMicros(\n                            LocalTime.ofSecondOfDay(0).plus(123456L, ChronoUnit.MICROS))\n                    .setTypeTimestampMillis(Instant.parse(\"2014-03-01T12:12:12.321Z\"))\n                    .setTypeTimestampMicros(\n                            Instant.ofEpochSecond(0).plus(123456L, ChronoUnit.MICROS))\n                        \n                        \n                    .setTypeDecimalBytes(\n                            ByteBuffer.wrap(\n                                    BigDecimal.valueOf(2000, 2).unscaledValue().toByteArray()))\n                        \n                        \n                        \n                    .setTypeDecimalFixed(\n                            new Fixed2(\n                                    BigDecimal.valueOf(2000, 2).unscaledValue().toByteArray()))\n                    .build();\n\n    final Row rowUser = new Row(23);\n    rowUser.setField(0, \"Charlie\");\n    rowUser.setField(1, null);\n    rowUser.setField(2, \"blue\");\n    rowUser.setField(3, 1337L);\n    rowUser.setField(4, 1.337d);\n    rowUser.setField(5, null);\n    rowUser.setField(6, false);\n    rowUser.setField(7, new String[] {\"hello\", \"world\"});\n    rowUser.setField(8, new Boolean[] {true, true, false});\n    rowUser.setField(9, null);\n    rowUser.setField(10, \"RED\");\n    rowUser.setField(11, Collections.singletonMap(\"test\", 12L));\n    rowUser.setField(12, new byte[] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16});\n    rowUser.setField(13, 12.0);\n    rowUser.setField(14, rowAddr);\n    rowUser.setField(15, new byte[10]);\n    rowUser.setField(16, Date.valueOf(\"2014-03-01\"));\n    rowUser.setField(17, Time.valueOf(\"12:12:12\"));\n    rowUser.setField(\n            18, Time.valueOf(LocalTime.ofSecondOfDay(0).plus(123456L, ChronoUnit.MICROS)));\n    rowUser.setField(19, Timestamp.valueOf(\"2014-03-01 12:12:12.321\"));\n    rowUser.setField(\n            20, Timestamp.from(Instant.ofEpochSecond(0).plus(123456L, ChronoUnit.MICROS)));\n    rowUser.setField(21, BigDecimal.valueOf(2000, 2));\n    rowUser.setField(22, BigDecimal.valueOf(2000, 2));\n\n    final Tuple3<Class<? extends SpecificRecord>, SpecificRecord, Row> t = new Tuple3<>();\n    t.f0 = User.class;\n    t.f1 = user;\n    t.f2 = rowUser;\n\n    return t;\n}", "summary_tokens": ["tests", "all", "avro", "data", "types", "as", "well", "as", "nested", "types", "for", "a", "specific", "record"], "project": "flink"}
{"id": 4013, "code": "public void testOnStartIsCalledWhenRpcEndpointStarts() throws Exception {\n    final OnStartEndpoint onStartEndpoint = new OnStartEndpoint(akkaRpcService, null);\n\n    try {\n        onStartEndpoint.start();\n        onStartEndpoint.awaitUntilOnStartCalled();\n    } finally {\n        RpcUtils.terminateRpcEndpoint(onStartEndpoint, timeout);\n    }\n}", "summary_tokens": ["tests", "that", "the", "rpc", "endpoint", "on", "start", "method", "is", "called", "when", "the", "rpc", "endpoint", "is", "started"], "project": "flink"}
{"id": 3837, "code": "public static ArrowWriter<RowData> createRowDataArrowWriter(\n        VectorSchemaRoot root, RowType rowType) {\n    ArrowFieldWriter<RowData>[] fieldWriters =\n            new ArrowFieldWriter[root.getFieldVectors().size()];\n    List<FieldVector> vectors = root.getFieldVectors();\n    for (int i = 0; i < vectors.size(); i++) {\n        FieldVector vector = vectors.get(i);\n        vector.allocateNew();\n        fieldWriters[i] = createArrowFieldWriterForRow(vector, rowType.getTypeAt(i));\n    }\n\n    return new ArrowWriter<>(root, fieldWriters);\n}", "summary_tokens": ["creates", "an", "arrow", "writer", "for", "the", "specified", "vector", "schema", "root"], "project": "flink"}
{"id": 1014, "code": "private void applySystemProperties() {\n  Map<String, String> systemProperties = getConfSystemProperties();\n  for (Entry<String, String> systemProperty : systemProperties.entrySet()) {\n    this.set(systemProperty.getKey(), systemProperty.getValue());\n  }\n}", "summary_tokens": ["apply", "system", "properties", "to", "this", "object", "if", "the", "property", "name", "is", "defined", "in", "conf", "vars", "and", "the", "value", "is", "non", "null", "and", "not", "an", "empty", "string"], "project": "flink"}
{"id": 691, "code": "public void runSimpleConcurrentProducerConsumerTopology() throws Exception {\n    final String topic = \"concurrentProducerConsumerTopic_\" + UUID.randomUUID().toString();\n    final String additionalEmptyTopic = \"additionalEmptyTopic_\" + UUID.randomUUID().toString();\n\n    final int parallelism = 3;\n    final int elementsPerPartition = 100;\n    final int totalElements = parallelism * elementsPerPartition;\n\n    createTestTopic(topic, parallelism, 2);\n    createTestTopic(\n            additionalEmptyTopic,\n            parallelism,\n            1); \n\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(parallelism);\n    env.enableCheckpointing(500);\n    env.setRestartStrategy(RestartStrategies.noRestart()); \n\n    TypeInformation<Tuple2<Long, String>> longStringType =\n            TypeInformation.of(new TypeHint<Tuple2<Long, String>>() {});\n\n    TypeInformationSerializationSchema<Tuple2<Long, String>> sourceSchema =\n            new TypeInformationSerializationSchema<>(longStringType, env.getConfig());\n\n    TypeInformationSerializationSchema<Tuple2<Long, String>> sinkSchema =\n            new TypeInformationSerializationSchema<>(longStringType, env.getConfig());\n\n        \n\n    DataStream<Tuple2<Long, String>> stream =\n            env.addSource(\n                    new RichParallelSourceFunction<Tuple2<Long, String>>() {\n\n                        private boolean running = true;\n\n                        @Override\n                        public void run(SourceContext<Tuple2<Long, String>> ctx)\n                                throws InterruptedException {\n                            int cnt =\n                                    getRuntimeContext().getIndexOfThisSubtask()\n                                            * elementsPerPartition;\n                            int limit = cnt + elementsPerPartition;\n\n                            while (running && cnt < limit) {\n                                ctx.collect(new Tuple2<>(1000L + cnt, \"kafka-\" + cnt));\n                                cnt++;\n                                    \n                                    \n                                    \n                                Thread.sleep(50);\n                            }\n                        }\n\n                        @Override\n                        public void cancel() {\n                            running = false;\n                        }\n                    });\n    Properties producerProperties =\n            FlinkKafkaProducerBase.getPropertiesFromBrokerList(brokerConnectionStrings);\n    producerProperties.setProperty(\"retries\", \"3\");\n    producerProperties.putAll(secureProps);\n    kafkaServer.produceIntoKafka(stream, topic, sinkSchema, producerProperties, null);\n\n        \n\n    List<String> topics = new ArrayList<>();\n    topics.add(topic);\n    topics.add(additionalEmptyTopic);\n\n    Properties props = new Properties();\n    props.putAll(standardProps);\n    props.putAll(secureProps);\n    DataStreamSource<Tuple2<Long, String>> consuming =\n            getStream(env, topics, sourceSchema, props);\n\n    consuming\n            .addSink(\n                    new RichSinkFunction<Tuple2<Long, String>>() {\n\n                        private int elCnt = 0;\n                        private BitSet validator = new BitSet(totalElements);\n\n                        @Override\n                        public void invoke(Tuple2<Long, String> value) throws Exception {\n                            String[] sp = value.f1.split(\"-\");\n                            int v = Integer.parseInt(sp[1]);\n\n                            assertEquals(value.f0 - 1000, (long) v);\n\n                            assertFalse(\"Received tuple twice\", validator.get(v));\n                            validator.set(v);\n                            elCnt++;\n\n                            if (elCnt == totalElements) {\n                                    \n                                int nc;\n                                if ((nc = validator.nextClearBit(0)) != totalElements) {\n                                    fail(\n                                            \"The bitset was not set to 1 on all elements. Next clear:\"\n                                                    + nc\n                                                    + \" Set: \"\n                                                    + validator);\n                                }\n                                throw new SuccessException();\n                            }\n                        }\n\n                        @Override\n                        public void close() throws Exception {\n                            super.close();\n                        }\n                    })\n            .setParallelism(1);\n\n    try {\n        tryExecutePropagateExceptions(env, \"runSimpleConcurrentProducerConsumerTopology\");\n    } catch (ProgramInvocationException | JobExecutionException e) {\n            \n        Throwable cause = e.getCause();\n\n            \n        int depth = 0;\n        while (cause != null && depth++ < 20) {\n            if (cause instanceof NotLeaderForPartitionException) {\n                throw (Exception) cause;\n            }\n            cause = cause.getCause();\n        }\n        throw e;\n    }\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["ensure", "kafka", "is", "working", "on", "both", "producer", "and", "consumer", "side"], "project": "flink"}
{"id": 174, "code": "public CassandraSink<IN> setUidHash(String uidHash) {\n    if (useDataStreamSink) {\n        getSinkTransformation().setUidHash(uidHash);\n    } else {\n        getTransformation().setUidHash(uidHash);\n    }\n    return this;\n}", "summary_tokens": ["sets", "an", "user", "provided", "hash", "for", "this", "operator"], "project": "flink"}
{"id": 9151, "code": "public static ArrayNode createArrayNode() {\n    return MAPPER.createArrayNode();\n}", "summary_tokens": ["returns", "a", "new", "array", "node"], "project": "flink"}
{"id": 6484, "code": "public static Function<AsynchronousJobOperationKey, CompletableFuture<OperationResult<String>>>\n        getResultIfKeyMatches(\n                OperationResult<String> resultToReturn,\n                AtomicReference<AsynchronousJobOperationKey> expectedKeyReference) {\n    return (AsynchronousJobOperationKey operationKey) -> {\n        if (operationKey.equals(expectedKeyReference.get())) {\n            return CompletableFuture.completedFuture(resultToReturn);\n        }\n        throw new RuntimeException(\n                \"Expected operation key \"\n                        + expectedKeyReference.get()\n                        + \", but received \"\n                        + operationKey);\n    };\n}", "summary_tokens": ["returns", "a", "function", "which", "returns", "the", "provided", "result", "when", "called", "with", "the", "key", "that", "the", "provided", "reference", "points", "to"], "project": "flink"}
{"id": 4573, "code": "long refreshAndGetTotal() {\n    return partition.getNumberOfQueuedBuffers();\n}", "summary_tokens": ["iterates", "over", "all", "sub", "partitions", "and", "collects", "the", "total", "number", "of", "queued", "buffers", "in", "a", "best", "effort", "way"], "project": "flink"}
{"id": 8795, "code": "private boolean has(Collection<CorDef> corDefs, CorRef corr) {\n    for (CorDef corDef : corDefs) {\n        if (corDef.corr.equals(corr.corr) && corDef.field == corr.field) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["returns", "whether", "a", "correlation", "id", "is", "satisfied", "by", "at", "least", "one", "of", "a", "collection", "of", "cor", "def", "s"], "project": "flink"}
{"id": 9234, "code": "private void cleanupExpiredVersionInState(long currentWatermark, List<RowData> rightRowsSorted)\n        throws Exception {\n    int i = 0;\n    int indexToKeep = firstIndexToKeep(currentWatermark, rightRowsSorted);\n        \n    while (i < indexToKeep) {\n        long rightTime = getRightTime(rightRowsSorted.get(i));\n        rightState.remove(rightTime);\n        i += 1;\n    }\n}", "summary_tokens": ["removes", "all", "expired", "version", "in", "the", "versioned", "table", "s", "state", "according", "to", "current", "watermark"], "project": "flink"}
{"id": 8349, "code": "public static int find(\n        MemorySegment[] segments1,\n        int offset1,\n        int numBytes1,\n        MemorySegment[] segments2,\n        int offset2,\n        int numBytes2) {\n    if (numBytes2 == 0) { \n        return offset1;\n    }\n    if (inFirstSegment(segments1, offset1, numBytes1)\n            && inFirstSegment(segments2, offset2, numBytes2)) {\n        byte first = segments2[0].get(offset2);\n        int end = numBytes1 - numBytes2 + offset1;\n        for (int i = offset1; i <= end; i++) {\n                \n            if (segments1[0].get(i) == first\n                    && segments1[0].equalTo(segments2[0], i, offset2, numBytes2)) {\n                return i;\n            }\n        }\n        return -1;\n    } else {\n        return findInMultiSegments(\n                segments1, offset1, numBytes1, segments2, offset2, numBytes2);\n    }\n}", "summary_tokens": ["find", "equal", "segments", "0", "in", "segments", "0"], "project": "flink"}
{"id": 8973, "code": "public static String treeToString(\n        ExecNode<?> node, List<ExecNode<?>> borders, boolean includingBorders) {\n    checkNotNull(node, \"node should not be null.\");\n        \n    List<ExecNode<?>> borderList =\n            new ArrayList<>(checkNotNull(borders, \"borders should not be null.\"));\n    TreeReuseInfo reuseInfo = new TreeReuseInfo(node, borderList);\n    return doConvertTreeToString(node, reuseInfo, true, borderList, includingBorders);\n}", "summary_tokens": ["converts", "an", "exec", "node", "tree", "to", "a", "string", "as", "a", "tree", "style"], "project": "flink"}
{"id": 8658, "code": "private static long parseTimestampTz(String dateStr, String tzStr) throws ParseException {\n    TimeZone tz = TIMEZONE_CACHE.get(tzStr);\n    return parseTimestampMillis(dateStr, DateTimeUtils.TIMESTAMP_FORMAT_STRING, tz);\n}", "summary_tokens": ["parse", "date", "time", "string", "to", "timestamp", "based", "on", "the", "given", "time", "zone", "string", "and", "format"], "project": "flink"}
{"id": 6635, "code": "public void testIncrementalRehash() {\n    final CopyOnWriteStateMap<Integer, Integer, ArrayList<Integer>> stateMap =\n            new CopyOnWriteStateMap<>(new ArrayListSerializer<>(IntSerializer.INSTANCE));\n\n    int insert = 0;\n    int remove = 0;\n    while (!stateMap.isRehashing()) {\n        stateMap.put(insert++, 0, new ArrayList<>());\n        if (insert % 8 == 0) {\n            stateMap.remove(remove++, 0);\n        }\n    }\n    Assert.assertEquals(insert - remove, stateMap.size());\n    while (stateMap.isRehashing()) {\n        stateMap.put(insert++, 0, new ArrayList<>());\n        if (insert % 8 == 0) {\n            stateMap.remove(remove++, 0);\n        }\n    }\n    Assert.assertEquals(insert - remove, stateMap.size());\n\n    for (int i = 0; i < insert; ++i) {\n        if (i < remove) {\n            Assert.assertFalse(stateMap.containsKey(i, 0));\n        } else {\n            Assert.assertTrue(stateMap.containsKey(i, 0));\n        }\n    }\n}", "summary_tokens": ["this", "test", "triggers", "incremental", "rehash", "and", "tests", "for", "corruptions"], "project": "flink"}
{"id": 9138, "code": "public static String regexpReplace(String str, String regex, String replacement) {\n    if (str == null || regex == null || replacement == null) {\n        return null;\n    }\n    try {\n        return str.replaceAll(regex, Matcher.quoteReplacement(replacement));\n    } catch (Exception e) {\n        LOG.error(\n                String.format(\n                        \"Exception in regexpReplace('%s', '%s', '%s')\",\n                        str, regex, replacement),\n                e);\n            \n        return null;\n    }\n}", "summary_tokens": ["returns", "a", "string", "resulting", "from", "replacing", "all", "substrings", "that", "match", "the", "regular", "expression", "with", "replacement"], "project": "flink"}
{"id": 2102, "code": "public static ConjunctFuture<Void> completeAll(\n        Collection<? extends CompletableFuture<?>> futuresToComplete) {\n    return new CompletionConjunctFuture(futuresToComplete);\n}", "summary_tokens": ["creates", "a", "conjunct", "future", "which", "is", "only", "completed", "after", "all", "given", "futures", "have", "completed"], "project": "flink"}
{"id": 2073, "code": "public static void tryEnrichTaskManagerError(@Nullable Throwable root) {\n    tryEnrichOutOfMemoryError(\n            root, TM_METASPACE_OOM_ERROR_MESSAGE, TM_DIRECT_OOM_ERROR_MESSAGE, null);\n}", "summary_tokens": ["tries", "to", "enrich", "the", "passed", "exception", "or", "its", "causes", "with", "additional", "information"], "project": "flink"}
{"id": 1130, "code": "public void add(Integer value) {\n    this.min = Math.min(this.min, value);\n}", "summary_tokens": ["consider", "using", "add", "int", "instead", "for", "primitive", "integer", "values"], "project": "flink"}
{"id": 8185, "code": "public static UniqueConstraint primaryKey(String name, List<String> columns) {\n    return new UniqueConstraint(name, false, ConstraintType.PRIMARY_KEY, columns);\n}", "summary_tokens": ["creates", "a", "non", "enforced", "constraint", "type", "primary", "key", "constraint"], "project": "flink"}
{"id": 2150, "code": "protected boolean allowNullInstances(TypeSerializer<T> serializer) {\n    return serializer.getClass().getName().endsWith(\"KryoSerializer\");\n}", "summary_tokens": ["allows", "type", "serializer", "create", "instance", "to", "return", "null"], "project": "flink"}
{"id": 2479, "code": "public CharSequence getFavoriteColor() {\n    return favorite_color;\n}", "summary_tokens": ["gets", "the", "value", "of", "the", "favorite", "color", "field"], "project": "flink"}
{"id": 539, "code": "public void recordCurrentOffset(TopicPartition tp, long offset) {\n    checkTopicPartitionTracked(tp);\n    offsets.get(tp).currentOffset = offset;\n}", "summary_tokens": ["update", "current", "consuming", "offset", "of", "the", "given", "topic", "partition"], "project": "flink"}
{"id": 3530, "code": "public float getFloat(String key, float defaultValue) {\n    String argument = getProperty(key, null);\n    return argument == null ? defaultValue : Float.parseFloat(argument);\n}", "summary_tokens": ["searches", "for", "the", "property", "with", "the", "specified", "key", "in", "this", "property", "list"], "project": "flink"}
{"id": 3266, "code": "public RMatGraph<T> setConstants(float a, float b, float c) {\n    Preconditions.checkArgument(\n            a >= 0.0f && b >= 0.0f && c >= 0.0f && a + b + c <= 1.0f,\n            \"RMat parameters A, B, and C must be non-negative and sum to less than or equal to one\");\n\n    this.a = a;\n    this.b = b;\n    this.c = c;\n\n    return this;\n}", "summary_tokens": ["the", "parameters", "for", "recursively", "subdividing", "the", "adjacency", "matrix"], "project": "flink"}
{"id": 432, "code": "private Operation convertShowFunctions(HiveParserASTNode ast) {\n    if (ast.getChildCount() == 2) {\n        assert (ast.getChild(0).getType() == HiveASTParser.KW_LIKE);\n        throw new ValidationException(\"SHOW FUNCTIONS LIKE is not supported yet\");\n    }\n    return new ShowFunctionsOperation();\n}", "summary_tokens": ["add", "the", "task", "according", "to", "the", "parsed", "command", "tree"], "project": "flink"}
{"id": 8184, "code": "public DataType getWatermarkExprOutputType() {\n    return watermarkExprOutputType;\n}", "summary_tokens": ["returns", "the", "data", "type", "of", "the", "computation", "result", "of", "watermark", "generation", "expression"], "project": "flink"}
{"id": 921, "code": "private boolean matchesSubscriptionMode(String topic) {\n    TopicName topicName = TopicName.get(topic);\n        \n    switch (subscriptionMode) {\n        case PersistentOnly:\n            return topicName.isPersistent();\n        case NonPersistentOnly:\n            return !topicName.isPersistent();\n        default:\n                \n            return true;\n    }\n}", "summary_tokens": ["filter", "the", "topic", "by", "regex", "subscription", "mode"], "project": "flink"}
{"id": 7144, "code": "public <T0, T1, T2, T3, T4>\n        SingleOutputStreamOperator<Tuple5<T0, T1, T2, T3, T4>> projectTuple5() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<Tuple5<T0, T1, T2, T3, T4>> tType =\n            new TupleTypeInfo<Tuple5<T0, T1, T2, T3, T4>>(fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<IN, Tuple5<T0, T1, T2, T3, T4>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 1540, "code": "public boolean equals(Object o) {\n    if (this == o) {\n        return true;\n    }\n    if (!(o instanceof Tuple5)) {\n        return false;\n    }\n    @SuppressWarnings(\"rawtypes\")\n    Tuple5 tuple = (Tuple5) o;\n    if (f0 != null ? !f0.equals(tuple.f0) : tuple.f0 != null) {\n        return false;\n    }\n    if (f1 != null ? !f1.equals(tuple.f1) : tuple.f1 != null) {\n        return false;\n    }\n    if (f2 != null ? !f2.equals(tuple.f2) : tuple.f2 != null) {\n        return false;\n    }\n    if (f3 != null ? !f3.equals(tuple.f3) : tuple.f3 != null) {\n        return false;\n    }\n    if (f4 != null ? !f4.equals(tuple.f4) : tuple.f4 != null) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["deep", "equality", "for", "tuples", "by", "calling", "equals", "on", "the", "tuple", "members"], "project": "flink"}
{"id": 7120, "code": "public String getQueryableStateName() {\n    return queryableStateName;\n}", "summary_tokens": ["returns", "the", "name", "under", "which", "the", "state", "can", "be", "queried"], "project": "flink"}
{"id": 5307, "code": "private void terminateExceptionally(Throwable throwable) {\n    checkpointScheduling.startCheckpointScheduler();\n    result.completeExceptionally(throwable);\n}", "summary_tokens": ["handles", "the", "termination", "of", "the", "stop", "with", "savepoint", "termination", "handler", "exceptionally", "without", "triggering", "a", "global", "job", "fail", "over", "but", "restarting", "the", "checkpointing"], "project": "flink"}
{"id": 4907, "code": "public void start() throws Exception {\n    synchronized (lock) {\n        checkState(!running, \"MiniCluster is already running\");\n\n        LOG.info(\"Starting Flink Mini Cluster\");\n        LOG.debug(\"Using configuration {}\", miniClusterConfiguration);\n\n        final Configuration configuration = miniClusterConfiguration.getConfiguration();\n        final boolean useSingleRpcService =\n                miniClusterConfiguration.getRpcServiceSharing() == RpcServiceSharing.SHARED;\n\n        try {\n            initializeIOFormatClasses(configuration);\n\n            rpcSystem = RpcSystem.load(configuration);\n\n            LOG.info(\"Starting Metrics Registry\");\n            metricRegistry =\n                    createMetricRegistry(\n                            configuration,\n                            rpcSystem.getMaximumMessageSizeInBytes(configuration));\n\n                \n            LOG.info(\"Starting RPC Service(s)\");\n\n            final RpcServiceFactory dispatcherResourceManagerComponentRpcServiceFactory;\n            final RpcService metricQueryServiceRpcService;\n\n            if (useSingleRpcService) {\n                    \n                commonRpcService = createLocalRpcService(configuration, rpcSystem);\n                final CommonRpcServiceFactory commonRpcServiceFactory =\n                        new CommonRpcServiceFactory(commonRpcService);\n                taskManagerRpcServiceFactory = commonRpcServiceFactory;\n                dispatcherResourceManagerComponentRpcServiceFactory = commonRpcServiceFactory;\n                metricQueryServiceRpcService =\n                        MetricUtils.startLocalMetricsRpcService(configuration, rpcSystem);\n            } else {\n\n                    \n                final String jobManagerExternalAddress =\n                        miniClusterConfiguration.getJobManagerExternalAddress();\n                final String taskManagerExternalAddress =\n                        miniClusterConfiguration.getTaskManagerExternalAddress();\n                final String jobManagerExternalPortRange =\n                        miniClusterConfiguration.getJobManagerExternalPortRange();\n                final String taskManagerExternalPortRange =\n                        miniClusterConfiguration.getTaskManagerExternalPortRange();\n                final String jobManagerBindAddress =\n                        miniClusterConfiguration.getJobManagerBindAddress();\n                final String taskManagerBindAddress =\n                        miniClusterConfiguration.getTaskManagerBindAddress();\n\n                dispatcherResourceManagerComponentRpcServiceFactory =\n                        new DedicatedRpcServiceFactory(\n                                configuration,\n                                jobManagerExternalAddress,\n                                jobManagerExternalPortRange,\n                                jobManagerBindAddress,\n                                rpcSystem);\n                taskManagerRpcServiceFactory =\n                        new DedicatedRpcServiceFactory(\n                                configuration,\n                                taskManagerExternalAddress,\n                                taskManagerExternalPortRange,\n                                taskManagerBindAddress,\n                                rpcSystem);\n\n                    \n                    \n                commonRpcService =\n                        createRemoteRpcService(\n                                configuration, jobManagerBindAddress, 0, rpcSystem);\n                metricQueryServiceRpcService =\n                        MetricUtils.startRemoteMetricsRpcService(\n                                configuration, commonRpcService.getAddress(), rpcSystem);\n            }\n\n            metricRegistry.startQueryService(metricQueryServiceRpcService, null);\n\n            processMetricGroup =\n                    MetricUtils.instantiateProcessMetricGroup(\n                            metricRegistry,\n                            RpcUtils.getHostname(commonRpcService),\n                            ConfigurationUtils.getSystemResourceMetricsProbingInterval(\n                                    configuration));\n\n            ioExecutor =\n                    Executors.newFixedThreadPool(\n                            ClusterEntrypointUtils.getPoolSize(configuration),\n                            new ExecutorThreadFactory(\"mini-cluster-io\"));\n            haServices = createHighAvailabilityServices(configuration, ioExecutor);\n\n            blobServer = new BlobServer(configuration, haServices.createBlobStore());\n            blobServer.start();\n\n            heartbeatServices = HeartbeatServices.fromConfiguration(configuration);\n\n            blobCacheService =\n                    new BlobCacheService(\n                            configuration,\n                            haServices.createBlobStore(),\n                            new InetSocketAddress(\n                                    InetAddress.getLocalHost(), blobServer.getPort()));\n\n            startTaskManagers();\n\n            MetricQueryServiceRetriever metricQueryServiceRetriever =\n                    new RpcMetricQueryServiceRetriever(\n                            metricRegistry.getMetricQueryServiceRpcService());\n\n            setupDispatcherResourceManagerComponents(\n                    configuration,\n                    dispatcherResourceManagerComponentRpcServiceFactory,\n                    metricQueryServiceRetriever);\n\n            resourceManagerLeaderRetriever = haServices.getResourceManagerLeaderRetriever();\n            dispatcherLeaderRetriever = haServices.getDispatcherLeaderRetriever();\n            clusterRestEndpointLeaderRetrievalService =\n                    haServices.getClusterRestEndpointLeaderRetriever();\n\n            dispatcherGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            commonRpcService,\n                            DispatcherGateway.class,\n                            DispatcherId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    21, Duration.ofMillis(5L), Duration.ofMillis(20L)));\n            resourceManagerGatewayRetriever =\n                    new RpcGatewayRetriever<>(\n                            commonRpcService,\n                            ResourceManagerGateway.class,\n                            ResourceManagerId::fromUuid,\n                            new ExponentialBackoffRetryStrategy(\n                                    21, Duration.ofMillis(5L), Duration.ofMillis(20L)));\n            webMonitorLeaderRetriever = new LeaderRetriever();\n\n            resourceManagerLeaderRetriever.start(resourceManagerGatewayRetriever);\n            dispatcherLeaderRetriever.start(dispatcherGatewayRetriever);\n            clusterRestEndpointLeaderRetrievalService.start(webMonitorLeaderRetriever);\n        } catch (Exception e) {\n                \n            try {\n                close();\n            } catch (Exception ee) {\n                e.addSuppressed(ee);\n            }\n            throw e;\n        }\n\n            \n        terminationFuture = new CompletableFuture<>();\n\n            \n        running = true;\n\n        LOG.info(\"Flink Mini Cluster started successfully\");\n    }\n}", "summary_tokens": ["starts", "the", "mini", "cluster", "based", "on", "the", "configured", "properties"], "project": "flink"}
{"id": 1331, "code": "public String getName() {\n    return name;\n}", "summary_tokens": ["returns", "the", "name", "of", "this", "state", "descriptor"], "project": "flink"}
{"id": 1032, "code": "public void testWikipediaEditsSource() throws Exception {\n    if (canConnect(1, TimeUnit.SECONDS)) {\n        final Time testTimeout = Time.seconds(60);\n        final WikipediaEditsSource wikipediaEditsSource = new WikipediaEditsSource();\n\n        ExecutorService executorService = null;\n        try {\n            executorService = Executors.newSingleThreadExecutor();\n            BlockingQueue<Object> collectedEvents = new ArrayBlockingQueue<>(1);\n            AtomicReference<Exception> asyncError = new AtomicReference<>();\n\n                \n                \n                \n                \n            executorService.execute(\n                    () -> {\n                        try {\n                            wikipediaEditsSource.run(\n                                    new CollectingSourceContext<>(collectedEvents));\n                        } catch (Exception e) {\n                            boolean interrupted = e instanceof InterruptedException;\n                            if (!interrupted) {\n                                LOG.warn(\"Failure in WikipediaEditsSource\", e);\n                            }\n\n                            asyncError.compareAndSet(null, e);\n                        }\n                    });\n\n            long deadline = deadlineNanos(testTimeout);\n\n            Object event = null;\n            Exception error = null;\n\n                \n            while (event == null && error == null && System.nanoTime() < deadline) {\n                event = collectedEvents.poll(1, TimeUnit.SECONDS);\n                error = asyncError.get();\n            }\n\n            if (error != null) {\n                    \n                fail(\"Failure in WikipediaEditsSource: \" + error.getMessage());\n            }\n\n            assertNotNull(\n                    \"Did not receive a WikipediaEditEvent within the desired timeout\", event);\n            assertTrue(\n                    \"Received unexpected event \" + event, event instanceof WikipediaEditEvent);\n        } finally {\n            wikipediaEditsSource.cancel();\n\n            if (executorService != null) {\n                executorService.shutdownNow();\n                executorService.awaitTermination(1, TimeUnit.SECONDS);\n            }\n        }\n    } else {\n        LOG.info(\"Skipping test, because not able to connect to IRC server.\");\n    }\n}", "summary_tokens": ["we", "first", "check", "the", "connection", "to", "the", "irc", "server"], "project": "flink"}
{"id": 7668, "code": "public void testEventTimeTimerWithState() throws Exception {\n\n    KeyedProcessOperator<Integer, Integer, String> operator =\n            new KeyedProcessOperator<>(\n                    new TriggeringStatefulFlatMapFunction(TimeDomain.EVENT_TIME));\n\n    OneInputStreamOperatorTestHarness<Integer, String> testHarness =\n            new KeyedOneInputStreamOperatorTestHarness<>(\n                    operator, new IdentityKeySelector<Integer>(), BasicTypeInfo.INT_TYPE_INFO);\n\n    testHarness.setup();\n    testHarness.open();\n\n    testHarness.processWatermark(new Watermark(1));\n    testHarness.processElement(new StreamRecord<>(17, 0L)); \n    testHarness.processElement(new StreamRecord<>(13, 0L)); \n\n    testHarness.processWatermark(new Watermark(2));\n    testHarness.processElement(new StreamRecord<>(42, 1L)); \n    testHarness.processElement(new StreamRecord<>(13, 1L)); \n\n    testHarness.processWatermark(new Watermark(6));\n    testHarness.processWatermark(new Watermark(7));\n\n    ConcurrentLinkedQueue<Object> expectedOutput = new ConcurrentLinkedQueue<>();\n\n    expectedOutput.add(new Watermark(1L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:17\", 0L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:13\", 0L));\n    expectedOutput.add(new Watermark(2L));\n    expectedOutput.add(new StreamRecord<>(\"INPUT:42\", 1L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:17\", 6L));\n    expectedOutput.add(new Watermark(6L));\n    expectedOutput.add(new StreamRecord<>(\"STATE:42\", 7L));\n    expectedOutput.add(new Watermark(7L));\n\n    TestHarnessUtil.assertOutputEquals(\n            \"Output was not correct.\", expectedOutput, testHarness.getOutput());\n\n    testHarness.close();\n}", "summary_tokens": ["verifies", "that", "we", "don", "t", "have", "leakage", "between", "different", "keys"], "project": "flink"}
{"id": 7614, "code": "public void testResources() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    ResourceSpec minResource1 = ResourceSpec.newBuilder(1.0, 100).build();\n    ResourceSpec preferredResource1 = ResourceSpec.newBuilder(2.0, 200).build();\n\n    ResourceSpec minResource2 = ResourceSpec.newBuilder(1.0, 200).build();\n    ResourceSpec preferredResource2 = ResourceSpec.newBuilder(2.0, 300).build();\n\n    ResourceSpec minResource3 = ResourceSpec.newBuilder(1.0, 300).build();\n    ResourceSpec preferredResource3 = ResourceSpec.newBuilder(2.0, 400).build();\n\n    ResourceSpec minResource4 = ResourceSpec.newBuilder(1.0, 400).build();\n    ResourceSpec preferredResource4 = ResourceSpec.newBuilder(2.0, 500).build();\n\n    ResourceSpec minResource5 = ResourceSpec.newBuilder(1.0, 500).build();\n    ResourceSpec preferredResource5 = ResourceSpec.newBuilder(2.0, 600).build();\n\n    ResourceSpec minResource6 = ResourceSpec.newBuilder(1.0, 600).build();\n    ResourceSpec preferredResource6 = ResourceSpec.newBuilder(2.0, 700).build();\n\n    ResourceSpec minResource7 = ResourceSpec.newBuilder(1.0, 700).build();\n    ResourceSpec preferredResource7 = ResourceSpec.newBuilder(2.0, 800).build();\n\n    Method opMethod =\n            SingleOutputStreamOperator.class.getDeclaredMethod(\n                    \"setResources\", ResourceSpec.class, ResourceSpec.class);\n    opMethod.setAccessible(true);\n\n    Method sinkMethod =\n            DataStreamSink.class.getDeclaredMethod(\n                    \"setResources\", ResourceSpec.class, ResourceSpec.class);\n    sinkMethod.setAccessible(true);\n\n    DataStream<Long> source1 = env.generateSequence(0, 0);\n    opMethod.invoke(source1, minResource1, preferredResource1);\n\n    DataStream<Long> map1 =\n            source1.map(\n                    new MapFunction<Long, Long>() {\n                        @Override\n                        public Long map(Long value) throws Exception {\n                            return null;\n                        }\n                    });\n    opMethod.invoke(map1, minResource2, preferredResource2);\n\n    DataStream<Long> source2 = env.generateSequence(0, 0);\n    opMethod.invoke(source2, minResource3, preferredResource3);\n\n    DataStream<Long> map2 =\n            source2.map(\n                    new MapFunction<Long, Long>() {\n                        @Override\n                        public Long map(Long value) throws Exception {\n                            return null;\n                        }\n                    });\n    opMethod.invoke(map2, minResource4, preferredResource4);\n\n    DataStream<Long> connected =\n            map1.connect(map2)\n                    .flatMap(\n                            new CoFlatMapFunction<Long, Long, Long>() {\n                                @Override\n                                public void flatMap1(Long value, Collector<Long> out)\n                                        throws Exception {}\n\n                                @Override\n                                public void flatMap2(Long value, Collector<Long> out)\n                                        throws Exception {}\n                            });\n    opMethod.invoke(connected, minResource5, preferredResource5);\n\n    DataStream<Long> windowed =\n            connected\n                    .windowAll(GlobalWindows.create())\n                    .trigger(PurgingTrigger.of(CountTrigger.of(10)))\n                    .reduce(\n                            new ReduceFunction<Long>() {\n                                private static final long serialVersionUID = 1L;\n\n                                @Override\n                                public Long reduce(Long value1, Long value2) throws Exception {\n                                    return null;\n                                }\n                            });\n    opMethod.invoke(windowed, minResource6, preferredResource6);\n\n    DataStreamSink<Long> sink = windowed.print();\n    sinkMethod.invoke(sink, minResource7, preferredResource7);\n\n    assertEquals(\n            minResource1, getStreamGraph(env).getStreamNode(source1.getId()).getMinResources());\n    assertEquals(\n            preferredResource1,\n            getStreamGraph(env).getStreamNode(source1.getId()).getPreferredResources());\n\n    assertEquals(\n            minResource2, getStreamGraph(env).getStreamNode(map1.getId()).getMinResources());\n    assertEquals(\n            preferredResource2,\n            getStreamGraph(env).getStreamNode(map1.getId()).getPreferredResources());\n\n    assertEquals(\n            minResource3, getStreamGraph(env).getStreamNode(source2.getId()).getMinResources());\n    assertEquals(\n            preferredResource3,\n            getStreamGraph(env).getStreamNode(source2.getId()).getPreferredResources());\n\n    assertEquals(\n            minResource4, getStreamGraph(env).getStreamNode(map2.getId()).getMinResources());\n    assertEquals(\n            preferredResource4,\n            getStreamGraph(env).getStreamNode(map2.getId()).getPreferredResources());\n\n    assertEquals(\n            minResource5,\n            getStreamGraph(env).getStreamNode(connected.getId()).getMinResources());\n    assertEquals(\n            preferredResource5,\n            getStreamGraph(env).getStreamNode(connected.getId()).getPreferredResources());\n\n    assertEquals(\n            minResource6,\n            getStreamGraph(env).getStreamNode(windowed.getId()).getMinResources());\n    assertEquals(\n            preferredResource6,\n            getStreamGraph(env).getStreamNode(windowed.getId()).getPreferredResources());\n\n    assertEquals(\n            minResource7,\n            getStreamGraph(env)\n                    .getStreamNode(sink.getTransformation().getId())\n                    .getMinResources());\n    assertEquals(\n            preferredResource7,\n            getStreamGraph(env)\n                    .getStreamNode(sink.getTransformation().getId())\n                    .getPreferredResources());\n}", "summary_tokens": ["tests", "whether", "resources", "get", "set"], "project": "flink"}
{"id": 8709, "code": "private static RexLiteral toLiteral(RelDataType type, Comparable<?> value) {\n    final SqlTypeName typeName = strictTypeName(type);\n    switch (typeName) {\n        case ROW:\n            final List<Comparable<?>> fieldValues = (List) value;\n            final List<RelDataTypeField> fields = type.getFieldList();\n            final List<RexLiteral> fieldLiterals =\n                    FlatLists.of(\n                            Functions.generate(\n                                    fieldValues.size(),\n                                    i ->\n                                            toLiteral(\n                                                    fields.get(i).getType(),\n                                                    fieldValues.get(i))));\n            return new RexLiteral((Comparable) fieldLiterals, type, typeName);\n\n        case MULTISET:\n            final List<Comparable<?>> elementValues = (List) value;\n            final List<RexLiteral> elementLiterals =\n                    FlatLists.of(\n                            Functions.generate(\n                                    elementValues.size(),\n                                    i ->\n                                            toLiteral(\n                                                    type.getComponentType(),\n                                                    elementValues.get(i))));\n            return new RexLiteral((Comparable) elementLiterals, type, typeName);\n\n        default:\n            return new RexLiteral(value, type, typeName);\n    }\n}", "summary_tokens": ["converts", "a", "value", "to", "a", "temporary", "literal", "for", "the", "purposes", "of", "generating", "a", "digest"], "project": "flink"}
{"id": 1766, "code": "public byte get(int index) {\n    final long pos = address + index;\n    if (index >= 0 && pos < addressLimit) {\n        return UNSAFE.getByte(heapMemory, pos);\n    } else if (address > addressLimit) {\n        throw new IllegalStateException(\"segment has been freed\");\n    } else {\n            \n        throw new IndexOutOfBoundsException();\n    }\n}", "summary_tokens": ["reads", "the", "byte", "at", "the", "given", "position"], "project": "flink"}
{"id": 9484, "code": "public void testMultipleSplits(TestEnvironment testEnv, ExternalContext<T> externalContext)\n        throws Exception {\n\n    final int splitNumber = 4;\n    final List<List<T>> testRecordsLists = new ArrayList<>();\n    LOG.info(\"Writing test data to split 0 to 3...\");\n    for (int i = 0; i < splitNumber; i++) {\n        testRecordsLists.add(generateAndWriteTestData(i, externalContext));\n    }\n\n    LOG.info(\"Submitting Flink job to test environment\");\n    StreamExecutionEnvironment execEnv = testEnv.createExecutionEnvironment();\n\n    try (final CloseableIterator<T> resultIterator =\n            execEnv.fromSource(\n                            externalContext.createSource(Boundedness.BOUNDED),\n                            WatermarkStrategy.noWatermarks(),\n                            \"Tested Source\")\n                    .setParallelism(splitNumber)\n                    .executeAndCollect(\"Source Multiple Split Test\")) {\n            \n        LOG.info(\"Checking test results\");\n        assertThat(resultIterator, matchesMultipleSplitTestData(testRecordsLists));\n    }\n}", "summary_tokens": ["test", "connector", "source", "with", "multiple", "splits", "in", "the", "external", "system"], "project": "flink"}
{"id": 8311, "code": "public static boolean isInFixedLengthPart(LogicalType type) {\n    switch (type.getTypeRoot()) {\n        case BOOLEAN:\n        case TINYINT:\n        case SMALLINT:\n        case INTEGER:\n        case DATE:\n        case TIME_WITHOUT_TIME_ZONE:\n        case INTERVAL_YEAR_MONTH:\n        case BIGINT:\n        case INTERVAL_DAY_TIME:\n        case FLOAT:\n        case DOUBLE:\n            return true;\n        case DECIMAL:\n            return DecimalData.isCompact(((DecimalType) type).getPrecision());\n        case TIMESTAMP_WITHOUT_TIME_ZONE:\n            return TimestampData.isCompact(((TimestampType) type).getPrecision());\n        case TIMESTAMP_WITH_LOCAL_TIME_ZONE:\n            return TimestampData.isCompact(((LocalZonedTimestampType) type).getPrecision());\n        default:\n            return false;\n    }\n}", "summary_tokens": ["if", "it", "is", "a", "fixed", "length", "field", "we", "can", "call", "this", "binary", "row", "data", "s", "set", "xx", "method", "for", "in", "place", "updates"], "project": "flink"}
{"id": 2008, "code": "public static int longToIntWithBitMixing(long in) {\n    in = (in ^ (in >>> 30)) * 0xbf58476d1ce4e5b9L;\n    in = (in ^ (in >>> 27)) * 0x94d049bb133111ebL;\n    in = in ^ (in >>> 31);\n    return (int) in;\n}", "summary_tokens": ["pseudo", "randomly", "maps", "a", "long", "0", "bit", "to", "an", "integer", "0", "bit", "using", "some", "bit", "mixing", "for", "better", "distribution"], "project": "flink"}
{"id": 1810, "code": "public void processAsByteBuffer(Consumer<ByteBuffer> processConsumer) {\n    Preconditions.checkNotNull(processConsumer).accept(wrapInternal(0, size));\n}", "summary_tokens": ["supplies", "a", "byte", "buffer", "that", "represents", "this", "entire", "segment", "to", "the", "given", "process", "consumer"], "project": "flink"}
{"id": 2537, "code": "public void testSerializeGenericData_withValidParams_withoutCompression_succeeds() {\n    AWSSchemaRegistryConstants.COMPRESSION compressionType =\n            AWSSchemaRegistryConstants.COMPRESSION.NONE;\n    configs.put(AWSSchemaRegistryConstants.COMPRESSION_TYPE, compressionType.name());\n\n    GlueSchemaRegistryJsonSchemaCoder glueSchemaRegistryJsonSchemaCoder =\n            new GlueSchemaRegistryJsonSchemaCoder(\n                    testTopic, configs, mockSerializationFacade, null);\n\n    GlueSchemaRegistryJsonSerializationSchema glueSchemaRegistryJsonSerializationSchema =\n            new GlueSchemaRegistryJsonSerializationSchema<>(glueSchemaRegistryJsonSchemaCoder);\n\n    byte[] serializedData = glueSchemaRegistryJsonSerializationSchema.serialize(userSchema);\n    assertThat(serializedData, equalTo(serializedBytes));\n}", "summary_tokens": ["test", "whether", "serialize", "method", "for", "generic", "type", "json", "schema", "data", "when", "compression", "is", "not", "enabled", "works"], "project": "flink"}
{"id": 6857, "code": "public void testUpdateLevelToLessThanCurrentLevel() {\n    int level = heapHeadIndex.getLevel();\n        \n    for (int i = 0; i < 10; i++) {\n        heapHeadIndex.updateLevel(++level);\n    }\n        \n    for (int i = level - 1; i >= 0; i--) {\n        heapHeadIndex.updateLevel(i);\n        Assert.assertEquals(level, heapHeadIndex.getLevel());\n    }\n}", "summary_tokens": ["test", "update", "to", "current", "level", "is", "allowed"], "project": "flink"}
{"id": 753, "code": "protected ShardConsumer<T> createShardConsumer(\n        final Integer subscribedShardStateIndex,\n        final StreamShardHandle subscribedShard,\n        final SequenceNumber lastSequenceNum,\n        final MetricGroup metricGroup,\n        final KinesisDeserializationSchema<T> shardDeserializer)\n        throws InterruptedException {\n\n    return new ShardConsumer<>(\n            this,\n            createRecordPublisher(lastSequenceNum, configProps, metricGroup, subscribedShard),\n            subscribedShardStateIndex,\n            subscribedShard,\n            lastSequenceNum,\n            new ShardConsumerMetricsReporter(metricGroup),\n            shardDeserializer);\n}", "summary_tokens": ["create", "a", "new", "shard", "consumer"], "project": "flink"}
{"id": 897, "code": "public PulsarSourceBuilder<OUT> setRangeGenerator(RangeGenerator rangeGenerator) {\n    if (configuration.contains(PULSAR_SUBSCRIPTION_TYPE)) {\n        SubscriptionType subscriptionType = configuration.get(PULSAR_SUBSCRIPTION_TYPE);\n        checkArgument(\n                subscriptionType == SubscriptionType.Key_Shared,\n                \"Key_Shared subscription should be used for custom rangeGenerator instead of %s\",\n                subscriptionType);\n    } else {\n        LOG.warn(\"No subscription type provided, set it to Key_Shared.\");\n        setSubscriptionType(SubscriptionType.Key_Shared);\n    }\n    this.rangeGenerator = checkNotNull(rangeGenerator);\n    return this;\n}", "summary_tokens": ["set", "a", "topic", "range", "generator", "for", "key", "shared", "subscription"], "project": "flink"}
{"id": 4330, "code": "public static String createDynamicProperty(String key, String value) {\n    final String keyPart = \"-D\" + key + '=';\n    final String valuePart;\n\n    if (value.contains(\" \")) {\n        valuePart = \"\\\"\" + value + \"\\\"\";\n    } else {\n        valuePart = value;\n    }\n\n    return keyPart + valuePart;\n}", "summary_tokens": ["create", "a", "dynamic", "property", "from", "the", "given", "key", "and", "value", "of", "the", "format", "dkey", "value"], "project": "flink"}
{"id": 4570, "code": "int refreshAndGetMax() {\n    int max = 0;\n\n    for (InputChannel channel : inputGate.getInputChannels().values()) {\n        if (channel instanceof RemoteInputChannel) {\n            RemoteInputChannel rc = (RemoteInputChannel) channel;\n\n            int size = rc.unsynchronizedGetNumberOfQueuedBuffers();\n            max = Math.max(max, size);\n        }\n    }\n\n    return max;\n}", "summary_tokens": ["iterates", "over", "all", "input", "channels", "and", "collects", "the", "maximum", "number", "of", "queued", "buffers", "in", "a", "channel", "in", "a", "best", "effort", "way"], "project": "flink"}
{"id": 2243, "code": "public void trigger() {\n    execService.trigger();\n}", "summary_tokens": ["triggers", "the", "next", "queued", "runnable", "and", "executes", "it", "synchronously"], "project": "flink"}
{"id": 7907, "code": "public void prepareSnapshotPreBarrier(long checkpointId) throws Exception {\n    operator.prepareSnapshotPreBarrier(checkpointId);\n}", "summary_tokens": ["calls", "stream", "operator", "prepare", "snapshot", "pre", "barrier", "long"], "project": "flink"}
{"id": 9257, "code": "public boolean containsKey(RowData key) {\n    return treeMap.containsKey(key);\n}", "summary_tokens": ["returns", "true", "if", "the", "buffer", "contains", "a", "mapping", "for", "the", "specified", "key"], "project": "flink"}
{"id": 8969, "code": "public int getJoinKeySize() {\n    return leftKeys.length;\n}", "summary_tokens": ["gets", "number", "of", "keys", "in", "join", "key"], "project": "flink"}
{"id": 7223, "code": "public StreamExecutionEnvironment registerSlotSharingGroup(SlotSharingGroup slotSharingGroup) {\n    final ResourceSpec resourceSpec =\n            SlotSharingGroupUtils.extractResourceSpec(slotSharingGroup);\n    if (!resourceSpec.equals(ResourceSpec.UNKNOWN)) {\n        this.slotSharingGroupResources.put(\n                slotSharingGroup.getName(),\n                ResourceProfile.fromResourceSpec(\n                        SlotSharingGroupUtils.extractResourceSpec(slotSharingGroup),\n                        MemorySize.ZERO));\n    }\n    return this;\n}", "summary_tokens": ["register", "a", "slot", "sharing", "group", "with", "its", "resource", "spec"], "project": "flink"}
{"id": 9645, "code": "private DataStream<Long> createProgramWithMixedInputs() {\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.setParallelism(PARALLELISM);\n    env.getConfig().enableObjectReuse();\n\n    final DataStream<Long> source1 =\n            env.fromSource(\n                    new NumberSequenceSource(1L, 10L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-1\");\n\n    final DataStream<Long> source2 =\n            env.fromSource(\n                    new NumberSequenceSource(11L, 20L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-2\");\n\n    final DataStream<Long> source3 =\n            env.fromSource(\n                    new NumberSequenceSource(21L, 30L),\n                    WatermarkStrategy.noWatermarks(),\n                    \"source-3\");\n\n    final DataStream<Long> stream1 = source1.map(v -> v);\n    final DataStream<Long> stream3 = source3.map(v -> v);\n\n    return nAryInputStreamOperation(stream1, source2, stream3);\n}", "summary_tokens": ["creates", "a", "data", "stream", "program", "as", "shown", "below"], "project": "flink"}
{"id": 3692, "code": "public void setRelativeTempMemory(double relativeTempMemory) {\n    this.relativeTempMemory = relativeTempMemory;\n}", "summary_tokens": ["sets", "the", "memory", "for", "materializing", "the", "channel", "s", "result", "from", "this", "channel"], "project": "flink"}
{"id": 3965, "code": "public static <T, E extends Throwable> T runWithContextClassLoader(\n        SupplierWithException<T, E> supplier, ClassLoader contextClassLoader) throws E {\n    try (TemporaryClassLoaderContext ignored =\n            TemporaryClassLoaderContext.of(contextClassLoader)) {\n        return supplier.get();\n    }\n}", "summary_tokens": ["runs", "the", "given", "supplier", "in", "a", "temporary", "class", "loader", "context", "based", "on", "the", "given", "classloader"], "project": "flink"}
{"id": 8712, "code": "public Comparable getValue() {\n    assert valueMatchesType(value, typeName, true) : value;\n    if (value == null) {\n        return null;\n    }\n    switch (typeName) {\n        case TIME:\n        case DATE:\n        case TIMESTAMP:\n            return getValueAs(Calendar.class);\n        default:\n            return value;\n    }\n}", "summary_tokens": ["returns", "the", "value", "of", "this", "literal"], "project": "flink"}
{"id": 8891, "code": "private Operation convertShowColumns(SqlShowColumns sqlShowColumns) {\n    UnresolvedIdentifier unresolvedIdentifier =\n            UnresolvedIdentifier.of(sqlShowColumns.fullTableName());\n    ObjectIdentifier identifier = catalogManager.qualifyIdentifier(unresolvedIdentifier);\n    return new ShowColumnsOperation(\n            identifier,\n            sqlShowColumns.getLikeSqlPattern(),\n            sqlShowColumns.isWithLike(),\n            sqlShowColumns.isNotLike(),\n            sqlShowColumns.getPreposition());\n}", "summary_tokens": ["convert", "show", "columns", "statement"], "project": "flink"}
{"id": 6878, "code": "public void setPredefinedOptions(@Nonnull PredefinedOptions options) {\n    predefinedOptions = checkNotNull(options);\n}", "summary_tokens": ["sets", "the", "predefined", "options", "for", "rocks", "db"], "project": "flink"}
{"id": 9335, "code": "public void update(W window, RowData value) throws IOException {\n    windowState.setCurrentNamespace(window);\n    windowState.update(value);\n}", "summary_tokens": ["update", "the", "state", "with", "the", "given", "value", "under", "current", "key", "and", "the", "given", "window"], "project": "flink"}
{"id": 2389, "code": "public void clear() {\n    getProps().clear();\n    getOverlay().clear();\n}", "summary_tokens": ["clears", "all", "keys", "from", "the", "configuration"], "project": "flink"}
{"id": 6540, "code": "public void testCreateJaasModuleFileInTemporary() throws IOException {\n    Configuration configuration = new Configuration();\n    SecurityConfiguration sc = new SecurityConfiguration(configuration);\n    JaasModule module = new JaasModule(sc);\n\n    module.install();\n\n    assertJaasFileLocateInRightDirectory(CoreOptions.TMP_DIRS.defaultValue());\n}", "summary_tokens": ["test", "that", "the", "jaas", "file", "will", "be", "created", "in", "the", "directory", "specified", "by", "core", "options", "tmp", "dirs", "s", "default", "value", "if", "we", "do", "not", "manually", "specify", "it"], "project": "flink"}
{"id": 1893, "code": "public String getValue() {\n    return toString();\n}", "summary_tokens": ["gets", "this", "string", "value", "as", "a", "string"], "project": "flink"}
{"id": 1654, "code": "public <T> boolean removeConfig(ConfigOption<T> configOption) {\n    synchronized (this.confData) {\n        final BiFunction<String, Boolean, Optional<Boolean>> applier =\n                (key, canBePrefixMap) -> {\n                    if (canBePrefixMap && removePrefixMap(this.confData, key)\n                            || this.confData.remove(key) != null) {\n                        return Optional.of(true);\n                    }\n                    return Optional.empty();\n                };\n        return applyWithOption(configOption, applier).orElse(false);\n    }\n}", "summary_tokens": ["removes", "given", "config", "option", "from", "the", "configuration"], "project": "flink"}
{"id": 8547, "code": "static @Nullable List<String> extractMethodParameterNames(Method method) {\n    return extractExecutableNames(method);\n}", "summary_tokens": ["extracts", "the", "parameter", "names", "of", "a", "method", "if", "possible"], "project": "flink"}
{"id": 5620, "code": "public int size() {\n    return this.elements.size();\n}", "summary_tokens": ["returns", "the", "number", "of", "currently", "stored", "elements"], "project": "flink"}
{"id": 2363, "code": "public IntegerRanges getRange(String name, String defaultValue) {\n    return new IntegerRanges(get(name, defaultValue));\n}", "summary_tokens": ["parse", "the", "given", "attribute", "as", "a", "set", "of", "integer", "ranges"], "project": "flink"}
{"id": 9374, "code": "public static void copyToView(\n        MemorySegment[] segments, int offset, int sizeInBytes, DataOutputView target)\n        throws IOException {\n    for (MemorySegment sourceSegment : segments) {\n        int curSegRemain = sourceSegment.size() - offset;\n        if (curSegRemain > 0) {\n            int copySize = Math.min(curSegRemain, sizeInBytes);\n\n            byte[] bytes = allocateReuseBytes(copySize);\n            sourceSegment.get(offset, bytes, 0, copySize);\n            target.write(bytes, 0, copySize);\n\n            sizeInBytes -= copySize;\n            offset = 0;\n        } else {\n            offset -= sourceSegment.size();\n        }\n\n        if (sizeInBytes == 0) {\n            return;\n        }\n    }\n\n    if (sizeInBytes != 0) {\n        throw new RuntimeException(\n                \"No copy finished, this should be a bug, \"\n                        + \"The remaining length is: \"\n                        + sizeInBytes);\n    }\n}", "summary_tokens": ["copy", "bytes", "of", "segments", "to", "output", "view"], "project": "flink"}
{"id": 8426, "code": "private static <T extends TableFactory> List<T> findAllInternal(\n        Class<T> factoryClass,\n        Map<String, String> properties,\n        Optional<ClassLoader> classLoader) {\n\n    List<TableFactory> tableFactories = discoverFactories(classLoader);\n    return filter(tableFactories, factoryClass, properties);\n}", "summary_tokens": ["finds", "a", "table", "factory", "of", "the", "given", "class", "property", "map", "and", "classloader"], "project": "flink"}
{"id": 8963, "code": "void makeAsFarAs(ExecNode<?> a, ExecNode<?> b) {\n    TopologyNode nodeA = getOrCreateTopologyNode(a);\n    TopologyNode nodeB = getOrCreateTopologyNode(b);\n\n    for (TopologyNode input : nodeB.inputs) {\n        link(input.execNode, nodeA.execNode);\n    }\n}", "summary_tokens": ["make", "the", "distance", "of", "node", "a", "at", "least", "as", "far", "as", "node", "b", "by", "adding", "edges", "from", "all", "inputs", "of", "node", "b", "to", "node", "a"], "project": "flink"}
{"id": 6126, "code": "public void testBroadcastEventBufferReferenceCounting() throws Exception {\n    int bufferSize = 32 * 1024;\n    int numSubpartitions = 2;\n\n    ResultPartition partition = createResultPartition(bufferSize, numSubpartitions);\n    RecordWriter<?> writer = createRecordWriter(partition);\n\n    writer.broadcastEvent(EndOfPartitionEvent.INSTANCE);\n\n        \n    Buffer[] buffers = new Buffer[numSubpartitions];\n\n        \n    for (int i = 0; i < numSubpartitions; i++) {\n        assertEquals(1, partition.getNumberOfQueuedBuffers(i));\n        ResultSubpartitionView view =\n                partition.createSubpartitionView(i, new NoOpBufferAvailablityListener());\n        buffers[i] = view.getNextBuffer().buffer();\n        assertTrue(parseBuffer(buffers[i], i).isEvent());\n    }\n\n    for (int i = 0; i < numSubpartitions; ++i) {\n        assertTrue(buffers[i].isRecycled());\n    }\n}", "summary_tokens": ["tests", "that", "event", "buffers", "are", "properly", "recycled", "when", "broadcasting", "events", "to", "multiple", "channels"], "project": "flink"}
{"id": 5120, "code": "public static KvStateServer createKvStateServer(\n        final String address,\n        final Iterator<Integer> ports,\n        final int eventLoopThreads,\n        final int queryThreads,\n        final KvStateRegistry kvStateRegistry,\n        final KvStateRequestStats stats) {\n\n    Preconditions.checkNotNull(address, \"address\");\n    Preconditions.checkNotNull(kvStateRegistry, \"registry\");\n    Preconditions.checkNotNull(stats, \"stats\");\n\n    Preconditions.checkArgument(eventLoopThreads >= 1);\n    Preconditions.checkArgument(queryThreads >= 1);\n\n    try {\n        String classname = \"org.apache.flink.queryablestate.server.KvStateServerImpl\";\n        Class<? extends KvStateServer> clazz =\n                Class.forName(classname).asSubclass(KvStateServer.class);\n        Constructor<? extends KvStateServer> constructor =\n                clazz.getConstructor(\n                        String.class,\n                        Iterator.class,\n                        Integer.class,\n                        Integer.class,\n                        KvStateRegistry.class,\n                        KvStateRequestStats.class);\n        return constructor.newInstance(\n                address, ports, eventLoopThreads, queryThreads, kvStateRegistry, stats);\n    } catch (ClassNotFoundException e) {\n        final String msg =\n                \"Could not load Queryable State Server. \" + ERROR_MESSAGE_ON_LOAD_FAILURE;\n        if (LOG.isDebugEnabled()) {\n            LOG.debug(msg + \" Cause: \" + e.getMessage());\n        } else {\n            LOG.info(msg);\n        }\n        return null;\n    } catch (InvocationTargetException e) {\n        LOG.error(\"Queryable State Server could not be created: \", e.getTargetException());\n        return null;\n    } catch (Throwable t) {\n        LOG.error(\"Failed to instantiate the Queryable State Server.\", t);\n        return null;\n    }\n}", "summary_tokens": ["initializes", "the", "kv", "state", "server", "server", "responsible", "for", "sending", "the", "requested", "internal", "state", "to", "the", "kv", "state", "client", "proxy", "client", "proxy"], "project": "flink"}
{"id": 2262, "code": "static DownloadCache get() {\n    return FactoryUtils.loadAndInvokeFactory(\n            DownloadCacheFactory.class, DownloadCacheFactory::create, LolCacheFactory::new);\n}", "summary_tokens": ["returns", "the", "configured", "download", "cache", "implementation", "or", "a", "lol", "cache", "if", "none", "is", "configured"], "project": "flink"}
{"id": 9215, "code": "private void registerCleanUpTimer(Context ctx, long rowTime, boolean leftRow)\n        throws IOException {\n    if (leftRow) {\n        long cleanUpTime =\n                rowTime + leftRelativeSize + minCleanUpInterval + allowedLateness + 1;\n        registerTimer(ctx, cleanUpTime);\n        rightTimerState.update(cleanUpTime);\n    } else {\n        long cleanUpTime =\n                rowTime + rightRelativeSize + minCleanUpInterval + allowedLateness + 1;\n        registerTimer(ctx, cleanUpTime);\n        leftTimerState.update(cleanUpTime);\n    }\n}", "summary_tokens": ["register", "a", "timer", "for", "cleaning", "up", "rows", "in", "a", "specified", "time"], "project": "flink"}
{"id": 1250, "code": "public ResourceSpec getPreferredResources() {\n    return this.preferredResources;\n}", "summary_tokens": ["gets", "the", "preferred", "resources", "for", "this", "contract", "instance"], "project": "flink"}
{"id": 7142, "code": "public <T0, T1, T2> SingleOutputStreamOperator<Tuple3<T0, T1, T2>> projectTuple3() {\n    TypeInformation<?>[] fTypes = extractFieldTypes(fieldIndexes, dataStream.getType());\n    TupleTypeInfo<Tuple3<T0, T1, T2>> tType = new TupleTypeInfo<Tuple3<T0, T1, T2>>(fTypes);\n\n    return dataStream.transform(\n            \"Projection\",\n            tType,\n            new StreamProject<IN, Tuple3<T0, T1, T2>>(\n                    fieldIndexes, tType.createSerializer(dataStream.getExecutionConfig())));\n}", "summary_tokens": ["projects", "a", "tuple", "data", "stream", "to", "the", "previously", "selected", "fields"], "project": "flink"}
{"id": 3582, "code": "public double getHeuristicCpuCost() {\n    return this.heuristicCpuCost;\n}", "summary_tokens": ["gets", "the", "heuristic", "cost", "for", "the", "cpu"], "project": "flink"}
{"id": 7867, "code": "public void processEvent(AbstractEvent event, int inputGate, int channel) {\n    inputGates[inputGate].sendEvent(event, channel);\n}", "summary_tokens": ["sends", "the", "event", "to", "the", "specified", "channel", "on", "the", "specified", "input", "gate"], "project": "flink"}
{"id": 3574, "code": "public void setCpuCost(double cost) {\n    if (cost == UNKNOWN || cost >= 0) {\n        this.cpuCost = cost;\n    } else {\n        throw new IllegalArgumentException();\n    }\n}", "summary_tokens": ["sets", "the", "cost", "for", "the", "cpu"], "project": "flink"}
{"id": 7169, "code": "public <R> SingleOutputStreamOperator<R> reduce(\n        ReduceFunction<T> reduceFunction,\n        ProcessWindowFunction<T, R, K, W> function,\n        TypeInformation<R> resultType) {\n        \n    function = input.getExecutionEnvironment().clean(function);\n    reduceFunction = input.getExecutionEnvironment().clean(reduceFunction);\n\n    final String opName = builder.generateOperatorName(reduceFunction, function);\n    OneInputStreamOperator<T, R> operator = builder.reduce(reduceFunction, function);\n\n    return input.transform(opName, resultType, operator);\n}", "summary_tokens": ["applies", "the", "given", "window", "function", "to", "each", "window"], "project": "flink"}
{"id": 3228, "code": "public GraphCsvReader ignoreInvalidLinesEdges() {\n    this.edgeReader.ignoreInvalidLines();\n    return this;\n}", "summary_tokens": ["sets", "the", "csv", "reader", "for", "the", "edges", "file", "to", "ignore", "any", "invalid", "lines"], "project": "flink"}
{"id": 891, "code": "public PulsarSourceBuilder<OUT> setAdminUrl(String adminUrl) {\n    return setConfig(PULSAR_ADMIN_URL, adminUrl);\n}", "summary_tokens": ["sets", "the", "admin", "endpoint", "for", "the", "pulsar", "admin", "of", "the", "pulsar", "source"], "project": "flink"}
{"id": 8049, "code": "public String getCurrentCatalog() {\n    return currentCatalogName;\n}", "summary_tokens": ["gets", "the", "current", "catalog", "that", "will", "be", "used", "when", "resolving", "table", "path"], "project": "flink"}
{"id": 2698, "code": "public JobExecutionResult execute(String jobName) throws Exception {\n    final JobClient jobClient = executeAsync(jobName);\n\n    try {\n        if (configuration.getBoolean(DeploymentOptions.ATTACHED)) {\n            lastJobExecutionResult = jobClient.getJobExecutionResult().get();\n        } else {\n            lastJobExecutionResult = new DetachedJobExecutionResult(jobClient.getJobID());\n        }\n\n        jobListeners.forEach(\n                jobListener -> jobListener.onJobExecuted(lastJobExecutionResult, null));\n\n    } catch (Throwable t) {\n            \n            \n            \n        Throwable strippedException = ExceptionUtils.stripExecutionException(t);\n\n        jobListeners.forEach(\n                jobListener -> {\n                    jobListener.onJobExecuted(null, strippedException);\n                });\n        ExceptionUtils.rethrowException(strippedException);\n    }\n\n    return lastJobExecutionResult;\n}", "summary_tokens": ["triggers", "the", "program", "execution"], "project": "flink"}
{"id": 1573, "code": "public static List<Method> getAllDeclaredMethods(Class<?> clazz) {\n    List<Method> result = new ArrayList<>();\n    while (clazz != null) {\n        Method[] methods = clazz.getDeclaredMethods();\n        Collections.addAll(result, methods);\n        clazz = clazz.getSuperclass();\n    }\n    return result;\n}", "summary_tokens": ["returns", "all", "declared", "methods", "of", "a", "class", "including", "methods", "of", "superclasses"], "project": "flink"}
{"id": 83, "code": "public void testCommandLineMaterialization() throws Exception {\n    final String hostname = \"home-sweet-home\";\n    final int port = 1234;\n    final String[] args = {\"-m\", hostname + ':' + port};\n\n    final AbstractCustomCommandLine defaultCLI = new DefaultCLI();\n    final CommandLine commandLine = defaultCLI.parseCommandLineOptions(args, false);\n\n    Configuration configuration = defaultCLI.toConfiguration(commandLine);\n\n    assertThat(configuration.get(RestOptions.ADDRESS), is(hostname));\n    assertThat(configuration.get(RestOptions.PORT), is(port));\n}", "summary_tokens": ["verifies", "command", "line", "options", "are", "correctly", "materialized"], "project": "flink"}
{"id": 445, "code": "public static <T> SinkFunction<T> sink(\n        String sql,\n        JdbcStatementBuilder<T> statementBuilder,\n        JdbcExecutionOptions executionOptions,\n        JdbcConnectionOptions connectionOptions) {\n    return new GenericJdbcSinkFunction<>(\n            new JdbcOutputFormat<>(\n                    new SimpleJdbcConnectionProvider(connectionOptions),\n                    executionOptions,\n                    context ->\n                            JdbcBatchStatementExecutor.simple(\n                                    sql, statementBuilder, Function.identity()),\n                    JdbcOutputFormat.RecordExtractor.identity()));\n}", "summary_tokens": ["create", "a", "jdbc", "sink"], "project": "flink"}
{"id": 4316, "code": "public TaskStateStatsSummary getSummaryStats() {\n    return summaryStats;\n}", "summary_tokens": ["summary", "of", "the", "subtask", "stats"], "project": "flink"}
{"id": 9135, "code": "public static String repeat(String str, int repeat) {\n    return EncodingUtils.repeat(str, repeat);\n}", "summary_tokens": ["returns", "a", "string", "that", "repeats", "the", "base", "string", "n", "times"], "project": "flink"}
{"id": 6296, "code": "public void testPendingBatchSlotRequestTimeout() throws Exception {\n    try (final SlotPool slotPool =\n            createAndSetUpSlotPool(mainThreadExecutor, null, Time.milliseconds(2L))) {\n        final CompletableFuture<PhysicalSlot> slotFuture =\n                SlotPoolUtils.requestNewAllocatedBatchSlot(\n                        slotPool, mainThreadExecutor, ResourceProfile.UNKNOWN);\n\n        try {\n            slotFuture.get();\n            fail(\"Expected that slot future times out.\");\n        } catch (ExecutionException ee) {\n            assertThat(ee, FlinkMatchers.containsCause(TimeoutException.class));\n        }\n    }\n}", "summary_tokens": ["tests", "that", "a", "batch", "slot", "request", "fails", "if", "there", "is", "no", "slot", "which", "can", "fulfill", "the", "slot", "request"], "project": "flink"}
{"id": 4880, "code": "public RpcService getMetricQueryServiceRpcService() {\n    return metricQueryServiceRpcService;\n}", "summary_tokens": ["returns", "the", "rpc", "service", "that", "the", "metric", "query", "service", "runs", "in"], "project": "flink"}
{"id": 3959, "code": "public void testResponseSerializationWithZeroLengthSerializedResult() throws Exception {\n    byte[] serializedResult = new byte[0];\n\n    final KvStateResponse response = new KvStateResponse(serializedResult);\n    final MessageSerializer<KvStateInternalRequest, KvStateResponse> serializer =\n            new MessageSerializer<>(\n                    new KvStateInternalRequest.KvStateInternalRequestDeserializer(),\n                    new KvStateResponse.KvStateResponseDeserializer());\n\n    ByteBuf buf = MessageSerializer.serializeResponse(alloc, 72727278L, response);\n\n    int frameLength = buf.readInt();\n\n    assertEquals(MessageType.REQUEST_RESULT, MessageSerializer.deserializeHeader(buf));\n    assertEquals(72727278L, MessageSerializer.getRequestId(buf));\n    KvStateResponse responseDeser = serializer.deserializeResponse(buf);\n    assertEquals(buf.readerIndex(), frameLength + 4);\n\n    assertArrayEquals(serializedResult, responseDeser.getContent());\n}", "summary_tokens": ["tests", "response", "serialization", "with", "zero", "length", "serialized", "result"], "project": "flink"}
{"id": 117, "code": "public ConcreteBuilderT setMaxTimeInBufferMS(long maxTimeInBufferMS) {\n    this.maxTimeInBufferMS = maxTimeInBufferMS;\n    return (ConcreteBuilderT) this;\n}", "summary_tokens": ["max", "time", "in", "buffer", "ms", "the", "maximum", "amount", "of", "time", "an", "element", "may", "remain", "in", "the", "buffer"], "project": "flink"}
{"id": 6760, "code": "private boolean isNodeRemoved(long node) {\n    return SkipListUtils.isNodeRemoved(node, spaceAllocator);\n}", "summary_tokens": ["whether", "the", "node", "has", "been", "logically", "removed"], "project": "flink"}
{"id": 4587, "code": "private static ByteBuf allocateBuffer(\n        ByteBufAllocator allocator,\n        byte id,\n        int messageHeaderLength,\n        int contentLength,\n        boolean allocateForContent) {\n    checkArgument(contentLength <= Integer.MAX_VALUE - FRAME_HEADER_LENGTH);\n\n    final ByteBuf buffer;\n    if (!allocateForContent) {\n        buffer = allocator.directBuffer(FRAME_HEADER_LENGTH + messageHeaderLength);\n    } else if (contentLength != -1) {\n        buffer =\n                allocator.directBuffer(\n                        FRAME_HEADER_LENGTH + messageHeaderLength + contentLength);\n    } else {\n            \n            \n        buffer = allocator.directBuffer();\n    }\n    buffer.writeInt(\n            FRAME_HEADER_LENGTH\n                    + messageHeaderLength\n                    + contentLength); \n    buffer.writeInt(MAGIC_NUMBER);\n    buffer.writeByte(id);\n\n    return buffer;\n}", "summary_tokens": ["allocates", "a", "new", "buffer", "and", "adds", "some", "header", "information", "for", "the", "frame", "decoder"], "project": "flink"}
{"id": 4778, "code": "public Configuration getConfiguration() {\n    if (this.configuration == null) {\n        this.configuration = new Configuration();\n    }\n    return this.configuration;\n}", "summary_tokens": ["returns", "the", "vertex", "s", "configuration", "object", "which", "can", "be", "used", "to", "pass", "custom", "settings", "to", "the", "task", "at", "runtime"], "project": "flink"}
{"id": 6110, "code": "public void testCleanupJobData() throws Exception {\n    String rootPath = \"/foo/bar/flink\";\n    final Configuration configuration = createConfiguration(rootPath);\n    final String namespace = configuration.get(HighAvailabilityOptions.HA_CLUSTER_ID);\n\n    JobID jobID = new JobID();\n    final String path = rootPath + namespace + ZooKeeperUtils.getJobsPath();\n\n    final TestingBlobStoreService blobStoreService = new TestingBlobStoreService();\n\n    runCleanupTestWithJob(\n            configuration,\n            blobStoreService,\n            jobID,\n            haServices -> {\n                final List<String> childrenBefore = client.getChildren().forPath(path);\n\n                haServices.cleanupJobData(jobID);\n\n                final List<String> childrenAfter = client.getChildren().forPath(path);\n\n                assertThat(childrenBefore, hasItem(jobID.toString()));\n                assertThat(childrenAfter, not(hasItem(jobID.toString())));\n            });\n}", "summary_tokens": ["tests", "that", "the", "zoo", "keeper", "ha", "services", "cleans", "up", "paths", "for", "job", "manager"], "project": "flink"}
{"id": 397, "code": "public void setDistributeByExprForClause(String clause, HiveParserASTNode ast) {\n    destToDistributeby.put(clause, ast);\n}", "summary_tokens": ["set", "the", "distribute", "by", "ast", "for", "the", "clause"], "project": "flink"}
{"id": 6500, "code": "public void testRunAsyncWithFencing() throws Exception {\n    final Time shortTimeout = Time.milliseconds(100L);\n    final UUID newFencingToken = UUID.randomUUID();\n    final CompletableFuture<UUID> resultFuture = new CompletableFuture<>();\n\n    testRunAsync(\n            endpoint -> {\n                endpoint.runAsync(() -> resultFuture.complete(endpoint.getFencingToken()));\n\n                return resultFuture;\n            },\n            newFencingToken);\n\n    try {\n        resultFuture.get(shortTimeout.toMilliseconds(), TimeUnit.MILLISECONDS);\n\n        fail(\n                \"The async run operation should not complete since it is filtered out due to the changed fencing token.\");\n    } catch (TimeoutException ignored) {\n    }\n}", "summary_tokens": ["tests", "that", "async", "code", "is", "not", "executed", "if", "the", "fencing", "token", "changes"], "project": "flink"}
{"id": 5015, "code": "protected int spillPartition() throws IOException {\n        \n    ArrayList<HashPartition<BT, PT>> partitions = this.partitionsBeingBuilt;\n    int largestNumBlocks = 0;\n    int largestPartNum = -1;\n\n    for (int i = 0; i < partitions.size(); i++) {\n        HashPartition<BT, PT> p = partitions.get(i);\n        if (p.isInMemory() && p.getNumOccupiedMemorySegments() > largestNumBlocks) {\n            largestNumBlocks = p.getNumOccupiedMemorySegments();\n            largestPartNum = i;\n        }\n    }\n    final HashPartition<BT, PT> p = partitions.get(largestPartNum);\n\n    if (useBloomFilters) {\n        buildBloomFilterForBucketsInPartition(largestPartNum, p);\n    }\n\n        \n    int numBuffersFreed =\n            p.spillPartition(\n                    this.availableMemory,\n                    this.ioManager,\n                    this.currentEnumerator.next(),\n                    this.writeBehindBuffers);\n    this.writeBehindBuffersAvailable += numBuffersFreed;\n        \n    MemorySegment currBuff;\n    while (this.writeBehindBuffersAvailable > 0\n            && (currBuff = this.writeBehindBuffers.poll()) != null) {\n        this.availableMemory.add(currBuff);\n        this.writeBehindBuffersAvailable--;\n    }\n    return largestPartNum;\n}", "summary_tokens": ["selects", "a", "partition", "and", "spills", "it"], "project": "flink"}
{"id": 5715, "code": "public void handleSuccessfulResponse(int requestId, ExecutionAttemptID executionId, T result) {\n\n    synchronized (lock) {\n        if (isShutDown) {\n            return;\n        }\n\n        if (log.isDebugEnabled()) {\n            log.debug(\"Collecting stats sample {} of task {}\", requestId, executionId);\n        }\n\n        PendingStatsRequest<T, V> pending = pendingRequests.get(requestId);\n\n        if (pending != null) {\n            pending.collectTaskStats(executionId, result);\n\n                \n            if (pending.isComplete()) {\n                pendingRequests.remove(requestId);\n                rememberRecentRequestId(requestId);\n\n                pending.completePromiseAndDiscard();\n            }\n        } else if (recentPendingRequestIds.contains(requestId)) {\n            if (log.isDebugEnabled()) {\n                log.debug(\"Received late stats sample {} of task {}\", requestId, executionId);\n            }\n        } else {\n            if (log.isDebugEnabled()) {\n                log.debug(String.format(\"Unknown request ID %d.\", requestId));\n            }\n        }\n    }\n}", "summary_tokens": ["handles", "the", "successfully", "returned", "task", "stats", "response", "by", "collecting", "the", "corresponding", "subtask", "samples"], "project": "flink"}
{"id": 6215, "code": "public void testCreateViewForReleasedPartition() throws Exception {\n    final ResultPartitionManager partitionManager = new ResultPartitionManager();\n    final ResultPartition partition = createPartition();\n\n    partitionManager.registerResultPartition(partition);\n    partitionManager.releasePartition(partition.getPartitionId(), null);\n\n    verifyCreateSubpartitionViewThrowsException(partitionManager, partition.getPartitionId());\n}", "summary_tokens": ["tests", "result", "partition", "manager", "create", "subpartition", "view", "result", "partition", "id", "int", "buffer", "availability", "listener", "would", "throw", "a", "partition", "not", "found", "exception", "if", "this", "partition", "was", "already", "released", "before"], "project": "flink"}
{"id": 4680, "code": "protected void checkError() throws IOException {\n    final Throwable t = cause.get();\n\n    if (t != null) {\n        if (t instanceof CancelTaskException) {\n            throw (CancelTaskException) t;\n        }\n        if (t instanceof IOException) {\n            throw (IOException) t;\n        } else {\n            throw new IOException(t);\n        }\n    }\n}", "summary_tokens": ["checks", "for", "an", "error", "and", "rethrows", "it", "if", "one", "was", "reported"], "project": "flink"}
{"id": 8108, "code": "public List<ResolvedExpression> resolve(List<Expression> expressions) {\n    final Function<List<Expression>, List<Expression>> resolveFunction =\n            concatenateRules(getAllResolverRules());\n    final List<Expression> resolvedExpressions = resolveFunction.apply(expressions);\n    return resolvedExpressions.stream()\n            .map(e -> e.accept(VERIFY_RESOLUTION_VISITOR))\n            .collect(Collectors.toList());\n}", "summary_tokens": ["resolves", "given", "expressions", "with", "configured", "set", "of", "rules"], "project": "flink"}
{"id": 5778, "code": "private void testPutBufferFails(@Nullable final JobID jobId, BlobKey.BlobType blobType)\n        throws IOException {\n    assumeTrue(!OperatingSystem.isWindows()); \n\n    final Configuration config = new Configuration();\n    config.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    File tempFileDir = null;\n    try (BlobServer server = new BlobServer(config, new VoidBlobStore());\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n            \n        tempFileDir = server.createTemporaryFilename().getParentFile().getParentFile();\n        assertTrue(tempFileDir.setExecutable(true, false));\n        assertTrue(tempFileDir.setReadable(true, false));\n        assertTrue(tempFileDir.setWritable(false, false));\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n\n            \n        exception.expect(IOException.class);\n        exception.expectMessage(\"PUT operation failed: \");\n\n        put(cache, jobId, data, blobType);\n\n    } finally {\n            \n        if (tempFileDir != null) {\n                \n            tempFileDir.setWritable(true, false);\n        }\n    }\n}", "summary_tokens": ["uploads", "a", "byte", "array", "to", "a", "server", "which", "cannot", "create", "any", "files", "via", "the", "blob", "cache", "service"], "project": "flink"}
{"id": 2388, "code": "public int size() {\n    return getProps().size();\n}", "summary_tokens": ["return", "the", "number", "of", "keys", "in", "the", "configuration"], "project": "flink"}
{"id": 5464, "code": "public FsStateBackend configure(ReadableConfig config, ClassLoader classLoader) {\n    return new FsStateBackend(this, config, classLoader);\n}", "summary_tokens": ["creates", "a", "copy", "of", "this", "state", "backend", "that", "uses", "the", "values", "defined", "in", "the", "configuration", "for", "fields", "where", "that", "were", "not", "specified", "in", "this", "state", "backend"], "project": "flink"}
{"id": 2020, "code": "public static String ipAddressToUrlString(InetAddress address) {\n    if (address == null) {\n        throw new NullPointerException(\"address is null\");\n    } else if (address instanceof Inet4Address) {\n        return address.getHostAddress();\n    } else if (address instanceof Inet6Address) {\n        return getIPv6UrlRepresentation((Inet6Address) address);\n    } else {\n        throw new IllegalArgumentException(\"Unrecognized type of InetAddress: \" + address);\n    }\n}", "summary_tokens": ["encodes", "an", "ip", "address", "properly", "as", "a", "url", "string"], "project": "flink"}
{"id": 4948, "code": "public static void cancelChainedTasks(List<ChainedDriver<?, ?>> tasks) {\n    for (ChainedDriver<?, ?> task : tasks) {\n        try {\n            task.cancelTask();\n        } catch (Throwable t) {\n                \n        }\n    }\n}", "summary_tokens": ["cancels", "all", "tasks", "via", "their", "chained", "driver", "cancel", "task", "method"], "project": "flink"}
{"id": 4470, "code": "private void removeContender(EmbeddedLeaderElectionService service) {\n    synchronized (lock) {\n            \n        if (!service.running || shutdown) {\n            return;\n        }\n\n        try {\n            if (!allLeaderContenders.remove(service)) {\n                throw new IllegalStateException(\n                        \"leader election service does not belong to this service\");\n            }\n\n                \n            service.contender = null;\n            service.running = false;\n            service.isLeader = false;\n\n                \n            if (currentLeaderConfirmed == service) {\n                currentLeaderConfirmed = null;\n                currentLeaderSessionId = null;\n                currentLeaderAddress = null;\n            }\n            if (currentLeaderProposed == service) {\n                currentLeaderProposed = null;\n                currentLeaderSessionId = null;\n            }\n\n            updateLeader()\n                    .whenComplete(\n                            (aVoid, throwable) -> {\n                                if (throwable != null) {\n                                    fatalError(throwable);\n                                }\n                            });\n        } catch (Throwable t) {\n            fatalError(t);\n        }\n    }\n}", "summary_tokens": ["callback", "from", "leader", "contenders", "when", "they", "stop", "their", "service"], "project": "flink"}
{"id": 5827, "code": "public void testEqualsDifferentBlobType() {\n    final BlobKey k1 = BlobKey.createKey(TRANSIENT_BLOB, KEY_ARRAY_1, RANDOM_ARRAY_1);\n    final BlobKey k2 = BlobKey.createKey(PERMANENT_BLOB, KEY_ARRAY_1, RANDOM_ARRAY_1);\n    assertFalse(k1.equals(k2));\n    assertFalse(k2.equals(k1));\n}", "summary_tokens": ["tests", "the", "equals", "method"], "project": "flink"}
{"id": 8306, "code": "public static TimestampData fromInstant(Instant instant) {\n    long epochSecond = instant.getEpochSecond();\n    int nanoSecond = instant.getNano();\n\n    long millisecond = epochSecond * 1_000 + nanoSecond / 1_000_000;\n    int nanoOfMillisecond = nanoSecond % 1_000_000;\n\n    return new TimestampData(millisecond, nanoOfMillisecond);\n}", "summary_tokens": ["creates", "an", "instance", "of", "timestamp", "data", "from", "an", "instance", "of", "instant"], "project": "flink"}
{"id": 6403, "code": "public void testRegisterJobMasterFromInvalidAddress() throws Exception {\n        \n        \n    String invalidAddress = \"/jobMasterAddress2\";\n    CompletableFuture<RegistrationResponse> invalidAddressFuture =\n            resourceManagerGateway.registerJobMaster(\n                    new JobMasterId(HighAvailabilityServices.DEFAULT_LEADER_ID),\n                    jobMasterResourceId,\n                    invalidAddress,\n                    jobId,\n                    TIMEOUT);\n    assertTrue(\n            invalidAddressFuture.get(5, TimeUnit.SECONDS)\n                    instanceof RegistrationResponse.Failure);\n}", "summary_tokens": ["test", "receive", "registration", "with", "invalid", "address", "from", "job", "master"], "project": "flink"}
{"id": 9273, "code": "protected boolean checkNextIndexOffset() {\n    if (this.currentSortIndexOffset > this.lastIndexEntryOffset) {\n        MemorySegment returnSegment = nextMemorySegment();\n        if (returnSegment != null) {\n            this.currentSortIndexSegment = returnSegment;\n            this.sortIndex.add(this.currentSortIndexSegment);\n            this.currentSortIndexOffset = 0;\n        } else {\n            return false;\n        }\n    }\n    return true;\n}", "summary_tokens": ["check", "if", "we", "need", "request", "next", "index", "memory"], "project": "flink"}
{"id": 2137, "code": "private static WatermarkOutput createDeferredOutput(WatermarkOutputMultiplexer multiplexer) {\n    final String id = UUID.randomUUID().toString();\n    multiplexer.registerNewOutput(id);\n    return multiplexer.getDeferredOutput(id);\n}", "summary_tokens": ["convenience", "method", "so", "we", "don", "t", "have", "to", "go", "through", "the", "output", "id", "dance", "when", "we", "only", "want", "an", "deferred", "output", "for", "a", "given", "output", "id"], "project": "flink"}
{"id": 6233, "code": "public void testAvailableBuffersMoreThanRequiredBuffers() throws Exception {\n        \n    final NetworkBufferPool networkBufferPool = new NetworkBufferPool(16, 32);\n    final int numFloatingBuffers = 14;\n\n    final SingleInputGate inputGate = createSingleInputGate(1, networkBufferPool);\n    final RemoteInputChannel inputChannel = createRemoteInputChannel(inputGate);\n    inputGate.setInputChannels(inputChannel);\n    Throwable thrown = null;\n    try {\n        final BufferPool bufferPool =\n                spy(networkBufferPool.createBufferPool(numFloatingBuffers, numFloatingBuffers));\n        inputGate.setBufferPool(bufferPool);\n        inputGate.setupChannels();\n        inputChannel.requestSubpartition(0);\n\n            \n        final Buffer exclusiveBuffer = inputChannel.requestBuffer();\n        assertNotNull(exclusiveBuffer);\n\n        final Buffer floatingBuffer = bufferPool.requestBuffer();\n        assertNotNull(floatingBuffer);\n\n        verify(bufferPool, times(1)).requestBuffer();\n\n            \n        inputChannel.onSenderBacklog(12);\n\n            \n        verify(bufferPool, times(14)).requestBuffer();\n        verify(bufferPool, times(0)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 14 buffers required in the channel\",\n                14,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n\n            \n            \n        inputChannel.onSenderBacklog(10);\n\n            \n        verify(bufferPool, times(14)).requestBuffer();\n        verify(bufferPool, times(0)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 12 buffers required in the channel\",\n                12,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 0 buffers available in local pool\",\n                0,\n                bufferPool.getNumberOfAvailableMemorySegments());\n\n            \n        exclusiveBuffer.recycleBuffer();\n\n            \n            \n            \n        verify(bufferPool, times(14)).requestBuffer();\n        verify(bufferPool, times(0)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 12 buffers required in the channel\",\n                12,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 1 buffer available in local pool\",\n                1,\n                bufferPool.getNumberOfAvailableMemorySegments());\n\n            \n        floatingBuffer.recycleBuffer();\n\n            \n            \n            \n        verify(bufferPool, times(14)).requestBuffer();\n        verify(bufferPool, times(0)).addBufferListener(inputChannel.getBufferManager());\n        assertEquals(\n                \"There should be 14 buffers available in the channel\",\n                14,\n                inputChannel.getNumberOfAvailableBuffers());\n        assertEquals(\n                \"There should be 12 buffers required in the channel\",\n                12,\n                inputChannel.getNumberOfRequiredBuffers());\n        assertEquals(\n                \"There should be 2 buffers available in local pool\",\n                2,\n                bufferPool.getNumberOfAvailableMemorySegments());\n    } catch (Throwable t) {\n        thrown = t;\n    } finally {\n        cleanup(networkBufferPool, null, null, thrown, inputChannel);\n    }\n}", "summary_tokens": ["tests", "to", "verify", "the", "behaviours", "of", "recycling", "floating", "and", "exclusive", "buffers", "if", "the", "number", "of", "available", "buffers", "is", "more", "than", "required", "buffers", "by", "decreasing", "the", "sender", "s", "backlog"], "project": "flink"}
{"id": 5862, "code": "public void testOnEphemeralPort() throws IOException {\n    Configuration conf = new Configuration();\n    conf.setString(BlobServerOptions.PORT, \"0\");\n    conf.setString(\n            BlobServerOptions.STORAGE_DIRECTORY, temporaryFolder.newFolder().getAbsolutePath());\n\n    BlobServer server = new BlobServer(conf, new VoidBlobStore());\n    server.start();\n    server.close();\n}", "summary_tokens": ["start", "blob", "server", "on", "0", "pick", "an", "ephemeral", "port"], "project": "flink"}
{"id": 732, "code": "public void testSerDeEventTime() throws Exception {\n    testRecordSerDe(EventTime);\n}", "summary_tokens": ["to", "test", "value", "and", "watermark", "serialization", "and", "deserialization", "with", "time", "characteristic", "event", "time"], "project": "flink"}
{"id": 2823, "code": "public AggregateOperator<T> aggregate(Aggregations agg, int field) {\n    return aggregate(agg, field, Utils.getCallLocationName());\n}", "summary_tokens": ["applies", "an", "aggregate", "transformation", "on", "a", "grouped", "org"], "project": "flink"}
{"id": 4015, "code": "public void callsOnStopOnlyOnce() throws Exception {\n    final CompletableFuture<Void> onStopFuture = new CompletableFuture<>();\n    final OnStopCountingRpcEndpoint endpoint =\n            new OnStopCountingRpcEndpoint(akkaRpcService, onStopFuture);\n\n    try {\n        endpoint.start();\n\n        final AkkaBasedEndpoint selfGateway = endpoint.getSelfGateway(AkkaBasedEndpoint.class);\n\n            \n        selfGateway.getActorRef().tell(ControlMessages.TERMINATE, ActorRef.noSender());\n        selfGateway.getActorRef().tell(ControlMessages.TERMINATE, ActorRef.noSender());\n\n        endpoint.waitUntilOnStopHasBeenCalled();\n\n        onStopFuture.complete(null);\n\n        endpoint.getTerminationFuture().get();\n\n        assertThat(endpoint.getNumOnStopCalls(), is(1));\n    } finally {\n        onStopFuture.complete(null);\n        RpcUtils.terminateRpcEndpoint(endpoint, timeout);\n    }\n}", "summary_tokens": ["tests", "that", "multiple", "termination", "calls", "won", "t", "trigger", "the", "on", "stop", "action", "multiple", "times"], "project": "flink"}
{"id": 1436, "code": "public Optional<Integer> declareManagedMemoryUseCaseAtOperatorScope(\n        ManagedMemoryUseCase managedMemoryUseCase, int weight) {\n    Preconditions.checkNotNull(managedMemoryUseCase);\n    Preconditions.checkArgument(\n            managedMemoryUseCase.scope == ManagedMemoryUseCase.Scope.OPERATOR,\n            \"Use case is not operator scope.\");\n    Preconditions.checkArgument(\n            weight > 0, \"Weights for operator scope use cases must be greater than 0.\");\n\n    return Optional.ofNullable(\n            managedMemoryOperatorScopeUseCaseWeights.put(managedMemoryUseCase, weight));\n}", "summary_tokens": ["declares", "that", "this", "transformation", "contains", "certain", "operator", "scope", "managed", "memory", "use", "case"], "project": "flink"}
{"id": 6785, "code": "public static void putKeyLen(MemorySegment memorySegment, int offset, int keyLen) {\n    memorySegment.putInt(offset + KEY_LEN_OFFSET, keyLen);\n}", "summary_tokens": ["puts", "the", "length", "of", "key", "to", "the", "key", "space"], "project": "flink"}
{"id": 5349, "code": "public TypeSerializerSchemaCompatibility<ArrayList<T>>\n        resolveSchemaCompatibilityViaRedirectingToNewSnapshotClass(\n                TypeSerializerConfigSnapshot<ArrayList<T>> deprecatedConfigSnapshot) {\n\n    if (deprecatedConfigSnapshot instanceof CollectionSerializerConfigSnapshot) {\n        CollectionSerializerConfigSnapshot<ArrayList<T>, T> castedLegacySnapshot =\n                (CollectionSerializerConfigSnapshot<ArrayList<T>, T>) deprecatedConfigSnapshot;\n\n        ArrayListSerializerSnapshot<T> newSnapshot = new ArrayListSerializerSnapshot<>();\n        return CompositeTypeSerializerUtil.delegateCompatibilityCheckToNewSnapshot(\n                this, newSnapshot, castedLegacySnapshot.getNestedSerializerSnapshots());\n    }\n\n    return TypeSerializerSchemaCompatibility.incompatible();\n}", "summary_tokens": ["we", "need", "to", "implement", "this", "method", "as", "a", "type", "serializer", "config", "snapshot"], "project": "flink"}
{"id": 6759, "code": "private MemorySegment getKeySegment(K key, N namespace) {\n    return skipListKeySerializer.serializeToSegment(key, namespace);\n}", "summary_tokens": ["get", "the", "memory", "segment", "wrapping", "up", "the", "serialized", "key", "bytes"], "project": "flink"}
{"id": 692, "code": "public void runOneToOneExactlyOnceTest() throws Exception {\n\n    final String topic = \"oneToOneTopic\";\n    final int parallelism = 5;\n    final int numElementsPerPartition = 1000;\n    final int totalElements = parallelism * numElementsPerPartition;\n    final int failAfterElements = numElementsPerPartition / 3;\n\n    createTestTopic(topic, parallelism, 1);\n\n    DataGenerators.generateRandomizedIntegerSequence(\n            StreamExecutionEnvironment.getExecutionEnvironment(),\n            kafkaServer,\n            topic,\n            parallelism,\n            numElementsPerPartition,\n            true);\n\n        \n\n    DeserializationSchema<Integer> schema =\n            new TypeInformationSerializationSchema<>(\n                    BasicTypeInfo.INT_TYPE_INFO, new ExecutionConfig());\n\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    env.enableCheckpointing(500);\n    env.setParallelism(parallelism);\n    env.setRestartStrategy(RestartStrategies.fixedDelayRestart(1, 0));\n\n    Properties props = new Properties();\n    props.putAll(standardProps);\n    props.putAll(secureProps);\n\n    getStream(env, topic, schema, props)\n            .map(new PartitionValidatingMapper(parallelism, 1))\n            .map(new FailingIdentityMapper<Integer>(failAfterElements))\n            .addSink(new ValidatingExactlyOnceSink(totalElements))\n            .setParallelism(1);\n\n    FailingIdentityMapper.failedBefore = false;\n    tryExecute(env, \"One-to-one exactly once test\");\n\n    deleteTestTopic(topic);\n}", "summary_tokens": ["tests", "the", "proper", "consumption", "when", "having", "a", "0", "0", "correspondence", "between", "kafka", "partitions", "and", "flink", "sources"], "project": "flink"}
{"id": 6428, "code": "public void testTaskManagerUnregistration() throws Exception {\n    final TaskExecutorGateway taskExecutorGateway =\n            new TestingTaskExecutorGatewayBuilder()\n                    .setRequestSlotFunction(tuple6 -> new CompletableFuture<>())\n                    .createTestingTaskExecutorGateway();\n    final TaskExecutorConnection taskManagerConnection =\n            createTaskExecutorConnection(taskExecutorGateway);\n    final ResourceID resourceId = taskManagerConnection.getResourceID();\n\n    final SlotID slotId1 = new SlotID(resourceId, 0);\n    final SlotID slotId2 = new SlotID(resourceId, 1);\n    final SlotReport slotReport =\n            new SlotReport(\n                    Arrays.asList(\n                            createAllocatedSlotStatus(slotId1), createFreeSlotStatus(slotId2)));\n\n    final ResourceRequirements resourceRequirements = createResourceRequirementsForSingleSlot();\n\n    final DefaultSlotTracker slotTracker = new DefaultSlotTracker();\n\n    try (DeclarativeSlotManager slotManager =\n            createDeclarativeSlotManagerBuilder()\n                    .setSlotTracker(slotTracker)\n                    .buildAndStartWithDirectExec()) {\n\n        slotManager.registerTaskManager(\n                taskManagerConnection, slotReport, ResourceProfile.ANY, ResourceProfile.ANY);\n\n        assertEquals(\n                \"The number registered slots does not equal the expected number.\",\n                2,\n                slotManager.getNumberRegisteredSlots());\n\n        slotManager.processResourceRequirements(resourceRequirements);\n\n        slotManager.unregisterTaskManager(\n                taskManagerConnection.getInstanceID(), TEST_EXCEPTION);\n\n        assertEquals(0, slotManager.getNumberRegisteredSlots());\n    }\n}", "summary_tokens": ["tests", "that", "un", "registration", "of", "task", "managers", "will", "free", "and", "remove", "all", "registered", "slots"], "project": "flink"}
{"id": 8698, "code": "public static LogicalSnapshot create(RelNode input, RexNode period) {\n    final RelOptCluster cluster = input.getCluster();\n    final RelMetadataQuery mq = cluster.getMetadataQuery();\n    final RelTraitSet traitSet =\n            cluster.traitSet()\n                    .replace(Convention.NONE)\n                    .replaceIfs(\n                            RelCollationTraitDef.INSTANCE,\n                            () -> RelMdCollation.snapshot(mq, input))\n                    .replaceIf(\n                            RelDistributionTraitDef.INSTANCE,\n                            () -> RelMdDistribution.snapshot(mq, input));\n    return new LogicalSnapshot(cluster, traitSet, input, period);\n}", "summary_tokens": ["creates", "a", "logical", "snapshot"], "project": "flink"}
{"id": 7656, "code": "public void testExceptionThrownIfAllRestoresFailed() throws Exception {\n\n    CloseableRegistry closeableRegistry = new CloseableRegistry();\n\n    OperatorStateHandle firstFailHandle = mock(OperatorStateHandle.class);\n    OperatorStateHandle secondFailHandle = mock(OperatorStateHandle.class);\n    OperatorStateHandle thirdFailHandle = mock(OperatorStateHandle.class);\n\n    List<StateObjectCollection<OperatorStateHandle>> sortedRestoreOptions =\n            Arrays.asList(\n                    new StateObjectCollection<>(Collections.singletonList(firstFailHandle)),\n                    new StateObjectCollection<>(Collections.singletonList(secondFailHandle)),\n                    new StateObjectCollection<>(Collections.singletonList(thirdFailHandle)));\n\n    BackendRestorerProcedure<OperatorStateBackend, OperatorStateHandle> restorerProcedure =\n            new BackendRestorerProcedure<>(\n                    backendSupplier, closeableRegistry, \"test op state backend\");\n\n    try {\n        restorerProcedure.createAndRestore(sortedRestoreOptions);\n        Assert.fail();\n    } catch (Exception ignore) {\n    }\n\n    verify(firstFailHandle).openInputStream();\n    verify(secondFailHandle).openInputStream();\n    verify(thirdFailHandle).openInputStream();\n}", "summary_tokens": ["tests", "if", "there", "is", "an", "exception", "if", "all", "restore", "attempts", "are", "exhausted", "and", "failed"], "project": "flink"}
{"id": 8431, "code": "private static Map<String, String> normalizeContext(TableFactory factory) {\n    Map<String, String> requiredContext = factory.requiredContext();\n    if (requiredContext == null) {\n        throw new TableException(\n                String.format(\n                        \"Required context of factory '%s' must not be null.\",\n                        factory.getClass().getName()));\n    }\n    return requiredContext.keySet().stream()\n            .collect(Collectors.toMap(String::toLowerCase, requiredContext::get));\n}", "summary_tokens": ["prepares", "the", "properties", "of", "a", "context", "to", "be", "used", "for", "match", "operations"], "project": "flink"}
{"id": 9565, "code": "public void testOperatorEventAckLost() throws Exception {\n    final int[] eventsWithLostAck = new int[] {2, 4};\n\n    OpEventRpcInterceptor.currentHandler =\n            new OperatorEventRpcHandler(\n                    (task, operator, event, originalRpcHandler) -> {\n                            \n                        originalRpcHandler.apply(task, operator, event);\n                            \n                        return askTimeoutFuture();\n                    },\n                    eventsWithLostAck);\n\n    runTest(false);\n}", "summary_tokens": ["this", "test", "the", "case", "that", "the", "enumerator", "must", "handle", "the", "case", "of", "presumably", "lost", "splits", "that", "were", "actually", "delivered"], "project": "flink"}
{"id": 9252, "code": "public RowData removeLast() {\n    Map.Entry<RowData, Collection<RowData>> last = treeMap.lastEntry();\n    RowData lastElement = null;\n    if (last != null) {\n        Collection<RowData> collection = last.getValue();\n        if (collection != null) {\n            if (collection instanceof List) {\n                    \n                List<RowData> list = (List<RowData>) collection;\n                if (!list.isEmpty()) {\n                    lastElement = list.remove(list.size() - 1);\n                    currentTopNum -= 1;\n                    if (list.isEmpty()) {\n                        treeMap.remove(last.getKey());\n                    }\n                }\n            } else {\n                lastElement = getLastElement(collection);\n                if (lastElement != null) {\n                    if (collection.remove(lastElement)) {\n                        currentTopNum -= 1;\n                    }\n                    if (collection.size() == 0) {\n                        treeMap.remove(last.getKey());\n                    }\n                }\n            }\n        }\n    }\n    return lastElement;\n}", "summary_tokens": ["removes", "the", "last", "record", "of", "the", "last", "entry", "in", "the", "buffer"], "project": "flink"}
{"id": 8015, "code": "public void setDecimalContext(MathContext decimalContext) {\n    this.decimalContext = Preconditions.checkNotNull(decimalContext);\n}", "summary_tokens": ["sets", "the", "default", "context", "for", "decimal", "division", "calculation"], "project": "flink"}
{"id": 6682, "code": "public void testTaskConfig() throws Exception {\n    long interval = 28218123;\n    long timeout = interval + 19292;\n\n    final Configuration config = new Configuration();\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_INTERVAL, interval);\n    config.setLong(TaskManagerOptions.TASK_CANCELLATION_TIMEOUT, timeout);\n\n    final ExecutionConfig executionConfig = new ExecutionConfig();\n    executionConfig.setTaskCancellationInterval(interval + 1337);\n    executionConfig.setTaskCancellationTimeout(timeout - 1337);\n\n    final Task task =\n            createTaskBuilder()\n                    .setInvokable(InvokableBlockingInInvoke.class)\n                    .setTaskManagerConfig(config)\n                    .setExecutionConfig(executionConfig)\n                    .build();\n\n    assertEquals(interval, task.getTaskCancellationInterval());\n    assertEquals(timeout, task.getTaskCancellationTimeout());\n\n    task.startTaskThread();\n\n    awaitLatch.await();\n\n    assertEquals(\n            executionConfig.getTaskCancellationInterval(), task.getTaskCancellationInterval());\n    assertEquals(\n            executionConfig.getTaskCancellationTimeout(), task.getTaskCancellationTimeout());\n\n    task.getExecutingThread().interrupt();\n    task.getExecutingThread().join();\n}", "summary_tokens": ["tests", "that", "the", "task", "configuration", "is", "respected", "and", "overwritten", "by", "the", "execution", "config"], "project": "flink"}
{"id": 8096, "code": "default Result lookupBuiltInFunction(BuiltInFunctionDefinition definition) {\n    return lookupFunction(UnresolvedIdentifier.of(definition.getName()))\n            .orElseThrow(\n                    () ->\n                            new TableException(\n                                    String.format(\n                                            \"Required built-in function [%s] could not be found in any catalog.\",\n                                            definition.getName())));\n}", "summary_tokens": ["helper", "method", "for", "looking", "up", "a", "built", "in", "function"], "project": "flink"}
{"id": 5760, "code": "private static void testGetFailsFromCorruptFile(\n        @Nullable JobID jobId,\n        BlobKey.BlobType blobType,\n        boolean corruptOnHAStore,\n        Configuration config,\n        BlobStore blobStore,\n        ExpectedException expectedException)\n        throws IOException {\n\n    assertTrue(\n            \"corrupt HA file requires a HA setup\",\n            !corruptOnHAStore || blobType == PERMANENT_BLOB);\n\n    Random rnd = new Random();\n\n    try (BlobServer server = new BlobServer(config, blobStore);\n            BlobCacheService cache =\n                    new BlobCacheService(\n                            config,\n                            corruptOnHAStore ? blobStore : new VoidBlobStore(),\n                            new InetSocketAddress(\"localhost\", server.getPort()))) {\n\n        server.start();\n\n        byte[] data = new byte[2000000];\n        rnd.nextBytes(data);\n\n            \n        BlobKey key = put(server, jobId, data, blobType);\n        assertNotNull(key);\n\n            \n        byte[] data2 = Arrays.copyOf(data, data.length);\n        data2[0] ^= 1;\n        if (corruptOnHAStore) {\n            File tmpFile = Files.createTempFile(\"blob\", \".jar\").toFile();\n            try {\n                FileUtils.writeByteArrayToFile(tmpFile, data2);\n                blobStore.put(tmpFile, jobId, key);\n            } finally {\n                    \n                tmpFile.delete();\n            }\n\n                \n                \n            File blobFile = server.getStorageLocation(jobId, key);\n            assertTrue(blobFile.delete());\n        } else {\n            File blobFile = server.getStorageLocation(jobId, key);\n            assertTrue(blobFile.exists());\n            FileUtils.writeByteArrayToFile(blobFile, data2);\n        }\n\n            \n        expectedException.expect(IOException.class);\n        expectedException.expectCause(\n                CoreMatchers.allOf(\n                        instanceOf(IOException.class),\n                        hasProperty(\"message\", containsString(\"data corruption\"))));\n\n        get(cache, jobId, key);\n    }\n}", "summary_tokens": ["checks", "the", "get", "operation", "fails", "when", "the", "downloaded", "file", "from", "blob", "server", "or", "ha", "store", "is", "corrupt", "i"], "project": "flink"}
{"id": 2108, "code": "public static <IN> CompletableFuture<IN> whenCompleteAsyncIfNotDone(\n        CompletableFuture<IN> completableFuture,\n        Executor executor,\n        BiConsumer<? super IN, ? super Throwable> whenCompleteFun) {\n    return completableFuture.isDone()\n            ? completableFuture.whenComplete(whenCompleteFun)\n            : completableFuture.whenCompleteAsync(whenCompleteFun, executor);\n}", "summary_tokens": ["this", "function", "takes", "a", "completable", "future", "and", "a", "bi", "consumer", "to", "call", "on", "completion", "of", "this", "future"], "project": "flink"}
{"id": 1354, "code": "public static Time hours(long hours) {\n    return of(hours, TimeUnit.HOURS);\n}", "summary_tokens": ["creates", "a", "new", "time", "that", "represents", "the", "given", "number", "of", "hours"], "project": "flink"}
{"id": 9491, "code": "public void releaseBlocker() {\n    synchronized (lock) {\n        blockerReleased = true;\n        lock.notifyAll();\n    }\n}", "summary_tokens": ["lets", "the", "blocked", "thread", "continue"], "project": "flink"}
{"id": 8246, "code": "public List<String> getColumns() {\n    return columns;\n}", "summary_tokens": ["list", "of", "column", "names", "for", "which", "the", "primary", "key", "was", "defined"], "project": "flink"}
{"id": 7415, "code": "public Long getWaitTime() {\n    return waitTime;\n}", "summary_tokens": ["returns", "the", "wait", "time"], "project": "flink"}
{"id": 1954, "code": "public static void tryRethrowIOException(Throwable t) throws IOException {\n    if (t instanceof IOException) {\n        throw (IOException) t;\n    } else if (t instanceof RuntimeException) {\n        throw (RuntimeException) t;\n    } else if (t instanceof Error) {\n        throw (Error) t;\n    }\n}", "summary_tokens": ["tries", "to", "throw", "the", "given", "throwable", "in", "scenarios", "where", "the", "signatures", "allows", "only", "ioexceptions", "and", "runtime", "exception", "and", "error"], "project": "flink"}
{"id": 2522, "code": "public CompressWriterFactory<IN> withHadoopCompression(\n        String codecName, Configuration hadoopConfig) throws IOException {\n    this.codecExtension = getHadoopCodecExtension(codecName, hadoopConfig);\n    this.hadoopCodecName = codecName;\n\n    for (Map.Entry<String, String> entry : hadoopConfig) {\n        hadoopConfigMap.put(entry.getKey(), entry.getValue());\n    }\n\n    return this;\n}", "summary_tokens": ["compresses", "the", "data", "using", "the", "provided", "hadoop", "compression", "codec", "and", "configuration"], "project": "flink"}
{"id": 6499, "code": "public void testJsonValue() throws Exception {\n    assertEquals(\n            \"\\\"ok\\\"\",\n            RestMapperUtils.getStrictObjectMapper()\n                    .writeValueAsString(JobVertexBackPressureInfo.VertexBackPressureStatus.OK));\n    assertEquals(\n            \"\\\"deprecated\\\"\",\n            RestMapperUtils.getStrictObjectMapper()\n                    .writeValueAsString(\n                            JobVertexBackPressureInfo.VertexBackPressureStatus.DEPRECATED));\n}", "summary_tokens": ["tests", "that", "the", "enum", "values", "are", "serialized", "correctly"], "project": "flink"}
{"id": 8344, "code": "public static StringData readStringData(\n        MemorySegment[] segments,\n        int baseOffset,\n        int fieldOffset,\n        long variablePartOffsetAndLen) {\n    long mark = variablePartOffsetAndLen & HIGHEST_FIRST_BIT;\n    if (mark == 0) {\n        final int subOffset = (int) (variablePartOffsetAndLen >> 32);\n        final int len = (int) variablePartOffsetAndLen;\n        return BinaryStringData.fromAddress(segments, baseOffset + subOffset, len);\n    } else {\n        int len = (int) ((variablePartOffsetAndLen & HIGHEST_SECOND_TO_EIGHTH_BIT) >>> 56);\n        if (BinarySegmentUtils.LITTLE_ENDIAN) {\n            return BinaryStringData.fromAddress(segments, fieldOffset, len);\n        } else {\n                \n            return BinaryStringData.fromAddress(segments, fieldOffset + 1, len);\n        }\n    }\n}", "summary_tokens": ["get", "binary", "string", "if", "len", "less", "than", "0", "will", "be", "include", "in", "variable", "part", "offset", "and", "len"], "project": "flink"}
{"id": 6712, "code": "public void testAddAndLock() throws Exception {\n    final TestingLongStateHandleHelper longStateStorage = new TestingLongStateHandleHelper();\n    ZooKeeperStateHandleStore<TestingLongStateHandleHelper.LongStateHandle> store =\n            new ZooKeeperStateHandleStore<>(ZOOKEEPER.getClient(), longStateStorage);\n\n        \n    final String pathInZooKeeper = \"/testAdd\";\n    final long state = 1239712317L;\n\n        \n    store.addAndLock(pathInZooKeeper, new TestingLongStateHandleHelper.LongStateHandle(state));\n\n        \n        \n    assertEquals(1, store.getAllAndLock().size());\n    assertEquals(state, store.getAndLock(pathInZooKeeper).retrieveState().getValue());\n\n        \n    Stat stat = ZOOKEEPER.getClient().checkExists().forPath(pathInZooKeeper);\n    assertNotNull(stat);\n    assertEquals(0, stat.getEphemeralOwner());\n\n    List<String> children = ZOOKEEPER.getClient().getChildren().forPath(pathInZooKeeper);\n\n        \n    assertEquals(1, children.size());\n\n    stat = ZOOKEEPER.getClient().checkExists().forPath(pathInZooKeeper + '/' + children.get(0));\n    assertNotNull(stat);\n\n        \n    assertNotEquals(0, stat.getEphemeralOwner());\n\n        \n    @SuppressWarnings(\"unchecked\")\n    final long actual =\n            ((RetrievableStateHandle<TestingLongStateHandleHelper.LongStateHandle>)\n                            InstantiationUtil.deserializeObject(\n                                    ZOOKEEPER.getClient().getData().forPath(pathInZooKeeper),\n                                    ClassLoader.getSystemClassLoader()))\n                    .retrieveState()\n                    .getValue();\n\n    assertEquals(state, actual);\n}", "summary_tokens": ["tests", "add", "operation", "with", "lock"], "project": "flink"}
{"id": 4083, "code": "public static StringifiedAccumulatorResult[] stringifyAccumulatorResults(\n        Map<String, OptionalFailure<Accumulator<?, ?>>> accs) {\n    if (accs == null || accs.isEmpty()) {\n        return new StringifiedAccumulatorResult[0];\n    } else {\n        StringifiedAccumulatorResult[] results = new StringifiedAccumulatorResult[accs.size()];\n\n        int i = 0;\n        for (Map.Entry<String, OptionalFailure<Accumulator<?, ?>>> entry : accs.entrySet()) {\n            results[i++] = stringifyAccumulatorResult(entry.getKey(), entry.getValue());\n        }\n        return results;\n    }\n}", "summary_tokens": ["flatten", "a", "map", "of", "accumulator", "names", "to", "accumulator", "instances", "into", "an", "array", "of", "stringified", "accumulator", "result", "values"], "project": "flink"}
{"id": 4953, "code": "private void initInputFormat() {\n    ClassLoader userCodeClassLoader = getUserCodeClassLoader();\n        \n    Configuration taskConf = getTaskConfiguration();\n    this.config = new TaskConfig(taskConf);\n\n    final Pair<OperatorID, InputFormat<OT, InputSplit>> operatorIdAndInputFormat;\n    InputOutputFormatContainer formatContainer =\n            new InputOutputFormatContainer(config, userCodeClassLoader);\n    try {\n        operatorIdAndInputFormat = formatContainer.getUniqueInputFormat();\n        this.format = operatorIdAndInputFormat.getValue();\n\n            \n        if (!InputFormat.class.isAssignableFrom(this.format.getClass())) {\n            throw new RuntimeException(\n                    \"The class '\"\n                            + this.format.getClass().getName()\n                            + \"' is not a subclass of '\"\n                            + InputFormat.class.getName()\n                            + \"' as is required.\");\n        }\n    } catch (ClassCastException ccex) {\n        throw new RuntimeException(\n                \"The stub class is not a proper subclass of \" + InputFormat.class.getName(),\n                ccex);\n    }\n\n    Thread thread = Thread.currentThread();\n    ClassLoader original = thread.getContextClassLoader();\n        \n        \n    try {\n        thread.setContextClassLoader(userCodeClassLoader);\n        this.format.configure(formatContainer.getParameters(operatorIdAndInputFormat.getKey()));\n    } catch (Throwable t) {\n        throw new RuntimeException(\n                \"The user defined 'configure()' method caused an error: \" + t.getMessage(), t);\n    } finally {\n        thread.setContextClassLoader(original);\n    }\n\n        \n    this.serializerFactory = this.config.getOutputSerializer(userCodeClassLoader);\n}", "summary_tokens": ["initializes", "the", "input", "format", "implementation", "and", "configuration"], "project": "flink"}
{"id": 3716, "code": "public void setDriverStrategy(DriverStrategy newDriverStrategy) {\n    this.driverStrategy = newDriverStrategy;\n}", "summary_tokens": ["sets", "the", "driver", "strategy", "for", "this", "node"], "project": "flink"}
{"id": 491, "code": "static <T> KafkaRecordSerializationSchemaBuilder<T> builder() {\n    return new KafkaRecordSerializationSchemaBuilder<>();\n}", "summary_tokens": ["creates", "a", "default", "schema", "builder", "to", "provide", "common", "building", "blocks", "i"], "project": "flink"}
{"id": 7853, "code": "public void streamTaskAsyncExceptionHandler_handleException_forwardsMessageProperly() {\n    MockEnvironment mockEnvironment = MockEnvironment.builder().build();\n    RuntimeException expectedException = new RuntimeException(\"RUNTIME EXCEPTION\");\n\n    final StreamTask.StreamTaskAsyncExceptionHandler asyncExceptionHandler =\n            new StreamTask.StreamTaskAsyncExceptionHandler(mockEnvironment);\n\n    mockEnvironment.setExpectedExternalFailureCause(AsynchronousException.class);\n    final String expectedErrorMessage = \"EXPECTED_ERROR MESSAGE\";\n\n    asyncExceptionHandler.handleAsyncException(expectedErrorMessage, expectedException);\n\n        \n    Optional<? extends Throwable> actualExternalFailureCause =\n            mockEnvironment.getActualExternalFailureCause();\n    final Throwable actualException =\n            actualExternalFailureCause.orElseThrow(\n                    () -> new AssertionError(\"Expected exceptional completion\"));\n\n    assertThat(actualException, instanceOf(AsynchronousException.class));\n    assertThat(actualException.getMessage(), is(\"EXPECTED_ERROR MESSAGE\"));\n    assertThat(actualException.getCause(), is(expectedException));\n}", "summary_tokens": ["this", "test", "checks", "the", "async", "exceptions", "handling", "wraps", "the", "message", "and", "cause", "as", "an", "asynchronous", "exception", "and", "propagates", "this", "to", "the", "environment"], "project": "flink"}
{"id": 9589, "code": "public void testDisposeSavepointWithCustomKvState() throws Exception {\n    ClusterClient<?> clusterClient =\n            new MiniClusterClient(new Configuration(), miniClusterResource.getMiniCluster());\n\n    Deadline deadline = new FiniteDuration(100, TimeUnit.SECONDS).fromNow();\n\n    File checkpointDir = FOLDER.newFolder();\n    File outputDir = FOLDER.newFolder();\n\n    final PackagedProgram program =\n            PackagedProgram.newBuilder()\n                    .setJarFile(new File(CUSTOM_KV_STATE_JAR_PATH))\n                    .setArguments(\n                            new String[] {\n                                String.valueOf(parallelism),\n                                checkpointDir.toURI().toString(),\n                                \"5000\",\n                                outputDir.toURI().toString(),\n                                \"false\" \n                                    \n                            })\n                    .build();\n\n    TestStreamEnvironment.setAsContext(\n            miniClusterResource.getMiniCluster(),\n            parallelism,\n            Collections.singleton(new Path(CUSTOM_KV_STATE_JAR_PATH)),\n            Collections.emptyList());\n\n        \n    Thread invokeThread =\n            new Thread(\n                    () -> {\n                        try {\n                            program.invokeInteractiveModeForExecution();\n                        } catch (ProgramInvocationException ex) {\n                            if (ex.getCause() == null\n                                    || !(ex.getCause() instanceof JobCancellationException)) {\n                                ex.printStackTrace();\n                            }\n                        }\n                    });\n\n    LOG.info(\"Starting program invoke thread\");\n    invokeThread.start();\n\n        \n    JobID jobId = null;\n\n    LOG.info(\"Waiting for job status running.\");\n\n        \n    while (jobId == null && deadline.hasTimeLeft()) {\n\n        Collection<JobStatusMessage> jobs =\n                clusterClient\n                        .listJobs()\n                        .get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n        for (JobStatusMessage job : jobs) {\n            if (job.getJobState() == JobStatus.RUNNING) {\n                jobId = job.getJobId();\n                LOG.info(\"Job running. ID: \" + jobId);\n                break;\n            }\n        }\n\n            \n        if (jobId == null) {\n            Thread.sleep(100L);\n        }\n    }\n\n        \n    String savepointPath = null;\n    for (int i = 0; i < 20; i++) {\n        LOG.info(\"Triggering savepoint (\" + (i + 1) + \"/20).\");\n        try {\n            savepointPath =\n                    clusterClient\n                            .triggerSavepoint(jobId, null)\n                            .get(deadline.timeLeft().toMillis(), TimeUnit.MILLISECONDS);\n        } catch (Exception cause) {\n            LOG.info(\"Failed to trigger savepoint. Retrying...\", cause);\n                \n            Thread.sleep(500);\n        }\n    }\n\n    assertNotNull(\"Failed to trigger savepoint\", savepointPath);\n\n    clusterClient.disposeSavepoint(savepointPath).get();\n\n    clusterClient.cancel(jobId).get();\n\n        \n    invokeThread.join(deadline.timeLeft().toMillis());\n    assertFalse(\"Program invoke thread still running\", invokeThread.isAlive());\n}", "summary_tokens": ["tests", "disposal", "of", "a", "savepoint", "which", "contains", "custom", "user", "code", "kv", "state"], "project": "flink"}
{"id": 5613, "code": "public static ThrowableType getThrowableType(Throwable cause) {\n    final ThrowableAnnotation annotation =\n            cause.getClass().getAnnotation(ThrowableAnnotation.class);\n    return annotation == null ? ThrowableType.RecoverableError : annotation.value();\n}", "summary_tokens": ["classify", "the", "exceptions", "by", "extracting", "the", "throwable", "type", "from", "a", "potential", "throwable", "annotation"], "project": "flink"}
{"id": 2611, "code": "private int readIntLittleEndian() throws IOException {\n    int ch4 = in.read();\n    int ch3 = in.read();\n    int ch2 = in.read();\n    int ch1 = in.read();\n    return ((ch1 << 24) + (ch2 << 16) + (ch3 << 8) + ch4);\n}", "summary_tokens": ["reads", "the", "next", "0", "byte", "little", "endian", "int"], "project": "flink"}
{"id": 7724, "code": "private Map<JobVertexID, String> rememberIds(JobGraph jobGraph) {\n    final Map<JobVertexID, String> ids = new HashMap<>();\n    for (JobVertex vertex : jobGraph.getVertices()) {\n        ids.put(vertex.getID(), vertex.getName());\n    }\n    return ids;\n}", "summary_tokens": ["returns", "a", "job", "vertex", "id", "to", "vertex", "name", "mapping", "for", "the", "given", "graph"], "project": "flink"}
{"id": 6170, "code": "public void testConnectionResetByPeer() throws Throwable {\n    EmbeddedChannel ch = createEmbeddedChannel();\n\n    NetworkClientHandler handler = getClientHandler(ch);\n\n    RemoteInputChannel rich = addInputChannel(handler);\n\n    final Throwable[] error = new Throwable[1];\n\n        \n    doAnswer(\n                    new Answer<Void>() {\n                        @Override\n                        public Void answer(InvocationOnMock invocation) throws Throwable {\n                            Throwable cause = (Throwable) invocation.getArguments()[0];\n\n                            try {\n                                assertEquals(RemoteTransportException.class, cause.getClass());\n                                assertNotEquals(\"Connection reset by peer\", cause.getMessage());\n\n                                assertEquals(IOException.class, cause.getCause().getClass());\n                                assertEquals(\n                                        \"Connection reset by peer\",\n                                        cause.getCause().getMessage());\n                            } catch (Throwable t) {\n                                error[0] = t;\n                            }\n\n                            return null;\n                        }\n                    })\n            .when(rich)\n            .onError(any(Throwable.class));\n\n    ch.pipeline().fireExceptionCaught(new IOException(\"Connection reset by peer\"));\n\n    assertNull(error[0]);\n}", "summary_tokens": ["verifies", "that", "connection", "reset", "by", "peer", "exceptions", "are", "special", "cased", "and", "are", "reported", "as", "an", "instance", "of", "remote", "transport", "exception"], "project": "flink"}
{"id": 7818, "code": "public void testApplyWithPreReducerEventTime() throws Exception {\n    StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n\n    DataStream<Tuple2<String, Integer>> source =\n            env.fromElements(Tuple2.of(\"hello\", 1), Tuple2.of(\"hello\", 2));\n\n    DummyReducer reducer = new DummyReducer();\n\n    DataStream<Tuple3<String, String, Integer>> window =\n            source.keyBy(new TupleKeySelector())\n                    .window(TumblingEventTimeWindows.of(Time.of(1, TimeUnit.SECONDS)))\n                    .apply(\n                            reducer,\n                            new WindowFunction<\n                                    Tuple2<String, Integer>,\n                                    Tuple3<String, String, Integer>,\n                                    String,\n                                    TimeWindow>() {\n                                private static final long serialVersionUID = 1L;\n\n                                @Override\n                                public void apply(\n                                        String key,\n                                        TimeWindow window,\n                                        Iterable<Tuple2<String, Integer>> values,\n                                        Collector<Tuple3<String, String, Integer>> out)\n                                        throws Exception {\n                                    for (Tuple2<String, Integer> in : values) {\n                                        out.collect(new Tuple3<>(in.f0, in.f0, in.f1));\n                                    }\n                                }\n                            });\n\n    OneInputTransformation<Tuple2<String, Integer>, Tuple3<String, String, Integer>> transform =\n            (OneInputTransformation<Tuple2<String, Integer>, Tuple3<String, String, Integer>>)\n                    window.getTransformation();\n    OneInputStreamOperator<Tuple2<String, Integer>, Tuple3<String, String, Integer>> operator =\n            transform.getOperator();\n    Assert.assertTrue(operator instanceof WindowOperator);\n    WindowOperator<String, Tuple2<String, Integer>, ?, ?, ?> winOperator =\n            (WindowOperator<String, Tuple2<String, Integer>, ?, ?, ?>) operator;\n    Assert.assertTrue(winOperator.getTrigger() instanceof EventTimeTrigger);\n    Assert.assertTrue(winOperator.getWindowAssigner() instanceof TumblingEventTimeWindows);\n    Assert.assertTrue(winOperator.getStateDescriptor() instanceof ReducingStateDescriptor);\n\n    processElementAndEnsureOutput(\n            operator,\n            winOperator.getKeySelector(),\n            BasicTypeInfo.STRING_TYPE_INFO,\n            new Tuple2<>(\"hello\", 1));\n}", "summary_tokens": ["test", "for", "the", "deprecated"], "project": "flink"}
{"id": 1307, "code": "public FieldList toFieldList() {\n    int[] pos = toArray();\n    Arrays.sort(pos);\n    return new FieldList(pos);\n}", "summary_tokens": ["turns", "the", "field", "set", "into", "an", "ordered", "field", "list"], "project": "flink"}
{"id": 1938, "code": "public int getSize() {\n    return getByteArray().length;\n}", "summary_tokens": ["returns", "the", "size", "of", "the", "compressed", "serialized", "data"], "project": "flink"}
{"id": 2411, "code": "private static boolean revokeLeaseByFileSystem(final FileSystem fs, final Path path)\n        throws IOException {\n    if (fs instanceof ViewFileSystem) {\n        final ViewFileSystem vfs = (ViewFileSystem) fs;\n        final Path resolvePath = vfs.resolvePath(path);\n        final FileSystem resolveFs = resolvePath.getFileSystem(fs.getConf());\n        return waitUntilLeaseIsRevoked(resolveFs, resolvePath);\n    }\n    return waitUntilLeaseIsRevoked(fs, path);\n}", "summary_tokens": ["resolve", "the", "real", "path", "of", "file", "system", "if", "it", "is", "view", "file", "system", "and", "revoke", "the", "lease", "of", "the", "file", "we", "are", "resuming", "with", "different", "file", "system"], "project": "flink"}
{"id": 9433, "code": "protected void growAndRehash() throws EOFException {\n        \n    int required = 2 * bucketSegments.size();\n    if (required * (long) numBucketsPerSegment > Integer.MAX_VALUE) {\n        LOG.warn(\n                \"We can't handle more than Integer.MAX_VALUE buckets (eg. because hash functions return int)\");\n        throw new EOFException();\n    }\n\n    int numAllocatedSegments = required - memoryPool.freePages();\n    if (numAllocatedSegments > 0) {\n        LOG.warn(\n                \"BytesHashMap can't allocate {} pages, and now used {} pages\",\n                required,\n                reservedNumBuffers);\n        throw new EOFException();\n    }\n\n    List<MemorySegment> newBucketSegments = memoryPool.allocateSegments(required);\n    setBucketVariables(newBucketSegments);\n\n    long reHashStartTime = System.currentTimeMillis();\n    resetBucketSegments(newBucketSegments);\n        \n    for (MemorySegment memorySegment : bucketSegments) {\n        for (int j = 0; j < numBucketsPerSegment; j++) {\n            final int recordPointer = memorySegment.getInt(j * BUCKET_SIZE);\n            if (recordPointer != END_OF_LIST) {\n                final int hashCode1 =\n                        memorySegment.getInt(j * BUCKET_SIZE + ELEMENT_POINT_LENGTH);\n                int newPos = hashCode1 & numBucketsMask;\n                int bucketSegmentIndex = newPos >>> numBucketsPerSegmentBits;\n                int bucketOffset = (newPos & numBucketsPerSegmentMask) << BUCKET_SIZE_BITS;\n                int step = STEP_INCREMENT;\n                long hashCode2 = 0;\n                while (newBucketSegments.get(bucketSegmentIndex).getInt(bucketOffset)\n                        != END_OF_LIST) {\n                    if (step == 1) {\n                        hashCode2 = calcSecondHashCode(hashCode1);\n                    }\n                    newPos = (int) ((hashCode1 + step * hashCode2) & numBucketsMask);\n                        \n                    bucketSegmentIndex = newPos >>> numBucketsPerSegmentBits;\n                        \n                    bucketOffset = (newPos & numBucketsPerSegmentMask) << BUCKET_SIZE_BITS;\n                    step += STEP_INCREMENT;\n                }\n                newBucketSegments.get(bucketSegmentIndex).putInt(bucketOffset, recordPointer);\n                newBucketSegments\n                        .get(bucketSegmentIndex)\n                        .putInt(bucketOffset + ELEMENT_POINT_LENGTH, hashCode1);\n            }\n        }\n    }\n    LOG.info(\n            \"The rehash take {} ms for {} segments\",\n            (System.currentTimeMillis() - reHashStartTime),\n            required);\n    this.memoryPool.returnAll(this.bucketSegments);\n    this.bucketSegments = newBucketSegments;\n}", "summary_tokens": ["eofexception", "if", "the", "map", "can", "t", "allocate", "much", "more", "memory"], "project": "flink"}
{"id": 8997, "code": "private void partitionPrimaryKeyPredicates(\n        List<RexNode> predicates,\n        Set<Integer> primaryKeyIndices,\n        List<RexNode> primaryKeyPredicates,\n        List<RexNode> remainingPredicates) {\n    for (RexNode predicate : predicates) {\n        int[] inputRefs = extractRefInputFields(Collections.singletonList(predicate));\n        if (Arrays.stream(inputRefs).allMatch(primaryKeyIndices::contains)) {\n            primaryKeyPredicates.add(predicate);\n        } else {\n            remainingPredicates.add(predicate);\n        }\n    }\n}", "summary_tokens": ["separates", "the", "given", "predicates", "into", "filters", "which", "affect", "only", "the", "primary", "key", "and", "anything", "else"], "project": "flink"}
{"id": 2539, "code": "public void testSerializeGenericData_withValidParams_withCompression_succeeds() {\n    AWSSchemaRegistryConstants.COMPRESSION compressionType =\n            AWSSchemaRegistryConstants.COMPRESSION.ZLIB;\n    configs.put(AWSSchemaRegistryConstants.COMPRESSION_TYPE, compressionType.name());\n\n    GlueSchemaRegistryJsonSchemaCoder glueSchemaRegistryJsonSchemaCoder =\n            new GlueSchemaRegistryJsonSchemaCoder(\n                    testTopic, configs, mockSerializationFacade, null);\n\n    GlueSchemaRegistryJsonSerializationSchema glueSchemaRegistryJsonSerializationSchema =\n            new GlueSchemaRegistryJsonSerializationSchema<>(glueSchemaRegistryJsonSchemaCoder);\n\n    byte[] serializedData = glueSchemaRegistryJsonSerializationSchema.serialize(userSchema);\n    assertThat(serializedData, equalTo(serializedBytes));\n}", "summary_tokens": ["test", "whether", "serialize", "method", "for", "generic", "type", "json", "schema", "data", "when", "compression", "is", "enabled", "works"], "project": "flink"}
{"id": 1051, "code": "public RestartStrategies.RestartStrategyConfiguration getRestartStrategy() {\n    if (restartStrategyConfiguration\n            instanceof RestartStrategies.FallbackRestartStrategyConfiguration) {\n            \n        if (getNumberOfExecutionRetries() > 0 && getExecutionRetryDelay() >= 0) {\n            return RestartStrategies.fixedDelayRestart(\n                    getNumberOfExecutionRetries(), getExecutionRetryDelay());\n        } else if (getNumberOfExecutionRetries() == 0) {\n            return RestartStrategies.noRestart();\n        } else {\n            return restartStrategyConfiguration;\n        }\n    } else {\n        return restartStrategyConfiguration;\n    }\n}", "summary_tokens": ["returns", "the", "restart", "strategy", "which", "has", "been", "set", "for", "the", "current", "job"], "project": "flink"}
{"id": 441, "code": "public void close() throws IOException {\n    if (resultSet == null) {\n        return;\n    }\n    try {\n        resultSet.close();\n    } catch (SQLException se) {\n        LOG.info(\"Inputformat ResultSet couldn't be closed - \" + se.getMessage());\n    }\n}", "summary_tokens": ["closes", "all", "resources", "used"], "project": "flink"}
{"id": 3953, "code": "private Object readInboundBlocking(EmbeddedChannel channel)\n        throws InterruptedException, TimeoutException {\n    final long sleepMillis = 50L;\n\n    long sleptMillis = 0L;\n\n    Object msg = null;\n    while (sleptMillis < READ_TIMEOUT_MILLIS && (msg = channel.readOutbound()) == null) {\n\n        Thread.sleep(sleepMillis);\n        sleptMillis += sleepMillis;\n    }\n\n    if (msg == null) {\n        throw new TimeoutException();\n    } else {\n        return msg;\n    }\n}", "summary_tokens": ["queries", "the", "embedded", "channel", "for", "data"], "project": "flink"}
{"id": 4543, "code": "public int appendAndCommit(ByteBuffer source) {\n    int writtenBytes = append(source);\n    commit();\n    return writtenBytes;\n}", "summary_tokens": ["same", "as", "append", "byte", "buffer", "but", "additionally", "commit", "the", "appending"], "project": "flink"}
{"id": 1098, "code": "public void addDataSink(GenericDataSinkBase<?> sink) {\n    checkNotNull(sink, \"The data sink must not be null.\");\n\n    if (!this.sinks.contains(sink)) {\n        this.sinks.add(sink);\n    }\n}", "summary_tokens": ["adds", "a", "data", "sink", "to", "the", "set", "of", "sinks", "in", "this", "program"], "project": "flink"}
{"id": 3274, "code": "public void setResult(VV result) {\n    outVal.f1 = result;\n    out.collect(outVal);\n}", "summary_tokens": ["sets", "the", "result", "for", "the", "apply", "function"], "project": "flink"}
{"id": 7560, "code": "public void flushOutputs() throws IOException {\n    for (RecordWriterOutput<?> streamOutput : getStreamOutputs()) {\n        streamOutput.flush();\n    }\n}", "summary_tokens": ["this", "method", "should", "be", "called", "before", "finishing", "the", "record", "emission", "to", "make", "sure", "any", "data", "that", "is", "still", "buffered", "will", "be", "sent"], "project": "flink"}
{"id": 34, "code": "static void setJobManagerAddressInConfig(Configuration config, InetSocketAddress address) {\n    config.setString(JobManagerOptions.ADDRESS, address.getHostString());\n    config.setInteger(JobManagerOptions.PORT, address.getPort());\n    config.setString(RestOptions.ADDRESS, address.getHostString());\n    config.setInteger(RestOptions.PORT, address.getPort());\n}", "summary_tokens": ["writes", "the", "given", "job", "manager", "address", "to", "the", "associated", "configuration", "object"], "project": "flink"}
{"id": 488, "code": "private static void setField(Object object, String fieldName, Object value) {\n    setField(object, object.getClass(), fieldName, value);\n}", "summary_tokens": ["sets", "the", "field", "field", "name", "on", "the", "given", "object", "object", "to", "value", "using", "reflection"], "project": "flink"}
{"id": 1691, "code": "public static LineBreakElement linebreak() {\n    return new LineBreakElement();\n}", "summary_tokens": ["creates", "a", "line", "break", "in", "the", "description"], "project": "flink"}
{"id": 8495, "code": "public String[] getFieldNames() {\n    if (fieldNames.isPresent()) {\n        return fieldNames.get();\n    } else {\n        throw new IllegalStateException(\n                \"Table sink must be configured to retrieve field names.\");\n    }\n}", "summary_tokens": ["returns", "the", "field", "names", "of", "the", "table", "to", "emit"], "project": "flink"}
{"id": 3547, "code": "public void testMetricCleanup() {\n    TestingScheduledDropwizardReporter rep = new TestingScheduledDropwizardReporter();\n\n    MetricGroup mp = new UnregisteredMetricsGroup();\n\n    Counter c = new SimpleCounter();\n    Meter m = new TestMeter();\n    Histogram h = new TestHistogram();\n    Gauge<?> g = () -> null;\n\n    rep.notifyOfAddedMetric(c, \"counter\", mp);\n    assertEquals(1, rep.getCounters().size());\n    assertEquals(1, rep.registry.getCounters().size());\n\n    rep.notifyOfAddedMetric(m, \"meter\", mp);\n    assertEquals(1, rep.getMeters().size());\n    assertEquals(1, rep.registry.getMeters().size());\n\n    rep.notifyOfAddedMetric(h, \"histogram\", mp);\n    assertEquals(1, rep.getHistograms().size());\n    assertEquals(1, rep.registry.getHistograms().size());\n\n    rep.notifyOfAddedMetric(g, \"gauge\", mp);\n    assertEquals(1, rep.getGauges().size());\n    assertEquals(1, rep.registry.getGauges().size());\n\n    rep.notifyOfRemovedMetric(c, \"counter\", mp);\n    assertEquals(0, rep.getCounters().size());\n    assertEquals(0, rep.registry.getCounters().size());\n\n    rep.notifyOfRemovedMetric(m, \"meter\", mp);\n    assertEquals(0, rep.getMeters().size());\n    assertEquals(0, rep.registry.getMeters().size());\n\n    rep.notifyOfRemovedMetric(h, \"histogram\", mp);\n    assertEquals(0, rep.getHistograms().size());\n    assertEquals(0, rep.registry.getHistograms().size());\n\n    rep.notifyOfRemovedMetric(g, \"gauge\", mp);\n    assertEquals(0, rep.getGauges().size());\n    assertEquals(0, rep.registry.getGauges().size());\n}", "summary_tokens": ["this", "test", "verifies", "that", "metrics", "are", "properly", "added", "and", "removed", "to", "from", "the", "scheduled", "dropwizard", "reporter", "and", "the", "underlying", "dropwizard", "metric", "registry"], "project": "flink"}
{"id": 3635, "code": "public boolean haveAllOutputConnectionInterestingProperties() {\n    for (DagConnection conn : getOutgoingConnections()) {\n        if (conn.getInterestingProperties() == null) {\n            return false;\n        }\n    }\n    return true;\n}", "summary_tokens": ["checks", "if", "all", "outgoing", "connections", "have", "their", "interesting", "properties", "set", "from", "their", "target", "nodes"], "project": "flink"}
{"id": 9453, "code": "public void testComplex() {\n    final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();\n    Transformation<RowData> source1 = createSource(env, \"source1\");\n    Transformation<RowData> source2 = createSource(env, \"source2\");\n    Transformation<RowData> source3 = createSource(env, \"source3\");\n    Transformation<RowData> source4 = createSource(env, \"source4\");\n    Transformation<RowData> source5 = createSource(env, \"source5\");\n\n    OneInputTransformation<RowData, RowData> agg1 =\n            createOneInputTransform(\n                    source1,\n                    \"agg1\",\n                    InternalTypeInfo.of(RowType.of(DataTypes.STRING().getLogicalType())));\n    agg1.declareManagedMemoryUseCaseAtOperatorScope(ManagedMemoryUseCase.OPERATOR, 1);\n\n    OneInputTransformation<RowData, RowData> agg2 =\n            createOneInputTransform(\n                    source2,\n                    \"agg2\",\n                    InternalTypeInfo.of(RowType.of(DataTypes.STRING().getLogicalType())));\n    agg2.declareManagedMemoryUseCaseAtOperatorScope(ManagedMemoryUseCase.OPERATOR, 2);\n\n    TwoInputTransformation<RowData, RowData, RowData> join1 =\n            createTwoInputTransform(\n                    agg1,\n                    agg2,\n                    \"join1\",\n                    InternalTypeInfo.of(\n                            RowType.of(\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType())));\n    join1.declareManagedMemoryUseCaseAtOperatorScope(ManagedMemoryUseCase.OPERATOR, 3);\n\n    TwoInputTransformation<RowData, RowData, RowData> join2 =\n            createTwoInputTransform(\n                    join1,\n                    source3,\n                    \"join2\",\n                    InternalTypeInfo.of(\n                            RowType.of(\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType())));\n    join2.declareManagedMemoryUseCaseAtOperatorScope(ManagedMemoryUseCase.OPERATOR, 4);\n\n    TwoInputTransformation<RowData, RowData, RowData> join3 =\n            createTwoInputTransform(\n                    source4,\n                    source5,\n                    \"join3\",\n                    InternalTypeInfo.of(\n                            RowType.of(\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType())));\n    join3.declareManagedMemoryUseCaseAtOperatorScope(ManagedMemoryUseCase.OPERATOR, 5);\n\n    TwoInputTransformation<RowData, RowData, RowData> join4 =\n            createTwoInputTransform(\n                    join2,\n                    join3,\n                    \"join4\",\n                    InternalTypeInfo.of(\n                            RowType.of(\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType(),\n                                    DataTypes.STRING().getLogicalType())));\n    join4.declareManagedMemoryUseCaseAtOperatorScope(ManagedMemoryUseCase.OPERATOR, 6);\n\n    TableOperatorWrapperGenerator generator =\n            new TableOperatorWrapperGenerator(\n                    Arrays.asList(source1, source2, source3, source4, source5),\n                    join4,\n                    new int[] {2, 3, 4, 0, 1});\n    generator.generate();\n\n    TableOperatorWrapper<?> aggWrapper1 = createWrapper(agg1, 3, 1.0 / 21);\n    TableOperatorWrapper<?> aggWrapper2 = createWrapper(agg2, 4, 2.0 / 21);\n    TableOperatorWrapper<?> joinWrapper1 = createWrapper(join1, 2, 3.0 / 21);\n    joinWrapper1.addInput(aggWrapper1, 1);\n    joinWrapper1.addInput(aggWrapper2, 2);\n    TableOperatorWrapper<?> joinWrapper2 = createWrapper(join2, 1, 4.0 / 21);\n    joinWrapper2.addInput(joinWrapper1, 1);\n    TableOperatorWrapper<?> joinWrapper3 = createWrapper(join3, 5, 5.0 / 21);\n\n    TableOperatorWrapper<?> outputWrapper = createWrapper(join4, 0, 6.0 / 21);\n    outputWrapper.addInput(joinWrapper2, 1);\n    outputWrapper.addInput(joinWrapper3, 2);\n\n    assertEquals(\n            Arrays.asList(\n                    Pair.of(source1, new InputSpec(1, 2, aggWrapper1, 1)),\n                    Pair.of(source2, new InputSpec(2, 3, aggWrapper2, 1)),\n                    Pair.of(source3, new InputSpec(3, 4, joinWrapper2, 2)),\n                    Pair.of(source4, new InputSpec(4, 0, joinWrapper3, 1)),\n                    Pair.of(source5, new InputSpec(5, 1, joinWrapper3, 2))),\n            generator.getInputTransformAndInputSpecPairs());\n\n    assertEquals(outputWrapper, generator.getTailWrapper());\n    assertEquals(21, generator.getManagedMemoryWeight());\n    assertEquals(10, generator.getParallelism());\n    assertEquals(-1, generator.getMaxParallelism());\n    assertEquals(ResourceSpec.UNKNOWN, generator.getMinResources());\n    assertEquals(ResourceSpec.UNKNOWN, generator.getPreferredResources());\n}", "summary_tokens": ["test", "for", "complex", "sub", "graph", "in", "a", "multiple", "input", "node"], "project": "flink"}
{"id": 8009, "code": "private void validateTimeZone(String zone) {\n    final String zoneId = zone.toUpperCase();\n    if (zoneId.startsWith(\"UTC+\")\n            || zoneId.startsWith(\"UTC-\")\n            || SHORT_IDS.containsKey(zoneId)) {\n        throw new IllegalArgumentException(\n                String.format(\n                        \"The supported Zone ID is either a full name such as 'America/Los_Angeles',\"\n                                + \" or a custom timezone id such as 'GMT-08:00', but configured Zone ID is '%s'.\",\n                        zone));\n    }\n}", "summary_tokens": ["validates", "user", "configured", "time", "zone"], "project": "flink"}
{"id": 2167, "code": "private String getGenerateResourceDirectory() {\n    return System.getProperty(\"user.dir\")\n            + \"/src/test/resources/\"\n            + testSpecification.name\n            + \"-\"\n            + CURRENT_VERSION;\n}", "summary_tokens": ["paths", "to", "use", "during", "snapshot", "generation", "which", "should", "only", "use", "the", "current", "version"], "project": "flink"}
{"id": 8073, "code": "public ResolvedCatalogTable resolveCatalogTable(CatalogTable table) {\n    Preconditions.checkState(schemaResolver != null, \"Schema resolver is not initialized.\");\n    if (table instanceof ResolvedCatalogTable) {\n        return (ResolvedCatalogTable) table;\n    }\n\n    final ResolvedSchema resolvedSchema = table.getUnresolvedSchema().resolve(schemaResolver);\n\n    final List<String> physicalColumns =\n            resolvedSchema.getColumns().stream()\n                    .filter(Column::isPhysical)\n                    .map(Column::getName)\n                    .collect(Collectors.toList());\n    table.getPartitionKeys()\n            .forEach(\n                    partitionKey -> {\n                        if (!physicalColumns.contains(partitionKey)) {\n                            throw new ValidationException(\n                                    String.format(\n                                            \"Invalid partition key '%s'. A partition key must \"\n                                                    + \"reference a physical column in the schema. \"\n                                                    + \"Available columns are: %s\",\n                                            partitionKey, physicalColumns));\n                        }\n                    });\n\n    return new ResolvedCatalogTable(table, resolvedSchema);\n}", "summary_tokens": ["resolves", "a", "catalog", "table", "to", "a", "validated", "resolved", "catalog", "table"], "project": "flink"}
{"id": 463, "code": "private boolean changeFlag(RowKind rowKind) {\n    switch (rowKind) {\n        case INSERT:\n        case UPDATE_AFTER:\n            return true;\n        case DELETE:\n        case UPDATE_BEFORE:\n            return false;\n        default:\n            throw new UnsupportedOperationException(\n                    String.format(\n                            \"Unknown row kind, the supported row kinds is: INSERT, UPDATE_BEFORE, UPDATE_AFTER,\"\n                                    + \" DELETE, but get: %s.\",\n                            rowKind));\n    }\n}", "summary_tokens": ["returns", "true", "if", "the", "row", "kind", "is", "insert", "or", "update", "after", "returns", "false", "if", "the", "row", "kind", "is", "delete", "or", "update", "before"], "project": "flink"}
{"id": 4727, "code": "public static Broker<SuperstepKickoffLatch> instance() {\n    return INSTANCE;\n}", "summary_tokens": ["retrieve", "the", "singleton", "instance"], "project": "flink"}
{"id": 7973, "code": "public final boolean isBounded() {\n    return true;\n}", "summary_tokens": ["always", "returns", "true", "which", "indicates", "this", "is", "a", "bounded", "source"], "project": "flink"}
{"id": 3739, "code": "public void postVisit(PlanNode node) {\n    try {\n            \n\n            \n            \n            \n            \n            \n        if (node instanceof SourcePlanNode\n                || node instanceof NAryUnionPlanNode\n                || node instanceof SolutionSetPlanNode) {\n            return;\n        }\n\n            \n            \n        if (checkAndConfigurePersistentIntermediateResult(node)) {\n            return;\n        }\n\n            \n        if (node instanceof IterationPlanNode) {\n                \n            if (node.isOnDynamicPath()) {\n                throw new CompilerException(\n                        \"Nested Iterations are not possible at the moment!\");\n            }\n\n                \n                \n                \n            if (this.currentIteration != null) {\n                this.iterationStack.add(this.currentIteration);\n            }\n\n            this.currentIteration = (IterationPlanNode) node;\n            this.currentIteration.acceptForStepFunction(this);\n\n                \n            if (this.iterationStack.isEmpty()) {\n                this.currentIteration = null;\n            } else {\n                this.currentIteration =\n                        this.iterationStack.remove(this.iterationStack.size() - 1);\n            }\n\n                \n                \n                \n            if (node instanceof WorksetIterationPlanNode) {\n                    \n                WorksetIterationPlanNode wsNode = (WorksetIterationPlanNode) node;\n                JobVertex headVertex = this.iterations.get(wsNode).getHeadTask();\n                TaskConfig headConfig = new TaskConfig(headVertex.getConfiguration());\n                int inputIndex = headConfig.getDriverStrategy().getNumInputs();\n                headConfig.setIterationHeadSolutionSetInputIndex(inputIndex);\n                translateChannel(\n                        wsNode.getInitialSolutionSetInput(),\n                        inputIndex,\n                        headVertex,\n                        headConfig,\n                        false);\n            }\n\n            return;\n        }\n\n        final JobVertex targetVertex = this.vertices.get(node);\n\n            \n            \n            \n            \n            \n            \n            \n\n            \n        if (targetVertex == null) {\n                \n                \n                \n            final TaskInChain chainedTask;\n            if ((chainedTask = this.chainedTasks.get(node)) != null) {\n                    \n                final Iterator<Channel> inConns = node.getInputs().iterator();\n                if (!inConns.hasNext()) {\n                    throw new CompilerException(\"Bug: Found chained task with no input.\");\n                }\n                final Channel inConn = inConns.next();\n\n                if (inConns.hasNext()) {\n                    throw new CompilerException(\n                            \"Bug: Found a chained task with more than one input!\");\n                }\n                if (inConn.getLocalStrategy() != null\n                        && inConn.getLocalStrategy() != LocalStrategy.NONE) {\n                    throw new CompilerException(\n                            \"Bug: Found a chained task with an input local strategy.\");\n                }\n                if (inConn.getShipStrategy() != null\n                        && inConn.getShipStrategy() != ShipStrategyType.FORWARD) {\n                    throw new CompilerException(\n                            \"Bug: Found a chained task with an input ship strategy other than FORWARD.\");\n                }\n\n                JobVertex container = chainedTask.getContainingVertex();\n\n                if (container == null) {\n                    final PlanNode sourceNode = inConn.getSource();\n                    container = this.vertices.get(sourceNode);\n                    if (container == null) {\n                            \n                        container = this.chainedTasks.get(sourceNode).getContainingVertex();\n                        if (container == null) {\n                            throw new IllegalStateException(\n                                    \"Bug: Chained task predecessor has not been assigned its containing vertex.\");\n                        }\n                    } else {\n                            \n                            \n                        new TaskConfig(container.getConfiguration())\n                                .addOutputShipStrategy(ShipStrategyType.FORWARD);\n                    }\n                    chainedTask.setContainingVertex(container);\n                }\n\n                    \n                chainedTask.getTaskConfig().setInputSerializer(inConn.getSerializer(), 0);\n\n                    \n                String containerTaskName = container.getName();\n                if (containerTaskName.startsWith(\"CHAIN \")) {\n                    container.setName(containerTaskName + \" -> \" + chainedTask.getTaskName());\n                } else {\n                    container.setName(\n                            \"CHAIN \" + containerTaskName + \" -> \" + chainedTask.getTaskName());\n                }\n\n                    \n                container.setResources(\n                        container.getMinResources().merge(node.getMinResources()),\n                        container.getPreferredResources().merge(node.getPreferredResources()));\n\n                this.chainedTasksInSequence.add(chainedTask);\n                return;\n            } else if (node instanceof BulkPartialSolutionPlanNode\n                    || node instanceof WorksetPlanNode) {\n                    \n                    \n                return;\n            } else {\n                throw new CompilerException(\"Bug: Unrecognized merged task vertex.\");\n            }\n        }\n\n            \n\n        if (this.currentIteration != null) {\n            JobVertex head = this.iterations.get(this.currentIteration).getHeadTask();\n                \n                \n            if (node.isOnDynamicPath()) {\n                targetVertex.setStrictlyCoLocatedWith(head);\n            }\n        }\n\n            \n        final TaskConfig targetVertexConfig = new TaskConfig(targetVertex.getConfiguration());\n\n            \n            \n            \n        final Iterator<Channel> inConns;\n        if (node instanceof BulkPartialSolutionPlanNode) {\n            inConns =\n                    ((BulkPartialSolutionPlanNode) node)\n                            .getContainingIterationNode()\n                            .getInputs()\n                            .iterator();\n                \n                \n            targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(0);\n        } else if (node instanceof WorksetPlanNode) {\n            WorksetPlanNode wspn = (WorksetPlanNode) node;\n                \n            inConns =\n                    Collections.singleton(wspn.getContainingIterationNode().getInput2())\n                            .iterator();\n\n                \n                \n                \n            targetVertexConfig.setIterationHeadPartialSolutionOrWorksetInputIndex(0);\n            targetVertexConfig.setIterationHeadSolutionSetInputIndex(1);\n        } else {\n            inConns = node.getInputs().iterator();\n        }\n        if (!inConns.hasNext()) {\n            throw new CompilerException(\"Bug: Found a non-source task with no input.\");\n        }\n\n        int inputIndex = 0;\n        while (inConns.hasNext()) {\n            Channel input = inConns.next();\n            inputIndex +=\n                    translateChannel(\n                            input, inputIndex, targetVertex, targetVertexConfig, false);\n        }\n            \n        int broadcastInputIndex = 0;\n        for (NamedChannel broadcastInput : node.getBroadcastInputs()) {\n            int broadcastInputIndexDelta =\n                    translateChannel(\n                            broadcastInput,\n                            broadcastInputIndex,\n                            targetVertex,\n                            targetVertexConfig,\n                            true);\n            targetVertexConfig.setBroadcastInputName(\n                    broadcastInput.getName(), broadcastInputIndex);\n            targetVertexConfig.setBroadcastInputSerializer(\n                    broadcastInput.getSerializer(), broadcastInputIndex);\n            broadcastInputIndex += broadcastInputIndexDelta;\n        }\n    } catch (Exception e) {\n        throw new CompilerException(\n                \"An error occurred while translating the optimized plan to a JobGraph: \"\n                        + e.getMessage(),\n                e);\n    }\n}", "summary_tokens": ["this", "method", "implements", "the", "post", "visit", "during", "the", "depth", "first", "traversal"], "project": "flink"}
{"id": 7860, "code": "private void outputEdgeConfiguration(Configuration taskConfiguration) {\n    StreamConfig streamConfig = new StreamConfig(taskConfiguration);\n    streamConfig.setStreamOperatorFactory(new UnusedOperatorFactory());\n\n    StreamConfigChainer cfg =\n            new StreamConfigChainer(new OperatorID(42, 42), streamConfig, this, 1);\n        \n        \n    cfg.setBufferTimeout(1);\n    cfg.chain(\n            new OperatorID(44, 44),\n            new UnusedOperatorFactory(),\n            StringSerializer.INSTANCE,\n            StringSerializer.INSTANCE,\n            false);\n    cfg.finish();\n}", "summary_tokens": ["make", "sure", "that", "there", "is", "some", "output", "edge", "in", "the", "config", "so", "that", "some", "record", "writer", "is", "created"], "project": "flink"}
{"id": 7197, "code": "public void setExternalizedCheckpointCleanup(ExternalizedCheckpointCleanup cleanupMode) {\n    this.externalizedCheckpointCleanup = checkNotNull(cleanupMode);\n}", "summary_tokens": ["sets", "the", "mode", "for", "externalized", "checkpoint", "clean", "up"], "project": "flink"}
{"id": 8968, "code": "public static ObjectMapper createObjectMapper(SerdeContext serdeCtx) {\n    FlinkDeserializationContext ctx =\n            new FlinkDeserializationContext(\n                    new DefaultDeserializationContext.Impl(BeanDeserializerFactory.instance),\n                    serdeCtx);\n    ObjectMapper mapper =\n            new ObjectMapper(\n                    null, \n                    null, \n                    ctx);\n    mapper.setTypeFactory(\n            mapper.getTypeFactory().withClassLoader(JsonSerdeUtil.class.getClassLoader()));\n    mapper.configure(MapperFeature.USE_GETTERS_AS_SETTERS, false);\n    ctx.setObjectMapper(mapper);\n    return mapper;\n}", "summary_tokens": ["create", "an", "object", "mapper", "which", "deserialization", "context", "wraps", "a", "serde", "context"], "project": "flink"}
{"id": 6131, "code": "private RecordWriter createRecordWriter(ResultPartitionWriter writer) {\n    if (isBroadcastWriter) {\n        return new RecordWriterBuilder()\n                .setChannelSelector(new OutputEmitter(ShipStrategyType.BROADCAST, 0))\n                .build(writer);\n    } else {\n        return new RecordWriterBuilder().build(writer);\n    }\n}", "summary_tokens": ["creates", "the", "record", "writer", "instance", "based", "on", "whether", "it", "is", "a", "broadcast", "writer"], "project": "flink"}
{"id": 3249, "code": "public MaximumDegree<K, VV, EV> setBroadcastHighDegreeVertices(\n        boolean broadcastHighDegreeVertices) {\n    this.broadcastHighDegreeVertices.set(broadcastHighDegreeVertices);\n\n    return this;\n}", "summary_tokens": ["after", "filtering", "high", "degree", "vertices", "this", "algorithm", "must", "perform", "joins", "on", "the", "original", "graph", "s", "vertex", "set", "and", "on", "both", "the", "source", "and", "target", "ids", "of", "the", "edge", "set"], "project": "flink"}
{"id": 5018, "code": "final MemorySegment getNextBuffer() {\n        \n    int s = this.availableMemory.size();\n    if (s > 0) {\n        return this.availableMemory.remove(s - 1);\n    }\n\n        \n    if (this.writeBehindBuffersAvailable > 0) {\n            \n        MemorySegment toReturn;\n        try {\n            toReturn = this.writeBehindBuffers.take();\n        } catch (InterruptedException iex) {\n            throw new RuntimeException(\n                    \"Hybrid Hash Join was interrupted while taking a buffer.\");\n        }\n        this.writeBehindBuffersAvailable--;\n\n            \n        MemorySegment currBuff;\n        while (this.writeBehindBuffersAvailable > 0\n                && (currBuff = this.writeBehindBuffers.poll()) != null) {\n            this.availableMemory.add(currBuff);\n            this.writeBehindBuffersAvailable--;\n        }\n        return toReturn;\n    } else {\n            \n        return null;\n    }\n}", "summary_tokens": ["gets", "the", "next", "buffer", "to", "be", "used", "with", "the", "hash", "table", "either", "for", "an", "in", "memory", "partition", "or", "for", "the", "table", "buckets"], "project": "flink"}
{"id": 3702, "code": "public Channel getInput1() {\n    return this.input1;\n}", "summary_tokens": ["gets", "the", "first", "input", "channel", "to", "this", "node"], "project": "flink"}
{"id": 1973, "code": "public static void skipFully(final InputStream in, long len) throws IOException {\n    while (len > 0) {\n        final long ret = in.skip(len);\n        if (ret < 0) {\n            throw new IOException(\"Premeture EOF from inputStream\");\n        }\n        len -= ret;\n    }\n}", "summary_tokens": ["similar", "to", "read", "fully"], "project": "flink"}
{"id": 8574, "code": "public static ExplicitArgumentTypeStrategy explicit(DataType expectedDataType) {\n    return new ExplicitArgumentTypeStrategy(expectedDataType);\n}", "summary_tokens": ["strategy", "for", "an", "argument", "that", "corresponds", "to", "an", "explicitly", "defined", "type", "casting"], "project": "flink"}
{"id": 3781, "code": "public void testBranchingPlanNotReJoined() {\n    try {\n        ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();\n\n        DataSet<Integer> data =\n                env.readTextFile(\"/never/accessed\")\n                        .map(\n                                new MapFunction<String, Integer>() {\n                                    @Override\n                                    public Integer map(String value) {\n                                        return 0;\n                                    }\n                                });\n\n            \n        data.filter(\n                        new FilterFunction<Integer>() {\n                            @Override\n                            public boolean filter(Integer value) {\n                                return false;\n                            }\n                        })\n                .output(new DiscardingOutputFormat<Integer>());\n\n            \n        data.join(env.fromElements(1, 2, 3, 4))\n                .where(new IdentityKeyExtractor<Integer>())\n                .equalTo(new IdentityKeyExtractor<Integer>())\n                .output(new DiscardingOutputFormat<Tuple2<Integer, Integer>>());\n\n            \n        data.output(new DiscardingOutputFormat<Integer>());\n\n        List<DataSinkNode> sinks = convertPlan(env.createProgramPlan());\n\n            \n\n        DataSinkNode sinkAfterFilter = sinks.get(0);\n        DataSinkNode sinkAfterJoin = sinks.get(1);\n        DataSinkNode sinkDirect = sinks.get(2);\n\n        SingleInputNode filterNode = (SingleInputNode) sinkAfterFilter.getPredecessorNode();\n        SingleInputNode mapNode = (SingleInputNode) filterNode.getPredecessorNode();\n\n        TwoInputNode joinNode = (TwoInputNode) sinkAfterJoin.getPredecessorNode();\n        SingleInputNode joinInput = (SingleInputNode) joinNode.getSecondPredecessorNode();\n\n            \n\n        assertFalse(sinkAfterFilter.getInputConnection().isBreakingPipeline());\n        assertFalse(sinkAfterJoin.getInputConnection().isBreakingPipeline());\n        assertFalse(sinkDirect.getInputConnection().isBreakingPipeline());\n\n        assertFalse(filterNode.getIncomingConnection().isBreakingPipeline());\n        assertFalse(mapNode.getIncomingConnection().isBreakingPipeline());\n\n        assertFalse(joinNode.getFirstIncomingConnection().isBreakingPipeline());\n        assertFalse(joinNode.getSecondIncomingConnection().isBreakingPipeline());\n        assertFalse(joinInput.getIncomingConnection().isBreakingPipeline());\n\n            \n\n        assertEquals(\n                mapNode,\n                ((SingleInputNode) joinNode.getFirstPredecessorNode()).getPredecessorNode());\n        assertEquals(mapNode, sinkDirect.getPredecessorNode());\n    } catch (Exception e) {\n        e.printStackTrace();\n        fail(e.getMessage());\n    }\n}", "summary_tokens": ["tests", "that", "branching", "plans", "where", "the", "branches", "are", "not", "re", "joined", "do", "not", "place", "pipeline", "breakers"], "project": "flink"}
{"id": 9670, "code": "public void setCoordinates(double[] coordinates) {\n    this.coordinates = coordinates;\n}", "summary_tokens": ["sets", "the", "coordinate", "vector", "of", "a", "multi", "dimensional", "point"], "project": "flink"}
{"id": 536, "code": "public DubboBootstrap await() {\n        \n    if (!awaited.get()) {\n        if (!isStopped()) {\n            executeMutually(() -> {\n                while (!awaited.get()) {\n                    if (logger.isInfoEnabled()) {\n                        logger.info(NAME + \" awaiting ...\");\n                    }\n                    try {\n                        condition.await();\n                    } catch (InterruptedException e) {\n                        Thread.currentThread().interrupt();\n                    }\n                }\n            });\n        }\n    }\n    return this;\n}", "summary_tokens": ["block", "current", "thread", "to", "be", "await"], "project": "dubbo"}
{"id": 639, "code": "private void prepareDubboConfigBeans() {\n    logger.info(\"loading dubbo config beans ...\");\n\n        \n        \n    loadConfigBeansOfType(ApplicationConfig.class, configManager);\n    loadConfigBeansOfType(RegistryConfig.class, configManager);\n    loadConfigBeansOfType(ProtocolConfig.class, configManager);\n    loadConfigBeansOfType(MonitorConfig.class, configManager);\n    loadConfigBeansOfType(ConfigCenterBean.class, configManager);\n    loadConfigBeansOfType(MetadataReportConfig.class, configManager);\n    loadConfigBeansOfType(MetricsConfig.class, configManager);\n    loadConfigBeansOfType(SslConfig.class, configManager);\n\n        \n    loadConfigBeansOfType(ModuleConfig.class, moduleModel.getConfigManager());\n    loadConfigBeansOfType(ProviderConfig.class, moduleModel.getConfigManager());\n    loadConfigBeansOfType(ConsumerConfig.class, moduleModel.getConfigManager());\n\n        \n    List<ConfigCenterBean> configCenterBeans = configManager.loadConfigsOfTypeFromProps(ConfigCenterBean.class);\n    for (ConfigCenterBean configCenterBean : configCenterBeans) {\n        String beanName = configCenterBean.getId() != null ? configCenterBean.getId() : \"configCenterBean\";\n        beanFactory.initializeBean(configCenterBean, beanName);\n    }\n\n    logger.info(\"dubbo config beans are loaded.\");\n}", "summary_tokens": ["initializes", "there", "dubbo", "s", "config", "beans", "before", "bean", "autowiring"], "project": "dubbo"}
{"id": 222, "code": "public ExecutorService getMappingRefreshingExecutor() {\n    return mappingRefreshingExecutor;\n}", "summary_tokens": ["executor", "used", "to", "run", "async", "mapping", "tasks"], "project": "dubbo"}
{"id": 405, "code": "public static String[] parseServiceKey(String serviceKey) {\n    String[] arr = new String[3];\n    int i = serviceKey.indexOf('/');\n    if (i > 0) {\n        arr[0] = serviceKey.substring(0, i);\n        serviceKey = serviceKey.substring(i + 1);\n    }\n\n    int j = serviceKey.indexOf(':');\n    if (j > 0) {\n        arr[2] = serviceKey.substring(j + 1);\n        serviceKey = serviceKey.substring(0, j);\n    }\n    arr[1] = serviceKey;\n    return arr;\n}", "summary_tokens": ["service", "key", "group", "interface", "name", "version", "group", "interface", "name", "version"], "project": "dubbo"}
{"id": 360, "code": "private static Class<?>[] desc2classArray(ClassLoader cl, String desc) throws ClassNotFoundException {\n    if (desc.length() == 0) {\n        return EMPTY_CLASS_ARRAY;\n    }\n\n    List<Class<?>> cs = new ArrayList<Class<?>>();\n    Matcher m = DESC_PATTERN.matcher(desc);\n    while (m.find()) {\n        cs.add(desc2class(cl, m.group()));\n    }\n    return cs.toArray(EMPTY_CLASS_ARRAY);\n}", "summary_tokens": ["get", "class", "array", "instance"], "project": "dubbo"}
{"id": 172, "code": "public List<String> getListOfStrings(Map<String, ?> obj, String key) {\n    assert obj != null;\n    List<?> list = getList(obj, key);\n    if (list == null) {\n        return null;\n    }\n    return checkStringList(list);\n}", "summary_tokens": ["gets", "a", "list", "from", "an", "object", "for", "the", "given", "key", "and", "verifies", "all", "entries", "are", "strings"], "project": "dubbo"}
{"id": 1063, "code": "public void destroy() {\n    this.processIds.clear();\n    this.WATCHDOG.destroyProcess();\n    try {\n        DEFAULT_EXECUTOR_SERVICE.shutdownNow();\n    } catch (SecurityException | NullPointerException ex) {\n        return;\n    }\n    try {\n        DEFAULT_EXECUTOR_SERVICE.awaitTermination(5, TimeUnit.SECONDS);\n    } catch (InterruptedException ex) {\n        Thread.currentThread().interrupt();\n    }\n}", "summary_tokens": ["destroy", "all", "registered", "resources"], "project": "dubbo"}
{"id": 91, "code": "public CtClass build(ClassLoader classLoader) throws NotFoundException, CannotCompileException {\n    ClassPool pool = new ClassPool(true);\n    pool.insertClassPath(new LoaderClassPath(classLoader));\n    pool.insertClassPath(new DubboLoaderClassPath());\n        \n        \n    CtClass ctClass = pool.makeClass(className, pool.get(superClassName));\n\n        \n    imports.forEach(pool::importPackage);\n\n        \n    for (String iface : ifaces) {\n        ctClass.addInterface(pool.get(iface));\n    }\n\n        \n    for (String constructor : constructors) {\n        ctClass.addConstructor(CtNewConstructor.make(constructor, ctClass));\n    }\n\n        \n    for (String field : fields) {\n        ctClass.addField(CtField.make(field, ctClass));\n    }\n\n        \n    for (String method : methods) {\n        ctClass.addMethod(CtNewMethod.make(method, ctClass));\n    }\n\n    return ctClass;\n}", "summary_tokens": ["build", "ct", "class", "object"], "project": "dubbo"}
{"id": 325, "code": "static boolean isMetaMethod(Method method) {\n    String name = method.getName();\n    if (!(name.startsWith(\"get\") || name.startsWith(\"is\"))) {\n        return false;\n    }\n    if (\"get\".equals(name)) {\n        return false;\n    }\n    if (\"getClass\".equals(name)) {\n        return false;\n    }\n    if (!Modifier.isPublic(method.getModifiers())) {\n        return false;\n    }\n    if (method.getParameterTypes().length != 0) {\n        return false;\n    }\n    if (!ClassUtils.isPrimitive(method.getReturnType())) {\n        return false;\n    }\n    return true;\n}", "summary_tokens": ["return", "true", "if", "this", "method", "is", "a", "meta", "method"], "project": "dubbo"}
{"id": 675, "code": "public void addListener(String key, String group, ConfigurationListener listener) {\n    ApolloListener apolloListener = listeners.computeIfAbsent(group + key, k -> createTargetListener(key, group));\n    apolloListener.addListener(listener);\n    dubboConfig.addChangeListener(apolloListener, Collections.singleton(key));\n}", "summary_tokens": ["since", "all", "governance", "rules", "will", "lay", "under", "dubbo", "group", "this", "method", "now", "always", "uses", "the", "default", "dubbo", "config", "and", "ignores", "the", "group", "parameter"], "project": "dubbo"}
{"id": 875, "code": "public static Object getRequestWithoutData(Object message) {\n    if (logger.isDebugEnabled()) {\n        return message;\n    }\n    if (message instanceof Request) {\n        Request request = (Request) message;\n        request.setData(null);\n        return request;\n    } else if (message instanceof Response) {\n        Response response = (Response) message;\n        response.setResult(null);\n        return response;\n    }\n    return message;\n}", "summary_tokens": ["only", "log", "body", "in", "debugger", "mode", "for", "size", "security", "consideration"], "project": "dubbo"}
{"id": 342, "code": "public static boolean isValidAddress(String address) {\n    return ADDRESS_PATTERN.matcher(address).matches();\n}", "summary_tokens": ["tells", "whether", "the", "address", "to", "test", "is", "an", "invalid", "address"], "project": "dubbo"}
{"id": 46, "code": "public void tagRouterRuleParseTest() {\n    String tagRouterRuleConfig = \"---\\n\" +\n        \"force: false\\n\" +\n        \"runtime: true\\n\" +\n        \"enabled: false\\n\" +\n        \"priority: 1\\n\" +\n        \"key: demo-provider\\n\" +\n        \"tags:\\n\" +\n        \"  - name: tag1\\n\" +\n        \"    addresses: null\\n\" +\n        \"  - name: tag2\\n\" +\n        \"    addresses: [\\\"30.5.120.37:20880\\\"]\\n\" +\n        \"  - name: tag3\\n\" +\n        \"    addresses: []\\n\" +\n        \"  - name: tag4\\n\" +\n        \"    addresses: ~\\n\" +\n        \"...\";\n\n    TagRouterRule tagRouterRule = TagRuleParser.parse(tagRouterRuleConfig);\n\n        \n    assert tagRouterRule.getKey().equals(\"demo-provider\");\n    assert tagRouterRule.getPriority() == 1;\n    assert tagRouterRule.getTagNames().contains(\"tag1\");\n    assert tagRouterRule.getTagNames().contains(\"tag2\");\n    assert tagRouterRule.getTagNames().contains(\"tag3\");\n    assert tagRouterRule.getTagNames().contains(\"tag4\");\n        \n    assert tagRouterRule.getAddresses().contains(\"30.5.120.37:20880\");\n    assert tagRouterRule.getTagnameToAddresses().get(\"tag1\") == null;\n    assert tagRouterRule.getTagnameToAddresses().get(\"tag2\").size() == 1;\n    assert tagRouterRule.getTagnameToAddresses().get(\"tag3\") == null;\n    assert tagRouterRule.getTagnameToAddresses().get(\"tag4\") == null;\n    assert tagRouterRule.getAddresses().size() == 1;\n}", "summary_tokens": ["tag", "router", "rule", "parse", "test", "when", "the", "tags", "addresses", "is", "null"], "project": "dubbo"}
{"id": 748, "code": "private void collect(Invoker<?> invoker, Invocation invocation, Result result, String remoteHost, long start, boolean error) {\n    try {\n        Object monitorUrl;\n        monitorUrl = invoker.getUrl().getAttribute(MONITOR_KEY);\n        if (monitorUrl instanceof URL) {\n            Monitor monitor = monitorFactory.getMonitor((URL) monitorUrl);\n            if (monitor == null) {\n                return;\n            }\n            URL statisticsUrl = createStatisticsUrl(invoker, invocation, result, remoteHost, start, error);\n            monitor.collect(statisticsUrl.toSerializableURL());\n        }\n    } catch (Throwable t) {\n        logger.warn(\"Failed to monitor count service \" + invoker.getUrl() + \", cause: \" + t.getMessage(), t);\n    }\n}", "summary_tokens": ["the", "collector", "logic", "it", "will", "be", "handled", "by", "the", "default", "monitor"], "project": "dubbo"}
{"id": 142, "code": "default Class<S> getSourceType() {\n    return findActualTypeArgument(getClass(), Converter.class, 0);\n}", "summary_tokens": ["get", "the", "source", "type"], "project": "dubbo"}
{"id": 489, "code": "public MethodDescriptor getMethod(String methodName, Class<?>[] paramTypes) {\n    List<MethodDescriptor> methodModels = methods.get(methodName);\n    if (CollectionUtils.isNotEmpty(methodModels)) {\n        for (MethodDescriptor descriptor : methodModels) {\n            if (Arrays.equals(paramTypes, descriptor.getParameterClasses())) {\n                return descriptor;\n            }\n        }\n    }\n    return null;\n}", "summary_tokens": ["does", "not", "use", "optional", "as", "return", "type", "to", "avoid", "potential", "performance", "decrease"], "project": "dubbo"}
{"id": 323, "code": "static boolean isSetter(Method method) {\n    return method.getName().startsWith(\"set\")\n            && !\"set\".equals(method.getName())\n            && Modifier.isPublic(method.getModifiers())\n            && method.getParameterCount() == 1\n            && ClassUtils.isPrimitive(method.getParameterTypes()[0]);\n}", "summary_tokens": ["return", "true", "if", "the", "provided", "method", "is", "a", "set", "method"], "project": "dubbo"}
{"id": 634, "code": "private void processAnnotatedBeanDefinition(String refServiceBeanName, AnnotatedBeanDefinition refServiceBeanDefinition, Map<String, Object> attributes) {\n\n    Map<String, Object> serviceAnnotationAttributes = new LinkedHashMap<>(attributes);\n\n        \n    String returnTypeName = SpringCompatUtils.getFactoryMethodReturnType(refServiceBeanDefinition);\n    Class<?> beanClass = resolveClassName(returnTypeName, classLoader);\n\n    String serviceInterface = resolveInterfaceName(serviceAnnotationAttributes, beanClass);\n\n        \n    String serviceBeanName = generateServiceBeanName(serviceAnnotationAttributes, serviceInterface);\n\n    AbstractBeanDefinition serviceBeanDefinition = buildServiceBeanDefinition(serviceAnnotationAttributes, serviceInterface, refServiceBeanName);\n\n        \n    serviceBeanDefinition.getPropertyValues().add(Constants.ID, serviceBeanName);\n\n    registerServiceBeanDefinition(serviceBeanName, serviceBeanDefinition, serviceInterface);\n}", "summary_tokens": ["process", "at", "java", "config", "method", "pre", "class", "code", "0", "configuration", "public", "class", "provider", "config"], "project": "dubbo"}
{"id": 940, "code": "public long getSucceededMaxElapsed() {\n    return succeededMaxElapsed.get();\n}", "summary_tokens": ["get", "succeeded", "max", "elapsed"], "project": "dubbo"}
{"id": 471, "code": "public ApplicationModel defaultApplication() {\n    ApplicationModel appModel = this.defaultAppModel;\n    if (appModel == null) {\n            \n        checkDestroyed();\n        resetDefaultAppModel();\n        if ((appModel = this.defaultAppModel) == null) {\n            synchronized (instLock) {\n                if (this.defaultAppModel == null) {\n                    this.defaultAppModel = newApplication();\n                }\n                appModel = this.defaultAppModel;\n            }\n        }\n    }\n    Assert.notNull(appModel, \"Default ApplicationModel is null\");\n    return appModel;\n}", "summary_tokens": ["get", "or", "create", "default", "application", "model"], "project": "dubbo"}
{"id": 1002, "code": "private void processBody() {\n        \n        \n        \n    byte[] stream = compressedFlag ? getCompressedBody() : getUncompressedBody();\n\n    listener.onRawMessage(stream);\n\n        \n    state = GrpcDecodeState.HEADER;\n    requiredLength = HEADER_LENGTH;\n}", "summary_tokens": ["processes", "the", "grpc", "message", "body", "which", "depending", "on", "frame", "header", "flags", "may", "be", "compressed"], "project": "dubbo"}
{"id": 374, "code": "public static String removeEnd(final String str, final String remove) {\n    if (isAnyEmpty(str, remove)) {\n        return str;\n    }\n    if (str.endsWith(remove)) {\n        return str.substring(0, str.length() - remove.length());\n    }\n    return str;\n}", "summary_tokens": ["p", "removes", "a", "substring", "only", "if", "it", "is", "at", "the", "end", "of", "a", "source", "string", "otherwise", "returns", "the", "source", "string"], "project": "dubbo"}
{"id": 583, "code": "private void afterInvoke() {\n        \n    Assertions.assertTrue(filter.hasCalled());\n        \n    Assertions.assertFalse(filter.hasError());\n        \n    Assertions.assertEquals(\"Hello Dubbo in multiple registry center\",\n        filter.getResponse());\n}", "summary_tokens": ["there", "are", "some", "checkpoints", "need", "to", "check", "after", "invoked", "as", "follow", "ul", "li", "the", "multiple", "registry", "center", "injvm", "filter", "has", "called", "or", "not", "li", "li", "the", "multiple", "registry", "center", "injvm", "filter", "exists", "error", "after", "invoked", "li", "li", "the", "multiple", "registry", "center", "injvm", "filter", "s", "response", "is", "right", "or", "not", "li", "ul"], "project": "dubbo"}
{"id": 1007, "code": "public static <TRequest, TResponse, TInvoker> Flux<TResponse> manyToMany(Invoker<TInvoker> invoker,\n                                                                         Flux<TRequest> requestFlux,\n                                                                         StubMethodDescriptor methodDescriptor) {\n    try {\n        ClientTripleReactorSubscriber<TRequest> clientSubscriber = requestFlux.subscribeWith(new ClientTripleReactorSubscriber<>());\n        ClientTripleReactorPublisher<TResponse> clientPublisher = new ClientTripleReactorPublisher<>(\n            s -> clientSubscriber.subscribe((CallStreamObserver<TRequest>) s),\n            clientSubscriber::cancel);\n        return Flux.from(clientPublisher).doOnSubscribe(dummy ->\n            StubInvocationUtil.biOrClientStreamCall(invoker, methodDescriptor, clientPublisher));\n    } catch (Throwable throwable) {\n        return Flux.error(throwable);\n    }\n}", "summary_tokens": ["implements", "a", "stream", "stream", "call", "as", "flux", "flux"], "project": "dubbo"}
{"id": 570, "code": "private void beforeExport() {\n        \n    serviceListener = (MultipleRegistryCenterExportMetadataServiceListener) ExtensionLoader.getExtensionLoader(ServiceListener.class).getExtension(SPI_NAME);\n    exporterListener = (MultipleRegistryCenterExportMetadataExporterListener) ExtensionLoader.getExtensionLoader(ExporterListener.class).getExtension(SPI_NAME);\n\n        \n        \n    Assertions.assertTrue(serviceListener.getExportedServices().isEmpty());\n        \n    Assertions.assertTrue(exporterListener.getExportedExporters().isEmpty());\n        \n    Assertions.assertFalse(serviceConfig.isExported());\n}", "summary_tokens": ["define", "service", "listener", "exporter", "listener", "and", "filter", "for", "helping", "check"], "project": "dubbo"}
{"id": 361, "code": "public static Method findMethodByMethodSignature(Class<?> clazz, String methodName, String[] parameterTypes)\n        throws NoSuchMethodException, ClassNotFoundException {\n    String signature = clazz.getName() + \".\" + methodName;\n    if (parameterTypes != null && parameterTypes.length > 0) {\n        signature += StringUtils.join(parameterTypes);\n    }\n    Method method;\n    if (parameterTypes == null) {\n        List<Method> finded = new ArrayList<Method>();\n        for (Method m : clazz.getMethods()) {\n            if (m.getName().equals(methodName)) {\n                finded.add(m);\n            }\n        }\n        if (finded.isEmpty()) {\n            throw new NoSuchMethodException(\"No such method \" + methodName + \" in class \" + clazz);\n        }\n        if (finded.size() > 1) {\n            String msg = String.format(\"Not unique method for method name(%s) in class(%s), find %d methods.\",\n                    methodName, clazz.getName(), finded.size());\n            throw new IllegalStateException(msg);\n        }\n        method = finded.get(0);\n    } else {\n        Class<?>[] types = new Class<?>[parameterTypes.length];\n        for (int i = 0; i < parameterTypes.length; i++) {\n            types[i] = ReflectUtils.name2class(parameterTypes[i]);\n        }\n        method = clazz.getMethod(methodName, types);\n\n    }\n    return method;\n}", "summary_tokens": ["find", "method", "from", "method", "signature"], "project": "dubbo"}
{"id": 10, "code": "public void refreshInvoker() {\n    if (invokersInitialized) {\n        refreshInvokerInternal();\n    }\n}", "summary_tokens": ["refresh", "invokers", "from", "total", "invokers", "0"], "project": "dubbo"}
{"id": 589, "code": "public ServiceDiscoveryRegistryStorage getStorage() {\n    return storage;\n}", "summary_tokens": ["return", "the", "stored", "service", "discovery", "registry", "info", "wrapper", "instances"], "project": "dubbo"}
{"id": 822, "code": "public void testReferWithGroup() {\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"application1\");\n\n    ConfigManager configManager = mock(ConfigManager.class);\n    when(configManager.getApplicationOrElseThrow()).thenReturn(applicationConfig);\n\n    CompositeConfiguration compositeConfiguration = mock(CompositeConfiguration.class);\n    when(compositeConfiguration.convert(Boolean.class, ENABLE_CONFIGURATION_LISTEN, true))\n        .thenReturn(true);\n\n    Map<String, String> parameters = new HashMap<>();\n    parameters.put(INTERFACE_KEY, DemoService.class.getName());\n    parameters.put(\"registry\", \"zookeeper\");\n    parameters.put(\"register\", \"false\");\n\n    Map<String, Object> attributes = new HashMap<>();\n    ServiceConfigURL serviceConfigURL = new ServiceConfigURL(\n        \"registry\",\n        \"127.0.0.1\",\n        2181,\n        \"org.apache.dubbo.registry.RegistryService\",\n        parameters);\n    Map<String, String> refer = new HashMap<>();\n    refer.put(GROUP_KEY, \"group1,group2\");\n    attributes.put(REFER_KEY, refer);\n    URL url = serviceConfigURL.addAttributes(attributes);\n\n    RegistryFactory registryFactory = mock(RegistryFactory.class);\n    Registry registry = mock(Registry.class);\n\n    MigrationRuleListener migrationRuleListener = mock(MigrationRuleListener.class);\n    List<RegistryProtocolListener> registryProtocolListeners = new ArrayList<>();\n    registryProtocolListeners.add(migrationRuleListener);\n\n    RegistryProtocol registryProtocol = new RegistryProtocol();\n    ModuleModel moduleModel = Mockito.spy(ApplicationModel.defaultModel().getDefaultModule());\n    moduleModel.getApplicationModel().getApplicationConfigManager().setApplication(new ApplicationConfig(\"application1\"));\n    ExtensionLoader extensionLoaderMock = mock(ExtensionLoader.class);\n    Mockito.when(moduleModel.getExtensionLoader(RegistryProtocolListener.class)).thenReturn(extensionLoaderMock);\n    Mockito.when(extensionLoaderMock.getActivateExtension(url, REGISTRY_PROTOCOL_LISTENER_KEY))\n        .thenReturn(registryProtocolListeners);\n    Mockito.when(moduleModel.getExtensionLoader(RegistryFactory.class)).thenReturn(extensionLoaderMock);\n    Mockito.when(extensionLoaderMock.getAdaptiveExtension()).thenReturn(registryFactory);\n    url = url.setScopeModel(moduleModel);\n\n    when(registryFactory.getRegistry(registryProtocol.getRegistryUrl(url))).thenReturn(registry);\n\n    Invoker<?> invoker = registryProtocol.refer(DemoService.class, url);\n\n    Assertions.assertTrue(invoker instanceof MigrationInvoker);\n\n    Assertions.assertTrue(((MigrationInvoker<?>) invoker).getCluster() instanceof MockClusterWrapper);\n\n    Assertions.assertTrue(\n        ((MockClusterWrapper) ((MigrationInvoker<?>) invoker).getCluster()).getCluster() instanceof MergeableCluster);\n\n}", "summary_tokens": ["verify", "that", "if", "multiple", "groups", "are", "configured", "the", "service", "reference", "of", "the", "registration", "center"], "project": "dubbo"}
{"id": 896, "code": "CuratorFramework getClient() {\n    return client;\n}", "summary_tokens": ["just", "for", "unit", "test"], "project": "dubbo"}
{"id": 1070, "code": "private boolean check(String segment, int clientPort) {\n    return (\"[::]:\" + clientPort).equalsIgnoreCase(segment)\n        || (\"0.0.0.0:\" + clientPort).equalsIgnoreCase(segment)\n        || (\"127.0.0.1:\" + clientPort).equalsIgnoreCase(segment);\n}", "summary_tokens": ["checks", "if", "segment", "is", "valid", "ip", "and", "port", "pair"], "project": "dubbo"}
{"id": 391, "code": "public static Map<String, String> parseQueryString(String qs) {\n    if (isEmpty(qs)) {\n        return new HashMap<String, String>();\n    }\n    return parseKeyValuePair(qs, \"\\\\&\");\n}", "summary_tokens": ["parse", "query", "string", "to", "parameters"], "project": "dubbo"}
{"id": 801, "code": "public void reset() {\n    destroyed.set(false);\n    registries.clear();\n}", "summary_tokens": ["reset", "state", "of", "abstract", "registry", "factory"], "project": "dubbo"}
{"id": 218, "code": "public ExecutorService getSharedExecutor() {\n    return sharedExecutor;\n}", "summary_tokens": ["get", "the", "default", "shared", "thread", "pool"], "project": "dubbo"}
{"id": 671, "code": "public ApplicationConfig applicationConfig() {\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"dubbo-demo-application\");\n    return applicationConfig;\n}", "summary_tokens": ["current", "application", "configuration", "to", "replace", "xml", "config", "prev", "lt", "dubbo", "application", "name", "dubbo", "demo", "application", "gt", "prev"], "project": "dubbo"}
{"id": 755, "code": "public void testListClient() throws Exception {\n    ExchangeClient client1 = Exchangers.connect(\"dubbo://127.0.0.1:\" + availablePort + \"/demo\");\n    ExchangeClient client2 = Exchangers.connect(\"dubbo://127.0.0.1:\" + availablePort + \"/demo\");\n    Thread.sleep(100);\n    String result = port.execute(mockCommandContext, new String[]{\"-l\", availablePort + \"\"});\n    String client1Addr = client1.getLocalAddress().toString();\n    String client2Addr = client2.getLocalAddress().toString();\n    System.out.printf(\"Result: %s %n\", result);\n    System.out.printf(\"Client 1 Address %s %n\", client1Addr);\n    System.out.printf(\"Client 2 Address %s %n\", client2Addr);\n    assertTrue(result.contains(String.valueOf(client1.getLocalAddress().getPort())));\n    assertTrue(result.contains(String.valueOf(client2.getLocalAddress().getPort())));\n}", "summary_tokens": ["in", "nat", "network", "scenario", "server", "s", "channel"], "project": "dubbo"}
{"id": 154, "code": "private String generateExtNameAssignment(String[] value, boolean hasInvocation) {\n        \n    String getNameCode = null;\n    for (int i = value.length - 1; i >= 0; --i) {\n        if (i == value.length - 1) {\n            if (null != defaultExtName) {\n                if (!\"protocol\".equals(value[i])) {\n                    if (hasInvocation) {\n                        getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n                    } else {\n                        getNameCode = String.format(\"url.getParameter(\\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n                    }\n                } else {\n                    getNameCode = String.format(\"( url.getProtocol() == null ? \\\"%s\\\" : url.getProtocol() )\", defaultExtName);\n                }\n            } else {\n                if (!\"protocol\".equals(value[i])) {\n                    if (hasInvocation) {\n                        getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n                    } else {\n                        getNameCode = String.format(\"url.getParameter(\\\"%s\\\")\", value[i]);\n                    }\n                } else {\n                    getNameCode = \"url.getProtocol()\";\n                }\n            }\n        } else {\n            if (!\"protocol\".equals(value[i])) {\n                if (hasInvocation) {\n                    getNameCode = String.format(\"url.getMethodParameter(methodName, \\\"%s\\\", \\\"%s\\\")\", value[i], defaultExtName);\n                } else {\n                    getNameCode = String.format(\"url.getParameter(\\\"%s\\\", %s)\", value[i], getNameCode);\n                }\n            } else {\n                getNameCode = String.format(\"url.getProtocol() == null ? (%s) : url.getProtocol()\", getNameCode);\n            }\n        }\n    }\n\n    return String.format(CODE_EXT_NAME_ASSIGNMENT, getNameCode);\n}", "summary_tokens": ["generate", "ext", "name", "assignment", "code"], "project": "dubbo"}
{"id": 956, "code": "public static void attachInvocationIdIfAsync(URL url, Invocation inv) {\n    if (isAttachInvocationId(url, inv) && getInvocationId(inv) == null && inv instanceof RpcInvocation) {\n        inv.setAttachment(ID_KEY, String.valueOf(INVOKE_ID.getAndIncrement()));\n    }\n}", "summary_tokens": ["idempotent", "operation", "invocation", "id", "will", "be", "added", "in", "async", "operation", "by", "default"], "project": "dubbo"}
{"id": 1066, "code": "private boolean checkFile(Path filePath) {\n    return Files.exists(filePath) && filePath.toFile().isFile();\n}", "summary_tokens": ["returns", "true", "if", "the", "file", "exists", "with", "the", "given", "file", "path", "otherwise", "false"], "project": "dubbo"}
{"id": 460, "code": "public static ConfigManager getConfigManager() {\n    return defaultModel().getApplicationConfigManager();\n}", "summary_tokens": ["replace", "to", "application", "model", "get", "application", "config", "manager"], "project": "dubbo"}
{"id": 661, "code": "public void setAutoStartup(boolean autoStartup) {\n    this.autoStartup = autoStartup;\n}", "summary_tokens": ["specify", "whether", "to", "start", "automatically"], "project": "dubbo"}
{"id": 100, "code": "public static int getServerShutdownTimeout(ScopeModel scopeModel) {\n    int timeout = DEFAULT_SERVER_SHUTDOWN_TIMEOUT;\n    Configuration configuration = getGlobalConfiguration(scopeModel);\n    String value = StringUtils.trim(configuration.getString(SHUTDOWN_WAIT_KEY));\n\n    if (StringUtils.isNotEmpty(value)) {\n        try {\n            timeout = Integer.parseInt(value);\n        } catch (Exception e) {\n                \n        }\n    } else {\n        value = StringUtils.trim(configuration.getString(SHUTDOWN_WAIT_SECONDS_KEY));\n        if (StringUtils.isNotEmpty(value)) {\n            try {\n                timeout = Integer.parseInt(value) * 1000;\n            } catch (Exception e) {\n                    \n            }\n        }\n    }\n    return timeout;\n}", "summary_tokens": ["server", "shutdown", "wait", "timeout", "mills"], "project": "dubbo"}
{"id": 883, "code": "public void interruptSend() throws Exception {\n    final DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\");\n    System.out.println(\"before a future is create , time is : \" + LocalDateTime.now().format(formatter));\n        \n    Channel channel = new MockedChannel();\n    int channelId = 10;\n    Request request = new Request(channelId);\n    ExecutorService sharedExecutor = ExtensionLoader.getExtensionLoader(ExecutorRepository.class)\n            .getDefaultExtension().createExecutorIfAbsent(URL.valueOf(\"dubbo://127.0.0.1:23456\"));\n    ThreadlessExecutor executor = new ThreadlessExecutor();\n    DefaultFuture f = DefaultFuture.newFuture(channel, request, 1000, executor);\n        \n    DefaultFuture.sent(channel, request);\n        \n    try {\n        new InterruptThread(Thread.currentThread()).start();\n        executor.waitAndDrain();\n        f.get();\n    } catch (Exception e) {\n        Assertions.assertTrue(e instanceof InterruptedException, \"catch exception is not interrupted exception!\");\n        System.out.println(e.getMessage());\n    }\n        \n    Thread.sleep(1500);\n    System.out.println(\"after a future is timeout , time is : \" + LocalDateTime.now().format(formatter));\n\n    DefaultFuture future = DefaultFuture.getFuture(channelId);\n        \n    Assertions.assertNull(future);\n}", "summary_tokens": ["for", "example", "it", "will", "print", "like", "this", "before", "a", "future", "is", "created", "time", "is", "0", "0", "0", "0", "0", "0", "null", "after", "a", "future", "is", "timeout", "time", "is", "0", "0", "0", "0", "0", "0"], "project": "dubbo"}
{"id": 841, "code": "void testRegister() {\n    Set<URL> registered;\n        \n    registered = registry.getRegistered();\n    for (URL url : registered) {\n        registry.unregister(url);\n    }\n\n    for (int i = 0; i < 2; i++) {\n        registry.register(serviceUrl);\n        registered = registry.getRegistered();\n        assertTrue(registered.contains(serviceUrl));\n    }\n        \n    registered = registry.getRegistered();\n    assertEquals(1, registered.size());\n}", "summary_tokens": ["test", "method", "for", "org"], "project": "dubbo"}
{"id": 226, "code": "public long pendingTimeouts() {\n    return pendingTimeouts.get();\n}", "summary_tokens": ["returns", "the", "number", "of", "pending", "timeouts", "of", "this", "timer"], "project": "dubbo"}
{"id": 944, "code": "public void afterUnExport() {\n}", "summary_tokens": ["subclasses", "need", "to", "override", "this", "method", "to", "destroy", "resources"], "project": "dubbo"}
{"id": 424, "code": "protected void checkDefault() {\n    super.checkDefault();\n\n        \n        \n    if (isReturn() == null) {\n        setReturn(true);\n    }\n\n        \n    if (getSent() == null) {\n        setSent(true);\n    }\n}", "summary_tokens": ["set", "default", "field", "values", "of", "method", "config"], "project": "dubbo"}
{"id": 814, "code": "public String[] instanceParamsIncluded() {\n    return new String[0];\n}", "summary_tokens": ["not", "included", "in", "this", "test"], "project": "dubbo"}
{"id": 1034, "code": "public static void startup() throws Exception {\n    INSTANCE.startup();\n}", "summary_tokens": ["start", "the", "registry", "center"], "project": "dubbo"}
{"id": 571, "code": "private void afterExport() {\n        \n    Assertions.assertEquals(serviceListener.getExportedServices().size(), 1);\n        \n    Assertions.assertEquals(serviceListener.getExportedServices().get(0).getInterfaceClass(),\n        MetadataService.class);\n        \n    Assertions.assertTrue(serviceListener.getExportedServices().get(0).isExported());\n        \n        \n        \n        \n        \n        \n    Assertions.assertEquals(exporterListener.getExportedExporters().size(), 2);\n        \n    Exporter<?> injvmExporter = (Exporter<?>) exporterListener.getExportedExporters()\n        .stream()\n        .filter(\n            exporter -> PROTOCOL_NAME.equalsIgnoreCase(exporter.getInvoker().getUrl().getProtocol())\n        )\n        .findFirst()\n        .get();\n        \n    Exporter<?> metadataExporter = (Exporter<?>) exporterListener.getExportedExporters()\n        .stream()\n        .filter(\n            exporter -> !PROTOCOL_NAME.equalsIgnoreCase(exporter.getInvoker().getUrl().getProtocol())\n        )\n        .filter(\n            exporter -> exporter.getInvoker().getInterface().equals(MetadataService.class)\n        )\n        .findFirst()\n        .get();\n        \n    Assertions.assertNotNull(injvmExporter);\n        \n    Assertions.assertNotNull(metadataExporter);\n}", "summary_tokens": ["there", "are", "some", "checkpoints", "need", "to", "check", "after", "exported", "as", "follow", "ul", "li", "the", "metadata", "service", "is", "only", "one", "or", "not", "li", "li", "the", "exported", "service", "is", "metadata", "service", "or", "not", "li", "li", "the", "metadata", "service", "is", "exported", "or", "not", "li", "li", "the", "exported", "exporters", "are", "right", "or", "not", "li", "ul"], "project": "dubbo"}
{"id": 34, "code": "protected boolean supportContinueRoute() {\n    return false;\n}", "summary_tokens": ["whether", "current", "router", "s", "implementation", "support", "call", "abstract", "state", "router", "continue", "route", "bit", "list", "url", "invocation", "boolean", "holder", "by", "router", "itself"], "project": "dubbo"}
{"id": 24, "code": "public boolean matchArguments(Map.Entry<String, MatchPair> matchPair, Invocation invocation) {\n    try {\n            \n        String key = matchPair.getKey();\n        String[] expressArray = key.split(\"\\\\.\");\n        String argumentExpress = expressArray[0];\n        final Matcher matcher = ARGUMENTS_PATTERN.matcher(argumentExpress);\n        if (!matcher.find()) {\n            return false;\n        }\n\n            \n        int index = Integer.parseInt(matcher.group(1));\n        if (index < 0 || index > invocation.getArguments().length) {\n            return false;\n        }\n\n            \n        Object object = invocation.getArguments()[index];\n\n        if (matchPair.getValue().isMatch(String.valueOf(object), null)) {\n            return true;\n        }\n    } catch (Exception e) {\n        logger.warn(\"2-7\",\"condition state router arguments match failed\",\"\",\"Arguments match failed, matchPair[]\" + matchPair + \"] invocation[\" + invocation + \"]\",e);\n    }\n\n    return false;\n}", "summary_tokens": ["analysis", "the", "arguments", "in", "the", "rule"], "project": "dubbo"}
{"id": 782, "code": "public static String getMetadataStorageType(ServiceInstance serviceInstance) {\n    Map<String, String> metadata = serviceInstance.getMetadata();\n    return metadata.getOrDefault(METADATA_STORAGE_TYPE_PROPERTY_NAME, DEFAULT_METADATA_STORAGE_TYPE);\n}", "summary_tokens": ["get", "the", "metadata", "storage", "type", "specified", "by", "the", "peer", "instance"], "project": "dubbo"}
{"id": 69, "code": "public String getColonSeparatedKey() {\n    StringBuilder serviceNameBuilder = new StringBuilder();\n    serviceNameBuilder.append(this.getServiceInterface());\n    append(serviceNameBuilder, VERSION_KEY, false);\n    append(serviceNameBuilder, GROUP_KEY, false);\n    return serviceNameBuilder.toString();\n}", "summary_tokens": ["the", "format", "is", "interface", "version", "group"], "project": "dubbo"}
{"id": 244, "code": "public String getRawParam() {\n    if (StringUtils.isNotEmpty(rawParam)) {\n        return rawParam;\n    } else {\n            \n        return toString();\n    }\n}", "summary_tokens": ["get", "raw", "string", "like", "parameters"], "project": "dubbo"}
{"id": 475, "code": "public void registerConsumer(String serviceKey,\n                             ServiceDescriptor serviceDescriptor,\n                             ReferenceConfigBase<?> rc,\n                             Object proxy,\n                             ServiceMetadata serviceMetadata) {\n    ClassLoader classLoader = null;\n    if (rc != null) {\n        classLoader = rc.getInterfaceClassLoader();\n    }\n    ConsumerModel consumerModel = new ConsumerModel(serviceMetadata.getServiceKey(), proxy, serviceDescriptor,\n        serviceMetadata, null, classLoader);\n    this.registerConsumer(consumerModel);\n}", "summary_tokens": ["replaced", "to", "module", "service", "repository", "register", "consumer", "consumer", "model"], "project": "dubbo"}
{"id": 232, "code": "public String getMethodParameter(String method, String key) {\n    String strictResult = getMethodParameterStrict(method, key);\n    return StringUtils.isNotEmpty(strictResult) ? strictResult : getParameter(key);\n}", "summary_tokens": ["get", "method", "related", "parameter"], "project": "dubbo"}
{"id": 412, "code": "public void refresh() {\n    try {\n            \n        preProcessRefresh();\n\n        Environment environment = getScopeModel().getModelEnvironment();\n        List<Map<String, String>> configurationMaps = environment.getConfigurationMaps();\n\n            \n        String preferredPrefix = null;\n        List<String> prefixes = getPrefixes();\n        for (String prefix : prefixes) {\n            if (ConfigurationUtils.hasSubProperties(configurationMaps, prefix)) {\n                preferredPrefix = prefix;\n                break;\n            }\n        }\n        if (preferredPrefix == null) {\n            preferredPrefix = prefixes.get(0);\n        }\n            \n        Collection<Map<String, String>> instanceConfigMaps = environment.getConfigurationMaps(this, preferredPrefix);\n        Map<String, String> subProperties = ConfigurationUtils.getSubProperties(instanceConfigMaps, preferredPrefix);\n        InmemoryConfiguration subPropsConfiguration = new InmemoryConfiguration(subProperties);\n\n        if (logger.isDebugEnabled()) {\n            String idOrName = \"\";\n            if (StringUtils.hasText(this.getId())) {\n                idOrName = \"[id=\" + this.getId() + \"]\";\n            } else {\n                String name = ReflectUtils.getProperty(this, \"getName\");\n                if (StringUtils.hasText(name)) {\n                    idOrName = \"[name=\" + name + \"]\";\n                }\n            }\n            logger.debug(\"Refreshing \" + this.getClass().getSimpleName() + idOrName +\n                \" with prefix [\" + preferredPrefix +\n                \"], extracted props: \" + subProperties);\n        }\n\n        assignProperties(this, environment, subProperties, subPropsConfiguration);\n\n            \n        processExtraRefresh(preferredPrefix, subPropsConfiguration);\n\n    } catch (Exception e) {\n        logger.error(\"Failed to override field value of config bean: \" + this, e);\n        throw new IllegalStateException(\"Failed to override field value of config bean: \" + this, e);\n    }\n\n    postProcessRefresh();\n    refreshed.set(true);\n}", "summary_tokens": ["dubbo", "config", "property", "override"], "project": "dubbo"}
{"id": 999, "code": "protected RpcInvocation buildInvocation(MethodDescriptor methodDescriptor) {\n    final URL url = invoker.getUrl();\n    RpcInvocation inv = new RpcInvocation(url.getServiceModel(),\n        methodDescriptor.getMethodName(),\n        serviceDescriptor.getInterfaceName(), url.getProtocolServiceKey(),\n        methodDescriptor.getParameterClasses(),\n        new Object[0]);\n    inv.setTargetServiceUniqueName(url.getServiceKey());\n    inv.setReturnTypes(methodDescriptor.getReturnTypes());\n    inv.setObjectAttachments(StreamUtils.toAttachments(requestMetadata));\n    inv.put(REMOTE_ADDRESS_KEY, stream.remoteAddress());\n        \n    String timeout = (String) requestMetadata.get(TripleHeaderEnum.TIMEOUT.getHeader());\n    try {\n        if (Objects.nonNull(timeout)) {\n            this.timeout = parseTimeoutToMills(timeout);\n        }\n    } catch (Throwable t) {\n        LOGGER.warn(String.format(\"Failed to parse request timeout set from:%s, service=%s \"\n            + \"method=%s\", timeout, serviceDescriptor.getInterfaceName(), methodName));\n    }\n    if (null != requestMetadata.get(TripleHeaderEnum.CONSUMER_APP_NAME_KEY.getHeader())) {\n        inv.put(TripleHeaderEnum.CONSUMER_APP_NAME_KEY,\n            requestMetadata.get(TripleHeaderEnum.CONSUMER_APP_NAME_KEY.getHeader()));\n    }\n    return inv;\n}", "summary_tokens": ["build", "the", "rpc", "invocation", "with", "metadata", "and", "execute", "header", "filter"], "project": "dubbo"}
{"id": 766, "code": "private Map<ProtocolServiceKeyWithAddress, Invoker<T>> toInvokers(Map<ProtocolServiceKeyWithAddress, Invoker<T>> oldUrlInvokerMap, List<URL> urls) {\n    Map<ProtocolServiceKeyWithAddress, Invoker<T>> newUrlInvokerMap = new ConcurrentHashMap<>(urls == null ? 1 : (int) (urls.size() / 0.75f + 1));\n    if (urls == null || urls.isEmpty()) {\n        return newUrlInvokerMap;\n    }\n\n    for (URL url : urls) {\n        InstanceAddressURL instanceAddressURL = (InstanceAddressURL) url;\n        if (EMPTY_PROTOCOL.equals(instanceAddressURL.getProtocol())) {\n            continue;\n        }\n        if (!getUrl().getOrDefaultFrameworkModel().getExtensionLoader(Protocol.class).hasExtension(instanceAddressURL.getProtocol())) {\n\n                \n\n            logger.error(\"4-1\", \"protocol extension does not installed\", \"\", \"Unsupported protocol.\",\n                new IllegalStateException(\"Unsupported protocol \" + instanceAddressURL.getProtocol() +\n                \" in notified url: \" + instanceAddressURL + \" from registry \" + getUrl().getAddress() +\n                \" to consumer \" + NetUtils.getLocalHost() + \", supported protocol: \" +\n                getUrl().getOrDefaultFrameworkModel().getExtensionLoader(Protocol.class).getSupportedExtensions()));\n\n            continue;\n        }\n\n        instanceAddressURL.setProviderFirstParams(providerFirstParams);\n\n            \n        if (enableConfigurationListen) {\n            instanceAddressURL = overrideWithConfigurator(instanceAddressURL);\n        }\n\n            \n        int port = instanceAddressURL.getPort();\n        List<ProtocolServiceKey> matchedProtocolServiceKeys = instanceAddressURL.getMetadataInfo()\n            .getMatchedServiceInfos(consumerProtocolServiceKey)\n            .stream()\n            .filter(serviceInfo -> serviceInfo.getPort() <= 0 || serviceInfo.getPort() == port)\n            .map(MetadataInfo.ServiceInfo::getProtocolServiceKey)\n            .collect(Collectors.toList());\n\n            \n            \n        boolean shouldWrap = matchedProtocolServiceKeys.size() != 1 || !consumerProtocolServiceKey.isSameWith(matchedProtocolServiceKeys.get(0));\n\n        for (ProtocolServiceKey matchedProtocolServiceKey : matchedProtocolServiceKeys) {\n            ProtocolServiceKeyWithAddress protocolServiceKeyWithAddress = new ProtocolServiceKeyWithAddress(matchedProtocolServiceKey, instanceAddressURL.getAddress());\n            Invoker<T> invoker = oldUrlInvokerMap == null ? null : oldUrlInvokerMap.get(protocolServiceKeyWithAddress);\n            if (invoker == null || urlChanged(invoker, instanceAddressURL, matchedProtocolServiceKey)) { \n                try {\n                    boolean enabled;\n                    if (instanceAddressURL.hasParameter(DISABLED_KEY)) {\n                        enabled = !instanceAddressURL.getParameter(DISABLED_KEY, false);\n                    } else {\n                        enabled = instanceAddressURL.getParameter(ENABLED_KEY, true);\n                    }\n                    if (enabled) {\n                        if (shouldWrap) {\n                            URL newConsumerUrl = customizedConsumerUrlMap.computeIfAbsent(matchedProtocolServiceKey,\n                                k -> consumerUrl.setProtocol(k.getProtocol())\n                                    .addParameter(CommonConstants.GROUP_KEY, k.getGroup())\n                                    .addParameter(CommonConstants.VERSION_KEY, k.getVersion()));\n                            RpcContext.getServiceContext().setConsumerUrl(newConsumerUrl);\n                            invoker = new InstanceWrappedInvoker<>(protocol.refer(serviceType, instanceAddressURL), newConsumerUrl, matchedProtocolServiceKey);\n                        } else {\n                            invoker = protocol.refer(serviceType, instanceAddressURL);\n                        }\n                    }\n                } catch (Throwable t) {\n                    logger.error(\"Failed to refer invoker for interface:\" + serviceType + \",url:(\" + instanceAddressURL + \")\" + t.getMessage(), t);\n                }\n                if (invoker != null) { \n                    newUrlInvokerMap.put(protocolServiceKeyWithAddress, invoker);\n                }\n            } else {\n                newUrlInvokerMap.put(protocolServiceKeyWithAddress, invoker);\n                oldUrlInvokerMap.remove(protocolServiceKeyWithAddress, invoker);\n            }\n        }\n    }\n    return newUrlInvokerMap;\n}", "summary_tokens": ["turn", "urls", "into", "invokers", "and", "if", "url", "has", "been", "refer", "will", "not", "re", "reference"], "project": "dubbo"}
{"id": 885, "code": "public void testReceivedEventInvokeDirect() throws RemotingException {\n    handler = new ConnectionOrderedChannelHandler(new BizChannelHandler(false), url);\n    ThreadPoolExecutor executor = (ThreadPoolExecutor) getField(handler, \"SHARED_EXECUTOR\", 1);\n    executor.shutdown();\n    executor = (ThreadPoolExecutor) getField(handler, \"executor\", 1);\n    executor.shutdown();\n    Request req = new Request();\n    req.setHeartbeat(true);\n    final AtomicInteger count = new AtomicInteger(0);\n    handler.received(new MockedChannel() {\n        @Override\n        public void send(Object message) throws RemotingException {\n            Assertions.assertTrue(((Response) message).isHeartbeat(), \"response.heartbeat\");\n            count.incrementAndGet();\n        }\n    }, req);\n    Assertions.assertEquals(1, count.get(), \"channel.send must be invoke\");\n}", "summary_tokens": ["events", "do", "not", "pass", "through", "the", "thread", "pool", "and", "execute", "directly", "on", "the", "io"], "project": "dubbo"}
{"id": 60, "code": "public void testMockInvokerFromOverride_Invoke_checkCompatible_ImplMock() {\n    URL url = URL.valueOf(\"remote://1.2.3.4/\" + IHelloService.class.getName())\n            .addParameter(REFER_KEY,\n                    URL.encode(PATH_KEY + \"=\" + IHelloService.class.getName()\n                            + \"&\" + \"mock=true\"\n                            + \"&\" + \"proxy=jdk\"))\n            .addParameter(\"invoke_return_error\", \"true\");\n    Invoker<IHelloService> cluster = getClusterInvoker(url);\n        \n    RpcInvocation invocation = new RpcInvocation();\n    invocation.setMethodName(\"getSomething\");\n    Result ret = cluster.invoke(invocation);\n    Assertions.assertEquals(\"somethingmock\", ret.getValue());\n}", "summary_tokens": ["test", "if", "mock", "policy", "works", "fine", "fail", "mock"], "project": "dubbo"}
{"id": 635, "code": "public static ServiceBeanNameBuilder create(AnnotationAttributes attributes, Class<?> defaultInterfaceClass, Environment environment) {\n    return new ServiceBeanNameBuilder(attributes, defaultInterfaceClass, environment);\n}", "summary_tokens": ["attributes", "default", "interface", "class", "environment", "0"], "project": "dubbo"}
{"id": 602, "code": "private void afterExport() {\n        \n    Assertions.assertTrue(registryProtocolListener.isExported());\n        \n    Assertions.assertEquals(serviceListener.getExportedServices().size(), 1);\n        \n    Assertions.assertEquals(serviceListener.getExportedServices().get(0).getInterfaceClass(),\n        SingleRegistryCenterExportProviderService.class);\n        \n    Assertions.assertTrue(serviceListener.getExportedServices().get(0).isExported());\n        \n        \n        \n        \n    Assertions.assertEquals(exporterListener.getExportedExporters().size(), 3);\n        \n    Assertions.assertTrue(exporterListener.getFilters().contains(filter));\n        \n        \n        \n        \n        \n        \n        \n        \n    ConfigItem configItem = ApplicationModel.defaultModel().getBeanFactory().getBean(MetadataReportInstance.class).getMetadataReport(CommonConstants.DEFAULT_KEY)\n        .getConfigItem(serviceConfig.getInterface()\n            , ServiceNameMapping.DEFAULT_MAPPING_GROUP);\n        \n    Assertions.assertNotNull(configItem);\n        \n    Assertions.assertEquals(PROVIDER_APPLICATION_NAME,configItem.getContent());\n        \n    Assertions.assertNotNull(configItem.getTicket());\n}", "summary_tokens": ["there", "are", "some", "checkpoints", "need", "to", "check", "after", "exported", "as", "follow", "ul", "li", "the", "exporter", "is", "exported", "or", "not", "li", "li", "the", "exported", "exporter", "are", "three", "li", "li", "the", "exported", "service", "is", "single", "registry", "center", "export", "provider", "service", "or", "not", "li", "li", "the", "single", "registry", "center", "export", "provider", "service", "is", "exported", "or", "not", "li", "li", "the", "exported", "exporter", "contains", "single", "registry", "center", "export", "provider", "filter", "or", "not", "li", "li", "the", "metadata", "mapping", "info", "is", "right", "or", "not", "li", "ul"], "project": "dubbo"}
{"id": 1044, "code": "public int[] getAdminServerPorts() {\n    return DEFAULT_ADMIN_SERVER_PORTS;\n}", "summary_tokens": ["returns", "the", "admin", "server", "ports", "of", "zookeeper"], "project": "dubbo"}
{"id": 487, "code": "public ServiceConfigBase<?> getServiceConfig() {\n    if (config == null) {\n        return null;\n    }\n    if (config instanceof ServiceConfigBase) {\n        return (ServiceConfigBase<?>) config;\n    } else {\n        throw new IllegalArgumentException(\"Current ServiceModel is not a ProviderModel\");\n    }\n}", "summary_tokens": ["service", "model", "should", "be", "decoupled", "from", "abstract", "interface", "config", "and", "removed", "in", "a", "future", "version"], "project": "dubbo"}
{"id": 197, "code": "public final void set(V value) {\n    if (value == null || value == InternalThreadLocalMap.UNSET) {\n        remove();\n    } else {\n        InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();\n        if (threadLocalMap.setIndexedVariable(index, value)) {\n            addToVariablesToRemove(threadLocalMap, this);\n        }\n    }\n}", "summary_tokens": ["sets", "the", "value", "for", "the", "current", "thread"], "project": "dubbo"}
{"id": 787, "code": "private Map<String, String> getMetadataServiceURLsParams(ServiceInstance serviceInstance) {\n    Map<String, String> metadata = serviceInstance.getMetadata();\n    String param = metadata.get(METADATA_SERVICE_URL_PARAMS_PROPERTY_NAME);\n    return isBlank(param) ? emptyMap() : (Map) JsonUtils.getJson().toJavaObject(param, Map.class);\n}", "summary_tokens": ["get", "the", "multiple", "url", "urls", "parameters", "of", "metadata", "service", "metadata", "service", "s", "metadata"], "project": "dubbo"}
{"id": 723, "code": "long calculateStartTime() {\n    Calendar calendar = Calendar.getInstance();\n    long nowMill = calendar.getTimeInMillis();\n    calendar.set(Calendar.HOUR_OF_DAY, 0);\n    calendar.set(Calendar.MINUTE, 0);\n    calendar.set(Calendar.SECOND, 0);\n    calendar.set(Calendar.MILLISECOND, 0);\n    long subtract = calendar.getTimeInMillis() + ONE_DAY_IN_MILLISECONDS - nowMill;\n    return subtract + (FOUR_HOURS_IN_MILLISECONDS / 2) + ThreadLocalRandom.current().nextInt(FOUR_HOURS_IN_MILLISECONDS);\n}", "summary_tokens": ["between", "0", "0", "am", "to", "0", "0", "am", "the", "time", "is", "random"], "project": "dubbo"}
{"id": 656, "code": "static void registerPlaceholderConfigurerBeanIfNotExists(ConfigurableListableBeanFactory beanFactory, BeanDefinitionRegistry registry) {\n        \n        \n    if (!checkBeanExists(beanFactory, PropertySourcesPlaceholderConfigurer.class)) {\n        Map<String, Object> propertySourcesPlaceholderPropertyValues = new HashMap<>();\n        propertySourcesPlaceholderPropertyValues.put(\"ignoreUnresolvablePlaceholders\", true);\n\n        registerBeanDefinition(registry, PropertySourcesPlaceholderConfigurer.class.getName(),\n            PropertySourcesPlaceholderConfigurer.class, propertySourcesPlaceholderPropertyValues);\n    }\n}", "summary_tokens": ["register", "a", "placeholder", "configurer", "beans", "if", "not", "exists"], "project": "dubbo"}
{"id": 1009, "code": "public static <T, R> void oneToMany(T request,\n                                    StreamObserver<R> responseObserver,\n                                    Function<Mono<T>, Flux<R>> func) {\n    try {\n        Flux<R> response = func.apply(Mono.just(request));\n        ServerTripleReactorSubscriber<R> subscriber = response.subscribeWith(new ServerTripleReactorSubscriber<>());\n        subscriber.subscribe((ServerCallToObserverAdapter<R>) responseObserver);\n    } catch (Throwable throwable) {\n        responseObserver.onError(throwable);\n    }\n}", "summary_tokens": ["implements", "a", "unary", "stream", "call", "as", "mono", "flux"], "project": "dubbo"}
{"id": 326, "code": "static boolean isDeprecated(Method method) {\n    return method.getAnnotation(Deprecated.class) != null;\n}", "summary_tokens": ["check", "if", "the", "method", "is", "a", "deprecated", "method"], "project": "dubbo"}
{"id": 563, "code": "public List<Exporter<?>> getExportedExporters() {\n    return Collections.unmodifiableList(exportedExporters);\n}", "summary_tokens": ["returns", "the", "exported", "exporters"], "project": "dubbo"}
{"id": 482, "code": "default void setScopeModel(ScopeModel scopeModel) {\n}", "summary_tokens": ["override", "this", "method", "if", "you", "need", "get", "the", "scope", "model", "maybe", "one", "of", "framework", "model", "application", "model", "module", "model"], "project": "dubbo"}
{"id": 484, "code": "default void setApplicationModel(ApplicationModel applicationModel) {\n}", "summary_tokens": ["override", "this", "method", "if", "you", "just", "need", "application", "model", "application", "model"], "project": "dubbo"}
{"id": 108, "code": "public static int get(String property, int defaultValue) {\n    return get(ApplicationModel.defaultModel(), property, defaultValue);\n}", "summary_tokens": ["for", "compact", "single", "instance", "replaced", "to", "configuration", "utils", "get", "scope", "model", "string", "int"], "project": "dubbo"}
{"id": 729, "code": "protected MethodDefinition resolveMethodDefinition(Method serviceMethod, Class<?> serviceType,\n                                                   Class<?> serviceInterfaceClass) {\n    MethodDefinitionBuilder builder = new MethodDefinitionBuilder();\n    return builder.build(serviceMethod);\n}", "summary_tokens": ["resolve", "the", "method", "definition"], "project": "dubbo"}
{"id": 201, "code": "public boolean setIndexedVariable(int index, Object value) {\n    Object[] lookup = indexedVariables;\n    if (index < lookup.length) {\n        Object oldValue = lookup[index];\n        lookup[index] = value;\n        return oldValue == UNSET;\n    } else {\n        expandIndexedVariableTableAndSet(index, value);\n        return true;\n    }\n}", "summary_tokens": ["true", "if", "and", "only", "if", "a", "new", "thread", "local", "variable", "has", "been", "created"], "project": "dubbo"}
{"id": 863, "code": "private static SslProvider findSslProvider() {\n    if (OpenSsl.isAvailable()) {\n        logger.debug(\"Using OPENSSL provider.\");\n        return SslProvider.OPENSSL;\n    }\n    if (checkJdkProvider()) {\n        logger.debug(\"Using JDK provider.\");\n        return SslProvider.JDK;\n    }\n    throw new IllegalStateException(\n            \"Could not find any valid TLS provider, please check your dependency or deployment environment, \" +\n                    \"usually netty-tcnative, Conscrypt, or Jetty NPN/ALPN is needed.\");\n}", "summary_tokens": ["returns", "open", "ssl", "if", "available", "otherwise", "returns", "the", "jdk", "provider"], "project": "dubbo"}
{"id": 949, "code": "private void setRemotePort(Integer remotePort) {\n    set(REMOTE_PORT, remotePort);\n}", "summary_tokens": ["set", "caller", "remote", "port"], "project": "dubbo"}
{"id": 1067, "code": "private void download(String url, Path targetPath) throws ExecutionException, InterruptedException, IOException, TimeoutException {\n    AsyncHttpClient asyncHttpClient = new DefaultAsyncHttpClient(\n        new DefaultAsyncHttpClientConfig.Builder()\n            .setConnectTimeout(CONNECT_TIMEOUT)\n            .setRequestTimeout(REQUEST_TIMEOUT)\n            .setMaxRequestRetry(1)\n            .build());\n    Future<Response> responseFuture = asyncHttpClient.prepareGet(url).execute(new AsyncCompletionHandler<Response>() {\n        @Override\n        public Response onCompleted(Response response) {\n            logger.info(\"Download zookeeper binary archive file successfully! download url: \" + url);\n            return response;\n        }\n\n        @Override\n        public void onThrowable(Throwable t) {\n            logger.warn(\"Failed to download the file, download url: \" + url);\n            super.onThrowable(t);\n        }\n    });\n        \n    Response response = responseFuture.get(REQUEST_TIMEOUT * 2, TimeUnit.MILLISECONDS);\n    Files.copy(response.getResponseBodyAsStream(), targetPath, StandardCopyOption.REPLACE_EXISTING);\n}", "summary_tokens": ["download", "the", "file", "with", "the", "given", "url"], "project": "dubbo"}
{"id": 793, "code": "private Optional<List<Router>> toRouters(List<URL> urls) {\n    if (urls == null || urls.isEmpty()) {\n        return Optional.empty();\n    }\n\n    List<Router> routers = new ArrayList<>();\n    for (URL url : urls) {\n        if (EMPTY_PROTOCOL.equals(url.getProtocol())) {\n            continue;\n        }\n        String routerType = url.getParameter(ROUTER_KEY);\n        if (routerType != null && routerType.length() > 0) {\n            url = url.setProtocol(routerType);\n        }\n        try {\n            Router router = routerFactory.getRouter(url);\n            if (!routers.contains(router)) {\n                routers.add(router);\n            }\n        } catch (Throwable t) {\n            logger.error(\"convert router url to router error, url: \" + url, t);\n        }\n    }\n\n    return Optional.of(routers);\n}", "summary_tokens": ["urls", "null", "no", "routers", "do", "nothing", "else", "routers", "list"], "project": "dubbo"}
{"id": 156, "code": "private boolean hasInvocationArgument(Method method) {\n    Class<?>[] pts = method.getParameterTypes();\n    return Arrays.stream(pts).anyMatch(p -> CLASS_NAME_INVOCATION.equals(p.getName()));\n}", "summary_tokens": ["test", "if", "method", "has", "argument", "of", "type", "code", "invocation", "code"], "project": "dubbo"}
{"id": 398, "code": "public static boolean startsWithIgnoreCase(String str, String prefix) {\n    if (str == null || prefix == null || str.length() < prefix.length()) {\n        return false;\n    }\n        \n    return str.regionMatches(true, 0, prefix, 0, prefix.length());\n}", "summary_tokens": ["test", "str", "whether", "starts", "with", "the", "prefix", "ignore", "case"], "project": "dubbo"}
{"id": 496, "code": "public void testRemoveConfigAndDoRemoveConfig() throws Exception {\n    String key = null;\n    String group = null;\n    assertEquals(configuration.removeConfig(key, group), configuration.doRemoveConfig(key, group));\n    assertFalse(configuration.removeConfig(key, group));\n}", "summary_tokens": ["test", "abstract", "dynamic", "configuration", "remove", "config", "string", "string", "and", "abstract", "dynamic", "configuration", "do", "remove", "config", "string", "string", "methods"], "project": "dubbo"}
{"id": 616, "code": "private void createLazyProxy() {\n\n        \n        \n    ProxyFactory proxyFactory = new ProxyFactory();\n    proxyFactory.setTargetSource(new DubboReferenceLazyInitTargetSource());\n    proxyFactory.addInterface(interfaceClass);\n    Class<?>[] internalInterfaces = AbstractProxyFactory.getInternalInterfaces();\n    for (Class<?> anInterface : internalInterfaces) {\n        proxyFactory.addInterface(anInterface);\n    }\n    if (!StringUtils.isEquals(interfaceClass.getName(), interfaceName)) {\n            \n        try {\n            Class<?> serviceInterface = ClassUtils.forName(interfaceName, beanClassLoader);\n            proxyFactory.addInterface(serviceInterface);\n        } catch (ClassNotFoundException e) {\n                \n        }\n    }\n\n    this.lazyProxy = proxyFactory.getProxy(this.beanClassLoader);\n}", "summary_tokens": ["create", "lazy", "proxy", "for", "reference"], "project": "dubbo"}
{"id": 827, "code": "public void testRegister() throws Exception {\n        \n    abstractRegistry.register(mockUrl);\n    assert abstractRegistry.getRegistered().contains(mockUrl);\n        \n    for (URL url : abstractRegistry.getRegistered()) {\n        abstractRegistry.unregister(url);\n    }\n    List<URL> urlList = getList();\n    for (URL url : urlList) {\n        abstractRegistry.register(url);\n    }\n    MatcherAssert.assertThat(abstractRegistry.getRegistered().size(), Matchers.equalTo(urlList.size()));\n}", "summary_tokens": ["test", "method", "for", "org"], "project": "dubbo"}
{"id": 65, "code": "public String getAuthority() {\n    StringBuilder ret = new StringBuilder();\n\n    ret.append(getUserInformation());\n\n    if (StringUtils.isNotEmpty(getHost())) {\n        if (StringUtils.isNotEmpty(getUsername()) || StringUtils.isNotEmpty(getPassword())) {\n            ret.append('@');\n        }\n        ret.append(getHost());\n        if (getPort() != 0) {\n            ret.append(':');\n            ret.append(getPort());\n        }\n    }\n\n    return ret.length() == 0 ? null : ret.toString();\n}", "summary_tokens": ["refer", "to", "https", "datatracker"], "project": "dubbo"}
{"id": 543, "code": "private void useRegistryAsConfigCenterIfNecessary() {\n        \n    if (environment.getDynamicConfiguration().isPresent()) {\n        return;\n    }\n\n    if (CollectionUtils.isNotEmpty(configManager.getConfigCenters())) {\n        return;\n    }\n\n        \n    configManager.loadConfigsOfTypeFromProps(RegistryConfig.class);\n\n    List<RegistryConfig> defaultRegistries = configManager.getDefaultRegistries();\n    if (defaultRegistries.size() > 0) {\n        defaultRegistries\n            .stream()\n            .filter(this::isUsedRegistryAsConfigCenter)\n            .map(this::registryAsConfigCenter)\n            .forEach(configCenter -> {\n                if (configManager.getConfigCenter(configCenter.getId()).isPresent()) {\n                    return;\n                }\n                configManager.addConfigCenter(configCenter);\n                logger.info(\"use registry as config-center: \" + configCenter);\n\n            });\n    }\n}", "summary_tokens": ["for", "compatibility", "purpose", "use", "registry", "as", "the", "default", "config", "center", "when", "there", "s", "no", "config", "center", "specified", "explicitly", "and", "use", "as", "config", "center", "of", "registry", "config", "is", "null", "or", "true"], "project": "dubbo"}
{"id": 137, "code": "protected <V> V delay(String configFilePath, ThrowableFunction<File, V> function) {\n    File configFile = new File(configFilePath);\n        \n    if (isBasedPoolingWatchService()) {\n        File configDirectory = configFile.getParentFile();\n        executeMutually(configDirectory, () -> {\n            if (hasListeners(configFile) && isProcessing(configDirectory)) {\n                Integer delay = getDelay();\n                if (delay != null) {\n                        \n                    long timeout = SECONDS.toMillis(delay);\n                    if (logger.isDebugEnabled()) {\n                        logger.debug(format(\"The config[path : %s] is about to delay in %d ms.\",\n                                configFilePath, timeout));\n                    }\n                    configDirectory.wait(timeout);\n                }\n            }\n            addProcessing(configDirectory);\n            return null;\n        });\n    }\n\n    V value = null;\n\n    try {\n        value = function.apply(configFile);\n    } catch (Throwable e) {\n        if (logger.isErrorEnabled()) {\n            logger.error(e.getMessage(), e);\n        }\n    }\n\n    return value;\n}", "summary_tokens": ["delay", "action", "for", "config", "file", "string", "string", "config", "file"], "project": "dubbo"}
{"id": 200, "code": "protected void onRemoval(@SuppressWarnings(\"unused\") V value) throws Exception {\n}", "summary_tokens": ["invoked", "when", "this", "thread", "local", "variable", "is", "removed", "by", "remove"], "project": "dubbo"}
{"id": 878, "code": "public List<String> getURLBackupAddress(URL url) {\n    List<String> addressList = new ArrayList<>();\n    addressList.add(url.getAddress());\n    addressList.addAll(url.getParameter(RemotingConstants.BACKUP_KEY, Collections.emptyList()));\n\n    String authPrefix = null;\n    if (StringUtils.isNotEmpty(url.getUsername())) {\n        StringBuilder buf = new StringBuilder();\n        buf.append(url.getUsername());\n        if (StringUtils.isNotEmpty(url.getPassword())) {\n            buf.append(':');\n            buf.append(url.getPassword());\n        }\n        buf.append('@');\n        authPrefix = buf.toString();\n    }\n\n    if (StringUtils.isNotEmpty(authPrefix)) {\n        List<String> authedAddressList = new ArrayList<>(addressList.size());\n        for (String addr : addressList) {\n            authedAddressList.add(authPrefix + addr);\n        }\n        return authedAddressList;\n    }\n\n    return addressList;\n}", "summary_tokens": ["get", "all", "zookeeper", "urls", "such", "as", "zookeeper", "0"], "project": "dubbo"}
{"id": 799, "code": "protected Semaphore getSemaphore() {\n    return semaphore;\n}", "summary_tokens": ["this", "method", "is", "for", "unit", "test", "to", "see", "if", "the", "removal", "task", "has", "completed", "or", "not"], "project": "dubbo"}
{"id": 696, "code": "protected Cache createCache(URL url) {\n    return new LruCache(url);\n}", "summary_tokens": ["takes", "url", "as", "an", "method", "argument", "and", "return", "new", "instance", "of", "cache", "store", "implemented", "by", "lru", "cache"], "project": "dubbo"}
{"id": 752, "code": "private static int width(String string) {\n    int maxWidth = 0;\n    try (Scanner scanner = new Scanner(new StringReader(string))) {\n        while (scanner.hasNextLine()) {\n            maxWidth = max(length(scanner.nextLine()), maxWidth);\n        }\n    }\n    return maxWidth;\n}", "summary_tokens": ["visible", "width", "for", "the", "given", "string"], "project": "dubbo"}
{"id": 183, "code": "public static List<String> getAvailableAdapter() {\n    Map<Class<? extends LoggerAdapter>, String> candidates = new HashMap<>();\n    candidates.put(Log4jLoggerAdapter.class, \"log4j\");\n    candidates.put(Slf4jLoggerAdapter.class, \"slf4j\");\n    candidates.put(Log4j2LoggerAdapter.class, \"log4j2\");\n    candidates.put(JclLoggerAdapter.class, \"jcl\");\n    candidates.put(JdkLoggerAdapter.class, \"jdk\");\n    List<String> result = new LinkedList<>();\n    for (Map.Entry<Class<? extends LoggerAdapter>, String> entry : candidates.entrySet()) {\n        try {\n            LoggerAdapter loggerAdapter = entry.getKey().newInstance();\n            loggerAdapter.getLogger(LoggerFactory.class);\n            result.add(entry.getValue());\n        } catch (Throwable ignored) {\n        }\n    }\n    return result;\n}", "summary_tokens": ["get", "the", "available", "adapter", "names"], "project": "dubbo"}
{"id": 176, "code": "public Long getNumberAsLong(Map<String, ?> obj, String key) {\n    assert obj != null;\n    assert key != null;\n    if (!obj.containsKey(key)) {\n        return null;\n    }\n    Object value = obj.get(key);\n    if (value instanceof Double) {\n        Double d = (Double) value;\n        long l = d.longValue();\n        if (l != d) {\n            throw new ClassCastException(\"Number expected to be long: \" + d);\n        }\n        return l;\n    }\n    if (value instanceof String) {\n        try {\n            return Long.parseLong((String) value);\n        } catch (NumberFormatException e) {\n            throw new IllegalArgumentException(\n                String.format(\"value '%s' for key '%s' is not a long integer\", value, key));\n        }\n    }\n    throw new IllegalArgumentException(\n        String.format(\"value '%s' for key '%s' is not a long integer\", value, key));\n}", "summary_tokens": ["gets", "a", "number", "from", "an", "object", "for", "the", "given", "key", "casted", "to", "an", "long"], "project": "dubbo"}
{"id": 695, "code": "public Object get(Object key) {\n    return store.get(key);\n}", "summary_tokens": ["api", "to", "return", "stored", "value", "using", "a", "key", "against", "the", "calling", "thread", "specific", "store"], "project": "dubbo"}
{"id": 1001, "code": "private void processHeader() {\n    int type = accumulate.readUnsignedByte();\n    if ((type & RESERVED_MASK) != 0) {\n        throw new RpcException(\"gRPC frame header malformed: reserved bits not zero\");\n    }\n    compressedFlag = (type & COMPRESSED_FLAG_MASK) != 0;\n\n    requiredLength = accumulate.readInt();\n\n        \n    state = GrpcDecodeState.PAYLOAD;\n}", "summary_tokens": ["processes", "the", "grpc", "compression", "header", "which", "is", "composed", "of", "the", "compression", "flag", "and", "the", "outer", "frame", "length"], "project": "dubbo"}
{"id": 933, "code": "public Invocation getInvocation() {\n    return invocation;\n}", "summary_tokens": ["replace", "to", "get", "method", "name", "get", "parameter", "types", "get", "arguments"], "project": "dubbo"}
{"id": 767, "code": "private void destroyUnusedInvokers(Map<ProtocolServiceKeyWithAddress, Invoker<T>> oldUrlInvokerMap, Map<ProtocolServiceKeyWithAddress, Invoker<T>> newUrlInvokerMap) {\n    if (newUrlInvokerMap == null || newUrlInvokerMap.size() == 0) {\n        destroyAllInvokers();\n        return;\n    }\n\n    if (oldUrlInvokerMap == null || oldUrlInvokerMap.size() == 0) {\n        return;\n    }\n\n    for (Map.Entry<ProtocolServiceKeyWithAddress, Invoker<T>> entry : oldUrlInvokerMap.entrySet()) {\n        Invoker<T> invoker = entry.getValue();\n        if (invoker != null) {\n            try {\n                invoker.destroyAll();\n                if (logger.isDebugEnabled()) {\n                    logger.debug(\"destroy invoker[\" + invoker.getUrl() + \"] success. \");\n                }\n            } catch (Exception e) {\n                logger.warn(\"destroy invoker[\" + invoker.getUrl() + \"] failed. \" + e.getMessage(), e);\n            }\n        }\n    }\n    logger.info(oldUrlInvokerMap.size() + \" deprecated invokers deleted.\");\n}", "summary_tokens": ["check", "whether", "the", "invoker", "in", "the", "cache", "needs", "to", "be", "destroyed", "if", "set", "attribute", "of", "url", "refer"], "project": "dubbo"}
{"id": 115, "code": "public void addProperties(Map<String, String> properties) {\n    if (properties != null) {\n        this.store.putAll(properties);\n    }\n}", "summary_tokens": ["add", "a", "set", "of", "properties", "into", "the", "store"], "project": "dubbo"}
{"id": 769, "code": "default boolean isHealthy() {\n    return true;\n}", "summary_tokens": ["the", "registered", "service", "instance", "is", "health", "or", "not"], "project": "dubbo"}
{"id": 159, "code": "private String generateUrlAssignmentIndirectly(Method method) {\n    Class<?>[] pts = method.getParameterTypes();\n\n    Map<String, Integer> getterReturnUrl = new HashMap<>();\n        \n    for (int i = 0; i < pts.length; ++i) {\n        for (Method m : pts[i].getMethods()) {\n            String name = m.getName();\n            if ((name.startsWith(\"get\") || name.length() > 3)\n                    && Modifier.isPublic(m.getModifiers())\n                    && !Modifier.isStatic(m.getModifiers())\n                    && m.getParameterTypes().length == 0\n                    && m.getReturnType() == URL.class) {\n                getterReturnUrl.put(name, i);\n            }\n        }\n    }\n\n    if (getterReturnUrl.size() <= 0) {\n            \n        throw new IllegalStateException(\"Failed to create adaptive class for interface \" + type.getName()\n                + \": not found url parameter or url attribute in parameters of method \" + method.getName());\n    }\n\n    Integer index = getterReturnUrl.get(\"getUrl\");\n    if (index != null) {\n        return generateGetUrlNullCheck(index, pts[index], \"getUrl\");\n    } else {\n        Map.Entry<String, Integer> entry = getterReturnUrl.entrySet().iterator().next();\n        return generateGetUrlNullCheck(entry.getValue(), pts[entry.getValue()], entry.getKey());\n    }\n}", "summary_tokens": ["get", "parameter", "with", "type", "code", "url", "code", "from", "method", "parameter", "p", "test", "if", "parameter", "has", "method", "which", "returns", "type", "code", "url", "code", "p", "if", "not", "found", "throws", "illegal", "state", "exception"], "project": "dubbo"}
{"id": 809, "code": "", "summary_tokens": ["same", "situation", "as", "test", "get", "so", "left", "empty"], "project": "dubbo"}
{"id": 343, "code": "static boolean isPreferIPV6Address() {\n    return Boolean.getBoolean(\"java.net.preferIPv6Addresses\");\n}", "summary_tokens": ["check", "if", "an", "ipv", "0", "address"], "project": "dubbo"}
{"id": 657, "code": "public static Map<String, Object> extractProperties(ConfigurableEnvironment environment) {\n    return Collections.unmodifiableMap(doExtraProperties(environment));\n}", "summary_tokens": ["extras", "the", "properties", "from", "configurable", "environment"], "project": "dubbo"}
{"id": 876, "code": "public ZookeeperClient connect(URL url) {\n    ZookeeperClient zookeeperClient;\n        \n    List<String> addressList = getURLBackupAddress(url);\n        \n    if ((zookeeperClient = fetchAndUpdateZookeeperClientCache(addressList)) != null && zookeeperClient.isConnected()) {\n        logger.info(\"find valid zookeeper client from the cache for address: \" + url);\n        return zookeeperClient;\n    }\n        \n    synchronized (zookeeperClientMap) {\n        if ((zookeeperClient = fetchAndUpdateZookeeperClientCache(addressList)) != null && zookeeperClient.isConnected()) {\n            logger.info(\"find valid zookeeper client from the cache for address: \" + url);\n            return zookeeperClient;\n        }\n\n        zookeeperClient = createZookeeperClient(url);\n        logger.info(\"No valid zookeeper client found from cache, therefore create a new client for url. \" + url);\n        writeToClientMap(addressList, zookeeperClient);\n    }\n    return zookeeperClient;\n}", "summary_tokens": ["share", "connect", "for", "registry", "metadata", "etc"], "project": "dubbo"}
{"id": 452, "code": "public static List<Field> getNonStaticFields(final Class<?> clazz) {\n    List<Field> result = new ArrayList<>();\n    Class<?> target = clazz;\n    while (target != null) {\n        if (JaketConfigurationUtils.isExcludedType(target)) {\n            break;\n        }\n\n        Field[] fields = target.getDeclaredFields();\n        for (Field field : fields) {\n            int modifiers = field.getModifiers();\n            if (Modifier.isStatic(modifiers) || Modifier.isTransient(modifiers)) {\n                continue;\n            }\n\n            result.add(field);\n        }\n        target = target.getSuperclass();\n    }\n\n    return result;\n}", "summary_tokens": ["get", "all", "non", "static", "fields", "of", "the", "class", "passed", "in", "or", "its", "super", "classes"], "project": "dubbo"}
{"id": 151, "code": "private int getUrlTypeIndex(Method method) {\n    int urlTypeIndex = -1;\n    Class<?>[] pts = method.getParameterTypes();\n    for (int i = 0; i < pts.length; ++i) {\n        if (pts[i].equals(URL.class)) {\n            urlTypeIndex = i;\n            break;\n        }\n    }\n    return urlTypeIndex;\n}", "summary_tokens": ["get", "index", "of", "parameter", "with", "type", "url"], "project": "dubbo"}
{"id": 165, "code": "static <T> Predicate<T> alwaysTrue() {\n    return e -> true;\n}", "summary_tokens": ["predicate", "always", "return", "code", "true", "code"], "project": "dubbo"}
{"id": 228, "code": "public boolean equals(Object obj) {\n    if (this == obj) {\n        return true;\n    }\n    if (obj == null) {\n        return false;\n    }\n    if (!(obj instanceof DubboServiceAddressURL)) {\n        return false;\n    }\n    if (overrideURL == null) {\n        return super.equals(obj);\n    } else {\n        DubboServiceAddressURL other = (DubboServiceAddressURL) obj;\n        boolean overrideEquals = Objects.equals(overrideURL.getParameters(), other.getOverrideURL().getParameters());\n        if (!overrideEquals) {\n            return false;\n        }\n\n        Map<String, String> params = this.getParameters();\n        for (Map.Entry<String, String> entry : params.entrySet()) {\n            String key = entry.getKey();\n            if (overrideURL.getParameters().containsKey(key)) {\n                continue;\n            }\n            if (!entry.getValue().equals(other.getUrlParam().getParameter(key))) {\n                return false;\n            }\n        }\n    }\n    return true;\n}", "summary_tokens": ["ignore", "consumer", "url", "compare"], "project": "dubbo"}
{"id": 282, "code": "public static Set<Class<?>> getAllInheritedTypes(Class<?> type, Predicate<Class<?>>... typeFilters) {\n        \n    Set<Class<?>> types = new LinkedHashSet<>(getAllSuperClasses(type, typeFilters));\n        \n    types.addAll(getAllInterfaces(type, typeFilters));\n    return unmodifiableSet(types);\n}", "summary_tokens": ["get", "all", "inherited", "types", "from", "the", "specified", "type"], "project": "dubbo"}
{"id": 248, "code": "static boolean isType(AnnotatedElement annotatedElement) {\n    return annotatedElement instanceof Class;\n}", "summary_tokens": ["is", "the", "specified", "type", "a", "generic", "class", "type"], "project": "dubbo"}
{"id": 974, "code": "private void closeInternal(int timeout, boolean closeAll) {\n    if (closeAll || referenceCount.decrementAndGet() <= 0) {\n        if (timeout == 0) {\n            client.close();\n\n        } else {\n            client.close(timeout);\n        }\n\n        replaceWithLazyClient();\n    }\n}", "summary_tokens": ["when", "destroy", "unused", "invoker", "close", "all", "should", "be", "true"], "project": "dubbo"}
{"id": 369, "code": "public static Set<String> getAllFieldNames(Class<?> type) {\n\n    Set<String> fieldNames = new HashSet<>();\n    for (Field field : type.getDeclaredFields()) {\n        fieldNames.add(field.getName());\n    }\n\n    Set<Class<?>> allSuperClasses = ClassUtils.getAllSuperClasses(type);\n    for (Class<?> aClass : allSuperClasses) {\n        for (Field field : aClass.getDeclaredFields()) {\n            fieldNames.add(field.getName());\n        }\n    }\n    return fieldNames;\n}", "summary_tokens": ["get", "all", "field", "names", "of", "target", "type", "type"], "project": "dubbo"}
{"id": 372, "code": "public static int length(final CharSequence cs) {\n    return cs == null ? 0 : cs.length();\n}", "summary_tokens": ["gets", "a", "char", "sequence", "length", "or", "0", "if", "the", "char", "sequence", "is", "null"], "project": "dubbo"}
{"id": 269, "code": "public static <T> T[] of(T... values) {\n    return values;\n}", "summary_tokens": ["convert", "from", "variable", "arguments", "to", "array"], "project": "dubbo"}
{"id": 194, "code": "public static void removeAll() {\n    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.getIfSet();\n    if (threadLocalMap == null) {\n        return;\n    }\n\n    try {\n        Object v = threadLocalMap.indexedVariable(VARIABLES_TO_REMOVE_INDEX);\n        if (v != null && v != InternalThreadLocalMap.UNSET) {\n            Set<InternalThreadLocal<?>> variablesToRemove = (Set<InternalThreadLocal<?>>) v;\n            InternalThreadLocal<?>[] variablesToRemoveArray =\n                    variablesToRemove.toArray(new InternalThreadLocal[0]);\n            for (InternalThreadLocal<?> tlv : variablesToRemoveArray) {\n                tlv.remove(threadLocalMap);\n            }\n        }\n    } finally {\n        InternalThreadLocalMap.remove();\n    }\n}", "summary_tokens": ["removes", "all", "internal", "thread", "local", "variables", "bound", "to", "the", "current", "thread"], "project": "dubbo"}
{"id": 830, "code": "public void testSubscribe() {\n        \n    try {\n        abstractRegistry.subscribe(testUrl, null);\n        Assertions.fail();\n    } catch (Exception e) {\n        Assertions.assertTrue(e instanceof IllegalArgumentException);\n    }\n        \n    try {\n        abstractRegistry.subscribe(null, null);\n        Assertions.fail();\n    } catch (Exception e) {\n        Assertions.assertTrue(e instanceof IllegalArgumentException);\n    }\n        \n    Assertions.assertNull(abstractRegistry.getSubscribed().get(testUrl));\n    abstractRegistry.subscribe(testUrl, listener);\n    Assertions.assertNotNull(abstractRegistry.getSubscribed().get(testUrl));\n    Assertions.assertTrue(abstractRegistry.getSubscribed().get(testUrl).contains(listener));\n}", "summary_tokens": ["test", "method", "for", "org"], "project": "dubbo"}
{"id": 849, "code": "private Set<String> getServiceNames(URL url, NacosAggregateListener listener) {\n    if (isAdminProtocol(url)) {\n        scheduleServiceNamesLookup(url, listener);\n        return getServiceNamesForOps(url);\n    } else {\n        return getServiceNames0(url);\n    }\n}", "summary_tokens": ["get", "the", "service", "names", "from", "the", "specified", "url", "url"], "project": "dubbo"}
{"id": 43, "code": "protected Result invokeWithContextAsync(Invoker<T> invoker, Invocation invocation, URL consumerUrl) {\n    setContext(invoker, consumerUrl);\n    Result result;\n    try {\n        result = invoker.invoke(invocation);\n    } finally {\n        clearContext(invoker);\n    }\n    return result;\n}", "summary_tokens": ["when", "using", "a", "thread", "pool", "to", "fork", "a", "child", "thread", "thread", "local", "cannot", "be", "passed"], "project": "dubbo"}
{"id": 971, "code": "private void closeReferenceCountExchangeClient(ReferenceCountExchangeClient client) {\n    if (client == null) {\n        return;\n    }\n\n    try {\n        if (logger.isInfoEnabled()) {\n            logger.info(\"Close dubbo connect: \" + client.getLocalAddress() + \"-->\" + client.getRemoteAddress());\n        }\n\n        client.close(client.getShutdownWaitTime());\n\n            \n            \n\n    } catch (Throwable t) {\n        logger.warn(t.getMessage(), t);\n    }\n}", "summary_tokens": ["close", "reference", "count", "exchange", "client"], "project": "dubbo"}
{"id": 106, "code": "public static String getDynamicProperty(String property, String defaultValue) {\n    return getDynamicProperty(ApplicationModel.defaultModel(), property, defaultValue);\n}", "summary_tokens": ["for", "compact", "single", "instance", "replaced", "to", "configuration", "utils", "get", "dynamic", "property", "scope", "model", "string", "string"], "project": "dubbo"}
{"id": 41, "code": "protected Invoker<T> select(LoadBalance loadbalance, Invocation invocation,\n                            List<Invoker<T>> invokers, List<Invoker<T>> selected) throws RpcException {\n\n    if (CollectionUtils.isEmpty(invokers)) {\n        return null;\n    }\n    String methodName = invocation == null ? StringUtils.EMPTY_STRING : invocation.getMethodName();\n\n    boolean sticky = invokers.get(0).getUrl()\n        .getMethodParameter(methodName, CLUSTER_STICKY_KEY, DEFAULT_CLUSTER_STICKY);\n\n        \n    if (stickyInvoker != null && !invokers.contains(stickyInvoker)) {\n        stickyInvoker = null;\n    }\n        \n    if (sticky && stickyInvoker != null && (selected == null || !selected.contains(stickyInvoker))) {\n        if (availableCheck && stickyInvoker.isAvailable()) {\n            return stickyInvoker;\n        }\n    }\n\n    Invoker<T> invoker = doSelect(loadbalance, invocation, invokers, selected);\n\n    if (sticky) {\n        stickyInvoker = invoker;\n    }\n\n    return invoker;\n}", "summary_tokens": ["select", "a", "invoker", "using", "loadbalance", "policy"], "project": "dubbo"}
{"id": 985, "code": "public List<ServerServiceDefinition> getServices() {\n    return Collections.unmodifiableList(new ArrayList<>(services.values()));\n}", "summary_tokens": ["returns", "the", "service", "definitions", "in", "this", "registry"], "project": "dubbo"}
{"id": 884, "code": "private DefaultFuture defaultFuture(int timeout) {\n    Channel channel = new MockedChannel();\n    Request request = new Request(index.getAndIncrement());\n    return DefaultFuture.newFuture(channel, request, timeout, null);\n}", "summary_tokens": ["mock", "a", "default", "future"], "project": "dubbo"}
{"id": 892, "code": "private static Response buildErrorResponse(Request request, Throwable t) {\n    Response response = new Response(request.getId(), request.getVersion());\n    response.setStatus(Response.BAD_REQUEST);\n    response.setErrorMessage(StringUtils.toString(t));\n    return response;\n}", "summary_tokens": ["build", "a", "bad", "request", "s", "response"], "project": "dubbo"}
{"id": 1049, "code": "public static String getConnectionAddressKey1() {\n    return CONFIG.getConnectionAddressKey1();\n}", "summary_tokens": ["returns", "the", "first", "connection", "address", "key", "in", "multiple", "registry", "center"], "project": "dubbo"}
{"id": 914, "code": "public String getRemoteHostName() {\n    return SERVICE_CONTEXT.get().getRemoteHostName();\n}", "summary_tokens": ["get", "remote", "host", "name"], "project": "dubbo"}
{"id": 19, "code": "protected int getWeight(Invoker<?> invoker, Invocation invocation) {\n    int weight;\n    URL url = invoker.getUrl();\n    if (invoker instanceof ClusterInvoker) {\n        url = ((ClusterInvoker<?>) invoker).getRegistryUrl();\n    }\n\n        \n    if (REGISTRY_SERVICE_REFERENCE_PATH.equals(url.getServiceInterface())) {\n        weight = url.getParameter(WEIGHT_KEY, DEFAULT_WEIGHT);\n    } else {\n        weight = url.getMethodParameter(invocation.getMethodName(), WEIGHT_KEY, DEFAULT_WEIGHT);\n        if (weight > 0) {\n            long timestamp = invoker.getUrl().getParameter(TIMESTAMP_KEY, 0L);\n            if (timestamp > 0L) {\n                long uptime = System.currentTimeMillis() - timestamp;\n                if (uptime < 0) {\n                    return 1;\n                }\n                int warmup = invoker.getUrl().getParameter(WARMUP_KEY, DEFAULT_WARMUP);\n                if (uptime > 0 && uptime < warmup) {\n                    weight = calculateWarmupWeight((int)uptime, warmup, weight);\n                }\n            }\n        }\n    }\n    return Math.max(weight, 0);\n}", "summary_tokens": ["get", "the", "weight", "of", "the", "invoker", "s", "invocation", "which", "takes", "warmup", "time", "into", "account", "if", "the", "uptime", "is", "within", "the", "warmup", "time", "the", "weight", "will", "be", "reduce", "proportionally"], "project": "dubbo"}
{"id": 562, "code": "public void test1ReferenceRetry() {\n    ApplicationConfig application = new ApplicationConfig();\n    application.setName(\"test-reference-retry\");\n    application.setEnableFileCache(false);\n    ApplicationModel.defaultModel().getApplicationConfigManager().setApplication(application);\n\n    RegistryConfig registry = new RegistryConfig();\n    registry.setAddress(zkUrl1);\n\n    ReferenceConfig<DemoService> rc = new ReferenceConfig<>();\n    rc.setRegistry(registry);\n    rc.setInterface(DemoService.class.getName());\n\n    boolean success = false;\n    DemoService demoService = null;\n    try {\n        demoService = rc.get();\n        success = true;\n    } catch (Exception e) {\n            \n    }\n    Assertions.assertFalse(success);\n    Assertions.assertNull(demoService);\n\n    try {\n        System.setProperty(\"java.net.preferIPv4Stack\", \"true\");\n        ProxyFactory proxy = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\n        DemoService service = new DemoServiceImpl();\n        URL url = URL.valueOf(\"dubbo://127.0.0.1/DemoService\")\n            .addParameter(INTERFACE_KEY, DemoService.class.getName());\n        InjvmProtocol.getInjvmProtocol(FrameworkModel.defaultModel()).export(proxy.getInvoker(service, DemoService.class, url));\n        demoService = rc.get();\n        success = true;\n    } catch (Exception e) {\n            \n    } finally {\n        rc.destroy();\n        InjvmProtocol.getInjvmProtocol(FrameworkModel.defaultModel()).destroy();\n        System.clearProperty(\"java.net.preferIPv4Stack\");\n\n    }\n    Assertions.assertTrue(success);\n    Assertions.assertNotNull(demoService);\n\n}", "summary_tokens": ["unit", "test", "for", "dubbo", "0"], "project": "dubbo"}
{"id": 171, "code": "public List<Map<String, ?>> getListOfObjects(Map<String, ?> obj, String key) {\n    assert obj != null;\n    List<?> list = getList(obj, key);\n    if (list == null) {\n        return null;\n    }\n    return checkObjectList(list);\n}", "summary_tokens": ["gets", "a", "list", "from", "an", "object", "for", "the", "given", "key", "and", "verifies", "all", "entries", "are", "objects"], "project": "dubbo"}
{"id": 149, "code": "public String generate(boolean sort) {\n        \n    if (!hasAdaptiveMethod()) {\n        throw new IllegalStateException(\"No adaptive method exist on extension \" + type.getName() + \", refuse to create the adaptive class!\");\n    }\n\n    StringBuilder code = new StringBuilder();\n    code.append(generatePackageInfo());\n    code.append(generateImports());\n    code.append(generateClassDeclaration());\n\n    Method[] methods = type.getMethods();\n    if (sort) {\n        Arrays.sort(methods, Comparator.comparing(Method::toString));\n    }\n    for (Method method : methods) {\n        code.append(generateMethod(method));\n    }\n    code.append('}');\n\n    if (logger.isDebugEnabled()) {\n        logger.debug(code.toString());\n    }\n    return code.toString();", "summary_tokens": ["generate", "and", "return", "class", "code", "sort", "whether", "sort", "methods"], "project": "dubbo"}
{"id": 899, "code": "public Object getValue() {\n    return getAppResponse().getValue();\n}", "summary_tokens": ["notice", "the", "return", "type", "of", "get", "value", "is", "the", "actual", "type", "of", "the", "rpc", "method", "not", "app", "response"], "project": "dubbo"}
{"id": 722, "code": "public boolean retry() {\n    return doHandleMetadataCollection(failedReports);\n}", "summary_tokens": ["if", "need", "to", "continue"], "project": "dubbo"}
{"id": 264, "code": "static <T> T getDefaultValue(Class<? extends Annotation> annotationType, String attributeName) {\n    Method method = findMethod(annotationType, attributeName);\n    return (T) (method == null ? null : method.getDefaultValue());\n}", "summary_tokens": ["get", "the", "default", "value", "of", "attribute", "on", "the", "specified", "annotation"], "project": "dubbo"}
{"id": 912, "code": "public String getLocalHostName() {\n    return SERVICE_CONTEXT.get().getLocalHostName();\n}", "summary_tokens": ["get", "local", "host", "name"], "project": "dubbo"}
{"id": 454, "code": "public static ApplicationModel defaultModel() {\n        \n    return FrameworkModel.defaultModel().defaultApplication();\n}", "summary_tokens": ["during", "destroying", "the", "default", "framework", "model", "the", "framework", "model"], "project": "dubbo"}
{"id": 155, "code": "private String generateReturnAndInvocation(Method method) {\n    String returnStatement = method.getReturnType().equals(void.class) ? \"\" : \"return \";\n\n    String args = IntStream.range(0, method.getParameters().length)\n            .mapToObj(i -> String.format(CODE_EXTENSION_METHOD_INVOKE_ARGUMENT, i))\n            .collect(Collectors.joining(\", \"));\n\n    return returnStatement + String.format(\"extension.%s(%s);\\n\", method.getName(), args);\n}", "summary_tokens": ["generate", "method", "invocation", "statement", "and", "return", "it", "if", "necessary"], "project": "dubbo"}
{"id": 433, "code": "public static Class<?> determineInterfaceClass(String generic, String interfaceName) {\n    return determineInterfaceClass(generic, interfaceName, ClassUtils.getClassLoader());\n}", "summary_tokens": ["determine", "the", "interface", "of", "the", "proxy", "class", "generic", "interface", "name"], "project": "dubbo"}
{"id": 456, "code": "public static Collection<ProviderModel> allProviderModels() {\n    return defaultModel().getApplicationServiceRepository().allProviderModels();\n}", "summary_tokens": ["use", "service", "repository", "all", "provider", "models"], "project": "dubbo"}
{"id": 817, "code": "public void testWithConfigurationListenerAndLocalRule() throws InterruptedException {\n    DynamicConfiguration dynamicConfiguration = Mockito.mock(DynamicConfiguration.class);\n    Mockito.doReturn(remoteRule).when(dynamicConfiguration).getConfig(Mockito.anyString(), Mockito.anyString());\n\n    ApplicationModel.defaultModel().getDefaultModule().getModelEnvironment().setDynamicConfiguration(dynamicConfiguration);\n    ApplicationModel.defaultModel().getDefaultModule().getModelEnvironment().setLocalMigrationRule(localRule);\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"demo-consumer\");\n    ApplicationModel.defaultModel().getApplicationConfigManager().setApplication(applicationConfig);\n\n    URL consumerURL = Mockito.mock(URL.class);\n    Mockito.when(consumerURL.getServiceKey()).thenReturn(\"Test\");\n    Mockito.when(consumerURL.getParameter(\"timestamp\")).thenReturn(\"1\");\n\n    URL consumerURL2 = Mockito.mock(URL.class);\n    Mockito.when(consumerURL2.getServiceKey()).thenReturn(\"Test2\");\n    Mockito.when(consumerURL2.getParameter(\"timestamp\")).thenReturn(\"2\");\n\n    System.setProperty(\"dubbo.application.migration.delay\", \"1000\");\n    MigrationRuleHandler<?> handler = Mockito.mock(MigrationRuleHandler.class, Mockito.withSettings().verboseLogging());\n    MigrationRuleHandler<?> handler2 = Mockito.mock(MigrationRuleHandler.class, Mockito.withSettings().verboseLogging());\n\n        \n        \n    MigrationRuleListener migrationRuleListener = new MigrationRuleListener(ApplicationModel.defaultModel().getDefaultModule());\n    Assertions.assertNotNull(migrationRuleListener.localRuleMigrationFuture);\n    Assertions.assertNull(migrationRuleListener.ruleMigrationFuture);\n    MigrationInvoker<?> migrationInvoker = Mockito.mock(MigrationInvoker.class);\n    MigrationInvoker<?> migrationInvoker2 = Mockito.mock(MigrationInvoker.class);\n\n        \n    migrationRuleListener.getHandlers().put(migrationInvoker, handler);\n    migrationRuleListener.onRefer(null, migrationInvoker, consumerURL, null);\n\n    MigrationRule tmpRemoteRule = migrationRuleListener.getRule();\n    ArgumentCaptor<MigrationRule> captor = ArgumentCaptor.forClass(MigrationRule.class);\n    Mockito.verify(handler, Mockito.times(1)).doMigrate(captor.capture());\n    Assertions.assertEquals(tmpRemoteRule, captor.getValue());\n\n    Thread.sleep(3000);\n    Assertions.assertNull(migrationRuleListener.ruleMigrationFuture);\n\n\n\n\n\n    ArgumentCaptor<MigrationRule> captor2 = ArgumentCaptor.forClass(MigrationRule.class);\n    migrationRuleListener.getHandlers().put(migrationInvoker2, handler2);\n    migrationRuleListener.onRefer(null, migrationInvoker2, consumerURL2, null);\n    Mockito.verify(handler2, Mockito.times(1)).doMigrate(captor2.capture());\n    Assertions.assertEquals(tmpRemoteRule, captor2.getValue());\n\n\n    migrationRuleListener.process(new ConfigChangedEvent(\"key\", \"group\", dynamicRemoteRule));\n    Thread.sleep(1000);\n    Assertions.assertNotNull(migrationRuleListener.ruleMigrationFuture);\n    ArgumentCaptor<MigrationRule> captor_event = ArgumentCaptor.forClass(MigrationRule.class);\n    Mockito.verify(handler, Mockito.times(2)).doMigrate(captor_event.capture());\n    Assertions.assertEquals(\"APPLICATION_FIRST\", captor_event.getValue().getStep().toString());\n    Mockito.verify(handler2, Mockito.times(2)).doMigrate(captor_event.capture());\n    Assertions.assertEquals(\"APPLICATION_FIRST\", captor_event.getValue().getStep().toString());\n\n    ApplicationModel.reset();\n}", "summary_tokens": ["listener", "with", "config", "center", "initial", "remote", "rule", "and", "local", "rule", "check", "0"], "project": "dubbo"}
{"id": 852, "code": "private Set<String> getServiceNamesForOps(URL url) {\n    Set<String> serviceNames = getAllServiceNames();\n    filterServiceNames(serviceNames, url);\n    return serviceNames;\n}", "summary_tokens": ["get", "the", "service", "names", "for", "dubbo", "ops"], "project": "dubbo"}
{"id": 77, "code": "public static boolean isRelease263OrHigher(String version) {\n    return getIntVersion(version) >= 2060300;\n}", "summary_tokens": ["check", "the", "framework", "release", "version", "number", "to", "decide", "if", "it", "s", "0"], "project": "dubbo"}
{"id": 511, "code": "public void setServices(String services) {\n    this.services = services;\n}", "summary_tokens": ["set", "the", "service", "names", "that", "the", "dubbo", "interface", "subscribed"], "project": "dubbo"}
{"id": 231, "code": "public boolean hasMethodParameter(String method) {\n    if (method == null) {\n        return false;\n    }\n\n    String methodsString = getParameter(METHODS_KEY);\n    if (StringUtils.isNotEmpty(methodsString)) {\n        if (!methodsString.contains(method)) {\n            return false;\n        }\n    }\n\n    for (Map.Entry<String, Map<String, String>> methods : METHOD_PARAMETERS.entrySet()) {\n        if (methods.getValue().containsKey(method)) {\n            return true;\n        }\n    }\n    return false;\n}", "summary_tokens": ["weather", "there", "contains", "some", "parameter", "match", "method"], "project": "dubbo"}
{"id": 534, "code": "public boolean isStopping() {\n    return applicationDeployer.isStopping();\n}", "summary_tokens": ["true", "if", "the", "dubbo", "application", "is", "stopping"], "project": "dubbo"}
{"id": 1059, "code": "public Integer getPid(int clientPort) {\n    return this.processIds.get(clientPort);\n}", "summary_tokens": ["returns", "the", "pid", "of", "zookeeper", "instance", "with", "the", "given", "client", "port"], "project": "dubbo"}
{"id": 283, "code": "public static boolean isAssignableFrom(Class<?> superType, Class<?> targetType) {\n        \n    if (superType == null || targetType == null) {\n        return false;\n    }\n        \n    if (Objects.equals(superType, targetType)) {\n        return true;\n    }\n        \n    return superType.isAssignableFrom(targetType);\n}", "summary_tokens": ["the", "semantics", "is", "same", "as", "class", "is", "assignable", "from", "class"], "project": "dubbo"}
{"id": 1058, "code": "public void register(int clientPort, int pid) {\n    this.processIds.put(clientPort, pid);\n}", "summary_tokens": ["register", "the", "process", "id", "of", "zookeeper"], "project": "dubbo"}
{"id": 196, "code": "public final V get() {\n    InternalThreadLocalMap threadLocalMap = InternalThreadLocalMap.get();\n    Object v = threadLocalMap.indexedVariable(index);\n    if (v != InternalThreadLocalMap.UNSET) {\n        return (V) v;\n    }\n\n    return initialize(threadLocalMap);\n}", "summary_tokens": ["returns", "the", "current", "value", "for", "the", "current", "thread"], "project": "dubbo"}
{"id": 103, "code": "public static DynamicConfigurationFactory getDynamicConfigurationFactory(ExtensionAccessor extensionAccessor, String name) {\n    ExtensionLoader<DynamicConfigurationFactory> loader = extensionAccessor.getExtensionLoader(DynamicConfigurationFactory.class);\n    return loader.getOrDefaultExtension(name);\n}", "summary_tokens": ["get", "an", "instance", "of", "dynamic", "configuration", "factory", "by", "the", "specified", "name"], "project": "dubbo"}
{"id": 257, "code": "static List<Annotation> getAllMetaAnnotations(Class<? extends Annotation> annotationType,\n                                              Predicate<Annotation>... annotationsToFilter) {\n\n    List<Annotation> allMetaAnnotations = new LinkedList<>();\n\n    List<Annotation> metaAnnotations = getMetaAnnotations(annotationType);\n\n    allMetaAnnotations.addAll(metaAnnotations);\n\n    for (Annotation metaAnnotation : metaAnnotations) {\n            \n        allMetaAnnotations.addAll(getAllMetaAnnotations(metaAnnotation.annotationType()));\n    }\n\n    return unmodifiableList(filterAll(allMetaAnnotations, annotationsToFilter));\n}", "summary_tokens": ["get", "all", "meta", "annotations", "from", "the", "specified", "annotation", "annotation", "type"], "project": "dubbo"}
{"id": 768, "code": "default boolean isEnabled() {\n    return true;\n}", "summary_tokens": ["the", "enabled", "status", "of", "the", "registered", "service", "instance"], "project": "dubbo"}
{"id": 256, "code": "static List<Annotation> getMetaAnnotations(Class<? extends Annotation> annotationType,\n                                           Predicate<Annotation>... metaAnnotationsToFilter) {\n    return getDeclaredAnnotations(annotationType,\n                \n                \n            excludedType(Target.class),\n            excludedType(Retention.class),\n            excludedType(Documented.class),\n                \n            and(metaAnnotationsToFilter)\n    );\n}", "summary_tokens": ["get", "the", "meta", "annotated", "annotation", "annotations", "directly", "excluding", "target", "retention", "and", "documented"], "project": "dubbo"}
{"id": 821, "code": "public void testReferWithoutGroup() {\n    ApplicationConfig applicationConfig = new ApplicationConfig();\n    applicationConfig.setName(\"application1\");\n\n\n    ConfigManager configManager = mock(ConfigManager.class);\n    when(configManager.getApplicationOrElseThrow()).thenReturn(applicationConfig);\n\n    CompositeConfiguration compositeConfiguration = mock(CompositeConfiguration.class);\n    when(compositeConfiguration.convert(Boolean.class, ENABLE_CONFIGURATION_LISTEN, true))\n        .thenReturn(true);\n\n    Map<String, String> parameters = new HashMap<>();\n    parameters.put(INTERFACE_KEY, DemoService.class.getName());\n    parameters.put(\"registry\", \"zookeeper\");\n    parameters.put(\"register\", \"false\");\n\n    Map<String, Object> attributes = new HashMap<>();\n    ServiceConfigURL serviceConfigURL = new ServiceConfigURL(\"registry\",\n        \"127.0.0.1\",\n        2181,\n        \"org.apache.dubbo.registry.RegistryService\",\n        parameters);\n    Map<String, String> refer = new HashMap<>();\n    attributes.put(REFER_KEY, refer);\n    URL url = serviceConfigURL.addAttributes(attributes);\n\n    RegistryFactory registryFactory = mock(RegistryFactory.class);\n    Registry registry = mock(Registry.class);\n\n    MigrationRuleListener migrationRuleListener = mock(MigrationRuleListener.class);\n    List<RegistryProtocolListener> registryProtocolListeners = new ArrayList<>();\n    registryProtocolListeners.add(migrationRuleListener);\n\n    RegistryProtocol registryProtocol = new RegistryProtocol();\n    ModuleModel moduleModel = Mockito.spy(ApplicationModel.defaultModel().getDefaultModule());\n    moduleModel.getApplicationModel().getApplicationConfigManager().setApplication(new ApplicationConfig(\"application1\"));\n    ExtensionLoader extensionLoaderMock = mock(ExtensionLoader.class);\n    Mockito.when(moduleModel.getExtensionLoader(RegistryProtocolListener.class)).thenReturn(extensionLoaderMock);\n    Mockito.when(extensionLoaderMock.getActivateExtension(url, REGISTRY_PROTOCOL_LISTENER_KEY))\n        .thenReturn(registryProtocolListeners);\n    Mockito.when(moduleModel.getExtensionLoader(RegistryFactory.class)).thenReturn(extensionLoaderMock);\n    Mockito.when(extensionLoaderMock.getAdaptiveExtension()).thenReturn(registryFactory);\n    url = url.setScopeModel(moduleModel);\n\n    when(registryFactory.getRegistry(registryProtocol.getRegistryUrl(url))).thenReturn(registry);\n\n    Invoker<?> invoker = registryProtocol.refer(DemoService.class, url);\n\n    Assertions.assertTrue(invoker instanceof MigrationInvoker);\n    Assertions.assertTrue(((MigrationInvoker<?>) invoker).getCluster() instanceof MockClusterWrapper);\n    Assertions.assertTrue(\n        ((MockClusterWrapper) ((MigrationInvoker<?>) invoker).getCluster()).getCluster() instanceof FailoverCluster);\n}", "summary_tokens": ["verify", "that", "if", "multiple", "groups", "are", "not", "configured", "the", "service", "reference", "of", "the", "registration", "center", "the", "default", "is", "failover", "cluster"], "project": "dubbo"}
{"id": 502, "code": "public void testSplitToSet() {\n    String value = \"1# 2#3 #4#3\";\n    Set<String> values = splitToSet(value, '#', false);\n    assertEquals(ofSet(\"1\", \" 2\", \"3 \", \"4\", \"3\"), values);\n\n    values = splitToSet(value, '#', true);\n    assertEquals(ofSet(\"1\", \"2\", \"3\", \"4\"), values);\n}", "summary_tokens": ["test", "string", "utils", "split", "to", "set", "string", "char", "boolean"], "project": "dubbo"}
{"id": 860, "code": "public static NacosNamingServiceWrapper createNamingService(URL connectionURL) {\n    Properties nacosProperties = buildNacosProperties(connectionURL);\n    NamingService namingService;\n    try {\n        namingService = NacosFactory.createNamingService(nacosProperties);\n    } catch (NacosException e) {\n        if (logger.isErrorEnabled()) {\n            logger.error(e.getErrMsg(), e);\n        }\n        throw new IllegalStateException(e);\n    }\n    return new NacosNamingServiceWrapper(namingService);\n}", "summary_tokens": ["create", "an", "instance", "of", "naming", "service", "from", "specified", "url", "connection", "url"], "project": "dubbo"}
{"id": 495, "code": "public void testGetTimeoutAndGetDefaultTimeout() {\n    assertEquals(configuration.getTimeout(), configuration.getDefaultTimeout());\n    assertEquals(-1L, configuration.getDefaultTimeout());\n}", "summary_tokens": ["test", "abstract", "dynamic", "configuration", "get", "timeout", "and", "abstract", "dynamic", "configuration", "get", "default", "timeout", "methods"], "project": "dubbo"}
{"id": 895, "code": "static FormattingTuple arrayFormat(final String messagePattern,\n                                   final Object[] argArray) {\n\n    Throwable throwableCandidate = getThrowableCandidate(argArray);\n\n    if (messagePattern == null) {\n        return new FormattingTuple(null, argArray, throwableCandidate);\n    }\n\n    if (argArray == null) {\n        return new FormattingTuple(messagePattern);\n    }\n\n    int i = 0;\n    int j;\n    StringBuffer sbuf = new StringBuffer(messagePattern.length() + 50);\n\n    int l;\n    for (l = 0; l < argArray.length; l++) {\n\n        j = messagePattern.indexOf(DELIM_STR, i);\n\n        if (j == -1) {\n                \n            if (i == 0) { \n                return new FormattingTuple(messagePattern, argArray,\n                        throwableCandidate);\n            } else { \n                    \n                sbuf.append(messagePattern.substring(i));\n                return new FormattingTuple(sbuf.toString(), argArray,\n                        throwableCandidate);\n            }\n        } else {\n            if (isEscapedDelimeter(messagePattern, j)) {\n                if (!isDoubleEscaped(messagePattern, j)) {\n                    l--; \n                    sbuf.append(messagePattern, i, j - 1);\n                    sbuf.append(DELIM_START);\n                    i = j + 1;\n                } else {\n                        \n                        \n                        \n                    sbuf.append(messagePattern, i, j - 1);\n                    deeplyAppendParameter(sbuf, argArray[l], new HashMap<Object[], Void>());\n                    i = j + 2;\n                }\n            } else {\n                    \n                sbuf.append(messagePattern, i, j);\n                deeplyAppendParameter(sbuf, argArray[l], new HashMap<Object[], Void>());\n                i = j + 2;\n            }\n        }\n    }\n        \n    sbuf.append(messagePattern.substring(i));\n    if (l < argArray.length - 1) {\n        return new FormattingTuple(sbuf.toString(), argArray, throwableCandidate);\n    } else {\n        return new FormattingTuple(sbuf.toString(), argArray, null);\n    }\n}", "summary_tokens": ["same", "principle", "as", "the", "format", "string", "object", "and", "format", "string", "object", "object", "methods", "except", "that", "any", "number", "of", "arguments", "can", "be", "passed", "in", "an", "array"], "project": "dubbo"}
{"id": 797, "code": "protected String createRegistryCacheKey(URL url) {\n    return url.toServiceStringWithoutResolving();\n}", "summary_tokens": ["create", "the", "key", "for", "the", "registries", "cache"], "project": "dubbo"}
{"id": 39, "code": "public void clear() {\n    rootSet.clear();\n        \n    originList = Collections.emptyList();\n    if (CollectionUtils.isNotEmpty(tailList)) {\n        tailList = null;\n    }\n}", "summary_tokens": ["caution", "this", "operation", "will", "clear", "origin", "list", "for", "removing", "references", "purpose"], "project": "dubbo"}
{"id": 704, "code": "private static Class<?> generateMethodParameterClass(Class<?> clazz, Method method, String parameterClassName)\n    throws Exception {\n    ClassPool pool = ClassGenerator.getClassPool(clazz.getClassLoader());\n    synchronized (parameterClassName.intern()) {\n        CtClass ctClass = null;\n        try {\n            ctClass = pool.getCtClass(parameterClassName);\n        } catch (NotFoundException ignore) {\n        }\n\n        if (null == ctClass) {\n            ctClass = pool.makeClass(parameterClassName);\n            ClassFile classFile = ctClass.getClassFile();\n            classFile.setVersionToJava5();\n            ctClass.addConstructor(CtNewConstructor.defaultConstructor(pool.getCtClass(parameterClassName)));\n                \n            Class<?>[] parameterTypes = method.getParameterTypes();\n            Annotation[][] parameterAnnotations = method.getParameterAnnotations();\n            for (int i = 0; i < parameterTypes.length; i++) {\n                Class<?> type = parameterTypes[i];\n                Annotation[] annotations = parameterAnnotations[i];\n                AnnotationsAttribute attribute = new AnnotationsAttribute(classFile.getConstPool(), AnnotationsAttribute.visibleTag);\n                for (Annotation annotation : annotations) {\n                    if (annotation.annotationType().isAnnotationPresent(Constraint.class)) {\n                        javassist.bytecode.annotation.Annotation ja = new javassist.bytecode.annotation.Annotation(\n                            classFile.getConstPool(), pool.getCtClass(annotation.annotationType().getName()));\n                        Method[] members = annotation.annotationType().getMethods();\n                        for (Method member : members) {\n                            if (Modifier.isPublic(member.getModifiers())\n                                && member.getParameterTypes().length == 0\n                                && member.getDeclaringClass() == annotation.annotationType()) {\n                                Object value = member.invoke(annotation);\n                                if (null != value) {\n                                    MemberValue memberValue = createMemberValue(\n                                        classFile.getConstPool(), pool.get(member.getReturnType().getName()), value);\n                                    ja.addMemberValue(member.getName(), memberValue);\n                                }\n                            }\n                        }\n                        attribute.addAnnotation(ja);\n                    }\n                }\n                String fieldName = method.getName() + \"Argument\" + i;\n                CtField ctField = CtField.make(\"public \" + type.getCanonicalName() + \" \" + fieldName + \";\", pool.getCtClass(parameterClassName));\n                ctField.getFieldInfo().addAttribute(attribute);\n                ctClass.addField(ctField);\n            }\n            return ctClass.toClass(clazz.getClassLoader(), null);\n        } else {\n            return Class.forName(parameterClassName, true, clazz.getClassLoader());\n        }\n    }\n}", "summary_tokens": ["try", "to", "generate", "method", "parameter", "class"], "project": "dubbo"}
{"id": 461, "code": "public static ServiceRepository getServiceRepository() {\n    return defaultModel().getApplicationServiceRepository();\n}", "summary_tokens": ["replace", "to", "application", "model", "get", "application", "service", "repository"], "project": "dubbo"}
{"id": 791, "code": "public URL getSubscribeUrl() {\n    return subscribeUrl;\n}", "summary_tokens": ["the", "url", "used", "to", "subscribe", "from", "registry"], "project": "dubbo"}
{"id": 286, "code": "public static boolean isGenericClass(Class<?> type) {\n    return type != null && !void.class.equals(type) && !Void.class.equals(type);\n}", "summary_tokens": ["is", "generic", "class", "or", "not"], "project": "dubbo"}
{"id": 753, "code": "public TTree begin(Object data) {\n    current = new Node(current, data);\n    current.markBegin();\n    return this;\n}", "summary_tokens": ["create", "a", "branch", "node"], "project": "dubbo"}
{"id": 377, "code": "public static boolean isNotBlank(CharSequence cs) {\n    return !isBlank(cs);\n}", "summary_tokens": ["is", "not", "blank", "string"], "project": "dubbo"}
{"id": 1048, "code": "public static String getConnectionAddressKey() {\n    return CONFIG.getConnectionAddressKey();\n}", "summary_tokens": ["returns", "the", "default", "connection", "address", "key", "in", "single", "registry", "center"], "project": "dubbo"}
{"id": 600, "code": "public boolean hasError() {\n    return error;\n}", "summary_tokens": ["returns", "if", "there", "exists", "error"], "project": "dubbo"}
{"id": 162, "code": "default String[] includedPackagesInCompatibleType() {\n        \n    return null;\n}", "summary_tokens": ["to", "restrict", "some", "class", "that", "should", "not", "be", "loaded", "from", "org"], "project": "dubbo"}
{"id": 312, "code": "static Field getDeclaredField(Class<?> declaredClass, String fieldName) {\n    try {\n        Field[] fields = declaredClass.getDeclaredFields();\n        for (int i = 0; i < fields.length; i++) {\n            if (fields[i].getName().equals(fieldName)) {\n                return fields[i];\n            }\n        }\n        return null;\n    } catch (Exception exception) {\n        throw new RuntimeException(exception);\n    }\n}", "summary_tokens": ["like", "the", "class", "get", "declared", "field", "string", "method", "without", "throwing", "any", "exception"], "project": "dubbo"}
{"id": 380, "code": "public static boolean isAnyEmpty(final String... ss) {\n    return !isNoneEmpty(ss);\n}", "summary_tokens": ["p", "checks", "if", "the", "strings", "contain", "at", "least", "on", "empty", "or", "null", "element"], "project": "dubbo"}
{"id": 774, "code": "public final Set<String> getServiceNames() {\n    return serviceNames;\n}", "summary_tokens": ["get", "the", "correlative", "service", "name"], "project": "dubbo"}
{"id": 916, "code": "public boolean isServerSide() {\n    return SERVICE_CONTEXT.get().isServerSide();\n}", "summary_tokens": ["replace", "to", "is", "provider", "side"], "project": "dubbo"}
{"id": 73, "code": "private static URL parseURLBody(String fullURLStr, String decodedBody, Map<String, String> parameters) {\n    int starIdx = 0, endIdx = decodedBody.length();\n        \n    int poundIndex = decodedBody.indexOf('#');\n    if (poundIndex != -1) {\n        endIdx = poundIndex;\n    }\n\n    String protocol = null;\n    int protoEndIdx = decodedBody.indexOf(\"://\");\n    if (protoEndIdx >= 0) {\n        if (protoEndIdx == 0) {\n            throw new IllegalStateException(\"url missing protocol: \\\"\" + fullURLStr + \"\\\"\");\n        }\n        protocol = decodedBody.substring(0, protoEndIdx);\n        starIdx = protoEndIdx + 3;\n    } else {\n            \n        protoEndIdx = decodedBody.indexOf(\":/\");\n        if (protoEndIdx >= 0) {\n            if (protoEndIdx == 0) {\n                throw new IllegalStateException(\"url missing protocol: \\\"\" + fullURLStr + \"\\\"\");\n            }\n            protocol = decodedBody.substring(0, protoEndIdx);\n            starIdx = protoEndIdx + 1;\n        }\n    }\n\n    String path = null;\n    int pathStartIdx = indexOf(decodedBody, '/', starIdx, endIdx);\n    if (pathStartIdx >= 0) {\n        path = decodedBody.substring(pathStartIdx + 1, endIdx);\n        endIdx = pathStartIdx;\n    }\n\n    String username = null;\n    String password = null;\n    int pwdEndIdx = lastIndexOf(decodedBody, '@', starIdx, endIdx);\n    if (pwdEndIdx > 0) {\n        int passwordStartIdx = indexOf(decodedBody, ':', starIdx, pwdEndIdx);\n        if (passwordStartIdx != -1) {\n            username = decodedBody.substring(starIdx, passwordStartIdx);\n            password = decodedBody.substring(passwordStartIdx + 1, pwdEndIdx);\n        } else {\n            username = decodedBody.substring(starIdx, pwdEndIdx);\n        }\n        starIdx = pwdEndIdx + 1;\n    }\n\n    String host = null;\n    int port = 0;\n    int hostEndIdx = lastIndexOf(decodedBody, ':', starIdx, endIdx);\n    if (hostEndIdx > 0 && hostEndIdx < decodedBody.length() - 1) {\n        if (lastIndexOf(decodedBody, '%', starIdx, endIdx) > hostEndIdx) {\n                \n                \n                \n                \n        } else {\n            port = Integer.parseInt(decodedBody.substring(hostEndIdx + 1, endIdx));\n            endIdx = hostEndIdx;\n        }\n    }\n\n    if (endIdx > starIdx) {\n        host = decodedBody.substring(starIdx, endIdx);\n    }\n\n        \n    protocol = URLItemCache.intern(protocol);\n    path = URLItemCache.checkPath(path);\n\n    return new ServiceConfigURL(protocol, username, password, host, port, path, parameters);\n}", "summary_tokens": ["full", "urlstr", "full", "urlstring", "decoded", "body", "format", "protocol", "username", "password", "host", "port", "path", "parameters", "url"], "project": "dubbo"}
{"id": 720, "code": "static ServiceNameMapping getDefaultExtension(ScopeModel scopeModel) {\n    return ScopeModelUtil.getApplicationModel(scopeModel).getDefaultExtension(ServiceNameMapping.class);\n}", "summary_tokens": ["get", "the", "default", "extension", "of", "service", "name", "mapping"], "project": "dubbo"}
{"id": 678, "code": "private ApolloListener createTargetListener(String key, String group) {\n    return new ApolloListener();\n}", "summary_tokens": ["ignores", "the", "group", "parameter"], "project": "dubbo"}
{"id": 976, "code": "public void incrementAndGetCount() {\n    referenceCount.incrementAndGet();\n}", "summary_tokens": ["the", "reference", "count", "of", "current", "exchange", "client", "connection", "will", "be", "closed", "if", "all", "invokers", "destroyed"], "project": "dubbo"}
{"id": 643, "code": "public final ApplicationContext getApplicationContext() {\n    return (ApplicationContext) getSource();\n}", "summary_tokens": ["get", "the", "application", "context", "that", "the", "event", "was", "raised", "for"], "project": "dubbo"}
{"id": 607, "code": "public boolean hasError() {\n    return error;\n}", "summary_tokens": ["returns", "if", "there", "exists", "error"], "project": "dubbo"}
{"id": 713, "code": "default String[] serviceParamsExcluded() {\n    return new String[0];\n}", "summary_tokens": ["params", "that", "need", "to", "be", "excluded", "before", "sending", "to", "metadata", "center"], "project": "dubbo"}
{"id": 683, "code": "public static void main(String[] args) throws Exception {\n    ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"spring/dubbo-consumer.xml\");\n    context.start();\n    DemoService demoService = context.getBean(\"demoService\", DemoService.class);\n    GreetingService greetingService = context.getBean(\"greetingService\", GreetingService.class);\n    RestDemoService restDemoService = context.getBean(\"restDemoService\", RestDemoService.class);\n    TripleService tripleService = context.getBean(\"tripleService\", TripleService.class);\n\n    new Thread(() -> {\n        while (true) {\n            try {\n                String greetings = greetingService.hello();\n                System.out.println(greetings + \" from separated thread.\");\n            } catch (Exception e) {\n\n            }\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n            }\n        }\n    }).start();\n\n    new Thread(() -> {\n        while (true) {\n            try {\n                String restResult = restDemoService.sayHello(\"rest\");\n                System.out.println(restResult + \" from separated thread.\");\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n            }\n        }\n    }).start();\n\n    new Thread(() -> {\n        while (true) {\n            try {\n                String restResult = tripleService.hello();\n                System.out.println(restResult + \" from separated thread.\");\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n            }\n        }\n    }).start();\n\n    while (true) {\n        try {\n            CompletableFuture<String> hello = demoService.sayHelloAsync(\"world\");\n            System.out.println(\"result: \" + hello.get());\n\n            String greetings = greetingService.hello();\n            System.out.println(\"result: \" + greetings);\n        } catch (Exception e) {\n\n        }\n\n        Thread.sleep(5000);\n    }\n}", "summary_tokens": ["in", "order", "to", "make", "sure", "multicast", "registry", "works", "need", "to", "specify", "djava"], "project": "dubbo"}
{"id": 122, "code": "default void removeListener(String key, ConfigurationListener listener) {\n    removeListener(key, getDefaultGroup(), listener);\n}", "summary_tokens": ["remove", "listener", "string", "string", "configuration", "listener"], "project": "dubbo"}
{"id": 88, "code": "default Class<?> compile(Class<?> neighbor, String code, ClassLoader classLoader) {\n    return compile(code, classLoader);\n}", "summary_tokens": ["compile", "java", "source", "code"], "project": "dubbo"}
{"id": 881, "code": "public void timeoutNotSend() throws Exception {\n    final DateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd HH:mm:ss\");\n    System.out.println(\"before a future is create , time is : \" + LocalDateTime.now().format(formatter));\n        \n    DefaultFuture f = defaultFuture(5000);\n    while (!f.isDone()) {\n            \n        Thread.sleep(100);\n    }\n    System.out.println(\"after a future is timeout , time is : \" + LocalDateTime.now().format(formatter));\n\n        \n    try {\n        f.get();\n    } catch (Exception e) {\n        Assertions.assertTrue(e.getCause() instanceof TimeoutException, \"catch exception is not timeout exception!\");\n        System.out.println(e.getMessage());\n    }\n}", "summary_tokens": ["for", "example", "it", "will", "print", "like", "this", "before", "a", "future", "is", "create", "time", "is", "0", "0", "0", "0", "0", "0", "after", "a", "future", "is", "timeout", "time", "is", "0", "0", "0", "0", "0", "0", "p", "the", "exception", "info", "print", "like", "sending", "request", "timeout", "in", "client", "side", "by", "scan", "timer"], "project": "dubbo"}
{"id": 951, "code": "public void setMethodName(String methodName) {\n    set(METHOD_NAME, methodName);\n}", "summary_tokens": ["set", "target", "method", "name"], "project": "dubbo"}
{"id": 637, "code": "default void setSource(BeanMetadataElement beanMetadataElement) {\n    if (beanMetadataElement instanceof BeanMetadataAttributeAccessor) {\n        BeanMetadataAttributeAccessor.class.cast(beanMetadataElement).setSource(this);\n    }\n}", "summary_tokens": ["set", "the", "source", "into", "the", "specified", "bean", "metadata", "element"], "project": "dubbo"}
{"id": 375, "code": "public static String stripEnd(final String str, final String stripChars) {\n    int end;\n    if (str == null || (end = str.length()) == 0) {\n        return str;\n    }\n\n    if (stripChars == null) {\n        while (end != 0 && Character.isWhitespace(str.charAt(end - 1))) {\n            end--;\n        }\n    } else if (stripChars.isEmpty()) {\n        return str;\n    } else {\n        while (end != 0 && stripChars.indexOf(str.charAt(end - 1)) != INDEX_NOT_FOUND) {\n            end--;\n        }\n    }\n    return str.substring(0, end);\n}", "summary_tokens": ["p", "strips", "any", "of", "a", "set", "of", "characters", "from", "the", "end", "of", "a", "string"], "project": "dubbo"}
{"id": 652, "code": "private void registerAnnotationConfigProcessors(BeanDefinitionRegistry registry) {\n    AnnotationConfigUtils.registerAnnotationConfigProcessors(registry);\n}", "summary_tokens": ["register", "the", "processors", "for", "the", "spring", "annotation", "driven", "features"], "project": "dubbo"}
{"id": 880, "code": "URL toClientURL(URL url) {\n    Map<String, String> parameterMap = new HashMap<>();\n        \n    if (url.getParameter(TIMEOUT_KEY) != null) {\n        parameterMap.put(TIMEOUT_KEY, url.getParameter(TIMEOUT_KEY));\n    }\n    if (url.getParameter(RemotingConstants.BACKUP_KEY) != null) {\n        parameterMap.put(RemotingConstants.BACKUP_KEY, url.getParameter(RemotingConstants.BACKUP_KEY));\n    }\n\n    return new ServiceConfigURL(url.getProtocol(), url.getUsername(), url.getPassword(), url.getHost(), url.getPort(),\n            ZookeeperTransporter.class.getName(), parameterMap);\n}", "summary_tokens": ["redefine", "the", "url", "for", "zookeeper"], "project": "dubbo"}
{"id": 687, "code": "public void put(Object key, Object value) {\n    store.put(key, value);\n}", "summary_tokens": ["api", "to", "store", "value", "against", "a", "key", "in", "the", "calling", "thread", "scope"], "project": "dubbo"}
{"id": 677, "code": "public String getInternalProperty(String key) {\n    return dubboConfig.getProperty(key, null);\n}", "summary_tokens": ["this", "method", "will", "be", "used", "by", "configuration", "to", "get", "valid", "value", "at", "runtime"], "project": "dubbo"}
{"id": 190, "code": "public void run() {\n    try{\n        runnable.run();\n    }finally {\n        InternalThreadLocal.removeAll();\n    }\n}", "summary_tokens": ["after", "the", "task", "execution", "is", "completed", "it", "will", "call", "internal", "thread", "local", "remove", "all", "to", "clear", "unnecessary", "variables", "in", "the", "thread"], "project": "dubbo"}
{"id": 792, "code": "private void refreshInvoker(List<URL> invokerUrls) {\n    Assert.notNull(invokerUrls, \"invokerUrls should not be null\");\n\n    if (invokerUrls.size() == 1\n        && invokerUrls.get(0) != null\n        && EMPTY_PROTOCOL.equals(invokerUrls.get(0).getProtocol())) {\n        this.forbidden = true; \n        routerChain.setInvokers(BitList.emptyList());\n        destroyAllInvokers(); \n    } else {\n        this.forbidden = false; \n\n        if (invokerUrls == Collections.<URL>emptyList()) {\n            invokerUrls = new ArrayList<>();\n        }\n            \n        Set<URL> localCachedInvokerUrls = this.cachedInvokerUrls;\n        if (invokerUrls.isEmpty() && localCachedInvokerUrls != null) {\n\n                \n            logger.warn(\"1-4\", \"configuration \", \"\",\n                \"Service\" + serviceKey + \" received empty address list with no EMPTY protocol set, trigger empty protection.\");\n\n            invokerUrls.addAll(localCachedInvokerUrls);\n\n        } else {\n            localCachedInvokerUrls = new HashSet<>();\n            localCachedInvokerUrls.addAll(invokerUrls);\n            this.cachedInvokerUrls = localCachedInvokerUrls;\n        }\n        if (invokerUrls.isEmpty()) {\n            return;\n        }\n\n            \n        Map<URL, Invoker<T>> localUrlInvokerMap = this.urlInvokerMap;\n            \n        Map<URL, Invoker<T>> oldUrlInvokerMap = null;\n        if (localUrlInvokerMap != null) {\n                \n            oldUrlInvokerMap = new LinkedHashMap<>(Math.round(1 + localUrlInvokerMap.size() / DEFAULT_HASHMAP_LOAD_FACTOR));\n            localUrlInvokerMap.forEach(oldUrlInvokerMap::put);\n        }\n        Map<URL, Invoker<T>> newUrlInvokerMap = toInvokers(oldUrlInvokerMap, invokerUrls);\n\n            \n        if (CollectionUtils.isEmptyMap(newUrlInvokerMap)) {\n\n                \n\n            logger.error(\n                \"3-1\", \"inconsistency between the client protocol and the protocol of the server\",\n                \"\", \"urls to invokers error\",\n                new IllegalStateException(\n                    \"urls to invokers error. invokerUrls.size :\" +\n                        invokerUrls.size() + \", invoker.size :0. urls :\" + invokerUrls.toString()));\n\n            return;\n        }\n\n        List<Invoker<T>> newInvokers = Collections.unmodifiableList(new ArrayList<>(newUrlInvokerMap.values()));\n        this.setInvokers(multiGroup ? new BitList<>(toMergeInvokerList(newInvokers)) : new BitList<>(newInvokers));\n            \n        routerChain.setInvokers(this.getInvokers());\n        this.urlInvokerMap = newUrlInvokerMap;\n\n        try {\n            destroyUnusedInvokers(oldUrlInvokerMap, newUrlInvokerMap); \n        } catch (Exception e) {\n            logger.warn(\"destroyUnusedInvokers error. \", e);\n        }\n\n            \n        this.invokersChanged();\n    }\n}", "summary_tokens": ["convert", "the", "invoker", "url", "list", "to", "the", "invoker", "map"], "project": "dubbo"}
{"id": 93, "code": "protected T initialize() {\n    try {\n        return callable.call();\n    } catch (Exception e) {\n        throw new RuntimeException(e.getMessage(), e);\n    }\n}", "summary_tokens": ["creates", "and", "initializes", "the", "object", "managed", "by", "this", "atomic", "initializer"], "project": "dubbo"}
{"id": 40, "code": "private <T> BitList<Invoker<T>> filterUsingStaticTag(BitList<Invoker<T>> invokers, URL url, Invocation invocation) {\n    BitList<Invoker<T>> result;\n        \n    String tag = StringUtils.isEmpty(invocation.getAttachment(TAG_KEY)) ? url.getParameter(TAG_KEY) :\n        invocation.getAttachment(TAG_KEY);\n        \n    if (!StringUtils.isEmpty(tag)) {\n        result = filterInvoker(invokers, invoker -> tag.equals(invoker.getUrl().getParameter(TAG_KEY)));\n        if (CollectionUtils.isEmpty(result) && !isForceUseTag(invocation)) {\n            result = filterInvoker(invokers, invoker -> StringUtils.isEmpty(invoker.getUrl().getParameter(TAG_KEY)));\n        }\n    } else {\n        result = filterInvoker(invokers, invoker -> StringUtils.isEmpty(invoker.getUrl().getParameter(TAG_KEY)));\n    }\n    return result;\n}", "summary_tokens": ["if", "there", "s", "no", "dynamic", "tag", "rule", "being", "set", "use", "static", "tag", "in", "url"], "project": "dubbo"}
{"id": 868, "code": "private long calculateLeastDuration(int time) {\n    if (time / HEARTBEAT_CHECK_TICK <= 0) {\n        return LEAST_HEARTBEAT_DURATION;\n    } else {\n        return time / HEARTBEAT_CHECK_TICK;\n    }\n}", "summary_tokens": ["each", "interval", "cannot", "be", "less", "than", "0", "ms"], "project": "dubbo"}
{"id": 271, "code": "public static Class<?> forName(String name, ClassLoader classLoader)\n        throws ClassNotFoundException, LinkageError {\n    return ClassUtils.forName(name, classLoader);\n}", "summary_tokens": ["replacement", "for", "code", "class"], "project": "dubbo"}
{"id": 478, "code": "public ConsumerModel lookupReferredService(String serviceKey) {\n    if (consumers.containsKey(serviceKey)) {\n        List<ConsumerModel> consumerModels = consumers.get(serviceKey);\n        return consumerModels.size() > 0 ? consumerModels.get(0) : null;\n    } else {\n        return null;\n    }\n}", "summary_tokens": ["replaced", "to", "module", "service", "repository", "lookup", "referred", "services", "string"], "project": "dubbo"}
{"id": 409, "code": "protected void postProcessAfterScopeModelChanged(ScopeModel oldScopeModel, ScopeModel newScopeModel) {\n        \n\n\n\n}", "summary_tokens": ["subclass", "should", "override", "this", "method", "to", "initialize", "its", "spi", "extensions", "and", "change", "referenced", "config", "s", "scope", "model"], "project": "dubbo"}
{"id": 518, "code": "private void aggregateUrlFromRegistry(Map<String, String> referenceParameters) {\n    checkRegistry();\n    List<URL> us = ConfigValidationUtils.loadRegistries(this, false);\n    if (CollectionUtils.isNotEmpty(us)) {\n        for (URL u : us) {\n            URL monitorUrl = ConfigValidationUtils.loadMonitor(this, u);\n            if (monitorUrl != null) {\n                u = u.putAttribute(MONITOR_KEY, monitorUrl);\n            }\n            u = u.setScopeModel(getScopeModel());\n            u = u.setServiceModel(consumerModel);\n            urls.add(u.putAttribute(REFER_KEY, referenceParameters));\n        }\n    }\n    if (urls.isEmpty()) {\n        throw new IllegalStateException(\n                \"No such any registry to reference \" + interfaceName + \" on the consumer \" + NetUtils.getLocalHost() +\n                        \" use dubbo version \" + Version.getVersion() +\n                        \", please config <dubbo:registry address=\\\"...\\\" /> to your spring config.\");\n    }\n}", "summary_tokens": ["get", "urls", "from", "the", "registry", "and", "aggregate", "them"], "project": "dubbo"}
{"id": 252, "code": "static <T> T getValue(Annotation annotation) throws IllegalArgumentException {\n    return getAttribute(annotation, \"value\");\n}", "summary_tokens": ["get", "the", "value", "attribute", "from", "the", "specified", "annotation", "annotation"], "project": "dubbo"}
{"id": 20, "code": "protected <T> Invoker<T> doSelect(List<Invoker<T>> invokers, URL url, Invocation invocation) {\n        \n    int length = invokers.size();\n\n    if (!needWeightLoadBalance(invokers, invocation)) {\n        return invokers.get(ThreadLocalRandom.current().nextInt(length));\n    }\n\n        \n    boolean sameWeight = true;\n        \n    int[] weights = new int[length];\n        \n    int totalWeight = 0;\n    for (int i = 0; i < length; i++) {\n        int weight = getWeight(invokers.get(i), invocation);\n            \n        totalWeight += weight;\n            \n        weights[i] = totalWeight;\n        if (sameWeight && totalWeight != weight * (i + 1)) {\n            sameWeight = false;\n        }\n    }\n    if (totalWeight > 0 && !sameWeight) {\n            \n        int offset = ThreadLocalRandom.current().nextInt(totalWeight);\n            \n        for (int i = 0; i < length; i++) {\n            if (offset < weights[i]) {\n                return invokers.get(i);\n            }\n        }\n    }\n        \n    return invokers.get(ThreadLocalRandom.current().nextInt(length));\n}", "summary_tokens": ["select", "one", "invoker", "between", "a", "list", "using", "a", "random", "criteria"], "project": "dubbo"}
{"id": 1026, "code": "public Set<String> dubboBasePackages(Environment environment) {\n    PropertyResolver propertyResolver = dubboScanBasePackagesPropertyResolver(environment);\n    return propertyResolver.getProperty(BASE_PACKAGES_PROPERTY_NAME, Set.class, emptySet());\n}", "summary_tokens": ["the", "bean", "is", "used", "to", "scan", "the", "packages", "of", "dubbo", "service", "classes"], "project": "dubbo"}
{"id": 697, "code": "public void put(Object key, Object value) {\n    store.get().put(key, value);\n}", "summary_tokens": ["api", "to", "store", "value", "against", "a", "key", "in", "the", "calling", "thread", "scope"], "project": "dubbo"}
{"id": 49, "code": "public void testInvokerToException() {\n    String menu = \"first\";\n    List<String> menuItems = new ArrayList<String>() {\n        {\n            add(\"1\");\n            add(\"2\");\n        }\n    };\n\n    given(invocation.getMethodName()).willReturn(\"addMenu\");\n    given(invocation.getParameterTypes()).willReturn(new Class<?>[]{String.class, List.class});\n    given(invocation.getArguments()).willReturn(new Object[]{menu, menuItems});\n    given(invocation.getObjectAttachments()).willReturn(new HashMap<>());\n    given(invocation.getInvoker()).willReturn(firstInvoker);\n\n    given(firstInvoker.getUrl()).willReturn(url.addParameter(GROUP_KEY, \"first\"));\n    given(firstInvoker.getInterface()).willReturn(MenuService.class);\n    given(firstInvoker.invoke(invocation)).willReturn(new AppResponse());\n    given(firstInvoker.isAvailable()).willReturn(true);\n    given(firstInvoker.invoke(invocation)).willThrow(new RpcException(RpcException.NETWORK_EXCEPTION));\n\n    given(secondInvoker.getUrl()).willReturn(url.addParameter(GROUP_KEY, \"second\"));\n    given(secondInvoker.getInterface()).willReturn(MenuService.class);\n    given(secondInvoker.invoke(invocation)).willReturn(new AppResponse());\n    given(secondInvoker.isAvailable()).willReturn(true);\n    given(secondInvoker.invoke(invocation)).willThrow(new RpcException(RpcException.NETWORK_EXCEPTION));\n\n    given(directory.list(invocation)).willReturn(new ArrayList() {\n\n        {\n            add(firstInvoker);\n            add(secondInvoker);\n        }\n    });\n    given(directory.getUrl()).willReturn(url);\n    given(directory.getConsumerUrl()).willReturn(url);\n    given(directory.getConsumerUrl()).willReturn(url);\n    given(directory.getInterface()).willReturn(MenuService.class);\n\n    mergeableClusterInvoker = new MergeableClusterInvoker<MenuService>(directory);\n\n        \n    try {\n        Result result = mergeableClusterInvoker.invoke(invocation);\n        fail();\n        Assertions.assertNull(result.getValue());\n    } catch (RpcException expected) {\n        assertEquals(expected.getCode(), RpcException.NETWORK_EXCEPTION);\n    }\n}", "summary_tokens": ["test", "when", "network", "exception"], "project": "dubbo"}
{"id": 761, "code": "default void removeServiceInstancesChangedListener(ServiceInstancesChangedListener listener)", "summary_tokens": ["unsubscribe", "to", "instance", "change", "event"], "project": "dubbo"}
{"id": 273, "code": "public static boolean isTypeMatch(Class<?> type, String value) {\nreturn ClassUtils.isTypeMatch(type,value);\n}", "summary_tokens": ["we", "only", "check", "boolean", "value", "at", "this", "moment"], "project": "dubbo"}
{"id": 79, "code": "private static String getFromFile(String file) {\n        \n    file = file.substring(0, file.length() - 4);\n\n        \n    int i = file.lastIndexOf('/');\n    if (i >= 0) {\n        file = file.substring(i + 1);\n    }\n\n        \n    i = file.indexOf(\"-\");\n    if (i >= 0) {\n        file = file.substring(i + 1);\n    }\n\n        \n    while (file.length() > 0 && !Character.isDigit(file.charAt(0))) {\n        i = file.indexOf(\"-\");\n        if (i >= 0) {\n            file = file.substring(i + 1);\n        } else {\n            break;\n        }\n    }\n    return file;\n}", "summary_tokens": ["get", "version", "from", "file", "path", "to", "group", "module", "x"], "project": "dubbo"}
{"id": 611, "code": "protected void assertUrlStringWithLocalTable(String paramStringFromDb,\n                                             Object[][] dataTable, String configName, int column) {\n    final String FAILLOG_HEADER = \"The following config items are not found in URLONE: \";\n\n    log.warn(\"Verifying service url for \" + configName + \"... \");\n    log.warn(\"Consumer url string: \" + paramStringFromDb);\n\n    String failLog = FAILLOG_HEADER;\n    for (Object[] row : dataTable) {\n\n        String targetString = genParamString(row[URL_KEY], row[column]);\n\n        log.warn(\"Checking \" + (String) row[KEY] + \"for\" + targetString);\n        if (paramStringFromDb.contains(targetString)) {\n            log.warn((String) row[KEY] + \" --> \" + targetString + \" OK!\");\n        } else {\n            failLog += targetString + \", \";\n        }\n    }\n\n    if (!failLog.equals(FAILLOG_HEADER)) {\n        fail(failLog);\n    }\n}", "summary_tokens": ["param", "string", "from", "db", "data", "table", "config", "name", "column"], "project": "dubbo"}
{"id": 381, "code": "public static boolean isNotEmpty(String str) {\n    return !isEmpty(str);\n}", "summary_tokens": ["is", "not", "empty", "string"], "project": "dubbo"}
{"id": 777, "code": "protected void notifyAddressChanged() {\n        \n    listeners.forEach((serviceKey, listenerSet) -> {\n            \n        for (NotifyListenerWithKey listenerWithKey : listenerSet) {\n            NotifyListener notifyListener = listenerWithKey.getNotifyListener();\n\n            List<URL> urls = toUrlsWithEmpty(getAddresses(listenerWithKey.getProtocolServiceKey(), notifyListener.getConsumerUrl()));\n            logger.info(\"Notify service \" + listenerWithKey.getProtocolServiceKey() + \" with urls \" + urls.size());\n            notifyListener.notify(urls);\n        }\n    });\n}", "summary_tokens": ["race", "condition", "is", "protected", "by", "on", "event", "do", "on", "event"], "project": "dubbo"}
